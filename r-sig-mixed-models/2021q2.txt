From @|mont@pper @end|ng |rom trentu@c@  Thu Apr  1 21:48:31 2021
From: @|mont@pper @end|ng |rom trentu@c@ (Simon Tapper)
Date: Thu, 1 Apr 2021 15:48:31 -0400
Subject: [R-sig-ME] Random effect variance estimates not matching in
 MCMCglmm and brms
Message-ID: <CALuZoL4gb9C-q2K8=usOG3t6O_cieQO7_-P3MqnpCQ4K8QrHbQ@mail.gmail.com>

Hi All,

I've run an analysis in MCMCglmm and in brms and am getting somewhat
different results in the random slope and sigma estimates between the two
packages. For my analysis, I applied a treatment to a group of animals, and
am trying to estimate heterogeneous variance components for each treatment.
In both packages, I've run the model with uninformative priors for the
random effect and residual components. I'm wondering if the discrepancy in
results is from how the two packages estimate the random slopes, or if from
differences in how I set the priors. I cannot provide reproducible data for
this question, but perhaps one can help me directly translate the MCMCglmm
priors into brms.

MCMCglmm model:

prior_MCMC <- list(B = list(mu = c(35, 0, -0.5, 0.05, 0), V=diag(5) * 1.5),
                  R = list(V = diag(2), nu = 1.002),
                  G = list(G1 = list(V = diag(2), nu =1.002),
                              G2 = list(V = diag(2), nu = 1.002)))

parallel::mclapply(1:3, function(i) {
  MCMCglmm(DV ~ Treatment*X + Y,
                 random =~us(at.level(Treatment, 1)+
                               at.level(Treatment, 1):X):ID +
                 us(at.level(Treatment, 2)+
                      at.level(Treatment, 2):X):ID,
                 data=data.frame(data),
                 rcov = ~idh(Treatment):units,
                 prior=prior_MCMC,
                 pr=T,
                 nitt=120000,
                 burnin=40000,
                 thin=30,
                 verbose=F)
}, mc.cores=4)

From my understanding, in MCMCglmm, when V=1, this is equivalent to an
inverse gamma distribution with shape and scale parameters set to nu/2. So,
whe nu = 1.002 in MCMCglmm, this would be 0.501 for a brms inverse gamma
prior. For the fixed effects in MCMCglmm, are the priors set properly for
mu? where DV = 35, Treatment_1 = 0, Treatment_2 = -0.5, X= 0.05, Y = 0.

brms model:

prior_treat <- c(
  set_prior("normal(35, 1.5)", class = "Intercept"),
  set_prior("normal(-0.5, 1.5)", class="b", coef="Treatment"),
  set_prior("normal(0.05, 1.5)", class="b", coef="X"),
  set_prior("normal(0, 1.5)", class="b", coef="Y"),
  set_prior("inv_gamma(0.501, 0.501)", class = "sd"),
  set_prior("inv_gamma(0.501, 0.501)", class = "b", lb=0, dpar="sigma"))

brm(bf(DV ~ Treatment*X + Y +
               (1 + X|gr(ID, by=Treatment)),
                 sigma~Treatment),
                data=data.frame(data),
                warmup = 1000,
                iter = 10000,
                chains = 3,
                thin = 10,
                cores = 4,
                seed = 123,
                sample_prior = TRUE,
                prior = prior_treat,
                control = list(adapt_delta = 0.95, max_treedepth=13))

Results:
In MCMCglmm,the variance for the slope estimates (for both treatments) ?
95% credible intervals are ~0.2 (0.05-0.5) and sigma = ~0.1. In brms, the
variance for the slope estimates (for both treatments) ? 95% credible
intervals are one order of magnitude lower, ~0.01 (0.0025-0.01) and sigma =
0.01. Oddly, the variance and credible interval estimates for the random
intercepts appear pretty similar between packages.

Any help would be appreciated,
Simon

	[[alternative HTML version deleted]]


From @|m@h@rme| @end|ng |rom gm@||@com  Fri Apr  2 05:19:28 2021
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Thu, 1 Apr 2021 22:19:28 -0500
Subject: [R-sig-ME] Random effects variances in R and SPSS not matching
In-Reply-To: <33215e2d-d3cf-bcc5-14c8-be4991269f47@phillipalday.com>
References: <CACgv6yXjhONDiJqvJYTbT9MZobp0HtHZzavyJ1mfEnWq4vAOCA@mail.gmail.com>
 <4ca98023-0453-c6f5-fabd-8aa9f322614f@phillipalday.com>
 <CACgv6yUy0aW4wag8+-GkrUCVTPg9L=fCo5onDGahgxg1Qnq0yQ@mail.gmail.com>
 <33215e2d-d3cf-bcc5-14c8-be4991269f47@phillipalday.com>
Message-ID: <CACgv6yXLXPWZobgZBKNEq__GajV+OxRC_COhb6vG=UNB66LsDw@mail.gmail.com>

Thank you so very much for your assistance.

On Wed, Mar 31, 2021 at 4:18 PM Phillip Alday <me at phillipalday.com> wrote:

> I don't think the optimum is well defined:
>
> > library("lattice")
> > library("lme4")
> > m2.4 <- lmer(value ~0 + name + (0+name| Student), data = dat,
> REML=FALSE,
> control=lmerControl(optimizer="bobyqa",check.nobs.vs.nRE="warning"))
> Warning messages:
> 1: number of observations (=1600) <= number of random effects (=1600)
> for term (0 + name | Student); the random-effects parameters and the
> residual variance (or scale parameter) are probably unidentifiable
> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model is nearly unidentifiable: large eigenvalue ratio
>  - Rescale variables?
> > p <- profile(m2.4)
> There were 50 or more warnings (use warnings() to see the first 50)
> > xyplot(p)
>
> Those are some very bad profiles! Also, this goes back to the lme4
> safety-check that I had to disable. The fundamental problem is that
> there isn't enough data to completely distinguish the residual variance
> from the RE, so you get difference answers for the RE variance depending
> on how much you attribute to the residual variance.
>
> I also tried to do this with MCMC and flat priors (always a bad idea,
> but...) and also ran into bad convergence issues.
>
> Phillip
>
>
>
> On 31/3/21 10:43 pm, Simon Harmel wrote:
> > Thank you. I'll be happy to give more info. SPSS model syntax is shown
> > on in Table 14.5, p. 585 (type `606` in page slot) of this book
> > (http://docshare02.docshare.tips/files/31719/317194846.pdf).
> >
> > The SPSS output is shown on p. 588 (type `606` in page slot).
> >
> > I should add the covariance between `Y1` and `Y2` exactly match. and the
> > log-likelihood seems to be almost identical. But variances differ by a
> > lot. SPSS is using "ML".
> >
> > Please let me know if I can provide any further information.
> >
> > Thank you for your prompt reply,
> > Simon
> >
> >
> >
> >
> > On Wed, Mar 31, 2021 at 3:36 PM Phillip Alday <me at phillipalday.com
> > <mailto:me at phillipalday.com>> wrote:
> >
> >     Without more information, we don't know for sure that the models are
> the
> >     same in both languages.
> >
> >     It's too much of a time sink for a human to change model details
> >     randomly until the output matches some expected output, but you could
> >     probably do something with genetic programming or simulated
> annealing to
> >     do that....
> >
> >     But if you can get more information, I would start by making sure
> >     - that the contrasts are truly the same
> >     - assumed covariance structures are the same
> >     - that one language isn't dropping some observations that the other
> is
> >     keeping (check the reporting number of observations levels of the
> >     grouping var)
> >     - the estimation method is the same across languages (ML,REML;
> hopefully
> >     SPSS isn't using something like quasi-likelihood)
> >     - different optimizers (if available) give the same  result across
> >     languages (i.e. make sure you're not in a local optimum)
> >     - cross checking the result against yet another software package
> >
> >     For example, cross-checking against lme4 immediately hints that this
> >     model might not be advisable / have a well-defined optimum:
> >
> >     > m2.4 <- lmer(value ~0 + name + (0 + name| Student), data = dat,
> >     REML=FALSE)
> >     Error: number of observations (=1600) <= number of random effects
> >     (=1600) for term (0 + name | Student); the random-effects parameters
> and
> >     the residual variance (or scale parameter) are probably
> unidentifiable
> >
> >     Phillip
> >
> >     On 31/3/21 10:15 pm, Simon Harmel wrote:
> >     > Dear All,
> >     >
> >     > For my reproducible model below, SPSS gives the variance component
> of
> >     > 119.95 for Y1, and 127.90 for Y2.
> >     >
> >     > But in `nlme::lme()` my variance components are 105.78 for Y1 and
> >     113.73
> >     > for Y2.
> >     >
> >     > Can we make the `lme()` reproduce the SPSS's variance components?
> >     >
> >     > #======= Data and R code:
> >     > dat <-
> >     read.csv('https://raw.githubusercontent.com/hkil/m/master/mv.l.csv')
> >     >
> >     > library(nlme)
> >     >
> >     > m2 <- lme(value ~0 + name, random = ~0 + name| Student, data =
> >     dat, method
> >     > = "ML")
> >     >
> >     > Random effects variance covariance matrix
> >     >              nameY1   nameY2
> >     > nameY1 105.780  60.869
> >     > nameY2  60.869 113.730
> >     >
> >     >       [[alternative HTML version deleted]]
> >     >
> >     > _______________________________________________
> >     > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     >
> >
>

	[[alternative HTML version deleted]]


From @|m@h@rme| @end|ng |rom gm@||@com  Fri Apr  2 05:57:39 2021
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Thu, 1 Apr 2021 22:57:39 -0500
Subject: [R-sig-ME] Random effects variances in R and SPSS not matching
In-Reply-To: <CACgv6yXLXPWZobgZBKNEq__GajV+OxRC_COhb6vG=UNB66LsDw@mail.gmail.com>
References: <CACgv6yXjhONDiJqvJYTbT9MZobp0HtHZzavyJ1mfEnWq4vAOCA@mail.gmail.com>
 <4ca98023-0453-c6f5-fabd-8aa9f322614f@phillipalday.com>
 <CACgv6yUy0aW4wag8+-GkrUCVTPg9L=fCo5onDGahgxg1Qnq0yQ@mail.gmail.com>
 <33215e2d-d3cf-bcc5-14c8-be4991269f47@phillipalday.com>
 <CACgv6yXLXPWZobgZBKNEq__GajV+OxRC_COhb6vG=UNB66LsDw@mail.gmail.com>
Message-ID: <CACgv6yXrAyp0---CWbm=Jonwj1nX4WZkFFYoHO+iVj4MAQfXWQ@mail.gmail.com>

Dear Ben,

I should add that using `control = lmeControl(sigma=1e-5, opt ="optim")`
does make the random effects variances from `lme()` match that of SPSS but
t completely change -2*logLik(model).

Specifically, before using  `control = lmeControl(sigma=1e-5, opt
="optim")`, the  -2*logLik(model_SPSS) =  -2*logLik(model_lme).
But,  after using  `control = lmeControl(sigma=1e-5, opt ="optim")`, the
-2*logLik(model_SPSS) NOT equal to   -2*logLik(model_lme).

Thanks,
Simon

On Thu, Apr 1, 2021 at 10:19 PM Simon Harmel <sim.harmel at gmail.com> wrote:

> Thank you so very much for your assistance.
>
> On Wed, Mar 31, 2021 at 4:18 PM Phillip Alday <me at phillipalday.com> wrote:
>
>> I don't think the optimum is well defined:
>>
>> > library("lattice")
>> > library("lme4")
>> > m2.4 <- lmer(value ~0 + name + (0+name| Student), data = dat,
>> REML=FALSE,
>> control=lmerControl(optimizer="bobyqa",check.nobs.vs.nRE="warning"))
>> Warning messages:
>> 1: number of observations (=1600) <= number of random effects (=1600)
>> for term (0 + name | Student); the random-effects parameters and the
>> residual variance (or scale parameter) are probably unidentifiable
>> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>   Model is nearly unidentifiable: large eigenvalue ratio
>>  - Rescale variables?
>> > p <- profile(m2.4)
>> There were 50 or more warnings (use warnings() to see the first 50)
>> > xyplot(p)
>>
>> Those are some very bad profiles! Also, this goes back to the lme4
>> safety-check that I had to disable. The fundamental problem is that
>> there isn't enough data to completely distinguish the residual variance
>> from the RE, so you get difference answers for the RE variance depending
>> on how much you attribute to the residual variance.
>>
>> I also tried to do this with MCMC and flat priors (always a bad idea,
>> but...) and also ran into bad convergence issues.
>>
>> Phillip
>>
>>
>>
>> On 31/3/21 10:43 pm, Simon Harmel wrote:
>> > Thank you. I'll be happy to give more info. SPSS model syntax is shown
>> > on in Table 14.5, p. 585 (type `606` in page slot) of this book
>> > (http://docshare02.docshare.tips/files/31719/317194846.pdf).
>> >
>> > The SPSS output is shown on p. 588 (type `606` in page slot).
>> >
>> > I should add the covariance between `Y1` and `Y2` exactly match. and the
>> > log-likelihood seems to be almost identical. But variances differ by a
>> > lot. SPSS is using "ML".
>> >
>> > Please let me know if I can provide any further information.
>> >
>> > Thank you for your prompt reply,
>> > Simon
>> >
>> >
>> >
>> >
>> > On Wed, Mar 31, 2021 at 3:36 PM Phillip Alday <me at phillipalday.com
>> > <mailto:me at phillipalday.com>> wrote:
>> >
>> >     Without more information, we don't know for sure that the models
>> are the
>> >     same in both languages.
>> >
>> >     It's too much of a time sink for a human to change model details
>> >     randomly until the output matches some expected output, but you
>> could
>> >     probably do something with genetic programming or simulated
>> annealing to
>> >     do that....
>> >
>> >     But if you can get more information, I would start by making sure
>> >     - that the contrasts are truly the same
>> >     - assumed covariance structures are the same
>> >     - that one language isn't dropping some observations that the other
>> is
>> >     keeping (check the reporting number of observations levels of the
>> >     grouping var)
>> >     - the estimation method is the same across languages (ML,REML;
>> hopefully
>> >     SPSS isn't using something like quasi-likelihood)
>> >     - different optimizers (if available) give the same  result across
>> >     languages (i.e. make sure you're not in a local optimum)
>> >     - cross checking the result against yet another software package
>> >
>> >     For example, cross-checking against lme4 immediately hints that this
>> >     model might not be advisable / have a well-defined optimum:
>> >
>> >     > m2.4 <- lmer(value ~0 + name + (0 + name| Student), data = dat,
>> >     REML=FALSE)
>> >     Error: number of observations (=1600) <= number of random effects
>> >     (=1600) for term (0 + name | Student); the random-effects
>> parameters and
>> >     the residual variance (or scale parameter) are probably
>> unidentifiable
>> >
>> >     Phillip
>> >
>> >     On 31/3/21 10:15 pm, Simon Harmel wrote:
>> >     > Dear All,
>> >     >
>> >     > For my reproducible model below, SPSS gives the variance
>> component of
>> >     > 119.95 for Y1, and 127.90 for Y2.
>> >     >
>> >     > But in `nlme::lme()` my variance components are 105.78 for Y1 and
>> >     113.73
>> >     > for Y2.
>> >     >
>> >     > Can we make the `lme()` reproduce the SPSS's variance components?
>> >     >
>> >     > #======= Data and R code:
>> >     > dat <-
>> >     read.csv('https://raw.githubusercontent.com/hkil/m/master/mv.l.csv
>> ')
>> >     >
>> >     > library(nlme)
>> >     >
>> >     > m2 <- lme(value ~0 + name, random = ~0 + name| Student, data =
>> >     dat, method
>> >     > = "ML")
>> >     >
>> >     > Random effects variance covariance matrix
>> >     >              nameY1   nameY2
>> >     > nameY1 105.780  60.869
>> >     > nameY2  60.869 113.730
>> >     >
>> >     >       [[alternative HTML version deleted]]
>> >     >
>> >     > _______________________________________________
>> >     > R-sig-mixed-models at r-project.org
>> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
>> >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >     >
>> >
>>
>

	[[alternative HTML version deleted]]


From j@h@d||e|d @end|ng |rom ed@@c@uk  Fri Apr  2 07:05:39 2021
From: j@h@d||e|d @end|ng |rom ed@@c@uk (Jarrod Hadfield)
Date: Fri, 2 Apr 2021 06:05:39 +0100
Subject: [R-sig-ME] Random effect variance estimates not matching in
 MCMCglmm and brms
In-Reply-To: <CALuZoL4gb9C-q2K8=usOG3t6O_cieQO7_-P3MqnpCQ4K8QrHbQ@mail.gmail.com>
References: <CALuZoL4gb9C-q2K8=usOG3t6O_cieQO7_-P3MqnpCQ4K8QrHbQ@mail.gmail.com>
Message-ID: <748ce215-9ff6-d303-63e0-26706e2452a6@ed.ac.uk>

Hi,

With a 2x2 us structure the marginal dsitribution of a variance is
inverse-Wishart with nu*=nu-1 and V*=V*nu/(nu-1), so in your case
nu*=0.002 and V*=501. This is inverse gamma with shape = nu*/2= 0.001
and scale (nu*)*(V*)/2=0.501, not 0.501 for both.

With an idh structure the marginal dsitribution of a variance is simply
inverse-Wishart with nu*=nu and V*=V which is inverse-gamma with a shape
and scale (in your case) of 0.001.

I don't use brms so I'm not exactly clear what model/prior is being
used, but is the second argument to normal in the prior a variance?
Typically a standard deviation is used so you might want to square-root
the 1.5 in the fixed effect prior.

I'm also not sure what is happening about the intercpet-slope covariance
in brms?

Cheers,

Jarrod



On 01/04/2021 20:48, Simon Tapper wrote:
> This email was sent to you by someone outside the University.
> You should only click on links or attachments if you are certain that the email is genuine and the content is safe.
>
> Hi All,
>
> I've run an analysis in MCMCglmm and in brms and am getting somewhat
> different results in the random slope and sigma estimates between the two
> packages. For my analysis, I applied a treatment to a group of animals, and
> am trying to estimate heterogeneous variance components for each treatment.
> In both packages, I've run the model with uninformative priors for the
> random effect and residual components. I'm wondering if the discrepancy in
> results is from how the two packages estimate the random slopes, or if from
> differences in how I set the priors. I cannot provide reproducible data for
> this question, but perhaps one can help me directly translate the MCMCglmm
> priors into brms.
>
> MCMCglmm model:
>
> prior_MCMC <- list(B = list(mu = c(35, 0, -0.5, 0.05, 0), V=diag(5) * 1.5),
>                    R = list(V = diag(2), nu = 1.002),
>                    G = list(G1 = list(V = diag(2), nu =1.002),
>                                G2 = list(V = diag(2), nu = 1.002)))
>
> parallel::mclapply(1:3, function(i) {
>    MCMCglmm(DV ~ Treatment*X + Y,
>                   random =~us(at.level(Treatment, 1)+
>                                 at.level(Treatment, 1):X):ID +
>                   us(at.level(Treatment, 2)+
>                        at.level(Treatment, 2):X):ID,
>                   data=data.frame(data),
>                   rcov = ~idh(Treatment):units,
>                   prior=prior_MCMC,
>                   pr=T,
>                   nitt=120000,
>                   burnin=40000,
>                   thin=30,
>                   verbose=F)
> }, mc.cores=4)
>
>  From my understanding, in MCMCglmm, when V=1, this is equivalent to an
> inverse gamma distribution with shape and scale parameters set to nu/2. So,
> whe nu = 1.002 in MCMCglmm, this would be 0.501 for a brms inverse gamma
> prior. For the fixed effects in MCMCglmm, are the priors set properly for
> mu? where DV = 35, Treatment_1 = 0, Treatment_2 = -0.5, X= 0.05, Y = 0.
>
> brms model:
>
> prior_treat <- c(
>    set_prior("normal(35, 1.5)", class = "Intercept"),
>    set_prior("normal(-0.5, 1.5)", class="b", coef="Treatment"),
>    set_prior("normal(0.05, 1.5)", class="b", coef="X"),
>    set_prior("normal(0, 1.5)", class="b", coef="Y"),
>    set_prior("inv_gamma(0.501, 0.501)", class = "sd"),
>    set_prior("inv_gamma(0.501, 0.501)", class = "b", lb=0, dpar="sigma"))
>
> brm(bf(DV ~ Treatment*X + Y +
>                 (1 + X|gr(ID, by=Treatment)),
>                   sigma~Treatment),
>                  data=data.frame(data),
>                  warmup = 1000,
>                  iter = 10000,
>                  chains = 3,
>                  thin = 10,
>                  cores = 4,
>                  seed = 123,
>                  sample_prior = TRUE,
>                  prior = prior_treat,
>                  control = list(adapt_delta = 0.95, max_treedepth=13))
>
> Results:
> In MCMCglmm,the variance for the slope estimates (for both treatments) ?
> 95% credible intervals are ~0.2 (0.05-0.5) and sigma = ~0.1. In brms, the
> variance for the slope estimates (for both treatments) ? 95% credible
> intervals are one order of magnitude lower, ~0.01 (0.0025-0.01) and sigma =
> 0.01. Oddly, the variance and credible interval estimates for the random
> intercepts appear pretty similar between packages.
>
> Any help would be appreciated,
> Simon
>
>          [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
The University of Edinburgh is a charitable body, registered in Scotland, with registration number SC005336. Is e buidheann carthannais a th? ann an Oilthigh Dh?n ?ideann, cl?raichte an Alba, ?ireamh cl?raidh SC005336.


From kj@j@o|omon @end|ng |rom gm@||@com  Sat Apr  3 00:55:07 2021
From: kj@j@o|omon @end|ng |rom gm@||@com (Jack Solomon)
Date: Fri, 2 Apr 2021 17:55:07 -0500
Subject: [R-sig-ME] Confidence interval around random effect variances in
 place of p-value
Message-ID: <CA+sL+8XgaEBMnGVPCJywV_RUjQdX0=+-xy2f7D-rj_5iwz_8eg@mail.gmail.com>

Dear All,

A colleague of mine suggested that I use the bootstrapped CIs around my
model's random effect variances in place of p-values for them.

But random effect variances (or sds) start from "0". So, to declare a
statistically NON-significant random effect variance component, the
lower bound of the CI must be EXACTLY "0", right?

Thank you very much,
Jack

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Sat Apr  3 01:19:02 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 2 Apr 2021 19:19:02 -0400
Subject: [R-sig-ME] 
 Confidence interval around random effect variances in
 place of p-value
In-Reply-To: <CA+sL+8XgaEBMnGVPCJywV_RUjQdX0=+-xy2f7D-rj_5iwz_8eg@mail.gmail.com>
References: <CA+sL+8XgaEBMnGVPCJywV_RUjQdX0=+-xy2f7D-rj_5iwz_8eg@mail.gmail.com>
Message-ID: <c86b9720-ada6-68b0-217d-8821e2dc5a11@gmail.com>

   This seems like a potential can of worms (as indeed are all 
hypothesis tests of null values on a boundary ...) However, in this case 
bootstrapping (provided you have resampled appropriately - you may need 
to do hierarchical bootstrapping ...) seems reasonable, because a null 
model would give you singular fits (i.e. estimated sd=0) half of the 
time ...

   Happy to hear more informed opinions.

On 4/2/21 6:55 PM, Jack Solomon wrote:
> Dear All,
> 
> A colleague of mine suggested that I use the bootstrapped CIs around my
> model's random effect variances in place of p-values for them.
> 
> But random effect variances (or sds) start from "0". So, to declare a
> statistically NON-significant random effect variance component, the
> lower bound of the CI must be EXACTLY "0", right?
> 
> Thank you very much,
> Jack
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From kj@j@o|omon @end|ng |rom gm@||@com  Sat Apr  3 01:37:17 2021
From: kj@j@o|omon @end|ng |rom gm@||@com (Jack Solomon)
Date: Fri, 2 Apr 2021 18:37:17 -0500
Subject: [R-sig-ME] 
 Confidence interval around random effect variances in
 place of p-value
In-Reply-To: <c86b9720-ada6-68b0-217d-8821e2dc5a11@gmail.com>
References: <CA+sL+8XgaEBMnGVPCJywV_RUjQdX0=+-xy2f7D-rj_5iwz_8eg@mail.gmail.com>
 <c86b9720-ada6-68b0-217d-8821e2dc5a11@gmail.com>
Message-ID: <CA+sL+8XpWn+oxs74z-T-CdRn01Fi3fKCG_nP_u+NdsYTa-fTZA@mail.gmail.com>

Thanks. Just to make sure, to declare a statistically NON-significant
random effect variance component, the lower bound of the CI must be EXACTLY
"0", right?

Tha is, for example, a CI like: [.0002, .14] is a statistically significant
random-effect variance component but one that perhaps borders a p-value of
relatively close to but smaller than .05, right?

On Fri, Apr 2, 2021 at 6:19 PM Ben Bolker <bbolker at gmail.com> wrote:

>    This seems like a potential can of worms (as indeed are all
> hypothesis tests of null values on a boundary ...) However, in this case
> bootstrapping (provided you have resampled appropriately - you may need
> to do hierarchical bootstrapping ...) seems reasonable, because a null
> model would give you singular fits (i.e. estimated sd=0) half of the
> time ...
>
>    Happy to hear more informed opinions.
>
> On 4/2/21 6:55 PM, Jack Solomon wrote:
> > Dear All,
> >
> > A colleague of mine suggested that I use the bootstrapped CIs around my
> > model's random effect variances in place of p-values for them.
> >
> > But random effect variances (or sds) start from "0". So, to declare a
> > statistically NON-significant random effect variance component, the
> > lower bound of the CI must be EXACTLY "0", right?
> >
> > Thank you very much,
> > Jack
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com  Sat Apr  3 01:43:10 2021
From: m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com (Patrick (Malone Quantitative))
Date: Fri, 2 Apr 2021 19:43:10 -0400
Subject: [R-sig-ME] 
 Confidence interval around random effect variances in
 place of p-value
In-Reply-To: <CA+sL+8XpWn+oxs74z-T-CdRn01Fi3fKCG_nP_u+NdsYTa-fTZA@mail.gmail.com>
References: <CA+sL+8XgaEBMnGVPCJywV_RUjQdX0=+-xy2f7D-rj_5iwz_8eg@mail.gmail.com>
 <c86b9720-ada6-68b0-217d-8821e2dc5a11@gmail.com>
 <CA+sL+8XpWn+oxs74z-T-CdRn01Fi3fKCG_nP_u+NdsYTa-fTZA@mail.gmail.com>
Message-ID: <CAJc=yOE=EW0d8O8dhM7j5mfNNKyQxCEEY1hVNCnTDvou1J80ow@mail.gmail.com>

Jack,

As Ben said, testing a hypothesis at the boundary of the parameter space is
a can of worms. I think the usual approach is to use difference (likelihood
ratio) tests for the variances, testing a model with the variance
constrained to zero against the original model.

Pat

On Fri, Apr 2, 2021 at 7:37 PM Jack Solomon <kj.jsolomon at gmail.com> wrote:

> Thanks. Just to make sure, to declare a statistically NON-significant
> random effect variance component, the lower bound of the CI must be EXACTLY
> "0", right?
>
> Tha is, for example, a CI like: [.0002, .14] is a statistically significant
> random-effect variance component but one that perhaps borders a p-value of
> relatively close to but smaller than .05, right?
>
> On Fri, Apr 2, 2021 at 6:19 PM Ben Bolker <bbolker at gmail.com> wrote:
>
> >    This seems like a potential can of worms (as indeed are all
> > hypothesis tests of null values on a boundary ...) However, in this case
> > bootstrapping (provided you have resampled appropriately - you may need
> > to do hierarchical bootstrapping ...) seems reasonable, because a null
> > model would give you singular fits (i.e. estimated sd=0) half of the
> > time ...
> >
> >    Happy to hear more informed opinions.
> >
> > On 4/2/21 6:55 PM, Jack Solomon wrote:
> > > Dear All,
> > >
> > > A colleague of mine suggested that I use the bootstrapped CIs around my
> > > model's random effect variances in place of p-values for them.
> > >
> > > But random effect variances (or sds) start from "0". So, to declare a
> > > statistically NON-significant random effect variance component, the
> > > lower bound of the CI must be EXACTLY "0", right?
> > >
> > > Thank you very much,
> > > Jack
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
Patrick S. Malone, Ph.D., Malone Quantitative
NEW Service Models: http://malonequantitative.com

He/Him/His

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Sat Apr  3 01:51:56 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 2 Apr 2021 19:51:56 -0400
Subject: [R-sig-ME] 
 Confidence interval around random effect variances in
 place of p-value
In-Reply-To: <CA+sL+8XpWn+oxs74z-T-CdRn01Fi3fKCG_nP_u+NdsYTa-fTZA@mail.gmail.com>
References: <CA+sL+8XgaEBMnGVPCJywV_RUjQdX0=+-xy2f7D-rj_5iwz_8eg@mail.gmail.com>
 <c86b9720-ada6-68b0-217d-8821e2dc5a11@gmail.com>
 <CA+sL+8XpWn+oxs74z-T-CdRn01Fi3fKCG_nP_u+NdsYTa-fTZA@mail.gmail.com>
Message-ID: <11791f10-2732-54ef-7bf9-3ef394d5e379@gmail.com>

  Sure. If all you want is p-values, I'd recommend parametric 
bootstrapping (implemented in the pbkrtest package) ... that will avoid 
these difficulties.  (I would also make sure that you know *why* you 
want p-values on the random effects ... they have all of the issues of 
regular p-values plus some extras: 
http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#testing-significance-of-random-effects 
)

On 4/2/21 7:37 PM, Jack Solomon wrote:
> Thanks. Just to make sure, to declare?a statistically NON-significant 
> random effect variance component, the lower?bound of the CI must be 
> EXACTLY "0", right?
> 
> Tha is, for example, a CI like: [.0002, .14] is a 
> statistically?significant random-effect variance component but one that 
> perhaps borders a p-value of relatively close to but smaller than .05, 
> right?
> 
> On Fri, Apr 2, 2021 at 6:19 PM Ben Bolker <bbolker at gmail.com 
> <mailto:bbolker at gmail.com>> wrote:
> 
>      ? ?This seems like a potential can of worms (as indeed are all
>     hypothesis tests of null values on a boundary ...) However, in this
>     case
>     bootstrapping (provided you have resampled appropriately - you may need
>     to do hierarchical bootstrapping ...) seems reasonable, because a null
>     model would give you singular fits (i.e. estimated sd=0) half of the
>     time ...
> 
>      ? ?Happy to hear more informed opinions.
> 
>     On 4/2/21 6:55 PM, Jack Solomon wrote:
>      > Dear All,
>      >
>      > A colleague of mine suggested that I use the bootstrapped CIs
>     around my
>      > model's random effect variances in place of p-values for them.
>      >
>      > But random effect variances (or sds) start from "0". So, to declare a
>      > statistically NON-significant random effect variance component, the
>      > lower bound of the CI must be EXACTLY "0", right?
>      >
>      > Thank you very much,
>      > Jack
>      >
>      >? ? ? ?[[alternative HTML version deleted]]
>      >
>      > _______________________________________________
>      > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >
> 
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>


From kj@j@o|omon @end|ng |rom gm@||@com  Sat Apr  3 02:12:26 2021
From: kj@j@o|omon @end|ng |rom gm@||@com (Jack Solomon)
Date: Fri, 2 Apr 2021 19:12:26 -0500
Subject: [R-sig-ME] 
 Confidence interval around random effect variances in
 place of p-value
In-Reply-To: <11791f10-2732-54ef-7bf9-3ef394d5e379@gmail.com>
References: <CA+sL+8XgaEBMnGVPCJywV_RUjQdX0=+-xy2f7D-rj_5iwz_8eg@mail.gmail.com>
 <c86b9720-ada6-68b0-217d-8821e2dc5a11@gmail.com>
 <CA+sL+8XpWn+oxs74z-T-CdRn01Fi3fKCG_nP_u+NdsYTa-fTZA@mail.gmail.com>
 <11791f10-2732-54ef-7bf9-3ef394d5e379@gmail.com>
Message-ID: <CA+sL+8VCf+CQVZDV7=LhL8Fus3GT6uo6mUjSSZWSQA+=Wm9oqw@mail.gmail.com>

Thank you all very much. So, I can conclude that a likelihood ratio test
and/or a parametric bootstrapping can be used for random effect variance
component hypothesis testing.

But I also concluded that the idea of simply using a bootstrapped CI for a
random-effect variance component [e.g., in lme4;
confint(model,method="boot",oldNames=FALSE)  ] by definition can't be used
for significance testing, because it requires the possibility of seeing sd
= 0 which can't be "strictly" captured by such a CI from a multilevel model
(at least not easily so).

I hope my conclusions are correct,
Thank you all, Jack

On Fri, Apr 2, 2021 at 6:51 PM Ben Bolker <bbolker at gmail.com> wrote:

>   Sure. If all you want is p-values, I'd recommend parametric
> bootstrapping (implemented in the pbkrtest package) ... that will avoid
> these difficulties.  (I would also make sure that you know *why* you
> want p-values on the random effects ... they have all of the issues of
> regular p-values plus some extras:
>
> http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#testing-significance-of-random-effects
> )
>
> On 4/2/21 7:37 PM, Jack Solomon wrote:
> > Thanks. Just to make sure, to declare a statistically NON-significant
> > random effect variance component, the lower bound of the CI must be
> > EXACTLY "0", right?
> >
> > Tha is, for example, a CI like: [.0002, .14] is a
> > statistically significant random-effect variance component but one that
> > perhaps borders a p-value of relatively close to but smaller than .05,
> > right?
> >
> > On Fri, Apr 2, 2021 at 6:19 PM Ben Bolker <bbolker at gmail.com
> > <mailto:bbolker at gmail.com>> wrote:
> >
> >         This seems like a potential can of worms (as indeed are all
> >     hypothesis tests of null values on a boundary ...) However, in this
> >     case
> >     bootstrapping (provided you have resampled appropriately - you may
> need
> >     to do hierarchical bootstrapping ...) seems reasonable, because a
> null
> >     model would give you singular fits (i.e. estimated sd=0) half of the
> >     time ...
> >
> >         Happy to hear more informed opinions.
> >
> >     On 4/2/21 6:55 PM, Jack Solomon wrote:
> >      > Dear All,
> >      >
> >      > A colleague of mine suggested that I use the bootstrapped CIs
> >     around my
> >      > model's random effect variances in place of p-values for them.
> >      >
> >      > But random effect variances (or sds) start from "0". So, to
> declare a
> >      > statistically NON-significant random effect variance component,
> the
> >      > lower bound of the CI must be EXACTLY "0", right?
> >      >
> >      > Thank you very much,
> >      > Jack
> >      >
> >      >       [[alternative HTML version deleted]]
> >      >
> >      > _______________________________________________
> >      > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >
> >
> >     _______________________________________________
> >     R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Sat Apr  3 02:15:40 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 2 Apr 2021 20:15:40 -0400
Subject: [R-sig-ME] 
 Confidence interval around random effect variances in
 place of p-value
In-Reply-To: <CA+sL+8VCf+CQVZDV7=LhL8Fus3GT6uo6mUjSSZWSQA+=Wm9oqw@mail.gmail.com>
References: <CA+sL+8XgaEBMnGVPCJywV_RUjQdX0=+-xy2f7D-rj_5iwz_8eg@mail.gmail.com>
 <c86b9720-ada6-68b0-217d-8821e2dc5a11@gmail.com>
 <CA+sL+8XpWn+oxs74z-T-CdRn01Fi3fKCG_nP_u+NdsYTa-fTZA@mail.gmail.com>
 <11791f10-2732-54ef-7bf9-3ef394d5e379@gmail.com>
 <CA+sL+8VCf+CQVZDV7=LhL8Fus3GT6uo6mUjSSZWSQA+=Wm9oqw@mail.gmail.com>
Message-ID: <2c84aacf-4d0c-437d-d096-09c1e4c38f1b@gmail.com>

    I'm not sure that the bootstrapped CIs *wouldn't* work; they might 
return the correct proportion of singular fits ...

On 4/2/21 8:12 PM, Jack Solomon wrote:
> Thank you all?very much. So, I can conclude that a likelihood ratio test 
> and/or a parametric bootstrapping can be used for random effect variance 
> component hypothesis?testing.
> 
> But I also concluded that the idea of simply using a bootstrapped CI for 
> a random-effect variance component [e.g., in lme4;  
> confint(model,method="boot",oldNames=FALSE)? ] by definition can't be 
> used for significance testing, because it requires the possibility of 
> seeing sd = 0 which can't be "strictly" captured by such a CI from a 
> multilevel model (at least not easily so).
> 
> I hope my conclusions are correct,
> Thank you all, Jack
> 
> On Fri, Apr 2, 2021 at 6:51 PM Ben Bolker <bbolker at gmail.com 
> <mailto:bbolker at gmail.com>> wrote:
> 
>      ? Sure. If all you want is p-values, I'd recommend parametric
>     bootstrapping (implemented in the pbkrtest package) ... that will avoid
>     these difficulties.? (I would also make sure that you know *why* you
>     want p-values on the random effects ... they have all of the issues of
>     regular p-values plus some extras:
>     http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#testing-significance-of-random-effects
>     <http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#testing-significance-of-random-effects>
> 
>     )
> 
>     On 4/2/21 7:37 PM, Jack Solomon wrote:
>      > Thanks. Just to make sure, to declare?a statistically
>     NON-significant
>      > random effect variance component, the lower?bound of the CI must be
>      > EXACTLY "0", right?
>      >
>      > Tha is, for example, a CI like: [.0002, .14] is a
>      > statistically?significant random-effect variance component but
>     one that
>      > perhaps borders a p-value of relatively close to but smaller than
>     .05,
>      > right?
>      >
>      > On Fri, Apr 2, 2021 at 6:19 PM Ben Bolker <bbolker at gmail.com
>     <mailto:bbolker at gmail.com>
>      > <mailto:bbolker at gmail.com <mailto:bbolker at gmail.com>>> wrote:
>      >
>      >? ? ? ? ?This seems like a potential can of worms (as indeed are all
>      >? ? ?hypothesis tests of null values on a boundary ...) However,
>     in this
>      >? ? ?case
>      >? ? ?bootstrapping (provided you have resampled appropriately -
>     you may need
>      >? ? ?to do hierarchical bootstrapping ...) seems reasonable,
>     because a null
>      >? ? ?model would give you singular fits (i.e. estimated sd=0) half
>     of the
>      >? ? ?time ...
>      >
>      >? ? ? ? ?Happy to hear more informed opinions.
>      >
>      >? ? ?On 4/2/21 6:55 PM, Jack Solomon wrote:
>      >? ? ? > Dear All,
>      >? ? ? >
>      >? ? ? > A colleague of mine suggested that I use the bootstrapped CIs
>      >? ? ?around my
>      >? ? ? > model's random effect variances in place of p-values for them.
>      >? ? ? >
>      >? ? ? > But random effect variances (or sds) start from "0". So,
>     to declare a
>      >? ? ? > statistically NON-significant random effect variance
>     component, the
>      >? ? ? > lower bound of the CI must be EXACTLY "0", right?
>      >? ? ? >
>      >? ? ? > Thank you very much,
>      >? ? ? > Jack
>      >? ? ? >
>      >? ? ? >? ? ? ?[[alternative HTML version deleted]]
>      >? ? ? >
>      >? ? ? > _______________________________________________
>      >? ? ? > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>> mailing list
>      >? ? ? > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>      >? ? ? >
>      >
>      >? ? ?_______________________________________________
>      > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>> mailing list
>      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>      >
>


From kj@j@o|omon @end|ng |rom gm@||@com  Sat Apr  3 02:22:08 2021
From: kj@j@o|omon @end|ng |rom gm@||@com (Jack Solomon)
Date: Fri, 2 Apr 2021 19:22:08 -0500
Subject: [R-sig-ME] 
 Confidence interval around random effect variances in
 place of p-value
In-Reply-To: <2c84aacf-4d0c-437d-d096-09c1e4c38f1b@gmail.com>
References: <CA+sL+8XgaEBMnGVPCJywV_RUjQdX0=+-xy2f7D-rj_5iwz_8eg@mail.gmail.com>
 <c86b9720-ada6-68b0-217d-8821e2dc5a11@gmail.com>
 <CA+sL+8XpWn+oxs74z-T-CdRn01Fi3fKCG_nP_u+NdsYTa-fTZA@mail.gmail.com>
 <11791f10-2732-54ef-7bf9-3ef394d5e379@gmail.com>
 <CA+sL+8VCf+CQVZDV7=LhL8Fus3GT6uo6mUjSSZWSQA+=Wm9oqw@mail.gmail.com>
 <2c84aacf-4d0c-437d-d096-09c1e4c38f1b@gmail.com>
Message-ID: <CA+sL+8URe+6p4Qd8uZpa_=m3bOffoQvDRbRcfFK6qDMe5XF13Q@mail.gmail.com>

Well, how about concluding so:

If a (say 2-level) model gives a singular fit (even though perhaps there is
a "tol" that is small but not exactly "0" for that warning to show up),
that would mean we have a "practically" non-significant random-effect
variance component.



On Fri, Apr 2, 2021 at 7:15 PM Ben Bolker <bbolker at gmail.com> wrote:

>     I'm not sure that the bootstrapped CIs *wouldn't* work; they might
> return the correct proportion of singular fits ...
>
> On 4/2/21 8:12 PM, Jack Solomon wrote:
> > Thank you all very much. So, I can conclude that a likelihood ratio test
> > and/or a parametric bootstrapping can be used for random effect variance
> > component hypothesis testing.
> >
> > But I also concluded that the idea of simply using a bootstrapped CI for
> > a random-effect variance component [e.g., in lme4;
> > confint(model,method="boot",oldNames=FALSE)  ] by definition can't be
> > used for significance testing, because it requires the possibility of
> > seeing sd = 0 which can't be "strictly" captured by such a CI from a
> > multilevel model (at least not easily so).
> >
> > I hope my conclusions are correct,
> > Thank you all, Jack
> >
> > On Fri, Apr 2, 2021 at 6:51 PM Ben Bolker <bbolker at gmail.com
> > <mailto:bbolker at gmail.com>> wrote:
> >
> >        Sure. If all you want is p-values, I'd recommend parametric
> >     bootstrapping (implemented in the pbkrtest package) ... that will
> avoid
> >     these difficulties.  (I would also make sure that you know *why* you
> >     want p-values on the random effects ... they have all of the issues
> of
> >     regular p-values plus some extras:
> >
> http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#testing-significance-of-random-effects
> >     <
> http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#testing-significance-of-random-effects
> >
> >
> >     )
> >
> >     On 4/2/21 7:37 PM, Jack Solomon wrote:
> >      > Thanks. Just to make sure, to declare a statistically
> >     NON-significant
> >      > random effect variance component, the lower bound of the CI must
> be
> >      > EXACTLY "0", right?
> >      >
> >      > Tha is, for example, a CI like: [.0002, .14] is a
> >      > statistically significant random-effect variance component but
> >     one that
> >      > perhaps borders a p-value of relatively close to but smaller than
> >     .05,
> >      > right?
> >      >
> >      > On Fri, Apr 2, 2021 at 6:19 PM Ben Bolker <bbolker at gmail.com
> >     <mailto:bbolker at gmail.com>
> >      > <mailto:bbolker at gmail.com <mailto:bbolker at gmail.com>>> wrote:
> >      >
> >      >         This seems like a potential can of worms (as indeed are
> all
> >      >     hypothesis tests of null values on a boundary ...) However,
> >     in this
> >      >     case
> >      >     bootstrapping (provided you have resampled appropriately -
> >     you may need
> >      >     to do hierarchical bootstrapping ...) seems reasonable,
> >     because a null
> >      >     model would give you singular fits (i.e. estimated sd=0) half
> >     of the
> >      >     time ...
> >      >
> >      >         Happy to hear more informed opinions.
> >      >
> >      >     On 4/2/21 6:55 PM, Jack Solomon wrote:
> >      >      > Dear All,
> >      >      >
> >      >      > A colleague of mine suggested that I use the bootstrapped
> CIs
> >      >     around my
> >      >      > model's random effect variances in place of p-values for
> them.
> >      >      >
> >      >      > But random effect variances (or sds) start from "0". So,
> >     to declare a
> >      >      > statistically NON-significant random effect variance
> >     component, the
> >      >      > lower bound of the CI must be EXACTLY "0", right?
> >      >      >
> >      >      > Thank you very much,
> >      >      > Jack
> >      >      >
> >      >      >       [[alternative HTML version deleted]]
> >      >      >
> >      >      > _______________________________________________
> >      >      > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>> mailing list
> >      >      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >      >
> >      >
> >      >     _______________________________________________
> >      > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>> mailing list
> >      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >
> >
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Mon Apr  5 00:58:10 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sun, 4 Apr 2021 18:58:10 -0400
Subject: [R-sig-ME] 
 Confidence interval around random effect variances in
 place of p-value
In-Reply-To: <CA+sL+8URe+6p4Qd8uZpa_=m3bOffoQvDRbRcfFK6qDMe5XF13Q@mail.gmail.com>
References: <CA+sL+8XgaEBMnGVPCJywV_RUjQdX0=+-xy2f7D-rj_5iwz_8eg@mail.gmail.com>
 <c86b9720-ada6-68b0-217d-8821e2dc5a11@gmail.com>
 <CA+sL+8XpWn+oxs74z-T-CdRn01Fi3fKCG_nP_u+NdsYTa-fTZA@mail.gmail.com>
 <11791f10-2732-54ef-7bf9-3ef394d5e379@gmail.com>
 <CA+sL+8VCf+CQVZDV7=LhL8Fus3GT6uo6mUjSSZWSQA+=Wm9oqw@mail.gmail.com>
 <2c84aacf-4d0c-437d-d096-09c1e4c38f1b@gmail.com>
 <CA+sL+8URe+6p4Qd8uZpa_=m3bOffoQvDRbRcfFK6qDMe5XF13Q@mail.gmail.com>
Message-ID: <a4bc9a8c-8f87-cb1b-423c-08533025f16b@gmail.com>

   This would make an interesting simulation and/or theoretical exercise 
(I'm going to resist the urge to do it), i.e. identifying the 
correspondence between p-values constructed from parametric bootstrap 
full-vs-reduced model comparisons and p-values estimated as fraction of 
PB fits of full model that give variance=0 for the tested variance 
component(s).

On 4/2/21 8:22 PM, Jack Solomon wrote:
> Well, how about concluding so:
> 
> If a (say 2-level) model gives a singular fit (even though perhaps there 
> is a "tol" that is small but not exactly "0" for that warning to show 
> up), that would mean we have a "practically" non-significant 
> random-effect variance component.
> 
> 
> 
> On Fri, Apr 2, 2021 at 7:15 PM Ben Bolker <bbolker at gmail.com 
> <mailto:bbolker at gmail.com>> wrote:
> 
>      ? ? I'm not sure that the bootstrapped CIs *wouldn't* work; they might
>     return the correct proportion of singular fits ...
> 
>     On 4/2/21 8:12 PM, Jack Solomon wrote:
>      > Thank you all?very much. So, I can conclude that a likelihood
>     ratio test
>      > and/or a parametric bootstrapping can be used for random effect
>     variance
>      > component hypothesis?testing.
>      >
>      > But I also concluded that the idea of simply using a bootstrapped
>     CI for
>      > a random-effect variance component [e.g., in lme4;
>      > confint(model,method="boot",oldNames=FALSE)? ] by definition
>     can't be
>      > used for significance testing, because it requires the
>     possibility of
>      > seeing sd = 0 which can't be "strictly" captured by such a CI from a
>      > multilevel model (at least not easily so).
>      >
>      > I hope my conclusions are correct,
>      > Thank you all, Jack
>      >
>      > On Fri, Apr 2, 2021 at 6:51 PM Ben Bolker <bbolker at gmail.com
>     <mailto:bbolker at gmail.com>
>      > <mailto:bbolker at gmail.com <mailto:bbolker at gmail.com>>> wrote:
>      >
>      >? ? ? ? Sure. If all you want is p-values, I'd recommend parametric
>      >? ? ?bootstrapping (implemented in the pbkrtest package) ... that
>     will avoid
>      >? ? ?these difficulties.? (I would also make sure that you know
>     *why* you
>      >? ? ?want p-values on the random effects ... they have all of the
>     issues of
>      >? ? ?regular p-values plus some extras:
>      >
>     http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#testing-significance-of-random-effects
>     <http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#testing-significance-of-random-effects>
>      >   
>      ?<http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#testing-significance-of-random-effects <http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#testing-significance-of-random-effects>>
>      >
>      >? ? ?)
>      >
>      >? ? ?On 4/2/21 7:37 PM, Jack Solomon wrote:
>      >? ? ? > Thanks. Just to make sure, to declare?a statistically
>      >? ? ?NON-significant
>      >? ? ? > random effect variance component, the lower?bound of the
>     CI must be
>      >? ? ? > EXACTLY "0", right?
>      >? ? ? >
>      >? ? ? > Tha is, for example, a CI like: [.0002, .14] is a
>      >? ? ? > statistically?significant random-effect variance component but
>      >? ? ?one that
>      >? ? ? > perhaps borders a p-value of relatively close to but
>     smaller than
>      >? ? ?.05,
>      >? ? ? > right?
>      >? ? ? >
>      >? ? ? > On Fri, Apr 2, 2021 at 6:19 PM Ben Bolker
>     <bbolker at gmail.com <mailto:bbolker at gmail.com>
>      >? ? ?<mailto:bbolker at gmail.com <mailto:bbolker at gmail.com>>
>      >? ? ? > <mailto:bbolker at gmail.com <mailto:bbolker at gmail.com>
>     <mailto:bbolker at gmail.com <mailto:bbolker at gmail.com>>>> wrote:
>      >? ? ? >
>      >? ? ? >? ? ? ? ?This seems like a potential can of worms (as
>     indeed are all
>      >? ? ? >? ? ?hypothesis tests of null values on a boundary ...)
>     However,
>      >? ? ?in this
>      >? ? ? >? ? ?case
>      >? ? ? >? ? ?bootstrapping (provided you have resampled appropriately -
>      >? ? ?you may need
>      >? ? ? >? ? ?to do hierarchical bootstrapping ...) seems reasonable,
>      >? ? ?because a null
>      >? ? ? >? ? ?model would give you singular fits (i.e. estimated
>     sd=0) half
>      >? ? ?of the
>      >? ? ? >? ? ?time ...
>      >? ? ? >
>      >? ? ? >? ? ? ? ?Happy to hear more informed opinions.
>      >? ? ? >
>      >? ? ? >? ? ?On 4/2/21 6:55 PM, Jack Solomon wrote:
>      >? ? ? >? ? ? > Dear All,
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? > A colleague of mine suggested that I use the
>     bootstrapped CIs
>      >? ? ? >? ? ?around my
>      >? ? ? >? ? ? > model's random effect variances in place of
>     p-values for them.
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? > But random effect variances (or sds) start from
>     "0". So,
>      >? ? ?to declare a
>      >? ? ? >? ? ? > statistically NON-significant random effect variance
>      >? ? ?component, the
>      >? ? ? >? ? ? > lower bound of the CI must be EXACTLY "0", right?
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? > Thank you very much,
>      >? ? ? >? ? ? > Jack
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? ?[[alternative HTML version deleted]]
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? > _______________________________________________
>      >? ? ? >? ? ? > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>> mailing list
>      >? ? ? >? ? ? >
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>      >? ? ? >   
>      ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
>      >? ? ? >? ? ? >
>      >? ? ? >
>      >? ? ? >? ? ?_______________________________________________
>      >? ? ? > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>      >? ? ? >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>> mailing list
>      >? ? ? > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>      >? ? ? >   
>      ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
>      >? ? ? >
>      >
>


From @pro @end|ng |rom un|me|b@edu@@u  Mon Apr  5 02:18:00 2021
From: @pro @end|ng |rom un|me|b@edu@@u (Andrew Robinson)
Date: Mon, 5 Apr 2021 00:18:00 +0000
Subject: [R-sig-ME] 
 Confidence interval around random effect variances in
 place of p-value
In-Reply-To: <a4bc9a8c-8f87-cb1b-423c-08533025f16b@gmail.com>
References: <CA+sL+8XgaEBMnGVPCJywV_RUjQdX0=+-xy2f7D-rj_5iwz_8eg@mail.gmail.com>
 <c86b9720-ada6-68b0-217d-8821e2dc5a11@gmail.com>
 <CA+sL+8XpWn+oxs74z-T-CdRn01Fi3fKCG_nP_u+NdsYTa-fTZA@mail.gmail.com>
 <11791f10-2732-54ef-7bf9-3ef394d5e379@gmail.com>
 <CA+sL+8VCf+CQVZDV7=LhL8Fus3GT6uo6mUjSSZWSQA+=Wm9oqw@mail.gmail.com>
 <2c84aacf-4d0c-437d-d096-09c1e4c38f1b@gmail.com>
 <CA+sL+8URe+6p4Qd8uZpa_=m3bOffoQvDRbRcfFK6qDMe5XF13Q@mail.gmail.com>
 <a4bc9a8c-8f87-cb1b-423c-08533025f16b@gmail.com>
Message-ID: <d30fb535-94ff-4908-bb04-a24154ec8613@Spark>

Surely any correspondence would be attenuated - IIRC there?s some tuned shrinkage towards zero in the estimates of the variance components?

Best wishes,

Andrew

--
Andrew Robinson
Director, CEBRA, and Professor of Biosecurity Risk and Applied Statistics
Schools of BioSciences and Mathematics & Statistics
University of Melbourne, VIC 3010 Australia
Tel: (+61) 0403 138 955
Email: apro at unimelb.edu.au
Website: http://cebra.unimelb.edu.au/
On 5 Apr 2021, 8:58 AM +1000, Ben Bolker <bbolker at gmail.com>, wrote:
This would make an interesting simulation and/or theoretical exercise
(I'm going to resist the urge to do it), i.e. identifying the
correspondence between p-values constructed from parametric bootstrap
full-vs-reduced model comparisons and p-values estimated as fraction of
PB fits of full model that give variance=0 for the tested variance
component(s).

On 4/2/21 8:22 PM, Jack Solomon wrote:
Well, how about concluding so:

If a (say 2-level) model gives a singular fit (even though perhaps there
is a "tol" that is small but not exactly "0" for that warning to show
up), that would mean we have a "practically" non-significant
random-effect variance component.



On Fri, Apr 2, 2021 at 7:15 PM Ben Bolker <bbolker at gmail.com
<mailto:bbolker at gmail.com>> wrote:

    I'm not sure that the bootstrapped CIs *wouldn't* work; they might
return the correct proportion of singular fits ...

On 4/2/21 8:12 PM, Jack Solomon wrote:
Thank you all very much. So, I can conclude that a likelihood
ratio test
and/or a parametric bootstrapping can be used for random effect
variance
component hypothesis testing.

But I also concluded that the idea of simply using a bootstrapped
CI for
a random-effect variance component [e.g., in lme4;
confint(model,method="boot",oldNames=FALSE)  ] by definition
can't be
used for significance testing, because it requires the
possibility of
seeing sd = 0 which can't be "strictly" captured by such a CI from a
multilevel model (at least not easily so).

I hope my conclusions are correct,
Thank you all, Jack

On Fri, Apr 2, 2021 at 6:51 PM Ben Bolker <bbolker at gmail.com
<mailto:bbolker at gmail.com>
<mailto:bbolker at gmail.com <mailto:bbolker at gmail.com>>> wrote:

        Sure. If all you want is p-values, I'd recommend parametric
     bootstrapping (implemented in the pbkrtest package) ... that
will avoid
     these difficulties.  (I would also make sure that you know
*why* you
     want p-values on the random effects ... they have all of the
issues of
     regular p-values plus some extras:

http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#testing-significance-of-random-effects
<http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#testing-significance-of-random-effects>

 <http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#testing-significance-of-random-effects <http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#testing-significance-of-random-effects>>

     )

     On 4/2/21 7:37 PM, Jack Solomon wrote:
      > Thanks. Just to make sure, to declare a statistically
     NON-significant
      > random effect variance component, the lower bound of the
CI must be
      > EXACTLY "0", right?
      >
      > Tha is, for example, a CI like: [.0002, .14] is a
      > statistically significant random-effect variance component but
     one that
      > perhaps borders a p-value of relatively close to but
smaller than
     .05,
      > right?
      >
      > On Fri, Apr 2, 2021 at 6:19 PM Ben Bolker
<bbolker at gmail.com <mailto:bbolker at gmail.com>
     <mailto:bbolker at gmail.com <mailto:bbolker at gmail.com>>
      > <mailto:bbolker at gmail.com <mailto:bbolker at gmail.com>
<mailto:bbolker at gmail.com <mailto:bbolker at gmail.com>>>> wrote:
      >
      >         This seems like a potential can of worms (as
indeed are all
      >     hypothesis tests of null values on a boundary ...)
However,
     in this
      >     case
      >     bootstrapping (provided you have resampled appropriately -
     you may need
      >     to do hierarchical bootstrapping ...) seems reasonable,
     because a null
      >     model would give you singular fits (i.e. estimated
sd=0) half
     of the
      >     time ...
      >
      >         Happy to hear more informed opinions.
      >
      >     On 4/2/21 6:55 PM, Jack Solomon wrote:
      >      > Dear All,
      >      >
      >      > A colleague of mine suggested that I use the
bootstrapped CIs
      >     around my
      >      > model's random effect variances in place of
p-values for them.
      >      >
      >      > But random effect variances (or sds) start from
"0". So,
     to declare a
      >      > statistically NON-significant random effect variance
     component, the
      >      > lower bound of the CI must be EXACTLY "0", right?
      >      >
      >      > Thank you very much,
      >      > Jack
      >      >
      >      >       [[alternative HTML version deleted]]
      >      >
      >      > _______________________________________________
      >      > R-sig-mixed-models at r-project.org
<mailto:R-sig-mixed-models at r-project.org>
     <mailto:R-sig-mixed-models at r-project.org
<mailto:R-sig-mixed-models at r-project.org>>
      >     <mailto:R-sig-mixed-models at r-project.org
<mailto:R-sig-mixed-models at r-project.org>
     <mailto:R-sig-mixed-models at r-project.org
<mailto:R-sig-mixed-models at r-project.org>>> mailing list
      >      >
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
      >
<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
      >      >
      >
      >     _______________________________________________
      > R-sig-mixed-models at r-project.org
<mailto:R-sig-mixed-models at r-project.org>
     <mailto:R-sig-mixed-models at r-project.org
<mailto:R-sig-mixed-models at r-project.org>>
      >     <mailto:R-sig-mixed-models at r-project.org
<mailto:R-sig-mixed-models at r-project.org>
     <mailto:R-sig-mixed-models at r-project.org
<mailto:R-sig-mixed-models at r-project.org>>> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
      >
<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
      >



_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From hedyeh@h @end|ng |rom u@c@edu  Mon Apr  5 17:25:59 2021
From: hedyeh@h @end|ng |rom u@c@edu (Hedyeh Ahmadi)
Date: Mon, 5 Apr 2021 15:25:59 +0000
Subject: [R-sig-ME] glmer() Gamma distribution - constant coefficient of
 variation
Message-ID: <BYAPR07MB5094B5213A9442371E7673A6D1779@BYAPR07MB5094.namprd07.prod.outlook.com>

Hi All,
This email is from an old chain which was giving me issues due to large email size, so I am starting over here to answer some of the questions + add some explanations.

I am running a GLMM with Gamma distribution and identity link which has a constant coefficient of variation (i.e. CV) assumption.

Answer to the previous question on why continuous outcome and not a negative binomial for example: We have eight different outcomes that we are interested at, they are skewed composite scores of different medical diagnostics, and they can go anywhere between 0 to 26+ so we decided to use these variables as continuous outcome.

My question: Previously it was suggested to look at the plot on the right to check the constant CV assumption. So, would you trust the following plots as passing the constant CV assumption? I am leaning toward giving it a pass since although the line on the plot looks like it has a positive slope, the magnitude of y-axis is small.

Here is the link to the plot: https://drive.google.com/file/d/1Sta8yyq8dhnewMSLtvnH7XXzR8i1-cSk/view?usp=sharing


Best,

Hedyeh Ahmadi, Ph.D.
Statistician
Keck School of Medicine
Department of Preventive Medicine
University of Southern California

Postdoctoral Scholar
Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
University of California, Irvine

LinkedIn
www.linkedin.com/in/hedyeh-ahmadi<http://www.linkedin.com/in/hedyeh-ahmadi>
<http://www.linkedin.com/in/hedyeh-ahmadi><http://www.linkedin.com/in/hedyeh-ahmadi>





	[[alternative HTML version deleted]]


From b@t|c @end|ng |rom |eed@@@c@uk  Thu Apr  8 13:02:27 2021
From: b@t|c @end|ng |rom |eed@@@c@uk (Tara Cox [RPG])
Date: Thu, 8 Apr 2021 11:02:27 +0000
Subject: [R-sig-ME] Bivariate MCMCglmm - single value threshold response
 variable
Message-ID: <AM6PR0302MB33350C4355582476FBC6E301F7789@AM6PR0302MB3335.eurprd03.prod.outlook.com>

Dear list,

I am stuck attempting to run a bivariate MCMCglmm that uses response variables phenotypic trait 'x' and survival (yes/no) (hereafter referred to as 'x' and 'y', modelled Poisson and threshold, respectively). I have multiple repeats per individual for x, but a single value for y. From my research, there are two options for running this analysis:

1) As trait y possesses a single value per individual, there is no within-individual variance and so I fix the variance to 0.0001 in my prior, as per below:

prior.chi = list(R = list(V = diag(c(1, 0.0001), 2, 2), nu = 2, fix=2),
                         G = list(G1 = list(V = diag(2), nu = 1000, alpha.mu = c(0,0), alpha.V = diag(c(1, 1)),   #chi squared as this random effect (AnimalID) is specified to both response variables
                                      G2 = list(V = diag(1), nu = 1,  alpha.mu = 0, alpha.V = diag(1000,1))))             #parameter expanded as this random effect (ObserverID) is specified only to response variable x, which is Poisson

model1 <- MCMCglmm(cbind(x, y) ~ trait-1 +
                          trait:Sex +
                          at.level(trait,1):Age +
                          at.level(trait,1):Age2 +
                          at.level(trait,2):PopulationDensity +
                          at.level(trait,2):LocalPopulationDensity +
                          at.level(trait,2):FoodAbundance
                        random =~ us(trait):AnimalID + idh(at.level(trait,1)):ObserverID,
                        rcov =~ idh(trait):units,
                        family = c("poisson","threshold"),
                        prior = prior.chi,
                        nitt=2250000,
                        burnin=150000,
                        thin=525,
                        verbose = FALSE,
                        pr=FALSE,
                        data = data)

2) Use the stacked data/'covu' approach, where I get rid of the ID term for the threshold variable, and allow a covariance between the threshold residual and the Poisson ID term (as per supplementary material in Thomson et al. 2017: https://doi.org/10.1111%2Fevo.13169):

prior.covu <- list(G = list(G1 = list(V = diag(1), nu = 1)),                                   # rand effect for ObserverID (fitted for x)
                              R = list(R1 = list(V = diag(2), nu = 0.002, covu = TRUE),     # 2-way var-cov matrix of AnimalID for x, residual for y
                                           R2 = list(V = diag(1), nu = 0.002)))                            # residual for x

model2 <- MCMCglmm(x.y.data.stack ~ variable - 1 +
                        trait:Sex +
                          at.level(variable, "x"):Age
                          at.level(variable, "x"):Age2 +
                          at.level(variable, "y"):PopulationDensity +
                          at.level(variable, "y"):LocalPopulationDensity +
                          at.level(variable, "y"):FoodAbundance,
                        random = ~ us(at.level(variable,"x")):ObserverID + us(at.level(variable, "x")):AnimalID,
                        rcov = ~us(at.level(variable, "y")):AnimalID + idh(at.level(variable, "x")):units,
                        family = NULL,            #specified already in the data
                        prior = prior.covu,
                        nitt=2250000,
                        burnin=150000,
                        thin=525,
                        verbose = FALSE,
                        pr=FALSE,
                        data = data)

My problem is that I cannot get my models for either method to run successfully.

The convergence model 1 is poor, with trace+density plots showing poor mixing. I know that the method is viable, as I have successfully run multiple models without convergence issues using a full parameter expanded prior alongside Poisson and gaussian response variables. Therefore, I must be specifying my chi squared prior incorrectly. I've tried to read further into how to amend the prior, but I've reached my limit of understanding and keep getting stuck.

When running model 2, I receive an error message stating some fixed effects are not estimable and have been removed, and that I should use an informative prior. I've tried specifying a parameter expanded prior by modifying the G structure to include 'alpha.mu = 0' and 'alpha.V = diag(1000,1)', but this doesn't help. When running the model with a single fixed effect (e.g. Age), I do not receive any error messages, but the model shows poor mixing.

If anyone could provide any insight into which method might be better suited to my analysis, or how to improve the priors for either model, it would be much appreciated!

Thanks a lot.

Best wishes,
Tara




	[[alternative HTML version deleted]]


From j@h@d||e|d @end|ng |rom ed@@c@uk  Thu Apr  8 15:28:29 2021
From: j@h@d||e|d @end|ng |rom ed@@c@uk (Jarrod Hadfield)
Date: Thu, 8 Apr 2021 14:28:29 +0100
Subject: [R-sig-ME] Bivariate MCMCglmm - single value threshold response
 variable
In-Reply-To: <AM6PR0302MB33350C4355582476FBC6E301F7789@AM6PR0302MB3335.eurprd03.prod.outlook.com>
References: <AM6PR0302MB33350C4355582476FBC6E301F7789@AM6PR0302MB3335.eurprd03.prod.outlook.com>
Message-ID: <4fbcc8dd-00a3-b86c-96b5-292e9267c2da@ed.ac.uk>

Hi Tara,

Your second model is correct. You can ignore the warning (not an error)
that some fixed effects have been removed; often when you set up
equations involving at.level, base R's model.matrix will not
automatically delete extra parameters and so MCMCglmm checks up on this.

The model is not mixing because you are trying to estimate the residual
variance for the binary trait and this is not identifiable in the
likelihood. You should fix it at one which results in a probit model. To
do this have fix=2 when specifying the prior for R1.

Also, make sure you are using the latest version of MCMCglmm as there
was a bug with covu models thatmay be triggered under certain
circumstances and this has now been fixed.

Cheers,

Jarrod


On 08/04/2021 12:02, Tara Cox [RPG] wrote:
> This email was sent to you by someone outside the University.
> You should only click on links or attachments if you are certain that the email is genuine and the content is safe.
>
> Dear list,
>
> I am stuck attempting to run a bivariate MCMCglmm that uses response variables phenotypic trait 'x' and survival (yes/no) (hereafter referred to as 'x' and 'y', modelled Poisson and threshold, respectively). I have multiple repeats per individual for x, but a single value for y. From my research, there are two options for running this analysis:
>
> 1) As trait y possesses a single value per individual, there is no within-individual variance and so I fix the variance to 0.0001 in my prior, as per below:
>
> prior.chi = list(R = list(V = diag(c(1, 0.0001), 2, 2), nu = 2, fix=2),
>                           G = list(G1 = list(V = diag(2), nu = 1000, alpha.mu = c(0,0), alpha.V = diag(c(1, 1)),   #chi squared as this random effect (AnimalID) is specified to both response variables
>                                        G2 = list(V = diag(1), nu = 1,  alpha.mu = 0, alpha.V = diag(1000,1))))             #parameter expanded as this random effect (ObserverID) is specified only to response variable x, which is Poisson
>
> model1 <- MCMCglmm(cbind(x, y) ~ trait-1 +
>                            trait:Sex +
>                            at.level(trait,1):Age +
>                            at.level(trait,1):Age2 +
>                            at.level(trait,2):PopulationDensity +
>                            at.level(trait,2):LocalPopulationDensity +
>                            at.level(trait,2):FoodAbundance
>                          random =~ us(trait):AnimalID + idh(at.level(trait,1)):ObserverID,
>                          rcov =~ idh(trait):units,
>                          family = c("poisson","threshold"),
>                          prior = prior.chi,
>                          nitt=2250000,
>                          burnin=150000,
>                          thin=525,
>                          verbose = FALSE,
>                          pr=FALSE,
>                          data = data)
>
> 2) Use the stacked data/'covu' approach, where I get rid of the ID term for the threshold variable, and allow a covariance between the threshold residual and the Poisson ID term (as per supplementary material in Thomson et al. 2017: https://doi.org/10.1111%2Fevo.13169):
>
> prior.covu <- list(G = list(G1 = list(V = diag(1), nu = 1)),                                   # rand effect for ObserverID (fitted for x)
>                                R = list(R1 = list(V = diag(2), nu = 0.002, covu = TRUE),     # 2-way var-cov matrix of AnimalID for x, residual for y
>                                             R2 = list(V = diag(1), nu = 0.002)))                            # residual for x
>
> model2 <- MCMCglmm(x.y.data.stack ~ variable - 1 +
>                          trait:Sex +
>                            at.level(variable, "x"):Age
>                            at.level(variable, "x"):Age2 +
>                            at.level(variable, "y"):PopulationDensity +
>                            at.level(variable, "y"):LocalPopulationDensity +
>                            at.level(variable, "y"):FoodAbundance,
>                          random = ~ us(at.level(variable,"x")):ObserverID + us(at.level(variable, "x")):AnimalID,
>                          rcov = ~us(at.level(variable, "y")):AnimalID + idh(at.level(variable, "x")):units,
>                          family = NULL,            #specified already in the data
>                          prior = prior.covu,
>                          nitt=2250000,
>                          burnin=150000,
>                          thin=525,
>                          verbose = FALSE,
>                          pr=FALSE,
>                          data = data)
>
> My problem is that I cannot get my models for either method to run successfully.
>
> The convergence model 1 is poor, with trace+density plots showing poor mixing. I know that the method is viable, as I have successfully run multiple models without convergence issues using a full parameter expanded prior alongside Poisson and gaussian response variables. Therefore, I must be specifying my chi squared prior incorrectly. I've tried to read further into how to amend the prior, but I've reached my limit of understanding and keep getting stuck.
>
> When running model 2, I receive an error message stating some fixed effects are not estimable and have been removed, and that I should use an informative prior. I've tried specifying a parameter expanded prior by modifying the G structure to include 'alpha.mu = 0' and 'alpha.V = diag(1000,1)', but this doesn't help. When running the model with a single fixed effect (e.g. Age), I do not receive any error messages, but the model shows poor mixing.
>
> If anyone could provide any insight into which method might be better suited to my analysis, or how to improve the priors for either model, it would be much appreciated!
>
> Thanks a lot.
>
> Best wishes,
> Tara
>
>
>
>
>          [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
The University of Edinburgh is a charitable body, registered in Scotland, with registration number SC005336. Is e buidheann carthannais a th? ann an Oilthigh Dh?n ?ideann, cl?raichte an Alba, ?ireamh cl?raidh SC005336.


From @h@h|nur@|@|@m @end|ng |rom mun@c@  Thu Apr  8 17:04:32 2021
From: @h@h|nur@|@|@m @end|ng |rom mun@c@ (Shahinur, Islam)
Date: Thu, 8 Apr 2021 12:34:32 -0230
Subject: [R-sig-ME] Observation-level random effects
Message-ID: <CAP5=mpj2gn6U5gAs1TqtQHscosAeErr1mWCwQK-x1DnaQXG6Jw@mail.gmail.com>

Hello All,
I am having trouble with observation-level random effects while running the
full model investigating two fixed covariates (one categorical and one
continuous) and two random covariates (tank and family). While I am using
the only tank random effect, it works fine, but while I am adding another
random covariate (family), I am getting the error message: Error: number of
levels of each grouping factor must be < number of observations (problems:
family).

FYI, here is my code:
model1 <- lmer(development~ 1 +cross + egg +cross*egg + (1|Tank)+
(1|family) ,data=sp)

I do have different family IDs (n=108) for each row, I assume it creates
the problem.

Your suggestions will be much appreciated!

Regards,

Shahin

<><><><><><><><><><><><><><><><><><><><><><><><><><>

Shahinur S. Islam
PhD Candidate, Department of Ocean Sciences
Ocean Sciences Centre, Memorial University of Newfoundland
St. John's, NL  A1C 5S7, Canada
Cell: (+1)709-740-3324; Twitter: @EcoEvoGen

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Thu Apr  8 18:04:49 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Thu, 8 Apr 2021 18:04:49 +0200
Subject: [R-sig-ME] Observation-level random effects
In-Reply-To: <CAP5=mpj2gn6U5gAs1TqtQHscosAeErr1mWCwQK-x1DnaQXG6Jw@mail.gmail.com>
References: <CAP5=mpj2gn6U5gAs1TqtQHscosAeErr1mWCwQK-x1DnaQXG6Jw@mail.gmail.com>
Message-ID: <CAJuCY5y8kqUMSdBREOhnqBK8mjA+Ya_YvOBbH6AxWjoCao49nw@mail.gmail.com>

Dear Shanin,

You can't use an observation level random effect with a Gaussian
distribution.
Please provide the number of observations, number of unique families and
number of unique tanks.

Best regards,

Thierry

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op do 8 apr. 2021 om 17:08 schreef Shahinur, Islam <shahinur.islam at mun.ca>:

> Hello All,
> I am having trouble with observation-level random effects while running the
> full model investigating two fixed covariates (one categorical and one
> continuous) and two random covariates (tank and family). While I am using
> the only tank random effect, it works fine, but while I am adding another
> random covariate (family), I am getting the error message: Error: number of
> levels of each grouping factor must be < number of observations (problems:
> family).
>
> FYI, here is my code:
> model1 <- lmer(development~ 1 +cross + egg +cross*egg + (1|Tank)+
> (1|family) ,data=sp)
>
> I do have different family IDs (n=108) for each row, I assume it creates
> the problem.
>
> Your suggestions will be much appreciated!
>
> Regards,
>
> Shahin
>
> <><><><><><><><><><><><><><><><><><><><><><><><><><>
>
> Shahinur S. Islam
> PhD Candidate, Department of Ocean Sciences
> Ocean Sciences Centre, Memorial University of Newfoundland
> St. John's, NL  A1C 5S7, Canada
> Cell: (+1)709-740-3324; Twitter: @EcoEvoGen
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From @h@h|nur@|@|@m @end|ng |rom mun@c@  Thu Apr  8 18:50:14 2021
From: @h@h|nur@|@|@m @end|ng |rom mun@c@ (Shahinur, Islam)
Date: Thu, 8 Apr 2021 14:20:14 -0230
Subject: [R-sig-ME] Observation-level random effects
In-Reply-To: <CAJuCY5y8kqUMSdBREOhnqBK8mjA+Ya_YvOBbH6AxWjoCao49nw@mail.gmail.com>
References: <CAP5=mpj2gn6U5gAs1TqtQHscosAeErr1mWCwQK-x1DnaQXG6Jw@mail.gmail.com>
 <CAJuCY5y8kqUMSdBREOhnqBK8mjA+Ya_YvOBbH6AxWjoCao49nw@mail.gmail.com>
Message-ID: <CAP5=mpi7aYAwCrcfd8yZGbjQysKFjjHKrBVW1TVeTEy1-Oivdg@mail.gmail.com>

Hello All,

Thank you, Dr. Thierry, for the reply!

I am still having the problem!- just in case, I have attached my data
template.

When I am running the following code:
model1 <- lmer(development~ 1 +cross + egg +cross*egg + (1|Tank)+
(1|family) ,data=sp)

Still getting the errors: Error: number of levels of each grouping factor
must be < number of observations (problems: family).

Your suggestions will be much appreciated.

Regards,

Shahin

<><><><><><><><><><><><><><><><><><><><><><><><><><>

Shahinur S. Islam
PhD Candidate, Department of Ocean Sciences
Ocean Sciences Centre, Memorial University of Newfoundland
St. John's, NL  A1C 5S7, Canada
Cell: (+1)709-740-3324; Twitter: @EcoEvoGen


On Thu, Apr 8, 2021 at 1:35 PM Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Shanin,
>
> You can't use an observation level random effect with a Gaussian
> distribution.
> Please provide the number of observations, number of unique families and
> number of unique tanks.
>
> Best regards,
>
> Thierry
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op do 8 apr. 2021 om 17:08 schreef Shahinur, Islam <shahinur.islam at mun.ca
> >:
>
>> Hello All,
>> I am having trouble with observation-level random effects while running
>> the
>> full model investigating two fixed covariates (one categorical and one
>> continuous) and two random covariates (tank and family). While I am using
>> the only tank random effect, it works fine, but while I am adding another
>> random covariate (family), I am getting the error message: Error: number
>> of
>> levels of each grouping factor must be < number of observations (problems:
>> family).
>>
>> FYI, here is my code:
>> model1 <- lmer(development~ 1 +cross + egg +cross*egg + (1|Tank)+
>> (1|family) ,data=sp)
>>
>> I do have different family IDs (n=108) for each row, I assume it creates
>> the problem.
>>
>> Your suggestions will be much appreciated!
>>
>> Regards,
>>
>> Shahin
>>
>> <><><><><><><><><><><><><><><><><><><><><><><><><><>
>>
>> Shahinur S. Islam
>> PhD Candidate, Department of Ocean Sciences
>> Ocean Sciences Centre, Memorial University of Newfoundland
>> St. John's, NL  A1C 5S7, Canada
>> Cell: (+1)709-740-3324; Twitter: @EcoEvoGen
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: development.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20210408/c98794d7/attachment.txt>

From th|erry@onke||nx @end|ng |rom |nbo@be  Fri Apr  9 09:26:26 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Fri, 9 Apr 2021 09:26:26 +0200
Subject: [R-sig-ME] Observation-level random effects
In-Reply-To: <CAP5=mpi7aYAwCrcfd8yZGbjQysKFjjHKrBVW1TVeTEy1-Oivdg@mail.gmail.com>
References: <CAP5=mpj2gn6U5gAs1TqtQHscosAeErr1mWCwQK-x1DnaQXG6Jw@mail.gmail.com>
 <CAJuCY5y8kqUMSdBREOhnqBK8mjA+Ya_YvOBbH6AxWjoCao49nw@mail.gmail.com>
 <CAP5=mpi7aYAwCrcfd8yZGbjQysKFjjHKrBVW1TVeTEy1-Oivdg@mail.gmail.com>
Message-ID: <CAJuCY5z5xkMs6z5GFs0Ti_NPgO6inj-p+bQG1Maii1eN-a6JLw@mail.gmail.com>

Dear Shahin,

I assume that a1 to a20 are replicates of the same family "a". If that is
the case, you need to use the name of the family ("a") instead of the
replicate id's (a1 to a20). Currently, it looks like every observation has
a unique value for family. That would lead to an observation level random
effect, which you can't use with a Gaussian distribution as it confounds
with the residuals.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op do 8 apr. 2021 om 18:50 schreef Shahinur, Islam <shahinur.islam at mun.ca>:

> Hello All,
>
> Thank you, Dr. Thierry, for the reply!
>
> I am still having the problem!- just in case, I have attached my data
> template.
>
> When I am running the following code:
> model1 <- lmer(development~ 1 +cross + egg +cross*egg + (1|Tank)+
> (1|family) ,data=sp)
>
> Still getting the errors: Error: number of levels of each grouping factor
> must be < number of observations (problems: family).
>
> Your suggestions will be much appreciated.
>
> Regards,
>
> Shahin
>
> <><><><><><><><><><><><><><><><><><><><><><><><><><>
>
> Shahinur S. Islam
> PhD Candidate, Department of Ocean Sciences
> Ocean Sciences Centre, Memorial University of Newfoundland
> St. John's, NL  A1C 5S7, Canada
> Cell: (+1)709-740-3324; Twitter: @EcoEvoGen
>
>
> On Thu, Apr 8, 2021 at 1:35 PM Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>
>> Dear Shanin,
>>
>> You can't use an observation level random effect with a Gaussian
>> distribution.
>> Please provide the number of observations, number of unique families and
>> number of unique tanks.
>>
>> Best regards,
>>
>> Thierry
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>> AND FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88 bus 73, 1000 Brussel
>> www.inbo.be
>>
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>
>> <https://www.inbo.be>
>>
>>
>> Op do 8 apr. 2021 om 17:08 schreef Shahinur, Islam <shahinur.islam at mun.ca
>> >:
>>
>>> Hello All,
>>> I am having trouble with observation-level random effects while running
>>> the
>>> full model investigating two fixed covariates (one categorical and one
>>> continuous) and two random covariates (tank and family). While I am using
>>> the only tank random effect, it works fine, but while I am adding another
>>> random covariate (family), I am getting the error message: Error: number
>>> of
>>> levels of each grouping factor must be < number of observations
>>> (problems:
>>> family).
>>>
>>> FYI, here is my code:
>>> model1 <- lmer(development~ 1 +cross + egg +cross*egg + (1|Tank)+
>>> (1|family) ,data=sp)
>>>
>>> I do have different family IDs (n=108) for each row, I assume it creates
>>> the problem.
>>>
>>> Your suggestions will be much appreciated!
>>>
>>> Regards,
>>>
>>> Shahin
>>>
>>> <><><><><><><><><><><><><><><><><><><><><><><><><><>
>>>
>>> Shahinur S. Islam
>>> PhD Candidate, Department of Ocean Sciences
>>> Ocean Sciences Centre, Memorial University of Newfoundland
>>> St. John's, NL  A1C 5S7, Canada
>>> Cell: (+1)709-740-3324; Twitter: @EcoEvoGen
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>

	[[alternative HTML version deleted]]


From @h@h|nur@|@|@m @end|ng |rom mun@c@  Fri Apr  9 11:46:16 2021
From: @h@h|nur@|@|@m @end|ng |rom mun@c@ (Shahinur, Islam)
Date: Fri, 9 Apr 2021 07:16:16 -0230
Subject: [R-sig-ME] Observation-level random effects
In-Reply-To: <CAJuCY5z5xkMs6z5GFs0Ti_NPgO6inj-p+bQG1Maii1eN-a6JLw@mail.gmail.com>
References: <CAP5=mpj2gn6U5gAs1TqtQHscosAeErr1mWCwQK-x1DnaQXG6Jw@mail.gmail.com>
 <CAJuCY5y8kqUMSdBREOhnqBK8mjA+Ya_YvOBbH6AxWjoCao49nw@mail.gmail.com>
 <CAP5=mpi7aYAwCrcfd8yZGbjQysKFjjHKrBVW1TVeTEy1-Oivdg@mail.gmail.com>
 <CAJuCY5z5xkMs6z5GFs0Ti_NPgO6inj-p+bQG1Maii1eN-a6JLw@mail.gmail.com>
Message-ID: <CAP5=mphtLjmOehMbRJzJHLu+U3Fe5T-bQeMALXpqcyfvMZ_Wyw@mail.gmail.com>

Hello Thierry,

No, they are not the replicates of the same family, but 20 different
families under Cross (Population) Farm.NA.

I am trying to see both Tank effect and family effect (possibly nested
within cross) separately, but it's giving me hard time with family.

Thank you for checking into this, and your suggestions will be much
appreciated!

Regards,

Shahin


On Fri., Apr. 9, 2021, 4:56 a.m. Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Shahin,
>
> I assume that a1 to a20 are replicates of the same family "a". If that is
> the case, you need to use the name of the family ("a") instead of the
> replicate id's (a1 to a20). Currently, it looks like every observation has
> a unique value for family. That would lead to an observation level random
> effect, which you can't use with a Gaussian distribution as it confounds
> with the residuals.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op do 8 apr. 2021 om 18:50 schreef Shahinur, Islam <shahinur.islam at mun.ca
> >:
>
>> Hello All,
>>
>> Thank you, Dr. Thierry, for the reply!
>>
>> I am still having the problem!- just in case, I have attached my data
>> template.
>>
>> When I am running the following code:
>> model1 <- lmer(development~ 1 +cross + egg +cross*egg + (1|Tank)+
>> (1|family) ,data=sp)
>>
>> Still getting the errors: Error: number of levels of each grouping factor
>> must be < number of observations (problems: family).
>>
>> Your suggestions will be much appreciated.
>>
>> Regards,
>>
>> Shahin
>>
>> <><><><><><><><><><><><><><><><><><><><><><><><><><>
>>
>> Shahinur S. Islam
>> PhD Candidate, Department of Ocean Sciences
>> Ocean Sciences Centre, Memorial University of Newfoundland
>> St. John's, NL  A1C 5S7, Canada
>> Cell: (+1)709-740-3324; Twitter: @EcoEvoGen
>>
>>
>> On Thu, Apr 8, 2021 at 1:35 PM Thierry Onkelinx <thierry.onkelinx at inbo.be>
>> wrote:
>>
>>> Dear Shanin,
>>>
>>> You can't use an observation level random effect with a Gaussian
>>> distribution.
>>> Please provide the number of observations, number of unique families and
>>> number of unique tanks.
>>>
>>> Best regards,
>>>
>>> Thierry
>>>
>>> ir. Thierry Onkelinx
>>> Statisticus / Statistician
>>>
>>> Vlaamse Overheid / Government of Flanders
>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>>> AND FOREST
>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>> thierry.onkelinx at inbo.be
>>> Havenlaan 88 bus 73, 1000 Brussel
>>> www.inbo.be
>>>
>>>
>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of data.
>>> ~ John Tukey
>>>
>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>
>>> <https://www.inbo.be>
>>>
>>>
>>> Op do 8 apr. 2021 om 17:08 schreef Shahinur, Islam <
>>> shahinur.islam at mun.ca>:
>>>
>>>> Hello All,
>>>> I am having trouble with observation-level random effects while running
>>>> the
>>>> full model investigating two fixed covariates (one categorical and one
>>>> continuous) and two random covariates (tank and family). While I am
>>>> using
>>>> the only tank random effect, it works fine, but while I am adding
>>>> another
>>>> random covariate (family), I am getting the error message: Error:
>>>> number of
>>>> levels of each grouping factor must be < number of observations
>>>> (problems:
>>>> family).
>>>>
>>>> FYI, here is my code:
>>>> model1 <- lmer(development~ 1 +cross + egg +cross*egg + (1|Tank)+
>>>> (1|family) ,data=sp)
>>>>
>>>> I do have different family IDs (n=108) for each row, I assume it creates
>>>> the problem.
>>>>
>>>> Your suggestions will be much appreciated!
>>>>
>>>> Regards,
>>>>
>>>> Shahin
>>>>
>>>> <><><><><><><><><><><><><><><><><><><><><><><><><><>
>>>>
>>>> Shahinur S. Islam
>>>> PhD Candidate, Department of Ocean Sciences
>>>> Ocean Sciences Centre, Memorial University of Newfoundland
>>>> St. John's, NL  A1C 5S7, Canada
>>>> Cell: (+1)709-740-3324; Twitter: @EcoEvoGen
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Fri Apr  9 12:51:17 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Fri, 9 Apr 2021 12:51:17 +0200
Subject: [R-sig-ME] Observation-level random effects
In-Reply-To: <CAP5=mphtLjmOehMbRJzJHLu+U3Fe5T-bQeMALXpqcyfvMZ_Wyw@mail.gmail.com>
References: <CAP5=mpj2gn6U5gAs1TqtQHscosAeErr1mWCwQK-x1DnaQXG6Jw@mail.gmail.com>
 <CAJuCY5y8kqUMSdBREOhnqBK8mjA+Ya_YvOBbH6AxWjoCao49nw@mail.gmail.com>
 <CAP5=mpi7aYAwCrcfd8yZGbjQysKFjjHKrBVW1TVeTEy1-Oivdg@mail.gmail.com>
 <CAJuCY5z5xkMs6z5GFs0Ti_NPgO6inj-p+bQG1Maii1eN-a6JLw@mail.gmail.com>
 <CAP5=mphtLjmOehMbRJzJHLu+U3Fe5T-bQeMALXpqcyfvMZ_Wyw@mail.gmail.com>
Message-ID: <CAJuCY5zaZ=zMYv32Z17Lg=FAzMf0MqnM4ksstnE46=dr88edNw@mail.gmail.com>

If you can't group observations in a meaningful way into groups of
families, then you can't use the (group of) families as a random effect.

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op vr 9 apr. 2021 om 11:46 schreef Shahinur, Islam <shahinur.islam at mun.ca>:

> Hello Thierry,
>
> No, they are not the replicates of the same family, but 20 different
> families under Cross (Population) Farm.NA.
>
> I am trying to see both Tank effect and family effect (possibly nested
> within cross) separately, but it's giving me hard time with family.
>
> Thank you for checking into this, and your suggestions will be much
> appreciated!
>
> Regards,
>
> Shahin
>
>
> On Fri., Apr. 9, 2021, 4:56 a.m. Thierry Onkelinx <
> thierry.onkelinx at inbo.be> wrote:
>
>> Dear Shahin,
>>
>> I assume that a1 to a20 are replicates of the same family "a". If that is
>> the case, you need to use the name of the family ("a") instead of the
>> replicate id's (a1 to a20). Currently, it looks like every observation has
>> a unique value for family. That would lead to an observation level random
>> effect, which you can't use with a Gaussian distribution as it confounds
>> with the residuals.
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>> AND FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88 bus 73, 1000 Brussel
>> www.inbo.be
>>
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>
>> <https://www.inbo.be>
>>
>>
>> Op do 8 apr. 2021 om 18:50 schreef Shahinur, Islam <shahinur.islam at mun.ca
>> >:
>>
>>> Hello All,
>>>
>>> Thank you, Dr. Thierry, for the reply!
>>>
>>> I am still having the problem!- just in case, I have attached my data
>>> template.
>>>
>>> When I am running the following code:
>>> model1 <- lmer(development~ 1 +cross + egg +cross*egg + (1|Tank)+
>>> (1|family) ,data=sp)
>>>
>>> Still getting the errors: Error: number of levels of each grouping
>>> factor must be < number of observations (problems: family).
>>>
>>> Your suggestions will be much appreciated.
>>>
>>> Regards,
>>>
>>> Shahin
>>>
>>> <><><><><><><><><><><><><><><><><><><><><><><><><><>
>>>
>>> Shahinur S. Islam
>>> PhD Candidate, Department of Ocean Sciences
>>> Ocean Sciences Centre, Memorial University of Newfoundland
>>> St. John's, NL  A1C 5S7, Canada
>>> Cell: (+1)709-740-3324; Twitter: @EcoEvoGen
>>>
>>>
>>> On Thu, Apr 8, 2021 at 1:35 PM Thierry Onkelinx <
>>> thierry.onkelinx at inbo.be> wrote:
>>>
>>>> Dear Shanin,
>>>>
>>>> You can't use an observation level random effect with a Gaussian
>>>> distribution.
>>>> Please provide the number of observations, number of unique families
>>>> and number of unique tanks.
>>>>
>>>> Best regards,
>>>>
>>>> Thierry
>>>>
>>>> ir. Thierry Onkelinx
>>>> Statisticus / Statistician
>>>>
>>>> Vlaamse Overheid / Government of Flanders
>>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>>>> AND FOREST
>>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>>> thierry.onkelinx at inbo.be
>>>> Havenlaan 88 bus 73, 1000 Brussel
>>>> www.inbo.be
>>>>
>>>>
>>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>> To call in the statistician after the experiment is done may be no more
>>>> than asking him to perform a post-mortem examination: he may be able to say
>>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>> The combination of some data and an aching desire for an answer does
>>>> not ensure that a reasonable answer can be extracted from a given body of
>>>> data. ~ John Tukey
>>>>
>>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>>
>>>> <https://www.inbo.be>
>>>>
>>>>
>>>> Op do 8 apr. 2021 om 17:08 schreef Shahinur, Islam <
>>>> shahinur.islam at mun.ca>:
>>>>
>>>>> Hello All,
>>>>> I am having trouble with observation-level random effects while
>>>>> running the
>>>>> full model investigating two fixed covariates (one categorical and one
>>>>> continuous) and two random covariates (tank and family). While I am
>>>>> using
>>>>> the only tank random effect, it works fine, but while I am adding
>>>>> another
>>>>> random covariate (family), I am getting the error message: Error:
>>>>> number of
>>>>> levels of each grouping factor must be < number of observations
>>>>> (problems:
>>>>> family).
>>>>>
>>>>> FYI, here is my code:
>>>>> model1 <- lmer(development~ 1 +cross + egg +cross*egg + (1|Tank)+
>>>>> (1|family) ,data=sp)
>>>>>
>>>>> I do have different family IDs (n=108) for each row, I assume it
>>>>> creates
>>>>> the problem.
>>>>>
>>>>> Your suggestions will be much appreciated!
>>>>>
>>>>> Regards,
>>>>>
>>>>> Shahin
>>>>>
>>>>> <><><><><><><><><><><><><><><><><><><><><><><><><><>
>>>>>
>>>>> Shahinur S. Islam
>>>>> PhD Candidate, Department of Ocean Sciences
>>>>> Ocean Sciences Centre, Memorial University of Newfoundland
>>>>> St. John's, NL  A1C 5S7, Canada
>>>>> Cell: (+1)709-740-3324; Twitter: @EcoEvoGen
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>

	[[alternative HTML version deleted]]


From D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u  Mon Apr 12 08:33:13 2021
From: D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u (David Duffy)
Date: Mon, 12 Apr 2021 06:33:13 +0000
Subject: [R-sig-ME] Observation-level random effects
In-Reply-To: <CAP5=mphtLjmOehMbRJzJHLu+U3Fe5T-bQeMALXpqcyfvMZ_Wyw@mail.gmail.com>
References: <CAP5=mpj2gn6U5gAs1TqtQHscosAeErr1mWCwQK-x1DnaQXG6Jw@mail.gmail.com>
 <CAJuCY5y8kqUMSdBREOhnqBK8mjA+Ya_YvOBbH6AxWjoCao49nw@mail.gmail.com>
 <CAP5=mpi7aYAwCrcfd8yZGbjQysKFjjHKrBVW1TVeTEy1-Oivdg@mail.gmail.com>
 <CAJuCY5z5xkMs6z5GFs0Ti_NPgO6inj-p+bQG1Maii1eN-a6JLw@mail.gmail.com>,
 <CAP5=mphtLjmOehMbRJzJHLu+U3Fe5T-bQeMALXpqcyfvMZ_Wyw@mail.gmail.com>
Message-ID: <4afd2a515d154f469d70d4d647d84c64@qimrberghofer.edu.au>

> No, they are not the replicates of the same family, but 20 different
> families under Cross (Population) Farm.NA.

Dear Shahin. 
Thierry has already answered your question, in that unless you provide a within-family standard deviation for each 
"development.overall" or "egg.size" observation, there is no information about familial random effects. You can examine paternal 
and maternal contributions, since some of these are repeated across families (in your example data), 
but you will not have a lot of power, I fear.


From @h@h|nur@|@|@m @end|ng |rom mun@c@  Mon Apr 12 13:40:22 2021
From: @h@h|nur@|@|@m @end|ng |rom mun@c@ (Shahinur, Islam)
Date: Mon, 12 Apr 2021 09:10:22 -0230
Subject: [R-sig-ME] Observation-level random effects
In-Reply-To: <4afd2a515d154f469d70d4d647d84c64@qimrberghofer.edu.au>
References: <CAP5=mpj2gn6U5gAs1TqtQHscosAeErr1mWCwQK-x1DnaQXG6Jw@mail.gmail.com>
 <CAJuCY5y8kqUMSdBREOhnqBK8mjA+Ya_YvOBbH6AxWjoCao49nw@mail.gmail.com>
 <CAP5=mpi7aYAwCrcfd8yZGbjQysKFjjHKrBVW1TVeTEy1-Oivdg@mail.gmail.com>
 <CAJuCY5z5xkMs6z5GFs0Ti_NPgO6inj-p+bQG1Maii1eN-a6JLw@mail.gmail.com>
 <CAP5=mphtLjmOehMbRJzJHLu+U3Fe5T-bQeMALXpqcyfvMZ_Wyw@mail.gmail.com>
 <4afd2a515d154f469d70d4d647d84c64@qimrberghofer.edu.au>
Message-ID: <CAP5=mpgWwfBP0QLLopvsZYSfqMm7=ja8C+Z=L6sjnB=6g6AB0w@mail.gmail.com>

Hello David,

Thank you for the reply (also thanks to Thierry).

You are right- I was trying to see paternal (Male.ID; 42 levels out of 103
observations) and maternal (Female.ID; 53 levels out of 103 observations)
contribution, but still getting boundary (singular) fit: see ?isSingular
errors  for development.overall or for some of the other traits (response
variables).

Thanks,

Shahin

<><><><><><><><><><><><><><><><><><><><><><><><><><>

Shahinur S. Islam
PhD Candidate, Department of Ocean Sciences
Ocean Sciences Centre, Memorial University of Newfoundland
St. John's, NL  A1C 5S7, Canada
Cell: (+1)709-740-3324; Twitter: @EcoEvoGen


On Mon, Apr 12, 2021 at 4:03 AM David Duffy <
David.Duffy at qimrberghofer.edu.au> wrote:

> > No, they are not the replicates of the same family, but 20 different
> > families under Cross (Population) Farm.NA.
>
> Dear Shahin.
> Thierry has already answered your question, in that unless you provide a
> within-family standard deviation for each
> "development.overall" or "egg.size" observation, there is no information
> about familial random effects. You can examine paternal
> and maternal contributions, since some of these are repeated across
> families (in your example data),
> but you will not have a lot of power, I fear.
>
>
>
>
>

	[[alternative HTML version deleted]]


From pr|db @end|ng |rom protonm@||@com  Tue Apr 13 04:45:24 2021
From: pr|db @end|ng |rom protonm@||@com (Peter R Law)
Date: Tue, 13 Apr 2021 02:45:24 +0000
Subject: [R-sig-ME] lmer code for multiple random slopes
In-Reply-To: <uE3jE1zXUjFp71_IDL14arC1sYdRmI86rrWgzVNBWIQd19Q42xVlC09lLsxR38Z7vGWSNAAdqtui3zs9Y24knhKn77WJlLJkwedvV2jGdlQ=@protonmail.com>
References: <34JKCz24u8awawkhTLmboO_cBRWW-m0XAb0frTUb9YqspQe1VeBBWUvfqKd3-QIMLeKpiDUyzhN0X6aqRlEqwX1LmBfg3gn9EB2XCa5v62s=@protonmail.com>
 <NCGF24lxdAy2bcOAoQsutEkYQ-ZIzb4e3xLenmSDhGyZN8a8sIcv-wHF0IEfLK8GQGccVE1hLTk-i1UPxFITTgLC9T929E6F4rQVMwVN8bg=@protonmail.com>
 <e2zoG5je3QHzcPl3dsttnLigMgzR8mqiUJAdgntQm9xPOX4j3SwlDytjMtbOFRj-vf5TjpHVRD7rzd54mvwMFm9OhW-ff4lfhR383lioPX4=@protonmail.com>
 <f286a096-f420-c246-61ad-542eaa5dad44@phillipalday.com>
 <CIYTFe7RNWpkAwUyuCM71pFEfhP-gPVj0OcD-UjLX0LbfzrRbySwMeVxASDMGs6D3aOxqydPUAg1NbZJar32LOtM42U-ZY-03eCCB7JbkUg=@protonmail.com>
 <e0894da27f994e64863768033e5c4989@UM-MAIL3214.unimaas.nl>
 <Ys_EWO7eMIPbh1nezv5C8Qd2cu51FF6MTNolLdBcuZcBgb8soEkJwTMl8QPDQKRCNqLEQQLJyqoVNkB2izRT13vOwKw_NIuBvK34uES4oJk=@protonmail.com>
 <8bc0234f3e904300b84f7df721ef6534@UM-MAIL3214.unimaas.nl>
 <uE3jE1zXUjFp71_IDL14arC1sYdRmI86rrWgzVNBWIQd19Q42xVlC09lLsxR38Z7vGWSNAAdqtui3zs9Y24knhKn77WJlLJkwedvV2jGdlQ=@protonmail.com>
Message-ID: <dcgVUuZEo0JKpGy6UNMO5Rs8gcsEaewdTDcc1JBzyMFHl_LmLRUEeKXvMTzGZh83op1veLGGEh1PfsItzIiHtBoK42mRUo54slXKhO_8Vio=@protonmail.com>

Hi Wolfgang:

I used some simulated data to explore the two different models you described in your response to my query:

lmer(y ~ x + (1|G1:G2) + (x|G1))

versus

lmer(y ~ x + (1|G1/G2) + (x|G1))

For my simulated data, the latter model divides the random intercept of G1 into two unequal parts but otherwise the models are almost identical, even with the same deviance.

Apart from replacing the single random intercept due to G1 in the top model by two random intercepts due to G1 in the bottom model, the models seem to be otherwise the same.

If so, is there any situation in which one would consider the top model?


Peter


Sent with ProtonMail Secure Email.

??????? Original Message ???????
On Thursday, March 4, 2021 9:13 PM, Peter R Law via R-sig-mixed-models <r-sig-mixed-models at r-project.org> wrote:

&gt; Many thanks Wolfgang.
&gt;
&gt; Peter
&gt;
&gt; Sent with ProtonMail Secure Email.
&gt;
&gt; ??????? Original Message ???????
&gt; On Thursday, March 4, 2021 5:45 AM, Viechtbauer, Wolfgang (SP) wolfgang.viechtbauer at maastrichtuniversity.nl wrote:
&gt;
&gt; &gt; Hi Peter,
&gt; &gt; In:
&gt; &gt; response ~ x + (1|G2/G1) + (x|G2)?
&gt; &gt; the first () term adds random intercepts for each level of G2 and random intercepts for each level of G1 within G2. The second () term actually stands for (1+x|G2), so it again adds random intercepts for each level of G2, and random slopes for x for each level of G2 (and allows these random intercepts and slopes to be correlated). So, you are in essence adding random intercepts for G2 twice; probably not what you intended. Maybe you want:
&gt; &gt; response ~ x + (1|G2/G1) + (0+x|G2)?
&gt; &gt; but this implies that the random intercepts and slopes at the G2 level are uncorrelated. Or you could use:
&gt; &gt; response ~ x + (1|G1:G2) + (x|G2)?
&gt; &gt; which gives you correlated random intercepts and slopes for G2 and also adds random intercepts for the various G1-G2 level combinations (i.e., random intercepts for each level of G1 within G2).
&gt; &gt; Best,
&gt; &gt; Wolfgang
&gt; &gt;
&gt; &gt; &gt; -----Original Message-----
&gt; &gt; &gt; From: Peter R Law [mailto:prldb at protonmail.com]
&gt; &gt; &gt; Sent: Thursday, 04 March, 2021 0:08
&gt; &gt; &gt; To: Viechtbauer, Wolfgang (SP); r-sig-mixed-models at r-project.org
&gt; &gt; &gt; Subject: RE: [R-sig-ME] lmer code for multiple random slopes
&gt; &gt; &gt; Many thanks Wolfgang! That does clear up my confusion. That interpretation of
&gt; &gt; &gt; 'random effects' didn't occur to me.
&gt; &gt; &gt; Thanks also for pointing out that the differences in the estimates provided by lme
&gt; &gt; &gt; and lmer occur because they handle singular models differently and won't occur for
&gt; &gt; &gt; non-singular examples.
&gt; &gt; &gt; When I have collected enough data, the model I am actually interested in will have
&gt; &gt; &gt; two nested random factors, G1 within G2, and I only want random slopes (say for a
&gt; &gt; &gt; covariate x) with respect to G2, but random intercepts for both factors. Am I
&gt; &gt; &gt; right in thinking the code will take the form
&gt; &gt; &gt; response ~ x + (1|G2/G1) + (x|G2)?
&gt; &gt; &gt; Much appreciated,
&gt; &gt; &gt; Peter
&gt; &gt; &gt; Peter R Law
&gt; &gt; &gt; Research Associate
&gt; &gt; &gt; Center for African Conservation Ecology
&gt; &gt; &gt; Nelson Mandela University
&gt; &gt; &gt; South Africa
&gt; &gt; &gt; ??????? Original Message ???????
&gt; &gt; &gt; On Wednesday, March 3, 2021 7:43 AM, Viechtbauer, Wolfgang (SP)
&gt; &gt; &gt; wolfgang.viechtbauer at maastrichtuniversity.nl wrote:
&gt; &gt; &gt;
&gt; &gt; &gt; &gt; Dear Peter, Dear All,
&gt; &gt; &gt; &gt; The error doesn't say 78 variance components, it says 78 random effects. There
&gt; &gt; &gt; &gt; are 26 groups in this dataset and you are estimating random intercepts and two
&gt; &gt; &gt; &gt; sets of random slopes. Hence, there are 3*26 = 78 random effects that are in this
&gt; &gt; &gt; &gt; model. But the dataset has only 74 rows. This is a check built into lmer() to
&gt; &gt; &gt; &gt; avoid fitting overly complex models for a given dataset. You can disable this
&gt; &gt; &gt; &gt; check with (also, use REML=FALSE, not "False"):
&gt; &gt; &gt; &gt; M2 &lt;- lmer(Response ~ P + A + (P + A | Group), REML=FALSE, data=Trial,
&gt; &gt; &gt; &gt; control=lmerControl(check.nobs.vs.nRE="ignore"))
&gt; &gt; &gt; &gt; Then it will run and this is the same model as fitted with:
&gt; &gt; &gt; &gt; M2n &lt;- lme( Response ~ P + A, random = ~ P + A | Group, data=Trial, method="ML")
&gt; &gt; &gt; &gt; The results differ somewhat though, because both packages handle such ill-
&gt; &gt; &gt; &gt; defined problems in different ways.
&gt; &gt; &gt; &gt; Best,
&gt; &gt; &gt; &gt; Wolfgang
&gt;
&gt; R-sig-mixed-models at r-project.org mailing list
&gt; https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

</r-sig-mixed-models at r-project.org>


From D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u  Tue Apr 13 08:51:09 2021
From: D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u (David Duffy)
Date: Tue, 13 Apr 2021 06:51:09 +0000
Subject: [R-sig-ME] Observation-level random effects
In-Reply-To: <CAP5=mpgWwfBP0QLLopvsZYSfqMm7=ja8C+Z=L6sjnB=6g6AB0w@mail.gmail.com>
References: <CAP5=mpj2gn6U5gAs1TqtQHscosAeErr1mWCwQK-x1DnaQXG6Jw@mail.gmail.com>
 <CAJuCY5y8kqUMSdBREOhnqBK8mjA+Ya_YvOBbH6AxWjoCao49nw@mail.gmail.com>
 <CAP5=mpi7aYAwCrcfd8yZGbjQysKFjjHKrBVW1TVeTEy1-Oivdg@mail.gmail.com>
 <CAJuCY5z5xkMs6z5GFs0Ti_NPgO6inj-p+bQG1Maii1eN-a6JLw@mail.gmail.com>
 <CAP5=mphtLjmOehMbRJzJHLu+U3Fe5T-bQeMALXpqcyfvMZ_Wyw@mail.gmail.com>
 <4afd2a515d154f469d70d4d647d84c64@qimrberghofer.edu.au>,
 <CAP5=mpgWwfBP0QLLopvsZYSfqMm7=ja8C+Z=L6sjnB=6g6AB0w@mail.gmail.com>
Message-ID: <a694364940f7414d865e008a986afa83@qimrberghofer.edu.au>

Dear Shahin. I have attempted to fit the "animal model" for "development", treating each observation as a single offspring, with egg and Tank as fixed effects (Tanks has 5 levels), and Cross as a RE. (These data are odd, with development falling on just 26 values, and Tank 5 has  20 obs at 895.3, and 2 x 901.1!). This was done in a couple of non-R genetics oriented LMM packages, incl Wombat (Karin Meyers' AI-REML package). This model still does not converge, but roughly Cross is 3/4 of the variance, and additive genetic ~1/4, with residual variance small (driven by repeated parents). You will have to seek local statistical advice re priors for a Bayesian model in, say, MCMCglmm, or augment your data with other datasets for this organism.
________________________________________
From: Shahinur, Islam <shahinur.islam at mun.ca>
Sent: Monday, 12 April 2021 9:40:22 PM
To: David Duffy
Cc: Shahinur, Islam; Thierry Onkelinx; r-sig-mixed-models
Subject: Re: [R-sig-ME] Observation-level random effects

Hello David,

Thank you for the reply (also thanks to Thierry).

You are right- I was trying to see paternal (Male.ID; 42 levels out of 103 observations) and maternal (Female.ID; 53 levels out of 103 observations) contribution, but still getting boundary (singular) fit: see ?isSingular  errors  for development.overall or for some of the other traits (response variables).

Thanks,

Shahin

<><><><><><><><><><><><><><><><><><><><><><><><><><>

Shahinur S. Islam
PhD Candidate, Department of Ocean Sciences
Ocean Sciences Centre, Memorial University of Newfoundland
St. John's, NL  A1C 5S7, Canada
Cell: (+1)709-740-3324; Twitter: @EcoEvoGen


On Mon, Apr 12, 2021 at 4:03 AM David Duffy <David.Duffy at qimrberghofer.edu.au<mailto:David.Duffy at qimrberghofer.edu.au>> wrote:
> No, they are not the replicates of the same family, but 20 different
> families under Cross (Population) Farm.NA.

Dear Shahin.
Thierry has already answered your question, in that unless you provide a within-family standard deviation for each
"development.overall" or "egg.size" observation, there is no information about familial random effects. You can examine paternal
and maternal contributions, since some of these are repeated across families (in your example data),
but you will not have a lot of power, I fear.





[EXTERNAL EMAIL] This message originates from an external email address, please exercise caution when clicking any links or opening attachments. If you believe the sender is impersonating someone at QIMR Berghofer, please forward this message to phishing at qimrberghofer.edu.au.


From wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n|  Tue Apr 13 14:31:51 2021
From: wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n| (Viechtbauer, Wolfgang (SP))
Date: Tue, 13 Apr 2021 12:31:51 +0000
Subject: [R-sig-ME] lmer code for multiple random slopes
In-Reply-To: <dcgVUuZEo0JKpGy6UNMO5Rs8gcsEaewdTDcc1JBzyMFHl_LmLRUEeKXvMTzGZh83op1veLGGEh1PfsItzIiHtBoK42mRUo54slXKhO_8Vio=@protonmail.com>
References: <34JKCz24u8awawkhTLmboO_cBRWW-m0XAb0frTUb9YqspQe1VeBBWUvfqKd3-QIMLeKpiDUyzhN0X6aqRlEqwX1LmBfg3gn9EB2XCa5v62s=@protonmail.com>
 <NCGF24lxdAy2bcOAoQsutEkYQ-ZIzb4e3xLenmSDhGyZN8a8sIcv-wHF0IEfLK8GQGccVE1hLTk-i1UPxFITTgLC9T929E6F4rQVMwVN8bg=@protonmail.com>
 <e2zoG5je3QHzcPl3dsttnLigMgzR8mqiUJAdgntQm9xPOX4j3SwlDytjMtbOFRj-vf5TjpHVRD7rzd54mvwMFm9OhW-ff4lfhR383lioPX4=@protonmail.com>
 <f286a096-f420-c246-61ad-542eaa5dad44@phillipalday.com>
 <CIYTFe7RNWpkAwUyuCM71pFEfhP-gPVj0OcD-UjLX0LbfzrRbySwMeVxASDMGs6D3aOxqydPUAg1NbZJar32LOtM42U-ZY-03eCCB7JbkUg=@protonmail.com>
 <e0894da27f994e64863768033e5c4989@UM-MAIL3214.unimaas.nl>
 <Ys_EWO7eMIPbh1nezv5C8Qd2cu51FF6MTNolLdBcuZcBgb8soEkJwTMl8QPDQKRCNqLEQQLJyqoVNkB2izRT13vOwKw_NIuBvK34uES4oJk=@protonmail.com>
 <8bc0234f3e904300b84f7df721ef6534@UM-MAIL3214.unimaas.nl>
 <uE3jE1zXUjFp71_IDL14arC1sYdRmI86rrWgzVNBWIQd19Q42xVlC09lLsxR38Z7vGWSNAAdqtui3zs9Y24knhKn77WJlLJkwedvV2jGdlQ=@protonmail.com>
 <dcgVUuZEo0JKpGy6UNMO5Rs8gcsEaewdTDcc1JBzyMFHl_LmLRUEeKXvMTzGZh83op1veLGGEh1PfsItzIiHtBoK42mRUo54slXKhO_8Vio=@protonmail.com>
Message-ID: <1ccfa60dca764c45a99e9468f0d6b16a@UM-MAIL3214.unimaas.nl>

Yes, lmer() will split up the intercept variances into two pieces, but marginally things will be the same, at least in this particular case. But the second model is overparameterized and should not be used, so in *all* situations you should use the top model. In other words, I cannot think of a single reason why you would ever want to use the *second* formulation.

Best,
Wolfgang

>-----Original Message-----
>From: Peter R Law [mailto:prldb at protonmail.com]
>Sent: Tuesday, 13 April, 2021 4:45
>To: Peter R Law; r-sig-mixed-models at r-project.org; Viechtbauer, Wolfgang (SP)
>Subject: Re: [R-sig-ME] lmer code for multiple random slopes
>
>Hi Wolfgang:
>
>I used some simulated data to explore the two different models you described in
>your response to my query:
>
>lmer(y ~ x + (1|G1:G2) + (x|G1))
>
>versus
>
>lmer(y ~ x + (1|G1/G2) + (x|G1))
>
>For my simulated data, the latter model divides the random intercept of G1 into
>two unequal parts but otherwise the models are almost identical, even with the
>same deviance.
>
>Apart from replacing the single random intercept due to G1 in the top model by two
>random intercepts due to G1 in the bottom model, the models seem to be otherwise
>the same.
>
>If so, is there any situation in which one would consider the top model?
>
>Peter
>
>??????? Original Message ???????
>On Thursday, March 4, 2021 9:13 PM, Peter R Law via R-sig-mixed-models <r-sig-
>mixed-models using r-project.org> wrote:
>
>> Many thanks Wolfgang.
>>
>> Peter
>>
>> ??????? Original Message ???????
>> On Thursday, March 4, 2021 5:45 AM, Viechtbauer, Wolfgang (SP)
>wolfgang.viechtbauer using maastrichtuniversity.nl wrote:
>>
>> > Hi Peter,
>> > In:
>> > response ~ x + (1|G2/G1) + (x|G2)?
>> > the first () term adds random intercepts for each level of G2 and random
>intercepts for each level of G1 within G2. The second () term actually stands for
>(1+x|G2), so it again adds random intercepts for each level of G2, and random
>slopes for x for each level of G2 (and allows these random intercepts and slopes
>to be correlated). So, you are in essence adding random intercepts for G2 twice;
>probably not what you intended. Maybe you want:
>> > response ~ x + (1|G2/G1) + (0+x|G2)?
>> > but this implies that the random intercepts and slopes at the G2 level are
>uncorrelated. Or you could use:
>> > response ~ x + (1|G1:G2) + (x|G2)?
>> > which gives you correlated random intercepts and slopes for G2 and also adds
>random intercepts for the various G1-G2 level combinations (i.e., random
>intercepts for each level of G1 within G2).
>> > Best,
>> > Wolfgang

From v|ncent@bremhor@t @end|ng |rom uc|ouv@|n@be  Fri Apr 16 11:54:16 2021
From: v|ncent@bremhor@t @end|ng |rom uc|ouv@|n@be (Vincent Bremhorst)
Date: Fri, 16 Apr 2021 09:54:16 +0000
Subject: [R-sig-ME] Comparison between the ouputs of the lmer and the brm
 (from the brms package) functions
Message-ID: <AM0PR03MB593783D9634E84C2B50E5B358A4C9@AM0PR03MB5937.eurprd03.prod.outlook.com>

Dear all,

I fitted the same mixed model using two different functions : lmer and brm.

The estimation of the standard deviation of the random effect and the estimation of the standard errors of the intercept differ. Both estimates are higher with the Bayesian procedure.
Since  I use non-informative prior in the brm specification, I would expect similar results.
The other estimates are similar for both procedures.

Do you have any idea what's happen here?
Thanks for your help,
Vincent Bremhorst.

lmer (model assumptions are met):

res <- lmer(dTmeanoff ~ habitat + (1|week), data=trh)


Linear mixed model fit by REML. t-tests use Satterthwaite's method ['lmerModLmerTest']

Formula: dTmeanoff ~ habitat + (1 | week)

   Data: trh



REML criterion at convergence: 312.5



Scaled residuals:

    Min      1Q  Median      3Q     Max

-3.5949 -0.5149 -0.0181  0.4792  2.2995



Random effects:

 Groups   Name        Variance Std.Dev.

 week     (Intercept) 0.06142  0.2478

 Residual             1.93221  1.3900

Number of obs: 89, groups:  week, 4



Fixed effects:

            Estimate Std. Error      df t value Pr(>|t|)

(Intercept)   0.6200     0.2788 12.5997   2.224   0.0451 *

habitatu     -0.8101     0.3503 83.0542  -2.312   0.0232 *

habitatw     -1.6366     0.3698 83.2151  -4.425  2.9e-05 ***

---

Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1



Correlation of Fixed Effects:

         (Intr) habitt

habitatu -0.638

habitatw -0.605  0.481

brm (convergence of the posterior chains ok)


> priors<- c(prior(normal(0,100), class="b"),

+            prior(normal(0, 100), class="Intercept"),

+            prior(exponential(0.1), class="sigma"),

+            prior(exponential(0.1), class="sd", group= "week")

+

+ )



> fit1<- brm(dTmeanoff~habitat+(1|week), data=trh,

+            prior=priors,

+            iter=4000, warmup=2000,chains=2,

+            family = gaussian(),#no logit function applied

+            file = "output.rds",

+            sample_prior = "yes",

+            control = list(adapt_delta = .9))



Family: gaussian

  Links: mu = identity; sigma = identity

Formula: dTmeanoff ~ habitat + (1 | week)

   Data: trh (Number of observations: 89)

Samples: 2 chains, each with iter = 4000; warmup = 2000; thin = 1;

         total post-warmup samples = 4000



Group-Level Effects:

~week (Number of levels: 4)

              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS

sd(Intercept)     0.50      0.48     0.02     1.82 1.00      900     1048



Population-Level Effects:

          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS

Intercept     0.63      0.36    -0.11     1.40 1.00     1159      901

habitatu     -0.82      0.35    -1.51    -0.13 1.00     2235     2581

habitatw     -1.65      0.37    -2.37    -0.89 1.00     2091     2500



Family Specific Parameters:

      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS

sigma     1.41      0.11     1.21     1.65 1.00     2863     2199



	[[alternative HTML version deleted]]


From me @end|ng |rom ph||||p@|d@y@com  Fri Apr 16 12:50:11 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Fri, 16 Apr 2021 12:50:11 +0200
Subject: [R-sig-ME] 
 Comparison between the ouputs of the lmer and the brm
 (from the brms package) functions
In-Reply-To: <AM0PR03MB593783D9634E84C2B50E5B358A4C9@AM0PR03MB5937.eurprd03.prod.outlook.com>
References: <AM0PR03MB593783D9634E84C2B50E5B358A4C9@AM0PR03MB5937.eurprd03.prod.outlook.com>
Message-ID: <fb73646f-a0d7-aef6-9e23-eb8ad071ce80@phillipalday.com>

Note that brms does some special reparameterization magic with the
intercept and uses a weakly informative prior for both the
reparameterized intercept and the random effects.

Also, if you look, you'll see that youR ESS is much lower for the
intercept and the RE than for the other parameters. This can be
indicative of the model having trouble exploring how those parameters
relate and thus still having a large amount of uncertainty.

In other words, the uncertainty in the random-effect of Intercept
results in increased uncertainty for the fixed-effect of Intercept.

Phillip

On 16/4/21 11:54 am, Vincent Bremhorst wrote:
> Dear all,
> 
> I fitted the same mixed model using two different functions : lmer and brm.
> 
> The estimation of the standard deviation of the random effect and the estimation of the standard errors of the intercept differ. Both estimates are higher with the Bayesian procedure.
> Since  I use non-informative prior in the brm specification, I would expect similar results.
> The other estimates are similar for both procedures.
> 
> Do you have any idea what's happen here?
> Thanks for your help,
> Vincent Bremhorst.
> 
> lmer (model assumptions are met):
> 
> res <- lmer(dTmeanoff ~ habitat + (1|week), data=trh)
> 
> 
> Linear mixed model fit by REML. t-tests use Satterthwaite's method ['lmerModLmerTest']
> 
> Formula: dTmeanoff ~ habitat + (1 | week)
> 
>    Data: trh
> 
> 
> 
> REML criterion at convergence: 312.5
> 
> 
> 
> Scaled residuals:
> 
>     Min      1Q  Median      3Q     Max
> 
> -3.5949 -0.5149 -0.0181  0.4792  2.2995
> 
> 
> 
> Random effects:
> 
>  Groups   Name        Variance Std.Dev.
> 
>  week     (Intercept) 0.06142  0.2478
> 
>  Residual             1.93221  1.3900
> 
> Number of obs: 89, groups:  week, 4
> 
> 
> 
> Fixed effects:
> 
>             Estimate Std. Error      df t value Pr(>|t|)
> 
> (Intercept)   0.6200     0.2788 12.5997   2.224   0.0451 *
> 
> habitatu     -0.8101     0.3503 83.0542  -2.312   0.0232 *
> 
> habitatw     -1.6366     0.3698 83.2151  -4.425  2.9e-05 ***
> 
> ---
> 
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> 
> 
> 
> Correlation of Fixed Effects:
> 
>          (Intr) habitt
> 
> habitatu -0.638
> 
> habitatw -0.605  0.481
> 
> brm (convergence of the posterior chains ok)
> 
> 
>> priors<- c(prior(normal(0,100), class="b"),
> 
> +            prior(normal(0, 100), class="Intercept"),
> 
> +            prior(exponential(0.1), class="sigma"),
> 
> +            prior(exponential(0.1), class="sd", group= "week")
> 
> +
> 
> + )
> 
> 
> 
>> fit1<- brm(dTmeanoff~habitat+(1|week), data=trh,
> 
> +            prior=priors,
> 
> +            iter=4000, warmup=2000,chains=2,
> 
> +            family = gaussian(),#no logit function applied
> 
> +            file = "output.rds",
> 
> +            sample_prior = "yes",
> 
> +            control = list(adapt_delta = .9))
> 
> 
> 
> Family: gaussian
> 
>   Links: mu = identity; sigma = identity
> 
> Formula: dTmeanoff ~ habitat + (1 | week)
> 
>    Data: trh (Number of observations: 89)
> 
> Samples: 2 chains, each with iter = 4000; warmup = 2000; thin = 1;
> 
>          total post-warmup samples = 4000
> 
> 
> 
> Group-Level Effects:
> 
> ~week (Number of levels: 4)
> 
>               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
> 
> sd(Intercept)     0.50      0.48     0.02     1.82 1.00      900     1048
> 
> 
> 
> Population-Level Effects:
> 
>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
> 
> Intercept     0.63      0.36    -0.11     1.40 1.00     1159      901
> 
> habitatu     -0.82      0.35    -1.51    -0.13 1.00     2235     2581
> 
> habitatw     -1.65      0.37    -2.37    -0.89 1.00     2091     2500
> 
> 
> 
> Family Specific Parameters:
> 
>       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
> 
> sigma     1.41      0.11     1.21     1.65 1.00     2863     2199
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From th|erry@onke||nx @end|ng |rom |nbo@be  Fri Apr 16 12:57:13 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Fri, 16 Apr 2021 12:57:13 +0200
Subject: [R-sig-ME] 
 Comparison between the ouputs of the lmer and the brm
 (from the brms package) functions
In-Reply-To: <fb73646f-a0d7-aef6-9e23-eb8ad071ce80@phillipalday.com>
References: <AM0PR03MB593783D9634E84C2B50E5B358A4C9@AM0PR03MB5937.eurprd03.prod.outlook.com>
 <fb73646f-a0d7-aef6-9e23-eb8ad071ce80@phillipalday.com>
Message-ID: <CAJuCY5xd9=RyGAZMqjYN5nFbqGSi1vXGoxXToEgoCdnr8EkuXQ@mail.gmail.com>

Dear Vincent,

Also, notice that you have a tiny data set. Hence the prior distribution
will dominate the posterior distribution.
You have too few levels for a reasonable estimate of the random effect
variance.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op vr 16 apr. 2021 om 12:50 schreef Phillip Alday <me at phillipalday.com>:

> Note that brms does some special reparameterization magic with the
> intercept and uses a weakly informative prior for both the
> reparameterized intercept and the random effects.
>
> Also, if you look, you'll see that youR ESS is much lower for the
> intercept and the RE than for the other parameters. This can be
> indicative of the model having trouble exploring how those parameters
> relate and thus still having a large amount of uncertainty.
>
> In other words, the uncertainty in the random-effect of Intercept
> results in increased uncertainty for the fixed-effect of Intercept.
>
> Phillip
>
> On 16/4/21 11:54 am, Vincent Bremhorst wrote:
> > Dear all,
> >
> > I fitted the same mixed model using two different functions : lmer and
> brm.
> >
> > The estimation of the standard deviation of the random effect and the
> estimation of the standard errors of the intercept differ. Both estimates
> are higher with the Bayesian procedure.
> > Since  I use non-informative prior in the brm specification, I would
> expect similar results.
> > The other estimates are similar for both procedures.
> >
> > Do you have any idea what's happen here?
> > Thanks for your help,
> > Vincent Bremhorst.
> >
> > lmer (model assumptions are met):
> >
> > res <- lmer(dTmeanoff ~ habitat + (1|week), data=trh)
> >
> >
> > Linear mixed model fit by REML. t-tests use Satterthwaite's method
> ['lmerModLmerTest']
> >
> > Formula: dTmeanoff ~ habitat + (1 | week)
> >
> >    Data: trh
> >
> >
> >
> > REML criterion at convergence: 312.5
> >
> >
> >
> > Scaled residuals:
> >
> >     Min      1Q  Median      3Q     Max
> >
> > -3.5949 -0.5149 -0.0181  0.4792  2.2995
> >
> >
> >
> > Random effects:
> >
> >  Groups   Name        Variance Std.Dev.
> >
> >  week     (Intercept) 0.06142  0.2478
> >
> >  Residual             1.93221  1.3900
> >
> > Number of obs: 89, groups:  week, 4
> >
> >
> >
> > Fixed effects:
> >
> >             Estimate Std. Error      df t value Pr(>|t|)
> >
> > (Intercept)   0.6200     0.2788 12.5997   2.224   0.0451 *
> >
> > habitatu     -0.8101     0.3503 83.0542  -2.312   0.0232 *
> >
> > habitatw     -1.6366     0.3698 83.2151  -4.425  2.9e-05 ***
> >
> > ---
> >
> > Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> >
> >
> >
> > Correlation of Fixed Effects:
> >
> >          (Intr) habitt
> >
> > habitatu -0.638
> >
> > habitatw -0.605  0.481
> >
> > brm (convergence of the posterior chains ok)
> >
> >
> >> priors<- c(prior(normal(0,100), class="b"),
> >
> > +            prior(normal(0, 100), class="Intercept"),
> >
> > +            prior(exponential(0.1), class="sigma"),
> >
> > +            prior(exponential(0.1), class="sd", group= "week")
> >
> > +
> >
> > + )
> >
> >
> >
> >> fit1<- brm(dTmeanoff~habitat+(1|week), data=trh,
> >
> > +            prior=priors,
> >
> > +            iter=4000, warmup=2000,chains=2,
> >
> > +            family = gaussian(),#no logit function applied
> >
> > +            file = "output.rds",
> >
> > +            sample_prior = "yes",
> >
> > +            control = list(adapt_delta = .9))
> >
> >
> >
> > Family: gaussian
> >
> >   Links: mu = identity; sigma = identity
> >
> > Formula: dTmeanoff ~ habitat + (1 | week)
> >
> >    Data: trh (Number of observations: 89)
> >
> > Samples: 2 chains, each with iter = 4000; warmup = 2000; thin = 1;
> >
> >          total post-warmup samples = 4000
> >
> >
> >
> > Group-Level Effects:
> >
> > ~week (Number of levels: 4)
> >
> >               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
> >
> > sd(Intercept)     0.50      0.48     0.02     1.82 1.00      900     1048
> >
> >
> >
> > Population-Level Effects:
> >
> >           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
> >
> > Intercept     0.63      0.36    -0.11     1.40 1.00     1159      901
> >
> > habitatu     -0.82      0.35    -1.51    -0.13 1.00     2235     2581
> >
> > habitatw     -1.65      0.37    -2.37    -0.89 1.00     2091     2500
> >
> >
> >
> > Family Specific Parameters:
> >
> >       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
> >
> > sigma     1.41      0.11     1.21     1.65 1.00     2863     2199
> >
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From tor@ten@h@u||e @end|ng |rom gm@||@com  Fri Apr 16 12:57:21 2021
From: tor@ten@h@u||e @end|ng |rom gm@||@com (Torsten Hauffe)
Date: Fri, 16 Apr 2021 12:57:21 +0200
Subject: [R-sig-ME] 
 Comparison between the ouputs of the lmer and the brm
 (from the brms package) functions
In-Reply-To: <fb73646f-a0d7-aef6-9e23-eb8ad071ce80@phillipalday.com>
References: <AM0PR03MB593783D9634E84C2B50E5B358A4C9@AM0PR03MB5937.eurprd03.prod.outlook.com>
 <fb73646f-a0d7-aef6-9e23-eb8ad071ce80@phillipalday.com>
Message-ID: <CAGCrCxae=Gek8s8cDqj4LmLks3N5UfCoN+cGeCfa8DoCwsVBaw@mail.gmail.com>

What is happening when you changeyour sample_prior = "yes" in brm() back to
the default "no"?
(Disclaimer: From the brm help, I only understand the settings "no" and
"only" sampling the prior).

Cheers!

On Fri, Apr 16, 2021 at 12:50 PM Phillip Alday <me at phillipalday.com> wrote:

> Note that brms does some special reparameterization magic with the
> intercept and uses a weakly informative prior for both the
> reparameterized intercept and the random effects.
>
> Also, if you look, you'll see that youR ESS is much lower for the
> intercept and the RE than for the other parameters. This can be
> indicative of the model having trouble exploring how those parameters
> relate and thus still having a large amount of uncertainty.
>
> In other words, the uncertainty in the random-effect of Intercept
> results in increased uncertainty for the fixed-effect of Intercept.
>
> Phillip
>
> On 16/4/21 11:54 am, Vincent Bremhorst wrote:
> > Dear all,
> >
> > I fitted the same mixed model using two different functions : lmer and
> brm.
> >
> > The estimation of the standard deviation of the random effect and the
> estimation of the standard errors of the intercept differ. Both estimates
> are higher with the Bayesian procedure.
> > Since  I use non-informative prior in the brm specification, I would
> expect similar results.
> > The other estimates are similar for both procedures.
> >
> > Do you have any idea what's happen here?
> > Thanks for your help,
> > Vincent Bremhorst.
> >
> > lmer (model assumptions are met):
> >
> > res <- lmer(dTmeanoff ~ habitat + (1|week), data=trh)
> >
> >
> > Linear mixed model fit by REML. t-tests use Satterthwaite's method
> ['lmerModLmerTest']
> >
> > Formula: dTmeanoff ~ habitat + (1 | week)
> >
> >    Data: trh
> >
> >
> >
> > REML criterion at convergence: 312.5
> >
> >
> >
> > Scaled residuals:
> >
> >     Min      1Q  Median      3Q     Max
> >
> > -3.5949 -0.5149 -0.0181  0.4792  2.2995
> >
> >
> >
> > Random effects:
> >
> >  Groups   Name        Variance Std.Dev.
> >
> >  week     (Intercept) 0.06142  0.2478
> >
> >  Residual             1.93221  1.3900
> >
> > Number of obs: 89, groups:  week, 4
> >
> >
> >
> > Fixed effects:
> >
> >             Estimate Std. Error      df t value Pr(>|t|)
> >
> > (Intercept)   0.6200     0.2788 12.5997   2.224   0.0451 *
> >
> > habitatu     -0.8101     0.3503 83.0542  -2.312   0.0232 *
> >
> > habitatw     -1.6366     0.3698 83.2151  -4.425  2.9e-05 ***
> >
> > ---
> >
> > Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> >
> >
> >
> > Correlation of Fixed Effects:
> >
> >          (Intr) habitt
> >
> > habitatu -0.638
> >
> > habitatw -0.605  0.481
> >
> > brm (convergence of the posterior chains ok)
> >
> >
> >> priors<- c(prior(normal(0,100), class="b"),
> >
> > +            prior(normal(0, 100), class="Intercept"),
> >
> > +            prior(exponential(0.1), class="sigma"),
> >
> > +            prior(exponential(0.1), class="sd", group= "week")
> >
> > +
> >
> > + )
> >
> >
> >
> >> fit1<- brm(dTmeanoff~habitat+(1|week), data=trh,
> >
> > +            prior=priors,
> >
> > +            iter=4000, warmup=2000,chains=2,
> >
> > +            family = gaussian(),#no logit function applied
> >
> > +            file = "output.rds",
> >
> > +            sample_prior = "yes",
> >
> > +            control = list(adapt_delta = .9))
> >
> >
> >
> > Family: gaussian
> >
> >   Links: mu = identity; sigma = identity
> >
> > Formula: dTmeanoff ~ habitat + (1 | week)
> >
> >    Data: trh (Number of observations: 89)
> >
> > Samples: 2 chains, each with iter = 4000; warmup = 2000; thin = 1;
> >
> >          total post-warmup samples = 4000
> >
> >
> >
> > Group-Level Effects:
> >
> > ~week (Number of levels: 4)
> >
> >               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
> >
> > sd(Intercept)     0.50      0.48     0.02     1.82 1.00      900     1048
> >
> >
> >
> > Population-Level Effects:
> >
> >           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
> >
> > Intercept     0.63      0.36    -0.11     1.40 1.00     1159      901
> >
> > habitatu     -0.82      0.35    -1.51    -0.13 1.00     2235     2581
> >
> > habitatw     -1.65      0.37    -2.37    -0.89 1.00     2091     2500
> >
> >
> >
> > Family Specific Parameters:
> >
> >       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
> >
> > sigma     1.41      0.11     1.21     1.65 1.00     2863     2199
> >
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From me @end|ng |rom ph||||p@|d@y@com  Fri Apr 16 13:00:58 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Fri, 16 Apr 2021 13:00:58 +0200
Subject: [R-sig-ME] 
 Comparison between the ouputs of the lmer and the brm
 (from the brms package) functions
In-Reply-To: <CAGCrCxae=Gek8s8cDqj4LmLks3N5UfCoN+cGeCfa8DoCwsVBaw@mail.gmail.com>
References: <AM0PR03MB593783D9634E84C2B50E5B358A4C9@AM0PR03MB5937.eurprd03.prod.outlook.com>
 <fb73646f-a0d7-aef6-9e23-eb8ad071ce80@phillipalday.com>
 <CAGCrCxae=Gek8s8cDqj4LmLks3N5UfCoN+cGeCfa8DoCwsVBaw@mail.gmail.com>
Message-ID: <eae1cf32-137f-3365-3adb-da8f2626bc44@phillipalday.com>

sample_prior generates extra return values, it doesn't block sampling
from the posterior.

Thierry is right though -- you have < 100 observation and only 4 levels
of your grouping variable. Recall that random effects are *variance*
components -- estimating the variance with only 4 observations won't
give you great estimates. The maximum-likelihood estimate is well
defined, but the likelihood surface is probably quite flat and so you
can have a "highest point" on it, but there will be a lot of points that
are as nearly as high. And that's what the Bayesian analysis catches
better because it's not using a point estimate of the variance components.

Phillip

On 16/4/21 12:57 pm, Torsten Hauffe wrote:
> What is happening when you changeyour sample_prior = "yes" in brm() back
> to the default "no"?
> (Disclaimer: From the brm help, I only understand the settings "no" and
> "only" sampling the prior).
> 
> Cheers!
> 
> On Fri, Apr 16, 2021 at 12:50 PM Phillip Alday <me at phillipalday.com
> <mailto:me at phillipalday.com>> wrote:
> 
>     Note that brms does some special reparameterization magic with the
>     intercept and uses a weakly informative prior for both the
>     reparameterized intercept and the random effects.
> 
>     Also, if you look, you'll see that youR ESS is much lower for the
>     intercept and the RE than for the other parameters. This can be
>     indicative of the model having trouble exploring how those parameters
>     relate and thus still having a large amount of uncertainty.
> 
>     In other words, the uncertainty in the random-effect of Intercept
>     results in increased uncertainty for the fixed-effect of Intercept.
> 
>     Phillip
> 
>     On 16/4/21 11:54 am, Vincent Bremhorst wrote:
>     > Dear all,
>     >
>     > I fitted the same mixed model using two different functions : lmer
>     and brm.
>     >
>     > The estimation of the standard deviation of the random effect and
>     the estimation of the standard errors of the intercept differ. Both
>     estimates are higher with the Bayesian procedure.
>     > Since? I use non-informative prior in the brm specification, I
>     would expect similar results.
>     > The other estimates are similar for both procedures.
>     >
>     > Do you have any idea what's happen here?
>     > Thanks for your help,
>     > Vincent Bremhorst.
>     >
>     > lmer (model assumptions are met):
>     >
>     > res <- lmer(dTmeanoff ~ habitat + (1|week), data=trh)
>     >
>     >
>     > Linear mixed model fit by REML. t-tests use Satterthwaite's method
>     ['lmerModLmerTest']
>     >
>     > Formula: dTmeanoff ~ habitat + (1 | week)
>     >
>     >? ? Data: trh
>     >
>     >
>     >
>     > REML criterion at convergence: 312.5
>     >
>     >
>     >
>     > Scaled residuals:
>     >
>     >? ? ?Min? ? ? 1Q? Median? ? ? 3Q? ? ?Max
>     >
>     > -3.5949 -0.5149 -0.0181? 0.4792? 2.2995
>     >
>     >
>     >
>     > Random effects:
>     >
>     >? Groups? ?Name? ? ? ? Variance Std.Dev.
>     >
>     >? week? ? ?(Intercept) 0.06142? 0.2478
>     >
>     >? Residual? ? ? ? ? ? ?1.93221? 1.3900
>     >
>     > Number of obs: 89, groups:? week, 4
>     >
>     >
>     >
>     > Fixed effects:
>     >
>     >? ? ? ? ? ? ?Estimate Std. Error? ? ? df t value Pr(>|t|)
>     >
>     > (Intercept)? ?0.6200? ? ?0.2788 12.5997? ?2.224? ?0.0451 *
>     >
>     > habitatu? ? ?-0.8101? ? ?0.3503 83.0542? -2.312? ?0.0232 *
>     >
>     > habitatw? ? ?-1.6366? ? ?0.3698 83.2151? -4.425? 2.9e-05 ***
>     >
>     > ---
>     >
>     > Signif. codes:? 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>     >
>     >
>     >
>     > Correlation of Fixed Effects:
>     >
>     >? ? ? ? ? (Intr) habitt
>     >
>     > habitatu -0.638
>     >
>     > habitatw -0.605? 0.481
>     >
>     > brm (convergence of the posterior chains ok)
>     >
>     >
>     >> priors<- c(prior(normal(0,100), class="b"),
>     >
>     > +? ? ? ? ? ? prior(normal(0, 100), class="Intercept"),
>     >
>     > +? ? ? ? ? ? prior(exponential(0.1), class="sigma"),
>     >
>     > +? ? ? ? ? ? prior(exponential(0.1), class="sd", group= "week")
>     >
>     > +
>     >
>     > + )
>     >
>     >
>     >
>     >> fit1<- brm(dTmeanoff~habitat+(1|week), data=trh,
>     >
>     > +? ? ? ? ? ? prior=priors,
>     >
>     > +? ? ? ? ? ? iter=4000, warmup=2000,chains=2,
>     >
>     > +? ? ? ? ? ? family = gaussian(),#no logit function applied
>     >
>     > +? ? ? ? ? ? file = "output.rds",
>     >
>     > +? ? ? ? ? ? sample_prior = "yes",
>     >
>     > +? ? ? ? ? ? control = list(adapt_delta = .9))
>     >
>     >
>     >
>     > Family: gaussian
>     >
>     >? ?Links: mu = identity; sigma = identity
>     >
>     > Formula: dTmeanoff ~ habitat + (1 | week)
>     >
>     >? ? Data: trh (Number of observations: 89)
>     >
>     > Samples: 2 chains, each with iter = 4000; warmup = 2000; thin = 1;
>     >
>     >? ? ? ? ? total post-warmup samples = 4000
>     >
>     >
>     >
>     > Group-Level Effects:
>     >
>     > ~week (Number of levels: 4)
>     >
>     >? ? ? ? ? ? ? ?Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
>     Tail_ESS
>     >
>     > sd(Intercept)? ? ?0.50? ? ? 0.48? ? ?0.02? ? ?1.82 1.00? ? ? 900?
>     ? ?1048
>     >
>     >
>     >
>     > Population-Level Effects:
>     >
>     >? ? ? ? ? ?Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
>     >
>     > Intercept? ? ?0.63? ? ? 0.36? ? -0.11? ? ?1.40 1.00? ? ?1159? ? ? 901
>     >
>     > habitatu? ? ?-0.82? ? ? 0.35? ? -1.51? ? -0.13 1.00? ? ?2235? ? ?2581
>     >
>     > habitatw? ? ?-1.65? ? ? 0.37? ? -2.37? ? -0.89 1.00? ? ?2091? ? ?2500
>     >
>     >
>     >
>     > Family Specific Parameters:
>     >
>     >? ? ? ?Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
>     >
>     > sigma? ? ?1.41? ? ? 0.11? ? ?1.21? ? ?1.65 1.00? ? ?2863? ? ?2199
>     >
>     >
>     >
>     >? ? ? ?[[alternative HTML version deleted]]
>     >
>     > _______________________________________________
>     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >
> 
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From y@@hree19 @end|ng |rom gm@||@com  Fri Apr 16 14:11:45 2021
From: y@@hree19 @end|ng |rom gm@||@com (Yashree Mehta)
Date: Fri, 16 Apr 2021 14:11:45 +0200
Subject: [R-sig-ME] Likelihood function of lme4
Message-ID: <CAOE=hqJX0sh34oxVFaZuS3xDsZo+184w+uDjNgjpY4ccT+FUYQ@mail.gmail.com>

Hi,

Where can I find the density function used for lmer model estimation in
lme4?
I need the log likelihood value for each observation because I have to run
a non-nested test statistic for which I have to compare the log likelihood
value of each observation with that from another model.

Regards,
Yashree

	[[alternative HTML version deleted]]


From b@t|c @end|ng |rom |eed@@@c@uk  Mon Apr 19 23:51:05 2021
From: b@t|c @end|ng |rom |eed@@@c@uk (Tara Cox [RPG])
Date: Mon, 19 Apr 2021 21:51:05 +0000
Subject: [R-sig-ME] Bivariate MCMCglmm - single value threshold response
 variable
In-Reply-To: <4fbcc8dd-00a3-b86c-96b5-292e9267c2da@ed.ac.uk>
References: <AM6PR0302MB33350C4355582476FBC6E301F7789@AM6PR0302MB3335.eurprd03.prod.outlook.com>,
 <4fbcc8dd-00a3-b86c-96b5-292e9267c2da@ed.ac.uk>
Message-ID: <AM6PR0302MB3335CF9C3845E846DB063C8BF7499@AM6PR0302MB3335.eurprd03.prod.outlook.com>

Hi Jarrod,

Thanks for getting back to me!

I've been attempting to run my models with your advised priors and it has improved convergence. However, for some of my models, the trace and density of plots of variableY (i.e. survival) still show poor mixing (see attached). The heidel.diag for at.level(variable, "X").ID:at.level(variable, "Y").ID also fails. I have tried playing around with the number of iterations, thin and burnin, but haven't had any luck. Is it possible to amend the prior to assist with convergence?

Further, as my hypotheses state that phenotypic trait X affects survival, I'd like to look at correlation between the two. I had considered using the below to extract these values, but am not sure what the best method would be. Would you be able to give any advice?

corr.calc <- model2$VCV[,"traitY:traitX.ID"]/(sqrt(model2$VCV[,"traitY:traitY.ID"])*sqrt(model2$VCV[,"traitX:traitX.ID"]))

Best wishes,
Tara

________________________________
From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
Sent: 08 April 2021 14:28
To: Tara Cox [RPG] <bstlc at leeds.ac.uk>; r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Bivariate MCMCglmm - single value threshold response variable

Hi Tara,

Your second model is correct. You can ignore the warning (not an error)
that some fixed effects have been removed; often when you set up
equations involving at.level, base R's model.matrix will not
automatically delete extra parameters and so MCMCglmm checks up on this.

The model is not mixing because you are trying to estimate the residual
variance for the binary trait and this is not identifiable in the
likelihood. You should fix it at one which results in a probit model. To
do this have fix=2 when specifying the prior for R1.

Also, make sure you are using the latest version of MCMCglmm as there
was a bug with covu models thatmay be triggered under certain
circumstances and this has now been fixed.

Cheers,

Jarrod


On 08/04/2021 12:02, Tara Cox [RPG] wrote:
> This email was sent to you by someone outside the University.
> You should only click on links or attachments if you are certain that the email is genuine and the content is safe.
>
> Dear list,
>
> I am stuck attempting to run a bivariate MCMCglmm that uses response variables phenotypic trait 'x' and survival (yes/no) (hereafter referred to as 'x' and 'y', modelled Poisson and threshold, respectively). I have multiple repeats per individual for x, but a single value for y. From my research, there are two options for running this analysis:
>
> 1) As trait y possesses a single value per individual, there is no within-individual variance and so I fix the variance to 0.0001 in my prior, as per below:
>
> prior.chi = list(R = list(V = diag(c(1, 0.0001), 2, 2), nu = 2, fix=2),
>                           G = list(G1 = list(V = diag(2), nu = 1000, alpha.mu = c(0,0), alpha.V = diag(c(1, 1)),   #chi squared as this random effect (AnimalID) is specified to both response variables
>                                        G2 = list(V = diag(1), nu = 1,  alpha.mu = 0, alpha.V = diag(1000,1))))             #parameter expanded as this random effect (ObserverID) is specified only to response variable x, which is Poisson
>
> model1 <- MCMCglmm(cbind(x, y) ~ trait-1 +
>                            trait:Sex +
>                            at.level(trait,1):Age +
>                            at.level(trait,1):Age2 +
>                            at.level(trait,2):PopulationDensity +
>                            at.level(trait,2):LocalPopulationDensity +
>                            at.level(trait,2):FoodAbundance
>                          random =~ us(trait):AnimalID + idh(at.level(trait,1)):ObserverID,
>                          rcov =~ idh(trait):units,
>                          family = c("poisson","threshold"),
>                          prior = prior.chi,
>                          nitt=2250000,
>                          burnin=150000,
>                          thin=525,
>                          verbose = FALSE,
>                          pr=FALSE,
>                          data = data)
>
> 2) Use the stacked data/'covu' approach, where I get rid of the ID term for the threshold variable, and allow a covariance between the threshold residual and the Poisson ID term (as per supplementary material in Thomson et al. 2017: https://doi.org/10.1111%2Fevo.13169):
>
> prior.covu <- list(G = list(G1 = list(V = diag(1), nu = 1)),                                   # rand effect for ObserverID (fitted for x)
>                                R = list(R1 = list(V = diag(2), nu = 0.002, covu = TRUE),     # 2-way var-cov matrix of AnimalID for x, residual for y
>                                             R2 = list(V = diag(1), nu = 0.002)))                            # residual for x
>
> model2 <- MCMCglmm(x.y.data.stack ~ variable - 1 +
>                          trait:Sex +
>                            at.level(variable, "x"):Age
>                            at.level(variable, "x"):Age2 +
>                            at.level(variable, "y"):PopulationDensity +
>                            at.level(variable, "y"):LocalPopulationDensity +
>                            at.level(variable, "y"):FoodAbundance,
>                          random = ~ us(at.level(variable,"x")):ObserverID + us(at.level(variable, "x")):AnimalID,
>                          rcov = ~us(at.level(variable, "y")):AnimalID + idh(at.level(variable, "x")):units,
>                          family = NULL,            #specified already in the data
>                          prior = prior.covu,
>                          nitt=2250000,
>                          burnin=150000,
>                          thin=525,
>                          verbose = FALSE,
>                          pr=FALSE,
>                          data = data)
>
> My problem is that I cannot get my models for either method to run successfully.
>
> The convergence model 1 is poor, with trace+density plots showing poor mixing. I know that the method is viable, as I have successfully run multiple models without convergence issues using a full parameter expanded prior alongside Poisson and gaussian response variables. Therefore, I must be specifying my chi squared prior incorrectly. I've tried to read further into how to amend the prior, but I've reached my limit of understanding and keep getting stuck.
>
> When running model 2, I receive an error message stating some fixed effects are not estimable and have been removed, and that I should use an informative prior. I've tried specifying a parameter expanded prior by modifying the G structure to include 'alpha.mu = 0' and 'alpha.V = diag(1000,1)', but this doesn't help. When running the model with a single fixed effect (e.g. Age), I do not receive any error messages, but the model shows poor mixing.
>
> If anyone could provide any insight into which method might be better suited to my analysis, or how to improve the priors for either model, it would be much appreciated!
>
> Thanks a lot.
>
> Best wishes,
> Tara
>
>
>
>
>          [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
The University of Edinburgh is a charitable body, registered in Scotland, with registration number SC005336. Is e buidheann carthannais a th? ann an Oilthigh Dh?n ?ideann, cl?raichte an Alba, ?ireamh cl?raidh SC005336.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Trace_density_variableSURVIVAL.png
Type: image/png
Size: 160002 bytes
Desc: Trace_density_variableSURVIVAL.png
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20210419/9349dee3/attachment-0001.png>

From pr|db @end|ng |rom protonm@||@com  Tue Apr 20 04:47:15 2021
From: pr|db @end|ng |rom protonm@||@com (Peter R Law)
Date: Tue, 20 Apr 2021 02:47:15 +0000
Subject: [R-sig-ME] GL(L)Ms, Gamma distributions, and AIC
Message-ID: <J2ot6tPy5hFVNZaEjfO75bkzL8RvWyCpTMA_jGyCLNVhjp6aj6xsBgPCtM1Ug90yHndwpJhxRWzpTb9zsWbmKLrxrgZbwJN6No9U-pFyubo=@protonmail.com>

Hello:

The R information from ?glm includes the following:

aic:

A version of Akaike'sAn Information Criterion, minus twice the maximized log-likelihood plus twice the number of parameters, computed by theaiccomponent of the family. For binomial and Poison families the dispersion is fixed at one and the number of parameters is the number of coefficients. For gaussian, Gamma and inverse gaussian families the dispersion is estimated from the residual deviance, and the number of parameters is the number of coefficients plus one. For a gaussian family the MLE of the dispersion is used so this is a valid value of AIC, but for Gamma and inverse gaussian families it is not. For families fitted by quasi-likelihood the value isNA.

Does the text in bold mean the AIC value contained in the summary output of a glm with the Gamma distribution run in R is not valid? If so, can one still use the output from logLik for the glm to compute AIC directly? It's not quite clear to me what the issue is. For a test model of the form

glm(y ~ x + y, family=Gamma)

I got
Deviance Residuals:

Min1QMedian3QMax

-0.42321-0.10661-0.020420.077280.45861

Coefficients:

Estimate Std. Error t value Pr(>|t|)

(Intercept)3.577e-029.012e-0439.692<2e-16 ***

density-1.134e-045.469e-06 -20.730<2e-16 ***

rain2.414e-051.758e-051.3740.17

---

Signif. codes:0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

(Dispersion parameter for Gamma family taken to be 0.02430272)

Null deviance: 21.859on 499degrees of freedom

Residual deviance: 11.702on 497degrees of freedom

AIC: 3095.8

Number of Fisher Scoring iterations: 4

> logLik(M50)

'log Lik.' -1543.925 (df=4)

The logLik and AIC indicate four parameters are counted in the computation of the AIC, as I would have expected.

Whatever the issue is, is there a similar issue with Gamma models in glmer in lme4?

Peter Law

Sent with [ProtonMail](https://protonmail.com) Secure Email.
	[[alternative HTML version deleted]]


From j@h@d||e|d @end|ng |rom ed@@c@uk  Tue Apr 20 09:39:02 2021
From: j@h@d||e|d @end|ng |rom ed@@c@uk (Jarrod Hadfield)
Date: Tue, 20 Apr 2021 08:39:02 +0100
Subject: [R-sig-ME] Bivariate MCMCglmm - single value threshold response
 variable
In-Reply-To: <AM6PR0302MB3335CF9C3845E846DB063C8BF7499@AM6PR0302MB3335.eurprd03.prod.outlook.com>
References: <AM6PR0302MB33350C4355582476FBC6E301F7789@AM6PR0302MB3335.eurprd03.prod.outlook.com>
 <4fbcc8dd-00a3-b86c-96b5-292e9267c2da@ed.ac.uk>
 <AM6PR0302MB3335CF9C3845E846DB063C8BF7499@AM6PR0302MB3335.eurprd03.prod.outlook.com>
Message-ID: <4254f651-7026-d1c0-6f8c-5b56768652e6@ed.ac.uk>

Hi,


It's hard to diagnose without the full code and summary of the output. 
Could you also give some indication of the sample sizes and data structure?


Cheers,


Jarrod

On 19/04/2021 22:51, Tara Cox [RPG] wrote:
> This email was sent to you by someone outside the University.
> You should only click on links or attachments if you are certain that 
> the email is genuine and the content is safe.
> Hi Jarrod,
>
> Thanks for getting back to me!
>
> I've been attempting to run my models with your advised priors and it 
> has improved convergence. However, for some of my models, the trace 
> and density of plots of variableY (i.e. survival) still show poor 
> mixing (see attached). The heidel.diag for at.level(variable, 
> "X").ID:at.level(variable, "Y").ID also fails. I have tried playing 
> around with the number of iterations, thin and burnin, but haven't had 
> any luck. Is it possible to amend the prior to assist with convergence?
>
> Further, as my hypotheses state that phenotypic trait X affects 
> survival, I'd like to look at correlation between the two. I had 
> considered using the below to extract these values, but am not sure 
> what the best method would be. Would you be able to give any advice?
>
> corr.calc <- 
> model2$VCV[,"traitY:traitX.ID"]/(sqrt(model2$VCV[,"traitY:traitY.ID"])*sqrt(model2$VCV[,"traitX:traitX.ID"]))
>
> Best wishes,
> Tara
>
> ------------------------------------------------------------------------
> *From:* Jarrod Hadfield <j.hadfield at ed.ac.uk>
> *Sent:* 08 April 2021 14:28
> *To:* Tara Cox [RPG] <bstlc at leeds.ac.uk>; 
> r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
> *Subject:* Re: [R-sig-ME] Bivariate MCMCglmm - single value threshold 
> response variable
> Hi Tara,
>
> Your second model is correct. You can ignore the warning (not an error)
> that some fixed effects have been removed; often when you set up
> equations involving at.level, base R's model.matrix will not
> automatically delete extra parameters and so MCMCglmm checks up on this.
>
> The model is not mixing because you are trying to estimate the residual
> variance for the binary trait and this is not identifiable in the
> likelihood. You should fix it at one which results in a probit model. To
> do this have fix=2 when specifying the prior for R1.
>
> Also, make sure you are using the latest version of MCMCglmm as there
> was a bug with covu models thatmay be triggered under certain
> circumstances and this has now been fixed.
>
> Cheers,
>
> Jarrod
>
>
> On 08/04/2021 12:02, Tara Cox [RPG] wrote:
> > This email was sent to you by someone outside the University.
> > You should only click on links or attachments if you are certain 
> that the email is genuine and the content is safe.
> >
> > Dear list,
> >
> > I am stuck attempting to run a bivariate MCMCglmm that uses response 
> variables phenotypic trait 'x' and survival (yes/no) (hereafter 
> referred to as 'x' and 'y', modelled Poisson and threshold, 
> respectively). I have multiple repeats per individual for x, but a 
> single value for y. From my research, there are two options for 
> running this analysis:
> >
> > 1) As trait y possesses a single value per individual, there is no 
> within-individual variance and so I fix the variance to 0.0001 in my 
> prior, as per below:
> >
> > prior.chi = list(R = list(V = diag(c(1, 0.0001), 2, 2), nu = 2, fix=2),
> >?????????????????????????? G = list(G1 = list(V = diag(2), nu = 1000, 
> alpha.mu = c(0,0), alpha.V = diag(c(1, 1)),?? #chi squared as this 
> random effect (AnimalID) is specified to both response variables
> >??????????????????????????????????????? G2 = list(V = diag(1), nu = 
> 1,? alpha.mu = 0, alpha.V = diag(1000,1))))???????????? #parameter 
> expanded as this random effect (ObserverID) is specified only to 
> response variable x, which is Poisson
> >
> > model1 <- MCMCglmm(cbind(x, y) ~ trait-1 +
> >??????????????????????????? trait:Sex +
> >??????????????????????????? at.level(trait,1):Age +
> >??????????????????????????? at.level(trait,1):Age2 +
> > at.level(trait,2):PopulationDensity +
> > at.level(trait,2):LocalPopulationDensity +
> > at.level(trait,2):FoodAbundance
> >????????????????????????? random =~ us(trait):AnimalID + 
> idh(at.level(trait,1)):ObserverID,
> >????????????????????????? rcov =~ idh(trait):units,
> >????????????????????????? family = c("poisson","threshold"),
> >????????????????????????? prior = prior.chi,
> >????????????????????????? nitt=2250000,
> >????????????????????????? burnin=150000,
> >????????????????????????? thin=525,
> >????????????????????????? verbose = FALSE,
> >????????????????????????? pr=FALSE,
> >????????????????????????? data = data)
> >
> > 2) Use the stacked data/'covu' approach, where I get rid of the ID 
> term for the threshold variable, and allow a covariance between the 
> threshold residual and the Poisson ID term (as per supplementary 
> material in Thomson et al. 2017: https://doi.org/10.1111%2Fevo.13169): 
> <https://doi.org/10.1111%2Fevo.13169):>
> >
> > prior.covu <- list(G = list(G1 = list(V = diag(1), nu = 
> 1)),?????????????????????????????????? # rand effect for ObserverID 
> (fitted for x)
> >??????????????????????????????? R = list(R1 = list(V = diag(2), nu = 
> 0.002, covu = TRUE),???? # 2-way var-cov matrix of AnimalID for x, 
> residual for y
> >???????????????????????????????????????????? R2 = list(V = diag(1), 
> nu = 0.002)))??????????????????????????? # residual for x
> >
> > model2 <- MCMCglmm(x.y.data.stack ~ variable - 1 +
> >????????????????????????? trait:Sex +
> >??????????????????????????? at.level(variable, "x"):Age
> >??????????????????????????? at.level(variable, "x"):Age2 +
> >??????????????????????????? at.level(variable, "y"):PopulationDensity +
> >??????????????????????????? at.level(variable, 
> "y"):LocalPopulationDensity +
> >??????????????????????????? at.level(variable, "y"):FoodAbundance,
> >????????????????????????? random = ~ 
> us(at.level(variable,"x")):ObserverID + us(at.level(variable, 
> "x")):AnimalID,
> >????????????????????????? rcov = ~us(at.level(variable, 
> "y")):AnimalID + idh(at.level(variable, "x")):units,
> >????????????????????????? family = NULL, #specified already in the data
> >????????????????????????? prior = prior.covu,
> >????????????????????????? nitt=2250000,
> >????????????????????????? burnin=150000,
> >????????????????????????? thin=525,
> >????????????????????????? verbose = FALSE,
> >????????????????????????? pr=FALSE,
> >????????????????????????? data = data)
> >
> > My problem is that I cannot get my models for either method to run 
> successfully.
> >
> > The convergence model 1 is poor, with trace+density plots showing 
> poor mixing. I know that the method is viable, as I have successfully 
> run multiple models without convergence issues using a full parameter 
> expanded prior alongside Poisson and gaussian response variables. 
> Therefore, I must be specifying my chi squared prior incorrectly. I've 
> tried to read further into how to amend the prior, but I've reached my 
> limit of understanding and keep getting stuck.
> >
> > When running model 2, I receive an error message stating some fixed 
> effects are not estimable and have been removed, and that I should use 
> an informative prior. I've tried specifying a parameter expanded prior 
> by modifying the G structure to include 'alpha.mu = 0' and 'alpha.V = 
> diag(1000,1)', but this doesn't help. When running the model with a 
> single fixed effect (e.g. Age), I do not receive any error messages, 
> but the model shows poor mixing.
> >
> > If anyone could provide any insight into which method might be 
> better suited to my analysis, or how to improve the priors for either 
> model, it would be much appreciated!
> >
> > Thanks a lot.
> >
> > Best wishes,
> > Tara
> >
> >
> >
> >
> >????????? [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models 
> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> The University of Edinburgh is a charitable body, registered in 
> Scotland, with registration number SC005336. Is e buidheann 
> carthannais a th? ann an Oilthigh Dh?n ?ideann, cl?raichte an Alba, 
> ?ireamh cl?raidh SC005336.

	[[alternative HTML version deleted]]


From merk|ee @end|ng |rom m|@@our|@edu  Tue Apr 20 15:33:52 2021
From: merk|ee @end|ng |rom m|@@our|@edu (Merkle, Edgar C.)
Date: Tue, 20 Apr 2021 13:33:52 +0000
Subject: [R-sig-ME] Likelihood function of lme4
In-Reply-To: <CAOE=hqJX0sh34oxVFaZuS3xDsZo+184w+uDjNgjpY4ccT+FUYQ@mail.gmail.com>
References: <CAOE=hqJX0sh34oxVFaZuS3xDsZo+184w+uDjNgjpY4ccT+FUYQ@mail.gmail.com>
Message-ID: <DM5PR0101MB3097DEF43D5BA493771596A0D8489@DM5PR0101MB3097.prod.exchangelabs.com>

Yashree,

You might look at llcont.lmerMod() from the merDeriv package.

Ed


________________________________
From: Yashree Mehta <yashree19 at gmail.com>
Sent: Friday, April 16, 2021 7:11 AM
To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] Likelihood function of lme4

Hi,

Where can I find the density function used for lmer model estimation in
lme4?
I need the log likelihood value for each observation because I have to run
a non-nested test statistic for which I have to compare the log likelihood
value of each observation with that from another model.

Regards,
Yashree

        [[alternative HTML version deleted]]



	[[alternative HTML version deleted]]


From y@@hree19 @end|ng |rom gm@||@com  Tue Apr 20 16:12:40 2021
From: y@@hree19 @end|ng |rom gm@||@com (Yashree Mehta)
Date: Tue, 20 Apr 2021 16:12:40 +0200
Subject: [R-sig-ME] Likelihood function of lme4
In-Reply-To: <DM5PR0101MB3097DEF43D5BA493771596A0D8489@DM5PR0101MB3097.prod.exchangelabs.com>
References: <CAOE=hqJX0sh34oxVFaZuS3xDsZo+184w+uDjNgjpY4ccT+FUYQ@mail.gmail.com>
 <DM5PR0101MB3097DEF43D5BA493771596A0D8489@DM5PR0101MB3097.prod.exchangelabs.com>
Message-ID: <CAOE=hqLO+XgZ5dXD8BRNt-yt=-+atwTMfEps0uDF2FP+Exf1BA@mail.gmail.com>

Ed,

This function worked perfectly. Thank you!

Regards,
Yashree

On Tue, Apr 20, 2021 at 3:33 PM Merkle, Edgar C. <merklee at missouri.edu>
wrote:

> Yashree,
>
> You might look at llcont.lmerMod() from the merDeriv package.
>
> Ed
>
>
> ------------------------------
> *From:* Yashree Mehta <yashree19 at gmail.com>
> *Sent:* Friday, April 16, 2021 7:11 AM
> *To:* r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
> *Subject:* [R-sig-ME] Likelihood function of lme4
>
> Hi,
>
> Where can I find the density function used for lmer model estimation in
> lme4?
> I need the log likelihood value for each observation because I have to run
> a non-nested test statistic for which I have to compare the log likelihood
> value of each observation with that from another model.
>
> Regards,
> Yashree
>
>         [[alternative HTML version deleted]]
>
>
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Tue Apr 20 16:15:40 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 20 Apr 2021 10:15:40 -0400
Subject: [R-sig-ME] Likelihood function of lme4
In-Reply-To: <CAOE=hqLO+XgZ5dXD8BRNt-yt=-+atwTMfEps0uDF2FP+Exf1BA@mail.gmail.com>
References: <CAOE=hqJX0sh34oxVFaZuS3xDsZo+184w+uDjNgjpY4ccT+FUYQ@mail.gmail.com>
 <DM5PR0101MB3097DEF43D5BA493771596A0D8489@DM5PR0101MB3097.prod.exchangelabs.com>
 <CAOE=hqLO+XgZ5dXD8BRNt-yt=-+atwTMfEps0uDF2FP+Exf1BA@mail.gmail.com>
Message-ID: <e52bb862-dd12-a87f-f577-0c43a1442fd3@gmail.com>

   I would also point out that Ed is the author of the nonnest2 package, 
which already implements the Vuong test (which may be what you're trying 
to do ??)

On 4/20/21 10:12 AM, Yashree Mehta wrote:
> Ed,
> 
> This function worked perfectly. Thank you!
> 
> Regards,
> Yashree
> 
> On Tue, Apr 20, 2021 at 3:33 PM Merkle, Edgar C. <merklee at missouri.edu>
> wrote:
> 
>> Yashree,
>>
>> You might look at llcont.lmerMod() from the merDeriv package.
>>
>> Ed
>>
>>
>> ------------------------------
>> *From:* Yashree Mehta <yashree19 at gmail.com>
>> *Sent:* Friday, April 16, 2021 7:11 AM
>> *To:* r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
>> *Subject:* [R-sig-ME] Likelihood function of lme4
>>
>> Hi,
>>
>> Where can I find the density function used for lmer model estimation in
>> lme4?
>> I need the log likelihood value for each observation because I have to run
>> a non-nested test statistic for which I have to compare the log likelihood
>> value of each observation with that from another model.
>>
>> Regards,
>> Yashree
>>
>>          [[alternative HTML version deleted]]
>>
>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From y@@hree19 @end|ng |rom gm@||@com  Tue Apr 20 17:52:49 2021
From: y@@hree19 @end|ng |rom gm@||@com (Yashree Mehta)
Date: Tue, 20 Apr 2021 17:52:49 +0200
Subject: [R-sig-ME] Likelihood function of lme4
In-Reply-To: <e52bb862-dd12-a87f-f577-0c43a1442fd3@gmail.com>
References: <CAOE=hqJX0sh34oxVFaZuS3xDsZo+184w+uDjNgjpY4ccT+FUYQ@mail.gmail.com>
 <DM5PR0101MB3097DEF43D5BA493771596A0D8489@DM5PR0101MB3097.prod.exchangelabs.com>
 <CAOE=hqLO+XgZ5dXD8BRNt-yt=-+atwTMfEps0uDF2FP+Exf1BA@mail.gmail.com>
 <e52bb862-dd12-a87f-f577-0c43a1442fd3@gmail.com>
Message-ID: <CAOE=hq+hmqNzS0qghCNSD-WKOERO9Rz2ynwn-bSkDukGRomz_Q@mail.gmail.com>

Yes, I am trying to run the Vuong test.

The other model with which I am comparing the lme4 model belongs to the
"frontier" class of models. I did use nonnest2 but got the following error:
Error in UseMethod("llcont") :
  no applicable method for 'llcont' applied to an object of class "frontier"

So I decided to calculate the Vuong statistic by constructing it using
observation-level loglikelihoods.

Thank you.

Regards,
Yashree

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Tue Apr 20 18:02:34 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 20 Apr 2021 12:02:34 -0400
Subject: [R-sig-ME] Likelihood function of lme4
In-Reply-To: <CAOE=hq+hmqNzS0qghCNSD-WKOERO9Rz2ynwn-bSkDukGRomz_Q@mail.gmail.com>
References: <CAOE=hqJX0sh34oxVFaZuS3xDsZo+184w+uDjNgjpY4ccT+FUYQ@mail.gmail.com>
 <DM5PR0101MB3097DEF43D5BA493771596A0D8489@DM5PR0101MB3097.prod.exchangelabs.com>
 <CAOE=hqLO+XgZ5dXD8BRNt-yt=-+atwTMfEps0uDF2FP+Exf1BA@mail.gmail.com>
 <e52bb862-dd12-a87f-f577-0c43a1442fd3@gmail.com>
 <CAOE=hq+hmqNzS0qghCNSD-WKOERO9Rz2ynwn-bSkDukGRomz_Q@mail.gmail.com>
Message-ID: <9be7efd5-3f60-2e05-c5b9-7f91c9ada8fc@gmail.com>

   OK.  You should make sure to check that lme4 and frontier are 
computing *commensurate* log-likelihoods (e.g. that the normalization 
constants are consistently included in both packages); if possible (it 
isn't always), it's good to try to fit *identical* models in both 
package to make sure they give the same log-likelihoods. (You can't fit 
an lmer model without a random effect, but you can re-evaluate its 
likelihood with the RE variances set to zero.)

On 4/20/21 11:52 AM, Yashree Mehta wrote:
> Yes, I am trying to run the Vuong test.
> 
> The other model with which I am comparing the lme4 model belongs to the 
> "frontier" class of models. I did use nonnest2 but got the following?error:
> Error in UseMethod("llcont") :
>  ? no applicable method for 'llcont' applied to an object of class 
> "frontier"
> 
> So I decided to calculate the Vuong statistic by constructing?it using 
> observation-level loglikelihoods.
> 
> Thank you.
> 
> Regards,
> Yashree


From y@@hree19 @end|ng |rom gm@||@com  Tue Apr 20 18:23:41 2021
From: y@@hree19 @end|ng |rom gm@||@com (Yashree Mehta)
Date: Tue, 20 Apr 2021 18:23:41 +0200
Subject: [R-sig-ME] Likelihood function of lme4
In-Reply-To: <9be7efd5-3f60-2e05-c5b9-7f91c9ada8fc@gmail.com>
References: <CAOE=hqJX0sh34oxVFaZuS3xDsZo+184w+uDjNgjpY4ccT+FUYQ@mail.gmail.com>
 <DM5PR0101MB3097DEF43D5BA493771596A0D8489@DM5PR0101MB3097.prod.exchangelabs.com>
 <CAOE=hqLO+XgZ5dXD8BRNt-yt=-+atwTMfEps0uDF2FP+Exf1BA@mail.gmail.com>
 <e52bb862-dd12-a87f-f577-0c43a1442fd3@gmail.com>
 <CAOE=hq+hmqNzS0qghCNSD-WKOERO9Rz2ynwn-bSkDukGRomz_Q@mail.gmail.com>
 <9be7efd5-3f60-2e05-c5b9-7f91c9ada8fc@gmail.com>
Message-ID: <CAOE=hqJQivznqCwPE+WnqQvbu+sM1-U799xyg1hX9zZZEMcZhg@mail.gmail.com>

OK. I will make sure.

On Tue, Apr 20, 2021 at 6:02 PM Ben Bolker <bbolker at gmail.com> wrote:

>    OK.  You should make sure to check that lme4 and frontier are
> computing *commensurate* log-likelihoods (e.g. that the normalization
> constants are consistently included in both packages); if possible (it
> isn't always), it's good to try to fit *identical* models in both
> package to make sure they give the same log-likelihoods. (You can't fit
> an lmer model without a random effect, but you can re-evaluate its
> likelihood with the RE variances set to zero.)
>
> On 4/20/21 11:52 AM, Yashree Mehta wrote:
> > Yes, I am trying to run the Vuong test.
> >
> > The other model with which I am comparing the lme4 model belongs to the
> > "frontier" class of models. I did use nonnest2 but got the
> following error:
> > Error in UseMethod("llcont") :
> >    no applicable method for 'llcont' applied to an object of class
> > "frontier"
> >
> > So I decided to calculate the Vuong statistic by constructing it using
> > observation-level loglikelihoods.
> >
> > Thank you.
> >
> > Regards,
> > Yashree
>

	[[alternative HTML version deleted]]


From S|mone@Me@@|n@ @end|ng |rom u@ntwerpen@be  Tue Apr 20 10:36:27 2021
From: S|mone@Me@@|n@ @end|ng |rom u@ntwerpen@be (Simone Messina)
Date: Tue, 20 Apr 2021 08:36:27 +0000
Subject: [R-sig-ME] underdispersion glmer/MCMCglmm
Message-ID: <0cf2364efa7d48429f50c41b2db4f572@uantwerpen.be>

Dear all,

I am running binomial models based on infection rates, but I have some doubts which I hope you can kindly help me to solve.

Briefly, I want to test for the effect of forest type (2 levels) on birds? infection rate (proportion data). My dataset is composed by 2 rows per each species (one row per each type of forest). Sample sizes per species in each forest type are mostly below 10, except for one species over 20.

Question 1: Is it possible that my model is under-dispersed (see below)?
To deal with under-dispersion shall I get the model estimates as in Quasi-distribution?

glm1<-glmer(infection ~ forest + (1|species), data=dataset, family=binomial, weights = SampleSize)

> summary(glm1)
Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
 Family: binomial  ( logit )
Formula: infection ~ forest + (1 | species)
   Data: dataset
Weights: Size

     AIC      BIC   logLik deviance df.resid
      96      100      -45       90       25

Scaled residuals:
    Min      1Q  Median      3Q     Max
-1.2925 -0.4949  0.1130  0.6178  1.1473

Random effects:
 Groups  Name        Variance Std.Dev.
 species (Intercept) 1.763    1.328
Number of obs: 28, groups:  species, 14

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)  -0.2969     0.4515  -0.657    0.511
forestUNL    -0.5426     0.3875  -1.400    0.161

Correlation of Fixed Effects:
          (Intr)
forestUNL -0.414

Then I test for under- / over-dispersion, and I detect under-dispersion:
> overdisp_fun(glm1)
chisq   ratio   rdf     p
14.729  0.589  25.000  0.947

Hence, I calculated model estimates as in Quasi-distribution.

 > printCoefmat(quasi_table(glm1),digits=3)
            Estimate Std. Error z value Pr(>|z|)
(Intercept)   -0.297      0.347   -0.86    0.392
forestUNL     -0.543      0.297   -1.82    0.068 .


Question 2: in case I decide to run the model with MCMCglmm (to include phylogeny), shall I consider under- / over-dispersion? How? Is there a way to get estimates as in Quasi-distribution in MCMCglmm models?

The only info I could get so far is that MCMCglmm automatically accounts for over-dispersion in count data with poisson distribution, but I don?t understand if this is valid also in case of proportion data with binomial family.

 Thank you very much for your attention and explanations.


	[[alternative HTML version deleted]]


From benpe|zer @end|ng |rom gm@||@com  Thu Apr 22 14:33:43 2021
From: benpe|zer @end|ng |rom gm@||@com (ben pelzer)
Date: Thu, 22 Apr 2021 14:33:43 +0200
Subject: [R-sig-ME] properties posterior means and ordinary means
Message-ID: <CAFgPNS_Vx7VsM83KnbDTkfLNGb7p511n=-CcGDSRXGRh=v9_QA@mail.gmail.com>

 Dear list,

I'm looking for some advice on the properties of posterior means as
produced by lmer and coef() and of ordinary means, provided by, say,
mean().

Say we use the null-model Y = b0 + u0j + eij, with b0 being the grand mean
en u0j the deviation for "school" j, which is normally distributed.
eij is the pupil's deviation from the schoolmean b0+u0j, and is also
normally distributed.
Let's assume the number of pupils in each school is the same.

In my understanding, the coef(nullmodel) posterior means are "best" in the
sense of smallest expected quadratic deviation from the true unknown school
means, where the expectation is taken over all schools in the population of
schools. This holds only, however, if the true schoolmeans are normally
distributed. Is that correct?

The ordinary mean of one school, is "best" for that particular school, also
in the sense of smallest expected quadratic deviation from the true mean of
that particular school, the expectation taken over repeated sampling from
that same school. And the ordinary mean is also unbiased. Is that correct
too?

----

Suppose I would simulate data based on the above null-model, for 1000
schools. One of these schools is school A. This produces dataset 1.
Next, I repeat the simulation for 999 new schools, and for school A,
producing dataset 2.
Next, I repeat the simulation for 999 new schools, and for school A,
producing dataset 3.
And so on, each time taking 999 new schools, and school A, producing e.g.
5000 datasets.

For each of these 5000 datasets,  I calculate the squared deviation of the
posterior mean of school A from the true mean of school A, and this would,
averaged over the 5000 datasets, be equal to say "averagePosterior".

Next, I calculate the squared deviation from the true mean, for each of the
5000 ordinary means of school A, and take the average, leading to
"averageOrdinary".

It then would appear that averageOrdinary  <  averagePosterior. Is that
indeed what one would expect to find?

----

Thanks for any help,

Ben.

	[[alternative HTML version deleted]]


From hedyeh@h @end|ng |rom u@c@edu  Thu Apr 22 17:12:17 2021
From: hedyeh@h @end|ng |rom u@c@edu (Hedyeh Ahmadi)
Date: Thu, 22 Apr 2021 15:12:17 +0000
Subject: [R-sig-ME] Binomial glmer(): appropriateness of link and
 influential points
Message-ID: <BYAPR07MB50940DAF44AD346CDDD312C0D1469@BYAPR07MB5094.namprd07.prod.outlook.com>

Hello all,
I have two questions regarding GLMM with binomial/logit link. Here are some information about my model/data before I ask my questions:

  *   My outcome is 0/1.
  *   I have continuous and categorical predictor.
  *   My data has 19000 rows with 2 observations per subject.
  *   My model only has one random intercept for each subject.
  *   I am using glmer() command in R.

My questions are as follows and any sample R code would be appreciated:

  1.  What's the best way to evaluate the appropriateness of my link function?
  2.  What's the best way to find influential points? Can I still use Cook's distance?
     *   If yes, with what package?
     *   What would be the rule of thumb for glmer() with binomial link for Cook's distance?

Thank you in advance for your time.

Best,

Hedyeh Ahmadi, Ph.D.
Applied Statistician
Keck School of Medicine
Department of Preventive Medicine
University of Southern California

Postdoctoral Scholar
Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
University of California, Irvine

LinkedIn
www.linkedin.com/in/hedyeh-ahmadi<http://www.linkedin.com/in/hedyeh-ahmadi>
<http://www.linkedin.com/in/hedyeh-ahmadi><http://www.linkedin.com/in/hedyeh-ahmadi>





	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Thu Apr 22 17:21:04 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 22 Apr 2021 11:21:04 -0400
Subject: [R-sig-ME] Binomial glmer(): appropriateness of link and
 influential points
In-Reply-To: <BYAPR07MB50940DAF44AD346CDDD312C0D1469@BYAPR07MB5094.namprd07.prod.outlook.com>
References: <BYAPR07MB50940DAF44AD346CDDD312C0D1469@BYAPR07MB5094.namprd07.prod.outlook.com>
Message-ID: <30d614f3-121f-583a-63d3-4326a9ad7c1a@gmail.com>



On 4/22/21 11:12 AM, Hedyeh Ahmadi wrote:
> Hello all,
> I have two questions regarding GLMM with binomial/logit link. Here are some information about my model/data before I ask my questions:
> 
>    *   My outcome is 0/1.
>    *   I have continuous and categorical predictor.
>    *   My data has 19000 rows with 2 observations per subject.
>    *   My model only has one random intercept for each subject.
>    *   I am using glmer() command in R.
> 
> My questions are as follows and any sample R code would be appreciated:
> 
>    1.  What's the best way to evaluate the appropriateness of my link function?
>    2.  What's the best way to find influential points? Can I still use Cook's distance?
>       *   If yes, with what package?
>       *   What would be the rule of thumb for glmer() with binomial link for Cook's distance?
> 

   An inappropriate link function will lead to nonlinearity of the 
response on the linear-predictor scale, so the first thing to check is 
the fitted vs. residual plot (with a smoothed line added so you can see 
the trends): either

plot(fitted_model, type=c("p", "smooth"))

(maybe include pch="." since your data set is big)

or the analog via ggplot+broom.mixed: use broom.mixed::augment() to get 
a data frame including .fitted and .resid, then plot it with 
geom_point() and geom_smooth().

   There are "goodness-of-link" tests that might be generalizable to 
GLMMs, but I'm not too familiar with them.

   2. There is an influence.merMod method for GLMM fits (it may be slow 
for large data sets! You may want to set ncores>1). The 'car' package 
has some additional functionality for plotting etc.

   I'm not sure about rules of thumb.

   If you are going to fit a mixed model with two binary observations 
per cluster, you will be far from the range where PQL/Laplace/etc. are 
going to be applicable; sonsider using nAGQ>1 to fit with Gauss-Hermite 
quadrature.

> Thank you in advance for your time.
> 
> Best,
> 
> Hedyeh Ahmadi, Ph.D.
> Applied Statistician
> Keck School of Medicine
> Department of Preventive Medicine
> University of Southern California
> 
> Postdoctoral Scholar
> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
> University of California, Irvine
> 
> LinkedIn
> www.linkedin.com/in/hedyeh-ahmadi<http://www.linkedin.com/in/hedyeh-ahmadi>
> <http://www.linkedin.com/in/hedyeh-ahmadi><http://www.linkedin.com/in/hedyeh-ahmadi>
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From hedyeh@h @end|ng |rom u@c@edu  Thu Apr 22 17:52:55 2021
From: hedyeh@h @end|ng |rom u@c@edu (Hedyeh Ahmadi)
Date: Thu, 22 Apr 2021 15:52:55 +0000
Subject: [R-sig-ME] Binomial glmer(): appropriateness of link and
 influential points
In-Reply-To: <30d614f3-121f-583a-63d3-4326a9ad7c1a@gmail.com>
References: <BYAPR07MB50940DAF44AD346CDDD312C0D1469@BYAPR07MB5094.namprd07.prod.outlook.com>,
 <30d614f3-121f-583a-63d3-4326a9ad7c1a@gmail.com>
Message-ID: <BYAPR07MB50940B3A9D5C4C67E2FCE0C8D1469@BYAPR07MB5094.namprd07.prod.outlook.com>

Thank you for the quick and informative reply.

  1.  Yes, I was aware of the plot(fitted_model, type=c("p", "smooth")) but is this appropriate for 0/1 outcome? I am asking since the plot would be just two lines for the 0 and 1 categories with a smoother in the middle.
  2.  I have tried influence.merMod() and it takes a very long time. So the Cook's distance is still appropriate for GLMM with logit link?

Best,

Hedyeh Ahmadi, Ph.D.
Statistician
Keck School of Medicine
Department of Preventive Medicine
University of Southern California

Postdoctoral Scholar
Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
University of California, Irvine

LinkedIn
www.linkedin.com/in/hedyeh-ahmadi<http://www.linkedin.com/in/hedyeh-ahmadi>
<http://www.linkedin.com/in/hedyeh-ahmadi><http://www.linkedin.com/in/hedyeh-ahmadi>




________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Ben Bolker <bbolker at gmail.com>
Sent: Thursday, April 22, 2021 8:21 AM
To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Binomial glmer(): appropriateness of link and influential points



On 4/22/21 11:12 AM, Hedyeh Ahmadi wrote:
> Hello all,
> I have two questions regarding GLMM with binomial/logit link. Here are some information about my model/data before I ask my questions:
>
>    *   My outcome is 0/1.
>    *   I have continuous and categorical predictor.
>    *   My data has 19000 rows with 2 observations per subject.
>    *   My model only has one random intercept for each subject.
>    *   I am using glmer() command in R.
>
> My questions are as follows and any sample R code would be appreciated:
>
>    1.  What's the best way to evaluate the appropriateness of my link function?
>    2.  What's the best way to find influential points? Can I still use Cook's distance?
>       *   If yes, with what package?
>       *   What would be the rule of thumb for glmer() with binomial link for Cook's distance?
>

   An inappropriate link function will lead to nonlinearity of the
response on the linear-predictor scale, so the first thing to check is
the fitted vs. residual plot (with a smoothed line added so you can see
the trends): either

plot(fitted_model, type=c("p", "smooth"))

(maybe include pch="." since your data set is big)

or the analog via ggplot+broom.mixed: use broom.mixed::augment() to get
a data frame including .fitted and .resid, then plot it with
geom_point() and geom_smooth().

   There are "goodness-of-link" tests that might be generalizable to
GLMMs, but I'm not too familiar with them.

   2. There is an influence.merMod method for GLMM fits (it may be slow
for large data sets! You may want to set ncores>1). The 'car' package
has some additional functionality for plotting etc.

   I'm not sure about rules of thumb.

   If you are going to fit a mixed model with two binary observations
per cluster, you will be far from the range where PQL/Laplace/etc. are
going to be applicable; sonsider using nAGQ>1 to fit with Gauss-Hermite
quadrature.

> Thank you in advance for your time.
>
> Best,
>
> Hedyeh Ahmadi, Ph.D.
> Applied Statistician
> Keck School of Medicine
> Department of Preventive Medicine
> University of Southern California
>
> Postdoctoral Scholar
> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
> University of California, Irvine
>
> LinkedIn
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4cS-_Nus$ <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4cS-_Nus$ >
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4cS-_Nus$ ><https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4cS-_Nus$ >
>
>
>
>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4m9HDgYw$
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4m9HDgYw$

	[[alternative HTML version deleted]]


From o||verhooker @end|ng |rom pr@t@t|@t|c@@com  Thu Apr 22 18:01:30 2021
From: o||verhooker @end|ng |rom pr@t@t|@t|c@@com (Oliver Hooker)
Date: Thu, 22 Apr 2021 17:01:30 +0100
Subject: [R-sig-ME] Bayesian Approaches to Regression and Mixed Effects
 Models using R and brms
Message-ID: <CAEsSYzz3WfTFZ8KnVmyMs8jhwe0AE3cY6u8-TAUj4z+siT+j5A@mail.gmail.com>

We have the following Byes course that may be of interest.

Bayesian Approaches to Regression and Mixed Effects Models using R and
brms (BARM01)
https://www.prstatistics.com/course/bayesian-approaches-to-regression-and-mixed-effects-models-using-r-and-brms-barm01/
26 - 27 May 2021



-- 
Oliver Hooker PhD.
PR statistics

2020 publications;
Parallelism in eco-morphology and gene expression despite variable
evolutionary and genomic backgrounds in a Holarctic fish. PLOS
GENETICS (2020). IN PRESS

www.PRstatistics.com
facebook.com/PRstatistics/
twitter.com/PRstatistics

53 Morrison Street
Glasgow
G5 8LB
+44 (0) 7966500340
+44 (0) 7966500340


From bbo|ker @end|ng |rom gm@||@com  Fri Apr 23 03:21:25 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 22 Apr 2021 21:21:25 -0400
Subject: [R-sig-ME] Binomial glmer(): appropriateness of link and
 influential points
In-Reply-To: <BYAPR07MB50940988CC13ABFF2F1F8970D1469@BYAPR07MB5094.namprd07.prod.outlook.com>
References: <BYAPR07MB50940DAF44AD346CDDD312C0D1469@BYAPR07MB5094.namprd07.prod.outlook.com>
 <30d614f3-121f-583a-63d3-4326a9ad7c1a@gmail.com>
 <BYAPR07MB50940988CC13ABFF2F1F8970D1469@BYAPR07MB5094.namprd07.prod.outlook.com>
Message-ID: <8c9db61a-9da0-888d-2e79-92d4a82c9257@gmail.com>



On 4/22/21 11:45 AM, Hedyeh Ahmadi wrote:
> Thank you for the quick and informative reply.
> 
>  1.  ?I was aware of using plot(fitted_model, type=c("p", "smooth")),
>     but I wasn't sure this would be helpful with 0/1 outcome since the
>     plot would be just two separate lines as follows - So do you think
>     this technique is still appropriate?

  Try the DHARMa package, which uses simulated quantile residuals to 
overcome this problem.
> 
> 
> 
> 
>  2. Yes, I have tried influence.merMod() and it takes way too long. So
>     Cook's distance is still sppropriate for glmer() with binomial link?

   I would think so (to be honest, most of the advice about model 
diagnostics is based on "this works for linear models and should work, 
at least asymptotically, for GLM(M)s as well"

> 
> Best,
> 
> Hedyeh Ahmadi, Ph.D.
> Statistician
> Keck School of Medicine
> Department of Preventive Medicine
> University of Southern California
> 
> Postdoctoral Scholar
> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
> University of California, Irvine
> 
> LinkedIn
> www.linkedin.com/in/hedyeh-ahmadi <http://www.linkedin.com/in/hedyeh-ahmadi>
> <http://www.linkedin.com/in/hedyeh-ahmadi><http://www.linkedin.com/in/hedyeh-ahmadi>
> 
> 
> 
> 
> ------------------------------------------------------------------------
> *From:* R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on 
> behalf of Ben Bolker <bbolker at gmail.com>
> *Sent:* Thursday, April 22, 2021 8:21 AM
> *To:* r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
> *Subject:* Re: [R-sig-ME] Binomial glmer(): appropriateness of link and 
> influential points
> 
> 
> On 4/22/21 11:12 AM, Hedyeh Ahmadi wrote:
>> Hello all,
>> I have two questions regarding GLMM with binomial/logit link. Here are some information about my model/data before I ask my questions:
>> 
>>??? *?? My outcome is 0/1.
>>??? *?? I have continuous and categorical predictor.
>>??? *?? My data has 19000 rows with 2 observations per subject.
>>??? *?? My model only has one random intercept for each subject.
>>??? *?? I am using glmer() command in R.
>> 
>> My questions are as follows and any sample R code would be appreciated:
>> 
>>??? 1.? What's the best way to evaluate the appropriateness of my link function?
>>??? 2.? What's the best way to find influential points? Can I still use Cook's distance?
>>?????? *?? If yes, with what package?
>>?????? *?? What would be the rule of thumb for glmer() with binomial link for Cook's distance?
>> 
> 
>  ?? An inappropriate link function will lead to nonlinearity of the
> response on the linear-predictor scale, so the first thing to check is
> the fitted vs. residual plot (with a smoothed line added so you can see
> the trends): either
> 
> plot(fitted_model, type=c("p", "smooth"))
> 
> (maybe include pch="." since your data set is big)
> 
> or the analog via ggplot+broom.mixed: use broom.mixed::augment() to get
> a data frame including .fitted and .resid, then plot it with
> geom_point() and geom_smooth().
> 
>  ?? There are "goodness-of-link" tests that might be generalizable to
> GLMMs, but I'm not too familiar with them.
> 
>  ?? 2. There is an influence.merMod method for GLMM fits (it may be slow
> for large data sets! You may want to set ncores>1). The 'car' package
> has some additional functionality for plotting etc.
> 
>  ?? I'm not sure about rules of thumb.
> 
>  ?? If you are going to fit a mixed model with two binary observations
> per cluster, you will be far from the range where PQL/Laplace/etc. are
> going to be applicable; sonsider using nAGQ>1 to fit with Gauss-Hermite
> quadrature.
> 
>> Thank you in advance for your time.
>> 
>> Best,
>> 
>> Hedyeh Ahmadi, Ph.D.
>> Applied Statistician
>> Keck School of Medicine
>> Department of Preventive Medicine
>> University of Southern California
>> 
>> Postdoctoral Scholar
>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>> University of California, Irvine
>> 
>> LinkedIn
>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4cS-_Nus$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4cS-_Nus$> 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4cS-_Nus$ 
>  >
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4cS-_Nus$ 
>  ><https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4cS-_Nus$ >
>> 
>> 
>> 
>> 
>> 
>>??????? [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4m9HDgYw$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4m9HDgYw$> 
> 
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4m9HDgYw$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4m9HDgYw$> 
>


From hedyeh@h @end|ng |rom u@c@edu  Fri Apr 23 04:02:00 2021
From: hedyeh@h @end|ng |rom u@c@edu (Hedyeh Ahmadi)
Date: Fri, 23 Apr 2021 02:02:00 +0000
Subject: [R-sig-ME] Binomial glmer(): appropriateness of link and
 influential points
In-Reply-To: <8c9db61a-9da0-888d-2e79-92d4a82c9257@gmail.com>
References: <BYAPR07MB50940DAF44AD346CDDD312C0D1469@BYAPR07MB5094.namprd07.prod.outlook.com>
 <30d614f3-121f-583a-63d3-4326a9ad7c1a@gmail.com>
 <BYAPR07MB50940988CC13ABFF2F1F8970D1469@BYAPR07MB5094.namprd07.prod.outlook.com>,
 <8c9db61a-9da0-888d-2e79-92d4a82c9257@gmail.com>
Message-ID: <BYAPR07MB50945F5726A59E61766A9170D1459@BYAPR07MB5094.namprd07.prod.outlook.com>

Thank you for the DHARMa suggestion - I tried it but I am not sure how to interpret the plot from simulateResiduals(). I am getting the attached plot and I think this is pretty linear so is this a pass?

Best,

Hedyeh Ahmadi, Ph.D.
Statistician
Keck School of Medicine
Department of Preventive Medicine
University of Southern California

Postdoctoral Scholar
Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
University of California, Irvine

LinkedIn
www.linkedin.com/in/hedyeh-ahmadi<http://www.linkedin.com/in/hedyeh-ahmadi>
<http://www.linkedin.com/in/hedyeh-ahmadi><http://www.linkedin.com/in/hedyeh-ahmadi>




________________________________
From: Ben Bolker <bbolker at gmail.com>
Sent: Thursday, April 22, 2021 6:21 PM
To: Hedyeh Ahmadi <hedyehah at usc.edu>; r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Binomial glmer(): appropriateness of link and influential points



On 4/22/21 11:45 AM, Hedyeh Ahmadi wrote:
> Thank you for the quick and informative reply.
>
>  1.   I was aware of using plot(fitted_model, type=c("p", "smooth")),
>     but I wasn't sure this would be helpful with 0/1 outcome since the
>     plot would be just two separate lines as follows - So do you think
>     this technique is still appropriate?

  Try the DHARMa package, which uses simulated quantile residuals to
overcome this problem.
>
>
>
>
>  2. Yes, I have tried influence.merMod() and it takes way too long. So
>     Cook's distance is still sppropriate for glmer() with binomial link?

   I would think so (to be honest, most of the advice about model
diagnostics is based on "this works for linear models and should work,
at least asymptotically, for GLM(M)s as well"

>
> Best,
>
> Hedyeh Ahmadi, Ph.D.
> Statistician
> Keck School of Medicine
> Department of Preventive Medicine
> University of Southern California
>
> Postdoctoral Scholar
> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
> University of California, Irvine
>
> LinkedIn
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7QzlJJ_apo0pfWsUyEQlBrvMwqxWXGwahNKQpyo9GM_AF8G8NAH4uDccjDXxfZA$  <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7QzlJJ_apo0pfWsUyEQlBrvMwqxWXGwahNKQpyo9GM_AF8G8NAH4uDccjDXxfZA$ >
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7QzlJJ_apo0pfWsUyEQlBrvMwqxWXGwahNKQpyo9GM_AF8G8NAH4uDccjDXxfZA$ ><https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7QzlJJ_apo0pfWsUyEQlBrvMwqxWXGwahNKQpyo9GM_AF8G8NAH4uDccjDXxfZA$ >
>
>
>
>
> ------------------------------------------------------------------------
> *From:* R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on
> behalf of Ben Bolker <bbolker at gmail.com>
> *Sent:* Thursday, April 22, 2021 8:21 AM
> *To:* r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
> *Subject:* Re: [R-sig-ME] Binomial glmer(): appropriateness of link and
> influential points
>
>
> On 4/22/21 11:12 AM, Hedyeh Ahmadi wrote:
>> Hello all,
>> I have two questions regarding GLMM with binomial/logit link. Here are some information about my model/data before I ask my questions:
>>
>>    *   My outcome is 0/1.
>>    *   I have continuous and categorical predictor.
>>    *   My data has 19000 rows with 2 observations per subject.
>>    *   My model only has one random intercept for each subject.
>>    *   I am using glmer() command in R.
>>
>> My questions are as follows and any sample R code would be appreciated:
>>
>>    1.  What's the best way to evaluate the appropriateness of my link function?
>>    2.  What's the best way to find influential points? Can I still use Cook's distance?
>>       *   If yes, with what package?
>>       *   What would be the rule of thumb for glmer() with binomial link for Cook's distance?
>>
>
>     An inappropriate link function will lead to nonlinearity of the
> response on the linear-predictor scale, so the first thing to check is
> the fitted vs. residual plot (with a smoothed line added so you can see
> the trends): either
>
> plot(fitted_model, type=c("p", "smooth"))
>
> (maybe include pch="." since your data set is big)
>
> or the analog via ggplot+broom.mixed: use broom.mixed::augment() to get
> a data frame including .fitted and .resid, then plot it with
> geom_point() and geom_smooth().
>
>     There are "goodness-of-link" tests that might be generalizable to
> GLMMs, but I'm not too familiar with them.
>
>     2. There is an influence.merMod method for GLMM fits (it may be slow
> for large data sets! You may want to set ncores>1). The 'car' package
> has some additional functionality for plotting etc.
>
>     I'm not sure about rules of thumb.
>
>     If you are going to fit a mixed model with two binary observations
> per cluster, you will be far from the range where PQL/Laplace/etc. are
> going to be applicable; sonsider using nAGQ>1 to fit with Gauss-Hermite
> quadrature.
>
>> Thank you in advance for your time.
>>
>> Best,
>>
>> Hedyeh Ahmadi, Ph.D.
>> Applied Statistician
>> Keck School of Medicine
>> Department of Preventive Medicine
>> University of Southern California
>>
>> Postdoctoral Scholar
>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>> University of California, Irvine
>>
>> LinkedIn
>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4cS-_Nus$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4cS-_Nus$>
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4cS-_Nus$
>  >
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4cS-_Nus$
>  ><https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4cS-_Nus$ >
>>
>>
>>
>>
>>
>>        [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4m9HDgYw$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4m9HDgYw$>
>
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4m9HDgYw$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4m9HDgYw$>
>

From john@m@|ndon@|d @end|ng |rom @nu@edu@@u  Fri Apr 23 04:28:49 2021
From: john@m@|ndon@|d @end|ng |rom @nu@edu@@u (John Maindonald)
Date: Fri, 23 Apr 2021 02:28:49 +0000
Subject: [R-sig-ME] Binomial glmer(): appropriateness of link and
 influential points
In-Reply-To: <BYAPR07MB50945F5726A59E61766A9170D1459@BYAPR07MB5094.namprd07.prod.outlook.com>
References: <BYAPR07MB50940DAF44AD346CDDD312C0D1469@BYAPR07MB5094.namprd07.prod.outlook.com>
 <30d614f3-121f-583a-63d3-4326a9ad7c1a@gmail.com>
 <BYAPR07MB50940988CC13ABFF2F1F8970D1469@BYAPR07MB5094.namprd07.prod.outlook.com>
 <8c9db61a-9da0-888d-2e79-92d4a82c9257@gmail.com>
 <BYAPR07MB50945F5726A59E61766A9170D1459@BYAPR07MB5094.namprd07.prod.outlook.com>
Message-ID: <5A3191CE-CB30-4AF2-944D-04979FAB2702@anu.edu.au>

My comments, which were a bit off the cuff without looking at your queries
with all the care that was desirable, were designed to highlight issues with
binomial models.  Also, for checking purposes you want to plot partial
residuals against explanatory variables in turn.  As Ben suggests, plots
using DHARMa can be a good way to go.

Alternatives to fitting a mixed model are, in your case? a model with quasibinomial
error, or a betabinomial. A betabinomial using glmmTMB allows you to model the
scale parameter.  Those sorts of abilities are also available (and plots of  simulated
quantile residuals) in the gamlss package.  Which model is more appropriate will
depend on how the within subject component of variance (for the mixed model),
or the scale parameter varies (if at all) with the fitted value.

It is worth checking these alternatives.

John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>



On 23/04/2021, at 14:02, Hedyeh Ahmadi <hedyehah at usc.edu<mailto:hedyehah at usc.edu>> wrote:

Thank you for the DHARMa suggestion - I tried it but I am not sure how to interpret the plot from simulateResiduals(). I am getting the attached plot and I think this is pretty linear so is this a pass?

Best,

Hedyeh Ahmadi, Ph.D.
Statistician
Keck School of Medicine
Department of Preventive Medicine
University of Southern California

Postdoctoral Scholar
Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
University of California, Irvine

LinkedIn
www.linkedin.com/in/hedyeh-ahmadi<http://www.linkedin.com/in/hedyeh-ahmadi><http://www.linkedin.com/in/hedyeh-ahmadi>
<http://www.linkedin.com/in/hedyeh-ahmadi><http://www.linkedin.com/in/hedyeh-ahmadi>




________________________________
From: Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com>>
Sent: Thursday, April 22, 2021 6:21 PM
To: Hedyeh Ahmadi <hedyehah at usc.edu<mailto:hedyehah at usc.edu>>; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org> <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: Re: [R-sig-ME] Binomial glmer(): appropriateness of link and influential points



On 4/22/21 11:45 AM, Hedyeh Ahmadi wrote:
Thank you for the quick and informative reply.

1.   I was aware of using plot(fitted_model, type=c("p", "smooth")),
   but I wasn't sure this would be helpful with 0/1 outcome since the
   plot would be just two separate lines as follows - So do you think
   this technique is still appropriate?

 Try the DHARMa package, which uses simulated quantile residuals to
overcome this problem.




2. Yes, I have tried influence.merMod() and it takes way too long. So
   Cook's distance is still sppropriate for glmer() with binomial link?

  I would think so (to be honest, most of the advice about model
diagnostics is based on "this works for linear models and should work,
at least asymptotically, for GLM(M)s as well"


Best,

Hedyeh Ahmadi, Ph.D.
Statistician
Keck School of Medicine
Department of Preventive Medicine
University of Southern California

Postdoctoral Scholar
Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
University of California, Irvine

LinkedIn
https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7QzlJJ_apo0pfWsUyEQlBrvMwqxWXGwahNKQpyo9GM_AF8G8NAH4uDccjDXxfZA$ <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7QzlJJ_apo0pfWsUyEQlBrvMwqxWXGwahNKQpyo9GM_AF8G8NAH4uDccjDXxfZA$ >
<https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7QzlJJ_apo0pfWsUyEQlBrvMwqxWXGwahNKQpyo9GM_AF8G8NAH4uDccjDXxfZA$ ><https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7QzlJJ_apo0pfWsUyEQlBrvMwqxWXGwahNKQpyo9GM_AF8G8NAH4uDccjDXxfZA$ >




------------------------------------------------------------------------
*From:* R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>> on
behalf of Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com>>
*Sent:* Thursday, April 22, 2021 8:21 AM
*To:* r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org> <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
*Subject:* Re: [R-sig-ME] Binomial glmer(): appropriateness of link and
influential points


On 4/22/21 11:12 AM, Hedyeh Ahmadi wrote:
Hello all,
I have two questions regarding GLMM with binomial/logit link. Here are some information about my model/data before I ask my questions:

  *   My outcome is 0/1.
  *   I have continuous and categorical predictor.
  *   My data has 19000 rows with 2 observations per subject.
  *   My model only has one random intercept for each subject.
  *   I am using glmer() command in R.

My questions are as follows and any sample R code would be appreciated:

  1.  What's the best way to evaluate the appropriateness of my link function?
  2.  What's the best way to find influential points? Can I still use Cook's distance?
     *   If yes, with what package?
     *   What would be the rule of thumb for glmer() with binomial link for Cook's distance?


   An inappropriate link function will lead to nonlinearity of the
response on the linear-predictor scale, so the first thing to check is
the fitted vs. residual plot (with a smoothed line added so you can see
the trends): either

plot(fitted_model, type=c("p", "smooth"))

(maybe include pch="." since your data set is big)

or the analog via ggplot+broom.mixed: use broom.mixed::augment() to get
a data frame including .fitted and .resid, then plot it with
geom_point() and geom_smooth().

   There are "goodness-of-link" tests that might be generalizable to
GLMMs, but I'm not too familiar with them.

   2. There is an influence.merMod method for GLMM fits (it may be slow
for large data sets! You may want to set ncores>1). The 'car' package
has some additional functionality for plotting etc.

   I'm not sure about rules of thumb.

   If you are going to fit a mixed model with two binary observations
per cluster, you will be far from the range where PQL/Laplace/etc. are
going to be applicable; sonsider using nAGQ>1 to fit with Gauss-Hermite
quadrature.

Thank you in advance for your time.

Best,

Hedyeh Ahmadi, Ph.D.
Applied Statistician
Keck School of Medicine
Department of Preventive Medicine
University of Southern California

Postdoctoral Scholar
Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
University of California, Irvine

LinkedIn
https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4cS-_Nus$
<https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4cS-_Nus$>
<https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4cS-_Nus$

<https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4cS-_Nus$
<https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4cS-_Nus$ >





      [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4m9HDgYw$
<https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4m9HDgYw$>



_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4m9HDgYw$
<https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4m9HDgYw$>

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From cm|o500 @end|ng |rom york@@c@uk  Sat Apr 24 20:29:02 2021
From: cm|o500 @end|ng |rom york@@c@uk (=?UTF-8?Q?C=C3=A1tia_Ferreira_De_Oliveira?=)
Date: Sat, 24 Apr 2021 19:29:02 +0100
Subject: [R-sig-ME] glmer and influence.me - complaining about nAGQ==0
Message-ID: <CACw+TfcLvEGOv=CG21U+MeYz9XU0VidHmmkKBO0+J7wUQircUw@mail.gmail.com>

Dear Professor Bolker,

I am really sorry for bothering you but I have been quite stuck and have
posted my question both on reddit and cross validated but nothing has come
from it. Do you know if there is a good way of running dfbetas for glmer
with a gamma distribution?  The model runs without issues,

lmer_log11 <- glmer(logRT ~ Probability*Block*Session*testing + (1 +
Block * Probability * Session|Participant), data= Data, family =
Gamma(link = "log"),
control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=1000000)),
nAGQ = 0)

yet when I run the influence function I get this error:

influentialcases <- influence(glmer_log11, "Participant")

Error in glmer(formula = RT ~ Probability * Block * Session * testing +  :
  should not specify both start$fixef and nAGQ==0

I have tried to remove the "nAGQ==0" but the model is now taking 10 days to
converge, a lot more than usual. Given this, I haven't been able to check
if the influential cases will run normally.

Do you have any idea why this is happening? I would very much
appreciate your help!

Thank you so much!

Best wishes,

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Sat Apr 24 21:52:43 2021
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Sat, 24 Apr 2021 15:52:43 -0400
Subject: [R-sig-ME] glmer and influence.me - complaining about nAGQ==0
In-Reply-To: <25510_1619289003_13OIU2KX028554_CACw+TfcLvEGOv=CG21U+MeYz9XU0VidHmmkKBO0+J7wUQircUw@mail.gmail.com>
References: <25510_1619289003_13OIU2KX028554_CACw+TfcLvEGOv=CG21U+MeYz9XU0VidHmmkKBO0+J7wUQircUw@mail.gmail.com>
Message-ID: <f0da674d-64f3-82f7-136b-2871465de994@mcmaster.ca>

Dear Catia,

I believe I understand what's going on: influence.merMod() works by 
updating the model -- it calls update() -- using the parameter estimates 
for the fit to the full data as start-values. The idea is to decrease 
the computation necessary for each re-fit.

It probably would have been better if I had made this an option, with 
using the start-values as the default, but perhaps there's a work-around:

You may be able to fit your model without specifying nACQ by instead 
specifying the estimates that you obtained as start-values. Then glmer() 
may converge quickly. If it doesn't, that would, I suppose, indicate 
some sort of ill-conditioning.

Ben might well have something to add.

I hope this helps,
  John

John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/

On 2021-04-24 2:29 p.m., C?tia Ferreira De Oliveira via 
R-sig-mixed-models wrote:
> Dear Professor Bolker,
> 
> I am really sorry for bothering you but I have been quite stuck and have
> posted my question both on reddit and cross validated but nothing has come
> from it. Do you know if there is a good way of running dfbetas for glmer
> with a gamma distribution?  The model runs without issues,
> 
> lmer_log11 <- glmer(logRT ~ Probability*Block*Session*testing + (1 +
> Block * Probability * Session|Participant), data= Data, family =
> Gamma(link = "log"),
> control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=1000000)),
> nAGQ = 0)
> 
> yet when I run the influence function I get this error:
> 
> influentialcases <- influence(glmer_log11, "Participant")
> 
> Error in glmer(formula = RT ~ Probability * Block * Session * testing +  :
>    should not specify both start$fixef and nAGQ==0
> 
> I have tried to remove the "nAGQ==0" but the model is now taking 10 days to
> converge, a lot more than usual. Given this, I haven't been able to check
> if the influential cases will run normally.
> 
> Do you have any idea why this is happening? I would very much
> appreciate your help!
> 
> Thank you so much!
> 
> Best wishes,
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From bbo|ker @end|ng |rom gm@||@com  Sat Apr 24 23:08:14 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sat, 24 Apr 2021 17:08:14 -0400
Subject: [R-sig-ME] glmer and influence.me - complaining about nAGQ==0
In-Reply-To: <f0da674d-64f3-82f7-136b-2871465de994@mcmaster.ca>
References: <25510_1619289003_13OIU2KX028554_CACw+TfcLvEGOv=CG21U+MeYz9XU0VidHmmkKBO0+J7wUQircUw@mail.gmail.com>
 <f0da674d-64f3-82f7-136b-2871465de994@mcmaster.ca>
Message-ID: <97f57616-50af-0467-920b-0e15c260b5d7@gmail.com>

    Don't have much to add to John's comments. You can see 
vignette("lmerperf") for a few suggestions on improving performance.

   I'm a little surprised that your response variable is "logRT" *and* 
you have a log-link; that seems like double-logging?  (I was going to 
suggest that if you aren't wedded to the Gamma model, a log-Normal model 
(lmer(log(logRT) ~ ...) would probably be a lot faster ...)

   It's possible that other platforms (glmmTMB, Julia::MixedModels.jl) 
would be faster ... but then you might be stuck without influence 
diagnostics again ...

On 4/24/21 3:52 PM, John Fox wrote:
> Dear Catia,
> 
> I believe I understand what's going on: influence.merMod() works by 
> updating the model -- it calls update() -- using the parameter estimates 
> for the fit to the full data as start-values. The idea is to decrease 
> the computation necessary for each re-fit.
> 
> It probably would have been better if I had made this an option, with 
> using the start-values as the default, but perhaps there's a work-around:
> 
> You may be able to fit your model without specifying nACQ by instead 
> specifying the estimates that you obtained as start-values. Then glmer() 
> may converge quickly. If it doesn't, that would, I suppose, indicate 
> some sort of ill-conditioning.
> 
> Ben might well have something to add.
> 
> I hope this helps,
>  ?John
> 
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> web: https://socialsciences.mcmaster.ca/jfox/
> 
> On 2021-04-24 2:29 p.m., C?tia Ferreira De Oliveira via 
> R-sig-mixed-models wrote:
>> Dear Professor Bolker,
>>
>> I am really sorry for bothering you but I have been quite stuck and have
>> posted my question both on reddit and cross validated but nothing has 
>> come
>> from it. Do you know if there is a good way of running dfbetas for glmer
>> with a gamma distribution?? The model runs without issues,
>>
>> lmer_log11 <- glmer(logRT ~ Probability*Block*Session*testing + (1 +
>> Block * Probability * Session|Participant), data= Data, family =
>> Gamma(link = "log"),
>> control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=1000000)),
>> nAGQ = 0)
>>
>> yet when I run the influence function I get this error:
>>
>> influentialcases <- influence(glmer_log11, "Participant")
>>
>> Error in glmer(formula = RT ~ Probability * Block * Session * testing 
>> +? :
>> ?? should not specify both start$fixef and nAGQ==0
>>
>> I have tried to remove the "nAGQ==0" but the model is now taking 10 
>> days to
>> converge, a lot more than usual. Given this, I haven't been able to check
>> if the influential cases will run normally.
>>
>> Do you have any idea why this is happening? I would very much
>> appreciate your help!
>>
>> Thank you so much!
>>
>> Best wishes,
>>
>> ????[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From me @end|ng |rom ph||||p@|d@y@com  Mon Apr 26 13:54:22 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Mon, 26 Apr 2021 13:54:22 +0200
Subject: [R-sig-ME] glmer and influence.me - complaining about nAGQ==0
In-Reply-To: <97f57616-50af-0467-920b-0e15c260b5d7@gmail.com>
References: <25510_1619289003_13OIU2KX028554_CACw+TfcLvEGOv=CG21U+MeYz9XU0VidHmmkKBO0+J7wUQircUw@mail.gmail.com>
 <f0da674d-64f3-82f7-136b-2871465de994@mcmaster.ca>
 <97f57616-50af-0467-920b-0e15c260b5d7@gmail.com>
Message-ID: <adc25a1b-dd59-78ff-f910-84f8f9f901cc@phillipalday.com>



On 24/4/21 11:08 pm, Ben Bolker wrote:
> ?? Don't have much to add to John's comments. You can see
> vignette("lmerperf") for a few suggestions on improving performance.
> 
> ? I'm a little surprised that your response variable is "logRT" *and*
> you have a log-link; that seems like double-logging?? (I was going to
> suggest that if you aren't wedded to the Gamma model, a log-Normal model
> (lmer(log(logRT) ~ ...) would probably be a lot faster ...)

Are you (C?tia) basing this model off the Lo and Andrews paper? I'm not
sure I really agree with that paper -- they seem very worried about
transformations, but then they use alternative error distributions and
links, which doesn't help interpretation for many users in my experience.

> 
> ? It's possible that other platforms (glmmTMB, Julia::MixedModels.jl)
> would be faster ... but then you might be stuck without influence
> diagnostics again ...
> 

We don't have influence currently implemented in MixedModels.jl, but
that wouldn't actually be hard. The bigger issue is that GLMMs with a
dispersion parameter, including Gamma, don't currently work in
MixedModels.jl


From hedyeh@h @end|ng |rom u@c@edu  Mon Apr 26 18:05:45 2021
From: hedyeh@h @end|ng |rom u@c@edu (Hedyeh Ahmadi)
Date: Mon, 26 Apr 2021 16:05:45 +0000
Subject: [R-sig-ME] Binomial glmer(): appropriateness of link and
 influential points
In-Reply-To: <5A3191CE-CB30-4AF2-944D-04979FAB2702@anu.edu.au>
References: <BYAPR07MB50940DAF44AD346CDDD312C0D1469@BYAPR07MB5094.namprd07.prod.outlook.com>
 <30d614f3-121f-583a-63d3-4326a9ad7c1a@gmail.com>
 <BYAPR07MB50940988CC13ABFF2F1F8970D1469@BYAPR07MB5094.namprd07.prod.outlook.com>
 <8c9db61a-9da0-888d-2e79-92d4a82c9257@gmail.com>
 <BYAPR07MB50945F5726A59E61766A9170D1459@BYAPR07MB5094.namprd07.prod.outlook.com>,
 <5A3191CE-CB30-4AF2-944D-04979FAB2702@anu.edu.au>
Message-ID: <BYAPR07MB5094F23329552DF0CCF50AA7D1429@BYAPR07MB5094.namprd07.prod.outlook.com>

Hi All,
Thank you for all your help on this - I finally found some good plots along with interpretation help and I thought I would share the link here just in case if anyone is interested:

https://github.com/florianhartig/DHARMa/issues/278
[https://opengraph.githubassets.com/c380efaec2f6833c58459e212b8ce5e36881f692f8c91082601c58e1409bc49d/florianhartig/DHARMa/issues/278]<https://github.com/florianhartig/DHARMa/issues/278>
Interpretation of DHARMa plot for logistic regression ? Issue #278 ? florianhartig/DHARMa<https://github.com/florianhartig/DHARMa/issues/278>
Question from a user: I am running a glmer() model with binomial/logit link and I assume that the smoother dash line (plot attached) should match the horizontal line at 0.50 closely so based on tha...
github.com



Best,

Hedyeh Ahmadi, Ph.D.
Statistician
Keck School of Medicine
Department of Preventive Medicine
University of Southern California

Postdoctoral Scholar
Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
University of California, Irvine

LinkedIn
www.linkedin.com/in/hedyeh-ahmadi<http://www.linkedin.com/in/hedyeh-ahmadi>
<http://www.linkedin.com/in/hedyeh-ahmadi><http://www.linkedin.com/in/hedyeh-ahmadi>




________________________________
From: John Maindonald <john.maindonald at anu.edu.au>
Sent: Thursday, April 22, 2021 7:28 PM
To: Hedyeh Ahmadi <hedyehah at usc.edu>
Cc: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Binomial glmer(): appropriateness of link and influential points

My comments, which were a bit off the cuff without looking at your queries
with all the care that was desirable, were designed to highlight issues with
binomial models.  Also, for checking purposes you want to plot partial
residuals against explanatory variables in turn.  As Ben suggests, plots
using DHARMa can be a good way to go.

Alternatives to fitting a mixed model are, in your case? a model with quasibinomial
error, or a betabinomial. A betabinomial using glmmTMB allows you to model the
scale parameter.  Those sorts of abilities are also available (and plots of  simulated
quantile residuals) in the gamlss package.  Which model is more appropriate will
depend on how the within subject component of variance (for the mixed model),
or the scale parameter varies (if at all) with the fitted value.

It is worth checking these alternatives.

John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>



On 23/04/2021, at 14:02, Hedyeh Ahmadi <hedyehah at usc.edu<mailto:hedyehah at usc.edu>> wrote:

Thank you for the DHARMa suggestion - I tried it but I am not sure how to interpret the plot from simulateResiduals(). I am getting the attached plot and I think this is pretty linear so is this a pass?

Best,

Hedyeh Ahmadi, Ph.D.
Statistician
Keck School of Medicine
Department of Preventive Medicine
University of Southern California

Postdoctoral Scholar
Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
University of California, Irvine

LinkedIn
www.linkedin.com/in/hedyeh-ahmadi<https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5KfXejPjZb_lpyQ6g97ZfJyFoqqsuFjs9k13wzQPH-Pxdh9sD0U1bIR2PprpMiw$><http://www.linkedin.com/in/hedyeh-ahmadi<https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5KfXejPjZb_lpyQ6g97ZfJyFoqqsuFjs9k13wzQPH-Pxdh9sD0U1bIR2PprpMiw$>>
<http://www.linkedin.com/in/hedyeh-ahmadi<https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5KfXejPjZb_lpyQ6g97ZfJyFoqqsuFjs9k13wzQPH-Pxdh9sD0U1bIR2PprpMiw$>><http://www.linkedin.com/in/hedyeh-ahmadi<https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5KfXejPjZb_lpyQ6g97ZfJyFoqqsuFjs9k13wzQPH-Pxdh9sD0U1bIR2PprpMiw$>>




________________________________
From: Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com>>
Sent: Thursday, April 22, 2021 6:21 PM
To: Hedyeh Ahmadi <hedyehah at usc.edu<mailto:hedyehah at usc.edu>>; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org> <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: Re: [R-sig-ME] Binomial glmer(): appropriateness of link and influential points



On 4/22/21 11:45 AM, Hedyeh Ahmadi wrote:
Thank you for the quick and informative reply.

1.   I was aware of using plot(fitted_model, type=c("p", "smooth")),
   but I wasn't sure this would be helpful with 0/1 outcome since the
   plot would be just two separate lines as follows - So do you think
   this technique is still appropriate?

 Try the DHARMa package, which uses simulated quantile residuals to
overcome this problem.




2. Yes, I have tried influence.merMod() and it takes way too long. So
   Cook's distance is still sppropriate for glmer() with binomial link?

  I would think so (to be honest, most of the advice about model
diagnostics is based on "this works for linear models and should work,
at least asymptotically, for GLM(M)s as well"


Best,

Hedyeh Ahmadi, Ph.D.
Statistician
Keck School of Medicine
Department of Preventive Medicine
University of Southern California

Postdoctoral Scholar
Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
University of California, Irvine

LinkedIn
https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7QzlJJ_apo0pfWsUyEQlBrvMwqxWXGwahNKQpyo9GM_AF8G8NAH4uDccjDXxfZA$ <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7QzlJJ_apo0pfWsUyEQlBrvMwqxWXGwahNKQpyo9GM_AF8G8NAH4uDccjDXxfZA$ >
<https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7QzlJJ_apo0pfWsUyEQlBrvMwqxWXGwahNKQpyo9GM_AF8G8NAH4uDccjDXxfZA$ ><https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7QzlJJ_apo0pfWsUyEQlBrvMwqxWXGwahNKQpyo9GM_AF8G8NAH4uDccjDXxfZA$ >




------------------------------------------------------------------------
*From:* R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>> on
behalf of Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com>>
*Sent:* Thursday, April 22, 2021 8:21 AM
*To:* r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org> <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
*Subject:* Re: [R-sig-ME] Binomial glmer(): appropriateness of link and
influential points


On 4/22/21 11:12 AM, Hedyeh Ahmadi wrote:
Hello all,
I have two questions regarding GLMM with binomial/logit link. Here are some information about my model/data before I ask my questions:

  *   My outcome is 0/1.
  *   I have continuous and categorical predictor.
  *   My data has 19000 rows with 2 observations per subject.
  *   My model only has one random intercept for each subject.
  *   I am using glmer() command in R.

My questions are as follows and any sample R code would be appreciated:

  1.  What's the best way to evaluate the appropriateness of my link function?
  2.  What's the best way to find influential points? Can I still use Cook's distance?
     *   If yes, with what package?
     *   What would be the rule of thumb for glmer() with binomial link for Cook's distance?


   An inappropriate link function will lead to nonlinearity of the
response on the linear-predictor scale, so the first thing to check is
the fitted vs. residual plot (with a smoothed line added so you can see
the trends): either

plot(fitted_model, type=c("p", "smooth"))

(maybe include pch="." since your data set is big)

or the analog via ggplot+broom.mixed: use broom.mixed::augment() to get
a data frame including .fitted and .resid, then plot it with
geom_point() and geom_smooth().

   There are "goodness-of-link" tests that might be generalizable to
GLMMs, but I'm not too familiar with them.

   2. There is an influence.merMod method for GLMM fits (it may be slow
for large data sets! You may want to set ncores>1). The 'car' package
has some additional functionality for plotting etc.

   I'm not sure about rules of thumb.

   If you are going to fit a mixed model with two binary observations
per cluster, you will be far from the range where PQL/Laplace/etc. are
going to be applicable; sonsider using nAGQ>1 to fit with Gauss-Hermite
quadrature.

Thank you in advance for your time.

Best,

Hedyeh Ahmadi, Ph.D.
Applied Statistician
Keck School of Medicine
Department of Preventive Medicine
University of Southern California

Postdoctoral Scholar
Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
University of California, Irvine

LinkedIn
https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4cS-_Nus$
<https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4cS-_Nus$>
<https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4cS-_Nus$

<https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4cS-_Nus$
<https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4cS-_Nus$ >





      [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4m9HDgYw$
<https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4m9HDgYw$>



_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4m9HDgYw$
<https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5CAcAPB0aDcXfMTpzFhHXeJ2eDwVdhX2DJEP5cx9Y_4GNT5qtAwjVCB4m9HDgYw$%3E

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5KfXejPjZb_lpyQ6g97ZfJyFoqqsuFjs9k13wzQPH-Pxdh9sD0U1bIR2P7L_tEk$>


	[[alternative HTML version deleted]]


From cm|o500 @end|ng |rom york@@c@uk  Mon Apr 26 18:24:50 2021
From: cm|o500 @end|ng |rom york@@c@uk (=?UTF-8?Q?C=C3=A1tia_Ferreira_De_Oliveira?=)
Date: Mon, 26 Apr 2021 17:24:50 +0100
Subject: [R-sig-ME] glmer and influence.me - complaining about nAGQ==0
In-Reply-To: <mailman.19131.684.1619453169.1227.r-sig-mixed-models@r-project.org>
References: <mailman.19131.684.1619453169.1227.r-sig-mixed-models@r-project.org>
Message-ID: <CACw+Tfd_s9HKfBNushVtmhWg2=i14yf0QJF1MWuNg8MAAuSgwA@mail.gmail.com>

Thank you for your replies!

Regarding your comment about having logRT in a gamma model with log link, I
decided to try it after getting this warning if I only use RT as the
dependent variable:
(glmer(RT ~ ...)





*optimizer (bobyqa) convergence code: 0 (OK)Model failed to converge with
max|grad| = 0.00209134 (tol = 0.002, component 1)Model is nearly
unidentifiable: very large eigenvalue - Rescale variables?*

Do you have a better suggestion for dealing with this that does not require
the log transformation and that may allow me to use the influence.me
package?

Best wishes,

Catia

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Mon Apr 26 19:55:11 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 26 Apr 2021 13:55:11 -0400
Subject: [R-sig-ME] glmer and influence.me - complaining about nAGQ==0
In-Reply-To: <CACw+Tfd_s9HKfBNushVtmhWg2=i14yf0QJF1MWuNg8MAAuSgwA@mail.gmail.com>
References: <mailman.19131.684.1619453169.1227.r-sig-mixed-models@r-project.org>
 <CACw+Tfd_s9HKfBNushVtmhWg2=i14yf0QJF1MWuNg8MAAuSgwA@mail.gmail.com>
Message-ID: <b515aefb-0bff-d27d-75eb-ff12f4069e42@gmail.com>


   These convergence warnings are not necessarily problematic (see 
?lme4::convergence, for example). In particular, the overly large max 
|grad| is only slightly above the threshold (and, these computations can 
be *less* reliable for very large data sets); the large eigenvalue is 
similarly just a warning, not necessarily a problem.

   Do model diagnostics (e.g. with DHARMa) generally look OK?  You can 
try allFit() if you have some patience.

   The main thing I would do is think carefully/inspect model 
predictions to see whether you think RT is the more appropriate scale.



On 4/26/21 12:24 PM, C?tia Ferreira De Oliveira via R-sig-mixed-models 
wrote:
> Thank you for your replies!
> 
> Regarding your comment about having logRT in a gamma model with log link, I
> decided to try it after getting this warning if I only use RT as the
> dependent variable:
> (glmer(RT ~ ...)
> 
> 
> 
> 
> 
> *optimizer (bobyqa) convergence code: 0 (OK)Model failed to converge with
> max|grad| = 0.00209134 (tol = 0.002, component 1)Model is nearly
> unidentifiable: very large eigenvalue - Rescale variables?*
> 
> Do you have a better suggestion for dealing with this that does not require
> the log transformation and that may allow me to use the influence.me
> package?
> 
> Best wishes,
> 
> Catia
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From b@t|c @end|ng |rom |eed@@@c@uk  Wed Apr 28 00:28:20 2021
From: b@t|c @end|ng |rom |eed@@@c@uk (Tara Cox [RPG])
Date: Tue, 27 Apr 2021 22:28:20 +0000
Subject: [R-sig-ME] Bivariate MCMCglmm - single value threshold response
 variable
In-Reply-To: <4254f651-7026-d1c0-6f8c-5b56768652e6@ed.ac.uk>
References: <AM6PR0302MB33350C4355582476FBC6E301F7789@AM6PR0302MB3335.eurprd03.prod.outlook.com>
 <4fbcc8dd-00a3-b86c-96b5-292e9267c2da@ed.ac.uk>
 <AM6PR0302MB3335CF9C3845E846DB063C8BF7499@AM6PR0302MB3335.eurprd03.prod.outlook.com>,
 <4254f651-7026-d1c0-6f8c-5b56768652e6@ed.ac.uk>
Message-ID: <AM6PR0302MB33358E46BF723423A1A825D9F7429@AM6PR0302MB3335.eurprd03.prod.outlook.com>

Hi Jarrod,

Below is a table detailing the number of individuals in my dataset and how many assays exists per individual for trait X. For the model I'd mentioned failing in my previous email, trait Y is decision to disperse Y/N (rather than survival):

Table showing the number of individuals that possess 1, 2, 3, 4, 5 or 6 assays for trait X.

Assay number
Total individuals
Total assays
1
2
3
4
5
6
Philopatric
15
2
1
0
0
0
18
22
Disperse
154
85
21
8
4
3
275
457
ALL
169
87
22
8
4
3
293
479









I assume the poor convergence is due to the small sample sizes for philopatric birds, but I was hoping there may be something that can be done. The model summary:


##  Iterations = 60001:2199501
##  Thinning interval  = 500
##  Sample size  = 4280
##
##  DIC: 2962.032
##
##  G-structure:  ~us(at.level(variable, "X")):ObserverID
##
##                                                            post.mean l-95% CI
## at.level(variable, "X"):at.level(variable, "X").ObserverID    0.2269  0.06213
##                                                            u-95% CI eff.samp
## at.level(variable, "X"):at.level(variable, "X").ObserverID   0.4546     4280
##
##                ~us(at.level(variable, "X")):BirdID
##
##  G-R structure below
##
##  R-structure:  ~us(at.level(variable, "DISP")):BirdID
##
##                                                                     post.mean
## at.level(variable, "X").BirdID:at.level(variable, "X").BirdID          0.2458
## at.level(variable, "DISP").BirdID:at.level(variable, "X").BirdID      -0.0168
## at.level(variable, "X").BirdID:at.level(variable, "DISP").BirdID      -0.0168
## at.level(variable, "DISP").BirdID:at.level(variable, "DISP").BirdID    1.0000
##                                                                       l-95% CI
## at.level(variable, "X").BirdID:at.level(variable, "X").BirdID        0.0005161
## at.level(variable, "DISP").BirdID:at.level(variable, "X").BirdID    -0.3445199
## at.level(variable, "X").BirdID:at.level(variable, "DISP").BirdID    -0.3445199
## at.level(variable, "DISP").BirdID:at.level(variable, "DISP").BirdID  1.0000000
##                                                                     u-95% CI
## at.level(variable, "X").BirdID:at.level(variable, "X").BirdID         0.5498
## at.level(variable, "DISP").BirdID:at.level(variable, "X").BirdID      0.3423
## at.level(variable, "X").BirdID:at.level(variable, "DISP").BirdID      0.3423
## at.level(variable, "DISP").BirdID:at.level(variable, "DISP").BirdID   1.0000
##                                                                     eff.samp
## at.level(variable, "X").BirdID:at.level(variable, "X").BirdID           1069
## at.level(variable, "DISP").BirdID:at.level(variable, "X").BirdID        1338
## at.level(variable, "X").BirdID:at.level(variable, "DISP").BirdID        1338
## at.level(variable, "DISP").BirdID:at.level(variable, "DISP").BirdID        0
##
##                ~idh(at.level(variable, "X")):units
##
##                               post.mean l-95% CI u-95% CI eff.samp
## at.level(variable, "X").units     1.164   0.8185    1.505     1244
##
##  Location effects: X.DISP.stack ~ variable - 1 + variable:Sex + at.level(variable, "X"):Age + at.level(variable, "X"):Age2 + at.level(variable, "X"):TentColour + at.level(variable, "X"):BranchOrientation + at.level(variable, "X"):BranchHeight + at.level(variable, "X"):TentPoles + at.level(variable, "X"):Assay.number + at.level(variable, "DISP"):PopulationDensity + at.level(variable, "DISP"):LocalPopDensity + at.level(variable, "DISP"):FoodAbundance
##
##                                              post.mean  l-95% CI  u-95% CI
## variableX                                     1.551577  1.156333  1.920005
## variableDISP                                  2.012833  1.523589  2.491882
## variableX:Sex1                                0.246286  0.002812  0.499340
## variableDISP:Sex1                             0.438481 -0.138548  0.964070
## at.level(variable, "X"):Age                   1.520044  0.795296  2.274839
## at.level(variable, "X"):Age2                 -0.940711 -1.640312 -0.212713
## at.level(variable, "X"):TentColourG          -0.522777 -0.880206 -0.168102
## at.level(variable, "X"):BranchOrientationP    0.266240 -0.045538  0.568197
## at.level(variable, "X"):BranchHeight1        -0.172651 -1.449845  1.128834
## at.level(variable, "X"):TentPoles1           -0.734384 -2.094550  0.526492
## at.level(variable, "X"):Assay.number          0.419480  0.297508  0.561766
## at.level(variable, "DISP"):PopulationDensity  0.508142  0.195178  0.799767
## at.level(variable, "DISP"):LocalPopDensity   -0.350103 -0.582710 -0.092236
## at.level(variable, "DISP"):FoodAbundance      1.224312  0.412853  1.949664
##                                              eff.samp    pMCMC
## variableX                                        4280  < 2e-04 ***
## variableDISP                                     3946  < 2e-04 ***
## variableX:Sex1                                   4059 0.052336 .
## variableDISP:Sex1                                4280 0.112150
## at.level(variable, "X"):Age                      3982  < 2e-04 ***
## at.level(variable, "X"):Age2                     4039 0.013084 *
## at.level(variable, "X"):TentColourG              4280 0.004206 **
## at.level(variable, "X"):BranchOrientationP       4280 0.096729 .
## at.level(variable, "X"):BranchHeight1            4051 0.772430
## at.level(variable, "X"):TentPoles1               3517 0.273832
## at.level(variable, "X"):Assay.number             4280  < 2e-04 ***
## at.level(variable, "DISP"):PopulationDensity     4070  < 2e-04 ***
## at.level(variable, "DISP"):LocalPopDensity       4280 0.005140 **
## at.level(variable, "DISP"):FoodAbundance         3493 0.000467 ***


Best wishes,
Tara



Tara Cox

Pronouns: she, her, hers

PhD researcher

Dugdale group, School of Biology

Faculty of Biological Sciences

University of Leeds


________________________________
From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
Sent: 20 April 2021 08:39
To: Tara Cox [RPG] <bstlc at leeds.ac.uk>; r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Bivariate MCMCglmm - single value threshold response variable


Hi,


It's hard to diagnose without the full code and summary of the output. Could you also give some indication of the sample sizes and data structure?


Cheers,


Jarrod

On 19/04/2021 22:51, Tara Cox [RPG] wrote:
This email was sent to you by someone outside the University.
You should only click on links or attachments if you are certain that the email is genuine and the content is safe.
Hi Jarrod,

Thanks for getting back to me!

I've been attempting to run my models with your advised priors and it has improved convergence. However, for some of my models, the trace and density of plots of variableY (i.e. survival) still show poor mixing (see attached). The heidel.diag for at.level(variable, "X").ID:at.level(variable, "Y").ID also fails. I have tried playing around with the number of iterations, thin and burnin, but haven't had any luck. Is it possible to amend the prior to assist with convergence?

Further, as my hypotheses state that phenotypic trait X affects survival, I'd like to look at correlation between the two. I had considered using the below to extract these values, but am not sure what the best method would be. Would you be able to give any advice?

corr.calc <- model2$VCV[,"traitY:traitX.ID"]/(sqrt(model2$VCV[,"traitY:traitY.ID"])*sqrt(model2$VCV[,"traitX:traitX.ID"]))

Best wishes,
Tara

________________________________
From: Jarrod Hadfield <j.hadfield at ed.ac.uk><mailto:j.hadfield at ed.ac.uk>
Sent: 08 April 2021 14:28
To: Tara Cox [RPG] <bstlc at leeds.ac.uk><mailto:bstlc at leeds.ac.uk>; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org> <r-sig-mixed-models at r-project.org><mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Bivariate MCMCglmm - single value threshold response variable

Hi Tara,

Your second model is correct. You can ignore the warning (not an error)
that some fixed effects have been removed; often when you set up
equations involving at.level, base R's model.matrix will not
automatically delete extra parameters and so MCMCglmm checks up on this.

The model is not mixing because you are trying to estimate the residual
variance for the binary trait and this is not identifiable in the
likelihood. You should fix it at one which results in a probit model. To
do this have fix=2 when specifying the prior for R1.

Also, make sure you are using the latest version of MCMCglmm as there
was a bug with covu models thatmay be triggered under certain
circumstances and this has now been fixed.

Cheers,

Jarrod


On 08/04/2021 12:02, Tara Cox [RPG] wrote:
> This email was sent to you by someone outside the University.
> You should only click on links or attachments if you are certain that the email is genuine and the content is safe.
>
> Dear list,
>
> I am stuck attempting to run a bivariate MCMCglmm that uses response variables phenotypic trait 'x' and survival (yes/no) (hereafter referred to as 'x' and 'y', modelled Poisson and threshold, respectively). I have multiple repeats per individual for x, but a single value for y. From my research, there are two options for running this analysis:
>
> 1) As trait y possesses a single value per individual, there is no within-individual variance and so I fix the variance to 0.0001 in my prior, as per below:
>
> prior.chi = list(R = list(V = diag(c(1, 0.0001), 2, 2), nu = 2, fix=2),
>                           G = list(G1 = list(V = diag(2), nu = 1000, alpha.mu = c(0,0), alpha.V = diag(c(1, 1)),   #chi squared as this random effect (AnimalID) is specified to both response variables
>                                        G2 = list(V = diag(1), nu = 1,  alpha.mu = 0, alpha.V = diag(1000,1))))             #parameter expanded as this random effect (ObserverID) is specified only to response variable x, which is Poisson
>
> model1 <- MCMCglmm(cbind(x, y) ~ trait-1 +
>                            trait:Sex +
>                            at.level(trait,1):Age +
>                            at.level(trait,1):Age2 +
>                            at.level(trait,2):PopulationDensity +
>                            at.level(trait,2):LocalPopulationDensity +
>                            at.level(trait,2):FoodAbundance
>                          random =~ us(trait):AnimalID + idh(at.level(trait,1)):ObserverID,
>                          rcov =~ idh(trait):units,
>                          family = c("poisson","threshold"),
>                          prior = prior.chi,
>                          nitt=2250000,
>                          burnin=150000,
>                          thin=525,
>                          verbose = FALSE,
>                          pr=FALSE,
>                          data = data)
>
> 2) Use the stacked data/'covu' approach, where I get rid of the ID term for the threshold variable, and allow a covariance between the threshold residual and the Poisson ID term (as per supplementary material in Thomson et al. 2017: https://doi.org/10.1111%2Fevo.13169):
>
> prior.covu <- list(G = list(G1 = list(V = diag(1), nu = 1)),                                   # rand effect for ObserverID (fitted for x)
>                                R = list(R1 = list(V = diag(2), nu = 0.002, covu = TRUE),     # 2-way var-cov matrix of AnimalID for x, residual for y
>                                             R2 = list(V = diag(1), nu = 0.002)))                            # residual for x
>
> model2 <- MCMCglmm(x.y.data.stack ~ variable - 1 +
>                          trait:Sex +
>                            at.level(variable, "x"):Age
>                            at.level(variable, "x"):Age2 +
>                            at.level(variable, "y"):PopulationDensity +
>                            at.level(variable, "y"):LocalPopulationDensity +
>                            at.level(variable, "y"):FoodAbundance,
>                          random = ~ us(at.level(variable,"x")):ObserverID + us(at.level(variable, "x")):AnimalID,
>                          rcov = ~us(at.level(variable, "y")):AnimalID + idh(at.level(variable, "x")):units,
>                          family = NULL,            #specified already in the data
>                          prior = prior.covu,
>                          nitt=2250000,
>                          burnin=150000,
>                          thin=525,
>                          verbose = FALSE,
>                          pr=FALSE,
>                          data = data)
>
> My problem is that I cannot get my models for either method to run successfully.
>
> The convergence model 1 is poor, with trace+density plots showing poor mixing. I know that the method is viable, as I have successfully run multiple models without convergence issues using a full parameter expanded prior alongside Poisson and gaussian response variables. Therefore, I must be specifying my chi squared prior incorrectly. I've tried to read further into how to amend the prior, but I've reached my limit of understanding and keep getting stuck.
>
> When running model 2, I receive an error message stating some fixed effects are not estimable and have been removed, and that I should use an informative prior. I've tried specifying a parameter expanded prior by modifying the G structure to include 'alpha.mu = 0' and 'alpha.V = diag(1000,1)', but this doesn't help. When running the model with a single fixed effect (e.g. Age), I do not receive any error messages, but the model shows poor mixing.
>
> If anyone could provide any insight into which method might be better suited to my analysis, or how to improve the priors for either model, it would be much appreciated!
>
> Thanks a lot.
>
> Best wishes,
> Tara
>
>
>
>
>          [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
The University of Edinburgh is a charitable body, registered in Scotland, with registration number SC005336. Is e buidheann carthannais a th? ann an Oilthigh Dh?n ?ideann, cl?raichte an Alba, ?ireamh cl?raidh SC005336.

	[[alternative HTML version deleted]]


From hedyeh@h @end|ng |rom u@c@edu  Fri Apr 30 20:51:20 2021
From: hedyeh@h @end|ng |rom u@c@edu (Hedyeh Ahmadi)
Date: Fri, 30 Apr 2021 18:51:20 +0000
Subject: [R-sig-ME] lmer()/glmer() data formatting question
Message-ID: <BYAPR07MB50947AB4C69D62E0564DF2B2D15E9@BYAPR07MB5094.namprd07.prod.outlook.com>

Hi All,
I am having a basic question about data formatting for lmer()/glmer() that I think I know the answer, but I would appreciate it if you could confirm my understanding.

In the lmer() world, we have either time-varying or time-invariant predictors. When we format the data, we need to have it in long format. In long data format we have the following:

  *   Time-varying predictors will change for each time point (i.e. each row).
  *   Time-invariant predictors will stay the same for all time points.

My question: If I want to adjust for a baseline predictor then the format for this variable should be the same as time-invariant predictor (i.e. same value for all time points) - is that correct?

Thank you in advance for your time!

Best,

Hedyeh Ahmadi, Ph.D.
Applied Statistician
Keck School of Medicine
Department of Preventive Medicine
University of Southern California

Postdoctoral Scholar
Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
University of California, Irvine

LinkedIn
www.linkedin.com/in/hedyeh-ahmadi<http://www.linkedin.com/in/hedyeh-ahmadi>
<http://www.linkedin.com/in/hedyeh-ahmadi><http://www.linkedin.com/in/hedyeh-ahmadi>





	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Fri Apr 30 21:15:51 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 30 Apr 2021 15:15:51 -0400
Subject: [R-sig-ME] lmer()/glmer() data formatting question
In-Reply-To: <BYAPR07MB50947AB4C69D62E0564DF2B2D15E9@BYAPR07MB5094.namprd07.prod.outlook.com>
References: <BYAPR07MB50947AB4C69D62E0564DF2B2D15E9@BYAPR07MB5094.namprd07.prod.outlook.com>
Message-ID: <9a5959b9-4a7f-ea8b-8ff4-ceb1af26d2a2@gmail.com>

  Yes, the value of the predictor for each observation should be the 
value relevant to that observation.  E.g. if subect 17 has a baseline 
value of 14.2, that value should be repeated for all of the observations 
pertaining to that subject.

   Requiring the data to be in long format makes implementation *much* 
easier, although I have sometimes mused about the possibility of 
implementing modeling machinery that takes relational tables rather than 
a single data frame as input ... (Is anyone aware of such a modeling 
system, specifically one that handles designs of more-or-less arbitrary 
complexity?)

  There is a package for handling multi-tables in R 
(https://rdrr.io/github/stevencarlislewalker/multitable/man/multitable-package.html), 
but it doesn't do anything clever/efficient in a mixed-model context, 
just allows the coercion to long format to happen automatically ...

On 4/30/21 2:51 PM, Hedyeh Ahmadi wrote:
> Hi All,
> I am having a basic question about data formatting for lmer()/glmer() that I think I know the answer, but I would appreciate it if you could confirm my understanding.
> 
> In the lmer() world, we have either time-varying or time-invariant predictors. When we format the data, we need to have it in long format. In long data format we have the following:
> 
>    *   Time-varying predictors will change for each time point (i.e. each row).
>    *   Time-invariant predictors will stay the same for all time points.
> 
> My question: If I want to adjust for a baseline predictor then the format for this variable should be the same as time-invariant predictor (i.e. same value for all time points) - is that correct?
> 
> Thank you in advance for your time!
> 
> Best,
> 
> Hedyeh Ahmadi, Ph.D.
> Applied Statistician
> Keck School of Medicine
> Department of Preventive Medicine
> University of Southern California
> 
> Postdoctoral Scholar
> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
> University of California, Irvine
> 
> LinkedIn
> www.linkedin.com/in/hedyeh-ahmadi<http://www.linkedin.com/in/hedyeh-ahmadi>
> <http://www.linkedin.com/in/hedyeh-ahmadi><http://www.linkedin.com/in/hedyeh-ahmadi>
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From cm|o500 @end|ng |rom york@@c@uk  Mon May  3 19:20:47 2021
From: cm|o500 @end|ng |rom york@@c@uk (=?UTF-8?Q?C=C3=A1tia_Ferreira_De_Oliveira?=)
Date: Mon, 3 May 2021 18:20:47 +0100
Subject: [R-sig-ME] glmer and influence.me - complaining about nAGQ==0
In-Reply-To: <mailman.19134.7.1619517602.39789.r-sig-mixed-models@r-project.org>
References: <mailman.19134.7.1619517602.39789.r-sig-mixed-models@r-project.org>
Message-ID: <CACw+TfeXT69tbbri5yOWwBAtJy4i_rmawzRxMqi4ZWXZTMuyYw@mail.gmail.com>

Dear Professor Bolker,

Thank you for your comment. I haven't been able to find this information
anywhere, but just wanted to check something you said, is the "(tol =
0.002, component 1)" the threshold you referred to?

optimizer (bobyqa) convergence code: 0 (OK)Model failed to converge with
max|grad| = 0.00209134 (tol = 0.002, component 1)

Also, if I run the model without the logRT I will still need to use
the nAGQ==0 right?

Best wishes,

Catia

On Tue, 27 Apr 2021 at 11:01, <r-sig-mixed-models-request at r-project.org>
wrote:

> Send R-sig-mixed-models mailing list submissions to
>         r-sig-mixed-models at r-project.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
>         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help' to
>         r-sig-mixed-models-request at r-project.org
>
> You can reach the person managing the list at
>         r-sig-mixed-models-owner at r-project.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-sig-mixed-models digest..."
>
>
> Today's Topics:
>
>    1. Re: glmer and influence.me - complaining about nAGQ==0
>       (=?UTF-8?Q?C=C3=A1tia_Ferreira_De_Oliveira?=)
>    2. Re: glmer and influence.me - complaining about nAGQ==0
>       (Ben Bolker)
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Mon, 26 Apr 2021 17:24:50 +0100
> From: =?UTF-8?Q?C=C3=A1tia_Ferreira_De_Oliveira?= <cmfo500 at york.ac.uk>
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] glmer and influence.me - complaining about
>         nAGQ==0
> Message-ID:
>         <CACw+Tfd_s9HKfBNushVtmhWg2=
> i14yf0QJF1MWuNg8MAAuSgwA at mail.gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
> Thank you for your replies!
>
> Regarding your comment about having logRT in a gamma model with log link, I
> decided to try it after getting this warning if I only use RT as the
> dependent variable:
> (glmer(RT ~ ...)
>
>
>
>
>
> *optimizer (bobyqa) convergence code: 0 (OK)Model failed to converge with
> max|grad| = 0.00209134 (tol = 0.002, component 1)Model is nearly
> unidentifiable: very large eigenvalue - Rescale variables?*
>
> Do you have a better suggestion for dealing with this that does not require
> the log transformation and that may allow me to use the influence.me
> package?
>
> Best wishes,
>
> Catia
>
>         [[alternative HTML version deleted]]
>
>
>
>
> ------------------------------
>
> Message: 2
> Date: Mon, 26 Apr 2021 13:55:11 -0400
> From: Ben Bolker <bbolker at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] glmer and influence.me - complaining about
>         nAGQ==0
> Message-ID: <b515aefb-0bff-d27d-75eb-ff12f4069e42 at gmail.com>
> Content-Type: text/plain; charset="utf-8"; Format="flowed"
>
>
>    These convergence warnings are not necessarily problematic (see
> ?lme4::convergence, for example). In particular, the overly large max
> |grad| is only slightly above the threshold (and, these computations can
> be *less* reliable for very large data sets); the large eigenvalue is
> similarly just a warning, not necessarily a problem.
>
>    Do model diagnostics (e.g. with DHARMa) generally look OK?  You can
> try allFit() if you have some patience.
>
>    The main thing I would do is think carefully/inspect model
> predictions to see whether you think RT is the more appropriate scale.
>
>
>
> On 4/26/21 12:24 PM, C?tia Ferreira De Oliveira via R-sig-mixed-models
> wrote:
> > Thank you for your replies!
> >
> > Regarding your comment about having logRT in a gamma model with log
> link, I
> > decided to try it after getting this warning if I only use RT as the
> > dependent variable:
> > (glmer(RT ~ ...)
> >
> >
> >
> >
> >
> > *optimizer (bobyqa) convergence code: 0 (OK)Model failed to converge with
> > max|grad| = 0.00209134 (tol = 0.002, component 1)Model is nearly
> > unidentifiable: very large eigenvalue - Rescale variables?*
> >
> > Do you have a better suggestion for dealing with this that does not
> require
> > the log transformation and that may allow me to use the influence.me
> > package?
> >
> > Best wishes,
> >
> > Catia
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>
>
>
> ------------------------------
>
> Subject: Digest Footer
>
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> ------------------------------
>
> End of R-sig-mixed-models Digest, Vol 172, Issue 27
> ***************************************************



-- 
C?tia Margarida Ferreira de Oliveira
Psychology PhD Student
Department of Psychology, Room B214
University of York, YO10 5DD

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Mon May  3 20:26:54 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 3 May 2021 14:26:54 -0400
Subject: [R-sig-ME] glmer and influence.me - complaining about nAGQ==0
In-Reply-To: <CACw+TfeXT69tbbri5yOWwBAtJy4i_rmawzRxMqi4ZWXZTMuyYw@mail.gmail.com>
References: <mailman.19134.7.1619517602.39789.r-sig-mixed-models@r-project.org>
 <CACw+TfeXT69tbbri5yOWwBAtJy4i_rmawzRxMqi4ZWXZTMuyYw@mail.gmail.com>
Message-ID: <3c595852-1d30-d6fb-c145-fb8d624a0046@gmail.com>



On 5/3/21 1:20 PM, C?tia Ferreira De Oliveira via R-sig-mixed-models wrote:
> Dear Professor Bolker,
> 
> Thank you for your comment. I haven't been able to find this information
> anywhere, but just wanted to check something you said, is the "(tol =
> 0.002, component 1)" the threshold you referred to?

   Yes.  I was comparing the max|grad| value of 0.00209 with the 
tolerance of 0.002.  This tolerance can be adjusted in ?glmerControl 
(e.g. glmerControl(check.conv.grad = .makeCC(tol=3e-3)) )

> 
> optimizer (bobyqa) convergence code: 0 (OK)Model failed to converge with
> max|grad| = 0.00209134 (tol = 0.002, component 1)
> 
> Also, if I run the model without the logRT I will still need to use
> the nAGQ==0 right?

    I don't know.  Hopefully it will work better and you'll be able to 
use the default Laplace approx (nAGQ=1) setting

> 
> Best wishes,
> 
> Catia
> 
> On Tue, 27 Apr 2021 at 11:01, <r-sig-mixed-models-request at r-project.org>
> wrote:
> 
>> Send R-sig-mixed-models mailing list submissions to
>>          r-sig-mixed-models at r-project.org
>>
>> To subscribe or unsubscribe via the World Wide Web, visit
>>          https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> or, via email, send a message with subject or body 'help' to
>>          r-sig-mixed-models-request at r-project.org
>>
>> You can reach the person managing the list at
>>          r-sig-mixed-models-owner at r-project.org
>>
>> When replying, please edit your Subject line so it is more specific
>> than "Re: Contents of R-sig-mixed-models digest..."
>>
>>
>> Today's Topics:
>>
>>     1. Re: glmer and influence.me - complaining about nAGQ==0
>>        (=?UTF-8?Q?C=C3=A1tia_Ferreira_De_Oliveira?=)
>>     2. Re: glmer and influence.me - complaining about nAGQ==0
>>        (Ben Bolker)
>>
>> ----------------------------------------------------------------------
>>
>> Message: 1
>> Date: Mon, 26 Apr 2021 17:24:50 +0100
>> From: =?UTF-8?Q?C=C3=A1tia_Ferreira_De_Oliveira?= <cmfo500 at york.ac.uk>
>> To: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] glmer and influence.me - complaining about
>>          nAGQ==0
>> Message-ID:
>>          <CACw+Tfd_s9HKfBNushVtmhWg2=
>> i14yf0QJF1MWuNg8MAAuSgwA at mail.gmail.com>
>> Content-Type: text/plain; charset="utf-8"
>>
>> Thank you for your replies!
>>
>> Regarding your comment about having logRT in a gamma model with log link, I
>> decided to try it after getting this warning if I only use RT as the
>> dependent variable:
>> (glmer(RT ~ ...)
>>
>>
>>
>>
>>
>> *optimizer (bobyqa) convergence code: 0 (OK)Model failed to converge with
>> max|grad| = 0.00209134 (tol = 0.002, component 1)Model is nearly
>> unidentifiable: very large eigenvalue - Rescale variables?*
>>
>> Do you have a better suggestion for dealing with this that does not require
>> the log transformation and that may allow me to use the influence.me
>> package?
>>
>> Best wishes,
>>
>> Catia
>>
>>          [[alternative HTML version deleted]]
>>
>>
>>
>>
>> ------------------------------
>>
>> Message: 2
>> Date: Mon, 26 Apr 2021 13:55:11 -0400
>> From: Ben Bolker <bbolker at gmail.com>
>> To: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] glmer and influence.me - complaining about
>>          nAGQ==0
>> Message-ID: <b515aefb-0bff-d27d-75eb-ff12f4069e42 at gmail.com>
>> Content-Type: text/plain; charset="utf-8"; Format="flowed"
>>
>>
>>     These convergence warnings are not necessarily problematic (see
>> ?lme4::convergence, for example). In particular, the overly large max
>> |grad| is only slightly above the threshold (and, these computations can
>> be *less* reliable for very large data sets); the large eigenvalue is
>> similarly just a warning, not necessarily a problem.
>>
>>     Do model diagnostics (e.g. with DHARMa) generally look OK?  You can
>> try allFit() if you have some patience.
>>
>>     The main thing I would do is think carefully/inspect model
>> predictions to see whether you think RT is the more appropriate scale.
>>
>>
>>
>> On 4/26/21 12:24 PM, C?tia Ferreira De Oliveira via R-sig-mixed-models
>> wrote:
>>> Thank you for your replies!
>>>
>>> Regarding your comment about having logRT in a gamma model with log
>> link, I
>>> decided to try it after getting this warning if I only use RT as the
>>> dependent variable:
>>> (glmer(RT ~ ...)
>>>
>>>
>>>
>>>
>>>
>>> *optimizer (bobyqa) convergence code: 0 (OK)Model failed to converge with
>>> max|grad| = 0.00209134 (tol = 0.002, component 1)Model is nearly
>>> unidentifiable: very large eigenvalue - Rescale variables?*
>>>
>>> Do you have a better suggestion for dealing with this that does not
>> require
>>> the log transformation and that may allow me to use the influence.me
>>> package?
>>>
>>> Best wishes,
>>>
>>> Catia
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>>
>>
>> ------------------------------
>>
>> Subject: Digest Footer
>>
>> _______________________________________________
>> R-sig-mixed-models mailing list
>> R-sig-mixed-models at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>> ------------------------------
>>
>> End of R-sig-mixed-models Digest, Vol 172, Issue 27
>> ***************************************************
> 
> 
>


From ch|@r@@m@@c| @end|ng |rom po||m|@|t  Tue May  4 16:29:06 2021
From: ch|@r@@m@@c| @end|ng |rom po||m|@|t (Chiara Masci)
Date: Tue, 4 May 2021 14:29:06 +0000
Subject: [R-sig-ME] Question about random effects variance in lme4
Message-ID: <AM6PR06MB576164A666186B59BB0F274C9C5A9@AM6PR06MB5761.eurprd06.prod.outlook.com>

Good morning,

I am a researcher at the Department of Mathematics of Politecnico di Milano, Italy.
I am working in the field of parametric and non parametric mixed-effects models and I would like to ask a question about the computation of random effects in the R package lme4.


If possible, I would like to ask a clarification about the random effects variance: I understand how the conditional variances of random effects are computed and then displayed by means of ranef and dotplot functions.  What I did not get is how the condVar values in ranef are related to the random effects variance that I can read from the summary of the lmer model (or, equivalently, from the function varCorr(lmer model)). I see that, if groups have the same number of observations within them, the values of condVar are all the same, so I guess they depend somehow on the number of observations. I am missing the relation between the group- specific condiational variances and the overall variance of random effects.


Thank you very much!

Best wishes,
Chiara Masci

	[[alternative HTML version deleted]]


From me @end|ng |rom ph||||p@|d@y@com  Tue May  4 16:44:01 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Tue, 4 May 2021 16:44:01 +0200
Subject: [R-sig-ME] Question about random effects variance in lme4
In-Reply-To: <AM6PR06MB576164A666186B59BB0F274C9C5A9@AM6PR06MB5761.eurprd06.prod.outlook.com>
References: <AM6PR06MB576164A666186B59BB0F274C9C5A9@AM6PR06MB5761.eurprd06.prod.outlook.com>
Message-ID: <e3c6b07e-3eb8-cf6a-48de-878077356d2b@phillipalday.com>

The same functionality in MixedModels.jl might be easier to understand,
especially with the math included in the docstring:

https://github.com/JuliaStats/MixedModels.jl/blob/628cbf31aac13f26dee4d2e2c50a0e459508d880/src/linearmixedmodel.jl#L269-L297

There is also an update in progress to allow it to work on more
complicated random effects:

https://github.com/JuliaStats/MixedModels.jl/pull/492/files

Phillip


On 4/5/21 4:29 pm, Chiara Masci wrote:
> Good morning,
> 
> I am a researcher at the Department of Mathematics of Politecnico di Milano, Italy.
> I am working in the field of parametric and non parametric mixed-effects models and I would like to ask a question about the computation of random effects in the R package lme4.
> 
> 
> If possible, I would like to ask a clarification about the random effects variance: I understand how the conditional variances of random effects are computed and then displayed by means of ranef and dotplot functions.  What I did not get is how the condVar values in ranef are related to the random effects variance that I can read from the summary of the lmer model (or, equivalently, from the function varCorr(lmer model)). I see that, if groups have the same number of observations within them, the values of condVar are all the same, so I guess they depend somehow on the number of observations. I am missing the relation between the group- specific condiational variances and the overall variance of random effects.
> 
> 
> Thank you very much!
> 
> Best wishes,
> Chiara Masci
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From n|ch@|@|@ @end|ng |rom hotm@||@com  Wed May  5 14:09:42 2021
From: n|ch@|@|@ @end|ng |rom hotm@||@com (ornicha anuchitchanchai)
Date: Wed, 5 May 2021 12:09:42 +0000
Subject: [R-sig-ME] compare result of ZINB model between glmmtmb and
 zeroinfl function
Message-ID: <DM6PR12MB3915C415F88601F166A254A8A2599@DM6PR12MB3915.namprd12.prod.outlook.com>

Hi,


I want to run spatial zero-inflated negative binomial regression model. So, I planned to run spatial correlation from glmtmb package but I found problems:

When running model with function zeroinfl, the model works fine


Here is my model with zeroinfl function:

zinbz <- zeroinfl(driver~zone+pop+market+depstore+religious+med+edu+res+conv+busstop+busline+rail+pier+transit+dist_sta+RL_motorway+RL_trunk+RL_primary+RL_secondary+RL_tertiary+RL_residential+RL_track+RL_footway+RL_livingstreet|pop+market+religious+med+edu+res+conv+busstop+busline+RL_motorway+RL_trunk+RL_primary+RL_secondary+RL_tertiary+RL_residential+RL_track+RL_footway+RL_livingstreet, data=wingrid, dist="negbin")


but when running with glmmTMB, I got warning:

Warning messages:
1: In fitTMB(TMBStruc) :
Model convergence problem; non-positive-definite Hessian matrix. See vignette('troubleshooting')
2: In fitTMB(TMBStruc) :
Model convergence problem; function evaluation limit reached without convergence (9). See vignette('troubleshooting')

here is my code:

zinb_glmm <- glmmTMB(driver~zone+pop+market+depstore+religious+med+edu+res+conv+busstop+busline+rail+pier+transit+dist_sta+RL_motorway+RL_trunk+RL_primary+RL_secondary+RL_tertiary+RL_residential+RL_track+RL_footway+RL_livingstreet+(1|null), zi=~pop+market+religious+med+edu+res+conv+busstop+busline+RL_motorway+RL_trunk+RL_primary+RL_secondary+RL_tertiary+RL_residential+RL_track+RL_footway+RL_livingstreet, data=wingrid, family=nbinom2)


(wingrid is my data,
null is column with value of 1 for all rows)

And I got this result:

     AIC      BIC   logLik deviance df.resid
      NA       NA       NA       NA     1535

Random effects:

Conditional model:
 Groups Name        Variance Std.Dev.
 null   (Intercept) 1.01     1.005
Number of obs: 1582, groups:  null, 1

Overdispersion parameter for nbinom2 family (): 1.02

Conditional model:
                  Estimate Std. Error z value Pr(>|z|)
(Intercept)      1.803e-03         NA      NA       NA
zonemiddle      -1.047e-02  1.062e-01  -0.099 0.921486
zoneouter        1.286e-02  1.254e-01   0.103 0.918278
pop              6.892e-05         NA      NA       NA
market           1.625e-02  7.505e-02   0.217 0.828535
depstore         2.863e-02  6.749e-02   0.424 0.671412
religious       -4.474e-03  3.638e-02  -0.123 0.902110
med              1.074e-02  2.731e-02   0.393 0.694192
edu              4.624e-03  2.955e-02   0.156 0.875670
res              3.904e-02  1.988e-02   1.964 0.049515 *
conv             4.895e-02  1.474e-02   3.320 0.000901 ***
busstop          5.870e-02  8.705e-03   6.744 1.54e-11 ***
busline          1.312e-02  1.480e-02   0.886 0.375492
rail            -2.076e-03  2.156e-01  -0.010 0.992317
pier            -8.357e-04  6.122e-02  -0.014 0.989108
transit          9.169e-03  1.333e-01   0.069 0.945176
dist_sta        -3.943e-02  6.868e-03  -5.741 9.42e-09 ***
RL_motorway      6.116e-07  1.991e-05   0.031 0.975492
RL_trunk         7.563e-05  2.669e-05   2.834 0.004603 **
RL_primary       3.558e-05  2.221e-05   1.602 0.109159
RL_secondary     9.770e-05  3.489e-05   2.800 0.005103 **
RL_tertiary      2.199e-05  2.884e-05   0.762 0.445778
RL_residential   5.639e-05  1.319e-05   4.276 1.90e-05 ***
RL_track        -1.745e-04  1.092e-04  -1.599 0.109862
RL_footway       5.313e-05  2.070e-05   2.567 0.010259 *
RL_livingstreet  1.314e-06  3.377e-05   0.039 0.968950
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Zero-inflation model:
                  Estimate Std. Error z value Pr(>|z|)
(Intercept)      6.020e-02  6.701e-02   0.898 0.368988
pop              1.177e-05  1.019e-04   0.116 0.907995
market          -4.133e-03  3.436e-01  -0.012 0.990401
religious       -1.511e-02  1.222e-01  -0.124 0.901611
med             -3.991e-02  9.085e-02  -0.439 0.660462
edu             -3.506e-02  9.395e-02  -0.373 0.709055
res             -5.044e-02  5.976e-02  -0.844 0.398597
conv            -3.881e-02  6.847e-02  -0.567 0.570848
busstop         -1.306e-01  3.946e-02  -3.310 0.000933 ***
busline         -1.364e-02  5.989e-02  -0.228 0.819842
RL_motorway     -4.707e-05  9.994e-05  -0.471 0.637641
RL_trunk         7.902e-05  1.280e-04   0.617 0.536956
RL_primary      -2.021e-04  7.746e-05  -2.609 0.009093 **
RL_secondary    -5.684e-04  1.251e-04  -4.543 5.54e-06 ***
RL_tertiary      3.062e-05  1.093e-04   0.280 0.779452
RL_residential  -3.759e-05  7.273e-06  -5.168 2.37e-07 ***
RL_track         8.114e-04  1.565e-04   5.186 2.15e-07 ***
RL_footway      -2.662e-04  1.280e-04  -2.079 0.037595 *
RL_livingstreet  6.237e-05  1.205e-04   0.518 0.604594
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
Warning message:
In sqrt(diag(vcov)) : NaNs produced


There is NA result. Also, the result is totally different from result from function zeroinf.


Regards,

nichalala



	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Fri May  7 01:33:24 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 6 May 2021 19:33:24 -0400
Subject: [R-sig-ME] compare result of ZINB model between glmmtmb and
 zeroinfl function
In-Reply-To: <DM6PR12MB3915C415F88601F166A254A8A2599@DM6PR12MB3915.namprd12.prod.outlook.com>
References: <DM6PR12MB3915C415F88601F166A254A8A2599@DM6PR12MB3915.namprd12.prod.outlook.com>
Message-ID: <4e7392c5-2226-c156-d345-86e5d5450c09@gmail.com>


   Very hard to know what's going on without a reproducible example. 
Can you provide a link to some data?


   Does the glmmTMB model perform equivalently to the zeroinfl model if 
you leave out the random effect term (so that the models should be 
*exactly* equivalent?



On 5/5/21 8:09 AM, ornicha anuchitchanchai wrote:
> Hi,
> 
> 
> I want to run spatial zero-inflated negative binomial regression model. So, I planned to run spatial correlation from glmtmb package but I found problems:
> 
> When running model with function zeroinfl, the model works fine
> 
> 
> Here is my model with zeroinfl function:
> 
> zinbz <- zeroinfl(driver~zone+pop+market+depstore+religious+med+edu+res+conv+busstop+busline+rail+pier+transit+dist_sta+RL_motorway+RL_trunk+

RL_primary+RL_secondary+RL_tertiary+RL_residential+RL_track+RL_footway+RL_livingstreet|pop+market+religious+med+edu+res+

conv+busstop+busline+RL_motorway+RL_trunk+RL_primary+RL_secondary+RL_tertiary+RL_residential+RL_track+RL_footway+RL_livingstreet, 
data=wingrid, dist="negbin")
> 
> 
> but when running with glmmTMB, I got warning:
> 
> Warning messages:
> 1: In fitTMB(TMBStruc) :
> Model convergence problem; non-positive-definite Hessian matrix. See vignette('troubleshooting')
> 2: In fitTMB(TMBStruc) :
> Model convergence problem; function evaluation limit reached without convergence (9). See vignette('troubleshooting')
> 
> here is my code:
> 
> zinb_glmm <- glmmTMB(driver~zone+pop+market+depstore+religious+med+edu+res+conv+busstop+busline+rail+pier+transit+dist_sta+RL_motorway+RL_trunk+RL_primary+RL_secondary+RL_tertiary+RL_residential+RL_track+RL_footway+RL_livingstreet+(1|null), zi=~pop+market+religious+med+edu+res+conv+busstop+busline+RL_motorway+RL_trunk+RL_primary+RL_secondary+RL_tertiary+RL_residential+RL_track+RL_footway+RL_livingstreet, data=wingrid, family=nbinom2)
> 
> 
> (wingrid is my data,
> null is column with value of 1 for all rows)
> 
> And I got this result:
> 
>       AIC      BIC   logLik deviance df.resid
>        NA       NA       NA       NA     1535
> 
> Random effects:
> 
> Conditional model:
>   Groups Name        Variance Std.Dev.
>   null   (Intercept) 1.01     1.005
> Number of obs: 1582, groups:  null, 1
> 
> Overdispersion parameter for nbinom2 family (): 1.02
> 
> Conditional model:
>                    Estimate Std. Error z value Pr(>|z|)
> (Intercept)      1.803e-03         NA      NA       NA
> zonemiddle      -1.047e-02  1.062e-01  -0.099 0.921486
> zoneouter        1.286e-02  1.254e-01   0.103 0.918278
> pop              6.892e-05         NA      NA       NA
> market           1.625e-02  7.505e-02   0.217 0.828535
> depstore         2.863e-02  6.749e-02   0.424 0.671412
> religious       -4.474e-03  3.638e-02  -0.123 0.902110
> med              1.074e-02  2.731e-02   0.393 0.694192
> edu              4.624e-03  2.955e-02   0.156 0.875670
> res              3.904e-02  1.988e-02   1.964 0.049515 *
> conv             4.895e-02  1.474e-02   3.320 0.000901 ***
> busstop          5.870e-02  8.705e-03   6.744 1.54e-11 ***
> busline          1.312e-02  1.480e-02   0.886 0.375492
> rail            -2.076e-03  2.156e-01  -0.010 0.992317
> pier            -8.357e-04  6.122e-02  -0.014 0.989108
> transit          9.169e-03  1.333e-01   0.069 0.945176
> dist_sta        -3.943e-02  6.868e-03  -5.741 9.42e-09 ***
> RL_motorway      6.116e-07  1.991e-05   0.031 0.975492
> RL_trunk         7.563e-05  2.669e-05   2.834 0.004603 **
> RL_primary       3.558e-05  2.221e-05   1.602 0.109159
> RL_secondary     9.770e-05  3.489e-05   2.800 0.005103 **
> RL_tertiary      2.199e-05  2.884e-05   0.762 0.445778
> RL_residential   5.639e-05  1.319e-05   4.276 1.90e-05 ***
> RL_track        -1.745e-04  1.092e-04  -1.599 0.109862
> RL_footway       5.313e-05  2.070e-05   2.567 0.010259 *
> RL_livingstreet  1.314e-06  3.377e-05   0.039 0.968950
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Zero-inflation model:
>                    Estimate Std. Error z value Pr(>|z|)
> (Intercept)      6.020e-02  6.701e-02   0.898 0.368988
> pop              1.177e-05  1.019e-04   0.116 0.907995
> market          -4.133e-03  3.436e-01  -0.012 0.990401
> religious       -1.511e-02  1.222e-01  -0.124 0.901611
> med             -3.991e-02  9.085e-02  -0.439 0.660462
> edu             -3.506e-02  9.395e-02  -0.373 0.709055
> res             -5.044e-02  5.976e-02  -0.844 0.398597
> conv            -3.881e-02  6.847e-02  -0.567 0.570848
> busstop         -1.306e-01  3.946e-02  -3.310 0.000933 ***
> busline         -1.364e-02  5.989e-02  -0.228 0.819842
> RL_motorway     -4.707e-05  9.994e-05  -0.471 0.637641
> RL_trunk         7.902e-05  1.280e-04   0.617 0.536956
> RL_primary      -2.021e-04  7.746e-05  -2.609 0.009093 **
> RL_secondary    -5.684e-04  1.251e-04  -4.543 5.54e-06 ***
> RL_tertiary      3.062e-05  1.093e-04   0.280 0.779452
> RL_residential  -3.759e-05  7.273e-06  -5.168 2.37e-07 ***
> RL_track         8.114e-04  1.565e-04   5.186 2.15e-07 ***
> RL_footway      -2.662e-04  1.280e-04  -2.079 0.037595 *
> RL_livingstreet  6.237e-05  1.205e-04   0.518 0.604594
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> Warning message:
> In sqrt(diag(vcov)) : NaNs produced
> 
> 
> There is NA result. Also, the result is totally different from result from function zeroinf.
> 
> 
> Regards,
> 
> nichalala
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From cm|o500 @end|ng |rom york@@c@uk  Sun May  9 20:16:48 2021
From: cm|o500 @end|ng |rom york@@c@uk (=?UTF-8?Q?C=C3=A1tia_Ferreira_De_Oliveira?=)
Date: Sun, 9 May 2021 19:16:48 +0100
Subject: [R-sig-ME] glmer and influence.me - complaining about nAGQ==0
Message-ID: <CACw+Tff2BeiGOgakYUP=a58yAL0_oBGqpSW3wNS+sMg1xxbUTw@mail.gmail.com>

Dear Professor Bolker,

I am currently running the allfit function for the models I mentioned in
the previous email and I am now doing the same for another model using the
same data and this seems much worse. This is the model that seems to give
even worse fit with this value "Model failed to converge with max|grad| *=
0.167262* (tol = 0.002, component 1)" being much higher. Are there any
other suggestions I could take? This model I am running without the logRT
and the nAGQ==0.

Thank you!

## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: Gamma  ( log )
## Formula:
## RT ~ Probability * Session * Group * Age + (1 + Session *
Probability |  Participant)
##    Data: Data.trimmed
## Control: glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e+05))
##
##       AIC       BIC    logLik  deviance  df.resid
##  938050.5  938301.3 -468998.3  937996.5     79890
##
## Scaled residuals:
##    Min     1Q Median     3Q    Max
## -4.258 -0.597 -0.151  0.410 33.938
##
## Random effects:
##  Groups      Name                  Variance  Std.Dev. Corr
##  Participant (Intercept)           1.700e-03 0.041232
##              Session1              2.583e-04 0.016073  0.13
##              Probability1          1.121e-04 0.010589 -0.06  0.11
##              Session1:Probability1 6.176e-05 0.007859  0.02 -0.02 -0.02
##  Residual                          5.448e-02 0.233418
## Number of obs: 79917, groups:  Participant, 45
##
## Fixed effects:
##                                    Estimate Std. Error t value Pr(>|z|)
## (Intercept)                       5.9334448  0.0739725  80.211  < 2e-16 ***
## Probability1                     -0.0162354  0.0100753  -1.611  0.10709
## Session1                          0.0631180  0.0209673   3.010  0.00261 **
## Group1                           -0.0331517  0.0740287  -0.448  0.65428
## Age                               0.0035260  0.0023510   1.500  0.13367
## Probability1:Session1             0.0059755  0.0075507   0.791  0.42872
## Probability1:Group1               0.0060958  0.0101003   0.604  0.54616
## Session1:Group1                   0.0215458  0.0210650   1.023  0.30639
## Probability1:Age                 -0.0003351  0.0003189  -1.051  0.29331
## Session1:Age                     -0.0006021  0.0006607  -0.911  0.36220
## Group1:Age                       -0.0009086  0.0023529  -0.386  0.69938
## Probability1:Session1:Group1      0.0067270  0.0075839   0.887  0.37507
## Probability1:Session1:Age        -0.0001585  0.0002380  -0.666  0.50544
## Probability1:Group1:Age          -0.0002775  0.0003196  -0.868  0.38519
## Session1:Group1:Age              -0.0007188  0.0006636  -1.083  0.27877
## Probability1:Session1:Group1:Age -0.0001956  0.0002391  -0.818  0.41320
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

##
## Correlation matrix not shown by default, as p = 16 > 12.
## Use print(x, correlation=TRUE)  or
##     vcov(x)        if you need it

## optimizer (bobyqa) convergence code: 0 (OK)
## Model failed to converge with max|grad| = 0.167262 (tol = 0.002, component 1)
## Model is nearly unidentifiable: very large eigenvalue
##  - Rescale variables?
## Model is nearly unidentifiable: large eigenvalue ratio
##  - Rescale variables?


-- 
C?tia Margarida Ferreira de Oliveira
Psychology PhD Student
Department of Psychology, Room B214
University of York, YO10 5DD

	[[alternative HTML version deleted]]


From em@nue|e|@v@ron @end|ng |rom gm@||@com  Mon May 10 16:20:57 2021
From: em@nue|e|@v@ron @end|ng |rom gm@||@com (emanuele favaron)
Date: Mon, 10 May 2021 16:20:57 +0200
Subject: [R-sig-ME] lme4
Message-ID: <CAN6UW7savDzhDiTspTrTnZ8Rpv_V6QxRT16j-CfboRKvEKV2aw@mail.gmail.com>

Good afternoon,

I'm working on R studio Version 1.4.1625 in MacOs Big Sur 11.2.2.
Trying to load library(lme4) I get this answer:

Error: package or namespace load failed for ?lme4? in dyn.load(file,
DLLpath = DLLpath, ...):
 unable to load shared object
'/Library/Frameworks/R.framework/Versions/4.1-arm64/Resources/library/statmod/libs/statmod.so':

dlopen(/Library/Frameworks/R.framework/Versions/4.1-arm64/Resources/library/statmod/libs/statmod.so,
6): Library not loaded: /opt/R/arm64/gfortran/lib/libgfortran.5.dylib
  Referenced from:
/Library/Frameworks/R.framework/Versions/4.1-arm64/Resources/library/statmod/libs/statmod.so
  Reason: image not found


I already tried all the possible solutions suggested in some websites but
they don't work. How can I solve this problem?

Thanks in advance
Emanuele

	[[alternative HTML version deleted]]


From me @end|ng |rom ph||||p@|d@y@com  Mon May 10 17:23:23 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Mon, 10 May 2021 17:23:23 +0200
Subject: [R-sig-ME] lme4
In-Reply-To: <CAN6UW7savDzhDiTspTrTnZ8Rpv_V6QxRT16j-CfboRKvEKV2aw@mail.gmail.com>
References: <CAN6UW7savDzhDiTspTrTnZ8Rpv_V6QxRT16j-CfboRKvEKV2aw@mail.gmail.com>
Message-ID: <79f9b1f0-8a63-914f-e52e-aa612d412704@phillipalday.com>

Hi Emanuele,

It helps us a little bit if you tell us what the solutions you tried
actually were. We don't know what websites you looked at.

It looks like you're on the new Apple silicon. Unfortunately, Apple
there isn't a release of gfortran for that, which has created a lot of
problems for numerical and statistical computing. For now, I would
recommend running R for x86-64 via Rosetta.

Phillip

On 10/5/21 4:20 pm, emanuele favaron wrote:
> Good afternoon,
> 
> I'm working on R studio Version 1.4.1625 in MacOs Big Sur 11.2.2.
> Trying to load library(lme4) I get this answer:
> 
> Error: package or namespace load failed for ?lme4? in dyn.load(file,
> DLLpath = DLLpath, ...):
>  unable to load shared object
> '/Library/Frameworks/R.framework/Versions/4.1-arm64/Resources/library/statmod/libs/statmod.so':
> 
> dlopen(/Library/Frameworks/R.framework/Versions/4.1-arm64/Resources/library/statmod/libs/statmod.so,
> 6): Library not loaded: /opt/R/arm64/gfortran/lib/libgfortran.5.dylib
>   Referenced from:
> /Library/Frameworks/R.framework/Versions/4.1-arm64/Resources/library/statmod/libs/statmod.so
>   Reason: image not found
> 
> 
> I already tried all the possible solutions suggested in some websites but
> they don't work. How can I solve this problem?
> 
> Thanks in advance
> Emanuele
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From me @end|ng |rom ph||||p@|d@y@com  Mon May 10 17:43:11 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Mon, 10 May 2021 17:43:11 +0200
Subject: [R-sig-ME] lme4
In-Reply-To: <CAN6UW7vvFKNnGGYqmN_iueK3ZMNoPzQrDLic1U7LYr_y7gonUQ@mail.gmail.com>
References: <CAN6UW7savDzhDiTspTrTnZ8Rpv_V6QxRT16j-CfboRKvEKV2aw@mail.gmail.com>
 <79f9b1f0-8a63-914f-e52e-aa612d412704@phillipalday.com>
 <CAN6UW7vvFKNnGGYqmN_iueK3ZMNoPzQrDLic1U7LYr_y7gonUQ@mail.gmail.com>
Message-ID: <932a7f6c-67be-0c0f-fac2-2674a6972d4a@phillipalday.com>

Again, I suspect that the problem is the lack of a Fortran compiler for
Apple Silicon. What is the output of version in R?

For example, mine looks like:

> version
               _
platform       x86_64-pc-linux-gnu
arch           x86_64
os             linux-gnu
system         x86_64, linux-gnu
status
major          4
minor          0.5
year           2021
month          03
day            31
svn rev        80133
language       R
version.string R version 4.0.5 (2021-03-31)
nickname       Shake and Throw

On 10/5/21 5:40 pm, emanuele favaron wrote:
> Thank you very much for your answer. At the moment I reinstalled R on my
> mac, and apparently the problem now is with the "statmod" package. I
> tried?to install it also with tgz files, the installation succeeds?but
> there's no package after that. Is there a way to avoid this problem?
> Here the answer I get when I try to install "lme4" from GitHub.
> 
> Thanks again?
> Emanuele
> 
> 
> Error: Failed to install 'lme4' from GitHub:
> ? System command 'R' failed, exit status: 1, stdout + stderr:
> E> * checking for file
> ?/private/var/folders/t2/gx44y9f5015gdcg8kth720gr0000gn/T/Rtmp3pHj9X/remotesf0a3ad15436/lme4-lme4-6a6d121/DESCRIPTION?
> ... OK
> E> * preparing ?lme4?:
> E> * checking DESCRIPTION meta-information ... OK
> E> * cleaning src
> E> * installing the package to process help pages
> E> ? ? ? -----------------------------------
> E> ERROR: dependency ?statmod? is not available for package ?lme4?
> E> * removing
> ?/private/var/folders/t2/gx44y9f5015gdcg8kth720gr0000gn/T/RtmpER6KCU/Rinstff01be45df1/lme4?
> E> ? ? ? -----------------------------------
> E> ERROR: package installation failed
> In addition: Warning message:
> In i.p(...) : installation of package ?statmod? had non-zero exit status
> 
> Thanks again?
> Emanuele
> 
> 
> On Mon, 10 May 2021 at 17:23, Phillip Alday <me at phillipalday.com
> <mailto:me at phillipalday.com>> wrote:
> 
>     Hi Emanuele,
> 
>     It helps us a little bit if you tell us what the solutions you tried
>     actually were. We don't know what websites you looked at.
> 
>     It looks like you're on the new Apple silicon. Unfortunately, Apple
>     there isn't a release of gfortran for that, which has created a lot of
>     problems for numerical and statistical computing. For now, I would
>     recommend running R for x86-64 via Rosetta.
> 
>     Phillip
> 
>     On 10/5/21 4:20 pm, emanuele favaron wrote:
>     > Good afternoon,
>     >
>     > I'm working on R studio Version 1.4.1625 in MacOs Big Sur 11.2.2.
>     > Trying to load library(lme4) I get this answer:
>     >
>     > Error: package or namespace load failed for ?lme4? in dyn.load(file,
>     > DLLpath = DLLpath, ...):
>     >? unable to load shared object
>     >
>     '/Library/Frameworks/R.framework/Versions/4.1-arm64/Resources/library/statmod/libs/statmod.so':
>     >
>     >
>     dlopen(/Library/Frameworks/R.framework/Versions/4.1-arm64/Resources/library/statmod/libs/statmod.so,
>     > 6): Library not loaded: /opt/R/arm64/gfortran/lib/libgfortran.5.dylib
>     >? ?Referenced from:
>     >
>     /Library/Frameworks/R.framework/Versions/4.1-arm64/Resources/library/statmod/libs/statmod.so
>     >? ?Reason: image not found
>     >
>     >
>     > I already tried all the possible solutions suggested in some
>     websites but
>     > they don't work. How can I solve this problem?
>     >
>     > Thanks in advance
>     > Emanuele
>     >
>     >? ? ? ?[[alternative HTML version deleted]]
>     >
>     > _______________________________________________
>     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >
>


From john@th@n@jone@ @end|ng |rom gm@||@com  Mon May 10 19:15:32 2021
From: john@th@n@jone@ @end|ng |rom gm@||@com (Johnathan Jones)
Date: Mon, 10 May 2021 18:15:32 +0100
Subject: [R-sig-ME] contradictory odds ratios--a problem with the equation
 or the interpretation?
Message-ID: <CAJB+otq5M-F3E_qHa4gQuzF6=TGydAC3EzCGw1BU+e=Y8kwepA@mail.gmail.com>

Hi all,

I?m running a generalized linear mixed model in R (4.0.3) and while most
findings are in-line with what could be expected, I?m getting one that?s
off. Either I?m mixing something up in my equation or there?s a reasonable
explanation for my results that I?m not seeing. I'm hoping someone here
might be able to diagnose the issue.


*Background*

I am researching speech perception in second languages (n = 53, 48 items).
Specifically, I am investigating how well a person's ability to accurately
perceive words spoken in isolation predicts their ability to perceive words
spoken in sentences.

Different language groups have different language transfer issues which
complicate things.

Also impacting perception is association--whether you associate the word
with its sentence context.


*Variables of interest*

Outcome variable (Y): perception of a word in a sentence

Predictor variables:

- iso1: the participant?s estimated ability to identify a word in isolation
(a performance score. I?ve used raw and Rasch standardised scores here to
see if results would change. No dice).

- iso2: the participant?s estimated ability to discriminate between
isolated words in sequences (a performance score, as described in iso1).

- language: what language group the participant is from. Languages include
English, Mandarin, and Spanish (note: Mandarin consistently outperforms
Spanish in raw and standard scores]

- association: whether the participant associates the target word in the
sentence with the sentence. Association levels include same, different, and
neutral (it's a little more nuanced, but this communicates what's
necessary).

Random variables: participant and item.

Equation: Y ~ iso1 + iso2 + language + association + (1|participant) +
(1|item)


*Outputs *(via sjPlot)

Predictor                             Odds ratio         CI

(Intercept)                            58.45                 18.47-184.90


- Iso1:                                    1.02                   1.00-1.03

- Iso2:                                    1.03                   1.01-1.04

- Association [same]:          2.44                   0.23-0.49

- Association [different]:     0.34                  1.64-3.61

- Language [Mandarin]:      0.04                  0.01-0.12

- Language [Spanish]:          0.05                  0.01-.18



The good from the output:

Association works out. Participants have greater log odds of obtaining a
correct answer when they associate the word with its sentential context.
Not associating the word with the context tends to lead to misperception.
There is a pretty large effect here.

The bad from the output:

Language is yielding opposite results than expected. The Spanish group has
an odds ratio of .05 while the Mandarin group has an odds ratio of .04.
This is irregular as Mandarin outperforms Spanish across all tasks
(evidenced by raw scores and Rasch analysis).


If the equation looks right, how can it be that a lower performing group
(by every other task or metric) has a better odds ratio than a higher
performing group when predicting performance?

Any ideas as to what I might try to resolve the language variable issue or
possible interpretations of what I see as a wonky result would be very much
appreciated.


Thank you!


John Jones
E: johnathan.jones at gmail.com
SM: linkedin.com/in/johnathanjones

	[[alternative HTML version deleted]]


From mm@|ten @end|ng |rom gm@||@com  Mon May 10 19:20:27 2021
From: mm@|ten @end|ng |rom gm@||@com (Mitchell Maltenfort)
Date: Mon, 10 May 2021 13:20:27 -0400
Subject: [R-sig-ME] 
 contradictory odds ratios--a problem with the equation
 or the interpretation?
In-Reply-To: <CAJB+otq5M-F3E_qHa4gQuzF6=TGydAC3EzCGw1BU+e=Y8kwepA@mail.gmail.com>
References: <CAJB+otq5M-F3E_qHa4gQuzF6=TGydAC3EzCGw1BU+e=Y8kwepA@mail.gmail.com>
Message-ID: <CANOgrHY_eA8aQvcbucxv+atyQO9LoT8iMA6M0AHiMC_EruuX9A@mail.gmail.com>

Look at the confidence intervals.  Mandarin and Spanish overlap.

On Mon, May 10, 2021 at 1:16 PM Johnathan Jones <johnathan.jones at gmail.com>
wrote:

> Hi all,
>
> I?m running a generalized linear mixed model in R (4.0.3) and while most
> findings are in-line with what could be expected, I?m getting one that?s
> off. Either I?m mixing something up in my equation or there?s a reasonable
> explanation for my results that I?m not seeing. I'm hoping someone here
> might be able to diagnose the issue.
>
>
> *Background*
>
> I am researching speech perception in second languages (n = 53, 48 items).
> Specifically, I am investigating how well a person's ability to accurately
> perceive words spoken in isolation predicts their ability to perceive words
> spoken in sentences.
>
> Different language groups have different language transfer issues which
> complicate things.
>
> Also impacting perception is association--whether you associate the word
> with its sentence context.
>
>
> *Variables of interest*
>
> Outcome variable (Y): perception of a word in a sentence
>
> Predictor variables:
>
> - iso1: the participant?s estimated ability to identify a word in isolation
> (a performance score. I?ve used raw and Rasch standardised scores here to
> see if results would change. No dice).
>
> - iso2: the participant?s estimated ability to discriminate between
> isolated words in sequences (a performance score, as described in iso1).
>
> - language: what language group the participant is from. Languages include
> English, Mandarin, and Spanish (note: Mandarin consistently outperforms
> Spanish in raw and standard scores]
>
> - association: whether the participant associates the target word in the
> sentence with the sentence. Association levels include same, different, and
> neutral (it's a little more nuanced, but this communicates what's
> necessary).
>
> Random variables: participant and item.
>
> Equation: Y ~ iso1 + iso2 + language + association + (1|participant) +
> (1|item)
>
>
> *Outputs *(via sjPlot)
>
> Predictor                             Odds ratio         CI
>
> (Intercept)                            58.45                 18.47-184.90
>
>
> - Iso1:                                    1.02                   1.00-1.03
>
> - Iso2:                                    1.03                   1.01-1.04
>
> - Association [same]:          2.44                   0.23-0.49
>
> - Association [different]:     0.34                  1.64-3.61
>
> - Language [Mandarin]:      0.04                  0.01-0.12
>
> - Language [Spanish]:          0.05                  0.01-.18
>
>
>
> The good from the output:
>
> Association works out. Participants have greater log odds of obtaining a
> correct answer when they associate the word with its sentential context.
> Not associating the word with the context tends to lead to misperception.
> There is a pretty large effect here.
>
> The bad from the output:
>
> Language is yielding opposite results than expected. The Spanish group has
> an odds ratio of .05 while the Mandarin group has an odds ratio of .04.
> This is irregular as Mandarin outperforms Spanish across all tasks
> (evidenced by raw scores and Rasch analysis).
>
>
> If the equation looks right, how can it be that a lower performing group
> (by every other task or metric) has a better odds ratio than a higher
> performing group when predicting performance?
>
> Any ideas as to what I might try to resolve the language variable issue or
> possible interpretations of what I see as a wonky result would be very much
> appreciated.
>
>
> Thank you!
>
>
> John Jones
> E: johnathan.jones at gmail.com
> SM: linkedin.com/in/johnathanjones
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
-- 
Sent from Gmail Mobile

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Mon May 10 19:32:21 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 10 May 2021 13:32:21 -0400
Subject: [R-sig-ME] 
 contradictory odds ratios--a problem with the equation
 or the interpretation?
In-Reply-To: <CAJB+otq5M-F3E_qHa4gQuzF6=TGydAC3EzCGw1BU+e=Y8kwepA@mail.gmail.com>
References: <CAJB+otq5M-F3E_qHa4gQuzF6=TGydAC3EzCGw1BU+e=Y8kwepA@mail.gmail.com>
Message-ID: <70147005-4377-1ced-f71a-862c419a7230@gmail.com>


    I don't know, but ... these are very small differences both 
absolutely (odds ratio of 0.4 vs 0.5) and in terms of the confidence 
intervals on each parameter (0.01-0.12 for Mandarin, even wider for 
Spanish).  A lot of the variation among language groups will also be 
included in the 'participant' random effect (since participants are 
effectively nested within language groups).

   If you look at the participant-by-participant predictions (i.e. 
including both the language group and the participant-level random 
effect in the prediction) do the results make more sense?

   Tangentially a little worried about your very high odds ratio for the 
intercept. At the baseline level your subjects have a probability of 
approximately 1-4e-26 (from plogis(58.45, lower.tail=FALSE)) of correct 
association?  Do you have a continuous predictor whose values are far 
from zero so that the model baseline doesn't make sense? This should be 
independent of the other issues, but makes me wonder if you have 
complete separation and/or other sources of numerical instability lurking?

On 5/10/21 1:15 PM, Johnathan Jones wrote:
> Hi all,
> 
> I?m running a generalized linear mixed model in R (4.0.3) and while most
> findings are in-line with what could be expected, I?m getting one that?s
> off. Either I?m mixing something up in my equation or there?s a reasonable
> explanation for my results that I?m not seeing. I'm hoping someone here
> might be able to diagnose the issue.
> 
> 
> *Background*
> 
> I am researching speech perception in second languages (n = 53, 48 items).
> Specifically, I am investigating how well a person's ability to accurately
> perceive words spoken in isolation predicts their ability to perceive words
> spoken in sentences.
> 
> Different language groups have different language transfer issues which
> complicate things.
> 
> Also impacting perception is association--whether you associate the word
> with its sentence context.
> 
> 
> *Variables of interest*
> 
> Outcome variable (Y): perception of a word in a sentence
> 
> Predictor variables:
> 
> - iso1: the participant?s estimated ability to identify a word in isolation
> (a performance score. I?ve used raw and Rasch standardised scores here to
> see if results would change. No dice).
> 
> - iso2: the participant?s estimated ability to discriminate between
> isolated words in sequences (a performance score, as described in iso1).
> 
> - language: what language group the participant is from. Languages include
> English, Mandarin, and Spanish (note: Mandarin consistently outperforms
> Spanish in raw and standard scores]
> 
> - association: whether the participant associates the target word in the
> sentence with the sentence. Association levels include same, different, and
> neutral (it's a little more nuanced, but this communicates what's
> necessary).
> 
> Random variables: participant and item.
> 
> Equation: Y ~ iso1 + iso2 + language + association + (1|participant) +
> (1|item)
> 
> 
> *Outputs *(via sjPlot)
> 
> Predictor                             Odds ratio         CI
> 
> (Intercept)                            58.45                 18.47-184.90
> 
> 
> - Iso1:                                    1.02                   1.00-1.03
> 
> - Iso2:                                    1.03                   1.01-1.04
> 
> - Association [same]:          2.44                   0.23-0.49
> 
> - Association [different]:     0.34                  1.64-3.61
> 
> - Language [Mandarin]:      0.04                  0.01-0.12
> 
> - Language [Spanish]:          0.05                  0.01-.18
> 
> 
> 
> The good from the output:
> 
> Association works out. Participants have greater log odds of obtaining a
> correct answer when they associate the word with its sentential context.
> Not associating the word with the context tends to lead to misperception.
> There is a pretty large effect here.
> 
> The bad from the output:
> 
> Language is yielding opposite results than expected. The Spanish group has
> an odds ratio of .05 while the Mandarin group has an odds ratio of .04.
> This is irregular as Mandarin outperforms Spanish across all tasks
> (evidenced by raw scores and Rasch analysis).
> 
> 
> If the equation looks right, how can it be that a lower performing group
> (by every other task or metric) has a better odds ratio than a higher
> performing group when predicting performance?
> 
> Any ideas as to what I might try to resolve the language variable issue or
> possible interpretations of what I see as a wonky result would be very much
> appreciated.
> 
> 
> Thank you!
> 
> 
> John Jones
> E: johnathan.jones at gmail.com
> SM: linkedin.com/in/johnathanjones
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From bbo|ker @end|ng |rom gm@||@com  Mon May 10 19:54:36 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 10 May 2021 13:54:36 -0400
Subject: [R-sig-ME] lme4
In-Reply-To: <932a7f6c-67be-0c0f-fac2-2674a6972d4a@phillipalday.com>
References: <CAN6UW7savDzhDiTspTrTnZ8Rpv_V6QxRT16j-CfboRKvEKV2aw@mail.gmail.com>
 <79f9b1f0-8a63-914f-e52e-aa612d412704@phillipalday.com>
 <CAN6UW7vvFKNnGGYqmN_iueK3ZMNoPzQrDLic1U7LYr_y7gonUQ@mail.gmail.com>
 <932a7f6c-67be-0c0f-fac2-2674a6972d4a@phillipalday.com>
Message-ID: <2a9e522f-e39e-ce85-1081-29a5dd2470c1@gmail.com>

   If this is a general problem, it would not be too hard to 'demote' 
statmod to a "suggested" package; we use it *only* for the rinvgauss() 
function, for simulating inverse Gaussian deviates (should anyone want 
to do that).

   I may do this anyway, but if you need a short-term solution you could 
download the source file, unpack it, edit the DESCRIPTION file to remove 
'statsmod' from Imports:, and install from the directory (this wouldn't 
pass R CMD check but I think it would install just fine).

   cheers
    Ben Bolker



On 5/10/21 11:43 AM, Phillip Alday wrote:
> Again, I suspect that the problem is the lack of a Fortran compiler for
> Apple Silicon. What is the output of version in R?
> 
> For example, mine looks like:
> 
>> version
>                 _
> platform       x86_64-pc-linux-gnu
> arch           x86_64
> os             linux-gnu
> system         x86_64, linux-gnu
> status
> major          4
> minor          0.5
> year           2021
> month          03
> day            31
> svn rev        80133
> language       R
> version.string R version 4.0.5 (2021-03-31)
> nickname       Shake and Throw
> 
> On 10/5/21 5:40 pm, emanuele favaron wrote:
>> Thank you very much for your answer. At the moment I reinstalled R on my
>> mac, and apparently the problem now is with the "statmod" package. I
>> tried?to install it also with tgz files, the installation succeeds?but
>> there's no package after that. Is there a way to avoid this problem?
>> Here the answer I get when I try to install "lme4" from GitHub.
>>
>> Thanks again
>> Emanuele
>>
>>
>> Error: Failed to install 'lme4' from GitHub:
>>  ? System command 'R' failed, exit status: 1, stdout + stderr:
>> E> * checking for file
>> ?/private/var/folders/t2/gx44y9f5015gdcg8kth720gr0000gn/T/Rtmp3pHj9X/remotesf0a3ad15436/lme4-lme4-6a6d121/DESCRIPTION?
>> ... OK
>> E> * preparing ?lme4?:
>> E> * checking DESCRIPTION meta-information ... OK
>> E> * cleaning src
>> E> * installing the package to process help pages
>> E> ? ? ? -----------------------------------
>> E> ERROR: dependency ?statmod? is not available for package ?lme4?
>> E> * removing
>> ?/private/var/folders/t2/gx44y9f5015gdcg8kth720gr0000gn/T/RtmpER6KCU/Rinstff01be45df1/lme4?
>> E> ? ? ? -----------------------------------
>> E> ERROR: package installation failed
>> In addition: Warning message:
>> In i.p(...) : installation of package ?statmod? had non-zero exit status
>>
>> Thanks again
>> Emanuele
>>
>>
>> On Mon, 10 May 2021 at 17:23, Phillip Alday <me at phillipalday.com
>> <mailto:me at phillipalday.com>> wrote:
>>
>>      Hi Emanuele,
>>
>>      It helps us a little bit if you tell us what the solutions you tried
>>      actually were. We don't know what websites you looked at.
>>
>>      It looks like you're on the new Apple silicon. Unfortunately, Apple
>>      there isn't a release of gfortran for that, which has created a lot of
>>      problems for numerical and statistical computing. For now, I would
>>      recommend running R for x86-64 via Rosetta.
>>
>>      Phillip
>>
>>      On 10/5/21 4:20 pm, emanuele favaron wrote:
>>      > Good afternoon,
>>      >
>>      > I'm working on R studio Version 1.4.1625 in MacOs Big Sur 11.2.2.
>>      > Trying to load library(lme4) I get this answer:
>>      >
>>      > Error: package or namespace load failed for ?lme4? in dyn.load(file,
>>      > DLLpath = DLLpath, ...):
>>      >? unable to load shared object
>>      >
>>      '/Library/Frameworks/R.framework/Versions/4.1-arm64/Resources/library/statmod/libs/statmod.so':
>>      >
>>      >
>>      dlopen(/Library/Frameworks/R.framework/Versions/4.1-arm64/Resources/library/statmod/libs/statmod.so,
>>      > 6): Library not loaded: /opt/R/arm64/gfortran/lib/libgfortran.5.dylib
>>      >? ?Referenced from:
>>      >
>>      /Library/Frameworks/R.framework/Versions/4.1-arm64/Resources/library/statmod/libs/statmod.so
>>      >? ?Reason: image not found
>>      >
>>      >
>>      > I already tried all the possible solutions suggested in some
>>      websites but
>>      > they don't work. How can I solve this problem?
>>      >
>>      > Thanks in advance
>>      > Emanuele
>>      >
>>      >? ? ? ?[[alternative HTML version deleted]]
>>      >
>>      > _______________________________________________
>>      > R-sig-mixed-models at r-project.org
>>      <mailto:R-sig-mixed-models at r-project.org> mailing list
>>      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>      >
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From john@m@|ndon@|d @end|ng |rom @nu@edu@@u  Mon May 10 22:36:01 2021
From: john@m@|ndon@|d @end|ng |rom @nu@edu@@u (John Maindonald)
Date: Mon, 10 May 2021 20:36:01 +0000
Subject: [R-sig-ME] 
 contradictory odds ratios--a problem with the equation
 or the interpretation?
In-Reply-To: <CAJB+otq5M-F3E_qHa4gQuzF6=TGydAC3EzCGw1BU+e=Y8kwepA@mail.gmail.com>
References: <CAJB+otq5M-F3E_qHa4gQuzF6=TGydAC3EzCGw1BU+e=Y8kwepA@mail.gmail.com>
Message-ID: <ED037734-3DCB-430E-9EE0-B905C60641F1@anu.edu.au>

How were the data obtained?  Are they from a designed experiment?
Are the  data balanced, i.e., equal numbers in each factor level and
interaction?

Is there an interaction between Association and language?
Is it possible that an important explanatory variable has been omitted.

Omission of a key variable or interaction can reverse the apparent
direction of an effect.  Also, check the matrix of correlations between
model parameters.  Remember that the regression coefficients are
telling you how a variable affects outcome when all other variables
are held constant.  If there is a strongish correlation between two
variables, this has implications for the individual coefficients.
Re-parameterization can sometimes help, e.g., in another context
(time to complete a hill race) work with distance and gradient
(height/distance) rather than distance and height, with the effect
of reducing the correlation to close to 0.


John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>


On 11/05/2021, at 05:15, Johnathan Jones <johnathan.jones at gmail.com<mailto:johnathan.jones at gmail.com>> wrote:

Hi all,

I?m running a generalized linear mixed model in R (4.0.3) and while most
findings are in-line with what could be expected, I?m getting one that?s
off. Either I?m mixing something up in my equation or there?s a reasonable
explanation for my results that I?m not seeing. I'm hoping someone here
might be able to diagnose the issue.


*Background*

I am researching speech perception in second languages (n = 53, 48 items).
Specifically, I am investigating how well a person's ability to accurately
perceive words spoken in isolation predicts their ability to perceive words
spoken in sentences.

Different language groups have different language transfer issues which
complicate things.

Also impacting perception is association--whether you associate the word
with its sentence context.


*Variables of interest*

Outcome variable (Y): perception of a word in a sentence

Predictor variables:

- iso1: the participant?s estimated ability to identify a word in isolation
(a performance score. I?ve used raw and Rasch standardised scores here to
see if results would change. No dice).

- iso2: the participant?s estimated ability to discriminate between
isolated words in sequences (a performance score, as described in iso1).

- language: what language group the participant is from. Languages include
English, Mandarin, and Spanish (note: Mandarin consistently outperforms
Spanish in raw and standard scores]

- association: whether the participant associates the target word in the
sentence with the sentence. Association levels include same, different, and
neutral (it's a little more nuanced, but this communicates what's
necessary).

Random variables: participant and item.

Equation: Y ~ iso1 + iso2 + language + association + (1|participant) +
(1|item)


*Outputs *(via sjPlot)

Predictor                             Odds ratio         CI

(Intercept)                            58.45                 18.47-184.90


- Iso1:                                    1.02                   1.00-1.03

- Iso2:                                    1.03                   1.01-1.04

- Association [same]:          2.44                   0.23-0.49

- Association [different]:     0.34                  1.64-3.61

- Language [Mandarin]:      0.04                  0.01-0.12

- Language [Spanish]:          0.05                  0.01-.18



The good from the output:

Association works out. Participants have greater log odds of obtaining a
correct answer when they associate the word with its sentential context.
Not associating the word with the context tends to lead to misperception.
There is a pretty large effect here.

The bad from the output:

Language is yielding opposite results than expected. The Spanish group has
an odds ratio of .05 while the Mandarin group has an odds ratio of .04.
This is irregular as Mandarin outperforms Spanish across all tasks
(evidenced by raw scores and Rasch analysis).


If the equation looks right, how can it be that a lower performing group
(by every other task or metric) has a better odds ratio than a higher
performing group when predicting performance?

Any ideas as to what I might try to resolve the language variable issue or
possible interpretations of what I see as a wonky result would be very much
appreciated.


Thank you!


John Jones
E: johnathan.jones at gmail.com<mailto:johnathan.jones at gmail.com>
SM: linkedin.com/in/johnathanjones<http://linkedin.com/in/johnathanjones>

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From john@th@n@jone@ @end|ng |rom gm@||@com  Tue May 11 03:41:58 2021
From: john@th@n@jone@ @end|ng |rom gm@||@com (Johnathan Jones)
Date: Tue, 11 May 2021 02:41:58 +0100
Subject: [R-sig-ME] 
 contradictory odds ratios--a problem with the equation
 or the interpretation?
Message-ID: <CAJB+otqR8=qNzLP++x41Fd7A957AJCdDEDeLsi9+fyUFobnjLw@mail.gmail.com>

Good suggestions and notes here, thanks all for taking the time. It
amounted to a very well-rounded accounting.

*Mitchell*, yes, this makes sense.

*John*, thanks for the questions. Yes, these are from a designed
experiment. Results were all as expected (from descriptives to inferentials
and the Rasch analysis) until this mixed methods output was produced. Of
note, I?m surprised that uneven levels matter for mixed models. It was my
understanding mixed models were flexible and robust enough to deal with
this kind of thing. I have omitted other explanatory factors which ?broke?
R and wouldn?t converge (vowel duration was address in item random effects;
word familiarity was explained by association), but I think the most
important predictors remain?at least the ones which address my research
question. Thanks for the suggestion for checking the matrix correlations.

*Ben*, yes, very small differences in outputs for the languages. I?m not
sure I quite follow you here:

?If you look at the participant-by-participant predictions (i.e. including
both the language group and the participant-level random effect in the
prediction) do the results make more sense??

Do you mean something like this: Y ~ iso1 + iso2 + language + association +
(language|participant) + (1|item)?

Removing language as a predictor is a possibility. As you mentioned, a lot
of that variation is covered by participant and language isn?t key to my
research question. This results in a drastically reduced intercept (3.48,
CI 2.08-5.84), but a higher AIC (2266 vs 2299). How much relative weight
does each carry? Is there literature on this? I may simply use the Mandarin
group to keep things clean (results are solid in doing this).

To the ?tangential worry?, yes, the predictors iso1 and iso2 are
continuous, but the confidence interval doesn?t make sense. (It does seem
reasonable when language is removed as a predictor, however).
For association, participants? associations aren?t correct or incorrect. It
simply indicates whether the participant associated the target word (a word
of interest to me, but unknown to them at the time) with the sentence. E.g.
?really? vs ?rarely?; I ___ enjoy family gatherings. Which is correct?
Neither, but many people will associate one over the other. Results are
showing that participants are ?hearing? the word they associate with the
context rather than the word that is said. (This correspondingly explains
why odds ratios are so high for when the target word is the same as the one
participants associate with the context.).

All the best,
John Jones
E: johnathan.jones at gmail.com
SM: linkedin.com/in/johnathanjones

	[[alternative HTML version deleted]]


From john@m@|ndon@|d @end|ng |rom @nu@edu@@u  Tue May 11 04:48:50 2021
From: john@m@|ndon@|d @end|ng |rom @nu@edu@@u (John Maindonald)
Date: Tue, 11 May 2021 02:48:50 +0000
Subject: [R-sig-ME] 
 contradictory odds ratios--a problem with the equation
 or the interpretation?
In-Reply-To: <CAJB+otqR8=qNzLP++x41Fd7A957AJCdDEDeLsi9+fyUFobnjLw@mail.gmail.com>
References: <CAJB+otqR8=qNzLP++x41Fd7A957AJCdDEDeLsi9+fyUFobnjLw@mail.gmail.com>
Message-ID: <510E333B-671A-4D26-BB1C-1025EB3969F4@anu.edu.au>

It looks to me that there is a strong interaction between language and Association,
or there may be effects that are more complicated than that.  If so, that would seem
to me an interesting outcome to probe further.  Have you tried fitting a language by
Association interaction?

On what you call the ?uneven levels? issue, I do not know what the basis may be
for thinking that "mixed models were flexible and robust enough to deal with
this kind of thing.?  Much depends, of course, on how the ?unevenness? feeds into
the weights given to factor or factor combinations.  But if there is an effect
consistently over the different levels of the relevant random effect or effects,
it will feature in the mixed models results.  Note Simpson?s paradox type effects,
or the same kind of effect for regression coefficients, sometimes called Laird?s
paradox.  Hopefully, the experiment has been executed in a way that these are
not issues.


John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>


On 11/05/2021, at 13:41, Johnathan Jones <johnathan.jones at gmail.com<mailto:johnathan.jones at gmail.com>> wrote:

Good suggestions and notes here, thanks all for taking the time. It amounted to a very well-rounded accounting.
Mitchell, yes, this makes sense.
John, thanks for the questions. Yes, these are from a designed experiment. Results were all as expected (from descriptives to inferentials and the Rasch analysis) until this mixed methods output was produced. Of note, I?m surprised that uneven levels matter for mixed models. It was my understanding mixed models were flexible and robust enough to deal with this kind of thing. I have omitted other explanatory factors which ?broke? R and wouldn?t converge (vowel duration was address in item random effects; word familiarity was explained by association), but I think the most important predictors remain?at least the ones which address my research question. Thanks for the suggestion for checking the matrix correlations.
Ben, yes, very small differences in outputs for the languages. I?m not sure I quite follow you here:
?If you look at the participant-by-participant predictions (i.e. including both the language group and the participant-level random effect in the prediction) do the results make more sense??
Do you mean something like this: Y ~ iso1 + iso2 + language + association + (language|participant) + (1|item)?
Removing language as a predictor is a possibility. As you mentioned, a lot of that variation is covered by participant and language isn?t key to my research question. This results in a drastically reduced intercept (3.48, CI 2.08-5.84), but a higher AIC (2266 vs 2299). How much relative weight does each carry? Is there literature on this? I may simply use the Mandarin group to keep things clean (results are solid in doing this).
To the ?tangential worry?, yes, the predictors iso1 and iso2 are continuous, but the confidence interval doesn?t make sense. (It does seem reasonable when language is removed as a predictor, however).
For association, participants? associations aren?t correct or incorrect. It simply indicates whether the participant associated the target word (a word of interest to me, but unknown to them at the time) with the sentence. E.g. ?really? vs ?rarely?; I ___ enjoy family gatherings. Which is correct? Neither, but many people will associate one over the other. Results are showing that participants are ?hearing? the word they associate with the context rather than the word that is said. (This correspondingly explains why odds ratios are so high for when the target word is the same as the one participants associate with the context.).

All the best,
John Jones
E: johnathan.jones at gmail.com<mailto:johnathan.jones at gmail.com>
SM: linkedin.com/in/johnathanjones<http://linkedin.com/in/johnathanjones>



	[[alternative HTML version deleted]]


From benpe|zer @end|ng |rom gm@||@com  Tue May 11 11:13:49 2021
From: benpe|zer @end|ng |rom gm@||@com (ben pelzer)
Date: Tue, 11 May 2021 11:13:49 +0200
Subject: [R-sig-ME] 
 contradictory odds ratios--a problem with the equation
 or the interpretation?
Message-ID: <CAFgPNS84af1sBbqk-2YWsKVz0byM4eRUtbxBdPPMyngYBGROXA@mail.gmail.com>

 Hi jonathan,

Another idea that may possibly help. Suppose you break down the problem
into smaller pieces.

1) start with only language as predictor (I think I would use Mandarin as
reference). It's interesting to see what happens when one of the other
predictors is added. Which other predictor, after adding, makes the
significant language difference (if present) dissapear?

2) analyse each word separately.  This means a simple regression per word.
You probably have 53 observations then? Maybe entering all 6 predictors is
too much, so you could again start with languages only, etc. On the other
hand, entering all 6 predictors could show that for some words languages
differ in the way you expect, and for some words they do not.

Good luck, Ben.

	[[alternative HTML version deleted]]


From em@nue|e|@v@ron @end|ng |rom gm@||@com  Tue May 11 09:50:48 2021
From: em@nue|e|@v@ron @end|ng |rom gm@||@com (emanuele favaron)
Date: Tue, 11 May 2021 09:50:48 +0200
Subject: [R-sig-ME] lme4
In-Reply-To: <932a7f6c-67be-0c0f-fac2-2674a6972d4a@phillipalday.com>
References: <CAN6UW7savDzhDiTspTrTnZ8Rpv_V6QxRT16j-CfboRKvEKV2aw@mail.gmail.com>
 <79f9b1f0-8a63-914f-e52e-aa612d412704@phillipalday.com>
 <CAN6UW7vvFKNnGGYqmN_iueK3ZMNoPzQrDLic1U7LYr_y7gonUQ@mail.gmail.com>
 <932a7f6c-67be-0c0f-fac2-2674a6972d4a@phillipalday.com>
Message-ID: <CAN6UW7u3y5kxqJG-15R1c0rbgn1-sRT2oV3XZs7VFaFGSwdOng@mail.gmail.com>

Ok if that is the case I will follow your previous suggestion.
the output version is:
> version
               _
platform       x86_64-apple-darwin17.0
arch           x86_64
os             darwin17.0
system         x86_64, darwin17.0
status
major          4
minor          0.5
year           2021
month          03
day            31
svn rev        80133
language       R
version.string R version 4.0.5 (2021-03-31)
nickname       Shake and Throw



On Mon, 10 May 2021 at 17:43, Phillip Alday <me at phillipalday.com> wrote:

> Again, I suspect that the problem is the lack of a Fortran compiler for
> Apple Silicon. What is the output of version in R?
>
> For example, mine looks like:
>
> > version
>                _
> platform       x86_64-pc-linux-gnu
> arch           x86_64
> os             linux-gnu
> system         x86_64, linux-gnu
> status
> major          4
> minor          0.5
> year           2021
> month          03
> day            31
> svn rev        80133
> language       R
> version.string R version 4.0.5 (2021-03-31)
> nickname       Shake and Throw
>
> On 10/5/21 5:40 pm, emanuele favaron wrote:
> > Thank you very much for your answer. At the moment I reinstalled R on my
> > mac, and apparently the problem now is with the "statmod" package. I
> > tried to install it also with tgz files, the installation succeeds but
> > there's no package after that. Is there a way to avoid this problem?
> > Here the answer I get when I try to install "lme4" from GitHub.
> >
> > Thanks again
> > Emanuele
> >
> >
> > Error: Failed to install 'lme4' from GitHub:
> >   System command 'R' failed, exit status: 1, stdout + stderr:
> > E> * checking for file
> >
> ?/private/var/folders/t2/gx44y9f5015gdcg8kth720gr0000gn/T/Rtmp3pHj9X/remotesf0a3ad15436/lme4-lme4-6a6d121/DESCRIPTION?
> > ... OK
> > E> * preparing ?lme4?:
> > E> * checking DESCRIPTION meta-information ... OK
> > E> * cleaning src
> > E> * installing the package to process help pages
> > E>       -----------------------------------
> > E> ERROR: dependency ?statmod? is not available for package ?lme4?
> > E> * removing
> >
> ?/private/var/folders/t2/gx44y9f5015gdcg8kth720gr0000gn/T/RtmpER6KCU/Rinstff01be45df1/lme4?
> > E>       -----------------------------------
> > E> ERROR: package installation failed
> > In addition: Warning message:
> > In i.p(...) : installation of package ?statmod? had non-zero exit status
> >
> > Thanks again
> > Emanuele
> >
> >
> > On Mon, 10 May 2021 at 17:23, Phillip Alday <me at phillipalday.com
> > <mailto:me at phillipalday.com>> wrote:
> >
> >     Hi Emanuele,
> >
> >     It helps us a little bit if you tell us what the solutions you tried
> >     actually were. We don't know what websites you looked at.
> >
> >     It looks like you're on the new Apple silicon. Unfortunately, Apple
> >     there isn't a release of gfortran for that, which has created a lot
> of
> >     problems for numerical and statistical computing. For now, I would
> >     recommend running R for x86-64 via Rosetta.
> >
> >     Phillip
> >
> >     On 10/5/21 4:20 pm, emanuele favaron wrote:
> >     > Good afternoon,
> >     >
> >     > I'm working on R studio Version 1.4.1625 in MacOs Big Sur 11.2.2.
> >     > Trying to load library(lme4) I get this answer:
> >     >
> >     > Error: package or namespace load failed for ?lme4? in
> dyn.load(file,
> >     > DLLpath = DLLpath, ...):
> >     >  unable to load shared object
> >     >
> >
>  '/Library/Frameworks/R.framework/Versions/4.1-arm64/Resources/library/statmod/libs/statmod.so':
> >     >
> >     >
> >
>  dlopen(/Library/Frameworks/R.framework/Versions/4.1-arm64/Resources/library/statmod/libs/statmod.so,
> >     > 6): Library not loaded:
> /opt/R/arm64/gfortran/lib/libgfortran.5.dylib
> >     >   Referenced from:
> >     >
> >
>  /Library/Frameworks/R.framework/Versions/4.1-arm64/Resources/library/statmod/libs/statmod.so
> >     >   Reason: image not found
> >     >
> >     >
> >     > I already tried all the possible solutions suggested in some
> >     websites but
> >     > they don't work. How can I solve this problem?
> >     >
> >     > Thanks in advance
> >     > Emanuele
> >     >
> >     >       [[alternative HTML version deleted]]
> >     >
> >     > _______________________________________________
> >     > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     >
> >
>

	[[alternative HTML version deleted]]


From cm|o500 @end|ng |rom york@@c@uk  Fri May 14 16:19:28 2021
From: cm|o500 @end|ng |rom york@@c@uk (=?UTF-8?Q?C=C3=A1tia_Ferreira_De_Oliveira?=)
Date: Fri, 14 May 2021 15:19:28 +0100
Subject: [R-sig-ME] glmer and influence.me - complaining about nAGQ==0
In-Reply-To: <CACw+Tff2BeiGOgakYUP=a58yAL0_oBGqpSW3wNS+sMg1xxbUTw@mail.gmail.com>
References: <CACw+Tff2BeiGOgakYUP=a58yAL0_oBGqpSW3wNS+sMg1xxbUTw@mail.gmail.com>
Message-ID: <CACw+TfcJVhf7GUWctdP4qEgY6keU7F2V=fpegjTc5bm3WHMkCg@mail.gmail.com>

Dear Professor Bolker,

I am currently running the allfit function for the models I mentioned in
the previous email and I am now doing the same for another model using the
same data and this seems much worse. This is the model that seems to give
even worse fit with this value "Model failed to converge with max|grad| *=
0.167262* (tol = 0.002, component 1)" being much higher. Are there any
other suggestions I could take? This model I am running without the logRT
and the nAGQ==0.

Thank you!

## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: Gamma  ( log )
## Formula:
## RT ~ Probability * Session * Group * Age + (1 + Session *
Probability |  Participant)
##    Data: Data.trimmed
## Control: glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e+05))
##
##       AIC       BIC    logLik  deviance  df.resid
##  938050.5  938301.3 -468998.3  937996.5     79890
##
## Scaled residuals:
##    Min     1Q Median     3Q    Max
## -4.258 -0.597 -0.151  0.410 33.938
##
## Random effects:
##  Groups      Name                  Variance  Std.Dev. Corr
##  Participant (Intercept)           1.700e-03 0.041232
##              Session1              2.583e-04 0.016073  0.13
##              Probability1          1.121e-04 0.010589 -0.06  0.11
##              Session1:Probability1 6.176e-05 0.007859  0.02 -0.02 -0.02
##  Residual                          5.448e-02 0.233418
## Number of obs: 79917, groups:  Participant, 45
##
## Fixed effects:
##                                    Estimate Std. Error t value Pr(>|z|)
## (Intercept)                       5.9334448  0.0739725  80.211  < 2e-16 ***
## Probability1                     -0.0162354  0.0100753  -1.611  0.10709
## Session1                          0.0631180  0.0209673   3.010  0.00261 **
## Group1                           -0.0331517  0.0740287  -0.448  0.65428
## Age                               0.0035260  0.0023510   1.500  0.13367
## Probability1:Session1             0.0059755  0.0075507   0.791  0.42872
## Probability1:Group1               0.0060958  0.0101003   0.604  0.54616
## Session1:Group1                   0.0215458  0.0210650   1.023  0.30639
## Probability1:Age                 -0.0003351  0.0003189  -1.051  0.29331
## Session1:Age                     -0.0006021  0.0006607  -0.911  0.36220
## Group1:Age                       -0.0009086  0.0023529  -0.386  0.69938
## Probability1:Session1:Group1      0.0067270  0.0075839   0.887  0.37507
## Probability1:Session1:Age        -0.0001585  0.0002380  -0.666  0.50544
## Probability1:Group1:Age          -0.0002775  0.0003196  -0.868  0.38519
## Session1:Group1:Age              -0.0007188  0.0006636  -1.083  0.27877
## Probability1:Session1:Group1:Age -0.0001956  0.0002391  -0.818  0.41320
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

##
## Correlation matrix not shown by default, as p = 16 > 12.
## Use print(x, correlation=TRUE)  or
##     vcov(x)        if you need it

## optimizer (bobyqa) convergence code: 0 (OK)
## Model failed to converge with max|grad| = 0.167262 (tol = 0.002, component 1)
## Model is nearly unidentifiable: very large eigenvalue
##  - Rescale variables?
## Model is nearly unidentifiable: large eigenvalue ratio
##  - Rescale variables?

	[[alternative HTML version deleted]]


From k|r@t|@|ynn @end|ng |rom gm@||@com  Sat May 15 15:21:23 2021
From: k|r@t|@|ynn @end|ng |rom gm@||@com (Kirsti Carr)
Date: Sat, 15 May 2021 08:21:23 -0500
Subject: [R-sig-ME] Logistic exposure glmer polynomial covariate issue
Message-ID: <CAL04JRXisWmcp1Zt42=-3i0-Ha6KF-5Jjr9cvpNhy7sH+JVj4w@mail.gmail.com>

I am having issues with a glmer logistic regression with a logistic
exposure link function (method popularized in 2004 paper by Terry Shaffer),
to analyze juvenile survival data in respect to land cover data around
nest sites.

Had no issues with rescaling warnings when I ran data as glm, but when I
added the random effect I started getting these warnings for my polynomial
models. I attempted to rescale by log transforming the covariates. This
helped with some, but not all. I am also still getting an error message for
some models - both models included get the warning or error. I am using
lme4 version 1.1.25.

Any help would be much appreciated! Thanks in advance.

Example data here
<https://www.dropbox.com/s/0w3csm2vfcj47yq/data_email.csv?dl=0>

My code (logexp function used from posts by Ben Bolker online):

library(MASS)
library(lme4)
packages(bbmle)

logexp <- function(expos = 1)
{
  linkfun <- function(mu) qlogis(mu^(1/expos))
  ## FIXME: is there some trick we can play here to allow
  ##   evaluation in the context of the 'data' argument?
  linkinv <- function(eta)  plogis(eta)^expos
  mu.eta <- function(eta) expos * plogis(eta)^(expos-1) *
    .Call(stats:::C_logit_mu_eta, eta, PACKAGE = "stats")
  valideta <- function(eta) TRUE
  link <- paste("logexp(", deparse(substitute(expos)), ")",
                sep="")
  structure(list(linkfun = linkfun, linkinv = linkinv,
                 mu.eta = mu.eta, valideta = valideta,
                 name = link),
            class = "link-glm")
}

FL1 <- read.csv("data_email.csv")

g250.3
<-glmer(fate~(1|brood)+log(I(1+G250))+(log(I(1+G250^2)))+(log(I(1+G250^3))),
family=binomial(link=logexp(FL1$Interval)), data=FL1, start=NULL)

#error I received:

# Error in (function (fr, X, reTrms, family, nAGQ = 1L, verbose = 0L, maxit
= 100L,  :
#(maxstephalfit) PIRLS step-halvings failed to reduce deviance in
pwrssUpdate

g500.2 <-glmer(fate~(1|brood)+log(I(1+G500))+(log(I(1+G500^2))),
family=binomial(link=logexp(FL1$Interval)), data=FL1, start=NULL)

# Warning for g500.2:

# Warning message:
  # In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
                # Model is nearly unidentifiable: large eigenvalue ratio
               # Rescale variables?

	[[alternative HTML version deleted]]


From john@th@n@jone@ @end|ng |rom gm@||@com  Sun May 16 00:23:39 2021
From: john@th@n@jone@ @end|ng |rom gm@||@com (Johnathan Jones)
Date: Sat, 15 May 2021 23:23:39 +0100
Subject: [R-sig-ME] 
 contradictory odds ratios--a problem with the equation
 or the interpretation?
Message-ID: <CAJB+otpz_W7niyx_rOVeUjSS9V1EGwh_GqdM-QkQGawNnpzVvQ@mail.gmail.com>

Hi all,

Thanks to everyone who contributed to this thread. Each comment and query
was helpful, not just for my immediate needs, but for a general
troubleshooting of mixed models.

I've modified the original equation somewhat by removing Language as a
predictor and allowing association to vary by participant. For anyone
interested, the best fit model--both conceptually and statistically--is:
correct response to a sentential listening prompt ~ isolated speech task
1 + isolated speech task 2 + association + (association | participant) +
(1|item). This yields the following:
*Predictors              Odds Ratios        CI                       p*
(Intercept)                     3.25                 1.82 ? 5.79
<0.001
bVt Transcription           1.03                 1.01 ? 1.05        0.006
Oddity                            1.04                 1.02 ? 1.06
 <0.001
Association?opposite   0.34                 0.21 ? 0.55       <0.001
Association?same        3.33                 2.03 ? 5.47       <0.001

John, Simpson's paradox is a keen take and something to keep my eye on for
subsequent related work. For unbalanced designs, you wouldn't say this is
something common with mixed models? Is this not one of its main advantages
over something like a traditional (or repeated measures) analysis of
variance?

Ben, I really like this approach. We've controlled pretty well for "word
type" and have a fairly tight understanding of which (types of) words lead
to perceptual issues in second language learners, but this could perhaps be
something to use down the line in another capacity. Thanks for the
suggestion and please feel free to email me if this is something you're
interested in.

All the best,

John Jones
E: johnathan.jones at gmail.com
SM: linkedin.com/in/johnathanjones

	[[alternative HTML version deleted]]


From n@k@g@w@ @end|ng |rom hum@n@goy@-cu@@c@jp  Sun May 16 12:10:21 2021
From: n@k@g@w@ @end|ng |rom hum@n@goy@-cu@@c@jp (Atsuko Nakagawa)
Date: Sun, 16 May 2021 19:10:21 +0900
Subject: [R-sig-ME] About warning
Message-ID: <ffbb4c00-7535-aa18-fd58-04a7492efc31@hum.nagoya-cu.ac.jp>

Hi

Thank you very much for your help.

When we ran Package lme4 to our longitudinal data, we got following 
warnings repeatedly.

> fixed-effect model matrix is rank deficient so dropping 2 columns / 
> coefficients
> boundary (singular) fit: see ?isSingular 
Nevertheless, we got some results. Are these valid?
When I look for the Q&A in some Statistic Forums, sometimes I found the 
previous answer that we do not have to care these warnings.

In actuality, how do we deal with these warnings?

Thank you for your time.

Atsuko Nakagawa

Graduate School of Humanities and Social Sciences, Nagoya City 
University, JAPAN




	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Sun May 16 23:28:38 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sun, 16 May 2021 17:28:38 -0400
Subject: [R-sig-ME] About warning
In-Reply-To: <ffbb4c00-7535-aa18-fd58-04a7492efc31@hum.nagoya-cu.ac.jp>
References: <ffbb4c00-7535-aa18-fd58-04a7492efc31@hum.nagoya-cu.ac.jp>
Message-ID: <dd7a9b9b-6e61-42cd-da64-d64b4e3e970d@gmail.com>

   There are two issues here.

  - fixed-effect model matrix is rank deficient: this is not necessarily 
a problem, but you should try to understand what's going on.  There is a 
detailed StackOverflow post here:

https://stackoverflow.com/questions/37090722/lme4lmer-reports-fixed-effect-model-matrix-is-rank-deficient-do-i-need-a-fi#37094040

  You can look at your results to figure out which coefficients are 
missing, or you can use attr(getME(m,"X"), "col.dropped") to see which 
columns of the original model frame were dropped.  (It would be useful 
if I or someone would write a more detailed diagnostic function to 
report which columns of the original model matrix were collinear ...)

  - singular fit.

  This is a little harder. In some sense this means that your model is 
overfitted (there is sufficiently little data that the best estimate of 
the inter-group variance is zero).  Conclusions on the fixed effects are 
most likely OK.  *If* the singular component corresponds to the variance 
of an entire random-effect term being exactly zero (e.g. you have a 
random intercept model), then you'll get exactly the same results for 
the fixed effects, at least to the level of point estimates and Wald 
confidence intervals/p-values, if you drop the RE term.

   There is a lot more discussion in ?lme4::isSingular, for a start ...


On 5/16/21 6:10 AM, Atsuko Nakagawa wrote:
> Hi
> 
> Thank you very much for your help.
> 
> When we ran Package lme4 to our longitudinal data, we got following
> warnings repeatedly.
> 
>> fixed-effect model matrix is rank deficient so dropping 2 columns /
>> coefficients
>> boundary (singular) fit: see ?isSingular
> Nevertheless, we got some results. Are these valid?
> When I look for the Q&A in some Statistic Forums, sometimes I found the
> previous answer that we do not have to care these warnings.
> 
> In actuality, how do we deal with these warnings?
> 
> Thank you for your time.
> 
> Atsuko Nakagawa
> 
> Graduate School of Humanities and Social Sciences, Nagoya City
> University, JAPAN
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From bbo|ker @end|ng |rom gm@||@com  Mon May 17 03:13:11 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sun, 16 May 2021 21:13:11 -0400
Subject: [R-sig-ME] Logistic exposure glmer polynomial covariate issue
In-Reply-To: <CAL04JRXisWmcp1Zt42=-3i0-Ha6KF-5Jjr9cvpNhy7sH+JVj4w@mail.gmail.com>
References: <CAL04JRXisWmcp1Zt42=-3i0-Ha6KF-5Jjr9cvpNhy7sH+JVj4w@mail.gmail.com>
Message-ID: <d02a80a4-7b61-205d-fd98-c6199b895fc7@gmail.com>



On 5/15/21 9:21 AM, Kirsti Carr wrote:
> I am having issues with a glmer logistic regression with a logistic
> exposure link function (method popularized in 2004 paper by Terry Shaffer),
> to analyze juvenile survival data in respect to land cover data around
> nest sites.

   I'll start by saying that while I appreciate why people use the 
logistic exposure link function, the approach that uses the 
complementary log-log link (described here: 
https://www.rpubs.com/bbolker/logregexp ) seems very much more sensible 
to me and may work more smoothly.
> 
> Had no issues with rescaling warnings when I ran data as glm, but when I
> added the random effect I started getting these warnings for my polynomial
> models. I attempted to rescale by log transforming the covariates. This
> helped with some, but not all. I am also still getting an error message for
> some models - both models included get the warning or error. I am using
> lme4 version 1.1.25.
> 
> Any help would be much appreciated! Thanks in advance.
> 
> Example data here
> <https://www.dropbox.com/s/0w3csm2vfcj47yq/data_email.csv?dl=0>

   I have looked at this a bit and may post more tomorrow.  Things that 
jump out at me:

- `with(FL1,table(fate))` shows 237 surviving nests, only 6 being 
predated.  This means your effective sample size is 6 (!), which means 
it will only work to fit very simple models (the rule of thumb from 
Frank Harrell's book and elsewhere is that you should aim for 10 data 
points *per parameter you're going to try to estimate*). Thus a cubic 
model is probably overkill.

- the whole log(1+G250) thing looks odd to me, unless there is some 
particular reason that G250 makes more sense on a log scale (log(1+x) is 
always a bit of a caution that you're trying to treat something as 
logarithmic that might not want to be ...). The values of G250 are 
pretty reasonably spaced as it is, there's no obvious *computational* 
reason to want to log-transform them.

  How far I got so far:

gm1 <- glmer(fate~(1|brood) + G250 + offset(log(Interval)),
              family=binomial(link="cloglog"),
              data=FL1)

gm2 <- update(gm1, . ~ . -G250 + poly(G250,2))
gm3 <- update(gm1, . ~ . -G250 + poly(G250,3)) ## warning
library(bbmle)
AICctab(gm1, gm2, gm3, mnames=c("linear","quad","cubic"))

        dAICc df
quad   0.0   4
cubic  2.1   5
linear 2.8   3

The cubic model gives a warning about large eigenvalues, and the AICc 
calculation says that it's not worth it.

If you want to go nuts, here are the quadratic and linear models:

library(sjPlot)
library(ggeffects)

g1 <- ggpredict(gm1, terms="G250 [0:8.5 by=0.2]")
plot_model(gm2, type="pred", terms="G250 [0:8.5 by=0.2]") +
   geom_line(data=g1, colour="red") +
   geom_ribbon(data=g1, colour=NA, fill="red", alpha=0.2,
               aes(ymin=conf.low, ymax=conf.high)) +
   stat_sum(data=FL1, alpha=0.5, aes(x=G250, y=fate))


   This is all with cloglog - it could probably be done with logexp() 
too, but would all be a little less stable / more fussy.

> 
> My code (logexp function used from posts by Ben Bolker online):
> 
> library(MASS)
> library(lme4)
> packages(bbmle)
> 
> logexp <- function(expos = 1)
> {
>    linkfun <- function(mu) qlogis(mu^(1/expos))
>    ## FIXME: is there some trick we can play here to allow
>    ##   evaluation in the context of the 'data' argument?
>    linkinv <- function(eta)  plogis(eta)^expos
>    mu.eta <- function(eta) expos * plogis(eta)^(expos-1) *
>      .Call(stats:::C_logit_mu_eta, eta, PACKAGE = "stats")
>    valideta <- function(eta) TRUE
>    link <- paste("logexp(", deparse(substitute(expos)), ")",
>                  sep="")
>    structure(list(linkfun = linkfun, linkinv = linkinv,
>                   mu.eta = mu.eta, valideta = valideta,
>                   name = link),
>              class = "link-glm")
> }
> 
> FL1 <- read.csv("data_email.csv")
> 
> g250.3
> <-glmer(fate~(1|brood)+log(I(1+G250))+(log(I(1+G250^2)))+(log(I(1+G250^3))),
> family=binomial(link=logexp(FL1$Interval)), data=FL1, start=NULL)
> 
> #error I received:
> 
> # Error in (function (fr, X, reTrms, family, nAGQ = 1L, verbose = 0L, maxit
> = 100L,  :
> #(maxstephalfit) PIRLS step-halvings failed to reduce deviance in
> pwrssUpdate
> 
> g500.2 <-glmer(fate~(1|brood)+log(I(1+G500))+(log(I(1+G500^2))),
> family=binomial(link=logexp(FL1$Interval)), data=FL1, start=NULL)
> 
> # Warning for g500.2:
> 
> # Warning message:
>    # In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>                  # Model is nearly unidentifiable: large eigenvalue ratio
>                 # Rescale variables?
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From n@k@g@w@ @end|ng |rom hum@n@goy@-cu@@c@jp  Mon May 17 09:33:54 2021
From: n@k@g@w@ @end|ng |rom hum@n@goy@-cu@@c@jp (Atsuko Nakagawa)
Date: Mon, 17 May 2021 16:33:54 +0900
Subject: [R-sig-ME] Fwd: About warning
In-Reply-To: <ffbb4c00-7535-aa18-fd58-04a7492efc31@hum.nagoya-cu.ac.jp>
References: <ffbb4c00-7535-aa18-fd58-04a7492efc31@hum.nagoya-cu.ac.jp>
Message-ID: <fd894813-f64c-ce0b-d44f-8b5dc442b71d@hum.nagoya-cu.ac.jp>

Hi

I send the following mail last night.? Please help us.

-------- Forwarded Message --------
Subject: 	About warning
Date: 	Sun, 16 May 2021 19:10:21 +0900
From: 	Atsuko Nakagawa <nakagawa at hum.nagoya-cu.ac.jp>
To: 	r-sig-mixed-models at r-project.org


Hi

Thank you very much for your help.

When we ran Package lme4 to our longitudinal data, we got following 
warnings repeatedly.

> fixed-effect model matrix is rank deficient so dropping 2 columns / 
> coefficients
> boundary (singular) fit: see ?isSingular 
Nevertheless, we got some results. Are these valid?
When I look for the Q&A in some Statistic Forums, sometimes I found the 
previous answer that we do not have to care these warnings.

In actuality, how do we deal with these warnings?

Thank you for your time.

Atsuko Nakagawa

Graduate School of Humanities and Social Sciences, Nagoya City 
University, JAPAN




	[[alternative HTML version deleted]]


From me @end|ng |rom ph||||p@|d@y@com  Mon May 17 12:37:43 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Mon, 17 May 2021 12:37:43 +0200
Subject: [R-sig-ME] Fwd: About warning
In-Reply-To: <fd894813-f64c-ce0b-d44f-8b5dc442b71d@hum.nagoya-cu.ac.jp>
References: <ffbb4c00-7535-aa18-fd58-04a7492efc31@hum.nagoya-cu.ac.jp>
 <fd894813-f64c-ce0b-d44f-8b5dc442b71d@hum.nagoya-cu.ac.jp>
Message-ID: <a1bbd927-3b3d-e58a-c607-426034947d4b@phillipalday.com>

Hi,


Two things:

1. Please be patient -- it's been less than 24 hours on the weekend.
2. Please check the list for replies, in case somebody replies to the
list but not to your individual address. In particular, Ben Bolker
already replied to the list with an answer:

https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q2/029481.html

Good luck!

Best,
Phillip

On 17/5/21 9:33 am, Atsuko Nakagawa wrote:
> Hi
> 
> I send the following mail last night.? Please help us.
> 
> -------- Forwarded Message --------
> Subject: 	About warning
> Date: 	Sun, 16 May 2021 19:10:21 +0900
> From: 	Atsuko Nakagawa <nakagawa at hum.nagoya-cu.ac.jp>
> To: 	r-sig-mixed-models at r-project.org
> 
> 
> Hi
> 
> Thank you very much for your help.
> 
> When we ran Package lme4 to our longitudinal data, we got following 
> warnings repeatedly.
> 
>> fixed-effect model matrix is rank deficient so dropping 2 columns / 
>> coefficients
>> boundary (singular) fit: see ?isSingular 
> Nevertheless, we got some results. Are these valid?
> When I look for the Q&A in some Statistic Forums, sometimes I found the 
> previous answer that we do not have to care these warnings.
> 
> In actuality, how do we deal with these warnings?
> 
> Thank you for your time.
> 
> Atsuko Nakagawa
> 
> Graduate School of Humanities and Social Sciences, Nagoya City 
> University, JAPAN
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From mrm|500 @end|ng |rom york@@c@uk  Mon May 17 13:51:33 2021
From: mrm|500 @end|ng |rom york@@c@uk (Michael Lawson)
Date: Mon, 17 May 2021 12:51:33 +0100
Subject: [R-sig-ME] Model specification/family for a continuous/proportional
 response with many zeros
Message-ID: <CACtWw1GgDWo3Zng0+9_soe9nW1-S-ziZLEJNyzt4t7cz4ZxwVg@mail.gmail.com>

Hello,

I am new to GLMMs and have a dataset where I have two distinct groups (A
and B) of 7 individuals each. The data consists of repeated measurements of
each individual where the amount of time spent at either zone_A or zone_B
is recorded (out of a total time of 300s/observation period). For most of
the time period the individuals are in neither zone.

I want to test if group A and group B spend more time in zone A compared to
zone B (and vice versa).

Speaking to someone else, they said I should use a Binomial GLMM using
cbind. i.e.
cbind(time_at_zone_A, time_at_zone_B) ~ group + (1| id).

However, the response variable is continuous (albeit with an upper bound of
300 seconds per observation period), so I'm not sure if this is appropriate?

Should I convert the response into a proportion and use something like a
Beta GLMM or else use a continuous (Gamma) GLMM? e.g. something like:
prop_time ~ zone*group + (1|id)

The data is quite heavily right-skewed and contains a lot of 0's, so
reading around it also looks like I may need to convert these into a
zero-inflated/hurdle model?

Thank you for any suggestions,
Mike

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Mon May 17 14:22:41 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Mon, 17 May 2021 14:22:41 +0200
Subject: [R-sig-ME] 
 Model specification/family for a continuous/proportional
 response with many zeros
In-Reply-To: <CACtWw1GgDWo3Zng0+9_soe9nW1-S-ziZLEJNyzt4t7cz4ZxwVg@mail.gmail.com>
References: <CACtWw1GgDWo3Zng0+9_soe9nW1-S-ziZLEJNyzt4t7cz4ZxwVg@mail.gmail.com>
Message-ID: <CAJuCY5zh-A5LOjNc=tkVNhj2bhEBO+QFUMrjSu0aqBe_v9Qu7A@mail.gmail.com>

Dear Michael,

Your data has bounds (lower bound at 0 and upper bound at 300) and you have
a lot of data close to a boundary. In such a case, a continuous
distribution which ignores those bound is not a good idea. If the time
spent outside of both zones is limited, then a long time in zone A excludes
a long time in zone B by definition. Then I'd look towards a multinomial
distribution. If the time spent outside both zones is dominant, then you
can use a zero-inflated beta as you suggested. A zero-inflated gamma might
be OK if the data is not too close to the upper boundary. If you are
considering zero-inflated beta vs zero-inflated gamma, then you should
choose zero-inflated beta IMHO.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 17 mei 2021 om 13:52 schreef Michael Lawson via R-sig-mixed-models <
r-sig-mixed-models at r-project.org>:

> Hello,
>
> I am new to GLMMs and have a dataset where I have two distinct groups (A
> and B) of 7 individuals each. The data consists of repeated measurements of
> each individual where the amount of time spent at either zone_A or zone_B
> is recorded (out of a total time of 300s/observation period). For most of
> the time period the individuals are in neither zone.
>
> I want to test if group A and group B spend more time in zone A compared to
> zone B (and vice versa).
>
> Speaking to someone else, they said I should use a Binomial GLMM using
> cbind. i.e.
> cbind(time_at_zone_A, time_at_zone_B) ~ group + (1| id).
>
> However, the response variable is continuous (albeit with an upper bound of
> 300 seconds per observation period), so I'm not sure if this is
> appropriate?
>
> Should I convert the response into a proportion and use something like a
> Beta GLMM or else use a continuous (Gamma) GLMM? e.g. something like:
> prop_time ~ zone*group + (1|id)
>
> The data is quite heavily right-skewed and contains a lot of 0's, so
> reading around it also looks like I may need to convert these into a
> zero-inflated/hurdle model?
>
> Thank you for any suggestions,
> Mike
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From mrm|500 @end|ng |rom york@@c@uk  Mon May 17 15:45:16 2021
From: mrm|500 @end|ng |rom york@@c@uk (Michael Lawson)
Date: Mon, 17 May 2021 14:45:16 +0100
Subject: [R-sig-ME] 
 Model specification/family for a continuous/proportional
 response with many zeros
In-Reply-To: <CAJuCY5zh-A5LOjNc=tkVNhj2bhEBO+QFUMrjSu0aqBe_v9Qu7A@mail.gmail.com>
References: <CACtWw1GgDWo3Zng0+9_soe9nW1-S-ziZLEJNyzt4t7cz4ZxwVg@mail.gmail.com>
 <CAJuCY5zh-A5LOjNc=tkVNhj2bhEBO+QFUMrjSu0aqBe_v9Qu7A@mail.gmail.com>
Message-ID: <CACtWw1HcC8zSqhh_eG2E5222i4pz6vJdWLh+3Q=_Gx21vw3qvQ@mail.gmail.com>

Hi Thierry,

Thank you for your advice and speedy response.

Most of the data is closer to the lower bound (0). e.g. the mean time for
group A in zone A = 15.1 seconds and group A in zone B = 3.8 seconds.
However there are a very small number of outliers near the upper bound, the
largest being 294 out of the 300 seconds (see the attached file if you want
to look at the data).

I have taken a stab at running a Zero-inflated Beta GLMM using glmmTMB in R
like so:

betta_mod <- glmmTMB(prop_time ~ group*zone + (1|id),
                             family = beta_family(),
                             ziformula=~1,
                             data = glmm_zone_data)

summary(beta_mod)

*Family: beta  ( logit )*






*Formula:          prop_time ~ group * zone + (1 | id)Zero inflation:
      ~1Data: glmm_zone_data     AIC      BIC   logLik deviance df.resid
-763.6   -736.3    388.8   -777.6      359Random effects:Conditional
model: Groups Name        Variance  Std.Dev. id     (Intercept) 2.386e-09
4.885e-05Number of obs: 366, groups:  id, 14Overdispersion parameter for
beta family (): 13.1Conditional model:                  Estimate Std. Error
z value Pr(>|z|)    (Intercept)        -2.7685     0.1031 -26.844  < 2e-16
***groupB             -0.4455     0.1498  -2.975 0.002932 **zonezone_B
    -0.4179     0.1524  -2.741 0.006124 **groupB:zonezone_B   0.8443
0.2190   3.855 0.000116 ***---Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*?
0.05 ?.? 0.1 ? ? 1Zero-inflation model:            Estimate Std. Error z
value Pr(>|z|)    (Intercept)  -1.1804     0.1233  -9.575   <2e-16
***---Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1*

Does this look like the correct way of specifying the model? I am a little
confused about specifying and interpreting the zero-inflation component - I
have only just begun reading about this.

I noticed that the dispersion parameter is quite high at 13.1. I'm not sure
if this matters for beta models?. I tried running DHARMa simulateResiduals
on the model output and got significant deviations in the dispersion
(<2.2e-16) and KS tests. e.g.

DHARMa::testDispersion(beta_mod)

*DHARMa nonparametric dispersion test via sd of residuals fitted vs.
simulated*

*data:  simulationOutput*
*ratioObsSim = 1.3612, p-value < 2.2e-16*
*alternative hypothesis: two.sided*



Many thanks,
Mike

On Mon, 17 May 2021 at 13:22, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Michael,
>
> Your data has bounds (lower bound at 0 and upper bound at 300) and you
> have a lot of data close to a boundary. In such a case, a continuous
> distribution which ignores those bound is not a good idea. If the time
> spent outside of both zones is limited, then a long time in zone A excludes
> a long time in zone B by definition. Then I'd look towards a multinomial
> distribution. If the time spent outside both zones is dominant, then you
> can use a zero-inflated beta as you suggested. A zero-inflated gamma might
> be OK if the data is not too close to the upper boundary. If you are
> considering zero-inflated beta vs zero-inflated gamma, then you should
> choose zero-inflated beta IMHO.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op ma 17 mei 2021 om 13:52 schreef Michael Lawson via R-sig-mixed-models <
> r-sig-mixed-models at r-project.org>:
>
>> Hello,
>>
>> I am new to GLMMs and have a dataset where I have two distinct groups (A
>> and B) of 7 individuals each. The data consists of repeated measurements
>> of
>> each individual where the amount of time spent at either zone_A or zone_B
>> is recorded (out of a total time of 300s/observation period). For most of
>> the time period the individuals are in neither zone.
>>
>> I want to test if group A and group B spend more time in zone A compared
>> to
>> zone B (and vice versa).
>>
>> Speaking to someone else, they said I should use a Binomial GLMM using
>> cbind. i.e.
>> cbind(time_at_zone_A, time_at_zone_B) ~ group + (1| id).
>>
>> However, the response variable is continuous (albeit with an upper bound
>> of
>> 300 seconds per observation period), so I'm not sure if this is
>> appropriate?
>>
>> Should I convert the response into a proportion and use something like a
>> Beta GLMM or else use a continuous (Gamma) GLMM? e.g. something like:
>> prop_time ~ zone*group + (1|id)
>>
>> The data is quite heavily right-skewed and contains a lot of 0's, so
>> reading around it also looks like I may need to convert these into a
>> zero-inflated/hurdle model?
>>
>> Thank you for any suggestions,
>> Mike
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

From me @end|ng |rom ph||||p@|d@y@com  Mon May 17 17:38:17 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Mon, 17 May 2021 17:38:17 +0200
Subject: [R-sig-ME] About warning
In-Reply-To: <dd7a9b9b-6e61-42cd-da64-d64b4e3e970d@gmail.com>
References: <ffbb4c00-7535-aa18-fd58-04a7492efc31@hum.nagoya-cu.ac.jp>
 <dd7a9b9b-6e61-42cd-da64-d64b4e3e970d@gmail.com>
Message-ID: <778bc171-e34a-2196-27fd-285976071a2d@phillipalday.com>



On 16/5/21 11:28 pm, Ben Bolker wrote:
> ?You can look at your results to figure out which coefficients are
> missing, or you can use attr(getME(m,"X"), "col.dropped") to see which
> columns of the original model frame were dropped.? (It would be useful
> if I or someone would write a more detailed diagnostic function to
> report which columns of the original model matrix were collinear ...)
> 

There is the findLinearCombos() function in the caret package:


https://www.rdocumentation.org/packages/caret/versions/6.0-86/topics/findLinearCombos


From k|r@t|@|ynn @end|ng |rom gm@||@com  Mon May 17 19:43:27 2021
From: k|r@t|@|ynn @end|ng |rom gm@||@com (Kirsti Carr)
Date: Mon, 17 May 2021 09:43:27 -0800
Subject: [R-sig-ME] Logistic exposure glmer polynomial covariate issue
Message-ID: <CAL04JRXeq4jGjiKV=1kFx5=1xT50M3-HQM61kV3VoZCP5OP_FQ@mail.gmail.com>

Hi Ben,

Thank you for your thoughts. I will look into cloglog and your other
suggestions. I should note that the data I provided was not the full
dataset (after reading the recommendations for posting I decided to provide
a minimum dataset that still produced the error). Actual effective sample
size/ number of failures is 23. Still small -- so perhaps taking out the
cubic and quadratic models is best? I can also provide full dataset if
necessary.

Thanks so much,
Kirsti

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Mon May 17 21:06:10 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 17 May 2021 15:06:10 -0400
Subject: [R-sig-ME] Logistic exposure glmer polynomial covariate issue
In-Reply-To: <CAL04JRXeq4jGjiKV=1kFx5=1xT50M3-HQM61kV3VoZCP5OP_FQ@mail.gmail.com>
References: <CAL04JRXeq4jGjiKV=1kFx5=1xT50M3-HQM61kV3VoZCP5OP_FQ@mail.gmail.com>
Message-ID: <724b7e96-e218-4b55-3f70-9abebeb16427@gmail.com>

   I worked on this a little more, posted at

https://github.com/bbolker/mixedmodels-misc/blob/master/notes/rsm_logexp.R

   I tried the power-logistic link and got it to work with linear (but 
not quadratic) models: it does appear to do a bit better on this data 
set, although with the small sample I wouldn't take that too seriously. 
(I left the predictor as G250, not log(1+G250).)

   I would certainly try some of this stuff out on your full data set 
(but be careful not to fish/snoop too much ...)

On 5/17/21 1:43 PM, Kirsti Carr wrote:
> Hi Ben,
> 
> Thank you for your thoughts. I will look into cloglog and your other
> suggestions. I should note that the data I provided was not the full
> dataset (after reading the recommendations for posting I decided to provide
> a minimum dataset that still produced the error). Actual effective sample
> size/ number of failures is 23. Still small -- so perhaps taking out the
> cubic and quadratic models is best? I can also provide full dataset if
> necessary.
> 
> Thanks so much,
> Kirsti
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From th|erry@onke||nx @end|ng |rom |nbo@be  Tue May 18 09:12:38 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Tue, 18 May 2021 09:12:38 +0200
Subject: [R-sig-ME] 
 Model specification/family for a continuous/proportional
 response with many zeros
In-Reply-To: <CACtWw1HcC8zSqhh_eG2E5222i4pz6vJdWLh+3Q=_Gx21vw3qvQ@mail.gmail.com>
References: <CACtWw1GgDWo3Zng0+9_soe9nW1-S-ziZLEJNyzt4t7cz4ZxwVg@mail.gmail.com>
 <CAJuCY5zh-A5LOjNc=tkVNhj2bhEBO+QFUMrjSu0aqBe_v9Qu7A@mail.gmail.com>
 <CACtWw1HcC8zSqhh_eG2E5222i4pz6vJdWLh+3Q=_Gx21vw3qvQ@mail.gmail.com>
Message-ID: <CAJuCY5yDWyj+EhZOntYFTwdyATX0+W4yWz7xvnAEYxR6eTh6-w@mail.gmail.com>

Dear Mike,

The zero-inflation is specified on the logit scale. plogis(-1.18) = 0.235
23.5% zero seems reasonable when reading your story. (Didn't look at the
data).

You need to look at the definition for the "over"dispersion parameter. For
a beta distribution is \phi with Var(y) = \mu * (1 - \mu) / (\phi + 1) (see
?glmmTMB::beta_family) Hence a large value of \phi implies a low variance.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 17 mei 2021 om 15:45 schreef Michael Lawson <mrml500 at york.ac.uk>:

> Hi Thierry,
>
> Thank you for your advice and speedy response.
>
> Most of the data is closer to the lower bound (0). e.g. the mean time for
> group A in zone A = 15.1 seconds and group A in zone B = 3.8 seconds.
> However there are a very small number of outliers near the upper bound, the
> largest being 294 out of the 300 seconds (see the attached file if you want
> to look at the data).
>
> I have taken a stab at running a Zero-inflated Beta GLMM using glmmTMB in
> R like so:
>
> betta_mod <- glmmTMB(prop_time ~ group*zone + (1|id),
>                              family = beta_family(),
>                              ziformula=~1,
>                              data = glmm_zone_data)
>
> summary(beta_mod)
>
> *Family: beta  ( logit )*
>
>
>
>
>
>
> *Formula:          prop_time ~ group * zone + (1 | id)Zero inflation:
>         ~1Data: glmm_zone_data     AIC      BIC   logLik deviance df.resid
> -763.6   -736.3    388.8   -777.6      359Random effects:Conditional
> model: Groups Name        Variance  Std.Dev. id     (Intercept) 2.386e-09
> 4.885e-05Number of obs: 366, groups:  id, 14Overdispersion parameter for
> beta family (): 13.1Conditional model:                  Estimate Std. Error
> z value Pr(>|z|)    (Intercept)        -2.7685     0.1031 -26.844  < 2e-16
> ***groupB             -0.4455     0.1498  -2.975 0.002932 **zonezone_B
>     -0.4179     0.1524  -2.741 0.006124 **groupB:zonezone_B   0.8443
> 0.2190   3.855 0.000116 ***---Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*?
> 0.05 ?.? 0.1 ? ? 1Zero-inflation model:            Estimate Std. Error z
> value Pr(>|z|)    (Intercept)  -1.1804     0.1233  -9.575   <2e-16
> ***---Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1*
>
> Does this look like the correct way of specifying the model? I am a little
> confused about specifying and interpreting the zero-inflation component - I
> have only just begun reading about this.
>
> I noticed that the dispersion parameter is quite high at 13.1. I'm not
> sure if this matters for beta models?. I tried running DHARMa
> simulateResiduals on the model output and got significant deviations in the
> dispersion (<2.2e-16) and KS tests. e.g.
>
> DHARMa::testDispersion(beta_mod)
>
> *DHARMa nonparametric dispersion test via sd of residuals fitted vs.
> simulated*
>
> *data:  simulationOutput*
> *ratioObsSim = 1.3612, p-value < 2.2e-16*
> *alternative hypothesis: two.sided*
>
>
>
> Many thanks,
> Mike
>
> On Mon, 17 May 2021 at 13:22, Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>
>> Dear Michael,
>>
>> Your data has bounds (lower bound at 0 and upper bound at 300) and you
>> have a lot of data close to a boundary. In such a case, a continuous
>> distribution which ignores those bound is not a good idea. If the time
>> spent outside of both zones is limited, then a long time in zone A excludes
>> a long time in zone B by definition. Then I'd look towards a multinomial
>> distribution. If the time spent outside both zones is dominant, then you
>> can use a zero-inflated beta as you suggested. A zero-inflated gamma might
>> be OK if the data is not too close to the upper boundary. If you are
>> considering zero-inflated beta vs zero-inflated gamma, then you should
>> choose zero-inflated beta IMHO.
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>> AND FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88 bus 73, 1000 Brussel
>> www.inbo.be
>>
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>
>> <https://www.inbo.be>
>>
>>
>> Op ma 17 mei 2021 om 13:52 schreef Michael Lawson via R-sig-mixed-models <
>> r-sig-mixed-models at r-project.org>:
>>
>>> Hello,
>>>
>>> I am new to GLMMs and have a dataset where I have two distinct groups (A
>>> and B) of 7 individuals each. The data consists of repeated measurements
>>> of
>>> each individual where the amount of time spent at either zone_A or zone_B
>>> is recorded (out of a total time of 300s/observation period). For most of
>>> the time period the individuals are in neither zone.
>>>
>>> I want to test if group A and group B spend more time in zone A compared
>>> to
>>> zone B (and vice versa).
>>>
>>> Speaking to someone else, they said I should use a Binomial GLMM using
>>> cbind. i.e.
>>> cbind(time_at_zone_A, time_at_zone_B) ~ group + (1| id).
>>>
>>> However, the response variable is continuous (albeit with an upper bound
>>> of
>>> 300 seconds per observation period), so I'm not sure if this is
>>> appropriate?
>>>
>>> Should I convert the response into a proportion and use something like a
>>> Beta GLMM or else use a continuous (Gamma) GLMM? e.g. something like:
>>> prop_time ~ zone*group + (1|id)
>>>
>>> The data is quite heavily right-skewed and contains a lot of 0's, so
>>> reading around it also looks like I may need to convert these into a
>>> zero-inflated/hurdle model?
>>>
>>> Thank you for any suggestions,
>>> Mike
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>

	[[alternative HTML version deleted]]


From mrm|500 @end|ng |rom york@@c@uk  Tue May 18 12:49:44 2021
From: mrm|500 @end|ng |rom york@@c@uk (Michael Lawson)
Date: Tue, 18 May 2021 11:49:44 +0100
Subject: [R-sig-ME] 
 Model specification/family for a continuous/proportional
 response with many zeros
In-Reply-To: <CAJuCY5yDWyj+EhZOntYFTwdyATX0+W4yWz7xvnAEYxR6eTh6-w@mail.gmail.com>
References: <CACtWw1GgDWo3Zng0+9_soe9nW1-S-ziZLEJNyzt4t7cz4ZxwVg@mail.gmail.com>
 <CAJuCY5zh-A5LOjNc=tkVNhj2bhEBO+QFUMrjSu0aqBe_v9Qu7A@mail.gmail.com>
 <CACtWw1HcC8zSqhh_eG2E5222i4pz6vJdWLh+3Q=_Gx21vw3qvQ@mail.gmail.com>
 <CAJuCY5yDWyj+EhZOntYFTwdyATX0+W4yWz7xvnAEYxR6eTh6-w@mail.gmail.com>
Message-ID: <CACtWw1Fv2e94+X9ZcQih+WHC4dHt+xnACa04M2_hkKWjc1jP0g@mail.gmail.com>

Dear Thierry,

Thanks for the help. So if the dispersion parameter in this model doesn't
fit with the beta distribution, are there any alternative approaches I can
use?

I can't seem to find much information on this elsewhere other than these
two threads:
https://stats.stackexchange.com/a/451453/233414
https://stats.stackexchange.com/a/466951/233414

All the best,
Mike

On Tue, 18 May 2021 at 08:12, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Mike,
>
> The zero-inflation is specified on the logit scale. plogis(-1.18) = 0.235
> 23.5% zero seems reasonable when reading your story. (Didn't look at the
> data).
>
> You need to look at the definition for the "over"dispersion parameter. For
> a beta distribution is \phi with Var(y) = \mu * (1 - \mu) / (\phi + 1) (see
> ?glmmTMB::beta_family) Hence a large value of \phi implies a low variance.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op ma 17 mei 2021 om 15:45 schreef Michael Lawson <mrml500 at york.ac.uk>:
>
>> Hi Thierry,
>>
>> Thank you for your advice and speedy response.
>>
>> Most of the data is closer to the lower bound (0). e.g. the mean time for
>> group A in zone A = 15.1 seconds and group A in zone B = 3.8 seconds.
>> However there are a very small number of outliers near the upper bound, the
>> largest being 294 out of the 300 seconds (see the attached file if you want
>> to look at the data).
>>
>> I have taken a stab at running a Zero-inflated Beta GLMM using glmmTMB in
>> R like so:
>>
>> betta_mod <- glmmTMB(prop_time ~ group*zone + (1|id),
>>                              family = beta_family(),
>>                              ziformula=~1,
>>                              data = glmm_zone_data)
>>
>> summary(beta_mod)
>>
>> *Family: beta  ( logit )*
>>
>>
>>
>>
>>
>>
>> *Formula:          prop_time ~ group * zone + (1 | id)Zero inflation:
>>         ~1Data: glmm_zone_data     AIC      BIC   logLik deviance df.resid
>> -763.6   -736.3    388.8   -777.6      359Random effects:Conditional
>> model: Groups Name        Variance  Std.Dev. id     (Intercept) 2.386e-09
>> 4.885e-05Number of obs: 366, groups:  id, 14Overdispersion parameter for
>> beta family (): 13.1Conditional model:                  Estimate Std. Error
>> z value Pr(>|z|)    (Intercept)        -2.7685     0.1031 -26.844  < 2e-16
>> ***groupB             -0.4455     0.1498  -2.975 0.002932 **zonezone_B
>>     -0.4179     0.1524  -2.741 0.006124 **groupB:zonezone_B   0.8443
>> 0.2190   3.855 0.000116 ***---Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*?
>> 0.05 ?.? 0.1 ? ? 1Zero-inflation model:            Estimate Std. Error z
>> value Pr(>|z|)    (Intercept)  -1.1804     0.1233  -9.575   <2e-16
>> ***---Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1*
>>
>> Does this look like the correct way of specifying the model? I am a
>> little confused about specifying and interpreting the zero-inflation
>> component - I have only just begun reading about this.
>>
>> I noticed that the dispersion parameter is quite high at 13.1. I'm not
>> sure if this matters for beta models?. I tried running DHARMa
>> simulateResiduals on the model output and got significant deviations in the
>> dispersion (<2.2e-16) and KS tests. e.g.
>>
>> DHARMa::testDispersion(beta_mod)
>>
>> *DHARMa nonparametric dispersion test via sd of residuals fitted vs.
>> simulated*
>>
>> *data:  simulationOutput*
>> *ratioObsSim = 1.3612, p-value < 2.2e-16*
>> *alternative hypothesis: two.sided*
>>
>>
>>
>> Many thanks,
>> Mike
>>
>> On Mon, 17 May 2021 at 13:22, Thierry Onkelinx <thierry.onkelinx at inbo.be>
>> wrote:
>>
>>> Dear Michael,
>>>
>>> Your data has bounds (lower bound at 0 and upper bound at 300) and you
>>> have a lot of data close to a boundary. In such a case, a continuous
>>> distribution which ignores those bound is not a good idea. If the time
>>> spent outside of both zones is limited, then a long time in zone A excludes
>>> a long time in zone B by definition. Then I'd look towards a multinomial
>>> distribution. If the time spent outside both zones is dominant, then you
>>> can use a zero-inflated beta as you suggested. A zero-inflated gamma might
>>> be OK if the data is not too close to the upper boundary. If you are
>>> considering zero-inflated beta vs zero-inflated gamma, then you should
>>> choose zero-inflated beta IMHO.
>>>
>>> Best regards,
>>>
>>> ir. Thierry Onkelinx
>>> Statisticus / Statistician
>>>
>>> Vlaamse Overheid / Government of Flanders
>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>>> AND FOREST
>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>> thierry.onkelinx at inbo.be
>>> Havenlaan 88 bus 73, 1000 Brussel
>>> www.inbo.be
>>>
>>>
>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of data.
>>> ~ John Tukey
>>>
>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>
>>> <https://www.inbo.be>
>>>
>>>
>>> Op ma 17 mei 2021 om 13:52 schreef Michael Lawson via R-sig-mixed-models
>>> <r-sig-mixed-models at r-project.org>:
>>>
>>>> Hello,
>>>>
>>>> I am new to GLMMs and have a dataset where I have two distinct groups (A
>>>> and B) of 7 individuals each. The data consists of repeated
>>>> measurements of
>>>> each individual where the amount of time spent at either zone_A or
>>>> zone_B
>>>> is recorded (out of a total time of 300s/observation period). For most
>>>> of
>>>> the time period the individuals are in neither zone.
>>>>
>>>> I want to test if group A and group B spend more time in zone A
>>>> compared to
>>>> zone B (and vice versa).
>>>>
>>>> Speaking to someone else, they said I should use a Binomial GLMM using
>>>> cbind. i.e.
>>>> cbind(time_at_zone_A, time_at_zone_B) ~ group + (1| id).
>>>>
>>>> However, the response variable is continuous (albeit with an upper
>>>> bound of
>>>> 300 seconds per observation period), so I'm not sure if this is
>>>> appropriate?
>>>>
>>>> Should I convert the response into a proportion and use something like a
>>>> Beta GLMM or else use a continuous (Gamma) GLMM? e.g. something like:
>>>> prop_time ~ zone*group + (1|id)
>>>>
>>>> The data is quite heavily right-skewed and contains a lot of 0's, so
>>>> reading around it also looks like I may need to convert these into a
>>>> zero-inflated/hurdle model?
>>>>
>>>> Thank you for any suggestions,
>>>> Mike
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Tue May 18 14:56:49 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Tue, 18 May 2021 14:56:49 +0200
Subject: [R-sig-ME] 
 Model specification/family for a continuous/proportional
 response with many zeros
In-Reply-To: <CACtWw1Fv2e94+X9ZcQih+WHC4dHt+xnACa04M2_hkKWjc1jP0g@mail.gmail.com>
References: <CACtWw1GgDWo3Zng0+9_soe9nW1-S-ziZLEJNyzt4t7cz4ZxwVg@mail.gmail.com>
 <CAJuCY5zh-A5LOjNc=tkVNhj2bhEBO+QFUMrjSu0aqBe_v9Qu7A@mail.gmail.com>
 <CACtWw1HcC8zSqhh_eG2E5222i4pz6vJdWLh+3Q=_Gx21vw3qvQ@mail.gmail.com>
 <CAJuCY5yDWyj+EhZOntYFTwdyATX0+W4yWz7xvnAEYxR6eTh6-w@mail.gmail.com>
 <CACtWw1Fv2e94+X9ZcQih+WHC4dHt+xnACa04M2_hkKWjc1jP0g@mail.gmail.com>
Message-ID: <CAJuCY5w9erbtEOeRbxkZdLxRYOd_t22g6HEC2US7Wrwm7=jjxQ@mail.gmail.com>

Dear Mike,

I think you misread my reply. I never stated that there's something wrong
with the model. The only "problem" I highlighted was your misconception
about the "high overdispersion". In this case, a high parameter value
indicates a low variance, which is what we mostly want to see.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op di 18 mei 2021 om 12:49 schreef Michael Lawson <mrml500 at york.ac.uk>:

> Dear Thierry,
>
> Thanks for the help. So if the dispersion parameter in this model doesn't
> fit with the beta distribution, are there any alternative approaches I can
> use?
>
> I can't seem to find much information on this elsewhere other than these
> two threads:
> https://stats.stackexchange.com/a/451453/233414
> https://stats.stackexchange.com/a/466951/233414
>
> All the best,
> Mike
>
> On Tue, 18 May 2021 at 08:12, Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>
>> Dear Mike,
>>
>> The zero-inflation is specified on the logit scale. plogis(-1.18) = 0.235
>> 23.5% zero seems reasonable when reading your story. (Didn't look at the
>> data).
>>
>> You need to look at the definition for the "over"dispersion parameter.
>> For a beta distribution is \phi with Var(y) = \mu * (1 - \mu) / (\phi + 1)
>> (see ?glmmTMB::beta_family) Hence a large value of \phi implies a low
>> variance.
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>> AND FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88 bus 73, 1000 Brussel
>> www.inbo.be
>>
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>
>> <https://www.inbo.be>
>>
>>
>> Op ma 17 mei 2021 om 15:45 schreef Michael Lawson <mrml500 at york.ac.uk>:
>>
>>> Hi Thierry,
>>>
>>> Thank you for your advice and speedy response.
>>>
>>> Most of the data is closer to the lower bound (0). e.g. the mean time
>>> for group A in zone A = 15.1 seconds and group A in zone B = 3.8 seconds.
>>> However there are a very small number of outliers near the upper bound, the
>>> largest being 294 out of the 300 seconds (see the attached file if you want
>>> to look at the data).
>>>
>>> I have taken a stab at running a Zero-inflated Beta GLMM using glmmTMB
>>> in R like so:
>>>
>>> betta_mod <- glmmTMB(prop_time ~ group*zone + (1|id),
>>>                              family = beta_family(),
>>>                              ziformula=~1,
>>>                              data = glmm_zone_data)
>>>
>>> summary(beta_mod)
>>>
>>> *Family: beta  ( logit )*
>>>
>>>
>>>
>>>
>>>
>>>
>>> *Formula:          prop_time ~ group * zone + (1 | id)Zero inflation:
>>>           ~1Data: glmm_zone_data     AIC      BIC   logLik deviance
>>> df.resid  -763.6   -736.3    388.8   -777.6      359Random
>>> effects:Conditional model: Groups Name        Variance  Std.Dev. id
>>> (Intercept) 2.386e-09 4.885e-05Number of obs: 366, groups:  id,
>>> 14Overdispersion parameter for beta family (): 13.1Conditional model:
>>>             Estimate Std. Error z value Pr(>|z|)    (Intercept)
>>>  -2.7685     0.1031 -26.844  < 2e-16 ***groupB             -0.4455
>>> 0.1498  -2.975 0.002932 **zonezone_B         -0.4179     0.1524  -2.741
>>> 0.006124 **groupB:zonezone_B   0.8443     0.2190   3.855 0.000116
>>> ***---Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ?
>>> 1Zero-inflation model:            Estimate Std. Error z value Pr(>|z|)
>>>   (Intercept)  -1.1804     0.1233  -9.575   <2e-16 ***---Signif. codes:  0
>>> ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1*
>>>
>>> Does this look like the correct way of specifying the model? I am a
>>> little confused about specifying and interpreting the zero-inflation
>>> component - I have only just begun reading about this.
>>>
>>> I noticed that the dispersion parameter is quite high at 13.1. I'm not
>>> sure if this matters for beta models?. I tried running DHARMa
>>> simulateResiduals on the model output and got significant deviations in the
>>> dispersion (<2.2e-16) and KS tests. e.g.
>>>
>>> DHARMa::testDispersion(beta_mod)
>>>
>>> *DHARMa nonparametric dispersion test via sd of residuals fitted vs.
>>> simulated*
>>>
>>> *data:  simulationOutput*
>>> *ratioObsSim = 1.3612, p-value < 2.2e-16*
>>> *alternative hypothesis: two.sided*
>>>
>>>
>>>
>>> Many thanks,
>>> Mike
>>>
>>> On Mon, 17 May 2021 at 13:22, Thierry Onkelinx <thierry.onkelinx at inbo.be>
>>> wrote:
>>>
>>>> Dear Michael,
>>>>
>>>> Your data has bounds (lower bound at 0 and upper bound at 300) and you
>>>> have a lot of data close to a boundary. In such a case, a continuous
>>>> distribution which ignores those bound is not a good idea. If the time
>>>> spent outside of both zones is limited, then a long time in zone A excludes
>>>> a long time in zone B by definition. Then I'd look towards a multinomial
>>>> distribution. If the time spent outside both zones is dominant, then you
>>>> can use a zero-inflated beta as you suggested. A zero-inflated gamma might
>>>> be OK if the data is not too close to the upper boundary. If you are
>>>> considering zero-inflated beta vs zero-inflated gamma, then you should
>>>> choose zero-inflated beta IMHO.
>>>>
>>>> Best regards,
>>>>
>>>> ir. Thierry Onkelinx
>>>> Statisticus / Statistician
>>>>
>>>> Vlaamse Overheid / Government of Flanders
>>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>>>> AND FOREST
>>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>>> thierry.onkelinx at inbo.be
>>>> Havenlaan 88 bus 73, 1000 Brussel
>>>> www.inbo.be
>>>>
>>>>
>>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>> To call in the statistician after the experiment is done may be no more
>>>> than asking him to perform a post-mortem examination: he may be able to say
>>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>> The combination of some data and an aching desire for an answer does
>>>> not ensure that a reasonable answer can be extracted from a given body of
>>>> data. ~ John Tukey
>>>>
>>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>>
>>>> <https://www.inbo.be>
>>>>
>>>>
>>>> Op ma 17 mei 2021 om 13:52 schreef Michael Lawson via
>>>> R-sig-mixed-models <r-sig-mixed-models at r-project.org>:
>>>>
>>>>> Hello,
>>>>>
>>>>> I am new to GLMMs and have a dataset where I have two distinct groups
>>>>> (A
>>>>> and B) of 7 individuals each. The data consists of repeated
>>>>> measurements of
>>>>> each individual where the amount of time spent at either zone_A or
>>>>> zone_B
>>>>> is recorded (out of a total time of 300s/observation period). For most
>>>>> of
>>>>> the time period the individuals are in neither zone.
>>>>>
>>>>> I want to test if group A and group B spend more time in zone A
>>>>> compared to
>>>>> zone B (and vice versa).
>>>>>
>>>>> Speaking to someone else, they said I should use a Binomial GLMM using
>>>>> cbind. i.e.
>>>>> cbind(time_at_zone_A, time_at_zone_B) ~ group + (1| id).
>>>>>
>>>>> However, the response variable is continuous (albeit with an upper
>>>>> bound of
>>>>> 300 seconds per observation period), so I'm not sure if this is
>>>>> appropriate?
>>>>>
>>>>> Should I convert the response into a proportion and use something like
>>>>> a
>>>>> Beta GLMM or else use a continuous (Gamma) GLMM? e.g. something like:
>>>>> prop_time ~ zone*group + (1|id)
>>>>>
>>>>> The data is quite heavily right-skewed and contains a lot of 0's, so
>>>>> reading around it also looks like I may need to convert these into a
>>>>> zero-inflated/hurdle model?
>>>>>
>>>>> Thank you for any suggestions,
>>>>> Mike
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>

	[[alternative HTML version deleted]]


From n@k@g@w@ @end|ng |rom hum@n@goy@-cu@@c@jp  Tue May 18 16:25:18 2021
From: n@k@g@w@ @end|ng |rom hum@n@goy@-cu@@c@jp (Atsuko Nakagawa)
Date: Tue, 18 May 2021 23:25:18 +0900
Subject: [R-sig-ME] the model with warning
Message-ID: <639214a8-5576-2afc-762e-6373b3824978@hum.nagoya-cu.ac.jp>

Hi

Thank you so much. But if so, can I report these results in my academic 
paper? Or how can I report these results properly to reviewers in my 
paper ? Or do we have to continue to find the model without warning for 
the academic paper?? If you have any suggestion, please let me know.

Atsu


From bbo|ker @end|ng |rom gm@||@com  Tue May 18 18:00:17 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 18 May 2021 12:00:17 -0400
Subject: [R-sig-ME] the model with warning
In-Reply-To: <639214a8-5576-2afc-762e-6373b3824978@hum.nagoya-cu.ac.jp>
References: <639214a8-5576-2afc-762e-6373b3824978@hum.nagoya-cu.ac.jp>
Message-ID: <dd99b500-c2f8-7fae-b14a-8499849a3d26@gmail.com>

    (Personal opinion follows.) I don't think you need to report these 
warnings in the main section of a paper **as long as you understand what 
they are telling you and are reasonably certain that they do not 
represent a problem with the interpretation/robustness of your 
results**.  These are kinds of the details that would go into 
supplementary material, if at all.

   But this does sound like it might be a case where you should try to 
find more dedicated statistical advice than you can get from an internet 
forum ...

   Ben Bolker

On 5/18/21 10:25 AM, Atsuko Nakagawa wrote:
> Hi
> 
> Thank you so much. But if so, can I report these results in my academic 
> paper? Or how can I report these results properly to reviewers in my 
> paper ? Or do we have to continue to find the model without warning for 
> the academic paper?? If you have any suggestion, please let me know.
> 
> Atsu
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From th|erry@onke||nx @end|ng |rom |nbo@be  Tue May 18 18:51:49 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Tue, 18 May 2021 18:51:49 +0200
Subject: [R-sig-ME] the model with warning
In-Reply-To: <dd99b500-c2f8-7fae-b14a-8499849a3d26@gmail.com>
References: <639214a8-5576-2afc-762e-6373b3824978@hum.nagoya-cu.ac.jp>
 <dd99b500-c2f8-7fae-b14a-8499849a3d26@gmail.com>
Message-ID: <CAJuCY5yeAx53+-jiA1TF5uZPmMDBXKjXDR5CAMEqxWY0kAt_NA@mail.gmail.com>

I second Ben's suggestions. You need a statistician to look into your data
and model in order to get an idea why and where the rank deficiency occurs.
Only then you'll know how you can either solve that problem or if it's safe
to ignore it.

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op di 18 mei 2021 om 18:00 schreef Ben Bolker <bbolker at gmail.com>:

>     (Personal opinion follows.) I don't think you need to report these
> warnings in the main section of a paper **as long as you understand what
> they are telling you and are reasonably certain that they do not
> represent a problem with the interpretation/robustness of your
> results**.  These are kinds of the details that would go into
> supplementary material, if at all.
>
>    But this does sound like it might be a case where you should try to
> find more dedicated statistical advice than you can get from an internet
> forum ...
>
>    Ben Bolker
>
> On 5/18/21 10:25 AM, Atsuko Nakagawa wrote:
> > Hi
> >
> > Thank you so much. But if so, can I report these results in my academic
> > paper? Or how can I report these results properly to reviewers in my
> > paper ? Or do we have to continue to find the model without warning for
> > the academic paper?  If you have any suggestion, please let me know.
> >
> > Atsu
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Wed May 19 02:56:23 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 18 May 2021 20:56:23 -0400
Subject: [R-sig-ME] glmer and influence.me - complaining about nAGQ==0
In-Reply-To: <c282453c-2710-b14d-4565-685e7d42c1c8@gmail.com>
References: <c282453c-2710-b14d-4565-685e7d42c1c8@gmail.com>
Message-ID: <8e372080-bd03-d384-4772-73bc5e007da8@gmail.com>


  [Replying to list]

   Good meta-question.

   You can check the archives at 
https://stat.ethz.ch/pipermail/r-sig-mixed-models/ to make sure you 
haven't missed a reply.

   Unfortunately, since this is an all-volunteer forum, there's no 
particular guarantee that people will remain interested in a thread/get 
around to answering your questions. IMO it's reasonable etiquette to 
"bump"/remind readers about a question that has been languishing for 
some time (once you've allowed a reasonable time for an answer, e.g. a 
few days); it may be helpful to include a link, in this case 
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q2/029477.html , 
to help people re-locate the question.

   It would be OK to try your luck in another forum such as 
CrossValidated; it would be polite and useful if/when you post there to 
provide a link to this thread so people can see what has already been 
discussed (although you should also provide a good summary there, so 
readers don't *have* to come trawl through the archives).

   A few more points since I'm responding:

* From your _original_ problem; I've updated the influence.merMod() 
method in the *development* version of lme4 so that it doesn't choke 
when nAGQ=0 (the starting value can be set manually, but it also checks 
and does the right thing by default when nAGQ is 0). If you're able to 
installed packages with compiled code from source 
(remotes::install_github("lme4/lme4")), you should be able to run 
influence() on your original model.

* The gold standard for whether convergence warnings are really a 
problem or not is allFit().  If you run allFit(), and the results from a 
range of optimizers **are sufficiently similar to each other for your 
scientific purposes**, then you can feel free to disregard convergence 
warnings (at that point it doesn't really matter how nasty the warnings 
sound).

* You _might_ try simplifying the model a little bit, e.g. removing the 
Session : Probability interaction in the random effects term (the 
standard deviation for that component is 5 times smaller than the 
intercept variation, and 29 times smaller than the residual variation term).


  One tiny final point: please don't use the salutation "Dear Professor 
Bolker" when responding to the list - even though I might be answering 
your question at the moment, the query is still to the whole list.

   cheers
     Ben Bolker



On 5/18/21 3:10 PM, C?tia Ferreira De Oliveira wrote:
> Hello,
> 
> I am sorry for bothering you but I have asked a follow-up question and I 
> haven't obtained a response, I wonder if it will ever be responded to as 
> I don't know if there is any way of keeping track of which questions get 
> or not answered. If not, I may need to try my luck on crossvalidated?as 
> it is quite a timely problem that I am experiencing with the models. 
> After removing the "logRT" from the glmer model I got a lot more 
> convergence issues, so I am left wondering if having the logRT would be 
> problematic. If so, would there be other options for me on what to do to 
> be able to model this data.
> 
> Best wishes,
> 
> Catia
> 
> -- 
> C?tia Margarida Ferreira de Oliveira
> Psychology PhD Student
> Department of Psychology, Room B214
> University of York, YO10 5DD


From cm|o500 @end|ng |rom york@@c@uk  Wed May 19 03:19:01 2021
From: cm|o500 @end|ng |rom york@@c@uk (=?UTF-8?Q?C=C3=A1tia_Ferreira_De_Oliveira?=)
Date: Wed, 19 May 2021 02:19:01 +0100
Subject: [R-sig-ME] Follow-up question
In-Reply-To: <CACw+TfezL8Oi2Z9MuDVfuVFtjxwH7vq1zM4zUBewGW6KmX2mEA@mail.gmail.com>
References: <CACw+Tfe1LYRRF9Q9PoffG8YXscO88i+C0bK8_3mjsy34SgkNzw@mail.gmail.com>
 <c282453c-2710-b14d-4565-685e7d42c1c8@gmail.com>
 <CACw+TfezL8Oi2Z9MuDVfuVFtjxwH7vq1zM4zUBewGW6KmX2mEA@mail.gmail.com>
Message-ID: <CACw+TfedOT0og1JPQOta5bqwjAj9LmB965=Eh07qWj6U-Vjmvg@mail.gmail.com>

>
>
Thank you for your reply!

>
I have run the allfit() function and it has shown some inconsistency in the
results. Are there any practical issues with running glmer(logRT) other
than interpretability? I have run simpler models but they still complain
about convergence. Even those with just a random intercept.

>
Thank you!

>
Best wishes,

>
C?tia



> A quarta, 19/05/2021, 01:52, Ben Bolker <bbolker at gmail.com> escreveu:
>
>>    Good meta-question.
>>
>>    You can check the archives at
>> https://stat.ethz.ch/pipermail/r-sig-mixed-models/ to make sure you
>> haven't missed a reply.
>>
>>    Unfortunately, since this is an all-volunteer forum, there's no
>> particular guarantee that people will remain interested in a thread/get
>> around to answering your questions. IMO it's reasonable etiquette to
>> "bump"/remind readers about a question that has been languishing for
>> some time (once you've allowed a reasonable time for an answer, e.g. a
>> few days); it may be helpful to include a link, in this case
>> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q2/029477.html ,
>> to help people re-locate the question.
>>
>>    It would be OK to try your luck in another forum such as
>> CrossValidated; it would be polite and useful if/when you post there to
>> provide a link to this thread so people can see what has already been
>> discussed (although you should also provide a good summary there, so
>> readers don't *have* to come trawl through the archives).
>>
>>    A few more points since I'm responding:
>>
>> * From your _original_ problem; I've updated the influence.merMod()
>> method in the *development* version of lme4 so that it doesn't choke
>> when nAGQ=0 (the starting value can be set manually, but it also checks
>> and does the right thing by default when nAGQ is 0). If you're able to
>> installed packages with compiled code from source
>> (remotes::install_github("lme4/lme4")), you should be able to run
>> influence() on your original model.
>>
>> * The gold standard for whether convergence warnings are really a
>> problem or not is allFit().  If you run allFit(), and the results from a
>> range of optimizers **are sufficiently similar to each other for your
>> scientific purposes**, then you can feel free to disregard convergence
>> warnings (at that point it doesn't really matter how nasty the warnings
>> sound).
>>
>> * You _might_ try simplifying the model a little bit, e.g. removing the
>> Session : Probability interaction in the random effects term (the
>> standard deviation for that component is 5 times smaller than the
>> intercept variation, and 29 times smaller than the residual variation
>> term).
>>
>>
>>   One tiny final point: please don't use the salutation "Dear Professor
>> Bolker" when responding to the list - even though I might be answering
>> your question at the moment, the query is still to the whole list.
>>
>>    cheers
>>      Ben Bolker
>>
>>
>>
>> On 5/18/21 3:10 PM, C?tia Ferreira De Oliveira wrote:
>> > Hello,
>> >
>> > I am sorry for bothering you but I have asked a follow-up question and
>> I
>> > haven't obtained a response, I wonder if it will ever be responded to
>> as
>> > I don't know if there is any way of keeping track of which questions
>> get
>> > or not answered. If not, I may need to try my luck on crossvalidated as
>> > it is quite a timely problem that I am experiencing with the models.
>> > After removing the "logRT" from the glmer model I got a lot more
>> > convergence issues, so I am left wondering if having the logRT would be
>> > problematic. If so, would there be other options for me on what to do
>> to
>> > be able to model this data.
>> >
>> > Best wishes,
>> >
>> > Catia
>> >
>> > --
>> > C?tia Margarida Ferreira de Oliveira
>> > Psychology PhD Student
>> > Department of Psychology, Room B214
>> > University of York, YO10 5DD
>>
>

-- 
C?tia Margarida Ferreira de Oliveira
Psychology PhD Student
Department of Psychology, Room B214
University of York, YO10 5DD

	[[alternative HTML version deleted]]


From mrm|500 @end|ng |rom york@@c@uk  Wed May 19 10:31:46 2021
From: mrm|500 @end|ng |rom york@@c@uk (Michael Lawson)
Date: Wed, 19 May 2021 09:31:46 +0100
Subject: [R-sig-ME] 
 Model specification/family for a continuous/proportional
 response with many zeros
In-Reply-To: <CAJuCY5w9erbtEOeRbxkZdLxRYOd_t22g6HEC2US7Wrwm7=jjxQ@mail.gmail.com>
References: <CACtWw1GgDWo3Zng0+9_soe9nW1-S-ziZLEJNyzt4t7cz4ZxwVg@mail.gmail.com>
 <CAJuCY5zh-A5LOjNc=tkVNhj2bhEBO+QFUMrjSu0aqBe_v9Qu7A@mail.gmail.com>
 <CACtWw1HcC8zSqhh_eG2E5222i4pz6vJdWLh+3Q=_Gx21vw3qvQ@mail.gmail.com>
 <CAJuCY5yDWyj+EhZOntYFTwdyATX0+W4yWz7xvnAEYxR6eTh6-w@mail.gmail.com>
 <CACtWw1Fv2e94+X9ZcQih+WHC4dHt+xnACa04M2_hkKWjc1jP0g@mail.gmail.com>
 <CAJuCY5w9erbtEOeRbxkZdLxRYOd_t22g6HEC2US7Wrwm7=jjxQ@mail.gmail.com>
Message-ID: <CACtWw1GAnDJ1d8CWh_DODP6jPqfsyptc-RV0gw0_5z9bWEwubw@mail.gmail.com>

Hi Thierry,

I understood after your previous message that a high dispersion parameter
in beta models does not signify overdispersion. Both answers addressed this
misconception in those two links I provided.

I suppose the real answer I am now looking for is -  how do I assess the
validity and fit of the model? Are there specifics or assumptions I must
take into account with zero-inflated beta glmms?

Thanks for your help,
Mike

On Tue, 18 May 2021 at 13:57, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Mike,
>
> I think you misread my reply. I never stated that there's something wrong
> with the model. The only "problem" I highlighted was your misconception
> about the "high overdispersion". In this case, a high parameter value
> indicates a low variance, which is what we mostly want to see.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op di 18 mei 2021 om 12:49 schreef Michael Lawson <mrml500 at york.ac.uk>:
>
>> Dear Thierry,
>>
>> Thanks for the help. So if the dispersion parameter in this model doesn't
>> fit with the beta distribution, are there any alternative approaches I can
>> use?
>>
>> I can't seem to find much information on this elsewhere other than these
>> two threads:
>> https://stats.stackexchange.com/a/451453/233414
>> https://stats.stackexchange.com/a/466951/233414
>>
>> All the best,
>> Mike
>>
>> On Tue, 18 May 2021 at 08:12, Thierry Onkelinx <thierry.onkelinx at inbo.be>
>> wrote:
>>
>>> Dear Mike,
>>>
>>> The zero-inflation is specified on the logit scale. plogis(-1.18) =
>>> 0.235 23.5% zero seems reasonable when reading your story. (Didn't look at
>>> the data).
>>>
>>> You need to look at the definition for the "over"dispersion parameter.
>>> For a beta distribution is \phi with Var(y) = \mu * (1 - \mu) / (\phi + 1)
>>> (see ?glmmTMB::beta_family) Hence a large value of \phi implies a low
>>> variance.
>>>
>>> Best regards,
>>>
>>> ir. Thierry Onkelinx
>>> Statisticus / Statistician
>>>
>>> Vlaamse Overheid / Government of Flanders
>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>>> AND FOREST
>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>> thierry.onkelinx at inbo.be
>>> Havenlaan 88 bus 73, 1000 Brussel
>>> www.inbo.be
>>>
>>>
>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of data.
>>> ~ John Tukey
>>>
>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>
>>> <https://www.inbo.be>
>>>
>>>
>>> Op ma 17 mei 2021 om 15:45 schreef Michael Lawson <mrml500 at york.ac.uk>:
>>>
>>>> Hi Thierry,
>>>>
>>>> Thank you for your advice and speedy response.
>>>>
>>>> Most of the data is closer to the lower bound (0). e.g. the mean time
>>>> for group A in zone A = 15.1 seconds and group A in zone B = 3.8 seconds.
>>>> However there are a very small number of outliers near the upper bound, the
>>>> largest being 294 out of the 300 seconds (see the attached file if you want
>>>> to look at the data).
>>>>
>>>> I have taken a stab at running a Zero-inflated Beta GLMM using glmmTMB
>>>> in R like so:
>>>>
>>>> betta_mod <- glmmTMB(prop_time ~ group*zone + (1|id),
>>>>                              family = beta_family(),
>>>>                              ziformula=~1,
>>>>                              data = glmm_zone_data)
>>>>
>>>> summary(beta_mod)
>>>>
>>>> *Family: beta  ( logit )*
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> *Formula:          prop_time ~ group * zone + (1 | id)Zero inflation:
>>>>           ~1Data: glmm_zone_data     AIC      BIC   logLik deviance
>>>> df.resid  -763.6   -736.3    388.8   -777.6      359Random
>>>> effects:Conditional model: Groups Name        Variance  Std.Dev. id
>>>> (Intercept) 2.386e-09 4.885e-05Number of obs: 366, groups:  id,
>>>> 14Overdispersion parameter for beta family (): 13.1Conditional model:
>>>>             Estimate Std. Error z value Pr(>|z|)    (Intercept)
>>>>  -2.7685     0.1031 -26.844  < 2e-16 ***groupB             -0.4455
>>>> 0.1498  -2.975 0.002932 **zonezone_B         -0.4179     0.1524  -2.741
>>>> 0.006124 **groupB:zonezone_B   0.8443     0.2190   3.855 0.000116
>>>> ***---Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ?
>>>> 1Zero-inflation model:            Estimate Std. Error z value Pr(>|z|)
>>>>   (Intercept)  -1.1804     0.1233  -9.575   <2e-16 ***---Signif. codes:  0
>>>> ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1*
>>>>
>>>> Does this look like the correct way of specifying the model? I am a
>>>> little confused about specifying and interpreting the zero-inflation
>>>> component - I have only just begun reading about this.
>>>>
>>>> I noticed that the dispersion parameter is quite high at 13.1. I'm not
>>>> sure if this matters for beta models?. I tried running DHARMa
>>>> simulateResiduals on the model output and got significant deviations in the
>>>> dispersion (<2.2e-16) and KS tests. e.g.
>>>>
>>>> DHARMa::testDispersion(beta_mod)
>>>>
>>>> *DHARMa nonparametric dispersion test via sd of residuals fitted vs.
>>>> simulated*
>>>>
>>>> *data:  simulationOutput*
>>>> *ratioObsSim = 1.3612, p-value < 2.2e-16*
>>>> *alternative hypothesis: two.sided*
>>>>
>>>>
>>>>
>>>> Many thanks,
>>>> Mike
>>>>
>>>> On Mon, 17 May 2021 at 13:22, Thierry Onkelinx <
>>>> thierry.onkelinx at inbo.be> wrote:
>>>>
>>>>> Dear Michael,
>>>>>
>>>>> Your data has bounds (lower bound at 0 and upper bound at 300) and you
>>>>> have a lot of data close to a boundary. In such a case, a continuous
>>>>> distribution which ignores those bound is not a good idea. If the time
>>>>> spent outside of both zones is limited, then a long time in zone A excludes
>>>>> a long time in zone B by definition. Then I'd look towards a multinomial
>>>>> distribution. If the time spent outside both zones is dominant, then you
>>>>> can use a zero-inflated beta as you suggested. A zero-inflated gamma might
>>>>> be OK if the data is not too close to the upper boundary. If you are
>>>>> considering zero-inflated beta vs zero-inflated gamma, then you should
>>>>> choose zero-inflated beta IMHO.
>>>>>
>>>>> Best regards,
>>>>>
>>>>> ir. Thierry Onkelinx
>>>>> Statisticus / Statistician
>>>>>
>>>>> Vlaamse Overheid / Government of Flanders
>>>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>>>>> AND FOREST
>>>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>>>> thierry.onkelinx at inbo.be
>>>>> Havenlaan 88 bus 73, 1000 Brussel
>>>>> www.inbo.be
>>>>>
>>>>>
>>>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>>> To call in the statistician after the experiment is done may be no
>>>>> more than asking him to perform a post-mortem examination: he may be able
>>>>> to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>>> The combination of some data and an aching desire for an answer does
>>>>> not ensure that a reasonable answer can be extracted from a given body of
>>>>> data. ~ John Tukey
>>>>>
>>>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>>>
>>>>> <https://www.inbo.be>
>>>>>
>>>>>
>>>>> Op ma 17 mei 2021 om 13:52 schreef Michael Lawson via
>>>>> R-sig-mixed-models <r-sig-mixed-models at r-project.org>:
>>>>>
>>>>>> Hello,
>>>>>>
>>>>>> I am new to GLMMs and have a dataset where I have two distinct groups
>>>>>> (A
>>>>>> and B) of 7 individuals each. The data consists of repeated
>>>>>> measurements of
>>>>>> each individual where the amount of time spent at either zone_A or
>>>>>> zone_B
>>>>>> is recorded (out of a total time of 300s/observation period). For
>>>>>> most of
>>>>>> the time period the individuals are in neither zone.
>>>>>>
>>>>>> I want to test if group A and group B spend more time in zone A
>>>>>> compared to
>>>>>> zone B (and vice versa).
>>>>>>
>>>>>> Speaking to someone else, they said I should use a Binomial GLMM using
>>>>>> cbind. i.e.
>>>>>> cbind(time_at_zone_A, time_at_zone_B) ~ group + (1| id).
>>>>>>
>>>>>> However, the response variable is continuous (albeit with an upper
>>>>>> bound of
>>>>>> 300 seconds per observation period), so I'm not sure if this is
>>>>>> appropriate?
>>>>>>
>>>>>> Should I convert the response into a proportion and use something
>>>>>> like a
>>>>>> Beta GLMM or else use a continuous (Gamma) GLMM? e.g. something like:
>>>>>> prop_time ~ zone*group + (1|id)
>>>>>>
>>>>>> The data is quite heavily right-skewed and contains a lot of 0's, so
>>>>>> reading around it also looks like I may need to convert these into a
>>>>>> zero-inflated/hurdle model?
>>>>>>
>>>>>> Thank you for any suggestions,
>>>>>> Mike
>>>>>>
>>>>>>         [[alternative HTML version deleted]]
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>
>>>>>

	[[alternative HTML version deleted]]


From h|gh@t@t @end|ng |rom h|gh@t@t@com  Wed May 19 12:18:32 2021
From: h|gh@t@t @end|ng |rom h|gh@t@t@com (Highland Statistics Ltd)
Date: Wed, 19 May 2021 11:18:32 +0100
Subject: [R-sig-ME] 
 Model specification/family for a continuous/proportional,
 response with many zeros
In-Reply-To: <mailman.19179.9.1621418401.6183.r-sig-mixed-models@r-project.org>
References: <mailman.19179.9.1621418401.6183.r-sig-mixed-models@r-project.org>
Message-ID: <cfe43ac8-331e-2cb3-5ebe-304db69fea98@highstat.com>


> Today's Topics:
>
>     1. Re:  Model specification/family for a continuous/proportional
>        response with many zeros (Michael Lawson)
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Wed, 19 May 2021 09:31:46 +0100
> From: Michael Lawson <mrml500 at york.ac.uk>
> To: Thierry Onkelinx <thierry.onkelinx at inbo.be>
> Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME]  Model specification/family for a
> 	continuous/proportional response with many zeros
> Message-ID:
> 	<CACtWw1GAnDJ1d8CWh_DODP6jPqfsyptc-RV0gw0_5z9bWEwubw at mail.gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
> Hi Thierry,
>
> I understood after your previous message that a high dispersion parameter
> in beta models does not signify overdispersion. Both answers addressed this
> misconception in those two links I provided.
>
> I suppose the real answer I am now looking for is -  how do I assess the
> validity and fit of the model? Are there specifics or assumptions I must
> take into account with zero-inflated beta glmms?

Just simulate 1000 data sets from your model, and see whether the 
simulated data sets are comparable to your original data. One of the 
things you can look at is whether the simulated data sets contain 
similar number of zeros as in the observed data. I'm not sure whether 
the DHARMA package can do this for you. If not..it is easy to program.

See also Figure 8 in (sorry for self-citing):

https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.12577

Alain


> Thanks for your help,
> Mike
>
> On Tue, 18 May 2021 at 13:57, Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>
>> Dear Mike,
>>
>> I think you misread my reply. I never stated that there's something wrong
>> with the model. The only "problem" I highlighted was your misconception
>> about the "high overdispersion". In this case, a high parameter value
>> indicates a low variance, which is what we mostly want to see.
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
>> FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88 bus 73, 1000 Brussel
>> www.inbo.be
>>
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>
>> <https://www.inbo.be>
>>
>>
>> Op di 18 mei 2021 om 12:49 schreef Michael Lawson <mrml500 at york.ac.uk>:
>>
>>> Dear Thierry,
>>>
>>> Thanks for the help. So if the dispersion parameter in this model doesn't
>>> fit with the beta distribution, are there any alternative approaches I can
>>> use?
>>>
>>> I can't seem to find much information on this elsewhere other than these
>>> two threads:
>>> https://stats.stackexchange.com/a/451453/233414
>>> https://stats.stackexchange.com/a/466951/233414
>>>
>>> All the best,
>>> Mike
>>>
>>> On Tue, 18 May 2021 at 08:12, Thierry Onkelinx <thierry.onkelinx at inbo.be>
>>> wrote:
>>>
>>>> Dear Mike,
>>>>
>>>> The zero-inflation is specified on the logit scale. plogis(-1.18) =
>>>> 0.235 23.5% zero seems reasonable when reading your story. (Didn't look at
>>>> the data).
>>>>
>>>> You need to look at the definition for the "over"dispersion parameter.
>>>> For a beta distribution is \phi with Var(y) = \mu * (1 - \mu) / (\phi + 1)
>>>> (see ?glmmTMB::beta_family) Hence a large value of \phi implies a low
>>>> variance.
>>>>
>>>> Best regards,
>>>>
>>>> ir. Thierry Onkelinx
>>>> Statisticus / Statistician
>>>>
>>>> Vlaamse Overheid / Government of Flanders
>>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>>>> AND FOREST
>>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>>> thierry.onkelinx at inbo.be
>>>> Havenlaan 88 bus 73, 1000 Brussel
>>>> www.inbo.be
>>>>
>>>>
>>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>> To call in the statistician after the experiment is done may be no more
>>>> than asking him to perform a post-mortem examination: he may be able to say
>>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>> The combination of some data and an aching desire for an answer does not
>>>> ensure that a reasonable answer can be extracted from a given body of data.
>>>> ~ John Tukey
>>>>
>>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>>
>>>> <https://www.inbo.be>
>>>>
>>>>
>>>> Op ma 17 mei 2021 om 15:45 schreef Michael Lawson <mrml500 at york.ac.uk>:
>>>>
>>>>> Hi Thierry,
>>>>>
>>>>> Thank you for your advice and speedy response.
>>>>>
>>>>> Most of the data is closer to the lower bound (0). e.g. the mean time
>>>>> for group A in zone A = 15.1 seconds and group A in zone B = 3.8 seconds.
>>>>> However there are a very small number of outliers near the upper bound, the
>>>>> largest being 294 out of the 300 seconds (see the attached file if you want
>>>>> to look at the data).
>>>>>
>>>>> I have taken a stab at running a Zero-inflated Beta GLMM using glmmTMB
>>>>> in R like so:
>>>>>
>>>>> betta_mod <- glmmTMB(prop_time ~ group*zone + (1|id),
>>>>>                               family = beta_family(),
>>>>>                               ziformula=~1,
>>>>>                               data = glmm_zone_data)
>>>>>
>>>>> summary(beta_mod)
>>>>>
>>>>> *Family: beta  ( logit )*
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> *Formula:          prop_time ~ group * zone + (1 | id)Zero inflation:
>>>>>            ~1Data: glmm_zone_data     AIC      BIC   logLik deviance
>>>>> df.resid  -763.6   -736.3    388.8   -777.6      359Random
>>>>> effects:Conditional model: Groups Name        Variance  Std.Dev. id
>>>>> (Intercept) 2.386e-09 4.885e-05Number of obs: 366, groups:  id,
>>>>> 14Overdispersion parameter for beta family (): 13.1Conditional model:
>>>>>              Estimate Std. Error z value Pr(>|z|)    (Intercept)
>>>>>   -2.7685     0.1031 -26.844  < 2e-16 ***groupB             -0.4455
>>>>> 0.1498  -2.975 0.002932 **zonezone_B         -0.4179     0.1524  -2.741
>>>>> 0.006124 **groupB:zonezone_B   0.8443     0.2190   3.855 0.000116
>>>>> ***---Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ?
>>>>> 1Zero-inflation model:            Estimate Std. Error z value Pr(>|z|)
>>>>>    (Intercept)  -1.1804     0.1233  -9.575   <2e-16 ***---Signif. codes:  0
>>>>> ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1*
>>>>>
>>>>> Does this look like the correct way of specifying the model? I am a
>>>>> little confused about specifying and interpreting the zero-inflation
>>>>> component - I have only just begun reading about this.
>>>>>
>>>>> I noticed that the dispersion parameter is quite high at 13.1. I'm not
>>>>> sure if this matters for beta models?. I tried running DHARMa
>>>>> simulateResiduals on the model output and got significant deviations in the
>>>>> dispersion (<2.2e-16) and KS tests. e.g.
>>>>>
>>>>> DHARMa::testDispersion(beta_mod)
>>>>>
>>>>> *DHARMa nonparametric dispersion test via sd of residuals fitted vs.
>>>>> simulated*
>>>>>
>>>>> *data:  simulationOutput*
>>>>> *ratioObsSim = 1.3612, p-value < 2.2e-16*
>>>>> *alternative hypothesis: two.sided*
>>>>>
>>>>>
>>>>>
>>>>> Many thanks,
>>>>> Mike
>>>>>
>>>>> On Mon, 17 May 2021 at 13:22, Thierry Onkelinx <
>>>>> thierry.onkelinx at inbo.be> wrote:
>>>>>
>>>>>> Dear Michael,
>>>>>>
>>>>>> Your data has bounds (lower bound at 0 and upper bound at 300) and you
>>>>>> have a lot of data close to a boundary. In such a case, a continuous
>>>>>> distribution which ignores those bound is not a good idea. If the time
>>>>>> spent outside of both zones is limited, then a long time in zone A excludes
>>>>>> a long time in zone B by definition. Then I'd look towards a multinomial
>>>>>> distribution. If the time spent outside both zones is dominant, then you
>>>>>> can use a zero-inflated beta as you suggested. A zero-inflated gamma might
>>>>>> be OK if the data is not too close to the upper boundary. If you are
>>>>>> considering zero-inflated beta vs zero-inflated gamma, then you should
>>>>>> choose zero-inflated beta IMHO.
>>>>>>
>>>>>> Best regards,
>>>>>>
>>>>>> ir. Thierry Onkelinx
>>>>>> Statisticus / Statistician
>>>>>>
>>>>>> Vlaamse Overheid / Government of Flanders
>>>>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>>>>>> AND FOREST
>>>>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>>>>> thierry.onkelinx at inbo.be
>>>>>> Havenlaan 88 bus 73, 1000 Brussel
>>>>>> www.inbo.be
>>>>>>
>>>>>>
>>>>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>>>> To call in the statistician after the experiment is done may be no
>>>>>> more than asking him to perform a post-mortem examination: he may be able
>>>>>> to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>>>> The combination of some data and an aching desire for an answer does
>>>>>> not ensure that a reasonable answer can be extracted from a given body of
>>>>>> data. ~ John Tukey
>>>>>>
>>>>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>>>>
>>>>>> <https://www.inbo.be>
>>>>>>
>>>>>>
>>>>>> Op ma 17 mei 2021 om 13:52 schreef Michael Lawson via
>>>>>> R-sig-mixed-models <r-sig-mixed-models at r-project.org>:
>>>>>>
>>>>>>> Hello,
>>>>>>>
>>>>>>> I am new to GLMMs and have a dataset where I have two distinct groups
>>>>>>> (A
>>>>>>> and B) of 7 individuals each. The data consists of repeated
>>>>>>> measurements of
>>>>>>> each individual where the amount of time spent at either zone_A or
>>>>>>> zone_B
>>>>>>> is recorded (out of a total time of 300s/observation period). For
>>>>>>> most of
>>>>>>> the time period the individuals are in neither zone.
>>>>>>>
>>>>>>> I want to test if group A and group B spend more time in zone A
>>>>>>> compared to
>>>>>>> zone B (and vice versa).
>>>>>>>
>>>>>>> Speaking to someone else, they said I should use a Binomial GLMM using
>>>>>>> cbind. i.e.
>>>>>>> cbind(time_at_zone_A, time_at_zone_B) ~ group + (1| id).
>>>>>>>
>>>>>>> However, the response variable is continuous (albeit with an upper
>>>>>>> bound of
>>>>>>> 300 seconds per observation period), so I'm not sure if this is
>>>>>>> appropriate?
>>>>>>>
>>>>>>> Should I convert the response into a proportion and use something
>>>>>>> like a
>>>>>>> Beta GLMM or else use a continuous (Gamma) GLMM? e.g. something like:
>>>>>>> prop_time ~ zone*group + (1|id)
>>>>>>>
>>>>>>> The data is quite heavily right-skewed and contains a lot of 0's, so
>>>>>>> reading around it also looks like I may need to convert these into a
>>>>>>> zero-inflated/hurdle model?
>>>>>>>
>>>>>>> Thank you for any suggestions,
>>>>>>> Mike
>>>>>>>
>>>>>>>          [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> _______________________________________________
>>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>
> 	[[alternative HTML version deleted]]
>
>
>
>
> ------------------------------
>
> Subject: Digest Footer
>
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> ------------------------------
>
> End of R-sig-mixed-models Digest, Vol 173, Issue 19
> ***************************************************

-- 
Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com
URL:   www.highstat.com


From mrm|500 @end|ng |rom york@@c@uk  Wed May 19 13:38:20 2021
From: mrm|500 @end|ng |rom york@@c@uk (Michael Lawson)
Date: Wed, 19 May 2021 12:38:20 +0100
Subject: [R-sig-ME] 
 Model specification/family for a continuous/proportional,
 response with many zeros
In-Reply-To: <cfe43ac8-331e-2cb3-5ebe-304db69fea98@highstat.com>
References: <mailman.19179.9.1621418401.6183.r-sig-mixed-models@r-project.org>
 <cfe43ac8-331e-2cb3-5ebe-304db69fea98@highstat.com>
Message-ID: <CACtWw1Gd89u1TGPdbXaMVyB=2HcJnLNVj7Y2qRg=4NzfcERkdA@mail.gmail.com>

Dear Alain,

Thank you for the suggestion. I tried simulating the 0's as you suggested
in the following way. The output is reassuring - with the actual number of
zeros in the middle of the distribution.

sim_beta_glmm <- simulate(beta_mod, nsim = 10000)
sim_zeros <- unlist(lapply(sim_beta_glmm, function(x){
length(which(x==0))/length(x)}), use.names = FALSE)
hist(sim_zeros, breaks = c(100))
abline(v = plogis(-1.1804), col = "red")

All the best,
Mike


On Wed, 19 May 2021 at 11:19, Highland Statistics Ltd via
R-sig-mixed-models <r-sig-mixed-models at r-project.org> wrote:

>
> > Today's Topics:
> >
> >     1. Re:  Model specification/family for a continuous/proportional
> >        response with many zeros (Michael Lawson)
> >
> > ----------------------------------------------------------------------
> >
> > Message: 1
> > Date: Wed, 19 May 2021 09:31:46 +0100
> > From: Michael Lawson <mrml500 at york.ac.uk>
> > To: Thierry Onkelinx <thierry.onkelinx at inbo.be>
> > Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
> > Subject: Re: [R-sig-ME]  Model specification/family for a
> >       continuous/proportional response with many zeros
> > Message-ID:
> >       <
> CACtWw1GAnDJ1d8CWh_DODP6jPqfsyptc-RV0gw0_5z9bWEwubw at mail.gmail.com>
> > Content-Type: text/plain; charset="utf-8"
> >
> > Hi Thierry,
> >
> > I understood after your previous message that a high dispersion parameter
> > in beta models does not signify overdispersion. Both answers addressed
> this
> > misconception in those two links I provided.
> >
> > I suppose the real answer I am now looking for is -  how do I assess the
> > validity and fit of the model? Are there specifics or assumptions I must
> > take into account with zero-inflated beta glmms?
>
> Just simulate 1000 data sets from your model, and see whether the
> simulated data sets are comparable to your original data. One of the
> things you can look at is whether the simulated data sets contain
> similar number of zeros as in the observed data. I'm not sure whether
> the DHARMA package can do this for you. If not..it is easy to program.
>
> See also Figure 8 in (sorry for self-citing):
>
>
> https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.12577
>
> Alain
>
>
> > Thanks for your help,
> > Mike
> >
> > On Tue, 18 May 2021 at 13:57, Thierry Onkelinx <thierry.onkelinx at inbo.be
> >
> > wrote:
> >
> >> Dear Mike,
> >>
> >> I think you misread my reply. I never stated that there's something
> wrong
> >> with the model. The only "problem" I highlighted was your misconception
> >> about the "high overdispersion". In this case, a high parameter value
> >> indicates a low variance, which is what we mostly want to see.
> >>
> >> Best regards,
> >>
> >> ir. Thierry Onkelinx
> >> Statisticus / Statistician
> >>
> >> Vlaamse Overheid / Government of Flanders
> >> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND
> >> FOREST
> >> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> >> thierry.onkelinx at inbo.be
> >> Havenlaan 88 bus 73, 1000 Brussel
> >> www.inbo.be
> >>
> >>
> >>
> ///////////////////////////////////////////////////////////////////////////////////////////
> >> To call in the statistician after the experiment is done may be no more
> >> than asking him to perform a post-mortem examination: he may be able to
> say
> >> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> >> The plural of anecdote is not data. ~ Roger Brinner
> >> The combination of some data and an aching desire for an answer does not
> >> ensure that a reasonable answer can be extracted from a given body of
> data.
> >> ~ John Tukey
> >>
> >>
> ///////////////////////////////////////////////////////////////////////////////////////////
> >>
> >> <https://www.inbo.be>
> >>
> >>
> >> Op di 18 mei 2021 om 12:49 schreef Michael Lawson <mrml500 at york.ac.uk>:
> >>
> >>> Dear Thierry,
> >>>
> >>> Thanks for the help. So if the dispersion parameter in this model
> doesn't
> >>> fit with the beta distribution, are there any alternative approaches I
> can
> >>> use?
> >>>
> >>> I can't seem to find much information on this elsewhere other than
> these
> >>> two threads:
> >>> https://stats.stackexchange.com/a/451453/233414
> >>> https://stats.stackexchange.com/a/466951/233414
> >>>
> >>> All the best,
> >>> Mike
> >>>
> >>> On Tue, 18 May 2021 at 08:12, Thierry Onkelinx <
> thierry.onkelinx at inbo.be>
> >>> wrote:
> >>>
> >>>> Dear Mike,
> >>>>
> >>>> The zero-inflation is specified on the logit scale. plogis(-1.18) =
> >>>> 0.235 23.5% zero seems reasonable when reading your story. (Didn't
> look at
> >>>> the data).
> >>>>
> >>>> You need to look at the definition for the "over"dispersion parameter.
> >>>> For a beta distribution is \phi with Var(y) = \mu * (1 - \mu) / (\phi
> + 1)
> >>>> (see ?glmmTMB::beta_family) Hence a large value of \phi implies a low
> >>>> variance.
> >>>>
> >>>> Best regards,
> >>>>
> >>>> ir. Thierry Onkelinx
> >>>> Statisticus / Statistician
> >>>>
> >>>> Vlaamse Overheid / Government of Flanders
> >>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> >>>> AND FOREST
> >>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> >>>> thierry.onkelinx at inbo.be
> >>>> Havenlaan 88 bus 73, 1000 Brussel
> >>>> www.inbo.be
> >>>>
> >>>>
> >>>>
> ///////////////////////////////////////////////////////////////////////////////////////////
> >>>> To call in the statistician after the experiment is done may be no
> more
> >>>> than asking him to perform a post-mortem examination: he may be able
> to say
> >>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> >>>> The plural of anecdote is not data. ~ Roger Brinner
> >>>> The combination of some data and an aching desire for an answer does
> not
> >>>> ensure that a reasonable answer can be extracted from a given body of
> data.
> >>>> ~ John Tukey
> >>>>
> >>>>
> ///////////////////////////////////////////////////////////////////////////////////////////
> >>>>
> >>>> <https://www.inbo.be>
> >>>>
> >>>>
> >>>> Op ma 17 mei 2021 om 15:45 schreef Michael Lawson <mrml500 at york.ac.uk
> >:
> >>>>
> >>>>> Hi Thierry,
> >>>>>
> >>>>> Thank you for your advice and speedy response.
> >>>>>
> >>>>> Most of the data is closer to the lower bound (0). e.g. the mean time
> >>>>> for group A in zone A = 15.1 seconds and group A in zone B = 3.8
> seconds.
> >>>>> However there are a very small number of outliers near the upper
> bound, the
> >>>>> largest being 294 out of the 300 seconds (see the attached file if
> you want
> >>>>> to look at the data).
> >>>>>
> >>>>> I have taken a stab at running a Zero-inflated Beta GLMM using
> glmmTMB
> >>>>> in R like so:
> >>>>>
> >>>>> betta_mod <- glmmTMB(prop_time ~ group*zone + (1|id),
> >>>>>                               family = beta_family(),
> >>>>>                               ziformula=~1,
> >>>>>                               data = glmm_zone_data)
> >>>>>
> >>>>> summary(beta_mod)
> >>>>>
> >>>>> *Family: beta  ( logit )*
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>> *Formula:          prop_time ~ group * zone + (1 | id)Zero inflation:
> >>>>>            ~1Data: glmm_zone_data     AIC      BIC   logLik deviance
> >>>>> df.resid  -763.6   -736.3    388.8   -777.6      359Random
> >>>>> effects:Conditional model: Groups Name        Variance  Std.Dev. id
> >>>>> (Intercept) 2.386e-09 4.885e-05Number of obs: 366, groups:  id,
> >>>>> 14Overdispersion parameter for beta family (): 13.1Conditional model:
> >>>>>              Estimate Std. Error z value Pr(>|z|)    (Intercept)
> >>>>>   -2.7685     0.1031 -26.844  < 2e-16 ***groupB             -0.4455
> >>>>> 0.1498  -2.975 0.002932 **zonezone_B         -0.4179     0.1524
> -2.741
> >>>>> 0.006124 **groupB:zonezone_B   0.8443     0.2190   3.855 0.000116
> >>>>> ***---Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ?
> >>>>> 1Zero-inflation model:            Estimate Std. Error z value
> Pr(>|z|)
> >>>>>    (Intercept)  -1.1804     0.1233  -9.575   <2e-16 ***---Signif.
> codes:  0
> >>>>> ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1*
> >>>>>
> >>>>> Does this look like the correct way of specifying the model? I am a
> >>>>> little confused about specifying and interpreting the zero-inflation
> >>>>> component - I have only just begun reading about this.
> >>>>>
> >>>>> I noticed that the dispersion parameter is quite high at 13.1. I'm
> not
> >>>>> sure if this matters for beta models?. I tried running DHARMa
> >>>>> simulateResiduals on the model output and got significant deviations
> in the
> >>>>> dispersion (<2.2e-16) and KS tests. e.g.
> >>>>>
> >>>>> DHARMa::testDispersion(beta_mod)
> >>>>>
> >>>>> *DHARMa nonparametric dispersion test via sd of residuals fitted vs.
> >>>>> simulated*
> >>>>>
> >>>>> *data:  simulationOutput*
> >>>>> *ratioObsSim = 1.3612, p-value < 2.2e-16*
> >>>>> *alternative hypothesis: two.sided*
> >>>>>
> >>>>>
> >>>>>
> >>>>> Many thanks,
> >>>>> Mike
> >>>>>
> >>>>> On Mon, 17 May 2021 at 13:22, Thierry Onkelinx <
> >>>>> thierry.onkelinx at inbo.be> wrote:
> >>>>>
> >>>>>> Dear Michael,
> >>>>>>
> >>>>>> Your data has bounds (lower bound at 0 and upper bound at 300) and
> you
> >>>>>> have a lot of data close to a boundary. In such a case, a continuous
> >>>>>> distribution which ignores those bound is not a good idea. If the
> time
> >>>>>> spent outside of both zones is limited, then a long time in zone A
> excludes
> >>>>>> a long time in zone B by definition. Then I'd look towards a
> multinomial
> >>>>>> distribution. If the time spent outside both zones is dominant,
> then you
> >>>>>> can use a zero-inflated beta as you suggested. A zero-inflated
> gamma might
> >>>>>> be OK if the data is not too close to the upper boundary. If you are
> >>>>>> considering zero-inflated beta vs zero-inflated gamma, then you
> should
> >>>>>> choose zero-inflated beta IMHO.
> >>>>>>
> >>>>>> Best regards,
> >>>>>>
> >>>>>> ir. Thierry Onkelinx
> >>>>>> Statisticus / Statistician
> >>>>>>
> >>>>>> Vlaamse Overheid / Government of Flanders
> >>>>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR
> NATURE
> >>>>>> AND FOREST
> >>>>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality
> Assurance
> >>>>>> thierry.onkelinx at inbo.be
> >>>>>> Havenlaan 88 bus 73, 1000 Brussel
> >>>>>> www.inbo.be
> >>>>>>
> >>>>>>
> >>>>>>
> ///////////////////////////////////////////////////////////////////////////////////////////
> >>>>>> To call in the statistician after the experiment is done may be no
> >>>>>> more than asking him to perform a post-mortem examination: he may
> be able
> >>>>>> to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> >>>>>> The plural of anecdote is not data. ~ Roger Brinner
> >>>>>> The combination of some data and an aching desire for an answer does
> >>>>>> not ensure that a reasonable answer can be extracted from a given
> body of
> >>>>>> data. ~ John Tukey
> >>>>>>
> >>>>>>
> ///////////////////////////////////////////////////////////////////////////////////////////
> >>>>>>
> >>>>>> <https://www.inbo.be>
> >>>>>>
> >>>>>>
> >>>>>> Op ma 17 mei 2021 om 13:52 schreef Michael Lawson via
> >>>>>> R-sig-mixed-models <r-sig-mixed-models at r-project.org>:
> >>>>>>
> >>>>>>> Hello,
> >>>>>>>
> >>>>>>> I am new to GLMMs and have a dataset where I have two distinct
> groups
> >>>>>>> (A
> >>>>>>> and B) of 7 individuals each. The data consists of repeated
> >>>>>>> measurements of
> >>>>>>> each individual where the amount of time spent at either zone_A or
> >>>>>>> zone_B
> >>>>>>> is recorded (out of a total time of 300s/observation period). For
> >>>>>>> most of
> >>>>>>> the time period the individuals are in neither zone.
> >>>>>>>
> >>>>>>> I want to test if group A and group B spend more time in zone A
> >>>>>>> compared to
> >>>>>>> zone B (and vice versa).
> >>>>>>>
> >>>>>>> Speaking to someone else, they said I should use a Binomial GLMM
> using
> >>>>>>> cbind. i.e.
> >>>>>>> cbind(time_at_zone_A, time_at_zone_B) ~ group + (1| id).
> >>>>>>>
> >>>>>>> However, the response variable is continuous (albeit with an upper
> >>>>>>> bound of
> >>>>>>> 300 seconds per observation period), so I'm not sure if this is
> >>>>>>> appropriate?
> >>>>>>>
> >>>>>>> Should I convert the response into a proportion and use something
> >>>>>>> like a
> >>>>>>> Beta GLMM or else use a continuous (Gamma) GLMM? e.g. something
> like:
> >>>>>>> prop_time ~ zone*group + (1|id)
> >>>>>>>
> >>>>>>> The data is quite heavily right-skewed and contains a lot of 0's,
> so
> >>>>>>> reading around it also looks like I may need to convert these into
> a
> >>>>>>> zero-inflated/hurdle model?
> >>>>>>>
> >>>>>>> Thank you for any suggestions,
> >>>>>>> Mike
> >>>>>>>
> >>>>>>>          [[alternative HTML version deleted]]
> >>>>>>>
> >>>>>>> _______________________________________________
> >>>>>>> R-sig-mixed-models at r-project.org mailing list
> >>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>>>>
> >       [[alternative HTML version deleted]]
> >
> >
> >
> >
> > ------------------------------
> >
> > Subject: Digest Footer
> >
> > _______________________________________________
> > R-sig-mixed-models mailing list
> > R-sig-mixed-models at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
> > ------------------------------
> >
> > End of R-sig-mixed-models Digest, Vol 173, Issue 19
> > ***************************************************
>
> --
> Dr. Alain F. Zuur
> Highland Statistics Ltd.
> 9 St Clair Wynd
> AB41 6DZ Newburgh, UK
> Email: highstat at highstat.com
> URL:   www.highstat.com
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From mrm|500 @end|ng |rom york@@c@uk  Thu May 20 10:46:07 2021
From: mrm|500 @end|ng |rom york@@c@uk (Michael Lawson)
Date: Thu, 20 May 2021 09:46:07 +0100
Subject: [R-sig-ME] 
 Model specification/family for a continuous/proportional,
 response with many zeros
In-Reply-To: <CACtWw1Gd89u1TGPdbXaMVyB=2HcJnLNVj7Y2qRg=4NzfcERkdA@mail.gmail.com>
References: <mailman.19179.9.1621418401.6183.r-sig-mixed-models@r-project.org>
 <cfe43ac8-331e-2cb3-5ebe-304db69fea98@highstat.com>
 <CACtWw1Gd89u1TGPdbXaMVyB=2HcJnLNVj7Y2qRg=4NzfcERkdA@mail.gmail.com>
Message-ID: <CACtWw1FQQzPQ7c-OW4Ha8K0GtpVrTQ=OO9zakcSZYsOJ4RqVDw@mail.gmail.com>

Hi again,

I wanted to look a little more at the rest of the simulated values
(non-zeros), so I took the mean proportion of simulated values in set bins
of 0.01 and compared this to the real values.


*bins <- seq(from = 0, to = 1, by = 0.01)*












*sim_seq <- c()for(i in bins){  a <- mean(unlist(lapply(sim_beta_glmm,
function(x){ length(which(x>i & x <= i+0.01))/length(x)}), use.names =
FALSE))  sim_seq <- c(sim_seq,a)}real_seq <- c()for(i in bins){  a <-
print(mean(unlist(lapply(glmm_zone_data$prop_time, function(x){
length(which(x>i & x <= i+0.01))/length(x)}), use.names = FALSE)))
real_seq <- c(real_seq,a)}*


*barplot(rbind(sim_seq,real_seq),col=c("green","red"),beside = TRUE,
legend.text = c("simulated","real"))*


*cbind(bins,sim_seq,real_seq)*











*bins         sim_seq    real_seq  [1,] 0.00 0.2199795081967 0.232240437
[2,] 0.01 0.1021612021858 0.166666667  [3,] 0.02 0.0750964480874
0.103825137  [4,] 0.03 0.0592128415301 0.073770492  [5,] 0.04
0.0478316939891 0.038251366  [6,] 0.05 0.0397267759563 0.030054645  [7,]
0.06 0.0331961748634 0.016393443  [8,] 0.07 0.0279322404372 0.013661202
[9,] 0.08 0.0238013661202 0.024590164 [10,] 0.09 0.0201101092896
0.010928962*

As you can see in the output above (and the plot attached), the real data
is quite a bit more right-skewed compared to the simulated values. Does
this look like a good enough fit or will I have to try a different model?

Many thanks,
Mike

On Wed, 19 May 2021 at 12:38, Michael Lawson <mrml500 at york.ac.uk> wrote:

> Dear Alain,
>
> Thank you for the suggestion. I tried simulating the 0's as you suggested
> in the following way. The output is reassuring - with the actual number of
> zeros in the middle of the distribution.
>
> sim_beta_glmm <- simulate(beta_mod, nsim = 10000)
> sim_zeros <- unlist(lapply(sim_beta_glmm, function(x){
> length(which(x==0))/length(x)}), use.names = FALSE)
> hist(sim_zeros, breaks = c(100))
> abline(v = plogis(-1.1804), col = "red")
>
> All the best,
> Mike
>
>
> On Wed, 19 May 2021 at 11:19, Highland Statistics Ltd via
> R-sig-mixed-models <r-sig-mixed-models at r-project.org> wrote:
>
>>
>> > Today's Topics:
>> >
>> >     1. Re:  Model specification/family for a continuous/proportional
>> >        response with many zeros (Michael Lawson)
>> >
>> > ----------------------------------------------------------------------
>> >
>> > Message: 1
>> > Date: Wed, 19 May 2021 09:31:46 +0100
>> > From: Michael Lawson <mrml500 at york.ac.uk>
>> > To: Thierry Onkelinx <thierry.onkelinx at inbo.be>
>> > Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
>> > Subject: Re: [R-sig-ME]  Model specification/family for a
>> >       continuous/proportional response with many zeros
>> > Message-ID:
>> >       <
>> CACtWw1GAnDJ1d8CWh_DODP6jPqfsyptc-RV0gw0_5z9bWEwubw at mail.gmail.com>
>> > Content-Type: text/plain; charset="utf-8"
>> >
>> > Hi Thierry,
>> >
>> > I understood after your previous message that a high dispersion
>> parameter
>> > in beta models does not signify overdispersion. Both answers addressed
>> this
>> > misconception in those two links I provided.
>> >
>> > I suppose the real answer I am now looking for is -  how do I assess the
>> > validity and fit of the model? Are there specifics or assumptions I must
>> > take into account with zero-inflated beta glmms?
>>
>> Just simulate 1000 data sets from your model, and see whether the
>> simulated data sets are comparable to your original data. One of the
>> things you can look at is whether the simulated data sets contain
>> similar number of zeros as in the observed data. I'm not sure whether
>> the DHARMA package can do this for you. If not..it is easy to program.
>>
>> See also Figure 8 in (sorry for self-citing):
>>
>>
>> https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.12577
>>
>> Alain
>>
>>
>> > Thanks for your help,
>> > Mike
>> >
>> > On Tue, 18 May 2021 at 13:57, Thierry Onkelinx <
>> thierry.onkelinx at inbo.be>
>> > wrote:
>> >
>> >> Dear Mike,
>> >>
>> >> I think you misread my reply. I never stated that there's something
>> wrong
>> >> with the model. The only "problem" I highlighted was your misconception
>> >> about the "high overdispersion". In this case, a high parameter value
>> >> indicates a low variance, which is what we mostly want to see.
>> >>
>> >> Best regards,
>> >>
>> >> ir. Thierry Onkelinx
>> >> Statisticus / Statistician
>> >>
>> >> Vlaamse Overheid / Government of Flanders
>> >> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>> AND
>> >> FOREST
>> >> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> >> thierry.onkelinx at inbo.be
>> >> Havenlaan 88 bus 73, 1000 Brussel
>> >> www.inbo.be
>> >>
>> >>
>> >>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> >> To call in the statistician after the experiment is done may be no more
>> >> than asking him to perform a post-mortem examination: he may be able
>> to say
>> >> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> >> The plural of anecdote is not data. ~ Roger Brinner
>> >> The combination of some data and an aching desire for an answer does
>> not
>> >> ensure that a reasonable answer can be extracted from a given body of
>> data.
>> >> ~ John Tukey
>> >>
>> >>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> >>
>> >> <https://www.inbo.be>
>> >>
>> >>
>> >> Op di 18 mei 2021 om 12:49 schreef Michael Lawson <mrml500 at york.ac.uk
>> >:
>> >>
>> >>> Dear Thierry,
>> >>>
>> >>> Thanks for the help. So if the dispersion parameter in this model
>> doesn't
>> >>> fit with the beta distribution, are there any alternative approaches
>> I can
>> >>> use?
>> >>>
>> >>> I can't seem to find much information on this elsewhere other than
>> these
>> >>> two threads:
>> >>> https://stats.stackexchange.com/a/451453/233414
>> >>> https://stats.stackexchange.com/a/466951/233414
>> >>>
>> >>> All the best,
>> >>> Mike
>> >>>
>> >>> On Tue, 18 May 2021 at 08:12, Thierry Onkelinx <
>> thierry.onkelinx at inbo.be>
>> >>> wrote:
>> >>>
>> >>>> Dear Mike,
>> >>>>
>> >>>> The zero-inflation is specified on the logit scale. plogis(-1.18) =
>> >>>> 0.235 23.5% zero seems reasonable when reading your story. (Didn't
>> look at
>> >>>> the data).
>> >>>>
>> >>>> You need to look at the definition for the "over"dispersion
>> parameter.
>> >>>> For a beta distribution is \phi with Var(y) = \mu * (1 - \mu) /
>> (\phi + 1)
>> >>>> (see ?glmmTMB::beta_family) Hence a large value of \phi implies a low
>> >>>> variance.
>> >>>>
>> >>>> Best regards,
>> >>>>
>> >>>> ir. Thierry Onkelinx
>> >>>> Statisticus / Statistician
>> >>>>
>> >>>> Vlaamse Overheid / Government of Flanders
>> >>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR
>> NATURE
>> >>>> AND FOREST
>> >>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> >>>> thierry.onkelinx at inbo.be
>> >>>> Havenlaan 88 bus 73, 1000 Brussel
>> >>>> www.inbo.be
>> >>>>
>> >>>>
>> >>>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> >>>> To call in the statistician after the experiment is done may be no
>> more
>> >>>> than asking him to perform a post-mortem examination: he may be able
>> to say
>> >>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> >>>> The plural of anecdote is not data. ~ Roger Brinner
>> >>>> The combination of some data and an aching desire for an answer does
>> not
>> >>>> ensure that a reasonable answer can be extracted from a given body
>> of data.
>> >>>> ~ John Tukey
>> >>>>
>> >>>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> >>>>
>> >>>> <https://www.inbo.be>
>> >>>>
>> >>>>
>> >>>> Op ma 17 mei 2021 om 15:45 schreef Michael Lawson <
>> mrml500 at york.ac.uk>:
>> >>>>
>> >>>>> Hi Thierry,
>> >>>>>
>> >>>>> Thank you for your advice and speedy response.
>> >>>>>
>> >>>>> Most of the data is closer to the lower bound (0). e.g. the mean
>> time
>> >>>>> for group A in zone A = 15.1 seconds and group A in zone B = 3.8
>> seconds.
>> >>>>> However there are a very small number of outliers near the upper
>> bound, the
>> >>>>> largest being 294 out of the 300 seconds (see the attached file if
>> you want
>> >>>>> to look at the data).
>> >>>>>
>> >>>>> I have taken a stab at running a Zero-inflated Beta GLMM using
>> glmmTMB
>> >>>>> in R like so:
>> >>>>>
>> >>>>> betta_mod <- glmmTMB(prop_time ~ group*zone + (1|id),
>> >>>>>                               family = beta_family(),
>> >>>>>                               ziformula=~1,
>> >>>>>                               data = glmm_zone_data)
>> >>>>>
>> >>>>> summary(beta_mod)
>> >>>>>
>> >>>>> *Family: beta  ( logit )*
>> >>>>>
>> >>>>>
>> >>>>>
>> >>>>>
>> >>>>>
>> >>>>>
>> >>>>> *Formula:          prop_time ~ group * zone + (1 | id)Zero
>> inflation:
>> >>>>>            ~1Data: glmm_zone_data     AIC      BIC   logLik deviance
>> >>>>> df.resid  -763.6   -736.3    388.8   -777.6      359Random
>> >>>>> effects:Conditional model: Groups Name        Variance  Std.Dev. id
>> >>>>> (Intercept) 2.386e-09 4.885e-05Number of obs: 366, groups:  id,
>> >>>>> 14Overdispersion parameter for beta family (): 13.1Conditional
>> model:
>> >>>>>              Estimate Std. Error z value Pr(>|z|)    (Intercept)
>> >>>>>   -2.7685     0.1031 -26.844  < 2e-16 ***groupB             -0.4455
>> >>>>> 0.1498  -2.975 0.002932 **zonezone_B         -0.4179     0.1524
>> -2.741
>> >>>>> 0.006124 **groupB:zonezone_B   0.8443     0.2190   3.855 0.000116
>> >>>>> ***---Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ?
>> >>>>> 1Zero-inflation model:            Estimate Std. Error z value
>> Pr(>|z|)
>> >>>>>    (Intercept)  -1.1804     0.1233  -9.575   <2e-16 ***---Signif.
>> codes:  0
>> >>>>> ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1*
>> >>>>>
>> >>>>> Does this look like the correct way of specifying the model? I am a
>> >>>>> little confused about specifying and interpreting the zero-inflation
>> >>>>> component - I have only just begun reading about this.
>> >>>>>
>> >>>>> I noticed that the dispersion parameter is quite high at 13.1. I'm
>> not
>> >>>>> sure if this matters for beta models?. I tried running DHARMa
>> >>>>> simulateResiduals on the model output and got significant
>> deviations in the
>> >>>>> dispersion (<2.2e-16) and KS tests. e.g.
>> >>>>>
>> >>>>> DHARMa::testDispersion(beta_mod)
>> >>>>>
>> >>>>> *DHARMa nonparametric dispersion test via sd of residuals fitted vs.
>> >>>>> simulated*
>> >>>>>
>> >>>>> *data:  simulationOutput*
>> >>>>> *ratioObsSim = 1.3612, p-value < 2.2e-16*
>> >>>>> *alternative hypothesis: two.sided*
>> >>>>>
>> >>>>>
>> >>>>>
>> >>>>> Many thanks,
>> >>>>> Mike
>> >>>>>
>> >>>>> On Mon, 17 May 2021 at 13:22, Thierry Onkelinx <
>> >>>>> thierry.onkelinx at inbo.be> wrote:
>> >>>>>
>> >>>>>> Dear Michael,
>> >>>>>>
>> >>>>>> Your data has bounds (lower bound at 0 and upper bound at 300) and
>> you
>> >>>>>> have a lot of data close to a boundary. In such a case, a
>> continuous
>> >>>>>> distribution which ignores those bound is not a good idea. If the
>> time
>> >>>>>> spent outside of both zones is limited, then a long time in zone A
>> excludes
>> >>>>>> a long time in zone B by definition. Then I'd look towards a
>> multinomial
>> >>>>>> distribution. If the time spent outside both zones is dominant,
>> then you
>> >>>>>> can use a zero-inflated beta as you suggested. A zero-inflated
>> gamma might
>> >>>>>> be OK if the data is not too close to the upper boundary. If you
>> are
>> >>>>>> considering zero-inflated beta vs zero-inflated gamma, then you
>> should
>> >>>>>> choose zero-inflated beta IMHO.
>> >>>>>>
>> >>>>>> Best regards,
>> >>>>>>
>> >>>>>> ir. Thierry Onkelinx
>> >>>>>> Statisticus / Statistician
>> >>>>>>
>> >>>>>> Vlaamse Overheid / Government of Flanders
>> >>>>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR
>> NATURE
>> >>>>>> AND FOREST
>> >>>>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality
>> Assurance
>> >>>>>> thierry.onkelinx at inbo.be
>> >>>>>> Havenlaan 88 bus 73, 1000 Brussel
>> >>>>>> www.inbo.be
>> >>>>>>
>> >>>>>>
>> >>>>>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> >>>>>> To call in the statistician after the experiment is done may be no
>> >>>>>> more than asking him to perform a post-mortem examination: he may
>> be able
>> >>>>>> to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> >>>>>> The plural of anecdote is not data. ~ Roger Brinner
>> >>>>>> The combination of some data and an aching desire for an answer
>> does
>> >>>>>> not ensure that a reasonable answer can be extracted from a given
>> body of
>> >>>>>> data. ~ John Tukey
>> >>>>>>
>> >>>>>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> >>>>>>
>> >>>>>> <https://www.inbo.be>
>> >>>>>>
>> >>>>>>
>> >>>>>> Op ma 17 mei 2021 om 13:52 schreef Michael Lawson via
>> >>>>>> R-sig-mixed-models <r-sig-mixed-models at r-project.org>:
>> >>>>>>
>> >>>>>>> Hello,
>> >>>>>>>
>> >>>>>>> I am new to GLMMs and have a dataset where I have two distinct
>> groups
>> >>>>>>> (A
>> >>>>>>> and B) of 7 individuals each. The data consists of repeated
>> >>>>>>> measurements of
>> >>>>>>> each individual where the amount of time spent at either zone_A or
>> >>>>>>> zone_B
>> >>>>>>> is recorded (out of a total time of 300s/observation period). For
>> >>>>>>> most of
>> >>>>>>> the time period the individuals are in neither zone.
>> >>>>>>>
>> >>>>>>> I want to test if group A and group B spend more time in zone A
>> >>>>>>> compared to
>> >>>>>>> zone B (and vice versa).
>> >>>>>>>
>> >>>>>>> Speaking to someone else, they said I should use a Binomial GLMM
>> using
>> >>>>>>> cbind. i.e.
>> >>>>>>> cbind(time_at_zone_A, time_at_zone_B) ~ group + (1| id).
>> >>>>>>>
>> >>>>>>> However, the response variable is continuous (albeit with an upper
>> >>>>>>> bound of
>> >>>>>>> 300 seconds per observation period), so I'm not sure if this is
>> >>>>>>> appropriate?
>> >>>>>>>
>> >>>>>>> Should I convert the response into a proportion and use something
>> >>>>>>> like a
>> >>>>>>> Beta GLMM or else use a continuous (Gamma) GLMM? e.g. something
>> like:
>> >>>>>>> prop_time ~ zone*group + (1|id)
>> >>>>>>>
>> >>>>>>> The data is quite heavily right-skewed and contains a lot of 0's,
>> so
>> >>>>>>> reading around it also looks like I may need to convert these
>> into a
>> >>>>>>> zero-inflated/hurdle model?
>> >>>>>>>
>> >>>>>>> Thank you for any suggestions,
>> >>>>>>> Mike
>> >>>>>>>
>> >>>>>>>          [[alternative HTML version deleted]]
>> >>>>>>>
>> >>>>>>> _______________________________________________
>> >>>>>>> R-sig-mixed-models at r-project.org mailing list
>> >>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>>>>>>
>> >       [[alternative HTML version deleted]]
>> >
>> >
>> >
>> >
>> > ------------------------------
>> >
>> > Subject: Digest Footer
>> >
>> > _______________________________________________
>> > R-sig-mixed-models mailing list
>> > R-sig-mixed-models at r-project.org
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>> >
>> > ------------------------------
>> >
>> > End of R-sig-mixed-models Digest, Vol 173, Issue 19
>> > ***************************************************
>>
>> --
>> Dr. Alain F. Zuur
>> Highland Statistics Ltd.
>> 9 St Clair Wynd
>> AB41 6DZ Newburgh, UK
>> Email: highstat at highstat.com
>> URL:   www.highstat.com
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: sim_vs_real_zero_beta_glmm.png
Type: image/png
Size: 3157 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20210520/0645037f/attachment.png>

From th|erry@onke||nx @end|ng |rom |nbo@be  Thu May 20 11:08:33 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Thu, 20 May 2021 11:08:33 +0200
Subject: [R-sig-ME] 
 Model specification/family for a continuous/proportional,
 response with many zeros
In-Reply-To: <CACtWw1FQQzPQ7c-OW4Ha8K0GtpVrTQ=OO9zakcSZYsOJ4RqVDw@mail.gmail.com>
References: <mailman.19179.9.1621418401.6183.r-sig-mixed-models@r-project.org>
 <cfe43ac8-331e-2cb3-5ebe-304db69fea98@highstat.com>
 <CACtWw1Gd89u1TGPdbXaMVyB=2HcJnLNVj7Y2qRg=4NzfcERkdA@mail.gmail.com>
 <CACtWw1FQQzPQ7c-OW4Ha8K0GtpVrTQ=OO9zakcSZYsOJ4RqVDw@mail.gmail.com>
Message-ID: <CAJuCY5w1HhJKSWgykU0gWHRc_jKu1f3HnYAQp-uKL7T8F+GHow@mail.gmail.com>

Dear Mike,

Your code is completely unreadable. Did you send it in plain text? Sending
HTML email tends to mangle code.

I check the distribution by running a large number of simulations to get
the range of potential values. Then I divide the observed density (from the
data) by the expected density (from the simulations). See
https://inlatools.netlify.app/articles/distribution.html#distribution-checks-1
for an example. This is based on INLA models and doesn't handle beta
distributions (yet). But you can get an idea of how you can do this
yourself.

Best regards,

Thierry

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op do 20 mei 2021 om 10:46 schreef Michael Lawson via R-sig-mixed-models <
r-sig-mixed-models at r-project.org>:

> Hi again,
>
> I wanted to look a little more at the rest of the simulated values
> (non-zeros), so I took the mean proportion of simulated values in set bins
> of 0.01 and compared this to the real values.
>
>
> *bins <- seq(from = 0, to = 1, by = 0.01)*
>
>
>
>
>
>
>
>
>
>
>
>
> *sim_seq <- c()for(i in bins){  a <- mean(unlist(lapply(sim_beta_glmm,
> function(x){ length(which(x>i & x <= i+0.01))/length(x)}), use.names =
> FALSE))  sim_seq <- c(sim_seq,a)}real_seq <- c()for(i in bins){  a <-
> print(mean(unlist(lapply(glmm_zone_data$prop_time, function(x){
> length(which(x>i & x <= i+0.01))/length(x)}), use.names = FALSE)))
> real_seq <- c(real_seq,a)}*
>
>
> *barplot(rbind(sim_seq,real_seq),col=c("green","red"),beside = TRUE,
> legend.text = c("simulated","real"))*
>
>
> *cbind(bins,sim_seq,real_seq)*
>
>
>
>
>
>
>
>
>
>
>
> *bins         sim_seq    real_seq  [1,] 0.00 0.2199795081967 0.232240437
> [2,] 0.01 0.1021612021858 0.166666667  [3,] 0.02 0.0750964480874
> 0.103825137  [4,] 0.03 0.0592128415301 0.073770492  [5,] 0.04
> 0.0478316939891 0.038251366  [6,] 0.05 0.0397267759563 0.030054645  [7,]
> 0.06 0.0331961748634 0.016393443  [8,] 0.07 0.0279322404372 0.013661202
> [9,] 0.08 0.0238013661202 0.024590164 [10,] 0.09 0.0201101092896
> 0.010928962*
>
> As you can see in the output above (and the plot attached), the real data
> is quite a bit more right-skewed compared to the simulated values. Does
> this look like a good enough fit or will I have to try a different model?
>
> Many thanks,
> Mike
>
> On Wed, 19 May 2021 at 12:38, Michael Lawson <mrml500 at york.ac.uk> wrote:
>
> > Dear Alain,
> >
> > Thank you for the suggestion. I tried simulating the 0's as you suggested
> > in the following way. The output is reassuring - with the actual number
> of
> > zeros in the middle of the distribution.
> >
> > sim_beta_glmm <- simulate(beta_mod, nsim = 10000)
> > sim_zeros <- unlist(lapply(sim_beta_glmm, function(x){
> > length(which(x==0))/length(x)}), use.names = FALSE)
> > hist(sim_zeros, breaks = c(100))
> > abline(v = plogis(-1.1804), col = "red")
> >
> > All the best,
> > Mike
> >
> >
> > On Wed, 19 May 2021 at 11:19, Highland Statistics Ltd via
> > R-sig-mixed-models <r-sig-mixed-models at r-project.org> wrote:
> >
> >>
> >> > Today's Topics:
> >> >
> >> >     1. Re:  Model specification/family for a continuous/proportional
> >> >        response with many zeros (Michael Lawson)
> >> >
> >> > ----------------------------------------------------------------------
> >> >
> >> > Message: 1
> >> > Date: Wed, 19 May 2021 09:31:46 +0100
> >> > From: Michael Lawson <mrml500 at york.ac.uk>
> >> > To: Thierry Onkelinx <thierry.onkelinx at inbo.be>
> >> > Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
> >> > Subject: Re: [R-sig-ME]  Model specification/family for a
> >> >       continuous/proportional response with many zeros
> >> > Message-ID:
> >> >       <
> >> CACtWw1GAnDJ1d8CWh_DODP6jPqfsyptc-RV0gw0_5z9bWEwubw at mail.gmail.com>
> >> > Content-Type: text/plain; charset="utf-8"
> >> >
> >> > Hi Thierry,
> >> >
> >> > I understood after your previous message that a high dispersion
> >> parameter
> >> > in beta models does not signify overdispersion. Both answers addressed
> >> this
> >> > misconception in those two links I provided.
> >> >
> >> > I suppose the real answer I am now looking for is -  how do I assess
> the
> >> > validity and fit of the model? Are there specifics or assumptions I
> must
> >> > take into account with zero-inflated beta glmms?
> >>
> >> Just simulate 1000 data sets from your model, and see whether the
> >> simulated data sets are comparable to your original data. One of the
> >> things you can look at is whether the simulated data sets contain
> >> similar number of zeros as in the observed data. I'm not sure whether
> >> the DHARMA package can do this for you. If not..it is easy to program.
> >>
> >> See also Figure 8 in (sorry for self-citing):
> >>
> >>
> >>
> https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.12577
> >>
> >> Alain
> >>
> >>
> >> > Thanks for your help,
> >> > Mike
> >> >
> >> > On Tue, 18 May 2021 at 13:57, Thierry Onkelinx <
> >> thierry.onkelinx at inbo.be>
> >> > wrote:
> >> >
> >> >> Dear Mike,
> >> >>
> >> >> I think you misread my reply. I never stated that there's something
> >> wrong
> >> >> with the model. The only "problem" I highlighted was your
> misconception
> >> >> about the "high overdispersion". In this case, a high parameter value
> >> >> indicates a low variance, which is what we mostly want to see.
> >> >>
> >> >> Best regards,
> >> >>
> >> >> ir. Thierry Onkelinx
> >> >> Statisticus / Statistician
> >> >>
> >> >> Vlaamse Overheid / Government of Flanders
> >> >> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR
> NATURE
> >> AND
> >> >> FOREST
> >> >> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> >> >> thierry.onkelinx at inbo.be
> >> >> Havenlaan 88 bus 73, 1000 Brussel
> >> >> www.inbo.be
> >> >>
> >> >>
> >> >>
> >>
> ///////////////////////////////////////////////////////////////////////////////////////////
> >> >> To call in the statistician after the experiment is done may be no
> more
> >> >> than asking him to perform a post-mortem examination: he may be able
> >> to say
> >> >> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> >> >> The plural of anecdote is not data. ~ Roger Brinner
> >> >> The combination of some data and an aching desire for an answer does
> >> not
> >> >> ensure that a reasonable answer can be extracted from a given body of
> >> data.
> >> >> ~ John Tukey
> >> >>
> >> >>
> >>
> ///////////////////////////////////////////////////////////////////////////////////////////
> >> >>
> >> >> <https://www.inbo.be>
> >> >>
> >> >>
> >> >> Op di 18 mei 2021 om 12:49 schreef Michael Lawson <
> mrml500 at york.ac.uk
> >> >:
> >> >>
> >> >>> Dear Thierry,
> >> >>>
> >> >>> Thanks for the help. So if the dispersion parameter in this model
> >> doesn't
> >> >>> fit with the beta distribution, are there any alternative approaches
> >> I can
> >> >>> use?
> >> >>>
> >> >>> I can't seem to find much information on this elsewhere other than
> >> these
> >> >>> two threads:
> >> >>> https://stats.stackexchange.com/a/451453/233414
> >> >>> https://stats.stackexchange.com/a/466951/233414
> >> >>>
> >> >>> All the best,
> >> >>> Mike
> >> >>>
> >> >>> On Tue, 18 May 2021 at 08:12, Thierry Onkelinx <
> >> thierry.onkelinx at inbo.be>
> >> >>> wrote:
> >> >>>
> >> >>>> Dear Mike,
> >> >>>>
> >> >>>> The zero-inflation is specified on the logit scale. plogis(-1.18) =
> >> >>>> 0.235 23.5% zero seems reasonable when reading your story. (Didn't
> >> look at
> >> >>>> the data).
> >> >>>>
> >> >>>> You need to look at the definition for the "over"dispersion
> >> parameter.
> >> >>>> For a beta distribution is \phi with Var(y) = \mu * (1 - \mu) /
> >> (\phi + 1)
> >> >>>> (see ?glmmTMB::beta_family) Hence a large value of \phi implies a
> low
> >> >>>> variance.
> >> >>>>
> >> >>>> Best regards,
> >> >>>>
> >> >>>> ir. Thierry Onkelinx
> >> >>>> Statisticus / Statistician
> >> >>>>
> >> >>>> Vlaamse Overheid / Government of Flanders
> >> >>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR
> >> NATURE
> >> >>>> AND FOREST
> >> >>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality
> Assurance
> >> >>>> thierry.onkelinx at inbo.be
> >> >>>> Havenlaan 88 bus 73, 1000 Brussel
> >> >>>> www.inbo.be
> >> >>>>
> >> >>>>
> >> >>>>
> >>
> ///////////////////////////////////////////////////////////////////////////////////////////
> >> >>>> To call in the statistician after the experiment is done may be no
> >> more
> >> >>>> than asking him to perform a post-mortem examination: he may be
> able
> >> to say
> >> >>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> >> >>>> The plural of anecdote is not data. ~ Roger Brinner
> >> >>>> The combination of some data and an aching desire for an answer
> does
> >> not
> >> >>>> ensure that a reasonable answer can be extracted from a given body
> >> of data.
> >> >>>> ~ John Tukey
> >> >>>>
> >> >>>>
> >>
> ///////////////////////////////////////////////////////////////////////////////////////////
> >> >>>>
> >> >>>> <https://www.inbo.be>
> >> >>>>
> >> >>>>
> >> >>>> Op ma 17 mei 2021 om 15:45 schreef Michael Lawson <
> >> mrml500 at york.ac.uk>:
> >> >>>>
> >> >>>>> Hi Thierry,
> >> >>>>>
> >> >>>>> Thank you for your advice and speedy response.
> >> >>>>>
> >> >>>>> Most of the data is closer to the lower bound (0). e.g. the mean
> >> time
> >> >>>>> for group A in zone A = 15.1 seconds and group A in zone B = 3.8
> >> seconds.
> >> >>>>> However there are a very small number of outliers near the upper
> >> bound, the
> >> >>>>> largest being 294 out of the 300 seconds (see the attached file if
> >> you want
> >> >>>>> to look at the data).
> >> >>>>>
> >> >>>>> I have taken a stab at running a Zero-inflated Beta GLMM using
> >> glmmTMB
> >> >>>>> in R like so:
> >> >>>>>
> >> >>>>> betta_mod <- glmmTMB(prop_time ~ group*zone + (1|id),
> >> >>>>>                               family = beta_family(),
> >> >>>>>                               ziformula=~1,
> >> >>>>>                               data = glmm_zone_data)
> >> >>>>>
> >> >>>>> summary(beta_mod)
> >> >>>>>
> >> >>>>> *Family: beta  ( logit )*
> >> >>>>>
> >> >>>>>
> >> >>>>>
> >> >>>>>
> >> >>>>>
> >> >>>>>
> >> >>>>> *Formula:          prop_time ~ group * zone + (1 | id)Zero
> >> inflation:
> >> >>>>>            ~1Data: glmm_zone_data     AIC      BIC   logLik
> deviance
> >> >>>>> df.resid  -763.6   -736.3    388.8   -777.6      359Random
> >> >>>>> effects:Conditional model: Groups Name        Variance  Std.Dev.
> id
> >> >>>>> (Intercept) 2.386e-09 4.885e-05Number of obs: 366, groups:  id,
> >> >>>>> 14Overdispersion parameter for beta family (): 13.1Conditional
> >> model:
> >> >>>>>              Estimate Std. Error z value Pr(>|z|)    (Intercept)
> >> >>>>>   -2.7685     0.1031 -26.844  < 2e-16 ***groupB
>  -0.4455
> >> >>>>> 0.1498  -2.975 0.002932 **zonezone_B         -0.4179     0.1524
> >> -2.741
> >> >>>>> 0.006124 **groupB:zonezone_B   0.8443     0.2190   3.855 0.000116
> >> >>>>> ***---Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ?
> >> >>>>> 1Zero-inflation model:            Estimate Std. Error z value
> >> Pr(>|z|)
> >> >>>>>    (Intercept)  -1.1804     0.1233  -9.575   <2e-16 ***---Signif.
> >> codes:  0
> >> >>>>> ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1*
> >> >>>>>
> >> >>>>> Does this look like the correct way of specifying the model? I am
> a
> >> >>>>> little confused about specifying and interpreting the
> zero-inflation
> >> >>>>> component - I have only just begun reading about this.
> >> >>>>>
> >> >>>>> I noticed that the dispersion parameter is quite high at 13.1. I'm
> >> not
> >> >>>>> sure if this matters for beta models?. I tried running DHARMa
> >> >>>>> simulateResiduals on the model output and got significant
> >> deviations in the
> >> >>>>> dispersion (<2.2e-16) and KS tests. e.g.
> >> >>>>>
> >> >>>>> DHARMa::testDispersion(beta_mod)
> >> >>>>>
> >> >>>>> *DHARMa nonparametric dispersion test via sd of residuals fitted
> vs.
> >> >>>>> simulated*
> >> >>>>>
> >> >>>>> *data:  simulationOutput*
> >> >>>>> *ratioObsSim = 1.3612, p-value < 2.2e-16*
> >> >>>>> *alternative hypothesis: two.sided*
> >> >>>>>
> >> >>>>>
> >> >>>>>
> >> >>>>> Many thanks,
> >> >>>>> Mike
> >> >>>>>
> >> >>>>> On Mon, 17 May 2021 at 13:22, Thierry Onkelinx <
> >> >>>>> thierry.onkelinx at inbo.be> wrote:
> >> >>>>>
> >> >>>>>> Dear Michael,
> >> >>>>>>
> >> >>>>>> Your data has bounds (lower bound at 0 and upper bound at 300)
> and
> >> you
> >> >>>>>> have a lot of data close to a boundary. In such a case, a
> >> continuous
> >> >>>>>> distribution which ignores those bound is not a good idea. If the
> >> time
> >> >>>>>> spent outside of both zones is limited, then a long time in zone
> A
> >> excludes
> >> >>>>>> a long time in zone B by definition. Then I'd look towards a
> >> multinomial
> >> >>>>>> distribution. If the time spent outside both zones is dominant,
> >> then you
> >> >>>>>> can use a zero-inflated beta as you suggested. A zero-inflated
> >> gamma might
> >> >>>>>> be OK if the data is not too close to the upper boundary. If you
> >> are
> >> >>>>>> considering zero-inflated beta vs zero-inflated gamma, then you
> >> should
> >> >>>>>> choose zero-inflated beta IMHO.
> >> >>>>>>
> >> >>>>>> Best regards,
> >> >>>>>>
> >> >>>>>> ir. Thierry Onkelinx
> >> >>>>>> Statisticus / Statistician
> >> >>>>>>
> >> >>>>>> Vlaamse Overheid / Government of Flanders
> >> >>>>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR
> >> NATURE
> >> >>>>>> AND FOREST
> >> >>>>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality
> >> Assurance
> >> >>>>>> thierry.onkelinx at inbo.be
> >> >>>>>> Havenlaan 88 bus 73, 1000 Brussel
> >> >>>>>> www.inbo.be
> >> >>>>>>
> >> >>>>>>
> >> >>>>>>
> >>
> ///////////////////////////////////////////////////////////////////////////////////////////
> >> >>>>>> To call in the statistician after the experiment is done may be
> no
> >> >>>>>> more than asking him to perform a post-mortem examination: he may
> >> be able
> >> >>>>>> to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> >> >>>>>> The plural of anecdote is not data. ~ Roger Brinner
> >> >>>>>> The combination of some data and an aching desire for an answer
> >> does
> >> >>>>>> not ensure that a reasonable answer can be extracted from a given
> >> body of
> >> >>>>>> data. ~ John Tukey
> >> >>>>>>
> >> >>>>>>
> >>
> ///////////////////////////////////////////////////////////////////////////////////////////
> >> >>>>>>
> >> >>>>>> <https://www.inbo.be>
> >> >>>>>>
> >> >>>>>>
> >> >>>>>> Op ma 17 mei 2021 om 13:52 schreef Michael Lawson via
> >> >>>>>> R-sig-mixed-models <r-sig-mixed-models at r-project.org>:
> >> >>>>>>
> >> >>>>>>> Hello,
> >> >>>>>>>
> >> >>>>>>> I am new to GLMMs and have a dataset where I have two distinct
> >> groups
> >> >>>>>>> (A
> >> >>>>>>> and B) of 7 individuals each. The data consists of repeated
> >> >>>>>>> measurements of
> >> >>>>>>> each individual where the amount of time spent at either zone_A
> or
> >> >>>>>>> zone_B
> >> >>>>>>> is recorded (out of a total time of 300s/observation period).
> For
> >> >>>>>>> most of
> >> >>>>>>> the time period the individuals are in neither zone.
> >> >>>>>>>
> >> >>>>>>> I want to test if group A and group B spend more time in zone A
> >> >>>>>>> compared to
> >> >>>>>>> zone B (and vice versa).
> >> >>>>>>>
> >> >>>>>>> Speaking to someone else, they said I should use a Binomial GLMM
> >> using
> >> >>>>>>> cbind. i.e.
> >> >>>>>>> cbind(time_at_zone_A, time_at_zone_B) ~ group + (1| id).
> >> >>>>>>>
> >> >>>>>>> However, the response variable is continuous (albeit with an
> upper
> >> >>>>>>> bound of
> >> >>>>>>> 300 seconds per observation period), so I'm not sure if this is
> >> >>>>>>> appropriate?
> >> >>>>>>>
> >> >>>>>>> Should I convert the response into a proportion and use
> something
> >> >>>>>>> like a
> >> >>>>>>> Beta GLMM or else use a continuous (Gamma) GLMM? e.g. something
> >> like:
> >> >>>>>>> prop_time ~ zone*group + (1|id)
> >> >>>>>>>
> >> >>>>>>> The data is quite heavily right-skewed and contains a lot of
> 0's,
> >> so
> >> >>>>>>> reading around it also looks like I may need to convert these
> >> into a
> >> >>>>>>> zero-inflated/hurdle model?
> >> >>>>>>>
> >> >>>>>>> Thank you for any suggestions,
> >> >>>>>>> Mike
> >> >>>>>>>
> >> >>>>>>>          [[alternative HTML version deleted]]
> >> >>>>>>>
> >> >>>>>>> _______________________________________________
> >> >>>>>>> R-sig-mixed-models at r-project.org mailing list
> >> >>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >>>>>>>
> >> >       [[alternative HTML version deleted]]
> >> >
> >> >
> >> >
> >> >
> >> > ------------------------------
> >> >
> >> > Subject: Digest Footer
> >> >
> >> > _______________________________________________
> >> > R-sig-mixed-models mailing list
> >> > R-sig-mixed-models at r-project.org
> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >
> >> >
> >> > ------------------------------
> >> >
> >> > End of R-sig-mixed-models Digest, Vol 173, Issue 19
> >> > ***************************************************
> >>
> >> --
> >> Dr. Alain F. Zuur
> >> Highland Statistics Ltd.
> >> 9 St Clair Wynd
> >> AB41 6DZ Newburgh, UK
> >> Email: highstat at highstat.com
> >> URL:   www.highstat.com
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From mrm|500 @end|ng |rom york@@c@uk  Thu May 20 11:34:16 2021
From: mrm|500 @end|ng |rom york@@c@uk (Michael Lawson)
Date: Thu, 20 May 2021 10:34:16 +0100
Subject: [R-sig-ME] 
 Model specification/family for a continuous/proportional,
 response with many zeros
In-Reply-To: <CAJuCY5w1HhJKSWgykU0gWHRc_jKu1f3HnYAQp-uKL7T8F+GHow@mail.gmail.com>
References: <mailman.19179.9.1621418401.6183.r-sig-mixed-models@r-project.org>
 <cfe43ac8-331e-2cb3-5ebe-304db69fea98@highstat.com>
 <CACtWw1Gd89u1TGPdbXaMVyB=2HcJnLNVj7Y2qRg=4NzfcERkdA@mail.gmail.com>
 <CACtWw1FQQzPQ7c-OW4Ha8K0GtpVrTQ=OO9zakcSZYsOJ4RqVDw@mail.gmail.com>
 <CAJuCY5w1HhJKSWgykU0gWHRc_jKu1f3HnYAQp-uKL7T8F+GHow@mail.gmail.com>
Message-ID: <CACtWw1FnqSYdqZBmL2A13=6HLP2zchGjAQq-YXV3xhSwA9AOTQ@mail.gmail.com>

Dear Thierry,

Sorry, I didn't realise I was sending everything in HTML mode. I have
enabled plain text mode so hopefully it has worked this time (code
below). Thanks for the suggestion and link - comparing the
observed-expected density looks a lot better than just comparing the
means like I did. I'll have a go!

Thanks,
Mike

bins <- seq(from = 0, to = 1, by = 0.01)

sim_seq <- c()
for(i in bins){
  a <- mean(unlist(lapply(sim_beta_glmm, function(x){ length(which(x>i
& x <= i+0.01))/length(x)}), use.names = FALSE))
  sim_seq <- c(sim_seq,a)
}

real_seq <- c()
for(i in bins){
  a <- print(mean(unlist(lapply(glmm_zone_data$prop_time, function(x){
length(which(x>i & x <= i+0.01))/length(x)}), use.names = FALSE)))
  real_seq <- c(real_seq,a)
}

barplot(rbind(sim_seq,real_seq),col=c("green","red"),beside = TRUE,
legend.text = c("simulated","real"))

cbind(bins,sim_seq,real_seq)

bins         sim_seq    real_seq
  [1,] 0.00 0.2199795081967 0.232240437
  [2,] 0.01 0.1021612021858 0.166666667
  [3,] 0.02 0.0750964480874 0.103825137
  [4,] 0.03 0.0592128415301 0.073770492
  [5,] 0.04 0.0478316939891 0.038251366
  [6,] 0.05 0.0397267759563 0.030054645
  [7,] 0.06 0.0331961748634 0.016393443
  [8,] 0.07 0.0279322404372 0.013661202
  [9,] 0.08 0.0238013661202 0.024590164
 [10,] 0.09 0.0201101092896 0.010928962

On Thu, 20 May 2021 at 10:08, Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
>
> Dear Mike,
>
> Your code is completely unreadable. Did you send it in plain text? Sending HTML email tends to mangle code.
>
> I check the distribution by running a large number of simulations to get the range of potential values. Then I divide the observed density (from the data) by the expected density (from the simulations). See https://inlatools.netlify.app/articles/distribution.html#distribution-checks-1 for an example. This is based on INLA models and doesn't handle beta distributions (yet). But you can get an idea of how you can do this yourself.
>
> Best regards,
>
> Thierry
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
>
>
>
>
> Op do 20 mei 2021 om 10:46 schreef Michael Lawson via R-sig-mixed-models <r-sig-mixed-models at r-project.org>:
>>
>> Hi again,
>>
>> I wanted to look a little more at the rest of the simulated values
>> (non-zeros), so I took the mean proportion of simulated values in set bins
>> of 0.01 and compared this to the real values.
>>
>>
>> *bins <- seq(from = 0, to = 1, by = 0.01)*
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> *sim_seq <- c()for(i in bins){  a <- mean(unlist(lapply(sim_beta_glmm,
>> function(x){ length(which(x>i & x <= i+0.01))/length(x)}), use.names =
>> FALSE))  sim_seq <- c(sim_seq,a)}real_seq <- c()for(i in bins){  a <-
>> print(mean(unlist(lapply(glmm_zone_data$prop_time, function(x){
>> length(which(x>i & x <= i+0.01))/length(x)}), use.names = FALSE)))
>> real_seq <- c(real_seq,a)}*
>>
>>
>> *barplot(rbind(sim_seq,real_seq),col=c("green","red"),beside = TRUE,
>> legend.text = c("simulated","real"))*
>>
>>
>> *cbind(bins,sim_seq,real_seq)*
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> *bins         sim_seq    real_seq  [1,] 0.00 0.2199795081967 0.232240437
>> [2,] 0.01 0.1021612021858 0.166666667  [3,] 0.02 0.0750964480874
>> 0.103825137  [4,] 0.03 0.0592128415301 0.073770492  [5,] 0.04
>> 0.0478316939891 0.038251366  [6,] 0.05 0.0397267759563 0.030054645  [7,]
>> 0.06 0.0331961748634 0.016393443  [8,] 0.07 0.0279322404372 0.013661202
>> [9,] 0.08 0.0238013661202 0.024590164 [10,] 0.09 0.0201101092896
>> 0.010928962*
>>
>> As you can see in the output above (and the plot attached), the real data
>> is quite a bit more right-skewed compared to the simulated values. Does
>> this look like a good enough fit or will I have to try a different model?
>>
>> Many thanks,
>> Mike
>>
>> On Wed, 19 May 2021 at 12:38, Michael Lawson <mrml500 at york.ac.uk> wrote:
>>
>> > Dear Alain,
>> >
>> > Thank you for the suggestion. I tried simulating the 0's as you suggested
>> > in the following way. The output is reassuring - with the actual number of
>> > zeros in the middle of the distribution.
>> >
>> > sim_beta_glmm <- simulate(beta_mod, nsim = 10000)
>> > sim_zeros <- unlist(lapply(sim_beta_glmm, function(x){
>> > length(which(x==0))/length(x)}), use.names = FALSE)
>> > hist(sim_zeros, breaks = c(100))
>> > abline(v = plogis(-1.1804), col = "red")
>> >
>> > All the best,
>> > Mike
>> >
>> >
>> > On Wed, 19 May 2021 at 11:19, Highland Statistics Ltd via
>> > R-sig-mixed-models <r-sig-mixed-models at r-project.org> wrote:
>> >
>> >>
>> >> > Today's Topics:
>> >> >
>> >> >     1. Re:  Model specification/family for a continuous/proportional
>> >> >        response with many zeros (Michael Lawson)
>> >> >
>> >> > ----------------------------------------------------------------------
>> >> >
>> >> > Message: 1
>> >> > Date: Wed, 19 May 2021 09:31:46 +0100
>> >> > From: Michael Lawson <mrml500 at york.ac.uk>
>> >> > To: Thierry Onkelinx <thierry.onkelinx at inbo.be>
>> >> > Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
>> >> > Subject: Re: [R-sig-ME]  Model specification/family for a
>> >> >       continuous/proportional response with many zeros
>> >> > Message-ID:
>> >> >       <
>> >> CACtWw1GAnDJ1d8CWh_DODP6jPqfsyptc-RV0gw0_5z9bWEwubw at mail.gmail.com>
>> >> > Content-Type: text/plain; charset="utf-8"
>> >> >
>> >> > Hi Thierry,
>> >> >
>> >> > I understood after your previous message that a high dispersion
>> >> parameter
>> >> > in beta models does not signify overdispersion. Both answers addressed
>> >> this
>> >> > misconception in those two links I provided.
>> >> >
>> >> > I suppose the real answer I am now looking for is -  how do I assess the
>> >> > validity and fit of the model? Are there specifics or assumptions I must
>> >> > take into account with zero-inflated beta glmms?
>> >>
>> >> Just simulate 1000 data sets from your model, and see whether the
>> >> simulated data sets are comparable to your original data. One of the
>> >> things you can look at is whether the simulated data sets contain
>> >> similar number of zeros as in the observed data. I'm not sure whether
>> >> the DHARMA package can do this for you. If not..it is easy to program.
>> >>
>> >> See also Figure 8 in (sorry for self-citing):
>> >>
>> >>
>> >> https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.12577
>> >>
>> >> Alain
>> >>
>> >>
>> >> > Thanks for your help,
>> >> > Mike
>> >> >
>> >> > On Tue, 18 May 2021 at 13:57, Thierry Onkelinx <
>> >> thierry.onkelinx at inbo.be>
>> >> > wrote:
>> >> >
>> >> >> Dear Mike,
>> >> >>
>> >> >> I think you misread my reply. I never stated that there's something
>> >> wrong
>> >> >> with the model. The only "problem" I highlighted was your misconception
>> >> >> about the "high overdispersion". In this case, a high parameter value
>> >> >> indicates a low variance, which is what we mostly want to see.
>> >> >>
>> >> >> Best regards,
>> >> >>
>> >> >> ir. Thierry Onkelinx
>> >> >> Statisticus / Statistician
>> >> >>
>> >> >> Vlaamse Overheid / Government of Flanders
>> >> >> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>> >> AND
>> >> >> FOREST
>> >> >> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> >> >> thierry.onkelinx at inbo.be
>> >> >> Havenlaan 88 bus 73, 1000 Brussel
>> >> >> www.inbo.be
>> >> >>
>> >> >>
>> >> >>
>> >> ///////////////////////////////////////////////////////////////////////////////////////////
>> >> >> To call in the statistician after the experiment is done may be no more
>> >> >> than asking him to perform a post-mortem examination: he may be able
>> >> to say
>> >> >> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> >> >> The plural of anecdote is not data. ~ Roger Brinner
>> >> >> The combination of some data and an aching desire for an answer does
>> >> not
>> >> >> ensure that a reasonable answer can be extracted from a given body of
>> >> data.
>> >> >> ~ John Tukey
>> >> >>
>> >> >>
>> >> ///////////////////////////////////////////////////////////////////////////////////////////
>> >> >>
>> >> >> <https://www.inbo.be>
>> >> >>
>> >> >>
>> >> >> Op di 18 mei 2021 om 12:49 schreef Michael Lawson <mrml500 at york.ac.uk
>> >> >:
>> >> >>
>> >> >>> Dear Thierry,
>> >> >>>
>> >> >>> Thanks for the help. So if the dispersion parameter in this model
>> >> doesn't
>> >> >>> fit with the beta distribution, are there any alternative approaches
>> >> I can
>> >> >>> use?
>> >> >>>
>> >> >>> I can't seem to find much information on this elsewhere other than
>> >> these
>> >> >>> two threads:
>> >> >>> https://stats.stackexchange.com/a/451453/233414
>> >> >>> https://stats.stackexchange.com/a/466951/233414
>> >> >>>
>> >> >>> All the best,
>> >> >>> Mike
>> >> >>>
>> >> >>> On Tue, 18 May 2021 at 08:12, Thierry Onkelinx <
>> >> thierry.onkelinx at inbo.be>
>> >> >>> wrote:
>> >> >>>
>> >> >>>> Dear Mike,
>> >> >>>>
>> >> >>>> The zero-inflation is specified on the logit scale. plogis(-1.18) =
>> >> >>>> 0.235 23.5% zero seems reasonable when reading your story. (Didn't
>> >> look at
>> >> >>>> the data).
>> >> >>>>
>> >> >>>> You need to look at the definition for the "over"dispersion
>> >> parameter.
>> >> >>>> For a beta distribution is \phi with Var(y) = \mu * (1 - \mu) /
>> >> (\phi + 1)
>> >> >>>> (see ?glmmTMB::beta_family) Hence a large value of \phi implies a low
>> >> >>>> variance.
>> >> >>>>
>> >> >>>> Best regards,
>> >> >>>>
>> >> >>>> ir. Thierry Onkelinx
>> >> >>>> Statisticus / Statistician
>> >> >>>>
>> >> >>>> Vlaamse Overheid / Government of Flanders
>> >> >>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR
>> >> NATURE
>> >> >>>> AND FOREST
>> >> >>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> >> >>>> thierry.onkelinx at inbo.be
>> >> >>>> Havenlaan 88 bus 73, 1000 Brussel
>> >> >>>> www.inbo.be
>> >> >>>>
>> >> >>>>
>> >> >>>>
>> >> ///////////////////////////////////////////////////////////////////////////////////////////
>> >> >>>> To call in the statistician after the experiment is done may be no
>> >> more
>> >> >>>> than asking him to perform a post-mortem examination: he may be able
>> >> to say
>> >> >>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> >> >>>> The plural of anecdote is not data. ~ Roger Brinner
>> >> >>>> The combination of some data and an aching desire for an answer does
>> >> not
>> >> >>>> ensure that a reasonable answer can be extracted from a given body
>> >> of data.
>> >> >>>> ~ John Tukey
>> >> >>>>
>> >> >>>>
>> >> ///////////////////////////////////////////////////////////////////////////////////////////
>> >> >>>>
>> >> >>>> <https://www.inbo.be>
>> >> >>>>
>> >> >>>>
>> >> >>>> Op ma 17 mei 2021 om 15:45 schreef Michael Lawson <
>> >> mrml500 at york.ac.uk>:
>> >> >>>>
>> >> >>>>> Hi Thierry,
>> >> >>>>>
>> >> >>>>> Thank you for your advice and speedy response.
>> >> >>>>>
>> >> >>>>> Most of the data is closer to the lower bound (0). e.g. the mean
>> >> time
>> >> >>>>> for group A in zone A = 15.1 seconds and group A in zone B = 3.8
>> >> seconds.
>> >> >>>>> However there are a very small number of outliers near the upper
>> >> bound, the
>> >> >>>>> largest being 294 out of the 300 seconds (see the attached file if
>> >> you want
>> >> >>>>> to look at the data).
>> >> >>>>>
>> >> >>>>> I have taken a stab at running a Zero-inflated Beta GLMM using
>> >> glmmTMB
>> >> >>>>> in R like so:
>> >> >>>>>
>> >> >>>>> betta_mod <- glmmTMB(prop_time ~ group*zone + (1|id),
>> >> >>>>>                               family = beta_family(),
>> >> >>>>>                               ziformula=~1,
>> >> >>>>>                               data = glmm_zone_data)
>> >> >>>>>
>> >> >>>>> summary(beta_mod)
>> >> >>>>>
>> >> >>>>> *Family: beta  ( logit )*
>> >> >>>>>
>> >> >>>>>
>> >> >>>>>
>> >> >>>>>
>> >> >>>>>
>> >> >>>>>
>> >> >>>>> *Formula:          prop_time ~ group * zone + (1 | id)Zero
>> >> inflation:
>> >> >>>>>            ~1Data: glmm_zone_data     AIC      BIC   logLik deviance
>> >> >>>>> df.resid  -763.6   -736.3    388.8   -777.6      359Random
>> >> >>>>> effects:Conditional model: Groups Name        Variance  Std.Dev. id
>> >> >>>>> (Intercept) 2.386e-09 4.885e-05Number of obs: 366, groups:  id,
>> >> >>>>> 14Overdispersion parameter for beta family (): 13.1Conditional
>> >> model:
>> >> >>>>>              Estimate Std. Error z value Pr(>|z|)    (Intercept)
>> >> >>>>>   -2.7685     0.1031 -26.844  < 2e-16 ***groupB             -0.4455
>> >> >>>>> 0.1498  -2.975 0.002932 **zonezone_B         -0.4179     0.1524
>> >> -2.741
>> >> >>>>> 0.006124 **groupB:zonezone_B   0.8443     0.2190   3.855 0.000116
>> >> >>>>> ***---Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ?
>> >> >>>>> 1Zero-inflation model:            Estimate Std. Error z value
>> >> Pr(>|z|)
>> >> >>>>>    (Intercept)  -1.1804     0.1233  -9.575   <2e-16 ***---Signif.
>> >> codes:  0
>> >> >>>>> ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1*
>> >> >>>>>
>> >> >>>>> Does this look like the correct way of specifying the model? I am a
>> >> >>>>> little confused about specifying and interpreting the zero-inflation
>> >> >>>>> component - I have only just begun reading about this.
>> >> >>>>>
>> >> >>>>> I noticed that the dispersion parameter is quite high at 13.1. I'm
>> >> not
>> >> >>>>> sure if this matters for beta models?. I tried running DHARMa
>> >> >>>>> simulateResiduals on the model output and got significant
>> >> deviations in the
>> >> >>>>> dispersion (<2.2e-16) and KS tests. e.g.
>> >> >>>>>
>> >> >>>>> DHARMa::testDispersion(beta_mod)
>> >> >>>>>
>> >> >>>>> *DHARMa nonparametric dispersion test via sd of residuals fitted vs.
>> >> >>>>> simulated*
>> >> >>>>>
>> >> >>>>> *data:  simulationOutput*
>> >> >>>>> *ratioObsSim = 1.3612, p-value < 2.2e-16*
>> >> >>>>> *alternative hypothesis: two.sided*
>> >> >>>>>
>> >> >>>>>
>> >> >>>>>
>> >> >>>>> Many thanks,
>> >> >>>>> Mike
>> >> >>>>>
>> >> >>>>> On Mon, 17 May 2021 at 13:22, Thierry Onkelinx <
>> >> >>>>> thierry.onkelinx at inbo.be> wrote:
>> >> >>>>>
>> >> >>>>>> Dear Michael,
>> >> >>>>>>
>> >> >>>>>> Your data has bounds (lower bound at 0 and upper bound at 300) and
>> >> you
>> >> >>>>>> have a lot of data close to a boundary. In such a case, a
>> >> continuous
>> >> >>>>>> distribution which ignores those bound is not a good idea. If the
>> >> time
>> >> >>>>>> spent outside of both zones is limited, then a long time in zone A
>> >> excludes
>> >> >>>>>> a long time in zone B by definition. Then I'd look towards a
>> >> multinomial
>> >> >>>>>> distribution. If the time spent outside both zones is dominant,
>> >> then you
>> >> >>>>>> can use a zero-inflated beta as you suggested. A zero-inflated
>> >> gamma might
>> >> >>>>>> be OK if the data is not too close to the upper boundary. If you
>> >> are
>> >> >>>>>> considering zero-inflated beta vs zero-inflated gamma, then you
>> >> should
>> >> >>>>>> choose zero-inflated beta IMHO.
>> >> >>>>>>
>> >> >>>>>> Best regards,
>> >> >>>>>>
>> >> >>>>>> ir. Thierry Onkelinx
>> >> >>>>>> Statisticus / Statistician
>> >> >>>>>>
>> >> >>>>>> Vlaamse Overheid / Government of Flanders
>> >> >>>>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR
>> >> NATURE
>> >> >>>>>> AND FOREST
>> >> >>>>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality
>> >> Assurance
>> >> >>>>>> thierry.onkelinx at inbo.be
>> >> >>>>>> Havenlaan 88 bus 73, 1000 Brussel
>> >> >>>>>> www.inbo.be
>> >> >>>>>>
>> >> >>>>>>
>> >> >>>>>>
>> >> ///////////////////////////////////////////////////////////////////////////////////////////
>> >> >>>>>> To call in the statistician after the experiment is done may be no
>> >> >>>>>> more than asking him to perform a post-mortem examination: he may
>> >> be able
>> >> >>>>>> to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> >> >>>>>> The plural of anecdote is not data. ~ Roger Brinner
>> >> >>>>>> The combination of some data and an aching desire for an answer
>> >> does
>> >> >>>>>> not ensure that a reasonable answer can be extracted from a given
>> >> body of
>> >> >>>>>> data. ~ John Tukey
>> >> >>>>>>
>> >> >>>>>>
>> >> ///////////////////////////////////////////////////////////////////////////////////////////
>> >> >>>>>>
>> >> >>>>>> <https://www.inbo.be>
>> >> >>>>>>
>> >> >>>>>>
>> >> >>>>>> Op ma 17 mei 2021 om 13:52 schreef Michael Lawson via
>> >> >>>>>> R-sig-mixed-models <r-sig-mixed-models at r-project.org>:
>> >> >>>>>>
>> >> >>>>>>> Hello,
>> >> >>>>>>>
>> >> >>>>>>> I am new to GLMMs and have a dataset where I have two distinct
>> >> groups
>> >> >>>>>>> (A
>> >> >>>>>>> and B) of 7 individuals each. The data consists of repeated
>> >> >>>>>>> measurements of
>> >> >>>>>>> each individual where the amount of time spent at either zone_A or
>> >> >>>>>>> zone_B
>> >> >>>>>>> is recorded (out of a total time of 300s/observation period). For
>> >> >>>>>>> most of
>> >> >>>>>>> the time period the individuals are in neither zone.
>> >> >>>>>>>
>> >> >>>>>>> I want to test if group A and group B spend more time in zone A
>> >> >>>>>>> compared to
>> >> >>>>>>> zone B (and vice versa).
>> >> >>>>>>>
>> >> >>>>>>> Speaking to someone else, they said I should use a Binomial GLMM
>> >> using
>> >> >>>>>>> cbind. i.e.
>> >> >>>>>>> cbind(time_at_zone_A, time_at_zone_B) ~ group + (1| id).
>> >> >>>>>>>
>> >> >>>>>>> However, the response variable is continuous (albeit with an upper
>> >> >>>>>>> bound of
>> >> >>>>>>> 300 seconds per observation period), so I'm not sure if this is
>> >> >>>>>>> appropriate?
>> >> >>>>>>>
>> >> >>>>>>> Should I convert the response into a proportion and use something
>> >> >>>>>>> like a
>> >> >>>>>>> Beta GLMM or else use a continuous (Gamma) GLMM? e.g. something
>> >> like:
>> >> >>>>>>> prop_time ~ zone*group + (1|id)
>> >> >>>>>>>
>> >> >>>>>>> The data is quite heavily right-skewed and contains a lot of 0's,
>> >> so
>> >> >>>>>>> reading around it also looks like I may need to convert these
>> >> into a
>> >> >>>>>>> zero-inflated/hurdle model?
>> >> >>>>>>>
>> >> >>>>>>> Thank you for any suggestions,
>> >> >>>>>>> Mike
>> >> >>>>>>>
>> >> >>>>>>>          [[alternative HTML version deleted]]
>> >> >>>>>>>
>> >> >>>>>>> _______________________________________________
>> >> >>>>>>> R-sig-mixed-models at r-project.org mailing list
>> >> >>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >> >>>>>>>
>> >> >       [[alternative HTML version deleted]]
>> >> >
>> >> >
>> >> >
>> >> >
>> >> > ------------------------------
>> >> >
>> >> > Subject: Digest Footer
>> >> >
>> >> > _______________________________________________
>> >> > R-sig-mixed-models mailing list
>> >> > R-sig-mixed-models at r-project.org
>> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >> >
>> >> >
>> >> > ------------------------------
>> >> >
>> >> > End of R-sig-mixed-models Digest, Vol 173, Issue 19
>> >> > ***************************************************
>> >>
>> >> --
>> >> Dr. Alain F. Zuur
>> >> Highland Statistics Ltd.
>> >> 9 St Clair Wynd
>> >> AB41 6DZ Newburgh, UK
>> >> Email: highstat at highstat.com
>> >> URL:   www.highstat.com
>> >>
>> >> _______________________________________________
>> >> R-sig-mixed-models at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>
>> >
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From john@m@|ndon@|d @end|ng |rom @nu@edu@@u  Fri May 21 12:30:07 2021
From: john@m@|ndon@|d @end|ng |rom @nu@edu@@u (John Maindonald)
Date: Fri, 21 May 2021 10:30:07 +0000
Subject: [R-sig-ME] glmmTMB predicted values and AIC, vs glmer
In-Reply-To: <CACtWw1FnqSYdqZBmL2A13=6HLP2zchGjAQq-YXV3xhSwA9AOTQ@mail.gmail.com>
References: <mailman.19179.9.1621418401.6183.r-sig-mixed-models@r-project.org>
 <cfe43ac8-331e-2cb3-5ebe-304db69fea98@highstat.com>
 <CACtWw1Gd89u1TGPdbXaMVyB=2HcJnLNVj7Y2qRg=4NzfcERkdA@mail.gmail.com>
 <CACtWw1FQQzPQ7c-OW4Ha8K0GtpVrTQ=OO9zakcSZYsOJ4RqVDw@mail.gmail.com>
 <CAJuCY5w1HhJKSWgykU0gWHRc_jKu1f3HnYAQp-uKL7T8F+GHow@mail.gmail.com>
 <CACtWw1FnqSYdqZBmL2A13=6HLP2zchGjAQq-YXV3xhSwA9AOTQ@mail.gmail.com>
Message-ID: <F5A31EE3-29CF-472C-A398-8F94B5FAEF3D@anu.edu.au>

The code that follows below demonstrates what I find a very odd
issue with r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>, and with the comparison between
glmmTMB::glmmTMB and lme4::glmer, for models that have the
same model formulae.

1) In the glmmTMB model as fitted to `ffly`, one predicted value is
infinite.  This, even though all coefficients and standard errors
have finite values.  This surely indicates that there is something
odd in the way that predictions on the scale of the linear
predictor are calculated.

2) Initially, I'd thought that the `Inf` value explained the
difference between the two AIC values.  But the difference
pretty much stays the same when the "offending" point is
removed.

I've not checked what happens when there are no observation level
random effects.  Is there some difference in the way that the
model formulae are interpreted in the two cases?


ffly <- read.csv('https://github.com/jhmaindonald/dataR/files/6521483/ffly.csv')
ffly$obs <- factor(ffly$obs)

form1 <- cbind(Dead,Live)~0+trtGp/TrtTime+(1|obs)+(1|trtGpRep)

library(lme4); library(glmmTMB)
ObsTMB.cll <- glmmTMB(form1,
                      family=binomial(link="cloglog"), data=ffly)
Obsglmer.cll <- glmer(form1, nAGQ=0,
                      family=binomial(link="cloglog"), data=ffly)

round(AIC(Obsglmer.cll, ObsTMB.cll), 2)
##                      df    AIC
## Obsglmer.cll 14 639.44
## ObsTMB.cll  14 636.02

round(c(max(predict(ObsTMB.cll)),max(predict(Obsglmer.cll))),3)
## [1]   Inf 3.833

range(fixef(ObsTMB.cll))
## [1] -5.28780064553  1.15952249272
range(vcov(ObsTMB.cll))
## [1] -0.0546986905338  0.2887049942215

## Try also; there are small deviations from the line
plot(predict(Obsglmer.cll)~predict(ObsTMB.cll))
abline(0,1)

## Remove offending point
ffly1 <- ffly[-which.max(predict(ObsTMB.cll)),]
ObsTMB1.cll <- glmmTMB(form1,
                      family=binomial(link="cloglog"), data=ffly1)
Obsglmer1.cll <- glmer(form1, nAGQ=0,
                      family=binomial(link="cloglog"), data=ffly1)

cbind(AIC(Obsglmer.cll, ObsTMB.cll), AIC1=AIC(Obsglmer1.cll, ObsTMB1.cll)[,2])
##                       df                    AIC                  AIC1
## Obsglmer.cll  14 639.441888969 639.441889196
## ObsTMB.cll   14 636.016597730 636.016597723
  ## Observe that changes are in the final four decimal places.


round(rbind(glmer=fixef(Obsglmer1.cll),
TMB=unclass(fixef(ObsTMB1.cll)$cond)),3)

      trtGpspAEgg trtGpspAL2 trtGpspAL3 trtGpspBEgg trtGpspBL2 trtGpspBL3
glmer       0.772     -2.255     -3.299      -1.803     -2.632     -5.114
TMB         0.790     -2.367     -3.441      -1.889     -2.757     -5.288
      trtGpspAEgg:TrtTime trtGpspAL2:TrtTime trtGpspAL3:TrtTime
glmer               0.231              0.372              0.563
TMB                 0.288              0.398              0.602
      trtGpspBEgg:TrtTime trtGpspBL2:TrtTime trtGpspBL3:TrtTime
glmer               0.278              0.517              1.112
TMB                 0.299              0.554              1.160


John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>


	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Fri May 21 15:27:42 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 21 May 2021 09:27:42 -0400
Subject: [R-sig-ME] glmmTMB predicted values and AIC, vs glmer
In-Reply-To: <F5A31EE3-29CF-472C-A398-8F94B5FAEF3D@anu.edu.au>
References: <mailman.19179.9.1621418401.6183.r-sig-mixed-models@r-project.org>
 <cfe43ac8-331e-2cb3-5ebe-304db69fea98@highstat.com>
 <CACtWw1Gd89u1TGPdbXaMVyB=2HcJnLNVj7Y2qRg=4NzfcERkdA@mail.gmail.com>
 <CACtWw1FQQzPQ7c-OW4Ha8K0GtpVrTQ=OO9zakcSZYsOJ4RqVDw@mail.gmail.com>
 <CAJuCY5w1HhJKSWgykU0gWHRc_jKu1f3HnYAQp-uKL7T8F+GHow@mail.gmail.com>
 <CACtWw1FnqSYdqZBmL2A13=6HLP2zchGjAQq-YXV3xhSwA9AOTQ@mail.gmail.com>
 <F5A31EE3-29CF-472C-A398-8F94B5FAEF3D@anu.edu.au>
Message-ID: <f6ecb9ba-2cfe-36c4-6ef3-ebe9a4727fe4@gmail.com>

   I don't know yet, I will dig in and try to see what's going on.  An 
infinite predicted value certainly seems like an issue.

   The most obvious difference is that nAGQ=0 is actually doing 
something slightly different (it's fitting the fixed-effect parameters 
as part of the PIRLS loop rather than maximizing over them explicitly); 
I would rather compare the nAGQ=1 case, just to minimize the number of 
differences.

On 5/21/21 6:30 AM, John Maindonald wrote:
> The code that follows below demonstrates what I find a very odd
> issue with r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>, and with the comparison between
> glmmTMB::glmmTMB and lme4::glmer, for models that have the
> same model formulae.
> 
> 1) In the glmmTMB model as fitted to `ffly`, one predicted value is
> infinite.  This, even though all coefficients and standard errors
> have finite values.  This surely indicates that there is something
> odd in the way that predictions on the scale of the linear
> predictor are calculated.
> 
> 2) Initially, I'd thought that the `Inf` value explained the
> difference between the two AIC values.  But the difference
> pretty much stays the same when the "offending" point is
> removed.
> 
> I've not checked what happens when there are no observation level
> random effects.  Is there some difference in the way that the
> model formulae are interpreted in the two cases?
> 
> 
> ffly <- read.csv('https://github.com/jhmaindonald/dataR/files/6521483/ffly.csv')
> ffly$obs <- factor(ffly$obs)
> 
> form1 <- cbind(Dead,Live)~0+trtGp/TrtTime+(1|obs)+(1|trtGpRep)
> 
> library(lme4); library(glmmTMB)
> ObsTMB.cll <- glmmTMB(form1,
>                        family=binomial(link="cloglog"), data=ffly)
> Obsglmer.cll <- glmer(form1, nAGQ=0,
>                        family=binomial(link="cloglog"), data=ffly)
> 
> round(AIC(Obsglmer.cll, ObsTMB.cll), 2)
> ##                      df    AIC
> ## Obsglmer.cll 14 639.44
> ## ObsTMB.cll  14 636.02
> 
> round(c(max(predict(ObsTMB.cll)),max(predict(Obsglmer.cll))),3)
> ## [1]   Inf 3.833
> 
> range(fixef(ObsTMB.cll))
> ## [1] -5.28780064553  1.15952249272
> range(vcov(ObsTMB.cll))
> ## [1] -0.0546986905338  0.2887049942215
> 
> ## Try also; there are small deviations from the line
> plot(predict(Obsglmer.cll)~predict(ObsTMB.cll))
> abline(0,1)
> 
> ## Remove offending point
> ffly1 <- ffly[-which.max(predict(ObsTMB.cll)),]
> ObsTMB1.cll <- glmmTMB(form1,
>                        family=binomial(link="cloglog"), data=ffly1)
> Obsglmer1.cll <- glmer(form1, nAGQ=0,
>                        family=binomial(link="cloglog"), data=ffly1)
> 
> cbind(AIC(Obsglmer.cll, ObsTMB.cll), AIC1=AIC(Obsglmer1.cll, ObsTMB1.cll)[,2])
> ##                       df                    AIC                  AIC1
> ## Obsglmer.cll  14 639.441888969 639.441889196
> ## ObsTMB.cll   14 636.016597730 636.016597723
>    ## Observe that changes are in the final four decimal places.
> 
> 
> round(rbind(glmer=fixef(Obsglmer1.cll),
> TMB=unclass(fixef(ObsTMB1.cll)$cond)),3)
> 
>        trtGpspAEgg trtGpspAL2 trtGpspAL3 trtGpspBEgg trtGpspBL2 trtGpspBL3
> glmer       0.772     -2.255     -3.299      -1.803     -2.632     -5.114
> TMB         0.790     -2.367     -3.441      -1.889     -2.757     -5.288
>        trtGpspAEgg:TrtTime trtGpspAL2:TrtTime trtGpspAL3:TrtTime
> glmer               0.231              0.372              0.563
> TMB                 0.288              0.398              0.602
>        trtGpspBEgg:TrtTime trtGpspBL2:TrtTime trtGpspBL3:TrtTime
> glmer               0.278              0.517              1.112
> TMB                 0.299              0.554              1.160
> 
> 
> John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From john@m@|ndon@|d @end|ng |rom @nu@edu@@u  Sat May 22 00:24:20 2021
From: john@m@|ndon@|d @end|ng |rom @nu@edu@@u (John Maindonald)
Date: Fri, 21 May 2021 22:24:20 +0000
Subject: [R-sig-ME] glmmTMB predicted values and AIC, vs glmer
In-Reply-To: <f6ecb9ba-2cfe-36c4-6ef3-ebe9a4727fe4@gmail.com>
References: <mailman.19179.9.1621418401.6183.r-sig-mixed-models@r-project.org>
 <cfe43ac8-331e-2cb3-5ebe-304db69fea98@highstat.com>
 <CACtWw1Gd89u1TGPdbXaMVyB=2HcJnLNVj7Y2qRg=4NzfcERkdA@mail.gmail.com>
 <CACtWw1FQQzPQ7c-OW4Ha8K0GtpVrTQ=OO9zakcSZYsOJ4RqVDw@mail.gmail.com>
 <CAJuCY5w1HhJKSWgykU0gWHRc_jKu1f3HnYAQp-uKL7T8F+GHow@mail.gmail.com>
 <CACtWw1FnqSYdqZBmL2A13=6HLP2zchGjAQq-YXV3xhSwA9AOTQ@mail.gmail.com>
 <F5A31EE3-29CF-472C-A398-8F94B5FAEF3D@anu.edu.au>
 <f6ecb9ba-2cfe-36c4-6ef3-ebe9a4727fe4@gmail.com>
Message-ID: <E48CBF04-01E3-491F-B139-F13B2B533B3B@anu.edu.au>

Setting nAGQ=1 does bring the AIC values closer together, albeit with
convergence failure when other parameters are left at their defaults.
Running allFit() does not provide (to me) any obvious clues on what
might work better.  Or, should one just accept the less strict tolerance?
Nor does centering and scale scTime help in this case.

llik <- summary(allFit(Obsglmer1.cll))$llik
max(lik)-lik
##                       bobyqa                   Nelder_Mead
##           0.00000000000e+00             1.31201379190e-04
##                   nlminbwrap                         nmkbw
##            1.76015646502e-09             3.48215053236e-06
##              optimx.L-BFGS-B nloptwrap.NLOPT_LN_NELDERMEAD
##            1.09246872171e-06             1.13990722639e-07
##    nloptwrap.NLOPT_LN_BOBYQA
##            5.81495783081e-07


John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>


On 22/05/2021, at 01:27, Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com>> wrote:

 I don't know yet, I will dig in and try to see what's going on.  An infinite predicted value certainly seems like an issue.

 The most obvious difference is that nAGQ=0 is actually doing something slightly different (it's fitting the fixed-effect parameters as part of the PIRLS loop rather than maximizing over them explicitly); I would rather compare the nAGQ=1 case, just to minimize the number of differences.

On 5/21/21 6:30 AM, John Maindonald wrote:
The code that follows below demonstrates what I find a very odd
issue with r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org><mailto:r-sig-mixed-models at r-project.org>, and with the comparison between
glmmTMB::glmmTMB and lme4::glmer, for models that have the
same model formulae.
1) In the glmmTMB model as fitted to `ffly`, one predicted value is
infinite.  This, even though all coefficients and standard errors
have finite values.  This surely indicates that there is something
odd in the way that predictions on the scale of the linear
predictor are calculated.
2) Initially, I'd thought that the `Inf` value explained the
difference between the two AIC values.  But the difference
pretty much stays the same when the "offending" point is
removed.
I've not checked what happens when there are no observation level
random effects.  Is there some difference in the way that the
model formulae are interpreted in the two cases?
ffly <- read.csv('https://github.com/jhmaindonald/dataR/files/6521483/ffly.csv')
ffly$obs <- factor(ffly$obs)
form1 <- cbind(Dead,Live)~0+trtGp/TrtTime+(1|obs)+(1|trtGpRep)
library(lme4); library(glmmTMB)
ObsTMB.cll <- glmmTMB(form1,
                      family=binomial(link="cloglog"), data=ffly)
Obsglmer.cll <- glmer(form1, nAGQ=0,
                      family=binomial(link="cloglog"), data=ffly)
round(AIC(Obsglmer.cll, ObsTMB.cll), 2)
##                      df    AIC
## Obsglmer.cll 14 639.44
## ObsTMB.cll  14 636.02
round(c(max(predict(ObsTMB.cll)),max(predict(Obsglmer.cll))),3)
## [1]   Inf 3.833
range(fixef(ObsTMB.cll))
## [1] -5.28780064553  1.15952249272
range(vcov(ObsTMB.cll))
## [1] -0.0546986905338  0.2887049942215
## Try also; there are small deviations from the line
plot(predict(Obsglmer.cll)~predict(ObsTMB.cll))
abline(0,1)
## Remove offending point
ffly1 <- ffly[-which.max(predict(ObsTMB.cll)),]
ObsTMB1.cll <- glmmTMB(form1,
                      family=binomial(link="cloglog"), data=ffly1)
Obsglmer1.cll <- glmer(form1, nAGQ=0,
                      family=binomial(link="cloglog"), data=ffly1)
cbind(AIC(Obsglmer.cll, ObsTMB.cll), AIC1=AIC(Obsglmer1.cll, ObsTMB1.cll)[,2])
##                       df                    AIC                  AIC1
## Obsglmer.cll  14 639.441888969 639.441889196
## ObsTMB.cll   14 636.016597730 636.016597723
  ## Observe that changes are in the final four decimal places.
round(rbind(glmer=fixef(Obsglmer1.cll),
TMB=unclass(fixef(ObsTMB1.cll)$cond)),3)
      trtGpspAEgg trtGpspAL2 trtGpspAL3 trtGpspBEgg trtGpspBL2 trtGpspBL3
glmer       0.772     -2.255     -3.299      -1.803     -2.632     -5.114
TMB         0.790     -2.367     -3.441      -1.889     -2.757     -5.288
      trtGpspAEgg:TrtTime trtGpspAL2:TrtTime trtGpspAL3:TrtTime
glmer               0.231              0.372              0.563
TMB                 0.288              0.398              0.602
      trtGpspBEgg:TrtTime trtGpspBL2:TrtTime trtGpspBL3:TrtTime
glmer               0.278              0.517              1.112
TMB                 0.299              0.554              1.160
John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au><mailto:john.maindonald at anu.edu.au>
[[alternative HTML version deleted]]
_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Sat May 22 02:16:15 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 21 May 2021 20:16:15 -0400
Subject: [R-sig-ME] glmmTMB predicted values and AIC, vs glmer
In-Reply-To: <E48CBF04-01E3-491F-B139-F13B2B533B3B@anu.edu.au>
References: <mailman.19179.9.1621418401.6183.r-sig-mixed-models@r-project.org>
 <cfe43ac8-331e-2cb3-5ebe-304db69fea98@highstat.com>
 <CACtWw1Gd89u1TGPdbXaMVyB=2HcJnLNVj7Y2qRg=4NzfcERkdA@mail.gmail.com>
 <CACtWw1FQQzPQ7c-OW4Ha8K0GtpVrTQ=OO9zakcSZYsOJ4RqVDw@mail.gmail.com>
 <CAJuCY5w1HhJKSWgykU0gWHRc_jKu1f3HnYAQp-uKL7T8F+GHow@mail.gmail.com>
 <CACtWw1FnqSYdqZBmL2A13=6HLP2zchGjAQq-YXV3xhSwA9AOTQ@mail.gmail.com>
 <F5A31EE3-29CF-472C-A398-8F94B5FAEF3D@anu.edu.au>
 <f6ecb9ba-2cfe-36c4-6ef3-ebe9a4727fe4@gmail.com>
 <E48CBF04-01E3-491F-B139-F13B2B533B3B@anu.edu.au>
Message-ID: <b51f6305-e6ac-1ca2-ddb4-80b40b4323f7@gmail.com>

  What allFit indicates to me is that all of the different optimizers 
reach very similar log-likelihoods (max difference of 1-4), and if I 
recall correctly all of the fixed effects are also very similar, so I 
would feel free to disregard the convergence warning as a false positive.

   The AIC values are still a lot more different than I would like, and 
digging into the gory details (available on request) it seems that they 
are actually giving different likelihood calculations -- e.g. for the 
parameters reached by glmer, glmmTMB returns a deviance of 607.037 while 
glmer returns 609.3362.  I suspect something deep in the guts of e.g. 
the way the Laplace approximation is computed (not technically a bug in 
either code, but some kind of numerical instability).

   This is good news if what you're interested in is making sure you get 
the correct parameter values.  It's bad news if you're interested in 
mixing and matching glmmTMB and lme4 fits in a model comparison.

   I'm not horribly surprised that things are a bit numerically unstable 
- 12 parameters for 95 observations, and the extremely rapid tail 
behaviour of cloglog often makes things worse.

   I do intend to track down where the infinite prediction is coming 
from too, but haven't gotten there yet.

I'm going to include some of my code in case it's useful, but it's 
poorly commented, messy *and may be in the wrong order* - I was bouncing 
around developing it interactively.

====
Obsglmer1.cll <- glmer(form1, nAGQ=1,
                       family=binomial(link="cloglog"), data=ffly)
aa <- allFit(Obsglmer1.cll)
summary(aa)$fixef
ll <- -summary(aa)$llik
ll-min(ll)
dotwhisker::dwplot(modList[-2])

library(dotwhisker)
modList <- list(glmmTMB=ObsTMB.cll, nAGQ0=Obsglmer.cll,
                 nAGQ1=Obsglmer1.cll)
f1 <- ObsTMB.cll$obj$fn
## TMB params, TMB format
p1 <- with(environment(f1),last.par.best[-random])
## TMB params, glmer format
p1B <- c(exp(p1[names(p1)=="theta"]), p1[names(p1)=="beta"])

f3 <- getME(Obsglmer1.cll,"devfun")
## glmer params, glmer format
p3 <- unlist(getME(Obsglmer1.cll,c("theta","beta")))
## glmer params, TMB format
p3B <- c(p3[-(1:2)],log(p3[1:2]))
f3(p1B) ## 609.3559

f3(p3)  ## 609.3362
2*f1(p3B) ## 608.037

2*f1(p1) ## 608.0166

Obsglmer2.cll <- update(Obsglmer1.cll,
                         start=list(theta=p1B[1:2],
                                    fixef=p1B[-(1:2)]))

dwplot(modList)
library(bbmle)
AICtab(modList, logLik=TRUE)
modList2 <- c(modList, list(nAGQ1_newstart=Obsglmer2.cll))
AICtab(modList2, logLik=TRUE)



On 5/21/21 6:24 PM, John Maindonald wrote:
> Setting nAGQ=1 does bring the AIC values closer together, albeit with
> convergence failure when other parameters are left at their defaults.
> Running allFit() does not provide (to me) any obvious clues on what
> might work better. ?Or, should one just accept the less strict tolerance?
> Nor does centering and scale scTime help in this case.
> 
> llik <- summary(allFit(Obsglmer1.cll))$llik
> max(lik)-lik
> ## ? ? ? ? ? ? ? ? ? ? ? bobyqa ? ? ? ? ? ? ? ? ? Nelder_Mead
> ## ? ? ? ? ? 0.00000000000e+00 ? ? ? ? ? ? 1.31201379190e-04
> ## ? ? ? ? ? ? ? ? ? nlminbwrap ? ? ? ? ? ? ? ? ? ? ? ? nmkbw
> ## ? ? ? ? ? ?1.76015646502e-09 ? ? ? ? ? ? 3.48215053236e-06
> ## ? ? ? ? ? ? ?optimx.L-BFGS-B nloptwrap.NLOPT_LN_NELDERMEAD
> ## ? ? ? ? ? ?1.09246872171e-06 ? ? ? ? ? ? 1.13990722639e-07
> ## ? ?nloptwrap.NLOPT_LN_BOBYQA
> ## ? ? ? ? ? ?5.81495783081e-07
> 
> John Maindonaldemail: john.maindonald at anu.edu.au 
> <mailto:john.maindonald at anu.edu.au>
> 
> 
>> On 22/05/2021, at 01:27, Ben Bolker <bbolker at gmail.com 
>> <mailto:bbolker at gmail.com>> wrote:
>>
>> ?I don't know yet, I will dig in and try to see what's going on. ?An 
>> infinite predicted value certainly seems like an issue.
>>
>> ?The most obvious difference is that nAGQ=0 is actually doing 
>> something slightly different (it's fitting the fixed-effect parameters 
>> as part of the PIRLS loop rather than maximizing over them 
>> explicitly); I would rather compare the nAGQ=1 case, just to minimize 
>> the number of differences.
>>
>> On 5/21/21 6:30 AM, John Maindonald wrote:
>>> The code that follows below demonstrates what I find a very odd
>>> issue with r-sig-mixed-models at r-project.org 
>>> <mailto:r-sig-mixed-models at r-project.org><mailto:r-sig-mixed-models at r-project.org 
>>> <mailto:r-sig-mixed-models at r-project.org>>, and with the comparison 
>>> between
>>> glmmTMB::glmmTMB and lme4::glmer, for models that have the
>>> same model formulae.
>>> 1) In the glmmTMB model as fitted to `ffly`, one predicted value is
>>> infinite. ?This, even though all coefficients and standard errors
>>> have finite values. ?This surely indicates that there is something
>>> odd in the way that predictions on the scale of the linear
>>> predictor are calculated.
>>> 2) Initially, I'd thought that the `Inf` value explained the
>>> difference between the two AIC values. ?But the difference
>>> pretty much stays the same when the "offending" point is
>>> removed.
>>> I've not checked what happens when there are no observation level
>>> random effects. ?Is there some difference in the way that the
>>> model formulae are interpreted in the two cases?
>>> ffly <- 
>>> read.csv('https://github.com/jhmaindonald/dataR/files/6521483/ffly.csv <https://github.com/jhmaindonald/dataR/files/6521483/ffly.csv>')
>>> ffly$obs <- factor(ffly$obs)
>>> form1 <- cbind(Dead,Live)~0+trtGp/TrtTime+(1|obs)+(1|trtGpRep)
>>> library(lme4); library(glmmTMB)
>>> ObsTMB.cll <- glmmTMB(form1,
>>> ??????????????????????family=binomial(link="cloglog"), data=ffly)
>>> Obsglmer.cll <- glmer(form1, nAGQ=0,
>>> ??????????????????????family=binomial(link="cloglog"), data=ffly)
>>> round(AIC(Obsglmer.cll, ObsTMB.cll), 2)
>>> ## ?????????????????????df ???AIC
>>> ## Obsglmer.cll 14 639.44
>>> ## ObsTMB.cll ?14 636.02
>>> round(c(max(predict(ObsTMB.cll)),max(predict(Obsglmer.cll))),3)
>>> ## [1] ??Inf 3.833
>>> range(fixef(ObsTMB.cll))
>>> ## [1] -5.28780064553 ?1.15952249272
>>> range(vcov(ObsTMB.cll))
>>> ## [1] -0.0546986905338 ?0.2887049942215
>>> ## Try also; there are small deviations from the line
>>> plot(predict(Obsglmer.cll)~predict(ObsTMB.cll))
>>> abline(0,1)
>>> ## Remove offending point
>>> ffly1 <- ffly[-which.max(predict(ObsTMB.cll)),]
>>> ObsTMB1.cll <- glmmTMB(form1,
>>> ??????????????????????family=binomial(link="cloglog"), data=ffly1)
>>> Obsglmer1.cll <- glmer(form1, nAGQ=0,
>>> ??????????????????????family=binomial(link="cloglog"), data=ffly1)
>>> cbind(AIC(Obsglmer.cll, ObsTMB.cll), AIC1=AIC(Obsglmer1.cll, 
>>> ObsTMB1.cll)[,2])
>>> ## ??????????????????????df ???????????????????AIC ?????????????????AIC1
>>> ## Obsglmer.cll ?14 639.441888969 639.441889196
>>> ## ObsTMB.cll ??14 636.016597730 636.016597723
>>> ??## Observe that changes are in the final four decimal places.
>>> round(rbind(glmer=fixef(Obsglmer1.cll),
>>> TMB=unclass(fixef(ObsTMB1.cll)$cond)),3)
>>> ??????trtGpspAEgg trtGpspAL2 trtGpspAL3 trtGpspBEgg trtGpspBL2 trtGpspBL3
>>> glmer ??????0.772 ????-2.255 ????-3.299 ?????-1.803 ????-2.632 ????-5.114
>>> TMB ????????0.790 ????-2.367 ????-3.441 ?????-1.889 ????-2.757 ????-5.288
>>> ??????trtGpspAEgg:TrtTime trtGpspAL2:TrtTime trtGpspAL3:TrtTime
>>> glmer ??????????????0.231 ?????????????0.372 ?????????????0.563
>>> TMB ????????????????0.288 ?????????????0.398 ?????????????0.602
>>> ??????trtGpspBEgg:TrtTime trtGpspBL2:TrtTime trtGpspBL3:TrtTime
>>> glmer ??????????????0.278 ?????????????0.517 ?????????????1.112
>>> TMB ????????????????0.299 ?????????????0.554 ?????????????1.160
>>> John Maindonald email: john.maindonald at anu.edu.au 
>>> <mailto:john.maindonald at anu.edu.au><mailto:john.maindonald at anu.edu.au 
>>> <mailto:john.maindonald at anu.edu.au>>
>>> [[alternative HTML version deleted]]
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org 
>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models 
>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org 
>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models 
>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>


From bbo|ker @end|ng |rom gm@||@com  Sat May 22 03:29:10 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 21 May 2021 21:29:10 -0400
Subject: [R-sig-ME] glmmTMB predicted values and AIC, vs glmer
In-Reply-To: <E48CBF04-01E3-491F-B139-F13B2B533B3B@anu.edu.au>
References: <mailman.19179.9.1621418401.6183.r-sig-mixed-models@r-project.org>
 <cfe43ac8-331e-2cb3-5ebe-304db69fea98@highstat.com>
 <CACtWw1Gd89u1TGPdbXaMVyB=2HcJnLNVj7Y2qRg=4NzfcERkdA@mail.gmail.com>
 <CACtWw1FQQzPQ7c-OW4Ha8K0GtpVrTQ=OO9zakcSZYsOJ4RqVDw@mail.gmail.com>
 <CAJuCY5w1HhJKSWgykU0gWHRc_jKu1f3HnYAQp-uKL7T8F+GHow@mail.gmail.com>
 <CACtWw1FnqSYdqZBmL2A13=6HLP2zchGjAQq-YXV3xhSwA9AOTQ@mail.gmail.com>
 <F5A31EE3-29CF-472C-A398-8F94B5FAEF3D@anu.edu.au>
 <f6ecb9ba-2cfe-36c4-6ef3-ebe9a4727fe4@gmail.com>
 <E48CBF04-01E3-491F-B139-F13B2B533B3B@anu.edu.au>
Message-ID: <88459820-f69d-0c8f-d23d-fb1cb808a964@gmail.com>

   I figured out the infinite-prediction thing (didn't solve it, but 
figured it out):

https://github.com/glmmTMB/glmmTMB/issues/696

On 5/21/21 6:24 PM, John Maindonald wrote:
> Setting nAGQ=1 does bring the AIC values closer together, albeit with
> convergence failure when other parameters are left at their defaults.
> Running allFit() does not provide (to me) any obvious clues on what
> might work better. ?Or, should one just accept the less strict tolerance?
> Nor does centering and scale scTime help in this case.
> 
> llik <- summary(allFit(Obsglmer1.cll))$llik
> max(lik)-lik
> ## ? ? ? ? ? ? ? ? ? ? ? bobyqa ? ? ? ? ? ? ? ? ? Nelder_Mead
> ## ? ? ? ? ? 0.00000000000e+00 ? ? ? ? ? ? 1.31201379190e-04
> ## ? ? ? ? ? ? ? ? ? nlminbwrap ? ? ? ? ? ? ? ? ? ? ? ? nmkbw
> ## ? ? ? ? ? ?1.76015646502e-09 ? ? ? ? ? ? 3.48215053236e-06
> ## ? ? ? ? ? ? ?optimx.L-BFGS-B nloptwrap.NLOPT_LN_NELDERMEAD
> ## ? ? ? ? ? ?1.09246872171e-06 ? ? ? ? ? ? 1.13990722639e-07
> ## ? ?nloptwrap.NLOPT_LN_BOBYQA
> ## ? ? ? ? ? ?5.81495783081e-07
> 
> John Maindonaldemail: john.maindonald at anu.edu.au 
> <mailto:john.maindonald at anu.edu.au>
> 
> 
>> On 22/05/2021, at 01:27, Ben Bolker <bbolker at gmail.com 
>> <mailto:bbolker at gmail.com>> wrote:
>>
>> ?I don't know yet, I will dig in and try to see what's going on. ?An 
>> infinite predicted value certainly seems like an issue.
>>
>> ?The most obvious difference is that nAGQ=0 is actually doing 
>> something slightly different (it's fitting the fixed-effect parameters 
>> as part of the PIRLS loop rather than maximizing over them 
>> explicitly); I would rather compare the nAGQ=1 case, just to minimize 
>> the number of differences.
>>
>> On 5/21/21 6:30 AM, John Maindonald wrote:
>>> The code that follows below demonstrates what I find a very odd
>>> issue with r-sig-mixed-models at r-project.org 
>>> <mailto:r-sig-mixed-models at r-project.org><mailto:r-sig-mixed-models at r-project.org 
>>> <mailto:r-sig-mixed-models at r-project.org>>, and with the comparison 
>>> between
>>> glmmTMB::glmmTMB and lme4::glmer, for models that have the
>>> same model formulae.
>>> 1) In the glmmTMB model as fitted to `ffly`, one predicted value is
>>> infinite. ?This, even though all coefficients and standard errors
>>> have finite values. ?This surely indicates that there is something
>>> odd in the way that predictions on the scale of the linear
>>> predictor are calculated.
>>> 2) Initially, I'd thought that the `Inf` value explained the
>>> difference between the two AIC values. ?But the difference
>>> pretty much stays the same when the "offending" point is
>>> removed.
>>> I've not checked what happens when there are no observation level
>>> random effects. ?Is there some difference in the way that the
>>> model formulae are interpreted in the two cases?
>>> ffly <- 
>>> read.csv('https://github.com/jhmaindonald/dataR/files/6521483/ffly.csv <https://github.com/jhmaindonald/dataR/files/6521483/ffly.csv>')
>>> ffly$obs <- factor(ffly$obs)
>>> form1 <- cbind(Dead,Live)~0+trtGp/TrtTime+(1|obs)+(1|trtGpRep)
>>> library(lme4); library(glmmTMB)
>>> ObsTMB.cll <- glmmTMB(form1,
>>> ??????????????????????family=binomial(link="cloglog"), data=ffly)
>>> Obsglmer.cll <- glmer(form1, nAGQ=0,
>>> ??????????????????????family=binomial(link="cloglog"), data=ffly)
>>> round(AIC(Obsglmer.cll, ObsTMB.cll), 2)
>>> ## ?????????????????????df ???AIC
>>> ## Obsglmer.cll 14 639.44
>>> ## ObsTMB.cll ?14 636.02
>>> round(c(max(predict(ObsTMB.cll)),max(predict(Obsglmer.cll))),3)
>>> ## [1] ??Inf 3.833
>>> range(fixef(ObsTMB.cll))
>>> ## [1] -5.28780064553 ?1.15952249272
>>> range(vcov(ObsTMB.cll))
>>> ## [1] -0.0546986905338 ?0.2887049942215
>>> ## Try also; there are small deviations from the line
>>> plot(predict(Obsglmer.cll)~predict(ObsTMB.cll))
>>> abline(0,1)
>>> ## Remove offending point
>>> ffly1 <- ffly[-which.max(predict(ObsTMB.cll)),]
>>> ObsTMB1.cll <- glmmTMB(form1,
>>> ??????????????????????family=binomial(link="cloglog"), data=ffly1)
>>> Obsglmer1.cll <- glmer(form1, nAGQ=0,
>>> ??????????????????????family=binomial(link="cloglog"), data=ffly1)
>>> cbind(AIC(Obsglmer.cll, ObsTMB.cll), AIC1=AIC(Obsglmer1.cll, 
>>> ObsTMB1.cll)[,2])
>>> ## ??????????????????????df ???????????????????AIC ?????????????????AIC1
>>> ## Obsglmer.cll ?14 639.441888969 639.441889196
>>> ## ObsTMB.cll ??14 636.016597730 636.016597723
>>> ??## Observe that changes are in the final four decimal places.
>>> round(rbind(glmer=fixef(Obsglmer1.cll),
>>> TMB=unclass(fixef(ObsTMB1.cll)$cond)),3)
>>> ??????trtGpspAEgg trtGpspAL2 trtGpspAL3 trtGpspBEgg trtGpspBL2 trtGpspBL3
>>> glmer ??????0.772 ????-2.255 ????-3.299 ?????-1.803 ????-2.632 ????-5.114
>>> TMB ????????0.790 ????-2.367 ????-3.441 ?????-1.889 ????-2.757 ????-5.288
>>> ??????trtGpspAEgg:TrtTime trtGpspAL2:TrtTime trtGpspAL3:TrtTime
>>> glmer ??????????????0.231 ?????????????0.372 ?????????????0.563
>>> TMB ????????????????0.288 ?????????????0.398 ?????????????0.602
>>> ??????trtGpspBEgg:TrtTime trtGpspBL2:TrtTime trtGpspBL3:TrtTime
>>> glmer ??????????????0.278 ?????????????0.517 ?????????????1.112
>>> TMB ????????????????0.299 ?????????????0.554 ?????????????1.160
>>> John Maindonald email: john.maindonald at anu.edu.au 
>>> <mailto:john.maindonald at anu.edu.au><mailto:john.maindonald at anu.edu.au 
>>> <mailto:john.maindonald at anu.edu.au>>
>>> [[alternative HTML version deleted]]
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org 
>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models 
>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org 
>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models 
>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>


From hedyeh@h @end|ng |rom u@c@edu  Sat May 22 04:47:48 2021
From: hedyeh@h @end|ng |rom u@c@edu (Hedyeh Ahmadi)
Date: Sat, 22 May 2021 02:47:48 +0000
Subject: [R-sig-ME] Natural spline (i.e. ns() ) with glmer()/lmer()
Message-ID: <BYAPR07MB509463072CB44EDC62A69784D1289@BYAPR07MB5094.namprd07.prod.outlook.com>

Hello All,

I would like to double check my understanding with the followings:

1 - In a linear mixed model if I use ns() for a continuous variable with for example one knot then I'll have two pieces of natural splines (i.e. third degree polynomial) one before the knot and one after the knot.

2 - But if I run the same ns() in a linear mixed model without any knots, does that mean I am fitting one 3rd degree polynomial between the boundaries (i.e. over the range of my continuous variable)?

Best,

Hedyeh Ahmadi, Ph.D.
Applied Statistician
Keck School of Medicine
Department of Preventive Medicine
University of Southern California

Postdoctoral Scholar
Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
University of California, Irvine

LinkedIn
www.linkedin.com/in/hedyeh-ahmadi<http://www.linkedin.com/in/hedyeh-ahmadi>


	[[alternative HTML version deleted]]


From hedyeh@h @end|ng |rom u@c@edu  Sat May 22 05:32:45 2021
From: hedyeh@h @end|ng |rom u@c@edu (Hedyeh Ahmadi)
Date: Sat, 22 May 2021 03:32:45 +0000
Subject: [R-sig-ME] Natural spline (i.e. ns() ) with glmer()/lmer()
In-Reply-To: <BYAPR07MB509463072CB44EDC62A69784D1289@BYAPR07MB5094.namprd07.prod.outlook.com>
References: <BYAPR07MB509463072CB44EDC62A69784D1289@BYAPR07MB5094.namprd07.prod.outlook.com>
Message-ID: <BYAPR07MB509433E852764F5F91927676D1289@BYAPR07MB5094.namprd07.prod.outlook.com>

Just a clarification, when I say "third degree polynomial" I mean, it generates a basis matrix for representing the family of piecewise-cubic splines with the specified sequence of interior knots, and the natural boundary conditions.

Best,

Hedyeh Ahmadi, Ph.D.
Statistician
Keck School of Medicine
Department of Preventive Medicine
University of Southern California

Postdoctoral Scholar
Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
University of California, Irvine

LinkedIn
www.linkedin.com/in/hedyeh-ahmadi<http://www.linkedin.com/in/hedyeh-ahmadi>


________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Hedyeh Ahmadi <hedyehah at usc.edu>
Sent: Friday, May 21, 2021 7:47:48 PM
To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] Natural spline (i.e. ns() ) with glmer()/lmer()

Hello All,

I would like to double check my understanding with the followings:

1 - In a linear mixed model if I use ns() for a continuous variable with for example one knot then I'll have two pieces of natural splines (i.e. third degree polynomial) one before the knot and one after the knot.

2 - But if I run the same ns() in a linear mixed model without any knots, does that mean I am fitting one 3rd degree polynomial between the boundaries (i.e. over the range of my continuous variable)?

Best,

Hedyeh Ahmadi, Ph.D.
Applied Statistician
Keck School of Medicine
Department of Preventive Medicine
University of Southern California

Postdoctoral Scholar
Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
University of California, Irvine

LinkedIn
https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!6PUpiQYPrgA3Fbz27Esf9awfY2HmnPLrPbPDJqoI4oUYiCY8mKXv0w7CCGwAYgU$ <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!6PUpiQYPrgA3Fbz27Esf9awfY2HmnPLrPbPDJqoI4oUYiCY8mKXv0w7CCGwAYgU$ >


        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!6PUpiQYPrgA3Fbz27Esf9awfY2HmnPLrPbPDJqoI4oUYiCY8mKXv0w7CEqjBXMs$

	[[alternative HTML version deleted]]


From john@m@|ndon@|d @end|ng |rom @nu@edu@@u  Sat May 22 05:52:39 2021
From: john@m@|ndon@|d @end|ng |rom @nu@edu@@u (John Maindonald)
Date: Sat, 22 May 2021 03:52:39 +0000
Subject: [R-sig-ME] glmmTMB predicted values and AIC, vs glmer
In-Reply-To: <88459820-f69d-0c8f-d23d-fb1cb808a964@gmail.com>
References: <mailman.19179.9.1621418401.6183.r-sig-mixed-models@r-project.org>
 <cfe43ac8-331e-2cb3-5ebe-304db69fea98@highstat.com>
 <CACtWw1Gd89u1TGPdbXaMVyB=2HcJnLNVj7Y2qRg=4NzfcERkdA@mail.gmail.com>
 <CACtWw1FQQzPQ7c-OW4Ha8K0GtpVrTQ=OO9zakcSZYsOJ4RqVDw@mail.gmail.com>
 <CAJuCY5w1HhJKSWgykU0gWHRc_jKu1f3HnYAQp-uKL7T8F+GHow@mail.gmail.com>
 <CACtWw1FnqSYdqZBmL2A13=6HLP2zchGjAQq-YXV3xhSwA9AOTQ@mail.gmail.com>
 <F5A31EE3-29CF-472C-A398-8F94B5FAEF3D@anu.edu.au>
 <f6ecb9ba-2cfe-36c4-6ef3-ebe9a4727fe4@gmail.com>
 <E48CBF04-01E3-491F-B139-F13B2B533B3B@anu.edu.au>
 <88459820-f69d-0c8f-d23d-fb1cb808a964@gmail.com>
Message-ID: <2BB7575E-6E0F-45A0-9D64-26117F2275D3@anu.edu.au>

Thanks for the informative responses.

Well, it does look as though dealing with the `Inf` is as simple as
calculating eta_predict directly from the model for the linear predictor
and returning that.  Why go the roundabout way and introduce
unnecessary inaccuracy that will in some cases manifest as a lurgy?

I?ve thought if it would be useful to collect a list of alternatives to default
control settings that users of these models have found to assist
convergence and/or avoid complaints of singularity in particular cases.
It does seem that some complaints are a consequence of the route
taken to get to convergence.  Also, there is a dearth of published work
that comments on how the various choices of link function and error
model pan out in practical data analysis contexts, and (especially in
the 99% lethal time estimates for insects on which I have worked in
a plant quarantine context in the past)response , large elements of unrealism
about the confidence that can be placed in any upper tail limits and
confidence intervals.

Incidentally, I have been experimenting with observation level random
effects because they add to the binomial variance on the scale of the
linear predictor, rather than (as for betabinomial and quasibinomial)
multiplying on the scale of the response.  For the dataset with which I
started, the variance then has to be ?corrected? by specifying a degree 2
or 3 polynomial or spline for the glmmTMB dispformula.


John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>


On 22/05/2021, at 13:29, Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com>> wrote:

 I figured out the infinite-prediction thing (didn't solve it, but figured it out):

https://github.com/glmmTMB/glmmTMB/issues/696

On 5/21/21 6:24 PM, John Maindonald wrote:
Setting nAGQ=1 does bring the AIC values closer together, albeit with
convergence failure when other parameters are left at their defaults.
Running allFit() does not provide (to me) any obvious clues on what
might work better.  Or, should one just accept the less strict tolerance?
Nor does centering and scale scTime help in this case.
llik <- summary(allFit(Obsglmer1.cll))$llik
max(lik)-lik
##                       bobyqa                   Nelder_Mead
##           0.00000000000e+00             1.31201379190e-04
##                   nlminbwrap                         nmkbw
##            1.76015646502e-09             3.48215053236e-06
##              optimx.L-BFGS-B nloptwrap.NLOPT_LN_NELDERMEAD
##            1.09246872171e-06             1.13990722639e-07
##    nloptwrap.NLOPT_LN_BOBYQA
##            5.81495783081e-07
John Maindonaldemail: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au> <mailto:john.maindonald at anu.edu.au>
On 22/05/2021, at 01:27, Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com> <mailto:bbolker at gmail.com>> wrote:

 I don't know yet, I will dig in and try to see what's going on.  An infinite predicted value certainly seems like an issue.

 The most obvious difference is that nAGQ=0 is actually doing something slightly different (it's fitting the fixed-effect parameters as part of the PIRLS loop rather than maximizing over them explicitly); I would rather compare the nAGQ=1 case, just to minimize the number of differences.

On 5/21/21 6:30 AM, John Maindonald wrote:
The code that follows below demonstrates what I find a very odd
issue with r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org> <mailto:r-sig-mixed-models at r-project.org><mailto:r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-models at r-project.org>>, and with the comparison between
glmmTMB::glmmTMB and lme4::glmer, for models that have the
same model formulae.
1) In the glmmTMB model as fitted to `ffly`, one predicted value is
infinite.  This, even though all coefficients and standard errors
have finite values.  This surely indicates that there is something
odd in the way that predictions on the scale of the linear
predictor are calculated.
2) Initially, I'd thought that the `Inf` value explained the
difference between the two AIC values.  But the difference
pretty much stays the same when the "offending" point is
removed.
I've not checked what happens when there are no observation level
random effects.  Is there some difference in the way that the
model formulae are interpreted in the two cases?
ffly <- read.csv('https://github.com/jhmaindonald/dataR/files/6521483/ffly.csv<https://github.com/jhmaindonald/dataR/files/6521483/ffly.csv>')
ffly$obs <- factor(ffly$obs)
form1 <- cbind(Dead,Live)~0+trtGp/TrtTime+(1|obs)+(1|trtGpRep)
library(lme4); library(glmmTMB)
ObsTMB.cll <- glmmTMB(form1,
                      family=binomial(link="cloglog"), data=ffly)
Obsglmer.cll <- glmer(form1, nAGQ=0,
                      family=binomial(link="cloglog"), data=ffly)
round(AIC(Obsglmer.cll, ObsTMB.cll), 2)
##                      df    AIC
## Obsglmer.cll 14 639.44
## ObsTMB.cll  14 636.02
round(c(max(predict(ObsTMB.cll)),max(predict(Obsglmer.cll))),3)
## [1]   Inf 3.833
range(fixef(ObsTMB.cll))
## [1] -5.28780064553  1.15952249272
range(vcov(ObsTMB.cll))
## [1] -0.0546986905338  0.2887049942215
## Try also; there are small deviations from the line
plot(predict(Obsglmer.cll)~predict(ObsTMB.cll))
abline(0,1)
## Remove offending point
ffly1 <- ffly[-which.max(predict(ObsTMB.cll)),]
ObsTMB1.cll <- glmmTMB(form1,
                      family=binomial(link="cloglog"), data=ffly1)
Obsglmer1.cll <- glmer(form1, nAGQ=0,
                      family=binomial(link="cloglog"), data=ffly1)
cbind(AIC(Obsglmer.cll, ObsTMB.cll), AIC1=AIC(Obsglmer1.cll, ObsTMB1.cll)[,2])
##                       df                    AIC                  AIC1
## Obsglmer.cll  14 639.441888969 639.441889196
## ObsTMB.cll   14 636.016597730 636.016597723
  ## Observe that changes are in the final four decimal places.
round(rbind(glmer=fixef(Obsglmer1.cll),
TMB=unclass(fixef(ObsTMB1.cll)$cond)),3)
      trtGpspAEgg trtGpspAL2 trtGpspAL3 trtGpspBEgg trtGpspBL2 trtGpspBL3
glmer       0.772     -2.255     -3.299      -1.803     -2.632     -5.114
TMB         0.790     -2.367     -3.441      -1.889     -2.757     -5.288
      trtGpspAEgg:TrtTime trtGpspAL2:TrtTime trtGpspAL3:TrtTime
glmer               0.231              0.372              0.563
TMB                 0.288              0.398              0.602
      trtGpspBEgg:TrtTime trtGpspBL2:TrtTime trtGpspBL3:TrtTime
glmer               0.278              0.517              1.112
TMB                 0.299              0.554              1.160
John Maindonald email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au> <mailto:john.maindonald at anu.edu.au><mailto:john.maindonald at anu.edu.au <mailto:john.maindonald at anu.edu.au>>
[[alternative HTML version deleted]]
_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> <mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>


_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> <mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>


	[[alternative HTML version deleted]]


From ru@@e||-|enth @end|ng |rom u|ow@@edu  Sat May 22 14:35:19 2021
From: ru@@e||-|enth @end|ng |rom u|ow@@edu (Lenth, Russell V)
Date: Sat, 22 May 2021 12:35:19 +0000
Subject: [R-sig-ME] Natural spline (i.e. ns() ) with glmer()/lmer()
Message-ID: <SN6PR04MB448088D145F38F1F0D46E6FFF1289@SN6PR04MB4480.namprd04.prod.outlook.com>

Regardless of what kind of model is used, a natural cubic spline has two end conditions -- that the second derivative is zero at each end. If there are no interior knots, then that forces it to be a straight line. (Consider a cubic polynomial has four parameters, and we have imposed two constraints, reducing it to two parameters, the slope and the intercept). 

With one interior knot, you do get two cubic polynomials, but with the condition that each end is an inflection point.

Russell V. Lenth? -? Professor Emeritus
Department of Statistics and Actuarial Science?? 
The University of Iowa ?-? Iowa City, IA 52242? USA?? 
Voice (319)335-0712 (Dept. office)? -? FAX (319)335-3017



-----Original Message-----

Just a clarification, when I say "third degree polynomial" I mean, it generates a basis matrix for representing the family of piecewise-cubic splines with the specified sequence of interior knots, and the natural boundary conditions.

-----------
I would like to double check my understanding with the followings:

1 - In a linear mixed model if I use ns() for a continuous variable with for example one knot then I'll have two pieces of natural splines (i.e. third degree polynomial) one before the knot and one after the knot.

2 - But if I run the same ns() in a linear mixed model without any knots, does that mean I am fitting one 3rd degree polynomial between the boundaries (i.e. over the range of my continuous variable)?

Best,

Hedyeh Ahmadi, Ph.D.
Applied Statistician
Keck School of Medicine
Department of Preventive Medicine
University of Southern California

Postdoctoral Scholar
Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
University of California, Irvine


From |uc@@|e|@ten @end|ng |rom @tudent@ru@n|  Sat May 22 18:13:48 2021
From: |uc@@|e|@ten @end|ng |rom @tudent@ru@n| (Leisten, L.M. (Luca))
Date: Sat, 22 May 2021 16:13:48 +0000
Subject: [R-sig-ME] Number of random effects error
Message-ID: <1621700028936.61330@student.ru.nl>

?Dear all,?


I am currently working on the data analysis of a project.


Basically our data frame contains 172 IDs, which is our grouping factor, but in total contains 1149 observation from these IDs. We have their weight, and time of measurement in months (that corresponds to their age). We are interested in looking at their weight development over time, thus using their age (which corresponds the the date of their measurement) as a random effect.


Our model structure looks  like this:


model <- lmer(z_WfL ~ c_age_child_month + f_stress + f_education_parent + c_parent_BMI + c_snacking_mean + c_age_child_month:f_stress + c_age_child_month:f_education_parent + c_age_child_month:c_parent_BMI + c_age_child_month:c_snacking_mean + c_age_child_month:f_stress:f_education_parent +  c_age_child_month:f_stress:c_parent_BMI + c_age_child_month:f_stress:c_snacking_mean + (1 + c_age_child_month | id), data = df_cleaned)?


Each child has a different number of observations (between 1 and 16), at different time points (as these correspond to the children's age). When running our model we get the following error:


number of observations (=172) <= number of random effects (=340) for term (1 + c_age_child_month | id); the random-effects parameters and the residual variance (or scale parameter) are probably unidentifiable?


We already googled it and figured that apparently we are trying to estimate too many random effects and have too little observations for that, but we don't quite understand why, as we have a lot of observations in total. We think the problem probably has to do with our time variable (aka age), as this can either be put in unrounded (so very different for most children), or rounded (which results in multiple measures on the same age per id).


We would really appreciate any help on this!


Best,


Luca & Fenna




	[[alternative HTML version deleted]]


From |uc@@|e|@ten @end|ng |rom @tudent@ru@n|  Sat May 22 18:56:29 2021
From: |uc@@|e|@ten @end|ng |rom @tudent@ru@n| (Leisten, L.M. (Luca))
Date: Sat, 22 May 2021 16:56:29 +0000
Subject: [R-sig-ME] Number of random effects error
In-Reply-To: <1621700028936.61330@student.ru.nl>
References: <1621700028936.61330@student.ru.nl>
Message-ID: <9fe7cb1a782740da8cfb9d6583631c36@EXPRD07.hosting.ru.nl>

Edit: we just figured it out. Our mistake was that our dependent variables were in the df just once for each ID instead of once per row. Thus it resulted in only 172 observations whereas in fact we had more. 

________________________________________
Von: Leisten, L.M. (Luca)
Gesendet: Samstag, 22. Mai 2021 18:13
An: r-sig-mixed-models at r-project.org
Cc: Andriessen, F.J.M. (Fenna)
Betreff: Number of random effects error

?Dear all,?


I am currently working on the data analysis of a project.


Basically our data frame contains 172 IDs, which is our grouping factor, but in total contains 1149 observation from these IDs. We have their weight, and time of measurement in months (that corresponds to their age). We are interested in looking at their weight development over time, thus using their age (which corresponds the the date of their measurement) as a random effect.


Our model structure looks  like this:


model <- lmer(z_WfL ~ c_age_child_month + f_stress + f_education_parent + c_parent_BMI + c_snacking_mean + c_age_child_month:f_stress + c_age_child_month:f_education_parent + c_age_child_month:c_parent_BMI + c_age_child_month:c_snacking_mean + c_age_child_month:f_stress:f_education_parent +  c_age_child_month:f_stress:c_parent_BMI + c_age_child_month:f_stress:c_snacking_mean + (1 + c_age_child_month | id), data = df_cleaned)?


Each child has a different number of observations (between 1 and 16), at different time points (as these correspond to the children's age). When running our model we get the following error:


number of observations (=172) <= number of random effects (=340) for term (1 + c_age_child_month | id); the random-effects parameters and the residual variance (or scale parameter) are probably unidentifiable?


We already googled it and figured that apparently we are trying to estimate too many random effects and have too little observations for that, but we don't quite understand why, as we have a lot of observations in total. We think the problem probably has to do with our time variable (aka age), as this can either be put in unrounded (so very different for most children), or rounded (which results in multiple measures on the same age per id).


We would really appreciate any help on this!


Best,


Luca & Fenna





From john@m@|ndon@|d @end|ng |rom @nu@edu@@u  Sat May 22 23:16:58 2021
From: john@m@|ndon@|d @end|ng |rom @nu@edu@@u (John Maindonald)
Date: Sat, 22 May 2021 21:16:58 +0000
Subject: [R-sig-ME] Natural spline (i.e. ns() ) with glmer()/lmer()
In-Reply-To: <SN6PR04MB448088D145F38F1F0D46E6FFF1289@SN6PR04MB4480.namprd04.prod.outlook.com>
References: <SN6PR04MB448088D145F38F1F0D46E6FFF1289@SN6PR04MB4480.namprd04.prod.outlook.com>
Message-ID: <F086E4B6-57AB-4ECA-845B-C66F8705F884@anu.edu.au>

It is worth checking how the choice of basis and end conditions (if any)
affects the range of shapes that can be fitted.  Try
  lattice::xyplot(ns(1:10,2)[,1]+ns(1:10,2)[,2] ~ I(1:10))
The basis is well suited to modeling a cup up or cup down shape with the
mode shifted somewhat to the right or left of center.


John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>


On 23/05/2021, at 00:35, Lenth, Russell V <russell-lenth at uiowa.edu<mailto:russell-lenth at uiowa.edu>> wrote:

Regardless of what kind of model is used, a natural cubic spline hwo end conditions -- that the second derivative is zero at each end. If there are no interior knots, then that forces it to be a straight line. (Consider a cubic polynomial has four parameters, and we have imposed two constraints, reducing it to two parameters, the slope and the intercept).

With one interior knot, you do get two cubic polynomials, but with the condition that each end is an inflection point.

Russell V. Lenth  -  Professor Emeritus
Department of Statistics and Actuarial Science
The University of Iowa  -  Iowa City, IA 52242  USA
Voice (319)335-0712 (Dept. office)  -  FAX (319)335-3017



-----Original Message-----

Just a clarification, when I say "third degree polynomial" I mean, it generates a basis matrix for representing the family of piecewise-cubic splines with the specified sequence of interior knots, and the natural boundary conditions.

-----------
I would like to double check my understanding with the followings:

1 - In a linear mixed model if I use ns() for a continuous variable with for example one knot then I'll have two pieces of natural splines (i.e. third degree polynomial) one before the knot and one after the knot.

2 - But if I run the same ns() in a linear mixed model without any knots, does that mean I am fitting one 3rd degree polynomial between the boundaries (i.e. over the range of my continuous variable)?

Best,

Hedyeh Ahmadi, Ph.D.
Applied Statistician
Keck School of Medicine
Department of Preventive Medicine
University of Southern California

Postdoctoral Scholar
Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
University of California, Irvine

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From rud|@re|ner @end|ng |rom boku@@c@@t  Tue May 25 09:14:28 2021
From: rud|@re|ner @end|ng |rom boku@@c@@t (Rudi Reiner)
Date: Tue, 25 May 2021 09:14:28 +0200
Subject: [R-sig-ME] 3-way interaction in random structure using gam
In-Reply-To: <f989a499-6c19-b5d1-516e-b80b124a6006@boku.ac.at>
References: <f989a499-6c19-b5d1-516e-b80b124a6006@boku.ac.at>
Message-ID: <3befbb8a-26b8-c378-e8d8-298e89f22494@boku.ac.at>


Hi there,

my actually trying to fit a non-linear mixed model (with a random 
structure) and am not sure how to do this correct using "gam" or "bam" 
from the mgcv package. My supervisor suggested me to ask R-sig.

My Data:

b.mass = body mass (continuous) - dependent variable
_
__predictor variables_
age = continuous; lon-linear relationship with b.mass
area.forest = continuous
period =? factor; 2 levels

_random variables
_year = continuous (1993-2019)
pop = factor (28 different populations)
--------------------------------------------------

First I fitted a linear model with quadratic age which seems to give me 
the "correct" results (biologically the results make sense). Especially 
I am interested in the 3-way interaction age x area.forest x period but 
also want/have to add all 2-way interactions:

*/LM <- lmer(b.mass ~ ns(age,2)*area.forest*period + (1|pop)+ (1|year), 
data = data)/*

Now I want to have the corresponding model using gam (or bam). I tried:

*/gam <- gam(b.mass ~ period+s(age)+area.forest+s(age, by = 
area.forest)+s(age, by=period)+te(area.forest, by=period)+te(age, 
area.forest, by = period), data = data, random = list(pop=~1, year=~1))/*

The results (plot age~b.mass for different area.forest) look different 
to the lmer approach. Do have an idea, if my model (gam) is fitted 
correct, i.e., is it the "same" like the model I fitted using /`lmer`?/

Thank you,
Rudi


	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Tue May 25 13:04:00 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Tue, 25 May 2021 13:04:00 +0200
Subject: [R-sig-ME] 3-way interaction in random structure using gam
In-Reply-To: <3befbb8a-26b8-c378-e8d8-298e89f22494@boku.ac.at>
References: <f989a499-6c19-b5d1-516e-b80b124a6006@boku.ac.at>
 <3befbb8a-26b8-c378-e8d8-298e89f22494@boku.ac.at>
Message-ID: <CAJuCY5x8ycniOXQieaoN9rDU+sxpuH=0btEJ=AfchEknifGkLg@mail.gmail.com>

Dear Rudi,

If age has a log-linear relationship, then use logAge as predictor rather
than age.

I'm wondering why you insist on adding the 2-way interactions smoothers.
You can't directly interpret 2-way interactions (or main effects) when you
have a 3-way interaction that contains the same variables.

I'd simplify the model to  gam(b.mass ~ te(log.age, area.forest, by =
period), data = data, random = list(pop=~1, year=~1)).

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op di 25 mei 2021 om 09:14 schreef Rudi Reiner <rudi.reiner at boku.ac.at>:

>
> Hi there,
>
> my actually trying to fit a non-linear mixed model (with a random
> structure) and am not sure how to do this correct using "gam" or "bam"
> from the mgcv package. My supervisor suggested me to ask R-sig.
>
> My Data:
>
> b.mass = body mass (continuous) - dependent variable
> _
> __predictor variables_
> age = continuous; lon-linear relationship with b.mass
> area.forest = continuous
> period =  factor; 2 levels
>
> _random variables
> _year = continuous (1993-2019)
> pop = factor (28 different populations)
> --------------------------------------------------
>
> First I fitted a linear model with quadratic age which seems to give me
> the "correct" results (biologically the results make sense). Especially
> I am interested in the 3-way interaction age x area.forest x period but
> also want/have to add all 2-way interactions:
>
> */LM <- lmer(b.mass ~ ns(age,2)*area.forest*period + (1|pop)+ (1|year),
> data = data)/*
>
> Now I want to have the corresponding model using gam (or bam). I tried:
>
> */gam <- gam(b.mass ~ period+s(age)+area.forest+s(age, by =
> area.forest)+s(age, by=period)+te(area.forest, by=period)+te(age,
> area.forest, by = period), data = data, random = list(pop=~1, year=~1))/*
>
> The results (plot age~b.mass for different area.forest) look different
> to the lmer approach. Do have an idea, if my model (gam) is fitted
> correct, i.e., is it the "same" like the model I fitted using /`lmer`?/
>
> Thank you,
> Rudi
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Tue May 25 13:34:37 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Tue, 25 May 2021 13:34:37 +0200
Subject: [R-sig-ME] 3-way interaction in random structure using gam
In-Reply-To: <abdda6ed-9369-7972-c187-33b7547b5009@boku.ac.at>
References: <f989a499-6c19-b5d1-516e-b80b124a6006@boku.ac.at>
 <3befbb8a-26b8-c378-e8d8-298e89f22494@boku.ac.at>
 <CAJuCY5x8ycniOXQieaoN9rDU+sxpuH=0btEJ=AfchEknifGkLg@mail.gmail.com>
 <abdda6ed-9369-7972-c187-33b7547b5009@boku.ac.at>
Message-ID: <CAJuCY5xAK1-ZMDm8OoK2cipXbJ1TOXx1qOJaB=YozvTuVSM8QQ@mail.gmail.com>

Dear Rudi,

Please keep the mailing list in cc.

Yes. I'd use the model with only the 3-way interaction smoother. It can
handle all patterns of the lower interactions.

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op di 25 mei 2021 om 13:30 schreef Rudi Reiner <rudi.reiner at boku.ac.at>:

> Dear Thierry,
>
> thank you for your reply. I am afraid, there was a typing error in my
> initial message. Age and b.mass do have a non-linear (not lon or log
> linear) relationship. Simplified, it may be a quadratic one (see me model
> using lmer) but I think a gam would fit better. So would you still suggest
> this model?:
>
>  gam(b.mass ~ te(age, area.forest, by = period), data = data, random =
> list(pop=~1, year=~1))
>
> Best regards,
> Rudi
>
> Am 25.05.2021 um 13:04 schrieb Thierry Onkelinx:
>
> Dear Rudi,
>
> If age has a log-linear relationship, then use logAge as predictor rather
> than age.
>
> I'm wondering why you insist on adding the 2-way interactions smoothers.
> You can't directly interpret 2-way interactions (or main effects) when you
> have a 3-way interaction that contains the same variables.
>
> I'd simplify the model to  gam(b.mass ~ te(log.age, area.forest, by =
> period), data = data, random = list(pop=~1, year=~1)).
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op di 25 mei 2021 om 09:14 schreef Rudi Reiner <rudi.reiner at boku.ac.at>:
>
>>
>> Hi there,
>>
>> my actually trying to fit a non-linear mixed model (with a random
>> structure) and am not sure how to do this correct using "gam" or "bam"
>> from the mgcv package. My supervisor suggested me to ask R-sig.
>>
>> My Data:
>>
>> b.mass = body mass (continuous) - dependent variable
>> _
>> __predictor variables_
>> age = continuous; lon-linear relationship with b.mass
>> area.forest = continuous
>> period =  factor; 2 levels
>>
>> _random variables
>> _year = continuous (1993-2019)
>> pop = factor (28 different populations)
>> --------------------------------------------------
>>
>> First I fitted a linear model with quadratic age which seems to give me
>> the "correct" results (biologically the results make sense). Especially
>> I am interested in the 3-way interaction age x area.forest x period but
>> also want/have to add all 2-way interactions:
>>
>> */LM <- lmer(b.mass ~ ns(age,2)*area.forest*period + (1|pop)+ (1|year),
>> data = data)/*
>>
>> Now I want to have the corresponding model using gam (or bam). I tried:
>>
>> */gam <- gam(b.mass ~ period+s(age)+area.forest+s(age, by =
>> area.forest)+s(age, by=period)+te(area.forest, by=period)+te(age,
>> area.forest, by = period), data = data, random = list(pop=~1, year=~1))/*
>>
>> The results (plot age~b.mass for different area.forest) look different
>> to the lmer approach. Do have an idea, if my model (gam) is fitted
>> correct, i.e., is it the "same" like the model I fitted using /`lmer`?/
>>
>> Thank you,
>> Rudi
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

	[[alternative HTML version deleted]]


From rud|@re|ner @end|ng |rom boku@@c@@t  Tue May 25 08:31:41 2021
From: rud|@re|ner @end|ng |rom boku@@c@@t (Rudi Reiner)
Date: Tue, 25 May 2021 08:31:41 +0200
Subject: [R-sig-ME] 3-way interaction in random structure using gam
Message-ID: <f989a499-6c19-b5d1-516e-b80b124a6006@boku.ac.at>

Hi there,

my actually trying to fit a non-linear mixed model (with a random 
structure) and am not sure how to do this correct using "gam" or "bam" 
from the mgcv package. My supervisor suggested me to ask R-sig.

My Data:

b.mass = body mass (continuous) - dependent variable
_
__predictor variables_
age = continuous; lon-linear relationship with b.mass
area.forest = continuous
period =? factor; 2 levels

_random variables
_year = continuous (1993-2019)
pop = factor (28 different populations)
__--------------------------------------------------

First I fitted a linear model with quadratic age which seems to give me 
the "correct" results (biologically the results make sense). Especially 
I am interested in the 3-way interaction age x area.forest x period but 
also want/have to add all 2-way interactions:

*/LM <- lmer(b.mass ~ ns(age,2)*area.forest*period + (1|pop)+ (1|year), 
data = data)/*

Now I want to have the corresponding model using gam (or bam). I tried:

*/gam <- gam(b.mass ~ period+s(age)+area.forest+s(age, by = 
area.forest)+s(age, by=period)+te(area.forest, by=period)+te(age, 
area.forest, by = period), data = data, random = list(pop=~1, year=~1))/*

The results (plot age~b.mass for different area.forest) look different 
to the lmer approach. Do have an idea, if my model (gam) is fitted 
correct, i.e., is it the "same" like the model I fitted using /`lmer`?/

Thank you,
Rudi


	[[alternative HTML version deleted]]


From rud|@re|ner @end|ng |rom boku@@c@@t  Tue May 25 14:58:37 2021
From: rud|@re|ner @end|ng |rom boku@@c@@t (Rudi Reiner)
Date: Tue, 25 May 2021 14:58:37 +0200
Subject: [R-sig-ME] 3-way interaction in random structure using gam
In-Reply-To: <CAJuCY5xAK1-ZMDm8OoK2cipXbJ1TOXx1qOJaB=YozvTuVSM8QQ@mail.gmail.com>
References: <f989a499-6c19-b5d1-516e-b80b124a6006@boku.ac.at>
 <3befbb8a-26b8-c378-e8d8-298e89f22494@boku.ac.at>
 <CAJuCY5x8ycniOXQieaoN9rDU+sxpuH=0btEJ=AfchEknifGkLg@mail.gmail.com>
 <abdda6ed-9369-7972-c187-33b7547b5009@boku.ac.at>
 <CAJuCY5xAK1-ZMDm8OoK2cipXbJ1TOXx1qOJaB=YozvTuVSM8QQ@mail.gmail.com>
Message-ID: <24524f11-4740-5b9e-f8a7-46fa7c42e79b@boku.ac.at>

Thank you very much Thierry!

Rudi

Am 25.05.2021 um 13:34 schrieb Thierry Onkelinx:
> Dear Rudi,
>
> Please keep the mailing list in cc.
>
> Yes. I'd use the model with only the 3-way interaction smoother. It 
> can handle all patterns of the lower interactions.
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE 
> AND FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be <http://www.inbo.be>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no 
> more than asking him to perform a post-mortem examination: he may be 
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does 
> not ensure that a reasonable answer can be extracted from a given body 
> of data. ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op di 25 mei 2021 om 13:30 schreef Rudi Reiner <rudi.reiner at boku.ac.at 
> <mailto:rudi.reiner at boku.ac.at>>:
>
>     Dear Thierry,
>
>     thank you for your reply. I am afraid, there was a typing error in
>     my initial message. Age and b.mass do have a non-linear (not lon
>     or log linear) relationship. Simplified, it may be a quadratic one
>     (see me model using lmer) but I think a gam would fit better. So
>     would you still suggest this model?:
>
>     gam(b.mass ~ te(age, area.forest, by = period), data = data,
>     random = list(pop=~1, year=~1))
>
>     Best regards,
>     Rudi
>
>     Am 25.05.2021 um 13:04 schrieb Thierry Onkelinx:
>>     Dear Rudi,
>>
>>     If age has a log-linear relationship, then use logAge as
>>     predictor rather than age.
>>
>>     I'm wondering why you insist on adding the 2-way interactions
>>     smoothers. You can't directly interpret 2-way interactions (or
>>     main effects) when you have a 3-way interaction that contains the
>>     same variables.
>>
>>     I'd simplify the model to gam(b.mass ~ te(log.age, area.forest,
>>     by = period), data = data, random = list(pop=~1, year=~1)).
>>
>>     Best regards,
>>
>>     ir. Thierry Onkelinx
>>     Statisticus / Statistician
>>
>>     Vlaamse Overheid / Government of Flanders
>>     INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR
>>     NATURE AND FOREST
>>     Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality
>>     Assurance
>>     thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>
>>     Havenlaan 88 bus 73, 1000 Brussel
>>     www.inbo.be <http://www.inbo.be>
>>
>>     ///////////////////////////////////////////////////////////////////////////////////////////
>>     To call in the statistician after the experiment is done may be
>>     no more than asking him to perform a post-mortem examination: he
>>     may be able to say what the experiment died of. ~ Sir Ronald
>>     Aylmer Fisher
>>     The plural of anecdote is not data. ~ Roger Brinner
>>     The combination of some data and an aching desire for an answer
>>     does not ensure that a reasonable answer can be extracted from a
>>     given body of data. ~ John Tukey
>>     ///////////////////////////////////////////////////////////////////////////////////////////
>>
>>     <https://www.inbo.be>
>>
>>
>>     Op di 25 mei 2021 om 09:14 schreef Rudi Reiner
>>     <rudi.reiner at boku.ac.at <mailto:rudi.reiner at boku.ac.at>>:
>>
>>
>>         Hi there,
>>
>>         my actually trying to fit a non-linear mixed model (with a
>>         random
>>         structure) and am not sure how to do this correct using "gam"
>>         or "bam"
>>         from the mgcv package. My supervisor suggested me to ask R-sig.
>>
>>         My Data:
>>
>>         b.mass = body mass (continuous) - dependent variable
>>         _
>>         __predictor variables_
>>         age = continuous; lon-linear relationship with b.mass
>>         area.forest = continuous
>>         period =? factor; 2 levels
>>
>>         _random variables
>>         _year = continuous (1993-2019)
>>         pop = factor (28 different populations)
>>         --------------------------------------------------
>>
>>         First I fitted a linear model with quadratic age which seems
>>         to give me
>>         the "correct" results (biologically the results make sense).
>>         Especially
>>         I am interested in the 3-way interaction age x area.forest x
>>         period but
>>         also want/have to add all 2-way interactions:
>>
>>         */LM <- lmer(b.mass ~ ns(age,2)*area.forest*period + (1|pop)+
>>         (1|year),
>>         data = data)/*
>>
>>         Now I want to have the corresponding model using gam (or
>>         bam). I tried:
>>
>>         */gam <- gam(b.mass ~ period+s(age)+area.forest+s(age, by =
>>         area.forest)+s(age, by=period)+te(area.forest,
>>         by=period)+te(age,
>>         area.forest, by = period), data = data, random = list(pop=~1,
>>         year=~1))/*
>>
>>         The results (plot age~b.mass for different area.forest) look
>>         different
>>         to the lmer approach. Do have an idea, if my model (gam) is
>>         fitted
>>         correct, i.e., is it the "same" like the model I fitted using
>>         /`lmer`?/
>>
>>         Thank you,
>>         Rudi
>>
>>
>>         ? ? ? ? [[alternative HTML version deleted]]
>>
>>         _______________________________________________
>>         R-sig-mixed-models at r-project.org
>>         <mailto:R-sig-mixed-models at r-project.org> mailing list
>>         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>         <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>
>


	[[alternative HTML version deleted]]


From @|e@@@ndro@noc| @end|ng |rom roche@com  Tue May 25 15:33:30 2021
From: @|e@@@ndro@noc| @end|ng |rom roche@com (Noci, Alessandro)
Date: Tue, 25 May 2021 15:33:30 +0200
Subject: [R-sig-ME] model convergence warnings with default optimizer but
 not with L-BFGS-B
Message-ID: <CAFGJF4pLccROiWCRsZLS62T3d1VxJc4yJLv=APNXn_vLWtMROA@mail.gmail.com>

Hi all,

I am running some experiments where I need to fit a mixed-effects model for
repeated measures (MMRM) for two arms clinical trials. The outcome is the
mean change from baseline of a given response variable; the model assumes
unstructured mean (i.e. different mean across groups and across time) and
unstructured covariance which is assumed to be different for the two
groups. Moreover the model contains the baseline outcome as an additional
predictor. As discussed in another post (
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2020q4/029135.html) I can
use the package glmmTMB for the model fit when assuming different
covariances for the two arms.

The issue I am encountering is related to the model convergence warnings (a
reproducible example is provided below). Fitting the model using the
default nlminb optimizer leads to the following convergence warning:

Warning message:In fitTMB(TMBStruc) :  Model convergence problem;
false convergence (8). See vignette('troubleshooting')


If I fit the same model on the same data using the L-BFGS-B optimizer I do
not receive any warning and the model convergence is detected as
successful. However the results from the model fit look very similar:
indeed regression coefficients, covariance matrices and log-likelihood
value are the same (at least up to the third decimal digits). Also, when
generating the data with different seeds or changing some parameters used
for the simulation (e.g. the sample size, population mean trajectories..),
I still obtain this issue; so I don't think this is a problem related to
the specific generated dataset.

I also tried to initialize the optimization problem close to the optimum,
i.e. with the results coming from the L-BFGS-B optimizer. I obtain that (1)
I get the same convergence warning and (2) I don't improve computational
time (I expect that if I start very close to the optimal value, I do have
convergence and I also reduce the computational time).

My questions are: why do I get the convergence warning only for the nlminb
optimizer but the optimal value seems almost identical to the results from
the L-BFGS-B optimizer? Why if I initialize the problem close to the
optimal value I do not improve computational times? Am I supplying the
starting values correctly?

Thank you very much.
Best regards,
Alessandro


library(tidyverse)
library(glmmTMB)
library(MASS)
library(lme4)

# set-up simulation
set.seed(123)
N = 300
n1 = n2 = N # equally sized arms

time = seq(0,12,by=2) # time variable

# create covariance matrix
sd_intercept = 10
sd_slope = 5
cor_slope_inter = 0.5

sd_error = 6

covRE = matrix(c(sd_intercept^2,cor_slope_inter*sd_intercept*sd_slope,
                 cor_slope_inter*sd_intercept*sd_slope,sd_slope^2),ncol=2)
Sigma =
cbind(1,time/12)%*%covRE%*%rbind(1,time/12)+diag(sd_error^2,nrow=length(time))

# mean trajectory control
mu2 = 10+12/12*time

# mean trajectory intervention
mu1 = 10+6/12*time

m = length(time)

# simulate data
r2 = data.frame("patnum" = rep(1:n2,each=m),
                "group" = "Control",
                "visit" = rep(0:(m-1),n2),
                "time" = rep(time,n2),
                "x_bl" = NA,
                "x" = c(t(mvrnorm(n=n2,mu=mu2,Sigma=Sigma))))
# Intervention group
r1 = data.frame("patnum" = n2+rep(1:n1,each=m),
                "group" = "Intervention",
                "visit" = rep(0:(m-1),n1),
                "time" = rep(time,n1),
                "x_bl" = NA,
                "x" = c(t(mvrnorm(n=n1,mu=mu1,Sigma=Sigma))))
# Pool both groups and add baseline
r = rbind(r2,r1)
r$x_bl = rep(r$x[time==0],each=m)
r$group = factor(r$group,levels=c("Control","Intervention"))

data = as.data.frame(r)

# add change from baseline
data = data %>%
  group_by(patnum) %>%
  mutate(x_change_bl = x - x_bl)

data = subset(data, visit != 0)
data$visit = as.factor(data$visit)
data$time = as.factor(data$time)

# create dummy variable related to the two treatment arms
data$g_ref = lme4::dummy(data$group, "Control") # reference arm
data$g_treat = lme4::dummy(data$group, "Intervention") # treatment arm

# set model formula
formula = x_change_bl ~ x_bl + visit*group + us(0 + g_ref:visit | patnum) +
us(0 + g_treat:visit | patnum)

# fit model
init = Sys.time()
fit_mmrm = glmmTMB::glmmTMB(formula,
                            data = data,
                            dispformula = ~0,
                            REML = TRUE)
end = Sys.time()
end-init

# extract regression coefficients
betas = glmmTMB::fixef(fit_mmrm)$cond

# log likelihood
loglik = logLik(fit_mmrm)

# extract Cholesky decomposition of the covariance matrices
theta = getME(fit_mmrm, "theta")

# Change optimizer
control = glmmTMB::glmmTMBControl(optimizer = optim,
                                  optArgs = list(method="L-BFGS-B"))
init = Sys.time()
fit_mmrm = glmmTMB::glmmTMB(formula,
                            data = data,
                            dispformula = ~0,
                            REML = TRUE,
                            control = control)
end = Sys.time()
end-init

# extract regression coefficients, log-likelihood and Cholesky
decomposition of covariance matrices
betas_2 = glmmTMB::fixef(fit_mmrm)$cond
loglik_2 = logLik(fit_mmrm)
theta_2 = getME(fit_mmrm, "theta")

# check equality of results
all.equal(betas, betas_2, tolerance=1e-3)
all.equal(loglik, loglik_2, tolerance=1e-3)
all.equal(theta, theta_2, tolerance=1e-3)

# fit model
init = Sys.time()
fit_glmm = glmmTMB::glmmTMB(formula,
                            data = data,
                            dispformula = ~0,
                            REML = TRUE,
                            start = list("beta" = as.numeric(betas_2),
                                         "theta" = theta_2))
end = Sys.time()
end-init

	[[alternative HTML version deleted]]


From @tevedrd @end|ng |rom y@hoo@com  Wed May 26 13:29:12 2021
From: @tevedrd @end|ng |rom y@hoo@com (Steve Denham)
Date: Wed, 26 May 2021 11:29:12 +0000 (UTC)
Subject: [R-sig-ME] 
 model convergence warnings with default optimizer but
 not with L-BFGS-B
In-Reply-To: <CAFGJF4pLccROiWCRsZLS62T3d1VxJc4yJLv=APNXn_vLWtMROA@mail.gmail.com>
References: <CAFGJF4pLccROiWCRsZLS62T3d1VxJc4yJLv=APNXn_vLWtMROA@mail.gmail.com>
Message-ID: <1094622802.248046.1622028552314@mail.yahoo.com>

Hi Alessandro,
I would be concerned that you have a partial confounding issue due to fitting change from baseline AND using baseline as a continuous covariate.? See Frank Harrell's comments regarding analysis of repeated measures at?https://biostat.app.vumc.org/wiki/Main/ManuscriptChecklist, especially regarding the use of change scores in parallel design analyses.
Steve Denham Senior Biostatistics Scientist, Charles River Laboratoies 

    On Tuesday, May 25, 2021, 10:16:14 AM EDT, Noci, Alessandro via R-sig-mixed-models <r-sig-mixed-models at r-project.org> wrote:  
 
 Hi all,

I am running some experiments where I need to fit a mixed-effects model for
repeated measures (MMRM) for two arms clinical trials. The outcome is the
mean change from baseline of a given response variable; the model assumes
unstructured mean (i.e. different mean across groups and across time) and
unstructured covariance which is assumed to be different for the two
groups. Moreover the model contains the baseline outcome as an additional
predictor. As discussed in another post (
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2020q4/029135.html) I can
use the package glmmTMB for the model fit when assuming different
covariances for the two arms.

The issue I am encountering is related to the model convergence warnings (a
reproducible example is provided below). Fitting the model using the
default nlminb optimizer leads to the following convergence warning:

Warning message:In fitTMB(TMBStruc) :? Model convergence problem;
false convergence (8). See vignette('troubleshooting')


If I fit the same model on the same data using the L-BFGS-B optimizer I do
not receive any warning and the model convergence is detected as
successful. However the results from the model fit look very similar:
indeed regression coefficients, covariance matrices and log-likelihood
value are the same (at least up to the third decimal digits). Also, when
generating the data with different seeds or changing some parameters used
for the simulation (e.g. the sample size, population mean trajectories..),
I still obtain this issue; so I don't think this is a problem related to
the specific generated dataset.

I also tried to initialize the optimization problem close to the optimum,
i.e. with the results coming from the L-BFGS-B optimizer. I obtain that (1)
I get the same convergence warning and (2) I don't improve computational
time (I expect that if I start very close to the optimal value, I do have
convergence and I also reduce the computational time).

My questions are: why do I get the convergence warning only for the nlminb
optimizer but the optimal value seems almost identical to the results from
the L-BFGS-B optimizer? Why if I initialize the problem close to the
optimal value I do not improve computational times? Am I supplying the
starting values correctly?

Thank you very much.
Best regards,
Alessandro


library(tidyverse)
library(glmmTMB)
library(MASS)
library(lme4)

# set-up simulation
set.seed(123)
N = 300
n1 = n2 = N # equally sized arms

time = seq(0,12,by=2) # time variable

# create covariance matrix
sd_intercept = 10
sd_slope = 5
cor_slope_inter = 0.5

sd_error = 6

covRE = matrix(c(sd_intercept^2,cor_slope_inter*sd_intercept*sd_slope,
? ? ? ? ? ? ? ? cor_slope_inter*sd_intercept*sd_slope,sd_slope^2),ncol=2)
Sigma =
cbind(1,time/12)%*%covRE%*%rbind(1,time/12)+diag(sd_error^2,nrow=length(time))

# mean trajectory control
mu2 = 10+12/12*time

# mean trajectory intervention
mu1 = 10+6/12*time

m = length(time)

# simulate data
r2 = data.frame("patnum" = rep(1:n2,each=m),
? ? ? ? ? ? ? ? "group" = "Control",
? ? ? ? ? ? ? ? "visit" = rep(0:(m-1),n2),
? ? ? ? ? ? ? ? "time" = rep(time,n2),
? ? ? ? ? ? ? ? "x_bl" = NA,
? ? ? ? ? ? ? ? "x" = c(t(mvrnorm(n=n2,mu=mu2,Sigma=Sigma))))
# Intervention group
r1 = data.frame("patnum" = n2+rep(1:n1,each=m),
? ? ? ? ? ? ? ? "group" = "Intervention",
? ? ? ? ? ? ? ? "visit" = rep(0:(m-1),n1),
? ? ? ? ? ? ? ? "time" = rep(time,n1),
? ? ? ? ? ? ? ? "x_bl" = NA,
? ? ? ? ? ? ? ? "x" = c(t(mvrnorm(n=n1,mu=mu1,Sigma=Sigma))))
# Pool both groups and add baseline
r = rbind(r2,r1)
r$x_bl = rep(r$x[time==0],each=m)
r$group = factor(r$group,levels=c("Control","Intervention"))

data = as.data.frame(r)

# add change from baseline
data = data %>%
? group_by(patnum) %>%
? mutate(x_change_bl = x - x_bl)

data = subset(data, visit != 0)
data$visit = as.factor(data$visit)
data$time = as.factor(data$time)

# create dummy variable related to the two treatment arms
data$g_ref = lme4::dummy(data$group, "Control") # reference arm
data$g_treat = lme4::dummy(data$group, "Intervention") # treatment arm

# set model formula
formula = x_change_bl ~ x_bl + visit*group + us(0 + g_ref:visit | patnum) +
us(0 + g_treat:visit | patnum)

# fit model
init = Sys.time()
fit_mmrm = glmmTMB::glmmTMB(formula,
? ? ? ? ? ? ? ? ? ? ? ? ? ? data = data,
? ? ? ? ? ? ? ? ? ? ? ? ? ? dispformula = ~0,
? ? ? ? ? ? ? ? ? ? ? ? ? ? REML = TRUE)
end = Sys.time()
end-init

# extract regression coefficients
betas = glmmTMB::fixef(fit_mmrm)$cond

# log likelihood
loglik = logLik(fit_mmrm)

# extract Cholesky decomposition of the covariance matrices
theta = getME(fit_mmrm, "theta")

# Change optimizer
control = glmmTMB::glmmTMBControl(optimizer = optim,
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? optArgs = list(method="L-BFGS-B"))
init = Sys.time()
fit_mmrm = glmmTMB::glmmTMB(formula,
? ? ? ? ? ? ? ? ? ? ? ? ? ? data = data,
? ? ? ? ? ? ? ? ? ? ? ? ? ? dispformula = ~0,
? ? ? ? ? ? ? ? ? ? ? ? ? ? REML = TRUE,
? ? ? ? ? ? ? ? ? ? ? ? ? ? control = control)
end = Sys.time()
end-init

# extract regression coefficients, log-likelihood and Cholesky
decomposition of covariance matrices
betas_2 = glmmTMB::fixef(fit_mmrm)$cond
loglik_2 = logLik(fit_mmrm)
theta_2 = getME(fit_mmrm, "theta")

# check equality of results
all.equal(betas, betas_2, tolerance=1e-3)
all.equal(loglik, loglik_2, tolerance=1e-3)
all.equal(theta, theta_2, tolerance=1e-3)

# fit model
init = Sys.time()
fit_glmm = glmmTMB::glmmTMB(formula,
? ? ? ? ? ? ? ? ? ? ? ? ? ? data = data,
? ? ? ? ? ? ? ? ? ? ? ? ? ? dispformula = ~0,
? ? ? ? ? ? ? ? ? ? ? ? ? ? REML = TRUE,
? ? ? ? ? ? ? ? ? ? ? ? ? ? start = list("beta" = as.numeric(betas_2),
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? "theta" = theta_2))
end = Sys.time()
end-init

??? [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
  
	[[alternative HTML version deleted]]


From t@h@|n|erdou@uo|c @end|ng |rom gm@||@com  Thu May 27 03:01:09 2021
From: t@h@|n|erdou@uo|c @end|ng |rom gm@||@com (Tahsin Ferdous)
Date: Wed, 26 May 2021 19:01:09 -0600
Subject: [R-sig-ME] Variable selection for varying dispersion beta glmm
 using glmmTMB package
Message-ID: <CAE5Duhtk6uc82_=ZqY1VCB83UCbBL6aniPKOv+Jsw6EmGUNHTQ@mail.gmail.com>

I am struggling with the varying dispersion beta regression using glmmTMB.
I did the Breusch-Pagan Test for checking heteroscedasticity for my model.
As, the p-value is smaller than 0.05, so heterodasticity is present. So, I
have to use beta glmm for varying dispersion. Further, I need to know which
variable I should include for a varying dispersion model. To know this, I
followed a procedure. For example, my response variable is y, independent
variable is x1,x2 and x3 and there is random effect for study id. At first,
I ran beta glmm for varying dispersion only for y and x1. Then, I did the
Breusch-Pagan Test for checking heteroscedasticity. If the p value is
smaller than 0.05, there is heteroscadsticity. In this case, I added x1
variable in my dispersion model. Similarly, I run beta glmm for y and x2,
and then perform the Breusch-Pagan test. If the result shows
homoscedasticity, then I didn't include x2 covariate for the dispersion
model. Again, I did the same thing for y and x3. If the result implies
heteroscedasticity, then I added x3 covariate for my dispersion model.

Finally, this will be like :
m1.f <- glmmTMB(y~ x1+x2+x3+(1|study_id), data=mydata, ziformula=
~1,dispformula = ~x1+x3, family=beta_family() )
summary(m1.f)

Is my procedure correct?

Should we comment on only conditional mean model?

Thanks.

	[[alternative HTML version deleted]]


From john@m@|ndon@|d @end|ng |rom @nu@edu@@u  Sat May 29 00:13:43 2021
From: john@m@|ndon@|d @end|ng |rom @nu@edu@@u (John Maindonald)
Date: Fri, 28 May 2021 22:13:43 +0000
Subject: [R-sig-ME] Variable selection for varying dispersion beta glmm
 using glmmTMB package
In-Reply-To: <CAE5Duhtk6uc82_=ZqY1VCB83UCbBL6aniPKOv+Jsw6EmGUNHTQ@mail.gmail.com>
References: <CAE5Duhtk6uc82_=ZqY1VCB83UCbBL6aniPKOv+Jsw6EmGUNHTQ@mail.gmail.com>
Message-ID: <067C36E3-02BC-49B6-AA07-04B5DDB2CFD6@anu.edu.au>

The Breusch-Pagan Test, as implemented in lmtest, is designed for
lm models with independent normal errors.   You have a random
effects term ? surely that invalidates use of this test.  Additionally,
I doubt that a normal distribution is a good enough approximation
to beta that, even without the random effects term, results from
lmtest() are valid.


John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>

On 27/05/2021, at 13:01, Tahsin Ferdous <tahsinferdousuofc at gmail.com<mailto:tahsinferdousuofc at gmail.com>> wrote:

I am struggling with the varying dispersion beta regression using glmmTMB.
I did the Breusch-Pagan Test for checking heteroscedasticity for my model.
As, the p-value is smaller than 0.05, so heterodasticity is present. So, I
have to use beta glmm for varying dispersion. Further, I need to know which
variable I should include for a varying dispersion model. To know this, I
followed a procedure. For example, my response variable is y, independent
variable is x1,x2 and x3 and there is random effect for study id. At first,
I ran beta glmm for varying dispersion only for y and x1. Then, I did the
Breusch-Pagan Test for checking heteroscedasticity. If the p value is
smaller than 0.05, there is heteroscadsticity. In this case, I added x1
variable in my dispersion model. Similarly, I run beta glmm for y and x2,
and then perform the Breusch-Pagan test. If the result shows
homoscedasticity, then I didn't include x2 covariate for the dispersion
model. Again, I did the same thing for y and x3. If the result implies
heteroscedasticity, then I added x3 covariate for my dispersion model.

Finally, this will be like :
m1.f <- glmmTMB(y~ x1+x2+x3+(1|study_id), data=mydata, ziformula=
~1,dispformula = ~x1+x3, family=beta_family() )
summary(m1.f)

Is my procedure correct?

Should we comment on only conditional mean model?

Thanks.

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From v|n|c|u@@@@m@|@77 @end|ng |rom gm@||@com  Mon May 31 20:56:20 2021
From: v|n|c|u@@@@m@|@77 @end|ng |rom gm@||@com (Vinicius Maia)
Date: Mon, 31 May 2021 15:56:20 -0300
Subject: [R-sig-ME] Interaction between random and fixed effects
Message-ID: <CAMXcYmY-nrAZuprHRT-MLAkMQMxNqzcffMcM3sJ87hPTKgjZqg@mail.gmail.com>

Hi all,

I have a subtle doubt in how to interpret the interaction between fixed (or
even random) and random effects in the following case.

I have a model: Y ~ Year + (1|Local)+(1|Genotype) + (Year:Local:Genotype)
Year is a fixed effect because it has only 4 levels.

I ran the model with the random and fixed effect interaction just to
explore, but I was not expecting that it would work because Locals are
completely nested within Years.

To my surprise, the model ran and the variance of Year:Local:Genotype are
quite big. How is it possible to have Local interacting with Year if they
are nested? I also tried: Y ~ Year + (1|Local)+(1|Genotype) + (Year:Local)
and the model rans too, without singular fit.

I am struggling to understand if random interactions (it also extends to
cases where the interactions are only between nested random effects) mean
that the variance between Locals changes with Years or if the effect of a
given Local changes with Years. If it is the former option I can understand
why the model ran and has a high variance for the interaction, but if it is
the later case (which I believe it is), how does the model estimate an
interaction for Local:Year if they are nested?

Thanks!

Best wishes,

Vin?cius Maia

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Mon May 31 21:10:13 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Mon, 31 May 2021 21:10:13 +0200
Subject: [R-sig-ME] Interaction between random and fixed effects
In-Reply-To: <CAMXcYmY-nrAZuprHRT-MLAkMQMxNqzcffMcM3sJ87hPTKgjZqg@mail.gmail.com>
References: <CAMXcYmY-nrAZuprHRT-MLAkMQMxNqzcffMcM3sJ87hPTKgjZqg@mail.gmail.com>
Message-ID: <CAJuCY5y91DEjjsnwBUZM10Ohw2P4cjUG3Twh54tdbKcZSqu0kw@mail.gmail.com>

Dear Vinicius,

What did you ran the interaction as a fixed effect Year:Local or a
random effect (1|Year:Local)?  How did you code Local: as a unique value
for every Local and Year combinations? Please do share output or a minimal
example so we know exactly what you did. I'm still a novice at mind reading.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 31 mei 2021 om 20:57 schreef Vinicius Maia <
vinicius.a.maia77 at gmail.com>:

> Hi all,
>
> I have a subtle doubt in how to interpret the interaction between fixed (or
> even random) and random effects in the following case.
>
> I have a model: Y ~ Year + (1|Local)+(1|Genotype) + (Year:Local:Genotype)
> Year is a fixed effect because it has only 4 levels.
>
> I ran the model with the random and fixed effect interaction just to
> explore, but I was not expecting that it would work because Locals are
> completely nested within Years.
>
> To my surprise, the model ran and the variance of Year:Local:Genotype are
> quite big. How is it possible to have Local interacting with Year if they
> are nested? I also tried: Y ~ Year + (1|Local)+(1|Genotype) + (Year:Local)
> and the model rans too, without singular fit.
>
> I am struggling to understand if random interactions (it also extends to
> cases where the interactions are only between nested random effects) mean
> that the variance between Locals changes with Years or if the effect of a
> given Local changes with Years. If it is the former option I can understand
> why the model ran and has a high variance for the interaction, but if it is
> the later case (which I believe it is), how does the model estimate an
> interaction for Local:Year if they are nested?
>
> Thanks!
>
> Best wishes,
>
> Vin?cius Maia
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From v|n|c|u@@@@m@|@77 @end|ng |rom gm@||@com  Mon May 31 21:20:38 2021
From: v|n|c|u@@@@m@|@77 @end|ng |rom gm@||@com (Vinicius Maia)
Date: Mon, 31 May 2021 16:20:38 -0300
Subject: [R-sig-ME] Interaction between random and fixed effects
In-Reply-To: <CAJuCY5y91DEjjsnwBUZM10Ohw2P4cjUG3Twh54tdbKcZSqu0kw@mail.gmail.com>
References: <CAMXcYmY-nrAZuprHRT-MLAkMQMxNqzcffMcM3sJ87hPTKgjZqg@mail.gmail.com>
 <CAJuCY5y91DEjjsnwBUZM10Ohw2P4cjUG3Twh54tdbKcZSqu0kw@mail.gmail.com>
Message-ID: <CAMXcYmZDN-XZ7Ojp1RJPB04NWSr1kbUmigC-1nSRfET0Tvm=uw@mail.gmail.com>

Dear Thierry,

Thank you for your response.
Local is coded with the name of the local, but I believe the nesting is
implicit in the data.

with(dataset, isNested(as.character(Local), as.character(Year)))
returns TRUE

The example is attached.

Best wishes,

Vin?cius

Em seg., 31 de mai. de 2021 ?s 16:10, Thierry Onkelinx <
thierry.onkelinx at inbo.be> escreveu:

> Dear Vinicius,
>
> What did you ran the interaction as a fixed effect Year:Local or a
> random effect (1|Year:Local)?  How did you code Local: as a unique value
> for every Local and Year combinations? Please do share output or a minimal
> example so we know exactly what you did. I'm still a novice at mind reading.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op ma 31 mei 2021 om 20:57 schreef Vinicius Maia <
> vinicius.a.maia77 at gmail.com>:
>
>> Hi all,
>>
>> I have a subtle doubt in how to interpret the interaction between fixed
>> (or
>> even random) and random effects in the following case.
>>
>> I have a model: Y ~ Year + (1|Local)+(1|Genotype) + (Year:Local:Genotype)
>> Year is a fixed effect because it has only 4 levels.
>>
>> I ran the model with the random and fixed effect interaction just to
>> explore, but I was not expecting that it would work because Locals are
>> completely nested within Years.
>>
>> To my surprise, the model ran and the variance of Year:Local:Genotype are
>> quite big. How is it possible to have Local interacting with Year if they
>> are nested? I also tried: Y ~ Year + (1|Local)+(1|Genotype) + (Year:Local)
>> and the model rans too, without singular fit.
>>
>> I am struggling to understand if random interactions (it also extends to
>> cases where the interactions are only between nested random effects) mean
>> that the variance between Locals changes with Years or if the effect of a
>> given Local changes with Years. If it is the former option I can
>> understand
>> why the model ran and has a high variance for the interaction, but if it
>> is
>> the later case (which I believe it is), how does the model estimate an
>> interaction for Local:Year if they are nested?
>>
>> Thanks!
>>
>> Best wishes,
>>
>> Vin?cius Maia
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

From th|erry@onke||nx @end|ng |rom |nbo@be  Mon May 31 21:52:47 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Mon, 31 May 2021 21:52:47 +0200
Subject: [R-sig-ME] Interaction between random and fixed effects
In-Reply-To: <CAMXcYmZDN-XZ7Ojp1RJPB04NWSr1kbUmigC-1nSRfET0Tvm=uw@mail.gmail.com>
References: <CAMXcYmY-nrAZuprHRT-MLAkMQMxNqzcffMcM3sJ87hPTKgjZqg@mail.gmail.com>
 <CAJuCY5y91DEjjsnwBUZM10Ohw2P4cjUG3Twh54tdbKcZSqu0kw@mail.gmail.com>
 <CAMXcYmZDN-XZ7Ojp1RJPB04NWSr1kbUmigC-1nSRfET0Tvm=uw@mail.gmail.com>
Message-ID: <CAJuCY5zdr-VQjuBtO-0+RQ43BiwYCxwqZnGKSsnekWq16qTo6w@mail.gmail.com>

Dear Vinicius,

I think the problem is with your response variable. It seems like you have
a lot of observations with a response value a few orders of magnitude
smaller than the global average. This grouping is not explained by any of
the covariates in your model, leading to huge random effect BLUPs.
Splitting the BLUPs over two variables probably yields a smaller penalty.

Fitting the model with a log transformed response leads to a singular model
with 0 variance for Local. This strengthens my belief that the problem is
with the data.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 31 mei 2021 om 21:21 schreef Vinicius Maia <
vinicius.a.maia77 at gmail.com>:

> Dear Thierry,
>
> Thank you for your response.
> Local is coded with the name of the local, but I believe the nesting is
> implicit in the data.
>
> with(dataset, isNested(as.character(Local), as.character(Year)))
> returns TRUE
>
> The example is attached.
>
> Best wishes,
>
> Vin?cius
>
> Em seg., 31 de mai. de 2021 ?s 16:10, Thierry Onkelinx <
> thierry.onkelinx at inbo.be> escreveu:
>
>> Dear Vinicius,
>>
>> What did you ran the interaction as a fixed effect Year:Local or a
>> random effect (1|Year:Local)?  How did you code Local: as a unique value
>> for every Local and Year combinations? Please do share output or a minimal
>> example so we know exactly what you did. I'm still a novice at mind reading.
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>> AND FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88 bus 73, 1000 Brussel
>> www.inbo.be
>>
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>
>> <https://www.inbo.be>
>>
>>
>> Op ma 31 mei 2021 om 20:57 schreef Vinicius Maia <
>> vinicius.a.maia77 at gmail.com>:
>>
>>> Hi all,
>>>
>>> I have a subtle doubt in how to interpret the interaction between fixed
>>> (or
>>> even random) and random effects in the following case.
>>>
>>> I have a model: Y ~ Year + (1|Local)+(1|Genotype) + (Year:Local:Genotype)
>>> Year is a fixed effect because it has only 4 levels.
>>>
>>> I ran the model with the random and fixed effect interaction just to
>>> explore, but I was not expecting that it would work because Locals are
>>> completely nested within Years.
>>>
>>> To my surprise, the model ran and the variance of Year:Local:Genotype are
>>> quite big. How is it possible to have Local interacting with Year if they
>>> are nested? I also tried: Y ~ Year + (1|Local)+(1|Genotype) +
>>> (Year:Local)
>>> and the model rans too, without singular fit.
>>>
>>> I am struggling to understand if random interactions (it also extends to
>>> cases where the interactions are only between nested random effects) mean
>>> that the variance between Locals changes with Years or if the effect of a
>>> given Local changes with Years. If it is the former option I can
>>> understand
>>> why the model ran and has a high variance for the interaction, but if it
>>> is
>>> the later case (which I believe it is), how does the model estimate an
>>> interaction for Local:Year if they are nested?
>>>
>>> Thanks!
>>>
>>> Best wishes,
>>>
>>> Vin?cius Maia
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>

	[[alternative HTML version deleted]]


From v|n|c|u@@@@m@|@77 @end|ng |rom gm@||@com  Mon May 31 22:02:15 2021
From: v|n|c|u@@@@m@|@77 @end|ng |rom gm@||@com (Vinicius Maia)
Date: Mon, 31 May 2021 17:02:15 -0300
Subject: [R-sig-ME] Interaction between random and fixed effects
In-Reply-To: <CAJuCY5zdr-VQjuBtO-0+RQ43BiwYCxwqZnGKSsnekWq16qTo6w@mail.gmail.com>
References: <CAMXcYmY-nrAZuprHRT-MLAkMQMxNqzcffMcM3sJ87hPTKgjZqg@mail.gmail.com>
 <CAJuCY5y91DEjjsnwBUZM10Ohw2P4cjUG3Twh54tdbKcZSqu0kw@mail.gmail.com>
 <CAMXcYmZDN-XZ7Ojp1RJPB04NWSr1kbUmigC-1nSRfET0Tvm=uw@mail.gmail.com>
 <CAJuCY5zdr-VQjuBtO-0+RQ43BiwYCxwqZnGKSsnekWq16qTo6w@mail.gmail.com>
Message-ID: <CAMXcYmbMD4SartvhKUFywn9dM-WRi5Yi5ebppqzqni8gXgxK4g@mail.gmail.com>

Thank you a lot Thierry,

But besides that, is it sensical to estimate an interaction such as
local:year if local is nested within year? I believe it does not make sense
but when this model ran I started to question what I know.

Best wishes,

Vin?cius



Em seg., 31 de mai. de 2021 ?s 16:52, Thierry Onkelinx <
thierry.onkelinx at inbo.be> escreveu:

> Dear Vinicius,
>
> I think the problem is with your response variable. It seems like you have
> a lot of observations with a response value a few orders of magnitude
> smaller than the global average. This grouping is not explained by any of
> the covariates in your model, leading to huge random effect BLUPs.
> Splitting the BLUPs over two variables probably yields a smaller penalty.
>
> Fitting the model with a log transformed response leads to a singular
> model with 0 variance for Local. This strengthens my belief that the
> problem is with the data.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op ma 31 mei 2021 om 21:21 schreef Vinicius Maia <
> vinicius.a.maia77 at gmail.com>:
>
>> Dear Thierry,
>>
>> Thank you for your response.
>> Local is coded with the name of the local, but I believe the nesting is
>> implicit in the data.
>>
>> with(dataset, isNested(as.character(Local), as.character(Year)))
>> returns TRUE
>>
>> The example is attached.
>>
>> Best wishes,
>>
>> Vin?cius
>>
>> Em seg., 31 de mai. de 2021 ?s 16:10, Thierry Onkelinx <
>> thierry.onkelinx at inbo.be> escreveu:
>>
>>> Dear Vinicius,
>>>
>>> What did you ran the interaction as a fixed effect Year:Local or a
>>> random effect (1|Year:Local)?  How did you code Local: as a unique value
>>> for every Local and Year combinations? Please do share output or a minimal
>>> example so we know exactly what you did. I'm still a novice at mind reading.
>>>
>>> Best regards,
>>>
>>> ir. Thierry Onkelinx
>>> Statisticus / Statistician
>>>
>>> Vlaamse Overheid / Government of Flanders
>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>>> AND FOREST
>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>> thierry.onkelinx at inbo.be
>>> Havenlaan 88 bus 73, 1000 Brussel
>>> www.inbo.be
>>>
>>>
>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of data.
>>> ~ John Tukey
>>>
>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>
>>> <https://www.inbo.be>
>>>
>>>
>>> Op ma 31 mei 2021 om 20:57 schreef Vinicius Maia <
>>> vinicius.a.maia77 at gmail.com>:
>>>
>>>> Hi all,
>>>>
>>>> I have a subtle doubt in how to interpret the interaction between fixed
>>>> (or
>>>> even random) and random effects in the following case.
>>>>
>>>> I have a model: Y ~ Year + (1|Local)+(1|Genotype) +
>>>> (Year:Local:Genotype)
>>>> Year is a fixed effect because it has only 4 levels.
>>>>
>>>> I ran the model with the random and fixed effect interaction just to
>>>> explore, but I was not expecting that it would work because Locals are
>>>> completely nested within Years.
>>>>
>>>> To my surprise, the model ran and the variance of Year:Local:Genotype
>>>> are
>>>> quite big. How is it possible to have Local interacting with Year if
>>>> they
>>>> are nested? I also tried: Y ~ Year + (1|Local)+(1|Genotype) +
>>>> (Year:Local)
>>>> and the model rans too, without singular fit.
>>>>
>>>> I am struggling to understand if random interactions (it also extends to
>>>> cases where the interactions are only between nested random effects)
>>>> mean
>>>> that the variance between Locals changes with Years or if the effect of
>>>> a
>>>> given Local changes with Years. If it is the former option I can
>>>> understand
>>>> why the model ran and has a high variance for the interaction, but if
>>>> it is
>>>> the later case (which I believe it is), how does the model estimate an
>>>> interaction for Local:Year if they are nested?
>>>>
>>>> Thanks!
>>>>
>>>> Best wishes,
>>>>
>>>> Vin?cius Maia
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Tue Jun  1 08:43:49 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Tue, 1 Jun 2021 08:43:49 +0200
Subject: [R-sig-ME] Interaction between random and fixed effects
In-Reply-To: <CAMXcYmbMD4SartvhKUFywn9dM-WRi5Yi5ebppqzqni8gXgxK4g@mail.gmail.com>
References: <CAMXcYmY-nrAZuprHRT-MLAkMQMxNqzcffMcM3sJ87hPTKgjZqg@mail.gmail.com>
 <CAJuCY5y91DEjjsnwBUZM10Ohw2P4cjUG3Twh54tdbKcZSqu0kw@mail.gmail.com>
 <CAMXcYmZDN-XZ7Ojp1RJPB04NWSr1kbUmigC-1nSRfET0Tvm=uw@mail.gmail.com>
 <CAJuCY5zdr-VQjuBtO-0+RQ43BiwYCxwqZnGKSsnekWq16qTo6w@mail.gmail.com>
 <CAMXcYmbMD4SartvhKUFywn9dM-WRi5Yi5ebppqzqni8gXgxK4g@mail.gmail.com>
Message-ID: <CAJuCY5ze1Xq5J4-0ekD5KftEgSdL3q0yfsV6TEhA2uPzinSsSw@mail.gmail.com>

No. It doesn't make sense to use an interaction term. Year + (1|Local) is
sufficient in this case.

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 31 mei 2021 om 22:02 schreef Vinicius Maia <
vinicius.a.maia77 at gmail.com>:

> Thank you a lot Thierry,
>
> But besides that, is it sensical to estimate an interaction such as
> local:year if local is nested within year? I believe it does not make sense
> but when this model ran I started to question what I know.
>
> Best wishes,
>
> Vin?cius
>
>
>
> Em seg., 31 de mai. de 2021 ?s 16:52, Thierry Onkelinx <
> thierry.onkelinx at inbo.be> escreveu:
>
>> Dear Vinicius,
>>
>> I think the problem is with your response variable. It seems like you
>> have a lot of observations with a response value a few orders of magnitude
>> smaller than the global average. This grouping is not explained by any of
>> the covariates in your model, leading to huge random effect BLUPs.
>> Splitting the BLUPs over two variables probably yields a smaller penalty.
>>
>> Fitting the model with a log transformed response leads to a singular
>> model with 0 variance for Local. This strengthens my belief that the
>> problem is with the data.
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>> AND FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88 bus 73, 1000 Brussel
>> www.inbo.be
>>
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>
>> <https://www.inbo.be>
>>
>>
>> Op ma 31 mei 2021 om 21:21 schreef Vinicius Maia <
>> vinicius.a.maia77 at gmail.com>:
>>
>>> Dear Thierry,
>>>
>>> Thank you for your response.
>>> Local is coded with the name of the local, but I believe the nesting is
>>> implicit in the data.
>>>
>>> with(dataset, isNested(as.character(Local), as.character(Year)))
>>> returns TRUE
>>>
>>> The example is attached.
>>>
>>> Best wishes,
>>>
>>> Vin?cius
>>>
>>> Em seg., 31 de mai. de 2021 ?s 16:10, Thierry Onkelinx <
>>> thierry.onkelinx at inbo.be> escreveu:
>>>
>>>> Dear Vinicius,
>>>>
>>>> What did you ran the interaction as a fixed effect Year:Local or a
>>>> random effect (1|Year:Local)?  How did you code Local: as a unique value
>>>> for every Local and Year combinations? Please do share output or a minimal
>>>> example so we know exactly what you did. I'm still a novice at mind reading.
>>>>
>>>> Best regards,
>>>>
>>>> ir. Thierry Onkelinx
>>>> Statisticus / Statistician
>>>>
>>>> Vlaamse Overheid / Government of Flanders
>>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>>>> AND FOREST
>>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>>> thierry.onkelinx at inbo.be
>>>> Havenlaan 88 bus 73, 1000 Brussel
>>>> www.inbo.be
>>>>
>>>>
>>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>> To call in the statistician after the experiment is done may be no more
>>>> than asking him to perform a post-mortem examination: he may be able to say
>>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>> The combination of some data and an aching desire for an answer does
>>>> not ensure that a reasonable answer can be extracted from a given body of
>>>> data. ~ John Tukey
>>>>
>>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>>
>>>> <https://www.inbo.be>
>>>>
>>>>
>>>> Op ma 31 mei 2021 om 20:57 schreef Vinicius Maia <
>>>> vinicius.a.maia77 at gmail.com>:
>>>>
>>>>> Hi all,
>>>>>
>>>>> I have a subtle doubt in how to interpret the interaction between
>>>>> fixed (or
>>>>> even random) and random effects in the following case.
>>>>>
>>>>> I have a model: Y ~ Year + (1|Local)+(1|Genotype) +
>>>>> (Year:Local:Genotype)
>>>>> Year is a fixed effect because it has only 4 levels.
>>>>>
>>>>> I ran the model with the random and fixed effect interaction just to
>>>>> explore, but I was not expecting that it would work because Locals are
>>>>> completely nested within Years.
>>>>>
>>>>> To my surprise, the model ran and the variance of Year:Local:Genotype
>>>>> are
>>>>> quite big. How is it possible to have Local interacting with Year if
>>>>> they
>>>>> are nested? I also tried: Y ~ Year + (1|Local)+(1|Genotype) +
>>>>> (Year:Local)
>>>>> and the model rans too, without singular fit.
>>>>>
>>>>> I am struggling to understand if random interactions (it also extends
>>>>> to
>>>>> cases where the interactions are only between nested random effects)
>>>>> mean
>>>>> that the variance between Locals changes with Years or if the effect
>>>>> of a
>>>>> given Local changes with Years. If it is the former option I can
>>>>> understand
>>>>> why the model ran and has a high variance for the interaction, but if
>>>>> it is
>>>>> the later case (which I believe it is), how does the model estimate an
>>>>> interaction for Local:Year if they are nested?
>>>>>
>>>>> Thanks!
>>>>>
>>>>> Best wishes,
>>>>>
>>>>> Vin?cius Maia
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>

	[[alternative HTML version deleted]]


From v|n|c|u@@@@m@|@77 @end|ng |rom gm@||@com  Tue Jun  1 18:11:07 2021
From: v|n|c|u@@@@m@|@77 @end|ng |rom gm@||@com (Vinicius Maia)
Date: Tue, 1 Jun 2021 13:11:07 -0300
Subject: [R-sig-ME] Interaction between random and fixed effects
In-Reply-To: <CAJuCY5ze1Xq5J4-0ekD5KftEgSdL3q0yfsV6TEhA2uPzinSsSw@mail.gmail.com>
References: <CAMXcYmY-nrAZuprHRT-MLAkMQMxNqzcffMcM3sJ87hPTKgjZqg@mail.gmail.com>
 <CAJuCY5y91DEjjsnwBUZM10Ohw2P4cjUG3Twh54tdbKcZSqu0kw@mail.gmail.com>
 <CAMXcYmZDN-XZ7Ojp1RJPB04NWSr1kbUmigC-1nSRfET0Tvm=uw@mail.gmail.com>
 <CAJuCY5zdr-VQjuBtO-0+RQ43BiwYCxwqZnGKSsnekWq16qTo6w@mail.gmail.com>
 <CAMXcYmbMD4SartvhKUFywn9dM-WRi5Yi5ebppqzqni8gXgxK4g@mail.gmail.com>
 <CAJuCY5ze1Xq5J4-0ekD5KftEgSdL3q0yfsV6TEhA2uPzinSsSw@mail.gmail.com>
Message-ID: <CAMXcYmaCi7zMtWKZcFmm50e9MZaU=VtimtLL4XL6oLGBeLBAFw@mail.gmail.com>

Thanks!

Best regards,

Vin?cius

Em ter., 1 de jun. de 2021 ?s 03:44, Thierry Onkelinx <
thierry.onkelinx at inbo.be> escreveu:

> No. It doesn't make sense to use an interaction term. Year + (1|Local) is
> sufficient in this case.
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op ma 31 mei 2021 om 22:02 schreef Vinicius Maia <
> vinicius.a.maia77 at gmail.com>:
>
>> Thank you a lot Thierry,
>>
>> But besides that, is it sensical to estimate an interaction such as
>> local:year if local is nested within year? I believe it does not make sense
>> but when this model ran I started to question what I know.
>>
>> Best wishes,
>>
>> Vin?cius
>>
>>
>>
>> Em seg., 31 de mai. de 2021 ?s 16:52, Thierry Onkelinx <
>> thierry.onkelinx at inbo.be> escreveu:
>>
>>> Dear Vinicius,
>>>
>>> I think the problem is with your response variable. It seems like you
>>> have a lot of observations with a response value a few orders of magnitude
>>> smaller than the global average. This grouping is not explained by any of
>>> the covariates in your model, leading to huge random effect BLUPs.
>>> Splitting the BLUPs over two variables probably yields a smaller penalty.
>>>
>>> Fitting the model with a log transformed response leads to a singular
>>> model with 0 variance for Local. This strengthens my belief that the
>>> problem is with the data.
>>>
>>> Best regards,
>>>
>>> ir. Thierry Onkelinx
>>> Statisticus / Statistician
>>>
>>> Vlaamse Overheid / Government of Flanders
>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>>> AND FOREST
>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>> thierry.onkelinx at inbo.be
>>> Havenlaan 88 bus 73, 1000 Brussel
>>> www.inbo.be
>>>
>>>
>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of data.
>>> ~ John Tukey
>>>
>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>
>>> <https://www.inbo.be>
>>>
>>>
>>> Op ma 31 mei 2021 om 21:21 schreef Vinicius Maia <
>>> vinicius.a.maia77 at gmail.com>:
>>>
>>>> Dear Thierry,
>>>>
>>>> Thank you for your response.
>>>> Local is coded with the name of the local, but I believe the nesting is
>>>> implicit in the data.
>>>>
>>>> with(dataset, isNested(as.character(Local), as.character(Year)))
>>>> returns TRUE
>>>>
>>>> The example is attached.
>>>>
>>>> Best wishes,
>>>>
>>>> Vin?cius
>>>>
>>>> Em seg., 31 de mai. de 2021 ?s 16:10, Thierry Onkelinx <
>>>> thierry.onkelinx at inbo.be> escreveu:
>>>>
>>>>> Dear Vinicius,
>>>>>
>>>>> What did you ran the interaction as a fixed effect Year:Local or a
>>>>> random effect (1|Year:Local)?  How did you code Local: as a unique value
>>>>> for every Local and Year combinations? Please do share output or a minimal
>>>>> example so we know exactly what you did. I'm still a novice at mind reading.
>>>>>
>>>>> Best regards,
>>>>>
>>>>> ir. Thierry Onkelinx
>>>>> Statisticus / Statistician
>>>>>
>>>>> Vlaamse Overheid / Government of Flanders
>>>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>>>>> AND FOREST
>>>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>>>> thierry.onkelinx at inbo.be
>>>>> Havenlaan 88 bus 73, 1000 Brussel
>>>>> www.inbo.be
>>>>>
>>>>>
>>>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>>> To call in the statistician after the experiment is done may be no
>>>>> more than asking him to perform a post-mortem examination: he may be able
>>>>> to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>>> The combination of some data and an aching desire for an answer does
>>>>> not ensure that a reasonable answer can be extracted from a given body of
>>>>> data. ~ John Tukey
>>>>>
>>>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>>>
>>>>> <https://www.inbo.be>
>>>>>
>>>>>
>>>>> Op ma 31 mei 2021 om 20:57 schreef Vinicius Maia <
>>>>> vinicius.a.maia77 at gmail.com>:
>>>>>
>>>>>> Hi all,
>>>>>>
>>>>>> I have a subtle doubt in how to interpret the interaction between
>>>>>> fixed (or
>>>>>> even random) and random effects in the following case.
>>>>>>
>>>>>> I have a model: Y ~ Year + (1|Local)+(1|Genotype) +
>>>>>> (Year:Local:Genotype)
>>>>>> Year is a fixed effect because it has only 4 levels.
>>>>>>
>>>>>> I ran the model with the random and fixed effect interaction just to
>>>>>> explore, but I was not expecting that it would work because Locals are
>>>>>> completely nested within Years.
>>>>>>
>>>>>> To my surprise, the model ran and the variance of Year:Local:Genotype
>>>>>> are
>>>>>> quite big. How is it possible to have Local interacting with Year if
>>>>>> they
>>>>>> are nested? I also tried: Y ~ Year + (1|Local)+(1|Genotype) +
>>>>>> (Year:Local)
>>>>>> and the model rans too, without singular fit.
>>>>>>
>>>>>> I am struggling to understand if random interactions (it also extends
>>>>>> to
>>>>>> cases where the interactions are only between nested random effects)
>>>>>> mean
>>>>>> that the variance between Locals changes with Years or if the effect
>>>>>> of a
>>>>>> given Local changes with Years. If it is the former option I can
>>>>>> understand
>>>>>> why the model ran and has a high variance for the interaction, but if
>>>>>> it is
>>>>>> the later case (which I believe it is), how does the model estimate an
>>>>>> interaction for Local:Year if they are nested?
>>>>>>
>>>>>> Thanks!
>>>>>>
>>>>>> Best wishes,
>>>>>>
>>>>>> Vin?cius Maia
>>>>>>
>>>>>>         [[alternative HTML version deleted]]
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>
>>>>>

	[[alternative HTML version deleted]]


From t@h@|n|erdou@uo|c @end|ng |rom gm@||@com  Tue Jun  1 19:07:10 2021
From: t@h@|n|erdou@uo|c @end|ng |rom gm@||@com (Tahsin Ferdous)
Date: Tue, 1 Jun 2021 11:07:10 -0600
Subject: [R-sig-ME] Variable selection for varying dispersion beta glmm
 using glmmTMB package
In-Reply-To: <067C36E3-02BC-49B6-AA07-04B5DDB2CFD6@anu.edu.au>
References: <CAE5Duhtk6uc82_=ZqY1VCB83UCbBL6aniPKOv+Jsw6EmGUNHTQ@mail.gmail.com>
 <067C36E3-02BC-49B6-AA07-04B5DDB2CFD6@anu.edu.au>
Message-ID: <CAE5Duhvkd8evE+_hHNJc-y2N8DUULi=cuBUafCoxxvWaM7B3Bw@mail.gmail.com>

Hi John,

Thanks for your clarification. Are you suggesting doing the Breusch-Pagan
Test without the random effects for glmm?

Best,

Tahsin

On Fri, May 28, 2021 at 4:13 PM John Maindonald <john.maindonald at anu.edu.au>
wrote:

> The Breusch-Pagan Test, as implemented in lmtest, is designed for
> lm models with independent normal errors.   You have a random
> effects term ? surely that invalidates use of this test.  Additionally,
> I doubt that a normal distribution is a good enough approximation
> to beta that, even without the random effects term, results from
> lmtest() are valid.
>
> John Maindonald             email: john.maindonald at anu.edu.au
> <john.maindonald at anu.edu.au>
>
> On 27/05/2021, at 13:01, Tahsin Ferdous <tahsinferdousuofc at gmail.com>
> wrote:
>
> I am struggling with the varying dispersion beta regression using glmmTMB.
> I did the Breusch-Pagan Test for checking heteroscedasticity for my model.
> As, the p-value is smaller than 0.05, so heterodasticity is present. So, I
> have to use beta glmm for varying dispersion. Further, I need to know which
> variable I should include for a varying dispersion model. To know this, I
> followed a procedure. For example, my response variable is y, independent
> variable is x1,x2 and x3 and there is random effect for study id. At first,
> I ran beta glmm for varying dispersion only for y and x1. Then, I did the
> Breusch-Pagan Test for checking heteroscedasticity. If the p value is
> smaller than 0.05, there is heteroscadsticity. In this case, I added x1
> variable in my dispersion model. Similarly, I run beta glmm for y and x2,
> and then perform the Breusch-Pagan test. If the result shows
> homoscedasticity, then I didn't include x2 covariate for the dispersion
> model. Again, I did the same thing for y and x3. If the result implies
> heteroscedasticity, then I added x3 covariate for my dispersion model.
>
> Finally, this will be like :
> m1.f <- glmmTMB(y~ x1+x2+x3+(1|study_id), data=mydata, ziformula=
> ~1,dispformula = ~x1+x3, family=beta_family() )
> summary(m1.f)
>
> Is my procedure correct?
>
> Should we comment on only conditional mean model?
>
> Thanks.
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>

	[[alternative HTML version deleted]]


From john@m@|ndon@|d @end|ng |rom @nu@edu@@u  Tue Jun  1 23:11:15 2021
From: john@m@|ndon@|d @end|ng |rom @nu@edu@@u (John Maindonald)
Date: Tue, 1 Jun 2021 21:11:15 +0000
Subject: [R-sig-ME] Variable selection for varying dispersion beta glmm
 using glmmTMB package
In-Reply-To: <CAE5Duhvkd8evE+_hHNJc-y2N8DUULi=cuBUafCoxxvWaM7B3Bw@mail.gmail.com>
References: <CAE5Duhtk6uc82_=ZqY1VCB83UCbBL6aniPKOv+Jsw6EmGUNHTQ@mail.gmail.com>
 <067C36E3-02BC-49B6-AA07-04B5DDB2CFD6@anu.edu.au>
 <CAE5Duhvkd8evE+_hHNJc-y2N8DUULi=cuBUafCoxxvWaM7B3Bw@mail.gmail.com>
Message-ID: <541E3A49-D680-4576-9995-37ABC979A96C@anu.edu.au>

No, I was not suggesting that.  I?d stick with the checks done
using simulateResiduals() and plotResiduals() from DHARMa.
The parameter `form` allows you to specify an explanatory
variable against whose values you can plot the simulated
residuals.

John Maindonald             email: john.maindonald at anu.edu.a<mailto:john.maindonald at anu.edu.a>


On 2/06/2021, at 05:07, Tahsin Ferdous <tahsinferdousuofc at gmail.com<mailto:tahsinferdousuofc at gmail.com>> wrote:

Hi John,

Thanks for your clarification. Are you suggesting doing the Breusch-Pagan Test without the random effects for glmm?

Best,

Tahsin

On Fri, May 28, 2021 at 4:13 PM John Maindonald <john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>> wrote:
The Breusch-Pagan Test, as implemented in lmtest, is designed for
lm models with independent normal errors.   You have a random
effects term ? surely that invalidates use of this test.  Additionally,
I doubt that a normal distribution is a good enough approximation
to beta that, even without the random effects term, results from
lmtest() are valid.

John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>

On 27/05/2021, at 13:01, Tahsin Ferdous <tahsinferdousuofc at gmail.com<mailto:tahsinferdousuofc at gmail.com>> wrote:

I am struggling with the varying dispersion beta regression using glmmTMB.
I did the Breusch-Pagan Test for checking heteroscedasticity for my model.
As, the p-value is smaller than 0.05, so heterodasticity is present. So, I
have to use beta glmm for varying dispersion. Further, I need to know which
variable I should include for a varying dispersion model. To know this, I
followed a procedure. For example, my response variable is y, independent
variable is x1,x2 and x3 and there is random effect for study id. At first,
I ran beta glmm for varying dispersion only for y and x1. Then, I did the
Breusch-Pagan Test for checking heteroscedasticity. If the p value is
smaller than 0.05, there is heteroscadsticity. In this case, I added x1
variable in my dispersion model. Similarly, I run beta glmm for y and x2,
and then perform the Breusch-Pagan test. If the result shows
homoscedasticity, then I didn't include x2 covariate for the dispersion
model. Again, I did the same thing for y and x3. If the result implies
heteroscedasticity, then I added x3 covariate for my dispersion model.

Finally, this will be like :
m1.f <- glmmTMB(y~ x1+x2+x3+(1|study_id), data=mydata, ziformula=
~1,dispformula = ~x1+x3, family=beta_family() )
summary(m1.f)

Is my procedure correct?

Should we comment on only conditional mean model?

Thanks.

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



	[[alternative HTML version deleted]]


From t@h@|n|erdou@uo|c @end|ng |rom gm@||@com  Thu Jun  3 00:33:20 2021
From: t@h@|n|erdou@uo|c @end|ng |rom gm@||@com (Tahsin Ferdous)
Date: Wed, 2 Jun 2021 16:33:20 -0600
Subject: [R-sig-ME] Variable selection for varying dispersion beta glmm
 using glmmTMB package
In-Reply-To: <CAE5DuhsbOTFzUtknj=AvTDM2PGNHS6kypnHp-HtppAGKxX9F-g@mail.gmail.com>
References: <CAE5Duhtk6uc82_=ZqY1VCB83UCbBL6aniPKOv+Jsw6EmGUNHTQ@mail.gmail.com>
 <067C36E3-02BC-49B6-AA07-04B5DDB2CFD6@anu.edu.au>
 <CAE5Duhvkd8evE+_hHNJc-y2N8DUULi=cuBUafCoxxvWaM7B3Bw@mail.gmail.com>
 <541E3A49-D680-4576-9995-37ABC979A96C@anu.edu.au>
 <CAE5DuhsbOTFzUtknj=AvTDM2PGNHS6kypnHp-HtppAGKxX9F-g@mail.gmail.com>
Message-ID: <CAE5DuhvatXv4bJhDDbRs+WPiiRNAP8cjAGFht+gQz_68E42oGw@mail.gmail.com>

Hi all,

I am struggling to interpret the residual plots from the Dharma package. If
we find a red line in residual plot,does it mean there is
heteroscedasticity in the model for the predictor variables? If the solid
line matches with the dashed line, can we say there is no
heteroscedasticity? I have attached three residual plots here to understand
heteroscedasticity of the model.  In the first plot, quantile deviationare
detected by the red line, so there is heteroscedasticity in the model. This
is for the model which includes all covariates. Then I created the residual
plot for one by one covariate to know which predictors are responsible for
variable dispersion. The 2nd and 3rd plots are for just one predictor. In
the 2nd plot, three solid lines are red and there exhibits a clear
deviation from the dashed line. So, there is heteroscedasticity in the
model for that predictor. The 3rd plot is box plot.The distribution for
each factor level should be uniformly distributed, so the box should go
from 0.25 to 0.75, with the median line at 0.5 (within-group ). As the two
box plots are red and it shows deviation of median line from 0.5, so there
is heteroscedasticity in the model for the predictor. The 4th plot shows
less deviation. Can we say this is better? I need your expert suggestions
and also please refer me to any article where I find a clear explanation of
heteroscedasticity checking by residual plot using DHARMA.Many thanks.

Kindest regards,

Tahsin

On Tue, Jun 1, 2021 at 4:14 PM Tahsin Ferdous <tahsinferdousuofc at gmail.com>
wrote:

> Thanks John.
>
> On Tue, Jun 1, 2021 at 3:11 PM John Maindonald <john.maindonald at anu.edu.au>
> wrote:
>
>> No, I was not suggesting that.  I?d stick with the checks done
>> using simulateResiduals() and plotResiduals() from DHARMa.
>> The parameter `form` allows you to specify an explanatory
>> variable against whose values you can plot the simulated
>> residuals.
>>
>> John Maindonald             email: john.maindonald at anu.edu.a
>> <john.maindonald at anu.edu.a>
>>
>>
>> On 2/06/2021, at 05:07, Tahsin Ferdous <tahsinferdousuofc at gmail.com>
>> wrote:
>>
>> Hi John,
>>
>> Thanks for your clarification. Are you suggesting doing the Breusch-Pagan
>> Test without the random effects for glmm?
>>
>> Best,
>>
>> Tahsin
>>
>> On Fri, May 28, 2021 at 4:13 PM John Maindonald <
>> john.maindonald at anu.edu.au> wrote:
>>
>>> The Breusch-Pagan Test, as implemented in lmtest, is designed for
>>> lm models with independent normal errors.   You have a random
>>> effects term ? surely that invalidates use of this test.  Additionally,
>>> I doubt that a normal distribution is a good enough approximation
>>> to beta that, even without the random effects term, results from
>>> lmtest() are valid.
>>>
>>> John Maindonald             email: john.maindonald at anu.edu.au
>>> <john.maindonald at anu.edu.au>
>>>
>>> On 27/05/2021, at 13:01, Tahsin Ferdous <tahsinferdousuofc at gmail.com>
>>> wrote:
>>>
>>> I am struggling with the varying dispersion beta regression using
>>> glmmTMB.
>>> I did the Breusch-Pagan Test for checking heteroscedasticity for my
>>> model.
>>> As, the p-value is smaller than 0.05, so heterodasticity is present. So,
>>> I
>>> have to use beta glmm for varying dispersion. Further, I need to know
>>> which
>>> variable I should include for a varying dispersion model. To know this, I
>>> followed a procedure. For example, my response variable is y, independent
>>> variable is x1,x2 and x3 and there is random effect for study id. At
>>> first,
>>> I ran beta glmm for varying dispersion only for y and x1. Then, I did the
>>> Breusch-Pagan Test for checking heteroscedasticity. If the p value is
>>> smaller than 0.05, there is heteroscadsticity. In this case, I added x1
>>> variable in my dispersion model. Similarly, I run beta glmm for y and x2,
>>> and then perform the Breusch-Pagan test. If the result shows
>>> homoscedasticity, then I didn't include x2 covariate for the dispersion
>>> model. Again, I did the same thing for y and x3. If the result implies
>>> heteroscedasticity, then I added x3 covariate for my dispersion model.
>>>
>>> Finally, this will be like :
>>> m1.f <- glmmTMB(y~ x1+x2+x3+(1|study_id), data=mydata, ziformula=
>>> ~1,dispformula = ~x1+x3, family=beta_family() )
>>> summary(m1.f)
>>>
>>> Is my procedure correct?
>>>
>>> Should we comment on only conditional mean model?
>>>
>>> Thanks.
>>>
>>> [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>>
>>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot1.png
Type: image/png
Size: 98722 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20210602/7c4b478f/attachment-0004.png>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot 2.png
Type: image/png
Size: 142547 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20210602/7c4b478f/attachment-0005.png>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot 3.png
Type: image/png
Size: 45874 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20210602/7c4b478f/attachment-0006.png>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot 4.png
Type: image/png
Size: 85031 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20210602/7c4b478f/attachment-0007.png>

From john@m@|ndon@|d @end|ng |rom @nu@edu@@u  Thu Jun  3 04:09:05 2021
From: john@m@|ndon@|d @end|ng |rom @nu@edu@@u (John Maindonald)
Date: Thu, 3 Jun 2021 02:09:05 +0000
Subject: [R-sig-ME] Variable selection for varying dispersion beta glmm
 using glmmTMB package
In-Reply-To: <CAE5DuhvatXv4bJhDDbRs+WPiiRNAP8cjAGFht+gQz_68E42oGw@mail.gmail.com>
References: <CAE5Duhtk6uc82_=ZqY1VCB83UCbBL6aniPKOv+Jsw6EmGUNHTQ@mail.gmail.com>
 <067C36E3-02BC-49B6-AA07-04B5DDB2CFD6@anu.edu.au>
 <CAE5Duhvkd8evE+_hHNJc-y2N8DUULi=cuBUafCoxxvWaM7B3Bw@mail.gmail.com>
 <541E3A49-D680-4576-9995-37ABC979A96C@anu.edu.au>
 <CAE5DuhsbOTFzUtknj=AvTDM2PGNHS6kypnHp-HtppAGKxX9F-g@mail.gmail.com>
 <CAE5DuhvatXv4bJhDDbRs+WPiiRNAP8cjAGFht+gQz_68E42oGw@mail.gmail.com>
Message-ID: <00844CDF-93B3-49D0-82F7-45651A89C2F6@anu.edu.au>


Look first in the help pages (?DHARMa etc) and vignettes for
the DHARMa package.  After that, I am not sure what to suggest.
Others may have suggestions.

You will be lucky to get a perfect fit.  At the end of the day, the
question is whether such differences as are apparent matter,
for the purpose for which you intend to use the model.  A useful
tack is to simulate from the fitted model, fit to that model, and
check what difference it makes for the purpose for which the
model is used.  If there is little difference, the deviations from
the model probably do not much matter.  Maybe, repeat several
times.

Maybe you need to include degree 2 term(s) in your dispformula.
Try, maybe, a degree 2 normal spline (this may give less wiggle
at the extremes, and more flexibility of shape in the midrange
region) or a degree 2 or even 3 orthogonal polynomial [use poly()].


John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>


On 3/06/2021, at 10:33, Tahsin Ferdous <tahsinferdousuofc at gmail.com<mailto:tahsinferdousuofc at gmail.com>> wrote:

Hi all,

I am struggling to interpret the residual plots from the Dharma package. If we find a red line in residual plot,does it mean there is heteroscedasticity in the model for the predictor variables? If the solid line matches with the dashed line, can we say there is no heteroscedasticity? I have attached three residual plots here to understand heteroscedasticity of the model.  In the first plot, quantile deviationare detected by the red line, so there is heteroscedasticity in the model. This is for the model which includes all covariates. Then I created the residual plot for one by one covariate to know which predictors are responsible for variable dispersion. The 2nd and 3rd plots are for just one predictor. In the 2nd plot, three solid lines are red and there exhibits a clear deviation from the dashed line. So, there is heteroscedasticity in the model for that predictor. The 3rd plot is box plot.The distribution for each factor level should be uniformly distributed, so the box should go from 0.25 to 0.75, with the median line at 0.5 (within-group ). As the two box plots are red and it shows deviation of median line from 0.5, so there is heteroscedasticity in the model for the predictor. The 4th plot shows less deviation. Can we say this is better? I need your expert suggestions and also please refer me to any article where I find a clear explanation of heteroscedasticity checking by residual plot using DHARMA.Many thanks.

Kindest regards,

Tahsin

On Tue, Jun 1, 2021 at 4:14 PM Tahsin Ferdous <tahsinferdousuofc at gmail.com<mailto:tahsinferdousuofc at gmail.com>> wrote:
Thanks John.

On Tue, Jun 1, 2021 at 3:11 PM John Maindonald <john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>> wrote:
No, I was not suggesting that.  I?d stick with the checks done
using simulateResiduals() and plotResiduals() from DHARMa.
The parameter `form` allows you to specify an explanatory
variable against whose values you can plot the simulated
residuals.
John Maindonald             email: john.maindonald at anu.edu.a<mailto:john.maindonald at anu.edu.a>

On 2/06/2021, at 05:07, Tahsin Ferdous <tahsinferdousuofc at gmail.com<mailto:tahsinferdousuofc at gmail.com>> wrote:

Hi John,

Thanks for your clarification. Are you suggesting doing the Breusch-Pagan Test without the random effects for glmm?

Best,

Tahsin

On Fri, May 28, 2021 at 4:13 PM John Maindonald <john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>> wrote:
The Breusch-Pagan Test, as implemented in lmtest, is designed for
lm models with independent normal errors.   You have a random
effects term ? surely that invalidates use of this test.  Additionally,
I doubt that a normal distribution is a good enough approximation
to beta that, even without the random effects term, results from
lmtest() are valid.

John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>

On 27/05/2021, at 13:01, Tahsin Ferdous <tahsinferdousuofc at gmail.com<mailto:tahsinferdousuofc at gmail.com>> wrote:

I am struggling with the varying dispersion beta regression using glmmTMB.
I did the Breusch-Pagan Test for checking heteroscedasticity for my model.
As, the p-value is smaller than 0.05, so heterodasticity is present. So, I
have to use beta glmm for varying dispersion. Further, I need to know which
variable I should include for a varying dispersion model. To know this, I
followed a procedure. For example, my response variable is y, independent
variable is x1,x2 and x3 and there is random effect for study id. At first,
I ran beta glmm for varying dispersion only for y and x1. Then, I did the
Breusch-Pagan Test for checking heteroscedasticity. If the p value is
smaller than 0.05, there is heteroscadsticity. In this case, I added x1
variable in my dispersion model. Similarly, I run beta glmm for y and x2,
and then perform the Breusch-Pagan test. If the result shows
homoscedasticity, then I didn't include x2 covariate for the dispersion
model. Again, I did the same thing for y and x3. If the result implies
heteroscedasticity, then I added x3 covariate for my dispersion model.

Finally, this will be like :
m1.f <- glmmTMB(y~ x1+x2+x3+(1|study_id), data=mydata, ziformula=
~1,dispformula = ~x1+x3, family=beta_family() )
summary(m1.f)

Is my procedure correct?

Should we comment on only conditional mean model?

Thanks.

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


<Rplot1.png><Rplot 2.png><Rplot 3.png><Rplot 4.png>


	[[alternative HTML version deleted]]


From |@|@n @end|ng |rom vu@n|  Thu Jun  3 14:52:20 2021
From: |@|@n @end|ng |rom vu@n| (Fan, L.)
Date: Thu, 3 Jun 2021 12:52:20 +0000
Subject: [R-sig-ME] Residual setting with makeLmer in simR package
In-Reply-To: <3BD202F1-FBE6-406A-BC23-C7B37AADB44E@vu.nl>
References: <3BD202F1-FBE6-406A-BC23-C7B37AADB44E@vu.nl>
Message-ID: <23E5145C-0087-4C4C-91E1-4203DAD64F90@vu.nl>

Hi all,

I have a doubt about how to set residual sd (sigma) for a PA, using makeLmer function of the simR package.

When defining the fixed effect, my parameter estimates were all standardized coefficients (i.e., I standardised/z-scored all the variables beforehand). When defining the random structures, since I extracted them from another similar but not same-structured study, I also used the standardized variances (variance divided by sum of variances) for random intercepts and slopes to match them with my manipulation for the fixed parts. 

When I tried to fill the sigma of makeLmer function, I got a little bit lost. It is said in the manual that I should enter the sd of the residual. However, since I standardized the random effects, I believe the residual sd should also be different than the original unstandardized one. My question is, how should I deal with this sigma part, should I indeed use a standardized residual sd? And if yes, should it be simply valued as 1, or how should I standardize it?

Thanks!

Best wishes,

Lei Fan

From t@h@|n|erdou@uo|c @end|ng |rom gm@||@com  Fri Jun  4 03:59:42 2021
From: t@h@|n|erdou@uo|c @end|ng |rom gm@||@com (Tahsin Ferdous)
Date: Thu, 3 Jun 2021 19:59:42 -0600
Subject: [R-sig-ME] Variable selection for varying dispersion beta glmm
 using glmmTMB package
In-Reply-To: <00844CDF-93B3-49D0-82F7-45651A89C2F6@anu.edu.au>
References: <CAE5Duhtk6uc82_=ZqY1VCB83UCbBL6aniPKOv+Jsw6EmGUNHTQ@mail.gmail.com>
 <067C36E3-02BC-49B6-AA07-04B5DDB2CFD6@anu.edu.au>
 <CAE5Duhvkd8evE+_hHNJc-y2N8DUULi=cuBUafCoxxvWaM7B3Bw@mail.gmail.com>
 <541E3A49-D680-4576-9995-37ABC979A96C@anu.edu.au>
 <CAE5DuhsbOTFzUtknj=AvTDM2PGNHS6kypnHp-HtppAGKxX9F-g@mail.gmail.com>
 <CAE5DuhvatXv4bJhDDbRs+WPiiRNAP8cjAGFht+gQz_68E42oGw@mail.gmail.com>
 <00844CDF-93B3-49D0-82F7-45651A89C2F6@anu.edu.au>
Message-ID: <CAE5DuhvO-xnjU+HTbTUvLjnEwaw=QAOjEMJZP6SuRGtBmSV9bA@mail.gmail.com>

Thanks a lot John for your valuable suggestions.

Kindest regards,

Tahsin

On Wed, Jun 2, 2021 at 8:09 PM John Maindonald <john.maindonald at anu.edu.au>
wrote:

>
> Look first in the help pages (?DHARMa etc) and vignettes for
> the DHARMa package.  After that, I am not sure what to suggest.
> Others may have suggestions.
>
> You will be lucky to get a perfect fit.  At the end of the day, the
> question is whether such differences as are apparent matter,
> for the purpose for which you intend to use the model.  A useful
> tack is to simulate from the fitted model, fit to that model, and
> check what difference it makes for the purpose for which the
> model is used.  If there is little difference, the deviations from
> the model probably do not much matter.  Maybe, repeat several
> times.
>
> Maybe you need to include degree 2 term(s) in your dispformula.
> Try, maybe, a degree 2 normal spline (this may give less wiggle
> at the extremes, and more flexibility of shape in the midrange
> region) or a degree 2 or even 3 orthogonal polynomial [use poly()].
>
> John Maindonald             email: john.maindonald at anu.edu.au
> <john.maindonald at anu.edu.au>
>
>
> On 3/06/2021, at 10:33, Tahsin Ferdous <tahsinferdousuofc at gmail.com>
> wrote:
>
> Hi all,
>
> I am struggling to interpret the residual plots from the Dharma package.
> If we find a red line in residual plot,does it mean there is
> heteroscedasticity in the model for the predictor variables? If the solid
> line matches with the dashed line, can we say there is no
> heteroscedasticity? I have attached three residual plots here to understand
> heteroscedasticity of the model.  In the first plot, quantile deviationare
> detected by the red line, so there is heteroscedasticity in the model. This
> is for the model which includes all covariates. Then I created the residual
> plot for one by one covariate to know which predictors are responsible for
> variable dispersion. The 2nd and 3rd plots are for just one predictor. In
> the 2nd plot, three solid lines are red and there exhibits a clear
> deviation from the dashed line. So, there is heteroscedasticity in the
> model for that predictor. The 3rd plot is box plot.The distribution for
> each factor level should be uniformly distributed, so the box should go
> from 0.25 to 0.75, with the median line at 0.5 (within-group ). As the two
> box plots are red and it shows deviation of median line from 0.5, so there
> is heteroscedasticity in the model for the predictor. The 4th plot shows
> less deviation. Can we say this is better? I need your expert suggestions
> and also please refer me to any article where I find a clear explanation of
> heteroscedasticity checking by residual plot using DHARMA.Many thanks.
>
> Kindest regards,
>
> Tahsin
>
> On Tue, Jun 1, 2021 at 4:14 PM Tahsin Ferdous <tahsinferdousuofc at gmail.com>
> wrote:
>
>> Thanks John.
>>
>> On Tue, Jun 1, 2021 at 3:11 PM John Maindonald <
>> john.maindonald at anu.edu.au> wrote:
>>
>>> No, I was not suggesting that.  I?d stick with the checks done
>>> using simulateResiduals() and plotResiduals() from DHARMa.
>>> The parameter `form` allows you to specify an explanatory
>>> variable against whose values you can plot the simulated
>>> residuals.
>>> John Maindonald             email: john.maindonald at anu.edu.a
>>> <john.maindonald at anu.edu.a>
>>>
>>> On 2/06/2021, at 05:07, Tahsin Ferdous <tahsinferdousuofc at gmail.com>
>>> wrote:
>>>
>>> Hi John,
>>>
>>> Thanks for your clarification. Are you suggesting doing the
>>> Breusch-Pagan Test without the random effects for glmm?
>>>
>>> Best,
>>>
>>> Tahsin
>>>
>>> On Fri, May 28, 2021 at 4:13 PM John Maindonald <
>>> john.maindonald at anu.edu.au> wrote:
>>>
>>>> The Breusch-Pagan Test, as implemented in lmtest, is designed for
>>>> lm models with independent normal errors.   You have a random
>>>> effects term ? surely that invalidates use of this test.  Additionally,
>>>> I doubt that a normal distribution is a good enough approximation
>>>> to beta that, even without the random effects term, results from
>>>> lmtest() are valid.
>>>>
>>>> John Maindonald             email: john.maindonald at anu.edu.au
>>>> <john.maindonald at anu.edu.au>
>>>>
>>>> On 27/05/2021, at 13:01, Tahsin Ferdous <tahsinferdousuofc at gmail.com>
>>>> wrote:
>>>>
>>>> I am struggling with the varying dispersion beta regression using
>>>> glmmTMB.
>>>> I did the Breusch-Pagan Test for checking heteroscedasticity for my
>>>> model.
>>>> As, the p-value is smaller than 0.05, so heterodasticity is present.
>>>> So, I
>>>> have to use beta glmm for varying dispersion. Further, I need to know
>>>> which
>>>> variable I should include for a varying dispersion model. To know this,
>>>> I
>>>> followed a procedure. For example, my response variable is y,
>>>> independent
>>>> variable is x1,x2 and x3 and there is random effect for study id. At
>>>> first,
>>>> I ran beta glmm for varying dispersion only for y and x1. Then, I did
>>>> the
>>>> Breusch-Pagan Test for checking heteroscedasticity. If the p value is
>>>> smaller than 0.05, there is heteroscadsticity. In this case, I added x1
>>>> variable in my dispersion model. Similarly, I run beta glmm for y and
>>>> x2,
>>>> and then perform the Breusch-Pagan test. If the result shows
>>>> homoscedasticity, then I didn't include x2 covariate for the dispersion
>>>> model. Again, I did the same thing for y and x3. If the result implies
>>>> heteroscedasticity, then I added x3 covariate for my dispersion model.
>>>>
>>>> Finally, this will be like :
>>>> m1.f <- glmmTMB(y~ x1+x2+x3+(1|study_id), data=mydata, ziformula=
>>>> ~1,dispformula = ~x1+x3, family=beta_family() )
>>>> summary(m1.f)
>>>>
>>>> Is my procedure correct?
>>>>
>>>> Should we comment on only conditional mean model?
>>>>
>>>> Thanks.
>>>>
>>>> [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>>
>>>>
>>> <Rplot1.png><Rplot 2.png><Rplot 3.png><Rplot 4.png>
>
>
>

	[[alternative HTML version deleted]]


From t@h@|n|erdou@uo|c @end|ng |rom gm@||@com  Thu Jun  3 01:11:15 2021
From: t@h@|n|erdou@uo|c @end|ng |rom gm@||@com (Tahsin Ferdous)
Date: Wed, 2 Jun 2021 17:11:15 -0600
Subject: [R-sig-ME] Interpretation of residual plot using DHARMA package for
 mixed model
Message-ID: <CAE5Duhv2oY864hZqpwkC9_oLHSZyZU8kgXWTLSytgkR96+pseQ@mail.gmail.com>

Dear all.

I am struggling to interpret the residual plots from the Dharma package. If
we find a red line in residual plot,does it mean there is
heteroscedasticity in the model for the predictor variables? If the solid
line matches with the dashed line, can we say there is no
heteroscedasticity? I have attached three residual plots here to understand
heteroscedasticity of the model.  In the first plot, quantile deviationare
detected by the red line, so there is heteroscedasticity in the model. This
is for the model which includes all covariates. Then I created the residual
plot for one by one covariate to know which predictors are responsible for
variable dispersion. The 2nd and 3rd plots are for just one predictor. In
the 2nd plot, three solid lines are red and there exhibits a clear
deviation from the dashed line. So, there is heteroscedasticity in the
model for that predictor. The 3rd plot is box plot.The distribution for
each factor level should be uniformly distributed, so the box should go
from 0.25 to 0.75, with the median line at 0.5 (within-group ). As the two
box plots are red and it shows deviation of median line from 0.5, so there
is heteroscedasticity in the model for the predictor. The 4th plot shows
less deviation. Can we say this is better? I need your expert suggestions
and also please refer me to any article where I find a clear explanation of
heteroscedasticity checking by residual plot using DHARMA.Many thanks.

Kindest regards,

Tahsin

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot1.png
Type: image/png
Size: 98722 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20210602/4687a53d/attachment-0004.png>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot 2.png
Type: image/png
Size: 142547 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20210602/4687a53d/attachment-0005.png>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot 3.png
Type: image/png
Size: 45874 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20210602/4687a53d/attachment-0006.png>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot 4.png
Type: image/png
Size: 85031 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20210602/4687a53d/attachment-0007.png>

From b@ud-bovy@g@br|e| @end|ng |rom h@r@|t  Fri Jun  4 18:29:21 2021
From: b@ud-bovy@g@br|e| @end|ng |rom h@r@|t (Gabriel Baud-Bovy)
Date: Fri, 4 Jun 2021 18:29:21 +0200
Subject: [R-sig-ME] glmer and influence.me - complaining about nAGQ==0
In-Reply-To: <adc25a1b-dd59-78ff-f910-84f8f9f901cc@phillipalday.com>
References: <25510_1619289003_13OIU2KX028554_CACw+TfcLvEGOv=CG21U+MeYz9XU0VidHmmkKBO0+J7wUQircUw@mail.gmail.com>
 <f0da674d-64f3-82f7-136b-2871465de994@mcmaster.ca>
 <97f57616-50af-0467-920b-0e15c260b5d7@gmail.com>
 <adc25a1b-dd59-78ff-f910-84f8f9f901cc@phillipalday.com>
Message-ID: <869e48f9-fe49-b431-bdd8-d8c051e8cfe6@hsr.it>


I agree that data should not be log transformed twice. In practice,
using the log link with the
Gamma model do solve  errors occutring when negative values occurs
during the fitting process.

However, I think that one should  avoid log-transforming RTs data
ideally because it can affect the significance
of an interaction. I would prefer to assess effect on RTs on its
original scale if possible as suggested by Lo and Andrew
(@Alday: am I wrong in this respect?).

In fact, two years ago, I was able to fit RT data with a Gamma model and
identity link but
I could not understand the results:

https://stats.stackexchange.com/questions/391076/how-to-interpret-significant-factors-in-a-glmm-gamma-model-that-appears-to-be-go

see also my question in this list (3/21/2019) Fitting RT:
underdispersion with gamma and identity link.  At the
time, I caclutated DHARMA  residuals but I was still unable to
understand what was going on with my dataset
(I had highly statistically significant fixed effects that, looking at
the plots, should not have been statistically
significant imho).


Gabriel




On 4/26/2021 1:54 PM, Phillip Alday wrote:
>
> On 24/4/21 11:08 pm, Ben Bolker wrote:
>>     Don't have much to add to John's comments. You can see
>> vignette("lmerperf") for a few suggestions on improving performance.
>>
>>    I'm a little surprised that your response variable is "logRT" *and*
>> you have a log-link; that seems like double-logging?  (I was going to
>> suggest that if you aren't wedded to the Gamma model, a log-Normal model
>> (lmer(log(logRT) ~ ...) would probably be a lot faster ...)
> Are you (C?tia) basing this model off the Lo and Andrews paper? I'm not
> sure I really agree with that paper -- they seem very worried about
> transformations, but then they use alternative error distributions and
> links, which doesn't help interpretation for many users in my experience.
>
>>    It's possible that other platforms (glmmTMB, Julia::MixedModels.jl)
>> would be faster ... but then you might be stuck without influence
>> diagnostics again ...
>>
> We don't have influence currently implemented in MixedModels.jl, but
> that wouldn't actually be hard. The bigger issue is that GLMMs with a
> dispersion parameter, including Gamma, don't currently work in
> MixedModels.jl
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> .


--
---------------------------------------------------------------------
Gabriel Baud-Bovy               tel.: (+39) 348 172 4045     (mobile)
UHSR University                       (+39) 02 2643 3429 (laboratory)
via Olgettina, 58                     (+39) 02 9175 1540  (secretary)
20132 Milan, Italy              email:       gabriel.baud-bovy at hsr.it
---------------------------------------------------------------------

[https://www.5xmille.org/images/img_01.png]<https://www.5xmille.org/?utm_source=firmamail&utm_medium=email&utm_campaign=5xmille2021>

CODICE FISCALE 07636600962
Scopri di pi? su www.5xmille.org<https://www.5xmille.org/?utm_source=firmamail&utm_medium=email&utm_campaign=5xmille2020>


Rispetta l?ambiente: non stampare questa mail se non ? necessario.
Respect the environment: print this email only if necessary.


From b|e|||@@|e@@@ndr@ @end|ng |rom gm@||@com  Mon Jun  7 01:21:13 2021
From: b|e|||@@|e@@@ndr@ @end|ng |rom gm@||@com (Alessandra Bielli)
Date: Sun, 6 Jun 2021 17:21:13 -0600
Subject: [R-sig-ME] model selection methodology
Message-ID: <CA+6N3yVZW5r+MNvNgV1HhO-hLZQSLrHG04P+K0svQAK33U3jiQ@mail.gmail.com>

Dear List,

I am writing this here because I am using glmmTMB to run a zero inflated
model, but the question is possibly more general, so please feel free to
redirect me to another list/help page.

I want to test whether a treatment (a) has an effect on a
dependent variable (y), so I built a full model :

m1 <- glmmTMB(y ~ a + offset(log(b)) + (1|ID), data=x, ziformula =  ~ a,
              family="poisson")

I used the dredge function to generate a model selection table and the top
model did not include the treatment (a) in the conditional model nor in the
ZI model.

My usual way to proceed is to run diagnostics for the selected model and
conclude that the effect of treatment on my dependent variable is not
statistically significant.

My questions are:
1- is this the right way to proceed or should I check the diagnostics plots
BEFORE model selection?
2- it has happened to me that, while the full model converged, the reduced
model gave a convergence warning message. Considering that my only goal was
to test whether the effect of treatment was significant or not, how would
the convergence issue influence my conclusions?

I feel like these are very basic questions but very important because I do
not want to draw wrong conclusions. Thanks,

Alessandra

	[[alternative HTML version deleted]]


From ALLENF @end|ng |rom cc|@org  Sat Jun  5 05:57:52 2021
From: ALLENF @end|ng |rom cc|@org (Allen, Frederick)
Date: Sat, 5 Jun 2021 03:57:52 +0000
Subject: [R-sig-ME] Question regarding updates or changes to lme4 package
Message-ID: <MWHPR03MB2430444E45B5643A72A98AFDC43A9@MWHPR03MB2430.namprd03.prod.outlook.com>

Hello,

I hope this email finds you well! I have a question with regard to the lme4 package (which I was told to redirect to this address). What, if any updates have been made to the package in the past six months to one year? Were any changes made to the package (or, if you know of any, to the imported packages) that would affect how p-values are calculated? (I looked at lme4 news but didn't find anything that I thought would explain my issue below.)

The reason I ask is this: about 9 months ago, I constructed linear effects models (plural, because we do this over a thousand times to analyze individual entities for -omics data) with and without a continuous independent (fixed) variable and with and without a categorical independent (fixed) variable to determine their contribution to a model for the dependent variable. At the time, we extracted coefficients from the model, as well as calculated p-values for contribution of each variable to the model.

When I repeat this analysis today with the same code and the same data, the coefficients and p-values for the categorical variable are exactly the same to the sixth decimal point (with occasional differences beyond the sixth decimal point). However, for the continuous variable, the coefficients are exactly the same, but the p-values are entirely different.

Of note, our workflow to extract p-values is as follows:

models.with <- dlply(data, "groups", function(df) lmer(Independent ~ categorical + continous + (1|random), data=df, REML = FALSE))
models.without <- dlply(data, "groups", function(df) lmer(Independent ~ categorical + (1|random), data=df, REML = FALSE))
object1 <- mapply(x=model.without, y=model.with, function(x,y) anova(x,y))

I would send an example with data, but I have no way of reproducing the old p-values I got.

Thank you for your help!
-Fred


Please consider the environment before printing this e-mail

Cleveland Clinic is currently ranked as the No. 2 hospital in the country by U.S. News & World Report (2017-2018). Visit us online at http://www.clevelandclinic.org for a complete listing of our services, staff and locations. Confidentiality Note: This message is intended for use only by the individual or entity to which it is addressed and may contain information that is privileged, confidential, and exempt from disclosure under applicable law. If the reader of this message is not the intended recipient or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any dissemination, distribution or copying of this communication is strictly prohibited. If you have received this communication in error, please contact the sender immediately and destroy the material in its entirety, whether electronic or hard copy. Thank you.

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Sun Jun  6 20:00:02 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sun, 6 Jun 2021 14:00:02 -0400
Subject: [R-sig-ME] 
 Question regarding updates or changes to lme4 package
In-Reply-To: <MWHPR03MB2430444E45B5643A72A98AFDC43A9@MWHPR03MB2430.namprd03.prod.outlook.com>
References: <MWHPR03MB2430444E45B5643A72A98AFDC43A9@MWHPR03MB2430.namprd03.prod.outlook.com>
Message-ID: <ae4206e1-ceb5-cde8-77a5-0024dc6c1975@gmail.com>


   A few quick thoughts.

   If you gave an example with data someone who was knowledgeable and 
motivated could try this out with an older version of lme4 to see if the 
results changed (e.g. by checking out an old commit from the GitHub 
repository and installing it).

  The 'snapshot' package allows you to install old versions of packages 
(specifying a target date) from Microsoft's archival-mirror of CRAN 
(MRAN), this would be another (easier) way to check for differences 
depending on lme4 changes.

   This kind of problem is a good argument for  using frameworks like 
the 'packrat' or 'renv' packages to manage the package 
versions/dependencies used in your analyses.

   All of the changes that the maintainers think could affect results 
are listed in the NEWS file; *all* of the changes are listed in the 
commit history of the GitHub repository.  I think it's a very long shot, 
but there have been (1) minor changes to anova() and (2) possibly some 
changes to the environments in which some objects are evaluated 
[although IIRC these changes were actually reverted because they caused 
problems in some downstream packages].

   My *best* guess is that the differences might come from whether or 
not you had the lmerTest package loaded; the lmerTest package changes 
the behaviour of some functions in a generally useful but 
not-always-transparent way ...

    cheers
      Ben Bolker




On 6/4/21 11:57 PM, Allen, Frederick wrote:
> Hello,
> 
> I hope this email finds you well! I have a question with regard to the lme4 package (which I was told to redirect to this address). What, if any updates have been made to the package in the past six months to one year? Were any changes made to the package (or, if you know of any, to the imported packages) that would affect how p-values are calculated? (I looked at lme4 news but didn't find anything that I thought would explain my issue below.)
> 
> The reason I ask is this: about 9 months ago, I constructed linear effects models (plural, because we do this over a thousand times to analyze individual entities for -omics data) with and without a continuous independent (fixed) variable and with and without a categorical independent (fixed) variable to determine their contribution to a model for the dependent variable. At the time, we extracted coefficients from the model, as well as calculated p-values for contribution of each variable to the model.
> 
> When I repeat this analysis today with the same code and the same data, the coefficients and p-values for the categorical variable are exactly the same to the sixth decimal point (with occasional differences beyond the sixth decimal point). However, for the continuous variable, the coefficients are exactly the same, but the p-values are entirely different.
> 
> Of note, our workflow to extract p-values is as follows:
> 
> models.with <- dlply(data, "groups", function(df) lmer(Independent ~ categorical + continous + (1|random), data=df, REML = FALSE))
> models.without <- dlply(data, "groups", function(df) lmer(Independent ~ categorical + (1|random), data=df, REML = FALSE))
> object1 <- mapply(x=model.without, y=model.with, function(x,y) anova(x,y))
> 
> I would send an example with data, but I have no way of reproducing the old p-values I got.
> 
> Thank you for your help!
> -Fred
> 
> 
> Please consider the environment before printing this e-mail
> 
> Cleveland Clinic is currently ranked as the No. 2 hospital in the country by U.S. News & World Report (2017-2018). Visit us online at http://www.clevelandclinic.org for a complete listing of our services, staff and locations. Confidentiality Note: This message is intended for use only by the individual or entity to which it is addressed and may contain information that is privileged, confidential, and exempt from disclosure under applicable law. If the reader of this message is not the intended recipient or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any dissemination, distribution or copying of this communication is strictly prohibited. If you have received this communication in error, please contact the sender immediately and destroy the material in its entirety, whether electronic or hard copy. Thank you.
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From dmb@te@ @end|ng |rom gm@||@com  Mon Jun  7 17:09:49 2021
From: dmb@te@ @end|ng |rom gm@||@com (Douglas Bates)
Date: Mon, 7 Jun 2021 10:09:49 -0500
Subject: [R-sig-ME] Relationship between mixed-effects models and
 fixed-effects models
Message-ID: <CAO7JsnTnnzXkXYHjoUGOk0kxmE1FWL0O-aZi1qW_AQxoD2zCgQ@mail.gmail.com>

Occasionally I encounter discussions of what are called fixed-effects
models in econometrics but I haven't seen descriptions of the underlying
statistical model.  Can anyone point me to a description of these models,
in particular a description in terms of a probability distribution of the
response? I would be particularly interested in a discussion of how they
relate to mixed-effects models as we think of them in lme4 and nlme.

	[[alternative HTML version deleted]]


From jepu@to @end|ng |rom gm@||@com  Mon Jun  7 17:26:27 2021
From: jepu@to @end|ng |rom gm@||@com (James Pustejovsky)
Date: Mon, 7 Jun 2021 10:26:27 -0500
Subject: [R-sig-ME] Relationship between mixed-effects models and
 fixed-effects models
In-Reply-To: <CAO7JsnTnnzXkXYHjoUGOk0kxmE1FWL0O-aZi1qW_AQxoD2zCgQ@mail.gmail.com>
References: <CAO7JsnTnnzXkXYHjoUGOk0kxmE1FWL0O-aZi1qW_AQxoD2zCgQ@mail.gmail.com>
Message-ID: <CAFUVuJzVMwLTD4dyR7wywfn2mzdmok6JCX8x-RHbF=itaKNmaw@mail.gmail.com>

Here's a good primer:

McNeish, D., & Kelley, K. (2019). Fixed effects models versus mixed effects
models for clustered data: Reviewing the approaches, disentangling the
differences, and making recommendations. *Psychological Methods*, *24*(1),
20.
https://www3.nd.edu/~kkelley/publications/articles/McNeish_Kelley_PsychMethods_2019.pdf

The challenge in these discussions is that econometricians use fixed
effects semi-parametrically, by specifying a *minimal* set of assumptions
regarding the conditional mean of the response (given the observed
predictors and the cluster-specific intercepts) and dependence structure.
Thus, many of the discussions will avoid writing down full probability
distributions. Another challenge is that econometricians tend to be worried
about confounding and dependence between the distribution of the predictors
and the distribution of the cluster-specific intercepts.

On Mon, Jun 7, 2021 at 10:14 AM Douglas Bates <dmbates at gmail.com> wrote:

> Occasionally I encounter discussions of what are called fixed-effects
> models in econometrics but I haven't seen descriptions of the underlying
> statistical model.  Can anyone point me to a description of these models,
> in particular a description in terms of a probability distribution of the
> response? I would be particularly interested in a discussion of how they
> relate to mixed-effects models as we think of them in lme4 and nlme.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From me @end|ng |rom ph||||p@|d@y@com  Mon Jun  7 17:27:22 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Mon, 7 Jun 2021 10:27:22 -0500
Subject: [R-sig-ME] Relationship between mixed-effects models and
 fixed-effects models
In-Reply-To: <CAO7JsnTnnzXkXYHjoUGOk0kxmE1FWL0O-aZi1qW_AQxoD2zCgQ@mail.gmail.com>
References: <CAO7JsnTnnzXkXYHjoUGOk0kxmE1FWL0O-aZi1qW_AQxoD2zCgQ@mail.gmail.com>
Message-ID: <27fda3d1-03dd-aa87-a1b8-01c03809ae7d@phillipalday.com>

If I understand correctly, "fixed effects" in econometrics are simply
categorical variables, especially ones with a large number of levels.
There are "fixed" in the sense that they are observed at fixed
(discrete) levels instead of as continuously.

I don't have access to my copy at the moment, but this is discussed in
Gelman & Hill (2006).

Phillip

On 07/06/2021 10:09, Douglas Bates wrote:
> Occasionally I encounter discussions of what are called fixed-effects
> models in econometrics but I haven't seen descriptions of the underlying
> statistical model.  Can anyone point me to a description of these models,
> in particular a description in terms of a probability distribution of the
> response? I would be particularly interested in a discussion of how they
> relate to mixed-effects models as we think of them in lme4 and nlme.
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From me @end|ng |rom ph||||p@|d@y@com  Mon Jun  7 17:30:44 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Mon, 7 Jun 2021 10:30:44 -0500
Subject: [R-sig-ME] Relationship between mixed-effects models and
 fixed-effects models
In-Reply-To: <27fda3d1-03dd-aa87-a1b8-01c03809ae7d@phillipalday.com>
References: <CAO7JsnTnnzXkXYHjoUGOk0kxmE1FWL0O-aZi1qW_AQxoD2zCgQ@mail.gmail.com>
 <27fda3d1-03dd-aa87-a1b8-01c03809ae7d@phillipalday.com>
Message-ID: <6e8d8456-504a-17f0-14f8-728f38cad75e@phillipalday.com>

Somewhat related to this and what James wrote, in the world of fMRI and
other two-stage analyses in psychology and neuroscience, the "fixed
effect" vs "random effect" distinction is used in the same sense as in
meta-analysis, which lines up more closely with the use in mixed models,
i.e. whether or not the individual estimates are treated as observed
draws from a random variable in the group-level analysis.

On 07/06/2021 10:27, Phillip Alday wrote:
> If I understand correctly, "fixed effects" in econometrics are simply
> categorical variables, especially ones with a large number of levels.
> There are "fixed" in the sense that they are observed at fixed
> (discrete) levels instead of as continuously.
>
> I don't have access to my copy at the moment, but this is discussed in
> Gelman & Hill (2006).
>
> Phillip
>
> On 07/06/2021 10:09, Douglas Bates wrote:
>> Occasionally I encounter discussions of what are called fixed-effects
>> models in econometrics but I haven't seen descriptions of the underlying
>> statistical model.  Can anyone point me to a description of these models,
>> in particular a description in terms of a probability distribution of the
>> response? I would be particularly interested in a discussion of how they
>> relate to mixed-effects models as we think of them in lme4 and nlme.
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From me @end|ng |rom ph||||p@|d@y@com  Mon Jun  7 17:40:39 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Mon, 7 Jun 2021 10:40:39 -0500
Subject: [R-sig-ME] Relationship between mixed-effects models and
 fixed-effects models
In-Reply-To: <6e8d8456-504a-17f0-14f8-728f38cad75e@phillipalday.com>
References: <CAO7JsnTnnzXkXYHjoUGOk0kxmE1FWL0O-aZi1qW_AQxoD2zCgQ@mail.gmail.com>
 <27fda3d1-03dd-aa87-a1b8-01c03809ae7d@phillipalday.com>
 <6e8d8456-504a-17f0-14f8-728f38cad75e@phillipalday.com>
Message-ID: <f01bf276-712a-11c2-85bd-72fd11d21001@phillipalday.com>

And the relevant page is on Google Books:

https://www.google.com/books/edition/Data_Analysis_Using_Regression_and_Multi/lV3DIdV0F9AC?hl=en&gbpv=1&dq=gelman%20hill&pg=PA245&printsec=frontcover

This matches up with both my and James' comments.


On 07/06/2021 10:30, Phillip Alday wrote:
> Somewhat related to this and what James wrote, in the world of fMRI and
> other two-stage analyses in psychology and neuroscience, the "fixed
> effect" vs "random effect" distinction is used in the same sense as in
> meta-analysis, which lines up more closely with the use in mixed models,
> i.e. whether or not the individual estimates are treated as observed
> draws from a random variable in the group-level analysis.
>
> On 07/06/2021 10:27, Phillip Alday wrote:
>> If I understand correctly, "fixed effects" in econometrics are simply
>> categorical variables, especially ones with a large number of levels.
>> There are "fixed" in the sense that they are observed at fixed
>> (discrete) levels instead of as continuously.
>>
>> I don't have access to my copy at the moment, but this is discussed in
>> Gelman & Hill (2006).
>>
>> Phillip
>>
>> On 07/06/2021 10:09, Douglas Bates wrote:
>>> Occasionally I encounter discussions of what are called fixed-effects
>>> models in econometrics but I haven't seen descriptions of the underlying
>>> statistical model.  Can anyone point me to a description of these models,
>>> in particular a description in terms of a probability distribution of the
>>> response? I would be particularly interested in a discussion of how they
>>> relate to mixed-effects models as we think of them in lme4 and nlme.
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From d@|uedecke @end|ng |rom uke@de  Mon Jun  7 21:07:54 2021
From: d@|uedecke @end|ng |rom uke@de (=?iso-8859-1?Q?Daniel_L=FCdecke?=)
Date: Mon, 7 Jun 2021 21:07:54 +0200
Subject: [R-sig-ME] Relationship between mixed-effects models and
 fixed-effects models
In-Reply-To: <CAO7JsnTnnzXkXYHjoUGOk0kxmE1FWL0O-aZi1qW_AQxoD2zCgQ@mail.gmail.com>
References: <CAO7JsnTnnzXkXYHjoUGOk0kxmE1FWL0O-aZi1qW_AQxoD2zCgQ@mail.gmail.com>
Message-ID: <001201d75bd0$6c0103d0$44030b70$@uke.de>

I think FE (fixed effects) models are used in particular in panel data or
longitudinal data analysis, when time varying predictors are included, e.g.
"income". Income has a between-subject effect (we have higher- and
lower-income groups) and a within-subject effect (income of person A can
increase over time, while it can decrease for person B - no matter, if A or
B belong to low- or high-income groups!).

The arguments from a FE perspective against mixed models is that you cannot
include "income" as predictor, because income has an effect on both
individual level (within) and higher levels (between), i.e. it would
introduce correlated error terms between the fixed effects and random
effects, which violates model assumptions. The solution is now to "demean"
the "income" variable and only include the within-effect, i.e. the time
varying component in the model. All between effects, and in general all
predictors that could be seen as "between" effects (gender, education, ...)
have to be omitted from the model. The group-level variation (e.g.
"subject", or whatever would be the group factor in mixed models) is
included as normal predictor.

So, a FE model is a classical linear model, where
- Intercept is removed
- time-invariant predictors are not allowed to be included
- the group-level factor is included as predictor
- time-varying predictors are de-meaned (?person-mean centered?, indicating
the ?within-subject? effect)

However, in particular Bell et al. [1, 2] have shown that the "demeaning"
trick also applies to mixed models, so that essentially, mixed models are
probably much better for panel data / longitudinal data analysis. You may be
interested in this vignette, describing the issue and comparing FE to mixed
models: https://easystats.github.io/parameters/articles/demean.html

There are some newer developments, like fixed effects individual slope
models (package feisr), or the panelr package (fun fact: which uses lme4 to
fit flexible models for panel data, so these models are actually mixed
models, no classical FE models).

Best
Daniel

1) Bell, Andrew, Malcolm Fairbrother, and Kelvyn Jones. 2019. ?Fixed and
Random Effects Models: Making an Informed Choice.? Quality & Quantity 53:
1051?74. https://doi.org/10.1007/s11135-018-0802-x.

2) Bell, Andrew, and Kelvyn Jones. 2015. ?Explaining Fixed Effects: Random
Effects Modeling of Time-Series Cross-Sectional and Panel Data.? Political
Science Research and Methods 3 (1): 133?53.
https://doi.org/10.1017/psrm.2014.7.

-----Urspr?ngliche Nachricht-----
Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Im
Auftrag von Douglas Bates
Gesendet: Montag, 7. Juni 2021 17:10
An: R-mixed models mailing list <r-sig-mixed-models at r-project.org>
Betreff: [R-sig-ME] Relationship between mixed-effects models and
fixed-effects models

Occasionally I encounter discussions of what are called fixed-effects
models in econometrics but I haven't seen descriptions of the underlying
statistical model.  Can anyone point me to a description of these models,
in particular a description in terms of a probability distribution of the
response? I would be particularly interested in a discussion of how they
relate to mixed-effects models as we think of them in lme4 and nlme.

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Joachim Pr?l?, Prof. Dr. Blanche Schwappach-Pignataro, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING


From jepu@to @end|ng |rom gm@||@com  Mon Jun  7 21:25:38 2021
From: jepu@to @end|ng |rom gm@||@com (James Pustejovsky)
Date: Mon, 7 Jun 2021 14:25:38 -0500
Subject: [R-sig-ME] Relationship between mixed-effects models and
 fixed-effects models
In-Reply-To: <001201d75bd0$6c0103d0$44030b70$@uke.de>
References: <CAO7JsnTnnzXkXYHjoUGOk0kxmE1FWL0O-aZi1qW_AQxoD2zCgQ@mail.gmail.com>
 <001201d75bd0$6c0103d0$44030b70$@uke.de>
Message-ID: <CAFUVuJyRvH9oOVsU3Rnhe=5wqE31qTWAq_pgQNFuVhHS2RBXkQ@mail.gmail.com>

I agree with Daneil's comments. Raudenbush has a very deep article on
generalizations of the de-meaning strategy:

Raudenbush, S. W. (2009). Adaptive centering with random effects: An
alternative to the fixed effects model for studying time-varying treatments
in school settings. *Education Finance and Policy*, *4*(4), 468-491.
https://cpb-us-w2.wpmucdn.com/voices.uchicago.edu/dist/6/1063/files/2018/11/AdaptiveCenterRandom-2009-educfinapoli.4.4.468.R-106edfh.pdf


On Mon, Jun 7, 2021 at 2:08 PM Daniel L?decke <d.luedecke at uke.de> wrote:

> I think FE (fixed effects) models are used in particular in panel data or
> longitudinal data analysis, when time varying predictors are included, e.g.
> "income". Income has a between-subject effect (we have higher- and
> lower-income groups) and a within-subject effect (income of person A can
> increase over time, while it can decrease for person B - no matter, if A or
> B belong to low- or high-income groups!).
>
> The arguments from a FE perspective against mixed models is that you cannot
> include "income" as predictor, because income has an effect on both
> individual level (within) and higher levels (between), i.e. it would
> introduce correlated error terms between the fixed effects and random
> effects, which violates model assumptions. The solution is now to "demean"
> the "income" variable and only include the within-effect, i.e. the time
> varying component in the model. All between effects, and in general all
> predictors that could be seen as "between" effects (gender, education, ...)
> have to be omitted from the model. The group-level variation (e.g.
> "subject", or whatever would be the group factor in mixed models) is
> included as normal predictor.
>
> So, a FE model is a classical linear model, where
> - Intercept is removed
> - time-invariant predictors are not allowed to be included
> - the group-level factor is included as predictor
> - time-varying predictors are de-meaned (?person-mean centered?, indicating
> the ?within-subject? effect)
>
> However, in particular Bell et al. [1, 2] have shown that the "demeaning"
> trick also applies to mixed models, so that essentially, mixed models are
> probably much better for panel data / longitudinal data analysis. You may
> be
> interested in this vignette, describing the issue and comparing FE to mixed
> models: https://easystats.github.io/parameters/articles/demean.html
>
> There are some newer developments, like fixed effects individual slope
> models (package feisr), or the panelr package (fun fact: which uses lme4 to
> fit flexible models for panel data, so these models are actually mixed
> models, no classical FE models).
>
> Best
> Daniel
>
> 1) Bell, Andrew, Malcolm Fairbrother, and Kelvyn Jones. 2019. ?Fixed and
> Random Effects Models: Making an Informed Choice.? Quality & Quantity 53:
> 1051?74. https://doi.org/10.1007/s11135-018-0802-x.
>
> 2) Bell, Andrew, and Kelvyn Jones. 2015. ?Explaining Fixed Effects: Random
> Effects Modeling of Time-Series Cross-Sectional and Panel Data.? Political
> Science Research and Methods 3 (1): 133?53.
> https://doi.org/10.1017/psrm.2014.7.
>
> -----Urspr?ngliche Nachricht-----
> Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Im
> Auftrag von Douglas Bates
> Gesendet: Montag, 7. Juni 2021 17:10
> An: R-mixed models mailing list <r-sig-mixed-models at r-project.org>
> Betreff: [R-sig-ME] Relationship between mixed-effects models and
> fixed-effects models
>
> Occasionally I encounter discussions of what are called fixed-effects
> models in econometrics but I haven't seen descriptions of the underlying
> statistical model.  Can anyone point me to a description of these models,
> in particular a description in terms of a probability distribution of the
> response? I would be particularly interested in a discussion of how they
> relate to mixed-effects models as we think of them in lme4 and nlme.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
>
> _____________________________________________________________________
>
> Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen
> Rechts; Gerichtsstand: Hamburg | www.uke.de
> Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Joachim
> Pr?l?, Prof. Dr. Blanche Schwappach-Pignataro, Marya Verdel
> _____________________________________________________________________
>
> SAVE PAPER - THINK BEFORE PRINTING
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u  Tue Jun  8 08:33:40 2021
From: D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u (David Duffy)
Date: Tue, 8 Jun 2021 06:33:40 +0000
Subject: [R-sig-ME] model selection methodology
In-Reply-To: <CA+6N3yVZW5r+MNvNgV1HhO-hLZQSLrHG04P+K0svQAK33U3jiQ@mail.gmail.com>
References: <CA+6N3yVZW5r+MNvNgV1HhO-hLZQSLrHG04P+K0svQAK33U3jiQ@mail.gmail.com>
Message-ID: <d060006733c247999cf4660f46dfcf52@qimrberghofer.edu.au>

Hi.

I suspect we would need more information. A real or simulated dataset of the correct form would be useful. In fact, if you could generate multiple such 
datasets, you could answer your own question about testing.

> I want to test whether a treatment (a) has an effect 
> on a dependent variable (y), so I built a full model :

> m1 <- glmmTMB(y ~ a + offset(log(b)) + (1|ID), data=x, 
>              ziformula =  ~ a,  family="poisson")

> I used the dredge function to generate a model selection table and the top
> model did not include the treatment (a) in the conditional model nor in the
> ZI model.

So. are there multiple records for each ID, or are you looking at both extra-poisson variation
and zero-inflation?

> My usual way to proceed is to run diagnostics for the selected model and
> conclude that the effect of treatment on my dependent variable is not
> statistically significant.

> My questions are:
> 1- is this the right way to proceed or should I check the diagnostics plots
> BEFORE model selection?
> 2- it has happened to me that, while the full model converged, the reduced
> model gave a convergence warning message. Considering that my only goal was
> to test whether the effect of treatment was significant or not, how would
> the convergence issue influence my conclusions?

> I feel like these are very basic questions but very important because I do
> not want to draw wrong conclusions. Thanks,

Personally, I think these are kind of cutting edge type questions. I would looking at
diagnostics from even simpler models first (say, poisson and quasi-poisson GLM, or hurdle model), and
the same model using a different package (say in STAN with uninformative priors).

From ch|r|com @end|ng |rom goog|e@com  Tue Jun  8 21:19:44 2021
From: ch|r|com @end|ng |rom goog|e@com (Michael Chirico)
Date: Tue, 8 Jun 2021 12:19:44 -0700
Subject: [R-sig-ME] Purpose of .nloptr object?
Message-ID: <CAD7Bkx8+DkvjxufuebYUHS3ZdUQB4nmSzn2W+59NdgP_rkKvmA@mail.gmail.com>

I see this code snippet suggested in the performance vignette:

https://cran.r-project.org/web/packages/lme4/vignettes/lmerperf.html

nlopt <- function(par, fn, lower, upper, control) {
    *.nloptr <<-* res <- nloptr(par, fn, lb = lower, ub = upper,
        opts = list(algorithm = "NLOPT_LN_BOBYQA", print_level = 1,
        maxeval = 1000, xtol_abs = 1e-6, ftol_abs = 1e-6))
    list(par = res$solution,
         fval = res$objective,
         conv = if (res$status > 0) 0 else res$status,
         message = res$message
    )
}

That's writing an .nloptr object to .GlobalEnv (usually), but there's no
mention of why and I don't see any usage of this object anywhere else in
the code base:

grep -Fr ".nloptr" lme4/R

Am I missing something?
Mike C

	[[alternative HTML version deleted]]


From me @end|ng |rom ph||||p@|d@y@com  Wed Jun  9 01:47:59 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Tue, 8 Jun 2021 18:47:59 -0500
Subject: [R-sig-ME] Purpose of .nloptr object?
In-Reply-To: <CAD7Bkx8+DkvjxufuebYUHS3ZdUQB4nmSzn2W+59NdgP_rkKvmA@mail.gmail.com>
References: <CAD7Bkx8+DkvjxufuebYUHS3ZdUQB4nmSzn2W+59NdgP_rkKvmA@mail.gmail.com>
Message-ID: <e8ac6489-aff3-77d4-2cb4-be322019259b@phillipalday.com>

This seems to be the docs getting slightly out of date in some sections
(as happens with any big piece of software). The actual nloptwrap
function in lme4 (now the default optimizer, IIRC) doesn't include that:

https://github.com/lme4/lme4/blob/c3d0c643d444785fad5e554380c028706f14e274/R/utilities.R#L1151-L1169

A wild guess on my part (until Ben Bolker has a few): that code was
there to debug writing a wrapper / show how you can further examine the
return value from nloptr to get more information and got left in, even
once the further debugging/examination was removed from the example.


Phillip

On 08/06/2021 14:19, Michael Chirico via R-sig-mixed-models wrote:
> I see this code snippet suggested in the performance vignette:
>
> https://cran.r-project.org/web/packages/lme4/vignettes/lmerperf.html
>
> nlopt <- function(par, fn, lower, upper, control) {
>     *.nloptr <<-* res <- nloptr(par, fn, lb = lower, ub = upper,
>         opts = list(algorithm = "NLOPT_LN_BOBYQA", print_level = 1,
>         maxeval = 1000, xtol_abs = 1e-6, ftol_abs = 1e-6))
>     list(par = res$solution,
>          fval = res$objective,
>          conv = if (res$status > 0) 0 else res$status,
>          message = res$message
>     )
> }
>
> That's writing an .nloptr object to .GlobalEnv (usually), but there's no
> mention of why and I don't see any usage of this object anywhere else in
> the code base:
>
> grep -Fr ".nloptr" lme4/R
>
> Am I missing something?
> Mike C
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbo|ker @end|ng |rom gm@||@com  Wed Jun  9 03:58:19 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 8 Jun 2021 21:58:19 -0400
Subject: [R-sig-ME] Purpose of .nloptr object?
In-Reply-To: <e8ac6489-aff3-77d4-2cb4-be322019259b@phillipalday.com>
References: <CAD7Bkx8+DkvjxufuebYUHS3ZdUQB4nmSzn2W+59NdgP_rkKvmA@mail.gmail.com>
 <e8ac6489-aff3-77d4-2cb4-be322019259b@phillipalday.com>
Message-ID: <89beccd7-edfd-8986-c3dc-5ad07251a675@gmail.com>

    Yes, that's probably it.
   I should look into updating that vignette anyway (it would be good to 
run the machinery and cache some timings to be included in the text).

   cheers
    Ben

On 6/8/21 7:47 PM, Phillip Alday wrote:
> This seems to be the docs getting slightly out of date in some sections
> (as happens with any big piece of software). The actual nloptwrap
> function in lme4 (now the default optimizer, IIRC) doesn't include that:
> 
> https://github.com/lme4/lme4/blob/c3d0c643d444785fad5e554380c028706f14e274/R/utilities.R#L1151-L1169
> 
> A wild guess on my part (until Ben Bolker has a few): that code was
> there to debug writing a wrapper / show how you can further examine the
> return value from nloptr to get more information and got left in, even
> once the further debugging/examination was removed from the example.
> 
> 
> Phillip
> 
> On 08/06/2021 14:19, Michael Chirico via R-sig-mixed-models wrote:
>> I see this code snippet suggested in the performance vignette:
>>
>> https://cran.r-project.org/web/packages/lme4/vignettes/lmerperf.html
>>
>> nlopt <- function(par, fn, lower, upper, control) {
>>      *.nloptr <<-* res <- nloptr(par, fn, lb = lower, ub = upper,
>>          opts = list(algorithm = "NLOPT_LN_BOBYQA", print_level = 1,
>>          maxeval = 1000, xtol_abs = 1e-6, ftol_abs = 1e-6))
>>      list(par = res$solution,
>>           fval = res$objective,
>>           conv = if (res$status > 0) 0 else res$status,
>>           message = res$message
>>      )
>> }
>>
>> That's writing an .nloptr object to .GlobalEnv (usually), but there's no
>> mention of why and I don't see any usage of this object anywhere else in
>> the code base:
>>
>> grep -Fr ".nloptr" lme4/R
>>
>> Am I missing something?
>> Mike C
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From @pr||m@rt|n|g @end|ng |rom hotm@||@com  Mon Jun 14 23:14:26 2021
From: @pr||m@rt|n|g @end|ng |rom hotm@||@com (April Martinig)
Date: Mon, 14 Jun 2021 15:14:26 -0600
Subject: [R-sig-ME] parameter expanded inverse Wishart prior for MCMCglmm
 multivariate model
Message-ID: <CY4PR17MB1000A6DD3500F662460D8E4FAA319@CY4PR17MB1000.namprd17.prod.outlook.com>

Hello,

I am using MCMCglmm to run a multivariate model (4 response variables) with two random effect terms. I am particularly interested in the among- and within-individual correlations.

I posted my original question on Stack Overflow (https://stackoverflow.com/questions/67941391/how-to-properly-code-a-scaled-inverse-wishart-prior-for-a-mcmcglmm-model?noredirect=1#comment120089208_67941391) and received a very helpful answer. 

To expand on that question, what is the correct format for a parameter expanded inverse Wishart prior?

The prior as I currently have it:

prior.miw<-list(R=list(V=diag(4), nu=1), 
                G=list(G1=list(V=diag(4), 
                nu=1,   
                alpha.mu=c(0,0,0,0), 
                alpha.V=diag(4)*1000),
                G2=list(V=diag(4), #need to repeat to deal with second random effect
                nu=1,   
                alpha.mu=c(0,0,0,0), 
                alpha.V=diag(4)*1000)))

Also, how do I know if 1000 is an appropriate scale for my alpha.V? I understand that it should be large, but I am not sure if this is also appropriate.

Take care,
April Martinig


	[[alternative HTML version deleted]]


From dunc@nj@ck@on @end|ng |rom gm@||@com  Fri Jun 18 08:24:22 2021
From: dunc@nj@ck@on @end|ng |rom gm@||@com (Duncan Jackson)
Date: Fri, 18 Jun 2021 07:24:22 +0100
Subject: [R-sig-ME] Fixed effects in lmer()
Message-ID: <CALjBeZT_jHT-YmMHVMEdyNZGFv5aAGXW=F=X2WWY5R_EnJENsg@mail.gmail.com>

Hi everyone.
I have some questions about lmer() and I'm wondering if you might be able
to help me out.
I?ve run a mixed-model in lmer() including multiple random effects and a
fixed effect.  I?ve noticed that if I run a comparison simple regression
model with no random effects but the same fixed effect, I get precisely the
same unstandardised beta coefficient for my fixed effect in the simple
regression as I get if I run the mixed model.
Am I correct in thinking, therefore, that the beta coefficients generated
in the mixed model in lmer() do not control for the random effects in the
model?  Would it make a difference in this respect if participants in my
dataset were nested in a random effect?  Also, how does one summarise
an overall R square value for the impact of a set of fixed effects in a
mixed model with lmer()?
On another note, I was wondering if there were any more recent suggestions
about how to handle random effects in REML-based models using lmer() that
are fenced at zero.  Is it possible that alternative optimizers might
assist in this respect?  One issue I find when comparing lmer() with
Bayesian estimators is that the difficulties in this respect often appear
to arise with very small effects (i.e., those that approach near-zero
variance estimates).
Looking forward to hearing your thoughts.
Kind regards,
Duncan

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Fri Jun 18 09:54:16 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Fri, 18 Jun 2021 09:54:16 +0200
Subject: [R-sig-ME] Fixed effects in lmer()
In-Reply-To: <CALjBeZT_jHT-YmMHVMEdyNZGFv5aAGXW=F=X2WWY5R_EnJENsg@mail.gmail.com>
References: <CALjBeZT_jHT-YmMHVMEdyNZGFv5aAGXW=F=X2WWY5R_EnJENsg@mail.gmail.com>
Message-ID: <CAJuCY5w42Ky2TQHv01NrwOF3sCix+W0PUEt=VxD=PtvP7Ww4Bg@mail.gmail.com>

Dear Duncan,

If the random effects only explain the noise of the linear regression, then
you could get similar fixed effect estimates. The summary of both models
would be useful.

IMHO R? has only a clear definition under very special conditions: a linear
regression with Gaussian distribution and without random effects.
Unfortunately, as people start learning statistics with this kind of model,
they assume that other models have the same properties. You could do an LRT
between models with and without the set of fixed effects.

Are you referring to non-negative random effects? The lmer random effects
assume a zero mean normal distribution. Which implies the possibility of
negative numbers.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op vr 18 jun. 2021 om 08:24 schreef Duncan Jackson <duncanjackson at gmail.com
>:

> Hi everyone.
> I have some questions about lmer() and I'm wondering if you might be able
> to help me out.
> I?ve run a mixed-model in lmer() including multiple random effects and a
> fixed effect.  I?ve noticed that if I run a comparison simple regression
> model with no random effects but the same fixed effect, I get precisely the
> same unstandardised beta coefficient for my fixed effect in the simple
> regression as I get if I run the mixed model.
> Am I correct in thinking, therefore, that the beta coefficients generated
> in the mixed model in lmer() do not control for the random effects in the
> model?  Would it make a difference in this respect if participants in my
> dataset were nested in a random effect?  Also, how does one summarise
> an overall R square value for the impact of a set of fixed effects in a
> mixed model with lmer()?
> On another note, I was wondering if there were any more recent suggestions
> about how to handle random effects in REML-based models using lmer() that
> are fenced at zero.  Is it possible that alternative optimizers might
> assist in this respect?  One issue I find when comparing lmer() with
> Bayesian estimators is that the difficulties in this respect often appear
> to arise with very small effects (i.e., those that approach near-zero
> variance estimates).
> Looking forward to hearing your thoughts.
> Kind regards,
> Duncan
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From ebhod@ghe|@|th @end|ng |rom gm@||@com  Fri Jun 18 10:10:29 2021
From: ebhod@ghe|@|th @end|ng |rom gm@||@com (Ebhodaghe Faith)
Date: Fri, 18 Jun 2021 01:10:29 -0700
Subject: [R-sig-ME] Question on glmmTMB
Message-ID: <CAEatWUoG24rGuWvVGTCv9-2e28ayXFCTG-WsHZsoKsV79Z3a0A@mail.gmail.com>

Dear All,

The glmmTMB package is used to model data with mixed effects. For example:

glmmTMB(count~spp + mined + (1|site), Salamanders, family=nbinom2)

But I'm just curious to know what happens when the package is used to model
data without random effects (will this still be fine? How does this compare
with just using the glm function in the MASS package?). See example below:

glmmTMB(count~spp + mined, Salamanders, family=nbinom2)

With kind regards,
Faith

	[[alternative HTML version deleted]]


From pr|db @end|ng |rom protonm@||@com  Fri Jun 18 21:52:28 2021
From: pr|db @end|ng |rom protonm@||@com (Peter R Law)
Date: Fri, 18 Jun 2021 19:52:28 +0000
Subject: [R-sig-ME] Fw: glmer and nAGQ
In-Reply-To: <IaPuZYIQ_b0xc3TiOKKB7qUSl_oIrJs3qAAhv0FzcMEmNLhnqVk2YTt7MujmZrjXeK2HmDlukIhdfOYOzYtSACRBseVXSGHWX01pVwXM3IA=@protonmail.com>
References: <IaPuZYIQ_b0xc3TiOKKB7qUSl_oIrJs3qAAhv0FzcMEmNLhnqVk2YTt7MujmZrjXeK2HmDlukIhdfOYOzYtSACRBseVXSGHWX01pVwXM3IA=@protonmail.com>
Message-ID: <eRi5lAvI3CZFpoVa8IsTe5tGL_XcunhS6SO19GpY3rHle2EAxwTwqPoXdjNc08xqm-V6bHJFOWwEMh5uGETjT0_tZXZjbp_wVZ02j2HtckI=@protonmail.com>

I am re-sending this query that I originally emailed June 13'th. I did not receive a copy of the sent email as I have with previous postings and my query doesn't appear in the archive of postings so does not seem to have been received.

Peter R Law

Sent with [ProtonMail](https://protonmail.com/) Secure Email.

??????? Original Message ???????
On Monday, June 14th, 2021 at 10:48 PM, Peter R Law <prldb at protonmail.com> wrote:

> Any help with the following query is much appreciated.
>
> I used some simulated data (not generated under any specific distributional assumption but all responses are positive quantities) to investigate the nAGQ argument in glmer, running a Gamma-distribution model. With nAAGQ=2 the logLik is dramatically different to the default value of nAGQ=1, while nAGQ=5 returned minus infinity for the logLik, but the estimates of the fixed effect parameters are somewhat consistent across each computation. Are the differences in the estimated logLik surprising or do they reflect the warnings glmer returns for this attempted modelling? I got similar results for a real dataset too.
>
> data.frame':500 obs. of8 variables:
>
> $ IBI: num25.5 25.4 25.2 25.6 25.8 ...
>
> $ MatID: Factor w/ 99 levels "M1","M10","M11",..: 1 1 1 1 1 12 12 12 12 12 ...
>
> $ Pop: Factor w/ 5 levels "P1","P2","P3",..: 1 1 1 1 1 1 1 1 1 1 ...
>
> $ density : int11 13 15 19 28 11 13 15 19 28 ...
>
> $ rain: num41.1 36.6 31.6 40 40.6 ...
>
> $ normIBI : num-1.28 -1.29 -1.31 -1.26 -1.24 ...
>
> $ normDens: num-1.72 -1.66 -1.61 -1.49 -1.23 ...
>
> $ normRain: num-0.249 -0.64 -1.073 -0.345 -0.287 ...
>
>> M61 <- glmer(IBI~normDens+normRain + (1|MatID), family=Gamma, data=Sim)
>
> Warning message:
>
> In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,:
>
> Model is nearly unidentifiable: very large eigenvalue
>
> - Rescale variables?
>
>> summary(M61)
>
> Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
>
> Family: Gamma( inverse )
>
> Formula: IBI ~ normDens + normRain + (1 | MatID)
>
> Data: Sim
>
> AICBIClogLik deviance df.resid
>
> 1297.61318.7-643.81287.6495
>
> Scaled residuals:
>
> Min1QMedian3QMax
>
> -1.58054 -0.306190.041690.367441.31012
>
> Random effects:
>
> GroupsNameVarianceStd.Dev.
>
> MatID(Intercept) 5.802e-06 0.002409
>
> Residual1.368e-03 0.036989
>
> Number of obs: 500, groups:MatID, 99
>
> Fixed effects:
>
> Estimate Std. Error t value Pr(>|z|)
>
> (Intercept)3.083e-026.090e-0450.63<2e-16 ***
>
> normDens -1.720e-037.946e-05-21.65<2e-16 ***
>
> normRain4.889e-042.463e-0519.85<2e-16 ***
>
> ---
>
> Signif. codes:0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>
> (Intr) nrmDns
>
> normDens0.028
>
> normRain0.000 -0.044
>
> convergence code: 0
>
> Model is nearly unidentifiable: very large eigenvalue
>
> - Rescale variables?
>
> What kind of scaling is being suggested in the case of the default value of nAGQ? The predictors are already normalized.
>
>> M62 <- glmer(IBI~normDens+normRain + (1|MatID), family=Gamma, nAGQ=2,data=Sim)
>
> boundary (singular) fit: see ?isSingular
>
>> summary(M62)
>
> Generalized linear mixed model fit by maximum likelihood (Adaptive Gauss-Hermite Quadrature, nAGQ = 2) ['glmerMod']
>
> Family: Gamma( inverse )
>
> Formula: IBI ~ normDens + normRain + (1 | MatID)
>
> Data: Sim
>
> AICBIClogLik deviance df.resid
>
> 21.742.8-5.911.7495
>
> Scaled residuals:
>
> Min1QMedian3QMax
>
> -2.3532 -0.6617 -0.13050.51013.4180
>
> Random effects:
>
> GroupsNameVariance Std.Dev.
>
> MatID(Intercept) 0.000000.0000
>
> Residual0.024160.1554
>
> Number of obs: 500, groups:MatID, 99
>
> Fixed effects:
>
> Estimate Std. Error t value Pr(>|z|)
>
> (Intercept)0.02882820.001300822.161< 2e-16 ***
>
> normDens-0.00392740.0012153-3.2320.00123 **
>
> normRain0.00027830.00129940.2140.83042
>
> ---
>
> Signif. codes:0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>
> (Intr) nrmDns
>
> normDens -0.275
>
> normRain0.019 -0.019
>
> convergence code: 0
>
> boundary (singular) fit: see ?isSingular
>
>> M65 <- glmer(IBI~normDens+normRain + (1|MatID), family=Gamma, nAGQ=5,data=Sim)
>
>> summary(M65)
>
> Generalized linear mixed model fit by maximum likelihood (Adaptive Gauss-Hermite Quadrature, nAGQ = 5) ['glmerMod']
>
> Family: Gamma( inverse )
>
> Formula: IBI ~ normDens + normRain + (1 | MatID)
>
> Data: Sim
>
> AICBIClogLik deviance df.resid
>
> InfInf-InfInf495
>
> Scaled residuals:
>
> Min1QMedian3QMax
>
> -2.2488 -0.39020.03160.34851.7127
>
> Random effects:
>
> GroupsNameVarianceStd.Dev.
>
> MatID(Intercept) 6.007e-06 0.002451
>
> Residual8.831e-04 0.029716
>
> Number of obs: 500, groups:MatID, 99
>
> Fixed effects:
>
> Estimate Std. Error t value Pr(>|z|)
>
> (Intercept)2.936e-022.495e-04117.68<2e-16 ***
>
> normDens-2.182e-031.163e-04-18.76<2e-16 ***
>
> normRain4.883e-043.973e-0512.29<2e-16 ***
>
> ---
>
> Signif. codes:0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>
> (Intr) nrmDns
>
> normDens -0.013
>
> normRain0.004 -0.041
>
> convergence code: 0
>
> Gradient contains NAs
>
> Warning messages:
>
> 1: In vcov.merMod(object, use.hessian = use.hessian) :
>
> variance-covariance matrix computed from finite-difference Hessian is
>
> not positive definite or contains NA values: falling back to var-cov estimated from RX
>
> 2: In vcov.merMod(object, correlation = correlation, sigm = sig) :
>
> variance-covariance matrix computed from finite-difference Hessian is
>
> not positive definite or contains NA values: falling back to var-cov estimated from RX
>
> For comparison, the linear model seems to be well behaved:
>
> M1 <- lmer(IBI~normDens+normRain +(1|MatID), REML=FALSE, data=Sim)
>
>>
>
> summary(M1)
>
> Linear mixed model fit by maximum likelihood
>
> ['lmerMod']
>
> Formula: IBI ~ normDens + normRain + (1 | MatID)
>
> Data: Sim
>
> AIC
>
> BIC
>
> logLik deviance df.resid
>
> 1804.2
>
> 1825.2
>
> -897.1
>
> 1794.2
>
> 495
>
> Scaled residuals:
>
> Min
>
> 1Q
>
> Median
>
> 3Q
>
> Max
>
> -3.2970 -0.5304
>
> 0.0153
>
> 0.5484
>
> 3.4798
>
> Random effects:
>
> Groups
>
> Name
>
> Variance Std.Dev.
>
> MatID
>
> (Intercept) 43.5694
>
> 6.6007
>
> Residual
>
> 0.6737
>
> 0.8208
>
> Number of obs: 500, groups:
>
> MatID, 99
>
> Fixed effects:
>
> Estimate Std. Error t value
>
> (Intercept) 35.47121
>
> 0.66443
>
> 53.39
>
> normDens
>
> 2.00732
>
> 0.11816
>
> 16.99
>
> normRain
>
> -0.71747
>
> 0.04237
>
> -16.93
>
> Correlation of Fixed Effects:
>
> (Intr) nrmDns
>
> normDens -0.002
>
> normRain
>
> 0.000 -0.044
>
> Should I just conclude that the data is not well modelled by a Gamma GLMM?
>
> Peter R Law
> Research Associate
> Center for African Conservation Ecology
> Nelson Mandela University
> South Africa
>
> Sent with [ProtonMail](https://protonmail.com/) Secure Email.
	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Fri Jun 18 23:44:09 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 18 Jun 2021 17:44:09 -0400
Subject: [R-sig-ME] Fw: glmer and nAGQ
In-Reply-To: <eRi5lAvI3CZFpoVa8IsTe5tGL_XcunhS6SO19GpY3rHle2EAxwTwqPoXdjNc08xqm-V6bHJFOWwEMh5uGETjT0_tZXZjbp_wVZ02j2HtckI=@protonmail.com>
References: <IaPuZYIQ_b0xc3TiOKKB7qUSl_oIrJs3qAAhv0FzcMEmNLhnqVk2YTt7MujmZrjXeK2HmDlukIhdfOYOzYtSACRBseVXSGHWX01pVwXM3IA=@protonmail.com>
 <eRi5lAvI3CZFpoVa8IsTe5tGL_XcunhS6SO19GpY3rHle2EAxwTwqPoXdjNc08xqm-V6bHJFOWwEMh5uGETjT0_tZXZjbp_wVZ02j2HtckI=@protonmail.com>
Message-ID: <ecb77626-a725-bb11-eead-9a00e21f71ce@gmail.com>

   This is kind of hard to read, but I'll try.

   First of all, log-likelihoods with nAGQ>1 (adaptive Gauss-Hermite 
quadrature) **are not currently commensurate with log-likelihoods with 
nAGQ==1 (Laplace approximation). This is hinted at in the "Deviance and 
log-likelihood of GLMMs" section under "Deviance and log-likelihood of 
GLMMs".

   In any case, the log-likelihoods computed under different numbers of 
quadrature points aren't comparable as though they were different 
statistical models (AIC, likelihood ratio tests, etc.). Rather, they are 
based on **different approximations** to the same model, and we know 
that larger numbers of quadrature points (increasing nAGQ) are *more 
accurate* (although slower) approximations.  The main thing is to see if 
*results* (parameter estimates etc.) change as nAGQ increases by a 
magnitude that is important for the current analysis ... if they do, 
then you should use an nAGQ that is large enough that it approximates 
"infinity", i.e. increasing nAGQ further doesn't change the answers by 
an important amount.

   In general if it is not important to you to use the inverse link (for 
interpretation/because you think this will be the natural scale on which 
to measure effects of continuous parameters and/or interactions), 
Gamma(link="log") is generally more robust.

   The "rescale variables?" suggestion is just that; if the parameters 
are already rescaled, then it's not going to help.  A large eigenvalue 
may not actually be a problem, it just indicates the *possibility* of 
numerical instability. In this case my guess is that the very small 
random effects variance might be responsible.

  It's also a little surprising that the normRain coefficient is very 
small in magnitude and yet but has a very large Z-statistic, given this 
sample size.

  The results with increasing AGQ do indeed look kind of wonky.  If this 
were my problem I would want to look more carefully at the data/think 
about where they came from.  How do the model diagnostics look?


On 6/18/21 3:52 PM, Peter R Law via R-sig-mixed-models wrote:
> I am re-sending this query that I originally emailed June 13'th. I did not receive a copy of the sent email as I have with previous postings and my query doesn't appear in the archive of postings so does not seem to have been received.
> 
> Peter R Law
> 
> Sent with [ProtonMail](https://protonmail.com/) Secure Email.
> 
> ??????? Original Message ???????
> On Monday, June 14th, 2021 at 10:48 PM, Peter R Law <prldb at protonmail.com> wrote:
> 
>> Any help with the following query is much appreciated.
>>
>> I used some simulated data (not generated under any specific distributional assumption but all responses are positive quantities) to investigate the nAGQ argument in glmer, running a Gamma-distribution model. With nAAGQ=2 the logLik is dramatically different to the default value of nAGQ=1, while nAGQ=5 returned minus infinity for the logLik, but the estimates of the fixed effect parameters are somewhat consistent across each computation. Are the differences in the estimated logLik surprising or do they reflect the warnings glmer returns for this attempted modelling? I got similar results for a real dataset too.
>>
>> data.frame':500 obs. of8 variables:
>>
>> $ IBI: num25.5 25.4 25.2 25.6 25.8 ...
>>
>> $ MatID: Factor w/ 99 levels "M1","M10","M11",..: 1 1 1 1 1 12 12 12 12 12 ...
>>
>> $ Pop: Factor w/ 5 levels "P1","P2","P3",..: 1 1 1 1 1 1 1 1 1 1 ...
>>
>> $ density : int11 13 15 19 28 11 13 15 19 28 ...
>>
>> $ rain: num41.1 36.6 31.6 40 40.6 ...
>>
>> $ normIBI : num-1.28 -1.29 -1.31 -1.26 -1.24 ...
>>
>> $ normDens: num-1.72 -1.66 -1.61 -1.49 -1.23 ...
>>
>> $ normRain: num-0.249 -0.64 -1.073 -0.345 -0.287 ...
>>
>>> M61 <- glmer(IBI~normDens+normRain + (1|MatID), family=Gamma, data=Sim)
>>
>> Warning message:
>>
>> In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,:
>>
>> Model is nearly unidentifiable: very large eigenvalue
>>
>> - Rescale variables?
>>
>>> summary(M61)
>>
>> Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
>>
>> Family: Gamma( inverse )
>>
>> Formula: IBI ~ normDens + normRain + (1 | MatID)
>>
>> Data: Sim
>>
>> AICBIClogLik deviance df.resid
>>
>> 1297.61318.7-643.81287.6495
>>
>> Scaled residuals:
>>
>> Min1QMedian3QMax
>>
>> -1.58054 -0.306190.041690.367441.31012
>>
>> Random effects:
>>
>> GroupsNameVarianceStd.Dev.
>>
>> MatID(Intercept) 5.802e-06 0.002409
>>
>> Residual1.368e-03 0.036989
>>
>> Number of obs: 500, groups:MatID, 99
>>
>> Fixed effects:
>>
>> Estimate Std. Error t value Pr(>|z|)
>>
>> (Intercept)3.083e-026.090e-0450.63<2e-16 ***
>>
>> normDens -1.720e-037.946e-05-21.65<2e-16 ***
>>
>> normRain4.889e-042.463e-0519.85<2e-16 ***
>>
>> ---
>>
>> Signif. codes:0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> Correlation of Fixed Effects:
>>
>> (Intr) nrmDns
>>
>> normDens0.028
>>
>> normRain0.000 -0.044
>>
>> convergence code: 0
>>
>> Model is nearly unidentifiable: very large eigenvalue
>>
>> - Rescale variables?
>>
>> What kind of scaling is being suggested in the case of the default value of nAGQ? The predictors are already normalized.
>>
>>> M62 <- glmer(IBI~normDens+normRain + (1|MatID), family=Gamma, nAGQ=2,data=Sim)
>>
>> boundary (singular) fit: see ?isSingular
>>
>>> summary(M62)
>>
>> Generalized linear mixed model fit by maximum likelihood (Adaptive Gauss-Hermite Quadrature, nAGQ = 2) ['glmerMod']
>>
>> Family: Gamma( inverse )
>>
>> Formula: IBI ~ normDens + normRain + (1 | MatID)
>>
>> Data: Sim
>>
>> AICBIClogLik deviance df.resid
>>
>> 21.742.8-5.911.7495
>>
>> Scaled residuals:
>>
>> Min1QMedian3QMax
>>
>> -2.3532 -0.6617 -0.13050.51013.4180
>>
>> Random effects:
>>
>> GroupsNameVariance Std.Dev.
>>
>> MatID(Intercept) 0.000000.0000
>>
>> Residual0.024160.1554
>>
>> Number of obs: 500, groups:MatID, 99
>>
>> Fixed effects:
>>
>> Estimate Std. Error t value Pr(>|z|)
>>
>> (Intercept)0.02882820.001300822.161< 2e-16 ***
>>
>> normDens-0.00392740.0012153-3.2320.00123 **
>>
>> normRain0.00027830.00129940.2140.83042
>>
>> ---
>>
>> Signif. codes:0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> Correlation of Fixed Effects:
>>
>> (Intr) nrmDns
>>
>> normDens -0.275
>>
>> normRain0.019 -0.019
>>
>> convergence code: 0
>>
>> boundary (singular) fit: see ?isSingular
>>
>>> M65 <- glmer(IBI~normDens+normRain + (1|MatID), family=Gamma, nAGQ=5,data=Sim)
>>
>>> summary(M65)
>>
>> Generalized linear mixed model fit by maximum likelihood (Adaptive Gauss-Hermite Quadrature, nAGQ = 5) ['glmerMod']
>>
>> Family: Gamma( inverse )
>>
>> Formula: IBI ~ normDens + normRain + (1 | MatID)
>>
>> Data: Sim
>>
>> AICBIClogLik deviance df.resid
>>
>> InfInf-InfInf495
>>
>> Scaled residuals:
>>
>> Min1QMedian3QMax
>>
>> -2.2488 -0.39020.03160.34851.7127
>>
>> Random effects:
>>
>> GroupsNameVarianceStd.Dev.
>>
>> MatID(Intercept) 6.007e-06 0.002451
>>
>> Residual8.831e-04 0.029716
>>
>> Number of obs: 500, groups:MatID, 99
>>
>> Fixed effects:
>>
>> Estimate Std. Error t value Pr(>|z|)
>>
>> (Intercept)2.936e-022.495e-04117.68<2e-16 ***
>>
>> normDens-2.182e-031.163e-04-18.76<2e-16 ***
>>
>> normRain4.883e-043.973e-0512.29<2e-16 ***
>>
>> ---
>>
>> Signif. codes:0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> Correlation of Fixed Effects:
>>
>> (Intr) nrmDns
>>
>> normDens -0.013
>>
>> normRain0.004 -0.041
>>
>> convergence code: 0
>>
>> Gradient contains NAs
>>
>> Warning messages:
>>
>> 1: In vcov.merMod(object, use.hessian = use.hessian) :
>>
>> variance-covariance matrix computed from finite-difference Hessian is
>>
>> not positive definite or contains NA values: falling back to var-cov estimated from RX
>>
>> 2: In vcov.merMod(object, correlation = correlation, sigm = sig) :
>>
>> variance-covariance matrix computed from finite-difference Hessian is
>>
>> not positive definite or contains NA values: falling back to var-cov estimated from RX
>>
>> For comparison, the linear model seems to be well behaved:
>>
>> M1 <- lmer(IBI~normDens+normRain +(1|MatID), REML=FALSE, data=Sim)
>>
>>>
>>
>> summary(M1)
>>
>> Linear mixed model fit by maximum likelihood
>>
>> ['lmerMod']
>>
>> Formula: IBI ~ normDens + normRain + (1 | MatID)
>>
>> Data: Sim
>>
>> AIC
>>
>> BIC
>>
>> logLik deviance df.resid
>>
>> 1804.2
>>
>> 1825.2
>>
>> -897.1
>>
>> 1794.2
>>
>> 495
>>
>> Scaled residuals:
>>
>> Min
>>
>> 1Q
>>
>> Median
>>
>> 3Q
>>
>> Max
>>
>> -3.2970 -0.5304
>>
>> 0.0153
>>
>> 0.5484
>>
>> 3.4798
>>
>> Random effects:
>>
>> Groups
>>
>> Name
>>
>> Variance Std.Dev.
>>
>> MatID
>>
>> (Intercept) 43.5694
>>
>> 6.6007
>>
>> Residual
>>
>> 0.6737
>>
>> 0.8208
>>
>> Number of obs: 500, groups:
>>
>> MatID, 99
>>
>> Fixed effects:
>>
>> Estimate Std. Error t value
>>
>> (Intercept) 35.47121
>>
>> 0.66443
>>
>> 53.39
>>
>> normDens
>>
>> 2.00732
>>
>> 0.11816
>>
>> 16.99
>>
>> normRain
>>
>> -0.71747
>>
>> 0.04237
>>
>> -16.93
>>
>> Correlation of Fixed Effects:
>>
>> (Intr) nrmDns
>>
>> normDens -0.002
>>
>> normRain
>>
>> 0.000 -0.044
>>
>> Should I just conclude that the data is not well modelled by a Gamma GLMM?
>>
>> Peter R Law
>> Research Associate
>> Center for African Conservation Ecology
>> Nelson Mandela University
>> South Africa
>>
>> Sent with [ProtonMail](https://protonmail.com/) Secure Email.
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From bbo|ker @end|ng |rom gm@||@com  Sat Jun 19 00:13:26 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 18 Jun 2021 18:13:26 -0400
Subject: [R-sig-ME] Question on glmmTMB
In-Reply-To: <CAEatWUoG24rGuWvVGTCv9-2e28ayXFCTG-WsHZsoKsV79Z3a0A@mail.gmail.com>
References: <CAEatWUoG24rGuWvVGTCv9-2e28ayXFCTG-WsHZsoKsV79Z3a0A@mail.gmail.com>
Message-ID: <9a47fb08-20d2-b48e-4845-83c6613b1bf7@gmail.com>

   This should be fine. Unlike many mixed model packages, glmmTMB can 
handle models with no random effect.  When in doubt, you can just try 
out a comparison - this obviously isn't a 100% guarantee that something 
works reliably, but in this example all three approaches give very 
similar answers:

library(glmmTMB)
library(bbmle)
m1 <- glmmTMB(count~spp + mined, Salamanders, family=nbinom2)
m2 <- MASS::glm.nb(count~spp + mined, Salamanders)
m3 <- mle2(count ~ dnbinom(mu = exp(logmu), size = exp(logk)),
            parameters = list(logmu ~ spp + mined),
            start = list(logmu = 0, logk = 0),
            data = Salamanders)

library(broom)
library(broom.mixed)
tidy(m1)
tidy(m2)
tidy(m3)

On 6/18/21 4:10 AM, Ebhodaghe Faith wrote:
> Dear All,
> 
> The glmmTMB package is used to model data with mixed effects. For example:
> 
> glmmTMB(count~spp + mined + (1|site), Salamanders, family=nbinom2)
> 
> But I'm just curious to know what happens when the package is used to model
> data without random effects (will this still be fine? How does this compare
> with just using the glm function in the MASS package?). See example below:
> 
> glmmTMB(count~spp + mined, Salamanders, family=nbinom2)
> 
> With kind regards,
> Faith
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From pr|db @end|ng |rom protonm@||@com  Sat Jun 19 00:39:20 2021
From: pr|db @end|ng |rom protonm@||@com (Peter R Law)
Date: Fri, 18 Jun 2021 22:39:20 +0000
Subject: [R-sig-ME] Fw: glmer and nAGQ
In-Reply-To: <ecb77626-a725-bb11-eead-9a00e21f71ce@gmail.com>
References: <IaPuZYIQ_b0xc3TiOKKB7qUSl_oIrJs3qAAhv0FzcMEmNLhnqVk2YTt7MujmZrjXeK2HmDlukIhdfOYOzYtSACRBseVXSGHWX01pVwXM3IA=@protonmail.com>
 <eRi5lAvI3CZFpoVa8IsTe5tGL_XcunhS6SO19GpY3rHle2EAxwTwqPoXdjNc08xqm-V6bHJFOWwEMh5uGETjT0_tZXZjbp_wVZ02j2HtckI=@protonmail.com>
 <ecb77626-a725-bb11-eead-9a00e21f71ce@gmail.com>
Message-ID: <CMAdImRcLjL5-85lpWAMiEgGkFecpFON3PRPgT2K0GyVYJzWqpfgCDRttmpyV4R_OMXMHP6zTMTBVOZTjKNI9n6hU77F8_u1XpPboKK6ca8=@protonmail.com>

Thanks for your response. I'm sorry the formatting of the R output got messed up and hard to read when I forwarded the original message. I do understand that changing the value of nAGQ is changing the approximation of the likelihood, not changing the model itself. I wondered whether the change in likelihood from -643.8 (n=1) to -5.9 (n=2) to -inf (n=3) was a reason to suspect the model was badly behaved in that none of these approximations of the logLik should be trusted. The parameter estimates for the fixed effects don't change that much, basically just the logLik and consequently the AIC. I wanted to compare the glmer with a Gamma distribution to the lmer to see whether AIC favoured one over the other. My intent was to start with the glmer with default n=1, then increase n until model parameters seemed stable, then use that n value for the glmer model to obtain a logLik and then AIC to compare to the lmer version. But the dramatic differences in logLik in going from n=1 to n= 2 and the negative infinite value already for n=3 I thought might suggest that none of these logLiks should be trusted and the the Gamma model simply abandoned. Does that sound plausible in light of the warning messages? In particular, that the negative infinity answer is a failuer in the estimation procedure rather than an indication that that the Gamma model has zero likelihood?

I will repeat the analyses with the log link. As far as the data is concerned, it's simulated data I created without using any distributional assumptions but rather based on ecological assumptions for how the response might depend on the fixed predictors. My purpose here is to explore the glmer function in preparation for a study with real data (still being collected). Because the responses are positive values, I thought it would be worth investigating how a Gamma glmer compares with an lmer (and compare both with a log-normal model, after making the adjustment in the latter so that its AIC is comparable to the others, as was pointed out in a previous posting).

Peter


Sent with ProtonMail Secure Email.

??????? Original Message ???????

On Friday, June 18th, 2021 at 5:44 PM, Ben Bolker <bbolker at gmail.com> wrote:

> This is kind of hard to read, but I'll try.
>
> First of all, log-likelihoods with nAGQ>1 (adaptive Gauss-Hermite
>
> quadrature) **are not currently commensurate with log-likelihoods with
>
> nAGQ==1 (Laplace approximation). This is hinted at in the "Deviance and
>
> log-likelihood of GLMMs" section under "Deviance and log-likelihood of
>
> GLMMs".
>
> In any case, the log-likelihoods computed under different numbers of
>
> quadrature points aren't comparable as though they were different
>
> statistical models (AIC, likelihood ratio tests, etc.). Rather, they are
>
> based on different approximations to the same model, and we know
>
> that larger numbers of quadrature points (increasing nAGQ) are more
>
> accurate (although slower) approximations. The main thing is to see if
>
> results (parameter estimates etc.) change as nAGQ increases by a
>
> magnitude that is important for the current analysis ... if they do,
>
> then you should use an nAGQ that is large enough that it approximates
>
> "infinity", i.e. increasing nAGQ further doesn't change the answers by
>
> an important amount.
>
> In general if it is not important to you to use the inverse link (for
>
> interpretation/because you think this will be the natural scale on which
>
> to measure effects of continuous parameters and/or interactions),
>
> Gamma(link="log") is generally more robust.
>
> The "rescale variables?" suggestion is just that; if the parameters
>
> are already rescaled, then it's not going to help. A large eigenvalue
>
> may not actually be a problem, it just indicates the possibility of
>
> numerical instability. In this case my guess is that the very small
>
> random effects variance might be responsible.
>
> It's also a little surprising that the normRain coefficient is very
>
> small in magnitude and yet but has a very large Z-statistic, given this
>
> sample size.
>
> The results with increasing AGQ do indeed look kind of wonky. If this
>
> were my problem I would want to look more carefully at the data/think
>
> about where they came from. How do the model diagnostics look?
>
> On 6/18/21 3:52 PM, Peter R Law via R-sig-mixed-models wrote:
>
> > I am re-sending this query that I originally emailed June 13'th. I did not receive a copy of the sent email as I have with previous postings and my query doesn't appear in the archive of postings so does not seem to have been received.
> >
> > Peter R Law
> >
> > Sent with ProtonMail Secure Email.
> >
> > ??????? Original Message ???????
> >
> > On Monday, June 14th, 2021 at 10:48 PM, Peter R Law prldb at protonmail.com wrote:
> >
> > > Any help with the following query is much appreciated.
> > >
> > > I used some simulated data (not generated under any specific distributional assumption but all responses are positive quantities) to investigate the nAGQ argument in glmer, running a Gamma-distribution model. With nAAGQ=2 the logLik is dramatically different to the default value of nAGQ=1, while nAGQ=5 returned minus infinity for the logLik, but the estimates of the fixed effect parameters are somewhat consistent across each computation. Are the differences in the estimated logLik surprising or do they reflect the warnings glmer returns for this attempted modelling? I got similar results for a real dataset too.
> > >
> > > data.frame':500 obs. of8 variables:
> > >
> > > $ IBI: num25.5 25.4 25.2 25.6 25.8 ...
> > >
> > > $ MatID: Factor w/ 99 levels "M1","M10","M11",..: 1 1 1 1 1 12 12 12 12 12 ...
> > >
> > > $ Pop: Factor w/ 5 levels "P1","P2","P3",..: 1 1 1 1 1 1 1 1 1 1 ...
> > >
> > > $ density : int11 13 15 19 28 11 13 15 19 28 ...
> > >
> > > $ rain: num41.1 36.6 31.6 40 40.6 ...
> > >
> > > $ normIBI : num-1.28 -1.29 -1.31 -1.26 -1.24 ...
> > >
> > > $ normDens: num-1.72 -1.66 -1.61 -1.49 -1.23 ...
> > >
> > > $ normRain: num-0.249 -0.64 -1.073 -0.345 -0.287 ...
> > >
> > > > M61 <- glmer(IBI~normDens+normRain + (1|MatID), family=Gamma, data=Sim)
> > >
> > > Warning message:
> > >
> > > In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,:
> > >
> > > Model is nearly unidentifiable: very large eigenvalue
> > >
> > > -   Rescale variables?
> > >
> > > > summary(M61)
> > >
> > > Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
> > >
> > > Family: Gamma( inverse )
> > >
> > > Formula: IBI ~ normDens + normRain + (1 | MatID)
> > >
> > > Data: Sim
> > >
> > > AICBIClogLik deviance df.resid
> > >
> > > 1297.61318.7-643.81287.6495
> > >
> > > Scaled residuals:
> > >
> > > Min1QMedian3QMax
> > >
> > > -1.58054 -0.306190.041690.367441.31012
> > >
> > > Random effects:
> > >
> > > GroupsNameVarianceStd.Dev.
> > >
> > > MatID(Intercept) 5.802e-06 0.002409
> > >
> > > Residual1.368e-03 0.036989
> > >
> > > Number of obs: 500, groups:MatID, 99
> > >
> > > Fixed effects:
> > >
> > > Estimate Std. Error t value Pr(>|z|)
> > >
> > > (Intercept)3.083e-026.090e-0450.63<2e-16 ***
> > >
> > > normDens -1.720e-037.946e-05-21.65<2e-16 ***
> > >
> > > normRain4.889e-042.463e-0519.85<2e-16 ***
> > >
> > > Signif. codes:0 ?? 0.001 ?? 0.01 ?? 0.05 ?.? 0.1 ? ? 1
> > >
> > > Correlation of Fixed Effects:
> > >
> > > (Intr) nrmDns
> > >
> > > normDens0.028
> > >
> > > normRain0.000 -0.044
> > >
> > > convergence code: 0
> > >
> > > Model is nearly unidentifiable: very large eigenvalue
> > >
> > > -   Rescale variables?
> > >
> > > What kind of scaling is being suggested in the case of the default value of nAGQ? The predictors are already normalized.
> > >
> > > > M62 <- glmer(IBI~normDens+normRain + (1|MatID), family=Gamma, nAGQ=2,data=Sim)
> > >
> > > boundary (singular) fit: see ?isSingular
> > >
> > > > summary(M62)
> > >
> > > Generalized linear mixed model fit by maximum likelihood (Adaptive Gauss-Hermite Quadrature, nAGQ = 2) ['glmerMod']
> > >
> > > Family: Gamma( inverse )
> > >
> > > Formula: IBI ~ normDens + normRain + (1 | MatID)
> > >
> > > Data: Sim
> > >
> > > AICBIClogLik deviance df.resid
> > >
> > > 21.742.8-5.911.7495
> > >
> > > Scaled residuals:
> > >
> > > Min1QMedian3QMax
> > >
> > > -2.3532 -0.6617 -0.13050.51013.4180
> > >
> > > Random effects:
> > >
> > > GroupsNameVariance Std.Dev.
> > >
> > > MatID(Intercept) 0.000000.0000
> > >
> > > Residual0.024160.1554
> > >
> > > Number of obs: 500, groups:MatID, 99
> > >
> > > Fixed effects:
> > >
> > > Estimate Std. Error t value Pr(>|z|)
> > >
> > > (Intercept)0.02882820.001300822.161< 2e-16 ***
> > >
> > > normDens-0.00392740.0012153-3.2320.00123 **
> > >
> > > normRain0.00027830.00129940.2140.83042
> > >
> > > Signif. codes:0 ?? 0.001 ?? 0.01 ?? 0.05 ?.? 0.1 ? ? 1
> > >
> > > Correlation of Fixed Effects:
> > >
> > > (Intr) nrmDns
> > >
> > > normDens -0.275
> > >
> > > normRain0.019 -0.019
> > >
> > > convergence code: 0
> > >
> > > boundary (singular) fit: see ?isSingular
> > >
> > > > M65 <- glmer(IBI~normDens+normRain + (1|MatID), family=Gamma, nAGQ=5,data=Sim)
> > >
> > > > summary(M65)
> > >
> > > Generalized linear mixed model fit by maximum likelihood (Adaptive Gauss-Hermite Quadrature, nAGQ = 5) ['glmerMod']
> > >
> > > Family: Gamma( inverse )
> > >
> > > Formula: IBI ~ normDens + normRain + (1 | MatID)
> > >
> > > Data: Sim
> > >
> > > AICBIClogLik deviance df.resid
> > >
> > > InfInf-InfInf495
> > >
> > > Scaled residuals:
> > >
> > > Min1QMedian3QMax
> > >
> > > -2.2488 -0.39020.03160.34851.7127
> > >
> > > Random effects:
> > >
> > > GroupsNameVarianceStd.Dev.
> > >
> > > MatID(Intercept) 6.007e-06 0.002451
> > >
> > > Residual8.831e-04 0.029716
> > >
> > > Number of obs: 500, groups:MatID, 99
> > >
> > > Fixed effects:
> > >
> > > Estimate Std. Error t value Pr(>|z|)
> > >
> > > (Intercept)2.936e-022.495e-04117.68<2e-16 ***
> > >
> > > normDens-2.182e-031.163e-04-18.76<2e-16 ***
> > >
> > > normRain4.883e-043.973e-0512.29<2e-16 ***
> > >
> > > Signif. codes:0 ?? 0.001 ?? 0.01 ?? 0.05 ?.? 0.1 ? ? 1
> > >
> > > Correlation of Fixed Effects:
> > >
> > > (Intr) nrmDns
> > >
> > > normDens -0.013
> > >
> > > normRain0.004 -0.041
> > >
> > > convergence code: 0
> > >
> > > Gradient contains NAs
> > >
> > > Warning messages:
> > >
> > > 1: In vcov.merMod(object, use.hessian = use.hessian) :
> > >
> > > variance-covariance matrix computed from finite-difference Hessian is
> > >
> > > not positive definite or contains NA values: falling back to var-cov estimated from RX
> > >
> > > 2: In vcov.merMod(object, correlation = correlation, sigm = sig) :
> > >
> > > variance-covariance matrix computed from finite-difference Hessian is
> > >
> > > not positive definite or contains NA values: falling back to var-cov estimated from RX
> > >
> > > For comparison, the linear model seems to be well behaved:
> > >
> > > M1 <- lmer(IBI~normDens+normRain +(1|MatID), REML=FALSE, data=Sim)
> > >
> > > summary(M1)
> > >
> > > Linear mixed model fit by maximum likelihood
> > >
> > > ['lmerMod']
> > >
> > > Formula: IBI ~ normDens + normRain + (1 | MatID)
> > >
> > > Data: Sim
> > >
> > > AIC
> > >
> > > BIC
> > >
> > > logLik deviance df.resid
> > >
> > > 1804.2
> > >
> > > 1825.2
> > >
> > > -897.1
> > >
> > > 1794.2
> > >
> > > 495
> > >
> > > Scaled residuals:
> > >
> > > Min
> > >
> > > 1Q
> > >
> > > Median
> > >
> > > 3Q
> > >
> > > Max
> > >
> > > -3.2970 -0.5304
> > >
> > > 0.0153
> > >
> > > 0.5484
> > >
> > > 3.4798
> > >
> > > Random effects:
> > >
> > > Groups
> > >
> > > Name
> > >
> > > Variance Std.Dev.
> > >
> > > MatID
> > >
> > > (Intercept) 43.5694
> > >
> > > 6.6007
> > >
> > > Residual
> > >
> > > 0.6737
> > >
> > > 0.8208
> > >
> > > Number of obs: 500, groups:
> > >
> > > MatID, 99
> > >
> > > Fixed effects:
> > >
> > > Estimate Std. Error t value
> > >
> > > (Intercept) 35.47121
> > >
> > > 0.66443
> > >
> > > 53.39
> > >
> > > normDens
> > >
> > > 2.00732
> > >
> > > 0.11816
> > >
> > > 16.99
> > >
> > > normRain
> > >
> > > -0.71747
> > >
> > > 0.04237
> > >
> > > -16.93
> > >
> > > Correlation of Fixed Effects:
> > >
> > > (Intr) nrmDns
> > >
> > > normDens -0.002
> > >
> > > normRain
> > >
> > > 0.000 -0.044
> > >
> > > Should I just conclude that the data is not well modelled by a Gamma GLMM?
> > >
> > > Peter R Law
> > >
> > > Research Associate
> > >
> > > Center for African Conservation Ecology
> > >
> > > Nelson Mandela University
> > >
> > > South Africa
> > >
> > > Sent with ProtonMail Secure Email.
> > >
> > > [[alternative HTML version deleted]]
> >
> > R-sig-mixed-models at r-project.org mailing list
> >
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> R-sig-mixed-models at r-project.org mailing list
>
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbo|ker @end|ng |rom gm@||@com  Sat Jun 19 02:16:46 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 18 Jun 2021 20:16:46 -0400
Subject: [R-sig-ME] Fw: glmer and nAGQ
In-Reply-To: <CMAdImRcLjL5-85lpWAMiEgGkFecpFON3PRPgT2K0GyVYJzWqpfgCDRttmpyV4R_OMXMHP6zTMTBVOZTjKNI9n6hU77F8_u1XpPboKK6ca8=@protonmail.com>
References: <IaPuZYIQ_b0xc3TiOKKB7qUSl_oIrJs3qAAhv0FzcMEmNLhnqVk2YTt7MujmZrjXeK2HmDlukIhdfOYOzYtSACRBseVXSGHWX01pVwXM3IA=@protonmail.com>
 <eRi5lAvI3CZFpoVa8IsTe5tGL_XcunhS6SO19GpY3rHle2EAxwTwqPoXdjNc08xqm-V6bHJFOWwEMh5uGETjT0_tZXZjbp_wVZ02j2HtckI=@protonmail.com>
 <ecb77626-a725-bb11-eead-9a00e21f71ce@gmail.com>
 <CMAdImRcLjL5-85lpWAMiEgGkFecpFON3PRPgT2K0GyVYJzWqpfgCDRttmpyV4R_OMXMHP6zTMTBVOZTjKNI9n6hU77F8_u1XpPboKK6ca8=@protonmail.com>
Message-ID: <bda8afa0-0ee9-5b52-cc58-e865009661ba@gmail.com>



On 6/18/21 6:39 PM, Peter R Law wrote:
> Thanks for your response. I'm sorry the formatting of the R output got messed up and hard to read when I forwarded the original message. I do understand that changing the value of nAGQ is changing the approximation of the likelihood, not changing the model itself. I wondered whether the change in likelihood from -643.8 (n=1) to -5.9 (n=2) to -inf (n=3) was a reason to suspect the model was badly behaved in that none of these approximations of the logLik should be trusted. The parameter estimates for the fixed effects don't change that much, basically just the logLik and consequently the AIC. I wanted to compare the glmer with a Gamma distribution to the lmer to see whether AIC favoured one over the other. My intent was to start with the glmer with default n=1, then increase n until model parameters seemed stable, then use that n value for the glmer model to obtain a logLik and then AIC to compare to the lmer version. But the dramatic differences in logLik in going from n=1 to n= 2 and the negative infinite value already for n=3 I thought might suggest that none of these logLiks should be trusted and the the Gamma model simply abandoned. Does that sound plausible in light of the warning messages? In particular, that the negative infinity answer is a failuer in the estimation procedure rather than an indication that that the Gamma model has zero likelihood?

   As I suggested in my answer, you shouldn't worry about the big jump 
in log-likelihood from nAGQ=1 to nAGQ=2. I would try n=5, 10, 15, 20 and 
see how it goes (unless n=20 is too slow to be practical). (Yes, I think 
-Inf is a problem with the fitting procedure)

> 
> I will repeat the analyses with the log link. As far as the data is concerned, it's simulated data I created without using any distributional assumptions but rather based on ecological assumptions for how the response might depend on the fixed predictors. My purpose here is to explore the glmer function in preparation for a study with real data (still being collected). Because the responses are positive values, I thought it would be worth investigating how a Gamma glmer compares with an lmer (and compare both with a log-normal model, after making the adjustment in the latter so that its AIC is comparable to the others, as was pointed out in a previous posting).

   Fair enough; "without any distributional assumptions" is a bit odd 
though.  Unless your ecological model is stochastic (in which case the 
conditional distribution will emerge naturally from the model), you have 
to make *some* assumptions about how the observations will vary around 
the expected mean ...

   cheers
    Ben Bolker

> 
> Peter
> 
> 
> Sent with ProtonMail Secure Email.
> 
> ??????? Original Message ???????
> 
> On Friday, June 18th, 2021 at 5:44 PM, Ben Bolker <bbolker at gmail.com> wrote:
> 
>> This is kind of hard to read, but I'll try.
>>
>> First of all, log-likelihoods with nAGQ>1 (adaptive Gauss-Hermite
>>
>> quadrature) **are not currently commensurate with log-likelihoods with
>>
>> nAGQ==1 (Laplace approximation). This is hinted at in the "Deviance and
>>
>> log-likelihood of GLMMs" section under "Deviance and log-likelihood of
>>
>> GLMMs".
>>
>> In any case, the log-likelihoods computed under different numbers of
>>
>> quadrature points aren't comparable as though they were different
>>
>> statistical models (AIC, likelihood ratio tests, etc.). Rather, they are
>>
>> based on different approximations to the same model, and we know
>>
>> that larger numbers of quadrature points (increasing nAGQ) are more
>>
>> accurate (although slower) approximations. The main thing is to see if
>>
>> results (parameter estimates etc.) change as nAGQ increases by a
>>
>> magnitude that is important for the current analysis ... if they do,
>>
>> then you should use an nAGQ that is large enough that it approximates
>>
>> "infinity", i.e. increasing nAGQ further doesn't change the answers by
>>
>> an important amount.
>>
>> In general if it is not important to you to use the inverse link (for
>>
>> interpretation/because you think this will be the natural scale on which
>>
>> to measure effects of continuous parameters and/or interactions),
>>
>> Gamma(link="log") is generally more robust.
>>
>> The "rescale variables?" suggestion is just that; if the parameters
>>
>> are already rescaled, then it's not going to help. A large eigenvalue
>>
>> may not actually be a problem, it just indicates the possibility of
>>
>> numerical instability. In this case my guess is that the very small
>>
>> random effects variance might be responsible.
>>
>> It's also a little surprising that the normRain coefficient is very
>>
>> small in magnitude and yet but has a very large Z-statistic, given this
>>
>> sample size.
>>
>> The results with increasing AGQ do indeed look kind of wonky. If this
>>
>> were my problem I would want to look more carefully at the data/think
>>
>> about where they came from. How do the model diagnostics look?
>>
>> On 6/18/21 3:52 PM, Peter R Law via R-sig-mixed-models wrote:
>>
>>> I am re-sending this query that I originally emailed June 13'th. I did not receive a copy of the sent email as I have with previous postings and my query doesn't appear in the archive of postings so does not seem to have been received.
>>>
>>> Peter R Law
>>>
>>> Sent with ProtonMail Secure Email.
>>>
>>> ??????? Original Message ???????
>>>
>>> On Monday, June 14th, 2021 at 10:48 PM, Peter R Law prldb at protonmail.com wrote:
>>>
>>>> Any help with the following query is much appreciated.
>>>>
>>>> I used some simulated data (not generated under any specific distributional assumption but all responses are positive quantities) to investigate the nAGQ argument in glmer, running a Gamma-distribution model. With nAAGQ=2 the logLik is dramatically different to the default value of nAGQ=1, while nAGQ=5 returned minus infinity for the logLik, but the estimates of the fixed effect parameters are somewhat consistent across each computation. Are the differences in the estimated logLik surprising or do they reflect the warnings glmer returns for this attempted modelling? I got similar results for a real dataset too.
>>>>
>>>> data.frame':500 obs. of8 variables:
>>>>
>>>> $ IBI: num25.5 25.4 25.2 25.6 25.8 ...
>>>>
>>>> $ MatID: Factor w/ 99 levels "M1","M10","M11",..: 1 1 1 1 1 12 12 12 12 12 ...
>>>>
>>>> $ Pop: Factor w/ 5 levels "P1","P2","P3",..: 1 1 1 1 1 1 1 1 1 1 ...
>>>>
>>>> $ density : int11 13 15 19 28 11 13 15 19 28 ...
>>>>
>>>> $ rain: num41.1 36.6 31.6 40 40.6 ...
>>>>
>>>> $ normIBI : num-1.28 -1.29 -1.31 -1.26 -1.24 ...
>>>>
>>>> $ normDens: num-1.72 -1.66 -1.61 -1.49 -1.23 ...
>>>>
>>>> $ normRain: num-0.249 -0.64 -1.073 -0.345 -0.287 ...
>>>>
>>>>> M61 <- glmer(IBI~normDens+normRain + (1|MatID), family=Gamma, data=Sim)
>>>>
>>>> Warning message:
>>>>
>>>> In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,:
>>>>
>>>> Model is nearly unidentifiable: very large eigenvalue
>>>>
>>>> -   Rescale variables?
>>>>
>>>>> summary(M61)
>>>>
>>>> Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
>>>>
>>>> Family: Gamma( inverse )
>>>>
>>>> Formula: IBI ~ normDens + normRain + (1 | MatID)
>>>>
>>>> Data: Sim
>>>>
>>>> AICBIClogLik deviance df.resid
>>>>
>>>> 1297.61318.7-643.81287.6495
>>>>
>>>> Scaled residuals:
>>>>
>>>> Min1QMedian3QMax
>>>>
>>>> -1.58054 -0.306190.041690.367441.31012
>>>>
>>>> Random effects:
>>>>
>>>> GroupsNameVarianceStd.Dev.
>>>>
>>>> MatID(Intercept) 5.802e-06 0.002409
>>>>
>>>> Residual1.368e-03 0.036989
>>>>
>>>> Number of obs: 500, groups:MatID, 99
>>>>
>>>> Fixed effects:
>>>>
>>>> Estimate Std. Error t value Pr(>|z|)
>>>>
>>>> (Intercept)3.083e-026.090e-0450.63<2e-16 ***
>>>>
>>>> normDens -1.720e-037.946e-05-21.65<2e-16 ***
>>>>
>>>> normRain4.889e-042.463e-0519.85<2e-16 ***
>>>>
>>>> Signif. codes:0 ?? 0.001 ?? 0.01 ?? 0.05 ?.? 0.1 ? ? 1
>>>>
>>>> Correlation of Fixed Effects:
>>>>
>>>> (Intr) nrmDns
>>>>
>>>> normDens0.028
>>>>
>>>> normRain0.000 -0.044
>>>>
>>>> convergence code: 0
>>>>
>>>> Model is nearly unidentifiable: very large eigenvalue
>>>>
>>>> -   Rescale variables?
>>>>
>>>> What kind of scaling is being suggested in the case of the default value of nAGQ? The predictors are already normalized.
>>>>
>>>>> M62 <- glmer(IBI~normDens+normRain + (1|MatID), family=Gamma, nAGQ=2,data=Sim)
>>>>
>>>> boundary (singular) fit: see ?isSingular
>>>>
>>>>> summary(M62)
>>>>
>>>> Generalized linear mixed model fit by maximum likelihood (Adaptive Gauss-Hermite Quadrature, nAGQ = 2) ['glmerMod']
>>>>
>>>> Family: Gamma( inverse )
>>>>
>>>> Formula: IBI ~ normDens + normRain + (1 | MatID)
>>>>
>>>> Data: Sim
>>>>
>>>> AICBIClogLik deviance df.resid
>>>>
>>>> 21.742.8-5.911.7495
>>>>
>>>> Scaled residuals:
>>>>
>>>> Min1QMedian3QMax
>>>>
>>>> -2.3532 -0.6617 -0.13050.51013.4180
>>>>
>>>> Random effects:
>>>>
>>>> GroupsNameVariance Std.Dev.
>>>>
>>>> MatID(Intercept) 0.000000.0000
>>>>
>>>> Residual0.024160.1554
>>>>
>>>> Number of obs: 500, groups:MatID, 99
>>>>
>>>> Fixed effects:
>>>>
>>>> Estimate Std. Error t value Pr(>|z|)
>>>>
>>>> (Intercept)0.02882820.001300822.161< 2e-16 ***
>>>>
>>>> normDens-0.00392740.0012153-3.2320.00123 **
>>>>
>>>> normRain0.00027830.00129940.2140.83042
>>>>
>>>> Signif. codes:0 ?? 0.001 ?? 0.01 ?? 0.05 ?.? 0.1 ? ? 1
>>>>
>>>> Correlation of Fixed Effects:
>>>>
>>>> (Intr) nrmDns
>>>>
>>>> normDens -0.275
>>>>
>>>> normRain0.019 -0.019
>>>>
>>>> convergence code: 0
>>>>
>>>> boundary (singular) fit: see ?isSingular
>>>>
>>>>> M65 <- glmer(IBI~normDens+normRain + (1|MatID), family=Gamma, nAGQ=5,data=Sim)
>>>>
>>>>> summary(M65)
>>>>
>>>> Generalized linear mixed model fit by maximum likelihood (Adaptive Gauss-Hermite Quadrature, nAGQ = 5) ['glmerMod']
>>>>
>>>> Family: Gamma( inverse )
>>>>
>>>> Formula: IBI ~ normDens + normRain + (1 | MatID)
>>>>
>>>> Data: Sim
>>>>
>>>> AICBIClogLik deviance df.resid
>>>>
>>>> InfInf-InfInf495
>>>>
>>>> Scaled residuals:
>>>>
>>>> Min1QMedian3QMax
>>>>
>>>> -2.2488 -0.39020.03160.34851.7127
>>>>
>>>> Random effects:
>>>>
>>>> GroupsNameVarianceStd.Dev.
>>>>
>>>> MatID(Intercept) 6.007e-06 0.002451
>>>>
>>>> Residual8.831e-04 0.029716
>>>>
>>>> Number of obs: 500, groups:MatID, 99
>>>>
>>>> Fixed effects:
>>>>
>>>> Estimate Std. Error t value Pr(>|z|)
>>>>
>>>> (Intercept)2.936e-022.495e-04117.68<2e-16 ***
>>>>
>>>> normDens-2.182e-031.163e-04-18.76<2e-16 ***
>>>>
>>>> normRain4.883e-043.973e-0512.29<2e-16 ***
>>>>
>>>> Signif. codes:0 ?? 0.001 ?? 0.01 ?? 0.05 ?.? 0.1 ? ? 1
>>>>
>>>> Correlation of Fixed Effects:
>>>>
>>>> (Intr) nrmDns
>>>>
>>>> normDens -0.013
>>>>
>>>> normRain0.004 -0.041
>>>>
>>>> convergence code: 0
>>>>
>>>> Gradient contains NAs
>>>>
>>>> Warning messages:
>>>>
>>>> 1: In vcov.merMod(object, use.hessian = use.hessian) :
>>>>
>>>> variance-covariance matrix computed from finite-difference Hessian is
>>>>
>>>> not positive definite or contains NA values: falling back to var-cov estimated from RX
>>>>
>>>> 2: In vcov.merMod(object, correlation = correlation, sigm = sig) :
>>>>
>>>> variance-covariance matrix computed from finite-difference Hessian is
>>>>
>>>> not positive definite or contains NA values: falling back to var-cov estimated from RX
>>>>
>>>> For comparison, the linear model seems to be well behaved:
>>>>
>>>> M1 <- lmer(IBI~normDens+normRain +(1|MatID), REML=FALSE, data=Sim)
>>>>
>>>> summary(M1)
>>>>
>>>> Linear mixed model fit by maximum likelihood
>>>>
>>>> ['lmerMod']
>>>>
>>>> Formula: IBI ~ normDens + normRain + (1 | MatID)
>>>>
>>>> Data: Sim
>>>>
>>>> AIC
>>>>
>>>> BIC
>>>>
>>>> logLik deviance df.resid
>>>>
>>>> 1804.2
>>>>
>>>> 1825.2
>>>>
>>>> -897.1
>>>>
>>>> 1794.2
>>>>
>>>> 495
>>>>
>>>> Scaled residuals:
>>>>
>>>> Min
>>>>
>>>> 1Q
>>>>
>>>> Median
>>>>
>>>> 3Q
>>>>
>>>> Max
>>>>
>>>> -3.2970 -0.5304
>>>>
>>>> 0.0153
>>>>
>>>> 0.5484
>>>>
>>>> 3.4798
>>>>
>>>> Random effects:
>>>>
>>>> Groups
>>>>
>>>> Name
>>>>
>>>> Variance Std.Dev.
>>>>
>>>> MatID
>>>>
>>>> (Intercept) 43.5694
>>>>
>>>> 6.6007
>>>>
>>>> Residual
>>>>
>>>> 0.6737
>>>>
>>>> 0.8208
>>>>
>>>> Number of obs: 500, groups:
>>>>
>>>> MatID, 99
>>>>
>>>> Fixed effects:
>>>>
>>>> Estimate Std. Error t value
>>>>
>>>> (Intercept) 35.47121
>>>>
>>>> 0.66443
>>>>
>>>> 53.39
>>>>
>>>> normDens
>>>>
>>>> 2.00732
>>>>
>>>> 0.11816
>>>>
>>>> 16.99
>>>>
>>>> normRain
>>>>
>>>> -0.71747
>>>>
>>>> 0.04237
>>>>
>>>> -16.93
>>>>
>>>> Correlation of Fixed Effects:
>>>>
>>>> (Intr) nrmDns
>>>>
>>>> normDens -0.002
>>>>
>>>> normRain
>>>>
>>>> 0.000 -0.044
>>>>
>>>> Should I just conclude that the data is not well modelled by a Gamma GLMM?
>>>>
>>>> Peter R Law
>>>>
>>>> Research Associate
>>>>
>>>> Center for African Conservation Ecology
>>>>
>>>> Nelson Mandela University
>>>>
>>>> South Africa
>>>>
>>>> Sent with ProtonMail Secure Email.
>>>>
>>>> [[alternative HTML version deleted]]
>>>
>>> R-sig-mixed-models at r-project.org mailing list
>>>
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> R-sig-mixed-models at r-project.org mailing list
>>
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From ebhod@ghe|@|th @end|ng |rom gm@||@com  Sat Jun 19 07:00:15 2021
From: ebhod@ghe|@|th @end|ng |rom gm@||@com (Ebhodaghe Faith)
Date: Sat, 19 Jun 2021 08:00:15 +0300
Subject: [R-sig-ME] Question on glmmTMB
In-Reply-To: <9a47fb08-20d2-b48e-4845-83c6613b1bf7@gmail.com>
References: <CAEatWUoG24rGuWvVGTCv9-2e28ayXFCTG-WsHZsoKsV79Z3a0A@mail.gmail.com>
 <9a47fb08-20d2-b48e-4845-83c6613b1bf7@gmail.com>
Message-ID: <CAEatWUpsZ9VmUX9rt29J9LrUYGrXc574Si+z5ygye8beC=vOtQ@mail.gmail.com>

Thank you, Ben Bolker.

I find your response very helpful.

Regards,
Faith

On Sat, 19 Jun 2021, 1:13 a.m. Ben Bolker, <bbolker at gmail.com> wrote:

>    This should be fine. Unlike many mixed model packages, glmmTMB can
> handle models with no random effect.  When in doubt, you can just try
> out a comparison - this obviously isn't a 100% guarantee that something
> works reliably, but in this example all three approaches give very
> similar answers:
>
> library(glmmTMB)
> library(bbmle)
> m1 <- glmmTMB(count~spp + mined, Salamanders, family=nbinom2)
> m2 <- MASS::glm.nb(count~spp + mined, Salamanders)
> m3 <- mle2(count ~ dnbinom(mu = exp(logmu), size = exp(logk)),
>             parameters = list(logmu ~ spp + mined),
>             start = list(logmu = 0, logk = 0),
>             data = Salamanders)
>
> library(broom)
> library(broom.mixed)
> tidy(m1)
> tidy(m2)
> tidy(m3)
>
> On 6/18/21 4:10 AM, Ebhodaghe Faith wrote:
> > Dear All,
> >
> > The glmmTMB package is used to model data with mixed effects. For
> example:
> >
> > glmmTMB(count~spp + mined + (1|site), Salamanders, family=nbinom2)
> >
> > But I'm just curious to know what happens when the package is used to
> model
> > data without random effects (will this still be fine? How does this
> compare
> > with just using the glm function in the MASS package?). See example
> below:
> >
> > glmmTMB(count~spp + mined, Salamanders, family=nbinom2)
> >
> > With kind regards,
> > Faith
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From me @end|ng |rom ph||||p@|d@y@com  Sat Jun 19 18:27:37 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Sat, 19 Jun 2021 11:27:37 -0500
Subject: [R-sig-ME] Residual setting with makeLmer in simR package
In-Reply-To: <23E5145C-0087-4C4C-91E1-4203DAD64F90@vu.nl>
References: <3BD202F1-FBE6-406A-BC23-C7B37AADB44E@vu.nl>
 <23E5145C-0087-4C4C-91E1-4203DAD64F90@vu.nl>
Message-ID: <ca6db759-dd3d-35b3-7aae-e512f7a02641@phillipalday.com>

If everything else is standardized, then setting the residual sd to 1
seems acceptable.

That said, there are non trivial issues with fully standardizing effect
sizes in mixed-effects models. Henrik Singmann has a very nice post on this:


https://afex.singmann.science/forums/topic/compute-effect-sizes-for-mixed-objects#post-295

On 3/6/21 7:52 am, Fan, L. via R-sig-mixed-models wrote:
> Hi all,
> 
> I have a doubt about how to set residual sd (sigma) for a PA, using makeLmer function of the simR package.
> 
> When defining the fixed effect, my parameter estimates were all standardized coefficients (i.e., I standardised/z-scored all the variables beforehand). When defining the random structures, since I extracted them from another similar but not same-structured study, I also used the standardized variances (variance divided by sum of variances) for random intercepts and slopes to match them with my manipulation for the fixed parts. 
> 
> When I tried to fill the sigma of makeLmer function, I got a little bit lost. It is said in the manual that I should enter the sd of the residual. However, since I standardized the random effects, I believe the residual sd should also be different than the original unstandardized one. My question is, how should I deal with this sigma part, should I indeed use a standardized residual sd? And if yes, should it be simply valued as 1, or how should I standardize it?
> 
> Thanks!
> 
> Best wishes,
> 
> Lei Fan
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From d@n|e||erud|ey @end|ng |rom gm@||@com  Wed Jun 23 12:25:23 2021
From: d@n|e||erud|ey @end|ng |rom gm@||@com (Danielle Rudley)
Date: Wed, 23 Jun 2021 11:25:23 +0100
Subject: [R-sig-ME] How to run an Auto Regressive Generalized Linear Mixed
 Model
Message-ID: <CAOCRGCzzDxEABf_pcMZXTzozrPG6V5BY-mHuix5k=z-_WLx5KA@mail.gmail.com>

Hello all,

I'm trying to run Auto Regressive Linear Mixed Models in R using the nlme()
package. For my continuous response variables I have used lme() with the
correlation set as 'corAR1()', but one of my response variables has a
poisson distribution (i.e.- count of number of conductive xylem cells). I
was wondering how to run an AR Generalized LMM within the nlme() package,
or if there was another solution to this. Thanks so much for your help.

Cheers,
-- 
Danielle Rudley

PhD Candidate
Forest Research Centre (CEF)
School of Agriculture, University of Lisbon
Tapada da Ajuda, 1349-017 Lisboa, Portugal

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Wed Jun 23 15:27:56 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 23 Jun 2021 09:27:56 -0400
Subject: [R-sig-ME] 
 How to run an Auto Regressive Generalized Linear Mixed Model
In-Reply-To: <CAOCRGCzzDxEABf_pcMZXTzozrPG6V5BY-mHuix5k=z-_WLx5KA@mail.gmail.com>
References: <CAOCRGCzzDxEABf_pcMZXTzozrPG6V5BY-mHuix5k=z-_WLx5KA@mail.gmail.com>
Message-ID: <12067f0b-1b70-1b43-c6e6-6d73a849b025@gmail.com>


    You can use the glmmPQL function in the MASS package; the glmmTMB 
package can also handle autoregressive GLMMs. (Also, MCMCglmm and brms 
if you want to go Bayesian.)

On 6/23/21 6:25 AM, Danielle Rudley wrote:
> Hello all,
> 
> I'm trying to run Auto Regressive Linear Mixed Models in R using the nlme()
> package. For my continuous response variables I have used lme() with the
> correlation set as 'corAR1()', but one of my response variables has a
> poisson distribution (i.e.- count of number of conductive xylem cells). I
> was wondering how to run an AR Generalized LMM within the nlme() package,
> or if there was another solution to this. Thanks so much for your help.
> 
> Cheers,
>


From pr|db @end|ng |rom protonm@||@com  Thu Jun 24 04:39:56 2021
From: pr|db @end|ng |rom protonm@||@com (Peter R Law)
Date: Thu, 24 Jun 2021 02:39:56 +0000
Subject: [R-sig-ME] Fw: glmer and nAGQ
In-Reply-To: <bda8afa0-0ee9-5b52-cc58-e865009661ba@gmail.com>
References: <IaPuZYIQ_b0xc3TiOKKB7qUSl_oIrJs3qAAhv0FzcMEmNLhnqVk2YTt7MujmZrjXeK2HmDlukIhdfOYOzYtSACRBseVXSGHWX01pVwXM3IA=@protonmail.com>
 <eRi5lAvI3CZFpoVa8IsTe5tGL_XcunhS6SO19GpY3rHle2EAxwTwqPoXdjNc08xqm-V6bHJFOWwEMh5uGETjT0_tZXZjbp_wVZ02j2HtckI=@protonmail.com>
 <ecb77626-a725-bb11-eead-9a00e21f71ce@gmail.com>
 <CMAdImRcLjL5-85lpWAMiEgGkFecpFON3PRPgT2K0GyVYJzWqpfgCDRttmpyV4R_OMXMHP6zTMTBVOZTjKNI9n6hU77F8_u1XpPboKK6ca8=@protonmail.com>
 <bda8afa0-0ee9-5b52-cc58-e865009661ba@gmail.com>
Message-ID: <LNnAz-OD7BJ9VSGO8RarV2UtO6AP82-oxLiYGqm-CuqYzm5AL_3QN-De_mLduTYGSa49c3CIQmFx5Xp1ELtdx3zSG3zSyRGGE0qQNvf21dc=@protonmail.com>

Thanks again for your feedback. Much appreciated. With the canonical link in the Gamma model, once a neg infinity result is returned for the logLik (n=4 for my simulation data), increasing the value of nAGQ doesn't change that result and the warning message about the estimated variance-covariance matrix not being positive definite is constant also.

If I use the log link, there is a large increase (-678.1 to -5.6) in the LogLik in going from the default value of n=1 to n=2, but it then doesn't change for larger n values and the model results are stable.

So I assume then that the Gamma model with the canonical link cannot be fit to this data while with the log link one does get a robust result?

There was no detectable delay in the time to run the model with nAGQ = 25 versus the default value. Is that suspicious?

Peter



Sent with ProtonMail Secure Email.

??????? Original Message ???????

On Friday, June 18th, 2021 at 8:16 PM, Ben Bolker <bbolker at gmail.com> wrote:

> On 6/18/21 6:39 PM, Peter R Law wrote:
>
> > Thanks for your response. I'm sorry the formatting of the R output got messed up and hard to read when I forwarded the original message. I do understand that changing the value of nAGQ is changing the approximation of the likelihood, not changing the model itself. I wondered whether the change in likelihood from -643.8 (n=1) to -5.9 (n=2) to -inf (n=3) was a reason to suspect the model was badly behaved in that none of these approximations of the logLik should be trusted. The parameter estimates for the fixed effects don't change that much, basically just the logLik and consequently the AIC. I wanted to compare the glmer with a Gamma distribution to the lmer to see whether AIC favoured one over the other. My intent was to start with the glmer with default n=1, then increase n until model parameters seemed stable, then use that n value for the glmer model to obtain a logLik and then AIC to compare to the lmer version. But the dramatic differences in logLik in going from n=1 to n= 2 and the negative infinite value already for n=3 I thought might suggest that none of these logLiks should be trusted and the the Gamma model simply abandoned. Does that sound plausible in light of the warning messages? In particular, that the negative infinity answer is a failuer in the estimation procedure rather than an indication that that the Gamma model has zero likelihood?
>
> As I suggested in my answer, you shouldn't worry about the big jump
>
> in log-likelihood from nAGQ=1 to nAGQ=2. I would try n=5, 10, 15, 20 and
>
> see how it goes (unless n=20 is too slow to be practical). (Yes, I think
>
> -Inf is a problem with the fitting procedure)
>
> > I will repeat the analyses with the log link. As far as the data is concerned, it's simulated data I created without using any distributional assumptions but rather based on ecological assumptions for how the response might depend on the fixed predictors. My purpose here is to explore the glmer function in preparation for a study with real data (still being collected). Because the responses are positive values, I thought it would be worth investigating how a Gamma glmer compares with an lmer (and compare both with a log-normal model, after making the adjustment in the latter so that its AIC is comparable to the others, as was pointed out in a previous posting).
>
> Fair enough; "without any distributional assumptions" is a bit odd
>
> though. Unless your ecological model is stochastic (in which case the
>
> conditional distribution will emerge naturally from the model), you have
>
> to make some assumptions about how the observations will vary around
>
> the expected mean ...
>
> cheers
>
> Ben Bolker
>
> > Peter
> >
> > Sent with ProtonMail Secure Email.
> >
> > ??????? Original Message ???????
> >
> > On Friday, June 18th, 2021 at 5:44 PM, Ben Bolker bbolker at gmail.com wrote:
> >
> > > This is kind of hard to read, but I'll try.
> > >
> > > First of all, log-likelihoods with nAGQ>1 (adaptive Gauss-Hermite
> > >
> > > quadrature) **are not currently commensurate with log-likelihoods with
> > >
> > > nAGQ==1 (Laplace approximation). This is hinted at in the "Deviance and
> > >
> > > log-likelihood of GLMMs" section under "Deviance and log-likelihood of
> > >
> > > GLMMs".
> > >
> > > In any case, the log-likelihoods computed under different numbers of
> > >
> > > quadrature points aren't comparable as though they were different
> > >
> > > statistical models (AIC, likelihood ratio tests, etc.). Rather, they are
> > >
> > > based on different approximations to the same model, and we know
> > >
> > > that larger numbers of quadrature points (increasing nAGQ) are more
> > >
> > > accurate (although slower) approximations. The main thing is to see if
> > >
> > > results (parameter estimates etc.) change as nAGQ increases by a
> > >
> > > magnitude that is important for the current analysis ... if they do,
> > >
> > > then you should use an nAGQ that is large enough that it approximates
> > >
> > > "infinity", i.e. increasing nAGQ further doesn't change the answers by
> > >
> > > an important amount.
> > >
> > > In general if it is not important to you to use the inverse link (for
> > >
> > > interpretation/because you think this will be the natural scale on which
> > >
> > > to measure effects of continuous parameters and/or interactions),
> > >
> > > Gamma(link="log") is generally more robust.
> > >
> > > The "rescale variables?" suggestion is just that; if the parameters
> > >
> > > are already rescaled, then it's not going to help. A large eigenvalue
> > >
> > > may not actually be a problem, it just indicates the possibility of
> > >
> > > numerical instability. In this case my guess is that the very small
> > >
> > > random effects variance might be responsible.
> > >
> > > It's also a little surprising that the normRain coefficient is very
> > >
> > > small in magnitude and yet but has a very large Z-statistic, given this
> > >
> > > sample size.
> > >
> > > The results with increasing AGQ do indeed look kind of wonky. If this
> > >
> > > were my problem I would want to look more carefully at the data/think
> > >
> > > about where they came from. How do the model diagnostics look?
> > >
> > > On 6/18/21 3:52 PM, Peter R Law via R-sig-mixed-models wrote:
> > >
> > > > I am re-sending this query that I originally emailed June 13'th. I did not receive a copy of the sent email as I have with previous postings and my query doesn't appear in the archive of postings so does not seem to have been received.
> > > >
> > > > Peter R Law
> > > >
> > > > Sent with ProtonMail Secure Email.
> > > >
> > > > ??????? Original Message ???????
> > > >
> > > > On Monday, June 14th, 2021 at 10:48 PM, Peter R Law prldb at protonmail.com wrote:
> > > >
> > > > > Any help with the following query is much appreciated.
> > > > >
> > > > > I used some simulated data (not generated under any specific distributional assumption but all responses are positive quantities) to investigate the nAGQ argument in glmer, running a Gamma-distribution model. With nAAGQ=2 the logLik is dramatically different to the default value of nAGQ=1, while nAGQ=5 returned minus infinity for the logLik, but the estimates of the fixed effect parameters are somewhat consistent across each computation. Are the differences in the estimated logLik surprising or do they reflect the warnings glmer returns for this attempted modelling? I got similar results for a real dataset too.
> > > > >
> > > > > data.frame':500 obs. of8 variables:
> > > > >
> > > > > $ IBI: num25.5 25.4 25.2 25.6 25.8 ...
> > > > >
> > > > > $ MatID: Factor w/ 99 levels "M1","M10","M11",..: 1 1 1 1 1 12 12 12 12 12 ...
> > > > >
> > > > > $ Pop: Factor w/ 5 levels "P1","P2","P3",..: 1 1 1 1 1 1 1 1 1 1 ...
> > > > >
> > > > > $ density : int11 13 15 19 28 11 13 15 19 28 ...
> > > > >
> > > > > $ rain: num41.1 36.6 31.6 40 40.6 ...
> > > > >
> > > > > $ normIBI : num-1.28 -1.29 -1.31 -1.26 -1.24 ...
> > > > >
> > > > > $ normDens: num-1.72 -1.66 -1.61 -1.49 -1.23 ...
> > > > >
> > > > > $ normRain: num-0.249 -0.64 -1.073 -0.345 -0.287 ...
> > > > >
> > > > > > M61 <- glmer(IBI~normDens+normRain + (1|MatID), family=Gamma, data=Sim)
> > > > >
> > > > > Warning message:
> > > > >
> > > > > In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,:
> > > > >
> > > > > Model is nearly unidentifiable: very large eigenvalue
> > > > >
> > > > > -   Rescale variables?
> > > > >
> > > > > > summary(M61)
> > > > >
> > > > > Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
> > > > >
> > > > > Family: Gamma( inverse )
> > > > >
> > > > > Formula: IBI ~ normDens + normRain + (1 | MatID)
> > > > >
> > > > > Data: Sim
> > > > >
> > > > > AICBIClogLik deviance df.resid
> > > > >
> > > > > 1297.61318.7-643.81287.6495
> > > > >
> > > > > Scaled residuals:
> > > > >
> > > > > Min1QMedian3QMax
> > > > >
> > > > > -1.58054 -0.306190.041690.367441.31012
> > > > >
> > > > > Random effects:
> > > > >
> > > > > GroupsNameVarianceStd.Dev.
> > > > >
> > > > > MatID(Intercept) 5.802e-06 0.002409
> > > > >
> > > > > Residual1.368e-03 0.036989
> > > > >
> > > > > Number of obs: 500, groups:MatID, 99
> > > > >
> > > > > Fixed effects:
> > > > >
> > > > > Estimate Std. Error t value Pr(>|z|)
> > > > >
> > > > > (Intercept)3.083e-026.090e-0450.63<2e-16 ***
> > > > >
> > > > > normDens -1.720e-037.946e-05-21.65<2e-16 ***
> > > > >
> > > > > normRain4.889e-042.463e-0519.85<2e-16 ***
> > > > >
> > > > > Signif. codes:0 ?? 0.001 ?? 0.01 ?? 0.05 ?.? 0.1 ? ? 1
> > > > >
> > > > > Correlation of Fixed Effects:
> > > > >
> > > > > (Intr) nrmDns
> > > > >
> > > > > normDens0.028
> > > > >
> > > > > normRain0.000 -0.044
> > > > >
> > > > > convergence code: 0
> > > > >
> > > > > Model is nearly unidentifiable: very large eigenvalue
> > > > >
> > > > > -   Rescale variables?
> > > > >
> > > > > What kind of scaling is being suggested in the case of the default value of nAGQ? The predictors are already normalized.
> > > > >
> > > > > > M62 <- glmer(IBI~normDens+normRain + (1|MatID), family=Gamma, nAGQ=2,data=Sim)
> > > > >
> > > > > boundary (singular) fit: see ?isSingular
> > > > >
> > > > > > summary(M62)
> > > > >
> > > > > Generalized linear mixed model fit by maximum likelihood (Adaptive Gauss-Hermite Quadrature, nAGQ = 2) ['glmerMod']
> > > > >
> > > > > Family: Gamma( inverse )
> > > > >
> > > > > Formula: IBI ~ normDens + normRain + (1 | MatID)
> > > > >
> > > > > Data: Sim
> > > > >
> > > > > AICBIClogLik deviance df.resid
> > > > >
> > > > > 21.742.8-5.911.7495
> > > > >
> > > > > Scaled residuals:
> > > > >
> > > > > Min1QMedian3QMax
> > > > >
> > > > > -2.3532 -0.6617 -0.13050.51013.4180
> > > > >
> > > > > Random effects:
> > > > >
> > > > > GroupsNameVariance Std.Dev.
> > > > >
> > > > > MatID(Intercept) 0.000000.0000
> > > > >
> > > > > Residual0.024160.1554
> > > > >
> > > > > Number of obs: 500, groups:MatID, 99
> > > > >
> > > > > Fixed effects:
> > > > >
> > > > > Estimate Std. Error t value Pr(>|z|)
> > > > >
> > > > > (Intercept)0.02882820.001300822.161< 2e-16 ***
> > > > >
> > > > > normDens-0.00392740.0012153-3.2320.00123 **
> > > > >
> > > > > normRain0.00027830.00129940.2140.83042
> > > > >
> > > > > Signif. codes:0 ?? 0.001 ?? 0.01 ?? 0.05 ?.? 0.1 ? ? 1
> > > > >
> > > > > Correlation of Fixed Effects:
> > > > >
> > > > > (Intr) nrmDns
> > > > >
> > > > > normDens -0.275
> > > > >
> > > > > normRain0.019 -0.019
> > > > >
> > > > > convergence code: 0
> > > > >
> > > > > boundary (singular) fit: see ?isSingular
> > > > >
> > > > > > M65 <- glmer(IBI~normDens+normRain + (1|MatID), family=Gamma, nAGQ=5,data=Sim)
> > > > >
> > > > > > summary(M65)
> > > > >
> > > > > Generalized linear mixed model fit by maximum likelihood (Adaptive Gauss-Hermite Quadrature, nAGQ = 5) ['glmerMod']
> > > > >
> > > > > Family: Gamma( inverse )
> > > > >
> > > > > Formula: IBI ~ normDens + normRain + (1 | MatID)
> > > > >
> > > > > Data: Sim
> > > > >
> > > > > AICBIClogLik deviance df.resid
> > > > >
> > > > > InfInf-InfInf495
> > > > >
> > > > > Scaled residuals:
> > > > >
> > > > > Min1QMedian3QMax
> > > > >
> > > > > -2.2488 -0.39020.03160.34851.7127
> > > > >
> > > > > Random effects:
> > > > >
> > > > > GroupsNameVarianceStd.Dev.
> > > > >
> > > > > MatID(Intercept) 6.007e-06 0.002451
> > > > >
> > > > > Residual8.831e-04 0.029716
> > > > >
> > > > > Number of obs: 500, groups:MatID, 99
> > > > >
> > > > > Fixed effects:
> > > > >
> > > > > Estimate Std. Error t value Pr(>|z|)
> > > > >
> > > > > (Intercept)2.936e-022.495e-04117.68<2e-16 ***
> > > > >
> > > > > normDens-2.182e-031.163e-04-18.76<2e-16 ***
> > > > >
> > > > > normRain4.883e-043.973e-0512.29<2e-16 ***
> > > > >
> > > > > Signif. codes:0 ?? 0.001 ?? 0.01 ?? 0.05 ?.? 0.1 ? ? 1
> > > > >
> > > > > Correlation of Fixed Effects:
> > > > >
> > > > > (Intr) nrmDns
> > > > >
> > > > > normDens -0.013
> > > > >
> > > > > normRain0.004 -0.041
> > > > >
> > > > > convergence code: 0
> > > > >
> > > > > Gradient contains NAs
> > > > >
> > > > > Warning messages:
> > > > >
> > > > > 1: In vcov.merMod(object, use.hessian = use.hessian) :
> > > > >
> > > > > variance-covariance matrix computed from finite-difference Hessian is
> > > > >
> > > > > not positive definite or contains NA values: falling back to var-cov estimated from RX
> > > > >
> > > > > 2: In vcov.merMod(object, correlation = correlation, sigm = sig) :
> > > > >
> > > > > variance-covariance matrix computed from finite-difference Hessian is
> > > > >
> > > > > not positive definite or contains NA values: falling back to var-cov estimated from RX
> > > > >
> > > > > For comparison, the linear model seems to be well behaved:
> > > > >
> > > > > M1 <- lmer(IBI~normDens+normRain +(1|MatID), REML=FALSE, data=Sim)
> > > > >
> > > > > summary(M1)
> > > > >
> > > > > Linear mixed model fit by maximum likelihood
> > > > >
> > > > > ['lmerMod']
> > > > >
> > > > > Formula: IBI ~ normDens + normRain + (1 | MatID)
> > > > >
> > > > > Data: Sim
> > > > >
> > > > > AIC
> > > > >
> > > > > BIC
> > > > >
> > > > > logLik deviance df.resid
> > > > >
> > > > > 1804.2
> > > > >
> > > > > 1825.2
> > > > >
> > > > > -897.1
> > > > >
> > > > > 1794.2
> > > > >
> > > > > 495
> > > > >
> > > > > Scaled residuals:
> > > > >
> > > > > Min
> > > > >
> > > > > 1Q
> > > > >
> > > > > Median
> > > > >
> > > > > 3Q
> > > > >
> > > > > Max
> > > > >
> > > > > -3.2970 -0.5304
> > > > >
> > > > > 0.0153
> > > > >
> > > > > 0.5484
> > > > >
> > > > > 3.4798
> > > > >
> > > > > Random effects:
> > > > >
> > > > > Groups
> > > > >
> > > > > Name
> > > > >
> > > > > Variance Std.Dev.
> > > > >
> > > > > MatID
> > > > >
> > > > > (Intercept) 43.5694
> > > > >
> > > > > 6.6007
> > > > >
> > > > > Residual
> > > > >
> > > > > 0.6737
> > > > >
> > > > > 0.8208
> > > > >
> > > > > Number of obs: 500, groups:
> > > > >
> > > > > MatID, 99
> > > > >
> > > > > Fixed effects:
> > > > >
> > > > > Estimate Std. Error t value
> > > > >
> > > > > (Intercept) 35.47121
> > > > >
> > > > > 0.66443
> > > > >
> > > > > 53.39
> > > > >
> > > > > normDens
> > > > >
> > > > > 2.00732
> > > > >
> > > > > 0.11816
> > > > >
> > > > > 16.99
> > > > >
> > > > > normRain
> > > > >
> > > > > -0.71747
> > > > >
> > > > > 0.04237
> > > > >
> > > > > -16.93
> > > > >
> > > > > Correlation of Fixed Effects:
> > > > >
> > > > > (Intr) nrmDns
> > > > >
> > > > > normDens -0.002
> > > > >
> > > > > normRain
> > > > >
> > > > > 0.000 -0.044
> > > > >
> > > > > Should I just conclude that the data is not well modelled by a Gamma GLMM?
> > > > >
> > > > > Peter R Law
> > > > >
> > > > > Research Associate
> > > > >
> > > > > Center for African Conservation Ecology
> > > > >
> > > > > Nelson Mandela University
> > > > >
> > > > > South Africa
> > > > >
> > > > > Sent with ProtonMail Secure Email.
> > > > >
> > > > > [[alternative HTML version deleted]]
> > > >
> > > > R-sig-mixed-models at r-project.org mailing list
> > > >
> > > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >
> > > R-sig-mixed-models at r-project.org mailing list
> > >
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbo|ker @end|ng |rom gm@||@com  Thu Jun 24 16:56:13 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 24 Jun 2021 10:56:13 -0400
Subject: [R-sig-ME] Fw: glmer and nAGQ
In-Reply-To: <LNnAz-OD7BJ9VSGO8RarV2UtO6AP82-oxLiYGqm-CuqYzm5AL_3QN-De_mLduTYGSa49c3CIQmFx5Xp1ELtdx3zSG3zSyRGGE0qQNvf21dc=@protonmail.com>
References: <IaPuZYIQ_b0xc3TiOKKB7qUSl_oIrJs3qAAhv0FzcMEmNLhnqVk2YTt7MujmZrjXeK2HmDlukIhdfOYOzYtSACRBseVXSGHWX01pVwXM3IA=@protonmail.com>
 <eRi5lAvI3CZFpoVa8IsTe5tGL_XcunhS6SO19GpY3rHle2EAxwTwqPoXdjNc08xqm-V6bHJFOWwEMh5uGETjT0_tZXZjbp_wVZ02j2HtckI=@protonmail.com>
 <ecb77626-a725-bb11-eead-9a00e21f71ce@gmail.com>
 <CMAdImRcLjL5-85lpWAMiEgGkFecpFON3PRPgT2K0GyVYJzWqpfgCDRttmpyV4R_OMXMHP6zTMTBVOZTjKNI9n6hU77F8_u1XpPboKK6ca8=@protonmail.com>
 <bda8afa0-0ee9-5b52-cc58-e865009661ba@gmail.com>
 <LNnAz-OD7BJ9VSGO8RarV2UtO6AP82-oxLiYGqm-CuqYzm5AL_3QN-De_mLduTYGSa49c3CIQmFx5Xp1ELtdx3zSG3zSyRGGE0qQNvf21dc=@protonmail.com>
Message-ID: <3838ed5d-0748-1150-106e-f945c39067c7@gmail.com>

  It's hard to make many more conclusions without digging into the 
particular data set.

   It might be worth comparing results from other packages, although 
GLMMadaptive is the only other package that I'm aware of that 
robustly/flexibly provides adaptive Gauss-Hermite quadrature.

   I also note lots of 'singular fit' messages below; that doesn't mean 
the fits are wrong, but does mean that you might need to consider 
whether you have enough signal to estimate the random effect variance ...

On 6/23/21 10:39 PM, Peter R Law wrote:
> Thanks again for your feedback. Much appreciated. With the canonical link in the Gamma model, once a neg infinity result is returned for the logLik (n=4 for my simulation data), increasing the value of nAGQ doesn't change that result and the warning message about the estimated variance-covariance matrix not being positive definite is constant also.
> 
> If I use the log link, there is a large increase (-678.1 to -5.6) in the LogLik in going from the default value of n=1 to n=2, but it then doesn't change for larger n values and the model results are stable.
> 
> So I assume then that the Gamma model with the canonical link cannot be fit to this data while with the log link one does get a robust result?
> 
> There was no detectable delay in the time to run the model with nAGQ = 25 versus the default value. Is that suspicious?
> 
> Peter
> 
> 
> 
> Sent with ProtonMail Secure Email.
> 
> ??????? Original Message ???????
> 
> On Friday, June 18th, 2021 at 8:16 PM, Ben Bolker <bbolker at gmail.com> wrote:
> 
>> On 6/18/21 6:39 PM, Peter R Law wrote:
>>
>>> Thanks for your response. I'm sorry the formatting of the R output got messed up and hard to read when I forwarded the original message. I do understand that changing the value of nAGQ is changing the approximation of the likelihood, not changing the model itself. I wondered whether the change in likelihood from -643.8 (n=1) to -5.9 (n=2) to -inf (n=3) was a reason to suspect the model was badly behaved in that none of these approximations of the logLik should be trusted. The parameter estimates for the fixed effects don't change that much, basically just the logLik and consequently the AIC. I wanted to compare the glmer with a Gamma distribution to the lmer to see whether AIC favoured one over the other. My intent was to start with the glmer with default n=1, then increase n until model parameters seemed stable, then use that n value for the glmer model to obtain a logLik and then AIC to compare to the lmer version. But the dramatic differences in logLik in going from n=1 to n= 2 and the negative infinite value already for n=3 I thought might suggest that none of these logLiks should be trusted and the the Gamma model simply abandoned. Does that sound plausible in light of the warning messages? In particular, that the negative infinity answer is a failuer in the estimation procedure rather than an indication that that the Gamma model has zero likelihood?
>>
>> As I suggested in my answer, you shouldn't worry about the big jump
>>
>> in log-likelihood from nAGQ=1 to nAGQ=2. I would try n=5, 10, 15, 20 and
>>
>> see how it goes (unless n=20 is too slow to be practical). (Yes, I think
>>
>> -Inf is a problem with the fitting procedure)
>>
>>> I will repeat the analyses with the log link. As far as the data is concerned, it's simulated data I created without using any distributional assumptions but rather based on ecological assumptions for how the response might depend on the fixed predictors. My purpose here is to explore the glmer function in preparation for a study with real data (still being collected). Because the responses are positive values, I thought it would be worth investigating how a Gamma glmer compares with an lmer (and compare both with a log-normal model, after making the adjustment in the latter so that its AIC is comparable to the others, as was pointed out in a previous posting).
>>
>> Fair enough; "without any distributional assumptions" is a bit odd
>>
>> though. Unless your ecological model is stochastic (in which case the
>>
>> conditional distribution will emerge naturally from the model), you have
>>
>> to make some assumptions about how the observations will vary around
>>
>> the expected mean ...
>>
>> cheers
>>
>> Ben Bolker
>>
>>> Peter
>>>
>>> Sent with ProtonMail Secure Email.
>>>
>>> ??????? Original Message ???????
>>>
>>> On Friday, June 18th, 2021 at 5:44 PM, Ben Bolker bbolker at gmail.com wrote:
>>>
>>>> This is kind of hard to read, but I'll try.
>>>>
>>>> First of all, log-likelihoods with nAGQ>1 (adaptive Gauss-Hermite
>>>>
>>>> quadrature) **are not currently commensurate with log-likelihoods with
>>>>
>>>> nAGQ==1 (Laplace approximation). This is hinted at in the "Deviance and
>>>>
>>>> log-likelihood of GLMMs" section under "Deviance and log-likelihood of
>>>>
>>>> GLMMs".
>>>>
>>>> In any case, the log-likelihoods computed under different numbers of
>>>>
>>>> quadrature points aren't comparable as though they were different
>>>>
>>>> statistical models (AIC, likelihood ratio tests, etc.). Rather, they are
>>>>
>>>> based on different approximations to the same model, and we know
>>>>
>>>> that larger numbers of quadrature points (increasing nAGQ) are more
>>>>
>>>> accurate (although slower) approximations. The main thing is to see if
>>>>
>>>> results (parameter estimates etc.) change as nAGQ increases by a
>>>>
>>>> magnitude that is important for the current analysis ... if they do,
>>>>
>>>> then you should use an nAGQ that is large enough that it approximates
>>>>
>>>> "infinity", i.e. increasing nAGQ further doesn't change the answers by
>>>>
>>>> an important amount.
>>>>
>>>> In general if it is not important to you to use the inverse link (for
>>>>
>>>> interpretation/because you think this will be the natural scale on which
>>>>
>>>> to measure effects of continuous parameters and/or interactions),
>>>>
>>>> Gamma(link="log") is generally more robust.
>>>>
>>>> The "rescale variables?" suggestion is just that; if the parameters
>>>>
>>>> are already rescaled, then it's not going to help. A large eigenvalue
>>>>
>>>> may not actually be a problem, it just indicates the possibility of
>>>>
>>>> numerical instability. In this case my guess is that the very small
>>>>
>>>> random effects variance might be responsible.
>>>>
>>>> It's also a little surprising that the normRain coefficient is very
>>>>
>>>> small in magnitude and yet but has a very large Z-statistic, given this
>>>>
>>>> sample size.
>>>>
>>>> The results with increasing AGQ do indeed look kind of wonky. If this
>>>>
>>>> were my problem I would want to look more carefully at the data/think
>>>>
>>>> about where they came from. How do the model diagnostics look?
>>>>
>>>> On 6/18/21 3:52 PM, Peter R Law via R-sig-mixed-models wrote:
>>>>
>>>>> I am re-sending this query that I originally emailed June 13'th. I did not receive a copy of the sent email as I have with previous postings and my query doesn't appear in the archive of postings so does not seem to have been received.
>>>>>
>>>>> Peter R Law
>>>>>
>>>>> Sent with ProtonMail Secure Email.
>>>>>
>>>>> ??????? Original Message ???????
>>>>>
>>>>> On Monday, June 14th, 2021 at 10:48 PM, Peter R Law prldb at protonmail.com wrote:
>>>>>
>>>>>> Any help with the following query is much appreciated.
>>>>>>
>>>>>> I used some simulated data (not generated under any specific distributional assumption but all responses are positive quantities) to investigate the nAGQ argument in glmer, running a Gamma-distribution model. With nAAGQ=2 the logLik is dramatically different to the default value of nAGQ=1, while nAGQ=5 returned minus infinity for the logLik, but the estimates of the fixed effect parameters are somewhat consistent across each computation. Are the differences in the estimated logLik surprising or do they reflect the warnings glmer returns for this attempted modelling? I got similar results for a real dataset too.
>>>>>>
>>>>>> data.frame':500 obs. of8 variables:
>>>>>>
>>>>>> $ IBI: num25.5 25.4 25.2 25.6 25.8 ...
>>>>>>
>>>>>> $ MatID: Factor w/ 99 levels "M1","M10","M11",..: 1 1 1 1 1 12 12 12 12 12 ...
>>>>>>
>>>>>> $ Pop: Factor w/ 5 levels "P1","P2","P3",..: 1 1 1 1 1 1 1 1 1 1 ...
>>>>>>
>>>>>> $ density : int11 13 15 19 28 11 13 15 19 28 ...
>>>>>>
>>>>>> $ rain: num41.1 36.6 31.6 40 40.6 ...
>>>>>>
>>>>>> $ normIBI : num-1.28 -1.29 -1.31 -1.26 -1.24 ...
>>>>>>
>>>>>> $ normDens: num-1.72 -1.66 -1.61 -1.49 -1.23 ...
>>>>>>
>>>>>> $ normRain: num-0.249 -0.64 -1.073 -0.345 -0.287 ...
>>>>>>
>>>>>>> M61 <- glmer(IBI~normDens+normRain + (1|MatID), family=Gamma, data=Sim)
>>>>>>
>>>>>> Warning message:
>>>>>>
>>>>>> In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,:
>>>>>>
>>>>>> Model is nearly unidentifiable: very large eigenvalue
>>>>>>
>>>>>> -   Rescale variables?
>>>>>>
>>>>>>> summary(M61)
>>>>>>
>>>>>> Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
>>>>>>
>>>>>> Family: Gamma( inverse )
>>>>>>
>>>>>> Formula: IBI ~ normDens + normRain + (1 | MatID)
>>>>>>
>>>>>> Data: Sim
>>>>>>
>>>>>> AICBIClogLik deviance df.resid
>>>>>>
>>>>>> 1297.61318.7-643.81287.6495
>>>>>>
>>>>>> Scaled residuals:
>>>>>>
>>>>>> Min1QMedian3QMax
>>>>>>
>>>>>> -1.58054 -0.306190.041690.367441.31012
>>>>>>
>>>>>> Random effects:
>>>>>>
>>>>>> GroupsNameVarianceStd.Dev.
>>>>>>
>>>>>> MatID(Intercept) 5.802e-06 0.002409
>>>>>>
>>>>>> Residual1.368e-03 0.036989
>>>>>>
>>>>>> Number of obs: 500, groups:MatID, 99
>>>>>>
>>>>>> Fixed effects:
>>>>>>
>>>>>> Estimate Std. Error t value Pr(>|z|)
>>>>>>
>>>>>> (Intercept)3.083e-026.090e-0450.63<2e-16 ***
>>>>>>
>>>>>> normDens -1.720e-037.946e-05-21.65<2e-16 ***
>>>>>>
>>>>>> normRain4.889e-042.463e-0519.85<2e-16 ***
>>>>>>
>>>>>> Signif. codes:0 ?? 0.001 ?? 0.01 ?? 0.05 ?.? 0.1 ? ? 1
>>>>>>
>>>>>> Correlation of Fixed Effects:
>>>>>>
>>>>>> (Intr) nrmDns
>>>>>>
>>>>>> normDens0.028
>>>>>>
>>>>>> normRain0.000 -0.044
>>>>>>
>>>>>> convergence code: 0
>>>>>>
>>>>>> Model is nearly unidentifiable: very large eigenvalue
>>>>>>
>>>>>> -   Rescale variables?
>>>>>>
>>>>>> What kind of scaling is being suggested in the case of the default value of nAGQ? The predictors are already normalized.
>>>>>>
>>>>>>> M62 <- glmer(IBI~normDens+normRain + (1|MatID), family=Gamma, nAGQ=2,data=Sim)
>>>>>>
>>>>>> boundary (singular) fit: see ?isSingular
>>>>>>
>>>>>>> summary(M62)
>>>>>>
>>>>>> Generalized linear mixed model fit by maximum likelihood (Adaptive Gauss-Hermite Quadrature, nAGQ = 2) ['glmerMod']
>>>>>>
>>>>>> Family: Gamma( inverse )
>>>>>>
>>>>>> Formula: IBI ~ normDens + normRain + (1 | MatID)
>>>>>>
>>>>>> Data: Sim
>>>>>>
>>>>>> AICBIClogLik deviance df.resid
>>>>>>
>>>>>> 21.742.8-5.911.7495
>>>>>>
>>>>>> Scaled residuals:
>>>>>>
>>>>>> Min1QMedian3QMax
>>>>>>
>>>>>> -2.3532 -0.6617 -0.13050.51013.4180
>>>>>>
>>>>>> Random effects:
>>>>>>
>>>>>> GroupsNameVariance Std.Dev.
>>>>>>
>>>>>> MatID(Intercept) 0.000000.0000
>>>>>>
>>>>>> Residual0.024160.1554
>>>>>>
>>>>>> Number of obs: 500, groups:MatID, 99
>>>>>>
>>>>>> Fixed effects:
>>>>>>
>>>>>> Estimate Std. Error t value Pr(>|z|)
>>>>>>
>>>>>> (Intercept)0.02882820.001300822.161< 2e-16 ***
>>>>>>
>>>>>> normDens-0.00392740.0012153-3.2320.00123 **
>>>>>>
>>>>>> normRain0.00027830.00129940.2140.83042
>>>>>>
>>>>>> Signif. codes:0 ?? 0.001 ?? 0.01 ?? 0.05 ?.? 0.1 ? ? 1
>>>>>>
>>>>>> Correlation of Fixed Effects:
>>>>>>
>>>>>> (Intr) nrmDns
>>>>>>
>>>>>> normDens -0.275
>>>>>>
>>>>>> normRain0.019 -0.019
>>>>>>
>>>>>> convergence code: 0
>>>>>>
>>>>>> boundary (singular) fit: see ?isSingular
>>>>>>
>>>>>>> M65 <- glmer(IBI~normDens+normRain + (1|MatID), family=Gamma, nAGQ=5,data=Sim)
>>>>>>
>>>>>>> summary(M65)
>>>>>>
>>>>>> Generalized linear mixed model fit by maximum likelihood (Adaptive Gauss-Hermite Quadrature, nAGQ = 5) ['glmerMod']
>>>>>>
>>>>>> Family: Gamma( inverse )
>>>>>>
>>>>>> Formula: IBI ~ normDens + normRain + (1 | MatID)
>>>>>>
>>>>>> Data: Sim
>>>>>>
>>>>>> AICBIClogLik deviance df.resid
>>>>>>
>>>>>> InfInf-InfInf495
>>>>>>
>>>>>> Scaled residuals:
>>>>>>
>>>>>> Min1QMedian3QMax
>>>>>>
>>>>>> -2.2488 -0.39020.03160.34851.7127
>>>>>>
>>>>>> Random effects:
>>>>>>
>>>>>> GroupsNameVarianceStd.Dev.
>>>>>>
>>>>>> MatID(Intercept) 6.007e-06 0.002451
>>>>>>
>>>>>> Residual8.831e-04 0.029716
>>>>>>
>>>>>> Number of obs: 500, groups:MatID, 99
>>>>>>
>>>>>> Fixed effects:
>>>>>>
>>>>>> Estimate Std. Error t value Pr(>|z|)
>>>>>>
>>>>>> (Intercept)2.936e-022.495e-04117.68<2e-16 ***
>>>>>>
>>>>>> normDens-2.182e-031.163e-04-18.76<2e-16 ***
>>>>>>
>>>>>> normRain4.883e-043.973e-0512.29<2e-16 ***
>>>>>>
>>>>>> Signif. codes:0 ?? 0.001 ?? 0.01 ?? 0.05 ?.? 0.1 ? ? 1
>>>>>>
>>>>>> Correlation of Fixed Effects:
>>>>>>
>>>>>> (Intr) nrmDns
>>>>>>
>>>>>> normDens -0.013
>>>>>>
>>>>>> normRain0.004 -0.041
>>>>>>
>>>>>> convergence code: 0
>>>>>>
>>>>>> Gradient contains NAs
>>>>>>
>>>>>> Warning messages:
>>>>>>
>>>>>> 1: In vcov.merMod(object, use.hessian = use.hessian) :
>>>>>>
>>>>>> variance-covariance matrix computed from finite-difference Hessian is
>>>>>>
>>>>>> not positive definite or contains NA values: falling back to var-cov estimated from RX
>>>>>>
>>>>>> 2: In vcov.merMod(object, correlation = correlation, sigm = sig) :
>>>>>>
>>>>>> variance-covariance matrix computed from finite-difference Hessian is
>>>>>>
>>>>>> not positive definite or contains NA values: falling back to var-cov estimated from RX
>>>>>>
>>>>>> For comparison, the linear model seems to be well behaved:
>>>>>>
>>>>>> M1 <- lmer(IBI~normDens+normRain +(1|MatID), REML=FALSE, data=Sim)
>>>>>>
>>>>>> summary(M1)
>>>>>>
>>>>>> Linear mixed model fit by maximum likelihood
>>>>>>
>>>>>> ['lmerMod']
>>>>>>
>>>>>> Formula: IBI ~ normDens + normRain + (1 | MatID)
>>>>>>
>>>>>> Data: Sim
>>>>>>
>>>>>> AIC
>>>>>>
>>>>>> BIC
>>>>>>
>>>>>> logLik deviance df.resid
>>>>>>
>>>>>> 1804.2
>>>>>>
>>>>>> 1825.2
>>>>>>
>>>>>> -897.1
>>>>>>
>>>>>> 1794.2
>>>>>>
>>>>>> 495
>>>>>>
>>>>>> Scaled residuals:
>>>>>>
>>>>>> Min
>>>>>>
>>>>>> 1Q
>>>>>>
>>>>>> Median
>>>>>>
>>>>>> 3Q
>>>>>>
>>>>>> Max
>>>>>>
>>>>>> -3.2970 -0.5304
>>>>>>
>>>>>> 0.0153
>>>>>>
>>>>>> 0.5484
>>>>>>
>>>>>> 3.4798
>>>>>>
>>>>>> Random effects:
>>>>>>
>>>>>> Groups
>>>>>>
>>>>>> Name
>>>>>>
>>>>>> Variance Std.Dev.
>>>>>>
>>>>>> MatID
>>>>>>
>>>>>> (Intercept) 43.5694
>>>>>>
>>>>>> 6.6007
>>>>>>
>>>>>> Residual
>>>>>>
>>>>>> 0.6737
>>>>>>
>>>>>> 0.8208
>>>>>>
>>>>>> Number of obs: 500, groups:
>>>>>>
>>>>>> MatID, 99
>>>>>>
>>>>>> Fixed effects:
>>>>>>
>>>>>> Estimate Std. Error t value
>>>>>>
>>>>>> (Intercept) 35.47121
>>>>>>
>>>>>> 0.66443
>>>>>>
>>>>>> 53.39
>>>>>>
>>>>>> normDens
>>>>>>
>>>>>> 2.00732
>>>>>>
>>>>>> 0.11816
>>>>>>
>>>>>> 16.99
>>>>>>
>>>>>> normRain
>>>>>>
>>>>>> -0.71747
>>>>>>
>>>>>> 0.04237
>>>>>>
>>>>>> -16.93
>>>>>>
>>>>>> Correlation of Fixed Effects:
>>>>>>
>>>>>> (Intr) nrmDns
>>>>>>
>>>>>> normDens -0.002
>>>>>>
>>>>>> normRain
>>>>>>
>>>>>> 0.000 -0.044
>>>>>>
>>>>>> Should I just conclude that the data is not well modelled by a Gamma GLMM?
>>>>>>
>>>>>> Peter R Law
>>>>>>
>>>>>> Research Associate
>>>>>>
>>>>>> Center for African Conservation Ecology
>>>>>>
>>>>>> Nelson Mandela University
>>>>>>
>>>>>> South Africa
>>>>>>
>>>>>> Sent with ProtonMail Secure Email.
>>>>>>
>>>>>> [[alternative HTML version deleted]]
>>>>>
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>> R-sig-mixed-models at r-project.org mailing list
>>>>
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From w||||@m@@||ver @end|ng |rom @tc@tz@ox@@c@uk  Thu Jun 24 17:40:08 2021
From: w||||@m@@||ver @end|ng |rom @tc@tz@ox@@c@uk (William Silver)
Date: Thu, 24 Jun 2021 15:40:08 +0000
Subject: [R-sig-ME] Query about fitting glmmTMB zero-inflated negative
 binomial model
Message-ID: <LO2P265MB33445C48FB8FDE105AAE8E8396079@LO2P265MB3344.GBRP265.PROD.OUTLOOK.COM>

Hi there,

I?ve been referred to post my problem on this mailing list, so apologies in advance if I?m not following best practice.

Essentially, I?m attempting to fit two zero-inflated negative binomial models. My two dependent variables are mode of accessing a news website (i.e., through social media, or through search engine) and I have raw counts for each individual (N = 900). Zero-inflated models are most theoretically plausible because some people do not use social media or search engines to access news. The distribution is extremely right skewed with an excess of zeros, and the right tail extends far out. On the advice of my professor, I truncated the models to exclude the 10-20 participants with extremely high counts, so that outliers would not be driving the model. Initially, I was met with NAs in the model summary and followed Ben Bolker?s advice here<https://stackoverflow.com/questions/62239351/why-am-i-getting-nas-in-the-model-summary-output-zero-inflated-glmm-with-glmmtm>. I looked for combinations of categories that were zero, and the categories I?ve found I have either dropped or combined. This fixed the NA issue initially when I ran the model with a different optimiser, following Ben Bolker?s advice here<https://stackoverflow.com/questions/62478569/understanding-and-fixing-false-convergence-errors-in-glmmtmb-lme4>, however this still seems to be a problem depending on which variables I include. I?ve pasted the model output below in which the standard errors look much more normal, however when running analysis of residuals, there are some significant problems.

The problem I?m now met with a number of various warnings about model convergence which I?ve been unable to resolve. The first was ?Error in e_complex_check(eigs$values) : detected complex eigenvalues of covariance matrix (max(abs(Im))=3.48036e-15: try se=FALSE??, which disappears when including se=FALSE in the command. I?m then met with ?Warning: In fitTMB(TMBStruc) : Model convergence problem. See vignette('troubleshooting')?. I?ve consulted the vignette<https://cran.r-project.org/web/packages/glmmTMB/vignettes/troubleshooting.html> it directs to, but am fairly new to statistics and find this all fairly advanced. I?ve tried applying the diagnose_vcov function, but am unsure how to interpret the results. Can I trust these models, given these warnings? Are there any recommendations someone might have for addressing the warnings if they are a significant issue?

These errors are only occurring in the ZINB models (and this is the case for both glmmTMB and pscl packages). The ZI poisson models on the same variables run fine, but suffer from overdispersion (with which I hoped to solve by using the ZINB technique because it is better adapted for dealing with this). Ideally, I?d use the ZINB models over the ZIP models as they are better suited, but am wary of using them given these seemingly unresolvable warnings. I?d really appreciate any guidance anyone could give.

Thank you so much in advance,

Best wishes,

William

Output:

zinb.am.se.test = glmmTMB(total_se_refer ~ diet_rob + polinterest + poleffic + age + trstmedia_sm + dummy_L_all + dummy_C_all + female_dum + trstmedia_sm + trstmedia_public, ziformula = ~ diet_rob + polinterest + poleffic + age + trstmedia_sm + dummy_L_all + dummy_C_all + female_dum + trstmedia_sm + trstmedia_public, data=df.trunc.se , family = nbinom1, se = FALSE, control = glmmTMBControl(optimizer = optim, optArgs = list(method="CG")))
Warning message:
In fitTMB(TMBStruc) :
  Model convergence problem; . See vignette('troubleshooting')
> summary(zinb.am.se.test)
Family: nbinom1  ( log )
Formula:          total_se_refer ~ diet_rob + polinterest + poleffic + age + trstmedia_sm +
    dummy_L_all + dummy_C_all + female_dum + trstmedia_sm + trstmedia_public
Zero inflation:
~diet_rob + polinterest + poleffic + age + trstmedia_sm + dummy_L_all +
    dummy_C_all + female_dum + trstmedia_sm + trstmedia_public
Data: df.trunc.se

     AIC      BIC   logLik deviance df.resid
  8316.0   8417.3  -4137.0   8274.0      899


Dispersion parameter for nbinom1 family (): 2.87

Conditional model:
                  Estimate Std. Error z value Pr(>|z|)
(Intercept)       0.096117   0.168652   0.570 0.568738
diet_rob         -0.007591   0.138051  -0.055 0.956151
polinterest       0.211511   0.030390   6.960  3.4e-12 ***
poleffic          0.089956   0.009867   9.117  < 2e-16 ***
age               0.001146   0.001934   0.592 0.553555
trstmedia_sm      0.090851   0.026701   3.402 0.000668 ***
dummy_L_all       0.088489   0.069593   1.272 0.203539
dummy_C_all      -0.035509   0.062070  -0.572 0.567264
female_dum        0.049242   0.053296   0.924 0.355518
trstmedia_public  0.165294   0.027917   5.921  3.2e-09 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Zero-inflation model:
                  Estimate Std. Error z value Pr(>|z|)
(Intercept)      -0.018224   0.425006  -0.043   0.9658
diet_rob          0.005089   0.404882   0.013   0.9900
polinterest      -0.046104   0.087863  -0.525   0.5998
poleffic         -0.062502   0.028639  -2.182   0.0291 *
age              -0.001789   0.005584  -0.320   0.7487
trstmedia_sm     -0.042205   0.085556  -0.493   0.6218
dummy_L_all      -0.005172   0.209608  -0.025   0.9803
dummy_C_all      -0.005723   0.183298  -0.031   0.9751
female_dum       -0.007491   0.165891  -0.045   0.9640
trstmedia_public -0.049461   0.082624  -0.599   0.5494
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
Warning messages:
1: In vcov.glmmTMB(object, include_mapped = TRUE) :
  Calculating sdreport. Use se=TRUE in glmmTMB to avoid repetitive calculation of sdreport
2: In vcov.glmmTMB(object) :
  Calculating sdreport. Use se=TRUE in glmmTMB to avoid repetitive calculation of sdreport

> summary(zinb.am.sm.test)
Family: nbinom1  ( log )
Formula:          total_sm_refer ~ diet_rob + polinterest + poleffic + age + trstmedia_sm +
    dummy_L_all + dummy_C_all + female_dum + trstmedia_sm + trstmedia_public
Zero inflation:
~diet_rob + polinterest + poleffic + age + trstmedia_sm + dummy_L_all +
    dummy_C_all + female_dum + trstmedia_sm + trstmedia_public
Data: df.trunc.sm

     AIC      BIC   logLik deviance df.resid
  5259.0   5360.3  -2608.5   5217.0      902


Dispersion parameter for nbinom1 family (): 10.6

Conditional model:
                 Estimate Std. Error z value Pr(>|z|)
(Intercept)       0.10901    0.68090   0.160   0.8728
diet_rob          0.08175    0.65938   0.124   0.9013
polinterest       0.15325    0.11435   1.340   0.1802
poleffic          0.03901    0.13561   0.288   0.7736
age               0.01047    0.01093   0.958   0.3379
trstmedia_sm      0.24108    0.13696   1.760   0.0784 .
dummy_L_all       0.16702    0.89975   0.186   0.8527
dummy_C_all       0.01118    1.46559   0.008   0.9939
female_dum        0.12071    0.65590   0.184   0.8540
trstmedia_public -0.01846    0.32520  -0.057   0.9547
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Zero-inflation model:
                   Estimate Std. Error z value Pr(>|z|)
(Intercept)      -0.0301001  1.3829502  -0.022    0.983
diet_rob         -0.0233937  2.3407518  -0.010    0.992
polinterest      -0.0897813  0.3597496  -0.250    0.803
poleffic         -0.0455312  0.3529030  -0.129    0.897
age              -0.0003903  0.0204699  -0.019    0.985
trstmedia_sm     -0.0884604  0.1374919  -0.643    0.520
dummy_L_all      -0.0205767  2.2994896  -0.009    0.993
dummy_C_all      -0.0167199  3.9414142  -0.004    0.997
female_dum       -0.0339406  1.8302418  -0.018    0.985
trstmedia_public -0.0408538  0.6763691  -0.060    0.952
Warning messages:
1: In vcov.glmmTMB(object, include_mapped = TRUE) :
  Calculating sdreport. Use se=TRUE in glmmTMB to avoid repetitive calculation of sdreport
2: In vcov.glmmTMB(object) :
  Calculating sdreport. Use se=TRUE in glmmTMB to avoid repetitive calculation of sdreport

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Thu Jun 24 17:52:48 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 24 Jun 2021 11:52:48 -0400
Subject: [R-sig-ME] Query about fitting glmmTMB zero-inflated negative
 binomial model
In-Reply-To: <LO2P265MB33445C48FB8FDE105AAE8E8396079@LO2P265MB3344.GBRP265.PROD.OUTLOOK.COM>
References: <LO2P265MB33445C48FB8FDE105AAE8E8396079@LO2P265MB3344.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <76137951-9000-0f04-ca1e-c6b710f6edea@gmail.com>

   A few quick comments:

   Since you're not using any random effects, you could also try this in 
the pscl package (although I think it offers only ZIP and ZINB2, not 
ZINB1 as you're fitting below).

   If your conditional and z-i models are the same I think you can use 
zi = ~ . as shorthand

   A new version of glmmTMB (1.1.1) is on CRAN now, although the 
Windows/MacOS binaries aren't built yet (should be in another day or 
so); that will I think resolve the complex-eigenvalue warning you're 
getting below. There's a new (experimental) diagnose() function as well, 
which tries to give more precise guidance.

  You don't need to create dummy variables by hand; R should do that for 
you automatically given the factors.

   I can't easily see what the difference is between your two models 
here (I guess they're using different data sets?)

On 6/24/21 11:40 AM, William Silver wrote:
> Hi there,
> 
> I?ve been referred to post my problem on this mailing list, so apologies in advance if I?m not following best practice.
> 
> Essentially, I?m attempting to fit two zero-inflated negative binomial models. My two dependent variables are mode of accessing a news website (i.e., through social media, or through search engine) and I have raw counts for each individual (N = 900). Zero-inflated models are most theoretically plausible because some people do not use social media or search engines to access news. The distribution is extremely right skewed with an excess of zeros, and the right tail extends far out. On the advice of my professor, I truncated the models to exclude the 10-20 participants with extremely high counts, so that outliers would not be driving the model. Initially, I was met with NAs in the model summary and followed Ben Bolker?s advice here<https://stackoverflow.com/questions/62239351/why-am-i-getting-nas-in-the-model-summary-output-zero-inflated-glmm-with-glmmtm>. I looked for combinations of categories that were zero, and the categories I?ve found I have either dropped or combined. This fixed the NA issue initially when I ran the model with a different optimiser, following Ben Bolker?s advice here<https://stackoverflow.com/questions/62478569/understanding-and-fixing-false-convergence-errors-in-glmmtmb-lme4>, however this still seems to be a problem depending on which variables I include. I?ve pasted the model output below in which the standard errors look much more normal, however when running analysis of residuals, there are some significant problems.
> 
> The problem I?m now met with a number of various warnings about model convergence which I?ve been unable to resolve. The first was ?Error in e_complex_check(eigs$values) : detected complex eigenvalues of covariance matrix (max(abs(Im))=3.48036e-15: try se=FALSE??, which disappears when including se=FALSE in the command. I?m then met with ?Warning: In fitTMB(TMBStruc) : Model convergence problem. See vignette('troubleshooting')?. I?ve consulted the vignette<https://cran.r-project.org/web/packages/glmmTMB/vignettes/troubleshooting.html> it directs to, but am fairly new to statistics and find this all fairly advanced. I?ve tried applying the diagnose_vcov function, but am unsure how to interpret the results. Can I trust these models, given these warnings? Are there any recommendations someone might have for addressing the warnings if they are a significant issue?
> 
> These errors are only occurring in the ZINB models (and this is the case for both glmmTMB and pscl packages). The ZI poisson models on the same variables run fine, but suffer from overdispersion (with which I hoped to solve by using the ZINB technique because it is better adapted for dealing with this). Ideally, I?d use the ZINB models over the ZIP models as they are better suited, but am wary of using them given these seemingly unresolvable warnings. I?d really appreciate any guidance anyone could give.
> 
> Thank you so much in advance,
> 
> Best wishes,
> 
> William
> 
> Output:
> 
> zinb.am.se.test = glmmTMB(total_se_refer ~ diet_rob + polinterest + poleffic + age + trstmedia_sm + dummy_L_all + dummy_C_all + female_dum + trstmedia_sm + trstmedia_public, ziformula = ~ diet_rob + polinterest + poleffic + age + trstmedia_sm + dummy_L_all + dummy_C_all + female_dum + trstmedia_sm + trstmedia_public, data=df.trunc.se , family = nbinom1, se = FALSE, control = glmmTMBControl(optimizer = optim, optArgs = list(method="CG")))
> Warning message:
> In fitTMB(TMBStruc) :
>    Model convergence problem; . See vignette('troubleshooting')
>> summary(zinb.am.se.test)
> Family: nbinom1  ( log )
> Formula:          total_se_refer ~ diet_rob + polinterest + poleffic + age + trstmedia_sm +
>      dummy_L_all + dummy_C_all + female_dum + trstmedia_sm + trstmedia_public
> Zero inflation:
> ~diet_rob + polinterest + poleffic + age + trstmedia_sm + dummy_L_all +
>      dummy_C_all + female_dum + trstmedia_sm + trstmedia_public
> Data: df.trunc.se
> 
>       AIC      BIC   logLik deviance df.resid
>    8316.0   8417.3  -4137.0   8274.0      899
> 
> 
> Dispersion parameter for nbinom1 family (): 2.87
> 
> Conditional model:
>                    Estimate Std. Error z value Pr(>|z|)
> (Intercept)       0.096117   0.168652   0.570 0.568738
> diet_rob         -0.007591   0.138051  -0.055 0.956151
> polinterest       0.211511   0.030390   6.960  3.4e-12 ***
> poleffic          0.089956   0.009867   9.117  < 2e-16 ***
> age               0.001146   0.001934   0.592 0.553555
> trstmedia_sm      0.090851   0.026701   3.402 0.000668 ***
> dummy_L_all       0.088489   0.069593   1.272 0.203539
> dummy_C_all      -0.035509   0.062070  -0.572 0.567264
> female_dum        0.049242   0.053296   0.924 0.355518
> trstmedia_public  0.165294   0.027917   5.921  3.2e-09 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Zero-inflation model:
>                    Estimate Std. Error z value Pr(>|z|)
> (Intercept)      -0.018224   0.425006  -0.043   0.9658
> diet_rob          0.005089   0.404882   0.013   0.9900
> polinterest      -0.046104   0.087863  -0.525   0.5998
> poleffic         -0.062502   0.028639  -2.182   0.0291 *
> age              -0.001789   0.005584  -0.320   0.7487
> trstmedia_sm     -0.042205   0.085556  -0.493   0.6218
> dummy_L_all      -0.005172   0.209608  -0.025   0.9803
> dummy_C_all      -0.005723   0.183298  -0.031   0.9751
> female_dum       -0.007491   0.165891  -0.045   0.9640
> trstmedia_public -0.049461   0.082624  -0.599   0.5494
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> Warning messages:
> 1: In vcov.glmmTMB(object, include_mapped = TRUE) :
>    Calculating sdreport. Use se=TRUE in glmmTMB to avoid repetitive calculation of sdreport
> 2: In vcov.glmmTMB(object) :
>    Calculating sdreport. Use se=TRUE in glmmTMB to avoid repetitive calculation of sdreport
> 
>> summary(zinb.am.sm.test)
> Family: nbinom1  ( log )
> Formula:          total_sm_refer ~ diet_rob + polinterest + poleffic + age + trstmedia_sm +
>      dummy_L_all + dummy_C_all + female_dum + trstmedia_sm + trstmedia_public
> Zero inflation:
> ~diet_rob + polinterest + poleffic + age + trstmedia_sm + dummy_L_all +
>      dummy_C_all + female_dum + trstmedia_sm + trstmedia_public
> Data: df.trunc.sm
> 
>       AIC      BIC   logLik deviance df.resid
>    5259.0   5360.3  -2608.5   5217.0      902
> 
> 
> Dispersion parameter for nbinom1 family (): 10.6
> 
> Conditional model:
>                   Estimate Std. Error z value Pr(>|z|)
> (Intercept)       0.10901    0.68090   0.160   0.8728
> diet_rob          0.08175    0.65938   0.124   0.9013
> polinterest       0.15325    0.11435   1.340   0.1802
> poleffic          0.03901    0.13561   0.288   0.7736
> age               0.01047    0.01093   0.958   0.3379
> trstmedia_sm      0.24108    0.13696   1.760   0.0784 .
> dummy_L_all       0.16702    0.89975   0.186   0.8527
> dummy_C_all       0.01118    1.46559   0.008   0.9939
> female_dum        0.12071    0.65590   0.184   0.8540
> trstmedia_public -0.01846    0.32520  -0.057   0.9547
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Zero-inflation model:
>                     Estimate Std. Error z value Pr(>|z|)
> (Intercept)      -0.0301001  1.3829502  -0.022    0.983
> diet_rob         -0.0233937  2.3407518  -0.010    0.992
> polinterest      -0.0897813  0.3597496  -0.250    0.803
> poleffic         -0.0455312  0.3529030  -0.129    0.897
> age              -0.0003903  0.0204699  -0.019    0.985
> trstmedia_sm     -0.0884604  0.1374919  -0.643    0.520
> dummy_L_all      -0.0205767  2.2994896  -0.009    0.993
> dummy_C_all      -0.0167199  3.9414142  -0.004    0.997
> female_dum       -0.0339406  1.8302418  -0.018    0.985
> trstmedia_public -0.0408538  0.6763691  -0.060    0.952
> Warning messages:
> 1: In vcov.glmmTMB(object, include_mapped = TRUE) :
>    Calculating sdreport. Use se=TRUE in glmmTMB to avoid repetitive calculation of sdreport
> 2: In vcov.glmmTMB(object) :
>    Calculating sdreport. Use se=TRUE in glmmTMB to avoid repetitive calculation of sdreport
> 
> 	[[alternative HTML version deleted]]
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

From Andre@Syvert@en @end|ng |rom u|b@no  Fri Jun 25 12:32:49 2021
From: Andre@Syvert@en @end|ng |rom u|b@no (Andre Syvertsen)
Date: Fri, 25 Jun 2021 10:32:49 +0000
Subject: [R-sig-ME] glmmTMB: Including variable in as fixed effect and in
 dispersion model
Message-ID: <AM0PR0102MB31726D5E121BCF3BE4F6FF5A9E069@AM0PR0102MB3172.eurprd01.prod.exchangelabs.com>

Hi guys,

Is it possible/meaningful to include a variable both as a fixed effect and in the dispersion model? For example, I have run the following model:

m4DaysPlayed <- glmmTMB(daysPlayed ~ 1 + time + ageCategory * gender + (time | id), disp = ~time, dfLong, family = truncated_nbinom2)

Rationale: I want to study the effect of time on the outcome variable, but I have also found evidence for heteorskedasticity when simulating through DHARMa. I suspect that the time variable influences this, the sample size decreases/variation increases as time goes on.

Kind regards,
Andr?

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Sat Jun 26 02:35:52 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 25 Jun 2021 20:35:52 -0400
Subject: [R-sig-ME] 
 glmmTMB: Including variable in as fixed effect and in
 dispersion model
In-Reply-To: <AM0PR0102MB31726D5E121BCF3BE4F6FF5A9E069@AM0PR0102MB3172.eurprd01.prod.exchangelabs.com>
References: <AM0PR0102MB31726D5E121BCF3BE4F6FF5A9E069@AM0PR0102MB3172.eurprd01.prod.exchangelabs.com>
Message-ID: <8213affb-ee0d-7839-325e-cdd69630d454@gmail.com>

   I don't see why not, although to some extent the negative binomial 
error structure should account for the phenomenon you're seeing: since 
the variance of the nbinom(2) is var = mu*(1+mu/k), the coefficient of 
variation is sqrt(var/mu^2) = sqrt(1/mu + k).  I'm not sure what you 
mean by "sample size decreasing", but for a large mean (mu), the CV 
should be approximately constant (~ sqrt(k)), while for small mean the 
CV should be increasing with decreasing mu (~ sqrt(1/mu)).

   It might be worth trying truncated_nbinom1 as well?



On 6/25/21 6:32 AM, Andre Syvertsen wrote:
> Hi guys,
> 
> Is it possible/meaningful to include a variable both as a fixed effect and in the dispersion model? For example, I have run the following model:
> 
> m4DaysPlayed <- glmmTMB(daysPlayed ~ 1 + time + ageCategory * gender + (time | id), disp = ~time, dfLong, family = truncated_nbinom2)
> 
> Rationale: I want to study the effect of time on the outcome variable, but I have also found evidence for heteorskedasticity when simulating through DHARMa. I suspect that the time variable influences this, the sample size decreases/variation increases as time goes on.
> 
> Kind regards,
> Andr?
> 
> 	[[alternative HTML version deleted]]
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From Andre@Syvert@en @end|ng |rom u|b@no  Mon Jun 28 13:29:08 2021
From: Andre@Syvert@en @end|ng |rom u|b@no (Andre Syvertsen)
Date: Mon, 28 Jun 2021 11:29:08 +0000
Subject: [R-sig-ME] 
 glmmTMB: Including variable in as fixed effect and in
 dispersion model (Ben Bolker): R-sig-mixed-models Digest, Vol 174, Issue 21
In-Reply-To: <mailman.19253.7.1624701602.32993.r-sig-mixed-models@r-project.org>
References: <mailman.19253.7.1624701602.32993.r-sig-mixed-models@r-project.org>
Message-ID: <AM6PR0102MB317410743439FBA7CA504EBB9E039@AM6PR0102MB3174.eurprd01.prod.exchangelabs.com>

Thank you for the feedback. I have attempted NB1 without any luck (model did not converge). Adding "time" to the dispersion model did not seem to influence the resulting simulation either. I have been trying several different adjustments to the models without success. The more general issue that motivated my question is covered in depth at https://stats.stackexchange.com/questions/523171/model-misfit-with-dharma-what-needs-can-be-done

Kind Regards,
Andre

________________________________
Fra: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> p? vegne av r-sig-mixed-models-request at r-project.org <r-sig-mixed-models-request at r-project.org>
Sendt: l?rdag 26. juni 2021 12:00
Til: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Emne: R-sig-mixed-models Digest, Vol 174, Issue 21

Send R-sig-mixed-models mailing list submissions to
        r-sig-mixed-models at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
        https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
or, via email, send a message with subject or body 'help' to
        r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
        r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

   1. glmmTMB: Including variable in as fixed effect and in
      dispersion model (Andre Syvertsen)
   2. Re:  glmmTMB: Including variable in as fixed effect and in
      dispersion model (Ben Bolker)

----------------------------------------------------------------------

Message: 1
Date: Fri, 25 Jun 2021 10:32:49 +0000
From: Andre Syvertsen <Andre.Syvertsen at uib.no>
To: "r-sig-mixed-models at r-project.org"
        <r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] glmmTMB: Including variable in as fixed effect and
        in dispersion model
Message-ID:
        <AM0PR0102MB31726D5E121BCF3BE4F6FF5A9E069 at AM0PR0102MB3172.eurprd01.prod.exchangelabs.com>

Content-Type: text/plain; charset="utf-8"

Hi guys,

Is it possible/meaningful to include a variable both as a fixed effect and in the dispersion model? For example, I have run the following model:

m4DaysPlayed <- glmmTMB(daysPlayed ~ 1 + time + ageCategory * gender + (time | id), disp = ~time, dfLong, family = truncated_nbinom2)

Rationale: I want to study the effect of time on the outcome variable, but I have also found evidence for heteorskedasticity when simulating through DHARMa. I suspect that the time variable influences this, the sample size decreases/variation increases as time goes on.

Kind regards,
Andr?

        [[alternative HTML version deleted]]




------------------------------

Message: 2
Date: Fri, 25 Jun 2021 20:35:52 -0400
From: Ben Bolker <bbolker at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME]  glmmTMB: Including variable in as fixed
        effect and in dispersion model
Message-ID: <8213affb-ee0d-7839-325e-cdd69630d454 at gmail.com>
Content-Type: text/plain; charset="utf-8"; Format="flowed"

   I don't see why not, although to some extent the negative binomial
error structure should account for the phenomenon you're seeing: since
the variance of the nbinom(2) is var = mu*(1+mu/k), the coefficient of
variation is sqrt(var/mu^2) = sqrt(1/mu + k).  I'm not sure what you
mean by "sample size decreasing", but for a large mean (mu), the CV
should be approximately constant (~ sqrt(k)), while for small mean the
CV should be increasing with decreasing mu (~ sqrt(1/mu)).

   It might be worth trying truncated_nbinom1 as well?



On 6/25/21 6:32 AM, Andre Syvertsen wrote:
> Hi guys,
>
> Is it possible/meaningful to include a variable both as a fixed effect and in the dispersion model? For example, I have run the following model:
>
> m4DaysPlayed <- glmmTMB(daysPlayed ~ 1 + time + ageCategory * gender + (time | id), disp = ~time, dfLong, family = truncated_nbinom2)
>
> Rationale: I want to study the effect of time on the outcome variable, but I have also found evidence for heteorskedasticity when simulating through DHARMa. I suspect that the time variable influences this, the sample size decreases/variation increases as time goes on.
>
> Kind regards,
> Andr?
>
>        [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>




------------------------------

Subject: Digest Footer

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


------------------------------

End of R-sig-mixed-models Digest, Vol 174, Issue 21
***************************************************

	[[alternative HTML version deleted]]


From @myrb@@ @end|ng |rom gm@||@com  Mon Jun 28 16:17:22 2021
From: @myrb@@ @end|ng |rom gm@||@com (Amy Huang)
Date: Mon, 28 Jun 2021 16:17:22 +0200
Subject: [R-sig-ME] Estimation of variance components in random- and
 mixed-effects models
Message-ID: <CAK2ikok__C0M9JduqEuqsmjOXETDewpX1pGDNTsXJvzpjYEC3g@mail.gmail.com>

Dear all,

I am examining maternal effects, and my data have three hierarchy levels:
clutches of the same female, females, and cohorts. My explanatory variables
are at the female level (female length, age) and at the cohort level
(temperature).

I would like to estimate the variance components of each hierarchy level
(i.e. relative amount of variance at each level) and then to find out which
factors (female length, age, temperature) explain most of the variance. For
these, I have two models:
    offspring trait ~ 1 + (1 | cohort/female/clutch)
    offspring trait ~ temperature + female length + age + (1 |
cohort/female/clutch)

The major problem is that I only have 3 cohorts (and so 3 temperatures).
>From the first model I am able to get the information, but from the second
one there is an error message: "Model failed to converge with 1 negative
eigenvalue: -2.0e+01". The error pops up probably because I have both
temperature (fixed) and cohort (random) included. Is my approach correct?
And is there a way to fix this error?

Thank you so much for your time.

Best regards,
Amy Huang

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Mon Jun 28 16:25:06 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 28 Jun 2021 10:25:06 -0400
Subject: [R-sig-ME] Estimation of variance components in random- and
 mixed-effects models
In-Reply-To: <CAK2ikok__C0M9JduqEuqsmjOXETDewpX1pGDNTsXJvzpjYEC3g@mail.gmail.com>
References: <CAK2ikok__C0M9JduqEuqsmjOXETDewpX1pGDNTsXJvzpjYEC3g@mail.gmail.com>
Message-ID: <327afce2-3e10-d179-b4ee-348e8232d74c@gmail.com>

   Are you using lme4? (I'm 99% sure you are, but it's good to be explicit.)

   Are all of your fixed predictors numeric (rather than 
factor/categorical) ?

   Note that a convergence warning is a *warning*, not an error: have 
you checked the troubleshooting steps in ?lme4::convergence (in 
particular, scaling and centering your predictor variables might help ...)

   cheers
    Ben Bolker


On 6/28/21 10:17 AM, Amy Huang wrote:
> Dear all,
> 
> I am examining maternal effects, and my data have three hierarchy levels:
> clutches of the same female, females, and cohorts. My explanatory variables
> are at the female level (female length, age) and at the cohort level
> (temperature).
> 
> I would like to estimate the variance components of each hierarchy level
> (i.e. relative amount of variance at each level) and then to find out which
> factors (female length, age, temperature) explain most of the variance. For
> these, I have two models:
>      offspring trait ~ 1 + (1 | cohort/female/clutch)
>      offspring trait ~ temperature + female length + age + (1 |
> cohort/female/clutch)
> 
> The major problem is that I only have 3 cohorts (and so 3 temperatures).
>  From the first model I am able to get the information, but from the second
> one there is an error message: "Model failed to converge with 1 negative
> eigenvalue: -2.0e+01". The error pops up probably because I have both
> temperature (fixed) and cohort (random) included. Is my approach correct?
> And is there a way to fix this error?
> 
> Thank you so much for your time.
> 
> Best regards,
> Amy Huang
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From th|erry@onke||nx @end|ng |rom |nbo@be  Mon Jun 28 19:17:54 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Mon, 28 Jun 2021 19:17:54 +0200
Subject: [R-sig-ME] Estimation of variance components in random- and
 mixed-effects models
In-Reply-To: <327afce2-3e10-d179-b4ee-348e8232d74c@gmail.com>
References: <CAK2ikok__C0M9JduqEuqsmjOXETDewpX1pGDNTsXJvzpjYEC3g@mail.gmail.com>
 <327afce2-3e10-d179-b4ee-348e8232d74c@gmail.com>
Message-ID: <CAJuCY5yRWNvvfBJk9Hk3oq8cUCS4L4iAu2nCu--Ams_6vLbDfw@mail.gmail.com>

Another issue is that you have too few levels to fit "cohort" as a random
effect. I wrote a blogpost on this a few years ago:
https://www.muscardinus.be/2018/09/number-random-effect-levels/

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 28 jun. 2021 om 16:31 schreef Ben Bolker <bbolker at gmail.com>:

>    Are you using lme4? (I'm 99% sure you are, but it's good to be
> explicit.)
>
>    Are all of your fixed predictors numeric (rather than
> factor/categorical) ?
>
>    Note that a convergence warning is a *warning*, not an error: have
> you checked the troubleshooting steps in ?lme4::convergence (in
> particular, scaling and centering your predictor variables might help ...)
>
>    cheers
>     Ben Bolker
>
>
> On 6/28/21 10:17 AM, Amy Huang wrote:
> > Dear all,
> >
> > I am examining maternal effects, and my data have three hierarchy levels:
> > clutches of the same female, females, and cohorts. My explanatory
> variables
> > are at the female level (female length, age) and at the cohort level
> > (temperature).
> >
> > I would like to estimate the variance components of each hierarchy level
> > (i.e. relative amount of variance at each level) and then to find out
> which
> > factors (female length, age, temperature) explain most of the variance.
> For
> > these, I have two models:
> >      offspring trait ~ 1 + (1 | cohort/female/clutch)
> >      offspring trait ~ temperature + female length + age + (1 |
> > cohort/female/clutch)
> >
> > The major problem is that I only have 3 cohorts (and so 3 temperatures).
> >  From the first model I am able to get the information, but from the
> second
> > one there is an error message: "Model failed to converge with 1 negative
> > eigenvalue: -2.0e+01". The error pops up probably because I have both
> > temperature (fixed) and cohort (random) included. Is my approach correct?
> > And is there a way to fix this error?
> >
> > Thank you so much for your time.
> >
> > Best regards,
> > Amy Huang
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Mon Jun 28 19:32:06 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 28 Jun 2021 13:32:06 -0400
Subject: [R-sig-ME] Estimation of variance components in random- and
 mixed-effects models
In-Reply-To: <CAJuCY5yRWNvvfBJk9Hk3oq8cUCS4L4iAu2nCu--Ams_6vLbDfw@mail.gmail.com>
References: <CAK2ikok__C0M9JduqEuqsmjOXETDewpX1pGDNTsXJvzpjYEC3g@mail.gmail.com>
 <327afce2-3e10-d179-b4ee-348e8232d74c@gmail.com>
 <CAJuCY5yRWNvvfBJk9Hk3oq8cUCS4L4iAu2nCu--Ams_6vLbDfw@mail.gmail.com>
Message-ID: <c70f7035-df66-7a96-8656-87a7b0c75b2a@gmail.com>

   See also:

https://stats.stackexchange.com/questions/37647/what-is-the-minimum-recommended-number-of-groups-for-a-random-effects-factor

https://www.biorxiv.org/content/10.1101/2021.05.03.442487v2

  (I should these links, and the blog post link, to the GLMM FAQ ...)

On 6/28/21 1:17 PM, Thierry Onkelinx wrote:
> Another issue is that you have too few levels to fit "cohort" as a 
> random effect. I wrote a blogpost on this a few years ago: 
> https://www.muscardinus.be/2018/09/number-random-effect-levels/ 
> <https://www.muscardinus.be/2018/09/number-random-effect-levels/>
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Statisticus / Statistician
> 
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE 
> AND FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be <http://www.inbo.be>
> 
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more 
> than asking him to perform a post-mortem examination: he may be able to 
> say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not 
> ensure that a reasonable answer can be extracted from a given body of 
> data. ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
> 
> <https://www.inbo.be>
> 
> 
> Op ma 28 jun. 2021 om 16:31 schreef Ben Bolker <bbolker at gmail.com 
> <mailto:bbolker at gmail.com>>:
> 
>      ? ?Are you using lme4? (I'm 99% sure you are, but it's good to be
>     explicit.)
> 
>      ? ?Are all of your fixed predictors numeric (rather than
>     factor/categorical) ?
> 
>      ? ?Note that a convergence warning is a *warning*, not an error: have
>     you checked the troubleshooting steps in ?lme4::convergence (in
>     particular, scaling and centering your predictor variables might
>     help ...)
> 
>      ? ?cheers
>      ? ? Ben Bolker
> 
> 
>     On 6/28/21 10:17 AM, Amy Huang wrote:
>      > Dear all,
>      >
>      > I am examining maternal effects, and my data have three hierarchy
>     levels:
>      > clutches of the same female, females, and cohorts. My explanatory
>     variables
>      > are at the female level (female length, age) and at the cohort level
>      > (temperature).
>      >
>      > I would like to estimate the variance components of each
>     hierarchy level
>      > (i.e. relative amount of variance at each level) and then to find
>     out which
>      > factors (female length, age, temperature) explain most of the
>     variance. For
>      > these, I have two models:
>      >? ? ? offspring trait ~ 1 + (1 | cohort/female/clutch)
>      >? ? ? offspring trait ~ temperature + female length + age + (1 |
>      > cohort/female/clutch)
>      >
>      > The major problem is that I only have 3 cohorts (and so 3
>     temperatures).
>      >? From the first model I am able to get the information, but from
>     the second
>      > one there is an error message: "Model failed to converge with 1
>     negative
>      > eigenvalue: -2.0e+01". The error pops up probably because I have both
>      > temperature (fixed) and cohort (random) included. Is my approach
>     correct?
>      > And is there a way to fix this error?
>      >
>      > Thank you so much for your time.
>      >
>      > Best regards,
>      > Amy Huang
>      >
>      >? ? ? ?[[alternative HTML version deleted]]
>      >
>      > _______________________________________________
>      > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >
> 
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>


From @myrb@@ @end|ng |rom gm@||@com  Mon Jun 28 21:20:53 2021
From: @myrb@@ @end|ng |rom gm@||@com (Amy Huang)
Date: Mon, 28 Jun 2021 21:20:53 +0200
Subject: [R-sig-ME] Estimation of variance components in random- and
 mixed-effects models
In-Reply-To: <c70f7035-df66-7a96-8656-87a7b0c75b2a@gmail.com>
References: <CAK2ikok__C0M9JduqEuqsmjOXETDewpX1pGDNTsXJvzpjYEC3g@mail.gmail.com>
 <327afce2-3e10-d179-b4ee-348e8232d74c@gmail.com>
 <CAJuCY5yRWNvvfBJk9Hk3oq8cUCS4L4iAu2nCu--Ams_6vLbDfw@mail.gmail.com>
 <c70f7035-df66-7a96-8656-87a7b0c75b2a@gmail.com>
Message-ID: <CAK2ikom9AASV49ib1_ytD0KAZwSUMw+KY43RMniY8SAc4v5i1Q@mail.gmail.com>

Thank you very much for your responses and references. Sorry that I missed
mentioning a lot of information.

I am using lme4, and the fixed predictors are all numeric. Only having 3
levels of cohorts is indeed the major issue. After removing insignificant
predictors in the 2nd model, the only factor left is temperature: offspring
trait ~ temperature + (1 | cohort/female/clutch), which gives the
convergence warning.

Now I treat cohort as a fixed effect, but when I include both cohort and
temperature as fixed effects (in the 2nd model), a warning appears:
"fixed-effect model matrix is rank deficient so dropping 1 column /
coefficient". When I remove cohort (2nd model), the two models become very
similar and give similar results.
    offspring trait ~ cohort + (1 | female/clutch)
    offspring trait ~ temperature + (1 | female/clutch)
But am I not introducing pseudoreplicates if I do not include cohort as a
factor?

PS. The section "How do I compute a coefficient of determination (R2), or
an analogue, for (G)LMMs?" in the GLMM FAQ also gives me some insight.
However, the links provided there seem to be not working.

Best regards,
Amy Huang

Am Mo., 28. Juni 2021 um 19:32 Uhr schrieb Ben Bolker <bbolker at gmail.com>:

>    See also:
>
>
> https://stats.stackexchange.com/questions/37647/what-is-the-minimum-recommended-number-of-groups-for-a-random-effects-factor
>
> https://www.biorxiv.org/content/10.1101/2021.05.03.442487v2
>
>   (I should these links, and the blog post link, to the GLMM FAQ ...)
>
> On 6/28/21 1:17 PM, Thierry Onkelinx wrote:
> > Another issue is that you have too few levels to fit "cohort" as a
> > random effect. I wrote a blogpost on this a few years ago:
> > https://www.muscardinus.be/2018/09/number-random-effect-levels/
> > <https://www.muscardinus.be/2018/09/number-random-effect-levels/>
> >
> > Best regards,
> >
> > ir. Thierry Onkelinx
> > Statisticus / Statistician
> >
> > Vlaamse Overheid / Government of Flanders
> > INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> > AND FOREST
> > Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> > thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>
> > Havenlaan 88 bus 73, 1000 Brussel
> > www.inbo.be <http://www.inbo.be>
> >
> >
> ///////////////////////////////////////////////////////////////////////////////////////////
> > To call in the statistician after the experiment is done may be no more
> > than asking him to perform a post-mortem examination: he may be able to
> > say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does not
> > ensure that a reasonable answer can be extracted from a given body of
> > data. ~ John Tukey
> >
> ///////////////////////////////////////////////////////////////////////////////////////////
> >
> > <https://www.inbo.be>
> >
> >
> > Op ma 28 jun. 2021 om 16:31 schreef Ben Bolker <bbolker at gmail.com
> > <mailto:bbolker at gmail.com>>:
> >
> >         Are you using lme4? (I'm 99% sure you are, but it's good to be
> >     explicit.)
> >
> >         Are all of your fixed predictors numeric (rather than
> >     factor/categorical) ?
> >
> >         Note that a convergence warning is a *warning*, not an error:
> have
> >     you checked the troubleshooting steps in ?lme4::convergence (in
> >     particular, scaling and centering your predictor variables might
> >     help ...)
> >
> >         cheers
> >          Ben Bolker
> >
> >
> >     On 6/28/21 10:17 AM, Amy Huang wrote:
> >      > Dear all,
> >      >
> >      > I am examining maternal effects, and my data have three hierarchy
> >     levels:
> >      > clutches of the same female, females, and cohorts. My explanatory
> >     variables
> >      > are at the female level (female length, age) and at the cohort
> level
> >      > (temperature).
> >      >
> >      > I would like to estimate the variance components of each
> >     hierarchy level
> >      > (i.e. relative amount of variance at each level) and then to find
> >     out which
> >      > factors (female length, age, temperature) explain most of the
> >     variance. For
> >      > these, I have two models:
> >      >      offspring trait ~ 1 + (1 | cohort/female/clutch)
> >      >      offspring trait ~ temperature + female length + age + (1 |
> >      > cohort/female/clutch)
> >      >
> >      > The major problem is that I only have 3 cohorts (and so 3
> >     temperatures).
> >      >  From the first model I am able to get the information, but from
> >     the second
> >      > one there is an error message: "Model failed to converge with 1
> >     negative
> >      > eigenvalue: -2.0e+01". The error pops up probably because I have
> both
> >      > temperature (fixed) and cohort (random) included. Is my approach
> >     correct?
> >      > And is there a way to fix this error?
> >      >
> >      > Thank you so much for your time.
> >      >
> >      > Best regards,
> >      > Amy Huang
> >      >
> >      >       [[alternative HTML version deleted]]
> >      >
> >      > _______________________________________________
> >      > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >
> >
> >     _______________________________________________
> >     R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Mon Jun 28 21:30:11 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Mon, 28 Jun 2021 21:30:11 +0200
Subject: [R-sig-ME] Estimation of variance components in random- and
 mixed-effects models
In-Reply-To: <CAK2ikom9AASV49ib1_ytD0KAZwSUMw+KY43RMniY8SAc4v5i1Q@mail.gmail.com>
References: <CAK2ikok__C0M9JduqEuqsmjOXETDewpX1pGDNTsXJvzpjYEC3g@mail.gmail.com>
 <327afce2-3e10-d179-b4ee-348e8232d74c@gmail.com>
 <CAJuCY5yRWNvvfBJk9Hk3oq8cUCS4L4iAu2nCu--Ams_6vLbDfw@mail.gmail.com>
 <c70f7035-df66-7a96-8656-87a7b0c75b2a@gmail.com>
 <CAK2ikom9AASV49ib1_ytD0KAZwSUMw+KY43RMniY8SAc4v5i1Q@mail.gmail.com>
Message-ID: <CAJuCY5yT6bnrtssdnTDUFTh3-wzYnvQsw5YPLE0Z52tAq-EFJg@mail.gmail.com>

Dear Amy,

Since you have only three cohorts and a single temperature for each cohort,
you can't include both in the model. I recommend using cohort rather than
temperature. You can plot the cohort effect against their temperature to
get an indication of potential correlation between cohort effect and
temperature.

Since you add cohort as a fixed effect, you take the common effect of all
observations of the same cohort into account. So no problem with
pseudoreplication. That would be a problem when you include only
temperature as a numeric instead of cohort as a factor.

Best regards,


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 28 jun. 2021 om 21:21 schreef Amy Huang <amyrbss at gmail.com>:

> Thank you very much for your responses and references. Sorry that I missed
> mentioning a lot of information.
>
> I am using lme4, and the fixed predictors are all numeric. Only having 3
> levels of cohorts is indeed the major issue. After removing insignificant
> predictors in the 2nd model, the only factor left is temperature: offspring
> trait ~ temperature + (1 | cohort/female/clutch), which gives the
> convergence warning.
>
> Now I treat cohort as a fixed effect, but when I include both cohort and
> temperature as fixed effects (in the 2nd model), a warning appears:
> "fixed-effect model matrix is rank deficient so dropping 1 column /
> coefficient". When I remove cohort (2nd model), the two models become very
> similar and give similar results.
>     offspring trait ~ cohort + (1 | female/clutch)
>     offspring trait ~ temperature + (1 | female/clutch)
> But am I not introducing pseudoreplicates if I do not include cohort as a
> factor?
>
> PS. The section "How do I compute a coefficient of determination (R2), or
> an analogue, for (G)LMMs?" in the GLMM FAQ also gives me some insight.
> However, the links provided there seem to be not working.
>
> Best regards,
> Amy Huang
>
> Am Mo., 28. Juni 2021 um 19:32 Uhr schrieb Ben Bolker <bbolker at gmail.com>:
>
> >    See also:
> >
> >
> >
> https://stats.stackexchange.com/questions/37647/what-is-the-minimum-recommended-number-of-groups-for-a-random-effects-factor
> >
> > https://www.biorxiv.org/content/10.1101/2021.05.03.442487v2
> >
> >   (I should these links, and the blog post link, to the GLMM FAQ ...)
> >
> > On 6/28/21 1:17 PM, Thierry Onkelinx wrote:
> > > Another issue is that you have too few levels to fit "cohort" as a
> > > random effect. I wrote a blogpost on this a few years ago:
> > > https://www.muscardinus.be/2018/09/number-random-effect-levels/
> > > <https://www.muscardinus.be/2018/09/number-random-effect-levels/>
> > >
> > > Best regards,
> > >
> > > ir. Thierry Onkelinx
> > > Statisticus / Statistician
> > >
> > > Vlaamse Overheid / Government of Flanders
> > > INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> > > AND FOREST
> > > Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> > > thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>
> > > Havenlaan 88 bus 73, 1000 Brussel
> > > www.inbo.be <http://www.inbo.be>
> > >
> > >
> >
> ///////////////////////////////////////////////////////////////////////////////////////////
> > > To call in the statistician after the experiment is done may be no more
> > > than asking him to perform a post-mortem examination: he may be able to
> > > say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > > The plural of anecdote is not data. ~ Roger Brinner
> > > The combination of some data and an aching desire for an answer does
> not
> > > ensure that a reasonable answer can be extracted from a given body of
> > > data. ~ John Tukey
> > >
> >
> ///////////////////////////////////////////////////////////////////////////////////////////
> > >
> > > <https://www.inbo.be>
> > >
> > >
> > > Op ma 28 jun. 2021 om 16:31 schreef Ben Bolker <bbolker at gmail.com
> > > <mailto:bbolker at gmail.com>>:
> > >
> > >         Are you using lme4? (I'm 99% sure you are, but it's good to be
> > >     explicit.)
> > >
> > >         Are all of your fixed predictors numeric (rather than
> > >     factor/categorical) ?
> > >
> > >         Note that a convergence warning is a *warning*, not an error:
> > have
> > >     you checked the troubleshooting steps in ?lme4::convergence (in
> > >     particular, scaling and centering your predictor variables might
> > >     help ...)
> > >
> > >         cheers
> > >          Ben Bolker
> > >
> > >
> > >     On 6/28/21 10:17 AM, Amy Huang wrote:
> > >      > Dear all,
> > >      >
> > >      > I am examining maternal effects, and my data have three
> hierarchy
> > >     levels:
> > >      > clutches of the same female, females, and cohorts. My
> explanatory
> > >     variables
> > >      > are at the female level (female length, age) and at the cohort
> > level
> > >      > (temperature).
> > >      >
> > >      > I would like to estimate the variance components of each
> > >     hierarchy level
> > >      > (i.e. relative amount of variance at each level) and then to
> find
> > >     out which
> > >      > factors (female length, age, temperature) explain most of the
> > >     variance. For
> > >      > these, I have two models:
> > >      >      offspring trait ~ 1 + (1 | cohort/female/clutch)
> > >      >      offspring trait ~ temperature + female length + age + (1 |
> > >      > cohort/female/clutch)
> > >      >
> > >      > The major problem is that I only have 3 cohorts (and so 3
> > >     temperatures).
> > >      >  From the first model I am able to get the information, but from
> > >     the second
> > >      > one there is an error message: "Model failed to converge with 1
> > >     negative
> > >      > eigenvalue: -2.0e+01". The error pops up probably because I have
> > both
> > >      > temperature (fixed) and cohort (random) included. Is my approach
> > >     correct?
> > >      > And is there a way to fix this error?
> > >      >
> > >      > Thank you so much for your time.
> > >      >
> > >      > Best regards,
> > >      > Amy Huang
> > >      >
> > >      >       [[alternative HTML version deleted]]
> > >      >
> > >      > _______________________________________________
> > >      > R-sig-mixed-models at r-project.org
> > >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> > >      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> > >      >
> > >
> > >     _______________________________________________
> > >     R-sig-mixed-models at r-project.org
> > >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> > >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> > >
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From john@m@|ndon@|d @end|ng |rom @nu@edu@@u  Mon Jun 28 23:37:32 2021
From: john@m@|ndon@|d @end|ng |rom @nu@edu@@u (John Maindonald)
Date: Mon, 28 Jun 2021 21:37:32 +0000
Subject: [R-sig-ME] 
 glmmTMB: Including variable in as fixed effect and in
 dispersion model (Ben Bolker): R-sig-mixed-models Digest, Vol 174, Issue 21
In-Reply-To: <AM6PR0102MB317410743439FBA7CA504EBB9E039@AM6PR0102MB3174.eurprd01.prod.exchangelabs.com>
References: <mailman.19253.7.1624701602.32993.r-sig-mixed-models@r-project.org>
 <AM6PR0102MB317410743439FBA7CA504EBB9E039@AM6PR0102MB3174.eurprd01.prod.exchangelabs.com>
Message-ID: <031AF16F-FC1E-428D-8FE0-6E1E90055E51@anu.edu.au>

The gamlss package offers several alternatives to the negative binomial.
The vignette `countDists` in the `qra` package that I have recently sent
to CRAN has a comparison of these (towards the end) on a relatively
simple example.  Shape (where the model has one) as well as scale
parameters can be modelled.  For fitting random effects, see ?gamlss::re
and ?gamlss::random.

The `qra` package implements Fieller?s formula for confidence intervals
for ratios, with the focus on models for a binomial-like response. There
are a couple of other vignettes that investigate a variety of models and
model fits, for binomial-like data and for counts.


John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>

On 28/06/2021, at 23:29, Andre Syvertsen <Andre.Syvertsen at uib.no<mailto:Andre.Syvertsen at uib.no>> wrote:

Thank you for the feedback. I have attempted NB1 without any luck (model did not converge). Adding "time" to the dispersion model did not seem to influence the resulting simulation either. I have been trying several different adjustments to the models without success. The more general issue that motivated my question is covered in depth at https://stats.stackexchange.com/questions/523171/model-misfit-with-dharma-what-needs-can-be-done

Kind Regards,
Andre

________________________________
Fra: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>> p? vegne av r-sig-mixed-models-request at r-project.org<mailto:r-sig-mixed-models-request at r-project.org> <r-sig-mixed-models-request at r-project.org<mailto:r-sig-mixed-models-request at r-project.org>>
Sendt: l?rdag 26. juni 2021 12:00
Til: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org> <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Emne: R-sig-mixed-models Digest, Vol 174, Issue 21

Send R-sig-mixed-models mailing list submissions to
       r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>

To subscribe or unsubscribe via the World Wide Web, visit
       https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
or, via email, send a message with subject or body 'help' to
       r-sig-mixed-models-request at r-project.org<mailto:r-sig-mixed-models-request at r-project.org>

You can reach the person managing the list at
       r-sig-mixed-models-owner at r-project.org<mailto:r-sig-mixed-models-owner at r-project.org>

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

  1. glmmTMB: Including variable in as fixed effect and in
     dispersion model (Andre Syvertsen)
  2. Re:  glmmTMB: Including variable in as fixed effect and in
     dispersion model (Ben Bolker)

----------------------------------------------------------------------

Message: 1
Date: Fri, 25 Jun 2021 10:32:49 +0000
From: Andre Syvertsen <Andre.Syvertsen at uib.no<mailto:Andre.Syvertsen at uib.no>>
To: "r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>"
       <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: [R-sig-ME] glmmTMB: Including variable in as fixed effect and
       in dispersion model
Message-ID:
       <AM0PR0102MB31726D5E121BCF3BE4F6FF5A9E069 at AM0PR0102MB3172.eurprd01.prod.exchangelabs.com<mailto:AM0PR0102MB31726D5E121BCF3BE4F6FF5A9E069 at AM0PR0102MB3172.eurprd01.prod.exchangelabs.com>>

Content-Type: text/plain; charset="utf-8"

Hi guys,

Is it possible/meaningful to include a variable both as a fixed effect and in the dispersion model? For example, I have run the following model:

m4DaysPlayed <- glmmTMB(daysPlayed ~ 1 + time + ageCategory * gender + (time | id), disp = ~time, dfLong, family = truncated_nbinom2)

Rationale: I want to study the effect of time on the outcome variable, but I have also found evidence for heteorskedasticity when simulating through DHARMa. I suspect that the time variable influences this, the sample size decreases/variation increases as time goes on.

Kind regards,
Andr?

       [[alternative HTML version deleted]]




------------------------------

Message: 2
Date: Fri, 25 Jun 2021 20:35:52 -0400
From: Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com>>
To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME]  glmmTMB: Including variable in as fixed
       effect and in dispersion model
Message-ID: <8213affb-ee0d-7839-325e-cdd69630d454 at gmail.com<mailto:8213affb-ee0d-7839-325e-cdd69630d454 at gmail.com>>
Content-Type: text/plain; charset="utf-8"; Format="flowed"

  I don't see why not, although to some extent the negative binomial
error structure should account for the phenomenon you're seeing: since
the variance of the nbinom(2) is var = mu*(1+mu/k), the coefficient of
variation is sqrt(var/mu^2) = sqrt(1/mu + k).  I'm not sure what you
mean by "sample size decreasing", but for a large mean (mu), the CV
should be approximately constant (~ sqrt(k)), while for small mean the
CV should be increasing with decreasing mu (~ sqrt(1/mu)).

  It might be worth trying truncated_nbinom1 as well?



On 6/25/21 6:32 AM, Andre Syvertsen wrote:
Hi guys,

Is it possible/meaningful to include a variable both as a fixed effect and in the dispersion model? For example, I have run the following model:

m4DaysPlayed <- glmmTMB(daysPlayed ~ 1 + time + ageCategory * gender + (time | id), disp = ~time, dfLong, family = truncated_nbinom2)

Rationale: I want to study the effect of time on the outcome variable, but I have also found evidence for heteorskedasticity when simulating through DHARMa. I suspect that the time variable influences this, the sample size decreases/variation increases as time goes on.

Kind regards,
Andr?

      [[alternative HTML version deleted]]


_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models





------------------------------

Subject: Digest Footer

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


------------------------------

End of R-sig-mixed-models Digest, Vol 174, Issue 21
***************************************************

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Tue Jun 29 02:12:09 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 28 Jun 2021 20:12:09 -0400
Subject: [R-sig-ME] Estimation of variance components in random- and
 mixed-effects models
In-Reply-To: <CAK2ikom9AASV49ib1_ytD0KAZwSUMw+KY43RMniY8SAc4v5i1Q@mail.gmail.com>
References: <CAK2ikok__C0M9JduqEuqsmjOXETDewpX1pGDNTsXJvzpjYEC3g@mail.gmail.com>
 <327afce2-3e10-d179-b4ee-348e8232d74c@gmail.com>
 <CAJuCY5yRWNvvfBJk9Hk3oq8cUCS4L4iAu2nCu--Ams_6vLbDfw@mail.gmail.com>
 <c70f7035-df66-7a96-8656-87a7b0c75b2a@gmail.com>
 <CAK2ikom9AASV49ib1_ytD0KAZwSUMw+KY43RMniY8SAc4v5i1Q@mail.gmail.com>
Message-ID: <ca93574d-ed1f-8934-85f8-ed1e233c590f@gmail.com>


   A couple of *quick* responses.

   * I don't recommend dropping non-significant predictors, this is a 
good way to overfit models.
   * Are the temperatures for your three cohorts in a strictly linear 
sequence? i.e., temperature (cohort 1) = T1, temp (2) = T1 + delta, temp 
(3) = T1 + 2*delta ? In that case, the two effects are indeed 
identical/confounded.  In principle, your original model (using cohort 
as a random effect and temperature as fixed) is the right way to handle 
this, but for the size of data set you can't really identify 
among-cohort variation beyond the effect of temperature.

   A nice way to handle this is to treat cohort as an *ordered* 
categorical fixed effect (see ?ordered), and leave out temperature (this 
is assuming that the temperatures are as suggested above).  If you do 
this (i.e. convert cohort to 'ordered' type), R will fit two parameters, 
one labeled .L and the other labeled .Q, which together explain all of 
the among-cohort variation; if you like (although it is quite a big 
assumption, and you must be explicit about it), you can ascribe the 
linear (".L") variation to temperature and the other (".Q" or quadratic) 
to non-temperature effects.  However, given your experimental design, 
the following two explanations would be *equally well supported*:

  * none of the between-cohort variation is due to temperature;
  * temperature has a quadratic effect, so all of the between-cohort 
variation is due to temperature.

  cheers
    Ben Bolker



On 6/28/21 3:20 PM, Amy Huang wrote:
> Thank you very much for your responses and references. Sorry that I missed
> mentioning a lot of information.
> 
> I am using lme4, and the fixed predictors are all numeric. Only having 3
> levels of cohorts is indeed the major issue. After removing insignificant
> predictors in the 2nd model, the only factor left is temperature: offspring
> trait ~ temperature + (1 | cohort/female/clutch), which gives the
> convergence warning.
> 
> Now I treat cohort as a fixed effect, but when I include both cohort and
> temperature as fixed effects (in the 2nd model), a warning appears:
> "fixed-effect model matrix is rank deficient so dropping 1 column /
> coefficient". When I remove cohort (2nd model), the two models become very
> similar and give similar results.
>      offspring trait ~ cohort + (1 | female/clutch)
>      offspring trait ~ temperature + (1 | female/clutch)
> But am I not introducing pseudoreplicates if I do not include cohort as a
> factor?
> 
> PS. The section "How do I compute a coefficient of determination (R2), or
> an analogue, for (G)LMMs?" in the GLMM FAQ also gives me some insight.
> However, the links provided there seem to be not working.
> 
> Best regards,
> Amy Huang
> 
> Am Mo., 28. Juni 2021 um 19:32 Uhr schrieb Ben Bolker <bbolker at gmail.com>:
> 
>>     See also:
>>
>>
>> https://stats.stackexchange.com/questions/37647/what-is-the-minimum-recommended-number-of-groups-for-a-random-effects-factor
>>
>> https://www.biorxiv.org/content/10.1101/2021.05.03.442487v2
>>
>>    (I should these links, and the blog post link, to the GLMM FAQ ...)
>>
>> On 6/28/21 1:17 PM, Thierry Onkelinx wrote:
>>> Another issue is that you have too few levels to fit "cohort" as a
>>> random effect. I wrote a blogpost on this a few years ago:
>>> https://www.muscardinus.be/2018/09/number-random-effect-levels/
>>> <https://www.muscardinus.be/2018/09/number-random-effect-levels/>
>>>
>>> Best regards,
>>>
>>> ir. Thierry Onkelinx
>>> Statisticus / Statistician
>>>
>>> Vlaamse Overheid / Government of Flanders
>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>>> AND FOREST
>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>> thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>
>>> Havenlaan 88 bus 73, 1000 Brussel
>>> www.inbo.be <http://www.inbo.be>
>>>
>>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to
>>> say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of
>>> data. ~ John Tukey
>>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>
>>> <https://www.inbo.be>
>>>
>>>
>>> Op ma 28 jun. 2021 om 16:31 schreef Ben Bolker <bbolker at gmail.com
>>> <mailto:bbolker at gmail.com>>:
>>>
>>>          Are you using lme4? (I'm 99% sure you are, but it's good to be
>>>      explicit.)
>>>
>>>          Are all of your fixed predictors numeric (rather than
>>>      factor/categorical) ?
>>>
>>>          Note that a convergence warning is a *warning*, not an error:
>> have
>>>      you checked the troubleshooting steps in ?lme4::convergence (in
>>>      particular, scaling and centering your predictor variables might
>>>      help ...)
>>>
>>>          cheers
>>>           Ben Bolker
>>>
>>>
>>>      On 6/28/21 10:17 AM, Amy Huang wrote:
>>>       > Dear all,
>>>       >
>>>       > I am examining maternal effects, and my data have three hierarchy
>>>      levels:
>>>       > clutches of the same female, females, and cohorts. My explanatory
>>>      variables
>>>       > are at the female level (female length, age) and at the cohort
>> level
>>>       > (temperature).
>>>       >
>>>       > I would like to estimate the variance components of each
>>>      hierarchy level
>>>       > (i.e. relative amount of variance at each level) and then to find
>>>      out which
>>>       > factors (female length, age, temperature) explain most of the
>>>      variance. For
>>>       > these, I have two models:
>>>       >      offspring trait ~ 1 + (1 | cohort/female/clutch)
>>>       >      offspring trait ~ temperature + female length + age + (1 |
>>>       > cohort/female/clutch)
>>>       >
>>>       > The major problem is that I only have 3 cohorts (and so 3
>>>      temperatures).
>>>       >  From the first model I am able to get the information, but from
>>>      the second
>>>       > one there is an error message: "Model failed to converge with 1
>>>      negative
>>>       > eigenvalue: -2.0e+01". The error pops up probably because I have
>> both
>>>       > temperature (fixed) and cohort (random) included. Is my approach
>>>      correct?
>>>       > And is there a way to fix this error?
>>>       >
>>>       > Thank you so much for your time.
>>>       >
>>>       > Best regards,
>>>       > Amy Huang
>>>       >
>>>       >       [[alternative HTML version deleted]]
>>>       >
>>>       > _______________________________________________
>>>       > R-sig-mixed-models at r-project.org
>>>      <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>       > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>       >
>>>
>>>      _______________________________________________
>>>      R-sig-mixed-models at r-project.org
>>>      <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>      https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From @ndre@m@uch@mp @end|ng |rom protonm@||@com  Tue Jun 29 13:03:11 2021
From: @ndre@m@uch@mp @end|ng |rom protonm@||@com (A Mauchamp)
Date: Tue, 29 Jun 2021 11:03:11 +0000
Subject: [R-sig-ME] How to consider temporal autocorrelation in a GLMM
Message-ID: <h4F_uEoXcHHd1avA3qVZGl2MIwIOOvXDTLjaDlEDRxjSkl22zcZyTIuIp4odEh7FF5o8f3DuYs8jC4uyGypXTvt5fGAf5zq-XOdhaMzSPmk=@protonmail.com>

Hello,

I am currently analyzing (in R) ecological monitoring data that have 5 successive years, one point per year and multiple sites and replicates within sites. Having a combination of fixed (environmental variables) and random (sites) effects, I need to use mixed models.
Using glmer of the package lme4, I would like to account for the strong correlation between one year data and the following that I observe for most variables.
I found this idea here https://stackoverflow.com/questions/24452796/accounting-for-temporal-correlation-in-glmm which looks very simple and straightforward.
It would result in a formula as
y_t ~ env1 + env2 + env3 + y_t-1 + (1|site)
However in some cases, all environmental effects disappear and the only relation that remains is with y_t-1.

I also found this approach:
y ~ env1+ env2 + time + (1|replicate) + (1|site) that treats time as fixed effect and groups the repeated measures of replicates. Though I am not sure it is correct.

Would it be correct to use time as a random effect ?

Data are either count data (Poisson error distribution) or quantitative and gaussian.
Which would be the most appropriate way of dealing with such repeated measures /short time series ?
Which reference could I use to support the method ?
My data series is indeed to short to go for a real time-series analysis and I don't think I can go for more than one year lag.

Thank you for any suggestion,
Andre

Sent with [ProtonMail](https://protonmail.com/) Secure Email.
	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Tue Jun 29 16:26:55 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Tue, 29 Jun 2021 16:26:55 +0200
Subject: [R-sig-ME] How to consider temporal autocorrelation in a GLMM
In-Reply-To: <h4F_uEoXcHHd1avA3qVZGl2MIwIOOvXDTLjaDlEDRxjSkl22zcZyTIuIp4odEh7FF5o8f3DuYs8jC4uyGypXTvt5fGAf5zq-XOdhaMzSPmk=@protonmail.com>
References: <h4F_uEoXcHHd1avA3qVZGl2MIwIOOvXDTLjaDlEDRxjSkl22zcZyTIuIp4odEh7FF5o8f3DuYs8jC4uyGypXTvt5fGAf5zq-XOdhaMzSPmk=@protonmail.com>
Message-ID: <CAJuCY5yXsp+rPkZitJT8MFdipSSMvviGGrDKTZh3hEsj=RD=rw@mail.gmail.com>

Dear Andre,

My go-to for temporal and/or spatial autocorrelation is the INLA package. I
wrote a blogpost on temporal autocorrelation (
https://www.muscardinus.be/2018/03/inla-temporal/).

An iid random intercept as lme4, implies a compound symmetry correlation
among the levels: every pair of levels has the same correlation. With
temporal correlation why can strong correlation for levels close in time.
That is something you can do with correlated random effects in INLA. See
the blog post for details.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op di 29 jun. 2021 om 13:03 schreef A Mauchamp via R-sig-mixed-models <
r-sig-mixed-models at r-project.org>:

> Hello,
>
> I am currently analyzing (in R) ecological monitoring data that have 5
> successive years, one point per year and multiple sites and replicates
> within sites. Having a combination of fixed (environmental variables) and
> random (sites) effects, I need to use mixed models.
> Using glmer of the package lme4, I would like to account for the strong
> correlation between one year data and the following that I observe for most
> variables.
> I found this idea here
> https://stackoverflow.com/questions/24452796/accounting-for-temporal-correlation-in-glmm
> which looks very simple and straightforward.
> It would result in a formula as
> y_t ~ env1 + env2 + env3 + y_t-1 + (1|site)
> However in some cases, all environmental effects disappear and the only
> relation that remains is with y_t-1.
>
> I also found this approach:
> y ~ env1+ env2 + time + (1|replicate) + (1|site) that treats time as fixed
> effect and groups the repeated measures of replicates. Though I am not sure
> it is correct.
>
> Would it be correct to use time as a random effect ?
>
> Data are either count data (Poisson error distribution) or quantitative
> and gaussian.
> Which would be the most appropriate way of dealing with such repeated
> measures /short time series ?
> Which reference could I use to support the method ?
> My data series is indeed to short to go for a real time-series analysis
> and I don't think I can go for more than one year lag.
>
> Thank you for any suggestion,
> Andre
>
> Sent with [ProtonMail](https://protonmail.com/) Secure Email.
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


