From ken.knoblauch at inserm.fr  Fri Oct  1 08:33:32 2010
From: ken.knoblauch at inserm.fr (Ken Knoblauch)
Date: Fri, 1 Oct 2010 06:33:32 +0000 (UTC)
Subject: [R-sig-ME] Logistic and nonlinear mixed models: Accounting for
	guessing probability
References: <C8C66EA3.24A6%miller@biopsych.tu-dresden.de>
	<1285604724.17358.4.camel@localhost.localdomain>
	<AANLkTimc2hR1Br247tCAGeNnvWXcSb_hjBK7s90nmzW5@mail.gmail.com>
	<AANLkTi=kXkb-kah9KRhA31=tBcwaNiMWMkVpDTYG4=mp@mail.gmail.com>
Message-ID: <loom.20101001T081523-330@post.gmane.org>

Douglas Bates <bates at ...> writes:

> 
> On Thu, Sep 30, 2010 at 3:29 PM, Douglas Bates <bates at ...> 
wrote:
> > Unfortunately an nlmer model is not appropriate for a binary 
response,
> > because it doesn't appropriately weight the residuals.
> >
> > Incorporating a non-zero guessing parameter requires a 
generalized
> > nonlinear mixed model if you need to estimate the guessing 
parameter.
> > The long term plan is to allow such a model. ?This is the 
reason that
> > Martin and I worked on factoring out the internal code 
dealing with
> > different kinds of models for the expected response. ?
Nonlinear 
models
> > affect these in one way and generalized linear models 
in another 
so
> > you need to chain these effects.
> >
> > For the particular case that Robert is considering, in 
which the
> > guessing parameter is fixed at 0.33 I think it may be 
possible to use
> > the mafc.logit link from the psyphy package with lme4a, the
> > development version of lme4. ?I am currently installing the 
necessary
> > packages to see if I can make it work. ?My thanks to Robert 
for making
> > the data available so we can test it.
> 
> It wasn't as easy as I had hoped it would be.  I'm getting 
an error
> when evaluating the linkfun (and, presumably, will get 
such an error
> for all the other functions in the family).  It probably has 
to do
> with the environment in which the function is evaluated 
in that it
> can't see the value of 'm'.
> 
> I'm not sure if I will be able to fix it in a reasonable 
amount of
> time (I should be grading assignments from one of 
my classes right
> now).

First, let me say thanks for putting some time into this issue,
 though I can hear you; it's time that you don't have.

If either you are Martin can suggest some way that I could modify
the mafc functions in psyphy to make m visible, I would be
happy to change them, provided they still work with glm, or I would
just define special ones for mixed effects models, but that wouldn't
be as efficient.  For example, I would think that defining functions with
fixed m for 2, 3, and 4 (and possibly 8) would cover about 99% of 
the cases in my field, but I can't speak for others.  In fact, would the 
following work for the case m = 3 in your modified code,

mafc.logit3 <- function () 
{

    linkfun <- function(mu) {
        mu <- pmax(mu, 1/3 + .Machine$double.eps)
        qlogis((3 * mu - 1)/2)
    }
    linkinv <- function(eta) {
        1/3 + (2/3) * .Call("logit_linkinv", eta, PACKAGE = "stats")
    }
    mu.eta <- function(eta) (2/3) * .Call("logit_mu_eta", 
        eta, PACKAGE = "stats")
    valideta <- function(eta) TRUE
    link <- paste("mafc.logit()", sep = "")
    structure(list(linkfun = linkfun, linkinv = linkinv, mu.eta = mu.eta, 
        valideta = valideta, name = link), class = "link-glm")
}



Finally, there is also the ecc2 data set in the psyphy package, if you 
need another data set for testing.  It is from a 4-alternative experiment
in which an obtserver had to choose between 1 of 4 positions at which a 
low contrast letter appeared and then identify it as 1 of 4 possible letters. 
It gives the aggrergated proportion correct, not the individual binary 
responses, but I could dig them out (I still have all that data), if binary 
responses were preferred.

Good luck.

best,

Ken

-- 
Ken Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html



From ken.knoblauch at inserm.fr  Fri Oct  1 09:23:57 2010
From: ken.knoblauch at inserm.fr (Ken Knoblauch)
Date: Fri, 1 Oct 2010 07:23:57 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?Logistic_and_nonlinear_mixed_models=3A_Accou?=
	=?utf-8?q?nting_for=09guessing_probability?=
References: <C8C66EA3.24A6%miller@biopsych.tu-dresden.de>
	<1285604724.17358.4.camel@localhost.localdomain>
	<AANLkTimc2hR1Br247tCAGeNnvWXcSb_hjBK7s90nmzW5@mail.gmail.com>
	<AANLkTi=kXkb-kah9KRhA31=tBcwaNiMWMkVpDTYG4=mp@mail.gmail.com>
	<loom.20101001T081523-330@post.gmane.org>
Message-ID: <loom.20101001T092223-528@post.gmane.org>

Ken Knoblauch <ken.knoblauch at ...> writes:


> Finally, there is also the ecc2 data set in the psyphy package, if you 
> need another data set for testing.  It is from a 4-alternative experiment
> in which an obtserver had to choose between 1 of 4 positions at which a 
> low contrast letter appeared and then identify it as 1 of 4 possible letters. 
> It gives the aggrergated proportion correct, not the individual binary 
> responses, but I could dig them out (I still have all that data), if binary 
> responses were preferred.
> 
Oops, the ecc2 data set doesn't involve any random effects.
Sorry about that.  

La cervelle ne marche pas bien avant le petit dej.

Ken



From m.fairbrother at bristol.ac.uk  Fri Oct  1 13:08:22 2010
From: m.fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Fri, 1 Oct 2010 12:08:22 +0100
Subject: [R-sig-ME] multilevel time series?
In-Reply-To: <AANLkTimjt1DU3c8=Hs-SuWZc4CuQz4rTaCtSq_5LMCz+@mail.gmail.com>
References: <mailman.593.1285510498.4267.r-sig-mixed-models@r-project.org>
	<ACE5A2B9-475C-4038-ADFA-F76934B0E6FC@bristol.ac.uk>
	<3DB16098F738284D8DBEB2FC369916383B3B4B@inboexch.inbo.be>
	<AANLkTimjt1DU3c8=Hs-SuWZc4CuQz4rTaCtSq_5LMCz+@mail.gmail.com>
Message-ID: <170FA8CF-E52B-46A5-AF94-1D55DB5C25E9@bristol.ac.uk>

Many thanks to both of you. However, I realise now that my description of the data was misleading. When I said "each observed about 15 or 16 times over about a 30-year period", I was referring to *states*, not individuals. So each individual survey respondent appears only once in the dataset, but the states from which samples of respondents are drawn are observed multiple times. (Conceivably, a given person might be sampled more than once, but if that occurs at all it will be extremely rare, and the dataset we have won't tell us this anyway.)

However, your answers/suggestions have, actually, been very interesting, and useful. Consider:

The models we were using looked like:
lmer(outcome ~ covariates + time + (1 | stateyear) + (1 | state), data=data) # time is a linear effect, measured in (whole) years from the earliest year in the dataset

If I understand correctly, Thierry suggests:
lmer(outcome ~ covariates + (1 | stateyear) + (1 | state) + (1 | time), data=data)

I tried this, and the variance at the time level is small, but not zero, implying there are some year-specific disturbances that are common across states. I also got similar results from:
lmer(outcome ~ covariates + time + (1 | stateyear) + (1 | state) + (1 | time), data=data) # time as *both* a linear fixed effect and a random effect

However Doug seems to suggest:
lmer(outcome ~ covariates + time + (1 | stateyear) + (time | state), data=data) # and maybe also with a fixed effect and random slope for time^2

Both suggestions seem reasonable to me, and in fact I ran a model combining them, and got sensible results:
lmer(outcome ~ covariates + time + (1 | stateyear) + (time | state) + (1 | time), data=data)

My co-author and I are satisfied with this, but our reviewer implied he/she wanted to see the model with an AR1 structure, and we're stumped about how to do this. The nlme package can include AR1, but only where the autocorrelation is across lowest-level units, and in our case the autocorrelation is across higher-level units.

Doug, can you suggest a reference that we might use to justify our choice of model? (That, is assuming you still agree with what we're doing, given the revised description of the data, provided above.)

The suggestions are very much appreciated.
- Malcolm


On 30 Sep 2010, at 20:56, Douglas Bates wrote:

> On Mon, Sep 27, 2010 at 3:34 AM, ONKELINX, Thierry
> <Thierry.ONKELINX at inbo.be> wrote:
>> Dear Malcolm,
> 
>> Your design requires IMHO crossed random effects instead of nested
>> random effects. Individual is clearly crossed with year. Each individual
>> can be surveyed in more that one year and vice versa. If they were
>> nested, all data from a specific individual would come from only one
>> specific year. The same goes for state and year, they are rather crossed
>> than nested.
> 
> Malcolm's original description mentions modeling a linear trend in
> time, which would make sense to me.  Even taking into account the fact
> that a person can move from one state to another (hence you don't have
> strict nesting of the person and state factors) such data can still be
> analyzed using lme4.  Before doing so I would want to plot response
> versus time for several individuals, just to see if a linear trend
> looks adequate.  Having 15 to 20 different time points per subject
> would allow you to model more than a linear trend within subject.
> 
> Sometimes people will approach such a case using time series methods,
> even though the series are rather short.  Simple relationships like an
> AR1 (first-order autoregressive) model generate marginal covariance
> patterns that are very similar to that generated by a model with
> per-subject random effects for the intercept and the slope with
> respect to time.  This is why I don't usually combine these terms.  It
> is hard to separate out the effect of each.
> 
> Your suggestion is somewhat different.  It is more like a panel data
> type of model and could definitely be appropriate if the effect of a
> particular year was more-or-less common across subjects.  This type of
> model is applied to data like the quarterly profits of several
> companies.  Macro-economic forces can (and did) have industry-wide
> effects on the Q1 results in 2009 so it makes sense to regard each
> time period as distinct.
> 
> If, on the other hand, you had time trends within individuals but not
> synchronized across time periods then I would set up a model for the
> within-subject time trends and try to incorporate random effects in
> that model, as Malcolm seems to indicate they have done.
> 
>> Fitting year as a crossed random effect will take nonstationarity along
>> time into account. The size of variance of this random effect will
>> indicate how strong this nonstationarity is.
>>> -----Oorspronkelijk bericht-----
>>> Van: r-sig-mixed-models-bounces at r-project.org
>>> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens
>>> Malcolm Fairbrother
>>> Verzonden: zondag 26 september 2010 21:18
>>> Aan: r-sig-mixed-models at r-project.org
>>> Onderwerp: [R-sig-ME] multilevel time series?
>>> 
>>> Dear all,
>>> 
>>> In macro-social science, it's become fairly conventional to
>>> analyse repeated cross-sectional survey data using
>>> three-level models. Individual survey espondents (level-1)
>>> are nested in state-years (level-2), which are in turn nested
>>> within states (level-3). One big pay-off is the ability to
>>> examine how time-constant or time-varying state-level
>>> variables affect level-1 outcomes.
>>> 
>>> A co-author and I recently had a reviewer question whether
>>> this approach is adequate, however. He/she suggested that
>>> this approach could generate very misleading results, if the
>>> data are nonstationary. (We just included a linear time
>>> effect in our models.) So I'm thinking about how to proceed
>>> (and I'm not particularly knowledgeable about time series
>>> analysis). Any advice would be much appreciated. We used lme4
>>> to fit the models in our paper, and we have several tens of
>>> thousands of respondents nested in 48 states, each observed
>>> about 15 or 16 times over about a 30-year period.
>>> 
>>> (1) Is the reviewer's query? Is he/she right to question this
>>> approach?
>>> 
>>> (2) How might we test for nonstationarity? The reviewer
>>> mentioned differencing the outcome variable, but in a
>>> multilevel context I'm not sure how to do that... Perhaps we
>>> could calculate an *aggregate* value for every state-year,
>>> and check the aggregated data for autocorrelation? My
>>> understanding is that autocorrelation across multiple lags is
>>> a strong indicator of nonstationarity (while, conversely, the
>>> absence of multiple-lag autocorrelation is almost a guarantee
>>> of stationarity). I believe this can be done with nlme, as a
>>> two-level model, with state-years nested within states.
>>> 
>>> (3) However, that approach would seem to throw away a lot of
>>> level-1 information (about individual respondents), and I'm
>>> not sure about the implications for any significance tests.
>>> An alternative approach would seem to be "multilevel time
>>> series", where autocorrelation at the *group* rather than
>>> individual/first level is specifically allowed for in the
>>> model. However, I can't find any references to R packages (or
>>> other software) that allow for the specification of, for
>>> example, AR1 processes at anything other than level-1 in
>>> multilevel models.
>>> 
>>> In short, I'd be curious to hear what people think...
>>> (especially if anyone out there happens to be a whiz at both
>>> multilevel and time series analysis). I hope I've been clear
>>> about the problem, but I'm happy to elaborate. Thanks in
>>> advance for any help.
>>> 
>>> Cheers,
>>> Malcolm
>>> 
>>> 
>>> Dr Malcolm Fairbrother
>>> Lecturer
>>> School of Geographical Sciences
>>> University of Bristol
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>> 
>> Druk dit bericht a.u.b. niet onnodig af.
>> Please do not print this message unnecessarily.
>> 
>> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer
>> en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
>> door een geldig ondertekend document. The views expressed in  this message
>> and any annex are purely those of the writer and may not be regarded as stating
>> an official position of INBO, as long as the message is not confirmed by a duly
>> signed document.
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 



From ken.knoblauch at inserm.fr  Fri Oct  1 16:45:20 2010
From: ken.knoblauch at inserm.fr (Ken Knoblauch)
Date: Fri, 1 Oct 2010 14:45:20 +0000 (UTC)
Subject: [R-sig-ME] Logistic and nonlinear mixed models: Accounting for
	guessing probability
References: <C8C669BD.24A1%miller@biopsych.tu-dresden.de>
	<C8C66EA3.24A6%miller@biopsych.tu-dresden.de>
Message-ID: <loom.20101001T163141-421@post.gmane.org>

Robert Miller <miller at ...> writes:

> 
> Hello everyone,
> 
> Recently i tried to predict the discrimination probability of a chemosignal
> by its concentration and an experimental manipulation factor (term:
> concentration*x + test*b + concentration*test*c + d) with nested factor
> "manipulation" within "participants". For statistical analysis i needed to
> incorporate a fixed guessing probability into my model (similiar to a 3-PL
> IRT model) resulting in the following equation:
> 
> P(correct) = 0.33 + 0.67*(exp(term)/(1 + exp(term)))
> 
> As i found no way to do so via the glmer()-function of the lme4-package, i
> tried to use nlmer() but unfortunately even the simplest analysis with just
> the concentration factor and intercept resulted in cryptic error messages.
> 
> Syntax:
> library(lme4)
> rawdata <- read.csv2("http://dl.dropbox.com/u/7147679/AND_data.csv")
> 
> mod1 <- glmer(Correct ~ log(Concentrat) * Test + (Test|Code), family =
> binomial, data=rawdata) #works fine but is inappropriate

Here is a temporary solution that Doug Bates encouraged me to share
with you to get you going, and until we come up with a more elegant/safer
method.  It requires the lme4a package as suggested and a modified link
from the psyphy package that I'll include below.  In essence, we solve
the problem of the visibility of m by making it global, which is not the
most elegant or safest of solutions, but it seems to work for now.

library(lme4a)

mafc.logit <- function (.m = 2) 
{
    .m <<- as.integer(.m)  # .m goes global
    if (.m < 2) 
        stop(".m must be an integer > 1")
    linkfun <- function(mu) {
        mu <- pmax(mu, 1/.m + .Machine$double.eps)
        qlogis((.m * mu - 1)/(.m - 1))
    }
    linkinv <- function(eta) {
        1/.m + (.m - 1)/.m * .Call("logit_linkinv", eta, PACKAGE = "stats")
    }
    mu.eta <- function(eta) ((.m - 1)/.m) * .Call("logit_mu_eta", 
        eta, PACKAGE = "stats")
    valideta <- function(eta) TRUE
    link <- paste("mafc.logit(", .m, ")", sep = "")
    structure(list(linkfun = linkfun, linkinv = linkinv, mu.eta = mu.eta, 
        valideta = valideta, name = link), class = "link-glm")
}

rawdata <- read.csv2("http://dl.dropbox.com/u/7147679/AND_data.csv")
mod1 <- glmer(Correct ~ log(Concentrat) * Test + (Test|Code), family =
     binomial(mafc.logit(3)), data=rawdata)
summary(mod1)
Generalized linear mixed model fit by maximum likelihood ['summary.mer']
 Family: binomial 
Formula: Correct ~ log(Concentrat) * Test + (Test | Code) 
   Data: rawdata 
      AIC       BIC    logLik  deviance 
 277.0939  301.4584 -131.5469  263.0939 

Random effects:
 Groups Name        Variance Std.Dev. Corr 
 Code   (Intercept) 112.6    10.61         
        Test        103.0    10.15    0.994
Number of obs: 240, groups: Code, 10

Fixed effects:
                     Estimate Std. Error z value
(Intercept)           -26.942     10.715  -2.514
log(Concentrat)         5.041      1.876   2.687
Test                   -1.918      6.931  -0.277
log(Concentrat):Test    2.136      1.304   1.638

Correlation of Fixed Effects:
            (Intr) lg(Cn) Test  
lg(Cncntrt) -0.934              
Test        -0.136  0.269       
lg(Cncnt):T -0.087  0.097 -0.739

range(fitted(mod1))
[1] 0.3333333 1.0000000

HTH

Ken

> Right now I'm quite desperate and would appreciate any help.
> Thank you
> Robert Miller
> 
> 

-- 
Ken Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html



From Corey.Godfrey at cadmusgroup.com  Fri Oct  1 21:33:58 2010
From: Corey.Godfrey at cadmusgroup.com (Corey Godfrey)
Date: Fri, 1 Oct 2010 15:33:58 -0400
Subject: [R-sig-ME] Confidence Intervals on Fitted Values from lmer
Message-ID: <8ACCEAD87A0FBD4B94590BEB20D9224A0D6E96B048@mail.cadmusgroup.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101001/b24b20fa/attachment.pl>

From bates at stat.wisc.edu  Fri Oct  1 21:54:53 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 1 Oct 2010 14:54:53 -0500
Subject: [R-sig-ME] Confidence Intervals on Fitted Values from lmer
In-Reply-To: <8ACCEAD87A0FBD4B94590BEB20D9224A0D6E96B048@mail.cadmusgroup.org>
References: <8ACCEAD87A0FBD4B94590BEB20D9224A0D6E96B048@mail.cadmusgroup.org>
Message-ID: <AANLkTikeSiJnEYq5VB80hZtxXJXXZmS2L_Eo5A786TNL@mail.gmail.com>

On Fri, Oct 1, 2010 at 2:33 PM, Corey Godfrey
<Corey.Godfrey at cadmusgroup.com> wrote:
> Hello,

> I would like to plot confidence intervals around the fitted values of a mixed effects model. Is this advisable? If so, is there a method for doing so?

First you need to decide what kind of confidence interval you have in
mind, involving the fixed-effects parameters only or both the fixed-
and random-effects.  You may be able to get what you want from the
variance-covariance matrix for the estimates of the fixed-effects
parameters, available as vcov(fittedModel), but I can't guarantee it.
I would need to think more carefully about the interpretation of the
various types of variability.



From Corey.Godfrey at cadmusgroup.com  Fri Oct  1 22:17:48 2010
From: Corey.Godfrey at cadmusgroup.com (Corey Godfrey)
Date: Fri, 1 Oct 2010 16:17:48 -0400
Subject: [R-sig-ME] Confidence Intervals on Fitted Values from lmer
In-Reply-To: <AANLkTikeSiJnEYq5VB80hZtxXJXXZmS2L_Eo5A786TNL@mail.gmail.com>
References: <8ACCEAD87A0FBD4B94590BEB20D9224A0D6E96B048@mail.cadmusgroup.org>
	<AANLkTikeSiJnEYq5VB80hZtxXJXXZmS2L_Eo5A786TNL@mail.gmail.com>
Message-ID: <8ACCEAD87A0FBD4B94590BEB20D9224A0D6E96B0A6@mail.cadmusgroup.org>

Yes, that seems to be the tricky part. I am able to extract what I need for the fixed effects from the variance-covariance matrix. However, the resulting confidence intervals are much wider than I believe they should be. I think this might be because the random effects are helping to explain some of the variance in the data, resulting in "significant" t-values on my fixed effects of interest, but they (the random effects) are not included in the calculation of the confidence intervals. Therefore, a plot of the fitted values and  confidence intervals appears to show a non-significant association between fitted values and my fixed effect of interest (i.e., you could draw a straight line between the CIs).

I apologize for not including the code in my post, but it is quite lengthy. I am also not a statistician or an expert in R, so am doing my best to explain this problem without getting in too far over my head.

-----Original Message-----
From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas Bates
Sent: Friday, October 01, 2010 3:55 PM
To: Corey Godfrey
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Confidence Intervals on Fitted Values from lmer

On Fri, Oct 1, 2010 at 2:33 PM, Corey Godfrey
<Corey.Godfrey at cadmusgroup.com> wrote:
> Hello,

> I would like to plot confidence intervals around the fitted values of a mixed effects model. Is this advisable? If so, is there a method for doing so?

First you need to decide what kind of confidence interval you have in
mind, involving the fixed-effects parameters only or both the fixed-
and random-effects.  You may be able to get what you want from the
variance-covariance matrix for the estimates of the fixed-effects
parameters, available as vcov(fittedModel), but I can't guarantee it.
I would need to think more carefully about the interpretation of the
various types of variability.



From Mike.Lawrence at dal.ca  Sat Oct  2 10:02:50 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Sat, 2 Oct 2010 05:02:50 -0300
Subject: [R-sig-ME] Confidence Intervals on Fitted Values from lmer
In-Reply-To: <8ACCEAD87A0FBD4B94590BEB20D9224A0D6E96B0A6@mail.cadmusgroup.org>
References: <8ACCEAD87A0FBD4B94590BEB20D9224A0D6E96B048@mail.cadmusgroup.org>
	<AANLkTikeSiJnEYq5VB80hZtxXJXXZmS2L_Eo5A786TNL@mail.gmail.com>
	<8ACCEAD87A0FBD4B94590BEB20D9224A0D6E96B0A6@mail.cadmusgroup.org>
Message-ID: <AANLkTinCq31e8FKWWnc9hnr8Eapw1Mm12pLds7Q8Jpt=@mail.gmail.com>

I thought I'd try to contribute a couple points:

1) Overlap of 95% CIs doesn't necessarily mean that two points can't
be considered as draw from populations of different means. On the
other hand, examining overlap of 84% CIs may let you make this
inference. Ref:
http://stats.stackexchange.com/questions/1169/ci-for-a-difference-based-on-independent-cis

2) The latest version (2.1) of the ez package, released earlier this
week, has an ezPredict() function that obtains lmer model predictions
for fixed effects plus expected variance (n.b. the variance considers
fixed effects only). Mostly a wrapper around code found at the glmm
wiki (glmm.wikidot.com/faq), but possibly convenient.

3) When in doubt, bootstrap! :Op Depending on the complexity of your
design, you may find the ezBoot() function from the ez package
interesting. By default it can only accept 1 random effect, and fixed
effects aren't allowed to affect the intercept, but you could take a
look at its source and easily adapt it to a more complex situation
(though you'll need to give careful consideration to formulating a
proper sampling procedure in the context of those complications). Then
look to ezBootPlot() for visualization inspiration.

Cheers,

Mike

--
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~



On Fri, Oct 1, 2010 at 5:17 PM, Corey Godfrey
<Corey.Godfrey at cadmusgroup.com> wrote:
> Yes, that seems to be the tricky part. I am able to extract what I need for the fixed effects from the variance-covariance matrix. However, the resulting confidence intervals are much wider than I believe they should be. I think this might be because the random effects are helping to explain some of the variance in the data, resulting in "significant" t-values on my fixed effects of interest, but they (the random effects) are not included in the calculation of the confidence intervals. Therefore, a plot of the fitted values and ?confidence intervals appears to show a non-significant association between fitted values and my fixed effect of interest (i.e., you could draw a straight line between the CIs).
>
> I apologize for not including the code in my post, but it is quite lengthy. I am also not a statistician or an expert in R, so am doing my best to explain this problem without getting in too far over my head.
>
> -----Original Message-----
> From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas Bates
> Sent: Friday, October 01, 2010 3:55 PM
> To: Corey Godfrey
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Confidence Intervals on Fitted Values from lmer
>
> On Fri, Oct 1, 2010 at 2:33 PM, Corey Godfrey
> <Corey.Godfrey at cadmusgroup.com> wrote:
>> Hello,
>
>> I would like to plot confidence intervals around the fitted values of a mixed effects model. Is this advisable? If so, is there a method for doing so?
>
> First you need to decide what kind of confidence interval you have in
> mind, involving the fixed-effects parameters only or both the fixed-
> and random-effects. ?You may be able to get what you want from the
> variance-covariance matrix for the estimates of the fixed-effects
> parameters, available as vcov(fittedModel), but I can't guarantee it.
> I would need to think more carefully about the interpretation of the
> various types of variability.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From skorsky12 at gmail.com  Sun Oct  3 09:05:37 2010
From: skorsky12 at gmail.com (Koala)
Date: Sun, 3 Oct 2010 07:05:37 +0000 (UTC)
Subject: [R-sig-ME] C test functions for lmer()
Message-ID: <loom.20101003T090241-190@post.gmane.org>

Hi everyone, I am trying to use lmer() using only C; Does anyone have test
functions available that do not require R? My main routine needs to be C, but I
am having a hard time understanding the data types going back and forth between
R and lme4 C code. Any help would be appreciated, 

Thanks,



From bates at stat.wisc.edu  Sun Oct  3 16:05:04 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 3 Oct 2010 09:05:04 -0500
Subject: [R-sig-ME] C test functions for lmer()
In-Reply-To: <loom.20101003T090241-190@post.gmane.org>
References: <loom.20101003T090241-190@post.gmane.org>
Message-ID: <AANLkTikLP4ZPYtUmQt_GR3rFjWC=eDuXV+Vvt=kYW=dk@mail.gmail.com>

On Sun, Oct 3, 2010 at 2:05 AM, Koala <skorsky12 at gmail.com> wrote:
> Hi everyone, I am trying to use lmer() using only C; Does anyone have test
> functions available that do not require R? My main routine needs to be C, but I
> am having a hard time understanding the data types going back and forth between
> R and lme4 C code. Any help would be appreciated,

Well, naturally enough, those structures are the internal
representations of R objects - vectors, matrices, functions, etc.  You
would need to read the "Writing R Extensions" manual to understand
their structure and even then you would need most of the R API to be
able to manipulate them.  If you really want to embark on this, and it
is definitely not trivial, I would recommend looking at the code in
the lme4a package instead, because it is based on C++ classes and the
Rcpp package.  I'm not sure that I see the point, though, as R is
already open source.  If you want to reimplement for another system
you would probably be better off examining the structure of the
calculations and reimplementing them instead of trying to adapt the
lme4 code.



From bates at stat.wisc.edu  Sun Oct  3 17:28:11 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 3 Oct 2010 10:28:11 -0500
Subject: [R-sig-ME] C test functions for lmer()
In-Reply-To: <AANLkTi=phdBH1RS=TyCNNvFauXGErqTonew+HjXA8AWt@mail.gmail.com>
References: <loom.20101003T090241-190@post.gmane.org>
	<AANLkTikLP4ZPYtUmQt_GR3rFjWC=eDuXV+Vvt=kYW=dk@mail.gmail.com>
	<AANLkTi=phdBH1RS=TyCNNvFauXGErqTonew+HjXA8AWt@mail.gmail.com>
Message-ID: <AANLkTik47jPkWX+tnEYFS1ET4+ezYb__wT3hQgz+VDEW@mail.gmail.com>

On Sun, Oct 3, 2010 at 10:03 AM, murat k. <skorsky12 at gmail.com> wrote:
> Hi, the caller side must be C based for my needs; Thanks for the lme4a
> suggestion.

> I also saw an nlme package, which was a precursor to lme4 I belive.. Its
> interface seems to use more of basic C types, so it is easier to understand.
> I might actually go with that option, instead of lme4 which is too tightly
> integrated into R at this point.

Well the code in the nlme package is more than 10 years old and we
have learned a lot about the computational methods in the intervening
years.

If you just want to fit a simple model with a random intercept you
would be much better off starting from the equations or the C++
classes instead of trying to decide what the internal C code in either
nlme or lme4 is doing.

> On Sun, Oct 3, 2010 at 5:05 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
>>
>> On Sun, Oct 3, 2010 at 2:05 AM, Koala <skorsky12 at gmail.com> wrote:
>> > Hi everyone, I am trying to use lmer() using only C; Does anyone have
>> > test
>> > functions available that do not require R? My main routine needs to be
>> > C, but I
>> > am having a hard time understanding the data types going back and forth
>> > between
>> > R and lme4 C code. Any help would be appreciated,
>>
>> Well, naturally enough, those structures are the internal
>> representations of R objects - vectors, matrices, functions, etc. ?You
>> would need to read the "Writing R Extensions" manual to understand
>> their structure and even then you would need most of the R API to be
>> able to manipulate them. ?If you really want to embark on this, and it
>> is definitely not trivial, I would recommend looking at the code in
>> the lme4a package instead, because it is based on C++ classes and the
>> Rcpp package. ?I'm not sure that I see the point, though, as R is
>> already open source. ?If you want to reimplement for another system
>> you would probably be better off examining the structure of the
>> calculations and reimplementing them instead of trying to adapt the
>> lme4 code.
>
>



From paul.metzner at gmail.com  Mon Oct  4 10:15:15 2010
From: paul.metzner at gmail.com (Paul Metzner)
Date: Mon, 4 Oct 2010 10:15:15 +0200
Subject: [R-sig-ME] Zero-inflated Poisson distribution
Message-ID: <05FC42B0-112D-4284-B2BF-A9D788090006@gmail.com>

Hello!

I am analyzing eye-movement data with LMM and find it difficult to get my head around the regression counts. They are heavily zero-inflated, which, as far as I know, renders a simple Poisson GLMM improbable. Would the following (simplified) command do the zero-inflation justice?

m1 <- lmer(RBRC~COND+CPCU+COND:CPCU+DIR+COND:DIR+(1|SUBJECT)+(1|ITEM), cr, quasipoisson)
m2 <- lmer(RBRC~COND+CPCU+COND:CPCU+DIR+COND:DIR+(1|SUBJECT)+(1|ITEM), cr, poisson)

The outcome is dramatically different from a poisson LMM, with three effects hinging on the choice of distribution. I'm afraid m1 might be overestimating, since the numerical difference is miniscule. I uploaded histograms at http://amor.cms.hu-berlin.de/~metznerp/ghist_trc.pdf and http://amor.cms.hu-berlin.de/~metznerp/ghist_rbrc.pdf.

Best,
Paul

---
Paul Metzner

Humboldt-Universit?t zu Berlin
Philosophische Fakult?t II
Institut f?r deutsche Sprache und Linguistik

Post: Unter den Linden 6 | 10099 Berlin | Deutschland
Besuch: Dorotheenstra?e 24 | 10117 Berlin | Deutschland

+49-(0)30-2093-9726
paul.metzner at rz.hu-berlin.de
http://amor.rz.hu-berlin.de/~metznerp/



From lamp at ese.eur.nl  Mon Oct  4 10:07:06 2010
From: lamp at ese.eur.nl (Felix Lamp)
Date: Mon, 4 Oct 2010 10:07:06 +0200
Subject: [R-sig-ME] Parameter restrictions
Message-ID: <48A907AA-B030-4F57-B840-C0D31230DF7F@ese.eur.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101004/0a0ef4d7/attachment.pl>

From skorsky12 at gmail.com  Mon Oct  4 18:50:56 2010
From: skorsky12 at gmail.com (Koala)
Date: Mon, 4 Oct 2010 16:50:56 +0000 (UTC)
Subject: [R-sig-ME] Entry point for lme4a
Message-ID: <loom.20101004T184835-482@post.gmane.org>

I am trying to pinpoint the entry point into C++ functions for lme4a. This
function in external.cpp

RCPP_FUNCTION_6(NumericVector, merDeviance, S4 xp, NumericVector theta,
		NumericVector beta, NumericVector u0, int verb, int alg) {

seemed to be it, but it is being called multiple times. What is the
corresponding C function to lmer() call in R? I am trying to call lme4a from an
outside C++ function that I need to integrate.



From bates at stat.wisc.edu  Mon Oct  4 19:32:59 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 4 Oct 2010 12:32:59 -0500
Subject: [R-sig-ME] Entry point for lme4a
In-Reply-To: <loom.20101004T184835-482@post.gmane.org>
References: <loom.20101004T184835-482@post.gmane.org>
Message-ID: <AANLkTimzUTdOphyuOkX-x2uLdKRRtV5VOAOrzBOGyS-V@mail.gmail.com>

On Mon, Oct 4, 2010 at 11:50 AM, Koala <skorsky12 at gmail.com> wrote:
> I am trying to pinpoint the entry point into C++ functions for lme4a. This
> function in external.cpp

> RCPP_FUNCTION_6(NumericVector, merDeviance, S4 xp, NumericVector theta,
> ? ? ? ? ? ? ? ?NumericVector beta, NumericVector u0, int verb, int alg) {

> seemed to be it, but it is being called multiple times.

Yes, that is the C++ function that evaluates the deviance.  It is
called repeatedly during the optimization of the deviance or REML
critterion.

> What is the
> corresponding C function to lmer() call in R? I am trying to call lme4a from an
> outside C++ function that I need to integrate.

I have tried to explain that there is no one C function the
corresponds to lmer.  If you look at the R code for lmer you will see
that a large amount of the code is written in the R language itself
and only the very core of the evaluation of the objective function is
written in the compiled language.  Expecting that there will be one C
function that you call and it "does lmer" for you is naive.  The lme4a
package depends strongly on the Matrix package, which, in turn,
depends on the CHOLMOD and AMD C libraries, and the MatrixModels
package and the Rcpp package and many, many facilities in base R.

If you have a very simple model and you need to implement the
calculations in C then I would suggest starting from the equations
rather than trying to find some magic C code that isn't there.  I'm
still at a loss to understand why you need to reimplement these
calculations in C.  I have been contacted in the past by software
vendors (Cytel) who thought that they could easily modify the lme4a
package to include such capabilities in proprietary software and this
is beginning to sound like that.

The lmer function is an R function that relies strongly on the
capabilities in base R and many R packages.  If you want to recreate
it from scratch in C you have a lot of work to do, much more than
simply discovering which C entry point to call.



From bates at stat.wisc.edu  Mon Oct  4 19:38:17 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 4 Oct 2010 12:38:17 -0500
Subject: [R-sig-ME] Parameter restrictions
In-Reply-To: <48A907AA-B030-4F57-B840-C0D31230DF7F@ese.eur.nl>
References: <48A907AA-B030-4F57-B840-C0D31230DF7F@ese.eur.nl>
Message-ID: <AANLkTimYTmS+mdefOhbh8w9cDsgq56frP7=dk7Rus=hw@mail.gmail.com>

On Mon, Oct 4, 2010 at 3:07 AM, Felix Lamp <lamp at ese.eur.nl> wrote:
> Dear all,

> is there a simple way in R to add parameter restrictions to linear mixed effects models. Specifically I would like to restrict a slope coefficient to be equal to 1.

That is done by adding an offset, which can be done in two ways.  The
general model might be

lmer(y ~ 1 + x + (1|g))

and the model with the slope restricted to 1 is either

lmer(y ~ 1 + offset(x) + (1|g))

or

lmer(y ~ 1 + (1|g), offset=x)

IIRC one of them works properly and one doesn't although I can't
recall which one is which.  Try them both.



From lbelton at zoology.up.ac.za  Tue Oct  5 08:06:15 2010
From: lbelton at zoology.up.ac.za (Lydia Belton)
Date: Tue, 5 Oct 2010 08:06:15 +0200
Subject: [R-sig-ME] Structural zeros in lme4
Message-ID: <c34f88b8c50d5bb149bd4438049bbbb0.squirrel@zoology.up.ac.za>

Dear R users,
I am working with a binary data set of categorical variables with repeated
measurements on 100 individuals over 24 trials with follwing variables

success =0 or 1
age = j, s, y or a
ra = l, m, h
sex= m or f

With the data layed out as below

success   age    ra    sex   ind trial
1         a      l     m     1     1
1         s      m     f     2     1
0         y      h     f     3     1
....................................
....................................
....................................
0         a      l     m     1     24
0         s      m     f     2     24
1         y      h     f     3     24
When I try to run the following model lme4

success~(age + ra + sex)^2 + (1|ind), binomial, verbose=T)
I get the following error message

0:           nan: 0.411061 -2.99573 -0.587787  14.0386  14.3205 -12.5703
-11.9282  11.3544  12.2767  1.07485  1.33312  13.4198      nan      nan
-11.0981 -14.4590 -13.2578  1.18634      nan
Error in asMethod(object) : matrix is not symmetric [1,2]
In addition: Warning message:
In mer_finalize(ans) : gr cannot be computed at initial par (65)

>From reading previous posts I'm assuming this is caused by empty cells
that are produced by the interactions in the data set.

However these empty cells are inherent in the data. Whilst all
combinations of sex and age are possible not all combinations or ra and
age, or ra and sex, can exist.

Specifically ra = l and sex = f
             ra = l and age = s
             ra = l and age = j cannot occur.

If the interactions with ra are removed the model runs. However
interactions between ra, age and sex are theoretically possible. From
looking at the raw data and running a glm without individual as a random
effect it seems like there might be a significant interaction between ra
and age.

Does anyone know if there is a way to test this without collapsing my data?


------------------------------------------------------------------
This message and attachments are subject to a disclaimer. Please refer to http://www.it.up.ac.za/documentation/governance/disclaimer/ for full details. / Hierdie boodskap en aanhangsels is aan 'n vrywaringsklousule onderhewig. Volledige besonderhede is by http://www.it.up.ac.za/documentation/governance/disclaimer/ beskikbaar.



From malsburg at gmail.com  Tue Oct  5 11:37:56 2010
From: malsburg at gmail.com (Titus von der Malsburg)
Date: Tue, 5 Oct 2010 11:37:56 +0200
Subject: [R-sig-ME] Zero-inflated Poisson distribution
In-Reply-To: <05FC42B0-112D-4284-B2BF-A9D788090006@gmail.com>
References: <05FC42B0-112D-4284-B2BF-A9D788090006@gmail.com>
Message-ID: <AANLkTikfJcA1Gycw-SQPpzicE2pxsf1c-Wu1nF=JzQbu@mail.gmail.com>

On Mon, Oct 4, 2010 at 10:15 AM, Paul Metzner <paul.metzner at gmail.com> wrote:
> I am analyzing eye-movement data with LMM and find it difficult to get my head around the regression counts. They are heavily zero-inflated, which, as far as I know, renders a simple Poisson GLMM improbable. Would the following (simplified) command do the zero-inflation justice?
>
> m1 <- lmer(RBRC~COND+CPCU+COND:CPCU+DIR+COND:DIR+(1|SUBJECT)+(1|ITEM), cr, quasipoisson)
> m2 <- lmer(RBRC~COND+CPCU+COND:CPCU+DIR+COND:DIR+(1|SUBJECT)+(1|ITEM), cr, poisson)
>
> The outcome is dramatically different from a poisson LMM, with three effects hinging on the choice of distribution. I'm afraid m1 might be overestimating, since the numerical difference is miniscule. I uploaded histograms at http://amor.cms.hu-berlin.de/~metznerp/ghist_trc.pdf and http://amor.cms.hu-berlin.de/~metznerp/ghist_rbrc.pdf.

I'm far from being an expert here, but I'm also interested in that
question.  To me it seems that your question is an empirical one.  The
correct link function is the one that makes the residuals look
normally distributed and this can be checked.  You would have to apply
the link function to the residuals and then use tests for normality.
What I don't know is how to do this technically.

Any suggestions or other opinions?

  Titus



From malsburg at gmail.com  Tue Oct  5 11:37:56 2010
From: malsburg at gmail.com (Titus von der Malsburg)
Date: Tue, 5 Oct 2010 11:37:56 +0200
Subject: [R-sig-ME] Zero-inflated Poisson distribution
In-Reply-To: <05FC42B0-112D-4284-B2BF-A9D788090006@gmail.com>
References: <05FC42B0-112D-4284-B2BF-A9D788090006@gmail.com>
Message-ID: <AANLkTikfJcA1Gycw-SQPpzicE2pxsf1c-Wu1nF=JzQbu@mail.gmail.com>

On Mon, Oct 4, 2010 at 10:15 AM, Paul Metzner <paul.metzner at gmail.com> wrote:
> I am analyzing eye-movement data with LMM and find it difficult to get my head around the regression counts. They are heavily zero-inflated, which, as far as I know, renders a simple Poisson GLMM improbable. Would the following (simplified) command do the zero-inflation justice?
>
> m1 <- lmer(RBRC~COND+CPCU+COND:CPCU+DIR+COND:DIR+(1|SUBJECT)+(1|ITEM), cr, quasipoisson)
> m2 <- lmer(RBRC~COND+CPCU+COND:CPCU+DIR+COND:DIR+(1|SUBJECT)+(1|ITEM), cr, poisson)
>
> The outcome is dramatically different from a poisson LMM, with three effects hinging on the choice of distribution. I'm afraid m1 might be overestimating, since the numerical difference is miniscule. I uploaded histograms at http://amor.cms.hu-berlin.de/~metznerp/ghist_trc.pdf and http://amor.cms.hu-berlin.de/~metznerp/ghist_rbrc.pdf.

I'm far from being an expert here, but I'm also interested in that
question.  To me it seems that your question is an empirical one.  The
correct link function is the one that makes the residuals look
normally distributed and this can be checked.  You would have to apply
the link function to the residuals and then use tests for normality.
What I don't know is how to do this technically.

Any suggestions or other opinions?

  Titus



From malsburg at gmail.com  Tue Oct  5 11:37:56 2010
From: malsburg at gmail.com (Titus von der Malsburg)
Date: Tue, 5 Oct 2010 11:37:56 +0200
Subject: [R-sig-ME] Zero-inflated Poisson distribution
In-Reply-To: <05FC42B0-112D-4284-B2BF-A9D788090006@gmail.com>
References: <05FC42B0-112D-4284-B2BF-A9D788090006@gmail.com>
Message-ID: <AANLkTikfJcA1Gycw-SQPpzicE2pxsf1c-Wu1nF=JzQbu@mail.gmail.com>

On Mon, Oct 4, 2010 at 10:15 AM, Paul Metzner <paul.metzner at gmail.com> wrote:
> I am analyzing eye-movement data with LMM and find it difficult to get my head around the regression counts. They are heavily zero-inflated, which, as far as I know, renders a simple Poisson GLMM improbable. Would the following (simplified) command do the zero-inflation justice?
>
> m1 <- lmer(RBRC~COND+CPCU+COND:CPCU+DIR+COND:DIR+(1|SUBJECT)+(1|ITEM), cr, quasipoisson)
> m2 <- lmer(RBRC~COND+CPCU+COND:CPCU+DIR+COND:DIR+(1|SUBJECT)+(1|ITEM), cr, poisson)
>
> The outcome is dramatically different from a poisson LMM, with three effects hinging on the choice of distribution. I'm afraid m1 might be overestimating, since the numerical difference is miniscule. I uploaded histograms at http://amor.cms.hu-berlin.de/~metznerp/ghist_trc.pdf and http://amor.cms.hu-berlin.de/~metznerp/ghist_rbrc.pdf.

I'm far from being an expert here, but I'm also interested in that
question.  To me it seems that your question is an empirical one.  The
correct link function is the one that makes the residuals look
normally distributed and this can be checked.  You would have to apply
the link function to the residuals and then use tests for normality.
What I don't know is how to do this technically.

Any suggestions or other opinions?

  Titus



From malsburg at gmail.com  Tue Oct  5 11:37:56 2010
From: malsburg at gmail.com (Titus von der Malsburg)
Date: Tue, 5 Oct 2010 11:37:56 +0200
Subject: [R-sig-ME] Zero-inflated Poisson distribution
In-Reply-To: <05FC42B0-112D-4284-B2BF-A9D788090006@gmail.com>
References: <05FC42B0-112D-4284-B2BF-A9D788090006@gmail.com>
Message-ID: <AANLkTikfJcA1Gycw-SQPpzicE2pxsf1c-Wu1nF=JzQbu@mail.gmail.com>

On Mon, Oct 4, 2010 at 10:15 AM, Paul Metzner <paul.metzner at gmail.com> wrote:
> I am analyzing eye-movement data with LMM and find it difficult to get my head around the regression counts. They are heavily zero-inflated, which, as far as I know, renders a simple Poisson GLMM improbable. Would the following (simplified) command do the zero-inflation justice?
>
> m1 <- lmer(RBRC~COND+CPCU+COND:CPCU+DIR+COND:DIR+(1|SUBJECT)+(1|ITEM), cr, quasipoisson)
> m2 <- lmer(RBRC~COND+CPCU+COND:CPCU+DIR+COND:DIR+(1|SUBJECT)+(1|ITEM), cr, poisson)
>
> The outcome is dramatically different from a poisson LMM, with three effects hinging on the choice of distribution. I'm afraid m1 might be overestimating, since the numerical difference is miniscule. I uploaded histograms at http://amor.cms.hu-berlin.de/~metznerp/ghist_trc.pdf and http://amor.cms.hu-berlin.de/~metznerp/ghist_rbrc.pdf.

I'm far from being an expert here, but I'm also interested in that
question.  To me it seems that your question is an empirical one.  The
correct link function is the one that makes the residuals look
normally distributed and this can be checked.  You would have to apply
the link function to the residuals and then use tests for normality.
What I don't know is how to do this technically.

Any suggestions or other opinions?

  Titus



From bbolker at gmail.com  Tue Oct  5 14:27:27 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 05 Oct 2010 08:27:27 -0400
Subject: [R-sig-ME] Zero-inflated Poisson distribution
In-Reply-To: <AANLkTikfJcA1Gycw-SQPpzicE2pxsf1c-Wu1nF=JzQbu@mail.gmail.com>
References: <05FC42B0-112D-4284-B2BF-A9D788090006@gmail.com>
	<AANLkTikfJcA1Gycw-SQPpzicE2pxsf1c-Wu1nF=JzQbu@mail.gmail.com>
Message-ID: <4CAB19AF.9040300@gmail.com>

On 10-10-05 05:37 AM, Titus von der Malsburg wrote:
> On Mon, Oct 4, 2010 at 10:15 AM, Paul Metzner
> <paul.metzner at gmail.com> wrote:
>> I am analyzing eye-movement data with LMM and find it difficult
>> to get my head around the regression counts. They are heavily
>> zero-inflated, which, as far as I know, renders a simple Poisson
>> GLMM improbable. Would the following (simplified) command do the
>> zero-inflation justice?
>>
>> m1 <-
>> lmer(RBRC~COND+CPCU+COND:CPCU+DIR+COND:DIR+(1|SUBJECT)+(1|ITEM),
>> cr, quasipoisson) m2 <-
>> lmer(RBRC~COND+CPCU+COND:CPCU+DIR+COND:DIR+(1|SUBJECT)+(1|ITEM),
>> cr, poisson)
>>
>> The outcome is dramatically different from a poisson LMM, with
>> three effects hinging on the choice of distribution. I'm afraid
>> m1 might be overestimating, since the numerical difference is
>> miniscule. I uploaded histograms at
>> http://amor.cms.hu-berlin.de/~metznerp/ghist_trc.pdf and
>> http://amor.cms.hu-berlin.de/~metznerp/ghist_rbrc.pdf.
>
> I'm far from being an expert here, but I'm also interested in that
> question.  To me it seems that your question is an empirical one.
> The correct link function is the one that makes the residuals look
> normally distributed and this can be checked.  You would have to
> apply the link function to the residuals and then use tests for
> normality. What I don't know is how to do this technically.
>
> Any suggestions or other opinions?
>
> Titus


   It's often very hard/nearly impossible to make residuals from a
discrete distribution,
especially a zero-inflated one, look normally distributed.  (There are
proposals in the
literature for jittering residuals in a theoretically sensible way,
but I wouldn't go
that direction.)  Also, quasi-likelihood fits in glmer are
questionable: several people have
reported strange results, and Doug Bates has essentially said that he
doesn't really
know what the justification is for quasi- fits in his mixed model
paradigm.

  My suggestion would be to try MCMCglmm, which does allow explicitly
zero-inflated models ...

  Ben Bolker



From bates at stat.wisc.edu  Tue Oct  5 16:01:37 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 5 Oct 2010 09:01:37 -0500
Subject: [R-sig-ME] Structural zeros in lme4
In-Reply-To: <c34f88b8c50d5bb149bd4438049bbbb0.squirrel@zoology.up.ac.za>
References: <c34f88b8c50d5bb149bd4438049bbbb0.squirrel@zoology.up.ac.za>
Message-ID: <AANLkTimkw+JE=_91wEpqmb5r0OzX4LtB2LMb8XHOCNiK@mail.gmail.com>

On Tue, Oct 5, 2010 at 1:06 AM, Lydia Belton <lbelton at zoology.up.ac.za> wrote:
> Dear R users,
> I am working with a binary data set of categorical variables with repeated
> measurements on 100 individuals over 24 trials with follwing variables

> success =0 or 1
> age = j, s, y or a
> ra = l, m, h
> sex= m or f

> With the data layed out as below
>
> success ? age ? ?ra ? ?sex ? ind trial
> 1 ? ? ? ? a ? ? ?l ? ? m ? ? 1 ? ? 1
> 1 ? ? ? ? s ? ? ?m ? ? f ? ? 2 ? ? 1
> 0 ? ? ? ? y ? ? ?h ? ? f ? ? 3 ? ? 1
> ....................................
> ....................................
> ....................................
> 0 ? ? ? ? a ? ? ?l ? ? m ? ? 1 ? ? 24
> 0 ? ? ? ? s ? ? ?m ? ? f ? ? 2 ? ? 24
> 1 ? ? ? ? y ? ? ?h ? ? f ? ? 3 ? ? 24
> When I try to run the following model lme4

> success~(age + ra + sex)^2 + (1|ind), binomial, verbose=T)
> I get the following error message

> 0: ? ? ? ? ? nan: 0.411061 -2.99573 -0.587787 ?14.0386 ?14.3205 -12.5703
> -11.9282 ?11.3544 ?12.2767 ?1.07485 ?1.33312 ?13.4198 ? ? ?nan ? ? ?nan
> -11.0981 -14.4590 -13.2578 ?1.18634 ? ? ?nan
> Error in asMethod(object) : matrix is not symmetric [1,2]
> In addition: Warning message:
> In mer_finalize(ans) : gr cannot be computed at initial par (65)

> >From reading previous posts I'm assuming this is caused by empty cells
> that are produced by the interactions in the data set.

> However these empty cells are inherent in the data. Whilst all
> combinations of sex and age are possible not all combinations or ra and
> age, or ra and sex, can exist.

> Specifically ra = l and sex = f
> ? ? ? ? ? ? ra = l and age = s
> ? ? ? ? ? ? ra = l and age = j cannot occur.

> If the interactions with ra are removed the model runs. However
> interactions between ra, age and sex are theoretically possible. From
> looking at the raw data and running a glm without individual as a random
> effect it seems like there might be a significant interaction between ra
> and age.

> Does anyone know if there is a way to test this without collapsing my data?

I don't know of an easy way of doing that but, as you are the second
person in as many weeks to pose such a question, it is obviously a
situation that we should accommodate.

The glm function uses a modified version of some classical linear
algebra software (Linpack, which predated Lapack) specifically to
handle rank deficient cases.  These arise most commonly from missing
cells, as above.  The way the calculations are done in lmer and glmer
we don't have the option of using that decomposition that detects rank
deficiency.  We may be able to modify the code to do a preliminary
decomposition using the modified Linpack routine and take corrective
action if it is found to be rank deficient.  I regret to say that I
won't be able to do so soon as I am swamped by my teaching obligations
at present.



From lbelton at zoology.up.ac.za  Wed Oct  6 15:13:48 2010
From: lbelton at zoology.up.ac.za (Lydia Belton)
Date: Wed, 6 Oct 2010 15:13:48 +0200
Subject: [R-sig-ME] Structural zeros in lme4
Message-ID: <6de55889eff2e38c8b08b9dcc55e5216.squirrel@zoology.up.ac.za>

Dear R users,

Thanks for the suggestions on how to work around this. One thing is, I
have got the impression from reading Agretsi that structural zeros need 
to be 'treated differently' to sampling zeros. I have an example of a glm
with a poisson distribution that subsets the data to remove the structural
zero combinations between between two fixed effects whilst leaving the
sampling zeros in place. However this isn't for interactions.

Unfortunately I'm not a statistician and I'm new to using R. Is this
something that I would also have to try to take into account or I have
tied myself in knots due to my extremely limited knowledge? Incidently I
don't actually have any sampling zeros in my data set if that makes a
difference.

Thank you all for your help it's very much appreciated

Lydia


------------------------------------------------------------------
This message and attachments are subject to a disclaimer. Please refer to http://www.it.up.ac.za/documentation/governance/disclaimer/ for full details. / Hierdie boodskap en aanhangsels is aan 'n vrywaringsklousule onderhewig. Volledige besonderhede is by http://www.it.up.ac.za/documentation/governance/disclaimer/ beskikbaar.



From hadley at rice.edu  Wed Oct  6 15:27:27 2010
From: hadley at rice.edu (Hadley Wickham)
Date: Wed, 6 Oct 2010 08:27:27 -0500
Subject: [R-sig-ME] Structural zeros in lme4
In-Reply-To: <AANLkTimkw+JE=_91wEpqmb5r0OzX4LtB2LMb8XHOCNiK@mail.gmail.com>
References: <c34f88b8c50d5bb149bd4438049bbbb0.squirrel@zoology.up.ac.za>
	<AANLkTimkw+JE=_91wEpqmb5r0OzX4LtB2LMb8XHOCNiK@mail.gmail.com>
Message-ID: <AANLkTi=E=PKcTL5eU2oOfU43nYiw9g=58rNAZQ6JGXe9@mail.gmail.com>

> I don't know of an easy way of doing that but, as you are the second
> person in as many weeks to pose such a question, it is obviously a
> situation that we should accommodate.

Well, it's not easy, but you can do:

  ra_age_sex <- interaction(ra, age, sex, drop = T)

and then model with

  success ~ ra_age_sex + (1|ind)

The hard part is creating the contrasts that take you back to the
questions you're interested in.

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/



From bates at stat.wisc.edu  Wed Oct  6 17:07:36 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 6 Oct 2010 10:07:36 -0500
Subject: [R-sig-ME] Structural zeros in lme4
In-Reply-To: <AANLkTi=E=PKcTL5eU2oOfU43nYiw9g=58rNAZQ6JGXe9@mail.gmail.com>
References: <c34f88b8c50d5bb149bd4438049bbbb0.squirrel@zoology.up.ac.za>
	<AANLkTimkw+JE=_91wEpqmb5r0OzX4LtB2LMb8XHOCNiK@mail.gmail.com>
	<AANLkTi=E=PKcTL5eU2oOfU43nYiw9g=58rNAZQ6JGXe9@mail.gmail.com>
Message-ID: <AANLkTi=po5CsxFME_sCnpyMW844EnuZaHWDNtfM+mR6m@mail.gmail.com>

On Wed, Oct 6, 2010 at 8:27 AM, Hadley Wickham <hadley at rice.edu> wrote:
>> I don't know of an easy way of doing that but, as you are the second
>> person in as many weeks to pose such a question, it is obviously a
>> situation that we should accommodate.
>
> Well, it's not easy, but you can do:
>
> ?ra_age_sex <- interaction(ra, age, sex, drop = T)
>
> and then model with
>
> ?success ~ ra_age_sex + (1|ind)
>
> The hard part is creating the contrasts that take you back to the
> questions you're interested in.

As you say, that's the hard part.

The fix I have in mind is to do a preliminary QR decomposition of the
model matrix for the fixed effects

qr(model.matrix(~ ra + age + sex))

and examine the rank.  If this matrix is rank-deficient there will be
a non-trivial permutation of the coefficients in the qr structure and
you simply extract the first r columns from the model matrix after
permutation.  The remaining p - r columns are the coefficients whose
estimates are NA in the coefficients table.



From elizabeth.crone at cfc.umt.edu  Wed Oct  6 20:59:13 2010
From: elizabeth.crone at cfc.umt.edu (Elizabeth Crone)
Date: Wed, 6 Oct 2010 12:59:13 -0600
Subject: [R-sig-ME] citation for significance testing in mixed models
In-Reply-To: <mailman.5.1286359202.6898.r-sig-mixed-models@r-project.org>
References: <mailman.5.1286359202.6898.r-sig-mixed-models@r-project.org>
Message-ID: <FDE3381E3E2B9945BDA9105DBBE2D608030A205E7E13@pangaea.cfc.umt.edu>

Hello,

I cannot find a good (published) citation for the statement that significance tests from mixed models (e.g., the t-statistics produced by lmer) are approximate and should be interpreted as such.  It would make me particularly happy if I could attribute the statement to D. Bates.

I often need to explain the idea to colleagues (ecologists) and reviewers of articles in ecological journals.  It would be nice to be able to argue from authority, as well as from first principles.

Humble apologies if I am missing something obvious....

Thanks!
Elizabeth



From desja004 at umn.edu  Wed Oct  6 23:25:40 2010
From: desja004 at umn.edu (Christopher Desjardins)
Date: Wed, 6 Oct 2010 16:25:40 -0500
Subject: [R-sig-ME] Chi-square test on random effects
Message-ID: <AANLkTinxKT1BBAGNz7HstP6NfdRmNgUdz7kvCq_62bxq@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101006/069a8fd7/attachment.pl>

From ned.dochtermann at gmail.com  Wed Oct  6 23:46:00 2010
From: ned.dochtermann at gmail.com (Ned Dochtermann)
Date: Wed, 6 Oct 2010 14:46:00 -0700
Subject: [R-sig-ME] Estimating repeatability from ZIP models (MCMCglmm)
In-Reply-To: <mailman.5.1284285603.7666.r-sig-mixed-models@r-project.org>
References: <mailman.5.1284285603.7666.r-sig-mixed-models@r-project.org>
Message-ID: <4cacee18.0a9c8e0a.1801.4f58@mx.google.com>

Hello,

I am working with some data and attempting to calculate repeatabilities for
individuals using ZIP models in MCMCglmm and was hoping for a bit of
clarification. 

I had previously calculated repeatabilities for Poisson models based on the
additive equations presented in Nakagawa and Schielzeth (2010, Biol. Rev)
using subject intercepts, unit residuals and the fixed effect intercept.
However, I have reanalyzed the data using a ZIP model due to substantial
zero-inflation.

I understand that the fixed coefficients are interpreted in the same manner
as they would be with a regular poisson model (with the exception of the
second latent) but I haven't seen anything discussing the effects of a ZIP
model on the random structure and thus repeatability.

Is it appropriate to calculate repeatability using the same variance
components and the same formula for a ZIP model as for a Poisson model?


Thanks for any advice,
Ned

--
Ned Dochtermann
Department of Biology
University of Nevada, Reno

ned.dochtermann at gmail.com
http://wolfweb.unr.edu/homepage/mpeacock/Dochter/
--



From ned.dochtermann at gmail.com  Thu Oct  7 00:05:49 2010
From: ned.dochtermann at gmail.com (Ned Dochtermann)
Date: Wed, 6 Oct 2010 15:05:49 -0700
Subject: [R-sig-ME] Chi-square test on random effects
Message-ID: <4cacf2bd.0948650a.2807.190c@mx.google.com>

Hi Chris,

You're not going to be able to do that test using lmer. To conduct the test
you want you'll need to know the likelihood estimates for two models, one
with the random factor and another without it. You can't run a model without
the random factor in lme4 and you can't use the likelihood from lm because
they aren't "commensurate" between lme4 and lm (this issue is discussed at:
http://glmm.wikidot.com/random-effects-testing). I've run the same sorts of
tests for lmer and lm, as I'm sure many other people have and they aren't
compatible.

You can, however, get what you want using nlme:
m.rand<-lme(Y~1,random=~1|Group,data=data)
m.null<-gls(Y~1,data=data)
(I don't use nlme much so you may want to double check the code syntax)

Then you just run the likelihood ratio test from there, I think with nlme
LRT is built in as anova(m.rand,m.null).

This issue has been discussed a lot so you may find more detailed info by
searching the archives. 


Good luck,
Ned

--
Ned Dochtermann
Department of Biology
University of Nevada, Reno

ned.dochtermann at gmail.com
http://wolfweb.unr.edu/homepage/mpeacock/Dochter/
--

Hi,
I originally ran a model in HLM 6 that I am now in lme4. In lme4 the model
would look like the following:

lmer(Y ~ 1 + (1 | Group), data= data)

So I only have a random intercept for Group.

I noticed that HLM 6 gives a chi-square test statistic associated with this
random variable. Does anyone know how I can calculate this chi-square
statistic in R or what formula the HLM authors are using?

Thanks!
Chris

	[[alternative HTML version deleted]]



From desja004 at umn.edu  Thu Oct  7 01:01:35 2010
From: desja004 at umn.edu (Christopher Desjardins)
Date: Wed, 6 Oct 2010 18:01:35 -0500
Subject: [R-sig-ME] Chi-square test on random effects
In-Reply-To: <4cacf2bd.0948650a.2807.190c@mx.google.com>
References: <4cacf2bd.0948650a.2807.190c@mx.google.com>
Message-ID: <AANLkTi=Sj4BsFrOLy63d159sBzBguoEcOi5Mi4V7Wa6i@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101006/2efdfa1b/attachment.pl>

From henrik.parn at bio.ntnu.no  Thu Oct  7 10:06:29 2010
From: henrik.parn at bio.ntnu.no (=?ISO-8859-1?Q?Henrik_P=E4rn?=)
Date: Thu, 07 Oct 2010 10:06:29 +0200
Subject: [R-sig-ME] citation for significance testing in mixed models
Message-ID: <4CAD7F85.7070204@bio.ntnu.no>



Dear Elizabeth,

I believe this article:

Baayen, R., D. Davidson, and D. Bates. 2008. Mixed-effects modeling
with crossed random effects for subjects and items. Journal of Memory
and Language 59:390-412.

...was been mentioned in an answer to a similar question on the mixed-list.


Best regards,


Henrik




Hello,

I cannot find a good (published) citation for the statement that significance tests from mixed models (e.g., the t-statistics produced by lmer) are approximate and should be interpreted as such.  It would make me particularly happy if I could attribute the statement to D. Bates.

I often need to explain the idea to colleagues (ecologists) and reviewers of articles in ecological journals.  It would be nice to be able to argue from authority, as well as from first principles.

Humble apologies if I am missing something obvious....

Thanks!

Elizabeth

-- 
Henrik P?rn
Centre for Conservation Biology
Department of Biology
Norwegian University of Science and Technology
No-7491 Trondheim
NORWAY

Office: +47 735 96084
Mobile: +47 909 89 255
Fax: +47 735 96100



From kushler at oakland.edu  Thu Oct  7 18:25:50 2010
From: kushler at oakland.edu (Robert Kushler)
Date: Thu, 07 Oct 2010 12:25:50 -0400
Subject: [R-sig-ME] Chi-square test on random effects
In-Reply-To: <AANLkTi=Sj4BsFrOLy63d159sBzBguoEcOi5Mi4V7Wa6i@mail.gmail.com>
References: <4cacf2bd.0948650a.2807.190c@mx.google.com>
	<AANLkTi=Sj4BsFrOLy63d159sBzBguoEcOi5Mi4V7Wa6i@mail.gmail.com>
Message-ID: <4CADF48E.9080304@oakland.edu>


I believe the RLRsim package provides a better solution.

Regards,   Rob Kushler


On 10/6/2010 7:01 PM, Christopher Desjardins wrote:
> Thanks.
> Chris
>
> On Wed, Oct 6, 2010 at 5:05 PM, Ned Dochtermann
> <ned.dochtermann at gmail.com>wrote:
>
>> Hi Chris,
>>
>> You're not going to be able to do that test using lmer. To conduct the test
>> you want you'll need to know the likelihood estimates for two models, one
>> with the random factor and another without it. You can't run a model
>> without
>> the random factor in lme4 and you can't use the likelihood from lm because
>> they aren't "commensurate" between lme4 and lm (this issue is discussed at:
>> http://glmm.wikidot.com/random-effects-testing). I've run the same sorts
>> of
>> tests for lmer and lm, as I'm sure many other people have and they aren't
>> compatible.
>>
>> You can, however, get what you want using nlme:
>> m.rand<-lme(Y~1,random=~1|Group,data=data)
>> m.null<-gls(Y~1,data=data)
>> (I don't use nlme much so you may want to double check the code syntax)
>>
>> Then you just run the likelihood ratio test from there, I think with nlme
>> LRT is built in as anova(m.rand,m.null).
>>
>> This issue has been discussed a lot so you may find more detailed info by
>> searching the archives.
>>
>>
>> Good luck,
>> Ned
>>
>> --
>> Ned Dochtermann
>> Department of Biology
>> University of Nevada, Reno
>>
>> ned.dochtermann at gmail.com
>> http://wolfweb.unr.edu/homepage/mpeacock/Dochter/
>> --
>>
>> Hi,
>> I originally ran a model in HLM 6 that I am now in lme4. In lme4 the model
>> would look like the following:
>>
>> lmer(Y ~ 1 + (1 | Group), data= data)
>>
>> So I only have a random intercept for Group.
>>
>> I noticed that HLM 6 gives a chi-square test statistic associated with this
>> random variable. Does anyone know how I can calculate this chi-square
>> statistic in R or what formula the HLM authors are using?
>>
>> Thanks!
>> Chris
>>
>>          [[alternative HTML version deleted]]
>>
>>
>>
>
>



From ned.dochtermann at gmail.com  Fri Oct  8 18:33:23 2010
From: ned.dochtermann at gmail.com (Ned Dochtermann)
Date: Fri, 8 Oct 2010 09:33:23 -0700
Subject: [R-sig-ME] Chi-square test on random effects
In-Reply-To: <mailman.5.1286532002.32335.r-sig-mixed-models@r-project.org>
References: <mailman.5.1286532002.32335.r-sig-mixed-models@r-project.org>
Message-ID: <4caf47d3.c624e70a.7b2b.7d98@mx.google.com>

Hi Rob,
Thanks, I didn't know about that package and a simulation approach certainly
seems preferable. 

However, and I easily could be wrong about this, it is worth noting that the
example used for exactLRT looks problematic to me. The two models are fit
using lme and lm which do not necessarily produce commensurate likelihoods
(lmer and lm do not, and I don't think lme and lmer do). Also, and this is
the part I'm a bit less sure about, but when you're comparing models like
those in the example I think you would have to use ML rather than REML. That
seems like something users should be informed of.

I'm really just a dabbler when it comes to this stuff so further
clarification from yourself and others would be useful.

Thanks,
Ned

--
Ned Dochtermann
Department of Biology
University of Nevada, Reno

ned.dochtermann at gmail.com
http://wolfweb.unr.edu/homepage/mpeacock/Dochter/
--



----------------------------------------------------------------------

Message: 1
Date: Thu, 07 Oct 2010 12:25:50 -0400
From: Robert Kushler <kushler at oakland.edu>
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Chi-square test on random effects
Message-ID: <4CADF48E.9080304 at oakland.edu>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed


I believe the RLRsim package provides a better solution.

Regards,   Rob Kushler


On 10/6/2010 7:01 PM, Christopher Desjardins wrote:
> Thanks.
> Chris
>
> On Wed, Oct 6, 2010 at 5:05 PM, Ned Dochtermann
> <ned.dochtermann at gmail.com>wrote:
>
>> Hi Chris,
>>
>> You're not going to be able to do that test using lmer. To conduct the
test
>> you want you'll need to know the likelihood estimates for two models, one
>> with the random factor and another without it. You can't run a model
>> without
>> the random factor in lme4 and you can't use the likelihood from lm
because
>> they aren't "commensurate" between lme4 and lm (this issue is discussed
at:
>> http://glmm.wikidot.com/random-effects-testing). I've run the same sorts
>> of
>> tests for lmer and lm, as I'm sure many other people have and they aren't
>> compatible.
>>
>> You can, however, get what you want using nlme:
>> m.rand<-lme(Y~1,random=~1|Group,data=data)
>> m.null<-gls(Y~1,data=data)
>> (I don't use nlme much so you may want to double check the code syntax)
>>
>> Then you just run the likelihood ratio test from there, I think with nlme
>> LRT is built in as anova(m.rand,m.null).
>>
>> This issue has been discussed a lot so you may find more detailed info by
>> searching the archives.
>>
>>
>> Good luck,
>> Ned
>>
>> --
>> Ned Dochtermann
>> Department of Biology
>> University of Nevada, Reno
>>
>> ned.dochtermann at gmail.com
>> http://wolfweb.unr.edu/homepage/mpeacock/Dochter/
>> --
>>
>> Hi,
>> I originally ran a model in HLM 6 that I am now in lme4. In lme4 the
model
>> would look like the following:
>>
>> lmer(Y ~ 1 + (1 | Group), data= data)
>>
>> So I only have a random intercept for Group.
>>
>> I noticed that HLM 6 gives a chi-square test statistic associated with
this
>> random variable. Does anyone know how I can calculate this chi-square
>> statistic in R or what formula the HLM authors are using?
>>
>> Thanks!
>> Chris
>>
>>          [[alternative HTML version deleted]]
>>
>>
>>
>
>



------------------------------

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


End of R-sig-mixed-models Digest, Vol 46, Issue 10



From lee.daejin at gmail.com  Fri Oct  8 20:27:35 2010
From: lee.daejin at gmail.com (Dae-Jin Lee)
Date: Fri, 8 Oct 2010 20:27:35 +0200
Subject: [R-sig-ME] lme and pdDiag definition
Message-ID: <AANLkTimfKtEzfmH_cYvhLvtxZ+_Wzu0jPjd_brF_sks+@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101008/b3a6e3ba/attachment.pl>

From arrayprofile at yahoo.com  Fri Oct  8 23:47:31 2010
From: arrayprofile at yahoo.com (array chip)
Date: Fri, 8 Oct 2010 14:47:31 -0700 (PDT)
Subject: [R-sig-ME] lmer give error message
Message-ID: <293395.34226.qm@web56304.mail.re3.yahoo.com>

Hi, I have an ophthalmology dataset, that has as response variable "y", patient 
ID (pid), visit (0,1,2) and eye examined ("L' and "R").

Basically, each patient has 3 visit, during each visit, both eyes will be 
assessed and produce response measurements. The first question is should I treat 
eye.examined and visit as crossed or nested? I think it should be treated as 
crossed because each eye will be assessed in each visit. On the other hand, the 
2 measurements from the 2 eyes were from a given visit, so it looks like it can 
be treated as nested as well (eye %in% visit). 


The second question is, no matter which way I use, lmer() gives me error 
message, while lme() from nlme package can handle nested design easily. Also, is 
there a way to specify corssed design in lme() as well?


> dat <- read.table ("dat.txt", sep='\t', row.names=1, header=T)
> library(nlme)

    ### nested using lme
> lme(y~1, random=~1|pid/visit/eye,dat)
Random effects:
 Formula: ~1 | pid
        (Intercept)
StdDev:    2.881611

 Formula: ~1 | visit %in% pid
        (Intercept)
StdDev:   0.8154632

 Formula: ~1 | eye %in% visit %in% pid
        (Intercept)  Residual
StdDev:    1.065172 0.5321993

    ### nested using lmer
> lmer(y~1+(1|pid/visit/eye),dat)
Error: length(f1) == length(f2) is not TRUE
In addition: Warning messages:
1: In visit:pid :
  numerical expression has 718 elements: only the first used
2: In visit:pid :
  numerical expression has 718 elements: only the first used

    ### crossed 
> lmer(y~1+(1|pid/visit)+(1|pid/eye),dat)
Error: length(f1) == length(f2) is not TRUE
In addition: Warning messages:
1: In visit:pid :
  numerical expression has 718 elements: only the first used
2: In visit:pid :
  numerical expression has 718 elements: only the first used
3: In eye:pid : numerical expression has 718 elements: only the first used
4: In eye:pid : numerical expression has 718 elements: only the first used


Can anyone share their thoughts.

Thanks

John


      
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: dat.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101008/62e3212e/attachment.txt>

From cewright at uci.edu  Sat Oct  9 00:02:17 2010
From: cewright at uci.edu (Charles E. (Ted) Wright)
Date: Fri, 8 Oct 2010 15:02:17 -0700 (Pacific Daylight Time)
Subject: [R-sig-ME] lmer give error message
In-Reply-To: <293395.34226.qm@web56304.mail.re3.yahoo.com>
References: <293395.34226.qm@web56304.mail.re3.yahoo.com>
Message-ID: <alpine.WNT.2.00.1010081500170.3892@pcwright>

John,

This is definitely a design in which visit and eye are crossed. To think of 
eye as nested within visit you would have to believe that it was a different 
pair of eyes that was being examined on each patient visit.

Ted Wright

On Fri, 8 Oct 2010, array chip wrote:

> Hi, I have an ophthalmology dataset, that has as response variable "y", patient
> ID (pid), visit (0,1,2) and eye examined ("L' and "R").
>
> Basically, each patient has 3 visit, during each visit, both eyes will be
> assessed and produce response measurements. The first question is should I treat
> eye.examined and visit as crossed or nested? I think it should be treated as
> crossed because each eye will be assessed in each visit. On the other hand, the
> 2 measurements from the 2 eyes were from a given visit, so it looks like it can
> be treated as nested as well (eye %in% visit).
>
>
> The second question is, no matter which way I use, lmer() gives me error
> message, while lme() from nlme package can handle nested design easily. Also, is
> there a way to specify corssed design in lme() as well?
>
>
>> dat <- read.table ("dat.txt", sep='\t', row.names=1, header=T)
>> library(nlme)
>
>    ### nested using lme
>> lme(y~1, random=~1|pid/visit/eye,dat)
> Random effects:
> Formula: ~1 | pid
>        (Intercept)
> StdDev:    2.881611
>
> Formula: ~1 | visit %in% pid
>        (Intercept)
> StdDev:   0.8154632
>
> Formula: ~1 | eye %in% visit %in% pid
>        (Intercept)  Residual
> StdDev:    1.065172 0.5321993
>
>    ### nested using lmer
>> lmer(y~1+(1|pid/visit/eye),dat)
> Error: length(f1) == length(f2) is not TRUE
> In addition: Warning messages:
> 1: In visit:pid :
>  numerical expression has 718 elements: only the first used
> 2: In visit:pid :
>  numerical expression has 718 elements: only the first used
>
>    ### crossed
>> lmer(y~1+(1|pid/visit)+(1|pid/eye),dat)
> Error: length(f1) == length(f2) is not TRUE
> In addition: Warning messages:
> 1: In visit:pid :
>  numerical expression has 718 elements: only the first used
> 2: In visit:pid :
>  numerical expression has 718 elements: only the first used
> 3: In eye:pid : numerical expression has 718 elements: only the first used
> 4: In eye:pid : numerical expression has 718 elements: only the first used
>
>
> Can anyone share their thoughts.
>
> Thanks
>
> John
>
>
>



From smckinney at bccrc.ca  Sat Oct  9 00:07:54 2010
From: smckinney at bccrc.ca (Steven McKinney)
Date: Fri, 8 Oct 2010 15:07:54 -0700
Subject: [R-sig-ME] lmer give error message
In-Reply-To: <14496_1286574473_1286574473_293395.34226.qm@web56304.mail.re3.yahoo.com>
References: <14496_1286574473_1286574473_293395.34226.qm@web56304.mail.re3.yahoo.com>
Message-ID: <DCE81E14EB74504B971DAD4D2DB0356B0864727D46@crcmail4.BCCRC.CA>

Hi John,

> dat <- read.table ("dat.txt", sep='\t', row.names=1, header=T)
> sapply(dat, class)
      pid     visit       eye         y 
"integer" "integer"  "factor" "integer" 

Part of the issue is that the modeling machinery is set up
to work with factor variables.  lmer does not always convert
numerics to integers.  Set up factor versions of your
independent variable groups.


> dat$fpid <- as.factor(dat$pid)
> dat$fvisit <- as.factor(dat$visit)


>     ### crossed
> lmer(y~1+(1|fpid/fvisit)+(1|fpid/eye),dat)
Linear mixed model fit by REML 
Formula: y ~ 1 + (1 | fpid/fvisit) + (1 | fpid/eye) 
   Data: dat 
  AIC  BIC logLik deviance REMLdev
 2848 2875  -1418     2835    2836
Random effects:
 Groups      Name        Variance Std.Dev.
 fvisit:fpid (Intercept) 0.92510  0.96182 
 eye:fpid    (Intercept) 0.51945  0.72073 
 fpid        (Intercept) 4.02193  2.00547 
 fpid        (Intercept) 4.02191  2.00547 
 Residual                0.89761  0.94742 
Number of obs: 718, groups: fvisit:fpid, 359; eye:fpid, 240; fpid, 120

Fixed effects:
            Estimate Std. Error t value
(Intercept)   4.0648     0.2702   15.04
> 

>     ### nested using lmer
> lmer(y~1+(1|fpid/fvisit/eye),dat)
Error in function (fr, FL, start, REML, verbose)  : 
  Number of levels of a grouping factor for the random effects
must be less than the number of observations

Issues of model specification, number of observations
per group, and groups missing data remain
to be worked out.


> with(dat, table(fpid, fvisit, eye))
, , eye = L

     fvisit
fpid  0 1 2
  1   1 1 1
  2   1 1 1
  3   1 1 1
...
  37  1 1 1
  38  1 0 1
  39  1 1 1
...
  119 1 1 1
  120 1 1 1

, , eye = R

     fvisit
fpid  0 1 2
  1   1 1 1
  2   1 1 1
  3   1 1 1
  4   1 1 1
  5   1 1 1
...
  117 1 1 1
  118 1 1 1
  119 1 1 1
  120 1 1 1



Steven McKinney


> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On
> Behalf Of array chip
> Sent: October-08-10 2:48 PM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] lmer give error message
> 
> Hi, I have an ophthalmology dataset, that has as response variable "y", patient
> ID (pid), visit (0,1,2) and eye examined ("L' and "R").
> 
> Basically, each patient has 3 visit, during each visit, both eyes will be
> assessed and produce response measurements. The first question is should I treat
> eye.examined and visit as crossed or nested? I think it should be treated as
> crossed because each eye will be assessed in each visit. On the other hand, the
> 2 measurements from the 2 eyes were from a given visit, so it looks like it can
> be treated as nested as well (eye %in% visit).
> 
> 
> The second question is, no matter which way I use, lmer() gives me error
> message, while lme() from nlme package can handle nested design easily. Also, is
> there a way to specify corssed design in lme() as well?
> 
> 
> > dat <- read.table ("dat.txt", sep='\t', row.names=1, header=T)
> > library(nlme)
> 
>     ### nested using lme
> > lme(y~1, random=~1|pid/visit/eye,dat)
> Random effects:
>  Formula: ~1 | pid
>         (Intercept)
> StdDev:    2.881611
> 
>  Formula: ~1 | visit %in% pid
>         (Intercept)
> StdDev:   0.8154632
> 
>  Formula: ~1 | eye %in% visit %in% pid
>         (Intercept)  Residual
> StdDev:    1.065172 0.5321993
> 
>     ### nested using lmer
> > lmer(y~1+(1|pid/visit/eye),dat)
> Error: length(f1) == length(f2) is not TRUE
> In addition: Warning messages:
> 1: In visit:pid :
>   numerical expression has 718 elements: only the first used
> 2: In visit:pid :
>   numerical expression has 718 elements: only the first used
> 
>     ### crossed
> > lmer(y~1+(1|pid/visit)+(1|pid/eye),dat)
> Error: length(f1) == length(f2) is not TRUE
> In addition: Warning messages:
> 1: In visit:pid :
>   numerical expression has 718 elements: only the first used
> 2: In visit:pid :
>   numerical expression has 718 elements: only the first used
> 3: In eye:pid : numerical expression has 718 elements: only the first used
> 4: In eye:pid : numerical expression has 718 elements: only the first used
> 
> 
> Can anyone share their thoughts.
> 
> Thanks
> 
> John
> 
> 
> 



From arrayprofile at yahoo.com  Sat Oct  9 00:38:50 2010
From: arrayprofile at yahoo.com (array chip)
Date: Fri, 8 Oct 2010 15:38:50 -0700 (PDT)
Subject: [R-sig-ME] lmer give error message
In-Reply-To: <DCE81E14EB74504B971DAD4D2DB0356B0864727D46@crcmail4.BCCRC.CA>
References: <14496_1286574473_1286574473_293395.34226.qm@web56304.mail.re3.yahoo.com>
	<DCE81E14EB74504B971DAD4D2DB0356B0864727D46@crcmail4.BCCRC.CA>
Message-ID: <346552.43113.qm@web56308.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101008/cb9a2fdf/attachment.pl>

From arrayprofile at yahoo.com  Sat Oct  9 00:32:22 2010
From: arrayprofile at yahoo.com (array chip)
Date: Fri, 8 Oct 2010 15:32:22 -0700 (PDT)
Subject: [R-sig-ME] lmer give error message
In-Reply-To: <alpine.WNT.2.00.1010081500170.3892@pcwright>
References: <293395.34226.qm@web56304.mail.re3.yahoo.com>
	<alpine.WNT.2.00.1010081500170.3892@pcwright>
Message-ID: <365320.77687.qm@web56303.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101008/219e2927/attachment.pl>

From lij at iastate.edu  Sat Oct  9 16:47:40 2010
From: lij at iastate.edu (Jie Li)
Date: Sat, 9 Oct 2010 07:47:40 -0700 (PDT)
Subject: [R-sig-ME] install the "repeated" package
Message-ID: <345390.91705.qm@web51306.mail.re2.yahoo.com>

Dear colleague,

I tried to install the "repeated" package (authored by Jim Lindsey?) so I can 
use glmm() for my analysis, but I failed because the package is not on CRAN or 
can be found elsewhere. I want to incorporate a random element in my generalized 
linear Poisson model. Could you point me towards the way forward? Thank you very 
much indeed.

Jie

Jie Li
Department of Statistics
Iowa State University
1229 Snedecor Hall
(515) 294-5790



      

From baron at psych.upenn.edu  Sat Oct  9 18:45:38 2010
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Sat, 9 Oct 2010 12:45:38 -0400
Subject: [R-sig-ME] install the "repeated" package
In-Reply-To: <345390.91705.qm@web51306.mail.re2.yahoo.com>
References: <345390.91705.qm@web51306.mail.re2.yahoo.com>
Message-ID: <20101009164538.GA20427@psych.upenn.edu>

Jim Lindsey's packages are here and were never on CRAN:

http://www.commanster.eu/rcode.html

But I am surprise that you need it for glmm().

Jon

On 10/09/10 07:47, Jie Li wrote:
> Dear colleague,
> 
> I tried to install the "repeated" package (authored by Jim Lindsey?) so I can 
> use glmm() for my analysis, but I failed because the package is not on CRAN or 
> can be found elsewhere. I want to incorporate a random element in my generalized 
> linear Poisson model. Could you point me towards the way forward? Thank you very 
> much indeed.
> 
> Jie
> 
> Jie Li
> Department of Statistics
> Iowa State University
> 1229 Snedecor Hall
> (515) 294-5790
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
Editor: Judgment and Decision Making (http://journal.sjdm.org)



From djmuser at gmail.com  Sat Oct  9 22:47:02 2010
From: djmuser at gmail.com (Dennis Murphy)
Date: Sat, 9 Oct 2010 13:47:02 -0700
Subject: [R-sig-ME] lmer give error message
In-Reply-To: <293395.34226.qm@web56304.mail.re3.yahoo.com>
References: <293395.34226.qm@web56304.mail.re3.yahoo.com>
Message-ID: <AANLkTimMTqtpPdvbH+hw5N9w4EidR5t9nLhn07E9332j@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101009/f2e51fb9/attachment.pl>

From renaud.lancelot at cirad.fr  Sun Oct 10 09:44:17 2010
From: renaud.lancelot at cirad.fr (lancelot)
Date: Sun, 10 Oct 2010 09:44:17 +0200
Subject: [R-sig-ME] install the "repeated" package
In-Reply-To: <345390.91705.qm@web51306.mail.re2.yahoo.com>
References: <345390.91705.qm@web51306.mail.re2.yahoo.com>
Message-ID: <4CB16ED1.70505@cirad.fr>

See http://www.commanster.eu/rcode.html

There are many other options, including the lme4 package (on CRAN).

Cheers,

Renaud

Le 09/10/2010 16:47, Jie Li a ?crit :
> Dear colleague,
>
> I tried to install the "repeated" package (authored by Jim Lindsey?) so I can
> use glmm() for my analysis, but I failed because the package is not on CRAN or
> can be found elsewhere. I want to incorporate a random element in my generalized
> linear Poisson model. Could you point me towards the way forward? Thank you very
> much indeed.
>
> Jie
>
> Jie Li
> Department of Statistics
> Iowa State University
> 1229 Snedecor Hall
> (515) 294-5790
>
>
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

-- 
Renaud Lancelot
EDEN Project, coordinator
http://www.eden-fp6project.net/

UMR CIRAD-INRA "Contr?le des maladies animales exotiques et ?mergentes"
Joint research unit "Control of emerging and exotic animal diseases"

CIRAD, Campus International de Baillarguet TA A-DIR / B
F34398 Montpellier
http://umr-cmaee.cirad.fr/

Tel.  +33 4 67 59 37 17  -  Fax  +33 4 67 59 37 95
Secr. +33 4 67 59 37 37  - Cell. +33 6 77 52 08 69



From bbolker at gmail.com  Sun Oct 10 14:38:40 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 10 Oct 2010 08:38:40 -0400
Subject: [R-sig-ME] install the "repeated" package
In-Reply-To: <345390.91705.qm@web51306.mail.re2.yahoo.com>
References: <345390.91705.qm@web51306.mail.re2.yahoo.com>
Message-ID: <4CB1B3D0.302@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101010/cf4c7768/attachment.pl>

From sbennett at ceab.csic.es  Mon Oct 11 17:32:49 2010
From: sbennett at ceab.csic.es (Scott Bennett)
Date: Mon, 11 Oct 2010 17:32:49 +0200
Subject: [R-sig-ME] why does my inter-annual SD = 0?
Message-ID: <20101011173249.137427bnnkkkhcm9@webmail.csic.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101011/3d36c917/attachment.pl>

From bates at stat.wisc.edu  Mon Oct 11 18:26:00 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 11 Oct 2010 11:26:00 -0500
Subject: [R-sig-ME] why does my inter-annual SD = 0?
In-Reply-To: <20101011173249.137427bnnkkkhcm9@webmail.csic.es>
References: <20101011173249.137427bnnkkkhcm9@webmail.csic.es>
Message-ID: <AANLkTim8A8uF59kTEKiOvLfcqicC2NBnuUucjEdf-+_3@mail.gmail.com>

Can you tell us how many levels there are of region, site, zone and
year?  If the data are collected in only a few years it is difficult
to estimate a variance component and the ML and REML  criteria drive
the estimates to zero.  You may be overmodeling the data but it is
difficult to say without access to the data or at least a feeling for
how many observations and in what configuration they are.

On Mon, Oct 11, 2010 at 10:32 AM, Scott Bennett <sbennett at ceab.csic.es> wrote:
>
>
> Hi,
>
> I am applying a mixed model to calculate the variance components of different factors in our seagrass data. The model i was using looks something like:
>
> POMI14_vc <- lmer(POMI_14 ~ Depth + surveyor + (1|region/site/zone) + (1|year),
> ?data = P_oceanica)
>
> When I apply this model, however, year comes out with SD = 0. Year, in this data set signifies inter-annual variation (in the health status of seagrass meadows), of which there is a considerable amount. That makes me believe that there is is a feature of the model which is 'absorbing' the inter-annual variation.
>
> Can you suggest why this may be occuring? What modifiations could i use to fix this?
>
> kind regards
>
> Scott Bennett
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bbolker at gmail.com  Mon Oct 11 18:26:21 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 11 Oct 2010 12:26:21 -0400
Subject: [R-sig-ME] why does my inter-annual SD = 0?
In-Reply-To: <20101011173249.137427bnnkkkhcm9@webmail.csic.es>
References: <20101011173249.137427bnnkkkhcm9@webmail.csic.es>
Message-ID: <4CB33AAD.5080409@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101011/454b74d8/attachment.pl>

From sbennett at ceab.csic.es  Mon Oct 11 19:38:33 2010
From: sbennett at ceab.csic.es (Scott Bennett)
Date: Mon, 11 Oct 2010 19:38:33 +0200
Subject: [R-sig-ME] why does my inter-annual SD = 0?
In-Reply-To: <4CB33AAD.5080409@gmail.com>
References: <20101011173249.137427bnnkkkhcm9@webmail.csic.es>
	<4CB33AAD.5080409@gmail.com>
Message-ID: <20101011193833.883163ya0oh9u6xl@webmail.csic.es>



Hi all, thanks for the quick replies! I have attached the data, if it helps for you to look at it directly. The end product that I would like to achieve is an estimate of the variance associated with each factor (depth, surveyor, year, water body, site and zone), to then model the probability of misclassifying the health status of a water body, based on the variability associated with each of the respective factors (An uncertainty analysis of our seagrass index). The index we are using POMI_14 (Posidonia oceanica multivariate index, Romero et al. 2008) is comprised of 14 metrics relates to the health and status of /P. oceanica./ There are only 4 years of data. The 2005, 2006 and 2008 data is from annual sampling of  30 seagrass meadows (sites) sampled at a single depth along the Catalan coast, Spain. The 2002 data is of a subset of those sites, but includes replication between 2 discrete depths (5m and 15m) and among three discrete zones nested within each site. The sites are nested within 'water-bodies'. A water body represents an area of coastal water (15 - 50 km in length) which has been classified based on its exposure to water quality pressures. The surveyor factor, is only from the 2008 series, where we calculated POMI based on two separate surveyors. Needless to say the design is unbalanced.  

In short the data looks like this:  

'data.frame':   231 obs. of  8 variables: 
 $ year    : Factor w/ 4 levels "2002","2005",..: 4 4 4 4 4 4 4 4 4 4 ...
 $ WB      : Factor w/ 17 levels "1","2","3","4",..: 1 2 3 3 3 4 5 6 7 8 ...
 $ Site    : Factor w/ 30 levels "Balis    ","Cadaques ",..: 22 19 27 7 9 2 16 21 20 15 ...
 $ Zone    : Factor w/ 3 levels "a","b","c":..: 1 1 1 1 1 1 1 1 1 1 ...
 $ Depth   : Factor w/ 2 levels "p","s": 1 1 1 1 1 1 1 1 1 1 ...
 $ surveyor: Factor w/ 2 levels "1","2": 1 1 1 1 1 1 1 1 1 1 ...
 $ POMI_14 : num  0.781 0.633 0.717 0.936 0.86 ...
 $ POMI_9  : num  0.803 0.67 0.745 0.942 0.873 ... 

I hope this makes things clearer. Any help will be greatly appreciated.  

Kind regards  

Scott Bennett  

> On 10-10-11 11:32 AM, Scott Bennett wrote:
>>
>>
>> Hi,
>>
>> I am applying a mixed model to calculate the variance components of
>> different factors in our seagrass data. The model i was using looks
>> something like:
>>
>> POMI14_vc <- lmer(POMI_14 ~ Depth + surveyor + (1|region/site/zone)
>> + (1|year), data = P_oceanica)
>>
>> When I apply this model, however, year comes out with SD = 0. Year,
>> in this data set signifies inter-annual variation (in the health
>> status of seagrass meadows), of which there is a considerable
>> amount. That makes me believe that there is is a feature of the
>> model which is 'absorbing' the inter-annual variation.
>>
>> Can you suggest why this may be occuring? What modifiations could i
>> use to fix this?
>>
>> kind regards
>>
>> Scott Bennett
>
>    Hard to say for sure without seeing the data.
>    How many years do you have?  Are Depth and surveyor well
> distributed across years?
>    What happens if you treat year as a fixed effect and calculate the
> among-year variance on
> the basis of the fixed effect estimates?
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

 
-------------- next part --------------
year,WB,Site,Zone,Depth,surveyor,POMI_14,POMI_9
2008,1,Rovellad ,a,p,1,0.781107622,0.80279966
2008,2,Port_Selva ,a,p,1,0.633441988,0.669767557
2008,3,Tamariua ,a,p,1,0.716925282,0.744977731
2008,3,Culip    ,a,p,1,0.935657559,0.942033837
2008,3,Jugadora ,a,p,1,0.859538869,0.873458441
2008,4,Cadaques ,a,p,1,0.684976423,0.716194975
2008,5,Montjoi  ,a,p,1,0.749745797,0.774545763
2008,6,Roses_2 ,a,p,1,0.705540388,0.73472107
2008,7,Roses_1  ,a,p,1,0.406455662,0.465275371
2008,10,Montgo ,a,p,1,0.468556701,0.521222254
2008,10,Medas    ,a,p,1,0.675423785,0.707588995
2008,14,Sa_Tuna  ,a,p,1,0.560703188,0.604237106
2008,14,Llafranc ,a,p,1,0.575450184,0.617522688
2008,14,Palamos  ,a,p,1,0.567427391,0.610294947
2008,14,St_Feliu ,a,p,1,0.630364509,0.666995053
2008,14,Tossa    ,a,p,1,0.696983928,0.727012548
2008,14,Canyelle ,a,p,1,0.666440392,0.699495849
2008,14,Fenals   ,a,p,1,0.884870258,0.896279512
2008,16,Balis    ,a,p,1,0.56050751,0.60406082
2008,16,Mataro   ,a,p,1,0.566466791,0.609429541
2008,23,Sitges   ,a,p,1,0.414958755,0.472935815
2008,24,Vilanova ,a,p,1,0.346702757,0.411443925
2008,25,Comarug ,a,p,1,0.303724782,0.372725028
2008,25,Torredem ,a,p,1,0.290578787,0.36088179
2008,29,Salou    ,a,p,1,0.268360454,0.340865274
2008,30,Montroig ,a,p,1,0.399909348,0.459377791
2008,31,L_Hospit ,a,p,1,0.517707424,0.565502184
2008,31,Calafat  ,a,p,1,0.620118104,0.657764058
2008,32,L_Ametll ,a,p,1,0.519628625,0.567232995
2008,32,Cap_Roig ,a,p,1,0.301643481,0.370849983
2006,1,Rovellad ,a,p,1,0.830061339,0.631092868
2006,3,Tamariua ,a,p,1,0.644537158,0.59184892
2006,3,Culip    ,a,p,1,0.696764496,0.647210919
2006,3,Jugadora ,a,p,1,0.699754821,0.69911104
2006,5,Montjoi  ,a,p,1,0.531083947,0.565331223
2006,7,Roses_1  ,a,p,1,0.338586935,0.416484533
2006,10,Montgo ,a,p,1,0.618630194,0.518771081
2006,10,Medas    ,a,p,1,0.599916547,0.744704099
2006,14,Sa_Tuna  ,a,p,1,0.438411429,0.579487076
2006,14,Llafranc ,a,p,1,0.297618103,0.422441203
2006,14,Palamos  ,a,p,1,0.513128216,0.494888336
2006,14,St_Feliu ,a,p,1,0.578708665,0.717093178
2006,14,Tossa    ,a,p,1,0.556797987,0.661815274
2006,14,Canyelle ,a,p,1,0.504377726,0.600790934
2006,14,Fenals   ,a,p,1,0.65746308,0.797038708
2006,16,Balis    ,a,p,1,0.398365877,0.540523441
2006,16,Mataro   ,a,p,1,0.293938763,0.546353971
2006,23,Sitges   ,a,p,1,0.419821804,0.295669234
2006,24,Vilanova ,a,p,1,0.473647656,0.447921739
2006,25,Comarug ,a,p,1,0.392950219,0.288899653
2006,25,Torredem ,a,p,1,0.488461479,0.284022191
2006,29,Salou    ,a,p,1,0.47425399,0.284442662
2006,30,Montroig ,a,p,1,0.448925798,0.459134295
2006,31,L_Hospit ,a,p,1,0.672318243,0.579893531
2006,31,Calafat  ,a,p,1,0.613972453,0.549185141
2006,32,L_Ametll ,a,p,1,0.740379146,0.63193381
2006,32,Cap_Roig ,a,p,1,0.377695427,0.425496625
2005,1,Rovellad ,a,p,1,0.613089417,0.6010795
2005,3,Tamariua ,a,p,1,0.627720981,0.664700276
2005,3,Culip    ,a,p,1,0.654396909,0.707133319
2005,3,Jugadora ,a,p,1,0.757197896,0.812208357
2005,5,Montjoi  ,a,p,1,0.675401462,0.724559462
2005,7,Roses_1  ,a,p,1,0.525139248,0.542237478
2005,10,Montgo ,a,p,1,0.5626171,0.557706059
2005,10,Medas    ,a,p,1,0.716986675,0.775244974
2005,14,Sa_Tuna  ,a,p,1,0.662041572,0.690167778
2005,14,Llafranc ,a,p,1,0.577818725,0.66366392
2005,14,Palamos  ,a,p,1,0.506707278,0.570545365
2005,14,St_Feliu ,a,p,1,0.683543101,0.779121715
2005,14,Tossa    ,a,p,1,0.651795093,0.688517285
2005,14,Canyelle ,a,p,1,0.525928563,0.574115038
2005,14,Fenals   ,a,p,1,0.693760347,0.759027913
2005,16,Balis    ,a,p,1,0.536876657,0.578529149
2005,16,Mataro   ,a,p,1,0.521017269,0.545864726
2005,23,Sitges   ,a,p,1,0.288373944,0.208780166
2005,24,Vilanova ,a,p,1,0.379861414,0.380757776
2005,25,Comarug ,a,p,1,0.254243373,0.163065328
2005,25,Torredem ,a,p,1,0.245195483,0.203003438
2005,29,Salou    ,a,p,1,0.245663225,0.143969499
2005,30,Montroig ,a,p,1,0.414678981,0.400678852
2005,31,L_Hospit ,a,p,1,0.518064646,0.487310582
2005,31,Calafat  ,a,p,1,0.537417484,0.548781878
2005,32,L_Ametll ,a,p,1,0.546363055,0.531374927
2005,32,Cap_Roig ,a,p,1,0.396583201,0.327903593
2008,1,Rovellad ,a,p,2,0.835797869,0.644942527
2008,2,Port_Selva ,a,p,2,0.791972534,0.653946258
2008,3,Tamariua ,a,p,2,0.662135843,0.685428269
2008,3,Culip    ,a,p,2,0.720143502,0.734483079
2008,3,Jugadora ,a,p,2,0.495271707,0.441691062
2008,4,Cadaques ,a,p,2,0.535878572,0.517213736
2008,5,Montjoi  ,a,p,2,0.782317124,0.548866508
2008,6,Roses_2 ,a,p,2,0.567130818,0.54638272
2008,7,Roses_1  ,a,p,2,0.153828129,0.35502239
2008,10,Montgo ,a,p,2,0.633124494,0.436583773
2008,10,Medas    ,a,p,2,0.562227915,0.713541642
2008,14,Sa_Tuna  ,a,p,2,0.657488613,0.546460338
2008,14,Llafranc ,a,p,2,0.520237409,0.547158904
2008,14,Palamos  ,a,p,2,0.525982528,0.44949947
2008,14,St_Feliu ,a,p,2,0.596548236,0.60346327
2008,14,Tossa    ,a,p,2,0.675325554,0.635845654
2008,14,Canyelle ,a,p,2,0.786167256,0.640580374
2008,14,Fenals   ,a,p,2,0.780692849,0.816354936
2008,16,Balis    ,a,p,2,0.393468792,0.767377744
2008,16,Mataro   ,a,p,2,0.458078826,0.685723218
2008,23,Sitges   ,a,p,2,0.583298366,0.354789535
2008,24,Vilanova ,a,p,2,0.425879086,0.458021967
2008,25,Comarug ,a,p,2,0.768751423,0.32299705
2008,25,Torredem ,a,p,2,0.614370138,0.29794184
2008,29,Salou    ,a,p,2,0.509138199,0.209037759
2008,30,Montroig ,a,p,2,0.403996498,0.293455498
2008,31,L_Hospit ,a,p,2,0.803718446,0.620585882
2008,31,Calafat  ,a,p,2,0.680318695,0.527645645
2008,32,L_Ametll ,a,p,2,0.591013671,0.439766127
2008,32,Cap_Roig ,a,p,2,0.490880149,0.328476907
2002,3,Jugadora ,a,s,1,0.852607907,0.787071029
2002,3,Jugadora ,b,s,1,0.798730237,0.736424513
2002,3,Jugadora ,c,s,1,0.757097491,0.675645884
2002,3,Jugadora ,a,p,1,0.645718219,0.612211263
2002,3,Jugadora ,b,p,1,0.659123934,0.626193861
2002,3,Jugadora ,c,p,1,0.593213678,0.562871663
2002,5,Montjoi  ,a,s,1,0.694542203,0.675182139
2002,5,Montjoi  ,b,s,1,0.754818378,0.611438355
2002,5,Montjoi  ,c,s,1,0.736443912,0.70729293
2002,5,Montjoi  ,a,p,1,0.529950591,0.500069421
2002,5,Montjoi  ,b,p,1,0.578123401,0.485370127
2002,5,Montjoi  ,c,p,1,0.555587076,0.492537087
2002,14,Fenals   ,a,s,1,0.691045676,0.63625571
2002,14,Fenals   ,b,s,1,0.751378474,0.615541791
2002,14,Fenals   ,c,s,1,0.777184831,0.645390071
2002,14,Fenals   ,a,p,1,0.554638625,0.54375977
2002,14,Fenals   ,b,p,1,0.468867526,0.438602201
2002,14,Fenals   ,c,p,1,0.533701927,0.552093118
2002,30,Montroig ,a,s,1,0.634379276,0.648467648
2002,30,Montroig ,b,s,1,0.690196317,0.695347997
2002,30,Montroig ,c,s,1,0.744229703,0.736817994
2002,30,Montroig ,a,p,1,0.60022089,0.457278455
2002,30,Montroig ,b,p,1,0.440371532,0.45543753
2002,30,Montroig ,c,p,1,0.510061436,0.381589738
2002,23,Sitges   ,a,p,1,0.394930827,0.344377759
2002,23,Sitges   ,b,p,1,0.436082269,0.332727936
2002,23,Sitges   ,c,p,1,0.269961811,0.282910539
2002,25,Comarug ,a,p,1,0.394520304,0.351614983
2002,25,Comarug ,b,p,1,0.375438039,0.260383801
2002,25,Comarug ,c,p,1,0.303681362,0.240555212
2002,16,Mataro   ,a,p,1,0.530247867,0.429819162
2002,16,Mataro   ,b,p,1,0.495197654,0.475842286
2002,16,Mataro   ,c,p,1,0.496528316,0.467607309
2002,10,Montgo ,a,p,1,0.641315708,0.541384837
2002,10,Montgo ,b,p,1,0.58235604,0.540696246
2002,10,Montgo ,c,p,1,0.578491456,0.477121097
2008,1,Rovellad ,a,p,1,0.624182987,0.671245913
2008,3,Tamariua ,a,p,1,0.704355158,0.72756147
2008,3,Culip    ,a,p,1,0.80911293,0.782600491
2008,3,Jugadora ,a,p,1,0.610176765,0.614042332
2008,5,Montjoi  ,a,p,1,0.506873409,0.518672196
2008,7,Roses_1  ,a,p,1,0.533132584,0.354350654
2008,10,Montgo ,a,p,1,0.401936325,0.459082049
2008,10,Medas    ,a,p,1,0.717146046,0.711780534
2008,14,Sa_Tuna  ,a,p,1,0.555387136,0.586032558
2008,14,Llafranc ,a,p,1,0.606630382,0.562351903
2008,14,Palamos  ,a,p,1,0.452283014,0.429277725
2008,14,St_Feliu ,a,p,1,0.636435941,0.621054026
2008,14,Tossa    ,a,p,1,0.667536527,0.673521476
2008,14,Canyelle ,a,p,1,0.573776528,0.637519481
2008,14,Fenals   ,a,p,1,0.853203639,0.858952101
2008,16,Balis    ,a,p,1,0.913492156,0.832514871
2008,16,Mataro   ,a,p,1,0.826884694,0.747560523
2008,23,Sitges   ,a,p,1,0.245477066,0.320827728
2008,24,Vilanova ,a,p,1,0.45419567,0.463707177
2008,25,Comarug ,a,p,1,0.127709248,0.311373966
2008,25,Torredem ,a,p,1,0.157156183,0.272041879
2008,29,Salou    ,a,p,1,0.128287029,0.146090398
2008,30,Montroig ,a,p,1,0.352565888,0.27387343
2008,31,L_Hospit ,a,p,1,0.533232202,0.463263165
2008,31,Calafat  ,a,p,1,0.516596078,0.534305128
2008,32,L_Ametll ,a,p,1,0.48930088,0.434772377
2008,32,Cap_Roig ,a,p,1,0.370736122,0.344452881
2006,1,Rovellad ,a,p,1,0.830061339,0.631092868
2006,3,Tamariua ,a,p,1,0.644537158,0.59184892
2006,3,Culip    ,a,p,1,0.696764496,0.647210919
2006,3,Jugadora ,a,p,1,0.699754821,0.69911104
2006,5,Montjoi  ,a,p,1,0.531083947,0.565331223
2006,7,Roses_1  ,a,p,1,0.338586935,0.416484533
2006,10,Montgo ,a,p,1,0.618630194,0.518771081
2006,10,Medas    ,a,p,1,0.599916547,0.744704099
2006,14,Sa_Tuna  ,a,p,1,0.438411429,0.579487076
2006,14,Llafranc ,a,p,1,0.297618103,0.422441203
2006,14,Palamos  ,a,p,1,0.513128216,0.494888336
2006,14,St_Feliu ,a,p,1,0.578708665,0.717093178
2006,14,Tossa    ,a,p,1,0.556797987,0.661815274
2006,14,Canyelle ,a,p,1,0.504377726,0.600790934
2006,14,Fenals   ,a,p,1,0.65746308,0.797038708
2006,16,Balis    ,a,p,1,0.398365877,0.540523441
2006,16,Mataro   ,a,p,1,0.293938763,0.546353971
2006,23,Sitges   ,a,p,1,0.419821804,0.295669234
2006,24,Vilanova ,a,p,1,0.473647656,0.447921739
2006,25,Comarug ,a,p,1,0.392950219,0.288899653
2006,25,Torredem ,a,p,1,0.488461479,0.284022191
2006,29,Salou    ,a,p,1,0.47425399,0.284442662
2006,30,Montroig ,a,p,1,0.448925798,0.459134295
2006,31,L_Hospit ,a,p,1,0.672318243,0.579893531
2006,31,Calafat  ,a,p,1,0.613972453,0.549185141
2006,32,L_Ametll ,a,p,1,0.740379146,0.63193381
2006,32,Cap_Roig ,a,p,1,0.377695427,0.425496625
2005,1,Rovellad ,a,p,1,0.613089417,0.6010795
2005,3,Tamariua ,a,p,1,0.627720981,0.664700276
2005,3,Culip    ,a,p,1,0.654396909,0.707133319
2005,3,Jugadora ,a,p,1,0.757197896,0.812208357
2005,5,Montjoi  ,a,p,1,0.675401462,0.724559462
2005,7,Roses_1  ,a,p,1,0.525139248,0.542237478
2005,10,Montgo ,a,p,1,0.5626171,0.557706059
2005,10,Medas    ,a,p,1,0.716986675,0.775244974
2005,14,Sa_Tuna  ,a,p,1,0.662041572,0.690167778
2005,14,Llafranc ,a,p,1,0.577818725,0.66366392
2005,14,Palamos  ,a,p,1,0.506707278,0.570545365
2005,14,St_Feliu ,a,p,1,0.683543101,0.779121715
2005,14,Tossa    ,a,p,1,0.651795093,0.688517285
2005,14,Canyelle ,a,p,1,0.525928563,0.574115038
2005,14,Fenals   ,a,p,1,0.693760347,0.759027913
2005,16,Balis    ,a,p,1,0.536876657,0.578529149
2005,16,Mataro   ,a,p,1,0.521017269,0.545864726
2005,23,Sitges   ,a,p,1,0.288373944,0.208780166
2005,24,Vilanova ,a,p,1,0.379861414,0.380757776
2005,25,Comarug ,a,p,1,0.254243373,0.163065328
2005,25,Torredem ,a,p,1,0.245195483,0.203003438
2005,29,Salou    ,a,p,1,0.245663225,0.143969499
2005,30,Montroig ,a,p,1,0.414678981,0.400678852
2005,31,L_Hospit ,a,p,1,0.518064646,0.487310582
2005,31,Calafat  ,a,p,1,0.537417484,0.548781878
2005,32,L_Ametll ,a,p,1,0.546363055,0.531374927
2005,32,Cap_Roig ,a,p,1,0.396583201,0.327903593

From ned.dochtermann at gmail.com  Mon Oct 11 22:06:25 2010
From: ned.dochtermann at gmail.com (Ned Dochtermann)
Date: Mon, 11 Oct 2010 13:06:25 -0700
Subject: [R-sig-ME] priors for a multi-response model (MCMCglmm)
Message-ID: <4cb36e43.4800e70a.39f9.0ae0@mx.google.com>

Hi all,

While I'm still struggling with properly specifying priors in general, I've
run into a specific problem I can't quite muddle through. I'm trying to
estimate the covariances among several behaviors with repeated measures per
individual. I initially did so using the following structure:

multi.prior<-list(G=list(G1=(list(V=diag(3),nu=3))),R=list(V=diag(3),nu=3))
#I know this assumes unit variance

multi.trait.p1<-MCMCglmm(cbind(trait1,trait2,trait3)~trait,
random=~us(trait):units, rcov=~us(trait):units,
family=c("poisson","poisson","poisson), data=Compiled, prior=multi.prior,
verbose=FALSE)

or if including fixed factors:
multi.trait.p2<-MCMCglmm(cbind(trait1,trait2,trait3)~trait+period+day,
random=~us(trait):units, rcov=~us(trait):units,
family=c("poisson","poisson","poisson), data=Compiled, prior=multi.prior,
verbose=FALSE)

(I actually run both a lot longer than the defaults but I've left that out
here as it isn't relevant)

Both of these models seem to work well, they give reasonable answers and
satisfy a variety of diagnostics.


However, in looking back over the data I realized the data had pretty severe
zero-inflation. Thus, I've tried to rerun the analyses using zero-inflated
models. Based on the MCMCglmm course notes I thought that the first step for
the priors would be to expand both G and R to diag(4):

multi.prior.zip<-list(G=list(G1=(list(V=diag(4),nu=4))),R=list(V=diag(4),nu=
4)) #the last 'nu' is wrong based on how ZIP model priors are specified in
the course notes

multi.trait.zip<-MCMCglmm(cbind(trait1,trait2,trait3)~trait,
random=~us(trait):units, rcov=~us(trait):units,
family=c("zipoisson","zipoisson","zipoisson),
data=Compiled,prior=multi.prior.zip,verbose=FALSE)

This doesn't work as "V is the wrong dimension for some priorG/priorR
elements". I also suspect it is more generally wrong due to the random and
rcov statements and issues with estimating aspects of the zero-inflation and
poisson covariances; however I'm specifically interested in estimating the
covariance matrix so I don't want to use an idh specification here.

I'd like to get the covariance matrix from a ZIP model but I'm not sure what
all the errors in the above coding are nor the solutions. Basically I know
both the specification of the prior and the specification of the model are
wrong. Any help would be greatly appreciated.


Thanks,
Ned

--
Ned Dochtermann
Department of Biology
University of Nevada, Reno

ned.dochtermann at gmail.com
http://wolfweb.unr.edu/homepage/mpeacock/Dochter/
--



From arrayprofile at yahoo.com  Tue Oct 12 07:23:17 2010
From: arrayprofile at yahoo.com (array chip)
Date: Mon, 11 Oct 2010 22:23:17 -0700 (PDT)
Subject: [R-sig-ME] lmer give error message
In-Reply-To: <AANLkTimMTqtpPdvbH+hw5N9w4EidR5t9nLhn07E9332j@mail.gmail.com>
References: <293395.34226.qm@web56304.mail.re3.yahoo.com>
	<AANLkTimMTqtpPdvbH+hw5N9w4EidR5t9nLhn07E9332j@mail.gmail.com>
Message-ID: <46741.40301.qm@web56308.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101011/e56b14e1/attachment.pl>

From djmuser at gmail.com  Tue Oct 12 10:29:40 2010
From: djmuser at gmail.com (Dennis Murphy)
Date: Tue, 12 Oct 2010 01:29:40 -0700
Subject: [R-sig-ME] lmer give error message
In-Reply-To: <46741.40301.qm@web56308.mail.re3.yahoo.com>
References: <293395.34226.qm@web56304.mail.re3.yahoo.com>
	<AANLkTimMTqtpPdvbH+hw5N9w4EidR5t9nLhn07E9332j@mail.gmail.com>
	<46741.40301.qm@web56308.mail.re3.yahoo.com>
Message-ID: <AANLkTi=CxddrJQ6nLPc5fAPMebrb-q_wGw0oE-1kP+38@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101012/42f888c0/attachment.pl>

From Thierry.ONKELINX at inbo.be  Tue Oct 12 10:36:40 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 12 Oct 2010 10:36:40 +0200
Subject: [R-sig-ME] why does my inter-annual SD = 0?
In-Reply-To: <20101011193833.883163ya0oh9u6xl@webmail.csic.es>
References: <20101011173249.137427bnnkkkhcm9@webmail.csic.es><4CB33AAD.5080409@gmail.com>
	<20101011193833.883163ya0oh9u6xl@webmail.csic.es>
Message-ID: <3DB16098F738284D8DBEB2FC369916383EFA24@inboexch.inbo.be>

Dear Scott,

Thanks for sharing your data. That makes things a lot easier.

IMHO you have several problems with your model. First you have only 4
years. Estimating a variance based on only 4 levels will give you very
unreliable estimates. Therefore it is better to treat them as a fixed
effect.
Another possible problem might be the structure of your nested random
effects. I noticed that many levels of WB have only one level of site,
and many levels of site have only one levels of zone. In such a case
there is competition between the nested effects. I'm not sure how lmer
handles that. If it were just a few cases I guess it will not be a big
issue. But your data has quite a lot of this things. A possible solution
is to use (1|WB:site:zone) as random effect.

HTH,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Scott Bennett
> Verzonden: maandag 11 oktober 2010 19:39
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: Re: [R-sig-ME] why does my inter-annual SD = 0?
> 
> 
> 
> Hi all, thanks for the quick replies! I have attached the 
> data, if it helps for you to look at it directly. The end 
> product that I would like to achieve is an estimate of the 
> variance associated with each factor (depth, surveyor, year, 
> water body, site and zone), to then model the probability of 
> misclassifying the health status of a water body, based on 
> the variability associated with each of the respective 
> factors (An uncertainty analysis of our seagrass index). The 
> index we are using POMI_14 (Posidonia oceanica multivariate 
> index, Romero et al. 2008) is comprised of 14 metrics relates 
> to the health and status of /P. oceanica./ There are only 4 
> years of data. The 2005, 2006 and 2008 data is from annual 
> sampling of  30 seagrass meadows (sites) sampled at a single 
> depth along the Catalan coast, Spain. The 2002 data is of a 
> subset of those sites, but includes replication between 2 
> discrete depths (5m and 15m) and among three discrete zones 
> nested within each site. The sites are nested within 
> 'water-bodies'. A water body represents an area of coastal 
> water (15 - 50 km in length) which has been classified based 
> on its exposure to water quality pressures. The surveyor 
> factor, is only from the 2008 series, where we calculated 
> POMI based on two separate surveyors. Needless to say the 
> design is unbalanced.  
> 
> In short the data looks like this:  
> 
> 'data.frame':   231 obs. of  8 variables: 
>  $ year    : Factor w/ 4 levels "2002","2005",..: 4 4 4 4 4 4 
> 4 4 4 4 ...
>  $ WB      : Factor w/ 17 levels "1","2","3","4",..: 1 2 3 3 
> 3 4 5 6 7 8 ...
>  $ Site    : Factor w/ 30 levels "Balis    ","Cadaques ",..: 
> 22 19 27 7 9 2 16 21 20 15 ...
>  $ Zone    : Factor w/ 3 levels "a","b","c":..: 1 1 1 1 1 1 1 
> 1 1 1 ...
>  $ Depth   : Factor w/ 2 levels "p","s": 1 1 1 1 1 1 1 1 1 1 ...
>  $ surveyor: Factor w/ 2 levels "1","2": 1 1 1 1 1 1 1 1 1 1 ...
>  $ POMI_14 : num  0.781 0.633 0.717 0.936 0.86 ...
>  $ POMI_9  : num  0.803 0.67 0.745 0.942 0.873 ... 
> 
> I hope this makes things clearer. Any help will be greatly 
> appreciated.  
> 
> Kind regards  
> 
> Scott Bennett  
> 
> > On 10-10-11 11:32 AM, Scott Bennett wrote:
> >>
> >>
> >> Hi,
> >>
> >> I am applying a mixed model to calculate the variance 
> components of 
> >> different factors in our seagrass data. The model i was 
> using looks 
> >> something like:
> >>
> >> POMI14_vc <- lmer(POMI_14 ~ Depth + surveyor + (1|region/site/zone)
> >> + (1|year), data = P_oceanica)
> >>
> >> When I apply this model, however, year comes out with SD = 
> 0. Year, 
> >> in this data set signifies inter-annual variation (in the health 
> >> status of seagrass meadows), of which there is a 
> considerable amount. 
> >> That makes me believe that there is is a feature of the 
> model which 
> >> is 'absorbing' the inter-annual variation.
> >>
> >> Can you suggest why this may be occuring? What 
> modifiations could i 
> >> use to fix this?
> >>
> >> kind regards
> >>
> >> Scott Bennett
> >
> >    Hard to say for sure without seeing the data.
> >    How many years do you have?  Are Depth and surveyor well 
> > distributed across years?
> >    What happens if you treat year as a fixed effect and 
> calculate the 
> > among-year variance on the basis of the fixed effect estimates?
> >
> >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
>  
> 



From j.hadfield at ed.ac.uk  Tue Oct 12 11:43:09 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 12 Oct 2010 10:43:09 +0100
Subject: [R-sig-ME] priors for a multi-response model (MCMCglmm)
In-Reply-To: <4cb36e43.4800e70a.39f9.0ae0@mx.google.com>
References: <4cb36e43.4800e70a.39f9.0ae0@mx.google.com>
Message-ID: <1CB6365E-135C-4967-8A98-CD01A8B74177@ed.ac.uk>

Hi Ned,

I think you haven't specified the model that you want to fit.

1) you have "random=~us(trait):units, rcov=~us(trait):units" which is  
fitting the same terms for the random effects and the residuals. I  
think you want something like  "random=~us(trait):individual,  
rcov=~us(trait):units"? At the moment any separation of these effects  
is coming entirely from the prior.

2) depending on what your responses are "~trait+period+day" for the  
fixed terms is probably not appropriate. You probably want to interact  
period and day with trait, so that the effect of these two predictors  
can have independent effects on each response

3) zero-inflated poisson are treated as multi-response. The first  
latent variable is for the poisson counts, and the second is for the  
zero-inflation. The residual variance for the zero-inflated part  
cannot be estimated from the data (for the same reasons that the  
residual variance in a binary model is not identified) and neither can  
the residual covariance between zero-inflation and the poisson counts  
(you only see one of the processes in any one observation).  I  
generally place strong priors on them by fixing the residual variance  
to one and the residual covariance to zero. I achieve this by fitting  
an idh residual structure idh(trait):units which fixes the residual  
covariance to zero, and fix the 2nd diagonal element of the residual  
matrix (the zero-inflation variance) to one in the prior:  
"prior=list(R=diag(2), nu=...,  fix=2)"

4)  If you have 3 ZIP responses you have 6 "traits" to worry about.   
It is not possible to place the appropriate constraints on this  
matrix: the sub-diagonals cannot be estimated (corresponding to the  
covariance between the poisson counts and the zero-inflation within  
traits) and neither can the even elements of the diagonal (the 3 zero- 
inflation terms). You may be able to specify a prior which has a  
desirable marginal effect on the things you want to calculate, but I  
think this would be hard and a lot of work.

5) These are very parameter rich models, and I would avoid them unless  
you have a lot of individuals measured many times.

Cheers,

Jarrod



On 11 Oct 2010, at 21:06, Ned Dochtermann wrote:

> Hi all,
>
> While I'm still struggling with properly specifying priors in  
> general, I've
> run into a specific problem I can't quite muddle through. I'm trying  
> to
> estimate the covariances among several behaviors with repeated  
> measures per
> individual. I initially did so using the following structure:
>
> multi.prior<- 
> list(G=list(G1=(list(V=diag(3),nu=3))),R=list(V=diag(3),nu=3))
> #I know this assumes unit variance
>
> multi.trait.p1<-MCMCglmm(cbind(trait1,trait2,trait3)~trait,
> random=~us(trait):units, rcov=~us(trait):units,
> family=c("poisson","poisson","poisson), data=Compiled,  
> prior=multi.prior,
> verbose=FALSE)
>
> or if including fixed factors:
> multi.trait.p2<-MCMCglmm(cbind(trait1,trait2,trait3)~trait+period+day,
> random=~us(trait):units, rcov=~us(trait):units,
> family=c("poisson","poisson","poisson), data=Compiled,  
> prior=multi.prior,
> verbose=FALSE)
>
> (I actually run both a lot longer than the defaults but I've left  
> that out
> here as it isn't relevant)
>
> Both of these models seem to work well, they give reasonable answers  
> and
> satisfy a variety of diagnostics.
>
>
> However, in looking back over the data I realized the data had  
> pretty severe
> zero-inflation. Thus, I've tried to rerun the analyses using zero- 
> inflated
> models. Based on the MCMCglmm course notes I thought that the first  
> step for
> the priors would be to expand both G and R to diag(4):
>
> multi.prior.zip<- 
> list(G=list(G1=(list(V=diag(4),nu=4))),R=list(V=diag(4),nu=
> 4)) #the last 'nu' is wrong based on how ZIP model priors are  
> specified in
> the course notes
>
> multi.trait.zip<-MCMCglmm(cbind(trait1,trait2,trait3)~trait,
> random=~us(trait):units, rcov=~us(trait):units,
> family=c("zipoisson","zipoisson","zipoisson),
> data=Compiled,prior=multi.prior.zip,verbose=FALSE)
>
> This doesn't work as "V is the wrong dimension for some priorG/priorR
> elements". I also suspect it is more generally wrong due to the  
> random and
> rcov statements and issues with estimating aspects of the zero- 
> inflation and
> poisson covariances; however I'm specifically interested in  
> estimating the
> covariance matrix so I don't want to use an idh specification here.
>
> I'd like to get the covariance matrix from a ZIP model but I'm not  
> sure what
> all the errors in the above coding are nor the solutions. Basically  
> I know
> both the specification of the prior and the specification of the  
> model are
> wrong. Any help would be greatly appreciated.
>
>
> Thanks,
> Ned
>
> --
> Ned Dochtermann
> Department of Biology
> University of Nevada, Reno
>
> ned.dochtermann at gmail.com
> http://wolfweb.unr.edu/homepage/mpeacock/Dochter/
> --
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From ndjido at gmail.com  Tue Oct 12 16:22:56 2010
From: ndjido at gmail.com (Ndjido Ardo BAR)
Date: Tue, 12 Oct 2010 14:22:56 +0000
Subject: [R-sig-ME] Wald test on heritabilty estimates from MCMCglmm
Message-ID: <AANLkTimQ_D2Ow20YMrYoCGAgmNkV2720P6URYb6wdtYo@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101012/f269e603/attachment.pl>

From bvholbi at yahoo.com  Tue Oct 12 21:03:42 2010
From: bvholbi at yahoo.com (Beth Holbrook)
Date: Tue, 12 Oct 2010 12:03:42 -0700 (PDT)
Subject: [R-sig-ME] Beginner help setting up a mixed model
Message-ID: <659582.98329.qm@web35308.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101012/232432b5/attachment.pl>

From desja004 at umn.edu  Tue Oct 12 22:08:44 2010
From: desja004 at umn.edu (Christopher Desjardins)
Date: Tue, 12 Oct 2010 15:08:44 -0500
Subject: [R-sig-ME] Beginner help setting up a mixed model
In-Reply-To: <659582.98329.qm@web35308.mail.mud.yahoo.com>
References: <659582.98329.qm@web35308.mail.mud.yahoo.com>
Message-ID: <AANLkTi=7yPOJmZkuKF6SQCJaB2CPCSTwr0G+0SfKSq28@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101012/ff5b2ba5/attachment.pl>

From bates at stat.wisc.edu  Tue Oct 12 23:03:31 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 12 Oct 2010 16:03:31 -0500
Subject: [R-sig-ME] Beginner help setting up a mixed model
In-Reply-To: <AANLkTi=7yPOJmZkuKF6SQCJaB2CPCSTwr0G+0SfKSq28@mail.gmail.com>
References: <659582.98329.qm@web35308.mail.mud.yahoo.com>
	<AANLkTi=7yPOJmZkuKF6SQCJaB2CPCSTwr0G+0SfKSq28@mail.gmail.com>
Message-ID: <AANLkTi=nB8=6g4+aKZNYHp5FdPX4pWJoy-t4TccW05G5@mail.gmail.com>

On Tue, Oct 12, 2010 at 3:08 PM, Christopher Desjardins
<desja004 at umn.edu> wrote:
> Hi Beth,
>
> On Tue, Oct 12, 2010 at 2:03 PM, Beth Holbrook <bvholbi at yahoo.com> wrote:
>
>> I am new to both R and mixed models, so I apologize in advance about the
>> simplistic nature of my question.
>>
>> My dataset is unbalanced and have been I have been advised by the
>> statistician
>> on my Ph.D. committee to run a mixed model. ?The response variable is
>> distance.
>> The factors are preyswim, light, and trial. ?I am interested in the effects
>> of
>> light and preyswim on distance. ?Trial is a random factor and there is also
>> a
>> crossed random effect of preyswim*trial. ?In SAS, the code would look like
>> this:
>>
>> Proc mixed data=laketrout;
>> Class preyswim light trial;
>> Model distance = light | preyswim;
>> Random trial trial*preyswim;
>> Run;
>>
>> My understanding is that to test the full ANOVA model in R, I would need to
>> code
>> three separate models and determine the most appropriate. ?This is how I
>> attempted to code the same model using the lme4 package in R:
>>
>> options(contrasts=c(unordered="contr.SAS", ordered="contr.poly"))
>> mixed1 <- lmer(distance~preyswim*light + (1|trial) + (1|preyswim),
>> laketrout,
>> REML=FALSE)
>>
>
> I am not sure this is the model you want to run. If you want a crossed
> random effect I believe you need something like the following:
>
> mixed1 <- lmer(distance~ + (1|trial) + (1|preyswim) + (1|preyswim:light),
> laketrout,REML=FALSE)
>
> But then you no longer have any fixed effects. So I am not sure. I wonder if
> you want this based on what you said above...
>
> mixed1 <- lmer(distance~ preyswim + light + (1|trial) + (1|preyswim:light),
> laketrout,REML=FALSE)
>
> or ...
>
> mixed1 <- lmer(distance~ preyswim + light + preyswim*light + (1|trial),
> laketrout,REML=FALSE)
>
> But that model doesn't treat preyswim*light as a crossed random effect
>
>
> mixed2 <-lmer(distance~preyswim + light + (1|trial) + (1|preyswim),
>> laketrout,
>> REML=FALSE)
>> mixed3 <-lmer(distance~preyswim + (1|trial) + (1|preyswim), laketrout,
>> REML=FALSE)
>>
>> My questions are:
>>
>> 1. ?Did I correctly set up the mixed model in R?
>> 2. ?When determining the most appropriate model in R (I used the anova
>> function
>> to compare the three models), does it matter whether I use the AIC/BIC or
>> log-likelihood criterion? ?Along those lines, I'm unsure whether I need to
>> use
>> REML=TRUE or REML=FALSE in my code.
>>
>
> The anova function would work here because your models are nested. I believe
> it's quite common to use the AIC and use the criterion of Burnham and
> Anderson, 2002. Also, I believe you want REML=TRUE when comparing models
> with different random effects.

Hmm - I think you have that backwards.  When comparing models with
different *fixed* effects you must use REML=FALSE.  The REML criterion
depends on the structure of the fixed-effects model matrix and you
can't easily compare values of the REML criterion for models with
different fixed-effects structure.  There may be advice to use
REML=TRUE when the random effects change but, if so, I don't know why.

My current attitude is that the usual justification for using REML
(reducing the bias in estimates of variance components) isn't as
important as many people believe, because the distribution of the
estimator can be highly skewed and why should we be overwhelmingly
interested in the mean value of a highly skewed distribution?  I
prefer to stay with maximum likelihood fits so that likelihood ratio
tests and derived criterion like AIC and BIC are well-defined.

>> I no longer have access to SAS although it is the preferred statistical
>> program
>> used by my committee statistician. ?I understand that there are some
>> limitations
>> to SAS anyway, particularly when calculating p-values for mixed models with
>> random effects.

Not sure I understand that statement.  All mixed models have random
effects.  The definition of a mixed models is that it incorporates
both fixed-effects parameters and random effects.

You mentioned p-values and I think you are reversing SAS and lme4
there.  Many people consider it to be a deficiency of the lme4 package
(which is different from R itself - you can blame SAS Institute for
everything that is in SAS but you should not blame the R Foundation
for everything that is in contributed R packages) that it does not
give p-values for fixed-effects coefficients in a model fit by lmer.
The preferred approach with lme4 is to fit the model with and without
a particular term and use a likelihood ratio test to compare the
quality of the fits.  SAS PROC MIXED, on the other hand, is happy to
provide p-values.  In fact, SAS seem to pride themselves on providing
many different p-values for the same test, even when the test wouldn't
make sense.

>> My preference is to use R for my statistical analyses, as
>> long
>> as I know that I'm using it correctly.

>>
>>
>> Thanks so much for your help,
>> -Beth
>>
>> Beth Holbrook
>> University of Minnesota
>> bvholbi at yahoo.com
>>
>>
>>
>>
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
> Christopher David Desjardins
> Ph.D. student, Quantitative Methods in Education
> M.S. student, Statistics
> University of Minnesota
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From desja004 at umn.edu  Wed Oct 13 01:37:20 2010
From: desja004 at umn.edu (Christopher David Desjardins)
Date: Tue, 12 Oct 2010 18:37:20 -0500
Subject: [R-sig-ME] Beginner help setting up a mixed model
In-Reply-To: <AANLkTi=nB8=6g4+aKZNYHp5FdPX4pWJoy-t4TccW05G5@mail.gmail.com>
References: <659582.98329.qm@web35308.mail.mud.yahoo.com>	<AANLkTi=7yPOJmZkuKF6SQCJaB2CPCSTwr0G+0SfKSq28@mail.gmail.com>
	<AANLkTi=nB8=6g4+aKZNYHp5FdPX4pWJoy-t4TccW05G5@mail.gmail.com>
Message-ID: <4CB4F130.3040204@umn.edu>

  On 10/12/10 4:03 PM, Douglas Bates wrote:
> On Tue, Oct 12, 2010 at 3:08 PM, Christopher Desjardins
> <desja004 at umn.edu>  wrote:
>> Hi Beth,
>>
>> On Tue, Oct 12, 2010 at 2:03 PM, Beth Holbrook<bvholbi at yahoo.com>  wrote:
>>
>>> I am new to both R and mixed models, so I apologize in advance about the
>>> simplistic nature of my question.
>>>
>>> My dataset is unbalanced and have been I have been advised by the
>>> statistician
>>> on my Ph.D. committee to run a mixed model.  The response variable is
>>> distance.
>>> The factors are preyswim, light, and trial.  I am interested in the effects
>>> of
>>> light and preyswim on distance.  Trial is a random factor and there is also
>>> a
>>> crossed random effect of preyswim*trial.  In SAS, the code would look like
>>> this:
>>>
>>> Proc mixed data=laketrout;
>>> Class preyswim light trial;
>>> Model distance = light | preyswim;
>>> Random trial trial*preyswim;
>>> Run;
>>>
>>> My understanding is that to test the full ANOVA model in R, I would need to
>>> code
>>> three separate models and determine the most appropriate.  This is how I
>>> attempted to code the same model using the lme4 package in R:
>>>
>>> options(contrasts=c(unordered="contr.SAS", ordered="contr.poly"))
>>> mixed1<- lmer(distance~preyswim*light + (1|trial) + (1|preyswim),
>>> laketrout,
>>> REML=FALSE)
>>>
>> I am not sure this is the model you want to run. If you want a crossed
>> random effect I believe you need something like the following:
>>
>> mixed1<- lmer(distance~ + (1|trial) + (1|preyswim) + (1|preyswim:light),
>> laketrout,REML=FALSE)
>>
>> But then you no longer have any fixed effects. So I am not sure. I wonder if
>> you want this based on what you said above...
>>
>> mixed1<- lmer(distance~ preyswim + light + (1|trial) + (1|preyswim:light),
>> laketrout,REML=FALSE)
>>
>> or ...
>>
>> mixed1<- lmer(distance~ preyswim + light + preyswim*light + (1|trial),
>> laketrout,REML=FALSE)
>>
>> But that model doesn't treat preyswim*light as a crossed random effect
>>
>>
>> mixed2<-lmer(distance~preyswim + light + (1|trial) + (1|preyswim),
>>> laketrout,
>>> REML=FALSE)
>>> mixed3<-lmer(distance~preyswim + (1|trial) + (1|preyswim), laketrout,
>>> REML=FALSE)
>>>
>>> My questions are:
>>>
>>> 1.  Did I correctly set up the mixed model in R?
>>> 2.  When determining the most appropriate model in R (I used the anova
>>> function
>>> to compare the three models), does it matter whether I use the AIC/BIC or
>>> log-likelihood criterion?  Along those lines, I'm unsure whether I need to
>>> use
>>> REML=TRUE or REML=FALSE in my code.
>>>
>> The anova function would work here because your models are nested. I believe
>> it's quite common to use the AIC and use the criterion of Burnham and
>> Anderson, 2002. Also, I believe you want REML=TRUE when comparing models
>> with different random effects.
> Hmm - I think you have that backwards.  When comparing models with
> different *fixed* effects you must use REML=FALSE.  The REML criterion
> depends on the structure of the fixed-effects model matrix and you
> can't easily compare values of the REML criterion for models with
> different fixed-effects structure.  There may be advice to use
> REML=TRUE when the random effects change but, if so, I don't know why.
Yes I mistyped and got that backwards.
Chris
> My current attitude is that the usual justification for using REML
> (reducing the bias in estimates of variance components) isn't as
> important as many people believe, because the distribution of the
> estimator can be highly skewed and why should we be overwhelmingly
> interested in the mean value of a highly skewed distribution?  I
> prefer to stay with maximum likelihood fits so that likelihood ratio
> tests and derived criterion like AIC and BIC are well-defined.
>
>>> I no longer have access to SAS although it is the preferred statistical
>>> program
>>> used by my committee statistician.  I understand that there are some
>>> limitations
>>> to SAS anyway, particularly when calculating p-values for mixed models with
>>> random effects.
> Not sure I understand that statement.  All mixed models have random
> effects.  The definition of a mixed models is that it incorporates
> both fixed-effects parameters and random effects.
>
> You mentioned p-values and I think you are reversing SAS and lme4
> there.  Many people consider it to be a deficiency of the lme4 package
> (which is different from R itself - you can blame SAS Institute for
> everything that is in SAS but you should not blame the R Foundation
> for everything that is in contributed R packages) that it does not
> give p-values for fixed-effects coefficients in a model fit by lmer.
> The preferred approach with lme4 is to fit the model with and without
> a particular term and use a likelihood ratio test to compare the
> quality of the fits.  SAS PROC MIXED, on the other hand, is happy to
> provide p-values.  In fact, SAS seem to pride themselves on providing
> many different p-values for the same test, even when the test wouldn't
> make sense.
>
>>> My preference is to use R for my statistical analyses, as
>>> long
>>> as I know that I'm using it correctly.
>>>
>>> Thanks so much for your help,
>>> -Beth
>>>
>>> Beth Holbrook
>>> University of Minnesota
>>> bvholbi at yahoo.com
>>>
>>>
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>> --
>> Christopher David Desjardins
>> Ph.D. student, Quantitative Methods in Education
>> M.S. student, Statistics
>> University of Minnesota
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>



From djmuser at gmail.com  Wed Oct 13 12:08:37 2010
From: djmuser at gmail.com (Dennis Murphy)
Date: Wed, 13 Oct 2010 03:08:37 -0700
Subject: [R-sig-ME] Beginner help setting up a mixed model
In-Reply-To: <659582.98329.qm@web35308.mail.mud.yahoo.com>
References: <659582.98329.qm@web35308.mail.mud.yahoo.com>
Message-ID: <AANLkTiknggq7nxzOZ14U30ufY_QriXOLJKA__RsZdu96@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101013/5fd6081f/attachment.pl>

From j.hadfield at ed.ac.uk  Wed Oct 13 12:40:20 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 13 Oct 2010 11:40:20 +0100
Subject: [R-sig-ME] Wald test on heritabilty estimates from MCMCglmm
In-Reply-To: <AANLkTimQ_D2Ow20YMrYoCGAgmNkV2720P6URYb6wdtYo@mail.gmail.com>
References: <AANLkTimQ_D2Ow20YMrYoCGAgmNkV2720P6URYb6wdtYo@mail.gmail.com>
Message-ID: <A9B96251-2496-41A3-9E79-DFCFBFACDCB6@ed.ac.uk>

Dear Ardo,

I think the Wald test will lead you to draw incorrect conclusions for  
bounded posteriors that are highly skewed. I think a priori that if  
the trait is variable then the probability that h2 = 0 is small  
(considerably smaller than the p-value everyone is searching for). For  
me at least, the important thing is to say something accurate and  
precise about the magnitude of h2, and this information is neatly  
summarised using HPDinterval. It is common to see h2 estimates that  
are "significant" but the CI's are essentially 0.01 to 1.   Such  
studies tell us little that we did not already know: a proportion lies  
between 0 and 1.

Cheers,

Jarrod


On 12 Oct 2010, at 15:22, Ndjido Ardo BAR wrote:

> Hi Folks!
> I would like to performe a Wald test on heritabilities I estimated  
> from
> MCMCglmm. Does it make sense to use the variance posterieur of h? to  
> build
> Wald statistics (h?/sqrt(Var_post))?
> Ardo
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From ned.dochtermann at gmail.com  Wed Oct 13 20:04:33 2010
From: ned.dochtermann at gmail.com (Ned Dochtermann)
Date: Wed, 13 Oct 2010 11:04:33 -0700
Subject: [R-sig-ME] priors for a multi-response model (MCMCglmm)
In-Reply-To: <1CB6365E-135C-4967-8A98-CD01A8B74177@ed.ac.uk>
References: <4cb36e43.4800e70a.39f9.0ae0@mx.google.com>
	<1CB6365E-135C-4967-8A98-CD01A8B74177@ed.ac.uk>
Message-ID: <4cb5f4b3.2249960a.7959.ffffef83@mx.google.com>

Jarrod,
Thanks a lot for the comments.
Regarding 1 and 2 below, sorry about that--those were actually typos from
trying to simplify the code and make it more generic. Both aspects of the
code were actually specified as you suggest; sorry for the sloppiness.

3 and 4 really look like the key issues for this analysis (besides the
number of parameters being estimated which has been a concern throughout).
Unfortunately those points suggest that the best alternative is to estimate
the covariance matrix using a Poisson distribution, despite the known
zero-inflation. Under the family statement in the help for MCMCglmm a
ztpoisson distribution is mentioned however no zero-truncated distribution
is mentioned in the course notes. Is this something that was previously
available but has been removed?



Thanks, 
Ned

--
Ned Dochtermann
Department of Biology
University of Nevada, Reno

ned.dochtermann at gmail.com
website
--



-----Original Message-----
From: Jarrod Hadfield [mailto:j.hadfield at ed.ac.uk] 
Sent: Tuesday, October 12, 2010 2:43 AM
To: Ned Dochtermann
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] priors for a multi-response model (MCMCglmm)

Hi Ned,

I think you haven't specified the model that you want to fit.

1) you have "random=~us(trait):units, rcov=~us(trait):units" which is  
fitting the same terms for the random effects and the residuals. I  
think you want something like  "random=~us(trait):individual,  
rcov=~us(trait):units"? At the moment any separation of these effects  
is coming entirely from the prior.

2) depending on what your responses are "~trait+period+day" for the  
fixed terms is probably not appropriate. You probably want to interact  
period and day with trait, so that the effect of these two predictors  
can have independent effects on each response

3) zero-inflated poisson are treated as multi-response. The first  
latent variable is for the poisson counts, and the second is for the  
zero-inflation. The residual variance for the zero-inflated part  
cannot be estimated from the data (for the same reasons that the  
residual variance in a binary model is not identified) and neither can  
the residual covariance between zero-inflation and the poisson counts  
(you only see one of the processes in any one observation).  I  
generally place strong priors on them by fixing the residual variance  
to one and the residual covariance to zero. I achieve this by fitting  
an idh residual structure idh(trait):units which fixes the residual  
covariance to zero, and fix the 2nd diagonal element of the residual  
matrix (the zero-inflation variance) to one in the prior:  
"prior=list(R=diag(2), nu=...,  fix=2)"

4)  If you have 3 ZIP responses you have 6 "traits" to worry about.   
It is not possible to place the appropriate constraints on this  
matrix: the sub-diagonals cannot be estimated (corresponding to the  
covariance between the poisson counts and the zero-inflation within  
traits) and neither can the even elements of the diagonal (the 3 zero- 
inflation terms). You may be able to specify a prior which has a  
desirable marginal effect on the things you want to calculate, but I  
think this would be hard and a lot of work.

5) These are very parameter rich models, and I would avoid them unless  
you have a lot of individuals measured many times.

Cheers,

Jarrod



On 11 Oct 2010, at 21:06, Ned Dochtermann wrote:

> Hi all,
>
> While I'm still struggling with properly specifying priors in  
> general, I've
> run into a specific problem I can't quite muddle through. I'm trying  
> to
> estimate the covariances among several behaviors with repeated  
> measures per
> individual. I initially did so using the following structure:
>
> multi.prior<- 
> list(G=list(G1=(list(V=diag(3),nu=3))),R=list(V=diag(3),nu=3))
> #I know this assumes unit variance
>
> multi.trait.p1<-MCMCglmm(cbind(trait1,trait2,trait3)~trait,
> random=~us(trait):units, rcov=~us(trait):units,
> family=c("poisson","poisson","poisson), data=Compiled,  
> prior=multi.prior,
> verbose=FALSE)
>
> or if including fixed factors:
> multi.trait.p2<-MCMCglmm(cbind(trait1,trait2,trait3)~trait+period+day,
> random=~us(trait):units, rcov=~us(trait):units,
> family=c("poisson","poisson","poisson), data=Compiled,  
> prior=multi.prior,
> verbose=FALSE)
>
> (I actually run both a lot longer than the defaults but I've left  
> that out
> here as it isn't relevant)
>
> Both of these models seem to work well, they give reasonable answers  
> and
> satisfy a variety of diagnostics.
>
>
> However, in looking back over the data I realized the data had  
> pretty severe
> zero-inflation. Thus, I've tried to rerun the analyses using zero- 
> inflated
> models. Based on the MCMCglmm course notes I thought that the first  
> step for
> the priors would be to expand both G and R to diag(4):
>
> multi.prior.zip<- 
> list(G=list(G1=(list(V=diag(4),nu=4))),R=list(V=diag(4),nu=
> 4)) #the last 'nu' is wrong based on how ZIP model priors are  
> specified in
> the course notes
>
> multi.trait.zip<-MCMCglmm(cbind(trait1,trait2,trait3)~trait,
> random=~us(trait):units, rcov=~us(trait):units,
> family=c("zipoisson","zipoisson","zipoisson),
> data=Compiled,prior=multi.prior.zip,verbose=FALSE)
>
> This doesn't work as "V is the wrong dimension for some priorG/priorR
> elements". I also suspect it is more generally wrong due to the  
> random and
> rcov statements and issues with estimating aspects of the zero- 
> inflation and
> poisson covariances; however I'm specifically interested in  
> estimating the
> covariance matrix so I don't want to use an idh specification here.
>
> I'd like to get the covariance matrix from a ZIP model but I'm not  
> sure what
> all the errors in the above coding are nor the solutions. Basically  
> I know
> both the specification of the prior and the specification of the  
> model are
> wrong. Any help would be greatly appreciated.
>
>
> Thanks,
> Ned
>
> --
> Ned Dochtermann
> Department of Biology
> University of Nevada, Reno
>
> ned.dochtermann at gmail.com
> http://wolfweb.unr.edu/homepage/mpeacock/Dochter/
> --
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From j.hadfield at ed.ac.uk  Thu Oct 14 15:42:56 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 14 Oct 2010 14:42:56 +0100
Subject: [R-sig-ME] priors for a multi-response model (MCMCglmm)
In-Reply-To: <4cb5f4b3.2249960a.7959.ffffef83@mx.google.com>
References: <4cb36e43.4800e70a.39f9.0ae0@mx.google.com>
	<1CB6365E-135C-4967-8A98-CD01A8B74177@ed.ac.uk>
	<4cb5f4b3.2249960a.7959.ffffef83@mx.google.com>
Message-ID: <9E1C2077-561C-4C07-9D5D-DEC9CA65D984@ed.ac.uk>

Hi Ned,

The zero-truncated poisson ("ztpoisson") is implemented and as far as  
I know works fine. In terms of model syntax it will be the same as a  
normal poisson model. The zero's would have to be discarded though.

Cheers,

Jarrod




On 13 Oct 2010, at 19:04, Ned Dochtermann wrote:

> Jarrod,
> Thanks a lot for the comments.
> Regarding 1 and 2 below, sorry about that--those were actually typos  
> from
> trying to simplify the code and make it more generic. Both aspects  
> of the
> code were actually specified as you suggest; sorry for the sloppiness.
>
> 3 and 4 really look like the key issues for this analysis (besides the
> number of parameters being estimated which has been a concern  
> throughout).
> Unfortunately those points suggest that the best alternative is to  
> estimate
> the covariance matrix using a Poisson distribution, despite the known
> zero-inflation. Under the family statement in the help for MCMCglmm a
> ztpoisson distribution is mentioned however no zero-truncated  
> distribution
> is mentioned in the course notes. Is this something that was  
> previously
> available but has been removed?
>
>
>
> Thanks,
> Ned
>
> --
> Ned Dochtermann
> Department of Biology
> University of Nevada, Reno
>
> ned.dochtermann at gmail.com
> website
> --
>
>
>
> -----Original Message-----
> From: Jarrod Hadfield [mailto:j.hadfield at ed.ac.uk]
> Sent: Tuesday, October 12, 2010 2:43 AM
> To: Ned Dochtermann
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] priors for a multi-response model (MCMCglmm)
>
> Hi Ned,
>
> I think you haven't specified the model that you want to fit.
>
> 1) you have "random=~us(trait):units, rcov=~us(trait):units" which is
> fitting the same terms for the random effects and the residuals. I
> think you want something like  "random=~us(trait):individual,
> rcov=~us(trait):units"? At the moment any separation of these effects
> is coming entirely from the prior.
>
> 2) depending on what your responses are "~trait+period+day" for the
> fixed terms is probably not appropriate. You probably want to interact
> period and day with trait, so that the effect of these two predictors
> can have independent effects on each response
>
> 3) zero-inflated poisson are treated as multi-response. The first
> latent variable is for the poisson counts, and the second is for the
> zero-inflation. The residual variance for the zero-inflated part
> cannot be estimated from the data (for the same reasons that the
> residual variance in a binary model is not identified) and neither can
> the residual covariance between zero-inflation and the poisson counts
> (you only see one of the processes in any one observation).  I
> generally place strong priors on them by fixing the residual variance
> to one and the residual covariance to zero. I achieve this by fitting
> an idh residual structure idh(trait):units which fixes the residual
> covariance to zero, and fix the 2nd diagonal element of the residual
> matrix (the zero-inflation variance) to one in the prior:
> "prior=list(R=diag(2), nu=...,  fix=2)"
>
> 4)  If you have 3 ZIP responses you have 6 "traits" to worry about.
> It is not possible to place the appropriate constraints on this
> matrix: the sub-diagonals cannot be estimated (corresponding to the
> covariance between the poisson counts and the zero-inflation within
> traits) and neither can the even elements of the diagonal (the 3 zero-
> inflation terms). You may be able to specify a prior which has a
> desirable marginal effect on the things you want to calculate, but I
> think this would be hard and a lot of work.
>
> 5) These are very parameter rich models, and I would avoid them unless
> you have a lot of individuals measured many times.
>
> Cheers,
>
> Jarrod
>
>
>
> On 11 Oct 2010, at 21:06, Ned Dochtermann wrote:
>
>> Hi all,
>>
>> While I'm still struggling with properly specifying priors in
>> general, I've
>> run into a specific problem I can't quite muddle through. I'm trying
>> to
>> estimate the covariances among several behaviors with repeated
>> measures per
>> individual. I initially did so using the following structure:
>>
>> multi.prior<-
>> list(G=list(G1=(list(V=diag(3),nu=3))),R=list(V=diag(3),nu=3))
>> #I know this assumes unit variance
>>
>> multi.trait.p1<-MCMCglmm(cbind(trait1,trait2,trait3)~trait,
>> random=~us(trait):units, rcov=~us(trait):units,
>> family=c("poisson","poisson","poisson), data=Compiled,
>> prior=multi.prior,
>> verbose=FALSE)
>>
>> or if including fixed factors:
>> multi.trait.p2<-MCMCglmm(cbind(trait1,trait2,trait3)~trait+period 
>> +day,
>> random=~us(trait):units, rcov=~us(trait):units,
>> family=c("poisson","poisson","poisson), data=Compiled,
>> prior=multi.prior,
>> verbose=FALSE)
>>
>> (I actually run both a lot longer than the defaults but I've left
>> that out
>> here as it isn't relevant)
>>
>> Both of these models seem to work well, they give reasonable answers
>> and
>> satisfy a variety of diagnostics.
>>
>>
>> However, in looking back over the data I realized the data had
>> pretty severe
>> zero-inflation. Thus, I've tried to rerun the analyses using zero-
>> inflated
>> models. Based on the MCMCglmm course notes I thought that the first
>> step for
>> the priors would be to expand both G and R to diag(4):
>>
>> multi.prior.zip<-
>> list(G=list(G1=(list(V=diag(4),nu=4))),R=list(V=diag(4),nu=
>> 4)) #the last 'nu' is wrong based on how ZIP model priors are
>> specified in
>> the course notes
>>
>> multi.trait.zip<-MCMCglmm(cbind(trait1,trait2,trait3)~trait,
>> random=~us(trait):units, rcov=~us(trait):units,
>> family=c("zipoisson","zipoisson","zipoisson),
>> data=Compiled,prior=multi.prior.zip,verbose=FALSE)
>>
>> This doesn't work as "V is the wrong dimension for some priorG/priorR
>> elements". I also suspect it is more generally wrong due to the
>> random and
>> rcov statements and issues with estimating aspects of the zero-
>> inflation and
>> poisson covariances; however I'm specifically interested in
>> estimating the
>> covariance matrix so I don't want to use an idh specification here.
>>
>> I'd like to get the covariance matrix from a ZIP model but I'm not
>> sure what
>> all the errors in the above coding are nor the solutions. Basically
>> I know
>> both the specification of the prior and the specification of the
>> model are
>> wrong. Any help would be greatly appreciated.
>>
>>
>> Thanks,
>> Ned
>>
>> --
>> Ned Dochtermann
>> Department of Biology
>> University of Nevada, Reno
>>
>> ned.dochtermann at gmail.com
>> http://wolfweb.unr.edu/homepage/mpeacock/Dochter/
>> --
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From helen at lamar.colostate.edu  Tue Oct 19 04:07:20 2010
From: helen at lamar.colostate.edu (Helen Sofaer)
Date: Mon, 18 Oct 2010 20:07:20 -0600
Subject: [R-sig-ME] deriv example for nlmer
Message-ID: <3eb7b00042b8e4533612ae628c32a113@lamar.colostate.edu>


Hello modelers,
I am working on a growth rate analysis in lme4, where my goal is to test
for differences in growth rates between two populations of birds while
incorporating random effects for nests (to deal with the lack of
independence between siblings) and for each nestling (to deal with repeated
measures of individuals). 

I?d like to build a model that is parameterized slightly differently than
the SSlogis self-starting model, where K = 1/scal (this is simply due to
convention in the bird world). I can tweak the SSlogis code (given in the
help file for selfStart) and the model runs, but cannot test for
differences between populations. Since determining reasonable starting
values is not a problem, and I?d like to be able to easily adjust the
formula to incorporate additional covariates, I would like to avoid using a
self-starting function.

It is my understanding that nlmer requires a function, but not necessarily
a self-starting one. However, I can?t find an example of any code that does
this. 

I can build a very simple function that allows for differences between
populations (referred to as site, which is a 0 1 dummy variable) in both
the inflection point (xmid) and the growth rate (K). I?m trying to start
with the simplest reasonable model, so I didn?t allow for differences in
the asymptote. This function works in nls:

logisKsite = function(Age, site, Asym, xmid, K, Kdiff, middiff){
	Asym/(1 + exp((xmid+middiff*site - Age)*(K+Kdiff*site)))
	}

startsite = c(Asym = 9, xmid = 3, K = .5, Kdiff=0, middiff=0)
nls_logisKsite = nls(weight ~ logisKsite(Age, site, Asym, xmid, K, Kdiff,
middiff), growth, start = startsite)

The nlmer model I am trying to run is (for simplicity, this model includes
only a random effect of nest, only on the K parameter):
nlmer_logisKsite = nlmer(weight ~ logisKsite(Age, site, Asym, xmid, K,
Kdiff, middiff) ~ (K | Nest_ID), growth, start = startsite, verbose = TRUE)

Running this model in nlmer produces the error: gradient attribute of
evaluated model must be a numeric matrix
Dr. Bates? posted lectures note that the model must provide derivatives,
via the deriv function. I haven?t been successful getting this to work,
even in the model without site effects.

If there is an example of how to run nlmer without a self-start function,
could someone please point me to it? Advise on how to implement the deriv
function would also be very helpful. 

Thank you very much,

Helen

Helen Sofaer, PhD Candidate in Ecology, Colorado State University



From Thierry.ONKELINX at inbo.be  Tue Oct 19 10:09:33 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 19 Oct 2010 10:09:33 +0200
Subject: [R-sig-ME] deriv example for nlmer
In-Reply-To: <3eb7b00042b8e4533612ae628c32a113@lamar.colostate.edu>
References: <3eb7b00042b8e4533612ae628c32a113@lamar.colostate.edu>
Message-ID: <3DB16098F738284D8DBEB2FC3699163842662C@inboexch.inbo.be>

Dear Helen,

Won't it be easier to stick with Sslogis to run the model and then
convert scal to K for your report?

HTH,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Helen Sofaer
> Verzonden: dinsdag 19 oktober 2010 4:07
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] deriv example for nlmer
> 
> 
> Hello modelers,
> I am working on a growth rate analysis in lme4, where my goal 
> is to test for differences in growth rates between two 
> populations of birds while incorporating random effects for 
> nests (to deal with the lack of independence between 
> siblings) and for each nestling (to deal with repeated 
> measures of individuals). 
> 
> I'd like to build a model that is parameterized slightly 
> differently than the SSlogis self-starting model, where K = 
> 1/scal (this is simply due to convention in the bird world). 
> I can tweak the SSlogis code (given in the help file for 
> selfStart) and the model runs, but cannot test for 
> differences between populations. Since determining reasonable 
> starting values is not a problem, and I'd like to be able to 
> easily adjust the formula to incorporate additional 
> covariates, I would like to avoid using a self-starting function.
> 
> It is my understanding that nlmer requires a function, but 
> not necessarily a self-starting one. However, I can't find an 
> example of any code that does this. 
> 
> I can build a very simple function that allows for 
> differences between populations (referred to as site, which 
> is a 0 1 dummy variable) in both the inflection point (xmid) 
> and the growth rate (K). I'm trying to start with the 
> simplest reasonable model, so I didn't allow for differences 
> in the asymptote. This function works in nls:
> 
> logisKsite = function(Age, site, Asym, xmid, K, Kdiff, middiff){
> 	Asym/(1 + exp((xmid+middiff*site - Age)*(K+Kdiff*site)))
> 	}
> 
> startsite = c(Asym = 9, xmid = 3, K = .5, Kdiff=0, middiff=0) 
> nls_logisKsite = nls(weight ~ logisKsite(Age, site, Asym, 
> xmid, K, Kdiff, middiff), growth, start = startsite)
> 
> The nlmer model I am trying to run is (for simplicity, this 
> model includes only a random effect of nest, only on the K parameter):
> nlmer_logisKsite = nlmer(weight ~ logisKsite(Age, site, Asym, 
> xmid, K, Kdiff, middiff) ~ (K | Nest_ID), growth, start = 
> startsite, verbose = TRUE)
> 
> Running this model in nlmer produces the error: gradient 
> attribute of evaluated model must be a numeric matrix Dr. 
> Bates' posted lectures note that the model must provide 
> derivatives, via the deriv function. I haven't been 
> successful getting this to work, even in the model without 
> site effects.
> 
> If there is an example of how to run nlmer without a 
> self-start function, could someone please point me to it? 
> Advise on how to implement the deriv function would also be 
> very helpful. 
> 
> Thank you very much,
> 
> Helen
> 
> Helen Sofaer, PhD Candidate in Ecology, Colorado State University
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 



From friedericksen.hope at gmail.com  Tue Oct 19 09:12:59 2010
From: friedericksen.hope at gmail.com (Friedericksen Hope)
Date: Tue, 19 Oct 2010 09:12:59 +0200
Subject: [R-sig-ME] Profile function does not work with objekt of class "mer"
Message-ID: <i9jgdr$fej$1@dough.gmane.org>

Hello,

I am unable to get profile zeta plots with the profile function. I am aware of the discussion of this issue earlier 
(http://markmail.org/message/gkfiwcj4ar4vk64e#query:Error%20in%20UseMethod%28profile%29%20%3A%20no%20applicable%20method%20for%20%27profile%27%20applied%20to%20an%20object%20of%20class%20mer%20lme4+page:1+mid:weai7ngdghudkbm5+state:results). 
Donald Bates stated there that with the useR! conference, there will be a solution. Unfortunately the commands introduced in the slides of his tutorial still give me the error.

What is the correct syntax for the profile function?

The following does not work:

>> fm2 <- lmer(diameter~1 + (1|plate) + (1|sample),Penicillin)
>> profile(fm2)
> Error in UseMethod("profile") :
>   no applicable method for 'profile' applied to an object of class "mer"

Session informations:
> R version 2.11.1 (2010-05-31)
> x86_64-pc-linux-gnu
>
> locale:
>  [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C              LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
>  [5] LC_MONETARY=C             LC_MESSAGES=en_US.utf8    LC_PAPER=en_US.utf8       LC_NAME=C
>  [9] LC_ADDRESS=C              LC_TELEPHONE=C            LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] tools     stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] lme4_0.999375-35   Matrix_0.999375-44 lattice_0.19-13
>
> loaded via a namespace (and not attached):
> [1] grid_2.11.1   nlme_3.1-97   stats4_2.11.1

Thank you in advance!

Best,
Friedericksen



From bates at stat.wisc.edu  Tue Oct 19 16:16:59 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 19 Oct 2010 09:16:59 -0500
Subject: [R-sig-ME] Profile function does not work with objekt of class
	"mer"
In-Reply-To: <i9jgdr$fej$1@dough.gmane.org>
References: <i9jgdr$fej$1@dough.gmane.org>
Message-ID: <AANLkTi=j9u1UHYX86mV2UoE7YBKtFsZzBW4kFO1JQBsc@mail.gmail.com>

On Tue, Oct 19, 2010 at 2:12 AM, Friedericksen Hope
<friedericksen.hope at gmail.com> wrote:
> Hello,

> I am unable to get profile zeta plots with the profile function. I am aware
> of the discussion of this issue earlier
> (http://markmail.org/message/gkfiwcj4ar4vk64e#query:Error%20in%20UseMethod%28profile%29%20%3A%20no%20applicable%20method%20for%20%27profile%27%20applied%20to%20an%20object%20of%20class%20mer%20lme4+page:1+mid:weai7ngdghudkbm5+state:results).
> Donald Bates stated there that with the useR! conference, there will be a
> solution. Unfortunately the commands introduced in the slides of his
> tutorial still give me the error.

> What is the correct syntax for the profile function?

At present only the lme4a package provides profiling of the deviance
function.  I would direct you to the R-forge repository except that
the Windows and Mac OS X builds on that repository are not completing.
 About the best I can offer is to have a binary package built on the
win-builder system and stick it on the web site somewhere.  I don't
use either Windows or Mac OS X myself so I need to rely on other
builders.

Martin and I had planned to release lme4a as lme4 some time ago but
both of us have very heavy teaching schedules this semester leaving us
with little time to devote to lme4.

> The following does not work:
>
>>> fm2 <- lmer(diameter~1 + (1|plate) + (1|sample),Penicillin)
>>> profile(fm2)
>>
>> Error in UseMethod("profile") :
>> ?no applicable method for 'profile' applied to an object of class "mer"
>
> Session informations:
>>
>> R version 2.11.1 (2010-05-31)
>> x86_64-pc-linux-gnu
>>
>> locale:
>> ?[1] LC_CTYPE=en_US.utf8 ? ? ? LC_NUMERIC=C
>> ?LC_TIME=en_US.utf8 ? ? ? ?LC_COLLATE=en_US.utf8
>> ?[5] LC_MONETARY=C ? ? ? ? ? ? LC_MESSAGES=en_US.utf8
>> ?LC_PAPER=en_US.utf8 ? ? ? LC_NAME=C
>> ?[9] LC_ADDRESS=C ? ? ? ? ? ? ?LC_TELEPHONE=C
>> ?LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] tools ? ? stats ? ? graphics ?grDevices utils ? ? datasets ?methods
>> base
>>
>> other attached packages:
>> [1] lme4_0.999375-35 ? Matrix_0.999375-44 lattice_0.19-13
>>
>> loaded via a namespace (and not attached):
>> [1] grid_2.11.1 ? nlme_3.1-97 ? stats4_2.11.1
>
> Thank you in advance!
>
> Best,
> Friedericksen
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From helen at lamar.colostate.edu  Tue Oct 19 16:25:48 2010
From: helen at lamar.colostate.edu (Helen Sofaer)
Date: Tue, 19 Oct 2010 08:25:48 -0600
Subject: [R-sig-ME] deriv example for nlmer
In-Reply-To: <3DB16098F738284D8DBEB2FC3699163842662C@inboexch.inbo.be>
References: <3eb7b00042b8e4533612ae628c32a113@lamar.colostate.edu>
	<3DB16098F738284D8DBEB2FC3699163842662C@inboexch.inbo.be>
Message-ID: <6e7e76da75d3bdc59617c8bffd7b6d0c@lamar.colostate.edu>


Hi Thierry,
My main goal is to test for a difference between populations, which I
can't do with SSlogis.
Check out the code for my function to see the model I'm trying to run.

Thanks,
Helen


On Tue, 19 Oct 2010 10:09:33 +0200, "ONKELINX, Thierry"
<Thierry.ONKELINX at inbo.be> wrote:
> Dear Helen,
> 
> Won't it be easier to stick with Sslogis to run the model and then
> convert scal to K for your report?
> 
> HTH,
> 
> Thierry
> 
> ------------------------------------------------------------------------
> ----
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek
> team Biometrie & Kwaliteitszorg
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
> 
> Research Institute for Nature and Forest
> team Biometrics & Quality Assurance
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
> 
> tel. + 32 54/436 185
> Thierry.Onkelinx at inbo.be
> www.inbo.be
> 
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to
> say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
> 
> The plural of anecdote is not data.
> ~ Roger Brinner
> 
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of
> data.
> ~ John Tukey
>   
> 
>> -----Oorspronkelijk bericht-----
>> Van: r-sig-mixed-models-bounces at r-project.org 
>> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Helen Sofaer
>> Verzonden: dinsdag 19 oktober 2010 4:07
>> Aan: r-sig-mixed-models at r-project.org
>> Onderwerp: [R-sig-ME] deriv example for nlmer
>> 
>> 
>> Hello modelers,
>> I am working on a growth rate analysis in lme4, where my goal 
>> is to test for differences in growth rates between two 
>> populations of birds while incorporating random effects for 
>> nests (to deal with the lack of independence between 
>> siblings) and for each nestling (to deal with repeated 
>> measures of individuals). 
>> 
>> I'd like to build a model that is parameterized slightly 
>> differently than the SSlogis self-starting model, where K = 
>> 1/scal (this is simply due to convention in the bird world). 
>> I can tweak the SSlogis code (given in the help file for 
>> selfStart) and the model runs, but cannot test for 
>> differences between populations. Since determining reasonable 
>> starting values is not a problem, and I'd like to be able to 
>> easily adjust the formula to incorporate additional 
>> covariates, I would like to avoid using a self-starting function.
>> 
>> It is my understanding that nlmer requires a function, but 
>> not necessarily a self-starting one. However, I can't find an 
>> example of any code that does this. 
>> 
>> I can build a very simple function that allows for 
>> differences between populations (referred to as site, which 
>> is a 0 1 dummy variable) in both the inflection point (xmid) 
>> and the growth rate (K). I'm trying to start with the 
>> simplest reasonable model, so I didn't allow for differences 
>> in the asymptote. This function works in nls:
>> 
>> logisKsite = function(Age, site, Asym, xmid, K, Kdiff, middiff){
>> 	Asym/(1 + exp((xmid+middiff*site - Age)*(K+Kdiff*site)))
>> 	}
>> 
>> startsite = c(Asym = 9, xmid = 3, K = .5, Kdiff=0, middiff=0) 
>> nls_logisKsite = nls(weight ~ logisKsite(Age, site, Asym, 
>> xmid, K, Kdiff, middiff), growth, start = startsite)
>> 
>> The nlmer model I am trying to run is (for simplicity, this 
>> model includes only a random effect of nest, only on the K parameter):
>> nlmer_logisKsite = nlmer(weight ~ logisKsite(Age, site, Asym, 
>> xmid, K, Kdiff, middiff) ~ (K | Nest_ID), growth, start = 
>> startsite, verbose = TRUE)
>> 
>> Running this model in nlmer produces the error: gradient 
>> attribute of evaluated model must be a numeric matrix Dr. 
>> Bates' posted lectures note that the model must provide 
>> derivatives, via the deriv function. I haven't been 
>> successful getting this to work, even in the model without 
>> site effects.
>> 
>> If there is an example of how to run nlmer without a 
>> self-start function, could someone please point me to it? 
>> Advise on how to implement the deriv function would also be 
>> very helpful. 
>> 
>> Thank you very much,
>> 
>> Helen
>> 
>> Helen Sofaer, PhD Candidate in Ecology, Colorado State University
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>

-- 
Helen Sofaer
PhD Candidate
Colorado State University
Graduate Degree Program in Ecology



From desja004 at umn.edu  Tue Oct 19 18:31:18 2010
From: desja004 at umn.edu (Christopher Desjardins)
Date: Tue, 19 Oct 2010 11:31:18 -0500
Subject: [R-sig-ME] ranef() on Mac OS X
Message-ID: <AANLkTin=ksZK=5eC30fHiaY9OH-Y3ExaU=5yktc0DB9O@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101019/646b0e11/attachment.pl>

From bates at stat.wisc.edu  Tue Oct 19 18:44:58 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 19 Oct 2010 11:44:58 -0500
Subject: [R-sig-ME] ranef() on Mac OS X
In-Reply-To: <AANLkTin=ksZK=5eC30fHiaY9OH-Y3ExaU=5yktc0DB9O@mail.gmail.com>
References: <AANLkTin=ksZK=5eC30fHiaY9OH-Y3ExaU=5yktc0DB9O@mail.gmail.com>
Message-ID: <AANLkTimOmPM0cdw6zLFjrSRrF_M_GgT9d3Q4RYM0F8WA@mail.gmail.com>

Notice that you have different versions of the lme4 package on Ubuntu
and on the Mac.  For some reason the lme4 package is failing a test on
Mac OS X only and we haven't been able to diagnose why the -35 version
fails there.  Also, we haven't been able to reproduce this on other
operating systems and we can't decide why it should fail on Mac OS X
unless it is an obscure memory issue.  As neither Martin nor I use Mac
OS X we aren't able to debug the issue.  Other folks have looked at it
but all they can say is that it is failing, no idea why.  We even
tried to bypass the test on the Mac but that doesn't seem to have
worked either.

I'm open to suggestions from the list on what can be done about lme4
and Mac OS X.  If you look at the test results for the package on
CRAN, e.g.

http://cran.us.r-project.org/web/checks/check_results_lme4.html

you will see that Mac OS X is the only system on which there is a
problem and the test on which it fails doesn't make sense for it to
fail.  The only difference between the two models being compared is
that they were generated from slightly different formulas but the
models are identical once the formula is parsed.

On Tue, Oct 19, 2010 at 11:31 AM, Christopher Desjardins
<desja004 at umn.edu> wrote:
> I am unable to use the ranef() function on a lmer function on a Mac. I get
> the following error:
>
>> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
>> ranef(fm1)
> Error in UseMethod("ranef") :
> ?no applicable method for 'ranef' applied to an object of class "mer"
>> sessionInfo()
> R version 2.11.1 (2010-05-31)
> i386-apple-darwin9.8.0
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
> other attached packages:
> [1] plyr_1.2.1 ? ? ? ? nlme_3.1-96 ? ? ? ?lme4_0.999375-34
> Matrix_0.999375-39 lattice_0.18-8 ? ? foreign_0.8-40
>
> loaded via a namespace (and not attached):
> [1] grid_2.11.1 ? stats4_2.11.1 tools_2.11.1
>
> This works as expected on Ubuntu 10.10 64 bit (see below). I built the lme4
> package from source on the Mac and I know that lme4 has had some issues on
> Mac for a while (i.e. it hasn't been available as a binary for some time). I
> just wanted to post this here to see if this was either a new bug, something
> already documented, or something that I've overlooked. Googling 'ranef lme4
> Mac' brought me to this thread
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q3/004091.html ... but
> the author was able to use the ranef() function.
>
> Thanks,
> Chris
>
>
> #################
> ### From Linux ###
> #################
>> fm1 <- lmer(Reaction ~ Days + (1|Subject), sleepstudy)
>> ranef(fm1)
> $Subject
> ? ?(Intercept)
> 308 ? 40.787403
> 309 ?-77.856603
> 310 ?-63.114282
> 330 ? ?4.406841
> 331 ? 10.217114
> 332 ? ?8.221982
> 333 ? 16.501988
> 334 ? -2.997253
> 335 ?-45.286227
> 337 ? 72.189222
> 349 ?-21.198168
> 350 ? 14.112641
> 351 ? -7.862933
> 352 ? 36.381719
> 369 ? ?7.037018
> 370 ? -6.363279
> 371 ? -3.294571
> 372 ? 18.117387
>> sessionInfo()
> R version 2.11.1 (2010-05-31)
> x86_64-pc-linux-gnu
>
> locale:
> ?[1] LC_CTYPE=en_US.utf8 ? ? ? LC_NUMERIC=C
> ?[3] LC_TIME=en_US.utf8 ? ? ? ?LC_COLLATE=en_US.utf8
> ?[5] LC_MONETARY=C ? ? ? ? ? ? LC_MESSAGES=en_US.utf8
> ?[7] LC_PAPER=en_US.utf8 ? ? ? LC_NAME=C
> ?[9] LC_ADDRESS=C ? ? ? ? ? ? ?LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
> other attached packages:
> [1] lme4_0.999375-35 ? Matrix_0.999375-40 lattice_0.18-8
>
> loaded via a namespace (and not attached):
> [1] grid_2.11.1 ? nlme_3.1-96 ? stats4_2.11.1 tcltk_2.11.1 ?tools_2.11.1
>
>
>
>
> --
> Christopher David Desjardins
> Ph.D. student, Quantitative Methods in Education
> M.S. student, Statistics
> University of Minnesota
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From m.fairbrother at bristol.ac.uk  Tue Oct 19 18:56:30 2010
From: m.fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Tue, 19 Oct 2010 17:56:30 +0100
Subject: [R-sig-ME] ranef() on Mac OS X
In-Reply-To: <mailman.5774.1287506712.4267.r-sig-mixed-models@r-project.org>
References: <mailman.5774.1287506712.4267.r-sig-mixed-models@r-project.org>
Message-ID: <D0E9AE9F-78D0-4E89-ACB3-CF5ACF73DD88@bristol.ac.uk>

Dear Chris,

I've had problems similar to this before, and it's often due to having nlme loaded along with lme4. I use a Mac. I see from your sessionInfo() that you had nlme loaded on Mac, but not Ubuntu. I'd trying detaching:

> ranef(fm1)
Error in UseMethod("ranef") : 
  no applicable method for 'ranef' applied to an object of class "mer"
> detach(package:nlme)
> ranef(fm1)
$Subject
    (Intercept)        Days
308   2.2571870   9.1992523
309 -40.3984020  -8.6211497

etc.

Hope that works.

- Malcolm


Dr Malcolm Fairbrother
Lecturer
School of Geographical Sciences
University of Bristol


> Message: 4
> Date: Tue, 19 Oct 2010 11:31:18 -0500
> From: Christopher Desjardins <desja004 at umn.edu>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] ranef() on Mac OS X
> Message-ID:
> 	<AANLkTin=ksZK=5eC30fHiaY9OH-Y3ExaU=5yktc0DB9O at mail.gmail.com>
> Content-Type: text/plain
> 
> I am unable to use the ranef() function on a lmer function on a Mac. I get
> the following error:
> 
>> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
>> ranef(fm1)
> Error in UseMethod("ranef") :
>  no applicable method for 'ranef' applied to an object of class "mer"
>> sessionInfo()
> R version 2.11.1 (2010-05-31)
> i386-apple-darwin9.8.0
> 
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] plyr_1.2.1         nlme_3.1-96        lme4_0.999375-34
> Matrix_0.999375-39 lattice_0.18-8     foreign_0.8-40
> 
> loaded via a namespace (and not attached):
> [1] grid_2.11.1   stats4_2.11.1 tools_2.11.1
> 
> This works as expected on Ubuntu 10.10 64 bit (see below). I built the lme4
> package from source on the Mac and I know that lme4 has had some issues on
> Mac for a while (i.e. it hasn't been available as a binary for some time). I
> just wanted to post this here to see if this was either a new bug, something
> already documented, or something that I've overlooked. Googling 'ranef lme4
> Mac' brought me to this thread
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q3/004091.html ... but
> the author was able to use the ranef() function.
> 
> Thanks,
> Chris
> 
> 
> #################
> ### From Linux ###
> #################
>> fm1 <- lmer(Reaction ~ Days + (1|Subject), sleepstudy)
>> ranef(fm1)
> $Subject
>    (Intercept)
> 308   40.787403
> 309  -77.856603
> 310  -63.114282
> 330    4.406841
> 331   10.217114
> 332    8.221982
> 333   16.501988
> 334   -2.997253
> 335  -45.286227
> 337   72.189222
> 349  -21.198168
> 350   14.112641
> 351   -7.862933
> 352   36.381719
> 369    7.037018
> 370   -6.363279
> 371   -3.294571
> 372   18.117387
>> sessionInfo()
> R version 2.11.1 (2010-05-31)
> x86_64-pc-linux-gnu
> 
> locale:
> [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
> [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
> [5] LC_MONETARY=C             LC_MESSAGES=en_US.utf8
> [7] LC_PAPER=en_US.utf8       LC_NAME=C
> [9] LC_ADDRESS=C              LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] lme4_0.999375-35   Matrix_0.999375-40 lattice_0.18-8
> 
> loaded via a namespace (and not attached):
> [1] grid_2.11.1   nlme_3.1-96   stats4_2.11.1 tcltk_2.11.1  tools_2.11.1
> 
> 
> 
> 
> -- 
> Christopher David Desjardins
> Ph.D. student, Quantitative Methods in Education
> M.S. student, Statistics
> University of Minnesota
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------
> 
> Message: 5
> Date: Tue, 19 Oct 2010 11:44:58 -0500
> From: Douglas Bates <bates at stat.wisc.edu>
> To: Christopher Desjardins <desja004 at umn.edu>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] ranef() on Mac OS X
> Message-ID:
> 	<AANLkTimOmPM0cdw6zLFjrSRrF_M_GgT9d3Q4RYM0F8WA at mail.gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1
> 
> Notice that you have different versions of the lme4 package on Ubuntu
> and on the Mac.  For some reason the lme4 package is failing a test on
> Mac OS X only and we haven't been able to diagnose why the -35 version
> fails there.  Also, we haven't been able to reproduce this on other
> operating systems and we can't decide why it should fail on Mac OS X
> unless it is an obscure memory issue.  As neither Martin nor I use Mac
> OS X we aren't able to debug the issue.  Other folks have looked at it
> but all they can say is that it is failing, no idea why.  We even
> tried to bypass the test on the Mac but that doesn't seem to have
> worked either.
> 
> I'm open to suggestions from the list on what can be done about lme4
> and Mac OS X.  If you look at the test results for the package on
> CRAN, e.g.
> 
> http://cran.us.r-project.org/web/checks/check_results_lme4.html
> 
> you will see that Mac OS X is the only system on which there is a
> problem and the test on which it fails doesn't make sense for it to
> fail.  The only difference between the two models being compared is
> that they were generated from slightly different formulas but the
> models are identical once the formula is parsed.
> 
> On Tue, Oct 19, 2010 at 11:31 AM, Christopher Desjardins
> <desja004 at umn.edu> wrote:
>> I am unable to use the ranef() function on a lmer function on a Mac. I get
>> the following error:
>> 
>>> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
>>> ranef(fm1)
>> Error in UseMethod("ranef") :
>> ?no applicable method for 'ranef' applied to an object of class "mer"
>>> sessionInfo()
>> R version 2.11.1 (2010-05-31)
>> i386-apple-darwin9.8.0
>> 
>> locale:
>> [1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
>> 
>> attached base packages:
>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>> 
>> other attached packages:
>> [1] plyr_1.2.1 ? ? ? ? nlme_3.1-96 ? ? ? ?lme4_0.999375-34
>> Matrix_0.999375-39 lattice_0.18-8 ? ? foreign_0.8-40
>> 
>> loaded via a namespace (and not attached):
>> [1] grid_2.11.1 ? stats4_2.11.1 tools_2.11.1
>> 
>> This works as expected on Ubuntu 10.10 64 bit (see below). I built the lme4
>> package from source on the Mac and I know that lme4 has had some issues on
>> Mac for a while (i.e. it hasn't been available as a binary for some time). I
>> just wanted to post this here to see if this was either a new bug, something
>> already documented, or something that I've overlooked. Googling 'ranef lme4
>> Mac' brought me to this thread
>> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q3/004091.html ... but
>> the author was able to use the ranef() function.
>> 
>> Thanks,
>> Chris
>> 
>> 
>> #################
>> ### From Linux ###
>> #################
>>> fm1 <- lmer(Reaction ~ Days + (1|Subject), sleepstudy)
>>> ranef(fm1)
>> $Subject
>> ? ?(Intercept)
>> 308 ? 40.787403
>> 309 ?-77.856603
>> 310 ?-63.114282
>> 330 ? ?4.406841
>> 331 ? 10.217114
>> 332 ? ?8.221982
>> 333 ? 16.501988
>> 334 ? -2.997253
>> 335 ?-45.286227
>> 337 ? 72.189222
>> 349 ?-21.198168
>> 350 ? 14.112641
>> 351 ? -7.862933
>> 352 ? 36.381719
>> 369 ? ?7.037018
>> 370 ? -6.363279
>> 371 ? -3.294571
>> 372 ? 18.117387
>>> sessionInfo()
>> R version 2.11.1 (2010-05-31)
>> x86_64-pc-linux-gnu
>> 
>> locale:
>> ?[1] LC_CTYPE=en_US.utf8 ? ? ? LC_NUMERIC=C
>> ?[3] LC_TIME=en_US.utf8 ? ? ? ?LC_COLLATE=en_US.utf8
>> ?[5] LC_MONETARY=C ? ? ? ? ? ? LC_MESSAGES=en_US.utf8
>> ?[7] LC_PAPER=en_US.utf8 ? ? ? LC_NAME=C
>> ?[9] LC_ADDRESS=C ? ? ? ? ? ? ?LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C
>> 
>> attached base packages:
>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>> 
>> other attached packages:
>> [1] lme4_0.999375-35 ? Matrix_0.999375-40 lattice_0.18-8
>> 
>> loaded via a namespace (and not attached):
>> [1] grid_2.11.1 ? nlme_3.1-96 ? stats4_2.11.1 tcltk_2.11.1 ?tools_2.11.1
>> 
>> 
>> 
>> 
>> --
>> Christopher David Desjardins
>> Ph.D. student, Quantitative Methods in Education
>> M.S. student, Statistics
>> University of Minnesota



From desja004 at umn.edu  Tue Oct 19 19:10:45 2010
From: desja004 at umn.edu (Christopher Desjardins)
Date: Tue, 19 Oct 2010 12:10:45 -0500
Subject: [R-sig-ME] ranef() on Mac OS X
In-Reply-To: <D0E9AE9F-78D0-4E89-ACB3-CF5ACF73DD88@bristol.ac.uk>
References: <mailman.5774.1287506712.4267.r-sig-mixed-models@r-project.org>
	<D0E9AE9F-78D0-4E89-ACB3-CF5ACF73DD88@bristol.ac.uk>
Message-ID: <AANLkTi=g8w=GCd+3aKH266Rbd3TbkXpjwaZVM7gNDfeE@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101019/c6b889f4/attachment.pl>

From Manuel.A.Morales at williams.edu  Tue Oct 19 19:11:47 2010
From: Manuel.A.Morales at williams.edu (Manuel Morales)
Date: Tue, 19 Oct 2010 13:11:47 -0400
Subject: [R-sig-ME] deriv example for nlmer
In-Reply-To: <6e7e76da75d3bdc59617c8bffd7b6d0c@lamar.colostate.edu>
References: <3eb7b00042b8e4533612ae628c32a113@lamar.colostate.edu>
	<3DB16098F738284D8DBEB2FC3699163842662C@inboexch.inbo.be>
	<6e7e76da75d3bdc59617c8bffd7b6d0c@lamar.colostate.edu>
Message-ID: <1287508307.29808.3.camel@localhost.localdomain>

How about:

grModel <- function(Age, site, Asym, xmid, K, Kdiff, middiff) {
  Asym/(1 + exp((xmid+middiff*site - Age)*(K+Kdiff*site)))
}

grModg <- deriv(body(grModel),
                namevec = c("Asym", "xmid", "K", "Kdiff", "middiff"),
                function.arg=grModel)

startsite <- c(Asym=9, xmid=3, K=.5, Kdiff=0, middiff=0)


nlmer(weight ~ grModg(Age,site,Asym,xmid,K,Kdiff,middiff) ~ (K|Nest_ID),
                      data=growth, start=startsite, verbose = TRUE)

On Tue, 2010-10-19 at 08:25 -0600, Helen Sofaer wrote:
> Hi Thierry,
> My main goal is to test for a difference between populations, which I
> can't do with SSlogis.
> Check out the code for my function to see the model I'm trying to run.
> 
> Thanks,
> Helen
> 
> 
> On Tue, 19 Oct 2010 10:09:33 +0200, "ONKELINX, Thierry"
> <Thierry.ONKELINX at inbo.be> wrote:
> > Dear Helen,
> > 
> > Won't it be easier to stick with Sslogis to run the model and then
> > convert scal to K for your report?
> > 
> > HTH,
> > 
> > Thierry
> > 
> > ------------------------------------------------------------------------
> > ----
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek
> > team Biometrie & Kwaliteitszorg
> > Gaverstraat 4
> > 9500 Geraardsbergen
> > Belgium
> > 
> > Research Institute for Nature and Forest
> > team Biometrics & Quality Assurance
> > Gaverstraat 4
> > 9500 Geraardsbergen
> > Belgium
> > 
> > tel. + 32 54/436 185
> > Thierry.Onkelinx at inbo.be
> > www.inbo.be
> > 
> > To call in the statistician after the experiment is done may be no more
> > than asking him to perform a post-mortem examination: he may be able to
> > say what the experiment died of.
> > ~ Sir Ronald Aylmer Fisher
> > 
> > The plural of anecdote is not data.
> > ~ Roger Brinner
> > 
> > The combination of some data and an aching desire for an answer does not
> > ensure that a reasonable answer can be extracted from a given body of
> > data.
> > ~ John Tukey
> >   
> > 
> >> -----Oorspronkelijk bericht-----
> >> Van: r-sig-mixed-models-bounces at r-project.org 
> >> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Helen Sofaer
> >> Verzonden: dinsdag 19 oktober 2010 4:07
> >> Aan: r-sig-mixed-models at r-project.org
> >> Onderwerp: [R-sig-ME] deriv example for nlmer
> >> 
> >> 
> >> Hello modelers,
> >> I am working on a growth rate analysis in lme4, where my goal 
> >> is to test for differences in growth rates between two 
> >> populations of birds while incorporating random effects for 
> >> nests (to deal with the lack of independence between 
> >> siblings) and for each nestling (to deal with repeated 
> >> measures of individuals). 
> >> 
> >> I'd like to build a model that is parameterized slightly 
> >> differently than the SSlogis self-starting model, where K = 
> >> 1/scal (this is simply due to convention in the bird world). 
> >> I can tweak the SSlogis code (given in the help file for 
> >> selfStart) and the model runs, but cannot test for 
> >> differences between populations. Since determining reasonable 
> >> starting values is not a problem, and I'd like to be able to 
> >> easily adjust the formula to incorporate additional 
> >> covariates, I would like to avoid using a self-starting function.
> >> 
> >> It is my understanding that nlmer requires a function, but 
> >> not necessarily a self-starting one. However, I can't find an 
> >> example of any code that does this. 
> >> 
> >> I can build a very simple function that allows for 
> >> differences between populations (referred to as site, which 
> >> is a 0 1 dummy variable) in both the inflection point (xmid) 
> >> and the growth rate (K). I'm trying to start with the 
> >> simplest reasonable model, so I didn't allow for differences 
> >> in the asymptote. This function works in nls:
> >> 
> >> logisKsite = function(Age, site, Asym, xmid, K, Kdiff, middiff){
> >> 	Asym/(1 + exp((xmid+middiff*site - Age)*(K+Kdiff*site)))
> >> 	}
> >> 
> >> startsite = c(Asym = 9, xmid = 3, K = .5, Kdiff=0, middiff=0) 
> >> nls_logisKsite = nls(weight ~ logisKsite(Age, site, Asym, 
> >> xmid, K, Kdiff, middiff), growth, start = startsite)
> >> 
> >> The nlmer model I am trying to run is (for simplicity, this 
> >> model includes only a random effect of nest, only on the K parameter):
> >> nlmer_logisKsite = nlmer(weight ~ logisKsite(Age, site, Asym, 
> >> xmid, K, Kdiff, middiff) ~ (K | Nest_ID), growth, start = 
> >> startsite, verbose = TRUE)
> >> 
> >> Running this model in nlmer produces the error: gradient 
> >> attribute of evaluated model must be a numeric matrix Dr. 
> >> Bates' posted lectures note that the model must provide 
> >> derivatives, via the deriv function. I haven't been 
> >> successful getting this to work, even in the model without 
> >> site effects.
> >> 
> >> If there is an example of how to run nlmer without a 
> >> self-start function, could someone please point me to it? 
> >> Advise on how to implement the deriv function would also be 
> >> very helpful. 
> >> 
> >> Thank you very much,
> >> 
> >> Helen
> >> 
> >> Helen Sofaer, PhD Candidate in Ecology, Colorado State University
> >> 
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list 
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> 

-- 
http://mutualism.williams.edu



From helen at lamar.colostate.edu  Tue Oct 19 19:43:12 2010
From: helen at lamar.colostate.edu (Helen Sofaer)
Date: Tue, 19 Oct 2010 11:43:12 -0600
Subject: [R-sig-ME] deriv example for nlmer
In-Reply-To: <1287508307.29808.3.camel@localhost.localdomain>
References: <3eb7b00042b8e4533612ae628c32a113@lamar.colostate.edu>
	<3DB16098F738284D8DBEB2FC3699163842662C@inboexch.inbo.be>
	<6e7e76da75d3bdc59617c8bffd7b6d0c@lamar.colostate.edu>
	<1287508307.29808.3.camel@localhost.localdomain>
Message-ID: <313b53a87acb5f6dfc8ba8f2b5b64d94@lamar.colostate.edu>


Thanks!!

With your deriv code I got the error: Function '`{`' is not in the
derivatives table
Googling the error led me to a suggestion that I add [[2]] to the deriv
function like this:

logisSiteDeriv = deriv(body(logisKsite)[[2]], namevec = c("Asym", "xmid",
"K", "Kdiff", "middiff"), function.arg=logisKsite)

And that function runs in nlmer! So, I've very happy, except I am curious
as to what the [[2]] does...

Thanks again for your quick response.
Helen

On Tue, 19 Oct 2010 13:11:47 -0400, Manuel Morales
<Manuel.A.Morales at williams.edu> wrote:
> How about:
> 
> grModel <- function(Age, site, Asym, xmid, K, Kdiff, middiff) {
>   Asym/(1 + exp((xmid+middiff*site - Age)*(K+Kdiff*site)))
> }
> 
> grModg <- deriv(body(grModel),
>                 namevec = c("Asym", "xmid", "K", "Kdiff", "middiff"),
>                 function.arg=grModel)
> 
> startsite <- c(Asym=9, xmid=3, K=.5, Kdiff=0, middiff=0)
> 
> 
> nlmer(weight ~ grModg(Age,site,Asym,xmid,K,Kdiff,middiff) ~ (K|Nest_ID),
>                       data=growth, start=startsite, verbose = TRUE)
> 
> On Tue, 2010-10-19 at 08:25 -0600, Helen Sofaer wrote:
>> Hi Thierry,
>> My main goal is to test for a difference between populations, which I
>> can't do with SSlogis.
>> Check out the code for my function to see the model I'm trying to run.
>> 
>> Thanks,
>> Helen
>> 
>> 
>> On Tue, 19 Oct 2010 10:09:33 +0200, "ONKELINX, Thierry"
>> <Thierry.ONKELINX at inbo.be> wrote:
>> > Dear Helen,
>> > 
>> > Won't it be easier to stick with Sslogis to run the model and then
>> > convert scal to K for your report?
>> > 
>> > HTH,
>> > 
>> > Thierry
>> > 
>> >
------------------------------------------------------------------------
>> > ----
>> > ir. Thierry Onkelinx
>> > Instituut voor natuur- en bosonderzoek
>> > team Biometrie & Kwaliteitszorg
>> > Gaverstraat 4
>> > 9500 Geraardsbergen
>> > Belgium
>> > 
>> > Research Institute for Nature and Forest
>> > team Biometrics & Quality Assurance
>> > Gaverstraat 4
>> > 9500 Geraardsbergen
>> > Belgium
>> > 
>> > tel. + 32 54/436 185
>> > Thierry.Onkelinx at inbo.be
>> > www.inbo.be
>> > 
>> > To call in the statistician after the experiment is done may be no
more
>> > than asking him to perform a post-mortem examination: he may be able
to
>> > say what the experiment died of.
>> > ~ Sir Ronald Aylmer Fisher
>> > 
>> > The plural of anecdote is not data.
>> > ~ Roger Brinner
>> > 
>> > The combination of some data and an aching desire for an answer does
>> > not
>> > ensure that a reasonable answer can be extracted from a given body of
>> > data.
>> > ~ John Tukey
>> >   
>> > 
>> >> -----Oorspronkelijk bericht-----
>> >> Van: r-sig-mixed-models-bounces at r-project.org 
>> >> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Helen
Sofaer
>> >> Verzonden: dinsdag 19 oktober 2010 4:07
>> >> Aan: r-sig-mixed-models at r-project.org
>> >> Onderwerp: [R-sig-ME] deriv example for nlmer
>> >> 
>> >> 
>> >> Hello modelers,
>> >> I am working on a growth rate analysis in lme4, where my goal 
>> >> is to test for differences in growth rates between two 
>> >> populations of birds while incorporating random effects for 
>> >> nests (to deal with the lack of independence between 
>> >> siblings) and for each nestling (to deal with repeated 
>> >> measures of individuals). 
>> >> 
>> >> I'd like to build a model that is parameterized slightly 
>> >> differently than the SSlogis self-starting model, where K = 
>> >> 1/scal (this is simply due to convention in the bird world). 
>> >> I can tweak the SSlogis code (given in the help file for 
>> >> selfStart) and the model runs, but cannot test for 
>> >> differences between populations. Since determining reasonable 
>> >> starting values is not a problem, and I'd like to be able to 
>> >> easily adjust the formula to incorporate additional 
>> >> covariates, I would like to avoid using a self-starting function.
>> >> 
>> >> It is my understanding that nlmer requires a function, but 
>> >> not necessarily a self-starting one. However, I can't find an 
>> >> example of any code that does this. 
>> >> 
>> >> I can build a very simple function that allows for 
>> >> differences between populations (referred to as site, which 
>> >> is a 0 1 dummy variable) in both the inflection point (xmid) 
>> >> and the growth rate (K). I'm trying to start with the 
>> >> simplest reasonable model, so I didn't allow for differences 
>> >> in the asymptote. This function works in nls:
>> >> 
>> >> logisKsite = function(Age, site, Asym, xmid, K, Kdiff, middiff){
>> >> 	Asym/(1 + exp((xmid+middiff*site - Age)*(K+Kdiff*site)))
>> >> 	}
>> >> 
>> >> startsite = c(Asym = 9, xmid = 3, K = .5, Kdiff=0, middiff=0) 
>> >> nls_logisKsite = nls(weight ~ logisKsite(Age, site, Asym, 
>> >> xmid, K, Kdiff, middiff), growth, start = startsite)
>> >> 
>> >> The nlmer model I am trying to run is (for simplicity, this 
>> >> model includes only a random effect of nest, only on the K
parameter):
>> >> nlmer_logisKsite = nlmer(weight ~ logisKsite(Age, site, Asym, 
>> >> xmid, K, Kdiff, middiff) ~ (K | Nest_ID), growth, start = 
>> >> startsite, verbose = TRUE)
>> >> 
>> >> Running this model in nlmer produces the error: gradient 
>> >> attribute of evaluated model must be a numeric matrix Dr. 
>> >> Bates' posted lectures note that the model must provide 
>> >> derivatives, via the deriv function. I haven't been 
>> >> successful getting this to work, even in the model without 
>> >> site effects.
>> >> 
>> >> If there is an example of how to run nlmer without a 
>> >> self-start function, could someone please point me to it? 
>> >> Advise on how to implement the deriv function would also be 
>> >> very helpful. 
>> >> 
>> >> Thank you very much,
>> >> 
>> >> Helen
>> >> 
>> >> Helen Sofaer, PhD Candidate in Ecology, Colorado State University
>> >> 
>> >> _______________________________________________
>> >> R-sig-mixed-models at r-project.org mailing list 
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>
>>

-- 
Helen Sofaer
PhD Candidate
Colorado State University
Graduate Degree Program in Ecology
Biology Department
Program for Interdisciplinary Mathematics, Ecology, and Statistics Fellow
(970) 491-2782



From friedericksen.hope at gmail.com  Tue Oct 19 20:29:28 2010
From: friedericksen.hope at gmail.com (Friedericksen Hope)
Date: Tue, 19 Oct 2010 20:29:28 +0200
Subject: [R-sig-ME] Profile function does not work with objekt of class
	"mer"
In-Reply-To: <AANLkTi=j9u1UHYX86mV2UoE7YBKtFsZzBW4kFO1JQBsc@mail.gmail.com>
References: <i9jgdr$fej$1@dough.gmane.org>
	<AANLkTi=j9u1UHYX86mV2UoE7YBKtFsZzBW4kFO1JQBsc@mail.gmail.com>
Message-ID: <i9ko27$gr3$1@dough.gmane.org>


> At present only the lme4a package provides profiling of the deviance
> function.  I would direct you to the R-forge repository except that
> the Windows and Mac OS X builds on that repository are not completing.
>   About the best I can offer is to have a binary package built on the
> win-builder system and stick it on the web site somewhere.  I don't
> use either Windows or Mac OS X myself so I need to rely on other
> builders.
>

Thank you for your response!

If I understand you correctly, the only way to explore the parameter estimates further with confidence intervalls and profile zeta plots is to use the lme4a package from the R-forge repository?!

Anyway, thank you very much for providing the means to do mixed modelling in R. :-)

Best,
Friedericksen



From Manuel.A.Morales at williams.edu  Tue Oct 19 20:49:24 2010
From: Manuel.A.Morales at williams.edu (Manuel Morales)
Date: Tue, 19 Oct 2010 14:49:24 -0400
Subject: [R-sig-ME] deriv example for nlmer
In-Reply-To: <313b53a87acb5f6dfc8ba8f2b5b64d94@lamar.colostate.edu>
References: <3eb7b00042b8e4533612ae628c32a113@lamar.colostate.edu>
	<3DB16098F738284D8DBEB2FC3699163842662C@inboexch.inbo.be>
	<6e7e76da75d3bdc59617c8bffd7b6d0c@lamar.colostate.edu>
	<1287508307.29808.3.camel@localhost.localdomain>
	<313b53a87acb5f6dfc8ba8f2b5b64d94@lamar.colostate.edu>
Message-ID: <1287514164.29808.12.camel@localhost.localdomain>

Oops - I should have checked the code before posting! Note that the
issue is with what is returned by body(logisKsite) ... you wouldn't need
the [[2]] if the function logisKsite didn't have brackets.

Compare:

fn1 <- function(x) x
fn2 <- function(x) {
  x
}

body(fn1)
body(fn2)
body(fn2)[[2]]               



On Tue, 2010-10-19 at 11:43 -0600, Helen Sofaer wrote:
> Thanks!!
> 
> With your deriv code I got the error: Function '`{`' is not in the
> derivatives table
> Googling the error led me to a suggestion that I add [[2]] to the deriv
> function like this:
> 
> logisSiteDeriv = deriv(body(logisKsite)[[2]], namevec = c("Asym", "xmid",
> "K", "Kdiff", "middiff"), function.arg=logisKsite)
> 
> And that function runs in nlmer! So, I've very happy, except I am curious
> as to what the [[2]] does...
> 
> Thanks again for your quick response.
> Helen
> 
> On Tue, 19 Oct 2010 13:11:47 -0400, Manuel Morales
> <Manuel.A.Morales at williams.edu> wrote:
> > How about:
> > 
> > grModel <- function(Age, site, Asym, xmid, K, Kdiff, middiff) {
> >   Asym/(1 + exp((xmid+middiff*site - Age)*(K+Kdiff*site)))
> > }
> > 
> > grModg <- deriv(body(grModel),
> >                 namevec = c("Asym", "xmid", "K", "Kdiff", "middiff"),
> >                 function.arg=grModel)
> > 
> > startsite <- c(Asym=9, xmid=3, K=.5, Kdiff=0, middiff=0)
> > 
> > 
> > nlmer(weight ~ grModg(Age,site,Asym,xmid,K,Kdiff,middiff) ~ (K|Nest_ID),
> >                       data=growth, start=startsite, verbose = TRUE)
> > 
> > On Tue, 2010-10-19 at 08:25 -0600, Helen Sofaer wrote:
> >> Hi Thierry,
> >> My main goal is to test for a difference between populations, which I
> >> can't do with SSlogis.
> >> Check out the code for my function to see the model I'm trying to run.
> >> 
> >> Thanks,
> >> Helen
> >> 
> >> 
> >> On Tue, 19 Oct 2010 10:09:33 +0200, "ONKELINX, Thierry"
> >> <Thierry.ONKELINX at inbo.be> wrote:
> >> > Dear Helen,
> >> > 
> >> > Won't it be easier to stick with Sslogis to run the model and then
> >> > convert scal to K for your report?
> >> > 
> >> > HTH,
> >> > 
> >> > Thierry
> >> > 
> >> >
> ------------------------------------------------------------------------
> >> > ----
> >> > ir. Thierry Onkelinx
> >> > Instituut voor natuur- en bosonderzoek
> >> > team Biometrie & Kwaliteitszorg
> >> > Gaverstraat 4
> >> > 9500 Geraardsbergen
> >> > Belgium
> >> > 
> >> > Research Institute for Nature and Forest
> >> > team Biometrics & Quality Assurance
> >> > Gaverstraat 4
> >> > 9500 Geraardsbergen
> >> > Belgium
> >> > 
> >> > tel. + 32 54/436 185
> >> > Thierry.Onkelinx at inbo.be
> >> > www.inbo.be
> >> > 
> >> > To call in the statistician after the experiment is done may be no
> more
> >> > than asking him to perform a post-mortem examination: he may be able
> to
> >> > say what the experiment died of.
> >> > ~ Sir Ronald Aylmer Fisher
> >> > 
> >> > The plural of anecdote is not data.
> >> > ~ Roger Brinner
> >> > 
> >> > The combination of some data and an aching desire for an answer does
> >> > not
> >> > ensure that a reasonable answer can be extracted from a given body of
> >> > data.
> >> > ~ John Tukey
> >> >   
> >> > 
> >> >> -----Oorspronkelijk bericht-----
> >> >> Van: r-sig-mixed-models-bounces at r-project.org 
> >> >> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Helen
> Sofaer
> >> >> Verzonden: dinsdag 19 oktober 2010 4:07
> >> >> Aan: r-sig-mixed-models at r-project.org
> >> >> Onderwerp: [R-sig-ME] deriv example for nlmer
> >> >> 
> >> >> 
> >> >> Hello modelers,
> >> >> I am working on a growth rate analysis in lme4, where my goal 
> >> >> is to test for differences in growth rates between two 
> >> >> populations of birds while incorporating random effects for 
> >> >> nests (to deal with the lack of independence between 
> >> >> siblings) and for each nestling (to deal with repeated 
> >> >> measures of individuals). 
> >> >> 
> >> >> I'd like to build a model that is parameterized slightly 
> >> >> differently than the SSlogis self-starting model, where K = 
> >> >> 1/scal (this is simply due to convention in the bird world). 
> >> >> I can tweak the SSlogis code (given in the help file for 
> >> >> selfStart) and the model runs, but cannot test for 
> >> >> differences between populations. Since determining reasonable 
> >> >> starting values is not a problem, and I'd like to be able to 
> >> >> easily adjust the formula to incorporate additional 
> >> >> covariates, I would like to avoid using a self-starting function.
> >> >> 
> >> >> It is my understanding that nlmer requires a function, but 
> >> >> not necessarily a self-starting one. However, I can't find an 
> >> >> example of any code that does this. 
> >> >> 
> >> >> I can build a very simple function that allows for 
> >> >> differences between populations (referred to as site, which 
> >> >> is a 0 1 dummy variable) in both the inflection point (xmid) 
> >> >> and the growth rate (K). I'm trying to start with the 
> >> >> simplest reasonable model, so I didn't allow for differences 
> >> >> in the asymptote. This function works in nls:
> >> >> 
> >> >> logisKsite = function(Age, site, Asym, xmid, K, Kdiff, middiff){
> >> >> 	Asym/(1 + exp((xmid+middiff*site - Age)*(K+Kdiff*site)))
> >> >> 	}
> >> >> 
> >> >> startsite = c(Asym = 9, xmid = 3, K = .5, Kdiff=0, middiff=0) 
> >> >> nls_logisKsite = nls(weight ~ logisKsite(Age, site, Asym, 
> >> >> xmid, K, Kdiff, middiff), growth, start = startsite)
> >> >> 
> >> >> The nlmer model I am trying to run is (for simplicity, this 
> >> >> model includes only a random effect of nest, only on the K
> parameter):
> >> >> nlmer_logisKsite = nlmer(weight ~ logisKsite(Age, site, Asym, 
> >> >> xmid, K, Kdiff, middiff) ~ (K | Nest_ID), growth, start = 
> >> >> startsite, verbose = TRUE)
> >> >> 
> >> >> Running this model in nlmer produces the error: gradient 
> >> >> attribute of evaluated model must be a numeric matrix Dr. 
> >> >> Bates' posted lectures note that the model must provide 
> >> >> derivatives, via the deriv function. I haven't been 
> >> >> successful getting this to work, even in the model without 
> >> >> site effects.
> >> >> 
> >> >> If there is an example of how to run nlmer without a 
> >> >> self-start function, could someone please point me to it? 
> >> >> Advise on how to implement the deriv function would also be 
> >> >> very helpful. 
> >> >> 
> >> >> Thank you very much,
> >> >> 
> >> >> Helen
> >> >> 
> >> >> Helen Sofaer, PhD Candidate in Ecology, Colorado State University
> >> >> 
> >> >> _______________________________________________
> >> >> R-sig-mixed-models at r-project.org mailing list 
> >> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >>
> >>
> 

-- 
http://mutualism.williams.edu



From helen at lamar.colostate.edu  Tue Oct 19 21:27:52 2010
From: helen at lamar.colostate.edu (Helen Sofaer)
Date: Tue, 19 Oct 2010 13:27:52 -0600
Subject: [R-sig-ME] deriv example for nlmer
In-Reply-To: <1287514164.29808.12.camel@localhost.localdomain>
References: <3eb7b00042b8e4533612ae628c32a113@lamar.colostate.edu>
	<3DB16098F738284D8DBEB2FC3699163842662C@inboexch.inbo.be>
	<6e7e76da75d3bdc59617c8bffd7b6d0c@lamar.colostate.edu>
	<1287508307.29808.3.camel@localhost.localdomain>
	<313b53a87acb5f6dfc8ba8f2b5b64d94@lamar.colostate.edu>
	<1287514164.29808.12.camel@localhost.localdomain>
Message-ID: <78b32144f7d1ae39433f90e575da4d3c@lamar.colostate.edu>


Thanks--that does make it clear.
Thanks again for your help with the deriv function, 
Helen

On Tue, 19 Oct 2010 14:49:24 -0400, Manuel Morales
<Manuel.A.Morales at williams.edu> wrote:
> Oops - I should have checked the code before posting! Note that the
> issue is with what is returned by body(logisKsite) ... you wouldn't need
> the [[2]] if the function logisKsite didn't have brackets.
> 
> Compare:
> 
> fn1 <- function(x) x
> fn2 <- function(x) {
>   x
> }
> 
> body(fn1)
> body(fn2)
> body(fn2)[[2]]               
> 
> 
> 
> On Tue, 2010-10-19 at 11:43 -0600, Helen Sofaer wrote:
>> Thanks!!
>> 
>> With your deriv code I got the error: Function '`{`' is not in the
>> derivatives table
>> Googling the error led me to a suggestion that I add [[2]] to the deriv
>> function like this:
>> 
>> logisSiteDeriv = deriv(body(logisKsite)[[2]], namevec = c("Asym",
"xmid",
>> "K", "Kdiff", "middiff"), function.arg=logisKsite)
>> 
>> And that function runs in nlmer! So, I've very happy, except I am
curious
>> as to what the [[2]] does...
>> 
>> Thanks again for your quick response.
>> Helen
>> 
>> On Tue, 19 Oct 2010 13:11:47 -0400, Manuel Morales
>> <Manuel.A.Morales at williams.edu> wrote:
>> > How about:
>> > 
>> > grModel <- function(Age, site, Asym, xmid, K, Kdiff, middiff) {
>> >   Asym/(1 + exp((xmid+middiff*site - Age)*(K+Kdiff*site)))
>> > }
>> > 
>> > grModg <- deriv(body(grModel),
>> >                 namevec = c("Asym", "xmid", "K", "Kdiff", "middiff"),
>> >                 function.arg=grModel)
>> > 
>> > startsite <- c(Asym=9, xmid=3, K=.5, Kdiff=0, middiff=0)
>> > 
>> > 
>> > nlmer(weight ~ grModg(Age,site,Asym,xmid,K,Kdiff,middiff) ~
>> > (K|Nest_ID),
>> >                       data=growth, start=startsite, verbose = TRUE)
>> > 
>> > On Tue, 2010-10-19 at 08:25 -0600, Helen Sofaer wrote:
>> >> Hi Thierry,
>> >> My main goal is to test for a difference between populations, which
I
>> >> can't do with SSlogis.
>> >> Check out the code for my function to see the model I'm trying to
run.
>> >> 
>> >> Thanks,
>> >> Helen
>> >> 
>> >> 
>> >> On Tue, 19 Oct 2010 10:09:33 +0200, "ONKELINX, Thierry"
>> >> <Thierry.ONKELINX at inbo.be> wrote:
>> >> > Dear Helen,
>> >> > 
>> >> > Won't it be easier to stick with Sslogis to run the model and then
>> >> > convert scal to K for your report?
>> >> > 
>> >> > HTH,
>> >> > 
>> >> > Thierry
>> >> > 
>> >> >
>>
------------------------------------------------------------------------
>> >> > ----
>> >> > ir. Thierry Onkelinx
>> >> > Instituut voor natuur- en bosonderzoek
>> >> > team Biometrie & Kwaliteitszorg
>> >> > Gaverstraat 4
>> >> > 9500 Geraardsbergen
>> >> > Belgium
>> >> > 
>> >> > Research Institute for Nature and Forest
>> >> > team Biometrics & Quality Assurance
>> >> > Gaverstraat 4
>> >> > 9500 Geraardsbergen
>> >> > Belgium
>> >> > 
>> >> > tel. + 32 54/436 185
>> >> > Thierry.Onkelinx at inbo.be
>> >> > www.inbo.be
>> >> > 
>> >> > To call in the statistician after the experiment is done may be no
>> more
>> >> > than asking him to perform a post-mortem examination: he may be
able
>> to
>> >> > say what the experiment died of.
>> >> > ~ Sir Ronald Aylmer Fisher
>> >> > 
>> >> > The plural of anecdote is not data.
>> >> > ~ Roger Brinner
>> >> > 
>> >> > The combination of some data and an aching desire for an answer
does
>> >> > not
>> >> > ensure that a reasonable answer can be extracted from a given body
>> >> > of
>> >> > data.
>> >> > ~ John Tukey
>> >> >   
>> >> > 
>> >> >> -----Oorspronkelijk bericht-----
>> >> >> Van: r-sig-mixed-models-bounces at r-project.org 
>> >> >> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Helen
>> Sofaer
>> >> >> Verzonden: dinsdag 19 oktober 2010 4:07
>> >> >> Aan: r-sig-mixed-models at r-project.org
>> >> >> Onderwerp: [R-sig-ME] deriv example for nlmer
>> >> >> 
>> >> >> 
>> >> >> Hello modelers,
>> >> >> I am working on a growth rate analysis in lme4, where my goal 
>> >> >> is to test for differences in growth rates between two 
>> >> >> populations of birds while incorporating random effects for 
>> >> >> nests (to deal with the lack of independence between 
>> >> >> siblings) and for each nestling (to deal with repeated 
>> >> >> measures of individuals). 
>> >> >> 
>> >> >> I'd like to build a model that is parameterized slightly 
>> >> >> differently than the SSlogis self-starting model, where K = 
>> >> >> 1/scal (this is simply due to convention in the bird world). 
>> >> >> I can tweak the SSlogis code (given in the help file for 
>> >> >> selfStart) and the model runs, but cannot test for 
>> >> >> differences between populations. Since determining reasonable 
>> >> >> starting values is not a problem, and I'd like to be able to 
>> >> >> easily adjust the formula to incorporate additional 
>> >> >> covariates, I would like to avoid using a self-starting function.
>> >> >> 
>> >> >> It is my understanding that nlmer requires a function, but 
>> >> >> not necessarily a self-starting one. However, I can't find an 
>> >> >> example of any code that does this. 
>> >> >> 
>> >> >> I can build a very simple function that allows for 
>> >> >> differences between populations (referred to as site, which 
>> >> >> is a 0 1 dummy variable) in both the inflection point (xmid) 
>> >> >> and the growth rate (K). I'm trying to start with the 
>> >> >> simplest reasonable model, so I didn't allow for differences 
>> >> >> in the asymptote. This function works in nls:
>> >> >> 
>> >> >> logisKsite = function(Age, site, Asym, xmid, K, Kdiff, middiff){
>> >> >> 	Asym/(1 + exp((xmid+middiff*site - Age)*(K+Kdiff*site)))
>> >> >> 	}
>> >> >> 
>> >> >> startsite = c(Asym = 9, xmid = 3, K = .5, Kdiff=0, middiff=0) 
>> >> >> nls_logisKsite = nls(weight ~ logisKsite(Age, site, Asym, 
>> >> >> xmid, K, Kdiff, middiff), growth, start = startsite)
>> >> >> 
>> >> >> The nlmer model I am trying to run is (for simplicity, this 
>> >> >> model includes only a random effect of nest, only on the K
>> parameter):
>> >> >> nlmer_logisKsite = nlmer(weight ~ logisKsite(Age, site, Asym, 
>> >> >> xmid, K, Kdiff, middiff) ~ (K | Nest_ID), growth, start = 
>> >> >> startsite, verbose = TRUE)
>> >> >> 
>> >> >> Running this model in nlmer produces the error: gradient 
>> >> >> attribute of evaluated model must be a numeric matrix Dr. 
>> >> >> Bates' posted lectures note that the model must provide 
>> >> >> derivatives, via the deriv function. I haven't been 
>> >> >> successful getting this to work, even in the model without 
>> >> >> site effects.
>> >> >> 
>> >> >> If there is an example of how to run nlmer without a 
>> >> >> self-start function, could someone please point me to it? 
>> >> >> Advise on how to implement the deriv function would also be 
>> >> >> very helpful. 
>> >> >> 
>> >> >> Thank you very much,
>> >> >> 
>> >> >> Helen
>> >> >> 
>> >> >> Helen Sofaer, PhD Candidate in Ecology, Colorado State University
>> >> >> 
>> >> >> _______________________________________________
>> >> >> R-sig-mixed-models at r-project.org mailing list 
>> >> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >> >>
>> >>
>>

-- 
Helen Sofaer
PhD Candidate
Colorado State University
Graduate Degree Program in Ecology
Biology Department
Program for Interdisciplinary Mathematics, Ecology, and Statistics Fellow
(970) 491-2782



From mjmilloy at cfenet.ubc.ca  Wed Oct 20 05:24:03 2010
From: mjmilloy at cfenet.ubc.ca (M-J Milloy)
Date: Tue, 19 Oct 2010 20:24:03 -0700
Subject: [R-sig-ME] lme4 missing from repositories?
Message-ID: <D12D381C-DF9A-4406-9CD8-76806DD93817@cfenet.ubc.ca>


Hello, After an initial inquiry, Douglas Bates helpfully suggested I send my question to this list: I installed R onto a new machine and tried to install a binary of lme4 but none of the repositories I've checked list it. I'm on OS X 10.6 running R 2.11.1. 

Thanks for any insight/assistance you can provide,


M-J





--

M-J Milloy

Research coordinator,
AIDS Care Cohort to Evaluate Access to Survival Services
Urban Health Research Initiative
British Columbia Centre for Excellence in HIV/AIDS
St. Paul's Hospital, Vancouver, BC, Canada

Doctoral candidate,
School of Population and Public Health,
University of British Columbia
Vancouver, BC, Canada

mjmilloy at cfenet.ubc.ca



From jwiley.psych at gmail.com  Wed Oct 20 14:42:55 2010
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Wed, 20 Oct 2010 05:42:55 -0700
Subject: [R-sig-ME] lme4 missing from repositories?
In-Reply-To: <D12D381C-DF9A-4406-9CD8-76806DD93817@cfenet.ubc.ca>
References: <D12D381C-DF9A-4406-9CD8-76806DD93817@cfenet.ubc.ca>
Message-ID: <AANLkTikZ48i-1m3J3+Bzp1UEW6B7ttfgpt2zu07BA7GL@mail.gmail.com>

Dear M-J,

Are you installing it via install.packages("lme4") or by downloading
the binary?  I would try install.packages() first, but here are two
links to binaries that should work for Mac OSX.

http://cran.stat.ucla.edu/bin/macosx/leopard/contrib/r-release/lme4_0.999375-35.tgz
or
http://cran.r-project.org/bin/macosx/leopard/contrib/r-release/lme4_0.999375-35.tgz

Best Regards,

Josh

On Tue, Oct 19, 2010 at 8:24 PM, M-J Milloy <mjmilloy at cfenet.ubc.ca> wrote:
>
> Hello, After an initial inquiry, Douglas Bates helpfully suggested I send my question to this list: I installed R onto a new machine and tried to install a binary of lme4 but none of the repositories I've checked list it. I'm on OS X 10.6 running R 2.11.1.
>
> Thanks for any insight/assistance you can provide,
>
>
> M-J
>
>
>
>
>
> --
>
> M-J Milloy
>
> Research coordinator,
> AIDS Care Cohort to Evaluate Access to Survival Services
> Urban Health Research Initiative
> British Columbia Centre for Excellence in HIV/AIDS
> St. Paul's Hospital, Vancouver, BC, Canada
>
> Doctoral candidate,
> School of Population and Public Health,
> University of British Columbia
> Vancouver, BC, Canada
>
> mjmilloy at cfenet.ubc.ca
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
University of California, Los Angeles
http://www.joshuawiley.com/



From jwiley.psych at gmail.com  Wed Oct 20 15:19:07 2010
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Wed, 20 Oct 2010 06:19:07 -0700
Subject: [R-sig-ME] lme4 missing from repositories?
In-Reply-To: <AANLkTikZ48i-1m3J3+Bzp1UEW6B7ttfgpt2zu07BA7GL@mail.gmail.com>
References: <D12D381C-DF9A-4406-9CD8-76806DD93817@cfenet.ubc.ca>
	<AANLkTikZ48i-1m3J3+Bzp1UEW6B7ttfgpt2zu07BA7GL@mail.gmail.com>
Message-ID: <AANLkTikN70kiHuMCFZNcbNyhh4oYJQeorYviCh3xW7CL@mail.gmail.com>

On Wed, Oct 20, 2010 at 5:42 AM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
> Dear M-J,
>
> Are you installing it via install.packages("lme4") or by downloading
> the binary? ?I would try install.packages() first,

Sorry, scratch that, I forgot about the error with Macs (I knew that
seemed too simple but somehow my foot worked its way out of my
mouth...).

These (relatively) recent threads discuss the topic of installing lme4 on Macs:

http://finzi.psych.upenn.edu/R-sig-mixed-models/2010q3/004246.html
http://finzi.psych.upenn.edu/R-sig-mixed-models/2010q3/004075.html

> but here are two links to binaries that should work for Mac OSX.
>
> http://cran.stat.ucla.edu/bin/macosx/leopard/contrib/r-release/lme4_0.999375-35.tgz
> or
> http://cran.r-project.org/bin/macosx/leopard/contrib/r-release/lme4_0.999375-35.tgz
>
> Best Regards,
>
> Josh
>
> On Tue, Oct 19, 2010 at 8:24 PM, M-J Milloy <mjmilloy at cfenet.ubc.ca> wrote:
>>
>> Hello, After an initial inquiry, Douglas Bates helpfully suggested I send my question to this list: I installed R onto a new machine and tried to install a binary of lme4 but none of the repositories I've checked list it. I'm on OS X 10.6 running R 2.11.1.
>>
>> Thanks for any insight/assistance you can provide,
>>
>>
>> M-J
>>
>>
>>
>>
>>
>> --
>>
>> M-J Milloy
>>
>> Research coordinator,
>> AIDS Care Cohort to Evaluate Access to Survival Services
>> Urban Health Research Initiative
>> British Columbia Centre for Excellence in HIV/AIDS
>> St. Paul's Hospital, Vancouver, BC, Canada
>>
>> Doctoral candidate,
>> School of Population and Public Health,
>> University of British Columbia
>> Vancouver, BC, Canada
>>
>> mjmilloy at cfenet.ubc.ca
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> --
> Joshua Wiley
> Ph.D. Student, Health Psychology
> University of California, Los Angeles
> http://www.joshuawiley.com/



From minhuangr at gmail.com  Wed Oct 20 15:36:34 2010
From: minhuangr at gmail.com (huang min)
Date: Wed, 20 Oct 2010 21:36:34 +0800
Subject: [R-sig-ME] lme4 missing from repositories?
In-Reply-To: <AANLkTikN70kiHuMCFZNcbNyhh4oYJQeorYviCh3xW7CL@mail.gmail.com>
References: <D12D381C-DF9A-4406-9CD8-76806DD93817@cfenet.ubc.ca>
	<AANLkTikZ48i-1m3J3+Bzp1UEW6B7ttfgpt2zu07BA7GL@mail.gmail.com>
	<AANLkTikN70kiHuMCFZNcbNyhh4oYJQeorYviCh3xW7CL@mail.gmail.com>
Message-ID: <AANLkTimKZTTUv3S12-uwoeL1Hrx5WzHAxioGVNLkxF3W@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101020/acd0d7b4/attachment.pl>

From tim.carnus at ucd.ie  Wed Oct 20 15:50:37 2010
From: tim.carnus at ucd.ie (tim carnus)
Date: Wed, 20 Oct 2010 14:50:37 +0100
Subject: [R-sig-ME] lme4 missing from repositories?
In-Reply-To: <AANLkTimKZTTUv3S12-uwoeL1Hrx5WzHAxioGVNLkxF3W@mail.gmail.com>
References: <D12D381C-DF9A-4406-9CD8-76806DD93817@cfenet.ubc.ca>
	<AANLkTikZ48i-1m3J3+Bzp1UEW6B7ttfgpt2zu07BA7GL@mail.gmail.com>
	<AANLkTikN70kiHuMCFZNcbNyhh4oYJQeorYviCh3xW7CL@mail.gmail.com>
	<AANLkTimKZTTUv3S12-uwoeL1Hrx5WzHAxioGVNLkxF3W@mail.gmail.com>
Message-ID: <1287582637.3008.0.camel@tim-laptop>

I concur, from Irish repository seems ok...



From f.calboli at imperial.ac.uk  Wed Oct 20 15:52:28 2010
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Wed, 20 Oct 2010 14:52:28 +0100
Subject: [R-sig-ME] lme4 missing from repositories?
In-Reply-To: <AANLkTimKZTTUv3S12-uwoeL1Hrx5WzHAxioGVNLkxF3W@mail.gmail.com>
References: <D12D381C-DF9A-4406-9CD8-76806DD93817@cfenet.ubc.ca>
	<AANLkTikZ48i-1m3J3+Bzp1UEW6B7ttfgpt2zu07BA7GL@mail.gmail.com>
	<AANLkTikN70kiHuMCFZNcbNyhh4oYJQeorYviCh3xW7CL@mail.gmail.com>
	<AANLkTimKZTTUv3S12-uwoeL1Hrx5WzHAxioGVNLkxF3W@mail.gmail.com>
Message-ID: <87312DEB-DFF3-40AF-B2F9-A9F365A0255A@imperial.ac.uk>

On 20 Oct 2010, at 14:36, huang min wrote:

> I just installed R2.12.0 and lme4 binary in MAC from either the Harvard or
> the Australian repositories. No problem at all.


I also upgraded to 2.12.0 and the binary and the source are both listed as 0.999375-35 which seems to be the latest lme4 (*not* a or b) even on r-forge.

F


--
Federico C. F. Calboli
Department of Epidemiology and Biostatistics
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From f.calboli at imperial.ac.uk  Wed Oct 20 16:00:30 2010
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Wed, 20 Oct 2010 15:00:30 +0100
Subject: [R-sig-ME] lme4 missing from repositories?
In-Reply-To: <87312DEB-DFF3-40AF-B2F9-A9F365A0255A@imperial.ac.uk>
References: <D12D381C-DF9A-4406-9CD8-76806DD93817@cfenet.ubc.ca>
	<AANLkTikZ48i-1m3J3+Bzp1UEW6B7ttfgpt2zu07BA7GL@mail.gmail.com>
	<AANLkTikN70kiHuMCFZNcbNyhh4oYJQeorYviCh3xW7CL@mail.gmail.com>
	<AANLkTimKZTTUv3S12-uwoeL1Hrx5WzHAxioGVNLkxF3W@mail.gmail.com>
	<87312DEB-DFF3-40AF-B2F9-A9F365A0255A@imperial.ac.uk>
Message-ID: <E84B04C7-E0F4-43D8-B9F4-B3917A4E2082@imperial.ac.uk>

On 20 Oct 2010, at 14:52, Federico Calboli wrote:
> 
> I also upgraded to 2.12.0 and the binary and the source are both listed as 0.999375-35 which seems to be the latest lme4 (*not* a or b) even on r-forge.

[Obviously] I had no problems.

F



--
Federico C. F. Calboli
Department of Epidemiology and Biostatistics
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From bates at stat.wisc.edu  Wed Oct 20 17:05:58 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 20 Oct 2010 10:05:58 -0500
Subject: [R-sig-ME] lme4 missing from repositories?
In-Reply-To: <E84B04C7-E0F4-43D8-B9F4-B3917A4E2082@imperial.ac.uk>
References: <D12D381C-DF9A-4406-9CD8-76806DD93817@cfenet.ubc.ca>
	<AANLkTikZ48i-1m3J3+Bzp1UEW6B7ttfgpt2zu07BA7GL@mail.gmail.com>
	<AANLkTikN70kiHuMCFZNcbNyhh4oYJQeorYviCh3xW7CL@mail.gmail.com>
	<AANLkTimKZTTUv3S12-uwoeL1Hrx5WzHAxioGVNLkxF3W@mail.gmail.com>
	<87312DEB-DFF3-40AF-B2F9-A9F365A0255A@imperial.ac.uk>
	<E84B04C7-E0F4-43D8-B9F4-B3917A4E2082@imperial.ac.uk>
Message-ID: <AANLkTinukxno63fWnzC8=m=KV+ogJm-M_jirg3qPMxdd@mail.gmail.com>

I think that is thanks to Martin Maechler and Simon Urbanek.  Martin
contacted Simon off-list to work out some of the problems with that
particular test.  I'm not sure of the details but it seems at least
part of the problem was related to the use of veclib (accelerated BLAS
on the Mac OS X platform), which is a little scary.

On Wed, Oct 20, 2010 at 9:00 AM, Federico Calboli
<f.calboli at imperial.ac.uk> wrote:
> On 20 Oct 2010, at 14:52, Federico Calboli wrote:
>>
>> I also upgraded to 2.12.0 and the binary and the source are both listed as 0.999375-35 which seems to be the latest lme4 (*not* a or b) even on r-forge.
>
> [Obviously] I had no problems.
>
> F
>
>
>
> --
> Federico C. F. Calboli
> Department of Epidemiology and Biostatistics
> Imperial College, St. Mary's Campus
> Norfolk Place, London W2 1PG
>
> Tel +44 (0)20 75941602 ? Fax +44 (0)20 75943193
>
> f.calboli [.a.t] imperial.ac.uk
> f.calboli [.a.t] gmail.com
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From f.calboli at imperial.ac.uk  Wed Oct 20 17:09:48 2010
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Wed, 20 Oct 2010 16:09:48 +0100
Subject: [R-sig-ME] lme4 missing from repositories?
In-Reply-To: <AANLkTinukxno63fWnzC8=m=KV+ogJm-M_jirg3qPMxdd@mail.gmail.com>
References: <D12D381C-DF9A-4406-9CD8-76806DD93817@cfenet.ubc.ca>
	<AANLkTikZ48i-1m3J3+Bzp1UEW6B7ttfgpt2zu07BA7GL@mail.gmail.com>
	<AANLkTikN70kiHuMCFZNcbNyhh4oYJQeorYviCh3xW7CL@mail.gmail.com>
	<AANLkTimKZTTUv3S12-uwoeL1Hrx5WzHAxioGVNLkxF3W@mail.gmail.com>
	<87312DEB-DFF3-40AF-B2F9-A9F365A0255A@imperial.ac.uk>
	<E84B04C7-E0F4-43D8-B9F4-B3917A4E2082@imperial.ac.uk>
	<AANLkTinukxno63fWnzC8=m=KV+ogJm-M_jirg3qPMxdd@mail.gmail.com>
Message-ID: <31655632-DB83-4219-943D-529A22167A32@imperial.ac.uk>

On 20 Oct 2010, at 16:05, Douglas Bates wrote:

> I think that is thanks to Martin Maechler and Simon Urbanek.  Martin
> contacted Simon off-list to work out some of the problems with that
> particular test.  I'm not sure of the details but it seems at least
> part of the problem was related to the use of veclib (accelerated BLAS
> on the Mac OS X platform), which is a little scary.


if I remember correctly, that only affected the 32 bit R on macs. I'm using the 64 bit.

F


--
Federico C. F. Calboli
Department of Epidemiology and Biostatistics
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From minhuangr at gmail.com  Wed Oct 20 17:18:31 2010
From: minhuangr at gmail.com (huang min)
Date: Wed, 20 Oct 2010 23:18:31 +0800
Subject: [R-sig-ME] lme4 missing from repositories?
In-Reply-To: <AANLkTinukxno63fWnzC8=m=KV+ogJm-M_jirg3qPMxdd@mail.gmail.com>
References: <D12D381C-DF9A-4406-9CD8-76806DD93817@cfenet.ubc.ca>
	<AANLkTikZ48i-1m3J3+Bzp1UEW6B7ttfgpt2zu07BA7GL@mail.gmail.com>
	<AANLkTikN70kiHuMCFZNcbNyhh4oYJQeorYviCh3xW7CL@mail.gmail.com>
	<AANLkTimKZTTUv3S12-uwoeL1Hrx5WzHAxioGVNLkxF3W@mail.gmail.com>
	<87312DEB-DFF3-40AF-B2F9-A9F365A0255A@imperial.ac.uk>
	<E84B04C7-E0F4-43D8-B9F4-B3917A4E2082@imperial.ac.uk>
	<AANLkTinukxno63fWnzC8=m=KV+ogJm-M_jirg3qPMxdd@mail.gmail.com>
Message-ID: <AANLkTimHDGJUQm+9k_8ACaujknJGtZ19SWZCSk+SWhNi@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101020/05a77c57/attachment.pl>

From minhuangr at gmail.com  Wed Oct 20 17:18:31 2010
From: minhuangr at gmail.com (huang min)
Date: Wed, 20 Oct 2010 23:18:31 +0800
Subject: [R-sig-ME] lme4 missing from repositories?
In-Reply-To: <AANLkTinukxno63fWnzC8=m=KV+ogJm-M_jirg3qPMxdd@mail.gmail.com>
References: <D12D381C-DF9A-4406-9CD8-76806DD93817@cfenet.ubc.ca>
	<AANLkTikZ48i-1m3J3+Bzp1UEW6B7ttfgpt2zu07BA7GL@mail.gmail.com>
	<AANLkTikN70kiHuMCFZNcbNyhh4oYJQeorYviCh3xW7CL@mail.gmail.com>
	<AANLkTimKZTTUv3S12-uwoeL1Hrx5WzHAxioGVNLkxF3W@mail.gmail.com>
	<87312DEB-DFF3-40AF-B2F9-A9F365A0255A@imperial.ac.uk>
	<E84B04C7-E0F4-43D8-B9F4-B3917A4E2082@imperial.ac.uk>
	<AANLkTinukxno63fWnzC8=m=KV+ogJm-M_jirg3qPMxdd@mail.gmail.com>
Message-ID: <AANLkTimHDGJUQm+9k_8ACaujknJGtZ19SWZCSk+SWhNi@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101020/05a77c57/attachment-0001.pl>

From bates at stat.wisc.edu  Wed Oct 20 17:29:12 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 20 Oct 2010 10:29:12 -0500
Subject: [R-sig-ME] lme4 missing from repositories?
In-Reply-To: <AANLkTimHDGJUQm+9k_8ACaujknJGtZ19SWZCSk+SWhNi@mail.gmail.com>
References: <D12D381C-DF9A-4406-9CD8-76806DD93817@cfenet.ubc.ca>
	<AANLkTikZ48i-1m3J3+Bzp1UEW6B7ttfgpt2zu07BA7GL@mail.gmail.com>
	<AANLkTikN70kiHuMCFZNcbNyhh4oYJQeorYviCh3xW7CL@mail.gmail.com>
	<AANLkTimKZTTUv3S12-uwoeL1Hrx5WzHAxioGVNLkxF3W@mail.gmail.com>
	<87312DEB-DFF3-40AF-B2F9-A9F365A0255A@imperial.ac.uk>
	<E84B04C7-E0F4-43D8-B9F4-B3917A4E2082@imperial.ac.uk>
	<AANLkTinukxno63fWnzC8=m=KV+ogJm-M_jirg3qPMxdd@mail.gmail.com>
	<AANLkTimHDGJUQm+9k_8ACaujknJGtZ19SWZCSk+SWhNi@mail.gmail.com>
Message-ID: <AANLkTin8WxPh2wB9sO+=xuhvH3iEhAraRBeP_+qtmqne@mail.gmail.com>

On Wed, Oct 20, 2010 at 10:18 AM, huang min <minhuangr at gmail.com> wrote:
> Hi, Prof. Bates,
>
> I tried some simple codes from Prof. Ripley.
>
> library(lme4)
> y <- (1:20)*pi; x <- (1:20)^2;group <- gl(2,10)
> M2. <- lmer (y ~ 1 + x + (1 + x | group))
> M2 <- lmer (y ~ x + ( x | group))
> identical(fixef(M2), fixef(M2.))

This is exactly what is so frustrating.  By the time the model
matrices have been constructed M2. and M2 are exactly the same model
so how they end up with different answers is somewhat mysterious and
something that we can't reproduce on other systems.

>
> The results are still false sometimes under MAC R2.12.0.
>
> Huang
>
> On Wed, Oct 20, 2010 at 11:05 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
>>
>> I think that is thanks to Martin Maechler and Simon Urbanek. ?Martin
>> contacted Simon off-list to work out some of the problems with that
>> particular test. ?I'm not sure of the details but it seems at least
>> part of the problem was related to the use of veclib (accelerated BLAS
>> on the Mac OS X platform), which is a little scary.
>>
>> On Wed, Oct 20, 2010 at 9:00 AM, Federico Calboli
>> <f.calboli at imperial.ac.uk> wrote:
>> > On 20 Oct 2010, at 14:52, Federico Calboli wrote:
>> >>
>> >> I also upgraded to 2.12.0 and the binary and the source are both listed
>> >> as 0.999375-35 which seems to be the latest lme4 (*not* a or b) even on
>> >> r-forge.
>> >
>> > [Obviously] I had no problems.
>> >
>> > F
>> >
>> >
>> >
>> > --
>> > Federico C. F. Calboli
>> > Department of Epidemiology and Biostatistics
>> > Imperial College, St. Mary's Campus
>> > Norfolk Place, London W2 1PG
>> >
>> > Tel +44 (0)20 75941602 ? Fax +44 (0)20 75943193
>> >
>> > f.calboli [.a.t] imperial.ac.uk
>> > f.calboli [.a.t] gmail.com
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



From f.calboli at imperial.ac.uk  Wed Oct 20 18:30:14 2010
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Wed, 20 Oct 2010 17:30:14 +0100
Subject: [R-sig-ME] lme4 missing from repositories?
In-Reply-To: <AANLkTin8WxPh2wB9sO+=xuhvH3iEhAraRBeP_+qtmqne@mail.gmail.com>
References: <D12D381C-DF9A-4406-9CD8-76806DD93817@cfenet.ubc.ca>
	<AANLkTikZ48i-1m3J3+Bzp1UEW6B7ttfgpt2zu07BA7GL@mail.gmail.com>
	<AANLkTikN70kiHuMCFZNcbNyhh4oYJQeorYviCh3xW7CL@mail.gmail.com>
	<AANLkTimKZTTUv3S12-uwoeL1Hrx5WzHAxioGVNLkxF3W@mail.gmail.com>
	<87312DEB-DFF3-40AF-B2F9-A9F365A0255A@imperial.ac.uk>
	<E84B04C7-E0F4-43D8-B9F4-B3917A4E2082@imperial.ac.uk>
	<AANLkTinukxno63fWnzC8=m=KV+ogJm-M_jirg3qPMxdd@mail.gmail.com>
	<AANLkTimHDGJUQm+9k_8ACaujknJGtZ19SWZCSk+SWhNi@mail.gmail.com>
	<AANLkTin8WxPh2wB9sO+=xuhvH3iEhAraRBeP_+qtmqne@mail.gmail.com>
Message-ID: <08E6A2A9-68B0-4AE0-95B5-692E4ED5F104@imperial.ac.uk>

On 20 Oct 2010, at 16:29, Douglas Bates wrote:

> On Wed, Oct 20, 2010 at 10:18 AM, huang min <minhuangr at gmail.com> wrote:
>> Hi, Prof. Bates,
>> 
>> I tried some simple codes from Prof. Ripley.
>> 
>> library(lme4)
>> y <- (1:20)*pi; x <- (1:20)^2;group <- gl(2,10)
>> M2. <- lmer (y ~ 1 + x + (1 + x | group))
>> M2 <- lmer (y ~ x + ( x | group))
>> identical(fixef(M2), fixef(M2.))
> 
> This is exactly what is so frustrating.  By the time the model
> matrices have been constructed M2. and M2 are exactly the same model
> so how they end up with different answers is somewhat mysterious and
> something that we can't reproduce on other systems.


FWIW:

R version 2.12.0 (2010-10-15)
Copyright (C) 2010 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
 ....
[R.app GUI 1.35 (5632) x86_64-apple-darwin9.8.0]

 library(lme4)
 test = rep(0, 10000)
 for (i in 1:10000){
 y <- (1:20)*pi; x <- (1:20)^2;group <- gl(2,10)
 M2. <- lmer (y ~ 1 + x + (1 + x | group))
 M2 <- lmer (y ~ x + ( x | group))
 test[i] = identical(fixef(M2), fixef(M2.))
 }
 sum(test)
[1] 10000
 sum(test == F)
[1] 0

I just fail to see why there is any need to use R32 and not R64, but that's just me.

F



--
Federico C. F. Calboli
Department of Epidemiology and Biostatistics
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From minhuangr at gmail.com  Thu Oct 21 04:32:35 2010
From: minhuangr at gmail.com (huang min)
Date: Thu, 21 Oct 2010 10:32:35 +0800
Subject: [R-sig-ME] lme4 missing from repositories?
In-Reply-To: <08E6A2A9-68B0-4AE0-95B5-692E4ED5F104@imperial.ac.uk>
References: <D12D381C-DF9A-4406-9CD8-76806DD93817@cfenet.ubc.ca>
	<AANLkTikZ48i-1m3J3+Bzp1UEW6B7ttfgpt2zu07BA7GL@mail.gmail.com>
	<AANLkTikN70kiHuMCFZNcbNyhh4oYJQeorYviCh3xW7CL@mail.gmail.com>
	<AANLkTimKZTTUv3S12-uwoeL1Hrx5WzHAxioGVNLkxF3W@mail.gmail.com>
	<87312DEB-DFF3-40AF-B2F9-A9F365A0255A@imperial.ac.uk>
	<E84B04C7-E0F4-43D8-B9F4-B3917A4E2082@imperial.ac.uk>
	<AANLkTinukxno63fWnzC8=m=KV+ogJm-M_jirg3qPMxdd@mail.gmail.com>
	<AANLkTimHDGJUQm+9k_8ACaujknJGtZ19SWZCSk+SWhNi@mail.gmail.com>
	<AANLkTin8WxPh2wB9sO+=xuhvH3iEhAraRBeP_+qtmqne@mail.gmail.com>
	<08E6A2A9-68B0-4AE0-95B5-692E4ED5F104@imperial.ac.uk>
Message-ID: <AANLkTinLYmO+PgTaP_=QRqqYkNHqdPtuO0vRhWxmBq=v@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101021/a4d96cbf/attachment.pl>

From f.calboli at imperial.ac.uk  Thu Oct 21 11:22:14 2010
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Thu, 21 Oct 2010 10:22:14 +0100
Subject: [R-sig-ME] lme4 missing from repositories?
In-Reply-To: <AANLkTinLYmO+PgTaP_=QRqqYkNHqdPtuO0vRhWxmBq=v@mail.gmail.com>
References: <D12D381C-DF9A-4406-9CD8-76806DD93817@cfenet.ubc.ca>
	<AANLkTikZ48i-1m3J3+Bzp1UEW6B7ttfgpt2zu07BA7GL@mail.gmail.com>
	<AANLkTikN70kiHuMCFZNcbNyhh4oYJQeorYviCh3xW7CL@mail.gmail.com>
	<AANLkTimKZTTUv3S12-uwoeL1Hrx5WzHAxioGVNLkxF3W@mail.gmail.com>
	<87312DEB-DFF3-40AF-B2F9-A9F365A0255A@imperial.ac.uk>
	<E84B04C7-E0F4-43D8-B9F4-B3917A4E2082@imperial.ac.uk>
	<AANLkTinukxno63fWnzC8=m=KV+ogJm-M_jirg3qPMxdd@mail.gmail.com>
	<AANLkTimHDGJUQm+9k_8ACaujknJGtZ19SWZCSk+SWhNi@mail.gmail.com>
	<AANLkTin8WxPh2wB9sO+=xuhvH3iEhAraRBeP_+qtmqne@mail.gmail.com>
	<08E6A2A9-68B0-4AE0-95B5-692E4ED5F104@imperial.ac.uk>
	<AANLkTinLYmO+PgTaP_=QRqqYkNHqdPtuO0vRhWxmBq=v@mail.gmail.com>
Message-ID: <9F065CD6-D40E-40A2-940D-9F22452510DD@imperial.ac.uk>

On 21 Oct 2010, at 03:32, huang min wrote:

> For your codes, R32 is about 20% faster on my machine and as Simon Urbanek suggested, R32 is more well tested. Though I forgot when he mentioned this (Maybe a bit outdated).
> 
> I don't know whether there are recently information about the 32bit vs 64bit.

I think it is reasonable to make the case that, for the use of the library lme4, in order to get results you are happy to send to a journal you have to use R64. The 20% time increase is nothing compared to letters of retraction, unpublished papers because you are not sure of the results, and possibly a license for a different software to doublecheck the results.

Additionally 64 bit architecture is not exactly new stuff now, and I've been running R64 on Mac and Linux for years. I'm surprised to hear that R64 is not as well tested as R32 (though I am surprised to hear that R32 is faster for the example I posted).

Best,

Federico


--
Federico C. F. Calboli
Department of Epidemiology and Biostatistics
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From marc_schwartz at me.com  Thu Oct 21 15:14:38 2010
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 21 Oct 2010 08:14:38 -0500
Subject: [R-sig-ME] lme4 missing from repositories?
In-Reply-To: <9F065CD6-D40E-40A2-940D-9F22452510DD@imperial.ac.uk>
References: <D12D381C-DF9A-4406-9CD8-76806DD93817@cfenet.ubc.ca>
	<AANLkTikZ48i-1m3J3+Bzp1UEW6B7ttfgpt2zu07BA7GL@mail.gmail.com>
	<AANLkTikN70kiHuMCFZNcbNyhh4oYJQeorYviCh3xW7CL@mail.gmail.com>
	<AANLkTimKZTTUv3S12-uwoeL1Hrx5WzHAxioGVNLkxF3W@mail.gmail.com>
	<87312DEB-DFF3-40AF-B2F9-A9F365A0255A@imperial.ac.uk>
	<E84B04C7-E0F4-43D8-B9F4-B3917A4E2082@imperial.ac.uk>
	<AANLkTinukxno63fWnzC8=m=KV+ogJm-M_jirg3qPMxdd@mail.gmail.com>
	<AANLkTimHDGJUQm+9k_8ACaujknJGtZ19SWZCSk+SWhNi@mail.gmail.com>
	<AANLkTin8WxPh2wB9sO+=xuhvH3iEhAraRBeP_+qtmqne@mail.gmail.com>
	<08E6A2A9-68B0-4AE0-95B5-692E4ED5F104@imperial.ac.uk>
	<AANLkTinLYmO+PgTaP_=QRqqYkNHqdPtuO0vRhWxmBq=v@mail.gmail.com>
	<9F065CD6-D40E-40A2-940D-9F22452510DD@imperial.ac.uk>
Message-ID: <A8F644A5-980E-4D46-80D2-2DFBEBD67032@me.com>

Hi all,

To the extent that it may be helpful here and I can do more if need be, I built 32 bit R 2.12.0 patched on Snow Leopard (10.6.4), using the R BLAS rather than Apple's veclib. This is on an early 2009 17" MBP with a 2.93 Ghz Core 2 Duo (MacBookPro5,2) and 4Gb of RAM. 

Based upon Doug's comment in this thread that the issue may be related to the use of Apple's veclib BLAS, as opposed to R's reference BLAS, I ran some tests.

My config includes:

  --without-blas --without-lapack

just to be sure that the above is the correct invocation, based upon what I found online.

Using this build, with all CRAN packages freshly installed using this build, I ran the example used here with lme4 0.999375-35. I get:

library(lme4)
y <- (1:20)*pi; x <- (1:20)^2;group <- gl(2,10)
M2. <- lmer (y ~ 1 + x + (1 + x | group))
M2 <- lmer (y ~ x + ( x | group))

> identical(fixef(M2), fixef(M2.))
[1] TRUE



I then created a function so that I could use replicate() to run this test a "larger" number of times:

testlme4 <- function()
{ 
  y <- (1:20)*pi; x <- (1:20)^2;group <- gl(2,10)
  M2. <- lmer (y ~ 1 + x + (1 + x | group))
  M2 <- lmer (y ~ x + ( x | group))
  identical(fixef(M2), fixef(M2.))
}


RES <- replicate(1000, testlme4())

> all(RES)
[1] TRUE

> table(RES)
RES
TRUE 
1000 

Does the example need to be run a "very large" number of times to be sure that it does not fail, or is the above a reasonable indication that the use of R's BLAS is a more appropriate default option for R on OSX?  If I am not mistaken (and somebody correct me if wrong), R's BLAS is the default on Windows and Linux (from my recollections on Fedora). Why should OSX be different in that regard?

Also, as an aside to Federico, I use 32 bit R on OSX largely because I have to interact with an Oracle server via RODBC. The only ODBC drivers available for Oracle on OSX are 32 bit and they are not compatible with 64 bit R. It would be rather cumbersome when running reports (via Sweave) to first extract the data in 32 bit R and then switch to 64 bit R to run the reports. I can run it all in a single step using 32 bit R. I also do not have a need for the larger memory address space afforded by 64 bit R.

HTH,

Marc Schwartz



From f.calboli at imperial.ac.uk  Thu Oct 21 15:47:10 2010
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Thu, 21 Oct 2010 14:47:10 +0100
Subject: [R-sig-ME] lme4 missing from repositories?
In-Reply-To: <A8F644A5-980E-4D46-80D2-2DFBEBD67032@me.com>
References: <D12D381C-DF9A-4406-9CD8-76806DD93817@cfenet.ubc.ca>
	<AANLkTikZ48i-1m3J3+Bzp1UEW6B7ttfgpt2zu07BA7GL@mail.gmail.com>
	<AANLkTikN70kiHuMCFZNcbNyhh4oYJQeorYviCh3xW7CL@mail.gmail.com>
	<AANLkTimKZTTUv3S12-uwoeL1Hrx5WzHAxioGVNLkxF3W@mail.gmail.com>
	<87312DEB-DFF3-40AF-B2F9-A9F365A0255A@imperial.ac.uk>
	<E84B04C7-E0F4-43D8-B9F4-B3917A4E2082@imperial.ac.uk>
	<AANLkTinukxno63fWnzC8=m=KV+ogJm-M_jirg3qPMxdd@mail.gmail.com>
	<AANLkTimHDGJUQm+9k_8ACaujknJGtZ19SWZCSk+SWhNi@mail.gmail.com>
	<AANLkTin8WxPh2wB9sO+=xuhvH3iEhAraRBeP_+qtmqne@mail.gmail.com>
	<08E6A2A9-68B0-4AE0-95B5-692E4ED5F104@imperial.ac.uk>
	<AANLkTinLYmO+PgTaP_=QRqqYkNHqdPtuO0vRhWxmBq=v@mail.gmail.com>
	<9F065CD6-D40E-40A2-940D-9F22452510DD@imperial.ac.uk>
	<A8F644A5-980E-4D46-80D2-2DFBEBD67032@me.com>
Message-ID: <03837FFF-2087-45DF-98F7-7E2439777CF3@imperial.ac.uk>

Mark, 
> 
> To the extent that it may be helpful here and I can do more if need be, I built 32 bit R 2.12.0 patched on Snow Leopard (10.6.4), using the R BLAS rather than Apple's veclib. This is on an early 2009 17" MBP with a 2.93 Ghz Core 2 Duo (MacBookPro5,2) and 4Gb of RAM. 
> 
> Based upon Doug's comment in this thread that the issue may be related to the use of Apple's veclib BLAS, as opposed to R's reference BLAS, I ran some tests.
> 
> My config includes:
> 
>  --without-blas --without-lapack
> 
> just to be sure that the above is the correct invocation, based upon what I found online.
> 
> Using this build, with all CRAN packages freshly installed using this build, I ran the example used here with lme4 0.999375-35. I get:
> 
> library(lme4)
> y <- (1:20)*pi; x <- (1:20)^2;group <- gl(2,10)
> M2. <- lmer (y ~ 1 + x + (1 + x | group))
> M2 <- lmer (y ~ x + ( x | group))
> 
>> identical(fixef(M2), fixef(M2.))
> [1] TRUE
> 
> 
> 
> I then created a function so that I could use replicate() to run this test a "larger" number of times:
> 
> testlme4 <- function()
> { 
>  y <- (1:20)*pi; x <- (1:20)^2;group <- gl(2,10)
>  M2. <- lmer (y ~ 1 + x + (1 + x | group))
>  M2 <- lmer (y ~ x + ( x | group))
>  identical(fixef(M2), fixef(M2.))
> }
> 
> 
> RES <- replicate(1000, testlme4())
> 
>> all(RES)
> [1] TRUE
> 
>> table(RES)
> RES
> TRUE 
> 1000 
> 
> Does the example need to be run a "very large" number of times to be sure that it does not fail, or is the above a reasonable indication that the use of R's BLAS is a more appropriate default option for R on OSX?  If I am not mistaken (and somebody correct me if wrong), R's BLAS is the default on Windows and Linux (from my recollections on Fedora). Why should OSX be different in that regard?

Thanks for the very informative post. I added R-Mac in my reply to see if someone can come up with a response to your query. It would also be interesting to know if it were possible to switch the OSX R binary to use the R BLAS library.
> 
> Also, as an aside to Federico, I use 32 bit R on OSX largely because I have to interact with an Oracle server via RODBC. The only ODBC drivers available for Oracle on OSX are 32 bit and they are not compatible with 64 bit R. It would be rather cumbersome when running reports (via Sweave) to first extract the data in 32 bit R and then switch to 64 bit R to run the reports. I can run it all in a single step using 32 bit R. I also do not have a need for the larger memory address space afforded by 64 bit R.

I'm very primitive in any integration between R and anything else, so much so that I abandoned Emacs (well integrated with R) for Vim (not as well integrated). On the other hand I do need the greater memory address space of R64. I understand my needs and habits are not universally shared, but, if the *only* reason for using R32 vs R64 is the 20% speed difference, I'd use R64 for running lme4.

Best,

Federico


--
Federico C. F. Calboli
Department of Epidemiology and Biostatistics
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From minhuangr at gmail.com  Thu Oct 21 15:48:00 2010
From: minhuangr at gmail.com (huang min)
Date: Thu, 21 Oct 2010 21:48:00 +0800
Subject: [R-sig-ME] lme4 missing from repositories?
In-Reply-To: <A8F644A5-980E-4D46-80D2-2DFBEBD67032@me.com>
References: <D12D381C-DF9A-4406-9CD8-76806DD93817@cfenet.ubc.ca>
	<AANLkTikZ48i-1m3J3+Bzp1UEW6B7ttfgpt2zu07BA7GL@mail.gmail.com>
	<AANLkTikN70kiHuMCFZNcbNyhh4oYJQeorYviCh3xW7CL@mail.gmail.com>
	<AANLkTimKZTTUv3S12-uwoeL1Hrx5WzHAxioGVNLkxF3W@mail.gmail.com>
	<87312DEB-DFF3-40AF-B2F9-A9F365A0255A@imperial.ac.uk>
	<E84B04C7-E0F4-43D8-B9F4-B3917A4E2082@imperial.ac.uk>
	<AANLkTinukxno63fWnzC8=m=KV+ogJm-M_jirg3qPMxdd@mail.gmail.com>
	<AANLkTimHDGJUQm+9k_8ACaujknJGtZ19SWZCSk+SWhNi@mail.gmail.com>
	<AANLkTin8WxPh2wB9sO+=xuhvH3iEhAraRBeP_+qtmqne@mail.gmail.com>
	<08E6A2A9-68B0-4AE0-95B5-692E4ED5F104@imperial.ac.uk>
	<AANLkTinLYmO+PgTaP_=QRqqYkNHqdPtuO0vRhWxmBq=v@mail.gmail.com>
	<9F065CD6-D40E-40A2-940D-9F22452510DD@imperial.ac.uk>
	<A8F644A5-980E-4D46-80D2-2DFBEBD67032@me.com>
Message-ID: <AANLkTims7xnDuOFtz1UwCW5x0wHESsT0iiVcjfzCs3dN@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101021/8cec09c4/attachment.pl>

From marc_schwartz at me.com  Thu Oct 21 17:11:51 2010
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 21 Oct 2010 10:11:51 -0500
Subject: [R-sig-ME] lme4 missing from repositories?
In-Reply-To: <03837FFF-2087-45DF-98F7-7E2439777CF3@imperial.ac.uk>
References: <D12D381C-DF9A-4406-9CD8-76806DD93817@cfenet.ubc.ca>
	<AANLkTikZ48i-1m3J3+Bzp1UEW6B7ttfgpt2zu07BA7GL@mail.gmail.com>
	<AANLkTikN70kiHuMCFZNcbNyhh4oYJQeorYviCh3xW7CL@mail.gmail.com>
	<AANLkTimKZTTUv3S12-uwoeL1Hrx5WzHAxioGVNLkxF3W@mail.gmail.com>
	<87312DEB-DFF3-40AF-B2F9-A9F365A0255A@imperial.ac.uk>
	<E84B04C7-E0F4-43D8-B9F4-B3917A4E2082@imperial.ac.uk>
	<AANLkTinukxno63fWnzC8=m=KV+ogJm-M_jirg3qPMxdd@mail.gmail.com>
	<AANLkTimHDGJUQm+9k_8ACaujknJGtZ19SWZCSk+SWhNi@mail.gmail.com>
	<AANLkTin8WxPh2wB9sO+=xuhvH3iEhAraRBeP_+qtmqne@mail.gmail.com>
	<08E6A2A9-68B0-4AE0-95B5-692E4ED5F104@imperial.ac.uk>
	<AANLkTinLYmO+PgTaP_=QRqqYkNHqdPtuO0vRhWxmBq=v@mail.gmail.com>
	<9F065CD6-D40E-40A2-940D-9F22452510DD@imperial.ac.uk>
	<A8F644A5-980E-4D46-80D2-2DFBEBD67032@me.com>
	<03837FFF-2087-45DF-98F7-7E2439777CF3@imperial.ac.uk>
Message-ID: <CCE3BF74-362B-4385-8B4E-2CC1173A7910@me.com>


On Oct 21, 2010, at 8:47 AM, Federico Calboli wrote:

> Mark, 
>> 
>> To the extent that it may be helpful here and I can do more if need be, I built 32 bit R 2.12.0 patched on Snow Leopard (10.6.4), using the R BLAS rather than Apple's veclib. This is on an early 2009 17" MBP with a 2.93 Ghz Core 2 Duo (MacBookPro5,2) and 4Gb of RAM. 
>> 
>> Based upon Doug's comment in this thread that the issue may be related to the use of Apple's veclib BLAS, as opposed to R's reference BLAS, I ran some tests.
>> 
>> My config includes:
>> 
>> --without-blas --without-lapack
>> 
>> just to be sure that the above is the correct invocation, based upon what I found online.
>> 
>> Using this build, with all CRAN packages freshly installed using this build, I ran the example used here with lme4 0.999375-35. I get:
>> 
>> library(lme4)
>> y <- (1:20)*pi; x <- (1:20)^2;group <- gl(2,10)
>> M2. <- lmer (y ~ 1 + x + (1 + x | group))
>> M2 <- lmer (y ~ x + ( x | group))
>> 
>>> identical(fixef(M2), fixef(M2.))
>> [1] TRUE
>> 
>> 
>> 
>> I then created a function so that I could use replicate() to run this test a "larger" number of times:
>> 
>> testlme4 <- function()
>> { 
>> y <- (1:20)*pi; x <- (1:20)^2;group <- gl(2,10)
>> M2. <- lmer (y ~ 1 + x + (1 + x | group))
>> M2 <- lmer (y ~ x + ( x | group))
>> identical(fixef(M2), fixef(M2.))
>> }
>> 
>> 
>> RES <- replicate(1000, testlme4())
>> 
>>> all(RES)
>> [1] TRUE
>> 
>>> table(RES)
>> RES
>> TRUE 
>> 1000 
>> 
>> Does the example need to be run a "very large" number of times to be sure that it does not fail, or is the above a reasonable indication that the use of R's BLAS is a more appropriate default option for R on OSX?  If I am not mistaken (and somebody correct me if wrong), R's BLAS is the default on Windows and Linux (from my recollections on Fedora). Why should OSX be different in that regard?
> 
> Thanks for the very informative post. I added R-Mac in my reply to see if someone can come up with a response to your query. It would also be interesting to know if it were possible to switch the OSX R binary to use the R BLAS library.
>> 
>> Also, as an aside to Federico, I use 32 bit R on OSX largely because I have to interact with an Oracle server via RODBC. The only ODBC drivers available for Oracle on OSX are 32 bit and they are not compatible with 64 bit R. It would be rather cumbersome when running reports (via Sweave) to first extract the data in 32 bit R and then switch to 64 bit R to run the reports. I can run it all in a single step using 32 bit R. I also do not have a need for the larger memory address space afforded by 64 bit R.
> 
> I'm very primitive in any integration between R and anything else, so much so that I abandoned Emacs (well integrated with R) for Vim (not as well integrated). On the other hand I do need the greater memory address space of R64. I understand my needs and habits are not universally shared, but, if the *only* reason for using R32 vs R64 is the 20% speed difference, I'd use R64 for running lme4.



OK, so here is some more data.  I wondered if my build using R's BLAS may have possibly been a Type II error. So I re-built 32 bit R (same SVN checkout code) using:

  --with-blas='-framework vecLib' --with-lapack

I then completely removed my old R build (using R's BLAS) and the installed CRAN packages. I re-installed R using the above configuration and then cleanly re-installed the required CRAN packages.

Here are the results:

y <- (1:20)*pi; x <- (1:20)^2;group <- gl(2,10)
M2. <- lmer (y ~ 1 + x + (1 + x | group))
M2 <- lmer (y ~ x + ( x | group))

> identical(fixef(M2), fixef(M2.))
[1] FALSE

testlme4 <- function()
{ 
 y <- (1:20)*pi; x <- (1:20)^2;group <- gl(2,10)
 M2. <- lmer (y ~ 1 + x + (1 + x | group))
 M2 <- lmer (y ~ x + ( x | group))
 identical(fixef(M2), fixef(M2.))
}
 
RES <- replicate(1000, testlme4())

> all(RES)
[1] FALSE

> table(RES)
RES
FALSE  TRUE 
  496   504 

So the test in question seems to fail with P(Failure) ~ 0.5 using Apple's veclib BLAS.

I should also note that all of my testing is from the CLI using the OSX terminal. I do not use R.app.

In response to Huang's reply, regarding his use of the shared lib approach, I wonder if there is some other interaction going on, either in the BLAS libs, or perhaps in the installed version of lme4, when one BLAS versus the other is in use at the time of lme4 installation, since it is installed from source on OSX. Note that I used a fully clean build of R and the required CRAN packages for each set of tests. 

If there is some other testing that I can do, let me know. But the above results with a clean build of R and lme4 each time, would seem to further reinforce a reconsideration of the use of Apple's veclib BLAS as the default for CRAN binary builds of R on OSX.

Regards,

Marc



From simon.urbanek at r-project.org  Thu Oct 21 17:41:57 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 21 Oct 2010 11:41:57 -0400
Subject: [R-sig-ME] [R-SIG-Mac]  lme4 missing from repositories?
In-Reply-To: <03837FFF-2087-45DF-98F7-7E2439777CF3@imperial.ac.uk>
References: <D12D381C-DF9A-4406-9CD8-76806DD93817@cfenet.ubc.ca>
	<AANLkTikZ48i-1m3J3+Bzp1UEW6B7ttfgpt2zu07BA7GL@mail.gmail.com>
	<AANLkTikN70kiHuMCFZNcbNyhh4oYJQeorYviCh3xW7CL@mail.gmail.com>
	<AANLkTimKZTTUv3S12-uwoeL1Hrx5WzHAxioGVNLkxF3W@mail.gmail.com>
	<87312DEB-DFF3-40AF-B2F9-A9F365A0255A@imperial.ac.uk>
	<E84B04C7-E0F4-43D8-B9F4-B3917A4E2082@imperial.ac.uk>
	<AANLkTinukxno63fWnzC8=m=KV+ogJm-M_jirg3qPMxdd@mail.gmail.com>
	<AANLkTimHDGJUQm+9k_8ACaujknJGtZ19SWZCSk+SWhNi@mail.gmail.com>
	<AANLkTin8WxPh2wB9sO+=xuhvH3iEhAraRBeP_+qtmqne@mail.gmail.com>
	<08E6A2A9-68B0-4AE0-95B5-692E4ED5F104@imperial.ac.uk>
	<AANLkTinLYmO+PgTaP_=QRqqYkNHqdPtuO0vRhWxmBq=v@mail.gmail.com>
	<9F065CD6-D40E-40A2-940D-9F22452510DD@imperial.ac.uk>
	<A8F644A5-980E-4D46-80D2-2DFBEBD67032@me.com>
	<03837FFF-2087-45DF-98F7-7E2439777CF3@imperial.ac.uk>
Message-ID: <B9B2D62A-CECC-4374-9333-8962B37FCC74@r-project.org>


On Oct 21, 2010, at 9:47 AM, Federico Calboli wrote:

> Mark, 
>> 
>> To the extent that it may be helpful here and I can do more if need be, I built 32 bit R 2.12.0 patched on Snow Leopard (10.6.4), using the R BLAS rather than Apple's veclib. This is on an early 2009 17" MBP with a 2.93 Ghz Core 2 Duo (MacBookPro5,2) and 4Gb of RAM. 
>> 
>> Based upon Doug's comment in this thread that the issue may be related to the use of Apple's veclib BLAS, as opposed to R's reference BLAS, I ran some tests.
>> 
>> My config includes:
>> 
>> --without-blas --without-lapack
>> 
>> just to be sure that the above is the correct invocation, based upon what I found online.
>> 
>> Using this build, with all CRAN packages freshly installed using this build, I ran the example used here with lme4 0.999375-35. I get:
>> 
>> library(lme4)
>> y <- (1:20)*pi; x <- (1:20)^2;group <- gl(2,10)
>> M2. <- lmer (y ~ 1 + x + (1 + x | group))
>> M2 <- lmer (y ~ x + ( x | group))
>> 
>>> identical(fixef(M2), fixef(M2.))
>> [1] TRUE
>> 
>> 
>> 
>> I then created a function so that I could use replicate() to run this test a "larger" number of times:
>> 
>> testlme4 <- function()
>> { 
>> y <- (1:20)*pi; x <- (1:20)^2;group <- gl(2,10)
>> M2. <- lmer (y ~ 1 + x + (1 + x | group))
>> M2 <- lmer (y ~ x + ( x | group))
>> identical(fixef(M2), fixef(M2.))
>> }
>> 
>> 
>> RES <- replicate(1000, testlme4())
>> 
>>> all(RES)
>> [1] TRUE
>> 
>>> table(RES)
>> RES
>> TRUE 
>> 1000 
>> 
>> Does the example need to be run a "very large" number of times to be sure that it does not fail, or is the above a reasonable indication that the use of R's BLAS is a more appropriate default option for R on OSX?  If I am not mistaken (and somebody correct me if wrong), R's BLAS is the default on Windows and Linux (from my recollections on Fedora). Why should OSX be different in that regard?
> 
> Thanks for the very informative post. I added R-Mac in my reply to see if someone can come up with a response to your query. It would also be interesting to know if it were possible to switch the OSX R binary to use the R BLAS library.

Yes, see R for Mac FAQ 12.5.

Cheers,
Simon



>> 
>> Also, as an aside to Federico, I use 32 bit R on OSX largely because I have to interact with an Oracle server via RODBC. The only ODBC drivers available for Oracle on OSX are 32 bit and they are not compatible with 64 bit R. It would be rather cumbersome when running reports (via Sweave) to first extract the data in 32 bit R and then switch to 64 bit R to run the reports. I can run it all in a single step using 32 bit R. I also do not have a need for the larger memory address space afforded by 64 bit R.
> 
> I'm very primitive in any integration between R and anything else, so much so that I abandoned Emacs (well integrated with R) for Vim (not as well integrated). On the other hand I do need the greater memory address space of R64. I understand my needs and habits are not universally shared, but, if the *only* reason for using R32 vs R64 is the 20% speed difference, I'd use R64 for running lme4.
> 
> Best,
> 
> Federico
> 
> 
> --
> Federico C. F. Calboli
> Department of Epidemiology and Biostatistics
> Imperial College, St. Mary's Campus
> Norfolk Place, London W2 1PG
> 
> Tel +44 (0)20 75941602   Fax +44 (0)20 75943193
> 
> f.calboli [.a.t] imperial.ac.uk
> f.calboli [.a.t] gmail.com
> 
> _______________________________________________
> R-SIG-Mac mailing list
> R-SIG-Mac at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-mac
> 
> 



From minhuangr at gmail.com  Thu Oct 21 18:06:58 2010
From: minhuangr at gmail.com (huang min)
Date: Fri, 22 Oct 2010 00:06:58 +0800
Subject: [R-sig-ME] lme4 missing from repositories?
In-Reply-To: <CCE3BF74-362B-4385-8B4E-2CC1173A7910@me.com>
References: <D12D381C-DF9A-4406-9CD8-76806DD93817@cfenet.ubc.ca>
	<AANLkTikZ48i-1m3J3+Bzp1UEW6B7ttfgpt2zu07BA7GL@mail.gmail.com>
	<AANLkTikN70kiHuMCFZNcbNyhh4oYJQeorYviCh3xW7CL@mail.gmail.com>
	<AANLkTimKZTTUv3S12-uwoeL1Hrx5WzHAxioGVNLkxF3W@mail.gmail.com>
	<87312DEB-DFF3-40AF-B2F9-A9F365A0255A@imperial.ac.uk>
	<E84B04C7-E0F4-43D8-B9F4-B3917A4E2082@imperial.ac.uk>
	<AANLkTinukxno63fWnzC8=m=KV+ogJm-M_jirg3qPMxdd@mail.gmail.com>
	<AANLkTimHDGJUQm+9k_8ACaujknJGtZ19SWZCSk+SWhNi@mail.gmail.com>
	<AANLkTin8WxPh2wB9sO+=xuhvH3iEhAraRBeP_+qtmqne@mail.gmail.com>
	<08E6A2A9-68B0-4AE0-95B5-692E4ED5F104@imperial.ac.uk>
	<AANLkTinLYmO+PgTaP_=QRqqYkNHqdPtuO0vRhWxmBq=v@mail.gmail.com>
	<9F065CD6-D40E-40A2-940D-9F22452510DD@imperial.ac.uk>
	<A8F644A5-980E-4D46-80D2-2DFBEBD67032@me.com>
	<03837FFF-2087-45DF-98F7-7E2439777CF3@imperial.ac.uk>
	<CCE3BF74-362B-4385-8B4E-2CC1173A7910@me.com>
Message-ID: <AANLkTimg3baD50B18M2ZXah4P32q8RG+c5HA2ho+Qcu9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101022/330b8298/attachment.pl>

From ripley at stats.ox.ac.uk  Thu Oct 21 18:23:24 2010
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 21 Oct 2010 17:23:24 +0100 (BST)
Subject: [R-sig-ME] [R-SIG-Mac]  lme4 missing from repositories?
In-Reply-To: <CCE3BF74-362B-4385-8B4E-2CC1173A7910@me.com>
References: <D12D381C-DF9A-4406-9CD8-76806DD93817@cfenet.ubc.ca>
	<AANLkTikZ48i-1m3J3+Bzp1UEW6B7ttfgpt2zu07BA7GL@mail.gmail.com>
	<AANLkTikN70kiHuMCFZNcbNyhh4oYJQeorYviCh3xW7CL@mail.gmail.com>
	<AANLkTimKZTTUv3S12-uwoeL1Hrx5WzHAxioGVNLkxF3W@mail.gmail.com>
	<87312DEB-DFF3-40AF-B2F9-A9F365A0255A@imperial.ac.uk>
	<E84B04C7-E0F4-43D8-B9F4-B3917A4E2082@imperial.ac.uk>
	<AANLkTinukxno63fWnzC8=m=KV+ogJm-M_jirg3qPMxdd@mail.gmail.com>
	<AANLkTimHDGJUQm+9k_8ACaujknJGtZ19SWZCSk+SWhNi@mail.gmail.com>
	<AANLkTin8WxPh2wB9sO+=xuhvH3iEhAraRBeP_+qtmqne@mail.gmail.com>
	<08E6A2A9-68B0-4AE0-95B5-692E4ED5F104@imperial.ac.uk>
	<AANLkTinLYmO+PgTaP_=QRqqYkNHqdPtuO0vRhWxmBq=v@mail.gmail.com>
	<9F065CD6-D40E-40A2-940D-9F22452510DD@imperial.ac.uk>
	<A8F644A5-980E-4D46-80D2-2DFBEBD67032@me.com>
	<03837FFF-2087-45DF-98F7-7E2439777CF3@imperial.ac.uk>
	<CCE3BF74-362B-4385-8B4E-2CC1173A7910@me.com>
Message-ID: <alpine.LFD.2.00.1010211716220.7969@toucan.stats.ox.ac.uk>

Let me point out 
https://stat.ethz.ch/pipermail/r-sig-mac/2010-July/007608.html

This is not just a BLAS issue: I saw it with both vecLib and the 
reference BLAS.

The lme4 code is doing exactly the same calculation for M2. 
and M2, but sometimes when it does that calculation the first time in 
a session it gives a different answer.  That makes it really hard to 
get a handle on, and easy to suppose one has a fix (been there a few 
times myself).


On Thu, 21 Oct 2010, Marc Schwartz wrote:

>
> On Oct 21, 2010, at 8:47 AM, Federico Calboli wrote:
>
>> Mark,
>>>
>>> To the extent that it may be helpful here and I can do more if need be, I built 32 bit R 2.12.0 patched on Snow Leopard (10.6.4), using the R BLAS rather than Apple's veclib. This is on an early 2009 17" MBP with a 2.93 Ghz Core 2 Duo (MacBookPro5,2) and 4Gb of RAM.
>>>
>>> Based upon Doug's comment in this thread that the issue may be related to the use of Apple's veclib BLAS, as opposed to R's reference BLAS, I ran some tests.
>>>
>>> My config includes:
>>>
>>> --without-blas --without-lapack
>>>
>>> just to be sure that the above is the correct invocation, based upon what I found online.
>>>
>>> Using this build, with all CRAN packages freshly installed using this build, I ran the example used here with lme4 0.999375-35. I get:
>>>
>>> library(lme4)
>>> y <- (1:20)*pi; x <- (1:20)^2;group <- gl(2,10)
>>> M2. <- lmer (y ~ 1 + x + (1 + x | group))
>>> M2 <- lmer (y ~ x + ( x | group))
>>>
>>>> identical(fixef(M2), fixef(M2.))
>>> [1] TRUE
>>>
>>>
>>>
>>> I then created a function so that I could use replicate() to run this test a "larger" number of times:
>>>
>>> testlme4 <- function()
>>> {
>>> y <- (1:20)*pi; x <- (1:20)^2;group <- gl(2,10)
>>> M2. <- lmer (y ~ 1 + x + (1 + x | group))
>>> M2 <- lmer (y ~ x + ( x | group))
>>> identical(fixef(M2), fixef(M2.))
>>> }
>>>
>>>
>>> RES <- replicate(1000, testlme4())
>>>
>>>> all(RES)
>>> [1] TRUE
>>>
>>>> table(RES)
>>> RES
>>> TRUE
>>> 1000
>>>
>>> Does the example need to be run a "very large" number of times to be sure that it does not fail, or is the above a reasonable indication that the use of R's BLAS is a more appropriate default option for R on OSX?  If I am not mistaken (and somebody correct me if wrong), R's BLAS is the default on Windows and Linux (from my recollections on Fedora). Why should OSX be different in that regard?
>>
>> Thanks for the very informative post. I added R-Mac in my reply to see if someone can come up with a response to your query. It would also be interesting to know if it were possible to switch the OSX R binary to use the R BLAS library.
>>>
>>> Also, as an aside to Federico, I use 32 bit R on OSX largely because I have to interact with an Oracle server via RODBC. The only ODBC drivers available for Oracle on OSX are 32 bit and they are not compatible with 64 bit R. It would be rather cumbersome when running reports (via Sweave) to first extract the data in 32 bit R and then switch to 64 bit R to run the reports. I can run it all in a single step using 32 bit R. I also do not have a need for the larger memory address space afforded by 64 bit R.
>>
>> I'm very primitive in any integration between R and anything else, so much so that I abandoned Emacs (well integrated with R) for Vim (not as well integrated). On the other hand I do need the greater memory address space of R64. I understand my needs and habits are not universally shared, but, if the *only* reason for using R32 vs R64 is the 20% speed difference, I'd use R64 for running lme4.
>
>
>
> OK, so here is some more data.  I wondered if my build using R's BLAS may have possibly been a Type II error. So I re-built 32 bit R (same SVN checkout code) using:
>
>  --with-blas='-framework vecLib' --with-lapack
>
> I then completely removed my old R build (using R's BLAS) and the installed CRAN packages. I re-installed R using the above configuration and then cleanly re-installed the required CRAN packages.
>
> Here are the results:
>
> y <- (1:20)*pi; x <- (1:20)^2;group <- gl(2,10)
> M2. <- lmer (y ~ 1 + x + (1 + x | group))
> M2 <- lmer (y ~ x + ( x | group))
>
>> identical(fixef(M2), fixef(M2.))
> [1] FALSE
>
> testlme4 <- function()
> {
> y <- (1:20)*pi; x <- (1:20)^2;group <- gl(2,10)
> M2. <- lmer (y ~ 1 + x + (1 + x | group))
> M2 <- lmer (y ~ x + ( x | group))
> identical(fixef(M2), fixef(M2.))
> }
>
> RES <- replicate(1000, testlme4())
>
>> all(RES)
> [1] FALSE
>
>> table(RES)
> RES
> FALSE  TRUE
>  496   504
>
> So the test in question seems to fail with P(Failure) ~ 0.5 using Apple's veclib BLAS.
>
> I should also note that all of my testing is from the CLI using the OSX terminal. I do not use R.app.
>
> In response to Huang's reply, regarding his use of the shared lib approach, I wonder if there is some other interaction going on, either in the BLAS libs, or perhaps in the installed version of lme4, when one BLAS versus the other is in use at the time of lme4 installation, since it is installed from source on OSX. Note that I used a fully clean build of R and the required CRAN packages for each set of tests.
>
> If there is some other testing that I can do, let me know. But the above results with a clean build of R and lme4 each time, would seem to further reinforce a reconsideration of the use of Apple's veclib BLAS as the default for CRAN binary builds of R on OSX.
>
> Regards,
>
> Marc
>
> _______________________________________________
> R-SIG-Mac mailing list
> R-SIG-Mac at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-mac
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From marc_schwartz at me.com  Thu Oct 21 19:15:54 2010
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 21 Oct 2010 12:15:54 -0500
Subject: [R-sig-ME] [R-SIG-Mac]  lme4 missing from repositories?
In-Reply-To: <alpine.LFD.2.00.1010211716220.7969@toucan.stats.ox.ac.uk>
References: <D12D381C-DF9A-4406-9CD8-76806DD93817@cfenet.ubc.ca>
	<AANLkTikZ48i-1m3J3+Bzp1UEW6B7ttfgpt2zu07BA7GL@mail.gmail.com>
	<AANLkTikN70kiHuMCFZNcbNyhh4oYJQeorYviCh3xW7CL@mail.gmail.com>
	<AANLkTimKZTTUv3S12-uwoeL1Hrx5WzHAxioGVNLkxF3W@mail.gmail.com>
	<87312DEB-DFF3-40AF-B2F9-A9F365A0255A@imperial.ac.uk>
	<E84B04C7-E0F4-43D8-B9F4-B3917A4E2082@imperial.ac.uk>
	<AANLkTinukxno63fWnzC8=m=KV+ogJm-M_jirg3qPMxdd@mail.gmail.com>
	<AANLkTimHDGJUQm+9k_8ACaujknJGtZ19SWZCSk+SWhNi@mail.gmail.com>
	<AANLkTin8WxPh2wB9sO+=xuhvH3iEhAraRBeP_+qtmqne@mail.gmail.com>
	<08E6A2A9-68B0-4AE0-95B5-692E4ED5F104@imperial.ac.uk>
	<AANLkTinLYmO+PgTaP_=QRqqYkNHqdPtuO0vRhWxmBq=v@mail.gmail.com>
	<9F065CD6-D40E-40A2-940D-9F22452510DD@imperial.ac.uk>
	<A8F644A5-980E-4D46-80D2-2DFBEBD67032@me.com>
	<03837FFF-2087-45DF-98F7-7E2439777CF3@imperial.ac.uk>
	<CCE3BF74-362B-4385-8B4E-2CC1173A7910@me.com>
	<alpine.LFD.2.00.1010211716220.7969@toucan.stats.ox.ac.uk>
Message-ID: <D79192C5-44BD-4E65-AEBA-526DA36F89F4@me.com>

Interesting. No matter what I do here, I can't seem to get the test to fail using R's BLAS with clean 32 bit builds. So perhaps it is not just the BLAS, but a combination of R's BLAS and specific hardware?, which gets me into a realm of knowledge below the event horizon. 

Have there been any repeatable scenarios where vecLib can be used without failure on a particular Mac platform?

Also, I just noted Simon's reply to a different thread on r-sig-mac to Stefan Evert, in which he notes that there may be a change in the default BLAS for OSX to vecLib in the next R release. Of course, now given Prof. Ripley's observations, it will be interesting to see the actual impact in the wild.

Thanks,

Marc

On Oct 21, 2010, at 11:23 AM, Prof Brian Ripley wrote:

> Let me point out https://stat.ethz.ch/pipermail/r-sig-mac/2010-July/007608.html
> 
> This is not just a BLAS issue: I saw it with both vecLib and the reference BLAS.
> 
> The lme4 code is doing exactly the same calculation for M2. and M2, but sometimes when it does that calculation the first time in a session it gives a different answer.  That makes it really hard to get a handle on, and easy to suppose one has a fix (been there a few times myself).
> 
> 
> On Thu, 21 Oct 2010, Marc Schwartz wrote:
> 
>> 
>> On Oct 21, 2010, at 8:47 AM, Federico Calboli wrote:
>> 
>>> Mark,
>>>> 
>>>> To the extent that it may be helpful here and I can do more if need be, I built 32 bit R 2.12.0 patched on Snow Leopard (10.6.4), using the R BLAS rather than Apple's veclib. This is on an early 2009 17" MBP with a 2.93 Ghz Core 2 Duo (MacBookPro5,2) and 4Gb of RAM.
>>>> 
>>>> Based upon Doug's comment in this thread that the issue may be related to the use of Apple's veclib BLAS, as opposed to R's reference BLAS, I ran some tests.
>>>> 
>>>> My config includes:
>>>> 
>>>> --without-blas --without-lapack
>>>> 
>>>> just to be sure that the above is the correct invocation, based upon what I found online.
>>>> 
>>>> Using this build, with all CRAN packages freshly installed using this build, I ran the example used here with lme4 0.999375-35. I get:
>>>> 
>>>> library(lme4)
>>>> y <- (1:20)*pi; x <- (1:20)^2;group <- gl(2,10)
>>>> M2. <- lmer (y ~ 1 + x + (1 + x | group))
>>>> M2 <- lmer (y ~ x + ( x | group))
>>>> 
>>>>> identical(fixef(M2), fixef(M2.))
>>>> [1] TRUE
>>>> 
>>>> 
>>>> 
>>>> I then created a function so that I could use replicate() to run this test a "larger" number of times:
>>>> 
>>>> testlme4 <- function()
>>>> {
>>>> y <- (1:20)*pi; x <- (1:20)^2;group <- gl(2,10)
>>>> M2. <- lmer (y ~ 1 + x + (1 + x | group))
>>>> M2 <- lmer (y ~ x + ( x | group))
>>>> identical(fixef(M2), fixef(M2.))
>>>> }
>>>> 
>>>> 
>>>> RES <- replicate(1000, testlme4())
>>>> 
>>>>> all(RES)
>>>> [1] TRUE
>>>> 
>>>>> table(RES)
>>>> RES
>>>> TRUE
>>>> 1000
>>>> 
>>>> Does the example need to be run a "very large" number of times to be sure that it does not fail, or is the above a reasonable indication that the use of R's BLAS is a more appropriate default option for R on OSX?  If I am not mistaken (and somebody correct me if wrong), R's BLAS is the default on Windows and Linux (from my recollections on Fedora). Why should OSX be different in that regard?
>>> 
>>> Thanks for the very informative post. I added R-Mac in my reply to see if someone can come up with a response to your query. It would also be interesting to know if it were possible to switch the OSX R binary to use the R BLAS library.
>>>> 
>>>> Also, as an aside to Federico, I use 32 bit R on OSX largely because I have to interact with an Oracle server via RODBC. The only ODBC drivers available for Oracle on OSX are 32 bit and they are not compatible with 64 bit R. It would be rather cumbersome when running reports (via Sweave) to first extract the data in 32 bit R and then switch to 64 bit R to run the reports. I can run it all in a single step using 32 bit R. I also do not have a need for the larger memory address space afforded by 64 bit R.
>>> 
>>> I'm very primitive in any integration between R and anything else, so much so that I abandoned Emacs (well integrated with R) for Vim (not as well integrated). On the other hand I do need the greater memory address space of R64. I understand my needs and habits are not universally shared, but, if the *only* reason for using R32 vs R64 is the 20% speed difference, I'd use R64 for running lme4.
>> 
>> 
>> 
>> OK, so here is some more data.  I wondered if my build using R's BLAS may have possibly been a Type II error. So I re-built 32 bit R (same SVN checkout code) using:
>> 
>> --with-blas='-framework vecLib' --with-lapack
>> 
>> I then completely removed my old R build (using R's BLAS) and the installed CRAN packages. I re-installed R using the above configuration and then cleanly re-installed the required CRAN packages.
>> 
>> Here are the results:
>> 
>> y <- (1:20)*pi; x <- (1:20)^2;group <- gl(2,10)
>> M2. <- lmer (y ~ 1 + x + (1 + x | group))
>> M2 <- lmer (y ~ x + ( x | group))
>> 
>>> identical(fixef(M2), fixef(M2.))
>> [1] FALSE
>> 
>> testlme4 <- function()
>> {
>> y <- (1:20)*pi; x <- (1:20)^2;group <- gl(2,10)
>> M2. <- lmer (y ~ 1 + x + (1 + x | group))
>> M2 <- lmer (y ~ x + ( x | group))
>> identical(fixef(M2), fixef(M2.))
>> }
>> 
>> RES <- replicate(1000, testlme4())
>> 
>>> all(RES)
>> [1] FALSE
>> 
>>> table(RES)
>> RES
>> FALSE  TRUE
>> 496   504
>> 
>> So the test in question seems to fail with P(Failure) ~ 0.5 using Apple's veclib BLAS.
>> 
>> I should also note that all of my testing is from the CLI using the OSX terminal. I do not use R.app.
>> 
>> In response to Huang's reply, regarding his use of the shared lib approach, I wonder if there is some other interaction going on, either in the BLAS libs, or perhaps in the installed version of lme4, when one BLAS versus the other is in use at the time of lme4 installation, since it is installed from source on OSX. Note that I used a fully clean build of R and the required CRAN packages for each set of tests.
>> 
>> If there is some other testing that I can do, let me know. But the above results with a clean build of R and lme4 each time, would seem to further reinforce a reconsideration of the use of Apple's veclib BLAS as the default for CRAN binary builds of R on OSX.
>> 
>> Regards,
>> 
>> Marc
>> 
>> _______________________________________________
>> R-SIG-Mac mailing list
>> R-SIG-Mac at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mac
>> 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> _______________________________________________
> R-SIG-Mac mailing list
> R-SIG-Mac at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-mac



From jpntsang at yahoo.com  Fri Oct 22 00:22:58 2010
From: jpntsang at yahoo.com (Juliet Ndukum)
Date: Thu, 21 Oct 2010 15:22:58 -0700 (PDT)
Subject: [R-sig-ME] bootstrapping nonlinear mixed-effects model
Message-ID: <849716.795.qm@web53201.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101021/9ebee975/attachment.pl>

From aspxwong at gmail.com  Fri Oct 22 11:35:00 2010
From: aspxwong at gmail.com (wong)
Date: Fri, 22 Oct 2010 10:35:00 +0100
Subject: [R-sig-ME] Package for GLMM with correlation matrix
Message-ID: <AANLkTimhxT3J-zPPxz0jwiLA1nscG2yTBY4+kxgSBW4L@mail.gmail.com>

Hi,

I'm looking for a R package for fitting a generalized linear mixed model
    g(E[y])=X?+Zu
where g is a link function, ? is a p vector of fixed effects, u is a
vector of random effects, X is design matrix, Z is an identity matrix.
In our data, each individual has only one observation for response y.
Because individuals may be correlated in some way, leading to similar
reponses, random effect u is employed to correct for individual
background effect. The variance of u is assumed to be Var[u]=G*?^2, in
which G is a correlation matrix.

glmmPQL in MASS has an argument for correlation. However, I
encountered an error of invalid formula when using a n*n dimension
matrix G (n is the number of individuals, and also the length of y)
for argument 'correlation' in glmmPQL. For example:

> y=sample(c(1,0),48,replace=T);x=sample(1:4,48,replace=T);id=1:48;covMat=matrix(rnorm(48*48),nrow=48)
> glmmPQL(y~x,random=~1|id,family=binomial,correlation=covMat)
iteration 1
Error in formula.default(object) : invalid formula

The R help documentation for glmmPQL is very compact. No detailed
explanation. Does anybody know how to use correlation matrix in
glmmPQL? Is it good to use glmmPQL for fitting my model?

Thanks.

Alex



From bbolker at gmail.com  Fri Oct 22 14:49:32 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 22 Oct 2010 08:49:32 -0400
Subject: [R-sig-ME] Package for GLMM with correlation matrix
In-Reply-To: <AANLkTimhxT3J-zPPxz0jwiLA1nscG2yTBY4+kxgSBW4L@mail.gmail.com>
References: <AANLkTimhxT3J-zPPxz0jwiLA1nscG2yTBY4+kxgSBW4L@mail.gmail.com>
Message-ID: <4CC1885C.6070404@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

   See the documentation for lme (nlme package), specifically ?lme and
?corClasses .
Beyond that, see Pinheiro and Bates 2000 (Springer).

On 10-10-22 05:35 AM, wong wrote:
> Hi,
>
> I'm looking for a R package for fitting a generalized linear mixed
> model g(E[y])=X?+Zu where g is a link function, ? is a p vector of
> fixed effects, u is a vector of random effects, X is design matrix,
> Z is an identity matrix. In our data, each individual has only one
> observation for response y. Because individuals may be correlated
> in some way, leading to similar reponses, random effect u is
> employed to correct for individual background effect. The variance
> of u is assumed to be Var[u]=G*?^2, in which G is a correlation
> matrix.
>
> glmmPQL in MASS has an argument for correlation. However, I
> encountered an error of invalid formula when using a n*n dimension
> matrix G (n is the number of individuals, and also the length of
> y) for argument 'correlation' in glmmPQL. For example:
>
>>
y=sample(c(1,0),48,replace=T);x=sample(1:4,48,replace=T);id=1:48;covMat=matrix(rnorm(48*48),nrow=48)
>>
>>
glmmPQL(y~x,random=~1|id,family=binomial,correlation=covMat)
> iteration 1 Error in formula.default(object) : invalid formula
>
> The R help documentation for glmmPQL is very compact. No detailed
> explanation. Does anybody know how to use correlation matrix in
> glmmPQL? Is it good to use glmmPQL for fitting my model?
>
> Thanks.
>
> Alex
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iEYEARECAAYFAkzBiFwACgkQc5UpGjwzenNcGgCfSlBm9eQ7EBwncwlOrxOhFW3u
EMsAn2j5HS2gPIcmpY6s09ktd6cCeeFJ
=ntzB
-----END PGP SIGNATURE-----



From carina.salt at googlemail.com  Fri Oct 22 15:02:16 2010
From: carina.salt at googlemail.com (Carina Salt)
Date: Fri, 22 Oct 2010 14:02:16 +0100
Subject: [R-sig-ME] Equivalent option to 'nobound' in SAS
Message-ID: <AANLkTin92cpUuBGJv7Ny=cuZv0pWRKxZQZTcgRziaj4_@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101022/e43f95a8/attachment.pl>

From valerio.bartolino at gmail.com  Fri Oct 22 15:12:56 2010
From: valerio.bartolino at gmail.com (valerio.bartolino)
Date: Fri, 22 Oct 2010 15:12:56 +0200
Subject: [R-sig-ME] resolution as random effect
Message-ID: <1287753176.2022.7.camel@ubuntu.ubuntu-domain>

Dear list,
I've a question about a spatial regression model I'm working with. Here
is my problem and question:

I'm modeling the local densities of a species (y) as a second order
polynom of the geographical position (lon,lat), time (year), and a
certain number of other variables:

mod1 <- lm( y ~ ... + poly(lon,lat, degree=2)*as.factor(year))

Then, I know that the sampling has a certain spatial resolution, that I
can represent with a regular grid. Thus, I was thinking that
observations within the same cell of the grid (gr.id) cannot be
considered completely independent, and that this could be represented
with a random effect like:

mod2 <- lme( y ~ ... + poly(lon,lat, degree=2)*as.factor(year),
random=list(gr.id=~1))

An additional level of complexity within my formulation, is given by the
temporal resolution. Thus, I would like to group the spatial dependency
of observations from the same cell within certain time intervals
(time.gr). Here my problem comes. I'm a bit confused on how to formulate
exactly the random effect expressed above into time.gr groups. I have
alternative slightly different formulations in mind, but I miss their
difference in practice.

Thanks in advance for any help or advice.

Valerio


-- 
Valerio Bartolino, PhD

Institute of Marine Research - Swedish Board of Fisheries
PO Box 4, 45321 Lysekil, Sweden

Department of Earth Sciences - Gothenburg University
PO Box 460, 40530 G?teborg, Sweden

e-mail: valerio.bartolino at gvc.gu.se
        valerio.bartolino at gmail.com

><(((*> ----- ><(((*> ----- ><(((*> ----- ><(((*>



From bbolker at gmail.com  Fri Oct 22 15:30:13 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 22 Oct 2010 09:30:13 -0400
Subject: [R-sig-ME] Equivalent option to 'nobound' in SAS
In-Reply-To: <AANLkTin92cpUuBGJv7Ny=cuZv0pWRKxZQZTcgRziaj4_@mail.gmail.com>
References: <AANLkTin92cpUuBGJv7Ny=cuZv0pWRKxZQZTcgRziaj4_@mail.gmail.com>
Message-ID: <4CC191E5.3060200@gmail.com>

On 10-10-22 09:02 AM, Carina Salt wrote:
> Hi everyone
>
> I'm trying to analyse a dataset (in nlme) where - within group -
> measurements are taken at two different times.  Each measurement occasion
> yields two values (one at each level of a 2-level factor, called Type) that
> are negatively correlated.  I have been handling this negative correlation
> by using
>
> correlation = corCompSymm (form = ~ Type | Group / Time)
>
> However, I've been advised by a SAS-using colleague that in SAS he would
> simply include Time as a 2-level random factor (presumably nested or crossed
> with Group) then use the the NOBOUND option in PROCMIXED to remove the
> boundary constraints on estimates and allow estimated variance parameters to
> be negative - this would handle the negative variance in a way that
> including Time as a random factor in the usual way would not.
>
> So my question is whether there is an equivalent of NOBOUND in R (in nlme or
> lme4 - or in any other library that does linear mixed models)?  I have
> looked at the help files but can't see anything.  Also, if so, which is
> better - the NOBOUND approach or my current approach of specifying a
> correlation structure?
>
> Any help would be much appreciated!  And if this question has been asked
> before I apologise, but I couldn't find anything when I searched.
>
> Regards
> Carrie
>   

   I don't think this is an option in nlme or lme4.

   At the risk of sounding like one of those cranky R guys, it seems as
though
the solution you're using in nlme is reasonable/appropriate/mimics
the way that you actually think about the problem ("the two measurements
within a group at a particular time are negatively correlated"), while the
SAS approach is a kluge ("if I pretend one of these variances is
negative ..."). 
What are the advantages of the SAS-style negative variance approach? 
What do you mean by "...handle the negative variance in a way that
including
Time as a random factor in the usual way would not"?



From carina.salt at googlemail.com  Fri Oct 22 17:26:23 2010
From: carina.salt at googlemail.com (Carina Salt)
Date: Fri, 22 Oct 2010 16:26:23 +0100
Subject: [R-sig-ME] Equivalent option to 'nobound' in SAS
Message-ID: <AANLkTinNVTm=N7XztnKpq6QspKKbsgeJbJJgKXFkHh_R@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101022/76777ba8/attachment.pl>

From bbolker at gmail.com  Fri Oct 22 18:28:05 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 22 Oct 2010 12:28:05 -0400
Subject: [R-sig-ME] Package for GLMM with correlation matrix
In-Reply-To: <AANLkTinLtq3HUw8wJ5q6U2e1UnFPjgoVGAHJRbT50Xvm@mail.gmail.com>
References: <AANLkTimhxT3J-zPPxz0jwiLA1nscG2yTBY4+kxgSBW4L@mail.gmail.com>	<4CC1885C.6070404@gmail.com>
	<AANLkTinLtq3HUw8wJ5q6U2e1UnFPjgoVGAHJRbT50Xvm@mail.gmail.com>
Message-ID: <4CC1BB95.9070502@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101022/02254442/attachment.pl>

From bbolker at gmail.com  Fri Oct 22 23:53:45 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 22 Oct 2010 17:53:45 -0400
Subject: [R-sig-ME] Package for GLMM with correlation matrix
In-Reply-To: <AANLkTinEiUBBRZn0ymOi_ZULZ8_v5NqNwQhBKHy7BNhA@mail.gmail.com>
References: <AANLkTimhxT3J-zPPxz0jwiLA1nscG2yTBY4+kxgSBW4L@mail.gmail.com>	<4CC1885C.6070404@gmail.com>	<AANLkTinLtq3HUw8wJ5q6U2e1UnFPjgoVGAHJRbT50Xvm@mail.gmail.com>	<4CC1BB95.9070502@gmail.com>
	<AANLkTinEiUBBRZn0ymOi_ZULZ8_v5NqNwQhBKHy7BNhA@mail.gmail.com>
Message-ID: <4CC207E9.3070304@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

   Hmmm.
   Hard-coding your correlation matrix into glmmPQL by way of corSymm
should
be possible, but I think it could be quite tricky -- you would have to
read and understand
the Pinheiro and Bates paper referenced in ?corSymm, and really
understand the way that
corStruct objects are created and manipulated in nlme, in order to
have a shot at doing
this.
   There are several existing tools for pedigree-based mixed model
estimation (pedigreemm,
kinship, MCMCglmm), and some tools in R's phylogenetic packages (ape)
for integrating phylogenetic
information with glmmPQL (the methods section in the paper that
introduces the EMMA package
refers to these phylogenetic frameworks, which is why I mention this);
I would see if any of them
will serve your purpose ...

  good luck
    Ben Bolker


On 10-10-22 01:18 PM, wong wrote:
> Hi Ben,
>
> I want to test the association between non-normal response y and
> fixed effect predictor x with a correction for relatedness between
> indivdiuals (through incorporation of an individual-level random
> effect). The correlation matrix is already known or can be
> directly estimated from other means. Thers is no grouping of
> individuals here. There is a R package called EMMA that can fit
> such correlated random effect model for normally distributed
> response. However, EMMA can't handle non-normal response data.
>
> Thanks for your help.
>
> Alex
>
> 2010/10/22 Ben Bolker <bbolker at gmail.com>:
>> Reading the description of your problem more carefully: you want
>> a correlation structure but no random effect (or equivalently an
>> individual-level random effect, with no grouping)?  You may have
>> a hard time doing this: * gls (nlme package) fits generalized
>> least-squares problem (no ['G-side'] random effect, but
>> ['R-side'] correlation models) -- but 'generalized' here means
>> 'non-trivial correlations', not 'non-normal responses in the
>> exponential family' * glmer (lme4 package) allows
>> individual-level random effects in GLMMs, but not R-side
>> structures (the package author isn't sure how they would be
>> formulated sensibly in a GLMM context) * You could create an
>> individual-level random effect and use it in glmmPQL, but I would
>> proceed with great caution, e.g.:
>>
>> library(MASS) bacteria$ind <- 1:nrow(bacteria) g1 <- glmmPQL(y ~
>> trt + week + offset(week), random = ~ 1 | ind, family=binomial,
>> data=bacteria)
>>
>> Are you saying you have a fixed, known correlation matrix?  That
>> seems surprising, but if you want to do so you will probably have
>> quite a bit of work in front of you -- read the appropriate
>> chapter of Pinheiro and Bates 2000, then probably also read some
>> of their papers on defining correlation structures.
>>
>> I'm sorry this isn't easier, but it's not a common task.
>>
>> On 10-10-22 11:26 AM, wong wrote:
>>> Thanks ben.
>>>
>>> The argument correlation in glmmPQL is an optional corStruct
>>> object describing the within-group correlation structure.
>>> However, in my dataset, there is no grouping among individuals.
>>> Also, each individual has only one observation for response y.
>>> I don't know how to create a corStruct object from an existing
>>> n*n correlation matrix (n = the number of indivdiuals = length
>>> of y). What can I do now? The documentation for corClasses is
>>> not quite explicit.
>>>
>>> Alex
>>>
>>> 2010/10/22 Ben Bolker <bbolker at gmail.com>: See the
>>> documentation for lme (nlme package), specifically ?lme and
>>> ?corClasses . Beyond that, see Pinheiro and Bates 2000
>>> (Springer).
>>>
>>> On 10-10-22 05:35 AM, wong wrote:
>>>>>> Hi,
>>>>>>
>>>>>> I'm looking for a R package for fitting a generalized
>>>>>> linear mixed model g(E[y])=X?+Zu where g is a link
>>>>>> function, ? is a p vector of fixed effects, u is a vector
>>>>>> of random effects, X is design matrix, Z is an identity
>>>>>> matrix. In our data, each individual has only one
>>>>>> observation for response y. Because individuals may be
>>>>>> correlated in some way, leading to similar reponses,
>>>>>> random effect u is employed to correct for individual
>>>>>> background effect. The variance of u is assumed to be
>>>>>> Var[u]=G*?^2, in which G is a correlation matrix.
>>>>>>
>>>>>> glmmPQL in MASS has an argument for correlation. However,
>>>>>> I encountered an error of invalid formula when using a
>>>>>> n*n dimension matrix G (n is the number of individuals,
>>>>>> and also the length of y) for argument 'correlation' in
>>>>>> glmmPQL. For example:
>>>>>>
>>>>>>>
>>>
>>>
y=sample(c(1,0),48,replace=T);x=sample(1:4,48,replace=T);id=1:48;covMat=matrix(rnorm(48*48),nrow=48)
>>>
>>>
>>>
>>>>>>
>>>>>>>
>>>
>>>
glmmPQL(y~x,random=~1|id,family=binomial,correlation=covMat)
>>>>>> iteration 1 Error in formula.default(object) : invalid
>>>>>> formula
>>>>>>
>>>>>> The R help documentation for glmmPQL is very compact. No
>>>>>> detailed explanation. Does anybody know how to use
>>>>>> correlation matrix in glmmPQL? Is it good to use glmmPQL
>>>>>> for fitting my model?
>>>>>>
>>>>>> Thanks.
>>>>>>
>>>>>> Alex
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>
>>
>>
>
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iEYEARECAAYFAkzCB+kACgkQc5UpGjwzenPzwgCfW7OWexFazDXlGjiW+QGtKVN4
MvIAnRA+NQK0j6LS7FNka6pA6In/yCWb
=R9AB
-----END PGP SIGNATURE-----



From myaseen208 at gmail.com  Sat Oct 23 05:36:39 2010
From: myaseen208 at gmail.com (Muhammad Yaseen)
Date: Fri, 22 Oct 2010 20:36:39 -0700
Subject: [R-sig-ME] Convert SAS codes into R
Message-ID: <AANLkTi=3jDmG7CiuojWWPj2NHd8HuashpNWpu1GQ=HDG@mail.gmail.com>

Hi Dear,

I'd highly appreciate if someone can help me to convert these SAS
codes into R. Thanks



?/*-------------------------------------------------------*/
?/*---Data Set 11.5, Uniformity Trial ? ? ? ? ? ? ? ? ?---*/
data spatvar;
?? input rep bloc row col yield;
?? datalines;
1 ? ?4 ? 1 ? 1 ? ? 10.5411
1 ? ?4 ? 1 ? 2 ? ? ?8.5806
1 ? ?2 ? 1 ? 3 ? ? 11.2790
..........................
..........................
..........................
4 ? 15 ? 7 ? 8 ? ? 10.4298
4 ? 14 ? 8 ? 5 ? ? ?7.3220
4 ? 14 ? 8 ? 6 ? ? 10.5104
4 ? 15 ? 8 ? 7 ? ? 12.6808
4 ? 15 ? 8 ? 8 ? ? 10.4482
;
?/*-------------------------------------------------------*/

?/*-------------------------------------------------------*/
?/*---Output 11.1 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?---*/
title 'no nugget - spherical covariance model';
proc mixed data=spatvar;
?? model yield = ;
?? repeated / subject = intercept
?? ? ? ? ? ? ?type ? ?= sp(sph)(row col);
?? parms (0 to 10 by 2.5)
?? ? ? ? (1 to 10 by 3 ?);
?? ods select ParmSearch CovParms IterHistory
?? ? ? ? ? ? ?ConvergenceStatus FitStatistics LRT;
run;
?/*-------------------------------------------------------*/
?/*-------------------------------------------------------*/
?/*---Output 11.2 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?---*/
title 'no nugget - exponential covariance model';
proc mixed data=spatvar;
?? model yield = ;
?? repeated / subject = intercept
?? ? ? ? ? ? ?type ? ?= sp(exp)(row col);
?? parms (0 to 10 by 2.5)
?? ? ? ? (1 to 10 by 3 ?);
?? ods select CovParms FitStatistics;
run;
proc mixed data=spatvar;
?? model yield = ;
?? repeated / subject = intercept
?? ? ? ? ? ? ?type ? ?= sp(gau)(row col);
?? parms (0 to 10 by 2.5)
?? ? ? ? (1 to 10 by 3 ?);
?? ods select CovParms FitStatistics;
run;
?/*-------------------------------------------------------*/
?/*-------------------------------------------------------*/
?/*---Output 11.3 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?---*/
title 'rcb error model';
proc mixed data=spatvar;
?? class rep;
?? model yield = ;
?? random rep;
?? ods select CovParms FitStatistics;
run;

title 'incomplete block error model';
proc mixed data=spatvar;
?? class bloc;
?? model yield = ;
?? random bloc;
?? ods select CovParms FitStatistics;
run;
?/*-------------------------------------------------------*/
?/*-------------------------------------------------------*/
?/*---Outpuyt 11.4 a ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ---*/
title 'nugget effect - exponential covariance model';
proc mixed data=spatvar;
?? model yield = ;
?? repeated / subject = intercept
?? ? ? ? ? ? ?type ? ?= sp(exp)(row col)
?? ? ? ? ? ? ?local;
?? parms (0 ? ?to 10 ? ?by 2.5 )
?? ? ? ? (1 ? ?to 10 ? ?by 3 ? )
?? ? ? ? (0.05 to ?1.05 by 0.25);
?? ods select IterHistory ConvergenceStatus CovParms;
run;
?/*-------------------------------------------------------*/
?/*-------------------------------------------------------*/
?/*---Outpuyt 11.4 b ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ---*/
title 'nugget effect - exponential covariance model';
proc mixed data=spatvar convg=1e-7;
?? model yield = ;
?? repeated / subject = intercept
?? ? ? ? ? ? ?type ? ?= sp(exp)(row col)
?? ? ? ? ? ? ?local;
?? parms (0 ? ?to 10 ? ?by 2.5 )
?? ? ? ? (1 ? ?to 10 ? ?by 3 ? )
?? ? ? ? (0.05 to ?1.05 by 0.25);
?? ods select IterHistory ConvergenceStatus CovParms;
run;
?/*-------------------------------------------------------*/
?/*-------------------------------------------------------*/
?/*---Output 11.5 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?---*/
data spatvar; set spatvar;
??obs = _n_;
run;
proc mixed data=spatvar convg=1e-7;
?? class obs;
?? model yield = ;
?? random obs / type=sp(exp)(row col);
?? parms (0 ? ?to 10 ? by 2.5 )
?? ? ? ? (1 ? ?to 10 ? by 3 ? )
?? ? ? ? (0.05 to 1.05 by 0.25);
?? ods select Dimensions IterHistory ConvergenceStatus
?? ? ? ? ? ? ?FitStatistics CovParms;
run;
?/*-------------------------------------------------------*/

--

Muhammad Yaseen



From Mike.Lawrence at dal.ca  Sat Oct 23 23:19:49 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Sat, 23 Oct 2010 18:19:49 -0300
Subject: [R-sig-ME] Assessing linearity
Message-ID: <AANLkTik+J6GDvOx8mfZBotYbok7=BGwCWxVFe0PgDHEm@mail.gmail.com>

Hi folks,

I have developmental data collected across several grades (1-6). I
would like to be able to assess whether there are any linear or
non-linear trends across grade. Does it make sense to run a first lmer
treating grade as continuous, obtain the residuals, then run a second
lmer treating grade as a factor? That is:

fit1 = lmer(
    formula = response ~ (1|individual)+grade_as_numeric
    , data = my_data
    , family = gaussian
)
my_data$resid = residuals(fit1)
fit2 = lmer(
    formula = resid ~ (1|individual)+grade_as_factor
    , data = my_data
    , family = gaussian
)


As I understand it, fit1 will tell me if there are any linear trends
in the data, while fit2 will tell me if there are any non-linear
trends in the data in addition to the linear trends obtained in fit1.

If this is sensible, how might I apply it to a second binomial
response variable given that the residuals from a binomial model are
not 0/1?

Cheers,

Mike

--
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~



From j.hadfield at ed.ac.uk  Sun Oct 24 11:41:26 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sun, 24 Oct 2010 10:41:26 +0100
Subject: [R-sig-ME] Assessing linearity
In-Reply-To: <AANLkTik+J6GDvOx8mfZBotYbok7=BGwCWxVFe0PgDHEm@mail.gmail.com>
References: <AANLkTik+J6GDvOx8mfZBotYbok7=BGwCWxVFe0PgDHEm@mail.gmail.com>
Message-ID: <20101024104126.b079b4eits8c4wc8@www.staffmail.ed.ac.uk>

Hi Mike,

You would be better off trying out something like polynomials or  
splines, For example:

  fit1 = lmer(
      formula = response ~ (1|individual)+poly(grade_as_numeric,n),
      , data = my_data
      , family = gaussian
  )

where n is the order of the polynomial. n=1 would fit the same model  
as your original fit1, although the covariate (and the regression  
parameter) would be scaled by some number. When n=6 the model would be  
a reparameterised version of your model fit2. When 1<n<6 you would be  
working with a non-linear relationship in between these two extremes,  
although the model is still linear in the parameters.

Cheers,

Jarrod








Quoting Mike Lawrence <Mike.Lawrence at dal.ca>:

> Hi folks,
>
> I have developmental data collected across several grades (1-6). I
> would like to be able to assess whether there are any linear or
> non-linear trends across grade. Does it make sense to run a first lmer
> treating grade as continuous, obtain the residuals, then run a second
> lmer treating grade as a factor? That is:
>
> fit1 = lmer(
>     formula = response ~ (1|individual)+grade_as_numeric
>     , data = my_data
>     , family = gaussian
> )
> my_data$resid = residuals(fit1)
> fit2 = lmer(
>     formula = resid ~ (1|individual)+grade_as_factor
>     , data = my_data
>     , family = gaussian
> )
>
>
> As I understand it, fit1 will tell me if there are any linear trends
> in the data, while fit2 will tell me if there are any non-linear
> trends in the data in addition to the linear trends obtained in fit1.
>
> If this is sensible, how might I apply it to a second binomial
> response variable given that the residuals from a binomial model are
> not 0/1?
>
> Cheers,
>
> Mike
>
> --
> Mike Lawrence
> Graduate Student
> Department of Psychology
> Dalhousie University
>
> Looking to arrange a meeting? Check my public calendar:
> http://tr.im/mikes_public_calendar
>
> ~ Certainty is folly... I think. ~
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From ken.knoblauch at inserm.fr  Sun Oct 24 15:11:40 2010
From: ken.knoblauch at inserm.fr (Ken Knoblauch)
Date: Sun, 24 Oct 2010 13:11:40 +0000 (UTC)
Subject: [R-sig-ME] Assessing linearity
References: <AANLkTik+J6GDvOx8mfZBotYbok7=BGwCWxVFe0PgDHEm@mail.gmail.com>
Message-ID: <loom.20101024T150809-840@post.gmane.org>

Mike Lawrence <Mike.Lawrence at ...> writes:
> I have developmental data collected across several grades (1-6). I
> would like to be able to assess whether there are any linear or
> non-linear trends across grade. Does it make sense to run a first lmer
> treating grade as continuous, obtain the residuals, then run a second
> lmer treating grade as a factor? That is:
> 
> fit1 = lmer(
>     formula = response ~ (1|individual)+grade_as_numeric
>     , data = my_data
>     , family = gaussian
> )
> my_data$resid = residuals(fit1)
> fit2 = lmer(
>     formula = resid ~ (1|individual)+grade_as_factor
>     , data = my_data
>     , family = gaussian
> )
> 
> If this is sensible, how might I apply it to a second binomial
> response variable given that the residuals from a binomial model are
> not 0/1?
> 
> Mike
> Mike Lawrence
> Graduate Student
> Department of Psychology
> Dalhousie University
> 

Or just make grade and ordered factor and see whether there
are significant higher order terms.

If the response variable is binomial, why not use glmer with a
binomial family?

Ken 

-- 
Ken Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html



From Mike.Lawrence at dal.ca  Sun Oct 24 18:43:17 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Sun, 24 Oct 2010 13:43:17 -0300
Subject: [R-sig-ME] Assessing linearity
In-Reply-To: <20101024104126.b079b4eits8c4wc8@www.staffmail.ed.ac.uk>
References: <AANLkTik+J6GDvOx8mfZBotYbok7=BGwCWxVFe0PgDHEm@mail.gmail.com>
	<20101024104126.b079b4eits8c4wc8@www.staffmail.ed.ac.uk>
Message-ID: <AANLkTimYzkX5Xda3otAFbhiAmmKxmhdYUjJmRC1GaAfg@mail.gmail.com>

Ah, this looks promising! So how does this sound:

I typically assess the evidence for a relationship between the
predictor and response variables by comparing the AIC values for a
model including the predictor to a model without it. In the case of
grade_as_numeric, I'd do:

fit_null = lmer(
    formula = response ~ (1|individual)
    data = my_data
)
fit_null_AIC = AIC(fit_null)

fit_alt = lmer(
    formula = response ~ (1|individual) + grade_as_numeric
    data = my_data
)
fit_alt_AIC = AIC(fit_alt)

grade_loglikratio = fit_null_AIC - fit_alt_AIC

Now, if I wanted to check whether there is a quadratic component to
the grade effect, I'd first compute an analogous likelihood ratio for
the quadratic fit compared to the null:
fit_alt_quad = lmer(
    formula = response ~ (1|individual) + poly(grade_as_numeric)^2
    data = my_data
)
fit_alt_quad_AIC = AIC(fit_alt_quad)
grade_quad_loglikratio = fit_null_AIC - fit_alt_quad_AIC

Then compute a final log likelihood ratio between the improvement over
the null caused by grade versus the improvement over the null caused
by grade as a quadratic:

grade_lin_vs_quad_LLR = grade_loglikratio - grade_quad_loglikratio

I could repeat this for higher-order polynomials of grade, each
compared to the order directly below it, to develop a series of
likelihoood ratios that describe the relative improvement of the fit.

Does this sound appropriate?

Cheers,

Mike

--
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~



On Sun, Oct 24, 2010 at 6:41 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
> Hi Mike,
>
> You would be better off trying out something like polynomials or splines,
> For example:
>
> ?fit1 = lmer(
> ? ? formula = response ~ (1|individual)+poly(grade_as_numeric,n),
> ? ? , data = my_data
> ? ? , family = gaussian
> ?)
>
> where n is the order of the polynomial. n=1 would fit the same model as your
> original fit1, although the covariate (and the regression parameter) would
> be scaled by some number. When n=6 the model would be a reparameterised
> version of your model fit2. When 1<n<6 you would be working with a
> non-linear relationship in between these two extremes, although the model is
> still linear in the parameters.
>
> Cheers,
>
> Jarrod
>
>
>
>
>
>
>
>
> Quoting Mike Lawrence <Mike.Lawrence at dal.ca>:
>
>> Hi folks,
>>
>> I have developmental data collected across several grades (1-6). I
>> would like to be able to assess whether there are any linear or
>> non-linear trends across grade. Does it make sense to run a first lmer
>> treating grade as continuous, obtain the residuals, then run a second
>> lmer treating grade as a factor? That is:
>>
>> fit1 = lmer(
>> ? ?formula = response ~ (1|individual)+grade_as_numeric
>> ? ?, data = my_data
>> ? ?, family = gaussian
>> )
>> my_data$resid = residuals(fit1)
>> fit2 = lmer(
>> ? ?formula = resid ~ (1|individual)+grade_as_factor
>> ? ?, data = my_data
>> ? ?, family = gaussian
>> )
>>
>>
>> As I understand it, fit1 will tell me if there are any linear trends
>> in the data, while fit2 will tell me if there are any non-linear
>> trends in the data in addition to the linear trends obtained in fit1.
>>
>> If this is sensible, how might I apply it to a second binomial
>> response variable given that the residuals from a binomial model are
>> not 0/1?
>>
>> Cheers,
>>
>> Mike
>>
>> --
>> Mike Lawrence
>> Graduate Student
>> Department of Psychology
>> Dalhousie University
>>
>> Looking to arrange a meeting? Check my public calendar:
>> http://tr.im/mikes_public_calendar
>>
>> ~ Certainty is folly... I think. ~
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From A.Robinson at ms.unimelb.edu.au  Mon Oct 25 00:08:36 2010
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Mon, 25 Oct 2010 09:08:36 +1100
Subject: [R-sig-ME] Convert SAS codes into R
In-Reply-To: <AANLkTi=3jDmG7CiuojWWPj2NHd8HuashpNWpu1GQ=HDG@mail.gmail.com>
References: <AANLkTi=3jDmG7CiuojWWPj2NHd8HuashpNWpu1GQ=HDG@mail.gmail.com>
Message-ID: <20101024220836.GA407@ms.unimelb.edu.au>

Honestly, I don't think that this is a reasonable request.  That was
my initial reaction, but I wondered if I might just be being grumpy.
The long intervening silence implies that others think the same ... at
least some others ... 

So, Muhummad, apologies, but this is not a reasoanble request.  Good
luck finding a resolution elsewhere.

Andrew

On Fri, Oct 22, 2010 at 08:36:39PM -0700, Muhammad Yaseen wrote:
> Hi Dear,
> 
> I'd highly appreciate if someone can help me to convert these SAS
> codes into R. Thanks
> 
> 
> 
> ?/*-------------------------------------------------------*/
> ?/*---Data Set 11.5, Uniformity Trial ? ? ? ? ? ? ? ? ?---*/
> data spatvar;
> ?? input rep bloc row col yield;
> ?? datalines;
> 1 ? ?4 ? 1 ? 1 ? ? 10.5411
> 1 ? ?4 ? 1 ? 2 ? ? ?8.5806
> 1 ? ?2 ? 1 ? 3 ? ? 11.2790
> ..........................
> ..........................
> ..........................
> 4 ? 15 ? 7 ? 8 ? ? 10.4298
> 4 ? 14 ? 8 ? 5 ? ? ?7.3220
> 4 ? 14 ? 8 ? 6 ? ? 10.5104
> 4 ? 15 ? 8 ? 7 ? ? 12.6808
> 4 ? 15 ? 8 ? 8 ? ? 10.4482
> ;
> ?/*-------------------------------------------------------*/
> 
> ?/*-------------------------------------------------------*/
> ?/*---Output 11.1 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?---*/
> title 'no nugget - spherical covariance model';
> proc mixed data=spatvar;
> ?? model yield = ;
> ?? repeated / subject = intercept
> ?? ? ? ? ? ? ?type ? ?= sp(sph)(row col);
> ?? parms (0 to 10 by 2.5)
> ?? ? ? ? (1 to 10 by 3 ?);
> ?? ods select ParmSearch CovParms IterHistory
> ?? ? ? ? ? ? ?ConvergenceStatus FitStatistics LRT;
> run;
> ?/*-------------------------------------------------------*/
> ?/*-------------------------------------------------------*/
> ?/*---Output 11.2 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?---*/
> title 'no nugget - exponential covariance model';
> proc mixed data=spatvar;
> ?? model yield = ;
> ?? repeated / subject = intercept
> ?? ? ? ? ? ? ?type ? ?= sp(exp)(row col);
> ?? parms (0 to 10 by 2.5)
> ?? ? ? ? (1 to 10 by 3 ?);
> ?? ods select CovParms FitStatistics;
> run;
> proc mixed data=spatvar;
> ?? model yield = ;
> ?? repeated / subject = intercept
> ?? ? ? ? ? ? ?type ? ?= sp(gau)(row col);
> ?? parms (0 to 10 by 2.5)
> ?? ? ? ? (1 to 10 by 3 ?);
> ?? ods select CovParms FitStatistics;
> run;
> ?/*-------------------------------------------------------*/
> ?/*-------------------------------------------------------*/
> ?/*---Output 11.3 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?---*/
> title 'rcb error model';
> proc mixed data=spatvar;
> ?? class rep;
> ?? model yield = ;
> ?? random rep;
> ?? ods select CovParms FitStatistics;
> run;
> 
> title 'incomplete block error model';
> proc mixed data=spatvar;
> ?? class bloc;
> ?? model yield = ;
> ?? random bloc;
> ?? ods select CovParms FitStatistics;
> run;
> ?/*-------------------------------------------------------*/
> ?/*-------------------------------------------------------*/
> ?/*---Outpuyt 11.4 a ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ---*/
> title 'nugget effect - exponential covariance model';
> proc mixed data=spatvar;
> ?? model yield = ;
> ?? repeated / subject = intercept
> ?? ? ? ? ? ? ?type ? ?= sp(exp)(row col)
> ?? ? ? ? ? ? ?local;
> ?? parms (0 ? ?to 10 ? ?by 2.5 )
> ?? ? ? ? (1 ? ?to 10 ? ?by 3 ? )
> ?? ? ? ? (0.05 to ?1.05 by 0.25);
> ?? ods select IterHistory ConvergenceStatus CovParms;
> run;
> ?/*-------------------------------------------------------*/
> ?/*-------------------------------------------------------*/
> ?/*---Outpuyt 11.4 b ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ---*/
> title 'nugget effect - exponential covariance model';
> proc mixed data=spatvar convg=1e-7;
> ?? model yield = ;
> ?? repeated / subject = intercept
> ?? ? ? ? ? ? ?type ? ?= sp(exp)(row col)
> ?? ? ? ? ? ? ?local;
> ?? parms (0 ? ?to 10 ? ?by 2.5 )
> ?? ? ? ? (1 ? ?to 10 ? ?by 3 ? )
> ?? ? ? ? (0.05 to ?1.05 by 0.25);
> ?? ods select IterHistory ConvergenceStatus CovParms;
> run;
> ?/*-------------------------------------------------------*/
> ?/*-------------------------------------------------------*/
> ?/*---Output 11.5 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?---*/
> data spatvar; set spatvar;
> ??obs = _n_;
> run;
> proc mixed data=spatvar convg=1e-7;
> ?? class obs;
> ?? model yield = ;
> ?? random obs / type=sp(exp)(row col);
> ?? parms (0 ? ?to 10 ? by 2.5 )
> ?? ? ? ? (1 ? ?to 10 ? by 3 ? )
> ?? ? ? ? (0.05 to 1.05 by 0.25);
> ?? ods select Dimensions IterHistory ConvergenceStatus
> ?? ? ? ? ? ? ?FitStatistics CovParms;
> run;
> ?/*-------------------------------------------------------*/
> 
> --
> 
> Muhammad Yaseen
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Andrew Robinson  
Program Manager, ACERA 
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia               (prefer email)
http://www.ms.unimelb.edu.au/~andrewpr              Fax: +61-3-8344-4599
http://www.acera.unimelb.edu.au/



From drewdogy at uw.edu  Sun Oct 24 19:33:42 2010
From: drewdogy at uw.edu (Andrew Kosydar)
Date: Sun, 24 Oct 2010 13:33:42 -0400
Subject: [R-sig-ME] Assessing linearity
In-Reply-To: <AANLkTimYzkX5Xda3otAFbhiAmmKxmhdYUjJmRC1GaAfg@mail.gmail.com>
References: <AANLkTik+J6GDvOx8mfZBotYbok7=BGwCWxVFe0PgDHEm@mail.gmail.com>
	<20101024104126.b079b4eits8c4wc8@www.staffmail.ed.ac.uk>
	<AANLkTimYzkX5Xda3otAFbhiAmmKxmhdYUjJmRC1GaAfg@mail.gmail.com>
Message-ID: <AANLkTin9Cp=zAqN=dJREvzAtSCrORdF2oCVbgzYSnhKf@mail.gmail.com>

Hi Mike,

Sounds as though you are debating about model comparison techniques.
I would suggest using multimodel inference if you do not have any one
model that is strongly supported by AIC values.  Burnham & Anderson
published a book on the technique and they have two papers (2000 &
2002) that lay out the theoretical framework and methodology pretty
clearly.

Good luck!

Andrew



-- 
Andrew Kosydar, PhD
drewdogy at uw.edu







On Sun, Oct 24, 2010 at 12:43 PM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
> Ah, this looks promising! So how does this sound:
>
> I typically assess the evidence for a relationship between the
> predictor and response variables by comparing the AIC values for a
> model including the predictor to a model without it. In the case of
> grade_as_numeric, I'd do:
>
> fit_null = lmer(
> ? ?formula = response ~ (1|individual)
> ? ?data = my_data
> )
> fit_null_AIC = AIC(fit_null)
>
> fit_alt = lmer(
> ? ?formula = response ~ (1|individual) + grade_as_numeric
> ? ?data = my_data
> )
> fit_alt_AIC = AIC(fit_alt)
>
> grade_loglikratio = fit_null_AIC - fit_alt_AIC
>
> Now, if I wanted to check whether there is a quadratic component to
> the grade effect, I'd first compute an analogous likelihood ratio for
> the quadratic fit compared to the null:
> fit_alt_quad = lmer(
> ? ?formula = response ~ (1|individual) + poly(grade_as_numeric)^2
> ? ?data = my_data
> )
> fit_alt_quad_AIC = AIC(fit_alt_quad)
> grade_quad_loglikratio = fit_null_AIC - fit_alt_quad_AIC
>
> Then compute a final log likelihood ratio between the improvement over
> the null caused by grade versus the improvement over the null caused
> by grade as a quadratic:
>
> grade_lin_vs_quad_LLR = grade_loglikratio - grade_quad_loglikratio
>
> I could repeat this for higher-order polynomials of grade, each
> compared to the order directly below it, to develop a series of
> likelihoood ratios that describe the relative improvement of the fit.
>
> Does this sound appropriate?
>
> Cheers,
>
> Mike
>
> --
> Mike Lawrence
> Graduate Student
> Department of Psychology
> Dalhousie University
>
> Looking to arrange a meeting? Check my public calendar:
> http://tr.im/mikes_public_calendar
>
> ~ Certainty is folly... I think. ~
>
>
>
> On Sun, Oct 24, 2010 at 6:41 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>> Hi Mike,
>>
>> You would be better off trying out something like polynomials or splines,
>> For example:
>>
>> ?fit1 = lmer(
>> ? ? formula = response ~ (1|individual)+poly(grade_as_numeric,n),
>> ? ? , data = my_data
>> ? ? , family = gaussian
>> ?)
>>
>> where n is the order of the polynomial. n=1 would fit the same model as your
>> original fit1, although the covariate (and the regression parameter) would
>> be scaled by some number. When n=6 the model would be a reparameterised
>> version of your model fit2. When 1<n<6 you would be working with a
>> non-linear relationship in between these two extremes, although the model is
>> still linear in the parameters.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>>
>>
>>
>>
>>
>> Quoting Mike Lawrence <Mike.Lawrence at dal.ca>:
>>
>>> Hi folks,
>>>
>>> I have developmental data collected across several grades (1-6). I
>>> would like to be able to assess whether there are any linear or
>>> non-linear trends across grade. Does it make sense to run a first lmer
>>> treating grade as continuous, obtain the residuals, then run a second
>>> lmer treating grade as a factor? That is:
>>>
>>> fit1 = lmer(
>>> ? ?formula = response ~ (1|individual)+grade_as_numeric
>>> ? ?, data = my_data
>>> ? ?, family = gaussian
>>> )
>>> my_data$resid = residuals(fit1)
>>> fit2 = lmer(
>>> ? ?formula = resid ~ (1|individual)+grade_as_factor
>>> ? ?, data = my_data
>>> ? ?, family = gaussian
>>> )
>>>
>>>
>>> As I understand it, fit1 will tell me if there are any linear trends
>>> in the data, while fit2 will tell me if there are any non-linear
>>> trends in the data in addition to the linear trends obtained in fit1.
>>>
>>> If this is sensible, how might I apply it to a second binomial
>>> response variable given that the residuals from a binomial model are
>>> not 0/1?
>>>
>>> Cheers,
>>>
>>> Mike
>>>
>>> --
>>> Mike Lawrence
>>> Graduate Student
>>> Department of Psychology
>>> Dalhousie University
>>>
>>> Looking to arrange a meeting? Check my public calendar:
>>> http://tr.im/mikes_public_calendar
>>>
>>> ~ Certainty is folly... I think. ~
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From helixed2 at yahoo.com  Mon Oct 25 01:46:59 2010
From: helixed2 at yahoo.com (Jeremy Koster)
Date: Sun, 24 Oct 2010 16:46:59 -0700 (PDT)
Subject: [R-sig-ME] Numerical integration for cross-classified random
	effects in lme4
Message-ID: <370934.50182.qm@web58204.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101024/76bc88fc/attachment.pl>

From andydolman at gmail.com  Mon Oct 25 17:59:39 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Mon, 25 Oct 2010 17:59:39 +0200
Subject: [R-sig-ME] Assessing linearity
In-Reply-To: <AANLkTimYzkX5Xda3otAFbhiAmmKxmhdYUjJmRC1GaAfg@mail.gmail.com>
References: <AANLkTik+J6GDvOx8mfZBotYbok7=BGwCWxVFe0PgDHEm@mail.gmail.com>
	<20101024104126.b079b4eits8c4wc8@www.staffmail.ed.ac.uk>
	<AANLkTimYzkX5Xda3otAFbhiAmmKxmhdYUjJmRC1GaAfg@mail.gmail.com>
Message-ID: <AANLkTink=kJLZx_d8GeDmCkTi-c0VySew2cRZ+r30vbJ@mail.gmail.com>

Hi Mike,

Couple of things.

poly() is used like this

a <- rnorm(100)
b <- rnorm(100)

m2 <- lm(a~poly(b,2))
summary(m2)

To compare a model with a linear predictor and a quadratic polynomial
you can do this:
m0 <- lm(a~1)
m1 <- lm(a~poly(b,1))
m2 <- lm(a~poly(b,2))
anova(m1,m2)

In the case of likelihood fitted models you'll get a likelihood ratio test.


You wouldn't normally fit a quadratic term instead of the linear term,
rather in addition, so m2 has 1 extra parameter. You can compare
multiple models at once with anova(m0,m1,m2), or you can go the AIC
route and calculate deltaAIC for your set of candidate models.

Unless you expect the non-linearity to be polynomial shaped you might
be better off fitting splines with varying number of knots/df.



andydolman at gmail.com



On 24 October 2010 18:43, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
> Ah, this looks promising! So how does this sound:
>
> I typically assess the evidence for a relationship between the
> predictor and response variables by comparing the AIC values for a
> model including the predictor to a model without it. In the case of
> grade_as_numeric, I'd do:
>
> fit_null = lmer(
> ? ?formula = response ~ (1|individual)
> ? ?data = my_data
> )
> fit_null_AIC = AIC(fit_null)
>
> fit_alt = lmer(
> ? ?formula = response ~ (1|individual) + grade_as_numeric
> ? ?data = my_data
> )
> fit_alt_AIC = AIC(fit_alt)
>
> grade_loglikratio = fit_null_AIC - fit_alt_AIC
>
> Now, if I wanted to check whether there is a quadratic component to
> the grade effect, I'd first compute an analogous likelihood ratio for
> the quadratic fit compared to the null:
> fit_alt_quad = lmer(
> ? ?formula = response ~ (1|individual) + poly(grade_as_numeric)^2
> ? ?data = my_data
> )
> fit_alt_quad_AIC = AIC(fit_alt_quad)
> grade_quad_loglikratio = fit_null_AIC - fit_alt_quad_AIC
>
> Then compute a final log likelihood ratio between the improvement over
> the null caused by grade versus the improvement over the null caused
> by grade as a quadratic:
>
> grade_lin_vs_quad_LLR = grade_loglikratio - grade_quad_loglikratio
>
> I could repeat this for higher-order polynomials of grade, each
> compared to the order directly below it, to develop a series of
> likelihoood ratios that describe the relative improvement of the fit.
>
> Does this sound appropriate?
>
> Cheers,
>
> Mike
>
> --
> Mike Lawrence
> Graduate Student
> Department of Psychology
> Dalhousie University
>
> Looking to arrange a meeting? Check my public calendar:
> http://tr.im/mikes_public_calendar
>
> ~ Certainty is folly... I think. ~
>
>
>
> On Sun, Oct 24, 2010 at 6:41 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>> Hi Mike,
>>
>> You would be better off trying out something like polynomials or splines,
>> For example:
>>
>> ?fit1 = lmer(
>> ? ? formula = response ~ (1|individual)+poly(grade_as_numeric,n),
>> ? ? , data = my_data
>> ? ? , family = gaussian
>> ?)
>>
>> where n is the order of the polynomial. n=1 would fit the same model as your
>> original fit1, although the covariate (and the regression parameter) would
>> be scaled by some number. When n=6 the model would be a reparameterised
>> version of your model fit2. When 1<n<6 you would be working with a
>> non-linear relationship in between these two extremes, although the model is
>> still linear in the parameters.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>>
>>
>>
>>
>>
>> Quoting Mike Lawrence <Mike.Lawrence at dal.ca>:
>>
>>> Hi folks,
>>>
>>> I have developmental data collected across several grades (1-6). I
>>> would like to be able to assess whether there are any linear or
>>> non-linear trends across grade. Does it make sense to run a first lmer
>>> treating grade as continuous, obtain the residuals, then run a second
>>> lmer treating grade as a factor? That is:
>>>
>>> fit1 = lmer(
>>> ? ?formula = response ~ (1|individual)+grade_as_numeric
>>> ? ?, data = my_data
>>> ? ?, family = gaussian
>>> )
>>> my_data$resid = residuals(fit1)
>>> fit2 = lmer(
>>> ? ?formula = resid ~ (1|individual)+grade_as_factor
>>> ? ?, data = my_data
>>> ? ?, family = gaussian
>>> )
>>>
>>>
>>> As I understand it, fit1 will tell me if there are any linear trends
>>> in the data, while fit2 will tell me if there are any non-linear
>>> trends in the data in addition to the linear trends obtained in fit1.
>>>
>>> If this is sensible, how might I apply it to a second binomial
>>> response variable given that the residuals from a binomial model are
>>> not 0/1?
>>>
>>> Cheers,
>>>
>>> Mike
>>>
>>> --
>>> Mike Lawrence
>>> Graduate Student
>>> Department of Psychology
>>> Dalhousie University
>>>
>>> Looking to arrange a meeting? Check my public calendar:
>>> http://tr.im/mikes_public_calendar
>>>
>>> ~ Certainty is folly... I think. ~
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From Mike.Lawrence at dal.ca  Mon Oct 25 20:15:40 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Mon, 25 Oct 2010 15:15:40 -0300
Subject: [R-sig-ME] Assessing linearity
In-Reply-To: <AANLkTink=kJLZx_d8GeDmCkTi-c0VySew2cRZ+r30vbJ@mail.gmail.com>
References: <AANLkTik+J6GDvOx8mfZBotYbok7=BGwCWxVFe0PgDHEm@mail.gmail.com>
	<20101024104126.b079b4eits8c4wc8@www.staffmail.ed.ac.uk>
	<AANLkTimYzkX5Xda3otAFbhiAmmKxmhdYUjJmRC1GaAfg@mail.gmail.com>
	<AANLkTink=kJLZx_d8GeDmCkTi-c0VySew2cRZ+r30vbJ@mail.gmail.com>
Message-ID: <AANLkTi=Uf=_D7b3-p4sco6P69WWU4yrZW+N1xHAP9Q9u@mail.gmail.com>

Thanks Andrew. Jarrod mentioned using splines as well, and I do think
they sound promising since I indeed do not have strong a priori
reasons to expect polynomial shaped trends.

I'm uncertain, however, how to choose values for the "degree" and "df"
arguments to the bs. I see that df has to be equal-to-or greater than
degree, and less than the number of unique values in grade minus 2
(minus one makes it equivalent to factorizing grade, which I'm doing
already). I also see that degree=1 and df=1 is equivalent to the
linear case, which I'm already estimating in the original lmer fit.

However, that still leaves a large parameter space (df at degree:
2 at 1;3 at 1,4 at 1, 2 at 2, 3 at 2; 4 at 2; 3 at 3; 4 at 3; 4 at 4), and I'm not sure it's
appropriate to compare the linear case to fits from every point in
this space. Thoughts?

Mike


On Mon, Oct 25, 2010 at 12:59 PM, Andrew Dolman <andydolman at gmail.com> wrote:
> Hi Mike,
>
> Couple of things.
>
> poly() is used like this
>
> a <- rnorm(100)
> b <- rnorm(100)
>
> m2 <- lm(a~poly(b,2))
> summary(m2)
>
> To compare a model with a linear predictor and a quadratic polynomial
> you can do this:
> m0 <- lm(a~1)
> m1 <- lm(a~poly(b,1))
> m2 <- lm(a~poly(b,2))
> anova(m1,m2)
>
> In the case of likelihood fitted models you'll get a likelihood ratio test.
>
>
> You wouldn't normally fit a quadratic term instead of the linear term,
> rather in addition, so m2 has 1 extra parameter. You can compare
> multiple models at once with anova(m0,m1,m2), or you can go the AIC
> route and calculate deltaAIC for your set of candidate models.
>
> Unless you expect the non-linearity to be polynomial shaped you might
> be better off fitting splines with varying number of knots/df.
>
>
>
> andydolman at gmail.com
>
>
>
> On 24 October 2010 18:43, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
>> Ah, this looks promising! So how does this sound:
>>
>> I typically assess the evidence for a relationship between the
>> predictor and response variables by comparing the AIC values for a
>> model including the predictor to a model without it. In the case of
>> grade_as_numeric, I'd do:
>>
>> fit_null = lmer(
>> ? ?formula = response ~ (1|individual)
>> ? ?data = my_data
>> )
>> fit_null_AIC = AIC(fit_null)
>>
>> fit_alt = lmer(
>> ? ?formula = response ~ (1|individual) + grade_as_numeric
>> ? ?data = my_data
>> )
>> fit_alt_AIC = AIC(fit_alt)
>>
>> grade_loglikratio = fit_null_AIC - fit_alt_AIC
>>
>> Now, if I wanted to check whether there is a quadratic component to
>> the grade effect, I'd first compute an analogous likelihood ratio for
>> the quadratic fit compared to the null:
>> fit_alt_quad = lmer(
>> ? ?formula = response ~ (1|individual) + poly(grade_as_numeric)^2
>> ? ?data = my_data
>> )
>> fit_alt_quad_AIC = AIC(fit_alt_quad)
>> grade_quad_loglikratio = fit_null_AIC - fit_alt_quad_AIC
>>
>> Then compute a final log likelihood ratio between the improvement over
>> the null caused by grade versus the improvement over the null caused
>> by grade as a quadratic:
>>
>> grade_lin_vs_quad_LLR = grade_loglikratio - grade_quad_loglikratio
>>
>> I could repeat this for higher-order polynomials of grade, each
>> compared to the order directly below it, to develop a series of
>> likelihoood ratios that describe the relative improvement of the fit.
>>
>> Does this sound appropriate?
>>
>> Cheers,
>>
>> Mike
>>
>> --
>> Mike Lawrence
>> Graduate Student
>> Department of Psychology
>> Dalhousie University
>>
>> Looking to arrange a meeting? Check my public calendar:
>> http://tr.im/mikes_public_calendar
>>
>> ~ Certainty is folly... I think. ~
>>
>>
>>
>> On Sun, Oct 24, 2010 at 6:41 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>> Hi Mike,
>>>
>>> You would be better off trying out something like polynomials or splines,
>>> For example:
>>>
>>> ?fit1 = lmer(
>>> ? ? formula = response ~ (1|individual)+poly(grade_as_numeric,n),
>>> ? ? , data = my_data
>>> ? ? , family = gaussian
>>> ?)
>>>
>>> where n is the order of the polynomial. n=1 would fit the same model as your
>>> original fit1, although the covariate (and the regression parameter) would
>>> be scaled by some number. When n=6 the model would be a reparameterised
>>> version of your model fit2. When 1<n<6 you would be working with a
>>> non-linear relationship in between these two extremes, although the model is
>>> still linear in the parameters.
>>>
>>> Cheers,
>>>
>>> Jarrod
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> Quoting Mike Lawrence <Mike.Lawrence at dal.ca>:
>>>
>>>> Hi folks,
>>>>
>>>> I have developmental data collected across several grades (1-6). I
>>>> would like to be able to assess whether there are any linear or
>>>> non-linear trends across grade. Does it make sense to run a first lmer
>>>> treating grade as continuous, obtain the residuals, then run a second
>>>> lmer treating grade as a factor? That is:
>>>>
>>>> fit1 = lmer(
>>>> ? ?formula = response ~ (1|individual)+grade_as_numeric
>>>> ? ?, data = my_data
>>>> ? ?, family = gaussian
>>>> )
>>>> my_data$resid = residuals(fit1)
>>>> fit2 = lmer(
>>>> ? ?formula = resid ~ (1|individual)+grade_as_factor
>>>> ? ?, data = my_data
>>>> ? ?, family = gaussian
>>>> )
>>>>
>>>>
>>>> As I understand it, fit1 will tell me if there are any linear trends
>>>> in the data, while fit2 will tell me if there are any non-linear
>>>> trends in the data in addition to the linear trends obtained in fit1.
>>>>
>>>> If this is sensible, how might I apply it to a second binomial
>>>> response variable given that the residuals from a binomial model are
>>>> not 0/1?
>>>>
>>>> Cheers,
>>>>
>>>> Mike
>>>>
>>>> --
>>>> Mike Lawrence
>>>> Graduate Student
>>>> Department of Psychology
>>>> Dalhousie University
>>>>
>>>> Looking to arrange a meeting? Check my public calendar:
>>>> http://tr.im/mikes_public_calendar
>>>>
>>>> ~ Certainty is folly... I think. ~
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>>
>>>
>>>
>>>
>>> --
>>> The University of Edinburgh is a charitable body, registered in
>>> Scotland, with registration number SC005336.
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Mon Oct 25 20:49:16 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 25 Oct 2010 13:49:16 -0500
Subject: [R-sig-ME] Numerical integration for cross-classified random
 effects in lme4
In-Reply-To: <370934.50182.qm@web58204.mail.re3.yahoo.com>
References: <370934.50182.qm@web58204.mail.re3.yahoo.com>
Message-ID: <AANLkTin+WEC90SGhC7ZFKJ6aX05zs+zZC1YRJK+Z6rvY@mail.gmail.com>

On Sun, Oct 24, 2010 at 6:46 PM, Jeremy Koster <helixed2 at yahoo.com> wrote:
> Hi folks,
>
> This has likely been asked before, so please feel free to link any relevant posts . . .
>
> I am looking at a network of 300+ households.? The outcome variable is dichotomous -- i.e., does Household A share food with Household B?? Because food can flow both ways, one row in the dataset is for Household A to Household B, and then there's another row for B to A.? So I'd like to add a random effect for the dyad (DyadID).? In addition, some households just generally give more, and others generally receive more, so I'd like to add random effects for donating households (GNO) and receiving households (RNO).
>
> My impression was that it's possible to fit cross-classified random effects using numerical integration in lme4.? However, when I try to fit an empty model using this code:
>
> model.empty <- glmer (Sharing ~ 1 + (1|DyadID) + (1|GNO) + (1|RNO),family = binomial, nAGQ=10)
>
> Then I get the following error message:
>
> Error in validObject(.Object) :
> ? invalid class "mer" object: AGQ method requires a single grouping factor

As the message indicates, adaptive Gauss-Hermite quadrature is only
available for models with random effects defined with respect to a
single grouping factor.

When there is only one grouping factor the observations can be split
according to the levels of the grouping factor and the integral
defining the likelihood of the parameters can be expressed as the
product of a number of low-dimensional integrals.  You need low
dimensional, preferably one-dimensional, integrals before you can hope
to apply AGQ.  For high-dimensional integrals that number of
evaluations of the conditional mean that would be required for a
single evaluation of the likelihood of the parameters would be
prohibitive.

The Laplace approximation, which does require optimization of the
unscaled conditional density, but only requires evaluation of the
conditional mean at that point, is feasible for models with crossed
random effects.



From moorcroft19 at hotmail.co.uk  Mon Oct 25 21:29:16 2010
From: moorcroft19 at hotmail.co.uk (Chris Smith)
Date: Mon, 25 Oct 2010 20:29:16 +0100
Subject: [R-sig-ME] Poisson GLMM for cross-classified data - structure and
 method queries
Message-ID: <COL104-W43C017039683068F8D6544E9410@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101025/e4e14609/attachment.pl>

From andydolman at gmail.com  Tue Oct 26 15:18:01 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Tue, 26 Oct 2010 15:18:01 +0200
Subject: [R-sig-ME] Assessing linearity
In-Reply-To: <AANLkTi=Uf=_D7b3-p4sco6P69WWU4yrZW+N1xHAP9Q9u@mail.gmail.com>
References: <AANLkTik+J6GDvOx8mfZBotYbok7=BGwCWxVFe0PgDHEm@mail.gmail.com>
	<20101024104126.b079b4eits8c4wc8@www.staffmail.ed.ac.uk>
	<AANLkTimYzkX5Xda3otAFbhiAmmKxmhdYUjJmRC1GaAfg@mail.gmail.com>
	<AANLkTink=kJLZx_d8GeDmCkTi-c0VySew2cRZ+r30vbJ@mail.gmail.com>
	<AANLkTi=Uf=_D7b3-p4sco6P69WWU4yrZW+N1xHAP9Q9u@mail.gmail.com>
Message-ID: <AANLkTi=s3HvB19eSXcHEViFP+Lz1h4aQnKCae9rhuZ5S@mail.gmail.com>

Hi Mike,

I don't see why you would want to fit such a complicated trend to your
data. If you need anything more than a cubic then just treat grade as
a factor. I would start by fitting a model with natural splines ns(),
not bs() with 1 and 2 degrees of freedom and then see whether your 2
degree model fits better - this would be a reasonable test for
non-linearity in grade. If you expect the effect of grade to jump
around all over the place then treating it as a factor if probably
more appropriate. Even a cubic is probably overkill, do you expect
performance to ever decline with grade?



andydolman at gmail.com



On 25 October 2010 20:15, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
> Thanks Andrew. Jarrod mentioned using splines as well, and I do think
> they sound promising since I indeed do not have strong a priori
> reasons to expect polynomial shaped trends.
>
> I'm uncertain, however, how to choose values for the "degree" and "df"
> arguments to the bs. I see that df has to be equal-to-or greater than
> degree, and less than the number of unique values in grade minus 2
> (minus one makes it equivalent to factorizing grade, which I'm doing
> already). I also see that degree=1 and df=1 is equivalent to the
> linear case, which I'm already estimating in the original lmer fit.
>
> However, that still leaves a large parameter space (df at degree:
> 2 at 1;3 at 1,4 at 1, 2 at 2, 3 at 2; 4 at 2; 3 at 3; 4 at 3; 4 at 4), and I'm not sure it's
> appropriate to compare the linear case to fits from every point in
> this space. Thoughts?
>
> Mike
>
>
> On Mon, Oct 25, 2010 at 12:59 PM, Andrew Dolman <andydolman at gmail.com> wrote:
>> Hi Mike,
>>
>> Couple of things.
>>
>> poly() is used like this
>>
>> a <- rnorm(100)
>> b <- rnorm(100)
>>
>> m2 <- lm(a~poly(b,2))
>> summary(m2)
>>
>> To compare a model with a linear predictor and a quadratic polynomial
>> you can do this:
>> m0 <- lm(a~1)
>> m1 <- lm(a~poly(b,1))
>> m2 <- lm(a~poly(b,2))
>> anova(m1,m2)
>>
>> In the case of likelihood fitted models you'll get a likelihood ratio test.
>>
>>
>> You wouldn't normally fit a quadratic term instead of the linear term,
>> rather in addition, so m2 has 1 extra parameter. You can compare
>> multiple models at once with anova(m0,m1,m2), or you can go the AIC
>> route and calculate deltaAIC for your set of candidate models.
>>
>> Unless you expect the non-linearity to be polynomial shaped you might
>> be better off fitting splines with varying number of knots/df.
>>
>>
>>
>> andydolman at gmail.com
>>
>>
>>
>> On 24 October 2010 18:43, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
>>> Ah, this looks promising! So how does this sound:
>>>
>>> I typically assess the evidence for a relationship between the
>>> predictor and response variables by comparing the AIC values for a
>>> model including the predictor to a model without it. In the case of
>>> grade_as_numeric, I'd do:
>>>
>>> fit_null = lmer(
>>> ? ?formula = response ~ (1|individual)
>>> ? ?data = my_data
>>> )
>>> fit_null_AIC = AIC(fit_null)
>>>
>>> fit_alt = lmer(
>>> ? ?formula = response ~ (1|individual) + grade_as_numeric
>>> ? ?data = my_data
>>> )
>>> fit_alt_AIC = AIC(fit_alt)
>>>
>>> grade_loglikratio = fit_null_AIC - fit_alt_AIC
>>>
>>> Now, if I wanted to check whether there is a quadratic component to
>>> the grade effect, I'd first compute an analogous likelihood ratio for
>>> the quadratic fit compared to the null:
>>> fit_alt_quad = lmer(
>>> ? ?formula = response ~ (1|individual) + poly(grade_as_numeric)^2
>>> ? ?data = my_data
>>> )
>>> fit_alt_quad_AIC = AIC(fit_alt_quad)
>>> grade_quad_loglikratio = fit_null_AIC - fit_alt_quad_AIC
>>>
>>> Then compute a final log likelihood ratio between the improvement over
>>> the null caused by grade versus the improvement over the null caused
>>> by grade as a quadratic:
>>>
>>> grade_lin_vs_quad_LLR = grade_loglikratio - grade_quad_loglikratio
>>>
>>> I could repeat this for higher-order polynomials of grade, each
>>> compared to the order directly below it, to develop a series of
>>> likelihoood ratios that describe the relative improvement of the fit.
>>>
>>> Does this sound appropriate?
>>>
>>> Cheers,
>>>
>>> Mike
>>>
>>> --
>>> Mike Lawrence
>>> Graduate Student
>>> Department of Psychology
>>> Dalhousie University
>>>
>>> Looking to arrange a meeting? Check my public calendar:
>>> http://tr.im/mikes_public_calendar
>>>
>>> ~ Certainty is folly... I think. ~
>>>
>>>
>>>
>>> On Sun, Oct 24, 2010 at 6:41 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>>> Hi Mike,
>>>>
>>>> You would be better off trying out something like polynomials or splines,
>>>> For example:
>>>>
>>>> ?fit1 = lmer(
>>>> ? ? formula = response ~ (1|individual)+poly(grade_as_numeric,n),
>>>> ? ? , data = my_data
>>>> ? ? , family = gaussian
>>>> ?)
>>>>
>>>> where n is the order of the polynomial. n=1 would fit the same model as your
>>>> original fit1, although the covariate (and the regression parameter) would
>>>> be scaled by some number. When n=6 the model would be a reparameterised
>>>> version of your model fit2. When 1<n<6 you would be working with a
>>>> non-linear relationship in between these two extremes, although the model is
>>>> still linear in the parameters.
>>>>
>>>> Cheers,
>>>>
>>>> Jarrod
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> Quoting Mike Lawrence <Mike.Lawrence at dal.ca>:
>>>>
>>>>> Hi folks,
>>>>>
>>>>> I have developmental data collected across several grades (1-6). I
>>>>> would like to be able to assess whether there are any linear or
>>>>> non-linear trends across grade. Does it make sense to run a first lmer
>>>>> treating grade as continuous, obtain the residuals, then run a second
>>>>> lmer treating grade as a factor? That is:
>>>>>
>>>>> fit1 = lmer(
>>>>> ? ?formula = response ~ (1|individual)+grade_as_numeric
>>>>> ? ?, data = my_data
>>>>> ? ?, family = gaussian
>>>>> )
>>>>> my_data$resid = residuals(fit1)
>>>>> fit2 = lmer(
>>>>> ? ?formula = resid ~ (1|individual)+grade_as_factor
>>>>> ? ?, data = my_data
>>>>> ? ?, family = gaussian
>>>>> )
>>>>>
>>>>>
>>>>> As I understand it, fit1 will tell me if there are any linear trends
>>>>> in the data, while fit2 will tell me if there are any non-linear
>>>>> trends in the data in addition to the linear trends obtained in fit1.
>>>>>
>>>>> If this is sensible, how might I apply it to a second binomial
>>>>> response variable given that the residuals from a binomial model are
>>>>> not 0/1?
>>>>>
>>>>> Cheers,
>>>>>
>>>>> Mike
>>>>>
>>>>> --
>>>>> Mike Lawrence
>>>>> Graduate Student
>>>>> Department of Psychology
>>>>> Dalhousie University
>>>>>
>>>>> Looking to arrange a meeting? Check my public calendar:
>>>>> http://tr.im/mikes_public_calendar
>>>>>
>>>>> ~ Certainty is folly... I think. ~
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>>
>>>>
>>>>
>>>>
>>>> --
>>>> The University of Edinburgh is a charitable body, registered in
>>>> Scotland, with registration number SC005336.
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>



From bates at stat.wisc.edu  Tue Oct 26 19:06:02 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 26 Oct 2010 12:06:02 -0500
Subject: [R-sig-ME] Mac OS X binary for lme4 package now available on CRAN
Message-ID: <AANLkTi=SMi3MF9dyYU0TNeFQLExLjjbxJwZAts8aA_2+@mail.gmail.com>

Thanks to Martin Maechler and Simon Urbanek who installed changes to
bypass the problematic test on Mac OS X, the binary package of lme4 is
now available on CRAN.



From dmsilv at gmail.com  Tue Oct 26 19:44:43 2010
From: dmsilv at gmail.com (Daniel)
Date: Tue, 26 Oct 2010 15:44:43 -0200
Subject: [R-sig-ME] Mac OS X binary for lme4 package now available on
	CRAN
In-Reply-To: <AANLkTi=SMi3MF9dyYU0TNeFQLExLjjbxJwZAts8aA_2+@mail.gmail.com>
References: <AANLkTi=SMi3MF9dyYU0TNeFQLExLjjbxJwZAts8aA_2+@mail.gmail.com>
Message-ID: <AANLkTimSMvhq0pseS4vRw6Lz6TRXZho7pHKSS_UQH8w2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101026/07dda685/attachment.pl>

From helixed2 at yahoo.com  Wed Oct 27 16:35:00 2010
From: helixed2 at yahoo.com (Jeremy Koster)
Date: Wed, 27 Oct 2010 07:35:00 -0700 (PDT)
Subject: [R-sig-ME] Numerical integration for cross-classified random
	effects in lme4
In-Reply-To: <AANLkTin+WEC90SGhC7ZFKJ6aX05zs+zZC1YRJK+Z6rvY@mail.gmail.com>
Message-ID: <936023.33031.qm@web58201.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101027/6c20da84/attachment.pl>

From dps215 at psu.edu  Wed Oct 27 20:20:36 2010
From: dps215 at psu.edu (David Stainbrook)
Date: Wed, 27 Oct 2010 14:20:36 -0400
Subject: [R-sig-ME] help with model convergence
Message-ID: <1288203635l.1032266l.0l@psu.edu>

To whom it may concern,

I am having some issues with model convergence with linear mixed modeling. 
I am using mixed modeling with count data (GPS locations) for 30 individuals
and landscape characteristics as covariates to estimate resource selection. 

The technique I am using is similar to those outlined in:
 
  Normal
  0
  
  
  false
  false
  false
  
   
   
   
   
   
  
  MicrosoftInternetExplorer4
 

 
 


st1\:*{behavior:url(#ieooui) }



 /* Style Definitions */
 table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-parent:"";
	mso-padding-alt:0in 5.4pt 0in 5.4pt;
	mso-para-margin:0in;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:10.0pt;
	font-family:"Times New Roman";
	mso-ansi-language:#0400;
	mso-fareast-language:#0400;
	mso-bidi-language:#0400;}





Manly, B.F.J., L.L.
McDonald, D.L. Thomas, T.L. McDonald, and W.P. Erickson. 2002. Resource
selection by animals: Statistical design
and analysis for field studies, Second Edition. Kluwer Academic Publishers,
Dordrecht.


 
  Normal
  0
  
  
  false
  false
  false
  
   
   
   
   
   
  
  MicrosoftInternetExplorer4
 

 
 


 /* Style Definitions */
 table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-parent:"";
	mso-padding-alt:0in 5.4pt 0in 5.4pt;
	mso-para-margin:0in;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:10.0pt;
	font-family:"Times New Roman";
	mso-ansi-language:#0400;
	mso-fareast-language:#0400;
	mso-bidi-language:#0400;}







Sawyer, H., Nielson, R.M.,
Lindzey, F., & McDonald, L.L. (2006) Winter habitat selection of mule deer
before and during development of a natural gas field. Journal of Wildlife
Management, 70, 396-403.



However, these resource selection methods have not incorporated mixed modeling,
which is part of what I am trying to do with my graduate thesis. Basically, I
randomly place sampling units over my 11 square mile study area (3000 circles
that are 200 meters in diameter), and then count the number of GPS locs for
each individual in those sampling units. Then, measure the landscape covariates
for each of the 3000 sampling units. Then use mixed modeling to obtain the
parameter estimates, which I then use to plug into a finer scale model across
the landscape (5 x 5 meter grid) based on each cell's covariate values.

I have attached a zipped file that includes my R script and txt file of data
for the first survey - so that you can see all of my steps. One script includes
all of the models and the other includes only model 13 which includes all of
the covariates with squared terms, and was the best model based on AIC. Each
model adds another covariate or a squared term. The more complex models take a
really long time to run (e.g. - Model 13 takes a few days to run). 

There are 7 total surveys and so far only the first survey has worked. The
models for the rest of the surveys either have a false convergence error (8) or
a function evaluation limit reached without convergence (9) error. As you can
see in my script, I have centered and normalized all of the covariates to help
with convergence and added a bit to increase the default number of iterations.
Since most count data are overdispersed, I am using the quasipoisson
distribution  - I would prefer to use negative binomial, but this is currently
not possible with lmer. I am also using an offset term to constrain my Resource
Selection Values or probabilites between 0 and 1, which are calculated as e^Y.

Are you able to help me at all with my convergence issue or offer some other
pointers? I may need to send you the datasets from the other models so you can
see why I get these errors.

Here is the current version of R and lme4 - taken from the "super" computers at
Penn State that I am running the models on - they are running linux, so it's a
bit different than on my own computer, which is running Windows XP. 

> sessionInfo()
R version 2.11.1 (2010-05-31) 
x86_64-unknown-linux-gnu 

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] lme4_0.999375-33   Matrix_0.999375-39 lattice_0.18-8    

loaded via a namespace (and not attached):
[1] grid_2.11.1 nlme_3.1-96


Also, can you please keep this email confidential.

Thanks so much, this help will be tremendous. 

..................................................................

David P. Stainbrook
M.S. Graduate Research Assistant
Pennsylvania Cooperative Fish & Wildlife Research Unit
The Pennsylvania State University
221 Forest Resources Bldg
University Park, PA 16802
(814) 865-0772

..................................................................



From bbolker at gmail.com  Wed Oct 27 21:20:29 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 27 Oct 2010 15:20:29 -0400
Subject: [R-sig-ME] help with model convergence
In-Reply-To: <1288203635l.1032266l.0l@psu.edu>
References: <1288203635l.1032266l.0l@psu.edu>
Message-ID: <4CC87B7D.7030009@gmail.com>

On 10-10-27 02:20 PM, David Stainbrook wrote:
> To whom it may concern,
> 

> Also, can you please keep this email confidential.

  Hmmm.  How confidential did you want it?  This is an open mailing list
...  Not that I think anyone will intentionally propagate your data etc.
against your wishes, but the list is archived and the archives are open
to the world.  Sorry ...

  Ben Bolker



From datkins at u.washington.edu  Wed Oct 27 21:39:35 2010
From: datkins at u.washington.edu (David Atkins)
Date: Wed, 27 Oct 2010 12:39:35 -0700
Subject: [R-sig-ME] Numerical integration for cross-classified random
 effects in lme4
In-Reply-To: <936023.33031.qm@web58201.mail.re3.yahoo.com>
References: <936023.33031.qm@web58201.mail.re3.yahoo.com>
Message-ID: <4CC87FF7.7090106@u.washington.edu>


Jeremy--

Just to chime in here, I think the devil is almost always in the details 
of the specific data and model.  Thus, "Stata can 'do' AGQ for multiple 
random-effects" really does not mean too much outside of a specific set 
of data and model.

I recently assisted with an Epidemiology colleague who was trying to run 
a cross-classified GLMM with logit outcome and ~45K participants.  After 
24 hours Stata had made it through 4-5 iterations.  lmer() fit the model 
in 5 minutes.

At the same time, that example does not mean lmer() is universally 
superior for all models and datasets.  However, if you're talking 
cross-classified data... it probably is. ;)

As for MCMC, I would strongly recommend taking a look at MCMCglmm, which 
is a fully Bayesian package for generalized linear mixed models and very 
good.

For what it's worth...

cheers, Dave
-- 
Dave Atkins, PhD
Research Associate Professor
Department of Psychiatry and Behavioral Science
University of Washington
datkins at u.washington.edu

Center for the Study of Health and Risk Behaviors (CSHRB)		
1100 NE 45th Street, Suite 300 	
Seattle, WA  98105 	
206-616-3879 	
http://depts.washington.edu/cshrb/
(Mon-Wed)	

Center for Healthcare Improvement, for Addictions, Mental Illness,
   Medically Vulnerable Populations (CHAMMP)
325 9th Avenue, 2HH-15
Box 359911
Seattle, WA 98104
http://www.chammp.org
(Thurs)

Jeremy wrote:

Thanks for the clarification, Doug.

I asked a colleague about this the other day, and she indicated that it 
is possible to use numerical integration for multiple random effects in 
Stata . . . but she wasn't sure if that would apply to cross-classified 
models or perhaps just hierarchically nested random effects.

On a related note, I'd be interested in using MCMC estimation, and I 
remember reading a while ago that you were thinking about integrating 
that option in lme4.  Since then, I've seen some evidence that there's 
an mcmcsamp option, but I haven't been able to find any representative 
scripts so far.  Do you know of any examples that would be good to follow?

Thanks again.

--- On Mon, 10/25/10, Douglas Bates <bates at stat.wisc.edu> wrote:

From: Douglas Bates <bates at stat.wisc.edu>
Subject: Re: [R-sig-ME] Numerical integration for cross-classified 
random effects in lme4
To: "Jeremy Koster" <helixed2 at yahoo.com>
Cc: r-sig-mixed-models at r-project.org
Date: Monday, October 25, 2010, 2:49 PM

On Sun, Oct 24, 2010 at 6:46 PM, Jeremy Koster <helixed2 at yahoo.com> wrote:
 > Hi folks,
 >
 > This has likely been asked before, so please feel free to link any 
relevant posts . . .
 >
 > I am looking at a network of 300+ households.  The outcome variable 
is dichotomous -- i.e., does Household A share food with Household B? 
Because food can flow both ways, one row in the dataset is for Household 
A to Household B, and then there's another row for B to A.  So I'd like 
to add a random effect for the dyad (DyadID).  In addition, some 
households just generally give more, and others generally receive more, 
so I'd like to add random effects for donating households (GNO) and 
receiving households (RNO).
 >
 > My impression was that it's possible to fit cross-classified random 
effects using numerical integration in lme4.  However, when I try to fit 
an empty model using this code:
 >
 > model.empty <- glmer (Sharing ~ 1 + (1|DyadID) + (1|GNO) + 
(1|RNO),family = binomial, nAGQ=10)
 >
 > Then I get the following error message:
 >
 > Error in validObject(.Object) :
 >   invalid class "mer" object: AGQ method requires a single grouping 
factor

As the message indicates, adaptive Gauss-Hermite quadrature is only
available for models with random effects defined with respect to a
single grouping factor.

When there is only one grouping factor the observations can be split
according to the levels of the grouping factor and the integral
defining the likelihood of the parameters can be expressed as the
product of a number of low-dimensional integrals.  You need low
dimensional, preferably one-dimensional, integrals before you can hope
to apply AGQ.  For high-dimensional integrals that number of
evaluations of the conditional mean that would be required for a
single evaluation of the likelihood of the parameters would be
prohibitive.

The Laplace approximation, which does require optimization of the
unscaled conditional density, but only requires evaluation of the
conditional mean at that point, is feasible for models with crossed
random effects.




	[[alternative HTML version deleted]]



From emptican at gmail.com  Fri Oct 29 16:32:17 2010
From: emptican at gmail.com (Steve Hong)
Date: Fri, 29 Oct 2010 09:32:17 -0500
Subject: [R-sig-ME] analysis of count data with many zero values
Message-ID: <AANLkTikz+SrqTZpm646vuKEUmyFS2YKmmrOE633v+EtH@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101029/a016a1c1/attachment.pl>

From desja004 at umn.edu  Fri Oct 29 16:46:33 2010
From: desja004 at umn.edu (Christopher Desjardins)
Date: Fri, 29 Oct 2010 09:46:33 -0500
Subject: [R-sig-ME] analysis of count data with many zero values
In-Reply-To: <AANLkTikz+SrqTZpm646vuKEUmyFS2YKmmrOE633v+EtH@mail.gmail.com>
References: <AANLkTikz+SrqTZpm646vuKEUmyFS2YKmmrOE633v+EtH@mail.gmail.com>
Message-ID: <AANLkTimqPrTD8OD-dRDRzgBraMU8Lq-SagD5BENidVjG@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101029/78985c9c/attachment.pl>

From charpent at bacbuc.dyndns.org  Fri Oct 29 07:57:38 2010
From: charpent at bacbuc.dyndns.org (Emmanuel Charpentier)
Date: Fri, 29 Oct 2010 07:57:38 +0200
Subject: [R-sig-ME] Numerical integration for cross-classified random
 effects in lme4
In-Reply-To: <4CC87FF7.7090106@u.washington.edu>
References: <936023.33031.qm@web58201.mail.re3.yahoo.com>
	<4CC87FF7.7090106@u.washington.edu>
Message-ID: <1288331857.4800.130.camel@PortableToshiba>

Le mercredi 27 octobre 2010 ? 12:39 -0700, David Atkins a ?crit :
> Jeremy--
> 
> Just to chime in here, I think the devil is almost always in the details 
> of the specific data and model.  Thus, "Stata can 'do' AGQ for multiple 
> random-effects" really does not mean too much outside of a specific set 
> of data and model.
> 
> I recently assisted with an Epidemiology colleague who was trying to run 
> a cross-classified GLMM with logit outcome and ~45K participants.  After 
> 24 hours Stata had made it through 4-5 iterations.  lmer() fit the model 
> in 5 minutes.
> 
> At the same time, that example does not mean lmer() is universally 
> superior for all models and datasets.  However, if you're talking 
> cross-classified data... it probably is. ;)
> 
> As for MCMC, I would strongly recommend taking a look at MCMCglmm, which 
> is a fully Bayesian package for generalized linear mixed models and very 
> good.

Or biting the whole bullet (cannonball ?), building a BUGS model, lauch
it in JAGS and planning  long nice weekend trip... after having
validated the model on a "reasonable" random subset of the data against
a "first aproximtion" given by lme4, Stata or whatever is your fad of
the week.

					Emmanuel Charpentier



From Thierry.ONKELINX at inbo.be  Fri Oct 29 17:27:21 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Fri, 29 Oct 2010 17:27:21 +0200
Subject: [R-sig-ME] analysis of count data with many zero values
In-Reply-To: <AANLkTimqPrTD8OD-dRDRzgBraMU8Lq-SagD5BENidVjG@mail.gmail.com>
References: <AANLkTikz+SrqTZpm646vuKEUmyFS2YKmmrOE633v+EtH@mail.gmail.com>
	<AANLkTimqPrTD8OD-dRDRzgBraMU8Lq-SagD5BENidVjG@mail.gmail.com>
Message-ID: <3DB16098F738284D8DBEB2FC3699163846B66D@inboexch.inbo.be>

Hi Steve,

In addition to the comments of Chris, I would like to add the a high
number of zero's does not imply a zero-inflated distribution. Have a
look at the example below.

HTH,

Thierry


> set.seed(123)
> # ordinay poisson with 91% zero
> counts <- rpois(10000, lambda = 0.1)
> mean(counts == 0)
[1] 0.9105
> table(counts)
counts
   0    1    2    3 
9105  855   39    1 
> # ordinay poisson with 99% zero
> counts <- rpois(10000, lambda = 0.01)
> mean(counts == 0)
[1] 0.9912
> table(counts)
counts
   0    1 
9912   88 
> # ordinay poisson without zero
> counts <- rpois(10000, lambda = 10)
> mean(counts == 0)
[1] 0
> table(counts)
counts
   1    2    3    4    5    6    7    8    9   10 
   4   21   86  203  389  606  887 1144 1277 1243 
  11   12   13   14   15   16   17   18   19   20 
1147  904  707  553  367  218  108   75   36   10 
  21   22   24   27 
   9    4    1    1 
> # zero-inflated poisson with 50% zero's
> # 20% zero's from the inflation
> # 30% zero's from the poisson
> # 50% non-zero from the poisson
> zi <- rbinom(10000, prob = 0.2, size = 1)
> counts <- rpois(10000, lambda = 1)
> counts[zi == 1] <- 0
> mean(counts == 0)
[1] 0.4961
> table(counts)
counts
   0    1    2    3    4    5    6    7 
4961 2946 1463  472  129   25    3    1 

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens 
> Christopher Desjardins
> Verzonden: vrijdag 29 oktober 2010 16:47
> Aan: Steve Hong
> CC: r-sig-mixed-models at r-project.org
> Onderwerp: Re: [R-sig-ME] analysis of count data with many zero values
> 
> Hi Steve,
> 
> The MCMCglmm package has several different models that you 
> could fit to zero-inflated count data. You can fit 
> zero-inflated Poisson models, hurdle models, zero-alterated 
> and zero-truncated models. I don't believe you can fit 
> zero-inflated negative binomials with that package but I 
> could be wrong.
> Also I believe that ZINB models work well when you have 
> zero-inflated and non-zero overdispersed data. You could also 
> roll your own using rjags or r2winbugs, etc.
> 
> There are lots of publications out there examining 
> zero-inflation especially using MCMC based approaches. (Do a 
> quick Google Scholar search for zero-inflated multilevel 
> models). In addition, Jarrod Hadfield's CourseNotes (they 
> come w/ MCMCglmm) are also quite informative and provide some 
> examples of how you might fit such a model. In my experience 
> with count data that are highly zero-inflated (86% of all 
> data were zeroes), the ZIP model worked well but converged 
> very slowly and required about 60,000 MCMC iterations. If 
> you'd like to see the code I can share it as well. Also I 
> believe this topic has come up several times and I would 
> encourage to search through the archives of R-Sig-Mixed-Models.
> 
> HTH,
> Chris
> 
> 
> 
> 
> On Fri, Oct 29, 2010 at 9:32 AM, Steve Hong 
> <emptican at gmail.com> wrote:
> 
> > Dear list,
> >
> > This is the first time I have this type of data.  I have count data 
> > collected repeatedly from the same plot with multiple years 
> (14 yrs) 
> > and have found that proportion of 'zero' values are very 
> high (average 
> > of proportion is about 92 %, min: 53 %, max: 100 %).  Only one year 
> > has 53% of zeros in the data and the rest of years have at least 
> > greater than 86% zero values in the data set.
> >
> > The objective of the study is to develop predictive models and 
> > validate them, for example, using cross validation.
> >
> > Variables collected are: year, insect count, longitude, 
> latitude, soil 
> > properties (x1...x4).
> >
> > Since data have too many zero observations, I am thinking 
> about using 
> > zero inflated model to fit the data.  However, I am very 
> new to this method.
> >
> > My questions are:
> > 1. Is it possible to use zero inflated model to fit data with about 
> > 90% zeros?  I am wondering if zero proportion is too high 
> to make any 
> > inference using statistical methods.
> > 2. If I can use zero inflated models, can I use either Poisson 
> > distribution or negative binomial distribution?  Or both?
> > 3. Do you have any good reference (paper and/or website) 
> for good and 
> > 'easy'
> > tutorial for me to study?
> >
> > I am wondering if I provided enough information or submitted it to 
> > correct mailing list.  Please let me know if you have any 
> comments and suggestions.
> > I would greatly appreciate that.
> >
> > Thank you very much in advance!!!
> >
> > Steve
> >
> >        [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
> 
> 
> --
> Christopher David Desjardins
> Ph.D. student, Quantitative Methods in Education M.S. 
> student, Statistics University of Minnesota
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 



From annaradtke2309 at googlemail.com  Fri Oct 29 18:18:29 2010
From: annaradtke2309 at googlemail.com (Anna Radtke)
Date: Fri, 29 Oct 2010 18:18:29 +0200
Subject: [R-sig-ME] Tukey post hoc comparison (glht?) after 3factorial mixed
	model (lmer)
In-Reply-To: <AANLkTinHhgvo95RzZyEUdF6x6GOrMoMYVz-nEzvyEEt0@mail.gmail.com>
References: <AANLkTinHhgvo95RzZyEUdF6x6GOrMoMYVz-nEzvyEEt0@mail.gmail.com>
Message-ID: <AANLkTi=7QewfLPpmoHHfnZvPeKAjrH-oRVaEqoCukCnt@mail.gmail.com>

Hello, dear R-community.

This is a question about TukeyHSD between factor combinations of a Three-Way
ANOVA, which is - since it is a multi measure ANOVA - not a simple ANOVA but
a Generalised Linear Mixed Model (GLMM), calculated with "lmer".

> growth <-
groupedData(length~meas|box_id,outer=~spec*comp*water,data=all.spec)
> model <- lmer(length~spec*comp*water+(meas|box_id),data=growth)
> summary(model)

This works fine. But now, I would like to calculate Tukey HSD among certain
factor combinations. Formerly (before version 1.0), Tukey contrasts
including all levels of interactions could be calculated with the multcomp
package more or less automatically like this:

> summary (glht (model, linfct = mcp (spec*comp*water = "Tukey")))

Now, Mr Hothorn et al. have changed the function and it is "suggestet to the
users that they write out, manually, the set of contrasts they want". I
think that is not a bad idea, but I got problems with the syntax in my case.
And I would really grateful if anybody could help me. So far I tried:

> K <- cbind(0,diag(length(fixef(model))-1))
> rownames(K) <- names(fixef(model))[-1]
> model_glht <- glht(model,linfct=K)
> summary(model_glht)  # but actually this is not what I want

I'm rather looking for a Tukey output like this

specSt:compControl - specSt:compRoot         p that they are equal < 0.05
specSt:compControl - specSt:compShoot
specSt:compControl - specSt:compFull
specSt:compRoot - specSt:compShoot
specSt:compRoot - specSt:compFull
specSt:compShoot - specSt:compFull

and that for each of the 3 studied species, i.e. compare all-pairwise
combinations of the levels of the second factor within each level of the
first factor. We are not interested in the third factor, so data can be
averaged over that.


THANKS A LOT FOR ANY ADVICE, Sincerely

Anna Radtke



-----> model output:

Linear mixed model fit by REML
Formula: length ~ spec * comp * water + (meas | box_id)
   Data: growth
  AIC  BIC logLik deviance REMLdev
 4800 4909  -2372     4988    4744
Random effects:
 Groups   Name        Variance Std.Dev. Corr
 box_id   (Intercept)      0.0   0.000
          meas        222484.2 471.682    NaN
 Residual               9439.4  97.157
Number of obs: 360, groups: box_id, 120

Fixed effects:
                            Estimate Std. Error t value
(Intercept)                 -353.554     65.777  -5.375
specSt                      -103.111     93.023  -1.108
specSv                        -4.485     93.023  -0.048
comproot                     -41.686     93.023  -0.448
compshoot                    241.847     93.023   2.600
compxfull                    316.849     93.023   3.406
watermoist                   -48.620     93.023  -0.523
specSt:comproot               97.168    131.554   0.739
specSv:comproot               54.849    131.554   0.417
specSt:compshoot              10.416    131.554   0.079
specSv:compshoot               6.584    131.554   0.050
specSt:compxfull              90.949    131.554   0.691
specSv:compxfull              43.284    131.554   0.329
specSt:watermoist              9.222    131.554   0.070
specSv:watermoist            104.229    131.554   0.792
comproot:watermoist           15.931    131.554   0.121
compshoot:watermoist          28.999    131.554   0.220
compxfull:watermoist          39.363    131.554   0.299
specSt:comproot:watermoist    45.513    186.046   0.245
specSv:comproot:watermoist   -24.350    186.046  -0.131
specSt:compshoot:watermoist   46.027    186.046   0.247
specSv:compshoot:watermoist    1.232    186.046   0.007
specSt:compxfull:watermoist   23.749    186.046   0.128
specSv:compxfull:watermoist  -57.109    186.046  -0.307
-------------- next part --------------
"meas" "spec" "comp" "water" "box_id" "sprouts" "leaves" "length" "long.sprout"
"81" 1 "Sf" "xfull" "moist" 81 6.8 13.6 150.4 43.8
"82" 1 "Sf" "root" "moist" 82 6.5 18.5 104.25 25.75
"83" 1 "Sf" "control" "moist" 83 9.25 29 146 27
"84" 1 "Sf" "control" "moist" 84 6.8 31.4 163.8 46.6
"85" 1 "Sf" "shoot" "moist" 85 4.8 19.8 127.6 32.8
"86" 1 "Sf" "control" "moist" 86 8.2 30.6 144.4 31.6
"87" 1 "Sf" "root" "moist" 87 7.8 32.8 174 38.8
"88" 1 "Sf" "shoot" "moist" 88 5 8.5 54 22.25
"89" 1 "Sf" "xfull" "moist" 89 2.25 7 54.25 27
"90" 1 "Sf" "control" "moist" 90 5.6 21.2 103 30
"91" 1 "Sf" "shoot" "moist" 91 4.25 18 84.25 29.25
"92" 1 "Sf" "root" "moist" 92 5.8 26.4 133.2 33
"93" 1 "Sf" "shoot" "moist" 93 11.25 35.25 215 44.25
"94" 1 "Sf" "root" "moist" 94 6 17.33333333 90.66666667 19.33333333
"95" 1 "Sf" "root" "moist" 95 4.666666667 5.333333333 33.66666667 9.333333333
"96" 1 "Sf" "shoot" "moist" 96 6.5 11.5 88.25 25.5
"97" 1 "Sf" "xfull" "moist" 97 9.8 13 184.4 40.2
"98" 1 "Sf" "xfull" "moist" 98 5.8 15.2 156.6 41.6
"99" 1 "Sf" "control" "moist" 99 7.5 26.5 140.75 36.5
"100" 1 "Sf" "xfull" "moist" 100 4.2 10.4 91 41.2
"101" 1 "Sf" "control" "awater-logged" 101 9 35.8 222.2 43.6
"102" 1 "Sf" "shoot" "awater-logged" 102 10.8 40.6 245.4 47.6
"103" 1 "Sf" "xfull" "awater-logged" 103 4.6 10.6 134.6 47
"104" 1 "Sf" "shoot" "awater-logged" 104 8.2 35.4 263.4 56.2
"105" 1 "Sf" "xfull" "awater-logged" 105 8.4 8 207.8 45.6
"106" 1 "Sf" "control" "awater-logged" 106 8.5 38.5 243.25 45.25
"107" 1 "Sf" "root" "awater-logged" 107 9 41 205 43.2
"108" 1 "Sf" "shoot" "awater-logged" 108 8.4 24.6 170.4 39.2
"109" 1 "Sf" "root" "awater-logged" 109 8.8 29.2 176.4 31.4
"110" 1 "Sf" "control" "awater-logged" 110 7 28.8 167 44
"111" 1 "Sf" "shoot" "awater-logged" 111 10.2 41.2 283.4 50.6
"112" 1 "Sf" "root" "awater-logged" 112 8.6 35.6 211.6 37.4
"113" 1 "Sf" "root" "awater-logged" 113 10.6 39 221 44.6
"114" 1 "Sf" "xfull" "awater-logged" 114 8 11.8 253.6 64.4
"115" 1 "Sf" "shoot" "awater-logged" 115 8.4 25 148 30.6
"116" 1 "Sf" "control" "awater-logged" 116 8.6 37.2 213 46.6
"117" 1 "Sf" "root" "awater-logged" 117 9.8 28 165.4 35.4
"118" 1 "Sf" "xfull" "awater-logged" 118 6.2 2.6 124 34
"119" 1 "Sf" "control" "awater-logged" 119 6.2 25.6 145 39.8
"120" 1 "Sf" "xfull" "awater-logged" 120 8.5 9.75 247.25 62.25
"811" 2 "Sf" "xfull" "moist" 81 4.4 41.6 464.6 217.6
"821" 2 "Sf" "root" "moist" 82 4.6 58.4 800 271.8
"831" 2 "Sf" "control" "moist" 83 7 79.2 967.8 248.8
"841" 2 "Sf" "control" "moist" 84 5.8 68.6 923 256.4
"851" 2 "Sf" "shoot" "moist" 85 4.4 46.4 549.6 263.8
"861" 2 "Sf" "control" "moist" 86 6.8 81.2 1077 309
"871" 2 "Sf" "root" "moist" 87 6.6 72.6 914.8 307.4
"881" 2 "Sf" "shoot" "moist" 88 3 28.25 361 242
"891" 2 "Sf" "xfull" "moist" 89 2.2 19.8 221.8 139.2
"901" 2 "Sf" "control" "moist" 90 5.8 72.4 1038.4 328.6
"911" 2 "Sf" "shoot" "moist" 91 4.5 39 423.25 253.25
"921" 2 "Sf" "root" "moist" 92 4.8 66.8 930.8 296.8
"931" 2 "Sf" "shoot" "moist" 93 7.75 69.5 843 323.25
"941" 2 "Sf" "root" "moist" 94 5.75 56.75 710.75 205
"951" 2 "Sf" "root" "moist" 95 6.666666667 68.33333333 703.6666667 136.3333333
"961" 2 "Sf" "shoot" "moist" 96 4.5 40.5 524.5 235.25
"971" 2 "Sf" "xfull" "moist" 97 4.2 26.4 277.2 159.8
"981" 2 "Sf" "xfull" "moist" 98 2.2 17.6 197.2 143.6
"991" 2 "Sf" "control" "moist" 99 5.8 63.6 660.4 230
"1001" 2 "Sf" "xfull" "moist" 100 2.2 24.8 252.6 179.8
"1011" 2 "Sf" "control" "awater-logged" 101 6.8 87 1356.6 346.6
"1021" 2 "Sf" "shoot" "awater-logged" 102 7.4 73.2 887 350.8
"1031" 2 "Sf" "xfull" "awater-logged" 103 3.8 42 582.4 330
"1041" 2 "Sf" "shoot" "awater-logged" 104 6.2 66.8 818.4 381.8
"1051" 2 "Sf" "xfull" "awater-logged" 105 4.6 28.4 258.8 136
"1061" 2 "Sf" "control" "awater-logged" 106 6.8 78.8 957.8 286
"1071" 2 "Sf" "root" "awater-logged" 107 6.6 85.6 1345.2 351.2
"1081" 2 "Sf" "shoot" "awater-logged" 108 5.6 61 861.6 371
"1091" 2 "Sf" "root" "awater-logged" 109 6.2 71.8 1051.6 337.2
"1101" 2 "Sf" "control" "awater-logged" 110 5.8 67.2 992.4 338
"1111" 2 "Sf" "shoot" "awater-logged" 111 7 74.4 936 362.6
"1121" 2 "Sf" "root" "awater-logged" 112 6.8 110.6 1490.4 369.8
"1131" 2 "Sf" "root" "awater-logged" 113 7.8 89 1328.6 373.8
"1141" 2 "Sf" "xfull" "awater-logged" 114 3.8 28.4 330 165.8
"1151" 2 "Sf" "shoot" "awater-logged" 115 5.8 54 647 301.2
"1161" 2 "Sf" "control" "awater-logged" 116 7 83.4 1332.2 384
"1171" 2 "Sf" "root" "awater-logged" 117 7 83.6 1212 341
"1181" 2 "Sf" "xfull" "awater-logged" 118 4.6 28.2 405.2 193.8
"1191" 2 "Sf" "control" "awater-logged" 119 5.2 70 815.4 271
"1201" 2 "Sf" "xfull" "awater-logged" 120 6 45.25 507 205.75
"812" 3 "Sf" "xfull" "moist" 81 3.4 38.4 635.6 387.8
"822" 3 "Sf" "root" "moist" 82 4.8 64.2 1163 441.2
"832" 3 "Sf" "control" "moist" 83 5.2 78.2 1470.4 481.2
"842" 3 "Sf" "control" "moist" 84 4 72.2 1401.8 499.4
"852" 3 "Sf" "shoot" "moist" 85 2.4 40.8 797.8 519.2
"862" 3 "Sf" "control" "moist" 86 4.8 80.8 1562.6 563.6
"872" 3 "Sf" "root" "moist" 87 3.4 57.8 1224.8 499.4
"882" 3 "Sf" "shoot" "moist" 88 2.6 30 565 430
"892" 3 "Sf" "xfull" "moist" 89 2 25.4 435.2 362.4
"902" 3 "Sf" "control" "moist" 90 3.8 68.4 1353.8 508.4
"912" 3 "Sf" "shoot" "moist" 91 3.25 34.5 593 465.5
"922" 3 "Sf" "root" "moist" 92 4.6 73.8 1406.4 495.8
"932" 3 "Sf" "shoot" "moist" 93 3 43.4 873.2 516.6
"942" 3 "Sf" "root" "moist" 94 5 72.75 1301.25 457
"952" 3 "Sf" "root" "moist" 95 6.333333333 90.33333333 1401.333333 350.6666667
"962" 3 "Sf" "shoot" "moist" 96 2.25 39.75 738.25 433.75
"972" 3 "Sf" "xfull" "moist" 97 3.6 35.6 428.2 281
"982" 3 "Sf" "xfull" "moist" 98 3.4 28.8 412.6 303.8
"992" 3 "Sf" "control" "moist" 99 4.8 89.4 1151.4 443.8
"1002" 3 "Sf" "xfull" "moist" 100 2.2 29.2 467.4 377
"1012" 3 "Sf" "control" "awater-logged" 101 6 83.6 1659.4 473.2
"1022" 3 "Sf" "shoot" "awater-logged" 102 3.4 56.2 1122.4 566.2
"1032" 3 "Sf" "xfull" "awater-logged" 103 2.8 46.4 882.4 633.2
"1042" 3 "Sf" "shoot" "awater-logged" 104 4 58.8 1052.8 636.4
"1052" 3 "Sf" "xfull" "awater-logged" 105 3.6 40.6 516.6 345
"1062" 3 "Sf" "control" "awater-logged" 106 4.6 71.6 1441 509.8
"1072" 3 "Sf" "root" "awater-logged" 107 5.4 92.6 1879 609
"1082" 3 "Sf" "shoot" "awater-logged" 108 2.2 46.8 1038.8 639.2
"1092" 3 "Sf" "root" "awater-logged" 109 5.4 73.6 1364.8 538.4
"1102" 3 "Sf" "control" "awater-logged" 110 4.4 80.4 1382.6 548.6
"1112" 3 "Sf" "shoot" "awater-logged" 111 3.4 67.6 1403.4 632.4
"1122" 3 "Sf" "root" "awater-logged" 112 6.4 103.6 1917.2 504.2
"1132" 3 "Sf" "root" "awater-logged" 113 5 89.8 1817.8 606
"1142" 3 "Sf" "xfull" "awater-logged" 114 2.2 27.8 424.8 347
"1152" 3 "Sf" "shoot" "awater-logged" 115 1.6 30.8 646 523.4
"1162" 3 "Sf" "control" "awater-logged" 116 5.2 84.4 1804.8 598.2
"1172" 3 "Sf" "root" "awater-logged" 117 5.8 80 1388.4 461.2
"1182" 3 "Sf" "xfull" "awater-logged" 118 3.4 42.8 630.4 341.4
"1192" 3 "Sf" "control" "awater-logged" 119 3.8 82.4 1276.8 541.6
"1202" 3 "Sf" "xfull" "awater-logged" 120 3.75 57 870.75 483.75
"1" 1 "Sv" "control" "moist" 1 8.8 37.8 211.2 60.6
"2" 1 "Sv" "xfull" "moist" 2 7 8 174.8 62.8
"3" 1 "Sv" "control" "moist" 3 9 42 255.2 66
"4" 1 "Sv" "root" "moist" 4 7.8 35 225.8 78.2
"5" 1 "Sv" "root" "moist" 5 7.8 31.4 182.6 59.4
"6" 1 "Sv" "shoot" "moist" 6 8.8 50.8 247.6 53.4
"7" 1 "Sv" "root" "moist" 7 7 26.2 169.2 63
"8" 1 "Sv" "xfull" "moist" 8 4.6 4 71.8 35.8
"9" 1 "Sv" "root" "moist" 9 8.8 40 246.8 69.4
"10" 1 "Sv" "shoot" "moist" 10 8 48.2 266.8 67.6
"11" 1 "Sv" "control" "moist" 11 15 71.8 380.2 53.6
"12" 1 "Sv" "shoot" "moist" 12 10.4 41.2 271.8 58.6
"13" 1 "Sv" "shoot" "moist" 13 8.2 44 243.8 53.4
"14" 1 "Sv" "xfull" "moist" 14 6.2 10 171.6 67.2
"15" 1 "Sv" "root" "moist" 15 9.6 42.2 187.6 57.8
"16" 1 "Sv" "xfull" "moist" 16 6.2 7.8 164 63.6
"17" 1 "Sv" "control" "moist" 17 11 53.4 262.4 59.6
"18" 1 "Sv" "control" "moist" 18 8.8 45 245.4 63.8
"19" 1 "Sv" "xfull" "moist" 19 6.2 7.4 161 61.6
"20" 1 "Sv" "shoot" "moist" 20 9.4 38.4 209 74.8
"21" 1 "Sv" "root" "awater-logged" 21 8.6 42 252 75.2
"22" 1 "Sv" "shoot" "awater-logged" 22 7.8 34.8 238.8 80.8
"23" 1 "Sv" "control" "awater-logged" 23 9.75 37.25 182.25 55.5
"24" 1 "Sv" "control" "awater-logged" 24 8.2 51 287.2 77.8
"25" 1 "Sv" "control" "awater-logged" 25 8.5 45.25 290.5 85
"26" 1 "Sv" "xfull" "awater-logged" 26 8.8 11.6 204.4 58.8
"27" 1 "Sv" "shoot" "awater-logged" 27 6.6 22 138.6 68.6
"28" 1 "Sv" "shoot" "awater-logged" 28 10.4 34.4 225.2 70
"29" 1 "Sv" "root" "awater-logged" 29 5 22.4 113.4 60.2
"30" 1 "Sv" "control" "awater-logged" 30 7.4 38 220.4 73.8
"31" 1 "Sv" "xfull" "awater-logged" 31 7.6 5 143.8 54.8
"32" 1 "Sv" "xfull" "awater-logged" 32 3.6 10.2 124.6 74.2
"33" 1 "Sv" "xfull" "awater-logged" 33 7.2 6 162.6 60.8
"34" 1 "Sv" "shoot" "awater-logged" 34 7.4 26.4 210.4 86.2
"35" 1 "Sv" "root" "awater-logged" 35 8.6 34.8 257.6 81.6
"36" 1 "Sv" "root" "awater-logged" 36 9.4 31 196.2 70.4
"37" 1 "Sv" "root" "awater-logged" 37 6.8 34.2 204.4 85.4
"38" 1 "Sv" "xfull" "awater-logged" 38 7.2 6.6 151.6 66
"39" 1 "Sv" "shoot" "awater-logged" 39 7.6 39.6 227.4 63.8
"40" 1 "Sv" "control" "awater-logged" 40 8.4 51.6 257.6 78.6
"41" 2 "Sv" "control" "moist" 1 5.4 100.8 1104.4 392.6
"42" 2 "Sv" "xfull" "moist" 2 5.2 33.6 404.4 182.4
"43" 2 "Sv" "control" "moist" 3 6.4 108.6 1060 364.2
"44" 2 "Sv" "root" "moist" 4 5 91.4 1017.6 394.4
"45" 2 "Sv" "root" "moist" 5 5.2 78.4 772.4 312.4
"46" 2 "Sv" "shoot" "moist" 6 5.6 77.6 775.6 318
"47" 2 "Sv" "root" "moist" 7 4.6 73.2 730.2 314.4
"48" 2 "Sv" "xfull" "moist" 8 3.6 17.4 238.8 136.6
"49" 2 "Sv" "root" "moist" 9 4.6 94.2 980.4 366.8
"50" 2 "Sv" "shoot" "moist" 10 7.75 96.5 876.25 327
"51" 2 "Sv" "control" "moist" 11 10 127.2 1209.6 327.2
"52" 2 "Sv" "shoot" "moist" 12 7.4 83.4 818.6 314
"53" 2 "Sv" "shoot" "moist" 13 6.8 83.8 812.4 283.6
"54" 2 "Sv" "xfull" "moist" 14 3.8 29.8 325 183.4
"55" 2 "Sv" "root" "moist" 15 4.6 72.2 734.8 378
"56" 2 "Sv" "xfull" "moist" 16 2.6 24.4 282 189
"57" 2 "Sv" "control" "moist" 17 8 124.6 1246.8 371.4
"58" 2 "Sv" "control" "moist" 18 4.4 84.4 1061.4 377.2
"59" 2 "Sv" "xfull" "moist" 19 4.2 29 353.8 193.4
"60" 2 "Sv" "shoot" "moist" 20 5.6 74.4 743.2 378.8
"61" 2 "Sv" "root" "awater-logged" 21 6.6 93.6 912.4 351.6
"62" 2 "Sv" "shoot" "awater-logged" 22 4 62 714.8 401
"63" 2 "Sv" "control" "awater-logged" 23 5 82 881.6 323.2
"64" 2 "Sv" "control" "awater-logged" 24 5.6 110.8 1264.8 424.8
"65" 2 "Sv" "control" "awater-logged" 25 5.8 89.6 930.8 346.2
"66" 2 "Sv" "xfull" "awater-logged" 26 4 39.6 455.2 268.8
"67" 2 "Sv" "shoot" "awater-logged" 27 3.4 55.4 614.6 384.2
"68" 2 "Sv" "shoot" "awater-logged" 28 5.4 71 698 320.6
"69" 2 "Sv" "root" "awater-logged" 29 3 66.4 757.4 427.8
"70" 2 "Sv" "control" "awater-logged" 30 4.8 83 990.4 413.4
"71" 2 "Sv" "xfull" "awater-logged" 31 3.2 23.2 300.6 238.8
"72" 2 "Sv" "xfull" "awater-logged" 32 1.4 24.6 210.8 192.8
"73" 2 "Sv" "xfull" "awater-logged" 33 3.2 28.6 344.8 185.8
"74" 2 "Sv" "shoot" "awater-logged" 34 3.6 59.6 631 402
"75" 2 "Sv" "root" "awater-logged" 35 5.2 86.4 826.4 289.8
"76" 2 "Sv" "root" "awater-logged" 36 7.2 87.4 918.8 351
"77" 2 "Sv" "root" "awater-logged" 37 4.2 84.8 840 422
"78" 2 "Sv" "xfull" "awater-logged" 38 2.4 29.8 355.6 239.6
"79" 2 "Sv" "shoot" "awater-logged" 39 6.2 71.2 683.8 282
"80" 2 "Sv" "control" "awater-logged" 40 5.4 106.4 1083.6 388.6
"813" 3 "Sv" "control" "moist" 1 5.2 149.6 1863.8 682
"823" 3 "Sv" "xfull" "moist" 2 2.5 42.25 427.5 344.5
"833" 3 "Sv" "control" "moist" 3 4.2 134 1496.2 572
"843" 3 "Sv" "root" "moist" 4 3.6 121 1488.8 706.8
"853" 3 "Sv" "root" "moist" 5 4 115 1340.2 587.2
"863" 3 "Sv" "shoot" "moist" 6 2.6 80 976 613.2
"873" 3 "Sv" "root" "moist" 7 3.6 94.4 1187.2 555
"883" 3 "Sv" "xfull" "moist" 8 3.5 41.75 367 195.5
"893" 3 "Sv" "root" "moist" 9 3.6 120.2 1450.4 630.6
"903" 3 "Sv" "shoot" "moist" 10 2.6 85 1007.2 586
"913" 3 "Sv" "control" "moist" 11 4 118.8 1386 626.6
"923" 3 "Sv" "shoot" "moist" 12 2.2 72.4 942.6 578.4
"933" 3 "Sv" "shoot" "moist" 13 2.2 80.6 957.6 606
"943" 3 "Sv" "xfull" "moist" 14 1.25 27 308 297
"953" 3 "Sv" "root" "moist" 15 2.6 85.8 1080.2 676.8
"963" 3 "Sv" "xfull" "moist" 16 1.666666667 41 475.6666667 374
"973" 3 "Sv" "control" "moist" 17 4.4 148 1795.6 681.8
"983" 3 "Sv" "control" "moist" 18 3.4 107.8 1484.4 653.6
"993" 3 "Sv" "xfull" "moist" 19 2.4 49.8 450.6 326.2
"1003" 3 "Sv" "shoot" "moist" 20 2.8 73.6 896.2 663.8
"1013" 3 "Sv" "root" "awater-logged" 21 4.8 119 1431.6 585
"1023" 3 "Sv" "shoot" "awater-logged" 22 1.8 61.2 896.8 654
"1033" 3 "Sv" "control" "awater-logged" 23 4.6 123.8 1471.6 552
"1043" 3 "Sv" "control" "awater-logged" 24 5 144 1906.6 734.2
"1053" 3 "Sv" "control" "awater-logged" 25 3.4 107.8 1388.4 639
"1063" 3 "Sv" "xfull" "awater-logged" 26 1.8 53.2 586.8 439.4
"1073" 3 "Sv" "shoot" "awater-logged" 27 1.8 68.4 910.6 704.4
"1083" 3 "Sv" "shoot" "awater-logged" 28 3.4 88.2 1092 615
"1093" 3 "Sv" "root" "awater-logged" 29 2.8 101.2 1342.8 740.4
"1103" 3 "Sv" "control" "awater-logged" 30 4 125.4 1556.6 769.6
"1113" 3 "Sv" "xfull" "awater-logged" 31 2 52.2 534.8 451
"1123" 3 "Sv" "xfull" "awater-logged" 32 1.8 40.4 428.6 375.6
"1133" 3 "Sv" "xfull" "awater-logged" 33 2 41.2 420.6 295.6
"1143" 3 "Sv" "shoot" "awater-logged" 34 1.8 74.6 978.8 760.6
"1153" 3 "Sv" "root" "awater-logged" 35 4 110.8 1262.8 494.4
"1163" 3 "Sv" "root" "awater-logged" 36 6.4 129.2 1518.8 590.4
"1173" 3 "Sv" "root" "awater-logged" 37 4.6 124.6 1389.8 746
"1183" 3 "Sv" "xfull" "awater-logged" 38 2 39 472.6 398.4
"1193" 3 "Sv" "shoot" "awater-logged" 39 1.6 59.8 809.4 576.4
"1203" 3 "Sv" "control" "awater-logged" 40 4.4 134.6 1622.6 664.4
"413" 1 "St" "root" "moist" 41 4.6 17.6 83 35.2
"423" 1 "St" "xfull" "moist" 42 3 4.6 29.6 15.6
"433" 1 "St" "root" "moist" 43 5.333333333 26.33333333 110.3333333 52.33333333
"443" 1 "St" "control" "moist" 44 8 38 187 63.4
"453" 1 "St" "control" "moist" 45 5.6 23.8 96.4 38.8
"463" 1 "St" "root" "moist" 46 7.5 18.75 92.25 33
"473" 1 "St" "xfull" "moist" 47 6.333333333 8 73 23
"483" 1 "St" "shoot" "moist" 48 6.4 20.6 93.4 22.4
"493" 1 "St" "xfull" "moist" 49 6 2.6 63 15
"503" 1 "St" "xfull" "moist" 50 5.4 2.8 56.4 21.2
"513" 1 "St" "shoot" "moist" 51 8 24.33333333 117 42.33333333
"523" 1 "St" "shoot" "moist" 52 7 13.4 80 25.8
"533" 1 "St" "root" "moist" 53 4.5 16 66.25 31
"543" 1 "St" "control" "moist" 54 6.8 19.4 83.8 32.6
"553" 1 "St" "control" "moist" 55 9.25 36.75 158.5 34.25
"563" 1 "St" "control" "moist" 56 5.2 18.2 97.6 39
"573" 1 "St" "shoot" "moist" 57 6.25 12.75 55.75 25
"583" 1 "St" "shoot" "moist" 58 6.333333333 30.66666667 131.3333333 39
"593" 1 "St" "xfull" "moist" 59 5.8 7.8 69.2 28.6
"603" 1 "St" "root" "moist" 60 5 19.8 84 27.6
"613" 1 "St" "xfull" "awater-logged" 61 6.2 3.2 73.4 21
"623" 1 "St" "control" "awater-logged" 62 7.2 15 89.2 32
"633" 1 "St" "shoot" "awater-logged" 63 6.5 15.25 85.25 35
"643" 1 "St" "root" "awater-logged" 64 4.666666667 18.66666667 99 40.33333333
"653" 1 "St" "control" "awater-logged" 65 5.8 16.8 75.8 26.2
"663" 1 "St" "xfull" "awater-logged" 66 5.666666667 4 62.33333333 28.33333333
"673" 1 "St" "control" "awater-logged" 67 9 33.25 120 37
"683" 1 "St" "root" "awater-logged" 68 6 16 70 24.25
"693" 1 "St" "shoot" "awater-logged" 69 7 15.4 71.6 31.4
"703" 1 "St" "xfull" "awater-logged" 70 5.2 1.2 57.4 23.6
"713" 1 "St" "control" "awater-logged" 71 7.25 23.5 114 33
"723" 1 "St" "shoot" "awater-logged" 72 6.75 30.5 125 40.75
"733" 1 "St" "shoot" "awater-logged" 73 7.25 13.75 81.5 29.5
"743" 1 "St" "root" "awater-logged" 74 8.2 18.2 89.8 35.6
"753" 1 "St" "shoot" "awater-logged" 75 5.6 15.8 69.6 29.4
"763" 1 "St" "control" "awater-logged" 76 7.4 27.8 100.2 28.8
"773" 1 "St" "root" "awater-logged" 77 6.4 15.4 79.2 36
"783" 1 "St" "xfull" "awater-logged" 78 6.2 0.6 42.6 13.4
"793" 1 "St" "xfull" "awater-logged" 79 3.8 3.8 46.4 22.6
"803" 1 "St" "root" "awater-logged" 80 5.2 26 92.4 25.6
"411" 2 "St" "root" "moist" 41 3 45.6 658.4 364.8
"421" 2 "St" "xfull" "moist" 42 3.4 9.2 130 93.2
"431" 2 "St" "root" "moist" 43 3.25 36 520.75 382.25
"441" 2 "St" "control" "moist" 44 5.6 68.2 966.2 456.4
"451" 2 "St" "control" "moist" 45 4.8 60.4 765.4 347.8
"461" 2 "St" "root" "moist" 46 6.8 57.2 631.4 282.8
"471" 2 "St" "xfull" "moist" 47 4.8 10 133.8 50.8
"481" 2 "St" "shoot" "moist" 48 6.6 61.2 547.4 233.6
"491" 2 "St" "xfull" "moist" 49 7.6 24.6 241.2 88
"501" 2 "St" "xfull" "moist" 50 5.4 19.4 138.2 43
"511" 2 "St" "shoot" "moist" 51 5 42.4 353.8 188
"521" 2 "St" "shoot" "moist" 52 4.6 39.2 417 256
"531" 2 "St" "root" "moist" 53 3.75 51 607.75 298.25
"541" 2 "St" "control" "moist" 54 6.2 66.8 771.4 303.4
"551" 2 "St" "control" "moist" 55 7 79 998 398
"561" 2 "St" "control" "moist" 56 4.6 58.8 782.4 365
"571" 2 "St" "shoot" "moist" 57 4.4 37.6 331 143
"581" 2 "St" "shoot" "moist" 58 4.25 44.25 466.5 261.25
"591" 2 "St" "xfull" "moist" 59 6.6 18.8 160.6 64.6
"601" 2 "St" "root" "moist" 60 3.8 49 668.8 311
"611" 2 "St" "xfull" "awater-logged" 61 6 17.8 204.2 96.4
"621" 2 "St" "control" "awater-logged" 62 4.2 56.8 800.4 353.6
"631" 2 "St" "shoot" "awater-logged" 63 3.5 45 534 305
"641" 2 "St" "root" "awater-logged" 64 4.666666667 61.33333333 665.6666667 338.6666667
"651" 2 "St" "control" "awater-logged" 65 4.2 58.8 759 323.2
"661" 2 "St" "xfull" "awater-logged" 66 4.5 14.25 171 97
"671" 2 "St" "control" "awater-logged" 67 5.5 72 851.5 363
"681" 2 "St" "root" "awater-logged" 68 5.75 62.75 616.75 262.25
"691" 2 "St" "shoot" "awater-logged" 69 3.2 41.6 587.8 415.4
"701" 2 "St" "xfull" "awater-logged" 70 3.8 14 141.4 79.8
"711" 2 "St" "control" "awater-logged" 71 4.2 57 774 298.2
"721" 2 "St" "shoot" "awater-logged" 72 3.8 41.4 468.4 227.2
"731" 2 "St" "shoot" "awater-logged" 73 3.75 42.25 492.25 235
"741" 2 "St" "root" "awater-logged" 74 4.4 52.4 691.2 342
"751" 2 "St" "shoot" "awater-logged" 75 2.4 30.6 379.4 294.2
"761" 2 "St" "control" "awater-logged" 76 6.6 80.2 966.6 340.6
"771" 2 "St" "root" "awater-logged" 77 3.4 38 526.8 361.2
"781" 2 "St" "xfull" "awater-logged" 78 4.6 17.4 198.2 107.4
"791" 2 "St" "xfull" "awater-logged" 79 3 14.2 166.6 104.4
"801" 2 "St" "root" "awater-logged" 80 5.4 63.8 636.6 292.6
"412" 3 "St" "root" "moist" 41 2.6 60.6 1161 617.6
"422" 3 "St" "xfull" "moist" 42 3.4 16.8 313.8 250.6
"432" 3 "St" "root" "moist" 43 2.75 46 906 707.25
"442" 3 "St" "control" "moist" 44 3 74.8 1550.4 742.4
"452" 3 "St" "control" "moist" 45 3.8 73 1324.6 627.6
"462" 3 "St" "root" "moist" 46 4.4 62.2 1096 496.4
"472" 3 "St" "xfull" "moist" 47 3.2 13.8 133.6 64.4
"482" 3 "St" "shoot" "moist" 48 3.2 53 776.8 447.2
"492" 3 "St" "xfull" "moist" 49 3.8 21.4 303.4 239.6
"502" 3 "St" "xfull" "moist" 50 7.5 18.75 207.5 58
"512" 3 "St" "shoot" "moist" 51 4.6 56.8 689 421.8
"522" 3 "St" "shoot" "moist" 52 1.6 34.6 640.4 575.8
"532" 3 "St" "root" "moist" 53 3.75 67.5 1164.25 586.75
"542" 3 "St" "control" "moist" 54 3 73.4 1325 617.2
"552" 3 "St" "control" "moist" 55 4.75 99 1730.75 678
"562" 3 "St" "control" "moist" 56 3.6 75.4 1386.6 713.8
"572" 3 "St" "shoot" "moist" 57 2.25 31 463.5 343
"582" 3 "St" "shoot" "moist" 58 2.5 47 799 551.5
"592" 3 "St" "xfull" "moist" 59 5.5 14.5 243 155
"602" 3 "St" "root" "moist" 60 2.8 55.6 1086.6 513
"612" 3 "St" "xfull" "awater-logged" 61 5.4 27 345 220
"622" 3 "St" "control" "awater-logged" 62 4 80.4 1154.4 496.2
"632" 3 "St" "shoot" "awater-logged" 63 2.25 50.5 835.5 425.25
"642" 3 "St" "root" "awater-logged" 64 4.333333333 83.33333333 1354.333333 551.6666667
"652" 3 "St" "control" "awater-logged" 65 4 71.4 1351.4 576.4
"662" 3 "St" "xfull" "awater-logged" 66 3.75 17 224.5 160.25
"672" 3 "St" "control" "awater-logged" 67 4.25 78.5 1268.5 549.75
"682" 3 "St" "root" "awater-logged" 68 5.25 92.75 1189.5 462
"692" 3 "St" "shoot" "awater-logged" 69 2.2 45 865.6 642.8
"702" 3 "St" "xfull" "awater-logged" 70 3.6 22.4 246.2 181.6
"712" 3 "St" "control" "awater-logged" 71 3.8 74.6 1284 545.4
"722" 3 "St" "shoot" "awater-logged" 72 2.2 42.2 647 405.2
"732" 3 "St" "shoot" "awater-logged" 73 2.25 47.25 798.75 491.75
"742" 3 "St" "root" "awater-logged" 74 3 61 1105.8 551.4
"752" 3 "St" "shoot" "awater-logged" 75 1.8 36.6 585.8 534.4
"762" 3 "St" "control" "awater-logged" 76 5.8 98 1633.8 640.4
"772" 3 "St" "root" "awater-logged" 77 3.4 51.6 876.8 572.6
"782" 3 "St" "xfull" "awater-logged" 78 4.8 25.6 295.6 175.6
"792" 3 "St" "xfull" "awater-logged" 79 2.6 21.4 295.2 228.2
"802" 3 "St" "root" "awater-logged" 80 4 72.2 1072.8 576

From Mike.Lawrence at dal.ca  Fri Oct 29 18:23:33 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Fri, 29 Oct 2010 13:23:33 -0300
Subject: [R-sig-ME] psychometric function fitting with lmer?
Message-ID: <AANLkTimW3HOY1r9+LrvGui9gfxmSDjS94fXShYu-DP3B@mail.gmail.com>

Hi folks,

In some areas of psychology, we encounter binomial response data that,
when aggregated to proportions and plotted against a continuous
predictor variable, forms a sigmoid-like function. It is typical to
use OLS to fit a probit function to this data, yielding measures of
bias (mean of the Gaussian) and variability (SD of the Gaussian). This
fitting is typically done within each individual and condition of
interest separately, then the resulting parameters are submitted to 2
ANOVAs: one for bias, one for variability. I wonder if this analysis
might be achieved more efficiently using a single mixed effects model,
but I'm having trouble figuring out how to approach coding this. Below
is an example of data similar to that collected in this sort of
research, where individuals fall into two groups (variable "group"),
and are tested under two conditions (variable "cue") across a set of
values from a continuous variable (variable "soa"), with each cue*soa
combination tested repeatedly within each individual. A model like

fit = lmer(
    formula = response ~ (1|id) + group*cue*soa
    , family = binomial( link='probit' )
    , data = a
)

employs the probit link, but of course yields estimates for the slope
and intercept of a linear model on the probit scale, and I'm not sure
how (if it's even possible) to convert the conclusions drawn on this
scale to conclusions about the bias and variability parameters of
interest.

Thoughts?

Mike

structure(list(id = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 11L, 11L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 13L, 13L, 13L, 13L, 13L, 13L,
13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L,
13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L,
13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L,
13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L,
13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L,
13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L,
13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L,
13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L,
13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L,
13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L,
13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L,
13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L,
13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L,
13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L,
13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L,
13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L,
13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L,
13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L,
13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L,
13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L,
13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L,
13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L,
13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L,
13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L,
13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L,
13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L,
13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L,
13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L,
13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L,
13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L,
13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L,
13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L,
13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L,
13L, 13L, 13L, 13L, 13L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
14L, 14L, 14L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L,
15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L,
15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L,
15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L,
15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L,
15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L,
15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L,
15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L,
15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L,
15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L,
15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L,
15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L,
15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L,
15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L,
15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L,
15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L,
15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L,
15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L,
15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L,
15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L,
15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L,
15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L,
15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L,
15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L,
15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L,
15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L,
15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L,
15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L,
15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L,
15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L,
15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L,
15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L,
15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L,
15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L,
15L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L,
16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L,
16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L,
16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L,
16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L,
16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L,
16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L,
16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L,
16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L,
16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L,
16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L,
16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L,
16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L,
16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L,
16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L,
16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L,
16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L,
16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L,
16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L,
16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L,
16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L,
16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L,
16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L,
16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L,
16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L,
16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L,
16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L,
16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L,
16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L,
16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L,
16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L,
16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L,
16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L,
16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 17L,
17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L,
17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L,
17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L,
17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L,
17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L,
17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L,
17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L,
17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L,
17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L,
17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L,
17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L,
17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L,
17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L,
17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L,
17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L,
17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L,
17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L,
17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L,
17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L,
17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L,
17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L,
17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L,
17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L,
17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L,
17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L,
17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L,
17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L,
17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L,
17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L,
17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L,
17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L,
17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L,
17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L,
17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 18L, 18L, 18L,
18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L,
18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L,
18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L,
18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L,
18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L,
18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L,
18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L,
18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L,
18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L,
18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L,
18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L,
18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L,
18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L,
18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L,
18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L,
18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L,
18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L,
18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L,
18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L,
18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L,
18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L,
18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L,
18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L,
18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L,
18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L,
18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L,
18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L,
18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L,
18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L,
18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L,
18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L,
18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L,
18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L,
18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 19L, 19L, 19L, 19L, 19L,
19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L,
19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L,
19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L,
19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L,
19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L,
19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L,
19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L,
19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L,
19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L,
19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L,
19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L,
19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L,
19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L,
19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L,
19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L,
19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L,
19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L,
19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L,
19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L,
19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L,
19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L,
19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L,
19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L,
19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L,
19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L,
19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L,
19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L,
19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L,
19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L,
19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L,
19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L,
19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L,
19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L,
19L, 19L, 19L, 19L, 19L, 19L, 20L, 20L, 20L, 20L, 20L, 20L, 20L,
20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L,
20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L,
20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L,
20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L,
20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L,
20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L,
20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L,
20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L,
20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L,
20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L,
20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L,
20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L,
20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L,
20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L,
20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L,
20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L,
20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L,
20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L,
20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L,
20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L,
20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L,
20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L,
20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L,
20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L,
20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L,
20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L,
20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L,
20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L,
20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L,
20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L,
20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L,
20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L,
20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L,
20L, 20L, 20L, 20L), .Label = c("1", "2", "3", "4", "5", "6",
"7", "8", "9", "10", "11", "12", "13", "14", "15", "16", "17",
"18", "19", "20"), class = "factor"), group = structure(c(2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label =
c("Control",
"Neglect"), class = "factor"), cue = structure(c(1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("Alert",
"Unalert"), class = "factor"), soa = c(-210L, -210L, -210L, -210L,
-210L, -210L, -210L, -210L, -210L, -210L, -190L, -190L, -190L,
-190L, -190L, -190L, -190L, -190L, -190L, -190L, -170L, -170L,
-170L, -170L, -170L, -170L, -170L, -170L, -170L, -170L, -150L,
-150L, -150L, -150L, -150L, -150L, -150L, -150L, -150L, -150L,
-130L, -130L, -130L, -130L, -130L, -130L, -130L, -130L, -130L,
-130L, -110L, -110L, -110L, -110L, -110L, -110L, -110L, -110L,
-110L, -110L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L,
-90L, -90L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L,
-70L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L,
-30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -10L,
-10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L,
50L, 50L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 90L,
90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 110L, 110L, 110L,
110L, 110L, 110L, 110L, 110L, 110L, 110L, 130L, 130L, 130L, 130L,
130L, 130L, 130L, 130L, 130L, 130L, 150L, 150L, 150L, 150L, 150L,
150L, 150L, 150L, 150L, 150L, 170L, 170L, 170L, 170L, 170L, 170L,
170L, 170L, 170L, 170L, 190L, 190L, 190L, 190L, 190L, 190L, 190L,
190L, 190L, 190L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L,
210L, 210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L,
-210L, -210L, -210L, -190L, -190L, -190L, -190L, -190L, -190L,
-190L, -190L, -190L, -190L, -170L, -170L, -170L, -170L, -170L,
-170L, -170L, -170L, -170L, -170L, -150L, -150L, -150L, -150L,
-150L, -150L, -150L, -150L, -150L, -150L, -130L, -130L, -130L,
-130L, -130L, -130L, -130L, -130L, -130L, -130L, -110L, -110L,
-110L, -110L, -110L, -110L, -110L, -110L, -110L, -110L, -90L,
-90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -70L, -70L,
-70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -50L, -50L, -50L,
-50L, -50L, -50L, -50L, -50L, -50L, -50L, -30L, -30L, -30L, -30L,
-30L, -30L, -30L, -30L, -30L, -30L, -10L, -10L, -10L, -10L, -10L,
-10L, -10L, -10L, -10L, -10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 70L, 70L, 70L,
70L, 70L, 70L, 70L, 70L, 70L, 70L, 90L, 90L, 90L, 90L, 90L, 90L,
90L, 90L, 90L, 90L, 110L, 110L, 110L, 110L, 110L, 110L, 110L,
110L, 110L, 110L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L,
130L, 130L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L,
150L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L,
190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 210L,
210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, -210L,
-210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L,
-190L, -190L, -190L, -190L, -190L, -190L, -190L, -190L, -190L,
-190L, -170L, -170L, -170L, -170L, -170L, -170L, -170L, -170L,
-170L, -170L, -150L, -150L, -150L, -150L, -150L, -150L, -150L,
-150L, -150L, -150L, -130L, -130L, -130L, -130L, -130L, -130L,
-130L, -130L, -130L, -130L, -110L, -110L, -110L, -110L, -110L,
-110L, -110L, -110L, -110L, -110L, -90L, -90L, -90L, -90L, -90L,
-90L, -90L, -90L, -90L, -90L, -70L, -70L, -70L, -70L, -70L, -70L,
-70L, -70L, -70L, -70L, -50L, -50L, -50L, -50L, -50L, -50L, -50L,
-50L, -50L, -50L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L,
-30L, -30L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L,
-10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 50L, 50L, 50L, 50L,
50L, 50L, 50L, 50L, 50L, 50L, 70L, 70L, 70L, 70L, 70L, 70L, 70L,
70L, 70L, 70L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L,
110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 130L,
130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 150L, 150L,
150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 170L, 170L, 170L,
170L, 170L, 170L, 170L, 170L, 170L, 170L, 190L, 190L, 190L, 190L,
190L, 190L, 190L, 190L, 190L, 190L, 210L, 210L, 210L, 210L, 210L,
210L, 210L, 210L, 210L, 210L, -210L, -210L, -210L, -210L, -210L,
-210L, -210L, -210L, -210L, -210L, -190L, -190L, -190L, -190L,
-190L, -190L, -190L, -190L, -190L, -190L, -170L, -170L, -170L,
-170L, -170L, -170L, -170L, -170L, -170L, -170L, -150L, -150L,
-150L, -150L, -150L, -150L, -150L, -150L, -150L, -150L, -130L,
-130L, -130L, -130L, -130L, -130L, -130L, -130L, -130L, -130L,
-110L, -110L, -110L, -110L, -110L, -110L, -110L, -110L, -110L,
-110L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L,
-90L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L,
-50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -30L,
-30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -10L, -10L,
-10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L,
50L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 90L, 90L,
90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 110L, 110L, 110L, 110L,
110L, 110L, 110L, 110L, 110L, 110L, 130L, 130L, 130L, 130L, 130L,
130L, 130L, 130L, 130L, 130L, 150L, 150L, 150L, 150L, 150L, 150L,
150L, 150L, 150L, 150L, 170L, 170L, 170L, 170L, 170L, 170L, 170L,
170L, 170L, 170L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L,
190L, 190L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L,
210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L,
-210L, -210L, -190L, -190L, -190L, -190L, -190L, -190L, -190L,
-190L, -190L, -190L, -170L, -170L, -170L, -170L, -170L, -170L,
-170L, -170L, -170L, -170L, -150L, -150L, -150L, -150L, -150L,
-150L, -150L, -150L, -150L, -150L, -130L, -130L, -130L, -130L,
-130L, -130L, -130L, -130L, -130L, -130L, -110L, -110L, -110L,
-110L, -110L, -110L, -110L, -110L, -110L, -110L, -90L, -90L,
-90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -70L, -70L, -70L,
-70L, -70L, -70L, -70L, -70L, -70L, -70L, -50L, -50L, -50L, -50L,
-50L, -50L, -50L, -50L, -50L, -50L, -30L, -30L, -30L, -30L, -30L,
-30L, -30L, -30L, -30L, -30L, -10L, -10L, -10L, -10L, -10L, -10L,
-10L, -10L, -10L, -10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 50L,
50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 70L, 70L, 70L, 70L,
70L, 70L, 70L, 70L, 70L, 70L, 90L, 90L, 90L, 90L, 90L, 90L, 90L,
90L, 90L, 90L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L,
110L, 110L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L,
130L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L,
170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 190L,
190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 210L, 210L,
210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, -210L, -210L,
-210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L, -190L,
-190L, -190L, -190L, -190L, -190L, -190L, -190L, -190L, -190L,
-170L, -170L, -170L, -170L, -170L, -170L, -170L, -170L, -170L,
-170L, -150L, -150L, -150L, -150L, -150L, -150L, -150L, -150L,
-150L, -150L, -130L, -130L, -130L, -130L, -130L, -130L, -130L,
-130L, -130L, -130L, -110L, -110L, -110L, -110L, -110L, -110L,
-110L, -110L, -110L, -110L, -90L, -90L, -90L, -90L, -90L, -90L,
-90L, -90L, -90L, -90L, -70L, -70L, -70L, -70L, -70L, -70L, -70L,
-70L, -70L, -70L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L,
-50L, -50L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L,
-30L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 50L, 50L, 50L, 50L, 50L, 50L,
50L, 50L, 50L, 50L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L,
70L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 110L,
110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 130L, 130L,
130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 150L, 150L, 150L,
150L, 150L, 150L, 150L, 150L, 150L, 150L, 170L, 170L, 170L, 170L,
170L, 170L, 170L, 170L, 170L, 170L, 190L, 190L, 190L, 190L, 190L,
190L, 190L, 190L, 190L, 190L, 210L, 210L, 210L, 210L, 210L, 210L,
210L, 210L, 210L, 210L, -210L, -210L, -210L, -210L, -210L, -210L,
-210L, -210L, -210L, -210L, -190L, -190L, -190L, -190L, -190L,
-190L, -190L, -190L, -190L, -190L, -170L, -170L, -170L, -170L,
-170L, -170L, -170L, -170L, -170L, -170L, -150L, -150L, -150L,
-150L, -150L, -150L, -150L, -150L, -150L, -150L, -130L, -130L,
-130L, -130L, -130L, -130L, -130L, -130L, -130L, -130L, -110L,
-110L, -110L, -110L, -110L, -110L, -110L, -110L, -110L, -110L,
-90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -70L,
-70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -50L, -50L,
-50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -30L, -30L, -30L,
-30L, -30L, -30L, -30L, -30L, -30L, -30L, -10L, -10L, -10L, -10L,
-10L, -10L, -10L, -10L, -10L, -10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 70L,
70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 90L, 90L, 90L, 90L,
90L, 90L, 90L, 90L, 90L, 90L, 110L, 110L, 110L, 110L, 110L, 110L,
110L, 110L, 110L, 110L, 130L, 130L, 130L, 130L, 130L, 130L, 130L,
130L, 130L, 130L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L,
150L, 150L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L,
170L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L,
210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, -210L,
-210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L,
-190L, -190L, -190L, -190L, -190L, -190L, -190L, -190L, -190L,
-190L, -170L, -170L, -170L, -170L, -170L, -170L, -170L, -170L,
-170L, -170L, -150L, -150L, -150L, -150L, -150L, -150L, -150L,
-150L, -150L, -150L, -130L, -130L, -130L, -130L, -130L, -130L,
-130L, -130L, -130L, -130L, -110L, -110L, -110L, -110L, -110L,
-110L, -110L, -110L, -110L, -110L, -90L, -90L, -90L, -90L, -90L,
-90L, -90L, -90L, -90L, -90L, -70L, -70L, -70L, -70L, -70L, -70L,
-70L, -70L, -70L, -70L, -50L, -50L, -50L, -50L, -50L, -50L, -50L,
-50L, -50L, -50L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L,
-30L, -30L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L,
-10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 50L, 50L, 50L, 50L,
50L, 50L, 50L, 50L, 50L, 50L, 70L, 70L, 70L, 70L, 70L, 70L, 70L,
70L, 70L, 70L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L,
110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 130L,
130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 150L, 150L,
150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 170L, 170L, 170L,
170L, 170L, 170L, 170L, 170L, 170L, 170L, 190L, 190L, 190L, 190L,
190L, 190L, 190L, 190L, 190L, 190L, 210L, 210L, 210L, 210L, 210L,
210L, 210L, 210L, 210L, 210L, -210L, -210L, -210L, -210L, -210L,
-210L, -210L, -210L, -210L, -210L, -190L, -190L, -190L, -190L,
-190L, -190L, -190L, -190L, -190L, -190L, -170L, -170L, -170L,
-170L, -170L, -170L, -170L, -170L, -170L, -170L, -150L, -150L,
-150L, -150L, -150L, -150L, -150L, -150L, -150L, -150L, -130L,
-130L, -130L, -130L, -130L, -130L, -130L, -130L, -130L, -130L,
-110L, -110L, -110L, -110L, -110L, -110L, -110L, -110L, -110L,
-110L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L,
-90L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L,
-50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -30L,
-30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -10L, -10L,
-10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L,
50L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 90L, 90L,
90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 110L, 110L, 110L, 110L,
110L, 110L, 110L, 110L, 110L, 110L, 130L, 130L, 130L, 130L, 130L,
130L, 130L, 130L, 130L, 130L, 150L, 150L, 150L, 150L, 150L, 150L,
150L, 150L, 150L, 150L, 170L, 170L, 170L, 170L, 170L, 170L, 170L,
170L, 170L, 170L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L,
190L, 190L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L,
210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L,
-210L, -210L, -190L, -190L, -190L, -190L, -190L, -190L, -190L,
-190L, -190L, -190L, -170L, -170L, -170L, -170L, -170L, -170L,
-170L, -170L, -170L, -170L, -150L, -150L, -150L, -150L, -150L,
-150L, -150L, -150L, -150L, -150L, -130L, -130L, -130L, -130L,
-130L, -130L, -130L, -130L, -130L, -130L, -110L, -110L, -110L,
-110L, -110L, -110L, -110L, -110L, -110L, -110L, -90L, -90L,
-90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -70L, -70L, -70L,
-70L, -70L, -70L, -70L, -70L, -70L, -70L, -50L, -50L, -50L, -50L,
-50L, -50L, -50L, -50L, -50L, -50L, -30L, -30L, -30L, -30L, -30L,
-30L, -30L, -30L, -30L, -30L, -10L, -10L, -10L, -10L, -10L, -10L,
-10L, -10L, -10L, -10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 50L,
50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 70L, 70L, 70L, 70L,
70L, 70L, 70L, 70L, 70L, 70L, 90L, 90L, 90L, 90L, 90L, 90L, 90L,
90L, 90L, 90L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L,
110L, 110L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L,
130L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L,
170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 190L,
190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 210L, 210L,
210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, -210L, -210L,
-210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L, -190L,
-190L, -190L, -190L, -190L, -190L, -190L, -190L, -190L, -190L,
-170L, -170L, -170L, -170L, -170L, -170L, -170L, -170L, -170L,
-170L, -150L, -150L, -150L, -150L, -150L, -150L, -150L, -150L,
-150L, -150L, -130L, -130L, -130L, -130L, -130L, -130L, -130L,
-130L, -130L, -130L, -110L, -110L, -110L, -110L, -110L, -110L,
-110L, -110L, -110L, -110L, -90L, -90L, -90L, -90L, -90L, -90L,
-90L, -90L, -90L, -90L, -70L, -70L, -70L, -70L, -70L, -70L, -70L,
-70L, -70L, -70L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L,
-50L, -50L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L,
-30L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 50L, 50L, 50L, 50L, 50L, 50L,
50L, 50L, 50L, 50L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L,
70L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 110L,
110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 130L, 130L,
130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 150L, 150L, 150L,
150L, 150L, 150L, 150L, 150L, 150L, 150L, 170L, 170L, 170L, 170L,
170L, 170L, 170L, 170L, 170L, 170L, 190L, 190L, 190L, 190L, 190L,
190L, 190L, 190L, 190L, 190L, 210L, 210L, 210L, 210L, 210L, 210L,
210L, 210L, 210L, 210L, -210L, -210L, -210L, -210L, -210L, -210L,
-210L, -210L, -210L, -210L, -190L, -190L, -190L, -190L, -190L,
-190L, -190L, -190L, -190L, -190L, -170L, -170L, -170L, -170L,
-170L, -170L, -170L, -170L, -170L, -170L, -150L, -150L, -150L,
-150L, -150L, -150L, -150L, -150L, -150L, -150L, -130L, -130L,
-130L, -130L, -130L, -130L, -130L, -130L, -130L, -130L, -110L,
-110L, -110L, -110L, -110L, -110L, -110L, -110L, -110L, -110L,
-90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -70L,
-70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -50L, -50L,
-50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -30L, -30L, -30L,
-30L, -30L, -30L, -30L, -30L, -30L, -30L, -10L, -10L, -10L, -10L,
-10L, -10L, -10L, -10L, -10L, -10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 70L,
70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 90L, 90L, 90L, 90L,
90L, 90L, 90L, 90L, 90L, 90L, 110L, 110L, 110L, 110L, 110L, 110L,
110L, 110L, 110L, 110L, 130L, 130L, 130L, 130L, 130L, 130L, 130L,
130L, 130L, 130L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L,
150L, 150L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L,
170L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L,
210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, -210L,
-210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L,
-190L, -190L, -190L, -190L, -190L, -190L, -190L, -190L, -190L,
-190L, -170L, -170L, -170L, -170L, -170L, -170L, -170L, -170L,
-170L, -170L, -150L, -150L, -150L, -150L, -150L, -150L, -150L,
-150L, -150L, -150L, -130L, -130L, -130L, -130L, -130L, -130L,
-130L, -130L, -130L, -130L, -110L, -110L, -110L, -110L, -110L,
-110L, -110L, -110L, -110L, -110L, -90L, -90L, -90L, -90L, -90L,
-90L, -90L, -90L, -90L, -90L, -70L, -70L, -70L, -70L, -70L, -70L,
-70L, -70L, -70L, -70L, -50L, -50L, -50L, -50L, -50L, -50L, -50L,
-50L, -50L, -50L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L,
-30L, -30L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L,
-10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 50L, 50L, 50L, 50L,
50L, 50L, 50L, 50L, 50L, 50L, 70L, 70L, 70L, 70L, 70L, 70L, 70L,
70L, 70L, 70L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L,
110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 130L,
130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 150L, 150L,
150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 170L, 170L, 170L,
170L, 170L, 170L, 170L, 170L, 170L, 170L, 190L, 190L, 190L, 190L,
190L, 190L, 190L, 190L, 190L, 190L, 210L, 210L, 210L, 210L, 210L,
210L, 210L, 210L, 210L, 210L, -210L, -210L, -210L, -210L, -210L,
-210L, -210L, -210L, -210L, -210L, -190L, -190L, -190L, -190L,
-190L, -190L, -190L, -190L, -190L, -190L, -170L, -170L, -170L,
-170L, -170L, -170L, -170L, -170L, -170L, -170L, -150L, -150L,
-150L, -150L, -150L, -150L, -150L, -150L, -150L, -150L, -130L,
-130L, -130L, -130L, -130L, -130L, -130L, -130L, -130L, -130L,
-110L, -110L, -110L, -110L, -110L, -110L, -110L, -110L, -110L,
-110L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L,
-90L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L,
-50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -30L,
-30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -10L, -10L,
-10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L,
50L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 90L, 90L,
90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 110L, 110L, 110L, 110L,
110L, 110L, 110L, 110L, 110L, 110L, 130L, 130L, 130L, 130L, 130L,
130L, 130L, 130L, 130L, 130L, 150L, 150L, 150L, 150L, 150L, 150L,
150L, 150L, 150L, 150L, 170L, 170L, 170L, 170L, 170L, 170L, 170L,
170L, 170L, 170L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L,
190L, 190L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L,
210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L,
-210L, -210L, -190L, -190L, -190L, -190L, -190L, -190L, -190L,
-190L, -190L, -190L, -170L, -170L, -170L, -170L, -170L, -170L,
-170L, -170L, -170L, -170L, -150L, -150L, -150L, -150L, -150L,
-150L, -150L, -150L, -150L, -150L, -130L, -130L, -130L, -130L,
-130L, -130L, -130L, -130L, -130L, -130L, -110L, -110L, -110L,
-110L, -110L, -110L, -110L, -110L, -110L, -110L, -90L, -90L,
-90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -70L, -70L, -70L,
-70L, -70L, -70L, -70L, -70L, -70L, -70L, -50L, -50L, -50L, -50L,
-50L, -50L, -50L, -50L, -50L, -50L, -30L, -30L, -30L, -30L, -30L,
-30L, -30L, -30L, -30L, -30L, -10L, -10L, -10L, -10L, -10L, -10L,
-10L, -10L, -10L, -10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 50L,
50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 70L, 70L, 70L, 70L,
70L, 70L, 70L, 70L, 70L, 70L, 90L, 90L, 90L, 90L, 90L, 90L, 90L,
90L, 90L, 90L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L,
110L, 110L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L,
130L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L,
170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 190L,
190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 210L, 210L,
210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, -210L, -210L,
-210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L, -190L,
-190L, -190L, -190L, -190L, -190L, -190L, -190L, -190L, -190L,
-170L, -170L, -170L, -170L, -170L, -170L, -170L, -170L, -170L,
-170L, -150L, -150L, -150L, -150L, -150L, -150L, -150L, -150L,
-150L, -150L, -130L, -130L, -130L, -130L, -130L, -130L, -130L,
-130L, -130L, -130L, -110L, -110L, -110L, -110L, -110L, -110L,
-110L, -110L, -110L, -110L, -90L, -90L, -90L, -90L, -90L, -90L,
-90L, -90L, -90L, -90L, -70L, -70L, -70L, -70L, -70L, -70L, -70L,
-70L, -70L, -70L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L,
-50L, -50L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L,
-30L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 50L, 50L, 50L, 50L, 50L, 50L,
50L, 50L, 50L, 50L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L,
70L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 110L,
110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 130L, 130L,
130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 150L, 150L, 150L,
150L, 150L, 150L, 150L, 150L, 150L, 150L, 170L, 170L, 170L, 170L,
170L, 170L, 170L, 170L, 170L, 170L, 190L, 190L, 190L, 190L, 190L,
190L, 190L, 190L, 190L, 190L, 210L, 210L, 210L, 210L, 210L, 210L,
210L, 210L, 210L, 210L, -210L, -210L, -210L, -210L, -210L, -210L,
-210L, -210L, -210L, -210L, -190L, -190L, -190L, -190L, -190L,
-190L, -190L, -190L, -190L, -190L, -170L, -170L, -170L, -170L,
-170L, -170L, -170L, -170L, -170L, -170L, -150L, -150L, -150L,
-150L, -150L, -150L, -150L, -150L, -150L, -150L, -130L, -130L,
-130L, -130L, -130L, -130L, -130L, -130L, -130L, -130L, -110L,
-110L, -110L, -110L, -110L, -110L, -110L, -110L, -110L, -110L,
-90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -70L,
-70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -50L, -50L,
-50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -30L, -30L, -30L,
-30L, -30L, -30L, -30L, -30L, -30L, -30L, -10L, -10L, -10L, -10L,
-10L, -10L, -10L, -10L, -10L, -10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 70L,
70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 90L, 90L, 90L, 90L,
90L, 90L, 90L, 90L, 90L, 90L, 110L, 110L, 110L, 110L, 110L, 110L,
110L, 110L, 110L, 110L, 130L, 130L, 130L, 130L, 130L, 130L, 130L,
130L, 130L, 130L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L,
150L, 150L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L,
170L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L,
210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, -210L,
-210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L,
-190L, -190L, -190L, -190L, -190L, -190L, -190L, -190L, -190L,
-190L, -170L, -170L, -170L, -170L, -170L, -170L, -170L, -170L,
-170L, -170L, -150L, -150L, -150L, -150L, -150L, -150L, -150L,
-150L, -150L, -150L, -130L, -130L, -130L, -130L, -130L, -130L,
-130L, -130L, -130L, -130L, -110L, -110L, -110L, -110L, -110L,
-110L, -110L, -110L, -110L, -110L, -90L, -90L, -90L, -90L, -90L,
-90L, -90L, -90L, -90L, -90L, -70L, -70L, -70L, -70L, -70L, -70L,
-70L, -70L, -70L, -70L, -50L, -50L, -50L, -50L, -50L, -50L, -50L,
-50L, -50L, -50L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L,
-30L, -30L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L,
-10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 50L, 50L, 50L, 50L,
50L, 50L, 50L, 50L, 50L, 50L, 70L, 70L, 70L, 70L, 70L, 70L, 70L,
70L, 70L, 70L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L,
110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 130L,
130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 150L, 150L,
150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 170L, 170L, 170L,
170L, 170L, 170L, 170L, 170L, 170L, 170L, 190L, 190L, 190L, 190L,
190L, 190L, 190L, 190L, 190L, 190L, 210L, 210L, 210L, 210L, 210L,
210L, 210L, 210L, 210L, 210L, -210L, -210L, -210L, -210L, -210L,
-210L, -210L, -210L, -210L, -210L, -190L, -190L, -190L, -190L,
-190L, -190L, -190L, -190L, -190L, -190L, -170L, -170L, -170L,
-170L, -170L, -170L, -170L, -170L, -170L, -170L, -150L, -150L,
-150L, -150L, -150L, -150L, -150L, -150L, -150L, -150L, -130L,
-130L, -130L, -130L, -130L, -130L, -130L, -130L, -130L, -130L,
-110L, -110L, -110L, -110L, -110L, -110L, -110L, -110L, -110L,
-110L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L,
-90L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L,
-50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -30L,
-30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -10L, -10L,
-10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L,
50L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 90L, 90L,
90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 110L, 110L, 110L, 110L,
110L, 110L, 110L, 110L, 110L, 110L, 130L, 130L, 130L, 130L, 130L,
130L, 130L, 130L, 130L, 130L, 150L, 150L, 150L, 150L, 150L, 150L,
150L, 150L, 150L, 150L, 170L, 170L, 170L, 170L, 170L, 170L, 170L,
170L, 170L, 170L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L,
190L, 190L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L,
210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L,
-210L, -210L, -190L, -190L, -190L, -190L, -190L, -190L, -190L,
-190L, -190L, -190L, -170L, -170L, -170L, -170L, -170L, -170L,
-170L, -170L, -170L, -170L, -150L, -150L, -150L, -150L, -150L,
-150L, -150L, -150L, -150L, -150L, -130L, -130L, -130L, -130L,
-130L, -130L, -130L, -130L, -130L, -130L, -110L, -110L, -110L,
-110L, -110L, -110L, -110L, -110L, -110L, -110L, -90L, -90L,
-90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -70L, -70L, -70L,
-70L, -70L, -70L, -70L, -70L, -70L, -70L, -50L, -50L, -50L, -50L,
-50L, -50L, -50L, -50L, -50L, -50L, -30L, -30L, -30L, -30L, -30L,
-30L, -30L, -30L, -30L, -30L, -10L, -10L, -10L, -10L, -10L, -10L,
-10L, -10L, -10L, -10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 50L,
50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 70L, 70L, 70L, 70L,
70L, 70L, 70L, 70L, 70L, 70L, 90L, 90L, 90L, 90L, 90L, 90L, 90L,
90L, 90L, 90L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L,
110L, 110L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L,
130L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L,
170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 190L,
190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 210L, 210L,
210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, -210L, -210L,
-210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L, -190L,
-190L, -190L, -190L, -190L, -190L, -190L, -190L, -190L, -190L,
-170L, -170L, -170L, -170L, -170L, -170L, -170L, -170L, -170L,
-170L, -150L, -150L, -150L, -150L, -150L, -150L, -150L, -150L,
-150L, -150L, -130L, -130L, -130L, -130L, -130L, -130L, -130L,
-130L, -130L, -130L, -110L, -110L, -110L, -110L, -110L, -110L,
-110L, -110L, -110L, -110L, -90L, -90L, -90L, -90L, -90L, -90L,
-90L, -90L, -90L, -90L, -70L, -70L, -70L, -70L, -70L, -70L, -70L,
-70L, -70L, -70L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L,
-50L, -50L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L,
-30L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 50L, 50L, 50L, 50L, 50L, 50L,
50L, 50L, 50L, 50L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L,
70L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 110L,
110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 130L, 130L,
130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 150L, 150L, 150L,
150L, 150L, 150L, 150L, 150L, 150L, 150L, 170L, 170L, 170L, 170L,
170L, 170L, 170L, 170L, 170L, 170L, 190L, 190L, 190L, 190L, 190L,
190L, 190L, 190L, 190L, 190L, 210L, 210L, 210L, 210L, 210L, 210L,
210L, 210L, 210L, 210L, -210L, -210L, -210L, -210L, -210L, -210L,
-210L, -210L, -210L, -210L, -190L, -190L, -190L, -190L, -190L,
-190L, -190L, -190L, -190L, -190L, -170L, -170L, -170L, -170L,
-170L, -170L, -170L, -170L, -170L, -170L, -150L, -150L, -150L,
-150L, -150L, -150L, -150L, -150L, -150L, -150L, -130L, -130L,
-130L, -130L, -130L, -130L, -130L, -130L, -130L, -130L, -110L,
-110L, -110L, -110L, -110L, -110L, -110L, -110L, -110L, -110L,
-90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -70L,
-70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -50L, -50L,
-50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -30L, -30L, -30L,
-30L, -30L, -30L, -30L, -30L, -30L, -30L, -10L, -10L, -10L, -10L,
-10L, -10L, -10L, -10L, -10L, -10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 70L,
70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 90L, 90L, 90L, 90L,
90L, 90L, 90L, 90L, 90L, 90L, 110L, 110L, 110L, 110L, 110L, 110L,
110L, 110L, 110L, 110L, 130L, 130L, 130L, 130L, 130L, 130L, 130L,
130L, 130L, 130L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L,
150L, 150L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L,
170L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L,
210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, -210L,
-210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L,
-190L, -190L, -190L, -190L, -190L, -190L, -190L, -190L, -190L,
-190L, -170L, -170L, -170L, -170L, -170L, -170L, -170L, -170L,
-170L, -170L, -150L, -150L, -150L, -150L, -150L, -150L, -150L,
-150L, -150L, -150L, -130L, -130L, -130L, -130L, -130L, -130L,
-130L, -130L, -130L, -130L, -110L, -110L, -110L, -110L, -110L,
-110L, -110L, -110L, -110L, -110L, -90L, -90L, -90L, -90L, -90L,
-90L, -90L, -90L, -90L, -90L, -70L, -70L, -70L, -70L, -70L, -70L,
-70L, -70L, -70L, -70L, -50L, -50L, -50L, -50L, -50L, -50L, -50L,
-50L, -50L, -50L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L,
-30L, -30L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L,
-10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 50L, 50L, 50L, 50L,
50L, 50L, 50L, 50L, 50L, 50L, 70L, 70L, 70L, 70L, 70L, 70L, 70L,
70L, 70L, 70L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L,
110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 130L,
130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 150L, 150L,
150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 170L, 170L, 170L,
170L, 170L, 170L, 170L, 170L, 170L, 170L, 190L, 190L, 190L, 190L,
190L, 190L, 190L, 190L, 190L, 190L, 210L, 210L, 210L, 210L, 210L,
210L, 210L, 210L, 210L, 210L, -210L, -210L, -210L, -210L, -210L,
-210L, -210L, -210L, -210L, -210L, -190L, -190L, -190L, -190L,
-190L, -190L, -190L, -190L, -190L, -190L, -170L, -170L, -170L,
-170L, -170L, -170L, -170L, -170L, -170L, -170L, -150L, -150L,
-150L, -150L, -150L, -150L, -150L, -150L, -150L, -150L, -130L,
-130L, -130L, -130L, -130L, -130L, -130L, -130L, -130L, -130L,
-110L, -110L, -110L, -110L, -110L, -110L, -110L, -110L, -110L,
-110L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L,
-90L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L,
-50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -30L,
-30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -10L, -10L,
-10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L,
50L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 90L, 90L,
90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 110L, 110L, 110L, 110L,
110L, 110L, 110L, 110L, 110L, 110L, 130L, 130L, 130L, 130L, 130L,
130L, 130L, 130L, 130L, 130L, 150L, 150L, 150L, 150L, 150L, 150L,
150L, 150L, 150L, 150L, 170L, 170L, 170L, 170L, 170L, 170L, 170L,
170L, 170L, 170L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L,
190L, 190L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L,
210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L,
-210L, -210L, -190L, -190L, -190L, -190L, -190L, -190L, -190L,
-190L, -190L, -190L, -170L, -170L, -170L, -170L, -170L, -170L,
-170L, -170L, -170L, -170L, -150L, -150L, -150L, -150L, -150L,
-150L, -150L, -150L, -150L, -150L, -130L, -130L, -130L, -130L,
-130L, -130L, -130L, -130L, -130L, -130L, -110L, -110L, -110L,
-110L, -110L, -110L, -110L, -110L, -110L, -110L, -90L, -90L,
-90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -70L, -70L, -70L,
-70L, -70L, -70L, -70L, -70L, -70L, -70L, -50L, -50L, -50L, -50L,
-50L, -50L, -50L, -50L, -50L, -50L, -30L, -30L, -30L, -30L, -30L,
-30L, -30L, -30L, -30L, -30L, -10L, -10L, -10L, -10L, -10L, -10L,
-10L, -10L, -10L, -10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 50L,
50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 70L, 70L, 70L, 70L,
70L, 70L, 70L, 70L, 70L, 70L, 90L, 90L, 90L, 90L, 90L, 90L, 90L,
90L, 90L, 90L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L,
110L, 110L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L,
130L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L,
170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 190L,
190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 210L, 210L,
210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, -210L, -210L,
-210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L, -190L,
-190L, -190L, -190L, -190L, -190L, -190L, -190L, -190L, -190L,
-170L, -170L, -170L, -170L, -170L, -170L, -170L, -170L, -170L,
-170L, -150L, -150L, -150L, -150L, -150L, -150L, -150L, -150L,
-150L, -150L, -130L, -130L, -130L, -130L, -130L, -130L, -130L,
-130L, -130L, -130L, -110L, -110L, -110L, -110L, -110L, -110L,
-110L, -110L, -110L, -110L, -90L, -90L, -90L, -90L, -90L, -90L,
-90L, -90L, -90L, -90L, -70L, -70L, -70L, -70L, -70L, -70L, -70L,
-70L, -70L, -70L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L,
-50L, -50L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L,
-30L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 50L, 50L, 50L, 50L, 50L, 50L,
50L, 50L, 50L, 50L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L,
70L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 110L,
110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 130L, 130L,
130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 150L, 150L, 150L,
150L, 150L, 150L, 150L, 150L, 150L, 150L, 170L, 170L, 170L, 170L,
170L, 170L, 170L, 170L, 170L, 170L, 190L, 190L, 190L, 190L, 190L,
190L, 190L, 190L, 190L, 190L, 210L, 210L, 210L, 210L, 210L, 210L,
210L, 210L, 210L, 210L, -210L, -210L, -210L, -210L, -210L, -210L,
-210L, -210L, -210L, -210L, -190L, -190L, -190L, -190L, -190L,
-190L, -190L, -190L, -190L, -190L, -170L, -170L, -170L, -170L,
-170L, -170L, -170L, -170L, -170L, -170L, -150L, -150L, -150L,
-150L, -150L, -150L, -150L, -150L, -150L, -150L, -130L, -130L,
-130L, -130L, -130L, -130L, -130L, -130L, -130L, -130L, -110L,
-110L, -110L, -110L, -110L, -110L, -110L, -110L, -110L, -110L,
-90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -70L,
-70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -50L, -50L,
-50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -30L, -30L, -30L,
-30L, -30L, -30L, -30L, -30L, -30L, -30L, -10L, -10L, -10L, -10L,
-10L, -10L, -10L, -10L, -10L, -10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 70L,
70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 90L, 90L, 90L, 90L,
90L, 90L, 90L, 90L, 90L, 90L, 110L, 110L, 110L, 110L, 110L, 110L,
110L, 110L, 110L, 110L, 130L, 130L, 130L, 130L, 130L, 130L, 130L,
130L, 130L, 130L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L,
150L, 150L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L,
170L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L,
210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, -210L,
-210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L,
-190L, -190L, -190L, -190L, -190L, -190L, -190L, -190L, -190L,
-190L, -170L, -170L, -170L, -170L, -170L, -170L, -170L, -170L,
-170L, -170L, -150L, -150L, -150L, -150L, -150L, -150L, -150L,
-150L, -150L, -150L, -130L, -130L, -130L, -130L, -130L, -130L,
-130L, -130L, -130L, -130L, -110L, -110L, -110L, -110L, -110L,
-110L, -110L, -110L, -110L, -110L, -90L, -90L, -90L, -90L, -90L,
-90L, -90L, -90L, -90L, -90L, -70L, -70L, -70L, -70L, -70L, -70L,
-70L, -70L, -70L, -70L, -50L, -50L, -50L, -50L, -50L, -50L, -50L,
-50L, -50L, -50L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L,
-30L, -30L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L,
-10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 50L, 50L, 50L, 50L,
50L, 50L, 50L, 50L, 50L, 50L, 70L, 70L, 70L, 70L, 70L, 70L, 70L,
70L, 70L, 70L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L,
110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 130L,
130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 150L, 150L,
150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 170L, 170L, 170L,
170L, 170L, 170L, 170L, 170L, 170L, 170L, 190L, 190L, 190L, 190L,
190L, 190L, 190L, 190L, 190L, 190L, 210L, 210L, 210L, 210L, 210L,
210L, 210L, 210L, 210L, 210L, -210L, -210L, -210L, -210L, -210L,
-210L, -210L, -210L, -210L, -210L, -190L, -190L, -190L, -190L,
-190L, -190L, -190L, -190L, -190L, -190L, -170L, -170L, -170L,
-170L, -170L, -170L, -170L, -170L, -170L, -170L, -150L, -150L,
-150L, -150L, -150L, -150L, -150L, -150L, -150L, -150L, -130L,
-130L, -130L, -130L, -130L, -130L, -130L, -130L, -130L, -130L,
-110L, -110L, -110L, -110L, -110L, -110L, -110L, -110L, -110L,
-110L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L,
-90L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L,
-50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -30L,
-30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -10L, -10L,
-10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L,
50L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 90L, 90L,
90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 110L, 110L, 110L, 110L,
110L, 110L, 110L, 110L, 110L, 110L, 130L, 130L, 130L, 130L, 130L,
130L, 130L, 130L, 130L, 130L, 150L, 150L, 150L, 150L, 150L, 150L,
150L, 150L, 150L, 150L, 170L, 170L, 170L, 170L, 170L, 170L, 170L,
170L, 170L, 170L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L,
190L, 190L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L,
210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L,
-210L, -210L, -190L, -190L, -190L, -190L, -190L, -190L, -190L,
-190L, -190L, -190L, -170L, -170L, -170L, -170L, -170L, -170L,
-170L, -170L, -170L, -170L, -150L, -150L, -150L, -150L, -150L,
-150L, -150L, -150L, -150L, -150L, -130L, -130L, -130L, -130L,
-130L, -130L, -130L, -130L, -130L, -130L, -110L, -110L, -110L,
-110L, -110L, -110L, -110L, -110L, -110L, -110L, -90L, -90L,
-90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -70L, -70L, -70L,
-70L, -70L, -70L, -70L, -70L, -70L, -70L, -50L, -50L, -50L, -50L,
-50L, -50L, -50L, -50L, -50L, -50L, -30L, -30L, -30L, -30L, -30L,
-30L, -30L, -30L, -30L, -30L, -10L, -10L, -10L, -10L, -10L, -10L,
-10L, -10L, -10L, -10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 50L,
50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 70L, 70L, 70L, 70L,
70L, 70L, 70L, 70L, 70L, 70L, 90L, 90L, 90L, 90L, 90L, 90L, 90L,
90L, 90L, 90L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L,
110L, 110L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L,
130L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L,
170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 190L,
190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 210L, 210L,
210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, -210L, -210L,
-210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L, -190L,
-190L, -190L, -190L, -190L, -190L, -190L, -190L, -190L, -190L,
-170L, -170L, -170L, -170L, -170L, -170L, -170L, -170L, -170L,
-170L, -150L, -150L, -150L, -150L, -150L, -150L, -150L, -150L,
-150L, -150L, -130L, -130L, -130L, -130L, -130L, -130L, -130L,
-130L, -130L, -130L, -110L, -110L, -110L, -110L, -110L, -110L,
-110L, -110L, -110L, -110L, -90L, -90L, -90L, -90L, -90L, -90L,
-90L, -90L, -90L, -90L, -70L, -70L, -70L, -70L, -70L, -70L, -70L,
-70L, -70L, -70L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L,
-50L, -50L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L,
-30L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 50L, 50L, 50L, 50L, 50L, 50L,
50L, 50L, 50L, 50L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L,
70L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 110L,
110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 130L, 130L,
130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 150L, 150L, 150L,
150L, 150L, 150L, 150L, 150L, 150L, 150L, 170L, 170L, 170L, 170L,
170L, 170L, 170L, 170L, 170L, 170L, 190L, 190L, 190L, 190L, 190L,
190L, 190L, 190L, 190L, 190L, 210L, 210L, 210L, 210L, 210L, 210L,
210L, 210L, 210L, 210L, -210L, -210L, -210L, -210L, -210L, -210L,
-210L, -210L, -210L, -210L, -190L, -190L, -190L, -190L, -190L,
-190L, -190L, -190L, -190L, -190L, -170L, -170L, -170L, -170L,
-170L, -170L, -170L, -170L, -170L, -170L, -150L, -150L, -150L,
-150L, -150L, -150L, -150L, -150L, -150L, -150L, -130L, -130L,
-130L, -130L, -130L, -130L, -130L, -130L, -130L, -130L, -110L,
-110L, -110L, -110L, -110L, -110L, -110L, -110L, -110L, -110L,
-90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -70L,
-70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -50L, -50L,
-50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -30L, -30L, -30L,
-30L, -30L, -30L, -30L, -30L, -30L, -30L, -10L, -10L, -10L, -10L,
-10L, -10L, -10L, -10L, -10L, -10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 70L,
70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 90L, 90L, 90L, 90L,
90L, 90L, 90L, 90L, 90L, 90L, 110L, 110L, 110L, 110L, 110L, 110L,
110L, 110L, 110L, 110L, 130L, 130L, 130L, 130L, 130L, 130L, 130L,
130L, 130L, 130L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L,
150L, 150L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L,
170L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L,
210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, -210L,
-210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L,
-190L, -190L, -190L, -190L, -190L, -190L, -190L, -190L, -190L,
-190L, -170L, -170L, -170L, -170L, -170L, -170L, -170L, -170L,
-170L, -170L, -150L, -150L, -150L, -150L, -150L, -150L, -150L,
-150L, -150L, -150L, -130L, -130L, -130L, -130L, -130L, -130L,
-130L, -130L, -130L, -130L, -110L, -110L, -110L, -110L, -110L,
-110L, -110L, -110L, -110L, -110L, -90L, -90L, -90L, -90L, -90L,
-90L, -90L, -90L, -90L, -90L, -70L, -70L, -70L, -70L, -70L, -70L,
-70L, -70L, -70L, -70L, -50L, -50L, -50L, -50L, -50L, -50L, -50L,
-50L, -50L, -50L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L,
-30L, -30L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L,
-10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 50L, 50L, 50L, 50L,
50L, 50L, 50L, 50L, 50L, 50L, 70L, 70L, 70L, 70L, 70L, 70L, 70L,
70L, 70L, 70L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L,
110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 130L,
130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 150L, 150L,
150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 170L, 170L, 170L,
170L, 170L, 170L, 170L, 170L, 170L, 170L, 190L, 190L, 190L, 190L,
190L, 190L, 190L, 190L, 190L, 190L, 210L, 210L, 210L, 210L, 210L,
210L, 210L, 210L, 210L, 210L, -210L, -210L, -210L, -210L, -210L,
-210L, -210L, -210L, -210L, -210L, -190L, -190L, -190L, -190L,
-190L, -190L, -190L, -190L, -190L, -190L, -170L, -170L, -170L,
-170L, -170L, -170L, -170L, -170L, -170L, -170L, -150L, -150L,
-150L, -150L, -150L, -150L, -150L, -150L, -150L, -150L, -130L,
-130L, -130L, -130L, -130L, -130L, -130L, -130L, -130L, -130L,
-110L, -110L, -110L, -110L, -110L, -110L, -110L, -110L, -110L,
-110L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L,
-90L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L,
-50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -30L,
-30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -10L, -10L,
-10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L,
50L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 90L, 90L,
90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 110L, 110L, 110L, 110L,
110L, 110L, 110L, 110L, 110L, 110L, 130L, 130L, 130L, 130L, 130L,
130L, 130L, 130L, 130L, 130L, 150L, 150L, 150L, 150L, 150L, 150L,
150L, 150L, 150L, 150L, 170L, 170L, 170L, 170L, 170L, 170L, 170L,
170L, 170L, 170L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L,
190L, 190L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L,
210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L,
-210L, -210L, -190L, -190L, -190L, -190L, -190L, -190L, -190L,
-190L, -190L, -190L, -170L, -170L, -170L, -170L, -170L, -170L,
-170L, -170L, -170L, -170L, -150L, -150L, -150L, -150L, -150L,
-150L, -150L, -150L, -150L, -150L, -130L, -130L, -130L, -130L,
-130L, -130L, -130L, -130L, -130L, -130L, -110L, -110L, -110L,
-110L, -110L, -110L, -110L, -110L, -110L, -110L, -90L, -90L,
-90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -70L, -70L, -70L,
-70L, -70L, -70L, -70L, -70L, -70L, -70L, -50L, -50L, -50L, -50L,
-50L, -50L, -50L, -50L, -50L, -50L, -30L, -30L, -30L, -30L, -30L,
-30L, -30L, -30L, -30L, -30L, -10L, -10L, -10L, -10L, -10L, -10L,
-10L, -10L, -10L, -10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 50L,
50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 70L, 70L, 70L, 70L,
70L, 70L, 70L, 70L, 70L, 70L, 90L, 90L, 90L, 90L, 90L, 90L, 90L,
90L, 90L, 90L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L,
110L, 110L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L,
130L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L,
170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 190L,
190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 210L, 210L,
210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, -210L, -210L,
-210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L, -190L,
-190L, -190L, -190L, -190L, -190L, -190L, -190L, -190L, -190L,
-170L, -170L, -170L, -170L, -170L, -170L, -170L, -170L, -170L,
-170L, -150L, -150L, -150L, -150L, -150L, -150L, -150L, -150L,
-150L, -150L, -130L, -130L, -130L, -130L, -130L, -130L, -130L,
-130L, -130L, -130L, -110L, -110L, -110L, -110L, -110L, -110L,
-110L, -110L, -110L, -110L, -90L, -90L, -90L, -90L, -90L, -90L,
-90L, -90L, -90L, -90L, -70L, -70L, -70L, -70L, -70L, -70L, -70L,
-70L, -70L, -70L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L,
-50L, -50L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L,
-30L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 50L, 50L, 50L, 50L, 50L, 50L,
50L, 50L, 50L, 50L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L,
70L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 110L,
110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 130L, 130L,
130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 150L, 150L, 150L,
150L, 150L, 150L, 150L, 150L, 150L, 150L, 170L, 170L, 170L, 170L,
170L, 170L, 170L, 170L, 170L, 170L, 190L, 190L, 190L, 190L, 190L,
190L, 190L, 190L, 190L, 190L, 210L, 210L, 210L, 210L, 210L, 210L,
210L, 210L, 210L, 210L, -210L, -210L, -210L, -210L, -210L, -210L,
-210L, -210L, -210L, -210L, -190L, -190L, -190L, -190L, -190L,
-190L, -190L, -190L, -190L, -190L, -170L, -170L, -170L, -170L,
-170L, -170L, -170L, -170L, -170L, -170L, -150L, -150L, -150L,
-150L, -150L, -150L, -150L, -150L, -150L, -150L, -130L, -130L,
-130L, -130L, -130L, -130L, -130L, -130L, -130L, -130L, -110L,
-110L, -110L, -110L, -110L, -110L, -110L, -110L, -110L, -110L,
-90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -70L,
-70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -50L, -50L,
-50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -30L, -30L, -30L,
-30L, -30L, -30L, -30L, -30L, -30L, -30L, -10L, -10L, -10L, -10L,
-10L, -10L, -10L, -10L, -10L, -10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 70L,
70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 90L, 90L, 90L, 90L,
90L, 90L, 90L, 90L, 90L, 90L, 110L, 110L, 110L, 110L, 110L, 110L,
110L, 110L, 110L, 110L, 130L, 130L, 130L, 130L, 130L, 130L, 130L,
130L, 130L, 130L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L,
150L, 150L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L,
170L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L,
210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, -210L,
-210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L,
-190L, -190L, -190L, -190L, -190L, -190L, -190L, -190L, -190L,
-190L, -170L, -170L, -170L, -170L, -170L, -170L, -170L, -170L,
-170L, -170L, -150L, -150L, -150L, -150L, -150L, -150L, -150L,
-150L, -150L, -150L, -130L, -130L, -130L, -130L, -130L, -130L,
-130L, -130L, -130L, -130L, -110L, -110L, -110L, -110L, -110L,
-110L, -110L, -110L, -110L, -110L, -90L, -90L, -90L, -90L, -90L,
-90L, -90L, -90L, -90L, -90L, -70L, -70L, -70L, -70L, -70L, -70L,
-70L, -70L, -70L, -70L, -50L, -50L, -50L, -50L, -50L, -50L, -50L,
-50L, -50L, -50L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L,
-30L, -30L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L,
-10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 30L,
30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 50L, 50L, 50L, 50L,
50L, 50L, 50L, 50L, 50L, 50L, 70L, 70L, 70L, 70L, 70L, 70L, 70L,
70L, 70L, 70L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L,
110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 130L,
130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 150L, 150L,
150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 170L, 170L, 170L,
170L, 170L, 170L, 170L, 170L, 170L, 170L, 190L, 190L, 190L, 190L,
190L, 190L, 190L, 190L, 190L, 190L, 210L, 210L, 210L, 210L, 210L,
210L, 210L, 210L, 210L, 210L, -210L, -210L, -210L, -210L, -210L,
-210L, -210L, -210L, -210L, -210L, -190L, -190L, -190L, -190L,
-190L, -190L, -190L, -190L, -190L, -190L, -170L, -170L, -170L,
-170L, -170L, -170L, -170L, -170L, -170L, -170L, -150L, -150L,
-150L, -150L, -150L, -150L, -150L, -150L, -150L, -150L, -130L,
-130L, -130L, -130L, -130L, -130L, -130L, -130L, -130L, -130L,
-110L, -110L, -110L, -110L, -110L, -110L, -110L, -110L, -110L,
-110L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L,
-90L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L, -70L,
-50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -50L, -30L,
-30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -30L, -10L, -10L,
-10L, -10L, -10L, -10L, -10L, -10L, -10L, -10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 30L, 30L, 30L, 30L, 30L, 30L,
30L, 30L, 30L, 30L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L,
50L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 70L, 90L, 90L,
90L, 90L, 90L, 90L, 90L, 90L, 90L, 90L, 110L, 110L, 110L, 110L,
110L, 110L, 110L, 110L, 110L, 110L, 130L, 130L, 130L, 130L, 130L,
130L, 130L, 130L, 130L, 130L, 150L, 150L, 150L, 150L, 150L, 150L,
150L, 150L, 150L, 150L, 170L, 170L, 170L, 170L, 170L, 170L, 170L,
170L, 170L, 170L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L,
190L, 190L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L,
210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L, -210L,
-210L, -210L, -190L, -190L, -190L, -190L, -190L, -190L, -190L,
-190L, -190L, -190L, -170L, -170L, -170L, -170L, -170L, -170L,
-170L, -170L, -170L, -170L, -150L, -150L, -150L, -150L, -150L,
-150L, -150L, -150L, -150L, -150L, -130L, -130L, -130L, -130L,
-130L, -130L, -130L, -130L, -130L, -130L, -110L, -110L, -110L,
-110L, -110L, -110L, -110L, -110L, -110L, -110L, -90L, -90L,
-90L, -90L, -90L, -90L, -90L, -90L, -90L, -90L, -70L, -70L, -70L,
-70L, -70L, -70L, -70L, -70L, -70L, -70L, -50L, -50L, -50L, -50L,
-50L, -50L, -50L, -50L, -50L, -50L, -30L, -30L, -30L, -30L, -30L,
-30L, -30L, -30L, -30L, -30L, -10L, -10L, -10L, -10L, -10L, -10L,
-10L, -10L, -10L, -10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 50L,
50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 50L, 70L, 70L, 70L, 70L,
70L, 70L, 70L, 70L, 70L, 70L, 90L, 90L, 90L, 90L, 90L, 90L, 90L,
90L, 90L, 90L, 110L, 110L, 110L, 110L, 110L, 110L, 110L, 110L,
110L, 110L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L, 130L,
130L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L, 150L,
170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 170L, 190L,
190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 190L, 210L, 210L,
210L, 210L, 210L, 210L, 210L, 210L, 210L, 210L), response = c(0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 1L, 0L,
0L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 0L, 1L, 0L,
0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 1L, 0L,
0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L,
0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L,
1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 0L,
1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L,
1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 1L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L,
0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 1L,
0L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 0L, 0L, 1L, 1L, 1L,
0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 0L,
1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L,
1L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L,
1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 1L,
1L, 0L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 0L,
1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 1L, 0L, 1L,
1L, 0L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L,
1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L,
0L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 0L, 1L, 0L, 1L, 1L, 0L, 0L,
0L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 1L, 0L,
0L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L,
1L, 0L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 0L,
0L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 0L, 0L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 0L, 1L,
1L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L,
1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L,
1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 1L, 0L, 0L, 0L,
0L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 0L,
0L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L,
1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L,
0L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 1L, 1L, 1L, 0L,
1L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L,
0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L,
1L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L,
1L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 0L, 0L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 0L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 1L,
0L, 1L, 1L, 0L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 0L, 0L, 0L,
1L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 1L,
1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L,
0L, 0L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L,
0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 0L, 0L,
1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L,
1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
1L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 1L,
0L, 0L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 1L, 1L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 1L, 0L, 0L, 1L, 1L, 1L, 0L, 0L, 1L, 0L, 0L, 1L, 0L,
1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L,
0L, 1L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L,
1L, 0L, 0L, 1L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 0L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 1L, 0L, 0L, 0L, 1L,
1L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L,
1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L,
1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L,
0L, 0L, 0L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 1L,
0L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L,
0L, 0L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
1L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L,
1L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 0L,
1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 1L,
1L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 0L, 1L, 1L,
0L, 0L, 1L, 1L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 1L, 1L, 0L, 1L,
1L, 1L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 1L, 0L, 0L, 1L, 1L, 1L, 1L,
1L, 0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
1L, 1L, 0L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 0L,
0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 0L, 1L,
1L, 1L, 1L, 0L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L,
0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 0L, 0L, 1L, 0L,
0L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 1L,
1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L,
1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 1L, 0L,
1L, 0L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 0L,
0L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L,
1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 1L,
0L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 0L, 0L, 1L,
1L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L,
1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L,
0L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L,
1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 1L,
1L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 0L,
1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 0L, 1L, 0L, 1L,
1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 1L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L,
0L, 1L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 0L,
1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 0L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L,
1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 1L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 1L,
0L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 1L, 0L, 0L, 1L, 1L, 0L, 0L, 0L,
1L, 0L, 1L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 0L, 0L,
1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L,
1L, 1L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 0L,
0L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 1L,
1L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L,
0L, 0L, 0L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
0L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
1L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 1L, 0L,
0L, 0L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 1L, 1L, 1L, 0L, 1L,
0L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 0L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 0L,
1L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L,
0L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 0L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L,
1L, 1L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 1L, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 0L, 1L, 1L, 1L,
0L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L,
1L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L,
0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L,
0L, 1L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L,
1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L,
1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 1L,
1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L,
0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 1L, 0L, 1L, 0L,
0L, 0L, 0L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 1L,
1L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 1L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 0L,
1L, 1L, 1L, 0L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L,
1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 1L,
0L, 0L, 1L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 1L,
1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 1L,
0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 0L, 0L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L,
1L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 0L,
0L, 0L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 0L, 1L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 1L, 0L, 0L, 0L,
1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L,
0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 0L,
1L, 0L, 0L, 0L, 0L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 1L,
1L, 0L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L,
0L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 1L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 0L,
0L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L,
1L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 1L, 0L,
0L, 0L, 1L, 0L, 1L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L,
0L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 0L,
1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 1L,
0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
0L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L,
1L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
1L, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 0L, 0L, 1L,
0L, 0L, 0L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L,
1L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 0L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L,
1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L)), .Names = c("id",
"group", "cue", "soa", "response"), row.names = c(NA, -8800L), class =
"data.frame")



From peter.dixon at ualberta.ca  Fri Oct 29 18:41:57 2010
From: peter.dixon at ualberta.ca (Peter Dixon)
Date: Fri, 29 Oct 2010 10:41:57 -0600
Subject: [R-sig-ME] psychometric function fitting with lmer?
In-Reply-To: <AANLkTimW3HOY1r9+LrvGui9gfxmSDjS94fXShYu-DP3B@mail.gmail.com>
References: <AANLkTimW3HOY1r9+LrvGui9gfxmSDjS94fXShYu-DP3B@mail.gmail.com>
Message-ID: <67D6DDE5-4F9D-41BC-9395-A7DAF8F0CCE5@ualberta.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101029/3d06666f/attachment.pl>

From desja004 at umn.edu  Fri Oct 29 19:54:48 2010
From: desja004 at umn.edu (Christopher Desjardins)
Date: Fri, 29 Oct 2010 12:54:48 -0500
Subject: [R-sig-ME] analysis of count data with many zero values
In-Reply-To: <3DB16098F738284D8DBEB2FC3699163846B66D@inboexch.inbo.be>
References: <AANLkTikz+SrqTZpm646vuKEUmyFS2YKmmrOE633v+EtH@mail.gmail.com>
	<AANLkTimqPrTD8OD-dRDRzgBraMU8Lq-SagD5BENidVjG@mail.gmail.com>
	<3DB16098F738284D8DBEB2FC3699163846B66D@inboexch.inbo.be>
Message-ID: <AANLkTinb67vOxDnuCDr7LSbHHS0hXRfpgpeWv999Qdjc@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101029/94c2fac3/attachment.pl>

From HDoran at air.org  Fri Oct 29 20:29:06 2010
From: HDoran at air.org (Doran, Harold)
Date: Fri, 29 Oct 2010 14:29:06 -0400
Subject: [R-sig-ME] psychometric function fitting with lmer?
In-Reply-To: <FEB7C1E22FBCA64F87B5210590C9E0FA045BBD3EA7@DC1EX07CMS.air.org>
References: <AANLkTimW3HOY1r9+LrvGui9gfxmSDjS94fXShYu-DP3B@mail.gmail.com>
	<FEB7C1E22FBCA64F87B5210590C9E0FA045BBD3EA7@DC1EX07CMS.air.org>
Message-ID: <C0772C7568B5374481D2F8A880E9BBDF06A53AC4E9@DC1EX07CMS.air.org>

> > In some areas of psychology, we encounter binomial response data that,
> > when aggregated to proportions and plotted against a continuous
> > predictor variable, forms a sigmoid-like function.
> 

Yes, what is called an empirical item characteristic curve (eICC)

> It is typical to
> > use OLS to fit a probit function to this data, yielding measures of
> > bias (mean of the Gaussian) and variability (SD of the Gaussian).
> 

 This is a very odd way to compute bias. First, I don't know how one uses OLS
 to fit a probit model. Probit models are fit using (R)IGLS, not OLS. Second,
 why are you treating the observed data as a parameter estimate? Why don't you
 actually estimate the model parameters (i.e., the item parameters), which are
 asymptotically unbiased under certain estimation conditions. You can do this in a number of
 ways in R, lme4 can do this using lmer as described here:
 
 http://www.jstatsoft.org/v20/i02
 
 Or you can use JML methods for Rasch in the MiscPsycho package or you can use
 MML methods in the LTM package. What you seem to be doing is treating the eICC
 as some kind of parameter for the item; but this is not reasonable I don't
 think.
 
> This
> > fitting is typically done within each individual and condition of
> > interest separately, then the resulting parameters are submitted to 2
> > ANOVAs: one for bias, one for variability. I wonder if this analysis
> > might be achieved more efficiently using a single mixed effects model,
> > but I'm having trouble figuring out how to approach coding this.
> 


 I'm not sure I can help you here as I am unclear on what you are doing
 exactly. Maybe if we elaborate a bit on what you are trying to do above, we
 can do this part next.
 
> 
> Below
> > is an example of data similar to that collected in this sort of
> > research, where individuals fall into two groups (variable "group"),
> > and are tested under two conditions (variable "cue") across a set of
> > values from a continuous variable (variable "soa"), with each cue*soa
> > combination tested repeatedly within each individual. A model like
> >
> > fit = lmer(
> >     formula = response ~ (1|id) + group*cue*soa
> >     , family = binomial( link='probit' )
> >     , data = a
> > )
> >
> > employs the probit link, but of course yields estimates for the slope
> > and intercept of a linear model on the probit scale, and I'm not sure
> > how (if it's even possible) to convert the conclusions drawn on this
> > scale to conclusions about the bias and variability parameters of
> > interest.
> >
> > Thoughts?
> >

> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From Mike.Lawrence at dal.ca  Fri Oct 29 21:40:50 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Fri, 29 Oct 2010 16:40:50 -0300
Subject: [R-sig-ME] psychometric function fitting with lmer?
In-Reply-To: <C0772C7568B5374481D2F8A880E9BBDF06A53AC4E9@DC1EX07CMS.air.org>
References: <AANLkTimW3HOY1r9+LrvGui9gfxmSDjS94fXShYu-DP3B@mail.gmail.com>
	<FEB7C1E22FBCA64F87B5210590C9E0FA045BBD3EA7@DC1EX07CMS.air.org>
	<C0772C7568B5374481D2F8A880E9BBDF06A53AC4E9@DC1EX07CMS.air.org>
Message-ID: <AANLkTinrOqMULokF1XKdDCOWbZLYOABrSpi5FX_Usy7K@mail.gmail.com>

On Fri, Oct 29, 2010 at 3:29 PM, Doran, Harold <HDoran at air.org> wrote:
> ? First, I don't know how one uses OLS
> ?to fit a probit model.

I've seen it done. Folks usually collapse responses to
means-per-value-on-the-x-axis  then either use a computationally
intensive search algorithm to minimize the squared error on the
proportion scale, or fit a simple linear function on the probit scale
(when they encounter means of 1 or 0, they "tweak" these values by
either dropping that data entirely or adding/subtracting some
arbitrary value).

Regardless, I suspect we both agree that these are inadvisable ways of
dealing with this data, but I'm not sure we are on the same page with
respect to the underlying paradigm motivating the data analysis.
Whereas the paper you provided appears to be discussing data derived
from questionnaires with different items, etc, I was thinking (and I
apologize for failing to be more clear on this earlier) of data
derived from studies of temporal order judgement and other
psychophysical discrimination studies. Here's an example that I
happened to find while searching google for an article not behind a
pay-wall:

http://www.psych.ut.ee/~jyri/en/Murd-Kreegipuu-Allik_Perception2009.pdf

In such studies, individuals are provided two stimuli and asked "which
one is more X", where the stimuli are manipulated to explore a variety
of values for the difference of X between them. For example, in
temporal order judgements, we ask which of two successive stimuli came
first, right or left, then plot proportion of "right first" responses,
accumulated over many trials, as a function of the amount of time by
which the right stimulus led the right stimulus (SOA, or stimulus
onset asynchrony, where negative values mean the right stimulus
followed the left stimulus). This typically yields a sigmoidal
function where people are unlikely to say "right-first" when the left
stimulus leads by a lot (large negative SOA values) and very likely to
say "right-first" when the right stimulus leads by a lot (large
positive SOA values. The place where this function crosses 50% is
termed the point of subjective simultaneity (PSS) and the slope of the
function indexes the participants' sensitivity (shallow slopes
indicate poor sensitivity, sharp slopes indicate good sensitivity).
Researchers are often then interested in how various experimental
manipulations affect these two characteristics of performance.


> Second,
> ?why are you treating the observed data as a parameter estimate? Why don't you
> ?actually estimate the model parameters (i.e., the item parameters), which are
> ?asymptotically unbiased under certain estimation conditions. You can do this in a number of
> ?ways in R, lme4 can do this using lmer as described here:
>
> ?http://www.jstatsoft.org/v20/i02
>
> ?Or you can use JML methods for Rasch in the MiscPsycho package or you can use
> ?MML methods in the LTM package. What you seem to be doing is treating the eICC
> ?as some kind of parameter for the item; but this is not reasonable I don't
> ?think.
>
>> This
>> > fitting is typically done within each individual and condition of
>> > interest separately, then the resulting parameters are submitted to 2
>> > ANOVAs: one for bias, one for variability. I wonder if this analysis
>> > might be achieved more efficiently using a single mixed effects model,
>> > but I'm having trouble figuring out how to approach coding this.
>>
>
>
> ?I'm not sure I can help you here as I am unclear on what you are doing
> ?exactly. Maybe if we elaborate a bit on what you are trying to do above, we
> ?can do this part next.
>
>>
>> Below
>> > is an example of data similar to that collected in this sort of
>> > research, where individuals fall into two groups (variable "group"),
>> > and are tested under two conditions (variable "cue") across a set of
>> > values from a continuous variable (variable "soa"), with each cue*soa
>> > combination tested repeatedly within each individual. A model like
>> >
>> > fit = lmer(
>> > ? ? formula = response ~ (1|id) + group*cue*soa
>> > ? ? , family = binomial( link='probit' )
>> > ? ? , data = a
>> > )
>> >
>> > employs the probit link, but of course yields estimates for the slope
>> > and intercept of a linear model on the probit scale, and I'm not sure
>> > how (if it's even possible) to convert the conclusions drawn on this
>> > scale to conclusions about the bias and variability parameters of
>> > interest.
>> >
>> > Thoughts?
>> >
>
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From Mike.Lawrence at dal.ca  Fri Oct 29 22:01:59 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Fri, 29 Oct 2010 17:01:59 -0300
Subject: [R-sig-ME] psychometric function fitting with lmer?
In-Reply-To: <67D6DDE5-4F9D-41BC-9395-A7DAF8F0CCE5@ualberta.ca>
References: <AANLkTimW3HOY1r9+LrvGui9gfxmSDjS94fXShYu-DP3B@mail.gmail.com>
	<67D6DDE5-4F9D-41BC-9395-A7DAF8F0CCE5@ualberta.ca>
Message-ID: <AANLkTinMbGHQMPo0wUYL_SSVzdnORffooyBfEXLA9pQa@mail.gmail.com>

On Fri, Oct 29, 2010 at 1:41 PM, Peter Dixon <peter.dixon at ualberta.ca> wrote:
> I would think that the means of the group*cue effects are your bias parameters and the interactions with SOA are the effects on variance.

I don't this this follows because changes in both bias and variability
will (as I understand it) affect the intercept on the probit scale, so
only if you found no support for interactions with SOA (and therefore
no differences between groups/conditions in variability) could you
then unambiguously attribute the main effects to a change in bias.
Even then, your test of bias is surely underpowered since the effects
combine random variation in bias with random variation in the
variability parameter.



From HDoran at air.org  Fri Oct 29 22:05:31 2010
From: HDoran at air.org (Doran, Harold)
Date: Fri, 29 Oct 2010 16:05:31 -0400
Subject: [R-sig-ME] psychometric function fitting with lmer?
In-Reply-To: <AANLkTinrOqMULokF1XKdDCOWbZLYOABrSpi5FX_Usy7K@mail.gmail.com>
References: <AANLkTimW3HOY1r9+LrvGui9gfxmSDjS94fXShYu-DP3B@mail.gmail.com>
	<FEB7C1E22FBCA64F87B5210590C9E0FA045BBD3EA7@DC1EX07CMS.air.org>
	<C0772C7568B5374481D2F8A880E9BBDF06A53AC4E9@DC1EX07CMS.air.org>
	<AANLkTinrOqMULokF1XKdDCOWbZLYOABrSpi5FX_Usy7K@mail.gmail.com>
Message-ID: <C0772C7568B5374481D2F8A880E9BBDF06A53AC54E@DC1EX07CMS.air.org>

The info below is helpful, more comments below.

> -----Original Message-----
> From: mike.lwrnc at gmail.com [mailto:mike.lwrnc at gmail.com] On Behalf Of Mike
> Lawrence
> Sent: Friday, October 29, 2010 3:41 PM
> To: Doran, Harold
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] psychometric function fitting with lmer?
> 
> On Fri, Oct 29, 2010 at 3:29 PM, Doran, Harold <HDoran at air.org> wrote:
> > ? First, I don't know how one uses OLS
> > ?to fit a probit model.
> 
> I've seen it done. Folks usually collapse responses to
> means-per-value-on-the-x-axis  then either use a computationally
> intensive search algorithm to minimize the squared error on the
> proportion scale, or fit a simple linear function on the probit scale
> (when they encounter means of 1 or 0, they "tweak" these values by
> either dropping that data entirely or adding/subtracting some
> arbitrary value).

I think you're right, this seems like an inadvisable way to estimate some model parameters. I'll try and ignore this part of the email and focus on the info below. I will most likely explode if I try and figure out a) how this was done and b) why someone would do it this way when there are well-known ways to estimate model parameters in such cases. 


> Regardless, I suspect we both agree that these are inadvisable ways of
> dealing with this data, but I'm not sure we are on the same page with
> respect to the underlying paradigm motivating the data analysis.
> Whereas the paper you provided appears to be discussing data derived
> from questionnaires with different items, etc, I was thinking (and I
> apologize for failing to be more clear on this earlier) of data
> derived from studies of temporal order judgement and other
> psychophysical discrimination studies. Here's an example that I
> happened to find while searching google for an article not behind a
> pay-wall:
> 
> http://www.psych.ut.ee/~jyri/en/Murd-Kreegipuu-Allik_Perception2009.pdf
> 
> In such studies, individuals are provided two stimuli and asked "which
> one is more X", where the stimuli are manipulated to explore a variety
> of values for the difference of X between them. For example, in
> temporal order judgements, we ask which of two successive stimuli came
> first, right or left, then plot proportion of "right first" responses,
> accumulated over many trials, as a function of the amount of time by
> which the right stimulus led the right stimulus (SOA, or stimulus
> onset asynchrony, where negative values mean the right stimulus
> followed the left stimulus). 

OK, with you here so far, though this kind of thing is a bit away from my field of study. So, let me simplify for sake of argument, we have binary responses at this point where 1 = respondent answer 'right' and 0 = respondent answer 'left'. You also have some observed characteristics of these individuals, call them x. 

Now, you use the terms "likely" and "unlikely" below is something of a colloquial sense, but we can actually quantify this in a model such as:

Pr(1|\theta, \beta) = 1/[1 + exp(beta-theta)]

Which gives the conditional probability that some individual with theta (being an aptitude of some form) will choose the answer "right" also conditional on \beta, which is a characteristic of the item/task itself. Now, you state that you have other observed characteristics, such as "time". You can further condition on these observed characteristics to get the conditional probabilities directly, which seems to be what you are after. If this is right, then the methods in the paper I linked are directly related to this problem, just based on a different data set. It is a general modeling strategy you can employ with lmer.

What I don't understand is what bias or variance are you trying to get at? Bias refers to the property that \beta - E[\hat{\beta}] = 0, which would not hold if the parameter estimate were biased. Maybe I am still a bit unclear on the issue.

> This typically yields a sigmoidal
> function where people are unlikely to say "right-first" when the left
> stimulus leads by a lot (large negative SOA values) and very likely to
> say "right-first" when the right stimulus leads by a lot (large
> positive SOA values. The place where this function crosses 50% is
> termed the point of subjective simultaneity (PSS) and the slope of the
> function indexes the participants' sensitivity (shallow slopes
> indicate poor sensitivity, sharp slopes indicate good sensitivity).
> Researchers are often then interested in how various experimental
> manipulations affect these two characteristics of performance.

Now, if the slope of the curve matters, and it often does, then lmer cannot be used to estimate such a model because the model we demonstrate (Rasch model) assumes all items/tasks have a constant slope. But, other models extend the conditional probability above and can do this. I believe you can accomplish this using LTM package. 


> 
> 
> > Second,
> > ?why are you treating the observed data as a parameter estimate? Why don't
> you
> > ?actually estimate the model parameters (i.e., the item parameters), which
> are
> > ?asymptotically unbiased under certain estimation conditions. You can do
> this in a number of
> > ?ways in R, lme4 can do this using lmer as described here:
> >
> > ?http://www.jstatsoft.org/v20/i02
> >
> > ?Or you can use JML methods for Rasch in the MiscPsycho package or you can
> use
> > ?MML methods in the LTM package. What you seem to be doing is treating the
> eICC
> > ?as some kind of parameter for the item; but this is not reasonable I don't
> > ?think.
> >
> >> This
> >> > fitting is typically done within each individual and condition of
> >> > interest separately, then the resulting parameters are submitted to 2
> >> > ANOVAs: one for bias, one for variability. I wonder if this analysis
> >> > might be achieved more efficiently using a single mixed effects model,
> >> > but I'm having trouble figuring out how to approach coding this.
> >>
> >
> >
> > ?I'm not sure I can help you here as I am unclear on what you are doing
> > ?exactly. Maybe if we elaborate a bit on what you are trying to do above, we
> > ?can do this part next.
> >
> >>
> >> Below
> >> > is an example of data similar to that collected in this sort of
> >> > research, where individuals fall into two groups (variable "group"),
> >> > and are tested under two conditions (variable "cue") across a set of
> >> > values from a continuous variable (variable "soa"), with each cue*soa
> >> > combination tested repeatedly within each individual. A model like
> >> >
> >> > fit = lmer(
> >> > ? ? formula = response ~ (1|id) + group*cue*soa
> >> > ? ? , family = binomial( link='probit' )
> >> > ? ? , data = a
> >> > )
> >> >
> >> > employs the probit link, but of course yields estimates for the slope
> >> > and intercept of a linear model on the probit scale, and I'm not sure
> >> > how (if it's even possible) to convert the conclusions drawn on this
> >> > scale to conclusions about the bias and variability parameters of
> >> > interest.
> >> >
> >> > Thoughts?
> >> >
> >
> >> > _______________________________________________
> >> > R-sig-mixed-models at r-project.org mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >



From pauljohn32 at gmail.com  Sat Oct 30 22:39:23 2010
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Sat, 30 Oct 2010 15:39:23 -0500
Subject: [R-sig-ME] IRT: discrimination parameters from LMER?
Message-ID: <AANLkTi=GRoe0-AXFbOiw6x_W95J_j5+rXek-OnoR9CwZ@mail.gmail.com>

Hello, everybody.

I've fallen into a crowd of IRT users.  I remembered seeing the IRT
with lmer paper.

## Doran, Harold, Douglas Bates, Paul Bliese,
## Maritza Dowling, 2007. ?Estimating the
## Multilevel Rasch Model: With the lme4 Package.?
## Journal of Statistical Software 20(2): 1?18.

I had not understood that a Rasch model is a very specialized kind of
logistic regression.   The items are all assumed to have the same
discrimination parameter.

I started to wonder if I could get a 2 parameter logistic IRT from
lmer, and I'm a bit stuck. I'm comparing against the output from the
rasch function in the "ltm" package.  I'm pasting in the code below
for comparison, and after that I have the output so you can compare.

I found a nice BUGS survey for the various kinds of IRT, in case you
wonder what all of these are.  The argument there is the same one that
Doran et al make, in favor of the idea of using general purpose
software for IRT.

Curtis, S. McKay. 2010. ?BUGS Code for Item Response Theory.? Journal
of Statistical Software, Code Snippets 36(1): 1?34.

In the most restrictive form of the Rasch model, the discrimination
parameter is assumed to be 1, but there is an estimate of the standard
deviation of the latent ability coefficient.  In other implementations
of Rasch, it is assumed the latent trait is N(0,1) and then a
discrimination coefficient is estimated.

I *believe* that is the point of comparison from  ltm's rasch to
lmer's random effect estimate. ltm rasch assumes the individual
ability parameter is N(0,1) and estimates a discrimination coefficient
common to all items

disc * N(0,1)

and the lmer estimates disc as the standard deviation of the random effect.

N(0, disc^2).

So the random effect standard deviation estimated by lmer is one
estimate of that same disc parameter.

This little simulation shows that lmer's fixed effects for the items
are very close to the same as the difficulty parameters in rasch.  The
one disc parameter estimate from ltm is usually closer to the "true"
discrimination value than the standard deviation of the random effect
in lmer.  However, they are "in the ballpark".

Partly I'm curious to know if you agree I'm comparing the numbers properly.

But, also, I want to estimate a different discrimination parameter for
each item, so I can get an IRT 2PL model. It would be nice to get a
3PL to allow a guessing parameter.

Once I realized this mismatch between lmer and the more general IRT, I
started to think either 1) we really do need specialized IRT software,
or 2) perhaps I need to learn to write family code for lmer.

PJ

## Paul Johnson Oct. 30, 2010
## Item Response Theory, compare the
## IRT-specific R package "ltm" with mixed-effct GLM
## perspective of lmer in "lme4" package.

## The argument against IRT specific software
## is that it restricts the user. May be better
## to adapt general purpose programs to
## estimate same models.  That's argued in:

library(ltm)

library(lme4)


### Create Data: 300 respondents with 3 items each.
N <- 300
Adiff <- c(-1, 2, 2) ### actually, easiness
Bdisc <- rep(2.2, 3) ### rasch requires all same!

z <- rnorm( N, 0, sd=1)

#create one long column for latent trait
z3 <- kronecker(Adiff, rep(1,N)) - kronecker(Bdisc, z)
## caution about signs of parameters. Very
## confusing, standard IRT is
## Bdisc ( theta - Adiff)
## So if Adiff = c(-1, 2, 2), IRT standard
## difficulty estimates will be sign reversed
## c(0.5, -0.84, -0.84)


pr <- 1/(1 + exp(-1*(z3)))
y <- rbinom(length(pr), prob=pr, size=1)

id <- rep(1:N, 3)
item <- c( rep(1, N), rep(2, N), rep(3, N))

### the item matrix, N by 3
maty <- matrix(y, ncol=3)


### Long version of data frame for use with lmer
dflong <- data.frame("id"=id, "item"=item, "value"=y)

### convert "item" to factor variable
dflong$item <- as.factor(dflong$item)
### create indicators for items, just experimenting
dflong$item1 <- ifelse(dflong$item == "1",1,0)
dflong$item2 <- ifelse(dflong$item == "2",1,0)
dflong$item3 <- ifelse(dflong$item == "3",1,0)

### fit with rasch in ltm,
### Transform estimates with IRT.param=F,
### gives values comparable to lmer, it gives
### parameters in form b0 + b1*theta
### rather than IRT code like b1(b0 - theta)

dfrasch <- rasch(maty, IRT.param=F)
summary(dfrasch)

### Compare to IRT standard coding, for fun
dfrasch2 <- rasch(maty)
summary(dfrasch2)
### Note discrim param is same as dfrasch, but
### difficulties are different. Can convert
### the dfrasch2 difficulties by multiplying by
### discrimination.


### use lmer, estimates of fixed effect parameters
### "item1", "item2", "item3" are "difficulty
### parameters.

dflmer <- lmer (value ~ -1 + item1 + item2 + item3 + (1|id) ,
data=dflong, family=binomial)
summary(dflmer)

### How to estimate the "discrimination parameter"?
### I'm just guessing now. rasch assumes all
### discrimination parameters for all items are same.
### Recall x ~ N(0, s^2), same as x ~ s * N(0,1).
### So estimated standard deviation of random effect
### is same as one discrimination parameter "s" in
### above.  I think.


dflmer2 <- lmer (value ~ -1 + item + (1|id) , data=dflong, family=binomial)
summary(dflmer2)


ldfy <- ltm( dfy ~ z1 , IRT.param=F)
summary(ldfy)

##################################################


Here's the output:


> library(ltm)
Loading required package: MASS
Loading required package: msm
Loading required package: mvtnorm
Loading required package: polycor
Loading required package: sfsmisc

This is package 'ltm' version '0.9-5'

> library(lme4)
Loading required package: Matrix
Loading required package: lattice

Attaching package: 'Matrix'

The following object(s) are masked from 'package:base':

    det


Attaching package: 'lme4'

The following object(s) are masked from 'package:stats':

    AIC

> N <- 300
> Adiff <- c(-1, 2, 2) ### actually, easiness
> Bdisc <- rep(2.2, 3) ### rasch requires all same!
> z <- rnorm( N, 0, sd=1)
> z3 <- kronecker(Adiff, rep(1,N)) - kronecker(Bdisc, z)
> pr <- 1/(1 + exp(-1*(z3)))
> y <- rbinom(length(pr), prob=pr, size=1)
> id <- rep(1:N, 3)
> item <- c( rep(1, N), rep(2, N), rep(3, N))
> maty <- matrix(y, ncol=3)
> dflong <- data.frame("id"=id, "item"=item, "value"=y)
> dflong$item <- as.factor(dflong$item)
> dflong$item1 <- ifelse(dflong$item == "1",1,0)
> dflong$item2 <- ifelse(dflong$item == "2",1,0)
> dflong$item3 <- ifelse(dflong$item == "3",1,0)
> dfrasch <- rasch(maty, IRT.param=F)
summary(dfrasch)
>
Call:
rasch(data = maty, IRT.param = F)

Model Summary:
   log.Lik      AIC      BIC
 -483.7193 975.4385 990.2537

Coefficients:
        value std.err  z.vals
Item1 -1.1239  0.2029 -5.5392
Item2  1.8955  0.2371  7.9957
Item3  1.7567  0.2305  7.6227
z      1.8959  0.2336  8.1157

Integration:
method: Gauss-Hermite
quadrature points: 21

Optimization:
Convergence: 0
max(|grad|): 0.003
quasi-Newton: BFGS


> dfrasch2 <- rasch(maty)
> summary(dfrasch2)

Call:
rasch(data = maty)

Model Summary:
   log.Lik      AIC      BIC
 -483.7193 975.4385 990.2537

Coefficients:
                value std.err  z.vals
Dffclt.Item 1  0.5928  0.1082  5.4799
Dffclt.Item 2 -0.9998  0.1249 -8.0022
Dffclt.Item 3 -0.9266  0.1211 -7.6502
Dscrmn         1.8959  0.2336  8.1157

Integration:
method: Gauss-Hermite
quadrature points: 21

Optimization:
Convergence: 0
max(|grad|): 0.003
quasi-Newton: BFGS


> dflmer <- lmer (value ~ -1 + item1 + item2 + item3 + (1|id) , data=dflong, family=binomial)
> summary(dflmer)
Generalized linear mixed model fit by the Laplace approximation
Formula: value ~ -1 + item1 + item2 + item3 + (1 | id)
   Data: dflong
 AIC  BIC logLik deviance
 984 1003   -488      976
Random effects:
 Groups Name        Variance Std.Dev.
 id     (Intercept) 2.9100   1.7059
Number of obs: 900, groups: id, 300

Fixed effects:
      Estimate Std. Error z value Pr(>|z|)
item1  -1.1155     0.1754  -6.358 2.04e-10 ***
item2   1.8382     0.1938   9.486  < 2e-16 ***
item3   1.7049     0.1898   8.984  < 2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
      item1 item2
item2 0.247
item3 0.255 0.310
>




-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas



From HDoran at air.org  Sat Oct 30 23:54:15 2010
From: HDoran at air.org (Doran, Harold)
Date: Sat, 30 Oct 2010 17:54:15 -0400
Subject: [R-sig-ME] IRT: discrimination parameters from LMER?
In-Reply-To: <AANLkTi=GRoe0-AXFbOiw6x_W95J_j5+rXek-OnoR9CwZ@mail.gmail.com>
References: <AANLkTi=GRoe0-AXFbOiw6x_W95J_j5+rXek-OnoR9CwZ@mail.gmail.com>
Message-ID: <C0772C7568B5374481D2F8A880E9BBDF06A650CA1B@DC1EX07CMS.air.org>

IRT people can be odd. Yes, your interpretation of the differences between the ltm package and lme4 are correct. lmer estimates the standard deviation of the population distribution, but ltm fixes it and then estimates a discrimination value that is constant for all items. It is currently not possible to estimate the 2pl using lmer, but that model can be easily estimated using other functions, such as those in ltm.   
________________________________________
From: r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] On Behalf Of Paul Johnson [pauljohn32 at gmail.com]
Sent: Saturday, October 30, 2010 4:39 PM
To: R-SIG-Mixed-Models at r-project.org
Subject: [R-sig-ME] IRT: discrimination parameters from LMER?

Hello, everybody.

I've fallen into a crowd of IRT users.  I remembered seeing the IRT
with lmer paper.

## Doran, Harold, Douglas Bates, Paul Bliese,
## Maritza Dowling, 2007. ?Estimating the
## Multilevel Rasch Model: With the lme4 Package.?
## Journal of Statistical Software 20(2): 1?18.

I had not understood that a Rasch model is a very specialized kind of
logistic regression.   The items are all assumed to have the same
discrimination parameter.

I started to wonder if I could get a 2 parameter logistic IRT from
lmer, and I'm a bit stuck. I'm comparing against the output from the
rasch function in the "ltm" package.  I'm pasting in the code below
for comparison, and after that I have the output so you can compare.

I found a nice BUGS survey for the various kinds of IRT, in case you
wonder what all of these are.  The argument there is the same one that
Doran et al make, in favor of the idea of using general purpose
software for IRT.

Curtis, S. McKay. 2010. ?BUGS Code for Item Response Theory.? Journal
of Statistical Software, Code Snippets 36(1): 1?34.

In the most restrictive form of the Rasch model, the discrimination
parameter is assumed to be 1, but there is an estimate of the standard
deviation of the latent ability coefficient.  In other implementations
of Rasch, it is assumed the latent trait is N(0,1) and then a
discrimination coefficient is estimated.

I *believe* that is the point of comparison from  ltm's rasch to
lmer's random effect estimate. ltm rasch assumes the individual
ability parameter is N(0,1) and estimates a discrimination coefficient
common to all items

disc * N(0,1)

and the lmer estimates disc as the standard deviation of the random effect.

N(0, disc^2).

So the random effect standard deviation estimated by lmer is one
estimate of that same disc parameter.

This little simulation shows that lmer's fixed effects for the items
are very close to the same as the difficulty parameters in rasch.  The
one disc parameter estimate from ltm is usually closer to the "true"
discrimination value than the standard deviation of the random effect
in lmer.  However, they are "in the ballpark".

Partly I'm curious to know if you agree I'm comparing the numbers properly.

But, also, I want to estimate a different discrimination parameter for
each item, so I can get an IRT 2PL model. It would be nice to get a
3PL to allow a guessing parameter.

Once I realized this mismatch between lmer and the more general IRT, I
started to think either 1) we really do need specialized IRT software,
or 2) perhaps I need to learn to write family code for lmer.

PJ

## Paul Johnson Oct. 30, 2010
## Item Response Theory, compare the
## IRT-specific R package "ltm" with mixed-effct GLM
## perspective of lmer in "lme4" package.

## The argument against IRT specific software
## is that it restricts the user. May be better
## to adapt general purpose programs to
## estimate same models.  That's argued in:

library(ltm)

library(lme4)


### Create Data: 300 respondents with 3 items each.
N <- 300
Adiff <- c(-1, 2, 2) ### actually, easiness
Bdisc <- rep(2.2, 3) ### rasch requires all same!

z <- rnorm( N, 0, sd=1)

#create one long column for latent trait
z3 <- kronecker(Adiff, rep(1,N)) - kronecker(Bdisc, z)
## caution about signs of parameters. Very
## confusing, standard IRT is
## Bdisc ( theta - Adiff)
## So if Adiff = c(-1, 2, 2), IRT standard
## difficulty estimates will be sign reversed
## c(0.5, -0.84, -0.84)


pr <- 1/(1 + exp(-1*(z3)))
y <- rbinom(length(pr), prob=pr, size=1)

id <- rep(1:N, 3)
item <- c( rep(1, N), rep(2, N), rep(3, N))

### the item matrix, N by 3
maty <- matrix(y, ncol=3)


### Long version of data frame for use with lmer
dflong <- data.frame("id"=id, "item"=item, "value"=y)

### convert "item" to factor variable
dflong$item <- as.factor(dflong$item)
### create indicators for items, just experimenting
dflong$item1 <- ifelse(dflong$item == "1",1,0)
dflong$item2 <- ifelse(dflong$item == "2",1,0)
dflong$item3 <- ifelse(dflong$item == "3",1,0)

### fit with rasch in ltm,
### Transform estimates with IRT.param=F,
### gives values comparable to lmer, it gives
### parameters in form b0 + b1*theta
### rather than IRT code like b1(b0 - theta)

dfrasch <- rasch(maty, IRT.param=F)
summary(dfrasch)

### Compare to IRT standard coding, for fun
dfrasch2 <- rasch(maty)
summary(dfrasch2)
### Note discrim param is same as dfrasch, but
### difficulties are different. Can convert
### the dfrasch2 difficulties by multiplying by
### discrimination.


### use lmer, estimates of fixed effect parameters
### "item1", "item2", "item3" are "difficulty
### parameters.

dflmer <- lmer (value ~ -1 + item1 + item2 + item3 + (1|id) ,
data=dflong, family=binomial)
summary(dflmer)

### How to estimate the "discrimination parameter"?
### I'm just guessing now. rasch assumes all
### discrimination parameters for all items are same.
### Recall x ~ N(0, s^2), same as x ~ s * N(0,1).
### So estimated standard deviation of random effect
### is same as one discrimination parameter "s" in
### above.  I think.


dflmer2 <- lmer (value ~ -1 + item + (1|id) , data=dflong, family=binomial)
summary(dflmer2)


ldfy <- ltm( dfy ~ z1 , IRT.param=F)
summary(ldfy)

##################################################


Here's the output:


> library(ltm)
Loading required package: MASS
Loading required package: msm
Loading required package: mvtnorm
Loading required package: polycor
Loading required package: sfsmisc

This is package 'ltm' version '0.9-5'

> library(lme4)
Loading required package: Matrix
Loading required package: lattice

Attaching package: 'Matrix'

The following object(s) are masked from 'package:base':

    det


Attaching package: 'lme4'

The following object(s) are masked from 'package:stats':

    AIC

> N <- 300
> Adiff <- c(-1, 2, 2) ### actually, easiness
> Bdisc <- rep(2.2, 3) ### rasch requires all same!
> z <- rnorm( N, 0, sd=1)
> z3 <- kronecker(Adiff, rep(1,N)) - kronecker(Bdisc, z)
> pr <- 1/(1 + exp(-1*(z3)))
> y <- rbinom(length(pr), prob=pr, size=1)
> id <- rep(1:N, 3)
> item <- c( rep(1, N), rep(2, N), rep(3, N))
> maty <- matrix(y, ncol=3)
> dflong <- data.frame("id"=id, "item"=item, "value"=y)
> dflong$item <- as.factor(dflong$item)
> dflong$item1 <- ifelse(dflong$item == "1",1,0)
> dflong$item2 <- ifelse(dflong$item == "2",1,0)
> dflong$item3 <- ifelse(dflong$item == "3",1,0)
> dfrasch <- rasch(maty, IRT.param=F)
summary(dfrasch)
>
Call:
rasch(data = maty, IRT.param = F)

Model Summary:
   log.Lik      AIC      BIC
 -483.7193 975.4385 990.2537

Coefficients:
        value std.err  z.vals
Item1 -1.1239  0.2029 -5.5392
Item2  1.8955  0.2371  7.9957
Item3  1.7567  0.2305  7.6227
z      1.8959  0.2336  8.1157

Integration:
method: Gauss-Hermite
quadrature points: 21

Optimization:
Convergence: 0
max(|grad|): 0.003
quasi-Newton: BFGS


> dfrasch2 <- rasch(maty)
> summary(dfrasch2)

Call:
rasch(data = maty)

Model Summary:
   log.Lik      AIC      BIC
 -483.7193 975.4385 990.2537

Coefficients:
                value std.err  z.vals
Dffclt.Item 1  0.5928  0.1082  5.4799
Dffclt.Item 2 -0.9998  0.1249 -8.0022
Dffclt.Item 3 -0.9266  0.1211 -7.6502
Dscrmn         1.8959  0.2336  8.1157

Integration:
method: Gauss-Hermite
quadrature points: 21

Optimization:
Convergence: 0
max(|grad|): 0.003
quasi-Newton: BFGS


> dflmer <- lmer (value ~ -1 + item1 + item2 + item3 + (1|id) , data=dflong, family=binomial)
> summary(dflmer)
Generalized linear mixed model fit by the Laplace approximation
Formula: value ~ -1 + item1 + item2 + item3 + (1 | id)
   Data: dflong
 AIC  BIC logLik deviance
 984 1003   -488      976
Random effects:
 Groups Name        Variance Std.Dev.
 id     (Intercept) 2.9100   1.7059
Number of obs: 900, groups: id, 300

Fixed effects:
      Estimate Std. Error z value Pr(>|z|)
item1  -1.1155     0.1754  -6.358 2.04e-10 ***
item2   1.8382     0.1938   9.486  < 2e-16 ***
item3   1.7049     0.1898   8.984  < 2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
      item1 item2
item2 0.247
item3 0.255 0.310
>




--
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From marie_helene48 at hotmail.com  Sun Oct 31 15:21:13 2010
From: marie_helene48 at hotmail.com (=?iso-8859-1?B?TWFyaWUtSOls6G5lIEhhY2hleQ==?=)
Date: Sun, 31 Oct 2010 14:21:13 +0000
Subject: [R-sig-ME] Overdispersion in Poisson mixed-model?
Message-ID: <SNT131-w44C9662A0818FC157CFBD0E1470@phx.gbl>


Hi,

I would like to know, in lmer, how to compute...:

1-Overdispersion of the model (estimated scale parameter)
2-% of variation explained by a model


1- For overdispersion, I found (on this mailing list) thant you can do
sqrt(sum(c(model at resid, model at u)^2)/length(model at resid)) = 1.29

(what is "u", by the way?)

But I also found #lme4:::sigma(model) = 1

Both dont give the same result. Which one should I use? And can I use this value
to say that my residuals are no longer overdispersed, due to the addition of random effects? 
When I had a Poisson glm model, the res. deviance/res. DF was 4.09.

2-For the % of variation explained, I used
(null model @deviance["wrss"] - model at deviance["wrss"])/null model at deviance["wrss"]
(also found on that mailing list, except the value was divided by the model deviance, instead of
the null model deviance... I thought it was the other way around...)
Do you think this is right to comment on how my model explained the variation observed? And why do 
we use weighted r sum of squared instead of, say, ML deviance?

Last question: if a model only explains 5% of the variation, should I not use it at all? I' m sorry, I know
it's a stats question but it's been bugging me.

Thank you in advance

Marie-Helene Hachey
M. Sc. Student 		 	   		  


From acopperbean at yahoo.com  Sat Oct 30 19:07:18 2010
From: acopperbean at yahoo.com (Jie Li)
Date: Sat, 30 Oct 2010 10:07:18 -0700 (PDT)
Subject: [R-sig-ME] fitting glmm under lme4 and Gauss Hermite integration
Message-ID: <908430.86146.qm@web51301.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101030/95653d2f/attachment.pl>

From evelien_jongepier at hotmail.com  Sat Oct 30 10:54:23 2010
From: evelien_jongepier at hotmail.com (Evelien Jongepier)
Date: Sat, 30 Oct 2010 10:54:23 +0200
Subject: [R-sig-ME] ZIP MCMCglmm AND separate random est. for levels of
	fixed factor
Message-ID: <COL115-W26A1EA41EC29727C31EAB28F460@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101030/f94e5b78/attachment.pl>

From j.hadfield at ed.ac.uk  Sun Oct 31 17:36:07 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sun, 31 Oct 2010 16:36:07 +0000
Subject: [R-sig-ME] ZIP MCMCglmm AND separate random est. for levels of
 fixed factor
In-Reply-To: <COL115-W26A1EA41EC29727C31EAB28F460@phx.gbl>
References: <COL115-W26A1EA41EC29727C31EAB28F460@phx.gbl>
Message-ID: <20101031163607.75614z093739ypkw@www.staffmail.ed.ac.uk>

Dear Evelien,

In answer to your questions:

1) Is it conceptually a good idea? I am new with MCMCglmm but I
couldn't find any posts on similar problems and wondered whether this
should be a warning sign.

Yes, I think the model makes sense, and you seem to have a lot of data  
replicated at the correct level.

2) And pragmatically? Am I bound to get severe convergence issues
(just asking for an educated guess)?

ZIP models are not well implemented in MCMCglmm and so tend to  
converge/mix poorly, particularly if the probability of zero-inflation  
is extreme (0 or 1). Hurdle and zero-altered models are may be a  
better alternative.

3) What would the syntax of such a random structure be?

I think it should be idh(at.level(trait,1):cln):spp

4) and should I be aware of any specific considerations regarding the
prior?

You should probably fix the residual variance for the zero-inflation  
at something (e.g. 1) because it cannot be estimated from the data.  
The results can be sensitive to the prior, and if you don't have good  
prior information you should keep nu small (<<1) or use  
parameter-expanded priors (I tend to use these more and more). Always  
check to see how influential the prior is.

Cheers,

Jarrod



Quoting Evelien Jongepier <evelien_jongepier at hotmail.com>:

>
> Dear all,
>
> I would appreciate some help on the following:
> I am trying to run MCMCglmm with zipoisson distribution AND separate  
> random effects for a fixed binary factor
>
> Some background:
> I want to test for the effect of clonality (cln -> binary (yes or  
> no)), environmental factors (e.g. fire and rain) and their  
> interaction on species abundances (ab), where I use sampled location  
> (pl.id) as random factor.
>
> my data looks smth like this:
> pl.id  - spp - ab - cln - fire.....
> 001 - 01 - 28 - n - 10
> .....
> 001 - 35 - 11 - y - 10
> .....
> .....
> 770 - 01 - 10 - n - 17
> .....
> 770 - 35 - 12 - y - 17
> [so I've got 770 plots and 35 species]
>
> Species abundance is poisson distributed but severely zero inflated  
> as each species only occurs in a subset of plots.
> Moreover, I have reason to believe that clonality (a species level  
> trait) further contributes to zero inflation (so I add trait:cln).
> Otherwise I am not interested in the effect of environmental vars or  
> random factors on the zero-inflation process (so I use  
> at.level;(trait,1):...).
>
> which comes down to [please correct me if I am wrong]:
>
> mdl <- MCMCglmm(
> ab ~ trait - 1 + trait:cln + at.level(trait,1):(cln*(fire + rain)),
> random=~idh(at.level(trait,1)):pl.id,
> rcov = ~idh(trait):units,
> prior=pr1, family = "zipoisson",
> .....data=dat)
>
> where pr1 is e.g. a flat prior for B and half-Cauchy prior for G
>
> However, I would like to account for variation explained by species  
> for clonals and non-clonals separately.
> Without zero-inflation this would look something like:
>
> random=~pl.id + idh(cln):spp
>
> But now I want to include this structure in "mdl", where the random  
> effects are fitted to test only for their potential effects on the  
> poisson processes
> Intuitively I would suspect a syntax like this:
>
>
> random=~idh(at.level(trait,1)):pl.id +  
> idh(at.level(trait,1)):idh(cln):spp or perhaps
> random=~idh(at.level(trait,1)):pl.id + idh(at.level(trait,1)):cln:spp
>
>
> I fiddled around quite a bit but generally got this message:
>
> Error in buildZ(rmodel.terms[r], data = data) : object (idh(cln) and  
> pl.id) not found
>
> So my questions are:
> 1) Is it conceptually a good idea? I am not overly familiar with  
> MCMCglmm but I couldn't find any posts on similar problems and  
> wondered whether this should be a warning sign.
> 2) Am I bound to get severe convergence issues (just asking for an  
> educated guess)?
> 3) What would the syntax of such a random structure be.
> 4) and should I be aware of any specific considerations regarding the prior?
>
> Would be great if anyone could enlighten me a bit or perhaps share  
> experiences if you are trying to fit a similar model
>
> Thanks!
> Evelien Jongepier
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From bbolker at gmail.com  Sun Oct 31 17:45:09 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 31 Oct 2010 12:45:09 -0400
Subject: [R-sig-ME] fitting glmm under lme4 and Gauss Hermite integration
In-Reply-To: <908430.86146.qm@web51301.mail.re2.yahoo.com>
References: <908430.86146.qm@web51301.mail.re2.yahoo.com>
Message-ID: <4CCD9D15.2000903@gmail.com>

On 10-10-30 01:07 PM, Jie Li wrote:
> Dear colleagues,
> 
> Happy Halloween.
> 
> When I try fitting glmm under lme4 using the following code:
> 
> x=as.factor(rep(c("1","2","3", "4", "5", "6"),each=2))
> y=c(14, 18, 10, 47, 13, 24, 10, 12,  1,  0,  6,  6)
> offset=c(5.505332,5.645447, 5.549076, 5.886104, 6.023448, 6.177944, 6.077642, 
> 6.186209,
> 5.030438, 5.117994, 5.170484, 5.493061)
> eu=gl(12,1)
> try=data.frame(x,y,eu,offset)
> fit <- glmer(y ~ x + (1 | eu) + offset(log(adjust)),
>               family = poisson, data =try)
> 
> 
> A message pops up, saying "Number of levels of a grouping factor for the random 
> effects
> is *equal* to n, the number of observations". 
> 
> 
> Question1: can I still use the fit statistics? (Should the levels be less than 
> the number of observations? But I can't help it. My data are like that)

  In principle, yes.
 1. You're essentially using the random effects here to account for
individual-level variance (i.e. a lognormal-Poisson model), rather than
accounting for grouping/correlation.
 2. This is a very small dataset. In particular, fitting k=6
fixed-effect parameters to n=12 data points means that you will be
far from reliable asymptotic rules of thumb (we would generally
prefer n/k >= 10 ...). I would strongly recommend bootstrapped
confidence intervals, or some other reasonably robust small-sample
procedure (permutation test, parametric bootstrap ...)
> 
> Question2:
> 
> 
> When running the glmm function under the repeated package written by James 
> Lindsey, I encountered the problem of trying to decide on the value of points, 
> ie. Gauss Hermite integration numbers. Different points resulted in quite 
> different fit statistics. Here is my code:
> 
> 
> fit2<-glmm(y~x, family=poisson, offset=offset, nest=gl(12,1),points=4,data=try)
> 
> Is it true that the more points, the better? A book says points=20 entails 
> decent approximation, but there???s an error msg when I increased my point number 
> to 10. It says ???Product of probabilities is too small to calculate.??? May I seek 
> your advice on this issue (what point should I be using)? Are there good 
> references you would recommend so that I can understand better understand Gauss 
> Hermite integration? BTW, glmer under lme4 uses adapted Gauss-Hermite 
> integration too.

   glmer uses the Laplace approximation (aGH with 1 quadrature point)
unless you set nAGQ>1.  I might recommend [Jiang, Jiming. 2007. Linear
and generalized linear mixed models and their applications. Springer].
<http://lme4.r-forge.r-project.org/book/Ch5.pdf> is Bates's draft of his
new book, but it only goes as far as defining the Laplace approximation.
 If you already have "a book" that talks about GH, does it give any more
information?

  I would suggest comparing the results of glmer() and glmm() for
different numbers of quadrature points; see if the two packages give
similar estimates, and see whether the estimates seem to be behaving
reasonably/converging to something sensible as you increase the number
of quadrature points. (For "extra credit" :-) or if this is really
important you could also try comparing the results with the glmmML package.)

  good luck,
    Ben Bolker



From bates at stat.wisc.edu  Sun Oct 31 17:52:54 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 31 Oct 2010 11:52:54 -0500
Subject: [R-sig-ME] [R] Need help with lmer model specification syntax
 for nested mixed model
In-Reply-To: <1288510503401-3020895.post@n4.nabble.com>
References: <1288510503401-3020895.post@n4.nabble.com>
Message-ID: <AANLkTin7x2AdVLMdqs3M2eGSCL9aN2jeQ2rqOBVOAoX5@mail.gmail.com>

On Sun, Oct 31, 2010 at 2:35 AM, Carabiniero <jason at troutnut.com> wrote:
>
> I haven't been able to fully make sense of the conflicting online information
> about whether and how to specify nesting structure for a nested, mixed
> model. ?I'll describe my experiment and hopefully somebody who knows lme4
> well can help.
>
> We're measuring the fluorescence intensity of brain slices from frogs that
> have undergone various treatments. ?We want to use multcomp to look for
> differences between treatments, while accounting for the variance introduced
> by the random effects of brain and slice. ?There are a few measurements per
> slice, several slices per brain, and several brains per treatment. ?In the
> data file, the numbering for slices starts over from 1 for each brain, and
> the numbering for brains starts over from 1 for each treatment.

This is what I call "implicit nesting" in the definition of the
variables.  My general recommendation is to create new variables that
reflect the actual structure of the data, as in

mydata <- within(mydata, {
    ubrain <- factor(Treatment:Brain)
    uslice <- factor(Treatment:Brain:Slice)
}

then define the model in terms of these factors, ubrain and uslice,
that have the desirable property that each distinct brain has a
distinct label.

> In other words: ?Treatment is a fixed effect, brain is a random effect
> nested in treatment, and slice is a random effect nested in brain.
>
> As I understood the documentation, this is the correct specification:
>
> log(Intensity) ~ Treatment + (1|Brain) + (1|Slice)

That will work with ubrain and uslice instead of the implicitly nested
Brain and Slice.

> However, I don't see how lmer understands the correct nesting structure from
> that. ?How does it know brain isn't crossed with treatment?

lmer can determine the crossed or nested structure from the data
whenever the data reflect the structure.  Implicitly nested factors
don't reflect the structure of the data and rely on external
information to augment the data given.

The computational methods used in lmer don't depend on whether the
grouping factors for the random effects are nested or not.  However
they do require that the grouping factors are well-defined.

> Here are two other things I tried, and each gave different results:
>
> log(Intensity) ~ Treatment + (1|Slice/Brain/Treatment)
> log(Intensity) ~ Treatment + (1|Brain/Treatment) + (1|Slice/Brain)
>
> I'm not sure why these things give different results, or which one (if any)
> is right. ?Can anyone help?

I have taken the liberty of cc:ing the R-SIG-Mixed-Models mailing list
on this reply and suggest that any follow-ups be on that list.



From bbolker at gmail.com  Sun Oct 31 18:06:26 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 31 Oct 2010 13:06:26 -0400
Subject: [R-sig-ME] fitting glmm under lme4 and Gauss Hermite integration
In-Reply-To: <908430.86146.qm@web51301.mail.re2.yahoo.com>
References: <908430.86146.qm@web51301.mail.re2.yahoo.com>
Message-ID: <4CCDA212.6090603@gmail.com>

PS it looks like the coefficients are quite stable under increasing
numbers of quadrature points ...


x=factor(rep(1:6,each=2))
y=c(14, 18, 10, 47, 13, 24, 10, 12,  1,  0,  6,  6)
adjust=c(5.505332,5.645447, 5.549076, 5.886104, 6.023448,
  6.177944, 6.077642, 6.186209, 5.030438, 5.117994, 5.170484, 5.493061)
eu=factor(1:12)
try=data.frame(x,y,eu,adjust)

library(lme4)
fit <- glmer(y ~ x + (1 | eu) + offset(log(adjust)),
              family = poisson, data =try)

nagqvec <- 1:20
fitlist1 <- lapply(nagqvec,
                   glmer,
                   formula=y ~ x + (1 | eu) + offset(log(adjust)),
                   family=poisson,
                   data=try,
                   start=NULL,
                   verbose=FALSE)

t(sapply(fitlist1,fixef))


On 10-10-30 01:07 PM, Jie Li wrote:
> Dear colleagues,
> 
> Happy Halloween.
> 
> When I try fitting glmm under lme4 using the following code:
> 
> x=as.factor(rep(c("1","2","3", "4", "5", "6"),each=2))
> y=c(14, 18, 10, 47, 13, 24, 10, 12,  1,  0,  6,  6)
> offset=c(5.505332,5.645447, 5.549076, 5.886104, 6.023448, 6.177944, 6.077642, 
> 6.186209,
> 5.030438, 5.117994, 5.170484, 5.493061)
> eu=gl(12,1)
> try=data.frame(x,y,eu,offset)
> fit <- glmer(y ~ x + (1 | eu) + offset(log(adjust)),
>               family = poisson, data =try)
> 
> 
> A message pops up, saying "Number of levels of a grouping factor for the random 
> effects
> is *equal* to n, the number of observations". 
> 
> 
> Question1: can I still use the fit statistics? (Should the levels be less than 
> the number of observations? But I can't help it. My data are like that)
> 
> Question2:
> 
> 
> When running the glmm function under the repeated package written by James 
> Lindsey, I encountered the problem of trying to decide on the value of points, 
> ie. Gauss Hermite integration numbers. Different points resulted in quite 
> different fit statistics. Here is my code:
> 
> 
> fit2<-glmm(y~x, family=poisson, offset=offset, nest=gl(12,1),points=4,data=try)
> 
> Is it true that the more points, the better? A book says points=20 entails 
> decent approximation, but there???s an error msg when I increased my point number 
> to 10. It says ???Product of probabilities is too small to calculate.??? May I seek 
> your advice on this issue (what point should I be using)? Are there good 
> references you would recommend so that I can understand better understand Gauss 
> Hermite integration? BTW, glmer under lme4 uses adapted Gauss-Hermite 
> integration too.
> 
> 
> Thanks so much. Bon week-end. -- jie
>  
>  Jie Li
> Department of Statistics
> 1219 Snedecor Hall
> Iowa State University
> Ames, IA 50010
> lij at iastate.edu
> (515) 294-5790
> 
> 
> 
>       
> 	[[alternative HTML version deleted]]
> 
> 
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From maj at waikato.ac.nz  Mon Nov  1 00:34:22 2010
From: maj at waikato.ac.nz (Murray Jorgensen)
Date: Mon, 01 Nov 2010 12:34:22 +1300
Subject: [R-sig-ME] John Nelder and Nelder-Lee HGLMs
Message-ID: <4CCDFCFE.7070103@waikato.ac.nz>

Roger Payne's obituary for John Nelder may be found at

http://www.vsni.co.uk/home-pages/john-nelder/

There can be no doubt that John Nelder has changed the face of modern 
statistics with his work on linear models and generalized linear models 
which form the core of the Genstat package and were central in the 
development of S and R.

I want to draw the attention of this Sig to the following passage in the 
obituary in which GLMMs are criticised.


<quote>
John?s other major activity at Imperial College was his collaboration 
with Youngjo Lee to develop the theory of hierarchical generalized 
linear models (HGLMs); see the papers by Lee & Nelder (1996, 2001, 2006) 
and the book by Lee, Nelder & Pawitan (2006). The 1996 and 2006 papers 
were presented as ?read papers? at meetings of the Royal Statistical 
Society; it is impressive to note that John was 81 years old when he and 
Youngjo presented the 2006 paper. HGLMs aimed to provide satisfactory 
methods of analysis for non-Normal data when there is more than one 
source of random variation. John viewed generalized linear models as a 
way of liberating statisticians from the ?tyranny? of the Normal 
distribution, and was a little bemused to see this same tyranny 
reestablished in methods that were devised initially to extend 
generalized linear models. These generalized linear mixed models (GLMMs) 
catered for additional random variation by adding additional 
Normally-distributed random effects into the linear model of the 
generalized linear model. John and Youngjo?s new HGLMs extended the 
methodology to include the beta-binomial, gamma and inverse-gamma 
distributions, and showed that the conjugate HGLMs (namely binomial GLM 
with additional beta-binomial random effects, or Poisson with gamma, or 
gamma with inverse gamma) had attractive advantages in their 
mathematical theory, computing algorithms and philosophical 
interpretation. HGLMs can be fitted very efficiently by two interlinked 
generalized linear models. So we have access to a familiar repertoire of 
model checking techniques, and can base our choice of error 
distributions on the data rather than on prejudice or software 
limitations. Furthermore the analysis can still be carried out 
interactively ? always a very important consideration for John.
</quote>


I have some difficulties with the views of this paragraph and wish to 
make some comments. Firstly HGLMs do allow added flexibility to the 
modelling of non-normal data by allowing for non-normal distributions of 
random effects. However unless there is knowledge about the about the 
nature of the random effect distributions from the context of the 
application this flexibility just adds problems by allowing a much 
larger model space within which to choose and estimate a model.

Secondly Nelder and Lee do not use standard likelihood or Bayesian 
methods to fit their HGLMs but instead develop another construction 
called h-likelihood. It is a while since I tried to look at these but I 
remember being reminded of the 'classification likelihood' approach to 
finite mixture modelling where assignments of data to components were 
treated as parameters to be estimated along with the component 
parameters and mixing proportions. A number of papers have commented 
that this is not a good idea, for example
@ARTICLE{lr83,
   author  = {Little, R. J. A. and Rubin, D. B.},
   title   = {On jointly estimating parameters and
missing data by maximizing the complete data likelihood},
   journal = {Amer. Statist.},
   volume  = {37},
   number  = {},
   pages   = {218-220},
   year    = {1983}
}

I wonder if members of this list can point me to discussions, critical 
or supportive, of Lee and Nelder's models and methods. Of course I am 
aware of the discussion of their JRSS paper so you needn't remind me of 
that.

Also, is anyone aware if someone is planning to implement HGLMs, by any 
estimation method, in R?

Best wishes,  Murray


-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    Home +64 7 825 0441   Mobile 021 0200 8350



From s.blomberg1 at uq.edu.au  Mon Nov  1 01:41:15 2010
From: s.blomberg1 at uq.edu.au (Simon Blomberg)
Date: Mon, 01 Nov 2010 10:41:15 +1000
Subject: [R-sig-ME] John Nelder and Nelder-Lee HGLMs
In-Reply-To: <4CCDFCFE.7070103@waikato.ac.nz>
References: <4CCDFCFE.7070103@waikato.ac.nz>
Message-ID: <4CCE0CAB.1050002@uq.edu.au>

Jim Lindsey has a function for HGLMs called hnlmix in his "repeated" 
package (non-CRAN)

http://tolstoy.newcastle.edu.au/R/help/02a/3721.html

http://www.commanster.eu/rcode.html

Cheers,

Simon.

On 01/11/10 09:34, Murray Jorgensen wrote:
> Roger Payne's obituary for John Nelder may be found at
>
> http://www.vsni.co.uk/home-pages/john-nelder/
>
> There can be no doubt that John Nelder has changed the face of modern 
> statistics with his work on linear models and generalized linear 
> models which form the core of the Genstat package and were central in 
> the development of S and R.
>
> I want to draw the attention of this Sig to the following passage in 
> the obituary in which GLMMs are criticised.
>
>
> <quote>
> John?s other major activity at Imperial College was his collaboration 
> with Youngjo Lee to develop the theory of hierarchical generalized 
> linear models (HGLMs); see the papers by Lee & Nelder (1996, 2001, 
> 2006) and the book by Lee, Nelder & Pawitan (2006). The 1996 and 2006 
> papers were presented as ?read papers? at meetings of the Royal 
> Statistical Society; it is impressive to note that John was 81 years 
> old when he and Youngjo presented the 2006 paper. HGLMs aimed to 
> provide satisfactory methods of analysis for non-Normal data when 
> there is more than one source of random variation. John viewed 
> generalized linear models as a way of liberating statisticians from 
> the ?tyranny? of the Normal distribution, and was a little bemused to 
> see this same tyranny reestablished in methods that were devised 
> initially to extend generalized linear models. These generalized 
> linear mixed models (GLMMs) catered for additional random variation by 
> adding additional Normally-distributed random effects into the linear 
> model of the generalized linear model. John and Youngjo?s new HGLMs 
> extended the methodology to include the beta-binomial, gamma and 
> inverse-gamma distributions, and showed that the conjugate HGLMs 
> (namely binomial GLM with additional beta-binomial random effects, or 
> Poisson with gamma, or gamma with inverse gamma) had attractive 
> advantages in their mathematical theory, computing algorithms and 
> philosophical interpretation. HGLMs can be fitted very efficiently by 
> two interlinked generalized linear models. So we have access to a 
> familiar repertoire of model checking techniques, and can base our 
> choice of error distributions on the data rather than on prejudice or 
> software limitations. Furthermore the analysis can still be carried 
> out interactively ? always a very important consideration for John.
> </quote>
>
>
> I have some difficulties with the views of this paragraph and wish to 
> make some comments. Firstly HGLMs do allow added flexibility to the 
> modelling of non-normal data by allowing for non-normal distributions 
> of random effects. However unless there is knowledge about the about 
> the nature of the random effect distributions from the context of the 
> application this flexibility just adds problems by allowing a much 
> larger model space within which to choose and estimate a model.
>
> Secondly Nelder and Lee do not use standard likelihood or Bayesian 
> methods to fit their HGLMs but instead develop another construction 
> called h-likelihood. It is a while since I tried to look at these but 
> I remember being reminded of the 'classification likelihood' approach 
> to finite mixture modelling where assignments of data to components 
> were treated as parameters to be estimated along with the component 
> parameters and mixing proportions. A number of papers have commented 
> that this is not a good idea, for example
> @ARTICLE{lr83,
>   author  = {Little, R. J. A. and Rubin, D. B.},
>   title   = {On jointly estimating parameters and
> missing data by maximizing the complete data likelihood},
>   journal = {Amer. Statist.},
>   volume  = {37},
>   number  = {},
>   pages   = {218-220},
>   year    = {1983}
> }
>
> I wonder if members of this list can point me to discussions, critical 
> or supportive, of Lee and Nelder's models and methods. Of course I am 
> aware of the discussion of their JRSS paper so you needn't remind me 
> of that.
>
> Also, is anyone aware if someone is planning to implement HGLMs, by 
> any estimation method, in R?
>
> Best wishes,  Murray
>
>

-- 
Simon Blomberg, BSc (Hons), PhD, MAppStat, AStat
Lecturer and Consultant Statistician
School of Biological Sciences
The University of Queensland
St. Lucia Queensland 4072
Australia
T: +61 7 3365 2506
email: S.Blomberg1_at_uq.edu.au
http://www.uq.edu.au/~uqsblomb/

Policies:
1.  I will NOT analyse your data for you.
2.  Your deadline is your problem

Statistics is the grammar of science - Karl Pearson.



From A.Robinson at ms.unimelb.edu.au  Mon Nov  1 01:52:40 2010
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Mon, 1 Nov 2010 11:52:40 +1100
Subject: [R-sig-ME] John Nelder and Nelder-Lee HGLMs
In-Reply-To: <4CCDFCFE.7070103@waikato.ac.nz>
References: <4CCDFCFE.7070103@waikato.ac.nz>
Message-ID: <20101101005240.GD6053@ms.unimelb.edu.au>

Hi Murray,

I reviewed the HGLM book for JRSSA a few years ago.  As part of the
review I implemented a simple comparison of the HGLM strategy within R
to compare with lme, and, not surprisingly, it worked just fine for
simple models.  Models with more complicated structure, for example,
random slopes, were not straightforward.  I can send the pdf and
sweave file to anyone who is interested.

I believe that Jim Lindsey has made some progress in implementing
these models in R, but I haven't checked recently.  From memory, it
was his 'repeated' package that had the essential code.

http://www.commanster.eu/rcode.html

I don't feel particularly strongly the same way that you do about the
increased space of models to search --- rather, it's pleasant to feel
that there is soemthing constructive that one could do if the qq plot
of the random effects is rather more skewed than is comfortable, also
it's good that a wider array of models can be accommodated in one
modelling approach when we do have reason to support them --- e.g. the
beta-binomial.

I do have some unease with the theory.  I suspect that the unease is
driven by some ad-hocceries that were deployed to make the theory make
sense.  As I recall, the authors had to invent an idea of a 'canonical
scale' to narrow the space of models down to those with nice
properties, but the required conditions are hard to meet.  An
alternative constraint is that the random effects must occur linearly
in the linear predictor.  If either of these constraints hold then the
HGLM does very nicely.  However, it's not obvious why they *should*
hold.  Nelder confirmed this impression in a pleasant email exchange
after my review was published.  So it seems to me that there is at
least one important piece of the theory still missing.

Cheers,

Andrew

On Mon, Nov 01, 2010 at 12:34:22PM +1300, Murray Jorgensen wrote:
> Roger Payne's obituary for John Nelder may be found at
> 
> http://www.vsni.co.uk/home-pages/john-nelder/
> 
> There can be no doubt that John Nelder has changed the face of modern 
> statistics with his work on linear models and generalized linear models 
> which form the core of the Genstat package and were central in the 
> development of S and R.
> 
> I want to draw the attention of this Sig to the following passage in the 
> obituary in which GLMMs are criticised.
> 
> 
> <quote>
> John?s other major activity at Imperial College was his collaboration 
> with Youngjo Lee to develop the theory of hierarchical generalized 
> linear models (HGLMs); see the papers by Lee & Nelder (1996, 2001, 2006) 
> and the book by Lee, Nelder & Pawitan (2006). The 1996 and 2006 papers 
> were presented as ?read papers? at meetings of the Royal Statistical 
> Society; it is impressive to note that John was 81 years old when he and 
> Youngjo presented the 2006 paper. HGLMs aimed to provide satisfactory 
> methods of analysis for non-Normal data when there is more than one 
> source of random variation. John viewed generalized linear models as a 
> way of liberating statisticians from the ?tyranny? of the Normal 
> distribution, and was a little bemused to see this same tyranny 
> reestablished in methods that were devised initially to extend 
> generalized linear models. These generalized linear mixed models (GLMMs) 
> catered for additional random variation by adding additional 
> Normally-distributed random effects into the linear model of the 
> generalized linear model. John and Youngjo?s new HGLMs extended the 
> methodology to include the beta-binomial, gamma and inverse-gamma 
> distributions, and showed that the conjugate HGLMs (namely binomial GLM 
> with additional beta-binomial random effects, or Poisson with gamma, or 
> gamma with inverse gamma) had attractive advantages in their 
> mathematical theory, computing algorithms and philosophical 
> interpretation. HGLMs can be fitted very efficiently by two interlinked 
> generalized linear models. So we have access to a familiar repertoire of 
> model checking techniques, and can base our choice of error 
> distributions on the data rather than on prejudice or software 
> limitations. Furthermore the analysis can still be carried out 
> interactively ? always a very important consideration for John.
> </quote>
> 
> 
> I have some difficulties with the views of this paragraph and wish to 
> make some comments. Firstly HGLMs do allow added flexibility to the 
> modelling of non-normal data by allowing for non-normal distributions of 
> random effects. However unless there is knowledge about the about the 
> nature of the random effect distributions from the context of the 
> application this flexibility just adds problems by allowing a much 
> larger model space within which to choose and estimate a model.
> 
> Secondly Nelder and Lee do not use standard likelihood or Bayesian 
> methods to fit their HGLMs but instead develop another construction 
> called h-likelihood. It is a while since I tried to look at these but I 
> remember being reminded of the 'classification likelihood' approach to 
> finite mixture modelling where assignments of data to components were 
> treated as parameters to be estimated along with the component 
> parameters and mixing proportions. A number of papers have commented 
> that this is not a good idea, for example
> @ARTICLE{lr83,
>   author  = {Little, R. J. A. and Rubin, D. B.},
>   title   = {On jointly estimating parameters and
> missing data by maximizing the complete data likelihood},
>   journal = {Amer. Statist.},
>   volume  = {37},
>   number  = {},
>   pages   = {218-220},
>   year    = {1983}
> }
> 
> I wonder if members of this list can point me to discussions, critical 
> or supportive, of Lee and Nelder's models and methods. Of course I am 
> aware of the discussion of their JRSS paper so you needn't remind me of 
> that.
> 
> Also, is anyone aware if someone is planning to implement HGLMs, by any 
> estimation method, in R?
> 
> Best wishes,  Murray
> 
> 
> -- 
> Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
> Department of Statistics, University of Waikato, Hamilton, New Zealand
> Email: maj at waikato.ac.nz                                Fax 7 838 4155
> Phone  +64 7 838 4773 wk    Home +64 7 825 0441   Mobile 021 0200 8350
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Andrew Robinson  
Program Manager, ACERA 
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia               (prefer email)
http://www.ms.unimelb.edu.au/~andrewpr              Fax: +61-3-8344-4599
http://www.acera.unimelb.edu.au/



From maj at waikato.ac.nz  Mon Nov  1 04:27:06 2010
From: maj at waikato.ac.nz (Murray Jorgensen)
Date: Mon, 01 Nov 2010 16:27:06 +1300
Subject: [R-sig-ME] John Nelder and Nelder-Lee HGLMs
In-Reply-To: <4CCDFCFE.7070103@waikato.ac.nz>
References: <4CCDFCFE.7070103@waikato.ac.nz>
Message-ID: <4CCE338A.6070507@waikato.ac.nz>

Thanks to those who responded to me both publicly and privately.

It seems that the package hglm answers my last question and Section 10 
of its vignette is one answer to my first question.

I would still be interested in pointers to more discussion of these matters.

Cheers,  Murray

On 1/11/2010 12:34 p.m., Murray Jorgensen wrote:
[...]
>
> I wonder if members of this list can point me to discussions, critical
> or supportive, of Lee and Nelder's models and methods. Of course I am
> aware of the discussion of their JRSS paper so you needn't remind me of
> that.
>
> Also, is anyone aware if someone is planning to implement HGLMs, by any
> estimation method, in R?
>
> Best wishes, Murray
>
>

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    Home +64 7 825 0441   Mobile 021 0200 8350



From rhbc at imm.dtu.dk  Mon Nov  1 07:53:22 2010
From: rhbc at imm.dtu.dk (Rune Haubo)
Date: Mon, 1 Nov 2010 07:53:22 +0100
Subject: [R-sig-ME] John Nelder and Nelder-Lee HGLMs
In-Reply-To: <4CCE338A.6070507@waikato.ac.nz>
References: <4CCDFCFE.7070103@waikato.ac.nz> <4CCE338A.6070507@waikato.ac.nz>
Message-ID: <AANLkTimHJgsf7jxxBV0NmHegWiY5p509m2QLjmDz2k4W@mail.gmail.com>

The most recent discussion of the h-likelihood framework that I have
seen was in Statistical Science, 2009, vol. 24, no.3: Inference for
Models with Unobservables: Another view by Lee and Nelder. I found the
following discussion very interesting --- in particular the
contribution by Xiao-Li Meng, which touches upon the, in some
respects, shaky theoretical foundation of the h-likelihood framework.
In addition one gets humorous references to the De Vinci Code.

Best,
Rune

On 1 November 2010 04:27, Murray Jorgensen <maj at waikato.ac.nz> wrote:
> Thanks to those who responded to me both publicly and privately.
>
> It seems that the package hglm answers my last question and Section 10 of
> its vignette is one answer to my first question.
>
> I would still be interested in pointers to more discussion of these matters.
>
> Cheers, ?Murray
>
> On 1/11/2010 12:34 p.m., Murray Jorgensen wrote:
> [...]
>>
>> I wonder if members of this list can point me to discussions, critical
>> or supportive, of Lee and Nelder's models and methods. Of course I am
>> aware of the discussion of their JRSS paper so you needn't remind me of
>> that.
>>
>> Also, is anyone aware if someone is planning to implement HGLMs, by any
>> estimation method, in R?
>>
>> Best wishes, Murray
>>
>>
>
> --
> Dr Murray Jorgensen ? ? ?http://www.stats.waikato.ac.nz/Staff/maj.html
> Department of Statistics, University of Waikato, Hamilton, New Zealand
> Email: maj at waikato.ac.nz ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Fax 7 838 4155
> Phone ?+64 7 838 4773 wk ? ?Home +64 7 825 0441 ? Mobile 021 0200 8350
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Rune Haubo Bojesen Christensen

PhD Student, M.Sc. Eng.
Phone: (+45) 45 25 33 63
Mobile: (+45) 30 26 45 54

DTU Informatics, Section for Statistics
Technical University of Denmark, Build. 305, Room 122,
DK-2800 Kgs. Lyngby, Denmark



From nikko at hailmail.net  Mon Nov  1 17:11:21 2010
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Mon, 01 Nov 2010 09:11:21 -0700
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 47, Issue 2
In-Reply-To: <mailman.5.1288609203.16331.r-sig-mixed-models@r-project.org>
References: <mailman.5.1288609203.16331.r-sig-mixed-models@r-project.org>
Message-ID: <1288627881.13180.1403010783@webmail.messagingengine.com>

Hi,
Since no one seems to have mentioned it Jim Lindsey also has an
unpublished paper 
on his web site "on h-likekihood"
www.commanster.eu/ms/hglm.ps

Nicholas

> Date: Mon, 1 Nov 2010 07:53:22 +0100
> From: Rune Haubo <rhbc at imm.dtu.dk>
> To: Murray Jorgensen <maj at waikato.ac.nz>
> Cc: R Mixed Models <r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] John Nelder and Nelder-Lee HGLMs
> Message-ID:
> 	<AANLkTimHJgsf7jxxBV0NmHegWiY5p509m2QLjmDz2k4W at mail.gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1
> 
> The most recent discussion of the h-likelihood framework that I have
> seen was in Statistical Science, 2009, vol. 24, no.3: Inference for
> Models with Unobservables: Another view by Lee and Nelder. I found the
> following discussion very interesting --- in particular the
> contribution by Xiao-Li Meng, which touches upon the, in some
> respects, shaky theoretical foundation of the h-likelihood framework.
> In addition one gets humorous references to the De Vinci Code.
> 
> Best,
> Rune
> 
> On 1 November 2010 04:27, Murray Jorgensen <maj at waikato.ac.nz> wrote:
> > Thanks to those who responded to me both publicly and privately.
> >
> > It seems that the package hglm answers my last question and Section 10 of
> > its vignette is one answer to my first question.
> >
> > I would still be interested in pointers to more discussion of these matters.
> >
> > Cheers, ?Murray
> >
> > On 1/11/2010 12:34 p.m., Murray Jorgensen wrote:
> > [...]
> >>
> >> I wonder if members of this list can point me to discussions, critical
> >> or supportive, of Lee and Nelder's models and methods. Of course I am
> >> aware of the discussion of their JRSS paper so you needn't remind me of
> >> that.
> >>
> >> Also, is anyone aware if someone is planning to implement HGLMs, by any
> >> estimation method, in R?
> >>
> >> Best wishes, Murray
> >>
> >>
> >
> > --
> > Dr Murray Jorgensen ? ? ?http://www.stats.waikato.ac.nz/Staff/maj.html
> > Department of Statistics, University of Waikato, Hamilton, New Zealand
> > Email: maj at waikato.ac.nz ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Fax 7 838 4155
> > Phone ?+64 7 838 4773 wk ? ?Home +64 7 825 0441 ? Mobile 021 0200 8350
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
> 
> 
> -- 
> Rune Haubo Bojesen Christensen
> 
> PhD Student, M.Sc. Eng.
> Phone: (+45) 45 25 33 63
> Mobile: (+45) 30 26 45 54
> 
> DTU Informatics, Section for Statistics
> Technical University of Denmark, Build. 305, Room 122,
> DK-2800 Kgs. Lyngby, Denmark
> 
> 
> 
> ------------------------------
> 
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> End of R-sig-mixed-models Digest, Vol 47, Issue 2
> *************************************************
>



From pauljohn32 at gmail.com  Mon Nov  1 19:28:34 2010
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Mon, 1 Nov 2010 13:28:34 -0500
Subject: [R-sig-ME] psychometric function fitting with lmer?
In-Reply-To: <AANLkTimW3HOY1r9+LrvGui9gfxmSDjS94fXShYu-DP3B@mail.gmail.com>
References: <AANLkTimW3HOY1r9+LrvGui9gfxmSDjS94fXShYu-DP3B@mail.gmail.com>
Message-ID: <AANLkTimqg6u3EOq=m5piPE0Hp-y-VPW_Dz9VjbQBxCnt@mail.gmail.com>

Hi, Mike

I think the terminology is confusing everybody.  Let me tell you how I
understand what you say, you can try again to tell us what you want.
Since I've just asked a similar kind of question comparing IRT scaling
with lmer, this is fresh in my mind.

On Fri, Oct 29, 2010 at 11:23 AM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
> Hi folks,
>
> In some areas of psychology, we encounter binomial response data that,
> when aggregated to proportions and plotted against a continuous
> predictor variable, forms a sigmoid-like function. It is typical to
> use OLS to fit a probit function to this data, yielding measures of
> bias (mean of the Gaussian) and variability (SD of the Gaussian).

That kind of data is commonly called "grouped" data, as opposed to
individual level data.  In the olden days, that kind of grouped-data
regression you describe was sometimes called a "minimum chi-square
model".  I have no idea what you mean "bias" in this context.

I've never seen a probit function fitted with OLS, but I've seen a
logistic transformation of the proportions on the left hand side
leading to a regression like

ln( prop/(1-prop)) = X b + e

OLS is heteroskedastic, even in the olden days you'd have use WLS to
estimate these coefficients.  There is heteroskedasticity because 1)
there are different numbers of observations in each group and 2) the
variance of the error term is proportional to prop(1-prop).

This model is NOT perfectly equivalent to a probit (or logistic)
regression on individual level data,  the kind where

Pr(y=1 | x, b) = PHI(Xb)

where PHI is the cumulative distribution of a  Normal for probit or
Logistic for logit.

That individual model does not exactly coincide with the grouped
proportion model., partly because the "e" term in the OLS regression
has no direct counterpart in the individual level regression.  The
scaling of the parameters is arbitrary, they will be proportional to
one another.

These days, I'd suggest you fit the "proportion" model with a Beta
regression, for which there is a very excellent R package (betareg).
That is, if you want to analyze the grouped-level proportion data,
that is.

Between the group proportion and individual-level probit, the
estimates of the b's are, at least in theory, estimating the same
thing, except for some scaling effects.  But they never really are the
same.

This
> fitting is typically done within each individual and condition of
> interest separately, then the resulting parameters are submitted to 2
> ANOVAs: one for bias, one for variability.

This one has me stumped.  Can you supply some citations?  "within each
individual" is puzzling to me.  Variability of what? bias in the sense
of a known mismatch between a "true" parameter value and its estimate?
  And the 2 separate ANOVA, well, I think you need to write it down.


 I wonder if this analysis
> might be achieved more efficiently using a single mixed effects model,
> but I'm having trouble figuring out how to approach coding this. Below
> is an example of data similar to that collected in this sort of
> research, where individuals fall into two groups (variable "group"),
> and are tested under two conditions (variable "cue") across a set of
> values from a continuous variable (variable "soa"), with each cue*soa
> combination tested repeatedly within each individual. A model like
>
> fit = lmer(
> ? ?formula = response ~ (1|id) + group*cue*soa
> ? ?, family = binomial( link='probit' )
> ? ?, data = a
> )

This does not have random effects for group, cue, soa.  it gives fixed
estimates for group, cue, soa, and all interactions among them.  I
don't think  you mean that.



>
> employs the probit link, but of course yields estimates for the slope
> and intercept of a linear model on the probit scale, and I'm not sure
> how (if it's even possible) to convert the conclusions drawn on this
> scale to conclusions about the bias and variability parameters of
> interest.
>
> Thoughts?
>

I think I'm inclined to say that the "bias" and "variability"
parameters you mention are not sensible, because I've never seen a
publication that uses that approach you describe.  My guess is that
you are trying to replicate nonsense, which is, well, a time honored
tradition :)

But, in my last year of work in an interdisciplinary statistics
center, I've learned that all of the fields have their own nicknames
for things and so it is quite likely we have no idea what you are
asking because the nicknames you use are different than the nicknames
we use.  In particular, I bet your claim of estimating probit models
with OLS made some heads spin.

> Mike
>



-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas



From pauljohn32 at gmail.com  Mon Nov  1 21:40:17 2010
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Mon, 1 Nov 2010 15:40:17 -0500
Subject: [R-sig-ME] IRT: discrimination parameters from LMER?
In-Reply-To: <C0772C7568B5374481D2F8A880E9BBDF06A650CA1B@DC1EX07CMS.air.org>
References: <AANLkTi=GRoe0-AXFbOiw6x_W95J_j5+rXek-OnoR9CwZ@mail.gmail.com>
	<C0772C7568B5374481D2F8A880E9BBDF06A650CA1B@DC1EX07CMS.air.org>
Message-ID: <AANLkTikzXr=KkDzHRUhPW_s+E7u_yf3N3A0d3EXpG=Qj@mail.gmail.com>

On Sat, Oct 30, 2010 at 4:54 PM, Doran, Harold <HDoran at air.org> wrote:
> IRT people can be odd. Yes, your interpretation of the differences between the ltm package and lme4 are correct. lmer estimates the standard deviation of the population distribution, but ltm fixes it and then estimates a discrimination value that is constant for all items. It is currently not possible to estimate the 2pl using lmer, but that model can be easily estimated using other functions, such as those in ltm.


Thanks for answering!

I'm glad to learn I'm not grossly misunderstanding IRT/lmer. What do
you think about my observation about the fact that the difficulty
estimate from ltm seems to be systematically different/better than the
lmer estimate?

Do you care to weigh in on the question of whether lmer could ever be
made to fit a 2PL or 3PL model?  I mean, could I write a family for
lmer that would do that, or is the calculation required too grossly
different?

If 2PL or 3PL is really a whole different structure, I don't mind
using "ltm."  But defeats the ideal that you proposed in that 2007 JSS
article (which I really like!), that we might be better off fitting
specialized models with general purpose software.

Here's a similar example.  Sometimes I have wanted to fit ordinal
dependent variables, and have learned that those models do not fall
into the family of GLM and a tool different from lmer is necessary to
work on them.   I wish it weren't so, but have accepted reality.

pj


> Hello, everybody.
>
> I've fallen into a crowd of IRT users. ?I remembered seeing the IRT
> with lmer paper.
>
> ## Doran, Harold, Douglas Bates, Paul Bliese,
> ## Maritza Dowling, 2007. ?Estimating the
> ## Multilevel Rasch Model: With the lme4 Package.?
> ## Journal of Statistical Software 20(2): 1?18.
>
> I had not understood that a Rasch model is a very specialized kind of
> logistic regression. ? The items are all assumed to have the same
> discrimination parameter.
>
> I started to wonder if I could get a 2 parameter logistic IRT from
> lmer, and I'm a bit stuck. I'm comparing against the output from the
> rasch function in the "ltm" package. ?I'm pasting in the code below
> for comparison, and after that I have the output so you can compare.
>
> I found a nice BUGS survey for the various kinds of IRT, in case you
> wonder what all of these are. ?The argument there is the same one that
> Doran et al make, in favor of the idea of using general purpose
> software for IRT.
>
> Curtis, S. McKay. 2010. ?BUGS Code for Item Response Theory.? Journal
> of Statistical Software, Code Snippets 36(1): 1?34.
>
> In the most restrictive form of the Rasch model, the discrimination
> parameter is assumed to be 1, but there is an estimate of the standard
> deviation of the latent ability coefficient. ?In other implementations
> of Rasch, it is assumed the latent trait is N(0,1) and then a
> discrimination coefficient is estimated.
>
> I *believe* that is the point of comparison from ?ltm's rasch to
> lmer's random effect estimate. ltm rasch assumes the individual
> ability parameter is N(0,1) and estimates a discrimination coefficient
> common to all items
>
> disc * N(0,1)
>
> and the lmer estimates disc as the standard deviation of the random effect.
>
> N(0, disc^2).
>
> So the random effect standard deviation estimated by lmer is one
> estimate of that same disc parameter.
>
> This little simulation shows that lmer's fixed effects for the items
> are very close to the same as the difficulty parameters in rasch. ?The
> one disc parameter estimate from ltm is usually closer to the "true"
> discrimination value than the standard deviation of the random effect
> in lmer. ?However, they are "in the ballpark".
>
> Partly I'm curious to know if you agree I'm comparing the numbers properly.
>
> But, also, I want to estimate a different discrimination parameter for
> each item, so I can get an IRT 2PL model. It would be nice to get a
> 3PL to allow a guessing parameter.
>
> Once I realized this mismatch between lmer and the more general IRT, I
> started to think either 1) we really do need specialized IRT software,
> or 2) perhaps I need to learn to write family code for lmer.
>
> PJ
>
> ## Paul Johnson Oct. 30, 2010
> ## Item Response Theory, compare the
> ## IRT-specific R package "ltm" with mixed-effct GLM
> ## perspective of lmer in "lme4" package.
>
> ## The argument against IRT specific software
> ## is that it restricts the user. May be better
> ## to adapt general purpose programs to
> ## estimate same models. ?That's argued in:
>
> library(ltm)
>
> library(lme4)
>
>
> ### Create Data: 300 respondents with 3 items each.
> N <- 300
> Adiff <- c(-1, 2, 2) ### actually, easiness
> Bdisc <- rep(2.2, 3) ### rasch requires all same!
>
> z <- rnorm( N, 0, sd=1)
>
> #create one long column for latent trait
> z3 <- kronecker(Adiff, rep(1,N)) - kronecker(Bdisc, z)
> ## caution about signs of parameters. Very
> ## confusing, standard IRT is
> ## Bdisc ( theta - Adiff)
> ## So if Adiff = c(-1, 2, 2), IRT standard
> ## difficulty estimates will be sign reversed
> ## c(0.5, -0.84, -0.84)
>
>
> pr <- 1/(1 + exp(-1*(z3)))
> y <- rbinom(length(pr), prob=pr, size=1)
>
> id <- rep(1:N, 3)
> item <- c( rep(1, N), rep(2, N), rep(3, N))
>
> ### the item matrix, N by 3
> maty <- matrix(y, ncol=3)
>
>
> ### Long version of data frame for use with lmer
> dflong <- data.frame("id"=id, "item"=item, "value"=y)
>
> ### convert "item" to factor variable
> dflong$item <- as.factor(dflong$item)
> ### create indicators for items, just experimenting
> dflong$item1 <- ifelse(dflong$item == "1",1,0)
> dflong$item2 <- ifelse(dflong$item == "2",1,0)
> dflong$item3 <- ifelse(dflong$item == "3",1,0)
>
> ### fit with rasch in ltm,
> ### Transform estimates with IRT.param=F,
> ### gives values comparable to lmer, it gives
> ### parameters in form b0 + b1*theta
> ### rather than IRT code like b1(b0 - theta)
>
> dfrasch <- rasch(maty, IRT.param=F)
> summary(dfrasch)
>
> ### Compare to IRT standard coding, for fun
> dfrasch2 <- rasch(maty)
> summary(dfrasch2)
> ### Note discrim param is same as dfrasch, but
> ### difficulties are different. Can convert
> ### the dfrasch2 difficulties by multiplying by
> ### discrimination.
>
>
> ### use lmer, estimates of fixed effect parameters
> ### "item1", "item2", "item3" are "difficulty
> ### parameters.
>
> dflmer <- lmer (value ~ -1 + item1 + item2 + item3 + (1|id) ,
> data=dflong, family=binomial)
> summary(dflmer)
>
> ### How to estimate the "discrimination parameter"?
> ### I'm just guessing now. rasch assumes all
> ### discrimination parameters for all items are same.
> ### Recall x ~ N(0, s^2), same as x ~ s * N(0,1).
> ### So estimated standard deviation of random effect
> ### is same as one discrimination parameter "s" in
> ### above. ?I think.
>
>
> dflmer2 <- lmer (value ~ -1 + item + (1|id) , data=dflong, family=binomial)
> summary(dflmer2)
>
>
> ldfy <- ltm( dfy ~ z1 , IRT.param=F)
> summary(ldfy)
>
> ##################################################
>
>
> Here's the output:
>
>
>> library(ltm)
> Loading required package: MASS
> Loading required package: msm
> Loading required package: mvtnorm
> Loading required package: polycor
> Loading required package: sfsmisc
>
> This is package 'ltm' version '0.9-5'
>
>> library(lme4)
> Loading required package: Matrix
> Loading required package: lattice
>
> Attaching package: 'Matrix'
>
> The following object(s) are masked from 'package:base':
>
> ? ?det
>
>
> Attaching package: 'lme4'
>
> The following object(s) are masked from 'package:stats':
>
> ? ?AIC
>
>> N <- 300
>> Adiff <- c(-1, 2, 2) ### actually, easiness
>> Bdisc <- rep(2.2, 3) ### rasch requires all same!
>> z <- rnorm( N, 0, sd=1)
>> z3 <- kronecker(Adiff, rep(1,N)) - kronecker(Bdisc, z)
>> pr <- 1/(1 + exp(-1*(z3)))
>> y <- rbinom(length(pr), prob=pr, size=1)
>> id <- rep(1:N, 3)
>> item <- c( rep(1, N), rep(2, N), rep(3, N))
>> maty <- matrix(y, ncol=3)
>> dflong <- data.frame("id"=id, "item"=item, "value"=y)
>> dflong$item <- as.factor(dflong$item)
>> dflong$item1 <- ifelse(dflong$item == "1",1,0)
>> dflong$item2 <- ifelse(dflong$item == "2",1,0)
>> dflong$item3 <- ifelse(dflong$item == "3",1,0)
>> dfrasch <- rasch(maty, IRT.param=F)
> summary(dfrasch)
>>
> Call:
> rasch(data = maty, IRT.param = F)
>
> Model Summary:
> ? log.Lik ? ? ?AIC ? ? ?BIC
> ?-483.7193 975.4385 990.2537
>
> Coefficients:
> ? ? ? ?value std.err ?z.vals
> Item1 -1.1239 ?0.2029 -5.5392
> Item2 ?1.8955 ?0.2371 ?7.9957
> Item3 ?1.7567 ?0.2305 ?7.6227
> z ? ? ?1.8959 ?0.2336 ?8.1157
>
> Integration:
> method: Gauss-Hermite
> quadrature points: 21
>
> Optimization:
> Convergence: 0
> max(|grad|): 0.003
> quasi-Newton: BFGS
>
>
>> dfrasch2 <- rasch(maty)
>> summary(dfrasch2)
>
> Call:
> rasch(data = maty)
>
> Model Summary:
> ? log.Lik ? ? ?AIC ? ? ?BIC
> ?-483.7193 975.4385 990.2537
>
> Coefficients:
> ? ? ? ? ? ? ? ?value std.err ?z.vals
> Dffclt.Item 1 ?0.5928 ?0.1082 ?5.4799
> Dffclt.Item 2 -0.9998 ?0.1249 -8.0022
> Dffclt.Item 3 -0.9266 ?0.1211 -7.6502
> Dscrmn ? ? ? ? 1.8959 ?0.2336 ?8.1157
>
> Integration:
> method: Gauss-Hermite
> quadrature points: 21
>
> Optimization:
> Convergence: 0
> max(|grad|): 0.003
> quasi-Newton: BFGS
>
>
>> dflmer <- lmer (value ~ -1 + item1 + item2 + item3 + (1|id) , data=dflong, family=binomial)
>> summary(dflmer)
> Generalized linear mixed model fit by the Laplace approximation
> Formula: value ~ -1 + item1 + item2 + item3 + (1 | id)
> ? Data: dflong
> ?AIC ?BIC logLik deviance
> ?984 1003 ? -488 ? ? ?976
> Random effects:
> ?Groups Name ? ? ? ?Variance Std.Dev.
> ?id ? ? (Intercept) 2.9100 ? 1.7059
> Number of obs: 900, groups: id, 300
>
> Fixed effects:
> ? ? ?Estimate Std. Error z value Pr(>|z|)
> item1 ?-1.1155 ? ? 0.1754 ?-6.358 2.04e-10 ***
> item2 ? 1.8382 ? ? 0.1938 ? 9.486 ?< 2e-16 ***
> item3 ? 1.7049 ? ? 0.1898 ? 8.984 ?< 2e-16 ***
> ---
> Signif. codes: ?0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
> ? ? ?item1 item2
> item2 0.247
> item3 0.255 0.310
>>
>
>
>
>
> --
> Paul E. Johnson
> Professor, Political Science
> 1541 Lilac Lane, Room 504
> University of Kansas
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas



From otter at otter-rsch.com  Mon Nov  1 16:47:51 2010
From: otter at otter-rsch.com (dave fournier)
Date: Mon, 01 Nov 2010 11:47:51 -0400
Subject: [R-sig-ME] IRT: discrimination parameters from LMER?
In-Reply-To: <AANLkTikzXr=KkDzHRUhPW_s+E7u_yf3N3A0d3EXpG=Qj@mail.gmail.com>
References: <AANLkTikzXr=KkDzHRUhPW_s+E7u_yf3N3A0d3EXpG=Qj@mail.gmail.com>
Message-ID: <4CCEE127.80303@otter-rsch.com>

If you need a more flexible modeling platform you could look at
AD Model Builders  random effects package.
There is an example there incorporating extra parameters
into the model for an example of Dorans.  The
extra parameters significantly improved the fit.


http://admb-project.org/community/tutorials-and-examples/random-effects-example-collection



From bbolker at gmail.com  Tue Nov  2 02:53:07 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 01 Nov 2010 21:53:07 -0400
Subject: [R-sig-ME] help with model convergence
In-Reply-To: <1288632521l.614426l.0l@psu.edu>
References: <1288203635l.1032266l.0l@psu.edu>	<1288208508l.1511628l.0l@psu.edu>	<1288296451l.1032274l.0l@psu.edu>	<AANLkTikscT885QSAdhJHS=yyVeeN5LV4_Qj7JC2QfGoB@mail.gmail.com><4CC9E1C5.407	0106@gmail.com>
	<1288632521l.614426l.0l@psu.edu>
Message-ID: <4CCF6F03.80101@gmail.com>

  [cc'ing r-sig-mixed-models: it's best to keep sending replies back to
the list so they can be archived and others can read them, or offer input]

On 10-11-01 01:28 PM, David Stainbrook wrote:
> Ben,
> 
> Thanks for your input. I read that article that you suggested and it
> appears they used SAS and Genstat to do their analysis. 

  Yes (although as I said at the time, I wouldn't actually trust the
methods that they used in Genstat for this problem.  I just think their
description of the problem is clear).

> Is it possible
> to use the Poisson-lognormal model in R or translate the model to this
> using R and lmer? Another professor mentioned that I may be able to get
> it to work using a negative binomial model in SAS or ADModel Builder.
> What do you suggest?

  Yes, you can use the Poisson-lognormal in recent versions of lme4,
simply by including an individual-level random variable.  You may get
warnings.
  You could indeed use a negative binomial model in SAS or AD Model
Builder (in ADMB you could also use the lognormal-Poisson model).

> Do you have any idea why Doug allowed the lmer function to fit
> quasipoisson if he doesn't feel that the results will be reliable? I
> would have trusted my results and wouldn't have had any idea that they
> might have been unreliable if he had not said that.

  I believe he implemented it a while ago and his opinions have now
changed. (I agree that it might be a good idea to disable this
functionality.)

> Also, do you have any idea how to increase both the default number of
> function evaluations and iterations with the control statement within
> the lmer model statement?
> The lme4 user's guide did not give an example for both.
> I tried this <control=list(maxIter=2000), control2=list(maxFN=3000)>,
> but I believe that only the default number of iterations was changed. I
> still got the error saying that it reached the function evaluation
> limit, so I don't think the second part actually worked. I stuck a "2"
> after control because otherwise I would get an error message saying that
> there were multiple control arguments used.

...,control=list(maxIter=2000,maxFN=3000),... should work. I would
expect "control2" would have exactly no effect.

  I went back and read your message
<https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q4/004653.html>.
 A few comments:
  * there was a bunch of HTML junk at the beginning of the file
(probably an accidental cut-and-paste error from Word) -- that may have
put people off from reading farther ...
  * I think your zip file may have been stripped -- the R mailing lists
don't allow every type of attachment, and zipped files can often contain
nasties.
  * you seem to be tackling a difficult problem.  I appreciate that
you're offering full details on your problem (full scripts and data),
but it's going to take someone else at least half an hour (and probably
quite a bit more) to get up to speed on what you're doing and what's not
working; unfortunately, that's more than most anyone has time for,
unless the problem happens to be something very close to their
interests. Unfortunately, you may well need to find local help for this
(your advisor? a friendly stats professor or graduate student?)
  * it's possible, depending on the complexity of your model, that
you're simply trying to fit too complicated a model.  You do have a lot
of data points, but some of your covariates may be strongly correlated.
Have you tried:
   - seeing if you can successfully fit a subset of the data points
(this could be faster, allowing you to debug quicker)?
   - seeing if you can successfully fit a subset of the covariates, or
which covariates or combinations of covariates are problematic?
   - seeing if you can successfully fit a non-mixed (GLM) model,
treating 'individual' as a fixed effect?
   - simulating data, possibly in a simplified form, to see if you can
get the right answer when you know what it is?
  * lme4 is quite finicky about convergence, on the philosophy that it's
better not to give an answer than to give a wrong one.

  R does have its advantages, but if you're up to working with SAS or AD
Model Builder I would recommend you also try those approaches -- see if
you run into the same problems.  But I would definitely try some of the
trouble-shooting strategies above, first.

  good luck,
    Ben Bolker


> Thanks again,
> 
> David

> 
> On Thu, Oct 28, 2010 04:49 PM, *Ben Bolker <bbolker at gmail.com>* wrote:
> 
>        My advice would be to use an individual-level random variable
>     (translating to a lognormal-Poisson model, which is qualitatively
>     similar to a negative binomial) -- see e.g. Elston et al 2001 for a
>     decent explanation, although you should not necessarily trust the
>     numeric methods they use ...
> 
>      [Elston, D. A., R. Moss, T. Boulinier, C. Arrowsmith, and X. Lambin.
>     2001. Analysis of Aggregation, a Worked Example: Numbers of Ticks on Red
>     Grouse Chicks. Parasitology 122, no. 05: 563-569.
>     doi:10.1017/S0031182001007740.
>     http://journals.cambridge.org/action/displayAbstract?fromPage=online&aid=82701.]
> 
> 
>       (Doug, thanks for the vote of confidence!)
> 
>       cheers
>         Ben
> 
> 
> 
> 
>



From maj at waikato.ac.nz  Tue Nov  2 05:09:25 2010
From: maj at waikato.ac.nz (Murray Jorgensen)
Date: Tue, 02 Nov 2010 17:09:25 +1300
Subject: [R-sig-ME] John Nelder and Nelder-Lee HGLMs
In-Reply-To: <4CCE0CAB.1050002@uq.edu.au>
References: <4CCDFCFE.7070103@waikato.ac.nz> <4CCE0CAB.1050002@uq.edu.au>
Message-ID: <4CCF8EF5.4080901@waikato.ac.nz>

The flow seem to have stopped so I will post a few things not already 
noted or expand a little on what has.

Firstly there is the Statistical Science issue with L+N's article and 
discussion:

STATISTICAL SCIENCE
Volume 24, Number 3 August 2009
Likelihood Inference for Models with Unobservables: Another View
Youngjo Lee and John A. Nelder 255

Discussion of Likelihood Inference for Models with Unobservables: 
Another View Thomas A. Louis 270

Discussion of Likelihood Inference for Models with Unobservables: 
Another View Geert Molenberghs, Michael G. Kenward and Geert Verbeke 273

Decoding the H-likelihood Xiao-Li Meng 280

Rejoinder: Likelihood Inference for Models with Unobservables Another 
View  Youngjo Lee and John A. Nelder 294

Secondly John Maindonald mentioned to me the large number of models 
which may be fitted by the MCMCglmm package, using Bayesian methods, of 
course.


Andrew Robinson and Simon Blomberg have already mentioned the interest 
shown by Jim Lindsey in HGLMs.

There are two packages in CRAN: hglm and HGLMM.

I will add that Charles McCulloch has taken some interest in this area. 
There is his JASA article

Maximum Likelihood Algorithms for Generalized Linear Mixed Models
Journal of the American Statistical Association, Vol. 92, No. 437 (Mar., 
1997), pp. 162-170

where he compares Maximum Likelihood methods to "Joint-Maximization" 
methods such as PQL.

and also a recent paper

Prediction of Random Effects in Linear and Generalized Linear
Models under Model Misspecification
Charles E. McCulloch? and John M. Neuhaus
(Biometrics Early View, June 2010)

which suggests that GLMMs are fairly robust against the 
mis-specification of the distribution of the random effects.

Murray

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    Home +64 7 825 0441   Mobile 021 0200 8350



From HDoran at air.org  Tue Nov  2 15:33:52 2010
From: HDoran at air.org (Doran, Harold)
Date: Tue, 2 Nov 2010 10:33:52 -0400
Subject: [R-sig-ME] IRT: discrimination parameters from LMER?
In-Reply-To: <AANLkTikzXr=KkDzHRUhPW_s+E7u_yf3N3A0d3EXpG=Qj@mail.gmail.com>
References: <AANLkTi=GRoe0-AXFbOiw6x_W95J_j5+rXek-OnoR9CwZ@mail.gmail.com>
	<C0772C7568B5374481D2F8A880E9BBDF06A650CA1B@DC1EX07CMS.air.org>
	<AANLkTikzXr=KkDzHRUhPW_s+E7u_yf3N3A0d3EXpG=Qj@mail.gmail.com>
Message-ID: <C0772C7568B5374481D2F8A880E9BBDF06A64B7A9C@DC1EX07CMS.air.org>

> I'm glad to learn I'm not grossly misunderstanding IRT/lmer. What do
> you think about my observation about the fact that the difficulty
> estimate from ltm seems to be systematically different/better than the
> lmer estimate?

I don't think this is true necessarily. I've done a small experiment all reproducible code is at bottom of email. I simulate some rasch data and then estimate item parameters using ltm, lmer, jml (in MiscPsycho), and mml (a function I wrote that is below using the traditional mml methods). To make a long story short, I compute the bias under each model.

> ### ltm bias
> mean((coef(fm1)[,1] - mean(coef(fm1)[,1])) - trueVals)
[1] -0.173386111948639
> 
> ### lmer bias
> mean((fixef(fm2) - mean(fixef(fm2))) - trueVals)
[1] -0.173386111948639
> 
> ### jml bias
> mean(coef(fm1) - trueVals)
[1] 0.39007242168395
> 
> ### mml bias
> mean((coef(fm4)[1:20] - mean(coef(fm4)[1:20])) - trueVals)
[1] -0.173386111948639

It seems to me that jml (as expected) performs the worst, but all other functions are comparable and seem to recover parameter estimates rather well. If you run the mml function below, it is slow. But, notice that the standard deviation in mml is exactly the same as what lmer gives. That is because a multilevel rasch model with the parameterization I have used (items as fixed respondents as random) is exactly the same as mml. But, lmer's capacity can go much, much further. Had I not constrained the ltm function to have a discrimination of 1, the common discrimination parameter would also be the sd given by mml and lmer.
 
> Do you care to weigh in on the question of whether lmer could ever be
> made to fit a 2PL or 3PL model?  I mean, could I write a family for
> lmer that would do that, or is the calculation required too grossly
> different?

Yes, I'm sure it can. The issue is who will write the code. Doug Bates is extremely generous with his help and his openness to others making contributions to lme4. But, (as he might do so on this thread), he will forewarn you that the underlying code in lmer is very complex and doesn't resemble methods commonly used in other packages. So, because Doug is so amazingly smart, and I am just a mortal, I have decided to steer away from contributing to lmer other than being a "toy tester" for Doug.

I am not a fan of the 3PL for many reasons. First, it is a model that cannot be identified without putting a very slim prior on the guessing parameter. In the end, because the prior is so slim, guess what your parameter estimates are close to? Yes, the prior. So, I just have never been made comfortable with that.

> If 2PL or 3PL is really a whole different structure, I don't mind
> using "ltm."  But defeats the ideal that you proposed in that 2007 JSS
> article (which I really like!), that we might be better off fitting
> specialized models with general purpose software.

I think ltm is a really great package. It may have some capacity to do what you want, I don't fully know its capacities. Perhaps Dimitris can offer some thought. 
 
> Here's a similar example.  Sometimes I have wanted to fit ordinal
> dependent variables, and have learned that those models do not fall
> into the family of GLM and a tool different from lmer is necessary to
> work on them.   I wish it weren't so, but have accepted reality.
> 
> pj

This is very true. I have been doing some work on polytomous models, but am working very slowly on functions to estimate them. There are packages in R that can currently do this. I wonder if MCMCglmm can do it; I don't know.


library(ltm)
library(lmer)
library(MiscPsycho)

Nitems <- 20
Nperson <- 500

set.seed(12345)
dat <- simRasch(Nperson, Nitems) 
itemDat <- dat$data

### Fit data using rasch in LTM
fm1 <- rasch(itemDat, constraint = cbind(ncol(itemDat) + 1, 1))

### Fit using lmer
itemDat$id <- 1:nrow(itemDat)
### reshape into long format
testScores <- reshape(itemDat, idvar='id', varying=list(names(itemDat)[1:Nitems]), v.names=c('answer'), timevar='question', direction='long')

# Treat items as fixed but students as random
fm2 <- lmer(answer ~ factor(question) - 1 + (1|id), testScores, family = binomial(link='logit'))


### Fit using JML
fm3 <- jml(dat$data, bias=TRUE)

### Fit using mml function below
fm4 <- mml(dat$data, Q =10, startVal = coef(fm1)[,1])

### Compute bias
trueVals <- dat$gen

### ltm bias
mean((coef(fm1)[,1] - mean(coef(fm1)[,1])) - trueVals)

### lmer bias
mean((fixef(fm2) - mean(fixef(fm2))) - trueVals)

### jml bias
mean(coef(fm1) - trueVals)

### mml bias
mean((coef(fm4)[1:20] - mean(coef(fm4)[1:20])) - trueVals)



mml <- function(data, Q, startVal = NULL, ...){
	if(!is.null(startVal) && length(startVal) != ncol(data) ){
		stop("Length of argument startVal not equal to the number of parameters estimated")
	}	
	if(!is.null(startVal)){
		startVal <- startVal
		} else {
		p <- colMeans(data)
		startVal <- as.vector(log((1 - p)/p))
	}
	qq <- gauss.quad.prob(Q, dist = 'normal', mu = 0, sigma=1)
	rr1 <- matrix(0, nrow = Q, ncol = nrow(data))
	data <- as.matrix(data)
	L <- nrow(data)
	C <- ncol(data)
	u <- 0
	fn <- function(b){
	s <- b[C+1]
	b <- b[1:C]	
		for(j in 1:Q){
			for(i in 1:L){
				rr1[j,i] <- exp(sum(dbinom(data[i,], 1, plogis(qq$nodes[j]-b), log = TRUE))) * 
				((1/(s*sqrt(2*pi)))  * exp(-((qq$nodes[j]-u)^2/(2*s^2))))/dnorm(qq$nodes[j]) * qq$weights[j]
			}
		}
	-sum(log(colSums(rr1)))
	}	
	opt <- optim(c(startVal,1), fn, method = "BFGS", hessian = TRUE)
	list("coefficients" = opt$par, "LogLik" = -opt$value, "Std.Error" = sqrt(diag(solve(opt$hessian))))
}



From HDoran at air.org  Tue Nov  2 15:39:01 2010
From: HDoran at air.org (Doran, Harold)
Date: Tue, 2 Nov 2010 10:39:01 -0400
Subject: [R-sig-ME] IRT: discrimination parameters from LMER?
In-Reply-To: <C0772C7568B5374481D2F8A880E9BBDF06A64B7A9C@DC1EX07CMS.air.org>
References: <AANLkTi=GRoe0-AXFbOiw6x_W95J_j5+rXek-OnoR9CwZ@mail.gmail.com>
	<C0772C7568B5374481D2F8A880E9BBDF06A650CA1B@DC1EX07CMS.air.org>
	<AANLkTikzXr=KkDzHRUhPW_s+E7u_yf3N3A0d3EXpG=Qj@mail.gmail.com>
	<C0772C7568B5374481D2F8A880E9BBDF06A64B7A9C@DC1EX07CMS.air.org>
Message-ID: <C0772C7568B5374481D2F8A880E9BBDF06A64B7AA3@DC1EX07CMS.air.org>

Just noticed the bias for jml was wrong. It should be

> ### jml bias
> mean(coef(fm3) - trueVals)
[1] -0.173386111948639

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
> bounces at r-project.org] On Behalf Of Doran, Harold
> Sent: Tuesday, November 02, 2010 10:34 AM
> To: Paul Johnson; R-SIG-Mixed-Models at r-project.org
> Cc: Dimitris Rizopoulos
> Subject: Re: [R-sig-ME] IRT: discrimination parameters from LMER?
> 
> > I'm glad to learn I'm not grossly misunderstanding IRT/lmer. What do
> > you think about my observation about the fact that the difficulty
> > estimate from ltm seems to be systematically different/better than the
> > lmer estimate?
> 
> I don't think this is true necessarily. I've done a small experiment all
> reproducible code is at bottom of email. I simulate some rasch data and then
> estimate item parameters using ltm, lmer, jml (in MiscPsycho), and mml (a
> function I wrote that is below using the traditional mml methods). To make a
> long story short, I compute the bias under each model.
> 
> > ### ltm bias
> > mean((coef(fm1)[,1] - mean(coef(fm1)[,1])) - trueVals)
> [1] -0.173386111948639
> >
> > ### lmer bias
> > mean((fixef(fm2) - mean(fixef(fm2))) - trueVals)
> [1] -0.173386111948639
> >
> > ### jml bias
> > mean(coef(fm1) - trueVals)
> [1] 0.39007242168395
> >
> > ### mml bias
> > mean((coef(fm4)[1:20] - mean(coef(fm4)[1:20])) - trueVals)
> [1] -0.173386111948639
> 
> It seems to me that jml (as expected) performs the worst, but all other
> functions are comparable and seem to recover parameter estimates rather well.
> If you run the mml function below, it is slow. But, notice that the standard
> deviation in mml is exactly the same as what lmer gives. That is because a
> multilevel rasch model with the parameterization I have used (items as fixed
> respondents as random) is exactly the same as mml. But, lmer's capacity can go
> much, much further. Had I not constrained the ltm function to have a
> discrimination of 1, the common discrimination parameter would also be the sd
> given by mml and lmer.
> 
> > Do you care to weigh in on the question of whether lmer could ever be
> > made to fit a 2PL or 3PL model?  I mean, could I write a family for
> > lmer that would do that, or is the calculation required too grossly
> > different?
> 
> Yes, I'm sure it can. The issue is who will write the code. Doug Bates is
> extremely generous with his help and his openness to others making
> contributions to lme4. But, (as he might do so on this thread), he will
> forewarn you that the underlying code in lmer is very complex and doesn't
> resemble methods commonly used in other packages. So, because Doug is so
> amazingly smart, and I am just a mortal, I have decided to steer away from
> contributing to lmer other than being a "toy tester" for Doug.
> 
> I am not a fan of the 3PL for many reasons. First, it is a model that cannot
> be identified without putting a very slim prior on the guessing parameter. In
> the end, because the prior is so slim, guess what your parameter estimates are
> close to? Yes, the prior. So, I just have never been made comfortable with
> that.
> 
> > If 2PL or 3PL is really a whole different structure, I don't mind
> > using "ltm."  But defeats the ideal that you proposed in that 2007 JSS
> > article (which I really like!), that we might be better off fitting
> > specialized models with general purpose software.
> 
> I think ltm is a really great package. It may have some capacity to do what
> you want, I don't fully know its capacities. Perhaps Dimitris can offer some
> thought.
> 
> > Here's a similar example.  Sometimes I have wanted to fit ordinal
> > dependent variables, and have learned that those models do not fall
> > into the family of GLM and a tool different from lmer is necessary to
> > work on them.   I wish it weren't so, but have accepted reality.
> >
> > pj
> 
> This is very true. I have been doing some work on polytomous models, but am
> working very slowly on functions to estimate them. There are packages in R
> that can currently do this. I wonder if MCMCglmm can do it; I don't know.
> 
> 
> library(ltm)
> library(lmer)
> library(MiscPsycho)
> 
> Nitems <- 20
> Nperson <- 500
> 
> set.seed(12345)
> dat <- simRasch(Nperson, Nitems)
> itemDat <- dat$data
> 
> ### Fit data using rasch in LTM
> fm1 <- rasch(itemDat, constraint = cbind(ncol(itemDat) + 1, 1))
> 
> ### Fit using lmer
> itemDat$id <- 1:nrow(itemDat)
> ### reshape into long format
> testScores <- reshape(itemDat, idvar='id',
> varying=list(names(itemDat)[1:Nitems]), v.names=c('answer'),
> timevar='question', direction='long')
> 
> # Treat items as fixed but students as random
> fm2 <- lmer(answer ~ factor(question) - 1 + (1|id), testScores, family =
> binomial(link='logit'))
> 
> 
> ### Fit using JML
> fm3 <- jml(dat$data, bias=TRUE)
> 
> ### Fit using mml function below
> fm4 <- mml(dat$data, Q =10, startVal = coef(fm1)[,1])
> 
> ### Compute bias
> trueVals <- dat$gen
> 
> ### ltm bias
> mean((coef(fm1)[,1] - mean(coef(fm1)[,1])) - trueVals)
> 
> ### lmer bias
> mean((fixef(fm2) - mean(fixef(fm2))) - trueVals)
> 
> ### jml bias
> mean(coef(fm1) - trueVals)
> 
> ### mml bias
> mean((coef(fm4)[1:20] - mean(coef(fm4)[1:20])) - trueVals)
> 
> 
> 
> mml <- function(data, Q, startVal = NULL, ...){
> 	if(!is.null(startVal) && length(startVal) != ncol(data) ){
> 		stop("Length of argument startVal not equal to the number of
> parameters estimated")
> 	}
> 	if(!is.null(startVal)){
> 		startVal <- startVal
> 		} else {
> 		p <- colMeans(data)
> 		startVal <- as.vector(log((1 - p)/p))
> 	}
> 	qq <- gauss.quad.prob(Q, dist = 'normal', mu = 0, sigma=1)
> 	rr1 <- matrix(0, nrow = Q, ncol = nrow(data))
> 	data <- as.matrix(data)
> 	L <- nrow(data)
> 	C <- ncol(data)
> 	u <- 0
> 	fn <- function(b){
> 	s <- b[C+1]
> 	b <- b[1:C]
> 		for(j in 1:Q){
> 			for(i in 1:L){
> 				rr1[j,i] <- exp(sum(dbinom(data[i,], 1,
> plogis(qq$nodes[j]-b), log = TRUE))) *
> 				((1/(s*sqrt(2*pi)))  * exp(-((qq$nodes[j]-
> u)^2/(2*s^2))))/dnorm(qq$nodes[j]) * qq$weights[j]
> 			}
> 		}
> 	-sum(log(colSums(rr1)))
> 	}
> 	opt <- optim(c(startVal,1), fn, method = "BFGS", hessian = TRUE)
> 	list("coefficients" = opt$par, "LogLik" = -opt$value, "Std.Error" =
> sqrt(diag(solve(opt$hessian))))
> }
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From d.rizopoulos at erasmusmc.nl  Tue Nov  2 15:42:01 2010
From: d.rizopoulos at erasmusmc.nl (Dimitris Rizopoulos)
Date: Tue, 02 Nov 2010 15:42:01 +0100
Subject: [R-sig-ME] IRT: discrimination parameters from LMER?
In-Reply-To: <C0772C7568B5374481D2F8A880E9BBDF06A64B7A9C@DC1EX07CMS.air.org>
References: <AANLkTi=GRoe0-AXFbOiw6x_W95J_j5+rXek-OnoR9CwZ@mail.gmail.com>	<C0772C7568B5374481D2F8A880E9BBDF06A650CA1B@DC1EX07CMS.air.org>	<AANLkTikzXr=KkDzHRUhPW_s+E7u_yf3N3A0d3EXpG=Qj@mail.gmail.com>
	<C0772C7568B5374481D2F8A880E9BBDF06A64B7A9C@DC1EX07CMS.air.org>
Message-ID: <4CD02339.7080802@erasmusmc.nl>

On 11/2/2010 3:33 PM, Doran, Harold wrote:
>> I'm glad to learn I'm not grossly misunderstanding IRT/lmer. What do
>> you think about my observation about the fact that the difficulty
>> estimate from ltm seems to be systematically different/better than the
>> lmer estimate?
>
> I don't think this is true necessarily. I've done a small experiment all reproducible code is at bottom of email. I simulate some rasch data and then estimate item parameters using ltm, lmer, jml (in MiscPsycho), and mml (a function I wrote that is below using the traditional mml methods). To make a long story short, I compute the bias under each model.
>
>> ### ltm bias
>> mean((coef(fm1)[,1] - mean(coef(fm1)[,1])) - trueVals)
> [1] -0.173386111948639
>>
>> ### lmer bias
>> mean((fixef(fm2) - mean(fixef(fm2))) - trueVals)
> [1] -0.173386111948639
>>
>> ### jml bias
>> mean(coef(fm1) - trueVals)
> [1] 0.39007242168395
>>
>> ### mml bias
>> mean((coef(fm4)[1:20] - mean(coef(fm4)[1:20])) - trueVals)
> [1] -0.173386111948639
>
> It seems to me that jml (as expected) performs the worst, but all other functions are comparable and seem to recover parameter estimates rather well. If you run the mml function below, it is slow. But, notice that the standard deviation in mml is exactly the same as what lmer gives. That is because a multilevel rasch model with the parameterization I have used (items as fixed respondents as random) is exactly the same as mml. But, lmer's capacity can go much, much further. Had I not constrained the ltm function to have a discrimination of 1, the common discrimination parameter would also be the sd given by mml and lmer.
>
>> Do you care to weigh in on the question of whether lmer could ever be
>> made to fit a 2PL or 3PL model?  I mean, could I write a family for
>> lmer that would do that, or is the calculation required too grossly
>> different?
>
> Yes, I'm sure it can. The issue is who will write the code. Doug Bates is extremely generous with his help and his openness to others making contributions to lme4. But, (as he might do so on this thread), he will forewarn you that the underlying code in lmer is very complex and doesn't resemble methods commonly used in other packages. So, because Doug is so amazingly smart, and I am just a mortal, I have decided to steer away from contributing to lmer other than being a "toy tester" for Doug.
>
> I am not a fan of the 3PL for many reasons. First, it is a model that cannot be identified without putting a very slim prior on the guessing parameter. In the end, because the prior is so slim, guess what your parameter estimates are close to? Yes, the prior. So, I just have never been made comfortable with that.
>
>> If 2PL or 3PL is really a whole different structure, I don't mind
>> using "ltm."  But defeats the ideal that you proposed in that 2007 JSS
>> article (which I really like!), that we might be better off fitting
>> specialized models with general purpose software.
>
> I think ltm is a really great package. It may have some capacity to do what you want, I don't fully know its capacities. Perhaps Dimitris can offer some thought.

well, the basic capabilities of ltm are described in the JSS paper 
(http://www.jstatsoft.org/v17/a5/paper), and more information about it 
including R script files with many example can be found in the R-wiki 
webpage: http://rwiki.sciviews.org/doku.php?id=packages:cran:ltm

Best,
Dimitris


>> Here's a similar example.  Sometimes I have wanted to fit ordinal
>> dependent variables, and have learned that those models do not fall
>> into the family of GLM and a tool different from lmer is necessary to
>> work on them.   I wish it weren't so, but have accepted reality.
>>
>> pj
>
> This is very true. I have been doing some work on polytomous models, but am working very slowly on functions to estimate them. There are packages in R that can currently do this. I wonder if MCMCglmm can do it; I don't know.
>
>
> library(ltm)
> library(lmer)
> library(MiscPsycho)
>
> Nitems<- 20
> Nperson<- 500
>
> set.seed(12345)
> dat<- simRasch(Nperson, Nitems)
> itemDat<- dat$data
>
> ### Fit data using rasch in LTM
> fm1<- rasch(itemDat, constraint = cbind(ncol(itemDat) + 1, 1))
>
> ### Fit using lmer
> itemDat$id<- 1:nrow(itemDat)
> ### reshape into long format
> testScores<- reshape(itemDat, idvar='id', varying=list(names(itemDat)[1:Nitems]), v.names=c('answer'), timevar='question', direction='long')
>
> # Treat items as fixed but students as random
> fm2<- lmer(answer ~ factor(question) - 1 + (1|id), testScores, family = binomial(link='logit'))
>
>
> ### Fit using JML
> fm3<- jml(dat$data, bias=TRUE)
>
> ### Fit using mml function below
> fm4<- mml(dat$data, Q =10, startVal = coef(fm1)[,1])
>
> ### Compute bias
> trueVals<- dat$gen
>
> ### ltm bias
> mean((coef(fm1)[,1] - mean(coef(fm1)[,1])) - trueVals)
>
> ### lmer bias
> mean((fixef(fm2) - mean(fixef(fm2))) - trueVals)
>
> ### jml bias
> mean(coef(fm1) - trueVals)
>
> ### mml bias
> mean((coef(fm4)[1:20] - mean(coef(fm4)[1:20])) - trueVals)
>
>
>
> mml<- function(data, Q, startVal = NULL, ...){
> 	if(!is.null(startVal)&&  length(startVal) != ncol(data) ){
> 		stop("Length of argument startVal not equal to the number of parameters estimated")
> 	}	
> 	if(!is.null(startVal)){
> 		startVal<- startVal
> 		} else {
> 		p<- colMeans(data)
> 		startVal<- as.vector(log((1 - p)/p))
> 	}
> 	qq<- gauss.quad.prob(Q, dist = 'normal', mu = 0, sigma=1)
> 	rr1<- matrix(0, nrow = Q, ncol = nrow(data))
> 	data<- as.matrix(data)
> 	L<- nrow(data)
> 	C<- ncol(data)
> 	u<- 0
> 	fn<- function(b){
> 	s<- b[C+1]
> 	b<- b[1:C]	
> 		for(j in 1:Q){
> 			for(i in 1:L){
> 				rr1[j,i]<- exp(sum(dbinom(data[i,], 1, plogis(qq$nodes[j]-b), log = TRUE))) *
> 				((1/(s*sqrt(2*pi)))  * exp(-((qq$nodes[j]-u)^2/(2*s^2))))/dnorm(qq$nodes[j]) * qq$weights[j]
> 			}
> 		}
> 	-sum(log(colSums(rr1)))
> 	}	
> 	opt<- optim(c(startVal,1), fn, method = "BFGS", hessian = TRUE)
> 	list("coefficients" = opt$par, "LogLik" = -opt$value, "Std.Error" = sqrt(diag(solve(opt$hessian))))
> }
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

-- 
Dimitris Rizopoulos
Assistant Professor
Department of Biostatistics
Erasmus University Medical Center

Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
Tel: +31/(0)10/7043478
Fax: +31/(0)10/7043014
Web: http://www.erasmusmc.nl/biostatistiek/



From bates at stat.wisc.edu  Tue Nov  2 16:08:31 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 2 Nov 2010 10:08:31 -0500
Subject: [R-sig-ME] Has anyone tried Whit Armstrong's CppMCMC library?
Message-ID: <AANLkTimLkM41225GPO5MdwW5tPKu-6HMX9u2s2PtmomH@mail.gmail.com>

Whit Armstrong has written a C++ library called CppMCMC that provides
BUGS-like functionality in compiled code.  I see that one of his
examples uses the contagious bovine pleuropneumonia data from the cbpp
data set in the lme4 package, fitting an overdispersed binomial-like
model to it.

Does anyone have experience with these classes?  This is not directly
an R question as, at present, I don't know of a bridge between CppMCMC
and R (although it would be an interesting project to use Rcpp for
this).



From armstrong.whit at gmail.com  Tue Nov  2 18:02:09 2010
From: armstrong.whit at gmail.com (Whit Armstrong)
Date: Tue, 2 Nov 2010 13:02:09 -0400
Subject: [R-sig-ME] Has anyone tried Whit Armstrong's CppMCMC library?
In-Reply-To: <AANLkTimLkM41225GPO5MdwW5tPKu-6HMX9u2s2PtmomH@mail.gmail.com>
References: <AANLkTimLkM41225GPO5MdwW5tPKu-6HMX9u2s2PtmomH@mail.gmail.com>
Message-ID: <AANLkTimd5T=8ZibkRYzF1xH_Bm=FYnFhLGHgrY5kXDSC@mail.gmail.com>

Thanks for the the post, Professor Bates.

CppBugs can be found here: http://github.com/armstrtw/CppBugs

It's a combination of WinBUGS and PyMC.

The api is still very unstable as I'm attempting to navigate between
good design and maintaining familiar WinBUGS conventions.

Rcpp is the best way to use it from R.  I'll add an example of calling
it this way on the front page so that everyone can try it.

My thinking is that since it's already very inconvenient to run a BUGS
model from R (writing the BUGS script, providing inits, passing data
back and forth), it's not really asking too much for users to write a
small c++ class inline in an R script that is the CppBugs equivalent
of a BUGS model.

I'm very keen to have help on this project, so if anyone is interested
please contact me.

I'll send a follow up post highlighting a few of the features of
CppBugs and examples of WinBUGS vs PyMC conventions that I've followed
in the design.

-Whit




On Tue, Nov 2, 2010 at 11:08 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
> Whit Armstrong has written a C++ library called CppMCMC that provides
> BUGS-like functionality in compiled code. ?I see that one of his
> examples uses the contagious bovine pleuropneumonia data from the cbpp
> data set in the lme4 package, fitting an overdispersed binomial-like
> model to it.
>
> Does anyone have experience with these classes? ?This is not directly
> an R question as, at present, I don't know of a bridge between CppMCMC
> and R (although it would be an interesting project to use Rcpp for
> this).
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From matz at mail.utexas.edu  Tue Nov  2 18:07:57 2010
From: matz at mail.utexas.edu (mikhail matz)
Date: Tue, 2 Nov 2010 12:07:57 -0500
Subject: [R-sig-ME] proportions data
Message-ID: <12BDCA63-6F88-4616-972C-860EFCE1F084@mail.utexas.edu>

Hello colleagues,

I am looking at the functional correlates of fluorescent color in the  
coral larvae. My response variable ("redness") is a proportion,  
ranging from about 0.5 to 0.9. The distribution of these is not very  
normal, unfortunately.  Arcsin-sqrt  transformation does not fully  
solve the problem: about a quarter of all the groups that I am  
comparing still deviate from normality (lillie.test). The data tend  
to be ever so slightly skewed towards larger values, but with the  
sample sizes I have even a small deviation from bell-shape leads to  
rejection of normality.

  Is there anything I can do to be formally able to run mixed model  
analysis on such data?

Misha
---------------------
Mikhail V. Matz
University of Texas at Austin
  http://www.bio.utexas.edu/research/matz_lab



From tylerdeanrudolph at gmail.com  Tue Nov  2 21:41:24 2010
From: tylerdeanrudolph at gmail.com (Tyler Dean Rudolph)
Date: Tue, 2 Nov 2010 16:41:24 -0400
Subject: [R-sig-ME] sandwich variance estimation using glmer?
Message-ID: <AANLkTi=bULK1vXwFt1+0PjzeWij+sktWNQ6hGcWt3ryj@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101102/f75fe42e/attachment.pl>

From HDoran at air.org  Wed Nov  3 13:57:18 2010
From: HDoran at air.org (Doran, Harold)
Date: Wed, 3 Nov 2010 08:57:18 -0400
Subject: [R-sig-ME] sandwich variance estimation using glmer?
In-Reply-To: <AANLkTi=bULK1vXwFt1+0PjzeWij+sktWNQ6hGcWt3ryj@mail.gmail.com>
References: <AANLkTi=bULK1vXwFt1+0PjzeWij+sktWNQ6hGcWt3ryj@mail.gmail.com>
Message-ID: <C0772C7568B5374481D2F8A880E9BBDF06A64B7C89@DC1EX07CMS.air.org>

Out of curiosity, why would you want a sandwich estimator from lmer? That estimator is typically used when the likelihood is misspecified, but you still want standard errors that account for correlations among units within a cluster.

Since this is what lmer standard errors already account for, is there a need for the sandwich?

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
> bounces at r-project.org] On Behalf Of Tyler Dean Rudolph
> Sent: Tuesday, November 02, 2010 4:41 PM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] sandwich variance estimation using glmer?
> 
> Are there any current functionalities in R that permit estimation of robust
> sandwich variances based on lmer (mixed model) objects??  I'm aware of the
> sandwich package and gee implementations but to my knowledge these are not
> yet compatible with mixed model objects.
> 
> Apparently these are already implemented in SAS....
> 
> Tyler
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From d.rizopoulos at erasmusmc.nl  Wed Nov  3 14:12:59 2010
From: d.rizopoulos at erasmusmc.nl (Dimitris Rizopoulos)
Date: Wed, 03 Nov 2010 14:12:59 +0100
Subject: [R-sig-ME] sandwich variance estimation using glmer?
In-Reply-To: <C0772C7568B5374481D2F8A880E9BBDF06A64B7C89@DC1EX07CMS.air.org>
References: <AANLkTi=bULK1vXwFt1+0PjzeWij+sktWNQ6hGcWt3ryj@mail.gmail.com>
	<C0772C7568B5374481D2F8A880E9BBDF06A64B7C89@DC1EX07CMS.air.org>
Message-ID: <4CD15FDB.8020808@erasmusmc.nl>

On 11/3/2010 1:57 PM, Doran, Harold wrote:
> Out of curiosity, why would you want a sandwich estimator from lmer? That estimator is typically used when the likelihood is misspecified, but you still want standard errors that account for correlations among units within a cluster.
>
> Since this is what lmer standard errors already account for, is there a need for the sandwich?

well, it is possible that the random-effects structure that you have 
specified is not the correct one (i.e., in order to fully account for 
the correlations), and in this case it makes sense to use the sandwich 
estimator (of course, the sandwich estimator has its own problems, but 
this is probably another discussion...)

Best,
Dimitris


>> -----Original Message-----
>> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
>> bounces at r-project.org] On Behalf Of Tyler Dean Rudolph
>> Sent: Tuesday, November 02, 2010 4:41 PM
>> To: r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] sandwich variance estimation using glmer?
>>
>> Are there any current functionalities in R that permit estimation of robust
>> sandwich variances based on lmer (mixed model) objects??  I'm aware of the
>> sandwich package and gee implementations but to my knowledge these are not
>> yet compatible with mixed model objects.
>>
>> Apparently these are already implemented in SAS....
>>
>> Tyler
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

-- 
Dimitris Rizopoulos
Assistant Professor
Department of Biostatistics
Erasmus University Medical Center

Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
Tel: +31/(0)10/7043478
Fax: +31/(0)10/7043014
Web: http://www.erasmusmc.nl/biostatistiek/



From armstrong.whit at gmail.com  Wed Nov  3 19:55:03 2010
From: armstrong.whit at gmail.com (Whit Armstrong)
Date: Wed, 3 Nov 2010 14:55:03 -0400
Subject: [R-sig-ME] Has anyone tried Whit Armstrong's CppMCMC library?
In-Reply-To: <AANLkTimd5T=8ZibkRYzF1xH_Bm=FYnFhLGHgrY5kXDSC@mail.gmail.com>
References: <AANLkTimLkM41225GPO5MdwW5tPKu-6HMX9u2s2PtmomH@mail.gmail.com>
	<AANLkTimd5T=8ZibkRYzF1xH_Bm=FYnFhLGHgrY5kXDSC@mail.gmail.com>
Message-ID: <AANLkTinLOeHqhLBAPGH8Q2McAw21Yc5aR_p+Rc0e+67=@mail.gmail.com>

Below is a minimal example of a simple linear model using CppBugs,
Rcpp, and inline.

The cppbugs dir needs to be on the include path of the compiler for
this example to work.  Otherwise, you will need to change the #include
statements to use the local path of your cppbugs install.

Other dependencies you need are Armadillo and Boost.

feedback welcome.

-Whit

require(inline)
require(Rcpp)

cppbugs.model <- '
#include <armadillo>
#include <cppbugs/cppbugs.hpp>

using namespace arma;
using namespace cppbugs;

class TestModel: public MCModel {
public:
  const mat& y; // given
  const mat& X; // given

  Stochastic<vec> b;
  Stochastic<double> tau_y;
  Deterministic<mat> y_hat;
  Stochastic<mat> likelihood;
  Deterministic<double> rsq;

  TestModel(const mat& y_,const mat& X_): y(y_),
X(X_),b(randn<vec>(X_.n_cols)),tau_y(1),y_hat(X*b.value),likelihood(y_,true),rsq(0)
  {
    add(b);
    add(tau_y);
    add(y_hat);
    add(likelihood);
    add(rsq);
  }

  void update() {
    y_hat.value = X*b.value;
    rsq.value = as_scalar(1 - var(y - y_hat.value) / var(y));
    b.dnorm(0.0, 0.0001);
    tau_y.dunif(0,100);
    likelihood.dnorm(y_hat.value,tau_y.value);
  }
};
'

src <- '
mat X(REAL(XR),::Rf_nrows(XR),::Rf_ncols(XR));
mat y(REAL(yr),::Rf_nrows(yr),::Rf_ncols(yr));
int iterations_ = as<int>(iterations);
int burn_ = as<int>(burn);
int thin_ = as<int>(thin);

TestModel m(y,X);
m.sample(iterations_, burn_, thin_);
return Rcpp::List::create(Rcpp::Named("b", m.b.mean()),
Rcpp::Named("tau.y", m.tau_y.mean()), Rcpp::Named("ar",
m.acceptance_ratio()), Rcpp::Named("rsq", m.rsq.mean()));
'

NR <- 100
NC <- 2
icept <- 10
y = rnorm(NR,icept)
X = matrix(rnorm(NR*NC),ncol=NC)
X[,1] <- 1.0
X[,2] <- y + - icept + rnorm(NR);

bayes.reg <- cxxfunction(signature(XR="numeric",
yr="numeric",iterations="integer",burn="integer",thin="integer"),
body=src, include=cppbugs.model, plugin="Rcpp")
ans <- bayes.reg(X,y,1e5L,1e4L,10L)
print(ans)


On Tue, Nov 2, 2010 at 1:02 PM, Whit Armstrong <armstrong.whit at gmail.com> wrote:
> Thanks for the the post, Professor Bates.
>
> CppBugs can be found here: http://github.com/armstrtw/CppBugs
>
> It's a combination of WinBUGS and PyMC.
>
> The api is still very unstable as I'm attempting to navigate between
> good design and maintaining familiar WinBUGS conventions.
>
> Rcpp is the best way to use it from R. ?I'll add an example of calling
> it this way on the front page so that everyone can try it.
>
> My thinking is that since it's already very inconvenient to run a BUGS
> model from R (writing the BUGS script, providing inits, passing data
> back and forth), it's not really asking too much for users to write a
> small c++ class inline in an R script that is the CppBugs equivalent
> of a BUGS model.
>
> I'm very keen to have help on this project, so if anyone is interested
> please contact me.
>
> I'll send a follow up post highlighting a few of the features of
> CppBugs and examples of WinBUGS vs PyMC conventions that I've followed
> in the design.
>
> -Whit
>
>
>
>
> On Tue, Nov 2, 2010 at 11:08 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
>> Whit Armstrong has written a C++ library called CppMCMC that provides
>> BUGS-like functionality in compiled code. ?I see that one of his
>> examples uses the contagious bovine pleuropneumonia data from the cbpp
>> data set in the lme4 package, fitting an overdispersed binomial-like
>> model to it.
>>
>> Does anyone have experience with these classes? ?This is not directly
>> an R question as, at present, I don't know of a bridge between CppMCMC
>> and R (although it would be an interesting project to use Rcpp for
>> this).
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>



From rsouza at uoguelph.ca  Wed Nov  3 21:04:25 2010
From: rsouza at uoguelph.ca (Raquel Souza Dias)
Date: Wed, 3 Nov 2010 16:04:25 -0400 (EDT)
Subject: [R-sig-ME] derivative for nlmer
Message-ID: <1955450208.49127.1288814665171.JavaMail.root@erie.cs.uoguelph.ca>

Hi 
I have data on phosphorus intake (avP) and P retention (Pret) of pigs from 11 studies which I consider a random effect of my model. I am trying to fit a monomolecular equation to this data and I get the following error: gradient matrix must be of size 46 by 3
See bellow my code:
myfun <- function(a, b, c, avP) {
+     a-(a+b)*exp(-c*avP)}
> mono.fun <- deriv(body (myfun)[[2]],
+                 namevec = c("avP", "a", "b", "c"),
+                 function.arg=myfun)
> startsite <- c(a=0.19, b=0.04, c=1)
> nlmer(Pret ~ mono.fun(a,b,c,avP) ~ (a|study),
+                       data=data, start=startsite, verbose = TRUE) 

It seems to be a very simple case. I am learning how to work in R. 
I really appreciate any help!
Thank you!
Raquel



From tylerdeanrudolph at gmail.com  Wed Nov  3 21:04:23 2010
From: tylerdeanrudolph at gmail.com (Tyler Dean Rudolph)
Date: Wed, 3 Nov 2010 16:04:23 -0400
Subject: [R-sig-ME] sandwich variance estimation using glmer?
In-Reply-To: <4CD15FDB.8020808@erasmusmc.nl>
References: <AANLkTi=bULK1vXwFt1+0PjzeWij+sktWNQ6hGcWt3ryj@mail.gmail.com>
	<C0772C7568B5374481D2F8A880E9BBDF06A64B7C89@DC1EX07CMS.air.org>
	<4CD15FDB.8020808@erasmusmc.nl>
Message-ID: <AANLkTi=AiOo9E82N+gZMFMpP1NSV4mTQ1LZ7q1TqBw=j@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101103/8a335ac5/attachment.pl>

From datkins at u.washington.edu  Wed Nov  3 21:45:22 2010
From: datkins at u.washington.edu (David Atkins)
Date: Wed, 03 Nov 2010 13:45:22 -0700
Subject: [R-sig-ME] sandwich variance estimation using glmer?
In-Reply-To: <AANLkTi=AiOo9E82N+gZMFMpP1NSV4mTQ1LZ7q1TqBw=j@mail.gmail.com>
References: <AANLkTi=AiOo9E82N+gZMFMpP1NSV4mTQ1LZ7q1TqBw=j@mail.gmail.com>
Message-ID: <4CD1C9E2.8070607@u.washington.edu>


Tyler--

This question about "robust" (usually, heteroscedastically consistent) 
SE has come up before with respect to lme4 and lmer.  For example, see 
the following thread:

http://tolstoy.newcastle.edu.au/R/e3/help/07/10/0754.html

I have a vague memory of seeing a post from Achim Zeileis (the author of 
the "sandwich" package) mentioning why it might be challenging to extend 
his methods to lmer, but I couldn't (quickly) find it.

[BTW, you might be cautious about comparisons to SAS... R is a wonderful 
resource, but not universally guaranteed to do everything SAS can, and 
sometimes for good reasons.  Moreover, it is the result of an 
incredible, collective generosity of time and expertise (ie, nobody is 
making money here...).]

Hope that helps.

cheers, Dave

Tyler wrote:

Indeed, in this case the correlation structure of the random effects is not
fully appreciated or known, in which case the standard errors are likely
underestimated.  The use of sandwich estimators should render variance
estimates, and therefore inference, somewhat more realistic.  While this is
currently possible with GEEs, that approach does not ask the same question
as a GLMM (i.e. marginal or "population" estimates vs. conditional or
"subject-specific" estimates).

I used to think R updates were ahead of SAS upgrades in terms of new
approaches but apparently that is often not the case.  Does anyone have the
know-how required to implement this in R, or is there something I'm still
missing?

Best,
Tyler


On Wed, Nov 3, 2010 at 9:12 AM, Dimitris Rizopoulos <
d.rizopoulos at erasmusmc.nl> wrote:

 > On 11/3/2010 1:57 PM, Doran, Harold wrote:
 >
 >> Out of curiosity, why would you want a sandwich estimator from lmer? 
That
 >> estimator is typically used when the likelihood is misspecified, but you
 >> still want standard errors that account for correlations among units 
within
 >> a cluster.
 >>
 >> Since this is what lmer standard errors already account for, is there a
 >> need for the sandwich?
 >>
 >
 > well, it is possible that the random-effects structure that you have
 > specified is not the correct one (i.e., in order to fully account for the
 > correlations), and in this case it makes sense to use the sandwich 
estimator
 > (of course, the sandwich estimator has its own problems, but this is
 > probably another discussion...)
 >
 > Best,
 > Dimitris
 >
 >
 >
 >  -----Original Message-----
 >>> From: r-sig-mixed-models-bounces at r-project.org [mailto:
 >>> r-sig-mixed-models-
 >>> bounces at r-project.org] On Behalf Of Tyler Dean Rudolph
 >>> Sent: Tuesday, November 02, 2010 4:41 PM
 >>> To: r-sig-mixed-models at r-project.org
 >>> Subject: [R-sig-ME] sandwich variance estimation using glmer?
 >>>
 >>> Are there any current functionalities in R that permit estimation of
 >>> robust
 >>> sandwich variances based on lmer (mixed model) objects??  I'm aware of
 >>> the
 >>> sandwich package and gee implementations but to my knowledge these are
 >>> not
 >>> yet compatible with mixed model objects.
 >>>
 >>> Apparently these are already implemented in SAS....
 >>>
 >>> Tyler
 >>>
 >>>        [[alternative HTML version deleted]]
 >>>
 >>> _______________________________________________
 >>> R-sig-mixed-models at r-project.org mailing list
 >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
 >>>
 >>
 >> _______________________________________________
 >> R-sig-mixed-models at r-project.org mailing list
 >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
 >>
 >>
 > --
 > Dimitris Rizopoulos
 > Assistant Professor
 > Department of Biostatistics
 > Erasmus University Medical Center
 >
 > Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
 > Tel: +31/(0)10/7043478
 > Fax: +31/(0)10/7043014
 > Web: http://www.erasmusmc.nl/biostatistiek/
 >

	[[alternative HTML version deleted]]


-- 
Dave Atkins, PhD
Research Associate Professor
Department of Psychiatry and Behavioral Science
University of Washington
datkins at u.washington.edu

Center for the Study of Health and Risk Behaviors (CSHRB)		
1100 NE 45th Street, Suite 300 	
Seattle, WA  98105 	
206-616-3879 	
http://depts.washington.edu/cshrb/
(Mon-Wed)	

Center for Healthcare Improvement, for Addictions, Mental Illness,
   Medically Vulnerable Populations (CHAMMP)
325 9th Avenue, 2HH-15
Box 359911
Seattle, WA 98104
http://www.chammp.org
(Thurs)



From A.Robinson at ms.unimelb.edu.au  Wed Nov  3 22:49:54 2010
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Thu, 4 Nov 2010 08:49:54 +1100
Subject: [R-sig-ME] sandwich variance estimation using glmer?
In-Reply-To: <AANLkTi=AiOo9E82N+gZMFMpP1NSV4mTQ1LZ7q1TqBw=j@mail.gmail.com>
References: <AANLkTi=bULK1vXwFt1+0PjzeWij+sktWNQ6hGcWt3ryj@mail.gmail.com>
	<C0772C7568B5374481D2F8A880E9BBDF06A64B7C89@DC1EX07CMS.air.org>
	<4CD15FDB.8020808@erasmusmc.nl>
	<AANLkTi=AiOo9E82N+gZMFMpP1NSV4mTQ1LZ7q1TqBw=j@mail.gmail.com>
Message-ID: <20101103214954.GA383@ms.unimelb.edu.au>

Hi Tyler,

I think that there's something that you're missing.

R is not motivated by comparisons with SAS or any package.  So, your
impression that R was ahead of SAS or behind SAS is mistaken, or at
least, it's your impression, so you are responsible for it.  R
responds exactly to the community's needs because the community
supports it.  If the functionality that you want isn't there, it's
because noone else has wanted it badly enough to

a) code it up, or

b) pay someone else to code it up.

If you want that function, and you know that SAS has it, then use SAS.
If you want to use that function in R, then see the above two points.

Good luck,

Andrew


On Wed, Nov 03, 2010 at 04:04:23PM -0400, Tyler Dean Rudolph wrote:
> Indeed, in this case the correlation structure of the random effects is not
> fully appreciated or known, in which case the standard errors are likely
> underestimated.  The use of sandwich estimators should render variance
> estimates, and therefore inference, somewhat more realistic.  While this is
> currently possible with GEEs, that approach does not ask the same question
> as a GLMM (i.e. marginal or "population" estimates vs. conditional or
> "subject-specific" estimates).
> 
> I used to think R updates were ahead of SAS upgrades in terms of new
> approaches but apparently that is often not the case.  Does anyone have the
> know-how required to implement this in R, or is there something I'm still
> missing?
> 
> Best,
> Tyler
> 
> 
> On Wed, Nov 3, 2010 at 9:12 AM, Dimitris Rizopoulos <
> d.rizopoulos at erasmusmc.nl> wrote:
> 
> > On 11/3/2010 1:57 PM, Doran, Harold wrote:
> >
> >> Out of curiosity, why would you want a sandwich estimator from lmer? That
> >> estimator is typically used when the likelihood is misspecified, but you
> >> still want standard errors that account for correlations among units within
> >> a cluster.
> >>
> >> Since this is what lmer standard errors already account for, is there a
> >> need for the sandwich?
> >>
> >
> > well, it is possible that the random-effects structure that you have
> > specified is not the correct one (i.e., in order to fully account for the
> > correlations), and in this case it makes sense to use the sandwich estimator
> > (of course, the sandwich estimator has its own problems, but this is
> > probably another discussion...)
> >
> > Best,
> > Dimitris
> >
> >
> >
> >  -----Original Message-----
> >>> From: r-sig-mixed-models-bounces at r-project.org [mailto:
> >>> r-sig-mixed-models-
> >>> bounces at r-project.org] On Behalf Of Tyler Dean Rudolph
> >>> Sent: Tuesday, November 02, 2010 4:41 PM
> >>> To: r-sig-mixed-models at r-project.org
> >>> Subject: [R-sig-ME] sandwich variance estimation using glmer?
> >>>
> >>> Are there any current functionalities in R that permit estimation of
> >>> robust
> >>> sandwich variances based on lmer (mixed model) objects??  I'm aware of
> >>> the
> >>> sandwich package and gee implementations but to my knowledge these are
> >>> not
> >>> yet compatible with mixed model objects.
> >>>
> >>> Apparently these are already implemented in SAS....
> >>>
> >>> Tyler
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >>
> > --
> > Dimitris Rizopoulos
> > Assistant Professor
> > Department of Biostatistics
> > Erasmus University Medical Center
> >
> > Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
> > Tel: +31/(0)10/7043478
> > Fax: +31/(0)10/7043014
> > Web: http://www.erasmusmc.nl/biostatistiek/
> >
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Andrew Robinson  
Program Manager, ACERA 
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia               (prefer email)
http://www.ms.unimelb.edu.au/~andrewpr              Fax: +61-3-8344-4599
http://www.acera.unimelb.edu.au/



From r.turner at auckland.ac.nz  Wed Nov  3 23:27:00 2010
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 4 Nov 2010 11:27:00 +1300
Subject: [R-sig-ME] sandwich variance estimation using glmer?
In-Reply-To: <20101103214954.GA383@ms.unimelb.edu.au>
References: <AANLkTi=bULK1vXwFt1+0PjzeWij+sktWNQ6hGcWt3ryj@mail.gmail.com>
	<C0772C7568B5374481D2F8A880E9BBDF06A64B7C89@DC1EX07CMS.air.org>
	<4CD15FDB.8020808@erasmusmc.nl>
	<AANLkTi=AiOo9E82N+gZMFMpP1NSV4mTQ1LZ7q1TqBw=j@mail.gmail.com>
	<20101103214954.GA383@ms.unimelb.edu.au>
Message-ID: <F4A29BCE-8568-450E-9EE5-6D1F301EB113@auckland.ac.nz>


On 4/11/2010, at 10:49 AM, Andrew Robinson wrote:

	<SNIP>

> .......  If the functionality that you want isn't there, it's
> because noone else has wanted it badly enough to
> 
> a) code it up, or
> 
> b) pay someone else to code it up.

	<SNIP>

There is another possibility that should be taken into consideration.
The person wanting that functionality may lack both the requisite skills
and insight to code up the functionality his or herself and the financial
resources to pay someone else to do this.

Yet another possibility is that the person responsible for the original
code simply never thought of including the requested functionality.  I am
sure I've seen instances where people have asked (on the R-help list) for
features in specific packages, and the maintainers of those packages have
responded ``Yes, that's a good idea.  I'll include that in the next release.''
Can't give specific examples off the top of my head.  However I know for
certain that I have accommodated such feature requests from users in respect
of packages that I maintain (specifically Iso and deldir).

	cheers,

		Rolf Turner


From A.Robinson at ms.unimelb.edu.au  Wed Nov  3 23:39:51 2010
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Thu, 4 Nov 2010 09:39:51 +1100
Subject: [R-sig-ME] sandwich variance estimation using glmer?
In-Reply-To: <AANLkTiktrKaX1wZTBcSSRm__YHCDc6ezuAR62pnFEgqX@mail.gmail.com>
References: <AANLkTi=bULK1vXwFt1+0PjzeWij+sktWNQ6hGcWt3ryj@mail.gmail.com>
	<C0772C7568B5374481D2F8A880E9BBDF06A64B7C89@DC1EX07CMS.air.org>
	<4CD15FDB.8020808@erasmusmc.nl>
	<AANLkTi=AiOo9E82N+gZMFMpP1NSV4mTQ1LZ7q1TqBw=j@mail.gmail.com>
	<20101103214954.GA383@ms.unimelb.edu.au>
	<AANLkTiktrKaX1wZTBcSSRm__YHCDc6ezuAR62pnFEgqX@mail.gmail.com>
Message-ID: <20101103223951.GI383@ms.unimelb.edu.au>

Hi Tyler,

I guess that it is a sensitive topic.  This is a community of
volunteers.  Specious comparisons with commercial software products
aren't helpful, unless they're *positive* specious comparisons ;).  

The other problem with working in a community is that it's very
difficult for any one person to definitively state that functionality
does not exist and is not presently being worked on.  

So, I repeat, good luck ....

Andrew


On Wed, Nov 03, 2010 at 06:06:43PM -0400, Tyler Dean Rudolph wrote:
>    Hi Andrew,
>    Unfortunately I do not have access to SAS, so that is simply not an option
>    for me, though I do welcome your clarification. If this is a sensitive
>    topic perhaps I will abstain from mentioning it in future, but to me it
>    was a simple observation and not a value statement requiring
>    qualification.
>    Perhaps I should put this another way: can anyone confirm that this
>    functionality does NOT exist or is NOT presently being worked on somewhere
>    within the R sphere?
>    Tyler
> 
>    On Wed, Nov 3, 2010 at 5:49 PM, Andrew Robinson
>    <[1]A.Robinson at ms.unimelb.edu.au> wrote:
> 
>      Hi Tyler,
> 
>      I think that there's something that you're missing.
> 
>      R is not motivated by comparisons with SAS or any package. So, your
>      impression that R was ahead of SAS or behind SAS is mistaken, or at
>      least, it's your impression, so you are responsible for it. R
>      responds exactly to the community's needs because the community
>      supports it. If the functionality that you want isn't there, it's
>      because noone else has wanted it badly enough to
> 
>      a) code it up, or
> 
>      b) pay someone else to code it up.
> 
>      If you want that function, and you know that SAS has it, then use SAS.
>      If you want to use that function in R, then see the above two points.
> 
>      Good luck,
> 
>      Andrew
> 
>      On Wed, Nov 03, 2010 at 04:04:23PM -0400, Tyler Dean Rudolph wrote:
>      > Indeed, in this case the correlation structure of the random effects
>      is not
>      > fully appreciated or known, in which case the standard errors are
>      likely
>      > underestimated. The use of sandwich estimators should render variance
>      > estimates, and therefore inference, somewhat more realistic. While
>      this is
>      > currently possible with GEEs, that approach does not ask the same
>      question
>      > as a GLMM (i.e. marginal or "population" estimates vs. conditional or
>      > "subject-specific" estimates).
>      >
>      > I used to think R updates were ahead of SAS upgrades in terms of new
>      > approaches but apparently that is often not the case. Does anyone have
>      the
>      > know-how required to implement this in R, or is there something I'm
>      still
>      > missing?
>      >
>      > Best,
>      > Tyler
>      >
>      >
>      > On Wed, Nov 3, 2010 at 9:12 AM, Dimitris Rizopoulos <
>      > [2]d.rizopoulos at erasmusmc.nl> wrote:
>      >
>      > > On 11/3/2010 1:57 PM, Doran, Harold wrote:
>      > >
>      > >> Out of curiosity, why would you want a sandwich estimator from
>      lmer? That
>      > >> estimator is typically used when the likelihood is misspecified,
>      but you
>      > >> still want standard errors that account for correlations among
>      units within
>      > >> a cluster.
>      > >>
>      > >> Since this is what lmer standard errors already account for, is
>      there a
>      > >> need for the sandwich?
>      > >>
>      > >
>      > > well, it is possible that the random-effects structure that you have
>      > > specified is not the correct one (i.e., in order to fully account
>      for the
>      > > correlations), and in this case it makes sense to use the sandwich
>      estimator
>      > > (of course, the sandwich estimator has its own problems, but this is
>      > > probably another discussion...)
>      > >
>      > > Best,
>      > > Dimitris
>      > >
>      > >
>      > >
>      > > -----Original Message-----
>      > >>> From: [3]r-sig-mixed-models-bounces at r-project.org [mailto:
>      > >>> r-sig-mixed-models-
>      > >>> [4]bounces at r-project.org] On Behalf Of Tyler Dean Rudolph
>      > >>> Sent: Tuesday, November 02, 2010 4:41 PM
>      > >>> To: [5]r-sig-mixed-models at r-project.org
>      > >>> Subject: [R-sig-ME] sandwich variance estimation using glmer?
>      > >>>
>      > >>> Are there any current functionalities in R that permit estimation
>      of
>      > >>> robust
>      > >>> sandwich variances based on lmer (mixed model) objects?? I'm aware
>      of
>      > >>> the
>      > >>> sandwich package and gee implementations but to my knowledge these
>      are
>      > >>> not
>      > >>> yet compatible with mixed model objects.
>      > >>>
>      > >>> Apparently these are already implemented in SAS....
>      > >>>
>      > >>> Tyler
>      > >>>
>      > >>> [[alternative HTML version deleted]]
>      > >>>
>      > >>> _______________________________________________
>      > >>> [6]R-sig-mixed-models at r-project.org mailing list
>      > >>> [7]https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>      > >>>
>      > >>
>      > >> _______________________________________________
>      > >> [8]R-sig-mixed-models at r-project.org mailing list
>      > >> [9]https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>      > >>
>      > >>
>      > > --
>      > > Dimitris Rizopoulos
>      > > Assistant Professor
>      > > Department of Biostatistics
>      > > Erasmus University Medical Center
>      > >
>      > > Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
>      > > Tel: +31/(0)10/7043478
>      > > Fax: +31/(0)10/7043014
>      > > Web: [10]http://www.erasmusmc.nl/biostatistiek/
>      > >
>      >
>      > [[alternative HTML version deleted]]
>      >
>      > _______________________________________________
>      > [11]R-sig-mixed-models at r-project.org mailing list
>      > [12]https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
>      --
>      Andrew Robinson
>      Program Manager, ACERA
>      Department of Mathematics and Statistics Tel: +61-3-8344-6410
>      University of Melbourne, VIC 3010 Australia (prefer email)
>      [13]http://www.ms.unimelb.edu.au/~andrewpr Fax: +61-3-8344-4599
>      [14]http://www.acera.unimelb.edu.au/
> 
> References
> 
>    Visible links
>    1. mailto:A.Robinson at ms.unimelb.edu.au
>    2. mailto:d.rizopoulos at erasmusmc.nl
>    3. mailto:r-sig-mixed-models-bounces at r-project.org
>    4. mailto:bounces at r-project.org
>    5. mailto:r-sig-mixed-models at r-project.org
>    6. mailto:R-sig-mixed-models at r-project.org
>    7. https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>    8. mailto:R-sig-mixed-models at r-project.org
>    9. https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>   10. http://www.erasmusmc.nl/biostatistiek/
>   11. mailto:R-sig-mixed-models at r-project.org
>   12. https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>   13. http://www.ms.unimelb.edu.au/~andrewpr
>   14. http://www.acera.unimelb.edu.au/

-- 
Andrew Robinson  
Program Manager, ACERA 
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia               (prefer email)
http://www.ms.unimelb.edu.au/~andrewpr              Fax: +61-3-8344-4599
http://www.acera.unimelb.edu.au/



From smccracken at tadpoleorg.org  Thu Nov  4 06:55:02 2010
From: smccracken at tadpoleorg.org (Shawn McCracken)
Date: Thu, 04 Nov 2010 00:55:02 -0500
Subject: [R-sig-ME] Questions - next steps in GLMM analysis on nested
	ecological dataset
Message-ID: <C8F7B4E6.1688C%smccracken@tadpoleorg.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101104/05c1a7f7/attachment.pl>

From tylerdeanrudolph at gmail.com  Wed Nov  3 23:06:43 2010
From: tylerdeanrudolph at gmail.com (Tyler Dean Rudolph)
Date: Wed, 3 Nov 2010 18:06:43 -0400
Subject: [R-sig-ME] sandwich variance estimation using glmer?
In-Reply-To: <20101103214954.GA383@ms.unimelb.edu.au>
References: <AANLkTi=bULK1vXwFt1+0PjzeWij+sktWNQ6hGcWt3ryj@mail.gmail.com>
	<C0772C7568B5374481D2F8A880E9BBDF06A64B7C89@DC1EX07CMS.air.org>
	<4CD15FDB.8020808@erasmusmc.nl>
	<AANLkTi=AiOo9E82N+gZMFMpP1NSV4mTQ1LZ7q1TqBw=j@mail.gmail.com>
	<20101103214954.GA383@ms.unimelb.edu.au>
Message-ID: <AANLkTiktrKaX1wZTBcSSRm__YHCDc6ezuAR62pnFEgqX@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101103/beaac9a8/attachment.pl>

From HDoran at air.org  Thu Nov  4 15:18:45 2010
From: HDoran at air.org (Doran, Harold)
Date: Thu, 4 Nov 2010 10:18:45 -0400
Subject: [R-sig-ME] sandwich variance estimation using glmer?
In-Reply-To: <AANLkTiktrKaX1wZTBcSSRm__YHCDc6ezuAR62pnFEgqX@mail.gmail.com>
References: <AANLkTi=bULK1vXwFt1+0PjzeWij+sktWNQ6hGcWt3ryj@mail.gmail.com>
	<C0772C7568B5374481D2F8A880E9BBDF06A64B7C89@DC1EX07CMS.air.org>
	<4CD15FDB.8020808@erasmusmc.nl>
	<AANLkTi=AiOo9E82N+gZMFMpP1NSV4mTQ1LZ7q1TqBw=j@mail.gmail.com>
	<20101103214954.GA383@ms.unimelb.edu.au>
	<AANLkTiktrKaX1wZTBcSSRm__YHCDc6ezuAR62pnFEgqX@mail.gmail.com>
Message-ID: <C0772C7568B5374481D2F8A880E9BBDF06A64B7EC8@DC1EX07CMS.air.org>

Let me push on this just a bit to spark further discussion. The OP was interested in robust standard errors given misspecification in the likelihood. So, one possible avenue was to explore Huber-White standard errors, or the sandwich estimator, to account for this misspecification and obtain "better" standard errors, but still use the point estimates of the fixed effects as given.

Some discussion on this has noted that the misspecification occurs in many ways, sometimes given that distributional assumptions were not met. Let's assume someone was willing and skilled to code up the HW as a possible solution within lmer to account for not meeting certain distributional assumptions.

My question is now why not directly code up models that permit for different distributional assumptions, such as t-distributions of residuals (random effects) or whatever the case might be? In other words, why not write code that addresses the problems directly (misspecification of the likelihood) rather than focusing on HW estimates.

Isn't it a better use of time and energy to focus on properly specifying the likelihood and estimating parameters from that model rather than HW?



> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
> bounces at r-project.org] On Behalf Of Tyler Dean Rudolph
> Sent: Wednesday, November 03, 2010 6:07 PM
> To: Andrew Robinson
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] sandwich variance estimation using glmer?
> 
> Hi Andrew,
> 
> Unfortunately I do not have access to SAS, so that is simply not an option
> for me, though I do welcome your clarification.  If this is a sensitive
> topic perhaps I will abstain from mentioning it in future, but to me it was
> a simple observation and not a value statement requiring qualification.
> 
> Perhaps I should put this another way: can anyone confirm that this
> functionality does NOT exist or is NOT presently being worked on somewhere
> within the R sphere?
> 
> Tyler
> 
> 
> 
> On Wed, Nov 3, 2010 at 5:49 PM, Andrew Robinson <
> A.Robinson at ms.unimelb.edu.au> wrote:
> 
> > Hi Tyler,
> >
> > I think that there's something that you're missing.
> >
> > R is not motivated by comparisons with SAS or any package.  So, your
> > impression that R was ahead of SAS or behind SAS is mistaken, or at
> > least, it's your impression, so you are responsible for it.  R
> > responds exactly to the community's needs because the community
> > supports it.  If the functionality that you want isn't there, it's
> > because noone else has wanted it badly enough to
> >
> > a) code it up, or
> >
> > b) pay someone else to code it up.
> >
> > If you want that function, and you know that SAS has it, then use SAS.
> > If you want to use that function in R, then see the above two points.
> >
> > Good luck,
> >
> > Andrew
> >
> >
> > On Wed, Nov 03, 2010 at 04:04:23PM -0400, Tyler Dean Rudolph wrote:
> > > Indeed, in this case the correlation structure of the random effects is
> > not
> > > fully appreciated or known, in which case the standard errors are likely
> > > underestimated.  The use of sandwich estimators should render variance
> > > estimates, and therefore inference, somewhat more realistic.  While this
> > is
> > > currently possible with GEEs, that approach does not ask the same
> > question
> > > as a GLMM (i.e. marginal or "population" estimates vs. conditional or
> > > "subject-specific" estimates).
> > >
> > > I used to think R updates were ahead of SAS upgrades in terms of new
> > > approaches but apparently that is often not the case.  Does anyone have
> > the
> > > know-how required to implement this in R, or is there something I'm still
> > > missing?
> > >
> > > Best,
> > > Tyler
> > >
> > >
> > > On Wed, Nov 3, 2010 at 9:12 AM, Dimitris Rizopoulos <
> > > d.rizopoulos at erasmusmc.nl> wrote:
> > >
> > > > On 11/3/2010 1:57 PM, Doran, Harold wrote:
> > > >
> > > >> Out of curiosity, why would you want a sandwich estimator from lmer?
> > That
> > > >> estimator is typically used when the likelihood is misspecified, but
> > you
> > > >> still want standard errors that account for correlations among units
> > within
> > > >> a cluster.
> > > >>
> > > >> Since this is what lmer standard errors already account for, is there
> > a
> > > >> need for the sandwich?
> > > >>
> > > >
> > > > well, it is possible that the random-effects structure that you have
> > > > specified is not the correct one (i.e., in order to fully account for
> > the
> > > > correlations), and in this case it makes sense to use the sandwich
> > estimator
> > > > (of course, the sandwich estimator has its own problems, but this is
> > > > probably another discussion...)
> > > >
> > > > Best,
> > > > Dimitris
> > > >
> > > >
> > > >
> > > >  -----Original Message-----
> > > >>> From: r-sig-mixed-models-bounces at r-project.org [mailto:
> > > >>> r-sig-mixed-models-
> > > >>> bounces at r-project.org] On Behalf Of Tyler Dean Rudolph
> > > >>> Sent: Tuesday, November 02, 2010 4:41 PM
> > > >>> To: r-sig-mixed-models at r-project.org
> > > >>> Subject: [R-sig-ME] sandwich variance estimation using glmer?
> > > >>>
> > > >>> Are there any current functionalities in R that permit estimation of
> > > >>> robust
> > > >>> sandwich variances based on lmer (mixed model) objects??  I'm aware
> > of
> > > >>> the
> > > >>> sandwich package and gee implementations but to my knowledge these
> > are
> > > >>> not
> > > >>> yet compatible with mixed model objects.
> > > >>>
> > > >>> Apparently these are already implemented in SAS....
> > > >>>
> > > >>> Tyler
> > > >>>
> > > >>>        [[alternative HTML version deleted]]
> > > >>>
> > > >>> _______________________________________________
> > > >>> R-sig-mixed-models at r-project.org mailing list
> > > >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > > >>>
> > > >>
> > > >> _______________________________________________
> > > >> R-sig-mixed-models at r-project.org mailing list
> > > >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > > >>
> > > >>
> > > > --
> > > > Dimitris Rizopoulos
> > > > Assistant Professor
> > > > Department of Biostatistics
> > > > Erasmus University Medical Center
> > > >
> > > > Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
> > > > Tel: +31/(0)10/7043478
> > > > Fax: +31/(0)10/7043014
> > > > Web: http://www.erasmusmc.nl/biostatistiek/
> > > >
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> > --
> > Andrew Robinson
> > Program Manager, ACERA
> > Department of Mathematics and Statistics            Tel: +61-3-8344-6410
> > University of Melbourne, VIC 3010 Australia               (prefer email)
> > http://www.ms.unimelb.edu.au/~andrewpr              Fax: +61-3-8344-4599
> > http://www.acera.unimelb.edu.au/
> >
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bbolker at gmail.com  Thu Nov  4 16:24:58 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 04 Nov 2010 11:24:58 -0400
Subject: [R-sig-ME] sandwich variance estimation using glmer?
In-Reply-To: <C0772C7568B5374481D2F8A880E9BBDF06A64B7EC8@DC1EX07CMS.air.org>
References: <AANLkTi=bULK1vXwFt1+0PjzeWij+sktWNQ6hGcWt3ryj@mail.gmail.com>	<C0772C7568B5374481D2F8A880E9BBDF06A64B7C89@DC1EX07CMS.air.org>	<4CD15FDB.8020808@erasmusmc.nl>	<AANLkTi=AiOo9E82N+gZMFMpP1NSV4mTQ1LZ7q1TqBw=j@mail.gmail.com>	<20101103214954.GA383@ms.unimelb.edu.au>	<AANLkTiktrKaX1wZTBcSSRm__YHCDc6ezuAR62pnFEgqX@mail.gmail.com>
	<C0772C7568B5374481D2F8A880E9BBDF06A64B7EC8@DC1EX07CMS.air.org>
Message-ID: <4CD2D04A.3070100@gmail.com>

On 10-11-04 10:18 AM, Doran, Harold wrote:
> Let me push on this just a bit to spark further discussion. The OP
> was interested in robust standard errors given misspecification in
> the likelihood. So, one possible avenue was to explore Huber-White
> standard errors, or the sandwich estimator, to account for this
> misspecification and obtain "better" standard errors, but still use
> the point estimates of the fixed effects as given.
> 
> Some discussion on this has noted that the misspecification occurs in
> many ways, sometimes given that distributional assumptions were not
> met. Let's assume someone was willing and skilled to code up the HW
> as a possible solution within lmer to account for not meeting certain
> distributional assumptions.
> 
> My question is now why not directly code up models that permit for
> different distributional assumptions, such as t-distributions of
> residuals (random effects) or whatever the case might be? In other
> words, why not write code that addresses the problems directly
> (misspecification of the likelihood) rather than focusing on HW
> estimates.
> 
> Isn't it a better use of time and energy to focus on properly
> specifying the likelihood and estimating parameters from that model
> rather than HW?

   I would say there are two issues here, one philosophical and one
technical/pragmatic.

  Philosophical: how should one divide one's time and effort between
trying to come up with better parametric models vs. admitting that 'all
models are wrong' and coming up instead with robust alternatives that
perform reasonably well across a broad range of (unknown/unspecified)
parametric models?

  Technical/pragmatic: taking your case of t-distributions of residuals
-- this could be reasonably straightforward to implement in a framework
that is closer to a brute force computational solution (MCMC, AD Model
Builder), but I wouldn't know where to begin trying to implement it in
the elegant/computationally efficient lme4 framework ...

  cheers
    Ben Bolker



From datkins at u.washington.edu  Thu Nov  4 16:59:12 2010
From: datkins at u.washington.edu (David Atkins)
Date: Thu, 04 Nov 2010 08:59:12 -0700
Subject: [R-sig-ME] sandwich variance estimation using glmer?
In-Reply-To: <C0772C7568B5374481D2F8A880E9BBDF06A64B7EC8@DC1EX07CMS.air.org>
References: <C0772C7568B5374481D2F8A880E9BBDF06A64B7EC8@DC1EX07CMS.air.org>
Message-ID: <4CD2D850.5050805@u.washington.edu>


One slightly different perspective on robust SE in mixed models:

The place where I have seen these used regularly is in the HLM software 
(popular in education and psychology circles).  HLM *always* reports 
both "standard" and robust SE.

What I find interesting is that if you read Raudenbush and Bryk (and the 
HLM manual), they suggest using the robust SE as a model diagnostic (my 
term).  That is, when there is a discrepancy between SE, they rightly 
note that something is amiss, and you should do further detective work 
related to the random-effects specification.

That seems like a very valid use of robust SE, though I fully 
acknowledge such info (ie, model isn't fitting well) could be got other 
ways.

[BTW, I'd love to see other robust approaches, such as t-distributed 
error and/or priors, but as Ben notes that's an awfully high bar to 
implement -- either in lmer or MCMCglmm.  The heavy package is an 
initial attempt, but seems to be "stalled out" at the moment.]

For what it's worth.

cheers, Dave


Harold wrote:

Let me push on this just a bit to spark further discussion. The OP was 
interested in robust standard errors given misspecification in the 
likelihood. So, one possible avenue was to explore Huber-White standard 
errors, or the sandwich estimator, to account for this misspecification 
and obtain "better" standard errors, but still use the point estimates 
of the fixed effects as given.

Some discussion on this has noted that the misspecification occurs in 
many ways, sometimes given that distributional assumptions were not met. 
Let's assume someone was willing and skilled to code up the HW as a 
possible solution within lmer to account for not meeting certain 
distributional assumptions.

My question is now why not directly code up models that permit for 
different distributional assumptions, such as t-distributions of 
residuals (random effects) or whatever the case might be? In other 
words, why not write code that addresses the problems directly 
(misspecification of the likelihood) rather than focusing on HW estimates.

Isn't it a better use of time and energy to focus on properly specifying 
the likelihood and estimating parameters from that model rather than HW?

-- 
Dave Atkins, PhD
Research Associate Professor
Department of Psychiatry and Behavioral Science
University of Washington
datkins at u.washington.edu

Center for the Study of Health and Risk Behaviors (CSHRB)		
1100 NE 45th Street, Suite 300 	
Seattle, WA  98105 	
206-616-3879 	
http://depts.washington.edu/cshrb/
(Mon-Wed)	

Center for Healthcare Improvement, for Addictions, Mental Illness,
   Medically Vulnerable Populations (CHAMMP)
325 9th Avenue, 2HH-15
Box 359911
Seattle, WA 98104
http://www.chammp.org
(Thurs)



From jpais.albany at gmail.com  Thu Nov  4 17:13:49 2010
From: jpais.albany at gmail.com (Jeremy Pais)
Date: Thu, 4 Nov 2010 12:13:49 -0400
Subject: [R-sig-ME] sandwich variance estimation using glmer?
In-Reply-To: <4CD2D850.5050805@u.washington.edu>
References: <C0772C7568B5374481D2F8A880E9BBDF06A64B7EC8@DC1EX07CMS.air.org>
	<4CD2D850.5050805@u.washington.edu>
Message-ID: <AANLkTinZypwqz5HiDa9nHJfu=qftS67O_abtxbu2B-ZV@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101104/8bad50f1/attachment.pl>

From bates at stat.wisc.edu  Thu Nov  4 18:40:27 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 4 Nov 2010 12:40:27 -0500
Subject: [R-sig-ME] Has anyone tried Whit Armstrong's CppMCMC library?
In-Reply-To: <AANLkTinLOeHqhLBAPGH8Q2McAw21Yc5aR_p+Rc0e+67=@mail.gmail.com>
References: <AANLkTimLkM41225GPO5MdwW5tPKu-6HMX9u2s2PtmomH@mail.gmail.com>
	<AANLkTimd5T=8ZibkRYzF1xH_Bm=FYnFhLGHgrY5kXDSC@mail.gmail.com>
	<AANLkTinLOeHqhLBAPGH8Q2McAw21Yc5aR_p+Rc0e+67=@mail.gmail.com>
Message-ID: <AANLkTinRpm1y=YbA8RZooP+cCjH92gqVZMteun8OM2Ke@mail.gmail.com>

One of the first things that I would change is to use the
RcppArmadillo plugin instead of the Rcpp plugin.  That way you can
have the inline package find the armadillo headers for you.  Long term
I would suggest creating a derived package RcppMCMC (or whatever name
seemed appropriate) and providing a plugin to the inline package so
that the headers and libraries do not need to be declared explicitly.

In using the C macros and functions REAL, Rf_nrows, ... you are
leaving yourself open to tromping on memory that doesn't belong to
you.  It is not too bad a risk when using the inline package because
you specify a signature.  However, if you build a more general package
and don't use inline then there is a risk that you will get something
passed that is not a numeric matrix.    I would go through the Rcpp
classes instead because they do all the checking of appropriate types
for you.

That is, I would rewrite the first line as

Rcpp::NumericMatrix x(XR);
mat X(x.begin(), x.nrows(), x.ncols(), false);

The false at the end of the constructor indicates that there is no
need to copy the storage.

And do you really need a matrix for y or is it suitable to use a
column vector?  Consider the following code from one of the examples
in the RcppArmadillo package

	Rcpp::NumericVector yr(ys);			// creates Rcpp vector from SEXP
	Rcpp::NumericMatrix Xr(Xs);			// creates Rcpp matrix from SEXP
	int n = Xr.nrow(), k = Xr.ncol();

	arma::mat X(Xr.begin(), n, k, false);   	// reuses memory and avoids extra copy
	arma::colvec y(yr.begin(), yr.size(), false);

	arma::colvec coef = arma::solve(X, y);      	// fit model y ~ X
	arma::colvec res = y - X*coef;			// residuals

On Wed, Nov 3, 2010 at 1:55 PM, Whit Armstrong <armstrong.whit at gmail.com> wrote:
> Below is a minimal example of a simple linear model using CppBugs,
> Rcpp, and inline.
>
> The cppbugs dir needs to be on the include path of the compiler for
> this example to work. ?Otherwise, you will need to change the #include
> statements to use the local path of your cppbugs install.
>
> Other dependencies you need are Armadillo and Boost.
>
> feedback welcome.
>
> -Whit
>
> require(inline)
> require(Rcpp)
>
> cppbugs.model <- '
> #include <armadillo>
> #include <cppbugs/cppbugs.hpp>
>
> using namespace arma;
> using namespace cppbugs;
>
> class TestModel: public MCModel {
> public:
> ?const mat& y; // given
> ?const mat& X; // given
>
> ?Stochastic<vec> b;
> ?Stochastic<double> tau_y;
> ?Deterministic<mat> y_hat;
> ?Stochastic<mat> likelihood;
> ?Deterministic<double> rsq;
>
> ?TestModel(const mat& y_,const mat& X_): y(y_),
> X(X_),b(randn<vec>(X_.n_cols)),tau_y(1),y_hat(X*b.value),likelihood(y_,true),rsq(0)
> ?{
> ? ?add(b);
> ? ?add(tau_y);
> ? ?add(y_hat);
> ? ?add(likelihood);
> ? ?add(rsq);
> ?}
>
> ?void update() {
> ? ?y_hat.value = X*b.value;
> ? ?rsq.value = as_scalar(1 - var(y - y_hat.value) / var(y));
> ? ?b.dnorm(0.0, 0.0001);
> ? ?tau_y.dunif(0,100);
> ? ?likelihood.dnorm(y_hat.value,tau_y.value);
> ?}
> };
> '
>
> src <- '
> mat X(REAL(XR),::Rf_nrows(XR),::Rf_ncols(XR));
> mat y(REAL(yr),::Rf_nrows(yr),::Rf_ncols(yr));
> int iterations_ = as<int>(iterations);
> int burn_ = as<int>(burn);
> int thin_ = as<int>(thin);
>
> TestModel m(y,X);
> m.sample(iterations_, burn_, thin_);
> return Rcpp::List::create(Rcpp::Named("b", m.b.mean()),
> Rcpp::Named("tau.y", m.tau_y.mean()), Rcpp::Named("ar",
> m.acceptance_ratio()), Rcpp::Named("rsq", m.rsq.mean()));
> '
>
> NR <- 100
> NC <- 2
> icept <- 10
> y = rnorm(NR,icept)
> X = matrix(rnorm(NR*NC),ncol=NC)
> X[,1] <- 1.0
> X[,2] <- y + - icept + rnorm(NR);
>
> bayes.reg <- cxxfunction(signature(XR="numeric",
> yr="numeric",iterations="integer",burn="integer",thin="integer"),
> body=src, include=cppbugs.model, plugin="Rcpp")
> ans <- bayes.reg(X,y,1e5L,1e4L,10L)
> print(ans)
>
>
> On Tue, Nov 2, 2010 at 1:02 PM, Whit Armstrong <armstrong.whit at gmail.com> wrote:
>> Thanks for the the post, Professor Bates.
>>
>> CppBugs can be found here: http://github.com/armstrtw/CppBugs
>>
>> It's a combination of WinBUGS and PyMC.
>>
>> The api is still very unstable as I'm attempting to navigate between
>> good design and maintaining familiar WinBUGS conventions.
>>
>> Rcpp is the best way to use it from R. ?I'll add an example of calling
>> it this way on the front page so that everyone can try it.
>>
>> My thinking is that since it's already very inconvenient to run a BUGS
>> model from R (writing the BUGS script, providing inits, passing data
>> back and forth), it's not really asking too much for users to write a
>> small c++ class inline in an R script that is the CppBugs equivalent
>> of a BUGS model.
>>
>> I'm very keen to have help on this project, so if anyone is interested
>> please contact me.
>>
>> I'll send a follow up post highlighting a few of the features of
>> CppBugs and examples of WinBUGS vs PyMC conventions that I've followed
>> in the design.
>>
>> -Whit
>>
>>
>>
>>
>> On Tue, Nov 2, 2010 at 11:08 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
>>> Whit Armstrong has written a C++ library called CppMCMC that provides
>>> BUGS-like functionality in compiled code. ?I see that one of his
>>> examples uses the contagious bovine pleuropneumonia data from the cbpp
>>> data set in the lme4 package, fitting an overdispersed binomial-like
>>> model to it.
>>>
>>> Does anyone have experience with these classes? ?This is not directly
>>> an R question as, at present, I don't know of a bridge between CppMCMC
>>> and R (although it would be an interesting project to use Rcpp for
>>> this).
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>



From mlarkin at rsmas.miami.edu  Thu Nov  4 22:22:35 2010
From: mlarkin at rsmas.miami.edu (Michael Larkin)
Date: Thu, 4 Nov 2010 17:22:35 -0400
Subject: [R-sig-ME] getting the residuals from the model
Message-ID: <000301cb7c66$66a949b0$33fbdd10$@miami.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101104/fcc018e6/attachment.pl>

From A.Robinson at ms.unimelb.edu.au  Thu Nov  4 23:06:13 2010
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Fri, 5 Nov 2010 09:06:13 +1100
Subject: [R-sig-ME] sandwich variance estimation using glmer?
In-Reply-To: <4CD2D850.5050805@u.washington.edu>
References: <C0772C7568B5374481D2F8A880E9BBDF06A64B7EC8@DC1EX07CMS.air.org>
	<4CD2D850.5050805@u.washington.edu>
Message-ID: <AANLkTinST_08oMguM6-B-Mgvw2s90aXrFkYKyu-poSGq@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101105/d043e095/attachment.pl>

From luciano.selzer at gmail.com  Fri Nov  5 00:07:36 2010
From: luciano.selzer at gmail.com (Luciano Selzer)
Date: Thu, 4 Nov 2010 20:07:36 -0300
Subject: [R-sig-ME] getting the residuals from the model
In-Reply-To: <000301cb7c66$66a949b0$33fbdd10$@miami.edu>
References: <Act8ZmZYEARSAWVwSduwcHV+Oz5H9w==>
	<000301cb7c66$66a949b0$33fbdd10$@miami.edu>
Message-ID: <AANLkTime9=w1m_oh6HnEDDXE1-Gcd2bk00c4fHi-sTr8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101104/2936ec9d/attachment.pl>

From datkins at u.washington.edu  Fri Nov  5 17:12:15 2010
From: datkins at u.washington.edu (David Atkins)
Date: Fri, 05 Nov 2010 09:12:15 -0700
Subject: [R-sig-ME] sandwich variance estimation using glmer?
In-Reply-To: <AANLkTinST_08oMguM6-B-Mgvw2s90aXrFkYKyu-poSGq@mail.gmail.com>
References: <C0772C7568B5374481D2F8A880E9BBDF06A64B7EC8@DC1EX07CMS.air.org>	<4CD2D850.5050805@u.washington.edu>
	<AANLkTinST_08oMguM6-B-Mgvw2s90aXrFkYKyu-poSGq@mail.gmail.com>
Message-ID: <4CD42CDF.1000600@u.washington.edu>


On 11/4/10 3:06 PM, Andrew Robinson wrote:
> That's an interesting point, Dave.  Surely, however, there are better
> model diagnostics?  By 'better' I mean more likely to pinpoint the
> source of lack of fit within a model?
>
> Personally I wouldn't rely on the concordance between robust and
> asymptotic SE as an indicator of model appropriateness.  I don't see how
> it adds anything important to the diagnostic process.
>
> 1) if the match is bad, I'll examine the diagnostics, but
>
> 2) if the match is good, I'll examine the diagnostics anyway, as part of
> due diligence.

Andrew--

You are, of course, absolutely correct.  I use R almost exclusively, and 
for the most part, not having robust SE doesn't really cause any 
problems for me (in general, or with respect to checking diagnostics... 
actually, I love it!).

 From my own experience, I have seen the HLM's software use of both be 
helpful in the following way: I have several times had colleagues / 
students come to me with output from HLM, noting the discrepancy between 
SE and wondering what this means?  In essence, b/c that software puts 
both of them in front of you, it's hard to miss when they are different 
(esp. since p-values will then be radically different).

These times tend to be "teachable moments" in terms of what it is saying 
about the model and data (and fit).  More often that not, the outcome 
has been some form of count variable (which lurk quite commonly in 
psychological/psychiatric waters), and thus we can talk about 
distributional properties of the outcome vs. model, etc. (And I think 
the mean-variance relationship of the Poisson tends to lead to large 
adjustments with the robust SE.)

I would in no way suggest that lme4 should follow suit with the HLM 
software, and I honestly doubt whether it would serve a similar purpose, 
as more novice statistical users tend to be intimidated by R (given lack 
of menus, GUI, etc.).

As I mentioned before, what I *would* be interested in are robust 
approaches a la incorporating t-distribution in prior or likelihood.  I 
am currently working with a colleague on an analysis of a small number 
of groups, where we have discused this -- he's exploring WinBUGS as an 
option at present (to follow-up on our analyses with glmer and MCMCglmm).

For what it's worth (and realizing it ain't all that much about R...).

cheers, Dave


>
> Also I don't know of any theory that suggests that deviation between
> robust and asymptotic standard error estimates *always* indicates a
> model problem.  If anyone does, I'm happy to learn about it.
>
> On the other hand, robust SE are (likely to be) larger than asymptotic
> SE.  So, if I see a deviation, it could be because (a) there's a problem
> with my model, and (b) the model is fine but I'm paying a price for
> robustness.
>
> All of which raises an interesting question: if we observe a deviation
> between the estimate and hunt through the model diagnostics to find a
> cause, but can't --- then what do we do?
>
> Cheers
>
> Andrew
>
>
> On Fri, Nov 5, 2010 at 2:59 AM, David Atkins <datkins at u.washington.edu
> <mailto:datkins at u.washington.edu>> wrote:
>
>
>     One slightly different perspective on robust SE in mixed models:
>
>     The place where I have seen these used regularly is in the HLM
>     software (popular in education and psychology circles).  HLM
>     *always* reports both "standard" and robust SE.
>
>     What I find interesting is that if you read Raudenbush and Bryk (and
>     the HLM manual), they suggest using the robust SE as a model
>     diagnostic (my term).  That is, when there is a discrepancy between
>     SE, they rightly note that something is amiss, and you should do
>     further detective work related to the random-effects specification.
>
>     That seems like a very valid use of robust SE, though I fully
>     acknowledge such info (ie, model isn't fitting well) could be got
>     other ways.
>
>     [BTW, I'd love to see other robust approaches, such as t-distributed
>     error and/or priors, but as Ben notes that's an awfully high bar to
>     implement -- either in lmer or MCMCglmm.  The heavy package is an
>     initial attempt, but seems to be "stalled out" at the moment.]
>
>     For what it's worth.
>
>     cheers, Dave
>
>
>
>     Harold wrote:
>
>     Let me push on this just a bit to spark further discussion. The OP
>     was interested in robust standard errors given misspecification in
>     the likelihood. So, one possible avenue was to explore Huber-White
>     standard errors, or the sandwich estimator, to account for this
>     misspecification and obtain "better" standard errors, but still use
>     the point estimates of the fixed effects as given.
>
>     Some discussion on this has noted that the misspecification occurs
>     in many ways, sometimes given that distributional assumptions were
>     not met. Let's assume someone was willing and skilled to code up the
>     HW as a possible solution within lmer to account for not meeting
>     certain distributional assumptions.
>
>     My question is now why not directly code up models that permit for
>     different distributional assumptions, such as t-distributions of
>     residuals (random effects) or whatever the case might be? In other
>     words, why not write code that addresses the problems directly
>     (misspecification of the likelihood) rather than focusing on HW
>     estimates.
>
>     Isn't it a better use of time and energy to focus on properly
>     specifying the likelihood and estimating parameters from that model
>     rather than HW?
>
>     --
>     Dave Atkins, PhD
>     Research Associate Professor
>     Department of Psychiatry and Behavioral Science
>     University of Washington
>     datkins at u.washington.edu <mailto:datkins at u.washington.edu>
>
>     Center for the Study of Health and Risk Behaviors (CSHRB)
>     1100 NE 45th Street, Suite 300
>     Seattle, WA  98105
>     206-616-3879
>     http://depts.washington.edu/cshrb/
>     (Mon-Wed)
>
>     Center for Healthcare Improvement, for Addictions, Mental Illness,
>       Medically Vulnerable Populations (CHAMMP)
>     325 9th Avenue, 2HH-15
>     Box 359911
>     Seattle, WA 98104
>     http://www.chammp.org
>     (Thurs)
>
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
>
> --
> Andrew Robinson
> Program Manager, ACERA
> Senior Lecturer in Applied Statistics                      Tel:
> +61-3-8344-6410
> Department of Mathematics and Statistics            Fax: +61-3-8344 4599
> University of Melbourne, VIC 3010 Australia
> Email: a.robinson at ms.unimelb.edu.au
> <mailto:a.robinson at ms.unimelb.edu.au>    Website:
> http://www.ms.unimelb.edu.au
>
>



From bbolker at gmail.com  Fri Nov  5 17:25:16 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 05 Nov 2010 12:25:16 -0400
Subject: [R-sig-ME] t-distributed residuals [was Re: sandwich variance
 estimation using glmer?]
In-Reply-To: <4CD42CDF.1000600@u.washington.edu>
References: <C0772C7568B5374481D2F8A880E9BBDF06A64B7EC8@DC1EX07CMS.air.org>	<4CD2D850.5050805@u.washington.edu>	<AANLkTinST_08oMguM6-B-Mgvw2s90aXrFkYKyu-poSGq@mail.gmail.com>
	<4CD42CDF.1000600@u.washington.edu>
Message-ID: <4CD42FEC.20102@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 10-11-05 12:12 PM, David Atkins wrote:
> 
> On 11/4/10 3:06 PM, Andrew Robinson wrote:
>> That's an interesting point, Dave.  Surely, however, there are better
>> model diagnostics?  By 'better' I mean more likely to pinpoint the
>> source of lack of fit within a model?
>>
>> Personally I wouldn't rely on the concordance between robust and
>> asymptotic SE as an indicator of model appropriateness.  I don't see how
>> it adds anything important to the diagnostic process.
>>
>> 1) if the match is bad, I'll examine the diagnostics, but
>>
>> 2) if the match is good, I'll examine the diagnostics anyway, as part of
>> due diligence.
> 
> Andrew--
> 
> You are, of course, absolutely correct.  I use R almost exclusively, and
> for the most part, not having robust SE doesn't really cause any
> problems for me (in general, or with respect to checking diagnostics...
> actually, I love it!).
> 
> From my own experience, I have seen the HLM's software use of both be
> helpful in the following way: I have several times had colleagues /
> students come to me with output from HLM, noting the discrepancy between
> SE and wondering what this means?  In essence, b/c that software puts
> both of them in front of you, it's hard to miss when they are different
> (esp. since p-values will then be radically different).
> 
> These times tend to be "teachable moments" in terms of what it is saying
> about the model and data (and fit).  More often that not, the outcome
> has been some form of count variable (which lurk quite commonly in
> psychological/psychiatric waters), and thus we can talk about
> distributional properties of the outcome vs. model, etc. (And I think
> the mean-variance relationship of the Poisson tends to lead to large
> adjustments with the robust SE.)
> 
> I would in no way suggest that lme4 should follow suit with the HLM
> software, and I honestly doubt whether it would serve a similar purpose,
> as more novice statistical users tend to be intimidated by R (given lack
> of menus, GUI, etc.).
> 
> As I mentioned before, what I *would* be interested in are robust
> approaches a la incorporating t-distribution in prior or likelihood.  I
> am currently working with a colleague on an analysis of a small number
> of groups, where we have discused this -- he's exploring WinBUGS as an
> option at present (to follow-up on our analyses with glmer and MCMCglmm).
> 
> For what it's worth (and realizing it ain't all that much about R...).
> 

  Channeling Dave Fournier here for a few moments ...

  For that particular project, I would recommend that you give AD Model
Builder and (to plug my own project and make things a little more R-ish)
the R2ADMB package a try. AD Model Builder is fast, flexible, uses
Laplace approximation for mixed modeling, and allows you to do post-hoc
MCMC sampling around the estimated modes; changing from a Gaussian to
t-distributed residual/likelihood calculations is in principle just a
matter of adding a parameter and changing the line of code that does the
likelihood calculation.  And ADMB is now open source.
  The downside is that you have to learn a new system (objective
functions in ADMB are written in a superset of C++). Overall I would say
that the effort, and the payoff, of learning ADMB are on the same order
of magnitude as learning WinBUGS/JAGS ...

  Ben Bolker
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iEYEARECAAYFAkzUL+wACgkQc5UpGjwzenPStQCglIPjBsjlEFsea5CjUFugaIFW
q7sAn1M78DGVTEctM/VETxBu/HdrrDj6
=fTTC
-----END PGP SIGNATURE-----



From armstrong.whit at gmail.com  Fri Nov  5 18:23:50 2010
From: armstrong.whit at gmail.com (Whit Armstrong)
Date: Fri, 5 Nov 2010 13:23:50 -0400
Subject: [R-sig-ME] t-distributed residuals [was Re: sandwich variance
 estimation using glmer?]
In-Reply-To: <4CD42FEC.20102@gmail.com>
References: <C0772C7568B5374481D2F8A880E9BBDF06A64B7EC8@DC1EX07CMS.air.org>
	<4CD2D850.5050805@u.washington.edu>
	<AANLkTinST_08oMguM6-B-Mgvw2s90aXrFkYKyu-poSGq@mail.gmail.com>
	<4CD42CDF.1000600@u.washington.edu> <4CD42FEC.20102@gmail.com>
Message-ID: <AANLkTimBVjh-SBO2ngb+f4FXB2b8E+TVm0pVy0nFLhFz@mail.gmail.com>

Do you have a winbugs example of the model you would like to fit?

If it is as simple as using a t-dist prior for your coefficients, then
it's pretty simple to do that in winbugs or PyMC.

Of course I'd like to plug my own project which is a c++ equivalent of
winbugs, now directly callable from R via inline.

I'm happy to translate a winbugs model and post the cppbugs equivalent.

-Whit


On Fri, Nov 5, 2010 at 12:25 PM, Ben Bolker <bbolker at gmail.com> wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 10-11-05 12:12 PM, David Atkins wrote:
>>
>> On 11/4/10 3:06 PM, Andrew Robinson wrote:
>>> That's an interesting point, Dave. ?Surely, however, there are better
>>> model diagnostics? ?By 'better' I mean more likely to pinpoint the
>>> source of lack of fit within a model?
>>>
>>> Personally I wouldn't rely on the concordance between robust and
>>> asymptotic SE as an indicator of model appropriateness. ?I don't see how
>>> it adds anything important to the diagnostic process.
>>>
>>> 1) if the match is bad, I'll examine the diagnostics, but
>>>
>>> 2) if the match is good, I'll examine the diagnostics anyway, as part of
>>> due diligence.
>>
>> Andrew--
>>
>> You are, of course, absolutely correct. ?I use R almost exclusively, and
>> for the most part, not having robust SE doesn't really cause any
>> problems for me (in general, or with respect to checking diagnostics...
>> actually, I love it!).
>>
>> From my own experience, I have seen the HLM's software use of both be
>> helpful in the following way: I have several times had colleagues /
>> students come to me with output from HLM, noting the discrepancy between
>> SE and wondering what this means? ?In essence, b/c that software puts
>> both of them in front of you, it's hard to miss when they are different
>> (esp. since p-values will then be radically different).
>>
>> These times tend to be "teachable moments" in terms of what it is saying
>> about the model and data (and fit). ?More often that not, the outcome
>> has been some form of count variable (which lurk quite commonly in
>> psychological/psychiatric waters), and thus we can talk about
>> distributional properties of the outcome vs. model, etc. (And I think
>> the mean-variance relationship of the Poisson tends to lead to large
>> adjustments with the robust SE.)
>>
>> I would in no way suggest that lme4 should follow suit with the HLM
>> software, and I honestly doubt whether it would serve a similar purpose,
>> as more novice statistical users tend to be intimidated by R (given lack
>> of menus, GUI, etc.).
>>
>> As I mentioned before, what I *would* be interested in are robust
>> approaches a la incorporating t-distribution in prior or likelihood. ?I
>> am currently working with a colleague on an analysis of a small number
>> of groups, where we have discused this -- he's exploring WinBUGS as an
>> option at present (to follow-up on our analyses with glmer and MCMCglmm).
>>
>> For what it's worth (and realizing it ain't all that much about R...).
>>
>
> ?Channeling Dave Fournier here for a few moments ...
>
> ?For that particular project, I would recommend that you give AD Model
> Builder and (to plug my own project and make things a little more R-ish)
> the R2ADMB package a try. AD Model Builder is fast, flexible, uses
> Laplace approximation for mixed modeling, and allows you to do post-hoc
> MCMC sampling around the estimated modes; changing from a Gaussian to
> t-distributed residual/likelihood calculations is in principle just a
> matter of adding a parameter and changing the line of code that does the
> likelihood calculation. ?And ADMB is now open source.
> ?The downside is that you have to learn a new system (objective
> functions in ADMB are written in a superset of C++). Overall I would say
> that the effort, and the payoff, of learning ADMB are on the same order
> of magnitude as learning WinBUGS/JAGS ...
>
> ?Ben Bolker
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.10 (GNU/Linux)
> Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/
>
> iEYEARECAAYFAkzUL+wACgkQc5UpGjwzenPStQCglIPjBsjlEFsea5CjUFugaIFW
> q7sAn1M78DGVTEctM/VETxBu/HdrrDj6
> =fTTC
> -----END PGP SIGNATURE-----
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From pauljohn32 at gmail.com  Sun Nov  7 06:00:14 2010
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Sun, 7 Nov 2010 00:00:14 -0500
Subject: [R-sig-ME] IRT: discrimination parameters from LMER?
In-Reply-To: <C0772C7568B5374481D2F8A880E9BBDF06A64B7A9C@DC1EX07CMS.air.org>
References: <AANLkTi=GRoe0-AXFbOiw6x_W95J_j5+rXek-OnoR9CwZ@mail.gmail.com>
	<C0772C7568B5374481D2F8A880E9BBDF06A650CA1B@DC1EX07CMS.air.org>
	<AANLkTikzXr=KkDzHRUhPW_s+E7u_yf3N3A0d3EXpG=Qj@mail.gmail.com>
	<C0772C7568B5374481D2F8A880E9BBDF06A64B7A9C@DC1EX07CMS.air.org>
Message-ID: <AANLkTik7jc+j8aJnv0cnH5F-caBKdB7Os8bOcRTNsJYW@mail.gmail.com>

Dear Harold.

Thanks for the example.  I've not heard of MiscPsycho before, that's
interesting.

Your test case focuses on difficulty parameters, and that's not where
I'm seeing trouble.  I agree with you difficulty estimates match the
fixed effects from lmer.

The discrimination estimate from ltm compared against lmer's random
effect estimate is my concern.  If the discrimination parameter is not
1.0, then I wonder if your argument holds up.  In that one simulation
I reported last time, I saw pretty big difference.

I'm adapting your simulation to do a lot of data sets.

But I can't amaze you with my result now because of this weird kernel
error I've never seen before, so I think I need to close everything
down. But I'll get back to you.


>   fm1 <- rasch(itemDat[, -21], IRT.param=F)
OMP: Error #15: Initializing libguide.so, but found libguide.so
already initialized.
OMP: Hint: This may cause performance degradation and correctness
issues. Set environment variable KMP_DUPLICATE_LIB_OK=TRUE to ignore
this problem and force the program to continue anyway. Please note
that the use of KMP_DUPLICATE_LIB_OK is unsupported and using it may
cause undefined behavior. For more information, please contact
Intel(R) Premier Support.


Weird, huh?

pj


> I don't think this is true necessarily. I've done a small experiment all reproducible code is at bottom of email. I simulate some rasch data and then estimate item parameters using ltm, lmer, jml (in MiscPsycho), and mml (a function I wrote that is below using the traditional mml methods). To make a long story short, I compute the bias under each model.
>
>> ### ltm bias
>> mean((coef(fm1)[,1] - mean(coef(fm1)[,1])) - trueVals)
> [1] -0.173386111948639
>>
>> ### lmer bias
>> mean((fixef(fm2) - mean(fixef(fm2))) - trueVals)
> [1] -0.173386111948639
>>
>> ### jml bias
>> mean(coef(fm1) - trueVals)
> [1] 0.39007242168395
>>
>> ### mml bias
>> mean((coef(fm4)[1:20] - mean(coef(fm4)[1:20])) - trueVals)
> [1] -0.173386111948639
>
> It seems to me that jml (as expected) performs the worst, but all other functions are comparable and seem to recover parameter estimates rather well. If you run the mml function below, it is slow. But, notice that the standard deviation in mml is exactly the same as what lmer gives. That is because a multilevel rasch model with the parameterization I have used (items as fixed respondents as random) is exactly the same as mml. But, lmer's capacity can go much, much further. Had I not constrained the ltm function to have a discrimination of 1, the common discrimination parameter would also be the sd given by mml and lmer.
>
>> Do you care to weigh in on the question of whether lmer could ever be
>> made to fit a 2PL or 3PL model? ?I mean, could I write a family for
>> lmer that would do that, or is the calculation required too grossly
>> different?
>
> Yes, I'm sure it can. The issue is who will write the code. Doug Bates is extremely generous with his help and his openness to others making contributions to lme4. But, (as he might do so on this thread), he will forewarn you that the underlying code in lmer is very complex and doesn't resemble methods commonly used in other packages. So, because Doug is so amazingly smart, and I am just a mortal, I have decided to steer away from contributing to lmer other than being a "toy tester" for Doug.
>
> I am not a fan of the 3PL for many reasons. First, it is a model that cannot be identified without putting a very slim prior on the guessing parameter. In the end, because the prior is so slim, guess what your parameter estimates are close to? Yes, the prior. So, I just have never been made comfortable with that.
>
>> If 2PL or 3PL is really a whole different structure, I don't mind
>> using "ltm." ?But defeats the ideal that you proposed in that 2007 JSS
>> article (which I really like!), that we might be better off fitting
>> specialized models with general purpose software.
>
> I think ltm is a really great package. It may have some capacity to do what you want, I don't fully know its capacities. Perhaps Dimitris can offer some thought.
>
>> Here's a similar example. ?Sometimes I have wanted to fit ordinal
>> dependent variables, and have learned that those models do not fall
>> into the family of GLM and a tool different from lmer is necessary to
>> work on them. ? I wish it weren't so, but have accepted reality.
>>
>> pj
>
> This is very true. I have been doing some work on polytomous models, but am working very slowly on functions to estimate them. There are packages in R that can currently do this. I wonder if MCMCglmm can do it; I don't know.
>
>
> library(ltm)
> library(lmer)
> library(MiscPsycho)
>
> Nitems <- 20
> Nperson <- 500
>
> set.seed(12345)
> dat <- simRasch(Nperson, Nitems)
> itemDat <- dat$data
>
> ### Fit data using rasch in LTM
> fm1 <- rasch(itemDat, constraint = cbind(ncol(itemDat) + 1, 1))
>
> ### Fit using lmer
> itemDat$id <- 1:nrow(itemDat)
> ### reshape into long format
> testScores <- reshape(itemDat, idvar='id', varying=list(names(itemDat)[1:Nitems]), v.names=c('answer'), timevar='question', direction='long')
>
> # Treat items as fixed but students as random
> fm2 <- lmer(answer ~ factor(question) - 1 + (1|id), testScores, family = binomial(link='logit'))
>
>
> ### Fit using JML
> fm3 <- jml(dat$data, bias=TRUE)
>
> ### Fit using mml function below
> fm4 <- mml(dat$data, Q =10, startVal = coef(fm1)[,1])
>
> ### Compute bias
> trueVals <- dat$gen
>
> ### ltm bias
> mean((coef(fm1)[,1] - mean(coef(fm1)[,1])) - trueVals)
>
> ### lmer bias
> mean((fixef(fm2) - mean(fixef(fm2))) - trueVals)
>
> ### jml bias
> mean(coef(fm1) - trueVals)
>
> ### mml bias
> mean((coef(fm4)[1:20] - mean(coef(fm4)[1:20])) - trueVals)
>
>
>
> mml <- function(data, Q, startVal = NULL, ...){
> ? ? ? ?if(!is.null(startVal) && length(startVal) != ncol(data) ){
> ? ? ? ? ? ? ? ?stop("Length of argument startVal not equal to the number of parameters estimated")
> ? ? ? ?}
> ? ? ? ?if(!is.null(startVal)){
> ? ? ? ? ? ? ? ?startVal <- startVal
> ? ? ? ? ? ? ? ?} else {
> ? ? ? ? ? ? ? ?p <- colMeans(data)
> ? ? ? ? ? ? ? ?startVal <- as.vector(log((1 - p)/p))
> ? ? ? ?}
> ? ? ? ?qq <- gauss.quad.prob(Q, dist = 'normal', mu = 0, sigma=1)
> ? ? ? ?rr1 <- matrix(0, nrow = Q, ncol = nrow(data))
> ? ? ? ?data <- as.matrix(data)
> ? ? ? ?L <- nrow(data)
> ? ? ? ?C <- ncol(data)
> ? ? ? ?u <- 0
> ? ? ? ?fn <- function(b){
> ? ? ? ?s <- b[C+1]
> ? ? ? ?b <- b[1:C]
> ? ? ? ? ? ? ? ?for(j in 1:Q){
> ? ? ? ? ? ? ? ? ? ? ? ?for(i in 1:L){
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?rr1[j,i] <- exp(sum(dbinom(data[i,], 1, plogis(qq$nodes[j]-b), log = TRUE))) *
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?((1/(s*sqrt(2*pi))) ?* exp(-((qq$nodes[j]-u)^2/(2*s^2))))/dnorm(qq$nodes[j]) * qq$weights[j]
> ? ? ? ? ? ? ? ? ? ? ? ?}
> ? ? ? ? ? ? ? ?}
> ? ? ? ?-sum(log(colSums(rr1)))
> ? ? ? ?}
> ? ? ? ?opt <- optim(c(startVal,1), fn, method = "BFGS", hessian = TRUE)
> ? ? ? ?list("coefficients" = opt$par, "LogLik" = -opt$value, "Std.Error" = sqrt(diag(solve(opt$hessian))))
> }
>



-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas



From bates at stat.wisc.edu  Sun Nov  7 18:38:44 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 7 Nov 2010 11:38:44 -0600
Subject: [R-sig-ME] I am liable to be slow to respond to email during the
	next two weeks
Message-ID: <AANLkTiniUt+4ZiWBZmjN=oTTx_iFA6pKrm5sYkZ2YRaX@mail.gmail.com>

Due to my usual meticulous planning (I'm being sarcastic there) I have
major assignments, reports, oral and written exams and proposals all
coming in to be graded during the next two weeks.  It is unlikely I
that I will have much time to respond to email on various R-related
lists until the week of American Thanksgiving (week of November 21).



From frocga at gmail.com  Sun Nov  7 17:14:58 2010
From: frocga at gmail.com (Shawn McCracken)
Date: Sun, 7 Nov 2010 16:14:58 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?Questions_-_next_steps_in_GLMM_analysis_on_n?=
	=?utf-8?q?ested=09ecological_dataset?=
References: <C8F7B4E6.1688C%smccracken@tadpoleorg.org>
Message-ID: <loom.20101107T171016-518@post.gmane.org>

Shawn McCracken <smccracken at ...> writes:

> 
> Dear Mixed-models group,
> 
> I am working with a dataset containing fixed and nested random effects. I
> have
> one fixed effect that I am most interested in and the others were collected
> to
> see if they also might have an influence. I apologize for the novel but
> hopefully discussion of this will help others in the future who are as
> intimidated as I was/am.
> 
> The data consist of total counts of anuran individuals from a particular
> species
> of epiphytic phytotelm plant found in tree canopies at two sites. The site
> difference (if any) is my main interest. At each site all trees with
> suitable
> #?s of this epiphyte species for sampling were located within a
> predetermined
> size area. 16 trees were randomly selected from those available at each site
> and
> 5 epiphytes were then randomly sampled for all anurans within them. So, 2
> sites
> -> 16 trees (at each site) -> 5 epiphytes (in each tree), which equals 80
> samples from each site for a total of 160........................
> 	[[alternative HTML version deleted]]
> 
> 

Update: The install problem with glmmADMB has been fixed on my Mac. Thanks to
Dave. Details below. I could still use some feedback on what I have done so far
still.

The solution that worked for me:

I used the binaries Dave sent in admbfiles.zip over in the post in the
admb-users group: http://groups.google.com/group/admb-users/t/df5779586e45b9b
 
First, I copied them to my desktop and unzipped.
Opened Terminal and typed the following to direct it to run nbmm in the expanded
folder and confirm it would run:

ShawnMBP:$ /Users/Shawn/Desktop/admbfiles/nbmm     #of course you will need to
change this to navigate to where it is on your computer#
Error trying to open data input file /users/shawn/desktop/admbfiles/nbmm.dat
 Error trying to read in model data
 This is usual caused by a missing DAT file

Dave said the error message comes from ndmm looking for the data file to use but
it is running.

I then located where glmmADMB had originally placed these same named files when
I did the install of glmmADMB. I can?t remember how I found where they were and
spotlight won?t show them either. I think I did a search just for ?R? and found
an R.framework folder in the Library folder. I looked through there and found
them in a folder called admb here:

MBP_SFM>Library>Frameworks>R.framework>Versions>2.11>Resources>library>glmmADMB>
admb

I then replaced the nbmm and bvprobit files that were there with the ones
provided by Dave.
Started up R, loaded glmmADMB, viewed the epil2 dataset, and then ran the
example model and it ran fine!

My system: Macbook Pro, Mac OSX 10.6.4, R 64-bit

Hope this helps.

Shawn



From bbolker at gmail.com  Sun Nov  7 19:42:12 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 07 Nov 2010 13:42:12 -0500
Subject: [R-sig-ME] Questions - next steps in GLMM analysis on nested
 ecological dataset
In-Reply-To: <loom.20101107T171016-518@post.gmane.org>
References: <C8F7B4E6.1688C%smccracken@tadpoleorg.org>
	<loom.20101107T171016-518@post.gmane.org>
Message-ID: <4CD6F304.5080202@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 10-11-07 11:14 AM, Shawn McCracken wrote:
> Shawn McCracken <smccracken at ...> writes:
> 
>>
>> Dear Mixed-models group,
>>
>> I am working with a dataset containing fixed and nested random effects. I
>> have
>> one fixed effect that I am most interested in and the others were collected
>> to
>> see if they also might have an influence. I apologize for the novel but
>> hopefully discussion of this will help others in the future who are as
>> intimidated as I was/am.
>>
>> The data consist of total counts of anuran individuals from a particular
>> species
>> of epiphytic phytotelm plant found in tree canopies at two sites. The site
>> difference (if any) is my main interest. At each site all trees with
>> suitable
>> #?s of this epiphyte species for sampling were located within a
>> predetermined
>> size area. 16 trees were randomly selected from those available at each site
>> and
>> 5 epiphytes were then randomly sampled for all anurans within them. So, 2
>> sites
>> -> 16 trees (at each site) -> 5 epiphytes (in each tree), which equals 80
>> samples from each site for a total of 160........................
>> 	[[alternative HTML version deleted]]
>>
>>
> 
> Update: The install problem with glmmADMB has been fixed on my Mac. Thanks to
> Dave. Details below. I could still use some feedback on what I have done so far
> still.
> 

  Update: I have been working on the glmmADMB package a bit.  The
current version on R-forge installs OK on my MacOS X.6 machine. It
contains 32-bit binaries which it automatically puts in the correct
location, so that you shouldn't have to mess around with doing this
stuff manually.  Dave F. has sent me compiled 64-bit OS X binaries, but
I haven't gotten around to incorporating them yet (the 32-bit binaries
do work on my system, although presumably the 64-bit ones would be
faster in general).
  So
  install.packages("glmmADMB",repos="http://r-forge.r-project.org")
should work on MacOS.
  It would be helpful to get reports of trouble from list members who
try it.

  To follow up on some of your other questions with my own opinions:
* as I recommend on <http://glmm.wikidot.com/faq> (I have just added a
few words to make my personal opinions clearer), I would recommend
glmm.admb or glmer with individual-level random effects over the various
quasi- options.
 * glmm.admb currently only works with a single random effect, so you
can't do nested random effects that way.  You could build a more
complete model in AD Model Builder, or revert to glmer.
 * Your model specification

m1po<-lmer(count~treat+treedbh+treehgt+numepi+elevepi+hgtepi+leafepi+
(1|tree/epi),family=poisson,data=ecpad2)

  looks reasonable.  If you say
ecpad2$indiv <- 1:nrow(ecpad2)
and add +(1|indiv) to your model specification you will have an
individual-level random effect.

 * Is 'treat' your site variable?  In any case, if you are trying to do
a statistical comparison between only two sites you have a major
pseudo-replication problem (Hurlbert 1984).

  * The p-values that you get from summary(lmer) are Wald Z statistics,
they assume large data sets and are possibly unreliable for
moderate-sized data sets ...

 * Opinions differ on the value of backward stepwise model reduction. It
is standard practice in many ecological contexts and is suggested for
moderate model complexity by many respected practicing
(eco)statisticians (Bates, Wood, Zuur ...) but is vehemently decried by
others (Harrell).  I would probably base inference on your full model
rather than doing backward elimination.


> The solution that worked for me:
> 
> I used the binaries Dave sent in admbfiles.zip over in the post in the
> admb-users group: http://groups.google.com/group/admb-users/t/df5779586e45b9b
>  
> First, I copied them to my desktop and unzipped.
> Opened Terminal and typed the following to direct it to run nbmm in the expanded
> folder and confirm it would run:
> 
> ShawnMBP:$ /Users/Shawn/Desktop/admbfiles/nbmm     #of course you will need to
> change this to navigate to where it is on your computer#
> Error trying to open data input file /users/shawn/desktop/admbfiles/nbmm.dat
>  Error trying to read in model data
>  This is usual caused by a missing DAT file
> 
> Dave said the error message comes from ndmm looking for the data file to use but
> it is running.
> 
> I then located where glmmADMB had originally placed these same named files when
> I did the install of glmmADMB. I can?t remember how I found where they were and
> spotlight won?t show them either. I think I did a search just for ?R? and found
> an R.framework folder in the Library folder. I looked through there and found
> them in a folder called admb here:
> 
> MBP_SFM>Library>Frameworks>R.framework>Versions>2.11>Resources>library>glmmADMB>
> admb
> 
> I then replaced the nbmm and bvprobit files that were there with the ones
> provided by Dave.
> Started up R, loaded glmmADMB, viewed the epil2 dataset, and then ran the
> example model and it ran fine!
> 
> My system: Macbook Pro, Mac OSX 10.6.4, R 64-bit
> 
> Hope this helps.
> 
> Shawn
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iEYEARECAAYFAkzW8wMACgkQc5UpGjwzenN0DACeNN/OmJf0UK9hSOtTt8DmPcdB
vHwAmwXH6qKTOwT9snxDsDgldVm6hzVO
=4NDD
-----END PGP SIGNATURE-----



From john.maindonald at anu.edu.au  Mon Nov  8 01:17:12 2010
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Mon, 8 Nov 2010 11:17:12 +1100
Subject: [R-sig-ME] Questions - the stepwise selection issue.
In-Reply-To: <4CD6F304.5080202@gmail.com>
References: <C8F7B4E6.1688C%smccracken@tadpoleorg.org>
	<loom.20101107T171016-518@post.gmane.org>
	<4CD6F304.5080202@gmail.com>
Message-ID: <8FA236D4-4484-488B-A064-0699801A97B6@anu.edu.au>

The stepwise model reduction issue is an interesting one.

My view is that:
1) One should always begin by looking at the t-statistics for
the coeffs in the full model (assuming that this is a situation
where they are more or less believable!).  If there is a clear
division into those that are significant and those that are
clearly not significant (p-value > 0.1, maybe), then drop
those that are not significant.  Check what difference this
makes to the residual SE, and to the coefficients (any large
changes may matter if there is an interest in interpreting 
coefficients).  There are other issues to consider; are some
variables of such scientific consequence that they should
be retained regardless?

2) Backwise stepwise selection or (better) exhaustive 
subset selection if the problem is not too large are a resort
of desperation if some variant of (1) fails to give a useful
result.  The approach (1) is most likely to fail to give a useful 
result in cases where there is quite a large number of 
explanatory variables, exactly the situation where variable 
selection bias becomes a serious issue.  The function
bestsetNoise() in the DAAG package is designed to make
it easy to experiment with variable selection effects for
data that are purely noise.  For getting realistic SEs, some
alternatives are:
  a) repeat the whole analysis, selection and all, with repeated 
  bootstrap samples;
  b) get SEs by repeated bootstrap sampling from 'test' data.
  c) simulate, with selection and all, from the fitted model.
For both a) and c) one has to deal with getting somewhat
different selections each time round (that is itself instructive).

3) If the approach (2) has been used, and there is interest
in the interpretation of coefficients, check the coefficients
against those from the full model.  Any large changes will
ring a warning bell for attempts to interpret them.

4) One possibility, following stepwise or other selection,
is that one or more p-values may be so small that they are
very unlikely to be an artefact of the selection process.
In general, a simulation will be required, in order to be
sure.

Somewhat casual approaches to the use of backward (or
other) stepwise selection may be a holdover from hand
calculator days, or times when computers grunted somewhat
to handle even modest sized calculations.  If the inclusion and
exclusion criteria are suitably chosen (but who really knows
what is suitable?), I suspect that in some contexts they do
more or less work to give believable answers, without undue
selection bias.  But how, without checks such as I have noted,
can one be sure?  This may be one of the murky dark alleys
of statistical practice, where magic incantations and hope too 
often prevail over hard evidence.

It would be useful to find a review paper that covers this 
ground systematically and incisively, without undue reliance 
on specific examples.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 08/11/2010, at 5:42 AM, Ben Bolker wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
> 
> On 10-11-07 11:14 AM, Shawn McCracken wrote:
>> Shawn McCracken <smccracken at ...> writes:
>> 
>>> 
>>> Dear Mixed-models group,
>>> 
>>> I am working with a dataset containing fixed and nested random effects. I
>>> have
>>> one fixed effect that I am most interested in and the others were collected
>>> to
>>> see if they also might have an influence. I apologize for the novel but
>>> hopefully discussion of this will help others in the future who are as
>>> intimidated as I was/am.
>>> 
>>> The data consist of total counts of anuran individuals from a particular
>>> species
>>> of epiphytic phytotelm plant found in tree canopies at two sites. The site
>>> difference (if any) is my main interest. At each site all trees with
>>> suitable
>>> #?s of this epiphyte species for sampling were located within a
>>> predetermined
>>> size area. 16 trees were randomly selected from those available at each site
>>> and
>>> 5 epiphytes were then randomly sampled for all anurans within them. So, 2
>>> sites
>>> -> 16 trees (at each site) -> 5 epiphytes (in each tree), which equals 80
>>> samples from each site for a total of 160........................
>>> 	[[alternative HTML version deleted]]
>>> 
>>> 
>> 
>> Update: The install problem with glmmADMB has been fixed on my Mac. Thanks to
>> Dave. Details below. I could still use some feedback on what I have done so far
>> still.
>> 
> 
>  Update: I have been working on the glmmADMB package a bit.  The
> current version on R-forge installs OK on my MacOS X.6 machine. It
> contains 32-bit binaries which it automatically puts in the correct
> location, so that you shouldn't have to mess around with doing this
> stuff manually.  Dave F. has sent me compiled 64-bit OS X binaries, but
> I haven't gotten around to incorporating them yet (the 32-bit binaries
> do work on my system, although presumably the 64-bit ones would be
> faster in general).
>  So
>  install.packages("glmmADMB",repos="http://r-forge.r-project.org")
> should work on MacOS.
>  It would be helpful to get reports of trouble from list members who
> try it.
> 
>  To follow up on some of your other questions with my own opinions:
> * as I recommend on <http://glmm.wikidot.com/faq> (I have just added a
> few words to make my personal opinions clearer), I would recommend
> glmm.admb or glmer with individual-level random effects over the various
> quasi- options.
> * glmm.admb currently only works with a single random effect, so you
> can't do nested random effects that way.  You could build a more
> complete model in AD Model Builder, or revert to glmer.
> * Your model specification
> 
> m1po<-lmer(count~treat+treedbh+treehgt+numepi+elevepi+hgtepi+leafepi+
> (1|tree/epi),family=poisson,data=ecpad2)
> 
>  looks reasonable.  If you say
> ecpad2$indiv <- 1:nrow(ecpad2)
> and add +(1|indiv) to your model specification you will have an
> individual-level random effect.
> 
> * Is 'treat' your site variable?  In any case, if you are trying to do
> a statistical comparison between only two sites you have a major
> pseudo-replication problem (Hurlbert 1984).
> 
>  * The p-values that you get from summary(lmer) are Wald Z statistics,
> they assume large data sets and are possibly unreliable for
> moderate-sized data sets ...
> 
> * Opinions differ on the value of backward stepwise model reduction. It
> is standard practice in many ecological contexts and is suggested for
> moderate model complexity by many respected practicing
> (eco)statisticians (Bates, Wood, Zuur ...) but is vehemently decried by
> others (Harrell).  I would probably base inference on your full model
> rather than doing backward elimination.
> 
> 
>> The solution that worked for me:
>> 
>> I used the binaries Dave sent in admbfiles.zip over in the post in the
>> admb-users group: http://groups.google.com/group/admb-users/t/df5779586e45b9b
>> 
>> First, I copied them to my desktop and unzipped.
>> Opened Terminal and typed the following to direct it to run nbmm in the expanded
>> folder and confirm it would run:
>> 
>> ShawnMBP:$ /Users/Shawn/Desktop/admbfiles/nbmm     #of course you will need to
>> change this to navigate to where it is on your computer#
>> Error trying to open data input file /users/shawn/desktop/admbfiles/nbmm.dat
>> Error trying to read in model data
>> This is usual caused by a missing DAT file
>> 
>> Dave said the error message comes from ndmm looking for the data file to use but
>> it is running.
>> 
>> I then located where glmmADMB had originally placed these same named files when
>> I did the install of glmmADMB. I can?t remember how I found where they were and
>> spotlight won?t show them either. I think I did a search just for ?R? and found
>> an R.framework folder in the Library folder. I looked through there and found
>> them in a folder called admb here:
>> 
>> MBP_SFM>Library>Frameworks>R.framework>Versions>2.11>Resources>library>glmmADMB>
>> admb
>> 
>> I then replaced the nbmm and bvprobit files that were there with the ones
>> provided by Dave.
>> Started up R, loaded glmmADMB, viewed the epil2 dataset, and then ran the
>> example model and it ran fine!
>> 
>> My system: Macbook Pro, Mac OSX 10.6.4, R 64-bit
>> 
>> Hope this helps.
>> 
>> Shawn
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.10 (GNU/Linux)
> Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/
> 
> iEYEARECAAYFAkzW8wMACgkQc5UpGjwzenN0DACeNN/OmJf0UK9hSOtTt8DmPcdB
> vHwAmwXH6qKTOwT9snxDsDgldVm6hzVO
> =4NDD
> -----END PGP SIGNATURE-----
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From drewdogy at uw.edu  Mon Nov  8 02:22:28 2010
From: drewdogy at uw.edu (Andrew Kosydar)
Date: Sun, 7 Nov 2010 20:22:28 -0500
Subject: [R-sig-ME] Questions - the stepwise selection issue.
In-Reply-To: <8FA236D4-4484-488B-A064-0699801A97B6@anu.edu.au>
References: <C8F7B4E6.1688C%smccracken@tadpoleorg.org>
	<loom.20101107T171016-518@post.gmane.org>
	<4CD6F304.5080202@gmail.com>
	<8FA236D4-4484-488B-A064-0699801A97B6@anu.edu.au>
Message-ID: <AANLkTikP0JMnChSkWi01Or0dNzcR4ZkVvweYEUfUvuOm@mail.gmail.com>

Hello All,

Instead of using step-wise selection, I would suggest instead using
multimodel inference (Burnham & Anderson).  The technique avoids
having to choose one "right" model and, in my opinion, is a more
accurate method than traditional step-wise procedures.

Cheers!

Andrew


-- 
Andrew Kosydar, PhD
drewdogy at uw.edu
(206) 669-0505




On Sun, Nov 7, 2010 at 7:17 PM, John Maindonald
<john.maindonald at anu.edu.au> wrote:
> The stepwise model reduction issue is an interesting one.
>
> My view is that:
> 1) One should always begin by looking at the t-statistics for
> the coeffs in the full model (assuming that this is a situation
> where they are more or less believable!). ?If there is a clear
> division into those that are significant and those that are
> clearly not significant (p-value > 0.1, maybe), then drop
> those that are not significant. ?Check what difference this
> makes to the residual SE, and to the coefficients (any large
> changes may matter if there is an interest in interpreting
> coefficients). ?There are other issues to consider; are some
> variables of such scientific consequence that they should
> be retained regardless?
>
> 2) Backwise stepwise selection or (better) exhaustive
> subset selection if the problem is not too large are a resort
> of desperation if some variant of (1) fails to give a useful
> result. ?The approach (1) is most likely to fail to give a useful
> result in cases where there is quite a large number of
> explanatory variables, exactly the situation where variable
> selection bias becomes a serious issue. ?The function
> bestsetNoise() in the DAAG package is designed to make
> it easy to experiment with variable selection effects for
> data that are purely noise. ?For getting realistic SEs, some
> alternatives are:
> ?a) repeat the whole analysis, selection and all, with repeated
> ?bootstrap samples;
> ?b) get SEs by repeated bootstrap sampling from 'test' data.
> ?c) simulate, with selection and all, from the fitted model.
> For both a) and c) one has to deal with getting somewhat
> different selections each time round (that is itself instructive).
>
> 3) If the approach (2) has been used, and there is interest
> in the interpretation of coefficients, check the coefficients
> against those from the full model. ?Any large changes will
> ring a warning bell for attempts to interpret them.
>
> 4) One possibility, following stepwise or other selection,
> is that one or more p-values may be so small that they are
> very unlikely to be an artefact of the selection process.
> In general, a simulation will be required, in order to be
> sure.
>
> Somewhat casual approaches to the use of backward (or
> other) stepwise selection may be a holdover from hand
> calculator days, or times when computers grunted somewhat
> to handle even modest sized calculations. ?If the inclusion and
> exclusion criteria are suitably chosen (but who really knows
> what is suitable?), I suspect that in some contexts they do
> more or less work to give believable answers, without undue
> selection bias. ?But how, without checks such as I have noted,
> can one be sure? ?This may be one of the murky dark alleys
> of statistical practice, where magic incantations and hope too
> often prevail over hard evidence.
>
> It would be useful to find a review paper that covers this
> ground systematically and incisively, without undue reliance
> on specific examples.
>
> John Maindonald ? ? ? ? ? ? email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473 ? ?fax ?: +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> http://www.maths.anu.edu.au/~johnm
>
> On 08/11/2010, at 5:42 AM, Ben Bolker wrote:
>
>> -----BEGIN PGP SIGNED MESSAGE-----
>> Hash: SHA1
>>
>> On 10-11-07 11:14 AM, Shawn McCracken wrote:
>>> Shawn McCracken <smccracken at ...> writes:
>>>
>>>>
>>>> Dear Mixed-models group,
>>>>
>>>> I am working with a dataset containing fixed and nested random effects. I
>>>> have
>>>> one fixed effect that I am most interested in and the others were collected
>>>> to
>>>> see if they also might have an influence. I apologize for the novel but
>>>> hopefully discussion of this will help others in the future who are as
>>>> intimidated as I was/am.
>>>>
>>>> The data consist of total counts of anuran individuals from a particular
>>>> species
>>>> of epiphytic phytotelm plant found in tree canopies at two sites. The site
>>>> difference (if any) is my main interest. At each site all trees with
>>>> suitable
>>>> #?s of this epiphyte species for sampling were located within a
>>>> predetermined
>>>> size area. 16 trees were randomly selected from those available at each site
>>>> and
>>>> 5 epiphytes were then randomly sampled for all anurans within them. So, 2
>>>> sites
>>>> -> 16 trees (at each site) -> 5 epiphytes (in each tree), which equals 80
>>>> samples from each site for a total of 160........................
>>>> ? ? [[alternative HTML version deleted]]
>>>>
>>>>
>>>
>>> Update: The install problem with glmmADMB has been fixed on my Mac. Thanks to
>>> Dave. Details below. I could still use some feedback on what I have done so far
>>> still.
>>>
>>
>> ?Update: I have been working on the glmmADMB package a bit. ?The
>> current version on R-forge installs OK on my MacOS X.6 machine. It
>> contains 32-bit binaries which it automatically puts in the correct
>> location, so that you shouldn't have to mess around with doing this
>> stuff manually. ?Dave F. has sent me compiled 64-bit OS X binaries, but
>> I haven't gotten around to incorporating them yet (the 32-bit binaries
>> do work on my system, although presumably the 64-bit ones would be
>> faster in general).
>> ?So
>> ?install.packages("glmmADMB",repos="http://r-forge.r-project.org")
>> should work on MacOS.
>> ?It would be helpful to get reports of trouble from list members who
>> try it.
>>
>> ?To follow up on some of your other questions with my own opinions:
>> * as I recommend on <http://glmm.wikidot.com/faq> (I have just added a
>> few words to make my personal opinions clearer), I would recommend
>> glmm.admb or glmer with individual-level random effects over the various
>> quasi- options.
>> * glmm.admb currently only works with a single random effect, so you
>> can't do nested random effects that way. ?You could build a more
>> complete model in AD Model Builder, or revert to glmer.
>> * Your model specification
>>
>> m1po<-lmer(count~treat+treedbh+treehgt+numepi+elevepi+hgtepi+leafepi+
>> (1|tree/epi),family=poisson,data=ecpad2)
>>
>> ?looks reasonable. ?If you say
>> ecpad2$indiv <- 1:nrow(ecpad2)
>> and add +(1|indiv) to your model specification you will have an
>> individual-level random effect.
>>
>> * Is 'treat' your site variable? ?In any case, if you are trying to do
>> a statistical comparison between only two sites you have a major
>> pseudo-replication problem (Hurlbert 1984).
>>
>> ?* The p-values that you get from summary(lmer) are Wald Z statistics,
>> they assume large data sets and are possibly unreliable for
>> moderate-sized data sets ...
>>
>> * Opinions differ on the value of backward stepwise model reduction. It
>> is standard practice in many ecological contexts and is suggested for
>> moderate model complexity by many respected practicing
>> (eco)statisticians (Bates, Wood, Zuur ...) but is vehemently decried by
>> others (Harrell). ?I would probably base inference on your full model
>> rather than doing backward elimination.
>>
>>
>>> The solution that worked for me:
>>>
>>> I used the binaries Dave sent in admbfiles.zip over in the post in the
>>> admb-users group: http://groups.google.com/group/admb-users/t/df5779586e45b9b
>>>
>>> First, I copied them to my desktop and unzipped.
>>> Opened Terminal and typed the following to direct it to run nbmm in the expanded
>>> folder and confirm it would run:
>>>
>>> ShawnMBP:$ /Users/Shawn/Desktop/admbfiles/nbmm ? ? #of course you will need to
>>> change this to navigate to where it is on your computer#
>>> Error trying to open data input file /users/shawn/desktop/admbfiles/nbmm.dat
>>> Error trying to read in model data
>>> This is usual caused by a missing DAT file
>>>
>>> Dave said the error message comes from ndmm looking for the data file to use but
>>> it is running.
>>>
>>> I then located where glmmADMB had originally placed these same named files when
>>> I did the install of glmmADMB. I can?t remember how I found where they were and
>>> spotlight won?t show them either. I think I did a search just for ?R? and found
>>> an R.framework folder in the Library folder. I looked through there and found
>>> them in a folder called admb here:
>>>
>>> MBP_SFM>Library>Frameworks>R.framework>Versions>2.11>Resources>library>glmmADMB>
>>> admb
>>>
>>> I then replaced the nbmm and bvprobit files that were there with the ones
>>> provided by Dave.
>>> Started up R, loaded glmmADMB, viewed the epil2 dataset, and then ran the
>>> example model and it ran fine!
>>>
>>> My system: Macbook Pro, Mac OSX 10.6.4, R 64-bit
>>>
>>> Hope this helps.
>>>
>>> Shawn
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> -----BEGIN PGP SIGNATURE-----
>> Version: GnuPG v1.4.10 (GNU/Linux)
>> Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/
>>
>> iEYEARECAAYFAkzW8wMACgkQc5UpGjwzenN0DACeNN/OmJf0UK9hSOtTt8DmPcdB
>> vHwAmwXH6qKTOwT9snxDsDgldVm6hzVO
>> =4NDD
>> -----END PGP SIGNATURE-----
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From tiflo at csli.stanford.edu  Mon Nov  8 04:30:54 2010
From: tiflo at csli.stanford.edu (T. Florian Jaeger)
Date: Sun, 7 Nov 2010 19:30:54 -0800
Subject: [R-sig-ME] quasi-binomial family in lme4
Message-ID: <AANLkTi=3X-0Fv3QagVn=kYpk4B00BoZn8fM7CaH8SBVT@mail.gmail.com>

Hi,
I am analyzing some data that seems to require a quasibinomial model,
but the model returns incredibly small standard errors (and
correspondingly inflated t-values) that do not seem to be justified
given my data.
I've been reading (I think) all available posts on problems with the
quasi-binomial family in lme4. But I can't judge from the posts
whether all issues with the??quasi-binomial models in lme4 are assumed
to be resolved. So, I am wondering, are there any known issues with
quasi-binomial models in lme4?

I am using

Package:            lme4
Version:            0.999375-35
Date:               2010-08-18

in environment:
?? ? ? ? ? ? ? _
platform ? ? ? i386-pc-mingw32
arch ? ? ? ? ? i386
os ? ? ? ? ? ? mingw32
system ? ? ? ? i386, mingw32
status
major ? ? ? ? ?2
minor ? ? ? ? ?11.1
year ? ? ? ? ? 2010
month ? ? ? ? ?05
day ? ? ? ? ? ?31
svn rev ? ? ? ?52157
language ? ? ? R
version.string R version 2.11.1 (2010-05-31)

cheers,
Florian



From bbolker at gmail.com  Mon Nov  8 14:57:45 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 08 Nov 2010 08:57:45 -0500
Subject: [R-sig-ME] Questions - the stepwise selection issue.
In-Reply-To: <AANLkTikP0JMnChSkWi01Or0dNzcR4ZkVvweYEUfUvuOm@mail.gmail.com>
References: <C8F7B4E6.1688C%smccracken@tadpoleorg.org>	<loom.20101107T171016-518@post.gmane.org>	<4CD6F304.5080202@gmail.com>	<8FA236D4-4484-488B-A064-0699801A97B6@anu.edu.au>
	<AANLkTikP0JMnChSkWi01Or0dNzcR4ZkVvweYEUfUvuOm@mail.gmail.com>
Message-ID: <4CD801D9.6090508@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 10-11-07 08:22 PM, Andrew Kosydar wrote:
> Hello All,
> 
> Instead of using step-wise selection, I would suggest instead using
> multimodel inference (Burnham & Anderson).  The technique avoids
> having to choose one "right" model and, in my opinion, is a more
> accurate method than traditional step-wise procedures.

  OK, but (in my opinion) only if: (1) you actually do multi-model
averaging (and don't just pick the best-AIC model to work with), and (2)
you actually want to maximize prediction accuracy rather than testing
statistical hypotheses. I am leery of people using information-theoretic
measures as a shortcut when the language in which they express their
questions strongly suggests that they are really interested in testing
hypotheses rather than making predictions.
One can be led to some marginally sensible statements when trying to
make inferences about the multi-model averaged values of parameters that
average across models containing different sets of correlated
predictors, or containing models with different interaction terms.

  Ben Bolker

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iEYEARECAAYFAkzYAdkACgkQc5UpGjwzenNP5wCggEa5yYIA/Nr4ebfpUkLB3Y9d
mxUAn1MpWojZ39nmvMCJQiV2fUEFA1XY
=P4am
-----END PGP SIGNATURE-----



From HDoran at air.org  Mon Nov  8 18:39:22 2010
From: HDoran at air.org (Doran, Harold)
Date: Mon, 8 Nov 2010 12:39:22 -0500
Subject: [R-sig-ME] IRT: discrimination parameters from LMER?
In-Reply-To: <AANLkTik7jc+j8aJnv0cnH5F-caBKdB7Os8bOcRTNsJYW@mail.gmail.com>
References: <AANLkTi=GRoe0-AXFbOiw6x_W95J_j5+rXek-OnoR9CwZ@mail.gmail.com>
	<C0772C7568B5374481D2F8A880E9BBDF06A650CA1B@DC1EX07CMS.air.org>
	<AANLkTikzXr=KkDzHRUhPW_s+E7u_yf3N3A0d3EXpG=Qj@mail.gmail.com>
	<C0772C7568B5374481D2F8A880E9BBDF06A64B7A9C@DC1EX07CMS.air.org>
	<AANLkTik7jc+j8aJnv0cnH5F-caBKdB7Os8bOcRTNsJYW@mail.gmail.com>
Message-ID: <C0772C7568B5374481D2F8A880E9BBDF06A64B8312@DC1EX07CMS.air.org>

I can't speak to the error below, perhaps the package author/maintainer can do so. I'm not sure I follow this last thread exactly. But, here is what you should be seeing, if not I too think there is an issue.

1) When you use lmer to fit the rasch model, you get b-parameters for the item (difficulties) and a population distribution that is N(0, s^2)
2) When you use the rasch function in ltm and the discrimination is not set at 1, then the items have a common slope. This common slope should be equivalent to s (the standard deviation from lmer). The parameter estimates will differ because they are identified differently. I think if you want to compare the difficulties from ltm to lmer then you need b/s where b is the difficulty of the item.

Dimitris, does rasch use D = 1 or 1.7 when the discrimination is not 1?

> -----Original Message-----
> From: Paul Johnson [mailto:pauljohn32 at gmail.com]
> Sent: Sunday, November 07, 2010 1:00 AM
> To: Doran, Harold
> Cc: R-SIG-Mixed-Models at r-project.org
> Subject: Re: [R-sig-ME] IRT: discrimination parameters from LMER?
> 
> Dear Harold.
> 
> Thanks for the example.  I've not heard of MiscPsycho before, that's
> interesting.
> 
> Your test case focuses on difficulty parameters, and that's not where
> I'm seeing trouble.  I agree with you difficulty estimates match the
> fixed effects from lmer.
> 
> The discrimination estimate from ltm compared against lmer's random
> effect estimate is my concern.  If the discrimination parameter is not
> 1.0, then I wonder if your argument holds up.  In that one simulation
> I reported last time, I saw pretty big difference.
> 
> I'm adapting your simulation to do a lot of data sets.
> 
> But I can't amaze you with my result now because of this weird kernel
> error I've never seen before, so I think I need to close everything
> down. But I'll get back to you.
> 
> 
> >   fm1 <- rasch(itemDat[, -21], IRT.param=F)
> OMP: Error #15: Initializing libguide.so, but found libguide.so
> already initialized.
> OMP: Hint: This may cause performance degradation and correctness
> issues. Set environment variable KMP_DUPLICATE_LIB_OK=TRUE to ignore
> this problem and force the program to continue anyway. Please note
> that the use of KMP_DUPLICATE_LIB_OK is unsupported and using it may
> cause undefined behavior. For more information, please contact
> Intel(R) Premier Support.
> 
> 
> Weird, huh?
> 
> pj
> 
> 
> > I don't think this is true necessarily. I've done a small experiment all
> reproducible code is at bottom of email. I simulate some rasch data and then
> estimate item parameters using ltm, lmer, jml (in MiscPsycho), and mml (a
> function I wrote that is below using the traditional mml methods). To make a
> long story short, I compute the bias under each model.
> >
> >> ### ltm bias
> >> mean((coef(fm1)[,1] - mean(coef(fm1)[,1])) - trueVals)
> > [1] -0.173386111948639
> >>
> >> ### lmer bias
> >> mean((fixef(fm2) - mean(fixef(fm2))) - trueVals)
> > [1] -0.173386111948639
> >>
> >> ### jml bias
> >> mean(coef(fm1) - trueVals)
> > [1] 0.39007242168395
> >>
> >> ### mml bias
> >> mean((coef(fm4)[1:20] - mean(coef(fm4)[1:20])) - trueVals)
> > [1] -0.173386111948639
> >
> > It seems to me that jml (as expected) performs the worst, but all other
> functions are comparable and seem to recover parameter estimates rather well.
> If you run the mml function below, it is slow. But, notice that the standard
> deviation in mml is exactly the same as what lmer gives. That is because a
> multilevel rasch model with the parameterization I have used (items as fixed
> respondents as random) is exactly the same as mml. But, lmer's capacity can go
> much, much further. Had I not constrained the ltm function to have a
> discrimination of 1, the common discrimination parameter would also be the sd
> given by mml and lmer.
> >
> >> Do you care to weigh in on the question of whether lmer could ever be
> >> made to fit a 2PL or 3PL model? ?I mean, could I write a family for
> >> lmer that would do that, or is the calculation required too grossly
> >> different?
> >
> > Yes, I'm sure it can. The issue is who will write the code. Doug Bates is
> extremely generous with his help and his openness to others making
> contributions to lme4. But, (as he might do so on this thread), he will
> forewarn you that the underlying code in lmer is very complex and doesn't
> resemble methods commonly used in other packages. So, because Doug is so
> amazingly smart, and I am just a mortal, I have decided to steer away from
> contributing to lmer other than being a "toy tester" for Doug.
> >
> > I am not a fan of the 3PL for many reasons. First, it is a model that cannot
> be identified without putting a very slim prior on the guessing parameter. In
> the end, because the prior is so slim, guess what your parameter estimates are
> close to? Yes, the prior. So, I just have never been made comfortable with
> that.
> >
> >> If 2PL or 3PL is really a whole different structure, I don't mind
> >> using "ltm." ?But defeats the ideal that you proposed in that 2007 JSS
> >> article (which I really like!), that we might be better off fitting
> >> specialized models with general purpose software.
> >
> > I think ltm is a really great package. It may have some capacity to do what
> you want, I don't fully know its capacities. Perhaps Dimitris can offer some
> thought.
> >
> >> Here's a similar example. ?Sometimes I have wanted to fit ordinal
> >> dependent variables, and have learned that those models do not fall
> >> into the family of GLM and a tool different from lmer is necessary to
> >> work on them. ? I wish it weren't so, but have accepted reality.
> >>
> >> pj
> >
> > This is very true. I have been doing some work on polytomous models, but am
> working very slowly on functions to estimate them. There are packages in R
> that can currently do this. I wonder if MCMCglmm can do it; I don't know.
> >
> >
> > library(ltm)
> > library(lmer)
> > library(MiscPsycho)
> >
> > Nitems <- 20
> > Nperson <- 500
> >
> > set.seed(12345)
> > dat <- simRasch(Nperson, Nitems)
> > itemDat <- dat$data
> >
> > ### Fit data using rasch in LTM
> > fm1 <- rasch(itemDat, constraint = cbind(ncol(itemDat) + 1, 1))
> >
> > ### Fit using lmer
> > itemDat$id <- 1:nrow(itemDat)
> > ### reshape into long format
> > testScores <- reshape(itemDat, idvar='id',
> varying=list(names(itemDat)[1:Nitems]), v.names=c('answer'),
> timevar='question', direction='long')
> >
> > # Treat items as fixed but students as random
> > fm2 <- lmer(answer ~ factor(question) - 1 + (1|id), testScores, family =
> binomial(link='logit'))
> >
> >
> > ### Fit using JML
> > fm3 <- jml(dat$data, bias=TRUE)
> >
> > ### Fit using mml function below
> > fm4 <- mml(dat$data, Q =10, startVal = coef(fm1)[,1])
> >
> > ### Compute bias
> > trueVals <- dat$gen
> >
> > ### ltm bias
> > mean((coef(fm1)[,1] - mean(coef(fm1)[,1])) - trueVals)
> >
> > ### lmer bias
> > mean((fixef(fm2) - mean(fixef(fm2))) - trueVals)
> >
> > ### jml bias
> > mean(coef(fm1) - trueVals)
> >
> > ### mml bias
> > mean((coef(fm4)[1:20] - mean(coef(fm4)[1:20])) - trueVals)
> >
> >
> >
> > mml <- function(data, Q, startVal = NULL, ...){
> > ? ? ? ?if(!is.null(startVal) && length(startVal) != ncol(data) ){
> > ? ? ? ? ? ? ? ?stop("Length of argument startVal not equal to the number of
> parameters estimated")
> > ? ? ? ?}
> > ? ? ? ?if(!is.null(startVal)){
> > ? ? ? ? ? ? ? ?startVal <- startVal
> > ? ? ? ? ? ? ? ?} else {
> > ? ? ? ? ? ? ? ?p <- colMeans(data)
> > ? ? ? ? ? ? ? ?startVal <- as.vector(log((1 - p)/p))
> > ? ? ? ?}
> > ? ? ? ?qq <- gauss.quad.prob(Q, dist = 'normal', mu = 0, sigma=1)
> > ? ? ? ?rr1 <- matrix(0, nrow = Q, ncol = nrow(data))
> > ? ? ? ?data <- as.matrix(data)
> > ? ? ? ?L <- nrow(data)
> > ? ? ? ?C <- ncol(data)
> > ? ? ? ?u <- 0
> > ? ? ? ?fn <- function(b){
> > ? ? ? ?s <- b[C+1]
> > ? ? ? ?b <- b[1:C]
> > ? ? ? ? ? ? ? ?for(j in 1:Q){
> > ? ? ? ? ? ? ? ? ? ? ? ?for(i in 1:L){
> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?rr1[j,i] <- exp(sum(dbinom(data[i,], 1,
> plogis(qq$nodes[j]-b), log = TRUE))) *
> > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?((1/(s*sqrt(2*pi))) ?* exp(-((qq$nodes[j]-
> u)^2/(2*s^2))))/dnorm(qq$nodes[j]) * qq$weights[j]
> > ? ? ? ? ? ? ? ? ? ? ? ?}
> > ? ? ? ? ? ? ? ?}
> > ? ? ? ?-sum(log(colSums(rr1)))
> > ? ? ? ?}
> > ? ? ? ?opt <- optim(c(startVal,1), fn, method = "BFGS", hessian = TRUE)
> > ? ? ? ?list("coefficients" = opt$par, "LogLik" = -opt$value, "Std.Error" =
> sqrt(diag(solve(opt$hessian))))
> > }
> >
> 
> 
> 
> --
> Paul E. Johnson
> Professor, Political Science
> 1541 Lilac Lane, Room 504
> University of Kansas



From HDoran at air.org  Mon Nov  8 19:05:58 2010
From: HDoran at air.org (Doran, Harold)
Date: Mon, 8 Nov 2010 13:05:58 -0500
Subject: [R-sig-ME] IRT: discrimination parameters from LMER?
In-Reply-To: <C0772C7568B5374481D2F8A880E9BBDF06A64B8312@DC1EX07CMS.air.org>
References: <AANLkTi=GRoe0-AXFbOiw6x_W95J_j5+rXek-OnoR9CwZ@mail.gmail.com>
	<C0772C7568B5374481D2F8A880E9BBDF06A650CA1B@DC1EX07CMS.air.org>
	<AANLkTikzXr=KkDzHRUhPW_s+E7u_yf3N3A0d3EXpG=Qj@mail.gmail.com>
	<C0772C7568B5374481D2F8A880E9BBDF06A64B7A9C@DC1EX07CMS.air.org>
	<AANLkTik7jc+j8aJnv0cnH5F-caBKdB7Os8bOcRTNsJYW@mail.gmail.com>
	<C0772C7568B5374481D2F8A880E9BBDF06A64B8312@DC1EX07CMS.air.org>
Message-ID: <C0772C7568B5374481D2F8A880E9BBDF06A64B8327@DC1EX07CMS.air.org>

Paul,

Just a quick example of what I meant if you want to compare item parameters between lmer and rasch with discrimination estimated at some value other than 1. I figured I might as well make this thread more replicable.

Here is some code to simulate the data.

Nitems <- 20
Nperson <- 500

set.seed(12345)
dat <- simRasch(Nperson, Nitems) 
itemDat <- dat$data

### Fit data using rasch in LTM
fm1 <- rasch(itemDat)

### Fit using lmer
itemDat$id <- 1:nrow(itemDat)
### reshape into long format
testScores <- reshape(itemDat, idvar='id', varying=list(names(itemDat)[1:Nitems]), v.names=c('answer'), timevar='question', direction='long')

# Treat items as fixed but students as random
fm2 <- lmer(answer ~ factor(question) - 1 + (1|id), testScores, family = binomial(link='logit'))

Now, if you do:

> coef(fm1)
> fixef(fm2)

The estimates are different. I won't paste all the output here since the code is replicable and the seed is set so we can compare output. Now, the discrimination value from rasch in this case is .949 and the standard deviation of the random effects from lmer is .946. Now, the log-likelihood under rasch and lmer is -4630.15799618799 and -4631.25819268, respectively. So, the sd and the log-like are pretty much the same between the different functions, so good so far. But, the item difficulties appear different. Why is this?

If you think about the parameterization of the rasch model, you have an "a" parameter, which is the slope of the item. Under lmer, that value is fixed at 1 for all items. But, for rasch, it is estimated (the value is .949) and it is common across all items. 

So now, if you want to compare the difficulties between rasch and lmer when the discrimination is not 1 under rasch, then you need to do:

> coef(fm1)[,1] * coef(fm1)[,2]
                 V1                  V2                  V3                  V4                  V5                  V6                  V7 
-2.4363375076723894  2.1282095647448513 -3.2456020170777404 -0.9922074612193649  1.0940596551348656 -1.4747653022333751 -1.9674236315390756 
                 V8                  V9                 V10                 V11                 V12                 V13                 V14 
 1.1286690341041918  3.0183007620878102  2.7669665964796186 -0.5520550496701296  2.2850817917913258  0.6125781984255096 -0.8937278122026954 
                V15                 V16                 V17                 V18                 V19                 V20 
 1.7286473472431816  0.0286736514649762 -2.7387309033941731  1.2960560094822793 -0.6529545363519687  1.3839487252561851

Now if we look at the lmer difficulties we have

> fixef(fm2)
  factor(question)1   factor(question)2   factor(question)3   factor(question)4   factor(question)5   factor(question)6   factor(question)7 
 2.4361348266711036 -2.1291740694356793  3.2416948820925300  0.9945299229893042 -1.0961119907031844  1.4771362900874057  1.9688762349930169 
  factor(question)8   factor(question)9  factor(question)10  factor(question)11  factor(question)12  factor(question)13  factor(question)14 
-1.1307455947353959 -3.0161274136566423 -2.7657709971218583  0.5536329523565644 -2.2855834341023469 -0.6139641860890157  0.8959339499969335 
 factor(question)15  factor(question)16  factor(question)17  factor(question)18  factor(question)19  factor(question)20 
-1.7304539905559007 -0.0286143300422378  2.7371985048319152 -1.2981830712160072  0.6547480328455485 -1.3866471195258758

So, we can see that lmer and rasch generate the same estimates of all parameters. Is this helpful?


> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
> bounces at r-project.org] On Behalf Of Doran, Harold
> Sent: Monday, November 08, 2010 12:39 PM
> To: Paul Johnson
> Cc: R-SIG-Mixed-Models at r-project.org
> Subject: Re: [R-sig-ME] IRT: discrimination parameters from LMER?
> 
> I can't speak to the error below, perhaps the package author/maintainer can do
> so. I'm not sure I follow this last thread exactly. But, here is what you
> should be seeing, if not I too think there is an issue.
> 
> 1) When you use lmer to fit the rasch model, you get b-parameters for the item
> (difficulties) and a population distribution that is N(0, s^2)
> 2) When you use the rasch function in ltm and the discrimination is not set at
> 1, then the items have a common slope. This common slope should be equivalent
> to s (the standard deviation from lmer). The parameter estimates will differ
> because they are identified differently. I think if you want to compare the
> difficulties from ltm to lmer then you need b/s where b is the difficulty of
> the item.
> 
> Dimitris, does rasch use D = 1 or 1.7 when the discrimination is not 1?



From ned.dochtermann at gmail.com  Mon Nov  8 19:21:36 2010
From: ned.dochtermann at gmail.com (Ned Dochtermann)
Date: Mon, 8 Nov 2010 10:21:36 -0800
Subject: [R-sig-ME] Questions - the stepwise selection issue.
In-Reply-To: <mailman.5.1289214002.739.r-sig-mixed-models@r-project.org>
References: <mailman.5.1289214002.739.r-sig-mixed-models@r-project.org>
Message-ID: <4cd83fb2.c74ee50a.6a81.0a95@mx.google.com>

If stepwise regression is being considered then there are not likely to be
solid hypotheses for consideration using a model comparison approach and
either approach is fundamentally going to be exploratory. Based on my
reading of the literature model selection is only going to be more accurate
(assuming you mean in regards to parameter estimates) if based on a priori
models. Otherwise there are still going to be the same problems with
estimates, and--if any critical threshold is used--the same problem with
spurious effects. Interestingly some of the discussion of stepwise versus
model comparison in the ecological literature has been done based on
comparison of all possible models which has the same problems and is equally
exploratory in nature.

Ned

--
Ned Dochtermann
Department of Biology
University of Nevada, Reno

ned.dochtermann at gmail.com
http://wolfweb.unr.edu/homepage/mpeacock/Ned.Dochtermann/
--



Today's Topics:

   1. Re: Questions - the stepwise selection issue. (Andrew Kosydar)
   2. quasi-binomial family in lme4 (T. Florian Jaeger)


----------------------------------------------------------------------

Message: 1
Date: Sun, 7 Nov 2010 20:22:28 -0500
From: Andrew Kosydar <drewdogy at uw.edu>
To: John Maindonald <john.maindonald at anu.edu.au>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Questions - the stepwise selection issue.
Message-ID:
	<AANLkTikP0JMnChSkWi01Or0dNzcR4ZkVvweYEUfUvuOm at mail.gmail.com>
Content-Type: text/plain; charset=windows-1252

Hello All,

Instead of using step-wise selection, I would suggest instead using
multimodel inference (Burnham & Anderson).  The technique avoids
having to choose one "right" model and, in my opinion, is a more
accurate method than traditional step-wise procedures.

Cheers!

Andrew


-- 
Andrew Kosydar, PhD
drewdogy at uw.edu
(206) 669-0505




On Sun, Nov 7, 2010 at 7:17 PM, John Maindonald
<john.maindonald at anu.edu.au> wrote:
> The stepwise model reduction issue is an interesting one.
>
> My view is that:
> 1) One should always begin by looking at the t-statistics for
> the coeffs in the full model (assuming that this is a situation
> where they are more or less believable!). ?If there is a clear
> division into those that are significant and those that are
> clearly not significant (p-value > 0.1, maybe), then drop
> those that are not significant. ?Check what difference this
> makes to the residual SE, and to the coefficients (any large
> changes may matter if there is an interest in interpreting
> coefficients). ?There are other issues to consider; are some
> variables of such scientific consequence that they should
> be retained regardless? 
*******



From javier.martinez at um.es  Mon Nov  8 20:53:32 2010
From: javier.martinez at um.es (Javier Martinez Lopez)
Date: Mon, 8 Nov 2010 20:53:32 +0100
Subject: [R-sig-ME] mixed models for non independet data sets (glmer)
Message-ID: <AANLkTinRn8UJfJRSrSpcKk3GoSNjdRH1TOXNoqsf5w2T@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101108/49d8126f/attachment.pl>

From j.hadfield at ed.ac.uk  Tue Nov  9 16:02:45 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 9 Nov 2010 15:02:45 +0000
Subject: [R-sig-ME] quasi-binomial family in lme4
In-Reply-To: <AANLkTi=3X-0Fv3QagVn=kYpk4B00BoZn8fM7CaH8SBVT@mail.gmail.com>
References: <AANLkTi=3X-0Fv3QagVn=kYpk4B00BoZn8fM7CaH8SBVT@mail.gmail.com>
Message-ID: <A7154ED7-0283-4AEC-BB4F-2358B1E3C2F1@ed.ac.uk>

Hi Florian,

This comes up regularly and the list (nearly) always stays silent. As  
far as I am aware quasi models in lmer do not, and never have, given  
sensible results. To model over-dispersion you can try fitting an  
observation-level random effect. For example:

data$resid<-as.factor(1:dim(data)[1])

and fitting (1|resid) in the model formula.

This year  I have reviewed four papers that have used quasi models in  
lmer, and its no fun to tell the authors that their results may not be  
meaningful. To paraphrase an earlier post, why are they there if they  
do not work - it's irresponsible?

Jarrod





On 8 Nov 2010, at 03:30, T. Florian Jaeger wrote:

> Hi,
> I am analyzing some data that seems to require a quasibinomial model,
> but the model returns incredibly small standard errors (and
> correspondingly inflated t-values) that do not seem to be justified
> given my data.
> I've been reading (I think) all available posts on problems with the
> quasi-binomial family in lme4. But I can't judge from the posts
> whether all issues with the  quasi-binomial models in lme4 are assumed
> to be resolved. So, I am wondering, are there any known issues with
> quasi-binomial models in lme4?
>
> I am using
>
> Package:            lme4
> Version:            0.999375-35
> Date:               2010-08-18
>
> in environment:
>                _
> platform       i386-pc-mingw32
> arch           i386
> os             mingw32
> system         i386, mingw32
> status
> major          2
> minor          11.1
> year           2010
> month          05
> day            31
> svn rev        52157
> language       R
> version.string R version 2.11.1 (2010-05-31)
>
> cheers,
> Florian
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From bates at stat.wisc.edu  Tue Nov  9 16:26:40 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 9 Nov 2010 09:26:40 -0600
Subject: [R-sig-ME] quasi-binomial family in lme4
In-Reply-To: <A7154ED7-0283-4AEC-BB4F-2358B1E3C2F1@ed.ac.uk>
References: <AANLkTi=3X-0Fv3QagVn=kYpk4B00BoZn8fM7CaH8SBVT@mail.gmail.com>
	<A7154ED7-0283-4AEC-BB4F-2358B1E3C2F1@ed.ac.uk>
Message-ID: <AANLkTi=zM2UG2GFt9YCQrpCsY_gLam0ddz5aboHBk+P7@mail.gmail.com>

On Tue, Nov 9, 2010 at 9:02 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
> Hi Florian,
>
> This comes up regularly and the list (nearly) always stays silent. As far as
> I am aware quasi models in lmer do not, and never have, given sensible
> results. To model over-dispersion you can try fitting an observation-level
> random effect. For example:
>
> data$resid<-as.factor(1:dim(data)[1])
>
> and fitting (1|resid) in the model formula.
>
> This year ?I have reviewed four papers that have used quasi models in lmer,
> and its no fun to tell the authors that their results may not be meaningful.
> To paraphrase an earlier post, why are they there if they do not work - it's
> irresponsible?

I agree.  I should have removed them from lme4 long ago if I suspected
that the results were not correct.

I will do so (once I figure out how to forbid them).

> On 8 Nov 2010, at 03:30, T. Florian Jaeger wrote:
>
>> Hi,
>> I am analyzing some data that seems to require a quasibinomial model,
>> but the model returns incredibly small standard errors (and
>> correspondingly inflated t-values) that do not seem to be justified
>> given my data.
>> I've been reading (I think) all available posts on problems with the
>> quasi-binomial family in lme4. But I can't judge from the posts
>> whether all issues with the ?quasi-binomial models in lme4 are assumed
>> to be resolved. So, I am wondering, are there any known issues with
>> quasi-binomial models in lme4?
>>
>> I am using
>>
>> Package: ? ? ? ? ? ?lme4
>> Version: ? ? ? ? ? ?0.999375-35
>> Date: ? ? ? ? ? ? ? 2010-08-18
>>
>> in environment:
>> ? ? ? ? ? ? ? _
>> platform ? ? ? i386-pc-mingw32
>> arch ? ? ? ? ? i386
>> os ? ? ? ? ? ? mingw32
>> system ? ? ? ? i386, mingw32
>> status
>> major ? ? ? ? ?2
>> minor ? ? ? ? ?11.1
>> year ? ? ? ? ? 2010
>> month ? ? ? ? ?05
>> day ? ? ? ? ? ?31
>> svn rev ? ? ? ?52157
>> language ? ? ? R
>> version.string R version 2.11.1 (2010-05-31)
>>
>> cheers,
>> Florian
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bbolker at gmail.com  Tue Nov  9 16:31:27 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 09 Nov 2010 10:31:27 -0500
Subject: [R-sig-ME] Fwd: Re:  quasi-binomial family in lme4
Message-ID: <4CD9694F.8000302@gmail.com>


  Alas, I may have (in my own small way) contributed to this, by
including a quasi-Poisson example (of Arabidopsis fruiting) in a review
article in TREE.  We did look at the results reasonably carefully, and
they seemed to make sense in that case (although of course we didn't
know and still don't know what the 'true' answer is).  I should try to
re-run those analyses in various ways (primarily individual-level random
effects in glmer and MCMCglmm; the structure of the random effects is
currently too complicated for glmm.admb and gnlmm, I think ...)

-------- Original Message --------
Subject: Re: [R-sig-ME] quasi-binomial family in lme4
Date: Tue, 9 Nov 2010 15:02:45 +0000
From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
To: T. Florian Jaeger <tiflo at csli.stanford.edu>
CC: r-sig-mixed-models at r-project.org

Hi Florian,

This comes up regularly and the list (nearly) always stays silent. As
far as I am aware quasi models in lmer do not, and never have, given
sensible results. To model over-dispersion you can try fitting an
observation-level random effect. For example:

data$resid<-as.factor(1:dim(data)[1])

and fitting (1|resid) in the model formula.

This year  I have reviewed four papers that have used quasi models in
lmer, and its no fun to tell the authors that their results may not be
meaningful. To paraphrase an earlier post, why are they there if they
do not work - it's irresponsible?

Jarrod





On 8 Nov 2010, at 03:30, T. Florian Jaeger wrote:

> Hi,
> I am analyzing some data that seems to require a quasibinomial model,
> but the model returns incredibly small standard errors (and
> correspondingly inflated t-values) that do not seem to be justified
> given my data.
> I've been reading (I think) all available posts on problems with the
> quasi-binomial family in lme4. But I can't judge from the posts
> whether all issues with the  quasi-binomial models in lme4 are assumed
> to be resolved. So, I am wondering, are there any known issues with
> quasi-binomial models in lme4?
>
> I am using
>
> Package:            lme4
> Version:            0.999375-35
> Date:               2010-08-18
>
> in environment:
>                _
> platform       i386-pc-mingw32
> arch           i386
> os             mingw32
> system         i386, mingw32
> status
> major          2
> minor          11.1
> year           2010
> month          05
> day            31
> svn rev        52157
> language       R
> version.string R version 2.11.1 (2010-05-31)
>
> cheers,
> Florian
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From j.hadfield at ed.ac.uk  Tue Nov  9 16:37:35 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 9 Nov 2010 15:37:35 +0000
Subject: [R-sig-ME] quasi-binomial family in lme4
In-Reply-To: <AANLkTi=zM2UG2GFt9YCQrpCsY_gLam0ddz5aboHBk+P7@mail.gmail.com>
References: <AANLkTi=3X-0Fv3QagVn=kYpk4B00BoZn8fM7CaH8SBVT@mail.gmail.com>
	<A7154ED7-0283-4AEC-BB4F-2358B1E3C2F1@ed.ac.uk>
	<AANLkTi=zM2UG2GFt9YCQrpCsY_gLam0ddz5aboHBk+P7@mail.gmail.com>
Message-ID: <2CB7B52C-7F49-44D6-8183-F20A686557C2@ed.ac.uk>

Dear Doug,

That would be very welcome. It might be nice for lmer to fit a  
residual term if quasi models are specified, since this now seems to  
be working?

Cheers,

Jarrod




On 9 Nov 2010, at 15:26, Douglas Bates wrote:

> On Tue, Nov 9, 2010 at 9:02 AM, Jarrod Hadfield  
> <j.hadfield at ed.ac.uk> wrote:
>> Hi Florian,
>>
>> This comes up regularly and the list (nearly) always stays silent.  
>> As far as
>> I am aware quasi models in lmer do not, and never have, given  
>> sensible
>> results. To model over-dispersion you can try fitting an  
>> observation-level
>> random effect. For example:
>>
>> data$resid<-as.factor(1:dim(data)[1])
>>
>> and fitting (1|resid) in the model formula.
>>
>> This year  I have reviewed four papers that have used quasi models  
>> in lmer,
>> and its no fun to tell the authors that their results may not be  
>> meaningful.
>> To paraphrase an earlier post, why are they there if they do not  
>> work - it's
>> irresponsible?
>
> I agree.  I should have removed them from lme4 long ago if I suspected
> that the results were not correct.
>
> I will do so (once I figure out how to forbid them).
>
>> On 8 Nov 2010, at 03:30, T. Florian Jaeger wrote:
>>
>>> Hi,
>>> I am analyzing some data that seems to require a quasibinomial  
>>> model,
>>> but the model returns incredibly small standard errors (and
>>> correspondingly inflated t-values) that do not seem to be justified
>>> given my data.
>>> I've been reading (I think) all available posts on problems with the
>>> quasi-binomial family in lme4. But I can't judge from the posts
>>> whether all issues with the  quasi-binomial models in lme4 are  
>>> assumed
>>> to be resolved. So, I am wondering, are there any known issues with
>>> quasi-binomial models in lme4?
>>>
>>> I am using
>>>
>>> Package:            lme4
>>> Version:            0.999375-35
>>> Date:               2010-08-18
>>>
>>> in environment:
>>>               _
>>> platform       i386-pc-mingw32
>>> arch           i386
>>> os             mingw32
>>> system         i386, mingw32
>>> status
>>> major          2
>>> minor          11.1
>>> year           2010
>>> month          05
>>> day            31
>>> svn rev        52157
>>> language       R
>>> version.string R version 2.11.1 (2010-05-31)
>>>
>>> cheers,
>>> Florian
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From mlarkin at rsmas.miami.edu  Tue Nov  9 18:05:31 2010
From: mlarkin at rsmas.miami.edu (Michael Larkin)
Date: Tue, 9 Nov 2010 12:05:31 -0500
Subject: [R-sig-ME] standardized residuals
Message-ID: <000001cb8030$51284410$f378cc30$@miami.edu>

Anyone use the standardized residuals function in R?  It is called stdres   

I can't get it to work.  It tells me there is no documentation for stdres.
I am assuming there is a package that I need to load.  I looked at the list
of packages and I can't find one for stdres.  It must be bundled in some
package.    

Any advice on how I can get stdres to work would be greatly appreciated.  

Mike



From malsburg at gmail.com  Tue Nov  9 18:33:05 2010
From: malsburg at gmail.com (Titus von der Malsburg)
Date: Tue, 9 Nov 2010 18:33:05 +0100
Subject: [R-sig-ME] standardized residuals
In-Reply-To: <000001cb8030$51284410$f378cc30$@miami.edu>
References: <000001cb8030$51284410$f378cc30$@miami.edu>
Message-ID: <AANLkTiky1xdmxHTh-U4jjX-52_b1=V+PTniROz3_tXp9@mail.gmail.com>

On Tue, Nov 9, 2010 at 6:05 PM, Michael Larkin <mlarkin at rsmas.miami.edu> wrote:
> I am assuming there is a package that I need to load. ?I looked at the list
> of packages and I can't find one for stdres. ?It must be bundled in some
> package.

'??stdres' tells me that this function lives in package MASS.

You could also have used rseek to find it:

  http://www.rseek.org

However, stdres doesn't seem to work with mer objects as returned by
the lmer function.

  Titus



From tiflo at csli.stanford.edu  Tue Nov  9 19:14:31 2010
From: tiflo at csli.stanford.edu (T. Florian Jaeger)
Date: Tue, 9 Nov 2010 10:14:31 -0800
Subject: [R-sig-ME] quasi-binomial family in lme4
In-Reply-To: <2CB7B52C-7F49-44D6-8183-F20A686557C2@ed.ac.uk>
References: <AANLkTi=3X-0Fv3QagVn=kYpk4B00BoZn8fM7CaH8SBVT@mail.gmail.com>
	<A7154ED7-0283-4AEC-BB4F-2358B1E3C2F1@ed.ac.uk>
	<AANLkTi=zM2UG2GFt9YCQrpCsY_gLam0ddz5aboHBk+P7@mail.gmail.com>
	<2CB7B52C-7F49-44D6-8183-F20A686557C2@ed.ac.uk>
Message-ID: <AANLkTik0+Uo+wvgesnQtOPRQRD3Cmiifo+nSPLizZOJo@mail.gmail.com>

Hi Jarrod and Doug,

thanks for the straightforward answers and for the suggestions of an
alternative. This is very helpful.

florian

On Tue, Nov 9, 2010 at 7:37 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
> Dear Doug,
>
> That would be very welcome. It might be nice for lmer to fit a residual term
> if quasi models are specified, since this now seems to be working?
>
> Cheers,
>
> Jarrod
>
>
>
>
> On 9 Nov 2010, at 15:26, Douglas Bates wrote:
>
>> On Tue, Nov 9, 2010 at 9:02 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk>
>> wrote:
>>>
>>> Hi Florian,
>>>
>>> This comes up regularly and the list (nearly) always stays silent. As far
>>> as
>>> I am aware quasi models in lmer do not, and never have, given sensible
>>> results. To model over-dispersion you can try fitting an
>>> observation-level
>>> random effect. For example:
>>>
>>> data$resid<-as.factor(1:dim(data)[1])
>>>
>>> and fitting (1|resid) in the model formula.
>>>
>>> This year ?I have reviewed four papers that have used quasi models in
>>> lmer,
>>> and its no fun to tell the authors that their results may not be
>>> meaningful.
>>> To paraphrase an earlier post, why are they there if they do not work -
>>> it's
>>> irresponsible?
>>
>> I agree. ?I should have removed them from lme4 long ago if I suspected
>> that the results were not correct.
>>
>> I will do so (once I figure out how to forbid them).
>>
>>> On 8 Nov 2010, at 03:30, T. Florian Jaeger wrote:
>>>
>>>> Hi,
>>>> I am analyzing some data that seems to require a quasibinomial model,
>>>> but the model returns incredibly small standard errors (and
>>>> correspondingly inflated t-values) that do not seem to be justified
>>>> given my data.
>>>> I've been reading (I think) all available posts on problems with the
>>>> quasi-binomial family in lme4. But I can't judge from the posts
>>>> whether all issues with the ?quasi-binomial models in lme4 are assumed
>>>> to be resolved. So, I am wondering, are there any known issues with
>>>> quasi-binomial models in lme4?
>>>>
>>>> I am using
>>>>
>>>> Package: ? ? ? ? ? ?lme4
>>>> Version: ? ? ? ? ? ?0.999375-35
>>>> Date: ? ? ? ? ? ? ? 2010-08-18
>>>>
>>>> in environment:
>>>> ? ? ? ? ? ? ?_
>>>> platform ? ? ? i386-pc-mingw32
>>>> arch ? ? ? ? ? i386
>>>> os ? ? ? ? ? ? mingw32
>>>> system ? ? ? ? i386, mingw32
>>>> status
>>>> major ? ? ? ? ?2
>>>> minor ? ? ? ? ?11.1
>>>> year ? ? ? ? ? 2010
>>>> month ? ? ? ? ?05
>>>> day ? ? ? ? ? ?31
>>>> svn rev ? ? ? ?52157
>>>> language ? ? ? R
>>>> version.string R version 2.11.1 (2010-05-31)
>>>>
>>>> cheers,
>>>> Florian
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>>
>>> --
>>> The University of Edinburgh is a charitable body, registered in
>>> Scotland, with registration number SC005336.
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>



From kevin.thorpe at utoronto.ca  Wed Nov 10 02:45:44 2010
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Tue, 9 Nov 2010 20:45:44 -0500
Subject: [R-sig-ME] Is there a problem with the lme4a package at R-Forge
Message-ID: <201011092045.45141.kevin.thorpe@utoronto.ca>

I just upgraded my version of R to 

R version 2.12.0 Patched (2010-11-07 r53537)
Platform: i686-pc-linux-gnu (32-bit)

So that I could install the current lme4a.  Earlier tonight, the package 
seemed to be available, but as of 20:40 EST, it seems not to be.

> install.packages("lme4a", repos="http://R-Forge.R-project.org")
Warning message:
In getDependencies(pkgs, dependencies, available, lib) :
  package 'lme4a' is not available

Also, downloading the package source (from the R-forge link) takes me to "Page 
not Found"

Anyone know what's going on?

-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016



From djmuser at gmail.com  Wed Nov 10 04:13:04 2010
From: djmuser at gmail.com (Dennis Murphy)
Date: Tue, 9 Nov 2010 19:13:04 -0800
Subject: [R-sig-ME] standardized residuals
In-Reply-To: <000001cb8030$51284410$f378cc30$@miami.edu>
References: <000001cb8030$51284410$f378cc30$@miami.edu>
Message-ID: <AANLkTi=fGaErjhnvDqWFEzyJf+tbEFGfJLG9f15OSm8P@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101109/0cd0010e/attachment.pl>

From frederic.gosselin at cemagref.fr  Wed Nov 10 08:39:57 2010
From: frederic.gosselin at cemagref.fr (Gosselin Frederic)
Date: Wed, 10 Nov 2010 08:39:57 +0100
Subject: [R-sig-ME] quasi-binomial family in lme4
Message-ID: <D74CFE08A4F86B45870D14844A636E900138AF17@murier.nogent.cemagref.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101110/4e4a75d5/attachment.pl>

From john.maindonald at anu.edu.au  Wed Nov 10 09:50:50 2010
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Wed, 10 Nov 2010 19:50:50 +1100
Subject: [R-sig-ME] quasi-binomial family in lme4
In-Reply-To: <D74CFE08A4F86B45870D14844A636E900138AF17@murier.nogent.cemagref.fr>
References: <D74CFE08A4F86B45870D14844A636E900138AF17@murier.nogent.cemagref.fr>
Message-ID: <02A63C09-0121-4DCE-8BD5-1AA7029A1278@anu.edu.au>

I wonder if you have compared the results that you quote 
with the result you get with observation level random effects
in a poisson model. 

As I see it, use of observation level random effects should, 
unless there is evidence that a multiplicative effect on the 
scale of the response is a better fit, replace use of the quasi- 
models in glm() as well as in generalised linear mixed models.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 10/11/2010, at 6:39 PM, Gosselin Frederic wrote:

> Hi Florian,
> 
> a different perpsective on the quasi-likelihood debate - that comes out sporadically on this list:
> 
> (i) I globally agree with the previous repliers that a fully probabilistic solution looks better - at least aesthetically - than a quasi-likelihood;
> 
> (ii) however, as I have already mentioned on the list (cf. below), earlier versions of lme4 give much more sensible results than the latest versions:
> http://markmail.org/message/s4abxhhdacqjkunm
> 
> This is why in the following papers:
> Elek Z., Dauffy-Richard & Gosselin F., 2010, Carabid species responses to hybrid poplar plantation in floodplains in France, Forest Ecology and Management, 260, 9, p. 1446-1455.
> 
> and
> 
> Vuidot A., Paillet Y., Archaux F. & Gosselin F. (In Press) Influence of tree characteristics and forest management on tree microhabitats in France, Biological Conservation.
> 
> we used version the R version 2.5.1 and the associated lme4 version (here with quasi-poisson, not quasi-bionomial).
> 
> Hope this helps.
> 
> Sincerely,
> 
> Fr?d?ric Gosselin 
> Engineer & Researcher (PhD) in Forest Ecology 
> Cemagref 
> Domaine des Barres 
> F-45290 Nogent sur Vernisson 
> France 
> 
> http://www.cemagref.fr/les-contacts/les-pages-personnelles-professionnelles/gosselin-frederic/english-short-scientific-cv
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From frederic.gosselin at cemagref.fr  Wed Nov 10 10:20:57 2010
From: frederic.gosselin at cemagref.fr (Gosselin Frederic)
Date: Wed, 10 Nov 2010 10:20:57 +0100
Subject: [R-sig-ME] quasi-binomial family in lme4
In-Reply-To: <02A63C09-0121-4DCE-8BD5-1AA7029A1278@anu.edu.au>
References: <D74CFE08A4F86B45870D14844A636E900138AF17@murier.nogent.cemagref.fr>
	<02A63C09-0121-4DCE-8BD5-1AA7029A1278@anu.edu.au>
Message-ID: <D74CFE08A4F86B45870D14844A636E900138AF1E@murier.nogent.cemagref.fr>

Dear Colleague,

good question:

the commands are under R2.5.1:
************************************************************************
library(lme4)
cbppbis<-cbind.data.frame(cbpp,Id=as.factor(1:dim(cbpp)[1]))
gm1 <- lmer(incidence ~ period + (1 | herd), family = quasipoisson, data = cbpp)
summary(gm1)

gm2 <- lmer(incidence ~ period + (1 | Id/herd), family = poisson, data = cbppbis)
summary(gm2)
**************************************************************************
(fope it is declared in the good order for the random effects in gm2)

The results do show a slight discrepancy between both methods:

*************************************************************************
> summary(gm1)
Generalized linear mixed model fit using Laplace 
Formula: incidence ~ period + (1 | herd) 
   Data: cbpp 
 Family: quasipoisson(log link)
   AIC   BIC logLik deviance
 112.2 122.3 -51.11    102.2
Random effects:
 Groups   Name        Variance Std.Dev.
 herd     (Intercept) 0.35085  0.59233 
 Residual             1.40470  1.18520 
number of obs: 56, groups: herd, 15

Fixed effects:
            Estimate Std. Error t value
(Intercept)   1.2812     0.2200   5.824
period2      -1.1240     0.3315  -3.391
period3      -1.3203     0.3579  -3.689
period4      -1.9477     0.4808  -4.051

Correlation of Fixed Effects:
        (Intr) perid2 perid3
period2 -0.339              
period3 -0.314  0.219       
period4 -0.233  0.163  0.151




> summary(gm2)
Generalized linear mixed model fit using Laplace 
Formula: incidence ~ period + (1 | Id/herd) 
   Data: cbppbis 
 Family: poisson(log link)
   AIC   BIC logLik deviance
 102.2 114.4 -45.11    90.21
Random effects:
 Groups  Name        Variance Std.Dev.
 herd:Id (Intercept) 0.29608  0.54413 
 Id      (Intercept) 0.29608  0.54413 
number of obs: 56, groups: herd:Id, 56; Id, 56

Estimated scale (compare to  1 )  0.9249959 

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)   1.1149     0.2476   4.503 6.69e-06 ***
period2      -1.2013     0.4184  -2.871 0.004089 ** 
period3      -1.4224     0.4378  -3.249 0.001159 ** 
period4      -2.0089     0.5294  -3.795 0.000148 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Correlation of Fixed Effects:
        (Intr) perid2 perid3
period2 -0.592              
period3 -0.565  0.335       
period4 -0.468  0.277  0.264
************************************************************************

The estimates and the standard errors are not exactly the same - which might not be unlogical given that the relationship between variance and mean is not the same in both models. They however are not very far one from the other.

Of course, this needs further investigation.

I remember of a paper that motivated the use of the quasi-poisson method based on empirical relationships between the residual variance and the mean:

Ver Hoef J.M. et Boveng P.L., 2007, Quasi-poisson vs. negative binomial regression: How should we model overdispersed count data?, Ecology, 88, 11, p. 2766-2772.

Sincerely,

Fr?d?ric

-----Message d'origine-----
De : John Maindonald [mailto:john.maindonald at anu.edu.au] 
Envoy? : mercredi 10 novembre 2010 09:51
? : Gosselin Frederic
Cc : r-sig-mixed-models at r-project.org; tiflo at csli.stanford.edu
Objet : Re: [R-sig-ME] quasi-binomial family in lme4

I wonder if you have compared the results that you quote with the result you get with observation level random effects in a poisson model. 

As I see it, use of observation level random effects should, unless there is evidence that a multiplicative effect on the scale of the response is a better fit, replace use of the quasi- models in glm() as well as in generalised linear mixed models.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194, John Dedman Mathematical Sciences Building (Building 27) Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 10/11/2010, at 6:39 PM, Gosselin Frederic wrote:

> Hi Florian,
> 
> a different perpsective on the quasi-likelihood debate - that comes out sporadically on this list:
> 
> (i) I globally agree with the previous repliers that a fully 
> probabilistic solution looks better - at least aesthetically - than a 
> quasi-likelihood;
> 
> (ii) however, as I have already mentioned on the list (cf. below), earlier versions of lme4 give much more sensible results than the latest versions:
> http://markmail.org/message/s4abxhhdacqjkunm
> 
> This is why in the following papers:
> Elek Z., Dauffy-Richard & Gosselin F., 2010, Carabid species responses to hybrid poplar plantation in floodplains in France, Forest Ecology and Management, 260, 9, p. 1446-1455.
> 
> and
> 
> Vuidot A., Paillet Y., Archaux F. & Gosselin F. (In Press) Influence of tree characteristics and forest management on tree microhabitats in France, Biological Conservation.
> 
> we used version the R version 2.5.1 and the associated lme4 version (here with quasi-poisson, not quasi-bionomial).
> 
> Hope this helps.
> 
> Sincerely,
> 
> Fr?d?ric Gosselin
> Engineer & Researcher (PhD) in Forest Ecology Cemagref Domaine des 
> Barres F-45290 Nogent sur Vernisson France
> 
> http://www.cemagref.fr/les-contacts/les-pages-personnelles-professionn
> elles/gosselin-frederic/english-short-scientific-cv
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From j.hadfield at ed.ac.uk  Wed Nov 10 10:53:32 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 10 Nov 2010 09:53:32 +0000
Subject: [R-sig-ME] quasi-binomial family in lme4
In-Reply-To: <D74CFE08A4F86B45870D14844A636E900138AF1E@murier.nogent.cemagref.fr>
References: <D74CFE08A4F86B45870D14844A636E900138AF17@murier.nogent.cemagref.fr>
	<02A63C09-0121-4DCE-8BD5-1AA7029A1278@anu.edu.au>
	<D74CFE08A4F86B45870D14844A636E900138AF1E@murier.nogent.cemagref.fr>
Message-ID: <20101110095332.35702sr5onyou6ck@www.staffmail.ed.ac.uk>

Hi,

It seems worrying to me that the Herd:Id estimate and the Id estimate  
are exactly the same. I get a (slightly) different estimate with  
version 0.999375-35 on Linux, but again the estimates are identical.  
MCMCglmm fitting the same model gives a very different answer.

Cheers,

Jarrod



> summary(gm2)
Generalized linear mixed model fit by the Laplace approximation
Formula: incidence ~ period + (1 | Id/herd)
    Data: cbpp
    AIC   BIC logLik deviance
  102.2 114.4 -45.11    90.21
Random effects:
  Groups  Name        Variance Std.Dev.
  herd:Id (Intercept) 0.29654  0.54456
  Id      (Intercept) 0.29654  0.54456
Number of obs: 56, groups: herd:Id, 56; Id, 56

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)
(Intercept)   1.1129     0.2477   4.492 7.04e-06 ***
period2      -1.1969     0.4185  -2.860 0.004233 **
period3      -1.4223     0.4381  -3.246 0.001169 **
period4      -2.0049     0.5292  -3.788 0.000152 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
         (Intr) perid2 perid3
period2 -0.592
period3 -0.565  0.335
period4 -0.468  0.277  0.265

Using a parameter expanded prior in order to improve mixing as the  
herd variance approaches zero:

prior<-list(R=list(V=1, nu=0), G=list(G1=list(V=1, nu=1, alpha.mu=0,  
alpha.V=1000)))

mcmc2<-MCMCglmm(incidence~period, random=~herd, family="poisson", data=cbpp)

> summary(mcmc2)

  Iterations = 12991
  Thinning interval  = 3001
  Sample size  = 1000

  DIC: 175.9590

  G-structure:  ~herd

      post.mean  l-95% CI u-95% CI eff.samp
herd   0.01433 1.067e-16   0.0713    61.58

  R-structure:  ~units

       post.mean l-95% CI u-95% CI eff.samp
units    0.7347   0.1564    1.421    222.9

  Location effects: incidence ~ period

             post.mean l-95% CI u-95% CI eff.samp  pMCMC
(Intercept)    1.0749   0.4584   1.5987    844.5  0.002 **
period2       -1.2054  -2.0862  -0.3556    771.8  0.004 **
period3       -1.4568  -2.4362  -0.4839    674.8  0.004 **
period4       -2.0584  -3.1851  -0.9430    446.5 <0.001 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


Quoting Gosselin Frederic <frederic.gosselin at cemagref.fr>:

> Dear Colleague,
>
> good question:
>
> the commands are under R2.5.1:
> ************************************************************************
> library(lme4)
> cbppbis<-cbind.data.frame(cbpp,Id=as.factor(1:dim(cbpp)[1]))
> gm1 <- lmer(incidence ~ period + (1 | herd), family = quasipoisson,  
> data = cbpp)
> summary(gm1)
>
> gm2 <- lmer(incidence ~ period + (1 | Id/herd), family = poisson,  
> data = cbppbis)
> summary(gm2)
> **************************************************************************
> (fope it is declared in the good order for the random effects in gm2)
>
> The results do show a slight discrepancy between both methods:
>
> *************************************************************************
>> summary(gm1)
> Generalized linear mixed model fit using Laplace
> Formula: incidence ~ period + (1 | herd)
>    Data: cbpp
>  Family: quasipoisson(log link)
>    AIC   BIC logLik deviance
>  112.2 122.3 -51.11    102.2
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  herd     (Intercept) 0.35085  0.59233
>  Residual             1.40470  1.18520
> number of obs: 56, groups: herd, 15
>
> Fixed effects:
>             Estimate Std. Error t value
> (Intercept)   1.2812     0.2200   5.824
> period2      -1.1240     0.3315  -3.391
> period3      -1.3203     0.3579  -3.689
> period4      -1.9477     0.4808  -4.051
>
> Correlation of Fixed Effects:
>         (Intr) perid2 perid3
> period2 -0.339
> period3 -0.314  0.219
> period4 -0.233  0.163  0.151
>
>
>
>
>> summary(gm2)
> Generalized linear mixed model fit using Laplace
> Formula: incidence ~ period + (1 | Id/herd)
>    Data: cbppbis
>  Family: poisson(log link)
>    AIC   BIC logLik deviance
>  102.2 114.4 -45.11    90.21
> Random effects:
>  Groups  Name        Variance Std.Dev.
>  herd:Id (Intercept) 0.29608  0.54413
>  Id      (Intercept) 0.29608  0.54413
> number of obs: 56, groups: herd:Id, 56; Id, 56
>
> Estimated scale (compare to  1 )  0.9249959
>
> Fixed effects:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept)   1.1149     0.2476   4.503 6.69e-06 ***
> period2      -1.2013     0.4184  -2.871 0.004089 **
> period3      -1.4224     0.4378  -3.249 0.001159 **
> period4      -2.0089     0.5294  -3.795 0.000148 ***
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
> Correlation of Fixed Effects:
>         (Intr) perid2 perid3
> period2 -0.592
> period3 -0.565  0.335
> period4 -0.468  0.277  0.264
> ************************************************************************
>
> The estimates and the standard errors are not exactly the same -  
> which might not be unlogical given that the relationship between  
> variance and mean is not the same in both models. They however are  
> not very far one from the other.
>
> Of course, this needs further investigation.
>
> I remember of a paper that motivated the use of the quasi-poisson  
> method based on empirical relationships between the residual  
> variance and the mean:
>
> Ver Hoef J.M. et Boveng P.L., 2007, Quasi-poisson vs. negative  
> binomial regression: How should we model overdispersed count data?,  
> Ecology, 88, 11, p. 2766-2772.
>
> Sincerely,
>
> Fr?d?ric
>
> -----Message d'origine-----
> De : John Maindonald [mailto:john.maindonald at anu.edu.au]
> Envoy? : mercredi 10 novembre 2010 09:51
> ? : Gosselin Frederic
> Cc : r-sig-mixed-models at r-project.org; tiflo at csli.stanford.edu
> Objet : Re: [R-sig-ME] quasi-binomial family in lme4
>
> I wonder if you have compared the results that you quote with the  
> result you get with observation level random effects in a poisson  
> model.
>
> As I see it, use of observation level random effects should, unless  
> there is evidence that a multiplicative effect on the scale of the  
> response is a better fit, replace use of the quasi- models in glm()  
> as well as in generalised linear mixed models.
>
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194, John Dedman  
> Mathematical Sciences Building (Building 27) Australian National  
> University, Canberra ACT 0200.
> http://www.maths.anu.edu.au/~johnm
>
> On 10/11/2010, at 6:39 PM, Gosselin Frederic wrote:
>
>> Hi Florian,
>>
>> a different perpsective on the quasi-likelihood debate - that comes  
>> out sporadically on this list:
>>
>> (i) I globally agree with the previous repliers that a fully
>> probabilistic solution looks better - at least aesthetically - than a
>> quasi-likelihood;
>>
>> (ii) however, as I have already mentioned on the list (cf. below),  
>> earlier versions of lme4 give much more sensible results than the  
>> latest versions:
>> http://markmail.org/message/s4abxhhdacqjkunm
>>
>> This is why in the following papers:
>> Elek Z., Dauffy-Richard & Gosselin F., 2010, Carabid species  
>> responses to hybrid poplar plantation in floodplains in France,  
>> Forest Ecology and Management, 260, 9, p. 1446-1455.
>>
>> and
>>
>> Vuidot A., Paillet Y., Archaux F. & Gosselin F. (In Press)  
>> Influence of tree characteristics and forest management on tree  
>> microhabitats in France, Biological Conservation.
>>
>> we used version the R version 2.5.1 and the associated lme4 version  
>> (here with quasi-poisson, not quasi-bionomial).
>>
>> Hope this helps.
>>
>> Sincerely,
>>
>> Fr?d?ric Gosselin
>> Engineer & Researcher (PhD) in Forest Ecology Cemagref Domaine des
>> Barres F-45290 Nogent sur Vernisson France
>>
>> http://www.cemagref.fr/les-contacts/les-pages-personnelles-professionn
>> elles/gosselin-frederic/english-short-scientific-cv
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From aidan at keane.org.uk  Wed Nov 10 11:11:55 2010
From: aidan at keane.org.uk (Aidan Keane)
Date: Wed, 10 Nov 2010 10:11:55 +0000
Subject: [R-sig-ME] quasi-binomial family in lme4
In-Reply-To: <20101110095332.35702sr5onyou6ck@www.staffmail.ed.ac.uk>
References: <D74CFE08A4F86B45870D14844A636E900138AF17@murier.nogent.cemagref.fr>
	<02A63C09-0121-4DCE-8BD5-1AA7029A1278@anu.edu.au>
	<D74CFE08A4F86B45870D14844A636E900138AF1E@murier.nogent.cemagref.fr>
	<20101110095332.35702sr5onyou6ck@www.staffmail.ed.ac.uk>
Message-ID: <AANLkTi=MALR_xDy5eU9gPG5s5BcmCG-VmgMtki-iueDK@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101110/137cbdc5/attachment.pl>

From j.hadfield at ed.ac.uk  Wed Nov 10 11:18:13 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 10 Nov 2010 10:18:13 +0000
Subject: [R-sig-ME] quasi-binomial family in lme4
In-Reply-To: <20101110095332.35702sr5onyou6ck@www.staffmail.ed.ac.uk>
References: <D74CFE08A4F86B45870D14844A636E900138AF17@murier.nogent.cemagref.fr>
	<02A63C09-0121-4DCE-8BD5-1AA7029A1278@anu.edu.au>
	<D74CFE08A4F86B45870D14844A636E900138AF1E@murier.nogent.cemagref.fr>
	<20101110095332.35702sr5onyou6ck@www.staffmail.ed.ac.uk>
Message-ID: <3DCC1460-8062-4820-AA94-652A75D3C444@ed.ac.uk>

I see the problem - the gm2 from the earlier post should have read  
herd/Id not Id/herd. Given herd:Id and Id are not identifiable from  
the likelihood then I think lmer should give a warning in these  
instances.


On 10 Nov 2010, at 09:53, Jarrod Hadfield wrote:

> Hi,
>
> It seems worrying to me that the Herd:Id estimate and the Id  
> estimate are exactly the same. I get a (slightly) different estimate  
> with version 0.999375-35 on Linux, but again the estimates are  
> identical. MCMCglmm fitting the same model gives a very different  
> answer.
>
> Cheers,
>
> Jarrod
>
>
>
>> summary(gm2)
> Generalized linear mixed model fit by the Laplace approximation
> Formula: incidence ~ period + (1 | Id/herd)
>   Data: cbpp
>   AIC   BIC logLik deviance
> 102.2 114.4 -45.11    90.21
> Random effects:
> Groups  Name        Variance Std.Dev.
> herd:Id (Intercept) 0.29654  0.54456
> Id      (Intercept) 0.29654  0.54456
> Number of obs: 56, groups: herd:Id, 56; Id, 56
>
> Fixed effects:
>            Estimate Std. Error z value Pr(>|z|)
> (Intercept)   1.1129     0.2477   4.492 7.04e-06 ***
> period2      -1.1969     0.4185  -2.860 0.004233 **
> period3      -1.4223     0.4381  -3.246 0.001169 **
> period4      -2.0049     0.5292  -3.788 0.000152 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>        (Intr) perid2 perid3
> period2 -0.592
> period3 -0.565  0.335
> period4 -0.468  0.277  0.265
>
> Using a parameter expanded prior in order to improve mixing as the  
> herd variance approaches zero:
>
> prior<-list(R=list(V=1, nu=0), G=list(G1=list(V=1, nu=1, alpha.mu=0,  
> alpha.V=1000)))
>
> mcmc2<-MCMCglmm(incidence~period, random=~herd, family="poisson",  
> data=cbpp)
>
>> summary(mcmc2)
>
> Iterations = 12991
> Thinning interval  = 3001
> Sample size  = 1000
>
> DIC: 175.9590
>
> G-structure:  ~herd
>
>     post.mean  l-95% CI u-95% CI eff.samp
> herd   0.01433 1.067e-16   0.0713    61.58
>
> R-structure:  ~units
>
>      post.mean l-95% CI u-95% CI eff.samp
> units    0.7347   0.1564    1.421    222.9
>
> Location effects: incidence ~ period
>
>            post.mean l-95% CI u-95% CI eff.samp  pMCMC
> (Intercept)    1.0749   0.4584   1.5987    844.5  0.002 **
> period2       -1.2054  -2.0862  -0.3556    771.8  0.004 **
> period3       -1.4568  -2.4362  -0.4839    674.8  0.004 **
> period4       -2.0584  -3.1851  -0.9430    446.5 <0.001 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>
> Quoting Gosselin Frederic <frederic.gosselin at cemagref.fr>:
>
>> Dear Colleague,
>>
>> good question:
>>
>> the commands are under R2.5.1:
>> ************************************************************************
>> library(lme4)
>> cbppbis<-cbind.data.frame(cbpp,Id=as.factor(1:dim(cbpp)[1]))
>> gm1 <- lmer(incidence ~ period + (1 | herd), family = quasipoisson,  
>> data = cbpp)
>> summary(gm1)
>>
>> gm2 <- lmer(incidence ~ period + (1 | Id/herd), family = poisson,  
>> data = cbppbis)
>> summary(gm2)
>> **************************************************************************
>> (fope it is declared in the good order for the random effects in gm2)
>>
>> The results do show a slight discrepancy between both methods:
>>
>> *************************************************************************
>>> summary(gm1)
>> Generalized linear mixed model fit using Laplace
>> Formula: incidence ~ period + (1 | herd)
>>   Data: cbpp
>> Family: quasipoisson(log link)
>>   AIC   BIC logLik deviance
>> 112.2 122.3 -51.11    102.2
>> Random effects:
>> Groups   Name        Variance Std.Dev.
>> herd     (Intercept) 0.35085  0.59233
>> Residual             1.40470  1.18520
>> number of obs: 56, groups: herd, 15
>>
>> Fixed effects:
>>            Estimate Std. Error t value
>> (Intercept)   1.2812     0.2200   5.824
>> period2      -1.1240     0.3315  -3.391
>> period3      -1.3203     0.3579  -3.689
>> period4      -1.9477     0.4808  -4.051
>>
>> Correlation of Fixed Effects:
>>        (Intr) perid2 perid3
>> period2 -0.339
>> period3 -0.314  0.219
>> period4 -0.233  0.163  0.151
>>
>>
>>
>>
>>> summary(gm2)
>> Generalized linear mixed model fit using Laplace
>> Formula: incidence ~ period + (1 | Id/herd)
>>   Data: cbppbis
>> Family: poisson(log link)
>>   AIC   BIC logLik deviance
>> 102.2 114.4 -45.11    90.21
>> Random effects:
>> Groups  Name        Variance Std.Dev.
>> herd:Id (Intercept) 0.29608  0.54413
>> Id      (Intercept) 0.29608  0.54413
>> number of obs: 56, groups: herd:Id, 56; Id, 56
>>
>> Estimated scale (compare to  1 )  0.9249959
>>
>> Fixed effects:
>>            Estimate Std. Error z value Pr(>|z|)
>> (Intercept)   1.1149     0.2476   4.503 6.69e-06 ***
>> period2      -1.2013     0.4184  -2.871 0.004089 **
>> period3      -1.4224     0.4378  -3.249 0.001159 **
>> period4      -2.0089     0.5294  -3.795 0.000148 ***
>> ---
>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>
>> Correlation of Fixed Effects:
>>        (Intr) perid2 perid3
>> period2 -0.592
>> period3 -0.565  0.335
>> period4 -0.468  0.277  0.264
>> ************************************************************************
>>
>> The estimates and the standard errors are not exactly the same -  
>> which might not be unlogical given that the relationship between  
>> variance and mean is not the same in both models. They however are  
>> not very far one from the other.
>>
>> Of course, this needs further investigation.
>>
>> I remember of a paper that motivated the use of the quasi-poisson  
>> method based on empirical relationships between the residual  
>> variance and the mean:
>>
>> Ver Hoef J.M. et Boveng P.L., 2007, Quasi-poisson vs. negative  
>> binomial regression: How should we model overdispersed count data?,  
>> Ecology, 88, 11, p. 2766-2772.
>>
>> Sincerely,
>>
>> Fr?d?ric
>>
>> -----Message d'origine-----
>> De : John Maindonald [mailto:john.maindonald at anu.edu.au]
>> Envoy? : mercredi 10 novembre 2010 09:51
>> ? : Gosselin Frederic
>> Cc : r-sig-mixed-models at r-project.org; tiflo at csli.stanford.edu
>> Objet : Re: [R-sig-ME] quasi-binomial family in lme4
>>
>> I wonder if you have compared the results that you quote with the  
>> result you get with observation level random effects in a poisson  
>> model.
>>
>> As I see it, use of observation level random effects should, unless  
>> there is evidence that a multiplicative effect on the scale of the  
>> response is a better fit, replace use of the quasi- models in glm()  
>> as well as in generalised linear mixed models.
>>
>> John Maindonald             email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Mathematics & Its Applications, Room 1194, John Dedman  
>> Mathematical Sciences Building (Building 27) Australian National  
>> University, Canberra ACT 0200.
>> http://www.maths.anu.edu.au/~johnm
>>
>> On 10/11/2010, at 6:39 PM, Gosselin Frederic wrote:
>>
>>> Hi Florian,
>>>
>>> a different perpsective on the quasi-likelihood debate - that  
>>> comes out sporadically on this list:
>>>
>>> (i) I globally agree with the previous repliers that a fully
>>> probabilistic solution looks better - at least aesthetically -  
>>> than a
>>> quasi-likelihood;
>>>
>>> (ii) however, as I have already mentioned on the list (cf. below),  
>>> earlier versions of lme4 give much more sensible results than the  
>>> latest versions:
>>> http://markmail.org/message/s4abxhhdacqjkunm
>>>
>>> This is why in the following papers:
>>> Elek Z., Dauffy-Richard & Gosselin F., 2010, Carabid species  
>>> responses to hybrid poplar plantation in floodplains in France,  
>>> Forest Ecology and Management, 260, 9, p. 1446-1455.
>>>
>>> and
>>>
>>> Vuidot A., Paillet Y., Archaux F. & Gosselin F. (In Press)  
>>> Influence of tree characteristics and forest management on tree  
>>> microhabitats in France, Biological Conservation.
>>>
>>> we used version the R version 2.5.1 and the associated lme4  
>>> version (here with quasi-poisson, not quasi-bionomial).
>>>
>>> Hope this helps.
>>>
>>> Sincerely,
>>>
>>> Fr?d?ric Gosselin
>>> Engineer & Researcher (PhD) in Forest Ecology Cemagref Domaine des
>>> Barres F-45290 Nogent sur Vernisson France
>>>
>>> http://www.cemagref.fr/les-contacts/les-pages-personnelles-professionn
>>> elles/gosselin-frederic/english-short-scientific-cv
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
>
>
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From frederic.gosselin at cemagref.fr  Wed Nov 10 11:15:52 2010
From: frederic.gosselin at cemagref.fr (Gosselin Frederic)
Date: Wed, 10 Nov 2010 11:15:52 +0100
Subject: [R-sig-ME] quasi-binomial family in lme4
In-Reply-To: <AANLkTi=MALR_xDy5eU9gPG5s5BcmCG-VmgMtki-iueDK@mail.gmail.com>
References: <D74CFE08A4F86B45870D14844A636E900138AF17@murier.nogent.cemagref.fr>
	<02A63C09-0121-4DCE-8BD5-1AA7029A1278@anu.edu.au>
	<D74CFE08A4F86B45870D14844A636E900138AF1E@murier.nogent.cemagref.fr>
	<20101110095332.35702sr5onyou6ck@www.staffmail.ed.ac.uk>
	<AANLkTi=MALR_xDy5eU9gPG5s5BcmCG-VmgMtki-iueDK@mail.gmail.com>
Message-ID: <D74CFE08A4F86B45870D14844A636E900138AF22@murier.nogent.cemagref.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101110/81170bf9/attachment.pl>

From cristian.pasquaretta at unipv.it  Wed Nov 10 13:54:36 2010
From: cristian.pasquaretta at unipv.it (Cristian Pasquaretta)
Date: Wed, 10 Nov 2010 13:54:36 +0100
Subject: [R-sig-ME] crossed random effect
Message-ID: <AANLkTikqwPnQX2YgSgdOmogi-o9J5=93fqkfvaWC-0NO@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101110/8fa7bc3f/attachment.pl>

From kevin.thorpe at utoronto.ca  Wed Nov 10 14:19:17 2010
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Wed, 10 Nov 2010 08:19:17 -0500
Subject: [R-sig-ME] Is there a problem with the lme4a package at R-Forge
In-Reply-To: <201011092045.45141.kevin.thorpe@utoronto.ca>
References: <201011092045.45141.kevin.thorpe@utoronto.ca>
Message-ID: <201011100819.17530.kevin.thorpe@utoronto.ca>

On November 9, 2010 08:45:44 pm Kevin E. Thorpe wrote:
> I just upgraded my version of R to
>
> R version 2.12.0 Patched (2010-11-07 r53537)
> Platform: i686-pc-linux-gnu (32-bit)
>
> So that I could install the current lme4a.  Earlier tonight, the package
> seemed to be available, but as of 20:40 EST, it seems not to be.
>
> > install.packages("lme4a", repos="http://R-Forge.R-project.org")
>
> Warning message:
> In getDependencies(pkgs, dependencies, available, lib) :
>   package 'lme4a' is not available
>
> Also, downloading the package source (from the R-forge link) takes me to
> "Page not Found"
>
> Anyone know what's going on?

I searched my saved mail, since this problem seemed like Deja Vu all over 
again.  I found the link to the SVN instructions, and svn seems to have found 
the package.

-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016



From kevin.thorpe at utoronto.ca  Wed Nov 10 14:33:51 2010
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Wed, 10 Nov 2010 08:33:51 -0500
Subject: [R-sig-ME] Is there a problem with the lme4a package at R-Forge
In-Reply-To: <201011100819.17530.kevin.thorpe@utoronto.ca>
References: <201011092045.45141.kevin.thorpe@utoronto.ca>
	<201011100819.17530.kevin.thorpe@utoronto.ca>
Message-ID: <201011100833.52029.kevin.thorpe@utoronto.ca>

On November 10, 2010 08:19:17 am Kevin E. Thorpe wrote:
> On November 9, 2010 08:45:44 pm Kevin E. Thorpe wrote:
> > I just upgraded my version of R to
> >
> > R version 2.12.0 Patched (2010-11-07 r53537)
> > Platform: i686-pc-linux-gnu (32-bit)
> >
> > So that I could install the current lme4a.  Earlier tonight, the package
> > seemed to be available, but as of 20:40 EST, it seems not to be.
> >
> > > install.packages("lme4a", repos="http://R-Forge.R-project.org")
> >
> > Warning message:
> > In getDependencies(pkgs, dependencies, available, lib) :
> >   package 'lme4a' is not available
> >
> > Also, downloading the package source (from the R-forge link) takes me to
> > "Page not Found"
> >
> > Anyone know what's going on?
>
> I searched my saved mail, since this problem seemed like Deja Vu all over
> again.  I found the link to the SVN instructions, and svn seems to have
> found the package.

OK, the build fails on my system.  I have the dependencies up-to-date.

> sessionInfo()
R version 2.12.0 Patched (2010-11-07 r53537)
Platform: i686-pc-linux-gnu (32-bit)

locale:
 [1] LC_CTYPE=en_US       LC_NUMERIC=C         LC_TIME=en_US
 [4] LC_COLLATE=C         LC_MONETARY=C        LC_MESSAGES=en_US
 [7] LC_PAPER=en_US       LC_NAME=C            LC_ADDRESS=C
[10] LC_TELEPHONE=C       LC_MEASUREMENT=en_US LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] minqa_1.1.9        Rcpp_0.8.8         MatrixModels_0.2-1 
Matrix_0.999375-44
[5] lattice_0.19-13

loaded via a namespace (and not attached):
[1] grid_2.12.0  tools_2.12.0

Here are the error messages from R CMD INSTALL.

g++ -I/usr/local/lib/R/include  -I/usr/local/include -I"/usr/local/lib/R/library/Matrix/include" -I"/usr/local/lib/R/library/Rcpp/include"   -fpic  -g -O2 -c 
glmFamily.cpp -o glmFamily.o
glmFamily.cpp: In function 'void _rcpp_module_glm_init()':
glmFamily.cpp:122: error: 'class Rcpp::class_<glm::glmFamily>' has no member 
named 'constructor'
glmFamily.cpp:122: error: 'init_1' was not declared in this scope
glmFamily.cpp:122: error: expected primary-expression before '>' token
glmFamily.cpp:122: error: expected primary-expression before ')' token
/usr/local/lib/R/library/Rcpp/include/Rcpp/Module.h: In member 
function 'SEXPREC* Rcpp::class_<Class>::newInstance(SEXPREC**, int) [with 
Class = glm::glmFamily]':
glmFamily.cpp:130:   instantiated from here
/usr/local/lib/R/library/Rcpp/include/Rcpp/Module.h:242: error: no matching 
function for call to 'glm::glmFamily::glmFamily()'
glmFamily.cpp:21: note: candidates are: glm::glmFamily::glmFamily(SEXPREC*)
glmFamily.h:12: note:                 glm::glmFamily::glmFamily(const 
glm::glmFamily&)
make: *** [glmFamily.o] Error 1
ERROR: compilation failed for package 'lme4a'
* removing '/usr/local/lib/R/library/lme4a'

Has anyone else encountered this?


-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016



From bbolker at gmail.com  Wed Nov 10 14:55:22 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 10 Nov 2010 08:55:22 -0500
Subject: [R-sig-ME] Is there a problem with the lme4a package at R-Forge
In-Reply-To: <201011100833.52029.kevin.thorpe@utoronto.ca>
References: <201011092045.45141.kevin.thorpe@utoronto.ca>	<201011100819.17530.kevin.thorpe@utoronto.ca>
	<201011100833.52029.kevin.thorpe@utoronto.ca>
Message-ID: <4CDAA44A.3070008@gmail.com>

On 10-11-10 08:33 AM, Kevin E. Thorpe wrote:
> On November 10, 2010 08:19:17 am Kevin E. Thorpe wrote:
>> On November 9, 2010 08:45:44 pm Kevin E. Thorpe wrote:
>>> I just upgraded my version of R to
>>>
>>> R version 2.12.0 Patched (2010-11-07 r53537)
>>> Platform: i686-pc-linux-gnu (32-bit)
>>>
>>> So that I could install the current lme4a.  Earlier tonight, the package
>>> seemed to be available, but as of 20:40 EST, it seems not to be.
>>>
>>>> install.packages("lme4a", repos="http://R-Forge.R-project.org")
>>>
>>> Warning message:
>>> In getDependencies(pkgs, dependencies, available, lib) :
>>>   package 'lme4a' is not available
>>>
>>> Also, downloading the package source (from the R-forge link) takes me to
>>> "Page not Found"
>>>
>>> Anyone know what's going on?
>>
>> I searched my saved mail, since this problem seemed like Deja Vu all over
>> again.  I found the link to the SVN instructions, and svn seems to have
>> found the package.
> 
> OK, the build fails on my system.  I have the dependencies up-to-date.
> 
>> sessionInfo()
> R version 2.12.0 Patched (2010-11-07 r53537)
> Platform: i686-pc-linux-gnu (32-bit)
> 
> locale:
>  [1] LC_CTYPE=en_US       LC_NUMERIC=C         LC_TIME=en_US
>  [4] LC_COLLATE=C         LC_MONETARY=C        LC_MESSAGES=en_US
>  [7] LC_PAPER=en_US       LC_NAME=C            LC_ADDRESS=C
> [10] LC_TELEPHONE=C       LC_MEASUREMENT=en_US LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] minqa_1.1.9        Rcpp_0.8.8         MatrixModels_0.2-1 
> Matrix_0.999375-44
> [5] lattice_0.19-13
> 
> loaded via a namespace (and not attached):
> [1] grid_2.12.0  tools_2.12.0
> 
> Here are the error messages from R CMD INSTALL.
> 
> g++ -I/usr/local/lib/R/include  -I/usr/local/include -I"/usr/local/lib/R/library/Matrix/include" -I"/usr/local/lib/R/library/Rcpp/include"   -fpic  -g -O2 -c 
> glmFamily.cpp -o glmFamily.o
> glmFamily.cpp: In function 'void _rcpp_module_glm_init()':
> glmFamily.cpp:122: error: 'class Rcpp::class_<glm::glmFamily>' has no member 
> named 'constructor'
> glmFamily.cpp:122: error: 'init_1' was not declared in this scope
> glmFamily.cpp:122: error: expected primary-expression before '>' token
> glmFamily.cpp:122: error: expected primary-expression before ')' token
> /usr/local/lib/R/library/Rcpp/include/Rcpp/Module.h: In member 
> function 'SEXPREC* Rcpp::class_<Class>::newInstance(SEXPREC**, int) [with 
> Class = glm::glmFamily]':
> glmFamily.cpp:130:   instantiated from here
> /usr/local/lib/R/library/Rcpp/include/Rcpp/Module.h:242: error: no matching 
> function for call to 'glm::glmFamily::glmFamily()'
> glmFamily.cpp:21: note: candidates are: glm::glmFamily::glmFamily(SEXPREC*)
> glmFamily.h:12: note:                 glm::glmFamily::glmFamily(const 
> glm::glmFamily&)
> make: *** [glmFamily.o] Error 1
> ERROR: compilation failed for package 'lme4a'
> * removing '/usr/local/lib/R/library/lme4a'
> 
> Has anyone else encountered this?

  I get the same problem.  I certainly can't guarantee the results, but
reverting to release 1083

  svn update -r1083

  at least appears to allow the package to build/install (it doesn't
quite make it through the examples in R CMD check -- it actually looks
like the failure may be somewhere in lattice ... ?)

  It may be that one needs a bleeding-edge Rcpp to compile the latest
version ... I'm trying upgrading to Rcpp 0.8.8.1 now ...

  cheers
    Ben



From bates at stat.wisc.edu  Wed Nov 10 15:00:22 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 10 Nov 2010 08:00:22 -0600
Subject: [R-sig-ME] Is there a problem with the lme4a package at R-Forge
In-Reply-To: <201011100833.52029.kevin.thorpe@utoronto.ca>
References: <201011092045.45141.kevin.thorpe@utoronto.ca>
	<201011100819.17530.kevin.thorpe@utoronto.ca>
	<201011100833.52029.kevin.thorpe@utoronto.ca>
Message-ID: <AANLkTinxuDDHtV4URCM6tKoeUJ_Ap-uxtXQ0=DhUiUEf@mail.gmail.com>

The svn archive of the development version is, well, unstable.  You
need version 0.8.8.0 of Rcpp.  It think that is now the released
version.  I haven't updated the dependencies in the DESCRIPTION file
yet.

I suppose I should spawn yet another package to experiment with
reference classes and Romain's latest module magic in the Rcpp
package.

On Wed, Nov 10, 2010 at 7:33 AM, Kevin E. Thorpe
<kevin.thorpe at utoronto.ca> wrote:
> On November 10, 2010 08:19:17 am Kevin E. Thorpe wrote:
>> On November 9, 2010 08:45:44 pm Kevin E. Thorpe wrote:
>> > I just upgraded my version of R to
>> >
>> > R version 2.12.0 Patched (2010-11-07 r53537)
>> > Platform: i686-pc-linux-gnu (32-bit)
>> >
>> > So that I could install the current lme4a. ?Earlier tonight, the package
>> > seemed to be available, but as of 20:40 EST, it seems not to be.
>> >
>> > > install.packages("lme4a", repos="http://R-Forge.R-project.org")
>> >
>> > Warning message:
>> > In getDependencies(pkgs, dependencies, available, lib) :
>> > ? package 'lme4a' is not available
>> >
>> > Also, downloading the package source (from the R-forge link) takes me to
>> > "Page not Found"
>> >
>> > Anyone know what's going on?
>>
>> I searched my saved mail, since this problem seemed like Deja Vu all over
>> again. ?I found the link to the SVN instructions, and svn seems to have
>> found the package.
>
> OK, the build fails on my system. ?I have the dependencies up-to-date.
>
>> sessionInfo()
> R version 2.12.0 Patched (2010-11-07 r53537)
> Platform: i686-pc-linux-gnu (32-bit)
>
> locale:
> ?[1] LC_CTYPE=en_US ? ? ? LC_NUMERIC=C ? ? ? ? LC_TIME=en_US
> ?[4] LC_COLLATE=C ? ? ? ? LC_MONETARY=C ? ? ? ?LC_MESSAGES=en_US
> ?[7] LC_PAPER=en_US ? ? ? LC_NAME=C ? ? ? ? ? ?LC_ADDRESS=C
> [10] LC_TELEPHONE=C ? ? ? LC_MEASUREMENT=en_US LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
> other attached packages:
> [1] minqa_1.1.9 ? ? ? ?Rcpp_0.8.8 ? ? ? ? MatrixModels_0.2-1
> Matrix_0.999375-44
> [5] lattice_0.19-13
>
> loaded via a namespace (and not attached):
> [1] grid_2.12.0 ?tools_2.12.0
>
> Here are the error messages from R CMD INSTALL.
>
> g++ -I/usr/local/lib/R/include ?-I/usr/local/include -I"/usr/local/lib/R/library/Matrix/include" -I"/usr/local/lib/R/library/Rcpp/include" ? -fpic ?-g -O2 -c
> glmFamily.cpp -o glmFamily.o
> glmFamily.cpp: In function 'void _rcpp_module_glm_init()':
> glmFamily.cpp:122: error: 'class Rcpp::class_<glm::glmFamily>' has no member
> named 'constructor'
> glmFamily.cpp:122: error: 'init_1' was not declared in this scope
> glmFamily.cpp:122: error: expected primary-expression before '>' token
> glmFamily.cpp:122: error: expected primary-expression before ')' token
> /usr/local/lib/R/library/Rcpp/include/Rcpp/Module.h: In member
> function 'SEXPREC* Rcpp::class_<Class>::newInstance(SEXPREC**, int) [with
> Class = glm::glmFamily]':
> glmFamily.cpp:130: ? instantiated from here
> /usr/local/lib/R/library/Rcpp/include/Rcpp/Module.h:242: error: no matching
> function for call to 'glm::glmFamily::glmFamily()'
> glmFamily.cpp:21: note: candidates are: glm::glmFamily::glmFamily(SEXPREC*)
> glmFamily.h:12: note: ? ? ? ? ? ? ? ? glm::glmFamily::glmFamily(const
> glm::glmFamily&)
> make: *** [glmFamily.o] Error 1
> ERROR: compilation failed for package 'lme4a'
> * removing '/usr/local/lib/R/library/lme4a'
>
> Has anyone else encountered this?
>
>
> --
> Kevin E. Thorpe
> Biostatistician/Trialist, Knowledge Translation Program
> Assistant Professor, Dalla Lana School of Public Health
> University of Toronto
> email: kevin.thorpe at utoronto.ca ?Tel: 416.864.5776 ?Fax: 416.864.3016
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Wed Nov 10 15:01:55 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 10 Nov 2010 08:01:55 -0600
Subject: [R-sig-ME] Is there a problem with the lme4a package at R-Forge
In-Reply-To: <4CDAA44A.3070008@gmail.com>
References: <201011092045.45141.kevin.thorpe@utoronto.ca>
	<201011100819.17530.kevin.thorpe@utoronto.ca>
	<201011100833.52029.kevin.thorpe@utoronto.ca>
	<4CDAA44A.3070008@gmail.com>
Message-ID: <AANLkTinq45HJWuxN5rri=0thR4ckOhqSL7wahoHoFAH9@mail.gmail.com>

On Wed, Nov 10, 2010 at 7:55 AM, Ben Bolker <bbolker at gmail.com> wrote:
> On 10-11-10 08:33 AM, Kevin E. Thorpe wrote:
>> On November 10, 2010 08:19:17 am Kevin E. Thorpe wrote:
>>> On November 9, 2010 08:45:44 pm Kevin E. Thorpe wrote:
>>>> I just upgraded my version of R to
>>>>
>>>> R version 2.12.0 Patched (2010-11-07 r53537)
>>>> Platform: i686-pc-linux-gnu (32-bit)
>>>>
>>>> So that I could install the current lme4a. ?Earlier tonight, the package
>>>> seemed to be available, but as of 20:40 EST, it seems not to be.
>>>>
>>>>> install.packages("lme4a", repos="http://R-Forge.R-project.org")
>>>>
>>>> Warning message:
>>>> In getDependencies(pkgs, dependencies, available, lib) :
>>>> ? package 'lme4a' is not available
>>>>
>>>> Also, downloading the package source (from the R-forge link) takes me to
>>>> "Page not Found"
>>>>
>>>> Anyone know what's going on?
>>>
>>> I searched my saved mail, since this problem seemed like Deja Vu all over
>>> again. ?I found the link to the SVN instructions, and svn seems to have
>>> found the package.
>>
>> OK, the build fails on my system. ?I have the dependencies up-to-date.
>>
>>> sessionInfo()
>> R version 2.12.0 Patched (2010-11-07 r53537)
>> Platform: i686-pc-linux-gnu (32-bit)
>>
>> locale:
>> ?[1] LC_CTYPE=en_US ? ? ? LC_NUMERIC=C ? ? ? ? LC_TIME=en_US
>> ?[4] LC_COLLATE=C ? ? ? ? LC_MONETARY=C ? ? ? ?LC_MESSAGES=en_US
>> ?[7] LC_PAPER=en_US ? ? ? LC_NAME=C ? ? ? ? ? ?LC_ADDRESS=C
>> [10] LC_TELEPHONE=C ? ? ? LC_MEASUREMENT=en_US LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>
>> other attached packages:
>> [1] minqa_1.1.9 ? ? ? ?Rcpp_0.8.8 ? ? ? ? MatrixModels_0.2-1
>> Matrix_0.999375-44
>> [5] lattice_0.19-13
>>
>> loaded via a namespace (and not attached):
>> [1] grid_2.12.0 ?tools_2.12.0
>>
>> Here are the error messages from R CMD INSTALL.
>>
>> g++ -I/usr/local/lib/R/include ?-I/usr/local/include -I"/usr/local/lib/R/library/Matrix/include" -I"/usr/local/lib/R/library/Rcpp/include" ? -fpic ?-g -O2 -c
>> glmFamily.cpp -o glmFamily.o
>> glmFamily.cpp: In function 'void _rcpp_module_glm_init()':
>> glmFamily.cpp:122: error: 'class Rcpp::class_<glm::glmFamily>' has no member
>> named 'constructor'
>> glmFamily.cpp:122: error: 'init_1' was not declared in this scope
>> glmFamily.cpp:122: error: expected primary-expression before '>' token
>> glmFamily.cpp:122: error: expected primary-expression before ')' token
>> /usr/local/lib/R/library/Rcpp/include/Rcpp/Module.h: In member
>> function 'SEXPREC* Rcpp::class_<Class>::newInstance(SEXPREC**, int) [with
>> Class = glm::glmFamily]':
>> glmFamily.cpp:130: ? instantiated from here
>> /usr/local/lib/R/library/Rcpp/include/Rcpp/Module.h:242: error: no matching
>> function for call to 'glm::glmFamily::glmFamily()'
>> glmFamily.cpp:21: note: candidates are: glm::glmFamily::glmFamily(SEXPREC*)
>> glmFamily.h:12: note: ? ? ? ? ? ? ? ? glm::glmFamily::glmFamily(const
>> glm::glmFamily&)
>> make: *** [glmFamily.o] Error 1
>> ERROR: compilation failed for package 'lme4a'
>> * removing '/usr/local/lib/R/library/lme4a'
>>
>> Has anyone else encountered this?
>
> ?I get the same problem. ?I certainly can't guarantee the results, but
> reverting to release 1083
>
> ?svn update -r1083
>
> ?at least appears to allow the package to build/install (it doesn't
> quite make it through the examples in R CMD check -- it actually looks
> like the failure may be somewhere in lattice ... ?)
>
> ?It may be that one needs a bleeding-edge Rcpp to compile the latest
> version ... I'm trying upgrading to Rcpp 0.8.8.1 now ...

You got it.  I guess that 0.8.8.0 is not sufficient and you need 0.8.8.1

Romain and Dirk, and now John Chambers, are so fast in development of
Rcpp that it is difficult to keep up.



From kevin.thorpe at utoronto.ca  Wed Nov 10 15:15:23 2010
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Wed, 10 Nov 2010 09:15:23 -0500
Subject: [R-sig-ME] Is there a problem with the lme4a package at R-Forge
In-Reply-To: <AANLkTinq45HJWuxN5rri=0thR4ckOhqSL7wahoHoFAH9@mail.gmail.com>
References: <201011092045.45141.kevin.thorpe@utoronto.ca>
	<4CDAA44A.3070008@gmail.com>
	<AANLkTinq45HJWuxN5rri=0thR4ckOhqSL7wahoHoFAH9@mail.gmail.com>
Message-ID: <201011100915.23373.kevin.thorpe@utoronto.ca>

On November 10, 2010 09:01:55 am Douglas Bates wrote:
> On Wed, Nov 10, 2010 at 7:55 AM, Ben Bolker <bbolker at gmail.com> wrote:
> > On 10-11-10 08:33 AM, Kevin E. Thorpe wrote:
> >> On November 10, 2010 08:19:17 am Kevin E. Thorpe wrote:
> >>> On November 9, 2010 08:45:44 pm Kevin E. Thorpe wrote:
> >>>> I just upgraded my version of R to
> >>>>
> >>>> R version 2.12.0 Patched (2010-11-07 r53537)
> >>>> Platform: i686-pc-linux-gnu (32-bit)
> >>>>
> >>>> So that I could install the current lme4a. ?Earlier tonight, the
> >>>> package seemed to be available, but as of 20:40 EST, it seems not to
> >>>> be.
> >>>>
> >>>>> install.packages("lme4a", repos="http://R-Forge.R-project.org")
> >>>>
> >>>> Warning message:
> >>>> In getDependencies(pkgs, dependencies, available, lib) :
> >>>> ? package 'lme4a' is not available
> >>>>
> >>>> Also, downloading the package source (from the R-forge link) takes me
> >>>> to "Page not Found"
> >>>>
> >>>> Anyone know what's going on?
> >>>
> >>> I searched my saved mail, since this problem seemed like Deja Vu all
> >>> over again. ?I found the link to the SVN instructions, and svn seems to
> >>> have found the package.
> >>
> >> OK, the build fails on my system. ?I have the dependencies up-to-date.
> >>
> >>> sessionInfo()
> >>
> >> R version 2.12.0 Patched (2010-11-07 r53537)
> >> Platform: i686-pc-linux-gnu (32-bit)
> >>
> >> locale:
> >> ?[1] LC_CTYPE=en_US ? ? ? LC_NUMERIC=C ? ? ? ? LC_TIME=en_US
> >> ?[4] LC_COLLATE=C ? ? ? ? LC_MONETARY=C ? ? ? ?LC_MESSAGES=en_US
> >> ?[7] LC_PAPER=en_US ? ? ? LC_NAME=C ? ? ? ? ? ?LC_ADDRESS=C
> >> [10] LC_TELEPHONE=C ? ? ? LC_MEASUREMENT=en_US LC_IDENTIFICATION=C
> >>
> >> attached base packages:
> >> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
> >>
> >> other attached packages:
> >> [1] minqa_1.1.9 ? ? ? ?Rcpp_0.8.8 ? ? ? ? MatrixModels_0.2-1
> >> Matrix_0.999375-44
> >> [5] lattice_0.19-13
> >>
> >> loaded via a namespace (and not attached):
> >> [1] grid_2.12.0 ?tools_2.12.0
> >>
> >> Here are the error messages from R CMD INSTALL.
> >>
> >> g++ -I/usr/local/lib/R/include ?-I/usr/local/include
> >> -I"/usr/local/lib/R/library/Matrix/include"
> >> -I"/usr/local/lib/R/library/Rcpp/include" ? -fpic ?-g -O2 -c
> >> glmFamily.cpp -o glmFamily.o
> >> glmFamily.cpp: In function 'void _rcpp_module_glm_init()':
> >> glmFamily.cpp:122: error: 'class Rcpp::class_<glm::glmFamily>' has no
> >> member named 'constructor'
> >> glmFamily.cpp:122: error: 'init_1' was not declared in this scope
> >> glmFamily.cpp:122: error: expected primary-expression before '>' token
> >> glmFamily.cpp:122: error: expected primary-expression before ')' token
> >> /usr/local/lib/R/library/Rcpp/include/Rcpp/Module.h: In member
> >> function 'SEXPREC* Rcpp::class_<Class>::newInstance(SEXPREC**, int)
> >> [with Class = glm::glmFamily]':
> >> glmFamily.cpp:130: ? instantiated from here
> >> /usr/local/lib/R/library/Rcpp/include/Rcpp/Module.h:242: error: no
> >> matching function for call to 'glm::glmFamily::glmFamily()'
> >> glmFamily.cpp:21: note: candidates are:
> >> glm::glmFamily::glmFamily(SEXPREC*) glmFamily.h:12: note: ? ? ? ? ? ? ?
> >> ? glm::glmFamily::glmFamily(const glm::glmFamily&)
> >> make: *** [glmFamily.o] Error 1
> >> ERROR: compilation failed for package 'lme4a'
> >> * removing '/usr/local/lib/R/library/lme4a'
> >>
> >> Has anyone else encountered this?
> >
> > ?I get the same problem. ?I certainly can't guarantee the results, but
> > reverting to release 1083
> >
> > ?svn update -r1083
> >
> > ?at least appears to allow the package to build/install (it doesn't
> > quite make it through the examples in R CMD check -- it actually looks
> > like the failure may be somewhere in lattice ... ?)
> >
> > ?It may be that one needs a bleeding-edge Rcpp to compile the latest
> > version ... I'm trying upgrading to Rcpp 0.8.8.1 now ...
>
> You got it.  I guess that 0.8.8.0 is not sufficient and you need 0.8.8.1
>
> Romain and Dirk, and now John Chambers, are so fast in development of
> Rcpp that it is difficult to keep up.
>

Thanks Doug and Ben.  I installed Rcpp 0.8.8.1 from R-Forge and then was able 
to INSTALL lme4a.

Kevin

-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016



From Thierry.ONKELINX at inbo.be  Wed Nov 10 15:49:53 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 10 Nov 2010 15:49:53 +0100
Subject: [R-sig-ME] crossed random effect
In-Reply-To: <AANLkTikqwPnQX2YgSgdOmogi-o9J5=93fqkfvaWC-0NO@mail.gmail.com>
References: <AANLkTikqwPnQX2YgSgdOmogi-o9J5=93fqkfvaWC-0NO@mail.gmail.com>
Message-ID: <3DB16098F738284D8DBEB2FC369916384AE7C3@inboexch.inbo.be>

Dear Cristian,

Having only 2 levels for a random effect is not ideal for a mixed model.
You will get very unreliable variance estiametes. You better fit
observer as fixed effect.
Note that this will only solve the problem of the false convergence. You
will not get good estimates of the inter observer variability because
that will require data on much more observers. 

What is your definition of repetition? Are those 7 different objects
that are measured? Or the same object 7 times?

HTH,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens 
> Cristian Pasquaretta
> Verzonden: woensdag 10 november 2010 13:55
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] crossed random effect
> 
> Dear list,
> 
> I have a really simple problem:
> I want to calculate intra and inter observer variability 
> collecting 7 measures using 2 observers and 2 repetitions for 
> each observer so I build the following model:
> 
> mod=lmer(y~1 +(1|repetition) + (1|observer))
> 
> the y variable is continuous but is completely different for 
> each of the 7 measures.
> the table is:
>                repetition
> observer   1 2 3 4 5 6 7
>             1 2 2 2 2 2 2 2
>             2 2 2 2 2 2 2 2
> but when I run the model the message I get is:
> In mer_finalize(ans) : false convergence (8)
> 
> Can someone help me?
> 
> Thank you
> Cristian
> 
> --
> PhD
> Cristian Pasquaretta
> University of Pavia
> Via Adolfo Ferrata 1,
> 27100 PAVIA
> cristian.pasquaretta at unipv.it
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 



From bates at stat.wisc.edu  Wed Nov 10 17:16:06 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 10 Nov 2010 10:16:06 -0600
Subject: [R-sig-ME] quasi-binomial family in lme4
In-Reply-To: <20101110095332.35702sr5onyou6ck@www.staffmail.ed.ac.uk>
References: <D74CFE08A4F86B45870D14844A636E900138AF17@murier.nogent.cemagref.fr>
	<02A63C09-0121-4DCE-8BD5-1AA7029A1278@anu.edu.au>
	<D74CFE08A4F86B45870D14844A636E900138AF1E@murier.nogent.cemagref.fr>
	<20101110095332.35702sr5onyou6ck@www.staffmail.ed.ac.uk>
Message-ID: <AANLkTimqG-hAGyvzicL_L5xDwToxGFOF3a_VAb3NNVp-@mail.gmail.com>

To fit a per-observation random effects term you need to expand the
binomial representation to a Bernoulli representation.  You should end
up with
> sum(cbpp$size)
[1] 842
rows, not 52.  Notice that you have 52 levels of herd:id and 52 levels
of id in this model.  Thus the two random effects are the same and the
variance components are not well-defined.

If the data were expanded to 842 observations with a binary response
the appropriate specification of the random effects term would be
(1|herd/id) or, more simply, (1|herd) + (1|id).


On Wed, Nov 10, 2010 at 3:53 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
> Hi,
>
> It seems worrying to me that the Herd:Id estimate and the Id estimate are
> exactly the same. I get a (slightly) different estimate with version
> 0.999375-35 on Linux, but again the estimates are identical. MCMCglmm
> fitting the same model gives a very different answer.
>
> Cheers,
>
> Jarrod
>
>
>
>> summary(gm2)
>
> Generalized linear mixed model fit by the Laplace approximation
> Formula: incidence ~ period + (1 | Id/herd)
> ? Data: cbpp
> ? AIC ? BIC logLik deviance
> ?102.2 114.4 -45.11 ? ?90.21
> Random effects:
> ?Groups ?Name ? ? ? ?Variance Std.Dev.
> ?herd:Id (Intercept) 0.29654 ?0.54456
> ?Id ? ? ?(Intercept) 0.29654 ?0.54456
> Number of obs: 56, groups: herd:Id, 56; Id, 56
>
> Fixed effects:
> ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
> (Intercept) ? 1.1129 ? ? 0.2477 ? 4.492 7.04e-06 ***
> period2 ? ? ?-1.1969 ? ? 0.4185 ?-2.860 0.004233 **
> period3 ? ? ?-1.4223 ? ? 0.4381 ?-3.246 0.001169 **
> period4 ? ? ?-2.0049 ? ? 0.5292 ?-3.788 0.000152 ***
> ---
> Signif. codes: ?0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
> ? ? ? ?(Intr) perid2 perid3
> period2 -0.592
> period3 -0.565 ?0.335
> period4 -0.468 ?0.277 ?0.265
>
> Using a parameter expanded prior in order to improve mixing as the herd
> variance approaches zero:
>
> prior<-list(R=list(V=1, nu=0), G=list(G1=list(V=1, nu=1, alpha.mu=0,
> alpha.V=1000)))
>
> mcmc2<-MCMCglmm(incidence~period, random=~herd, family="poisson", data=cbpp)
>
>> summary(mcmc2)
>
> ?Iterations = 12991
> ?Thinning interval ?= 3001
> ?Sample size ?= 1000
>
> ?DIC: 175.9590
>
> ?G-structure: ?~herd
>
> ? ? post.mean ?l-95% CI u-95% CI eff.samp
> herd ? 0.01433 1.067e-16 ? 0.0713 ? ?61.58
>
> ?R-structure: ?~units
>
> ? ? ?post.mean l-95% CI u-95% CI eff.samp
> units ? ?0.7347 ? 0.1564 ? ?1.421 ? ?222.9
>
> ?Location effects: incidence ~ period
>
> ? ? ? ? ? ?post.mean l-95% CI u-95% CI eff.samp ?pMCMC
> (Intercept) ? ?1.0749 ? 0.4584 ? 1.5987 ? ?844.5 ?0.002 **
> period2 ? ? ? -1.2054 ?-2.0862 ?-0.3556 ? ?771.8 ?0.004 **
> period3 ? ? ? -1.4568 ?-2.4362 ?-0.4839 ? ?674.8 ?0.004 **
> period4 ? ? ? -2.0584 ?-3.1851 ?-0.9430 ? ?446.5 <0.001 ***
> ---
> Signif. codes: ?0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>
> Quoting Gosselin Frederic <frederic.gosselin at cemagref.fr>:
>
>> Dear Colleague,
>>
>> good question:
>>
>> the commands are under R2.5.1:
>> ************************************************************************
>> library(lme4)
>> cbppbis<-cbind.data.frame(cbpp,Id=as.factor(1:dim(cbpp)[1]))
>> gm1 <- lmer(incidence ~ period + (1 | herd), family = quasipoisson, data =
>> cbpp)
>> summary(gm1)
>>
>> gm2 <- lmer(incidence ~ period + (1 | Id/herd), family = poisson, data =
>> cbppbis)
>> summary(gm2)
>> **************************************************************************
>> (fope it is declared in the good order for the random effects in gm2)
>>
>> The results do show a slight discrepancy between both methods:
>>
>> *************************************************************************
>>>
>>> summary(gm1)
>>
>> Generalized linear mixed model fit using Laplace
>> Formula: incidence ~ period + (1 | herd)
>> ? Data: cbpp
>> ?Family: quasipoisson(log link)
>> ? AIC ? BIC logLik deviance
>> ?112.2 122.3 -51.11 ? ?102.2
>> Random effects:
>> ?Groups ? Name ? ? ? ?Variance Std.Dev.
>> ?herd ? ? (Intercept) 0.35085 ?0.59233
>> ?Residual ? ? ? ? ? ? 1.40470 ?1.18520
>> number of obs: 56, groups: herd, 15
>>
>> Fixed effects:
>> ? ? ? ? ? ?Estimate Std. Error t value
>> (Intercept) ? 1.2812 ? ? 0.2200 ? 5.824
>> period2 ? ? ?-1.1240 ? ? 0.3315 ?-3.391
>> period3 ? ? ?-1.3203 ? ? 0.3579 ?-3.689
>> period4 ? ? ?-1.9477 ? ? 0.4808 ?-4.051
>>
>> Correlation of Fixed Effects:
>> ? ? ? ?(Intr) perid2 perid3
>> period2 -0.339
>> period3 -0.314 ?0.219
>> period4 -0.233 ?0.163 ?0.151
>>
>>
>>
>>
>>> summary(gm2)
>>
>> Generalized linear mixed model fit using Laplace
>> Formula: incidence ~ period + (1 | Id/herd)
>> ? Data: cbppbis
>> ?Family: poisson(log link)
>> ? AIC ? BIC logLik deviance
>> ?102.2 114.4 -45.11 ? ?90.21
>> Random effects:
>> ?Groups ?Name ? ? ? ?Variance Std.Dev.
>> ?herd:Id (Intercept) 0.29608 ?0.54413
>> ?Id ? ? ?(Intercept) 0.29608 ?0.54413
>> number of obs: 56, groups: herd:Id, 56; Id, 56
>>
>> Estimated scale (compare to ?1 ) ?0.9249959
>>
>> Fixed effects:
>> ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
>> (Intercept) ? 1.1149 ? ? 0.2476 ? 4.503 6.69e-06 ***
>> period2 ? ? ?-1.2013 ? ? 0.4184 ?-2.871 0.004089 **
>> period3 ? ? ?-1.4224 ? ? 0.4378 ?-3.249 0.001159 **
>> period4 ? ? ?-2.0089 ? ? 0.5294 ?-3.795 0.000148 ***
>> ---
>> Signif. codes: ?0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>
>> Correlation of Fixed Effects:
>> ? ? ? ?(Intr) perid2 perid3
>> period2 -0.592
>> period3 -0.565 ?0.335
>> period4 -0.468 ?0.277 ?0.264
>> ************************************************************************
>>
>> The estimates and the standard errors are not exactly the same - which
>> might not be unlogical given that the relationship between variance and mean
>> is not the same in both models. They however are not very far one from the
>> other.
>>
>> Of course, this needs further investigation.
>>
>> I remember of a paper that motivated the use of the quasi-poisson method
>> based on empirical relationships between the residual variance and the mean:
>>
>> Ver Hoef J.M. et Boveng P.L., 2007, Quasi-poisson vs. negative binomial
>> regression: How should we model overdispersed count data?, Ecology, 88, 11,
>> p. 2766-2772.
>>
>> Sincerely,
>>
>> Fr?d?ric
>>
>> -----Message d'origine-----
>> De : John Maindonald [mailto:john.maindonald at anu.edu.au]
>> Envoy? : mercredi 10 novembre 2010 09:51
>> ? : Gosselin Frederic
>> Cc : r-sig-mixed-models at r-project.org; tiflo at csli.stanford.edu
>> Objet : Re: [R-sig-ME] quasi-binomial family in lme4
>>
>> I wonder if you have compared the results that you quote with the result
>> you get with observation level random effects in a poisson model.
>>
>> As I see it, use of observation level random effects should, unless there
>> is evidence that a multiplicative effect on the scale of the response is a
>> better fit, replace use of the quasi- models in glm() as well as in
>> generalised linear mixed models.
>>
>> John Maindonald ? ? ? ? ? ? email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473 ? ?fax ?: +61 2(6125)5549
>> Centre for Mathematics & Its Applications, Room 1194, John Dedman
>> Mathematical Sciences Building (Building 27) Australian National University,
>> Canberra ACT 0200.
>> http://www.maths.anu.edu.au/~johnm
>>
>> On 10/11/2010, at 6:39 PM, Gosselin Frederic wrote:
>>
>>> Hi Florian,
>>>
>>> a different perpsective on the quasi-likelihood debate - that comes out
>>> sporadically on this list:
>>>
>>> (i) I globally agree with the previous repliers that a fully
>>> probabilistic solution looks better - at least aesthetically - than a
>>> quasi-likelihood;
>>>
>>> (ii) however, as I have already mentioned on the list (cf. below),
>>> earlier versions of lme4 give much more sensible results than the latest
>>> versions:
>>> http://markmail.org/message/s4abxhhdacqjkunm
>>>
>>> This is why in the following papers:
>>> Elek Z., Dauffy-Richard & Gosselin F., 2010, Carabid species responses to
>>> hybrid poplar plantation in floodplains in France, Forest Ecology and
>>> Management, 260, 9, p. 1446-1455.
>>>
>>> and
>>>
>>> Vuidot A., Paillet Y., Archaux F. & Gosselin F. (In Press) Influence of
>>> tree characteristics and forest management on tree microhabitats in France,
>>> Biological Conservation.
>>>
>>> we used version the R version 2.5.1 and the associated lme4 version (here
>>> with quasi-poisson, not quasi-bionomial).
>>>
>>> Hope this helps.
>>>
>>> Sincerely,
>>>
>>> Fr?d?ric Gosselin
>>> Engineer & Researcher (PhD) in Forest Ecology Cemagref Domaine des
>>> Barres F-45290 Nogent sur Vernisson France
>>>
>>> http://www.cemagref.fr/les-contacts/les-pages-personnelles-professionn
>>> elles/gosselin-frederic/english-short-scientific-cv
>>>
>>>
>>> ? ? ? ?[[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Wed Nov 10 17:48:34 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 10 Nov 2010 10:48:34 -0600
Subject: [R-sig-ME] standardized residuals
In-Reply-To: <AANLkTi=fGaErjhnvDqWFEzyJf+tbEFGfJLG9f15OSm8P@mail.gmail.com>
References: <000001cb8030$51284410$f378cc30$@miami.edu>
	<AANLkTi=fGaErjhnvDqWFEzyJf+tbEFGfJLG9f15OSm8P@mail.gmail.com>
Message-ID: <AANLkTikK+SBQcRJZJRufnvj_KEj+E28PwNZ-hmrbigLp@mail.gmail.com>

On Tue, Nov 9, 2010 at 9:13 PM, Dennis Murphy <djmuser at gmail.com> wrote:
> Hi:
>
> A standardized residual in (non-mixed) linear models has the form
>
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?e_i / (s * sqrt(1 - h_i)),
>
> where s is the (residual) standard deviation and h_i is the i-th element of
> the 'hat matrix'. h_i is also called the leverage that the i-th observation
> exerts on the model. You could look into the influence.ME package on CRAN to
> see if something like it has already been implemented, but if not, all you
> need is the hat matrix analogue of a mixed model and you can write it up
> yourself. You can get the residuals and residual standard deviation from a
> lme(r) object directly, and should be able to access the hat matrix, too,
> perhaps indirectly.

And, for a linear model or generalized linear model (without random
effects), which is stored as an S3 object, you can find the names of
methods specific to the class as
> methods(class="lm")
 [1] add1.lm*           alias.lm*          anova.lm           BIC.lm*
 [5] case.names.lm*     confint.lm*        cooks.distance.lm* deviance.lm*
 [9] dfbeta.lm*         dfbetas.lm*        drop1.lm*          dummy.coef.lm*
[13] effects.lm*        extractAIC.lm*     family.lm*         formula.lm*
[17] hatvalues.lm       influence.lm*      kappa.lm           labels.lm*
[21] logLik.lm*         model.frame.lm     model.matrix.lm    plot.lm
[25] predict.lm         print.lm           proj.lm*           qqnorm.lm*
[29] qr.lm*             residuals.lm       rstandard.lm       rstudent.lm
[33] simulate.lm*       summary.lm         variable.names.lm* vcov.lm*

   Non-visible functions are asterisked
> methods(class="glm")
 [1] add1.glm*           anova.glm           confint.glm*
 [4] cooks.distance.glm* deviance.glm*       drop1.glm*
 [7] effects.glm*        extractAIC.glm*     family.glm*
[10] formula.glm*        influence.glm*      logLik.glm*
[13] model.frame.glm     predict.glm         print.glm
[16] residuals.glm       rstandard.glm       rstudent.glm
[19] summary.glm         vcov.glm*           weights.glm*

   Non-visible functions are asterisked

from which you can see that there are functions called rstandard and
rstudent providing standardized or Studentized residuals in the stats
package.  That is, you do not need to use stdres.
>
> HTH,
> Dennis
>
> On Tue, Nov 9, 2010 at 9:05 AM, Michael Larkin <mlarkin at rsmas.miami.edu>wrote:
>
>> Anyone use the standardized residuals function in R? ?It is called stdres
>>
>> I can't get it to work. ?It tells me there is no documentation for stdres.
>> I am assuming there is a package that I need to load. ?I looked at the list
>> of packages and I can't find one for stdres. ?It must be bundled in some
>> package.
>>
>> Any advice on how I can get stdres to work would be greatly appreciated.
>>
>> Mike
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From orna.intrator at gmail.com  Wed Nov 10 19:13:07 2010
From: orna.intrator at gmail.com (Orna Intrator)
Date: Wed, 10 Nov 2010 13:13:07 -0500
Subject: [R-sig-ME] lmer with fixed effects size restrictions?
Message-ID: <AANLkTimugdAM5h7jyDDuKWVw1D5TFA2Br00dGVfDqHRZ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101110/657cc9f3/attachment.pl>

From Jason_Taylor1 at baylor.edu  Wed Nov 10 21:01:30 2010
From: Jason_Taylor1 at baylor.edu (Taylor, Jason)
Date: Wed, 10 Nov 2010 14:01:30 -0600
Subject: [R-sig-ME] dealing with nestedness
Message-ID: <DB0892FFCE97CA42BE2144E916EB43F22D557488C8@MAIL-IK.baylor.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101110/e163300e/attachment.pl>

From marie_helene48 at hotmail.com  Thu Nov 11 00:07:25 2010
From: marie_helene48 at hotmail.com (=?iso-8859-1?B?TWFyaWUtSOls6G5lIEhhY2hleQ==?=)
Date: Wed, 10 Nov 2010 23:07:25 +0000
Subject: [R-sig-ME] profile, confint and p-values in lme4
Message-ID: <SNT131-w6EAF2ED52CC4FF7D524A7E1310@phx.gbl>


Hi,



I've been trying to make a profile zeta plot and check the confidence interval of
my data in lme4 but I got these messages:

?

> profile(model)

Erreur dans UseMethod("profile")
:???pas de m?thode pour 'profile' applicable pour un objet de
classe "mer" (No method for "profile" applicable for an
object of class "mer")

?

> confint(model)

Erreur dans object$coefficients : $ operator not
defined for this S4 class ?(Error in objects$coefficients)

?

I found the "profile" and "confint" functions in Doug Bates e-book. I
know he's been using lme4a for that book, so I downloaded it and installed it
last week but then?the function lmer stopped working and I uninstalled it.

?

Any advice?

?

Next question: I've read about p-values for lmer,
and I understand that because of the problems with the p-values (conservative, value?of p twice of what it should be),?
lme4 didn't give them before in its output. At the present time, lme4 gives the p-values. Is the problem
solved?

?

In other words: can I rely on those p-value or
should I use a Monte Carlo simulation like D. Bates suggested in 2006 (in article "lmer,
p-values and all that")?

?

Thank you

?

Marie-Helene Hachey

? 		 	   		  


From jens.astrom at ekol.slu.se  Thu Nov 11 15:58:18 2010
From: jens.astrom at ekol.slu.se (=?UTF-8?B?SmVucyDDhXN0csO2bQ==?=)
Date: Thu, 11 Nov 2010 15:58:18 +0100
Subject: [R-sig-ME] glmer Z-test with individual random effects
Message-ID: <4CDC048A.3040908@ekol.slu.se>

Dear list,

As I have read (Bolker et al. 2009 TREE), the Wald Z test is only
appropriate for GLMMs in cases without overdispersion.

Assuming we use family=poisson with lmer and tackle overdispersion by
incorporating an individual random effect AND this adequately "reduces"
the overdispersion, is it then OK to use the Wald z test as reported by
lmer?

In other words, are the p-values reported by lmer in those cases
useful/"correct"? Or do they suffer from the usual problems with
figuring out the number of parameters used by the random effects?

Secondly, is it good practice to judge lmer's capability of "reducing"
the overdispersion by summing the squared residuals (pearson) and
compare this to a chi square distribution (with N-1 degrees of freedom)?


Thankful for any comments or suggestions,

Jens ?str?m



From bbolker at gmail.com  Thu Nov 11 16:18:00 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 11 Nov 2010 10:18:00 -0500
Subject: [R-sig-ME] glmer Z-test with individual random effects
In-Reply-To: <4CDC048A.3040908@ekol.slu.se>
References: <4CDC048A.3040908@ekol.slu.se>
Message-ID: <4CDC0928.9070405@gmail.com>

On 11/11/2010 09:58 AM, Jens ?str?m wrote:
> Dear list,
> 
> As I have read (Bolker et al. 2009 TREE), the Wald Z test is only
> appropriate for GLMMs in cases without overdispersion.
> 
> Assuming we use family=poisson with lmer and tackle overdispersion by
> incorporating an individual random effect AND this adequately "reduces"
> the overdispersion, is it then OK to use the Wald z test as reported by
> lmer?
> 
> In other words, are the p-values reported by lmer in those cases
> useful/"correct"? Or do they suffer from the usual problems with
> figuring out the number of parameters used by the random effects?

  They are equivalent to assuming an infinite/large 'denominator degrees
of freedom'.  If you have a large sample size (both a large number of
total samples relative to the number of parameters, and a large number
of random-effects levels/blocks) then this should be reasonable -- if
not, then yes, the 'usual problems with figuring out the number of
parameters' is relevant.  On the other hand, if you're willing to assume
that the sample size is large, then likelihood ratio rests
(anova(model1,model2)) are probably better than the Wald tests anyway.

> 
> Secondly, is it good practice to judge lmer's capability of "reducing"
> the overdispersion by summing the squared residuals (pearson) and
> compare this to a chi square distribution (with N-1 degrees of freedom)?

   I would say this is reasonable, although again it's a rough guide
because the true degrees of freedom are a bit fuzzy -- it should
probably be at most N-(fixed effect degrees of freedom)?

   Would be happy to hear any conflicting opinions.

  Ben Bolker



From marie_helene48 at hotmail.com  Thu Nov 11 16:58:09 2010
From: marie_helene48 at hotmail.com (=?iso-8859-1?B?TWFyaWUtSOls6G5lIEhhY2hleQ==?=)
Date: Thu, 11 Nov 2010 15:58:09 +0000
Subject: [R-sig-ME] more info for "profile", "confint" and p-values
Message-ID: <SNT131-w5371209C6E3D37594844ABE1320@phx.gbl>


Hi again,
I forgot to mention that I'm using R 2.12.0.Sorry about all the question marks in my letter, I don't know how that happened.
Marie-Helene HacheyM. Sc. studentUniversite Laval, Quebec 		 	   		  


From bbolker at gmail.com  Thu Nov 11 20:43:04 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 11 Nov 2010 14:43:04 -0500
Subject: [R-sig-ME] Dealing with Overdispersion in Count Data with Mixed
	Modeling
In-Reply-To: <1289502674l.892954l.0l@psu.edu>
References: <1288203635l.1032266l.0l@psu.edu>	<1288208508l.1511628l.0l@psu.edu>	<1288296451l.1032274l.0l@psu.edu>	<AANLkTikscT885QSAdhJHS=yyVeeN5LV4_Qj7JC2QfGoB@mail.gmail.com><4CC9E1C5.407	0106@gmail.com>
	<1288632521l.614426l.0l@psu.edu><4CCF6F03.80101@gmail.com>
	<1289502674l.892954l.0l@psu.edu>
Message-ID: <4CDC4748.7060002@gmail.com>

On 11/11/2010 02:11 PM, David Stainbrook wrote:
> Ben,
> 
> Putting aside the issues of model convergence, I would like to focus on
> the issue of how to deal with overdispersion in count data. Typically, a
> negative binomial or quasi-poisson model deals with overdispersion in
> situations where it is not appropriate to use Poisson. However, to my
> knowledge, lme4 does not allow multiple random effects using the
> negative binomial family 

  [correction: it doesn't implement negative binomial models at all,
although I believe that *in* principle this could be added by using an
additional 'k' parameter that controlled the mean-variance relationship,
in a way analogous to glm.nb() in the MASS package].

and quasi-poisson has issues with the
> likelihood estimation. As you suggested in a previous email, and from
> the article at
> <http://journals.cambridge.org/action/displayAbstract?fromPage=online&aid=82701
> <http://journals.cambridge.org/action/displayAbstract?fromPage=online&aid=82701>>,
> translating the model to a lognormal-Poisson model by using an
> individual-level random variable and using family=poisson should deal
> with the overdispersion.

  Yes.

> 
> I wanted to clarify what you meant by the individual level to make sure
> that I am doing it correctly. I already have a random intercept for each
> individual (1|LT), where LT=lowest tag number for each individual, to
> account for pseudoreplication. For the individual-level random variable
> to deal with overdispersion, did you mean adding (1|Observation), where
> Observation is a vector from 1 to the total number of observations or
> records in the dataset?

  yes, exactly.

> 
> This is demonstrated here in a very simple model with no covariates:
> model_1<-lmer(Y~1 + (1|LT) + (1|Observation), data=df3, ! family=poisson)
> 
> and here with an additional covariate (covx) with both fixed and random
> effects:
> model_2<-lmer(Y~1 + (1+covx|LT) + (1|Observation) + covx, data=df3, 
> family=poisson)
> 
> Is this what you meant and is it coded correctly?
> 
> I tried this code with an older version of R and lme4, and it yielded an
> error and no summary data, but after updating both the version of R and
> the lme4 library, I received a warning "Number of levels of a grouping
> factor for the random effects is *equal* to n, the number of
> observations", but it yielded summary information that I took to be
> legitimate.

   That is what I would expect.

  Ben Bolker


> 
> Thanks for the help,
> 
> ..................................................................
> 
> David Stainbrook
> M.S. Graduate Research Assistant
> Pennsylvania Cooperative Fish & Wildlife Research Unit
> The Pennsylvania State University
> 
> ..................................................................
> 
> 
> On Mon, Nov 1, 2010 09:53 PM, *Ben Bolker <bbolker at gmail.com>* wrote:
> 
>       [cc'ing r-sig-mixed-models: it's best to keep sending replies back to
>     the list so they can be archived and others can read them, or offer input]
> 
>     On 10-11-01 01:28 PM, David Stainbrook wrote:
>     > Ben,
>     > 
>     > Thanks for your input. I read that article that you suggested and it
>     > appears they used SAS and Genstat to do their analysis. 
> 
>       Yes (although as I said at the time, I wouldn't actually trust the
>     methods that they used in Genstat for this problem.  I just think their
>     description of the problem is clear).
> 
>     > Is it possible
>     > to use the Poisson-lognormal model in R or translate the model to this
>     > using R and lmer? Another professor mentioned that I may be able to get
>     > it to work using a negative binomial model in SAS or ADModel Builder.
>     > What do you suggest?
> 
>       Yes, you can use the Poisson-lognormal in recent versions of lme4,
>     simply by including an individual-level random variable.  You may get
>     warnings.
>       You could indeed use a negative binomial model in SAS or AD Model
>     Builder (in ADMB you could also use the lognormal-Poisson model).
> 
>     > Do you have any idea why Doug allowed the lmer function to fit
>     > quasipoisson if he doesn't feel that the results will be reliable? I
>     > would have trusted my results and wouldn't have had any idea that they
>     > might have been unreliable if he had not said that.
> 
>       I believe he implemented it a while ago and his opinions have now
>     changed. (I agree that it might be a good idea to disable this
>     functionality.)
> 
>     > Also, do you have any idea how to increase both the default number of
>     > function evaluations and iterations with the control statement within
>     > the lmer model statement?
> 
>     ...,control=list(maxIter=2000,maxFN=3000),... should work.
> 
>        * you seem to be tackling a difficult problem.  I appreciate that
>     you're offering full details on your problem (full scripts and data),
>     but it's going to take someone else at least half an hour (and probably
>     quite a bit more) to get up to speed on what you're doing and what's not
>     working; unfortunately, that's more than most anyone has time for,
>     unless the problem happens to be something very close to their
>     interests. Unfortunately, you may well need to find local help for this
>     (your advisor? a friendly stats professor or graduate student?) - <I already exhausted those options, hence contacting you and Doug>
>       * it's possible, depending on the complexity of your model, that
>     you're simply trying to fit too complicated a model.  You do have a lot
>     of data points, but some of your covariates may be strongly correlated.
>     Have you tried:
>        - seeing if you can successfully fit a subset of the data points
>     (this could be faster, allowing you to debug quicker)?
>        - seeing if you can successfully fit a subset of the covariates, or
>     which covariates or combinations of covariates are problematic?
>        - seeing if you can successfully fit a non-mixed (GLM) model,
>     treating 'individual' as a fixed effect?
>        - simulating data, possibly in a simplified form, to see if you can
>     get the right answer when you know what it is?
>       * lme4 is quite finicky about convergence, on the philosophy that it's
>     better not to give an answer than to give a wrong one.
> 
>       R does have its advantages, but if you're up to working with SAS or AD
>     Model Builder I would recommend you also try those approaches -- see if
>     you run into the same problems.  But I would definitely try some of the
>     trouble-shooting strategies above, first.
> 
>       good luck,
>         Ben Bolker
> 
> 
>     > Thanks again,
>     > 
>     > David
> 
>     > 
>     > On Thu, Oct 28, 2010 04:49 PM, *Ben Bolker <bbolker at gmail.com>*
>     wrote:
>     > 
>     >        My advice would be to use an individual-level random variable
>     >     (translating to a lognormal-Poisson model, which is qualitatively
>     >     similar to a negative binomial) -- see e.g. Elston et al 2001 for
>     a
>     >     decent explanation, although you should not necessarily trust the
>     >     numeric methods they use ...
>     > 
>     >      [Elston, D. A., R. Moss, T. Boulinier, C. Arrowsmith, and X. Lambin.
>     >     2001. Analysis of Aggregation, a Worked Example: Numbers of Ticks on
>     Red
>     >     Grouse Chicks. Parasitology 122, no. 05: 563-569.
>     >     doi:10.1017/S0031182001007740.
>     >    
>     http://journals.cambridge.org/action/displayAbstract?fromPage=online&aid=82701.]
>     > 
>     > 
>     >       (Doug, thanks for the vote of confidence!)
>     > 
>     >       cheers
>     >         Ben
>     > 
>     > 
>     > 
>     > 
>     > 
> 
> 
> 
>



From john.maindonald at anu.edu.au  Fri Nov 12 00:45:00 2010
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Fri, 12 Nov 2010 10:45:00 +1100
Subject: [R-sig-ME] glmer Z-test with individual random effects
In-Reply-To: <4CDC0928.9070405@gmail.com>
References: <4CDC048A.3040908@ekol.slu.se> <4CDC0928.9070405@gmail.com>
Message-ID: <9BD43DA3-2EC7-4E91-B392-72E2A94D7E8F@anu.edu.au>

The Wald tests (as represented in glm and glmer output of z-statistics
and p-values) are approximate for both glm models and glmm models
with non-identity links. The approximation can fail badly if the link is
highly non-linear over a region of the response that is relevant for a
parameter of interest.  The Hauck-Donner phenomenon, where the 
z-statistic decreases as the effect estimate increases, is an extreme 
example.
(This happens, e.g., as one of the levels being compared gives a
fitted value that moves close to a binomial proportion of 0 or 1, or 
close to a Poisson estimate of 0.)

The additional complication for a glmm is that the SE may have
two components -- e.g., a poisson or binomial error, and a random
normal error that is added on the scale of the linear predictor.  This
random normal error somewhat alleviates variance change effects
(including Hauck-Donner) that result from non-linearity in the link,
while adding uncertainty to the SE estimate.  If the contribution from
the glm family error term is largish relative to contribution from the 
random normal error (> 3 or 4  times as large?), treating the z-statistic 
as normal may not in many circumstances be too unreasonable,
even if the relevant degrees of freedom are as small as maybe 4
(e.g., where the test is for consistency across 5 locations). 

On data where I seem to have this situation, fairly consistently 
across a number of responses, I initially used MCMCglmm().
I was concerned about the contribution from the random normal 
error (including a contribution from an observation level random 
effect term).  I found I hat I had to choose a somewhat informative 
prior (inverse Wishart with V=1, nu=0.002) to consistently get 
convergence.  With this prior, the MCMCglmm credible intervals 
were remarkably close to glmer confidence intervals, treating the 
z-statistics as normal.  

No doubt the effect of the chosen prior is to insist that the true 
random normal error variance is fairly close to the variance as 
estimated by glmer().  A frustration (for me, at least) with using 
MCMCglmm is that I do not know just what MCMCglmm() is doing 
in this respect, short of doing some careful investigative exploration 
of the MCMC simulation results (which is an after-the-event check, 
where I'd like to know before the event).  Comments, Jarrod?

All this is to emphasise that we are not in the arena, unless the
relevant degrees of freedom are large, of precise science.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 12/11/2010, at 2:18 AM, Ben Bolker wrote:

> On 11/11/2010 09:58 AM, Jens ?str?m wrote:
>> Dear list,
>> 
>> As I have read (Bolker et al. 2009 TREE), the Wald Z test is only
>> appropriate for GLMMs in cases without overdispersion.
>> 
>> Assuming we use family=poisson with lmer and tackle overdispersion by
>> incorporating an individual random effect AND this adequately "reduces"
>> the overdispersion, is it then OK to use the Wald z test as reported by
>> lmer?
>> 
>> In other words, are the p-values reported by lmer in those cases
>> useful/"correct"? Or do they suffer from the usual problems with
>> figuring out the number of parameters used by the random effects?
> 
>  They are equivalent to assuming an infinite/large 'denominator degrees
> of freedom'.  If you have a large sample size (both a large number of
> total samples relative to the number of parameters, and a large number
> of random-effects levels/blocks) then this should be reasonable -- if
> not, then yes, the 'usual problems with figuring out the number of
> parameters' is relevant.  On the other hand, if you're willing to assume
> that the sample size is large, then likelihood ratio rests
> (anova(model1,model2)) are probably better than the Wald tests anyway.
> 
>> 
>> Secondly, is it good practice to judge lmer's capability of "reducing"
>> the overdispersion by summing the squared residuals (pearson) and
>> compare this to a chi square distribution (with N-1 degrees of freedom)?
> 
>   I would say this is reasonable, although again it's a rough guide
> because the true degrees of freedom are a bit fuzzy -- it should
> probably be at most N-(fixed effect degrees of freedom)?
> 
>   Would be happy to hear any conflicting opinions.
> 
>  Ben Bolker
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From j.hadfield at ed.ac.uk  Fri Nov 12 12:51:29 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 12 Nov 2010 11:51:29 +0000
Subject: [R-sig-ME] glmer Z-test with individual random effects
In-Reply-To: <9BD43DA3-2EC7-4E91-B392-72E2A94D7E8F@anu.edu.au>
References: <4CDC048A.3040908@ekol.slu.se> <4CDC0928.9070405@gmail.com>
	<9BD43DA3-2EC7-4E91-B392-72E2A94D7E8F@anu.edu.au>
Message-ID: <3F00BB51-2D71-476A-9637-A032E31EE51D@ed.ac.uk>

Hi John,

I'm not sure which part of the MCMCglmm routine is unclear but in a  
nut shell:

The data are distributed according to the specified distribution (e.g.  
Poisson ) with the dsitribution parameter equal to the linear  
predictor (nu) on the inverse link scale:

y ~ Pois(exp(nu))

A linear (mixed) model is proposed for the linear predictor:

nu ~ N(Xb+Zu, I*Ve)

In all models a "units" term is included which is the same as an  
observational-level random effect.  This is the residual term in the  
linear part of the model.

Priors are passed as  a list of the form:

prior=list(B=list(),
                  R=list(),
                  G=list(G1=list(),
                              G2=list()))


where B is the prior for the fixed effects, R is the prior for Ve (or  
possibly a residual covariance matrix depending on the model) and the  
elements of G are the priors for each of the random effect  
(co)variances.


The prior for b is multivariate normal Pr(b) ~ N(B$mu, B$V)

The prior for Ve is inverse-Wishart Pr(Ve) ~ IW(R$nu, R$V*R$nu) where  
the first term is the degree of belief and R$V*R$nu is the scale matrix

The prior for the random effects variances (Vg) are set in the same  
way as Ve, although its possible to also fit parameter expanded priors.

When the variance term is scalar (rather than a covariance matrix)  
then the inverse-Wishart and inverse-gamma are the same and IW(R$nu, R 
$V*R$nu) = IG(R$nu/2, R$V*R$nu/2) where the two parameters are the  
shape and scale. Your specification R=list(V=1, nu=0.002)  is  
therefore  IG(0.001, 0.001) which used to be used a lot (and probably  
still is) as a "weak" prior by users of WinBUGS.  The REML estimator  
for Ve should be equal to the posterior mode in MCMCglmm when the  
improper prior R=list(V=0, nu=-2)  is used. 0 will not be accepted by  
MCMCglmm so you would have to use something small (e.g. 1e-6). The  
prior is improper so you have to be careful when using it, and  
although the point estimate may have some useful properties (the same  
as the REML estimate) the full posterior distribution may not be ideal  
with small sample sizes.

The sampling scheme is:

update nu using MH updates or slice sampling
Gibbs sample b and u together
Gibbs sample (co)variance components sequentially.

For other models  such as ordinal regression or simultaneous/recursive  
models there are other schemes also, but these are quite specialised.

Cheers,

Jarrod



















On 11 Nov 2010, at 23:45, John Maindonald wrote:

> The Wald tests (as represented in glm and glmer output of z-statistics
> and p-values) are approximate for both glm models and glmm models
> with non-identity links. The approximation can fail badly if the  
> link is
> highly non-linear over a region of the response that is relevant for a
> parameter of interest.  The Hauck-Donner phenomenon, where the
> z-statistic decreases as the effect estimate increases, is an extreme
> example.
> (This happens, e.g., as one of the levels being compared gives a
> fitted value that moves close to a binomial proportion of 0 or 1, or
> close to a Poisson estimate of 0.)
>
> The additional complication for a glmm is that the SE may have
> two components -- e.g., a poisson or binomial error, and a random
> normal error that is added on the scale of the linear predictor.  This
> random normal error somewhat alleviates variance change effects
> (including Hauck-Donner) that result from non-linearity in the link,
> while adding uncertainty to the SE estimate.  If the contribution from
> the glm family error term is largish relative to contribution from the
> random normal error (> 3 or 4  times as large?), treating the z- 
> statistic
> as normal may not in many circumstances be too unreasonable,
> even if the relevant degrees of freedom are as small as maybe 4
> (e.g., where the test is for consistency across 5 locations).
>
> On data where I seem to have this situation, fairly consistently
> across a number of responses, I initially used MCMCglmm().
> I was concerned about the contribution from the random normal
> error (including a contribution from an observation level random
> effect term).  I found I hat I had to choose a somewhat informative
> prior (inverse Wishart with V=1, nu=0.002) to consistently get
> convergence.  With this prior, the MCMCglmm credible intervals
> were remarkably close to glmer confidence intervals, treating the
> z-statistics as normal.
>
> No doubt the effect of the chosen prior is to insist that the true
> random normal error variance is fairly close to the variance as
> estimated by glmer().  A frustration (for me, at least) with using
> MCMCglmm is that I do not know just what MCMCglmm() is doing
> in this respect, short of doing some careful investigative exploration
> of the MCMC simulation results (which is an after-the-event check,
> where I'd like to know before the event).  Comments, Jarrod?
>
> All this is to emphasise that we are not in the arena, unless the
> relevant degrees of freedom are large, of precise science.
>
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> http://www.maths.anu.edu.au/~johnm
>
> On 12/11/2010, at 2:18 AM, Ben Bolker wrote:
>
>> On 11/11/2010 09:58 AM, Jens ?str?m wrote:
>>> Dear list,
>>>
>>> As I have read (Bolker et al. 2009 TREE), the Wald Z test is only
>>> appropriate for GLMMs in cases without overdispersion.
>>>
>>> Assuming we use family=poisson with lmer and tackle overdispersion  
>>> by
>>> incorporating an individual random effect AND this adequately  
>>> "reduces"
>>> the overdispersion, is it then OK to use the Wald z test as  
>>> reported by
>>> lmer?
>>>
>>> In other words, are the p-values reported by lmer in those cases
>>> useful/"correct"? Or do they suffer from the usual problems with
>>> figuring out the number of parameters used by the random effects?
>>
>> They are equivalent to assuming an infinite/large 'denominator  
>> degrees
>> of freedom'.  If you have a large sample size (both a large number of
>> total samples relative to the number of parameters, and a large  
>> number
>> of random-effects levels/blocks) then this should be reasonable -- if
>> not, then yes, the 'usual problems with figuring out the number of
>> parameters' is relevant.  On the other hand, if you're willing to  
>> assume
>> that the sample size is large, then likelihood ratio rests
>> (anova(model1,model2)) are probably better than the Wald tests  
>> anyway.
>>
>>>
>>> Secondly, is it good practice to judge lmer's capability of  
>>> "reducing"
>>> the overdispersion by summing the squared residuals (pearson) and
>>> compare this to a chi square distribution (with N-1 degrees of  
>>> freedom)?
>>
>>  I would say this is reasonable, although again it's a rough guide
>> because the true degrees of freedom are a bit fuzzy -- it should
>> probably be at most N-(fixed effect degrees of freedom)?
>>
>>  Would be happy to hear any conflicting opinions.
>>
>> Ben Bolker
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From Kay.Cichini at uibk.ac.at  Fri Nov 12 12:09:15 2010
From: Kay.Cichini at uibk.ac.at (Kay Cecil Cichini)
Date: Fri, 12 Nov 2010 12:09:15 +0100
Subject: [R-sig-ME] parameterization for partly nested design with repeated
	measurements
Message-ID: <4CDD205B.8090704@uibk.ac.at>

dear listers,

i'd very much appreciate help with setting up the right parameterization 
for the following design:
4 regions, in each region 3 to 12 schools, at each school 2-4 classes 
and each class tested before and after intervention, yielding a bimomial 
outcome (pupils that passed / not passed a test).

i'm interested in differences between before and after (factor = 
"interv") intervention outcomes (X = passed, n = passed + not passed) 
and in the interaction region * interv.

i tried with:
glmer (cbind(X, n - X) ~ region * interv + (region | school / class), 
family = binomial)

and with:
glmer (cbind(X, n - X) ~ region * interv + (1 | school / class), family 
= binomial)


i'd be happy about comments on the parameterization or any ideas.

yours,
kay



From dps215 at psu.edu  Thu Nov 11 20:11:14 2010
From: dps215 at psu.edu (David Stainbrook)
Date: Thu, 11 Nov 2010 14:11:14 -0500
Subject: [R-sig-ME] Dealing with Overdispersion in Count Data with Mixed
	Modeling
In-Reply-To: 4CCF6F03.80101@gmail.com
References: <1288203635l.1032266l.0l@psu.edu> <1288208508l.1511628l.0l@psu.edu>
	<1288296451l.1032274l.0l@psu.edu>
	<AANLkTikscT885QSAdhJHS=yyVeeN5LV4_Qj7JC2QfGoB@mail.gmail.com><4CC9E1C5.407
	0106@gmail.com>
	<1288632521l.614426l.0l@psu.edu><4CCF6F03.80101@gmail.com>
Message-ID: <1289502674l.892954l.0l@psu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101111/24a5dfae/attachment.pl>

From bates at stat.wisc.edu  Fri Nov 12 20:13:23 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 12 Nov 2010 13:13:23 -0600
Subject: [R-sig-ME] parameterization for partly nested design with
 repeated measurements
In-Reply-To: <4CDD205B.8090704@uibk.ac.at>
References: <4CDD205B.8090704@uibk.ac.at>
Message-ID: <AANLkTinho-pPMYg62exT-mKVcOZKnScgZfuYm4AfLG7O@mail.gmail.com>

On Fri, Nov 12, 2010 at 5:09 AM, Kay Cecil Cichini
<Kay.Cichini at uibk.ac.at> wrote:
> dear listers,
>
> i'd very much appreciate help with setting up the right parameterization for
> the following design:
> 4 regions, in each region 3 to 12 schools, at each school 2-4 classes and
> each class tested before and after intervention, yielding a bimomial outcome
> (pupils that passed / not passed a test).
>
> i'm interested in differences between before and after (factor = "interv")
> intervention outcomes (X = passed, n = passed + not passed) and in the
> interaction region * interv.
>
> i tried with:
> glmer (cbind(X, n - X) ~ region * interv + (region | school / class), family
> = binomial)

This model is generating an interaction between the fixed-effects
factor "region" and the random-effects factor "school", which doesn't
make sense because each school occurs within only one region.

The simplest way to establish the desired structure is to create the
region, school and class factors so they follow the "each distinct
structure corresponds to a distinct level of the factor" rule.  For
example, if you call the regions "A", "B", "C" and "D" and you call
the schools "A01", ... "A10", "B01", ..., "B06", "C01", ..., "C12" and
you call the classes "A01a", "A01b", "A01c", ..., "C12d" then you can
specify the model very easily as

glmer(cbind(X, n - X) ~ region * interv + (1|school) + (1|class),
family = binomial)

Most of the confusion about model specification comes from the
unfortunate practice of labeling the schools as "01", ..., "12"
without taking into account that school 1 in region A is not
associated in any way with school 1 in region C.  In other words, all
you need to do is to disambiguate the names of the schools and the
classrooms.


> and with:
> glmer (cbind(X, n - X) ~ region * interv + (1 | school / class), family =
> binomial)
>
>
> i'd be happy about comments on the parameterization or any ideas.
>
> yours,
> kay
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Fri Nov 12 20:24:42 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 12 Nov 2010 13:24:42 -0600
Subject: [R-sig-ME] profile, confint and p-values in lme4
In-Reply-To: <SNT131-w6EAF2ED52CC4FF7D524A7E1310@phx.gbl>
References: <SNT131-w6EAF2ED52CC4FF7D524A7E1310@phx.gbl>
Message-ID: <AANLkTimdk5uQx+LUogrWPECCK7xW6WfaVjmqn-xANf1x@mail.gmail.com>

Profiling and the associated plots and confidence intervals are not in
the currently released version of the lme4 package.  They currently
only available in the development version that is called lme4a and
must be obtained from R-forge.  At some point this version will be
released as lme4 but I can't say exactly when.  Both Martin and I have
heavy teaching loads at present and are unable to make much progress
on the package.

On Wed, Nov 10, 2010 at 5:07 PM, Marie-H?l?ne Hachey
<marie_helene48 at hotmail.com> wrote:
>
> Hi,
>
>
>
> I've been trying to make a profile zeta plot and check the confidence interval of
> my data in lme4 but I got these messages:
>
>
>
>> profile(model)
>
> Erreur dans UseMethod("profile")
> :???pas de m?thode pour 'profile' applicable pour un objet de
> classe "mer" (No method for "profile" applicable for an
> object of class "mer")
>
>
>
>> confint(model)
>
> Erreur dans object$coefficients : $ operator not
> defined for this S4 class ?(Error in objects$coefficients)
>
>
>
> I found the "profile" and "confint" functions in Doug Bates e-book. I
> know he's been using lme4a for that book, so I downloaded it and installed it
> last week but then?the function lmer stopped working and I uninstalled it.
>
>
>
> Any advice?
>
>
>
> Next question: I've read about p-values for lmer,
> and I understand that because of the problems with the p-values (conservative, value?of p twice of what it should be),
> lme4 didn't give them before in its output. At the present time, lme4 gives the p-values. Is the problem
> solved?
>
>
>
> In other words: can I rely on those p-value or
> should I use a Monte Carlo simulation like D. Bates suggested in 2006 (in article "lmer,
> p-values and all that")?
>
>
>
> Thank you
>
>
>
> Marie-Helene Hachey
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From john.maindonald at anu.edu.au  Sat Nov 13 01:42:30 2010
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Sat, 13 Nov 2010 11:42:30 +1100
Subject: [R-sig-ME] glmer Z-test with individual random effects
In-Reply-To: <3F00BB51-2D71-476A-9637-A032E31EE51D@ed.ac.uk>
References: <4CDC048A.3040908@ekol.slu.se> <4CDC0928.9070405@gmail.com>
	<9BD43DA3-2EC7-4E91-B392-72E2A94D7E8F@anu.edu.au>
	<3F00BB51-2D71-476A-9637-A032E31EE51D@ed.ac.uk>
Message-ID: <755D562E-A8D2-4999-9507-9BAFF970EC99@anu.edu.au>

HI Jarrod -
The mechanics of what is happening are not my issue.  What bothers 
me is that I do not have any intuitive sense of how the choice of prior 
may be constraining the variance estimates.  Is it for example possible 
to say that the effect is comparable to adding  some number of degrees 
of freedom to the variance estimate?  What is the balance between
what comes from the prior, and what derives from the data?
John.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 12/11/2010, at 10:51 PM, Jarrod Hadfield wrote:

> Hi John,
> 
> I'm not sure which part of the MCMCglmm routine is unclear but in a nut shell:
> 
> The data are distributed according to the specified distribution (e.g. Poisson ) with the dsitribution parameter equal to the linear predictor (nu) on the inverse link scale:
> 
> y ~ Pois(exp(nu))
> 
> A linear (mixed) model is proposed for the linear predictor:
> 
> nu ~ N(Xb+Zu, I*Ve)
> 
> In all models a "units" term is included which is the same as an observational-level random effect.  This is the residual term in the linear part of the model.
> 
> Priors are passed as  a list of the form:
> 
> prior=list(B=list(),
>               R=list(),
>               G=list(G1=list(),
>                           G2=list()))
> 
> 
> where B is the prior for the fixed effects, R is the prior for Ve (or possibly a residual covariance matrix depending on the model) and the elements of G are the priors for each of the random effect (co)variances.
> 
> 
> The prior for b is multivariate normal Pr(b) ~ N(B$mu, B$V)
> 
> The prior for Ve is inverse-Wishart Pr(Ve) ~ IW(R$nu, R$V*R$nu) where the first term is the degree of belief and R$V*R$nu is the scale matrix
> 
> The prior for the random effects variances (Vg) are set in the same way as Ve, although its possible to also fit parameter expanded priors.
> 
> When the variance term is scalar (rather than a covariance matrix) then the inverse-Wishart and inverse-gamma are the same and IW(R$nu, R$V*R$nu) = IG(R$nu/2, R$V*R$nu/2) where the two parameters are the shape and scale. Your specification R=list(V=1, nu=0.002)  is therefore  IG(0.001, 0.001) which used to be used a lot (and probably still is) as a "weak" prior by users of WinBUGS.  The REML estimator for Ve should be equal to the posterior mode in MCMCglmm when the improper prior R=list(V=0, nu=-2)  is used. 0 will not be accepted by MCMCglmm so you would have to use something small (e.g. 1e-6). The prior is improper so you have to be careful when using it, and although the point estimate may have some useful properties (the same as the REML estimate) the full posterior distribution may not be ideal with small sample sizes.
> 
> The sampling scheme is:
> 
> update nu using MH updates or slice sampling
> Gibbs sample b and u together
> Gibbs sample (co)variance components sequentially.
> 
> For other models  such as ordinal regression or simultaneous/recursive models there are other schemes also, but these are quite specialised.
> 
> Cheers,
> 
> Jarrod
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> On 11 Nov 2010, at 23:45, John Maindonald wrote:
> 
>> The Wald tests (as represented in glm and glmer output of z-statistics
>> and p-values) are approximate for both glm models and glmm models
>> with non-identity links. The approximation can fail badly if the link is
>> highly non-linear over a region of the response that is relevant for a
>> parameter of interest.  The Hauck-Donner phenomenon, where the
>> z-statistic decreases as the effect estimate increases, is an extreme
>> example.
>> (This happens, e.g., as one of the levels being compared gives a
>> fitted value that moves close to a binomial proportion of 0 or 1, or
>> close to a Poisson estimate of 0.)
>> 
>> The additional complication for a glmm is that the SE may have
>> two components -- e.g., a poisson or binomial error, and a random
>> normal error that is added on the scale of the linear predictor.  This
>> random normal error somewhat alleviates variance change effects
>> (including Hauck-Donner) that result from non-linearity in the link,
>> while adding uncertainty to the SE estimate.  If the contribution from
>> the glm family error term is largish relative to contribution from the
>> random normal error (> 3 or 4  times as large?), treating the z-statistic
>> as normal may not in many circumstances be too unreasonable,
>> even if the relevant degrees of freedom are as small as maybe 4
>> (e.g., where the test is for consistency across 5 locations).
>> 
>> On data where I seem to have this situation, fairly consistently
>> across a number of responses, I initially used MCMCglmm().
>> I was concerned about the contribution from the random normal
>> error (including a contribution from an observation level random
>> effect term).  I found I hat I had to choose a somewhat informative
>> prior (inverse Wishart with V=1, nu=0.002) to consistently get
>> convergence.  With this prior, the MCMCglmm credible intervals
>> were remarkably close to glmer confidence intervals, treating the
>> z-statistics as normal.
>> 
>> No doubt the effect of the chosen prior is to insist that the true
>> random normal error variance is fairly close to the variance as
>> estimated by glmer().  A frustration (for me, at least) with using
>> MCMCglmm is that I do not know just what MCMCglmm() is doing
>> in this respect, short of doing some careful investigative exploration
>> of the MCMC simulation results (which is an after-the-event check,
>> where I'd like to know before the event).  Comments, Jarrod?
>> 
>> All this is to emphasise that we are not in the arena, unless the
>> relevant degrees of freedom are large, of precise science.
>> 
>> John Maindonald             email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Mathematics & Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>> http://www.maths.anu.edu.au/~johnm
>> 
>> On 12/11/2010, at 2:18 AM, Ben Bolker wrote:
>> 
>>> On 11/11/2010 09:58 AM, Jens ?str?m wrote:
>>>> Dear list,
>>>> 
>>>> As I have read (Bolker et al. 2009 TREE), the Wald Z test is only
>>>> appropriate for GLMMs in cases without overdispersion.
>>>> 
>>>> Assuming we use family=poisson with lmer and tackle overdispersion by
>>>> incorporating an individual random effect AND this adequately "reduces"
>>>> the overdispersion, is it then OK to use the Wald z test as reported by
>>>> lmer?
>>>> 
>>>> In other words, are the p-values reported by lmer in those cases
>>>> useful/"correct"? Or do they suffer from the usual problems with
>>>> figuring out the number of parameters used by the random effects?
>>> 
>>> They are equivalent to assuming an infinite/large 'denominator degrees
>>> of freedom'.  If you have a large sample size (both a large number of
>>> total samples relative to the number of parameters, and a large number
>>> of random-effects levels/blocks) then this should be reasonable -- if
>>> not, then yes, the 'usual problems with figuring out the number of
>>> parameters' is relevant.  On the other hand, if you're willing to assume
>>> that the sample size is large, then likelihood ratio rests
>>> (anova(model1,model2)) are probably better than the Wald tests anyway.
>>> 
>>>> 
>>>> Secondly, is it good practice to judge lmer's capability of "reducing"
>>>> the overdispersion by summing the squared residuals (pearson) and
>>>> compare this to a chi square distribution (with N-1 degrees of freedom)?
>>> 
>>> I would say this is reasonable, although again it's a rough guide
>>> because the true degrees of freedom are a bit fuzzy -- it should
>>> probably be at most N-(fixed effect degrees of freedom)?
>>> 
>>> Would be happy to hear any conflicting opinions.
>>> 
>>> Ben Bolker
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> 
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
> 



From andydolman at gmail.com  Sat Nov 13 09:30:07 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Sat, 13 Nov 2010 09:30:07 +0100
Subject: [R-sig-ME] glmer Z-test with individual random effects
In-Reply-To: <4CDC0928.9070405@gmail.com>
References: <4CDC048A.3040908@ekol.slu.se>
	<4CDC0928.9070405@gmail.com>
Message-ID: <AANLkTi=pqSy+V+EN4EYCySm1MJkiMOi4PfmFmB3poAdQ@mail.gmail.com>

Dear Ben,

Can I just check, is it necessary to have both a large total sample
size and a large number of levels of your random effect(s) for a
likelihood ratio test to be robust? Or does the large number of levels
requirement apply only to the Wald test? I'm referring to the part of
your answer below.

Thanks,

Andy.


"They are equivalent to assuming an infinite/large 'denominator degrees
of freedom'.  If you have a large sample size (both a large number of
total samples relative to the number of parameters, and a large number
of random-effects levels/blocks) then this should be reasonable -- if
not, then yes, the 'usual problems with figuring out the number of
parameters' is relevant.  On the other hand, if you're willing to assume
that the sample size is large, then likelihood ratio rests
(anova(model1,model2)) are probably better than the Wald tests anyway."



From j.hadfield at ed.ac.uk  Sat Nov 13 12:23:08 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 13 Nov 2010 11:23:08 +0000
Subject: [R-sig-ME] glmer Z-test with individual random effects
In-Reply-To: <755D562E-A8D2-4999-9507-9BAFF970EC99@anu.edu.au>
References: <4CDC048A.3040908@ekol.slu.se> <4CDC0928.9070405@gmail.com>
	<9BD43DA3-2EC7-4E91-B392-72E2A94D7E8F@anu.edu.au>
	<3F00BB51-2D71-476A-9637-A032E31EE51D@ed.ac.uk>
	<755D562E-A8D2-4999-9507-9BAFF970EC99@anu.edu.au>
Message-ID: <14C52455-2FEF-4E2F-91FA-044E61F52001@ed.ac.uk>

Hi,

I think this is a hard question to answer for complex models  
(otherwise MCMC would be redundant) but in simple situations the  
inverse-Wishart prior can be thought of as adding nu effects with  
known squared deviation V.

For example, we could have 5 levels of some factor (rfac) and observe  
10 data with pairs of observations associated with each level of rfac:

rfac<-gl(5,2)
e.rfac<-rnorm(5, 0, sqrt(0.1))
y<-rnorm(10)+e.rfac[rfac]
dat<-data.frame(y=y, rfac=rfac)

Here the intercept is 0.0, the residual variance is 1.0 and the  
variance of effects associated with rfac is 0.1. I'll call this last  
variance Vg.  We can fix the posterior for all parameters at their  
true values except Vg which has an IW prior with V=1 and nu=1:

prior1=list(B=list(mu=0, V=1e-6), R=list(V=1, fix=1),  
G=list(G1=list(V=1, nu=1)))

m1<-MCMCglmm(y~1, random=~rfac, data=dat, prior=prior1)

We could also observe an additional 1000 data points associated with a  
6th level of rfac which has an effect of 1.0:

  dat2<-data.frame(y=c(y,rnorm(1000)+1), rfac=c(rfac,rep(6, 1000)))

and analyse as before but with a flat prior (i.e. nu=0):

prior2=list(B=list(mu=0, V=1e-6), R=list(V=1, fix=1),  
G=list(G1=list(V=1, nu=0)))

m2<-MCMCglmm(y~1, random=~rfac, data=dat, prior=prior2)

The posterior distribution for Vg should be (almost) the same in both  
cases

plot(density(m1$VCV[,1]))
lines(density(m2$VCV[,1]), col="red")

With multi-parameter models, or quantities that are functions of two  
or more parameters, then this interpretation can be misleading.  
However, in many instances the idea does seem to serve as a good  
heuristic. The danger of course is thinking how can adding 1 prior  
effect (i.e. nu =1) make that much difference (compared to nu=0, say).  
It can when a) factor levels are poorly replicated b) replication  
within factor levels is poor and c) when prior V conflicts with the  
actual value of Vg.

Cheers,

Jarrod






On 13 Nov 2010, at 00:42, John Maindonald wrote:

> HI Jarrod -
> The mechanics of what is happening are not my issue.  What bothers
> me is that I do not have any intuitive sense of how the choice of  
> prior
> may be constraining the variance estimates.  Is it for example  
> possible
> to say that the effect is comparable to adding  some number of degrees
> of freedom to the variance estimate?  What is the balance between
> what comes from the prior, and what derives from the data?
> John.
>
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> http://www.maths.anu.edu.au/~johnm
>
> On 12/11/2010, at 10:51 PM, Jarrod Hadfield wrote:
>
>> Hi John,
>>
>> I'm not sure which part of the MCMCglmm routine is unclear but in a  
>> nut shell:
>>
>> The data are distributed according to the specified distribution  
>> (e.g. Poisson ) with the dsitribution parameter equal to the linear  
>> predictor (nu) on the inverse link scale:
>>
>> y ~ Pois(exp(nu))
>>
>> A linear (mixed) model is proposed for the linear predictor:
>>
>> nu ~ N(Xb+Zu, I*Ve)
>>
>> In all models a "units" term is included which is the same as an  
>> observational-level random effect.  This is the residual term in  
>> the linear part of the model.
>>
>> Priors are passed as  a list of the form:
>>
>> prior=list(B=list(),
>>              R=list(),
>>              G=list(G1=list(),
>>                          G2=list()))
>>
>>
>> where B is the prior for the fixed effects, R is the prior for Ve  
>> (or possibly a residual covariance matrix depending on the model)  
>> and the elements of G are the priors for each of the random effect  
>> (co)variances.
>>
>>
>> The prior for b is multivariate normal Pr(b) ~ N(B$mu, B$V)
>>
>> The prior for Ve is inverse-Wishart Pr(Ve) ~ IW(R$nu, R$V*R$nu)  
>> where the first term is the degree of belief and R$V*R$nu is the  
>> scale matrix
>>
>> The prior for the random effects variances (Vg) are set in the same  
>> way as Ve, although its possible to also fit parameter expanded  
>> priors.
>>
>> When the variance term is scalar (rather than a covariance matrix)  
>> then the inverse-Wishart and inverse-gamma are the same and IW(R 
>> $nu, R$V*R$nu) = IG(R$nu/2, R$V*R$nu/2) where the two parameters  
>> are the shape and scale. Your specification R=list(V=1, nu=0.002)   
>> is therefore  IG(0.001, 0.001) which used to be used a lot (and  
>> probably still is) as a "weak" prior by users of WinBUGS.  The REML  
>> estimator for Ve should be equal to the posterior mode in MCMCglmm  
>> when the improper prior R=list(V=0, nu=-2)  is used. 0 will not be  
>> accepted by MCMCglmm so you would have to use something small (e.g.  
>> 1e-6). The prior is improper so you have to be careful when using  
>> it, and although the point estimate may have some useful properties  
>> (the same as the REML estimate) the full posterior distribution may  
>> not be ideal with small sample sizes.
>>
>> The sampling scheme is:
>>
>> update nu using MH updates or slice sampling
>> Gibbs sample b and u together
>> Gibbs sample (co)variance components sequentially.
>>
>> For other models  such as ordinal regression or simultaneous/ 
>> recursive models there are other schemes also, but these are quite  
>> specialised.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> On 11 Nov 2010, at 23:45, John Maindonald wrote:
>>
>>> The Wald tests (as represented in glm and glmer output of z- 
>>> statistics
>>> and p-values) are approximate for both glm models and glmm models
>>> with non-identity links. The approximation can fail badly if the  
>>> link is
>>> highly non-linear over a region of the response that is relevant  
>>> for a
>>> parameter of interest.  The Hauck-Donner phenomenon, where the
>>> z-statistic decreases as the effect estimate increases, is an  
>>> extreme
>>> example.
>>> (This happens, e.g., as one of the levels being compared gives a
>>> fitted value that moves close to a binomial proportion of 0 or 1, or
>>> close to a Poisson estimate of 0.)
>>>
>>> The additional complication for a glmm is that the SE may have
>>> two components -- e.g., a poisson or binomial error, and a random
>>> normal error that is added on the scale of the linear predictor.   
>>> This
>>> random normal error somewhat alleviates variance change effects
>>> (including Hauck-Donner) that result from non-linearity in the link,
>>> while adding uncertainty to the SE estimate.  If the contribution  
>>> from
>>> the glm family error term is largish relative to contribution from  
>>> the
>>> random normal error (> 3 or 4  times as large?), treating the z- 
>>> statistic
>>> as normal may not in many circumstances be too unreasonable,
>>> even if the relevant degrees of freedom are as small as maybe 4
>>> (e.g., where the test is for consistency across 5 locations).
>>>
>>> On data where I seem to have this situation, fairly consistently
>>> across a number of responses, I initially used MCMCglmm().
>>> I was concerned about the contribution from the random normal
>>> error (including a contribution from an observation level random
>>> effect term).  I found I hat I had to choose a somewhat informative
>>> prior (inverse Wishart with V=1, nu=0.002) to consistently get
>>> convergence.  With this prior, the MCMCglmm credible intervals
>>> were remarkably close to glmer confidence intervals, treating the
>>> z-statistics as normal.
>>>
>>> No doubt the effect of the chosen prior is to insist that the true
>>> random normal error variance is fairly close to the variance as
>>> estimated by glmer().  A frustration (for me, at least) with using
>>> MCMCglmm is that I do not know just what MCMCglmm() is doing
>>> in this respect, short of doing some careful investigative  
>>> exploration
>>> of the MCMC simulation results (which is an after-the-event check,
>>> where I'd like to know before the event).  Comments, Jarrod?
>>>
>>> All this is to emphasise that we are not in the arena, unless the
>>> relevant degrees of freedom are large, of precise science.
>>>
>>> John Maindonald             email: john.maindonald at anu.edu.au
>>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>>> Centre for Mathematics & Its Applications, Room 1194,
>>> John Dedman Mathematical Sciences Building (Building 27)
>>> Australian National University, Canberra ACT 0200.
>>> http://www.maths.anu.edu.au/~johnm
>>>
>>> On 12/11/2010, at 2:18 AM, Ben Bolker wrote:
>>>
>>>> On 11/11/2010 09:58 AM, Jens ?str?m wrote:
>>>>> Dear list,
>>>>>
>>>>> As I have read (Bolker et al. 2009 TREE), the Wald Z test is only
>>>>> appropriate for GLMMs in cases without overdispersion.
>>>>>
>>>>> Assuming we use family=poisson with lmer and tackle  
>>>>> overdispersion by
>>>>> incorporating an individual random effect AND this adequately  
>>>>> "reduces"
>>>>> the overdispersion, is it then OK to use the Wald z test as  
>>>>> reported by
>>>>> lmer?
>>>>>
>>>>> In other words, are the p-values reported by lmer in those cases
>>>>> useful/"correct"? Or do they suffer from the usual problems with
>>>>> figuring out the number of parameters used by the random effects?
>>>>
>>>> They are equivalent to assuming an infinite/large 'denominator  
>>>> degrees
>>>> of freedom'.  If you have a large sample size (both a large  
>>>> number of
>>>> total samples relative to the number of parameters, and a large  
>>>> number
>>>> of random-effects levels/blocks) then this should be reasonable  
>>>> -- if
>>>> not, then yes, the 'usual problems with figuring out the number of
>>>> parameters' is relevant.  On the other hand, if you're willing to  
>>>> assume
>>>> that the sample size is large, then likelihood ratio rests
>>>> (anova(model1,model2)) are probably better than the Wald tests  
>>>> anyway.
>>>>
>>>>>
>>>>> Secondly, is it good practice to judge lmer's capability of  
>>>>> "reducing"
>>>>> the overdispersion by summing the squared residuals (pearson) and
>>>>> compare this to a chi square distribution (with N-1 degrees of  
>>>>> freedom)?
>>>>
>>>> I would say this is reasonable, although again it's a rough guide
>>>> because the true degrees of freedom are a bit fuzzy -- it should
>>>> probably be at most N-(fixed effect degrees of freedom)?
>>>>
>>>> Would be happy to hear any conflicting opinions.
>>>>
>>>> Ben Bolker
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>> -- 
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From bates at stat.wisc.edu  Sat Nov 13 14:03:10 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 13 Nov 2010 07:03:10 -0600
Subject: [R-sig-ME] parameterization for partly nested design with
 repeated measurements
In-Reply-To: <20101112232823.2140114i1irdy6qs@web-mail.uibk.ac.at>
References: <4CDD205B.8090704@uibk.ac.at>
	<AANLkTinho-pPMYg62exT-mKVcOZKnScgZfuYm4AfLG7O@mail.gmail.com>
	<20101112232823.2140114i1irdy6qs@web-mail.uibk.ac.at>
Message-ID: <AANLkTika=509pASBzhF+Jnd_eCfT=FzYJ7Xr0Un=sA-Q@mail.gmail.com>

On Fri, Nov 12, 2010 at 4:28 PM, Kay Cecil Cichini
<Kay.Cichini at uibk.ac.at> wrote:
> dear mr. bates,
>
> many thanks for answering to my mail.
> "1|school/class" is the same as "1|school + 1|class", isn't it?

If the classes have unique labels they are.  Technically the expression

(1 | school/year) expands to (1|school:class) + (1|school)

but if the classes are labeled uniquely then (1|school:class) is the
same as (1|class)

I find it easier to avoid using the (1|school/class) notation because
it is not commutative.  (1|class/school) is not the same as
(1|school/class) and I have seen people choose the wrong one.

The whole issue of crossed versus nested factors is in some ways
artificial.  The model specification in lmer and glmer is the same
provided that the factors have appropriate labels.

> - this would be the second model i mentioned.


> Zitat von Douglas Bates <bates at stat.wisc.edu>:
>
>> On Fri, Nov 12, 2010 at 5:09 AM, Kay Cecil Cichini
>> <Kay.Cichini at uibk.ac.at> wrote:
>>>
>>> dear listers,
>>>
>>> i'd very much appreciate help with setting up the right parameterization
>>> for
>>> the following design:
>>> 4 regions, in each region 3 to 12 schools, at each school 2-4 classes and
>>> each class tested before and after intervention, yielding a bimomial
>>> outcome
>>> (pupils that passed / not passed a test).
>>>
>>> i'm interested in differences between before and after (factor =
>>> "interv")
>>> intervention outcomes (X = passed, n = passed + not passed) and in the
>>> interaction region * interv.
>>>
>>> i tried with:
>>> glmer (cbind(X, n - X) ~ region * interv + (region | school / class),
>>> family
>>> = binomial)
>>
>> This model is generating an interaction between the fixed-effects
>> factor "region" and the random-effects factor "school", which doesn't
>> make sense because each school occurs within only one region.
>>
>> The simplest way to establish the desired structure is to create the
>> region, school and class factors so they follow the "each distinct
>> structure corresponds to a distinct level of the factor" rule. ?For
>> example, if you call the regions "A", "B", "C" and "D" and you call
>> the schools "A01", ... "A10", "B01", ..., "B06", "C01", ..., "C12" and
>> you call the classes "A01a", "A01b", "A01c", ..., "C12d" then you can
>> specify the model very easily as
>>
>> glmer(cbind(X, n - X) ~ region * interv + (1|school) + (1|class),
>> family = binomial)
>>
>> Most of the confusion about model specification comes from the
>> unfortunate practice of labeling the schools as "01", ..., "12"
>> without taking into account that school 1 in region A is not
>> associated in any way with school 1 in region C. ?In other words, all
>> you need to do is to disambiguate the names of the schools and the
>> classrooms.
>>
>>
>>> and with:
>>> glmer (cbind(X, n - X) ~ region * interv + (1 | school / class), family =
>>> binomial)
>>>
>>>
>>> i'd be happy about comments on the parameterization or any ideas.
>>>
>>> yours,
>>> kay
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>
>
>
>



From marina.saadia at gmail.com  Sat Nov 13 18:36:22 2010
From: marina.saadia at gmail.com (Marina SAADIA OTERO)
Date: Sat, 13 Nov 2010 18:36:22 +0100
Subject: [R-sig-ME] parameterization for partly nested design with
 repeated measurements
In-Reply-To: <AANLkTika=509pASBzhF+Jnd_eCfT=FzYJ7Xr0Un=sA-Q@mail.gmail.com>
References: <4CDD205B.8090704@uibk.ac.at>
	<AANLkTinho-pPMYg62exT-mKVcOZKnScgZfuYm4AfLG7O@mail.gmail.com>
	<20101112232823.2140114i1irdy6qs@web-mail.uibk.ac.at>
	<AANLkTika=509pASBzhF+Jnd_eCfT=FzYJ7Xr0Un=sA-Q@mail.gmail.com>
Message-ID: <AANLkTim6KTbZO8EuwQdfy9wPnTNUj212DSO4kmE3VXdM@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101113/f5ef1488/attachment.pl>

From Mike.Lawrence at dal.ca  Mon Nov 15 04:58:03 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Sun, 14 Nov 2010 23:58:03 -0400
Subject: [R-sig-ME] Analysis of signal detection data
Message-ID: <AANLkTik+i8-e=gZMdy7tvzypcF2G86M=s-GxstA1hRtX@mail.gmail.com>

Hi folks,

Yet another query on whether traditional stats employed in psychology
might be improved by mixed effects modelling...

Consider a radiologist looking at a CT scan and attempting to make the
binary diagnosis of cancer/no cancer. Signal detection theory suggests
that the normalized difference between the radiologist's hit rate and
false alarm rate provides a metric of the radiologist's discrimination
skill (d'). That is:

d' = qnorm(hit_rate) - qnorm(FA_rate)

Now, if we wanted to see if discrimination skill was improved by some
intervention, we might recruit a bunch of radiologists and measure
their d' both before and after the intervention. That is, both before
the intervention, each radiologist would be presented with a number of
"trials" where they review CT scans, mark them as cancer/no cancer,
and we experimentalists score each diagnosis as a hit, miss, false
alarm, or correct rejection.

Presented with data like this, most psychologists would compute a d'
score for each radiologist both before and after the intervention,
then submit the d' scores to a repeated-measures ANOVA, which assumes
gaussian error. However, hit and false alarm rates should yield
binomially distributed error distributions, and monte carlo
experimentation in R leads me to believe that in cases where only a
moderate number of CT scans are reviewed per session (say, 10-20), d'
may be expected to be considerably non-gaussian.

I know mixed effects modelling can handle binomially distributed
error, but is there any way to handle this sort of signal detection
data? My first thought is that glmmer with 4 categories corresponding
to the hit, miss, false alarm, and correction categorization of
responses, but I don't immediately see how this would properly connect
the hit-vs-miss data to reflect a hit rate and the
false-alarm-vs-correct-rejection data to reflect a FA rate.

Thoughts?

Mike

--
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~



From jsorkin at grecc.umaryland.edu  Mon Nov 15 05:21:49 2010
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Sun, 14 Nov 2010 23:21:49 -0500
Subject: [R-sig-ME] Analysis of signal detection data
In-Reply-To: <4CE06F0D020000CB0007970A@medicine.umaryland.edu>
References: <4CE06F0A020000CB00079707@medicine.umaryland.edu>
	<4CE06F0D020000CB0007970A@medicine.umaryland.edu>
Message-ID: <4CE06F0D020000CB0007970A@medicine.umaryland.edu>

Would logistic regression with a dichotomous variable indicating pre- or post-training provide an adequate model?
John 
John Sorkin
Chief Biostatistics and Informatics
Univ. of Maryland School of Medicine
Division of Gerontology and Geriatric Medicine
JSorkin at grecc.umaryland.edu 
-----Original Message-----
From: Mike Lawrence <Mike.Lawrence at dal.ca>
To:  <r-sig-mixed-models at r-project.org>

Sent: 11/14/2010 10:58:03 PM
Subject: [R-sig-ME] Analysis of signal detection data

Hi folks,

Yet another query on whether traditional stats employed in psychology
might be improved by mixed effects modelling...

Consider a radiologist looking at a CT scan and attempting to make the
binary diagnosis of cancer/no cancer. Signal detection theory suggests
that the normalized difference between the radiologist's hit rate and
false alarm rate provides a metric of the radiologist's discrimination
skill (d'). That is:

d' = qnorm(hit_rate) - qnorm(FA_rate)

Now, if we wanted to see if discrimination skill was improved by some
intervention, we might recruit a bunch of radiologists and measure
their d' both before and after the intervention. That is, both before
the intervention, each radiologist would be presented with a number of
"trials" where they review CT scans, mark them as cancer/no cancer,
and we experimentalists score each diagnosis as a hit, miss, false
alarm, or correct rejection.

Presented with data like this, most psychologists would compute a d'
score for each radiologist both before and after the intervention,
then submit the d' scores to a repeated-measures ANOVA, which assumes
gaussian error. However, hit and false alarm rates should yield
binomially distributed error distributions, and monte carlo
experimentation in R leads me to believe that in cases where only a
moderate number of CT scans are reviewed per session (say, 10-20), d'
may be expected to be considerably non-gaussian.

I know mixed effects modelling can handle binomially distributed
error, but is there any way to handle this sort of signal detection
data? My first thought is that glmmer with 4 categories corresponding
to the hit, miss, false alarm, and correction categorization of
responses, but I don't immediately see how this would properly connect
the hit-vs-miss data to reflect a hit rate and the
false-alarm-vs-correct-rejection data to reflect a FA rate.

Thoughts?

Mike

--
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Confidentiality Statement:
This email message, including any attachments, is for th...{{dropped:6}}



From Paul.Thompson at sanfordhealth.org  Mon Nov 15 06:13:26 2010
From: Paul.Thompson at sanfordhealth.org (Thompson,Paul)
Date: Sun, 14 Nov 2010 23:13:26 -0600
Subject: [R-sig-ME] Analysis of signal detection data
References: <AANLkTik+i8-e=gZMdy7tvzypcF2G86M=s-GxstA1hRtX@mail.gmail.com>
Message-ID: <4CF2646FA7AADD49A08570779F45B78D01BCF8EE@SVMAIL6.domain.siouxvalley.local>

Mike:

This situation is well described and most appropriately analyzed by the use of GEE methods.  Using GEE methods, you may examine data observed multiple Level 1 times for a given Level 2 unit (that is, multi-level data), but with a binomial (hit-miss, yes-no), Poisson (count), ordered categorical (ordinal), or several other distributions.  In these methods, you use linear models methods of least-squares estimation to obtain coefficients, but then use an appropriate error term to model the errors.

You may think of this as logistic regression with repeated measures if you wish since logistic regression involving yes-no data and generalized linear models involving binomial link function are the same model. And ROC curve analysis is performed more efficiently, and in a manner incorporating multiple covariates, using logistic regression. 

In short, your suggestion is a good one, and is quite well encompassed (but possibly not completely) using existing methods.

Software for these methods includes PROC GENMOD and LOGISTIC in SAS, MPlus for multivariate structural equation modeling of this logistic binomially distributed data, and a number of other programs as well.



-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org on behalf of Mike Lawrence
Sent: Sun 11/14/2010 9:58 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Analysis of signal detection data
 
Hi folks,

Yet another query on whether traditional stats employed in psychology
might be improved by mixed effects modelling...

Consider a radiologist looking at a CT scan and attempting to make the
binary diagnosis of cancer/no cancer. Signal detection theory suggests
that the normalized difference between the radiologist's hit rate and
false alarm rate provides a metric of the radiologist's discrimination
skill (d'). That is:

d' = qnorm(hit_rate) - qnorm(FA_rate)

Now, if we wanted to see if discrimination skill was improved by some
intervention, we might recruit a bunch of radiologists and measure
their d' both before and after the intervention. That is, both before
the intervention, each radiologist would be presented with a number of
"trials" where they review CT scans, mark them as cancer/no cancer,
and we experimentalists score each diagnosis as a hit, miss, false
alarm, or correct rejection.

Presented with data like this, most psychologists would compute a d'
score for each radiologist both before and after the intervention,
then submit the d' scores to a repeated-measures ANOVA, which assumes
gaussian error. However, hit and false alarm rates should yield
binomially distributed error distributions, and monte carlo
experimentation in R leads me to believe that in cases where only a
moderate number of CT scans are reviewed per session (say, 10-20), d'
may be expected to be considerably non-gaussian.

I know mixed effects modelling can handle binomially distributed
error, but is there any way to handle this sort of signal detection
data? My first thought is that glmmer with 4 categories corresponding
to the hit, miss, false alarm, and correction categorization of
responses, but I don't immediately see how this would properly connect
the hit-vs-miss data to reflect a hit rate and the
false-alarm-vs-correct-rejection data to reflect a FA rate.

Thoughts?

Mike

--
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-----------------------------------------------------------------------
Please note that My Email Address Has Changed!
Please begin using the address in the "From" line above, immediately.
Soon, email sent to my old address will no longer be delivered to me.

Confidentiality Notice: This e-mail message, including any attachments,
is for the sole use of the intended recipient(s) and may contain
privileged and confidential information.  Any unauthorized review, use,
disclosure or distribution is prohibited.  If you are not the intended
recipient, please contact the sender by reply e-mail and destroy
all copies of the original message.




From davidD at qimr.edu.au  Mon Nov 15 07:45:19 2010
From: davidD at qimr.edu.au (David Duffy)
Date: Mon, 15 Nov 2010 16:45:19 +1000 (EST)
Subject: [R-sig-ME] Analysis of signal detection data
In-Reply-To: <4CF2646FA7AADD49A08570779F45B78D01BCF8EE@SVMAIL6.domain.siouxvalley.local>
References: <AANLkTik+i8-e=gZMdy7tvzypcF2G86M=s-GxstA1hRtX@mail.gmail.com>
	<4CF2646FA7AADD49A08570779F45B78D01BCF8EE@SVMAIL6.domain.siouxvalley.local>
Message-ID: <Pine.LNX.4.64.1011151633080.18571@orpheus.qimr.edu.au>

On Sun, 14 Nov 2010, Thompson,Paul wrote:

>>
>> This situation is well described and most appropriately analyzed by the 
>> use of GEE methods.
> Mike Lawrence wrote:
>
> Yet another query on whether traditional stats employed in psychology
> might be improved by mixed effects modelling...
> [diagnostic accuracy v. gold standard]

As I understand it, GEE can be seen as an approximate method related to 
approaches such as quasi-likelihood, though there may be cases where its 
underlying model is closer to the true state of what you are actually 
looking at.  So, a GLMM may better -- I'm more familiar with SEM/ 
graphical models for this type of setup, in that they are more flexible
eg diagnosis where there is no gold standard diagnosis to compare to, 
mixture models for task difficulty... 
These will usually have a "full likelihood" GLMM underlying them, or some 
type of approximation eg Browne's WLS seen in Lisrel/MX.

Just 2c, David Duffy.
-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From ken.knoblauch at inserm.fr  Mon Nov 15 09:03:13 2010
From: ken.knoblauch at inserm.fr (Ken Knoblauch)
Date: Mon, 15 Nov 2010 08:03:13 +0000 (UTC)
Subject: [R-sig-ME] Analysis of signal detection data
References: <AANLkTik+i8-e=gZMdy7tvzypcF2G86M=s-GxstA1hRtX@mail.gmail.com>
	<4CF2646FA7AADD49A08570779F45B78D01BCF8EE@SVMAIL6.domain.siouxvalley.local>
	<Pine.LNX.4.64.1011151633080.18571@orpheus.qimr.edu.au>
Message-ID: <loom.20101115T090214-752@post.gmane.org>

David Duffy <davidD at ...> writes:
> On Sun, 14 Nov 2010, Thompson,Paul wrote:
> >> This situation is well described and most appropriately analyzed by the 
> >> use of GEE methods.
> > Mike Lawrence wrote:
> > Yet another query on whether traditional stats employed in psychology
> > might be improved by mixed effects modelling...
> > [diagnostic accuracy v. gold standard]
> As I understand it, GEE can be seen as an approximate method related to 
> approaches such as quasi-likelihood, though there may be cases where its 
> underlying model is closer to the true state of what you are actually 
> looking at.  So, a GLMM may better -- I'm more familiar with SEM/ 
> graphical models for this type of setup, in that they are more flexible
> eg diagnosis where there is no gold standard diagnosis to compare to, 
> mixture models for task difficulty... 
> These will usually have a "full likelihood" GLMM underlying them, or some 
> type of approximation eg Browne's WLS seen in Lisrel/MX.
> 
> Just 2c, David Duffy.
The classic signal detection theory (SDT) model, 
in which an observer's choice behavior is modeled by an 
unobserved decision variable contaminated by noise, is
essentially a probit model (see Green & Swets and 
Macmillan &  Creelman references below).  A logistic 
version called choice theory was developed by Luce.  
A clear formalization in terms of GLMs is given in the 
DeCarlo reference below (but see also the Klein reference 
for a general extension to psychometric function fitting
and the 2 papers by Wichmann & Hill in the same special
issue) with extensions to rating scales using ordinal
regression.

In R, these models can be simply fit with a glm, taking
the observer's response as a 2-level variable (factor or
logical) and the stimulus (signal present/absent) as a 
2-level factor.  The model would be 

g(E(Pr(Resp = 1))) = beta_0 + beta_1 Stim,

where g is the link function, taken as an inverse
Gaussian for the probit case.  When, the stimulus is
absent, the linear predictor gives beta_0 which
equals Phi^-1(Pr(False Alarm)) = z(FA) (to use the
more conventional SDT terminology).  Treatment contrasts
then directly give you z(Hit) - z(FA) = d'.
For example,

Stim <- rep(factor(c(0, 1), labels = c("A", "P")), 
	each = 500)
##unbiased observer w/ true d' = 1.0	
Resp <- ((Stim == "P") + rnorm(length(Stim))) > 0

glm(Resp ~ Stim, binomial(probit))
Call:  glm(formula = Resp ~ Stim, family = binomial(probit))

Coefficients:
(Intercept)        StimP  
   -0.05015      1.03642  

Degrees of Freedom: 999 Total (i.e. Null);  998 Residual
Null Deviance:	    1283 
Residual Deviance: 1135 	AIC: 1139

Compare this with the manual method of calculating d' 
given in SDT texts.

( dp.tab <- prop.table(table(Stim, Resp), margin = 1) )

    Resp
Stim FALSE  TRUE
   A 0.520 0.480
   P 0.162 0.838

diff(qnorm(dp.tab[, 2]))

       P 
1.036425 


The extension to more complex GLM's with more complex
explanatory variables as well as to miwed-effects models
with glmer then follows quite naturally.
(You can't extend this to m-alternative forced-choice
in a simple way, i.e., you cannot simply substitute
one of the links from the psyphy package in the glm.
The situation is more complicated than that.)
With glmer you can add observer and item random effects.
If you had several observers in the above toy example,
you could include terms (1 | Obs) for random criterion
models and (Stim | Obs) to model both random criterion 
and random sensitivity (using SDT jargon, here).

The sdtalt package provides a simplified interface
(wrapper function) for specifying response, stimulus, 
observer and item variables although the last time that I
looked at the code, the Resp and Stim (or equivalent) 
variables were reversed in the call to glmer.

See also, the MLDS and MLCM packages for extensions of
an SDT model to choices involving suprathreshold stimuli


@Book{GreenSwets66,
  author = 	 {D. M. Green  and J. A. Swets},
  title = 	 {Signal Detection Theory and Psychophysics},
  publisher = 	 {Robert E. Krieger Publishing Company},
  year = 	 {1966},
  address = 	 {Huntington},
}

@Book{MacCreel,
  author = 	 {N.~A.~Macmillan and C.~D.~Creelman},
  title = 	 {Detection Theory:  A User's Guide},
  publisher = 	 {Lawrence Erlbaum Associates},
  year = 	 {2005},
  address = 	 {New York},
  edition = 	 {Second},
}

@Article{DeCarlo98,
  author = 	 {L. T. De{C}arlo},
  title = 	 {Signal detection theory and generalized linear models},
  journal = 	 {Psych Meth},
  year = 	 {1998},
  volume = 	 {3},
  pages = 	 {186--205},
}

@Article{Klein01,
   Author="Klein, S. A. ",
   Title="{{M}easuring, estimating, and understanding 
the psychometric function: a commentary}",
   Journal="Perception \& Psychophysics",
   Year="2001",
   Volume="63",
   Pages="1421--1455",
   Month="Nov"
}



From edgar.merkle at wichita.edu  Mon Nov 15 18:17:01 2010
From: edgar.merkle at wichita.edu (Ed Merkle)
Date: Mon, 15 Nov 2010 11:17:01 -0600
Subject: [R-sig-ME] Analysis of signal detection data
In-Reply-To: <mailman.5.1289818802.21521.r-sig-mixed-models@r-project.org>
References: <mailman.5.1289818802.21521.r-sig-mixed-models@r-project.org>
Message-ID: <4CE16B0D.7010009@wichita.edu>

Mike,

I would add the following paper, which discusses Bayesian SDT models. 
Rouder's website may have software to estimate the models.


@ARTICLE{RouLu05,
   author = {J. N. Rouder and J. Lu},
   title = {An introduction to {B}ayesian hierarchical models with an 
application in the theory of signal detection},
   journal = {Psychonomic Bulletin and Review},
   year = {2005},
   volume = {12},
   pages = {573-604}
}


Ed

-- 
Ed Merkle, PhD
Assistant Professor
Department of Psychology
Wichita State University
Wichita, KS, USA 67260
http://psychology.wichita.edu/merkle



-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org on behalf of Mike Lawrence
Sent: Sun 11/14/2010 9:58 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Analysis of signal detection data


I know mixed effects modelling can handle binomially distributed
error, but is there any way to handle this sort of signal detection
data? My first thought is that glmmer with 4 categories corresponding
to the hit, miss, false alarm, and correction categorization of
responses, but I don't immediately see how this would properly connect
the hit-vs-miss data to reflect a hit rate and the
false-alarm-vs-correct-rejection data to reflect a FA rate.

Thoughts?

Mike

--
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~



From Kay.Cichini at uibk.ac.at  Fri Nov 12 23:28:23 2010
From: Kay.Cichini at uibk.ac.at (Kay Cecil Cichini)
Date: Fri, 12 Nov 2010 23:28:23 +0100
Subject: [R-sig-ME] parameterization for partly nested design with
 repeated measurements
In-Reply-To: <AANLkTinho-pPMYg62exT-mKVcOZKnScgZfuYm4AfLG7O@mail.gmail.com>
References: <4CDD205B.8090704@uibk.ac.at>
	<AANLkTinho-pPMYg62exT-mKVcOZKnScgZfuYm4AfLG7O@mail.gmail.com>
Message-ID: <20101112232823.2140114i1irdy6qs@web-mail.uibk.ac.at>

dear mr. bates,

many thanks for answering to my mail.
"1|school/class" is the same as "1|school + 1|class", isn't it? - this  
would be the second model i mentioned.

yours,
kay cichini



Zitat von Douglas Bates <bates at stat.wisc.edu>:

> On Fri, Nov 12, 2010 at 5:09 AM, Kay Cecil Cichini
> <Kay.Cichini at uibk.ac.at> wrote:
>> dear listers,
>>
>> i'd very much appreciate help with setting up the right parameterization for
>> the following design:
>> 4 regions, in each region 3 to 12 schools, at each school 2-4 classes and
>> each class tested before and after intervention, yielding a bimomial outcome
>> (pupils that passed / not passed a test).
>>
>> i'm interested in differences between before and after (factor = "interv")
>> intervention outcomes (X = passed, n = passed + not passed) and in the
>> interaction region * interv.
>>
>> i tried with:
>> glmer (cbind(X, n - X) ~ region * interv + (region | school / class), family
>> = binomial)
>
> This model is generating an interaction between the fixed-effects
> factor "region" and the random-effects factor "school", which doesn't
> make sense because each school occurs within only one region.
>
> The simplest way to establish the desired structure is to create the
> region, school and class factors so they follow the "each distinct
> structure corresponds to a distinct level of the factor" rule.  For
> example, if you call the regions "A", "B", "C" and "D" and you call
> the schools "A01", ... "A10", "B01", ..., "B06", "C01", ..., "C12" and
> you call the classes "A01a", "A01b", "A01c", ..., "C12d" then you can
> specify the model very easily as
>
> glmer(cbind(X, n - X) ~ region * interv + (1|school) + (1|class),
> family = binomial)
>
> Most of the confusion about model specification comes from the
> unfortunate practice of labeling the schools as "01", ..., "12"
> without taking into account that school 1 in region A is not
> associated in any way with school 1 in region C.  In other words, all
> you need to do is to disambiguate the names of the schools and the
> classrooms.
>
>
>> and with:
>> glmer (cbind(X, n - X) ~ region * interv + (1 | school / class), family =
>> binomial)
>>
>>
>> i'd be happy about comments on the parameterization or any ideas.
>>
>> yours,
>> kay
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>



From Mike.Lawrence at dal.ca  Mon Nov 15 19:29:48 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Mon, 15 Nov 2010 14:29:48 -0400
Subject: [R-sig-ME] Analysis of signal detection data
In-Reply-To: <4CE16B0D.7010009@wichita.edu>
References: <mailman.5.1289818802.21521.r-sig-mixed-models@r-project.org>
	<4CE16B0D.7010009@wichita.edu>
Message-ID: <AANLkTimm39JkPD5AK7b0MBX6pFMDbba3i2EpTeU0caJ5@mail.gmail.com>

Thanks all for your responses and input! :O)

Cheers,

Mike

--
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~



On Mon, Nov 15, 2010 at 1:17 PM, Ed Merkle <edgar.merkle at wichita.edu> wrote:
> Mike,
>
> I would add the following paper, which discusses Bayesian SDT models.
> Rouder's website may have software to estimate the models.
>
>
> @ARTICLE{RouLu05,
> ?author = {J. N. Rouder and J. Lu},
> ?title = {An introduction to {B}ayesian hierarchical models with an
> application in the theory of signal detection},
> ?journal = {Psychonomic Bulletin and Review},
> ?year = {2005},
> ?volume = {12},
> ?pages = {573-604}
> }
>
>
> Ed
>
> --
> Ed Merkle, PhD
> Assistant Professor
> Department of Psychology
> Wichita State University
> Wichita, KS, USA 67260
> http://psychology.wichita.edu/merkle
>
>
>
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org on behalf of Mike Lawrence
> Sent: Sun 11/14/2010 9:58 PM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Analysis of signal detection data
>
>
> I know mixed effects modelling can handle binomially distributed
> error, but is there any way to handle this sort of signal detection
> data? My first thought is that glmmer with 4 categories corresponding
> to the hit, miss, false alarm, and correction categorization of
> responses, but I don't immediately see how this would properly connect
> the hit-vs-miss data to reflect a hit rate and the
> false-alarm-vs-correct-rejection data to reflect a FA rate.
>
> Thoughts?
>
> Mike
>
> --
> Mike Lawrence
> Graduate Student
> Department of Psychology
> Dalhousie University
>
> Looking to arrange a meeting? Check my public calendar:
> http://tr.im/mikes_public_calendar
>
> ~ Certainty is folly... I think. ~
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From andydolman at gmail.com  Mon Nov 15 19:55:52 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Mon, 15 Nov 2010 19:55:52 +0100
Subject: [R-sig-ME] parameterization for partly nested design with
 repeated measurements
In-Reply-To: <AANLkTim6KTbZO8EuwQdfy9wPnTNUj212DSO4kmE3VXdM@mail.gmail.com>
References: <4CDD205B.8090704@uibk.ac.at>
	<AANLkTinho-pPMYg62exT-mKVcOZKnScgZfuYm4AfLG7O@mail.gmail.com>
	<20101112232823.2140114i1irdy6qs@web-mail.uibk.ac.at>
	<AANLkTika=509pASBzhF+Jnd_eCfT=FzYJ7Xr0Un=sA-Q@mail.gmail.com>
	<AANLkTim6KTbZO8EuwQdfy9wPnTNUj212DSO4kmE3VXdM@mail.gmail.com>
Message-ID: <AANLkTi=WFfsQEsEVVWyU7Bi-YUwn1_6Rz+eFGBBWeUEM@mail.gmail.com>

What Dr Bates means is, in case he's not here to answer himself, that

(1|school/class)   always means class nested in school

but it's easy to confuse this notation and by mistake write

(1|class/school)  meaning school nested in class, which does not make sense



andydolman at gmail.com



On 13 November 2010 18:36, Marina SAADIA OTERO <marina.saadia at gmail.com> wrote:
> Dear Mr Bates
> Thanks ?very much for all your remarks.
>
>> "1|school/class" is the same as "1|school + 1|class", isn't it?
>>
>> If the classes have unique labels they are. ?Technically the expression
>>
>> (1 | school/year) expands to (1|school:class) + (1|school)
>>
>> but if the classes are labeled uniquely then (1|school:class) is the
>> same as (1|class)
>>
>
> Do you mean that the notation (1|school/class) do not always read "class
> nested in school and, both class and school, as random effects" ?
>
> Regards,
> Marina
>
>>
>>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From djmuser at gmail.com  Tue Nov 16 04:19:16 2010
From: djmuser at gmail.com (Dennis Murphy)
Date: Mon, 15 Nov 2010 19:19:16 -0800
Subject: [R-sig-ME] parameterization for partly nested design with
 repeated measurements
In-Reply-To: <20101112232823.2140114i1irdy6qs@web-mail.uibk.ac.at>
References: <4CDD205B.8090704@uibk.ac.at>
	<AANLkTinho-pPMYg62exT-mKVcOZKnScgZfuYm4AfLG7O@mail.gmail.com>
	<20101112232823.2140114i1irdy6qs@web-mail.uibk.ac.at>
Message-ID: <AANLkTi=maqUGZt=oXC_z4kSGSgYbkL9ycbxak4v_7VVy@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101115/d6cff478/attachment.pl>

From pmilin at ff.uns.ac.rs  Tue Nov 16 13:41:28 2010
From: pmilin at ff.uns.ac.rs (Petar Milin)
Date: Tue, 16 Nov 2010 13:41:28 +0100
Subject: [R-sig-ME] Prediction interval values
Message-ID: <4CE27BF8.3080600@ff.uns.ac.rs>

Hello!
Sorry for posting this here, but I did not get any answer at the R-help list. In brief,
I wonder how can one get upper and lower limits of a prediction interval
-- exact values, for random-effects? They are shown on caterpillar plot using ranef() with
argument postVar=TRUE, but I would like to know them. A while ago, some
discussions were opened on "Confidence Intervals for Random Effect
BLUP's", but the answer was never clear:
http://www.mail-archive.com/r-help at r-project.org/msg04820.html

Thanks!
PM



From marina.saadia at gmail.com  Tue Nov 16 16:15:32 2010
From: marina.saadia at gmail.com (Marina SAADIA OTERO)
Date: Tue, 16 Nov 2010 16:15:32 +0100
Subject: [R-sig-ME] parameterization for partly nested design with
 repeated measurements
In-Reply-To: <AANLkTi=maqUGZt=oXC_z4kSGSgYbkL9ycbxak4v_7VVy@mail.gmail.com>
References: <4CDD205B.8090704@uibk.ac.at>
	<AANLkTinho-pPMYg62exT-mKVcOZKnScgZfuYm4AfLG7O@mail.gmail.com>
	<20101112232823.2140114i1irdy6qs@web-mail.uibk.ac.at>
	<AANLkTi=maqUGZt=oXC_z4kSGSgYbkL9ycbxak4v_7VVy@mail.gmail.com>
Message-ID: <AANLkTimdXQ9tMTas-06PJwGZFCSTfWF3JMnK5NZudCJv@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101116/367fbffc/attachment.pl>

From bates at stat.wisc.edu  Tue Nov 16 22:00:55 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 16 Nov 2010 15:00:55 -0600
Subject: [R-sig-ME] [R] Question about GLMER
In-Reply-To: <A9A9D4085E3D4A7CA051A1119C7C4257@JeskePC>
References: <A9A9D4085E3D4A7CA051A1119C7C4257@JeskePC>
Message-ID: <AANLkTiky_1oqZDvwDnms7FS5BTUGC9y_J4B9RvWYX=KW@mail.gmail.com>

I am cc:ing the R-SIG-Mixed-Models at R-project.org mailing list on this
reply as such questions are often answered more quickly on that list.

On Tue, Nov 16, 2010 at 2:00 PM, Daniel Jeske <daniel.jeske at ucr.edu> wrote:
> Dear R Help,

> I believe the glmer() function in lme4 automatically fits an
> unstrucruted covariance matirx for the random effects.
> Is that true?

The short answer is "no".

The longer answer is that you will need to be more specific about the
form of the data and the model before your question can be answered.
"unstructured" variance-covariance is SAS-speak (and an oxymoron, but
I promise not to rant about that).

So please give us a context.

> ? ?If so, do I have an option to somehow ask for a
> diagonal structured covariance matrix?



From bates at stat.wisc.edu  Tue Nov 16 23:48:52 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 16 Nov 2010 16:48:52 -0600
Subject: [R-sig-ME] [R] Question about GLMER
In-Reply-To: <F592767DEB6042F6AD446B163DF181C7@JeskePC>
References: <AANLkTiky_1oqZDvwDnms7FS5BTUGC9y_J4B9RvWYX=KW@mail.gmail.com>
	<F592767DEB6042F6AD446B163DF181C7@JeskePC>
Message-ID: <AANLkTim1-tkmmWUjMHus0a5Jq-Gyw1zo9sFNRR56BswV@mail.gmail.com>

On Tue, Nov 16, 2010 at 4:02 PM, Daniel Jeske <daniel.jeske at ucr.edu> wrote:
> Hi All -

> Doug, thanks for your reply. ?The context I'm looking at is a Poisson
> GLMM with random (intercept,slope) for each subject. ?The
> variance-covariance matrix is 2x2. ?By unstructured, I meant a 3
> parameter matrix (sig1^2,sig2^2,sig12), as compared to a (reduced)
> alternative diagonal structure.

I thought that might be what you were doing. Look at the fm1 and fm2 from

example(lmer)

fm1 allows for correlation of the random effects within subject.  fm2 doesn't.

>
> Dan
>
> -----Original Message-----
> From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas
> Bates
> Sent: Tuesday, November 16, 2010 1:01 PM
> To: Daniel Jeske
> Cc: r-help at r-project.org; R-mixed models mailing list
> Subject: Re: [R] Question about GLMER
>
>
> I am cc:ing the R-SIG-Mixed-Models at R-project.org mailing list on this
> reply as such questions are often answered more quickly on that list.
>
> On Tue, Nov 16, 2010 at 2:00 PM, Daniel Jeske <daniel.jeske at ucr.edu>
> wrote:
>> Dear R Help,
>
>> I believe the glmer() function in lme4 automatically fits an
>> unstrucruted covariance matirx for the random effects. Is that true?
>
> The short answer is "no".
>
> The longer answer is that you will need to be more specific about the
> form of the data and the model before your question can be answered.
> "unstructured" variance-covariance is SAS-speak (and an oxymoron, but I
> promise not to rant about that).
>
> So please give us a context.
>
>> ? ?If so, do I have an option to somehow ask for a
>> diagonal structured covariance matrix?
> No virus found in this incoming message.
> Checked by AVG - www.avg.com
> Version: 9.0.869 / Virus Database: 271.1.1/3237 - Release Date: 11/15/10
> 23:34:00
>
>
>



From daniel.jeske at ucr.edu  Tue Nov 16 23:02:19 2010
From: daniel.jeske at ucr.edu (Daniel Jeske)
Date: Tue, 16 Nov 2010 14:02:19 -0800
Subject: [R-sig-ME] [R] Question about GLMER
In-Reply-To: <AANLkTiky_1oqZDvwDnms7FS5BTUGC9y_J4B9RvWYX=KW@mail.gmail.com>
Message-ID: <F592767DEB6042F6AD446B163DF181C7@JeskePC>

Hi All -

Doug, thanks for your reply.  The context I'm looking at is a Poisson
GLMM with random (intercept,slope) for each subject.  The
variance-covariance matrix is 2x2.  By unstructured, I meant a 3
parameter matrix (sig1^2,sig2^2,sig12), as compared to a (reduced)
alternative diagonal structure.

Dan

-----Original Message-----
From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas
Bates
Sent: Tuesday, November 16, 2010 1:01 PM
To: Daniel Jeske
Cc: r-help at r-project.org; R-mixed models mailing list
Subject: Re: [R] Question about GLMER


I am cc:ing the R-SIG-Mixed-Models at R-project.org mailing list on this
reply as such questions are often answered more quickly on that list.

On Tue, Nov 16, 2010 at 2:00 PM, Daniel Jeske <daniel.jeske at ucr.edu>
wrote:
> Dear R Help,

> I believe the glmer() function in lme4 automatically fits an 
> unstrucruted covariance matirx for the random effects. Is that true?

The short answer is "no".

The longer answer is that you will need to be more specific about the
form of the data and the model before your question can be answered.
"unstructured" variance-covariance is SAS-speak (and an oxymoron, but I
promise not to rant about that).

So please give us a context.

> ? ?If so, do I have an option to somehow ask for a
> diagonal structured covariance matrix?
No virus found in this incoming message.
Checked by AVG - www.avg.com 

23:34:00



From mlarkin at rsmas.miami.edu  Wed Nov 17 05:57:57 2010
From: mlarkin at rsmas.miami.edu (Michael Larkin)
Date: Tue, 16 Nov 2010 23:57:57 -0500
Subject: [R-sig-ME] declaring the variables
Message-ID: <000001cb8614$009d2e40$01d78ac0$@miami.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101116/d29b97e7/attachment.pl>

From andydolman at gmail.com  Wed Nov 17 08:57:25 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Wed, 17 Nov 2010 08:57:25 +0100
Subject: [R-sig-ME] declaring the variables
In-Reply-To: <000001cb8614$009d2e40$01d78ac0$@miami.edu>
References: <AcuGFABrAG2MxKZuRCepFkc/qpehsw==>
	<000001cb8614$009d2e40$01d78ac0$@miami.edu>
Message-ID: <AANLkTikmoccmmVBuCjKF6NA5-XPpsQ6qKD0X1PJ_=9kc@mail.gmail.com>

Hi Michael,

You will need to use a different function than glm(). Something from
an additional R package such as nlme or lme4.

There's some information here:
http://glmm.wikidot.com/


With glmm() from lme4 your model specification would look something like this:

fish <- glmm(Catch ~ Season + Tide + (1|Angler),
family=gaussian(identity), data=fishcatch)


Assuming Catch is appropriately modelled as gaussian that is.



andydolman at gmail.com



On 17 November 2010 05:57, Michael Larkin <mlarkin at rsmas.miami.edu> wrote:
> I am running a GLM with catch data from a fishery. ?I understand how to run
> a GLM in R. ?What I don't understand is how to declare the types of
> variables that I have. ?For example, I am modeling catch with several
> different types of variables. ?Here are details on my variables:
>
>
>
> Variable ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Type
> comment
>
> Anglers ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? random factor ? ? ? ? ? ? ? ? ? I
> have the names of over 100 anglers.
>
> Season ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? fixed factors ? ? ? ? ? ? ? ? ? ? ? I
> broke it up into the 4 seasons
>
> Tide phase ? ? ? ? ? ? ? ? ? ? ? ? ?Continuous variable ? ? ? ?I have the
> proportion of the tide phase during the fishing event
>
>
>
> My R code for the GLM is:
>
>
>
> fish <- glm(Catch ~ Angler +Season + Tide, family=gaussian(identity),
> data=fishcatch)
>
>
>
> However, how do declare the types of variables used in the model? ?For
> example, how do I declare that the angler variable is a random factor?
>
>
>
> Any help would be greatly appreciated.
>
>
>
> Mike
>
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From andydolman at gmail.com  Wed Nov 17 08:57:25 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Wed, 17 Nov 2010 08:57:25 +0100
Subject: [R-sig-ME] declaring the variables
In-Reply-To: <000001cb8614$009d2e40$01d78ac0$@miami.edu>
References: <AcuGFABrAG2MxKZuRCepFkc/qpehsw==>
	<000001cb8614$009d2e40$01d78ac0$@miami.edu>
Message-ID: <AANLkTikmoccmmVBuCjKF6NA5-XPpsQ6qKD0X1PJ_=9kc@mail.gmail.com>

Hi Michael,

You will need to use a different function than glm(). Something from
an additional R package such as nlme or lme4.

There's some information here:
http://glmm.wikidot.com/


With glmm() from lme4 your model specification would look something like this:

fish <- glmm(Catch ~ Season + Tide + (1|Angler),
family=gaussian(identity), data=fishcatch)


Assuming Catch is appropriately modelled as gaussian that is.



andydolman at gmail.com



On 17 November 2010 05:57, Michael Larkin <mlarkin at rsmas.miami.edu> wrote:
> I am running a GLM with catch data from a fishery. ?I understand how to run
> a GLM in R. ?What I don't understand is how to declare the types of
> variables that I have. ?For example, I am modeling catch with several
> different types of variables. ?Here are details on my variables:
>
>
>
> Variable ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Type
> comment
>
> Anglers ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? random factor ? ? ? ? ? ? ? ? ? I
> have the names of over 100 anglers.
>
> Season ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? fixed factors ? ? ? ? ? ? ? ? ? ? ? I
> broke it up into the 4 seasons
>
> Tide phase ? ? ? ? ? ? ? ? ? ? ? ? ?Continuous variable ? ? ? ?I have the
> proportion of the tide phase during the fishing event
>
>
>
> My R code for the GLM is:
>
>
>
> fish <- glm(Catch ~ Angler +Season + Tide, family=gaussian(identity),
> data=fishcatch)
>
>
>
> However, how do declare the types of variables used in the model? ?For
> example, how do I declare that the angler variable is a random factor?
>
>
>
> Any help would be greatly appreciated.
>
>
>
> Mike
>
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From pmilin at ff.uns.ac.rs  Wed Nov 17 09:18:44 2010
From: pmilin at ff.uns.ac.rs (Petar Milin)
Date: Wed, 17 Nov 2010 09:18:44 +0100
Subject: [R-sig-ME] declaring the variables
In-Reply-To: <000001cb8614$009d2e40$01d78ac0$@miami.edu>
References: <000001cb8614$009d2e40$01d78ac0$@miami.edu>
Message-ID: <4CE38FE4.5090908@ff.uns.ac.rs>

Hello!
Maybe I am missing something, but I think you should first check how R 
"understands" your data structure:
 > str(<data-frame-name>)
 From this you can explitily define type that you need/want, like:
 > <data-frame-name>$Anglers = as.factor(<data-frame-name>$Anglers)
 > <data-frame-name>$Season = as.factor(<data-frame-name>$Season)
 > <data-frame-name>$Tide.phase = as.numeric(<data-frame-name>$Tide.phase)
Also, you can use: as.logical(), as.integer(), even as.character() and 
some others.

Again, I apologize if I understood you problem wrongly, but this seems 
to me a solution.

Best,
PM

On 17/11/10 05:57, Michael Larkin wrote:
> I am running a GLM with catch data from a fishery.  I understand how to run
> a GLM in R.  What I don't understand is how to declare the types of
> variables that I have.  For example, I am modeling catch with several
> different types of variables.  Here are details on my variables:
>
>
>
> Variable                               Type
> comment
>
> Anglers                                 random factor                   I
> have the names of over 100 anglers.
>
> Season                                 fixed factors                       I
> broke it up into the 4 seasons
>
> Tide phase                          Continuous variable        I have the
> proportion of the tide phase during the fishing event
>
>
>
> My R code for the GLM is:
>
>
>
> fish<- glm(Catch ~ Angler +Season + Tide, family=gaussian(identity),
> data=fishcatch)
>
>
>
> However, how do declare the types of variables used in the model?  For
> example, how do I declare that the angler variable is a random factor?
>
>
>
> Any help would be greatly appreciated.
>
>
>
> Mike
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



From pmilin at ff.uns.ac.rs  Wed Nov 17 09:25:35 2010
From: pmilin at ff.uns.ac.rs (Petar Milin)
Date: Wed, 17 Nov 2010 09:25:35 +0100
Subject: [R-sig-ME] declaring the variables
In-Reply-To: <000001cb8614$009d2e40$01d78ac0$@miami.edu>
References: <000001cb8614$009d2e40$01d78ac0$@miami.edu>
Message-ID: <4CE3917F.1040602@ff.uns.ac.rs>

Sorry, again, mail went before I concluded.
As to second part:
> fish<- glm(Catch ~ Angler +Season + Tide, family=gaussian(identity),
> data=fishcatch)
>
> However, how do declare the types of variables used in the model?  For
> example, how do I declare that the angler variable is a random factor?
>    
Then, you should use something like:

fish <- lmer(Catch ~ Season + Tide + (1|Angler), data=fishcatch)

In lmer(), Gaussian is the default and linear mixed-model is fit, but 
you can also use 'binomial', 'poisson' etc, and then generalized linear 
mixed-model is fit.

Best,
PM



From andydolman at gmail.com  Wed Nov 17 20:11:29 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Wed, 17 Nov 2010 20:11:29 +0100
Subject: [R-sig-ME] declaring the variables
In-Reply-To: <001101cb8688$5eb49bc0$1c1dd340$@miami.edu>
References: <000001cb8614$009d2e40$01d78ac0$@miami.edu>
	<AANLkTimAYg9QxvogkVDVZJHzrQmwxZM9gTdK7T5PtE=b@mail.gmail.com>
	<001101cb8688$5eb49bc0$1c1dd340$@miami.edu>
Message-ID: <AANLkTimUv8DWeFGjcAoffyNa7+sLG7Mfyz8ynQ+Ups88@mail.gmail.com>

lmer or glmm, the distinction (from a user point of view) is like lm
vs glm. If you are using a Gaussian model then either will work. If
you want to use a non-gaussian model then you will need to use glmm.



andydolman at gmail.com



On 17 November 2010 19:50, Michael Larkin <mlarkin at rsmas.miami.edu> wrote:
> Awesome!? All three of you have been extremely helpful.? Thanks!
>
>
>
> I have a couple of follow-up questions.
>
>
>
> When I log transformed my catch data to make it normally (gaussian)
> distributed.? Therefore, I do have normally distributed random error terms.
> I will log transform the catch before I apply the model.
>
>
>
> I will do the declaring steps suggested by Petar where I declare the
> variables (Angler = factor, Season=factor, and tide phase = numeric).
>
>
>
> So by using (1 | Angler) in the model for my angler variable (i.e. Joe
> Smith, John Doe, ect) it makes this variable have a random intercept?
>
>
>
> My last question, from reading your emails I should pursue the glmm instead
> of the lmer function because of the random nature of my angler variable?
>
>
>
> Mike
>
>
>
>
>
>



From bates at stat.wisc.edu  Wed Nov 17 20:21:32 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 17 Nov 2010 13:21:32 -0600
Subject: [R-sig-ME] declaring the variables
In-Reply-To: <AANLkTimUv8DWeFGjcAoffyNa7+sLG7Mfyz8ynQ+Ups88@mail.gmail.com>
References: <000001cb8614$009d2e40$01d78ac0$@miami.edu>
	<AANLkTimAYg9QxvogkVDVZJHzrQmwxZM9gTdK7T5PtE=b@mail.gmail.com>
	<001101cb8688$5eb49bc0$1c1dd340$@miami.edu>
	<AANLkTimUv8DWeFGjcAoffyNa7+sLG7Mfyz8ynQ+Ups88@mail.gmail.com>
Message-ID: <AANLkTinb=4QNuANDa43aBubNQDQNrvcbpiWd3C3a_d7p@mail.gmail.com>

There is a function glmm in the repeated package but I think the
function meant here is glmer in the lme4 package, not glmm.

On Wed, Nov 17, 2010 at 1:11 PM, Andrew Dolman <andydolman at gmail.com> wrote:
> lmer or glmm, the distinction (from a user point of view) is like lm
> vs glm. If you are using a Gaussian model then either will work. If
> you want to use a non-gaussian model then you will need to use glmm.
>
>
>
> andydolman at gmail.com
>
>
>
> On 17 November 2010 19:50, Michael Larkin <mlarkin at rsmas.miami.edu> wrote:
>> Awesome!? All three of you have been extremely helpful.? Thanks!
>>
>>
>>
>> I have a couple of follow-up questions.
>>
>>
>>
>> When I log transformed my catch data to make it normally (gaussian)
>> distributed.? Therefore, I do have normally distributed random error terms.
>> I will log transform the catch before I apply the model.
>>
>>
>>
>> I will do the declaring steps suggested by Petar where I declare the
>> variables (Angler = factor, Season=factor, and tide phase = numeric).
>>
>>
>>
>> So by using (1 | Angler) in the model for my angler variable (i.e. Joe
>> Smith, John Doe, ect) it makes this variable have a random intercept?
>>
>>
>>
>> My last question, from reading your emails I should pursue the glmm instead
>> of the lmer function because of the random nature of my angler variable?
>>
>>
>>
>> Mike
>>
>>
>>
>>
>>
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From andydolman at gmail.com  Wed Nov 17 20:23:05 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Wed, 17 Nov 2010 20:23:05 +0100
Subject: [R-sig-ME] declaring the variables
In-Reply-To: <AANLkTinb=4QNuANDa43aBubNQDQNrvcbpiWd3C3a_d7p@mail.gmail.com>
References: <000001cb8614$009d2e40$01d78ac0$@miami.edu>
	<AANLkTimAYg9QxvogkVDVZJHzrQmwxZM9gTdK7T5PtE=b@mail.gmail.com>
	<001101cb8688$5eb49bc0$1c1dd340$@miami.edu>
	<AANLkTimUv8DWeFGjcAoffyNa7+sLG7Mfyz8ynQ+Ups88@mail.gmail.com>
	<AANLkTinb=4QNuANDa43aBubNQDQNrvcbpiWd3C3a_d7p@mail.gmail.com>
Message-ID: <AANLkTimUe9yFhrcFWbNSFP0dmahJcvMMajrnLxsK=p-G@mail.gmail.com>

Woops, sorry, yes glmer.


andydolman at gmail.com



On 17 November 2010 20:21, Douglas Bates <bates at stat.wisc.edu> wrote:
> There is a function glmm in the repeated package but I think the
> function meant here is glmer in the lme4 package, not glmm.
>
> On Wed, Nov 17, 2010 at 1:11 PM, Andrew Dolman <andydolman at gmail.com> wrote:
>> lmer or glmm, the distinction (from a user point of view) is like lm
>> vs glm. If you are using a Gaussian model then either will work. If
>> you want to use a non-gaussian model then you will need to use glmm.
>>
>>
>>
>> andydolman at gmail.com
>>
>>
>>
>> On 17 November 2010 19:50, Michael Larkin <mlarkin at rsmas.miami.edu> wrote:
>>> Awesome!? All three of you have been extremely helpful.? Thanks!
>>>
>>>
>>>
>>> I have a couple of follow-up questions.
>>>
>>>
>>>
>>> When I log transformed my catch data to make it normally (gaussian)
>>> distributed.? Therefore, I do have normally distributed random error terms.
>>> I will log transform the catch before I apply the model.
>>>
>>>
>>>
>>> I will do the declaring steps suggested by Petar where I declare the
>>> variables (Angler = factor, Season=factor, and tide phase = numeric).
>>>
>>>
>>>
>>> So by using (1 | Angler) in the model for my angler variable (i.e. Joe
>>> Smith, John Doe, ect) it makes this variable have a random intercept?
>>>
>>>
>>>
>>> My last question, from reading your emails I should pursue the glmm instead
>>> of the lmer function because of the random nature of my angler variable?
>>>
>>>
>>>
>>> Mike
>>>
>>>
>>>
>>>
>>>
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>



From ychang at rvc.ac.uk  Thu Nov 18 15:21:33 2010
From: ychang at rvc.ac.uk (Chang, Yu-Mei)
Date: Thu, 18 Nov 2010 14:21:33 -0000
Subject: [R-sig-ME] glmer with/without intercept gave different results
Message-ID: <C79C4DD076C6834EB10EB0CA1F5063551DD82E7C@hhw2kex01.rvc.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101118/007ddd61/attachment.pl>

From Thierry.ONKELINX at inbo.be  Thu Nov 18 16:42:46 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 18 Nov 2010 16:42:46 +0100
Subject: [R-sig-ME] glmer with/without intercept gave different results
In-Reply-To: <C79C4DD076C6834EB10EB0CA1F5063551DD82E7C@hhw2kex01.rvc.ac.uk>
References: <C79C4DD076C6834EB10EB0CA1F5063551DD82E7C@hhw2kex01.rvc.ac.uk>
Message-ID: <3DB16098F738284D8DBEB2FC369916384D5E55@inboexch.inbo.be>

Dear Ruby,

The hypotheses of those models are different. Hence the diference in
p-values.

Fit1:
H0: Capsule 1 = 0
H0: Capsule 2 - Capsule 1 = 0
H0: Control - Capsule 1 = 0

Fit2:
H0: Capsule 1 = 0
H0: Capsule 2 = 0
H0: Control = 0

However, the predictions of both model should be the same.

Best regards,

Thierry


------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Chang, Yu-Mei
> Verzonden: donderdag 18 november 2010 15:22
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] glmer with/without intercept gave 
> different results
> 
> Dear all,
> 
>  
> 
> I have fitted two glmer models (with or without intercept 
> term). I thought the results should be similar if not 
> identical, but they are quite different. I suspect it's 
> related to the random effects. Any suggestions on how to 
> proceed is greatly appreciated.
> 
>  
> 
> Kind regards,
> 
> Ruby Chang
> 
>  
> 
> fit1 <- glmer(Cyptoplasmic.vacuolation ~ Group +  (1|Villus) 
> + (1|Cell),family=binomial(link = "logit"))
> 
> fit2 <- glmer(Cyptoplasmic.vacuolation ~ Group -1 +  
> (1|Villus) + (1|Cell),family=binomial(link = "logit"))
> 
>  
> 
> > table(Cyptoplasmic.vacuolation, Group)
> 
>                         Group
> 
> Cyptoplasmic.vacuolation Capsule 1 Capsule 2 Control
> 
>                        0       560       340    1230
> 
>                        1       190       160      20
> 
>  
> 
> > fit1 <- glmer(Cyptoplasmic.vacuolation ~ Group +  (1|Villus) +
> (1|Cell),family=binomial(link = "logit"))
> 
> > summary(fit1)
> 
> Generalized linear mixed model fit by the Laplace approximation 
> 
> Formula: Cyptoplasmic.vacuolation ~ Group + (1 | Villus) + (1 | Cell) 
> 
>    AIC   BIC logLik deviance
> 
>  138.9 168.1 -64.47    128.9
> 
> Random effects:
> 
>  Groups Name        Variance  Std.Dev.
> 
>  Cell   (Intercept) 1983.5708 44.5373 
> 
>  Villus (Intercept)    5.9475  2.4387 
> 
> Number of obs: 2500, groups: Cell, 250; Villus, 50
> 
>  
> 
> Fixed effects:
> 
>                Estimate Std. Error z value Pr(>|z|)
> 
> (Intercept)     -11.945      9.123  -1.309    0.190
> 
> GroupCapsule 2   -1.409     14.343  -0.098    0.922
> 
> GroupControl    -17.792     33.251  -0.535    0.593
> 
>  
> 
> Correlation of Fixed Effects:
> 
>             (Intr) GrpCp2
> 
> GroupCapsl2 -0.636       
> 
> GroupContrl -0.274  0.175
> 
> > fit2 <- glmer(Cyptoplasmic.vacuolation ~ Group -1 +  (1|Villus) +
> (1|Cell),family=binomial(link = "logit"))
> 
> > summary(fit2)
> 
> Generalized linear mixed model fit by the Laplace approximation 
> 
> Formula: Cyptoplasmic.vacuolation ~ Group - 1 + (1 | Villus) + (1 |
> Cell) 
> 
>    AIC   BIC logLik deviance
> 
>  132.9 162.0 -61.43    122.9
> 
> Random effects:
> 
>  Groups Name        Variance   Std.Dev.  
> 
>  Cell   (Intercept) 5.9933e+03 7.7417e+01
> 
>  Villus (Intercept) 1.2025e-07 3.4677e-04
> 
> Number of obs: 2500, groups: Cell, 250; Villus, 50
> 
>  
> 
> Fixed effects:
> 
>                Estimate Std. Error z value Pr(>|z|)
> 
> GroupCapsule 1   -15.08      17.70  -0.852    0.394
> 
> GroupCapsule 2   -14.72      19.29  -0.763    0.445
> 
> GroupControl     -18.23      54.54  -0.334    0.738
> 
>  
> 
> Correlation of Fixed Effects:
> 
>             GrpCp1 GrpCp2
> 
> GroupCapsl2 0.000        
> 
> GroupContrl 0.000  0.000
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 



From ychang at rvc.ac.uk  Thu Nov 18 16:51:50 2010
From: ychang at rvc.ac.uk (Chang, Yu-Mei)
Date: Thu, 18 Nov 2010 15:51:50 -0000
Subject: [R-sig-ME] glmer with/without intercept gave different results
In-Reply-To: <3DB16098F738284D8DBEB2FC369916384D5E55@inboexch.inbo.be>
References: <C79C4DD076C6834EB10EB0CA1F5063551DD82E7C@hhw2kex01.rvc.ac.uk>
	<3DB16098F738284D8DBEB2FC369916384D5E55@inboexch.inbo.be>
Message-ID: <C79C4DD076C6834EB10EB0CA1F5063551DD83106@hhw2kex01.rvc.ac.uk>

Dear Thierry,

I understood the hypotheses were different between the two models. What
surprise me were the different estimated variances for the random
effects and also the estimated differences between fixed effects levels.


Ruby

-----Original Message-----
From: ONKELINX, Thierry [mailto:Thierry.ONKELINX at inbo.be] 
Sent: 18 November 2010 15:43
To: Chang, Yu-Mei; r-sig-mixed-models at r-project.org
Subject: RE: [R-sig-ME] glmer with/without intercept gave different
results

Dear Ruby,

The hypotheses of those models are different. Hence the diference in
p-values.

Fit1:
H0: Capsule 1 = 0
H0: Capsule 2 - Capsule 1 = 0
H0: Control - Capsule 1 = 0

Fit2:
H0: Capsule 1 = 0
H0: Capsule 2 = 0
H0: Control = 0

However, the predictions of both model should be the same.

Best regards,

Thierry


------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Chang, Yu-Mei
> Verzonden: donderdag 18 november 2010 15:22
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] glmer with/without intercept gave 
> different results
> 
> Dear all,
> 
>  
> 
> I have fitted two glmer models (with or without intercept 
> term). I thought the results should be similar if not 
> identical, but they are quite different. I suspect it's 
> related to the random effects. Any suggestions on how to 
> proceed is greatly appreciated.
> 
>  
> 
> Kind regards,
> 
> Ruby Chang
> 
>  
> 
> fit1 <- glmer(Cyptoplasmic.vacuolation ~ Group +  (1|Villus) 
> + (1|Cell),family=binomial(link = "logit"))
> 
> fit2 <- glmer(Cyptoplasmic.vacuolation ~ Group -1 +  
> (1|Villus) + (1|Cell),family=binomial(link = "logit"))
> 
>  
> 
> > table(Cyptoplasmic.vacuolation, Group)
> 
>                         Group
> 
> Cyptoplasmic.vacuolation Capsule 1 Capsule 2 Control
> 
>                        0       560       340    1230
> 
>                        1       190       160      20
> 
>  
> 
> > fit1 <- glmer(Cyptoplasmic.vacuolation ~ Group +  (1|Villus) +
> (1|Cell),family=binomial(link = "logit"))
> 
> > summary(fit1)
> 
> Generalized linear mixed model fit by the Laplace approximation 
> 
> Formula: Cyptoplasmic.vacuolation ~ Group + (1 | Villus) + (1 | Cell) 
> 
>    AIC   BIC logLik deviance
> 
>  138.9 168.1 -64.47    128.9
> 
> Random effects:
> 
>  Groups Name        Variance  Std.Dev.
> 
>  Cell   (Intercept) 1983.5708 44.5373 
> 
>  Villus (Intercept)    5.9475  2.4387 
> 
> Number of obs: 2500, groups: Cell, 250; Villus, 50
> 
>  
> 
> Fixed effects:
> 
>                Estimate Std. Error z value Pr(>|z|)
> 
> (Intercept)     -11.945      9.123  -1.309    0.190
> 
> GroupCapsule 2   -1.409     14.343  -0.098    0.922
> 
> GroupControl    -17.792     33.251  -0.535    0.593
> 
>  
> 
> Correlation of Fixed Effects:
> 
>             (Intr) GrpCp2
> 
> GroupCapsl2 -0.636       
> 
> GroupContrl -0.274  0.175
> 
> > fit2 <- glmer(Cyptoplasmic.vacuolation ~ Group -1 +  (1|Villus) +
> (1|Cell),family=binomial(link = "logit"))
> 
> > summary(fit2)
> 
> Generalized linear mixed model fit by the Laplace approximation 
> 
> Formula: Cyptoplasmic.vacuolation ~ Group - 1 + (1 | Villus) + (1 |
> Cell) 
> 
>    AIC   BIC logLik deviance
> 
>  132.9 162.0 -61.43    122.9
> 
> Random effects:
> 
>  Groups Name        Variance   Std.Dev.  
> 
>  Cell   (Intercept) 5.9933e+03 7.7417e+01
> 
>  Villus (Intercept) 1.2025e-07 3.4677e-04
> 
> Number of obs: 2500, groups: Cell, 250; Villus, 50
> 
>  
> 
> Fixed effects:
> 
>                Estimate Std. Error z value Pr(>|z|)
> 
> GroupCapsule 1   -15.08      17.70  -0.852    0.394
> 
> GroupCapsule 2   -14.72      19.29  -0.763    0.445
> 
> GroupControl     -18.23      54.54  -0.334    0.738
> 
>  
> 
> Correlation of Fixed Effects:
> 
>             GrpCp1 GrpCp2
> 
> GroupCapsl2 0.000        
> 
> GroupContrl 0.000  0.000
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 



From j.hadfield at ed.ac.uk  Thu Nov 18 17:09:29 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 18 Nov 2010 16:09:29 +0000
Subject: [R-sig-ME] glmer with/without intercept gave different results
In-Reply-To: <C79C4DD076C6834EB10EB0CA1F5063551DD83106@hhw2kex01.rvc.ac.uk>
References: <C79C4DD076C6834EB10EB0CA1F5063551DD82E7C@hhw2kex01.rvc.ac.uk>
	<3DB16098F738284D8DBEB2FC369916384D5E55@inboexch.inbo.be>
	<C79C4DD076C6834EB10EB0CA1F5063551DD83106@hhw2kex01.rvc.ac.uk>
Message-ID: <32953C33-A06F-4F4D-A7F8-845B0172EB75@ed.ac.uk>

Dear Ruby,

I notice that the fixed effect estimates are very small and the Cell  
variance very large which may indicate numerical issues.

What does:

table(table(Cyptoplasmic.vacuolation, Cell)[1,])

look like?

Cheers,

Jarrod




On 18 Nov 2010, at 15:51, Chang, Yu-Mei wrote:

> Dear Thierry,
>
> I understood the hypotheses were different between the two models.  
> What
> surprise me were the different estimated variances for the random
> effects and also the estimated differences between fixed effects  
> levels.
>
>
> Ruby
>
> -----Original Message-----
> From: ONKELINX, Thierry [mailto:Thierry.ONKELINX at inbo.be]
> Sent: 18 November 2010 15:43
> To: Chang, Yu-Mei; r-sig-mixed-models at r-project.org
> Subject: RE: [R-sig-ME] glmer with/without intercept gave different
> results
>
> Dear Ruby,
>
> The hypotheses of those models are different. Hence the diference in
> p-values.
>
> Fit1:
> H0: Capsule 1 = 0
> H0: Capsule 2 - Capsule 1 = 0
> H0: Control - Capsule 1 = 0
>
> Fit2:
> H0: Capsule 1 = 0
> H0: Capsule 2 = 0
> H0: Control = 0
>
> However, the predictions of both model should be the same.
>
> Best regards,
>
> Thierry
>
>
> ------------------------------------------------------------------------
> ----
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek
> team Biometrie & Kwaliteitszorg
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
>
> Research Institute for Nature and Forest
> team Biometrics & Quality Assurance
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
>
> tel. + 32 54/436 185
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no  
> more
> than asking him to perform a post-mortem examination: he may be able  
> to
> say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does  
> not
> ensure that a reasonable answer can be extracted from a given body of
> data.
> ~ John Tukey
>
>
>> -----Oorspronkelijk bericht-----
>> Van: r-sig-mixed-models-bounces at r-project.org
>> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Chang, Yu- 
>> Mei
>> Verzonden: donderdag 18 november 2010 15:22
>> Aan: r-sig-mixed-models at r-project.org
>> Onderwerp: [R-sig-ME] glmer with/without intercept gave
>> different results
>>
>> Dear all,
>>
>>
>>
>> I have fitted two glmer models (with or without intercept
>> term). I thought the results should be similar if not
>> identical, but they are quite different. I suspect it's
>> related to the random effects. Any suggestions on how to
>> proceed is greatly appreciated.
>>
>>
>>
>> Kind regards,
>>
>> Ruby Chang
>>
>>
>>
>> fit1 <- glmer(Cyptoplasmic.vacuolation ~ Group +  (1|Villus)
>> + (1|Cell),family=binomial(link = "logit"))
>>
>> fit2 <- glmer(Cyptoplasmic.vacuolation ~ Group -1 +
>> (1|Villus) + (1|Cell),family=binomial(link = "logit"))
>>
>>
>>
>>> table(Cyptoplasmic.vacuolation, Group)
>>
>>                        Group
>>
>> Cyptoplasmic.vacuolation Capsule 1 Capsule 2 Control
>>
>>                       0       560       340    1230
>>
>>                       1       190       160      20
>>
>>
>>
>>> fit1 <- glmer(Cyptoplasmic.vacuolation ~ Group +  (1|Villus) +
>> (1|Cell),family=binomial(link = "logit"))
>>
>>> summary(fit1)
>>
>> Generalized linear mixed model fit by the Laplace approximation
>>
>> Formula: Cyptoplasmic.vacuolation ~ Group + (1 | Villus) + (1 | Cell)
>>
>>   AIC   BIC logLik deviance
>>
>> 138.9 168.1 -64.47    128.9
>>
>> Random effects:
>>
>> Groups Name        Variance  Std.Dev.
>>
>> Cell   (Intercept) 1983.5708 44.5373
>>
>> Villus (Intercept)    5.9475  2.4387
>>
>> Number of obs: 2500, groups: Cell, 250; Villus, 50
>>
>>
>>
>> Fixed effects:
>>
>>               Estimate Std. Error z value Pr(>|z|)
>>
>> (Intercept)     -11.945      9.123  -1.309    0.190
>>
>> GroupCapsule 2   -1.409     14.343  -0.098    0.922
>>
>> GroupControl    -17.792     33.251  -0.535    0.593
>>
>>
>>
>> Correlation of Fixed Effects:
>>
>>            (Intr) GrpCp2
>>
>> GroupCapsl2 -0.636
>>
>> GroupContrl -0.274  0.175
>>
>>> fit2 <- glmer(Cyptoplasmic.vacuolation ~ Group -1 +  (1|Villus) +
>> (1|Cell),family=binomial(link = "logit"))
>>
>>> summary(fit2)
>>
>> Generalized linear mixed model fit by the Laplace approximation
>>
>> Formula: Cyptoplasmic.vacuolation ~ Group - 1 + (1 | Villus) + (1 |
>> Cell)
>>
>>   AIC   BIC logLik deviance
>>
>> 132.9 162.0 -61.43    122.9
>>
>> Random effects:
>>
>> Groups Name        Variance   Std.Dev.
>>
>> Cell   (Intercept) 5.9933e+03 7.7417e+01
>>
>> Villus (Intercept) 1.2025e-07 3.4677e-04
>>
>> Number of obs: 2500, groups: Cell, 250; Villus, 50
>>
>>
>>
>> Fixed effects:
>>
>>               Estimate Std. Error z value Pr(>|z|)
>>
>> GroupCapsule 1   -15.08      17.70  -0.852    0.394
>>
>> GroupCapsule 2   -14.72      19.29  -0.763    0.445
>>
>> GroupControl     -18.23      54.54  -0.334    0.738
>>
>>
>>
>> Correlation of Fixed Effects:
>>
>>            GrpCp1 GrpCp2
>>
>> GroupCapsl2 0.000
>>
>> GroupContrl 0.000  0.000
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From ychang at rvc.ac.uk  Thu Nov 18 17:18:31 2010
From: ychang at rvc.ac.uk (Chang, Yu-Mei)
Date: Thu, 18 Nov 2010 16:18:31 -0000
Subject: [R-sig-ME] glmer with/without intercept gave different results
In-Reply-To: <32953C33-A06F-4F4D-A7F8-845B0172EB75@ed.ac.uk>
References: <C79C4DD076C6834EB10EB0CA1F5063551DD82E7C@hhw2kex01.rvc.ac.uk>
	<3DB16098F738284D8DBEB2FC369916384D5E55@inboexch.inbo.be>
	<C79C4DD076C6834EB10EB0CA1F5063551DD83106@hhw2kex01.rvc.ac.uk>
	<32953C33-A06F-4F4D-A7F8-845B0172EB75@ed.ac.uk>
Message-ID: <C79C4DD076C6834EB10EB0CA1F5063551DD831E0@hhw2kex01.rvc.ac.uk>

Dear Jarrod,

Yes, that's the culprit. The 10 repeated cells are either all 0's or
1's!

> table(table(Cyptoplasmic.vacuolation, Cell)[1,])

  0  10 
 37 213

Many thanks! 
Ruby


-----Original Message-----
From: Jarrod Hadfield [mailto:j.hadfield at ed.ac.uk] 
Sent: 18 November 2010 16:09
To: Chang, Yu-Mei
Cc: ONKELINX, Thierry; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] glmer with/without intercept gave different
results

Dear Ruby,

I notice that the fixed effect estimates are very small and the Cell  
variance very large which may indicate numerical issues.

What does:

table(table(Cyptoplasmic.vacuolation, Cell)[1,])

look like?

Cheers,

Jarrod




On 18 Nov 2010, at 15:51, Chang, Yu-Mei wrote:

> Dear Thierry,
>
> I understood the hypotheses were different between the two models.  
> What
> surprise me were the different estimated variances for the random
> effects and also the estimated differences between fixed effects  
> levels.
>
>
> Ruby
>
> -----Original Message-----
> From: ONKELINX, Thierry [mailto:Thierry.ONKELINX at inbo.be]
> Sent: 18 November 2010 15:43
> To: Chang, Yu-Mei; r-sig-mixed-models at r-project.org
> Subject: RE: [R-sig-ME] glmer with/without intercept gave different
> results
>
> Dear Ruby,
>
> The hypotheses of those models are different. Hence the diference in
> p-values.
>
> Fit1:
> H0: Capsule 1 = 0
> H0: Capsule 2 - Capsule 1 = 0
> H0: Control - Capsule 1 = 0
>
> Fit2:
> H0: Capsule 1 = 0
> H0: Capsule 2 = 0
> H0: Control = 0
>
> However, the predictions of both model should be the same.
>
> Best regards,
>
> Thierry
>
>
>
------------------------------------------------------------------------
> ----
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek
> team Biometrie & Kwaliteitszorg
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
>
> Research Institute for Nature and Forest
> team Biometrics & Quality Assurance
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
>
> tel. + 32 54/436 185
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no  
> more
> than asking him to perform a post-mortem examination: he may be able  
> to
> say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does  
> not
> ensure that a reasonable answer can be extracted from a given body of
> data.
> ~ John Tukey
>
>
>> -----Oorspronkelijk bericht-----
>> Van: r-sig-mixed-models-bounces at r-project.org
>> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Chang, Yu- 
>> Mei
>> Verzonden: donderdag 18 november 2010 15:22
>> Aan: r-sig-mixed-models at r-project.org
>> Onderwerp: [R-sig-ME] glmer with/without intercept gave
>> different results
>>
>> Dear all,
>>
>>
>>
>> I have fitted two glmer models (with or without intercept
>> term). I thought the results should be similar if not
>> identical, but they are quite different. I suspect it's
>> related to the random effects. Any suggestions on how to
>> proceed is greatly appreciated.
>>
>>
>>
>> Kind regards,
>>
>> Ruby Chang
>>
>>
>>
>> fit1 <- glmer(Cyptoplasmic.vacuolation ~ Group +  (1|Villus)
>> + (1|Cell),family=binomial(link = "logit"))
>>
>> fit2 <- glmer(Cyptoplasmic.vacuolation ~ Group -1 +
>> (1|Villus) + (1|Cell),family=binomial(link = "logit"))
>>
>>
>>
>>> table(Cyptoplasmic.vacuolation, Group)
>>
>>                        Group
>>
>> Cyptoplasmic.vacuolation Capsule 1 Capsule 2 Control
>>
>>                       0       560       340    1230
>>
>>                       1       190       160      20
>>
>>
>>
>>> fit1 <- glmer(Cyptoplasmic.vacuolation ~ Group +  (1|Villus) +
>> (1|Cell),family=binomial(link = "logit"))
>>
>>> summary(fit1)
>>
>> Generalized linear mixed model fit by the Laplace approximation
>>
>> Formula: Cyptoplasmic.vacuolation ~ Group + (1 | Villus) + (1 | Cell)
>>
>>   AIC   BIC logLik deviance
>>
>> 138.9 168.1 -64.47    128.9
>>
>> Random effects:
>>
>> Groups Name        Variance  Std.Dev.
>>
>> Cell   (Intercept) 1983.5708 44.5373
>>
>> Villus (Intercept)    5.9475  2.4387
>>
>> Number of obs: 2500, groups: Cell, 250; Villus, 50
>>
>>
>>
>> Fixed effects:
>>
>>               Estimate Std. Error z value Pr(>|z|)
>>
>> (Intercept)     -11.945      9.123  -1.309    0.190
>>
>> GroupCapsule 2   -1.409     14.343  -0.098    0.922
>>
>> GroupControl    -17.792     33.251  -0.535    0.593
>>
>>
>>
>> Correlation of Fixed Effects:
>>
>>            (Intr) GrpCp2
>>
>> GroupCapsl2 -0.636
>>
>> GroupContrl -0.274  0.175
>>
>>> fit2 <- glmer(Cyptoplasmic.vacuolation ~ Group -1 +  (1|Villus) +
>> (1|Cell),family=binomial(link = "logit"))
>>
>>> summary(fit2)
>>
>> Generalized linear mixed model fit by the Laplace approximation
>>
>> Formula: Cyptoplasmic.vacuolation ~ Group - 1 + (1 | Villus) + (1 |
>> Cell)
>>
>>   AIC   BIC logLik deviance
>>
>> 132.9 162.0 -61.43    122.9
>>
>> Random effects:
>>
>> Groups Name        Variance   Std.Dev.
>>
>> Cell   (Intercept) 5.9933e+03 7.7417e+01
>>
>> Villus (Intercept) 1.2025e-07 3.4677e-04
>>
>> Number of obs: 2500, groups: Cell, 250; Villus, 50
>>
>>
>>
>> Fixed effects:
>>
>>               Estimate Std. Error z value Pr(>|z|)
>>
>> GroupCapsule 1   -15.08      17.70  -0.852    0.394
>>
>> GroupCapsule 2   -14.72      19.29  -0.763    0.445
>>
>> GroupControl     -18.23      54.54  -0.334    0.738
>>
>>
>>
>> Correlation of Fixed Effects:
>>
>>            GrpCp1 GrpCp2
>>
>> GroupCapsl2 0.000
>>
>> GroupContrl 0.000  0.000
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From j.hadfield at ed.ac.uk  Thu Nov 18 17:33:48 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 18 Nov 2010 16:33:48 +0000
Subject: [R-sig-ME] glmer with/without intercept gave different results
In-Reply-To: <C79C4DD076C6834EB10EB0CA1F5063551DD831E0@hhw2kex01.rvc.ac.uk>
References: <C79C4DD076C6834EB10EB0CA1F5063551DD82E7C@hhw2kex01.rvc.ac.uk>
	<3DB16098F738284D8DBEB2FC369916384D5E55@inboexch.inbo.be>
	<C79C4DD076C6834EB10EB0CA1F5063551DD83106@hhw2kex01.rvc.ac.uk>
	<32953C33-A06F-4F4D-A7F8-845B0172EB75@ed.ac.uk>
	<C79C4DD076C6834EB10EB0CA1F5063551DD831E0@hhw2kex01.rvc.ac.uk>
Message-ID: <C8D03F24-A097-4CFA-92FB-C65E557E0505@ed.ac.uk>

Dear Ruby,

I do not think a REML solution exists for the Cell variance in this  
instance (it's infinity). I presume the data for each Cell all have  
the same Villus and Group?  If so you would be better off reducing  
your data to 250 binary data (i.e. One datum for each Cell) and  
removing the (1|Cell) term from the model.

Cheers,

Jarrod

On 18 Nov 2010, at 16:18, Chang, Yu-Mei wrote:

> Dear Jarrod,
>
> Yes, that's the culprit. The 10 repeated cells are either all 0's or
> 1's!
>
>> table(table(Cyptoplasmic.vacuolation, Cell)[1,])
>
>  0  10
> 37 213
>
> Many thanks!
> Ruby
>
>
> -----Original Message-----
> From: Jarrod Hadfield [mailto:j.hadfield at ed.ac.uk]
> Sent: 18 November 2010 16:09
> To: Chang, Yu-Mei
> Cc: ONKELINX, Thierry; r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] glmer with/without intercept gave different
> results
>
> Dear Ruby,
>
> I notice that the fixed effect estimates are very small and the Cell
> variance very large which may indicate numerical issues.
>
> What does:
>
> table(table(Cyptoplasmic.vacuolation, Cell)[1,])
>
> look like?
>
> Cheers,
>
> Jarrod
>
>
>
>
> On 18 Nov 2010, at 15:51, Chang, Yu-Mei wrote:
>
>> Dear Thierry,
>>
>> I understood the hypotheses were different between the two models.
>> What
>> surprise me were the different estimated variances for the random
>> effects and also the estimated differences between fixed effects
>> levels.
>>
>>
>> Ruby
>>
>> -----Original Message-----
>> From: ONKELINX, Thierry [mailto:Thierry.ONKELINX at inbo.be]
>> Sent: 18 November 2010 15:43
>> To: Chang, Yu-Mei; r-sig-mixed-models at r-project.org
>> Subject: RE: [R-sig-ME] glmer with/without intercept gave different
>> results
>>
>> Dear Ruby,
>>
>> The hypotheses of those models are different. Hence the diference in
>> p-values.
>>
>> Fit1:
>> H0: Capsule 1 = 0
>> H0: Capsule 2 - Capsule 1 = 0
>> H0: Control - Capsule 1 = 0
>>
>> Fit2:
>> H0: Capsule 1 = 0
>> H0: Capsule 2 = 0
>> H0: Control = 0
>>
>> However, the predictions of both model should be the same.
>>
>> Best regards,
>>
>> Thierry
>>
>>
>>
> ------------------------------------------------------------------------
>> ----
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek
>> team Biometrie & Kwaliteitszorg
>> Gaverstraat 4
>> 9500 Geraardsbergen
>> Belgium
>>
>> Research Institute for Nature and Forest
>> team Biometrics & Quality Assurance
>> Gaverstraat 4
>> 9500 Geraardsbergen
>> Belgium
>>
>> tel. + 32 54/436 185
>> Thierry.Onkelinx at inbo.be
>> www.inbo.be
>>
>> To call in the statistician after the experiment is done may be no
>> more
>> than asking him to perform a post-mortem examination: he may be able
>> to
>> say what the experiment died of.
>> ~ Sir Ronald Aylmer Fisher
>>
>> The plural of anecdote is not data.
>> ~ Roger Brinner
>>
>> The combination of some data and an aching desire for an answer does
>> not
>> ensure that a reasonable answer can be extracted from a given body of
>> data.
>> ~ John Tukey
>>
>>
>>> -----Oorspronkelijk bericht-----
>>> Van: r-sig-mixed-models-bounces at r-project.org
>>> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Chang, Yu-
>>> Mei
>>> Verzonden: donderdag 18 november 2010 15:22
>>> Aan: r-sig-mixed-models at r-project.org
>>> Onderwerp: [R-sig-ME] glmer with/without intercept gave
>>> different results
>>>
>>> Dear all,
>>>
>>>
>>>
>>> I have fitted two glmer models (with or without intercept
>>> term). I thought the results should be similar if not
>>> identical, but they are quite different. I suspect it's
>>> related to the random effects. Any suggestions on how to
>>> proceed is greatly appreciated.
>>>
>>>
>>>
>>> Kind regards,
>>>
>>> Ruby Chang
>>>
>>>
>>>
>>> fit1 <- glmer(Cyptoplasmic.vacuolation ~ Group +  (1|Villus)
>>> + (1|Cell),family=binomial(link = "logit"))
>>>
>>> fit2 <- glmer(Cyptoplasmic.vacuolation ~ Group -1 +
>>> (1|Villus) + (1|Cell),family=binomial(link = "logit"))
>>>
>>>
>>>
>>>> table(Cyptoplasmic.vacuolation, Group)
>>>
>>>                       Group
>>>
>>> Cyptoplasmic.vacuolation Capsule 1 Capsule 2 Control
>>>
>>>                      0       560       340    1230
>>>
>>>                      1       190       160      20
>>>
>>>
>>>
>>>> fit1 <- glmer(Cyptoplasmic.vacuolation ~ Group +  (1|Villus) +
>>> (1|Cell),family=binomial(link = "logit"))
>>>
>>>> summary(fit1)
>>>
>>> Generalized linear mixed model fit by the Laplace approximation
>>>
>>> Formula: Cyptoplasmic.vacuolation ~ Group + (1 | Villus) + (1 |  
>>> Cell)
>>>
>>>  AIC   BIC logLik deviance
>>>
>>> 138.9 168.1 -64.47    128.9
>>>
>>> Random effects:
>>>
>>> Groups Name        Variance  Std.Dev.
>>>
>>> Cell   (Intercept) 1983.5708 44.5373
>>>
>>> Villus (Intercept)    5.9475  2.4387
>>>
>>> Number of obs: 2500, groups: Cell, 250; Villus, 50
>>>
>>>
>>>
>>> Fixed effects:
>>>
>>>              Estimate Std. Error z value Pr(>|z|)
>>>
>>> (Intercept)     -11.945      9.123  -1.309    0.190
>>>
>>> GroupCapsule 2   -1.409     14.343  -0.098    0.922
>>>
>>> GroupControl    -17.792     33.251  -0.535    0.593
>>>
>>>
>>>
>>> Correlation of Fixed Effects:
>>>
>>>           (Intr) GrpCp2
>>>
>>> GroupCapsl2 -0.636
>>>
>>> GroupContrl -0.274  0.175
>>>
>>>> fit2 <- glmer(Cyptoplasmic.vacuolation ~ Group -1 +  (1|Villus) +
>>> (1|Cell),family=binomial(link = "logit"))
>>>
>>>> summary(fit2)
>>>
>>> Generalized linear mixed model fit by the Laplace approximation
>>>
>>> Formula: Cyptoplasmic.vacuolation ~ Group - 1 + (1 | Villus) + (1 |
>>> Cell)
>>>
>>>  AIC   BIC logLik deviance
>>>
>>> 132.9 162.0 -61.43    122.9
>>>
>>> Random effects:
>>>
>>> Groups Name        Variance   Std.Dev.
>>>
>>> Cell   (Intercept) 5.9933e+03 7.7417e+01
>>>
>>> Villus (Intercept) 1.2025e-07 3.4677e-04
>>>
>>> Number of obs: 2500, groups: Cell, 250; Villus, 50
>>>
>>>
>>>
>>> Fixed effects:
>>>
>>>              Estimate Std. Error z value Pr(>|z|)
>>>
>>> GroupCapsule 1   -15.08      17.70  -0.852    0.394
>>>
>>> GroupCapsule 2   -14.72      19.29  -0.763    0.445
>>>
>>> GroupControl     -18.23      54.54  -0.334    0.738
>>>
>>>
>>>
>>> Correlation of Fixed Effects:
>>>
>>>           GrpCp1 GrpCp2
>>>
>>> GroupCapsl2 0.000
>>>
>>> GroupContrl 0.000  0.000
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From sgarnier at Princeton.EDU  Thu Nov 18 19:14:44 2010
From: sgarnier at Princeton.EDU (Simon Garnier)
Date: Thu, 18 Nov 2010 13:14:44 -0500
Subject: [R-sig-ME] [R] Help with lmer, nested data and repeated measures
Message-ID: <84C7E4F8-7BAE-4E41-9F9F-5078FBC08D77@Princeton.EDU>

Dear all,

I'm discovering the somehow confusing (for me) world of linear mixed models after having been advised it could be the best option to analyze my dataset. After several days of reading, I'm not sure that what I ended up with makes some sense and I'd greatly appreciate any help and explanations.

The dataset has been obtained as follows. In 15 different locations, I counted during 10 seconds the number of ants crossing a gap, before and after destroying a bridge that ants had previously built over the gap. I then waited for the ants to rebuild the bridge and repeated two more times the counting and destroying process. Therefore, for each gap observed, I have 3 replicates of the same experiment, each of them providing 1 count value for each treatment tested (before and after bridge destruction), i.e. 6 values in total per gap. I also measured for each gap its length. 

I now want to model the effect of the gap length (GapLength, continuous variable), the treatment (Treatment, categorical variable) and the replicate position (Replicate, categorical variable) on the number of ants crossing the gap (AntCount, count variable). As far as I understand, the gap (Gap) can be treated here as a random effect, the gap length, the treatment and the replicate position as fixed effects. Moreover, the treatment variable is nested in the replicate position variable that is also nested in the gap variable. Finally, since I have count data, a poisson distribution should be used for the model. With all this information in mind and some additional information from various sources, I ended up with the following R code:

lmer(AntCount ~ Treatment + GapLength + (Treatment | Gap / Replicate) + (GapLength | Gap), data=dat, family=poisson(link=log))

The code runs fine and does not return any error. But of course this does not mean the model was correctly designed. Am I right when I'm doing this or am I (most likely) completely wrong? 

Thanks in advance for your help.

Best,
Simon.

-- 
--------------------------------------------------------------------------------
Dr. Simon Garnier
Department of Ecology & Evolutionary Biology
Princeton University
Guyot Hall

e-mail: sgarnier at princeton.edu / simon.garnier at gmail.com
website: http://www.simongarnier.com
photoblog: http://www.simongarnier.org
--------------------------------------------------------------------------------



From billy.requena at gmail.com  Thu Nov 18 20:11:55 2010
From: billy.requena at gmail.com (Billy)
Date: Thu, 18 Nov 2010 13:11:55 -0600
Subject: [R-sig-ME] Logistic regression with factorial effect
In-Reply-To: <1290101520652-3049208.post@n4.nabble.com>
References: <1290101520652-3049208.post@n4.nabble.com>
Message-ID: <AANLkTi=n=0M1XKDY-gNJnm=9b0nX4=0esPiM1BW-3Ohq@mail.gmail.com>

Hello,

I?d like to evaluate the temporal effect on the relationship between a
continuous variable (e.g. size) and the probability of mate success.
Initially I was trying to do a logistic regression model incorporating the
temporal effect, but I don?t know if that is the best option. I simulated
some data and that?s the problem:


rep(c("Jan","Feb","Mar","Apr","May"), each=20) -> month
as.factor(month)

rep(LETTERS[seq(1:20)], 5) -> ind

rep(sort(rnorm(20, 5.5, 0.2)), 5) -> size
size

c(c(rep(0,12), rep(1,8)), c(rep(0,12), rep(1,8)),
? ? ? ?c(rep(c(0,1), 10)),
? ? ? ?c(rep(1,8), rep(0,12)),
? ? ? ?c(rep(1,8), rep(0,12))) -> success1
success1

With the object ?success1?, only the highest values of size are successful
at the two first months, but only the lowest values of size are successful
at the two last months. So, the overall effect of size on the successful
probability should not exist, but if we consider the interaction between
size and time, we should be able to see that effect.


glm(success1 ~ size, family=binomial) -> test1.1
glmer(success1 ~ size + (1|ind), family=binomial) -> test2.1
glmer(success1 ~ size + month + (1|ind), family=binomial) -> test3.1
glmer(success1 ~ size : month + (1|ind), family=binomial) -> test4.1


However, the expected result is not observed in the output of all these
models. Using a model selection approach and comparing the AIC values of all
models, it seems that ?test1.1? model is the most likely. All the deviances
are almost at the same level and the differences in AIC values are due for
the new parameters added.

Given the data was simulated to generate differences between models and
model ?test4.1? is supposed to be the best one, I?m probably doing something
wrong.
Has anyone faced this kind of problem? Or has anyone any idea how to solve
that?

Thanks and Regards
Gustavo Requena
PhD student - Laboratory of Arthropod Behavior and Evolution
Universidade de S?o Paulo
http://ecologia.ib.usp.br/opilio/gustavo.html



From Camille.Szmaragd at bristol.ac.uk  Wed Nov 17 12:21:28 2010
From: Camille.Szmaragd at bristol.ac.uk (Camille Szmaragd)
Date: Wed, 17 Nov 2010 11:21:28 -0000
Subject: [R-sig-ME] Problem with lmer crashing on x64 server
Message-ID: <00fe01cb8649$93e760a0$bbb621e0$@Szmaragd@bristol.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101117/49d51d65/attachment.pl>

From sibylle.stoeckli at gmx.ch  Thu Nov 18 20:44:18 2010
From: sibylle.stoeckli at gmx.ch (=?ISO-8859-1?Q?Sibylle_St=F6ckli?=)
Date: Thu, 18 Nov 2010 20:44:18 +0100
Subject: [R-sig-ME] LME and TukeyHSD
Message-ID: <C69C143D-01D6-4916-AD3E-BF790552F9E4@gmx.ch>

Dear R users

I used lme to fit a linear mixed model inlcuding weights=varPower()  
and subset. Additionally I wanted to use glht to calculate Tukey- 
Kramer multiple comparisions.

I think that the error in glht() is probably caused by the subset and  
varPower function within the lme model? I would very much appreciate    
an input.

Thanks
Sibylle

LME MODEL
 > modelF<-lme(asin(sqrt(PropMortality))~Diversity+Management+Species 
+Height+Year+Diversity*Year, data=Kaltenborn, random=~1|Plot/SubPlot,  
na.action=na.omit, weights=varPower(form=~Diversity), subset=Kaltenborn 
$ADDspecies!=1, method="REML")

 > anova(modelF, type="marginal")
                numDF denDF  F-value p-value
(Intercept)        1   162  7.12789  0.0084
Diversity          1    14 12.89284  0.0030
Management         2    30  5.52544  0.0091
Species            3   162 41.81003  <.0001
Height             1   162  2.59134  0.1094
Year               1   162  7.07660  0.0086
Diversity:Year     1   162 12.88095  0.0004

TukeyHSD
 > library(multcomp)
Loading required package: mvtnorm
Warning messages:
1: package 'multcomp' was built under R version 2.7.2
2: package 'mvtnorm' was built under R version 2.7.2
 > summary(glht(modelF,linfct=mcp(Species="Tukey")))

error
Error in glht.matrix(model = list(modelStruct = list(reStruct =  
list(SubPlot = -0.305856275920955,  :
   ?ncol(linfct)? is not equal to ?length(coef(model))?
 > 


From Christoph.Scherber at agr.uni-goettingen.de  Thu Nov 18 21:05:48 2010
From: Christoph.Scherber at agr.uni-goettingen.de (Christoph Scherber)
Date: Thu, 18 Nov 2010 21:05:48 +0100
Subject: [R-sig-ME] LME and TukeyHSD
In-Reply-To: <C69C143D-01D6-4916-AD3E-BF790552F9E4@gmx.ch>
References: <C69C143D-01D6-4916-AD3E-BF790552F9E4@gmx.ch>
Message-ID: <0e76326b737a9a8554053a2857c8c92e.squirrel@mailbox.gwdg.de>

Dear Sibylle,

The reason for the error message may be that you transform your response
variable inside the model formula. This frequently causes errors when
working with components of lme models. In addition, you should try "ML"
instead of "REML" (when working with the fixed effects).

You may want to try:

##

mydata<-subset(Kaltenborn,ADDspecies!=1)
mydata$sinmortality<-asin(sqrt(Kaltenborn$PropMortality))
mydata<-mydata[!is.na(mydata$sinmortality),]

modelF<-lme(sinmortality~Diversity+Management+Species
+Height+Year+Diversity*Year, data=mydata, random=~1|Plot/SubPlot,
weights=varPower(form=~Diversity), method="ML")

summary(glht(modelF,linfct=mcp(Species="Tukey")))

##

Be reminded that it may not be sensible to test for Species main effects
when interactions are present; have you tested for interactions between
Species and other terms in the model?

Best wishes,
Christoph





> Dear R users
>
> I used lme to fit a linear mixed model inlcuding weights=varPower()
> and subset. Additionally I wanted to use glht to calculate Tukey-
> Kramer multiple comparisions.
>
> I think that the error in glht() is probably caused by the subset and
> varPower function within the lme model? I would very much appreciate
> an input.
>
> Thanks
> Sibylle
>
> LME MODEL
>  > modelF<-lme(asin(sqrt(PropMortality))~Diversity+Management+Species
> +Height+Year+Diversity*Year, data=Kaltenborn, random=~1|Plot/SubPlot,
> na.action=na.omit, weights=varPower(form=~Diversity), subset=Kaltenborn
> $ADDspecies!=1, method="REML")
>
>  > anova(modelF, type="marginal")
>                 numDF denDF  F-value p-value
> (Intercept)        1   162  7.12789  0.0084
> Diversity          1    14 12.89284  0.0030
> Management         2    30  5.52544  0.0091
> Species            3   162 41.81003  <.0001
> Height             1   162  2.59134  0.1094
> Year               1   162  7.07660  0.0086
> Diversity:Year     1   162 12.88095  0.0004
>
> TukeyHSD
>  > library(multcomp)
> Loading required package: mvtnorm
> Warning messages:
> 1: package 'multcomp' was built under R version 2.7.2
> 2: package 'mvtnorm' was built under R version 2.7.2
>  > summary(glht(modelF,linfct=mcp(Species="Tukey")))
>
> error
> Error in glht.matrix(model = list(modelStruct = list(reStruct =
> list(SubPlot = -0.305856275920955,  :
>    ?ncol(linfct)? is not equal to ?length(coef(model))?
>  >
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From sgarnier at Princeton.EDU  Thu Nov 18 22:22:05 2010
From: sgarnier at Princeton.EDU (Simon Garnier)
Date: Thu, 18 Nov 2010 16:22:05 -0500
Subject: [R-sig-ME] [R] Help with lmer, nested data and repeated measures
In-Reply-To: <B35C864E-D6EB-4C30-A83E-7C8FDCC6E074@gmail.com>
References: <84C7E4F8-7BAE-4E41-9F9F-5078FBC08D77@Princeton.EDU>
	<B35C864E-D6EB-4C30-A83E-7C8FDCC6E074@gmail.com>
Message-ID: <89B93CB8-1F5F-41C7-AE9B-B01F141FDD2B@Princeton.EDU>

Hi Andrew, 

As I said, I'm not really sure of what I'm doing, and it's why I'm submitting this problem to the list. If I understand your concerns, you rather suggest that I go first with a simpler model that would not take into account the nesting? 
Also, I don't know what you mean by "learning"? Do you have some references I could read about it? Thanks.

Best,
Simon. 

On Nov 18, 2010, at 4:12 PM, Andrew Robinson wrote:

> Hi Simon,
> 
> I'm not sure that I agree with your nesting of the fixed effects inside each other, or inside the random effect. I would do that if I had a reason based on poor fit of a simpler model, but not as a consequence of the design that you have described. Also, do you want to allow for the possibility of learning? Your model doesn't presently accommodate that. 
> 
> Cheers
> 
> Andrew
> 
> On 19/11/2010, at 5:14 AM, Simon Garnier <sgarnier at princeton.edu> wrote:
> 
>> Dear all,
>> 
>> I'm discovering the somehow confusing (for me) world of linear mixed models after having been advised it could be the best option to analyze my dataset. After several days of reading, I'm not sure that what I ended up with makes some sense and I'd greatly appreciate any help and explanations.
>> 
>> The dataset has been obtained as follows. In 15 different locations, I counted during 10 seconds the number of ants crossing a gap, before and after destroying a bridge that ants had previously built over the gap. I then waited for the ants to rebuild the bridge and repeated two more times the counting and destroying process. Therefore, for each gap observed, I have 3 replicates of the same experiment, each of them providing 1 count value for each treatment tested (before and after bridge destruction), i.e. 6 values in total per gap. I also measured for each gap its length. 
>> 
>> I now want to model the effect of the gap length (GapLength, continuous variable), the treatment (Treatment, categorical variable) and the replicate position (Replicate, categorical variable) on the number of ants crossing the gap (AntCount, count variable). As far as I understand, the gap (Gap) can be treated here as a random effect, the gap length, the treatment and the replicate position as fixed effects. Moreover, the treatment variable is nested in the replicate position variable that is also nested in the gap variable. Finally, since I have count data, a poisson distribution should be used for the model. With all this information in mind and some additional information from various sources, I ended up with the following R code:
>> 
>> lmer(AntCount ~ Treatment + GapLength + (Treatment | Gap / Replicate) + (GapLength | Gap), data=dat, family=poisson(link=log))
>> 
>> The code runs fine and does not return any error. But of course this does not mean the model was correctly designed. Am I right when I'm doing this or am I (most likely) completely wrong? 
>> 
>> Thanks in advance for your help.
>> 
>> Best,
>> Simon.
>> 
>> -- 
>> --------------------------------------------------------------------------------
>> Dr. Simon Garnier
>> Department of Ecology & Evolutionary Biology
>> Princeton University
>> Guyot Hall
>> 
>> e-mail: sgarnier at princeton.edu / simon.garnier at gmail.com
>> website: http://www.simongarnier.com
>> photoblog: http://www.simongarnier.org
>> --------------------------------------------------------------------------------
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
--------------------------------------------------------------------------------
Dr. Simon Garnier
Department of Ecology & Evolutionary Biology
Princeton University
Guyot Hall

e-mail: sgarnier at princeton.edu / simon.garnier at gmail.com
website: http://www.simongarnier.com
photoblog: http://www.simongarnier.org
--------------------------------------------------------------------------------



From mensurationist at gmail.com  Thu Nov 18 22:12:28 2010
From: mensurationist at gmail.com (Andrew Robinson)
Date: Fri, 19 Nov 2010 08:12:28 +1100
Subject: [R-sig-ME] [R] Help with lmer, nested data and repeated measures
In-Reply-To: <84C7E4F8-7BAE-4E41-9F9F-5078FBC08D77@Princeton.EDU>
References: <84C7E4F8-7BAE-4E41-9F9F-5078FBC08D77@Princeton.EDU>
Message-ID: <B35C864E-D6EB-4C30-A83E-7C8FDCC6E074@gmail.com>

Hi Simon,

I'm not sure that I agree with your nesting of the fixed effects inside each other, or inside the random effect. I would do that if I had a reason based on poor fit of a simpler model, but not as a consequence of the design that you have described. Also, do you want to allow for the possibility of learning? Your model doesn't presently accommodate that. 

Cheers

Andrew

On 19/11/2010, at 5:14 AM, Simon Garnier <sgarnier at princeton.edu> wrote:

> Dear all,
> 
> I'm discovering the somehow confusing (for me) world of linear mixed models after having been advised it could be the best option to analyze my dataset. After several days of reading, I'm not sure that what I ended up with makes some sense and I'd greatly appreciate any help and explanations.
> 
> The dataset has been obtained as follows. In 15 different locations, I counted during 10 seconds the number of ants crossing a gap, before and after destroying a bridge that ants had previously built over the gap. I then waited for the ants to rebuild the bridge and repeated two more times the counting and destroying process. Therefore, for each gap observed, I have 3 replicates of the same experiment, each of them providing 1 count value for each treatment tested (before and after bridge destruction), i.e. 6 values in total per gap. I also measured for each gap its length. 
> 
> I now want to model the effect of the gap length (GapLength, continuous variable), the treatment (Treatment, categorical variable) and the replicate position (Replicate, categorical variable) on the number of ants crossing the gap (AntCount, count variable). As far as I understand, the gap (Gap) can be treated here as a random effect, the gap length, the treatment and the replicate position as fixed effects. Moreover, the treatment variable is nested in the replicate position variable that is also nested in the gap variable. Finally, since I have count data, a poisson distribution should be used for the model. With all this information in mind and some additional information from various sources, I ended up with the following R code:
> 
> lmer(AntCount ~ Treatment + GapLength + (Treatment | Gap / Replicate) + (GapLength | Gap), data=dat, family=poisson(link=log))
> 
> The code runs fine and does not return any error. But of course this does not mean the model was correctly designed. Am I right when I'm doing this or am I (most likely) completely wrong? 
> 
> Thanks in advance for your help.
> 
> Best,
> Simon.
> 
> -- 
> --------------------------------------------------------------------------------
> Dr. Simon Garnier
> Department of Ecology & Evolutionary Biology
> Princeton University
> Guyot Hall
> 
> e-mail: sgarnier at princeton.edu / simon.garnier at gmail.com
> website: http://www.simongarnier.com
> photoblog: http://www.simongarnier.org
> --------------------------------------------------------------------------------
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From davidD at qimr.edu.au  Fri Nov 19 04:36:23 2010
From: davidD at qimr.edu.au (David Duffy)
Date: Fri, 19 Nov 2010 13:36:23 +1000 (EST)
Subject: [R-sig-ME] Logistic regression with factorial effect
In-Reply-To: <AANLkTi=n=0M1XKDY-gNJnm=9b0nX4=0esPiM1BW-3Ohq@mail.gmail.com>
References: <1290101520652-3049208.post@n4.nabble.com>
	<AANLkTi=n=0M1XKDY-gNJnm=9b0nX4=0esPiM1BW-3Ohq@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1011191253550.3427@orpheus.qimr.edu.au>

On Thu, 18 Nov 2010, Billy wrote:

> Hello,
>
> I?d like to evaluate the temporal effect on the relationship between a
> continuous variable (e.g. size) and the probability of mate success.
>
> glm(success1 ~ size, family=binomial) -> test1.1
> glmer(success1 ~ size + (1|ind), family=binomial) -> test2.1
> glmer(success1 ~ size + month + (1|ind), family=binomial) -> test3.1
> glmer(success1 ~ size : month + (1|ind), family=binomial) -> test4.1
>
> However, the expected result is not observed in the output of all these
> models. Using a model selection approach and comparing the AIC values of all
> models, it seems that test1.1 model is the most likely.

You have kind of done something wrong.  Consider

m0: success ~ size + month + size:month [in R, size*month]
m1: success ~ size:month


Cheers, David Duffy.



From sibylle.stoeckli at gmx.ch  Fri Nov 19 09:52:15 2010
From: sibylle.stoeckli at gmx.ch (=?iso-8859-1?Q?=22Sibylle_St=F6ckli=22?=)
Date: Fri, 19 Nov 2010 09:52:15 +0100
Subject: [R-sig-ME] LME and TukeyHSD
In-Reply-To: <Pine.LNX.4.64.1011191253550.3427@orpheus.qimr.edu.au>
References: <1290101520652-3049208.post@n4.nabble.com>
	<AANLkTi=n=0M1XKDY-gNJnm=9b0nX4=0esPiM1BW-3Ohq@mail.gmail.com>
	<Pine.LNX.4.64.1011191253550.3427@orpheus.qimr.edu.au>
Message-ID: <20101119085215.228070@gmx.net>


Dear Christoph

Thanks a lot! I still have some trouble with the is.na function

#
mydata<-subset(Kaltenborn,ADDspecies!=1)
mydata$sinmortality<-asin(sqrt(Kaltenborn$PropMortality))
mydata<-mydata[!is.na(mydata$sinmortality),]
error: is.na() applied to non-(list or vector)of type "NULL".

I tried to use as.list
#
mydata<-mydata[!is.na(as.list(mydata$sinmortality)),]

but this function produced some error within the lme model (varialbe lenght of sinmortality).

Do you have some idea, how to change the !is.na function for non-list data?

Thanks Sibylle



Dear Sibylle,

The reason for the error message may be that you transform your response
variable inside the model formula. This frequently causes errors when
working with components of lme models. In addition, you should try "ML"
instead of "REML" (when working with the fixed effects).

You may want to try:

##

mydata<-subset(Kaltenborn,ADDspecies!=1)
mydata$sinmortality<-asin(sqrt(Kaltenborn$PropMortality))
mydata<-mydata[!is.na(mydata$sinmortality),]

modelF<-lme(sinmortality~Diversity+Management+Species
+Height+Year+Diversity*Year, data=mydata, random=~1|Plot/SubPlot,
weights=varPower(form=~Diversity), method="ML")

summary(glht(modelF,linfct=mcp(Species="Tukey")))

##

Be reminded that it may not be sensible to test for Species main effects
when interactions are present; have you tested for interactions between
Species and other terms in the model?

Best wishes,
Christoph





Dear R users

I used lme to fit a linear mixed model inlcuding weights=varPower()
and subset. Additionally I wanted to use glht to calculate Tukey-
Kramer multiple comparisions.

I think that the error in glht() is probably caused by the subset and
varPower function within the lme model? I would very much appreciate
an input.

Thanks
Sibylle

LME MODEL
modelF<-lme(asin(sqrt(PropMortality))~Diversity+Management+Species
+Height+Year+Diversity*Year, data=Kaltenborn, random=~1|Plot/SubPlot,
na.action=na.omit, weights=varPower(form=~Diversity), subset=Kaltenborn
$ADDspecies!=1, method="REML")

anova(modelF, type="marginal")
               numDF denDF  F-value p-value
(Intercept)        1   162  7.12789  0.0084
Diversity          1    14 12.89284  0.0030
Management         2    30  5.52544  0.0091
Species            3   162 41.81003  <.0001
Height             1   162  2.59134  0.1094
Year               1   162  7.07660  0.0086
Diversity:Year     1   162 12.88095  0.0004

TukeyHSD
library(multcomp)
Loading required package: mvtnorm
Warning messages:
1: package 'multcomp' was built under R version 2.7.2
2: package 'mvtnorm' was built under R version 2.7.2
summary(glht(modelF,linfct=mcp(Species="Tukey")))

error
Error in glht.matrix(model = list(modelStruct = list(reStruct =
list(SubPlot = -0.305856275920955,  :
  ?ncol(linfct)? is not equal to ?length(coef(model))?

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models




-- 
GMX DSL Doppel-Flat ab 19,99 &euro;/mtl.! Jetzt auch mit 
gratis Notebook-Flat! http://portal.gmx.net/de/go/dsl



From tahirajamil at yahoo.com  Fri Nov 19 10:13:19 2010
From: tahirajamil at yahoo.com (Tahira Jamil)
Date: Fri, 19 Nov 2010 01:13:19 -0800 (PST)
Subject: [R-sig-ME] How to install lme4a
Message-ID: <995268.34452.qm@web113519.mail.gq1.yahoo.com>

Hi 
I wanted to install lme4a on my computer so to install this package directly within R I type
install.packages("lme4a", repos="http://R-Forge.R-project.org")
But I got the warning message
Warning message:
In getDependencies(pkgs, dependencies, available, lib) :
  package ?lme4a? is not available
Could anyone please help me how to install lme4a. 
Best Regards,
Tahira jamil
PhD student
Biometris 
Wageningen University







From Thierry.ONKELINX at inbo.be  Fri Nov 19 10:39:45 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Fri, 19 Nov 2010 10:39:45 +0100
Subject: [R-sig-ME] [R] Question on overdispersion
In-Reply-To: <1290141527037-3049898.post@n4.nabble.com>
References: <1290141527037-3049898.post@n4.nabble.com>
Message-ID: <3DB16098F738284D8DBEB2FC369916384D5F24@inboexch.inbo.be>

Dear Nameless,

The quasi distribution can no longer be used in lme4 because a) the
results were not very reliable b) there is an alternative to model
overdispersion.

The alternative is to expand your dataset to bernoulli trials. Then add
a random effect with one level per observation. This random effect will
model additive overdisperion. The quasi distributions model
overdisperion multiplicative.

In the example below, the random effect of RowID has 0 variance. Hence
no overdispersion.

dataset <- data.frame(
	male_chick_no = c(2,4,1,0,3,5,2), 
	female_chick_no=c(1,0,3,3,1,0,2), 
	FemaleID=c("A","A","B","B","C","D","E"))

longFormat <- do.call(rbind, lapply(seq_len(nrow(dataset)), function(i){
	with(dataset, data.frame(Sex = c(rep("M", male_chick_no[i]),
rep("F", female_chick_no[i])), FemaleID = FemaleID[i]))
}))
longFormat$FemaleID <- factor(longFormat$FemaleID)
longFormat$RowID <- factor(seq_len(nrow(longFormat)))
longFormat$Male <- longFormat$Sex == "M"

library(lme4)
fit1 <- glmer(Male ~ (1|FemaleID), data = longFormat, family = binomial)
fit2 <- glmer(Male ~ (1|FemaleID) + (1|RowID), data = longFormat, family
= binomial)
anova(fit1, fit2)

Best regards,

Thierry

PS sig-mixed-models is a better mailinglist for this kind of questions.

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] Namens cct663
> Verzonden: vrijdag 19 november 2010 5:39
> Aan: r-help at r-project.org
> Onderwerp: [R] Question on overdispersion
> 
> 
> I have a few questions relating to overdispersion in a sex 
> ratio data set that I am working with (note that I already 
> have an analysis with GLMMs for fixed effects, this is just 
> to estimate dispersion). The response variable is binomial 
> because nestlings can only be male or female. I have samples of
> 1-5 nestlings from each nest (individuals within a nest are 
> not independent, so the response variable is the ratio of 
> sons to daughters) and some females have multiple nests in 
> the data set (so I need to include female identity as a 
> random effect). 
> 
> Here is an example of what the three vectors used in the 
> model look like (the real data set is much bigger, just to 
> illustrate what I'm talking
> about):
> 
> male_chick_no=c(2,4,1,0,3,5,2)
> female_chick_no=c(1,0,3,3,1,0,2)
> FemaleID=c(A,A,B,B,C,D,E)
> 
> My first question relates to coding the test in R. I received 
> this suggested R syntax from a reviewer:
> 
> SexRatio = cbind(male_chick_no, female_chick_no)
> 
> Model <- lmer(SexRatio ~ 1 +(1|FemaleID), family = quasibinomial)
> 
> But when I try to use this in R I get the error: "Error in 
> glmer(formula = ratio ~ 1 + (1 | femid), family = 
> quasibinomial) : "quasi" families cannot be used in glmer".
> 
> I've tried playing around with some other mixed model 
> functions but can't seem to find one that will provide an 
> estimate of dispersion and allow me to include my random effect. 
> 
> Is there some other function I should be using? Or is there a 
> different syntax that I should use for lmer?
> 
> My second question is more general: I understand that with 
> binomial data overdispersion suggests that the observed data 
> have a greater variance than expected given binomial errors 
> (in my case this means that more nests would be all male/all 
> female than expected if sex is random). So with binomial 
> errors the expected estimate of dispersion is 1, if I find 
> that dispersion is > 1 it suggests that my data are 
> overdispersed. My question is, how much greater than 1 should 
> that number be to conclude that the data are overdispersed? 
> Is there a rule of thumb or does it just depend on the dataset? 
> 
> I was thinking of doing a randomization test with the same 
> structure (nest size and female id) as my real data set but 
> with sex ratio of each nest randomized with a 50:50 chance of 
> individuals being sons or daughters and comparing my observed 
> dispersion to the distribution of dispersions from the 
> randomization test. Would this be a valid way to ask whether 
> my data are overdispersed? Is it even necessary?
> 
> Any help/advice that you can provide would be greatly 
> appreciated. I am relatively new to R so explicit 
> instructions (i.e. easy to follow) would be wonderful.
> 
> Thanks.
> 
> --
> View this message in context: 
> http://r.789695.n4.nabble.com/Question-on-overdispersion-tp304
> 9898p3049898.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 



From j.hadfield at ed.ac.uk  Fri Nov 19 10:52:00 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 19 Nov 2010 09:52:00 +0000
Subject: [R-sig-ME] [R] Question on overdispersion
In-Reply-To: <3DB16098F738284D8DBEB2FC369916384D5F24@inboexch.inbo.be>
References: <1290141527037-3049898.post@n4.nabble.com>
	<3DB16098F738284D8DBEB2FC369916384D5F24@inboexch.inbo.be>
Message-ID: <20101119095200.23134d5s4a1whrcw@www.staffmail.ed.ac.uk>

Hi Thierry + nameless,

It is not necessary to expand the binomial into Bernoulli trials (nor  
advisable if n and/or the binomial size are large). You can just fit  
observation-level random effects:

dataset$resid<-as.factor(1:dim(dataset)[1])

fit3 <- glmer(cbind(male_chick_no, female_chick_no) ~ 1+(1|FemaleID)+  
(1|resid), data = dataset, family = binomial)

gives the same answer as fit2

Cheers,

Jarrod






Quoting "ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be>:

> Dear Nameless,
>
> The quasi distribution can no longer be used in lme4 because a) the
> results were not very reliable b) there is an alternative to model
> overdispersion.
>
> The alternative is to expand your dataset to bernoulli trials. Then add
> a random effect with one level per observation. This random effect will
> model additive overdisperion. The quasi distributions model
> overdisperion multiplicative.
>
> In the example below, the random effect of RowID has 0 variance. Hence
> no overdispersion.
>
> dataset <- data.frame(
> 	male_chick_no = c(2,4,1,0,3,5,2),
> 	female_chick_no=c(1,0,3,3,1,0,2),
> 	FemaleID=c("A","A","B","B","C","D","E"))
>
> longFormat <- do.call(rbind, lapply(seq_len(nrow(dataset)), function(i){
> 	with(dataset, data.frame(Sex = c(rep("M", male_chick_no[i]),
> rep("F", female_chick_no[i])), FemaleID = FemaleID[i]))
> }))
> longFormat$FemaleID <- factor(longFormat$FemaleID)
> longFormat$RowID <- factor(seq_len(nrow(longFormat)))
> longFormat$Male <- longFormat$Sex == "M"
>
> library(lme4)
> fit1 <- glmer(Male ~ (1|FemaleID), data = longFormat, family = binomial)
> fit2 <- glmer(Male ~ (1|FemaleID) + (1|RowID), data = longFormat, family
> = binomial)
> anova(fit1, fit2)
>
> Best regards,
>
> Thierry
>
> PS sig-mixed-models is a better mailinglist for this kind of questions.
>
> ------------------------------------------------------------------------
> ----
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek
> team Biometrie & Kwaliteitszorg
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
>
> Research Institute for Nature and Forest
> team Biometrics & Quality Assurance
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
>
> tel. + 32 54/436 185
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to
> say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of
> data.
> ~ John Tukey
>
>
>> -----Oorspronkelijk bericht-----
>> Van: r-help-bounces at r-project.org
>> [mailto:r-help-bounces at r-project.org] Namens cct663
>> Verzonden: vrijdag 19 november 2010 5:39
>> Aan: r-help at r-project.org
>> Onderwerp: [R] Question on overdispersion
>>
>>
>> I have a few questions relating to overdispersion in a sex
>> ratio data set that I am working with (note that I already
>> have an analysis with GLMMs for fixed effects, this is just
>> to estimate dispersion). The response variable is binomial
>> because nestlings can only be male or female. I have samples of
>> 1-5 nestlings from each nest (individuals within a nest are
>> not independent, so the response variable is the ratio of
>> sons to daughters) and some females have multiple nests in
>> the data set (so I need to include female identity as a
>> random effect).
>>
>> Here is an example of what the three vectors used in the
>> model look like (the real data set is much bigger, just to
>> illustrate what I'm talking
>> about):
>>
>> male_chick_no=c(2,4,1,0,3,5,2)
>> female_chick_no=c(1,0,3,3,1,0,2)
>> FemaleID=c(A,A,B,B,C,D,E)
>>
>> My first question relates to coding the test in R. I received
>> this suggested R syntax from a reviewer:
>>
>> SexRatio = cbind(male_chick_no, female_chick_no)
>>
>> Model <- lmer(SexRatio ~ 1 +(1|FemaleID), family = quasibinomial)
>>
>> But when I try to use this in R I get the error: "Error in
>> glmer(formula = ratio ~ 1 + (1 | femid), family =
>> quasibinomial) : "quasi" families cannot be used in glmer".
>>
>> I've tried playing around with some other mixed model
>> functions but can't seem to find one that will provide an
>> estimate of dispersion and allow me to include my random effect.
>>
>> Is there some other function I should be using? Or is there a
>> different syntax that I should use for lmer?
>>
>> My second question is more general: I understand that with
>> binomial data overdispersion suggests that the observed data
>> have a greater variance than expected given binomial errors
>> (in my case this means that more nests would be all male/all
>> female than expected if sex is random). So with binomial
>> errors the expected estimate of dispersion is 1, if I find
>> that dispersion is > 1 it suggests that my data are
>> overdispersed. My question is, how much greater than 1 should
>> that number be to conclude that the data are overdispersed?
>> Is there a rule of thumb or does it just depend on the dataset?
>>
>> I was thinking of doing a randomization test with the same
>> structure (nest size and female id) as my real data set but
>> with sex ratio of each nest randomized with a 50:50 chance of
>> individuals being sons or daughters and comparing my observed
>> dispersion to the distribution of dispersions from the
>> randomization test. Would this be a valid way to ask whether
>> my data are overdispersed? Is it even necessary?
>>
>> Any help/advice that you can provide would be greatly
>> appreciated. I am relatively new to R so explicit
>> instructions (i.e. easy to follow) would be wonderful.
>>
>> Thanks.
>>
>> --
>> View this message in context:
>> http://r.789695.n4.nabble.com/Question-on-overdispersion-tp304
>> 9898p3049898.html
>> Sent from the R help mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From Christoph.Scherber at agr.uni-goettingen.de  Fri Nov 19 10:58:34 2010
From: Christoph.Scherber at agr.uni-goettingen.de (Christoph Scherber)
Date: Fri, 19 Nov 2010 10:58:34 +0100
Subject: [R-sig-ME] LME and TukeyHSD
In-Reply-To: <20101119085215.228070@gmx.net>
References: <1290101520652-3049208.post@n4.nabble.com>	<AANLkTi=n=0M1XKDY-gNJnm=9b0nX4=0esPiM1BW-3Ohq@mail.gmail.com>
	<Pine.LNX.4.64.1011191253550.3427@orpheus.qimr.edu.au>
	<20101119085215.228070@gmx.net>
Message-ID: <4CE64A4A.5000004@agr.uni-goettingen.de>

Dear Sibylle,

You could also try to remove the NA?s like this:

mydata<-mydata[is.na(mydata$sinmortality)==F,]

or:

mydata<-na.exclude(mydata) # this may be a bit too strong, especially if many other variables contain NAs

Best wishes
Christoph




Sibylle St?ckli wrote:

> Dear Christoph
> 
> Thanks a lot! I still have some trouble with the is.na function
> 
> #
> mydata<-subset(Kaltenborn,ADDspecies!=1)
> mydata$sinmortality<-asin(sqrt(Kaltenborn$PropMortality))
> mydata<-mydata[!is.na(mydata$sinmortality),]
> error: is.na() applied to non-(list or vector)of type "NULL".
> 
> I tried to use as.list
> #
> mydata<-mydata[!is.na(as.list(mydata$sinmortality)),]
> 
> but this function produced some error within the lme model (varialbe lenght of sinmortality).
> 
> Do you have some idea, how to change the !is.na function for non-list data?
> 
> Thanks Sibylle
> 
> 
> 
> Dear Sibylle,
> 
> The reason for the error message may be that you transform your response
> variable inside the model formula. This frequently causes errors when
> working with components of lme models. In addition, you should try "ML"
> instead of "REML" (when working with the fixed effects).
> 
> You may want to try:
> 
> ##
> 
> mydata<-subset(Kaltenborn,ADDspecies!=1)
> mydata$sinmortality<-asin(sqrt(Kaltenborn$PropMortality))
> mydata<-mydata[!is.na(mydata$sinmortality),]
> 
> modelF<-lme(sinmortality~Diversity+Management+Species
> +Height+Year+Diversity*Year, data=mydata, random=~1|Plot/SubPlot,
> weights=varPower(form=~Diversity), method="ML")
> 
> summary(glht(modelF,linfct=mcp(Species="Tukey")))
> 
> ##
> 
> Be reminded that it may not be sensible to test for Species main effects
> when interactions are present; have you tested for interactions between
> Species and other terms in the model?
> 
> Best wishes,
> Christoph
> 
> 
> 
> 
> 
> Dear R users
> 
> I used lme to fit a linear mixed model inlcuding weights=varPower()
> and subset. Additionally I wanted to use glht to calculate Tukey-
> Kramer multiple comparisions.
> 
> I think that the error in glht() is probably caused by the subset and
> varPower function within the lme model? I would very much appreciate
> an input.
> 
> Thanks
> Sibylle
> 
> LME MODEL
> modelF<-lme(asin(sqrt(PropMortality))~Diversity+Management+Species
> +Height+Year+Diversity*Year, data=Kaltenborn, random=~1|Plot/SubPlot,
> na.action=na.omit, weights=varPower(form=~Diversity), subset=Kaltenborn
> $ADDspecies!=1, method="REML")
> 
> anova(modelF, type="marginal")
>                numDF denDF  F-value p-value
> (Intercept)        1   162  7.12789  0.0084
> Diversity          1    14 12.89284  0.0030
> Management         2    30  5.52544  0.0091
> Species            3   162 41.81003  <.0001
> Height             1   162  2.59134  0.1094
> Year               1   162  7.07660  0.0086
> Diversity:Year     1   162 12.88095  0.0004
> 
> TukeyHSD
> library(multcomp)
> Loading required package: mvtnorm
> Warning messages:
> 1: package 'multcomp' was built under R version 2.7.2
> 2: package 'mvtnorm' was built under R version 2.7.2
> summary(glht(modelF,linfct=mcp(Species="Tukey")))
> 
> error
> Error in glht.matrix(model = list(modelStruct = list(reStruct =
> list(SubPlot = -0.305856275920955,  :
>   ?ncol(linfct)? is not equal to ?length(coef(model))?
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 
> 


From Thierry.ONKELINX at inbo.be  Fri Nov 19 10:59:11 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Fri, 19 Nov 2010 10:59:11 +0100
Subject: [R-sig-ME] [R] Question on overdispersion
In-Reply-To: <20101119095200.23134d5s4a1whrcw@www.staffmail.ed.ac.uk>
References: <1290141527037-3049898.post@n4.nabble.com>
	<3DB16098F738284D8DBEB2FC369916384D5F24@inboexch.inbo.be>
	<20101119095200.23134d5s4a1whrcw@www.staffmail.ed.ac.uk>
Message-ID: <3DB16098F738284D8DBEB2FC369916384D5F3B@inboexch.inbo.be>

Dear Jarrod,

Thanks for the information 

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: Jarrod Hadfield [mailto:j.hadfield at ed.ac.uk] 
> Verzonden: vrijdag 19 november 2010 10:52
> Aan: ONKELINX, Thierry
> CC: cct663; r-help at r-project.org; r-sig-mixed-models at r-project.org
> Onderwerp: Re: [R-sig-ME] [R] Question on overdispersion
> 
> Hi Thierry + nameless,
> 
> It is not necessary to expand the binomial into Bernoulli 
> trials (nor advisable if n and/or the binomial size are 
> large). You can just fit observation-level random effects:
> 
> dataset$resid<-as.factor(1:dim(dataset)[1])
> 
> fit3 <- glmer(cbind(male_chick_no, female_chick_no) ~ 
> 1+(1|FemaleID)+ (1|resid), data = dataset, family = binomial)
> 
> gives the same answer as fit2
> 
> Cheers,
> 
> Jarrod
> 
> 
> 
> 
> 
> 
> Quoting "ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be>:
> 
> > Dear Nameless,
> >
> > The quasi distribution can no longer be used in lme4 because a) the 
> > results were not very reliable b) there is an alternative to model 
> > overdispersion.
> >
> > The alternative is to expand your dataset to bernoulli trials. Then 
> > add a random effect with one level per observation. This 
> random effect 
> > will model additive overdisperion. The quasi distributions model 
> > overdisperion multiplicative.
> >
> > In the example below, the random effect of RowID has 0 
> variance. Hence 
> > no overdispersion.
> >
> > dataset <- data.frame(
> > 	male_chick_no = c(2,4,1,0,3,5,2),
> > 	female_chick_no=c(1,0,3,3,1,0,2),
> > 	FemaleID=c("A","A","B","B","C","D","E"))
> >
> > longFormat <- do.call(rbind, lapply(seq_len(nrow(dataset)), 
> function(i){
> > 	with(dataset, data.frame(Sex = c(rep("M", 
> male_chick_no[i]), rep("F", 
> > female_chick_no[i])), FemaleID = FemaleID[i]))
> > }))
> > longFormat$FemaleID <- factor(longFormat$FemaleID) 
> longFormat$RowID <- 
> > factor(seq_len(nrow(longFormat))) longFormat$Male <- 
> longFormat$Sex == 
> > "M"
> >
> > library(lme4)
> > fit1 <- glmer(Male ~ (1|FemaleID), data = longFormat, family = 
> > binomial)
> > fit2 <- glmer(Male ~ (1|FemaleID) + (1|RowID), data = longFormat, 
> > family = binomial) anova(fit1, fit2)
> >
> > Best regards,
> >
> > Thierry
> >
> > PS sig-mixed-models is a better mailinglist for this kind 
> of questions.
> >
> > 
> ----------------------------------------------------------------------
> > --
> > ----
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek team Biometrie & 
> Kwaliteitszorg 
> > Gaverstraat 4 9500 Geraardsbergen Belgium
> >
> > Research Institute for Nature and Forest team Biometrics & Quality 
> > Assurance Gaverstraat 4 9500 Geraardsbergen Belgium
> >
> > tel. + 32 54/436 185
> > Thierry.Onkelinx at inbo.be
> > www.inbo.be
> >
> > To call in the statistician after the experiment is done may be no 
> > more than asking him to perform a post-mortem examination: 
> he may be 
> > able to say what the experiment died of.
> > ~ Sir Ronald Aylmer Fisher
> >
> > The plural of anecdote is not data.
> > ~ Roger Brinner
> >
> > The combination of some data and an aching desire for an 
> answer does 
> > not ensure that a reasonable answer can be extracted from a 
> given body 
> > of data.
> > ~ John Tukey
> >
> >
> >> -----Oorspronkelijk bericht-----
> >> Van: r-help-bounces at r-project.org
> >> [mailto:r-help-bounces at r-project.org] Namens cct663
> >> Verzonden: vrijdag 19 november 2010 5:39
> >> Aan: r-help at r-project.org
> >> Onderwerp: [R] Question on overdispersion
> >>
> >>
> >> I have a few questions relating to overdispersion in a sex 
> ratio data 
> >> set that I am working with (note that I already have an 
> analysis with 
> >> GLMMs for fixed effects, this is just to estimate dispersion). The 
> >> response variable is binomial because nestlings can only 
> be male or 
> >> female. I have samples of
> >> 1-5 nestlings from each nest (individuals within a nest are not 
> >> independent, so the response variable is the ratio of sons to 
> >> daughters) and some females have multiple nests in the 
> data set (so I 
> >> need to include female identity as a random effect).
> >>
> >> Here is an example of what the three vectors used in the 
> model look 
> >> like (the real data set is much bigger, just to illustrate 
> what I'm 
> >> talking
> >> about):
> >>
> >> male_chick_no=c(2,4,1,0,3,5,2)
> >> female_chick_no=c(1,0,3,3,1,0,2)
> >> FemaleID=c(A,A,B,B,C,D,E)
> >>
> >> My first question relates to coding the test in R. I received this 
> >> suggested R syntax from a reviewer:
> >>
> >> SexRatio = cbind(male_chick_no, female_chick_no)
> >>
> >> Model <- lmer(SexRatio ~ 1 +(1|FemaleID), family = quasibinomial)
> >>
> >> But when I try to use this in R I get the error: "Error in 
> >> glmer(formula = ratio ~ 1 + (1 | femid), family =
> >> quasibinomial) : "quasi" families cannot be used in glmer".
> >>
> >> I've tried playing around with some other mixed model 
> functions but 
> >> can't seem to find one that will provide an estimate of dispersion 
> >> and allow me to include my random effect.
> >>
> >> Is there some other function I should be using? Or is there a 
> >> different syntax that I should use for lmer?
> >>
> >> My second question is more general: I understand that with 
> binomial 
> >> data overdispersion suggests that the observed data have a greater 
> >> variance than expected given binomial errors (in my case 
> this means 
> >> that more nests would be all male/all female than expected 
> if sex is 
> >> random). So with binomial errors the expected estimate of 
> dispersion 
> >> is 1, if I find that dispersion is > 1 it suggests that my 
> data are 
> >> overdispersed. My question is, how much greater than 1 should that 
> >> number be to conclude that the data are overdispersed?
> >> Is there a rule of thumb or does it just depend on the dataset?
> >>
> >> I was thinking of doing a randomization test with the same 
> structure 
> >> (nest size and female id) as my real data set but with sex 
> ratio of 
> >> each nest randomized with a 50:50 chance of individuals 
> being sons or 
> >> daughters and comparing my observed dispersion to the 
> distribution of 
> >> dispersions from the randomization test. Would this be a 
> valid way to 
> >> ask whether my data are overdispersed? Is it even necessary?
> >>
> >> Any help/advice that you can provide would be greatly 
> appreciated. I 
> >> am relatively new to R so explicit instructions (i.e. easy 
> to follow) 
> >> would be wonderful.
> >>
> >> Thanks.
> >>
> >> --
> >> View this message in context:
> >> http://r.789695.n4.nabble.com/Question-on-overdispersion-tp304
> >> 9898p3049898.html
> >> Sent from the R help mailing list archive at Nabble.com.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
> 
> 
> 
> --
> The University of Edinburgh is a charitable body, registered 
> in Scotland, with registration number SC005336.
> 
> 
> 



From pmilin at ff.uns.ac.rs  Sat Nov 20 10:46:29 2010
From: pmilin at ff.uns.ac.rs (Petar Milin)
Date: Sat, 20 Nov 2010 10:46:29 +0100
Subject: [R-sig-ME] Are prediction interval values ungettable?
Message-ID: <4CE798F5.70203@ff.uns.ac.rs>

Hello all!
This is my third attempt (first at the general R-list, and one here five 
days or so ago), and I apologize for being tedious, but this started to 
bother me and my students are making my life a misery with this:
How can one get upper and lower limits of a prediction interval for 
random-effect levels; the exact exact values, numbers? They are shown on 
caterpillar plot using ranef() with
argument postVar=TRUE, but I would like to know them. A while ago, some
discussions were opened on "Confidence Intervals for Random Effect
BLUP's", but the answer was never clear:
http://www.mail-archive.com/r-help at r-project.org/msg04820.html

Thanks!
PM



From A.Robinson at ms.unimelb.edu.au  Sat Nov 20 12:13:20 2010
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Sat, 20 Nov 2010 22:13:20 +1100
Subject: [R-sig-ME] Are prediction interval values ungettable?
In-Reply-To: <4CE798F5.70203@ff.uns.ac.rs>
References: <4CE798F5.70203@ff.uns.ac.rs>
Message-ID: <AANLkTikJXHnoyZ7kR28DOvg515Qed9F3pXyUe6LeCSC5@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101120/927e112f/attachment.pl>

From pmilin at ff.uns.ac.rs  Sat Nov 20 14:21:02 2010
From: pmilin at ff.uns.ac.rs (Petar Milin)
Date: Sat, 20 Nov 2010 14:21:02 +0100
Subject: [R-sig-ME] Are prediction interval values ungettable?
In-Reply-To: <AANLkTikJXHnoyZ7kR28DOvg515Qed9F3pXyUe6LeCSC5@mail.gmail.com>
References: <4CE798F5.70203@ff.uns.ac.rs>
	<AANLkTikJXHnoyZ7kR28DOvg515Qed9F3pXyUe6LeCSC5@mail.gmail.com>
Message-ID: <4CE7CB3E.8020007@ff.uns.ac.rs>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101120/a9913497/attachment.pl>

From mensurationist at gmail.com  Sat Nov 20 19:36:52 2010
From: mensurationist at gmail.com (Andrew Robinson)
Date: Sun, 21 Nov 2010 05:36:52 +1100
Subject: [R-sig-ME] Are prediction interval values ungettable?
In-Reply-To: <4CE7CB3E.8020007@ff.uns.ac.rs>
References: <4CE798F5.70203@ff.uns.ac.rs>
	<AANLkTikJXHnoyZ7kR28DOvg515Qed9F3pXyUe6LeCSC5@mail.gmail.com>
	<4CE7CB3E.8020007@ff.uns.ac.rs>
Message-ID: <6FCFE614-2002-4EDB-AF0A-F7EDECE13480@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101121/740f8be6/attachment.pl>

From d.rizopoulos at erasmusmc.nl  Sun Nov 21 18:07:36 2010
From: d.rizopoulos at erasmusmc.nl (Dimitris Rizopoulos)
Date: Sun, 21 Nov 2010 18:07:36 +0100
Subject: [R-sig-ME] Are prediction interval values ungettable?
In-Reply-To: <4CE7CB3E.8020007@ff.uns.ac.rs>
References: <4CE798F5.70203@ff.uns.ac.rs>	<AANLkTikJXHnoyZ7kR28DOvg515Qed9F3pXyUe6LeCSC5@mail.gmail.com>
	<4CE7CB3E.8020007@ff.uns.ac.rs>
Message-ID: <4CE951D8.30909@erasmusmc.nl>

On 11/20/2010 2:21 PM, Petar Milin wrote:
> This is great! Many thanks!
> Now, practically, I can build: +/- 1.96*my.se
> Am I right?

maybe one thing that I think needs to be kept in mind is that the 
posterior variances that ranef(..., postVar = TRUE) returns condition on 
the MLEs and do not take their variability into account.

Best,
Dimitris


> Best,
> PM
>
> On 20/11/10 12:13, Andrew Robinson wrote:
>> last I tried this, the estimated variance of the random effects is
>> (optionally) stored as an attribute.  So, something like this should work
>> rfg<- ranef(my.lmer, postVar=TRUE)
>> my.se<http://my.se>  = sqrt(as.numeric(attributes(rfg$group)$postVar))
>>
>> On Sat, Nov 20, 2010 at 8:46 PM, Petar Milin wrote:
>>
>>      How can one get upper and lower limits of a prediction interval
>>      for random-effect levels; the exact exact values, numbers? They
>>      are shown on caterpillar plot using ranef() with
>>      argument postVar=TRUE, but I would like to know them. A while ago,
>>      some
>>      discussions were opened on "Confidence Intervals for Random Effect
>>      BLUP's", but the answer was never clear:
>>      http://www.mail-archive.com/r-help at r-project.org/msg04820.html
>>
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

-- 
Dimitris Rizopoulos
Assistant Professor
Department of Biostatistics
Erasmus University Medical Center

Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
Tel: +31/(0)10/7043478
Fax: +31/(0)10/7043014
Web: http://www.erasmusmc.nl/biostatistiek/



From pmilin at ff.uns.ac.rs  Sun Nov 21 18:11:54 2010
From: pmilin at ff.uns.ac.rs (Petar Milin)
Date: Sun, 21 Nov 2010 18:11:54 +0100
Subject: [R-sig-ME] Are prediction interval values ungettable?
In-Reply-To: <4CE951D8.30909@erasmusmc.nl>
References: <4CE798F5.70203@ff.uns.ac.rs>	<AANLkTikJXHnoyZ7kR28DOvg515Qed9F3pXyUe6LeCSC5@mail.gmail.com>
	<4CE7CB3E.8020007@ff.uns.ac.rs> <4CE951D8.30909@erasmusmc.nl>
Message-ID: <4CE952DA.1020208@ff.uns.ac.rs>

This is right, but I have compared values I get with the below procedure 
explained by Andrew and the end points of whiskers on the caterpillar 
plot (I tried to approximate them the best I could), and they do match 
for five different data sets and models.

Best,
PM

On 21/11/10 18:07, Dimitris Rizopoulos wrote:
> On 11/20/2010 2:21 PM, Petar Milin wrote:
>> This is great! Many thanks!
>> Now, practically, I can build: +/- 1.96*my.se
>> Am I right?
>
> maybe one thing that I think needs to be kept in mind is that the 
> posterior variances that ranef(..., postVar = TRUE) returns condition 
> on the MLEs and do not take their variability into account.
>
> Best,
> Dimitris
>
>
>> Best,
>> PM
>>
>> On 20/11/10 12:13, Andrew Robinson wrote:
>>> last I tried this, the estimated variance of the random effects is
>>> (optionally) stored as an attribute.  So, something like this should 
>>> work
>>> rfg<- ranef(my.lmer, postVar=TRUE)
>>> my.se<http://my.se>  = sqrt(as.numeric(attributes(rfg$group)$postVar))
>>>
>>> On Sat, Nov 20, 2010 at 8:46 PM, Petar Milin wrote:
>>>
>>>      How can one get upper and lower limits of a prediction interval
>>>      for random-effect levels; the exact exact values, numbers? They
>>>      are shown on caterpillar plot using ranef() with
>>>      argument postVar=TRUE, but I would like to know them. A while ago,
>>>      some
>>>      discussions were opened on "Confidence Intervals for Random Effect
>>>      BLUP's", but the answer was never clear:
>>>      http://www.mail-archive.com/r-help at r-project.org/msg04820.html
>>>
>>
>>
>>
>>     [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>



From S.Ellison at lgc.co.uk  Mon Nov 22 12:50:34 2010
From: S.Ellison at lgc.co.uk (S Ellison)
Date: Mon, 22 Nov 2010 11:50:34 +0000
Subject: [R-sig-ME] Expected correlation in a mixed model
Message-ID: <scea5914.023@tedmail.lgc.co.uk>

Forgive the possibly numb-brained question, but is there a reason why
the correlation between random effects coefficients in lmer should come
out as identically 1.0 in a model of the form

lmer(x ~ a + (a|b) )

?

An example:
set.seed(403)
require(lme4)
run <- gl(4, 15)
conc <- rep(rep(c(0,0.1, 0.2, 0.4, 1.0), 3), 4)
boxplot(conc~run)
offset=0.2*as.numeric(run)
od <- offset+conc+rnorm(60, 0, 0.2)
plot(conc, od)

(lmer1<-lmer(od~conc+(conc|run)))
VarCorr(lmer1)


S Ellison
LGC

*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}



From c.ryan.king at gmail.com  Mon Nov 22 13:50:00 2010
From: c.ryan.king at gmail.com (Ryan King)
Date: Mon, 22 Nov 2010 06:50:00 -0600
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 47, Issue 39
In-Reply-To: <mailman.3.1290423602.12086.r-sig-mixed-models@r-project.org>
References: <mailman.3.1290423602.12086.r-sig-mixed-models@r-project.org>
Message-ID: <AANLkTi=PvYUjBeaJW7=_6J7kfwopWdj1NC3xYEYWRiZE@mail.gmail.com>

It's just a caveat; neither the variance inflation of Kackar and
Harville (84) nor the t-statistics degree of freedom juggling that SAS
uses are being applied, so the variance is understated relative to
those.  My understanding is that it makes little difference in many
cases in practice, and I have no idea if the coverage properties
perform as advertised.

Ryan King
Dept Health Studies
University of Chicago

On Mon, Nov 22, 2010 at 5:00 AM,
<r-sig-mixed-models-request at r-project.org> wrote:
> Date: Sun, 21 Nov 2010 18:11:54 +0100
> From: Petar Milin <pmilin at ff.uns.ac.rs>
> To: Dimitris Rizopoulos <d.rizopoulos at erasmusmc.nl>
> Cc: R-SIG-LMER <r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] Are prediction interval values ungettable?
> Message-ID: <4CE952DA.1020208 at ff.uns.ac.rs>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
> This is right, but I have compared values I get with the below procedure
> explained by Andrew and the end points of whiskers on the caterpillar
> plot (I tried to approximate them the best I could), and they do match
> for five different data sets and models.
>
> Best,
> PM



From catferr at libero.it  Mon Nov 22 14:38:06 2010
From: catferr at libero.it (catferr)
Date: Mon, 22 Nov 2010 14:38:06 +0100
Subject: [R-sig-ME] problems with the variance in lmer
Message-ID: <LCAGJI$7264AA5BBAB5947E530F7677567623AC@libero.it>

Dear all
I am using lmer to analyze data on repeated measures of  physiological and hormonal parameters. In two cases (on five parameters that I have) the variance of the random term is equal to zero ( 0.000), suggesting an error in the way I am modelling the data. I was wondering if there is any function to define different correlation structure with lmer (I did not find a lot about it) or if you have other cues that I could try .
Thanks a lot in advance 
Caterina Ferrari
UQAM

Here the output of one of my model

modid<-lmer(increase~I.II+sex+age+(1|ID), data=cort)
>summary(modid)
Linear mixed model fit by REML 
Formula: increase ~ I.II + sex + age + (1 | ID) 
   Data: cort 
   AIC   BIC logLik deviance REMLdev
 249.1 258.9 -118.6    243.2   237.1
Random effects:
 Groups   Name        Variance Std.Dev.
 ID       (Intercept)  0.000   0.0000  
 Residual             39.419   6.2785  
Number of obs: 38, groups: ID, 18

Fixed effects:
            Estimate Std. Error t value
(Intercept)  2.10456    3.59425   0.586
I.II         0.07807    0.12102   0.645
sexm        -1.56851    2.29559  -0.683
agesubad     0.61569    2.26940   0.271

Correlation of Fixed Effects:
         (Intr) I.II   sexm  
I.II     -0.838              
sexm     -0.167 -0.292       
agesubad -0.315  0.128  0.025



From A.Robinson at ms.unimelb.edu.au  Mon Nov 22 15:44:23 2010
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Mon, 22 Nov 2010 23:44:23 +0900
Subject: [R-sig-ME] Expected correlation in a mixed model
In-Reply-To: <scea5914.023@tedmail.lgc.co.uk>
References: <scea5914.023@tedmail.lgc.co.uk>
Message-ID: <AANLkTiku1J+ohgO6Y52pu8p9vR+Ns0K-YWGsOo6xFbnv@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101122/a6866215/attachment.pl>

From bbolker at gmail.com  Mon Nov 22 16:07:36 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 22 Nov 2010 10:07:36 -0500
Subject: [R-sig-ME] Expected correlation in a mixed model
In-Reply-To: <AANLkTiku1J+ohgO6Y52pu8p9vR+Ns0K-YWGsOo6xFbnv@mail.gmail.com>
References: <scea5914.023@tedmail.lgc.co.uk>
	<AANLkTiku1J+ohgO6Y52pu8p9vR+Ns0K-YWGsOo6xFbnv@mail.gmail.com>
Message-ID: <4CEA8738.5040804@gmail.com>

  However: centering the concentration doesn't actually have much effect
in this example (which it would if the remoteness from the origin were
the problem), i.e.

concsc <- scale(conc)
(lmer1<-lmer(od~concsc+(concsc|run)))

  This setup seems a little bit odd to me:
 * the data set size is fairly small -- only 4 levels of the random
effect ('run'), which often leads to this sort of collapse (zero
variances and/or perfect correlations)
 * there is no variation in slopes across runs (the only randomness
here is the error term).  Perhaps what you're looking for is

(lmer2<-lmer(od~concsc+(1|run) + (0+concsc|run)))

  which fixes the correlation at zero.

  * it's also the case here that the random effect on the intercept of
'run' is uniformly distributed, rather than normal -- I don't know if
that would have an effect.

 Ben Bolker



On 11/22/2010 09:44 AM, Andrew Robinson wrote:
> Yes indeed --- remoteness of the data from the origin is a plausible
> explanation.
> 
> Cheers
> 
> Andrew
> 
> On Mon, Nov 22, 2010 at 8:50 PM, S Ellison <S.Ellison at lgc.co.uk> wrote:
> 
>> Forgive the possibly numb-brained question, but is there a reason why
>> the correlation between random effects coefficients in lmer should come
>> out as identically 1.0 in a model of the form
>>
>> lmer(x ~ a + (a|b) )
>>
>> ?
>>
>> An example:
>> set.seed(403)
>> require(lme4)
>> run <- gl(4, 15)
>> conc <- rep(rep(c(0,0.1, 0.2, 0.4, 1.0), 3), 4)
>> boxplot(conc~run)
>> offset=0.2*as.numeric(run)
>> od <- offset+conc+rnorm(60, 0, 0.2)
>> plot(conc, od)
>>
>> (lmer1<-lmer(od~conc+(conc|run)))
>> VarCorr(lmer1)
>>
>>
>> S Ellison
>> LGC
>>
>> *******************************************************************
>> This email and any attachments are confidential. Any u...{{dropped:21}}
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bbolker at gmail.com  Mon Nov 22 16:48:59 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 22 Nov 2010 10:48:59 -0500
Subject: [R-sig-ME] problems with the variance in lmer
In-Reply-To: <LCAGJI$7264AA5BBAB5947E530F7677567623AC@libero.it>
References: <LCAGJI$7264AA5BBAB5947E530F7677567623AC@libero.it>
Message-ID: <4CEA90EB.1050206@gmail.com>

On 11/22/2010 08:38 AM, catferr wrote:
> Dear all I am using lmer to analyze data on repeated measures of 
> physiological and hormonal parameters. In two cases (on five 
> parameters that I have) the variance of the random term is equal to 
> zero ( 0.000), suggesting an error in the way I am modelling the 
> data. I was wondering if there is any function to define different 
> correlation structure with lmer (I did not find a lot about it) or
> if you have other cues that I could try . Thanks a lot in advance
> Caterina Ferrari UQAM
> 
> Here the output of one of my model
> 
> modid<-lmer(increase~I.II+sex+age+(1|ID), data=cort)
>> summary(modid)
> Linear mixed model fit by REML Formula: increase ~ I.II + sex + age
> + (1 | ID) Data: cort AIC   BIC logLik deviance REMLdev 249.1 258.9 
> -118.6    243.2   237.1 Random effects: Groups   Name Variance 
> Std.Dev. ID       (Intercept)  0.000   0.0000 Residual 39.419 6.2785
>  Number of obs: 38, groups: ID, 18
> 
> Fixed effects: Estimate Std. Error t value (Intercept)  2.10456 
> 3.59425   0.586 I.II         0.07807    0.12102   0.645 sexm -1.56851
> 2.29559  -0.683 agesubad     0.61569    2.26940   0.271
> 
> Correlation of Fixed Effects: (Intr) I.II   sexm I.II     -0.838 sexm
> -0.167 -0.292 agesubad -0.315  0.128  0.025
> 

  The most common cause of this kind of problem is insufficient data.
Your data set is not as small as some I've seen, but it's pretty small
-- fitting 3 fixed effects to 38 data points (assuming each is either a
continuous covariate or a two-level factor, i.e. one parameter per
effect) is near the edge of what you can reliably manage (rule of thumb,
e.g. see Harrell's _Regression Modeling Strategies_ book, is 10-20 data
points per parameter).
  In lmer you can turn off the correlation between random effects
parameters, but in your case you only have one RE parameter (variance
among intercepts of ID), so that won't help. Continuously varying
correlation (as in the correlation= argument in lme) is not available in
lmer, and unlikely to be available soon, but again I don't see how it
would apply in your case. (The specification above does not, for
example, allow for differential correlation among samples within
individuals -- the samples within individual are assumed exchangeable --
but I wouldn't feel too comfortable trying to fit a model of that
complexity anyway when you have an average of about two samples per
individual ...)
   My general advice when you think you might be specifying the model
wrong is to simulate some data (esp. with larger sample sizes) and see
if you get the expected answer ...
   Since this model can also be fitted in lme, I also might consider

library(nlme)
lme(increase~I.II+sex+age, random=~1|ID, data=cort)

  and see whether you get similar answers.



From Jason_Taylor1 at baylor.edu  Mon Nov 22 23:49:45 2010
From: Jason_Taylor1 at baylor.edu (Taylor, Jason)
Date: Mon, 22 Nov 2010 16:49:45 -0600
Subject: [R-sig-ME] Need advice on model specification for repeated measures
 on split-plot design
Message-ID: <DB0892FFCE97CA42BE2144E916EB43F22D557488DA@MAIL-IK.baylor.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101122/c073acf5/attachment.pl>

From a.mosnier at gmail.com  Tue Nov 23 16:06:16 2010
From: a.mosnier at gmail.com (Arnaud Mosnier)
Date: Tue, 23 Nov 2010 10:06:16 -0500
Subject: [R-sig-ME] P value value for a large number of degree of freedom in
	lmer
Message-ID: <AANLkTim+13OU0K1oUVcv1N6d6K_Qq00HxvK6EprVO6w5@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101123/b47b6827/attachment.pl>

From kevin.thorpe at utoronto.ca  Tue Nov 23 19:05:44 2010
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Tue, 23 Nov 2010 13:05:44 -0500
Subject: [R-sig-ME] Fitted values for binomial family in lme4a{glmer}
Message-ID: <201011231305.44141.kevin.thorpe@utoronto.ca>

I searched the archives and found questions like this with no definitive 
answers.  I also did not find an answer in the lme4a help files.

I'm using lme4a_0.999375-57 in R version 2.12.0 Patched (2010-11-07 r53537) on
Platform: i686-pc-linux-gnu (32-bit).

I've fit a model with glmer() using the binomial family.  I'm wondering what 
fitted() gives on the result.  It appears that fitted() on a regular logistic 
model fit with glm() returns fitted probabilities.  It looks like the same 
behaviour occurs with a glmer() object, but some confirmation would be nice.

Kevin

-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016



From r.turner at auckland.ac.nz  Tue Nov 23 19:59:33 2010
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 24 Nov 2010 07:59:33 +1300
Subject: [R-sig-ME] P value value for a large number of degree of
	freedom in lmer
In-Reply-To: <AANLkTim+13OU0K1oUVcv1N6d6K_Qq00HxvK6EprVO6w5@mail.gmail.com>
References: <AANLkTim+13OU0K1oUVcv1N6d6K_Qq00HxvK6EprVO6w5@mail.gmail.com>
Message-ID: <EB95FF77-2DAF-4E6A-8EBA-6A2BE61E0236@auckland.ac.nz>


It is well known amongst statisticians that having a large enough data set will
result in the rejection of *any* null hypothesis, i.e. will result in a small
p-value.  There is no ``bias'' involved.

	cheers,

		Rolf Turner

On 24/11/2010, at 4:06 AM, Arnaud Mosnier wrote:

> Dear UseRs,
> 
> I am using a database containing nearly 200 000 observations occurring in 33
> groups.
> With a model of the form ( y ~ x + (1|group) ) in lmer, my number of degree
> of freedom is really large.
> I am wondering if this large df have an impact on the p values, mainly if
> this could conduct to consider the effect of a variable as significant while
> it is not .
> ... and if it is the case, does it exist a correction to apply on the
> results to take into account that bias.
> 
> thanks !
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From a.mosnier at gmail.com  Tue Nov 23 20:25:14 2010
From: a.mosnier at gmail.com (Arnaud Mosnier)
Date: Tue, 23 Nov 2010 14:25:14 -0500
Subject: [R-sig-ME] P value value for a large number of degree of
 freedom in lmer
In-Reply-To: <EB95FF77-2DAF-4E6A-8EBA-6A2BE61E0236@auckland.ac.nz>
References: <AANLkTim+13OU0K1oUVcv1N6d6K_Qq00HxvK6EprVO6w5@mail.gmail.com>
	<EB95FF77-2DAF-4E6A-8EBA-6A2BE61E0236@auckland.ac.nz>
Message-ID: <AANLkTikVA-u-kAuNKYn8U5sxi8Sro8_fWah-SO3KKAdp@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101123/2b7651ba/attachment.pl>

From smckinney at bccrc.ca  Tue Nov 23 20:40:28 2010
From: smckinney at bccrc.ca (Steven McKinney)
Date: Tue, 23 Nov 2010 11:40:28 -0800
Subject: [R-sig-ME] P value value for a large number of degree of
 freedom in lmer
In-Reply-To: <7680_1290540348_1290540348_AANLkTikVA-u-kAuNKYn8U5sxi8Sro8_fWah-SO3KKAdp@mail.gmail.com>
References: <AANLkTim+13OU0K1oUVcv1N6d6K_Qq00HxvK6EprVO6w5@mail.gmail.com>
	<EB95FF77-2DAF-4E6A-8EBA-6A2BE61E0236@auckland.ac.nz>,
	<7680_1290540348_1290540348_AANLkTikVA-u-kAuNKYn8U5sxi8Sro8_fWah-SO3KKAdp@mail.gmail.com>
Message-ID: <DCE81E14EB74504B971DAD4D2DB0356B0864568541@crcmail4.BCCRC.CA>


You have to determine what is a "real" effect - how big of a departure from the null is 
scientifically or biologically relevant (or whatever your area of interest is)?

If differences of scientific relevance are not too small, you will have enough power to
detect differences of importance.  This is the situation we all want to get to.
Enough data to declare unambiguously that a difference of relevance has been detected.

Some of your differences may be statistically significant, though the measured size may
be less than your difference of scientific relevance.  Such differences, though statistically
significant, are then not scientifically relevant.

Though it is not trivial to peg the size of scientifically relevant differences, it can be done
with some deliberation by considering a range of difference values, from ludicrously small
to ridiculously large.  Somewhere in between is a reasonable difference of relevance.



Steven McKinney

________________________________________
From: r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] On Behalf Of Arnaud Mosnier [a.mosnier at gmail.com]
Sent: November 23, 2010 11:25 AM
To: Rolf Turner
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] P value value for a large number of degree of freedom in lmer

I agree but how to test that a significant result is not due to the amount
of data but by a real effect.
I though about subsetting my dataset and rerun the model X time to see if
the result still persist ... but you can also say that doing so I will
achieve to find a (small enough) size of subset at which I will not detect
the effect :-)
I also agree that the term "bias" was not correctly used ... but is there a
method to increase the confidence in those results ?

cheers,

Arnaud

2010/11/23 Rolf Turner <r.turner at auckland.ac.nz>

>
> It is well known amongst statisticians that having a large enough data set
> will
> result in the rejection of *any* null hypothesis, i.e. will result in a
> small
> p-value.  There is no ``bias'' involved.
>
>        cheers,
>
>                Rolf Turner
>
> On 24/11/2010, at 4:06 AM, Arnaud Mosnier wrote:
>
> > Dear UseRs,
> >
> > I am using a database containing nearly 200 000 observations occurring in
> 33
> > groups.
> > With a model of the form ( y ~ x + (1|group) ) in lmer, my number of
> degree
> > of freedom is really large.
> > I am wondering if this large df have an impact on the p values, mainly if
> > this could conduct to consider the effect of a variable as significant
> while
> > it is not .
> > ... and if it is the case, does it exist a correction to apply on the
> > results to take into account that bias.
> >
> > thanks !
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From r.turner at auckland.ac.nz  Tue Nov 23 20:42:39 2010
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 24 Nov 2010 08:42:39 +1300
Subject: [R-sig-ME] P value value for a large number of degree of
	freedom in lmer
In-Reply-To: <AANLkTikVA-u-kAuNKYn8U5sxi8Sro8_fWah-SO3KKAdp@mail.gmail.com>
References: <AANLkTim+13OU0K1oUVcv1N6d6K_Qq00HxvK6EprVO6w5@mail.gmail.com>
	<EB95FF77-2DAF-4E6A-8EBA-6A2BE61E0236@auckland.ac.nz>
	<AANLkTikVA-u-kAuNKYn8U5sxi8Sro8_fWah-SO3KKAdp@mail.gmail.com>
Message-ID: <0648D993-3000-48C1-8AEF-79D5D7E41F33@auckland.ac.nz>


On 24/11/2010, at 8:25 AM, Arnaud Mosnier wrote:

> I agree but how to test that a significant result is not due to the amount of data but by a real effect.

	The point is that there is *always* a ``real'' effect,
	and a large enough sample will detect this.  The question is
	whether this effect is meaningful or of *practical* significance.

> I though about subsetting my dataset and rerun the model X time to see if the result still persist ... but you can also say that doing so I will achieve to find a (small enough) size of subset at which I will not detect the effect :-)
> I also agree that the term "bias" was not correctly used ... but is there a method to increase the confidence in those results ?


Stop thinking p-values.  Think estimates and confidence intervals for
the estimated quantities.

	cheers,

		Rolf Turner


From jwiley.psych at gmail.com  Tue Nov 23 20:45:44 2010
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Tue, 23 Nov 2010 11:45:44 -0800
Subject: [R-sig-ME] P value value for a large number of degree of
 freedom in lmer
In-Reply-To: <AANLkTikVA-u-kAuNKYn8U5sxi8Sro8_fWah-SO3KKAdp@mail.gmail.com>
References: <AANLkTim+13OU0K1oUVcv1N6d6K_Qq00HxvK6EprVO6w5@mail.gmail.com>
	<EB95FF77-2DAF-4E6A-8EBA-6A2BE61E0236@auckland.ac.nz>
	<AANLkTikVA-u-kAuNKYn8U5sxi8Sro8_fWah-SO3KKAdp@mail.gmail.com>
Message-ID: <AANLkTik5mgX+Hq7tXrwLj6vFShngGAWs+yn1Ld2gsJrh@mail.gmail.com>

Dear Arnaud,

Having a large amount of data *is* exactly what increases confidence
in results.  A p-value is the probability of obtaining your results
given the null hypothesis is true *in the population*.  If you have a
lot of data, you have a lot of the population, and can more
confidently say "this is what the population is or is note like".  The
p-value is serving its purpose exactly as it was meant to, there is no
need to "correct" or "alter" it.  The real question is, does anyone
care about your effect?  Effect sizes are often a good way to get at
the idea of is the effect meaningful, does it have practical
significance, could an average person notice the difference?

Cheers,

Josh

On Tue, Nov 23, 2010 at 11:25 AM, Arnaud Mosnier <a.mosnier at gmail.com> wrote:
> I agree but how to test that a significant result is not due to the amount
> of data but by a real effect.
> I though about subsetting my dataset and rerun the model X time to see if
> the result still persist ... but you can also say that doing so I will
> achieve to find a (small enough) size of subset at which I will not detect
> the effect :-)
> I also agree that the term "bias" was not correctly used ... but is there a
> method to increase the confidence in those results ?
>
> cheers,
>
> Arnaud
>
> 2010/11/23 Rolf Turner <r.turner at auckland.ac.nz>
>
>>
>> It is well known amongst statisticians that having a large enough data set
>> will
>> result in the rejection of *any* null hypothesis, i.e. will result in a
>> small
>> p-value. ?There is no ``bias'' involved.
>>
>> ? ? ? ?cheers,
>>
>> ? ? ? ? ? ? ? ?Rolf Turner
>>
>> On 24/11/2010, at 4:06 AM, Arnaud Mosnier wrote:
>>
>> > Dear UseRs,
>> >
>> > I am using a database containing nearly 200 000 observations occurring in
>> 33
>> > groups.
>> > With a model of the form ( y ~ x + (1|group) ) in lmer, my number of
>> degree
>> > of freedom is really large.
>> > I am wondering if this large df have an impact on the p values, mainly if
>> > this could conduct to consider the effect of a variable as significant
>> while
>> > it is not .
>> > ... and if it is the case, does it exist a correction to apply on the
>> > results to take into account that bias.
>> >
>> > thanks !
>> >
>> > ? ? ? [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
University of California, Los Angeles
http://www.joshuawiley.com/



From pmilin at ff.uns.ac.rs  Tue Nov 23 20:59:18 2010
From: pmilin at ff.uns.ac.rs (Petar Milin)
Date: Tue, 23 Nov 2010 20:59:18 +0100
Subject: [R-sig-ME] P value value for a large number of degree of
 freedom in lmer
In-Reply-To: <AANLkTik5mgX+Hq7tXrwLj6vFShngGAWs+yn1Ld2gsJrh@mail.gmail.com>
References: <AANLkTim+13OU0K1oUVcv1N6d6K_Qq00HxvK6EprVO6w5@mail.gmail.com>	<EB95FF77-2DAF-4E6A-8EBA-6A2BE61E0236@auckland.ac.nz>	<AANLkTikVA-u-kAuNKYn8U5sxi8Sro8_fWah-SO3KKAdp@mail.gmail.com>
	<AANLkTik5mgX+Hq7tXrwLj6vFShngGAWs+yn1Ld2gsJrh@mail.gmail.com>
Message-ID: <4CEC1D16.7000902@ff.uns.ac.rs>

Hello!

On 23/11/10 20:45, Joshua Wiley wrote:
> Having a large amount of data *is* exactly what increases confidence
> in results.  A p-value is the probability of obtaining your results
> given the null hypothesis is true *in the population*.  If you have a
> lot of data, you have a lot of the population, and can more
> confidently say "this is what the population is or is note like".  The
> p-value is serving its purpose exactly as it was meant to, there is no
> need to "correct" or "alter" it.  The real question is, does anyone
> care about your effect?  Effect sizes are often a good way to get at
> the idea of is the effect meaningful, does it have practical
> significance, could an average person notice the difference?
>    
This is very good! In some oldish statistical books you can find the 
expression "effect's substantiality".
Of course, not only the size of the sample matters. Think of having very 
large sample of clinically ill people. Would you like to generalize your 
finding to all humans, ever? Probably not, I believe. What I am trying 
to say is that not all issues can be resolved statistically. You also 
have many methodological aspects, some of which are related to the 
sampling issues.

Best,
Petar



From bbolker at gmail.com  Tue Nov 23 21:09:50 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 23 Nov 2010 15:09:50 -0500
Subject: [R-sig-ME] P value value for a large number of degree of
 freedom in lmer
In-Reply-To: <AANLkTik5mgX+Hq7tXrwLj6vFShngGAWs+yn1Ld2gsJrh@mail.gmail.com>
References: <AANLkTim+13OU0K1oUVcv1N6d6K_Qq00HxvK6EprVO6w5@mail.gmail.com>	<EB95FF77-2DAF-4E6A-8EBA-6A2BE61E0236@auckland.ac.nz>	<AANLkTikVA-u-kAuNKYn8U5sxi8Sro8_fWah-SO3KKAdp@mail.gmail.com>
	<AANLkTik5mgX+Hq7tXrwLj6vFShngGAWs+yn1Ld2gsJrh@mail.gmail.com>
Message-ID: <4CEC1F8E.3010502@gmail.com>


  What may be getting lost in this discussion is that in simple cases
(normally distributed data, balanced orthogonal designs etc. etc.) there
is at least a coherent *definition* of the p-value, which would involve
the upper (or extreme/two-sided) tail of the t distribution with the
appropriate degrees of freedom or an F distribution with equivalent
denominator df. [I was going to write that in this case it would be
g-1=31 degrees of freedom, but I actually realized (I think) that would
only be the df for determining an effect in the intercept or in other
factors that varied across groups.  Here I think you have something like
199,999 df left to make inferences on the slope, because it is assumed
*not* to vary across groups ...] The best thing to do (IMO) if you want
to use these approaches is to look at a classical textbook, find the
appropriate calculation for your design, and apply the df to the test
statistic by hand. (You can also try the problem in lme and see what it
guesses, although it may guess wrong.) In many, many cases (unbalanced,
GLMMs, crossed designs, R-side correlation structures, ...) a
universally accepted definition does not exist.
  I do agree with the previous posters that you should think hard about
what (if anything) the p-values mean in this case, though.  Suppose your
t-statistic was 100.  Does the difference between p=exp(-184) and
p=exp(-10011) mean anything?

> 2*pnorm(-abs(100),log.p=TRUE)
[1] -10011.05
> 2*pt(-abs(100),df=31,log.p=TRUE)
[1] -184.448


On 10-11-23 02:45 PM, Joshua Wiley wrote:
> Dear Arnaud,
> 
> Having a large amount of data *is* exactly what increases confidence
> in results.  A p-value is the probability of obtaining your results
> given the null hypothesis is true *in the population*.  If you have a
> lot of data, you have a lot of the population, and can more
> confidently say "this is what the population is or is note like".  The
> p-value is serving its purpose exactly as it was meant to, there is no
> need to "correct" or "alter" it.  The real question is, does anyone
> care about your effect?  Effect sizes are often a good way to get at
> the idea of is the effect meaningful, does it have practical
> significance, could an average person notice the difference?
> 
> Cheers,
> 
> Josh
> 
> On Tue, Nov 23, 2010 at 11:25 AM, Arnaud Mosnier <a.mosnier at gmail.com> wrote:
>> I agree but how to test that a significant result is not due to the amount
>> of data but by a real effect.
>> I though about subsetting my dataset and rerun the model X time to see if
>> the result still persist ... but you can also say that doing so I will
>> achieve to find a (small enough) size of subset at which I will not detect
>> the effect :-)
>> I also agree that the term "bias" was not correctly used ... but is there a
>> method to increase the confidence in those results ?
>>
>> cheers,
>>
>> Arnaud
>>
>> 2010/11/23 Rolf Turner <r.turner at auckland.ac.nz>
>>
>>>
>>> It is well known amongst statisticians that having a large enough data set
>>> will
>>> result in the rejection of *any* null hypothesis, i.e. will result in a
>>> small
>>> p-value.  There is no ``bias'' involved.
>>>
>>>        cheers,
>>>
>>>                Rolf Turner
>>>
>>> On 24/11/2010, at 4:06 AM, Arnaud Mosnier wrote:
>>>
>>>> Dear UseRs,
>>>>
>>>> I am using a database containing nearly 200 000 observations occurring in
>>> 33
>>>> groups.
>>>> With a model of the form ( y ~ x + (1|group) ) in lmer, my number of
>>> degree
>>>> of freedom is really large.
>>>> I am wondering if this large df have an impact on the p values, mainly if
>>>> this could conduct to consider the effect of a variable as significant
>>> while
>>>> it is not .
>>>> ... and if it is the case, does it exist a correction to apply on the
>>>> results to take into account that bias.
>>>>
>>>> thanks !
>>>>
>>>>       [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>
>>        [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 
>



From bvholbi at yahoo.com  Tue Nov 23 22:11:16 2010
From: bvholbi at yahoo.com (Beth Holbrook)
Date: Tue, 23 Nov 2010 13:11:16 -0800 (PST)
Subject: [R-sig-ME] lmer vs SAS results
In-Reply-To: <mailman.5.1287655203.31036.r-sig-mixed-models@r-project.org>
References: <mailman.5.1287655203.31036.r-sig-mixed-models@r-project.org>
Message-ID: <346807.26639.qm@web35303.mail.mud.yahoo.com>

First, let me preface this by saying I am an ecology Ph.D. student, relatively 
new to R, and even more new to mixed models, so I apologize in advance for my 
limited knowledge on this topic. (Also, I need to apologize for the length of 
this email - but I wanted to be as specific as possible).

I posted a question a few weeks ago, and received many helpful responses, so I'm 
hoping you can help me again.  The statistician on my committee has assisted me 
in setting up my analysis design; however, he is receiving different results 
using SAS than I am using lmer.  I understand that the goal of lmer is not to 
replicate results of SAS; however, I am unable to move ahead with my 
dissertation until I can provide him with a satisfactory explanation for these 
differences (I no longer have access to SAS so I need to use R as my primary 
statistical software).

My analysis design is to run a mixed model to test for the effects of prey 
movement ("preyswimy.n") and light ("lightclass") on the reaction distance 
("logrxndist") of young lake trout.  The random effect is "trial" since I 
observed several responses to prey for the same fish during each trial.

Using the lme4 package, I set up the following:

> options(contrasts = c(factor = "contr.SAS", ordered = "contr.poly"))
> lightclass <- factor(Dataset$light)
> trial <- factor(Dataset$trial)
> model1 <-lmer(logrxndist~preyswimy.n * lightclass + (1|trial), Dataset, 
>REML=FALSE)
> model2 <-lmer(logrxndist~preyswimy.n + lightclass + (1|trial), Dataset, 
>REML=FALSE)
> model3 <-lmer(logrxndist~preyswimy.n + (1|trial), Dataset, REML=FALSE)

Based on the following results, I concluded that the most appropriate model was 
model3 where lightclass was omitted.

> anova(model1, model2, model3)
Data: Dataset
Models:
model3: logrxndist ~ preyswimy.n + (1 | trial)
model2: logrxndist ~ preyswimy.n + lightclass + (1 | trial)
model1: logrxndist ~ preyswimy.n * lightclass + (1 | trial)
       Df    AIC    BIC   logLik  Chisq Chi Df Pr(>Chisq)
model3  4 214.21 229.98 -103.103                         
model2  9 215.26 250.74  -98.628 8.9494      5     0.1111
model1 14 219.15 274.35  -95.575 6.1062      5     0.2960   



In SAS, the statistician on my committee used the following code:


model1: 
proc mixed data=holbrook.bethfull method=ml;
  class preyswimy.n trial light;
  model logrxndist = light | preyswimy.n /solution;
  random trial;
  run;

model2:
proc mixed data=holbrook.bethfull method=ml;
  class preyswimy.n trial light;
  model logrxndist = light  preyswimy.n / solution;
  random trial;
  run;


model3
proc mixed data=holbrook.bethfull method=ml;
  class preyswimy.n trial;
  model logrxndist = preyswimy.n / solution ;
  random trial;
  run;

His results are as follows:
     
               AIC    BIC    -2 Log Likelihood  
model1   216.7  251.1   188.7 
model2   213.3  235.4   195.3
model3   214.2  224.0   206.2                         

Based on these results, he concluded that model2 had the lowest AIC and light 
was significant.

The lmer and SAS fixed effect parameter estimates were similar for model1, 
model2, and model3 (see below).  The lmer and SAS variance estimates for the 
random effect were the same for model3 (when light was excluded).  However, the 
variance estimates for the random effect differed in model1 and in model2.  The 
lmer results suggest that there is no random effect of "trial" in these models. 
 However, SAS results gave a larger variance estimate for the random effect of 
trial in model1 and model2.  Any ideas why that might be the case?  
     
model1 Random effects
 Groups   Variance-lmerVariance-SAS   
 trials    1.0305e-11 0.005385
 Residual        9.6697e-02 0.09126

model1 Fixed effects
                            Estimate-lmer   Estimate-SAS
(Intercept)                 2.151398   2.1448
preyswimy.nN               -0.344458   -0.3386
lightclass0.4               0.056317   0.06450
lightclass2.5               0.104469   0.1108
lightclass8                 0.074183   0.07667
lightclass55               -0.043046  -0.03805
lightclass340              -0.074705   -0.06529
preyswimy.nN:lightclass0.4 -0.257426   -0.2651
preyswimy.nN:lightclass2.5 -0.179126  -0.1808
preyswimy.nN:lightclass8   -0.058160   -0.05099
preyswimy.nN:lightclass55  -0.007468   -0.00753
preyswimy.nN:lightclass340 -0.123571   -0.1413


model2 Random effects:
GroupsVariance-lmerVariance-SAS
trial8.3902e-120.004775
Residual9.8259e-02  0.09394

model2 Fixed effects:

               Estimate-lmerEstimate-SAS
(Intercept)     2.20135   2.1975
preyswimy.nY    -0.45319   -0.4507
lightclass0.4  -0.02280-0.01755
lightclass2.5   0.02251    0.02634
lightclass8     0.04108    0.04401
lightclass55   -0.03539   -0.03229
lightclass340  -0.13272    -0.1336



model3 Random effects:
GroupsVariance-lmerVariance-SAS
trial0.00769170.007692
Residual0.0939409  0.09394

model3 Fixed effects:
  Estimate-lmerEstimate-SAS
(Intercept)2.186092.1861
preyswimy.nN  -0.46016 -0.4602


Thank you for any insight that you can provide.  Below, I've also attached a 
copy of the data in case you would like to run it yourself.

Thanks again,
Beth

Beth Holbrook
Ph.D. Candidate
University of Minnesota


Dataset

triallogrxndistpreyswimy.nlight
5220712.115943177N0.4
5220712.470557485Y0.4
5220721.902546779Y0.4
5220722.272769587Y0.4
5220731.985426474Y0.4
5220731.862131379Y0.4
5220732.275541688Y0.4
5220731.846337112Y0.4
5250712.314709693Y0.4
5250712.360025089Y0.4
5250712.344785123Y0.4
5250711.068185862Y0.4
5250712.540329475Y0.4
5250722.030599722Y0.4
5250721.848804701Y0.4
5250722.326540669Y0.4
5250732.186391216Y0.4
5250732.421603927Y0.4
5250732.381295623Y0.4
5250731.672097858Y0.4
6050761.844477176Y0.4
6050762.219060332Y0.4
6050762.518645524Y0.4
6050762.546419267Y0.4
6060712.153814864Y0.4
6060712.625106575Y0.4
6060712.369957607Y0.4
6060711.589949601N0.4
6060712.506505032Y0.4
6060721.439332694N0.4
6060721.822168079Y0.4
6220732.218010043Y0.4
6220732.299289334Y0.4
6220741.431363764N0.4
6220742.419955748Y0.4
6220752.227372442Y0.4
6220752.338057875Y0.4
6220761.643452676N0.4
6220762.260309946Y0.4
6220761.404833717N0.4
6220762.343802333Y0.4
6250712.366236124Y0.4
6250712.557867962Y0.4
6250712.452706227Y0.4
6250721.920645001Y0.4
6250721.967079734Y0.4
6250721.6599162N0.4
6250721.492760389N0.4
6250721.240549248N0.4
6250722.040206628N0.4
6250722.428134794Y0.4
5220741.860936621Y2.5
5220742.020361283N2.5
5220742.567731963Y2.5
5220751.599883072N2.5
5220761.350248018N2.5
5220762.288919606Y2.5
5220761.320146286N2.5
5230712.069668097N2.5
5230711.953759692N2.5
5230712.016197354N2.5
5230712.240549248Y2.5
5250741.620136055N2.5
5250742.160768562N2.5
5250741.498310554N2.5
5250742.431685345N2.5
5250751.855519156N2.5
6070712.357363031Y2.5
6070712.657629431Y2.5
6070712.302763708Y2.5
6070712.353723938Y2.5
6070712.584670384Y2.5
6070722.393224116Y2.5
6070721.722633923N2.5
6070721.830588669N2.5
6070721.812913357Y2.5
6070731.920645001N2.5
6070732.635081436Y2.5
6250731.859738566N2.5
6250732.418798291Y2.5
6250732.488550717Y2.5
6250732.084576278Y2.5
6250732.384353414Y2.5
6250732.489677292Y2.5
6250741.795880017N2.5
6250742.245265839Y2.5
6250742.068927612Y2.5
6250742.590841835Y2.5
6250742.5594278Y2.5
6250741.589949601N2.5
6250751.848189117Y2.5
6250751.816903839N2.5
6250751.613841822N2.5
6250752.536305872Y2.5
6250752.461948495Y2.5
6250752.456214155Y2.5
6250761.629409599N2.5
6250761.921686475N2.5
6250761.862727528N2.5
6250761.475671188N2.5
7020712.254064453Y2.5
7020712.137037455Y2.5
7020722.245759356Y2.5
7020721.773786445N2.5
7020722.639486489Y2.5
7020721.725094521N2.5
7020722.332842267Y2.5
7020721.854306042Y2.5
7020721.534026106N2.5
7020732.521268876Y2.5
7020732.176380692Y2.5
7020732.358125285Y2.5
7020731.530199698N2.5
7020731.970811611Y2.5
7020731.787460475N2.5
7020732.106870544Y2.5
7020731.447158031N2.5
7040712.317227349N2.5
7040712.039017322Y2.5
7040712.294466226Y2.5
7040712.276921132Y2.5
7040722.06483222N2.5
7040722.187802639Y2.5
7040722.267406419Y2.5
7040722.645520515Y2.5
7040721.906873535N2.5
7040731.536558443Y2.5
7040732.295347148Y2.5
7040731.671172843N2.5
7040732.118925753Y2.5
7040741.69019608N2.5
7040742.038620162N2.5
7040742.199480915Y2.5
7040741.999130541Y2.5
7040741.609594409N2.5
7040751.195899652N2.5
7040752.14113609Y2.5
7040752.032618761Y2.5
7040751.909556029Y2.5
7040751.336459734N2.5
7040751.59439255N2.5
7050731.717670503N2.5
7050732.141449773Y2.5
7050731.494154594N2.5
7050731.981818607Y2.5
7050732.292699003Y2.5
7050731.354108439N2.5
7050761.582063363N2.5
7050762.171433901Y2.5
7050761.645422269N2.5
5230721.852479994N8
5230722.324488233N8
5230721.941014244N8
5230721.465382851N8
5240712.605951158Y8
5240711.424881637N8
5240711.702430536Y8
5240722.407390904Y8
5240722.190051418Y8
5240722.326335861Y8
5240721.948901761N8
5240732.089198367Y8
5240732.562292864Y8
5240732.19893187Y8
5240732.466571072Y8
5240731.591064607N8
6040712.169380495Y8
6040712.692494408Y8
6040712.489817908Y8
6040712.390581879Y8
6040712.65571455Y8
6040721.86923172Y8
6040722.39707055Y8
6040722.110252917Y8
6040732.604226053Y8
6040732.322219295Y8
6040731.848804701Y8
6040740.995635195Y8
6040741.873901598N8
6040741.931966115N8
6040741.442479769N8
6040741.881384657N8
6040742.184975191Y8
6080711.843855423Y8
6080712.583652109Y8
6080711.978636948N8
6080712.557519232Y8
6080722.24723655Y8
6080722.348110068Y8
6080721.828015064Y8
6080722.069668097N8
6080732.338854746Y8
6080732.126456113N8
6080732.384353414Y8
6080731.723455672Y8
6260711.501059262Y8
6260712.020775488Y8
6260712.445915414Y8
6260711.399673721N8
6260722.571592383Y8
6260722.15136985Y8
6260731.71432976N8
6260732.248953615Y8
6260732.256958153Y8
6260732.358505911Y8
6260742.402089351Y8
6260741.829303773N8
6260741.751279104N8
6260741.963315511Y8
6260741.665580991N8
6260752.349471799Y8
6260752.259354927N8
6260751.911157609N8
6260751.721810615N8
6260752.276921132Y8
6260752.244029589Y8
6210752.100715087N55
6210752.220892249Y55
6210751.209515015N55
6210762.139879086Y55
6210761.804139432Y55
6210762.198106999N55
6210761.606381365Y55
6210761.894869657N55
6210761.746634199N55
6220711.710117365N55
6220711.925827575Y55
6220711.605305046N55
6220711.691081492N55
6220711.814913181N55
6220712.004321374N55
6220711.840733235N55
6220721.788168371Y55
6220722.35945602Y55
6220722.576686805Y55
6260762.055378331N55
6260761.10720997N55
6260761.994317153Y55
6260762.146748014Y55
6260761.421603927N55
6260761.374748346N55
6270711.064457989N55
6270711.981818607N55
6270711.445604203Y55
6270711.948901761Y55
6270712.118925753N55
6270711.996073654N55
6270711.08278537N55
6270712.370328008Y55
6270721.692846919Y55
6270722.320146286Y55
6270731.498310554Y55
6270731.728353782N55
6270732.229169703N55
6270731.79518459N55
6270732.75151005Y55
6270741.987666265N55
6270742.311329952Y55
6270741.830588669N55
6270742.215108581N55
6270742.237040791Y55
6270741.713490543Y55
7050712.181271772Y55
7050712.314709693Y55
7050711.563481085N55
7050711.859738566N55
7050711.892094603N55
7050722.705436047Y55
7050722.261262869Y55
7050721.506505032N55
7050721.810904281N55
7050721.563481085N55
7050721.960470778N55
7050722.394101302Y55
5210712.036628895Y340
5210712.220631019Y340
5210711.850646235Y340
5210711.978636948N340
5210711.602059991Y340
5210711.789580712N340
5210712.090610708Y340
5210710.903089987N340
5210711.915927212N340
5210712.278982117Y340
5210721.250420002Y340
5210721.875061263Y340
5210721.956648579Y340
5210721.127104798N340
5210721.049218023Y340
5210731.155336037N340
5210731.643452676N340
5210731.004321374N340
5210731.660865478N340
5210742.017867719N340
5210742.103119254Y340
5210741.779596491Y340
5210742.054995862Y340
5210741.017033339N340
5210741.365487985N340
5210742.046104787Y340
5210741.705863712N340
5210741.501059262N340
5210751.944482672Y340
5210751.586587305N340
5210751.243038049N340
5210751.994756945Y340
5210762.336259552Y340
5210762.499961866Y340
5210761.737192643Y340
5210762.490941205Y340
5210762.089198367N340
5210761.903089987Y340
6050732.701395269Y340
6050731.574031268N340
6050731.736396502Y340
6050731.103803721N340
6050732.04453976N340
6050731.547774705N340
6050741.722633923N340
6050742.017867719N340
6050742.126131407N340
6050742.329194415Y340
6050742.033021445Y340
6050742.299725154N340
6050742.269979677Y340
6050741.715167358N340
6050741.445604203N340
6050751.460897843N340
6280711.075546961N340
6280711.583198774N340
6280712.351989455Y340
6280712.248708736Y340
6280711.729974286N340
6290711.893761762N340
6290712.637689819Y340
6290711.227886705N340
6290722.038222638Y340
6290721.530199698N340
6290722.491081413Y340
6290732.047664195N340
6290731.740362689N340
6290731.910624405N340
6290732.515078675Y340
6290731.627365857N340
6210711.604226053N1965
6210712.264345507Y1965
6210712.062205809Y1965
6210721.555094449N1965
6210721.838219222N1965
6210732.477121255Y1965
6210732.36078269Y1965
6210732.243781916N1965
6210731.117271296N1965
6210741.376576957N1965
6210742.159567193Y1965
6210741.814913181N1965
6290742.142389466Y1965
6290742.354492601Y1965
6290741.829303773N1965
6290741.956648579N1965
6290742.359835482Y1965
6290742.258397804N1965
6290742.438858659N1965
6290752.412628521Y1965
6290752.149219113Y1965
6290752.11058971Y1965
6290752.403977964Y1965
6290751.783188691Y1965
6290752.712902125Y1965
6290761.29666519Y1965
6290761.450249108Y1965
6290762.1532049Y1965
6290761.826074803N1965
6290762.236285277N1965
6290762.168497484Y1965
6290761.614897216N1965
6290771.555094449N1965
6290771.866877814N1965
6290772.520352504Y1965
6290771.58546073N1965
6290771.685741739Y1965



From bbolker at gmail.com  Tue Nov 23 22:41:07 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 23 Nov 2010 16:41:07 -0500
Subject: [R-sig-ME] Dealing with Overdispersion in Count Data with Mixed
	Modeling
In-Reply-To: <1290547396l.516114l.0l@psu.edu>
References: <1288203635l.1032266l.0l@psu.edu>	<1288208508l.1511628l.0l@psu.edu>	<1288296451l.1032274l.0l@psu.edu>	<AANLkTikscT885QSAdhJHS=yyVeeN5LV4_Qj7JC2QfGoB@mail.gmail.com><4CC9E1C5.407	0106@gmail.com>
	<1288632521l.614426l.0l@psu.edu><4CCF6F03.80101@gmail.com>	<1289502674l.892954l.0l@psu.edu><4CDC4748.7060002@gmail.com>
	<1290547396l.516114l.0l@psu.edu>
Message-ID: <4CEC34F3.8000606@gmail.com>

  Quick answer: this is most often a symptom of overfitted models and/or
strongly correlated predictors.  Your intercepts and slopes are likely
to be strongly correlated, as are linear and quadratic terms, if the
means of your predictors are far from zero.

  A few quick things to try:
    * center (and possibly scale) your continuous predictors
    * use poly(covx,2) rather than (1+covx+I(covx^2) [I think this
should work for both fixed and random effects]
    * if covx and covz (or their effects) are likely to be correlated,
try substituting (1|LT)+(0+covx|LT)+(0+covz|LT) for the (1+covx+covz|LT)
term (this is a different, simpler, model but one that is likely to be
easier to fit -- if it works you can worry about returning to the more
complex model later).
    * if desperate/willing to invest quite a bit more time, try
simulating data from the model under a best-case scenario and see if you
can get it to work (and give the right answer) under those conditions.

  good luck
    Ben Bolker


On 11/23/2010 04:23 PM, David Stainbrook wrote:
> Ben,
> 
> I have updated both the version or R and the lme4 library, but receive
> error messages and no summary output for models with more than one
> covariate.
> [R version 2.12.0 (2010-10-15) and lme4_0.999375-37] 
> 
> 
> The two simple models I described before worked, but when I add another
> covariate or a squared term, it does not and I get warning messages.
> 
> These two worked:
> model_1<-lmer(Y~1 + (1|LT) + (1|Observation), data=df3, family=poisson)
> model_2<-lmer(Y~1 + (1+covx|LT) + (1|Observation) + covx, data=df3,
> family=poisson)
> 
> I get the following message: "Number of levels of a grouping factor for
> the random effects is *equal* to n, the number of observations." I don't
> get any warning messages and I get a summary output.
> 
> 
> 
> These fails to work:
> model_3<-lmer(Y~1 + (1+covx + I(covx^2)|LT) + (1|Observation) + covx +
> I(covx^2), data=df3, family=poisson)
> model_4<-lmer(Y~1 + (1+covx + covz |LT) + (1|Observation) + covx + covz,
> data=df3, family=poisson)
> 
> I get the same message but now with warning messages and no summary output:
> "Number of levels of a grouping factor for the random effects
> is *equal* to n, the number of observations
> Warning messages:
> 1: In mer_finalize(ans) :
>   Cholmod warning 'not positive definite' at
> file:../Cholesky/t_cholmod_rowfac.c, line 432
> 2: In mer_finalize(ans) :
>   Cholmod warning 'not positive definite' at
> file:../Cholesky/t_cholmod_rowfac.c, line 432
> 3: In mer_finalize(ans) :
>   Cholmod warning 'not positive definite' at
> file:../Cholesky/t_cholmod_rowfac.c, line 432
> 
>> summary(model_3)
> Error in asMethod(object) : matrix is not symmetric [1,2]"
> 
> Do you know why this is and do you know how I can get a summary output
> for more complex models?
> 
> Thanks,
> David
> 
> 
> 
> 
> 
> 
> 
> 
> On Thu, Nov 11, 2010 02:43 PM, *Ben Bolker <bbolker at gmail.com>* wrote:
> 
>     On 11/11/2010 02:11 PM, David Stainbrook wrote:
>     > Ben,
>     > 
>     > Putting aside the issues of model convergence, I would like to focus on
>     > the issue of how to deal with overdispersion in count data. Typically, a
>     > negative binomial or quasi-poisson model deals with overdispersion in
>     > situations where it is not appropriate to use Poisson. However, to my
>     > knowledge, lme4 does not allow multiple random effects using the
>     > negative binomial family 
> 
>       [correction: it doesn't implement negative binomial models at all,
>     although I believe that *in* principle this could be added by using an
>     additional 'k' parameter that controlled the mean-variance relationship,
>     in a way analogous to glm.nb() in the MASS package].
> 
>     and quasi-poisson has issues with the
>     > likelihood estimation. As you suggested in a previous email, and from
>     > the article at
>     >
>     <http://journals.cambridge.org/action/displayAbstract?fromPage=online&aid=82701
>     > <http://journals.cambridge.org/action/displayAbstract?fromPage=online&aid=82701>,
>     > translating the model to a lognormal-Poisson model by using an
>     > individual-level random variable and using family=poisson should deal
>     > with the overdispersion.
> 
>       Yes.
> 
>     > 
>     > I wanted to clarify what you meant by the individual level to make sure
>     > that I am doing it correctly. I already have a random intercept for each
>     > individual (1|LT), where LT=lowest tag number for each individual, to
>     > account for pseudoreplication. For the individual-level random variable
>     > to deal with overdispersion, did you mean adding (1|Observation), where
>     > Observation is a vector from 1 to the total number of observations or
>     > records in the dataset?
> 
>       yes, exactly.
> 
>     > 
>     > This is demonstrated here in a very simple model with no covariates:
>     > model_1<-lmer(Y~1 + (1|LT) + (1|Observation), data=df3, family=poisson)
>     > 
>     > and here with an additional covariate (covx) with both fixed and random
>     > effects:
>     > model_2<-lmer(Y~1 + (1+covx|LT) + (1|Observation) + covx, data=df3, 
>     > family=poisson)
>     > 
>     > Is this what you meant and is it coded correctly?
>     > 
>     > I tried this code with an older version of R and lme4, and it yielded an
>     > error and no summary data, but after updating both the version of R and
>     > the lme4 library, I received a warning "Number of levels of a grouping
>     > factor for the random effects is *equal* to n, the number of
>     > observations", but it yielded summary information that I took to be
>     > legitimate.
> 
>        That is what I would expect.
> 
>       Ben Bolker
> 
> 
>     > 
>     > Thanks for the help,
>     > 
>     > ..................................................................
>     > 
>     > David Stainbrook
>     > M.S. Graduate Research Assistant
>     > Pennsylvania Cooperative Fish & Wildlife Research Unit
>     > The Pennsylvania State University
>     > 
>     > ..................................................................
>     > 
>     > 
>     > On Mon, Nov 1, 2010 09:53 PM, *Ben Bolker <bbolker at gmail.com>* wrote:
>     > 
>     >       [cc'ing r-sig-mixed-models: it's best to keep sending replies back to
>     >     the list so they can be archived and others can read them, or offer input]
>     > 
>     >     On 10-11-01 01:28 PM, David Stainbrook wrote:
>     >     > Ben,
>     >     > 
>     >     > Thanks for your input. I read that article that you suggested and it
>     >     > appears they used SAS and Genstat to do their analysis. 
>     > 
>     >       Yes (although as I said at the time, I wouldn't actually trust the
>     >     methods that they used in Genstat for this problem.  I just think their
>     >     description of the problem is clear).
>     > 
>     >     > Is it possible
>     >     > to use the Poisson-lognormal model in R or translate the model to this
>     >     > using R and lmer? Another professor mentioned that I may be able to get
>     >     > it to work using a negative binomial model in SAS or ADModel Builder.
>     >     > What do you suggest?
>     > 
>     >       Yes, you can use the Poisson-lognormal in recent versions of lme4,
>     >     simply by including an individual-level random variable.  You may get
>     >     warnings.
>     >       You could indeed use a negative binomial model in SAS or AD Model
>     >     Builder (in ADMB you could also use the lognormal-Poisson model).
>     > 
>     >     > Do you have any idea why Doug allowed the lmer function to fit
>     >     > quasipoisson if he doesn't feel that the results will be reliable? I
>     >     > would have trusted my results and wouldn't have had any idea that they
>     >     > might have been unreliable if he had not said that.
>     > 
>     >       I believe he implemented it a while ago and his opinions have now
>     >     changed. (I agree that it might be a good idea to disable this
>     >     functionality.)
>     > 
>     >     > Also, do you have any idea how to increase both the default number of
>     >     > function evaluations and iterations with the control statement within
>     >     > the lmer model statement?
>     > 
>     >     ...,control=list(maxIter=2000,maxFN=3000),... should work.
>     > 
>     >        * you seem to be tackling a difficult problem.  I appreciate that
>     >     you're offering full details on your problem (full scripts and data),
>     >     but it's going to take someone else at least half an hour (and probably
>     >     quite a bit more) to get up to speed on what you're doing and what's not
>     >     working; unfortunately, that's more than most anyone has time for,
>     >     unless the problem happens to be something very close to their
>     >     interests. Unfortunately, you may well need to find local help for this
>     >     (your advisor? a friendly stats professor or graduate student?) - <I already exhausted those options, hence contacting you and Doug>
>     >       * it's possible, depending on the complexity of your model, that
>     >     you're simply trying to fit too complicated a model.  You do have a lot
>     >     of data points, but some of your covariates may be strongly correlated.
>     >     Have you tried:
>     >        - seeing if you can successfully fit a subset of the data points
>     >     (this could be faster, allowing you to debug quicker)?
>     >        - seeing if you can successfully fit a subset of the covariates, or
>     >     which covariates or combinations of covariates are problematic?
>     >        - seeing if you can successfully fit a non-mixed (GLM) model,
>     >     treating 'individual' as a fixed effect?
>     >        - simulating data, possibly in a simplified form, to see if you can
>     >     get the right answer when you know what it is?
>     >       * lme4 is quite finicky about convergence, on the philosophy that it's
>     >     better not to give an answer than to give a wrong one.
>     > 
>     >       R does have its advantages, but if you're up to working with SAS or AD
>     >     Model Builder I would recommend you also try those approaches -- see if
>     >     you run into the same problems.  But I would definitely try some of the
>     >     trouble-shooting strategies above, first.
>     > 
>     >       good luck,
>     >         Ben Bolker
>     > 
>     > 
>     >     > Thanks again,
>     >     > 
>     >     > David
>     > 
>     >     > 
>     >     > On Thu, Oct 28, 2010 04:49 PM, *Ben Bolker <bbolker at gmail.com>*
>     >     wrote:
>     >     > 
>     >     >        My advice would be to use an individual-level random variable
>     >     >     (translating to a lognormal-Poisson model, which is qualitatively
>     >     >     similar to a negative binomial) -- see e.g. Elston et al 2001 for
>     >     a
>     >     >     decent explanation, although you should not necessarily trust the
>     >     >     numeric methods they use ...
>     >     > 
>     >     >      [Elston, D. A., R. Moss, T. Boulinier, C. Arrowsmith, and X. Lambin.
>     >     >     2001. Analysis of Aggregation, a Worked Example: Numbers of Ticks on
>     >     Red
>     >     >     Grouse Chicks. Parasitology 122, no. 05: 563-569.
>     >     >     doi:10.1017/S0031182001007740.
>     >     >    
>     >     http://journals.cambridge.org/action/displayAbstract?fromPage=online&aid=82701.]
>     >     > 
>     >     > 
>     >     >       (Doug, thanks for the vote of confidence!)
>     >     > 
>     >     >       cheers
>     >     >         Ben
>     >     > 
>     >     > 
>     >     > 
>     >     > 
>     >     > 
>     > 
>     > 
>     > 
>     > 
> 
> 
> 
>



From bbolker at gmail.com  Tue Nov 23 23:07:59 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 23 Nov 2010 17:07:59 -0500
Subject: [R-sig-ME] lme4a build broken?
Message-ID: <4CEC3B3F.6000100@ufl.edu>

  Anyone else getting this?

Error in dyn.load(file, DLLpath = DLLpath, ...) :
  unable to load shared object
'/mnt/hgfs/bolker/Documents/R/i486-pc-linux-gnu-library/2.12/lme4a/libs/lme4a.so':

/mnt/hgfs/bolker/Documents/R/i486-pc-linux-gnu-library/2.12/lme4a/libs/lme4a.so:
undefined symbol: dtrtrs_

  Tried updating to bleeding-edge (SVN) Matrix, no luck.
  Given enough time I might be able to sort this out for myself, but any
hints would be appreciated.

> sessionInfo()
R version 2.12.0 (2010-10-15)
Platform: i486-pc-linux-gnu (32-bit)

locale:
 [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
 [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
 [5] LC_MONETARY=C             LC_MESSAGES=en_US.utf8
 [7] LC_PAPER=en_US.utf8       LC_NAME=C
 [9] LC_ADDRESS=C              LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

gcc (Ubuntu 4.4.3-4ubuntu5) 4.4.3
Copyright (C) 2009 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.



From pierces1 at msu.edu  Tue Nov 23 23:09:31 2010
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Tue, 23 Nov 2010 17:09:31 -0500
Subject: [R-sig-ME] P value value for a large number of degree of
	freedom in lmer
In-Reply-To: <4CEC1F8E.3010502@gmail.com>
References: <AANLkTim+13OU0K1oUVcv1N6d6K_Qq00HxvK6EprVO6w5@mail.gmail.com>	<EB95FF77-2DAF-4E6A-8EBA-6A2BE61E0236@auckland.ac.nz>	<AANLkTikVA-u-kAuNKYn8U5sxi8Sro8_fWah-SO3KKAdp@mail.gmail.com>	<AANLkTik5mgX+Hq7tXrwLj6vFShngGAWs+yn1Ld2gsJrh@mail.gmail.com>
	<4CEC1F8E.3010502@gmail.com>
Message-ID: <002201cb8b5b$1a7437e0$4f5ca7a0$@msu.edu>

I think maybe the focus here should be on the substantive interpretation of the actual model parameters. Let's assume for the moment some effect has a significant p-value: the key then is to actually understand what the corresponding coefficient tells the analyst about the strength of that effect on the outcome. In some cases it may be trivial in practical importance, even if it is statistically distinguishable from zero (i.e., has a significant p-value). Unless you understand the units of measurement and associated with each variable and you have some external reference for what constitutes an effect size that actually matters, you can't properly interpret the results. That reference must be informed by subject-matter knowledge about the phenomenon being studied and the context in which it occurs. 

For example, imagine that we have an effect showing us that, on average, 2 different groups of physicians have annual incomes that differ by $10/year and the corresponding effect is statistically significant (because we have a HUGE sample size). I should hope that the analyst would look at the size of that difference and recognize that it is absolutely trivial when compared to the actual average incomes for both kinds of physicians (perhaps on the order of $150,000/year). Heck, $10 is barely enough to buy 2 or 3 cups of coffee in places like Starbuck's. However if the difference was $10,000/year, then it might be worth saying it has some real practical significance in addition to statistical significance. 


Steven J. Pierce, Ph.D. 
Associate Director 
Center for Statistical Training & Consulting (CSTAT) 
Michigan State University 
178 Giltner Hall 
East Lansing, MI 48824 
E-mail: pierces1 at msu.edu 
Web: http://www.cstat.msu.edu 

-----Original Message-----
From: Ben Bolker [mailto:bbolker at gmail.com] 
Sent: Tuesday, November 23, 2010 3:10 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] P value value for a large number of degree of freedom in lmer


  What may be getting lost in this discussion is that in simple cases
(normally distributed data, balanced orthogonal designs etc. etc.) there
is at least a coherent *definition* of the p-value, which would involve
the upper (or extreme/two-sided) tail of the t distribution with the
appropriate degrees of freedom or an F distribution with equivalent
denominator df. [I was going to write that in this case it would be
g-1=31 degrees of freedom, but I actually realized (I think) that would
only be the df for determining an effect in the intercept or in other
factors that varied across groups.  Here I think you have something like
199,999 df left to make inferences on the slope, because it is assumed
*not* to vary across groups ...] The best thing to do (IMO) if you want
to use these approaches is to look at a classical textbook, find the
appropriate calculation for your design, and apply the df to the test
statistic by hand. (You can also try the problem in lme and see what it
guesses, although it may guess wrong.) In many, many cases (unbalanced,
GLMMs, crossed designs, R-side correlation structures, ...) a
universally accepted definition does not exist.
  I do agree with the previous posters that you should think hard about
what (if anything) the p-values mean in this case, though.  Suppose your
t-statistic was 100.  Does the difference between p=exp(-184) and
p=exp(-10011) mean anything?

> 2*pnorm(-abs(100),log.p=TRUE)
[1] -10011.05
> 2*pt(-abs(100),df=31,log.p=TRUE)
[1] -184.448


On 10-11-23 02:45 PM, Joshua Wiley wrote:
> Dear Arnaud,
> 
> Having a large amount of data *is* exactly what increases confidence
> in results.  A p-value is the probability of obtaining your results
> given the null hypothesis is true *in the population*.  If you have a
> lot of data, you have a lot of the population, and can more
> confidently say "this is what the population is or is note like".  The
> p-value is serving its purpose exactly as it was meant to, there is no
> need to "correct" or "alter" it.  The real question is, does anyone
> care about your effect?  Effect sizes are often a good way to get at
> the idea of is the effect meaningful, does it have practical
> significance, could an average person notice the difference?
> 
> Cheers,
> 
> Josh
> 
> On Tue, Nov 23, 2010 at 11:25 AM, Arnaud Mosnier <a.mosnier at gmail.com> wrote:
>> I agree but how to test that a significant result is not due to the amount
>> of data but by a real effect.
>> I though about subsetting my dataset and rerun the model X time to see if
>> the result still persist ... but you can also say that doing so I will
>> achieve to find a (small enough) size of subset at which I will not detect
>> the effect :-)
>> I also agree that the term "bias" was not correctly used ... but is there a
>> method to increase the confidence in those results ?
>>
>> cheers,
>>
>> Arnaud
>>
>> 2010/11/23 Rolf Turner <r.turner at auckland.ac.nz>
>>
>>>
>>> It is well known amongst statisticians that having a large enough data set
>>> will
>>> result in the rejection of *any* null hypothesis, i.e. will result in a
>>> small
>>> p-value.  There is no ``bias'' involved.
>>>
>>>        cheers,
>>>
>>>                Rolf Turner
>>>
>>> On 24/11/2010, at 4:06 AM, Arnaud Mosnier wrote:
>>>
>>>> Dear UseRs,
>>>>
>>>> I am using a database containing nearly 200 000 observations occurring in
>>> 33
>>>> groups.
>>>> With a model of the form ( y ~ x + (1|group) ) in lmer, my number of
>>> degree
>>>> of freedom is really large.
>>>> I am wondering if this large df have an impact on the p values, mainly if
>>>> this could conduct to consider the effect of a variable as significant
>>> while
>>>> it is not .
>>>> ... and if it is the case, does it exist a correction to apply on the
>>>> results to take into account that bias.
>>>>
>>>> thanks !
>>>>
>>>>       [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>
>>        [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 
>



From bvholbi at yahoo.com  Tue Nov 23 23:22:55 2010
From: bvholbi at yahoo.com (Beth Holbrook)
Date: Tue, 23 Nov 2010 14:22:55 -0800 (PST)
Subject: [R-sig-ME] lmer vs SAS results
Message-ID: <772204.55750.qm@web35303.mail.mud.yahoo.com>

When I posted the following question, my data was formatted incorrectly.  Here 
is the correct dataset:


Thanks,
Beth

522071 2.115943177 N 0.4 
522071 2.470557485 Y 0.4 
522072 1.902546779 Y 0.4 
522072 2.272769587 Y 0.4 
522073 1.985426474 Y 0.4 
522073 1.862131379 Y 0.4 
522073 2.275541688 Y 0.4 
522073 1.846337112 Y 0.4 
525071 2.314709693 Y 0.4 
525071 2.360025089 Y 0.4 
525071 2.344785123 Y 0.4 
525071 1.068185862 Y 0.4 
525071 2.540329475 Y 0.4 
525072 2.030599722 Y 0.4 
525072 1.848804701 Y 0.4 
525072 2.326540669 Y 0.4 
525073 2.186391216 Y 0.4 
525073 2.421603927 Y 0.4 
525073 2.381295623 Y 0.4 
525073 1.672097858 Y 0.4 
605076 1.844477176 Y 0.4 
605076 2.219060332 Y 0.4 
605076 2.518645524 Y 0.4 
605076 2.546419267 Y 0.4 
606071 2.153814864 Y 0.4 
606071 2.625106575 Y 0.4 
606071 2.369957607 Y 0.4 
606071 1.589949601 N 0.4 
606071 2.506505032 Y 0.4 
606072 1.439332694 N 0.4 
606072 1.822168079 Y 0.4 
622073 2.218010043 Y 0.4 
622073 2.299289334 Y 0.4 
622074 1.431363764 N 0.4 
622074 2.419955748 Y 0.4 
622075 2.227372442 Y 0.4 
622075 2.338057875 Y 0.4 
622076 1.643452676 N 0.4 
622076 2.260309946 Y 0.4 
622076 1.404833717 N 0.4 
622076 2.343802333 Y 0.4 
625071 2.366236124 Y 0.4 
625071 2.557867962 Y 0.4 
625071 2.452706227 Y 0.4 
625072 1.920645001 Y 0.4 
625072 1.967079734 Y 0.4 
625072 1.6599162 N 0.4 
625072 1.492760389 N 0.4 
625072 1.240549248 N 0.4 
625072 2.040206628 N 0.4 
625072 2.428134794 Y 0.4 
522074 1.860936621 Y 2.5 
522074 2.020361283 N 2.5 
522074 2.567731963 Y 2.5 
522075 1.599883072 N 2.5 
522076 1.350248018 N 2.5 
522076 2.288919606 Y 2.5 
522076 1.320146286 N 2.5 
523071 2.069668097 N 2.5 
523071 1.953759692 N 2.5 
523071 2.016197354 N 2.5 
523071 2.240549248 Y 2.5 
525074 1.620136055 N 2.5 
525074 2.160768562 N 2.5 
525074 1.498310554 N 2.5 
525074 2.431685345 N 2.5 
525075 1.855519156 N 2.5 
607071 2.357363031 Y 2.5 
607071 2.657629431 Y 2.5 
607071 2.302763708 Y 2.5 
607071 2.353723938 Y 2.5 
607071 2.584670384 Y 2.5 
607072 2.393224116 Y 2.5 
607072 1.722633923 N 2.5 
607072 1.830588669 N 2.5 
607072 1.812913357 Y 2.5 
607073 1.920645001 N 2.5 
607073 2.635081436 Y 2.5 
625073 1.859738566 N 2.5 
625073 2.418798291 Y 2.5 
625073 2.488550717 Y 2.5 
625073 2.084576278 Y 2.5 
625073 2.384353414 Y 2.5 
625073 2.489677292 Y 2.5 
625074 1.795880017 N 2.5 
625074 2.245265839 Y 2.5 
625074 2.068927612 Y 2.5 
625074 2.590841835 Y 2.5 
625074 2.5594278 Y 2.5 
625074 1.589949601 N 2.5 
625075 1.848189117 Y 2.5 
625075 1.816903839 N 2.5 
625075 1.613841822 N 2.5 
625075 2.536305872 Y 2.5 
625075 2.461948495 Y 2.5 
625075 2.456214155 Y 2.5 
625076 1.629409599 N 2.5 
625076 1.921686475 N 2.5 
625076 1.862727528 N 2.5 
625076 1.475671188 N 2.5 
702071 2.254064453 Y 2.5 
702071 2.137037455 Y 2.5 
702072 2.245759356 Y 2.5 
702072 1.773786445 N 2.5 
702072 2.639486489 Y 2.5 
702072 1.725094521 N 2.5 
702072 2.332842267 Y 2.5 
702072 1.854306042 Y 2.5 
702072 1.534026106 N 2.5 
702073 2.521268876 Y 2.5 
702073 2.176380692 Y 2.5 
702073 2.358125285 Y 2.5 
702073 1.530199698 N 2.5 
702073 1.970811611 Y 2.5 
702073 1.787460475 N 2.5 
702073 2.106870544 Y 2.5 
702073 1.447158031 N 2.5 
704071 2.317227349 N 2.5 
704071 2.039017322 Y 2.5 
704071 2.294466226 Y 2.5 
704071 2.276921132 Y 2.5 
704072 2.06483222 N 2.5 
704072 2.187802639 Y 2.5 
704072 2.267406419 Y 2.5 
704072 2.645520515 Y 2.5 
704072 1.906873535 N 2.5 
704073 1.536558443 Y 2.5 
704073 2.295347148 Y 2.5 
704073 1.671172843 N 2.5 
704073 2.118925753 Y 2.5 
704074 1.69019608 N 2.5 
704074 2.038620162 N 2.5 
704074 2.199480915 Y 2.5 
704074 1.999130541 Y 2.5 
704074 1.609594409 N 2.5 
704075 1.195899652 N 2.5 
704075 2.14113609 Y 2.5 
704075 2.032618761 Y 2.5 
704075 1.909556029 Y 2.5 
704075 1.336459734 N 2.5 
704075 1.59439255 N 2.5 
705073 1.717670503 N 2.5 
705073 2.141449773 Y 2.5 
705073 1.494154594 N 2.5 
705073 1.981818607 Y 2.5 
705073 2.292699003 Y 2.5 
705073 1.354108439 N 2.5 
705076 1.582063363 N 2.5 
705076 2.171433901 Y 2.5 
705076 1.645422269 N 2.5 
523072 1.852479994 N 8 
523072 2.324488233 N 8 
523072 1.941014244 N 8 
523072 1.465382851 N 8 
524071 2.605951158 Y 8 
524071 1.424881637 N 8 
524071 1.702430536 Y 8 
524072 2.407390904 Y 8 
524072 2.190051418 Y 8 
524072 2.326335861 Y 8 
524072 1.948901761 N 8 
524073 2.089198367 Y 8 
524073 2.562292864 Y 8 
524073 2.19893187 Y 8 
524073 2.466571072 Y 8 
524073 1.591064607 N 8 
604071 2.169380495 Y 8 
604071 2.692494408 Y 8 
604071 2.489817908 Y 8 
604071 2.390581879 Y 8 
604071 2.65571455 Y 8 
604072 1.86923172 Y 8 
604072 2.39707055 Y 8 
604072 2.110252917 Y 8 
604073 2.604226053 Y 8 
604073 2.322219295 Y 8 
604073 1.848804701 Y 8 
604074 0.995635195 Y 8 
604074 1.873901598 N 8 
604074 1.931966115 N 8 
604074 1.442479769 N 8 
604074 1.881384657 N 8 
604074 2.184975191 Y 8 
608071 1.843855423 Y 8 
608071 2.583652109 Y 8 
608071 1.978636948 N 8 
608071 2.557519232 Y 8 
608072 2.24723655 Y 8 
608072 2.348110068 Y 8 
608072 1.828015064 Y 8 
608072 2.069668097 N 8 
608073 2.338854746 Y 8 
608073 2.126456113 N 8 
608073 2.384353414 Y 8 
608073 1.723455672 Y 8 
626071 1.501059262 Y 8 
626071 2.020775488 Y 8 
626071 2.445915414 Y 8 
626071 1.399673721 N 8 
626072 2.571592383 Y 8 
626072 2.15136985 Y 8 
626073 1.71432976 N 8 
626073 2.248953615 Y 8 
626073 2.256958153 Y 8 
626073 2.358505911 Y 8 
626074 2.402089351 Y 8 
626074 1.829303773 N 8 
626074 1.751279104 N 8 
626074 1.963315511 Y 8 
626074 1.665580991 N 8 
626075 2.349471799 Y 8 
626075 2.259354927 N 8 
626075 1.911157609 N 8 
626075 1.721810615 N 8 
626075 2.276921132 Y 8 
626075 2.244029589 Y 8 
621075 2.100715087 N 55 
621075 2.220892249 Y 55 
621075 1.209515015 N 55 
621076 2.139879086 Y 55 
621076 1.804139432 Y 55 
621076 2.198106999 N 55 
621076 1.606381365 Y 55 
621076 1.894869657 N 55 
621076 1.746634199 N 55 
622071 1.710117365 N 55 
622071 1.925827575 Y 55 
622071 1.605305046 N 55 
622071 1.691081492 N 55 
622071 1.814913181 N 55 
622071 2.004321374 N 55 
622071 1.840733235 N 55 
622072 1.788168371 Y 55 
622072 2.35945602 Y 55 
622072 2.576686805 Y 55 
626076 2.055378331 N 55 
626076 1.10720997 N 55 
626076 1.994317153 Y 55 
626076 2.146748014 Y 55 
626076 1.421603927 N 55 
626076 1.374748346 N 55 
627071 1.064457989 N 55 
627071 1.981818607 N 55 
627071 1.445604203 Y 55 
627071 1.948901761 Y 55 
627071 2.118925753 N 55 
627071 1.996073654 N 55 
627071 1.08278537 N 55 
627071 2.370328008 Y 55 
627072 1.692846919 Y 55 
627072 2.320146286 Y 55 
627073 1.498310554 Y 55 
627073 1.728353782 N 55 
627073 2.229169703 N 55 
627073 1.79518459 N 55 
627073 2.75151005 Y 55 
627074 1.987666265 N 55 
627074 2.311329952 Y 55 
627074 1.830588669 N 55 
627074 2.215108581 N 55 
627074 2.237040791 Y 55 
627074 1.713490543 Y 55 
705071 2.181271772 Y 55 
705071 2.314709693 Y 55 
705071 1.563481085 N 55 
705071 1.859738566 N 55 
705071 1.892094603 N 55 
705072 2.705436047 Y 55 
705072 2.261262869 Y 55 
705072 1.506505032 N 55 
705072 1.810904281 N 55 
705072 1.563481085 N 55 
705072 1.960470778 N 55 
705072 2.394101302 Y 55 
521071 2.036628895 Y 340 
521071 2.220631019 Y 340 
521071 1.850646235 Y 340 
521071 1.978636948 N 340 
521071 1.602059991 Y 340 
521071 1.789580712 N 340 
521071 2.090610708 Y 340 
521071 0.903089987 N 340 
521071 1.915927212 N 340 
521071 2.278982117 Y 340 
521072 1.250420002 Y 340 
521072 1.875061263 Y 340 
521072 1.956648579 Y 340 
521072 1.127104798 N 340 
521072 1.049218023 Y 340 
521073 1.155336037 N 340 
521073 1.643452676 N 340 
521073 1.004321374 N 340 
521073 1.660865478 N 340 
521074 2.017867719 N 340 
521074 2.103119254 Y 340 
521074 1.779596491 Y 340 
521074 2.054995862 Y 340 
521074 1.017033339 N 340 
521074 1.365487985 N 340 
521074 2.046104787 Y 340 
521074 1.705863712 N 340 
521074 1.501059262 N 340 
521075 1.944482672 Y 340 
521075 1.586587305 N 340 
521075 1.243038049 N 340 
521075 1.994756945 Y 340 
521076 2.336259552 Y 340 
521076 2.499961866 Y 340 
521076 1.737192643 Y 340 
521076 2.490941205 Y 340 
521076 2.089198367 N 340 
521076 1.903089987 Y 340 
605073 2.701395269 Y 340 
605073 1.574031268 N 340 
605073 1.736396502 Y 340 
605073 1.103803721 N 340 
605073 2.04453976 N 340 
605073 1.547774705 N 340 
605074 1.722633923 N 340 
605074 2.017867719 N 340 
605074 2.126131407 N 340 
605074 2.329194415 Y 340 
605074 2.033021445 Y 340 
605074 2.299725154 N 340 
605074 2.269979677 Y 340 
605074 1.715167358 N 340 
605074 1.445604203 N 340 
605075 1.460897843 N 340 
628071 1.075546961 N 340 
628071 1.583198774 N 340 
628071 2.351989455 Y 340 
628071 2.248708736 Y 340 
628071 1.729974286 N 340 
629071 1.893761762 N 340 
629071 2.637689819 Y 340 
629071 1.227886705 N 340 
629072 2.038222638 Y 340 
629072 1.530199698 N 340 
629072 2.491081413 Y 340 
629073 2.047664195 N 340 
629073 1.740362689 N 340 
629073 1.910624405 N 340 
629073 2.515078675 Y 340 
629073 1.627365857 N 340 
621071 1.604226053 N 1965 
621071 2.264345507 Y 1965 
621071 2.062205809 Y 1965 
621072 1.555094449 N 1965 
621072 1.838219222 N 1965 
621073 2.477121255 Y 1965 
621073 2.36078269 Y 1965 
621073 2.243781916 N 1965 
621073 1.117271296 N 1965 
621074 1.376576957 N 1965 
621074 2.159567193 Y 1965 
621074 1.814913181 N 1965 
629074 2.142389466 Y 1965 
629074 2.354492601 Y 1965 
629074 1.829303773 N 1965 
629074 1.956648579 N 1965 
629074 2.359835482 Y 1965 
629074 2.258397804 N 1965 
629074 2.438858659 N 1965 
629075 2.412628521 Y 1965 
629075 2.149219113 Y 1965 
629075 2.11058971 Y 1965 
629075 2.403977964 Y 1965 
629075 1.783188691 Y 1965 
629075 2.712902125 Y 1965 
629076 1.29666519 Y 1965 
629076 1.450249108 Y 1965 
629076 2.1532049 Y 1965 
629076 1.826074803 N 1965 
629076 2.236285277 N 1965 
629076 2.168497484 Y 1965 
629076 1.614897216 N 1965 
629077 1.555094449 N 1965 
629077 1.866877814 N 1965 
629077 2.520352504 Y 1965 
629077 1.58546073 N 1965 
629077 1.685741739 Y 1965 



------------------------------

Message: 3
Date: Tue, 23 Nov 2010 13:11:16 -0800 (PST)

To: r-sig-mixed-models at r-project.org

Subject: [R-sig-ME] lmer vs SAS results
Message-ID: <346807.26639.qm at web35303.mail.mud.yahoo.com>
Content-Type: text/plain; charset=us-ascii

First, let me preface this by saying I am an ecology Ph.D. student, relatively 
new to R, and even more new to mixed models, so I apologize in advance for my 
limited knowledge on this topic. (Also, I need to apologize for the length of 
this email - but I wanted to be as specific as possible).

I posted a question a few weeks ago, and received many helpful responses, so I'm 


hoping you can help me again.  The statistician on my committee has assisted me 
in setting up my analysis design; however, he is receiving different results 
using SAS than I am using lmer.  I understand that the goal of lmer is not to 
replicate results of SAS; however, I am unable to move ahead with my 
dissertation until I can provide him with a satisfactory explanation for these 
differences (I no longer have access to SAS so I need to use R as my primary 
statistical software).

My analysis design is to run a mixed model to test for the effects of prey 
movement ("preyswimy.n") and light ("lightclass") on the reaction distance 
("logrxndist") of young lake trout.  The random effect is "trial" since I 
observed several responses to prey for the same fish during each trial.

Using the lme4 package, I set up the following:

> options(contrasts = c(factor = "contr.SAS", ordered = "contr.poly"))
> lightclass <- factor(Dataset$light)
> trial <- factor(Dataset$trial)
> model1 <-lmer(logrxndist~preyswimy.n * lightclass + (1|trial), Dataset, 
>REML=FALSE)
> model2 <-lmer(logrxndist~preyswimy.n + lightclass + (1|trial), Dataset, 
>REML=FALSE)
> model3 <-lmer(logrxndist~preyswimy.n + (1|trial), Dataset, REML=FALSE)

Based on the following results, I concluded that the most appropriate model was 
model3 where lightclass was omitted.

> anova(model1, model2, model3)
Data: Dataset
Models:
model3: logrxndist ~ preyswimy.n + (1 | trial)
model2: logrxndist ~ preyswimy.n + lightclass + (1 | trial)
model1: logrxndist ~ preyswimy.n * lightclass + (1 | trial)
       Df    AIC    BIC   logLik  Chisq Chi Df Pr(>Chisq)
model3  4 214.21 229.98 -103.103                        
model2  9 215.26 250.74  -98.628 8.9494      5     0.1111
model1 14 219.15 274.35  -95.575 6.1062      5     0.2960  



In SAS, the statistician on my committee used the following code:


model1: 
proc mixed data=holbrook.bethfull method=ml;
  class preyswimy.n trial light;
  model logrxndist = light | preyswimy.n /solution;
  random trial;
  run;

model2:
proc mixed data=holbrook.bethfull method=ml;
  class preyswimy.n trial light;
  model logrxndist = light  preyswimy.n / solution;
  random trial;
  run;


model3
proc mixed data=holbrook.bethfull method=ml;
  class preyswimy.n trial;
  model logrxndist = preyswimy.n / solution ;
  random trial;
  run;

His results are as follows:
    
               AIC    BIC    -2 Log Likelihood  
model1   216.7  251.1   188.7 
model2   213.3  235.4   195.3
model3   214.2  224.0   206.2                        

Based on these results, he concluded that model2 had the lowest AIC and light 
was significant.

The lmer and SAS fixed effect parameter estimates were similar for model1, 
model2, and model3 (see below).  The lmer and SAS variance estimates for the 
random effect were the same for model3 (when light was excluded).  However, the 
variance estimates for the random effect differed in model1 and in model2.  The 
lmer results suggest that there is no random effect of "trial" in these models. 
However, SAS results gave a larger variance estimate for the random effect of 
trial in model1 and model2.  Any ideas why that might be the case?  
    
model1 Random effects
Groups   Variance-lmerVariance-SAS  
trials    1.0305e-11 0.005385
Residual        9.6697e-02 0.09126

model1 Fixed effects
                            Estimate-lmer   Estimate-SAS
(Intercept)                 2.151398   2.1448
preyswimy.nN               -0.344458   -0.3386
lightclass0.4               0.056317   0.06450
lightclass2.5               0.104469   0.1108
lightclass8                 0.074183   0.07667
lightclass55               -0.043046  -0.03805
lightclass340              -0.074705   -0.06529
preyswimy.nN:lightclass0.4 -0.257426   -0.2651
preyswimy.nN:lightclass2.5 -0.179126  -0.1808
preyswimy.nN:lightclass8   -0.058160   -0.05099
preyswimy.nN:lightclass55  -0.007468   -0.00753
preyswimy.nN:lightclass340 -0.123571   -0.1413


model2 Random effects:
GroupsVariance-lmerVariance-SAS
trial8.3902e-120.004775
Residual9.8259e-02  0.09394

model2 Fixed effects:

               Estimate-lmerEstimate-SAS
(Intercept)     2.20135   2.1975
preyswimy.nY    -0.45319   -0.4507
lightclass0.4  -0.02280-0.01755
lightclass2.5   0.02251    0.02634
lightclass8     0.04108    0.04401
lightclass55   -0.03539   -0.03229
lightclass340  -0.13272    -0.1336



model3 Random effects:
GroupsVariance-lmerVariance-SAS
trial0.00769170.007692
Residual0.0939409  0.09394

model3 Fixed effects:
  Estimate-lmerEstimate-SAS
(Intercept)2.186092.1861
preyswimy.nN  -0.46016 -0.4602


Thank you for any insight that you can provide.  Below, I've also attached a 
copy of the data in case you would like to run it yourself.

Thanks again,
Beth

Beth Holbrook
Ph.D. Candidate
University of Minnesota


Dataset

triallogrxndistpreyswimy.nlight
5220712.115943177N0.4
5220712.470557485Y0.4
5220721.902546779Y0.4
5220722.272769587Y0.4
5220731.985426474Y0.4
5220731.862131379Y0.4
5220732.275541688Y0.4
5220731.846337112Y0.4
5250712.314709693Y0.4
5250712.360025089Y0.4
5250712.344785123Y0.4
5250711.068185862Y0.4
5250712.540329475Y0.4
5250722.030599722Y0.4
5250721.848804701Y0.4
5250722.326540669Y0.4
5250732.186391216Y0.4
5250732.421603927Y0.4
5250732.381295623Y0.4
5250731.672097858Y0.4
6050761.844477176Y0.4
6050762.219060332Y0.4
6050762.518645524Y0.4
6050762.546419267Y0.4
6060712.153814864Y0.4
6060712.625106575Y0.4
6060712.369957607Y0.4
6060711.589949601N0.4
6060712.506505032Y0.4
6060721.439332694N0.4
6060721.822168079Y0.4
6220732.218010043Y0.4
6220732.299289334Y0.4
6220741.431363764N0.4
6220742.419955748Y0.4
6220752.227372442Y0.4
6220752.338057875Y0.4
6220761.643452676N0.4
6220762.260309946Y0.4
6220761.404833717N0.4
6220762.343802333Y0.4
6250712.366236124Y0.4
6250712.557867962Y0.4
6250712.452706227Y0.4
6250721.920645001Y0.4
6250721.967079734Y0.4
6250721.6599162N0.4
6250721.492760389N0.4
6250721.240549248N0.4
6250722.040206628N0.4
6250722.428134794Y0.4
5220741.860936621Y2.5
5220742.020361283N2.5
5220742.567731963Y2.5
5220751.599883072N2.5
5220761.350248018N2.5
5220762.288919606Y2.5
5220761.320146286N2.5
5230712.069668097N2.5
5230711.953759692N2.5
5230712.016197354N2.5
5230712.240549248Y2.5
5250741.620136055N2.5
5250742.160768562N2.5
5250741.498310554N2.5
5250742.431685345N2.5
5250751.855519156N2.5
6070712.357363031Y2.5
6070712.657629431Y2.5
6070712.302763708Y2.5
6070712.353723938Y2.5
6070712.584670384Y2.5
6070722.393224116Y2.5
6070721.722633923N2.5
6070721.830588669N2.5
6070721.812913357Y2.5
6070731.920645001N2.5
6070732.635081436Y2.5
6250731.859738566N2.5
6250732.418798291Y2.5
6250732.488550717Y2.5
6250732.084576278Y2.5
6250732.384353414Y2.5
6250732.489677292Y2.5
6250741.795880017N2.5
6250742.245265839Y2.5
6250742.068927612Y2.5
6250742.590841835Y2.5
6250742.5594278Y2.5
6250741.589949601N2.5
6250751.848189117Y2.5
6250751.816903839N2.5
6250751.613841822N2.5
6250752.536305872Y2.5
6250752.461948495Y2.5
6250752.456214155Y2.5
6250761.629409599N2.5
6250761.921686475N2.5
6250761.862727528N2.5
6250761.475671188N2.5
7020712.254064453Y2.5
7020712.137037455Y2.5
7020722.245759356Y2.5
7020721.773786445N2.5
7020722.639486489Y2.5
7020721.725094521N2.5
7020722.332842267Y2.5
7020721.854306042Y2.5
7020721.534026106N2.5
7020732.521268876Y2.5
7020732.176380692Y2.5
7020732.358125285Y2.5
7020731.530199698N2.5
7020731.970811611Y2.5
7020731.787460475N2.5
7020732.106870544Y2.5
7020731.447158031N2.5
7040712.317227349N2.5
7040712.039017322Y2.5
7040712.294466226Y2.5
7040712.276921132Y2.5
7040722.06483222N2.5
7040722.187802639Y2.5
7040722.267406419Y2.5
7040722.645520515Y2.5
7040721.906873535N2.5
7040731.536558443Y2.5
7040732.295347148Y2.5
7040731.671172843N2.5
7040732.118925753Y2.5
7040741.69019608N2.5
7040742.038620162N2.5
7040742.199480915Y2.5
7040741.999130541Y2.5
7040741.609594409N2.5
7040751.195899652N2.5
7040752.14113609Y2.5
7040752.032618761Y2.5
7040751.909556029Y2.5
7040751.336459734N2.5
7040751.59439255N2.5
7050731.717670503N2.5
7050732.141449773Y2.5
7050731.494154594N2.5
7050731.981818607Y2.5
7050732.292699003Y2.5
7050731.354108439N2.5
7050761.582063363N2.5
7050762.171433901Y2.5
7050761.645422269N2.5
5230721.852479994N8
5230722.324488233N8
5230721.941014244N8
5230721.465382851N8
5240712.605951158Y8
5240711.424881637N8
5240711.702430536Y8
5240722.407390904Y8
5240722.190051418Y8
5240722.326335861Y8
5240721.948901761N8
5240732.089198367Y8
5240732.562292864Y8
5240732.19893187Y8
5240732.466571072Y8
5240731.591064607N8
6040712.169380495Y8
6040712.692494408Y8
6040712.489817908Y8
6040712.390581879Y8
6040712.65571455Y8
6040721.86923172Y8
6040722.39707055Y8
6040722.110252917Y8
6040732.604226053Y8
6040732.322219295Y8
6040731.848804701Y8
6040740.995635195Y8
6040741.873901598N8
6040741.931966115N8
6040741.442479769N8
6040741.881384657N8
6040742.184975191Y8
6080711.843855423Y8
6080712.583652109Y8
6080711.978636948N8
6080712.557519232Y8
6080722.24723655Y8
6080722.348110068Y8
6080721.828015064Y8
6080722.069668097N8
6080732.338854746Y8
6080732.126456113N8
6080732.384353414Y8
6080731.723455672Y8
6260711.501059262Y8
6260712.020775488Y8
6260712.445915414Y8
6260711.399673721N8
6260722.571592383Y8
6260722.15136985Y8
6260731.71432976N8
6260732.248953615Y8
6260732.256958153Y8
6260732.358505911Y8
6260742.402089351Y8
6260741.829303773N8
6260741.751279104N8
6260741.963315511Y8
6260741.665580991N8
6260752.349471799Y8
6260752.259354927N8
6260751.911157609N8
6260751.721810615N8
6260752.276921132Y8
6260752.244029589Y8
6210752.100715087N55
6210752.220892249Y55
6210751.209515015N55
6210762.139879086Y55
6210761.804139432Y55
6210762.198106999N55
6210761.606381365Y55
6210761.894869657N55
6210761.746634199N55
6220711.710117365N55
6220711.925827575Y55
6220711.605305046N55
6220711.691081492N55
6220711.814913181N55
6220712.004321374N55
6220711.840733235N55
6220721.788168371Y55
6220722.35945602Y55
6220722.576686805Y55
6260762.055378331N55
6260761.10720997N55
6260761.994317153Y55
6260762.146748014Y55
6260761.421603927N55
6260761.374748346N55
6270711.064457989N55
6270711.981818607N55
6270711.445604203Y55
6270711.948901761Y55
6270712.118925753N55
6270711.996073654N55
6270711.08278537N55
6270712.370328008Y55
6270721.692846919Y55
6270722.320146286Y55
6270731.498310554Y55
6270731.728353782N55
6270732.229169703N55
6270731.79518459N55
6270732.75151005Y55
6270741.987666265N55
6270742.311329952Y55
6270741.830588669N55
6270742.215108581N55
6270742.237040791Y55
6270741.713490543Y55
7050712.181271772Y55
7050712.314709693Y55
7050711.563481085N55
7050711.859738566N55
7050711.892094603N55
7050722.705436047Y55
7050722.261262869Y55
7050721.506505032N55
7050721.810904281N55
7050721.563481085N55
7050721.960470778N55
7050722.394101302Y55
5210712.036628895Y340
5210712.220631019Y340
5210711.850646235Y340
5210711.978636948N340
5210711.602059991Y340
5210711.789580712N340
5210712.090610708Y340
5210710.903089987N340
5210711.915927212N340
5210712.278982117Y340
5210721.250420002Y340
5210721.875061263Y340
5210721.956648579Y340
5210721.127104798N340
5210721.049218023Y340
5210731.155336037N340
5210731.643452676N340
5210731.004321374N340
5210731.660865478N340
5210742.017867719N340
5210742.103119254Y340
5210741.779596491Y340
5210742.054995862Y340
5210741.017033339N340
5210741.365487985N340
5210742.046104787Y340
5210741.705863712N340
5210741.501059262N340
5210751.944482672Y340
5210751.586587305N340
5210751.243038049N340
5210751.994756945Y340
5210762.336259552Y340
5210762.499961866Y340
5210761.737192643Y340
5210762.490941205Y340
5210762.089198367N340
5210761.903089987Y340
6050732.701395269Y340
6050731.574031268N340
6050731.736396502Y340
6050731.103803721N340
6050732.04453976N340
6050731.547774705N340
6050741.722633923N340
6050742.017867719N340
6050742.126131407N340
6050742.329194415Y340
6050742.033021445Y340
6050742.299725154N340
6050742.269979677Y340
6050741.715167358N340
6050741.445604203N340
6050751.460897843N340
6280711.075546961N340
6280711.583198774N340
6280712.351989455Y340
6280712.248708736Y340
6280711.729974286N340
6290711.893761762N340
6290712.637689819Y340
6290711.227886705N340
6290722.038222638Y340
6290721.530199698N340
6290722.491081413Y340
6290732.047664195N340
6290731.740362689N340
6290731.910624405N340
6290732.515078675Y340
6290731.627365857N340
6210711.604226053N1965
6210712.264345507Y1965
6210712.062205809Y1965
6210721.555094449N1965
6210721.838219222N1965
6210732.477121255Y1965
6210732.36078269Y1965
6210732.243781916N1965
6210731.117271296N1965
6210741.376576957N1965
6210742.159567193Y1965
6210741.814913181N1965
6290742.142389466Y1965
6290742.354492601Y1965
6290741.829303773N1965
6290741.956648579N1965
6290742.359835482Y1965
6290742.258397804N1965
6290742.438858659N1965
6290752.412628521Y1965
6290752.149219113Y1965
6290752.11058971Y1965
6290752.403977964Y1965
6290751.783188691Y1965
6290752.712902125Y1965
6290761.29666519Y1965
6290761.450249108Y1965
6290762.1532049Y1965
6290761.826074803N1965
6290762.236285277N1965
6290762.168497484Y1965
6290761.614897216N1965
6290771.555094449N1965
6290771.866877814N1965
6290772.520352504Y1965
6290771.58546073N1965
6290771.685741739Y1965



From doon75 at hotmail.com  Wed Nov 24 00:35:09 2010
From: doon75 at hotmail.com (Darren Norris)
Date: Tue, 23 Nov 2010 21:35:09 -0200
Subject: [R-sig-ME] lmer vs SAS results
Message-ID: <BLU0-SMTP202F5BE0C9182C882DE4F2EC73E0@phx.gbl>

Hi Beth,
I am sure other members will add their thoughts as to why the 
differences are occurring (I know how much they love such comparisons).
However, I just wanted to add that between 5 May 2008 and 20 September 
2010 there have been around 115 messages with "SAS" on this list.
I know it is hard but it could be worth looking through some of these 
previous posts.

Secondly your AIC values are not that different between any of the 3 
models. Are you expecting particularly strong support for one over any 
other?
You might be beating yourself up needlessly?

Members of this list have made and maintain several amazingly accessible 
packages and contributed time to the wiki ( http://glmm.wikidot.com/ ) 
etc....
The fact you are using this list and the packages to me suggests that 
you do not necessarily need the "help" of the statistician -
at least when it comes to mixed models....... oh did you think about 
using BIC (seems to "agree" pretty well.....).
Best wishes,
Darren



From baron at psych.upenn.edu  Wed Nov 24 01:09:58 2010
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Tue, 23 Nov 2010 19:09:58 -0500
Subject: [R-sig-ME] P value value for a large number of degree of
	freedom in lmer
In-Reply-To: <EB95FF77-2DAF-4E6A-8EBA-6A2BE61E0236@auckland.ac.nz>
References: <AANLkTim+13OU0K1oUVcv1N6d6K_Qq00HxvK6EprVO6w5@mail.gmail.com>
	<EB95FF77-2DAF-4E6A-8EBA-6A2BE61E0236@auckland.ac.nz>
Message-ID: <20101124000958.GA31594@psych.upenn.edu>

For the record, I have to register my disagreement.  In the
experimental sciences, the name of the game is to design a
well-controlled experiment, which means that the null hypothesis will
be true if the alternative hypothesis is false.  People who say what
is below, which includes almost everyone who responded to this post,
have something else in mind.  What they say is true in most
disciplines.  But when I hear this sort of thing, it is like someone
is telling me that my research career as an EXPERIMENTAL psychologist
has been some sort of delusion.

If you have a very large sample and you are doing a correlational
study, yes, everything will be significant.  But if you do the kind of
experiment we struggle to design, with perfect control conditions, you
won't get significant results (except by chance) if your hypothesis is
wrong.

Jon

On 11/24/10 07:59, Rolf Turner wrote:
> 
> It is well known amongst statisticians that having a large enough data set will
> result in the rejection of *any* null hypothesis, i.e. will result in a small
> p-value.  There is no ``bias'' involved.

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
Editor: Judgment and Decision Making (http://journal.sjdm.org)



From davidD at qimr.edu.au  Wed Nov 24 01:16:46 2010
From: davidD at qimr.edu.au (David Duffy)
Date: Wed, 24 Nov 2010 10:16:46 +1000 (EST)
Subject: [R-sig-ME] lmer vs SAS results
In-Reply-To: <346807.26639.qm@web35303.mail.mud.yahoo.com>
References: <mailman.5.1287655203.31036.r-sig-mixed-models@r-project.org>
	<346807.26639.qm@web35303.mail.mud.yahoo.com>
Message-ID: <Pine.LNX.4.64.1011240958360.5347@orpheus.qimr.edu.au>

On Tue, 23 Nov 2010, Beth Holbrook wrote:

lme4:
>       Df    AIC    BIC   logLik  Chisq Chi Df Pr(>Chisq)
> model3  4 214.21 229.98 -103.103
> model2  9 215.26 250.74  -98.628 8.9494      5     0.1111
> model1 14 219.15 274.35  -95.575 6.1062      5     0.2960
>
SAS:
>               AIC    BIC    -2 Log Likelihood
> model1   216.7  251.1   188.7
> model2   213.3  235.4   195.3
> model3   214.2  224.0   206.2
>

Well, SAS agrees with lme here (with method="ML"):

Model df      AIC      BIC     logLik   Test  L.Ratio p-value
m1    14 216.7262 271.9254  -94.36309 1 vs 2  6.59408  0.2526
m2     9 213.3203 248.8055  -97.66013 2 vs 3 10.88519  0.0537
m3     4 214.2055 229.9767 -103.10273

Directly maximizing the likelihood (using AS319), I get the
m2 v. m3 LRTS to be 10.8852.

I haven't evaluated likelihood at the lmer and SAS solutions yet, but 
obviously the likelihood surface will be fairly flat.

Cheers, David Duffy.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From r.turner at auckland.ac.nz  Wed Nov 24 01:25:15 2010
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 24 Nov 2010 13:25:15 +1300
Subject: [R-sig-ME] P value value for a large number of degree of
	freedom in lmer
In-Reply-To: <20101124000958.GA31594@psych.upenn.edu>
References: <AANLkTim+13OU0K1oUVcv1N6d6K_Qq00HxvK6EprVO6w5@mail.gmail.com>
	<EB95FF77-2DAF-4E6A-8EBA-6A2BE61E0236@auckland.ac.nz>
	<20101124000958.GA31594@psych.upenn.edu>
Message-ID: <BD42EE44-7BE4-4A1E-8879-17A295B5BD33@auckland.ac.nz>


On 24/11/2010, at 1:09 PM, Jonathan Baron wrote:

> For the record, I have to register my disagreement.  In the
> experimental sciences, the name of the game is to design a
> well-controlled experiment, which means that the null hypothesis will
> be true if the alternative hypothesis is false.  People who say what
> is below, which includes almost everyone who responded to this post,
> have something else in mind.  What they say is true in most
> disciplines.  But when I hear this sort of thing, it is like someone
> is telling me that my research career as an EXPERIMENTAL psychologist
> has been some sort of delusion.
> 
> If you have a very large sample and you are doing a correlational
> study, yes, everything will be significant.  But if you do the kind of
> experiment we struggle to design, with perfect control conditions, you
> won't get significant results (except by chance) if your hypothesis is
> wrong.
> 

	I'll bet you don't work with samples of size 200,000. :-)

	Also I'll bet that you don't ***really*** care if the
	difference between mu_T and mu_C is bigger than 0.000001 mm,
	say, whereas you might care if the difference were bigger than
	10 mm.

	Also there's no such thing as ``perfect'' anything, let alone
	control conditions.

		cheers,

			Rolf Turner

> Jon
> 
> On 11/24/10 07:59, Rolf Turner wrote:
>> 
>> It is well known amongst statisticians that having a large enough data set will
>> result in the rejection of *any* null hypothesis, i.e. will result in a small
>> p-value.  There is no ``bias'' involved.



From jwiley.psych at gmail.com  Wed Nov 24 01:51:47 2010
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Tue, 23 Nov 2010 16:51:47 -0800
Subject: [R-sig-ME] P value value for a large number of degree of
 freedom in lmer
In-Reply-To: <20101124000958.GA31594@psych.upenn.edu>
References: <AANLkTim+13OU0K1oUVcv1N6d6K_Qq00HxvK6EprVO6w5@mail.gmail.com>
	<EB95FF77-2DAF-4E6A-8EBA-6A2BE61E0236@auckland.ac.nz>
	<20101124000958.GA31594@psych.upenn.edu>
Message-ID: <AANLkTi=qWv+ZZm5vtbzUEuLfmrXB=CyxsvV+taehm-iX@mail.gmail.com>

On Tue, Nov 23, 2010 at 4:09 PM, Jonathan Baron <baron at psych.upenn.edu> wrote:
> For the record, I have to register my disagreement. ?In the
> experimental sciences, the name of the game is to design a
> well-controlled experiment, which means that the null hypothesis will
> be true if the alternative hypothesis is false. ?People who say what
> is below, which includes almost everyone who responded to this post,
> have something else in mind. ?What they say is true in most
> disciplines. ?But when I hear this sort of thing, it is like someone
> is telling me that my research career as an EXPERIMENTAL psychologist
> has been some sort of delusion.

I would not take it that way.  I agree there is a difference between
some arbitrary null of no difference and a well designed control, but
no matter what case, the null is a specific hypothesis.  Given a
continuous distribution, if you the probability of any constant
occurring to an infinite decimal place is infinitely small.  With only
100,000 observations:

> dt(.49, df = 10^5) - dt(.5, df = 10^5)
[1] 0.001747051

Your career as an experimental psychologist is not a delusion, null
hypothesis statistical testing is---even with a perfect control, we
set up an unrealistic hypothesis.  Now if we could set up the null as
an interval....

>
> If you have a very large sample and you are doing a correlational
> study, yes, everything will be significant. ?But if you do the kind of
> experiment we struggle to design, with perfect control conditions, you
> won't get significant results (except by chance) if your hypothesis is
> wrong.

I agree that this is typically a bigger problem for correlational
studies, but if it became practical to run well-controlled experiments
on millions of participants, I suspect p-values would be disregarded
awfully quickly.  Even then, the study was not pointless or a
delusion, that kind of precision lets you confidently talk about the
actual effect your treatment had compared to your well-designed
control, and would give any applied person or practitioner a great
guide what to expect if they implemented it in the field.

x <- rnorm(10^6, mean = 0)
y <- rnorm(10^6, mean = .01)
t.test(x, y, var.equal = TRUE)

Best regards,

Josh (fan of experiments, correlational studies, & psychology...not so
much of NHST, but you use what you have)



>
> Jon
>
> On 11/24/10 07:59, Rolf Turner wrote:
>>
>> It is well known amongst statisticians that having a large enough data set will
>> result in the rejection of *any* null hypothesis, i.e. will result in a small
>> p-value. ?There is no ``bias'' involved.
>
> --
> Jonathan Baron, Professor of Psychology, University of Pennsylvania
> Home page: http://www.sas.upenn.edu/~baron
> Editor: Judgment and Decision Making (http://journal.sjdm.org)
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
University of California, Los Angeles
http://www.joshuawiley.com/



From emptican at gmail.com  Wed Nov 24 02:28:27 2010
From: emptican at gmail.com (Steve Hong)
Date: Tue, 23 Nov 2010 19:28:27 -0600
Subject: [R-sig-ME] correlation test and Bonferroni
Message-ID: <AANLkTins4DoJHDb3Ypmt2Kx6PX-nbGxBXmWMSgEOK23Y@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101123/d26a91a7/attachment.pl>

From djmuser at gmail.com  Wed Nov 24 03:37:55 2010
From: djmuser at gmail.com (Dennis Murphy)
Date: Tue, 23 Nov 2010 18:37:55 -0800
Subject: [R-sig-ME] correlation test and Bonferroni
In-Reply-To: <AANLkTins4DoJHDb3Ypmt2Kx6PX-nbGxBXmWMSgEOK23Y@mail.gmail.com>
References: <AANLkTins4DoJHDb3Ypmt2Kx6PX-nbGxBXmWMSgEOK23Y@mail.gmail.com>
Message-ID: <AANLkTinRDC6B7JnN2ATUNu008_Vau+jPPehp42DAYPrR@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101123/f93a816f/attachment.pl>

From john.maindonald at anu.edu.au  Wed Nov 24 03:59:52 2010
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Wed, 24 Nov 2010 13:59:52 +1100
Subject: [R-sig-ME] P value value for a large number of degree
	of	freedom in lmer
In-Reply-To: <BD42EE44-7BE4-4A1E-8879-17A295B5BD33@auckland.ac.nz>
References: <AANLkTim+13OU0K1oUVcv1N6d6K_Qq00HxvK6EprVO6w5@mail.gmail.com>
	<EB95FF77-2DAF-4E6A-8EBA-6A2BE61E0236@auckland.ac.nz>
	<20101124000958.GA31594@psych.upenn.edu>
	<BD42EE44-7BE4-4A1E-8879-17A295B5BD33@auckland.ac.nz>
Message-ID: <B409B221-7022-4FA5-BE06-224FE96DE46F@anu.edu.au>

There are other considerations, which may often be more
serious.  In any observational dataset, there is almost
bound to be structure.  This arises in different areas in 
different ways, but some of the possibilities are:
1) a time element
2) a space element
3) a location or culture or group or family element
4) an effect from collection instrument or person.

So the correlation structure is not iid or even i, something
we might be expected to know about on this list.  The
correlations will often be positive.  Even after multi-level
or spatial models have been used to take out what is
thought to be the structure, there will often be structure 
left.  The consequence is that even quite substantial
effects may appear statistically significant, according to
the usual rituals.

There are other problems.  Some variables may be measured
very inaccurately.  Used on their own, this reduces the chances
of finding a significant effect, catastrophically if the error is of
the same order of magnitude as the SD of that variable.  
If other accurately measured explanatory variables are included
in the same analysis, they may appear falsely significant.  This
sort of issue has been extensively canvassed in connection
with the use of food frequency questionnaire (FFQ) measuring
instruments in large-scale studies of the effect of diet on disease.
See for example:
Schatzkin, A.; Kipnis, V.; Carroll, R.; Midthune, D.; Subar, A.; Bingham, S.; Schoeller, D.; Troiano, R.; and Freedman, L., 2003. A comparison of a food frequency ques- tionnaire with a 24-hour recall for use in an epidemiological cohort study: results from the biomarker-based observing protein and energy nutrition (open) study. International Journal of Epidemiology, 32:1054?1062.
Here was an instrument that many thought adequately accurate.

These problems may of course affect all observational studies.
Deficiencies in the data and in the modeling (because some
structure is not accounted for) become more likely to show up
as the modeling becomes more sensitive to smallish, but 
perhaps still consequential effects.

In modest sized experiments, careful design can largely
avoid such problems.  In experiments where the number
of subjects is very large, the same sorts of problems will
almost inevitably appear.  Minor deviations from the
protocol become almost impossible to avoid.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 24/11/2010, at 11:25 AM, Rolf Turner wrote:

> 
> On 24/11/2010, at 1:09 PM, Jonathan Baron wrote:
> 
>> For the record, I have to register my disagreement.  In the
>> experimental sciences, the name of the game is to design a
>> well-controlled experiment, which means that the null hypothesis will
>> be true if the alternative hypothesis is false.  People who say what
>> is below, which includes almost everyone who responded to this post,
>> have something else in mind.  What they say is true in most
>> disciplines.  But when I hear this sort of thing, it is like someone
>> is telling me that my research career as an EXPERIMENTAL psychologist
>> has been some sort of delusion.
>> 
>> If you have a very large sample and you are doing a correlational
>> study, yes, everything will be significant.  But if you do the kind of
>> experiment we struggle to design, with perfect control conditions, you
>> won't get significant results (except by chance) if your hypothesis is
>> wrong.
>> 
> 
> 	I'll bet you don't work with samples of size 200,000. :-)
> 
> 	Also I'll bet that you don't ***really*** care if the
> 	difference between mu_T and mu_C is bigger than 0.000001 mm,
> 	say, whereas you might care if the difference were bigger than
> 	10 mm.
> 
> 	Also there's no such thing as ``perfect'' anything, let alone
> 	control conditions.
> 
> 		cheers,
> 
> 			Rolf Turner
> 
>> Jon
>> 
>> On 11/24/10 07:59, Rolf Turner wrote:
>>> 
>>> It is well known amongst statisticians that having a large enough data set will
>>> result in the rejection of *any* null hypothesis, i.e. will result in a small
>>> p-value.  There is no ``bias'' involved.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From john.maindonald at anu.edu.au  Wed Nov 24 05:13:58 2010
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Wed, 24 Nov 2010 15:13:58 +1100
Subject: [R-sig-ME] P value value for a large number of degree
	of	freedom in lmer
In-Reply-To: <BD42EE44-7BE4-4A1E-8879-17A295B5BD33@auckland.ac.nz>
References: <AANLkTim+13OU0K1oUVcv1N6d6K_Qq00HxvK6EprVO6w5@mail.gmail.com>
	<EB95FF77-2DAF-4E6A-8EBA-6A2BE61E0236@auckland.ac.nz>
	<20101124000958.GA31594@psych.upenn.edu>
	<BD42EE44-7BE4-4A1E-8879-17A295B5BD33@auckland.ac.nz>
Message-ID: <289B5A37-6AD7-4E75-B1FC-0C100DB1618B@anu.edu.au>

I need to redraft the final sentence of the first paragraph,
to read: "The consequence is that effects that are well within
the bounds of statistical variation may, according to the
the usual rituals, appear statistically significant, "
----------------------------------------------------------------------------

There are other considerations, which may often be more
serious.  In any observational dataset, there is almost
bound to be structure.  This arises in different areas in 
different ways, but some of the possibilities are:
1) a time element
2) a space element
3) a location or culture or group or family element
4) an effect from collection instrument or person.

So the correlation structure is not iid or even i, something
we might be expected to know about on this list.  The
correlations will often be positive.  Even after multi-level
or spatial models have been used to take out what is
thought to be the structure, there will often be structure 
left.  The consequence is that effects that are well within
the bounds of statistical variation may, according to the
the usual rituals, appear statistically significant, 

There are other problems.  Some variables may be measured
very inaccurately.  Used on their own, this reduces the chances
of finding a significant effect, catastrophically if the error is of
the same order of magnitude as the SD of that variable.  
If other accurately measured explanatory variables are included
in the same analysis, they may appear falsely significant.  This
sort of issue has been extensively canvassed in connection
with the use of food frequency questionnaire (FFQ) measuring
instruments in large-scale studies of the effect of diet on disease.
See for example:
Schatzkin, A.; Kipnis, V.; Carroll, R.; Midthune, D.; Subar, A.; Bingham, S.; Schoeller, D.; Troiano, R.; and Freedman, L., 2003. A comparison of a food frequency ques- tionnaire with a 24-hour recall for use in an epidemiological cohort study: results from the biomarker-based observing protein and energy nutrition (open) study. International Journal of Epidemiology, 32:1054?1062.
Here was an instrument that many thought adequately accurate.

These problems may of course affect all observational studies.
Deficiencies in the data and in the modeling (because some
structure is not accounted for) become more likely to show up
as the modeling becomes more sensitive to smallish, but 
perhaps still consequential effects.

In modest sized experiments, careful design can largely
avoid such problems.  In experiments where the number
of subjects is very large, the same sorts of problems will
almost inevitably appear.  Minor deviations from the
protocol become almost impossible to avoid.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 24/11/2010, at 11:25 AM, Rolf Turner wrote:

> 
> On 24/11/2010, at 1:09 PM, Jonathan Baron wrote:
> 
>> For the record, I have to register my disagreement.  In the
>> experimental sciences, the name of the game is to design a
>> well-controlled experiment, which means that the null hypothesis will
>> be true if the alternative hypothesis is false.  People who say what
>> is below, which includes almost everyone who responded to this post,
>> have something else in mind.  What they say is true in most
>> disciplines.  But when I hear this sort of thing, it is like someone
>> is telling me that my research career as an EXPERIMENTAL psychologist
>> has been some sort of delusion.
>> 
>> If you have a very large sample and you are doing a correlational
>> study, yes, everything will be significant.  But if you do the kind of
>> experiment we struggle to design, with perfect control conditions, you
>> won't get significant results (except by chance) if your hypothesis is
>> wrong.
>> 
> 
> 	I'll bet you don't work with samples of size 200,000. :-)
> 
> 	Also I'll bet that you don't ***really*** care if the
> 	difference between mu_T and mu_C is bigger than 0.000001 mm,
> 	say, whereas you might care if the difference were bigger than
> 	10 mm.
> 
> 	Also there's no such thing as ``perfect'' anything, let alone
> 	control conditions.
> 
> 		cheers,
> 
> 			Rolf Turner
> 
>> Jon
>> 
>> On 11/24/10 07:59, Rolf Turner wrote:
>>> 
>>> It is well known amongst statisticians that having a large enough data set will
>>> result in the rejection of *any* null hypothesis, i.e. will result in a small
>>> p-value.  There is no ``bias'' involved.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From tliglesias at ucdavis.edu  Wed Nov 24 08:12:57 2010
From: tliglesias at ucdavis.edu (Teresa Iglesias)
Date: Wed, 24 Nov 2010 01:12:57 -0600
Subject: [R-sig-ME] eager for Gamma capability in lme4
Message-ID: <AANLkTik+cavJcKaNZ+CNxdg=gAVsh1EvZiVqx+G1AB4-@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101124/c341da47/attachment.pl>

From javier.martinez at um.es  Wed Nov 24 12:04:55 2010
From: javier.martinez at um.es (Javier Martinez Lopez)
Date: Wed, 24 Nov 2010 12:04:55 +0100
Subject: [R-sig-ME] Validation of mixed model for nested data
Message-ID: <AANLkTimAmcn6HBS2EcZG1-GTBXqj5HHyzsz7EGEr3DCK@mail.gmail.com>

Dear list members,

I am performing mixed models to relate the axes of a correspondence analysis
of environmental variables and the axes of a multidimensional scaling
analysis based on species frequencies. I am using mixed models (function
'lme') because I have a temporal data set at 8 different sites, containing
only two dates per site, so that site is a random effect for the model, MDS
axe is the dependent variable and the environmental variables axe is the
fixed factor (random intercepts model ). As a result, I get the following
model and graph, which I attach hereby. The residuals graphs look OK. The
question is whether such model is meaningful taking into account that there
are only two points per group and each site has a very different intercept.
Could I even try a random slopes and intercepts model? My goal is to test
whether there is a general relationship between the environmental and
biological variables, not to predict it. Besides, is there a way of looking
for a goodness of fit for my model?

Thank you for any advice,

Javier
-------------- next part --------------
A non-text attachment was scrubbed...
Name: lme_mds2_cu1.png
Type: image/png
Size: 8260 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101124/8a7b8466/attachment.png>

From a.s.wade at reading.ac.uk  Wed Nov 24 13:29:26 2010
From: a.s.wade at reading.ac.uk (Amy Wade)
Date: Wed, 24 Nov 2010 12:29:26 -0000
Subject: [R-sig-ME] lmer predicted and fitted values differ
Message-ID: <000001cb8bd3$3bd0efa0$b372cee0$@s.wade@reading.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101124/8a9583e1/attachment.pl>

From Thierry.ONKELINX at inbo.be  Wed Nov 24 13:46:55 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 24 Nov 2010 13:46:55 +0100
Subject: [R-sig-ME] lmer predicted and fitted values differ
In-Reply-To: <000001cb8bd3$3bd0efa0$b372cee0$@s.wade@reading.ac.uk>
References: <000001cb8bd3$3bd0efa0$b372cee0$@s.wade@reading.ac.uk>
Message-ID: <3DB16098F738284D8DBEB2FC369916384D66C3@inboexch.inbo.be>

Dear Amy,

The functions that you used take only the fixed effects into account.
While fitted() takes both the fixed and the random effects into account.

What do you want to predict? The 'average' data (all random effect
levels = 0)? Data for existing levels of the random effects? Data for
new levels of the random effects?

Best regards,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Amy Wade
> Verzonden: woensdag 24 november 2010 13:29
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] lmer predicted and fitted values differ
> 
> Hello,
> 
>  
> 
> I am trying to predict response values for a model with new, 
> unmeasured parameter values. It is an lmer model constructed 
> using the lme4 package. I realise there is not a 
> 'predict.lmer()' function or similar for lmer models.
> Having searched on the internet I found 3 possible methods 
> for calculating predicted values given unmeasured values for 
> a given parameter in the model.
> 
> 
>  
> 
> This is my model:
> 
> data.m2<-data.frame(pods.bind,FUNGICIDE,N.TENTS,Day,HUMIDITY,P
> LOT,TREE)
> #where 'pods.bind' is cbind(Black.pods,healthy.pods)
> 
> m2<-lmer(pods.bind~FUNGICIDE+N.TENTS*Day+HUMIDITY*Day+(1|PLOT/
> TREE),family="
> quasibinomial")
> 
>  
> 
>  
> 
> Here are the possible methods:
> 
> #1
> 
> mm = model.matrix(terms(m2),data.m2)
> 
> data.m2$pods.bind = mm %*% fixef(m2)
> 
> predicted.1<-exp(data.m2$pods.bind)/(1+exp(data.m2$pods.bind))
> 
>  
> 
> #2
> 
> predict.lmerBin <- function(object, X){
> 
> if(missing(X))
> 
> X <- object at X
> 
> b <- fixef(object)
> 
> plogis(X %*% b)
> 
> }
> 
> predicted.2<-predict.lmerBin(m2)
> 
>  
> 
> #3
> 
> predicted.3<-exp(model.matrix(terms(m2),data.m2)%*%fixef(m2))
> 
>  
> 
>  
> 
> All three methods result in exactly the same predicted 
> values. However, when I plug in the real data I get different 
> values than I do for fitted(). This makes me doubt the 
> validity of my predicted values. Could anybody explain why 
> the predicted values, using these methods, differ from the 
> fitted values? 
> 
>  
> 
> Thanks for your help.
> 
>  
> 
> Amy
> 
>  
> 
> ..............................................................
> ..............
> ...............
> 
> Amy S. I. Wade
> 
> Centre for Agri-Environmental Research
> 
> University of Reading
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 



From a.s.wade at reading.ac.uk  Wed Nov 24 14:44:06 2010
From: a.s.wade at reading.ac.uk (Amy Wade)
Date: Wed, 24 Nov 2010 13:44:06 -0000
Subject: [R-sig-ME] lmer predicted and fitted values differ
In-Reply-To: <3DB16098F738284D8DBEB2FC369916384D66C3@inboexch.inbo.be>
References: <000001cb8bd3$3bd0efa0$b372cee0$@s.wade@reading.ac.uk>
	<3DB16098F738284D8DBEB2FC369916384D66C3@inboexch.inbo.be>
Message-ID: <000501cb8bdd$aa102850$fe3078f0$@s.wade@reading.ac.uk>

Theirry,

Thanks for that clarification. I would like to predict data for the existing
levels of the random effects.


Many thanks,
Amy

P.S. not sure how to continue a thread - hope this works....





.......................................
Amy S. I. Wade
Centre for Agri-Environmental Research
University of Reading





-----Original Message-----
From: ONKELINX, Thierry [mailto:Thierry.ONKELINX at inbo.be] 
Sent: 24 November 2010 12:47
To: Amy Wade; r-sig-mixed-models at r-project.org
Subject: RE: [R-sig-ME] lmer predicted and fitted values differ

Dear Amy,

The functions that you used take only the fixed effects into account.
While fitted() takes both the fixed and the random effects into account.

What do you want to predict? The 'average' data (all random effect
levels = 0)? Data for existing levels of the random effects? Data for
new levels of the random effects?

Best regards,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Amy Wade
> Verzonden: woensdag 24 november 2010 13:29
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] lmer predicted and fitted values differ
> 
> Hello,
> 
>  
> 
> I am trying to predict response values for a model with new, 
> unmeasured parameter values. It is an lmer model constructed 
> using the lme4 package. I realise there is not a 
> 'predict.lmer()' function or similar for lmer models.
> Having searched on the internet I found 3 possible methods 
> for calculating predicted values given unmeasured values for 
> a given parameter in the model.
> 
> 
>  
> 
> This is my model:
> 
> data.m2<-data.frame(pods.bind,FUNGICIDE,N.TENTS,Day,HUMIDITY,P
> LOT,TREE)
> #where 'pods.bind' is cbind(Black.pods,healthy.pods)
> 
> m2<-lmer(pods.bind~FUNGICIDE+N.TENTS*Day+HUMIDITY*Day+(1|PLOT/
> TREE),family="
> quasibinomial")
> 
>  
> 
>  
> 
> Here are the possible methods:
> 
> #1
> 
> mm = model.matrix(terms(m2),data.m2)
> 
> data.m2$pods.bind = mm %*% fixef(m2)
> 
> predicted.1<-exp(data.m2$pods.bind)/(1+exp(data.m2$pods.bind))
> 
>  
> 
> #2
> 
> predict.lmerBin <- function(object, X){
> 
> if(missing(X))
> 
> X <- object at X
> 
> b <- fixef(object)
> 
> plogis(X %*% b)
> 
> }
> 
> predicted.2<-predict.lmerBin(m2)
> 
>  
> 
> #3
> 
> predicted.3<-exp(model.matrix(terms(m2),data.m2)%*%fixef(m2))
> 
>  
> 
>  
> 
> All three methods result in exactly the same predicted 
> values. However, when I plug in the real data I get different 
> values than I do for fitted(). This makes me doubt the 
> validity of my predicted values. Could anybody explain why 
> the predicted values, using these methods, differ from the 
> fitted values? 
> 
>  
> 
> Thanks for your help.
> 
>  
> 
> Amy
> 
>  
> 
> ..............................................................
> ..............
> ...............
> 
> Amy S. I. Wade
> 
> Centre for Agri-Environmental Research
> 
> University of Reading
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From Thierry.ONKELINX at inbo.be  Wed Nov 24 15:15:59 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 24 Nov 2010 15:15:59 +0100
Subject: [R-sig-ME] lmer predicted and fitted values differ
In-Reply-To: <000501cb8bdd$aa102850$fe3078f0$@s.wade@reading.ac.uk>
References: <000001cb8bd3$3bd0efa0$b372cee0$@s.wade@reading.ac.uk>
	<3DB16098F738284D8DBEB2FC369916384D66C3@inboexch.inbo.be>
	<000501cb8bdd$aa102850$fe3078f0$@s.wade@reading.ac.uk>
Message-ID: <3DB16098F738284D8DBEB2FC3699163850DDA7@inboexch.inbo.be>

Dear Amy,

Here is a solution. It should work with nested random effects. Untested
with random slopes and crossed random effects.

Best regards,

Thierry

library(lme4)
cbpp$Obs <- factor(seq_len(nrow(cbpp)))
(gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 |
herd/Obs), family = binomial, data = cbpp))
str(gm1)

predict.lmerBin <- function(object, X, Zt){
	if(missing(X)){
		X <- object at X
	}
	b <- fixef(object)
	if(missing(Zt)){
		Zt <- as.matrix(object at Zt)
	}
	z <- unlist(ranef(object))
	plogis(X %*% b + t(Zt) %*% z)
}

all.equal(as.vector(predict.lmerBin(gm1)), fitted(gm1))

PS Replying to all should keep the thread intact.

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: Amy Wade [mailto:a.s.wade at reading.ac.uk] 
> Verzonden: woensdag 24 november 2010 14:44
> Aan: ONKELINX, Thierry; r-sig-mixed-models at r-project.org
> Onderwerp: lmer predicted and fitted values differ
> 
> Theirry,
> 
> Thanks for that clarification. I would like to predict data 
> for the existing levels of the random effects.
> 
> 
> Many thanks,
> Amy
> 
> P.S. not sure how to continue a thread - hope this works....
> 
> 
> 
> 
> 
> .......................................
> Amy S. I. Wade
> Centre for Agri-Environmental Research
> University of Reading
> 
> 
> 
> 
> 
> -----Original Message-----
> From: ONKELINX, Thierry [mailto:Thierry.ONKELINX at inbo.be]
> Sent: 24 November 2010 12:47
> To: Amy Wade; r-sig-mixed-models at r-project.org
> Subject: RE: [R-sig-ME] lmer predicted and fitted values differ
> 
> Dear Amy,
> 
> The functions that you used take only the fixed effects into account.
> While fitted() takes both the fixed and the random effects 
> into account.
> 
> What do you want to predict? The 'average' data (all random 
> effect levels = 0)? Data for existing levels of the random 
> effects? Data for new levels of the random effects?
> 
> Best regards,
> 
> Thierry
> 
> --------------------------------------------------------------
> ----------
> ----
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek
> team Biometrie & Kwaliteitszorg
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
> 
> Research Institute for Nature and Forest team Biometrics & 
> Quality Assurance Gaverstraat 4 9500 Geraardsbergen Belgium
> 
> tel. + 32 54/436 185
> Thierry.Onkelinx at inbo.be
> www.inbo.be
> 
> To call in the statistician after the experiment is done may 
> be no more than asking him to perform a post-mortem 
> examination: he may be able to say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
> 
> The plural of anecdote is not data.
> ~ Roger Brinner
> 
> The combination of some data and an aching desire for an 
> answer does not ensure that a reasonable answer can be 
> extracted from a given body of data.
> ~ John Tukey
>   
> 
> > -----Oorspronkelijk bericht-----
> > Van: r-sig-mixed-models-bounces at r-project.org
> > [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Amy Wade
> > Verzonden: woensdag 24 november 2010 13:29
> > Aan: r-sig-mixed-models at r-project.org
> > Onderwerp: [R-sig-ME] lmer predicted and fitted values differ
> > 
> > Hello,
> > 
> >  
> > 
> > I am trying to predict response values for a model with new, 
> > unmeasured parameter values. It is an lmer model 
> constructed using the 
> > lme4 package. I realise there is not a 'predict.lmer()' function or 
> > similar for lmer models.
> > Having searched on the internet I found 3 possible methods for 
> > calculating predicted values given unmeasured values for a given 
> > parameter in the model.
> > 
> > 
> >  
> > 
> > This is my model:
> > 
> > data.m2<-data.frame(pods.bind,FUNGICIDE,N.TENTS,Day,HUMIDITY,P
> > LOT,TREE)
> > #where 'pods.bind' is cbind(Black.pods,healthy.pods)
> > 
> > m2<-lmer(pods.bind~FUNGICIDE+N.TENTS*Day+HUMIDITY*Day+(1|PLOT/
> > TREE),family="
> > quasibinomial")
> > 
> >  
> > 
> >  
> > 
> > Here are the possible methods:
> > 
> > #1
> > 
> > mm = model.matrix(terms(m2),data.m2)
> > 
> > data.m2$pods.bind = mm %*% fixef(m2)
> > 
> > predicted.1<-exp(data.m2$pods.bind)/(1+exp(data.m2$pods.bind))
> > 
> >  
> > 
> > #2
> > 
> > predict.lmerBin <- function(object, X){
> > 
> > if(missing(X))
> > 
> > X <- object at X
> > 
> > b <- fixef(object)
> > 
> > plogis(X %*% b)
> > 
> > }
> > 
> > predicted.2<-predict.lmerBin(m2)
> > 
> >  
> > 
> > #3
> > 
> > predicted.3<-exp(model.matrix(terms(m2),data.m2)%*%fixef(m2))
> > 
> >  
> > 
> >  
> > 
> > All three methods result in exactly the same predicted values. 
> > However, when I plug in the real data I get different 
> values than I do 
> > for fitted(). This makes me doubt the validity of my 
> predicted values. 
> > Could anybody explain why the predicted values, using these 
> methods, 
> > differ from the fitted values?
> > 
> >  
> > 
> > Thanks for your help.
> > 
> >  
> > 
> > Amy
> > 
> >  
> > 
> > ..............................................................
> > ..............
> > ...............
> > 
> > Amy S. I. Wade
> > 
> > Centre for Agri-Environmental Research
> > 
> > University of Reading
> > 
> >  
> > 
> > 
> > 	[[alternative HTML version deleted]]
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > 
> 
> 



From a.s.wade at reading.ac.uk  Wed Nov 24 17:56:39 2010
From: a.s.wade at reading.ac.uk (Amy Wade)
Date: Wed, 24 Nov 2010 16:56:39 -0000
Subject: [R-sig-ME] lmer predicted and fitted values differ
In-Reply-To: <3DB16098F738284D8DBEB2FC3699163850DDA7@inboexch.inbo.be>
References: <000001cb8bd3$3bd0efa0$b372cee0$@s.wade@reading.ac.uk>
	<3DB16098F738284D8DBEB2FC369916384D66C3@inboexch.inbo.be>
	<000501cb8bdd$aa102850$fe3078f0$@s.wade@reading.ac.uk>
	<3DB16098F738284D8DBEB2FC3699163850DDA7@inboexch.inbo.be>
Message-ID: <000901cb8bf8$9079c200$b16d4600$@s.wade@reading.ac.uk>

Thierry,

Your function did exactly what I wanted. Very much appreciated.

All the best,
Amy


.....................................................
Amy S. I. Wade
Centre for Agri-Environmental Research
University of Reading




-----Original Message-----
From: ONKELINX, Thierry [mailto:Thierry.ONKELINX at inbo.be] 
Sent: 24 November 2010 14:16
To: Amy Wade; r-sig-mixed-models at r-project.org
Subject: RE: lmer predicted and fitted values differ

Dear Amy,

Here is a solution. It should work with nested random effects. Untested
with random slopes and crossed random effects.

Best regards,

Thierry

library(lme4)
cbpp$Obs <- factor(seq_len(nrow(cbpp)))
(gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 |
herd/Obs), family = binomial, data = cbpp))
str(gm1)

predict.lmerBin <- function(object, X, Zt){
	if(missing(X)){
		X <- object at X
	}
	b <- fixef(object)
	if(missing(Zt)){
		Zt <- as.matrix(object at Zt)
	}
	z <- unlist(ranef(object))
	plogis(X %*% b + t(Zt) %*% z)
}

all.equal(as.vector(predict.lmerBin(gm1)), fitted(gm1))

PS Replying to all should keep the thread intact.

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: Amy Wade [mailto:a.s.wade at reading.ac.uk] 
> Verzonden: woensdag 24 november 2010 14:44
> Aan: ONKELINX, Thierry; r-sig-mixed-models at r-project.org
> Onderwerp: lmer predicted and fitted values differ
> 
> Theirry,
> 
> Thanks for that clarification. I would like to predict data 
> for the existing levels of the random effects.
> 
> 
> Many thanks,
> Amy
> 
> P.S. not sure how to continue a thread - hope this works....
> 
> 
> 
> 
> 
> .......................................
> Amy S. I. Wade
> Centre for Agri-Environmental Research
> University of Reading
> 
> 
> 
> 
> 
> -----Original Message-----
> From: ONKELINX, Thierry [mailto:Thierry.ONKELINX at inbo.be]
> Sent: 24 November 2010 12:47
> To: Amy Wade; r-sig-mixed-models at r-project.org
> Subject: RE: [R-sig-ME] lmer predicted and fitted values differ
> 
> Dear Amy,
> 
> The functions that you used take only the fixed effects into account.
> While fitted() takes both the fixed and the random effects 
> into account.
> 
> What do you want to predict? The 'average' data (all random 
> effect levels = 0)? Data for existing levels of the random 
> effects? Data for new levels of the random effects?
> 
> Best regards,
> 
> Thierry
> 
> --------------------------------------------------------------
> ----------
> ----
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek
> team Biometrie & Kwaliteitszorg
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
> 
> Research Institute for Nature and Forest team Biometrics & 
> Quality Assurance Gaverstraat 4 9500 Geraardsbergen Belgium
> 
> tel. + 32 54/436 185
> Thierry.Onkelinx at inbo.be
> www.inbo.be
> 
> To call in the statistician after the experiment is done may 
> be no more than asking him to perform a post-mortem 
> examination: he may be able to say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
> 
> The plural of anecdote is not data.
> ~ Roger Brinner
> 
> The combination of some data and an aching desire for an 
> answer does not ensure that a reasonable answer can be 
> extracted from a given body of data.
> ~ John Tukey
>   
> 
> > -----Oorspronkelijk bericht-----
> > Van: r-sig-mixed-models-bounces at r-project.org
> > [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Amy Wade
> > Verzonden: woensdag 24 november 2010 13:29
> > Aan: r-sig-mixed-models at r-project.org
> > Onderwerp: [R-sig-ME] lmer predicted and fitted values differ
> > 
> > Hello,
> > 
> >  
> > 
> > I am trying to predict response values for a model with new, 
> > unmeasured parameter values. It is an lmer model 
> constructed using the 
> > lme4 package. I realise there is not a 'predict.lmer()' function or 
> > similar for lmer models.
> > Having searched on the internet I found 3 possible methods for 
> > calculating predicted values given unmeasured values for a given 
> > parameter in the model.
> > 
> > 
> >  
> > 
> > This is my model:
> > 
> > data.m2<-data.frame(pods.bind,FUNGICIDE,N.TENTS,Day,HUMIDITY,P
> > LOT,TREE)
> > #where 'pods.bind' is cbind(Black.pods,healthy.pods)
> > 
> > m2<-lmer(pods.bind~FUNGICIDE+N.TENTS*Day+HUMIDITY*Day+(1|PLOT/
> > TREE),family="
> > quasibinomial")
> > 
> >  
> > 
> >  
> > 
> > Here are the possible methods:
> > 
> > #1
> > 
> > mm = model.matrix(terms(m2),data.m2)
> > 
> > data.m2$pods.bind = mm %*% fixef(m2)
> > 
> > predicted.1<-exp(data.m2$pods.bind)/(1+exp(data.m2$pods.bind))
> > 
> >  
> > 
> > #2
> > 
> > predict.lmerBin <- function(object, X){
> > 
> > if(missing(X))
> > 
> > X <- object at X
> > 
> > b <- fixef(object)
> > 
> > plogis(X %*% b)
> > 
> > }
> > 
> > predicted.2<-predict.lmerBin(m2)
> > 
> >  
> > 
> > #3
> > 
> > predicted.3<-exp(model.matrix(terms(m2),data.m2)%*%fixef(m2))
> > 
> >  
> > 
> >  
> > 
> > All three methods result in exactly the same predicted values. 
> > However, when I plug in the real data I get different 
> values than I do 
> > for fitted(). This makes me doubt the validity of my 
> predicted values. 
> > Could anybody explain why the predicted values, using these 
> methods, 
> > differ from the fitted values?
> > 
> >  
> > 
> > Thanks for your help.
> > 
> >  
> > 
> > Amy
> > 
> >  
> > 
> > ..............................................................
> > ..............
> > ...............
> > 
> > Amy S. I. Wade
> > 
> > Centre for Agri-Environmental Research
> > 
> > University of Reading
> > 
> >  
> > 
> > 
> > 	[[alternative HTML version deleted]]
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > 
> 
>



From bbolker at gmail.com  Wed Nov 24 18:11:28 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 24 Nov 2010 12:11:28 -0500
Subject: [R-sig-ME] lmer vs SAS results
In-Reply-To: <Pine.LNX.4.64.1011240958360.5347@orpheus.qimr.edu.au>
References: <mailman.5.1287655203.31036.r-sig-mixed-models@r-project.org>	<346807.26639.qm@web35303.mail.mud.yahoo.com>
	<Pine.LNX.4.64.1011240958360.5347@orpheus.qimr.edu.au>
Message-ID: <4CED4740.4040401@gmail.com>

  I got a little carried away: see
<http://www.math.mcmaster.ca/~bolker/misc/preyswim.pdf> for details.

  My conclusions:

 * lme and lme4a agree with SAS (and not lme4) in estimating the MLE of
among-trial variance as >0.  There are a variety of differences between
lme4 and lme4a, I don't really know why lme4 performs suboptimally in
this case.

 * lme4a on R-forge (r1088) does not build on my system [gives the
'drtrs' symbol missing error I posted yesterday]; if I revert to r1080 I
can get it built.  (Doug, Martin?)  I was using a slightly older version
here.

 * If you're really trying to test a hypothesis here (rather than find
the best predictive model), and if you're obeying the magic "p=0.05"
rule, you may be out of luck; the p-value for the LRT between the model
with (swim+light) and (swim) alone is 0.0537.  This should (?) be a
fairly reliable number because the number of groups and data points is
fairly large (lme gives a similar p-value for the F test, which it
claims has 80 denominator df).  Looking at the pictures, I don't see
much of an effect of light jumping out at me except (maybe) at the
lowest light level in the "preyswim=N" group. Maybe the trial effect is
blurring the picture, or ???

On 10-11-23 07:16 PM, David Duffy wrote:
> On Tue, 23 Nov 2010, Beth Holbrook wrote:
> 
> lme4:
>>       Df    AIC    BIC   logLik  Chisq Chi Df Pr(>Chisq)
>> model3  4 214.21 229.98 -103.103
>> model2  9 215.26 250.74  -98.628 8.9494      5     0.1111
>> model1 14 219.15 274.35  -95.575 6.1062      5     0.2960
>>
> SAS:
>>               AIC    BIC    -2 Log Likelihood
>> model1   216.7  251.1   188.7
>> model2   213.3  235.4   195.3
>> model3   214.2  224.0   206.2
>>
> 
> Well, SAS agrees with lme here (with method="ML"):
> 
> Model df      AIC      BIC     logLik   Test  L.Ratio p-value
> m1    14 216.7262 271.9254  -94.36309 1 vs 2  6.59408  0.2526
> m2     9 213.3203 248.8055  -97.66013 2 vs 3 10.88519  0.0537
> m3     4 214.2055 229.9767 -103.10273
> 
> Directly maximizing the likelihood (using AS319), I get the
> m2 v. m3 LRTS to be 10.8852.
> 
> I haven't evaluated likelihood at the lmer and SAS solutions yet, but
> obviously the likelihood surface will be fairly flat.
> 
> Cheers, David Duffy.
>



From Jason_Taylor1 at baylor.edu  Wed Nov 24 19:50:14 2010
From: Jason_Taylor1 at baylor.edu (Taylor, Jason)
Date: Wed, 24 Nov 2010 12:50:14 -0600
Subject: [R-sig-ME] Need advice on model specification for repeated measures
 on split-plot design
Message-ID: <DB0892FFCE97CA42BE2144E916EB43F22D5573F779@MAIL-IK.baylor.edu>

Hello,
I sent this earlier this week but realized my data table had been unfolded in the email.  Here is my post again with the data table formatted correctly.

Thanks,
Jason

I am new to the mixed-model world.  I posted a couple of weeks ago but received no feedback so I have plowed on ahead and tried to figure things out on my own.   Any feedback on my current perspective would be very useful.

I essentially have a split plot design with repeated measurements.

I have 12 experimental sampling units.

Each sampling unit is assigned to one of 3 nutrient treatments (4 replicates per treatment).

Within each sampling unit I have a grazed and ungrazed treatment.

Each sampling unit was sampled repeatedly on day 0 (before nutrients and grazer manipulations began), day 14 and day 28.

I am interested in the fixed effects of nutrient, grazing, time and their interactions but also want to account for potential random differences in sampling units.

First few lines of data are listed below for reference.

obs      Sample unit     Date     Nut     Graz     Response
1         S1                  DAY0    Low     G         2.014

2         S5                  DAY0    Low     G         2.487

3         S8                  DAY0    Low     G         2.144

4         S11                DAY0    Low     G         1.946

5         S1                  DAY0    Low     UG       2.199

6         S5                  DAY0    Low     UG       1.666

7         S8                  DAY0    Low     UG       1.642

8        S11                 DAY0    Low      UG      2.288

9        S3                   DAY0    Med      G       2.786

10      S6                   DAY0    Med      G       1.766

11      S7                   DAY0    Med      G       1.756

12      S12                 DAY0    Med      G       0.943

13      S3                   DAY0    Med      UG     2.124

14      S6                   DAY0    Med      UG     1.33

15      S7                   DAY0    Med      UG     1.847

16      S12                 DAY0    Med      UG     1.424

17      S2                   DAY0    High      G      1.775

18      S4                   DAY0    High      G      1.838

19      S9                   DAY0    High      G      2.971

20     S10                  DAY0    High      G      2.14



21     S1                   DAY14    Low     G         2.014

22    .......


I believe the correct code for a starting model in lme4 that accounts for the fixed effects and their interactions + the random effect of sample unit would be:

model.1<-lmer(response~Nut*Graz*Date+(1|Sample unit))

I realize now that if I wanted to do any nested random effects my data is currently coded poorly (implicit nesting of the variables).  However, if I understand correctly,  I don't need to incorporate (1|Stream:Graz) or (1|Stream:Date) as nested random effects because:


1)      autocorrelation between Graz or Date treatments within a sample unit will be accounted for by treating the sample unit as a random effect,

2)      they are not pseudo-replicates but actual fixed factors that I am interested in, and

3)      Graz only has 2 groups and I may only use day 14 and 28 for date (also resulting in 2 groups) since Day 0 was not influenced by any of the treatment effects.  Estimating variance from only 2 groups would be pointless.


Thanks in advance for any comments,

Cheers,
Jason



From baron at psych.upenn.edu  Thu Nov 25 01:10:35 2010
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Wed, 24 Nov 2010 19:10:35 -0500
Subject: [R-sig-ME] P value value for a large number of degree of
	freedom in lmer
In-Reply-To: <289B5A37-6AD7-4E75-B1FC-0C100DB1618B@anu.edu.au>
	<BD42EE44-7BE4-4A1E-8879-17A295B5BD33@auckland.ac.nz>
References: <AANLkTim+13OU0K1oUVcv1N6d6K_Qq00HxvK6EprVO6w5@mail.gmail.com>
	<EB95FF77-2DAF-4E6A-8EBA-6A2BE61E0236@auckland.ac.nz>
	<20101124000958.GA31594@psych.upenn.edu>
	<BD42EE44-7BE4-4A1E-8879-17A295B5BD33@auckland.ac.nz>
	<289B5A37-6AD7-4E75-B1FC-0C100DB1618B@anu.edu.au>
	<AANLkTim+13OU0K1oUVcv1N6d6K_Qq00HxvK6EprVO6w5@mail.gmail.com>
	<EB95FF77-2DAF-4E6A-8EBA-6A2BE61E0236@auckland.ac.nz>
	<20101124000958.GA31594@psych.upenn.edu>
	<BD42EE44-7BE4-4A1E-8879-17A295B5BD33@auckland.ac.nz>
Message-ID: <20101125001035.GA28839@psych.upenn.edu>

I am not going to belabor this point anymore - hence I don't plan to
reply to further comments, although I will read them - but the idea of
a well-controlled experiment is an idealization, and sometimes we come
very very close to achieving it.

My PhD thesis had a psychophysical experiment in which each of five
subjects - I was one of them - made judgments for 10 1-hour sessions
about which of three events came first, and then a second guess.  The
main question was whether signal-detection theory could explain the
second-guess results.  That was the null hypothesis, and it was
rejected, for each subject.  Each subject made several thousand
judgments.  The experiment was designed so that the null hypothesis
would be true if the theory behind it were true.  This is typical of
experiments in psychophysics.

I have done many other experiments that I thought were well
controlled, but never with so many observations.

The more general point is that I think there is a distinction between
the logical structure of experiments and the structure of
observational studies.  Null hypothesis testing is almost always
appropriate for the former and almost never appropriate for the
latter, except as a short-hand for descriptive statistics.

I think that I am unusual among psychologists only for admitting the
inappropriateness of null-hypothesis testing for observational
studies.

Jon

On 11/24/10 13:25, Rolf Turner wrote:
> 
> On 24/11/2010, at 1:09 PM, Jonathan Baron wrote:
> 
> > For the record, I have to register my disagreement.  In the
> > experimental sciences, the name of the game is to design a
> > well-controlled experiment, which means that the null hypothesis will
> > be true if the alternative hypothesis is false.  People who say what
> > is below, which includes almost everyone who responded to this post,
> > have something else in mind.  What they say is true in most
> > disciplines.  But when I hear this sort of thing, it is like someone
> > is telling me that my research career as an EXPERIMENTAL psychologist
> > has been some sort of delusion.
> > 
> > If you have a very large sample and you are doing a correlational
> > study, yes, everything will be significant.  But if you do the kind of
> > experiment we struggle to design, with perfect control conditions, you
> > won't get significant results (except by chance) if your hypothesis is
> > wrong.
> > 
> 
> 	I'll bet you don't work with samples of size 200,000. :-)
> 
> 	Also I'll bet that you don't ***really*** care if the
> 	difference between mu_T and mu_C is bigger than 0.000001 mm,
> 	say, whereas you might care if the difference were bigger than
> 	10 mm.
> 
> 	Also there's no such thing as ``perfect'' anything, let alone
> 	control conditions.
> 
> 		cheers,
> 
> 			Rolf Turner
> 
> > Jon
> > 
> > On 11/24/10 07:59, Rolf Turner wrote:
> >> 
> >> It is well known amongst statisticians that having a large enough data set will
> >> result in the rejection of *any* null hypothesis, i.e. will result in a small
> >> p-value.  There is no ``bias'' involved.
> 

On 11/24/10 15:13, John Maindonald wrote:
> I need to redraft the final sentence of the first paragraph,
> to read: "The consequence is that effects that are well within
> the bounds of statistical variation may, according to the
> the usual rituals, appear statistically significant, "
> ----------------------------------------------------------------------------
> 
> There are other considerations, which may often be more
> serious.  In any observational dataset, there is almost
> bound to be structure.  This arises in different areas in 
> different ways, but some of the possibilities are:
> 1) a time element
> 2) a space element
> 3) a location or culture or group or family element
> 4) an effect from collection instrument or person.
> 
> So the correlation structure is not iid or even i, something
> we might be expected to know about on this list.  The
> correlations will often be positive.  Even after multi-level
> or spatial models have been used to take out what is
> thought to be the structure, there will often be structure 
> left.  The consequence is that effects that are well within
> the bounds of statistical variation may, according to the
> the usual rituals, appear statistically significant, 
> 
> There are other problems.  Some variables may be measured
> very inaccurately.  Used on their own, this reduces the chances
> of finding a significant effect, catastrophically if the error is of
> the same order of magnitude as the SD of that variable.  
> If other accurately measured explanatory variables are included
> in the same analysis, they may appear falsely significant.  This
> sort of issue has been extensively canvassed in connection
> with the use of food frequency questionnaire (FFQ) measuring
> instruments in large-scale studies of the effect of diet on disease.
> See for example:
> Schatzkin, A.; Kipnis, V.; Carroll, R.; Midthune, D.; Subar, A.; Bingham, S.; 
> Schoeller, D.; Troiano, R.; and Freedman, L., 2003. A comparison of a food frequency 
> ques- tionnaire with a 24-hour recall for use in an epidemiological cohort study: 
> results from the biomarker-based observing protein and energy nutrition (open) 
> study. International Journal of Epidemiology, 32:1054 - 1062.
> Here was an instrument that many thought adequately accurate.
> 
> These problems may of course affect all observational studies.
> Deficiencies in the data and in the modeling (because some
> structure is not accounted for) become more likely to show up
> as the modeling becomes more sensitive to smallish, but 
> perhaps still consequential effects.
> 
> In modest sized experiments, careful design can largely
> avoid such problems.  In experiments where the number
> of subjects is very large, the same sorts of problems will
> almost inevitably appear.  Minor deviations from the
> protocol become almost impossible to avoid.
> 
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> http://www.maths.anu.edu.au/~johnm
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron



From tim.carnus at ucd.ie  Thu Nov 25 19:16:21 2010
From: tim.carnus at ucd.ie (tim carnus)
Date: Thu, 25 Nov 2010 18:16:21 +0000
Subject: [R-sig-ME] weights argument in lme
Message-ID: <1290708981.3158.7.camel@tim-laptop>

Dear All,

Simple question, I hope, to which I cannot find a simple answer: I can
extract from a fitted lme object 'fit' fixed effects (fixef(fit)),
random effects (ranef(fit)) and variance-covariance matrix of the random
effects (VarCorr(fit)). However, I cant get to the residual variance
estimated for different levels of a factor (weights=varIdent(form=~1|
factor)) without printing the full summary(fit). I've looked in detail
at print of str(fit) and str(summary(fit)) but really have no clue...

Any help appreciated,

Best regards,

Tim



From Brian.Burke at noaa.gov  Fri Nov 26 18:54:26 2010
From: Brian.Burke at noaa.gov (Brian Burke)
Date: Fri, 26 Nov 2010 09:54:26 -0800
Subject: [R-sig-ME] comparison between glmm.admb and lme4
Message-ID: <4CEFF452.1090601@noaa.gov>

Hi all,
I have a situation where I will be using glmm.admb for some analyses 
(e.g., when I need a negative binomial distribution or zero inflation) 
and lme4 for others (e.g., when I have crossed random effects).  I would 
like to be able to compare the log likelihoods for all of the results, 
regardless of the package I use.  I decided to run a model from each 
package on the same data set, to see if they resulted in the same (or at 
least similar) log likelihoods.  The data are catch of salmon in over 
1100 trawls, many of which are zeros.  Results are below.  Both models 
result in parameter estimates that seem reasonable (and they are 
similar, but not identical, to each other).  Did the glmer really fit 
that much better or are the log likelihoods not technically comparable?

# Compare  glmm.admb and lme4
pois.admb <- glmm.admb(count ~ temp + I(temp^2) + depth + secchi + chl + 
month + year, random=~1, group="site", data=stations, family="poisson")

pois.glmer <- glmer(count ~ temp + I(temp^2) + depth + secchi + chl + 
month + year + (1|site), data=stations, family="poisson", REML=F) # I 
get the same nll whether I put in the REML statement or not


# Results in:
 > logLik(pois.admb)
'log Lik.' -2550.45 (df=NULL)
 > logLik(pois.glmer)
'log Lik.' -2474.079 (df=20)

Thanks!!
-Brian



From bates at stat.wisc.edu  Fri Nov 26 19:29:42 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 26 Nov 2010 12:29:42 -0600
Subject: [R-sig-ME] lmer vs SAS results
In-Reply-To: <4CED4740.4040401@gmail.com>
References: <mailman.5.1287655203.31036.r-sig-mixed-models@r-project.org>
	<346807.26639.qm@web35303.mail.mud.yahoo.com>
	<Pine.LNX.4.64.1011240958360.5347@orpheus.qimr.edu.au>
	<4CED4740.4040401@gmail.com>
Message-ID: <AANLkTi=qq6uXnZPvwErV8v+3QfASXx1XPOPTnq8sBhgm@mail.gmail.com>

Thanks very much for all your work on this question, Ben.  Did you
happen to check the convergence trace for the problematic model in
lme4?

I would look at it myself but I'm still a little out of it from a bout
of pneumonia.  About 3 a.m. on Wednesday with a raging fever
(sometimes close to 104 F) and piercing headaches for hours on end
plus the continuous cough, I managed to convince myself that the
headaches were caused by brain cancer. I felt I would need to write to
the list to apologize for never having gotten lme4 to version 1.0 and
for never having finished the book on lme4

On Wed, Nov 24, 2010 at 11:11 AM, Ben Bolker <bbolker at gmail.com> wrote:
> ?I got a little carried away: see
> <http://www.math.mcmaster.ca/~bolker/misc/preyswim.pdf> for details.
>
> ?My conclusions:
>
> ?* lme and lme4a agree with SAS (and not lme4) in estimating the MLE of
> among-trial variance as >0. ?There are a variety of differences between
> lme4 and lme4a, I don't really know why lme4 performs suboptimally in
> this case.
>
> ?* lme4a on R-forge (r1088) does not build on my system [gives the
> 'drtrs' symbol missing error I posted yesterday]; if I revert to r1080 I
> can get it built. ?(Doug, Martin?) ?I was using a slightly older version
> here.
>
> ?* If you're really trying to test a hypothesis here (rather than find
> the best predictive model), and if you're obeying the magic "p=0.05"
> rule, you may be out of luck; the p-value for the LRT between the model
> with (swim+light) and (swim) alone is 0.0537. ?This should (?) be a
> fairly reliable number because the number of groups and data points is
> fairly large (lme gives a similar p-value for the F test, which it
> claims has 80 denominator df). ?Looking at the pictures, I don't see
> much of an effect of light jumping out at me except (maybe) at the
> lowest light level in the "preyswim=N" group. Maybe the trial effect is
> blurring the picture, or ???
>
> On 10-11-23 07:16 PM, David Duffy wrote:
>> On Tue, 23 Nov 2010, Beth Holbrook wrote:
>>
>> lme4:
>>> ? ? ? Df ? ?AIC ? ?BIC ? logLik ?Chisq Chi Df Pr(>Chisq)
>>> model3 ?4 214.21 229.98 -103.103
>>> model2 ?9 215.26 250.74 ?-98.628 8.9494 ? ? ?5 ? ? 0.1111
>>> model1 14 219.15 274.35 ?-95.575 6.1062 ? ? ?5 ? ? 0.2960
>>>
>> SAS:
>>> ? ? ? ? ? ? ? AIC ? ?BIC ? ?-2 Log Likelihood
>>> model1 ? 216.7 ?251.1 ? 188.7
>>> model2 ? 213.3 ?235.4 ? 195.3
>>> model3 ? 214.2 ?224.0 ? 206.2
>>>
>>
>> Well, SAS agrees with lme here (with method="ML"):
>>
>> Model df ? ? ?AIC ? ? ?BIC ? ? logLik ? Test ?L.Ratio p-value
>> m1 ? ?14 216.7262 271.9254 ?-94.36309 1 vs 2 ?6.59408 ?0.2526
>> m2 ? ? 9 213.3203 248.8055 ?-97.66013 2 vs 3 10.88519 ?0.0537
>> m3 ? ? 4 214.2055 229.9767 -103.10273
>>
>> Directly maximizing the likelihood (using AS319), I get the
>> m2 v. m3 LRTS to be 10.8852.
>>
>> I haven't evaluated likelihood at the lmer and SAS solutions yet, but
>> obviously the likelihood surface will be fairly flat.
>>
>> Cheers, David Duffy.
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From edeline at biologie.ens.fr  Fri Nov 26 21:04:31 2010
From: edeline at biologie.ens.fr (Eric Edeline)
Date: Fri, 26 Nov 2010 21:04:31 +0100
Subject: [R-sig-ME] Non normal random effects
Message-ID: <4CF012CF.7080700@biologie.ens.fr>

Dear list,

is non normality of random effects a serious issue for inference on the 
fixed effects? I am having a non normal random effect that tremendously 
improves model AIC.

Thanks!

-- 
Eric Edeline
Assistant Professor
UPMC-Paris6
UMR 7618 BIOEMCO
Ecole Normale Sup?rieure
46 rue d'Ulm
75230 Paris cedex 05
France

Tel: +33 (0)1 44 32 38 84
Fax: +33 (0)1 44 32 38 85

http://www.biologie.ens.fr/bioemco/biodiversite/edeline.html



From billy.requena at gmail.com  Fri Nov 26 22:14:26 2010
From: billy.requena at gmail.com (Billy)
Date: Fri, 26 Nov 2010 15:14:26 -0600
Subject: [R-sig-ME] Repeated measure comparisons: should the identity be a
 random or a fixed variable?
Message-ID: <AANLkTim5+x5mnK18pBpSQj3WxdFzfM3upAQibf28=2OK@mail.gmail.com>

Hello everybody!

I'm relatively new at the mixed-models world and I'm facing a
theoretical/philosophical problem.
Let's go to my data collection.

I wanna compare the number of eggs laid by females (different
individuals or the same, I have no idea) at the time 1 and at the time
2 in the same location. Therefore, I have repeated measures by
location and wanna compare time 1 versus time two. Given I have count
data, to minimize the overdispersion I have considered the Poisson
distribution for the errors.
Furthermore, I have collected this data throughout one year and I'm
also interested in temporal variation among months.

model0 <- glmer ( y ~ 1 + (1|location) + (1|month), family="poisson")
model1 <- glmer ( y ~ x + (1|location) + (1|month), family="poisson")

where y = number of eggs laid,
          x = factor concerning the first or the second oviposition
          location = factor concerning the exactly position in the
space (just an identity of the oviposition site and responsible for
the repeated comparison)
          month = factor concerning the month when I've collected the data

Is that right? If I wanna repeated comparison regarding specific
identity of oviposition sites, should this factor (location) be a
random variable?

Furthermore, in both examples above, I'm just considering a temporal
variation (among months) as random a effect. But I'm also interested
if there are significant seasonal variation in the comparison (the
difference could be higher during warm season or not even existent
during cold season). Then:

model2 <- glmer ( y ~ x + month + (1|location), family="poisson")
model3 <- glmer ( y ~ x * month + (1|location), family="poisson")

Is that right too?
Finally, I'll use a model selection approach to compare the different
models and rank the most likely one to reproduce the data observed in
the nature.
Thanks to everyone

-- 
Gustavo Requena
PhD student - Laboratory of Arthropod Behavior and Evolution
Universidade de S?o Paulo
Correspondence adress:
a/c Glauco Machado
Departamento de Ecologia - IBUSP
Rua do Mat?o - Travessa 14 no 321 Cidade Universit?ria, S?o Paulo - SP, Brasil
CEP 05508-900
Phone number: 55 11 3091-7488

http://ecologia.ib.usp.br/opilio/gustavo.html



From john.maindonald at anu.edu.au  Fri Nov 26 22:51:04 2010
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Sat, 27 Nov 2010 08:51:04 +1100
Subject: [R-sig-ME] Non normal random effects
In-Reply-To: <4CF012CF.7080700@biologie.ens.fr>
References: <4CF012CF.7080700@biologie.ens.fr>
Message-ID: <3131A41F-6AA4-4ACC-9A18-DCC9A36F2485@anu.edu.au>

Contrary to what is often claimed, it is not the normality of the
random effects themselves that matters, but the normality of 
the sampling distribution of the relevant fixed effect.  In mixed 
models, there is by comparison with iid models the additional 
complication that normality can affect the trade-offs between 
the different components in the fitted model.   Opportunities
for such trade-offs are large if there are several random effects
and there is imbalance or incompleteness (some combinations
of factor levels missing) in the fixed effects structure.  Non-normality
in the random effects can then be both hard to detect and have
implications for inference.

There is an examination of a data set with a relatively complicated 
random effects structure in the overheads at:
http://www.maths.anu.edu.au/%7Ejohnm/r-book/2edn/xtras/mlm-ohp.pdf

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 27/11/2010, at 7:04 AM, Eric Edeline wrote:

> Dear list,
> 
> is non normality of random effects a serious issue for inference on the fixed effects? I am having a non normal random effect that tremendously improves model AIC.
> 
> Thanks!
> 
> -- 
> Eric Edeline
> Assistant Professor
> UPMC-Paris6
> UMR 7618 BIOEMCO
> Ecole Normale Sup?rieure
> 46 rue d'Ulm
> 75230 Paris cedex 05
> France
> 
> Tel: +33 (0)1 44 32 38 84
> Fax: +33 (0)1 44 32 38 85
> 
> http://www.biologie.ens.fr/bioemco/biodiversite/edeline.html
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From chris at trickysolutions.com.au  Sat Nov 27 08:00:53 2010
From: chris at trickysolutions.com.au (Chris Howden)
Date: Sat, 27 Nov 2010 16:30:53 +0930
Subject: [R-sig-ME] problem using geeglm: R keeps crashing
In-Reply-To: 91806c2e3e8878df4546800ebbbfedda@mail.gmail.com
References: 91806c2e3e8878df4546800ebbbfedda@mail.gmail.com
Message-ID: <88a7dc3cc9fec75040028de580301bad@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101127/402dcf5e/attachment.pl>

From chris at trickysolutions.com.au  Sat Nov 27 09:15:32 2010
From: chris at trickysolutions.com.au (Chris Howden)
Date: Sat, 27 Nov 2010 17:45:32 +0930
Subject: [R-sig-ME] problem using geeglm: R keeps crashing
In-Reply-To: 88a7dc3cc9fec75040028de580301bad@mail.gmail.com
References: 91806c2e3e8878df4546800ebbbfedda@mail.gmail.com
	88a7dc3cc9fec75040028de580301bad@mail.gmail.com
Message-ID: <79a1c83cf1249a323e028e7a9a205832@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101127/051d2e15/attachment.pl>

From j.hadfield at ed.ac.uk  Sat Nov 27 09:18:53 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 27 Nov 2010 08:18:53 +0000
Subject: [R-sig-ME] comparison between glmm.admb and lme4
In-Reply-To: <4CEFF452.1090601@noaa.gov>
References: <4CEFF452.1090601@noaa.gov>
Message-ID: <20101127081853.15821t0rjk4dgv7o@www.staffmail.ed.ac.uk>

Hi Brian,

Likelihoods are not necessarily comparable between programs, but  
differences in log-likelihoods between two models should be (i.e.  
likelihoods from different programs should be proportional). For mixed  
models with non-Gaussian data the likelihood has to be approximated so  
programs that use different approximations will give different  
answers, but I guess you would hope the differences are not large.

Cheers,

Jarrod

  Quoting Brian Burke <Brian.Burke at noaa.gov>:

> Hi all,
> I have a situation where I will be using glmm.admb for some analyses  
> (e.g., when I need a negative binomial distribution or zero  
> inflation) and lme4 for others (e.g., when I have crossed random  
> effects).  I would like to be able to compare the log likelihoods  
> for all of the results, regardless of the package I use.  I decided  
> to run a model from each package on the same data set, to see if  
> they resulted in the same (or at least similar) log likelihoods.   
> The data are catch of salmon in over 1100 trawls, many of which are  
> zeros.  Results are below.  Both models result in parameter  
> estimates that seem reasonable (and they are similar, but not  
> identical, to each other).  Did the glmer really fit that much  
> better or are the log likelihoods not technically comparable?
>
> # Compare  glmm.admb and lme4
> pois.admb <- glmm.admb(count ~ temp + I(temp^2) + depth + secchi +  
> chl + month + year, random=~1, group="site", data=stations,  
> family="poisson")
>
> pois.glmer <- glmer(count ~ temp + I(temp^2) + depth + secchi + chl  
> + month + year + (1|site), data=stations, family="poisson", REML=F)  
> # I get the same nll whether I put in the REML statement or not
>
>
> # Results in:
>> logLik(pois.admb)
> 'log Lik.' -2550.45 (df=NULL)
>> logLik(pois.glmer)
> 'log Lik.' -2474.079 (df=20)
>
> Thanks!!
> -Brian
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From j.hadfield at ed.ac.uk  Sat Nov 27 09:26:01 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 27 Nov 2010 08:26:01 +0000
Subject: [R-sig-ME] Repeated measure comparisons: should the identity be
 a random or a fixed variable?
In-Reply-To: <AANLkTim5+x5mnK18pBpSQj3WxdFzfM3upAQibf28=2OK@mail.gmail.com>
References: <AANLkTim5+x5mnK18pBpSQj3WxdFzfM3upAQibf28=2OK@mail.gmail.com>
Message-ID: <20101127082601.17263ut2ss7hdps0@www.staffmail.ed.ac.uk>

Hi Billy,

I think your models look reasonable, although in models 2 and 3 you  
may want  to treat month as a continuous variable in the fixed part of  
the model. Also, most count data are overdispersed with respect to the  
poisson and so a model that does not account for this will be  
anti-conservative in terms of standard errors etc. One way to deal  
with this is to fit an additional random effect at the level of each  
observation:

my.data$resid<-as.factor(1:dim(my.data)[2])

and fit (1|resid) in the model formula.

Cheers,

Jarrod




Quoting Billy <billy.requena at gmail.com>:

> Hello everybody!
>
> I'm relatively new at the mixed-models world and I'm facing a
> theoretical/philosophical problem.
> Let's go to my data collection.
>
> I wanna compare the number of eggs laid by females (different
> individuals or the same, I have no idea) at the time 1 and at the time
> 2 in the same location. Therefore, I have repeated measures by
> location and wanna compare time 1 versus time two. Given I have count
> data, to minimize the overdispersion I have considered the Poisson
> distribution for the errors.
> Furthermore, I have collected this data throughout one year and I'm
> also interested in temporal variation among months.
>
> model0 <- glmer ( y ~ 1 + (1|location) + (1|month), family="poisson")
> model1 <- glmer ( y ~ x + (1|location) + (1|month), family="poisson")
>
> where y = number of eggs laid,
>           x = factor concerning the first or the second oviposition
>           location = factor concerning the exactly position in the
> space (just an identity of the oviposition site and responsible for
> the repeated comparison)
>           month = factor concerning the month when I've collected the data
>
> Is that right? If I wanna repeated comparison regarding specific
> identity of oviposition sites, should this factor (location) be a
> random variable?
>
> Furthermore, in both examples above, I'm just considering a temporal
> variation (among months) as random a effect. But I'm also interested
> if there are significant seasonal variation in the comparison (the
> difference could be higher during warm season or not even existent
> during cold season). Then:
>
> model2 <- glmer ( y ~ x + month + (1|location), family="poisson")
> model3 <- glmer ( y ~ x * month + (1|location), family="poisson")
>
> Is that right too?
> Finally, I'll use a model selection approach to compare the different
> models and rank the most likely one to reproduce the data observed in
> the nature.
> Thanks to everyone
>
> --
> Gustavo Requena
> PhD student - Laboratory of Arthropod Behavior and Evolution
> Universidade de S?o Paulo
> Correspondence adress:
> a/c Glauco Machado
> Departamento de Ecologia - IBUSP
> Rua do Mat?o - Travessa 14 no 321 Cidade Universit?ria, S?o Paulo -  
> SP, Brasil
> CEP 05508-900
> Phone number: 55 11 3091-7488
>
> http://ecologia.ib.usp.br/opilio/gustavo.html
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From edeline at biologie.ens.fr  Sat Nov 27 13:43:49 2010
From: edeline at biologie.ens.fr (Eric Edeline)
Date: Sat, 27 Nov 2010 13:43:49 +0100
Subject: [R-sig-ME] Non normal random effects
In-Reply-To: <3131A41F-6AA4-4ACC-9A18-DCC9A36F2485@anu.edu.au>
References: <4CF012CF.7080700@biologie.ens.fr>
	<3131A41F-6AA4-4ACC-9A18-DCC9A36F2485@anu.edu.au>
Message-ID: <4CF0FD05.7060501@biologie.ens.fr>

Dear John,

thanks for your feed back and for the useful tutorial. Actually the 
random effect in question is normally distributed (I did not check 
before, sorry), so the problem comes from somewhere else. I am modeling 
fish body size from a large dataset as a function of many covariates, 
and adding a "species" effect (be it fixed or random) skews the 
residuals but drops the AIC:

m1<-lmer(log(Length) 
~log(Slope)+log(Width)+Temp*log(D)+Temp*log(Compint2)+Temp*log(Predln102)+Temp*Year
+(1|Species/Station),
data=Data, na.action=na.omit, REML=TRUE) #AIC 73427, skewed residuals

m2<-lmer(log(Length) 
~log(Slope)+log(Width)+Temp*log(D)+Temp*log(Compint2)+Temp*log(Predln102)+Temp*Year
+(1|Station),
data=Data, na.action=na.omit, REML=TRUE) #AIC 147157, Gaussian residuals

This looks puzzling to me. Would you have an idea for why introducing a 
normally distributed effect shews the residuals?




On 11/26/2010 10:51 PM, John Maindonald wrote:
> Contrary to what is often claimed, it is not the normality of the
> random effects themselves that matters, but the normality of
> the sampling distribution of the relevant fixed effect.  In mixed
> models, there is by comparison with iid models the additional
> complication that normality can affect the trade-offs between
> the different components in the fitted model.   Opportunities
> for such trade-offs are large if there are several random effects
> and there is imbalance or incompleteness (some combinations
> of factor levels missing) in the fixed effects structure.  Non-normality
> in the random effects can then be both hard to detect and have
> implications for inference.
>
> There is an examination of a data set with a relatively complicated
> random effects structure in the overheads at:
> http://www.maths.anu.edu.au/%7Ejohnm/r-book/2edn/xtras/mlm-ohp.pdf
>
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics&  Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> http://www.maths.anu.edu.au/~johnm
>
> On 27/11/2010, at 7:04 AM, Eric Edeline wrote:
>
>    
>> Dear list,
>>
>> is non normality of random effects a serious issue for inference on the fixed effects? I am having a non normal random effect that tremendously improves model AIC.
>>
>> Thanks!
>>
>> -- 
>> Eric Edeline
>> Assistant Professor
>> UPMC-Paris6
>> UMR 7618 BIOEMCO
>> Ecole Normale Sup?rieure
>> 46 rue d'Ulm
>> 75230 Paris cedex 05
>> France
>>
>> Tel: +33 (0)1 44 32 38 84
>> Fax: +33 (0)1 44 32 38 85
>>
>> http://www.biologie.ens.fr/bioemco/biodiversite/edeline.html
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>      
>    

-- 
Eric Edeline
Assistant Professor
UPMC-Paris6
UMR 7618 BIOEMCO
Ecole Normale Sup?rieure
46 rue d'Ulm
75230 Paris cedex 05
France

Tel: +33 (0)1 44 32 38 84
Fax: +33 (0)1 44 32 38 85

http://www.biologie.ens.fr/bioemco/biodiversite/edeline.html



From valerio.bartolino at gmail.com  Sat Nov 27 16:45:35 2010
From: valerio.bartolino at gmail.com (Valerio Bartolino)
Date: Sat, 27 Nov 2010 16:45:35 +0100
Subject: [R-sig-ME] Non normal random effects
In-Reply-To: <4CF0FD05.7060501@biologie.ens.fr>
References: <4CF012CF.7080700@biologie.ens.fr>
	<3131A41F-6AA4-4ACC-9A18-DCC9A36F2485@anu.edu.au>
	<4CF0FD05.7060501@biologie.ens.fr>
Message-ID: <AANLkTik-EPVk+W4OZ3NuxMv7aNtdnUDh8huyfyJs-JkL@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101127/921046ec/attachment.pl>

From edepa001 at ucr.edu  Tue Nov 23 18:34:09 2010
From: edepa001 at ucr.edu (Elijah DePalma)
Date: Tue, 23 Nov 2010 09:34:09 -0800
Subject: [R-sig-ME] Spatially correlated random effects
Message-ID: <AANLkTiniXbfoiBNo1vjzLesUOBiC5O_EfnLO5OkM7+qS@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101123/bd4b4a14/attachment.pl>

From dps215 at psu.edu  Tue Nov 23 22:23:16 2010
From: dps215 at psu.edu (David Stainbrook)
Date: Tue, 23 Nov 2010 16:23:16 -0500
Subject: [R-sig-ME] Dealing with Overdispersion in Count Data with Mixed
	Modeling
In-Reply-To: 4CDC4748.7060002@gmail.com
References: <1288203635l.1032266l.0l@psu.edu> <1288208508l.1511628l.0l@psu.edu>
	<1288296451l.1032274l.0l@psu.edu>
	<AANLkTikscT885QSAdhJHS=yyVeeN5LV4_Qj7JC2QfGoB@mail.gmail.com><4CC9E1C5.407
	0106@gmail.com>
	<1288632521l.614426l.0l@psu.edu><4CCF6F03.80101@gmail.com>
	<1289502674l.892954l.0l@psu.edu><4CDC4748.7060002@gmail.com>
Message-ID: <1290547396l.516114l.0l@psu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101123/dc7546a8/attachment.pl>

From montagnini at incm.cnrs-mrs.fr  Wed Nov 24 23:20:18 2010
From: montagnini at incm.cnrs-mrs.fr (montagnini)
Date: Wed, 24 Nov 2010 23:20:18 +0100
Subject: [R-sig-ME] deviance residuals, leverage, hat matrix...
Message-ID: <3e27bc47c72e1df161d8040460fe20fd@incm.cnrs-mrs.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101124/794cb9af/attachment.pl>

From charpent at bacbuc.dyndns.org  Thu Nov 25 10:02:06 2010
From: charpent at bacbuc.dyndns.org (Emmanuel Charpentier)
Date: Thu, 25 Nov 2010 10:02:06 +0100
Subject: [R-sig-ME] P value value for a large number of degree of
	freedom in lmer
In-Reply-To: <AANLkTi=qWv+ZZm5vtbzUEuLfmrXB=CyxsvV+taehm-iX@mail.gmail.com>
References: <AANLkTim+13OU0K1oUVcv1N6d6K_Qq00HxvK6EprVO6w5@mail.gmail.com>
	<EB95FF77-2DAF-4E6A-8EBA-6A2BE61E0236@auckland.ac.nz>
	<20101124000958.GA31594@psych.upenn.edu>
	<AANLkTi=qWv+ZZm5vtbzUEuLfmrXB=CyxsvV+taehm-iX@mail.gmail.com>
Message-ID: <1290675726.2540.28.camel@PortableToshiba>

Small Bayesian provocation below...

Le mardi 23 novembre 2010 ? 16:51 -0800, Joshua Wiley a ?crit :
> On Tue, Nov 23, 2010 at 4:09 PM, Jonathan Baron <baron at psych.upenn.edu> wrote:
> > For the record, I have to register my disagreement.  In the
> > experimental sciences, the name of the game is to design a
> > well-controlled experiment, which means that the null hypothesis will
> > be true if the alternative hypothesis is false.  People who say what
> > is below, which includes almost everyone who responded to this post,
> > have something else in mind.  What they say is true in most
> > disciplines.  But when I hear this sort of thing, it is like someone
> > is telling me that my research career as an EXPERIMENTAL psychologist
> > has been some sort of delusion.
> 
> I would not take it that way.  I agree there is a difference between
> some arbitrary null of no difference and a well designed control, but
> no matter what case, the null is a specific hypothesis.  Given a
> continuous distribution, if you the probability of any constant
> occurring to an infinite decimal place is infinitely small.  With only
> 100,000 observations:
> 
> > dt(.49, df = 10^5) - dt(.5, df = 10^5)
> [1] 0.001747051
> 
> Your career as an experimental psychologist is not a delusion, null
> hypothesis statistical testing is---even with a perfect control, we
> set up an unrealistic hypothesis.  Now if we could set up the null as
> an interval....

Assess (Bayes' theorem, whatever the computational process : conjugacy,
explicit computation, MCMC...) the *distribution* of mu_b-mu_a from
prior knowledge (possibly zilch), compute Pr(mu_b-mu_a \in
YourH0Interval) and Pr(mu_b-mu_a \not\in YourH0Interval), and deduce
(Bayes' theorem again) Pr(y|mu_b-mu_a \in YourH0Interval) if you need
something looking like a p-value ; if you want a simpler-interpretaton
one-number summary, compute Bayes' factor.

Easy.

The hard part is to convince your reviewer (and maybe yourself) that
*this* is a valid probabilistic reasoning, that Karl Popper was not God
and that *all*probabilities are conditional.

A harder part is to convince yourself that your choice of distributional
*shapes* (and, more generally, your modelling  choice) is reasonable.
Some variable transformations might help (e. g. use rank(X) rather than
X, postulate t-shaped distributions, etc...), but entails some
non-negligible computational difficulties.

HTH,

					Emmanuel Charpentier


> > If you have a very large sample and you are doing a correlational
> > study, yes, everything will be significant.  But if you do the kind of
> > experiment we struggle to design, with perfect control conditions, you
> > won't get significant results (except by chance) if your hypothesis is
> > wrong.
> 
> I agree that this is typically a bigger problem for correlational
> studies, but if it became practical to run well-controlled experiments
> on millions of participants, I suspect p-values would be disregarded
> awfully quickly.  Even then, the study was not pointless or a
> delusion, that kind of precision lets you confidently talk about the
> actual effect your treatment had compared to your well-designed
> control, and would give any applied person or practitioner a great
> guide what to expect if they implemented it in the field.
> 
> x <- rnorm(10^6, mean = 0)
> y <- rnorm(10^6, mean = .01)
> t.test(x, y, var.equal = TRUE)
> 
> Best regards,
> 
> Josh (fan of experiments, correlational studies, & psychology...not so
> much of NHST, but you use what you have)
> 
> 
> 
> >
> > Jon
> >
> > On 11/24/10 07:59, Rolf Turner wrote:
> >>
> >> It is well known amongst statisticians that having a large enough data set will
> >> result in the rejection of *any* null hypothesis, i.e. will result in a small
> >> p-value.  There is no ``bias'' involved.
> >
> > --
> > Jonathan Baron, Professor of Psychology, University of Pennsylvania
> > Home page: http://www.sas.upenn.edu/~baron
> > Editor: Judgment and Decision Making (http://journal.sjdm.org)
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
> 
> 



From KINLEY_ROBERT at lilly.com  Thu Nov 25 19:13:10 2010
From: KINLEY_ROBERT at lilly.com (Robert Kinley)
Date: Thu, 25 Nov 2010 18:13:10 +0000
Subject: [R-sig-ME] Fw: difficulty setting the random = argument to lme()
Message-ID: <OFECB707B8.BCA1B9FC-ON802577E6.0063CB37-802577E6.0063F213@EliLilly.lilly.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101125/42eec7c2/attachment.pl>

From shigesong at gmail.com  Sat Nov 27 16:53:59 2010
From: shigesong at gmail.com (Shige Song)
Date: Sat, 27 Nov 2010 10:53:59 -0500
Subject: [R-sig-ME] Spatially correlated random effects
In-Reply-To: <AANLkTiniXbfoiBNo1vjzLesUOBiC5O_EfnLO5OkM7+qS@mail.gmail.com>
References: <AANLkTiniXbfoiBNo1vjzLesUOBiC5O_EfnLO5OkM7+qS@mail.gmail.com>
Message-ID: <AANLkTim5Cb_O6THsznJbNtzQGJPhLGd22GbOmGoU6+8g@mail.gmail.com>

I recently found the R-INLA package to be very promising. You can find
many papers and sample code on their web site
(http://www.r-inla.org/papers) for spatial modelling.

Shige

On Tue, Nov 23, 2010 at 12:34 PM, Elijah DePalma <edepa001 at ucr.edu> wrote:
> May you please provide insight to fitting a poisson (or neg binomial) glmm,
> in which the random effects are spatially correlated?
>
> I must be able to specify the correlation matrix (up to a parameter), and
> the only package I have found which permits this is the "hglm" package (and
> also Proc Glimmix).
>
> Thank you for any insight,
> Elijah DePalma
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Sat Nov 27 18:04:58 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 27 Nov 2010 11:04:58 -0600
Subject: [R-sig-ME] Non normal random effects
In-Reply-To: <4CF0FD05.7060501@biologie.ens.fr>
References: <4CF012CF.7080700@biologie.ens.fr>
	<3131A41F-6AA4-4ACC-9A18-DCC9A36F2485@anu.edu.au>
	<4CF0FD05.7060501@biologie.ens.fr>
Message-ID: <AANLkTik5F9E8h_q6anVhn48BfnSBCwCceFGBciT0esG6@mail.gmail.com>

On Sat, Nov 27, 2010 at 6:43 AM, Eric Edeline <edeline at biologie.ens.fr> wrote:
> Dear John,
>
> thanks for your feed back and for the useful tutorial. Actually the random
> effect in question is normally distributed (I did not check before, sorry),
> so the problem comes from somewhere else. I am modeling fish body size from
> a large dataset as a function of many covariates, and adding a "species"
> effect (be it fixed or random) skews the residuals but drops the AIC:
>
> m1<-lmer(log(Length)
> ~log(Slope)+log(Width)+Temp*log(D)+Temp*log(Compint2)+Temp*log(Predln102)+Temp*Year
> +(1|Species/Station),
> data=Data, na.action=na.omit, REML=TRUE) #AIC 73427, skewed residuals

Just in terms of the model specification, do you really mean
(1|Species/Station)?  That expands to

 (1|Species) + (1|Species:Station)

and wouldn't reduce to (1|Station) in a model specification.  I think
you meant "species within station", which would be written as
(1|Station/Species) although I prefer the more explicit form
(1|Station) + (1|Station:Species)

> m2<-lmer(log(Length)
> ~log(Slope)+log(Width)+Temp*log(D)+Temp*log(Compint2)+Temp*log(Predln102)+Temp*Year
> +(1|Station),
> data=Data, na.action=na.omit, REML=TRUE) #AIC 147157, Gaussian residuals
>
> This looks puzzling to me. Would you have an idea for why introducing a
> normally distributed effect shews the residuals?
>
>
>
>
> On 11/26/2010 10:51 PM, John Maindonald wrote:
>>
>> Contrary to what is often claimed, it is not the normality of the
>> random effects themselves that matters, but the normality of
>> the sampling distribution of the relevant fixed effect. ?In mixed
>> models, there is by comparison with iid models the additional
>> complication that normality can affect the trade-offs between
>> the different components in the fitted model. ? Opportunities
>> for such trade-offs are large if there are several random effects
>> and there is imbalance or incompleteness (some combinations
>> of factor levels missing) in the fixed effects structure. ?Non-normality
>> in the random effects can then be both hard to detect and have
>> implications for inference.
>>
>> There is an examination of a data set with a relatively complicated
>> random effects structure in the overheads at:
>> http://www.maths.anu.edu.au/%7Ejohnm/r-book/2edn/xtras/mlm-ohp.pdf
>>
>> John Maindonald ? ? ? ? ? ? email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473 ? ?fax ?: +61 2(6125)5549
>> Centre for Mathematics& ?Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>> http://www.maths.anu.edu.au/~johnm
>>
>> On 27/11/2010, at 7:04 AM, Eric Edeline wrote:
>>
>>
>>>
>>> Dear list,
>>>
>>> is non normality of random effects a serious issue for inference on the
>>> fixed effects? I am having a non normal random effect that tremendously
>>> improves model AIC.
>>>
>>> Thanks!
>>>
>>> --
>>> Eric Edeline
>>> Assistant Professor
>>> UPMC-Paris6
>>> UMR 7618 BIOEMCO
>>> Ecole Normale Sup?rieure
>>> 46 rue d'Ulm
>>> 75230 Paris cedex 05
>>> France
>>>
>>> Tel: +33 (0)1 44 32 38 84
>>> Fax: +33 (0)1 44 32 38 85
>>>
>>> http://www.biologie.ens.fr/bioemco/biodiversite/edeline.html
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>
> --
> Eric Edeline
> Assistant Professor
> UPMC-Paris6
> UMR 7618 BIOEMCO
> Ecole Normale Sup?rieure
> 46 rue d'Ulm
> 75230 Paris cedex 05
> France
>
> Tel: +33 (0)1 44 32 38 84
> Fax: +33 (0)1 44 32 38 85
>
> http://www.biologie.ens.fr/bioemco/biodiversite/edeline.html
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From valerio.bartolino at gmail.com  Sat Nov 27 19:14:51 2010
From: valerio.bartolino at gmail.com (valerio.bartolino)
Date: Sat, 27 Nov 2010 19:14:51 +0100
Subject: [R-sig-ME] Non normal random effects
In-Reply-To: <4CF012CF.7080700@biologie.ens.fr>
References: <4CF012CF.7080700@biologie.ens.fr>
Message-ID: <1290881691.5188.10.camel@ubuntu.ubuntu-domain>

Dear Eric,
I'm impressed by the drop in the AIC due to the 'Species' variable. I
think it could be useful comparing the coefficients estimated for the
fixed effects between the two models. It may be the case that they are
rather different between m1 and m2. I would pay great attention to the
interpretation of the effect of each variable.

Hope this could help

Valerio


On Fri, 2010-11-26 at 21:04 +0100, Eric Edeline wrote:
> Dear list,
> 
> is non normality of random effects a serious issue for inference on the 
> fixed effects? I am having a non normal random effect that tremendously 
> improves model AIC.
> 
> Thanks!
> 

-- 
Valerio Bartolino, PhD

Institute of Marine Research - Swedish Board of Fisheries
PO Box 4, 45321 Lysekil, Sweden

Department of Earth Sciences - Gothenburg University
PO Box 460, 40530 G?teborg, Sweden

e-mail: valerio.bartolino at gvc.gu.se
        valerio.bartolino at gmail.com

><(((*> ----- ><(((*> ----- ><(((*> ----- ><(((*>



From edeline at biologie.ens.fr  Sat Nov 27 19:31:59 2010
From: edeline at biologie.ens.fr (Eric Edeline)
Date: Sat, 27 Nov 2010 19:31:59 +0100
Subject: [R-sig-ME] Non normal random effects
In-Reply-To: <1290881691.5188.10.camel@ubuntu.ubuntu-domain>
References: <4CF012CF.7080700@biologie.ens.fr>
	<1290881691.5188.10.camel@ubuntu.ubuntu-domain>
Message-ID: <4CF14E9F.5090206@biologie.ens.fr>

Here are model coeffs, which are indeed very different between the two 
models for some effects:

1> m1 at fixef
         (Intercept)          log(Slope)          
log(Width)                Temp
       64.3355546922        0.0176278497       -0.0301275431       
-3.8692860013
              log(D)       log(Compint2)      
log(Predln102)                Year
        0.0021372925        0.0023000751        0.0327498020       
-0.0294303421
         Temp:log(D)  Temp:log(Compint2) Temp:log(Predln102)           
Temp:Year
       -0.0032965368       -0.0013422775       -0.0008383696        
0.0019082777
1> m2 at fixef
         (Intercept)          log(Slope)          
log(Width)                Temp
        49.601725055        -0.113952871        -0.013659799        
-2.285783668
              log(D)       log(Compint2)      
log(Predln102)                Year
         0.023140502         0.055044993        -0.252180423        
-0.023767542
         Temp:log(D)  Temp:log(Compint2) Temp:log(Predln102)           
Temp:Year
        -0.006871451        -0.011123770         0.010086872         
0.001163320

In m1 I indeed meant "Station" within "Species". Actually, the full 
model I have selected so far is much more complex and includes several 
nested random effects + variance functions in lme:

m3<-lme(log(Length) 
~log(Slope)+log(Width)+log(Fcl)+Nb.species+Temp*log(D)+Temp*log(Compint2)+Temp*log(Predln102)+Temp*Year,
data=Data, na.action=na.omit, random=list(Species=pdDiag(form=~1), 
Strategy=pdDiag(form=~1), Method=pdDiag(form=~1),
Region=pdDiag(form=~1), Station=pdDiag(form=~1)), control=list(maxIter=100),
weights=varComb(varPower(form=~D), varPower(form=~Predln102), 
varPower(form=~Compint2)))#AIC 50945.01

Maybe this is too complex, but this is the best structure in terms of 
AIC. Still, the problem of skewed residuals from having a species effect 
remains (even as a fixed effect in simple lm models), and I really can't 
figure out why...


On 11/27/2010 07:14 PM, valerio.bartolino wrote:
> Dear Eric,
> I'm impressed by the drop in the AIC due to the 'Species' variable. I
> think it could be useful comparing the coefficients estimated for the
> fixed effects between the two models. It may be the case that they are
> rather different between m1 and m2. I would pay great attention to the
> interpretation of the effect of each variable.
>
> Hope this could help
>
> Valerio
>
>
> On Fri, 2010-11-26 at 21:04 +0100, Eric Edeline wrote:
>    
>> Dear list,
>>
>> is non normality of random effects a serious issue for inference on the
>> fixed effects? I am having a non normal random effect that tremendously
>> improves model AIC.
>>
>> Thanks!
>>
>>      
>    

-- 
Eric Edeline
Assistant Professor
UPMC-Paris6
UMR 7618 BIOEMCO
Ecole Normale Sup?rieure
46 rue d'Ulm
75230 Paris cedex 05
France

Tel: +33 (0)1 44 32 38 84
Fax: +33 (0)1 44 32 38 85

http://www.biologie.ens.fr/bioemco/biodiversite/edeline.html



From danielezrajohnson at gmail.com  Sat Nov 27 20:22:07 2010
From: danielezrajohnson at gmail.com (Daniel Ezra Johnson)
Date: Sat, 27 Nov 2010 14:22:07 -0500
Subject: [R-sig-ME] large data set implies rejection of null?
Message-ID: <AANLkTimbUmG5yaf_JKiseBzyyz9EJmchj6ieE2MU0PrN@mail.gmail.com>

On 11/24/10 07:59, Rolf Turner wrote:
> >>
> >> It is well known amongst statisticians that having a large enough data set will
> >> result in the rejection of *any* null hypothesis, i.e. will result in a small
> >> p-value.

This seems to be a well-accepted guideline, probably because in the
social sciences, usually, none of the predictors truly has an effect
size of zero.
However, unless I am misunderstanding it, the statement appears to me
to be more generally false.
For example, when the population difference of means actually equals
zero, in a t-test, very large sample sizes do not lead to small
p-values.

set.seed(1)
n <- 1000000  # 10^6
dat.1 <- rnorm(n/2,0,1)
dat.2 <- rnorm(n/2,0,1)
t.test(dat.1,dat.2,var.equal=T)
# p = 0.60

set.seed(1)
n <- 10000000  # 10^7
dat.1 <- rnorm(n/2,0,1)
dat.2 <- rnorm(n/2,0,1)
t.test(dat.1,dat.2,var.equal=T)
# p = 0.48

set.seed(1)
n <- 100000000  # 10^8
dat.1 <- rnorm(n/2,0,1)
dat.2 <- rnorm(n/2,0,1)
t.test(dat.1,dat.2,var.equal=T)
# p = 0.80

Such results - where the null hypothesis is NOT rejected - would
presumably also occur in any experimental situations where the null
hypothesis was literally true, regardless of the size of the data set.
No?

Daniel



From baron at psych.upenn.edu  Sat Nov 27 21:13:10 2010
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Sat, 27 Nov 2010 15:13:10 -0500
Subject: [R-sig-ME] large data set implies rejection of null?
In-Reply-To: <AANLkTimbUmG5yaf_JKiseBzyyz9EJmchj6ieE2MU0PrN@mail.gmail.com>
References: <AANLkTimbUmG5yaf_JKiseBzyyz9EJmchj6ieE2MU0PrN@mail.gmail.com>
Message-ID: <20101127201310.GA3751@psych.upenn.edu>

Although I said I would not reply anymore, I did think of one example
of what I thought was a perfectly well-controlled experiment that I
did.  I don't remember it very well and don't have a reprint (!), but
here is the citation:

Baron, J. (1974). Facilitation of perception by spelling
constraints. Canadian Journal of Psychology, 28, 37-50.

In one condition, subjects got practice with AB CD.  In another, they
got AB CD AD CB.  But the frequency of AB CD is the same in both
conditions, so frequency of presentation was perfectly controlled.
The former condition was superior in perception, thus showing that
subjects could use information about sequential constraints.  (Or
something like this.  I might be misremembering.)  Even a tiny effect
would have been theoretically interesting.  This involved many
thousands of observations per subject, as I recall.  Even with a tiny
effect with millions of observations, I cannot think of an alternative
explanation of a significant result (except the usual, that it was
chance and would not replicate).  There was no issue of sampling
because everything was counterbalanced.

I have done many other experiments that I think were well controlled,
but nothing as simple as this one.

I am not yet convinced that null hypotheses are never true.  They seem
to be true quite often in my lab. :(

Jon

On 11/27/10 14:22, Daniel Ezra Johnson wrote:
> On 11/24/10 07:59, Rolf Turner wrote:
> > >>
> > >> It is well known amongst statisticians that having a large enough data set will
> > >> result in the rejection of *any* null hypothesis, i.e. will result in a small
> > >> p-value.
> 
> This seems to be a well-accepted guideline, probably because in the
> social sciences, usually, none of the predictors truly has an effect
> size of zero.
> However, unless I am misunderstanding it, the statement appears to me
> to be more generally false.
> For example, when the population difference of means actually equals
> zero, in a t-test, very large sample sizes do not lead to small
> p-values.
> 
> set.seed(1)
> n <- 1000000  # 10^6
> dat.1 <- rnorm(n/2,0,1)
> dat.2 <- rnorm(n/2,0,1)
> t.test(dat.1,dat.2,var.equal=T)
> # p = 0.60
> 
> set.seed(1)
> n <- 10000000  # 10^7
> dat.1 <- rnorm(n/2,0,1)
> dat.2 <- rnorm(n/2,0,1)
> t.test(dat.1,dat.2,var.equal=T)
> # p = 0.48
> 
> set.seed(1)
> n <- 100000000  # 10^8
> dat.1 <- rnorm(n/2,0,1)
> dat.2 <- rnorm(n/2,0,1)
> t.test(dat.1,dat.2,var.equal=T)
> # p = 0.80
> 
> Such results - where the null hypothesis is NOT rejected - would
> presumably also occur in any experimental situations where the null
> hypothesis was literally true, regardless of the size of the data set.
> No?
> 
> Daniel
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
Editor: Judgment and Decision Making (http://journal.sjdm.org)



From john.maindonald at anu.edu.au  Sat Nov 27 23:18:18 2010
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Sun, 28 Nov 2010 09:18:18 +1100
Subject: [R-sig-ME] Non normal random effects
In-Reply-To: <4CF0FD05.7060501@biologie.ens.fr>
References: <4CF012CF.7080700@biologie.ens.fr>
	<3131A41F-6AA4-4ACC-9A18-DCC9A36F2485@anu.edu.au>
	<4CF0FD05.7060501@biologie.ens.fr>
Message-ID: <E0ED3EFD-6F39-488E-AE00-CF4B7007A864@anu.edu.au>

You can have this sort of situation:
'Normal' effect                       .                                       .                                  .
Observations                   .. .  .  .    .                        ..  .    .    .                      ..  .    .     .

The large contribution from the random effect means that,
until it is accounted for, you will not see the non-normality.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 27/11/2010, at 11:43 PM, Eric Edeline wrote:

> Dear John,
> 
> thanks for your feed back and for the useful tutorial. Actually the random effect in question is normally distributed (I did not check before, sorry), so the problem comes from somewhere else. I am modeling fish body size from a large dataset as a function of many covariates, and adding a "species" effect (be it fixed or random) skews the residuals but drops the AIC:
> 
> m1<-lmer(log(Length) ~log(Slope)+log(Width)+Temp*log(D)+Temp*log(Compint2)+Temp*log(Predln102)+Temp*Year
> +(1|Species/Station),
> data=Data, na.action=na.omit, REML=TRUE) #AIC 73427, skewed residuals
> 
> m2<-lmer(log(Length) ~log(Slope)+log(Width)+Temp*log(D)+Temp*log(Compint2)+Temp*log(Predln102)+Temp*Year
> +(1|Station),
> data=Data, na.action=na.omit, REML=TRUE) #AIC 147157, Gaussian residuals
> 
> This looks puzzling to me. Would you have an idea for why introducing a normally distributed effect shews the residuals?
> 
> 
> 
> 
> On 11/26/2010 10:51 PM, John Maindonald wrote:
>> Contrary to what is often claimed, it is not the normality of the
>> random effects themselves that matters, but the normality of
>> the sampling distribution of the relevant fixed effect.  In mixed
>> models, there is by comparison with iid models the additional
>> complication that normality can affect the trade-offs between
>> the different components in the fitted model.   Opportunities
>> for such trade-offs are large if there are several random effects
>> and there is imbalance or incompleteness (some combinations
>> of factor levels missing) in the fixed effects structure.  Non-normality
>> in the random effects can then be both hard to detect and have
>> implications for inference.
>> 
>> There is an examination of a data set with a relatively complicated
>> random effects structure in the overheads at:
>> http://www.maths.anu.edu.au/%7Ejohnm/r-book/2edn/xtras/mlm-ohp.pdf
>> 
>> John Maindonald             email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Mathematics&  Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>> http://www.maths.anu.edu.au/~johnm
>> 
>> On 27/11/2010, at 7:04 AM, Eric Edeline wrote:
>> 
>>   
>>> Dear list,
>>> 
>>> is non normality of random effects a serious issue for inference on the fixed effects? I am having a non normal random effect that tremendously improves model AIC.
>>> 
>>> Thanks!
>>> 
>>> -- 
>>> Eric Edeline
>>> Assistant Professor
>>> UPMC-Paris6
>>> UMR 7618 BIOEMCO
>>> Ecole Normale Sup?rieure
>>> 46 rue d'Ulm
>>> 75230 Paris cedex 05
>>> France
>>> 
>>> Tel: +33 (0)1 44 32 38 84
>>> Fax: +33 (0)1 44 32 38 85
>>> 
>>> http://www.biologie.ens.fr/bioemco/biodiversite/edeline.html
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>     
>>   
> 
> -- 
> Eric Edeline
> Assistant Professor
> UPMC-Paris6
> UMR 7618 BIOEMCO
> Ecole Normale Sup?rieure
> 46 rue d'Ulm
> 75230 Paris cedex 05
> France
> 
> Tel: +33 (0)1 44 32 38 84
> Fax: +33 (0)1 44 32 38 85
> 
> http://www.biologie.ens.fr/bioemco/biodiversite/edeline.html
> 



From laf.nilsson at gmail.com  Sat Nov 27 23:54:24 2010
From: laf.nilsson at gmail.com (Fredrik Nilsson)
Date: Sat, 27 Nov 2010 23:54:24 +0100
Subject: [R-sig-ME] large data set implies rejection of null?
In-Reply-To: <AANLkTimbUmG5yaf_JKiseBzyyz9EJmchj6ieE2MU0PrN@mail.gmail.com>
References: <AANLkTimbUmG5yaf_JKiseBzyyz9EJmchj6ieE2MU0PrN@mail.gmail.com>
Message-ID: <AANLkTimd14g=ncOOboMHPU+2m3frnyjwRJP5nyP7GRaQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101127/c1304204/attachment.pl>

From john.maindonald at anu.edu.au  Sun Nov 28 00:01:23 2010
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Sun, 28 Nov 2010 10:01:23 +1100
Subject: [R-sig-ME] Non normal random effects
In-Reply-To: <4CF0FD05.7060501@biologie.ens.fr>
References: <4CF012CF.7080700@biologie.ens.fr>
	<3131A41F-6AA4-4ACC-9A18-DCC9A36F2485@anu.edu.au>
	<4CF0FD05.7060501@biologie.ens.fr>
Message-ID: <EAC4B6D4-8E09-4343-83C6-64B6C5B6F6DD@anu.edu.au>

You can have this sort of situation:
'Normal' effect                       .                                       .                                  .
Observations                   .. .  .  .    .                        ..  .    .    .                      ..  .    .     .

The large contribution from the random effect means that,
until it is accounted for, you will not see the non-normality.
                                                                              ~~~~~~~~~~~

[For the extreme case that is illustrated, "skewness" perhaps
rather than "non-normality".    But if the contribution from the
random effect is somewhat weaker, overlap between points 
that correspond to the successive sets of non-normally 
distributed residuals will indeed lead to a distribution that, in 
practice, will be quite hard to distinguish from normal.  
Non-normality at the level of the residuals may or may not 
matter, depending on what it does to the sampling distributions 
that are relevant to the intended inferences.]

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 27/11/2010, at 11:43 PM, Eric Edeline wrote:

> Dear John,
> 
> thanks for your feed back and for the useful tutorial. Actually the random effect in question is normally distributed (I did not check before, sorry), so the problem comes from somewhere else. I am modeling fish body size from a large dataset as a function of many covariates, and adding a "species" effect (be it fixed or random) skews the residuals but drops the AIC:
> 
> m1<-lmer(log(Length) ~log(Slope)+log(Width)+Temp*log(D)+Temp*log(Compint2)+Temp*log(Predln102)+Temp*Year
> +(1|Species/Station),
> data=Data, na.action=na.omit, REML=TRUE) #AIC 73427, skewed residuals
> 
> m2<-lmer(log(Length) ~log(Slope)+log(Width)+Temp*log(D)+Temp*log(Compint2)+Temp*log(Predln102)+Temp*Year
> +(1|Station),
> data=Data, na.action=na.omit, REML=TRUE) #AIC 147157, Gaussian residuals
> 
> This looks puzzling to me. Would you have an idea for why introducing a normally distributed effect shews the residuals?
> 
> 
> 
> 
> On 11/26/2010 10:51 PM, John Maindonald wrote:
>> Contrary to what is often claimed, it is not the normality of the
>> random effects themselves that matters, but the normality of
>> the sampling distribution of the relevant fixed effect.  In mixed
>> models, there is by comparison with iid models the additional
>> complication that normality can affect the trade-offs between
>> the different components in the fitted model.   Opportunities
>> for such trade-offs are large if there are several random effects
>> and there is imbalance or incompleteness (some combinations
>> of factor levels missing) in the fixed effects structure.  Non-normality
>> in the random effects can then be both hard to detect and have
>> implications for inference.
>> 
>> There is an examination of a data set with a relatively complicated
>> random effects structure in the overheads at:
>> http://www.maths.anu.edu.au/%7Ejohnm/r-book/2edn/xtras/mlm-ohp.pdf
>> 
>> John Maindonald             email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Mathematics&  Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>> http://www.maths.anu.edu.au/~johnm
>> 
>> On 27/11/2010, at 7:04 AM, Eric Edeline wrote:
>> 
>> 
>>> Dear list,
>>> 
>>> is non normality of random effects a serious issue for inference on the fixed effects? I am having a non normal random effect that tremendously improves model AIC.
>>> 
>>> Thanks!
>>> 
>>> -- 
>>> Eric Edeline
>>> Assistant Professor
>>> UPMC-Paris6
>>> UMR 7618 BIOEMCO
>>> Ecole Normale Sup?rieure
>>> 46 rue d'Ulm
>>> 75230 Paris cedex 05
>>> France
>>> 
>>> Tel: +33 (0)1 44 32 38 84
>>> Fax: +33 (0)1 44 32 38 85
>>> 
>>> http://www.biologie.ens.fr/bioemco/biodiversite/edeline.html
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>> 
> 
> -- 
> Eric Edeline
> Assistant Professor
> UPMC-Paris6
> UMR 7618 BIOEMCO
> Ecole Normale Sup?rieure
> 46 rue d'Ulm
> 75230 Paris cedex 05
> France
> 
> Tel: +33 (0)1 44 32 38 84
> Fax: +33 (0)1 44 32 38 85
> 
> http://www.biologie.ens.fr/bioemco/biodiversite/edeline.html
> 



From laf.nilsson at gmail.com  Sun Nov 28 09:26:57 2010
From: laf.nilsson at gmail.com (Fredrik Nilsson)
Date: Sun, 28 Nov 2010 09:26:57 +0100
Subject: [R-sig-ME] large data set implies rejection of null?
In-Reply-To: <AANLkTimbUmG5yaf_JKiseBzyyz9EJmchj6ieE2MU0PrN@mail.gmail.com>
References: <AANLkTimbUmG5yaf_JKiseBzyyz9EJmchj6ieE2MU0PrN@mail.gmail.com>
Message-ID: <AANLkTimrXR2mohH_G1NLnnBqBeuBADJ=oyrXSFBHMqN9@mail.gmail.com>

No. The thing to observe is, that we are dealing with continuous
outcomes (the distribution of the mean is approximately normal
distributed) and if you compare two *different* populations then their
difference is *exactly* equal to zero with probability 0. That is if
you really have two different populations then it is improbable that
their means are exactly the same.

So this is not a guideline it's a fact. The key is that when you
increase the number of samples then you increase your precision of the
mean and when the precision is high enough then you will be able to
detect even the tiniest difference given that there is a difference
and since we know that, if the populations are different, the means
differ almost surely the result follows.

What I mean here is that if you, for instance, have two different
machines producing chewing gums and mean weight of the ones from  the
first is 5.00000... grams and the the mean from the ones from the
second machine is 5.00012..... grams then you would with large enough
samples from each machine be able to tell that there is indeed a
difference. But suppose that the standard deviation in weight per
chewing gum is 0.05 grams then the small difference in mean weight
would not influence your chewing gum experience, since the difference
between two items ,either from the same or different machines, is so
large. That's why it is relevant to think in relevant differences.
Note that I am not saying that the individual observations are
normally distributed.

Now one could say that this is frequentist mumbo jumbo since the
machines will not have a constant mean due to wear etc. But it is
important when one wishes to show that a difference is neglible e.g.
when comparing two different producers making the same pill
(equivalence trials/bioequivalence). One has to define how small
neglible is to begin with.

No statistician will say that if you compared two samples from the
same populations then their difference would be significant with
probability close to 1 if only the sample is large enough, which is
what you are trying to show when comparing dat.1 and dat.2 (their
means are exactly equal).

Best regards,
Fredrik Nilsson


2010/11/27 Daniel Ezra Johnson <danielezrajohnson at gmail.com>
>
> On 11/24/10 07:59, Rolf Turner wrote:
> > >>
> > >> It is well known amongst statisticians that having a large enough data set will
> > >> result in the rejection of *any* null hypothesis, i.e. will result in a small
> > >> p-value.
>
> This seems to be a well-accepted guideline, probably because in the
> social sciences, usually, none of the predictors truly has an effect
> size of zero.
> However, unless I am misunderstanding it, the statement appears to me
> to be more generally false.
> For example, when the population difference of means actually equals
> zero, in a t-test, very large sample sizes do not lead to small
> p-values.
>
> set.seed(1)
> n <- 1000000 ?# 10^6
> dat.1 <- rnorm(n/2,0,1)
> dat.2 <- rnorm(n/2,0,1)
> t.test(dat.1,dat.2,var.equal=T)
> # p = 0.60
>
> set.seed(1)
> n <- 10000000 ?# 10^7
> dat.1 <- rnorm(n/2,0,1)
> dat.2 <- rnorm(n/2,0,1)
> t.test(dat.1,dat.2,var.equal=T)
> # p = 0.48
>
> set.seed(1)
> n <- 100000000 ?# 10^8
> dat.1 <- rnorm(n/2,0,1)
> dat.2 <- rnorm(n/2,0,1)
> t.test(dat.1,dat.2,var.equal=T)
> # p = 0.80
>
> Such results - where the null hypothesis is NOT rejected - would
> presumably also occur in any experimental situations where the null
> hypothesis was literally true, regardless of the size of the data set.
> No?
>
> Daniel
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From edeline at biologie.ens.fr  Sun Nov 28 12:27:46 2010
From: edeline at biologie.ens.fr (Eric Edeline)
Date: Sun, 28 Nov 2010 12:27:46 +0100
Subject: [R-sig-ME] Non normal random effects
In-Reply-To: <EAC4B6D4-8E09-4343-83C6-64B6C5B6F6DD@anu.edu.au>
References: <4CF012CF.7080700@biologie.ens.fr>
	<3131A41F-6AA4-4ACC-9A18-DCC9A36F2485@anu.edu.au>
	<4CF0FD05.7060501@biologie.ens.fr>
	<EAC4B6D4-8E09-4343-83C6-64B6C5B6F6DD@anu.edu.au>
Message-ID: <4CF23CB2.1060804@biologie.ens.fr>

Dear John,

thanks a lot for your reply. For some reason part of your message 
(illustrations of distributions seemingly) comes up corrupted. Although 
I got the essence of your explanation, I would very much like having it 
in full. Could you send illustrations in another format?

eric

On 11/28/2010 12:01 AM, John Maindonald wrote:
> You can have this sort of situation:
> 'Normal' effect                       .                                       .                                  .
> Observations                   .. .  .  .    .                        ..  .    .    .                      ..  .    .     .
>
> The large contribution from the random effect means that,
> until it is accounted for, you will not see the non-normality.
>                                                                                ~~~~~~~~~~~
>
> [For the extreme case that is illustrated, "skewness" perhaps
> rather than "non-normality".    But if the contribution from the
> random effect is somewhat weaker, overlap between points
> that correspond to the successive sets of non-normally
> distributed residuals will indeed lead to a distribution that, in
> practice, will be quite hard to distinguish from normal.
> Non-normality at the level of the residuals may or may not
> matter, depending on what it does to the sampling distributions
> that are relevant to the intended inferences.]
>
> John Maindonald             email:john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics&  Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> http://www.maths.anu.edu.au/~johnm
>
> On 27/11/2010, at 11:43 PM, Eric Edeline wrote:
>
>    
>> Dear John,
>>
>> thanks for your feed back and for the useful tutorial. Actually the random effect in question is normally distributed (I did not check before, sorry), so the problem comes from somewhere else. I am modeling fish body size from a large dataset as a function of many covariates, and adding a "species" effect (be it fixed or random) skews the residuals but drops the AIC:
>>
>> m1<-lmer(log(Length) ~log(Slope)+log(Width)+Temp*log(D)+Temp*log(Compint2)+Temp*log(Predln102)+Temp*Year
>> +(1|Species/Station),
>> data=Data, na.action=na.omit, REML=TRUE) #AIC 73427, skewed residuals
>>
>> m2<-lmer(log(Length) ~log(Slope)+log(Width)+Temp*log(D)+Temp*log(Compint2)+Temp*log(Predln102)+Temp*Year
>> +(1|Station),
>> data=Data, na.action=na.omit, REML=TRUE) #AIC 147157, Gaussian residuals
>>
>> This looks puzzling to me. Would you have an idea for why introducing a normally distributed effect shews the residuals?
>>
>>
>>
>>
>> On 11/26/2010 10:51 PM, John Maindonald wrote:
>>      
>>> Contrary to what is often claimed, it is not the normality of the
>>> random effects themselves that matters, but the normality of
>>> the sampling distribution of the relevant fixed effect.  In mixed
>>> models, there is by comparison with iid models the additional
>>> complication that normality can affect the trade-offs between
>>> the different components in the fitted model.   Opportunities
>>> for such trade-offs are large if there are several random effects
>>> and there is imbalance or incompleteness (some combinations
>>> of factor levels missing) in the fixed effects structure.  Non-normality
>>> in the random effects can then be both hard to detect and have
>>> implications for inference.
>>>
>>> There is an examination of a data set with a relatively complicated
>>> random effects structure in the overheads at:
>>> http://www.maths.anu.edu.au/%7Ejohnm/r-book/2edn/xtras/mlm-ohp.pdf
>>>
>>> John Maindonald             email:john.maindonald at anu.edu.au
>>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>>> Centre for Mathematics&   Its Applications, Room 1194,
>>> John Dedman Mathematical Sciences Building (Building 27)
>>> Australian National University, Canberra ACT 0200.
>>> http://www.maths.anu.edu.au/~johnm
>>>
>>> On 27/11/2010, at 7:04 AM, Eric Edeline wrote:
>>>
>>>
>>>        
>>>> Dear list,
>>>>
>>>> is non normality of random effects a serious issue for inference on the fixed effects? I am having a non normal random effect that tremendously improves model AIC.
>>>>
>>>> Thanks!
>>>>
>>>> -- 
>>>> Eric Edeline
>>>> Assistant Professor
>>>> UPMC-Paris6
>>>> UMR 7618 BIOEMCO
>>>> Ecole Normale Sup?rieure
>>>> 46 rue d'Ulm
>>>> 75230 Paris cedex 05
>>>> France
>>>>
>>>> Tel: +33 (0)1 44 32 38 84
>>>> Fax: +33 (0)1 44 32 38 85
>>>>
>>>> http://www.biologie.ens.fr/bioemco/biodiversite/edeline.html
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org  mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>>          
>>>        
>> -- 
>> Eric Edeline
>> Assistant Professor
>> UPMC-Paris6
>> UMR 7618 BIOEMCO
>> Ecole Normale Sup?rieure
>> 46 rue d'Ulm
>> 75230 Paris cedex 05
>> France
>>
>> Tel: +33 (0)1 44 32 38 84
>> Fax: +33 (0)1 44 32 38 85
>>
>> http://www.biologie.ens.fr/bioemco/biodiversite/edeline.html
>>
>>      
>    

-- 
Eric Edeline
Assistant Professor
UPMC-Paris6
UMR 7618 BIOEMCO
Ecole Normale Sup?rieure
46 rue d'Ulm
75230 Paris cedex 05
France

Tel: +33 (0)1 44 32 38 84
Fax: +33 (0)1 44 32 38 85

http://www.biologie.ens.fr/bioemco/biodiversite/edeline.html



From chris at trickysolutions.com.au  Mon Nov 29 01:17:29 2010
From: chris at trickysolutions.com.au (Chris Howden)
Date: Mon, 29 Nov 2010 09:47:29 +0930
Subject: [R-sig-ME] problem using geeglm: R keeps crashing
Message-ID: <64dbfdb2ded3e91631701a17894528d3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101129/6da1494d/attachment.pl>

From bbolker at gmail.com  Mon Nov 29 02:06:22 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 28 Nov 2010 20:06:22 -0500
Subject: [R-sig-ME] problem using geeglm: R keeps crashing
In-Reply-To: <64dbfdb2ded3e91631701a17894528d3@mail.gmail.com>
References: <64dbfdb2ded3e91631701a17894528d3@mail.gmail.com>
Message-ID: <4CF2FC8E.8060403@gmail.com>


On 10-11-28 07:17 PM, Chris Howden wrote:
> 
> (sorry if this has posted before, I?ve sent it twice but because I haven?t
> received a copy or any replies it appears that it?s not getting onto the
> list)

 It has showed up (I think three times including this one): you can
always check the archive at
<https://stat.ethz.ch/pipermail/r-sig-mixed-models/> to see if your
messages get through).

> I?m using geeglm to do a resource function analysis on some dingo radio
> collar data. When I try to fit the following  model R crashes and I get the
> following error message (I?m actually running R through ESS, just in case
> that?s relevant)
> 
>>  fit.geeglm <- geeglm(resp~rubbish, data=data, id=dogname,
> family=binomial, corstr="exchangeable")
> 
> ?This application has requested the Runtime to terminate it in an unusual
> way.
> 
> Please contact the application's support team for more information.?
>
> I?m also getting a Microsoft Windows pop up that says:
> 
> "R for Windows terminal front-end has stopped working"
> 
> A problem caused the program to stop working correctly.
> 
> Windows will close the program and notify you if a solution is available "

  In general if a package crashes R, that by definition constitutes a
bug in the package and should be reported to the maintainers -- but see
below ...

> The weird thing is that if I reorder my data the model seems to fit OK. I
> can reorder the data and run a model as follows:
> 
>>  sample <- data[sample(93948,93948),]  # (my data has 93948 rows)
> 
>> fit.geeglm
> <-geeglm(resp~rubbish,data=sample,id=dogname,family=binomial,corstr="exchangeable")
> 
> My understanding of the corstr="exchangeable" correlation structure in
> geeglm() is that it assumes equal correlation amongst all data points for
> each dingo?.so I can?t see why reordering the data changes anything?.if I
> was fitting something like an AR(1) model then I can see why reordering
> changes things?.
> 
> One reason I have considered is that geeglm() actually fits a correlation
> structure for each *block *of* *id?s, rather than for all id?s?  For
> example, if my data set had the following id structure id1, id1, id1, id2,
> id2, id1, id1. Then it would fit 1 correlation structure to the first set of
> id1?s and then a different correlation structure to the second set of id1?s?
> Rather than fitting a single correlation structure to id1?

Based on my reading of ?geeglm, and this note under the "id" argument
description: "Data are assumed to be sorted so that observations on a
cluster are contiguous rows for all entities in the formula."  Thus I
would not be surprised if the example you give above failed, because it
violates the rules laid out in the documentation (on the other hand,
this is pretty easy to check and it would be wise for the package
authors to make their code a bit more "fool-resistant" by checking for
this condition and throwing an error if the elements aren't properly
sorted).
  You can easily sort your observations by id to make them conform to
the rules, or, if you want to fit each contiguous block separately, you
can use something like

factor(c(0,cumsum(diff(as.numeric(id))!=0)))

to generate a new id variable that identifies contiguous blocks.
 Given all this it seems really surprising that geeglm works with
permuted data.  Does it work consistently (say 10 or 20 times in a row)
and give the same answers for different permutations ... ? Maybe you
just got lucky.

  (It would also seem pretty dicey to me to run a random effects model
with only 4 levels (animals), although if you do want to use 'bout'
(contiguous block) as the id variable you will have a lot more levels ...)

> 
> Does anyone have any suggestions on why this is happening??? And what I can
> do to get the model to run?
> 
> My fall back model is to use glmer with random intercepts, but I really want
> to use gee since it?s a marginal model and gives me robust SE?s.
> 
> Thanks for any ideas
> 
> The following is some more info that may be relevant:
> 
> For those unfamiliar with this type of resource function analysis it is
> conceptually *similar* to a case control study. The ?used? resource units
> being the cases and coming from the radio collared telemetry data. The
> ?available? resource units are the controls and are randomly sampled from
> the home range of each dingo (I have sampled 5 controls for each case). The
> resource units are 40 by 40 m pixels from a GIS.
> 
> I have data for 4 dingos. It has 93948 rows and 9 variables. The first 1/6
> of my data is the radio collar data ?case? or ?used resource units? (so
> resp=1) and the next 5/6 of my data is the ?control? or ?available resource
> units? (so resp =0).



From geralttee at gmail.com  Mon Nov 29 02:14:35 2010
From: geralttee at gmail.com (Szymek Drobniak)
Date: Mon, 29 Nov 2010 02:14:35 +0100
Subject: [R-sig-ME] MCMCglmm question
Message-ID: <AANLkTi=GmOEGr_mb3hR_ToKGogieEECn4py5e62Hfm84@mail.gmail.com>

Hi,

I've been a bit confused by different wyas we specify random effects
in lmer and MCMCglmm i just want to clear something. When I want to
look for  intersexual genetic correlations in the trait, is it
equivalent to treat this trait for opposite sexes as separate traits
and include the term idh(trait):animal - to treating this as a single
trait and fitting idh(sex):animal? Do these two ways of specyfying
random effects differ in this case? Are the calculations of rG correct
in the second case?

Cheers,
sz.



From chris at trickysolutions.com.au  Mon Nov 29 05:57:32 2010
From: chris at trickysolutions.com.au (Chris Howden)
Date: Mon, 29 Nov 2010 14:27:32 +0930
Subject: [R-sig-ME] problem using geeglm: R keeps crashing
In-Reply-To: <4CF2FC8E.8060403@gmail.com>
References: <64dbfdb2ded3e91631701a17894528d3@mail.gmail.com>
	<4CF2FC8E.8060403@gmail.com>
Message-ID: <55243b6f3b46cb660633fe556e4b268f@mail.gmail.com>

Thanks for the reply Ben,

(And sorry for sending the same email 3 times everyone. I'm on other R
lists where I receive a copy of my sent posts. And I also logged onto the
r-sig-models admin site to confirm my settings are set so I receive copies
of emails I send to the list. So not sure why I didn't receive them.)

Sorting the id's doesn't help, R still crashes.

What's interesting is that permutating the data actually makes geeglm()
fit a model, while it is incapable of doing so on the correct id sorted
data. (As U suggested I have run it again a number of times and get
similar results each time. The model estimates are also quite similar to a
standard GLM)

Looking at the summary() results for the permutated data model has given
me a clue as to why a model can be fit to the permutated data, but not the
'correct' data. The permutated model has fit 68987 clusters, which is
incorrect since there should only be 4 (1 for each dog)

I suspect the problem here is that geeglm cannot fit an "exchangeable"
correlation structure to such large blocks of data (the smallest of which
has 24000 rows).

PS: I was wondering why u think it is dicey to run a random effects model
with only 4 levels. If I only have 4 individuals then I only have 4
levels.

Chris Howden
Founding Partner
Tricky Solutions
Tricky Solutions 4 Tricky Problems
Evidence Based Strategic Development, IP Commercialisation and Innovation,
Data Analysis, Modelling, and Training
(mobile) 0410 689 945
(fax / office) (+618) 8952 7878
chris at trickysolutions.com.au

-----Original Message-----
From: Ben Bolker [mailto:bbolker at gmail.com]
Sent: Monday, 29 November 2010 10:36 AM
To: r-sig-mixed-models at r-project.org; Chris Howden
Subject: Re: [R-sig-ME] problem using geeglm: R keeps crashing


On 10-11-28 07:17 PM, Chris Howden wrote:
>
> (sorry if this has posted before, I've sent it twice but because I
haven't
> received a copy or any replies it appears that it's not getting onto the
> list)

 It has showed up (I think three times including this one): you can
always check the archive at
<https://stat.ethz.ch/pipermail/r-sig-mixed-models/> to see if your
messages get through).

> I'm using geeglm to do a resource function analysis on some dingo radio
> collar data. When I try to fit the following  model R crashes and I get
the
> following error message (I'm actually running R through ESS, just in
case
> that's relevant)
>
>>  fit.geeglm <- geeglm(resp~rubbish, data=data, id=dogname,
> family=binomial, corstr="exchangeable")
>
> "This application has requested the Runtime to terminate it in an
unusual
> way.
>
> Please contact the application's support team for more information."
>
> I'm also getting a Microsoft Windows pop up that says:
>
> "R for Windows terminal front-end has stopped working"
>
> A problem caused the program to stop working correctly.
>
> Windows will close the program and notify you if a solution is available
"

  In general if a package crashes R, that by definition constitutes a
bug in the package and should be reported to the maintainers -- but see
below ...

> The weird thing is that if I reorder my data the model seems to fit OK.
I
> can reorder the data and run a model as follows:
>
>>  sample <- data[sample(93948,93948),]  # (my data has 93948 rows)
>
>> fit.geeglm
>
<-geeglm(resp~rubbish,data=sample,id=dogname,family=binomial,corstr="excha
ngeable")
>
> My understanding of the corstr="exchangeable" correlation structure in
> geeglm() is that it assumes equal correlation amongst all data points
for
> each dingo..so I can't see why reordering the data changes anything..if
I
> was fitting something like an AR(1) model then I can see why reordering
> changes things..
>
> One reason I have considered is that geeglm() actually fits a
correlation
> structure for each *block *of* *id's, rather than for all id's?  For
> example, if my data set had the following id structure id1, id1, id1,
id2,
> id2, id1, id1. Then it would fit 1 correlation structure to the first
set of
> id1's and then a different correlation structure to the second set of
id1's?
> Rather than fitting a single correlation structure to id1?

Based on my reading of ?geeglm, and this note under the "id" argument
description: "Data are assumed to be sorted so that observations on a
cluster are contiguous rows for all entities in the formula."  Thus I
would not be surprised if the example you give above failed, because it
violates the rules laid out in the documentation (on the other hand,
this is pretty easy to check and it would be wise for the package
authors to make their code a bit more "fool-resistant" by checking for
this condition and throwing an error if the elements aren't properly
sorted).
  You can easily sort your observations by id to make them conform to
the rules, or, if you want to fit each contiguous block separately, you
can use something like

factor(c(0,cumsum(diff(as.numeric(id))!=0)))

to generate a new id variable that identifies contiguous blocks.
 Given all this it seems really surprising that geeglm works with
permuted data.  Does it work consistently (say 10 or 20 times in a row)
and give the same answers for different permutations ... ? Maybe you
just got lucky.

  (It would also seem pretty dicey to me to run a random effects model
with only 4 levels (animals), although if you do want to use 'bout'
(contiguous block) as the id variable you will have a lot more levels ...)

>
> Does anyone have any suggestions on why this is happening??? And what I
can
> do to get the model to run?
>
> My fall back model is to use glmer with random intercepts, but I really
want
> to use gee since it's a marginal model and gives me robust SE's.
>
> Thanks for any ideas
>
> The following is some more info that may be relevant:
>
> For those unfamiliar with this type of resource function analysis it is
> conceptually *similar* to a case control study. The "used" resource
units
> being the cases and coming from the radio collared telemetry data. The
> "available" resource units are the controls and are randomly sampled
from
> the home range of each dingo (I have sampled 5 controls for each case).
The
> resource units are 40 by 40 m pixels from a GIS.
>
> I have data for 4 dingos. It has 93948 rows and 9 variables. The first
1/6
> of my data is the radio collar data "case" or "used resource units" (so
> resp=1) and the next 5/6 of my data is the "control" or "available
resource
> units" (so resp =0).



From sjreilly1 at gmail.com  Mon Nov 29 08:04:11 2010
From: sjreilly1 at gmail.com (Sarah Reilly)
Date: Mon, 29 Nov 2010 01:04:11 -0600
Subject: [R-sig-ME] LMER problem when all observations in one level are zero?
Message-ID: <AANLkTikX66AEkZEc5+woBBwqDmLoFOQUeSPVb45UUL_E@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101129/99d32fff/attachment.pl>

From Thierry.ONKELINX at inbo.be  Mon Nov 29 10:34:02 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 29 Nov 2010 10:34:02 +0100
Subject: [R-sig-ME] LMER problem when all observations in one level are
	zero?
In-Reply-To: <AANLkTikX66AEkZEc5+woBBwqDmLoFOQUeSPVb45UUL_E@mail.gmail.com>
References: <AANLkTikX66AEkZEc5+woBBwqDmLoFOQUeSPVb45UUL_E@mail.gmail.com>
Message-ID: <3DB16098F738284D8DBEB2FC3699163850E2F4@inboexch.inbo.be>

Dear Sarah,

The problem might be due to the perfect, negative correlation between
some of the fixed effects. Refitting your model without intercept might
reduce that effect.

Also note that the standard errors of the fixed effects are huge.

Best regards,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Sarah Reilly
> Verzonden: maandag 29 november 2010 8:04
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] LMER problem when all observations in 
> one level are zero?
> 
> Hello,
> 
> We are analyzing data on the number of insects of certain 
> species on individual plants.  There are 3 species of plants 
> (fixed effect) nested within 8 different sites (random 
> effect).  We have structured the model as follows, after 
> tentatively dropping the intercept of site:
> 
> >lmer(insects ~ plantsp + (0+ plantsp|site) , family = 
> poisson, REML = 
> >TRUE
> )
> 
> We then went on to do contrasts between levels of the fixed effect:
> 
> >glht(bestmod, linfct = mcp(plantsp = "Tukey"))
> 
> This seems to work ok for some contrasts, but not others.  In 
> particular, sometimes we have the situation where an insect 
> was not found at all on one particular plant species (hence 
> all observations are 0 for that level of the
> fixed effect).   This returns the unsatisfactory result that 
> the level with
> the highest mean is different from the level with the 
> intermediate mean, but not at all different from the level 
> with the low (i.e. 0) mean.  Furthermore, adding a single 
> insect to a random plant within the all 0s group makes all 
> the contrasts highly significant.  The data are overdispersed 
> and zero-inflated but that doesn't seem to be responsible for 
> this particular problem.  We may end up using MCMCglmm but we 
> still would like to understand why this is happening in LMER.
> 
> Thanks for your assistance,
> 
> Sarah
> 
> Here are the results from a test where this happens:
> 
> Generalized linear mixed model fit by the Laplace approximation
> 
> Formula: insects ~ plantsp + (0 + plantsp | site)
> 
>   AIC  BIC logLik deviance
> 
>  1002 1042 -491.9    983.9
> 
> Random effects:
> 
>  Groups Name      Variance Std.Dev. Corr
> 
>  site   plantspTA 0.13088  0.36177
> 
>         plantspTG 1.81646  1.34776  0.000
> 
>         plantspTL 1.62193  1.27355  0.000 0.325
> 
> Number of obs: 626, groups: site, 8
> 
> Fixed effects:
> 
>             Estimate Std. Error z value Pr(>|z|)
> 
> (Intercept)   -18.71     907.10  -0.021    0.984
> 
> plantspTG      16.97     907.10   0.019    0.985
> 
> plantspTL      19.10     907.10   0.021    0.983
> 
> Correlation of Fixed Effects:
> 
>           (Intr) plntTG
> 
> plantspTG -1.000
> 
> plantspTL -1.000  1.000
> 
> 
> 
> Simultaneous Tests for General Linear Hypotheses
> 
> Multiple Comparisons of Means: Tukey Contrasts
> 
> Fit: glmer(formula = insects ~ plantsp + (0 + plantsp | 
> site), family = poisson,
> 
>     REML = TRUE)
> 
> Linear Hypotheses:
> 
>              Estimate Std. Error z value Pr(>|z|)
> 
> TG - TA == 0  16.9673   907.1004   0.019 0.999777
> 
> TL - TA == 0  19.1032   907.1003   0.021 0.999718
> 
> TL - TG == 0   2.1358     0.6068   3.520 0.000864 ***
> 
> ---
> 
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> 
> (Adjusted p values reported -- single-step method)
> 
> 	[[alternative HTML version deleted]]
> 
> 



From john.maindonald at anu.edu.au  Mon Nov 29 10:44:43 2010
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Mon, 29 Nov 2010 20:44:43 +1100
Subject: [R-sig-ME] LMER problem when all observations in one level are
	zero?
In-Reply-To: <AANLkTikX66AEkZEc5+woBBwqDmLoFOQUeSPVb45UUL_E@mail.gmail.com>
References: <AANLkTikX66AEkZEc5+woBBwqDmLoFOQUeSPVb45UUL_E@mail.gmail.com>
Message-ID: <4955FF55-F093-49BE-A18E-CDDD6A75198E@anu.edu.au>

You have to use the likelihood ratio statistic to make comparisons 
between other levels and the level where observations are zero.  
The Wald statistic approximation  typically (or always?) breaks 
down in this situation.  This is related to the Hauck-Donner effect, 
which is more commonly discussed in connection with binomilal 
or quasi-binomial data.  You might run the example code for the
moths dataset in the DAAG package.

Hope this helps

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 29/11/2010, at 6:04 PM, Sarah Reilly wrote:

> Hello,
> 
> We are analyzing data on the number of insects of certain species on
> individual plants.  There are 3 species of plants (fixed effect) nested
> within 8 different sites (random effect).  We have structured the model as
> follows, after tentatively dropping the intercept of site:
> 
>> lmer(insects ~ plantsp + (0+ plantsp|site) , family = poisson, REML = TRUE
> )
> 
> We then went on to do contrasts between levels of the fixed effect:
> 
>> glht(bestmod, linfct = mcp(plantsp = "Tukey"))
> 
> This seems to work ok for some contrasts, but not others.  In particular,
> sometimes we have the situation where an insect was not found at all on one
> particular plant species (hence all observations are 0 for that level of the
> fixed effect).   This returns the unsatisfactory result that the level with
> the highest mean is different from the level with the intermediate mean, but
> not at all different from the level with the low (i.e. 0) mean.  Furthermore,
> adding a single insect to a random plant within the all 0s group makes all
> the contrasts highly significant.  The data are overdispersed and
> zero-inflated but that doesn?t seem to be responsible for this particular
> problem.  We may end up using MCMCglmm but we still would like to understand
> why this is happening in LMER.
> 
> Thanks for your assistance,
> 
> Sarah
> 
> Here are the results from a test where this happens:
> 
> Generalized linear mixed model fit by the Laplace approximation
> 
> Formula: insects ~ plantsp + (0 + plantsp | site)
> 
> AIC  BIC logLik deviance
> 
> 1002 1042 -491.9    983.9
> 
> Random effects:
> 
> Groups Name      Variance Std.Dev. Corr
> 
> site   plantspTA 0.13088  0.36177
> 
>       plantspTG 1.81646  1.34776  0.000
> 
>       plantspTL 1.62193  1.27355  0.000 0.325
> 
> Number of obs: 626, groups: site, 8
> 
> Fixed effects:
> 
>           Estimate Std. Error z value Pr(>|z|)
> 
> (Intercept)   -18.71     907.10  -0.021    0.984
> 
> plantspTG      16.97     907.10   0.019    0.985
> 
> plantspTL      19.10     907.10   0.021    0.983
> 
> Correlation of Fixed Effects:
> 
>         (Intr) plntTG
> 
> plantspTG -1.000
> 
> plantspTL -1.000  1.000
> 
> 
> 
> Simultaneous Tests for General Linear Hypotheses
> 
> Multiple Comparisons of Means: Tukey Contrasts
> 
> Fit: glmer(formula = insects ~ plantsp + (0 + plantsp | site), family =
> poisson,
> 
>   REML = TRUE)
> 
> Linear Hypotheses:
> 
>            Estimate Std. Error z value Pr(>|z|)
> 
> TG - TA == 0  16.9673   907.1004   0.019 0.999777
> 
> TL - TA == 0  19.1032   907.1003   0.021 0.999718
> 
> TL - TG == 0   2.1358     0.6068   3.520 0.000864 ***
> 
> ---
> 
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> (Adjusted p values reported -- single-step method)
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From betinig at uoguelph.ca  Mon Nov 29 16:02:45 2010
From: betinig at uoguelph.ca (Gustavo Betini)
Date: Mon, 29 Nov 2010 10:02:45 -0500 (EST)
Subject: [R-sig-ME] Non normal random effects
In-Reply-To: <AANLkTik5F9E8h_q6anVhn48BfnSBCwCceFGBciT0esG6@mail.gmail.com>
Message-ID: <853590539.831991.1291042965811.JavaMail.root@erie.cs.uoguelph.ca>

Lets say that I want to look at the interaction between Species and some other variable...Temperature. The right specification would be 

(Temperature|Species) + (Temperature|Station:Species) 

or simply 

(1|Species) + (Temperature|Station:Species) 

Thanks, 

Gustavo S. Betini 
Dept. of Integrative Biology 
University of Guelph, Canada 




On 10-11-27 12:04 PM, Douglas Bates wrote: 


Just in terms of the model specification, do you really mean
(1|Species/Station)?  That expands to

 (1|Species) + (1|Species:Station)

and wouldn't reduce to (1|Station) in a model specification.  I think
you meant "species within station", which would be written as
(1|Station/Species) although I prefer the more explicit form
(1|Station) + (1|Station:Species)



From statslearner at gmail.com  Mon Nov 29 16:26:58 2010
From: statslearner at gmail.com (Lucas Kid)
Date: Mon, 29 Nov 2010 10:26:58 -0500
Subject: [R-sig-ME] multicolinearity?
Message-ID: <AANLkTi=QPVsmMDseiT0LTjDOz7oUZFB_Q+S_Xdes5m=C@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101129/7a80d69f/attachment.pl>

From bbolker at gmail.com  Mon Nov 29 16:28:32 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 29 Nov 2010 10:28:32 -0500
Subject: [R-sig-ME] LMER problem when all observations in one level are
 zero?
In-Reply-To: <AANLkTikX66AEkZEc5+woBBwqDmLoFOQUeSPVb45UUL_E@mail.gmail.com>
References: <AANLkTikX66AEkZEc5+woBBwqDmLoFOQUeSPVb45UUL_E@mail.gmail.com>
Message-ID: <4CF3C6A0.1060702@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

   I think this may be the Hauck-Donner effect ... ?  You can see a
brief (one-paragraph) discussion of this in MASS (Venables & Ripley) p.
198-199 by searching "Hauck-Donner effect" in Google books ...


On 11/29/2010 02:04 AM, Sarah Reilly wrote:
> Hello,
> 
> We are analyzing data on the number of insects of certain species on
> individual plants.  There are 3 species of plants (fixed effect) nested
> within 8 different sites (random effect).  We have structured the model as
> follows, after tentatively dropping the intercept of site:
> 
>> lmer(insects ~ plantsp + (0+ plantsp|site) , family = poisson, REML = TRUE
> )
> 
> We then went on to do contrasts between levels of the fixed effect:
> 
>> glht(bestmod, linfct = mcp(plantsp = "Tukey"))
> 
> This seems to work ok for some contrasts, but not others.  In particular,
> sometimes we have the situation where an insect was not found at all on one
> particular plant species (hence all observations are 0 for that level of the
> fixed effect).   This returns the unsatisfactory result that the level with
> the highest mean is different from the level with the intermediate mean, but
> not at all different from the level with the low (i.e. 0) mean.  Furthermore,
> adding a single insect to a random plant within the all 0s group makes all
> the contrasts highly significant.  The data are overdispersed and
> zero-inflated but that doesn?t seem to be responsible for this particular
> problem.  We may end up using MCMCglmm but we still would like to understand
> why this is happening in LMER.
> 
> Thanks for your assistance,
> 
> Sarah
> 
> Here are the results from a test where this happens:
> 
> Generalized linear mixed model fit by the Laplace approximation
> 
> Formula: insects ~ plantsp + (0 + plantsp | site)
> 
>   AIC  BIC logLik deviance
> 
>  1002 1042 -491.9    983.9
> 
> Random effects:
> 
>  Groups Name      Variance Std.Dev. Corr
> 
>  site   plantspTA 0.13088  0.36177
> 
>         plantspTG 1.81646  1.34776  0.000
> 
>         plantspTL 1.62193  1.27355  0.000 0.325
> 
> Number of obs: 626, groups: site, 8
> 
> Fixed effects:
> 
>             Estimate Std. Error z value Pr(>|z|)
> 
> (Intercept)   -18.71     907.10  -0.021    0.984
> 
> plantspTG      16.97     907.10   0.019    0.985
> 
> plantspTL      19.10     907.10   0.021    0.983
> 
> Correlation of Fixed Effects:
> 
>           (Intr) plntTG
> 
> plantspTG -1.000
> 
> plantspTL -1.000  1.000
> 
> 
> 
> Simultaneous Tests for General Linear Hypotheses
> 
> Multiple Comparisons of Means: Tukey Contrasts
> 
> Fit: glmer(formula = insects ~ plantsp + (0 + plantsp | site), family =
> poisson,
> 
>     REML = TRUE)
> 
> Linear Hypotheses:
> 
>              Estimate Std. Error z value Pr(>|z|)
> 
> TG - TA == 0  16.9673   907.1004   0.019 0.999777
> 
> TL - TA == 0  19.1032   907.1003   0.021 0.999718
> 
> TL - TG == 0   2.1358     0.6068   3.520 0.000864 ***
> 
> ---
> 
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> (Adjusted p values reported -- single-step method)
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iEYEARECAAYFAkzzxqAACgkQc5UpGjwzenMGSgCcC0iBgzvpIQvYT0LpzdNA4A1s
p0QAnRd5m85A8H1fMkwn9qTt1bKyWB+U
=4sUd
-----END PGP SIGNATURE-----



From Thierry.ONKELINX at inbo.be  Mon Nov 29 17:09:02 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 29 Nov 2010 17:09:02 +0100
Subject: [R-sig-ME] multicolinearity?
In-Reply-To: <AANLkTi=QPVsmMDseiT0LTjDOz7oUZFB_Q+S_Xdes5m=C@mail.gmail.com>
References: <AANLkTi=QPVsmMDseiT0LTjDOz7oUZFB_Q+S_Xdes5m=C@mail.gmail.com>
Message-ID: <3DB16098F738284D8DBEB2FC3699163850E4E7@inboexch.inbo.be>

Dear Lucas,

It will be probably sufficient to drop the Focus:Stimulus interaction.

m1f <- glmer(Correct ~ Months*(Focus + Stimulus) + (1|Subject),
family=binomial, data=mydataset)

You will be some NA values because stimulus is nested in focus.

Best regards,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Lucas Kid
> Verzonden: maandag 29 november 2010 16:27
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] multicolinearity?
> 
> Mixed modelers,
> 
> I have a dataset (mydataset) where subjects' (Subject) 
> responses (Correct) to a stimulus (Stimulus) was tested over 
> time (Months). There were 8 stimuli, 2 of which had focus A 
> and 6 had focus B (Focus).  At each time point, subjects were 
> tested multiple times for each stimuli.  Subject, Stimulus, 
> and Focus are all factors.
> 
> I have run model as follows:
> 
> (m1 <- glmer(Correct ~ Months*Stimulus + (1|Subject), family=binomial,
> data=mydataset))
> (m2 <- glmer(Correct ~ Months*Stimulus + (1|Subject) + (0 + Months
> |Subject), family=binomial, data=mydataset))
> (m3 <- glmer(Correct ~ Months*Stimulus + (1 + Months 
> |Subject), family=binomial, data=mydataset))
> (m4 <- glmer(Correct ~ Months*Stimulus + (1 + Months + 
> Stimulus |Subject), family=binomial, data=mydataset))
> (m5 <- glmer(Correct ~ Months*Stimulus + (1 + Months + 
> Stimulus + Months * Stimulus |Subject), family=binomial, 
> data=mydataset))
> 
> I would like to test Focus to see if, when controlling for 
> Focus, the effect of Stimulus goes away.
> 
> (m1f <- glmer(Correct ~ Months*Stimulus*Focus + (1|Subject), 
> family=binomial, data=mydataset))
> 
> However, I get the following error:
> 
> Error in asMethod(object) : matrix is not symmetric [1,2] In 
> addition: Warning message:
> In mer_finalize(ans) : gr cannot be computed at initial par (65)
> 
> I believe this is a case of multicolinearity between Focus 
> and Stimulus.
> Would that be a correct assumption?  What options do I have 
> in order to examine the relationship between Correct and 
> Stimulus/Focus in a mixed-effects situation.
> 
> I'm using version 0.999375-35 of lme4.
> 
> Thanks!
> 
> Luke
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 



From statslearner at gmail.com  Mon Nov 29 19:48:03 2010
From: statslearner at gmail.com (Lucas Kid)
Date: Mon, 29 Nov 2010 13:48:03 -0500
Subject: [R-sig-ME] multicolinearity?
In-Reply-To: <3DB16098F738284D8DBEB2FC3699163850E4E7@inboexch.inbo.be>
References: <AANLkTi=QPVsmMDseiT0LTjDOz7oUZFB_Q+S_Xdes5m=C@mail.gmail.com>
	<3DB16098F738284D8DBEB2FC3699163850E4E7@inboexch.inbo.be>
Message-ID: <AANLkTi=7H1ntVd7PpsVLNx=kz0w-4o37rrc7YyxEbp0W@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101129/622533bb/attachment.pl>

From bbolker at gmail.com  Mon Nov 29 20:02:38 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 29 Nov 2010 14:02:38 -0500
Subject: [R-sig-ME] problem using geeglm: R keeps crashing
In-Reply-To: <55243b6f3b46cb660633fe556e4b268f@mail.gmail.com>
References: <64dbfdb2ded3e91631701a17894528d3@mail.gmail.com>
	<4CF2FC8E.8060403@gmail.com>
	<55243b6f3b46cb660633fe556e4b268f@mail.gmail.com>
Message-ID: <4CF3F8CE.6050100@gmail.com>

  If the model with only 4 clusters is the one you wanted (i.e. data
sorted in id order, contiguous blocks), then I would definitely contact
the maintainers to see why it's crashing.  That is, you seem to be
following the rules laid out in the documentation, so it shouldn't crash.

  The reason it's dicey to run a RE model with only 4 levels is that you
are in effect trying to estimate a variance from 4 observations, which
tends to be very inaccurate/unstable.  Since you apparently have very
large quantities of data per individual, I would expect you to get
approximately the same answers if you just treated individuals as a
fixed effect (although admittedly the model is philosophically different).

  Ben Bolker


On 11/28/2010 11:57 PM, Chris Howden wrote:
> Thanks for the reply Ben,
> 
> (And sorry for sending the same email 3 times everyone. I'm on other R
> lists where I receive a copy of my sent posts. And I also logged onto the
> r-sig-models admin site to confirm my settings are set so I receive copies
> of emails I send to the list. So not sure why I didn't receive them.)
> 
> Sorting the id's doesn't help, R still crashes.
> 
> What's interesting is that permutating the data actually makes geeglm()
> fit a model, while it is incapable of doing so on the correct id sorted
> data. (As U suggested I have run it again a number of times and get
> similar results each time. The model estimates are also quite similar to a
> standard GLM)
> 
> Looking at the summary() results for the permutated data model has given
> me a clue as to why a model can be fit to the permutated data, but not the
> 'correct' data. The permutated model has fit 68987 clusters, which is
> incorrect since there should only be 4 (1 for each dog)
> 
> I suspect the problem here is that geeglm cannot fit an "exchangeable"
> correlation structure to such large blocks of data (the smallest of which
> has 24000 rows).
> 
> PS: I was wondering why u think it is dicey to run a random effects model
> with only 4 levels. If I only have 4 individuals then I only have 4
> levels.
> 
> Chris Howden
> Founding Partner
> Tricky Solutions
> Tricky Solutions 4 Tricky Problems
> Evidence Based Strategic Development, IP Commercialisation and Innovation,
> Data Analysis, Modelling, and Training
> (mobile) 0410 689 945
> (fax / office) (+618) 8952 7878
> chris at trickysolutions.com.au
> 
> -----Original Message-----
> From: Ben Bolker [mailto:bbolker at gmail.com]
> Sent: Monday, 29 November 2010 10:36 AM
> To: r-sig-mixed-models at r-project.org; Chris Howden
> Subject: Re: [R-sig-ME] problem using geeglm: R keeps crashing
> 
> 
> On 10-11-28 07:17 PM, Chris Howden wrote:
>>
>> (sorry if this has posted before, I've sent it twice but because I
> haven't
>> received a copy or any replies it appears that it's not getting onto the
>> list)
> 
>  It has showed up (I think three times including this one): you can
> always check the archive at
> <https://stat.ethz.ch/pipermail/r-sig-mixed-models/> to see if your
> messages get through).
> 
>> I'm using geeglm to do a resource function analysis on some dingo radio
>> collar data. When I try to fit the following  model R crashes and I get
> the
>> following error message (I'm actually running R through ESS, just in
> case
>> that's relevant)
>>
>>>  fit.geeglm <- geeglm(resp~rubbish, data=data, id=dogname,
>> family=binomial, corstr="exchangeable")
>>
>> "This application has requested the Runtime to terminate it in an
> unusual
>> way.
>>
>> Please contact the application's support team for more information."
>>
>> I'm also getting a Microsoft Windows pop up that says:
>>
>> "R for Windows terminal front-end has stopped working"
>>
>> A problem caused the program to stop working correctly.
>>
>> Windows will close the program and notify you if a solution is available
> "
> 
>   In general if a package crashes R, that by definition constitutes a
> bug in the package and should be reported to the maintainers -- but see
> below ...
> 
>> The weird thing is that if I reorder my data the model seems to fit OK.
> I
>> can reorder the data and run a model as follows:
>>
>>>  sample <- data[sample(93948,93948),]  # (my data has 93948 rows)
>>
>>> fit.geeglm
>>
> <-geeglm(resp~rubbish,data=sample,id=dogname,family=binomial,corstr="excha
> ngeable")
>>
>> My understanding of the corstr="exchangeable" correlation structure in
>> geeglm() is that it assumes equal correlation amongst all data points
> for
>> each dingo..so I can't see why reordering the data changes anything..if
> I
>> was fitting something like an AR(1) model then I can see why reordering
>> changes things..
>>
>> One reason I have considered is that geeglm() actually fits a
> correlation
>> structure for each *block *of* *id's, rather than for all id's?  For
>> example, if my data set had the following id structure id1, id1, id1,
> id2,
>> id2, id1, id1. Then it would fit 1 correlation structure to the first
> set of
>> id1's and then a different correlation structure to the second set of
> id1's?
>> Rather than fitting a single correlation structure to id1?
> 
> Based on my reading of ?geeglm, and this note under the "id" argument
> description: "Data are assumed to be sorted so that observations on a
> cluster are contiguous rows for all entities in the formula."  Thus I
> would not be surprised if the example you give above failed, because it
> violates the rules laid out in the documentation (on the other hand,
> this is pretty easy to check and it would be wise for the package
> authors to make their code a bit more "fool-resistant" by checking for
> this condition and throwing an error if the elements aren't properly
> sorted).
>   You can easily sort your observations by id to make them conform to
> the rules, or, if you want to fit each contiguous block separately, you
> can use something like
> 
> factor(c(0,cumsum(diff(as.numeric(id))!=0)))
> 
> to generate a new id variable that identifies contiguous blocks.
>  Given all this it seems really surprising that geeglm works with
> permuted data.  Does it work consistently (say 10 or 20 times in a row)
> and give the same answers for different permutations ... ? Maybe you
> just got lucky.
> 
>   (It would also seem pretty dicey to me to run a random effects model
> with only 4 levels (animals), although if you do want to use 'bout'
> (contiguous block) as the id variable you will have a lot more levels ...)
> 
>>
>> Does anyone have any suggestions on why this is happening??? And what I
> can
>> do to get the model to run?
>>
>> My fall back model is to use glmer with random intercepts, but I really
> want
>> to use gee since it's a marginal model and gives me robust SE's.
>>
>> Thanks for any ideas
>>
>> The following is some more info that may be relevant:
>>
>> For those unfamiliar with this type of resource function analysis it is
>> conceptually *similar* to a case control study. The "used" resource
> units
>> being the cases and coming from the radio collared telemetry data. The
>> "available" resource units are the controls and are randomly sampled
> from
>> the home range of each dingo (I have sampled 5 controls for each case).
> The
>> resource units are 40 by 40 m pixels from a GIS.
>>
>> I have data for 4 dingos. It has 93948 rows and 9 variables. The first
> 1/6
>> of my data is the radio collar data "case" or "used resource units" (so
>> resp=1) and the next 5/6 of my data is the "control" or "available
> resource
>> units" (so resp =0).



From bates at stat.wisc.edu  Mon Nov 29 20:12:31 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 29 Nov 2010 13:12:31 -0600
Subject: [R-sig-ME] Non normal random effects
In-Reply-To: <853590539.831991.1291042965811.JavaMail.root@erie.cs.uoguelph.ca>
References: <AANLkTik5F9E8h_q6anVhn48BfnSBCwCceFGBciT0esG6@mail.gmail.com>
	<853590539.831991.1291042965811.JavaMail.root@erie.cs.uoguelph.ca>
Message-ID: <AANLkTi=Fuif_XQGivCOOjVeCwRMON_7ZhWzExgS9s+zV@mail.gmail.com>

On Mon, Nov 29, 2010 at 9:02 AM, Gustavo Betini <betinig at uoguelph.ca> wrote:
> Lets say that I want to look at the interaction between Species and some other variable...Temperature. The right specification would be
>
> (Temperature|Species) + (Temperature|Station:Species)
>
> or simply
>
> (1|Species) + (Temperature|Station:Species)

That depends on whether you feel that the changes in temperature
coefficient would be associated with the Species or with the
Station:Species combination or both.  I would try to start simply,
perhaps with

(1 + Temperature|Species) + (1|Station:Species)

It is difficult to estimate a large number of variance components
without a lot of data.  Starting with the "sumo" model that has every
possible term and interaction then seeing if you can pare it back
makes more sense in fixed-effects models than in mixed-effects models.
 Deletion strategies are easier to describe and evaluate when working
with fixed-effects only.  Also, in the fixed-effects case having a
model with too many terms in it doesn't usually prevent estimation of
coefficients, it just make the estimators less precise.

In a mixed-effects model, adding interaction terms increases the
number of variance-component parameters quadratically, not linearly.
And it is a lot more difficult to determine that the
variance-covariance matrix of the random effects is singular than to
detect that a model matrix is rank deficient.

So I would recommend building mixed-effects models using forward
selection, not backward selection, and proceeding cautiously.

>
> Thanks,
>
> Gustavo S. Betini
> Dept. of Integrative Biology
> University of Guelph, Canada
>
>
>
>
> On 10-11-27 12:04 PM, Douglas Bates wrote:
>
>
> Just in terms of the model specification, do you really mean
> (1|Species/Station)? ?That expands to
>
> ?(1|Species) + (1|Species:Station)
>
> and wouldn't reduce to (1|Station) in a model specification. ?I think
> you meant "species within station", which would be written as
> (1|Station/Species) although I prefer the more explicit form
> (1|Station) + (1|Station:Species)
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Mon Nov 29 22:36:17 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 29 Nov 2010 15:36:17 -0600
Subject: [R-sig-ME] multicolinearity?
In-Reply-To: <AANLkTi=7H1ntVd7PpsVLNx=kz0w-4o37rrc7YyxEbp0W@mail.gmail.com>
References: <AANLkTi=QPVsmMDseiT0LTjDOz7oUZFB_Q+S_Xdes5m=C@mail.gmail.com>
	<3DB16098F738284D8DBEB2FC3699163850E4E7@inboexch.inbo.be>
	<AANLkTi=7H1ntVd7PpsVLNx=kz0w-4o37rrc7YyxEbp0W@mail.gmail.com>
Message-ID: <AANLkTin+v5bTBR2XLSMGRuAxFkrYjXAem6E=hkHi+DW1@mail.gmail.com>

On Mon, Nov 29, 2010 at 12:48 PM, Lucas Kid <statslearner at gmail.com> wrote:
> Thanks, Thierry, but I still receive the same error, albeit with fewer nan's
> in my verbose parameter output:

>> (m1 <- glmer(Correct ~ Months * ( Stimulus + Focus) + (1|Subject),
> family=binomial, data=mydataset, verbose=TRUE))
> ?0: ? ? ? ? ? nan: 0.0774439 -2.86253 0.309665 ?1.18527 ?2.32723 ?1.68874
> ?2.42588 ?3.43032 -1.68977 ?2.91237 ? ? ?nan -0.169244 -0.232590 -0.212932
> -0.261447 -0.345893 0.0672266 -0.269589 ? ? ?nan
> Error in asMethod(object) : matrix is not symmetric [1,2]
> In addition: Warning message:
> In mer_finalize(ans) : gr cannot be computed at initial par (65)

Do you have missing cells in the data.  That is, are all combinations
of Months:Stimulus and Months:Focus present in the data?

Missing cells are one of the conditions that lead to rank-deficient
model matrices for the fixed-effects.  In functions like lm and glm
this is handled by a special pivoting scheme
based on very old code.  (It is ironic that the most common linear
algebra operation in R, determining least squares fits, does not
benefit from accelerated BLAS, because it is based on Linpack, not
Lapack.)  The code in lmer/glmer doesn't use such a scheme and I
suspect that is the cause of the nan's in the verbose output.

> vs
>
>> (m1 <- glmer(Correct ~ Months * Stimulus * Focus + (1|Subject),
> family=binomial, data=mydataset, verbose=TRUE))
> ?0: ? ? ? ? ? nan: 0.0774439 -2.86253 0.309665 ?1.18527 ?2.32723 ?1.68874
> ?2.42588 ?3.43032 -1.68977 ?2.91237 ? ? ?nan -0.169244 -0.232590 -0.212932
> -0.261447 -0.345893 0.0672266 -0.269589 ? ? ?nan ? ? ?nan ? ? ?nan ? ? ?nan
> ? ? nan ? ? ?nan ? ? ?nan ? ? ?nan ? ? ?nan ? ? ?nan ? ? ?nan ? ? ?nan
> ?nan ? ? ?nan ? ? ?nan
> Error in asMethod(object) : matrix is not symmetric [1,2]
> In addition: Warning message:
> In mer_finalize(ans) : gr cannot be computed at initial par (65)
>
> Thanks,
>
> Luke
>
> On Mon, Nov 29, 2010 at 11:09 AM, ONKELINX, Thierry <
> Thierry.ONKELINX at inbo.be> wrote:
>
>> Dear Lucas,
>>
>> It will be probably sufficient to drop the Focus:Stimulus interaction.
>>
>> m1f <- glmer(Correct ~ Months*(Focus + Stimulus) + (1|Subject),
>> family=binomial, data=mydataset)
>>
>> You will be some NA values because stimulus is nested in focus.
>>
>> Best regards,
>>
>> Thierry
>>
>> ------------------------------------------------------------------------
>> ----
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek
>> team Biometrie & Kwaliteitszorg
>> Gaverstraat 4
>> 9500 Geraardsbergen
>> Belgium
>>
>> Research Institute for Nature and Forest
>> team Biometrics & Quality Assurance
>> Gaverstraat 4
>> 9500 Geraardsbergen
>> Belgium
>>
>> tel. + 32 54/436 185
>> Thierry.Onkelinx at inbo.be
>> www.inbo.be
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to
>> say what the experiment died of.
>> ~ Sir Ronald Aylmer Fisher
>>
>> The plural of anecdote is not data.
>> ~ Roger Brinner
>>
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of
>> data.
>> ~ John Tukey
>>
>>
>> > -----Oorspronkelijk bericht-----
>> > Van: r-sig-mixed-models-bounces at r-project.org
>> > [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Lucas Kid
>> > Verzonden: maandag 29 november 2010 16:27
>> > Aan: r-sig-mixed-models at r-project.org
>> > Onderwerp: [R-sig-ME] multicolinearity?
>> >
>> > Mixed modelers,
>> >
>> > I have a dataset (mydataset) where subjects' (Subject)
>> > responses (Correct) to a stimulus (Stimulus) was tested over
>> > time (Months). There were 8 stimuli, 2 of which had focus A
>> > and 6 had focus B (Focus). ?At each time point, subjects were
>> > tested multiple times for each stimuli. ?Subject, Stimulus,
>> > and Focus are all factors.
>> >
>> > I have run model as follows:
>> >
>> > (m1 <- glmer(Correct ~ Months*Stimulus + (1|Subject), family=binomial,
>> > data=mydataset))
>> > (m2 <- glmer(Correct ~ Months*Stimulus + (1|Subject) + (0 + Months
>> > |Subject), family=binomial, data=mydataset))
>> > (m3 <- glmer(Correct ~ Months*Stimulus + (1 + Months
>> > |Subject), family=binomial, data=mydataset))
>> > (m4 <- glmer(Correct ~ Months*Stimulus + (1 + Months +
>> > Stimulus |Subject), family=binomial, data=mydataset))
>> > (m5 <- glmer(Correct ~ Months*Stimulus + (1 + Months +
>> > Stimulus + Months * Stimulus |Subject), family=binomial,
>> > data=mydataset))
>> >
>> > I would like to test Focus to see if, when controlling for
>> > Focus, the effect of Stimulus goes away.
>> >
>> > (m1f <- glmer(Correct ~ Months*Stimulus*Focus + (1|Subject),
>> > family=binomial, data=mydataset))
>> >
>> > However, I get the following error:
>> >
>> > Error in asMethod(object) : matrix is not symmetric [1,2] In
>> > addition: Warning message:
>> > In mer_finalize(ans) : gr cannot be computed at initial par (65)
>> >
>> > I believe this is a case of multicolinearity between Focus
>> > and Stimulus.
>> > Would that be a correct assumption? ?What options do I have
>> > in order to examine the relationship between Correct and
>> > Stimulus/Focus in a mixed-effects situation.
>> >
>> > I'm using version 0.999375-35 of lme4.
>> >
>> > Thanks!
>> >
>> > Luke
>> >
>> > ? ? ? [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From btpinotti at gmail.com  Tue Nov 30 00:20:32 2010
From: btpinotti at gmail.com (Bruno Trevizan Pinotti)
Date: Mon, 29 Nov 2010 21:20:32 -0200
Subject: [R-sig-ME] Mixed models in lmer with no fixed effects
Message-ID: <AANLkTinnSi=vP_Q8d+j8chJ3DV0TTu+xwCYvHNqnYf6q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101129/8ee47a2c/attachment.pl>

From chris at trickysolutions.com.au  Tue Nov 30 01:09:31 2010
From: chris at trickysolutions.com.au (Chris Howden)
Date: Tue, 30 Nov 2010 09:39:31 +0930
Subject: [R-sig-ME] problem using geeglm: R keeps crashing
In-Reply-To: <4CF3F8CE.6050100@gmail.com>
References: <64dbfdb2ded3e91631701a17894528d3@mail.gmail.com>
	<4CF2FC8E.8060403@gmail.com>
	<55243b6f3b46cb660633fe556e4b268f@mail.gmail.com>
	<4CF3F8CE.6050100@gmail.com>
Message-ID: <e40d9746a3177b10194e548e956c65fb@mail.gmail.com>

Thanks Ben,

I've contacted the administrators and we're looking into it.

And your absolutely right, a GLMM with random intercept is giving me
pretty much the same answer as a GLM.

Although I'm hoping the GEE model with it's robust SE's will account for
the obvious autocorrelation in my dataset.

Chris Howden
Founding Partner
Tricky Solutions
Tricky Solutions 4 Tricky Problems
Evidence Based Strategic Development, IP Commercialisation and Innovation,
Data Analysis, Modelling, and Training
(mobile) 0410 689 945
(fax / office) (+618) 8952 7878
chris at trickysolutions.com.au


-----Original Message-----
From: Ben Bolker [mailto:bbolker at gmail.com]
Sent: Tuesday, 30 November 2010 4:33 AM
To: Chris Howden
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] problem using geeglm: R keeps crashing

  If the model with only 4 clusters is the one you wanted (i.e. data
sorted in id order, contiguous blocks), then I would definitely contact
the maintainers to see why it's crashing.  That is, you seem to be
following the rules laid out in the documentation, so it shouldn't crash.

  The reason it's dicey to run a RE model with only 4 levels is that you
are in effect trying to estimate a variance from 4 observations, which
tends to be very inaccurate/unstable.  Since you apparently have very
large quantities of data per individual, I would expect you to get
approximately the same answers if you just treated individuals as a
fixed effect (although admittedly the model is philosophically different).

  Ben Bolker


On 11/28/2010 11:57 PM, Chris Howden wrote:
> Thanks for the reply Ben,
>
> (And sorry for sending the same email 3 times everyone. I'm on other R
> lists where I receive a copy of my sent posts. And I also logged onto
the
> r-sig-models admin site to confirm my settings are set so I receive
copies
> of emails I send to the list. So not sure why I didn't receive them.)
>
> Sorting the id's doesn't help, R still crashes.
>
> What's interesting is that permutating the data actually makes geeglm()
> fit a model, while it is incapable of doing so on the correct id sorted
> data. (As U suggested I have run it again a number of times and get
> similar results each time. The model estimates are also quite similar to
a
> standard GLM)
>
> Looking at the summary() results for the permutated data model has given
> me a clue as to why a model can be fit to the permutated data, but not
the
> 'correct' data. The permutated model has fit 68987 clusters, which is
> incorrect since there should only be 4 (1 for each dog)
>
> I suspect the problem here is that geeglm cannot fit an "exchangeable"
> correlation structure to such large blocks of data (the smallest of
which
> has 24000 rows).
>
> PS: I was wondering why u think it is dicey to run a random effects
model
> with only 4 levels. If I only have 4 individuals then I only have 4
> levels.
>
> Chris Howden
> Founding Partner
> Tricky Solutions
> Tricky Solutions 4 Tricky Problems
> Evidence Based Strategic Development, IP Commercialisation and
Innovation,
> Data Analysis, Modelling, and Training
> (mobile) 0410 689 945
> (fax / office) (+618) 8952 7878
> chris at trickysolutions.com.au
>
> -----Original Message-----
> From: Ben Bolker [mailto:bbolker at gmail.com]
> Sent: Monday, 29 November 2010 10:36 AM
> To: r-sig-mixed-models at r-project.org; Chris Howden
> Subject: Re: [R-sig-ME] problem using geeglm: R keeps crashing
>
>
> On 10-11-28 07:17 PM, Chris Howden wrote:
>>
>> (sorry if this has posted before, I've sent it twice but because I
> haven't
>> received a copy or any replies it appears that it's not getting onto
the
>> list)
>
>  It has showed up (I think three times including this one): you can
> always check the archive at
> <https://stat.ethz.ch/pipermail/r-sig-mixed-models/> to see if your
> messages get through).
>
>> I'm using geeglm to do a resource function analysis on some dingo radio
>> collar data. When I try to fit the following  model R crashes and I get
> the
>> following error message (I'm actually running R through ESS, just in
> case
>> that's relevant)
>>
>>>  fit.geeglm <- geeglm(resp~rubbish, data=data, id=dogname,
>> family=binomial, corstr="exchangeable")
>>
>> "This application has requested the Runtime to terminate it in an
> unusual
>> way.
>>
>> Please contact the application's support team for more information."
>>
>> I'm also getting a Microsoft Windows pop up that says:
>>
>> "R for Windows terminal front-end has stopped working"
>>
>> A problem caused the program to stop working correctly.
>>
>> Windows will close the program and notify you if a solution is
available
> "
>
>   In general if a package crashes R, that by definition constitutes a
> bug in the package and should be reported to the maintainers -- but see
> below ...
>
>> The weird thing is that if I reorder my data the model seems to fit OK.
> I
>> can reorder the data and run a model as follows:
>>
>>>  sample <- data[sample(93948,93948),]  # (my data has 93948 rows)
>>
>>> fit.geeglm
>>
>
<-geeglm(resp~rubbish,data=sample,id=dogname,family=binomial,corstr="excha
> ngeable")
>>
>> My understanding of the corstr="exchangeable" correlation structure in
>> geeglm() is that it assumes equal correlation amongst all data points
> for
>> each dingo..so I can't see why reordering the data changes anything..if
> I
>> was fitting something like an AR(1) model then I can see why reordering
>> changes things..
>>
>> One reason I have considered is that geeglm() actually fits a
> correlation
>> structure for each *block *of* *id's, rather than for all id's?  For
>> example, if my data set had the following id structure id1, id1, id1,
> id2,
>> id2, id1, id1. Then it would fit 1 correlation structure to the first
> set of
>> id1's and then a different correlation structure to the second set of
> id1's?
>> Rather than fitting a single correlation structure to id1?
>
> Based on my reading of ?geeglm, and this note under the "id" argument
> description: "Data are assumed to be sorted so that observations on a
> cluster are contiguous rows for all entities in the formula."  Thus I
> would not be surprised if the example you give above failed, because it
> violates the rules laid out in the documentation (on the other hand,
> this is pretty easy to check and it would be wise for the package
> authors to make their code a bit more "fool-resistant" by checking for
> this condition and throwing an error if the elements aren't properly
> sorted).
>   You can easily sort your observations by id to make them conform to
> the rules, or, if you want to fit each contiguous block separately, you
> can use something like
>
> factor(c(0,cumsum(diff(as.numeric(id))!=0)))
>
> to generate a new id variable that identifies contiguous blocks.
>  Given all this it seems really surprising that geeglm works with
> permuted data.  Does it work consistently (say 10 or 20 times in a row)
> and give the same answers for different permutations ... ? Maybe you
> just got lucky.
>
>   (It would also seem pretty dicey to me to run a random effects model
> with only 4 levels (animals), although if you do want to use 'bout'
> (contiguous block) as the id variable you will have a lot more levels
...)
>
>>
>> Does anyone have any suggestions on why this is happening??? And what I
> can
>> do to get the model to run?
>>
>> My fall back model is to use glmer with random intercepts, but I really
> want
>> to use gee since it's a marginal model and gives me robust SE's.
>>
>> Thanks for any ideas
>>
>> The following is some more info that may be relevant:
>>
>> For those unfamiliar with this type of resource function analysis it is
>> conceptually *similar* to a case control study. The "used" resource
> units
>> being the cases and coming from the radio collared telemetry data. The
>> "available" resource units are the controls and are randomly sampled
> from
>> the home range of each dingo (I have sampled 5 controls for each case).
> The
>> resource units are 40 by 40 m pixels from a GIS.
>>
>> I have data for 4 dingos. It has 93948 rows and 9 variables. The first
> 1/6
>> of my data is the radio collar data "case" or "used resource units" (so
>> resp=1) and the next 5/6 of my data is the "control" or "available
> resource
>> units" (so resp =0).



From djmuser at gmail.com  Tue Nov 30 05:16:42 2010
From: djmuser at gmail.com (Dennis Murphy)
Date: Mon, 29 Nov 2010 20:16:42 -0800
Subject: [R-sig-ME] LMER problem when all observations in one level are
	zero?
In-Reply-To: <AANLkTikX66AEkZEc5+woBBwqDmLoFOQUeSPVb45UUL_E@mail.gmail.com>
References: <AANLkTikX66AEkZEc5+woBBwqDmLoFOQUeSPVb45UUL_E@mail.gmail.com>
Message-ID: <AANLkTikaZtO3Ci1RRDMjfa6=mhZioXU6491dNdDeS6ez@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101129/489e8b97/attachment.pl>

From biostatistica at gmail.com  Tue Nov 30 15:18:15 2010
From: biostatistica at gmail.com (=?ISO-8859-1?Q?Niccol=F2_Bassani?=)
Date: Tue, 30 Nov 2010 15:18:15 +0100
Subject: [R-sig-ME] HPDinterval, lmer and strange intervals
Message-ID: <AANLkTimFBLxija+fcCma-ETPc0j-BfF-+b05xW3jqCcn@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101130/273cac85/attachment.pl>

From bvholbi at yahoo.com  Tue Nov 30 19:04:13 2010
From: bvholbi at yahoo.com (Beth Holbrook)
Date: Tue, 30 Nov 2010 10:04:13 -0800 (PST)
Subject: [R-sig-ME] Random effects variance estimates lme vs lmer
Message-ID: <874553.26070.qm@web35305.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101130/d0dba51f/attachment.pl>

From xiedong0123 at gmail.com  Tue Nov 30 17:02:26 2010
From: xiedong0123 at gmail.com (Dong Xie)
Date: Wed, 01 Dec 2010 00:02:26 +0800
Subject: [R-sig-ME] Some questions about lme4 package
Message-ID: <4CF52012.7080003@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101201/3e6898e5/attachment.pl>

From billy.requena at gmail.com  Tue Nov 30 21:26:15 2010
From: billy.requena at gmail.com (Billy)
Date: Tue, 30 Nov 2010 14:26:15 -0600
Subject: [R-sig-ME] Repeated measure comparisons: should the identity be
 a random or a fixed variable?
In-Reply-To: <20101127082601.17263ut2ss7hdps0@www.staffmail.ed.ac.uk>
References: <AANLkTim5+x5mnK18pBpSQj3WxdFzfM3upAQibf28=2OK@mail.gmail.com>
	<20101127082601.17263ut2ss7hdps0@www.staffmail.ed.ac.uk>
Message-ID: <AANLkTinz8DoYctNbemHu7xVKXteixaYw0-e0gLn6P0Au@mail.gmail.com>

Hi Jarrod,

Thanks for the reply.
I followed your suggestion to treat months as continuous variable and
the model selection result was totally different. In the first
analyses, model 2 (considering an additive effect of x and month) was
the most likely model, but after implemented your suggestion, the best
model was model 1 (considering only the effect of x, with month as a
random variable). However, I think in such case (following your
suggestion) there is an assumption that the third month, for example,
is in a higher level than the first or second month, right? Maybe
that's not the case in nature and my goal is exactly investigate if
the relationship between y and x could change from one month to
another, not necessarily always increasing or always decreasing. In
fact, the first sampled month is August and the last one is July of
the next year. Assuming a seasonal variation, maybe a should use a
circular statistics approach to deal with this case, I don't know.
Furthermore, I don't know if I really understand your other suggestion.

Thanks again and sorry for some misunderstandings.

Billy

-- 
Gustavo Requena
PhD student - Laboratory of Arthropod Behavior and Evolution
Universidade de S?o Paulo
Correspondence adress:
a/c Glauco Machado
Departamento de Ecologia - IBUSP
Rua do Mat?o - Travessa 14 no 321 Cidade Universit?ria, S?o Paulo - SP, Brasil
CEP 05508-900
Phone number: 55 11 3091-7488

http://ecologia.ib.usp.br/opilio/gustavo.html



On Sat, Nov 27, 2010 at 2:26 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
> Hi Billy,
>
> I think your models look reasonable, although in models 2 and 3 you may want
> ?to treat month as a continuous variable in the fixed part of the model.
> Also, most count data are overdispersed with respect to the poisson and so a
> model that does not account for this will be anti-conservative in terms of
> standard errors etc. One way to deal with this is to fit an additional
> random effect at the level of each observation:
>
> my.data$resid<-as.factor(1:dim(my.data)[2])
>
> and fit (1|resid) in the model formula.
>
> Cheers,
>
> Jarrod
>
>
>
>
> Quoting Billy <billy.requena at gmail.com>:
>
>> Hello everybody!
>>
>> I'm relatively new at the mixed-models world and I'm facing a
>> theoretical/philosophical problem.
>> Let's go to my data collection.
>>
>> I wanna compare the number of eggs laid by females (different
>> individuals or the same, I have no idea) at the time 1 and at the time
>> 2 in the same location. Therefore, I have repeated measures by
>> location and wanna compare time 1 versus time two. Given I have count
>> data, to minimize the overdispersion I have considered the Poisson
>> distribution for the errors.
>> Furthermore, I have collected this data throughout one year and I'm
>> also interested in temporal variation among months.
>>
>> model0 <- glmer ( y ~ 1 + (1|location) + (1|month), family="poisson")
>> model1 <- glmer ( y ~ x + (1|location) + (1|month), family="poisson")
>>
>> where y = number of eggs laid,
>> ? ? ? ? ?x = factor concerning the first or the second oviposition
>> ? ? ? ? ?location = factor concerning the exactly position in the
>> space (just an identity of the oviposition site and responsible for
>> the repeated comparison)
>> ? ? ? ? ?month = factor concerning the month when I've collected the data
>>
>> Is that right? If I wanna repeated comparison regarding specific
>> identity of oviposition sites, should this factor (location) be a
>> random variable?
>>
>> Furthermore, in both examples above, I'm just considering a temporal
>> variation (among months) as random a effect. But I'm also interested
>> if there are significant seasonal variation in the comparison (the
>> difference could be higher during warm season or not even existent
>> during cold season). Then:
>>
>> model2 <- glmer ( y ~ x + month + (1|location), family="poisson")
>> model3 <- glmer ( y ~ x * month + (1|location), family="poisson")
>>
>> Is that right too?
>> Finally, I'll use a model selection approach to compare the different
>> models and rank the most likely one to reproduce the data observed in
>> the nature.
>> Thanks to everyone
>>
>> --
>> Gustavo Requena
>> PhD student - Laboratory of Arthropod Behavior and Evolution
>> Universidade de S?o Paulo
>> Correspondence adress:
>> a/c Glauco Machado
>> Departamento de Ecologia - IBUSP
>> Rua do Mat?o - Travessa 14 no 321 Cidade Universit?ria, S?o Paulo - SP,
>> Brasil
>> CEP 05508-900
>> Phone number: 55 11 3091-7488
>>
>> http://ecologia.ib.usp.br/opilio/gustavo.html
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>



From geralttee at gmail.com  Tue Nov 30 23:19:20 2010
From: geralttee at gmail.com (Szymek Drobniak)
Date: Tue, 30 Nov 2010 23:19:20 +0100
Subject: [R-sig-ME] Another MCMCglmm question - fixing correlations
Message-ID: <AANLkTi=4MVp+=zSNoYhGfD6EQEM_4OdHq=kLKV+rf=FC@mail.gmail.com>

Hi,

is it possible in MCMglmm to fix the (co)variance matrix so that the
resulting variances could vary, but covariances had always the value
ensuring that r=1? It would be useful in testing cross-sex rG where
the H0 should be rG=1 rather than rG=0 (as defined in idh()). I looked
through available (co)variance structures but none seems suitable.

best,
sz.



From els.latham at gmail.com  Tue Nov 30 23:20:13 2010
From: els.latham at gmail.com (Erin Latham)
Date: Tue, 30 Nov 2010 17:20:13 -0500
Subject: [R-sig-ME] Modeling for a zero-inflated continuous response
Message-ID: <AANLkTi=YL4f++ProE1cE+uTew5yq4uBiwK1ySaawTh=Q@mail.gmail.com>

Hi R list,

I'm attempting to model a continuous response (CHANGEM) using three
variables (SLOPE, ASPECT, ELEVATION).

> str(sheep)
'data.frame':   419 obs. of  10 variables:
 $ SITE     : Factor w/ 4 levels "Gibbs","Langley",..: 1 1 1 1 1 1 1 1 1 1
...
 $ AREACODE : Factor w/ 20 levels "Aspect1","Aspect2",..: 2 2 2 2 2 2 2 2 3
3 ...
 $ GRID     : int  0 3 4 5 6 1 2 7 0 4 ...
 $ SLOPE    : num  40.8 30 59.7 44.8 56.1 56.7 60.7 47.2 36.6 25.1 ...
 $ ASPECT   : num  0.7597 -0.4677 0.0963 0.2272 -0.2194 ...
 $ ELEVATION: int  2576 2757 2521 2659 2562 2725 2627 2657 2221 2242 ...
 $ LATITUDE : Factor w/ 2 levels "n","s": 1 1 1 1 1 1 1 1 1 1 ...
 $ CHANGEM  : num  0 0 0 0 0 ...
 $ CHANGEP  : num  0 0 0 0 0 ...
 $ VEG      : Factor w/ 18 levels "","BA","BL","BM",..: 1 1 1 1 1 1 1 1 1 1
...

I performed a change analysis with an unbalanced hierarchical sample design.
I interpreted usually 8 grids (GRID) (sometimes less) from each AREACODE of
each SITE. There are 4 sites with 8 to 19 sub-plots (AREACODEs) for a total
of 419 total grids analyzed.
My problem is that the response has many zeroes (260/419 grids). The
response was calculated as a change detection between two dates, and the
units are square meters. Technically I performed the change based on a grid,
so it could be considered a proportion or change as percent cover, as well
(CHANGEP). Besides the zeros, the data is normally distributed.

I found this helpful post by Ben Bolker, but I'm uncertain how to go about
modeling the zeroes as part of the mixture process when the distribution is
otherwise normal.
http://permalink.gmane.org/gmane.comp.lang.r.lme4.devel/3454
I'm been reading Bolker (2007), but I'm a bit stuck translating the
discussion to code.

Any help is greatly appreciated.
Thank you.

-- 
Erin Latham, M.GIS

From mchaudhari at deltadentalwa.com  Wed Dec  1 00:57:10 2010
From: mchaudhari at deltadentalwa.com (Chaudhari, Monica)
Date: Tue, 30 Nov 2010 15:57:10 -0800
Subject: [R-sig-ME] Error in asMethod(object) : matrix is not symmetric [1,
	2]
In-Reply-To: <AANLkTi=4MVp+=zSNoYhGfD6EQEM_4OdHq=kLKV+rf=FC@mail.gmail.com>
References: <AANLkTi=4MVp+=zSNoYhGfD6EQEM_4OdHq=kLKV+rf=FC@mail.gmail.com>
Message-ID: <06C1E76E03FE9C4B85BFA9C75365D9DA24655B5C@tiger.deltadentalwa.com>

Hello All,

I am receiving this error while trying to model follow-up  restorative
costs on  patients' teeth using Gamma family mixed model. 

> lmer9<-lmer(cumappAmtCPIAdj ~ toothNo  + yrFromBase +  (yrFromBase |
ptntId/quad), data = datsample[procClass == "Restorative" & ptntId %in%
levels(ptntId)[1:10],],family = Gamma(link="log"))
The model appears to fit until you give the bellow command:
> summary(lmer9)
Error in asMethod(object) : matrix is not symmetric [1,2]

When tracing back for error, it gives:
> traceback()
15: .Call(dense_to_symmetric, from, "U", TRUE)
14: asMethod(object)
13: as(from, "symmetricMatrix")
12: .class1(object)
11: as(as(from, "symmetricMatrix"), "dMatrix")
10: .class1(object)
9: as(as(as(from, "symmetricMatrix"), "dMatrix"), "denseMatrix")
8: .class1(object)
7: as(as(as(as(from, "symmetricMatrix"), "dMatrix"), "denseMatrix"), 
       "dpoMatrix")
6: asMethod(object)
5: as(sigma(object)^2 * chol2inv(object at RX, size = object at dims["p"]), 
       "dpoMatrix")
4: vcov(object)
3: vcov(object)
2: summary(lmer9)
1: summary(lmer9)

Below is additional information about the session:
> sessionInfo()
R version 2.11.1 (2010-05-31) 
i386-pc-mingw32 

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
States.1252    LC_MONETARY=English_United States.1252 LC_NUMERIC=C
LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


other attached packages:
[1] lme4_0.999375-37   Matrix_0.999375-45 lattice_0.19-13   

loaded via a namespace (and not attached):
[1] grid_2.11.1   nlme_3.1-97   stats4_2.11.1

I have not had success fitting Gamma(link="log") even a single time
using lme4. It returns the above error always. Could you please point
any resolutions?

Thanks,
Monica

______________________________________________________________________
The information contained in this e-mail and subsequent ...{{dropped:9}}



From bates at stat.wisc.edu  Wed Dec  1 03:24:23 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 30 Nov 2010 20:24:23 -0600
Subject: [R-sig-ME] Ben Bolker has joined the lme4 development team
Message-ID: <AANLkTi=ym7_ZfKGtyUjGFfHuaexv6MSeJZs7mtuYDRFO@mail.gmail.com>

Martin and I are pleased to announce that Ben Bolker has joined the
development team for the lme4 and lme4a packages.  Ben's expertise in
generalized linear mixed models and in applications of linear and
generalized linear mixed models in ecology and other biological areas
will be invaluable as we continue to develop these packages.



From j.hadfield at ed.ac.uk  Wed Dec  1 11:28:43 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 1 Dec 2010 10:28:43 +0000
Subject: [R-sig-ME] Another MCMCglmm question - fixing correlations
In-Reply-To: <AANLkTi=4MVp+=zSNoYhGfD6EQEM_4OdHq=kLKV+rf=FC@mail.gmail.com>
References: <AANLkTi=4MVp+=zSNoYhGfD6EQEM_4OdHq=kLKV+rf=FC@mail.gmail.com>
Message-ID: <0AF131D6-557C-4324-A65A-A175E41DBA8F@ed.ac.uk>

Hi,

There is a way, but its quite involved and you may find it easier to  
fit this type of model in something like ASReml if you can get a  
license. If not ......

I have implemented simultaneous-recursive (SIR) mixed models  in  
MCMCglmm, although currently they are not well tested or documented  
(See Chapter 9 of the CourseNotes) and cannot be used with non- 
Gaussian data or certain patterns of missing data. Nevertheless, in  
this example the existing code should work fine.  A simple SIR model  
has the form:

y_{i} = mu + \lambda*y_{j} + u_{i} + e_{i}

where mu is the intercept, u is a random effect (e.g. breeding value  
in your case) and e is a residual. The new part of the model is the  
structural parameter \lambda multiplied by y_{j}, the jth element of  
the response vector, which can be useful for modelling the effects of  
behavioural interactions or time series etc.  However, placing y's on  
the LHS and RHS complicates the likelihood, but MCMCglmm deals with  
this.

If we set i=j then the above equation can be rearranged:

y_{i}  - \lambda*y_{i} = mu + u_{i} + e_{i}
y_{i}(1  - \lambda) = mu + u_{i} + e_{i}
y_{i} = (mu + u_{i} + e_{i})/(1  - \lambda)

from this it can be seen that mu, u, e, and \lambda cannot be uniquely  
estimated without restrictions.  To illustrate we'll simulate some data:

fac<-gl(25,4)
y<-rnorm(25)[fac]+rnorm(100, -1, sqrt(2))

# mu = -1, VAR(u)=1, VAR(e) = 2, \lambda = 0

dat<-data.frame(y=y, fac=fac)

prior1 = list(R=list(V=1, nu=0.002), G=list(G1=list(V=1, nu=0.002)))

m1<-MCMCglmm(y~1, random=~fac,  data=dat, prior=prior1)

# fitting a non-SIR model gives estimates consistent with the true  
values, which you can verify through summary(m1). Now for the SIR  
model. Because we know all parameters cannot be uniquely estimated  
I've set the residual variance to one arbitrarily.

prior2 = list(R=list(V=1, fix=1), G=list(G1=list(V=1, nu=0.002)))

m2<-MCMCglmm(y~1+sir(~units, ~units), random=~fac,  data=dat,  
prior=prior2)   # sir(~units, ~units) sets i=j.

# The estimates do not look consistent with the real values.  However,  
we can rescale them by 1-\lambda and the estimates  are close to being  
identical up to Monte Carlo error (the prior will have slightly  
different effects)

HPDinterval(m1$VCV[,1])
HPDinterval(m2$VCV[,1]/(1-m2$Lambda)^2)

HPDinterval(m1$VCV[,2])
HPDinterval(m2$VCV[,2]/(1-m2$Lambda)^2)

HPDinterval(m1$Sol)
HPDinterval(m2$Sol/(1-m2$Lambda))

# And what's the point? Lets Imagine the same data are associated with  
2 genders:

dat$sex<-gl(2,1,100, labels=c("Female", "Male"))

# and that Females are twice as big as males, and on top of this have  
some additional residual variation:

dat$y[which(dat$sex=="Female")]<-2*dat$y[which(dat$sex=="Female")]
dat$y[which(dat$sex=="Female")]<-dat$y[which(dat$sex=="Female")] 
+rnorm(50)

For Males   mu = -1, VAR(u)=1, VAR(e) = 2 as before
For Females   mu = -2, VAR(u)=4, VAR(e) = 8+1=9.

# Importantly the correlation between u's in the different sexes is 1,  
despite them having the same variance. By only fitting a sir model to  
females

prior3=list(R=list(V=diag(2), nu=0.002), G=list(G1=list(V=1, nu=0.002)))

m3<-MCMCglmm(y~1+sir(~units:at.level(sex,"Female"),  
~units:at.level(sex,"Female")), random=~fac, rcov=~idh(sex):units,  
data=dat, prior=prior3)

# we can extract the male estimates and they are consistent with what  
we expect.

mean(m3$VCV[,1])  # var(u) males
mean(m3$VCV[,3])  # var(e) males
mean(m3$Sol)          # mu     males

# we can then rescale the female estimates as before:

mean(m3$VCV[,1]/(1-m3$Lambda)^2) # var(u) females
mean(m3$VCV[,2]/(1-m3$Lambda)^2)  # var(e) females
mean(m3$Sol/(1-m3$Lambda))  # mu  females

# and the estimates should be good.

Note in this last model we did not need to place restrictions on the  
variance components through the prior. Restrictions are required, but  
we achieved this by having ~fac rather than something  like  
us(sex):fac or idh(sex):fac.  More complicated models could be  
generated which place other types of restriction on the covariance  
matrices.

Cheers,

Jarrod












On 30 Nov 2010, at 22:19, Szymek Drobniak wrote:

> Hi,
>
> is it possible in MCMglmm to fix the (co)variance matrix so that the
> resulting variances could vary, but covariances had always the value
> ensuring that r=1? It would be useful in testing cross-sex rG where
> the H0 should be rG=1 rather than rG=0 (as defined in idh()). I looked
> through available (co)variance structures but none seems suitable.
>
> best,
> sz.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From j.hadfield at ed.ac.uk  Wed Dec  1 12:30:55 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 1 Dec 2010 11:30:55 +0000
Subject: [R-sig-ME] Repeated measure comparisons: should the identity be
	a random or a fixed variable?
In-Reply-To: <AANLkTinz8DoYctNbemHu7xVKXteixaYw0-e0gLn6P0Au@mail.gmail.com>
References: <AANLkTim5+x5mnK18pBpSQj3WxdFzfM3upAQibf28=2OK@mail.gmail.com>
	<20101127082601.17263ut2ss7hdps0@www.staffmail.ed.ac.uk>
	<AANLkTinz8DoYctNbemHu7xVKXteixaYw0-e0gLn6P0Au@mail.gmail.com>
Message-ID: <903ECD4C-34C8-4D49-A17E-7696F91EF205@ed.ac.uk>

Hi Billy,

There are some earlier posts regarding circular statistics and lmer  
which you could check out, although I'm not sure anything was  
resolved.  Regarding the second suggestion of fitting an observation- 
level random effect, I think it is important that this is done as a  
matter of course. Heterogeneity in the expected response across  
observations will exist even in the most carefully controlled  
experiments  and should be modeled. If it is not, the SE's on the  
fixed effects will be too small, and the variances associated with  
other random effects may well be meaningless.  For example, refit the  
example glmm model in ?lmer with an observation-level random effect  
and notice how different the conclusions are regarding the herd  
variance.

Cheers,

Jarrod


On 30 Nov 2010, at 20:26, Billy wrote:

> Hi Jarrod,
>
> Thanks for the reply.
> I followed your suggestion to treat months as continuous variable and
> the model selection result was totally different. In the first
> analyses, model 2 (considering an additive effect of x and month) was
> the most likely model, but after implemented your suggestion, the best
> model was model 1 (considering only the effect of x, with month as a
> random variable). However, I think in such case (following your
> suggestion) there is an assumption that the third month, for example,
> is in a higher level than the first or second month, right? Maybe
> that's not the case in nature and my goal is exactly investigate if
> the relationship between y and x could change from one month to
> another, not necessarily always increasing or always decreasing. In
> fact, the first sampled month is August and the last one is July of
> the next year. Assuming a seasonal variation, maybe a should use a
> circular statistics approach to deal with this case, I don't know.
> Furthermore, I don't know if I really understand your other  
> suggestion.
>
> Thanks again and sorry for some misunderstandings.
>
> Billy
>
> -- 
> Gustavo Requena
> PhD student - Laboratory of Arthropod Behavior and Evolution
> Universidade de S?o Paulo
> Correspondence adress:
> a/c Glauco Machado
> Departamento de Ecologia - IBUSP
> Rua do Mat?o - Travessa 14 no 321 Cidade Universit?ria, S?o Paulo -  
> SP, Brasil
> CEP 05508-900
> Phone number: 55 11 3091-7488
>
> http://ecologia.ib.usp.br/opilio/gustavo.html
>
>
>
> On Sat, Nov 27, 2010 at 2:26 AM, Jarrod Hadfield  
> <j.hadfield at ed.ac.uk> wrote:
>> Hi Billy,
>>
>> I think your models look reasonable, although in models 2 and 3 you  
>> may want
>>  to treat month as a continuous variable in the fixed part of the  
>> model.
>> Also, most count data are overdispersed with respect to the poisson  
>> and so a
>> model that does not account for this will be anti-conservative in  
>> terms of
>> standard errors etc. One way to deal with this is to fit an  
>> additional
>> random effect at the level of each observation:
>>
>> my.data$resid<-as.factor(1:dim(my.data)[2])
>>
>> and fit (1|resid) in the model formula.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>>
>> Quoting Billy <billy.requena at gmail.com>:
>>
>>> Hello everybody!
>>>
>>> I'm relatively new at the mixed-models world and I'm facing a
>>> theoretical/philosophical problem.
>>> Let's go to my data collection.
>>>
>>> I wanna compare the number of eggs laid by females (different
>>> individuals or the same, I have no idea) at the time 1 and at the  
>>> time
>>> 2 in the same location. Therefore, I have repeated measures by
>>> location and wanna compare time 1 versus time two. Given I have  
>>> count
>>> data, to minimize the overdispersion I have considered the Poisson
>>> distribution for the errors.
>>> Furthermore, I have collected this data throughout one year and I'm
>>> also interested in temporal variation among months.
>>>
>>> model0 <- glmer ( y ~ 1 + (1|location) + (1|month),  
>>> family="poisson")
>>> model1 <- glmer ( y ~ x + (1|location) + (1|month),  
>>> family="poisson")
>>>
>>> where y = number of eggs laid,
>>>          x = factor concerning the first or the second oviposition
>>>          location = factor concerning the exactly position in the
>>> space (just an identity of the oviposition site and responsible for
>>> the repeated comparison)
>>>          month = factor concerning the month when I've collected  
>>> the data
>>>
>>> Is that right? If I wanna repeated comparison regarding specific
>>> identity of oviposition sites, should this factor (location) be a
>>> random variable?
>>>
>>> Furthermore, in both examples above, I'm just considering a temporal
>>> variation (among months) as random a effect. But I'm also interested
>>> if there are significant seasonal variation in the comparison (the
>>> difference could be higher during warm season or not even existent
>>> during cold season). Then:
>>>
>>> model2 <- glmer ( y ~ x + month + (1|location), family="poisson")
>>> model3 <- glmer ( y ~ x * month + (1|location), family="poisson")
>>>
>>> Is that right too?
>>> Finally, I'll use a model selection approach to compare the  
>>> different
>>> models and rank the most likely one to reproduce the data observed  
>>> in
>>> the nature.
>>> Thanks to everyone
>>>
>>> --
>>> Gustavo Requena
>>> PhD student - Laboratory of Arthropod Behavior and Evolution
>>> Universidade de S?o Paulo
>>> Correspondence adress:
>>> a/c Glauco Machado
>>> Departamento de Ecologia - IBUSP
>>> Rua do Mat?o - Travessa 14 no 321 Cidade Universit?ria, S?o Paulo  
>>> - SP,
>>> Brasil
>>> CEP 05508-900
>>> Phone number: 55 11 3091-7488
>>>
>>> http://ecologia.ib.usp.br/opilio/gustavo.html
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From youngjin.lee.ku at gmail.com  Wed Dec  1 17:04:22 2010
From: youngjin.lee.ku at gmail.com (GMail (KU))
Date: Wed, 1 Dec 2010 10:04:22 -0600
Subject: [R-sig-ME] [Q] MCMCglmm priors
Message-ID: <8AD06503-5979-49BD-B56C-E033C209D9FB@gmail.com>

Dear R users,

While I was trying to learn MCMCglmm by following MCMCglmmCourseNotes.pdf, I ran into a few questions, and am looking for some help.

First, for some reason, I cannot load the "Traffic" data set. When I did "data(Traffic)", I got the following warning message:
Warning message:
In data(Traffic) : data set 'Traffic' not found

Since I failed to load the Traffic data set, I was not able to following the examples in the MCMCglmmCourseNotes.pdf. (By the way, I am using the latest version of R (R version 2.12.0) on Mac OS X Snow Leopard (v. 10.6.5). Can any one help me solve this problem?

Second, I understand that MCMCglmm uses Inverse-Wishart distribution to specify a prior for variances. But, unfortunately, I am not used to Inverse-Wishart distribution. Could someone explain how the inverse-Wishart distribution is related to other distributions, such as uniform, normal distributions, that were often used in WinBUGS/JAGS? I know how to specify priors using uniform and normal distributions in WinBUGS/JAGS, but could not figure out how to use the inverse-Wishart distribution. 

Any comments would be highly appreciated!

Young-Jin Lee


From KINLEY_ROBERT at lilly.com  Wed Dec  1 11:22:16 2010
From: KINLEY_ROBERT at lilly.com (Robert Kinley)
Date: Wed, 1 Dec 2010 10:22:16 +0000
Subject: [R-sig-ME] problems formulating arguments to lme()
Message-ID: <OF25B316E2.8B0AA552-ON802577EC.00330375-802577EC.0038D331@EliLilly.lilly.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101201/d8e12e01/attachment.pl>

From bbolker at gmail.com  Wed Dec  1 17:35:07 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 01 Dec 2010 11:35:07 -0500
Subject: [R-sig-ME] problems formulating arguments to lme()
In-Reply-To: <OF25B316E2.8B0AA552-ON802577EC.00330375-802577EC.0038D331@EliLilly.lilly.com>
References: <OF25B316E2.8B0AA552-ON802577EC.00330375-802577EC.0038D331@EliLilly.lilly.com>
Message-ID: <4CF6793B.6070409@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 10-12-01 05:22 AM, Robert Kinley wrote:
> this is a clearer (I hope) version of an earlier post  -

  (Please don't cross-post: r-sig-mixed-models is probably more
appropriate.)

> My problem is formulating the  random = argument to give estimates
> of all 9 random components for this kind of setup where there are
> (I think) 9  variance/covariance components ...
> 
>                              Study.1    Study.2   ...  Study.5
>  Treatment T1: subject:  1  2  3          4  5  6   ...  13 14 15
>  
>  Treatment T2: subject: 16 17 18   19 20 21   ...  28 29 30 
>  
>  A variable is measured at the same 2 fixed sites (a and b) on each 
> subject
> 
> { Toy example data at end of email }
> 
> so fixed effects are :-
>  between-Treatments ( T1 and T2 )
>  between-sites   ( a and b )
>  Treatment*site interaction
> 
> and random effects are :-
>  study effects at site a 
>  study effects at site b
>  correlation between site a and site b study effects 
> 
>  study*treatment interaction effects at site a 
>  study*treatment interaction effects at site b
>  correlation between site a and b study*treatment interaction effects 
>  
>  residual (between-subject) effects at site a 
>  residual (between-subject) effects at site b
>  correlation between site a and b residuals (between-subject) effects 
> 
> I'm having trouble seeing how to formulate this correctly in  lme()

  I don't know offhand if you can do this in lme(), you may need to
switch to lmer() in the lme4 package, but I would take a wild initial
guess at

lme(Result~Treatment*Site,random=list(~Site|Subject,Site*Treatment|Study))

This gives 13 variance components, I'm not sure they're the same as
yours --

  a. variation across subjects
  b. variation in site effect across subjects
  c. correlation between a and b

  d. variation across studies
  e. variation in treatment effect across studies
  f. variation in site effect across studies
  g. variation in site:treatment interaction across studies
  h, i, j, k, l, m ... correlations among these effects.

Because your subjects are (sensibly) numbered uniquely, rather than
within study, you don't have to specify 'nesting' explicitly.

  If you really want to estimate all of these effects I hope you have a
very big data set ...


> Hope someone can help ...
> 
>         cheers          Bob Kinley
> 
>> Toy
>    Study Treatment Subject Site    Result
>    1        T1       1    a      13.901820
>    1        T1       1    b      19.158889
>    1        T1       2    a      16.026299
>    1        T1       2    b      15.545153
>    1        T1       3    a      19.667706
>    1        T1       3    b      21.945156
>    1        T2      16    a       9.822498
>    1        T2      16    b      13.271435
>    1        T2      17    a      18.602909
>    1        T2      17    b      15.679736
>    1        T2      18    a      15.083195
>    1        T2      18    b      18.012834
>    2        T1       4    a      19.394835
>    2        T1       4    b      13.537977
>    2        T1       5    a      17.921014
>    2        T1       5    b      12.070566
>    2        T1       6    a      14.419953
>    2        T1       6    b      16.990585
>    2        T2      19    a      15.489600
>    2        T2      19    b      21.721682
>    2        T2      20    a      18.553789
>    2        T2      20    b      16.628156
>    2        T2      21    a      20.310238
>    2        T2      21    b      18.604716
>    3        T1       7    a      12.458706
>    3        T1       7    b      17.279394
>    3        T1       8    a      14.598512
>    3        T1       8    b      17.024093
>    3        T1       9    a      20.821720
>    3        T1       9    b      22.051680
>    3        T2      22    a      17.923521
>    3        T2      22    b      11.690319
>    3        T2      23    a      12.547144
>    3        T2      23    b      15.051402
>    3        T2      24    a      12.865087
>    3        T2      24    b      13.451004
>    4        T1      10    a      13.819201
>    4        T1      10    b      18.375914
>    4        T1      11    a      18.540972
>    4        T1      11    b      15.741144
>    4        T1      12    a      16.992064
>    4        T1      12    b      16.964870
>    4        T2      25    a      18.583896
>    4        T2      25    b      19.920100
>    4        T2      26    a      18.782343
>    4        T2      26    b      15.095778
>    4        T2      27    a      23.042282
>    4        T2      27    b      19.296852
>    5        T1      13    a      12.425960
>    5        T1      13    b      12.865022
>    5        T1      14    a      16.774604
>    5        T1      14    b      15.540754
>    5        T1      15    a      15.726991
>    5        T1      15    b       8.089564
>    5        T2      28    a      11.694392
>    5        T2      28    b      24.740416
>    5        T2      29    a      14.664904
>    5        T2      29    b      16.348194
>    5        T2      30    a      20.911168
>    5        T2      30    b      15.394160
>>
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iEYEARECAAYFAkz2eTsACgkQc5UpGjwzenOqjQCdEIPvZv4YoXnoWnapsUqZUeLf
qE8AnjRagrymmcgWfonjT1WV9fkgz2e9
=om4v
-----END PGP SIGNATURE-----



From djmuser at gmail.com  Wed Dec  1 20:56:22 2010
From: djmuser at gmail.com (Dennis Murphy)
Date: Wed, 1 Dec 2010 11:56:22 -0800
Subject: [R-sig-ME] [Q] MCMCglmm priors
In-Reply-To: <8AD06503-5979-49BD-B56C-E033C209D9FB@gmail.com>
References: <8AD06503-5979-49BD-B56C-E033C209D9FB@gmail.com>
Message-ID: <AANLkTik8Zy4au+Pf=DT6nmFzxOOxmS=pgK-wSn0Tqrds@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101201/b37d422b/attachment.pl>

From m.fairbrother at bristol.ac.uk  Wed Dec  1 21:10:26 2010
From: m.fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Wed, 1 Dec 2010 20:10:26 +0000
Subject: [R-sig-ME] Another MCMCglmm question - fixing 	correlations
In-Reply-To: <mailman.7.1291201202.14469.r-sig-mixed-models@r-project.org>
References: <mailman.7.1291201202.14469.r-sig-mixed-models@r-project.org>
Message-ID: <65C3FF86-9E7A-449A-86E7-1096E3F480CD@bristol.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101201/93d3e81c/attachment.pl>

From statslearner at gmail.com  Thu Dec  2 03:42:11 2010
From: statslearner at gmail.com (Lucas Kid)
Date: Wed, 1 Dec 2010 21:42:11 -0500
Subject: [R-sig-ME] glmer p-values?
Message-ID: <AANLkTikBas3DYR-+x7rtHsfqCdQo6sps717-pfj3+35k@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101201/66edd1fc/attachment.pl>

From john.maindonald at anu.edu.au  Thu Dec  2 04:52:21 2010
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Thu, 2 Dec 2010 14:52:21 +1100
Subject: [R-sig-ME] glmer p-values?
In-Reply-To: <AANLkTikBas3DYR-+x7rtHsfqCdQo6sps717-pfj3+35k@mail.gmail.com>
References: <AANLkTikBas3DYR-+x7rtHsfqCdQo6sps717-pfj3+35k@mail.gmail.com>
Message-ID: <A80DDC95-0DAB-4966-BBA2-BC957D6FC2C9@anu.edu.au>

You are of course talking about cases, notably poisson
or binomial, where there is a theoretical value for the
exponential family component of variances.

p-values returned by glmer do suffer from the same issues, 
except where observation level random effects can be 
assumed zero, and then only for parameters (if any) where 
the only contribution to the standard error is from the 
binomial or Poisson variance.  (In this situation, for 
purposes of getting estimates and SEs for those 
parameters, a glm model would give very nearly the 
same result.)

They do not however suffer quite so badly, because
part of the variance (the binomial or Poisson part)
is unaffected by degrees of freedom considerations.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 02/12/2010, at 1:42 PM, Lucas Kid wrote:

> Am I correct in assuming that the p-values returned by glmer do not suffer
> from the same issues as those that are not returned by lmer (addressed quite
> famously before by Dr. Bates)?
> 
> Thanks!
> 
> Luke
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bbolker at gmail.com  Thu Dec  2 04:57:49 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 01 Dec 2010 22:57:49 -0500
Subject: [R-sig-ME] glmer p-values?
In-Reply-To: <AANLkTikBas3DYR-+x7rtHsfqCdQo6sps717-pfj3+35k@mail.gmail.com>
References: <AANLkTikBas3DYR-+x7rtHsfqCdQo6sps717-pfj3+35k@mail.gmail.com>
Message-ID: <4CF7193D.2060509@gmail.com>

On 10-12-01 09:42 PM, Lucas Kid wrote:
> Am I correct in assuming that the p-values returned by glmer do not suffer
> from the same issues as those that are not returned by lmer (addressed quite
> famously before by Dr. Bates)?
> 
  Unfortunately, you're incorrect.

  The situation is possibly even worse than for linear mixed models.  To
**very** briefly recap, for classical linear mixed models, we know that
certain ratios of sums of squares are F-distributed with certain degrees
of freedom under the null hypothesis.  This goes away once one leaves
the classical (balanced, orthogonal, nested ...) case.

  For generalized (NOT mixed) linear models, we don't even have a good
(or at least widely used) finite-sample correction (that I know of).
For models with overdispersion there are some cases where you may use an
F test (or at least Venables and Ripley say so), but even that use is
"with caution".

  The usual choices (use large-sample/asymptotic approaches and hope for
the best; MCMC approaches, non-parameteric or parametric bootstrap) apply.

   I would be happy to be corrected by someone.

  Ben Bolker



From john.maindonald at anu.edu.au  Thu Dec  2 05:36:16 2010
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Thu, 2 Dec 2010 15:36:16 +1100
Subject: [R-sig-ME] glmer p-values?
In-Reply-To: <4CF7193D.2060509@gmail.com>
References: <AANLkTikBas3DYR-+x7rtHsfqCdQo6sps717-pfj3+35k@mail.gmail.com>
	<4CF7193D.2060509@gmail.com>
Message-ID: <390A38A0-90BA-4D28-A0CE-C0018E126DD0@anu.edu.au>

Perhaps it is worth adding that there are two kinds of issues:

1) there are the issues that arise in connection with the
asymptotic (large sample) approximations used in GLMs.
Adding in components of normal error may ameliorate
these somewhat, but at the cost of leading to distributions
that are more complicated to characterise.  In any case, 
these issues do not arise for lmer models, not at all events 
if the distributional assumptions are correct.

2) there are the issues on which my message focused,
where adding in components of normally distributed variation
invokes issues, just as for gaussian lmer models, about how 
to allow for uncertainty in the standard error estimates.
----

In some ways maybe better, in some ways worse!  Certainly,
in this no man's land between the normal distributions of
gaussian lmer models, and GLM models with an exponential
error term that has a theoretical variance, the complications
are greater.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 02/12/2010, at 2:57 PM, Ben Bolker wrote:

> On 10-12-01 09:42 PM, Lucas Kid wrote:
>> Am I correct in assuming that the p-values returned by glmer do not suffer
>> from the same issues as those that are not returned by lmer (addressed quite
>> famously before by Dr. Bates)?
>> 
>  Unfortunately, you're incorrect.
> 
>  The situation is possibly even worse than for linear mixed models.  To
> **very** briefly recap, for classical linear mixed models, we know that
> certain ratios of sums of squares are F-distributed with certain degrees
> of freedom under the null hypothesis.  This goes away once one leaves
> the classical (balanced, orthogonal, nested ...) case.
> 
>  For generalized (NOT mixed) linear models, we don't even have a good
> (or at least widely used) finite-sample correction (that I know of).
> For models with overdispersion there are some cases where you may use an
> F test (or at least Venables and Ripley say so), but even that use is
> "with caution".
> 
>  The usual choices (use large-sample/asymptotic approaches and hope for
> the best; MCMC approaches, non-parameteric or parametric bootstrap) apply.
> 
>   I would be happy to be corrected by someone.
> 
>  Ben Bolker
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From j.hadfield at ed.ac.uk  Thu Dec  2 12:20:42 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 2 Dec 2010 11:20:42 +0000
Subject: [R-sig-ME] Another MCMCglmm question - fixing 	correlations
In-Reply-To: <65C3FF86-9E7A-449A-86E7-1096E3F480CD@bristol.ac.uk>
References: <mailman.7.1291201202.14469.r-sig-mixed-models@r-project.org>
	<65C3FF86-9E7A-449A-86E7-1096E3F480CD@bristol.ac.uk>
Message-ID: <EEED6CE6-2D3D-480B-88E3-52A4C25797FA@ed.ac.uk>

Hi Malcolm,

The suggestion of using SIR models for time series was a throw away  
remark, but I can't see anything technically incorrect with it. For  
example the model y[t] = \lambda*y[t-1]+..... can be treated as a SIR  
model, although there are certainly better ways of fitting it. I'm not  
familiar with spatial models and connectivity matrices but if W[i,j]  
is a way of specifying y[i] = \lambda*y[j] + ... then it is possible  
to fit it as a SIR model. You could modify the sir code to do what you  
would like (and then reinstall MCMCglmm) , for example:

sir<-function(W){W}

and then place W in the data.frame.

MCMCglmm will associate design matrices with recursive/simultaneous  
structures if the design matrix is returned from a function called  
"sir".

Cheers,

Jarrod









On 1 Dec 2010, at 20:10, Malcolm Fairbrother wrote:

> Dear Jarrod,
>
> I'm very interested in this SIR feature of MCMCglmm, which I hadn't  
> been aware of until your e-mail earlier today. Do I understand  
> correctly that this should allow for feedback effects between units,  
> reflecting the fact that y(i) and y(not-i) affect each other? If so,  
> this could be a useful way of fitting, for example, spatial  
> autoregressive models, where some units may affect each other by  
> virtue of being neighbours, and we would like to know the magnitude  
> of these effects. (You mentioned time series, but some web searches  
> haven't turned up much on MCMCglmm and time series. And time only  
> flows in one direction, whereas units in space can have two-way  
> effects.)
>
> However, in looking at the documentation and code, I've been  
> struggling a bit with the "sir(~XX, ~XX)" part. Is there a way to  
> specify a "connectivity" matrix directly, rather than using the  
> "sir" function? Looking at the MCMCglmm code, as I understand it,  
> "sir" is both a way of generating a connectivity matrix AND a way of  
> telling MCMCglmm to treat the sir(~XX, ~XX) differently than other  
> covariates.
>
> In the case of spatial autoregressive models, each element on the  
> main diagonal of the connectivity matrix is 0, and rows are often  
> standardised to sum to 1. Such a connectivity matrix might, for  
> example, look like:
>
> N <- 100
> W <- matrix(rbinom(N^2, 1, 0.1), N, N)*upper.tri(matrix(1, N, N)) #  
> chance of being neighbours is 0.1
> W <- W + t(W) # matrix is symmetrical, with zeros on the main diagonal
>
> But I'm having a hard time figuring out how to use "sir" to specify  
> such a matrix in the middle of a call to MCMCglmm.
>
> If you see what I mean, can you offer any suggestions? I might take  
> a stab at modifying MCMCglmm to make this possible, but before I do  
> that (and I'm not certain I'll have the know-how) I wanted to check  
> whether you had any ideas.
>
> Many thanks for any assistance or clarification you can provide.
> - Malcolm
>
>
>
>> Message: 5
>> Date: Wed, 1 Dec 2010 10:28:43 +0000
>> From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
>> To: Szymek Drobniak <geralttee at gmail.com>
>> Cc: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] Another MCMCglmm question - fixing
>> 	correlations
>> Message-ID: <0AF131D6-557C-4324-A65A-A175E41DBA8F at ed.ac.uk>
>> Content-Type: text/plain; charset=US-ASCII; format=flowed; delsp=yes
>>
>> Hi,
>>
>> There is a way, but its quite involved and you may find it easier to
>> fit this type of model in something like ASReml if you can get a
>> license. If not ......
>>
>> I have implemented simultaneous-recursive (SIR) mixed models  in
>> MCMCglmm, although currently they are not well tested or documented
>> (See Chapter 9 of the CourseNotes) and cannot be used with non-
>> Gaussian data or certain patterns of missing data. Nevertheless, in
>> this example the existing code should work fine.  A simple SIR model
>> has the form:
>>
>> y_{i} = mu + \lambda*y_{j} + u_{i} + e_{i}
>>
>> where mu is the intercept, u is a random effect (e.g. breeding value
>> in your case) and e is a residual. The new part of the model is the
>> structural parameter \lambda multiplied by y_{j}, the jth element of
>> the response vector, which can be useful for modelling the effects of
>> behavioural interactions or time series etc.  However, placing y's on
>> the LHS and RHS complicates the likelihood, but MCMCglmm deals with
>> this.
>>
>> If we set i=j then the above equation can be rearranged:
>>
>> y_{i}  - \lambda*y_{i} = mu + u_{i} + e_{i}
>> y_{i}(1  - \lambda) = mu + u_{i} + e_{i}
>> y_{i} = (mu + u_{i} + e_{i})/(1  - \lambda)
>>
>> from this it can be seen that mu, u, e, and \lambda cannot be  
>> uniquely
>> estimated without restrictions.  To illustrate we'll simulate some  
>> data:
>>
>> fac<-gl(25,4)
>> y<-rnorm(25)[fac]+rnorm(100, -1, sqrt(2))
>>
>> # mu = -1, VAR(u)=1, VAR(e) = 2, \lambda = 0
>>
>> dat<-data.frame(y=y, fac=fac)
>>
>> prior1 = list(R=list(V=1, nu=0.002), G=list(G1=list(V=1, nu=0.002)))
>>
>> m1<-MCMCglmm(y~1, random=~fac,  data=dat, prior=prior1)
>>
>> # fitting a non-SIR model gives estimates consistent with the true
>> values, which you can verify through summary(m1). Now for the SIR
>> model. Because we know all parameters cannot be uniquely estimated
>> I've set the residual variance to one arbitrarily.
>>
>> prior2 = list(R=list(V=1, fix=1), G=list(G1=list(V=1, nu=0.002)))
>>
>> m2<-MCMCglmm(y~1+sir(~units, ~units), random=~fac,  data=dat,
>> prior=prior2)   # sir(~units, ~units) sets i=j.
>>
>> # The estimates do not look consistent with the real values.   
>> However,
>> we can rescale them by 1-\lambda and the estimates  are close to  
>> being
>> identical up to Monte Carlo error (the prior will have slightly
>> different effects)
>>
>> HPDinterval(m1$VCV[,1])
>> HPDinterval(m2$VCV[,1]/(1-m2$Lambda)^2)
>>
>> HPDinterval(m1$VCV[,2])
>> HPDinterval(m2$VCV[,2]/(1-m2$Lambda)^2)
>>
>> HPDinterval(m1$Sol)
>> HPDinterval(m2$Sol/(1-m2$Lambda))
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From achaz.hardenberg at gmail.com  Thu Dec  2 15:09:58 2010
From: achaz.hardenberg at gmail.com (Achaz von Hardenberg)
Date: Thu, 2 Dec 2010 15:09:58 +0100
Subject: [R-sig-ME] cenexponential family in MCMCglmm
Message-ID: <74635C38-A64D-4617-9F2F-F06A8C044899@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101202/13c99692/attachment.pl>

From statslearner at gmail.com  Thu Dec  2 20:35:06 2010
From: statslearner at gmail.com (Lucas Kid)
Date: Thu, 2 Dec 2010 14:35:06 -0500
Subject: [R-sig-ME] glmer p-values?
In-Reply-To: <390A38A0-90BA-4D28-A0CE-C0018E126DD0@anu.edu.au>
References: <AANLkTikBas3DYR-+x7rtHsfqCdQo6sps717-pfj3+35k@mail.gmail.com>
	<4CF7193D.2060509@gmail.com>
	<390A38A0-90BA-4D28-A0CE-C0018E126DD0@anu.edu.au>
Message-ID: <AANLkTik_00bv-ojn-Ow4iJZ=2U=E6_MmU=5C0rmsTn9h@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101202/3eb29906/attachment.pl>

From ned.dochtermann at gmail.com  Thu Dec  2 22:45:08 2010
From: ned.dochtermann at gmail.com (Ned Dochtermann)
Date: Thu, 2 Dec 2010 13:45:08 -0800
Subject: [R-sig-ME] Fixed effects structure
Message-ID: <4cf81358.0348960a.7a4f.0128@mx.google.com>

List members,

I have a question regarding the structure of fixed effects and I was hoping
to get a bit of feedback and hopefully direction to a few references. I
figured this topic should be okay here since "mixed" necessarily includes
"fixed".

A colleague of mine is working on a project where she is primarily
interested in the effects of an experimental treatment and the interaction
of the experimental treatment with another fixed factor. She is not,
however, interested in the main effect of this additional factor. 

I know that the conventional wisdom has been that you shouldn't include a
term in an interaction if it isn't also included as a main effect (based on
undergraduate stats mantra). My comment was that since the statistical
hypothesis is meant to represent the biological hypothesis, not including
the main effect *might* be okay. She has some power concerns and would
prefer to maximize her denominator degrees of freedom (yes it is actually a
mixed model; yes I'm aware of the problems with calculating the dfs).

Are there compelling statistical reasons against not including the main
effect? Are there good references discussing this (I know she's gone through
Sokal & Rohlf and a few other books) that would support either argument?

Cliff notes:
is: ~ trt + trt:grp
versus: ~ trt + grp + trt:grp
okay?



Thanks for any feed back,
Ned

--
Ned Dochtermann
Department of Biology
University of Nevada, Reno

ned.dochtermann at gmail.com
http://wolfweb.unr.edu/homepage/mpeacock/Ned.Dochtermann/
http://www.researcherid.com/rid/A-7146-2010
--



From bates at stat.wisc.edu  Thu Dec  2 23:37:06 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 2 Dec 2010 16:37:06 -0600
Subject: [R-sig-ME] Fixed effects structure
In-Reply-To: <4cf81358.0348960a.7a4f.0128@mx.google.com>
References: <4cf81358.0348960a.7a4f.0128@mx.google.com>
Message-ID: <AANLkTikuCVi5NKfwrehdFQku1KS8gvcjcJjD9=HHnOc8@mail.gmail.com>

On Thu, Dec 2, 2010 at 3:45 PM, Ned Dochtermann
<ned.dochtermann at gmail.com> wrote:
> List members,
>
> I have a question regarding the structure of fixed effects and I was hoping
> to get a bit of feedback and hopefully direction to a few references. I
> figured this topic should be okay here since "mixed" necessarily includes
> "fixed".
>
> A colleague of mine is working on a project where she is primarily
> interested in the effects of an experimental treatment and the interaction
> of the experimental treatment with another fixed factor. She is not,
> however, interested in the main effect of this additional factor.
>
> I know that the conventional wisdom has been that you shouldn't include a
> term in an interaction if it isn't also included as a main effect (based on
> undergraduate stats mantra). My comment was that since the statistical
> hypothesis is meant to represent the biological hypothesis, not including
> the main effect *might* be okay. She has some power concerns and would
> prefer to maximize her denominator degrees of freedom (yes it is actually a
> mixed model; yes I'm aware of the problems with calculating the dfs).

Having a term in the model and performing significance tests on that
term are different.  For example, a blocking factor would typically be
included in the model, even if it was not contributing substantially
to the model.

There is one occasion where it makes sense to include an interaction
but not one of the corresponding main effects.  I refer to this as the
"zero dose" or "zero time on treatment" situation.  If you randomly
allocate subjects to a control and one or more treatment groups and
follow them over time, you might expect different slopes with respect
to time in the different groups but you would not expect a difference
in response between groups at time zero.  Thus you would end up
specifying a model with

resp ~ time + time:trt

but no treatment.
> Are there compelling statistical reasons against not including the main
> effect? Are there good references discussing this (I know she's gone through
> Sokal & Rohlf and a few other books) that would support either argument?
>
> Cliff notes:
> is: ~ trt + trt:grp
> versus: ~ trt + grp + trt:grp
> okay?
>
>
>
> Thanks for any feed back,
> Ned
>
> --
> Ned Dochtermann
> Department of Biology
> University of Nevada, Reno
>
> ned.dochtermann at gmail.com
> http://wolfweb.unr.edu/homepage/mpeacock/Ned.Dochtermann/
> http://www.researcherid.com/rid/A-7146-2010
> --
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bbolker at gmail.com  Fri Dec  3 01:16:59 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 02 Dec 2010 19:16:59 -0500
Subject: [R-sig-ME] Fixed effects structure
In-Reply-To: <AANLkTikuCVi5NKfwrehdFQku1KS8gvcjcJjD9=HHnOc8@mail.gmail.com>
References: <4cf81358.0348960a.7a4f.0128@mx.google.com>
	<AANLkTikuCVi5NKfwrehdFQku1KS8gvcjcJjD9=HHnOc8@mail.gmail.com>
Message-ID: <4CF836FB.6050900@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1


>> Cliff notes:
>> is: ~ trt + trt:grp
>> versus: ~ trt + grp + trt:grp
>> okay?

  It may not have the effect you want or think -- it
will just reparameterize the effects, not change the df expended.

For example:

> d <- expand.grid(trt=factor(1:5),grp=factor(1:3))
> ncol(model.matrix(~trt+trt:grp,data=d))
[1] 15
> ncol(model.matrix(~trt+grp+trt:grp,data=d))
[1] 15


  For a little more detail, using only two levels of each factor for
clarity:

> d <- expand.grid(trt=factor(1:2),grp=factor(1:2))


> model.matrix(~trt+grp+trt:grp,data=d)
  (Intercept) trt2 grp2 trt2:grp2
1           1    0    0         0
2           1    1    0         0
3           1    0    1         0
4           1    1    1         1
attr(,"assign")
[1] 0 1 2 3
attr(,"contrasts")
attr(,"contrasts")$trt
[1] "contr.treatment"

attr(,"contrasts")$grp
[1] "contr.treatment"


> model.matrix(~trt+trt:grp,data=d)
  (Intercept) trt2 trt1:grp2 trt2:grp2
1           1    0         0         0
2           1    1         0         0
3           1    0         1         0
4           1    1         0         1
attr(,"assign")
[1] 0 1 2 2
attr(,"contrasts")
attr(,"contrasts")$trt
[1] "contr.treatment"

attr(,"contrasts")$grp
[1] "contr.treatment"


-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iEYEARECAAYFAkz4NvsACgkQc5UpGjwzenMtVgCbBY8WINmHfRfPZcgpnEPZxcZe
CQYAnjj+S+WOHTaZOfQo1LspYAnRGHAS
=xIeI
-----END PGP SIGNATURE-----



From j.hadfield at ed.ac.uk  Fri Dec  3 11:31:41 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 03 Dec 2010 10:31:41 +0000
Subject: [R-sig-ME] cenexponential family in MCMCglmm
In-Reply-To: <74635C38-A64D-4617-9F2F-F06A8C044899@gmail.com>
References: <74635C38-A64D-4617-9F2F-F06A8C044899@gmail.com>
Message-ID: <20101203103141.14333dn7fcrwi24g@www.staffmail.ed.ac.uk>

Hi Achaz,

The minimum and maximum values the response could take is the  
response, essentially. As an example,

y<-rexp(1000,exp(rnorm(1000, 0.5, 1)))
dat<-data.frame(y=y, ymin=floor(y), ymax=ceiling(y))
dat$ymax[which(dat$ymax>3)]<-Inf
dat$ymin[which(dat$ymax>3)]<-3

# Interval censoring [0,1) [1,2) [2,3] and right censoring [3,Inf]

m1<-MCMCglmm(cbind(ymin, ymax)~1, family="cenexponential", data=dat)

Cheers,

Jarrod


Quoting Achaz von Hardenberg <achaz.hardenberg at gmail.com>:

> Dear all,
> I am trying to fit a MCMCglmm model with right censored exponential  
> data as a response where the minimum value the response can be is 0  
> and INF the maximum.
> However, I can not find in the documentation, nor on the web, any  
> example about how I should specify such a model.
> This is what is written in the tutorial:
>
> "For censored responses two data columns must be passed. The first  
> column should contain the minimum value the data could take and the  
> second column the maximum."
>
> But it is not clear to me how I should pass these two columns  
> together with the response variable in the model...
> Could anybody send me an example?
>
>
> Thanks a lot for your assistance!
>
> achaz
>
>
> Dr. Achaz von Hardenberg
> --------------------------------------------------------------------------------------------------------
> Centro Studi Fauna Alpina - Alpine Wildlife Research Centre
> Servizio Sanitario e della Ricerca Scientifica
> Parco Nazionale Gran Paradiso, Degioz, 11, 11010-Valsavarenche (Ao), Italy
>
> E-mail: achaz.hardenberg at pngp.it
> 	     fauna at pngp.it
> Skype: achazhardenberg
> --------------------------------------------------------------------------------------------------------
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From cyrille.gouat at ens-lyon.fr  Fri Dec  3 15:23:54 2010
From: cyrille.gouat at ens-lyon.fr (Cyrille Gouat)
Date: Fri, 03 Dec 2010 15:23:54 +0100
Subject: [R-sig-ME] Predictions with glmer
Message-ID: <20101203152354.97582ok567fjmwl6@webmail.ens-lyon.fr>

Hello,

I'm a master student and a newbie with mixed models.
I'm doing generalised linear mixed models using lme4 with binomial  
family to test facotrs influencing reproduction (success or failure)  
and I was wondering weather it was possible to obtain predictions with  
such model taking into acount fixed and random effects and would it  
make sense?
Here is the model I use:

m3<-glmer(reproduction~year+habitat+(1|Id), family=binomial, data= dv)

I have missing data in my dataset (not all years for each individual)  
so I was wondering if it was to reconstitute individual trajectories.

Thanks for your help.

Cyrille



From a.mosnier at gmail.com  Fri Dec  3 16:20:47 2010
From: a.mosnier at gmail.com (Arnaud Mosnier)
Date: Fri, 3 Dec 2010 10:20:47 -0500
Subject: [R-sig-ME] Evaluating mixed logistic model efficiency
Message-ID: <AANLkTi=i-wOADyJME8XWV6a=aZzAMgT=1PYfV_hXOkAX@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101203/57daff06/attachment.pl>

From atyre2 at unl.edu  Fri Dec  3 16:50:46 2010
From: atyre2 at unl.edu (Drew Tyre)
Date: Fri, 3 Dec 2010 09:50:46 -0600
Subject: [R-sig-ME] Evaluating mixed logistic model efficiency
In-Reply-To: <AANLkTi=i-wOADyJME8XWV6a=aZzAMgT=1PYfV_hXOkAX@mail.gmail.com>
References: <AANLkTi=i-wOADyJME8XWV6a=aZzAMgT=1PYfV_hXOkAX@mail.gmail.com>
Message-ID: <AANLkTi=dpkD+Ug+KMUGSFm+DUyS1PSZtZ3ox2DJ9FtBe@mail.gmail.com>

Arnaud,

If you have binary 0/1 data one widely used method for looking at the
quality of the fit uses the Area under the Receiver Operating
Characteristic Curve - variously abbreviated ROC or AUC. It gives the
probability your model will correctly rank any two observations. There
is a nice package PresenceAbsence which does the calculations and
makes pretty plots.

If you have binomial data you can compare the residual deviance with a
Chisquare distribution with n-p df (n is sample size and p is the
number of parameters), but I'm not sure how well that works in the
mixed model case. I look forward to other suggestions.

On Fri, Dec 3, 2010 at 9:20 AM, Arnaud Mosnier <a.mosnier at gmail.com> wrote:
> Dear mixed modelers,
>
> In my actual knowledge status, the best available measures to evaluate
> goodness-of-fit of a mixed logistic model are Deviance, LogLikelihood, AIC,
> AICc if necessary, BIC (I may forgot some of them but they are all linked).
> However, these measures only permit to classify models from the best to the
> worse without knowing if the best model is really efficient in explaining
> the data.
>
> It exists pseudo-R2 calculation based on differences between the likelihood
> of ?the intersect only model and the likelihood of the model that you wanted
> to evaluate. But use of those methods are generally discouraged.
>
> I would like your opinion about that !
> If you have any suggestion I will be happy to learn from you !
>
> Thanks for your help.
>
> Arnaud
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Drew Tyre

School of Natural Resources
University of Nebraska-Lincoln
416 Hardin Hall, East Campus
3310 Holdrege Street
Lincoln, NE 68583-0974

phone: +1 402 472 4054
fax: +1 402 472 2946
email: atyre2 at unl.edu
http://snr.unl.edu/tyre
http://aminpractice.blogspot.com
http://www.flickr.com/photos/atiretoo



From m.fairbrother at bristol.ac.uk  Fri Dec  3 19:31:14 2010
From: m.fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Fri, 3 Dec 2010 18:31:14 +0000
Subject: [R-sig-ME] Another MCMCglmm question - fixing 	correlations
In-Reply-To: <EEED6CE6-2D3D-480B-88E3-52A4C25797FA@ed.ac.uk>
References: <mailman.7.1291201202.14469.r-sig-mixed-models@r-project.org>
	<65C3FF86-9E7A-449A-86E7-1096E3F480CD@bristol.ac.uk>
	<EEED6CE6-2D3D-480B-88E3-52A4C25797FA@ed.ac.uk>
Message-ID: <7FC5B5A7-3E8D-43ED-B54F-7785257F3841@bristol.ac.uk>

Hi Jarrod,

Thanks very much for the suggestion. However, in trying what you said, I'm not getting very far (see code below). I redefine the function "sir", and then re-install the MCMCglmm package. But the MCMCglmm function still seems to use the old "sir" function, not the new one, with the result that when I try calling sir in the middle of a call to MCMCglmm, I get an error message telling me that my call to sir is problematic ("Error in sir(W) : formula not passed to formula1 in sir"). Can you please clarify what I'm doing wrong?

Thanks again for any assistance.
- Malcolm


sir <- function(W) {W}
install.packages("MCMCglmm")
library(MCMCglmm)

N <- 50 # set sample size
W <- matrix(rbinom(N^2, 1, 0.25), N, N)*upper.tri(matrix(1, N, N))
W <- W + t(W) # symmetrical connectivity matrix
rho <- 0.2 # set autocorrelation coefficient
M <- solve(diag(N) - rho*W)
X1 <- runif(N, min=-5, max=5)
Xbe <- X1+rnorm(N)
y <- M %*% Xbe # generate lagged y
dat <- data.frame(X1=X1, y=y)

prior1 = list(R=list(V=1, nu=0.002), G=list(G1=list(V=1, nu=0.002)))
MC1 <- MCMCglmm(y ~ X1, data=dat, prior=prior1, verbose=F)
# works OK, compare with summary(lm(dat$y~dat$X1))

identical(sir(W), W) # TRUE
MC2 <- MCMCglmm(y ~ X1 + sir(W), data=dat, prior=prior1, verbose=F)
# doesn't work

fac2 <- fac1 < -factor(sample(letters, N, TRUE), levels=letters)
MC3 <- MCMCglmm(y ~ X1 + sir(~fac1, ~fac2), data=dat, prior=prior1, verbose=F)
# works--results are meaningless, but doesn't return any error





On 2 Dec 2010, at 11:20, Jarrod Hadfield wrote:

> Hi Malcolm,
> 
> The suggestion of using SIR models for time series was a throw away remark, but I can't see anything technically incorrect with it. For example the model y[t] = \lambda*y[t-1]+..... can be treated as a SIR model, although there are certainly better ways of fitting it. I'm not familiar with spatial models and connectivity matrices but if W[i,j] is a way of specifying y[i] = \lambda*y[j] + ... then it is possible to fit it as a SIR model. You could modify the sir code to do what you would like (and then reinstall MCMCglmm) , for example:
> 
> sir<-function(W){W}
> 
> and then place W in the data.frame.
> 
> MCMCglmm will associate design matrices with recursive/simultaneous structures if the design matrix is returned from a function called "sir".
> 
> Cheers,
> 
> Jarrod
> 
> 
> 
> 
> 
> 
> 
> 
> 
> On 1 Dec 2010, at 20:10, Malcolm Fairbrother wrote:
> 
>> Dear Jarrod,
>> 
>> I'm very interested in this SIR feature of MCMCglmm, which I hadn't been aware of until your e-mail earlier today. Do I understand correctly that this should allow for feedback effects between units, reflecting the fact that y(i) and y(not-i) affect each other? If so, this could be a useful way of fitting, for example, spatial autoregressive models, where some units may affect each other by virtue of being neighbours, and we would like to know the magnitude of these effects. (You mentioned time series, but some web searches haven't turned up much on MCMCglmm and time series. And time only flows in one direction, whereas units in space can have two-way effects.)
>> 
>> However, in looking at the documentation and code, I've been struggling a bit with the "sir(~XX, ~XX)" part. Is there a way to specify a "connectivity" matrix directly, rather than using the "sir" function? Looking at the MCMCglmm code, as I understand it, "sir" is both a way of generating a connectivity matrix AND a way of telling MCMCglmm to treat the sir(~XX, ~XX) differently than other covariates.
>> 
>> In the case of spatial autoregressive models, each element on the main diagonal of the connectivity matrix is 0, and rows are often standardised to sum to 1. Such a connectivity matrix might, for example, look like:
>> 
>> N <- 100
>> W <- matrix(rbinom(N^2, 1, 0.1), N, N)*upper.tri(matrix(1, N, N)) # chance of being neighbours is 0.1
>> W <- W + t(W) # matrix is symmetrical, with zeros on the main diagonal
>> 
>> But I'm having a hard time figuring out how to use "sir" to specify such a matrix in the middle of a call to MCMCglmm.
>> 
>> If you see what I mean, can you offer any suggestions? I might take a stab at modifying MCMCglmm to make this possible, but before I do that (and I'm not certain I'll have the know-how) I wanted to check whether you had any ideas.
>> 
>> Many thanks for any assistance or clarification you can provide.
>> - Malcolm
>> 
>> 
>> 
>>> Message: 5
>>> Date: Wed, 1 Dec 2010 10:28:43 +0000
>>> From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>> To: Szymek Drobniak <geralttee at gmail.com>
>>> Cc: r-sig-mixed-models at r-project.org
>>> Subject: Re: [R-sig-ME] Another MCMCglmm question - fixing
>>> 	correlations
>>> Message-ID: <0AF131D6-557C-4324-A65A-A175E41DBA8F at ed.ac.uk>
>>> Content-Type: text/plain; charset=US-ASCII; format=flowed; delsp=yes
>>> 
>>> Hi,
>>> 
>>> There is a way, but its quite involved and you may find it easier to
>>> fit this type of model in something like ASReml if you can get a
>>> license. If not ......
>>> 
>>> I have implemented simultaneous-recursive (SIR) mixed models  in
>>> MCMCglmm, although currently they are not well tested or documented
>>> (See Chapter 9 of the CourseNotes) and cannot be used with non-
>>> Gaussian data or certain patterns of missing data. Nevertheless, in
>>> this example the existing code should work fine.  A simple SIR model
>>> has the form:
>>> 
>>> y_{i} = mu + \lambda*y_{j} + u_{i} + e_{i}
>>> 
>>> where mu is the intercept, u is a random effect (e.g. breeding value
>>> in your case) and e is a residual. The new part of the model is the
>>> structural parameter \lambda multiplied by y_{j}, the jth element of
>>> the response vector, which can be useful for modelling the effects of
>>> behavioural interactions or time series etc.  However, placing y's on
>>> the LHS and RHS complicates the likelihood, but MCMCglmm deals with
>>> this.
>>> 
>>> If we set i=j then the above equation can be rearranged:
>>> 
>>> y_{i}  - \lambda*y_{i} = mu + u_{i} + e_{i}
>>> y_{i}(1  - \lambda) = mu + u_{i} + e_{i}
>>> y_{i} = (mu + u_{i} + e_{i})/(1  - \lambda)
>>> 
>>> from this it can be seen that mu, u, e, and \lambda cannot be uniquely
>>> estimated without restrictions.  To illustrate we'll simulate some data:
>>> 
>>> fac<-gl(25,4)
>>> y<-rnorm(25)[fac]+rnorm(100, -1, sqrt(2))
>>> 
>>> # mu = -1, VAR(u)=1, VAR(e) = 2, \lambda = 0
>>> 
>>> dat<-data.frame(y=y, fac=fac)
>>> 
>>> prior1 = list(R=list(V=1, nu=0.002), G=list(G1=list(V=1, nu=0.002)))
>>> 
>>> m1<-MCMCglmm(y~1, random=~fac,  data=dat, prior=prior1)
>>> 
>>> # fitting a non-SIR model gives estimates consistent with the true
>>> values, which you can verify through summary(m1). Now for the SIR
>>> model. Because we know all parameters cannot be uniquely estimated
>>> I've set the residual variance to one arbitrarily.
>>> 
>>> prior2 = list(R=list(V=1, fix=1), G=list(G1=list(V=1, nu=0.002)))
>>> 
>>> m2<-MCMCglmm(y~1+sir(~units, ~units), random=~fac,  data=dat,
>>> prior=prior2)   # sir(~units, ~units) sets i=j.
>>> 
>>> # The estimates do not look consistent with the real values.  However,
>>> we can rescale them by 1-\lambda and the estimates  are close to being
>>> identical up to Monte Carlo error (the prior will have slightly
>>> different effects)
>>> 
>>> HPDinterval(m1$VCV[,1])
>>> HPDinterval(m2$VCV[,1]/(1-m2$Lambda)^2)
>>> 
>>> HPDinterval(m1$VCV[,2])
>>> HPDinterval(m2$VCV[,2]/(1-m2$Lambda)^2)
>>> 
>>> HPDinterval(m1$Sol)
>>> HPDinterval(m2$Sol/(1-m2$Lambda))
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> 
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
> 



From a.mosnier at gmail.com  Fri Dec  3 19:52:38 2010
From: a.mosnier at gmail.com (Arnaud Mosnier)
Date: Fri, 3 Dec 2010 13:52:38 -0500
Subject: [R-sig-ME] complex random effect
Message-ID: <AANLkTikT7u7aV5tFtfaWrOZepOz6nvRRmF3=uMxXe0d5@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101203/00c91c49/attachment.pl>

From j.hadfield at ed.ac.uk  Sat Dec  4 22:11:50 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 04 Dec 2010 21:11:50 +0000
Subject: [R-sig-ME] Another MCMCglmm question - fixing 	correlations
In-Reply-To: <7FC5B5A7-3E8D-43ED-B54F-7785257F3841@bristol.ac.uk>
References: <mailman.7.1291201202.14469.r-sig-mixed-models@r-project.org>
	<65C3FF86-9E7A-449A-86E7-1096E3F480CD@bristol.ac.uk>
	<EEED6CE6-2D3D-480B-88E3-52A4C25797FA@ed.ac.uk>
	<7FC5B5A7-3E8D-43ED-B54F-7785257F3841@bristol.ac.uk>
Message-ID: <20101204211150.50434f1dwuwqf7ok@www.staffmail.ed.ac.uk>

Hi Malcolm,

I meant replace the sir function in the R directory and rebuild +  
reinstall MCMCglmm. However, I later realised that for your problem  
there is a simpler way:

N <- 50 # set sample size
W <- matrix(rbinom(N^2, 1, 0.25), N, N)*upper.tri(matrix(1, N, N))
W <- W + t(W) # symmetrical connectivity matrix
rho <- 0.2 # set autocorrelation coefficient
L <- diag(N) - rho*W  # my L is your M^{-1}
X1 <- runif(N, min=-5, max=5)
Xbe <- X1+rnorm(N)
y <- solve(L, Xbe) # generate lagged y
dat <- data.frame(X1=X1, y=y, W=W)

prior1 = list(R=list(V=1, nu=0.002))
MC2 <- MCMCglmm(y ~ X1+sir(~W, ~units), data=dat, prior=prior1, verbose=F)

This works because ~units sets up an identity matrix and W%*%t(I) = W.

However, I could not get sensible results from MCMCglmm with rho=0.3  
and wasn't sure why (rho=0.03 for example gives sense). The problem is  
associated with a change in the sign of the determinant of L (or M)  
(i.e the Jacobian), which is perhaps not that surprising since if W=I  
then rho=0.3 and rho = 1.7 should be indiscriminable even with a fixed  
residual variance:

y = Xbe/(1-0.3) = -Xbe/(1-1.7)

I would have to think about this harder than I have to offer a  
solution (this is why the sir models are undocumented!), but perhaps  
you have some insight?

Also, I don't think MC3 results are meaningless, the estimate for the  
sir parameter overlaps zero as expected.

Cheers,

Jarrod



Quoting Malcolm Fairbrother <m.fairbrother at bristol.ac.uk>:

> Hi Jarrod,
>
> Thanks very much for the suggestion. However, in trying what you  
> said, I'm not getting very far (see code below). I redefine the  
> function "sir", and then re-install the MCMCglmm package. But the  
> MCMCglmm function still seems to use the old "sir" function, not the  
> new one, with the result that when I try calling sir in the middle  
> of a call to MCMCglmm, I get an error message telling me that my  
> call to sir is problematic ("Error in sir(W) : formula not passed to  
> formula1 in sir"). Can you please clarify what I'm doing wrong?
>
> Thanks again for any assistance.
> - Malcolm
>
>
> sir <- function(W) {W}
> install.packages("MCMCglmm")
> library(MCMCglmm)
>
> N <- 50 # set sample size
> W <- matrix(rbinom(N^2, 1, 0.25), N, N)*upper.tri(matrix(1, N, N))
> W <- W + t(W) # symmetrical connectivity matrix
> rho <- 0.2 # set autocorrelation coefficient
> M <- solve(diag(N) - rho*W)
> X1 <- runif(N, min=-5, max=5)
> Xbe <- X1+rnorm(N)
> y <- M %*% Xbe # generate lagged y
> dat <- data.frame(X1=X1, y=y)
>
> prior1 = list(R=list(V=1, nu=0.002), G=list(G1=list(V=1, nu=0.002)))
> MC1 <- MCMCglmm(y ~ X1, data=dat, prior=prior1, verbose=F)
> # works OK, compare with summary(lm(dat$y~dat$X1))
>
> identical(sir(W), W) # TRUE
> MC2 <- MCMCglmm(y ~ X1 + sir(W), data=dat, prior=prior1, verbose=F)
> # doesn't work
>
> fac2 <- fac1 < -factor(sample(letters, N, TRUE), levels=letters)
> MC3 <- MCMCglmm(y ~ X1 + sir(~fac1, ~fac2), data=dat, prior=prior1,  
> verbose=F)
> # works--results are meaningless, but doesn't return any error
>
>
>
>
>
> On 2 Dec 2010, at 11:20, Jarrod Hadfield wrote:
>
>> Hi Malcolm,
>>
>> The suggestion of using SIR models for time series was a throw away  
>> remark, but I can't see anything technically incorrect with it. For  
>> example the model y[t] = \lambda*y[t-1]+..... can be treated as a  
>> SIR model, although there are certainly better ways of fitting it.  
>> I'm not familiar with spatial models and connectivity matrices but  
>> if W[i,j] is a way of specifying y[i] = \lambda*y[j] + ... then it  
>> is possible to fit it as a SIR model. You could modify the sir code  
>> to do what you would like (and then reinstall MCMCglmm) , for  
>> example:
>>
>> sir<-function(W){W}
>>
>> and then place W in the data.frame.
>>
>> MCMCglmm will associate design matrices with recursive/simultaneous  
>> structures if the design matrix is returned from a function called  
>> "sir".
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> On 1 Dec 2010, at 20:10, Malcolm Fairbrother wrote:
>>
>>> Dear Jarrod,
>>>
>>> I'm very interested in this SIR feature of MCMCglmm, which I  
>>> hadn't been aware of until your e-mail earlier today. Do I  
>>> understand correctly that this should allow for feedback effects  
>>> between units, reflecting the fact that y(i) and y(not-i) affect  
>>> each other? If so, this could be a useful way of fitting, for  
>>> example, spatial autoregressive models, where some units may  
>>> affect each other by virtue of being neighbours, and we would like  
>>> to know the magnitude of these effects. (You mentioned time  
>>> series, but some web searches haven't turned up much on MCMCglmm  
>>> and time series. And time only flows in one direction, whereas  
>>> units in space can have two-way effects.)
>>>
>>> However, in looking at the documentation and code, I've been  
>>> struggling a bit with the "sir(~XX, ~XX)" part. Is there a way to  
>>> specify a "connectivity" matrix directly, rather than using the  
>>> "sir" function? Looking at the MCMCglmm code, as I understand it,  
>>> "sir" is both a way of generating a connectivity matrix AND a way  
>>> of telling MCMCglmm to treat the sir(~XX, ~XX) differently than  
>>> other covariates.
>>>
>>> In the case of spatial autoregressive models, each element on the  
>>> main diagonal of the connectivity matrix is 0, and rows are often  
>>> standardised to sum to 1. Such a connectivity matrix might, for  
>>> example, look like:
>>>
>>> N <- 100
>>> W <- matrix(rbinom(N^2, 1, 0.1), N, N)*upper.tri(matrix(1, N, N))  
>>> # chance of being neighbours is 0.1
>>> W <- W + t(W) # matrix is symmetrical, with zeros on the main diagonal
>>>
>>> But I'm having a hard time figuring out how to use "sir" to  
>>> specify such a matrix in the middle of a call to MCMCglmm.
>>>
>>> If you see what I mean, can you offer any suggestions? I might  
>>> take a stab at modifying MCMCglmm to make this possible, but  
>>> before I do that (and I'm not certain I'll have the know-how) I  
>>> wanted to check whether you had any ideas.
>>>
>>> Many thanks for any assistance or clarification you can provide.
>>> - Malcolm
>>>
>>>
>>>
>>>> Message: 5
>>>> Date: Wed, 1 Dec 2010 10:28:43 +0000
>>>> From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>>> To: Szymek Drobniak <geralttee at gmail.com>
>>>> Cc: r-sig-mixed-models at r-project.org
>>>> Subject: Re: [R-sig-ME] Another MCMCglmm question - fixing
>>>> 	correlations
>>>> Message-ID: <0AF131D6-557C-4324-A65A-A175E41DBA8F at ed.ac.uk>
>>>> Content-Type: text/plain; charset=US-ASCII; format=flowed; delsp=yes
>>>>
>>>> Hi,
>>>>
>>>> There is a way, but its quite involved and you may find it easier to
>>>> fit this type of model in something like ASReml if you can get a
>>>> license. If not ......
>>>>
>>>> I have implemented simultaneous-recursive (SIR) mixed models  in
>>>> MCMCglmm, although currently they are not well tested or documented
>>>> (See Chapter 9 of the CourseNotes) and cannot be used with non-
>>>> Gaussian data or certain patterns of missing data. Nevertheless, in
>>>> this example the existing code should work fine.  A simple SIR model
>>>> has the form:
>>>>
>>>> y_{i} = mu + \lambda*y_{j} + u_{i} + e_{i}
>>>>
>>>> where mu is the intercept, u is a random effect (e.g. breeding value
>>>> in your case) and e is a residual. The new part of the model is the
>>>> structural parameter \lambda multiplied by y_{j}, the jth element of
>>>> the response vector, which can be useful for modelling the effects of
>>>> behavioural interactions or time series etc.  However, placing y's on
>>>> the LHS and RHS complicates the likelihood, but MCMCglmm deals with
>>>> this.
>>>>
>>>> If we set i=j then the above equation can be rearranged:
>>>>
>>>> y_{i}  - \lambda*y_{i} = mu + u_{i} + e_{i}
>>>> y_{i}(1  - \lambda) = mu + u_{i} + e_{i}
>>>> y_{i} = (mu + u_{i} + e_{i})/(1  - \lambda)
>>>>
>>>> from this it can be seen that mu, u, e, and \lambda cannot be uniquely
>>>> estimated without restrictions.  To illustrate we'll simulate some data:
>>>>
>>>> fac<-gl(25,4)
>>>> y<-rnorm(25)[fac]+rnorm(100, -1, sqrt(2))
>>>>
>>>> # mu = -1, VAR(u)=1, VAR(e) = 2, \lambda = 0
>>>>
>>>> dat<-data.frame(y=y, fac=fac)
>>>>
>>>> prior1 = list(R=list(V=1, nu=0.002), G=list(G1=list(V=1, nu=0.002)))
>>>>
>>>> m1<-MCMCglmm(y~1, random=~fac,  data=dat, prior=prior1)
>>>>
>>>> # fitting a non-SIR model gives estimates consistent with the true
>>>> values, which you can verify through summary(m1). Now for the SIR
>>>> model. Because we know all parameters cannot be uniquely estimated
>>>> I've set the residual variance to one arbitrarily.
>>>>
>>>> prior2 = list(R=list(V=1, fix=1), G=list(G1=list(V=1, nu=0.002)))
>>>>
>>>> m2<-MCMCglmm(y~1+sir(~units, ~units), random=~fac,  data=dat,
>>>> prior=prior2)   # sir(~units, ~units) sets i=j.
>>>>
>>>> # The estimates do not look consistent with the real values.  However,
>>>> we can rescale them by 1-\lambda and the estimates  are close to being
>>>> identical up to Monte Carlo error (the prior will have slightly
>>>> different effects)
>>>>
>>>> HPDinterval(m1$VCV[,1])
>>>> HPDinterval(m2$VCV[,1]/(1-m2$Lambda)^2)
>>>>
>>>> HPDinterval(m1$VCV[,2])
>>>> HPDinterval(m2$VCV[,2]/(1-m2$Lambda)^2)
>>>>
>>>> HPDinterval(m1$Sol)
>>>> HPDinterval(m2$Sol/(1-m2$Lambda))
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From m.fairbrother at bristol.ac.uk  Sun Dec  5 17:16:07 2010
From: m.fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Sun, 5 Dec 2010 16:16:07 +0000
Subject: [R-sig-ME] Another MCMCglmm question - fixing 	correlations
In-Reply-To: <20101204211150.50434f1dwuwqf7ok@www.staffmail.ed.ac.uk>
References: <mailman.7.1291201202.14469.r-sig-mixed-models@r-project.org>
	<65C3FF86-9E7A-449A-86E7-1096E3F480CD@bristol.ac.uk>
	<EEED6CE6-2D3D-480B-88E3-52A4C25797FA@ed.ac.uk>
	<7FC5B5A7-3E8D-43ED-B54F-7785257F3841@bristol.ac.uk>
	<20101204211150.50434f1dwuwqf7ok@www.staffmail.ed.ac.uk>
Message-ID: <3259EF79-BB81-4C7B-90D7-F51948B88022@bristol.ac.uk>

Hi Jarrod,

Thanks very much for the suggestions, which did the trick. (And standardising the row weights to 1 seemed to prevent any trouble with any values of rho.)

MCMCglmm does appear to fit spatial simultaneous autoregressive lag models, and about as well as the specialised functions for such models in the "spdep" package. I've tried a few values of rho, and MCMCglmm recovers them well (the estimates from both it and "lagsarlm"  are slightly downward biased--see below for simulations code).

My real/ulterior interest here is actually estimating multilevel models where diffusion takes place across higher-level units, and some preliminary investigations suggest that MCMCglmm can fit such a model--unlike any other R function I've tried--but I'll spare the list the gory details of this work-in-progress, unless somebody wants to know.

Cheers,
Malcolm



library(MCMCglmm)
library(spdep)
N <- 50 # set sample size
rho <- 0.6 # set autocorrelation coefficient
sims <- 100
prior1 = list(R=list(V=1, nu=0.002))
MSE <- res <- matrix(NA, nrow=sims, ncol=6)
for (i in 1:sims) {
	W <- matrix(rbinom(N^2, 1, 0.25), N, N)*upper.tri(matrix(1, N, N))
	W <- W + t(W) # symmetrical connectivity matrix
	W <- W/apply(W, 1, sum) # standardise rows
	listw <- mat2listw(W) # convert contiguities to listw format
	L <- diag(N) - rho*W
	X1 <- runif(N, min=-5, max=5)
	Xbe <- X1+rnorm(N)
	y <- solve(L, Xbe) # generate lagged y
	dat <- data.frame(X1=X1, y=y, W=W)
	autoreg <- lagsarlm(y ~ X1, listw=listw, data=dat) # fit autoregressive model
	MC2 <- MCMCglmm(y ~ X1+sir(~W, ~units), data=dat, prior=prior1, verbose=F)
	res[i,] <- c(coefficients(autoreg), mean(MC2$Lambda), apply(MC2$Sol, 2, mean))
	MSE[i,] <- c((coefficients(autoreg)-c(rho, 0, 1))^2, (mean(MC2$Lambda)-rho)^2, (apply(MC2$Sol, 2, mean) - c(0, 1))^2)
	}



On 4 Dec 2010, at 21:11, Jarrod Hadfield wrote:

> Hi Malcolm,
> 
> I meant replace the sir function in the R directory and rebuild + reinstall MCMCglmm. However, I later realised that for your problem there is a simpler way:
> 
> N <- 50 # set sample size
> W <- matrix(rbinom(N^2, 1, 0.25), N, N)*upper.tri(matrix(1, N, N))
> W <- W + t(W) # symmetrical connectivity matrix
> rho <- 0.2 # set autocorrelation coefficient
> L <- diag(N) - rho*W  # my L is your M^{-1}
> X1 <- runif(N, min=-5, max=5)
> Xbe <- X1+rnorm(N)
> y <- solve(L, Xbe) # generate lagged y
> dat <- data.frame(X1=X1, y=y, W=W)
> 
> prior1 = list(R=list(V=1, nu=0.002))
> MC2 <- MCMCglmm(y ~ X1+sir(~W, ~units), data=dat, prior=prior1, verbose=F)
> 
> This works because ~units sets up an identity matrix and W%*%t(I) = W.
> 
> However, I could not get sensible results from MCMCglmm with rho=0.3 and wasn't sure why (rho=0.03 for example gives sense). The problem is associated with a change in the sign of the determinant of L (or M) (i.e the Jacobian), which is perhaps not that surprising since if W=I then rho=0.3 and rho = 1.7 should be indiscriminable even with a fixed residual variance:
> 
> y = Xbe/(1-0.3) = -Xbe/(1-1.7)
> 
> I would have to think about this harder than I have to offer a solution (this is why the sir models are undocumented!), but perhaps you have some insight?
> 
> Also, I don't think MC3 results are meaningless, the estimate for the sir parameter overlaps zero as expected.
> 
> Cheers,
> 
> Jarrod
> 
> 
> 
> Quoting Malcolm Fairbrother <m.fairbrother at bristol.ac.uk>:
> 
>> Hi Jarrod,
>> 
>> Thanks very much for the suggestion. However, in trying what you said, I'm not getting very far (see code below). I redefine the function "sir", and then re-install the MCMCglmm package. But the MCMCglmm function still seems to use the old "sir" function, not the new one, with the result that when I try calling sir in the middle of a call to MCMCglmm, I get an error message telling me that my call to sir is problematic ("Error in sir(W) : formula not passed to formula1 in sir"). Can you please clarify what I'm doing wrong?
>> 
>> Thanks again for any assistance.
>> - Malcolm
>> 
>> 
>> sir <- function(W) {W}
>> install.packages("MCMCglmm")
>> library(MCMCglmm)
>> 
>> N <- 50 # set sample size
>> W <- matrix(rbinom(N^2, 1, 0.25), N, N)*upper.tri(matrix(1, N, N))
>> W <- W + t(W) # symmetrical connectivity matrix
>> rho <- 0.2 # set autocorrelation coefficient
>> M <- solve(diag(N) - rho*W)
>> X1 <- runif(N, min=-5, max=5)
>> Xbe <- X1+rnorm(N)
>> y <- M %*% Xbe # generate lagged y
>> dat <- data.frame(X1=X1, y=y)
>> 
>> prior1 = list(R=list(V=1, nu=0.002), G=list(G1=list(V=1, nu=0.002)))
>> MC1 <- MCMCglmm(y ~ X1, data=dat, prior=prior1, verbose=F)
>> # works OK, compare with summary(lm(dat$y~dat$X1))
>> 
>> identical(sir(W), W) # TRUE
>> MC2 <- MCMCglmm(y ~ X1 + sir(W), data=dat, prior=prior1, verbose=F)
>> # doesn't work
>> 
>> fac2 <- fac1 < -factor(sample(letters, N, TRUE), levels=letters)
>> MC3 <- MCMCglmm(y ~ X1 + sir(~fac1, ~fac2), data=dat, prior=prior1, verbose=F)
>> # works--results are meaningless, but doesn't return any error
>> 
>> 
>> 
>> 
>> 
>> On 2 Dec 2010, at 11:20, Jarrod Hadfield wrote:
>> 
>>> Hi Malcolm,
>>> 
>>> The suggestion of using SIR models for time series was a throw away remark, but I can't see anything technically incorrect with it. For example the model y[t] = \lambda*y[t-1]+..... can be treated as a SIR model, although there are certainly better ways of fitting it. I'm not familiar with spatial models and connectivity matrices but if W[i,j] is a way of specifying y[i] = \lambda*y[j] + ... then it is possible to fit it as a SIR model. You could modify the sir code to do what you would like (and then reinstall MCMCglmm) , for example:
>>> 
>>> sir<-function(W){W}
>>> 
>>> and then place W in the data.frame.
>>> 
>>> MCMCglmm will associate design matrices with recursive/simultaneous structures if the design matrix is returned from a function called "sir".
>>> 
>>> Cheers,
>>> 
>>> Jarrod
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> On 1 Dec 2010, at 20:10, Malcolm Fairbrother wrote:
>>> 
>>>> Dear Jarrod,
>>>> 
>>>> I'm very interested in this SIR feature of MCMCglmm, which I hadn't been aware of until your e-mail earlier today. Do I understand correctly that this should allow for feedback effects between units, reflecting the fact that y(i) and y(not-i) affect each other? If so, this could be a useful way of fitting, for example, spatial autoregressive models, where some units may affect each other by virtue of being neighbours, and we would like to know the magnitude of these effects. (You mentioned time series, but some web searches haven't turned up much on MCMCglmm and time series. And time only flows in one direction, whereas units in space can have two-way effects.)
>>>> 
>>>> However, in looking at the documentation and code, I've been struggling a bit with the "sir(~XX, ~XX)" part. Is there a way to specify a "connectivity" matrix directly, rather than using the "sir" function? Looking at the MCMCglmm code, as I understand it, "sir" is both a way of generating a connectivity matrix AND a way of telling MCMCglmm to treat the sir(~XX, ~XX) differently than other covariates.
>>>> 
>>>> In the case of spatial autoregressive models, each element on the main diagonal of the connectivity matrix is 0, and rows are often standardised to sum to 1. Such a connectivity matrix might, for example, look like:
>>>> 
>>>> N <- 100
>>>> W <- matrix(rbinom(N^2, 1, 0.1), N, N)*upper.tri(matrix(1, N, N)) # chance of being neighbours is 0.1
>>>> W <- W + t(W) # matrix is symmetrical, with zeros on the main diagonal
>>>> 
>>>> But I'm having a hard time figuring out how to use "sir" to specify such a matrix in the middle of a call to MCMCglmm.
>>>> 
>>>> If you see what I mean, can you offer any suggestions? I might take a stab at modifying MCMCglmm to make this possible, but before I do that (and I'm not certain I'll have the know-how) I wanted to check whether you had any ideas.
>>>> 
>>>> Many thanks for any assistance or clarification you can provide.
>>>> - Malcolm
>>>> 
>>>> 
>>>> 
>>>>> Message: 5
>>>>> Date: Wed, 1 Dec 2010 10:28:43 +0000
>>>>> From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>>>> To: Szymek Drobniak <geralttee at gmail.com>
>>>>> Cc: r-sig-mixed-models at r-project.org
>>>>> Subject: Re: [R-sig-ME] Another MCMCglmm question - fixing
>>>>> 	correlations
>>>>> Message-ID: <0AF131D6-557C-4324-A65A-A175E41DBA8F at ed.ac.uk>
>>>>> Content-Type: text/plain; charset=US-ASCII; format=flowed; delsp=yes
>>>>> 
>>>>> Hi,
>>>>> 
>>>>> There is a way, but its quite involved and you may find it easier to
>>>>> fit this type of model in something like ASReml if you can get a
>>>>> license. If not ......
>>>>> 
>>>>> I have implemented simultaneous-recursive (SIR) mixed models  in
>>>>> MCMCglmm, although currently they are not well tested or documented
>>>>> (See Chapter 9 of the CourseNotes) and cannot be used with non-
>>>>> Gaussian data or certain patterns of missing data. Nevertheless, in
>>>>> this example the existing code should work fine.  A simple SIR model
>>>>> has the form:
>>>>> 
>>>>> y_{i} = mu + \lambda*y_{j} + u_{i} + e_{i}
>>>>> 
>>>>> where mu is the intercept, u is a random effect (e.g. breeding value
>>>>> in your case) and e is a residual. The new part of the model is the
>>>>> structural parameter \lambda multiplied by y_{j}, the jth element of
>>>>> the response vector, which can be useful for modelling the effects of
>>>>> behavioural interactions or time series etc.  However, placing y's on
>>>>> the LHS and RHS complicates the likelihood, but MCMCglmm deals with
>>>>> this.
>>>>> 
>>>>> If we set i=j then the above equation can be rearranged:
>>>>> 
>>>>> y_{i}  - \lambda*y_{i} = mu + u_{i} + e_{i}
>>>>> y_{i}(1  - \lambda) = mu + u_{i} + e_{i}
>>>>> y_{i} = (mu + u_{i} + e_{i})/(1  - \lambda)
>>>>> 
>>>>> from this it can be seen that mu, u, e, and \lambda cannot be uniquely
>>>>> estimated without restrictions.  To illustrate we'll simulate some data:
>>>>> 
>>>>> fac<-gl(25,4)
>>>>> y<-rnorm(25)[fac]+rnorm(100, -1, sqrt(2))
>>>>> 
>>>>> # mu = -1, VAR(u)=1, VAR(e) = 2, \lambda = 0
>>>>> 
>>>>> dat<-data.frame(y=y, fac=fac)
>>>>> 
>>>>> prior1 = list(R=list(V=1, nu=0.002), G=list(G1=list(V=1, nu=0.002)))
>>>>> 
>>>>> m1<-MCMCglmm(y~1, random=~fac,  data=dat, prior=prior1)
>>>>> 
>>>>> # fitting a non-SIR model gives estimates consistent with the true
>>>>> values, which you can verify through summary(m1). Now for the SIR
>>>>> model. Because we know all parameters cannot be uniquely estimated
>>>>> I've set the residual variance to one arbitrarily.
>>>>> 
>>>>> prior2 = list(R=list(V=1, fix=1), G=list(G1=list(V=1, nu=0.002)))
>>>>> 
>>>>> m2<-MCMCglmm(y~1+sir(~units, ~units), random=~fac,  data=dat,
>>>>> prior=prior2)   # sir(~units, ~units) sets i=j.
>>>>> 
>>>>> # The estimates do not look consistent with the real values.  However,
>>>>> we can rescale them by 1-\lambda and the estimates  are close to being
>>>>> identical up to Monte Carlo error (the prior will have slightly
>>>>> different effects)
>>>>> 
>>>>> HPDinterval(m1$VCV[,1])
>>>>> HPDinterval(m2$VCV[,1]/(1-m2$Lambda)^2)
>>>>> 
>>>>> HPDinterval(m1$VCV[,2])
>>>>> HPDinterval(m2$VCV[,2]/(1-m2$Lambda)^2)
>>>>> 
>>>>> HPDinterval(m1$Sol)
>>>>> HPDinterval(m2$Sol/(1-m2$Lambda))
>>>> 
>>>> 
>>>> 	[[alternative HTML version deleted]]
>>>> 
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> 
>>> 
>>> 
>>> --
>>> The University of Edinburgh is a charitable body, registered in
>>> Scotland, with registration number SC005336.
>>> 
>> 
>> 
>> 
> 
> 
> 
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
> 
> 



From chris at trickysolutions.com.au  Mon Dec  6 00:09:12 2010
From: chris at trickysolutions.com.au (Chris Howden)
Date: Mon, 6 Dec 2010 08:39:12 +0930
Subject: [R-sig-ME] Evaluating mixed logistic model efficiency
In-Reply-To: <AANLkTi=i-wOADyJME8XWV6a=aZzAMgT=1PYfV_hXOkAX@mail.gmail.com>
References: <AANLkTi=i-wOADyJME8XWV6a=aZzAMgT=1PYfV_hXOkAX@mail.gmail.com>
Message-ID: <beae03153a91f2d724efa79b49281410@mail.gmail.com>

I 'quick and dirty' method I like to us is to calculate the mean predicted
value by actual value. If your model is working well the predicted score
for actual 0's should be quite low and the predicted score for actual 1's
quite high.



Chris Howden
Founding Partner
Tricky Solutions
Tricky Solutions 4 Tricky Problems
Evidence Based Strategic Development, IP Commercialisation and Innovation,
Data Analysis, Modelling, and Training
(mobile) 0410 689 945
(fax / office) (+618) 8952 7878
chris at trickysolutions.com.au

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Arnaud
Mosnier
Sent: Saturday, 4 December 2010 12:51 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Evaluating mixed logistic model efficiency

Dear mixed modelers,

In my actual knowledge status, the best available measures to evaluate
goodness-of-fit of a mixed logistic model are Deviance, LogLikelihood,
AIC,
AICc if necessary, BIC (I may forgot some of them but they are all
linked).
However, these measures only permit to classify models from the best to
the
worse without knowing if the best model is really efficient in explaining
the data.

It exists pseudo-R2 calculation based on differences between the
likelihood
of  the intersect only model and the likelihood of the model that you
wanted
to evaluate. But use of those methods are generally discouraged.

I would like your opinion about that !
If you have any suggestion I will be happy to learn from you !

Thanks for your help.

Arnaud

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From davidD at qimr.edu.au  Mon Dec  6 02:47:23 2010
From: davidD at qimr.edu.au (David Duffy)
Date: Mon, 6 Dec 2010 11:47:23 +1000 (EST)
Subject: [R-sig-ME] Random effects variance estimates lme vs lmer
In-Reply-To: <874553.26070.qm@web35305.mail.mud.yahoo.com>
References: <874553.26070.qm@web35305.mail.mud.yahoo.com>
Message-ID: <Pine.LNX.4.64.1012061111040.15863@orpheus.qimr.edu.au>

On Tue, 30 Nov 2010, Beth Holbrook wrote:

> I've been running some mixed models in lmer and lme and I've found that in some
> models lmer estimates essentially a zero variance for a random effect while lme
> estimates a variance greater than zero.  Everything else (parameter estimates,
> etc.) looks essentially the same.  Can someone help explain this? Is there
> something differently I should be doing in lmer?
>> mode1 <- lme(rxndist ~ lightclass, random=~1|trial, daphnia, method='ML')
>> mode2 <- lmer(rxndist ~ lightclass + (1|trial), daphnia, REML=FALSE)
>        (Intercept) Residual
> StdDev:   0.3537305 1.798685
>
> Groups   Name        Variance   Std.Dev.
> trial    (Intercept) 9.2927e-10 3.0484e-05
> Residual             3.3602e+00 1.8331e+00

You have specified the models correctly.  The lmer random effect 
estimate should be non-zero, so it has got stuck.  However, the MLE is
not greatly different from zero, so it is not practically important (the 
difference in likelihoods between the model with s2=0 and s2=0.125 is
only 0.38).  As with your earlier queries, the development version of
lme4 might have converged more closely.


-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From j.hadfield at ed.ac.uk  Mon Dec  6 12:40:17 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 6 Dec 2010 11:40:17 +0000
Subject: [R-sig-ME] Another MCMCglmm question - fixing 	correlations
In-Reply-To: <3259EF79-BB81-4C7B-90D7-F51948B88022@bristol.ac.uk>
References: <mailman.7.1291201202.14469.r-sig-mixed-models@r-project.org>
	<65C3FF86-9E7A-449A-86E7-1096E3F480CD@bristol.ac.uk>
	<EEED6CE6-2D3D-480B-88E3-52A4C25797FA@ed.ac.uk>
	<7FC5B5A7-3E8D-43ED-B54F-7785257F3841@bristol.ac.uk>
	<20101204211150.50434f1dwuwqf7ok@www.staffmail.ed.ac.uk>
	<3259EF79-BB81-4C7B-90D7-F51948B88022@bristol.ac.uk>
Message-ID: <124EBC75-CA3D-492D-B54D-E0F9E1236667@ed.ac.uk>

Hi Malcolm,

I'm glad MCMCglmm seems to fit spatial simultaneous autoregressive lag  
models . I had never heard of them before, but looking at some of the  
literature I agree they can be modeled using the sir function.  The  
code is not thoroughly tested (I have only used it on one real data  
set, for which it was intended) and is not efficient yet for large  
models, so I would treat with caution. In particular MCMCglmm is  
constraining rho such that L (I-rho*W) is positive definite and I am  
not sure this is a valid strategy for all SIR models.  Any pointers,  
particularly to the relevant literature would be welcome.

Cheers,

Jarrod




On 5 Dec 2010, at 16:16, Malcolm Fairbrother wrote:

> spatial simultaneous autoregressive lag models


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From KINLEY_ROBERT at lilly.com  Fri Dec  3 18:52:35 2010
From: KINLEY_ROBERT at lilly.com (Robert Kinley)
Date: Fri, 3 Dec 2010 17:52:35 +0000
Subject: [R-sig-ME] lmer() - no applicable method for 'profile'
Message-ID: <OFCD5E23BB.46ED04AF-ON802577EE.00612C79-802577EE.00620C8E@EliLilly.lilly.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101203/ad718fa2/attachment.pl>

From bbolker at gmail.com  Mon Dec  6 14:19:37 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 06 Dec 2010 08:19:37 -0500
Subject: [R-sig-ME] lmer() - no applicable method for 'profile'
In-Reply-To: <OFCD5E23BB.46ED04AF-ON802577EE.00612C79-802577EE.00620C8E@EliLilly.lilly.com>
References: <OFCD5E23BB.46ED04AF-ON802577EE.00612C79-802577EE.00620C8E@EliLilly.lilly.com>
Message-ID: <4CFCE2E9.9090709@gmail.com>

  You need to be using the development version (lme4a).

  install.packages("lme4a",repos="http://r-forge.r-project.org")

  if that fails, try posting sessionInfo()


On 10-12-03 12:52 PM, Robert Kinley wrote:
> R 2.12.0 , windows XP 
> 
> hi
> 
> I've been trying an example from Douglas Bates's draft 
> "lme4 : Mixed effects modelling with R" (page 14) , 
> but I get an error message :-
> 
> #
>> fm1ML<-lmer(Yield ~ 1|Batch,Dyestuff,REML=F)
>> pr1<-profile(fm1ML)
> Error in UseMethod("profile") : 
>   no applicable method for 'profile' applied to an object of class "mer"
>  
>  
> I daresay I've done something daft (or failed to do something sensible) - 
> but I don't know what.
> 
> Can someone help ... ?
> 
>         cheers
> 
> 
>   Robert Kinley 
>  
> 
>  
>  
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From KINLEY_ROBERT at lilly.com  Mon Dec  6 17:06:58 2010
From: KINLEY_ROBERT at lilly.com (Robert Kinley)
Date: Mon, 6 Dec 2010 16:06:58 +0000
Subject: [R-sig-ME] problems installing lme4a()
In-Reply-To: <4CFCE2E9.9090709@gmail.com>
Message-ID: <OF41FD001A.95BEBD58-ON802577F1.00586621-802577F1.00588794@EliLilly.lilly.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101206/b90ccdb9/attachment.pl>

From bates at stat.wisc.edu  Wed Dec  8 17:53:49 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 8 Dec 2010 10:53:49 -0600
Subject: [R-sig-ME] Expected correlation in a mixed model
In-Reply-To: <4CEA8738.5040804@gmail.com>
References: <scea5914.023@tedmail.lgc.co.uk>
	<AANLkTiku1J+ohgO6Y52pu8p9vR+Ns0K-YWGsOo6xFbnv@mail.gmail.com>
	<4CEA8738.5040804@gmail.com>
Message-ID: <AANLkTik7u_-qKO173On1d3Yea9Eai0zNzSTRA0Ee7WAq@mail.gmail.com>

On Mon, Nov 22, 2010 at 9:07 AM, Ben Bolker <bbolker at gmail.com> wrote:
> ?However: centering the concentration doesn't actually have much effect
> in this example (which it would if the remoteness from the origin were
> the problem), i.e.
>
> concsc <- scale(conc)
> (lmer1<-lmer(od~concsc+(concsc|run)))
>
> ?This setup seems a little bit odd to me:
> ?* the data set size is fairly small -- only 4 levels of the random
> effect ('run'), which often leads to this sort of collapse (zero
> variances and/or perfect correlations)

Exactly.  You are trying to estimate three variance components (two
variances and a covariance) from four groups.  That is not very much
information for what you are trying to estimate.

Bear in mind that it is generally more difficult to estimate a
variance or a covariance than it is to estimate a coefficient in a
linear predictor.  If you use the verbose=TRUE option you can see the
path of the iterations with respect to the three relative variance
component parameters. In lme4a the verbose output shows

> (lmer1<-lmer(od~conc+(conc|run), verbose=TRUE))
npt = 7 , n =  3
rhobeg =  0.2 , rhoend =  2e-07
   0.020:  12:     -2.66406; 1.07341 0.0671561  0.00000
  0.0020:  19:     -2.73319; 1.12766 0.161299  0.00000
 0.00020:  27:     -2.73356; 1.11840 0.161578  0.00000
 2.0e-05:  34:     -2.73357; 1.11786 0.161331 2.74933e-05
 2.0e-06:  40:     -2.73357; 1.11777 0.161302  0.00000
 2.0e-07:  44:     -2.73357; 1.11777 0.161301  0.00000
At return
 48:    -2.7335660:  1.11777 0.161300 1.10253e-08
Linear mixed model fit by REML ['merMod']
Formula: od ~ conc + (conc | run)
REML criterion at convergence: -2.7336

Random effects:
 Groups   Name        Variance Std.Dev. Corr
 run      (Intercept) 0.053559 0.23143
          conc        0.001115 0.03340  1.000
 Residual             0.042867 0.20704
Number of obs: 60, groups: run, 4

Fixed effects:
            Estimate Std. Error t value
(Intercept)  0.52654    0.12148   4.334
conc         0.92236    0.07701  11.977

Correlation of Fixed Effects:
     (Intr)
conc 0.001

The important thing about the iterations is that the first and third
parameters are constrained to be non-negative and the third parameter
immediately is driven to zero.

Both the REML and the ML criteria try to balance complexity of the
model versus the fidelity to the data.  It happens that the way that
the complexity is defined, the least complex models have a singular
variance-covariance matrix for the random effects.  Unless there is
sufficient information in the data to make a non-singular
variance-covariance matrix then the criterion will drive it to
singularity.

Also, as Ben notes you are not simulating from the model that you are
fitting.  You are simulating from a simpler model and that's what the
fit tends towards.

> ?* there is no variation in slopes across runs (the only randomness
> here is the error term). ?Perhaps what you're looking for is
>
> (lmer2<-lmer(od~concsc+(1|run) + (0+concsc|run)))
>
> ?which fixes the correlation at zero.
>
> ?* it's also the case here that the random effect on the intercept of
> 'run' is uniformly distributed, rather than normal -- I don't know if
> that would have an effect.
>
> ?Ben Bolker
>
>
>
> On 11/22/2010 09:44 AM, Andrew Robinson wrote:
>> Yes indeed --- remoteness of the data from the origin is a plausible
>> explanation.
>>
>> Cheers
>>
>> Andrew
>>
>> On Mon, Nov 22, 2010 at 8:50 PM, S Ellison <S.Ellison at lgc.co.uk> wrote:
>>
>>> Forgive the possibly numb-brained question, but is there a reason why
>>> the correlation between random effects coefficients in lmer should come
>>> out as identically 1.0 in a model of the form
>>>
>>> lmer(x ~ a + (a|b) )
>>>
>>> ?
>>>
>>> An example:
>>> set.seed(403)
>>> require(lme4)
>>> run <- gl(4, 15)
>>> conc <- rep(rep(c(0,0.1, 0.2, 0.4, 1.0), 3), 4)
>>> boxplot(conc~run)
>>> offset=0.2*as.numeric(run)
>>> od <- offset+conc+rnorm(60, 0, 0.2)
>>> plot(conc, od)
>>>
>>> (lmer1<-lmer(od~conc+(conc|run)))
>>> VarCorr(lmer1)
>>>
>>>
>>> S Ellison
>>> LGC
>>>
>>> *******************************************************************
>>> This email and any attachments are confidential. Any u...{{dropped:21}}
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From betinig at uoguelph.ca  Thu Dec  9 17:22:41 2010
From: betinig at uoguelph.ca (Gustavo Betini)
Date: Thu, 09 Dec 2010 11:22:41 -0500
Subject: [R-sig-ME] lmer model specification for nested random effects
Message-ID: <4D010251.7000402@uoguelph.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101209/27d7b03a/attachment.pl>

From f.calboli at imperial.ac.uk  Thu Dec  9 17:37:58 2010
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Thu, 9 Dec 2010 16:37:58 +0000
Subject: [R-sig-ME] lmer model specification for nested random effects
In-Reply-To: <4D010251.7000402@uoguelph.ca>
References: <4D010251.7000402@uoguelph.ca>
Message-ID: <B733AA26-904D-428E-8BBA-8EBB1A9E798F@imperial.ac.uk>

Hi,

> Is this what Douglas Bates call "implicit nesting"? If so, the recommendation is to create a new variable

I am not sure about implicit, but I'd argue that Id is nested within site. Whether you need a new variable is difficult to say without seeing the data: in my experience, if for instance you have 30 individuals and 3 sites, coding the individuals as 1 to 30 (and changing that to factor btw) is "absolutely" unique and should be enough, while if your id are coded 1:10 for each site, your coding is "locally" unique only and a new variable is required.
> 
> data<- within(data, {siteid<- factor(site:id)}
> 
> And the model specification...
> 
> fm1<- lmer(y ~ x1 + x2 + (1|siteid), data)
> 
> which seems to be identical to
> 
> fm2<- lmer(y ~ x1 + x2 + (1|site:id)), data)
> 
> What is the difference between the specifications above and
> 
> fm3<- lmer(y ~ x1 + x2 + (1|id) + (1|site), data)
> 
> I get identical results from models fm1 and fm2, but slightly different 
> results from fm3.

I am not 100% sure, but my guess is that in fm1 you only have the (newly coded) ids as random variable, while in fm2/fm3 you have both site and id as random. The differences between fm2/fm3 are most likely to the fact you coded your individuals in a "locally" unique way, rather than in a "absolutely" unique way. Having said that, I am perplexed why fm1 and fm2 should give the same results. 

HTH,

F


--
Federico C. F. Calboli
Department of Epidemiology and Biostatistics
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From bates at stat.wisc.edu  Thu Dec  9 17:40:13 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 9 Dec 2010 10:40:13 -0600
Subject: [R-sig-ME] lmer model specification for nested random effects
In-Reply-To: <4D010251.7000402@uoguelph.ca>
References: <4D010251.7000402@uoguelph.ca>
Message-ID: <AANLkTikhfVP9YaGycVbc7_NY_mPn8SOcDouS-pn8a4vf@mail.gmail.com>

On Thu, Dec 9, 2010 at 10:22 AM, Gustavo Betini <betinig at uoguelph.ca> wrote:
> Hi, all,

> I have a dataset with several individuals from different sites measured
> several times. There are 7 different sites and around 10 individuals
> from each site. My question is:

> Is this what Douglas Bates call "implicit nesting"? If so, the recommendation is to create a new variable

We would need to see the output of

str(data)

to decide.  Assuming that there are around 70 individuals in total,
the question is whether the id factor has about 70 levels or about 10
levels.  In the second case id is only meaningful within a site and to
produce unique levels for each individual it is necessary to consider
the site:id interaction.

But that is not the way that most researchers would organize the data.
 The sensible thing to do is to assign a unique level to each
individual in which case (1|id) is a suitable specification.

> data<- within(data, {siteid<- factor(site:id)}
>
> And the model specification...
>
> fm1<- lmer(y ~ x1 + x2 + (1|siteid), data)
>
> which seems to be identical to
>
> fm2<- lmer(y ~ x1 + x2 + (1|site:id)), data)
>
> What is the difference between the specifications above and
>
> fm3<- lmer(y ~ x1 + x2 + (1|id) + (1|site), data)
>
> I get identical results from models fm1 and fm2, but slightly different
> results from fm3.

Because fm3 is a different model.



From gangchen6 at gmail.com  Thu Dec  9 21:23:20 2010
From: gangchen6 at gmail.com (Gang Chen)
Date: Thu, 9 Dec 2010 15:23:20 -0500
Subject: [R-sig-ME] Comparing models with different random effects
Message-ID: <AANLkTimKdT9yYnktcHNf3rweVWTdZK=s8HnGDdwr=jHA@mail.gmail.com>

Suppose that there are multiple task types (Task) and each task type
is represented with a few questions (Item). And all subjects (Subj)
answer the same questions (Item).

How do I compare a model with (1 | Subj) + (1 | Item) versus one with
(1 | Subj) + (1 | Subj:Item) in lmer()? Through AIC/BIC (assuming the
fixed effect remain the same)? Would it make more sense to consider (1
| Subj) + (1 | Subj:Item) + (1 | Item)?

Is (1 | Subj) considered as nested within (Task | Subj)?

Thanks,
Gang



From zhangyuanye0706 at gmail.com  Fri Dec 10 11:19:40 2010
From: zhangyuanye0706 at gmail.com (Yuan-Ye Zhang)
Date: Fri, 10 Dec 2010 11:19:40 +0100
Subject: [R-sig-ME] Comparing models with different random effects
In-Reply-To: <AANLkTimKdT9yYnktcHNf3rweVWTdZK=s8HnGDdwr=jHA@mail.gmail.com>
References: <AANLkTimKdT9yYnktcHNf3rweVWTdZK=s8HnGDdwr=jHA@mail.gmail.com>
Message-ID: <AANLkTin3oOVBzz_uZx8wN-GuQBzrNPObYjwxWoD=GYNz@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101210/c0184b33/attachment.pl>

From calesso at fca.unl.edu.ar  Fri Dec 10 12:37:48 2010
From: calesso at fca.unl.edu.ar (Ing. Agr. =?ISO-8859-1?Q?Agust=EDn?= Alesso)
Date: Fri, 10 Dec 2010 08:37:48 -0300
Subject: [R-sig-ME] spatial correlation structure for GLS (nlme)
Message-ID: <1291981068.6676.38.camel@agustin-Studio14>

Hello,

I need some advice to include a spatial correlation structure to an
ANOVA one-way GLS model. 

First, I fit a simple model asuming uncorrelated errors and plotted the
residuals variogram which showed the spatial autocorrelation. Then, with
gstat package, I fit some models to guess initial values for corSpatial.
The best model fitted has a nugget efect with to spherical structures (2
ranges).
Before adding more complexity to the model, I tried to fit few models
with basic predefined corStructures and then looking at their
residuals variograms. Although including correlation results in smaller
AICs, the variograms still showing strong spatial correlation of
residuals.  

Is there a way to bluid a spatial correlation structure including two
ranges?

Thanks in advance,



-- 
Ing. Agr. Agust?n Alesso
Dpto. Ciencias del Ambiente
Fac. Cs. Agrarias - UNL
Kreder 2805 - S3080HOF - Esperanza
Tel: 03496-428575 int 337/256



From Thierry.ONKELINX at inbo.be  Fri Dec 10 13:18:45 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Fri, 10 Dec 2010 13:18:45 +0100
Subject: [R-sig-ME] spatial correlation structure for GLS (nlme)
In-Reply-To: <1291981068.6676.38.camel@agustin-Studio14>
References: <1291981068.6676.38.camel@agustin-Studio14>
Message-ID: <3DB16098F738284D8DBEB2FC3699163854E097@inboexch.inbo.be>

Dear Augustin,

Which residuals did you use? You need to normalised residuals because they take the effect of the correlation function into account.

Best regards,

Thierry

----------------------------------------------------------------------------
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Ing. 
> Agr." Agust?n Alesso
> Verzonden: vrijdag 10 december 2010 12:38
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] spatial correlation structure for GLS (nlme)
> 
> Hello,
> 
> I need some advice to include a spatial correlation structure 
> to an ANOVA one-way GLS model. 
> 
> First, I fit a simple model asuming uncorrelated errors and 
> plotted the residuals variogram which showed the spatial 
> autocorrelation. Then, with gstat package, I fit some models 
> to guess initial values for corSpatial.
> The best model fitted has a nugget efect with to spherical 
> structures (2 ranges).
> Before adding more complexity to the model, I tried to fit 
> few models with basic predefined corStructures and then 
> looking at their residuals variograms. Although including 
> correlation results in smaller AICs, the variograms still 
> showing strong spatial correlation of residuals.  
> 
> Is there a way to bluid a spatial correlation structure 
> including two ranges?
> 
> Thanks in advance,
> 
> 
> 
> --
> Ing. Agr. Agust?n Alesso
> Dpto. Ciencias del Ambiente
> Fac. Cs. Agrarias - UNL
> Kreder 2805 - S3080HOF - Esperanza
> Tel: 03496-428575 int 337/256
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 



From bates at stat.wisc.edu  Fri Dec 10 14:01:50 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 10 Dec 2010 07:01:50 -0600
Subject: [R-sig-ME] Fitted values for binomial family in lme4a{glmer}
In-Reply-To: <201011231305.44141.kevin.thorpe@utoronto.ca>
References: <201011231305.44141.kevin.thorpe@utoronto.ca>
Message-ID: <AANLkTi=QQR22XWS24nDLVkA4-hr2hcfZ2-waaL8fk==p@mail.gmail.com>

On Tue, Nov 23, 2010 at 12:05 PM, Kevin E. Thorpe
<kevin.thorpe at utoronto.ca> wrote:
> I searched the archives and found questions like this with no definitive
> answers. ?I also did not find an answer in the lme4a help files.

> I'm using lme4a_0.999375-57 in R version 2.12.0 Patched (2010-11-07 r53537) on
> Platform: i686-pc-linux-gnu (32-bit).
>
> I've fit a model with glmer() using the binomial family. ?I'm wondering what
> fitted() gives on the result. ?It appears that fitted() on a regular logistic
> model fit with glm() returns fitted probabilities. ?It looks like the same
> behaviour occurs with a glmer() object, but some confirmation would be nice.

Yes, the value of the fitted method is on the scale of the mean
response, which is the probability scale when using a binomial family.



From cecile.sauder at gmail.com  Fri Dec 10 15:10:38 2010
From: cecile.sauder at gmail.com (=?ISO-8859-1?Q?C=E9cile_SAUDER?=)
Date: Fri, 10 Dec 2010 15:10:38 +0100
Subject: [R-sig-ME] Help to convert a SAS code for lmer() use
Message-ID: <AANLkTin_3KKRcUx9wDFR18LLOBZ_5nKkqq4BS9O4-Xsd@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101210/76e0ceea/attachment.pl>

From gangchen6 at gmail.com  Fri Dec 10 15:38:21 2010
From: gangchen6 at gmail.com (Gang Chen)
Date: Fri, 10 Dec 2010 09:38:21 -0500
Subject: [R-sig-ME] Comparing models with different random effects
In-Reply-To: <AANLkTin3oOVBzz_uZx8wN-GuQBzrNPObYjwxWoD=GYNz@mail.gmail.com>
References: <AANLkTimKdT9yYnktcHNf3rweVWTdZK=s8HnGDdwr=jHA@mail.gmail.com>
	<AANLkTin3oOVBzz_uZx8wN-GuQBzrNPObYjwxWoD=GYNz@mail.gmail.com>
Message-ID: <AANLkTimZK0fagkKgOTKXy=O9uxeFEdM7pkk0zN47YTwY@mail.gmail.com>

Thanks for the help!

> It could make sense if you anova these two models, to find a better one.
> (1 | Subj) + (1 | Item)
> (1 | Subj) + (1 | Subj:Item)

These two models have the same number of parameters (and degrees of
freedom), thus likelihood ration test in anova() would not be
available. And that is why I was asking whether AIC/BIC is the only
way to compare the two model.

My second question is still open: I tend to believe that (1 | Subj) is
nested within (Task | Subj) since the first model has one parameter
(variance) which can be viewed as multiple variances in the second
model being constrained as equal, but I would still appreciate it if
somebody could confirm this.

Gang

> 2010/12/9 Gang Chen <gangchen6 at gmail.com>
>>
>> Suppose that there are multiple task types (Task) and each task type
>> is represented with a few questions (Item). And all subjects (Subj)
>> answer the same questions (Item).
>>
>> How do I compare a model with (1 | Subj) + (1 | Item) versus one with
>> (1 | Subj) + (1 | Subj:Item) in lmer()? Through AIC/BIC (assuming the
>> fixed effect remain the same)? Would it make more sense to consider (1
>> | Subj) + (1 | Subj:Item) + (1 | Item)?
>>
>> Is (1 | Subj) considered as nested within (Task | Subj)?
>>
>> Thanks,
>> Gang
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



From bates at stat.wisc.edu  Fri Dec 10 16:20:34 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 10 Dec 2010 09:20:34 -0600
Subject: [R-sig-ME] Comparing models with different random effects
In-Reply-To: <AANLkTimZK0fagkKgOTKXy=O9uxeFEdM7pkk0zN47YTwY@mail.gmail.com>
References: <AANLkTimKdT9yYnktcHNf3rweVWTdZK=s8HnGDdwr=jHA@mail.gmail.com>
	<AANLkTin3oOVBzz_uZx8wN-GuQBzrNPObYjwxWoD=GYNz@mail.gmail.com>
	<AANLkTimZK0fagkKgOTKXy=O9uxeFEdM7pkk0zN47YTwY@mail.gmail.com>
Message-ID: <AANLkTi=4UQXaDXcsVbzwm1ZR4tENFuLtZZv6HLbB_tFX@mail.gmail.com>

On Fri, Dec 10, 2010 at 8:38 AM, Gang Chen <gangchen6 at gmail.com> wrote:
> Thanks for the help!
>
>> It could make sense if you anova these two models, to find a better one.
>> (1 | Subj) + (1 | Item)
>> (1 | Subj) + (1 | Subj:Item)
>
> These two models have the same number of parameters (and degrees of
> freedom), thus likelihood ration test in anova() would not be
> available. And that is why I was asking whether AIC/BIC is the only
> way to compare the two model.
>
> My second question is still open: I tend to believe that (1 | Subj) is
> nested within (Task | Subj) since the first model has one parameter
> (variance) which can be viewed as multiple variances in the second
> model being constrained as equal, but I would still appreciate it if
> somebody could confirm this.

If you are using "is nested within" to mean "is a submodel of" then
the answer is yes.

>> 2010/12/9 Gang Chen <gangchen6 at gmail.com>
>>>
>>> Suppose that there are multiple task types (Task) and each task type
>>> is represented with a few questions (Item). And all subjects (Subj)
>>> answer the same questions (Item).
>>>
>>> How do I compare a model with (1 | Subj) + (1 | Item) versus one with
>>> (1 | Subj) + (1 | Subj:Item) in lmer()? Through AIC/BIC (assuming the
>>> fixed effect remain the same)? Would it make more sense to consider (1
>>> | Subj) + (1 | Subj:Item) + (1 | Item)?
>>>
>>> Is (1 | Subj) considered as nested within (Task | Subj)?
>>>
>>> Thanks,
>>> Gang
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From gangchen6 at gmail.com  Fri Dec 10 16:27:32 2010
From: gangchen6 at gmail.com (Gang Chen)
Date: Fri, 10 Dec 2010 10:27:32 -0500
Subject: [R-sig-ME] Comparing models with different random effects
In-Reply-To: <AANLkTi=4UQXaDXcsVbzwm1ZR4tENFuLtZZv6HLbB_tFX@mail.gmail.com>
References: <AANLkTimKdT9yYnktcHNf3rweVWTdZK=s8HnGDdwr=jHA@mail.gmail.com>
	<AANLkTin3oOVBzz_uZx8wN-GuQBzrNPObYjwxWoD=GYNz@mail.gmail.com>
	<AANLkTimZK0fagkKgOTKXy=O9uxeFEdM7pkk0zN47YTwY@mail.gmail.com>
	<AANLkTi=4UQXaDXcsVbzwm1ZR4tENFuLtZZv6HLbB_tFX@mail.gmail.com>
Message-ID: <AANLkTimzGLSWDaMcjeezqibL2tDPuEMyqGR9jHf7CgFA@mail.gmail.com>

Thanks for the quick help, Dr. Bates!

>> My second question is still open: I tend to believe that (1 | Subj) is
>> nested within (Task | Subj) since the first model has one parameter
>> (variance) which can be viewed as multiple variances in the second
>> model being constrained as equal, but I would still appreciate it if
>> somebody could confirm this.
>
> If you are using "is nested within" to mean "is a submodel of" then
> the answer is yes.

The reason I'm asking about the relationship between the two models is
whether I could use anova() to compare the two models. So, under this
context is likelihood ratio test meaningful?

Thanks,
Gang


>>> 2010/12/9 Gang Chen <gangchen6 at gmail.com>
>>>>
>>>> Suppose that there are multiple task types (Task) and each task type
>>>> is represented with a few questions (Item). And all subjects (Subj)
>>>> answer the same questions (Item).
>>>>
>>>> How do I compare a model with (1 | Subj) + (1 | Item) versus one with
>>>> (1 | Subj) + (1 | Subj:Item) in lmer()? Through AIC/BIC (assuming the
>>>> fixed effect remain the same)? Would it make more sense to consider (1
>>>> | Subj) + (1 | Subj:Item) + (1 | Item)?
>>>>
>>>> Is (1 | Subj) considered as nested within (Task | Subj)?
>>>>
>>>> Thanks,
>>>> Gang
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>



From bates at stat.wisc.edu  Fri Dec 10 16:31:20 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 10 Dec 2010 09:31:20 -0600
Subject: [R-sig-ME] Comparing models with different random effects
In-Reply-To: <AANLkTimzGLSWDaMcjeezqibL2tDPuEMyqGR9jHf7CgFA@mail.gmail.com>
References: <AANLkTimKdT9yYnktcHNf3rweVWTdZK=s8HnGDdwr=jHA@mail.gmail.com>
	<AANLkTin3oOVBzz_uZx8wN-GuQBzrNPObYjwxWoD=GYNz@mail.gmail.com>
	<AANLkTimZK0fagkKgOTKXy=O9uxeFEdM7pkk0zN47YTwY@mail.gmail.com>
	<AANLkTi=4UQXaDXcsVbzwm1ZR4tENFuLtZZv6HLbB_tFX@mail.gmail.com>
	<AANLkTimzGLSWDaMcjeezqibL2tDPuEMyqGR9jHf7CgFA@mail.gmail.com>
Message-ID: <AANLkTikSsJ2AtULx_4_co=m=+9XQdG+3pOuERDsHKgd4@mail.gmail.com>

On Fri, Dec 10, 2010 at 9:27 AM, Gang Chen <gangchen6 at gmail.com> wrote:
> Thanks for the quick help, Dr. Bates!
>
>>> My second question is still open: I tend to believe that (1 | Subj) is
>>> nested within (Task | Subj) since the first model has one parameter
>>> (variance) which can be viewed as multiple variances in the second
>>> model being constrained as equal, but I would still appreciate it if
>>> somebody could confirm this.
>>
>> If you are using "is nested within" to mean "is a submodel of" then
>> the answer is yes.
>
> The reason I'm asking about the relationship between the two models is
> whether I could use anova() to compare the two models. So, under this
> context is likelihood ratio test meaningful?

If that is the only difference between the models, yes.

>>>> 2010/12/9 Gang Chen <gangchen6 at gmail.com>
>>>>>
>>>>> Suppose that there are multiple task types (Task) and each task type
>>>>> is represented with a few questions (Item). And all subjects (Subj)
>>>>> answer the same questions (Item).
>>>>>
>>>>> How do I compare a model with (1 | Subj) + (1 | Item) versus one with
>>>>> (1 | Subj) + (1 | Subj:Item) in lmer()? Through AIC/BIC (assuming the
>>>>> fixed effect remain the same)? Would it make more sense to consider (1
>>>>> | Subj) + (1 | Subj:Item) + (1 | Item)?
>>>>>
>>>>> Is (1 | Subj) considered as nested within (Task | Subj)?
>>>>>
>>>>> Thanks,
>>>>> Gang
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>>
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>



From zhangyuanye0706 at gmail.com  Fri Dec 10 16:35:01 2010
From: zhangyuanye0706 at gmail.com (Yuan-Ye Zhang)
Date: Fri, 10 Dec 2010 16:35:01 +0100
Subject: [R-sig-ME] Comparing models with different random effects
In-Reply-To: <AANLkTimzGLSWDaMcjeezqibL2tDPuEMyqGR9jHf7CgFA@mail.gmail.com>
References: <AANLkTimKdT9yYnktcHNf3rweVWTdZK=s8HnGDdwr=jHA@mail.gmail.com>
	<AANLkTin3oOVBzz_uZx8wN-GuQBzrNPObYjwxWoD=GYNz@mail.gmail.com>
	<AANLkTimZK0fagkKgOTKXy=O9uxeFEdM7pkk0zN47YTwY@mail.gmail.com>
	<AANLkTi=4UQXaDXcsVbzwm1ZR4tENFuLtZZv6HLbB_tFX@mail.gmail.com>
	<AANLkTimzGLSWDaMcjeezqibL2tDPuEMyqGR9jHf7CgFA@mail.gmail.com>
Message-ID: <AANLkTinbtad22cZdu6_ZU+MPSq9xbtFCWUSuo3HRiWdb@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101210/f738e184/attachment.pl>

From bbolker at gmail.com  Fri Dec 10 22:41:30 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 10 Dec 2010 16:41:30 -0500
Subject: [R-sig-ME] Comparing models with different random effects
In-Reply-To: <AANLkTinbtad22cZdu6_ZU+MPSq9xbtFCWUSuo3HRiWdb@mail.gmail.com>
References: <AANLkTimKdT9yYnktcHNf3rweVWTdZK=s8HnGDdwr=jHA@mail.gmail.com>	<AANLkTin3oOVBzz_uZx8wN-GuQBzrNPObYjwxWoD=GYNz@mail.gmail.com>	<AANLkTimZK0fagkKgOTKXy=O9uxeFEdM7pkk0zN47YTwY@mail.gmail.com>	<AANLkTi=4UQXaDXcsVbzwm1ZR4tENFuLtZZv6HLbB_tFX@mail.gmail.com>	<AANLkTimzGLSWDaMcjeezqibL2tDPuEMyqGR9jHf7CgFA@mail.gmail.com>
	<AANLkTinbtad22cZdu6_ZU+MPSq9xbtFCWUSuo3HRiWdb@mail.gmail.com>
Message-ID: <4D029E8A.502@gmail.com>

On 10-12-10 10:35 AM, Yuan-Ye Zhang wrote:
> test the sig. of random slope, if you compare these two
> (1 | Subj): random intercept
> (Task | Subj): random intercept and random slope
> 
> but can you do (Task | Subj)? I thought some levels of Subj is present in
> given levels of Task, so is nested.
> 

  (Task|Subj) means that the effect of Task varies among subjects --
perfectly sensible to try to estimate this if each subject answered
Items representing in more than one Task category.  And because
(Task|Subj) implicitly includes an intercept term [(Task|Subj) is
equivalent to (1+Task|Subj)], (1|Subj) is nested (in the sense of
models) within (Task|Subj).

  I was going to write more about how one would interpret the
relationship between Task and Subj in terms of 'effects', but I think it
really doesn't make sense when Task is a fixed effect. The model
specification about (Task|Subj) sets up *none* of the following models:

a. there is variation among Task:Subj combinations within a Subj ["Task
nested within Subj", (1|Task/Subj)], or
b. there is variation among Task:Subj combinations within a Task ["Subj
nested within Task", (1|Subj/Task)] [I may have the order of the a/b
notation backwards: I have yet to discover a good mnemonic], or
c. samples from each Task have random deviations from the overall mean
that are consistent across all Subj's, or vice versa ["crossed random
effects Subj and Task", (1|Task)+(1|Subj)]

 instead, this sets up a model where (as stated above) the *effect* of
Task varies randomly (around its overall mean) across Subj's.

  Hope that helps and that I didn't screw anything up.

  Anyone know of a really good clear primer for this stuff (printed or
on the web) that includes (1) mathematical notation and (2) graphical
representations/example data plots for the descriptions above?

> 2010/12/10 Gang Chen <gangchen6 at gmail.com>
> 
>> Thanks for the quick help, Dr. Bates!
>>
>>>> My second question is still open: I tend to believe that (1 | Subj) is
>>>> nested within (Task | Subj) since the first model has one parameter
>>>> (variance) which can be viewed as multiple variances in the second
>>>> model being constrained as equal, but I would still appreciate it if
>>>> somebody could confirm this.
>>>
>>> If you are using "is nested within" to mean "is a submodel of" then
>>> the answer is yes.
>>
>> The reason I'm asking about the relationship between the two models is
>> whether I could use anova() to compare the two models. So, under this
>> context is likelihood ratio test meaningful?
>>
>> Thanks,
>> Gang
>>
>>
>>>>> 2010/12/9 Gang Chen <gangchen6 at gmail.com>
>>>>>>
>>>>>> Suppose that there are multiple task types (Task) and each task type
>>>>>> is represented with a few questions (Item). And all subjects (Subj)
>>>>>> answer the same questions (Item).
>>>>>>
>>>>>> How do I compare a model with (1 | Subj) + (1 | Item) versus one with
>>>>>> (1 | Subj) + (1 | Subj:Item) in lmer()? Through AIC/BIC (assuming the
>>>>>> fixed effect remain the same)? Would it make more sense to consider (1
>>>>>> | Subj) + (1 | Subj:Item) + (1 | Item)?
>>>>>>
>>>>>> Is (1 | Subj) considered as nested within (Task | Subj)?
>>>>>>
>>>>>> Thanks,
>>>>>> Gang
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>>
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bbolker at gmail.com  Fri Dec 10 22:59:35 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 10 Dec 2010 16:59:35 -0500
Subject: [R-sig-ME] Fitted values for binomial family in lme4a{glmer}
In-Reply-To: <AANLkTi=QQR22XWS24nDLVkA4-hr2hcfZ2-waaL8fk==p@mail.gmail.com>
References: <201011231305.44141.kevin.thorpe@utoronto.ca>
	<AANLkTi=QQR22XWS24nDLVkA4-hr2hcfZ2-waaL8fk==p@mail.gmail.com>
Message-ID: <4D02A2C7.6020108@gmail.com>

On 10-12-10 08:01 AM, Douglas Bates wrote:
> On Tue, Nov 23, 2010 at 12:05 PM, Kevin E. Thorpe
> <kevin.thorpe at utoronto.ca> wrote:
>> I searched the archives and found questions like this with no definitive
>> answers.  I also did not find an answer in the lme4a help files.
> 
>> I'm using lme4a_0.999375-57 in R version 2.12.0 Patched (2010-11-07 r53537) on
>> Platform: i686-pc-linux-gnu (32-bit).
>>
>> I've fit a model with glmer() using the binomial family.  I'm wondering what
>> fitted() gives on the result.  It appears that fitted() on a regular logistic
>> model fit with glm() returns fitted probabilities.  It looks like the same
>> behaviour occurs with a glmer() object, but some confirmation would be nice.
> 
> Yes, the value of the fitted method is on the scale of the mean
> response, which is the probability scale when using a binomial family.

   This is not necessarily easy for everyone, but I find the "empirical
hack" approach works well for answering these questions (often easier
than reading the source, and sometimes even easier than reading the
docs): make up an example where you know the answer.

f <- factor(rep(LETTERS[1:10],each=10))
set.seed(101)
rf <- rnorm(10)
eta <- rf[f]
p <- plogis(eta)
N <- 10
y <- rbinom(length(f),size=N,prob=p)

library(lme4)
m <- glmer(y~1+(1|f))
plot(N*p,fitted(m),xlab="true",ylab="est")
abline(a=0,b=1)

  So fitted() is on the "N*p" scale ...

  (oops, I did this with lme4 not lme4a.  You could try it for lme4a, or
just take Doug's word for it :-)  )



From bbolker at gmail.com  Fri Dec 10 23:24:42 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 10 Dec 2010 17:24:42 -0500
Subject: [R-sig-ME] lmer model specification for nested random effects
In-Reply-To: <AANLkTikhfVP9YaGycVbc7_NY_mPn8SOcDouS-pn8a4vf@mail.gmail.com>
References: <4D010251.7000402@uoguelph.ca>
	<AANLkTikhfVP9YaGycVbc7_NY_mPn8SOcDouS-pn8a4vf@mail.gmail.com>
Message-ID: <4D02A8AA.9040009@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 10-12-09 11:40 AM, Douglas Bates wrote:
> On Thu, Dec 9, 2010 at 10:22 AM, Gustavo Betini <betinig at uoguelph.ca> wrote:
>> Hi, all,
> 
>> I have a dataset with several individuals from different sites measured
>> several times. There are 7 different sites and around 10 individuals
>> from each site. My question is:
> 
>> Is this what Douglas Bates call "implicit nesting"? If so, the recommendation is to create a new variable
> 
> We would need to see the output of
> 
> str(data)
> 
> to decide.  Assuming that there are around 70 individuals in total,
> the question is whether the id factor has about 70 levels or about 10
> levels.  In the second case id is only meaningful within a site and to
> produce unique levels for each individual it is necessary to consider
> the site:id interaction.
> 
> But that is not the way that most researchers would organize the data.
>  The sensible thing to do is to assign a unique level to each
> individual in which case (1|id) is a suitable specification.
> 
>> data<- within(data, {siteid<- factor(site:id)}
>>

  I agree that it's sensible and works well with lme4, but I don't know
about "how most researchers would organize the data" -- depends very
much on the researcher/field.

  Ben Bolker

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iEYEARECAAYFAk0CqKoACgkQc5UpGjwzenPaNgCfUX2uo7l+dErpnR1sx9/o1F0m
JPUAoJEs9wCJbRHn6yCMi5l8a6oRgo44
=m6NY
-----END PGP SIGNATURE-----



From billy.requena at gmail.com  Sat Dec 11 03:39:15 2010
From: billy.requena at gmail.com (Billy)
Date: Fri, 10 Dec 2010 20:39:15 -0600
Subject: [R-sig-ME] Could the random effect at the level of each observation
	be a trap?
Message-ID: <AANLkTi=155JVhNP3L7U-MBwUqKzwxwtsWL10Lgo13yo1@mail.gmail.com>

Hi all!

I'm a relatively newbie ecologist student getting adventures at the
mixed models world and facing some trouble to interpret random
effects. I hope someone could help me.
Quickly, I'm constructing different models using glmer() to discover
which factors could influence females' reproductive decisions. I have
sampled several males and classified them as successful or
unsuccessful.  Therefore, I'm modelling logistic regressions with more
than one fixed variable and random variables.
I have sampled individuals monthly and, sometimes, the same individual
(MaleID) was sampled more than once, in different status. Then, I used
"MaleID" as a random variable.
Well, I built a bunch of models considering only MaleID as the random
variable as:

m1 <- glmer(y ~ 1 + (1|MaleID), family=binomial)
m2 <- glmer(y ~ x + (1|MaleID), family=binomial)
m3 <- glmer(y ~ z + (1|MaleID), family=binomial)


Moreover, in several posts here I've read about count data show high
overdispersion, even using family=binomial for the error. One
recurrent solution suggested is create a vector to each observation
as:

resid <- as.factor(1:dim(data)[1])

Then, I built models considering this random variable too, trying to
understand that, as following

m4 <- glmer(y ~ 1 + (1|resid), family=binomial)
m5 <- glmer(y ~ x + (1|resid), family=binomial)
m6 <- glmer(y ~ w + (1|resid), family=binomial)

and

m7 <- glmer(y ~ 1 + (1|MaleID:resid ), family=binomial)
m8 <- glmer(y ~ x + (1|MaleID:resid ), family=binomial)
m9 <- glmer(y ~ z + (1|MaleID:resid ), family=binomial)

Using a model selection approach and looking for the deviance and the
AIC values, I observed that the correspondent models from the second
block (m4, m5 and m6 in the example above) and the third block (m7, m8
and m9) showed the same values. Is that due to the "resid" random
effect?

Besides that, those models in fact showed a lower deviance (an
improvement of more than 300) compared to the models that only
included "MaleID". When using only "MaleID" as random variable, a
model considering the interaction between x and w was the most
plausible. On the other hand, using the "resid" as random variable,
the null model (considering no effect of x or w) was selected.

Is there any possibility that, with this "resid" procedure, I am being
trapped in some statistical artifact?

Thank you all for any help
-- 
Gustavo Requena
PhD student - Laboratory of Arthropod Behavior and Evolution
Universidade de S?o Paulo
Correspondence adress:
a/c Glauco Machado
Departamento de Ecologia - IBUSP
Rua do Mat?o - Travessa 14 no 321 Cidade Universit?ria, S?o Paulo - SP, Brasil
CEP 05508-900
Phone number: 55 11 3091-7488

http://ecologia.ib.usp.br/opilio/gustavo.html



From C.vanLeeuwen at nioo.knaw.nl  Sat Dec 11 08:21:47 2010
From: C.vanLeeuwen at nioo.knaw.nl (Leeuwen, Casper van)
Date: Sat, 11 Dec 2010 08:21:47 +0100
Subject: [R-sig-ME] standardized coefficients in glmer model
Message-ID: <AD30DD503BC9E9479E223CA90866D28601DF0AB4@clmail1.nioo.int>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101211/03ee22d5/attachment.pl>

From gangchen at mail.nih.gov  Sat Dec 11 15:40:57 2010
From: gangchen at mail.nih.gov (Gang Chen)
Date: Sat, 11 Dec 2010 09:40:57 -0500
Subject: [R-sig-ME] Comparing models with different random effects
In-Reply-To: <4D029E8A.502@gmail.com>
References: <AANLkTimKdT9yYnktcHNf3rweVWTdZK=s8HnGDdwr=jHA@mail.gmail.com>
	<AANLkTin3oOVBzz_uZx8wN-GuQBzrNPObYjwxWoD=GYNz@mail.gmail.com>
	<AANLkTimZK0fagkKgOTKXy=O9uxeFEdM7pkk0zN47YTwY@mail.gmail.com>
	<AANLkTi=4UQXaDXcsVbzwm1ZR4tENFuLtZZv6HLbB_tFX@mail.gmail.com>
	<AANLkTimzGLSWDaMcjeezqibL2tDPuEMyqGR9jHf7CgFA@mail.gmail.com>
	<AANLkTinbtad22cZdu6_ZU+MPSq9xbtFCWUSuo3HRiWdb@mail.gmail.com>
	<4D029E8A.502@gmail.com>
Message-ID: <AANLkTin75QUUHDRhnN_Sfr6T-sdytbfaygQ2C8GEMKcm@mail.gmail.com>

Thanks a lot for the clarifications, Dr. Bolker!

Could you comment a little more about the following?

>?I was going to write more about how one would interpret the
> relationship between Task and Subj in terms of 'effects', but I think it
> really doesn't make sense when Task is a fixed effect.

In my case Task has only 3 levels, and that's why I didn't consider
(1|Task/Subj) or (1|Task)+(1|Subj). Do you think (1|Task) should be
included in the model?

Thanks,
Gang


On Fri, Dec 10, 2010 at 4:41 PM, Ben Bolker <bbolker at gmail.com> wrote:
> On 10-12-10 10:35 AM, Yuan-Ye Zhang wrote:
>> test the sig. of random slope, if you compare these two
>> (1 | Subj): random intercept
>> (Task | Subj): random intercept and random slope
>>
>> but can you do (Task | Subj)? I thought some levels of Subj is present in
>> given levels of Task, so is nested.
>>
>
> ?(Task|Subj) means that the effect of Task varies among subjects --
> perfectly sensible to try to estimate this if each subject answered
> Items representing in more than one Task category. ?And because
> (Task|Subj) implicitly includes an intercept term [(Task|Subj) is
> equivalent to (1+Task|Subj)], (1|Subj) is nested (in the sense of
> models) within (Task|Subj).
>
> ?I was going to write more about how one would interpret the
> relationship between Task and Subj in terms of 'effects', but I think it
> really doesn't make sense when Task is a fixed effect. The model
> specification about (Task|Subj) sets up *none* of the following models:
>
> a. there is variation among Task:Subj combinations within a Subj ["Task
> nested within Subj", (1|Task/Subj)], or
> b. there is variation among Task:Subj combinations within a Task ["Subj
> nested within Task", (1|Subj/Task)] [I may have the order of the a/b
> notation backwards: I have yet to discover a good mnemonic], or
> c. samples from each Task have random deviations from the overall mean
> that are consistent across all Subj's, or vice versa ["crossed random
> effects Subj and Task", (1|Task)+(1|Subj)]
>
> ?instead, this sets up a model where (as stated above) the *effect* of
> Task varies randomly (around its overall mean) across Subj's.
>
> ?Hope that helps and that I didn't screw anything up.
>
> ?Anyone know of a really good clear primer for this stuff (printed or
> on the web) that includes (1) mathematical notation and (2) graphical
> representations/example data plots for the descriptions above?
>
>> 2010/12/10 Gang Chen <gangchen6 at gmail.com>
>>
>>> Thanks for the quick help, Dr. Bates!
>>>
>>>>> My second question is still open: I tend to believe that (1 | Subj) is
>>>>> nested within (Task | Subj) since the first model has one parameter
>>>>> (variance) which can be viewed as multiple variances in the second
>>>>> model being constrained as equal, but I would still appreciate it if
>>>>> somebody could confirm this.
>>>>
>>>> If you are using "is nested within" to mean "is a submodel of" then
>>>> the answer is yes.
>>>
>>> The reason I'm asking about the relationship between the two models is
>>> whether I could use anova() to compare the two models. So, under this
>>> context is likelihood ratio test meaningful?
>>>
>>> Thanks,
>>> Gang
>>>
>>>
>>>>>> 2010/12/9 Gang Chen <gangchen6 at gmail.com>
>>>>>>>
>>>>>>> Suppose that there are multiple task types (Task) and each task type
>>>>>>> is represented with a few questions (Item). And all subjects (Subj)
>>>>>>> answer the same questions (Item).
>>>>>>>
>>>>>>> How do I compare a model with (1 | Subj) + (1 | Item) versus one with
>>>>>>> (1 | Subj) + (1 | Subj:Item) in lmer()? Through AIC/BIC (assuming the
>>>>>>> fixed effect remain the same)? Would it make more sense to consider (1
>>>>>>> | Subj) + (1 | Subj:Item) + (1 | Item)?
>>>>>>>
>>>>>>> Is (1 | Subj) considered as nested within (Task | Subj)?
>>>>>>>
>>>>>>> Thanks,
>>>>>>> Gang



From bbolker at gmail.com  Sat Dec 11 16:30:22 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 11 Dec 2010 10:30:22 -0500
Subject: [R-sig-ME] Comparing models with different random effects
In-Reply-To: <AANLkTin75QUUHDRhnN_Sfr6T-sdytbfaygQ2C8GEMKcm@mail.gmail.com>
References: <AANLkTimKdT9yYnktcHNf3rweVWTdZK=s8HnGDdwr=jHA@mail.gmail.com>	<AANLkTin3oOVBzz_uZx8wN-GuQBzrNPObYjwxWoD=GYNz@mail.gmail.com>	<AANLkTimZK0fagkKgOTKXy=O9uxeFEdM7pkk0zN47YTwY@mail.gmail.com>	<AANLkTi=4UQXaDXcsVbzwm1ZR4tENFuLtZZv6HLbB_tFX@mail.gmail.com>	<AANLkTimzGLSWDaMcjeezqibL2tDPuEMyqGR9jHf7CgFA@mail.gmail.com>	<AANLkTinbtad22cZdu6_ZU+MPSq9xbtFCWUSuo3HRiWdb@mail.gmail.com>	<4D029E8A.502@gmail.com>
	<AANLkTin75QUUHDRhnN_Sfr6T-sdytbfaygQ2C8GEMKcm@mail.gmail.com>
Message-ID: <4D03990E.5020002@gmail.com>

On 10-12-11 09:40 AM, Gang Chen wrote:
> Thanks a lot for the clarifications, Dr. Bolker!
> 
> Could you comment a little more about the following?
> 
>>  I was going to write more about how one would interpret the
>> relationship between Task and Subj in terms of 'effects', but I think it
>> really doesn't make sense when Task is a fixed effect.
> 
> In my case Task has only 3 levels, and that's why I didn't consider
> (1|Task/Subj) or (1|Task)+(1|Subj). Do you think (1|Task) should be
> included in the model?

  From what you've said so far it sounds to me like Task should be
treated as a fixed effect (i.e., you are interested in the actual means
for each task, or the differences among them, and not just the
variability in responses across tasks) -- so no, I would say (1|Task)
should not be in the model (that would be including it as a random
effect).  You probably do want Task in the model as a fixed effect (i.e.
something like

response~Task+(Task|Subj)+(1|Item)

> 
> Thanks,
> Gang
> 
> 
> On Fri, Dec 10, 2010 at 4:41 PM, Ben Bolker <bbolker at gmail.com> wrote:
>> On 10-12-10 10:35 AM, Yuan-Ye Zhang wrote:
>>> test the sig. of random slope, if you compare these two
>>> (1 | Subj): random intercept
>>> (Task | Subj): random intercept and random slope
>>>
>>> but can you do (Task | Subj)? I thought some levels of Subj is present in
>>> given levels of Task, so is nested.
>>>
>>
>>  (Task|Subj) means that the effect of Task varies among subjects --
>> perfectly sensible to try to estimate this if each subject answered
>> Items representing in more than one Task category.  And because
>> (Task|Subj) implicitly includes an intercept term [(Task|Subj) is
>> equivalent to (1+Task|Subj)], (1|Subj) is nested (in the sense of
>> models) within (Task|Subj).
>>
>>  I was going to write more about how one would interpret the
>> relationship between Task and Subj in terms of 'effects', but I think it
>> really doesn't make sense when Task is a fixed effect. The model
>> specification about (Task|Subj) sets up *none* of the following models:
>>
>> a. there is variation among Task:Subj combinations within a Subj ["Task
>> nested within Subj", (1|Task/Subj)], or
>> b. there is variation among Task:Subj combinations within a Task ["Subj
>> nested within Task", (1|Subj/Task)] [I may have the order of the a/b
>> notation backwards: I have yet to discover a good mnemonic], or
>> c. samples from each Task have random deviations from the overall mean
>> that are consistent across all Subj's, or vice versa ["crossed random
>> effects Subj and Task", (1|Task)+(1|Subj)]
>>
>>  instead, this sets up a model where (as stated above) the *effect* of
>> Task varies randomly (around its overall mean) across Subj's.
>>
>>  Hope that helps and that I didn't screw anything up.
>>
>>  Anyone know of a really good clear primer for this stuff (printed or
>> on the web) that includes (1) mathematical notation and (2) graphical
>> representations/example data plots for the descriptions above?
>>
>>> 2010/12/10 Gang Chen <gangchen6 at gmail.com>
>>>
>>>> Thanks for the quick help, Dr. Bates!
>>>>
>>>>>> My second question is still open: I tend to believe that (1 | Subj) is
>>>>>> nested within (Task | Subj) since the first model has one parameter
>>>>>> (variance) which can be viewed as multiple variances in the second
>>>>>> model being constrained as equal, but I would still appreciate it if
>>>>>> somebody could confirm this.
>>>>>
>>>>> If you are using "is nested within" to mean "is a submodel of" then
>>>>> the answer is yes.
>>>>
>>>> The reason I'm asking about the relationship between the two models is
>>>> whether I could use anova() to compare the two models. So, under this
>>>> context is likelihood ratio test meaningful?
>>>>
>>>> Thanks,
>>>> Gang
>>>>
>>>>
>>>>>>> 2010/12/9 Gang Chen <gangchen6 at gmail.com>
>>>>>>>>
>>>>>>>> Suppose that there are multiple task types (Task) and each task type
>>>>>>>> is represented with a few questions (Item). And all subjects (Subj)
>>>>>>>> answer the same questions (Item).
>>>>>>>>
>>>>>>>> How do I compare a model with (1 | Subj) + (1 | Item) versus one with
>>>>>>>> (1 | Subj) + (1 | Subj:Item) in lmer()? Through AIC/BIC (assuming the
>>>>>>>> fixed effect remain the same)? Would it make more sense to consider (1
>>>>>>>> | Subj) + (1 | Subj:Item) + (1 | Item)?
>>>>>>>>
>>>>>>>> Is (1 | Subj) considered as nested within (Task | Subj)?
>>>>>>>>
>>>>>>>> Thanks,
>>>>>>>> Gang



From bbolker at gmail.com  Sat Dec 11 17:09:12 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 11 Dec 2010 11:09:12 -0500
Subject: [R-sig-ME] standardized coefficients in glmer model
In-Reply-To: <AD30DD503BC9E9479E223CA90866D28601DF0AB4@clmail1.nioo.int>
References: <AD30DD503BC9E9479E223CA90866D28601DF0AB4@clmail1.nioo.int>
Message-ID: <4D03A228.4090909@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 10-12-11 02:21 AM, Leeuwen, Casper van wrote:
> Dear R-list,
> 
> I'm running a mixed effect logistic regression with both factors and
> covariates, an interaction and a random factor.
> 
> model <- glmer (intact_binomial ~ species + sex + retention_time +
> body_mass + body_mass * retention_time + (1 | individual) , family =
> binomial (link = "logit") ) summary(model)
> 
> summary() returns effects sizes given as coefficients of the
> different factors. However, I would like to indicate the importance
> of the different terms in the model, to determine the relative
> importance of for instance sex versus body_mass: which one is more
> important in explaining my dependent variable?

  If all your variables were numeric (which sex is not) then

model_scaled <- glmer(...,data=scale(mydata))

would work: looking at lm.beta and Make.Z in the QuantPsyc package (you
didn't tell us where lm.beta() came from ...), Make.Z seems (as far as I
can tell) to replicate the behavior of the built-in scale() function.
But that approach won't work properly for factors with more than two
levels ...

  Here's lm.beta:

lm.beta
function (MOD)
{
    b <- summary(MOD)$coef[-1, 1]
    sx <- sd(MOD$model[-1])
    sy <- sd(MOD$model[1])
    beta <- b * sx/sy
    return(beta)
}

 Here's a translation into lmer-land:

lm.beta.lmer <- function(mod) {
  b <- fixef(mod)[-1]            ## fixed-effect coefs, sans intercept
  sd.x <- apply(mod at X[,-1],2,sd) ## pull out model (design) matrix,
                                 ## drop intercept column, calculate
                                 ## sd of remaining columns
  sd.y <- sd(mod at y)              ## sd of response
  b*sd.x/sd.y
}

  Here's an example, using the Orthodont data from the nlme package:

library(nlme)
data(Orthodont)
dat <- as.data.frame(Orthodont)
detach(package:nlme)

library(lme4)
fm2 <- lmer(distance ~ age + Sex + (age|Subject), data = dat)
lm.beta.lmer(fm2)

  For this example (which like yours has Sex, a two-level factor, as its
only non-numeric predictor) we can show that we get the same answer (up
to numeric fuzz) by scale()ing:

pdat <- with(dat,cbind(distance,age,s=as.numeric(Sex)))
pdat <- scale(pdat)
dat2 <- data.frame(pdat,Subject=dat$Subject)

fm3 <- lmer(distance ~ age + s + (age|Subject), data = dat2)
fixef(fm3)

  The only remaining question I have is whether it makes sense to scale
by sd(y) in this case -- may not generalize to the GLM case from the LM
case?  But you should have the correct *relative* magnitudes of
parameters in any case.

  good luck,
    Ben Bolker

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iEYEARECAAYFAk0DoigACgkQc5UpGjwzenOqSgCZAcApAJmi5JmuhZL4H1prsFp9
4p0AnAlkF7B5JU1b7hrXqA/eLfy5l2TZ
=Vkhu
-----END PGP SIGNATURE-----



From bbolker at gmail.com  Sat Dec 11 19:27:56 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 11 Dec 2010 13:27:56 -0500
Subject: [R-sig-ME] Could the random effect at the level of each
 observation be a trap?
In-Reply-To: <AANLkTi=155JVhNP3L7U-MBwUqKzwxwtsWL10Lgo13yo1@mail.gmail.com>
References: <AANLkTi=155JVhNP3L7U-MBwUqKzwxwtsWL10Lgo13yo1@mail.gmail.com>
Message-ID: <4D03C2AC.7050503@gmail.com>

On 10-12-10 09:39 PM, Billy wrote:
> Hi all!
> 
> I'm a relatively newbie ecologist student getting adventures at the
> mixed models world and facing some trouble to interpret random
> effects. I hope someone could help me.
> Quickly, I'm constructing different models using glmer() to discover
> which factors could influence females' reproductive decisions. I have
> sampled several males and classified them as successful or
> unsuccessful.  Therefore, I'm modelling logistic regressions with more
> than one fixed variable and random variables.
> I have sampled individuals monthly and, sometimes, the same individual
> (MaleID) was sampled more than once, in different status. Then, I used
> "MaleID" as a random variable.
> Well, I built a bunch of models considering only MaleID as the random
> variable as:
> 
> m1 <- glmer(y ~ 1 + (1|MaleID), family=binomial)
> m2 <- glmer(y ~ x + (1|MaleID), family=binomial)
> m3 <- glmer(y ~ z + (1|MaleID), family=binomial)
> 
> 
> Moreover, in several posts here I've read about count data show high
> overdispersion, even using family=binomial for the error. One
> recurrent solution suggested is create a vector to each observation
> as:
> 
> resid <- as.factor(1:dim(data)[1])
> 
> Then, I built models considering this random variable too, trying to
> understand that, as following
> 
> m4 <- glmer(y ~ 1 + (1|resid), family=binomial)
> m5 <- glmer(y ~ x + (1|resid), family=binomial)
> m6 <- glmer(y ~ w + (1|resid), family=binomial)
> 
> and
> 
> m7 <- glmer(y ~ 1 + (1|MaleID:resid ), family=binomial)
> m8 <- glmer(y ~ x + (1|MaleID:resid ), family=binomial)
> m9 <- glmer(y ~ z + (1|MaleID:resid ), family=binomial)
> 
> Using a model selection approach and looking for the deviance and the
> AIC values, I observed that the correspondent models from the second
> block (m4, m5 and m6 in the example above) and the third block (m7, m8
> and m9) showed the same values. Is that due to the "resid" random
> effect?
> 

   I think you want

  ~ [fixed predictor(s)] + (1|MaleID)+(1|resid)

?



From davidD at qimr.edu.au  Sat Dec 11 21:29:23 2010
From: davidD at qimr.edu.au (David Duffy)
Date: Sun, 12 Dec 2010 06:29:23 +1000 (EST)
Subject: [R-sig-ME] standardized coefficients in glmer model
In-Reply-To: <AD30DD503BC9E9479E223CA90866D28601DF0AB4@clmail1.nioo.int>
References: <AD30DD503BC9E9479E223CA90866D28601DF0AB4@clmail1.nioo.int>
Message-ID: <Pine.LNX.4.64.1012120623530.7782@orpheus.qimr.edu.au>

On Sat, 11 Dec 2010, Leeuwen, Casper van wrote:

> model <- glmer (intact_binomial ~
>              species
>              + sex
>              + retention_time
>              + body_mass
>              + body_mass * retention_time
>              + (1 | individual)
>              , family = binomial (link = "logit")
>              )
> summary(model)
>
> summary() returns effects sizes given as coefficients of the different 
> factors. However, I would like to indicate the importance of the 
> different terms in the model, to determine the relative importance of 
> for instance sex versus body_mass: which one is more important in 
> explaining my dependent variable?

Given this is a logistic regression, there are various more or less 
unsatisfactory equivalents of an R2.  You might be better off just 
comparing effect sizes eg odds ratio (exp(beta)) for sex versus that for 
the difference between the first and third quartiles of BMI or
from say BMI=20 to BMI=25 and BMI=30, presuming this is human data.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From bbolker at gmail.com  Sun Dec 12 03:16:34 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 11 Dec 2010 21:16:34 -0500
Subject: [R-sig-ME] standardized coefficients in glmer model
In-Reply-To: <Pine.LNX.4.64.1012120623530.7782@orpheus.qimr.edu.au>
References: <AD30DD503BC9E9479E223CA90866D28601DF0AB4@clmail1.nioo.int>
	<Pine.LNX.4.64.1012120623530.7782@orpheus.qimr.edu.au>
Message-ID: <4D043082.4000300@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 10-12-11 03:29 PM, David Duffy wrote:
> On Sat, 11 Dec 2010, Leeuwen, Casper van wrote:
> 
>> model <- glmer (intact_binomial ~
>>              species
>>              + sex
>>              + retention_time
>>              + body_mass
>>              + body_mass * retention_time
>>              + (1 | individual)
>>              , family = binomial (link = "logit")
>>              )
>> summary(model)
>>
>> summary() returns effects sizes given as coefficients of the different
>> factors. However, I would like to indicate the importance of the
>> different terms in the model, to determine the relative importance of
>> for instance sex versus body_mass: which one is more important in
>> explaining my dependent variable?
> 
> Given this is a logistic regression, there are various more or less
> unsatisfactory equivalents of an R2.  You might be better off just
> comparing effect sizes eg odds ratio (exp(beta)) for sex versus that for
> the difference between the first and third quartiles of BMI or
> from say BMI=20 to BMI=25 and BMI=30, presuming this is human data.
> 
  I think the OP is not asking for a pseudo-R^2 or summary of overall
goodness of fit, but standardized regression coefficients ...
  given that "species" is one of the predictors, I bet it's not human data.

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iEYEARECAAYFAk0EMIIACgkQc5UpGjwzenMMMACggnoP3zcO9lEDX7SMMnz6Ztou
utQAnA1u72CiRuU7w+H2kGjdr9jI0Ldy
=Nxg0
-----END PGP SIGNATURE-----



From C.vanLeeuwen at nioo.knaw.nl  Sun Dec 12 03:18:47 2010
From: C.vanLeeuwen at nioo.knaw.nl (Leeuwen, Casper van)
Date: Sun, 12 Dec 2010 03:18:47 +0100
Subject: [R-sig-ME] standardized coefficients in glmer model
References: <AD30DD503BC9E9479E223CA90866D28601DF0AB4@clmail1.nioo.int>
	<Pine.LNX.4.64.1012120623530.7782@orpheus.qimr.edu.au>
Message-ID: <AD30DD503BC9E9479E223CA90866D28601DF0AB8@clmail1.nioo.int>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101212/6316b57c/attachment.pl>

From bbolker at gmail.com  Sun Dec 12 03:56:46 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 11 Dec 2010 21:56:46 -0500
Subject: [R-sig-ME] standardized coefficients in glmer model
In-Reply-To: <AD30DD503BC9E9479E223CA90866D28601DF0AB8@clmail1.nioo.int>
References: <AD30DD503BC9E9479E223CA90866D28601DF0AB4@clmail1.nioo.int>
	<Pine.LNX.4.64.1012120623530.7782@orpheus.qimr.edu.au>
	<AD30DD503BC9E9479E223CA90866D28601DF0AB8@clmail1.nioo.int>
Message-ID: <4D0439EE.7060208@gmail.com>

  What I meant is that in the linear model case, what you get when you
calculate the standardized regression coefficients is expected change in
(y/(sd y)) per unit change in (x/(sd x)). With GLM you don't get this,
because of the link function.  The natural analogue would (I think) be
expected change in (link(y)/sd(link(y))), or something like that
[because the assumption is that the relationship is linear on the linear
predictor scale], but naively calculating sd(link(y)) won't work,
because link(y) is often infinite.

  A bit of googling suggests (as with many other times when one wants to
generalize from linear models to GLMs -- e.g. R^2 values) that the
answer is not obvious ...

<http://goliath.ecnext.com/coms2/gi_0199-762729/Six-approaches-to-calculating-standardized.html>
<http://www.nd.edu/~rwilliam/stats3/L06.pdf>

  Again, for your purposes I think (?) the most important thing is that
you have the scales of the betas standardized correctly with respect to
each other (as opposed to standardizing the response variable), which
isn't a problem.

On 10-12-11 09:18 PM, Leeuwen, Casper van wrote:
> Dear list, David and Ben,
>  
> Ben Bolker:
> Thanks so much for the awesome function: that was exacty what I was
> looking for, and it works perfectly on my dataset. Even including
> estimate for the interactions. 
> However, I'm sorry but don't understand your remark on the scaling of
> sd(y) "may not generalize to the GLM case from the LM case?". I think it
> doesn't matter to scale the y-values for my x-estimates, but do you mean
> this would be different for a GLM model than for a LM model? Do you
> think the scaling of the y-values is incorrect if the regression is
> non-linear?
> 
>  
> 
> David Duffy:
> 
> Thanks a lot for the suggestion, my data is not human but birds body
> mass, essentially the same but no BMI. If I understand you correctly,
> you say it doesn't make sense to compare estimates between a binomial
> term (sex) and a (continuous) covariate (body mass)?
> 
> Should I somehow construct a binomial variable from the body mass to be
> able to compare the estimates?
> 
>  
> 
> Thanks,
> 
> Casper
> 
> 
> ------------------------------------------------------------------------
> *From:* David Duffy [mailto:davidD at qimr.edu.au]
> *Sent:* Sat 12/11/2010 21:29
> *To:* Leeuwen, Casper van
> *Cc:* r-sig-mixed-models at r-project.org
> *Subject:* Re: [R-sig-ME] standardized coefficients in glmer model
> 
> On Sat, 11 Dec 2010, Leeuwen, Casper van wrote:
> 
>> model <- glmer (intact_binomial ~
>>              species
>>              + sex
>>              + retention_time
>>              + body_mass
>>              + body_mass * retention_time
>>              + (1 | individual)
>>              , family = binomial (link = "logit")
>>              )
>> summary(model)
>>
>> summary() returns effects sizes given as coefficients of the different
>> factors. However, I would like to indicate the importance of the
>> different terms in the model, to determine the relative importance of
>> for instance sex versus body_mass: which one is more important in
>> explaining my dependent variable?
> 
> Given this is a logistic regression, there are various more or less
> unsatisfactory equivalents of an R2.  You might be better off just
> comparing effect sizes eg odds ratio (exp(beta)) for sex versus that for
> the difference between the first and third quartiles of BMI or
> from say BMI=20 to BMI=25 and BMI=30, presuming this is human data.
> 
> --
> | David Duffy (MBBS PhD)                                         ,-_|\
> | email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
> | Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
> | 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v
> 
> ------------------------------------------------------------------------
> 
> *From:* Ben Bolker [mailto:bbolker at gmail.com]
> *Sent:* Sat 12/11/2010 17:09
> *To:* Leeuwen, Casper van; r-sig-mixed-models at r-project.org
> *Subject:* Re: [R-sig-ME] standardized coefficients in glmer model
> 
> On 10-12-11 02:21 AM, Leeuwen, Casper van wrote:
>> Dear R-list,
> 
>> I'm running a mixed effect logistic regression with both factors and
>> covariates, an interaction and a random factor.
> 
>> model <- glmer (intact_binomial ~ species + sex + retention_time +
>> body_mass + body_mass * retention_time + (1 | individual) , family =
>> binomial (link = "logit") ) summary(model)
> 
>> summary() returns effects sizes given as coefficients of the
>> different factors. However, I would like to indicate the importance
>> of the different terms in the model, to determine the relative
>> importance of for instance sex versus body_mass: which one is more
>> important in explaining my dependent variable?
> 
>   If all your variables were numeric (which sex is not) then
> 
> model_scaled <- glmer(...,data=scale(mydata))
> 
> would work: looking at lm.beta and Make.Z in the QuantPsyc package (you
> didn't tell us where lm.beta() came from ...), Make.Z seems (as far as I
> can tell) to replicate the behavior of the built-in scale() function.
> But that approach won't work properly for factors with more than two
> levels ...
> 
>   Here's lm.beta:
> 
> lm.beta
> function (MOD)
> {
>     b <- summary(MOD)$coef[-1, 1]
>     sx <- sd(MOD$model[-1])
>     sy <- sd(MOD$model[1])
>     beta <- b * sx/sy
>     return(beta)
> }
> 
>  Here's a translation into lmer-land:
> 
> lm.beta.lmer <- function(mod) {
>   b <- fixef(mod)[-1]            ## fixed-effect coefs, sans intercept
>   sd.x <- apply(mod at X[,-1],2,sd) ## pull out model (design) matrix,
>                                  ## drop intercept column, calculate
>                                  ## sd of remaining columns
>   sd.y <- sd(mod at y)              ## sd of response
>   b*sd.x/sd.y
> }
> 
>   Here's an example, using the Orthodont data from the nlme package:
> 
> library(nlme)
> data(Orthodont)
> dat <- as.data.frame(Orthodont)
> detach(package:nlme)
> 
> library(lme4)
> fm2 <- lmer(distance ~ age + Sex + (age|Subject), data = dat)
> lm.beta.lmer(fm2)
> 
>   For this example (which like yours has Sex, a two-level factor, as its
> only non-numeric predictor) we can show that we get the same answer (up
> to numeric fuzz) by scale()ing:
> 
> pdat <- with(dat,cbind(distance,age,s=as.numeric(Sex)))
> pdat <- scale(pdat)
> dat2 <- data.frame(pdat,Subject=dat$Subject)
> 
> fm3 <- lmer(distance ~ age + s + (age|Subject), data = dat2)
> fixef(fm3)
> 
>   The only remaining question I have is whether it makes sense to scale
> by sd(y) in this case -- may not generalize to the GLM case from the LM
> case?  But you should have the correct *relative* magnitudes of
> parameters in any case.
> 
>   good luck,
>     Ben Bolker
>



From helixed2 at yahoo.com  Mon Dec 13 04:03:30 2010
From: helixed2 at yahoo.com (Jeremy Koster)
Date: Sun, 12 Dec 2010 19:03:30 -0800 (PST)
Subject: [R-sig-ME] lme4 to MCMCglmm
Message-ID: <962152.37418.qm@web58207.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101212/363f915f/attachment.pl>

From billy.requena at gmail.com  Mon Dec 13 18:33:49 2010
From: billy.requena at gmail.com (Billy)
Date: Mon, 13 Dec 2010 11:33:49 -0600
Subject: [R-sig-ME] Could the random effect at the level of each
 observation be a trap?
In-Reply-To: <4D03C2AC.7050503@gmail.com>
References: <AANLkTi=155JVhNP3L7U-MBwUqKzwxwtsWL10Lgo13yo1@mail.gmail.com>
	<4D03C2AC.7050503@gmail.com>
Message-ID: <AANLkTi==obqdyEUK8yhWhe4Pz0m=ZmRe4j7VmFBRn93C@mail.gmail.com>

Hi Ben,

thanks for your reply.
In fact, I've tried the additive random effect of MaleID and resid,
but I got the same problem: quantitatively and qualitatively
differences. Models considering Male ID + resid showed smaller
deviances than models that only considered MaleID AND among models
considering MaleID + resid, the best model was the one which consider
no effect of any explanatory variable, while among models considering
only MaleID as random variable, the best model was the one considering
effect of the interaction between 2 explanatory variables.
I still have doubts about the usage of this "resid" variable, mainly
because the interpretation of the results is completely different. Is
the decrease of the whole deviance enough justification to use that
and interpret only the results obtained among models considering
MaleID + resid?

Thanks again for you all,

Billy

On Sat, Dec 11, 2010 at 12:27 PM, Ben Bolker <bbolker at gmail.com> wrote:
> On 10-12-10 09:39 PM, Billy wrote:
>> Hi all!
>>
>> I'm a relatively newbie ecologist student getting adventures at the
>> mixed models world and facing some trouble to interpret random
>> effects. I hope someone could help me.
>> Quickly, I'm constructing different models using glmer() to discover
>> which factors could influence females' reproductive decisions. I have
>> sampled several males and classified them as successful or
>> unsuccessful. ?Therefore, I'm modelling logistic regressions with more
>> than one fixed variable and random variables.
>> I have sampled individuals monthly and, sometimes, the same individual
>> (MaleID) was sampled more than once, in different status. Then, I used
>> "MaleID" as a random variable.
>> Well, I built a bunch of models considering only MaleID as the random
>> variable as:
>>
>> m1 <- glmer(y ~ 1 + (1|MaleID), family=binomial)
>> m2 <- glmer(y ~ x + (1|MaleID), family=binomial)
>> m3 <- glmer(y ~ z + (1|MaleID), family=binomial)
>>
>>
>> Moreover, in several posts here I've read about count data show high
>> overdispersion, even using family=binomial for the error. One
>> recurrent solution suggested is create a vector to each observation
>> as:
>>
>> resid <- as.factor(1:dim(data)[1])
>>
>> Then, I built models considering this random variable too, trying to
>> understand that, as following
>>
>> m4 <- glmer(y ~ 1 + (1|resid), family=binomial)
>> m5 <- glmer(y ~ x + (1|resid), family=binomial)
>> m6 <- glmer(y ~ w + (1|resid), family=binomial)
>>
>> and
>>
>> m7 <- glmer(y ~ 1 + (1|MaleID:resid ), family=binomial)
>> m8 <- glmer(y ~ x + (1|MaleID:resid ), family=binomial)
>> m9 <- glmer(y ~ z + (1|MaleID:resid ), family=binomial)
>>
>> Using a model selection approach and looking for the deviance and the
>> AIC values, I observed that the correspondent models from the second
>> block (m4, m5 and m6 in the example above) and the third block (m7, m8
>> and m9) showed the same values. Is that due to the "resid" random
>> effect?
>>
>
> ? I think you want
>
> ?~ [fixed predictor(s)] + (1|MaleID)+(1|resid)
>
> ?
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Gustavo Requena
PhD student - Laboratory of Arthropod Behavior and Evolution
Universidade de S?o Paulo
Correspondence adress:
a/c Glauco Machado
Departamento de Ecologia - IBUSP
Rua do Mat?o - Travessa 14 no 321 Cidade Universit?ria, S?o Paulo - SP, Brasil
CEP 05508-900
Phone number: 55 11 3091-7488

http://ecologia.ib.usp.br/opilio/gustavo.html



From billy.requena at gmail.com  Mon Dec 13 20:50:42 2010
From: billy.requena at gmail.com (Billy)
Date: Mon, 13 Dec 2010 13:50:42 -0600
Subject: [R-sig-ME] Could the random effect at the level of each
 observation be a trap?
In-Reply-To: <AANLkTikLO=E_tscuww0H+xwzUaC62AzSc3cb_xVM7PLh@mail.gmail.com>
References: <AANLkTi=155JVhNP3L7U-MBwUqKzwxwtsWL10Lgo13yo1@mail.gmail.com>
	<4D03C2AC.7050503@gmail.com>
	<AANLkTi==obqdyEUK8yhWhe4Pz0m=ZmRe4j7VmFBRn93C@mail.gmail.com>
	<AANLkTikLO=E_tscuww0H+xwzUaC62AzSc3cb_xVM7PLh@mail.gmail.com>
Message-ID: <AANLkTinS3HjDcaRTnKwJeKy8P1fkQotG7P0frEHE5h+L@mail.gmail.com>

Hi Drew!

Thanks for the reply, but I think I wasn't clear enough before. As I
have sampled males throughout one year, some individuals were sampled
in more than one month, but several individuals were sampled just once
(as a successful or as unsuccessful). Therefore, differently from your
example, I don't have the same individuals recaptured in all 12
months, just changing their breeding success status. I think that's
the reason to the overdispersion I mentioned before. It means the most
of my data are about unsuccessful individuals (more than half of the
sample size fall into the unsuccessful category) and I wanna
investigated if some specific characteristics of the successful males
are responsible to that success in achieving mates.

Billy

On Mon, Dec 13, 2010 at 1:39 PM, Drew Tyre <atyre2 at unl.edu> wrote:
> This question of overdispersion in binomial models is near and dear to
> my heart - so I tried to make an example to see if I can replicate the
> type of situation you're describing Billy (code below). I guess I
> don't understand the data you have, because as long as each male is
> either successful or unsuccessful (once), you will never observe
> overdispersion, at least not the way I understand it?
>
> setseed(32493)
> x = rnorm(100)
> z = rnorm(100)
> maleID = sample(1:40,size=100,replace=TRUE)
> n.male = length(unique(maleID))
> sigmaMale = 1
> sigmaResid = 0.2
> Maleeffect = rnorm(40,sd=sigmaMale)
> Resideffect = rnorm(100,sd=sigmaResid)
> beta = c(0,2,1,0.54) # effect of x, z, and x*z
>
> logodds.y = cbind(1,x,z,x*z) %*% beta + Maleeffect[maleID] + Resideffect
>
> y = rbinom(100,1,1/(1+exp(-logodds.y)))
>
> df = data.frame(x=x,z=z,maleID=maleID,y=y)
>
> glm(y~x*z,data=df,family=binomial) # OK, seems to work
>
> library(lme4)
>
> models = list(y~x*z + (1|maleID),
> ? ? ? ?y~x+z + (1|maleID),
> ? ? ? ?y~x + (1|maleID),
> ? ? ? ?y~z + (1|maleID),
> ? ? ? ?y~1 + (1|maleID))
>
> fits = lapply(models,function(ff)glmer(ff,family=binomial,data=df))
>
> sapply(fits,function(fm)summary(fm)@AICtab) # model 2 is best,
> parameters about right
>
> # ok try this residual idea
> resid <- as.factor(1:dim(df)[1])
>
> models = list(y~x*z + (1|maleID)+(1|resid),
> ? ? ? ?y~x+z + (1|maleID)+(1|resid),
> ? ? ? ?y~x + (1|maleID)+(1|resid),
> ? ? ? ?y~z + (1|maleID)+(1|resid),
> ? ? ? ?y~1 + (1|maleID)+(1|resid))
>
> fits = lapply(models,function(ff)glmer(ff,family=binomial,data=df))
>
> # lots of warnings, otherwise results unaffected - estimated variance
> of resid very small
>
>
> On Mon, Dec 13, 2010 at 11:33 AM, Billy <billy.requena at gmail.com> wrote:
>> Hi Ben,
>>
>> thanks for your reply.
>> In fact, I've tried the additive random effect of MaleID and resid,
>> but I got the same problem: quantitatively and qualitatively
>> differences. Models considering Male ID + resid showed smaller
>> deviances than models that only considered MaleID AND among models
>> considering MaleID + resid, the best model was the one which consider
>> no effect of any explanatory variable, while among models considering
>> only MaleID as random variable, the best model was the one considering
>> effect of the interaction between 2 explanatory variables.
>> I still have doubts about the usage of this "resid" variable, mainly
>> because the interpretation of the results is completely different. Is
>> the decrease of the whole deviance enough justification to use that
>> and interpret only the results obtained among models considering
>> MaleID + resid?
>>
>> Thanks again for you all,
>>
>> Billy
>>
>> On Sat, Dec 11, 2010 at 12:27 PM, Ben Bolker <bbolker at gmail.com> wrote:
>>> On 10-12-10 09:39 PM, Billy wrote:
>>>> Hi all!
>>>>
>>>> I'm a relatively newbie ecologist student getting adventures at the
>>>> mixed models world and facing some trouble to interpret random
>>>> effects. I hope someone could help me.
>>>> Quickly, I'm constructing different models using glmer() to discover
>>>> which factors could influence females' reproductive decisions. I have
>>>> sampled several males and classified them as successful or
>>>> unsuccessful. ?Therefore, I'm modelling logistic regressions with more
>>>> than one fixed variable and random variables.
>>>> I have sampled individuals monthly and, sometimes, the same individual
>>>> (MaleID) was sampled more than once, in different status. Then, I used
>>>> "MaleID" as a random variable.
>>>> Well, I built a bunch of models considering only MaleID as the random
>>>> variable as:
>>>>
>>>> m1 <- glmer(y ~ 1 + (1|MaleID), family=binomial)
>>>> m2 <- glmer(y ~ x + (1|MaleID), family=binomial)
>>>> m3 <- glmer(y ~ z + (1|MaleID), family=binomial)
>>>>
>>>>
>>>> Moreover, in several posts here I've read about count data show high
>>>> overdispersion, even using family=binomial for the error. One
>>>> recurrent solution suggested is create a vector to each observation
>>>> as:
>>>>
>>>> resid <- as.factor(1:dim(data)[1])
>>>>
>>>> Then, I built models considering this random variable too, trying to
>>>> understand that, as following
>>>>
>>>> m4 <- glmer(y ~ 1 + (1|resid), family=binomial)
>>>> m5 <- glmer(y ~ x + (1|resid), family=binomial)
>>>> m6 <- glmer(y ~ w + (1|resid), family=binomial)
>>>>
>>>> and
>>>>
>>>> m7 <- glmer(y ~ 1 + (1|MaleID:resid ), family=binomial)
>>>> m8 <- glmer(y ~ x + (1|MaleID:resid ), family=binomial)
>>>> m9 <- glmer(y ~ z + (1|MaleID:resid ), family=binomial)
>>>>
>>>> Using a model selection approach and looking for the deviance and the
>>>> AIC values, I observed that the correspondent models from the second
>>>> block (m4, m5 and m6 in the example above) and the third block (m7, m8
>>>> and m9) showed the same values. Is that due to the "resid" random
>>>> effect?
>>>>
>>>
>>> ? I think you want
>>>
>>> ?~ [fixed predictor(s)] + (1|MaleID)+(1|resid)
>>>
>>> ?
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>>
>> --
>> Gustavo Requena
>> PhD student - Laboratory of Arthropod Behavior and Evolution
>> Universidade de S?o Paulo
>> Correspondence adress:
>> a/c Glauco Machado
>> Departamento de Ecologia - IBUSP
>> Rua do Mat?o - Travessa 14 no 321 Cidade Universit?ria, S?o Paulo - SP, Brasil
>> CEP 05508-900
>> Phone number: 55 11 3091-7488
>>
>> http://ecologia.ib.usp.br/opilio/gustavo.html
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
> Drew Tyre
>
> School of Natural Resources
> University of Nebraska-Lincoln
> 416 Hardin Hall, East Campus
> 3310 Holdrege Street
> Lincoln, NE 68583-0974
>
> phone: +1 402 472 4054
> fax: +1 402 472 2946
> email: atyre2 at unl.edu
> http://snr.unl.edu/tyre
> http://aminpractice.blogspot.com
> http://www.flickr.com/photos/atiretoo
>



-- 
Gustavo Requena
PhD student - Laboratory of Arthropod Behavior and Evolution
Universidade de S?o Paulo
Correspondence adress:
a/c Glauco Machado
Departamento de Ecologia - IBUSP
Rua do Mat?o - Travessa 14 no 321 Cidade Universit?ria, S?o Paulo - SP, Brasil
CEP 05508-900
Phone number: 55 11 3091-7488

http://ecologia.ib.usp.br/opilio/gustavo.html



From datkins at u.washington.edu  Mon Dec 13 21:51:47 2010
From: datkins at u.washington.edu (David Atkins)
Date: Mon, 13 Dec 2010 12:51:47 -0800
Subject: [R-sig-ME] lme4 to MCMCglmm
In-Reply-To: <962152.37418.qm@web58207.mail.re3.yahoo.com>
References: <962152.37418.qm@web58207.mail.re3.yahoo.com>
Message-ID: <4D068763.8000501@u.washington.edu>


Jeremy--

Jarrod Hadfield (developer of MCMCglmm) has quite a bit of 
documentation, including an article at Journal of Statistical Software 
and fairly extensive course notes, included with the package.  Though, 
don't think of any that compares explicitly with lme4.

However, both packages can fit such a wide range of models, that I'm not 
sure whether "general" comparisons would be all that useful to you.

If you know what your model might be in (g)lmer, you might post that 
(ideally with real or fake data), and then I suspect you could get some 
more specific feedback about how to translate that into an MCMCglmm model.

cheers, Dave


Jeremy wrote:

Per a suggestion from David Atkins, I am trying to familiarize myself 
with the MCMCglmm package for the estimation of cross-classified 
mixed-effects models of inter-household food sharing.  I'm having a 
little trouble as I attempt to specify the model, however.

I am wondering if anyone knows of resources for folks who are working 
with MCMCglmm after already being familiar with lme4.  In other words, 
are there any online scripts or other resources from researchers who 
have first estimated models in lme4, then specified comparable models in 
MCMCglmm?

Thanks!




	[[alternative HTML version deleted]]


-- 
Dave Atkins, PhD
Research Associate Professor
Department of Psychiatry and Behavioral Science
University of Washington
datkins at u.washington.edu

Center for the Study of Health and Risk Behaviors (CSHRB)		
1100 NE 45th Street, Suite 300 	
Seattle, WA  98105 	
206-616-3879 	
http://depts.washington.edu/cshrb/
(Mon-Wed)	

Center for Healthcare Improvement, for Addictions, Mental Illness,
   Medically Vulnerable Populations (CHAMMP)
325 9th Avenue, 2HH-15
Box 359911
Seattle, WA 98104
http://www.chammp.org
(Thurs)



From atyre2 at unl.edu  Mon Dec 13 20:39:41 2010
From: atyre2 at unl.edu (Drew Tyre)
Date: Mon, 13 Dec 2010 13:39:41 -0600
Subject: [R-sig-ME] Could the random effect at the level of each
 observation be a trap?
In-Reply-To: <AANLkTi==obqdyEUK8yhWhe4Pz0m=ZmRe4j7VmFBRn93C@mail.gmail.com>
References: <AANLkTi=155JVhNP3L7U-MBwUqKzwxwtsWL10Lgo13yo1@mail.gmail.com>
	<4D03C2AC.7050503@gmail.com>
	<AANLkTi==obqdyEUK8yhWhe4Pz0m=ZmRe4j7VmFBRn93C@mail.gmail.com>
Message-ID: <AANLkTikLO=E_tscuww0H+xwzUaC62AzSc3cb_xVM7PLh@mail.gmail.com>

This question of overdispersion in binomial models is near and dear to
my heart - so I tried to make an example to see if I can replicate the
type of situation you're describing Billy (code below). I guess I
don't understand the data you have, because as long as each male is
either successful or unsuccessful (once), you will never observe
overdispersion, at least not the way I understand it?

setseed(32493)
x = rnorm(100)
z = rnorm(100)
maleID = sample(1:40,size=100,replace=TRUE)
n.male = length(unique(maleID))
sigmaMale = 1
sigmaResid = 0.2
Maleeffect = rnorm(40,sd=sigmaMale)
Resideffect = rnorm(100,sd=sigmaResid)
beta = c(0,2,1,0.54) # effect of x, z, and x*z

logodds.y = cbind(1,x,z,x*z) %*% beta + Maleeffect[maleID] + Resideffect

y = rbinom(100,1,1/(1+exp(-logodds.y)))

df = data.frame(x=x,z=z,maleID=maleID,y=y)

glm(y~x*z,data=df,family=binomial) # OK, seems to work

library(lme4)

models = list(y~x*z + (1|maleID),
	y~x+z + (1|maleID),
	y~x + (1|maleID),
	y~z + (1|maleID),
	y~1 + (1|maleID))

fits = lapply(models,function(ff)glmer(ff,family=binomial,data=df))

sapply(fits,function(fm)summary(fm)@AICtab) # model 2 is best,
parameters about right

# ok try this residual idea
resid <- as.factor(1:dim(df)[1])

models = list(y~x*z + (1|maleID)+(1|resid),
	y~x+z + (1|maleID)+(1|resid),
	y~x + (1|maleID)+(1|resid),
	y~z + (1|maleID)+(1|resid),
	y~1 + (1|maleID)+(1|resid))

fits = lapply(models,function(ff)glmer(ff,family=binomial,data=df))

# lots of warnings, otherwise results unaffected - estimated variance
of resid very small


On Mon, Dec 13, 2010 at 11:33 AM, Billy <billy.requena at gmail.com> wrote:
> Hi Ben,
>
> thanks for your reply.
> In fact, I've tried the additive random effect of MaleID and resid,
> but I got the same problem: quantitatively and qualitatively
> differences. Models considering Male ID + resid showed smaller
> deviances than models that only considered MaleID AND among models
> considering MaleID + resid, the best model was the one which consider
> no effect of any explanatory variable, while among models considering
> only MaleID as random variable, the best model was the one considering
> effect of the interaction between 2 explanatory variables.
> I still have doubts about the usage of this "resid" variable, mainly
> because the interpretation of the results is completely different. Is
> the decrease of the whole deviance enough justification to use that
> and interpret only the results obtained among models considering
> MaleID + resid?
>
> Thanks again for you all,
>
> Billy
>
> On Sat, Dec 11, 2010 at 12:27 PM, Ben Bolker <bbolker at gmail.com> wrote:
>> On 10-12-10 09:39 PM, Billy wrote:
>>> Hi all!
>>>
>>> I'm a relatively newbie ecologist student getting adventures at the
>>> mixed models world and facing some trouble to interpret random
>>> effects. I hope someone could help me.
>>> Quickly, I'm constructing different models using glmer() to discover
>>> which factors could influence females' reproductive decisions. I have
>>> sampled several males and classified them as successful or
>>> unsuccessful. ?Therefore, I'm modelling logistic regressions with more
>>> than one fixed variable and random variables.
>>> I have sampled individuals monthly and, sometimes, the same individual
>>> (MaleID) was sampled more than once, in different status. Then, I used
>>> "MaleID" as a random variable.
>>> Well, I built a bunch of models considering only MaleID as the random
>>> variable as:
>>>
>>> m1 <- glmer(y ~ 1 + (1|MaleID), family=binomial)
>>> m2 <- glmer(y ~ x + (1|MaleID), family=binomial)
>>> m3 <- glmer(y ~ z + (1|MaleID), family=binomial)
>>>
>>>
>>> Moreover, in several posts here I've read about count data show high
>>> overdispersion, even using family=binomial for the error. One
>>> recurrent solution suggested is create a vector to each observation
>>> as:
>>>
>>> resid <- as.factor(1:dim(data)[1])
>>>
>>> Then, I built models considering this random variable too, trying to
>>> understand that, as following
>>>
>>> m4 <- glmer(y ~ 1 + (1|resid), family=binomial)
>>> m5 <- glmer(y ~ x + (1|resid), family=binomial)
>>> m6 <- glmer(y ~ w + (1|resid), family=binomial)
>>>
>>> and
>>>
>>> m7 <- glmer(y ~ 1 + (1|MaleID:resid ), family=binomial)
>>> m8 <- glmer(y ~ x + (1|MaleID:resid ), family=binomial)
>>> m9 <- glmer(y ~ z + (1|MaleID:resid ), family=binomial)
>>>
>>> Using a model selection approach and looking for the deviance and the
>>> AIC values, I observed that the correspondent models from the second
>>> block (m4, m5 and m6 in the example above) and the third block (m7, m8
>>> and m9) showed the same values. Is that due to the "resid" random
>>> effect?
>>>
>>
>> ? I think you want
>>
>> ?~ [fixed predictor(s)] + (1|MaleID)+(1|resid)
>>
>> ?
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
> Gustavo Requena
> PhD student - Laboratory of Arthropod Behavior and Evolution
> Universidade de S?o Paulo
> Correspondence adress:
> a/c Glauco Machado
> Departamento de Ecologia - IBUSP
> Rua do Mat?o - Travessa 14 no 321 Cidade Universit?ria, S?o Paulo - SP, Brasil
> CEP 05508-900
> Phone number: 55 11 3091-7488
>
> http://ecologia.ib.usp.br/opilio/gustavo.html
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Drew Tyre

School of Natural Resources
University of Nebraska-Lincoln
416 Hardin Hall, East Campus
3310 Holdrege Street
Lincoln, NE 68583-0974

phone: +1 402 472 4054
fax: +1 402 472 2946
email: atyre2 at unl.edu
http://snr.unl.edu/tyre
http://aminpractice.blogspot.com
http://www.flickr.com/photos/atiretoo



From Jason_Taylor1 at baylor.edu  Mon Dec 13 23:18:31 2010
From: Jason_Taylor1 at baylor.edu (Taylor, Jason)
Date: Mon, 13 Dec 2010 16:18:31 -0600
Subject: [R-sig-ME] p values for balanced experimental designs in lme.
Message-ID: <DB0892FFCE97CA42BE2144E916EB43F22D557488F4@MAIL-IK.baylor.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101213/becfd26c/attachment.pl>

From bbolker at gmail.com  Mon Dec 13 23:37:22 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 13 Dec 2010 17:37:22 -0500
Subject: [R-sig-ME] p values for balanced experimental designs in lme.
In-Reply-To: <DB0892FFCE97CA42BE2144E916EB43F22D557488F4@MAIL-IK.baylor.edu>
References: <DB0892FFCE97CA42BE2144E916EB43F22D557488F4@MAIL-IK.baylor.edu>
Message-ID: <4D06A022.2000506@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 10-12-13 05:18 PM, Taylor, Jason wrote:
> I am looking for some confirmation on the use of F statistics and P
> values in the anova(model) output for lme, specifically for balanced
> experimental designs.
> 
> Briefly, I will explain my experiment.
> 
> I have twelve experimental units that have each been assigned to one
> of three nutrient treatments. Within each experimental unit I have
> excluded grazers from half of the unit (Split plot). I sampled each
> unit on day 14 and day 28 of the experiment (Repeated measurement).
> 
> There are no missing data points so my data is balanced.
> 
> I am interested in the effects of Nutrients, Grazing and how they
> change with date.
> 
> I am using random effects in a mixed model to account for the
> grouping structure of the data.
> 
> lme (Response~Nut*Graz*Date,random=~1|Stream/Graz) or
> 
> lmer(Response~Nut*Graz*Date+(1|Stream)+(1|Stream:Graz))
> 
> So my question returns to the much asked F tests/P value debate.   I
> have read Pinheiro and Bates, Zuur et al., all the posts including D.
> Bates statement, the wiki, the Trends in Ecology and Evolution paper
> (Dr. Bolker).  If I understand everything I have read this is my
> conclusion:
> 
> Since my data is balanced, the null distribution of the computed
> ratio of sums of squares approaches an F distribution and F tests and
> associated P values should be reliable from anova(model) outputs for
> lme.  This appears to be correct in that I get similar (but not
> exactly the same) F values when I run lme, lmer or aov with
> Error(Stream/Graz).   Thus, I should be able to report a traditional
> anova table with DF, F and p values in my manuscript (which is what
> journals want in my field for simple experiments).
> 
> Are my conclusions correct?

  I think so.

  I'm not quite sure why you used 1|Stream/Graz in one case and
1|Stream:Graz in another -- I think they need not be exactly equivalent
(Stream/Graz is equivalent to Graz+Graz:Stream, I think, although I
always get the syntax backward), although in this case they may indeed
be equivalent.

> 
> One response to my question who suggested I send it along to the list
> serve is listed below.
> 
> 
>> I believe this isn't an issue for normally distributed data in the
>> case of balanced designs, or isn't much of an issue with normal
>> data and >reasonably large sample sizes. In those cases you can use
>> lme() which does report P values and which calculates DF as
>> indicated in P&B's book.
> 
>> But keep in mind that for unbalanced data you'll be getting
>> P-values from type I SS.
> 
> 
> 
>> To get type III SS you'd need to change the contrasts before
>> fitting your model with lme():
> 
>> options(list(contrasts=c(ordered="contr.treatment",unordered="contr.poly")))
>
>> 
> 
> 
>> And then:
> 
>> anova(model, type="m")
> 
> 
> 
>> BTW, an important reason to post to the list is so that others can
>> benefit from your questions. You may find it easier to get answers
>> posting to R->sig-eco for ecologically-oriented questions or
>> R-sig-ME for mixed-effect model-oriented questions ...
> 
> 
> 
> Best regards,
> 
> Jason
> 
> 
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iEYEARECAAYFAk0GoCIACgkQc5UpGjwzenPOMACgkzhVaEm9SumJ6/bup9LUkQYc
/ecAoJdMlhdyrBWcE5t7zSffllr3iERI
=mDRs
-----END PGP SIGNATURE-----



From calesso at fca.unl.edu.ar  Tue Dec 14 12:35:45 2010
From: calesso at fca.unl.edu.ar (Ing. Agr. =?ISO-8859-1?Q?Agust=EDn?= Alesso)
Date: Tue, 14 Dec 2010 08:35:45 -0300
Subject: [R-sig-ME] spatial correlation ANOVA-GLS
Message-ID: <1292326545.9268.12.camel@agustin-Studio14>

Hello,

I need some advice about how to include a spatial correlation structure
to an ANOVA-GLS one-way model. 

After fitting a simple model asuming uncorrelated errors and plotting a
variogram with its normalized residuals variogram the spatial
autocorrelation was evident (nuget 0,5 and range 600 m aprox).
So I tried to fit few models with predefined corStructures (lin, exp,
sph) without initial values for range and nugget and then looking at
their normalized residuals variograms. Although including correlation
results in smaller AICs, the variograms still showing strong spatial
correlation of normalized residuals.  

1) Could it be because of a poor estimation of corStructure? Indeed With
gstat package, the best model fitted has a nugget efect with to
spherical structures (2 ranges).

2) Is there a way to bluid a spatial correlation structure including two
ranges?

I'd appreciate some tip. Thanks.


-- 
Ing. Agr. Agust?n Alesso
Dpto. Ciencias del Ambiente
Fac. Cs. Agrarias - UNL
Kreder 2805 - S3080HOF - Esperanza
Tel: 03496-428575 int 337/256



From a.mosnier at gmail.com  Tue Dec 14 16:01:00 2010
From: a.mosnier at gmail.com (Arnaud Mosnier)
Date: Tue, 14 Dec 2010 10:01:00 -0500
Subject: [R-sig-ME] Spatial autocorrelation in dependent variable
Message-ID: <AANLkTim2nwJ5GJ1bWUqmwysH51vvy=gwwo_5Gz55FtYu@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101214/0609577a/attachment.pl>

From bbolker at gmail.com  Tue Dec 14 16:13:41 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 14 Dec 2010 10:13:41 -0500
Subject: [R-sig-ME] Spatial autocorrelation in dependent variable
In-Reply-To: <AANLkTim2nwJ5GJ1bWUqmwysH51vvy=gwwo_5Gz55FtYu@mail.gmail.com>
References: <AANLkTim2nwJ5GJ1bWUqmwysH51vvy=gwwo_5Gz55FtYu@mail.gmail.com>
Message-ID: <4D0789A5.4040705@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 10-12-14 10:01 AM, Arnaud Mosnier wrote:
> Dear list,
> 
> I am searching a method to include spatial autocorrelation structure of my
> dependent variable into a mixed model.
> Any suggestions would be much appreciated ?
> 

  see the 'correlation' argument of ?lme in the nlme package.
Furthermore, see ?corSpatial (and the appropriate chapter of Pinheiro
and Bates 2000)

  Ben Bolker
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iEYEARECAAYFAk0HiaUACgkQc5UpGjwzenMB5QCeMFkKEtlm40idYcH+jOPpOyQn
/fIAnjNq2IeaqYke/xjfWaLtPRYv/9/U
=okbF
-----END PGP SIGNATURE-----



From a.mosnier at gmail.com  Wed Dec 15 15:59:11 2010
From: a.mosnier at gmail.com (Arnaud Mosnier)
Date: Wed, 15 Dec 2010 09:59:11 -0500
Subject: [R-sig-ME] Spatial autocorrelation in dependent variable
In-Reply-To: <AANLkTim2nwJ5GJ1bWUqmwysH51vvy=gwwo_5Gz55FtYu@mail.gmail.com>
References: <AANLkTim2nwJ5GJ1bWUqmwysH51vvy=gwwo_5Gz55FtYu@mail.gmail.com>
Message-ID: <AANLkTimRqVj8Lu2TF9_nE8V_N9E0_giK5=qd7xQhgfDx@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101215/c5a71457/attachment.pl>

From bbolker at gmail.com  Wed Dec 15 16:09:43 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 15 Dec 2010 10:09:43 -0500
Subject: [R-sig-ME] Spatial autocorrelation in dependent variable
In-Reply-To: <AANLkTimRqVj8Lu2TF9_nE8V_N9E0_giK5=qd7xQhgfDx@mail.gmail.com>
References: <AANLkTim2nwJ5GJ1bWUqmwysH51vvy=gwwo_5Gz55FtYu@mail.gmail.com>
	<AANLkTimRqVj8Lu2TF9_nE8V_N9E0_giK5=qd7xQhgfDx@mail.gmail.com>
Message-ID: <4D08DA37.2090407@gmail.com>

On 10-12-15 09:59 AM, Arnaud Mosnier wrote:

> *However, when I define the correlation structure with a function like
> corGaus, things start correctly, but after a moment, R simply close
> without any warning on my desktop computer.
> I used the same code on a workstation with larger RAM capacities and
> Rx64 and this time it did not close but gave me the following message.
> "Error: evaluation nested too deeply: infinite recursion /
> options(expressions=)?"
> 
> Looking at previous mails dealing with that kind of problem, I tried
> options(expressions = 10000), but this time R close without warning as
> previously on the other computer.
> Have you suggestions about what could cause the infinite recursion ?
> 
> my model has the following form
> 
> test_lme <- lme(Dens ~ Speed , random = ~ 1|Year/Date/Survey, data =
> test, correlation = corGaus(form = ~ Xproj + Yproj))
> 
>>str(test)
> 
> 'data.frame':   54445 obs. of  7 variables:
>  $ Xprojc: num  -1.91 -1.91 -1.91 -1.91 -1.91 ...
>  $ Yprojc: num  -1.99 -1.96 -1.93 -1.9 -1.87 ...
>  $ Year  : Factor w/ 11 levels "1990","1992",..: 1 1 1 1 1 1 1 1 1 1 ...
>  $ Date  : Factor w/ 34 levels "1990-09-12","1992-09-12",..: 1 1 1 1 1 1
> 1 1 1 1 ...
>  $ Survey: Factor w/ 37 levels "pts_kernP1990-09-12_Real",..: 1 1 1 1 1
> 1 1 1 1 1 ...
>  $ Dens  : num  4.72e-05 8.27e-04 4.65e-03 8.70e-03 5.65e-03 ...
>  $ Speed : num  0.794 0.575 0.572 0.67 0.867 ...

  The only thing that springs to mind is that you are using Xproj and
Yproj in your correlation formula, but you have Xprojc and Yprojc
(presumably centered versions of the same variables) in your data frame?



From gcsadoti at yahoo.com  Thu Dec 16 06:50:32 2010
From: gcsadoti at yahoo.com (Giancarlo Sadoti)
Date: Wed, 15 Dec 2010 21:50:32 -0800 (PST)
Subject: [R-sig-ME] time-series analysis: how to deal with 'nuisance'
	factors influencing a trend?
Message-ID: <332178.30709.qm@web120511.mail.ne1.yahoo.com>

Greetings list,

I'm examining longitudinal data of counts [COUNT] of a species across three years [YEAR] and across 40 sites [SITE].  My primary interest is in the coefficient of YEAR to determine if there is a trend across the three years.  Counts fit a poisson distribution.  I can't cite this, but it is my understanding that three years is inadequate for the inclusion of a temporal correlation structure, so I am not including it.  Thus, my basic model is:

lmer(COUNT~YEAR+(1|SITE),family=poisson,data=data)

However, based on exploratory analysis, it appears the per-site trend is correlated with the general size of the per-site population such that smaller populations tend to decline while larger populations tend to increase.  Because, again, my main interest is in the trend (more-or-less) independent of population size, I would consider this 'nuisance variance'.  Unfortunately, I'm not sure where to account for this variance in a mixed model.

Without any clear way (to me) to treat this as a random effect*, I'm considering adding a YEAR:MEAN_COUNT (interaction) fixed effect (where MEAN_COUNT = the average count across the three site visits [within each site]).  This model would appear as:

lmer(COUNT~YEAR+YEAR:MEAN_COUNT+(1|SITE),family=poisson, data=data)

If the resulting 95% CIs of the YEAR effect do not include zero (after accounting for the YEAR:MEAN_COUNT interaction), I would conclude that there is a trend in the counts across the three years, while a significant YEAR:MEAN_COUNT term would indicate a relationship (as expected) between trend and population size.

Does this sound reasonable, or can anyone offer any suggestions?

Many thanks,

Giancarlo

*Including MEAN_COUNT per site as a random effect (1|MEAN_COUNT) explains the same variance as (1|SITE) while neither (YEAR|SITE) or (YEAR|MEAN_COUNT) (correlated random coefficients) nor (1|SITE)+(0+YEAR|SITE) (uncorrelated random coefficient/intercept) seem to address the issue.



From davidD at qimr.edu.au  Thu Dec 16 07:44:41 2010
From: davidD at qimr.edu.au (David Duffy)
Date: Thu, 16 Dec 2010 16:44:41 +1000 (EST)
Subject: [R-sig-ME] time-series analysis: how to deal with
	'nuisance'factors influencing a trend?
In-Reply-To: <332178.30709.qm@web120511.mail.ne1.yahoo.com>
References: <332178.30709.qm@web120511.mail.ne1.yahoo.com>
Message-ID: <Pine.LNX.4.64.1012161638420.25534@orpheus.qimr.edu.au>

On Wed, 15 Dec 2010, Giancarlo Sadoti wrote:

> I'm examining longitudinal data of counts [COUNT] of a species across 
> three years [YEAR] and across 40 sites [SITE].  My primary interest is 
> in the coefficient of YEAR to determine if there is a trend across the 
> three years.  Counts fit a poisson distribution.  I can't cite this, but 
> it is my understanding that three years is inadequate for the inclusion 
> of a temporal correlation structure, so I am not including it.

As I understand it, 3 years is not enough data to _differentiate_ between 
an autoregressive model with innovations, and a "general" correlation 
model.  You can definitely include YEAR random effects and either model 
will fit equally well, and may or may not be a significant improvement on 
your original model.

Cheers, David Duffy.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From gcsadoti at yahoo.com  Thu Dec 16 08:22:23 2010
From: gcsadoti at yahoo.com (Giancarlo Sadoti)
Date: Wed, 15 Dec 2010 23:22:23 -0800 (PST)
Subject: [R-sig-ME] time-series analysis: how to deal with 'nuisance'
	factors influencing a trend?
In-Reply-To: <Pine.LNX.4.64.1012161638420.25534@orpheus.qimr.edu.au>
Message-ID: <732325.86101.qm@web120509.mail.ne1.yahoo.com>

Thank you David. 

I meant to say "three years is inadequate for the inclusion of an autoregressive or moving-average structure".  Thank you for confirming this. 

My central question relates to the apparent and confounding influence of another characteristic of each site (in this case the mean # of individuals) on the "trend" fixed effect (in this case the change in per-site # of individuals across the three years).  How is the best way to 'control' for this influence in a mixed model in order to get to the 'true' trend?

Thanks for any additional insights.

Giancarlo



--- On Wed, 12/15/10, David Duffy <davidD at qimr.edu.au> wrote:

> From: David Duffy <davidD at qimr.edu.au>
> Subject: Re: [R-sig-ME] time-series analysis: how to deal with 'nuisance'factors influencing a trend?
> To: "Giancarlo Sadoti" <gcsadoti at yahoo.com>
> Cc: r-sig-mixed-models at r-project.org
> Date: Wednesday, December 15, 2010, 11:44 PM
> On Wed, 15 Dec 2010, Giancarlo Sadoti
> wrote:
> 
> > I'm examining longitudinal data of counts [COUNT] of a
> species across three years [YEAR] and across 40 sites
> [SITE].? My primary interest is in the coefficient of
> YEAR to determine if there is a trend across the three
> years.? Counts fit a poisson distribution.? I
> can't cite this, but it is my understanding that three years
> is inadequate for the inclusion of a temporal correlation
> structure, so I am not including it.
> 
> As I understand it, 3 years is not enough data to
> _differentiate_ between an autoregressive model with
> innovations, and a "general" correlation model.? You
> can definitely include YEAR random effects and either model
> will fit equally well, and may or may not be a significant
> improvement on your original model.
> 
> Cheers, David Duffy.
> 
> -- | David Duffy (MBBS PhD)? ? ? ?
> ? ? ? ? ? ? ? ?
> ? ? ? ? ? ? ?
> ???,-_|\
> | email: davidD at qimr.edu.au?
> ph: INT+61+7+3362-0217 fax: -0101? /?
> ???*
> | Epidemiology Unit, Queensland Institute of Medical
> Research???\_,-._/
> | 300 Herston Rd, Brisbane, Queensland 4029,
> Australia? GPG 4D0B994A v
> 






From bates at stat.wisc.edu  Thu Dec 16 13:55:52 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 16 Dec 2010 06:55:52 -0600
Subject: [R-sig-ME] Problem with lmer crashing on x64 server
In-Reply-To: <-8144796767581659265@unknownmsgid>
References: <-8144796767581659265@unknownmsgid>
Message-ID: <AANLkTik3rSceEDyRBsRnzRfdxi6d4ucSS2fTLRuffqht@mail.gmail.com>

Sorry for the delayed response (end of semester and all that).  You
must bear in mind that you are estimating many variance-covariance
parameters (at least 21 and perhaps more if cohort90 is a factor).  It
is quite likely that the estimates are converging to a singular
variance-covariance matrix and the estimates are not meaningful in
either case.

On Wed, Nov 17, 2010 at 5:21 AM, Camille Szmaragd
<Camille.Szmaragd at bristol.ac.uk> wrote:
> Dear all,
>
> I am fitting a fairly simple 2 levels hierarchical ?normal model with random
> slopes:
>
>
>
> lmer(score ~ cohort90 + female + sclassf + (1 + cohort90 + sclassf |
> schoolid), data = mydata, REML = FALSE), with sclassf being a 4 category
> factor.
>
>
>
> I can fit this model without a problem on a Windows Desktop (and R 2.11.0)
> and get sensible parameter estimates, matching the estimates obtained with
> other software packages.

>
>
> However when I tried to fit the same model on a 64 bit server, running R
> x64 2.12.0 (and the latest update of lme4), I get the following error
> message at the end of the model output:
>
>
>
> #####
>
> Warning message:
>
> In mer_finalize(ans) : iteration limit reached without convergence (9)
>
> #####
>
>
>
> I appreciate if anybody has a suggestion/idea as to why this is happening.
>
>
>
> ?Many thanks in advance
>
>
>
> Camille
>
>
>
>
>
>
>
>
>
> ****---Save Paper - Do you need to print this message?---****
>
>
>
> ?Dr Camille Szmaragd
>
> ?Research Associate
>
> ?School of Veterinary Science
>
> ?University of Bristol
>
> ?Langford BS40 5DU
>
>
>
> ?Camille.Szmaragd at bristol.ac.uk
>
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From a.mosnier at gmail.com  Thu Dec 16 18:35:23 2010
From: a.mosnier at gmail.com (Arnaud Mosnier)
Date: Thu, 16 Dec 2010 12:35:23 -0500
Subject: [R-sig-ME] Spatial autocorrelation in dependent variable
In-Reply-To: <AANLkTimRqVj8Lu2TF9_nE8V_N9E0_giK5=qd7xQhgfDx@mail.gmail.com>
References: <AANLkTim2nwJ5GJ1bWUqmwysH51vvy=gwwo_5Gz55FtYu@mail.gmail.com>
	<AANLkTimRqVj8Lu2TF9_nE8V_N9E0_giK5=qd7xQhgfDx@mail.gmail.com>
Message-ID: <AANLkTikxPdAuy58R7PzaQFgjxMz8MKKLBmAKJ1EaVQav@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101216/65e848a4/attachment.pl>

From billy.requena at gmail.com  Fri Dec 17 22:59:51 2010
From: billy.requena at gmail.com (Billy)
Date: Fri, 17 Dec 2010 15:59:51 -0600
Subject: [R-sig-ME] Fwd: Could the random effect at the level of each
 observation be a trap?
In-Reply-To: <AANLkTikT=krJ5Jnz+wkyoFOv2DhvwEj_h4UQNYOc8xLm@mail.gmail.com>
References: <AANLkTi=155JVhNP3L7U-MBwUqKzwxwtsWL10Lgo13yo1@mail.gmail.com>
	<4D03C2AC.7050503@gmail.com>
	<AANLkTi==obqdyEUK8yhWhe4Pz0m=ZmRe4j7VmFBRn93C@mail.gmail.com>
	<AANLkTikLO=E_tscuww0H+xwzUaC62AzSc3cb_xVM7PLh@mail.gmail.com>
	<AANLkTinS3HjDcaRTnKwJeKy8P1fkQotG7P0frEHE5h+L@mail.gmail.com>
	<AANLkTi=mSyTdkr3NRhX6kdTxZbD8Hvu7Y+UN1m+VcraY@mail.gmail.com>
	<AANLkTi=mRbxJoDPRfFAJg4xdF5MjPnm0o8+gwOK4LfOP@mail.gmail.com>
	<AANLkTinTuTHTSuJQ+j12mPAp7dUBs=487WDbkpWBBNgw@mail.gmail.com>
	<AANLkTikT=krJ5Jnz+wkyoFOv2DhvwEj_h4UQNYOc8xLm@mail.gmail.com>
Message-ID: <AANLkTimQ+=a82G5CbBDPLPctB_HrZbfLLijMtZc348mD@mail.gmail.com>

---------- Forwarded message ----------
From: Billy <billy.requena at gmail.com>
Date: Fri, Dec 17, 2010 at 3:57 PM
Subject: Re: [R-sig-ME] Could the random effect at the level of each
observation be a trap?
To: Drew Tyre <atyre2 at unl.edu>


Hi Drew!

Well, below I'm sending the summary of two corresponding models (just
for simplicity, because I have at least 5 models including onlye the
'MaleID' random effect and other 5 including 'MaleID' + 'resid'
randiom effects):

m1 <- glmer (y~ x + (1|MaleID), family=binomial)
m1.1 <- glmer (y~ x + (1|MaleID) + (1|resid), family=binomial)

> summary(m1)
Generalized linear mixed model fit by the Laplace approximation
Formula: y ~ x + (1 | MaleID)
?AIC ?BIC logLik deviance
?1012 1027 -502.9 ? ? 1006
Random effects:
?Groups Name ? ? ? ?Variance ? Std.Dev.
?MaleID (Intercept) 6.9038e-11 8.309e-06
Number of obs: 1045, groups: MaleID, 464

Fixed effects:
? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
(Intercept) ? -8.273 ? ? ?2.036 ?-4.063 4.84e-05 ***
x ? ? ? ? ? ? ? ? ? 1.192 ? ? ?0.354 ? 3.366 0.000762 ***
---
Signif. codes: ?0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
? (Intr)
x ?-0.999

> summary(m1.1)
Generalized linear mixed model fit by the Laplace approximation
Formula: y~ x + (1 | MaleID) + (1 | resid)
? AIC ? BIC logLik deviance
?619.4 639.2 -305.7 ? ?611.4
Random effects:
?Groups Name ? ? ? ?Variance Std.Dev.
?resid ?(Intercept) 2089.1 ? 45.707
?MaleID (Intercept) ? ?0.0 ? ?0.000
Number of obs: 1045, groups: resid, 1045; MaleID, 464

Fixed effects:
? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
(Intercept) ?-19.049 ? ? 85.552 ?-0.223 ? ?0.824
x ? ? ? ? ? ? ? ? ? ?1.281 ? ? 14.844 ? 0.086 ? ?0.931

Correlation of Fixed Effects:
? (Intr)
x ?-0.999


We can see that the variance associated to the 'resid' random variable
is really huge, but I don't really know if that's a problem or it's
just expected due the nature of this individual observation-based
variable.
Furthermore, the correlation between fixed effects seems pretty
strong, but again I don't know if it's a problem.
Does anyone have an insight to help me?

Thanks again

Billy


--
Gustavo Requena
PhD student - Laboratory of Arthropod Behavior and Evolution
Universidade de S?o Paulo
Correspondence adress:
a/c Glauco Machado
Departamento de Ecologia - IBUSP
Rua do Mat?o - Travessa 14 no 321 Cidade Universit?ria, S?o Paulo - SP, Brasil
CEP 05508-900
Phone number: 55 11 3091-7488

http://ecologia.ib.usp.br/opilio/gustavo.html



-- 
Gustavo Requena
PhD student - Laboratory of Arthropod Behavior and Evolution
Universidade de S?o Paulo
Correspondence adress:
a/c Glauco Machado
Departamento de Ecologia - IBUSP
Rua do Mat?o - Travessa 14 no 321 Cidade Universit?ria, S?o Paulo - SP, Brasil
CEP 05508-900
Phone number: 55 11 3091-7488

http://ecologia.ib.usp.br/opilio/gustavo.html



From j.hadfield at ed.ac.uk  Sat Dec 18 13:32:20 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 18 Dec 2010 12:32:20 +0000
Subject: [R-sig-ME] Fwd: Could the random effect at the level of each
 observation be a trap?
In-Reply-To: <AANLkTimQ+=a82G5CbBDPLPctB_HrZbfLLijMtZc348mD@mail.gmail.com>
References: <AANLkTi=155JVhNP3L7U-MBwUqKzwxwtsWL10Lgo13yo1@mail.gmail.com>
	<4D03C2AC.7050503@gmail.com>
	<AANLkTi==obqdyEUK8yhWhe4Pz0m=ZmRe4j7VmFBRn93C@mail.gmail.com>
	<AANLkTikLO=E_tscuww0H+xwzUaC62AzSc3cb_xVM7PLh@mail.gmail.com>
	<AANLkTinS3HjDcaRTnKwJeKy8P1fkQotG7P0frEHE5h+L@mail.gmail.com>
	<AANLkTi=mSyTdkr3NRhX6kdTxZbD8Hvu7Y+UN1m+VcraY@mail.gmail.com>
	<AANLkTi=mRbxJoDPRfFAJg4xdF5MjPnm0o8+gwOK4LfOP@mail.gmail.com>
	<AANLkTinTuTHTSuJQ+j12mPAp7dUBs=487WDbkpWBBNgw@mail.gmail.com>
	<AANLkTikT=krJ5Jnz+wkyoFOv2DhvwEj_h4UQNYOc8xLm@mail.gmail.com>
	<AANLkTimQ+=a82G5CbBDPLPctB_HrZbfLLijMtZc348mD@mail.gmail.com>
Message-ID: <20101218123220.12125pg8co4nc7wg@www.staffmail.ed.ac.uk>

Hi Billy,

As Drew mentioned, if the data are binary then over-dispersion does  
not exist. There may well be heterogeneity at the observation-level  
not accounted for by the fixed/random effects, but the data would look  
the same irrespective of the magnitude of this heterogeneity. Because  
this "residual" variation cannot be estimated it is usual to set it to  
zero (i.e omit 1|resid).

The sampling correlation between the x coefficient and the intercept  
is not a problem. For example you could center x,  and the correlation  
should be close to zero.

Cheers,

Jarrod




Quoting Billy <billy.requena at gmail.com>:

> ---------- Forwarded message ----------
> From: Billy <billy.requena at gmail.com>
> Date: Fri, Dec 17, 2010 at 3:57 PM
> Subject: Re: [R-sig-ME] Could the random effect at the level of each
> observation be a trap?
> To: Drew Tyre <atyre2 at unl.edu>
>
>
> Hi Drew!
>
> Well, below I'm sending the summary of two corresponding models (just
> for simplicity, because I have at least 5 models including onlye the
> 'MaleID' random effect and other 5 including 'MaleID' + 'resid'
> randiom effects):
>
> m1 <- glmer (y~ x + (1|MaleID), family=binomial)
> m1.1 <- glmer (y~ x + (1|MaleID) + (1|resid), family=binomial)
>
>> summary(m1)
> Generalized linear mixed model fit by the Laplace approximation
> Formula: y ~ x + (1 | MaleID)
> ?AIC ?BIC logLik deviance
> ?1012 1027 -502.9 ? ? 1006
> Random effects:
> ?Groups Name ? ? ? ?Variance ? Std.Dev.
> ?MaleID (Intercept) 6.9038e-11 8.309e-06
> Number of obs: 1045, groups: MaleID, 464
>
> Fixed effects:
> ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
> (Intercept) ? -8.273 ? ? ?2.036 ?-4.063 4.84e-05 ***
> x ? ? ? ? ? ? ? ? ? 1.192 ? ? ?0.354 ? 3.366 0.000762 ***
> ---
> Signif. codes: ?0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
> ? (Intr)
> x ?-0.999
>
>> summary(m1.1)
> Generalized linear mixed model fit by the Laplace approximation
> Formula: y~ x + (1 | MaleID) + (1 | resid)
> ? AIC ? BIC logLik deviance
> ?619.4 639.2 -305.7 ? ?611.4
> Random effects:
> ?Groups Name ? ? ? ?Variance Std.Dev.
> ?resid ?(Intercept) 2089.1 ? 45.707
> ?MaleID (Intercept) ? ?0.0 ? ?0.000
> Number of obs: 1045, groups: resid, 1045; MaleID, 464
>
> Fixed effects:
> ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
> (Intercept) ?-19.049 ? ? 85.552 ?-0.223 ? ?0.824
> x ? ? ? ? ? ? ? ? ? ?1.281 ? ? 14.844 ? 0.086 ? ?0.931
>
> Correlation of Fixed Effects:
> ? (Intr)
> x ?-0.999
>
>
> We can see that the variance associated to the 'resid' random variable
> is really huge, but I don't really know if that's a problem or it's
> just expected due the nature of this individual observation-based
> variable.
> Furthermore, the correlation between fixed effects seems pretty
> strong, but again I don't know if it's a problem.
> Does anyone have an insight to help me?
>
> Thanks again
>
> Billy
>
>
> --
> Gustavo Requena
> PhD student - Laboratory of Arthropod Behavior and Evolution
> Universidade de S?o Paulo
> Correspondence adress:
> a/c Glauco Machado
> Departamento de Ecologia - IBUSP
> Rua do Mat?o - Travessa 14 no 321 Cidade Universit?ria, S?o Paulo -  
> SP, Brasil
> CEP 05508-900
> Phone number: 55 11 3091-7488
>
> http://ecologia.ib.usp.br/opilio/gustavo.html
>
>
>
> --
> Gustavo Requena
> PhD student - Laboratory of Arthropod Behavior and Evolution
> Universidade de S?o Paulo
> Correspondence adress:
> a/c Glauco Machado
> Departamento de Ecologia - IBUSP
> Rua do Mat?o - Travessa 14 no 321 Cidade Universit?ria, S?o Paulo -  
> SP, Brasil
> CEP 05508-900
> Phone number: 55 11 3091-7488
>
> http://ecologia.ib.usp.br/opilio/gustavo.html
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From jude.phillips at gmail.com  Sun Dec 19 18:26:17 2010
From: jude.phillips at gmail.com (Jude Phillips)
Date: Sun, 19 Dec 2010 12:26:17 -0500
Subject: [R-sig-ME] different AIC value from anova() and AIC() for lm
Message-ID: <AANLkTinWFDzg63SCG_zuC=HheT8ukOCj32rMUJGB9E0B@mail.gmail.com>

Hi,

I'm trying to compare models with same fixed effects but different
random effects, but I've noticed that for lm models, I get a different
AIC value when I compare models with anova, compared to when I just
use the AIC command to calculate AIC.  I've put an example below using
the Orthodont data.  I'm worried about his because an editor has asked
me to use AICc rather than AIC to compare models.  My plan was to use
the AICc command in the AICcmodavg package, to calculate AICc for each
model and compare them manually, but now I'm not sure this will work.

I'd appreciate any thoughts on this!

Thanks, Jude Girard
PhD candidate
GLEL, Carleton University.


>fm2Orth.lme <- lme(fixed = distance~Sex*I(age-11), random=~I(age-11)|Subject, data=Orthodont)
>fm4Orth.lm <- lm( distance ~ Sex * I(age-11), Orthodont )
>anova( fm2Orth.lme, fm4Orth.lm )

           Model df      AIC      BIC    logLik   Test  L.Ratio p-value
fm2Orth.lme     1  8 448.5817 469.7368 -216.2908
fm4Orth.lm       2  5 493.5591 506.7811 -241.7796 1 vs 2 50.97746  <.0001

> AIC(fm2Orth.lme, fm4Orth.lm)
                  df      AIC
fm2Orth.lme  8 448.5817
fm4Orth.lm    5 488.2418



From bbolker at gmail.com  Sun Dec 19 19:54:19 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 19 Dec 2010 13:54:19 -0500
Subject: [R-sig-ME] different AIC value from anova() and AIC() for lm
In-Reply-To: <AANLkTinWFDzg63SCG_zuC=HheT8ukOCj32rMUJGB9E0B@mail.gmail.com>
References: <AANLkTinWFDzg63SCG_zuC=HheT8ukOCj32rMUJGB9E0B@mail.gmail.com>
Message-ID: <4D0E54DB.5010203@gmail.com>

On 10-12-19 12:26 PM, Jude Phillips wrote:
> Hi,
> 
> I'm trying to compare models with same fixed effects but different
> random effects, but I've noticed that for lm models, I get a different
> AIC value when I compare models with anova, compared to when I just
> use the AIC command to calculate AIC.  I've put an example below using
> the Orthodont data.  I'm worried about his because an editor has asked
> me to use AICc rather than AIC to compare models.  My plan was to use
> the AICc command in the AICcmodavg package, to calculate AICc for each
> model and compare them manually, but now I'm not sure this will work.
> 
  It looks like the difference is due to the REML condition:

AIC(fm4Orth.lm)
AIC(logLik(fm4Orth.lm,REML=TRUE))

  I figured this out by a combination of:

trace(anova,browser)
anova.lme
debug(anova.lme)

 etc.



> Thanks, Jude Girard
> PhD candidate
> GLEL, Carleton University.
> 
> 
>> fm2Orth.lme <- lme(fixed = distance~Sex*I(age-11), random=~I(age-11)|Subject, data=Orthodont)
>> fm4Orth.lm <- lm( distance ~ Sex * I(age-11), Orthodont )
>> anova( fm2Orth.lme, fm4Orth.lm )
> 
>            Model df      AIC      BIC    logLik   Test  L.Ratio p-value
> fm2Orth.lme     1  8 448.5817 469.7368 -216.2908
> fm4Orth.lm       2  5 493.5591 506.7811 -241.7796 1 vs 2 50.97746  <.0001
> 
>> AIC(fm2Orth.lme, fm4Orth.lm)
>                   df      AIC
> fm2Orth.lme  8 448.5817
> fm4Orth.lm    5 488.2418
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From davidD at qimr.edu.au  Mon Dec 20 04:55:23 2010
From: davidD at qimr.edu.au (David Duffy)
Date: Mon, 20 Dec 2010 13:55:23 +1000 (EST)
Subject: [R-sig-ME] time-series analysis: how to deal with
	'nuisance'factors influencing a trend?
In-Reply-To: <732325.86101.qm@web120509.mail.ne1.yahoo.com>
References: <732325.86101.qm@web120509.mail.ne1.yahoo.com>
Message-ID: <Pine.LNX.4.64.1012201350250.25794@orpheus.qimr.edu.au>

On Wed, 15 Dec 2010, Giancarlo Sadoti wrote:

> My central question relates to the apparent and confounding influence of 
> another characteristic of each site (in this case the mean # of 
> individuals) on the "trend" fixed effect (in this case the change in 
> per-site # of individuals across the three years).  How is the best way 
> to 'control' for this influence in a mixed model in order to get to the 
> 'true' trend?

Your lmer(COUNT~YEAR+YEAR:MEAN_COUNT+(1|SITE),family=poisson, data=data)
is probably how I would do it, given you say diagnostics suggest a 
Poisson model for the counts was OK.  I would look to biology re 
alternative models: the generation time for your 
species is longer than YEAR? you expect larger populations to be more 
viable?

Cheers, David.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From myaseen208 at gmail.com  Mon Dec 20 15:07:01 2010
From: myaseen208 at gmail.com (Muhammad Yaseen)
Date: Mon, 20 Dec 2010 06:07:01 -0800
Subject: [R-sig-ME] Defining Two-dimensional Separable
 Variance-Covariance Structure in nlme Package
Message-ID: <AANLkTi=+E2B+bbvtsirCSLUmogc0ix2JpeGzmSvtPzzw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101220/c09a2923/attachment.pl>

From marie_helene48 at hotmail.com  Mon Dec 20 15:55:59 2010
From: marie_helene48 at hotmail.com (=?iso-8859-1?B?TWFyaWUtSOls6G5lIEhhY2hleQ==?=)
Date: Mon, 20 Dec 2010 14:55:59 +0000
Subject: [R-sig-ME] (no subject)
Message-ID: <SNT131-w36415687676905A864942FE1190@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101220/1f7499e9/attachment.pl>

From marie_helene48 at hotmail.com  Mon Dec 20 16:09:51 2010
From: marie_helene48 at hotmail.com (=?iso-8859-1?B?TWFyaWUtSOls6G5lIEhhY2hleQ==?=)
Date: Mon, 20 Dec 2010 15:09:51 +0000
Subject: [R-sig-ME] Singular convergence in lmer
Message-ID: <SNT131-w434EF557EA2B6546C152D4E1190@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101220/9e5e2fde/attachment.pl>

From lborger at cebc.cnrs.fr  Mon Dec 20 16:13:46 2010
From: lborger at cebc.cnrs.fr (Luca Borger)
Date: Mon, 20 Dec 2010 16:13:46 +0100
Subject: [R-sig-ME] (no subject)
In-Reply-To: <SNT131-w36415687676905A864942FE1190@phx.gbl>
References: <SNT131-w36415687676905A864942FE1190@phx.gbl>
Message-ID: <4D0F72AA.5080901@cebc.cnrs.fr>

Hello,

you should first search the archives, very often  similar questions have 
been asked in the past. E.g. see :

http://www.mail-archive.com/r-help at r-project.org/msg80092.html


 >I noticed that it appears most of the time when I try to include the 
(temperature^2).

Do you have enough data to estimate a quadratic effect?


HTH,

Cheers,

Luca


-------------------------------------------
Luca Borger
Postdoctoral Research Fellow
CNRS - Centre d'Etudes Biologiques de Chiz?
Villiers-en-Bois
79360 Beauvoir-sur-Niort
France

Tel: +33 (0)549 09 96 13
Fax: +33 (0)549 09 65 26

email: lborger at cebc.cnrs.fr
http://www.researcherid.com/rid/C-6003-2008
-------------------------------------------


Le 20/12/2010 15:55, Marie-H?l?ne Hachey a ?crit :
> Hi, I am running a model with lmer and I had this message from R (2.12)
>> Model<-lmer(freq ~ ln_age_rel + ppt_vis + gps_dec + tempsq + (1|espece/nestid), family=poisson)Messages d'avis :1: In mer_finalize(ans) :  Cholmod warning 'not positive definite' at file:../Cholesky/t_cholmod_rowfac.c, line 4322: In mer_finalize(ans) :  Cholmod warning 'not positive definite' at file:../Cholesky/t_cholmod_rowfac.c, line 4323: In mer_finalize(ans) : singular convergence (7)>  summary (Model)Erreur dans asMethod(object) : matrix is not symmetric [1,2]
> Can anyone give me a clue about what the message means?>  I noticed that it appears most of the time when I try to include the (temperature^2).
> Thank you
> Marie-Helene 		 	   		
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> __________ Information from ESET Mail Security, version of virus signature database 5718 (20101220) __________
>
> The message was checked by ESET Mail Security.
> http://www.eset.com
>
>
>
>
>



__________ Information from ESET Mail Security, version of virus signature database 5718 (20101220) __________

The message was checked by ESET Mail Security.
http://www.eset.com



From bbolker at gmail.com  Mon Dec 20 20:50:01 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 20 Dec 2010 14:50:01 -0500
Subject: [R-sig-ME] Singular convergence in lmer
In-Reply-To: <SNT131-w434EF557EA2B6546C152D4E1190@phx.gbl>
References: <SNT131-w434EF557EA2B6546C152D4E1190@phx.gbl>
Message-ID: <4D0FB369.5050902@gmail.com>

On 10-12-20 10:09 AM, Marie-H?l?ne Hachey wrote:
> 
> Hi, Sorry I forgot to put a subjet on my last message. I also should
> have added that my dataset has only 49 lines. I am starting to
> understand by reading messages from R-help that the singular
> convergence is a problem aboutthe number of lines of data not being
> enough to estimate effects of many variables? Thank you for
> confirming this! Marie-Helene

  Yes.  The rule of thumb (see e.g. Frank Harrell's book) is that you
should have at least 10-20 data points per parameter you want to
estimate, and that's a best case scenario for continuously distributed
data -- for example, if your Poisson data are fairly sparse they count
for less.



From datkins at u.washington.edu  Mon Dec 20 23:20:35 2010
From: datkins at u.washington.edu (David Atkins)
Date: Mon, 20 Dec 2010 14:20:35 -0800
Subject: [R-sig-ME] Does MCMCglmm allow offset?
Message-ID: <4D0FD6B3.2070300@u.washington.edu>


Hi all--

I am wondering whether MCMCglmm will take an offset?  Specifically, we 
have a study with number of drinks as the outcome, but we also have an 
estimate of over how many hours those drinks were consumed.  Thus, might 
make sense to model it as a rate of drinks per hour.

As far as I can tell, glmer does allow an offset, but it seems like 
maybe MCMCglmm does not.  A search of MCMCglmm's course notes and JSS 
paper does not turn up any discussion.

Below is a real dataset, with a "toy" offset term that would seem to 
support this.

Any input appreciated.

cheers, Dave

[sessionInfo() at very end]

### MCMCglmm and offset
#
### read data
rapi.df <- 
read.csv("http://depts.washington.edu/cshrb/newweb/stats%20documents/RAPI.Final.csv")
head(rapi.df)

### "rapi" is the rutgers alcohol problems index and was measured
### over previous 30 days -- thus, constant exposure, but we can still
### use it as toy example
#
### over-dispersion term
rapi.df$over <- 1:nrow(rapi.df)

### make up "offset" term
rapi.df$off30 <- rpois(n = nrow(rapi.df), lambda = 30)

### GLM (no random-effects) just as baseline comparator
glm.nooff <- glm(rapi ~ gender*time,
						data = rapi.df, family = "poisson")
glm.off <- glm(rapi ~ gender*time + offset(log(off30)),
						data = rapi.df, family = "poisson")
summary(glm.nooff)						
summary(glm.off)						

### over-dispersed Poisson GLMM in glmer
library(lme4)

### without offset
glmer.nooff <- glmer(rapi ~ gender*time + (time | id) + (1 | over),
						data = rapi.df, verbose = TRUE, family = "poisson")

### with offset
glmer.off <- glmer(rapi ~ gender*time + offset(log(off30)) + (time | id) 
+ (1 | over),
						data = rapi.df, verbose = TRUE, family = "poisson")
print(glmer.nooff, corr = FALSE)	
print(glmer.off, corr = FALSE)	

### same models using MCMCglmm
library(MCMCglmm)

mcmc.nooff <- MCMCglmm(rapi ~ gender*time, data = rapi.df,
								family = "poisson", verbose = TRUE,
								random = ~ us(1 + time):id)
mcmc.off <- MCMCglmm(rapi ~ gender*time + offset(log(off30)), data = 
rapi.df,
								family = "poisson", verbose = TRUE,
								random = ~ us(1 + time):id)
summary(mcmc.nooff)					
summary(mcmc.off)	


 > sessionInfo()
R version 2.12.1 (2010-12-16)
Platform: i386-apple-darwin9.8.0/i386 (32-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods
[7] base

other attached packages:
[1] MCMCglmm_2.10      corpcor_1.5.7      ape_2.6-2
[4] coda_0.14-2        tensorA_0.36       lme4_0.999375-37
[7] Matrix_0.999375-47 lattice_0.19-16

loaded via a namespace (and not attached):
[1] gee_4.13-16   grid_2.12.1   nlme_3.1-97   stats4_2.12.1
[5] tools_2.12.1

-- 
Dave Atkins, PhD
Research Associate Professor
Department of Psychiatry and Behavioral Science
University of Washington
datkins at u.washington.edu

Center for the Study of Health and Risk Behaviors (CSHRB)		
1100 NE 45th Street, Suite 300 	
Seattle, WA  98105 	
206-616-3879 	
http://depts.washington.edu/cshrb/
(Mon-Wed)	

Center for Healthcare Improvement, for Addictions, Mental Illness,
   Medically Vulnerable Populations (CHAMMP)
325 9th Avenue, 2HH-15
Box 359911
Seattle, WA 98104
http://www.chammp.org
(Thurs)



From calesso at fca.unl.edu.ar  Tue Dec 21 14:42:54 2010
From: calesso at fca.unl.edu.ar (Agustin Alesso)
Date: Tue, 21 Dec 2010 10:42:54 -0300
Subject: [R-sig-ME] help creating spatial autocorrelation structure
Message-ID: <1292938974.2355.49.camel@agustin-Studio14>

Hello dear readers,

I'm working with nlme package and I need to create a double-spherical
correlation structure to include into my ANOVA-GLS model. As Pinheiro &
Bates suggests in their book ("Mixed-effects models in S and S-Plus",
2000, Springer), I have to create a corSpatial constructor and at least
methods for 'coef', 'corMatrix' and 'Initialize' functions.
I'm a (pre)intermediate user of R, so I'd appreciate if someone could
send me and example of how to create a croSpatial class and those
methods (commented code would be great).

Thanks in advance!

Best regards,

-- 
Ing. Agr. Agust?n Alesso
Dpto. Ciencias del Ambiente
Fac. Cs. Agrarias - UNL
Kreder 2805 - S3080HOF - Esperanza
Tel: 03496-428575 int 337/256



From jens.astrom at ekol.slu.se  Tue Dec 21 15:13:36 2010
From: jens.astrom at ekol.slu.se (=?ISO-8859-1?Q?Jens_=C5str=F6m?=)
Date: Tue, 21 Dec 2010 15:13:36 +0100
Subject: [R-sig-ME] Does MCMCglmm allow offset?
In-Reply-To: <mailman.5.1292929202.28946.r-sig-mixed-models@r-project.org>
References: <mailman.5.1292929202.28946.r-sig-mixed-models@r-project.org>
Message-ID: <4D10B610.1010800@ekol.slu.se>

Setting the prior of "off30" manually to 1 produce results that appear
very similar to glmer with "off30" as an offset.

It would be interesting to know if this is the intended way of
specifying an offset with MCMCglmm.


########################
prior1 = list(B= list (mu = matrix(c(0,0,0,1,0),5),V = diag(5)*(10)))
diag(prior1$B$V)[4]<-1e-9

mcmc.manual.off <- MCMCglmm(rapi ~ gender*time + log(off30), data =
rapi.df,family = "poisson", verbose = TRUE, random = ~ us(1 +
time):id,prior=prior1)


summary(mcmc.manual.off)					
#########################

/Jens



------------------------------

Message: 6
Date: Mon, 20 Dec 2010 14:20:35 -0800
From: David Atkins <datkins at u.washington.edu>
To: "r-sig-mixed-models at r-project.org"
	<r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] Does MCMCglmm allow offset?
Message-ID: <4D0FD6B3.2070300 at u.washington.edu>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed


Hi all--

I am wondering whether MCMCglmm will take an offset?  Specifically, we
have a study with number of drinks as the outcome, but we also have an
estimate of over how many hours those drinks were consumed.  Thus, might
make sense to model it as a rate of drinks per hour.

As far as I can tell, glmer does allow an offset, but it seems like
maybe MCMCglmm does not.  A search of MCMCglmm's course notes and JSS
paper does not turn up any discussion.

Below is a real dataset, with a "toy" offset term that would seem to
support this.

Any input appreciated.

cheers, Dave

[sessionInfo() at very end]

### MCMCglmm and offset
#
### read data
rapi.df <-
read.csv("http://depts.washington.edu/cshrb/newweb/stats%20documents/RAPI.Final.csv")
head(rapi.df)

### "rapi" is the rutgers alcohol problems index and was measured
### over previous 30 days -- thus, constant exposure, but we can still
### use it as toy example
#
### over-dispersion term
rapi.df$over <- 1:nrow(rapi.df)

### make up "offset" term
rapi.df$off30 <- rpois(n = nrow(rapi.df), lambda = 30)

### GLM (no random-effects) just as baseline comparator
glm.nooff <- glm(rapi ~ gender*time,
						data = rapi.df, family = "poisson")
glm.off <- glm(rapi ~ gender*time + offset(log(off30)),
						data = rapi.df, family = "poisson")
summary(glm.nooff)						
summary(glm.off)						

### over-dispersed Poisson GLMM in glmer
library(lme4)

### without offset
glmer.nooff <- glmer(rapi ~ gender*time + (time | id) + (1 | over),
						data = rapi.df, verbose = TRUE, family = "poisson")

### with offset
glmer.off <- glmer(rapi ~ gender*time + offset(log(off30)) + (time | id)
+ (1 | over),
						data = rapi.df, verbose = TRUE, family = "poisson")
print(glmer.nooff, corr = FALSE)	
print(glmer.off, corr = FALSE)	

### same models using MCMCglmm
library(MCMCglmm)

mcmc.nooff <- MCMCglmm(rapi ~ gender*time, data = rapi.df,
								family = "poisson", verbose = TRUE,
								random = ~ us(1 + time):id)
mcmc.off <- MCMCglmm(rapi ~ gender*time + offset(log(off30)), data =
rapi.df,
								family = "poisson", verbose = TRUE,
								random = ~ us(1 + time):id)
summary(mcmc.nooff)					
summary(mcmc.off)	


 > sessionInfo()
R version 2.12.1 (2010-12-16)
Platform: i386-apple-darwin9.8.0/i386 (32-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods
[7] base

other attached packages:
[1] MCMCglmm_2.10      corpcor_1.5.7      ape_2.6-2
[4] coda_0.14-2        tensorA_0.36       lme4_0.999375-37
[7] Matrix_0.999375-47 lattice_0.19-16

loaded via a namespace (and not attached):
[1] gee_4.13-16   grid_2.12.1   nlme_3.1-97   stats4_2.12.1
[5] tools_2.12.1

-- Dave Atkins, PhD Research Associate Professor Department of
Psychiatry and Behavioral Science University of Washington
datkins at u.washington.edu Center for the Study of Health and Risk
Behaviors (CSHRB) 1100 NE 45th Street, Suite 300 Seattle, WA 98105
206-616-3879 http://depts.washington.edu/cshrb/ (Mon-Wed) Center for
Healthcare Improvement, for Addictions, Mental Illness, Medically
Vulnerable Populations (CHAMMP) 325 9th Avenue, 2HH-15 Box 359911
Seattle, WA 98104 http://www.chammp.org (Thurs)



From S.Ellison at lgc.co.uk  Tue Dec 21 17:46:34 2010
From: S.Ellison at lgc.co.uk (S Ellison)
Date: Tue, 21 Dec 2010 16:46:34 +0000
Subject: [R-sig-ME] Expected correlation in a mixed model
Message-ID: <sd10d9f4.060@tedmail.lgc.co.uk>

Thanks, all, for the discussion on this.

My take-home message seems to be that messing around with lme or
lmer-like calculations is simply not very sensible with small numbers of
groups. Is that fair? 

(I already knew that anyone who's asking for variance info with four
instances is asking for very imprecise estimates indeed; the question is
more whether lmer or lme, as opposed to some classical estimate, would
be more unsafe because of the sometimes inconvenient convergence than is
already implied by the low number of instances.)

Or is the message less restrictive; for example that one needs to take
singular or zero variance/covariance information as a warning that there
really wasn't enough info in the data to form sensible estimates?

Steve Ellison


>>> Douglas Bates <bates at stat.wisc.edu> 08/12/2010 16:53:49 >>>
On Mon, Nov 22, 2010 at 9:07 AM, Ben Bolker <bbolker at gmail.com> wrote:
>  However: centering the concentration doesn't actually have much
effect
> in this example (which it would if the remoteness from the origin
were
> the problem), i.e.
>
> concsc <- scale(conc)
> (lmer1<-lmer(od~concsc+(concsc|run)))
>
>  This setup seems a little bit odd to me:
>  * the data set size is fairly small -- only 4 levels of the random
> effect ('run'), which often leads to this sort of collapse (zero
> variances and/or perfect correlations)

Exactly.  You are trying to estimate three variance components (two
variances and a covariance) from four groups.  That is not very much
information for what you are trying to estimate.

Bear in mind that it is generally more difficult to estimate a
variance or a covariance than it is to estimate a coefficient in a
linear predictor.  If you use the verbose=TRUE option you can see the
path of the iterations with respect to the three relative variance
component parameters. In lme4a the verbose output shows

> (lmer1<-lmer(od~conc+(conc|run), verbose=TRUE))
npt = 7 , n =  3
rhobeg =  0.2 , rhoend =  2e-07
   0.020:  12:     -2.66406; 1.07341 0.0671561  0.00000
  0.0020:  19:     -2.73319; 1.12766 0.161299  0.00000
 0.00020:  27:     -2.73356; 1.11840 0.161578  0.00000
 2.0e-05:  34:     -2.73357; 1.11786 0.161331 2.74933e-05
 2.0e-06:  40:     -2.73357; 1.11777 0.161302  0.00000
 2.0e-07:  44:     -2.73357; 1.11777 0.161301  0.00000
At return
 48:    -2.7335660:  1.11777 0.161300 1.10253e-08
Linear mixed model fit by REML ['merMod']
Formula: od ~ conc + (conc | run)
REML criterion at convergence: -2.7336

Random effects:
 Groups   Name        Variance Std.Dev. Corr
 run      (Intercept) 0.053559 0.23143
          conc        0.001115 0.03340  1.000
 Residual             0.042867 0.20704
Number of obs: 60, groups: run, 4

Fixed effects:
            Estimate Std. Error t value
(Intercept)  0.52654    0.12148   4.334
conc         0.92236    0.07701  11.977

Correlation of Fixed Effects:
     (Intr)
conc 0.001

The important thing about the iterations is that the first and third
parameters are constrained to be non-negative and the third parameter
immediately is driven to zero.

Both the REML and the ML criteria try to balance complexity of the
model versus the fidelity to the data.  It happens that the way that
the complexity is defined, the least complex models have a singular
variance-covariance matrix for the random effects.  Unless there is
sufficient information in the data to make a non-singular
variance-covariance matrix then the criterion will drive it to
singularity.

Also, as Ben notes you are not simulating from the model that you are
fitting.  You are simulating from a simpler model and that's what the
fit tends towards.

>  * there is no variation in slopes across runs (the only randomness
> here is the error term).  Perhaps what you're looking for is
>
> (lmer2<-lmer(od~concsc+(1|run) + (0+concsc|run)))
>
>  which fixes the correlation at zero.
>
>  * it's also the case here that the random effect on the intercept
of
> 'run' is uniformly distributed, rather than normal -- I don't know
if
> that would have an effect.
>
>  Ben Bolker
>
>
>
> On 11/22/2010 09:44 AM, Andrew Robinson wrote:
>> Yes indeed --- remoteness of the data from the origin is a
plausible
>> explanation.
>>
>> Cheers
>>
>> Andrew
>>
>> On Mon, Nov 22, 2010 at 8:50 PM, S Ellison <S.Ellison at lgc.co.uk>
wrote:
>>
>>> Forgive the possibly numb-brained question, but is there a reason
why
>>> the correlation between random effects coefficients in lmer should
come
>>> out as identically 1.0 in a model of the form
>>>
>>> lmer(x ~ a + (a|b) )
>>>
>>> ?
>>>
>>> An example:
>>> set.seed(403)
>>> require(lme4)
>>> run <- gl(4, 15)
>>> conc <- rep(rep(c(0,0.1, 0.2, 0.4, 1.0), 3), 4)
>>> boxplot(conc~run)
>>> offset=0.2*as.numeric(run)
>>> od <- offset+conc+rnorm(60, 0, 0.2)
>>> plot(conc, od)
>>>
>>> (lmer1<-lmer(od~conc+(conc|run)))
>>> VarCorr(lmer1)
>>>
>>>
>>> S Ellison
>>> LGC
>>>
>>>
*******************************************************************
>>> This email and any attachments are confidential. Any
u...{{dropped:21}}
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models 
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models 
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}



From dieter.menne at menne-biomed.de  Tue Dec 21 18:58:15 2010
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Tue, 21 Dec 2010 17:58:15 +0000 (UTC)
Subject: [R-sig-ME] lmer() - no applicable method for 'profile'
References: <OFCD5E23BB.46ED04AF-ON802577EE.00612C79-802577EE.00620C8E@EliLilly.lilly.com>
	<4CFCE2E9.9090709@gmail.com>
Message-ID: <loom.20101221T185613-872@post.gmane.org>

Ben Bolker <bbolker at ...> writes:

> 
>   You need to be using the development version (lme4a).
>   install.packages("lme4a",repos="http://r-forge.r-project.org")
>   if that fails, try posting sessionInfo()

This fails on Windows, and has been reported several times already and confirmed
as "temporary broken".

Is there a way to get the Windows build updated?

Dieter



From bbolker at gmail.com  Tue Dec 21 19:11:47 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 21 Dec 2010 13:11:47 -0500
Subject: [R-sig-ME] lmer() - no applicable method for 'profile'
In-Reply-To: <loom.20101221T185613-872@post.gmane.org>
References: <OFCD5E23BB.46ED04AF-ON802577EE.00612C79-802577EE.00620C8E@EliLilly.lilly.com>	<4CFCE2E9.9090709@gmail.com>
	<loom.20101221T185613-872@post.gmane.org>
Message-ID: <4D10EDE3.8070208@gmail.com>

On 10-12-21 12:58 PM, Dieter Menne wrote:
> Ben Bolker <bbolker at ...> writes:
> 
>>
>>   You need to be using the development version (lme4a).
>>   install.packages("lme4a",repos="http://r-forge.r-project.org")
>>   if that fails, try posting sessionInfo()
> 
> This fails on Windows, and has been reported several times already and confirmed
> as "temporary broken".
> 
> Is there a way to get the Windows build updated?
> 
> Dieter
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

  (Resending to list)

  I've put up a recent binary (32-bit Windows, R 2.12.x): try

install.packages("lme4a",repos="http://www.math.mcmaster.ca/bolker/R")

and let me know if it works.

I'm a little puzzled that install.packages() doesn't work from R-forge,
there seems to be a binary version there: can you download
<https://r-forge.r-project.org/bin/windows/contrib/latest/lme4_0.999375-37.zip>
 ... ?

  Ben



From Gustaf.Granath at ebc.uu.se  Tue Dec 21 19:25:18 2010
From: Gustaf.Granath at ebc.uu.se (Gustaf Granath)
Date: Tue, 21 Dec 2010 19:25:18 +0100
Subject: [R-sig-ME] Does MCMCglmm allow offset?
Message-ID: <4D10F10E.6050504@ebc.uu.se>

Hi,
The offset term should have mean = 1, I guess. A work around might be to 
fix the parameter to one. Or?
The results corresponds to what lmer() gives.

prior2 = list(B= list (mu = matrix(c(0,1,0,0,0),5),V = diag(5)*1e+6))
diag(prior2$B$V)[2]<-(1e-6)      #change the prior variance to something 
small
mcmc.off2 <- MCMCglmm(rapi ~ log(off30)+gender*time, data =
                 rapi.df,family = "poisson", verbose = TRUE,
         random = ~ us(1 + time):id,prior=prior2)
summary(mcmc.off2$Sol)

Please correct me if Im wrong.

Gustaf



From andydolman at gmail.com  Tue Dec 21 19:25:12 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Tue, 21 Dec 2010 19:25:12 +0100
Subject: [R-sig-ME] lmer() - no applicable method for 'profile'
In-Reply-To: <4D10EDE3.8070208@gmail.com>
References: <OFCD5E23BB.46ED04AF-ON802577EE.00612C79-802577EE.00620C8E@EliLilly.lilly.com>
	<4CFCE2E9.9090709@gmail.com>
	<loom.20101221T185613-872@post.gmane.org>
	<4D10EDE3.8070208@gmail.com>
Message-ID: <AANLkTimKFeXn2OevR6=92JtYUBn-CZijXyBxH30mLtOj@mail.gmail.com>

That's an lme4 binary that you linked to on r-forge. Your hosted
binary work though cheers.

Andy.


andydolman at gmail.com



On 21 December 2010 19:11, Ben Bolker <bbolker at gmail.com> wrote:
> On 10-12-21 12:58 PM, Dieter Menne wrote:
>> Ben Bolker <bbolker at ...> writes:
>>
>>>
>>> ? You need to be using the development version (lme4a).
>>> ? install.packages("lme4a",repos="http://r-forge.r-project.org")
>>> ? if that fails, try posting sessionInfo()
>>
>> This fails on Windows, and has been reported several times already and confirmed
>> as "temporary broken".
>>
>> Is there a way to get the Windows build updated?
>>
>> Dieter
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> ?(Resending to list)
>
> ?I've put up a recent binary (32-bit Windows, R 2.12.x): try
>
> install.packages("lme4a",repos="http://www.math.mcmaster.ca/bolker/R")
>
> and let me know if it works.
>
> I'm a little puzzled that install.packages() doesn't work from R-forge,
> there seems to be a binary version there: can you download
> <https://r-forge.r-project.org/bin/windows/contrib/latest/lme4_0.999375-37.zip>
> ?... ?
>
> ?Ben
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bbolker at gmail.com  Tue Dec 21 19:26:57 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 21 Dec 2010 13:26:57 -0500
Subject: [R-sig-ME] lmer() - no applicable method for 'profile'
In-Reply-To: <AANLkTimKFeXn2OevR6=92JtYUBn-CZijXyBxH30mLtOj@mail.gmail.com>
References: <OFCD5E23BB.46ED04AF-ON802577EE.00612C79-802577EE.00620C8E@EliLilly.lilly.com>	<4CFCE2E9.9090709@gmail.com>	<loom.20101221T185613-872@post.gmane.org>	<4D10EDE3.8070208@gmail.com>
	<AANLkTimKFeXn2OevR6=92JtYUBn-CZijXyBxH30mLtOj@mail.gmail.com>
Message-ID: <4D10F171.9070005@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 10-12-21 01:25 PM, Andrew Dolman wrote:
> That's an lme4 binary that you linked to on r-forge. Your hosted
> binary work though cheers.
> 
> Andy.
> 
> 
> andydolman at gmail.com
> 

 Oops.  How about

<https://r-forge.r-project.org/bin/windows/contrib/latest/lme4a_0.999375-59.zip>

  ?


> 
> 
> On 21 December 2010 19:11, Ben Bolker <bbolker at gmail.com> wrote:
>> On 10-12-21 12:58 PM, Dieter Menne wrote:
>>> Ben Bolker <bbolker at ...> writes:
>>>
>>>>
>>>>   You need to be using the development version (lme4a).
>>>>   install.packages("lme4a",repos="http://r-forge.r-project.org")
>>>>   if that fails, try posting sessionInfo()
>>>
>>> This fails on Windows, and has been reported several times already and confirmed
>>> as "temporary broken".
>>>
>>> Is there a way to get the Windows build updated?
>>>
>>> Dieter
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>  (Resending to list)
>>
>>  I've put up a recent binary (32-bit Windows, R 2.12.x): try
>>
>> install.packages("lme4a",repos="http://www.math.mcmaster.ca/bolker/R")
>>
>> and let me know if it works.
>>
>> I'm a little puzzled that install.packages() doesn't work from R-forge,
>> there seems to be a binary version there: can you download
>> <https://r-forge.r-project.org/bin/windows/contrib/latest/lme4_0.999375-37.zip>
>>  ... ?
>>
>>  Ben
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iEYEARECAAYFAk0Q8XEACgkQc5UpGjwzenNo3gCePG24NoFCoZ/lcvv8QJawde43
O3oAnjZqcTR6y2KjbTgU9uKkzcVM/BW+
=g4SJ
-----END PGP SIGNATURE-----



From jwidman at mi.nmfs.gov  Tue Dec 21 20:43:35 2010
From: jwidman at mi.nmfs.gov (James Widman)
Date: Tue, 21 Dec 2010 14:43:35 -0500
Subject: [R-sig-ME] nlmer model specification
In-Reply-To: <4D10B610.1010800@ekol.slu.se>
References: <mailman.5.1292929202.28946.r-sig-mixed-models@r-project.org>
	<4D10B610.1010800@ekol.slu.se>
Message-ID: <4D110367.8010005@mi.nmfs.gov>

Happy Holidays to All,

  I'm trying to use nlmer to model some data from an experiment I ran 
and am having some trouble specifying the model correctly. Would 
appreciate any insight you can provide.

I am examining the growth of fish fed two diets over 9 weeks - with 
weekly measurements. Thirty fish were placed in each of 8 tanks, 4 tanks 
fed foodtype NRD and 4 tanks fed foodtype OTO.
Unbalanced data due to mortality.
I'm trying to fit a nlmer to the data and want to make sure I have 
specified the model correctly. I can provide additional information if 
needed.
This is what I came up with and have tried a number of alternatives but 
don't seem to  be progressing.  I realize the model will probably be 
simplified.

foodtype should be a fixed effect.

 > str(scupgrowth)
'data.frame':   2925 obs. of  11 variables:
  $ StartDate  : Factor w/ 1 level "2008/07/29": 1 1 1 1 1 1 1 1 1 1 ...
  $ SampleDate : Factor w/ 10 levels "2008/07/29","2008/08/05",..: 1 1 1 
1 1 1 1 1 1 1 ...
  $ FishID     : int  1 2 3 4 5 6 7 8 9 10 ...
  $ Length..mm.: int  38 39 34 33 36 40 39 34 32 35 ...
  $ Weight..g. : num  0.64 0.81 0.47 0.48 0.62 0.78 0.7 0.47 0.47 0.62 ...
  $ Tank       : int  1 1 1 1 1 1 1 1 1 1 ...
  $ Days       : int  0 0 0 0 0 0 0 0 0 0 ...
  $ FishIDf    : Factor w/ 2925 levels "1","2","3","4",..: 1 2 3 4 5 6 7 
8 9 10 ...
  $ foodtype   : Factor w/ 2 levels "NRD","OTO": 1 1 1 1 1 1 1 1 1 1 ...
  $ tankf      : Factor w/ 8 levels "1","2","3","4",..: 1 1 1 1 1 1 1 1 
1 1 ...
  $ week       : num  0 0 0 0 0 0 0 0 0 0 ...
 > (nlm1 <- nlmer(Weight..g. ~ SSgompertz(week, Asym, a, b) ~ foodtype + 
tankf + tankf|FishIDf,
+  scupgrowth, start = c(Asym = 72.70484, a = 5.34048, b = 0.83792)))
Nonlinear mixed model fit by the Laplace approximation
Formula: Weight..g. ~ SSgompertz(week, Asym, a, b) ~ foodtype + tankf 
+      tankf | FishIDf
    Data: scupgrowth
   AIC  BIC logLik deviance
  6010 6249  -2965     5930
Random effects:
  Groups   Name        Variance   Std.Dev.  Corr
  FishIDf  foodtypeOTO 4.7489e-06 0.0021792
           tankf2      2.8193e-04 0.0167909 -0.829
           tankf3      1.4213e-04 0.0119219  0.001  0.110
           tankf4      2.0968e-04 0.0144804 -0.913  0.759  0.056
           tankf5      1.8160e-04 0.0134760 -0.023 -0.007 -0.035  0.019
           tankf6      3.7620e-04 0.0193958 -0.800  0.704  0.014  0.731 
-0.260
           tankf7      2.0907e-04 0.0144592  0.023 -0.195 -0.062 -0.022 
-0.038
           tankf8      3.4983e-04 0.0187038 -0.958  0.701 -0.033  0.870  
0.222
  Residual             1.1874e+00 1.0896851

  -0.021
   0.702 -0.107

Number of obs: 2925, groups: FishIDf, 2925

Fixed effects:
       Estimate Std. Error t value
Asym 90.150991   5.205204   17.32
a     5.160145   0.042640  121.02
b     0.868886   0.003198  271.73

Correlation of Fixed Effects:
   Asym  a
a 0.748
b 0.970 0.576

When I tried the following I get an error.
   (nlm1 <- nlmer(Weight..g. ~ SSgompertz(week, Asym, a, b) ~ (1 | 
foodtype) + tankf + tankf|FishIDf,
+  scupgrowth, start = c(Asym = 72.70484, a = 5.34048, b = 0.83792)))
Error in model.matrix.default(eval(substitute(~expr, list(expr = 
x[[2]]))),  :
   model frame and formula mismatch in model.matrix()

Thanks for any feedback you can provide.
Jim Widman



From bbolker at gmail.com  Tue Dec 21 22:16:50 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 21 Dec 2010 16:16:50 -0500
Subject: [R-sig-ME] nlmer model specification
In-Reply-To: <4D110367.8010005@mi.nmfs.gov>
References: <mailman.5.1292929202.28946.r-sig-mixed-models@r-project.org>	<4D10B610.1010800@ekol.slu.se>
	<4D110367.8010005@mi.nmfs.gov>
Message-ID: <4D111942.4060000@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 10-12-21 02:43 PM, James Widman wrote:
> Happy Holidays to All,
> 
>  I'm trying to use nlmer to model some data from an experiment I ran and
> am having some trouble specifying the model correctly. Would appreciate
> any insight you can provide.
> 
> I am examining the growth of fish fed two diets over 9 weeks - with
> weekly measurements. Thirty fish were placed in each of 8 tanks, 4 tanks
> fed foodtype NRD and 4 tanks fed foodtype OTO.
> Unbalanced data due to mortality.
> I'm trying to fit a nlmer to the data and want to make sure I have
> specified the model correctly. I can provide additional information if
> needed.
> This is what I came up with and have tried a number of alternatives but
> don't seem to  be progressing.  I realize the model will probably be
> simplified.
> 
> foodtype should be a fixed effect.
> 

  Hmmm.  It's not obvious to me from looking at the ?lmer page how one
would go about fitting this sort of 'split-plot' design in lmer: I see
how one would allow all three variables to vary among tanks and among
fish within tanks:

 nlmer(Weight..g. ~ SSgompertz(week, Asym, a, b) ~
Asym+b+c|tankf/FishIDf, ...)

  If there weren't a problem with specifying a fixed effect with only
two types, we could do

nlmer(Weight..g. ~ SSgompertz(week, Asym, a, b) ~
Asym+b+c|foodtype/tankf/FishIDf, ...)

  but that probably won't work well.

  My next try, unless someone on the list has a better solution, would
probably be to try this in AD Model Builder.

  (I just got a copy of Madsen and Thyregod "Intro to general and
generalized linear models", which has an interesting section on
extending the orange-tree analysis (?Orange) using Laplace
approximations coded around nlme and using AD Model Builder ...)

  Ben Bolker


>> str(scupgrowth)
> 'data.frame':   2925 obs. of  11 variables:
>  $ StartDate  : Factor w/ 1 level "2008/07/29": 1 1 1 1 1 1 1 1 1 1 ...
>  $ SampleDate : Factor w/ 10 levels "2008/07/29","2008/08/05",..: 1 1 1
> 1 1 1 1 1 1 1 ...
>  $ FishID     : int  1 2 3 4 5 6 7 8 9 10 ...
>  $ Length..mm.: int  38 39 34 33 36 40 39 34 32 35 ...
>  $ Weight..g. : num  0.64 0.81 0.47 0.48 0.62 0.78 0.7 0.47 0.47 0.62 ...
>  $ Tank       : int  1 1 1 1 1 1 1 1 1 1 ...
>  $ Days       : int  0 0 0 0 0 0 0 0 0 0 ...
>  $ FishIDf    : Factor w/ 2925 levels "1","2","3","4",..: 1 2 3 4 5 6 7
> 8 9 10 ...
>  $ foodtype   : Factor w/ 2 levels "NRD","OTO": 1 1 1 1 1 1 1 1 1 1 ...
>  $ tankf      : Factor w/ 8 levels "1","2","3","4",..: 1 1 1 1 1 1 1 1 1
> 1 ...
>  $ week       : num  0 0 0 0 0 0 0 0 0 0 ...
>> (nlm1 <- nlmer(Weight..g. ~ SSgompertz(week, Asym, a, b) ~ foodtype +
> tankf + tankf|FishIDf,
> +  scupgrowth, start = c(Asym = 72.70484, a = 5.34048, b = 0.83792)))
> Nonlinear mixed model fit by the Laplace approximation
> Formula: Weight..g. ~ SSgompertz(week, Asym, a, b) ~ foodtype + tankf
> +      tankf | FishIDf
>    Data: scupgrowth
>   AIC  BIC logLik deviance
>  6010 6249  -2965     5930
> Random effects:
>  Groups   Name        Variance   Std.Dev.  Corr
>  FishIDf  foodtypeOTO 4.7489e-06 0.0021792
>           tankf2      2.8193e-04 0.0167909 -0.829
>           tankf3      1.4213e-04 0.0119219  0.001  0.110
>           tankf4      2.0968e-04 0.0144804 -0.913  0.759  0.056
>           tankf5      1.8160e-04 0.0134760 -0.023 -0.007 -0.035  0.019
>           tankf6      3.7620e-04 0.0193958 -0.800  0.704  0.014  0.731
> -0.260
>           tankf7      2.0907e-04 0.0144592  0.023 -0.195 -0.062 -0.022
> -0.038
>           tankf8      3.4983e-04 0.0187038 -0.958  0.701 -0.033  0.870 
> 0.222
>  Residual             1.1874e+00 1.0896851
> 
>  -0.021
>   0.702 -0.107
> 
> Number of obs: 2925, groups: FishIDf, 2925
> 
> Fixed effects:
>       Estimate Std. Error t value
> Asym 90.150991   5.205204   17.32
> a     5.160145   0.042640  121.02
> b     0.868886   0.003198  271.73
> 
> Correlation of Fixed Effects:
>   Asym  a
> a 0.748
> b 0.970 0.576
> 
> When I tried the following I get an error.
>   (nlm1 <- nlmer(Weight..g. ~ SSgompertz(week, Asym, a, b) ~ (1 |
> foodtype) + tankf + tankf|FishIDf,
> +  scupgrowth, start = c(Asym = 72.70484, a = 5.34048, b = 0.83792)))
> Error in model.matrix.default(eval(substitute(~expr, list(expr =
> x[[2]]))),  :
>   model frame and formula mismatch in model.matrix()
> 


-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iEYEARECAAYFAk0RGUIACgkQc5UpGjwzenPswwCfUo5zcC9OBCKRTwwoUuGBrr0k
8xEAmwa6mpJaboeDXTZrod8jqqDbBXj4
=VpL8
-----END PGP SIGNATURE-----



From djmuser at gmail.com  Wed Dec 22 02:13:57 2010
From: djmuser at gmail.com (Dennis Murphy)
Date: Tue, 21 Dec 2010 17:13:57 -0800
Subject: [R-sig-ME] nlmer model specification
In-Reply-To: <4D110367.8010005@mi.nmfs.gov>
References: <mailman.5.1292929202.28946.r-sig-mixed-models@r-project.org>
	<4D10B610.1010800@ekol.slu.se> <4D110367.8010005@mi.nmfs.gov>
Message-ID: <AANLkTinLf7UT-Lb18NJe+f69Win0kJbSXT+pXkftQS6V@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101221/a5aa03df/attachment.pl>

From modlogist at gmail.com  Wed Dec 22 04:20:21 2010
From: modlogist at gmail.com (william russell)
Date: Tue, 21 Dec 2010 22:20:21 -0500
Subject: [R-sig-ME] models for population growth
Message-ID: <AANLkTimBtiHLUuTtJEd=Hr1H4S0_L5n=9e_M5zutqenV@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101221/5a4993ef/attachment.pl>

From renaud.lancelot at cirad.fr  Wed Dec 22 09:56:58 2010
From: renaud.lancelot at cirad.fr (lancelot)
Date: Wed, 22 Dec 2010 09:56:58 +0100
Subject: [R-sig-ME] lmer() - no applicable method for 'profile'
In-Reply-To: <4D10F171.9070005@gmail.com>
References: <OFCD5E23BB.46ED04AF-ON802577EE.00612C79-802577EE.00620C8E@EliLilly.lilly.com>	<4CFCE2E9.9090709@gmail.com>	<loom.20101221T185613-872@post.gmane.org>	<4D10EDE3.8070208@gmail.com>	<AANLkTimKFeXn2OevR6=92JtYUBn-CZijXyBxH30mLtOj@mail.gmail.com>
	<4D10F171.9070005@gmail.com>
Message-ID: <4D11BD5A.7090504@cirad.fr>

I have a "page not found" message for this URL.

Renaud

Le 21/12/2010 19:26, Ben Bolker a ?crit :
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 10-12-21 01:25 PM, Andrew Dolman wrote:
>> That's an lme4 binary that you linked to on r-forge. Your hosted
>> binary work though cheers.
>>
>> Andy.
>>
>>
>> andydolman at gmail.com
>>
>
>   Oops.  How about
>
> <https://r-forge.r-project.org/bin/windows/contrib/latest/lme4a_0.999375-59.zip>
>
>    ?
>
>
>>
>>
>> On 21 December 2010 19:11, Ben Bolker<bbolker at gmail.com>  wrote:
>>> On 10-12-21 12:58 PM, Dieter Menne wrote:
>>>> Ben Bolker<bbolker at ...>  writes:
>>>>
>>>>>
>>>>>    You need to be using the development version (lme4a).
>>>>>    install.packages("lme4a",repos="http://r-forge.r-project.org")
>>>>>    if that fails, try posting sessionInfo()
>>>>
>>>> This fails on Windows, and has been reported several times already and confirmed
>>>> as "temporary broken".
>>>>
>>>> Is there a way to get the Windows build updated?
>>>>
>>>> Dieter
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>   (Resending to list)
>>>
>>>   I've put up a recent binary (32-bit Windows, R 2.12.x): try
>>>
>>> install.packages("lme4a",repos="http://www.math.mcmaster.ca/bolker/R")
>>>
>>> and let me know if it works.
>>>
>>> I'm a little puzzled that install.packages() doesn't work from R-forge,
>>> there seems to be a binary version there: can you download
>>> <https://r-forge.r-project.org/bin/windows/contrib/latest/lme4_0.999375-37.zip>
>>>   ... ?
>>>
>>>   Ben
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.10 (GNU/Linux)
> Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/
>
> iEYEARECAAYFAk0Q8XEACgkQc5UpGjwzenNo3gCePG24NoFCoZ/lcvv8QJawde43
> O3oAnjZqcTR6y2KjbTgU9uKkzcVM/BW+
> =g4SJ
> -----END PGP SIGNATURE-----
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

-- 
Renaud Lancelot
EDEN Project, coordinator
http://www.eden-fp6project.net/

UMR CIRAD-INRA "Contr?le des maladies animales exotiques et ?mergentes"
Joint research unit "Control of emerging and exotic animal diseases"

CIRAD, Campus International de Baillarguet TA A-DIR / B
F34398 Montpellier
http://umr-cmaee.cirad.fr/

Tel.  +33 4 67 59 37 17  -  Fax  +33 4 67 59 37 95
Secr. +33 4 67 59 37 37  - Cell. +33 6 77 52 08 69



From robert.espesser at lpl-aix.fr  Wed Dec 22 10:25:03 2010
From: robert.espesser at lpl-aix.fr (espesser)
Date: Wed, 22 Dec 2010 10:25:03 +0100
Subject: [R-sig-ME] lmer() - no applicable method for 'profile'
In-Reply-To: <4D11BD5A.7090504@cirad.fr>
References: <OFCD5E23BB.46ED04AF-ON802577EE.00612C79-802577EE.00620C8E@EliLilly.lilly.com>	<4CFCE2E9.9090709@gmail.com>	<loom.20101221T185613-872@post.gmane.org>	<4D10EDE3.8070208@gmail.com>	<AANLkTimKFeXn2OevR6=92JtYUBn-CZijXyBxH30mLtOj@mail.gmail.com>	<4D10F171.9070005@gmail.com>
	<4D11BD5A.7090504@cirad.fr>
Message-ID: <4D11C3EF.7050302@lpl-aix.fr>

  There is a:

https://r-forge.r-project.org/bin/windows/contrib/latest/lme4b_0.999375-60.zip
????
 From previous mails, I believe this version was not intended to be used 
by  lambda user  ,  is it still true ?
I'm looking for a windows  lme4a   distribution to  use logit link from 
package "psyphy" (function mafc()  )   in lmer() .
Dr Bates mailed some times ago about this.
R. Espesser

Le 22/12/2010 09:56, lancelot a ?crit :
> I have a "page not found" message for this URL.
>
> Renaud
>
> Le 21/12/2010 19:26, Ben Bolker a ?crit :
>> -----BEGIN PGP SIGNED MESSAGE-----
>> Hash: SHA1
>>
>> On 10-12-21 01:25 PM, Andrew Dolman wrote:
>>> That's an lme4 binary that you linked to on r-forge. Your hosted
>>> binary work though cheers.
>>>
>>> Andy.
>>>
>>>
>>> andydolman at gmail.com
>>>
>>
>>   Oops.  How about
>>
>> <https://r-forge.r-project.org/bin/windows/contrib/latest/lme4a_0.999375-59.zip> 
>>
>>
>>    ?
>>
>>
>>>
>>>
>>> On 21 December 2010 19:11, Ben Bolker<bbolker at gmail.com>  wrote:
>>>> On 10-12-21 12:58 PM, Dieter Menne wrote:
>>>>> Ben Bolker<bbolker at ...>  writes:
>>>>>
>>>>>>
>>>>>>    You need to be using the development version (lme4a).
>>>>>>    install.packages("lme4a",repos="http://r-forge.r-project.org")
>>>>>>    if that fails, try posting sessionInfo()
>>>>>
>>>>> This fails on Windows, and has been reported several times already 
>>>>> and confirmed
>>>>> as "temporary broken".
>>>>>
>>>>> Is there a way to get the Windows build updated?
>>>>>
>>>>> Dieter
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>>   (Resending to list)
>>>>
>>>>   I've put up a recent binary (32-bit Windows, R 2.12.x): try
>>>>
>>>> install.packages("lme4a",repos="http://www.math.mcmaster.ca/bolker/R")
>>>>
>>>> and let me know if it works.
>>>>
>>>> I'm a little puzzled that install.packages() doesn't work from 
>>>> R-forge,
>>>> there seems to be a binary version there: can you download
>>>> <https://r-forge.r-project.org/bin/windows/contrib/latest/lme4_0.999375-37.zip> 
>>>>
>>>>   ... ?
>>>>
>>>>   Ben
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>
>> -----BEGIN PGP SIGNATURE-----
>> Version: GnuPG v1.4.10 (GNU/Linux)
>> Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/
>>
>> iEYEARECAAYFAk0Q8XEACgkQc5UpGjwzenNo3gCePG24NoFCoZ/lcvv8QJawde43
>> O3oAnjZqcTR6y2KjbTgU9uKkzcVM/BW+
>> =g4SJ
>> -----END PGP SIGNATURE-----
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>


-- 
Robert Espesser
CNRS UMR 6057 - Universit? de Provence
5 Avenue Pasteur - BP 80975
13604 AIX-EN-PROVENCE Cedex 1

Tel: +33 (0)442 95 36 26



From ken.knoblauch at inserm.fr  Wed Dec 22 12:04:52 2010
From: ken.knoblauch at inserm.fr (Ken Knoblauch)
Date: Wed, 22 Dec 2010 11:04:52 +0000 (UTC)
Subject: [R-sig-ME] lmer() - no applicable method for 'profile'
References: <OFCD5E23BB.46ED04AF-ON802577EE.00612C79-802577EE.00620C8E@EliLilly.lilly.com>	<4CFCE2E9.9090709@gmail.com>	<loom.20101221T185613-872@post.gmane.org>	<4D10EDE3.8070208@gmail.com>	<AANLkTimKFeXn2OevR6=92JtYUBn-CZijXyBxH30mLtOj@mail.gmail.com>	<4D10F171.9070005@gmail.com>
	<4D11BD5A.7090504@cirad.fr> <4D11C3EF.7050302@lpl-aix.fr>
Message-ID: <loom.20101222T120219-461@post.gmane.org>

espesser <robert.espesser at ...> writes:

> 
>   There is a:
> 
> https://r-forge.r-project.org/bin/windows/contrib/latest/lme4b_0.999375-60.zip
> ????
>  From previous mails, I believe this version was not intended to be used 
> by  lambda user  ,  is it still true ?
> I'm looking for a windows  lme4a   distribution to  use logit link from 
> package "psyphy" (function mafc()  )   in lmer() .
> Dr Bates mailed some times ago about this.
> R. Espesser
> 
>>>>> snip <<<<<<<<<<<<

do see

https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q4/004531.html

although the current version of lme4a doesn't seem to be available from
the package installer on Mac OS X, but this usually is resolved in several
days, if one is patient.


-- 
Ken Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html



From bbolker at gmail.com  Wed Dec 22 14:40:59 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 22 Dec 2010 08:40:59 -0500
Subject: [R-sig-ME] lmer() - no applicable method for 'profile'
In-Reply-To: <4D11BD5A.7090504@cirad.fr>
References: <OFCD5E23BB.46ED04AF-ON802577EE.00612C79-802577EE.00620C8E@EliLilly.lilly.com>	<4CFCE2E9.9090709@gmail.com>	<loom.20101221T185613-872@post.gmane.org>	<4D10EDE3.8070208@gmail.com>	<AANLkTimKFeXn2OevR6=92JtYUBn-CZijXyBxH30mLtOj@mail.gmail.com>
	<4D10F171.9070005@gmail.com> <4D11BD5A.7090504@cirad.fr>
Message-ID: <4D11FFEB.4050606@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

  Yes.  For now I think

install.packages("lme4a",repos="http://www.math.mcmaster.ca/bolker/R")

or

manually getting

<http://www.math.mcmaster.ca/bolker/R/bin/windows/contrib/2.12/lme4a_0.999375-59.zip>

  should work.




On 10-12-22 03:56 AM, lancelot wrote:
> I have a "page not found" message for this URL.
> 
> Renaud
> 
> Le 21/12/2010 19:26, Ben Bolker a ?crit :
> On 10-12-21 01:25 PM, Andrew Dolman wrote:
>>>> That's an lme4 binary that you linked to on r-forge. Your hosted
>>>> binary work though cheers.
>>>>
>>>> Andy.
>>>>
>>>>
>>>> andydolman at gmail.com
>>>>
> 
>   Oops.  How about
> 
> <https://r-forge.r-project.org/bin/windows/contrib/latest/lme4a_0.999375-59.zip>
> 
> 
>    ?
> 
> 
>>>>
>>>>
>>>> On 21 December 2010 19:11, Ben Bolker<bbolker at gmail.com>  wrote:
>>>>> On 10-12-21 12:58 PM, Dieter Menne wrote:
>>>>>> Ben Bolker<bbolker at ...>  writes:
>>>>>>
>>>>>>>
>>>>>>>    You need to be using the development version (lme4a).
>>>>>>>    install.packages("lme4a",repos="http://r-forge.r-project.org")
>>>>>>>    if that fails, try posting sessionInfo()
>>>>>>
>>>>>> This fails on Windows, and has been reported several times already
>>>>>> and confirmed
>>>>>> as "temporary broken".
>>>>>>
>>>>>> Is there a way to get the Windows build updated?
>>>>>>
>>>>>> Dieter
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>>   (Resending to list)
>>>>>
>>>>>   I've put up a recent binary (32-bit Windows, R 2.12.x): try
>>>>>
>>>>> install.packages("lme4a",repos="http://www.math.mcmaster.ca/bolker/R")
>>>>>
>>>>> and let me know if it works.
>>>>>
>>>>> I'm a little puzzled that install.packages() doesn't work from R-forge,
>>>>> there seems to be a binary version there: can you download
>>>>> <https://r-forge.r-project.org/bin/windows/contrib/latest/lme4_0.999375-37.zip>
>>>>>
>>>>>   ... ?
>>>>>
>>>>>   Ben
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
> 
>>
_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iEYEARECAAYFAk0R/+sACgkQc5UpGjwzenOqoACghl1TkqQiCjctGxzN8OyirM2+
LqEAoIgEVJYyxpXkWonqgKaA7DC34P6G
=S50A
-----END PGP SIGNATURE-----



From djmuser at gmail.com  Wed Dec 22 17:03:19 2010
From: djmuser at gmail.com (Dennis Murphy)
Date: Wed, 22 Dec 2010 08:03:19 -0800
Subject: [R-sig-ME] lmer() - no applicable method for 'profile'
In-Reply-To: <4D11FFEB.4050606@gmail.com>
References: <OFCD5E23BB.46ED04AF-ON802577EE.00612C79-802577EE.00620C8E@EliLilly.lilly.com>
	<4CFCE2E9.9090709@gmail.com>
	<loom.20101221T185613-872@post.gmane.org>
	<4D10EDE3.8070208@gmail.com>
	<AANLkTimKFeXn2OevR6=92JtYUBn-CZijXyBxH30mLtOj@mail.gmail.com>
	<4D10F171.9070005@gmail.com> <4D11BD5A.7090504@cirad.fr>
	<4D11FFEB.4050606@gmail.com>
Message-ID: <AANLkTi=E-hNhHrqSmmy3m12mCd2r=uJDoziBgE_agkX8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101222/5efd2481/attachment.pl>

From jwidman at mi.nmfs.gov  Wed Dec 22 20:04:05 2010
From: jwidman at mi.nmfs.gov (James Widman)
Date: Wed, 22 Dec 2010 14:04:05 -0500
Subject: [R-sig-ME] nlmer model specification
In-Reply-To: <4D111942.4060000@gmail.com>
References: <mailman.5.1292929202.28946.r-sig-mixed-models@r-project.org>	<4D10B610.1010800@ekol.slu.se>
	<4D110367.8010005@mi.nmfs.gov> <4D111942.4060000@gmail.com>
Message-ID: <4D124BA5.7080902@mi.nmfs.gov>


Hi Ben,
   Thanks for your help, I'm closer but not there yet - see below.
On 12/21/2010 04:16 PM, Ben Bolker wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 10-12-21 02:43 PM, James Widman wrote:
>> Happy Holidays to All,
>>
>>   I'm trying to use nlmer to model some data from an experiment I ran and
>> am having some trouble specifying the model correctly. Would appreciate
>> any insight you can provide.
>>
>> I am examining the growth of fish fed two diets over 9 weeks - with
>> weekly measurements. Thirty fish were placed in each of 8 tanks, 4 tanks
>> fed foodtype NRD and 4 tanks fed foodtype OTO.
>> Unbalanced data due to mortality.
>> I'm trying to fit a nlmer to the data and want to make sure I have
>> specified the model correctly. I can provide additional information if
>> needed.
>> This is what I came up with and have tried a number of alternatives but
>> don't seem to  be progressing.  I realize the model will probably be
>> simplified.
>>
>> foodtype should be a fixed effect.
>>
>    Hmmm.  It's not obvious to me from looking at the ?lmer page how one
> would go about fitting this sort of 'split-plot' design in lmer: I see
> how one would allow all three variables to vary among tanks and among
> fish within tanks:

   I'm assuming the equations were supposed to be Asym+a+b. I still 
don't see a fixed affect for foodtype.
>   nlmer(Weight..g. ~ SSgompertz(week, Asym, a, b) ~
> Asym+b+c|tankf/FishIDf, ...)
>
>    If there weren't a problem with specifying a fixed effect with only
> two types, we could do
>
> nlmer(Weight..g. ~ SSgompertz(week, Asym, a, b) ~
> Asym+b+c|foodtype/tankf/FishIDf, ...)
>
>    but that probably won't work well.
>
>    My next try, unless someone on the list has a better solution, would
> probably be to try this in AD Model Builder.
>
>    (I just got a copy of Madsen and Thyregod "Intro to general and
> generalized linear models", which has an interesting section on
> extending the orange-tree analysis (?Orange) using Laplace
> approximations coded around nlme and using AD Model Builder ...)
>
>    Ben Bolker
>  nlmer(Weight..g. ~ SSgompertz(week, Asym, a, b) ~

+ Asym+b+a|foodtype/tankf/FishIDf,

+  scupgrowth, start = c(Asym = 72.70484, a = 5.34048, b = 0.83792))

Nonlinear mixed model fit by the Laplace approximation

Formula: Weight..g. ~ SSgompertz(week, Asym, a, b) ~ Asym + b + a | foodtype/tankf/FishIDf

    Data: scupgrowth

   AIC  BIC logLik deviance

  4251 4383  -2104     4207

Random effects:

  Groups                   Name Variance   Std.Dev.   Corr

  FishIDf:(tankf:foodtype) Asym 3.1676e+01 5.62811999

                           b    3.4431e-04 0.01855561  1.000

                           a    2.7675e-02 0.16635946 -1.000 -1.000

  tankf:foodtype           Asym 3.9691e-07 0.00063001

                           b    5.4414e-07 0.00073766 -0.994

                           a    2.1861e-05 0.00467557 -0.996  1.000

  foodtype                 Asym 6.2047e-01 0.78769773

                           b    1.9456e-05 0.00441087  1.000

                           a    9.6219e-04 0.03101925 -1.000 -1.000

  Residual                      5.9801e-01 0.77331039

Number of obs: 2925, groups: FishIDf:(tankf:foodtype), 2925; tankf:foodtype, 8; foodtype, 2

Fixed effects:

       Estimate Std. Error t value

Asym 85.091422   1.569495   54.22

a     5.302438   0.031940  166.01

b     0.856355   0.003421  250.30

Correlation of Fixed Effects:

   Asym   a

a -0.131

b  0.647 -0.717

Warning message:

In mer_finalize(ans) : iteration limit reached without convergence (9)


>
>>> str(scupgrowth)
>> 'data.frame':   2925 obs. of  11 variables:
>>   $ StartDate  : Factor w/ 1 level "2008/07/29": 1 1 1 1 1 1 1 1 1 1 ...
>>   $ SampleDate : Factor w/ 10 levels "2008/07/29","2008/08/05",..: 1 1 1
>> 1 1 1 1 1 1 1 ...
>>   $ FishID     : int  1 2 3 4 5 6 7 8 9 10 ...
>>   $ Length..mm.: int  38 39 34 33 36 40 39 34 32 35 ...
>>   $ Weight..g. : num  0.64 0.81 0.47 0.48 0.62 0.78 0.7 0.47 0.47 0.62 ...
>>   $ Tank       : int  1 1 1 1 1 1 1 1 1 1 ...
>>   $ Days       : int  0 0 0 0 0 0 0 0 0 0 ...
>>   $ FishIDf    : Factor w/ 2925 levels "1","2","3","4",..: 1 2 3 4 5 6 7
>> 8 9 10 ...
>>   $ foodtype   : Factor w/ 2 levels "NRD","OTO": 1 1 1 1 1 1 1 1 1 1 ...
>>   $ tankf      : Factor w/ 8 levels "1","2","3","4",..: 1 1 1 1 1 1 1 1 1
>> 1 ...
>>   $ week       : num  0 0 0 0 0 0 0 0 0 0 ...
>>> (nlm1<- nlmer(Weight..g. ~ SSgompertz(week, Asym, a, b) ~ foodtype +
>> tankf + tankf|FishIDf,
>> +  scupgrowth, start = c(Asym = 72.70484, a = 5.34048, b = 0.83792)))
>> Nonlinear mixed model fit by the Laplace approximation
>> Formula: Weight..g. ~ SSgompertz(week, Asym, a, b) ~ foodtype + tankf
>> +      tankf | FishIDf
>>     Data: scupgrowth
>>    AIC  BIC logLik deviance
>>   6010 6249  -2965     5930
>> Random effects:
>>   Groups   Name        Variance   Std.Dev.  Corr
>>   FishIDf  foodtypeOTO 4.7489e-06 0.0021792
>>            tankf2      2.8193e-04 0.0167909 -0.829
>>            tankf3      1.4213e-04 0.0119219  0.001  0.110
>>            tankf4      2.0968e-04 0.0144804 -0.913  0.759  0.056
>>            tankf5      1.8160e-04 0.0134760 -0.023 -0.007 -0.035  0.019
>>            tankf6      3.7620e-04 0.0193958 -0.800  0.704  0.014  0.731
>> -0.260
>>            tankf7      2.0907e-04 0.0144592  0.023 -0.195 -0.062 -0.022
>> -0.038
>>            tankf8      3.4983e-04 0.0187038 -0.958  0.701 -0.033  0.870
>> 0.222
>>   Residual             1.1874e+00 1.0896851
>>
>>   -0.021
>>    0.702 -0.107
>>
>> Number of obs: 2925, groups: FishIDf, 2925
>>
>> Fixed effects:
>>        Estimate Std. Error t value
>> Asym 90.150991   5.205204   17.32
>> a     5.160145   0.042640  121.02
>> b     0.868886   0.003198  271.73
>>
>> Correlation of Fixed Effects:
>>    Asym  a
>> a 0.748
>> b 0.970 0.576
>>
>> When I tried the following I get an error.
>>    (nlm1<- nlmer(Weight..g. ~ SSgompertz(week, Asym, a, b) ~ (1 |
>> foodtype) + tankf + tankf|FishIDf,
>> +  scupgrowth, start = c(Asym = 72.70484, a = 5.34048, b = 0.83792)))
>> Error in model.matrix.default(eval(substitute(~expr, list(expr =
>> x[[2]]))),  :
>>    model frame and formula mismatch in model.matrix()
>>
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.10 (GNU/Linux)
> Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/
>
> iEYEARECAAYFAk0RGUIACgkQc5UpGjwzenPswwCfUo5zcC9OBCKRTwwoUuGBrr0k
> 8xEAmwa6mpJaboeDXTZrod8jqqDbBXj4
> =VpL8
> -----END PGP SIGNATURE-----



From jwidman at mi.nmfs.gov  Wed Dec 22 20:04:03 2010
From: jwidman at mi.nmfs.gov (James Widman)
Date: Wed, 22 Dec 2010 14:04:03 -0500
Subject: [R-sig-ME] nlmer model specification
In-Reply-To: <AANLkTinLf7UT-Lb18NJe+f69Win0kJbSXT+pXkftQS6V@mail.gmail.com>
References: <mailman.5.1292929202.28946.r-sig-mixed-models@r-project.org>	<4D10B610.1010800@ekol.slu.se>	<4D110367.8010005@mi.nmfs.gov>
	<AANLkTinLf7UT-Lb18NJe+f69Win0kJbSXT+pXkftQS6V@mail.gmail.com>
Message-ID: <4D124BA3.8010009@mi.nmfs.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101222/267b5ed4/attachment.pl>

From datkins at u.washington.edu  Wed Dec 22 23:01:12 2010
From: datkins at u.washington.edu (David Atkins)
Date: Wed, 22 Dec 2010 14:01:12 -0800
Subject: [R-sig-ME] Does MCMCglmm allow offset?
In-Reply-To: <4D10F10E.6050504@ebc.uu.se>
References: <4D10F10E.6050504@ebc.uu.se>
Message-ID: <4D127528.7060606@u.washington.edu>


Thanks to both Gustaf and Jens for their responses.  In a nutshell, I 
wasn't thinking like a Bayesian! ;)

Let me unpack their proposals, to confirm *I* understand, and also so 
that there is a record of why this likely works with MCMCglmm.

With Poisson regression (and it cousins) we assume a constant exposure, 
that is, if we are examining number of problems related to drinking, we 
assume that the time over which these problems occurred is constant 
across people.  If this exposure varies across people, then we typically 
include the log of the exposure time as an "offset" term in the model 
(effectively changing the count to a rate per specified time).

The key issue here is that the offset term is essentially an unmodelled 
regression parameter, where the coefficient is set equal to 1.

What Gustaf and Jens both point out is that we can use the prior 
distribution of the fixed-effects to force the coefficient of the offset 
term to be 1.

Using Gustaf's code:

On 12/21/10 10:25 AM, Gustaf Granath wrote:
[snip]

>
> prior2 = list(B= list (mu = matrix(c(0,1,0,0,0),5),V = diag(5)*1e+6))

The B component of the prior is the prior for the fixed-effects; the 
critical piece above is that the term for the offset is set to have a 
mean of 1 (whereas everything else has mean 0).  The only thing to watch 
is that you know where the offset occurs in the list of variables.

> diag(prior2$B$V)[2]<-(1e-6) #change the prior variance to something small

We also want to set a very small variance around the mean of 1; the code 
above targets the variance associated with the mean of 1 and sets it to 
a really small amount.

At that point, we are ready to call MCMCglmm (eg, the call below).

Thanks again for the input.

cheers, Dave

> mcmc.off2 <- MCMCglmm(rapi ~ log(off30)+gender*time, data =
> rapi.df,family = "poisson", verbose = TRUE,
> random = ~ us(1 + time):id,prior=prior2)
> summary(mcmc.off2$Sol)
>
> Please correct me if Im wrong.
>
> Gustaf



From pmilin at ff.uns.ac.rs  Thu Dec 23 14:42:14 2010
From: pmilin at ff.uns.ac.rs (Petar Milin)
Date: Thu, 23 Dec 2010 14:42:14 +0100
Subject: [R-sig-ME] Index-terms confusion
Message-ID: <4D1351B6.1080905@ff.uns.ac.rs>

Hello all!
I noticed that many users, here and otherwise, use term "hierarchical 
models" to refer to models that are nested. However, in other places, 
one can find "hierarchical models" to refer to the "multilevel models". 
There, one determine direct/indirect relations of some predictors with 
the criterion, aiming in particular to understand mediator effects 
(significance of changes in betas of one variable when another intervene 
etc.). Recently, I realized that some of my students are quite confused 
with this terminology. How would you explain commonalities and 
differences between the two? I know about nlme plus multilevel packages 
for multilevel regression 
(http://cran.r-project.org/doc/contrib/Bliese_Multilevel.pdf). Any other 
recommendation? How about statistics that should inform about changes in 
betas? Some advices for practitioners?

Thanks,
Petar



From modlogist at gmail.com  Thu Dec 23 22:56:39 2010
From: modlogist at gmail.com (william russell)
Date: Thu, 23 Dec 2010 16:56:39 -0500
Subject: [R-sig-ME] Fwd: models for population growth
In-Reply-To: <AANLkTimBtiHLUuTtJEd=Hr1H4S0_L5n=9e_M5zutqenV@mail.gmail.com>
References: <AANLkTimBtiHLUuTtJEd=Hr1H4S0_L5n=9e_M5zutqenV@mail.gmail.com>
Message-ID: <AANLkTin=EgsTL73V_NHG4YcAwLs3RBgKzEUWeqPcDcLd@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101223/8d13e87a/attachment.pl>

From Anna.Richards at csiro.au  Fri Dec 24 01:22:08 2010
From: Anna.Richards at csiro.au (Anna.Richards at csiro.au)
Date: Fri, 24 Dec 2010 11:22:08 +1100
Subject: [R-sig-ME] design of nested mixed effects model with repeated
	measures
Message-ID: <91268D5D4CFDA744A78BAA0F930F4F857CFDC8D2B0@exvic-mbx04.nexus.csiro.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101224/41fc6119/attachment.pl>

From john.maindonald at anu.edu.au  Fri Dec 24 01:37:51 2010
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Fri, 24 Dec 2010 13:37:51 +1300
Subject: [R-sig-ME] Index-terms confusion
In-Reply-To: <4D1351B6.1080905@ff.uns.ac.rs>
References: <4D1351B6.1080905@ff.uns.ac.rs>
Message-ID: <7483CFF3-6726-477D-B213-02485E51A45B@anu.edu.au>

A strict use of language would use the term "hierarchical multilevel model" when the error terms have a hierarchical structure, e.g. subplots within
plots within blocks within sites.  One may also speak of a "hierarchical structure of variation".  In practice, "hierarchical multilevel model" is likely, in a context where multilevel models are in mind, to be abbreviated to "hierarchical model".  

In other contexts, there can be other hierarchies.  Where there is a sequence of models in which each model is nested in the next  (in the
sense that its terms are a subset of those in the next models, one may speak of this as a hierarchy of models.

You ask "How about statistics that should inform about changes in betas?"  I do not understand the intent of this question.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 24/12/2010, at 2:42 AM, Petar Milin wrote:

> Hello all!
> I noticed that many users, here and otherwise, use term "hierarchical models" to refer to models that are nested. However, in other places, one can find "hierarchical models" to refer to the "multilevel models". There, one determine direct/indirect relations of some predictors with the criterion, aiming in particular to understand mediator effects (significance of changes in betas of one variable when another intervene etc.). Recently, I realized that some of my students are quite confused with this terminology. How would you explain commonalities and differences between the two? I know about nlme plus multilevel packages for multilevel regression (http://cran.r-project.org/doc/contrib/Bliese_Multilevel.pdf). Any other recommendation? How about statistics that should inform about changes in betas? Some advices for practitioners?
> 
> Thanks,
> Petar
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From pmilin at ff.uns.ac.rs  Fri Dec 24 10:21:00 2010
From: pmilin at ff.uns.ac.rs (Petar Milin)
Date: Fri, 24 Dec 2010 10:21:00 +0100
Subject: [R-sig-ME] Index-terms confusion
In-Reply-To: <7483CFF3-6726-477D-B213-02485E51A45B@anu.edu.au>
References: <4D1351B6.1080905@ff.uns.ac.rs>
	<7483CFF3-6726-477D-B213-02485E51A45B@anu.edu.au>
Message-ID: <4D1465FC.1020307@ff.uns.ac.rs>



On 24/12/10 01:37, John Maindonald wrote:
> A strict use of language would use the term "hierarchical multilevel model" when the error terms have a hierarchical structure, e.g. subplots within
> plots within blocks within sites.  One may also speak of a "hierarchical structure of variation".  In practice, "hierarchical multilevel model" is likely, in a context where multilevel models are in mind, to be abbreviated to "hierarchical model".
>
> In other contexts, there can be other hierarchies.  Where there is a sequence of models in which each model is nested in the next  (in the
> sense that its terms are a subset of those in the next models, one may speak of this as a hierarchy of models.
>
> You ask "How about statistics that should inform about changes in betas?"  I do not understand the intent of this question.
>    
Thanks for the clarification of the term (now officially) "hierarchical 
multilevel model".
As for the send question: there is considerable literature (c.f., Baron 
& Kenny, 1986; Robins & Greenland, 1992; Pearl, 2000; Muller, Judd, & 
Yzerbyt, 2005 etc.) of something which is also known as "mediation 
analysis". Sometimes, this group of techniques uses the term "multilevel 
modeling". To my understanding (and it is shallow, I confess, I only 
played with these techniques to get some general impression), index-term 
for this family of techniques could be "path analysis" or "causal 
analysis", and is related to SEM. This is exact point of confusion.
In the abovementioned techniques, changes of betas should inform 
researcher about "partial" or "complete" mediation of one variable that 
intervenes between the predictor and the criterion. In the toy-example I 
played with, structure was such that mother's iq-score was mediated by 
some score on achievement-motivation test, to some assessments of 
high-schoolers.

Best,
Petar



From andydolman at gmail.com  Fri Dec 24 17:45:57 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Fri, 24 Dec 2010 17:45:57 +0100
Subject: [R-sig-ME] design of nested mixed effects model with repeated
	measures
In-Reply-To: <91268D5D4CFDA744A78BAA0F930F4F857CFDC8D2B0@exvic-mbx04.nexus.csiro.au>
References: <91268D5D4CFDA744A78BAA0F930F4F857CFDC8D2B0@exvic-mbx04.nexus.csiro.au>
Message-ID: <AANLkTinDFe-EfVRGN4A+YMg+VON6F7PZc9+kzERyOqfP@mail.gmail.com>

Hello Anna,

My first reaction on reading this was that your random effects
structure is far too complicated. In fact, I'm not sure you need to be
using mixed effects models at all.

> model1_lme<-lme (y~patch*date*fire ,random=~1|date/block/fire/patch/replicate)

There are a few issues I can see:

Fire is not nested in block at all, it is crossed, and it is not
random either. So fire should go from your random effects structure.

> model1_lme<-lme (y~patch*date*fire ,random=~1|date/block/patch/replicate)

Patch is not random either and even if it were it only has 2 levels
and so cannot properly be fit as random. It's also crossed with block
and with fire. (It's also a confusing name. Consider calling it
habitat, or canopy(T,F))

> model1_lme<-lme (y~patch*date*fire ,random=~1|date/block/replicate)

Replicate is nested in block but if treated as such should be coded as
1:12 rather than 1:3 inside fire. Also a good idea to make the coding
explicit that the reps are in different patches so A1-A12, B1-B12 etc.

> model1_lme<-lme (y~patch*date*fire ,random=~1|date/block/replicate)  # recode replicate so that they are unique


Date depends a bit on whether you are treating is as a factor or as a
continuous variable. However, either way it is crossed with everything
else.

> model1_lme<-lme (y~patch*date*fire ,random=~date|block/replicate)  # if date is a continuous variable
> model1_lme<-lme (y~patch*date*fire ,random=~1|block/replicate)  # if date is factor

The other consideration is that to fit a random variable you really
need at least 5 levels and block only has 3.


Christmas is about to officially start apparently, so I'm off.


Andy.


andydolman at gmail.com



On 24 December 2010 01:22,  <Anna.Richards at csiro.au> wrote:
> Hello,
>
> I am having a lot of difficulty specifying a mixed effects model structure for analysing some soil nutrient data. I have been reading a lot about mixed effects models from books and the R mailing lists and I thought I had my design sorted until I had some feedback from reviewers that suggested otherwise. My design is as follows:
>
> I have collected data from a fire experiment which has a randomised block design. There are three blocks of vegetation and each block is separated into 4 plots that get burnt at 4 different frequencies. I sampled soil from each of these 12 plots, however, I stratified my sampling by tree cover ('patch'). That is, I took 3 samples from beneath tree canopies and 3 samples away from canopies in each plot (the samples were actually composite samples made from bulking 8 individual soil samples collected over a 2 x 2m grid). I performed this sampling directly after the experimental burns were undertaken and at a further 4 other time points (2 weeks, 1 month, 3 months, 5 months) after the fires. At each time point I made sure that soil samples were collected a small distance away from the previous collections, but still ?beneath the same canopy conditions.
>
> Fire: factor with 4 levels: 1,2,5,0
> Block: factor with 3 levels: A, B, C
> Patch: factor with 2 levels: T, I
> Replicate: factor with 3 levels: 1, 2, 3
> Date (time since fire): 1, 12, 28, 55, 152
>
> Total number of observation: 359 (one missing observation)
>
> Response: soil amino acid concentration
> Fixed effects: patch, date, fire
>
> I wanted to treat block as a random effect and then because replicate samples taken from each patch type are nested within fire treatments I designed my random effects as block/fire/patch/replicate. However, because I took samples at different dates I wanted to account for the fact that samples collected from one time point are more closely related than samples collected at another time point. I also checked that there was no auto-correlation in my residuals using the corSpher correlation function (ie. that samples taken closer together e.g. days 1 and 12 are more highly correlated than samples taken further apart e.g. days 1 and 155) and I didn't find this to be a problem. The main difference of opinion has been where to place the 'date' term in the random effects. My original design was:
>
> model1_lme<-lme (y~patch*date*fire ,random=~1|date/block/fire/patch/replicate)
>
> but it was suggested that I should instead use:
>
> model1_lme<-lme (y~patch*date*fire ,random=~1|block/fire/patch/replicate/date)
> or
> model1_lme<-lme (y~patch*date*fire ,random=~1|date/block/fire/patch/date/replicate)
>
> Both these alternative models don't make sense to me but I am very new to mixed models so perhaps they are correct? Additionally, I understand that this group uses lmer and perhaps that is what I need to start using for these complicated designs? Lastly, I tried including date as a random covariate: random =~date|block/fire/patch/replicate but I receive the error:
>
> Error in logLik.lmeStructInt(lmeSt, lmePars) :
> ?NA/NaN/Inf in foreign function call (arg 3)
> In addition: There were 50 or more warnings (use warnings() to see the first 50)
>> warnings()
> Warning messages:
> 1: In logLik.lmeStructInt(lmeSt, lmePars) :
> ?Singular precision matrix in level -2, block 1
> Etc
>
> Any suggestions would be much appreciated, we don't have any statistics support in my lab so I feel very much in the dark when it comes to these things.
> Thanks!
> Anna
> Dr Anna Richards
> OCE Postdoctoral Fellow
> CSIRO Ecosystem Sciences
> Darwin, Australia
>
>
> Dr Anna Richards
> OCE Postdoctoral Fellow
> CSIRO Ecosystem Sciences
> Phone: +61 8 89448437 | Fax: +61 8 89448444 | Mobile: 0423 971 997
> anna.richards at csiro.au<mailto:anna.richards at csiro.au> | www.csiro.au | www.csiro.au/people/Anna.Richards.html
> Address: CSIRO Tropical Ecosystems Research Centre, 564 Vanderlin Drive, Berrimah NT 0828 Australia. (Postal address: PMB 44, Winnellie NT 0822)
>
> PLEASE NOTE
> The information contained in this email may be confidential or privileged. Any unauthorised use or disclosure is prohibited. If you have received this email in error, please delete it immediately and notify the sender by return email. Thank you. To the extent permitted by law, CSIRO does not represent, warrant and/or guarantee that the integrity of this communication has been maintained or that the communication is free of errors, virus, interception or interference.
> Please consider the environment before printing this email.
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From jmblanco at ub.edu  Fri Dec 24 20:53:19 2010
From: jmblanco at ub.edu (=?UTF-8?B?Sm9zw6kgTWFudWVsIEJsYW5jbyBNb3Jlbm8=?=)
Date: Fri, 24 Dec 2010 20:53:19 +0100
Subject: [R-sig-ME] design of nested mixed effects model with repeated
 measures
In-Reply-To: <AANLkTinDFe-EfVRGN4A+YMg+VON6F7PZc9+kzERyOqfP@mail.gmail.com>
References: <91268D5D4CFDA744A78BAA0F930F4F857CFDC8D2B0@exvic-mbx04.nexus.csiro.au>
	<AANLkTinDFe-EfVRGN4A+YMg+VON6F7PZc9+kzERyOqfP@mail.gmail.com>
Message-ID: <4D14FA2F.6060301@ub.edu>

El 24/12/2010 17:45, Andrew Dolman escribi?:
> Patch is not random either and even if it were it only has 2 levels
> and so cannot properly be fit as random. It's also crossed with block
> and with fire. (It's also a confusing name. Consider calling it
> habitat, or canopy(T,F))
>
I may be misunderstanding the design, but I would be somewhat reluctant to throw 
away the random effect for patch. Indeed I think that Andrew is right when 
considering renaming this factor as canopy or habitat (a factor wih two levels); 
however, if the "replicates" are taken from beneath a single canopy (instead of 
selecting different canopies from a plot), should not this nesting be included 
in the random effects, even if the structure seems complicated?
Moreover, I do not think that canopy and plot are crossed, since you cannot move 
one canopy from one plot to another, and each canopy on each plot is actually a 
different individual.
Forgive me if I got it completely wrong. And merry Christmas by the way.


-- 
---------------------------------------
Jos? M. Blanco Moreno

Dept. de Biologia Vegetal (Bot?nica)
Universitat de Barcelona
Av. Diagonal 645
08028 Barcelona SPAIN
---------------------------------------

phone: (+34) 934 039 863
fax: (+34) 934 112 842
e-mail: jmblanco at ub.edu



From pierces1 at msu.edu  Sun Dec 26 16:51:58 2010
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Sun, 26 Dec 2010 10:51:58 -0500
Subject: [R-sig-ME] Index-terms confusion
In-Reply-To: <4D1465FC.1020307@ff.uns.ac.rs>
References: <4D1351B6.1080905@ff.uns.ac.rs>	<7483CFF3-6726-477D-B213-02485E51A45B@anu.edu.au>
	<4D1465FC.1020307@ff.uns.ac.rs>
Message-ID: <004f01cba514$d46c56f0$7d4504d0$@msu.edu>

Petar,

Mediation analysis is not necessarily tied to multilevel models. While you
can certainly test meditation hypotheses with multilevel models, you can
also test them in data that do not have the grouped or nested structure
associated with mixed effects models. 

Broadly speaking, mediation analyses are aimed at testing theories about
causal chains of variables so that you can better understand the process by
which one variable influences another. For example, if you believe that
variable A only has an indirect influence on variable C because of the way
it affects variable B, you can draw a path diagram  (A --> B --> C ), then
test the mediation hypotheses using various techniques described in
MacKinnon, Fairchild, & Fritz (2007)or MacKinnon (2008). The modern way to
test those hypotheses is via structural equation modeling (SEM), which can
also adjust for multilevel structure as well if you use software like Mplus.


It may help to remember that ultimately, multilevel models are a method for
correctly representing the non-independence of observations that may arise
because of how you did the sampling. They let you test all the sorts of
things you can test with simpler regression models, plus a few new
hypotheses about the variance structures.  Meanwhile, mediation analyses are
more narrow in scope and defined by the kind of hypothesis you are testing
than by the specific statistical model you are using to do so.


MacKinnon, D. P., Fairchild, A. J., & Fritz, M. S. (2007). Mediation
analysis. Annual Review of Psychology, 58, 593-614. doi:
10.1146/annurev.psych.58.110405.085542 

MacKinnon, D. P. (2008). Introduction to statistical mediation analysis. New
York, NY: Taylor & Francis Group, LLC.


Steven J. Pierce, Ph.D. 
Associate Director 
Center for Statistical Training & Consulting (CSTAT) 
Michigan State University 
178 Giltner Hall 
East Lansing, MI 48824 
E-mail: pierces1 at msu.edu 
Web: http://www.cstat.msu.edu 

-----Original Message-----
From: Petar Milin [mailto:pmilin at ff.uns.ac.rs] 
Sent: Friday, December 24, 2010 4:21 AM
To: John Maindonald
Cc: r-sig-mixed-models at r-project.org Mixed
Subject: Re: [R-sig-ME] Index-terms confusion



On 24/12/10 01:37, John Maindonald wrote:
> A strict use of language would use the term "hierarchical multilevel
model" when the error terms have a hierarchical structure, e.g. subplots
within
> plots within blocks within sites.  One may also speak of a "hierarchical
structure of variation".  In practice, "hierarchical multilevel model" is
likely, in a context where multilevel models are in mind, to be abbreviated
to "hierarchical model".
>
> In other contexts, there can be other hierarchies.  Where there is a
sequence of models in which each model is nested in the next  (in the
> sense that its terms are a subset of those in the next models, one may
speak of this as a hierarchy of models.
>
> You ask "How about statistics that should inform about changes in betas?"
I do not understand the intent of this question.
>    
Thanks for the clarification of the term (now officially) "hierarchical 
multilevel model".
As for the send question: there is considerable literature (c.f., Baron 
& Kenny, 1986; Robins & Greenland, 1992; Pearl, 2000; Muller, Judd, & 
Yzerbyt, 2005 etc.) of something which is also known as "mediation 
analysis". Sometimes, this group of techniques uses the term "multilevel 
modeling". To my understanding (and it is shallow, I confess, I only 
played with these techniques to get some general impression), index-term 
for this family of techniques could be "path analysis" or "causal 
analysis", and is related to SEM. This is exact point of confusion.
In the abovementioned techniques, changes of betas should inform 
researcher about "partial" or "complete" mediation of one variable that 
intervenes between the predictor and the criterion. In the toy-example I 
played with, structure was such that mother's iq-score was mediated by 
some score on achievement-motivation test, to some assessments of 
high-schoolers.

Best,
Petar



From pmilin at ff.uns.ac.rs  Sun Dec 26 18:00:38 2010
From: pmilin at ff.uns.ac.rs (Petar Milin)
Date: Sun, 26 Dec 2010 18:00:38 +0100
Subject: [R-sig-ME] Index-terms confusion
In-Reply-To: <004f01cba514$d46c56f0$7d4504d0$@msu.edu>
References: <4D1351B6.1080905@ff.uns.ac.rs>	<7483CFF3-6726-477D-B213-02485E51A45B@anu.edu.au>
	<4D1465FC.1020307@ff.uns.ac.rs>
	<004f01cba514$d46c56f0$7d4504d0$@msu.edu>
Message-ID: <4D1774B6.3050306@ff.uns.ac.rs>

Dear Steven,
This is very elaborated and precise explanation. Thank you very much!
Moreover, this is exactly what I learned about these terms. Recently, 
few of my students were confused with "multilevel models" term used in 
sense of "mediation analysis".

Thanks, again! Best,
Petar

On 26/12/10 16:51, Steven J. Pierce wrote:
> Petar,
>
> Mediation analysis is not necessarily tied to multilevel models. While you
> can certainly test meditation hypotheses with multilevel models, you can
> also test them in data that do not have the grouped or nested structure
> associated with mixed effects models.
>
> Broadly speaking, mediation analyses are aimed at testing theories about
> causal chains of variables so that you can better understand the process by
> which one variable influences another. For example, if you believe that
> variable A only has an indirect influence on variable C because of the way
> it affects variable B, you can draw a path diagram  (A -->  B -->  C ), then
> test the mediation hypotheses using various techniques described in
> MacKinnon, Fairchild,&  Fritz (2007)or MacKinnon (2008). The modern way to
> test those hypotheses is via structural equation modeling (SEM), which can
> also adjust for multilevel structure as well if you use software like Mplus.
>
>
> It may help to remember that ultimately, multilevel models are a method for
> correctly representing the non-independence of observations that may arise
> because of how you did the sampling. They let you test all the sorts of
> things you can test with simpler regression models, plus a few new
> hypotheses about the variance structures.  Meanwhile, mediation analyses are
> more narrow in scope and defined by the kind of hypothesis you are testing
> than by the specific statistical model you are using to do so.
>
>
> MacKinnon, D. P., Fairchild, A. J.,&  Fritz, M. S. (2007). Mediation
> analysis. Annual Review of Psychology, 58, 593-614. doi:
> 10.1146/annurev.psych.58.110405.085542
>
> MacKinnon, D. P. (2008). Introduction to statistical mediation analysis. New
> York, NY: Taylor&  Francis Group, LLC.
>
>
> Steven J. Pierce, Ph.D.
> Associate Director
> Center for Statistical Training&  Consulting (CSTAT)
> Michigan State University
> 178 Giltner Hall
> East Lansing, MI 48824
> E-mail: pierces1 at msu.edu
> Web: http://www.cstat.msu.edu
>
> -----Original Message-----
> From: Petar Milin [mailto:pmilin at ff.uns.ac.rs]
> Sent: Friday, December 24, 2010 4:21 AM
> To: John Maindonald
> Cc: r-sig-mixed-models at r-project.org Mixed
> Subject: Re: [R-sig-ME] Index-terms confusion
>
>
>
> On 24/12/10 01:37, John Maindonald wrote:
>    
>> A strict use of language would use the term "hierarchical multilevel
>>      
> model" when the error terms have a hierarchical structure, e.g. subplots
> within
>    
>> plots within blocks within sites.  One may also speak of a "hierarchical
>>      
> structure of variation".  In practice, "hierarchical multilevel model" is
> likely, in a context where multilevel models are in mind, to be abbreviated
> to "hierarchical model".
>    
>> In other contexts, there can be other hierarchies.  Where there is a
>>      
> sequence of models in which each model is nested in the next  (in the
>    
>> sense that its terms are a subset of those in the next models, one may
>>      
> speak of this as a hierarchy of models.
>    
>> You ask "How about statistics that should inform about changes in betas?"
>>      
> I do not understand the intent of this question.
>    
>>
>>      
> Thanks for the clarification of the term (now officially) "hierarchical
> multilevel model".
> As for the send question: there is considerable literature (c.f., Baron
> &  Kenny, 1986; Robins&  Greenland, 1992; Pearl, 2000; Muller, Judd,&
> Yzerbyt, 2005 etc.) of something which is also known as "mediation
> analysis". Sometimes, this group of techniques uses the term "multilevel
> modeling". To my understanding (and it is shallow, I confess, I only
> played with these techniques to get some general impression), index-term
> for this family of techniques could be "path analysis" or "causal
> analysis", and is related to SEM. This is exact point of confusion.
> In the abovementioned techniques, changes of betas should inform
> researcher about "partial" or "complete" mediation of one variable that
> intervenes between the predictor and the criterion. In the toy-example I
> played with, structure was such that mother's iq-score was mediated by
> some score on achievement-motivation test, to some assessments of
> high-schoolers.
>
> Best,
> Petar
>
>
>
>
>



From Mike.Lawrence at dal.ca  Sun Dec 26 21:50:18 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Sun, 26 Dec 2010 16:50:18 -0400
Subject: [R-sig-ME] obtaining the range of a poly()'d fixed effect variable
	from an lmer object
Message-ID: <AANLkTikf1No6X-t3XStPRo0dTPp3mHdTqREPQFouzBuA@mail.gmail.com>

Hi folks,

I'm working on an update to the "ez" package, which has an
"ezPredict()" function to compute fixed effects predictions from an
lmer object. The version currently on CRAN breaks when the lmer object
was created with a formula in which poly() is used within the fixed
effects. I have a solution to this, but I need to know the range of
values for each fixed effect that is poly()'d, which doesn't seem to
be obtainable anywhere in the lmer object so far as I can tell (unlike
the case where a variable is numeric but not modified by poly(), in
which the range of the variable is easily obtained from the "frame"
attribute of the lmer object). Have I not looked hard enough?

For example, using the ANT data set from the ez package, I might
create the model:
fit = lmer(
    rt ~ (1|subnum) + poly(block,3)*poly(trial,3)*cue*flank*group
    , data = ANT[ANT$error==0,]
)

For ezPredict() to obtain predictions, I'd need to find the range of
the variables "block" and "trial". Thoughts?

Cheers,

Mike

--
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~



From Anna.Richards at csiro.au  Sun Dec 26 21:51:47 2010
From: Anna.Richards at csiro.au (Anna.Richards at csiro.au)
Date: Mon, 27 Dec 2010 07:51:47 +1100
Subject: [R-sig-ME] design of nested mixed effects model with repeated
 measures
In-Reply-To: <4D14FA2F.6060301@ub.edu>
References: <91268D5D4CFDA744A78BAA0F930F4F857CFDC8D2B0@exvic-mbx04.nexus.csiro.au>
	<AANLkTinDFe-EfVRGN4A+YMg+VON6F7PZc9+kzERyOqfP@mail.gmail.com>,
	<4D14FA2F.6060301@ub.edu>
Message-ID: <91268D5D4CFDA744A78BAA0F930F4F857CFDCD3ECE@exvic-mbx04.nexus.csiro.au>

Thanks Jose and Andrew for the advice, especially so close to Christmas!

I included patch (or canopy type) in the random part of the model because I thought that the three samples taken from each patch type within a fire treatment are more closely related spatially than samples from other fire treatment. (Each 'patch' sample 'pseudo-replicate' was taken from beneath or far from a different tree canopy across the 1 hectare fire treatment plots). Does this mean I should nest patch within block in the random effects?

ie. y~patch*date*block, random=~1|block/patch/replicate  

Thanks again,
Anna
________________________________________
From: Jos? Manuel Blanco Moreno [jmblanco at ub.edu]
Sent: Saturday, December 25, 2010 6:53 AM
To: Andrew Dolman
Cc: Richards, Anna (CES, Darwin); r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] design of nested mixed effects model with repeated measures

El 24/12/2010 17:45, Andrew Dolman escribi?:
> Patch is not random either and even if it were it only has 2 levels
> and so cannot properly be fit as random. It's also crossed with block
> and with fire. (It's also a confusing name. Consider calling it
> habitat, or canopy(T,F))
>
I may be misunderstanding the design, but I would be somewhat reluctant to throw
away the random effect for patch. Indeed I think that Andrew is right when
considering renaming this factor as canopy or habitat (a factor wih two levels);
however, if the "replicates" are taken from beneath a single canopy (instead of
selecting different canopies from a plot), should not this nesting be included
in the random effects, even if the structure seems complicated?
Moreover, I do not think that canopy and plot are crossed, since you cannot move
one canopy from one plot to another, and each canopy on each plot is actually a
different individual.
Forgive me if I got it completely wrong. And merry Christmas by the way.


--
---------------------------------------
Jos? M. Blanco Moreno

Dept. de Biologia Vegetal (Bot?nica)
Universitat de Barcelona
Av. Diagonal 645
08028 Barcelona SPAIN
---------------------------------------

phone: (+34) 934 039 863
fax: (+34) 934 112 842
e-mail: jmblanco at ub.edu



From andydolman at gmail.com  Mon Dec 27 01:01:23 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Mon, 27 Dec 2010 01:01:23 +0100
Subject: [R-sig-ME] design of nested mixed effects model with repeated
	measures
In-Reply-To: <91268D5D4CFDA744A78BAA0F930F4F857CFDCD3ECE@exvic-mbx04.nexus.csiro.au>
References: <91268D5D4CFDA744A78BAA0F930F4F857CFDC8D2B0@exvic-mbx04.nexus.csiro.au>
	<AANLkTinDFe-EfVRGN4A+YMg+VON6F7PZc9+kzERyOqfP@mail.gmail.com>
	<4D14FA2F.6060301@ub.edu>
	<91268D5D4CFDA744A78BAA0F930F4F857CFDCD3ECE@exvic-mbx04.nexus.csiro.au>
Message-ID: <AANLkTinOhHL4RjR5iZKhp6CnFuiiSQQW1JuTfc0VziM9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101227/30d1cf3d/attachment.pl>

From Mike.Lawrence at dal.ca  Tue Dec 28 17:12:10 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Tue, 28 Dec 2010 12:12:10 -0400
Subject: [R-sig-ME] For list review: an update to the ezPredict() function
Message-ID: <AANLkTin50Z-L-0YCkUPmpr+8ww16+iF+5BKoQgSXqq3H@mail.gmail.com>

Hi folks,

As I've mentioned in previous posts, I maintain the "ez" package and
of late I've been coding a number of functions that aim to provide
shortcuts for very simple mixed effects modelling. I'm working on an
update to the ezPredict() function. The version on CRAN simply
provides fixed-effects predictions from an lmer object as proscribed
by the "Predictions and/or confidence (or prediction) intervals on
predictions" section at http://glmm.wikidot.com/faq. I coded an update
(https://gist.github.com/757342) that *I think* allows the user to ask
for predictions from the model for designs that do not constitute the
full model; that is, if the full model is "y ~ x*z", the new code
allows the user to request predictions from the simpler model "y ~ x",
or if the full model is "y ~ x*z*q", the user can request predictions
from the simpler model "y ~ x*q", etc. I think this will be useful for
visualizing lower order effects in designs with multiple interacting
fixed effects.

As I've also mentioned in previous posts, I'm still very much a mixed
effects beginner so I'd appreciate the list's feedback on whether I've
coded this appropriately. Specifically, I don't think that the
approach I take in the code would return the appropriate predicted
values and variances if the model provided to ezPredict was fit with
treatment contrasts. This is why line 27, if uncommented, halts
variables with treatment contrasts are detected. However, this notion
that models fitted with treatment contrasts would yield inaccurate
prediction values and variances is based on simply the rather informal
observation that when I let it attempt prediction in such cases
(leaving line 27 commented), the resulting predictions seem not to
vary from those of the intercept level of the corresponding full
model, which doesn't seem right. That is, using the ANT data set from
the ez package, I can run:

library(ez)
data(ANT)

options(contrasts=c('contr.treatment','contr.poly'))
this_fit = lmer(
    formula = rt ~ (1|subnum) + cue*flank
    , data = ANT[ANT$error==0,]
)
ezPredict(this_fit) #request the default full design predictions

#which yields:
       cue       flank    value      var
1     None     Neutral 428.1463 6.635549
2   Center     Neutral 380.6527 6.462319
3   Double     Neutral 374.7787 6.462646
4  Spatial     Neutral 340.0514 6.476256
5     None   Congruent 427.8102 6.519188
6   Center   Congruent 378.6538 6.547445
7   Double   Congruent 375.4768 6.448728
8  Spatial   Congruent 340.6319 6.634970
9     None Incongruent 497.3793 6.490352
10  Center Incongruent 467.9080 6.393626
11  Double Incongruent 459.9358 6.448578
12 Spatial Incongruent 412.9730 6.286458

#attempt to get predictions for the main effect of flank
ezPredict(
    fit = this_fit
    , to_predict = .(flank)
)

#which yields:
        flank    value      var
1     Neutral 428.1463 6.635549
2   Congruent 427.8102 6.519188
3 Incongruent 497.3793 6.490352

#which is identical to the predictions for the levels of flank when cue=='None'.

#compare to contr.sum:
options(contrasts=c('contr.sum','contr.poly'))
this_fit = lmer(
    formula = rt ~ (1|subnum) + cue*flank
    , data = ANT[ANT$error==0,]
)
ezPredict(this_fit) #request the default full design predictions

#same as before:
       cue       flank    value      var
1     None     Neutral 428.1463 6.635549
2   Center     Neutral 380.6527 6.462319
3   Double     Neutral 374.7787 6.462646
4  Spatial     Neutral 340.0514 6.476256
5     None   Congruent 427.8102 6.519188
6   Center   Congruent 378.6538 6.547445
7   Double   Congruent 375.4768 6.448728
8  Spatial   Congruent 340.6319 6.634970
9     None Incongruent 497.3793 6.490352
10  Center Incongruent 467.9080 6.393626
11  Double Incongruent 459.9358 6.448578
12 Spatial Incongruent 412.9730 6.286458

#but now
ezPredict(
    fit = this_fit
    , to_predict = .(flank)
)

#yields different and frankly more reasonable looking
#values for the main effect of flank
        flank    value      var
1     Neutral 380.9073 1.934647
2   Congruent 380.6432 1.942136
3 Incongruent 459.5490 1.908503


Thoughts?

Mike

--
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~



From samsteyaert at gmail.com  Tue Dec 28 18:22:05 2010
From: samsteyaert at gmail.com (sam steyaert)
Date: Tue, 28 Dec 2010 18:22:05 +0100
Subject: [R-sig-ME] lmer() - no applicable method for 'profile'
In-Reply-To: <AANLkTi=E-hNhHrqSmmy3m12mCd2r=uJDoziBgE_agkX8@mail.gmail.com>
References: <OFCD5E23BB.46ED04AF-ON802577EE.00612C79-802577EE.00620C8E@EliLilly.lilly.com>
	<4CFCE2E9.9090709@gmail.com>
	<loom.20101221T185613-872@post.gmane.org>
	<4D10EDE3.8070208@gmail.com>
	<AANLkTimKFeXn2OevR6=92JtYUBn-CZijXyBxH30mLtOj@mail.gmail.com>
	<4D10F171.9070005@gmail.com> <4D11BD5A.7090504@cirad.fr>
	<4D11FFEB.4050606@gmail.com>
	<AANLkTi=E-hNhHrqSmmy3m12mCd2r=uJDoziBgE_agkX8@mail.gmail.com>
Message-ID: <AANLkTimKQfA5WvgVaQu9GuJyfhZy6KOrpWovmCUdqAoX@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101228/115641f6/attachment.pl>

From djmuser at gmail.com  Wed Dec 29 01:20:13 2010
From: djmuser at gmail.com (Dennis Murphy)
Date: Tue, 28 Dec 2010 16:20:13 -0800
Subject: [R-sig-ME] lmer() - no applicable method for 'profile'
In-Reply-To: <AANLkTimKQfA5WvgVaQu9GuJyfhZy6KOrpWovmCUdqAoX@mail.gmail.com>
References: <OFCD5E23BB.46ED04AF-ON802577EE.00612C79-802577EE.00620C8E@EliLilly.lilly.com>
	<4CFCE2E9.9090709@gmail.com>
	<loom.20101221T185613-872@post.gmane.org>
	<4D10EDE3.8070208@gmail.com>
	<AANLkTimKFeXn2OevR6=92JtYUBn-CZijXyBxH30mLtOj@mail.gmail.com>
	<4D10F171.9070005@gmail.com> <4D11BD5A.7090504@cirad.fr>
	<4D11FFEB.4050606@gmail.com>
	<AANLkTi=E-hNhHrqSmmy3m12mCd2r=uJDoziBgE_agkX8@mail.gmail.com>
	<AANLkTimKQfA5WvgVaQu9GuJyfhZy6KOrpWovmCUdqAoX@mail.gmail.com>
Message-ID: <AANLkTinvPrc1Lr2cANLvubQGB59VXomHaMg7qh89-peR@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101228/90b31364/attachment.pl>

From bates at stat.wisc.edu  Wed Dec 29 02:03:43 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 28 Dec 2010 19:03:43 -0600
Subject: [R-sig-ME] lmer() - no applicable method for 'profile'
In-Reply-To: <AANLkTinvPrc1Lr2cANLvubQGB59VXomHaMg7qh89-peR@mail.gmail.com>
References: <OFCD5E23BB.46ED04AF-ON802577EE.00612C79-802577EE.00620C8E@EliLilly.lilly.com>
	<4CFCE2E9.9090709@gmail.com>
	<loom.20101221T185613-872@post.gmane.org>
	<4D10EDE3.8070208@gmail.com>
	<AANLkTimKFeXn2OevR6=92JtYUBn-CZijXyBxH30mLtOj@mail.gmail.com>
	<4D10F171.9070005@gmail.com> <4D11BD5A.7090504@cirad.fr>
	<4D11FFEB.4050606@gmail.com>
	<AANLkTi=E-hNhHrqSmmy3m12mCd2r=uJDoziBgE_agkX8@mail.gmail.com>
	<AANLkTimKQfA5WvgVaQu9GuJyfhZy6KOrpWovmCUdqAoX@mail.gmail.com>
	<AANLkTinvPrc1Lr2cANLvubQGB59VXomHaMg7qh89-peR@mail.gmail.com>
Message-ID: <AANLkTimLi0nJOZi_bDPwMfTFHXhfeGK+2FUGmLBRXDM=@mail.gmail.com>

Thanks for checking that out, Dennis.  I will produce updated scripts
etc. if I ever finish my grading of project reports.  (Well I have to
finish them because the grades are due tomorrow.)

The env stuff has gone away to be replaced by reference classes,
something that John Chambers added to R-2.12.0.  They are based on
environments but indirectly.

On Tue, Dec 28, 2010 at 6:20 PM, Dennis Murphy <djmuser at gmail.com> wrote:
> Hi:
>
> I decided to check Sam's claims but couldn't reproduce them, at least in
> Chapter 1. Sam, please check out the sessionInfo() and see if you have the
> same packages loaded with the same versions. [I autoload ggplot2, lattice
> and sos; of these, only lattice is relevant to lme4(a).]
>
> OTOH, some glitches did appear when I ran the code chunks from Chapter 1 of
> the draft book:
>
> (i) env() could not be found (missing package, maybe?);
> (ii) running splom() opens up the browser.
>
> Abridged transcript:
>
> ####### Chunk 16, Ch. 1:
>
> env(fm1ML)$Lambda
> Error: could not find function "env"
>
> ####### Chunk 17 (ditto 18)...which makes sense given the result of 16:
>
>> print(image(env(fm1)$Lambda, sub=NULL, xlab=NULL, ylab=NULL))
> Error in print(image(env(fm1)$Lambda, sub = NULL, xlab = NULL, ylab = NULL))
> :
> ?error in evaluating the argument 'x' in selecting a method for function
> 'print'
>
>
> ####### Chunks 19 and 20 work, as does everything through chunk 26:
>> pr1 <- profile(fm1ML)
>> print(xyplot(pr1, aspect = 1.3))
>
>
> ####### Chunk 27 (and by extension, 28):
> ####### calling splom() opens up the browser
> ####### the plot seems to render correctly, though
>
>> print(splom(pr1))
> Called from: function (x, y, groups, subscripts, i, j, ...)
> {
> ? ?tr <- traces[[j]][[i]]
> ? ?browser()
> ? ?grid::pushViewport(viewport(xscale = c(-1.07, 1.07) * mlev,
> ? ? ? ?yscale = c(-1.07, 1.07) * mlev))
> ? ?dd <- sapply(current.panel.limits(), diff)/50
> ? ?psij <- predict(tr$sij)
> ? ?ll <- tr$ll
> ? ?panel.grid(h = -1, v = -1)
> ? ?llines(psij$y, psij$x, ...)
> ? ?llines(predict(tr$sji), ...)
> ? ?with(ll$tki, lsegments(y - dd[1], x, y + dd[1], x, ...))
> ? ?with(ll$tkj, lsegments(x, y - dd[2], x, y + dd[2], ...))
> ? ?for (k in seq_along(levels)) llines(ll$pts[k, , ], ...)
> ? ?grid::popViewport(1)
> }(x = c(3.51976904877845, 4.41462262361588), y = c(0, 145.71944617029
> ), groups = NULL, subscripts = 1:2, i = 1L, j = 2L)
> Browse[1]>
>
> ?<message iterates three times as I hit CRs to advance the browser and then
> exits without error>
>
> Everything else in Chapter 1 seems to work fine, though, including profile()
> and its plots.
>
>> sessionInfo()
> R version 2.12.1 Patched (2010-12-18 r53869)
> Platform: x86_64-pc-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252 ?LC_CTYPE=English_United
> States.1252
> [3] LC_MONETARY=English_United States.1252
> LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] splines ? stats ? ? graphics ?grDevices utils ? ? datasets ?grid
> methods
> [9] base
>
> other attached packages:
> ?[1] lme4a_0.999375-59 ?MatrixModels_0.2-1 minqa_1.1.13
> Rcpp_0.9.0
> ?[5] Matrix_0.999375-46 sos_1.3-0 ? ? ? ? ?brew_1.0-4
> lattice_0.19-13
> ?[9] ggplot2_0.8.9 ? ? ?proto_0.3-8 ? ? ? ?reshape_0.8.3
> plyr_1.2.1
>
> loaded via a namespace (and not attached):
> [1] codetools_0.2-6 nlme_3.1-97 ? ? stats4_2.12.1 ? tools_2.12.1
>
> Hope this is of some help.
> Dennis
>
> On Tue, Dec 28, 2010 at 9:22 AM, sam steyaert <samsteyaert at gmail.com> wrote:
>
>> Dear all,
>>
>> I am relatively new to this list. I would like to use the 'profile'
>> function of the lme4a package. I followed the instructions by Ben Bolker.
>>
>> "Yes. ?For now I think
>>
>> install.packages("lme4a",repos="http://www.math.mcmaster.ca/bolker/R")
>>
>> or
>> manually getting
>> <
>> http://www.math.mcmaster.ca/bolker/R/bin/windows/contrib/2.12/lme4a_0.999375-59.zip
>> >
>> ?should work. "
>>
>> I still get the error message as mentioned before:
>>
>> "Error in UseMethod("profile") :
>> ? no applicable method for 'profile' applied to an object of class "mer" "
>>
>> ...even if lme4a was already installed:
>>
>> " install.packages("lme4a",repos="http://www.math.mcmaster.ca/bolker/R")
>> Installing package(s) into ?d:\Documents and Settings\samst\My
>> Documents/R/win-library/2.12?
>> (as ?lib? is unspecified)
>> Warning: package 'lme4a' is in use and will not be installed"
>>
>> Can anyone help me further with this?
>>
>> Kind regards,
>>
>> Sam Steyaert
>>
>>
>>
>> 2010/12/22 Dennis Murphy <djmuser at gmail.com>
>>
>>> Hi Ben:
>>>
>>> Thanks for your early Christmas present :)
>>>
>>> Best,
>>> Dennis
>>>
>>> On Wed, Dec 22, 2010 at 5:40 AM, Ben Bolker <bbolker at gmail.com> wrote:
>>>
>>> > -----BEGIN PGP SIGNED MESSAGE-----
>>> > Hash: SHA1
>>> >
>>> > ? Yes. ?For now I think
>>> >
>>> > install.packages("lme4a",repos="http://www.math.mcmaster.ca/bolker/R")
>>> >
>>> > or
>>> >
>>> > manually getting
>>> >
>>> > <
>>> >
>>> http://www.math.mcmaster.ca/bolker/R/bin/windows/contrib/2.12/lme4a_0.999375-59.zip
>>> > >
>>> >
>>> > ?should work.
>>> >
>>> >
>>> >
>>> >
>>> > On 10-12-22 03:56 AM, lancelot wrote:
>>> > > I have a "page not found" message for this URL.
>>> > >
>>> > > Renaud
>>> > >
>>> > > Le 21/12/2010 19:26, Ben Bolker a ?crit :
>>> > > On 10-12-21 01:25 PM, Andrew Dolman wrote:
>>> > >>>> That's an lme4 binary that you linked to on r-forge. Your hosted
>>> > >>>> binary work though cheers.
>>> > >>>>
>>> > >>>> Andy.
>>> > >>>>
>>> > >>>>
>>> > >>>> andydolman at gmail.com
>>> > >>>>
>>> > >
>>> > > ? Oops. ?How about
>>> > >
>>> > > <
>>> >
>>> https://r-forge.r-project.org/bin/windows/contrib/latest/lme4a_0.999375-59.zip
>>> > >
>>> > >
>>> > >
>>> > > ? ??
>>> > >
>>> > >
>>> > >>>>
>>> > >>>>
>>> > >>>> On 21 December 2010 19:11, Ben Bolker<bbolker at gmail.com> ?wrote:
>>> > >>>>> On 10-12-21 12:58 PM, Dieter Menne wrote:
>>> > >>>>>> Ben Bolker<bbolker at ...> ?writes:
>>> > >>>>>>
>>> > >>>>>>>
>>> > >>>>>>> ? ?You need to be using the development version (lme4a).
>>> > >>>>>>> ? ?install.packages("lme4a",repos="http://r-forge.r-project.org
>>> ")
>>> > >>>>>>> ? ?if that fails, try posting sessionInfo()
>>> > >>>>>>
>>> > >>>>>> This fails on Windows, and has been reported several times
>>> already
>>> > >>>>>> and confirmed
>>> > >>>>>> as "temporary broken".
>>> > >>>>>>
>>> > >>>>>> Is there a way to get the Windows build updated?
>>> > >>>>>>
>>> > >>>>>> Dieter
>>> > >>>>>>
>>> > >>>>>> _______________________________________________
>>> > >>>>>> R-sig-mixed-models at r-project.org mailing list
>>> > >>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> > >>>>>
>>> > >>>>> ? (Resending to list)
>>> > >>>>>
>>> > >>>>> ? I've put up a recent binary (32-bit Windows, R 2.12.x): try
>>> > >>>>>
>>> > >>>>> install.packages("lme4a",repos="
>>> http://www.math.mcmaster.ca/bolker/R
>>> > ")
>>> > >>>>>
>>> > >>>>> and let me know if it works.
>>> > >>>>>
>>> > >>>>> I'm a little puzzled that install.packages() doesn't work from
>>> > R-forge,
>>> > >>>>> there seems to be a binary version there: can you download
>>> > >>>>> <
>>> >
>>> https://r-forge.r-project.org/bin/windows/contrib/latest/lme4_0.999375-37.zip
>>> > >
>>> > >>>>>
>>> > >>>>> ? ... ?
>>> > >>>>>
>>> > >>>>> ? Ben
>>> > >>>>>
>>> > >>>>> _______________________________________________
>>> > >>>>> R-sig-mixed-models at r-project.org mailing list
>>> > >>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> > >>>>>
>>> > >
>>> > >>
>>> > _______________________________________________
>>> > R-sig-mixed-models at r-project.org mailing list
>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> > >>
>>> >
>>> > -----BEGIN PGP SIGNATURE-----
>>> > Version: GnuPG v1.4.10 (GNU/Linux)
>>> > Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/
>>> >
>>> > iEYEARECAAYFAk0R/+sACgkQc5UpGjwzenOqoACghl1TkqQiCjctGxzN8OyirM2+
>>> > LqEAoIgEVJYyxpXkWonqgKaA7DC34P6G
>>> > =S50A
>>> > -----END PGP SIGNATURE-----
>>> >
>>> > _______________________________________________
>>> > R-sig-mixed-models at r-project.org mailing list
>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> >
>>>
>>> ? ? ? ?[[alternative HTML version deleted]]
>>>
>>>
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



From lucianolasala at yahoo.com.ar  Wed Dec 29 21:17:02 2010
From: lucianolasala at yahoo.com.ar (Luciano La Sala)
Date: Wed, 29 Dec 2010 17:17:02 -0300
Subject: [R-sig-ME] Coefficients interpretation and plot
Message-ID: <8DBAB477C3E64F19A5E3E6CBEC9918B4@Negro1>

Hello everyone, 

Since I'm not entirely sure this is THE list I should be referring too, feel
free to blow me off and refer me to another mailing list if necessary. 
I am analyzing a small dataset using lmer from lme4 package. My model has
"egg volume" as dependent variable and "hatching order" and "year" as
dependent variables. The best fit model has these two variables plus their
interaction (hatching order*year). I included Nest_ID as random intercepts.
Output follows: 

> best <- lmer(EggVolume~HatchOrder+Year+HatchOrder*Year+(1|NestID), data =
Data)
> summary(best)

Linear mixed model fit by REML 

Formula: EggVolume ~ HatchOrder + Year + HatchOrder * Year + (1 | NestID) 
   Data: Data 
   AIC BIC logLik deviance REMLdev
 736.1 759 -360.1    729.1   720.1

Random effects:
 Groups   Name        Variance Std.Dev.
 NestID   (Intercept) 26.2931  5.1277  
 Residual              6.2175  2.4935  

Number of obs: 130, groups: NestID, 55

Fixed effects:
                      Estimate Std. Error t value
(Intercept)           79.7261     1.1350   70.24
HatchSecond           -0.7227     0.7758   -0.93
HatchThird            -4.8455     0.9112   -5.32
Year2007               3.5548     1.5750    2.26
HatchSecond:Year2007  -2.6914     1.0752   -2.50
HatchThird:Year2007   -2.7999     1.2294   -2.28

Correlation of Fixed Effects:
            (Intr) HtchOS HtchOT Yr2007 HOS:Y2
HtchOrdrScn -0.277                            
HtchOrdrThr -0.229  0.388                     
Year2007    -0.721  0.199  0.165              
HtcOS:Y2007  0.200 -0.722 -0.280 -0.299       
HtcOT:Y2007  0.170 -0.287 -0.741 -0.301  0.415

I used the "pvals.fnc" function in the "coda" package to estimate p-values.
Output follows:

> pvals.fnc(best, nsim = 10000, ndigits = 4, withMCMC = FALSE,
addPlot=FALSE)

$fixed
                  Estimate MCMCmean HPD95lower HPD95upper  pMCMC Pr(>|t|)
(Intercept)       79.7261  79.5990     77.687    81.5521 0.0001   0.0000
HatchSecond       -0.7227   0.1239     -2.630     2.8256 0.9468   0.3534
HatchThird        -4.8455  -4.3177     -7.391    -1.0711 0.0086   0.0000
Year2007           3.5548   3.9605      1.090     6.8664 0.0080   0.0258
HatchSecond:2007  -2.6914  -3.4393     -7.235     0.3782 0.0772   0.0136
HatchThird:2007   -2.7999  -3.6649     -7.768     0.5046 0.0830   0.0245

$random
    Groups        Name Std.Dev. MCMCmedian MCMCmean HPD95lower HPD95upper
1   NestID (Intercept)   5.1277     2.3265   2.3166     1.5388     3.1619
2 Residual               2.4935     4.5507   4.5744     3.8179     5.4108

I understand that, even in mixed models, one should not interpret main
effects' coefficients by themselves when a significant interaction is
present. Instead, coefficients of the main effect and the interaction term
should be added. In my example:
  
# Coefficient for HatchSecond:Year2007: -0.7227 + (-2.6914) = -3.4141

Then, in 2007 the volume of HatchSecond eggs was 3.41 units lower than that
of HathFirst eggs.   

# HatchThird:Year2007: -4.8455 + (-2.7999) = -7.6454      

Then, in 2007 the volumen of HatchThird eggs was 7.64 units lower than that
of HathFirst eggs.

1. Are these interpretations correct in the contest of mixed modeling? 

2. When I plot my raw data (means of egg volume for each year and stratified
by hatching order), the plot looks good for 2007 (decreasing egg volumes
along the hatching sequence). However, HatchSecond eggs have a mean volume
slightly larger than that of HatchFirst eggs (80,02 vs. 79,47) which doesn't
reconcile with my GLMM: HatchSecond eggs from 2007 are 3.41 units lower than
that of HathFirst eggs. 

That said, I was wondering if this differences is due to the fact that the
GLMM includes a random effect (Nest) while plotting raw data ignores it. 
     
Thank you very much in advance! 

LFLS



From lucianolasala at yahoo.com.ar  Wed Dec 29 21:23:03 2010
From: lucianolasala at yahoo.com.ar (Luciano La Sala)
Date: Wed, 29 Dec 2010 17:23:03 -0300
Subject: [R-sig-ME] Coefficients interpretation and plot
Message-ID: <7643A69B363545B193BA3B3158ABF590@Negro1>

Hello everyone, 

Since I'm not entirely sure this is THE list I should be referring too, feel
free to blow me off and refer me to another mailing list if necessary. 
I am analyzing a small dataset using lmer from lme4 package. My model has
"egg volume" as dependent variable and "hatching order" and "year" as
dependent variables. The best fit model has these two variables plus their
interaction (hatching order*year). I included Nest_ID as random intercepts.
Output follows: 

> best <- lmer(EggVolume~HatchOrder+Year+HatchOrder*Year+(1|NestID), data =
Data)
> summary(best)

Linear mixed model fit by REML 

Formula: EggVolume ~ HatchOrder + Year + HatchOrder * Year + (1 | NestID) 
   Data: Data 
   AIC BIC logLik deviance REMLdev
 736.1 759 -360.1    729.1   720.1

Random effects:
 Groups   Name        Variance Std.Dev.
 NestID   (Intercept) 26.2931  5.1277  
 Residual              6.2175  2.4935  

Number of obs: 130, groups: NestID, 55

Fixed effects:
                      Estimate Std. Error t value
(Intercept)           79.7261     1.1350   70.24
HatchSecond           -0.7227     0.7758   -0.93
HatchThird            -4.8455     0.9112   -5.32
Year2007               3.5548     1.5750    2.26
HatchSecond:Year2007  -2.6914     1.0752   -2.50
HatchThird:Year2007   -2.7999     1.2294   -2.28

Correlation of Fixed Effects:
            (Intr) HtchOS HtchOT Yr2007 HOS:Y2
HtchOrdrScn -0.277                            
HtchOrdrThr -0.229  0.388                     
Year2007    -0.721  0.199  0.165              
HtcOS:Y2007  0.200 -0.722 -0.280 -0.299       
HtcOT:Y2007  0.170 -0.287 -0.741 -0.301  0.415

I used the "pvals.fnc" function in the "coda" package to estimate p-values.
Output follows:

> pvals.fnc(best, nsim = 10000, ndigits = 4, withMCMC = FALSE,
addPlot=FALSE)

$fixed
                  Estimate MCMCmean HPD95lower HPD95upper  pMCMC Pr(>|t|)
(Intercept)       79.7261  79.5990     77.687    81.5521 0.0001   0.0000
HatchSecond       -0.7227   0.1239     -2.630     2.8256 0.9468   0.3534
HatchThird        -4.8455  -4.3177     -7.391    -1.0711 0.0086   0.0000
Year2007           3.5548   3.9605      1.090     6.8664 0.0080   0.0258
HatchSecond:2007  -2.6914  -3.4393     -7.235     0.3782 0.0772   0.0136
HatchThird:2007   -2.7999  -3.6649     -7.768     0.5046 0.0830   0.0245

$random
    Groups        Name Std.Dev. MCMCmedian MCMCmean HPD95lower HPD95upper
1   NestID (Intercept)   5.1277     2.3265   2.3166     1.5388     3.1619
2 Residual               2.4935     4.5507   4.5744     3.8179     5.4108

I understand that, even in mixed models, one should not interpret main
effects' coefficients by themselves when a significant interaction is
present. Instead, coefficients of the main effect and the interaction term
should be added. In my example:
  
# Coefficient for HatchSecond:Year2007: -0.7227 + (-2.6914) = -3.4141

Then, in 2007 the volume of HatchSecond eggs was 3.41 units lower than that
of HathFirst eggs.   

# HatchThird:Year2007: -4.8455 + (-2.7999) = -7.6454      

Then, in 2007 the volumen of HatchThird eggs was 7.64 units lower than that
of HathFirst eggs.

1. Are these interpretations correct in the contest of mixed modeling? 

2. When I plot my raw data (means of egg volume for each year and stratified
by hatching order), the plot looks good for 2007 (decreasing egg volumes
along the hatching sequence). However, HatchSecond eggs have a mean volume
slightly larger than that of HatchFirst eggs (80,02 vs. 79,47) which doesn't
reconcile with my GLMM: HatchSecond eggs from 2007 are 3.41 units lower than
that of HathFirst eggs. 

That said, I was wondering if this differences is due to the fact that the
GLMM includes a random effect (Nest) while plotting raw data ignores it. 
     
Thank you very much in advance! 

LFLS



From j.hadfield at ed.ac.uk  Wed Dec 29 22:05:28 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 29 Dec 2010 21:05:28 +0000
Subject: [R-sig-ME] Coefficients interpretation and plot
In-Reply-To: <7643A69B363545B193BA3B3158ABF590@Negro1>
References: <7643A69B363545B193BA3B3158ABF590@Negro1>
Message-ID: <20101229210528.16890pjzl7mvth28@www.staffmail.ed.ac.uk>

Hi Luciano,

If I understand you correctly, your issue is that the prediction for  
the first egg in the year that is NOT (?) 2007 is greater than second  
eggs in that year, yet the raw data indicate the opposite?

I notice that you have less than 3 eggs for each nest. If there is a  
(positive) relationship between clutch size and egg volume you could  
get such a discrepancy. You could try putting clutch size in the  
model. That being said, the offending coefficient is small with a  
large p-value (0.35) so the discrepancy may not be that surprising.

Also, I'm not sure what the state of play with pvals.func is. mcmcsamp  
used to behave oddly, and from your output the fixed effects look OK,  
but the 95% MCMC CI's for the variance components do not seem to  
overlap the REML estimates. Its possible there on a different scale,  
but I would check.

Cheers,

Jarrod




Quoting Luciano La Sala <lucianolasala at yahoo.com.ar>:

> Hello everyone,
>
> Since I'm not entirely sure this is THE list I should be referring too, feel
> free to blow me off and refer me to another mailing list if necessary.
> I am analyzing a small dataset using lmer from lme4 package. My model has
> "egg volume" as dependent variable and "hatching order" and "year" as
> dependent variables. The best fit model has these two variables plus their
> interaction (hatching order*year). I included Nest_ID as random intercepts.
> Output follows:
>
>> best <- lmer(EggVolume~HatchOrder+Year+HatchOrder*Year+(1|NestID), data =
> Data)
>> summary(best)
>
> Linear mixed model fit by REML
>
> Formula: EggVolume ~ HatchOrder + Year + HatchOrder * Year + (1 | NestID)
>    Data: Data
>    AIC BIC logLik deviance REMLdev
>  736.1 759 -360.1    729.1   720.1
>
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  NestID   (Intercept) 26.2931  5.1277
>  Residual              6.2175  2.4935
>
> Number of obs: 130, groups: NestID, 55
>
> Fixed effects:
>                       Estimate Std. Error t value
> (Intercept)           79.7261     1.1350   70.24
> HatchSecond           -0.7227     0.7758   -0.93
> HatchThird            -4.8455     0.9112   -5.32
> Year2007               3.5548     1.5750    2.26
> HatchSecond:Year2007  -2.6914     1.0752   -2.50
> HatchThird:Year2007   -2.7999     1.2294   -2.28
>
> Correlation of Fixed Effects:
>             (Intr) HtchOS HtchOT Yr2007 HOS:Y2
> HtchOrdrScn -0.277
> HtchOrdrThr -0.229  0.388
> Year2007    -0.721  0.199  0.165
> HtcOS:Y2007  0.200 -0.722 -0.280 -0.299
> HtcOT:Y2007  0.170 -0.287 -0.741 -0.301  0.415
>
> I used the "pvals.fnc" function in the "coda" package to estimate p-values.
> Output follows:
>
>> pvals.fnc(best, nsim = 10000, ndigits = 4, withMCMC = FALSE,
> addPlot=FALSE)
>
> $fixed
>                   Estimate MCMCmean HPD95lower HPD95upper  pMCMC Pr(>|t|)
> (Intercept)       79.7261  79.5990     77.687    81.5521 0.0001   0.0000
> HatchSecond       -0.7227   0.1239     -2.630     2.8256 0.9468   0.3534
> HatchThird        -4.8455  -4.3177     -7.391    -1.0711 0.0086   0.0000
> Year2007           3.5548   3.9605      1.090     6.8664 0.0080   0.0258
> HatchSecond:2007  -2.6914  -3.4393     -7.235     0.3782 0.0772   0.0136
> HatchThird:2007   -2.7999  -3.6649     -7.768     0.5046 0.0830   0.0245
>
> $random
>     Groups        Name Std.Dev. MCMCmedian MCMCmean HPD95lower HPD95upper
> 1   NestID (Intercept)   5.1277     2.3265   2.3166     1.5388     3.1619
> 2 Residual               2.4935     4.5507   4.5744     3.8179     5.4108
>
> I understand that, even in mixed models, one should not interpret main
> effects' coefficients by themselves when a significant interaction is
> present. Instead, coefficients of the main effect and the interaction term
> should be added. In my example:
>
> # Coefficient for HatchSecond:Year2007: -0.7227 + (-2.6914) = -3.4141
>
> Then, in 2007 the volume of HatchSecond eggs was 3.41 units lower than that
> of HathFirst eggs.
>
> # HatchThird:Year2007: -4.8455 + (-2.7999) = -7.6454
>
> Then, in 2007 the volumen of HatchThird eggs was 7.64 units lower than that
> of HathFirst eggs.
>
> 1. Are these interpretations correct in the contest of mixed modeling?
>
> 2. When I plot my raw data (means of egg volume for each year and stratified
> by hatching order), the plot looks good for 2007 (decreasing egg volumes
> along the hatching sequence). However, HatchSecond eggs have a mean volume
> slightly larger than that of HatchFirst eggs (80,02 vs. 79,47) which doesn't
> reconcile with my GLMM: HatchSecond eggs from 2007 are 3.41 units lower than
> that of HathFirst eggs.
>
> That said, I was wondering if this differences is due to the fact that the
> GLMM includes a random effect (Nest) while plotting raw data ignores it.
>
> Thank you very much in advance!
>
> LFLS
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From lucianolasala at yahoo.com.ar  Wed Dec 29 23:09:14 2010
From: lucianolasala at yahoo.com.ar (Luciano La Sala)
Date: Wed, 29 Dec 2010 19:09:14 -0300
Subject: [R-sig-ME] Coefficients interpretation and plot
References: <7643A69B363545B193BA3B3158ABF590@Negro1>
	<20101229210528.16890pjzl7mvth28@www.staffmail.ed.ac.uk> 
Message-ID: <DBF99A5B78B642D18C99460A9D4F2891@Negro1>

Hi Jarrod,

Thank you for the speedy reply. My issue seems to be the opposite: raw data
indicates that A-eggs are a little smaller than B-eggs in 2006, while the
GLMM (with Nest IDs as random intercepts) shows that A-eggs are a little
larger than B-eggs. I wonder if this difference comes from having included
Nests as a random intercepts. Very far from being a statistician myself, the
issue at hand baffles me.

By the way, I only have three-egg clutches, and first, second, and third
hatching chicks within each nest. Any ideas as to where this difference
comes from?  

Best,
Luciano


________________________________________
De: Jarrod Hadfield [mailto:j.hadfield at ed.ac.uk] 
Enviado el: Wednesday, December 29, 2010 6:05 PM
Para: Luciano La Sala
CC: r-sig-mixed-models at r-project.org
Asunto: Re: [R-sig-ME] Coefficients interpretation and plot

Hi Luciano,

If I understand you correctly, your issue is that the prediction for?
the first egg in the year that is NOT (?) 2007 is greater than second?
eggs in that year, yet the raw data indicate the opposite?

I notice that you have less than 3 eggs for each nest. If there is a?
(positive) relationship between clutch size and egg volume you could?
get such a discrepancy. You could try putting clutch size in the?
model. That being said, the offending coefficient is small with a?
large p-value (0.35) so the discrepancy may not be that surprising.

Also, I'm not sure what the state of play with pvals.func is. mcmcsamp?
used to behave oddly, and from your output the fixed effects look OK,?
but the 95% MCMC CI's for the variance components do not seem to?
overlap the REML estimates. Its possible there on a different scale,?
but I would check.

Cheers,

Jarrod




Quoting Luciano La Sala <lucianolasala at yahoo.com.ar>:

> Hello everyone,
>
> Since I'm not entirely sure this is THE list I should be referring too,
feel
> free to blow me off and refer me to another mailing list if necessary.
> I am analyzing a small dataset using lmer from lme4 package. My model has
> "egg volume" as dependent variable and "hatching order" and "year" as
> dependent variables. The best fit model has these two variables plus their
> interaction (hatching order*year). I included Nest_ID as random
intercepts.
> Output follows:
>
>> best <- lmer(EggVolume~HatchOrder+Year+HatchOrder*Year+(1|NestID), data =
> Data)
>> summary(best)
>
> Linear mixed model fit by REML
>
> Formula: EggVolume ~ HatchOrder + Year + HatchOrder * Year + (1 | NestID)
>??? Data: Data
>??? AIC BIC logLik deviance REMLdev
>? 736.1 759 -360.1??? 729.1?? 720.1
>
> Random effects:
>? Groups?? Name??????? Variance Std.Dev.
>? NestID?? (Intercept) 26.2931? 5.1277
>? Residual????????????? 6.2175? 2.4935
>
> Number of obs: 130, groups: NestID, 55
>
> Fixed effects:
>?????????????????????? Estimate Std. Error t value
> (Intercept)?????????? 79.7261???? 1.1350?? 70.24
> HatchSecond?????????? -0.7227???? 0.7758?? -0.93
> HatchThird??????????? -4.8455???? 0.9112?? -5.32
> Year2007?????????????? 3.5548???? 1.5750??? 2.26
> HatchSecond:Year2007? -2.6914???? 1.0752?? -2.50
> HatchThird:Year2007?? -2.7999???? 1.2294?? -2.28
>
> Correlation of Fixed Effects:
>???????????? (Intr) HtchOS HtchOT Yr2007 HOS:Y2
> HtchOrdrScn -0.277
> HtchOrdrThr -0.229? 0.388
> Year2007??? -0.721? 0.199? 0.165
> HtcOS:Y2007? 0.200 -0.722 -0.280 -0.299
> HtcOT:Y2007? 0.170 -0.287 -0.741 -0.301? 0.415
>
> I used the "pvals.fnc" function in the "coda" package to estimate
p-values.
> Output follows:
>
>> pvals.fnc(best, nsim = 10000, ndigits = 4, withMCMC = FALSE,
> addPlot=FALSE)
>
> $fixed
>?????????????????? Estimate MCMCmean HPD95lower HPD95upper? pMCMC Pr(>|t|)
> (Intercept)?????? 79.7261? 79.5990???? 77.687??? 81.5521 0.0001?? 0.0000
> HatchSecond?????? -0.7227?? 0.1239???? -2.630???? 2.8256 0.9468?? 0.3534
> HatchThird??????? -4.8455? -4.3177???? -7.391??? -1.0711 0.0086?? 0.0000
> Year2007?????????? 3.5548?? 3.9605????? 1.090???? 6.8664 0.0080?? 0.0258
> HatchSecond:2007? -2.6914? -3.4393???? -7.235???? 0.3782 0.0772?? 0.0136
> HatchThird:2007?? -2.7999? -3.6649???? -7.768???? 0.5046 0.0830?? 0.0245
>
> $random
>???? Groups??????? Name Std.Dev. MCMCmedian MCMCmean HPD95lower HPD95upper
> 1?? NestID (Intercept)?? 5.1277???? 2.3265?? 2.3166???? 1.5388???? 3.1619
> 2 Residual?????????????? 2.4935???? 4.5507?? 4.5744???? 3.8179???? 5.4108
>
> I understand that, even in mixed models, one should not interpret main
> effects' coefficients by themselves when a significant interaction is
> present. Instead, coefficients of the main effect and the interaction term
> should be added. In my example:
>
> # Coefficient for HatchSecond:Year2007: -0.7227 + (-2.6914) = -3.4141
>
> Then, in 2007 the volume of HatchSecond eggs was 3.41 units lower than
that
> of HathFirst eggs.
>
> # HatchThird:Year2007: -4.8455 + (-2.7999) = -7.6454
>
> Then, in 2007 the volumen of HatchThird eggs was 7.64 units lower than
that
> of HathFirst eggs.
>
> 1. Are these interpretations correct in the contest of mixed modeling?
>
> 2. When I plot my raw data (means of egg volume for each year and
stratified
> by hatching order), the plot looks good for 2007 (decreasing egg volumes
> along the hatching sequence). However, HatchSecond eggs have a mean volume
> slightly larger than that of HatchFirst eggs (80,02 vs. 79,47) which
doesn't
> reconcile with my GLMM: HatchSecond eggs from 2007 are 3.41 units lower
than
> that of HathFirst eggs.
>
> That said, I was wondering if this differences is due to the fact that the
> GLMM includes a random effect (Nest) while plotting raw data ignores it.
>
> Thank you very much in advance!
>
> LFLS
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



--
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.
________________________________________
No virus found in this message.
Checked by AVG - www.avg.com



From j.hadfield at ed.ac.uk  Wed Dec 29 23:14:52 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 29 Dec 2010 22:14:52 +0000
Subject: [R-sig-ME] Coefficients interpretation and plot
In-Reply-To: <DBF99A5B78B642D18C99460A9D4F2891@Negro1>
References: <7643A69B363545B193BA3B3158ABF590@Negro1>
	<20101229210528.16890pjzl7mvth28@www.staffmail.ed.ac.uk>
	<DBF99A5B78B642D18C99460A9D4F2891@Negro1>
Message-ID: <20101229221452.12215k33rox6ecws@www.staffmail.ed.ac.uk>

Hi Luciano,


Quoting Luciano La Sala <lucianolasala at yahoo.com.ar>:

> Hi Jarrod,
>
> Thank you for the speedy reply. My issue seems to be the opposite: raw data
> indicates that A-eggs are a little smaller than B-eggs in 2006, while the
> GLMM (with Nest IDs as random intercepts) shows that A-eggs are a little
> larger than B-eggs.

I think this is what I meant too (if call the first to hatch as A-eggs).


I wonder if this difference comes from having included
> Nests as a random intercepts. Very far from being a statistician myself, the
> issue at hand baffles me.
>
> By the way, I only have three-egg clutches, and first, second, and third
> hatching chicks within each nest. Any ideas as to where this difference
> comes from?

In your output you have 130 observations from 55 nests: which is about  
2.46 eggs per nest rather than three. Is it possible there are NA's  
for some of the predictors?

Cheers,

Jarrod




>
> Best,
> Luciano
>
>
> ________________________________________
> De: Jarrod Hadfield [mailto:j.hadfield at ed.ac.uk]
> Enviado el: Wednesday, December 29, 2010 6:05 PM
> Para: Luciano La Sala
> CC: r-sig-mixed-models at r-project.org
> Asunto: Re: [R-sig-ME] Coefficients interpretation and plot
>
> Hi Luciano,
>
> If I understand you correctly, your issue is that the prediction for?
> the first egg in the year that is NOT (?) 2007 is greater than second?
> eggs in that year, yet the raw data indicate the opposite?
>
> I notice that you have less than 3 eggs for each nest. If there is a?
> (positive) relationship between clutch size and egg volume you could?
> get such a discrepancy. You could try putting clutch size in the?
> model. That being said, the offending coefficient is small with a?
> large p-value (0.35) so the discrepancy may not be that surprising.
>
> Also, I'm not sure what the state of play with pvals.func is. mcmcsamp?
> used to behave oddly, and from your output the fixed effects look OK,?
> but the 95% MCMC CI's for the variance components do not seem to?
> overlap the REML estimates. Its possible there on a different scale,?
> but I would check.
>
> Cheers,
>
> Jarrod
>
>
>
>
> Quoting Luciano La Sala <lucianolasala at yahoo.com.ar>:
>
>> Hello everyone,
>>
>> Since I'm not entirely sure this is THE list I should be referring too,
> feel
>> free to blow me off and refer me to another mailing list if necessary.
>> I am analyzing a small dataset using lmer from lme4 package. My model has
>> "egg volume" as dependent variable and "hatching order" and "year" as
>> dependent variables. The best fit model has these two variables plus their
>> interaction (hatching order*year). I included Nest_ID as random
> intercepts.
>> Output follows:
>>
>>> best <- lmer(EggVolume~HatchOrder+Year+HatchOrder*Year+(1|NestID), data =
>> Data)
>>> summary(best)
>>
>> Linear mixed model fit by REML
>>
>> Formula: EggVolume ~ HatchOrder + Year + HatchOrder * Year + (1 | NestID)
>> ??? Data: Data
>> ??? AIC BIC logLik deviance REMLdev
>> ? 736.1 759 -360.1??? 729.1?? 720.1
>>
>> Random effects:
>> ? Groups?? Name??????? Variance Std.Dev.
>> ? NestID?? (Intercept) 26.2931? 5.1277
>> ? Residual????????????? 6.2175? 2.4935
>>
>> Number of obs: 130, groups: NestID, 55
>>
>> Fixed effects:
>> ?????????????????????? Estimate Std. Error t value
>> (Intercept)?????????? 79.7261???? 1.1350?? 70.24
>> HatchSecond?????????? -0.7227???? 0.7758?? -0.93
>> HatchThird??????????? -4.8455???? 0.9112?? -5.32
>> Year2007?????????????? 3.5548???? 1.5750??? 2.26
>> HatchSecond:Year2007? -2.6914???? 1.0752?? -2.50
>> HatchThird:Year2007?? -2.7999???? 1.2294?? -2.28
>>
>> Correlation of Fixed Effects:
>> ???????????? (Intr) HtchOS HtchOT Yr2007 HOS:Y2
>> HtchOrdrScn -0.277
>> HtchOrdrThr -0.229? 0.388
>> Year2007??? -0.721? 0.199? 0.165
>> HtcOS:Y2007? 0.200 -0.722 -0.280 -0.299
>> HtcOT:Y2007? 0.170 -0.287 -0.741 -0.301? 0.415
>>
>> I used the "pvals.fnc" function in the "coda" package to estimate
> p-values.
>> Output follows:
>>
>>> pvals.fnc(best, nsim = 10000, ndigits = 4, withMCMC = FALSE,
>> addPlot=FALSE)
>>
>> $fixed
>> ?????????????????? Estimate MCMCmean HPD95lower HPD95upper? pMCMC Pr(>|t|)
>> (Intercept)?????? 79.7261? 79.5990???? 77.687??? 81.5521 0.0001?? 0.0000
>> HatchSecond?????? -0.7227?? 0.1239???? -2.630???? 2.8256 0.9468?? 0.3534
>> HatchThird??????? -4.8455? -4.3177???? -7.391??? -1.0711 0.0086?? 0.0000
>> Year2007?????????? 3.5548?? 3.9605????? 1.090???? 6.8664 0.0080?? 0.0258
>> HatchSecond:2007? -2.6914? -3.4393???? -7.235???? 0.3782 0.0772?? 0.0136
>> HatchThird:2007?? -2.7999? -3.6649???? -7.768???? 0.5046 0.0830?? 0.0245
>>
>> $random
>> ???? Groups??????? Name Std.Dev. MCMCmedian MCMCmean HPD95lower HPD95upper
>> 1?? NestID (Intercept)?? 5.1277???? 2.3265?? 2.3166???? 1.5388???? 3.1619
>> 2 Residual?????????????? 2.4935???? 4.5507?? 4.5744???? 3.8179???? 5.4108
>>
>> I understand that, even in mixed models, one should not interpret main
>> effects' coefficients by themselves when a significant interaction is
>> present. Instead, coefficients of the main effect and the interaction term
>> should be added. In my example:
>>
>> # Coefficient for HatchSecond:Year2007: -0.7227 + (-2.6914) = -3.4141
>>
>> Then, in 2007 the volume of HatchSecond eggs was 3.41 units lower than
> that
>> of HathFirst eggs.
>>
>> # HatchThird:Year2007: -4.8455 + (-2.7999) = -7.6454
>>
>> Then, in 2007 the volumen of HatchThird eggs was 7.64 units lower than
> that
>> of HathFirst eggs.
>>
>> 1. Are these interpretations correct in the contest of mixed modeling?
>>
>> 2. When I plot my raw data (means of egg volume for each year and
> stratified
>> by hatching order), the plot looks good for 2007 (decreasing egg volumes
>> along the hatching sequence). However, HatchSecond eggs have a mean volume
>> slightly larger than that of HatchFirst eggs (80,02 vs. 79,47) which
> doesn't
>> reconcile with my GLMM: HatchSecond eggs from 2007 are 3.41 units lower
> than
>> that of HathFirst eggs.
>>
>> That said, I was wondering if this differences is due to the fact that the
>> GLMM includes a random effect (Nest) while plotting raw data ignores it.
>>
>> Thank you very much in advance!
>>
>> LFLS
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
> ________________________________________
> No virus found in this message.
> Checked by AVG - www.avg.com
> Version: 10.0.1191 / Virus Database: 1435/3346 - Release Date: 12/29/10
>
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From helixed2 at yahoo.com  Wed Dec 29 23:28:14 2010
From: helixed2 at yahoo.com (Jeremy Koster)
Date: Wed, 29 Dec 2010 14:28:14 -0800 (PST)
Subject: [R-sig-ME] What approach would be appropriate for this multinomial
	outcome?
Message-ID: <406258.13119.qm@web161810.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101229/defb2f73/attachment.pl>

From lucianolasala at yahoo.com.ar  Thu Dec 30 00:31:58 2010
From: lucianolasala at yahoo.com.ar (Luciano La Sala)
Date: Wed, 29 Dec 2010 20:31:58 -0300
Subject: [R-sig-ME] Coefficients interpretation and plot
In-Reply-To: <20101229221452.12215k33rox6ecws@www.staffmail.ed.ac.uk>
References: <7643A69B363545B193BA3B3158ABF590@Negro1>
	<20101229210528.16890pjzl7mvth28@www.staffmail.ed.ac.uk>
	<DBF99A5B78B642D18C99460A9D4F2891@Negro1>
	<20101229221452.12215k33rox6ecws@www.staffmail.ed.ac.uk>
Message-ID: <391C686E1B88431981B54A34698122B7@Negro1>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101229/8cad5e2e/attachment.pl>

From djmuser at gmail.com  Thu Dec 30 04:01:31 2010
From: djmuser at gmail.com (Dennis Murphy)
Date: Wed, 29 Dec 2010 19:01:31 -0800
Subject: [R-sig-ME] What approach would be appropriate for this
 multinomial outcome?
In-Reply-To: <406258.13119.qm@web161810.mail.bf1.yahoo.com>
References: <406258.13119.qm@web161810.mail.bf1.yahoo.com>
Message-ID: <AANLkTinQYLndp+88uzJ4LLnx0r2_wx8aL_YwsGZBZW66@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101229/6eac4981/attachment.pl>

From joris.dewolf at cropdesign.com  Thu Dec 30 17:56:45 2010
From: joris.dewolf at cropdesign.com (joris.dewolf at cropdesign.com)
Date: Thu, 30 Dec 2010 17:56:45 +0100
Subject: [R-sig-ME] use.u argument in bootMer in lme4a
Message-ID: <OF0C9159B2.D6AC9856-ONC1257809.005CF977-C1257809.005D16A0@basf-c-s.be>

Hi,

(sorry for reposting...)
I am trying out the function bootMer in lme4a (lme4a_0.999375-59), 
specifically the option whether or not to bootstrap the random effects and 
stumbled on a couple of problems.

The documentation says:
bootMer(x, FUN, nsim=1, seed, use.u=FALSE, verbose=FALSE, control=list())
use.u: logical, indicating, if the spherized random effects should be 
simulated / bootstrapped as well. If FALSE, they are not changed, and all 
inference is conditional on these.

I interpret this as if the argument 'use.u' is FALSE, the random effects 
are not simulated.

Applying this on my model with call 
lmer(value ~ transgenity + (transgenity | event))

(the merMod object is given in attach), I get the following:

load("modL1.2.obj")
params <- function(m) {
        VC <- VarCorr(m)$event
        c(beta =m at fe@coef, sigma = sigma(m),
                sig01 = sqrt(VC[1,1]), sig02 = sqrt(VC[2,2]),sig03 = VC[1,
2])
}
bs.uF <- bootMer(modL1.2, params, nsim = 3,use.u = FALSE)

[no warnings nor errors, output looks fine]

bs.uT <- bootMer(modL1.2, params, nsim = 3,use.u = TRUE)
Warning messages:
1: In (if (use.u) u else as.vector(U %*% rnorm(q))) + rnorm(n) :
  longer object length is not a multiple of shorter object length
2: In (if (use.u) u else as.vector(U %*% rnorm(q))) + rnorm(n) :
  longer object length is not a multiple of shorter object length
3: In (if (use.u) u else as.vector(U %*% rnorm(q))) + rnorm(n) :
  longer object length is not a multiple of shorter object length

[only this warning, output looks fine as well]

In order to understand the warning, I checked the function bootMer from 
which I reproduced two pieces of code.


snippet1:
    if (use.u) {
        u <- x at re@u
    }
    else {
        U <- crossprod(x at re@Zt, x at re@Lambda)
        q <- ncol(U)
    }

snippet2

        y <- {
            X.beta + sigm.x * ((if (use.u) 
                u
            else as.vector(U %*% rnorm(q))) + rnorm(n))
        }

My two questions are:

1. From snippet 2, it seems to me that if(use.u) == TRUE, the random 
effects are NOT bootstrapped, contrary to what the documentation says. 
2. u has indeed wrong dimensions. Would 
u <- crossprod(x at re@Zt, x at re@u)
be the correct definition of u? 


Thanks.
Joris







> sessionInfo()
R version 2.12.0 (2010-10-15)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=Dutch_Belgium.1252  LC_CTYPE=Dutch_Belgium.1252 
[3] LC_MONETARY=Dutch_Belgium.1252 LC_NUMERIC=C 
[5] LC_TIME=Dutch_Belgium.1252 

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base 

other attached packages:
 [1] boot_1.2-43        TeachingDemos_2.7  coda_0.14-2 lme4a_0.999375-59 
 [5] MatrixModels_0.2-1 minqa_1.1.13       Rcpp_0.8.9 Matrix_0.999375-46
 [9] lattice_0.19-13    RODBC_1.3-2        gtools_2.6.2       rj_0.5.0-5   
 

loaded via a namespace (and not attached):
[1] codetools_0.2-2 grid_2.12.0     nlme_3.1-97     rJava_0.8-8 
[5] splines_2.12.0  stats4_2.12.0   tools_2.12.0 
 
 

From wade.wall at gmail.com  Fri Dec 31 17:00:03 2010
From: wade.wall at gmail.com (Wade Wall)
Date: Fri, 31 Dec 2010 11:00:03 -0500
Subject: [R-sig-ME] false convergence error,
	with bonus "matrix is not symmetric" error
Message-ID: <AANLkTi=7Jm+y=WAOsXH-oBN0xvh5WNHiK3ce49WvK_1q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20101231/39ef439a/attachment.pl>

From joris.dewolf at cropdesign.com  Thu Dec 30 17:39:54 2010
From: joris.dewolf at cropdesign.com (joris.dewolf at cropdesign.com)
Date: Thu, 30 Dec 2010 17:39:54 +0100
Subject: [R-sig-ME] use.u argument in bootMer in lme4a
Message-ID: <OF9CE64987.C97AC1EF-ONC1257809.005320F5-C1257809.005B8B56@basf-c-s.be>

Hi,

I am trying out the function bootMer in lme4a (lme4a_0.999375-59), 
specifically the option whether or not to bootstrap the random effects and 
stumbled on a couple of problems.

The documentation says:
bootMer(x, FUN, nsim=1, seed, use.u=FALSE, verbose=FALSE, control=list())
use.u: logical, indicating, if the spherized random effects should be 
simulated / bootstrapped as well. If FALSE, they are not changed, and all 
inference is conditional on these.

I interpret this as if the argument 'use.u' is FALSE, the random effects 
are not simulated.

Applying this on my model with call 
lmer(value ~ transgenity + (transgenity | event))

(the merMod object is given in attach), I get the following:

load("modL1.2.obj")
params <- function(m) {
        VC <- VarCorr(m)$event
        c(beta =m at fe@coef, sigma = sigma(m),
                sig01 = sqrt(VC[1,1]), sig02 = sqrt(VC[2,2]),sig03 = VC[1,
2])
}
bs.uF <- bootMer(modL1.2, params, nsim = 3,use.u = FALSE)

[no warnings nor errors, output looks fine]

bs.uT <- bootMer(modL1.2, params, nsim = 3,use.u = TRUE)
Warning messages:
1: In (if (use.u) u else as.vector(U %*% rnorm(q))) + rnorm(n) :
  longer object length is not a multiple of shorter object length
2: In (if (use.u) u else as.vector(U %*% rnorm(q))) + rnorm(n) :
  longer object length is not a multiple of shorter object length
3: In (if (use.u) u else as.vector(U %*% rnorm(q))) + rnorm(n) :
  longer object length is not a multiple of shorter object length

[only this warning, output looks fine as well]

In order to understand the warning, I checked the function bootMer from 
which I reproduced two pieces of code.


snippet1:
    if (use.u) {
        u <- x at re@u
    }
    else {
        U <- crossprod(x at re@Zt, x at re@Lambda)
        q <- ncol(U)
    }

snippet2

        y <- {
            X.beta + sigm.x * ((if (use.u) 
                u
            else as.vector(U %*% rnorm(q))) + rnorm(n))
        }

My two questions are:

1. From snippet 2, it seems to me that if(use.u) == TRUE, the random 
effects are NOT bootstrapped, contrary to what the documentation says. 
2. u has indeed wrong dimensions. Would 
u <- crossprod(x at re@Zt, x at re@u)
be the correct definition of u? 


Thanks.
Joris







> sessionInfo()
R version 2.12.0 (2010-10-15)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=Dutch_Belgium.1252  LC_CTYPE=Dutch_Belgium.1252 
[3] LC_MONETARY=Dutch_Belgium.1252 LC_NUMERIC=C 
[5] LC_TIME=Dutch_Belgium.1252 

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base 

other attached packages:
 [1] boot_1.2-43        TeachingDemos_2.7  coda_0.14-2 lme4a_0.999375-59 
 [5] MatrixModels_0.2-1 minqa_1.1.13       Rcpp_0.8.9 Matrix_0.999375-46
 [9] lattice_0.19-13    RODBC_1.3-2        gtools_2.6.2       rj_0.5.0-5   
 

loaded via a namespace (and not attached):
[1] codetools_0.2-2 grid_2.12.0     nlme_3.1-97     rJava_0.8-8 
[5] splines_2.12.0  stats4_2.12.0   tools_2.12.0 
 

From emm.charpentier at free.fr  Thu Dec 30 23:27:41 2010
From: emm.charpentier at free.fr (Emmanuel Charpentier)
Date: Thu, 30 Dec 2010 22:27:41 +0000 (UTC)
Subject: [R-sig-ME] Mixed-model polytomous ordered logistic regression ?
Message-ID: <ifj10t$e5$1@dough.gmane.org>

Dear list,

Following a hint of an exercise in Gelman & Hill's (2007) regression 
textbook, I tried to understand  how to build a function generalizing to 
mixed models what polr() (MASS) does for fixed models.

I started with a very simple artificial dataset (see at end). Using the 
simplest polr() use :

> summary(polr(Cat~X, data=Data))

Re-fitting to get Hessian

Call:
polr(formula = Cat ~ X, data = Data)

Coefficients:
  Value Std. Error t value
X 9.557      1.821   5.247

Intercepts:
      Value   Std. Error t value
C1|C2 14.8668  3.0447     4.8828
C2|C3 24.2772  4.7119     5.1523
C3|C4 34.2367  6.5861     5.1984
C4|C5 43.3543  8.2390     5.2621
C5|C6 53.8174 10.3240     5.2128
C6|C7 63.5247 12.2352     5.1920
C7|C8 72.5850 13.7899     5.2636
C8|C9 82.2256 15.8144     5.1994

Residual Deviance: 55.7395 
AIC: 73.7395 
Message d'avis :
glm.fit: fitted probabilities numerically 0 or 1 occurred 

the following snippet :

Glm.polr<-local({
  ll<-length(lev<-levels(Data$Cat))
  thr<-paste(lev[-ll], "|", lev[-1], sep="")
  Dataset<-do.call(rbind,
                   lapply(2:ll,
                          function(i) {
                            data.frame(Thr=thr[i-1],
                                       Cat=Data$Cat>=lev[i],
                                       Data[,names(Data)[!(names(Data) %in
% c("Thr", "Cat"))]])}))
  Dataset$Thr<-factor(Dataset$Thr)
  glm(Cat~0+Thr+X, data=Dataset, family=binomial(link=logit))
})

made me able to reproduce my standard (up to numerical precision, with 
which I didn't tinker, and a couple of cosmetic details (names and sign 
of intercepts)), both for central value and variability :

> summary(Glm.polr)

Call:
glm(formula = Cat ~ 0 + Thr + X, family = binomial(link = logit), 
    data = Dataset)

Deviance Residuals: 
     Min        1Q    Median        3Q       Max  
-2.09822  -0.00001   0.00000   0.00000   1.92014  

Coefficients:
         Estimate Std. Error z value Pr(>|z|)    
ThrC1|C2  -14.858      3.050  -4.872 1.11e-06 ***
ThrC2|C3  -24.263      4.722  -5.138 2.78e-07 ***
ThrC3|C4  -34.217      6.600  -5.184 2.17e-07 ***
ThrC4|C5  -43.329      8.257  -5.247 1.54e-07 ***
ThrC5|C6  -53.786     10.346  -5.199 2.01e-07 ***
ThrC6|C7  -63.489     12.260  -5.179 2.24e-07 ***
ThrC7|C8  -72.542     13.820  -5.249 1.53e-07 ***
ThrC8|C9  -82.174     15.852  -5.184 2.18e-07 ***
X           9.551      1.825   5.233 1.67e-07 ***
---
Signif. codes:  0  ***  0.001  **  0.01  *  0.05  .  0.1     1 

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 1109.035  on 800  degrees of freedom
Residual deviance:   55.737  on 791  degrees of freedom
AIC: 73.737

Number of Fisher Scoring iterations: 12

One should note that "large" thresholds (in absolute value) have larger 
standard errors, which is probably an artifact, which I don't know how to 
get rid of. The glm claim of "800 degrees of freedom" is ridiculous : I 
have only 100 observations. More on this below...

Now, to extend this to mixed models (using lme4's notation as  model) is 
not absolutely trivial :

The "fixed effect" part of the formula must *not* have intercepts (that's 
what the thresholds become) : how to ensure this ?

In the "random effect" part, the intercepts can be replaced by the 
thresholds (one can think of legitimate reasons for which thresholds 
should depend on a random factor...). Should that be done also for 
implicit thresholds (e. g. (X | Id) means, in a GLM (implicitely) 
"variation of slope of X AND intercept according to Id". Should that 
become "variation of slope AND threshold according to Id" ?).

How should the tinkering with the original data be handled ? 
Systematically copying the original dta can be heavy, but is safe. Can 
the built-in "copy-on-write" mechanisms of R be sufficient ?

What "other" models would be useful in such a function ? Cloglog ? 
"Continuation" ? Others ?

More generally, shouldn't such a function (polrer ?) be part of some 
hypothetical (Platonician ?) lme4 ? Ordered data are important in many 
cases where numerical expressions cannot be trusted, and the ability to 
fit mixed models of these data would be important. But doing this on a 
case by case basis is somewhat error-prone (especially when done by me :).

For now on, I cope with BUGS and Bayesian interpretation. And hereby lies 
a possibly important remark.

My BUGS code (JAGS dialect, inspired by the "Bones" example of Classic 
Bugs vol I) and R call (through rjags) is at end.

The results call for some comments. Both graphical examination and some 
formal inspection show good convergence (the predictions are somewhat 
harder to stabilize...) :

> gelman.diag(Mod$Mod.coda[,-(1:100)]) ## First 100 columns are 
                                       ## predicted values for the 
                                       ## original data.
Potential scale reduction factors:

         Point est. 97.5% quantile
beta.1         1.00           1.00
deviance       1.00           1.00
gamma[1]       1.00           1.00
gamma[2]       1.00           1.00
gamma[3]       1.00           1.01
gamma[4]       1.00           1.00
gamma[5]       1.00           1.00
gamma[6]       1.00           1.00
gamma[7]       1.00           1.00
gamma[8]       1.00           1.00

Multivariate psrf

1.00

The fitted data and their variability are cosmetically quite different 
(the Bayesian model's gamma is the equivalent of the Threshold/X 
coefficient of the polr/glm frequentist model), but their central value 
quite consistent with previous values :

> summary(Mod$Mod.coda[,-(1:100)]) 

Iterations = 11010:21000
Thinning interval = 10 
Number of chains = 3 
Sample size per chain = 1000 

1. Empirical mean and standard deviation for each variable,
   plus standard error of the mean:

           Mean      SD Naive SE Time-series SE
beta.1    8.927 1.68312 0.030729       0.027433
deviance 64.674 4.26684 0.077902       0.087455
gamma[1]  1.544 0.08815 0.001609       0.001649
gamma[2]  2.544 0.10957 0.002000       0.002065
gamma[3]  3.580 0.09930 0.001813       0.001708
gamma[4]  4.544 0.08445 0.001542       0.001607
gamma[5]  5.630 0.11998 0.002191       0.002137
gamma[6]  6.627 0.12406 0.002265       0.002463
gamma[7]  7.606 0.11175 0.002040       0.002019
gamma[8]  8.608 0.18558 0.003388       0.003343

2. Quantiles for each variable:

           2.5%    25%    50%    75%  97.5%
beta.1    6.180  7.741  8.799  9.878 12.582
deviance 58.271 61.458 64.116 67.112 74.836
gamma[1]  1.363  1.489  1.548  1.604  1.706
gamma[2]  2.333  2.469  2.541  2.616  2.765
gamma[3]  3.386  3.512  3.582  3.647  3.779
gamma[4]  4.385  4.487  4.543  4.600  4.713
gamma[5]  5.406  5.545  5.630  5.713  5.870
gamma[6]  6.358  6.550  6.633  6.715  6.851
gamma[7]  7.392  7.529  7.603  7.682  7.821
gamma[8]  8.266  8.470  8.608  8.738  8.967

One should note, however, that, while the central value and sampling StD 
of beta are consistent with polr/glm results, the ratios SD/mean of the 
thresholds are much smaller than with polr/glm, and this is reflected in 
the credible intervals. Furthermore, the SDs do not seem to increase as 
much with the (absolute value) of the central values. (Yes, I am aware 
that centering my X values would reduce this phenomenon, but I kept them 
uncentered to illustrate my point).

For example, the 0.95 confidence interval of the C1|C2 threshold is about 
6.1 wide (about 41% of the mean) whereas the 0.95 credible interval of 
gamma[1] is (1.36 1.70), 0.34 wide, which is about 25% of its mean. For 
the C8|C9 thershold, the IC95/mean ratio is about 37% of the mean, while 
the CrI95/mean of gamma[8] is 8.1%.

Given that the two models are respectively a frequentist and a Bayesian 
of the very same probability model, this is perplexing.

Are there reasons to suspect that the SD reported by glm and/or polr are 
inflated (for example, these model do not seem to account for the re-use 
of the same data for the estimation of the various thresholds) ? Or is 
there a (maybe not so subtle) error in the Bayesian model interpretation 
in BUGS ?

Or am I barking up the wrong tree ?

Any idea would be welcome ...

Sincerely yours,

					Emmanuel Charpentier

The artificial data :
Data <-
structure(list(X.real = c(3.49764437862872, 6.90659633160501, 
2.49335390384994, 7.24293843863257, 0.803964727576124, 4.04213878877333, 
1.06214939381180, 0.554054259416088, 4.08729099177371, 2.52629057633986, 
3.24127380430347, 1.11891797458651, 0.530158326675324, 9.13663197362062, 
4.50887509479721, 8.28526961997477, 4.88346597634514, 7.1687905770683, 
8.30770739436844, 4.10970688126136, 0.926142793485848, 1.60153659527237, 
7.9980129347903, 7.09517767824342, 3.13154316634710, 3.73947230927693, 
2.80221854118421, 6.59984440492743, 2.61928305396566, 7.01599863310761, 
2.24968126253923, 1.58829945203618, 1.90902984485251, 5.12920046748922, 
9.2118070532461, 9.08208307216233, 4.43550132482185, 8.05729871351512, 
1.18297174176127, 8.46910981252808, 4.43676303030525, 6.4418454794069, 
4.53446029962874, 0.699769024165557, 8.46097165332483, 4.53799448354545, 
5.27431575051651, 7.54335240307173, 2.17309956012568, 5.88721264347949, 
9.4071993099453, 1.88089249201845, 5.3721556593878, 0.771888320064126, 
8.1072438324685, 6.31264339382069, 2.00734973388480, 1.55494366180340, 
7.02181982951623, 2.30599238507652, 0.527109325928194, 3.66541005952039, 
5.5545317236498, 1.09950173374848, 0.589535171670769, 3.53540683843517, 
4.45889129379049, 6.80170522713363, 7.37081649369139, 9.4889221652781, 
7.19282466718394, 6.13643707306052, 1.35088176999453, 3.16405426710045, 
3.32833977017296, 6.08074276163767, 1.63873091713528, 1.46557732912316, 
4.91770214161358, 0.938513984685997, 1.48740958479596, 2.01597792723018, 
4.21291073575364, 5.43887605123115, 4.70221174192061, 1.67668472528311, 
5.24846045233372, 9.0111473276549, 7.23671006856042, 3.72080675801418, 
4.39171014756293, 4.81283564404103, 2.41342165250038, 3.82321065255632, 
7.669782577978, 9.2234752201292, 0.641411897606775, 1.13470612170815, 
1.02966988829139, 1.24689684186557), Cat = structure(c(3L, 7L, 
2L, 7L, 1L, 4L, 1L, 1L, 4L, 3L, 3L, 1L, 1L, 9L, 5L, 8L, 5L, 7L, 
8L, 4L, 1L, 2L, 8L, 7L, 3L, 4L, 3L, 7L, 3L, 7L, 2L, 2L, 2L, 5L, 
9L, 9L, 4L, 8L, 1L, 8L, 4L, 6L, 5L, 1L, 8L, 5L, 5L, 8L, 2L, 6L, 
9L, 2L, 5L, 1L, 8L, 6L, 2L, 2L, 7L, 2L, 1L, 4L, 6L, 1L, 1L, 4L, 
4L, 7L, 7L, 9L, 7L, 6L, 1L, 3L, 3L, 6L, 2L, 1L, 5L, 1L, 1L, 2L, 
4L, 5L, 5L, 2L, 5L, 9L, 7L, 4L, 4L, 5L, 2L, 4L, 8L, 9L, 1L, 1L, 
1L, 1L), .Label = c("C1", "C2", "C3", "C4", "C5", "C6", "C7", 
"C8", "C9"), class = c("ordered", "factor")), X = c(3.78512255820666, 
7.03710649735623, 2.37579547880536, 7.01687069036889, 0.572774665466921, 
4.53333128338774, 0.92564311992818, 0.682074690286214, 4.17197303371935, 
2.62951212025962, 3.44249595134830, 1.02688214798057, 0.440959503725193, 
9.05785834195666, 4.52616407157106, 8.07448237191856, 4.95371782896727, 
7.35730414103575, 8.07638469674326, 4.26407495806574, 1.06385684713162, 
1.63333280184271, 7.9246178454581, 7.41541196525404, 3.12459209709868, 
3.64101167776984, 2.51917629411974, 6.8118629850261, 2.77786400733997, 
7.36566898280035, 2.03009770691198, 1.61723070290973, 1.96657910701987, 
5.22600151472831, 9.21386030948403, 9.18902347324618, 4.39493834305473, 
8.27266371630105, 1.15477068640133, 8.15280513569419, 4.6734050583675, 
6.51664088906166, 4.40955269905174, 0.54646886424704, 8.03605092676131, 
4.36779957410513, 5.44860695752003, 7.83429549417553, 1.84916430642593, 
5.81109382387844, 9.32133297147632, 1.73276033539495, 5.3490390105937, 
0.695781216499173, 8.05603266764859, 6.67741469458807, 2.03017543225991, 
1.60754713124494, 6.63481861913185, 2.20004584719421, 0.675994410762504, 
3.98953568167253, 5.45631429591027, 0.675175153754915, 0.305522085250977, 
3.58440905189674, 4.58557708778191, 6.99911313460102, 7.21102458968007, 
9.44650050070282, 7.33311596756764, 5.87485729872331, 1.11824133536435, 
3.40701638829918, 3.36818213997361, 5.92742193489156, 2.08701427718401, 
1.73709762230381, 4.71589786549998, 0.980248052739725, 1.58957599464140, 
2.17701413093404, 4.22999685414555, 5.84947271423299, 4.94396458250251, 
1.65133703600731, 5.17336780283038, 8.8993318875765, 7.29238547003421, 
3.62020801752199, 4.28550112286315, 4.95543088867053, 2.61555021108721, 
3.85711807608966, 7.67091954093986, 9.24609859359625, 0.436967673925767, 
1.32063426377087, 0.794911931890139, 1.16453130413352)), .Names = c
("X.real", 
"Cat", "X"), row.names = c(NA, -100L), class = "data.frame")

The R/BUGS Bayesian model :

system.time(Mod<-local({
  Mod<-function(){ ## BUGS model as an R function. Easy to manage.
    ## Thresholds.
    for (j in 1:ncut) {
      gamma.raw[j]~dnorm(0, 1.0E-4)
    }
    gamma<-sort(gamma.raw)
    ## p[i,j]=Pr(Cat[i]>j)
    ## q[i,j]=Pr(Cat[i]=j)
    ##       =Pr(Cat[i]>j-1)-Pr(Cat[i]>j)
    ##       =p[i,j-1]-p[i,j]
    for (i in 1:nobs) {
      Cat[i]~dcat(q[i,1:(ncut+1)])
      ## Predictions
      Cat.new[i]~dcat(q[i,1:(ncut+1)])
      q[i,1]<-1-p[i,1]
      for (j in 2:ncut) {
        q[i,j]<-p[i,j-1]-p[i,j]
      }
      q[i,ncut+1]<-p[i,ncut]
      for (j in 1:ncut) {
        logit(p[i,j])<-beta.1*(X[i]-gamma[j])
      }
    }
    beta.1~dnorm(0, 1.0E-4)
  }
  tmpf<-tempfile()
  write.model(Mod, tmpf) ## Auxilliary function writing a function body
  Mod.jags<-jags.model(tmpf,
                       data=with(Data, {
                         Y<-outer(Cat, levels(Cat)[-1], ">=")
                         list(X=X,
                              Cat=unclass(Cat),
                              nobs=nrow(Y),
                              ncut=ncol(Y))}),
                       ## "Reasonable" (not too overdispersed) initial
                       ## values are *CRUCIAL* to model initialisation
                       inits=function() {
                         list(gamma.raw=sort(runif(8,min=-1,max=1)),
                              beta.1=runif(1,min=0,max=1))
                       },
                       n.chains=3)
  update(Mod.jags, n.iter=10000)
  unlink(tmpf)
  Mod.coda<-coda.samples(Mod.jags,
                         variable.names=c("gamma",
                           ## "beta.0",
                           "beta.1",
                           ## "gamma.adj",
                           ## "lzeta",
                           ## "pi.sgn",
                           "deviance",
                           "Cat.new"),
                         thin=10,
                         n.iter=10000)
  list(Mod.jags=Mod.jags, Mod.coda=Mod.coda)
}))



