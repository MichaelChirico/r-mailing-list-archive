From pauljohn32 at gmail.com  Mon Apr  4 13:20:52 2016
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Mon, 4 Apr 2016 06:20:52 -0500
Subject: [R-sig-ME] GLMM estimation readings?
In-Reply-To: <CAErODj8rBfk_rEN_K-3A6n51_1=okOHsi4awzm5kcwW5+NOzcA@mail.gmail.com>
References: <CAErODj-i4_JeniXN=Hf2BptLQnRk6F3rTo9+vfyqqeGjP8+MkQ@mail.gmail.com>
	<CAErODj9zjwkRq5ba1e98t23Gg0YzwpKxs3xQme_if8kOuF9XiQ@mail.gmail.com>
	<CAErODj8rBfk_rEN_K-3A6n51_1=okOHsi4awzm5kcwW5+NOzcA@mail.gmail.com>
Message-ID: <CAErODj_WAzqrORLf0dQ9T5vv=fhacOBu2XXQpW-hf7Ebx6iYcg@mail.gmail.com>

I'm trying to explain GLMM estimation and defend random effects in an
audience of econometricians.  I am focused on logit models, mostly, with
random intercepts.

The literature is difficult. I can understand applications and overviews
like the paper by Bolker et al in Trends in Ecology and Evolution. But I
can't understand much about glmer that is deeper than that.  Can you point
me at some books/articles that explain the GLMM estimation process in an
understandable way? Is there a PLS derivation for GLMM?  I want to better
understand adaptive quadrature. And Laplace approximation.

You might be able to advise me better if I tell you why I need to know.

I was surprised to learn that economists hate random effects. It is almost
visceral. For the economists, the fixed vs random effects debate is not
philosophical, but rather practical. In an LMM, the Hausman test seems to
bluntly reject almost all random effects models.  (See William Greene's
Econometrics book).  Unmeasured group-level predictors always exist, it
seems, so random effects estimates are biased/inconsistent. Even if you
believe Intercept differences are random, LMM estimates are
biased/inconsistent, so you should treat as fixed.

I'm a little surprised there is so little discussion of Hausman's test in
the random effect literature outside economics.

One argument used by random effect advocates, that group-level predictors
can be included in LMM, holds no weight at all. It is just evidence of bias
in LMM. Well, the estimates thus obtained are useless because, if the group
level intercept estimates were correct, then the group-level predictors
would not be identifiable.

My argument with them so far is based on the characterization of LMM as a
PLS exercise, which I learned in this email list. That makes a point
obvious: the fixed vs random models differ because PLS penalizes the b's,
but fixed estimators do not. The issue is not "random" against "fixed". It
is penalized against unpenalized. The parallel between LMM and ridge
regression and LASSO helps.  If the number of observations within groups
grows, then the posterior modes  and the fixed effect estimates converge.
Yes?

The small sample debate hinges on mean square error of the b's. The PLS
view makes it plain that Empirical Bayes gives shrinkage not as
afterthought (as it seems in the GLS narrative), but as a primary element
(Henderson's estimator).   Ironically, the shrinkage effect of LMM, widely
praised in stats and hierarchical modeling applications, raises suspicion
of bias. One might prefer a biased, but lower variance estimate of b, and
that's shrinkage.  That's my theme, anyway, we'll see if I can sell it.

In that context, I come to the chore of comparing a glmer estimate with a
fixed effect method known as conditional logit or Chamberlain's panel logit
model.

pj
Paul Johnson
http://pj.freefaculty.org

	[[alternative HTML version deleted]]


From tiffany.vidal at gmail.com  Sat Apr  2 21:23:26 2016
From: tiffany.vidal at gmail.com (Tiffany Vidal)
Date: Sat, 2 Apr 2016 15:23:26 -0400
Subject: [R-sig-ME] lme4 observation level effects with indicator
Message-ID: <CAArSc3WC-fJCWy1fSFS-ve0dgjm5Z5PnOakr7yjGHyptNC4SKw@mail.gmail.com>

I am interested in estimating a mixed model with a random effect for year,
site, and an observation-level effect to account for overdispersion,
assuming Poisson error structure, using the lme4 package in R.
Additionally, I have an indicator variable 'period' to adjust the parameter
estimated by pre- and post- time periods. I am running into problems trying
to specify the observation level effect by time period. I could model this
using glmer.nb and avoid the observation-level effect, but I would like the
flexibility to allow overdispersion to vary by time period as well. If
there was a way to allow the negative binomial scaling parameter to vary by
time period, I would probably use glmer.nb.

My model as I'm trying to specify with glmer:
mod.pois <- glmer( count ~ 1 + period + year  + year*period +
(period|year.factor) + (period|Site) ,
                        data=dat, family=poisson)

The above runs and I think does what I want, but doesn't include the
observation-level effect.

I have tried:
mod.pois <- glmer( count ~ 1 + period + year  + year*period +
(period|year.factor) + (period|Site)  + (period|Site:year.factor),
                        data=dat, family=poisson)

but the error indicates identifiability issues. I have one observation at
each site x year combination.

Is there a way to achieve this using this package? Thank you in advance for
any thoughts.

	[[alternative HTML version deleted]]


From g.czanner at googlemail.com  Mon Apr  4 19:38:29 2016
From: g.czanner at googlemail.com (Gabriela Czanner)
Date: Mon, 4 Apr 2016 18:38:29 +0100
Subject: [R-sig-ME] Output and post-hoc comparisons for lme with splines
 specification of fixed effects
Message-ID: <CAOQoCVtympRj+w3OJCg9wYrqp8Rx=BrmBvWacQMhOb7Lmzan2w@mail.gmail.com>

Dear R-users,

I am attempting to estimate a difference in damage across space (at 24
locations) for two disease types of patients (defined as a factor, 0
disease absent, 1 disease present). Examining the plots of the damage
across the 24 locations in space it appears that the damage increases then
decreases and it is best described by a spline specification like this:

model<- lme( Damage ~ bs( Location , degree=1, df=5) * Disease,
              random=~1| PatientID,
              data=my.data,na.action=na.omit,method="ML")

I wonder if any one can advice with my questions: How can I plot the
predicted mean profiles of the damage for the two groups? How can I make
post-hoc comparison of mean damage across the two disease groups of
patients?

I did tried many online searches but did not find a good answer. So I will
really appreciate your advice!

Gabriela

--
Gabriela Czanner, PhD
Lecturer
Department of Biostatistics
Department of Eye and Vision Science
University of Liverpool

	[[alternative HTML version deleted]]


From mwiederm at mtu.edu  Tue Apr  5 04:53:18 2016
From: mwiederm at mtu.edu (Magdalena Wiedermann)
Date: Mon, 4 Apr 2016 22:53:18 -0400
Subject: [R-sig-ME] glmer vs glmmPQL vs glmmadmb
In-Reply-To: <CAErODj_WAzqrORLf0dQ9T5vv=fhacOBu2XXQpW-hf7Ebx6iYcg@mail.gmail.com>
References: <CAErODj-i4_JeniXN=Hf2BptLQnRk6F3rTo9+vfyqqeGjP8+MkQ@mail.gmail.com>
	<CAErODj9zjwkRq5ba1e98t23Gg0YzwpKxs3xQme_if8kOuF9XiQ@mail.gmail.com>
	<CAErODj8rBfk_rEN_K-3A6n51_1=okOHsi4awzm5kcwW5+NOzcA@mail.gmail.com>
	<CAErODj_WAzqrORLf0dQ9T5vv=fhacOBu2XXQpW-hf7Ebx6iYcg@mail.gmail.com>
Message-ID: <5703289E.8010909@mtu.edu>

Dear List

Quick question: Why is the interaction term usingglmmPQL not 
significant, whereas it is highly significant using glmer and glmmadmb?

Thank you!
Lena

*_
Example:_*

resp = resp<-cbind(data$Dead, data$Alive)

m1<-glmer(resp~(treatm+log(Tree))^2+block+(1|plot), family=binomial, 
data = data)

summary(m1)


m2<-glmmPQL(resp~(treatm+log(Tree))^2+block, random=~1|plot, 
family=binomial, data=data)

summary(m2)


|m3<-|glmmadmb|(||resp||~||(||treatm||+||log(Tree)||)^2||+block, 
random=~1|plot,||||family=||"||binomial||"||, ||data=||data||)|

|summary(m3) |*_Results:_*

 > car::Anova(m1)
Analysis of Deviance Table (Type II Wald chisquare tests)

Response: resp
                                   Chisq Df Pr(>Chisq)
treatm                        82.6249  4     <2e-16 ***
log(Tree)                  17992.6841  1     <2e-16 ***
block                          3.6873  5     0.5953
treatm:log(Tree) 230.6844 4 <2e-16 ***


 >car::Anova(m2)
Analysis of Deviance Table (Type II tests)

Response: resp
                                 Chisq Df Pr(>Chisq)
treatm                       114.4015  4     <2e-16 ***
log(Tree)                    384.7095  1     <2e-16 ***
block                          1.0899  5     0.9550
treatm:log(Tree) 2.9839 4 0.5605

 > car::Anova(m3)
Analysis of Deviance Table (Type II tests)

Response: resp
                               Df     Chisq Pr(>Chisq)
treatm                        4   68.7297  4.208e-14 ***
log(Tree)                     1 1846.9933  < 2.2e-16 ***
block                         5    3.0464     0.6928
treatm:log(Tree) 4 117.7358 < 2.2e-16 ***
Residuals                    734

	
p.s.: this it true for summary(m1,m2,m3) too.



	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Apr  5 05:51:45 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 4 Apr 2016 23:51:45 -0400
Subject: [R-sig-ME] glmer vs glmmPQL vs glmmadmb
In-Reply-To: <5703289E.8010909@mtu.edu>
References: <CAErODj-i4_JeniXN=Hf2BptLQnRk6F3rTo9+vfyqqeGjP8+MkQ@mail.gmail.com>
	<CAErODj9zjwkRq5ba1e98t23Gg0YzwpKxs3xQme_if8kOuF9XiQ@mail.gmail.com>
	<CAErODj8rBfk_rEN_K-3A6n51_1=okOHsi4awzm5kcwW5+NOzcA@mail.gmail.com>
	<CAErODj_WAzqrORLf0dQ9T5vv=fhacOBu2XXQpW-hf7Ebx6iYcg@mail.gmail.com>
	<5703289E.8010909@mtu.edu>
Message-ID: <CABghstRuZ49uCqdHZiAuY0Awa247XsZO2jfAG38uUGb_ixpqEw@mail.gmail.com>

  If glmer and glmmADMB agree with each other and disagree with
glmmPQL, I would generally trust the former (Laplace approximation is
better than PQL, esp for binary data).  However, (1) you should also
try Gauss-Hermite quadrature (nAGQ>1) in glmer, and (2) the very large
magnitude of your parameters makes it look like you probably have a
complete-separation problem ...


On Mon, Apr 4, 2016 at 10:53 PM, Magdalena Wiedermann <mwiederm at mtu.edu> wrote:
> Dear List
>
> Quick question: Why is the interaction term usingglmmPQL not
> significant, whereas it is highly significant using glmer and glmmadmb?
>
> Thank you!
> Lena
>
> *_
> Example:_*
>
> resp = resp<-cbind(data$Dead, data$Alive)
>
> m1<-glmer(resp~(treatm+log(Tree))^2+block+(1|plot), family=binomial,
> data = data)
>
> summary(m1)
>
>
> m2<-glmmPQL(resp~(treatm+log(Tree))^2+block, random=~1|plot,
> family=binomial, data=data)
>
> summary(m2)
>
>
> |m3<-|glmmadmb|(||resp||~||(||treatm||+||log(Tree)||)^2||+block,
> random=~1|plot,||||family=||"||binomial||"||, ||data=||data||)|
>
> |summary(m3) |*_Results:_*
>
>  > car::Anova(m1)
> Analysis of Deviance Table (Type II Wald chisquare tests)
>
> Response: resp
>                                    Chisq Df Pr(>Chisq)
> treatm                        82.6249  4     <2e-16 ***
> log(Tree)                  17992.6841  1     <2e-16 ***
> block                          3.6873  5     0.5953
> treatm:log(Tree) 230.6844 4 <2e-16 ***
>
>
>  >car::Anova(m2)
> Analysis of Deviance Table (Type II tests)
>
> Response: resp
>                                  Chisq Df Pr(>Chisq)
> treatm                       114.4015  4     <2e-16 ***
> log(Tree)                    384.7095  1     <2e-16 ***
> block                          1.0899  5     0.9550
> treatm:log(Tree) 2.9839 4 0.5605
>
>  > car::Anova(m3)
> Analysis of Deviance Table (Type II tests)
>
> Response: resp
>                                Df     Chisq Pr(>Chisq)
> treatm                        4   68.7297  4.208e-14 ***
> log(Tree)                     1 1846.9933  < 2.2e-16 ***
> block                         5    3.0464     0.6928
> treatm:log(Tree) 4 117.7358 < 2.2e-16 ***
> Residuals                    734
>
>
> p.s.: this it true for summary(m1,m2,m3) too.
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From thierry.onkelinx at inbo.be  Tue Apr  5 09:17:50 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 5 Apr 2016 09:17:50 +0200
Subject: [R-sig-ME] lme4 observation level effects with indicator
In-Reply-To: <CAArSc3WC-fJCWy1fSFS-ve0dgjm5Z5PnOakr7yjGHyptNC4SKw@mail.gmail.com>
References: <CAArSc3WC-fJCWy1fSFS-ve0dgjm5Z5PnOakr7yjGHyptNC4SKw@mail.gmail.com>
Message-ID: <CAJuCY5wTDqkzOwWV3Wb3bBVYbO=3q7hd2+p-MdOh2=zY9ZbHkw@mail.gmail.com>

Dear Tiffany,

You could try to make dummy variables for each level of period.
dat$PrePeriod <- as.integer(dat$period == "Pre")
dat$PostPeriod <- as.integer(dat$period == "Post")

mod.pois <- glmer( count ~ 1 + period + year  + year*period +
(period|year.factor) + (period|Site)  + (0 + PrePeriod|Site:year.factor)  +
(0 + PostPeriod|Site:year.factor),
                        data=dat, family=poisson)

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-04-02 21:23 GMT+02:00 Tiffany Vidal <tiffany.vidal at gmail.com>:

> I am interested in estimating a mixed model with a random effect for year,
> site, and an observation-level effect to account for overdispersion,
> assuming Poisson error structure, using the lme4 package in R.
> Additionally, I have an indicator variable 'period' to adjust the parameter
> estimated by pre- and post- time periods. I am running into problems trying
> to specify the observation level effect by time period. I could model this
> using glmer.nb and avoid the observation-level effect, but I would like the
> flexibility to allow overdispersion to vary by time period as well. If
> there was a way to allow the negative binomial scaling parameter to vary by
> time period, I would probably use glmer.nb.
>
> My model as I'm trying to specify with glmer:
> mod.pois <- glmer( count ~ 1 + period + year  + year*period +
> (period|year.factor) + (period|Site) ,
>                         data=dat, family=poisson)
>
> The above runs and I think does what I want, but doesn't include the
> observation-level effect.
>
> I have tried:
> mod.pois <- glmer( count ~ 1 + period + year  + year*period +
> (period|year.factor) + (period|Site)  + (period|Site:year.factor),
>                         data=dat, family=poisson)
>
> but the error indicates identifiability issues. I have one observation at
> each site x year combination.
>
> Is there a way to achieve this using this package? Thank you in advance for
> any thoughts.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Apr  5 09:22:34 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 5 Apr 2016 09:22:34 +0200
Subject: [R-sig-ME] Questions concerning glmmADMB and hurdle model
In-Reply-To: <56FBA07B.10904@cerco.ups-tlse.fr>
References: <56FBA07B.10904@cerco.ups-tlse.fr>
Message-ID: <CAJuCY5xMFkk66ZenbBcw-91g80uMVkjGAJRsQJRJsPcjS6YteQ@mail.gmail.com>

Dear Amirouche,

A common misconception is that a lot of zero's in the the response
automatically implies zero-inflation. Poisson or negative binomial
distributions with low expected values yield a lot of zero's, even without
zero-inflation.

So my advice would be to fit a Poisson or negative binomial model and test
if there is any zero-inflation.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-03-30 11:46 GMT+02:00 Amirouche Sadoun <
amirouche.sadoun at cerco.ups-tlse.fr>:

> Dear Sir,
>
> I'm currently a PhD student in cognitive neurosciences at the CerCo
> laboratory, France.
>
> I'm dealing with a problematic trying to analyze my data with the glmmADMB
> function in R.
> I thank you in advance for paying attention to my present problem
> regarding the use of a Hurdle model with glmmADMB, because I didn't yet
> found a solution, especially as I am new in using R.
> I'm trying to analyze behavioral data containing a given number of trials
> called ab. (Experimental design with repeated measures.  Fixed effects:
> GROUP and DELAY; random effect: the id of the subjects). (Please find the
> data attached).
>
> The response variable is the number of AB responses related to the Total
> number of trials.
> In this data, many subjects had 0 values . This requires the use of a Zero
> inflated or Hurdle model with glmmADMB function (), as it was recommended
> to me.
> I tried than to do the analysis with this function, even if it seems not
> clear to me, but I get error messages, in addition to that I don't know how
> to deal with both models after (with post hoc analysis).
> Please, find the following lines of the R code and the error messages:
>
> datab $ ID <-factor ($ datab ID)
> mod1 <-glmmadmb (cbind (AB, Total-AB) ~ * DELAY GROUP + (1 | ID), data =
> subset (datab, AB> 0), family = "truncnbinom1")
> datab $ nz <- as.numeric (datab $ AB> 0)
> mod2 <-glmmadmb (nz ~ * DELAY GROUP + (1 | ID), data = datab, family =
> "binomial")
>
> The error message: [1] NOTICE: Warning in eval (expr, envir, pen):
> sd.est not defined for this family
> [2] ERROR:
> The maximizer function failed (could not find parameter file)
> Troubleshooting steps include (1) run with
> 'Save.dir' set and inspect output files; (2) changes run parameters
>
> I hope wholeheartedly find help
>
> Please accept the assurance of my distinguished regards.
>
> A. SADOUN
>
> CerCo, UMR 5549
>
> Pavillon Baudot
>
> Toulouse 31052 FRANCE
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Apr  5 10:20:27 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 5 Apr 2016 10:20:27 +0200
Subject: [R-sig-ME] Complex model yields similar results to simpler
 model, but also warnings: can I ignore them?
In-Reply-To: <CAOxxGRk1A-C7=Mp1B3stQ6y2REWfzBpSF5qEFJbYk6-Zc-tUaQ@mail.gmail.com>
References: <CAOxxGRm6qg-o0deD-PaUoxrr_Xkc2qZuntoeDez2Zsq+O2q7RA@mail.gmail.com>
	<CAJuCY5yQBWbYJmdqa4bCS7bQs6rCDeOGNGnxJDDZnHu8LVoHJQ@mail.gmail.com>
	<CAOxxGRk1A-C7=Mp1B3stQ6y2REWfzBpSF5qEFJbYk6-Zc-tUaQ@mail.gmail.com>
Message-ID: <CAJuCY5ye0z2R-4H2JYCKiEuz4XfEQ7etQNm6ZLmyA=qRWyGjzA@mail.gmail.com>

Hi Jackie,

IMHO it is safer to drop the models with the warnings and keep a simpler
model. Although you have some visual evidence for the more complex models,
the data doesn't provide the evidence. This is probably because you have
too few observations for the complex model.

Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-03-31 18:40 GMT+02:00 Jackie Wood <jackiewood7 at gmail.com>:

> Hi Thierry,
>
> Thanks for the quick response! I've tried the following variance weight
> structures:
>
> vf1 <- varIdent (form = ~ 1 | cross*age_bin)
>
> vf2 <- varExp (form = ~ age_bin | cross)
>
> vf3 <- varComb (varIdent(form =~ 1 | cross), varExp (form = ~ age_bin))
>
> vf4 <- varExp (form = ~ age_bin)
>
> vf2 and vf3 yielded the same warnings as for the original model (using
> vf1). vf4 ran fine but  I do think the data indicate that there are some
> differences in heteroscedasticity among the crosses as well. The AIC value
> was quite a bit lower for the model using vf1 but perhaps that is not
> entirely trustworthy given the warnings that were generated.
>
> I guess my original question stands about whether this warning means that
> the model is bad news and I should go with something like varExp (form = ~
> age_bin) regardless of which specification seems preferred via comparison
> of AIC values. Or if, because all other relevant output stays fairly
> consistent regardless of the variance weighting specification, I can
> proceed with the more complex version.
>
> Jackie
>
>
>
>
>
> On Thu, Mar 31, 2016 at 10:53 AM, Thierry Onkelinx <
> thierry.onkelinx at inbo.be> wrote:
>
>> Dear Jackie,
>>
>> I presume that the heteroscedasticy along age_bin is somewhat smooth. In
>> such case you use a less parametrised model the variance. Like e.g.
>> varExp(form = ~age_bin|cross). ?varClasses gives an overview of available
>> classes. Note that you can combine classes with varComb().
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2016-03-31 16:14 GMT+02:00 Jackie Wood <jackiewood7 at gmail.com>:
>>
>>> Hello R-users,
>>>
>>> I'm attempting to model differences in fork length over time for 4
>>> different cross types of a species of freshwater fish using the most
>>> recent
>>> version of nlme . Examining plots of the data, fork length increases
>>> non-linearly over time so I've included a second order polynomial for age
>>> such that the fixed effects portion of the model has the following
>>> specification:
>>>
>>> model <- lme(FL ~ cross * age_bin + cross*I(age_bin^2)
>>>
>>> Plots of the random effects suggest evidence for random slopes with
>>> respect
>>> to family for age and age^2, and further these are correlated with the
>>> intercept.
>>>
>>> So I specified the random effects part as:
>>>
>>> random = ~age_bin + I(age_bin^2)|fam
>>>
>>> Likelihood ratio tests do favor this random effects structure over
>>> simpler
>>> structures.
>>>
>>> Plotting the residuals, variance in length definitely increases with
>>> increasing age and also appears to vary per cross type so I added the
>>> following variance weighting structure to the model:
>>>
>>> weights = varIdent(form = ~ 1|cross*age_bin))
>>>
>>> I've performed typical likelihood ratio tests which consistently favor
>>> the
>>> model described above over other simpler model specifications (in terms
>>> of
>>> random effects specifications, and variance weighting), but with the
>>> above
>>> model I also get a few of these types of warnings:
>>>
>>> 1: In logLik.reStruct(object, conLin) :
>>>   Singular precision matrix in level -1, block 15
>>>
>>> Searching online help forums the advice I see is that the model is likely
>>> overparameterized, and indeed if I remove either the variance weighting
>>> completely, or simplify the random effects to 1|fam (any random slope
>>> type
>>> random effects specification gives the same warning), everything works
>>> just
>>> fine. I also checked the raw data which seems sound to me.
>>>
>>> I do feel as though the more complex random effects structure is
>>> warranted
>>> from plotting the data and there is definitely heteroscedasticity to
>>> account for. When I run the above model without the variance weights, the
>>> resulting fixed effects coefficients and estimated random effects and
>>> correlations have values that are pretty close to the model with variance
>>> weights (the residual variance is of course different). So my question is
>>> how important are the warnings? If the output seems reasonable and
>>> corresponds pretty closely with the output of a simpler model that runs
>>> just fine, is it justifiable to ignore the warnings or am I asking for
>>> trouble?
>>>
>>> I mean, I could get rid of the variance weighting structure and simply
>>> transform fork length, it does help the heteroscedasticity issue, but I
>>> do
>>> find the variance interesting and transforming it away wouldn't be my
>>> first
>>> choice.
>>>
>>> I'd really appreciate your input!
>>>
>>> Jackie
>>>
>>> --
>>> Jacquelyn L.A. Wood, PhD.
>>> 224 Montrose Avenue
>>> Toronto, ON
>>> M6G 3G7
>>> Phone: (514) 293-7255
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>
>
> --
> Jacquelyn L.A. Wood, PhD.
> 224 Montrose Avenue
> Toronto, ON
> M6G 3G7
> Phone: (514) 293-7255
>
>

	[[alternative HTML version deleted]]


From M.Fairbrother at bristol.ac.uk  Tue Apr  5 12:02:08 2016
From: M.Fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Tue, 5 Apr 2016 11:02:08 +0100
Subject: [R-sig-ME] GLMM estimation readings?
Message-ID: <CAAH-yP_So5pxX6LKBJur4ptb2ZcvCi+PKgdTiwXe=F8Y5C3UBA@mail.gmail.com>

Hi Paul,
(1) To my mind, it would be helpful to keep specification and estimation
separate. RE vs. FE is a specification issue (more on this below), while
adaptive quadrature vs. Laplace approximation is an estimation issue. (And
that doesn't get into issues of Bayesian vs. frequentist, which might arise
if you start using MCMC estimation, which personally I find quite useful
for G/LMMs. The simulation studies I've seen have generally found that MCMC
is most reliable.)
(2) Hausman: This simply tests whether the within-group and between-group
effects are different. Usually they will be, and the Hausman test will tell
you so. Economists (but not only economists) often take this to mean that
Hausman is a "specification test" adjudicating between RE and FE models,
and thus usually "rejecting" RE. However, as you suggest, one can easily
allow for different between and within effects in a RE model, simply by
including group means of each X as level-2 covariates. There's a lot of
misunderstanding about this.
(3) Bias: If the between and within effects are different, but you estimate
a single beta that does not distinguish between them, that beta will be a
weighted average of the two. As the economists suggest, this beta will be a
biased estimator of the purely within estimate that you get from a FE
model. But, again, if you include the group means in a RE model, you can
get unbiased results for both with the within and between relationships.
(In a FE model, you get only the within, not the between.)
(4) If the (within) relationship between some x and y varies across groups,
then the standard errors returned by a FE model will be anticonservative
(even if Stata consecrates them as "robust"). So will the SEs returned by a
random intercepts-only RE model. Only a random-slopes RE model will return
unbiased SEs.
All of the above is discussed and demonstrated in the following three
papers (one unpublished):
http://dx.doi.org/10.1017/psrm.2014.7
http://dx.doi.org/10.1017/psrm.2013.24
www.researchgate.net/publication/299604336_Fixed_and_Random_effects_making_an_informed_choice
The first two papers are the most cited from *Political Science Research &
Methods*.
Hope that's useful,
Malcolm



> From: Paul Johnson <pauljohn32 at gmail.com>
> To: "R-SIG-Mixed-Models at r-project.org"
>         <r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] GLMM estimation readings?
>
> I'm trying to explain GLMM estimation and defend random effects in an
> audience of econometricians.  I am focused on logit models, mostly, with
> random intercepts.
>
> The literature is difficult. I can understand applications and overviews
> like the paper by Bolker et al in Trends in Ecology and Evolution. But I
> can't understand much about glmer that is deeper than that.  Can you point
> me at some books/articles that explain the GLMM estimation process in an
> understandable way? Is there a PLS derivation for GLMM?  I want to better
> understand adaptive quadrature. And Laplace approximation.
>
> You might be able to advise me better if I tell you why I need to know.
>
> I was surprised to learn that economists hate random effects. It is almost
> visceral. For the economists, the fixed vs random effects debate is not
> philosophical, but rather practical. In an LMM, the Hausman test seems to
> bluntly reject almost all random effects models.  (See William Greene's
> Econometrics book).  Unmeasured group-level predictors always exist, it
> seems, so random effects estimates are biased/inconsistent. Even if you
> believe Intercept differences are random, LMM estimates are
> biased/inconsistent, so you should treat as fixed.
>
> I'm a little surprised there is so little discussion of Hausman's test in
> the random effect literature outside economics.
>
> One argument used by random effect advocates, that group-level predictors
> can be included in LMM, holds no weight at all. It is just evidence of bias
> in LMM. Well, the estimates thus obtained are useless because, if the group
> level intercept estimates were correct, then the group-level predictors
> would not be identifiable.
>
> My argument with them so far is based on the characterization of LMM as a
> PLS exercise, which I learned in this email list. That makes a point
> obvious: the fixed vs random models differ because PLS penalizes the b's,
> but fixed estimators do not. The issue is not "random" against "fixed". It
> is penalized against unpenalized. The parallel between LMM and ridge
> regression and LASSO helps.  If the number of observations within groups
> grows, then the posterior modes  and the fixed effect estimates converge.
> Yes?
>
> The small sample debate hinges on mean square error of the b's. The PLS
> view makes it plain that Empirical Bayes gives shrinkage not as
> afterthought (as it seems in the GLS narrative), but as a primary element
> (Henderson's estimator).   Ironically, the shrinkage effect of LMM, widely
> praised in stats and hierarchical modeling applications, raises suspicion
> of bias. One might prefer a biased, but lower variance estimate of b, and
> that's shrinkage.  That's my theme, anyway, we'll see if I can sell it.
>
> In that context, I come to the chore of comparing a glmer estimate with a
> fixed effect method known as conditional logit or Chamberlain's panel logit
> model.
>
> pj
> Paul Johnson
> http://pj.freefaculty.org
>
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Apr  5 16:22:33 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 5 Apr 2016 16:22:33 +0200
Subject: [R-sig-ME] lme4 observation level effects with indicator
In-Reply-To: <CAArSc3WakQzC39qya3vVDc6+ce_5S6oGhEaUWr9rAUBwcAPsZw@mail.gmail.com>
References: <CAArSc3WC-fJCWy1fSFS-ve0dgjm5Z5PnOakr7yjGHyptNC4SKw@mail.gmail.com>
	<CAJuCY5wTDqkzOwWV3Wb3bBVYbO=3q7hd2+p-MdOh2=zY9ZbHkw@mail.gmail.com>
	<CAArSc3WakQzC39qya3vVDc6+ce_5S6oGhEaUWr9rAUBwcAPsZw@mail.gmail.com>
Message-ID: <CAJuCY5y8FK-ahAsiPqCwkvfdju=xawDPYOaNzCPv7pdN22mBMg@mail.gmail.com>

Hi Tiffany,

The standard formula for a random slope is (slope | group). When slope is
numeric, the formula translate to b_i0 + b_i1*slope. b_i0 is the random
intercept for group i, b_i1 is its random slope.

(0 + slope | group) removes the intercept. In case of numeric slope this
sets all b_i0 = 0. Hence reducing the random effect to b_i1*slope.

In case of dummy coding slope is either 0 or 1. So (0 + PrePeriod|group) is
equivalent to b_i1 * 1 = b_i1 when Period == "Pre" and b_i1 * 0 = 0 when
Period != "Pre". Hence (0 + PrePeriod|group) is equivalent to a random
intercept for group when Period == "Pre".

When group is the finest level of grouping with only differences in period,
then (0 + PrePeriod|group) is an observation level random effect (OLRE) for
the observation with period == "Pre".

So (0 + PrePeriod|group)  + (0 + PostPeriod|group) gives two OLRE
conditional on period. Both random effects are independent and can have a
different variance.

(0 + period | group) will also estimate the covariance between the two
periodes. But that is probably to complex given the data.

Best regards,



ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-04-05 16:02 GMT+02:00 Tiffany Vidal <tiffany.vidal at gmail.com>:

> Hi Thierry,
>
> Thank you for the reply. Would you be able to explain what the 0 does (I
> have read the lme4 documentation, but it's not very clear to me), and why
> you would use the (0+ PrePeriod|...) for the site x year interaction term
> and not the other two random effects that should also vary by period? Would
> that coding be more appropriate for the year.factor and Site random effects
> too? Also, why does it work differently if I have a single factor column of
> 0s and 1s named 'period' and simply use (0+ period | Site:year.factor)?
>
> Thank you again!
> Tiffany
>
> On Tue, Apr 5, 2016 at 3:17 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be
> > wrote:
>
>> Dear Tiffany,
>>
>> You could try to make dummy variables for each level of period.
>> dat$PrePeriod <- as.integer(dat$period == "Pre")
>> dat$PostPeriod <- as.integer(dat$period == "Post")
>>
>> mod.pois <- glmer( count ~ 1 + period + year  + year*period +
>> (period|year.factor) + (period|Site)  + (0 + PrePeriod|Site:year.factor)
>> + (0 + PostPeriod|Site:year.factor),
>>                         data=dat, family=poisson)
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2016-04-02 21:23 GMT+02:00 Tiffany Vidal <tiffany.vidal at gmail.com>:
>>
>>> I am interested in estimating a mixed model with a random effect for
>>> year,
>>> site, and an observation-level effect to account for overdispersion,
>>> assuming Poisson error structure, using the lme4 package in R.
>>> Additionally, I have an indicator variable 'period' to adjust the
>>> parameter
>>> estimated by pre- and post- time periods. I am running into problems
>>> trying
>>> to specify the observation level effect by time period. I could model
>>> this
>>> using glmer.nb and avoid the observation-level effect, but I would like
>>> the
>>> flexibility to allow overdispersion to vary by time period as well. If
>>> there was a way to allow the negative binomial scaling parameter to vary
>>> by
>>> time period, I would probably use glmer.nb.
>>>
>>> My model as I'm trying to specify with glmer:
>>> mod.pois <- glmer( count ~ 1 + period + year  + year*period +
>>> (period|year.factor) + (period|Site) ,
>>>                         data=dat, family=poisson)
>>>
>>> The above runs and I think does what I want, but doesn't include the
>>> observation-level effect.
>>>
>>> I have tried:
>>> mod.pois <- glmer( count ~ 1 + period + year  + year*period +
>>> (period|year.factor) + (period|Site)  + (period|Site:year.factor),
>>>                         data=dat, family=poisson)
>>>
>>> but the error indicates identifiability issues. I have one observation at
>>> each site x year combination.
>>>
>>> Is there a way to achieve this using this package? Thank you in advance
>>> for
>>> any thoughts.
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From tiffany.vidal at gmail.com  Tue Apr  5 16:02:08 2016
From: tiffany.vidal at gmail.com (Tiffany Vidal)
Date: Tue, 5 Apr 2016 10:02:08 -0400
Subject: [R-sig-ME] lme4 observation level effects with indicator
In-Reply-To: <CAJuCY5wTDqkzOwWV3Wb3bBVYbO=3q7hd2+p-MdOh2=zY9ZbHkw@mail.gmail.com>
References: <CAArSc3WC-fJCWy1fSFS-ve0dgjm5Z5PnOakr7yjGHyptNC4SKw@mail.gmail.com>
	<CAJuCY5wTDqkzOwWV3Wb3bBVYbO=3q7hd2+p-MdOh2=zY9ZbHkw@mail.gmail.com>
Message-ID: <CAArSc3WakQzC39qya3vVDc6+ce_5S6oGhEaUWr9rAUBwcAPsZw@mail.gmail.com>

Hi Thierry,

Thank you for the reply. Would you be able to explain what the 0 does (I
have read the lme4 documentation, but it's not very clear to me), and why
you would use the (0+ PrePeriod|...) for the site x year interaction term
and not the other two random effects that should also vary by period? Would
that coding be more appropriate for the year.factor and Site random effects
too? Also, why does it work differently if I have a single factor column of
0s and 1s named 'period' and simply use (0+ period | Site:year.factor)?

Thank you again!
Tiffany

On Tue, Apr 5, 2016 at 3:17 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Tiffany,
>
> You could try to make dummy variables for each level of period.
> dat$PrePeriod <- as.integer(dat$period == "Pre")
> dat$PostPeriod <- as.integer(dat$period == "Post")
>
> mod.pois <- glmer( count ~ 1 + period + year  + year*period +
> (period|year.factor) + (period|Site)  + (0 + PrePeriod|Site:year.factor)
> + (0 + PostPeriod|Site:year.factor),
>                         data=dat, family=poisson)
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2016-04-02 21:23 GMT+02:00 Tiffany Vidal <tiffany.vidal at gmail.com>:
>
>> I am interested in estimating a mixed model with a random effect for year,
>> site, and an observation-level effect to account for overdispersion,
>> assuming Poisson error structure, using the lme4 package in R.
>> Additionally, I have an indicator variable 'period' to adjust the
>> parameter
>> estimated by pre- and post- time periods. I am running into problems
>> trying
>> to specify the observation level effect by time period. I could model this
>> using glmer.nb and avoid the observation-level effect, but I would like
>> the
>> flexibility to allow overdispersion to vary by time period as well. If
>> there was a way to allow the negative binomial scaling parameter to vary
>> by
>> time period, I would probably use glmer.nb.
>>
>> My model as I'm trying to specify with glmer:
>> mod.pois <- glmer( count ~ 1 + period + year  + year*period +
>> (period|year.factor) + (period|Site) ,
>>                         data=dat, family=poisson)
>>
>> The above runs and I think does what I want, but doesn't include the
>> observation-level effect.
>>
>> I have tried:
>> mod.pois <- glmer( count ~ 1 + period + year  + year*period +
>> (period|year.factor) + (period|Site)  + (period|Site:year.factor),
>>                         data=dat, family=poisson)
>>
>> but the error indicates identifiability issues. I have one observation at
>> each site x year combination.
>>
>> Is there a way to achieve this using this package? Thank you in advance
>> for
>> any thoughts.
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

	[[alternative HTML version deleted]]


From mwiederm at mtu.edu  Tue Apr  5 16:53:53 2016
From: mwiederm at mtu.edu (Magdalena Wiedermann)
Date: Tue, 5 Apr 2016 10:53:53 -0400
Subject: [R-sig-ME] glmer vs glmmPQL vs glmmadmb
In-Reply-To: <CABghstRuZ49uCqdHZiAuY0Awa247XsZO2jfAG38uUGb_ixpqEw@mail.gmail.com>
References: <CAErODj-i4_JeniXN=Hf2BptLQnRk6F3rTo9+vfyqqeGjP8+MkQ@mail.gmail.com>
	<CAErODj9zjwkRq5ba1e98t23Gg0YzwpKxs3xQme_if8kOuF9XiQ@mail.gmail.com>
	<CAErODj8rBfk_rEN_K-3A6n51_1=okOHsi4awzm5kcwW5+NOzcA@mail.gmail.com>
	<CAErODj_WAzqrORLf0dQ9T5vv=fhacOBu2XXQpW-hf7Ebx6iYcg@mail.gmail.com>
	<5703289E.8010909@mtu.edu>
	<CABghstRuZ49uCqdHZiAuY0Awa247XsZO2jfAG38uUGb_ixpqEw@mail.gmail.com>
Message-ID: <5703D181.4040003@mtu.edu>

Thank you Ben!

Indeed there is a problem and I keep coming back to this dater after 
having learned more about GLMM on other projects. I tried the suggested 
Gauss-Hermite quadrature. The higher the nAGQ number the more 
interactions become significant in the summary output. The car::Anova 
output stays the same though. I have a lot of Zero values both in one of 
my explanatory variables as well as in about half of my response values. 
Adding 1 and log transforming both of them (which is admittedly 
questionable in terms of elegance) reduces the importance of the 
interaction term but loosens up the cluster in the residual plots. 
During a previous attempt I had talked to Dave about using a zero 
inflation model, but we had concluded that this is not the way to go. 
Now I don't know where to go, because my residual plots are always 
highly clustered around the many 0 (1) values.

Thank you
Lena


On 04/04/2016 11:51 PM, Ben Bolker wrote:
>    If glmer and glmmADMB agree with each other and disagree with
> glmmPQL, I would generally trust the former (Laplace approximation is
> better than PQL, esp for binary data).  However, (1) you should also
> try Gauss-Hermite quadrature (nAGQ>1) in glmer, and (2) the very large
> magnitude of your parameters makes it look like you probably have a
> complete-separation problem ...
>
>
> On Mon, Apr 4, 2016 at 10:53 PM, Magdalena Wiedermann <mwiederm at mtu.edu> wrote:
>> Dear List
>>
>> Quick question: Why is the interaction term usingglmmPQL not
>> significant, whereas it is highly significant using glmer and glmmadmb?
>>
>> Thank you!
>> Lena
>>
>> *_
>> Example:_*
>>
>> resp = resp<-cbind(data$Dead, data$Alive)
>>
>> m1<-glmer(resp~(treatm+log(Tree))^2+block+(1|plot), family=binomial,
>> data = data)
>>
>> summary(m1)
>>
>>
>> m2<-glmmPQL(resp~(treatm+log(Tree))^2+block, random=~1|plot,
>> family=binomial, data=data)
>>
>> summary(m2)
>>
>>
>> |m3<-|glmmadmb|(||resp||~||(||treatm||+||log(Tree)||)^2||+block,
>> random=~1|plot,||||family=||"||binomial||"||, ||data=||data||)|
>>
>> |summary(m3) |*_Results:_*
>>
>>   > car::Anova(m1)
>> Analysis of Deviance Table (Type II Wald chisquare tests)
>>
>> Response: resp
>>                                     Chisq Df Pr(>Chisq)
>> treatm                        82.6249  4     <2e-16 ***
>> log(Tree)                  17992.6841  1     <2e-16 ***
>> block                          3.6873  5     0.5953
>> treatm:log(Tree) 230.6844 4 <2e-16 ***
>>
>>
>>   >car::Anova(m2)
>> Analysis of Deviance Table (Type II tests)
>>
>> Response: resp
>>                                   Chisq Df Pr(>Chisq)
>> treatm                       114.4015  4     <2e-16 ***
>> log(Tree)                    384.7095  1     <2e-16 ***
>> block                          1.0899  5     0.9550
>> treatm:log(Tree) 2.9839 4 0.5605
>>
>>   > car::Anova(m3)
>> Analysis of Deviance Table (Type II tests)
>>
>> Response: resp
>>                                 Df     Chisq Pr(>Chisq)
>> treatm                        4   68.7297  4.208e-14 ***
>> log(Tree)                     1 1846.9933  < 2.2e-16 ***
>> block                         5    3.0464     0.6928
>> treatm:log(Tree) 4 117.7358 < 2.2e-16 ***
>> Residuals                    734
>>
>>
>> p.s.: this it true for summary(m1,m2,m3) too.
>>
>>
>>
>>          [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From samantha.cox at plymouth.ac.uk  Tue Apr  5 17:43:52 2016
From: samantha.cox at plymouth.ac.uk (Samantha Cox)
Date: Tue, 5 Apr 2016 15:43:52 +0000
Subject: [R-sig-ME] Fitting interaction term in GAMM with random effect
Message-ID: <7AEB852E418272489F0B582BAC54FCC8ACB8CE89@TIS102.uopnet.plymouth.ac.uk>

Hi,

First sorry for cross posting with the R datatable help page -  I was not sure which list is more appropriate.

I am trying to fit a model with a random effect of DeploymentID with a nested AR1 autoregressive correlation structure.  For the fixed component I am fitting a smooth of tide.  I have two sets of models I am fitting with different data sets.  For the smooth of tide, I want a separate smooth to be fitted per SiteID.  In one set of models this is fine (each SiteID contains multiple DeploymentIDs).  In the other SiteID and DeploymentID are identical.  I am wondering how to code this.  I am not interested in the intercept of SiteID hence why it has previously been a random effect.  I am interested in how smooths vary between SiteIDs and hence why this is a fixed effect.

Example data structure first data set:

SiteID    DeploymentID
1                  1
1                  1
1                  1
1                  1
1                  1
1                  2
1                  2
1                  2
1                  3
2                  4
2                  4
2                  4
2                  4
2                  4
2                  5
2                  5
2                  5
3                  6
3                  7
3                  8
etc etc

Example data structure seconddata set:

SiteID    DeploymentID
1                  1
2                  2
3                  3
4                  4

My problem is that I understand to fit a interaction term, one must use
gamm(Y~s(tide,k=5,bs="cc",by=SiteID)+SiteID,knots=list(tide=c(0,1)),correlation=corAR1(form=~1|DeploymentID).....

- if I include +SiteID then I should NOT include DeploymentID as a random effect also (for the second model where SiteId and DeploymentID are identical - but this is ok for the first model)?
- the problem is when I want to compare nested models I run into issues if the smooth term is dropped as I do not have a random or smooth term in the model.

Can I code as
gamm(Y~s(tide,k=5,bs="cc",by=SiteID),knots=list(tide=c(0,1)),random=list(DeploymentID=~1),correlation=corAR1(form=~1|DeploymentID).....

Any help on this is appreciated....

Cheers
________________________________
[http://www.plymouth.ac.uk/images/email_footer.gif]<http://www.plymouth.ac.uk/worldclass>

This email and any files with it are confidential and intended solely for the use of the recipient to whom it is addressed. If you are not the intended recipient then copying, distribution or other use of the information contained is strictly prohibited and you should not rely on it. If you have received this email in error please let the sender know immediately and delete it from your system(s). Internet emails are not necessarily secure. While we take every care, Plymouth University accepts no responsibility for viruses and it is your responsibility to scan emails and their attachments. Plymouth University does not accept responsibility for any changes made after it was sent. Nothing in this email or its attachments constitutes an order for goods or services unless accompanied by an official order form.

	[[alternative HTML version deleted]]


From jackiewood7 at gmail.com  Tue Apr  5 17:54:02 2016
From: jackiewood7 at gmail.com (Jackie Wood)
Date: Tue, 5 Apr 2016 11:54:02 -0400
Subject: [R-sig-ME] Complex model yields similar results to simpler
 model, but also warnings: can I ignore them?
In-Reply-To: <CAJuCY5ye0z2R-4H2JYCKiEuz4XfEQ7etQNm6ZLmyA=qRWyGjzA@mail.gmail.com>
References: <CAOxxGRm6qg-o0deD-PaUoxrr_Xkc2qZuntoeDez2Zsq+O2q7RA@mail.gmail.com>
	<CAJuCY5yQBWbYJmdqa4bCS7bQs6rCDeOGNGnxJDDZnHu8LVoHJQ@mail.gmail.com>
	<CAOxxGRk1A-C7=Mp1B3stQ6y2REWfzBpSF5qEFJbYk6-Zc-tUaQ@mail.gmail.com>
	<CAJuCY5ye0z2R-4H2JYCKiEuz4XfEQ7etQNm6ZLmyA=qRWyGjzA@mail.gmail.com>
Message-ID: <CAOxxGRnin=RxXxuULgs4rnXq3FZ5+tg1cpKRVx1Mvg9xa-ew=Q@mail.gmail.com>

Hi Thierry,

Ok! Thanks for the advice; I'll go ahead with the simpler model.

Cheers,
Jackie


On Tue, Apr 5, 2016 at 4:20 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Hi Jackie,
>
> IMHO it is safer to drop the models with the warnings and keep a simpler
> model. Although you have some visual evidence for the more complex models,
> the data doesn't provide the evidence. This is probably because you have
> too few observations for the complex model.
>
> Best regards,
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2016-03-31 18:40 GMT+02:00 Jackie Wood <jackiewood7 at gmail.com>:
>
>> Hi Thierry,
>>
>> Thanks for the quick response! I've tried the following variance weight
>> structures:
>>
>> vf1 <- varIdent (form = ~ 1 | cross*age_bin)
>>
>> vf2 <- varExp (form = ~ age_bin | cross)
>>
>> vf3 <- varComb (varIdent(form =~ 1 | cross), varExp (form = ~ age_bin))
>>
>> vf4 <- varExp (form = ~ age_bin)
>>
>> vf2 and vf3 yielded the same warnings as for the original model (using
>> vf1). vf4 ran fine but  I do think the data indicate that there are some
>> differences in heteroscedasticity among the crosses as well. The AIC value
>> was quite a bit lower for the model using vf1 but perhaps that is not
>> entirely trustworthy given the warnings that were generated.
>>
>> I guess my original question stands about whether this warning means that
>> the model is bad news and I should go with something like varExp (form = ~
>> age_bin) regardless of which specification seems preferred via comparison
>> of AIC values. Or if, because all other relevant output stays fairly
>> consistent regardless of the variance weighting specification, I can
>> proceed with the more complex version.
>>
>> Jackie
>>
>>
>>
>>
>>
>> On Thu, Mar 31, 2016 at 10:53 AM, Thierry Onkelinx <
>> thierry.onkelinx at inbo.be> wrote:
>>
>>> Dear Jackie,
>>>
>>> I presume that the heteroscedasticy along age_bin is somewhat smooth. In
>>> such case you use a less parametrised model the variance. Like e.g.
>>> varExp(form = ~age_bin|cross). ?varClasses gives an overview of available
>>> classes. Note that you can combine classes with varComb().
>>>
>>> Best regards,
>>>
>>> ir. Thierry Onkelinx
>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>> and Forest
>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>> Kliniekstraat 25
>>> 1070 Anderlecht
>>> Belgium
>>>
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of data.
>>> ~ John Tukey
>>>
>>> 2016-03-31 16:14 GMT+02:00 Jackie Wood <jackiewood7 at gmail.com>:
>>>
>>>> Hello R-users,
>>>>
>>>> I'm attempting to model differences in fork length over time for 4
>>>> different cross types of a species of freshwater fish using the most
>>>> recent
>>>> version of nlme . Examining plots of the data, fork length increases
>>>> non-linearly over time so I've included a second order polynomial for
>>>> age
>>>> such that the fixed effects portion of the model has the following
>>>> specification:
>>>>
>>>> model <- lme(FL ~ cross * age_bin + cross*I(age_bin^2)
>>>>
>>>> Plots of the random effects suggest evidence for random slopes with
>>>> respect
>>>> to family for age and age^2, and further these are correlated with the
>>>> intercept.
>>>>
>>>> So I specified the random effects part as:
>>>>
>>>> random = ~age_bin + I(age_bin^2)|fam
>>>>
>>>> Likelihood ratio tests do favor this random effects structure over
>>>> simpler
>>>> structures.
>>>>
>>>> Plotting the residuals, variance in length definitely increases with
>>>> increasing age and also appears to vary per cross type so I added the
>>>> following variance weighting structure to the model:
>>>>
>>>> weights = varIdent(form = ~ 1|cross*age_bin))
>>>>
>>>> I've performed typical likelihood ratio tests which consistently favor
>>>> the
>>>> model described above over other simpler model specifications (in terms
>>>> of
>>>> random effects specifications, and variance weighting), but with the
>>>> above
>>>> model I also get a few of these types of warnings:
>>>>
>>>> 1: In logLik.reStruct(object, conLin) :
>>>>   Singular precision matrix in level -1, block 15
>>>>
>>>> Searching online help forums the advice I see is that the model is
>>>> likely
>>>> overparameterized, and indeed if I remove either the variance weighting
>>>> completely, or simplify the random effects to 1|fam (any random slope
>>>> type
>>>> random effects specification gives the same warning), everything works
>>>> just
>>>> fine. I also checked the raw data which seems sound to me.
>>>>
>>>> I do feel as though the more complex random effects structure is
>>>> warranted
>>>> from plotting the data and there is definitely heteroscedasticity to
>>>> account for. When I run the above model without the variance weights,
>>>> the
>>>> resulting fixed effects coefficients and estimated random effects and
>>>> correlations have values that are pretty close to the model with
>>>> variance
>>>> weights (the residual variance is of course different). So my question
>>>> is
>>>> how important are the warnings? If the output seems reasonable and
>>>> corresponds pretty closely with the output of a simpler model that runs
>>>> just fine, is it justifiable to ignore the warnings or am I asking for
>>>> trouble?
>>>>
>>>> I mean, I could get rid of the variance weighting structure and simply
>>>> transform fork length, it does help the heteroscedasticity issue, but I
>>>> do
>>>> find the variance interesting and transforming it away wouldn't be my
>>>> first
>>>> choice.
>>>>
>>>> I'd really appreciate your input!
>>>>
>>>> Jackie
>>>>
>>>> --
>>>> Jacquelyn L.A. Wood, PhD.
>>>> 224 Montrose Avenue
>>>> Toronto, ON
>>>> M6G 3G7
>>>> Phone: (514) 293-7255
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>>
>>
>>
>> --
>> Jacquelyn L.A. Wood, PhD.
>> 224 Montrose Avenue
>> Toronto, ON
>> M6G 3G7
>> Phone: (514) 293-7255
>>
>>
>


-- 
Jacquelyn L.A. Wood, PhD.
224 Montrose Avenue
Toronto, ON
M6G 3G7
Phone: (514) 293-7255

	[[alternative HTML version deleted]]


From russell-lenth at uiowa.edu  Tue Apr  5 18:31:02 2016
From: russell-lenth at uiowa.edu (Lenth, Russell V)
Date: Tue, 5 Apr 2016 16:31:02 +0000
Subject: [R-sig-ME] Output and post-hoc comparisons for lme with splines
 specification of fixed effects
Message-ID: <BY2PR0401MB0919D96FDA24F832F5A2CA87F19E0@BY2PR0401MB0919.namprd04.prod.outlook.com>

There are all kinds of ways to plot the predictions. All you need to do is create a data.frame, say 'new.df', with the desired combinations of Location and Disease, then obtain the predictions using

	predict(model, newdata = new.df)

and plot the results using whatever plotting functions you like.

To do post hoc comparisons, note that your model specifies an interaction between the factors, so the comparison will be different at each Location. The lsmeans package produces predictions, or averages thereof, over a regular grid of values, and facilitates the kind of analysis you want.(These results are called "predicted marginal means", or PMMs.) It would go something like this:

	library("lsmeans")
	model.pmm <- pmmeans(model, ~ Disease | Location, at = list(Location = 1:10))   
			#### but probably change the Location values

	# comparisons of predictions at each Location specified:
	pairs(model.pmm)

	# Plot of predictions, separately for each Disease
	pmmip(model.pmm, Disease ~ Location)

If you don't like the style of the plot, you can do

	new.df <- summary(model.pmm)

which produces a data.frame with the values of Disease, Location, and predictions (named "pmmeans"), which you can plot using whatever methods you like.

If you prefer the terminology "least-squares means" to "predicted marginal means", you get the same results using the functions 'lsmeans' and 'lsmip'. 

--
Russell V. Lenth ?- ?Professor Emeritus
Department of Statistics and Actuarial Science ??
The University of Iowa ?- ?Iowa City, IA 52242 ?USA ??
Voice (319)335-0712 ?- ?FAX (319)335-3017
russell-lenth at uiowa.edu??- ?http://www.stat.uiowa.edu/~rlenth/?


-------
Gabriela Czanner wrote:

Dear R-users,

I am attempting to estimate a difference in damage across space (at 24
locations) for two disease types of patients (defined as a factor, 0
disease absent, 1 disease present). Examining the plots of the damage
across the 24 locations in space it appears that the damage increases then
decreases and it is best described by a spline specification like this:

model<- lme( Damage ~ bs( Location , degree=1, df=5) * Disease,
              random=~1| PatientID,
              data=my.data,na.action=na.omit,method="ML")

I wonder if any one can advice with my questions: How can I plot the
predicted mean profiles of the damage for the two groups? How can I make
post-hoc comparison of mean damage across the two disease groups of
patients?

I did tried many online searches but did not find a good answer. So I will
really appreciate your advice!

Gabriela

--
Gabriela Czanner, PhD
Lecturer
Department of Biostatistics
Department of Eye and Vision Science
University of Liverpool


From bates at stat.wisc.edu  Tue Apr  5 20:58:56 2016
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 05 Apr 2016 18:58:56 +0000
Subject: [R-sig-ME] GLMM estimation readings?
In-Reply-To: <CAErODj_WAzqrORLf0dQ9T5vv=fhacOBu2XXQpW-hf7Ebx6iYcg@mail.gmail.com>
References: <CAErODj-i4_JeniXN=Hf2BptLQnRk6F3rTo9+vfyqqeGjP8+MkQ@mail.gmail.com>
	<CAErODj9zjwkRq5ba1e98t23Gg0YzwpKxs3xQme_if8kOuF9XiQ@mail.gmail.com>
	<CAErODj8rBfk_rEN_K-3A6n51_1=okOHsi4awzm5kcwW5+NOzcA@mail.gmail.com>
	<CAErODj_WAzqrORLf0dQ9T5vv=fhacOBu2XXQpW-hf7Ebx6iYcg@mail.gmail.com>
Message-ID: <CAO7JsnS5QfHaGKEY0xMuEU0GAJvUaAHO1S1N+m_46kLz51kSJA@mail.gmail.com>

Hi Paul,

I recently added fitting of GLMMs to the MixedModels package for Julia (
https://github.com/dmbates/MixedModels.jl).  It is by no means finished but
it does fit a couple of examples.

I mention this because the Julia code is, I feel, easier to read than is
the C++ code that implements GLMM fitting in the lme4 package, although
being easier to read than that C++ code is a low bar.

If you click through to src/PIRLS.jl you will see that the Laplace
approximation to the deviance is defined as
- the sum of the (squared) deviance residuals at the current values of beta
and u
- plus the squared length of u, where b = Lambda * u
- plus the logarithm of the determinant of Lambda'Z'Z * Lambda + I

The model provides the conditional distribution of Y given B = b (or,
equivalently, U = u) and the unconditional distribution of B (or U).  From
those we get the joint density of Y and B (or Y and U). From the joint
density we obtain the conditional density of U given Y = y up to a scaling
factor.  I call this the unscaled conditional density.  The likelihood for
beta and theta (the covariance parameter vector that determines Lambda) is
the integral of this unscaled conditional density.

Because the unconditional density of U is multivariate normal, the unscaled
conditional density ends up being pretty close to a scaled multivariate
normal.  We approximate the unscaled conditional density by a scaled
multivariate normal that matches the value at the peak (i.e. the
conditional modes of the random effects) and the Hessian at that point.
This is the Laplace approximation. Adaptive Gauss-Hermite quadrature
refines this integral by evaluating the unscaled conditional density at
other points near the peak.

The conditional modes are determined via penalized iteratively reweighted
least squares (PIRLS).  See the function pirls! in the PIRLS.jl file. (The
function name ending in ! is an indication that it is a mutating function.
That is, it modifies the values of one or more of its arguments.)

Linear mixed models (LMMs) are simpler to fit because there is a
closed-form expression for the conditional modes of the random effects and
the conditional estimates of the fixed effects given theta.  Also, the
conditional distribution of U given Y = y is a multivariate normal so the
Laplace "approximation" is actually the exact value of the log-likelihood.
See section 3 of  https://www.jstatsoft.org/article/view/v067i01

I'm not sure if this explanation is illuminating or confusing.  To recap,
evaluating the deviance of a GLMM at given values of beta and theta requires
- evaluating Lambda from theta
- setting X*beta at the offset in the model
- determine the conditional modes of the random effects, U, via PIRLS
- evaluate an approximation to the integral of the conditional density

I agree that the penalty is an important justification for random effects
versus fixed effects.  John Tukey put a positive spin on the situation by
saying that we are "borrowing strength" from the other individuals in the
sample when we use random effects.

Consider fitting an item response model to a dichotomous response (say
correct/incorrect) where each response is associated with a subject and an
item (e.g. a question on an exam).  Often such models are fit using
fixed-effects for the subject and random effects for the item, in which
case there is no finite estimate of the fixed-effect for a subject who gets
all the items correct.  It we model both subjects and items with random
effects, the penalty or shrinkage brings the extremes of the estimates for
the subjects in closer to the population mean.

I hope this helps.

On Mon, Apr 4, 2016 at 6:22 AM Paul Johnson <pauljohn32 at gmail.com> wrote:

> I'm trying to explain GLMM estimation and defend random effects in an
> audience of econometricians.  I am focused on logit models, mostly, with
> random intercepts.
>
> The literature is difficult. I can understand applications and overviews
> like the paper by Bolker et al in Trends in Ecology and Evolution. But I
> can't understand much about glmer that is deeper than that.  Can you point
> me at some books/articles that explain the GLMM estimation process in an
> understandable way? Is there a PLS derivation for GLMM?  I want to better
> understand adaptive quadrature. And Laplace approximation.
>
> You might be able to advise me better if I tell you why I need to know.
>
> I was surprised to learn that economists hate random effects. It is almost
> visceral. For the economists, the fixed vs random effects debate is not
> philosophical, but rather practical. In an LMM, the Hausman test seems to
> bluntly reject almost all random effects models.  (See William Greene's
> Econometrics book).  Unmeasured group-level predictors always exist, it
> seems, so random effects estimates are biased/inconsistent. Even if you
> believe Intercept differences are random, LMM estimates are
> biased/inconsistent, so you should treat as fixed.
>
> I'm a little surprised there is so little discussion of Hausman's test in
> the random effect literature outside economics.
>
> One argument used by random effect advocates, that group-level predictors
> can be included in LMM, holds no weight at all. It is just evidence of bias
> in LMM. Well, the estimates thus obtained are useless because, if the group
> level intercept estimates were correct, then the group-level predictors
> would not be identifiable.
>
> My argument with them so far is based on the characterization of LMM as a
> PLS exercise, which I learned in this email list. That makes a point
> obvious: the fixed vs random models differ because PLS penalizes the b's,
> but fixed estimators do not. The issue is not "random" against "fixed". It
> is penalized against unpenalized. The parallel between LMM and ridge
> regression and LASSO helps.  If the number of observations within groups
> grows, then the posterior modes  and the fixed effect estimates converge.
> Yes?
>
> The small sample debate hinges on mean square error of the b's. The PLS
> view makes it plain that Empirical Bayes gives shrinkage not as
> afterthought (as it seems in the GLS narrative), but as a primary element
> (Henderson's estimator).   Ironically, the shrinkage effect of LMM, widely
> praised in stats and hierarchical modeling applications, raises suspicion
> of bias. One might prefer a biased, but lower variance estimate of b, and
> that's shrinkage.  That's my theme, anyway, we'll see if I can sell it.
>
> In that context, I come to the chore of comparing a glmer estimate with a
> fixed effect method known as conditional logit or Chamberlain's panel logit
> model.
>
> pj
> Paul Johnson
> http://pj.freefaculty.org
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From alejandreandrea at gmail.com  Tue Apr  5 22:28:02 2016
From: alejandreandrea at gmail.com (Alejandra Tapia)
Date: Tue, 5 Apr 2016 16:28:02 -0400
Subject: [R-sig-ME] Fwd: Question of Chile
In-Reply-To: <CAAJcTEAE63Pr8EpZQJqfP3V-AYx64P=PqqqpouWaJcMiTRhT4Q@mail.gmail.com>
References: <CAAJcTEAE63Pr8EpZQJqfP3V-AYx64P=PqqqpouWaJcMiTRhT4Q@mail.gmail.com>
Message-ID: <CAAJcTEBGd0TB_2QK2+8AuroATjpk+4HhQSMY7CdLhiC-cGOxAw@mail.gmail.com>

---------- Forwarded message ----------
From: Alejandra Tapia <alejandreandrea at gmail.com>
Date: 2016-04-05 16:26 GMT-04:00
Subject: Question of Chile
To: bbolker+lme4-authors at gmail.com, Ben Bolker <bbolker at gmail.com>


Dear Prof. Ben,

I have doubts about how is the procedure for calculating the BLUP or
conditional modes associated with the function glmer of package lme4.

BLUP is b ?i=E(biIy)= int bi f(biIy) dbi evaluated at estimates parameters,
for i=1,..,I, right?

Do you have documentation to understand the algorithm that calculates the
BLUPs?

I would greatly appreciate your response, because I could not find
information to clarify my doubt.

Thank's

Greetings

-- 
Alejandra



-- 
Alejandra

	[[alternative HTML version deleted]]


From ss1272 at york.ac.uk  Wed Apr  6 15:22:02 2016
From: ss1272 at york.ac.uk (Saudi Sadiq)
Date: Wed, 6 Apr 2016 14:22:02 +0100
Subject: [R-sig-ME] Does changing the reference level cause any difference
	in results?
Message-ID: <CAGpVz+g+f0Y15Tx8eS5DgF8jGaA_HNgVwZOZDT0XLcyOvpeQiw@mail.gmail.com>

Hi all,
I am analysing a dataset 'qaaf' (attached) using logistic regression.
The dataset includes:
1. speaker: participants in my study
2. item: words as used by my participants
3. gender: independent variable (2 levels: 'female' and 'male')
4. age.group: independent variable (3 levels:  'middle-aged',  'old' and
'young')
5. education: independent variable (3 levels:  'postgraduate', 'secondary
or below' and 'university')
6. residence: independent variable (3 levels: 'migrant', 'urbanite' and
'villager')
7. convergence: the dependent variable (whether a speaker uses a CA or MA
form).  Here, I am testing whether my participants use the CA form or not.
This is the form of the prestigious dialect in Egypt. If they use MA, this
means that they use their traditional dialect. I am trying to find out
which factor (independent variable) is responsible or more responsible for
using the CA form.
As the target is CA and this (alphabetically) takes the 0 value,
I re-levelled the dependent variable (convergence) to change the value of
CA from 0 to 1,  as follows:
(a) attach(qaaf)
(b) qaaf$convergence= factor(convergence, levels=c(MA', 'CA'))
I also re-levelled these variables:
(c) qaaf$education=factor(education, levels=c("secondary or below",
"university",  "postgraduate"))
(d) qaaf$residence = factor(residence, levels=c('villager', 'migrant',
'urbanite'))
(e) qaaf$age.group = factor(age.group, levels=c('young', 'middle-aged',
'old'))

I re-levelled the variables in (c), (d) and (e) because these are ordinal
variables (e.g. old people were middle-aged one day and before that had
been young). My question may be general:
Q: Does changing the reference level cause any difference in results?
or
Q: Is leaving the variable levels alphabetically arranged good or bad? Put
another way, when should levels be left alphabetically arranged and when
should they be re-levelled?

Best


-- 
Saudi Sadiq,
Assistant Lecturer, English Department,
Faculty of Al-Alsun,Minia University,
Minia City, Egypt &
PhD Student, Language and Linguistic Science Department,
University of York, York, North Yorkshire, UK,
YO10 5DD
http://york.academia.edu/SaudiSadiq
https://www.researchgate.net/profile/Saudi_Sadiq
Certified Translator by Egyptian Translation Association (Egyta)
<http://www.egyta.com/>
Certified Interpreter by Pearl Linguistics
<http://www.pearllinguistics.com/>
Verified Teacher at https://lingos.co/users/saudi-sadiq
Verified Teacher at
https://www.firsttutors.com/uk/languages/teacher/saudi.arabic.english

From drmccloy at uw.edu  Wed Apr  6 19:55:08 2016
From: drmccloy at uw.edu (Dan McCloy)
Date: Wed, 6 Apr 2016 10:55:08 -0700
Subject: [R-sig-ME] Does changing the reference level cause any
 difference in results?
In-Reply-To: <CAGpVz+g+f0Y15Tx8eS5DgF8jGaA_HNgVwZOZDT0XLcyOvpeQiw@mail.gmail.com>
References: <CAGpVz+g+f0Y15Tx8eS5DgF8jGaA_HNgVwZOZDT0XLcyOvpeQiw@mail.gmail.com>
Message-ID: <CAOE0pY=d6o+=-iUbUBtOte_x06RLOroa4aEy7Gz+QMNsxEo4_w@mail.gmail.com>

To answer your specific questions:

1. changing the reference level should not change the overall model fit
itself, but it will change the magnitude and direction of the coefficient
estimates (because when you change the reference level the new coefficients
will represent different comparisons).

2. you should always code factor variables in a way that makes sense given
the scientific question you are trying to answer.  A very good discussion
of factor coding is here:  http://talklab.psy.gla.ac.uk/tvw/catpred/

General comments: Coding the ordinal variables (like age cohort) in their
proper order does not in fact capture their ordered-ness: the model will
not necessarily enforce the assumption that the change from middle-aged to
old should be the same magnitude and direction as the change from young to
middle-aged.  In all of the examples you've given, what you will get is the
first level of the factor treated as baseline, and the coefficient
estimates for other levels as differences between them and the baseline.
For example, a coefficient "residence:migrant" will tell you how much more
(or less) likely migrants are to use the "CA" form than the "MA" form, when
compared to villagers (the baseline level).

-- dan

Daniel McCloy
http://dan.mccloy.info/
Postdoctoral Research Associate
Institute for Learning and Brain Sciences
University of Washington




On Wed, Apr 6, 2016 at 6:22 AM, Saudi Sadiq <ss1272 at york.ac.uk> wrote:

> Hi all,
> I am analysing a dataset 'qaaf' (attached) using logistic regression.
> The dataset includes:
> 1. speaker: participants in my study
> 2. item: words as used by my participants
> 3. gender: independent variable (2 levels: 'female' and 'male')
> 4. age.group: independent variable (3 levels:  'middle-aged',  'old' and
> 'young')
> 5. education: independent variable (3 levels:  'postgraduate', 'secondary
> or below' and 'university')
> 6. residence: independent variable (3 levels: 'migrant', 'urbanite' and
> 'villager')
> 7. convergence: the dependent variable (whether a speaker uses a CA or MA
> form).  Here, I am testing whether my participants use the CA form or not.
> This is the form of the prestigious dialect in Egypt. If they use MA, this
> means that they use their traditional dialect. I am trying to find out
> which factor (independent variable) is responsible or more responsible for
> using the CA form.
> As the target is CA and this (alphabetically) takes the 0 value,
> I re-levelled the dependent variable (convergence) to change the value of
> CA from 0 to 1,  as follows:
> (a) attach(qaaf)
> (b) qaaf$convergence= factor(convergence, levels=c(MA', 'CA'))
> I also re-levelled these variables:
> (c) qaaf$education=factor(education, levels=c("secondary or below",
> "university",  "postgraduate"))
> (d) qaaf$residence = factor(residence, levels=c('villager', 'migrant',
> 'urbanite'))
> (e) qaaf$age.group = factor(age.group, levels=c('young', 'middle-aged',
> 'old'))
>
> I re-levelled the variables in (c), (d) and (e) because these are ordinal
> variables (e.g. old people were middle-aged one day and before that had
> been young). My question may be general:
> Q: Does changing the reference level cause any difference in results?
> or
> Q: Is leaving the variable levels alphabetically arranged good or bad? Put
> another way, when should levels be left alphabetically arranged and when
> should they be re-levelled?
>
> Best
>
>
> --
> Saudi Sadiq,
> Assistant Lecturer, English Department,
> Faculty of Al-Alsun,Minia University,
> Minia City, Egypt &
> PhD Student, Language and Linguistic Science Department,
> University of York, York, North Yorkshire, UK,
> YO10 5DD
> http://york.academia.edu/SaudiSadiq
> https://www.researchgate.net/profile/Saudi_Sadiq
> Certified Translator by Egyptian Translation Association (Egyta)
> <http://www.egyta.com/>
> Certified Interpreter by Pearl Linguistics
> <http://www.pearllinguistics.com/>
> Verified Teacher at https://lingos.co/users/saudi-sadiq
> Verified Teacher at
> https://www.firsttutors.com/uk/languages/teacher/saudi.arabic.english
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From mzhang at newfields.com  Wed Apr  6 20:35:23 2016
From: mzhang at newfields.com (Mengni Zhang)
Date: Wed, 6 Apr 2016 18:35:23 +0000
Subject: [R-sig-ME] mismatch between R lme and SPSS mixed model
Message-ID: <db1c4c333ca649cd9ddad35f86168a6b@MBX02B-IAD3.mex06.mlsrvr.com>

I'm using linear mixed model on an ecology dataset. I want to test whether location and year has an impact on bird egg which were sampled from different marshes and nests. I found a slight mismatch on the results between the R function "lme" and the SPSS option "Mixed Model". Does anyone know the potential reasons for the mismatch? The differences on p-values are not big. For example, the p-value of fixed factor Year is 0.031 from R and 0.029 from SPSS, and the p-value of fixed factor Location is 0.51 from R and 0.43 from SPSS.

My R code is: model1 <- lme(Results~Location+Year, data=data, random=~1|Marsh/NEST)

My SPSS syntax is set as below:
*Generalized Linear Mixed Models.
GENLINMIXED
  /DATA_STRUCTURE SUBJECTS=Marsh*NEST*EGG
  /FIELDS TARGET=Results TRIALS=NONE OFFSET=NONE
  /TARGET_OPTIONS DISTRIBUTION=NORMAL LINK=IDENTITY
  /FIXED  EFFECTS=Location Year USE_INTERCEPT=TRUE
  /RANDOM USE_INTERCEPT=TRUE SUBJECTS=Marsh COVARIANCE_TYPE=VARIANCE_COMPONENTS
  /RANDOM USE_INTERCEPT=TRUE SUBJECTS=Marsh*NEST COVARIANCE_TYPE=VARIANCE_COMPONENTS
  /BUILD_OPTIONS TARGET_CATEGORY_ORDER=ASCENDING INPUTS_CATEGORY_ORDER=ASCENDING MAX_ITERATIONS=100 CONFIDENCE_LEVEL=95 DF_METHOD=RESIDUAL COVB=MODEL PCONVERGE=0.000001(ABSOLUTE) SCORING=0 SINGULAR=0.000000000001
  /EMMEANS TABLES=Location COMPARE=Location CONTRAST=PAIRWISE
   /EMMEANS TABLES=Year COMPARE=Year CONTRAST=PAIRWISE
  /EMMEANS_OPTIONS SCALE=ORIGINAL PADJUST=SEQSIDAK.

Thank you very much!




Please note that this message and any attachments may be protected by federal and/or state privacy laws and might also contain information that is privileged, confidential, and/or subject to attorney/client, attorney work product, or other similar protections.  If you suspect that you are not the intended recipient of this message, please be so kind as to reply and let me know of my error and then delete the message and any attachments, without further dissemination, copying, or distribution.  Thank you.
	[[alternative HTML version deleted]]


From dirienzo.julio at gmail.com  Wed Apr  6 22:34:35 2016
From: dirienzo.julio at gmail.com (Julio Alejandro Di Rienzo)
Date: Wed, 6 Apr 2016 17:34:35 -0300
Subject: [R-sig-ME] mismatch between R lme and SPSS mixed model
In-Reply-To: <db1c4c333ca649cd9ddad35f86168a6b@MBX02B-IAD3.mex06.mlsrvr.com>
References: <db1c4c333ca649cd9ddad35f86168a6b@MBX02B-IAD3.mex06.mlsrvr.com>
Message-ID: <CABC_0C0pkpqR_YVV79WXde0O8YdnKrAjeX0dsAkOSYPkos0+kA@mail.gmail.com>

A detail about anova function, applied to lme objects is that it returns
asequential hypothesis tests. In this type of hypothesis, with unbalance in
the number of replicates for each treatment, the order of factors affects
p-values.

Usually, most software displays type III hypotesis test, which are probably
the way SPSS is reporting the anova table. The way to obtain type III sum
of squares in lme anova has 2 steps.

1.   You must redefine the way factors are coded in the model matrix. If
say you have a factor named F1 y a data frame named myData, you have to use
the following sentence:

myData$F1<-C(myData$F1,contr.sum)

2. When calling anova function you need another parameter to be specified

    anova(mymodel, *type="marginal"*)

You can even have differences if there are "corrections" on the denominators
degree of freedom.

Good luck

	[[alternative HTML version deleted]]


From tim.cole at ucl.ac.uk  Thu Apr  7 14:39:33 2016
From: tim.cole at ucl.ac.uk (Cole, Tim)
Date: Thu, 7 Apr 2016 12:39:33 +0000
Subject: [R-sig-ME] Output and post-hoc comparisons for lme with splines
 specification of fixed effects
Message-ID: <D32C0B86.12133%tim.cole@ucl.ac.uk>

Dear Gabriela,

I think this addresses your first question:

model <- lme( Damage ~ bs( Location , degree=1, df=5) * Disease,
              random=~1| PatientID,
              data=my.data, na.action=na.omit, method="ML")

x <- with(my.data, seq(min(Location), max(Location), length.out=50))
pred0 <- predict(model, newdata=data.frame(Location=x, Disease=0), level=0)
pred1 <- predict(model, newdata=data.frame(Location=x, Disease=1), level=0)
plot(x, pred0, type='l', xlab='Location', ylab='Damage')
lines(x, pred1, col=2)

I'm not sure I follow your second question.

Best wishes,
Tim Cole
---
Tim.Cole at ucl.ac.uk<mailto:Tim.Cole at ich.ucl.ac.uk> Phone +44(0)20 7905 2666 Fax +44(0)20 7905 2381
Population Policy and Practice Programme
UCL Institute of Child Health, London WC1N 1EH, UK


Date: Mon, 4 Apr 2016 18:38:29 +0100
From: Gabriela Czanner <g.czanner at googlemail.com<mailto:g.czanner at googlemail.com>>
To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] Output and post-hoc comparisons for lme with
splines specification of fixed effects

Dear R-users,

I am attempting to estimate a difference in damage across space (at 24
locations) for two disease types of patients (defined as a factor, 0
disease absent, 1 disease present). Examining the plots of the damage
across the 24 locations in space it appears that the damage increases then
decreases and it is best described by a spline specification like this:

model<- lme( Damage ~ bs( Location , degree=1, df=5) * Disease,
              random=~1| PatientID,
              data=my.data,na.action=na.omit,method="ML")

I wonder if any one can advice with my questions: How can I plot the
predicted mean profiles of the damage for the two groups? How can I make
post-hoc comparison of mean damage across the two disease groups of
patients?

I did tried many online searches but did not find a good answer. So I will
really appreciate your advice!

Gabriela

--
Gabriela Czanner, PhD
Lecturer
Department of Biostatistics
Department of Eye and Vision Science
University of Liverpool


	[[alternative HTML version deleted]]


From matthew.t.boden at gmail.com  Thu Apr  7 19:37:17 2016
From: matthew.t.boden at gmail.com (Matthew Boden)
Date: Thu, 7 Apr 2016 10:37:17 -0700
Subject: [R-sig-ME] Longitudinal covariation parameter estimate does not
 match average association over time
Message-ID: <CAE10PCzdrwPia4emSUyTXaVjPAwN1UfKKMcUobpipE8J1rGq5A@mail.gmail.com>

Hello,

I am thoroughly perplexed and could greatly benefit from your feedback
(thanks in advance!).

I am examining the longitudinal covariation between two variables (N, P)
measured each month for 26 months among 140 subjects. I am interested in
determining the average relation between these two variables when
accounting for dependencies due to repeated measures. Thus, I am interested
in between-subject variation more so than within-subject variation. Yet,
there exists considerable variation in both trajectories and intercepts for
individual subjects.

The issue is that the average association between N and P at each time
point is negative (e.g., r = -.29).  Yet, in most LMM models I run, the
fixed effects estimate for P predicting N is positive.

For example, including random effects for both intercept and slope (to
account for within subject variation in each) using the following code
yields a positive estimate for P.  This is also true if I include only a
random effect for the intercept or a random effect for the slope.

long <- lmer (N ~ P + (1 + P | ID), data = lip)

Fixed effect estimate (SE), Z
Intercept = 46.9 (4.38), 10.68
P = 2.99 (.57), 5.19

The only way I obtain a negative estimate for P is when I include
duration/time in the model and a random effect for duration/time, but
exclude the random effect for P AND exclude the random intercept.

long <- lmer (N ~ P + time +  (1 + time | ID), data = lip)

Fixed effect estimate (SE), Z
Intercept = 73.99 (2.17), 34.09
Time = .18 (.06), 2.84
P = -1.01 (.28), -3.51

Besides the fact that I'm not really interested in the structure of N over
time, and thus seemingly do not need a duration/time parameter, there is
substantial variation in the intercept and slope for N by P for which
random effects would be needed.

It is my understanding, perhaps wrong, that the fixed effect parameter
estimate for P should be akin to the average association between N and P
across time. Thus, this parameter estimate should be negative, regardless
of whether or not duration/time is included in the model. Indeed, plotting
N by P without consideration of duration/time reveals a negative average
regression slope.

I'm at a loss and could use some help.

Thank you,

Matt

	[[alternative HTML version deleted]]


From ss1272 at york.ac.uk  Thu Apr  7 21:06:10 2016
From: ss1272 at york.ac.uk (Saudi Sadiq)
Date: Thu, 7 Apr 2016 20:06:10 +0100
Subject: [R-sig-ME] Does changing the reference level cause any
 difference in results?
In-Reply-To: <CAOE0pY=d6o+=-iUbUBtOte_x06RLOroa4aEy7Gz+QMNsxEo4_w@mail.gmail.com>
References: <CAGpVz+g+f0Y15Tx8eS5DgF8jGaA_HNgVwZOZDT0XLcyOvpeQiw@mail.gmail.com>
	<CAOE0pY=d6o+=-iUbUBtOte_x06RLOroa4aEy7Gz+QMNsxEo4_w@mail.gmail.com>
Message-ID: <CAGpVz+hCGXZbpn-cz3TYW3d55XDa3DDQceEGme_vNnxea5gaSw@mail.gmail.com>

Many thanks, Dan. This is really helpful.

On 6 April 2016 at 18:55, Dan McCloy <drmccloy at uw.edu> wrote:

> To answer your specific questions:
>
> 1. changing the reference level should not change the overall model fit
> itself, but it will change the magnitude and direction of the coefficient
> estimates (because when you change the reference level the new coefficients
> will represent different comparisons).
>
> 2. you should always code factor variables in a way that makes sense given
> the scientific question you are trying to answer.  A very good discussion
> of factor coding is here:  http://talklab.psy.gla.ac.uk/tvw/catpred/
>
> General comments: Coding the ordinal variables (like age cohort) in their
> proper order does not in fact capture their ordered-ness: the model will
> not necessarily enforce the assumption that the change from middle-aged to
> old should be the same magnitude and direction as the change from young to
> middle-aged.  In all of the examples you've given, what you will get is the
> first level of the factor treated as baseline, and the coefficient
> estimates for other levels as differences between them and the baseline.
> For example, a coefficient "residence:migrant" will tell you how much more
> (or less) likely migrants are to use the "CA" form than the "MA" form, when
> compared to villagers (the baseline level).
>
> -- dan
>
> Daniel McCloy
> http://dan.mccloy.info/
> Postdoctoral Research Associate
> Institute for Learning and Brain Sciences
> University of Washington
>
>
>
>
> On Wed, Apr 6, 2016 at 6:22 AM, Saudi Sadiq <ss1272 at york.ac.uk> wrote:
>
>> Hi all,
>> I am analysing a dataset 'qaaf' (attached) using logistic regression.
>> The dataset includes:
>> 1. speaker: participants in my study
>> 2. item: words as used by my participants
>> 3. gender: independent variable (2 levels: 'female' and 'male')
>> 4. age.group: independent variable (3 levels:  'middle-aged',  'old' and
>> 'young')
>> 5. education: independent variable (3 levels:  'postgraduate', 'secondary
>> or below' and 'university')
>> 6. residence: independent variable (3 levels: 'migrant', 'urbanite' and
>> 'villager')
>> 7. convergence: the dependent variable (whether a speaker uses a CA or MA
>> form).  Here, I am testing whether my participants use the CA form or not.
>> This is the form of the prestigious dialect in Egypt. If they use MA, this
>> means that they use their traditional dialect. I am trying to find out
>> which factor (independent variable) is responsible or more responsible for
>> using the CA form.
>> As the target is CA and this (alphabetically) takes the 0 value,
>> I re-levelled the dependent variable (convergence) to change the value of
>> CA from 0 to 1,  as follows:
>> (a) attach(qaaf)
>> (b) qaaf$convergence= factor(convergence, levels=c(MA', 'CA'))
>> I also re-levelled these variables:
>> (c) qaaf$education=factor(education, levels=c("secondary or below",
>> "university",  "postgraduate"))
>> (d) qaaf$residence = factor(residence, levels=c('villager', 'migrant',
>> 'urbanite'))
>> (e) qaaf$age.group = factor(age.group, levels=c('young', 'middle-aged',
>> 'old'))
>>
>> I re-levelled the variables in (c), (d) and (e) because these are ordinal
>> variables (e.g. old people were middle-aged one day and before that had
>> been young). My question may be general:
>> Q: Does changing the reference level cause any difference in results?
>> or
>> Q: Is leaving the variable levels alphabetically arranged good or bad? Put
>> another way, when should levels be left alphabetically arranged and when
>> should they be re-levelled?
>>
>> Best
>>
>>
>> --
>> Saudi Sadiq,
>> Assistant Lecturer, English Department,
>> Faculty of Al-Alsun,Minia University,
>> Minia City, Egypt &
>> PhD Student, Language and Linguistic Science Department,
>> University of York, York, North Yorkshire, UK,
>> YO10 5DD
>> http://york.academia.edu/SaudiSadiq
>> https://www.researchgate.net/profile/Saudi_Sadiq
>> Certified Translator by Egyptian Translation Association (Egyta)
>> <http://www.egyta.com/>
>> Certified Interpreter by Pearl Linguistics
>> <http://www.pearllinguistics.com/>
>> Verified Teacher at https://lingos.co/users/saudi-sadiq
>> Verified Teacher at
>> https://www.firsttutors.com/uk/languages/teacher/saudi.arabic.english
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>


-- 
Saudi Sadiq,
Assistant Lecturer, English Department,
Faculty of Al-Alsun,Minia University,
Minia City, Egypt &
PhD Student, Language and Linguistic Science Department,
University of York, York, North Yorkshire, UK,
YO10 5DD
http://york.academia.edu/SaudiSadiq
https://www.researchgate.net/profile/Saudi_Sadiq
Certified Translator by Egyptian Translation Association (Egyta)
<http://www.egyta.com/>
Certified Interpreter by Pearl Linguistics
<http://www.pearllinguistics.com/>
Verified Teacher at https://lingos.co/users/saudi-sadiq
Verified Teacher at
https://www.firsttutors.com/uk/languages/teacher/saudi.arabic.english

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Fri Apr  8 09:59:32 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 8 Apr 2016 09:59:32 +0200
Subject: [R-sig-ME] Longitudinal covariation parameter estimate does not
 match average association over time
In-Reply-To: <CAE10PCzdrwPia4emSUyTXaVjPAwN1UfKKMcUobpipE8J1rGq5A@mail.gmail.com>
References: <CAE10PCzdrwPia4emSUyTXaVjPAwN1UfKKMcUobpipE8J1rGq5A@mail.gmail.com>
Message-ID: <CAJuCY5zu-x9ymu=arZPAbDFmO3z17sDrRTyN1NZ8swZdddFtBA@mail.gmail.com>

Dear Matt,

It looks like N differs along among ID. And that ID's with high overal N
have a low overal P. Try to plot N minus the average N per ID against P. I
would expect that this graph will show a positive correlation.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-04-07 19:37 GMT+02:00 Matthew Boden <matthew.t.boden at gmail.com>:

> Hello,
>
> I am thoroughly perplexed and could greatly benefit from your feedback
> (thanks in advance!).
>
> I am examining the longitudinal covariation between two variables (N, P)
> measured each month for 26 months among 140 subjects. I am interested in
> determining the average relation between these two variables when
> accounting for dependencies due to repeated measures. Thus, I am interested
> in between-subject variation more so than within-subject variation. Yet,
> there exists considerable variation in both trajectories and intercepts for
> individual subjects.
>
> The issue is that the average association between N and P at each time
> point is negative (e.g., r = -.29).  Yet, in most LMM models I run, the
> fixed effects estimate for P predicting N is positive.
>
> For example, including random effects for both intercept and slope (to
> account for within subject variation in each) using the following code
> yields a positive estimate for P.  This is also true if I include only a
> random effect for the intercept or a random effect for the slope.
>
> long <- lmer (N ~ P + (1 + P | ID), data = lip)
>
> Fixed effect estimate (SE), Z
> Intercept = 46.9 (4.38), 10.68
> P = 2.99 (.57), 5.19
>
> The only way I obtain a negative estimate for P is when I include
> duration/time in the model and a random effect for duration/time, but
> exclude the random effect for P AND exclude the random intercept.
>
> long <- lmer (N ~ P + time +  (1 + time | ID), data = lip)
>
> Fixed effect estimate (SE), Z
> Intercept = 73.99 (2.17), 34.09
> Time = .18 (.06), 2.84
> P = -1.01 (.28), -3.51
>
> Besides the fact that I'm not really interested in the structure of N over
> time, and thus seemingly do not need a duration/time parameter, there is
> substantial variation in the intercept and slope for N by P for which
> random effects would be needed.
>
> It is my understanding, perhaps wrong, that the fixed effect parameter
> estimate for P should be akin to the average association between N and P
> across time. Thus, this parameter estimate should be negative, regardless
> of whether or not duration/time is included in the model. Indeed, plotting
> N by P without consideration of duration/time reveals a negative average
> regression slope.
>
> I'm at a loss and could use some help.
>
> Thank you,
>
> Matt
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From b.pelzer at maw.ru.nl  Fri Apr  8 12:04:30 2016
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Fri, 8 Apr 2016 12:04:30 +0200
Subject: [R-sig-ME] Longitudinal covariation parameter estimate does not
 match average association over time
In-Reply-To: <CAE10PCzdrwPia4emSUyTXaVjPAwN1UfKKMcUobpipE8J1rGq5A@mail.gmail.com>
References: <CAE10PCzdrwPia4emSUyTXaVjPAwN1UfKKMcUobpipE8J1rGq5A@mail.gmail.com>
Message-ID: <5707822E.1080903@maw.ru.nl>

Hi Matthew,

Could this be the difference between a within and a between regression 
effect?

What if you "group-center", i.e., calculate the subject means (Pmean) 
over time for each of the 140 subjects and subtract these group-means 
from your original P values so that the Pdev = P - Pmean and then try:

long <- lmer (N ~ Pdev + Pmean + (1 | ID), data = lip)

The parameter of Pdev could be positive and the one of Pmean negative, 
showing that the (negative) within-subject effect of P differs from the 
(positive) between-subject effect. This is e.g. discussed by Snijders 
and Bosker, chapter 4.

Best, Ben.



On 7-4-2016 19:37, Matthew Boden wrote:
> Hello,
>
> I am thoroughly perplexed and could greatly benefit from your feedback
> (thanks in advance!).
>
> I am examining the longitudinal covariation between two variables (N, P)
> measured each month for 26 months among 140 subjects. I am interested in
> determining the average relation between these two variables when
> accounting for dependencies due to repeated measures. Thus, I am interested
> in between-subject variation more so than within-subject variation. Yet,
> there exists considerable variation in both trajectories and intercepts for
> individual subjects.
>
> The issue is that the average association between N and P at each time
> point is negative (e.g., r = -.29).  Yet, in most LMM models I run, the
> fixed effects estimate for P predicting N is positive.
>
> For example, including random effects for both intercept and slope (to
> account for within subject variation in each) using the following code
> yields a positive estimate for P.  This is also true if I include only a
> random effect for the intercept or a random effect for the slope.
>
> long <- lmer (N ~ P + (1 + P | ID), data = lip)
>
> Fixed effect estimate (SE), Z
> Intercept = 46.9 (4.38), 10.68
> P = 2.99 (.57), 5.19
>
> The only way I obtain a negative estimate for P is when I include
> duration/time in the model and a random effect for duration/time, but
> exclude the random effect for P AND exclude the random intercept.
>
> long <- lmer (N ~ P + time +  (1 + time | ID), data = lip)
>
> Fixed effect estimate (SE), Z
> Intercept = 73.99 (2.17), 34.09
> Time = .18 (.06), 2.84
> P = -1.01 (.28), -3.51
>
> Besides the fact that I'm not really interested in the structure of N over
> time, and thus seemingly do not need a duration/time parameter, there is
> substantial variation in the intercept and slope for N by P for which
> random effects would be needed.
>
> It is my understanding, perhaps wrong, that the fixed effect parameter
> estimate for P should be akin to the average association between N and P
> across time. Thus, this parameter estimate should be negative, regardless
> of whether or not duration/time is included in the model. Indeed, plotting
> N by P without consideration of duration/time reveals a negative average
> regression slope.
>
> I'm at a loss and could use some help.
>
> Thank you,
>
> Matt
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From b.pelzer at maw.ru.nl  Fri Apr  8 12:58:57 2016
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Fri, 8 Apr 2016 12:58:57 +0200
Subject: [R-sig-ME] Longitudinal covariation parameter estimate does not
 match average association over time
In-Reply-To: <5707822E.1080903@maw.ru.nl>
References: <CAE10PCzdrwPia4emSUyTXaVjPAwN1UfKKMcUobpipE8J1rGq5A@mail.gmail.com>
	<5707822E.1080903@maw.ru.nl>
Message-ID: <57078EF1.3080608@maw.ru.nl>

Hi Matthew,

There was a type in my previous mail, at the end. I switched "negative" 
and "positive", so it should:

The parameter of Pdev could be positive and the one of Pmean negative, 
showing that the (***positive) within-subject effect of P differs from 
the (***negative) between-subject effect.

Ben.

On 8-4-2016 12:04, Ben Pelzer wrote:
> Hi Matthew,
>
> Could this be the difference between a within and a between regression 
> effect?
>
> What if you "group-center", i.e., calculate the subject means (Pmean) 
> over time for each of the 140 subjects and subtract these group-means 
> from your original P values so that the Pdev = P - Pmean and then try:
>
> long <- lmer (N ~ Pdev + Pmean + (1 | ID), data = lip)
>
> The parameter of Pdev could be positive and the one of Pmean negative, 
> showing that the (negative) within-subject effect of P differs from 
> the (positive) between-subject effect. This is e.g. discussed by 
> Snijders and Bosker, chapter 4.
>
> Best, Ben.
>
>
>
> On 7-4-2016 19:37, Matthew Boden wrote:
>> Hello,
>>
>> I am thoroughly perplexed and could greatly benefit from your feedback
>> (thanks in advance!).
>>
>> I am examining the longitudinal covariation between two variables (N, P)
>> measured each month for 26 months among 140 subjects. I am interested in
>> determining the average relation between these two variables when
>> accounting for dependencies due to repeated measures. Thus, I am 
>> interested
>> in between-subject variation more so than within-subject variation. Yet,
>> there exists considerable variation in both trajectories and 
>> intercepts for
>> individual subjects.
>>
>> The issue is that the average association between N and P at each time
>> point is negative (e.g., r = -.29).  Yet, in most LMM models I run, the
>> fixed effects estimate for P predicting N is positive.
>>
>> For example, including random effects for both intercept and slope (to
>> account for within subject variation in each) using the following code
>> yields a positive estimate for P.  This is also true if I include only a
>> random effect for the intercept or a random effect for the slope.
>>
>> long <- lmer (N ~ P + (1 + P | ID), data = lip)
>>
>> Fixed effect estimate (SE), Z
>> Intercept = 46.9 (4.38), 10.68
>> P = 2.99 (.57), 5.19
>>
>> The only way I obtain a negative estimate for P is when I include
>> duration/time in the model and a random effect for duration/time, but
>> exclude the random effect for P AND exclude the random intercept.
>>
>> long <- lmer (N ~ P + time +  (1 + time | ID), data = lip)
>>
>> Fixed effect estimate (SE), Z
>> Intercept = 73.99 (2.17), 34.09
>> Time = .18 (.06), 2.84
>> P = -1.01 (.28), -3.51
>>
>> Besides the fact that I'm not really interested in the structure of N 
>> over
>> time, and thus seemingly do not need a duration/time parameter, there is
>> substantial variation in the intercept and slope for N by P for which
>> random effects would be needed.
>>
>> It is my understanding, perhaps wrong, that the fixed effect parameter
>> estimate for P should be akin to the average association between N and P
>> across time. Thus, this parameter estimate should be negative, 
>> regardless
>> of whether or not duration/time is included in the model. Indeed, 
>> plotting
>> N by P without consideration of duration/time reveals a negative average
>> regression slope.
>>
>> I'm at a loss and could use some help.
>>
>> Thank you,
>>
>> Matt
>>
>>     [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From matthew.t.boden at gmail.com  Fri Apr  8 16:54:22 2016
From: matthew.t.boden at gmail.com (Matthew Boden)
Date: Fri, 8 Apr 2016 07:54:22 -0700
Subject: [R-sig-ME] Longitudinal covariation parameter estimate does not
 match average association over time
In-Reply-To: <57078EF1.3080608@maw.ru.nl>
References: <CAE10PCzdrwPia4emSUyTXaVjPAwN1UfKKMcUobpipE8J1rGq5A@mail.gmail.com>
	<5707822E.1080903@maw.ru.nl> <57078EF1.3080608@maw.ru.nl>
Message-ID: <CAE10PCyD8cwLU7F9nqfJqNuYwjpXEdY6_s-SWL576qXrZ-LbAQ@mail.gmail.com>

Thank you, Thierry and Ben!  I will do this immediately.

Matt

On Fri, Apr 8, 2016 at 3:58 AM, Ben Pelzer <b.pelzer at maw.ru.nl> wrote:

> Hi Matthew,
>
> There was a type in my previous mail, at the end. I switched "negative"
> and "positive", so it should:
>
> The parameter of Pdev could be positive and the one of Pmean negative,
> showing that the (***positive) within-subject effect of P differs from the
> (***negative) between-subject effect.
>
> Ben.
>
>
> On 8-4-2016 12:04, Ben Pelzer wrote:
>
>> Hi Matthew,
>>
>> Could this be the difference between a within and a between regression
>> effect?
>>
>> What if you "group-center", i.e., calculate the subject means (Pmean)
>> over time for each of the 140 subjects and subtract these group-means from
>> your original P values so that the Pdev = P - Pmean and then try:
>>
>> long <- lmer (N ~ Pdev + Pmean + (1 | ID), data = lip)
>>
>> The parameter of Pdev could be positive and the one of Pmean negative,
>> showing that the (negative) within-subject effect of P differs from the
>> (positive) between-subject effect. This is e.g. discussed by Snijders and
>> Bosker, chapter 4.
>>
>> Best, Ben.
>>
>>
>>
>> On 7-4-2016 19:37, Matthew Boden wrote:
>>
>>> Hello,
>>>
>>> I am thoroughly perplexed and could greatly benefit from your feedback
>>> (thanks in advance!).
>>>
>>> I am examining the longitudinal covariation between two variables (N, P)
>>> measured each month for 26 months among 140 subjects. I am interested in
>>> determining the average relation between these two variables when
>>> accounting for dependencies due to repeated measures. Thus, I am
>>> interested
>>> in between-subject variation more so than within-subject variation. Yet,
>>> there exists considerable variation in both trajectories and intercepts
>>> for
>>> individual subjects.
>>>
>>> The issue is that the average association between N and P at each time
>>> point is negative (e.g., r = -.29).  Yet, in most LMM models I run, the
>>> fixed effects estimate for P predicting N is positive.
>>>
>>> For example, including random effects for both intercept and slope (to
>>> account for within subject variation in each) using the following code
>>> yields a positive estimate for P.  This is also true if I include only a
>>> random effect for the intercept or a random effect for the slope.
>>>
>>> long <- lmer (N ~ P + (1 + P | ID), data = lip)
>>>
>>> Fixed effect estimate (SE), Z
>>> Intercept = 46.9 (4.38), 10.68
>>> P = 2.99 (.57), 5.19
>>>
>>> The only way I obtain a negative estimate for P is when I include
>>> duration/time in the model and a random effect for duration/time, but
>>> exclude the random effect for P AND exclude the random intercept.
>>>
>>> long <- lmer (N ~ P + time +  (1 + time | ID), data = lip)
>>>
>>> Fixed effect estimate (SE), Z
>>> Intercept = 73.99 (2.17), 34.09
>>> Time = .18 (.06), 2.84
>>> P = -1.01 (.28), -3.51
>>>
>>> Besides the fact that I'm not really interested in the structure of N
>>> over
>>> time, and thus seemingly do not need a duration/time parameter, there is
>>> substantial variation in the intercept and slope for N by P for which
>>> random effects would be needed.
>>>
>>> It is my understanding, perhaps wrong, that the fixed effect parameter
>>> estimate for P should be akin to the average association between N and P
>>> across time. Thus, this parameter estimate should be negative, regardless
>>> of whether or not duration/time is included in the model. Indeed,
>>> plotting
>>> N by P without consideration of duration/time reveals a negative average
>>> regression slope.
>>>
>>> I'm at a loss and could use some help.
>>>
>>> Thank you,
>>>
>>> Matt
>>>
>>>     [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From matthew.t.boden at gmail.com  Fri Apr  8 18:24:08 2016
From: matthew.t.boden at gmail.com (Matthew Boden)
Date: Fri, 8 Apr 2016 09:24:08 -0700
Subject: [R-sig-ME] Longitudinal covariation parameter estimate does not
 match average association over time
In-Reply-To: <CAE10PCyD8cwLU7F9nqfJqNuYwjpXEdY6_s-SWL576qXrZ-LbAQ@mail.gmail.com>
References: <CAE10PCzdrwPia4emSUyTXaVjPAwN1UfKKMcUobpipE8J1rGq5A@mail.gmail.com>
	<5707822E.1080903@maw.ru.nl> <57078EF1.3080608@maw.ru.nl>
	<CAE10PCyD8cwLU7F9nqfJqNuYwjpXEdY6_s-SWL576qXrZ-LbAQ@mail.gmail.com>
Message-ID: <CAE10PCzOogQx2kc5H7fPzi3mxGBy1b_ge1sWnVKvP9_k-BPbLQ@mail.gmail.com>

Ben and Theirry,

You were both absolutely correct.  Thank you much for the help!

Matt

On Fri, Apr 8, 2016 at 7:54 AM, Matthew Boden <matthew.t.boden at gmail.com>
wrote:

> Thank you, Thierry and Ben!  I will do this immediately.
>
> Matt
>
> On Fri, Apr 8, 2016 at 3:58 AM, Ben Pelzer <b.pelzer at maw.ru.nl> wrote:
>
>> Hi Matthew,
>>
>> There was a type in my previous mail, at the end. I switched "negative"
>> and "positive", so it should:
>>
>> The parameter of Pdev could be positive and the one of Pmean negative,
>> showing that the (***positive) within-subject effect of P differs from the
>> (***negative) between-subject effect.
>>
>> Ben.
>>
>>
>> On 8-4-2016 12:04, Ben Pelzer wrote:
>>
>>> Hi Matthew,
>>>
>>> Could this be the difference between a within and a between regression
>>> effect?
>>>
>>> What if you "group-center", i.e., calculate the subject means (Pmean)
>>> over time for each of the 140 subjects and subtract these group-means from
>>> your original P values so that the Pdev = P - Pmean and then try:
>>>
>>> long <- lmer (N ~ Pdev + Pmean + (1 | ID), data = lip)
>>>
>>> The parameter of Pdev could be positive and the one of Pmean negative,
>>> showing that the (negative) within-subject effect of P differs from the
>>> (positive) between-subject effect. This is e.g. discussed by Snijders and
>>> Bosker, chapter 4.
>>>
>>> Best, Ben.
>>>
>>>
>>>
>>> On 7-4-2016 19:37, Matthew Boden wrote:
>>>
>>>> Hello,
>>>>
>>>> I am thoroughly perplexed and could greatly benefit from your feedback
>>>> (thanks in advance!).
>>>>
>>>> I am examining the longitudinal covariation between two variables (N, P)
>>>> measured each month for 26 months among 140 subjects. I am interested in
>>>> determining the average relation between these two variables when
>>>> accounting for dependencies due to repeated measures. Thus, I am
>>>> interested
>>>> in between-subject variation more so than within-subject variation. Yet,
>>>> there exists considerable variation in both trajectories and intercepts
>>>> for
>>>> individual subjects.
>>>>
>>>> The issue is that the average association between N and P at each time
>>>> point is negative (e.g., r = -.29).  Yet, in most LMM models I run, the
>>>> fixed effects estimate for P predicting N is positive.
>>>>
>>>> For example, including random effects for both intercept and slope (to
>>>> account for within subject variation in each) using the following code
>>>> yields a positive estimate for P.  This is also true if I include only a
>>>> random effect for the intercept or a random effect for the slope.
>>>>
>>>> long <- lmer (N ~ P + (1 + P | ID), data = lip)
>>>>
>>>> Fixed effect estimate (SE), Z
>>>> Intercept = 46.9 (4.38), 10.68
>>>> P = 2.99 (.57), 5.19
>>>>
>>>> The only way I obtain a negative estimate for P is when I include
>>>> duration/time in the model and a random effect for duration/time, but
>>>> exclude the random effect for P AND exclude the random intercept.
>>>>
>>>> long <- lmer (N ~ P + time +  (1 + time | ID), data = lip)
>>>>
>>>> Fixed effect estimate (SE), Z
>>>> Intercept = 73.99 (2.17), 34.09
>>>> Time = .18 (.06), 2.84
>>>> P = -1.01 (.28), -3.51
>>>>
>>>> Besides the fact that I'm not really interested in the structure of N
>>>> over
>>>> time, and thus seemingly do not need a duration/time parameter, there is
>>>> substantial variation in the intercept and slope for N by P for which
>>>> random effects would be needed.
>>>>
>>>> It is my understanding, perhaps wrong, that the fixed effect parameter
>>>> estimate for P should be akin to the average association between N and P
>>>> across time. Thus, this parameter estimate should be negative,
>>>> regardless
>>>> of whether or not duration/time is included in the model. Indeed,
>>>> plotting
>>>> N by P without consideration of duration/time reveals a negative average
>>>> regression slope.
>>>>
>>>> I'm at a loss and could use some help.
>>>>
>>>> Thank you,
>>>>
>>>> Matt
>>>>
>>>>     [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

	[[alternative HTML version deleted]]


From bates at stat.wisc.edu  Sat Apr  9 17:06:09 2016
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 09 Apr 2016 15:06:09 +0000
Subject: [R-sig-ME] R Data sets from data in Stroup's book?
Message-ID: <CAO7JsnQz2KXq8MUfA4LXs86ZC6u5pWcLFE2wPFQcMb1Tyhj2zA@mail.gmail.com>

Has anyone created R data sets from the data used in the examples and the
exercise of Walter Stroup's book "Generalized Linear Mixed Models: Modern
Concepts, Methods and Applications" (CRC Press, 2013)?

I did get the SAS code from the publisher's web site and can scrape the
data from there and create .rda or .rds files (or maybe .feather files -
see https://github.com/wesm/feather). However, if someone has already done
so I would appreciate getting the data.

	[[alternative HTML version deleted]]


From ss1272 at york.ac.uk  Sat Apr  9 17:35:33 2016
From: ss1272 at york.ac.uk (Saudi Sadiq)
Date: Sat, 9 Apr 2016 16:35:33 +0100
Subject: [R-sig-ME] On what basis one of the predictors/fixed factors should
 be included in a random slope model?
Message-ID: <CAGpVz+iyG0QF45dYCbLRrhiuZxaXuK+OHeydtojcgWe4CRxv1Q@mail.gmail.com>

I read this paper  'Random effects structure for confirmatory hypothesis
testing: Keep it maximal' by Barr, Levy, Scheepers and Tily (2013) and
enjoyed it. I tried, then, to keep it maximal with a dataset I am analysing
but I am facing a problem (this may look naive). I hope you will help me
solve it. The dataset includes 9 predictors and I am using R. The model I
ran is:

modle1<- glmer(convergence ~ gender + age.group
+education+residence+sound_before+sound_after+ part.of.speech +
grammatical.gender + style + (1|speaker) + (1|item), data = qaaf,
family='binomial', control = glmerControl(optimizer = "bobyqa"), nAGQ = 1)

As you see, I have two random factors (speaker and item).
Q1: On what basis one of the predictors/fixed factors should be included in
a random slope model?
The model with random slopes could be like model2 or model3:

modle2<- glmer(convergence ~ gender + age.group
+education+residence+sound_before+sound_after+ part.of.speech
+ grammatical.gender + style + (1+gender|speaker) + (1+education|item),
data = qaaf,  family='binomial', control = glmerControl(optimizer =
"bobyqa"), nAGQ = 1)

modle3<- glmer(convergence ~ gender + age.group
+education+residence+sound_before+sound_after+ part.of.speech +
grammatical.gender + style + (1+residence|speaker) + (1+residence|item),
data = qaaf,  family='binomial', control = glmerControl(optimizer =
"bobyqa"), nAGQ = 1)

Model2 has gender and education included in the random slope and model3 has
residence alone.
Q2: Should the fixed factor used in a random slope model be the same (as in
model3)?
Q3: If  it is okay for such a model to have  two fixed factors (as in model2)
or just one (as inmodel3), which is better?
Q4: What should be done if the model does not converge with a random slope,
is there a way to make it work? Or can i trus and report the results of the
model even if there is a warning message?

Best regards


-- 
Saudi Sadiq,
Assistant Lecturer, English Department,
Faculty of Al-Alsun,Minia University,
Minia City, Egypt &
PhD Student, Language and Linguistic Science Department,
University of York, York, North Yorkshire, UK,
YO10 5DD
http://york.academia.edu/SaudiSadiq
https://www.researchgate.net/profile/Saudi_Sadiq
Certified Translator by Egyptian Translation Association (Egyta)
<http://www.egyta.com/>
Certified Interpreter by Pearl Linguistics
<http://www.pearllinguistics.com/>
Verified Teacher at https://lingos.co/users/saudi-sadiq
Verified Teacher at
https://www.firsttutors.com/uk/languages/teacher/saudi.arabic.english

	[[alternative HTML version deleted]]


From abfine at gmail.com  Sat Apr  9 18:09:15 2016
From: abfine at gmail.com (Alex Fine)
Date: Sat, 9 Apr 2016 12:09:15 -0400
Subject: [R-sig-ME] On what basis one of the predictors/fixed factors
 should be included in a random slope model?
In-Reply-To: <CAGpVz+iyG0QF45dYCbLRrhiuZxaXuK+OHeydtojcgWe4CRxv1Q@mail.gmail.com>
References: <CAGpVz+iyG0QF45dYCbLRrhiuZxaXuK+OHeydtojcgWe4CRxv1Q@mail.gmail.com>
Message-ID: <CAJ6ui+P=EXfEFV==6yDjuwgE=27Xo9bJ14XnVJmFAjPrGpPk6Q@mail.gmail.com>

You may want to check out the response to that paper, which was pretty well
received:  http://arxiv.org/abs/1506.04967

Somewhat unconventionally, here is a facebook thread where a subset of the
authors of each paper talked about it:
https://www.facebook.com/alex.b.fine.9/posts/10102858621451518

A couple quick notes:

1.  I think the basic consensus is that, when using LMMs for hypothesis
testing, you must use the random effects to do what virtually every other
framework for hypothesis testing does, which is account for sources of
variation that may lead to Type I error.  So if "gender" is an experimental
manipulation that might vary depending on item, you should include it.

2.  Does it make sense to have a by-speaker random slope for gender?  This
implies that a given speaker could have either gender.  Without getting too
far afield, I doubt this was indeed the case in your design.  In the
terminology of the Barr et al. paper, a by-speaker random slope for gender
is not "justified by the design".

3.  Do not trust or report a model with an error warning.

On Sat, Apr 9, 2016 at 11:35 AM, Saudi Sadiq <ss1272 at york.ac.uk> wrote:

> I read this paper  'Random effects structure for confirmatory hypothesis
> testing: Keep it maximal' by Barr, Levy, Scheepers and Tily (2013) and
> enjoyed it. I tried, then, to keep it maximal with a dataset I am analysing
> but I am facing a problem (this may look naive). I hope you will help me
> solve it. The dataset includes 9 predictors and I am using R. The model I
> ran is:
>
> modle1<- glmer(convergence ~ gender + age.group
> +education+residence+sound_before+sound_after+ part.of.speech +
> grammatical.gender + style + (1|speaker) + (1|item), data = qaaf,
> family='binomial', control = glmerControl(optimizer = "bobyqa"), nAGQ = 1)
>
> As you see, I have two random factors (speaker and item).
> Q1: On what basis one of the predictors/fixed factors should be included in
> a random slope model?
> The model with random slopes could be like model2 or model3:
>
> modle2<- glmer(convergence ~ gender + age.group
> +education+residence+sound_before+sound_after+ part.of.speech
> + grammatical.gender + style + (1+gender|speaker) + (1+education|item),
> data = qaaf,  family='binomial', control = glmerControl(optimizer =
> "bobyqa"), nAGQ = 1)
>
> modle3<- glmer(convergence ~ gender + age.group
> +education+residence+sound_before+sound_after+ part.of.speech +
> grammatical.gender + style + (1+residence|speaker) + (1+residence|item),
> data = qaaf,  family='binomial', control = glmerControl(optimizer =
> "bobyqa"), nAGQ = 1)
>
> Model2 has gender and education included in the random slope and model3 has
> residence alone.
> Q2: Should the fixed factor used in a random slope model be the same (as in
> model3)?
> Q3: If  it is okay for such a model to have  two fixed factors (as in
> model2)
> or just one (as inmodel3), which is better?
> Q4: What should be done if the model does not converge with a random slope,
> is there a way to make it work? Or can i trus and report the results of the
> model even if there is a warning message?
>
> Best regards
>
>
> --
> Saudi Sadiq,
> Assistant Lecturer, English Department,
> Faculty of Al-Alsun,Minia University,
> Minia City, Egypt &
> PhD Student, Language and Linguistic Science Department,
> University of York, York, North Yorkshire, UK,
> YO10 5DD
> http://york.academia.edu/SaudiSadiq
> https://www.researchgate.net/profile/Saudi_Sadiq
> Certified Translator by Egyptian Translation Association (Egyta)
> <http://www.egyta.com/>
> Certified Interpreter by Pearl Linguistics
> <http://www.pearllinguistics.com/>
> Verified Teacher at https://lingos.co/users/saudi-sadiq
> Verified Teacher at
> https://www.firsttutors.com/uk/languages/teacher/saudi.arabic.english
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Alex Fine
Ph. (336) 302-3251
web:  http://internal.psychology.illinois.edu/~abfine/
<http://internal.psychology.illinois.edu/~abfine/AlexFineHome.html>

	[[alternative HTML version deleted]]


From ss1272 at york.ac.uk  Sun Apr 10 22:09:33 2016
From: ss1272 at york.ac.uk (Saudi Sadiq)
Date: Sun, 10 Apr 2016 21:09:33 +0100
Subject: [R-sig-ME] On what basis one of the predictors/fixed factors
 should be included in a random slope model?
In-Reply-To: <CAJ6ui+P=EXfEFV==6yDjuwgE=27Xo9bJ14XnVJmFAjPrGpPk6Q@mail.gmail.com>
References: <CAGpVz+iyG0QF45dYCbLRrhiuZxaXuK+OHeydtojcgWe4CRxv1Q@mail.gmail.com>
	<CAJ6ui+P=EXfEFV==6yDjuwgE=27Xo9bJ14XnVJmFAjPrGpPk6Q@mail.gmail.com>
Message-ID: <CAGpVz+jcrQDqXW5nGwrwhtHHkpioqJfFNF_LR-ff_uXmr-=tzw@mail.gmail.com>

Hi Alex,
Many thanks for your reply and the historical FB thread.
Best

On 9 April 2016 at 17:09, Alex Fine <abfine at gmail.com> wrote:

> You may want to check out the response to that paper, which was pretty
> well received:  http://arxiv.org/abs/1506.04967
>
> Somewhat unconventionally, here is a facebook thread where a subset of the
> authors of each paper talked about it:
> https://www.facebook.com/alex.b.fine.9/posts/10102858621451518
>
> A couple quick notes:
>
> 1.  I think the basic consensus is that, when using LMMs for hypothesis
> testing, you must use the random effects to do what virtually every other
> framework for hypothesis testing does, which is account for sources of
> variation that may lead to Type I error.  So if "gender" is an experimental
> manipulation that might vary depending on item, you should include it.
>
> 2.  Does it make sense to have a by-speaker random slope for gender?  This
> implies that a given speaker could have either gender.  Without getting too
> far afield, I doubt this was indeed the case in your design.  In the
> terminology of the Barr et al. paper, a by-speaker random slope for gender
> is not "justified by the design".
>
> 3.  Do not trust or report a model with an error warning.
>
> On Sat, Apr 9, 2016 at 11:35 AM, Saudi Sadiq <ss1272 at york.ac.uk> wrote:
>
>> I read this paper  'Random effects structure for confirmatory hypothesis
>> testing: Keep it maximal' by Barr, Levy, Scheepers and Tily (2013) and
>> enjoyed it. I tried, then, to keep it maximal with a dataset I am
>> analysing
>> but I am facing a problem (this may look naive). I hope you will help me
>> solve it. The dataset includes 9 predictors and I am using R. The model I
>> ran is:
>>
>> modle1<- glmer(convergence ~ gender + age.group
>> +education+residence+sound_before+sound_after+ part.of.speech +
>> grammatical.gender + style + (1|speaker) + (1|item), data = qaaf,
>> family='binomial', control = glmerControl(optimizer = "bobyqa"), nAGQ = 1)
>>
>> As you see, I have two random factors (speaker and item).
>> Q1: On what basis one of the predictors/fixed factors should be included
>> in
>> a random slope model?
>> The model with random slopes could be like model2 or model3:
>>
>> modle2<- glmer(convergence ~ gender + age.group
>> +education+residence+sound_before+sound_after+ part.of.speech
>> + grammatical.gender + style + (1+gender|speaker) + (1+education|item),
>> data = qaaf,  family='binomial', control = glmerControl(optimizer =
>> "bobyqa"), nAGQ = 1)
>>
>> modle3<- glmer(convergence ~ gender + age.group
>> +education+residence+sound_before+sound_after+ part.of.speech +
>> grammatical.gender + style + (1+residence|speaker) + (1+residence|item),
>> data = qaaf,  family='binomial', control = glmerControl(optimizer =
>> "bobyqa"), nAGQ = 1)
>>
>> Model2 has gender and education included in the random slope and model3
>> has
>> residence alone.
>> Q2: Should the fixed factor used in a random slope model be the same (as
>> in
>> model3)?
>> Q3: If  it is okay for such a model to have  two fixed factors (as in
>> model2)
>> or just one (as inmodel3), which is better?
>> Q4: What should be done if the model does not converge with a random
>> slope,
>> is there a way to make it work? Or can i trus and report the results of
>> the
>> model even if there is a warning message?
>>
>> Best regards
>>
>>
>> --
>> Saudi Sadiq,
>> Assistant Lecturer, English Department,
>> Faculty of Al-Alsun,Minia University,
>> Minia City, Egypt &
>> PhD Student, Language and Linguistic Science Department,
>> University of York, York, North Yorkshire, UK,
>> YO10 5DD
>> http://york.academia.edu/SaudiSadiq
>> https://www.researchgate.net/profile/Saudi_Sadiq
>> Certified Translator by Egyptian Translation Association (Egyta)
>> <http://www.egyta.com/>
>> Certified Interpreter by Pearl Linguistics
>> <http://www.pearllinguistics.com/>
>> Verified Teacher at https://lingos.co/users/saudi-sadiq
>> Verified Teacher at
>> https://www.firsttutors.com/uk/languages/teacher/saudi.arabic.english
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
> Alex Fine
> Ph. (336) 302-3251
> web:  http://internal.psychology.illinois.edu/~abfine/
> <http://internal.psychology.illinois.edu/~abfine/AlexFineHome.html>
>



-- 
Saudi Sadiq,
Assistant Lecturer, English Department,
Faculty of Al-Alsun,Minia University,
Minia City, Egypt &
PhD Student, Language and Linguistic Science Department,
University of York, York, North Yorkshire, UK,
YO10 5DD
http://york.academia.edu/SaudiSadiq
https://www.researchgate.net/profile/Saudi_Sadiq
Certified Translator by Egyptian Translation Association (Egyta)
<http://www.egyta.com/>
Certified Interpreter by Pearl Linguistics
<http://www.pearllinguistics.com/>
Verified Teacher at https://lingos.co/users/saudi-sadiq
Verified Teacher at
https://www.firsttutors.com/uk/languages/teacher/saudi.arabic.english

	[[alternative HTML version deleted]]


From vickers.mathew at gmail.com  Mon Apr 11 15:30:47 2016
From: vickers.mathew at gmail.com (Mathew Vickers)
Date: Mon, 11 Apr 2016 15:30:47 +0200
Subject: [R-sig-ME] specify random term and autocorrelation and plot lme
Message-ID: <CAAUAsC-ugStSX7Ao7Tz+BeceA6coN-u7W7pAjC2HQ3EwPfjyhQ@mail.gmail.com>

Hi,

I am modeling autocorrelation in a an individual's walk. For a given
walker, I estimate the autocorrelation decay as lag increases.

Dependent
corel (autocorrelation)

Factors:
2 species (a,b)
2 Tanks (t1, t2 - these are two experimental arenas)

random:
subject (there was 10 individuals in each species)

I want to ask whether there is a significant difference in "corel" as a
function of "lag" between species in each Tank, and between the two Tanks
per species


The data look not dissimilar to this:


# data for SIG question

set.seed(100)
dataz <- expand.grid(subject = 1:10, sp = c("a", "b"), Tank = c("t1",
"t2"), lag = 1:100)
dataz$subject <- as.factor(paste(dataz$subject, dataz$sp, (dataz$Tank),
sep=""))
slope <- c(rnorm(10, 40, 2), rnorm(10, 5, 2)); slope <- rep(slope, 200)
dataz$corel <- dataz$lag*slope + rnorm(4000, 0, 1)*dataz$lag
dataz$corel[dataz$Tank=="t2" & dataz$sp=="a"] <-
dataz$corel[dataz$Tank=="t2"& dataz$sp=="a"]*2
dataz$corel[dataz$Tank=="t1" & dataz$sp=="b"] <-
dataz$corel[dataz$Tank=="t1"& dataz$sp=="b"]*1.8
dataz$corel <- -1*dataz$corel
plot(corel~lag, data=dataz, col=interaction(sp, Tank),
pch=c(1,2)[as.numeric(Tank)], cex=0.5)
plot(corel~lag, data=dataz, col=as.numeric(subject),
pch=c(1,2)[as.numeric(Tank)], cex=0.5)


# a dataset with:
# corel = correlation score
# sp = species (a,b)
# Tank = experimental setup (t1, t2)
# lag = indepentdent variable. A time-step (1:100)
# subject = individual
# in this case, I want to force the intercept to 0. The response variable,
"corel" is the autocorrelation between points with lag "lag". This means
point 1 (lag 0) = 0

library(ggplot)
library(nlme)

lma <- gls(corel~0+lag, data=dataz)
ggplot(dataz, aes(x=lag, y=corel)) + geom_point()+
 stat_smooth(method="lm", size=1, se = T)
# this is a test model


lm0 <- gls(corel~0+sp*Tank*lag, data=dataz)
anova(lm0)
plot(lm0)

# add autocorrelation strucuture, allow it to vary by subject?
lm1 <- gls(corel~0+sp*Tank*lag, correlation = corAR1(form = ~ lag |
subject), data=dataz)
anova(lm0, lm1)
plot(lm1)  # i am not convinced autocor structure has helped
summary(lm1)

# is this a plot of model  lm1   ? There is no allowance for
autocorrelation:
ggplot(dataz, aes(x=lag, y=corel, group=interaction(sp, Tank))) +
  geom_point(aes(colour=interaction(sp, Tank)))+
  stat_smooth(method="lm", size=1, se = T)


# add random effect.
# i am not sure if the random effect is specified correctly: repeated
measured of corel per subject, subject nested in sp (species)?
# if random=~subject|sp, the autocorrelation and random terms are
incompatible
lm2 <- lme(corel~0+sp*Tank*lag, random=~1|subject, correlation =
corAR1(form = ~ lag | subject), data=dataz)
plot(lm2)
anova(lm2)
anova(lm0, lm1, lm2)  # seems like lm2 is the best

#how do I plot this?
# I want a plot like the ggplot above, but I am not sure how to do it.




-- 
Mathew Vickers
Post Doc
OuLaLab
CNRS
Moulis, France

	[[alternative HTML version deleted]]


From gaad_djouher at yahoo.fr  Mon Apr 11 07:08:00 2016
From: gaad_djouher at yahoo.fr (Djouher Gaad)
Date: Mon, 11 Apr 2016 05:08:00 +0000 (UTC)
Subject: [R-sig-ME] GLMM Model
References: <808342618.746639.1460351280435.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <808342618.746639.1460351280435.JavaMail.yahoo@mail.yahoo.com>

Dear Professor,First I introduce myself, I amMis. GAAD Djouher, researcher at National Research Center for biotechnology(Algeria). I am working in the field of Agriculture. I was conducted two fieldexperiments in two consecutive years in order to estimate genetic diversityanalysis among forty fourth genotypes of lentil (lens culinaris M.). Morphologicalcharacterization was done based on different parameters like plant height, podper plant, seed per plant, 100 seeds weight? The experiments were carried outfollowing an Alpha Lattice design with fourth replicates. Data were recordedfrom both years. I would like to know if generalized linear mixed model (GLMM)is applicable in this case, considering a genotype as a fixed effect and a blocas random effect.

Thank you for your response.

Best Regards,


?
?GAAD Djouher?Biotechnology and Agriculture Division/ Division Biotechnologies & Agriculture National Research Center of Biotechnology/Centre de Recherche en Biotechnologie?PO Box: E73 .UV N?03 Nouvelle Ville Ali Mendjelli, Constantine?T?l?phone:031-67-22-03 \ 031-67-22-05?Fax: 031-67-22-10??????http://www.crbt.dz??Email: d.gaad at crbt.dz
	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Apr 11 21:10:41 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 11 Apr 2016 21:10:41 +0200
Subject: [R-sig-ME] GLMM Model
In-Reply-To: <808342618.746639.1460351280435.JavaMail.yahoo@mail.yahoo.com>
References: <808342618.746639.1460351280435.JavaMail.yahoo.ref@mail.yahoo.com>
	<808342618.746639.1460351280435.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAJuCY5x1e+Ax6VH4FUdmN_Fw9sj2zwbtLhcQj1NrZN-w_cjL2A@mail.gmail.com>

Dear Djouher,

A (G)LMM seems relevant for this kind of data.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-04-11 7:08 GMT+02:00 Djouher Gaad via R-sig-mixed-models <
r-sig-mixed-models at r-project.org>:

> Dear Professor,First I introduce myself, I amMis. GAAD Djouher, researcher
> at National Research Center for biotechnology(Algeria). I am working in the
> field of Agriculture. I was conducted two fieldexperiments in two
> consecutive years in order to estimate genetic diversityanalysis among
> forty fourth genotypes of lentil (lens culinaris M.).
> Morphologicalcharacterization was done based on different parameters like
> plant height, podper plant, seed per plant, 100 seeds weight? The
> experiments were carried outfollowing an Alpha Lattice design with fourth
> replicates. Data were recordedfrom both years. I would like to know if
> generalized linear mixed model (GLMM)is applicable in this case,
> considering a genotype as a fixed effect and a blocas random effect.
>
> Thank you for your response.
>
> Best Regards,
>
>
>
>  GAAD Djouher Biotechnology and Agriculture Division/ Division
> Biotechnologies & Agriculture National Research Center of
> Biotechnology/Centre de Recherche en Biotechnologie PO Box: E73 .UV N?03
> Nouvelle Ville Ali Mendjelli, Constantine T?l?phone:031-67-22-03 \
> 031-67-22-05 Fax: 031-67-22-10      http://www.crbt.dz  Email:
> d.gaad at crbt.dz
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From highstat at highstat.com  Tue Apr 12 00:44:59 2016
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Mon, 11 Apr 2016 23:44:59 +0100
Subject: [R-sig-ME] Intro GAM and GAMM course: Singapore
Message-ID: <570C28EB.4060109@highstat.com>



There are 4 remaining seats on the following statistics course:

Course: Introduction to GAM and GAMM with R
When: 30 May-3 June 2016
Where: Tropical Marine Science Institute, National University of 
Singapore, Singapore
Course website: http://highstat.com/statscourse.htm
Course flyer: http://highstat.com/Courses/Flyers/Flyer2016_05Singapore.pdf



-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From thierry.onkelinx at inbo.be  Tue Apr 12 09:37:25 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 12 Apr 2016 09:37:25 +0200
Subject: [R-sig-ME] specify random term and autocorrelation and plot lme
In-Reply-To: <CAAUAsC-ugStSX7Ao7Tz+BeceA6coN-u7W7pAjC2HQ3EwPfjyhQ@mail.gmail.com>
References: <CAAUAsC-ugStSX7Ao7Tz+BeceA6coN-u7W7pAjC2HQ3EwPfjyhQ@mail.gmail.com>
Message-ID: <CAJuCY5zughQaHqtiVWHL9oHNwx_u0b42URgV8JHoh_DB0SnZ4g@mail.gmail.com>

Dear Mathew,

AFAIK you can't model different correlation parameters with nlme. The
correlation structures only allow to specify the grouping and the time
covariate. The strength of the correlation is assumed to be equal among
groups.

In your case you are looking for correlation structures with different
strength among the groups. So I would suggest that you look for a technique
which allows you to model that. Then you can compare a model with different
correlation strengths with a model with equal correlation strength.

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-04-11 15:30 GMT+02:00 Mathew Vickers <vickers.mathew at gmail.com>:

> Hi,
>
> I am modeling autocorrelation in a an individual's walk. For a given
> walker, I estimate the autocorrelation decay as lag increases.
>
> Dependent
> corel (autocorrelation)
>
> Factors:
> 2 species (a,b)
> 2 Tanks (t1, t2 - these are two experimental arenas)
>
> random:
> subject (there was 10 individuals in each species)
>
> I want to ask whether there is a significant difference in "corel" as a
> function of "lag" between species in each Tank, and between the two Tanks
> per species
>
>
> The data look not dissimilar to this:
>
>
> # data for SIG question
>
> set.seed(100)
> dataz <- expand.grid(subject = 1:10, sp = c("a", "b"), Tank = c("t1",
> "t2"), lag = 1:100)
> dataz$subject <- as.factor(paste(dataz$subject, dataz$sp, (dataz$Tank),
> sep=""))
> slope <- c(rnorm(10, 40, 2), rnorm(10, 5, 2)); slope <- rep(slope, 200)
> dataz$corel <- dataz$lag*slope + rnorm(4000, 0, 1)*dataz$lag
> dataz$corel[dataz$Tank=="t2" & dataz$sp=="a"] <-
> dataz$corel[dataz$Tank=="t2"& dataz$sp=="a"]*2
> dataz$corel[dataz$Tank=="t1" & dataz$sp=="b"] <-
> dataz$corel[dataz$Tank=="t1"& dataz$sp=="b"]*1.8
> dataz$corel <- -1*dataz$corel
> plot(corel~lag, data=dataz, col=interaction(sp, Tank),
> pch=c(1,2)[as.numeric(Tank)], cex=0.5)
> plot(corel~lag, data=dataz, col=as.numeric(subject),
> pch=c(1,2)[as.numeric(Tank)], cex=0.5)
>
>
> # a dataset with:
> # corel = correlation score
> # sp = species (a,b)
> # Tank = experimental setup (t1, t2)
> # lag = indepentdent variable. A time-step (1:100)
> # subject = individual
> # in this case, I want to force the intercept to 0. The response variable,
> "corel" is the autocorrelation between points with lag "lag". This means
> point 1 (lag 0) = 0
>
> library(ggplot)
> library(nlme)
>
> lma <- gls(corel~0+lag, data=dataz)
> ggplot(dataz, aes(x=lag, y=corel)) + geom_point()+
>  stat_smooth(method="lm", size=1, se = T)
> # this is a test model
>
>
> lm0 <- gls(corel~0+sp*Tank*lag, data=dataz)
> anova(lm0)
> plot(lm0)
>
> # add autocorrelation strucuture, allow it to vary by subject?
> lm1 <- gls(corel~0+sp*Tank*lag, correlation = corAR1(form = ~ lag |
> subject), data=dataz)
> anova(lm0, lm1)
> plot(lm1)  # i am not convinced autocor structure has helped
> summary(lm1)
>
> # is this a plot of model  lm1   ? There is no allowance for
> autocorrelation:
> ggplot(dataz, aes(x=lag, y=corel, group=interaction(sp, Tank))) +
>   geom_point(aes(colour=interaction(sp, Tank)))+
>   stat_smooth(method="lm", size=1, se = T)
>
>
> # add random effect.
> # i am not sure if the random effect is specified correctly: repeated
> measured of corel per subject, subject nested in sp (species)?
> # if random=~subject|sp, the autocorrelation and random terms are
> incompatible
> lm2 <- lme(corel~0+sp*Tank*lag, random=~1|subject, correlation =
> corAR1(form = ~ lag | subject), data=dataz)
> plot(lm2)
> anova(lm2)
> anova(lm0, lm1, lm2)  # seems like lm2 is the best
>
> #how do I plot this?
> # I want a plot like the ggplot above, but I am not sure how to do it.
>
>
>
>
> --
> Mathew Vickers
> Post Doc
> OuLaLab
> CNRS
> Moulis, France
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From vickers.mathew at gmail.com  Tue Apr 12 14:42:14 2016
From: vickers.mathew at gmail.com (Mathew Vickers)
Date: Tue, 12 Apr 2016 14:42:14 +0200
Subject: [R-sig-ME] specify random term and autocorrelation and plot lme
In-Reply-To: <CAJuCY5zughQaHqtiVWHL9oHNwx_u0b42URgV8JHoh_DB0SnZ4g@mail.gmail.com>
References: <CAAUAsC-ugStSX7Ao7Tz+BeceA6coN-u7W7pAjC2HQ3EwPfjyhQ@mail.gmail.com>
	<CAJuCY5zughQaHqtiVWHL9oHNwx_u0b42URgV8JHoh_DB0SnZ4g@mail.gmail.com>
Message-ID: <CAAUAsC8O22GFbY=n40owgAnbyGd=qxEtY85rsbfg7-SdKjMqoA@mail.gmail.com>

Hi Thierry,

thank you for your answer.

What I am looking for is an interaction between sp and Tank in slope
(perhaps this is not what I modelled, but it was what I was trying to
model).

I am OK if the strength of the correlation is equal among groups (in this
case, subjects), I thought that including a correlation structure was to
correct for non-independent residuals? (am I incorrect?)

mat.




On Tue, Apr 12, 2016 at 9:37 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Mathew,
>
> AFAIK you can't model different correlation parameters with nlme. The
> correlation structures only allow to specify the grouping and the time
> covariate. The strength of the correlation is assumed to be equal among
> groups.
>
> In your case you are looking for correlation structures with different
> strength among the groups. So I would suggest that you look for a technique
> which allows you to model that. Then you can compare a model with different
> correlation strengths with a model with equal correlation strength.
>
> Best regards,
>
> Thierry
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2016-04-11 15:30 GMT+02:00 Mathew Vickers <vickers.mathew at gmail.com>:
>
>> Hi,
>>
>> I am modeling autocorrelation in a an individual's walk. For a given
>> walker, I estimate the autocorrelation decay as lag increases.
>>
>> Dependent
>> corel (autocorrelation)
>>
>> Factors:
>> 2 species (a,b)
>> 2 Tanks (t1, t2 - these are two experimental arenas)
>>
>> random:
>> subject (there was 10 individuals in each species)
>>
>> I want to ask whether there is a significant difference in "corel" as a
>> function of "lag" between species in each Tank, and between the two Tanks
>> per species
>>
>>
>> The data look not dissimilar to this:
>>
>>
>> # data for SIG question
>>
>> set.seed(100)
>> dataz <- expand.grid(subject = 1:10, sp = c("a", "b"), Tank = c("t1",
>> "t2"), lag = 1:100)
>> dataz$subject <- as.factor(paste(dataz$subject, dataz$sp, (dataz$Tank),
>> sep=""))
>> slope <- c(rnorm(10, 40, 2), rnorm(10, 5, 2)); slope <- rep(slope, 200)
>> dataz$corel <- dataz$lag*slope + rnorm(4000, 0, 1)*dataz$lag
>> dataz$corel[dataz$Tank=="t2" & dataz$sp=="a"] <-
>> dataz$corel[dataz$Tank=="t2"& dataz$sp=="a"]*2
>> dataz$corel[dataz$Tank=="t1" & dataz$sp=="b"] <-
>> dataz$corel[dataz$Tank=="t1"& dataz$sp=="b"]*1.8
>> dataz$corel <- -1*dataz$corel
>> plot(corel~lag, data=dataz, col=interaction(sp, Tank),
>> pch=c(1,2)[as.numeric(Tank)], cex=0.5)
>> plot(corel~lag, data=dataz, col=as.numeric(subject),
>> pch=c(1,2)[as.numeric(Tank)], cex=0.5)
>>
>>
>> # a dataset with:
>> # corel = correlation score
>> # sp = species (a,b)
>> # Tank = experimental setup (t1, t2)
>> # lag = indepentdent variable. A time-step (1:100)
>> # subject = individual
>> # in this case, I want to force the intercept to 0. The response variable,
>> "corel" is the autocorrelation between points with lag "lag". This means
>> point 1 (lag 0) = 0
>>
>> library(ggplot)
>> library(nlme)
>>
>> lma <- gls(corel~0+lag, data=dataz)
>> ggplot(dataz, aes(x=lag, y=corel)) + geom_point()+
>>  stat_smooth(method="lm", size=1, se = T)
>> # this is a test model
>>
>>
>> lm0 <- gls(corel~0+sp*Tank*lag, data=dataz)
>> anova(lm0)
>> plot(lm0)
>>
>> # add autocorrelation strucuture, allow it to vary by subject?
>> lm1 <- gls(corel~0+sp*Tank*lag, correlation = corAR1(form = ~ lag |
>> subject), data=dataz)
>> anova(lm0, lm1)
>> plot(lm1)  # i am not convinced autocor structure has helped
>> summary(lm1)
>>
>> # is this a plot of model  lm1   ? There is no allowance for
>> autocorrelation:
>> ggplot(dataz, aes(x=lag, y=corel, group=interaction(sp, Tank))) +
>>   geom_point(aes(colour=interaction(sp, Tank)))+
>>   stat_smooth(method="lm", size=1, se = T)
>>
>>
>> # add random effect.
>> # i am not sure if the random effect is specified correctly: repeated
>> measured of corel per subject, subject nested in sp (species)?
>> # if random=~subject|sp, the autocorrelation and random terms are
>> incompatible
>> lm2 <- lme(corel~0+sp*Tank*lag, random=~1|subject, correlation =
>> corAR1(form = ~ lag | subject), data=dataz)
>> plot(lm2)
>> anova(lm2)
>> anova(lm0, lm1, lm2)  # seems like lm2 is the best
>>
>> #how do I plot this?
>> # I want a plot like the ggplot above, but I am not sure how to do it.
>>
>>
>>
>>
>> --
>> Mathew Vickers
>> Post Doc
>> OuLaLab
>> CNRS
>> Moulis, France
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>


-- 
Mathew Vickers
Post Doc
OuLaLab
CNRS
Moulis, France

	[[alternative HTML version deleted]]


From david.tn.jones at gmail.com  Tue Apr 12 17:10:53 2016
From: david.tn.jones at gmail.com (David Jones)
Date: Tue, 12 Apr 2016 11:10:53 -0400
Subject: [R-sig-ME] Specifying Random Effects For Multiple Cross-Level
	Interactions
Message-ID: <CAJgUsw+RFkkxt770DJoidf0RbZ8Mo7xCaN9HKdEC+2QcP5Y1LA@mail.gmail.com>

I have a question about cross-level interactions in lmer which is a novice
one, but I cannot find examples online to address this in lmer because most
examples only focus on 1 cross-level interaction at a time.

I am trying to look at a model with 4 L1 variables, 4 L2 variables, and a
cross-level interaction between each respective pair (for 4 total
interactions). I have tried to specify the models in lmer, but have had
problems with the models and understanding why the errors occur. I have
searched these archives, and also used Doug Bates's slides and the lme4
wiki, among other resources.

As a preface, my sample is small (N=61, 29 clusters). L1 units (Xs) are
nested under site (between-subjects variables are the Ws). I would prefer
to use mixed-effects models if possible given precedent in my field. Here
are the the models I have tried:

For this first model, I get near perfect correlations between each set of
random intercepts/slopes (from looking at resources, it is probably because
my model has too many random effects). Syntax for the model as well as the
output for random effects is below.

model1 <- lmer(y ~ x1 + x2 + x3 + x4 + w1 + w2 + w3 + w4 +
                   x1:w1 + x2:w2 + x3:w3 + x4:w4 +
                   (x1 | site) + (x2 | site) + (x3 | site) + (x4 | site),
data = dataset,
                 REML=FALSE)

Random effects:
 Groups      Name          Variance   Std.Dev.   Corr
 site        (Intercept)   0.000e+00  0.000e+00
             x1   	   7.594e-14  2.756e-07  NaN
 site.1      (Intercept)   9.916e+00  3.149e+00
             x2   	   5.444e+01  7.378e+00  1.00
 site.2      (Intercept)   0.000e+00  0.000e+00
             x3   	   1.965e-11  4.433e-06  NaN
 site.3      (Intercept)   1.262e-01  3.553e-01
             x4   	   2.262e+00  1.504e+00  1.00
 Residual

Given this, I tried a different model with only 1 random intercept and a 1
random slope for each L1 variable (which are uncorrelated with intercepts
or each other). This runs (the first model I listed didn't converge for one
of my DVs; all of these examples have output associated with the same DV).
But, I often get perfect 0s for the random effects for the slopes (not even
a very, very small number like 7.2e-10, but rather literally 0.000 for the
variance and its SD, as if the random slopes are perfectly multicollinear).
Syntax and output are below.

model2 <- lmer(y ~ x1 + x2 + x3 + x4 + w1 + w2 + w3 + w4 +
                   x1:y1 + x2:y2 + x3:y3 + x4:y4 +
                   (1 | site) + (0 + x1 | site) + (0 + x2 | site) + (0 + x3
| site) + (0 + x4 | site), data = dataset,
                 REML=FALSE)


 Random effects:
 Groups      Name              Variance     Std.Dev.
 site            (Intercept)        4.091         2.023
 site.1         x1                     0.000         0.000
 site.2         x2                     0.000         0.000
 site.3         x3                     0.000         0.000
 site.4         x4                     0.000         0.000
 Residual                            53.150       7.290

If I specify a model with fewer effects, I do get non-negligible random
slopes, but the correlation between random effects generally is still
perfect.

model3 <- lmer(y ~ x1 + x2 + x3 + x4 + w1 + w2 + w3 + w4 +
                   x1:y1 + x2:y2 + x3:y3 + x4:y4 +
                   (x1 | site), data = dataset, REML=FALSE)

 Random effects:
 Groups    Name            Variance   Std.Dev.   Corr
 site          (Intercept)      10.01       3.164
                 x1                  55.76       7.467        1.00
 Residual                        46.04       6.785

Finally, if I tried to let estimate all random effects and let them covary,
the model won't run R indicates that there are way too many random effects
to estimate - syntax for this is below:

model3 <- lmer(y ~ x1 + x2 + x3 + x4 + w1 + w2 + w3 + w4 +
                   x1:y1 + x2:y2 + x3:y3 + x4:y4 +
                   (1 + x1 + x2 + x3 + x4 | site), data = dataset,
REML=FALSE)

The main thing that is confusing me is, for each cross level interaction,
shouldn't I need a random slope for each L1 predictor? My main question
then is, how should I address this situation?

I recognize there is something I must be doing wrongly as I am new to
cross-level interactions. I must be specifying redundant intercepts/slopes
at some point. As secondary questions, what do the multiple intercepts
represent that were obtained from the first model, and why are there
multiple listings for site when specifying uncorrelated random effects
(e.g., site.1, site.2, etc.)?

Many thanks for your input.

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Apr 12 21:05:18 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 12 Apr 2016 21:05:18 +0200
Subject: [R-sig-ME] Specifying Random Effects For Multiple Cross-Level
	Interactions
In-Reply-To: <CAJgUsw+RFkkxt770DJoidf0RbZ8Mo7xCaN9HKdEC+2QcP5Y1LA@mail.gmail.com>
References: <CAJgUsw+RFkkxt770DJoidf0RbZ8Mo7xCaN9HKdEC+2QcP5Y1LA@mail.gmail.com>
Message-ID: <CAJuCY5y3fgbqQxibo6CDL9u1aNqGhEHJYiR9jCGM3J-GX918PQ@mail.gmail.com>

Dear David,

Please don't post in HTML as is can mangle up code and output.

It seems like you have only 2 or 3 observations per site. That amount of
replications per site only allows to fit a random intercept.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-04-12 17:10 GMT+02:00 David Jones <david.tn.jones at gmail.com>:

> I have a question about cross-level interactions in lmer which is a novice
> one, but I cannot find examples online to address this in lmer because most
> examples only focus on 1 cross-level interaction at a time.
>
> I am trying to look at a model with 4 L1 variables, 4 L2 variables, and a
> cross-level interaction between each respective pair (for 4 total
> interactions). I have tried to specify the models in lmer, but have had
> problems with the models and understanding why the errors occur. I have
> searched these archives, and also used Doug Bates's slides and the lme4
> wiki, among other resources.
>
> As a preface, my sample is small (N=61, 29 clusters). L1 units (Xs) are
> nested under site (between-subjects variables are the Ws). I would prefer
> to use mixed-effects models if possible given precedent in my field. Here
> are the the models I have tried:
>
> For this first model, I get near perfect correlations between each set of
> random intercepts/slopes (from looking at resources, it is probably because
> my model has too many random effects). Syntax for the model as well as the
> output for random effects is below.
>
> model1 <- lmer(y ~ x1 + x2 + x3 + x4 + w1 + w2 + w3 + w4 +
>                    x1:w1 + x2:w2 + x3:w3 + x4:w4 +
>                    (x1 | site) + (x2 | site) + (x3 | site) + (x4 | site),
> data = dataset,
>                  REML=FALSE)
>
> Random effects:
>  Groups      Name          Variance   Std.Dev.   Corr
>  site        (Intercept)   0.000e+00  0.000e+00
>              x1            7.594e-14  2.756e-07  NaN
>  site.1      (Intercept)   9.916e+00  3.149e+00
>              x2            5.444e+01  7.378e+00  1.00
>  site.2      (Intercept)   0.000e+00  0.000e+00
>              x3            1.965e-11  4.433e-06  NaN
>  site.3      (Intercept)   1.262e-01  3.553e-01
>              x4            2.262e+00  1.504e+00  1.00
>  Residual
>
> Given this, I tried a different model with only 1 random intercept and a 1
> random slope for each L1 variable (which are uncorrelated with intercepts
> or each other). This runs (the first model I listed didn't converge for one
> of my DVs; all of these examples have output associated with the same DV).
> But, I often get perfect 0s for the random effects for the slopes (not even
> a very, very small number like 7.2e-10, but rather literally 0.000 for the
> variance and its SD, as if the random slopes are perfectly multicollinear).
> Syntax and output are below.
>
> model2 <- lmer(y ~ x1 + x2 + x3 + x4 + w1 + w2 + w3 + w4 +
>                    x1:y1 + x2:y2 + x3:y3 + x4:y4 +
>                    (1 | site) + (0 + x1 | site) + (0 + x2 | site) + (0 + x3
> | site) + (0 + x4 | site), data = dataset,
>                  REML=FALSE)
>
>
>  Random effects:
>  Groups      Name              Variance     Std.Dev.
>  site            (Intercept)        4.091         2.023
>  site.1         x1                     0.000         0.000
>  site.2         x2                     0.000         0.000
>  site.3         x3                     0.000         0.000
>  site.4         x4                     0.000         0.000
>  Residual                            53.150       7.290
>
> If I specify a model with fewer effects, I do get non-negligible random
> slopes, but the correlation between random effects generally is still
> perfect.
>
> model3 <- lmer(y ~ x1 + x2 + x3 + x4 + w1 + w2 + w3 + w4 +
>                    x1:y1 + x2:y2 + x3:y3 + x4:y4 +
>                    (x1 | site), data = dataset, REML=FALSE)
>
>  Random effects:
>  Groups    Name            Variance   Std.Dev.   Corr
>  site          (Intercept)      10.01       3.164
>                  x1                  55.76       7.467        1.00
>  Residual                        46.04       6.785
>
> Finally, if I tried to let estimate all random effects and let them covary,
> the model won't run R indicates that there are way too many random effects
> to estimate - syntax for this is below:
>
> model3 <- lmer(y ~ x1 + x2 + x3 + x4 + w1 + w2 + w3 + w4 +
>                    x1:y1 + x2:y2 + x3:y3 + x4:y4 +
>                    (1 + x1 + x2 + x3 + x4 | site), data = dataset,
> REML=FALSE)
>
> The main thing that is confusing me is, for each cross level interaction,
> shouldn't I need a random slope for each L1 predictor? My main question
> then is, how should I address this situation?
>
> I recognize there is something I must be doing wrongly as I am new to
> cross-level interactions. I must be specifying redundant intercepts/slopes
> at some point. As secondary questions, what do the multiple intercepts
> represent that were obtained from the first model, and why are there
> multiple listings for site when specifying uncorrelated random effects
> (e.g., site.1, site.2, etc.)?
>
> Many thanks for your input.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Wed Apr 13 09:27:35 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 13 Apr 2016 09:27:35 +0200
Subject: [R-sig-ME] specify random term and autocorrelation and plot lme
In-Reply-To: <CAAUAsC8O22GFbY=n40owgAnbyGd=qxEtY85rsbfg7-SdKjMqoA@mail.gmail.com>
References: <CAAUAsC-ugStSX7Ao7Tz+BeceA6coN-u7W7pAjC2HQ3EwPfjyhQ@mail.gmail.com>
	<CAJuCY5zughQaHqtiVWHL9oHNwx_u0b42URgV8JHoh_DB0SnZ4g@mail.gmail.com>
	<CAAUAsC8O22GFbY=n40owgAnbyGd=qxEtY85rsbfg7-SdKjMqoA@mail.gmail.com>
Message-ID: <CAJuCY5zTv0V=cuzkCXZjc1EBapvY_0iMrePsTOkQjYEn-_FSmQ@mail.gmail.com>

Dear Mathew,

My point was not to estimate the autocorrelation and model these estimated
autocorrelations. But rather model the random walk with different
autocorrelation structures and compare these models.

Modelling the estimated autocorrelation at different lags inflates the data
and ignores the uncertainty on the autocorrelation measurements.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-04-12 14:42 GMT+02:00 Mathew Vickers <vickers.mathew at gmail.com>:

> Hi Thierry,
>
> thank you for your answer.
>
> What I am looking for is an interaction between sp and Tank in slope
> (perhaps this is not what I modelled, but it was what I was trying to
> model).
>
> I am OK if the strength of the correlation is equal among groups (in this
> case, subjects), I thought that including a correlation structure was to
> correct for non-independent residuals? (am I incorrect?)
>
> mat.
>
>
>
>
> On Tue, Apr 12, 2016 at 9:37 AM, Thierry Onkelinx <
> thierry.onkelinx at inbo.be> wrote:
>
>> Dear Mathew,
>>
>> AFAIK you can't model different correlation parameters with nlme. The
>> correlation structures only allow to specify the grouping and the time
>> covariate. The strength of the correlation is assumed to be equal among
>> groups.
>>
>> In your case you are looking for correlation structures with different
>> strength among the groups. So I would suggest that you look for a technique
>> which allows you to model that. Then you can compare a model with different
>> correlation strengths with a model with equal correlation strength.
>>
>> Best regards,
>>
>> Thierry
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2016-04-11 15:30 GMT+02:00 Mathew Vickers <vickers.mathew at gmail.com>:
>>
>>> Hi,
>>>
>>> I am modeling autocorrelation in a an individual's walk. For a given
>>> walker, I estimate the autocorrelation decay as lag increases.
>>>
>>> Dependent
>>> corel (autocorrelation)
>>>
>>> Factors:
>>> 2 species (a,b)
>>> 2 Tanks (t1, t2 - these are two experimental arenas)
>>>
>>> random:
>>> subject (there was 10 individuals in each species)
>>>
>>> I want to ask whether there is a significant difference in "corel" as a
>>> function of "lag" between species in each Tank, and between the two Tanks
>>> per species
>>>
>>>
>>> The data look not dissimilar to this:
>>>
>>>
>>> # data for SIG question
>>>
>>> set.seed(100)
>>> dataz <- expand.grid(subject = 1:10, sp = c("a", "b"), Tank = c("t1",
>>> "t2"), lag = 1:100)
>>> dataz$subject <- as.factor(paste(dataz$subject, dataz$sp, (dataz$Tank),
>>> sep=""))
>>> slope <- c(rnorm(10, 40, 2), rnorm(10, 5, 2)); slope <- rep(slope, 200)
>>> dataz$corel <- dataz$lag*slope + rnorm(4000, 0, 1)*dataz$lag
>>> dataz$corel[dataz$Tank=="t2" & dataz$sp=="a"] <-
>>> dataz$corel[dataz$Tank=="t2"& dataz$sp=="a"]*2
>>> dataz$corel[dataz$Tank=="t1" & dataz$sp=="b"] <-
>>> dataz$corel[dataz$Tank=="t1"& dataz$sp=="b"]*1.8
>>> dataz$corel <- -1*dataz$corel
>>> plot(corel~lag, data=dataz, col=interaction(sp, Tank),
>>> pch=c(1,2)[as.numeric(Tank)], cex=0.5)
>>> plot(corel~lag, data=dataz, col=as.numeric(subject),
>>> pch=c(1,2)[as.numeric(Tank)], cex=0.5)
>>>
>>>
>>> # a dataset with:
>>> # corel = correlation score
>>> # sp = species (a,b)
>>> # Tank = experimental setup (t1, t2)
>>> # lag = indepentdent variable. A time-step (1:100)
>>> # subject = individual
>>> # in this case, I want to force the intercept to 0. The response
>>> variable,
>>> "corel" is the autocorrelation between points with lag "lag". This means
>>> point 1 (lag 0) = 0
>>>
>>> library(ggplot)
>>> library(nlme)
>>>
>>> lma <- gls(corel~0+lag, data=dataz)
>>> ggplot(dataz, aes(x=lag, y=corel)) + geom_point()+
>>>  stat_smooth(method="lm", size=1, se = T)
>>> # this is a test model
>>>
>>>
>>> lm0 <- gls(corel~0+sp*Tank*lag, data=dataz)
>>> anova(lm0)
>>> plot(lm0)
>>>
>>> # add autocorrelation strucuture, allow it to vary by subject?
>>> lm1 <- gls(corel~0+sp*Tank*lag, correlation = corAR1(form = ~ lag |
>>> subject), data=dataz)
>>> anova(lm0, lm1)
>>> plot(lm1)  # i am not convinced autocor structure has helped
>>> summary(lm1)
>>>
>>> # is this a plot of model  lm1   ? There is no allowance for
>>> autocorrelation:
>>> ggplot(dataz, aes(x=lag, y=corel, group=interaction(sp, Tank))) +
>>>   geom_point(aes(colour=interaction(sp, Tank)))+
>>>   stat_smooth(method="lm", size=1, se = T)
>>>
>>>
>>> # add random effect.
>>> # i am not sure if the random effect is specified correctly: repeated
>>> measured of corel per subject, subject nested in sp (species)?
>>> # if random=~subject|sp, the autocorrelation and random terms are
>>> incompatible
>>> lm2 <- lme(corel~0+sp*Tank*lag, random=~1|subject, correlation =
>>> corAR1(form = ~ lag | subject), data=dataz)
>>> plot(lm2)
>>> anova(lm2)
>>> anova(lm0, lm1, lm2)  # seems like lm2 is the best
>>>
>>> #how do I plot this?
>>> # I want a plot like the ggplot above, but I am not sure how to do it.
>>>
>>>
>>>
>>>
>>> --
>>> Mathew Vickers
>>> Post Doc
>>> OuLaLab
>>> CNRS
>>> Moulis, France
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>
>
> --
> Mathew Vickers
> Post Doc
> OuLaLab
> CNRS
> Moulis, France
>

	[[alternative HTML version deleted]]


From david.tn.jones at gmail.com  Wed Apr 13 17:02:20 2016
From: david.tn.jones at gmail.com (David Jones)
Date: Wed, 13 Apr 2016 11:02:20 -0400
Subject: [R-sig-ME] Specifying Random Effects For Multiple Cross-Level
	Interactions
In-Reply-To: <CAJuCY5y3fgbqQxibo6CDL9u1aNqGhEHJYiR9jCGM3J-GX918PQ@mail.gmail.com>
References: <CAJgUsw+RFkkxt770DJoidf0RbZ8Mo7xCaN9HKdEC+2QcP5Y1LA@mail.gmail.com>
	<CAJuCY5y3fgbqQxibo6CDL9u1aNqGhEHJYiR9jCGM3J-GX918PQ@mail.gmail.com>
Message-ID: <CAJgUswKJizh_fCNpM4XpT0iE=HVg21nE+Ed-KMV2HSPgP7jc_A@mail.gmail.com>

Many thanks, Thierry - this is very helpful and I am very grateful for
your input. I am sending this message via plain text as well :) I will
plan on going forward with just a random intercept while specifying
the cross-level interaction.

On Tue, Apr 12, 2016 at 3:05 PM, Thierry Onkelinx
<thierry.onkelinx at inbo.be> wrote:
> Dear David,
>
> Please don't post in HTML as is can mangle up code and output.
>
> It seems like you have only 2 or 3 observations per site. That amount of
> replications per site only allows to fit a random intercept.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more than
> asking him to perform a post-mortem examination: he may be able to say what
> the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2016-04-12 17:10 GMT+02:00 David Jones <david.tn.jones at gmail.com>:
>>
>> I have a question about cross-level interactions in lmer which is a novice
>> one, but I cannot find examples online to address this in lmer because
>> most
>> examples only focus on 1 cross-level interaction at a time.
>>
>> I am trying to look at a model with 4 L1 variables, 4 L2 variables, and a
>> cross-level interaction between each respective pair (for 4 total
>> interactions). I have tried to specify the models in lmer, but have had
>> problems with the models and understanding why the errors occur. I have
>> searched these archives, and also used Doug Bates's slides and the lme4
>> wiki, among other resources.
>>
>> As a preface, my sample is small (N=61, 29 clusters). L1 units (Xs) are
>> nested under site (between-subjects variables are the Ws). I would prefer
>> to use mixed-effects models if possible given precedent in my field. Here
>> are the the models I have tried:
>>
>> For this first model, I get near perfect correlations between each set of
>> random intercepts/slopes (from looking at resources, it is probably
>> because
>> my model has too many random effects). Syntax for the model as well as the
>> output for random effects is below.
>>
>> model1 <- lmer(y ~ x1 + x2 + x3 + x4 + w1 + w2 + w3 + w4 +
>>                    x1:w1 + x2:w2 + x3:w3 + x4:w4 +
>>                    (x1 | site) + (x2 | site) + (x3 | site) + (x4 | site),
>> data = dataset,
>>                  REML=FALSE)
>>
>> Random effects:
>>  Groups      Name          Variance   Std.Dev.   Corr
>>  site        (Intercept)   0.000e+00  0.000e+00
>>              x1            7.594e-14  2.756e-07  NaN
>>  site.1      (Intercept)   9.916e+00  3.149e+00
>>              x2            5.444e+01  7.378e+00  1.00
>>  site.2      (Intercept)   0.000e+00  0.000e+00
>>              x3            1.965e-11  4.433e-06  NaN
>>  site.3      (Intercept)   1.262e-01  3.553e-01
>>              x4            2.262e+00  1.504e+00  1.00
>>  Residual
>>
>> Given this, I tried a different model with only 1 random intercept and a 1
>> random slope for each L1 variable (which are uncorrelated with intercepts
>> or each other). This runs (the first model I listed didn't converge for
>> one
>> of my DVs; all of these examples have output associated with the same DV).
>> But, I often get perfect 0s for the random effects for the slopes (not
>> even
>> a very, very small number like 7.2e-10, but rather literally 0.000 for the
>> variance and its SD, as if the random slopes are perfectly
>> multicollinear).
>> Syntax and output are below.
>>
>> model2 <- lmer(y ~ x1 + x2 + x3 + x4 + w1 + w2 + w3 + w4 +
>>                    x1:y1 + x2:y2 + x3:y3 + x4:y4 +
>>                    (1 | site) + (0 + x1 | site) + (0 + x2 | site) + (0 +
>> x3
>> | site) + (0 + x4 | site), data = dataset,
>>                  REML=FALSE)
>>
>>
>>  Random effects:
>>  Groups      Name              Variance     Std.Dev.
>>  site            (Intercept)        4.091         2.023
>>  site.1         x1                     0.000         0.000
>>  site.2         x2                     0.000         0.000
>>  site.3         x3                     0.000         0.000
>>  site.4         x4                     0.000         0.000
>>  Residual                            53.150       7.290
>>
>> If I specify a model with fewer effects, I do get non-negligible random
>> slopes, but the correlation between random effects generally is still
>> perfect.
>>
>> model3 <- lmer(y ~ x1 + x2 + x3 + x4 + w1 + w2 + w3 + w4 +
>>                    x1:y1 + x2:y2 + x3:y3 + x4:y4 +
>>                    (x1 | site), data = dataset, REML=FALSE)
>>
>>  Random effects:
>>  Groups    Name            Variance   Std.Dev.   Corr
>>  site          (Intercept)      10.01       3.164
>>                  x1                  55.76       7.467        1.00
>>  Residual                        46.04       6.785
>>
>> Finally, if I tried to let estimate all random effects and let them
>> covary,
>> the model won't run R indicates that there are way too many random effects
>> to estimate - syntax for this is below:
>>
>> model3 <- lmer(y ~ x1 + x2 + x3 + x4 + w1 + w2 + w3 + w4 +
>>                    x1:y1 + x2:y2 + x3:y3 + x4:y4 +
>>                    (1 + x1 + x2 + x3 + x4 | site), data = dataset,
>> REML=FALSE)
>>
>> The main thing that is confusing me is, for each cross level interaction,
>> shouldn't I need a random slope for each L1 predictor? My main question
>> then is, how should I address this situation?
>>
>> I recognize there is something I must be doing wrongly as I am new to
>> cross-level interactions. I must be specifying redundant intercepts/slopes
>> at some point. As secondary questions, what do the multiple intercepts
>> represent that were obtained from the first model, and why are there
>> multiple listings for site when specifying uncorrelated random effects
>> (e.g., site.1, site.2, etc.)?
>>
>> Many thanks for your input.
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


From chun.chen at wur.nl  Wed Apr 13 21:51:47 2016
From: chun.chen at wur.nl (Chen, Chun)
Date: Wed, 13 Apr 2016 19:51:47 +0000
Subject: [R-sig-ME] simulation of factor-specific random effect variance
 estimation, the order of assigned variance matters?
Message-ID: <b8d6506462864f33bf388e6d32837cb2@scomp5296.wurnet.nl>

Dear all,

I have a nested data structure and I would like to estimate factor-specific random effect variance. Inspired by the article:

http://rstudio-pubs-static.s3.amazonaws.com/6B98_c0ae95A0AAA44A3Aa8a9b6ba9703fcf5.html<http://rstudio-pubs-static.s3.amazonaws.com/6298_c0ae951011144131a8a9b6ba9703fcf5.html>

I conducted some simulations:

###############
##--generate data-----
ngroup <- 25
nrep<- 5
##----random effect of group---
meanh <- 0
sigmahA <- 1   ##--these are the two assigned variance of the random factor group for each class (A, B)
sigmahB <- 3

##----residual random error---
meanR <- 0
sigmaR <- 0.2

##---simulate smaple--------------------------------------------------
set.seed(55)
out_A   <- NA
out_B   <- NA
raneff_groupA <- rnorm(ngroup, meanh, sigmahA)
raneff_groupB <- rnorm(ngroup, meanh, sigmahB)
groupID      <- seq(1, ngroup)
for (i in 1:ngroup) {
    raneff_red_A <- rnorm(nrep, meanR, sigmaR)
    temp_A       <- 0 + raneff_groupA[i] + raneff_red_A
    raneff_red_B   <- rnorm(nrep, meanR, sigmaR)
    temp_B   <- 1 + raneff_groupB[i] + raneff_red_B
    out_A <- rbind(out_A, cbind(groupID[i], raneff_groupA[i], raneff_red_A, temp_A))
    out_B   <- rbind(out_B, cbind(groupID[i], raneff_groupB[i], raneff_red_B, temp_B))
}
out_A <- out_A[-1,]
out_B   <- out_B[-1,]

dat <- data.frame(groupID=c(out_A[,1], out_B[,1]), prog=c(rep("A",nrow(out_A)), rep("B",nrow(out_B))), out=c(out_A[,"temp_A"], out_B[,"temp_B"]), raneff_haul=c(out_A[,2], out_B[,2]), error=c(out_A[,3], out_B[,3]))

library(lattice)
bwplot(out~paste(prog,groupID), data=dat)

##--apply model-----
fit2 <- lme(out ~ prog-1, random = list(groupID = pdDiag(~prog)), method = "REML", data = dat)
summary(fit2)

This code gives the expected model output: as estimated variance of groups for A and B are:  1.07957 2.835139, similar to assigned value
###############
###############
Model output:
Linear mixed-effects model fit by REML
Data: dat
       AIC      BIC    logLik
  202.7263 220.2934 -96.36314

Random effects:
Formula: ~prog | groupID
Structure: Diagonal
        (Intercept)    progB  Residual
StdDev:     1.07957 2.835139 0.1959905

Fixed effects: out ~ prog - 1
          Value Std.Error  DF   t-value p-value
progA 0.0316535 0.2166244 224 0.1461215  0.8840
progB 1.1446339 0.6069982 224 1.8857287  0.0606
Correlation:
      progA
progB 0.355

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max
-2.29868033 -0.63163428  0.03981236  0.64863494  2.63613133

Number of Observations: 250
Number of Groups: 25
#########################



However, it I dont make any other changes, but simply to switch the order of the simulation variance:

sigmahA <- 3
sigmahB <- 1

, generate the data and apply the model, the model gives very confusing result:
###############
###############
Model output:
Linear mixed-effects model fit by REML
Data: dat
      AIC      BIC    logLik
  261.763 279.3301 -125.8815

Random effects:
Formula: ~prog | groupID
Structure: Diagonal
        (Intercept)    progB  Residual
StdDev:    3.187986 3.295383 0.1959864

Fixed effects: out ~ prog - 1
          Value Std.Error  DF   t-value p-value
progA 0.1455012 0.6378382 224 0.2281162  0.8198
progB 1.0590270 0.9171802 224 1.1546553  0.2495
Correlation:
      progA
progB 0.695

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max
-2.30847626 -0.63592816  0.03830767  0.64349268  2.63737406

Number of Observations: 250
Number of Groups: 25
#########################



The model output gives equal variance. The same situation happens if I run the same code in the article (link above) and also simply change the order of the variance assigned to the groups.

Can someone help me to figure out why the order of assigning the variance matters? And why the second case does not gives the expected results?

Thanks

Regards,
Chun Chen

	[[alternative HTML version deleted]]


From pauljohn32 at gmail.com  Sun Apr 17 18:36:31 2016
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Sun, 17 Apr 2016 11:36:31 -0500
Subject: [R-sig-ME] GLMM: tricking software to estimate normal error at
	lower level
Message-ID: <CAErODj8unEb3uuO8mLN6mJV83wx2i-dtkZpDvbV_=Faw=9eotw@mail.gmail.com>

Thanks for the help last week on GLMM estimators.  I'm gradually
figuring this out.

Today I'm writing notes comparing NB with Poisson models. Recall, NB
is Poisson with a log(gamma) error variable added to the linear
predictor.  I've often wondered how different that would be from
adding a normal error, but did not have way to estimate.

In Rabe-Hesketh and Skrondal Multilevel / Longitudinal Modeling Using
Stata, 3ed, they show a way to estimate a normally distributed random
error inserted into a Poisson GLM in a one level model by "tricking"
an estimator for a multilevel model (p. 707). I've checked, can do
with xtpoisson or meglm in Stata 14).  Code is below.

I have some trouble with glmer trying to do same. Estimates are close
to the "seems to work" answer from Stata, but I get glmer convergence
warning and different numbers, grossly different predicted values. I
understand glmer was not intended for this purpose, but wouldn't it be
fun if we could make it work?

Here's the basic plan in Stata that RHS demonstrate. Declare an id
variable with values 1, ..., N. This is non-replicated data, there
will be just one observation per group.

generate id = _n
xtset id
xtpoisson y x1 x2 x3, normal

The Stata xtpoisson defaults the additive random error as log(gamma),
but you can ask for normal. I've confirmed this runs, and it also
works in the newer Stata meglm fitting function (meglm is only for
normal errors).  Then you can compare side by side xtpoisson with
log(gamma), xtpoisson with normal, and meglm with family(poisson) and
normal mixed effects.

I fiddled around with glmer trying to do same, and the results are not
completely different, but I hit convergence errors. Since I don't
understand the fitting process, as I confessed last week, I'm a little
blocked here.

My minimal running example R code:


## Paul Johnson <pauljohn at ku.edu>
## 20160417

library(MASS)
quine$id <- 1:NROW(quine)

library(foreign)
write.dta(quine, file = "quine.dta12")
## Original model in MASS example(glm.nb)
quine.pois1 <- glm(Days ~ Sex/(Age + Eth*Lrn), data = quine, family =
poisson(log))
summary(quine.pois1)
## Don't know how to write Stata formula to compare to that, so
## rewrite without "/"
quine.pois2 <- glm(Days ~ Sex*Age + Sex*Eth*Lrn, family =
poisson(link=log), data = quine)
summary(quine.pois2)

quine.nb1 <- glm.nb(Days ~ Sex*Age + Sex*Eth*Lrn, data = quine)
summary(quine.nb1)
quine$predpois <- predict(quine.pois2, type = "link")
quine$prednb <- predict(quine.nb1, type = "link")

plot(predpois ~ prednb, data = quine)
with(quine, cor(predpois, prednb))

library(lme4)
# Stata uses  nAGQ=14 equivalent:
glmer1 <- glmer(Days ~ Sex*Age + Sex*Eth*Lrn + (1|id), data = quine,
                family = "poisson", nAGQ = 14)
summary(glmer1)
quine$predglmer1 <- predict(glmer1)
plot(predglmer1 ~ prednb, data = quine)

glmer2 <- glmer.nb(Days ~ Sex*Age + Sex*Eth*Lrn + (1|id), data =
quine, family = "poisson",
                control = glmerControl(optCtrl = list(maxfun = 10000)))

glmer3 <- glmer(Days ~ Sex*Age + Sex*Eth*Lrn + (1|id), data = quine,
family = "poisson",
                     control = glmerControl(optimizer = "Nelder_Mead",
optCtrl = list(maxfun = 10000)))
summary(glmer3)

## end of MRE


The output from glmer indicates convergence trouble,

> glmer1 <- glmer(Days ~ Sex*Age + Sex*Eth*Lrn + (1|id), data = quine, family = "poisson")
Warning message:
In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge with max|grad| = 0.0294911 (tol = 0.001, component 1)
> summary(glmer1)
Generalized linear mixed model fit by maximum likelihood (Laplace
  Approximation) [glmerMod]
 Family: poisson  ( log )
Formula: Days ~ Sex * Age + Sex * Eth * Lrn + (1 | id)
   Data: quine

     AIC      BIC   logLik deviance df.resid
  1106.5   1151.3   -538.3   1076.5      131

Scaled residuals:
     Min       1Q   Median       3Q      Max
-1.56406 -0.27761  0.00195  0.20574  0.42374

Random effects:
 Groups Name        Variance Std.Dev.
 id     (Intercept) 0.6947   0.8335
Number of obs: 146, groups:  id, 146

Fixed effects:
                 Estimate Std. Error z value Pr(>|z|)
(Intercept)      2.652416   0.318366   8.331  < 2e-16 ***
SexM            -0.333252   0.423300  -0.787 0.431123
AgeF1           -0.571727   0.345721  -1.654 0.098183 .
AgeF2           -0.539010   0.403068  -1.337 0.181134
AgeF3           -0.424210   0.351702  -1.206 0.227754
EthN             0.002994   0.286200   0.010 0.991652
LrnSL            0.834826   0.349273   2.390 0.016840 *
SexM:AgeF1      -0.035285   0.493283  -0.072 0.942976
SexM:AgeF2       1.278388   0.499877   2.557 0.010546 *
SexM:AgeF3       1.614987   0.487992   3.309 0.000935 ***
SexM:EthN       -0.918835   0.397881  -2.309 0.020926 *
SexM:LrnSL      -0.701193   0.499202  -1.405 0.160132
EthN:LrnSL      -1.312972   0.405854  -3.235 0.001216 **
SexM:EthN:LrnSL  2.211797   0.623020   3.550 0.000385 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

I played around with glmerControl a while, no progress....


In Stata, no convergence troubles are reported, estimates are not
entirely different:

Mixed-effects GLM                               Number of obs     =        146
Family:                 Poisson
Link:                       log
Group variable:              id                 Number of groups  =        146

                                                Obs per group:
                                                              min =          1
                                                              avg =        1.0
                                                              max =          1

Integration method: mvaghermite                 Integration pts.  =         14

                                                Wald chi2(13)     =      61.55
Log likelihood = -537.82328                     Prob > chi2       =     0.0000
------------------------------------------------------------------------------
        Days |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         Sex |
          M  |  -.3410261   .4261292    -0.80   0.424    -1.176224    .4941718
         Age |
         F1  |  -.5795131   .3480225    -1.67   0.096    -1.261625    .1025984
         F2  |  -.5478196   .4062568    -1.35   0.178    -1.344068     .248429
         F3  |  -.4316382   .3540887    -1.22   0.223    -1.125639    .2623628
     Sex#Age |
       M#F1  |  -.0280678   .4970979    -0.06   0.955    -1.002362    .9462261
       M#F2  |   1.284848   .5037952     2.55   0.011     .2974278    2.272269
       M#F3  |   1.620156   .4914708     3.30   0.001     .6568905    2.583421
         Eth |
          N  |  -.0025892   .2883566    -0.01   0.993    -.5677578    .5625793
     Sex#Eth |
        M#N  |   -.912496   .4009248    -2.28   0.023    -1.698294   -.1266978
         Lrn |
         SL  |   .8328745   .3519247     2.37   0.018     .1431148    1.522634
     Sex#Lrn |
       M#SL  |  -.6980045    .502695    -1.39   0.165    -1.683269    .2872596
     Eth#Lrn |
       N#SL  |  -1.305221   .4090007    -3.19   0.001    -2.106848   -.5035948
 Sex#Eth#Lrn |
     M#N#SL  |   2.200301   .6276649     3.51   0.000     .9701005    3.430502
       _cons |    2.66012   .3203568     8.30   0.000     2.032233    3.288008
-------------+----------------------------------------------------------------
id           |
   var(_cons)|   .7010502   .1077163                      .5187547    .9474061
------------------------------------------------------------------------------
LR test vs. Poisson model: chibar2(01) = 906.35       Prob >= chibar2 = 0.0000

Here is my Stata code, in case you have Stata 14

* How to use the Stata multilevel random effect
* fitters to estiamte a one level normal
* random effect

capture log close
set more off, permanently
log using glmm-nb.log, replace text

use quine.dta12
glm Days i.Sex##i.Age i.Sex##i.Eth##i.Lrn, family(poisson) link(log)
glm Days i.Sex##i.Age i.Sex##i.Eth##i.Lrn, family(nbinom) link(log)

* The variable id is a case identifier, there is one observation per group

xtset id
xtpoisson Days i.Sex##i.Age i.Sex##i.Eth##i.Lrn, normal
estimates store ran1xt
predict ran1xtpxb, xb
predict ran1xtpmu, nu0


meglm Days i.Sex##i.Age i.Sex##i.Eth##i.Lrn || id: , family(poisson) link(log)
estimates store ran1me
predict ran1mepxb, xb
predict ran1mepmu2, mu conditional(fixedonly)

* Previous 2 models identical predicted values
twoway (scatter ran1xtpxb ran1mepxb)

* Tune up the AGQ int points, waste some CPU
meglm Days i.Sex##i.Age i.Sex##i.Eth##i.Lrn || id: , family(poisson) ///
    link(log) intp(14)
estimates store ran2me
predict ran2mepxb, xb
predict ran2mepmu2, mu conditional(fixedonly)

* 2 xtpoisson equiv to meglm
twoway (scatter ran1xtpxb ran2mepxb)
cor ran1xtpxb ran2mepxb

* same
twoway (scatter ran1xtpxb ran2mepxb)
cor ran1xtpxb ran2mepxb

* Compare to log-gamma random effect
xtpoisson Days i.Sex##i.Age i.Sex##i.Eth##i.Lrn, re
estimates store ran2xt
predict ran2xtlgxb, xb
predict ran2xtlgmu, nu0

twoway (scatter ran2xtlgxb ran2mepxb)
cor ran2xtlgxb ran2mepxb
* Not identical, r = 0.986



Oh, I almost forgot:

> sessionInfo()
R version 3.2.4 Revised (2016-03-16 r70336)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 15.10

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] foreign_0.8-66 lme4_1.1-11    Matrix_1.2-4   MASS_7.3-44

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.3.2      lattice_0.20-33    grid_3.2.4         MatrixModels_0.4-1
 [5] nlme_3.1-126       rockchalk_1.8.102  SparseM_1.7        minqa_1.2.4
 [9] nloptr_1.0.4       car_2.1-0          splines_3.2.4      tools_3.2.4
[13] pbkrtest_0.4-6     parallel_3.2.4     compiler_3.2.4     mgcv_1.8-12
[17] nnet_7.3-12        quantreg_5.19


pj

-- 
Paul E. Johnson   http://pj.freefaculty.org
Director, Center for Research Methods and Data Analysis http://crmda.ku.edu

When Google mail changed their sorting rules, I lost interest in their
services. I only use this account for email list memberships. To write
directly, address me at pauljohn
at ku.edu.


From bbolker at gmail.com  Mon Apr 18 03:55:37 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 18 Apr 2016 01:55:37 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?GLMM=3A_tricking_software_to_estimate_normal?=
	=?utf-8?q?_error_at=09lower_level?=
References: <CAErODj8unEb3uuO8mLN6mJV83wx2i-dtkZpDvbV_=Faw=9eotw@mail.gmail.com>
Message-ID: <loom.20160418T034949-682@post.gmane.org>




Paul Johnson <pauljohn32 at ...> writes:

> 
> Thanks for the help last week on GLMM estimators.  I'm gradually
> figuring this out.
> 



   Some *very* quick responses to a good question (if I wait this
will just get buried in the e-mail pile).

1. The general strategy you're describing (lognormal-Poisson error
via observation-level random effect) has been discussed on this list
before, I think: it's in the GLMM FAQ, the new version of which is at

https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.html

(search for "overdispersion")

2.  When you predict from the model with the observation-level
random effects, you should leave out those terms: use re.form=~0
or re.form=NULL if the observation-level RE is the only random
effect in your model, otherwise use an appropriate re.form that
includes only the higher-level groups.  That should make the predictions
make a lot more sense.

3. I'm not sure your convergence problems are actually that bad
(i.e. false positive); do the results from different optimizers
agree reasonably well?  (I would compare "bobyqa" and "nloptwrap")

4. It doesn't make sense to specify a family argument with glmer.nb

  cheers
    Ben Bolker

 [I'm deleting a huge amount below because I'm posting via gmane, which
doesn't like too much quoted stuff -- argh.)


> Today I'm writing notes comparing NB with Poisson models. Recall, NB
> is Poisson with a log(gamma) error variable added to the linear
> predictor.  I've often wondered how different that would be from
> adding a normal error, but did not have way to estimate.
> 
> In Rabe-Hesketh and Skrondal Multilevel / Longitudinal Modeling Using
> Stata, 3ed, they show a way to estimate a normally distributed random
> error inserted into a Poisson GLM in a one level model by "tricking"
> an estimator for a multilevel model (p. 707). I've checked, can do
> with xtpoisson or meglm in Stata 14).  Code is below.
> 
> I have some trouble with glmer trying to do same. Estimates are close
> to the "seems to work" answer from Stata, but I get glmer convergence
> warning and different numbers, grossly different predicted values. I
> understand glmer was not intended for this purpose, but wouldn't it be
> fun if we could make it work?
> 
> Here's the basic plan in Stata that RHS demonstrate. Declare an id
> variable with values 1, ..., N. This is non-replicated data, there
> will be just one observation per group.
> 
> generate id = _n
> xtset id
> xtpoisson y x1 x2 x3, normal
> 
> The Stata xtpoisson defaults the additive random error as log(gamma),
> but you can ask for normal. I've confirmed this runs, and it also
> works in the newer Stata meglm fitting function (meglm is only for
> normal errors).  Then you can compare side by side xtpoisson with
> log(gamma), xtpoisson with normal, and meglm with family(poisson) and
> normal mixed effects.
> 
> I fiddled around with glmer trying to do same, and the results are not
> completely different, but I hit convergence errors. Since I don't
> understand the fitting process, as I confessed last week, I'm a little
> blocked here.
> 
> My minimal running example R code:
> 
> ## Paul Johnson <pauljohn <at> ku.edu>
> ## 20160417
> 
> library(MASS)
> quine$id <- 1:NROW(quine)
> 
> library(foreign)
> write.dta(quine, file = "quine.dta12")
> ## Original model in MASS example(glm.nb)
> quine.pois1 <- glm(Days ~ Sex/(Age + Eth*Lrn), data = quine, family =
> poisson(log))
> summary(quine.pois1)
> ## Don't know how to write Stata formula to compare to that, so
> ## rewrite without "/"
> quine.pois2 <- glm(Days ~ Sex*Age + Sex*Eth*Lrn, family =
> poisson(link=log), data = quine)
> summary(quine.pois2)
> 
> quine.nb1 <- glm.nb(Days ~ Sex*Age + Sex*Eth*Lrn, data = quine)
> summary(quine.nb1)
> quine$predpois <- predict(quine.pois2, type = "link")
> quine$prednb <- predict(quine.nb1, type = "link")
> 
> plot(predpois ~ prednb, data = quine)
> with(quine, cor(predpois, prednb))
> 
> library(lme4)
> # Stata uses  nAGQ=14 equivalent:
> glmer1 <- glmer(Days ~ Sex*Age + Sex*Eth*Lrn + (1|id), data = quine,
>                 family = "poisson", nAGQ = 14)
> summary(glmer1)
> quine$predglmer1 <- predict(glmer1)
> plot(predglmer1 ~ prednb, data = quine)
> 
> glmer2 <- glmer.nb(Days ~ Sex*Age + Sex*Eth*Lrn + (1|id), data =
> quine, family = "poisson",
>                 control = glmerControl(optCtrl = list(maxfun = 10000)))
> 
> glmer3 <- glmer(Days ~ Sex*Age + Sex*Eth*Lrn + (1|id), data = quine,
> family = "poisson",
>                      control = glmerControl(optimizer = "Nelder_Mead",
> optCtrl = list(maxfun = 10000)))
> summary(glmer3)
> 
> ## end of MRE


From j.hadfield at ed.ac.uk  Mon Apr 18 08:42:32 2016
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 18 Apr 2016 07:42:32 +0100
Subject: [R-sig-ME] GLMM: tricking software to estimate normal error at
 lower level
In-Reply-To: <loom.20160418T034949-682@post.gmane.org>
References: <CAErODj8unEb3uuO8mLN6mJV83wx2i-dtkZpDvbV_=Faw=9eotw@mail.gmail.com>
	<loom.20160418T034949-682@post.gmane.org>
Message-ID: <571481D8.1060603@ed.ac.uk>

Hi,

Regarding 2) you also need to specify type="terms" in the glmer predict 
function in orer to make them comparable to the previous link function 
predictions.

Cheers,

Jarrod


On 18/04/2016 02:55, Ben Bolker wrote:
>
>
> Paul Johnson <pauljohn32 at ...> writes:
>
>> Thanks for the help last week on GLMM estimators.  I'm gradually
>> figuring this out.
>>
>
>
>     Some *very* quick responses to a good question (if I wait this
> will just get buried in the e-mail pile).
>
> 1. The general strategy you're describing (lognormal-Poisson error
> via observation-level random effect) has been discussed on this list
> before, I think: it's in the GLMM FAQ, the new version of which is at
>
> https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.html
>
> (search for "overdispersion")
>
> 2.  When you predict from the model with the observation-level
> random effects, you should leave out those terms: use re.form=~0
> or re.form=NULL if the observation-level RE is the only random
> effect in your model, otherwise use an appropriate re.form that
> includes only the higher-level groups.  That should make the predictions
> make a lot more sense.
>
> 3. I'm not sure your convergence problems are actually that bad
> (i.e. false positive); do the results from different optimizers
> agree reasonably well?  (I would compare "bobyqa" and "nloptwrap")
>
> 4. It doesn't make sense to specify a family argument with glmer.nb
>
>    cheers
>      Ben Bolker
>
>   [I'm deleting a huge amount below because I'm posting via gmane, which
> doesn't like too much quoted stuff -- argh.)
>
>
>> Today I'm writing notes comparing NB with Poisson models. Recall, NB
>> is Poisson with a log(gamma) error variable added to the linear
>> predictor.  I've often wondered how different that would be from
>> adding a normal error, but did not have way to estimate.
>>
>> In Rabe-Hesketh and Skrondal Multilevel / Longitudinal Modeling Using
>> Stata, 3ed, they show a way to estimate a normally distributed random
>> error inserted into a Poisson GLM in a one level model by "tricking"
>> an estimator for a multilevel model (p. 707). I've checked, can do
>> with xtpoisson or meglm in Stata 14).  Code is below.
>>
>> I have some trouble with glmer trying to do same. Estimates are close
>> to the "seems to work" answer from Stata, but I get glmer convergence
>> warning and different numbers, grossly different predicted values. I
>> understand glmer was not intended for this purpose, but wouldn't it be
>> fun if we could make it work?
>>
>> Here's the basic plan in Stata that RHS demonstrate. Declare an id
>> variable with values 1, ..., N. This is non-replicated data, there
>> will be just one observation per group.
>>
>> generate id = _n
>> xtset id
>> xtpoisson y x1 x2 x3, normal
>>
>> The Stata xtpoisson defaults the additive random error as log(gamma),
>> but you can ask for normal. I've confirmed this runs, and it also
>> works in the newer Stata meglm fitting function (meglm is only for
>> normal errors).  Then you can compare side by side xtpoisson with
>> log(gamma), xtpoisson with normal, and meglm with family(poisson) and
>> normal mixed effects.
>>
>> I fiddled around with glmer trying to do same, and the results are not
>> completely different, but I hit convergence errors. Since I don't
>> understand the fitting process, as I confessed last week, I'm a little
>> blocked here.
>>
>> My minimal running example R code:
>>
>> ## Paul Johnson <pauljohn <at> ku.edu>
>> ## 20160417
>>
>> library(MASS)
>> quine$id <- 1:NROW(quine)
>>
>> library(foreign)
>> write.dta(quine, file = "quine.dta12")
>> ## Original model in MASS example(glm.nb)
>> quine.pois1 <- glm(Days ~ Sex/(Age + Eth*Lrn), data = quine, family =
>> poisson(log))
>> summary(quine.pois1)
>> ## Don't know how to write Stata formula to compare to that, so
>> ## rewrite without "/"
>> quine.pois2 <- glm(Days ~ Sex*Age + Sex*Eth*Lrn, family =
>> poisson(link=log), data = quine)
>> summary(quine.pois2)
>>
>> quine.nb1 <- glm.nb(Days ~ Sex*Age + Sex*Eth*Lrn, data = quine)
>> summary(quine.nb1)
>> quine$predpois <- predict(quine.pois2, type = "link")
>> quine$prednb <- predict(quine.nb1, type = "link")
>>
>> plot(predpois ~ prednb, data = quine)
>> with(quine, cor(predpois, prednb))
>>
>> library(lme4)
>> # Stata uses  nAGQ=14 equivalent:
>> glmer1 <- glmer(Days ~ Sex*Age + Sex*Eth*Lrn + (1|id), data = quine,
>>                  family = "poisson", nAGQ = 14)
>> summary(glmer1)
>> quine$predglmer1 <- predict(glmer1)
>> plot(predglmer1 ~ prednb, data = quine)
>>
>> glmer2 <- glmer.nb(Days ~ Sex*Age + Sex*Eth*Lrn + (1|id), data =
>> quine, family = "poisson",
>>                  control = glmerControl(optCtrl = list(maxfun = 10000)))
>>
>> glmer3 <- glmer(Days ~ Sex*Age + Sex*Eth*Lrn + (1|id), data = quine,
>> family = "poisson",
>>                       control = glmerControl(optimizer = "Nelder_Mead",
>> optCtrl = list(maxfun = 10000)))
>> summary(glmer3)
>>
>> ## end of MRE
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From Olga.Viedma at uclm.es  Mon Apr 18 21:20:57 2016
From: Olga.Viedma at uclm.es (MARIA OLGA VIEDMA SILLERO)
Date: Mon, 18 Apr 2016 19:20:57 +0000
Subject: [R-sig-ME] ZINB multi-level model using MCMCglmm
Message-ID: <AMXPR01MB022F035D6187DC197967087EC6B0@AMXPR01MB022.eurprd01.prod.exchangelabs.com>

Hi,

I am Olga Viedma. I am running a Zero-inflated negative binomial (ZINB) multi-level model using MCMCglmm package. I have a doubt. Can I use the "Liab" outputs as fitted data, instead of the predicted values from "predict"? The liab outputs fit very well with the observed data, whereas the predicted values are so bad.

Thanks in advance,

Olga Viedma

D?. Olga Viedma Sillero
Profesora Ordenaci?n del Territorio
Facultad de Ciencias del Medio Ambiente y Bioqu?mica
Universidad de Castilla-La Mancha
Avd/ Carlos III, s/n. 45071 Toledo
Tel: 925 268800 (ext. 5780)
Email: olga.viedma at uclm.es
http://blog.uclm.es/grupofuego


	[[alternative HTML version deleted]]


From wzhmelly at gmail.com  Tue Apr 19 17:48:54 2016
From: wzhmelly at gmail.com (Zhaohong)
Date: Tue, 19 Apr 2016 11:48:54 -0400
Subject: [R-sig-ME] Why does the log-likelihood ratio test need a larger
	maxfun?
Message-ID: <CAHpascdPKy=FNWw42JHKu4GT5Oe+T=9qPUwEdtCUnwHiXJQ85Q@mail.gmail.com>

Dear All,

I am running a log-likelihood ratio test on two mixed models (differing
only in one variable) to test the significance of that variable. The two
mixed models (I set the maxfun=500000 for both) are able to converge with
no warnings, but the anova(model1, model2) gives warnings as follows:
       Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
..1    92 1450.7 2029.6 -633.33   1266.7
object 93 1452.5 2037.7 -633.22   1266.5 0.2098      1     0.6469
Warning messages:
1: In commonArgs(par, fn, control, environment()) :
  maxfun < 10 * length(par)^2 is not recommended.
2: In optwrap(optimizer, devfun, x at theta, lower = x at lower, calc.derivs =
TRUE) :
  convergence code 1 from bobyqa: bobyqa -- maximum number of function
evaluations exceeded
3: In commonArgs(par, fn, control, environment()) :
  maxfun < 10 * length(par)^2 is not recommended.
4: In optwrap(optimizer, devfun, x at theta, lower = x at lower, calc.derivs =
TRUE) :
  convergence code 1 from bobyqa: bobyqa -- maximum number of function
evaluations exceeded

The Pr(>Chisq) given from this test is 0.6469, but the Pr(>|t|) from the
lmerTest is 0.00160 ** , which seems more likely the case, because the
t-value from the lmer model summary is 3.445, with a total Number of obs:
3996.

So I thought maybe I need to increase the maxfun for the anova() test. I
rerun the test with the command anova(model1,
model2, ,control=lmerControl(optCtrl=list(maxfun=5000000))), and got the
same results:
       Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
..1    92 1450.7 2029.6 -633.33   1266.7
object 93 1452.5 2037.7 -633.22   1266.5 0.2098      1     0.6469
Warning messages:
1: In commonArgs(par, fn, control, environment()) :
  maxfun < 10 * length(par)^2 is not recommended.
2: In optwrap(optimizer, devfun, x at theta, lower = x at lower, calc.derivs =
TRUE) :
  convergence code 1 from bobyqa: bobyqa -- maximum number of function
evaluations exceeded
3: In commonArgs(par, fn, control, environment()) :
  maxfun < 10 * length(par)^2 is not recommended.
4: In optwrap(optimizer, devfun, x at theta, lower = x at lower, calc.derivs =
TRUE) :
  convergence code 1 from bobyqa: bobyqa -- maximum number of function
evaluations exceeded

I am wondering what I should do in this situation then?

Thanks a lot!

	[[alternative HTML version deleted]]


From clara.hildegard.ruecker at uni-jena.de  Tue Apr 19 10:20:37 2016
From: clara.hildegard.ruecker at uni-jena.de (Clara Neudecker)
Date: Tue, 19 Apr 2016 10:20:37 +0200
Subject: [R-sig-ME] LRT significant but new variable's beta not
Message-ID: <1461054037.1393.26.camel@uni-jena.de>

Dear all,

I'm looking for some hints on how to interprete my results. I have a
logistic mixed effects model in which I include a single new variable.
Comparing the old and new model with a likelihood ratio test yields a
significant difference (p < .001), but when I look at the new variable's
beta it's not significant at all.

How do I interprete this? After thinking and googling I have only one
suspicion left: Is it possible that including the new variable makes the
other variables more informative because there is some kind of supressor
effect in the data? Or is there another explanation?

(The phenomenon cannot be a coincidence; the same happens with other
variables as well.)

I attach some output in case it helps.

Best regards and thanks in advance,
Clara Neudecker 



My model without the new variable:

> summary(fm501)
Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) ['glmerMod']
 Family: binomial  ( logit )
Formula: umzug50000 ~ 1 + gebjahr_c + sex + (1 | zp12401) + (1 | ror96)
   Data: master_5

     AIC      BIC   logLik deviance df.resid 
  1077.9   1110.7   -534.0   1067.9     5167 

Scaled residuals: 
   Min     1Q Median     3Q    Max 
-0.547 -0.169 -0.102 -0.065 35.188 

Random effects:
 Groups  Name        Variance Std.Dev.
 ror96   (Intercept) 0.23757  0.4874  
 zp12401 (Intercept) 0.01509  0.1229  
Number of obs: 5172, groups:  ror96, 96; zp12401, 7

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)    
(Intercept) -4.433991   0.001499 -2957.3   <2e-16 ***
gebjahr_c    0.075061   0.001449    51.8   <2e-16 ***
sex.L        0.113758   0.001498    75.9   <2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
          (Intr) gbjhr_
gebjahr_c -0.001       
sex.L      0.000  0.000




With the new variable pol_fit_ror:

> summary(fm510)
Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) ['glmerMod']
 Family: binomial  ( logit )
Formula: umzug50000 ~ 1 + gebjahr_c + sex + pol_fit_ror + (1 | zp12401)
+      (1 | ror96)
   Data: master_5

     AIC      BIC   logLik deviance df.resid 
  1027.6   1066.5   -507.8   1015.6     4857 

Scaled residuals: 
   Min     1Q Median     3Q    Max 
-0.564 -0.171 -0.104 -0.066 33.626 

Random effects:
 Groups  Name        Variance  Std.Dev.
 ror96   (Intercept) 0.2125987 0.46108 
 zp12401 (Intercept) 0.0008857 0.02976 
Number of obs: 4863, groups:  ror96, 88; zp12401, 7

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)    
(Intercept) -4.086460   0.351692 -11.619   <2e-16 ***
gebjahr_c    0.074675   0.006972  10.711   <2e-16 ***
sex.L        0.158924   0.132901   1.196    0.232    
pol_fit_ror -0.256504   0.288639  -0.889    0.374    
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
            (Intr) gbjhr_ sex.L 
gebjahr_c   -0.293              
sex.L        0.084 -0.152       
pol_fit_ror -0.872 -0.030 -0.010

LRT of the two models:

> anova(fm501, fm510)
Data: master_5
Models:
fm501: umzug50000 ~ 1 + gebjahr_c + sex + (1 | zp12401) + (1 | ror96)
fm510: umzug50000 ~ 1 + gebjahr_c + sex + pol_fit_ror + (1 | zp12401) + 
fm510:     (1 | ror96)
      Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)    
fm501  5 1077.9 1110.7 -533.96   1067.9                             
fm510  6 1027.5 1066.5 -507.78   1015.5 52.362      1  4.615e-13 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


From abfine at gmail.com  Tue Apr 19 20:29:42 2016
From: abfine at gmail.com (Alex Fine)
Date: Tue, 19 Apr 2016 14:29:42 -0400
Subject: [R-sig-ME] LRT significant but new variable's beta not
In-Reply-To: <1461054037.1393.26.camel@uni-jena.de>
References: <1461054037.1393.26.camel@uni-jena.de>
Message-ID: <CAJ6ui+PJqU-LJMTHF0jo2U7kv2Zi_4z7AFM6q1EAfRJK+bY6_g@mail.gmail.com>

The LRT is robust to multicollinearity but the coefficient-based test is
not, so that could be it (collinearity involving the new predictor could be
inflating the standard error on the coefficient).

On Tue, Apr 19, 2016 at 4:20 AM, Clara Neudecker <
clara.hildegard.ruecker at uni-jena.de> wrote:

> Dear all,
>
> I'm looking for some hints on how to interprete my results. I have a
> logistic mixed effects model in which I include a single new variable.
> Comparing the old and new model with a likelihood ratio test yields a
> significant difference (p < .001), but when I look at the new variable's
> beta it's not significant at all.
>
> How do I interprete this? After thinking and googling I have only one
> suspicion left: Is it possible that including the new variable makes the
> other variables more informative because there is some kind of supressor
> effect in the data? Or is there another explanation?
>
> (The phenomenon cannot be a coincidence; the same happens with other
> variables as well.)
>
> I attach some output in case it helps.
>
> Best regards and thanks in advance,
> Clara Neudecker
>
>
>
> My model without the new variable:
>
> > summary(fm501)
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
>  Family: binomial  ( logit )
> Formula: umzug50000 ~ 1 + gebjahr_c + sex + (1 | zp12401) + (1 | ror96)
>    Data: master_5
>
>      AIC      BIC   logLik deviance df.resid
>   1077.9   1110.7   -534.0   1067.9     5167
>
> Scaled residuals:
>    Min     1Q Median     3Q    Max
> -0.547 -0.169 -0.102 -0.065 35.188
>
> Random effects:
>  Groups  Name        Variance Std.Dev.
>  ror96   (Intercept) 0.23757  0.4874
>  zp12401 (Intercept) 0.01509  0.1229
> Number of obs: 5172, groups:  ror96, 96; zp12401, 7
>
> Fixed effects:
>              Estimate Std. Error z value Pr(>|z|)
> (Intercept) -4.433991   0.001499 -2957.3   <2e-16 ***
> gebjahr_c    0.075061   0.001449    51.8   <2e-16 ***
> sex.L        0.113758   0.001498    75.9   <2e-16 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>           (Intr) gbjhr_
> gebjahr_c -0.001
> sex.L      0.000  0.000
>
>
>
>
> With the new variable pol_fit_ror:
>
> > summary(fm510)
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
>  Family: binomial  ( logit )
> Formula: umzug50000 ~ 1 + gebjahr_c + sex + pol_fit_ror + (1 | zp12401)
> +      (1 | ror96)
>    Data: master_5
>
>      AIC      BIC   logLik deviance df.resid
>   1027.6   1066.5   -507.8   1015.6     4857
>
> Scaled residuals:
>    Min     1Q Median     3Q    Max
> -0.564 -0.171 -0.104 -0.066 33.626
>
> Random effects:
>  Groups  Name        Variance  Std.Dev.
>  ror96   (Intercept) 0.2125987 0.46108
>  zp12401 (Intercept) 0.0008857 0.02976
> Number of obs: 4863, groups:  ror96, 88; zp12401, 7
>
> Fixed effects:
>              Estimate Std. Error z value Pr(>|z|)
> (Intercept) -4.086460   0.351692 -11.619   <2e-16 ***
> gebjahr_c    0.074675   0.006972  10.711   <2e-16 ***
> sex.L        0.158924   0.132901   1.196    0.232
> pol_fit_ror -0.256504   0.288639  -0.889    0.374
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>             (Intr) gbjhr_ sex.L
> gebjahr_c   -0.293
> sex.L        0.084 -0.152
> pol_fit_ror -0.872 -0.030 -0.010
>
> LRT of the two models:
>
> > anova(fm501, fm510)
> Data: master_5
> Models:
> fm501: umzug50000 ~ 1 + gebjahr_c + sex + (1 | zp12401) + (1 | ror96)
> fm510: umzug50000 ~ 1 + gebjahr_c + sex + pol_fit_ror + (1 | zp12401) +
> fm510:     (1 | ror96)
>       Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
> fm501  5 1077.9 1110.7 -533.96   1067.9
> fm510  6 1027.5 1066.5 -507.78   1015.5 52.362      1  4.615e-13 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models




-- 
Alex Fine
Ph. (336) 302-3251
web:  http://internal.psychology.illinois.edu/~abfine/
<http://internal.psychology.illinois.edu/~abfine/AlexFineHome.html>

	[[alternative HTML version deleted]]


From Paul.Thompson at sanfordhealth.org  Tue Apr 19 20:32:18 2016
From: Paul.Thompson at sanfordhealth.org (Thompson,Paul)
Date: Tue, 19 Apr 2016 18:32:18 +0000
Subject: [R-sig-ME] LRT significant but new variable's beta not
In-Reply-To: <1461054037.1393.26.camel@uni-jena.de>
References: <1461054037.1393.26.camel@uni-jena.de>
Message-ID: <9B75E7CF385CB94EAD6587DD96AC2D9701D16F9E3B@SFSMCEXMBX3.sanfordhealth.org>

The first model has 5172 obs
The second model has 4863 obs

That is a difference of 309 obs. Clearly the new variable has a bunch of missing values. I would pay attention to that. You are fitting models in different groups, although they do overlap.

-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Clara Neudecker
Sent: Tuesday, April 19, 2016 3:21 AM
To: R-sig-mixed-models at r-project.org
Subject: [R-sig-ME] LRT significant but new variable's beta not

Dear all,

I'm looking for some hints on how to interprete my results. I have a logistic mixed effects model in which I include a single new variable.
Comparing the old and new model with a likelihood ratio test yields a significant difference (p < .001), but when I look at the new variable's beta it's not significant at all.

How do I interprete this? After thinking and googling I have only one suspicion left: Is it possible that including the new variable makes the other variables more informative because there is some kind of supressor effect in the data? Or is there another explanation?

(The phenomenon cannot be a coincidence; the same happens with other variables as well.)

I attach some output in case it helps.

Best regards and thanks in advance,
Clara Neudecker 



My model without the new variable:

> summary(fm501)
Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) ['glmerMod']
 Family: binomial  ( logit )
Formula: umzug50000 ~ 1 + gebjahr_c + sex + (1 | zp12401) + (1 | ror96)
   Data: master_5

     AIC      BIC   logLik deviance df.resid 
  1077.9   1110.7   -534.0   1067.9     5167 

Scaled residuals: 
   Min     1Q Median     3Q    Max 
-0.547 -0.169 -0.102 -0.065 35.188 

Random effects:
 Groups  Name        Variance Std.Dev.
 ror96   (Intercept) 0.23757  0.4874  
 zp12401 (Intercept) 0.01509  0.1229
Number of obs: 5172, groups:  ror96, 96; zp12401, 7

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)    
(Intercept) -4.433991   0.001499 -2957.3   <2e-16 ***
gebjahr_c    0.075061   0.001449    51.8   <2e-16 ***
sex.L        0.113758   0.001498    75.9   <2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
          (Intr) gbjhr_
gebjahr_c -0.001       
sex.L      0.000  0.000




With the new variable pol_fit_ror:

> summary(fm510)
Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) ['glmerMod']
 Family: binomial  ( logit )
Formula: umzug50000 ~ 1 + gebjahr_c + sex + pol_fit_ror + (1 | zp12401)
+      (1 | ror96)
   Data: master_5

     AIC      BIC   logLik deviance df.resid 
  1027.6   1066.5   -507.8   1015.6     4857 

Scaled residuals: 
   Min     1Q Median     3Q    Max 
-0.564 -0.171 -0.104 -0.066 33.626 

Random effects:
 Groups  Name        Variance  Std.Dev.
 ror96   (Intercept) 0.2125987 0.46108 
 zp12401 (Intercept) 0.0008857 0.02976
Number of obs: 4863, groups:  ror96, 88; zp12401, 7

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)    
(Intercept) -4.086460   0.351692 -11.619   <2e-16 ***
gebjahr_c    0.074675   0.006972  10.711   <2e-16 ***
sex.L        0.158924   0.132901   1.196    0.232    
pol_fit_ror -0.256504   0.288639  -0.889    0.374    
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
            (Intr) gbjhr_ sex.L 
gebjahr_c   -0.293              
sex.L        0.084 -0.152       
pol_fit_ror -0.872 -0.030 -0.010

LRT of the two models:

> anova(fm501, fm510)
Data: master_5
Models:
fm501: umzug50000 ~ 1 + gebjahr_c + sex + (1 | zp12401) + (1 | ror96)
fm510: umzug50000 ~ 1 + gebjahr_c + sex + pol_fit_ror + (1 | zp12401) + 
fm510:     (1 | ror96)
      Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)    
fm501  5 1077.9 1110.7 -533.96   1067.9                             
fm510  6 1027.5 1066.5 -507.78   1015.5 52.362      1  4.615e-13 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
-----------------------------------------------------------------------
Confidentiality Notice: This e-mail message, including any attachments,
is for the sole use of the intended recipient(s) and may contain
privileged and confidential information.  Any unauthorized review, use,
disclosure or distribution is prohibited.  If you are not the intended
recipient, please contact the sender by reply e-mail and destroy
all copies of the original message.

From bbolker at gmail.com  Tue Apr 19 20:35:25 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 19 Apr 2016 14:35:25 -0400
Subject: [R-sig-ME] LRT significant but new variable's beta not
In-Reply-To: <CAJ6ui+PJqU-LJMTHF0jo2U7kv2Zi_4z7AFM6q1EAfRJK+bY6_g@mail.gmail.com>
References: <1461054037.1393.26.camel@uni-jena.de>
	<CAJ6ui+PJqU-LJMTHF0jo2U7kv2Zi_4z7AFM6q1EAfRJK+bY6_g@mail.gmail.com>
Message-ID: <CABghstQwZGkzafYjpP_8RiWj=bHG5__-sz-+XX8httrj3AdZZQ@mail.gmail.com>

I agree with Alex.  I do find these results *mildly* surprising, but note that:

- estimated coefficient of gebjahr_c doesn't change much, but Z-score
goes from 52 (model 1) to 11 (model 2)
- fixed effects in first model are nearly perfectly independent
- fairly strong correlation (-0.88) between the new variable and gebjahr_c

  Note that these kinds of questions are not specific to mixed models,
but are general to essentially all linear/generalized models as soon
as the experimental/observation design no longer provides
orthogonal/independent estimates of the coefficients.

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)
(Intercept) -4.433991   0.001499 -2957.3   <2e-16 ***
gebjahr_c    0.075061   0.001449    51.8   <2e-16 ***
sex.L        0.113758   0.001498    75.9   <2e-16 ***
---
Correlation of Fixed Effects:
          (Intr) gbjhr_
gebjahr_c -0.001
sex.L      0.000  0.000

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)
(Intercept) -4.086460   0.351692 -11.619   <2e-16 ***
gebjahr_c    0.074675   0.006972  10.711   <2e-16 ***
sex.L        0.158924   0.132901   1.196    0.232
pol_fit_ror -0.256504   0.288639  -0.889    0.374
--
Correlation of Fixed Effects:
            (Intr) gbjhr_ sex.L
gebjahr_c   -0.293
sex.L        0.084 -0.152
pol_fit_ror -0.872 -0.030 -0.010

On Tue, Apr 19, 2016 at 2:29 PM, Alex Fine <abfine at gmail.com> wrote:
> The LRT is robust to multicollinearity but the coefficient-based test is
> not, so that could be it (collinearity involving the new predictor could be
> inflating the standard error on the coefficient).
>
> On Tue, Apr 19, 2016 at 4:20 AM, Clara Neudecker <
> clara.hildegard.ruecker at uni-jena.de> wrote:
>
>> Dear all,
>>
>> I'm looking for some hints on how to interprete my results. I have a
>> logistic mixed effects model in which I include a single new variable.
>> Comparing the old and new model with a likelihood ratio test yields a
>> significant difference (p < .001), but when I look at the new variable's
>> beta it's not significant at all.
>>
>> How do I interprete this? After thinking and googling I have only one
>> suspicion left: Is it possible that including the new variable makes the
>> other variables more informative because there is some kind of supressor
>> effect in the data? Or is there another explanation?
>>
>> (The phenomenon cannot be a coincidence; the same happens with other
>> variables as well.)
>>
>> I attach some output in case it helps.
>>
>> Best regards and thanks in advance,
>> Clara Neudecker
>>
>>
>>
>> My model without the new variable:
>>
>> > summary(fm501)
>> Generalized linear mixed model fit by maximum likelihood (Laplace
>> Approximation) ['glmerMod']
>>  Family: binomial  ( logit )
>> Formula: umzug50000 ~ 1 + gebjahr_c + sex + (1 | zp12401) + (1 | ror96)
>>    Data: master_5
>>
>>      AIC      BIC   logLik deviance df.resid
>>   1077.9   1110.7   -534.0   1067.9     5167
>>
>> Scaled residuals:
>>    Min     1Q Median     3Q    Max
>> -0.547 -0.169 -0.102 -0.065 35.188
>>
>> Random effects:
>>  Groups  Name        Variance Std.Dev.
>>  ror96   (Intercept) 0.23757  0.4874
>>  zp12401 (Intercept) 0.01509  0.1229
>> Number of obs: 5172, groups:  ror96, 96; zp12401, 7
>>
>> Fixed effects:
>>              Estimate Std. Error z value Pr(>|z|)
>> (Intercept) -4.433991   0.001499 -2957.3   <2e-16 ***
>> gebjahr_c    0.075061   0.001449    51.8   <2e-16 ***
>> sex.L        0.113758   0.001498    75.9   <2e-16 ***
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> Correlation of Fixed Effects:
>>           (Intr) gbjhr_
>> gebjahr_c -0.001
>> sex.L      0.000  0.000
>>
>>
>>
>>
>> With the new variable pol_fit_ror:
>>
>> > summary(fm510)
>> Generalized linear mixed model fit by maximum likelihood (Laplace
>> Approximation) ['glmerMod']
>>  Family: binomial  ( logit )
>> Formula: umzug50000 ~ 1 + gebjahr_c + sex + pol_fit_ror + (1 | zp12401)
>> +      (1 | ror96)
>>    Data: master_5
>>
>>      AIC      BIC   logLik deviance df.resid
>>   1027.6   1066.5   -507.8   1015.6     4857
>>
>> Scaled residuals:
>>    Min     1Q Median     3Q    Max
>> -0.564 -0.171 -0.104 -0.066 33.626
>>
>> Random effects:
>>  Groups  Name        Variance  Std.Dev.
>>  ror96   (Intercept) 0.2125987 0.46108
>>  zp12401 (Intercept) 0.0008857 0.02976
>> Number of obs: 4863, groups:  ror96, 88; zp12401, 7
>>
>> Fixed effects:
>>              Estimate Std. Error z value Pr(>|z|)
>> (Intercept) -4.086460   0.351692 -11.619   <2e-16 ***
>> gebjahr_c    0.074675   0.006972  10.711   <2e-16 ***
>> sex.L        0.158924   0.132901   1.196    0.232
>> pol_fit_ror -0.256504   0.288639  -0.889    0.374
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> Correlation of Fixed Effects:
>>             (Intr) gbjhr_ sex.L
>> gebjahr_c   -0.293
>> sex.L        0.084 -0.152
>> pol_fit_ror -0.872 -0.030 -0.010
>>
>> LRT of the two models:
>>
>> > anova(fm501, fm510)
>> Data: master_5
>> Models:
>> fm501: umzug50000 ~ 1 + gebjahr_c + sex + (1 | zp12401) + (1 | ror96)
>> fm510: umzug50000 ~ 1 + gebjahr_c + sex + pol_fit_ror + (1 | zp12401) +
>> fm510:     (1 | ror96)
>>       Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
>> fm501  5 1077.9 1110.7 -533.96   1067.9
>> fm510  6 1027.5 1066.5 -507.78   1015.5 52.362      1  4.615e-13 ***
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
>
> --
> Alex Fine
> Ph. (336) 302-3251
> web:  http://internal.psychology.illinois.edu/~abfine/
> <http://internal.psychology.illinois.edu/~abfine/AlexFineHome.html>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Tue Apr 19 20:37:41 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 19 Apr 2016 14:37:41 -0400
Subject: [R-sig-ME] LRT significant but new variable's beta not
In-Reply-To: <9B75E7CF385CB94EAD6587DD96AC2D9701D16F9E3B@SFSMCEXMBX3.sanfordhealth.org>
References: <1461054037.1393.26.camel@uni-jena.de>
	<9B75E7CF385CB94EAD6587DD96AC2D9701D16F9E3B@SFSMCEXMBX3.sanfordhealth.org>
Message-ID: <CABghstQTuaSL=qY0eA=U6hH2goojki45X5nBYURk+iXcxbfBpw@mail.gmail.com>

  Good catch!  That's probably it.  I'm a little bit confused that
this isn't caught by lmer, as in the following example:

> library(lme4)
> ss <- subset(sleepstudy,Days<8)
> fm1 <- lmer(Reaction~Days+(1|Subject),data=sleepstudy)
> fm2 <- lmer(Reaction~(1|Subject),data=ss)
> anova(fm1,fm2)
Error in anova.merMod(fm1, fm2) :
  models were not all fitted to the same size of dataset

On Tue, Apr 19, 2016 at 2:32 PM, Thompson,Paul
<Paul.Thompson at sanfordhealth.org> wrote:
> The first model has 5172 obs
> The second model has 4863 obs
>
> That is a difference of 309 obs. Clearly the new variable has a bunch of missing values. I would pay attention to that. You are fitting models in different groups, although they do overlap.
>
> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Clara Neudecker
> Sent: Tuesday, April 19, 2016 3:21 AM
> To: R-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] LRT significant but new variable's beta not
>
> Dear all,
>
> I'm looking for some hints on how to interprete my results. I have a logistic mixed effects model in which I include a single new variable.
> Comparing the old and new model with a likelihood ratio test yields a significant difference (p < .001), but when I look at the new variable's beta it's not significant at all.
>
> How do I interprete this? After thinking and googling I have only one suspicion left: Is it possible that including the new variable makes the other variables more informative because there is some kind of supressor effect in the data? Or is there another explanation?
>
> (The phenomenon cannot be a coincidence; the same happens with other variables as well.)
>
> I attach some output in case it helps.
>
> Best regards and thanks in advance,
> Clara Neudecker
>
>
>
> My model without the new variable:
>
>> summary(fm501)
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
>  Family: binomial  ( logit )
> Formula: umzug50000 ~ 1 + gebjahr_c + sex + (1 | zp12401) + (1 | ror96)
>    Data: master_5
>
>      AIC      BIC   logLik deviance df.resid
>   1077.9   1110.7   -534.0   1067.9     5167
>
> Scaled residuals:
>    Min     1Q Median     3Q    Max
> -0.547 -0.169 -0.102 -0.065 35.188
>
> Random effects:
>  Groups  Name        Variance Std.Dev.
>  ror96   (Intercept) 0.23757  0.4874
>  zp12401 (Intercept) 0.01509  0.1229
> Number of obs: 5172, groups:  ror96, 96; zp12401, 7
>
> Fixed effects:
>              Estimate Std. Error z value Pr(>|z|)
> (Intercept) -4.433991   0.001499 -2957.3   <2e-16 ***
> gebjahr_c    0.075061   0.001449    51.8   <2e-16 ***
> sex.L        0.113758   0.001498    75.9   <2e-16 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>           (Intr) gbjhr_
> gebjahr_c -0.001
> sex.L      0.000  0.000
>
>
>
>
> With the new variable pol_fit_ror:
>
>> summary(fm510)
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
>  Family: binomial  ( logit )
> Formula: umzug50000 ~ 1 + gebjahr_c + sex + pol_fit_ror + (1 | zp12401)
> +      (1 | ror96)
>    Data: master_5
>
>      AIC      BIC   logLik deviance df.resid
>   1027.6   1066.5   -507.8   1015.6     4857
>
> Scaled residuals:
>    Min     1Q Median     3Q    Max
> -0.564 -0.171 -0.104 -0.066 33.626
>
> Random effects:
>  Groups  Name        Variance  Std.Dev.
>  ror96   (Intercept) 0.2125987 0.46108
>  zp12401 (Intercept) 0.0008857 0.02976
> Number of obs: 4863, groups:  ror96, 88; zp12401, 7
>
> Fixed effects:
>              Estimate Std. Error z value Pr(>|z|)
> (Intercept) -4.086460   0.351692 -11.619   <2e-16 ***
> gebjahr_c    0.074675   0.006972  10.711   <2e-16 ***
> sex.L        0.158924   0.132901   1.196    0.232
> pol_fit_ror -0.256504   0.288639  -0.889    0.374
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>             (Intr) gbjhr_ sex.L
> gebjahr_c   -0.293
> sex.L        0.084 -0.152
> pol_fit_ror -0.872 -0.030 -0.010
>
> LRT of the two models:
>
>> anova(fm501, fm510)
> Data: master_5
> Models:
> fm501: umzug50000 ~ 1 + gebjahr_c + sex + (1 | zp12401) + (1 | ror96)
> fm510: umzug50000 ~ 1 + gebjahr_c + sex + pol_fit_ror + (1 | zp12401) +
> fm510:     (1 | ror96)
>       Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
> fm501  5 1077.9 1110.7 -533.96   1067.9
> fm510  6 1027.5 1066.5 -507.78   1015.5 52.362      1  4.615e-13 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> -----------------------------------------------------------------------
> Confidentiality Notice: This e-mail message, including any attachments,
> is for the sole use of the intended recipient(s) and may contain
> privileged and confidential information.  Any unauthorized review, use,
> disclosure or distribution is prohibited.  If you are not the intended
> recipient, please contact the sender by reply e-mail and destroy
> all copies of the original message.
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From singmann at psychologie.uzh.ch  Tue Apr 19 23:08:39 2016
From: singmann at psychologie.uzh.ch (Henrik Singmann)
Date: Tue, 19 Apr 2016 23:08:39 +0200
Subject: [R-sig-ME] Why does the log-likelihood ratio test need a larger
	maxfun?
In-Reply-To: <CAHpascdPKy=FNWw42JHKu4GT5Oe+T=9qPUwEdtCUnwHiXJQ85Q@mail.gmail.com>
References: <CAHpascdPKy=FNWw42JHKu4GT5Oe+T=9qPUwEdtCUnwHiXJQ85Q@mail.gmail.com>
Message-ID: <57169E57.4030308@psychologie.uzh.ch>

Hi Zhaohong,

The following warning indicates that your results cannot be trusted:

 > convergence code 1 from bobyqa: bobyqa -- maximum number of function
 > evaluations exceeded

This means that the results are most likely not the MLEs. You should 
rerun the model with higher values of maxfun. For example:

control = g/lmerControl(optCtrl = list(maxfun = 1e6))

Why you do not see the warning when fitting seems weird.

Hope that helps,
Henrik


Am 19.04.2016 um 17:48 schrieb Zhaohong:
> Dear All,
>
> I am running a log-likelihood ratio test on two mixed models (differing
> only in one variable) to test the significance of that variable. The two
> mixed models (I set the maxfun=500000 for both) are able to converge with
> no warnings, but the anova(model1, model2) gives warnings as follows:
>         Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
> ..1    92 1450.7 2029.6 -633.33   1266.7
> object 93 1452.5 2037.7 -633.22   1266.5 0.2098      1     0.6469
> Warning messages:
> 1: In commonArgs(par, fn, control, environment()) :
>    maxfun < 10 * length(par)^2 is not recommended.
> 2: In optwrap(optimizer, devfun, x at theta, lower = x at lower, calc.derivs =
> TRUE) :
>    convergence code 1 from bobyqa: bobyqa -- maximum number of function
> evaluations exceeded
> 3: In commonArgs(par, fn, control, environment()) :
>    maxfun < 10 * length(par)^2 is not recommended.
> 4: In optwrap(optimizer, devfun, x at theta, lower = x at lower, calc.derivs =
> TRUE) :
>    convergence code 1 from bobyqa: bobyqa -- maximum number of function
> evaluations exceeded
>
> The Pr(>Chisq) given from this test is 0.6469, but the Pr(>|t|) from the
> lmerTest is 0.00160 ** , which seems more likely the case, because the
> t-value from the lmer model summary is 3.445, with a total Number of obs:
> 3996.
>
> So I thought maybe I need to increase the maxfun for the anova() test. I
> rerun the test with the command anova(model1,
> model2, ,control=lmerControl(optCtrl=list(maxfun=5000000))), and got the
> same results:
>         Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
> ..1    92 1450.7 2029.6 -633.33   1266.7
> object 93 1452.5 2037.7 -633.22   1266.5 0.2098      1     0.6469
> Warning messages:
> 1: In commonArgs(par, fn, control, environment()) :
>    maxfun < 10 * length(par)^2 is not recommended.
> 2: In optwrap(optimizer, devfun, x at theta, lower = x at lower, calc.derivs =
> TRUE) :
>    convergence code 1 from bobyqa: bobyqa -- maximum number of function
> evaluations exceeded
> 3: In commonArgs(par, fn, control, environment()) :
>    maxfun < 10 * length(par)^2 is not recommended.
> 4: In optwrap(optimizer, devfun, x at theta, lower = x at lower, calc.derivs =
> TRUE) :
>    convergence code 1 from bobyqa: bobyqa -- maximum number of function
> evaluations exceeded
>
> I am wondering what I should do in this situation then?
>
> Thanks a lot!
>
> 	[[alternative HTML version deleted]]
>


From chirleu at gmail.com  Thu Apr 21 16:19:32 2016
From: chirleu at gmail.com (=?UTF-8?Q?David_Villegas_R=C3=ADos?=)
Date: Thu, 21 Apr 2016 16:19:32 +0200
Subject: [R-sig-ME] How can I know if I have enough data for a complex
	random slopes model?
Message-ID: <CALC46t8iJM5N=6ELV7ny-t-H5LYPxtUZFuVBY5SQeQ53ZX25Rg@mail.gmail.com>

Dear list,

I am investigating the effect of the interaction between two continuous
variables (A and B) on a behavioral trait. I have repeated measures from 64
individuals. The number of measures per individual varies a lot with a
minimum of 3 and a maximum of 68 (mean=36). That makes a total of 2300
records.

After some initial exploration and plotting of the data, I have realized
that the effect of A on my response variable varies a lot among
individuals, both in the intercept and the slope.

So I would like to fit a random slopes model to allow each individual to
have a different intercept and slope. My replicates have some temporal
autocorrelation that I want to model using corAR1 (in nlme). And finally,
it seems that using "weights" to model the variance (varExp(form=~A)) also
improves the model.

In summary there is a quite complex random structure + modeling of variance.

Question: How can I be confident that the results are robust and that I
have enough power in my data to fit such a model? Is there any rule of
thumb?

So far the model runs, although I haven't found a correlation structure
that removes all the temporal autocorrelation (tried corAR1 and several
corARMA options)

Thanks in advance,

David

	[[alternative HTML version deleted]]


From pharriso at uwaterloo.ca  Thu Apr 21 17:46:13 2016
From: pharriso at uwaterloo.ca (Philip Harrison)
Date: Thu, 21 Apr 2016 11:46:13 -0400
Subject: [R-sig-ME] How can I know if I have enough data for a complex
 random slopes model?
In-Reply-To: <CALC46t8iJM5N=6ELV7ny-t-H5LYPxtUZFuVBY5SQeQ53ZX25Rg@mail.gmail.com>
References: <CALC46t8iJM5N=6ELV7ny-t-H5LYPxtUZFuVBY5SQeQ53ZX25Rg@mail.gmail.com>
Message-ID: <20160421114613.16266wfezwh3oxc5@www.nexusmail.uwaterloo.ca>

Hi David,

I would suggest using a heirarchical random regression model following  
the Araya-Ajoy 2015 method:

Araya&#8208;Ajoy, Yimen G., Kimberley J. Mathot, and Niels J.  
Dingemanse. "An approach to estimate short&#8208;term, long&#8208;term  
and reaction norm repeatability." Methods in Ecology and Evolution  
6.12 (2015): 1462-1473.

By decomposing variance at various temporal scales (days, season,  
years for example) you will be able to capture the consistency (in  
slopes and intercepts) that occurs due to short term  between  
individual differences in experience and long term consistency, ie  
that which occurs likely as as a function of genetic or permenent  
environmental effects. That way you eliminate the need to fit a  
correlation structure, which may well be over-fitting. You probably  
cant fit a variance weighting structure using this method as it is  
based on lme4 not nlme, however if you transform your response that  
will likely have the same effect.

In terms of power, precision and bias, if you fit the heirachical  
model, you can use the power analysis package (MultiRR) , plug in your  
design and generate estimates of power etc. It works for unbalanced  
data too. You can also get a rough idea of power by looking at the  
plots based on various sample sizes provided within the manuscripts.

If you run a single level random regression, you can run power  
analyses based on your sample design, using power analysis packages  
associated with thew following papers:

Martin, Julien GA, et al. "Measuring individual differences in  
reaction norms in field and experimental studies: a power analysis of  
random regression models." Methods in Ecology and Evolution 2.4  
(2011): 362-374.

or alterantively:

van de Pol, M. (2012). Quantifying individual variation in reaction  
norms: how study design affects the accuracy, precision and power of  
random regression models. Methods in Ecology and Evolution, 3(2),  
268-280.

Cheers

Philip Harrison PhD
Post-Doc in Cooke and Power Labs
Department of Biology
University of Waterloo
200 University Avenue West
Waterloo, Ontario, Canada
N2L 3G1
Office 519-888-4567 x30166
Email:pharriso at uwaterloo.ca
https://www.researchgate.net/profile/Phil_Harrison4
http://www.fecpl.ca/people/philip-harrison/






Quoting David Villegas R?os <chirleu at gmail.com>:

> Dear list,
>
> I am investigating the effect of the interaction between two continuous
> variables (A and B) on a behavioral trait. I have repeated measures from 64
> individuals. The number of measures per individual varies a lot with a
> minimum of 3 and a maximum of 68 (mean=36). That makes a total of 2300
> records.
>
> After some initial exploration and plotting of the data, I have realized
> that the effect of A on my response variable varies a lot among
> individuals, both in the intercept and the slope.
>
> So I would like to fit a random slopes model to allow each individual to
> have a different intercept and slope. My replicates have some temporal
> autocorrelation that I want to model using corAR1 (in nlme). And finally,
> it seems that using "weights" to model the variance (varExp(form=~A)) also
> improves the model.
>
> In summary there is a quite complex random structure + modeling of variance.
>
> Question: How can I be confident that the results are robust and that I
> have enough power in my data to fit such a model? Is there any rule of
> thumb?
>
> So far the model runs, although I haven't found a correlation structure
> that removes all the temporal autocorrelation (tried corAR1 and several
> corARMA options)
>
> Thanks in advance,
>
> David
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



Philip Harrison PhD
Post-Doc in Cooke and Power Labs
Department of Biology
University of Waterloo
200 University Avenue West
Waterloo, Ontario, Canada
N2L 3G1
Office 519-888-4567 x30166
Email:pharriso at uwaterloo.ca
https://www.researchgate.net/profile/Phil_Harrison4
http://www.fecpl.ca/people/philip-harrison/


From firespot71 at gmail.com  Thu Apr 21 21:46:09 2016
From: firespot71 at gmail.com (Thomas Mang)
Date: Thu, 21 Apr 2016 21:46:09 +0200
Subject: [R-sig-ME] assessing GLMM fixed- and random-effects for their
 relative importances (dominance analysis, variation partitioning etc.)
Message-ID: <57192E01.50807@gmail.com>

Dear newsgroups,

I have fitted a Poisson-GLMM (species counts) using lme4. The model's 
fixed-effect predictors (about a dozen in total, possibly with selected 
interactions) can be logically split into 4 major measurement categories 
(e.g. biogeographic variables, climatic variables, etc.). The model has 
three "regular" random factors (spatial/measurement clustering groups), 
plus an additional observation-level random factor due to otherwise 
heavily pronounced Poisson overdispersion; sample size is fairly large 
(several hundreds).

What I would like to do now is, quite untechnically speaking (please 
also apologize if some points may appear a bit naive):
1) contrast the overall "role" of the fixed-effects vs. the 
random-effects on the outcome
2) for the fixed-effects, assess the"importance" of each group of predictors
3) for the random-effects, assess how each random factor shapes outcome 
variation
Note: none of the questions aims at significance testing; given the 
fitted model it's about quantifying (e.g. proportional values) in how 
far each major model component (i.e., each major measurement category of 
fixed-effects and the random factors) influences/explains outcomes. With 
respect to the observation-level random-effect, I am much inclined to 
treat it in the same manner as the three "regular" random factors, 
thereby representing the individual-level variation (as opposed to 
considering it a mere technical means for overdispersion handling and to 
be skipped from above assessments).

Now I am a bit stuck as to which methods are most suited for each 
assessment kind, and the availability of pre-built functions / libraries 
for calculations. What I have roughly come up with so far:
With respect to bullet 2), I suppose dominance analysis for GLMMs would 
be right thing to do. However, I haven't found an R package which could 
perform that for lme4 models. Alternatively, I could calculate AIC 
importance weights for models including/omitting each fixed-effects 
category, but this may be less direct.
With respect to bullet 3), I suppose variation partitioning is the right 
way, but again I haven't found a package for GLMMs. Maybe the easiest 
approach is simply relating the magnitudes of the fitted random-effect 
variances against each other and their sum, thus splitting the total 
random-effects variation (at the link scale) into the individual 
contributions.
With respect to bullet 1), great question. I could fit a model with and 
without fixed-effects, but I fail to see how I would subsequently have 
to relate these models to yield the desired statements. I could 
calculate an R2-measure (e.g. Nakagawa & Schielzeth 2013, A general and 
simple method for obtaining R2 from generalized linear mixed-effects 
models, Methods in Ecolocy and Evolution) and relate the marginal and 
conditional R2 (or, generally speaking, contrasting different sums of 
model terms for "explaining" variance), but this also appears fairly 
indirect, approximative at best.

Any pointers are much appreciated to make it "smell least hacked 
together", both with respect to the general statistical options on the 
market as well as specific packages/implementations for calculations. If 
results can be graphically presented (e.g. Venn's diagrams) that would 
also be great!
If required, I could also fit models using MCMCglmm or glmmADMB if that 
would resolve technical handicaps which could not be overcome by lme4 fits.

best regards and many thanks,
Thomas


From ravi.varadhan at jhu.edu  Thu Apr 21 23:19:42 2016
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Thu, 21 Apr 2016 21:19:42 +0000
Subject: [R-sig-ME] na.action in lmer()
Message-ID: <63bde12d7b5249f5ad0f8292c973a9bd@ESGEBEX10.win.ad.jhu.edu>

Hi,

I am fitting a model like this with random intercept and random slope using lme4::lmer.

lmer(y ~ time + (time|Patient), REML="FALSE", na.action=na.omit)

The `na.omit' option is the default. However, I would like to include patients with one or missing values in their time trajectory.  Which NA handling option would I use?

Thank you,
Ravi

Ravi Varadhan, Ph.D. (Biostatistics), Ph.D. (Environmental Engg)
Associate Professor,  Department of Oncology
Division of Biostatistics & Bionformatics
Sidney Kimmel Comprehensive Cancer Center
Johns Hopkins University
550 N. Broadway, Suite 1111-E
Baltimore, MD 21205
410-502-2619


	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu Apr 21 23:31:03 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 21 Apr 2016 17:31:03 -0400
Subject: [R-sig-ME] na.action in lmer()
In-Reply-To: <63bde12d7b5249f5ad0f8292c973a9bd@ESGEBEX10.win.ad.jhu.edu>
References: <63bde12d7b5249f5ad0f8292c973a9bd@ESGEBEX10.win.ad.jhu.edu>
Message-ID: <57194697.3060404@gmail.com>


  You shouldn't need to do anything special, since the data are written
out in a long format, e.g.

Patient  time   y
1           0   0.1
1           1   0.3
...
2           0   0.1
2           1   NA
2           2   0.3
...

  Unlike in the classic MANOVA setup where the responses from an
individual are all considered part of the same observation (and hence an
NA screws things up badly), this is just handled automatically/naturally
in the mixed-model context.

  The only difference between na.omit() and na.exclude() is whether NA
values are inserted into appropriate places in the downstream
residual/prediction calculations.  (g)lmer can't do anything with
observations containing NA values, but 'observation' means (in this
case) 'patient-time combination', not 'patient'.

  (Do you mean REML=FALSE ... ?)


On 16-04-21 05:19 PM, Ravi Varadhan wrote:
> Hi,
> 
> I am fitting a model like this with random intercept and random slope
> using lme4::lmer.
> 
> lmer(y ~ time + (time|Patient), REML="FALSE", na.action=na.omit)
> 
> The `na.omit' option is the default. However, I would like to include
> patients with one or missing values in their time trajectory.  Which
> NA handling option would I use?
> 
> Thank you, Ravi
> 
> Ravi Varadhan, Ph.D. (Biostatistics), Ph.D. (Environmental Engg) 
> Associate Professor,  Department of Oncology Division of
> Biostatistics & Bionformatics Sidney Kimmel Comprehensive Cancer
> Center Johns Hopkins University 550 N. Broadway, Suite 1111-E 
> Baltimore, MD 21205 410-502-2619
> 
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From matt.brain1 at gmail.com  Fri Apr 22 17:42:48 2016
From: matt.brain1 at gmail.com (Matthew Brain)
Date: Sat, 23 Apr 2016 01:42:48 +1000
Subject: [R-sig-ME] Mixed Effects Models to compare different testing sites
Message-ID: <A98D63A1-32A9-4FCE-A49E-AB7362064D89@gmail.com>

Hi,
I have an awkward correlation problem with an unbalanced nested repeated measures data set. Essentially we have 3 sampling sites on a flowing fluid stream: site A is at the source and sites B and C are sequentially downstream after additives and filters are applied. A significant process difference is additive A or B (which affects sites B and C). Hierarchical structure is group (source of fluid stream), batch of filter, processA or B. Sample of data can be found at http://www.irenabyss.com.au/testing/ddata.html. 

I am trying to answer four questions: 
1. What is the correlation and CI between measurements taken from Sample sites B and C 
2. Is the measurement variance significantly greater at sample sites B or C when compared to site A
3. Is there heteroskedasticity of measurements (from A,B or C) as values vary between low and high values

My main issue is with assessing correlation and model specification. This post: http://stackoverflow.com/questions/2336056/how-to-do-correlation-with-blocks-or-repeated-measures suggests using nlme?s correlation structure however I am uncertain whether this is truly a valid method. 

In regards to point 2: can I compare the fit parameters of identical lmer models that substitute Sample B and C with each other to comment on variation at either site.

Code so far is:
#Data at http://www.irenabyss.com.au/testing/ddata.html
library(nlme)
library(lme4)
library(lattice)

#simple correlation - that is clearly incorrect due to the range of the measurements within different patients.
cor.test(ddata$SampleB,ddata$SampleC,use = "everything",na.rm=TRUE)


#method from stack_overflow: nlme correlation function to assess intra-class correlation
summary(mod <- gls(SampleC ~ SampleB+Batch:Group,
                   correlation = corLin(form=~1|Batch/Group), #Post_Filt_iCa_mmol.L
                   data=ddata,na.action = na.omit) ) 
intervals(mod)$corStruct  # confidence interval for the correlation
summary(mod)

#plot of predicted vs fitted values from the gls model
bwtheme<-standard.theme("pdf",color = FALSE)
(plot5<- with(ddata,
              xyplot(SampleC ~ SampleB|(paste(ddata$Process,  formatC(ddata$Group,width=2,format="d",flag="0"),sep=".")), groups=as.factor(Batch), as.table=TRUE, panel = function(x, y, ...) {panel.xyplot(x, y, ...);panel.abline(coef = coef(mod), ...)  },par.settings = bwtheme, aspect = "iso",type = c('p'),xlab = "Sample B Conc.", ylab = "Sample A Conc",scales = "free",auto.key = list(title = "Batch", cex = 0.7,space = 'right',adj = 1,columns = 1,levels(as.factor(ddata$Batch))))))


#comparisons of intercept, slope and variance at sites B & C compared to Site A
summary(lme4_modC<-lmer(SampleC ~(1|SampleA) +(Batch|Group),data=ddata))
summary(lme4_modB<-lmer(SampleB ~(1|SampleA) +(Batch|Group),data=ddata))

Any suggestions or identifying errors appreciated.

Kind Regards


Matt Brain
PhD Candidate, Monash University

From ravi.varadhan at jhu.edu  Fri Apr 22 17:23:03 2016
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Fri, 22 Apr 2016 15:23:03 +0000
Subject: [R-sig-ME] na.action in lmer()
In-Reply-To: <57194697.3060404@gmail.com>
References: <63bde12d7b5249f5ad0f8292c973a9bd@ESGEBEX10.win.ad.jhu.edu>
	<57194697.3060404@gmail.com>
Message-ID: <8ab678b3e90b49af8f9d7d9d815ef1ab@ESGEBEX10.win.ad.jhu.edu>

Ok, I get it.  
Yes, I did mean REML=FALSE.  I use that option so that I can do an anova() on the two nested models.

Thank you,
Ravi

-----Original Message-----
From: Ben Bolker [mailto:bbolker at gmail.com] 
Sent: Thursday, April 21, 2016 5:31 PM
To: Ravi Varadhan <ravi.varadhan at jhu.edu>; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] na.action in lmer()


  You shouldn't need to do anything special, since the data are written out in a long format, e.g.

Patient  time   y
1           0   0.1
1           1   0.3
...
2           0   0.1
2           1   NA
2           2   0.3
...

  Unlike in the classic MANOVA setup where the responses from an individual are all considered part of the same observation (and hence an NA screws things up badly), this is just handled automatically/naturally in the mixed-model context.

  The only difference between na.omit() and na.exclude() is whether NA values are inserted into appropriate places in the downstream residual/prediction calculations.  (g)lmer can't do anything with observations containing NA values, but 'observation' means (in this
case) 'patient-time combination', not 'patient'.

  (Do you mean REML=FALSE ... ?)


On 16-04-21 05:19 PM, Ravi Varadhan wrote:
> Hi,
> 
> I am fitting a model like this with random intercept and random slope 
> using lme4::lmer.
> 
> lmer(y ~ time + (time|Patient), REML="FALSE", na.action=na.omit)
> 
> The `na.omit' option is the default. However, I would like to include 
> patients with one or missing values in their time trajectory.  Which 
> NA handling option would I use?
> 
> Thank you, Ravi
> 
> Ravi Varadhan, Ph.D. (Biostatistics), Ph.D. (Environmental Engg) 
> Associate Professor,  Department of Oncology Division of Biostatistics 
> & Bionformatics Sidney Kimmel Comprehensive Cancer Center Johns 
> Hopkins University 550 N. Broadway, Suite 1111-E Baltimore, MD 21205 
> 410-502-2619
> 
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 


From pratyayr at gmail.com  Fri Apr 22 07:49:48 2016
From: pratyayr at gmail.com (Pratyaydipta Rudra)
Date: Thu, 21 Apr 2016 23:49:48 -0600
Subject: [R-sig-ME] Tweedie GLMM with "cplm" package
Message-ID: <CALV8YNR3nKnn6eLqoQr7C0oKPjMfxXJKFGkBVY0Pb3qk=MD+PQ@mail.gmail.com>

Hi,

I am trying to use the "cplm" package in R to fit compound Poisson
generalized linear mixed effects model. Although the package is quite
powerful, it seems to have some bugs and memory issues. I am using the
function "cpglmm" to fit a model with log-link which has a fixed intercept,
and a group specific random intercept. My code is like

fit=cpglmm(y ~ 1 + (1|s))

A common error that I get (I have tried it in a windows machine and a mac)
is like:

> Calloc' could not allocate memory (18446744071562067968 of 8 bytes)

It seems to me that there is some memory leak. Unfortunately this error is
not reproducible and the model fits okay in an immediate second attempt.

A second error that I get can be reproduced. Please find the R object
"bug1.RObj" from the link below:
https://dl.dropboxusercontent.com/u/58392882/bug1.RObj

When I run the following, I get different estimates for the same model (the
model corresponding to dat[2, ] ). If I fit it again and again, it gives me
the same result as the second fit. But if I fit it immediately after the
first model, it gives me different result.

load("bug1.RObj")
tryfit=cpglmm(as.numeric(dat[1,]) ~ 1 + (1|s))
tryfit=cpglmm(as.numeric(dat[2,]) ~ 1 + (1|s))
tryfit
tryfit=cpglmm(as.numeric(dat[2,]) ~ 1 + (1|s))
tryfit

There were many other instances with similar code where it seems like the
package is "carrying" something from the previous fit. For example, a data
fits perfectly fine when fitted on its own, but when fitted after another
particular fit, my computer gets stuck and never recovers until I close the
R session.

The only way I could resolve this issue for all such cases was to detach
the package after each fit and re-attach it, which I do not want to do.

A different error from the function "cpglm" when I try to fit a fixed
effects model with just an intercept:

> Error: cannot allocate vector of size 5.6 Gb
   In addition: Warning messages:
   1: In dtweedie.logw.smallp(y = y, power = power, phi = phi) :
   Reached total allocation of 16275Mb: see help(memory.size)

I don't get why R should attempt to allocate such huge memory to fit a data
with ~180 observations.

I tried to read through the functions to catch these errors, but could not
figure out.

Any help will be appreciated.
Thanks.

Pratyay

-- 
*Pratyaydipta Rudra*
Post Doctoral fellow
Department of Biostatistics and Informatics
Colorado School of Public Health
University of Colorado Anschutz Medical Campus

	[[alternative HTML version deleted]]


From quentin.schorpp at thuenen.de  Fri Apr 22 19:44:45 2016
From: quentin.schorpp at thuenen.de (Quentin Schorpp)
Date: Fri, 22 Apr 2016 19:44:45 +0200 (CEST)
Subject: [R-sig-ME] Strange predictions from binomial glmm - multi average
	approach
Message-ID: <d762ae30ef351835029840daed4b38ea.squirrel@webmail.thuenen.de>

Hello,

I am analysing the dominance of a Species, i.e. its relative abundance
(Proportion) in a community. Since these data are proportions I use
binomial models. However, the predictions from these models are
surprisingly non-sense. Can somebody help me finding the mistake?

Background: I sampled a Chronosequence of agicultural fields. Sampling
took place in two consecutive years and 12 of the fields have been sampled
repeatedly. However, the reference fields had a different plant species
and due to the field management, reference fields have been switched
between the years. Therfore 6 of the fields have been sampled only once.
Due to the repeated measures design I use mixed models with the field.ID
as random factor (although refernce-field.IDs appear only once, all others
appear twice). The age of the fields was not very different (2-3 years
difference). Since I took samples in intervals of 1 year, I want to
consider both time dependent factors: Year of sampling and Age of the
field (class of the chronosequence). Therefore I calculated time since
establishment (or: cpl - cultivation period length) of the field for all
samples and regress relative abundance against cpl. Besides time dependent
factor I use environmental measures as (nuisance-) covariables.

The strange thing about the predicitions is, that the prediciton lines
reaches values, that ahsve not been observed during the study, i.e. they
are far too high.


Ths is my approach:
fml.glb   <- as.formula(cbind(scs,fail) ~ cpl + I(cpl^2) + pH + mc + ats1
+ nitrogen + (1|field.ID))

con = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=2e5),
calc.derivs = TRUE, check.conv.grad="ignore")

G1 <- glmer(fml.glb, df1, family=binomial(link="logit"),control=con)

GD1 <- dredge(G1, m.lim = c(NA,3), subset = dc(cpl,I(cpl^2)))

delta4 <- get.models(GD1, subset = delta < 4, REML=T)
M.avg <- model.avg(GD1, subset= delta < 4, fit=TRUE)

pred.se <- predict(M.avg, type="response", se.fit=TRUE, re.form=NA,
full=T, newdata)
newdata$fit <- pred.se$fit
newdata$SE <- pred.se$se
newdata$upr=newdata$fit+1.96*newdata$SE
newdata$lwr=newdata$fit-1.96*newdata$SE

I also posted this Question i?n stack overflow, where i provide a dataset
, addititional explanations and R-code and the prediction plots as well as
the results table for Averaged Coefficients:
http://stackoverflow.com/questions/36725160/strange-predicitons-from-binomial-glmm-multi-model-average-approach

Any Suggestions or ideas why the predicitions are out of the range of
observed proportions?


From Arvid.Sjolander at ki.se  Sun Apr 24 08:07:39 2016
From: Arvid.Sjolander at ki.se (=?iso-8859-1?Q?Arvid_Sj=F6lander?=)
Date: Sun, 24 Apr 2016 06:07:39 +0000
Subject: [R-sig-ME] question
In-Reply-To: <5A2B25374FBF34429A2D8D60EF2E4A0FF06712FD@KIMSX01.user.ki.se>
References: <5A2B25374FBF34429A2D8D60EF2E4A0FF06712FD@KIMSX01.user.ki.se>
Message-ID: <5A2B25374FBF34429A2D8D60EF2E4A0FF0671348@KIMSX01.user.ki.se>

Dear authors of lme4,

I have a question regarding your very nice package. In your notation, after fitting a model with glmer, with one grouping factor, is it possible to

- get out the ML score functions for (\beta,\theta,\sigma), evaluated at (\hat{\beta},\hat{\theta},\hat{\sigma}), for each group separately?
- get out the estimated variance-covariance matrix for (\hat{\beta},\hat{\theta},\hat{\sigma})?

Best regards
Arvid Sj?lander

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Apr 25 11:02:39 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 25 Apr 2016 11:02:39 +0200
Subject: [R-sig-ME] Mixed Effects Models to compare different testing
	sites
In-Reply-To: <A98D63A1-32A9-4FCE-A49E-AB7362064D89@gmail.com>
References: <A98D63A1-32A9-4FCE-A49E-AB7362064D89@gmail.com>
Message-ID: <CAJuCY5w4e4VbPeCoztr0W9eic9rMDTm_X-bmLLLphoh-FHGZ=g@mail.gmail.com>

Dear Matthew,

You need to transform the data into long format. Then you can model the
correlation with lme (not lmer). Here is an example.

library(dplyr)
library(nlme)

long.data <- ddata %>%
  mutate(Timestamp = as.POSIXct(Timestamp)) %>%
  gather(key = "Site", value = "Measurement", 10:12) %>%
  mutate(
    Site = gsub("Sample", "", Site),
    Siteint = as.integer(factor(Site)),
    ID = factor(Timestamp)
  )
model <- lme(
  Measurement ~ Process,
  random = ~1 | Batch /ID,
  data = long.data,
  correlation = corAR1(form = ~ Siteint),
  na.action = na.exclude
)

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-04-22 17:42 GMT+02:00 Matthew Brain <matt.brain1 at gmail.com>:

> Hi,
> I have an awkward correlation problem with an unbalanced nested repeated
> measures data set. Essentially we have 3 sampling sites on a flowing fluid
> stream: site A is at the source and sites B and C are sequentially
> downstream after additives and filters are applied. A significant process
> difference is additive A or B (which affects sites B and C). Hierarchical
> structure is group (source of fluid stream), batch of filter, processA or
> B. Sample of data can be found at
> http://www.irenabyss.com.au/testing/ddata.html.
>
> I am trying to answer four questions:
> 1. What is the correlation and CI between measurements taken from Sample
> sites B and C
> 2. Is the measurement variance significantly greater at sample sites B or
> C when compared to site A
> 3. Is there heteroskedasticity of measurements (from A,B or C) as values
> vary between low and high values
>
> My main issue is with assessing correlation and model specification. This
> post:
> http://stackoverflow.com/questions/2336056/how-to-do-correlation-with-blocks-or-repeated-measures
> suggests using nlme?s correlation structure however I am uncertain whether
> this is truly a valid method.
>
> In regards to point 2: can I compare the fit parameters of identical lmer
> models that substitute Sample B and C with each other to comment on
> variation at either site.
>
> Code so far is:
> #Data at http://www.irenabyss.com.au/testing/ddata.html
> library(nlme)
> library(lme4)
> library(lattice)
>
> #simple correlation - that is clearly incorrect due to the range of the
> measurements within different patients.
> cor.test(ddata$SampleB,ddata$SampleC,use = "everything",na.rm=TRUE)
>
>
> #method from stack_overflow: nlme correlation function to assess
> intra-class correlation
> summary(mod <- gls(SampleC ~ SampleB+Batch:Group,
>                    correlation = corLin(form=~1|Batch/Group),
> #Post_Filt_iCa_mmol.L
>                    data=ddata,na.action = na.omit) )
> intervals(mod)$corStruct  # confidence interval for the correlation
> summary(mod)
>
> #plot of predicted vs fitted values from the gls model
> bwtheme<-standard.theme("pdf",color = FALSE)
> (plot5<- with(ddata,
>               xyplot(SampleC ~ SampleB|(paste(ddata$Process,
> formatC(ddata$Group,width=2,format="d",flag="0"),sep=".")),
> groups=as.factor(Batch), as.table=TRUE, panel = function(x, y, ...)
> {panel.xyplot(x, y, ...);panel.abline(coef = coef(mod), ...)
> },par.settings = bwtheme, aspect = "iso",type = c('p'),xlab = "Sample B
> Conc.", ylab = "Sample A Conc",scales = "free",auto.key = list(title =
> "Batch", cex = 0.7,space = 'right',adj = 1,columns =
> 1,levels(as.factor(ddata$Batch))))))
>
>
> #comparisons of intercept, slope and variance at sites B & C compared to
> Site A
> summary(lme4_modC<-lmer(SampleC ~(1|SampleA) +(Batch|Group),data=ddata))
> summary(lme4_modB<-lmer(SampleB ~(1|SampleA) +(Batch|Group),data=ddata))
>
> Any suggestions or identifying errors appreciated.
>
> Kind Regards
>
>
> Matt Brain
> PhD Candidate, Monash University
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From gaughra at tcd.ie  Mon Apr 25 14:08:49 2016
From: gaughra at tcd.ie (Aoibheann Gaughran)
Date: Mon, 25 Apr 2016 13:08:49 +0100
Subject: [R-sig-ME] Convergence Problems with glmer.nb model
In-Reply-To: <CAN=0SEkfdDsdiqmK51K0U4FYHyDhcsvWFLNTtbRJFL9oZXbF9g@mail.gmail.com>
References: <CAN=0SEkfdDsdiqmK51K0U4FYHyDhcsvWFLNTtbRJFL9oZXbF9g@mail.gmail.com>
Message-ID: <CAN=0SEkTL+-UyXcpMRAQFwcCWvNJu+9ZR0wzBTHi+DXQ2JhKqg@mail.gmail.com>

On 25 April 2016 at 13:00, Aoibheann Gaughran <gaughra at tcd.ie> wrote:

> Good morning,
>
> First time posting so I hope I am including all of the relevant
> information.
>
> I am attempting to analyse the foraging behaviour of a animal in an
> agricultural landscape. The objective is to identify the factors (habitat
> type, environmental variables and animal-specific variables) that best
> predict foraging site preference. Some fields are preferred while others
> are avoided.
>
> The response variable is count data - the number of times a given animal
> was in a given field in a given month. An animal's home range varies from
> month to month, so the area available to it and the fields that fall within
> its home range change somewhat every month. The count data shows an
> overdispersed, negative binomial distribution, and is zero inflated as
> fields that fell within the home range where the animal had *not *foraged
> in that month are also included in the dataset. The individual animal is
> specified as a random variable to account for pseudoreplication.
>
> It should be noted that at the moment I am attempting to run a the model
> on a subset of the data (n=671) as I had attempted to run the model on the
> full dataset (n=62,000) but three days later the model (which included
> interaction terms at this point) had still failed to run, and when stopped,
> R gave me a multitude of convergence warning messages e.g.
>
> 13: In (function (fn, par, lower = rep.int(-Inf, n), upper = rep.int(Inf,
> ... :
>   failure to converge in 10000 evaluations
>
> Simpler iterations of the model, with fewer explanatory terms, and no
> interaction terms, also gave me convergence and some scaling warnings,
> which I sought to address using:
>
> control=glmerControl(optCtrl=list(maxfun=20000)
>
> and by scaling the numeric variables age, slope and aspect as follows:-
>
> dframe1$agescale <- scale(dframe1$age, center = TRUE, scale = FALSE)
> dframe1$slopescale <- scale(dframe1$slope, center = TRUE, scale = FALSE)
> dframe1$aspectscale <- scale(dframe1$aspect, center = TRUE, scale = FALSE)
>
> Currently, the model looks like this:
>
> > model1 <- glmer.nb(field_count ~ habitat +                    + sex+                    + agescale+                    #+ mon+                    + soil+                    + slopescale+                    + aspectscale+                    + offset(log(origarea)) #take into account field size +                    +(1|animal),+                    control=glmerControl(optCtrl=list(maxfun=20000)),+                    data = dframe1)
>
> There were 24 warnings (use warnings() to see them)
> > warnings()Warning messages:
> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :
>   Model is nearly unidentifiable: very large eigenvalue
>  - Rescale variables?;Model is nearly unidentifiable: large eigenvalue ratio
>  - Rescale variables?
> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :
>   Model failed to converge with max|grad| = 0.0134799 (tol = 0.001, component 1)
> 3: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :
>   Model failed to converge with max|grad| = 0.148644 (tol = 0.001, component 1)
> 4: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :
>   Model is nearly unidentifiable: large eigenvalue ratio
>  - Rescale variables?
>
> etc.
>
> So the model still fails to converge despite rescaling and altering the
> number of iterations. I had also received the following error in relation
> to month (in the reduced dataset there are only *four *months), so Ive
> had to exclude it for the time being. I am not sure why I am getting this
> error since the factor has four levels.
>
> Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
> contrasts can be applied only to factors with 2 or more levels
>
> I do eventually want to include interaction terms as previous analysis on
> ranging behaviour suggests there is an interaction between age and sex.
>
> Summary of dataset attached.  Also attached is the .csv file containing
> the reduced dataset.
>
> I have read various suggestions online and have come across the following
> worrying line "It's perfectly possible that your data is insufficient to
> support the complexity of the model or the model is incorrectly constructed
> for the design of the study".
>
> I would greatly appreciate any help you could give me with understanding
> and solving the problems I am encountering with my model.
>
> Kind regards,
>
> --
> Aoibheann Gaughran
>
> Behavioural and Evolutionary Ecology Research Group
> Zoology Building
> School of Natural Sciences
> Trinity College Dublin
> Dublin 2
> Ireland
> Phone: +353 (86) 3812615
>



-- 
Aoibheann Gaughran

Behavioural and Evolutionary Ecology Research Group
Zoology Building
School of Natural Sciences
Trinity College Dublin
Dublin 2
Ireland
Phone: +353 (86) 3812615

From thierry.onkelinx at inbo.be  Mon Apr 25 14:40:39 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 25 Apr 2016 14:40:39 +0200
Subject: [R-sig-ME] Convergence Problems with glmer.nb model
In-Reply-To: <CAN=0SEkTL+-UyXcpMRAQFwcCWvNJu+9ZR0wzBTHi+DXQ2JhKqg@mail.gmail.com>
References: <CAN=0SEkfdDsdiqmK51K0U4FYHyDhcsvWFLNTtbRJFL9oZXbF9g@mail.gmail.com>
	<CAN=0SEkTL+-UyXcpMRAQFwcCWvNJu+9ZR0wzBTHi+DXQ2JhKqg@mail.gmail.com>
Message-ID: <CAJuCY5xLg1bN8A6-6oHQmQJgnDXTyDN+SvHJ1sRGtowP60DWzQ@mail.gmail.com>

Dear Aoibheann,

Two general suggestions on the design. 1) A random effect of field seems
relevant too. 2) Have the units of origarea in a relevant scale. You are
modelling the number of visits per unit of origarea. Then the number per
hectare seems more relevant to me than the number per square meter.

Then try the most simple Poisson model to see it that converge.
glmer(field_count
~ (1| animal) + (1|field) + offset(log(origarea)), family = poisson)

If that works, then you could try the negative binomial distribution or
adding an observation level random effect.

The mailing list strips most attachments. So you need to put them on a
website or post a dropbox or google drive link.

Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-04-25 14:08 GMT+02:00 Aoibheann Gaughran <gaughra at tcd.ie>:

> On 25 April 2016 at 13:00, Aoibheann Gaughran <gaughra at tcd.ie> wrote:
>
> > Good morning,
> >
> > First time posting so I hope I am including all of the relevant
> > information.
> >
> > I am attempting to analyse the foraging behaviour of a animal in an
> > agricultural landscape. The objective is to identify the factors (habitat
> > type, environmental variables and animal-specific variables) that best
> > predict foraging site preference. Some fields are preferred while others
> > are avoided.
> >
> > The response variable is count data - the number of times a given animal
> > was in a given field in a given month. An animal's home range varies from
> > month to month, so the area available to it and the fields that fall
> within
> > its home range change somewhat every month. The count data shows an
> > overdispersed, negative binomial distribution, and is zero inflated as
> > fields that fell within the home range where the animal had *not *foraged
> > in that month are also included in the dataset. The individual animal is
> > specified as a random variable to account for pseudoreplication.
> >
> > It should be noted that at the moment I am attempting to run a the model
> > on a subset of the data (n=671) as I had attempted to run the model on
> the
> > full dataset (n=62,000) but three days later the model (which included
> > interaction terms at this point) had still failed to run, and when
> stopped,
> > R gave me a multitude of convergence warning messages e.g.
> >
> > 13: In (function (fn, par, lower = rep.int(-Inf, n), upper = rep.int
> (Inf,
> > ... :
> >   failure to converge in 10000 evaluations
> >
> > Simpler iterations of the model, with fewer explanatory terms, and no
> > interaction terms, also gave me convergence and some scaling warnings,
> > which I sought to address using:
> >
> > control=glmerControl(optCtrl=list(maxfun=20000)
> >
> > and by scaling the numeric variables age, slope and aspect as follows:-
> >
> > dframe1$agescale <- scale(dframe1$age, center = TRUE, scale = FALSE)
> > dframe1$slopescale <- scale(dframe1$slope, center = TRUE, scale = FALSE)
> > dframe1$aspectscale <- scale(dframe1$aspect, center = TRUE, scale =
> FALSE)
> >
> > Currently, the model looks like this:
> >
> > > model1 <- glmer.nb(field_count ~ habitat +                    + sex+
>                   + agescale+                    #+ mon+
> + soil+                    + slopescale+                    + aspectscale+
>                   + offset(log(origarea)) #take into account field size +
>                   +(1|animal),+
> control=glmerControl(optCtrl=list(maxfun=20000)),+                    data
> = dframe1)
> >
> > There were 24 warnings (use warnings() to see them)
> > > warnings()Warning messages:
> > 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
> ... :
> >   Model is nearly unidentifiable: very large eigenvalue
> >  - Rescale variables?;Model is nearly unidentifiable: large eigenvalue
> ratio
> >  - Rescale variables?
> > 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
> ... :
> >   Model failed to converge with max|grad| = 0.0134799 (tol = 0.001,
> component 1)
> > 3: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
> ... :
> >   Model failed to converge with max|grad| = 0.148644 (tol = 0.001,
> component 1)
> > 4: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
> ... :
> >   Model is nearly unidentifiable: large eigenvalue ratio
> >  - Rescale variables?
> >
> > etc.
> >
> > So the model still fails to converge despite rescaling and altering the
> > number of iterations. I had also received the following error in relation
> > to month (in the reduced dataset there are only *four *months), so Ive
> > had to exclude it for the time being. I am not sure why I am getting this
> > error since the factor has four levels.
> >
> > Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
> > contrasts can be applied only to factors with 2 or more levels
> >
> > I do eventually want to include interaction terms as previous analysis on
> > ranging behaviour suggests there is an interaction between age and sex.
> >
> > Summary of dataset attached.  Also attached is the .csv file containing
> > the reduced dataset.
> >
> > I have read various suggestions online and have come across the following
> > worrying line "It's perfectly possible that your data is insufficient to
> > support the complexity of the model or the model is incorrectly
> constructed
> > for the design of the study".
> >
> > I would greatly appreciate any help you could give me with understanding
> > and solving the problems I am encountering with my model.
> >
> > Kind regards,
> >
> > --
> > Aoibheann Gaughran
> >
> > Behavioural and Evolutionary Ecology Research Group
> > Zoology Building
> > School of Natural Sciences
> > Trinity College Dublin
> > Dublin 2
> > Ireland
> > Phone: +353 (86) 3812615
> >
>
>
>
> --
> Aoibheann Gaughran
>
> Behavioural and Evolutionary Ecology Research Group
> Zoology Building
> School of Natural Sciences
> Trinity College Dublin
> Dublin 2
> Ireland
> Phone: +353 (86) 3812615
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From gaughra at tcd.ie  Mon Apr 25 15:44:28 2016
From: gaughra at tcd.ie (Aoibheann Gaughran)
Date: Mon, 25 Apr 2016 14:44:28 +0100
Subject: [R-sig-ME] Convergence Problems with glmer.nb model
In-Reply-To: <CAJuCY5xLg1bN8A6-6oHQmQJgnDXTyDN+SvHJ1sRGtowP60DWzQ@mail.gmail.com>
References: <CAN=0SEkfdDsdiqmK51K0U4FYHyDhcsvWFLNTtbRJFL9oZXbF9g@mail.gmail.com>
	<CAN=0SEkTL+-UyXcpMRAQFwcCWvNJu+9ZR0wzBTHi+DXQ2JhKqg@mail.gmail.com>
	<CAJuCY5xLg1bN8A6-6oHQmQJgnDXTyDN+SvHJ1sRGtowP60DWzQ@mail.gmail.com>
Message-ID: <CAN=0SEnVLZzbQGTqVJDHgFqUAXZHWpz-sPwQv5TOO4fCz+oQ_A@mail.gmail.com>

Hi Thierry,

Here is the dropbox link to the data -
https://www.dropbox.com/s/ne5d4zp2gncwylm/foraging%20subset.csv?dl=0

I had changed the field area units from meter square to hectures already,
so that *should *be okay.  There is one exceedingly large "field" which is
actually a large area of forestry. Perhaps this is throwing the scaling
off.

Can you confirm that this is how I specify the observation level random
effect:

dframe1$obs <- factor(seq(nrow(dframe1)))  #modified from
https://rpubs.com/bbolker/glmmchapter

which is included in the model as

+(1|obs)


I'll try your suggestions and see how I get on.

Many thanks,

Aoibheann

On 25 April 2016 at 13:40, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Aoibheann,
>
> Two general suggestions on the design. 1) A random effect of field seems
> relevant too. 2) Have the units of origarea in a relevant scale. You are
> modelling the number of visits per unit of origarea. Then the number per
> hectare seems more relevant to me than the number per square meter.
>
> Then try the most simple Poisson model to see it that converge. glmer(field_count
> ~ (1| animal) + (1|field) + offset(log(origarea)), family = poisson)
>
> If that works, then you could try the negative binomial distribution or
> adding an observation level random effect.
>
> The mailing list strips most attachments. So you need to put them on a
> website or post a dropbox or google drive link.
>
> Best regards,
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2016-04-25 14:08 GMT+02:00 Aoibheann Gaughran <gaughra at tcd.ie>:
>
>> On 25 April 2016 at 13:00, Aoibheann Gaughran <gaughra at tcd.ie> wrote:
>>
>> > Good morning,
>> >
>> > First time posting so I hope I am including all of the relevant
>> > information.
>> >
>> > I am attempting to analyse the foraging behaviour of a animal in an
>> > agricultural landscape. The objective is to identify the factors
>> (habitat
>> > type, environmental variables and animal-specific variables) that best
>> > predict foraging site preference. Some fields are preferred while others
>> > are avoided.
>> >
>> > The response variable is count data - the number of times a given animal
>> > was in a given field in a given month. An animal's home range varies
>> from
>> > month to month, so the area available to it and the fields that fall
>> within
>> > its home range change somewhat every month. The count data shows an
>> > overdispersed, negative binomial distribution, and is zero inflated as
>> > fields that fell within the home range where the animal had *not
>> *foraged
>> > in that month are also included in the dataset. The individual animal is
>> > specified as a random variable to account for pseudoreplication.
>> >
>> > It should be noted that at the moment I am attempting to run a the model
>> > on a subset of the data (n=671) as I had attempted to run the model on
>> the
>> > full dataset (n=62,000) but three days later the model (which included
>> > interaction terms at this point) had still failed to run, and when
>> stopped,
>> > R gave me a multitude of convergence warning messages e.g.
>> >
>> > 13: In (function (fn, par, lower = rep.int(-Inf, n), upper = rep.int
>> (Inf,
>> > ... :
>> >   failure to converge in 10000 evaluations
>> >
>> > Simpler iterations of the model, with fewer explanatory terms, and no
>> > interaction terms, also gave me convergence and some scaling warnings,
>> > which I sought to address using:
>> >
>> > control=glmerControl(optCtrl=list(maxfun=20000)
>> >
>> > and by scaling the numeric variables age, slope and aspect as follows:-
>> >
>> > dframe1$agescale <- scale(dframe1$age, center = TRUE, scale = FALSE)
>> > dframe1$slopescale <- scale(dframe1$slope, center = TRUE, scale = FALSE)
>> > dframe1$aspectscale <- scale(dframe1$aspect, center = TRUE, scale =
>> FALSE)
>> >
>> > Currently, the model looks like this:
>> >
>> > > model1 <- glmer.nb(field_count ~ habitat +                    + sex+
>>                   + agescale+                    #+ mon+
>> + soil+                    + slopescale+                    + aspectscale+
>>                   + offset(log(origarea)) #take into account field size +
>>                   +(1|animal),+
>> control=glmerControl(optCtrl=list(maxfun=20000)),+                    data
>> = dframe1)
>> >
>> > There were 24 warnings (use warnings() to see them)
>> > > warnings()Warning messages:
>> > 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
>> control$checkConv,  ... :
>> >   Model is nearly unidentifiable: very large eigenvalue
>> >  - Rescale variables?;Model is nearly unidentifiable: large eigenvalue
>> ratio
>> >  - Rescale variables?
>> > 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
>> control$checkConv,  ... :
>> >   Model failed to converge with max|grad| = 0.0134799 (tol = 0.001,
>> component 1)
>> > 3: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
>> control$checkConv,  ... :
>> >   Model failed to converge with max|grad| = 0.148644 (tol = 0.001,
>> component 1)
>> > 4: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
>> control$checkConv,  ... :
>> >   Model is nearly unidentifiable: large eigenvalue ratio
>> >  - Rescale variables?
>> >
>> > etc.
>> >
>> > So the model still fails to converge despite rescaling and altering the
>> > number of iterations. I had also received the following error in
>> relation
>> > to month (in the reduced dataset there are only *four *months), so Ive
>>
>> > had to exclude it for the time being. I am not sure why I am getting
>> this
>> > error since the factor has four levels.
>> >
>> > Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
>> > contrasts can be applied only to factors with 2 or more levels
>> >
>> > I do eventually want to include interaction terms as previous analysis
>> on
>> > ranging behaviour suggests there is an interaction between age and sex.
>> >
>> > Summary of dataset attached.  Also attached is the .csv file containing
>> > the reduced dataset.
>> >
>> > I have read various suggestions online and have come across the
>> following
>> > worrying line "It's perfectly possible that your data is insufficient to
>> > support the complexity of the model or the model is incorrectly
>> constructed
>> > for the design of the study".
>> >
>> > I would greatly appreciate any help you could give me with understanding
>> > and solving the problems I am encountering with my model.
>> >
>> > Kind regards,
>> >
>> > --
>> > Aoibheann Gaughran
>> >
>> > Behavioural and Evolutionary Ecology Research Group
>> > Zoology Building
>> > School of Natural Sciences
>> > Trinity College Dublin
>> > Dublin 2
>> > Ireland
>> > Phone: +353 (86) 3812615
>> >
>>
>>
>>
>> --
>> Aoibheann Gaughran
>>
>> Behavioural and Evolutionary Ecology Research Group
>> Zoology Building
>> School of Natural Sciences
>> Trinity College Dublin
>> Dublin 2
>> Ireland
>> Phone: +353 (86) 3812615
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>


-- 
Aoibheann Gaughran

Behavioural and Evolutionary Ecology Research Group
Zoology Building
School of Natural Sciences
Trinity College Dublin
Dublin 2
Ireland
Phone: +353 (86) 3812615

	[[alternative HTML version deleted]]


From b.pelzer at maw.ru.nl  Mon Apr 25 15:52:36 2016
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Mon, 25 Apr 2016 15:52:36 +0200
Subject: [R-sig-ME] (no) significance value (gl)mer
In-Reply-To: <CAGwfgc6uN05Xf5q=rMfwzXR0zoFK2YtK9dJtn4GnraAEfxPr7A@mail.gmail.com>
References: <CAGwfgc6uN05Xf5q=rMfwzXR0zoFK2YtK9dJtn4GnraAEfxPr7A@mail.gmail.com>
Message-ID: <571E2124.80202@maw.ru.nl>

Dear list,

In lmer, no significances for the t-values of fixed effects are given, 
while in a logistic model with glmer, significances for z-values are 
shown. Where does this difference come from? Does it mean, that the 
problem of computing the "right" nr. of degrees of freedom for the 
t-values of a linear model does not exits (or is less of a problem) for 
non-linear models? Are the significances that glmer produces (at least 
in case of logistic regression) based on the Wald statistic or may be on 
an LRT test? Thanks for any explanation!

Ben.


From marko.bachl at uni-hohenheim.de  Mon Apr 25 16:27:21 2016
From: marko.bachl at uni-hohenheim.de (Marko Bachl)
Date: Mon, 25 Apr 2016 16:27:21 +0200
Subject: [R-sig-ME] (no) significance value (gl)mer
In-Reply-To: <571E2124.80202@maw.ru.nl>
References: <CAGwfgc6uN05Xf5q=rMfwzXR0zoFK2YtK9dJtn4GnraAEfxPr7A@mail.gmail.com>
	<571E2124.80202@maw.ru.nl>
Message-ID: <CAE5vbrtY-+vh+uFjEFZKsq5vrLik1+qHQJNVsGCdi353O3J=fw@mail.gmail.com>

Dear Ben,
Just a short info, others may have something more substantial to add.

You will find plenty of information on significance tests and
inference in lme4 in the top sections of this website:
http://glmm.wikidot.com/faq.
A short info inside the lme4 package is given by
require(lme4)
?pvalues

Best,
Marko





2016-04-25 15:52 GMT+02:00 Ben Pelzer <b.pelzer at maw.ru.nl>:
> Dear list,
>
> In lmer, no significances for the t-values of fixed effects are given, while
> in a logistic model with glmer, significances for z-values are shown. Where
> does this difference come from? Does it mean, that the problem of computing
> the "right" nr. of degrees of freedom for the t-values of a linear model
> does not exits (or is less of a problem) for non-linear models? Are the
> significances that glmer produces (at least in case of logistic regression)
> based on the Wald statistic or may be on an LRT test? Thanks for any
> explanation!
>
> Ben.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Dr. Marko Bachl
Universit?t Hohenheim
Institut f?r Kommunikationswissenschaft (540C)
T 0711 459 228 66
M marko.bachl at uni-hohenheim.de
W www.komm.uni-hohenheim.de/bachl


From mollieebrooks at gmail.com  Mon Apr 25 16:01:44 2016
From: mollieebrooks at gmail.com (Mollie Brooks)
Date: Mon, 25 Apr 2016 16:01:44 +0200
Subject: [R-sig-ME] (no) significance value (gl)mer
In-Reply-To: <571E2124.80202@maw.ru.nl>
References: <CAGwfgc6uN05Xf5q=rMfwzXR0zoFK2YtK9dJtn4GnraAEfxPr7A@mail.gmail.com>
	<571E2124.80202@maw.ru.nl>
Message-ID: <7106F834-A8F4-4C29-A53F-46CAE41663EE@ufl.edu>

Hi Ben,

The latest documentation on that topic should be available with the code
help("pvalues",package="lme4")

cheers,
Mollie

------------------------
Mollie Brooks, PhD
Postdoctoral Researcher, Population Ecology Research Group
Department of Evolutionary Biology & Environmental Studies, University of Z?rich
http://www.popecol.org/team/mollie-brooks/


> On 25Apr 2016, at 15:52, Ben Pelzer <b.pelzer at maw.ru.nl> wrote:
> 
> Dear list,
> 
> In lmer, no significances for the t-values of fixed effects are given, while in a logistic model with glmer, significances for z-values are shown. Where does this difference come from? Does it mean, that the problem of computing the "right" nr. of degrees of freedom for the t-values of a linear model does not exits (or is less of a problem) for non-linear models? Are the significances that glmer produces (at least in case of logistic regression) based on the Wald statistic or may be on an LRT test? Thanks for any explanation!
> 
> Ben.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 


	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Apr 25 18:04:02 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 25 Apr 2016 18:04:02 +0200
Subject: [R-sig-ME] Convergence Problems with glmer.nb model
In-Reply-To: <CAN=0SEnVLZzbQGTqVJDHgFqUAXZHWpz-sPwQv5TOO4fCz+oQ_A@mail.gmail.com>
References: <CAN=0SEkfdDsdiqmK51K0U4FYHyDhcsvWFLNTtbRJFL9oZXbF9g@mail.gmail.com>
	<CAN=0SEkTL+-UyXcpMRAQFwcCWvNJu+9ZR0wzBTHi+DXQ2JhKqg@mail.gmail.com>
	<CAJuCY5xLg1bN8A6-6oHQmQJgnDXTyDN+SvHJ1sRGtowP60DWzQ@mail.gmail.com>
	<CAN=0SEnVLZzbQGTqVJDHgFqUAXZHWpz-sPwQv5TOO4fCz+oQ_A@mail.gmail.com>
Message-ID: <CAJuCY5yQGo=+B_D05sue6_LR1eQxQNbnBEZXHzfVniH+7v+H3g@mail.gmail.com>

Dear Aoibheann,

The specification of the observation level random effect is correct.

Looking at your data, I would expect that the large range in area of the
fields is the culprit. They range from only 0.07 ha up to 37.12 ha. Note
that one visit in the smallest fields equals a density of 14.5 visits/ha
while one visit in the largest 0.027 visits/ha.

I recommend to split the large field into smaller chunks. Creating smaller
chunks would make variables like slope and aspect more meaningful. I doubt
that they are homogeneous over large areas.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-04-25 15:44 GMT+02:00 Aoibheann Gaughran <gaughra at tcd.ie>:

> Hi Thierry,
>
> Here is the dropbox link to the data -
> https://www.dropbox.com/s/ne5d4zp2gncwylm/foraging%20subset.csv?dl=0
>
> I had changed the field area units from meter square to hectures already,
> so that *should *be okay.  There is one exceedingly large "field" which
> is actually a large area of forestry. Perhaps this is throwing the scaling
> off.
>
> Can you confirm that this is how I specify the observation level random
> effect:
>
> dframe1$obs <- factor(seq(nrow(dframe1)))  #modified from https://rpubs.com/bbolker/glmmchapter
>
> which is included in the model as
>
> +(1|obs)
>
>
> I'll try your suggestions and see how I get on.
>
> Many thanks,
>
> Aoibheann
>
> On 25 April 2016 at 13:40, Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>
>> Dear Aoibheann,
>>
>> Two general suggestions on the design. 1) A random effect of field seems
>> relevant too. 2) Have the units of origarea in a relevant scale. You are
>> modelling the number of visits per unit of origarea. Then the number per
>> hectare seems more relevant to me than the number per square meter.
>>
>> Then try the most simple Poisson model to see it that converge. glmer(field_count
>> ~ (1| animal) + (1|field) + offset(log(origarea)), family = poisson)
>>
>> If that works, then you could try the negative binomial distribution or
>> adding an observation level random effect.
>>
>> The mailing list strips most attachments. So you need to put them on a
>> website or post a dropbox or google drive link.
>>
>> Best regards,
>>
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2016-04-25 14:08 GMT+02:00 Aoibheann Gaughran <gaughra at tcd.ie>:
>>
>>> On 25 April 2016 at 13:00, Aoibheann Gaughran <gaughra at tcd.ie> wrote:
>>>
>>> > Good morning,
>>> >
>>> > First time posting so I hope I am including all of the relevant
>>> > information.
>>> >
>>> > I am attempting to analyse the foraging behaviour of a animal in an
>>> > agricultural landscape. The objective is to identify the factors
>>> (habitat
>>> > type, environmental variables and animal-specific variables) that best
>>> > predict foraging site preference. Some fields are preferred while
>>> others
>>> > are avoided.
>>> >
>>> > The response variable is count data - the number of times a given
>>> animal
>>> > was in a given field in a given month. An animal's home range varies
>>> from
>>> > month to month, so the area available to it and the fields that fall
>>> within
>>> > its home range change somewhat every month. The count data shows an
>>> > overdispersed, negative binomial distribution, and is zero inflated as
>>> > fields that fell within the home range where the animal had *not
>>> *foraged
>>> > in that month are also included in the dataset. The individual animal
>>> is
>>> > specified as a random variable to account for pseudoreplication.
>>> >
>>> > It should be noted that at the moment I am attempting to run a the
>>> model
>>> > on a subset of the data (n=671) as I had attempted to run the model on
>>> the
>>> > full dataset (n=62,000) but three days later the model (which included
>>> > interaction terms at this point) had still failed to run, and when
>>> stopped,
>>> > R gave me a multitude of convergence warning messages e.g.
>>> >
>>> > 13: In (function (fn, par, lower = rep.int(-Inf, n), upper = rep.int
>>> (Inf,
>>> > ... :
>>> >   failure to converge in 10000 evaluations
>>> >
>>> > Simpler iterations of the model, with fewer explanatory terms, and no
>>> > interaction terms, also gave me convergence and some scaling warnings,
>>> > which I sought to address using:
>>> >
>>> > control=glmerControl(optCtrl=list(maxfun=20000)
>>> >
>>> > and by scaling the numeric variables age, slope and aspect as follows:-
>>> >
>>> > dframe1$agescale <- scale(dframe1$age, center = TRUE, scale = FALSE)
>>> > dframe1$slopescale <- scale(dframe1$slope, center = TRUE, scale =
>>> FALSE)
>>> > dframe1$aspectscale <- scale(dframe1$aspect, center = TRUE, scale =
>>> FALSE)
>>> >
>>> > Currently, the model looks like this:
>>> >
>>> > > model1 <- glmer.nb(field_count ~ habitat +                    +
>>> sex+                    + agescale+                    #+ mon+
>>>       + soil+                    + slopescale+                    +
>>> aspectscale+                    + offset(log(origarea)) #take into account
>>> field size +                    +(1|animal),+
>>> control=glmerControl(optCtrl=list(maxfun=20000)),+                    data
>>> = dframe1)
>>> >
>>> > There were 24 warnings (use warnings() to see them)
>>> > > warnings()Warning messages:
>>> > 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
>>> control$checkConv,  ... :
>>> >   Model is nearly unidentifiable: very large eigenvalue
>>> >  - Rescale variables?;Model is nearly unidentifiable: large eigenvalue
>>> ratio
>>> >  - Rescale variables?
>>> > 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
>>> control$checkConv,  ... :
>>> >   Model failed to converge with max|grad| = 0.0134799 (tol = 0.001,
>>> component 1)
>>> > 3: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
>>> control$checkConv,  ... :
>>> >   Model failed to converge with max|grad| = 0.148644 (tol = 0.001,
>>> component 1)
>>> > 4: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
>>> control$checkConv,  ... :
>>> >   Model is nearly unidentifiable: large eigenvalue ratio
>>> >  - Rescale variables?
>>> >
>>> > etc.
>>> >
>>> > So the model still fails to converge despite rescaling and altering the
>>> > number of iterations. I had also received the following error in
>>> relation
>>> > to month (in the reduced dataset there are only *four *months), so Ive
>>>
>>> > had to exclude it for the time being. I am not sure why I am getting
>>> this
>>> > error since the factor has four levels.
>>> >
>>> > Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
>>> > contrasts can be applied only to factors with 2 or more levels
>>> >
>>> > I do eventually want to include interaction terms as previous analysis
>>> on
>>> > ranging behaviour suggests there is an interaction between age and sex.
>>> >
>>> > Summary of dataset attached.  Also attached is the .csv file containing
>>> > the reduced dataset.
>>> >
>>> > I have read various suggestions online and have come across the
>>> following
>>> > worrying line "It's perfectly possible that your data is insufficient
>>> to
>>> > support the complexity of the model or the model is incorrectly
>>> constructed
>>> > for the design of the study".
>>> >
>>> > I would greatly appreciate any help you could give me with
>>> understanding
>>> > and solving the problems I am encountering with my model.
>>> >
>>> > Kind regards,
>>> >
>>> > --
>>> > Aoibheann Gaughran
>>> >
>>> > Behavioural and Evolutionary Ecology Research Group
>>> > Zoology Building
>>> > School of Natural Sciences
>>> > Trinity College Dublin
>>> > Dublin 2
>>> > Ireland
>>> > Phone: +353 (86) 3812615
>>> >
>>>
>>>
>>>
>>> --
>>> Aoibheann Gaughran
>>>
>>> Behavioural and Evolutionary Ecology Research Group
>>> Zoology Building
>>> School of Natural Sciences
>>> Trinity College Dublin
>>> Dublin 2
>>> Ireland
>>> Phone: +353 (86) 3812615
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>
>
> --
> Aoibheann Gaughran
>
> Behavioural and Evolutionary Ecology Research Group
> Zoology Building
> School of Natural Sciences
> Trinity College Dublin
> Dublin 2
> Ireland
> Phone: +353 (86) 3812615
>

	[[alternative HTML version deleted]]


From dexter.locke at gmail.com  Mon Apr 25 18:28:51 2016
From: dexter.locke at gmail.com (Dexter Locke)
Date: Mon, 25 Apr 2016 12:28:51 -0400
Subject: [R-sig-ME] test spatial autocorrelation of level 2 residuals in
	lme()
Message-ID: <CAA=SVwEQz2Cfy_UGVkyQujsG16LZPxLPWyw2joJN1+DpYcw9Hg@mail.gmail.com>

Apologies for cross-posting, its unclear if this is a spatial or a mixed
models question. Maybe its both?

I am interested in extracting the residuals from level 2 of a mixed model
(created using lme()), building a spatial weights matrix, and then testing
for spatial autocorrelation using Moran's I.

While I have found methods of incorporating spatial effects into a mixed
model using corStruct, I am interested in first evaluating *if* that is an
appropriate model for a given dataset by examining the level 2 residuals'
spatial patterning - or lack thereof.

Which slot contains the residuals for level 2 and how are they ordered?

Best,
Dexter

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Apr 25 19:43:34 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 25 Apr 2016 13:43:34 -0400
Subject: [R-sig-ME] (no) significance value (gl)mer
In-Reply-To: <CAE5vbrtY-+vh+uFjEFZKsq5vrLik1+qHQJNVsGCdi353O3J=fw@mail.gmail.com>
References: <CAGwfgc6uN05Xf5q=rMfwzXR0zoFK2YtK9dJtn4GnraAEfxPr7A@mail.gmail.com>
	<571E2124.80202@maw.ru.nl>
	<CAE5vbrtY-+vh+uFjEFZKsq5vrLik1+qHQJNVsGCdi353O3J=fw@mail.gmail.com>
Message-ID: <571E5746.9040608@gmail.com>


  For what it's worth, I've lately been playing with the FAQ; a (*very*
slightly) updated version is at
https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.html  (source
at https://github.com/bbolker/mixedmodels-misc/blob/master/glmmFAQ.rmd ).
   At some point when I think the new version is sufficiently improved
over the old one to warrant it, I'll replace the old (wikidot.com)
version with a pointer to the Github repo.

  Comments (and pull requests) welcome!



On 16-04-25 10:27 AM, Marko Bachl wrote:
> Dear Ben,
> Just a short info, others may have something more substantial to add.
> 
> You will find plenty of information on significance tests and
> inference in lme4 in the top sections of this website:
> http://glmm.wikidot.com/faq.
> A short info inside the lme4 package is given by
> require(lme4)
> ?pvalues
> 
> Best,
> Marko
> 
> 
> 
> 
> 
> 2016-04-25 15:52 GMT+02:00 Ben Pelzer <b.pelzer at maw.ru.nl>:
>> Dear list,
>>
>> In lmer, no significances for the t-values of fixed effects are given, while
>> in a logistic model with glmer, significances for z-values are shown. Where
>> does this difference come from? Does it mean, that the problem of computing
>> the "right" nr. of degrees of freedom for the t-values of a linear model
>> does not exits (or is less of a problem) for non-linear models? Are the
>> significances that glmer produces (at least in case of logistic regression)
>> based on the Wald statistic or may be on an LRT test? Thanks for any
>> explanation!
>>
>> Ben.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
>


From bbolker at gmail.com  Mon Apr 25 19:43:27 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 25 Apr 2016 13:43:27 -0400
Subject: [R-sig-ME] (no) significance value (gl)mer
In-Reply-To: <CAE5vbrtY-+vh+uFjEFZKsq5vrLik1+qHQJNVsGCdi353O3J=fw@mail.gmail.com>
References: <CAGwfgc6uN05Xf5q=rMfwzXR0zoFK2YtK9dJtn4GnraAEfxPr7A@mail.gmail.com>
	<571E2124.80202@maw.ru.nl>
	<CAE5vbrtY-+vh+uFjEFZKsq5vrLik1+qHQJNVsGCdi353O3J=fw@mail.gmail.com>
Message-ID: <571E573F.1080803@gmail.com>


  For what it's worth, I've lately been playing with the FAQ; a (*very*
slightly) updated version is at
https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.html  (source
at https://github.com/bbolker/mixedmodels-misc/blob/master/glmmFAQ.rmd ).
   At some point when I think the new version is sufficiently improved
over the old one to warrant it, I'll replace the old (wikidot.com)
version with a pointer to the Github repo.

  Comments (and pull requests) welcome!



On 16-04-25 10:27 AM, Marko Bachl wrote:
> Dear Ben,
> Just a short info, others may have something more substantial to add.
> 
> You will find plenty of information on significance tests and
> inference in lme4 in the top sections of this website:
> http://glmm.wikidot.com/faq.
> A short info inside the lme4 package is given by
> require(lme4)
> ?pvalues
> 
> Best,
> Marko
> 
> 
> 
> 
> 
> 2016-04-25 15:52 GMT+02:00 Ben Pelzer <b.pelzer at maw.ru.nl>:
>> Dear list,
>>
>> In lmer, no significances for the t-values of fixed effects are given, while
>> in a logistic model with glmer, significances for z-values are shown. Where
>> does this difference come from? Does it mean, that the problem of computing
>> the "right" nr. of degrees of freedom for the t-values of a linear model
>> does not exits (or is less of a problem) for non-linear models? Are the
>> significances that glmer produces (at least in case of logistic regression)
>> based on the Wald statistic or may be on an LRT test? Thanks for any
>> explanation!
>>
>> Ben.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
>


From b.pelzer at maw.ru.nl  Mon Apr 25 21:40:00 2016
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Mon, 25 Apr 2016 21:40:00 +0200
Subject: [R-sig-ME] (no) significance value (gl)mer
In-Reply-To: <571E573F.1080803@gmail.com>
References: <CAGwfgc6uN05Xf5q=rMfwzXR0zoFK2YtK9dJtn4GnraAEfxPr7A@mail.gmail.com>
	<571E2124.80202@maw.ru.nl>
	<CAE5vbrtY-+vh+uFjEFZKsq5vrLik1+qHQJNVsGCdi353O3J=fw@mail.gmail.com>
	<571E573F.1080803@gmail.com>
Message-ID: <571E7290.6000801@maw.ru.nl>

Dear Milly, Marko and Ben,

Thanks a lot for your replies and pointing me to these packages, great! 
Kind regards,

Ben.


On 25-4-2016 19:43, Ben Bolker wrote:
>    For what it's worth, I've lately been playing with the FAQ; a (*very*
> slightly) updated version is at
> https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.html  (source
> at https://github.com/bbolker/mixedmodels-misc/blob/master/glmmFAQ.rmd ).
>     At some point when I think the new version is sufficiently improved
> over the old one to warrant it, I'll replace the old (wikidot.com)
> version with a pointer to the Github repo.
>
>    Comments (and pull requests) welcome!
>
>
>
> On 16-04-25 10:27 AM, Marko Bachl wrote:
>> Dear Ben,
>> Just a short info, others may have something more substantial to add.
>>
>> You will find plenty of information on significance tests and
>> inference in lme4 in the top sections of this website:
>> http://glmm.wikidot.com/faq.
>> A short info inside the lme4 package is given by
>> require(lme4)
>> ?pvalues
>>
>> Best,
>> Marko
>>
>>
>>
>>
>>
>> 2016-04-25 15:52 GMT+02:00 Ben Pelzer <b.pelzer at maw.ru.nl>:
>>> Dear list,
>>>
>>> In lmer, no significances for the t-values of fixed effects are given, while
>>> in a logistic model with glmer, significances for z-values are shown. Where
>>> does this difference come from? Does it mean, that the problem of computing
>>> the "right" nr. of degrees of freedom for the t-values of a linear model
>>> does not exits (or is less of a problem) for non-linear models? Are the
>>> significances that glmer produces (at least in case of logistic regression)
>>> based on the Wald statistic or may be on an LRT test? Thanks for any
>>> explanation!
>>>
>>> Ben.
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From adriana.guevara.rukoz at ens.fr  Tue Apr 26 18:19:45 2016
From: adriana.guevara.rukoz at ens.fr (Adriana Guevara Rukoz)
Date: Tue, 26 Apr 2016 18:19:45 +0200
Subject: [R-sig-ME] MCMCglmm interpretation with contrast coding and
 multinomial IVs and DV
Message-ID: <571F9521.70004@ens.fr>

Dear all,

I would like to analyze some data from an identification task, in which 
subjects hear a V1h[V2]pV1 stimulus (e.g. ah[i]pa), where [V2] 
designates the coarticulation within the /hp/ cluster (V1 != V2 when the 
stimuli have been spliced). Subjects are asked what vowel they perceived 
between the consonants of the cluster (vowel epenthesis).

In particular, I'm interested in the relative contributions of V1 and V2 
on the choice of each response vowel (e.g., do subjects choose /i/ more 
often than other vowels when V1=/i/? Even more or less so when 
COART=[i]? Which contribution is more important between V1 and V2 for 
each vowel?)

First, here is a recap of my variables (baseline = u ; as that is the 
"default" epenthetic vowel):

** RV: *
- RESP (categorical, 5 levels): {u, o, i, e, a}
** IV: *
- V1 (categorical, 5 levels): {u, o, i, e, a} - sum-contrast coded
- V2, henceforth named COART for easier reading, (categorical, 5 
levels): {u, o, i, e, a} - sum-contrast coded
** Random effects: *subject id (SUBJ), item id (ITEM).

Which gives me the following model:

k <- length(levels(h.epenth$RESP))
I <- diag(k-1)
J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))

prior3 = list(R = list(fix=1, V=(1/k) * (I + J), n = k),
               G = list(G1=list(V = diag(k-1), n = k),
                        G1=list(V = diag(k-1), n = k)))

mh1 <- MCMCglmm(RESP ~  - 1 + trait + V1:trait + COART:trait,
                random = ~us(trait):SUBJ + us(trait):ITEM,
                rcov = ~ us(trait):units,
                prior = prior3,
                burnin = nburnin,
                nitt = nnitt,
                thin = nthin,
                family="categorical",
                data=epenth)

I'm currently running the model on pilot data and with 20000 iterations 
only, so the actual values of the estimated coefficients are not 
important, but here is the output from summary(mh1), for location effects:

Location effects: RESP ~ -1 + trait + V1:trait + COART:trait

                    post.mean  l-95% CI  u-95% CI eff.samp pMCMC
traitRESP.o         -3.59168  -6.51885  -0.40005   340.00 0.03529 *
traitRESP.i         -6.97617 -10.20436  -3.63351   340.00 < 0.003 **
traitRESP.e         -7.58867 -10.16525  -4.44600    17.06 < 0.003 **
traitRESP.a         -6.32136  -8.75020  -3.92369   170.22 < 0.003 **
----
traitRESP.o:V1o      0.96720  -1.91595   4.68645    57.00 0.57059
traitRESP.i:V1o      0.34601  -3.13529   3.65788   275.27 0.81176
traitRESP.e:V1o      0.01064  -2.31169   2.48395   179.78 0.94706
traitRESP.a:V1o     -0.08993  -2.52314   2.14315   134.33 0.97059
traitRESP.o:V1i     -0.57546  -3.82799   2.97239    18.85 0.81765
traitRESP.i:V1i      5.34557   2.23693   8.74984   398.06 0.01176 *
traitRESP.e:V1i      2.43926   0.20358   5.15729    68.81 0.07059 .
traitRESP.a:V1i      1.65012  -1.21129   3.84189   177.83 0.17647
traitRESP.o:V1e     -1.16602  -4.16428   2.01458    86.38 0.46471
traitRESP.i:V1e      4.68686   1.38014   7.48422   202.13 < 0.003 **
traitRESP.e:V1e      5.03065   2.33411   7.25455    17.88 < 0.003 **
traitRESP.a:V1e      0.55748  -2.02347   3.63707     4.68 0.74706
traitRESP.o:V1a     -0.49801  -4.05488   2.82815   340.00 0.78824
traitRESP.i:V1a      1.20223  -2.48158   4.27902   252.94 0.53529
traitRESP.e:V1a      1.41483  -1.13591   3.77316   254.96 0.28235
traitRESP.a:V1a      3.04426   0.49008   5.59015   340.00 0.01765 *
----
traitRESP.o:COARTo  -0.30663  -3.86220   2.94796   287.64 0.88824
traitRESP.i:COARTo   0.92669  -2.28283   4.60833   340.00 0.56471
traitRESP.e:COARTo  -0.05533  -2.61372   2.40955   140.88 0.96471
traitRESP.a:COARTo   0.13161  -2.46333   2.22642   340.00 0.92353
traitRESP.o:COARTi  -1.37804  -5.35041   1.66590    51.21 0.42353
traitRESP.i:COARTi   5.54896   1.53047   8.69056   340.00 0.00588 **
traitRESP.e:COARTi   2.37792  -0.33337   4.73054   340.00 0.08824 .
traitRESP.a:COARTi   0.59577  -1.90546   2.99576   175.13 0.61176
traitRESP.o:COARTe  -1.90106  -5.67091   1.52474    33.76 0.33529
traitRESP.i:COARTe   5.57507   2.15612   8.66226   340.00 0.00588 **
traitRESP.e:COARTe   2.44821  -0.28758   4.69727   340.00 0.05882 .
traitRESP.a:COARTe   0.53713  -1.72573   2.66476   340.00 0.64118
traitRESP.o:COARTa  -1.16952  -4.53311   2.54438    45.44 0.52353
traitRESP.i:COARTa   0.96946  -3.23285   4.17157   206.69 0.61765
traitRESP.e:COARTa   0.76110  -1.74846   3.68853   340.00 0.54118
traitRESP.a:COARTa   1.98751  -0.73148   4.65783    29.15 0.15294

1) Knowing that I sum-contrast coded the independent variables V1 and 
COART, is it correct for me to interpret
                                post.mean l-95% CI  u-95% CI eff.samp   
pMCMC
/traitRESP.i:COARTe   5.57507 2.15612   8.66226   340.00 0.00588 **
/as: "there is a significant increase in "i" responses relative to "u" 
responses when the coarticulation in the cluster (i.e. COART) is [e], 
for an 'average' V1" (as opposed to only comparing the change in  "i" vs 
"u"  responses when going from uh[u]pu to uh[e]pu, since /u/ is the 
baseline for V1 and COART)

2) Following up on this, would contrast coding the response variable 
RESP (if there is any sense in doing that, model-wise) allow me to 
change the statement above to:  "there is a significant increase in "i" 
responses relative to any other response vowel when the coarticulation 
in the cluster (i.e. COART) is [e], for an 'average' V1", or does the 
trait always take "u" as a baseline?

3) Also, I guess I am a confused about how to interpret the significance 
codes. Basically, for
                    post.mean  l-95% CI  u-95% CI eff.samp   pMCMC
traitRESP.o         -3.59168  -6.51885  -0.40005   340.00 0.03529 *
traitRESP.i         -6.97617 -10.20436  -3.63351   340.00 < 0.003 **
traitRESP.e         -7.58867 -10.16525  -4.44600    17.06 < 0.003 **
traitRESP.a         -6.32136  -8.75020  -3.92369   170.22 < 0.003 **
I understand this as: subjects responded "u" significantly more often 
than "o", "i", "e" and "a", in general (because of contrast coding). Is 
this correct?
If so, are these significance tests "independent" from the significance 
testing for V1:trait and for COART:trait?

I hope that my explanations are not too unclear...

Thank you in advance for your help!

Best,
Adriana

-- 
Adriana Guevara Rukoz

PhD Student
Laboratoire de Sciences Cognitives et Psycholinguistique
?cole Normale Sup?rieure
29 rue d?Ulm
75005 Paris, France


	[[alternative HTML version deleted]]


From DCher at si-bone.com  Tue Apr 26 20:36:57 2016
From: DCher at si-bone.com (Daniel Cher)
Date: Tue, 26 Apr 2016 18:36:57 +0000
Subject: [R-sig-ME] help with mixed modeling
Message-ID: <SN1PR0501MB184072CE747111E983B69578FC630@SN1PR0501MB1840.namprd05.prod.outlook.com>

I need help with a meta-analysis project. The fundamental design is this:

*          3 trials, 2 of which are randomized trials

*          Continuous outcome measure (pain score), assessed at multiple time intervals (see plot below).

*          I'd like to calculate the effect size across all time points in months 1 to 6 taking into account: 1) repeated measures within subjects, and 2) random effect across sites
 I'm an R programmer, and have used gls<https://stat.ethz.ch/R-manual/R-devel/library/nlme/html/gls.html> from the nlme package. However, I get quickly lost when it comes to LS means and appropriate covariance structures.
 I appreciate any advice or reference to a person who can help.

Daniel Cher, MD
Vice President of Clinical Affairs
Tel: 408-207-0700 x2233
Mob: 650-269-5763
FAX: 888-243-4502
dcher at si-bone.com<https://bl2prd0510.outlook.com/owa/redir.aspx?C=ZquXLWlJAUucgyZxRxKb4zmkXsdVH88IFjGENZQYTO-GuKZ_ASTriHzF7kSzRDs8HnsZfZz4H5Y.&URL=mailto%3adcher%40si-bone.com>

Notice: This message, including any attachments, may con...{{dropped:18}}


From saah500 at york.ac.uk  Wed Apr 27 10:38:35 2016
From: saah500 at york.ac.uk (Shadiya Al Hashmi)
Date: Wed, 27 Apr 2016 11:38:35 +0300
Subject: [R-sig-ME] Random slopes for 2 variables and random intercept for 1
	variable
Message-ID: <CACrevpkzwdc5r3LTBjo2EYL0mGFeO5fm2adT0jKBV6F7qONVqA@mail.gmail.com>

Good morning,


I have a data design which includes 3 factors of interest/*experimental
manipulations* (using Barr et. al?s (2013) terminology); namely *Listgp*
(listener group: T[monolinguals], TA [bilinguals] and TQ [Turkish speakers
who know Arabic through reading Quran]), *length* (long and short vowels)
and *context (emphatics, pharyngeals, plain and q)*.



*Listgp* is a *between-listener* (subject) and *within-stimulus* (item)
variable [(1|listener), (1+Listgp|stimulus)] while both *length* and
*context* are *within-listener* and *between-stimulus* variables
[(1+length|listener), (1|stimulus) and (1+context|listener), (1|stimulus)].



My question is, how can I code this in the following maximal model lacking
the random effects (for the time being?



maxmodal<- glmer(match ~ Listgp + length + context + gender + age + freq.,
data = msba, family = "binomial", control = glmerControl(optimizer =
"bobyqa"), nAGQ =1)



Here is more information on the variables involved.

*DV/Y (response):* match

*Random effects:* listener and stimulus

*Fixed effects/predictors:* a) *By-listener predictors*+ b) *by-stimulus
predictors: *

*a) By-listener predictors:* (*3*)

*1. Factors: (2)*

-*Listgp* (listener group): effect of interest (T: monolingual Turkish
speakers, TA: bilingual Turkish speakers and TQ: Turkish speakers who know
Arabic through reading Quran).)

-*gender* (female and male)



*2. Continuous predictors (1)*

-*age *(age of listeners at the time of experiment)



*b) By-stimulus predictors: (3)*

*1. Factors: (2)_*

-* context *(stimulus context: emphatic, pharyngeal, plain and q)

-*length *(stimulus length: long and short)

*2. Continuous predictors: (1)*

-*freq*. (stimulus frequency as per arabiCorpus)

Number of obs: 1224, groups:  listener, 51; stimulus, 24





Appreciating your kind input.

-- 
Shad

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Wed Apr 27 10:45:19 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 27 Apr 2016 10:45:19 +0200
Subject: [R-sig-ME] Random slopes for 2 variables and random intercept
 for 1 variable
In-Reply-To: <CACrevpkzwdc5r3LTBjo2EYL0mGFeO5fm2adT0jKBV6F7qONVqA@mail.gmail.com>
References: <CACrevpkzwdc5r3LTBjo2EYL0mGFeO5fm2adT0jKBV6F7qONVqA@mail.gmail.com>
Message-ID: <CAJuCY5wPQopQor=Tueyyqg6SihUo5de1bafi78DC5roxLyH4Uw@mail.gmail.com>

Dear Shadiya,

glmer() requires at least one random effect. You can use glm() to fit the
model without random effects.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-04-27 10:38 GMT+02:00 Shadiya Al Hashmi <saah500 at york.ac.uk>:

> Good morning,
>
>
> I have a data design which includes 3 factors of interest/*experimental
> manipulations* (using Barr et. al?s (2013) terminology); namely *Listgp*
> (listener group: T[monolinguals], TA [bilinguals] and TQ [Turkish speakers
> who know Arabic through reading Quran]), *length* (long and short vowels)
> and *context (emphatics, pharyngeals, plain and q)*.
>
>
>
> *Listgp* is a *between-listener* (subject) and *within-stimulus* (item)
> variable [(1|listener), (1+Listgp|stimulus)] while both *length* and
> *context* are *within-listener* and *between-stimulus* variables
> [(1+length|listener), (1|stimulus) and (1+context|listener), (1|stimulus)].
>
>
>
> My question is, how can I code this in the following maximal model lacking
> the random effects (for the time being?
>
>
>
> maxmodal<- glmer(match ~ Listgp + length + context + gender + age + freq.,
> data = msba, family = "binomial", control = glmerControl(optimizer =
> "bobyqa"), nAGQ =1)
>
>
>
> Here is more information on the variables involved.
>
> *DV/Y (response):* match
>
> *Random effects:* listener and stimulus
>
> *Fixed effects/predictors:* a) *By-listener predictors*+ b) *by-stimulus
> predictors: *
>
> *a) By-listener predictors:* (*3*)
>
> *1. Factors: (2)*
>
> -*Listgp* (listener group): effect of interest (T: monolingual Turkish
> speakers, TA: bilingual Turkish speakers and TQ: Turkish speakers who know
> Arabic through reading Quran).)
>
> -*gender* (female and male)
>
>
>
> *2. Continuous predictors (1)*
>
> -*age *(age of listeners at the time of experiment)
>
>
>
> *b) By-stimulus predictors: (3)*
>
> *1. Factors: (2)_*
>
> -* context *(stimulus context: emphatic, pharyngeal, plain and q)
>
> -*length *(stimulus length: long and short)
>
> *2. Continuous predictors: (1)*
>
> -*freq*. (stimulus frequency as per arabiCorpus)
>
> Number of obs: 1224, groups:  listener, 51; stimulus, 24
>
>
>
>
>
> Appreciating your kind input.
>
> --
> Shad
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From saah500 at york.ac.uk  Wed Apr 27 11:17:39 2016
From: saah500 at york.ac.uk (Shadiya Al Hashmi)
Date: Wed, 27 Apr 2016 12:17:39 +0300
Subject: [R-sig-ME] Random slopes for 2 variables and random intercept
 for 1 variable
In-Reply-To: <CAJuCY5wPQopQor=Tueyyqg6SihUo5de1bafi78DC5roxLyH4Uw@mail.gmail.com>
References: <CACrevpkzwdc5r3LTBjo2EYL0mGFeO5fm2adT0jKBV6F7qONVqA@mail.gmail.com>
	<CAJuCY5wPQopQor=Tueyyqg6SihUo5de1bafi78DC5roxLyH4Uw@mail.gmail.com>
Message-ID: <CACrevpnbgY8b=a3UEJWpJsVHuyFJ6CKmH3sWFJFFCp1=jXEHHg@mail.gmail.com>

Thanks Thierry but I need the random effects in the model since I am
working within a generalized mixed effects model. That's why I used glmer.

The reason why I didn't include the random effects in the model is that I
wasn't sure of how to translate the slopes and intercepts of the variables.

Two ways I could think of, however, are as follows.

maxmodal<- glmer(match ~ Listgp + length + context + gender + age + freq. +
(0-Listgp|listener), (1+length|listener)+(1+context|listener),
(1+Listgp|stimulus), (0-length|stimulus), (0-context|stimulus), data =
msba, family = "binomial", control = glmerControl(optimizer =
"bobyqa"), nAGQ =1)

maxmodal<- glmer(match ~ Listgp + length + context + gender + age + freq. +
(1-Listgp|listener), (1+length|listener)+(1+context|listener),
(1+Listgp|stimulus), (1-length|stimulus), (1-context|stimulus), data =
msba, family = "binomial", control = glmerControl(optimizer =
"bobyqa"), nAGQ =1)


However, I am not sure either is the right way to go about it.

Best wishes,

Shad

On 27 April 2016 at 11:45, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Shadiya,
>
> glmer() requires at least one random effect. You can use glm() to fit the
> model without random effects.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2016-04-27 10:38 GMT+02:00 Shadiya Al Hashmi <saah500 at york.ac.uk>:
>
>> Good morning,
>>
>>
>> I have a data design which includes 3 factors of interest/*experimental
>> manipulations* (using Barr et. al?s (2013) terminology); namely *Listgp*
>> (listener group: T[monolinguals], TA [bilinguals] and TQ [Turkish speakers
>> who know Arabic through reading Quran]), *length* (long and short vowels)
>> and *context (emphatics, pharyngeals, plain and q)*.
>>
>>
>>
>> *Listgp* is a *between-listener* (subject) and *within-stimulus* (item)
>> variable [(1|listener), (1+Listgp|stimulus)] while both *length* and
>> *context* are *within-listener* and *between-stimulus* variables
>> [(1+length|listener), (1|stimulus) and (1+context|listener),
>> (1|stimulus)].
>>
>>
>>
>> My question is, how can I code this in the following maximal model lacking
>> the random effects (for the time being?
>>
>>
>>
>> maxmodal<- glmer(match ~ Listgp + length + context + gender + age + freq.,
>> data = msba, family = "binomial", control = glmerControl(optimizer =
>> "bobyqa"), nAGQ =1)
>>
>>
>>
>> Here is more information on the variables involved.
>>
>> *DV/Y (response):* match
>>
>> *Random effects:* listener and stimulus
>>
>> *Fixed effects/predictors:* a) *By-listener predictors*+ b) *by-stimulus
>> predictors: *
>>
>> *a) By-listener predictors:* (*3*)
>>
>> *1. Factors: (2)*
>>
>> -*Listgp* (listener group): effect of interest (T: monolingual Turkish
>> speakers, TA: bilingual Turkish speakers and TQ: Turkish speakers who know
>> Arabic through reading Quran).)
>>
>> -*gender* (female and male)
>>
>>
>>
>> *2. Continuous predictors (1)*
>>
>> -*age *(age of listeners at the time of experiment)
>>
>>
>>
>> *b) By-stimulus predictors: (3)*
>>
>> *1. Factors: (2)_*
>>
>> -* context *(stimulus context: emphatic, pharyngeal, plain and q)
>>
>> -*length *(stimulus length: long and short)
>>
>> *2. Continuous predictors: (1)*
>>
>> -*freq*. (stimulus frequency as per arabiCorpus)
>>
>> Number of obs: 1224, groups:  listener, 51; stimulus, 24
>>
>>
>>
>>
>>
>> Appreciating your kind input.
>>
>> --
>> Shad
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Wed Apr 27 11:21:54 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 27 Apr 2016 11:21:54 +0200
Subject: [R-sig-ME] Random slopes for 2 variables and random intercept
 for 1 variable
In-Reply-To: <CACrevpnbgY8b=a3UEJWpJsVHuyFJ6CKmH3sWFJFFCp1=jXEHHg@mail.gmail.com>
References: <CACrevpkzwdc5r3LTBjo2EYL0mGFeO5fm2adT0jKBV6F7qONVqA@mail.gmail.com>
	<CAJuCY5wPQopQor=Tueyyqg6SihUo5de1bafi78DC5roxLyH4Uw@mail.gmail.com>
	<CACrevpnbgY8b=a3UEJWpJsVHuyFJ6CKmH3sWFJFFCp1=jXEHHg@mail.gmail.com>
Message-ID: <CAJuCY5xhbegW3wwNEPMuOyHw_MKRcZybRsCZRwnZabQaDU-6dw@mail.gmail.com>

Dear Shad,

Your question isn't very clear. You'll need to tell use which random slopes
you want to add to the model.

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-04-27 11:17 GMT+02:00 Shadiya Al Hashmi <saah500 at york.ac.uk>:

> Thanks Thierry but I need the random effects in the model since I am
> working within a generalized mixed effects model. That's why I used glmer.
>
> The reason why I didn't include the random effects in the model is that I
> wasn't sure of how to translate the slopes and intercepts of the variables.
>
> Two ways I could think of, however, are as follows.
>
> maxmodal<- glmer(match ~ Listgp + length + context + gender + age + freq.
> + (0-Listgp|listener), (1+length|listener)+(1+context|listener),
> (1+Listgp|stimulus), (0-length|stimulus), (0-context|stimulus), data =
> msba, family = "binomial", control = glmerControl(optimizer =
> "bobyqa"), nAGQ =1)
>
> maxmodal<- glmer(match ~ Listgp + length + context + gender + age + freq.
> + (1-Listgp|listener), (1+length|listener)+(1+context|listener),
> (1+Listgp|stimulus), (1-length|stimulus), (1-context|stimulus), data =
> msba, family = "binomial", control = glmerControl(optimizer =
> "bobyqa"), nAGQ =1)
>
>
> However, I am not sure either is the right way to go about it.
>
> Best wishes,
>
> Shad
>
> On 27 April 2016 at 11:45, Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>
>> Dear Shadiya,
>>
>> glmer() requires at least one random effect. You can use glm() to fit the
>> model without random effects.
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2016-04-27 10:38 GMT+02:00 Shadiya Al Hashmi <saah500 at york.ac.uk>:
>>
>>> Good morning,
>>>
>>>
>>> I have a data design which includes 3 factors of interest/*experimental
>>> manipulations* (using Barr et. al?s (2013) terminology); namely *Listgp*
>>> (listener group: T[monolinguals], TA [bilinguals] and TQ [Turkish
>>> speakers
>>> who know Arabic through reading Quran]), *length* (long and short vowels)
>>> and *context (emphatics, pharyngeals, plain and q)*.
>>>
>>>
>>>
>>> *Listgp* is a *between-listener* (subject) and *within-stimulus* (item)
>>> variable [(1|listener), (1+Listgp|stimulus)] while both *length* and
>>> *context* are *within-listener* and *between-stimulus* variables
>>> [(1+length|listener), (1|stimulus) and (1+context|listener),
>>> (1|stimulus)].
>>>
>>>
>>>
>>> My question is, how can I code this in the following maximal model
>>> lacking
>>> the random effects (for the time being?
>>>
>>>
>>>
>>> maxmodal<- glmer(match ~ Listgp + length + context + gender + age +
>>> freq.,
>>> data = msba, family = "binomial", control = glmerControl(optimizer =
>>> "bobyqa"), nAGQ =1)
>>>
>>>
>>>
>>> Here is more information on the variables involved.
>>>
>>> *DV/Y (response):* match
>>>
>>> *Random effects:* listener and stimulus
>>>
>>> *Fixed effects/predictors:* a) *By-listener predictors*+ b) *by-stimulus
>>> predictors: *
>>>
>>> *a) By-listener predictors:* (*3*)
>>>
>>> *1. Factors: (2)*
>>>
>>> -*Listgp* (listener group): effect of interest (T: monolingual Turkish
>>> speakers, TA: bilingual Turkish speakers and TQ: Turkish speakers who
>>> know
>>> Arabic through reading Quran).)
>>>
>>> -*gender* (female and male)
>>>
>>>
>>>
>>> *2. Continuous predictors (1)*
>>>
>>> -*age *(age of listeners at the time of experiment)
>>>
>>>
>>>
>>> *b) By-stimulus predictors: (3)*
>>>
>>> *1. Factors: (2)_*
>>>
>>> -* context *(stimulus context: emphatic, pharyngeal, plain and q)
>>>
>>> -*length *(stimulus length: long and short)
>>>
>>> *2. Continuous predictors: (1)*
>>>
>>> -*freq*. (stimulus frequency as per arabiCorpus)
>>>
>>> Number of obs: 1224, groups:  listener, 51; stimulus, 24
>>>
>>>
>>>
>>>
>>>
>>> Appreciating your kind input.
>>>
>>> --
>>> Shad
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>
>
>
>

	[[alternative HTML version deleted]]


From saah500 at york.ac.uk  Wed Apr 27 11:32:42 2016
From: saah500 at york.ac.uk (Shadiya Al Hashmi)
Date: Wed, 27 Apr 2016 12:32:42 +0300
Subject: [R-sig-ME] Random slopes for 2 variables and random intercept
	for 1 variable
In-Reply-To: <CAJuCY5xhbegW3wwNEPMuOyHw_MKRcZybRsCZRwnZabQaDU-6dw@mail.gmail.com>
References: <CACrevpkzwdc5r3LTBjo2EYL0mGFeO5fm2adT0jKBV6F7qONVqA@mail.gmail.com>
	<CAJuCY5wPQopQor=Tueyyqg6SihUo5de1bafi78DC5roxLyH4Uw@mail.gmail.com>
	<CACrevpnbgY8b=a3UEJWpJsVHuyFJ6CKmH3sWFJFFCp1=jXEHHg@mail.gmail.com>
	<CAJuCY5xhbegW3wwNEPMuOyHw_MKRcZybRsCZRwnZabQaDU-6dw@mail.gmail.com>
Message-ID: <91F79067-AC6C-4531-87EB-27EB6CC50A30@york.ac.uk>

Dear Thierry,

Apologies if my question wasn't clear.

I need to add a slope for Listgp per stimulus, a slope for length per listener and a slope for context per listener. 

Listgp per listener is intercept only, length and context per stimulus per listener are both intercept only.

Hope this clarifies things.

Best wishes,

Shad

Sent from my iPhone

> On Apr 27, 2016, at 12:21 PM, Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
> 
> Dear Shad,
> 
> Your question isn't very clear. You'll need to tell use which random slopes you want to add to the model.
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest 
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance 
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner 
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
> 
> 2016-04-27 11:17 GMT+02:00 Shadiya Al Hashmi <saah500 at york.ac.uk>:
>> Thanks Thierry but I need the random effects in the model since I am working within a generalized mixed effects model. That's why I used glmer.
>> 
>> The reason why I didn't include the random effects in the model is that I wasn't sure of how to translate the slopes and intercepts of the variables.
>> 
>> Two ways I could think of, however, are as follows.
>> 
>> maxmodal<- glmer(match ~ Listgp + length + context + gender + age + freq. + (0-Listgp|listener), (1+length|listener)+(1+context|listener), (1+Listgp|stimulus), (0-length|stimulus), (0-context|stimulus), data = msba, family = "binomial", control = glmerControl(optimizer =
>> "bobyqa"), nAGQ =1)
>> 
>> maxmodal<- glmer(match ~ Listgp + length + context + gender + age + freq. + (1-Listgp|listener), (1+length|listener)+(1+context|listener), (1+Listgp|stimulus), (1-length|stimulus), (1-context|stimulus), data = msba, family = "binomial", control = glmerControl(optimizer =
>> "bobyqa"), nAGQ =1)
>> 
>> 
>> However, I am not sure either is the right way to go about it. 
>> 
>> Best wishes,
>> 
>> Shad
>> 
>>> On 27 April 2016 at 11:45, Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
>>> Dear Shadiya,
>>> 
>>> glmer() requires at least one random effect. You can use glm() to fit the model without random effects. 
>>> 
>>> Best regards,
>>> 
>>> ir. Thierry Onkelinx
>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest 
>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance 
>>> Kliniekstraat 25
>>> 1070 Anderlecht
>>> Belgium
>>> 
>>> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner 
>>> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
>>> 
>>> 2016-04-27 10:38 GMT+02:00 Shadiya Al Hashmi <saah500 at york.ac.uk>:
>>>> Good morning,
>>>> 
>>>> 
>>>> I have a data design which includes 3 factors of interest/*experimental
>>>> manipulations* (using Barr et. al?s (2013) terminology); namely *Listgp*
>>>> (listener group: T[monolinguals], TA [bilinguals] and TQ [Turkish speakers
>>>> who know Arabic through reading Quran]), *length* (long and short vowels)
>>>> and *context (emphatics, pharyngeals, plain and q)*.
>>>> 
>>>> 
>>>> 
>>>> *Listgp* is a *between-listener* (subject) and *within-stimulus* (item)
>>>> variable [(1|listener), (1+Listgp|stimulus)] while both *length* and
>>>> *context* are *within-listener* and *between-stimulus* variables
>>>> [(1+length|listener), (1|stimulus) and (1+context|listener), (1|stimulus)].
>>>> 
>>>> 
>>>> 
>>>> My question is, how can I code this in the following maximal model lacking
>>>> the random effects (for the time being?
>>>> 
>>>> 
>>>> 
>>>> maxmodal<- glmer(match ~ Listgp + length + context + gender + age + freq.,
>>>> data = msba, family = "binomial", control = glmerControl(optimizer =
>>>> "bobyqa"), nAGQ =1)
>>>> 
>>>> 
>>>> 
>>>> Here is more information on the variables involved.
>>>> 
>>>> *DV/Y (response):* match
>>>> 
>>>> *Random effects:* listener and stimulus
>>>> 
>>>> *Fixed effects/predictors:* a) *By-listener predictors*+ b) *by-stimulus
>>>> predictors: *
>>>> 
>>>> *a) By-listener predictors:* (*3*)
>>>> 
>>>> *1. Factors: (2)*
>>>> 
>>>> -*Listgp* (listener group): effect of interest (T: monolingual Turkish
>>>> speakers, TA: bilingual Turkish speakers and TQ: Turkish speakers who know
>>>> Arabic through reading Quran).)
>>>> 
>>>> -*gender* (female and male)
>>>> 
>>>> 
>>>> 
>>>> *2. Continuous predictors (1)*
>>>> 
>>>> -*age *(age of listeners at the time of experiment)
>>>> 
>>>> 
>>>> 
>>>> *b) By-stimulus predictors: (3)*
>>>> 
>>>> *1. Factors: (2)_*
>>>> 
>>>> -* context *(stimulus context: emphatic, pharyngeal, plain and q)
>>>> 
>>>> -*length *(stimulus length: long and short)
>>>> 
>>>> *2. Continuous predictors: (1)*
>>>> 
>>>> -*freq*. (stimulus frequency as per arabiCorpus)
>>>> 
>>>> Number of obs: 1224, groups:  listener, 51; stimulus, 24
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> Appreciating your kind input.
>>>> 
>>>> --
>>>> Shad
>>>> 
>>>>         [[alternative HTML version deleted]]
>>>> 
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Wed Apr 27 13:34:36 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 27 Apr 2016 13:34:36 +0200
Subject: [R-sig-ME] Random slopes for 2 variables and random intercept
 for 1 variable
In-Reply-To: <91F79067-AC6C-4531-87EB-27EB6CC50A30@york.ac.uk>
References: <CACrevpkzwdc5r3LTBjo2EYL0mGFeO5fm2adT0jKBV6F7qONVqA@mail.gmail.com>
	<CAJuCY5wPQopQor=Tueyyqg6SihUo5de1bafi78DC5roxLyH4Uw@mail.gmail.com>
	<CACrevpnbgY8b=a3UEJWpJsVHuyFJ6CKmH3sWFJFFCp1=jXEHHg@mail.gmail.com>
	<CAJuCY5xhbegW3wwNEPMuOyHw_MKRcZybRsCZRwnZabQaDU-6dw@mail.gmail.com>
	<91F79067-AC6C-4531-87EB-27EB6CC50A30@york.ac.uk>
Message-ID: <CAJuCY5wviOtcywH77zrVZB3Hci++trQR2icjhHbZ20hEcbLREQ@mail.gmail.com>

Adding (Listgp|stimulus) + (length + context|listener) to the formula would
add these slopes and their correlations.

Other options are possible. e.g. (0 + Listgp|stimulus) + (0 +
length|listener) + (0 + context |listener). Please have a look at
http://glmm.wikidot.com/faq and look for "Model specification etc." (0 +
x|group) is explained on that webpage.

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-04-27 11:32 GMT+02:00 Shadiya Al Hashmi <saah500 at york.ac.uk>:

> Dear Thierry,
>
> Apologies if my question wasn't clear.
>
> I need to add a slope for Listgp per stimulus, a slope for length per
> listener and a slope for context per listener.
>
> Listgp per listener is intercept only, length and context per stimulus per
> listener are both intercept only.
>
> Hope this clarifies things.
>
> Best wishes,
>
> Shad
>
> Sent from my iPhone
>
> On Apr 27, 2016, at 12:21 PM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>
> Dear Shad,
>
> Your question isn't very clear. You'll need to tell use which random
> slopes you want to add to the model.
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2016-04-27 11:17 GMT+02:00 Shadiya Al Hashmi <saah500 at york.ac.uk>:
>
>> Thanks Thierry but I need the random effects in the model since I am
>> working within a generalized mixed effects model. That's why I used glmer.
>>
>> The reason why I didn't include the random effects in the model is that I
>> wasn't sure of how to translate the slopes and intercepts of the variables.
>>
>> Two ways I could think of, however, are as follows.
>>
>> maxmodal<- glmer(match ~ Listgp + length + context + gender + age + freq.
>> + (0-Listgp|listener), (1+length|listener)+(1+context|listener),
>> (1+Listgp|stimulus), (0-length|stimulus), (0-context|stimulus), data =
>> msba, family = "binomial", control = glmerControl(optimizer =
>> "bobyqa"), nAGQ =1)
>>
>> maxmodal<- glmer(match ~ Listgp + length + context + gender + age + freq.
>> + (1-Listgp|listener), (1+length|listener)+(1+context|listener),
>> (1+Listgp|stimulus), (1-length|stimulus), (1-context|stimulus), data =
>> msba, family = "binomial", control = glmerControl(optimizer =
>> "bobyqa"), nAGQ =1)
>>
>>
>> However, I am not sure either is the right way to go about it.
>>
>> Best wishes,
>>
>> Shad
>>
>> On 27 April 2016 at 11:45, Thierry Onkelinx <thierry.onkelinx at inbo.be>
>> wrote:
>>
>>> Dear Shadiya,
>>>
>>> glmer() requires at least one random effect. You can use glm() to fit
>>> the model without random effects.
>>>
>>> Best regards,
>>>
>>> ir. Thierry Onkelinx
>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>> and Forest
>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>> Kliniekstraat 25
>>> 1070 Anderlecht
>>> Belgium
>>>
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of data.
>>> ~ John Tukey
>>>
>>> 2016-04-27 10:38 GMT+02:00 Shadiya Al Hashmi <saah500 at york.ac.uk>:
>>>
>>>> Good morning,
>>>>
>>>>
>>>> I have a data design which includes 3 factors of interest/*experimental
>>>> manipulations* (using Barr et. al?s (2013) terminology); namely *Listgp*
>>>> (listener group: T[monolinguals], TA [bilinguals] and TQ [Turkish
>>>> speakers
>>>> who know Arabic through reading Quran]), *length* (long and short
>>>> vowels)
>>>> and *context (emphatics, pharyngeals, plain and q)*.
>>>>
>>>>
>>>>
>>>> *Listgp* is a *between-listener* (subject) and *within-stimulus* (item)
>>>> variable [(1|listener), (1+Listgp|stimulus)] while both *length* and
>>>> *context* are *within-listener* and *between-stimulus* variables
>>>> [(1+length|listener), (1|stimulus) and (1+context|listener),
>>>> (1|stimulus)].
>>>>
>>>>
>>>>
>>>> My question is, how can I code this in the following maximal model
>>>> lacking
>>>> the random effects (for the time being?
>>>>
>>>>
>>>>
>>>> maxmodal<- glmer(match ~ Listgp + length + context + gender + age +
>>>> freq.,
>>>> data = msba, family = "binomial", control = glmerControl(optimizer =
>>>> "bobyqa"), nAGQ =1)
>>>>
>>>>
>>>>
>>>> Here is more information on the variables involved.
>>>>
>>>> *DV/Y (response):* match
>>>>
>>>> *Random effects:* listener and stimulus
>>>>
>>>> *Fixed effects/predictors:* a) *By-listener predictors*+ b) *by-stimulus
>>>> predictors: *
>>>>
>>>> *a) By-listener predictors:* (*3*)
>>>>
>>>> *1. Factors: (2)*
>>>>
>>>> -*Listgp* (listener group): effect of interest (T: monolingual Turkish
>>>> speakers, TA: bilingual Turkish speakers and TQ: Turkish speakers who
>>>> know
>>>> Arabic through reading Quran).)
>>>>
>>>> -*gender* (female and male)
>>>>
>>>>
>>>>
>>>> *2. Continuous predictors (1)*
>>>>
>>>> -*age *(age of listeners at the time of experiment)
>>>>
>>>>
>>>>
>>>> *b) By-stimulus predictors: (3)*
>>>>
>>>> *1. Factors: (2)_*
>>>>
>>>> -* context *(stimulus context: emphatic, pharyngeal, plain and q)
>>>>
>>>> -*length *(stimulus length: long and short)
>>>>
>>>> *2. Continuous predictors: (1)*
>>>>
>>>> -*freq*. (stimulus frequency as per arabiCorpus)
>>>>
>>>> Number of obs: 1224, groups:  listener, 51; stimulus, 24
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> Appreciating your kind input.
>>>>
>>>> --
>>>> Shad
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>>
>>
>>
>>
>>
>

	[[alternative HTML version deleted]]


From saah500 at york.ac.uk  Wed Apr 27 17:46:29 2016
From: saah500 at york.ac.uk (Shadiya Al Hashmi)
Date: Wed, 27 Apr 2016 18:46:29 +0300
Subject: [R-sig-ME] Random slopes for 2 variables and random intercept
 for 1 variable
In-Reply-To: <CAJuCY5wviOtcywH77zrVZB3Hci++trQR2icjhHbZ20hEcbLREQ@mail.gmail.com>
References: <CACrevpkzwdc5r3LTBjo2EYL0mGFeO5fm2adT0jKBV6F7qONVqA@mail.gmail.com>
	<CAJuCY5wPQopQor=Tueyyqg6SihUo5de1bafi78DC5roxLyH4Uw@mail.gmail.com>
	<CACrevpnbgY8b=a3UEJWpJsVHuyFJ6CKmH3sWFJFFCp1=jXEHHg@mail.gmail.com>
	<CAJuCY5xhbegW3wwNEPMuOyHw_MKRcZybRsCZRwnZabQaDU-6dw@mail.gmail.com>
	<91F79067-AC6C-4531-87EB-27EB6CC50A30@york.ac.uk>
	<CAJuCY5wviOtcywH77zrVZB3Hci++trQR2icjhHbZ20hEcbLREQ@mail.gmail.com>
Message-ID: <CACrevp=XT8VcQU8iX8Yd7Tm6drO7sDnGwGoawwYRQvNV2jDMwA@mail.gmail.com>

Many thanks indeed Thierry!

I tried both options, one with no variation in the intercept and another
with correlated intercept as in maxmodal1 and maxmodal1.1.
When I compared them using anova, the one with no variation in the
intercept was found to better fit the data.

> anova(maxmodal1, maxmodal1.1)
Data: msba
Models:
maxmodal1: match ~ Listgp + length + context + gender + age + freq. + (0 +
maxmodal1:     Listgp | stimulus) + (0 + length | listener) + (0 + context
|
maxmodal1:     listener)
maxmodal1.1: match ~ Listgp + length + context + gender + age + freq. +
(length +
maxmodal1.1:     context | listener) + (Listgp | stimulus)
            Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
maxmodal1   29 1169.5 1317.6 -555.73   1111.5
maxmodal1.1 31 1171.8 1330.2 -554.90   1109.8 1.6631      2     0.4354


My task now is to decide whether I need the one with or without variation
in the intercept!

Thanks again Thierry.

Best wishes,

Shad







On 27 April 2016 at 14:34, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Adding (Listgp|stimulus) + (length + context|listener) to the formula
> would add these slopes and their correlations.
>
> Other options are possible. e.g. (0 + Listgp|stimulus) + (0 +
> length|listener) + (0 + context |listener). Please have a look at
> http://glmm.wikidot.com/faq and look for "Model specification etc." (0 +
> x|group) is explained on that webpage.
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2016-04-27 11:32 GMT+02:00 Shadiya Al Hashmi <saah500 at york.ac.uk>:
>
>> Dear Thierry,
>>
>> Apologies if my question wasn't clear.
>>
>> I need to add a slope for Listgp per stimulus, a slope for length per
>> listener and a slope for context per listener.
>>
>> Listgp per listener is intercept only, length and context per stimulus
>> per listener are both intercept only.
>>
>> Hope this clarifies things.
>>
>> Best wishes,
>>
>> Shad
>>
>> Sent from my iPhone
>>
>> On Apr 27, 2016, at 12:21 PM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
>> wrote:
>>
>> Dear Shad,
>>
>> Your question isn't very clear. You'll need to tell use which random
>> slopes you want to add to the model.
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2016-04-27 11:17 GMT+02:00 Shadiya Al Hashmi <saah500 at york.ac.uk>:
>>
>>> Thanks Thierry but I need the random effects in the model since I am
>>> working within a generalized mixed effects model. That's why I used glmer.
>>>
>>> The reason why I didn't include the random effects in the model is that
>>> I wasn't sure of how to translate the slopes and intercepts of the
>>> variables.
>>>
>>> Two ways I could think of, however, are as follows.
>>>
>>> maxmodal<- glmer(match ~ Listgp + length + context + gender + age +
>>> freq. + (0-Listgp|listener), (1+length|listener)+(1+context|listener),
>>> (1+Listgp|stimulus), (0-length|stimulus), (0-context|stimulus), data =
>>> msba, family = "binomial", control = glmerControl(optimizer =
>>> "bobyqa"), nAGQ =1)
>>>
>>> maxmodal<- glmer(match ~ Listgp + length + context + gender + age +
>>> freq. + (1-Listgp|listener), (1+length|listener)+(1+context|listener),
>>> (1+Listgp|stimulus), (1-length|stimulus), (1-context|stimulus), data =
>>> msba, family = "binomial", control = glmerControl(optimizer =
>>> "bobyqa"), nAGQ =1)
>>>
>>>
>>> However, I am not sure either is the right way to go about it.
>>>
>>> Best wishes,
>>>
>>> Shad
>>>
>>> On 27 April 2016 at 11:45, Thierry Onkelinx <thierry.onkelinx at inbo.be>
>>> wrote:
>>>
>>>> Dear Shadiya,
>>>>
>>>> glmer() requires at least one random effect. You can use glm() to fit
>>>> the model without random effects.
>>>>
>>>> Best regards,
>>>>
>>>> ir. Thierry Onkelinx
>>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>>> and Forest
>>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>>> Kliniekstraat 25
>>>> 1070 Anderlecht
>>>> Belgium
>>>>
>>>> To call in the statistician after the experiment is done may be no more
>>>> than asking him to perform a post-mortem examination: he may be able to say
>>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>> The combination of some data and an aching desire for an answer does
>>>> not ensure that a reasonable answer can be extracted from a given body of
>>>> data. ~ John Tukey
>>>>
>>>> 2016-04-27 10:38 GMT+02:00 Shadiya Al Hashmi <saah500 at york.ac.uk>:
>>>>
>>>>> Good morning,
>>>>>
>>>>>
>>>>> I have a data design which includes 3 factors of interest/*experimental
>>>>> manipulations* (using Barr et. al?s (2013) terminology); namely
>>>>> *Listgp*
>>>>> (listener group: T[monolinguals], TA [bilinguals] and TQ [Turkish
>>>>> speakers
>>>>> who know Arabic through reading Quran]), *length* (long and short
>>>>> vowels)
>>>>> and *context (emphatics, pharyngeals, plain and q)*.
>>>>>
>>>>>
>>>>>
>>>>> *Listgp* is a *between-listener* (subject) and *within-stimulus* (item)
>>>>> variable [(1|listener), (1+Listgp|stimulus)] while both *length* and
>>>>> *context* are *within-listener* and *between-stimulus* variables
>>>>> [(1+length|listener), (1|stimulus) and (1+context|listener),
>>>>> (1|stimulus)].
>>>>>
>>>>>
>>>>>
>>>>> My question is, how can I code this in the following maximal model
>>>>> lacking
>>>>> the random effects (for the time being?
>>>>>
>>>>>
>>>>>
>>>>> maxmodal<- glmer(match ~ Listgp + length + context + gender + age +
>>>>> freq.,
>>>>> data = msba, family = "binomial", control = glmerControl(optimizer =
>>>>> "bobyqa"), nAGQ =1)
>>>>>
>>>>>
>>>>>
>>>>> Here is more information on the variables involved.
>>>>>
>>>>> *DV/Y (response):* match
>>>>>
>>>>> *Random effects:* listener and stimulus
>>>>>
>>>>> *Fixed effects/predictors:* a) *By-listener predictors*+ b)
>>>>> *by-stimulus
>>>>> predictors: *
>>>>>
>>>>> *a) By-listener predictors:* (*3*)
>>>>>
>>>>> *1. Factors: (2)*
>>>>>
>>>>> -*Listgp* (listener group): effect of interest (T: monolingual Turkish
>>>>> speakers, TA: bilingual Turkish speakers and TQ: Turkish speakers who
>>>>> know
>>>>> Arabic through reading Quran).)
>>>>>
>>>>> -*gender* (female and male)
>>>>>
>>>>>
>>>>>
>>>>> *2. Continuous predictors (1)*
>>>>>
>>>>> -*age *(age of listeners at the time of experiment)
>>>>>
>>>>>
>>>>>
>>>>> *b) By-stimulus predictors: (3)*
>>>>>
>>>>> *1. Factors: (2)_*
>>>>>
>>>>> -* context *(stimulus context: emphatic, pharyngeal, plain and q)
>>>>>
>>>>> -*length *(stimulus length: long and short)
>>>>>
>>>>> *2. Continuous predictors: (1)*
>>>>>
>>>>> -*freq*. (stimulus frequency as per arabiCorpus)
>>>>>
>>>>> Number of obs: 1224, groups:  listener, 51; stimulus, 24
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> Appreciating your kind input.
>>>>>
>>>>> --
>>>>> Shad
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>>
>>>>
>>>
>>>
>>>
>>>
>>
>


-- 
Shadiya al-Hashmi

PhD candidate
Department of Language & Linguistic Science
University of York, Heslington, York YO10 5DD
email: saah500 at york.ac.uk

	[[alternative HTML version deleted]]


From andrluis at ualberta.ca  Wed Apr 27 20:09:13 2016
From: andrluis at ualberta.ca (=?UTF-8?Q?Andr=C3=A9_Luis_Neves?=)
Date: Wed, 27 Apr 2016 12:09:13 -0600
Subject: [R-sig-ME] glmer error
Message-ID: <CAHxKz8bjBHUEF+C_Ny4g3TTaX1ajbSkT1EoycHDLtShU2nWE3g@mail.gmail.com>

Dear all:

I`m trying to fit a model using glmer from qPCR counts. The model is
running fine to all the variables (archaea, protozoa and fungi counts), but
not for bacteria, which have by far a larger population than the other
communities.

--------------------------
Here is the model:

M1 <- glmer (Baci ~ Starch + Crossover + (1|fID:Crossover) + Period, family
= gaussian(log), data=qPCR)

Here is the error:

'Error in (function (fr, X, reTrms, family, nAGQ = 1L, verbose = 0L, maxit
= 100L,  :Downdated VtV is not positive definite'

---------------------------

I have tried centering the continuous predictor variables and optimizing
the glmerControl
(for instance,optimizer="bobyqa",check.conv.grad=.makeCC("warning",2e-3)),
nAGQ = 10), but haven`t got anything.

Could anyone please help me to find a solution?

Thank you so much for your attention.

-- 
Andre

	[[alternative HTML version deleted]]


From carolina.magda.adm at gmail.com  Thu Apr 28 12:47:05 2016
From: carolina.magda.adm at gmail.com (Carolina Magda Roma)
Date: Thu, 28 Apr 2016 07:47:05 -0300
Subject: [R-sig-ME] How o treat time when using stocks and a growth model
	(longitudinal data)
Message-ID: <CACTi1UotcKWWcFsSy_T=vorDvzUc=iMQmzEt8p3LsnMfULPMNw@mail.gmail.com>

Hello,

I have been studying multilevel models to understand how I can use it to
investigate the behavior of stocks listed on a exchange. I am still very
new with this methodology so I would like to ask if its possible to do that
using growth model and how I should treat stocks that start to be traded in
different period (for instance, stock of company A is traded since 1998 and
stock of company B is traded since 2005).

Thank you for any help.


-- 
Carolina Magda

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu Apr 28 14:43:32 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 28 Apr 2016 08:43:32 -0400
Subject: [R-sig-ME] How o treat time when using stocks and a growth
 model (longitudinal data)
In-Reply-To: <CACTi1UotcKWWcFsSy_T=vorDvzUc=iMQmzEt8p3LsnMfULPMNw@mail.gmail.com>
References: <CACTi1UotcKWWcFsSy_T=vorDvzUc=iMQmzEt8p3LsnMfULPMNw@mail.gmail.com>
Message-ID: <57220574.1040105@gmail.com>


  It's not entirely clear what you are trying to find out, but in
general having stocks traded at different periods shouldn't be a big
barrier.  A simple random-slope model with temporal autocorrelation
would look something like this:

   lme(log(value) ~ 1+year, random = ~1+company|year,
     correlation=corAR1(form=~year|company), data=stock_data)

Using lme() because lmer() still doesn't do autocorrelation easily.
You should probably center the year variable (i.e. for technical reasons
you don't want to have your intercept at Gregorian calendar year 0).

  I don't know much about financial modeling but I know that people use
much more sophisticated (e.g. GARCH) models; I don't know if anyone has
tried to do mixed GARCH models or not.  Probably.

On 16-04-28 06:47 AM, Carolina Magda Roma wrote:
> Hello,
> 
> I have been studying multilevel models to understand how I can use it to
> investigate the behavior of stocks listed on a exchange. I am still very
> new with this methodology so I would like to ask if its possible to do that
> using growth model and how I should treat stocks that start to be traded in
> different period (for instance, stock of company A is traded since 1998 and
> stock of company B is traded since 2005).
> 
> Thank you for any help.
> 
>


From highstat at highstat.com  Thu Apr 28 20:09:52 2016
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Thu, 28 Apr 2016 19:09:52 +0100
Subject: [R-sig-ME] New book: Beginner's Guide to Zero-Inflated Models with R
Message-ID: <572251F0.4070306@highstat.com>

We are pleased to announce the following book:

Title: Beginner's Guide to Zero-Inflated Models with R
Authors: Zuur, Ieno


Book website: http://www.highstat.com/BGZIM.htm
Paperback or EBook can be order (exclusively) from:
http://www.highstat.com/bookorder.htm
TOC: http://www.highstat.com/BGS/ZIM/pdfs/TOCOnly.pdf

Keywords: 430 pages. Zero inflated count data. Zero inflated continuous 
data. Zero inflated proportional data. Frequentist and Bayesian 
approaches. Random effects. Introduction to Bayesian statistics and 
MCMC. JAGS. Bayesian model selection. Multivariate GLMM.
R code and data sets available.


-----------------------------------------------------
Outline
The minimum prerequisite for Beginner's Guide to Zero-Inflated Models 
with R is knowledge of multiple linear regression, and in Chapter 2 we 
start with brief explanations of the Poisson, negative binomial, 
Bernoulli, binomial and gamma distributions. The motivation for doing 
this is that zero-inflated models consist of two distributions ?glued? 
together, one of which is the Bernoulli distribution. We begin Chapter 3 
with a brief revision of the Poisson generalised linear model (GLM) and 
the Bernoulli GLM, followed by a gentle introduction to zero-inflated 
Poisson (ZIP) models. Chapters 4 and 5 contain detailed case studies 
using count data of orange-crowned warblers and sharks. Just like all 
other chapters, these case studies are based on real datasets used in 
scientific papers.

In Chapter 6 we use zero-altered Poisson (ZAP) models to deal with the 
excessive number of zeros in count data. In Chapter 7 we analyse 
continuous data with a large number of zeros. Biomass of Chinese tallow 
trees is analysed with zero-altered gamma (ZAG) models.

In Chapter 8, which begins the second part of the book, we explain how 
to deal with dependency. Mixed models are introduced, using beaver and 
monkey datasets. In Chapter 9 we encounter a rather complicated dataset 
in terms of dependency. Reproductive indices are sampled from plants. 
But the seeds come from the same source and are planted in the same bed 
in the same garden. We apply models that take care of the excessive 
number of zeros in count data, crossed random effects and nested random 
effects.

Up to this point we have done everything in a frequentist setting, but 
at this stage of the book you will see that we are reaching the limit of 
what we can achieve with the frequentist software. For this reason we 
switch to Bayesian techniques in the third part of the book. Chapter 10 
contains an excellent beginner?s guide to Bayesian statistics and Markov 
Chain Monte Carlo (MCMC) techniques. The chapter also contains exercises 
and a video solution file for one of the exercises. This means that you 
can see our screen and listen to our voices (just in case you have 
trouble falling asleep at night). A large number of students reviewed 
this chapter and we incorporated their suggestions for improvement, so 
Chapter 10 should be very easy to understand.

In Chapter 11 we show how to implement the Poisson, negative binomial 
and ZIP models in MCMC. We do the same for mixed models in Chapter 12. 
In Chapter 13 we discuss a method, called the ?zero trick?, that allows 
you to fit nearly every distribution in JAGS.

A major stumbling block in Bayesian analysis is model selection. Chapter 
14 provides an easy-to-understand overview of various Bayesian model 
selection tools. Chapter 15 contains an example of Bayesian model 
selection using butterfly data.

In Chapter 16 we discuss methods for the analysis of proportional data 
(seagrass coverage time series) with a large number of zeros. We use a 
zero-altered beta model with nested random effects. Finally, in Chapters 
17 and 18 we discuss various topics, including multivariate GLMMs and 
generalised Poisson models (these can be used for underdispersion). We 
also discuss zero-inflated binomial models.
-----------------------------------------------------



-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From gaughra at tcd.ie  Fri Apr 29 16:55:35 2016
From: gaughra at tcd.ie (Aoibheann Gaughran)
Date: Fri, 29 Apr 2016 15:55:35 +0100
Subject: [R-sig-ME] Convergence Problems with glmer.nb model
In-Reply-To: <CAN=0SEnVLZzbQGTqVJDHgFqUAXZHWpz-sPwQv5TOO4fCz+oQ_A@mail.gmail.com>
References: <CAN=0SEkfdDsdiqmK51K0U4FYHyDhcsvWFLNTtbRJFL9oZXbF9g@mail.gmail.com>
	<CAN=0SEkTL+-UyXcpMRAQFwcCWvNJu+9ZR0wzBTHi+DXQ2JhKqg@mail.gmail.com>
	<CAJuCY5xLg1bN8A6-6oHQmQJgnDXTyDN+SvHJ1sRGtowP60DWzQ@mail.gmail.com>
	<CAN=0SEnVLZzbQGTqVJDHgFqUAXZHWpz-sPwQv5TOO4fCz+oQ_A@mail.gmail.com>
Message-ID: <CAN=0SEm4Kc5_9qtsxxqvYp=fEVe+mvXvpW1LpncHJhHXQtkb1w@mail.gmail.com>

Hi Thierry,

Apologies in the delay in reverting, I have been out on fieldwork. I have
tried your suggestions, but unfortunately am still having convergence
issues.  The most simple Poisson model runs fine, so I tried a negative
binomial distribution but that produced about 12 convergence warnings.

> modelA <- glmer.nb(field_count ~ (1|animal) + (1|field_id) + offset(log(origarea)), family = poisson, data = dframe2)

 There were 12 warnings (use warnings() to see them)

 > warnings()

Warning messages:

1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :
  Model failed to converge with max|grad| = 0.0493534 (tol = 0.001, component 1)

2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :
  Model failed to converge with max|grad| = 0.0627833 (tol = 0.001, component 1)

3: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :
  Model is nearly unidentifiable: very large eigenvalue - Rescale variables?

etc.


I reverted to the simple Poisson and added the OLR, which ran, but as soon
as I add any additional complexity/variables (apart from sex) it produces a
convergence warning.

Warning message:In checkConv(attr(opt, "derivs"), opt$par, ctrl =
control$checkConv,  :
  Model failed to converge with max|grad| = 0.0332321 (tol = 0.001, component 1)


I am not sure where to go from here. Any guidance would be much appreciated.

Kind regards,

Aoibheann



On 25 April 2016 at 14:44, Aoibheann Gaughran <gaughra at tcd.ie> wrote:

> Hi Thierry,
>
> Here is the dropbox link to the data -
> https://www.dropbox.com/s/ne5d4zp2gncwylm/foraging%20subset.csv?dl=0
>
> I had changed the field area units from meter square to hectures already,
> so that *should *be okay.  There is one exceedingly large "field" which
> is actually a large area of forestry. Perhaps this is throwing the scaling
> off.
>
> Can you confirm that this is how I specify the observation level random
> effect:
>
> dframe1$obs <- factor(seq(nrow(dframe1)))  #modified from https://rpubs.com/bbolker/glmmchapter
>
> which is included in the model as
>
> +(1|obs)
>
>
> I'll try your suggestions and see how I get on.
>
> Many thanks,
>
> Aoibheann
>
> On 25 April 2016 at 13:40, Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>
>> Dear Aoibheann,
>>
>> Two general suggestions on the design. 1) A random effect of field seems
>> relevant too. 2) Have the units of origarea in a relevant scale. You are
>> modelling the number of visits per unit of origarea. Then the number per
>> hectare seems more relevant to me than the number per square meter.
>>
>> Then try the most simple Poisson model to see it that converge. glmer(field_count
>> ~ (1| animal) + (1|field) + offset(log(origarea)), family = poisson)
>>
>> If that works, then you could try the negative binomial distribution or
>> adding an observation level random effect.
>>
>> The mailing list strips most attachments. So you need to put them on a
>> website or post a dropbox or google drive link.
>>
>> Best regards,
>>
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2016-04-25 14:08 GMT+02:00 Aoibheann Gaughran <gaughra at tcd.ie>:
>>
>>> On 25 April 2016 at 13:00, Aoibheann Gaughran <gaughra at tcd.ie> wrote:
>>>
>>> > Good morning,
>>> >
>>> > First time posting so I hope I am including all of the relevant
>>> > information.
>>> >
>>> > I am attempting to analyse the foraging behaviour of a animal in an
>>> > agricultural landscape. The objective is to identify the factors
>>> (habitat
>>> > type, environmental variables and animal-specific variables) that best
>>> > predict foraging site preference. Some fields are preferred while
>>> others
>>> > are avoided.
>>> >
>>> > The response variable is count data - the number of times a given
>>> animal
>>> > was in a given field in a given month. An animal's home range varies
>>> from
>>> > month to month, so the area available to it and the fields that fall
>>> within
>>> > its home range change somewhat every month. The count data shows an
>>> > overdispersed, negative binomial distribution, and is zero inflated as
>>> > fields that fell within the home range where the animal had *not
>>> *foraged
>>> > in that month are also included in the dataset. The individual animal
>>> is
>>> > specified as a random variable to account for pseudoreplication.
>>> >
>>> > It should be noted that at the moment I am attempting to run a the
>>> model
>>> > on a subset of the data (n=671) as I had attempted to run the model on
>>> the
>>> > full dataset (n=62,000) but three days later the model (which included
>>> > interaction terms at this point) had still failed to run, and when
>>> stopped,
>>> > R gave me a multitude of convergence warning messages e.g.
>>> >
>>> > 13: In (function (fn, par, lower = rep.int(-Inf, n), upper = rep.int
>>> (Inf,
>>> > ... :
>>> >   failure to converge in 10000 evaluations
>>> >
>>> > Simpler iterations of the model, with fewer explanatory terms, and no
>>> > interaction terms, also gave me convergence and some scaling warnings,
>>> > which I sought to address using:
>>> >
>>> > control=glmerControl(optCtrl=list(maxfun=20000)
>>> >
>>> > and by scaling the numeric variables age, slope and aspect as follows:-
>>> >
>>> > dframe1$agescale <- scale(dframe1$age, center = TRUE, scale = FALSE)
>>> > dframe1$slopescale <- scale(dframe1$slope, center = TRUE, scale =
>>> FALSE)
>>> > dframe1$aspectscale <- scale(dframe1$aspect, center = TRUE, scale =
>>> FALSE)
>>> >
>>> > Currently, the model looks like this:
>>> >
>>> > > model1 <- glmer.nb(field_count ~ habitat +                    +
>>> sex+                    + agescale+                    #+ mon+
>>>       + soil+                    + slopescale+                    +
>>> aspectscale+                    + offset(log(origarea)) #take into account
>>> field size +                    +(1|animal),+
>>> control=glmerControl(optCtrl=list(maxfun=20000)),+
>>> data = dframe1)
>>> >
>>> > There were 24 warnings (use warnings() to see them)
>>> > > warnings()Warning messages:
>>> > 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
>>> control$checkConv,  ... :
>>> >   Model is nearly unidentifiable: very large eigenvalue
>>> >  - Rescale variables?;Model is nearly unidentifiable: large eigenvalue
>>> ratio
>>> >  - Rescale variables?
>>> > 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
>>> control$checkConv,  ... :
>>> >   Model failed to converge with max|grad| = 0.0134799 (tol = 0.001,
>>> component 1)
>>> > 3: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
>>> control$checkConv,  ... :
>>> >   Model failed to converge with max|grad| = 0.148644 (tol = 0.001,
>>> component 1)
>>> > 4: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
>>> control$checkConv,  ... :
>>> >   Model is nearly unidentifiable: large eigenvalue ratio
>>> >  - Rescale variables?
>>> >
>>> > etc.
>>> >
>>> > So the model still fails to converge despite rescaling and altering the
>>> > number of iterations. I had also received the following error in
>>> relation
>>> > to month (in the reduced dataset there are only *four *months), so Ive
>>>
>>> > had to exclude it for the time being. I am not sure why I am getting
>>> this
>>> > error since the factor has four levels.
>>> >
>>> > Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
>>> > contrasts can be applied only to factors with 2 or more levels
>>> >
>>> > I do eventually want to include interaction terms as previous analysis
>>> on
>>> > ranging behaviour suggests there is an interaction between age and sex.
>>> >
>>> > Summary of dataset attached.  Also attached is the .csv file containing
>>> > the reduced dataset.
>>> >
>>> > I have read various suggestions online and have come across the
>>> following
>>> > worrying line "It's perfectly possible that your data is insufficient
>>> to
>>> > support the complexity of the model or the model is incorrectly
>>> constructed
>>> > for the design of the study".
>>> >
>>> > I would greatly appreciate any help you could give me with
>>> understanding
>>> > and solving the problems I am encountering with my model.
>>> >
>>> > Kind regards,
>>> >
>>> > --
>>> > Aoibheann Gaughran
>>> >
>>> > Behavioural and Evolutionary Ecology Research Group
>>> > Zoology Building
>>> > School of Natural Sciences
>>> > Trinity College Dublin
>>> > Dublin 2
>>> > Ireland
>>> > Phone: +353 (86) 3812615
>>> >
>>>
>>>
>>>
>>> --
>>> Aoibheann Gaughran
>>>
>>> Behavioural and Evolutionary Ecology Research Group
>>> Zoology Building
>>> School of Natural Sciences
>>> Trinity College Dublin
>>> Dublin 2
>>> Ireland
>>> Phone: +353 (86) 3812615
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>
>
> --
> Aoibheann Gaughran
>
> Behavioural and Evolutionary Ecology Research Group
> Zoology Building
> School of Natural Sciences
> Trinity College Dublin
> Dublin 2
> Ireland
> Phone: +353 (86) 3812615
>



-- 
Aoibheann Gaughran

Behavioural and Evolutionary Ecology Research Group
Zoology Building
School of Natural Sciences
Trinity College Dublin
Dublin 2
Ireland
Phone: +353 (86) 3812615

	[[alternative HTML version deleted]]


From chriscrewbaker at gmail.com  Sat Apr 30 20:36:18 2016
From: chriscrewbaker at gmail.com (Christopher Baker)
Date: Sat, 30 Apr 2016 11:36:18 -0700
Subject: [R-sig-ME] Leave list
Message-ID: <CAFpFX3K4bQjnBqeS1RDDG0Xipf979RRiVEJQat74Jxu0ttc8GA@mail.gmail.com>

Hi, I would like to stop receiving emails from this list. My email is
chriscrewbaker at gmail.com

Thanks,
Chris

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Sat Apr 30 20:36:44 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 30 Apr 2016 14:36:44 -0400
Subject: [R-sig-ME] Leave list
In-Reply-To: <CAFpFX3K4bQjnBqeS1RDDG0Xipf979RRiVEJQat74Jxu0ttc8GA@mail.gmail.com>
References: <CAFpFX3K4bQjnBqeS1RDDG0Xipf979RRiVEJQat74Jxu0ttc8GA@mail.gmail.com>
Message-ID: <5724FB3C.3000700@gmail.com>


  The link for subscription management etc.,
<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>, is posted at
the bottom of every mailing list post.  Please go to that URL and scroll
to the bottom for directions about unsubscribing.

On 16-04-30 02:36 PM, Christopher Baker wrote:
> Hi, I would like to stop receiving emails from this list. My email is
> chriscrewbaker at gmail.com
> 
> Thanks,
> Chris
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From robgriffin247 at hotmail.com  Sun May  1 21:47:55 2016
From: robgriffin247 at hotmail.com (Rob Griffin)
Date: Sun, 1 May 2016 21:47:55 +0200
Subject: [R-sig-ME] design matrix for R2
Message-ID: <DUB124-W24EB94E79733F46CEC9FDCFA780@phx.gbl>

Dear list,
I am trying to implement the R2 method of Nakagawa and Schielzeth for a model in lme4 but having problems. Using the documentation provided with the paper (including R script and dummy data: http://onlinelibrary.wiley.com/doi/10.1111/j.2041-210x.2012.00261.x/suppinfo) I run in to the same problem as when I try it on my own data. The full script from supplementary file S4 is pasted at the end of this message for the first example in the paper (I've slightly modified to make self contained dummy data and dropping the "Condition" variable from the model, which is absent from the dummy data file [S1] and not mentioned in the paper). The issue arises when running:
> Fixed <- fixef(mF)[2] * mF at X[, 2] + fixef(mF)[3] * mF at X[, 3] + fixef(mF)[4] * mF at X[, 4]Error: no slot of name "X" for this object of class "lmerMod"
My suspicion is that there has been a change in the structure of the models in lmer such that "mF at X" no longer relates to the design matrix, but reading the latest lme4 documentation I can't solve the issue... any suggestions? I'm using R version 3.2.4 (2016-03-16), and lme4 version 1.1-12.
Many thanks,Robert
-----
# Clear memoryrm(list = ls())
# Read body length data (Gaussian, available for both sexes)Data <- data.frame(rep(1:12, each = 80), rep(1:120, each = 8), rep(c("Female","Male"), each = 8), rep(c("A","B"), each = 4), rep(c("Cont","Exp")), rep(sample(c(9,10,11), replace=T, size = 120), each = 8)+rnorm(960,0,0.5))colnames(Data) = c("Population","Container","Sex","Habitat","Treatment","BodyL")
# Fit null model without fixed effects (but including all random effects)m0 <- lmer(BodyL ~ 1 + (1 | Population) + (1 | Container), data = Data)
# Fit alternative model including fixed and all random effectsmF <- lmer(BodyL ~ Sex + Treatment + (1 | Population) + (1 | Container), data = Data)
# View model fits for both modelssummary(m0)summary(mF)
# Extraction of fitted value for the alternative model# fixef() extracts coefficents for fixed effects# mF at X returns fixed effect design matrixFixed <- fixef(mF)[2] * mF at X[, 2] + fixef(mF)[3] * mF at X[, 3] + fixef(mF)[4] * mF at X[, 4]
# Calculation of the variance in fitted valuesVarF <- var(Fixed)
# An alternative way for getting the same resultVarF <- var(as.vector(fixef(mF) %*% t(mF at X)))
# R2GLMM(m) - marginal R2GLMM# Equ. 26, 29 and 30# VarCorr() extracts variance components# attr(VarCorr(lmer.model),'sc')^2 extracts the residual varianceVarF/(VarF + VarCorr(mF)$Container[1] + VarCorr(mF)$Population[1] + attr(VarCorr(mF), "sc")^2)
# R2GLMM(c) - conditional R2GLMM for full model# Equ. XXX, XXX(VarF + VarCorr(mF)$Container[1] + VarCorr(mF)$Population[1])/(VarF + VarCorr(mF)$Container[1] + VarCorr(mF)$Population[1] + (attr(VarCorr(mF), "sc")^2))
# AIC and BIC needs to be calcualted with ML not REML in body size modelsm0ML <- lmer(BodyL ~ 1 + (1 | Population) + (1 | Container), data = Data, REML = FALSE)mFML <- lmer(BodyL ~ Sex + Treatment + (1 | Population) + (1 | Container), data = Data, REML = FALSE)
# View model fits for both models fitted by MLsummary(m0ML)summary(mFML)
 		 	   		  
	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon May  2 01:22:34 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 1 May 2016 19:22:34 -0400
Subject: [R-sig-ME] design matrix for R2
In-Reply-To: <DUB124-W24EB94E79733F46CEC9FDCFA780@phx.gbl>
References: <DUB124-W24EB94E79733F46CEC9FDCFA780@phx.gbl>
Message-ID: <57268FBA.5050907@gmail.com>


  try getME(mF,"X") (and more generally see ?getME)

On 16-05-01 03:47 PM, Rob Griffin wrote:
> Dear list,
> I am trying to implement the R2 method of Nakagawa and Schielzeth for a model in lme4 but having problems. Using the documentation provided with the paper (including R script and dummy data: http://onlinelibrary.wiley.com/doi/10.1111/j.2041-210x.2012.00261.x/suppinfo) I run in to the same problem as when I try it on my own data. The full script from supplementary file S4 is pasted at the end of this message for the first example in the paper (I've slightly modified to make self contained dummy data and dropping the "Condition" variable from the model, which is absent from the dummy data file [S1] and not mentioned in the paper). The issue arises when running:
>> Fixed <- fixef(mF)[2] * mF at X[, 2] + fixef(mF)[3] * mF at X[, 3] + fixef(mF)[4] * mF at X[, 4]Error: no slot of name "X" for this object of class "lmerMod"
> My suspicion is that there has been a change in the structure of the models in lmer such that "mF at X" no longer relates to the design matrix, but reading the latest lme4 documentation I can't solve the issue... any suggestions? I'm using R version 3.2.4 (2016-03-16), and lme4 version 1.1-12.
> Many thanks,Robert
> -----
> # Clear memoryrm(list = ls())
> # Read body length data (Gaussian, available for both sexes)Data <- data.frame(rep(1:12, each = 80), rep(1:120, each = 8), rep(c("Female","Male"), each = 8), rep(c("A","B"), each = 4), rep(c("Cont","Exp")), rep(sample(c(9,10,11), replace=T, size = 120), each = 8)+rnorm(960,0,0.5))colnames(Data) = c("Population","Container","Sex","Habitat","Treatment","BodyL")
> # Fit null model without fixed effects (but including all random effects)m0 <- lmer(BodyL ~ 1 + (1 | Population) + (1 | Container), data = Data)
> # Fit alternative model including fixed and all random effectsmF <- lmer(BodyL ~ Sex + Treatment + (1 | Population) + (1 | Container), data = Data)
> # View model fits for both modelssummary(m0)summary(mF)
> # Extraction of fitted value for the alternative model# fixef() extracts coefficents for fixed effects# mF at X returns fixed effect design matrixFixed <- fixef(mF)[2] * mF at X[, 2] + fixef(mF)[3] * mF at X[, 3] + fixef(mF)[4] * mF at X[, 4]
> # Calculation of the variance in fitted valuesVarF <- var(Fixed)
> # An alternative way for getting the same resultVarF <- var(as.vector(fixef(mF) %*% t(mF at X)))
> # R2GLMM(m) - marginal R2GLMM# Equ. 26, 29 and 30# VarCorr() extracts variance components# attr(VarCorr(lmer.model),'sc')^2 extracts the residual varianceVarF/(VarF + VarCorr(mF)$Container[1] + VarCorr(mF)$Population[1] + attr(VarCorr(mF), "sc")^2)
> # R2GLMM(c) - conditional R2GLMM for full model# Equ. XXX, XXX(VarF + VarCorr(mF)$Container[1] + VarCorr(mF)$Population[1])/(VarF + VarCorr(mF)$Container[1] + VarCorr(mF)$Population[1] + (attr(VarCorr(mF), "sc")^2))
> # AIC and BIC needs to be calcualted with ML not REML in body size modelsm0ML <- lmer(BodyL ~ 1 + (1 | Population) + (1 | Container), data = Data, REML = FALSE)mFML <- lmer(BodyL ~ Sex + Treatment + (1 | Population) + (1 | Container), data = Data, REML = FALSE)
> # View model fits for both models fitted by MLsummary(m0ML)summary(mFML)
>  		 	   		  
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From asher.strauss at gmail.com  Mon May  2 10:17:16 2016
From: asher.strauss at gmail.com (Asher Strauss)
Date: Mon, 2 May 2016 11:17:16 +0300
Subject: [R-sig-ME] Toeplitz correlation object for nlme
Message-ID: <57270d10.ce9d1c0a.cf851.ffff8017@mx.google.com>




Dear List,
I?ve been searching the?archives for help defining a Toeplitz cor structure, but can't find any help. Has anybody here have any experience with this? Any advice and direction points would be very helpful.
Best
Asher?

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon May  2 13:05:25 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 2 May 2016 13:05:25 +0200
Subject: [R-sig-ME] Convergence Problems with glmer.nb model
In-Reply-To: <CAN=0SEm4Kc5_9qtsxxqvYp=fEVe+mvXvpW1LpncHJhHXQtkb1w@mail.gmail.com>
References: <CAN=0SEkfdDsdiqmK51K0U4FYHyDhcsvWFLNTtbRJFL9oZXbF9g@mail.gmail.com>
	<CAN=0SEkTL+-UyXcpMRAQFwcCWvNJu+9ZR0wzBTHi+DXQ2JhKqg@mail.gmail.com>
	<CAJuCY5xLg1bN8A6-6oHQmQJgnDXTyDN+SvHJ1sRGtowP60DWzQ@mail.gmail.com>
	<CAN=0SEnVLZzbQGTqVJDHgFqUAXZHWpz-sPwQv5TOO4fCz+oQ_A@mail.gmail.com>
	<CAN=0SEm4Kc5_9qtsxxqvYp=fEVe+mvXvpW1LpncHJhHXQtkb1w@mail.gmail.com>
Message-ID: <CAJuCY5ynUsVZqbdhk_=kij+nVgpDaG6q9SO2zj4z66_2x_Vc9w@mail.gmail.com>

Dear Aoibheann,

It looks like the problem is within glmer.nb. I've fit the same model with
glmer.nb, glmmadmb and inla. glmmadmb and inla give comparable estimates.
The standard errors of glmer.nb are problematic.

Maybe Ben Bolker can diagnose what is going wrong with glmer.nb.

library(readr)
library(dplyr)
dataset <- read_csv("foraging subset.csv") %>%
  mutate(
    name = factor(name),
    fieldid = factor(rank(origarea)),
    logarea = log(origarea)
  )

library(lme4)
m.lme4 <- glmer.nb(field_count ~ logarea + habitat + (1 | name) + (1 |
fieldid), data = dataset)

library(glmmADMB)
m.admb <- glmmadmb(field_count ~ logarea + habitat + (1 | name) + (1 |
fieldid), data = dataset, family = "nbinom")


# install.packages("INLA", repos="https://www.math.ntnu.no/inla/R/stable")
library(INLA)
m.inla <- inla(field_count ~ f(name, model = "iid") + f(fieldid, model =
"iid") + logarea + habitat, data = dataset, family = "nbinomial")

summary(m.lme4)$coefficients
summary(m.admb)$coefficients
m.inla$summary.fixed

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-04-29 16:55 GMT+02:00 Aoibheann Gaughran <gaughra at tcd.ie>:

> Hi Thierry,
>
> Apologies in the delay in reverting, I have been out on fieldwork. I have
> tried your suggestions, but unfortunately am still having convergence
> issues.  The most simple Poisson model runs fine, so I tried a negative
> binomial distribution but that produced about 12 convergence warnings.
>
> > modelA <- glmer.nb(field_count ~ (1|animal) + (1|field_id) + offset(log(origarea)), family = poisson, data = dframe2)
>
>  There were 12 warnings (use warnings() to see them)
>
>  > warnings()
>
> Warning messages:
>
> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :
>   Model failed to converge with max|grad| = 0.0493534 (tol = 0.001, component 1)
>
> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :
>   Model failed to converge with max|grad| = 0.0627833 (tol = 0.001, component 1)
>
> 3: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :
>   Model is nearly unidentifiable: very large eigenvalue - Rescale variables?
>
> etc.
>
>
> I reverted to the simple Poisson and added the OLR, which ran, but as soon
> as I add any additional complexity/variables (apart from sex) it produces a
> convergence warning.
>
> Warning message:In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model failed to converge with max|grad| = 0.0332321 (tol = 0.001, component 1)
>
>
> I am not sure where to go from here. Any guidance would be much
> appreciated.
>
> Kind regards,
>
> Aoibheann
>
>
>
> On 25 April 2016 at 14:44, Aoibheann Gaughran <gaughra at tcd.ie> wrote:
>
>> Hi Thierry,
>>
>> Here is the dropbox link to the data -
>> https://www.dropbox.com/s/ne5d4zp2gncwylm/foraging%20subset.csv?dl=0
>>
>> I had changed the field area units from meter square to hectures already,
>> so that *should *be okay.  There is one exceedingly large "field" which
>> is actually a large area of forestry. Perhaps this is throwing the scaling
>> off.
>>
>> Can you confirm that this is how I specify the observation level random
>> effect:
>>
>> dframe1$obs <- factor(seq(nrow(dframe1)))  #modified from https://rpubs.com/bbolker/glmmchapter
>>
>> which is included in the model as
>>
>> +(1|obs)
>>
>>
>> I'll try your suggestions and see how I get on.
>>
>> Many thanks,
>>
>> Aoibheann
>>
>> On 25 April 2016 at 13:40, Thierry Onkelinx <thierry.onkelinx at inbo.be>
>> wrote:
>>
>>> Dear Aoibheann,
>>>
>>> Two general suggestions on the design. 1) A random effect of field seems
>>> relevant too. 2) Have the units of origarea in a relevant scale. You are
>>> modelling the number of visits per unit of origarea. Then the number per
>>> hectare seems more relevant to me than the number per square meter.
>>>
>>> Then try the most simple Poisson model to see it that converge. glmer(field_count
>>> ~ (1| animal) + (1|field) + offset(log(origarea)), family = poisson)
>>>
>>> If that works, then you could try the negative binomial distribution or
>>> adding an observation level random effect.
>>>
>>> The mailing list strips most attachments. So you need to put them on a
>>> website or post a dropbox or google drive link.
>>>
>>> Best regards,
>>>
>>>
>>> ir. Thierry Onkelinx
>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>> and Forest
>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>> Kliniekstraat 25
>>> 1070 Anderlecht
>>> Belgium
>>>
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of data.
>>> ~ John Tukey
>>>
>>> 2016-04-25 14:08 GMT+02:00 Aoibheann Gaughran <gaughra at tcd.ie>:
>>>
>>>> On 25 April 2016 at 13:00, Aoibheann Gaughran <gaughra at tcd.ie> wrote:
>>>>
>>>> > Good morning,
>>>> >
>>>> > First time posting so I hope I am including all of the relevant
>>>> > information.
>>>> >
>>>> > I am attempting to analyse the foraging behaviour of a animal in an
>>>> > agricultural landscape. The objective is to identify the factors
>>>> (habitat
>>>> > type, environmental variables and animal-specific variables) that best
>>>> > predict foraging site preference. Some fields are preferred while
>>>> others
>>>> > are avoided.
>>>> >
>>>> > The response variable is count data - the number of times a given
>>>> animal
>>>> > was in a given field in a given month. An animal's home range varies
>>>> from
>>>> > month to month, so the area available to it and the fields that fall
>>>> within
>>>> > its home range change somewhat every month. The count data shows an
>>>> > overdispersed, negative binomial distribution, and is zero inflated as
>>>> > fields that fell within the home range where the animal had *not
>>>> *foraged
>>>> > in that month are also included in the dataset. The individual animal
>>>> is
>>>> > specified as a random variable to account for pseudoreplication.
>>>> >
>>>> > It should be noted that at the moment I am attempting to run a the
>>>> model
>>>> > on a subset of the data (n=671) as I had attempted to run the model
>>>> on the
>>>> > full dataset (n=62,000) but three days later the model (which included
>>>> > interaction terms at this point) had still failed to run, and when
>>>> stopped,
>>>> > R gave me a multitude of convergence warning messages e.g.
>>>> >
>>>> > 13: In (function (fn, par, lower = rep.int(-Inf, n), upper = rep.int
>>>> (Inf,
>>>> > ... :
>>>> >   failure to converge in 10000 evaluations
>>>> >
>>>> > Simpler iterations of the model, with fewer explanatory terms, and no
>>>> > interaction terms, also gave me convergence and some scaling warnings,
>>>> > which I sought to address using:
>>>> >
>>>> > control=glmerControl(optCtrl=list(maxfun=20000)
>>>> >
>>>> > and by scaling the numeric variables age, slope and aspect as
>>>> follows:-
>>>> >
>>>> > dframe1$agescale <- scale(dframe1$age, center = TRUE, scale = FALSE)
>>>> > dframe1$slopescale <- scale(dframe1$slope, center = TRUE, scale =
>>>> FALSE)
>>>> > dframe1$aspectscale <- scale(dframe1$aspect, center = TRUE, scale =
>>>> FALSE)
>>>> >
>>>> > Currently, the model looks like this:
>>>> >
>>>> > > model1 <- glmer.nb(field_count ~ habitat +                    +
>>>> sex+                    + agescale+                    #+ mon+
>>>>       + soil+                    + slopescale+                    +
>>>> aspectscale+                    + offset(log(origarea)) #take into account
>>>> field size +                    +(1|animal),+
>>>> control=glmerControl(optCtrl=list(maxfun=20000)),+
>>>> data = dframe1)
>>>> >
>>>> > There were 24 warnings (use warnings() to see them)
>>>> > > warnings()Warning messages:
>>>> > 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
>>>> control$checkConv,  ... :
>>>> >   Model is nearly unidentifiable: very large eigenvalue
>>>> >  - Rescale variables?;Model is nearly unidentifiable: large
>>>> eigenvalue ratio
>>>> >  - Rescale variables?
>>>> > 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
>>>> control$checkConv,  ... :
>>>> >   Model failed to converge with max|grad| = 0.0134799 (tol = 0.001,
>>>> component 1)
>>>> > 3: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
>>>> control$checkConv,  ... :
>>>> >   Model failed to converge with max|grad| = 0.148644 (tol = 0.001,
>>>> component 1)
>>>> > 4: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
>>>> control$checkConv,  ... :
>>>> >   Model is nearly unidentifiable: large eigenvalue ratio
>>>> >  - Rescale variables?
>>>> >
>>>> > etc.
>>>> >
>>>> > So the model still fails to converge despite rescaling and altering
>>>> the
>>>> > number of iterations. I had also received the following error in
>>>> relation
>>>> > to month (in the reduced dataset there are only *four *months), so Ive
>>>>
>>>> > had to exclude it for the time being. I am not sure why I am getting
>>>> this
>>>> > error since the factor has four levels.
>>>> >
>>>> > Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
>>>> > contrasts can be applied only to factors with 2 or more levels
>>>> >
>>>> > I do eventually want to include interaction terms as previous
>>>> analysis on
>>>> > ranging behaviour suggests there is an interaction between age and
>>>> sex.
>>>> >
>>>> > Summary of dataset attached.  Also attached is the .csv file
>>>> containing
>>>> > the reduced dataset.
>>>> >
>>>> > I have read various suggestions online and have come across the
>>>> following
>>>> > worrying line "It's perfectly possible that your data is insufficient
>>>> to
>>>> > support the complexity of the model or the model is incorrectly
>>>> constructed
>>>> > for the design of the study".
>>>> >
>>>> > I would greatly appreciate any help you could give me with
>>>> understanding
>>>> > and solving the problems I am encountering with my model.
>>>> >
>>>> > Kind regards,
>>>> >
>>>> > --
>>>> > Aoibheann Gaughran
>>>> >
>>>> > Behavioural and Evolutionary Ecology Research Group
>>>> > Zoology Building
>>>> > School of Natural Sciences
>>>> > Trinity College Dublin
>>>> > Dublin 2
>>>> > Ireland
>>>> > Phone: +353 (86) 3812615
>>>> >
>>>>
>>>>
>>>>
>>>> --
>>>> Aoibheann Gaughran
>>>>
>>>> Behavioural and Evolutionary Ecology Research Group
>>>> Zoology Building
>>>> School of Natural Sciences
>>>> Trinity College Dublin
>>>> Dublin 2
>>>> Ireland
>>>> Phone: +353 (86) 3812615
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>>
>>
>>
>> --
>> Aoibheann Gaughran
>>
>> Behavioural and Evolutionary Ecology Research Group
>> Zoology Building
>> School of Natural Sciences
>> Trinity College Dublin
>> Dublin 2
>> Ireland
>> Phone: +353 (86) 3812615
>>
>
>
>
> --
> Aoibheann Gaughran
>
> Behavioural and Evolutionary Ecology Research Group
> Zoology Building
> School of Natural Sciences
> Trinity College Dublin
> Dublin 2
> Ireland
> Phone: +353 (86) 3812615
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon May  2 13:54:32 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 2 May 2016 13:54:32 +0200
Subject: [R-sig-ME] Toeplitz correlation object for nlme
In-Reply-To: <57270d10.ce9d1c0a.cf851.ffff8017@mx.google.com>
References: <57270d10.ce9d1c0a.cf851.ffff8017@mx.google.com>
Message-ID: <CAJuCY5yBSgjvs43HxizC0TdrFZ_xh4L06wyLvTeuzDJU9E4tbw@mail.gmail.com>

Dear Asher,

IMHO a corARMA structure with only AR components should give something
similar to a Toeplitz correlation structure.

Notice that ?corClasses has: "Users may define their own corStruct classes
by specifying a constructor function and, at a minimum, methods for the
functions corMatrix and coef. For examples of these functions, see the
methods for classes corSymm and corAR1."

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-05-02 10:17 GMT+02:00 Asher Strauss <asher.strauss at gmail.com>:

>
>
>
> Dear List,
> I?ve been searching the archives for help defining a Toeplitz cor
> structure, but can't find any help. Has anybody here have any experience
> with this? Any advice and direction points would be very helpful.
> Best
> Asher
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon May  2 14:49:01 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 2 May 2016 08:49:01 -0400
Subject: [R-sig-ME] Toeplitz correlation object for nlme
In-Reply-To: <CAJuCY5yBSgjvs43HxizC0TdrFZ_xh4L06wyLvTeuzDJU9E4tbw@mail.gmail.com>
References: <57270d10.ce9d1c0a.cf851.ffff8017@mx.google.com>
	<CAJuCY5yBSgjvs43HxizC0TdrFZ_xh4L06wyLvTeuzDJU9E4tbw@mail.gmail.com>
Message-ID: <CABghstSTeTLGjVWsh1pzs2RwDoUaBLk-+t0_BKROyLTYbTcPbg@mail.gmail.com>

  I would also suggest that people trying to create their own
correlation structures might want to look at something like
corBrownian in the ape package (and the corresponding
corMatrix.corBrownian), which is a bit simpler -- the correlation
structures in nlme are embedded in a fairly complex class hierarchy,
and use C code for efficiency ...)


On Mon, May 2, 2016 at 7:54 AM, Thierry Onkelinx
<thierry.onkelinx at inbo.be> wrote:
> Dear Asher,
>
> IMHO a corARMA structure with only AR components should give something
> similar to a Toeplitz correlation structure.
>
> Notice that ?corClasses has: "Users may define their own corStruct classes
> by specifying a constructor function and, at a minimum, methods for the
> functions corMatrix and coef. For examples of these functions, see the
> methods for classes corSymm and corAR1."
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2016-05-02 10:17 GMT+02:00 Asher Strauss <asher.strauss at gmail.com>:
>
>>
>>
>>
>> Dear List,
>> I?ve been searching the archives for help defining a Toeplitz cor
>> structure, but can't find any help. Has anybody here have any experience
>> with this? Any advice and direction points would be very helpful.
>> Best
>> Asher
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From jenyourkavitch at yahoo.com  Sun May  1 23:20:19 2016
From: jenyourkavitch at yahoo.com (Jennifer Yourkavitch)
Date: Sun, 1 May 2016 17:20:19 -0400
Subject: [R-sig-ME] Setting start values for log binomial model in glmmPQL
Message-ID: <F259760B-BAB5-46AA-AC71-D8CB20BDD602@yahoo.com>

Hello,
I'm having trouble setting starting values and   I think there is a problem with my syntax for the ?start? command.


First, I?m trying to use the coefficients from a logit model as start values for the log binomial model I want to run:

coefini=coef(glmmPQL(anybf~n_dis +mage_r+mage_sq+married+parity_r+nhblack+hisp+nhasian+mom_lths+mom_sclg+mom_ba+mwork+medicaid+nodad+mom_foreign,
     random=~1|grptr0010,family = binomial))
summary(coefini) 

#coefini model looks good and runs

fit2<-glmmPQL(anybf~n_dis +mage_r+mage_sq+married+parity_r+nhblack+hisp+nhasian+mom_lths+mom_sclg+mom_ba+mwork+medicaid+nodad+mom_foreign,
     random=~1|grptr0010,family = binomial(log),start=c(coefini,1, 0))

summary(fit2)

I get this error: 
Error in glm.fit(x = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  :
  length of 'start' should equal 16 and correspond to initial coefs for c("(Intercept)", "n_dis", "mage_r", "mage_sq", "married", "parity_r", , "nhblack", "hisp", "nhasian", "mom_lths", "mom_sclg", "mom_ba", , "mwork", "medicaid", "nodad", "mom_foreign")

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
So then I tried typing in the coefficients from the logit model directly:

fit2<-glmmPQL(anybf~n_dis +mage_r+mage_sq+married+parity_r+nhblack+hisp+nhasian+mom_lths+mom_sclg+mom_ba+mwork+medicaid+nodad+mom_foreign,
              random=~1|grptr0010,family = binomial(log),start=c(0.0675, -0.127, 0.008, -0.0002, 0.369, -0.111, -0.0795, 0.363, 0.1387, -0.121, 0.415, 0.861, 0.023, -0.033, -0.307, 0.915))
summary(fit2)

And I get this error:
Error: cannot find valid starting values: please specify some


Can you see the problem?

Thanks!
Jennifer


	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon May  2 20:33:29 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 2 May 2016 14:33:29 -0400
Subject: [R-sig-ME] Setting start values for log binomial model in
	glmmPQL
In-Reply-To: <F259760B-BAB5-46AA-AC71-D8CB20BDD602@yahoo.com>
References: <F259760B-BAB5-46AA-AC71-D8CB20BDD602@yahoo.com>
Message-ID: <CABghstQ5vyVCsAgTcDQXOGZKJQyGRkbi52qSRhNZk-qf1pw1fQ@mail.gmail.com>

This is a perfectly reasonable question, but it would be easier to
answer with a reproducible example.  See e.g

http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

On Sun, May 1, 2016 at 5:20 PM, Jennifer Yourkavitch via
R-sig-mixed-models <r-sig-mixed-models at r-project.org> wrote:
> Hello,
> I'm having trouble setting starting values and   I think there is a problem with my syntax for the ?start? command.
>
>
> First, I?m trying to use the coefficients from a logit model as start values for the log binomial model I want to run:
>
> coefini=coef(glmmPQL(anybf~n_dis +mage_r+mage_sq+married+parity_r+nhblack+hisp+nhasian+mom_lths+mom_sclg+mom_ba+mwork+medicaid+nodad+mom_foreign,
>      random=~1|grptr0010,family = binomial))
> summary(coefini)
>
> #coefini model looks good and runs
>
> fit2<-glmmPQL(anybf~n_dis +mage_r+mage_sq+married+parity_r+nhblack+hisp+nhasian+mom_lths+mom_sclg+mom_ba+mwork+medicaid+nodad+mom_foreign,
>      random=~1|grptr0010,family = binomial(log),start=c(coefini,1, 0))
>
> summary(fit2)
>
> I get this error:
> Error in glm.fit(x = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  :
>   length of 'start' should equal 16 and correspond to initial coefs for c("(Intercept)", "n_dis", "mage_r", "mage_sq", "married", "parity_r", , "nhblack", "hisp", "nhasian", "mom_lths", "mom_sclg", "mom_ba", , "mwork", "medicaid", "nodad", "mom_foreign")
>
> -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> So then I tried typing in the coefficients from the logit model directly:
>
> fit2<-glmmPQL(anybf~n_dis +mage_r+mage_sq+married+parity_r+nhblack+hisp+nhasian+mom_lths+mom_sclg+mom_ba+mwork+medicaid+nodad+mom_foreign,
>               random=~1|grptr0010,family = binomial(log),start=c(0.0675, -0.127, 0.008, -0.0002, 0.369, -0.111, -0.0795, 0.363, 0.1387, -0.121, 0.415, 0.861, 0.023, -0.033, -0.307, 0.915))
> summary(fit2)
>
> And I get this error:
> Error: cannot find valid starting values: please specify some
>
>
> Can you see the problem?
>
> Thanks!
> Jennifer
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From thierry.onkelinx at inbo.be  Mon May  2 20:40:45 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 2 May 2016 20:40:45 +0200
Subject: [R-sig-ME] Setting start values for log binomial model in
	glmmPQL
In-Reply-To: <F259760B-BAB5-46AA-AC71-D8CB20BDD602@yahoo.com>
References: <F259760B-BAB5-46AA-AC71-D8CB20BDD602@yahoo.com>
Message-ID: <CAJuCY5ymAdTfVPziPDL=c4G7ABdtpsy+gAdOyuTgwDcqbFqYxA@mail.gmail.com>

Dear Jennifer,

Are you sure that the result of c(coefini,1, 0) is a vector of length 16?
The output of c() could be something else than a vector.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-05-01 23:20 GMT+02:00 Jennifer Yourkavitch via R-sig-mixed-models <
r-sig-mixed-models at r-project.org>:

> Hello,
> I'm having trouble setting starting values and   I think there is a
> problem with my syntax for the ?start? command.
>
>
> First, I?m trying to use the coefficients from a logit model as start
> values for the log binomial model I want to run:
>
> coefini=coef(glmmPQL(anybf~n_dis
> +mage_r+mage_sq+married+parity_r+nhblack+hisp+nhasian+mom_lths+mom_sclg+mom_ba+mwork+medicaid+nodad+mom_foreign,
>      random=~1|grptr0010,family = binomial))
> summary(coefini)
>
> #coefini model looks good and runs
>
> fit2<-glmmPQL(anybf~n_dis
> +mage_r+mage_sq+married+parity_r+nhblack+hisp+nhasian+mom_lths+mom_sclg+mom_ba+mwork+medicaid+nodad+mom_foreign,
>      random=~1|grptr0010,family = binomial(log),start=c(coefini,1, 0))
>
> summary(fit2)
>
> I get this error:
> Error in glm.fit(x = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  :
>   length of 'start' should equal 16 and correspond to initial coefs for
> c("(Intercept)", "n_dis", "mage_r", "mage_sq", "married", "parity_r", ,
> "nhblack", "hisp", "nhasian", "mom_lths", "mom_sclg", "mom_ba", , "mwork",
> "medicaid", "nodad", "mom_foreign")
>
>
> -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> So then I tried typing in the coefficients from the logit model directly:
>
> fit2<-glmmPQL(anybf~n_dis
> +mage_r+mage_sq+married+parity_r+nhblack+hisp+nhasian+mom_lths+mom_sclg+mom_ba+mwork+medicaid+nodad+mom_foreign,
>               random=~1|grptr0010,family = binomial(log),start=c(0.0675,
> -0.127, 0.008, -0.0002, 0.369, -0.111, -0.0795, 0.363, 0.1387, -0.121,
> 0.415, 0.861, 0.023, -0.033, -0.307, 0.915))
> summary(fit2)
>
> And I get this error:
> Error: cannot find valid starting values: please specify some
>
>
> Can you see the problem?
>
> Thanks!
> Jennifer
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From jenyourkavitch at yahoo.com  Tue May  3 15:07:51 2016
From: jenyourkavitch at yahoo.com (Jennifer Yourkavitch)
Date: Tue, 3 May 2016 09:07:51 -0400
Subject: [R-sig-ME] Setting start values for log binomial model in
	glmmPQL
In-Reply-To: <CAJuCY5ymAdTfVPziPDL=c4G7ABdtpsy+gAdOyuTgwDcqbFqYxA@mail.gmail.com>
References: <F259760B-BAB5-46AA-AC71-D8CB20BDD602@yahoo.com>
	<CAJuCY5ymAdTfVPziPDL=c4G7ABdtpsy+gAdOyuTgwDcqbFqYxA@mail.gmail.com>
Message-ID: <331157AD-5C7F-4A45-98EB-646D141539CD@yahoo.com>

Yes, I think you're right. A friend pointed out that I need to specify the coefficients for the fixed effects only.
Thanks,
Jennifer


> On May 2, 2016, at 2:40 PM, Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
> 
> Dear Jennifer,
> 
> Are you sure that the result of c(coefini,1, 0) is a vector of length 16? The output of c() could be something else than a vector.
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest 
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance 
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner 
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
> 
> 2016-05-01 23:20 GMT+02:00 Jennifer Yourkavitch via R-sig-mixed-models <r-sig-mixed-models at r-project.org>:
>> Hello,
>> I'm having trouble setting starting values and   I think there is a problem with my syntax for the ?start? command.
>> 
>> 
>> First, I?m trying to use the coefficients from a logit model as start values for the log binomial model I want to run:
>> 
>> coefini=coef(glmmPQL(anybf~n_dis +mage_r+mage_sq+married+parity_r+nhblack+hisp+nhasian+mom_lths+mom_sclg+mom_ba+mwork+medicaid+nodad+mom_foreign,
>>      random=~1|grptr0010,family = binomial))
>> summary(coefini)
>> 
>> #coefini model looks good and runs
>> 
>> fit2<-glmmPQL(anybf~n_dis +mage_r+mage_sq+married+parity_r+nhblack+hisp+nhasian+mom_lths+mom_sclg+mom_ba+mwork+medicaid+nodad+mom_foreign,
>>      random=~1|grptr0010,family = binomial(log),start=c(coefini,1, 0))
>> 
>> summary(fit2)
>> 
>> I get this error:
>> Error in glm.fit(x = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  :
>>   length of 'start' should equal 16 and correspond to initial coefs for c("(Intercept)", "n_dis", "mage_r", "mage_sq", "married", "parity_r", , "nhblack", "hisp", "nhasian", "mom_lths", "mom_sclg", "mom_ba", , "mwork", "medicaid", "nodad", "mom_foreign")
>> 
>> -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>> So then I tried typing in the coefficients from the logit model directly:
>> 
>> fit2<-glmmPQL(anybf~n_dis +mage_r+mage_sq+married+parity_r+nhblack+hisp+nhasian+mom_lths+mom_sclg+mom_ba+mwork+medicaid+nodad+mom_foreign,
>>               random=~1|grptr0010,family = binomial(log),start=c(0.0675, -0.127, 0.008, -0.0002, 0.369, -0.111, -0.0795, 0.363, 0.1387, -0.121, 0.415, 0.861, 0.023, -0.033, -0.307, 0.915))
>> summary(fit2)
>> 
>> And I get this error:
>> Error: cannot find valid starting values: please specify some
>> 
>> 
>> Can you see the problem?
>> 
>> Thanks!
>> Jennifer
>> 
>> 
>>         [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

	[[alternative HTML version deleted]]


From orzack at freshpond.org  Tue May  3 16:00:23 2016
From: orzack at freshpond.org (Steven Orzack)
Date: Tue, 3 May 2016 10:00:23 -0400
Subject: [R-sig-ME] syntax for random effects for an autocorrelated time
	series
Message-ID: <5728AEF7.9040501@freshpond.org>

  I am working on an analysis with time series data. In particular, a 
(simulated) population is counted at discrete time intervals. One has

N1, N2, N3, N4, N5, N6, N7, N8, N9, N10, N11, N12,......

where Ni is the number of individuals counted at time i.

 From this time series, one can create another time series, say,

CV1, CV2, CV3, CV4,.....

where CVi is the coefficient of variation calculated from the first z 
values of Ni. So, for example, if z = 4,

CV1 is the coefficient of variation of  N1, N2, N3, N4
CV2 is the coefficient of variation of  N2, N3, N4, N5
CV3 is the coefficient of variation of  N3, N4, N5, N6
..
CVi  is the coefficient of variation of  Ni, Ni+1 Ni+2, Ni+3
.
.


Obviously, the values in the times series of CVi do NOT have independent 
errors. BTW, I have chosen z  = 4 for the example but it could take 
other values. Of course, in any given analysis z is fixed.

The autocorrelation (lack of independence) among values in the CVi time 
series means that I need to account for this in the fitting of a GLMM. 
In this particular case, the link function would probably best be log. 
The choice of the link function is secondary at the moment. What I need 
to know is how to specify the random effects given the autocorrelation.

I am interested in assessing trends in the CV values so one of the 
models will have time (i) as a predictor

The intercept model is going to look something like (using log)

log(CV) = 1 + (1 | random effects)

and the model with time is something like


log(CV) = 1 + time + (time | random effects)

  The autocorrelation here seems simple but I am unsure about the exact 
syntax needed for model fitting with glmer.

Suggestions for the syntax are welcome. I will be very appreciative.


Many thanks in advance,

S.

-- 
Steven Orzack
Fresh Pond Research Institute
173 Harvey Street
Cambridge, MA 02140
617 864-4307

www.freshpond.org


From alex at iim.csic.es  Tue May  3 22:51:28 2016
From: alex at iim.csic.es (Xandre)
Date: Tue, 3 May 2016 22:51:28 +0200
Subject: [R-sig-ME] Why se.fit differ in predict.glm and predict.glmmadmb?
Message-ID: <384d50e7-7d81-6c24-e75a-05b01174e4b4@iim.csic.es>

Dear list,

I am running a GLM (family="binomial") without random effects using both 
glm and glmmadmb.

Summaries are almost identical, however when I used the predict function 
as follows:

predict(glm1,newdatos1,type="link",se.fit =T)

predict(admb1,newdatos1,type="link",se.fit =T)

I realized that se.fit differ a lot between them, admb se.fit resulted 
much much higher (fit is almost identical). This is just and example of 
what I found:

glm1$se.fit	admb1$se.fit
0.04290869	0.2676562
0.04435600	0.2733130
0.04095631	0.2728592
0.03402992	0.2718389
0.03000669	0.2713617
0.03633637	0.2722059

Maybe I'm missing something or I am making a big mistake. Any help with 
this?


Many thanks,

Alexandre Alonso


	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed May  4 00:28:38 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 3 May 2016 18:28:38 -0400
Subject: [R-sig-ME] Why se.fit differ in predict.glm and
	predict.glmmadmb?
In-Reply-To: <384d50e7-7d81-6c24-e75a-05b01174e4b4@iim.csic.es>
References: <384d50e7-7d81-6c24-e75a-05b01174e4b4@iim.csic.es>
Message-ID: <57292616.4020702@gmail.com>


  Not sure, this will be worth looking into ...

On 16-05-03 04:51 PM, Xandre wrote:
> Dear list,
> 
> I am running a GLM (family="binomial") without random effects using both 
> glm and glmmadmb.
> 
> Summaries are almost identical, however when I used the predict function 
> as follows:
> 
> predict(glm1,newdatos1,type="link",se.fit =T)
> 
> predict(admb1,newdatos1,type="link",se.fit =T)
> 
> I realized that se.fit differ a lot between them, admb se.fit resulted 
> much much higher (fit is almost identical). This is just and example of 
> what I found:
> 
> glm1$se.fit	admb1$se.fit
> 0.04290869	0.2676562
> 0.04435600	0.2733130
> 0.04095631	0.2728592
> 0.03402992	0.2718389
> 0.03000669	0.2713617
> 0.03633637	0.2722059
> 
> Maybe I'm missing something or I am making a big mistake. Any help with 
> this?
> 
> 
> Many thanks,
> 
> Alexandre Alonso
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From alex at iim.csic.es  Wed May  4 10:49:06 2016
From: alex at iim.csic.es (Xandre)
Date: Wed, 4 May 2016 10:49:06 +0200
Subject: [R-sig-ME] Why se.fit differ in predict.glm and
	predict.glmmadmb?
In-Reply-To: <57292616.4020702@gmail.com>
References: <384d50e7-7d81-6c24-e75a-05b01174e4b4@iim.csic.es>
	<57292616.4020702@gmail.com>
Message-ID: <be22997f-025f-cf26-5a59-d196bf09e0fb@iim.csic.es>

Thanks for the interest,

Just to check problems of code I tried again with a much more simple 
example. I made a subset of my original data base (see attached .csv) 
and run a much more simple model as follows:

*> M1<-glm(response~explanatory, **
**+           data=datos,**
**+           family="binomial")**
**> M2<-glmmadmb(response~explanatory, **
**+                 data=datos,**
**+                 family="binomial")**
**> **
**> summary(M1)*

Call:
glm(formula = response ~ explanatory, family = "binomial", data = datos)

Deviance Residuals:
    Min      1Q  Median      3Q     Max
-1.272  -1.226   1.089   1.128   1.549

Coefficients:
               Estimate Std. Error z value Pr(>|z|)
(Intercept)  2.537e-01  6.638e-02   3.822 0.000132 ***
explanatory -1.660e-04  5.214e-05  -3.183 0.001456 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

(Dispersion parameter for binomial family taken to be 1)

     Null deviance: 3461.2  on 2499  degrees of freedom
Residual deviance: 3450.9  on 2498  degrees of freedom
AIC: 3454.9

Number of Fisher Scoring iterations: 3

*> summary(M2)*

Call:
glmmadmb(formula = response ~ explanatory, data = datos, family = 
"binomial")

AIC: 3454.9

Coefficients:
              Estimate Std. Error z value Pr(>|z|)
(Intercept)  2.54e-01   6.64e-02    3.82  0.00013 ***
explanatory -1.66e-04   5.21e-05   -3.18  0.00146 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Number of observations: total=2500

Log-likelihood: -1725.45
 >
*> newdatos <- 
data.frame(explanatory=seq(min(datos$explanatory),max(datos$explanatory),length.out=10))*
 >
*> pred1<-predict(M1,newdatos,type="link",se.fit =T)**
**> pred2<-predict(M2,newdatos,type="link",se.fit =T)*
 >
*> cbind(pred1$fit,pred2$fit)*
           [,1]        [,2]
1   0.22051737  0.22051798
2   0.09972924  0.09972896
3  -0.02105888 -0.02106007
4  -0.14184701 -0.14184909
5  -0.26263513 -0.26263811
6  -0.38342326 -0.38342713
7  -0.50421139 -0.50421615
8  -0.62499951 -0.62500518
9  -0.74578764 -0.74579420
10 -0.86657576 -0.86658322
*> cbind(pred1$se.fit,pred2$se.fit)*
          [,1]       [,2]
1  0.05841106 0.06724456
2  0.04037125 0.08232769
3  0.05222381 0.10914997
4  0.08187989 0.14117163
5  0.11645089 0.17557048
6  0.15263291 0.21118808
7  0.18950541 0.24749882
8  0.22673178 0.28423718
9  0.26416245 0.32125649
10 0.30172140 0.35846971

#Although now de differences are lower, I think they still are quite 
important.

This is my *sessionInfo()*:

R version 3.2.4 Revised (2016-03-16 r70336)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 Service Pack 1

locale:
[1] LC_COLLATE=Spanish_Spain.1252  LC_CTYPE=Spanish_Spain.1252 
LC_MONETARY=Spanish_Spain.1252
[4] LC_NUMERIC=C                   LC_TIME=Spanish_Spain.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods base

other attached packages:
[1] glmmADMB_0.8.3.3 MASS_7.3-45

loaded via a namespace (and not attached):
  [1] Matrix_1.2-4    plyr_1.8.3      magrittr_1.5 tools_3.2.4     
coda_0.18-1     Rcpp_0.12.4     stringi_1.0-1
  [8] nlme_3.1-126    grid_3.2.4      stringr_1.0.0 R2admb_0.7.13   
lattice_0.20-33


Hopefully all this info will be helpful.

Thanks in advance for your time.

Regards,

Alex


El 04/05/2016 a las 0:28, Ben Bolker escribi?:
>    Not sure, this will be worth looking into ...
>
> On 16-05-03 04:51 PM, Xandre wrote:
>> Dear list,
>>
>> I am running a GLM (family="binomial") without random effects using both
>> glm and glmmadmb.
>>
>> Summaries are almost identical, however when I used the predict function
>> as follows:
>>
>> predict(glm1,newdatos1,type="link",se.fit =T)
>>
>> predict(admb1,newdatos1,type="link",se.fit =T)
>>
>> I realized that se.fit differ a lot between them, admb se.fit resulted
>> much much higher (fit is almost identical). This is just and example of
>> what I found:
>>
>> glm1$se.fit	admb1$se.fit
>> 0.04290869	0.2676562
>> 0.04435600	0.2733130
>> 0.04095631	0.2728592
>> 0.03402992	0.2718389
>> 0.03000669	0.2713617
>> 0.03633637	0.2722059
>>
>> Maybe I'm missing something or I am making a big mistake. Any help with
>> this?
>>
>>
>> Many thanks,
>>
>> Alexandre Alonso
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From bernhard.voelkl at vetsuisse.unibe.ch  Wed May  4 12:29:49 2016
From: bernhard.voelkl at vetsuisse.unibe.ch (bernhard.voelkl at vetsuisse.unibe.ch)
Date: Wed, 4 May 2016 10:29:49 +0000
Subject: [R-sig-ME] Is multi-level modelling applicable to crossed designs?
Message-ID: <88B10DA7113B8F4C8E7710DD8F4879BE81EE51@AAI-EXCH-MBX2.campus.unibe.ch>

Is multi-level modelling applicable to fully-crossed designs?
Dear mailing list,
Dear Ben,

The more I read about multi-level models the more confused I get. What I have read now in several different sources (e.g. Moerbeek & Teerenstra 2016) are statements like this: (1) .. multilevel
model is also known as the hierarchical model, mixed effects model, random coefficient model or variance component model. And (2) The multilevel model differs from the traditional (single level) model since it explicitly accounts for the nested (sic) data structure by including random effects
at the group level.

Now, here is my question: the design that I have is one that would be classically described as ?crossed design? and the classical textbooks go at length emphasising the difference between ?nested? and ?crossed? (which also leads to different ways for calculating degrees of freedom and standard errors in the fixed-factor case). My question: can I use mixed models for analysing a crossed design? Does the distinction between nested and crossed make any sense in the hierarchical/multilevel modelling approach?

In R-speak: does Y ~ Treatment + (1|Clinic) + (Treatment|Clinic) make sense if Clinic and Treatment are crossed (not nested) factors but Treatment is fixed while Clinic is random?

To be more concrete here is my setup: I have a large pool of subjects which I can randomly distribute to a number of clinics. At each clinic subjects are (randomly) divided into two groups and get either treatment A or treatment B. Then I take one measure from each subject. Subjects are really randomly distributed to clinics and at all clinics exactly the same treatments are applied. This is a classical crossed design. Treatment is clearly a fixed factor but I would like to treat clinic as a random factor (as I have many clinics, they are a sample of all existing clinics and I want to make generalizations beyond the specific clinics).

(Just to clarify: I searched both ?Ecological Models and Data in R? and the Gelman/Hill book ?Data analysis using regression and multilevel/hierarchical models? but both did not explicitly mention crossed designs, yet in a relatively recent points-of-significance in Nature Methods (2014, 11, 977-978) Krzywinski nicely explains the difference between nested and crossed, so it doesn?t seem to be an obsolete distinction.)

Any help highly appreciated!
Kind regards,
Bernhard

	[[alternative HTML version deleted]]


From Phillip.Alday at unisa.edu.au  Wed May  4 15:47:04 2016
From: Phillip.Alday at unisa.edu.au (Phillip Alday)
Date: Wed, 4 May 2016 13:47:04 +0000
Subject: [R-sig-ME] Why se.fit differ in predict.glm and
	predict.glmmadmb?
In-Reply-To: <be22997f-025f-cf26-5a59-d196bf09e0fb@iim.csic.es>
References: <384d50e7-7d81-6c24-e75a-05b01174e4b4@iim.csic.es>
	<57292616.4020702@gmail.com>
	<be22997f-025f-cf26-5a59-d196bf09e0fb@iim.csic.es>
Message-ID: <1462369668.417.4.camel@loki>

Hi Alex,

Attachments aren't put through to the mailing list, you need to put them
on a publicly available share. 

But thanks for putting forth a (soon-to-be) reproducible example!

Best,
Phillip

On Wed, 2016-05-04 at 10:49 +0200, Xandre wrote:
> Thanks for the interest,
> 
> Just to check problems of code I tried again with a much more simple 
> example. I made a subset of my original data base (see attached .csv) 
> and run a much more simple model as follows:
> 
> *> M1<-glm(response~explanatory, **
> **+           data=datos,**
> **+           family="binomial")**
> **> M2<-glmmadmb(response~explanatory, **
> **+                 data=datos,**
> **+                 family="binomial")**
> **> **
> **> summary(M1)*
> 
> Call:
> glm(formula = response ~ explanatory, family = "binomial", data = datos)
> 
> Deviance Residuals:
>     Min      1Q  Median      3Q     Max
> -1.272  -1.226   1.089   1.128   1.549
> 
> Coefficients:
>                Estimate Std. Error z value Pr(>|z|)
> (Intercept)  2.537e-01  6.638e-02   3.822 0.000132 ***
> explanatory -1.660e-04  5.214e-05  -3.183 0.001456 **
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> (Dispersion parameter for binomial family taken to be 1)
> 
>      Null deviance: 3461.2  on 2499  degrees of freedom
> Residual deviance: 3450.9  on 2498  degrees of freedom
> AIC: 3454.9
> 
> Number of Fisher Scoring iterations: 3
> 
> *> summary(M2)*
> 
> Call:
> glmmadmb(formula = response ~ explanatory, data = datos, family = 
> "binomial")
> 
> AIC: 3454.9
> 
> Coefficients:
>               Estimate Std. Error z value Pr(>|z|)
> (Intercept)  2.54e-01   6.64e-02    3.82  0.00013 ***
> explanatory -1.66e-04   5.21e-05   -3.18  0.00146 **
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Number of observations: total=2500
> 
> Log-likelihood: -1725.45
>  >
> *> newdatos <- 
> data.frame(explanatory=seq(min(datos$explanatory),max(datos$explanatory),length.out=10))*
>  >
> *> pred1<-predict(M1,newdatos,type="link",se.fit =T)**
> **> pred2<-predict(M2,newdatos,type="link",se.fit =T)*
>  >
> *> cbind(pred1$fit,pred2$fit)*
>            [,1]        [,2]
> 1   0.22051737  0.22051798
> 2   0.09972924  0.09972896
> 3  -0.02105888 -0.02106007
> 4  -0.14184701 -0.14184909
> 5  -0.26263513 -0.26263811
> 6  -0.38342326 -0.38342713
> 7  -0.50421139 -0.50421615
> 8  -0.62499951 -0.62500518
> 9  -0.74578764 -0.74579420
> 10 -0.86657576 -0.86658322
> *> cbind(pred1$se.fit,pred2$se.fit)*
>           [,1]       [,2]
> 1  0.05841106 0.06724456
> 2  0.04037125 0.08232769
> 3  0.05222381 0.10914997
> 4  0.08187989 0.14117163
> 5  0.11645089 0.17557048
> 6  0.15263291 0.21118808
> 7  0.18950541 0.24749882
> 8  0.22673178 0.28423718
> 9  0.26416245 0.32125649
> 10 0.30172140 0.35846971
> 
> #Although now de differences are lower, I think they still are quite 
> important.
> 
> This is my *sessionInfo()*:
> 
> R version 3.2.4 Revised (2016-03-16 r70336)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 Service Pack 1
> 
> locale:
> [1] LC_COLLATE=Spanish_Spain.1252  LC_CTYPE=Spanish_Spain.1252 
> LC_MONETARY=Spanish_Spain.1252
> [4] LC_NUMERIC=C                   LC_TIME=Spanish_Spain.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods base
> 
> other attached packages:
> [1] glmmADMB_0.8.3.3 MASS_7.3-45
> 
> loaded via a namespace (and not attached):
>   [1] Matrix_1.2-4    plyr_1.8.3      magrittr_1.5 tools_3.2.4     
> coda_0.18-1     Rcpp_0.12.4     stringi_1.0-1
>   [8] nlme_3.1-126    grid_3.2.4      stringr_1.0.0 R2admb_0.7.13   
> lattice_0.20-33
> 
> 
> Hopefully all this info will be helpful.
> 
> Thanks in advance for your time.
> 
> Regards,
> 
> Alex
> 
> 
> El 04/05/2016 a las 0:28, Ben Bolker escribi?:
> >    Not sure, this will be worth looking into ...
> >
> > On 16-05-03 04:51 PM, Xandre wrote:
> >> Dear list,
> >>
> >> I am running a GLM (family="binomial") without random effects using both
> >> glm and glmmadmb.
> >>
> >> Summaries are almost identical, however when I used the predict function
> >> as follows:
> >>
> >> predict(glm1,newdatos1,type="link",se.fit =T)
> >>
> >> predict(admb1,newdatos1,type="link",se.fit =T)
> >>
> >> I realized that se.fit differ a lot between them, admb se.fit resulted
> >> much much higher (fit is almost identical). This is just and example of
> >> what I found:
> >>
> >> glm1$se.fit	admb1$se.fit
> >> 0.04290869	0.2676562
> >> 0.04435600	0.2733130
> >> 0.04095631	0.2728592
> >> 0.03402992	0.2718389
> >> 0.03000669	0.2713617
> >> 0.03633637	0.2722059
> >>
> >> Maybe I'm missing something or I am making a big mistake. Any help with
> >> this?
> >>
> >>
> >> Many thanks,
> >>
> >> Alexandre Alonso
> >>
> >>
> >> 	[[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From alex at iim.csic.es  Wed May  4 15:59:52 2016
From: alex at iim.csic.es (Xandre)
Date: Wed, 4 May 2016 15:59:52 +0200
Subject: [R-sig-ME] Why se.fit differ in predict.glm and
	predict.glmmadmb?
In-Reply-To: <1462369668.417.4.camel@loki>
References: <384d50e7-7d81-6c24-e75a-05b01174e4b4@iim.csic.es>
	<57292616.4020702@gmail.com>
	<be22997f-025f-cf26-5a59-d196bf09e0fb@iim.csic.es>
	<1462369668.417.4.camel@loki>
Message-ID: <c67dfc93-9304-7a50-04ce-ab1230228b2d@iim.csic.es>

I am aware of that, sorry. Hopefully, with the following link, 
https://www.dropbox.com/s/pptl595chabjtly/datos.csv?dl=0 , the example 
will be completely reproducible.

Regards,

Alex


El 04/05/2016 a las 15:47, Phillip Alday escribi?:
> Hi Alex,
>
> Attachments aren't put through to the mailing list, you need to put them
> on a publicly available share.
>
> But thanks for putting forth a (soon-to-be) reproducible example!
>
> Best,
> Phillip
>
> On Wed, 2016-05-04 at 10:49 +0200, Xandre wrote:
>> Thanks for the interest,
>>
>> Just to check problems of code I tried again with a much more simple
>> example. I made a subset of my original data base (see attached .csv)
>> and run a much more simple model as follows:
>>
>> *> M1<-glm(response~explanatory, **
>> **+           data=datos,**
>> **+           family="binomial")**
>> **> M2<-glmmadmb(response~explanatory, **
>> **+                 data=datos,**
>> **+                 family="binomial")**
>> **> **
>> **> summary(M1)*
>>
>> Call:
>> glm(formula = response ~ explanatory, family = "binomial", data = datos)
>>
>> Deviance Residuals:
>>      Min      1Q  Median      3Q     Max
>> -1.272  -1.226   1.089   1.128   1.549
>>
>> Coefficients:
>>                 Estimate Std. Error z value Pr(>|z|)
>> (Intercept)  2.537e-01  6.638e-02   3.822 0.000132 ***
>> explanatory -1.660e-04  5.214e-05  -3.183 0.001456 **
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> (Dispersion parameter for binomial family taken to be 1)
>>
>>       Null deviance: 3461.2  on 2499  degrees of freedom
>> Residual deviance: 3450.9  on 2498  degrees of freedom
>> AIC: 3454.9
>>
>> Number of Fisher Scoring iterations: 3
>>
>> *> summary(M2)*
>>
>> Call:
>> glmmadmb(formula = response ~ explanatory, data = datos, family =
>> "binomial")
>>
>> AIC: 3454.9
>>
>> Coefficients:
>>                Estimate Std. Error z value Pr(>|z|)
>> (Intercept)  2.54e-01   6.64e-02    3.82  0.00013 ***
>> explanatory -1.66e-04   5.21e-05   -3.18  0.00146 **
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> Number of observations: total=2500
>>
>> Log-likelihood: -1725.45
>>   >
>> *> newdatos <-
>> data.frame(explanatory=seq(min(datos$explanatory),max(datos$explanatory),length.out=10))*
>>   >
>> *> pred1<-predict(M1,newdatos,type="link",se.fit =T)**
>> **> pred2<-predict(M2,newdatos,type="link",se.fit =T)*
>>   >
>> *> cbind(pred1$fit,pred2$fit)*
>>             [,1]        [,2]
>> 1   0.22051737  0.22051798
>> 2   0.09972924  0.09972896
>> 3  -0.02105888 -0.02106007
>> 4  -0.14184701 -0.14184909
>> 5  -0.26263513 -0.26263811
>> 6  -0.38342326 -0.38342713
>> 7  -0.50421139 -0.50421615
>> 8  -0.62499951 -0.62500518
>> 9  -0.74578764 -0.74579420
>> 10 -0.86657576 -0.86658322
>> *> cbind(pred1$se.fit,pred2$se.fit)*
>>            [,1]       [,2]
>> 1  0.05841106 0.06724456
>> 2  0.04037125 0.08232769
>> 3  0.05222381 0.10914997
>> 4  0.08187989 0.14117163
>> 5  0.11645089 0.17557048
>> 6  0.15263291 0.21118808
>> 7  0.18950541 0.24749882
>> 8  0.22673178 0.28423718
>> 9  0.26416245 0.32125649
>> 10 0.30172140 0.35846971
>>
>> #Although now de differences are lower, I think they still are quite
>> important.
>>
>> This is my *sessionInfo()*:
>>
>> R version 3.2.4 Revised (2016-03-16 r70336)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows 7 x64 Service Pack 1
>>
>> locale:
>> [1] LC_COLLATE=Spanish_Spain.1252  LC_CTYPE=Spanish_Spain.1252
>> LC_MONETARY=Spanish_Spain.1252
>> [4] LC_NUMERIC=C                   LC_TIME=Spanish_Spain.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods base
>>
>> other attached packages:
>> [1] glmmADMB_0.8.3.3 MASS_7.3-45
>>
>> loaded via a namespace (and not attached):
>>    [1] Matrix_1.2-4    plyr_1.8.3      magrittr_1.5 tools_3.2.4
>> coda_0.18-1     Rcpp_0.12.4     stringi_1.0-1
>>    [8] nlme_3.1-126    grid_3.2.4      stringr_1.0.0 R2admb_0.7.13
>> lattice_0.20-33
>>
>>
>> Hopefully all this info will be helpful.
>>
>> Thanks in advance for your time.
>>
>> Regards,
>>
>> Alex
>>
>>
>> El 04/05/2016 a las 0:28, Ben Bolker escribi?:
>>>     Not sure, this will be worth looking into ...
>>>
>>> On 16-05-03 04:51 PM, Xandre wrote:
>>>> Dear list,
>>>>
>>>> I am running a GLM (family="binomial") without random effects using both
>>>> glm and glmmadmb.
>>>>
>>>> Summaries are almost identical, however when I used the predict function
>>>> as follows:
>>>>
>>>> predict(glm1,newdatos1,type="link",se.fit =T)
>>>>
>>>> predict(admb1,newdatos1,type="link",se.fit =T)
>>>>
>>>> I realized that se.fit differ a lot between them, admb se.fit resulted
>>>> much much higher (fit is almost identical). This is just and example of
>>>> what I found:
>>>>
>>>> glm1$se.fit	admb1$se.fit
>>>> 0.04290869	0.2676562
>>>> 0.04435600	0.2733130
>>>> 0.04095631	0.2728592
>>>> 0.03402992	0.2718389
>>>> 0.03000669	0.2713617
>>>> 0.03633637	0.2722059
>>>>
>>>> Maybe I'm missing something or I am making a big mistake. Any help with
>>>> this?
>>>>
>>>>
>>>> Many thanks,
>>>>
>>>> Alexandre Alonso
>>>>
>>>>
>>>> 	[[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bates at stat.wisc.edu  Wed May  4 20:06:39 2016
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 04 May 2016 18:06:39 +0000
Subject: [R-sig-ME] Is multi-level modelling applicable to crossed
	designs?
In-Reply-To: <88B10DA7113B8F4C8E7710DD8F4879BE81EE51@AAI-EXCH-MBX2.campus.unibe.ch>
References: <88B10DA7113B8F4C8E7710DD8F4879BE81EE51@AAI-EXCH-MBX2.campus.unibe.ch>
Message-ID: <CAO7JsnRri65dC=x7Wp+zMQhbmqdkrkvrwCi21RzD5Tzh96uiUg@mail.gmail.com>

"Multilevel model" and "hierarchical linear model" are terms that are
outmoded and, in my opinion, introduce more confusion than illumination. In
some ways you are better off ignoring such descriptions.

To begin with you should distinguish between experimental factors, like
Treatment, and blocking factors, like Clinic.  Random effects are
associated with blocking factors, like Clinic, which show up on the right
hand side of the | in a random-effects term like (Treatment | Clinic).
Experimental factors occur in fixed-effects terms and on the left hand side
of the | in random-effects terms.  In your case you only have one factor,
Clinic, for which there are random-effects. The characterization of
"levels" or, as we term them, the "grouping factors" for the random-effects
terms, only applies to the blocking factors.

Treatment is an experimental factor with clearly defined, reproducible
levels.  Thus it is modeled as a fixed-effects term.  (Note that the name
"fixed-effects" is a misnomer - it is the levels of the factor that are
fixed, not the effects of these levels.)  The Clinic factor is a blocking
factor - a known source of variability for which we must control.  The
levels represent a sample from a population of clinics that could
participate in the trial.  These levels could be different in another trial.

A term like (1 | Clinic) allows for an additive shift between clinics
whereas a term like (1 + Treatment | Clinic) allows for the additive shift
plus a shift in the effect of each level of treatment between clinic.  You
should not use  (1 | Clinic) + (Treatment | Clinic) because the latter term
expands to (1 + Treatment | Clinic) and you would have the shift by Clinic
of the intercept in the model twice.

For this to make sense you must have different treatments applied at the
same clinic.   In other words, it would be a mistake to try to use a term
like (1 + Treatment | Clinic)l if Clinic was nested within Treatment.  But
you should be able to figure that out - how can I measure an effect for the
change in Treatment within each Clinic if only one Treatment is used at
each clinic?

In the language of multilevel models you have two levels of variability
here, the residual or per-observation random variability and the
variability between clinics.  With only one grouping factor for random
effects (Clinic) or a two-level model, there is no concept of nested or
non-nested for the random-effects terms.

If you had another known source of variability, say Doctor, it could be
nested within Clinic (each Doctor practices at only one Clinic) or it could
be non-nested (at least one of the Doctor's is seeing patients in the trial
at more than one of the clinics).  The latter case is neither nested nor
completely crossed.  It is a case of partially crossed factors.  It is
perhaps easier to think of examples in Subject/Item types of experiments.
Experiments in Psychology often have completely crossed random effects
where each of a sample of subjects is exposed to each of a sample of items
and both the subjects and the items represent samples from populations.  In
a rater experiment, say Netflix-like data where people rate movies, there
may be a large number of raters and a large number of movies but you don't
expect every subject to rate every movie.

The point of the methods behind the lme4 package is that they can handle
nested or partially crossed or completely crossed factors.  Earlier
software for multilevel models or hierarchical linear models depended upon
having a nested structure for the grouping factors in the random effects.
There are certain simplifications available with nested factors.  (Again,
let me emphasize that this is for the blocking factors only).  It is okay
to use such simplifications except that the descriptions tended to conflate
mixed-effects models with multilevel models, as in the passage you quote.
Multilevel models or hierarchical models are a subset of linear or
generalized linear mixed-effects models.  Also, the descriptions of the
models emphasized the levels of the hierarchy for the grouping factors and
for the experimental factors.

I hope this helps.


On Wed, May 4, 2016 at 7:04 AM <bernhard.voelkl at vetsuisse.unibe.ch> wrote:

> Is multi-level modelling applicable to fully-crossed designs?
> Dear mailing list,
> Dear Ben,
>
> The more I read about multi-level models the more confused I get. What I
> have read now in several different sources (e.g. Moerbeek & Teerenstra
> 2016) are statements like this: (1) .. multilevel
> model is also known as the hierarchical model, mixed effects model, random
> coefficient model or variance component model. And (2) The multilevel model
> differs from the traditional (single level) model since it explicitly
> accounts for the nested (sic) data structure by including random effects
> at the group level.
>
> Now, here is my question: the design that I have is one that would be
> classically described as ?crossed design? and the classical textbooks go at
> length emphasising the difference between ?nested? and ?crossed? (which
> also leads to different ways for calculating degrees of freedom and
> standard errors in the fixed-factor case). My question: can I use mixed
> models for analysing a crossed design? Does the distinction between nested
> and crossed make any sense in the hierarchical/multilevel modelling
> approach?
>
> In R-speak: does Y ~ Treatment + (1|Clinic) + (Treatment|Clinic) make
> sense if Clinic and Treatment are crossed (not nested) factors but
> Treatment is fixed while Clinic is random?
>
> To be more concrete here is my setup: I have a large pool of subjects
> which I can randomly distribute to a number of clinics. At each clinic
> subjects are (randomly) divided into two groups and get either treatment A
> or treatment B. Then I take one measure from each subject. Subjects are
> really randomly distributed to clinics and at all clinics exactly the same
> treatments are applied. This is a classical crossed design. Treatment is
> clearly a fixed factor but I would like to treat clinic as a random factor
> (as I have many clinics, they are a sample of all existing clinics and I
> want to make generalizations beyond the specific clinics).
>
> (Just to clarify: I searched both ?Ecological Models and Data in R? and
> the Gelman/Hill book ?Data analysis using regression and
> multilevel/hierarchical models? but both did not explicitly mention crossed
> designs, yet in a relatively recent points-of-significance in Nature
> Methods (2014, 11, 977-978) Krzywinski nicely explains the difference
> between nested and crossed, so it doesn?t seem to be an obsolete
> distinction.)
>
> Any help highly appreciated!
> Kind regards,
> Bernhard
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From pierces1 at msu.edu  Wed May  4 20:23:41 2016
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Wed, 4 May 2016 14:23:41 -0400
Subject: [R-sig-ME] Is multi-level modelling applicable to crossed
	designs?
In-Reply-To: <88B10DA7113B8F4C8E7710DD8F4879BE81EE51@AAI-EXCH-MBX2.campus.unibe.ch>
References: <88B10DA7113B8F4C8E7710DD8F4879BE81EE51@AAI-EXCH-MBX2.campus.unibe.ch>
Message-ID: <000d01d1a632$162823c0$42786b40$@msu.edu>

Bernhard,

You may find Chapter 12 in the following book useful. 

Raudenbush, S. W., & Bryk, A. S. (2002). Hierarchical linear models: Applications and data analysis methods (2nd ed.). Thousand Oaks, CA: Sage Publications.

Steven J. Pierce, Ph.D.
Associate Director
Center for Statistical Training & Consulting (CSTAT)
Michigan State University

-----Original Message-----
From: bernhard.voelkl at vetsuisse.unibe.ch [mailto:bernhard.voelkl at vetsuisse.unibe.ch] 
Sent: Wednesday, May 04, 2016 6:30 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Is multi-level modelling applicable to crossed designs?

Is multi-level modelling applicable to fully-crossed designs?
Dear mailing list,
Dear Ben,

The more I read about multi-level models the more confused I get. What I have read now in several different sources (e.g. Moerbeek & Teerenstra 2016) are statements like this: (1) .. multilevel
model is also known as the hierarchical model, mixed effects model, random coefficient model or variance component model. And (2) The multilevel model differs from the traditional (single level) model since it explicitly accounts for the nested (sic) data structure by including random effects
at the group level.

Now, here is my question: the design that I have is one that would be classically described as ?crossed design? and the classical textbooks go at length emphasising the difference between ?nested? and ?crossed? (which also leads to different ways for calculating degrees of freedom and standard errors in the fixed-factor case). My question: can I use mixed models for analysing a crossed design? Does the distinction between nested and crossed make any sense in the hierarchical/multilevel modelling approach?

In R-speak: does Y ~ Treatment + (1|Clinic) + (Treatment|Clinic) make sense if Clinic and Treatment are crossed (not nested) factors but Treatment is fixed while Clinic is random?

To be more concrete here is my setup: I have a large pool of subjects which I can randomly distribute to a number of clinics. At each clinic subjects are (randomly) divided into two groups and get either treatment A or treatment B. Then I take one measure from each subject. Subjects are really randomly distributed to clinics and at all clinics exactly the same treatments are applied. This is a classical crossed design. Treatment is clearly a fixed factor but I would like to treat clinic as a random factor (as I have many clinics, they are a sample of all existing clinics and I want to make generalizations beyond the specific clinics).

(Just to clarify: I searched both ?Ecological Models and Data in R? and the Gelman/Hill book ?Data analysis using regression and multilevel/hierarchical models? but both did not explicitly mention crossed designs, yet in a relatively recent points-of-significance in Nature Methods (2014, 11, 977-978) Krzywinski nicely explains the difference between nested and crossed, so it doesn?t seem to be an obsolete distinction.)

Any help highly appreciated!
Kind regards,
Bernhard

	[[alternative HTML version deleted]]


From robgriffin247 at hotmail.com  Thu May  5 14:34:24 2016
From: robgriffin247 at hotmail.com (Rob Griffin)
Date: Thu, 5 May 2016 14:34:24 +0200
Subject: [R-sig-ME] strong effect of prior on residual variance
Message-ID: <DUB124-W17637265016C46EB279EABFA7C0@phx.gbl>




Dear list members,
I'm using MCMCglmm to model variance among ~90 cohorts as a result of an environmental factor ("B" - numerical). "T" is the response variable, which is formed as a ratio, with mean ~1 & is normally distributed. The cohorts come from two different populations, where each cohort is defined by the place and year of birth (e.g. one cohort is all individuals born in one area, A1, in 2014), such that there is one value of T per cohort. B is measured on a larger level, so there is one score of B per year, regardless of population. I include Area as a fixed effect (factor with two levels) because in some years only one area is measured so it may induce sampling bias of the environmental effect (e.g. one year where only one area is measured has an extreme B score). From a biological perspective I expect B to have a small impact on the among-cohort variance in T so I've used parameter expanded priors for the random effect and inverse-wishart for the residual (as suggested to a previous thread I started - on priors for small variance components - last year: https://stat.ethz.ch/pipermail/r-sig-mixed-models/2015q1/023370.html).
When I used similar set up to my previous model (see code below) I find that, contrary to my expectation, B has a relatively large variance estimate compared to the residual (both mean and median of the posterior for B is 10x higher than residual). It seems unlikely that 90% of the variance in T is explained by B.
This prompted me to fiddle with the prior specification to make sure nothing was wrong... Settings used were nu = 0.002 or 2, & V = 1 or 10 (for the priors in R with all four combinations of V and nu tested), also producing 4 independent chains with 100k iterations, 25k burnin, and thinning interval of 50 for each; autocorrelation is low (<0.1 between successive samples), convergence appears good for both B and Residual. The estimate of variance (both the median and mean of the posterior) is similar across the four chains, within each combination of nu and V, for both B and Residual.
In the previous thread it is pointed out that "Usually the data overwhelm the prior for the residual variance so you can probably be pretty relaxed about that." I find that estimates of B and residual (units) are generally insensitive to changes in any of the parameters in G, but highly sensitive to changes in both the belief and variance inputs for R (increases in nu and V both increase the estimate of residual, while also absorbing variance from the random effect B). Given the statement that data usually overwhelm the prior, should I be concerned that the prior is strongly affecting the estimate of residual (and random effects) variance in this case? How should this be interpreted and dealt with? The consistency across independent chains suggests to me that the model is able to estimate B and residual variances well, but is drawing too much information from the prior rather than the data, and therefore I'm using the wrong prior.
Thanks,Rob
####################prior1 = list(G = list(	 G1 = list(V = 1, nu=0.001, alpha.mu=0, alpha.V=1000)					),				        R  = list(V = 1, nu=0.001))	M1A = MCMCglmm(	T ~ 1 + Area	,random = ~ B 	,data = DF3	,nitt = nitt	,burnin = burnin	,thin = thin	,family = "gaussian"	,prior = prior1	)


 		 	   		  
	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Thu May  5 14:47:37 2016
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 5 May 2016 13:47:37 +0100
Subject: [R-sig-ME] strong effect of prior on residual variance
In-Reply-To: <DUB124-W17637265016C46EB279EABFA7C0@phx.gbl>
References: <DUB124-W17637265016C46EB279EABFA7C0@phx.gbl>
Message-ID: <572B40E9.8080507@ed.ac.uk>

Hi Rob,

1) how many observations are there per cohort on average?
2) how many levels does B have in it?
3) nu=1 is typical in a parameter expanded prior, as this is flat for 
the standard deviation.

Cheers,

Jarrod



On 05/05/2016 13:34, Rob Griffin wrote:
>
>
> Dear list members,
> I'm using MCMCglmm to model variance among ~90 cohorts as a result of an environmental factor ("B" - numerical). "T" is the response variable, which is formed as a ratio, with mean ~1 & is normally distributed. The cohorts come from two different populations, where each cohort is defined by the place and year of birth (e.g. one cohort is all individuals born in one area, A1, in 2014), such that there is one value of T per cohort. B is measured on a larger level, so there is one score of B per year, regardless of population. I include Area as a fixed effect (factor with two levels) because in some years only one area is measured so it may induce sampling bias of the environmental effect (e.g. one year where only one area is measured has an extreme B score). From a biological perspective I expect B to have a small impact on the among-cohort variance in T so I've used parameter expanded priors for the random effect and inverse-wishart for the residual (as suggested to a previou!
>   s thread I started - on priors for small variance components - last year: https://stat.ethz.ch/pipermail/r-sig-mixed-models/2015q1/023370.html).
> When I used similar set up to my previous model (see code below) I find that, contrary to my expectation, B has a relatively large variance estimate compared to the residual (both mean and median of the posterior for B is 10x higher than residual). It seems unlikely that 90% of the variance in T is explained by B.
> This prompted me to fiddle with the prior specification to make sure nothing was wrong... Settings used were nu = 0.002 or 2, & V = 1 or 10 (for the priors in R with all four combinations of V and nu tested), also producing 4 independent chains with 100k iterations, 25k burnin, and thinning interval of 50 for each; autocorrelation is low (<0.1 between successive samples), convergence appears good for both B and Residual. The estimate of variance (both the median and mean of the posterior) is similar across the four chains, within each combination of nu and V, for both B and Residual.
> In the previous thread it is pointed out that "Usually the data overwhelm the prior for the residual variance so you can probably be pretty relaxed about that." I find that estimates of B and residual (units) are generally insensitive to changes in any of the parameters in G, but highly sensitive to changes in both the belief and variance inputs for R (increases in nu and V both increase the estimate of residual, while also absorbing variance from the random effect B). Given the statement that data usually overwhelm the prior, should I be concerned that the prior is strongly affecting the estimate of residual (and random effects) variance in this case? How should this be interpreted and dealt with? The consistency across independent chains suggests to me that the model is able to estimate B and residual variances well, but is drawing too much information from the prior rather than the data, and therefore I'm using the wrong prior.
> Thanks,Rob
> ####################prior1 = list(G = list(	 G1 = list(V = 1, nu=0.001, alpha.mu=0, alpha.V=1000)					),				        R  = list(V = 1, nu=0.001))	M1A = MCMCglmm(	T ~ 1 + Area	,random = ~ B 	,data = DF3	,nitt = nitt	,burnin = burnin	,thin = thin	,family = "gaussian"	,prior = prior1	)
>
>
>   		 	   		
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From robgriffin247 at hotmail.com  Thu May  5 15:08:39 2016
From: robgriffin247 at hotmail.com (Rob Griffin)
Date: Thu, 5 May 2016 15:08:39 +0200
Subject: [R-sig-ME] strong effect of prior on residual variance
In-Reply-To: <572B40E9.8080507@ed.ac.uk>
References: <DUB124-W17637265016C46EB279EABFA7C0@phx.gbl>,
	<572B40E9.8080507@ed.ac.uk>
Message-ID: <DUB124-W2DAA69D45EC6D01E74CC4FA7C0@phx.gbl>

Hi Jarrod,
Thanks for the speedy response,
There is just one measure of T per cohort. T is sexual dimorphism in a trait, so its a cohort level value - individuals can't be sexually dimorphic: it was calculated using mcmcglmm to estimate cohort-specific posterior distributions for both male and female trait values, then randomising the order of the distributions and dividing them (Male[sample_i]/Female[sample_i]) where i is 1:1000. I then took the mean of the posterior for each cohort as my response variable. It's much the same as one could do to derive a posterior distribution of heritability when given posterior distributions of additive and phenotypic variation (also as stated on page 5 of the course notes). Perhaps it would be more appropriate to use the entire posterior distributions of SD for all 90 cohort rather than the just means (so there would be 1000 samples of SD per cohort)?
B is a numerical variable, if expressed as a factor it has 65 levels (not all years have a measure of B). Should this be converted to a factor?
Cheers,Rob
> Subject: Re: [R-sig-ME] strong effect of prior on residual variance
> To: robgriffin247 at hotmail.com; r-sig-mixed-models at r-project.org
> From: j.hadfield at ed.ac.uk
> Date: Thu, 5 May 2016 13:47:37 +0100
> 
> Hi Rob,
> 
> 1) how many observations are there per cohort on average?
> 2) how many levels does B have in it?
> 3) nu=1 is typical in a parameter expanded prior, as this is flat for 
> the standard deviation.
> 
> Cheers,
> 
> Jarrod
> 
> 
> 
> On 05/05/2016 13:34, Rob Griffin wrote:
> >
> >
> > Dear list members,
> > I'm using MCMCglmm to model variance among ~90 cohorts as a result of an environmental factor ("B" - numerical). "T" is the response variable, which is formed as a ratio, with mean ~1 & is normally distributed. The cohorts come from two different populations, where each cohort is defined by the place and year of birth (e.g. one cohort is all individuals born in one area, A1, in 2014), such that there is one value of T per cohort. B is measured on a larger level, so there is one score of B per year, regardless of population. I include Area as a fixed effect (factor with two levels) because in some years only one area is measured so it may induce sampling bias of the environmental effect (e.g. one year where only one area is measured has an extreme B score). From a biological perspective I expect B to have a small impact on the among-cohort variance in T so I've used parameter expanded priors for the random effect and inverse-wishart for the residual (as suggested to a previou!
> >   s thread I started - on priors for small variance components - last year: https://stat.ethz.ch/pipermail/r-sig-mixed-models/2015q1/023370.html).
> > When I used similar set up to my previous model (see code below) I find that, contrary to my expectation, B has a relatively large variance estimate compared to the residual (both mean and median of the posterior for B is 10x higher than residual). It seems unlikely that 90% of the variance in T is explained by B.
> > This prompted me to fiddle with the prior specification to make sure nothing was wrong... Settings used were nu = 0.002 or 2, & V = 1 or 10 (for the priors in R with all four combinations of V and nu tested), also producing 4 independent chains with 100k iterations, 25k burnin, and thinning interval of 50 for each; autocorrelation is low (<0.1 between successive samples), convergence appears good for both B and Residual. The estimate of variance (both the median and mean of the posterior) is similar across the four chains, within each combination of nu and V, for both B and Residual.
> > In the previous thread it is pointed out that "Usually the data overwhelm the prior for the residual variance so you can probably be pretty relaxed about that." I find that estimates of B and residual (units) are generally insensitive to changes in any of the parameters in G, but highly sensitive to changes in both the belief and variance inputs for R (increases in nu and V both increase the estimate of residual, while also absorbing variance from the random effect B). Given the statement that data usually overwhelm the prior, should I be concerned that the prior is strongly affecting the estimate of residual (and random effects) variance in this case? How should this be interpreted and dealt with? The consistency across independent chains suggests to me that the model is able to estimate B and residual variances well, but is drawing too much information from the prior rather than the data, and therefore I'm using the wrong prior.
> > Thanks,Rob
> > ####################prior1 = list(G = list(	 G1 = list(V = 1, nu=0.001, alpha.mu=0, alpha.V=1000)					),				        R  = list(V = 1, nu=0.001))	M1A = MCMCglmm(	T ~ 1 + Area	,random = ~ B 	,data = DF3	,nitt = nitt	,burnin = burnin	,thin = thin	,family = "gaussian"	,prior = prior1	)
> >
> >
> >   		 	   		
> > 	[[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
> 
> 
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
> 
 		 	   		  
	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Thu May  5 15:41:03 2016
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 5 May 2016 14:41:03 +0100
Subject: [R-sig-ME] strong effect of prior on residual variance
In-Reply-To: <DUB124-W2DAA69D45EC6D01E74CC4FA7C0@phx.gbl>
References: <DUB124-W17637265016C46EB279EABFA7C0@phx.gbl>
	<572B40E9.8080507@ed.ac.uk>
	<DUB124-W2DAA69D45EC6D01E74CC4FA7C0@phx.gbl>
Message-ID: <572B4D6F.7010903@ed.ac.uk>

Hi,

It doesn't make sense to have B as a random effect - it should be a 
fixed effect. The sensitivity of the prior is because there are almost 
as many levels of B as there are observations, so there is a one-to-one 
mapping between B and the residuals.

If you want to model sexual dimorphism (for example as a function of B) 
why not have a sex by B interaction?

Cheers,

Jarrod


On 05/05/2016 14:08, Rob Griffin wrote:
> Hi Jarrod,
>
> Thanks for the speedy response,
>
> There is just one measure of T per cohort. T is sexual dimorphism in a 
> trait, so its a cohort level value - individuals can't be sexually 
> dimorphic: it was calculated using mcmcglmm to estimate 
> cohort-specific posterior distributions for both male and female trait 
> values, then randomising the order of the distributions and dividing 
> them (Male[sample_i]/Female[sample_i]) where i is 1:1000. I then took 
> the mean of the posterior for each cohort as my response variable. 
> It's much the same as one could do to derive a posterior distribution 
> of heritability when given posterior distributions of additive and 
> phenotypic variation (also as stated on page 5 of the course notes). 
> Perhaps it would be more appropriate to use the entire posterior 
> distributions of SD for all 90 cohort rather than the just means (so 
> there would be 1000 samples of SD per cohort)?
>
> B is a numerical variable, if expressed as a factor it has 65 levels 
> (not all years have a measure of B). Should this be converted to a factor?
>
> Cheers,
> Rob
>
> > Subject: Re: [R-sig-ME] strong effect of prior on residual variance
> > To: robgriffin247 at hotmail.com; r-sig-mixed-models at r-project.org
> > From: j.hadfield at ed.ac.uk
> > Date: Thu, 5 May 2016 13:47:37 +0100
> >
> > Hi Rob,
> >
> > 1) how many observations are there per cohort on average?
> > 2) how many levels does B have in it?
> > 3) nu=1 is typical in a parameter expanded prior, as this is flat for
> > the standard deviation.
> >
> > Cheers,
> >
> > Jarrod
> >
> >
> >
> > On 05/05/2016 13:34, Rob Griffin wrote:
> > >
> > >
> > > Dear list members,
> > > I'm using MCMCglmm to model variance among ~90 cohorts as a result 
> of an environmental factor ("B" - numerical). "T" is the response 
> variable, which is formed as a ratio, with mean ~1 & is normally 
> distributed. The cohorts come from two different populations, where 
> each cohort is defined by the place and year of birth (e.g. one cohort 
> is all individuals born in one area, A1, in 2014), such that there is 
> one value of T per cohort. B is measured on a larger level, so there 
> is one score of B per year, regardless of population. I include Area 
> as a fixed effect (factor with two levels) because in some years only 
> one area is measured so it may induce sampling bias of the 
> environmental effect (e.g. one year where only one area is measured 
> has an extreme B score). From a biological perspective I expect B to 
> have a small impact on the among-cohort variance in T so I've used 
> parameter expanded priors for the random effect and inverse-wishart 
> for the residual (as suggested to a previou!
> > > s thread I started - on priors for small variance components - 
> last year: 
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2015q1/023370.html).
> > > When I used similar set up to my previous model (see code below) I 
> find that, contrary to my expectation, B has a relatively large 
> variance estimate compared to the residual (both mean and median of 
> the posterior for B is 10x higher than residual). It seems unlikely 
> that 90% of the variance in T is explained by B.
> > > This prompted me to fiddle with the prior specification to make 
> sure nothing was wrong... Settings used were nu = 0.002 or 2, & V = 1 
> or 10 (for the priors in R with all four combinations of V and nu 
> tested), also producing 4 independent chains with 100k iterations, 25k 
> burnin, and thinning interval of 50 for each; autocorrelation is low 
> (<0.1 between successive samples), convergence appears good for both B 
> and Residual. The estimate of variance (both the median and mean of 
> the posterior) is similar across the four chains, within each 
> combination of nu and V, for both B and Residual.
> > > In the previous thread it is pointed out that "Usually the data 
> overwhelm the prior for the residual variance so you can probably be 
> pretty relaxed about that." I find that estimates of B and residual 
> (units) are generally insensitive to changes in any of the parameters 
> in G, but highly sensitive to changes in both the belief and variance 
> inputs for R (increases in nu and V both increase the estimate of 
> residual, while also absorbing variance from the random effect B). 
> Given the statement that data usually overwhelm the prior, should I be 
> concerned that the prior is strongly affecting the estimate of 
> residual (and random effects) variance in this case? How should this 
> be interpreted and dealt with? The consistency across independent 
> chains suggests to me that the model is able to estimate B and 
> residual variances well, but is drawing too much information from the 
> prior rather than the data, and therefore I'm using the wrong prior.
> > > Thanks,Rob
> > > ####################prior1 = list(G = list( G1 = list(V = 1, 
> nu=0.001, alpha.mu=0, alpha.V=1000) ), R = list(V = 1, nu=0.001)) M1A 
> = MCMCglmm( T ~ 1 + Area ,random = ~ B ,data = DF3 ,nitt = nitt 
> ,burnin = burnin ,thin = thin ,family = "gaussian" ,prior = prior1 )
> > >
> > >
> > >
> > > [[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >
> >
> >
> >
> > --
> > The University of Edinburgh is a charitable body, registered in
> > Scotland, with registration number SC005336.
> >

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20160505/f4badedb/attachment.pl>

From xiaomali at iastate.edu  Thu May  5 15:46:41 2016
From: xiaomali at iastate.edu (Li, Xiaoma [GE AT])
Date: Thu, 5 May 2016 13:46:41 +0000
Subject: [R-sig-ME] question about predict using lme4
Message-ID: <BN3PR04MB236950176CB270E8CC781878C97C0@BN3PR04MB2369.namprd04.prod.outlook.com>

Hi all,
I want to use lme4 to predict air temperature using land surface temperature.
I now can ran the package successfully. But I am not familiar to the parameters of the predict function. Here is my code: plsttest=predict(mod.xm,lsttest2,allow.new.levels = T)
I have two questions: Is there some parameters missed?
How does lme4 predict new levels (new climate station in my study?) Does it use fixed model or others?

Thank you very much!

Sincerely
Xiaoma li

	[[alternative HTML version deleted]]


From hughes.dupond at gmx.de  Thu May  5 17:45:50 2016
From: hughes.dupond at gmx.de (Lionel)
Date: Thu, 5 May 2016 17:45:50 +0200
Subject: [R-sig-ME] question about predict using lme4
In-Reply-To: <BN3PR04MB236950176CB270E8CC781878C97C0@BN3PR04MB2369.namprd04.prod.outlook.com>
References: <BN3PR04MB236950176CB270E8CC781878C97C0@BN3PR04MB2369.namprd04.prod.outlook.com>
Message-ID: <572B6AAE.5000909@gmx.de>

Dear Xiaoma Li,

To answer your questions:

- No parameters are missed (why should they?)

- If you have in your lsttest2 data frame new levels for the random 
factors, new random deviates will be generated for these levels from a 
normal distribution with mean 0 and standard deviation equal to the 
estimated random standard deviation (to get these estimated values look 
at the summary output).

Hope this helps.

Yours,
Lionel

On 05/05/2016 15:46, Li, Xiaoma [GE AT] wrote:
> Hi all,
> I want to use lme4 to predict air temperature using land surface temperature.
> I now can ran the package successfully. But I am not familiar to the parameters of the predict function. Here is my code: plsttest=predict(mod.xm,lsttest2,allow.new.levels = T)
> I have two questions: Is there some parameters missed?
> How does lme4 predict new levels (new climate station in my study?) Does it use fixed model or others?
>
> Thank you very much!
>
> Sincerely
> Xiaoma li
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From dsidhu at ucalgary.ca  Thu May  5 21:47:35 2016
From: dsidhu at ucalgary.ca (David Sidhu)
Date: Thu, 5 May 2016 19:47:35 +0000
Subject: [R-sig-ME] How sinful is it to...
Message-ID: <491B84B7-B655-4538-85FD-BF3DCA79EDEA@ucalgary.ca>

Hi Everyone!

I am conducting a mixed model logistic regression analysis of some simple experimental data in which participants made dichotomous choices. My independent variable has two levels. What I am really interested in is the ability of the independent variable to predict the dependent variable, with the random effects in there simply to allow the best test of this.

I am starting from the point of view that I should ?keep it maximal?. That being said my two questions are:

  *   Is there something horrible about keeping in random effects that are highly (or perfectly!) correlated with one another?
     *   If so?would you retain the term that gives you the best model, based on AIC or some other value?
  *   Should you always remove random effects that have 0 variance associated with them?

It seems like the intuitive answer to both of these is yes. But in this paper I am working on, there are several experiments, and for simplicity?s sake it would be much easier to always just have the maximally complex random effects structure that managed to converge, instead of giving details in each case about which terms were removed and why. But is there something horrible wrong with that??

Thanks!

Dave

---

David M. Sidhu, MSc
PhD Student
Department of Psychology
University of Calgary


	[[alternative HTML version deleted]]


From dexter.locke at gmail.com  Thu May  5 20:20:10 2016
From: dexter.locke at gmail.com (Dexter Locke)
Date: Thu, 5 May 2016 14:20:10 -0400
Subject: [R-sig-ME] extract level 2 residuals of merMod from lme() and test
	for spatial autocorrelation.
Message-ID: <CAA=SVwFSEj3XBQ7VCu_ZFc4fBbt1zRfvx9jj919YpAHuo-kCzw@mail.gmail.com>

Apologies for cross-posting, another version of this was posted on
r-sig-geo at r-project.org

I want to extract the level 2 residuals from a merMod object created with
lme() and am struggling. How can I pull out a vector that is the residuals
at level 2? Everything I see on stack exchange and the mixed models list
serve points towards methods like VarCorr(). I'm not interested in a
summary of the L2 residuals so much as a vector of the same length as the
number of groups I have. Ultimately I want to test them for spatial
autocorrelation. Apologies if this is documented somewhere, but I have not
been able to find help online.

While I have found methods of incorporating spatial effects into a mixed
model using corStruct, I am interested in first evaluating if that is an
appropriate model for a given dataset by examining the level 2 residuals'
spatial patterning - or lack thereof.

Which slot contains the residuals for level 2 and how are they ordered?

Thanks again for a great package.

Best,
Dexter

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Sat May  7 17:34:30 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 7 May 2016 11:34:30 -0400
Subject: [R-sig-ME] Comparing mixed models
In-Reply-To: <CAGAvxRn2AB=ZhkQWtKYLFg9pRj9mT=D5t=7RpM-aJuoj+q3=Xw@mail.gmail.com>
References: <CAGAvxRn2AB=ZhkQWtKYLFg9pRj9mT=D5t=7RpM-aJuoj+q3=Xw@mail.gmail.com>
Message-ID: <CABghstSY5pRv2qw=HtPLa=Xri-D8L=fhzdwLQCi1m0AGUpZL6g@mail.gmail.com>

  My only other comment would be that my standard approach would be to
retain all random effects in the model unless they are causing difficulty
in model fitting -- this depends on your goal (confirmation/testing,
prediction, exploration)

On Sat, May 7, 2016 at 11:26 AM, Carlos Barboza <carlosambarboza at gmail.com>
wrote:

> Dear Dr. Ben Bolker
>
> My name is Carlos Barboza and I am a Marine Biologist from the Rio de
> Janeiro University, Brazil. First it's a pleasure to again have the
> opportunity to send you a message.The reason for it is a simple doubt:
> Can I compare AIC from:
>
> 1. glmmADMB: Density ~ 1 + 1|Site
>
> 2. glmmADMB: Density ~ Sector + 1|Site + Cage
>
> Note that they have different random and fixed structures. I know that
> this is not the best choice to model selection but, I think that the AIC
> values can be compared.
>
> thank you very much for your attention
>
>
>   is Cage a random effect?  Are you intentionally leaving out the
> intercept in the second case (it will be included anyway unless you
> use -1)?  In any case, I don't see any obvious reason you can't
> compare AIC values; see
>
> https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.html#can-i-use-aic-for-mixed-models-how-do-i-count-the-number-of-degrees-of-freedom-for-a-random-effect
>
>   Follow-ups to r-sig-mixed-models at r-project.org, please ...
>
> sorry, yes, cage was included only to examplify a different random
> structure in the second case...it should be coded (1|Site) + (1|Cage)
> yes, I know that the intercept will be included in the second model
>
> it's an example of comparing AIC values from mixed models with different
> fixed and random structures:
>
> 1. Density ~ 1 + 1|Site
>
> 2. Density ~ Sector + 1|Site + 1|Cage
>
> comparing AIC...I beleive that both values can be compared
>
> again, thank you very much for your very fast message
>
>
>
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Sat May  7 20:03:31 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 7 May 2016 18:03:31 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?extract_level_2_residuals_of_merMod_from_lme?=
	=?utf-8?q?=28=29_and_test=09for_spatial_autocorrelation=2E?=
References: <CAA=SVwFSEj3XBQ7VCu_ZFc4fBbt1zRfvx9jj919YpAHuo-kCzw@mail.gmail.com>
Message-ID: <loom.20160507T195150-293@post.gmane.org>

Dexter Locke <dexter.locke at ...> writes:

> 
> Apologies for cross-posting, another version of this was posted on
> r-sig-geo at ...
> 
> I want to extract the level 2 residuals from a merMod object created with
> lme() and am struggling. 

  Not sure what you mean here -- this is a little bit inconsistent.
lmer (from lme4) makes merMod objects, lme (from nlme) makes lme objects.
I'm going to assume you're talking about lmer (since that's a more
likely typo).

> How can I pull out a vector that is the residuals
> at level 2? Everything I see on stack exchange and the mixed models list
> serve points towards methods like VarCorr(). I'm not interested in a
> summary of the L2 residuals so much as a vector of the same length as the
> number of groups I have. Ultimately I want to test them for spatial
> autocorrelation. Apologies if this is documented somewhere, but I have not
> been able to find help online.

 I always get confused about what levels mean in the context of 
mixed models (i.e. whether one counts down from the population level
or up from the individual level), but the basic answer here is to
get the *predictions* at the desired level and subtract them from
the observed values, see ?predict.merMod -- the re.form argument
is what you need.  re.form=NA or re.form=~0 gives you predictions
at the population level (i.e. neglecting all random effects),
re.form=NULL gives you predictions at the individual level (i.e.
including all random effects), intermediate cases can be gotten
by using a formula.

The results will be ordered the same as the original observation
vector.

  
> 
> While I have found methods of incorporating spatial effects into a mixed
> model using corStruct, I am interested in first evaluating if that is an
> appropriate model for a given dataset by examining the level 2 residuals'
> spatial patterning - or lack thereof.

  Seems reasonable.

> 
> Which slot contains the residuals for level 2 and how are they ordered?
>


From bbolker at gmail.com  Sat May  7 21:27:31 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 7 May 2016 19:27:31 +0000 (UTC)
Subject: [R-sig-ME] How sinful is it to...
References: <491B84B7-B655-4538-85FD-BF3DCA79EDEA@ucalgary.ca>
Message-ID: <loom.20160507T200340-424@post.gmane.org>

David Sidhu <dsidhu at ...> writes:

> 
> Hi Everyone!
> 
> I am conducting a mixed model logistic regression analysis 
> of some simple experimental data in which
> participants made dichotomous choices. My independent 
> variable has two levels. What I am really
> interested in is the ability of the independent variable 
> to predict the dependent variable, with the
> random effects in there simply to allow the best test of this.
> 
> I am starting from the point of view that I should ?keep it maximal?. 
> That being said my two questions are:
> 
>   *   Is there something horrible about keeping in 
> random effects that are highly (or perfectly!) correlated
> with one another?
>      *   If so?would you retain the term that gives you 
> the best model, based on AIC or some other value?
>   *   Should you always remove random effects that have 
> 0 variance associated with them?
> 
> It seems like the intuitive answer to both of these is yes. 
> But in this paper I am working on, there are several
> experiments, and for simplicity?s sake it would be much easier 
> to always just have the maximally
> complex random effects structure that managed to converge, 
> instead of giving details in each case about
> which terms were removed and why. But is there something
>  horrible wrong with that??

   I don't think so, but be aware that this is very much an open
question.  At one level, the perfectly correlated (or zero-variance)
solution is the correct answer to the question you posed with your
model ("what set of parameters maximizes the likelihood of this
statistical model"?)  The things to be concerned about would be:

* this suggests the model is overfitted (but it's not obvious that
removing these terms post hoc, introducing a model selection step into
the statistical procedure, will automatically solve the problem

http://arxiv.org/abs/1506.04967

(Example 1) "Fortunately and interestingly, none of the analyses impacted the
statistical inference about fixed effects in these experiments.
Again, the different model
specifications reported in this section were of no consequence for the
significance or interpretation
of fixed effects, but they led to inappropriate conclusions about the
correlations between variance
components.

From bbolker at gmail.com  Sat May  7 22:00:24 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 7 May 2016 20:00:24 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?Why_se=2Efit_differ_in_predict=2Eglm_and=09p?=
	=?utf-8?q?redict=2Eglmmadmb=3F?=
References: <384d50e7-7d81-6c24-e75a-05b01174e4b4@iim.csic.es>
	<57292616.4020702@gmail.com>
	<be22997f-025f-cf26-5a59-d196bf09e0fb@iim.csic.es>
	<1462369668.417.4.camel@loki>
	<c67dfc93-9304-7a50-04ce-ab1230228b2d@iim.csic.es>
Message-ID: <loom.20160507T215741-889@post.gmane.org>

Xandre <alex at ...> writes:

> 
> I am aware of that, sorry. Hopefully, with the following link, 
> https://www.dropbox.com/s/pptl595chabjtly/datos.csv?dl=0 , the example 
> will be completely reproducible.
> 
> Regards,
> 
> Alex

  It looks like glmmADMB is getting the estimate of the correlation
between the fixed effects wrong (I don't yet know whether this is 
a problem with
the optimization in AD Model Builder or an actual bug in the translation
of results from ADMB output to R):

datos <- read.csv("datos.csv")
M1<-glm(response~explanatory,
        data=datos,
        family="binomial")
library(glmmADMB)
M2 <- glmmadmb(response~explanatory,
             data=datos,
             family="binomial")
## Estimated covariance matrix may not be positive definite
##  4.0211 4.1655
coef(summary(M1))
coef(summary(M2))

newdatos <- with(datos,
          data.frame(explanatory=seq(min(explanatory),
                                     max(explanatory),length.out=10)))
predict(M1,type="link",newdata=newdatos,se.fit=TRUE)
predict(M2,type="link",newdata=newdatos,se.fit=TRUE)
X <- model.matrix(~explanatory, data = newdatos)

## compare var-cov matrices
vcov(M1)
vcov(M2)

## compare SEs
sqrt(diag(vcov(M1)))
sqrt(diag(vcov(M2)))

## compare correlations
cov2cor(vcov(M1))
cov2cor(vcov(M2))

## compare predicted SEs
sqrt(diag(X %*% vcov(M1) %*% t(X)))
sqrt(diag(X %*% vcov(M2) %*% t(X)))

## try with glmmTMB
library(glmmTMB)
M3 <- glmmTMB(response~explanatory,
             data=datos,
             family=binomial)
cov2cor(vcov(M3)$cond)



> >>
> >> Just to check problems of code I tried again with a much more simple
> >> example. I made a subset of my original data base (see attached .csv)
> >> and run a much more simple model as follows:
> >>
> >> *> M1<-glm(response~explanatory, **
> >> **+           data=datos,**
> >> **+           family="binomial")**
> >> **? M2<-glmmadmb(response~explanatory, **
> >> **+                 data=datos,**
> >> **+                 family="binomial")**
> >> **? **
> >> **? summary(M1)*
> >>
> >>

 [snip snip snip snip]

From carlosambarboza at gmail.com  Sat May  7 17:26:34 2016
From: carlosambarboza at gmail.com (Carlos Barboza)
Date: Sat, 7 May 2016 12:26:34 -0300
Subject: [R-sig-ME] Comparing mixed models
Message-ID: <CAGAvxRn2AB=ZhkQWtKYLFg9pRj9mT=D5t=7RpM-aJuoj+q3=Xw@mail.gmail.com>

Dear Dr. Ben Bolker

My name is Carlos Barboza and I am a Marine Biologist from the Rio de
Janeiro University, Brazil. First it's a pleasure to again have the
opportunity to send you a message.The reason for it is a simple doubt: Can
I compare AIC from:

1. glmmADMB: Density ~ 1 + 1|Site

2. glmmADMB: Density ~ Sector + 1|Site + Cage

Note that they have different random and fixed structures. I know that this
is not the best choice to model selection but, I think that the AIC values
can be compared.

thank you very much for your attention


  is Cage a random effect?  Are you intentionally leaving out the
intercept in the second case (it will be included anyway unless you
use -1)?  In any case, I don't see any obvious reason you can't
compare AIC values; see
https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.html#can-i-use-aic-for-mixed-models-how-do-i-count-the-number-of-degrees-of-freedom-for-a-random-effect

  Follow-ups to r-sig-mixed-models at r-project.org, please ...

sorry, yes, cage was included only to examplify a different random
structure in the second case...it should be coded (1|Site) + (1|Cage)
yes, I know that the intercept will be included in the second model

it's an example of comparing AIC values from mixed models with different
fixed and random structures:

1. Density ~ 1 + 1|Site

2. Density ~ Sector + 1|Site + 1|Cage

comparing AIC...I beleive that both values can be compared

again, thank you very much for your very fast message

	[[alternative HTML version deleted]]


From carlosambarboza at gmail.com  Sat May  7 17:42:45 2016
From: carlosambarboza at gmail.com (Carlos Barboza)
Date: Sat, 7 May 2016 12:42:45 -0300
Subject: [R-sig-ME] Comparing mixed models
In-Reply-To: <CABghstSY5pRv2qw=HtPLa=Xri-D8L=fhzdwLQCi1m0AGUpZL6g@mail.gmail.com>
References: <CAGAvxRn2AB=ZhkQWtKYLFg9pRj9mT=D5t=7RpM-aJuoj+q3=Xw@mail.gmail.com>
	<CABghstSY5pRv2qw=HtPLa=Xri-D8L=fhzdwLQCi1m0AGUpZL6g@mail.gmail.com>
Message-ID: <CAGAvxRk8oKKM9PGtSUTktr3iKprr6YQkoad5hwH6WqiGg+zp1A@mail.gmail.com>

yes I agree, my question was just a numerical doubt about comparing AIC
values. My approach was to show that, the AIC value from a model including
the single fixed effect has a smaller AIC value than any other model only
including the interecept effect in the fixed structure

thank you

2016-05-07 12:34 GMT-03:00 Ben Bolker <bbolker at gmail.com>:

>
>   My only other comment would be that my standard approach would be to
> retain all random effects in the model unless they are causing difficulty
> in model fitting -- this depends on your goal (confirmation/testing,
> prediction, exploration)
>
> On Sat, May 7, 2016 at 11:26 AM, Carlos Barboza <carlosambarboza at gmail.com
> > wrote:
>
>> Dear Dr. Ben Bolker
>>
>> My name is Carlos Barboza and I am a Marine Biologist from the Rio de
>> Janeiro University, Brazil. First it's a pleasure to again have the
>> opportunity to send you a message.The reason for it is a simple doubt:
>> Can I compare AIC from:
>>
>> 1. glmmADMB: Density ~ 1 + 1|Site
>>
>> 2. glmmADMB: Density ~ Sector + 1|Site + Cage
>>
>> Note that they have different random and fixed structures. I know that
>> this is not the best choice to model selection but, I think that the AIC
>> values can be compared.
>>
>> thank you very much for your attention
>>
>>
>>   is Cage a random effect?  Are you intentionally leaving out the
>> intercept in the second case (it will be included anyway unless you
>> use -1)?  In any case, I don't see any obvious reason you can't
>> compare AIC values; see
>>
>> https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.html#can-i-use-aic-for-mixed-models-how-do-i-count-the-number-of-degrees-of-freedom-for-a-random-effect
>>
>>   Follow-ups to r-sig-mixed-models at r-project.org, please ...
>>
>> sorry, yes, cage was included only to examplify a different random
>> structure in the second case...it should be coded (1|Site) + (1|Cage)
>> yes, I know that the intercept will be included in the second model
>>
>> it's an example of comparing AIC values from mixed models with different
>> fixed and random structures:
>>
>> 1. Density ~ 1 + 1|Site
>>
>> 2. Density ~ Sector + 1|Site + 1|Cage
>>
>> comparing AIC...I beleive that both values can be compared
>>
>> again, thank you very much for your very fast message
>>
>>
>>
>>
>

	[[alternative HTML version deleted]]


From abfine at gmail.com  Mon May  9 05:20:16 2016
From: abfine at gmail.com (Alex Fine)
Date: Sun, 8 May 2016 23:20:16 -0400
Subject: [R-sig-ME] Comparing mixed models
In-Reply-To: <CAGAvxRk8oKKM9PGtSUTktr3iKprr6YQkoad5hwH6WqiGg+zp1A@mail.gmail.com>
References: <CAGAvxRn2AB=ZhkQWtKYLFg9pRj9mT=D5t=7RpM-aJuoj+q3=Xw@mail.gmail.com>
	<CABghstSY5pRv2qw=HtPLa=Xri-D8L=fhzdwLQCi1m0AGUpZL6g@mail.gmail.com>
	<CAGAvxRk8oKKM9PGtSUTktr3iKprr6YQkoad5hwH6WqiGg+zp1A@mail.gmail.com>
Message-ID: <CAJ6ui+PergEyjj3ptW0De+BYHy--W8oa=bHv1U3DYVsfkYEWBA@mail.gmail.com>

The problem (depending on what you're trying to do) with comparing model 1
and model 2 is that, if you observe, say, a large change in the AIC, it's
not clear what to attribute the change to.  It could be driven either by
the fixed effect of Sector or by the random intercept for Cage.  Maybe it
doesn't matter in your case.

On Sat, May 7, 2016 at 11:42 AM, Carlos Barboza <carlosambarboza at gmail.com>
wrote:

> yes I agree, my question was just a numerical doubt about comparing AIC
> values. My approach was to show that, the AIC value from a model including
> the single fixed effect has a smaller AIC value than any other model only
> including the interecept effect in the fixed structure
>
> thank you
>
> 2016-05-07 12:34 GMT-03:00 Ben Bolker <bbolker at gmail.com>:
>
> >
> >   My only other comment would be that my standard approach would be to
> > retain all random effects in the model unless they are causing difficulty
> > in model fitting -- this depends on your goal (confirmation/testing,
> > prediction, exploration)
> >
> > On Sat, May 7, 2016 at 11:26 AM, Carlos Barboza <
> carlosambarboza at gmail.com
> > > wrote:
> >
> >> Dear Dr. Ben Bolker
> >>
> >> My name is Carlos Barboza and I am a Marine Biologist from the Rio de
> >> Janeiro University, Brazil. First it's a pleasure to again have the
> >> opportunity to send you a message.The reason for it is a simple doubt:
> >> Can I compare AIC from:
> >>
> >> 1. glmmADMB: Density ~ 1 + 1|Site
> >>
> >> 2. glmmADMB: Density ~ Sector + 1|Site + Cage
> >>
> >> Note that they have different random and fixed structures. I know that
> >> this is not the best choice to model selection but, I think that the AIC
> >> values can be compared.
> >>
> >> thank you very much for your attention
> >>
> >>
> >>   is Cage a random effect?  Are you intentionally leaving out the
> >> intercept in the second case (it will be included anyway unless you
> >> use -1)?  In any case, I don't see any obvious reason you can't
> >> compare AIC values; see
> >>
> >>
> https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.html#can-i-use-aic-for-mixed-models-how-do-i-count-the-number-of-degrees-of-freedom-for-a-random-effect
> >>
> >>   Follow-ups to r-sig-mixed-models at r-project.org, please ...
> >>
> >> sorry, yes, cage was included only to examplify a different random
> >> structure in the second case...it should be coded (1|Site) + (1|Cage)
> >> yes, I know that the intercept will be included in the second model
> >>
> >> it's an example of comparing AIC values from mixed models with different
> >> fixed and random structures:
> >>
> >> 1. Density ~ 1 + 1|Site
> >>
> >> 2. Density ~ Sector + 1|Site + 1|Cage
> >>
> >> comparing AIC...I beleive that both values can be compared
> >>
> >> again, thank you very much for your very fast message
> >>
> >>
> >>
> >>
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Alex Fine
Ph. (336) 302-3251
web:  http://internal.psychology.illinois.edu/~abfine/
<http://internal.psychology.illinois.edu/~abfine/AlexFineHome.html>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon May  9 16:34:35 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 9 May 2016 14:34:35 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?Why_se=2Efit_differ_in_predict=2Eglm_and=09p?=
	=?utf-8?q?redict=2Eglmmadmb=3F?=
References: <384d50e7-7d81-6c24-e75a-05b01174e4b4@iim.csic.es>
	<57292616.4020702@gmail.com>
	<be22997f-025f-cf26-5a59-d196bf09e0fb@iim.csic.es>
	<1462369668.417.4.camel@loki>
	<c67dfc93-9304-7a50-04ce-ab1230228b2d@iim.csic.es>
	<loom.20160507T215741-889@post.gmane.org>
Message-ID: <loom.20160509T160108-321@post.gmane.org>

Ben Bolker <bbolker at ...> writes:

> 
> Xandre <alex <at> ...> writes:
> 
> 
>   It looks like glmmADMB is getting the estimate of the correlation
> between the fixed effects wrong (I don't yet know whether this is 
> a problem with
> the optimization in AD Model Builder or an actual bug in the translation
> of results from ADMB output to R):
> 

  Update: it turns out that you found a serious, long-standing
bug in glmmADMB.  I've just moved glmmADMB development to

https://github.com/bbolker/glmmadmb

so I'm hoping you can simply install the new version via

devtools::install_github("bbolker/glmmadmb")

and see if that solves the problem

 cheers
    Ben Bolker


From alex at iim.csic.es  Mon May  9 20:54:38 2016
From: alex at iim.csic.es (Xandre)
Date: Mon, 9 May 2016 20:54:38 +0200
Subject: [R-sig-ME] Why se.fit differ in predict.glm and
	predict.glmmadmb?
In-Reply-To: <loom.20160509T160108-321@post.gmane.org>
References: <384d50e7-7d81-6c24-e75a-05b01174e4b4@iim.csic.es>
	<57292616.4020702@gmail.com>
	<be22997f-025f-cf26-5a59-d196bf09e0fb@iim.csic.es>
	<1462369668.417.4.camel@loki>
	<c67dfc93-9304-7a50-04ce-ab1230228b2d@iim.csic.es>
	<loom.20160507T215741-889@post.gmane.org>
	<loom.20160509T160108-321@post.gmane.org>
Message-ID: <502d9526-fb64-9108-1255-d6c72e8141a2@iim.csic.es>

Thanks a lot Ben Bolker. Now it is working properly.

Cheers,

Alex


El 09/05/2016 a las 16:34, Ben Bolker escribi?:
> Ben Bolker <bbolker at ...> writes:
>
>> Xandre <alex <at> ...> writes:
>>
>>
>>    It looks like glmmADMB is getting the estimate of the correlation
>> between the fixed effects wrong (I don't yet know whether this is
>> a problem with
>> the optimization in AD Model Builder or an actual bug in the translation
>> of results from ADMB output to R):
>>
>    Update: it turns out that you found a serious, long-standing
> bug in glmmADMB.  I've just moved glmmADMB development to
>
> https://github.com/bbolker/glmmadmb
>
> so I'm hoping you can simply install the new version via
>
> devtools::install_github("bbolker/glmmadmb")
>
> and see if that solves the problem
>
>   cheers
>      Ben Bolker
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From smit.reuben at gmail.com  Tue May 10 01:15:30 2016
From: smit.reuben at gmail.com (Reuben Smit)
Date: Mon, 9 May 2016 16:15:30 -0700
Subject: [R-sig-ME] Justification to exclude random effect
Message-ID: <CAFFAEtipC_=Gw5tjVJ_HHhSm-pz_-3u2f8hF2J_RiQNDyZDVOw@mail.gmail.com>

Hello,

The results of my mixed model show the single random effect variance and
standard deviation equal to zero. A statistician reviewed my results and
suggested the random effect is not explaining any additional variance apart
from the fixed effects. I'm asking the list to support or refute this claim
based on the aforementioned variance and standard deviation estimate. If
indeed the random effect is not contributing to the model, is it justified
to exclude the random effect and may I use a more simple generalized linear
model with fixed effects only?

Also, the random effect is the effect of Site from a random nested study
design. My conjecture is that a longitudinal/spatial fixed effect is
accounting for relatedness between sample points located in the same Site
(block).

Thanks in advance,
Reuben

	[[alternative HTML version deleted]]


From jbaldwin at fs.fed.us  Tue May 10 02:36:24 2016
From: jbaldwin at fs.fed.us (Baldwin, Jim -FS)
Date: Tue, 10 May 2016 00:36:24 +0000
Subject: [R-sig-ME] Justification to exclude random effect
In-Reply-To: <CAFFAEtipC_=Gw5tjVJ_HHhSm-pz_-3u2f8hF2J_RiQNDyZDVOw@mail.gmail.com>
References: <CAFFAEtipC_=Gw5tjVJ_HHhSm-pz_-3u2f8hF2J_RiQNDyZDVOw@mail.gmail.com>
Message-ID: <3191158cf0354ce9b0384e3eb6276db1@DM2PR0202MB057.001f.mgd2.msft.net>

I'm not seeing enough information to make such a decision - although in any event, I don't see that the slight additional complexity of a single random effect would warrant the need to re-run the analysis without it.  Plus, if the random effect was part of the experimental layout, then (other than maybe having too few levels to be able to estimate adequately it as a random effect) it ought to be in the model.

Does this deal with count data or something more continuous?  Are the residuals well behaved?

Jim


-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Reuben Smit
Sent: Monday, May 09, 2016 4:16 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Justification to exclude random effect

Hello,

The results of my mixed model show the single random effect variance and standard deviation equal to zero. A statistician reviewed my results and suggested the random effect is not explaining any additional variance apart from the fixed effects. I'm asking the list to support or refute this claim based on the aforementioned variance and standard deviation estimate. If indeed the random effect is not contributing to the model, is it justified to exclude the random effect and may I use a more simple generalized linear model with fixed effects only?

Also, the random effect is the effect of Site from a random nested study design. My conjecture is that a longitudinal/spatial fixed effect is accounting for relatedness between sample points located in the same Site (block).

Thanks in advance,
Reuben

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models




This electronic message contains information generated by the USDA solely for the intended recipients. Any unauthorized interception of this message or the use or disclosure of the information it contains may violate the law and subject the violator to civil or criminal penalties. If you believe you have received this message in error, please notify the sender and delete the email immediately.


From liliana.dalba at ugent.be  Tue May 10 12:09:28 2016
From: liliana.dalba at ugent.be (Liliana D'Alba Altamirano)
Date: Tue, 10 May 2016 10:09:28 +0000
Subject: [R-sig-ME] Species as both fixed and random effect
Message-ID: <1462875424991.73851@ugent.be>

I have a question about the use of a factor as both fixed and random effect.  Specifically, I want to test the effects of an experimental treatment and the species from which the samples originate on the response variable "y".

I have seven different species with about 10 samples from each.  On one hand I want to be able to make inferences about the differences in "y" between different species, but I also want to look at the variance among the values of "y" at different species (random). In addition, two separate reviewers have explicitly asked for species to be included as random effect to account for the non-independence among data from different species.


So, my model looks like this:


y ~ treatment + species + (1|species)


The question is whether this is an example of statistical malpractice or it is correct to do it.

I am aware of the discussion about this topic posted here:

https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q3/022365.html

in which Thierry Onkelinx mentioned that it is ok to specify a factor as fixed and random effect but only when it is treated as continuous (fixed) variable.

However, that did not fully answer my question and unlike Year (which can be used as continuous variable), it does not make sense to treat Species as continuous just so the model produce good estimates.


Thank you, I appreciate your help.


Liliana

	[[alternative HTML version deleted]]


From paul.debes at utu.fi  Tue May 10 12:42:42 2016
From: paul.debes at utu.fi (Paul Debes)
Date: Tue, 10 May 2016 13:42:42 +0300
Subject: [R-sig-ME] Species as both fixed and random effect
In-Reply-To: <1462875424991.73851@ugent.be>
References: <1462875424991.73851@ugent.be>
Message-ID: <op.yg8tdgsvsgx3xe@armadillo50.utu.fi>

Hi Liliana,

If your interest is in differences in among-y variance among the seven  
species, and you have single measurements for each combination of the  
seven species by 10 samples (five per species and treatment?), then you  
can do this at the residual (not the random) level by specifying different  
variances for species. However, it would probably be better to have more  
than 10 samples for each species. You can use the 'gls' function of the  
nlme package to do this, or if you include random effects in addition,  
'lme'.

I'm not sure about your experimental design, but if adequate and your  
interest is in firstly Treatment effects, secondly Species effects, and  
thirdly if the Treatment effects differ among Species, then you should do  
this based on the Treatment by Species interaction. Making inferences  
about differences in treatment effects among different groups in the  
absence of formally tested interactions is an horribly often-made mistake  
in many scientific fields:

http://www.nature.com/neuro/journal/v14/n9/full/nn.2886.html

 From the information you provide, it does not make sense to me to specify  
Species also as a random term. However, why are data from DIFFERENT  
species considered to be not independent? I don't think including Species  
as a random term would account for any non-independence among species.

I hope this helps,
Paul



On Tue, 10 May 2016 13:09:28 +0300, Liliana D'Alba Altamirano  
<liliana.dalba at ugent.be> wrote:

> I have a question about the use of a factor as both fixed and random  
> effect.  Specifically, I want to test the effects of an experimental  
> treatment and the species from which the samples originate on the  
> response variable "y".
>
> I have seven different species with about 10 samples from each.  On one  
> hand I want to be able to make inferences about the differences in "y"  
> between different species, but I also want to look at the variance among  
> the values of "y" at different species (random). In addition, two  
> separate reviewers have explicitly asked for species to be included as  
> random effect to account for the non-independence among data from  
> different species.
>
>
> So, my model looks like this:
>
>
> y ~ treatment + species + (1|species)
>
>
> The question is whether this is an example of statistical malpractice or  
> it is correct to do it.
>
> I am aware of the discussion about this topic posted here:
>
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q3/022365.html
>
> in which Thierry Onkelinx mentioned that it is ok to specify a factor as  
> fixed and random effect but only when it is treated as continuous  
> (fixed) variable.
>
> However, that did not fully answer my question and unlike Year (which  
> can be used as continuous variable), it does not make sense to treat  
> Species as continuous just so the model produce good estimates.
>
>
> Thank you, I appreciate your help.
>
>
> Liliana
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Paul V. Debes
DFG Research Fellow

Division of Genetics and Physiology
Department of Biology
University of Turku
PharmaCity, 7th floor
Itainen Pitkakatu 4
20014 Finland

Email: paul.debes at utu.fi


From jsylves92 at gmail.com  Tue May 10 01:16:02 2016
From: jsylves92 at gmail.com (Janelle Sylvester)
Date: Tue, 10 May 2016 01:16:02 +0200
Subject: [R-sig-ME] Help with MCMC fitting in R
Message-ID: <CAHtiW-mjfL1yE53ijAdA8ugF-J+13ktTZSSETtEJxUXYHvR+jQ@mail.gmail.com>

Hi,

I found this email address from the R-Forge website and was hoping you
could help me with a problem I am having.  I keep getting an error message
every time I try to preform a *post hoc* Markov chain on my zero-inflated,
neg. binomial mixed model.  Below is my code and the error message I keep
getting.  If I can't make this work, can you recommend any other ways of
validating my model? I really can't find anything on this topic.

glmmNB<- glmmadmb(CON_XAL~Treatment+(1|Site), data = SR.year.raw,
> zeroInflation = TRUE, family = "nbinom")
>


summary(glmmNB) #Summary output is attached to this email as a picture


> fit_glmmNB <- glmmadmb(CON_XAL~Treatment+(1|Site),

                       data=SR.year.raw,
>                        zeroInflation=TRUE, save.dir = "TMP",
>                        family="nbinom",
>                        mcmc=TRUE,
>                        mcmc.opts=mcmcControl(mcmc=5000))


And the error message I get:

Error in R2admb::read_psv(file_name) : no PSV file found
> In addition: Warning messages:
> 1: In glmmadmb(CON_XAL ~ Treatment + (1 | Site), data = SR.year.raw,  :
>   file glmmadmb.std exists: overwriting
> 2: running command 'C:\Windows\system32\cmd.exe /c glmmadmb -maxfn 500
> -maxph 5 -noinit -shess -mcmc 1000 -mcsave 1 -mcmult 1' had status 42


I tried running this:

mcmc.control <- function(mcmc=50000,
>                          mcmc2=0,
>                          mcsave,
>                          mcnoscale=FALSE,
>                          mcgrope=FALSE,
>                          mcmult=1,
>                          mcmcpars=NULL) {
>   if (missing(mcsave)) mcsave <- pmax(1,floor(mcmc/5000))
>   if (mcmc2>0) {
>     if (missing(mcmc)) {
>       mcmc <- 0
>     }
>     if (mcmc>0) stop("may not specify both mcmc and mcmc2>0")
>   }
>   r <-
> list(mcsave=mcsave,mcnoscale=mcnoscale,mcgrope=mcgrope,mcmult=mcmult,mcmcpars=mcmcpars)
>   if (mcmc>0) c(list(mcmc=mcmc),r) else c(list(mcmc2=mcmc2),r)
> }:


But then when I run my model again, I get this error message:

Parameters were estimated, but standard errors were not: the most likely
> problem is that the curvature at MLE was zero or negative
> Error in glmmadmb(CON_XAL ~ Treatment + (1 | Site), data = SR.year.raw,  :
>   The function maximizer failed (couldn't find parameter file)
> Troubleshooting steps include (1) run with 'save.dir' set and inspect
> output files; (2) change run parameters: see '?admbControl';(3) re-run with
> debug=TRUE for more information on failure mode
> In addition: Warning message:
> running command 'C:\Windows\system32\cmd.exe /c glmmadmb -maxfn 500 -maxph
> 5 -noinit -shess -mcmc 50000 -mcsave 50 -mcmult 1' had status 1


I've tried for weeks to fix this problem and I just don't know what to do.
If my data is just not suitable enough for this *post hoc* procedure, can
you please recommend another way to validate my model so I can ensure that
it fits well?

I attached my data and would be happy to send any other information that
may help figure out a solution.  I am looking at the "Treatment" effect on
seed abundances of 11 species (ignore ALL_PSI).  Site is my random factor.
I am looking at species separately.

I really hope you can provide some help. Thank you so much for your time!

Sincerely,

Janelle Sylvester

From smit.reuben at gmail.com  Wed May 11 02:43:03 2016
From: smit.reuben at gmail.com (Reuben Smit)
Date: Tue, 10 May 2016 17:43:03 -0700
Subject: [R-sig-ME] Justification to exclude random effect
In-Reply-To: <3191158cf0354ce9b0384e3eb6276db1@DM2PR0202MB057.001f.mgd2.msft.net>
References: <CAFFAEtipC_=Gw5tjVJ_HHhSm-pz_-3u2f8hF2J_RiQNDyZDVOw@mail.gmail.com>
	<3191158cf0354ce9b0384e3eb6276db1@DM2PR0202MB057.001f.mgd2.msft.net>
Message-ID: <CAFFAEtg-okZiPGMkNEEELPtMc+WK-w+dEcAx9tMkBKW6syFDAQ@mail.gmail.com>

I'm modeling presence/absence using binary logistic regression. The
complexity begins with using a model-averaged logistic mixed model to
predict onto a new and very large dataset. I'm having trouble with
non-conformable argument error messages, only with the logistic regression.
I can model counts with the random effect and those average and predict
fine with the same dataset. Standard glm predicts very well. I suppose I
should provide a reproducible example, since the error is really why I'm
trying to avoid the random effect, and that maybe content for a separate
post.

-Reuben

On Mon, May 9, 2016 at 5:36 PM, Baldwin, Jim -FS <jbaldwin at fs.fed.us> wrote:

> I'm not seeing enough information to make such a decision - although in
> any event, I don't see that the slight additional complexity of a single
> random effect would warrant the need to re-run the analysis without it.
> Plus, if the random effect was part of the experimental layout, then (other
> than maybe having too few levels to be able to estimate adequately it as a
> random effect) it ought to be in the model.
>
> Does this deal with count data or something more continuous?  Are the
> residuals well behaved?
>
> Jim
>
>
> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
> On Behalf Of Reuben Smit
> Sent: Monday, May 09, 2016 4:16 PM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Justification to exclude random effect
>
> Hello,
>
> The results of my mixed model show the single random effect variance and
> standard deviation equal to zero. A statistician reviewed my results and
> suggested the random effect is not explaining any additional variance apart
> from the fixed effects. I'm asking the list to support or refute this claim
> based on the aforementioned variance and standard deviation estimate. If
> indeed the random effect is not contributing to the model, is it justified
> to exclude the random effect and may I use a more simple generalized linear
> model with fixed effects only?
>
> Also, the random effect is the effect of Site from a random nested study
> design. My conjecture is that a longitudinal/spatial fixed effect is
> accounting for relatedness between sample points located in the same Site
> (block).
>
> Thanks in advance,
> Reuben
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
>
> This electronic message contains information generated by the USDA solely
> for the intended recipients. Any unauthorized interception of this message
> or the use or disclosure of the information it contains may violate the law
> and subject the violator to civil or criminal penalties. If you believe you
> have received this message in error, please notify the sender and delete
> the email immediately.
>

	[[alternative HTML version deleted]]


From jlaurenceau at psych.udel.edu  Wed May 11 04:52:24 2016
From: jlaurenceau at psych.udel.edu (Jean-Philippe Laurenceau)
Date: Wed, 11 May 2016 02:52:24 +0000
Subject: [R-sig-ME] Comparing mixed models
In-Reply-To: <CABghstSY5pRv2qw=HtPLa=Xri-D8L=fhzdwLQCi1m0AGUpZL6g@mail.gmail.com>
References: <CAGAvxRn2AB=ZhkQWtKYLFg9pRj9mT=D5t=7RpM-aJuoj+q3=Xw@mail.gmail.com>
	<CABghstSY5pRv2qw=HtPLa=Xri-D8L=fhzdwLQCi1m0AGUpZL6g@mail.gmail.com>
Message-ID: <8cfad19636844b2bac45c2df299e75eb@Mercury.psych.udel.edu>

Dear Ben et al.--I agree with the general practice of trying to estimate and retain as many random effects as possible (without estimation issues) in a mixed model. However, I was wondering whether anyone had some references recommending or arguing for this approach. I am aware of a paper on this topic with some simulation work by Barr et al. (2013; Journal of Memory and Language), but I would be interested in whether there are others. Thanks, J-P

Jean-Philippe Laurenceau, Ph.D.
Department of Psychological & Brain Sciences
University of Delaware


-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ben Bolker
Sent: Saturday, May 7, 2016 11:35 AM
To: Carlos Barboza <carlosambarboza at gmail.com>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Comparing mixed models

  My only other comment would be that my standard approach would be to retain all random effects in the model unless they are causing difficulty in model fitting -- this depends on your goal (confirmation/testing, prediction, exploration)

On Sat, May 7, 2016 at 11:26 AM, Carlos Barboza <carlosambarboza at gmail.com>
wrote:

> Dear Dr. Ben Bolker
>
> My name is Carlos Barboza and I am a Marine Biologist from the Rio de 
> Janeiro University, Brazil. First it's a pleasure to again have the 
> opportunity to send you a message.The reason for it is a simple doubt:
> Can I compare AIC from:
>
> 1. glmmADMB: Density ~ 1 + 1|Site
>
> 2. glmmADMB: Density ~ Sector + 1|Site + Cage
>
> Note that they have different random and fixed structures. I know that 
> this is not the best choice to model selection but, I think that the 
> AIC values can be compared.
>
> thank you very much for your attention
>
>
>   is Cage a random effect?  Are you intentionally leaving out the 
> intercept in the second case (it will be included anyway unless you 
> use -1)?  In any case, I don't see any obvious reason you can't 
> compare AIC values; see
>
> https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.html#can-i-
> use-aic-for-mixed-models-how-do-i-count-the-number-of-degrees-of-freed
> om-for-a-random-effect
>
>   Follow-ups to r-sig-mixed-models at r-project.org, please ...
>
> sorry, yes, cage was included only to examplify a different random 
> structure in the second case...it should be coded (1|Site) + (1|Cage) 
> yes, I know that the intercept will be included in the second model
>
> it's an example of comparing AIC values from mixed models with 
> different fixed and random structures:
>
> 1. Density ~ 1 + 1|Site
>
> 2. Density ~ Sector + 1|Site + 1|Cage
>
> comparing AIC...I beleive that both values can be compared
>
> again, thank you very much for your very fast message
>
>
>
>

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From abfine at gmail.com  Wed May 11 05:33:27 2016
From: abfine at gmail.com (Alex Fine)
Date: Tue, 10 May 2016 23:33:27 -0400
Subject: [R-sig-ME] Comparing mixed models
In-Reply-To: <8cfad19636844b2bac45c2df299e75eb@Mercury.psych.udel.edu>
References: <CAGAvxRn2AB=ZhkQWtKYLFg9pRj9mT=D5t=7RpM-aJuoj+q3=Xw@mail.gmail.com>
	<CABghstSY5pRv2qw=HtPLa=Xri-D8L=fhzdwLQCi1m0AGUpZL6g@mail.gmail.com>
	<8cfad19636844b2bac45c2df299e75eb@Mercury.psych.udel.edu>
Message-ID: <CAJ6ui+PgNBn2DEQo61tHgMfoLqkjG5H6SwRn_PsO8wi62fbjZg@mail.gmail.com>

There's a newer one out by Bates et al. that is sort of a response to Barr
et al.:  http://arxiv.org/abs/1506.04967



On Tue, May 10, 2016 at 10:52 PM, Jean-Philippe Laurenceau <
jlaurenceau at psych.udel.edu> wrote:

> Dear Ben et al.--I agree with the general practice of trying to estimate
> and retain as many random effects as possible (without estimation issues)
> in a mixed model. However, I was wondering whether anyone had some
> references recommending or arguing for this approach. I am aware of a paper
> on this topic with some simulation work by Barr et al. (2013; Journal of
> Memory and Language), but I would be interested in whether there are
> others. Thanks, J-P
>
> Jean-Philippe Laurenceau, Ph.D.
> Department of Psychological & Brain Sciences
> University of Delaware
>
>
> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
> On Behalf Of Ben Bolker
> Sent: Saturday, May 7, 2016 11:35 AM
> To: Carlos Barboza <carlosambarboza at gmail.com>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Comparing mixed models
>
>   My only other comment would be that my standard approach would be to
> retain all random effects in the model unless they are causing difficulty
> in model fitting -- this depends on your goal (confirmation/testing,
> prediction, exploration)
>
> On Sat, May 7, 2016 at 11:26 AM, Carlos Barboza <carlosambarboza at gmail.com
> >
> wrote:
>
> > Dear Dr. Ben Bolker
> >
> > My name is Carlos Barboza and I am a Marine Biologist from the Rio de
> > Janeiro University, Brazil. First it's a pleasure to again have the
> > opportunity to send you a message.The reason for it is a simple doubt:
> > Can I compare AIC from:
> >
> > 1. glmmADMB: Density ~ 1 + 1|Site
> >
> > 2. glmmADMB: Density ~ Sector + 1|Site + Cage
> >
> > Note that they have different random and fixed structures. I know that
> > this is not the best choice to model selection but, I think that the
> > AIC values can be compared.
> >
> > thank you very much for your attention
> >
> >
> >   is Cage a random effect?  Are you intentionally leaving out the
> > intercept in the second case (it will be included anyway unless you
> > use -1)?  In any case, I don't see any obvious reason you can't
> > compare AIC values; see
> >
> > https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.html#can-i-
> > use-aic-for-mixed-models-how-do-i-count-the-number-of-degrees-of-freed
> > om-for-a-random-effect
> >
> >   Follow-ups to r-sig-mixed-models at r-project.org, please ...
> >
> > sorry, yes, cage was included only to examplify a different random
> > structure in the second case...it should be coded (1|Site) + (1|Cage)
> > yes, I know that the intercept will be included in the second model
> >
> > it's an example of comparing AIC values from mixed models with
> > different fixed and random structures:
> >
> > 1. Density ~ 1 + 1|Site
> >
> > 2. Density ~ Sector + 1|Site + 1|Cage
> >
> > comparing AIC...I beleive that both values can be compared
> >
> > again, thank you very much for your very fast message
> >
> >
> >
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Alex Fine
Ph. (336) 302-3251
web:  http://internal.psychology.illinois.edu/~abfine/
<http://internal.psychology.illinois.edu/~abfine/AlexFineHome.html>

	[[alternative HTML version deleted]]


From paul.debes at utu.fi  Wed May 11 07:39:25 2016
From: paul.debes at utu.fi (Paul Debes)
Date: Wed, 11 May 2016 08:39:25 +0300
Subject: [R-sig-ME] Comparing mixed models
In-Reply-To: <8cfad19636844b2bac45c2df299e75eb@Mercury.psych.udel.edu>
References: <CAGAvxRn2AB=ZhkQWtKYLFg9pRj9mT=D5t=7RpM-aJuoj+q3=Xw@mail.gmail.com>
	<CABghstSY5pRv2qw=HtPLa=Xri-D8L=fhzdwLQCi1m0AGUpZL6g@mail.gmail.com>
	<8cfad19636844b2bac45c2df299e75eb@Mercury.psych.udel.edu>
Message-ID: <op.yg99zzg9sgx3xe@armadillo50>

Dear Jean-Philippe,

There are some papers that deal with the special case that the variance of  
an experimental design random term becomes negative due to a negative  
intraclass correlation. In old ANOVA models this could be detected as  
negative variance (this term will earn head shaking...), whereas in mixed  
models, where the design term is modeled at the random level, this is  
often not detectable because the design term variance may just be fixed at  
zero / converge to zero (if restrained to be positive). As a consequence,  
it happens that people tend to remove design terms from their models  
(because a zero variance random term clearly does not improve the model)  
and make inferences about, let's say treatments, based on observational  
rather than experimental units (that would only be represented by  
including the experimental design term) and this can lead to unrepeatable  
and overconfident inferences.

This problem cannot always be simply accounted for by leaving the random  
design term with a zero variance in the model. For example asreml-R does  
not account for zero-variance terms in F-tests (the denominator degrees of  
freedom inflate to observational level numbers), not sure what happens in  
lme4 / nlme models.

Here are some references about this very special topic that only covers  
the issue of zero-variance design terms that may in fact be negative, and  
how the experimental design can be accounted for at the residual level  
(with the associated consequences on prediction ability) in alternative to  
having zero-variance random terms:

Nelder, J. A. 1954. The interpretation of negative components of variance.  
Biometrika 41:544-548.

Wang, C. S., B. S. Yandell, and J. J. Rutledge. 1992. The dilemma of  
negative analysis of variance estimators of intraclass correlation.  
Theoretical and Applied Genetics 85:79-88.

Pryseley, A., C. Tchonlafi, G. Verbeke, and G. Molenberghs. 2011.  
Estimating negative variance components from Gaussian and non-Gaussian  
data: A mixed models approach. Computational Statistics & Data Analysis  
55:1071-1085.

I hope that is not too special case for your question, but I think it is a  
very important case for making inferences that account for an experimental  
design, i.e., when a non-significant random term should be left in the  
model.

Best,
Paul





On Wed, 11 May 2016 05:52:24 +0300, Jean-Philippe Laurenceau  
<jlaurenceau at psych.udel.edu> wrote:

> Dear Ben et al.--I agree with the general practice of trying to estimate  
> and retain as many random effects as possible (without estimation  
> issues) in a mixed model. However, I was wondering whether anyone had  
> some references recommending or arguing for this approach. I am aware of  
> a paper on this topic with some simulation work by Barr et al. (2013;  
> Journal of Memory and Language), but I would be interested in whether  
> there are others. Thanks, J-P
>
> Jean-Philippe Laurenceau, Ph.D.
> Department of Psychological & Brain Sciences
> University of Delaware
>
>
> -----Original Message-----
> From: R-sig-mixed-models  
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ben Bolker
> Sent: Saturday, May 7, 2016 11:35 AM
> To: Carlos Barboza <carlosambarboza at gmail.com>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Comparing mixed models
>
>   My only other comment would be that my standard approach would be to  
> retain all random effects in the model unless they are causing  
> difficulty in model fitting -- this depends on your goal  
> (confirmation/testing, prediction, exploration)
>
> On Sat, May 7, 2016 at 11:26 AM, Carlos Barboza  
> <carlosambarboza at gmail.com>
> wrote:
>
>> Dear Dr. Ben Bolker
>>
>> My name is Carlos Barboza and I am a Marine Biologist from the Rio de
>> Janeiro University, Brazil. First it's a pleasure to again have the
>> opportunity to send you a message.The reason for it is a simple doubt:
>> Can I compare AIC from:
>>
>> 1. glmmADMB: Density ~ 1 + 1|Site
>>
>> 2. glmmADMB: Density ~ Sector + 1|Site + Cage
>>
>> Note that they have different random and fixed structures. I know that
>> this is not the best choice to model selection but, I think that the
>> AIC values can be compared.
>>
>> thank you very much for your attention
>>
>>
>>   is Cage a random effect?  Are you intentionally leaving out the
>> intercept in the second case (it will be included anyway unless you
>> use -1)?  In any case, I don't see any obvious reason you can't
>> compare AIC values; see
>>
>> https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.html#can-i-
>> use-aic-for-mixed-models-how-do-i-count-the-number-of-degrees-of-freed
>> om-for-a-random-effect
>>
>>   Follow-ups to r-sig-mixed-models at r-project.org, please ...
>>
>> sorry, yes, cage was included only to examplify a different random
>> structure in the second case...it should be coded (1|Site) + (1|Cage)
>> yes, I know that the intercept will be included in the second model
>>
>> it's an example of comparing AIC values from mixed models with
>> different fixed and random structures:
>>
>> 1. Density ~ 1 + 1|Site
>>
>> 2. Density ~ Sector + 1|Site + 1|Cage
>>
>> comparing AIC...I beleive that both values can be compared
>>
>> again, thank you very much for your very fast message
>>
>>
>>
>>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list  
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Paul V. Debes
DFG Research Fellow

Division of Genetics and Physiology
Department of Biology
University of Turku
PharmaCity, 7th floor
Itainen Pitkakatu 4
20014 Finland

Email: paul.debes at utu.fi


From john.maindonald at anu.edu.au  Wed May 11 08:49:41 2016
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Wed, 11 May 2016 06:49:41 +0000
Subject: [R-sig-ME] Comparing mixed models
In-Reply-To: <op.yg99zzg9sgx3xe@armadillo50>
References: <CAGAvxRn2AB=ZhkQWtKYLFg9pRj9mT=D5t=7RpM-aJuoj+q3=Xw@mail.gmail.com>
	<CABghstSY5pRv2qw=HtPLa=Xri-D8L=fhzdwLQCi1m0AGUpZL6g@mail.gmail.com>
	<8cfad19636844b2bac45c2df299e75eb@Mercury.psych.udel.edu>
	<op.yg99zzg9sgx3xe@armadillo50>
Message-ID: <2B670BCC-B5B2-4CB4-BAFE-79C97842940E@anu.edu.au>

I have argued for allowing negative random effect estimates to be 
output, as was and I expect still is the case for Genstat mixed model 
fits.  What does asreml-R do? The negative value is needed so that 
the variance-covariance matrix, which does have to be positive definite 
(or at least semi-definite) is correctly estimated.  

The negative value, if more negative than can be ascribed to chance, is
a useful warning device.  Someone at Rothamsted told me about getting
data where blocks had been chosen in which treatment plots moved
successively further away from the stream.  The additional systematic
within block variance thereby induced called for a negative between 
blocks random effect so that the variance-covariance matrix would come 
out ?right?.  Maybe Nelder?s paper mentions this specific type of effect?

John Maindonald             email: john.maindonald at anu.edu.au


> On 11/05/2016, at 17:39, Paul Debes <paul.debes at utu.fi> wrote:
> 
> Dear Jean-Philippe,
> 
> There are some papers that deal with the special case that the variance of an experimental design random term becomes negative due to a negative intraclass correlation. In old ANOVA models this could be detected as negative variance (this term will earn head shaking...), whereas in mixed models, where the design term is modeled at the random level, this is often not detectable because the design term variance may just be fixed at zero / converge to zero (if restrained to be positive). As a consequence, it happens that people tend to remove design terms from their models (because a zero variance random term clearly does not improve the model) and make inferences about, let's say treatments, based on observational rather than experimental units (that would only be represented by including the experimental design term) and this can lead to unrepeatable and overconfident inferences.
> 
> This problem cannot always be simply accounted for by leaving the random design term with a zero variance in the model. For example asreml-R does not account for zero-variance terms in F-tests (the denominator degrees of freedom inflate to observational level numbers), not sure what happens in lme4 / nlme models.
> 
> Here are some references about this very special topic that only covers the issue of zero-variance design terms that may in fact be negative, and how the experimental design can be accounted for at the residual level (with the associated consequences on prediction ability) in alternative to having zero-variance random terms:
> 
> Nelder, J. A. 1954. The interpretation of negative components of variance. Biometrika 41:544-548.
> 
> Wang, C. S., B. S. Yandell, and J. J. Rutledge. 1992. The dilemma of negative analysis of variance estimators of intraclass correlation. Theoretical and Applied Genetics 85:79-88.
> 
> Pryseley, A., C. Tchonlafi, G. Verbeke, and G. Molenberghs. 2011. Estimating negative variance components from Gaussian and non-Gaussian data: A mixed models approach. Computational Statistics & Data Analysis 55:1071-1085.
> 
> I hope that is not too special case for your question, but I think it is a very important case for making inferences that account for an experimental design, i.e., when a non-significant random term should be left in the model.
> 
> Best,
> Paul
> 
> 
> 
> 
> 
> On Wed, 11 May 2016 05:52:24 +0300, Jean-Philippe Laurenceau <jlaurenceau at psych.udel.edu> wrote:
> 
>> Dear Ben et al.--I agree with the general practice of trying to estimate and retain as many random effects as possible (without estimation issues) in a mixed model. However, I was wondering whether anyone had some references recommending or arguing for this approach. I am aware of a paper on this topic with some simulation work by Barr et al. (2013; Journal of Memory and Language), but I would be interested in whether there are others. Thanks, J-P
>> 
>> Jean-Philippe Laurenceau, Ph.D.
>> Department of Psychological & Brain Sciences
>> University of Delaware
>> 
>> 
>> -----Original Message-----
>> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ben Bolker
>> Sent: Saturday, May 7, 2016 11:35 AM
>> To: Carlos Barboza <carlosambarboza at gmail.com>
>> Cc: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] Comparing mixed models
>> 
>>  My only other comment would be that my standard approach would be to retain all random effects in the model unless they are causing difficulty in model fitting -- this depends on your goal (confirmation/testing, prediction, exploration)
>> 
>> On Sat, May 7, 2016 at 11:26 AM, Carlos Barboza <carlosambarboza at gmail.com>
>> wrote:
>> 
>>> Dear Dr. Ben Bolker
>>> 
>>> My name is Carlos Barboza and I am a Marine Biologist from the Rio de
>>> Janeiro University, Brazil. First it's a pleasure to again have the
>>> opportunity to send you a message.The reason for it is a simple doubt:
>>> Can I compare AIC from:
>>> 
>>> 1. glmmADMB: Density ~ 1 + 1|Site
>>> 
>>> 2. glmmADMB: Density ~ Sector + 1|Site + Cage
>>> 
>>> Note that they have different random and fixed structures. I know that
>>> this is not the best choice to model selection but, I think that the
>>> AIC values can be compared.
>>> 
>>> thank you very much for your attention
>>> 
>>> 
>>>  is Cage a random effect?  Are you intentionally leaving out the
>>> intercept in the second case (it will be included anyway unless you
>>> use -1)?  In any case, I don't see any obvious reason you can't
>>> compare AIC values; see
>>> 
>>> https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.html#can-i-
>>> use-aic-for-mixed-models-how-do-i-count-the-number-of-degrees-of-freed
>>> om-for-a-random-effect
>>> 
>>>  Follow-ups to r-sig-mixed-models at r-project.org, please ...
>>> 
>>> sorry, yes, cage was included only to examplify a different random
>>> structure in the second case...it should be coded (1|Site) + (1|Cage)
>>> yes, I know that the intercept will be included in the second model
>>> 
>>> it's an example of comparing AIC values from mixed models with
>>> different fixed and random structures:
>>> 
>>> 1. Density ~ 1 + 1|Site
>>> 
>>> 2. Density ~ Sector + 1|Site + 1|Cage
>>> 
>>> comparing AIC...I beleive that both values can be compared
>>> 
>>> again, thank you very much for your very fast message
>>> 
>>> 
>>> 
>>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> -- 
> Paul V. Debes
> DFG Research Fellow
> 
> Division of Genetics and Physiology
> Department of Biology
> University of Turku
> PharmaCity, 7th floor
> Itainen Pitkakatu 4
> 20014 Finland
> 
> Email: paul.debes at utu.fi
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From paul.debes at utu.fi  Wed May 11 10:04:59 2016
From: paul.debes at utu.fi (Paul Debes)
Date: Wed, 11 May 2016 11:04:59 +0300
Subject: [R-sig-ME] Comparing mixed models
In-Reply-To: <2B670BCC-B5B2-4CB4-BAFE-79C97842940E@anu.edu.au>
References: <CAGAvxRn2AB=ZhkQWtKYLFg9pRj9mT=D5t=7RpM-aJuoj+q3=Xw@mail.gmail.com>
	<CABghstSY5pRv2qw=HtPLa=Xri-D8L=fhzdwLQCi1m0AGUpZL6g@mail.gmail.com>
	<8cfad19636844b2bac45c2df299e75eb@Mercury.psych.udel.edu>
	<op.yg99zzg9sgx3xe@armadillo50>
	<2B670BCC-B5B2-4CB4-BAFE-79C97842940E@anu.edu.au>
Message-ID: <op.yhagqlgqsgx3xe@armadillo50>

ASReml-R does allow for negative variances, but you have to explicitly  
specify it via the component constraints. I also think this may be  
advisable to do for testing what is going on, especially when an important  
design term variance converged to zero. The variance may either simply be  
very small, which may just ask for a response / covariate rescaling or  
changing the threshold when the software considers a component to be zero,  
or be really negative. Otherwise, for 'boundary' variance terms ASReml-R  
appears to estimate the random effects (you can still extract them from  
the model) but it does not estimate the variance among them.

My guess is that designs described by Nelder occur more often than thought  
because I still see mention of 'pooling variance' of design terms (or  
'stepwise reducing models for non-significant terms'), so it remains  
unknown what was really going on with these removed design terms. I worked  
with different fish populations, kept due to space limitations in the same  
tanks; tanks were the experimental treatment units (split plot design of  
fish type within treatment tank). Now the fish populations had very  
different growth for families across treatments (wild vs. aquaculture -  
what a surprise), leading to a negative variance among tank effects, like  
what Nelder described. I think this block design in the stream you  
describe may have exhibited a similar pattern (I think I already read  
about it in an older post).
Back then, I really struggled how to deal with this practically, without  
running into controversies (I'm a biologist - impossible to be further  
away from being a statistician), until Geert Molenbeek helped me with  
bringing up (covered, if I remember correctly, also by some of his  
publications) that it may be easiest to interpret a negative variance if  
specified as correlation at the residual level. I did this and was able to  
include tank effects that did not converge to zero (as I accounted for the  
negative correlation elsewhere). Thus, I could happily report the negative  
variance as negative correlation, include tank effects, and report F-test  
results with the correct denominator degrees of freedom, though the model  
was more complicated than I wished for.
However, for more complicated experimental designs where a negative  
variance occurs at a level that cannot be moved to the residuals (or be  
specified directly as a covariance/correlation between other random effect  
groups, which may also have been a solution for my problem back then), one  
may have to deal with a negative variance component and risk being fried  
by reviewers.



On Wed, 11 May 2016 09:49:41 +0300, John Maindonald  
<john.maindonald at anu.edu.au> wrote:

> I have argued for allowing negative random effect estimates to be
> output, as was and I expect still is the case for Genstat mixed model
> fits.  What does asreml-R do? The negative value is needed so that
> the variance-covariance matrix, which does have to be positive definite
> (or at least semi-definite) is correctly estimated.
>
> The negative value, if more negative than can be ascribed to chance, is
> a useful warning device.  Someone at Rothamsted told me about getting
> data where blocks had been chosen in which treatment plots moved
> successively further away from the stream.  The additional systematic
> within block variance thereby induced called for a negative between
> blocks random effect so that the variance-covariance matrix would come
> out ?right?.  Maybe Nelder?s paper mentions this specific type of effect?
>
> John Maindonald             email: john.maindonald at anu.edu.au
>
>
>> On 11/05/2016, at 17:39, Paul Debes <paul.debes at utu.fi> wrote:
>>
>> Dear Jean-Philippe,
>>
>> There are some papers that deal with the special case that the variance  
>> of an experimental design random term becomes negative due to a  
>> negative intraclass correlation. In old ANOVA models this could be  
>> detected as negative variance (this term will earn head shaking...),  
>> whereas in mixed models, where the design term is modeled at the random  
>> level, this is often not detectable because the design term variance  
>> may just be fixed at zero / converge to zero (if restrained to be  
>> positive). As a consequence, it happens that people tend to remove  
>> design terms from their models (because a zero variance random term  
>> clearly does not improve the model) and make inferences about, let's  
>> say treatments, based on observational rather than experimental units  
>> (that would only be represented by including the experimental design  
>> term) and this can lead to unrepeatable and overconfident inferences.
>>
>> This problem cannot always be simply accounted for by leaving the  
>> random design term with a zero variance in the model. For example  
>> asreml-R does not account for zero-variance terms in F-tests (the  
>> denominator degrees of freedom inflate to observational level numbers),  
>> not sure what happens in lme4 / nlme models.
>>
>> Here are some references about this very special topic that only covers  
>> the issue of zero-variance design terms that may in fact be negative,  
>> and how the experimental design can be accounted for at the residual  
>> level (with the associated consequences on prediction ability) in  
>> alternative to having zero-variance random terms:
>>
>> Nelder, J. A. 1954. The interpretation of negative components of  
>> variance. Biometrika 41:544-548.
>>
>> Wang, C. S., B. S. Yandell, and J. J. Rutledge. 1992. The dilemma of  
>> negative analysis of variance estimators of intraclass correlation.  
>> Theoretical and Applied Genetics 85:79-88.
>>
>> Pryseley, A., C. Tchonlafi, G. Verbeke, and G. Molenberghs. 2011.  
>> Estimating negative variance components from Gaussian and non-Gaussian  
>> data: A mixed models approach. Computational Statistics & Data Analysis  
>> 55:1071-1085.
>>
>> I hope that is not too special case for your question, but I think it  
>> is a very important case for making inferences that account for an  
>> experimental design, i.e., when a non-significant random term should be  
>> left in the model.
>>
>> Best,
>> Paul
>>
>>
>>
>>
>>
>> On Wed, 11 May 2016 05:52:24 +0300, Jean-Philippe Laurenceau  
>> <jlaurenceau at psych.udel.edu> wrote:
>>
>>> Dear Ben et al.--I agree with the general practice of trying to  
>>> estimate and retain as many random effects as possible (without  
>>> estimation issues) in a mixed model. However, I was wondering whether  
>>> anyone had some references recommending or arguing for this approach.  
>>> I am aware of a paper on this topic with some simulation work by Barr  
>>> et al. (2013; Journal of Memory and Language), but I would be  
>>> interested in whether there are others. Thanks, J-P
>>>
>>> Jean-Philippe Laurenceau, Ph.D.
>>> Department of Psychological & Brain Sciences
>>> University of Delaware
>>>
>>>
>>> -----Original Message-----
>>> From: R-sig-mixed-models  
>>> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ben  
>>> Bolker
>>> Sent: Saturday, May 7, 2016 11:35 AM
>>> To: Carlos Barboza <carlosambarboza at gmail.com>
>>> Cc: r-sig-mixed-models at r-project.org
>>> Subject: Re: [R-sig-ME] Comparing mixed models
>>>
>>>  My only other comment would be that my standard approach would be to  
>>> retain all random effects in the model unless they are causing  
>>> difficulty in model fitting -- this depends on your goal  
>>> (confirmation/testing, prediction, exploration)
>>>
>>> On Sat, May 7, 2016 at 11:26 AM, Carlos Barboza  
>>> <carlosambarboza at gmail.com>
>>> wrote:
>>>
>>>> Dear Dr. Ben Bolker
>>>>
>>>> My name is Carlos Barboza and I am a Marine Biologist from the Rio de
>>>> Janeiro University, Brazil. First it's a pleasure to again have the
>>>> opportunity to send you a message.The reason for it is a simple doubt:
>>>> Can I compare AIC from:
>>>>
>>>> 1. glmmADMB: Density ~ 1 + 1|Site
>>>>
>>>> 2. glmmADMB: Density ~ Sector + 1|Site + Cage
>>>>
>>>> Note that they have different random and fixed structures. I know that
>>>> this is not the best choice to model selection but, I think that the
>>>> AIC values can be compared.
>>>>
>>>> thank you very much for your attention
>>>>
>>>>
>>>>  is Cage a random effect?  Are you intentionally leaving out the
>>>> intercept in the second case (it will be included anyway unless you
>>>> use -1)?  In any case, I don't see any obvious reason you can't
>>>> compare AIC values; see
>>>>
>>>> https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.html#can-i-
>>>> use-aic-for-mixed-models-how-do-i-count-the-number-of-degrees-of-freed
>>>> om-for-a-random-effect
>>>>
>>>>  Follow-ups to r-sig-mixed-models at r-project.org, please ...
>>>>
>>>> sorry, yes, cage was included only to examplify a different random
>>>> structure in the second case...it should be coded (1|Site) + (1|Cage)
>>>> yes, I know that the intercept will be included in the second model
>>>>
>>>> it's an example of comparing AIC values from mixed models with
>>>> different fixed and random structures:
>>>>
>>>> 1. Density ~ 1 + 1|Site
>>>>
>>>> 2. Density ~ Sector + 1|Site + 1|Cage
>>>>
>>>> comparing AIC...I beleive that both values can be compared
>>>>
>>>> again, thank you very much for your very fast message
>>>>
>>>>
>>>>
>>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list  
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>> --
>> Paul V. Debes
>> DFG Research Fellow
>>
>> Division of Genetics and Physiology
>> Department of Biology
>> University of Turku
>> PharmaCity, 7th floor
>> Itainen Pitkakatu 4
>> 20014 Finland
>>
>> Email: paul.debes at utu.fi
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
Paul V. Debes
DFG Research Fellow

Division of Genetics and Physiology
Department of Biology
University of Turku
PharmaCity, 7th floor
Itainen Pitkakatu 4
20014 Finland

Email: paul.debes at utu.fi


From thierry.onkelinx at inbo.be  Wed May 11 10:20:07 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 11 May 2016 10:20:07 +0200
Subject: [R-sig-ME] Comparing mixed models
In-Reply-To: <op.yhagqlgqsgx3xe@armadillo50>
References: <CAGAvxRn2AB=ZhkQWtKYLFg9pRj9mT=D5t=7RpM-aJuoj+q3=Xw@mail.gmail.com>
	<CABghstSY5pRv2qw=HtPLa=Xri-D8L=fhzdwLQCi1m0AGUpZL6g@mail.gmail.com>
	<8cfad19636844b2bac45c2df299e75eb@Mercury.psych.udel.edu>
	<op.yg99zzg9sgx3xe@armadillo50>
	<2B670BCC-B5B2-4CB4-BAFE-79C97842940E@anu.edu.au>
	<op.yhagqlgqsgx3xe@armadillo50>
Message-ID: <CAJuCY5yCsv8TYfN8j+b36ePJWYXdSibhqMj_xPtH0MLhruz-Rg@mail.gmail.com>

This is a fortunes candidate.

I'm a biologist - impossible to be further away from being a statistician.
-- Paul Debes

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey


2016-05-11 10:04 GMT+02:00 Paul Debes <paul.debes at utu.fi>:
> ASReml-R does allow for negative variances, but you have to explicitly
> specify it via the component constraints. I also think this may be advisable
> to do for testing what is going on, especially when an important design term
> variance converged to zero. The variance may either simply be very small,
> which may just ask for a response / covariate rescaling or changing the
> threshold when the software considers a component to be zero, or be really
> negative. Otherwise, for 'boundary' variance terms ASReml-R appears to
> estimate the random effects (you can still extract them from the model) but
> it does not estimate the variance among them.
>
> My guess is that designs described by Nelder occur more often than thought
> because I still see mention of 'pooling variance' of design terms (or
> 'stepwise reducing models for non-significant terms'), so it remains unknown
> what was really going on with these removed design terms. I worked with
> different fish populations, kept due to space limitations in the same tanks;
> tanks were the experimental treatment units (split plot design of fish type
> within treatment tank). Now the fish populations had very different growth
> for families across treatments (wild vs. aquaculture - what a surprise),
> leading to a negative variance among tank effects, like what Nelder
> described. I think this block design in the stream you describe may have
> exhibited a similar pattern (I think I already read about it in an older
> post).
> Back then, I really struggled how to deal with this practically, without
> running into controversies (I'm a biologist - impossible to be further away
> from being a statistician), until Geert Molenbeek helped me with bringing up
> (covered, if I remember correctly, also by some of his publications) that it
> may be easiest to interpret a negative variance if specified as correlation
> at the residual level. I did this and was able to include tank effects that
> did not converge to zero (as I accounted for the negative correlation
> elsewhere). Thus, I could happily report the negative variance as negative
> correlation, include tank effects, and report F-test results with the
> correct denominator degrees of freedom, though the model was more
> complicated than I wished for.
> However, for more complicated experimental designs where a negative variance
> occurs at a level that cannot be moved to the residuals (or be specified
> directly as a covariance/correlation between other random effect groups,
> which may also have been a solution for my problem back then), one may have
> to deal with a negative variance component and risk being fried by
> reviewers.
>
>
>
> On Wed, 11 May 2016 09:49:41 +0300, John Maindonald
> <john.maindonald at anu.edu.au> wrote:
>
>> I have argued for allowing negative random effect estimates to be
>> output, as was and I expect still is the case for Genstat mixed model
>> fits.  What does asreml-R do? The negative value is needed so that
>> the variance-covariance matrix, which does have to be positive definite
>> (or at least semi-definite) is correctly estimated.
>>
>> The negative value, if more negative than can be ascribed to chance, is
>> a useful warning device.  Someone at Rothamsted told me about getting
>> data where blocks had been chosen in which treatment plots moved
>> successively further away from the stream.  The additional systematic
>> within block variance thereby induced called for a negative between
>> blocks random effect so that the variance-covariance matrix would come
>> out ?right?.  Maybe Nelder?s paper mentions this specific type of effect?
>>
>> John Maindonald             email: john.maindonald at anu.edu.au
>>
>>
>>> On 11/05/2016, at 17:39, Paul Debes <paul.debes at utu.fi> wrote:
>>>
>>> Dear Jean-Philippe,
>>>
>>> There are some papers that deal with the special case that the variance
>>> of an experimental design random term becomes negative due to a negative
>>> intraclass correlation. In old ANOVA models this could be detected as
>>> negative variance (this term will earn head shaking...), whereas in mixed
>>> models, where the design term is modeled at the random level, this is often
>>> not detectable because the design term variance may just be fixed at zero /
>>> converge to zero (if restrained to be positive). As a consequence, it
>>> happens that people tend to remove design terms from their models (because a
>>> zero variance random term clearly does not improve the model) and make
>>> inferences about, let's say treatments, based on observational rather than
>>> experimental units (that would only be represented by including the
>>> experimental design term) and this can lead to unrepeatable and
>>> overconfident inferences.
>>>
>>> This problem cannot always be simply accounted for by leaving the random
>>> design term with a zero variance in the model. For example asreml-R does not
>>> account for zero-variance terms in F-tests (the denominator degrees of
>>> freedom inflate to observational level numbers), not sure what happens in
>>> lme4 / nlme models.
>>>
>>> Here are some references about this very special topic that only covers
>>> the issue of zero-variance design terms that may in fact be negative, and
>>> how the experimental design can be accounted for at the residual level (with
>>> the associated consequences on prediction ability) in alternative to having
>>> zero-variance random terms:
>>>
>>> Nelder, J. A. 1954. The interpretation of negative components of
>>> variance. Biometrika 41:544-548.
>>>
>>> Wang, C. S., B. S. Yandell, and J. J. Rutledge. 1992. The dilemma of
>>> negative analysis of variance estimators of intraclass correlation.
>>> Theoretical and Applied Genetics 85:79-88.
>>>
>>> Pryseley, A., C. Tchonlafi, G. Verbeke, and G. Molenberghs. 2011.
>>> Estimating negative variance components from Gaussian and non-Gaussian data:
>>> A mixed models approach. Computational Statistics & Data Analysis
>>> 55:1071-1085.
>>>
>>> I hope that is not too special case for your question, but I think it is
>>> a very important case for making inferences that account for an experimental
>>> design, i.e., when a non-significant random term should be left in the
>>> model.
>>>
>>> Best,
>>> Paul
>>>
>>>
>>>
>>>
>>>
>>> On Wed, 11 May 2016 05:52:24 +0300, Jean-Philippe Laurenceau
>>> <jlaurenceau at psych.udel.edu> wrote:
>>>
>>>> Dear Ben et al.--I agree with the general practice of trying to estimate
>>>> and retain as many random effects as possible (without estimation issues) in
>>>> a mixed model. However, I was wondering whether anyone had some references
>>>> recommending or arguing for this approach. I am aware of a paper on this
>>>> topic with some simulation work by Barr et al. (2013; Journal of Memory and
>>>> Language), but I would be interested in whether there are others. Thanks,
>>>> J-P
>>>>
>>>> Jean-Philippe Laurenceau, Ph.D.
>>>> Department of Psychological & Brain Sciences
>>>> University of Delaware
>>>>
>>>>
>>>> -----Original Message-----
>>>> From: R-sig-mixed-models
>>>> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ben Bolker
>>>> Sent: Saturday, May 7, 2016 11:35 AM
>>>> To: Carlos Barboza <carlosambarboza at gmail.com>
>>>> Cc: r-sig-mixed-models at r-project.org
>>>> Subject: Re: [R-sig-ME] Comparing mixed models
>>>>
>>>>  My only other comment would be that my standard approach would be to
>>>> retain all random effects in the model unless they are causing difficulty in
>>>> model fitting -- this depends on your goal (confirmation/testing,
>>>> prediction, exploration)
>>>>
>>>> On Sat, May 7, 2016 at 11:26 AM, Carlos Barboza
>>>> <carlosambarboza at gmail.com>
>>>> wrote:
>>>>
>>>>> Dear Dr. Ben Bolker
>>>>>
>>>>> My name is Carlos Barboza and I am a Marine Biologist from the Rio de
>>>>> Janeiro University, Brazil. First it's a pleasure to again have the
>>>>> opportunity to send you a message.The reason for it is a simple doubt:
>>>>> Can I compare AIC from:
>>>>>
>>>>> 1. glmmADMB: Density ~ 1 + 1|Site
>>>>>
>>>>> 2. glmmADMB: Density ~ Sector + 1|Site + Cage
>>>>>
>>>>> Note that they have different random and fixed structures. I know that
>>>>> this is not the best choice to model selection but, I think that the
>>>>> AIC values can be compared.
>>>>>
>>>>> thank you very much for your attention
>>>>>
>>>>>
>>>>>  is Cage a random effect?  Are you intentionally leaving out the
>>>>> intercept in the second case (it will be included anyway unless you
>>>>> use -1)?  In any case, I don't see any obvious reason you can't
>>>>> compare AIC values; see
>>>>>
>>>>> https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.html#can-i-
>>>>> use-aic-for-mixed-models-how-do-i-count-the-number-of-degrees-of-freed
>>>>> om-for-a-random-effect
>>>>>
>>>>>  Follow-ups to r-sig-mixed-models at r-project.org, please ...
>>>>>
>>>>> sorry, yes, cage was included only to examplify a different random
>>>>> structure in the second case...it should be coded (1|Site) + (1|Cage)
>>>>> yes, I know that the intercept will be included in the second model
>>>>>
>>>>> it's an example of comparing AIC values from mixed models with
>>>>> different fixed and random structures:
>>>>>
>>>>> 1. Density ~ 1 + 1|Site
>>>>>
>>>>> 2. Density ~ Sector + 1|Site + 1|Cage
>>>>>
>>>>> comparing AIC...I beleive that both values can be compared
>>>>>
>>>>> again, thank you very much for your very fast message
>>>>>
>>>>>
>>>>>
>>>>>
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>>
>>> --
>>> Paul V. Debes
>>> DFG Research Fellow
>>>
>>> Division of Genetics and Physiology
>>> Department of Biology
>>> University of Turku
>>> PharmaCity, 7th floor
>>> Itainen Pitkakatu 4
>>> 20014 Finland
>>>
>>> Email: paul.debes at utu.fi
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
>
> --
> Paul V. Debes
> DFG Research Fellow
>
> Division of Genetics and Physiology
> Department of Biology
> University of Turku
> PharmaCity, 7th floor
> Itainen Pitkakatu 4
> 20014 Finland
>
> Email: paul.debes at utu.fi
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From dexter.locke at gmail.com  Wed May 11 15:32:22 2016
From: dexter.locke at gmail.com (Dexter Locke)
Date: Wed, 11 May 2016 09:32:22 -0400
Subject: [R-sig-ME] extract level 2 residuals of merMod from lme() and
 test for spatial autocorrelation.
In-Reply-To: <loom.20160507T195150-293@post.gmane.org>
References: <CAA=SVwFSEj3XBQ7VCu_ZFc4fBbt1zRfvx9jj919YpAHuo-kCzw@mail.gmail.com>
	<loom.20160507T195150-293@post.gmane.org>
Message-ID: <CAA=SVwFn0sfj5Lx_h6Tfa+nOOVFn6O-TT2M+cNmfMT2RBCn5fg@mail.gmail.com>

Thanks very much.

Yes, that was a typo. I'm working with lme4 and the lmer function to make
merMod objects. Sorry for any confusion.

Here is a reproducible example of my attempt to extract residuals at the
population level (ie random effects) by subtracting predictions from
observations.

library(lme4)
fm1 <- lmer(Reaction ~ Days + (1 | Subject), sleepstudy) # load library,
fit merMod object

test <- sleepstudy$Reaction - (predict(fm1, re.form= ~ (1| Subject))) #
subtract predictions from observations

summary(fm1) # examine residuals of random effects, which provides:
# "Residual              960.5   30.99 " for variance and std dev,
respectively
var(test); sd(test) # which provides 869.8171 and 29.49266

# test <- sleepstudy$Reaction - (predict(fm1, re.form= NULL)) #
unsurprisingly has same results as above

960.5 <> 869.8171 and 30.99 <> 29.49266 although they are the same
direction and order of magnitude. I'm finding similar results with my
actual data and model fits.

Any advice is appreciated, thanks again!
Dexter

On Sat, May 7, 2016 at 2:03 PM, Ben Bolker <bbolker at gmail.com> wrote:

> Dexter Locke <dexter.locke at ...> writes:
>
> >
> > Apologies for cross-posting, another version of this was posted on
> > r-sig-geo at ...
> >
> > I want to extract the level 2 residuals from a merMod object created with
> > lme() and am struggling.
>
>   Not sure what you mean here -- this is a little bit inconsistent.
> lmer (from lme4) makes merMod objects, lme (from nlme) makes lme objects.
> I'm going to assume you're talking about lmer (since that's a more
> likely typo).
>
> > How can I pull out a vector that is the residuals
> > at level 2? Everything I see on stack exchange and the mixed models list
> > serve points towards methods like VarCorr(). I'm not interested in a
> > summary of the L2 residuals so much as a vector of the same length as the
> > number of groups I have. Ultimately I want to test them for spatial
> > autocorrelation. Apologies if this is documented somewhere, but I have
> not
> > been able to find help online.
>
>  I always get confused about what levels mean in the context of
> mixed models (i.e. whether one counts down from the population level
> or up from the individual level), but the basic answer here is to
> get the *predictions* at the desired level and subtract them from
> the observed values, see ?predict.merMod -- the re.form argument
> is what you need.  re.form=NA or re.form=~0 gives you predictions
> at the population level (i.e. neglecting all random effects),
> re.form=NULL gives you predictions at the individual level (i.e.
> including all random effects), intermediate cases can be gotten
> by using a formula.
>
> The results will be ordered the same as the original observation
> vector.
>
>
> >
> > While I have found methods of incorporating spatial effects into a mixed
> > model using corStruct, I am interested in first evaluating if that is an
> > appropriate model for a given dataset by examining the level 2 residuals'
> > spatial patterning - or lack thereof.
>
>   Seems reasonable.
>
> >
> > Which slot contains the residuals for level 2 and how are they ordered?
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed May 11 16:30:12 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 11 May 2016 10:30:12 -0400
Subject: [R-sig-ME] extract level 2 residuals of merMod from lme() and
 test for spatial autocorrelation.
In-Reply-To: <CAA=SVwFn0sfj5Lx_h6Tfa+nOOVFn6O-TT2M+cNmfMT2RBCn5fg@mail.gmail.com>
References: <CAA=SVwFSEj3XBQ7VCu_ZFc4fBbt1zRfvx9jj919YpAHuo-kCzw@mail.gmail.com>
	<loom.20160507T195150-293@post.gmane.org>
	<CAA=SVwFn0sfj5Lx_h6Tfa+nOOVFn6O-TT2M+cNmfMT2RBCn5fg@mail.gmail.com>
Message-ID: <CABghstSoaMm52gHbaKAMWUSWMAqToRrE3CwDH1qKX8QGte4Fdg@mail.gmail.com>

  Briefly (without spending too much time digging into the details), I
suspect the discrepancy between the variance of the residuals and the
reported residual variance may be that the residual is calculated
based on the *penalized* residual sum of squares ... ?  May be worth
taking a look at the formulas in the lme4 JSS paper (which is included
as a vignette in the package) to clarify/confirm.


On Wed, May 11, 2016 at 9:32 AM, Dexter Locke <dexter.locke at gmail.com> wrote:
> Thanks very much.
>
> Yes, that was a typo. I'm working with lme4 and the lmer function to make
> merMod objects. Sorry for any confusion.
>
> Here is a reproducible example of my attempt to extract residuals at the
> population level (ie random effects) by subtracting predictions from
> observations.
>
> library(lme4)
> fm1 <- lmer(Reaction ~ Days + (1 | Subject), sleepstudy) # load library, fit
> merMod object
>
> test <- sleepstudy$Reaction - (predict(fm1, re.form= ~ (1| Subject))) #
> subtract predictions from observations
>
> summary(fm1) # examine residuals of random effects, which provides:
> # "Residual              960.5   30.99 " for variance and std dev,
> respectively
> var(test); sd(test) # which provides 869.8171 and 29.49266
>
> # test <- sleepstudy$Reaction - (predict(fm1, re.form= NULL)) #
> unsurprisingly has same results as above
>
> 960.5 <> 869.8171 and 30.99 <> 29.49266 although they are the same direction
> and order of magnitude. I'm finding similar results with my actual data and
> model fits.
>
> Any advice is appreciated, thanks again!
> Dexter
>
> On Sat, May 7, 2016 at 2:03 PM, Ben Bolker <bbolker at gmail.com> wrote:
>>
>> Dexter Locke <dexter.locke at ...> writes:
>>
>> >
>> > Apologies for cross-posting, another version of this was posted on
>> > r-sig-geo at ...
>> >
>> > I want to extract the level 2 residuals from a merMod object created
>> > with
>> > lme() and am struggling.
>>
>>   Not sure what you mean here -- this is a little bit inconsistent.
>> lmer (from lme4) makes merMod objects, lme (from nlme) makes lme objects.
>> I'm going to assume you're talking about lmer (since that's a more
>> likely typo).
>>
>> > How can I pull out a vector that is the residuals
>> > at level 2? Everything I see on stack exchange and the mixed models list
>> > serve points towards methods like VarCorr(). I'm not interested in a
>> > summary of the L2 residuals so much as a vector of the same length as
>> > the
>> > number of groups I have. Ultimately I want to test them for spatial
>> > autocorrelation. Apologies if this is documented somewhere, but I have
>> > not
>> > been able to find help online.
>>
>>  I always get confused about what levels mean in the context of
>> mixed models (i.e. whether one counts down from the population level
>> or up from the individual level), but the basic answer here is to
>> get the *predictions* at the desired level and subtract them from
>> the observed values, see ?predict.merMod -- the re.form argument
>> is what you need.  re.form=NA or re.form=~0 gives you predictions
>> at the population level (i.e. neglecting all random effects),
>> re.form=NULL gives you predictions at the individual level (i.e.
>> including all random effects), intermediate cases can be gotten
>> by using a formula.
>>
>> The results will be ordered the same as the original observation
>> vector.
>>
>>
>> >
>> > While I have found methods of incorporating spatial effects into a mixed
>> > model using corStruct, I am interested in first evaluating if that is an
>> > appropriate model for a given dataset by examining the level 2
>> > residuals'
>> > spatial patterning - or lack thereof.
>>
>>   Seems reasonable.
>>
>> >
>> > Which slot contains the residuals for level 2 and how are they ordered?
>> >
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


From harrietjamieson86 at gmail.com  Wed May 11 09:54:22 2016
From: harrietjamieson86 at gmail.com (Harriet Jamieson)
Date: Wed, 11 May 2016 08:54:22 +0100
Subject: [R-sig-ME] Fwd: linear model selection analysis
In-Reply-To: <CABPy4j57ZN_0KoshYMPtEH88L_4Yjj9G9DxuLWsmz8B_QxWChA@mail.gmail.com>
References: <CABPy4j57ZN_0KoshYMPtEH88L_4Yjj9G9DxuLWsmz8B_QxWChA@mail.gmail.com>
Message-ID: <CABPy4j6a+dRN9REso1izWQcih+jSbrO=ih=YBh-cZzRvLLRrhA@mail.gmail.com>

Hello list,

I am attempting a selection analysis sensu Lande and Arnold (1983), where
the basic premise is to model relative fitness of individuals as a function
of standardised trait values, where the relative fitness is relative to the
mean (by dividing fitness values by the mean fitness value, so centred
around 1) and the standardised trait values are calculated as z scores,
i.e. = (trait - mean) / SD, so they are centred around zero. The idea is
that, in its simplest form with a single trait of interest, the results of
the model 'fitness ~ trait? should give a coefficient for ?trait? that is a
selection gradient. My problem is that my ?trait? in this case is count
data, and it doesn?t seem appropriate to transform Poisson data into the
standardised trait variable as above. So my first question is whether this
is an appropriate way to treat count data?

I have considered three alternatives to work round this:
1. Plough ahead and transform the count data into the standardised trait
scores and do the analysis.
2. Use the raw count data as the trait variable, unstandardised - this
might be fine as a general linear model, but doesn?t give me sensible
estimates for selection gradients on the traits.
3. I tried looking for published work where count data was used in a
selection analysis - I?m sure I can?t be doing something that strange, but
I could only find one other example, and here they did something different,
where they actually turned the model around and modelled the trait as a
function of fitness, so trait ~ fitness, where fitness was relativised but
the trait was kept as count data and a Poisson distribution was specified.

I suppose if anyone has any specific experience of selection analysis, this
would be extremely helpful. More generally, however, I think I would like
some thoughts on the following questions:
1. Is it appropriate to z score transform count data? Why/why not?
2. If the basic model Y ~ X gives a coefficient for X that is the gradient,
then how is this interpretation of the coefficient affected if X is raw
count data?
3. Does the example I found where the model was flipped round give the same
information?

I realise the problem is rather specific to a certain application of linear
models, but I would be grateful for any insight anyone could offer on how
these alternatives change the interpretation of the models.

Thanks very much in advance,
Harriet

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed May 11 18:07:16 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 11 May 2016 16:07:16 +0000 (UTC)
Subject: [R-sig-ME] Help with MCMC fitting in R
References: <CAHtiW-mjfL1yE53ijAdA8ugF-J+13ktTZSSETtEJxUXYHvR+jQ@mail.gmail.com>
Message-ID: <loom.20160511T175921-156@post.gmane.org>

Janelle Sylvester <jsylves92 at ...> writes:

> 
> Hi,
> 
> I found this email address from the R-Forge website and was hoping you
> could help me with a problem I am having.  I keep getting an error message
> every time I try to preform a *post hoc* Markov chain on my zero-inflated,
> neg. binomial mixed model.  Below is my code and the error message I keep
> getting.  If I can't make this work, can you recommend any other ways of
> validating my model? I really can't find anything on this topic.
> 
> glmmNB<- glmmadmb(CON_XAL~Treatment+(1|Site), data = SR.year.raw,
> > zeroInflation = TRUE, family = "nbinom")
>
> summary(glmmNB) #Summary output is attached to this email as a picture
> 
> > fit_glmmNB <- glmmadmb(CON_XAL~Treatment+(1|Site),
> 
>                        data=SR.year.raw,
> >                        zeroInflation=TRUE, save.dir = "TMP",
> >                        family="nbinom",
> >                        mcmc=TRUE,
> >                        mcmc.opts=mcmcControl(mcmc=5000))
> 
> And the error message I get:
> 
> Error in R2admb::read_psv(file_name) : no PSV file found
> > In addition: Warning messages:
> > 1: In glmmadmb(CON_XAL ~ Treatment + (1 | Site), data = SR.year.raw,  :
> >   file glmmadmb.std exists: overwriting
> > 2: running command 'C:\Windows\system32\cmd.exe /c glmmadmb -maxfn 500
> > -maxph 5 -noinit -shess -mcmc 1000 -mcsave 1 -mcmult 1' had status 42
> 
> I tried running this:
> 
> mcmc.control <- function(mcmc=50000,

 snip

> > }:
> 
> But then when I run my model again, I get this error message:
> 
> Parameters were estimated, but standard errors were not: the most likely
> > problem is that the curvature at MLE was zero or negative
> > Error in glmmadmb(CON_XAL ~ Treatment + (1 | Site), 
> data = SR.year.raw,  :
> >   The function maximizer failed (couldn't find parameter file)

 snip

> I've tried for weeks to fix this problem and I just don't know what to do.
> If my data is just not suitable enough for this *post hoc* procedure, can
> you please recommend another way to validate my model so I can ensure that
> it fits well?
> 
> I attached my data and would be happy to send any other information that
> may help figure out a solution.  I am looking at the "Treatment" effect on
> seed abundances of 11 species (ignore ALL_PSI).  Site is my random factor.
> I am looking at species separately.
> 

 [snip]

  It's possible that you're just having problems with an out-of-date
binary: some people reported difficulty like this, and solved it
using instructions at:

https://stat.ethz.ch/pipermail/r-sig-mixed-models/2016q1/024490.html

  Data and figures get stripped by the mailing list software, so we
haven't seen that (you could send it to me, but I can't guarantee
I'll have time to take a look at it).

  I'm not sure what you're up to with defining mcmc.control there ...

  As far as other solutions go: do you absolutely need the post-hoc
MCMC?  It is nice, but I would generally say that if you do standard
model diagnostics (examine residuals and model predictions, ideally
graphically) it's not an ironclad requirement. (Among other things,
most other non-Bayesian model-fitting methods don't offer this 
feature ...)  Other ways to go to cross-check your model would be:

- fit a zero-inflated Poisson-logNormal with MCMCglmm (a bit of a nuisance,
but doable: search for "owls NCEAS bolker" to find an example)
- use the relatively new/experimental glmmTMB package (install
via devtools::install_github("glmmTMB/glmmTMB",sub="glmmTMB") , 
then library("glmmTMB"); ?Owls for an example)

  Ben Bolker


From bbolker at gmail.com  Wed May 11 18:52:48 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 11 May 2016 12:52:48 -0400
Subject: [R-sig-ME] Convergence Problems with glmer.nb model
In-Reply-To: <CAJuCY5ynUsVZqbdhk_=kij+nVgpDaG6q9SO2zj4z66_2x_Vc9w@mail.gmail.com>
References: <CAN=0SEkfdDsdiqmK51K0U4FYHyDhcsvWFLNTtbRJFL9oZXbF9g@mail.gmail.com>
	<CAN=0SEkTL+-UyXcpMRAQFwcCWvNJu+9ZR0wzBTHi+DXQ2JhKqg@mail.gmail.com>
	<CAJuCY5xLg1bN8A6-6oHQmQJgnDXTyDN+SvHJ1sRGtowP60DWzQ@mail.gmail.com>
	<CAN=0SEnVLZzbQGTqVJDHgFqUAXZHWpz-sPwQv5TOO4fCz+oQ_A@mail.gmail.com>
	<CAN=0SEm4Kc5_9qtsxxqvYp=fEVe+mvXvpW1LpncHJhHXQtkb1w@mail.gmail.com>
	<CAJuCY5ynUsVZqbdhk_=kij+nVgpDaG6q9SO2zj4z66_2x_Vc9w@mail.gmail.com>
Message-ID: <CABghstS9T9_q6YJEmEPEhFX3mSWomkmQOwAsGVA0Yt0dgs+2vQ@mail.gmail.com>

I've worked on this a bit more but haven't yet resolved it: see
https://github.com/lme4/lme4/issues/379

Nothing is *obviously* wrong. It actually looks like this *only*
happens with the default optimizer setting (bobyqa followed by
Nelder-Mead), yet another reason to switch the default to bobyqa
alone, which is something I have been meaning to do for months but
haven't done for various "perfect-is-the-enemy-of-the-good" reasons
...

On Mon, May 2, 2016 at 7:05 AM, Thierry Onkelinx
<thierry.onkelinx at inbo.be> wrote:
> Dear Aoibheann,
>
> It looks like the problem is within glmer.nb. I've fit the same model with
> glmer.nb, glmmadmb and inla. glmmadmb and inla give comparable estimates.
> The standard errors of glmer.nb are problematic.
>
> Maybe Ben Bolker can diagnose what is going wrong with glmer.nb.
>
> library(readr)
> library(dplyr)
> dataset <- read_csv("foraging subset.csv") %>%
>   mutate(
>     name = factor(name),
>     fieldid = factor(rank(origarea)),
>     logarea = log(origarea)
>   )
>
> library(lme4)
> m.lme4 <- glmer.nb(field_count ~ logarea + habitat + (1 | name) + (1 |
> fieldid), data = dataset)
>
> library(glmmADMB)
> m.admb <- glmmadmb(field_count ~ logarea + habitat + (1 | name) + (1 |
> fieldid), data = dataset, family = "nbinom")
>
>
> # install.packages("INLA", repos="https://www.math.ntnu.no/inla/R/stable")
> library(INLA)
> m.inla <- inla(field_count ~ f(name, model = "iid") + f(fieldid, model =
> "iid") + logarea + habitat, data = dataset, family = "nbinomial")
>
> summary(m.lme4)$coefficients
> summary(m.admb)$coefficients
> m.inla$summary.fixed
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more than
> asking him to perform a post-mortem examination: he may be able to say what
> the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2016-04-29 16:55 GMT+02:00 Aoibheann Gaughran <gaughra at tcd.ie>:
>>
>> Hi Thierry,
>>
>> Apologies in the delay in reverting, I have been out on fieldwork. I have
>> tried your suggestions, but unfortunately am still having convergence
>> issues.  The most simple Poisson model runs fine, so I tried a negative
>> binomial distribution but that produced about 12 convergence warnings.
>>
>> > modelA <- glmer.nb(field_count ~ (1|animal) + (1|field_id) +
>> > offset(log(origarea)), family = poisson, data = dframe2)
>>
>>  There were 12 warnings (use warnings() to see them)
>>
>>  > warnings()
>>
>> Warning messages:
>>
>> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
>> ... :
>>   Model failed to converge with max|grad| = 0.0493534 (tol = 0.001,
>> component 1)
>>
>> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
>> ... :
>>   Model failed to converge with max|grad| = 0.0627833 (tol = 0.001,
>> component 1)
>>
>> 3: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
>> ... :
>>   Model is nearly unidentifiable: very large eigenvalue - Rescale
>> variables?
>>
>> etc.
>>
>>
>> I reverted to the simple Poisson and added the OLR, which ran, but as soon
>> as I add any additional complexity/variables (apart from sex) it produces a
>> convergence warning.
>>
>> Warning message:
>> In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>   Model failed to converge with max|grad| = 0.0332321 (tol = 0.001,
>> component 1)
>>
>>
>> I am not sure where to go from here. Any guidance would be much
>> appreciated.
>>
>> Kind regards,
>>
>> Aoibheann
>>
>>
>>
>> On 25 April 2016 at 14:44, Aoibheann Gaughran <gaughra at tcd.ie> wrote:
>>>
>>> Hi Thierry,
>>>
>>> Here is the dropbox link to the data -
>>> https://www.dropbox.com/s/ne5d4zp2gncwylm/foraging%20subset.csv?dl=0
>>>
>>> I had changed the field area units from meter square to hectures already,
>>> so that should be okay.  There is one exceedingly large "field" which is
>>> actually a large area of forestry. Perhaps this is throwing the scaling off.
>>>
>>> Can you confirm that this is how I specify the observation level random
>>> effect:
>>>
>>> dframe1$obs <- factor(seq(nrow(dframe1)))  #modified from
>>> https://rpubs.com/bbolker/glmmchapter
>>>
>>> which is included in the model as
>>>
>>> +(1|obs)
>>>
>>>
>>> I'll try your suggestions and see how I get on.
>>>
>>> Many thanks,
>>>
>>> Aoibheann
>>>
>>> On 25 April 2016 at 13:40, Thierry Onkelinx <thierry.onkelinx at inbo.be>
>>> wrote:
>>>>
>>>> Dear Aoibheann,
>>>>
>>>> Two general suggestions on the design. 1) A random effect of field seems
>>>> relevant too. 2) Have the units of origarea in a relevant scale. You are
>>>> modelling the number of visits per unit of origarea. Then the number per
>>>> hectare seems more relevant to me than the number per square meter.
>>>>
>>>> Then try the most simple Poisson model to see it that converge.
>>>> glmer(field_count ~ (1| animal) + (1|field) + offset(log(origarea)), family
>>>> = poisson)
>>>>
>>>> If that works, then you could try the negative binomial distribution or
>>>> adding an observation level random effect.
>>>>
>>>> The mailing list strips most attachments. So you need to put them on a
>>>> website or post a dropbox or google drive link.
>>>>
>>>> Best regards,
>>>>
>>>>
>>>> ir. Thierry Onkelinx
>>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>>> and Forest
>>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>>> Kliniekstraat 25
>>>> 1070 Anderlecht
>>>> Belgium
>>>>
>>>> To call in the statistician after the experiment is done may be no more
>>>> than asking him to perform a post-mortem examination: he may be able to say
>>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>> The combination of some data and an aching desire for an answer does not
>>>> ensure that a reasonable answer can be extracted from a given body of data.
>>>> ~ John Tukey
>>>>
>>>> 2016-04-25 14:08 GMT+02:00 Aoibheann Gaughran <gaughra at tcd.ie>:
>>>>>
>>>>> On 25 April 2016 at 13:00, Aoibheann Gaughran <gaughra at tcd.ie> wrote:
>>>>>
>>>>> > Good morning,
>>>>> >
>>>>> > First time posting so I hope I am including all of the relevant
>>>>> > information.
>>>>> >
>>>>> > I am attempting to analyse the foraging behaviour of a animal in an
>>>>> > agricultural landscape. The objective is to identify the factors
>>>>> > (habitat
>>>>> > type, environmental variables and animal-specific variables) that
>>>>> > best
>>>>> > predict foraging site preference. Some fields are preferred while
>>>>> > others
>>>>> > are avoided.
>>>>> >
>>>>> > The response variable is count data - the number of times a given
>>>>> > animal
>>>>> > was in a given field in a given month. An animal's home range varies
>>>>> > from
>>>>> > month to month, so the area available to it and the fields that fall
>>>>> > within
>>>>> > its home range change somewhat every month. The count data shows an
>>>>> > overdispersed, negative binomial distribution, and is zero inflated
>>>>> > as
>>>>> > fields that fell within the home range where the animal had *not
>>>>> > *foraged
>>>>> > in that month are also included in the dataset. The individual animal
>>>>> > is
>>>>> > specified as a random variable to account for pseudoreplication.
>>>>> >
>>>>> > It should be noted that at the moment I am attempting to run a the
>>>>> > model
>>>>> > on a subset of the data (n=671) as I had attempted to run the model
>>>>> > on the
>>>>> > full dataset (n=62,000) but three days later the model (which
>>>>> > included
>>>>> > interaction terms at this point) had still failed to run, and when
>>>>> > stopped,
>>>>> > R gave me a multitude of convergence warning messages e.g.
>>>>> >
>>>>> > 13: In (function (fn, par, lower = rep.int(-Inf, n), upper =
>>>>> > rep.int(Inf,
>>>>> > ... :
>>>>> >   failure to converge in 10000 evaluations
>>>>> >
>>>>> > Simpler iterations of the model, with fewer explanatory terms, and no
>>>>> > interaction terms, also gave me convergence and some scaling
>>>>> > warnings,
>>>>> > which I sought to address using:
>>>>> >
>>>>> > control=glmerControl(optCtrl=list(maxfun=20000)
>>>>> >
>>>>> > and by scaling the numeric variables age, slope and aspect as
>>>>> > follows:-
>>>>> >
>>>>> > dframe1$agescale <- scale(dframe1$age, center = TRUE, scale = FALSE)
>>>>> > dframe1$slopescale <- scale(dframe1$slope, center = TRUE, scale =
>>>>> > FALSE)
>>>>> > dframe1$aspectscale <- scale(dframe1$aspect, center = TRUE, scale =
>>>>> > FALSE)
>>>>> >
>>>>> > Currently, the model looks like this:
>>>>> >
>>>>> > > model1 <- glmer.nb(field_count ~ habitat +                    +
>>>>> > > sex+                    + agescale+                    #+ mon+
>>>>> > > + soil+                    + slopescale+                    + aspectscale+
>>>>> > > + offset(log(origarea)) #take into account field size +
>>>>> > > +(1|animal),+
>>>>> > > control=glmerControl(optCtrl=list(maxfun=20000)),+                    data =
>>>>> > > dframe1)
>>>>> >
>>>>> > There were 24 warnings (use warnings() to see them)
>>>>> > > warnings()Warning messages:
>>>>> > 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
>>>>> > control$checkConv,  ... :
>>>>> >   Model is nearly unidentifiable: very large eigenvalue
>>>>> >  - Rescale variables?;Model is nearly unidentifiable: large
>>>>> > eigenvalue ratio
>>>>> >  - Rescale variables?
>>>>> > 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
>>>>> > control$checkConv,  ... :
>>>>> >   Model failed to converge with max|grad| = 0.0134799 (tol = 0.001,
>>>>> > component 1)
>>>>> > 3: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
>>>>> > control$checkConv,  ... :
>>>>> >   Model failed to converge with max|grad| = 0.148644 (tol = 0.001,
>>>>> > component 1)
>>>>> > 4: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
>>>>> > control$checkConv,  ... :
>>>>> >   Model is nearly unidentifiable: large eigenvalue ratio
>>>>> >  - Rescale variables?
>>>>> >
>>>>> > etc.
>>>>> >
>>>>> > So the model still fails to converge despite rescaling and altering
>>>>> > the
>>>>> > number of iterations. I had also received the following error in
>>>>> > relation
>>>>> > to month (in the reduced dataset there are only *four *months), so
>>>>> > Ive
>>>>>
>>>>> > had to exclude it for the time being. I am not sure why I am getting
>>>>> > this
>>>>> > error since the factor has four levels.
>>>>> >
>>>>> > Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
>>>>> > contrasts can be applied only to factors with 2 or more levels
>>>>> >
>>>>> > I do eventually want to include interaction terms as previous
>>>>> > analysis on
>>>>> > ranging behaviour suggests there is an interaction between age and
>>>>> > sex.
>>>>> >
>>>>> > Summary of dataset attached.  Also attached is the .csv file
>>>>> > containing
>>>>> > the reduced dataset.
>>>>> >
>>>>> > I have read various suggestions online and have come across the
>>>>> > following
>>>>> > worrying line "It's perfectly possible that your data is insufficient
>>>>> > to
>>>>> > support the complexity of the model or the model is incorrectly
>>>>> > constructed
>>>>> > for the design of the study".
>>>>> >
>>>>> > I would greatly appreciate any help you could give me with
>>>>> > understanding
>>>>> > and solving the problems I am encountering with my model.
>>>>> >
>>>>> > Kind regards,
>>>>> >
>>>>> > --
>>>>> > Aoibheann Gaughran
>>>>> >
>>>>> > Behavioural and Evolutionary Ecology Research Group
>>>>> > Zoology Building
>>>>> > School of Natural Sciences
>>>>> > Trinity College Dublin
>>>>> > Dublin 2
>>>>> > Ireland
>>>>> > Phone: +353 (86) 3812615
>>>>> >
>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> Aoibheann Gaughran
>>>>>
>>>>> Behavioural and Evolutionary Ecology Research Group
>>>>> Zoology Building
>>>>> School of Natural Sciences
>>>>> Trinity College Dublin
>>>>> Dublin 2
>>>>> Ireland
>>>>> Phone: +353 (86) 3812615
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>>
>>>
>>>
>>>
>>> --
>>> Aoibheann Gaughran
>>>
>>> Behavioural and Evolutionary Ecology Research Group
>>> Zoology Building
>>> School of Natural Sciences
>>> Trinity College Dublin
>>> Dublin 2
>>> Ireland
>>> Phone: +353 (86) 3812615
>>
>>
>>
>>
>> --
>> Aoibheann Gaughran
>>
>> Behavioural and Evolutionary Ecology Research Group
>> Zoology Building
>> School of Natural Sciences
>> Trinity College Dublin
>> Dublin 2
>> Ireland
>> Phone: +353 (86) 3812615
>
>


From l.blything at lancaster.ac.uk  Wed May 11 20:34:21 2016
From: l.blything at lancaster.ac.uk (Blything, Liam)
Date: Wed, 11 May 2016 18:34:21 +0000
Subject: [R-sig-ME] ENQUIRY: independent slopes of categorical effects in a
 random-effects
Message-ID: <AF88371526D5C042BFB82F14316AF7A423F78859@EX-1-MB1.lancs.local>

Dear Dr Bolker,

Enquiry: Independent slopes of categorical effects in a random-effects.

An important prior note is that I am dealing with IVs that are binomial (e.g., the influence of age: young vs old).
My advisor and I both cannot understand the output for a random effects structure that occurs when excluding the correlations between the slope and the intercept (i.e., without investing a parameter for their correlation).

Specifically, if I put in a simple syntax for any dataset, such as below, ....
NAMEOFMODEL= glmer(DV + (IVone + IVtwo) +
(1|subject) +(0+IVone|subject), data=ANYDATASET, family = "binomial")

.... The random effect structure is not what we would expect:

Random effects







        Variance
SD

Subject (intercept)







        0.10
0.32

Subject.1 (slope) young







        0.20
0.45

Subject.1 (slope) old







        0.42
0.65


Obviously, we would expect the following output (below) just as we get when we do not exclude correlations [e.g., (IVone+1|subject) ]

Random effects









Variance

SD

Subject (intercept)









0.53

0.72

Subject.1 (slope) IVone









0.29

0.54



I find the first random effects output extremely difficult to interpret, and I wonder whether it indicates a bug?


Your expertise would be very valuable here, and hoprfully it helps raise an issue for the future when people want to interpret a random effects structure that has a binomial IV slope that is not allowed to correlate with the intercept.

Thank you in advance,

Liam Blything

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Wed May 11 20:46:33 2016
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 11 May 2016 19:46:33 +0100
Subject: [R-sig-ME] Fwd: linear model selection analysis
In-Reply-To: <CABPy4j6a+dRN9REso1izWQcih+jSbrO=ih=YBh-cZzRvLLRrhA@mail.gmail.com>
References: <CABPy4j57ZN_0KoshYMPtEH88L_4Yjj9G9DxuLWsmz8B_QxWChA@mail.gmail.com>
	<CABPy4j6a+dRN9REso1izWQcih+jSbrO=ih=YBh-cZzRvLLRrhA@mail.gmail.com>
Message-ID: <57337E09.7000908@ed.ac.uk>

Hi,

If your traits don't appear as interactions (or quadratics) then the 
coefficients associated with the traits are Lande-Arnold standardised 
selection gradients if you fit a log-link glm (i.e. the standard with 
Poisson models).  If you do have interactions, then its a bit more 
complicated.

Cheers,

Jarrod


On 11/05/2016 08:54, Harriet Jamieson wrote:
> Hello list,
>
> I am attempting a selection analysis sensu Lande and Arnold (1983), where
> the basic premise is to model relative fitness of individuals as a function
> of standardised trait values, where the relative fitness is relative to the
> mean (by dividing fitness values by the mean fitness value, so centred
> around 1) and the standardised trait values are calculated as z scores,
> i.e. = (trait - mean) / SD, so they are centred around zero. The idea is
> that, in its simplest form with a single trait of interest, the results of
> the model 'fitness ~ trait? should give a coefficient for ?trait? that is a
> selection gradient. My problem is that my ?trait? in this case is count
> data, and it doesn?t seem appropriate to transform Poisson data into the
> standardised trait variable as above. So my first question is whether this
> is an appropriate way to treat count data?
>
> I have considered three alternatives to work round this:
> 1. Plough ahead and transform the count data into the standardised trait
> scores and do the analysis.
> 2. Use the raw count data as the trait variable, unstandardised - this
> might be fine as a general linear model, but doesn?t give me sensible
> estimates for selection gradients on the traits.
> 3. I tried looking for published work where count data was used in a
> selection analysis - I?m sure I can?t be doing something that strange, but
> I could only find one other example, and here they did something different,
> where they actually turned the model around and modelled the trait as a
> function of fitness, so trait ~ fitness, where fitness was relativised but
> the trait was kept as count data and a Poisson distribution was specified.
>
> I suppose if anyone has any specific experience of selection analysis, this
> would be extremely helpful. More generally, however, I think I would like
> some thoughts on the following questions:
> 1. Is it appropriate to z score transform count data? Why/why not?
> 2. If the basic model Y ~ X gives a coefficient for X that is the gradient,
> then how is this interpretation of the coefficient affected if X is raw
> count data?
> 3. Does the example I found where the model was flipped round give the same
> information?
>
> I realise the problem is rather specific to a certain application of linear
> models, but I would be grateful for any insight anyone could offer on how
> these alternatives change the interpretation of the models.
>
> Thanks very much in advance,
> Harriet
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From M.Fairbrother at bristol.ac.uk  Wed May 11 20:58:07 2016
From: M.Fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Wed, 11 May 2016 19:58:07 +0100
Subject: [R-sig-ME] extract level 2 residuals of merMod from lme() and
 test for spatial autocorrelation.
Message-ID: <CAAH-yP9hgCt5=uHqLb1W4y2j_39NHY8Acmkwbo6W8TkdP3uhaw@mail.gmail.com>

Hi Dexter,
I may be wrong, but it sounds like you may simply be looking for ranef(fm1)
?
However, it seems you are also troubled by the fact that the standard
deviation of the residuals is not the same as the residual-level standard
deviation.
That is, sigma(fm1) and as.data.frame(VarCorr(fm1))[2,] are not equal to
sd(resid(fm1)).
What is resid(fm1)? Compare:
head(resid(fm1))
head(sleepstudy$Reaction - (predict(fm1, re.form= NULL)))
head(with(sleepstudy, Reaction - fixef(fm1)[1] - fixef(fm1)[2]*Days -
ranef(fm1)$Subject[Subject,]))
In other words, you are looking at the residuals *after* taking into
account the random effects (i.e., the group-level errors).
In that vein, compare also:
as.data.frame(VarCorr(fm1))[1,]
sd(ranef(fm1)$Subject[,1])
The standard deviation of the random effects (group-level errors) is,
therefore, not the same as the group-level standard deviation. At both
levels, the variance of the random errors you can extract is smaller than
the variance of the random errors you can't see. So what's going on?
Basically, the random effects are shrunk towards zero, while the estimate
provided of the group-level standard deviation is pre-shrinkage. And
because the residuals you can extract are calculated taking into account
the random effects, the residuals--and thus their SD--are also affected by
the shrinkage.
Does that help?
- Malcolm



> Date: Wed, 11 May 2016 10:30:12 -0400
> From: Ben Bolker <bbolker at gmail.com>
> To: Dexter Locke <dexter.locke at gmail.com>
> Cc: "r-sig-mixed-models at r-project.org"
>         <r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] extract level 2 residuals of merMod from lme()
>         and test for spatial autocorrelation.
>
>   Briefly (without spending too much time digging into the details), I
> suspect the discrepancy between the variance of the residuals and the
> reported residual variance may be that the residual is calculated
> based on the *penalized* residual sum of squares ... ?  May be worth
> taking a look at the formulas in the lme4 JSS paper (which is included
> as a vignette in the package) to clarify/confirm.
>
>
> On Wed, May 11, 2016 at 9:32 AM, Dexter Locke <dexter.locke at gmail.com>
> wrote:
> > Thanks very much.
> >
> > Yes, that was a typo. I'm working with lme4 and the lmer function to make
> > merMod objects. Sorry for any confusion.
> >
> > Here is a reproducible example of my attempt to extract residuals at the
> > population level (ie random effects) by subtracting predictions from
> > observations.
> >
> > library(lme4)
> > fm1 <- lmer(Reaction ~ Days + (1 | Subject), sleepstudy) # load library,
> fit
> > merMod object
> >
> > test <- sleepstudy$Reaction - (predict(fm1, re.form= ~ (1| Subject))) #
> > subtract predictions from observations
> >
> > summary(fm1) # examine residuals of random effects, which provides:
> > # "Residual              960.5   30.99 " for variance and std dev,
> > respectively
> > var(test); sd(test) # which provides 869.8171 and 29.49266
> >
> > # test <- sleepstudy$Reaction - (predict(fm1, re.form= NULL)) #
> > unsurprisingly has same results as above
> >
> > 960.5 <> 869.8171 and 30.99 <> 29.49266 although they are the same
> direction
> > and order of magnitude. I'm finding similar results with my actual data
> and
> > model fits.
> >
> > Any advice is appreciated, thanks again!
> > Dexter
> >
> > On Sat, May 7, 2016 at 2:03 PM, Ben Bolker <bbolker at gmail.com> wrote:
> >>
> >> Dexter Locke <dexter.locke at ...> writes:
> >>
> >> >
> >> > Apologies for cross-posting, another version of this was posted on
> >> > r-sig-geo at ...
> >> >
> >> > I want to extract the level 2 residuals from a merMod object created
> >> > with
> >> > lme() and am struggling.
> >>
> >>   Not sure what you mean here -- this is a little bit inconsistent.
> >> lmer (from lme4) makes merMod objects, lme (from nlme) makes lme
> objects.
> >> I'm going to assume you're talking about lmer (since that's a more
> >> likely typo).
> >>
> >> > How can I pull out a vector that is the residuals
> >> > at level 2? Everything I see on stack exchange and the mixed models
> list
> >> > serve points towards methods like VarCorr(). I'm not interested in a
> >> > summary of the L2 residuals so much as a vector of the same length as
> >> > the
> >> > number of groups I have. Ultimately I want to test them for spatial
> >> > autocorrelation. Apologies if this is documented somewhere, but I have
> >> > not
> >> > been able to find help online.
> >>
> >>  I always get confused about what levels mean in the context of
> >> mixed models (i.e. whether one counts down from the population level
> >> or up from the individual level), but the basic answer here is to
> >> get the *predictions* at the desired level and subtract them from
> >> the observed values, see ?predict.merMod -- the re.form argument
> >> is what you need.  re.form=NA or re.form=~0 gives you predictions
> >> at the population level (i.e. neglecting all random effects),
> >> re.form=NULL gives you predictions at the individual level (i.e.
> >> including all random effects), intermediate cases can be gotten
> >> by using a formula.
> >>
> >> The results will be ordered the same as the original observation
> >> vector.
> >>
> >>
> >> >
> >> > While I have found methods of incorporating spatial effects into a
> mixed
> >> > model using corStruct, I am interested in first evaluating if that is
> an
> >> > appropriate model for a given dataset by examining the level 2
> >> > residuals'
> >> > spatial patterning - or lack thereof.
> >>
> >>   Seems reasonable.
> >>
> >> >
> >> > Which slot contains the residuals for level 2 and how are they
> ordered?
>

	[[alternative HTML version deleted]]


From robgriffin247 at hotmail.com  Fri May 13 14:51:37 2016
From: robgriffin247 at hotmail.com (Rob Griffin)
Date: Fri, 13 May 2016 14:51:37 +0200
Subject: [R-sig-ME] Interpreting fixed effects of mcmcglmm interaction and
	randomisation
Message-ID: <DUB124-W46D7062EBC22B90C54F7D9FA740@phx.gbl>

Dear list,

I am trying learn how to model the relationship between an environmental factor and sexual dimorphism using MCMCglmm, and have based analysis on the data in Garratt et al 2015* - a study looking at the relationship between sexual dimorphism in lifespan, and juvenile mortality. They use two populations measured over a number of years, giving cohorts (for which juvenile mortality can be estimated), and information on the identity, lifespan, and sex of each individual. The script below** creates the dummy data I am using to develop the model which is similar to the data set they would have used (though entirely artificial - I have forced a?positive relationship between juvenile mortality and male lifespan, while female lifespan is random).??They fit a general linear mixed model to "assess the relationship between survival to the onset of actuarial senescence (dependent variable) and cohort-specific juvenile mortality (independent variable), while including sex as a fixed effect, year and population as random effects, with year nested within population." I have attempted to recreate this analysis (but using MCMCglmm) as the following (where 'Life' is lifespan, 'Mort' is juvenile mortality within the individuals cohort, 'Sex' is the sex of the individual, 'Pop' and 'Year' are the population and year of the individual):


mod1 = MCMCglmm(Life ~ Mort:Sex - 1,
random = ~ Pop:Year,
rcov = ~units,	
nitt = ? 13000, burnin = 3000, thin = ? 10,?
prior = prior1,?
pr = T,
family = "gaussian",?
start = list(QUASI = FALSE),?
data = DF1)	

> summary(mod1)

?Iterations = 3001:12991
?Thinning interval ?= 10
?Sample size ?= 1000?

?DIC: 1437.558?

?G-structure: ?~Pop:Year

? ? ? ? ?post.mean l-95% CI u-95% CI eff.samp
Pop:Year ? ? 34.23 ? ? 19.4 ? ? 55.2 ? ? 1000

?R-structure: ?~units

? ? ? post.mean l-95% CI u-95% CI eff.samp
units ? ? 4.746 ? ?3.946 ? ?5.487 ? ?909.7

?Location effects: Life ~ Mort:Sex - 1?

? ? ? ? ? post.mean l-95% CI u-95% CI eff.samp ?pMCMC ? ?
Mort:SexF ? ? 25.17 ? ?20.61 ? ?30.46 ? ? 1000 <0.001 ***
Mort:SexM ? ? 43.81 ? ?38.82 ? ?48.71 ? ? 1000 <0.001 ***
---
Signif. codes: ?0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


Which brings me to my main subject(s) of interest: essentially, how to interpret the fixed effect estimates, given that?I am aiming to answer the question, is juvenile mortality related to sexual dimorphism in lifespan?

Going from 'Life ~ Mort -1' to?'Life ~ Mort:Sex -1' improves the fit of the model (DIC 1902 -> 1438), so could I conclude that there is a significant sex-specific effect/interaction with juvenile mortality on lifespan? What do the actual values of the posterior mean (post.mean) tell me - is it just that the Mort:SexM interaction effect is significantly larger than the Mort:SexF effect (CI's of the two estimates do not overlap)? Using Mort*Sex gives SexM and SexF estimates which seem to better reflect the true mean values of the population, where the post.means of Mort is ~0, SexF and SexM are ~12, and the Mort:SexM fixed effect is ~18, which makes me more inclined to think that Mort*Sex is a more appropriate model (but brings up the question what does the post.mean of ~18 for Mort:SexM actually mean?).?

I have also done randomisation where I randomise the mortality rates among cohorts for 50 chains, in the 'Mort:Sex' model this results in the Mort:SexF and Mort:SexM estimates remaining similar to the raw data model - does randomisation offer insight in to the relationship between sexual dimorphism and juvenile mortality? Using a model where 'Mort*Sex' is the fixed effect then the randomisation shifts the estimates of Mort:SexM to ~0, and that difference is absorbed in to the SexM fixed effect (because there is sexual dimorphism, but the relationship to juvenile mortality disappears). Could I effectively use this as a kind of significance test (e.g. I do 1000 randomisations, the mean Mort:SexM estimate is> the actual estimate in 11/1000 cases, thus pseudo-p is ~0.011).

Finally, (and on a slightly different topic) I have used 'pr = T' which means I can get posterior distributions for each level of the Pop:Year combination - i.e. a posterior distribution for each cohort. Could this information be used to get an estimate of the sex-specific lifespans for each population? For example, summing the posterior distribution of 'Mort:SexM' with 'Pop:Year.A.1983' would give a distribution of the estimated lifespan for males in population A for the year 1983? I don't think this is the case - as the numbers seem too different from the data - so how could I derive cohort-sex-specific lifespans?

Long story short - I'm looking for some insight on how to correctly define and interpret the fixed effects... Overall I'm inclined to think that 'Mort*Sex' gives the correct specification of the model, and the randomisation shows whether the environmental factor has an effect on sexual dimorphism.?
Thanks - full script below,
Rob

* Garratt et al 2015, Current Biology?"High juvenile mortality is associated with sex-specific adult survival and lifespan in wild roe deer."

**
#### R-SCRIPT ####
rm(list=ls())
set.seed(255)
library("reshape")
library("MCMCglmm")

DF1 = data.frame(c(1:320), rep(c("A", "B"), each = 10), rep(1983:1998, each = 20), sample(c("M", "F"), replace = T, size = 320), rnorm(320, 12, 2), rep((1/(1+abs(rnorm(16, 2, 1 )))), each = 20))
colnames(DF1) = c("ID", "Pop", "Year", "Sex", "Life", "Mort")

# Make SD related to juvenile mortality
DF1$Life = ifelse(DF1$Sex == "M", DF1$Life + DF1$Mort*18, DF1$Life)
# Mean zero, unit variance
DF1$Life0 = (DF1$Life-mean(DF1$Life))/sqrt(var(DF1$Life))

prior1 = list(	G = list(G1 = list(V = 1, nu = 1, alpha.mu = 0, alpha.V = 1000)),
R = list(V = 1, nu = 0.002))

mod1 = MCMCglmm(Life ~ Mort:Sex - 1,
random = ~ Pop:Year,
rcov = ~units,	
nitt = ? 13000, burnin = 3000, thin = ?10,?
prior = prior1,?
pr = T,
family = "gaussian",?
start = list(QUASI = FALSE),?
data = DF1)	

summary(mod1)



----------------------------------------------------------

Robert M. Griffin
Postdoctoral Researcher, University of Turku
www.griffinevo.wordpress.com? 		 	   		  

From g.czanner at googlemail.com  Thu May 12 11:29:25 2016
From: g.czanner at googlemail.com (Gabriela Czanner)
Date: Thu, 12 May 2016 10:29:25 +0100
Subject: [R-sig-ME] lme with cyclic cubic regression splines
Message-ID: <CAOQoCVt0n+0yexN_OuWKvnaYPKiQuNLkccijsnQ7Lcb94ygr3g@mail.gmail.com>

Hello list,

I am trying to fit linear mixed model with fixed effect being cyclic cubic
regression splines, because my data are defined on a circle, while circle
is divided into 24 directions. I defined a variable Direction which is
numeric and has values 1,2,... 24. I receive this error message:

> out.lme.8=lme(Y~ s(Direction,bs="cc",k=8),
+               random=~1|PatientID,
+               data=mydata,na.action=na.omit,method="ML")
Error in model.frame.default(fixed, dataMix) :
  invalid type (list) for variable 's(Direction, bs = "cc", k = 8)'
>

I wonder if anyone has any suggestion, please?

Best regards,

Gabriela

Dr Gabriela Czanner
Lecturer in Ophthalmic Statistics
University of Liverpool

	[[alternative HTML version deleted]]


From stephanie.periquet at gmail.com  Fri May 13 18:28:02 2016
From: stephanie.periquet at gmail.com (=?UTF-8?B?U3TDqXBoYW5pZSBQw6lyaXF1ZXQ=?=)
Date: Fri, 13 May 2016 18:28:02 +0200
Subject: [R-sig-ME] Mixed mutlinomial regression for count data with
	overdisperion & zero-inflation
Message-ID: <CAMKTVFX_ci_4kFyM2UcXh0uK=QKZGuX70yuL19ZD9oNyhT2BOw@mail.gmail.com>

Dear list members,



First sorry for this very long first post ?


I am looking for advises to fit a mixed multinomial regression on count
data that are overdispersed and zero-inflated. My question is to evaluate
the effect of season and moonlight on diet composition of bat-eared foxes.
My dataset is composed of 14 possible prey item, 20 individual foxes
observed, 4 seasons and a moon illumination index ranging from 0 to 1 by
0.1 implements (considered as a continuous variable even if takes only 11
values). For each unique combination of individual*season*moon, I thus has
14 lines, one for the count of each prey item.


>From what I gathered, it would be possible to use a standard glmm model of
the following form to answer my question (ie a multinomial regression):

glmer(count~item+item:season+item:moon+offset(logduration)+(1+indiv)+(1|obs)+
(1|id), family=poisson)

where count is the number of prey of a given type recorded eaten;

item is the prey type;

logduration is the log(total time observed for a given combination of
individual*season*moon);

obs is a unique id for each combination of individual*season*moon, so each
obs value regroups 14 lines (one for each prey item) with the same
individual*season*moon;

id is a unique id for each line to account for overdispersion (as
quasi-poisson or negative binomial distributions are not implemented in
lme4, Elston et al. 2001).



However, they are a lot of zeros in my data i.e. lot of prey items has
never been observed being eaten for mane combinations of
individual*season*moon.

Following Ben Bolker wiki (http://glmm.wikidot.com/faq) I summarize that I
should use of the following methods to answer my question


   - ?      glmmADMB, with family=nbinom
   - ?      MCMCglmm, with family=zipoisson
   - ?      "expectation-maximization (EM) algorithm" in lme4



Here come the questions:

1.               1. Is it correct to assume that I could use the same model
structure (count~item+item:season+item:moon+offset(logduration)+(1+indiv)+(1|obs))
in glmmADMB or MCMCglmm to answer my question ?

2.   I then wouldn't need the (1|id) to correct for overdispersion as both
methods would already account for it, correct?

3.   I am totally new to MCMCglmm, so would it be correct to define the
priors and model as follows (inspired from Ben Bolker et al. 2012 Owls
example: a zero-inflated, generalized linear mixed model for count data
2012)

# define the fixed effects

fixef2 <- count~trait-1+  at.level(trait,1):logduration  +
at.level(trait,1):(item*season) +  at.level(trait,1):(item*moon)

#Set up a variable that will pick out the offset (duration) parameter,
which will be in 3rd position

offvec <- c(1,1,2,rep(1,))

#define the priors with 2 random factors and log(duration) as offset

prior2 <- list(R=list(V=diag(c(1,1)),nu=0.002,fix=2),

G=list(G1=list(V=diag(c(1,1e-6)),nu=0.002,fix=2),
G2=list(V=diag(c(1,1e-6)),nu=0.002,fix=2)),

list(B=list(mu=c(0,1)[offvec],

V=diag(c(1e6,1e-6)[offvec]))))

# define the model

mfit1 <- MCMCglmm(fixef2, rcov=~idh(trait):units,
random=~idh(trait):indiv+idh(trait):obs, prior=prior2,data=diet,
family="zipoisson",verbose=FALSE))

4.     4.  If I were to use the EM algorithm method, how should the results
be interpreted?



Thanks in advance for your help!

Stephanie

-- 
*St?phanie PERIQUET (PhD) * - Bat-eared Fox Research Project
*Dept of Zoology & Entomology*
*University of the Free State, Qwaqwa Campus*
*Cell: +27 79 570 2683*
ResearchGate profile
<https://www.researchgate.net/profile/Stephanie_Periquet>


Kalahari bat-eared foxes on Twitter <https://twitter.com/kal_batearedfox>

	[[alternative HTML version deleted]]


From epalmery at cns.umass.edu  Fri May 13 18:58:20 2016
From: epalmery at cns.umass.edu (Evan Palmer-Young)
Date: Fri, 13 May 2016 12:58:20 -0400
Subject: [R-sig-ME] Analyzing evolution of resistance
In-Reply-To: <20534_1463156776_57360028_20534_1781_1_mailman.2855.1463156772.3828.r-sig-mixed-models@r-project.org>
References: <20534_1463156776_57360028_20534_1781_1_mailman.2855.1463156772.3828.r-sig-mixed-models@r-project.org>
Message-ID: <CAAge6+5_XpN59hdySfEfx1zsA7iU+NO6FqFa=WPmouzx8+d4Pw@mail.gmail.com>

>
>
> Dear List,
> I'd appreciate suggestions on how to model a series of experiments on the
> evolution of resistance by a bee pathogen to nectar chemicals.
> I conducted an experiment in which I exposed pathogens to a constant drug
> concentration over 6 weeks. At each week, I tested drug resistance in the
> exposed lines, and also in control lines that were propagated in the
> absence of the drug. I have three replicate sub-cultured lines within each
> treatment (n=3).
>
> Here's a link to the DATA
> <https://drive.google.com/file/d/0B1YU9mSCw_jSbnpXVkYyWHJoTG8/view?usp=sharing>
> and my SCRIPT
> <https://drive.google.com/open?id=0B1YU9mSCw_jSb0MzZzZvMEtVYmM>
>
> I was planning to analyze this with a mixed model (lmer) of:
> *Drug EC50 ~ Treatment*Time + (1|Line)*
> to account for repeated measures on the lines in each week.
>
> However, the effect of time on EC50 is not at all linear.
> So my next idea was to standardize each week's EC50 values relative to the
> average EC50 in the control lines in the same week. So the model looks like:
> *standardized ec50 ~ Treatment*Time + (1|Line)*
> However, this seems to cause problems with the likelihood ratio test for
> the effect of time, because there is no variation in the control group: the
> standardized ec50 is pinned at 1.00 for each week.
> With this model, I get a df=0 when I compare full and reduced models, and
> p-values that are either 0 or 1. I feel like something is being divided by
> zero.
> I can still do chi-squared tests, but I preferred to use likelihood ratio
> tests, and I'm a little worried about the model because the likelihood
> ratio tests aren't behaving normally.
>
> My third idea was just to abandon the mixed model framework in favor of
> Tukey-corrected
> *t-tests of exposed vs. control lines ... at each timepoint*
> This would avoid the problem of explicitly testing the effect of time, and
> also avoid pretending that there was a linear effect of time.
> However, I'm concerned about just having n=3 at each timepoint, and also
> not having an overarching model for the whole analysis.
>
> What would you advice?
> Analysis on absolute ec50 values or ratios?
> Mixed-effects model or t-tests?
>
> Thanks very much for your suggestions,
> Evan
>
> Here is also a draft of the figure depicting changes in ratios over time,
> both for the (1) EC50 values (inhibitory concentrations of the chemical in
> the weekly "challenges" across a range of concentrations) and
> (2) Cell density ratios-- these show the degree of inhibition at a given
> concentration, to which the cells were constantly exposed?
> https://drive.google.com/open?id=0B1YU9mSCw_jSUGtJUWh3dkJPZHM
>
>
> --
> Department of Biology
> 221 Morrill Science Center
> 611 North Pleasant St
> Amherst MA 01003
> https://sites.google.com/a/cornell.edu/evan-palmer-young/
>
>


-- 
Department of Biology
221 Morrill Science Center
611 North Pleasant St
Amherst MA 01003
https://sites.google.com/a/cornell.edu/evan-palmer-young/

	[[alternative HTML version deleted]]


From villers.alexandre at gmail.com  Sat May 14 11:15:43 2016
From: villers.alexandre at gmail.com (Alexandre Villers)
Date: Sat, 14 May 2016 11:15:43 +0200
Subject: [R-sig-ME] lme with cyclic cubic regression splines
In-Reply-To: <CAOQoCVt0n+0yexN_OuWKvnaYPKiQuNLkccijsnQ7Lcb94ygr3g@mail.gmail.com>
References: <CAOQoCVt0n+0yexN_OuWKvnaYPKiQuNLkccijsnQ7Lcb94ygr3g@mail.gmail.com>
Message-ID: <CAFrtd2N-=c9cYdy00w5Wg_aW8-goFQ9TXB1_7ZEnwNgjJp9WAg@mail.gmail.com>

Good morning,

For that you can use mgcv::gamm or gamm4::gamm4 (but for the later, I'm not
sure whether cyclic splines are possible).
HTH

Alex

	[[alternative HTML version deleted]]


From itzikf at outlook.com  Sun May 15 12:45:56 2016
From: itzikf at outlook.com (=?iso-8859-8-i?B?4On26fcg9Pjj9+nv?=)
Date: Sun, 15 May 2016 10:45:56 +0000
Subject: [R-sig-ME] Using r for multi-level meta-analysis
Message-ID: <DUB128-W4868B211C8F7BD11786BB1DF760@phx.gbl>

Dear R and MLM experts,I'm trying to figure out whether it's possible to implement Van den Noortgate (2014) approach for three-level meta-analysis in lme4 or nlme. In my data structure I have several outcomes per study, and the three levels are: Level 1 - regressing observed effect size on its estimated population effect size + residual errorLevel 2- regressing each outcome and study estimated population effect size on the study overall population effect size + errorLevel 3 - regressing each study overall population effect size on the mean effect size of all studies + error
The special case of meta-analysis doesn't require the estimation of the residual error at level 1, because it is estimated by the variance of the effect size (e.g. variance of Hedges g), which is given for each outcome and study. In a regular meta-analysis model, the inverse of this variance is used to weight different studies when combining them to an overall mean effect size.
Van den Noortgate provides a SAS script (using Proc mixed) for this purpose. Specifically, he suggested that weighting effects sizes according to their respective weight (1/variance of effect size) , and constraining the residual error term to 1, which should constrain the residual error of each outcome and study to the given variance of this effect size. I attach below the SAS code he provided.

I was wondering whether it's possible to do the same by using R MLM packages. specifically - I'm stuck with how to constrain the level 1 errors to 1.
Thanks a lot!Isaac.


Proc mixed data=D method=reml;         class Study Outcome         model ES= /solution ddfm=satterhwaite;         weight W;         random intercept/sub=Study;         random intercept/sub=Outcome;         params 1 1 1/hold=3run; 		 	   		  
	[[alternative HTML version deleted]]


From mikewlcheung at gmail.com  Sun May 15 14:52:11 2016
From: mikewlcheung at gmail.com (Mike Cheung)
Date: Sun, 15 May 2016 20:52:11 +0800
Subject: [R-sig-ME] Using r for multi-level meta-analysis
In-Reply-To: <DUB128-W4868B211C8F7BD11786BB1DF760@phx.gbl>
References: <DUB128-W4868B211C8F7BD11786BB1DF760@phx.gbl>
Message-ID: <CADF7-FO0kuYoZsc4Eez4C3wzYNry2u_e3HC7A7Ksnz_1kGmM+w@mail.gmail.com>

Hi,

The meta3 function in the metaSEM package has implemented the three-level
meta-analysis using the SEM approach. The metafor package has also
implemented it using the multilevel modelling approach.

Regards,
Mike

On Sunday, 15 May 2016, ????? ?????? <itzikf at outlook.com> wrote:

> Dear R and MLM experts,I'm trying to figure out whether it's possible to
> implement Van den Noortgate (2014) approach for three-level meta-analysis
> in lme4 or nlme. In my data structure I have several outcomes per study,
> and the three levels are: Level 1 - regressing observed effect size on its
> estimated population effect size + residual errorLevel 2- regressing each
> outcome and study estimated population effect size on the study overall
> population effect size + errorLevel 3 - regressing each study overall
> population effect size on the mean effect size of all studies + error
> The special case of meta-analysis doesn't require the estimation of the
> residual error at level 1, because it is estimated by the variance of the
> effect size (e.g. variance of Hedges g), which is given for each outcome
> and study. In a regular meta-analysis model, the inverse of this variance
> is used to weight different studies when combining them to an overall mean
> effect size.
> Van den Noortgate provides a SAS script (using Proc mixed) for this
> purpose. Specifically, he suggested that weighting effects sizes according
> to their respective weight (1/variance of effect size) , and constraining
> the residual error term to 1, which should constrain the residual error of
> each outcome and study to the given variance of this effect size. I attach
> below the SAS code he provided.
>
> I was wondering whether it's possible to do the same by using R MLM
> packages. specifically - I'm stuck with how to constrain the level 1 errors
> to 1.
> Thanks a lot!Isaac.
>
>
> Proc mixed data=D method=reml;         class Study Outcome         model
> ES= /solution ddfm=satterhwaite;         weight W;         random
> intercept/sub=Study;         random intercept/sub=Outcome;         params 1
> 1 1/hold=3run;
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org <javascript:;> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
---------------------------------------------------------------------
 Mike W.L. Cheung               Phone: (65) 6516-3702
 Department of Psychology       Fax:   (65) 6773-1843
 National University of Singapore
 http://courses.nus.edu.sg/course/psycwlm/internet/
---------------------------------------------------------------------

	[[alternative HTML version deleted]]


From wolfgang.viechtbauer at maastrichtuniversity.nl  Sun May 15 16:25:21 2016
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Sun, 15 May 2016 14:25:21 +0000
Subject: [R-sig-ME] Using r for multi-level meta-analysis
In-Reply-To: <CADF7-FO0kuYoZsc4Eez4C3wzYNry2u_e3HC7A7Ksnz_1kGmM+w@mail.gmail.com>
References: <DUB128-W4868B211C8F7BD11786BB1DF760@phx.gbl>
	<CADF7-FO0kuYoZsc4Eez4C3wzYNry2u_e3HC7A7Ksnz_1kGmM+w@mail.gmail.com>
Message-ID: <517c997b3c6f4fed96d891693cfe3932@UM-MAIL3216.unimaas.nl>

You may also find this of interest: http://www.metafor-project.org/doku.php/tips:rma_vs_lm_and_lme

Best,
Wolfgang

-- 
Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry and    
Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200 MD    
Maastricht, The Netherlands | +31 (43) 388-4170 | http://www.wvbauer.com    

> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org] On Behalf Of Mike Cheung
> Sent: Sunday, May 15, 2016 14:52
> To: ????? ??????
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Using r for multi-level meta-analysis
> 
> Hi,
> 
> The meta3 function in the metaSEM package has implemented the three-level
> meta-analysis using the SEM approach. The metafor package has also
> implemented it using the multilevel modelling approach.
> 
> Regards,
> Mike
> 
> On Sunday, 15 May 2016, ????? ?????? <itzikf at outlook.com> wrote:
> 
> > Dear R and MLM experts,I'm trying to figure out whether it's possible
> to
> > implement Van den Noortgate (2014) approach for three-level meta-
> analysis
> > in lme4 or nlme. In my data structure I have several outcomes per
> study,
> > and the three levels are: Level 1 - regressing observed effect size on
> its
> > estimated population effect size + residual errorLevel 2- regressing
> each
> > outcome and study estimated population effect size on the study overall
> > population effect size + errorLevel 3 - regressing each study overall
> > population effect size on the mean effect size of all studies + error
> > The special case of meta-analysis doesn't require the estimation of the
> > residual error at level 1, because it is estimated by the variance of
> the
> > effect size (e.g. variance of Hedges g), which is given for each
> outcome
> > and study. In a regular meta-analysis model, the inverse of this
> variance
> > is used to weight different studies when combining them to an overall
> mean
> > effect size.
> > Van den Noortgate provides a SAS script (using Proc mixed) for this
> > purpose. Specifically, he suggested that weighting effects sizes
> according
> > to their respective weight (1/variance of effect size) , and
> constraining
> > the residual error term to 1, which should constrain the residual error
> of
> > each outcome and study to the given variance of this effect size. I
> attach
> > below the SAS code he provided.
> >
> > I was wondering whether it's possible to do the same by using R MLM
> > packages. specifically - I'm stuck with how to constrain the level 1
> errors
> > to 1.
> > Thanks a lot!Isaac.
> >
> >
> > Proc mixed data=D method=reml;         class Study Outcome
> model
> > ES= /solution ddfm=satterhwaite;         weight W;         random
> > intercept/sub=Study;         random intercept/sub=Outcome;
> params 1
> > 1 1/hold=3run;

From highstat at highstat.com  Mon May 16 08:50:23 2016
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Mon, 16 May 2016 07:50:23 +0100
Subject: [R-sig-ME] Adelaide course: Introduction to mixed modelling
Message-ID: <278942cf-82c2-ec63-21d8-ffe5007ca7e6@highstat.com>

We would like to announce the following statistics course:

Course: Introduction to Linear Mixed Effects Models and GLMM with R. 
Frequentist and Bayesian approaches.
Where:  University of Adelaide, Adelaide, Australia
When:   20-24 June 2016

Course website: http://www.highstat.com/statscourse.htm
Course flyer: 
http://highstat.com/Courses/Flyers/Flyer2016_06Adelaide_GLMM_V2.pdf

Kind regards,

Alain Zuur


-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


	[[alternative HTML version deleted]]


From mikewlcheung at gmail.com  Mon May 16 09:23:36 2016
From: mikewlcheung at gmail.com (Mike Cheung)
Date: Mon, 16 May 2016 15:23:36 +0800
Subject: [R-sig-ME] Using r for multi-level meta-analysis
In-Reply-To: <DUB407-EAS2040B34D55CCFE201BB98F9DF760@phx.gbl>
References: <DUB128-W4868B211C8F7BD11786BB1DF760@phx.gbl>
	<CADF7-FO0kuYoZsc4Eez4C3wzYNry2u_e3HC7A7Ksnz_1kGmM+w@mail.gmail.com>
	<DUB407-EAS2040B34D55CCFE201BB98F9DF760@phx.gbl>
Message-ID: <CADF7-FN_5Jrvn2S9-7WV5gBt__a4jn3TR9dhbs5uv3vfWdAqhA@mail.gmail.com>

Dear Isaac,

The mathematical models are identical in the metaSEM and metafor packages.
The main difference is the implementation--SEM vs. MLM. The meta3 and reml3
in the metaSEM package use ML and REML estimation methods, respectively.

Best,
Mike

On Mon, May 16, 2016 at 1:03 AM, ????? ?????? <itzikf at outlook.com> wrote:

> Dear Mike
>
> Thanks for your response.
> I had the chance to read your paper on multilevel SEM implementation and
> package you've written. I have some experience with MLM, but almost no
> experience with the SEM framework. I was wondering then if you think the
> results of both analyses (using MetaSEM vs. metafor) would be roughly
> similar.  The basic idea is to conduct a meta analysis on
> neuropsychological findings in anxiety patients, while controlling for the
> fact that most studies have more than one measure and each measure more
> than one subscale. Moderators at both study and outcome levels will be
> probed.
>
> Thanks a lot!
> Isaac.
>
> Sent from my iPhone
>
> On 15 May 2016, at 15:52, Mike Cheung <mikewlcheung at gmail.com> wrote:
>
> Hi,
>
> The meta3 function in the metaSEM package has implemented the three-level
> meta-analysis using the SEM approach. The metafor package has also
> implemented it using the multilevel modelling approach.
>
> Regards,
> Mike
>
> On Sunday, 15 May 2016, ????? ?????? <itzikf at outlook.com> wrote:
>
>> Dear R and MLM experts,I'm trying to figure out whether it's possible to
>> implement Van den Noortgate (2014) approach for three-level meta-analysis
>> in lme4 or nlme. In my data structure I have several outcomes per study,
>> and the three levels are: Level 1 - regressing observed effect size on its
>> estimated population effect size + residual errorLevel 2- regressing each
>> outcome and study estimated population effect size on the study overall
>> population effect size + errorLevel 3 - regressing each study overall
>> population effect size on the mean effect size of all studies + error
>> The special case of meta-analysis doesn't require the estimation of the
>> residual error at level 1, because it is estimated by the variance of the
>> effect size (e.g. variance of Hedges g), which is given for each outcome
>> and study. In a regular meta-analysis model, the inverse of this variance
>> is used to weight different studies when combining them to an overall mean
>> effect size.
>> Van den Noortgate provides a SAS script (using Proc mixed) for this
>> purpose. Specifically, he suggested that weighting effects sizes according
>> to their respective weight (1/variance of effect size) , and constraining
>> the residual error term to 1, which should constrain the residual error of
>> each outcome and study to the given variance of this effect size. I attach
>> below the SAS code he provided.
>>
>> I was wondering whether it's possible to do the same by using R MLM
>> packages. specifically - I'm stuck with how to constrain the level 1 errors
>> to 1.
>> Thanks a lot!Isaac.
>>
>>
>> Proc mixed data=D method=reml;         class Study Outcome         model
>> ES= /solution ddfm=satterhwaite;         weight W;         random
>> intercept/sub=Study;         random intercept/sub=Outcome;         params 1
>> 1 1/hold=3run;
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
> --
> ---------------------------------------------------------------------
>  Mike W.L. Cheung               Phone: (65) 6516-3702
>  Department of Psychology       Fax:   (65) 6773-1843
>  National University of Singapore
>  http://courses.nus.edu.sg/course/psycwlm/internet/
> ---------------------------------------------------------------------
>
>

	[[alternative HTML version deleted]]


From sara.fraixedas at helsinki.fi  Mon May 16 13:09:20 2016
From: sara.fraixedas at helsinki.fi (Fraixedas, Sara)
Date: Mon, 16 May 2016 11:09:20 +0000
Subject: [R-sig-ME] Details control options for glmmADMB
Message-ID: <AM4PR07MB1555AA40140B6A8D92E50F1394770@AM4PR07MB1555.eurprd07.prod.outlook.com>

Dear all,

I am a PhD student at the University of Helsinki and I would like to know what exactly the argument "maximum phase" means in the control options for the glmmADMB package. How does it help/contribute to solve convergence problems?

Best wishes,


Sara Fraixedas
Doctoral Student
The Helsinki Lab of Ornithology (HelLO) Finnish Museum of Natural
History P.O. Box 17
00014 University of Helsinki, Finland
Tel. +358-9-19128851

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon May 16 15:54:19 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 16 May 2016 09:54:19 -0400
Subject: [R-sig-ME] Details control options for glmmADMB
In-Reply-To: <AM4PR07MB1555AA40140B6A8D92E50F1394770@AM4PR07MB1555.eurprd07.prod.outlook.com>
References: <AM4PR07MB1555AA40140B6A8D92E50F1394770@AM4PR07MB1555.eurprd07.prod.outlook.com>
Message-ID: <5739D10B.3050403@gmail.com>


ADMB runs its optimization in 'phases' where a progressively larger
subset of the parameters are estimated (in earlier phases, some
parameters are fixed to default values).  If you look in the definition
(TPL) file

file.show(system.file("tpl","glmmadmb.tpl",package="glmmADMB"))

and search for 'phase' you'll see that different phases are used for the
overdispersion parameters, zero-inflation parameters, random effects
standard deviations, random effects correlations.

  That said, I haven't actually seen a context where I've actually
needed to use this feature -- often you could just turn off the relevant
part of the model (e.g. zero-inflation) rather than setting
the maximum phase to a smaller value.

For more about phases, the ADMB manuals are at

http://admb-project.org/documentation/manuals/admb-user-manuals

specifically, the current version is at

http://ftp.admb-project.org/admb-11.4/manuals/admb-11.4.1.pdf

On 16-05-16 07:09 AM, Fraixedas, Sara wrote:
> Dear all,
> 
> I am a PhD student at the University of Helsinki and I would like to
> know what exactly the argument "maximum phase" means in the control
> options for the glmmADMB package. How does it help/contribute to
> solve convergence problems?
> 
> Best wishes,
> 
> 
> Sara Fraixedas Doctoral Student The Helsinki Lab of Ornithology
> (HelLO) Finnish Museum of Natural History P.O. Box 17 00014
> University of Helsinki, Finland Tel. +358-9-19128851
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From j.hadfield at ed.ac.uk  Mon May 16 18:26:11 2016
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 16 May 2016 17:26:11 +0100
Subject: [R-sig-ME] Interpreting fixed effects of mcmcglmm interaction
 and randomisation
In-Reply-To: <DUB124-W46D7062EBC22B90C54F7D9FA740@phx.gbl>
References: <DUB124-W46D7062EBC22B90C54F7D9FA740@phx.gbl>
Message-ID: <5739F4A3.1000903@ed.ac.uk>

Hi,

You should use ~Mort*SexF. At the moment you force the male and female 
intercepts through the origin. You will get four terms; an intercept and 
Mort effect (which are the female intercpet and slope) and a SexM and 
Mort:SexM effect (which are the deviations of the male inetcept and 
slope from the female intercept and slope. The two lines will cross at 
some value of Mort. If we denote the four effects as b1 (intercept), b2 
(Mort), b3 (SexM) and b4 (Mort:SexM) and a value of Mort as x then

female prediction  = b1+b2*x
male prediction  = b1+b3+(b2+b4)*x

and so the value of x when female prediction = male prediction is -b3/b4

You could test whether the posterior distribution of -b3/b4 lies outside 
the range of observed x in which case sexual-dimorophism always 
increases as x (if -b3/b4 is smaller than the minimum of x) increases or 
always increases as x (if -b3/b4 is larger than the maximum of x) 
decreases. If -b3/b4 lies at intermediate values of x the change in 
sexual dimorphism will flip across the range of x.

Cheers,

Jarrod




On 13/05/2016 13:51, Rob Griffin wrote:
> Dear list,
>
> I am trying learn how to model the relationship between an environmental factor and sexual dimorphism using MCMCglmm, and have based analysis on the data in Garratt et al 2015* - a study looking at the relationship between sexual dimorphism in lifespan, and juvenile mortality. They use two populations measured over a number of years, giving cohorts (for which juvenile mortality can be estimated), and information on the identity, lifespan, and sex of each individual. The script below** creates the dummy data I am using to develop the model which is similar to the data set they would have used (though entirely artificial - I have forced a positive relationship between juvenile mortality and male lifespan, while female lifespan is random).  They fit a general linear mixed model to "assess the relationship between survival to the onset of actuarial senescence (dependent variable) and cohort-specific juvenile mortality (independent variable), while including sex as a fixed effect, year and population as random effects, with year nested within population." I have attempted to recreate this analysis (but using MCMCglmm) as the following (where 'Life' is lifespan, 'Mort' is juvenile mortality within the individuals cohort, 'Sex' is the sex of the individual, 'Pop' and 'Year' are the population and year of the individual):
>
>
> mod1 = MCMCglmm(Life ~ Mort:Sex - 1,
> random = ~ Pop:Year,
> rcov = ~units,	
> nitt =   13000, burnin = 3000, thin =   10,
> prior = prior1,
> pr = T,
> family = "gaussian",
> start = list(QUASI = FALSE),
> data = DF1)	
>
>> summary(mod1)
>   Iterations = 3001:12991
>   Thinning interval  = 10
>   Sample size  = 1000
>
>   DIC: 1437.558
>
>   G-structure:  ~Pop:Year
>
>           post.mean l-95% CI u-95% CI eff.samp
> Pop:Year     34.23     19.4     55.2     1000
>
>   R-structure:  ~units
>
>        post.mean l-95% CI u-95% CI eff.samp
> units     4.746    3.946    5.487    909.7
>
>   Location effects: Life ~ Mort:Sex - 1
>
>            post.mean l-95% CI u-95% CI eff.samp  pMCMC
> Mort:SexF     25.17    20.61    30.46     1000 <0.001 ***
> Mort:SexM     43.81    38.82    48.71     1000 <0.001 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>
> Which brings me to my main subject(s) of interest: essentially, how to interpret the fixed effect estimates, given that I am aiming to answer the question, is juvenile mortality related to sexual dimorphism in lifespan?
>
> Going from 'Life ~ Mort -1' to 'Life ~ Mort:Sex -1' improves the fit of the model (DIC 1902 -> 1438), so could I conclude that there is a significant sex-specific effect/interaction with juvenile mortality on lifespan? What do the actual values of the posterior mean (post.mean) tell me - is it just that the Mort:SexM interaction effect is significantly larger than the Mort:SexF effect (CI's of the two estimates do not overlap)? Using Mort*Sex gives SexM and SexF estimates which seem to better reflect the true mean values of the population, where the post.means of Mort is ~0, SexF and SexM are ~12, and the Mort:SexM fixed effect is ~18, which makes me more inclined to think that Mort*Sex is a more appropriate model (but brings up the question what does the post.mean of ~18 for Mort:SexM actually mean?).
>
> I have also done randomisation where I randomise the mortality rates among cohorts for 50 chains, in the 'Mort:Sex' model this results in the Mort:SexF and Mort:SexM estimates remaining similar to the raw data model - does randomisation offer insight in to the relationship between sexual dimorphism and juvenile mortality? Using a model where 'Mort*Sex' is the fixed effect then the randomisation shifts the estimates of Mort:SexM to ~0, and that difference is absorbed in to the SexM fixed effect (because there is sexual dimorphism, but the relationship to juvenile mortality disappears). Could I effectively use this as a kind of significance test (e.g. I do 1000 randomisations, the mean Mort:SexM estimate is> the actual estimate in 11/1000 cases, thus pseudo-p is ~0.011).
>
> Finally, (and on a slightly different topic) I have used 'pr = T' which means I can get posterior distributions for each level of the Pop:Year combination - i.e. a posterior distribution for each cohort. Could this information be used to get an estimate of the sex-specific lifespans for each population? For example, summing the posterior distribution of 'Mort:SexM' with 'Pop:Year.A.1983' would give a distribution of the estimated lifespan for males in population A for the year 1983? I don't think this is the case - as the numbers seem too different from the data - so how could I derive cohort-sex-specific lifespans?
>
> Long story short - I'm looking for some insight on how to correctly define and interpret the fixed effects... Overall I'm inclined to think that 'Mort*Sex' gives the correct specification of the model, and the randomisation shows whether the environmental factor has an effect on sexual dimorphism.
> Thanks - full script below,
> Rob
>
> * Garratt et al 2015, Current Biology "High juvenile mortality is associated with sex-specific adult survival and lifespan in wild roe deer."
>
> **
> #### R-SCRIPT ####
> rm(list=ls())
> set.seed(255)
> library("reshape")
> library("MCMCglmm")
>
> DF1 = data.frame(c(1:320), rep(c("A", "B"), each = 10), rep(1983:1998, each = 20), sample(c("M", "F"), replace = T, size = 320), rnorm(320, 12, 2), rep((1/(1+abs(rnorm(16, 2, 1 )))), each = 20))
> colnames(DF1) = c("ID", "Pop", "Year", "Sex", "Life", "Mort")
>
> # Make SD related to juvenile mortality
> DF1$Life = ifelse(DF1$Sex == "M", DF1$Life + DF1$Mort*18, DF1$Life)
> # Mean zero, unit variance
> DF1$Life0 = (DF1$Life-mean(DF1$Life))/sqrt(var(DF1$Life))
>
> prior1 = list(	G = list(G1 = list(V = 1, nu = 1, alpha.mu = 0, alpha.V = 1000)),
> R = list(V = 1, nu = 0.002))
>
> mod1 = MCMCglmm(Life ~ Mort:Sex - 1,
> random = ~ Pop:Year,
> rcov = ~units,	
> nitt =   13000, burnin = 3000, thin =  10,
> prior = prior1,
> pr = T,
> family = "gaussian",
> start = list(QUASI = FALSE),
> data = DF1)	
>
> summary(mod1)
>
>
>
> ----------------------------------------------------------
>
> Robert M. Griffin
> Postdoctoral Researcher, University of Turku
> www.griffinevo.wordpress.com  		 	   		
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From bbolker at gmail.com  Mon May 16 21:20:17 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 16 May 2016 19:20:17 +0000 (UTC)
Subject: [R-sig-ME] lme with cyclic cubic regression splines
References: <CAOQoCVt0n+0yexN_OuWKvnaYPKiQuNLkccijsnQ7Lcb94ygr3g@mail.gmail.com>
Message-ID: <loom.20160516T211712-365@post.gmane.org>

Gabriela Czanner via R-sig-mixed-models <r-sig-mixed-models at ...> writes:

> 
> Hello list,
> 
> I am trying to fit linear mixed model with fixed effect being cyclic cubic
> regression splines, because my data are defined on a circle, while circle
> is divided into 24 directions. I defined a variable Direction which is
> numeric and has values 1,2,... 24. I receive this error message:
> 
> > out.lme.8=lme(Y~ s(Direction,bs="cc",k=8),
> +               random=~1|PatientID,
> +               data=mydata,na.action=na.omit,method="ML")
> Error in model.frame.default(fixed, dataMix) :
>   invalid type (list) for variable 's(Direction, bs = "cc", k = 8)'
> >
> 
> I wonder if anyone has any suggestion, please?

As Alexandre Villers implicitly pointed out, specifying a smooth
term via s() is restricted to the mgcv:gam(m) and gamm4:gamm functions.
However, if you want to do this in lme (with spline order and knot
positions pre-specified, rather than using penalized regression splines)
it looks like you could use cSplineDes from the mgcv package to set
up the splines yourself.  However, I don't know how smoothly these
will work with the built-in model matrix machinery -- using gamm(4)
will probably be easier. 

  Ben Bolker


From bbolker at gmail.com  Tue May 17 00:41:04 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 16 May 2016 22:41:04 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?Mixed_mutlinomial_regression_for_count_data_?=
	=?utf-8?q?with=09overdisperion_=26_zero-inflation?=
References: <CAMKTVFX_ci_4kFyM2UcXh0uK=QKZGuX70yuL19ZD9oNyhT2BOw@mail.gmail.com>
Message-ID: <loom.20160517T004048-551@post.gmane.org>

St?phanie P?riquet <stephanie.periquet at ...> writes:

> 
> Dear list members,
> 
> First sorry for this very long first post ?

  That's OK.  I'm only going to answer part of it, because it's long.
> 
> I am looking for advises to fit a mixed multinomial regression on count
> data that are overdispersed and zero-inflated. My question is to evaluate
> the effect of season and moonlight on diet composition of bat-eared foxes.
> My dataset is composed of 14 possible prey item, 20 individual foxes
> observed, 4 seasons and a moon illumination index ranging from 0 to 1 by
> 0.1 implements (considered as a continuous variable even if takes only 11
> values). For each unique combination of individual*season*moon, I thus has
> 14 lines, one for the count of each prey item.
> 
> From what I gathered, it would be possible to use 
> a standard glmm model of
> the following form to answer my question (ie a multinomial regression):
> 
> glmer(count~item+item:season+item:moon+offset(logduration)+
> (1+indiv)+(1|obs)+
> (1|id), family=poisson)

  Yes, but I don't know if this will account for the possible dependence
*among* prey types.

> 
> where count is the number of prey of a given type recorded eaten;
> 
> item is the prey type;
> 
> logduration is the log(total time observed for a given combination of
> individual*season*moon);
> 
> obs is a unique id for each combination of individual*season*moon, 
> so each
> obs value regroups 14 lines (one for each prey item) with the same
> individual*season*moon;
> 
> id is a unique id for each line to account for overdispersion (as
> quasi-poisson or negative binomial distributions are not implemented in
> lme4, Elston et al. 2001).

   Seems about right.
   There is glmer.nb now, but you might not want it; it tends to
be slower and more fragile, and you'd still have to deal with
zero-inflation.

> However, they are a lot of zeros in my data i.e. lot of prey items has
> never been observed being eaten for mane combinations of
> individual*season*moon.

  That doesn't *necessarily* mean you need zero-inflation. Large 
numbers of zeros might just reflect low probabilities, not ZI per se.

> Following Ben Bolker wiki (http://glmm.wikidot.com/faq) I summarize that I
> should use of the following methods to answer my question
> 
>    - ?      glmmADMB, with family=nbinom
>    - ?      MCMCglmm, with family=zipoisson
>    - ?      "expectation-maximization (EM) algorithm" in lme4

  Note there's a marginally newer version at 
https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.html

  Another, newer choice is glmmTMB (available on Github) with
family="nbinom2"

> Here come the questions:
 
> 1.  1. Is it correct to assume that I could use the same model
> structure
> (count~item+item:season+item:moon+offset(logduration)+(1+indiv)+(1|obs))
> in glmmADMB or MCMCglmm to answer my question ?

  glmmADMB or glmmTMB, yes: I'm not sure about MCMCglmm
 
> 2.   I then wouldn't need the (1|id) to correct for overdispersion as both
> methods would already account for it, correct?

   That's right, I think.

> 3.   I am totally new to MCMCglmm, so  ...
 
  I'm going to let Jarrod Hadfield, or someone else, answer this one.
> 
> 4.     4.  If I were to use the EM algorithm method, 
> how should the results
> be interpreted?

  The result is composed of two models -- a 'binary' (structural zero vs
non-structural zero) and a 'conditional' (count) part.

From stephanie.periquet at gmail.com  Tue May 17 08:28:42 2016
From: stephanie.periquet at gmail.com (=?UTF-8?B?U3TDqXBoYW5pZSBQw6lyaXF1ZXQ=?=)
Date: Tue, 17 May 2016 08:28:42 +0200
Subject: [R-sig-ME] Mixed mutlinomial regression for count data with
 overdisperion & zero-inflation
In-Reply-To: <loom.20160517T004048-551@post.gmane.org>
References: <CAMKTVFX_ci_4kFyM2UcXh0uK=QKZGuX70yuL19ZD9oNyhT2BOw@mail.gmail.com>
	<loom.20160517T004048-551@post.gmane.org>
Message-ID: <CAMKTVFXZnvS1g-FaNVQ1FQUj5u84S-fd=k4u_6x5PwJUZ2R+bQ@mail.gmail.com>

Hi Ben,

Thank you very much for your answer!

I am aware that a lot of zero doesn't mean zero inflation, but if my
understanding is correct the only way to check for ZI would be to compare
one model take doesn't take it into account and another one that does right?

With the model example I gave (count~item+item:season+item:
moon+offset(logduration)+(1+indiv)+(1|obs)) glmmADMB doesn't run but I'm
gonna dig a bit more into this ans come back t you if I can't figure it out.

Best,
Stephanie

On 17 May 2016 at 00:41, Ben Bolker <bbolker at gmail.com> wrote:

> St?phanie P?riquet <stephanie.periquet at ...> writes:
>
> >
> > Dear list members,
> >
> > First sorry for this very long first post ?
>
>   That's OK.  I'm only going to answer part of it, because it's long.
> >
> > I am looking for advises to fit a mixed multinomial regression on count
> > data that are overdispersed and zero-inflated. My question is to evaluate
> > the effect of season and moonlight on diet composition of bat-eared
> foxes.
> > My dataset is composed of 14 possible prey item, 20 individual foxes
> > observed, 4 seasons and a moon illumination index ranging from 0 to 1 by
> > 0.1 implements (considered as a continuous variable even if takes only 11
> > values). For each unique combination of individual*season*moon, I thus
> has
> > 14 lines, one for the count of each prey item.
> >
> > From what I gathered, it would be possible to use
> > a standard glmm model of
> > the following form to answer my question (ie a multinomial regression):
> >
> > glmer(count~item+item:season+item:moon+offset(logduration)+
> > (1+indiv)+(1|obs)+
> > (1|id), family=poisson)
>
>   Yes, but I don't know if this will account for the possible dependence
> *among* prey types.
>
> >
> > where count is the number of prey of a given type recorded eaten;
> >
> > item is the prey type;
> >
> > logduration is the log(total time observed for a given combination of
> > individual*season*moon);
> >
> > obs is a unique id for each combination of individual*season*moon,
> > so each
> > obs value regroups 14 lines (one for each prey item) with the same
> > individual*season*moon;
> >
> > id is a unique id for each line to account for overdispersion (as
> > quasi-poisson or negative binomial distributions are not implemented in
> > lme4, Elston et al. 2001).
>
>    Seems about right.
>    There is glmer.nb now, but you might not want it; it tends to
> be slower and more fragile, and you'd still have to deal with
> zero-inflation.
>
> > However, they are a lot of zeros in my data i.e. lot of prey items has
> > never been observed being eaten for mane combinations of
> > individual*season*moon.
>
>   That doesn't *necessarily* mean you need zero-inflation. Large
> numbers of zeros might just reflect low probabilities, not ZI per se.
>
> > Following Ben Bolker wiki (http://glmm.wikidot.com/faq) I summarize
> that I
> > should use of the following methods to answer my question
> >
> >    - ?      glmmADMB, with family=nbinom
> >    - ?      MCMCglmm, with family=zipoisson
> >    - ?      "expectation-maximization (EM) algorithm" in lme4
>
>   Note there's a marginally newer version at
> https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.html
>
>   Another, newer choice is glmmTMB (available on Github) with
> family="nbinom2"
>
> > Here come the questions:
>
> > 1.  1. Is it correct to assume that I could use the same model
> > structure
> > (count~item+item:season+item:moon+offset(logduration)+(1+indiv)+(1|obs))
> > in glmmADMB or MCMCglmm to answer my question ?
>
>   glmmADMB or glmmTMB, yes: I'm not sure about MCMCglmm
>
> > 2.   I then wouldn't need the (1|id) to correct for overdispersion as
> both
> > methods would already account for it, correct?
>
>    That's right, I think.
>
> > 3.   I am totally new to MCMCglmm, so  ...
>
>   I'm going to let Jarrod Hadfield, or someone else, answer this one.
> >
> > 4.     4.  If I were to use the EM algorithm method,
> > how should the results
> > be interpreted?
>
>   The result is composed of two models -- a 'binary' (structural zero vs
> non-structural zero) and a 'conditional' (count) part.
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models




-- 
*St?phanie PERIQUET (PhD) * - Bat-eared Fox Research Project
*Dept of Zoology & Entomology*
*University of the Free State, Qwaqwa Campus*
*Cell: +27 79 570 2683*
ResearchGate profile
<https://www.researchgate.net/profile/Stephanie_Periquet>


Kalahari bat-eared foxes on Twitter <https://twitter.com/kal_batearedfox>

	[[alternative HTML version deleted]]


From highstat at highstat.com  Tue May 17 12:08:39 2016
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Tue, 17 May 2016 11:08:39 +0100
Subject: [R-sig-ME] mixed mutlinomial regression for count data with,
 overdisperion & zero-inflation
In-Reply-To: <mailman.1.1463479201.8680.r-sig-mixed-models@r-project.org>
References: <mailman.1.1463479201.8680.r-sig-mixed-models@r-project.org>
Message-ID: <b400a06c-ad29-ee23-8bac-e5be7a6d7077@highstat.com>




> ----------------------------------------------------------------------
>
> Message: 1
> Date: Tue, 17 May 2016 08:28:42 +0200
> From: St?phanie P?riquet <stephanie.periquet at gmail.com>
> To: Ben Bolker <bbolker at gmail.com>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Mixed mutlinomial regression for count data
> 	with overdisperion & zero-inflation
> Message-ID:
> 	<CAMKTVFXZnvS1g-FaNVQ1FQUj5u84S-fd=k4u_6x5PwJUZ2R+bQ at mail.gmail.com>
> Content-Type: text/plain; charset="UTF-8"
>
> Hi Ben,
>
> Thank you very much for your answer!
>
> I am aware that a lot of zero doesn't mean zero inflation, but if my
> understanding is correct the only way to check for ZI would be to compare
> one model take doesn't take it into account and another one that does right?

Incorrect.
1. Calculate the percentage of zeros for your observed data.
2. Fit a model....this can be a model without zero inflation stuff.
3. Simulate 1000 data sets from your model and for each simulated data 
set assess the percentage of zeros.
4. Compare the results in 3 with those in 1.

5. Even nicer....
5a. Plot a simple frequency table for the original data 
(plot(table(Response), type = "h").
5b. Calculate a table() for each of your simulated data.
5c. Calculate the average frequency table.
5d. Compare 5a and 5c.

For a nice example and R code, see:
A protocol for conducting and presenting results of regression-type 
analyses. Zuur & Ieno
doi: 10.1111/2041-210X.12577
Methods in Ecology and Evolution 2016

Comes out in 2 weeks or so.

Kind regards,

Alain


> With the model example I gave (count~item+item:season+item:
> moon+offset(logduration)+(1+indiv)+(1|obs)) glmmADMB doesn't run but I'm
> gonna dig a bit more into this ans come back t you if I can't figure it out.
>
> Best,
> Stephanie
>
> On 17 May 2016 at 00:41, Ben Bolker <bbolker at gmail.com> wrote:
>
>> St?phanie P?riquet <stephanie.periquet at ...> writes:
>>
>>> Dear list members,
>>>
>>> First sorry for this very long first post ?
>>    That's OK.  I'm only going to answer part of it, because it's long.
>>> I am looking for advises to fit a mixed multinomial regression on count
>>> data that are overdispersed and zero-inflated. My question is to evaluate
>>> the effect of season and moonlight on diet composition of bat-eared
>> foxes.
>>> My dataset is composed of 14 possible prey item, 20 individual foxes
>>> observed, 4 seasons and a moon illumination index ranging from 0 to 1 by
>>> 0.1 implements (considered as a continuous variable even if takes only 11
>>> values). For each unique combination of individual*season*moon, I thus
>> has
>>> 14 lines, one for the count of each prey item.
>>>
>>>  From what I gathered, it would be possible to use
>>> a standard glmm model of
>>> the following form to answer my question (ie a multinomial regression):
>>>
>>> glmer(count~item+item:season+item:moon+offset(logduration)+
>>> (1+indiv)+(1|obs)+
>>> (1|id), family=poisson)
>>    Yes, but I don't know if this will account for the possible dependence
>> *among* prey types.
>>
>>> where count is the number of prey of a given type recorded eaten;
>>>
>>> item is the prey type;
>>>
>>> logduration is the log(total time observed for a given combination of
>>> individual*season*moon);
>>>
>>> obs is a unique id for each combination of individual*season*moon,
>>> so each
>>> obs value regroups 14 lines (one for each prey item) with the same
>>> individual*season*moon;
>>>
>>> id is a unique id for each line to account for overdispersion (as
>>> quasi-poisson or negative binomial distributions are not implemented in
>>> lme4, Elston et al. 2001).
>>     Seems about right.
>>     There is glmer.nb now, but you might not want it; it tends to
>> be slower and more fragile, and you'd still have to deal with
>> zero-inflation.
>>
>>> However, they are a lot of zeros in my data i.e. lot of prey items has
>>> never been observed being eaten for mane combinations of
>>> individual*season*moon.
>>    That doesn't *necessarily* mean you need zero-inflation. Large
>> numbers of zeros might just reflect low probabilities, not ZI per se.
>>
>>> Following Ben Bolker wiki (http://glmm.wikidot.com/faq) I summarize
>> that I
>>> should use of the following methods to answer my question
>>>
>>>     - ?      glmmADMB, with family=nbinom
>>>     - ?      MCMCglmm, with family=zipoisson
>>>     - ?      "expectation-maximization (EM) algorithm" in lme4
>>    Note there's a marginally newer version at
>> https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.html
>>
>>    Another, newer choice is glmmTMB (available on Github) with
>> family="nbinom2"
>>
>>> Here come the questions:
>>> 1.  1. Is it correct to assume that I could use the same model
>>> structure
>>> (count~item+item:season+item:moon+offset(logduration)+(1+indiv)+(1|obs))
>>> in glmmADMB or MCMCglmm to answer my question ?
>>    glmmADMB or glmmTMB, yes: I'm not sure about MCMCglmm
>>
>>> 2.   I then wouldn't need the (1|id) to correct for overdispersion as
>> both
>>> methods would already account for it, correct?
>>     That's right, I think.
>>
>>> 3.   I am totally new to MCMCglmm, so  ...
>>    I'm going to let Jarrod Hadfield, or someone else, answer this one.
>>> 4.     4.  If I were to use the EM algorithm method,
>>> how should the results
>>> be interpreted?
>>    The result is composed of two models -- a 'binary' (structural zero vs
>> non-structural zero) and a 'conditional' (count) part.
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>

-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


	[[alternative HTML version deleted]]


From stephanie.periquet at gmail.com  Tue May 17 19:53:45 2016
From: stephanie.periquet at gmail.com (=?UTF-8?B?U3TDqXBoYW5pZSBQw6lyaXF1ZXQ=?=)
Date: Tue, 17 May 2016 19:53:45 +0200
Subject: [R-sig-ME] mixed mutlinomial regression for count data with,
 overdisperion & zero-inflation
In-Reply-To: <b400a06c-ad29-ee23-8bac-e5be7a6d7077@highstat.com>
References: <mailman.1.1463479201.8680.r-sig-mixed-models@r-project.org>
	<b400a06c-ad29-ee23-8bac-e5be7a6d7077@highstat.com>
Message-ID: <CAMKTVFUt1aknwcN6Wq6ecv1uSM+k36PKNC0d5gShY2WorX2=OQ@mail.gmail.com>

Dear Alain,

Thanks for your reply and advices! Will try to do that and wait for your
very timely paper to come out to be sure I did the right thing!

Best,
Stephanie

On 17 May 2016 at 12:08, Highland Statistics Ltd <highstat at highstat.com>
wrote:

>
>
>
> > ----------------------------------------------------------------------
> >
> > Message: 1
> > Date: Tue, 17 May 2016 08:28:42 +0200
> > From: St?phanie P?riquet <stephanie.periquet at gmail.com>
> > To: Ben Bolker <bbolker at gmail.com>
> > Cc: r-sig-mixed-models at r-project.org
> > Subject: Re: [R-sig-ME] Mixed mutlinomial regression for count data
> >       with overdisperion & zero-inflation
> > Message-ID:
> >       <CAMKTVFXZnvS1g-FaNVQ1FQUj5u84S-fd=
> k4u_6x5PwJUZ2R+bQ at mail.gmail.com>
> > Content-Type: text/plain; charset="UTF-8"
> >
> > Hi Ben,
> >
> > Thank you very much for your answer!
> >
> > I am aware that a lot of zero doesn't mean zero inflation, but if my
> > understanding is correct the only way to check for ZI would be to compare
> > one model take doesn't take it into account and another one that does
> right?
>
> Incorrect.
> 1. Calculate the percentage of zeros for your observed data.
> 2. Fit a model....this can be a model without zero inflation stuff.
> 3. Simulate 1000 data sets from your model and for each simulated data
> set assess the percentage of zeros.
> 4. Compare the results in 3 with those in 1.
>
> 5. Even nicer....
> 5a. Plot a simple frequency table for the original data
> (plot(table(Response), type = "h").
> 5b. Calculate a table() for each of your simulated data.
> 5c. Calculate the average frequency table.
> 5d. Compare 5a and 5c.
>
> For a nice example and R code, see:
> A protocol for conducting and presenting results of regression-type
> analyses. Zuur & Ieno
> doi: 10.1111/2041-210X.12577
> Methods in Ecology and Evolution 2016
>
> Comes out in 2 weeks or so.
>
> Kind regards,
>
> Alain
>
>
> > With the model example I gave (count~item+item:season+item:
> > moon+offset(logduration)+(1+indiv)+(1|obs)) glmmADMB doesn't run but I'm
> > gonna dig a bit more into this ans come back t you if I can't figure it
> out.
> >
> > Best,
> > Stephanie
> >
> > On 17 May 2016 at 00:41, Ben Bolker <bbolker at gmail.com> wrote:
> >
> >> St?phanie P?riquet <stephanie.periquet at ...> writes:
> >>
> >>> Dear list members,
> >>>
> >>> First sorry for this very long first post ?
> >>    That's OK.  I'm only going to answer part of it, because it's long.
> >>> I am looking for advises to fit a mixed multinomial regression on count
> >>> data that are overdispersed and zero-inflated. My question is to
> evaluate
> >>> the effect of season and moonlight on diet composition of bat-eared
> >> foxes.
> >>> My dataset is composed of 14 possible prey item, 20 individual foxes
> >>> observed, 4 seasons and a moon illumination index ranging from 0 to 1
> by
> >>> 0.1 implements (considered as a continuous variable even if takes only
> 11
> >>> values). For each unique combination of individual*season*moon, I thus
> >> has
> >>> 14 lines, one for the count of each prey item.
> >>>
> >>>  From what I gathered, it would be possible to use
> >>> a standard glmm model of
> >>> the following form to answer my question (ie a multinomial regression):
> >>>
> >>> glmer(count~item+item:season+item:moon+offset(logduration)+
> >>> (1+indiv)+(1|obs)+
> >>> (1|id), family=poisson)
> >>    Yes, but I don't know if this will account for the possible
> dependence
> >> *among* prey types.
> >>
> >>> where count is the number of prey of a given type recorded eaten;
> >>>
> >>> item is the prey type;
> >>>
> >>> logduration is the log(total time observed for a given combination of
> >>> individual*season*moon);
> >>>
> >>> obs is a unique id for each combination of individual*season*moon,
> >>> so each
> >>> obs value regroups 14 lines (one for each prey item) with the same
> >>> individual*season*moon;
> >>>
> >>> id is a unique id for each line to account for overdispersion (as
> >>> quasi-poisson or negative binomial distributions are not implemented in
> >>> lme4, Elston et al. 2001).
> >>     Seems about right.
> >>     There is glmer.nb now, but you might not want it; it tends to
> >> be slower and more fragile, and you'd still have to deal with
> >> zero-inflation.
> >>
> >>> However, they are a lot of zeros in my data i.e. lot of prey items has
> >>> never been observed being eaten for mane combinations of
> >>> individual*season*moon.
> >>    That doesn't *necessarily* mean you need zero-inflation. Large
> >> numbers of zeros might just reflect low probabilities, not ZI per se.
> >>
> >>> Following Ben Bolker wiki (http://glmm.wikidot.com/faq) I summarize
> >> that I
> >>> should use of the following methods to answer my question
> >>>
> >>>     - ?      glmmADMB, with family=nbinom
> >>>     - ?      MCMCglmm, with family=zipoisson
> >>>     - ?      "expectation-maximization (EM) algorithm" in lme4
> >>    Note there's a marginally newer version at
> >> https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.html
> >>
> >>    Another, newer choice is glmmTMB (available on Github) with
> >> family="nbinom2"
> >>
> >>> Here come the questions:
> >>> 1.  1. Is it correct to assume that I could use the same model
> >>> structure
> >>>
> (count~item+item:season+item:moon+offset(logduration)+(1+indiv)+(1|obs))
> >>> in glmmADMB or MCMCglmm to answer my question ?
> >>    glmmADMB or glmmTMB, yes: I'm not sure about MCMCglmm
> >>
> >>> 2.   I then wouldn't need the (1|id) to correct for overdispersion as
> >> both
> >>> methods would already account for it, correct?
> >>     That's right, I think.
> >>
> >>> 3.   I am totally new to MCMCglmm, so  ...
> >>    I'm going to let Jarrod Hadfield, or someone else, answer this one.
> >>> 4.     4.  If I were to use the EM algorithm method,
> >>> how should the results
> >>> be interpreted?
> >>    The result is composed of two models -- a 'binary' (structural zero
> vs
> >> non-structural zero) and a 'conditional' (count) part.
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
> >
>
> --
> Dr. Alain F. Zuur
>
> First author of:
> 1. Beginner's Guide to GAMM with R (2014).
> 2. Beginner's Guide to GLM and GLMM with R (2013).
> 3. Beginner's Guide to GAM with R (2012).
> 4. Zero Inflated Models and GLMM with R (2012).
> 5. A Beginner's Guide to R (2009).
> 6. Mixed effects models and extensions in ecology with R (2009).
> 7. Analysing Ecological Data (2007).
>
> Highland Statistics Ltd.
> 9 St Clair Wynd
> UK - AB41 6DZ Newburgh
> Tel:   0044 1358 788177
> Email: highstat at highstat.com
> URL:   www.highstat.com
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
*St?phanie PERIQUET (PhD) * - Bat-eared Fox Research Project
*Dept of Zoology & Entomology*
*University of the Free State, Qwaqwa Campus*
*Cell: +27 79 570 2683*
ResearchGate profile
<https://www.researchgate.net/profile/Stephanie_Periquet>


Kalahari bat-eared foxes on Twitter <https://twitter.com/kal_batearedfox>

	[[alternative HTML version deleted]]


From highstat at highstat.com  Tue May 17 20:21:26 2016
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Tue, 17 May 2016 19:21:26 +0100
Subject: [R-sig-ME] mixed mutlinomial regression for count data with,
 overdisperion & zero-inflation
In-Reply-To: <CAMKTVFUt1aknwcN6Wq6ecv1uSM+k36PKNC0d5gShY2WorX2=OQ@mail.gmail.com>
References: <mailman.1.1463479201.8680.r-sig-mixed-models@r-project.org>
	<b400a06c-ad29-ee23-8bac-e5be7a6d7077@highstat.com>
	<CAMKTVFUt1aknwcN6Wq6ecv1uSM+k36PKNC0d5gShY2WorX2=OQ@mail.gmail.com>
Message-ID: <87c2fa6b-5778-3e72-63e9-21fce2da97af@highstat.com>



On 17/05/2016 18:53, St?phanie P?riquet wrote:
> Dear Alain,
>
> Thanks for your reply and advices! Will try to do that and wait for 
> your very timely paper to come out to be sure I did the right thing!
>

Stephanie,

Although it does not cover multinomial models directly, this one may be 
of use as well:

Beginner's Guide to Zero-Inflated Models with R (2016). Zuur AF and Ieno EN
http://highstat.com/BGZIM.htm

Sorry for the self-references.

Kind regards,

Alain

> Best,
> Stephanie
>
> On 17 May 2016 at 12:08, Highland Statistics Ltd 
> <highstat at highstat.com <mailto:highstat at highstat.com>> wrote:
>
>
>
>
>     >
>     ----------------------------------------------------------------------
>     >
>     > Message: 1
>     > Date: Tue, 17 May 2016 08:28:42 +0200
>     > From: St?phanie P?riquet <stephanie.periquet at gmail.com
>     <mailto:stephanie.periquet at gmail.com>>
>     > To: Ben Bolker <bbolker at gmail.com <mailto:bbolker at gmail.com>>
>     > Cc: r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>     > Subject: Re: [R-sig-ME] Mixed mutlinomial regression for count data
>     >       with overdisperion & zero-inflation
>     > Message-ID:
>     >     
>      <CAMKTVFXZnvS1g-FaNVQ1FQUj5u84S-fd=k4u_6x5PwJUZ2R+bQ at mail.gmail.com
>     <mailto:k4u_6x5PwJUZ2R%2BbQ at mail.gmail.com>>
>     > Content-Type: text/plain; charset="UTF-8"
>     >
>     > Hi Ben,
>     >
>     > Thank you very much for your answer!
>     >
>     > I am aware that a lot of zero doesn't mean zero inflation, but if my
>     > understanding is correct the only way to check for ZI would be
>     to compare
>     > one model take doesn't take it into account and another one that
>     does right?
>
>     Incorrect.
>     1. Calculate the percentage of zeros for your observed data.
>     2. Fit a model....this can be a model without zero inflation stuff.
>     3. Simulate 1000 data sets from your model and for each simulated data
>     set assess the percentage of zeros.
>     4. Compare the results in 3 with those in 1.
>
>     5. Even nicer....
>     5a. Plot a simple frequency table for the original data
>     (plot(table(Response), type = "h").
>     5b. Calculate a table() for each of your simulated data.
>     5c. Calculate the average frequency table.
>     5d. Compare 5a and 5c.
>
>     For a nice example and R code, see:
>     A protocol for conducting and presenting results of regression-type
>     analyses. Zuur & Ieno
>     doi: 10.1111/2041-210X.12577
>     Methods in Ecology and Evolution 2016
>
>     Comes out in 2 weeks or so.
>
>     Kind regards,
>
>     Alain
>
>
>     > With the model example I gave (count~item+item:season+item:
>     > moon+offset(logduration)+(1+indiv)+(1|obs)) glmmADMB doesn't run
>     but I'm
>     > gonna dig a bit more into this ans come back t you if I can't
>     figure it out.
>     >
>     > Best,
>     > Stephanie
>     >
>     > On 17 May 2016 at 00:41, Ben Bolker <bbolker at gmail.com
>     <mailto:bbolker at gmail.com>> wrote:
>     >
>     >> St?phanie P?riquet <stephanie.periquet at ...> writes:
>     >>
>     >>> Dear list members,
>     >>>
>     >>> First sorry for this very long first post ?
>     >>    That's OK.  I'm only going to answer part of it, because
>     it's long.
>     >>> I am looking for advises to fit a mixed multinomial regression
>     on count
>     >>> data that are overdispersed and zero-inflated. My question is
>     to evaluate
>     >>> the effect of season and moonlight on diet composition of
>     bat-eared
>     >> foxes.
>     >>> My dataset is composed of 14 possible prey item, 20 individual
>     foxes
>     >>> observed, 4 seasons and a moon illumination index ranging from
>     0 to 1 by
>     >>> 0.1 implements (considered as a continuous variable even if
>     takes only 11
>     >>> values). For each unique combination of
>     individual*season*moon, I thus
>     >> has
>     >>> 14 lines, one for the count of each prey item.
>     >>>
>     >>>  From what I gathered, it would be possible to use
>     >>> a standard glmm model of
>     >>> the following form to answer my question (ie a multinomial
>     regression):
>     >>>
>     >>> glmer(count~item+item:season+item:moon+offset(logduration)+
>     >>> (1+indiv)+(1|obs)+
>     >>> (1|id), family=poisson)
>     >>    Yes, but I don't know if this will account for the possible
>     dependence
>     >> *among* prey types.
>     >>
>     >>> where count is the number of prey of a given type recorded eaten;
>     >>>
>     >>> item is the prey type;
>     >>>
>     >>> logduration is the log(total time observed for a given
>     combination of
>     >>> individual*season*moon);
>     >>>
>     >>> obs is a unique id for each combination of individual*season*moon,
>     >>> so each
>     >>> obs value regroups 14 lines (one for each prey item) with the same
>     >>> individual*season*moon;
>     >>>
>     >>> id is a unique id for each line to account for overdispersion (as
>     >>> quasi-poisson or negative binomial distributions are not
>     implemented in
>     >>> lme4, Elston et al. 2001).
>     >>     Seems about right.
>     >>     There is glmer.nb now, but you might not want it; it tends to
>     >> be slower and more fragile, and you'd still have to deal with
>     >> zero-inflation.
>     >>
>     >>> However, they are a lot of zeros in my data i.e. lot of prey
>     items has
>     >>> never been observed being eaten for mane combinations of
>     >>> individual*season*moon.
>     >>    That doesn't *necessarily* mean you need zero-inflation. Large
>     >> numbers of zeros might just reflect low probabilities, not ZI
>     per se.
>     >>
>     >>> Following Ben Bolker wiki (http://glmm.wikidot.com/faq) I
>     summarize
>     >> that I
>     >>> should use of the following methods to answer my question
>     >>>
>     >>>     - ?      glmmADMB, with family=nbinom
>     >>>     - ?      MCMCglmm, with family=zipoisson
>     >>>     - ?      "expectation-maximization (EM) algorithm" in lme4
>     >>    Note there's a marginally newer version at
>     >> https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.html
>     >>
>     >>    Another, newer choice is glmmTMB (available on Github) with
>     >> family="nbinom2"
>     >>
>     >>> Here come the questions:
>     >>> 1.  1. Is it correct to assume that I could use the same model
>     >>> structure
>     >>>
>     (count~item+item:season+item:moon+offset(logduration)+(1+indiv)+(1|obs))
>     >>> in glmmADMB or MCMCglmm to answer my question ?
>     >>    glmmADMB or glmmTMB, yes: I'm not sure about MCMCglmm
>     >>
>     >>> 2.   I then wouldn't need the (1|id) to correct for
>     overdispersion as
>     >> both
>     >>> methods would already account for it, correct?
>     >>     That's right, I think.
>     >>
>     >>> 3.   I am totally new to MCMCglmm, so  ...
>     >>    I'm going to let Jarrod Hadfield, or someone else, answer
>     this one.
>     >>> 4.     4.  If I were to use the EM algorithm method,
>     >>> how should the results
>     >>> be interpreted?
>     >>    The result is composed of two models -- a 'binary'
>     (structural zero vs
>     >> non-structural zero) and a 'conditional' (count) part.
>     >> _______________________________________________
>     >> R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >
>     >
>     >
>
>     --
>     Dr. Alain F. Zuur
>
>     First author of:
>     1. Beginner's Guide to GAMM with R (2014).
>     2. Beginner's Guide to GLM and GLMM with R (2013).
>     3. Beginner's Guide to GAM with R (2012).
>     4. Zero Inflated Models and GLMM with R (2012).
>     5. A Beginner's Guide to R (2009).
>     6. Mixed effects models and extensions in ecology with R (2009).
>     7. Analysing Ecological Data (2007).
>
>     Highland Statistics Ltd.
>     9 St Clair Wynd
>     UK - AB41 6DZ Newburgh
>     Tel:   0044 1358 788177
>     Email: highstat at highstat.com <mailto:highstat at highstat.com>
>     URL: www.highstat.com <http://www.highstat.com>
>
>
>             [[alternative HTML version deleted]]
>
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
>
> -- 
> *St?phanie PERIQUET (PhD) * - Bat-eared Fox Research Project
> /Dept of Zoology & Entomology/
> /University of the Free State, Qwaqwa Campus/
> *Cell: +27 79 570 2683*
> ResearchGate profile 
> <https://www.researchgate.net/profile/Stephanie_Periquet>
>
>
> Kalahari bat-eared foxes on Twitter <https://twitter.com/kal_batearedfox>

-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


	[[alternative HTML version deleted]]


From c.acharya at duke.edu  Tue May 17 20:23:04 2016
From: c.acharya at duke.edu (Chaitanya Acharya)
Date: Tue, 17 May 2016 18:23:04 +0000
Subject: [R-sig-ME] lmer() fit
Message-ID: <706EC88D-DFAC-4F91-B69C-6594EEBB595C@duke.edu>

Hi,
Apologies for a very non-specific question. Any idea how many random effects could lmer() reasonably fit? I am thinking of a situation where I want to fit ~20k random effects with ~250k observations. What kind of issues should I foresee?

Thanks,
Chuck

From bbolker at gmail.com  Tue May 17 21:43:07 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 17 May 2016 15:43:07 -0400
Subject: [R-sig-ME] lmer() fit
In-Reply-To: <706EC88D-DFAC-4F91-B69C-6594EEBB595C@duke.edu>
References: <706EC88D-DFAC-4F91-B69C-6594EEBB595C@duke.edu>
Message-ID: <573B744B.7050803@gmail.com>


  This doesn't seem like a big deal.  The following fit takes about 4.5
seconds on my Macbook Pro.

library(lme4)
set.seed(101)
nRE <- 20000
nobs <- 250000
dd <- data.frame(f=sample(1:nRE,size=nobs,replace=TRUE),
                 x=rnorm(nobs))
dd$y <- simulate(~x+(1|f),
         newparams=list(beta=c(1,2),theta=1,sigma=1),
         newdata=dd,
         family=gaussian,
         seed=102)[[1]]
system.time(fit <- lmer(y~x+(1|f),
              data=dd))
fixef(fit)
VarCorr(fit)


   If you have lots of fixed effects or very complex random effects,
things could get a bit slower.  If you have a *much* bigger problem than
this -- or if you're going to want to this sort of thing thousands of
times in a row and 4.5 seconds is too slow -- you might want to talk to
Doug Bates about the MixedModels package for Julia ...


On 16-05-17 02:23 PM, Chaitanya Acharya wrote:
> Hi, Apologies for a very non-specific question. Any idea how many
> random effects could lmer() reasonably fit? I am thinking of a
> situation where I want to fit ~20k random effects with ~250k
> observations. What kind of issues should I foresee?
> 
> Thanks, Chuck _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From dianxiangan32 at sina.cn  Wed May 18 05:07:36 2016
From: dianxiangan32 at sina.cn (=?GBK?B?zfXuow==?=)
Date: Wed, 18 May 2016 11:07:36 +0800
Subject: [R-sig-ME] e-book
Message-ID: <20160518030736.BEE17A800D1@webmail.sinamail.sina.com.cn>

Hi,
I found a good e-book: lme4: mixed-effects modeling with r
If there is a place to buy it?
--------------------------------


	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed May 18 08:10:48 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 17 May 2016 23:10:48 -0700
Subject: [R-sig-ME] e-book
In-Reply-To: <20160518030736.BEE17A800D1@webmail.sinamail.sina.com.cn>
References: <20160518030736.BEE17A800D1@webmail.sinamail.sina.com.cn>
Message-ID: <8942EC55-B944-4F30-A7F1-9A98ACC9910E@dcn.davis.ca.us>

Amazon in paperback.  ISBN 1441903178
-- 
Sent from my phone. Please excuse my brevity.

On May 17, 2016 8:07:36 PM PDT, "??" <dianxiangan32 at sina.cn> wrote:
>Hi,
>I found a good e-book: lme4: mixed-effects modeling with r
>If there is a place to buy it?
>--------------------------------
>
>
>	[[alternative HTML version deleted]]
>
>_______________________________________________
>R-sig-mixed-models at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From stephanie.periquet at gmail.com  Wed May 18 09:26:56 2016
From: stephanie.periquet at gmail.com (=?UTF-8?B?U3TDqXBoYW5pZSBQw6lyaXF1ZXQ=?=)
Date: Wed, 18 May 2016 09:26:56 +0200
Subject: [R-sig-ME] mixed mutlinomial regression for count data with,
 overdisperion & zero-inflation
In-Reply-To: <87c2fa6b-5778-3e72-63e9-21fce2da97af@highstat.com>
References: <mailman.1.1463479201.8680.r-sig-mixed-models@r-project.org>
	<b400a06c-ad29-ee23-8bac-e5be7a6d7077@highstat.com>
	<CAMKTVFUt1aknwcN6Wq6ecv1uSM+k36PKNC0d5gShY2WorX2=OQ@mail.gmail.com>
	<87c2fa6b-5778-3e72-63e9-21fce2da97af@highstat.com>
Message-ID: <CAMKTVFXaHmAi+YCBpKdZO58ciwc9GQKAMrf--n_aCKqgGU2LEg@mail.gmail.com>

Yeah thanks Alain, I'm definitely planning to buy this book!

So I looked at the zeros in my data abased on you advice and I did the
following:
mod<-glmer(count~item+item:season+item:moon+item:season:moon+(1|indiv/obs)+(1|id),family=poisson,nAGQ=0,data=diet3)
z<-simulate(mod,nsim=1000)

For the original data I have 69.3% of zeros while the average over the 1000
simulations is 63.5%.Is there a way to statistically compare these 2
values? Or could you say that these 2 figures are not very different and
then zero inflation models might not be necessary?

Best,
Stephanie

On 17 May 2016 at 20:21, Highland Statistics Ltd <highstat at highstat.com>
wrote:

>
>
> On 17/05/2016 18:53, St?phanie P?riquet wrote:
>
> Dear Alain,
>
> Thanks for your reply and advices! Will try to do that and wait for your
> very timely paper to come out to be sure I did the right thing!
>
>
> Stephanie,
>
> Although it does not cover multinomial models directly, this one may be of
> use as well:
>
> Beginner's Guide to Zero-Inflated Models with R (2016). Zuur AF and Ieno EN
> http://highstat.com/BGZIM.htm
>
> Sorry for the self-references.
>
> Kind regards,
>
> Alain
>
>
> Best,
> Stephanie
>
> On 17 May 2016 at 12:08, Highland Statistics Ltd <highstat at highstat.com>
> wrote:
>
>>
>>
>>
>> > ----------------------------------------------------------------------
>> >
>> > Message: 1
>> > Date: Tue, 17 May 2016 08:28:42 +0200
>> > From: St?phanie P?riquet <stephanie.periquet at gmail.com>
>> > To: Ben Bolker <bbolker at gmail.com>
>> > Cc: r-sig-mixed-models at r-project.org
>> > Subject: Re: [R-sig-ME] Mixed mutlinomial regression for count data
>> >       with overdisperion & zero-inflation
>> > Message-ID:
>> >       <CAMKTVFXZnvS1g-FaNVQ1FQUj5u84S-fd=
>> <k4u_6x5PwJUZ2R%2BbQ at mail.gmail.com>k4u_6x5PwJUZ2R+bQ at mail.gmail.com>
>> > Content-Type: text/plain; charset="UTF-8"
>> >
>> > Hi Ben,
>> >
>> > Thank you very much for your answer!
>> >
>> > I am aware that a lot of zero doesn't mean zero inflation, but if my
>> > understanding is correct the only way to check for ZI would be to
>> compare
>> > one model take doesn't take it into account and another one that does
>> right?
>>
>> Incorrect.
>> 1. Calculate the percentage of zeros for your observed data.
>> 2. Fit a model....this can be a model without zero inflation stuff.
>> 3. Simulate 1000 data sets from your model and for each simulated data
>> set assess the percentage of zeros.
>> 4. Compare the results in 3 with those in 1.
>>
>> 5. Even nicer....
>> 5a. Plot a simple frequency table for the original data
>> (plot(table(Response), type = "h").
>> 5b. Calculate a table() for each of your simulated data.
>> 5c. Calculate the average frequency table.
>> 5d. Compare 5a and 5c.
>>
>> For a nice example and R code, see:
>> A protocol for conducting and presenting results of regression-type
>> analyses. Zuur & Ieno
>> doi: 10.1111/2041-210X.12577
>> Methods in Ecology and Evolution 2016
>>
>> Comes out in 2 weeks or so.
>>
>> Kind regards,
>>
>> Alain
>>
>>
>> > With the model example I gave (count~item+item:season+item:
>> > moon+offset(logduration)+(1+indiv)+(1|obs)) glmmADMB doesn't run but I'm
>> > gonna dig a bit more into this ans come back t you if I can't figure it
>> out.
>> >
>> > Best,
>> > Stephanie
>> >
>> > On 17 May 2016 at 00:41, Ben Bolker < <bbolker at gmail.com>
>> bbolker at gmail.com> wrote:
>> >
>> >> St?phanie P?riquet <stephanie.periquet at ...> <stephanie.periquet at ...>
>> writes:
>> >>
>> >>> Dear list members,
>> >>>
>> >>> First sorry for this very long first post ?
>> >>    That's OK.  I'm only going to answer part of it, because it's long.
>> >>> I am looking for advises to fit a mixed multinomial regression on
>> count
>> >>> data that are overdispersed and zero-inflated. My question is to
>> evaluate
>> >>> the effect of season and moonlight on diet composition of bat-eared
>> >> foxes.
>> >>> My dataset is composed of 14 possible prey item, 20 individual foxes
>> >>> observed, 4 seasons and a moon illumination index ranging from 0 to 1
>> by
>> >>> 0.1 implements (considered as a continuous variable even if takes
>> only 11
>> >>> values). For each unique combination of individual*season*moon, I thus
>> >> has
>> >>> 14 lines, one for the count of each prey item.
>> >>>
>> >>>  From what I gathered, it would be possible to use
>> >>> a standard glmm model of
>> >>> the following form to answer my question (ie a multinomial
>> regression):
>> >>>
>> >>> glmer(count~item+item:season+item:moon+offset(logduration)+
>> >>> (1+indiv)+(1|obs)+
>> >>> (1|id), family=poisson)
>> >>    Yes, but I don't know if this will account for the possible
>> dependence
>> >> *among* prey types.
>> >>
>> >>> where count is the number of prey of a given type recorded eaten;
>> >>>
>> >>> item is the prey type;
>> >>>
>> >>> logduration is the log(total time observed for a given combination of
>> >>> individual*season*moon);
>> >>>
>> >>> obs is a unique id for each combination of individual*season*moon,
>> >>> so each
>> >>> obs value regroups 14 lines (one for each prey item) with the same
>> >>> individual*season*moon;
>> >>>
>> >>> id is a unique id for each line to account for overdispersion (as
>> >>> quasi-poisson or negative binomial distributions are not implemented
>> in
>> >>> lme4, Elston et al. 2001).
>> >>     Seems about right.
>> >>     There is glmer.nb now, but you might not want it; it tends to
>> >> be slower and more fragile, and you'd still have to deal with
>> >> zero-inflation.
>> >>
>> >>> However, they are a lot of zeros in my data i.e. lot of prey items has
>> >>> never been observed being eaten for mane combinations of
>> >>> individual*season*moon.
>> >>    That doesn't *necessarily* mean you need zero-inflation. Large
>> >> numbers of zeros might just reflect low probabilities, not ZI per se.
>> >>
>> >>> Following Ben Bolker wiki ( <http://glmm.wikidot.com/faq>
>> http://glmm.wikidot.com/faq) I summarize
>> >> that I
>> >>> should use of the following methods to answer my question
>> >>>
>> >>>     - ?      glmmADMB, with family=nbinom
>> >>>     - ?      MCMCglmm, with family=zipoisson
>> >>>     - ?      "expectation-maximization (EM) algorithm" in lme4
>> >>    Note there's a marginally newer version at
>> >> https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.html
>> >>
>> >>    Another, newer choice is glmmTMB (available on Github) with
>> >> family="nbinom2"
>> >>
>> >>> Here come the questions:
>> >>> 1.  1. Is it correct to assume that I could use the same model
>> >>> structure
>> >>>
>> (count~item+item:season+item:moon+offset(logduration)+(1+indiv)+(1|obs))
>> >>> in glmmADMB or MCMCglmm to answer my question ?
>> >>    glmmADMB or glmmTMB, yes: I'm not sure about MCMCglmm
>> >>
>> >>> 2.   I then wouldn't need the (1|id) to correct for overdispersion as
>> >> both
>> >>> methods would already account for it, correct?
>> >>     That's right, I think.
>> >>
>> >>> 3.   I am totally new to MCMCglmm, so  ...
>> >>    I'm going to let Jarrod Hadfield, or someone else, answer this one.
>> >>> 4.     4.  If I were to use the EM algorithm method,
>> >>> how should the results
>> >>> be interpreted?
>> >>    The result is composed of two models -- a 'binary' (structural zero
>> vs
>> >> non-structural zero) and a 'conditional' (count) part.
>> >> _______________________________________________
>> >> R-sig-mixed-models at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>> >
>> >
>>
>> --
>> Dr. Alain F. Zuur
>>
>> First author of:
>> 1. Beginner's Guide to GAMM with R (2014).
>> 2. Beginner's Guide to GLM and GLMM with R (2013).
>> 3. Beginner's Guide to GAM with R (2012).
>> 4. Zero Inflated Models and GLMM with R (2012).
>> 5. A Beginner's Guide to R (2009).
>> 6. Mixed effects models and extensions in ecology with R (2009).
>> 7. Analysing Ecological Data (2007).
>>
>> Highland Statistics Ltd.
>> 9 St Clair Wynd
>> UK - AB41 6DZ Newburgh
>> Tel:   0044 1358 788177
>> Email: highstat at highstat.com
>> URL:   www.highstat.com
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
> *St?phanie PERIQUET (PhD) * - Bat-eared Fox Research Project
> *Dept of Zoology & Entomology*
> *University of the Free State, Qwaqwa Campus*
> *Cell: +27 79 570 2683*
> ResearchGate profile
> <https://www.researchgate.net/profile/Stephanie_Periquet>
>
>
> Kalahari bat-eared foxes on Twitter <https://twitter.com/kal_batearedfox>
>
>
> --
> Dr. Alain F. Zuur
>
> First author of:
> 1. Beginner's Guide to GAMM with R (2014).
> 2. Beginner's Guide to GLM and GLMM with R (2013).
> 3. Beginner's Guide to GAM with R (2012).
> 4. Zero Inflated Models and GLMM with R (2012).
> 5. A Beginner's Guide to R (2009).
> 6. Mixed effects models and extensions in ecology with R (2009).
> 7. Analysing Ecological Data (2007).
>
> Highland Statistics Ltd.
> 9 St Clair Wynd
> UK - AB41 6DZ Newburgh
> Tel:   0044 1358 788177
> Email: highstat at highstat.com
> URL:   www.highstat.com
>
>


-- 
*St?phanie PERIQUET (PhD) * - Bat-eared Fox Research Project
*Dept of Zoology & Entomology*
*University of the Free State, Qwaqwa Campus*
*Cell: +27 79 570 2683*
ResearchGate profile
<https://www.researchgate.net/profile/Stephanie_Periquet>


Kalahari bat-eared foxes on Twitter <https://twitter.com/kal_batearedfox>

	[[alternative HTML version deleted]]


From highstat at highstat.com  Wed May 18 09:39:53 2016
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Wed, 18 May 2016 08:39:53 +0100
Subject: [R-sig-ME] mixed mutlinomial regression for count data with,
 overdisperion & zero-inflation
In-Reply-To: <CAMKTVFXaHmAi+YCBpKdZO58ciwc9GQKAMrf--n_aCKqgGU2LEg@mail.gmail.com>
References: <mailman.1.1463479201.8680.r-sig-mixed-models@r-project.org>
	<b400a06c-ad29-ee23-8bac-e5be7a6d7077@highstat.com>
	<CAMKTVFUt1aknwcN6Wq6ecv1uSM+k36PKNC0d5gShY2WorX2=OQ@mail.gmail.com>
	<87c2fa6b-5778-3e72-63e9-21fce2da97af@highstat.com>
	<CAMKTVFXaHmAi+YCBpKdZO58ciwc9GQKAMrf--n_aCKqgGU2LEg@mail.gmail.com>
Message-ID: <cd6f436d-742a-6c50-5268-0ddd43bdf24e@highstat.com>



On 18/05/2016 08:26, St?phanie P?riquet wrote:
> Yeah thanks Alain, I'm definitely planning to buy this book!
>
> So I looked at the zeros in my data abased on you advice and I did the 
> following:
> mod<-glmer(count~item+item:season+item:moon+item:season:moon+(1|indiv/obs)+(1|id),family=poisson,nAGQ=0,data=diet3)
> z<-simulate(mod,nsim=1000)
>
> For the original data I have 69.3% of zeros while the average over the 
> 1000 simulations is 63.5%.Is there a way to statistically compare 
> these 2 values? Or could you say that these 2 figures are not very 
> different and then zero inflation models might not be necessary?
>

Stephanie,

Make a histogram of the 1000 values of the percentages of zeros....and 
present the 69.3% as a big blue/red dot. If the dot for your observed 
data is in the tails you have a problem.

I don't see the point of a test in your case. Such a simulation is close 
to bootstrapping...so I guess you can come up with a test somehow. If 
you do this type of analysis in a Bayesian framework it is often (and 
confusingly) called a Bayesian p-value (counting how often the simulated 
value is larger than your observed one).

I would just go for the histogram...seems you are lucky.

Alain






> Best,
> Stephanie
>
> On 17 May 2016 at 20:21, Highland Statistics Ltd 
> <highstat at highstat.com <mailto:highstat at highstat.com>> wrote:
>
>
>
>     On 17/05/2016 18:53, St?phanie P?riquet wrote:
>>     Dear Alain,
>>
>>     Thanks for your reply and advices! Will try to do that and wait
>>     for your very timely paper to come out to be sure I did the right
>>     thing!
>>
>
>     Stephanie,
>
>     Although it does not cover multinomial models directly, this one
>     may be of use as well:
>
>     Beginner's Guide to Zero-Inflated Models with R (2016). Zuur AF
>     and Ieno EN
>     http://highstat.com/BGZIM.htm
>
>     Sorry for the self-references.
>
>     Kind regards,
>
>     Alain
>
>
>>     Best,
>>     Stephanie
>>
>>     On 17 May 2016 at 12:08, Highland Statistics Ltd
>>     <highstat at highstat.com <mailto:highstat at highstat.com>> wrote:
>>
>>
>>
>>
>>         >
>>         ----------------------------------------------------------------------
>>         >
>>         > Message: 1
>>         > Date: Tue, 17 May 2016 08:28:42 +0200
>>         > From: St?phanie P?riquet <stephanie.periquet at gmail.com
>>         <mailto:stephanie.periquet at gmail.com>>
>>         > To: Ben Bolker <bbolker at gmail.com <mailto:bbolker at gmail.com>>
>>         > Cc: r-sig-mixed-models at r-project.org
>>         <mailto:r-sig-mixed-models at r-project.org>
>>         > Subject: Re: [R-sig-ME] Mixed mutlinomial regression for
>>         count data
>>         >       with overdisperion & zero-inflation
>>         > Message-ID:
>>         >
>>          <CAMKTVFXZnvS1g-FaNVQ1FQUj5u84S-fd=k4u_6x5PwJUZ2R+bQ at mail.gmail.com
>>         <mailto:k4u_6x5PwJUZ2R+bQ at mail.gmail.com>>
>>         > Content-Type: text/plain; charset="UTF-8"
>>         >
>>         > Hi Ben,
>>         >
>>         > Thank you very much for your answer!
>>         >
>>         > I am aware that a lot of zero doesn't mean zero inflation,
>>         but if my
>>         > understanding is correct the only way to check for ZI would
>>         be to compare
>>         > one model take doesn't take it into account and another one
>>         that does right?
>>
>>         Incorrect.
>>         1. Calculate the percentage of zeros for your observed data.
>>         2. Fit a model....this can be a model without zero inflation
>>         stuff.
>>         3. Simulate 1000 data sets from your model and for each
>>         simulated data
>>         set assess the percentage of zeros.
>>         4. Compare the results in 3 with those in 1.
>>
>>         5. Even nicer....
>>         5a. Plot a simple frequency table for the original data
>>         (plot(table(Response), type = "h").
>>         5b. Calculate a table() for each of your simulated data.
>>         5c. Calculate the average frequency table.
>>         5d. Compare 5a and 5c.
>>
>>         For a nice example and R code, see:
>>         A protocol for conducting and presenting results of
>>         regression-type
>>         analyses. Zuur & Ieno
>>         doi: 10.1111/2041-210X.12577
>>         Methods in Ecology and Evolution 2016
>>
>>         Comes out in 2 weeks or so.
>>
>>         Kind regards,
>>
>>         Alain
>>
>>
>>         > With the model example I gave (count~item+item:season+item:
>>         > moon+offset(logduration)+(1+indiv)+(1|obs)) glmmADMB
>>         doesn't run but I'm
>>         > gonna dig a bit more into this ans come back t you if I
>>         can't figure it out.
>>         >
>>         > Best,
>>         > Stephanie
>>         >
>>         > On 17 May 2016 at 00:41, Ben Bolker <bbolker at gmail.com
>>         <mailto:bbolker at gmail.com>> wrote:
>>         >
>>         >> St?phanie P?riquet <stephanie.periquet at ...>
>>         <mailto:stephanie.periquet at ...> writes:
>>         >>
>>         >>> Dear list members,
>>         >>>
>>         >>> First sorry for this very long first post ?
>>         >>    That's OK.  I'm only going to answer part of it,
>>         because it's long.
>>         >>> I am looking for advises to fit a mixed multinomial
>>         regression on count
>>         >>> data that are overdispersed and zero-inflated. My
>>         question is to evaluate
>>         >>> the effect of season and moonlight on diet composition of
>>         bat-eared
>>         >> foxes.
>>         >>> My dataset is composed of 14 possible prey item, 20
>>         individual foxes
>>         >>> observed, 4 seasons and a moon illumination index ranging
>>         from 0 to 1 by
>>         >>> 0.1 implements (considered as a continuous variable even
>>         if takes only 11
>>         >>> values). For each unique combination of
>>         individual*season*moon, I thus
>>         >> has
>>         >>> 14 lines, one for the count of each prey item.
>>         >>>
>>         >>>  From what I gathered, it would be possible to use
>>         >>> a standard glmm model of
>>         >>> the following form to answer my question (ie a
>>         multinomial regression):
>>         >>>
>>         >>> glmer(count~item+item:season+item:moon+offset(logduration)+
>>         >>> (1+indiv)+(1|obs)+
>>         >>> (1|id), family=poisson)
>>         >>    Yes, but I don't know if this will account for the
>>         possible dependence
>>         >> *among* prey types.
>>         >>
>>         >>> where count is the number of prey of a given type
>>         recorded eaten;
>>         >>>
>>         >>> item is the prey type;
>>         >>>
>>         >>> logduration is the log(total time observed for a given
>>         combination of
>>         >>> individual*season*moon);
>>         >>>
>>         >>> obs is a unique id for each combination of
>>         individual*season*moon,
>>         >>> so each
>>         >>> obs value regroups 14 lines (one for each prey item) with
>>         the same
>>         >>> individual*season*moon;
>>         >>>
>>         >>> id is a unique id for each line to account for
>>         overdispersion (as
>>         >>> quasi-poisson or negative binomial distributions are not
>>         implemented in
>>         >>> lme4, Elston et al. 2001).
>>         >>     Seems about right.
>>         >>     There is glmer.nb now, but you might not want it; it
>>         tends to
>>         >> be slower and more fragile, and you'd still have to deal with
>>         >> zero-inflation.
>>         >>
>>         >>> However, they are a lot of zeros in my data i.e. lot of
>>         prey items has
>>         >>> never been observed being eaten for mane combinations of
>>         >>> individual*season*moon.
>>         >>    That doesn't *necessarily* mean you need
>>         zero-inflation. Large
>>         >> numbers of zeros might just reflect low probabilities, not
>>         ZI per se.
>>         >>
>>         >>> Following Ben Bolker wiki (http://glmm.wikidot.com/faq) I
>>         summarize
>>         >> that I
>>         >>> should use of the following methods to answer my question
>>         >>>
>>         >>>     - ?      glmmADMB, with family=nbinom
>>         >>>     - ?      MCMCglmm, with family=zipoisson
>>         >>>     - ? "expectation-maximization (EM) algorithm" in lme4
>>         >>    Note there's a marginally newer version at
>>         >>
>>         https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.html
>>         >>
>>         >>    Another, newer choice is glmmTMB (available on Github) with
>>         >> family="nbinom2"
>>         >>
>>         >>> Here come the questions:
>>         >>> 1.  1. Is it correct to assume that I could use the same
>>         model
>>         >>> structure
>>         >>>
>>         (count~item+item:season+item:moon+offset(logduration)+(1+indiv)+(1|obs))
>>         >>> in glmmADMB or MCMCglmm to answer my question ?
>>         >>    glmmADMB or glmmTMB, yes: I'm not sure about MCMCglmm
>>         >>
>>         >>> 2.   I then wouldn't need the (1|id) to correct for
>>         overdispersion as
>>         >> both
>>         >>> methods would already account for it, correct?
>>         >>     That's right, I think.
>>         >>
>>         >>> 3.   I am totally new to MCMCglmm, so  ...
>>         >>    I'm going to let Jarrod Hadfield, or someone else,
>>         answer this one.
>>         >>> 4.     4.  If I were to use the EM algorithm method,
>>         >>> how should the results
>>         >>> be interpreted?
>>         >>    The result is composed of two models -- a 'binary'
>>         (structural zero vs
>>         >> non-structural zero) and a 'conditional' (count) part.
>>         >> _______________________________________________
>>         >> R-sig-mixed-models at r-project.org
>>         <mailto:R-sig-mixed-models at r-project.org> mailing list
>>         >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>         >
>>         >
>>         >
>>
>>         --
>>         Dr. Alain F. Zuur
>>
>>         First author of:
>>         1. Beginner's Guide to GAMM with R (2014).
>>         2. Beginner's Guide to GLM and GLMM with R (2013).
>>         3. Beginner's Guide to GAM with R (2012).
>>         4. Zero Inflated Models and GLMM with R (2012).
>>         5. A Beginner's Guide to R (2009).
>>         6. Mixed effects models and extensions in ecology with R (2009).
>>         7. Analysing Ecological Data (2007).
>>
>>         Highland Statistics Ltd.
>>         9 St Clair Wynd
>>         UK - AB41 6DZ Newburgh
>>         Tel:   0044 1358 788177
>>         Email: highstat at highstat.com <mailto:highstat at highstat.com>
>>         URL: www.highstat.com <http://www.highstat.com>
>>
>>
>>                 [[alternative HTML version deleted]]
>>
>>         _______________________________________________
>>         R-sig-mixed-models at r-project.org
>>         <mailto:R-sig-mixed-models at r-project.org> mailing list
>>         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>>
>>     -- 
>>     *St?phanie PERIQUET (PhD) * - Bat-eared Fox Research Project
>>     /Dept of Zoology & Entomology/
>>     /University of the Free State, Qwaqwa Campus/
>>     *Cell: +27 79 570 2683*
>>     ResearchGate profile
>>     <https://www.researchgate.net/profile/Stephanie_Periquet>
>>
>>
>>     Kalahari bat-eared foxes on Twitter
>>     <https://twitter.com/kal_batearedfox>
>
>     -- 
>     Dr. Alain F. Zuur
>
>     First author of:
>     1. Beginner's Guide to GAMM with R (2014).
>     2. Beginner's Guide to GLM and GLMM with R (2013).
>     3. Beginner's Guide to GAM with R (2012).
>     4. Zero Inflated Models and GLMM with R (2012).
>     5. A Beginner's Guide to R (2009).
>     6. Mixed effects models and extensions in ecology with R (2009).
>     7. Analysing Ecological Data (2007).
>
>     Highland Statistics Ltd.
>     9 St Clair Wynd
>     UK - AB41 6DZ Newburgh
>     Tel:   0044 1358 788177
>     Email:highstat at highstat.com <mailto:highstat at highstat.com>
>     URL:www.highstat.com <http://www.highstat.com>
>
>
>
>
> -- 
> *St?phanie PERIQUET (PhD) * - Bat-eared Fox Research Project
> /Dept of Zoology & Entomology/
> /University of the Free State, Qwaqwa Campus/
> *Cell: +27 79 570 2683*
> ResearchGate profile 
> <https://www.researchgate.net/profile/Stephanie_Periquet>
>
>
> Kalahari bat-eared foxes on Twitter <https://twitter.com/kal_batearedfox>

-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


	[[alternative HTML version deleted]]


From b.pelzer at maw.ru.nl  Wed May 18 09:59:40 2016
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Wed, 18 May 2016 09:59:40 +0200
Subject: [R-sig-ME] lmer() fit
In-Reply-To: <573B744B.7050803@gmail.com>
References: <706EC88D-DFAC-4F91-B69C-6594EEBB595C@duke.edu>
	<573B744B.7050803@gmail.com>
Message-ID: <9c87d8ec-04de-6390-0c79-caacfe410010@maw.ru.nl>

Hi,

I used Julia to do a similar job some months ago with about 35 fixed 
effects and one random slope. On my PC  (older type i7 processor, 
windows 7, 12 Gb memory) Julia was about 5 to 6 times as fast as lmer in 
R. Since I had to estimate many models, one after the other, I could 
also use the parallel processing option in Julia, which resulted in 
about 20 times as fast per model as in R. To be honest: I did not use 
the same facility in R, which exists, but just to give you an idea.

Regards, Ben.


On 17-5-2016 21:43, Ben Bolker wrote:
>    This doesn't seem like a big deal.  The following fit takes about 4.5
> seconds on my Macbook Pro.
>
> library(lme4)
> set.seed(101)
> nRE <- 20000
> nobs <- 250000
> dd <- data.frame(f=sample(1:nRE,size=nobs,replace=TRUE),
>                   x=rnorm(nobs))
> dd$y <- simulate(~x+(1|f),
>           newparams=list(beta=c(1,2),theta=1,sigma=1),
>           newdata=dd,
>           family=gaussian,
>           seed=102)[[1]]
> system.time(fit <- lmer(y~x+(1|f),
>                data=dd))
> fixef(fit)
> VarCorr(fit)
>
>
>     If you have lots of fixed effects or very complex random effects,
> things could get a bit slower.  If you have a *much* bigger problem than
> this -- or if you're going to want to this sort of thing thousands of
> times in a row and 4.5 seconds is too slow -- you might want to talk to
> Doug Bates about the MixedModels package for Julia ...
>
>
> On 16-05-17 02:23 PM, Chaitanya Acharya wrote:
>> Hi, Apologies for a very non-specific question. Any idea how many
>> random effects could lmer() reasonably fit? I am thinking of a
>> situation where I want to fit ~20k random effects with ~250k
>> observations. What kind of issues should I foresee?
>>
>> Thanks, Chuck _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From stephanie.periquet at gmail.com  Wed May 18 10:48:22 2016
From: stephanie.periquet at gmail.com (=?UTF-8?B?U3TDqXBoYW5pZSBQw6lyaXF1ZXQ=?=)
Date: Wed, 18 May 2016 10:48:22 +0200
Subject: [R-sig-ME] mixed mutlinomial regression for count data with,
 overdisperion & zero-inflation
In-Reply-To: <cd6f436d-742a-6c50-5268-0ddd43bdf24e@highstat.com>
References: <mailman.1.1463479201.8680.r-sig-mixed-models@r-project.org>
	<b400a06c-ad29-ee23-8bac-e5be7a6d7077@highstat.com>
	<CAMKTVFUt1aknwcN6Wq6ecv1uSM+k36PKNC0d5gShY2WorX2=OQ@mail.gmail.com>
	<87c2fa6b-5778-3e72-63e9-21fce2da97af@highstat.com>
	<CAMKTVFXaHmAi+YCBpKdZO58ciwc9GQKAMrf--n_aCKqgGU2LEg@mail.gmail.com>
	<cd6f436d-742a-6c50-5268-0ddd43bdf24e@highstat.com>
Message-ID: <CAMKTVFVn8kydX6PFgj3sJ+4mqt5kNaudp001judt5Z1aLcMGxA@mail.gmail.com>

Ok thanks for the details. And this histogram confirms I have zero
inflation indeed, the value from the original data is out of the
distribution from the simulated data...

Best,
Stephanie

On 18 May 2016 at 09:39, Highland Statistics Ltd <highstat at highstat.com>
wrote:

>
>
> On 18/05/2016 08:26, St?phanie P?riquet wrote:
>
> Yeah thanks Alain, I'm definitely planning to buy this book!
>
> So I looked at the zeros in my data abased on you advice and I did the
> following:
>
> mod<-glmer(count~item+item:season+item:moon+item:season:moon+(1|indiv/obs)+(1|id),family=poisson,nAGQ=0,data=diet3)
> z<-simulate(mod,nsim=1000)
>
> For the original data I have 69.3% of zeros while the average over the
> 1000 simulations is 63.5%.Is there a way to statistically compare these 2
> values? Or could you say that these 2 figures are not very different and
> then zero inflation models might not be necessary?
>
>
> Stephanie,
>
> Make a histogram of the 1000 values of the percentages of zeros....and
> present the 69.3% as a big blue/red dot. If the dot for your observed data
> is in the tails you have a problem.
>
> I don't see the point of a test in your case. Such a simulation is close
> to bootstrapping...so I guess you can come up with a test somehow. If you
> do this type of analysis in a Bayesian framework it is often (and
> confusingly) called a Bayesian p-value (counting how often the simulated
> value is larger than your observed one).
>
> I would just go for the histogram...seems you are lucky.
>
>
> Alain
>
>
>
>
>
>
> Best,
> Stephanie
>
> On 17 May 2016 at 20:21, Highland Statistics Ltd <highstat at highstat.com>
> wrote:
>
>>
>>
>> On 17/05/2016 18:53, St?phanie P?riquet wrote:
>>
>> Dear Alain,
>>
>> Thanks for your reply and advices! Will try to do that and wait for your
>> very timely paper to come out to be sure I did the right thing!
>>
>>
>> Stephanie,
>>
>> Although it does not cover multinomial models directly, this one may be
>> of use as well:
>>
>> Beginner's Guide to Zero-Inflated Models with R (2016). Zuur AF and Ieno
>> EN
>> http://highstat.com/BGZIM.htm
>>
>> Sorry for the self-references.
>>
>> Kind regards,
>>
>> Alain
>>
>>
>> Best,
>> Stephanie
>>
>> On 17 May 2016 at 12:08, Highland Statistics Ltd <
>> <highstat at highstat.com>highstat at highstat.com> wrote:
>>
>>>
>>>
>>>
>>> > ----------------------------------------------------------------------
>>> >
>>> > Message: 1
>>> > Date: Tue, 17 May 2016 08:28:42 +0200
>>> > From: St?phanie P?riquet < <stephanie.periquet at gmail.com>
>>> stephanie.periquet at gmail.com>
>>> > To: Ben Bolker < <bbolker at gmail.com>bbolker at gmail.com>
>>> > Cc: r-sig-mixed-models at r-project.org
>>> > Subject: Re: [R-sig-ME] Mixed mutlinomial regression for count data
>>> >       with overdisperion & zero-inflation
>>> > Message-ID:
>>> >       <CAMKTVFXZnvS1g-FaNVQ1FQUj5u84S-fd=
>>> <k4u_6x5PwJUZ2R+bQ at mail.gmail.com>k4u_6x5PwJUZ2R+bQ at mail.gmail.com>
>>> > Content-Type: text/plain; charset="UTF-8"
>>> >
>>> > Hi Ben,
>>> >
>>> > Thank you very much for your answer!
>>> >
>>> > I am aware that a lot of zero doesn't mean zero inflation, but if my
>>> > understanding is correct the only way to check for ZI would be to
>>> compare
>>> > one model take doesn't take it into account and another one that does
>>> right?
>>>
>>> Incorrect.
>>> 1. Calculate the percentage of zeros for your observed data.
>>> 2. Fit a model....this can be a model without zero inflation stuff.
>>> 3. Simulate 1000 data sets from your model and for each simulated data
>>> set assess the percentage of zeros.
>>> 4. Compare the results in 3 with those in 1.
>>>
>>> 5. Even nicer....
>>> 5a. Plot a simple frequency table for the original data
>>> (plot(table(Response), type = "h").
>>> 5b. Calculate a table() for each of your simulated data.
>>> 5c. Calculate the average frequency table.
>>> 5d. Compare 5a and 5c.
>>>
>>> For a nice example and R code, see:
>>> A protocol for conducting and presenting results of regression-type
>>> analyses. Zuur & Ieno
>>> doi: 10.1111/2041-210X.12577
>>> Methods in Ecology and Evolution 2016
>>>
>>> Comes out in 2 weeks or so.
>>>
>>> Kind regards,
>>>
>>> Alain
>>>
>>>
>>> > With the model example I gave (count~item+item:season+item:
>>> > moon+offset(logduration)+(1+indiv)+(1|obs)) glmmADMB doesn't run but
>>> I'm
>>> > gonna dig a bit more into this ans come back t you if I can't figure
>>> it out.
>>> >
>>> > Best,
>>> > Stephanie
>>> >
>>> > On 17 May 2016 at 00:41, Ben Bolker < <bbolker at gmail.com>
>>> bbolker at gmail.com> wrote:
>>> >
>>> >> St?phanie P?riquet <stephanie.periquet at ...><stephanie.periquet at ...>
>>> <stephanie.periquet at ...> writes:
>>> >>
>>> >>> Dear list members,
>>> >>>
>>> >>> First sorry for this very long first post ?
>>> >>    That's OK.  I'm only going to answer part of it, because it's long.
>>> >>> I am looking for advises to fit a mixed multinomial regression on
>>> count
>>> >>> data that are overdispersed and zero-inflated. My question is to
>>> evaluate
>>> >>> the effect of season and moonlight on diet composition of bat-eared
>>> >> foxes.
>>> >>> My dataset is composed of 14 possible prey item, 20 individual foxes
>>> >>> observed, 4 seasons and a moon illumination index ranging from 0 to
>>> 1 by
>>> >>> 0.1 implements (considered as a continuous variable even if takes
>>> only 11
>>> >>> values). For each unique combination of individual*season*moon, I
>>> thus
>>> >> has
>>> >>> 14 lines, one for the count of each prey item.
>>> >>>
>>> >>>  From what I gathered, it would be possible to use
>>> >>> a standard glmm model of
>>> >>> the following form to answer my question (ie a multinomial
>>> regression):
>>> >>>
>>> >>> glmer(count~item+item:season+item:moon+offset(logduration)+
>>> >>> (1+indiv)+(1|obs)+
>>> >>> (1|id), family=poisson)
>>> >>    Yes, but I don't know if this will account for the possible
>>> dependence
>>> >> *among* prey types.
>>> >>
>>> >>> where count is the number of prey of a given type recorded eaten;
>>> >>>
>>> >>> item is the prey type;
>>> >>>
>>> >>> logduration is the log(total time observed for a given combination of
>>> >>> individual*season*moon);
>>> >>>
>>> >>> obs is a unique id for each combination of individual*season*moon,
>>> >>> so each
>>> >>> obs value regroups 14 lines (one for each prey item) with the same
>>> >>> individual*season*moon;
>>> >>>
>>> >>> id is a unique id for each line to account for overdispersion (as
>>> >>> quasi-poisson or negative binomial distributions are not implemented
>>> in
>>> >>> lme4, Elston et al. 2001).
>>> >>     Seems about right.
>>> >>     There is glmer.nb now, but you might not want it; it tends to
>>> >> be slower and more fragile, and you'd still have to deal with
>>> >> zero-inflation.
>>> >>
>>> >>> However, they are a lot of zeros in my data i.e. lot of prey items
>>> has
>>> >>> never been observed being eaten for mane combinations of
>>> >>> individual*season*moon.
>>> >>    That doesn't *necessarily* mean you need zero-inflation. Large
>>> >> numbers of zeros might just reflect low probabilities, not ZI per se.
>>> >>
>>> >>> Following Ben Bolker wiki ( <http://glmm.wikidot.com/faq>
>>> http://glmm.wikidot.com/faq) I summarize
>>> >> that I
>>> >>> should use of the following methods to answer my question
>>> >>>
>>> >>>     - ?      glmmADMB, with family=nbinom
>>> >>>     - ?      MCMCglmm, with family=zipoisson
>>> >>>     - ?      "expectation-maximization (EM) algorithm" in lme4
>>> >>    Note there's a marginally newer version at
>>> >> https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.html
>>> >>
>>> >>    Another, newer choice is glmmTMB (available on Github) with
>>> >> family="nbinom2"
>>> >>
>>> >>> Here come the questions:
>>> >>> 1.  1. Is it correct to assume that I could use the same model
>>> >>> structure
>>> >>>
>>> (count~item+item:season+item:moon+offset(logduration)+(1+indiv)+(1|obs))
>>> >>> in glmmADMB or MCMCglmm to answer my question ?
>>> >>    glmmADMB or glmmTMB, yes: I'm not sure about MCMCglmm
>>> >>
>>> >>> 2.   I then wouldn't need the (1|id) to correct for overdispersion as
>>> >> both
>>> >>> methods would already account for it, correct?
>>> >>     That's right, I think.
>>> >>
>>> >>> 3.   I am totally new to MCMCglmm, so  ...
>>> >>    I'm going to let Jarrod Hadfield, or someone else, answer this one.
>>> >>> 4.     4.  If I were to use the EM algorithm method,
>>> >>> how should the results
>>> >>> be interpreted?
>>> >>    The result is composed of two models -- a 'binary' (structural
>>> zero vs
>>> >> non-structural zero) and a 'conditional' (count) part.
>>> >> _______________________________________________
>>> >> R-sig-mixed-models at r-project.org mailing list
>>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> >
>>> >
>>> >
>>>
>>> --
>>> Dr. Alain F. Zuur
>>>
>>> First author of:
>>> 1. Beginner's Guide to GAMM with R (2014).
>>> 2. Beginner's Guide to GLM and GLMM with R (2013).
>>> 3. Beginner's Guide to GAM with R (2012).
>>> 4. Zero Inflated Models and GLMM with R (2012).
>>> 5. A Beginner's Guide to R (2009).
>>> 6. Mixed effects models and extensions in ecology with R (2009).
>>> 7. Analysing Ecological Data (2007).
>>>
>>> Highland Statistics Ltd.
>>> 9 St Clair Wynd
>>> UK - AB41 6DZ Newburgh
>>> Tel:   0044 1358 788177
>>> Email: highstat at highstat.com
>>> URL:   www.highstat.com
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>>
>> --
>> *St?phanie PERIQUET (PhD) * - Bat-eared Fox Research Project
>> *Dept of Zoology & Entomology*
>> *University of the Free State, Qwaqwa Campus*
>> *Cell: +27 79 570 2683*
>> ResearchGate profile
>> <https://www.researchgate.net/profile/Stephanie_Periquet>
>>
>>
>> Kalahari bat-eared foxes on Twitter <https://twitter.com/kal_batearedfox>
>>
>>
>> --
>> Dr. Alain F. Zuur
>>
>> First author of:
>> 1. Beginner's Guide to GAMM with R (2014).
>> 2. Beginner's Guide to GLM and GLMM with R (2013).
>> 3. Beginner's Guide to GAM with R (2012).
>> 4. Zero Inflated Models and GLMM with R (2012).
>> 5. A Beginner's Guide to R (2009).
>> 6. Mixed effects models and extensions in ecology with R (2009).
>> 7. Analysing Ecological Data (2007).
>>
>> Highland Statistics Ltd.
>> 9 St Clair Wynd
>> UK - AB41 6DZ Newburgh
>> Tel:   0044 1358 788177
>> Email: highstat at highstat.com
>> URL:   www.highstat.com
>>
>>
>
>
> --
> *St?phanie PERIQUET (PhD) * - Bat-eared Fox Research Project
> *Dept of Zoology & Entomology*
> *University of the Free State, Qwaqwa Campus*
> *Cell: +27 79 570 2683*
> ResearchGate profile
> <https://www.researchgate.net/profile/Stephanie_Periquet>
>
>
> Kalahari bat-eared foxes on Twitter <https://twitter.com/kal_batearedfox>
>
>
> --
> Dr. Alain F. Zuur
>
> First author of:
> 1. Beginner's Guide to GAMM with R (2014).
> 2. Beginner's Guide to GLM and GLMM with R (2013).
> 3. Beginner's Guide to GAM with R (2012).
> 4. Zero Inflated Models and GLMM with R (2012).
> 5. A Beginner's Guide to R (2009).
> 6. Mixed effects models and extensions in ecology with R (2009).
> 7. Analysing Ecological Data (2007).
>
> Highland Statistics Ltd.
> 9 St Clair Wynd
> UK - AB41 6DZ Newburgh
> Tel:   0044 1358 788177
> Email: highstat at highstat.com
> URL:   www.highstat.com
>
>


-- 
*St?phanie PERIQUET (PhD) * - Bat-eared Fox Research Project
*Dept of Zoology & Entomology*
*University of the Free State, Qwaqwa Campus*
*Cell: +27 79 570 2683*
ResearchGate profile
<https://www.researchgate.net/profile/Stephanie_Periquet>


Kalahari bat-eared foxes on Twitter <https://twitter.com/kal_batearedfox>

	[[alternative HTML version deleted]]


From bates at stat.wisc.edu  Wed May 18 16:45:11 2016
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 18 May 2016 09:45:11 -0500
Subject: [R-sig-ME] e-book
In-Reply-To: <8942EC55-B944-4F30-A7F1-9A98ACC9910E@dcn.davis.ca.us>
References: <20160518030736.BEE17A800D1@webmail.sinamail.sina.com.cn>
	<8942EC55-B944-4F30-A7F1-9A98ACC9910E@dcn.davis.ca.us>
Message-ID: <CAO7JsnQ4xpoWPa2a1_Y6yCGxF-+-eJOgMGwp13MjEuL5gA6V-g@mail.gmail.com>

On Wed, May 18, 2016 at 1:10 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Amazon in paperback.  ISBN 1441903178
>

Different book.  "Mixed-effects models in S and S-PLUS" describes the use
of the nlme package, a predecessor to the lme4 package.

The book the OP was asking about was never published (I'm good at starting
projects, not so good at finishing them).  An incomplete version is
available at

http://lme4.r-forge.r-project.org/lMMwR/lrgprt.pdf

--
> Sent from my phone. Please excuse my brevity.
>
> On May 17, 2016 8:07:36 PM PDT, "??" <dianxiangan32 at sina.cn> wrote:
> >Hi,
> >I found a good e-book: lme4: mixed-effects modeling with r
> >If there is a place to buy it?
> >--------------------------------
> >
> >
> >       [[alternative HTML version deleted]]
> >
> >_______________________________________________
> >R-sig-mixed-models at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From davef at otter-rsch.com  Thu May 19 20:43:47 2016
From: davef at otter-rsch.com (dave fournier)
Date: Thu, 19 May 2016 11:43:47 -0700
Subject: [R-sig-ME] mixed mutlinomial regression for count data with,
 overdisperion & zero-inflation
In-Reply-To: <CAMKTVFVn8kydX6PFgj3sJ+4mqt5kNaudp001judt5Z1aLcMGxA@mail.gmail.com>
References: <CAMKTVFVn8kydX6PFgj3sJ+4mqt5kNaudp001judt5Z1aLcMGxA@mail.gmail.com>
Message-ID: <573E0963.3060900@otter-rsch.com>


Hi,

I ran your data outside of R.  It was immediately clear that the version 
of glmmADMB I had
in R was missing a feature.  the additional feature was the rescaling of 
badly scaled parameters
in the model.  Aftewr a simple rescaling I ran your data according to 
your model hypothesis
using both ZI and non ZI and Neg Bin type 1 and type 2 overdispersion.  
the model converged easily
and produced the following results.  the Objective function value is the 
negative log likelihood so smaller is better.
clearly zero inflation is indicated and type 2 fits a lot better than 
type 1.





Type 2
# Number of parameters = 33  Objective function value = 5698.40 Maximum 
gradient component = 7.96141e-05
# pz:
  0.0000
# Number of parameters = 34  Objective function value = 5672.69 Maximum 
gradient component = 4.96526e-05
# pz:
0.118535625347
Type 1
# Number of parameters = 33  Objective function value = 5954.95 Maximum 
gradient component = 9.43931e-05
# pz:
  0.0000
# Number of parameters = 34  Objective function value = 5936.85 Maximum 
gradient component = 7.44436e-05
# pz:
0.0684308821563


From davef at otter-rsch.com  Fri May 20 05:05:06 2016
From: davef at otter-rsch.com (dave fournier)
Date: Thu, 19 May 2016 20:05:06 -0700
Subject: [R-sig-ME] mixed mutlinomial regression for count data with,
 overdisperion & zero-inflation
In-Reply-To: <573E0963.3060900@otter-rsch.com>
References: <573E0963.3060900@otter-rsch.com>
Message-ID: <573E7EE2.3040606@otter-rsch.com>

I found a version of glmmadmb for Windows 64bit ( I sadly assume) that 
almost does the job out of the
box. Using the information from R Forge

    http://glmmadmb.r-forge.r-project.org/

which points to

       http://www.admb-project.org/buildbot/glmmadmb/

where I found this exe

             glmmadmb-mingw64-r3274-windows10-mingw64.exe

  Using your glmmadmb.pin and glmmadmb.dat files (which you renamed to
glmmadmb1.pin and glmmadmb1.dat) I ran the following script.

    ./glmmadmb-mingw64-r3274-windows10-mingw64.exe -crit 1.e-6  -ind 
glmmadmb1.dat -ainp glmmadmb.par -maxph 5 -shess -noinit -phase 7

(I have added two extra phases and modified the convergence criterion to 
1.e-6.)

which converged with nice estimates etc.   Now one of the really nice 
things about actually fitting the model
rather than resorting to other diagnostics is that if you are successful 
you can look at the fit.  In this
case the squared residuals divided by the predicted variance.  These are 
in the output glmmadmb.rep file.

I sorted them in R and looked at the large ones at the end.


index           obs    pred             whatever its called
1206 1206  319 3.47536e+01 1.24498e+01
305   305 4490 2.18655e+03 1.29949e+01
1074 1074  413 5.13552e+01 1.36380e+01
1385 1385 4002 1.68879e+03 1.69679e+01
854   854  224 1.22219e+01 1.96515e+01
1691 1691 2713 8.33316e+02 2.27056e+01
1427 1427 1732 3.92621e+02 2.44684e+01
1433 1433 1612 3.25266e+02 2.72590e+01
1313 1313 1815 3.52356e+02 3.25137e+01
341   341 2031 3.55824e+02 4.22336e+01
191   191 5814 7.18097e+02 1.93656e+02
599   599 3586 2.68911e+02 2.19118e+02

So you have a few gigantic outliers.  This is fairly common with data 
for which the model
has problems converging.  But rather than celebrating the failure of the 
model as a useful diagnostic for
bad data it is really useful to coax it to fit the data and investigate 
the residuals,
If you can explain them it should help.


From stephanie.periquet at gmail.com  Fri May 20 09:04:26 2016
From: stephanie.periquet at gmail.com (=?UTF-8?B?U3TDqXBoYW5pZSBQw6lyaXF1ZXQ=?=)
Date: Fri, 20 May 2016 09:04:26 +0200
Subject: [R-sig-ME] mixed mutlinomial regression for count data with,
 overdisperion & zero-inflation
In-Reply-To: <573E7EE2.3040606@otter-rsch.com>
References: <573E0963.3060900@otter-rsch.com> <573E7EE2.3040606@otter-rsch.com>
Message-ID: <CAMKTVFVkAonnYTS=E4Gsa1pne0aO=pzZxUKJ6G0CB8DrXvH2cw@mail.gmail.com>

Hi Dave,

Thanks for all this detailed info. I'm on Mac unfortunately. But as the
model with nbinom2 runs and is a better fit, I'll inspect the rep file fo
this one. Or is there a way to access this directly on R?

Best,
Stephanie

On 20 May 2016 at 05:05, dave fournier <davef at otter-rsch.com> wrote:

> I found a version of glmmadmb for Windows 64bit ( I sadly assume) that
> almost does the job out of the
> box. Using the information from R Forge
>
>    http://glmmadmb.r-forge.r-project.org/
>
> which points to
>
>       http://www.admb-project.org/buildbot/glmmadmb/
>
> where I found this exe
>
>             glmmadmb-mingw64-r3274-windows10-mingw64.exe
>
>  Using your glmmadmb.pin and glmmadmb.dat files (which you renamed to
> glmmadmb1.pin and glmmadmb1.dat) I ran the following script.
>
>    ./glmmadmb-mingw64-r3274-windows10-mingw64.exe -crit 1.e-6  -ind
> glmmadmb1.dat -ainp glmmadmb.par -maxph 5 -shess -noinit -phase 7
>
> (I have added two extra phases and modified the convergence criterion to
> 1.e-6.)
>
> which converged with nice estimates etc.   Now one of the really nice
> things about actually fitting the model
> rather than resorting to other diagnostics is that if you are successful
> you can look at the fit.  In this
> case the squared residuals divided by the predicted variance.  These are
> in the output glmmadmb.rep file.
>
> I sorted them in R and looked at the large ones at the end.
>
>
> index           obs    pred             whatever its called
> 1206 1206  319 3.47536e+01 1.24498e+01
> 305   305 4490 2.18655e+03 1.29949e+01
> 1074 1074  413 5.13552e+01 1.36380e+01
> 1385 1385 4002 1.68879e+03 1.69679e+01
> 854   854  224 1.22219e+01 1.96515e+01
> 1691 1691 2713 8.33316e+02 2.27056e+01
> 1427 1427 1732 3.92621e+02 2.44684e+01
> 1433 1433 1612 3.25266e+02 2.72590e+01
> 1313 1313 1815 3.52356e+02 3.25137e+01
> 341   341 2031 3.55824e+02 4.22336e+01
> 191   191 5814 7.18097e+02 1.93656e+02
> 599   599 3586 2.68911e+02 2.19118e+02
>
> So you have a few gigantic outliers.  This is fairly common with data for
> which the model
> has problems converging.  But rather than celebrating the failure of the
> model as a useful diagnostic for
> bad data it is really useful to coax it to fit the data and investigate
> the residuals,
> If you can explain them it should help.
>
>
>
>
>
>
>
>
>
>
>


-- 
*St?phanie PERIQUET (PhD) * - Bat-eared Fox Research Project
*Dept of Zoology & Entomology*
*University of the Free State, Qwaqwa Campus*
*Cell: +27 79 570 2683*
ResearchGate profile
<https://www.researchgate.net/profile/Stephanie_Periquet>


Kalahari bat-eared foxes on Twitter <https://twitter.com/kal_batearedfox>

	[[alternative HTML version deleted]]


From claudia.kasper at iee.unibe.ch  Fri May 20 10:49:41 2016
From: claudia.kasper at iee.unibe.ch (claudia.kasper at iee.unibe.ch)
Date: Fri, 20 May 2016 08:49:41 +0000
Subject: [R-sig-ME] residual covariance in trivariate MCMCglmm model with
 different error families
Message-ID: <8C514C5A993CBA43A3FA8A1E242BD216307F7164@aai-exch-mbx4.campus.unibe.ch>

Dear list members,
I have a question concerning a way to obtain the residual covariance from a trivariate model with different error families. I am using MCMCglmm to see if 3 traits (one count, two binary) correlate on a genetic, maternal, and individual level. The model contains six random effects and an inverse Wishart prior that distributes the variation across the variance components and the residual variation had produced the best results (in terms of convergence, chain length, etc). To run the model I fixed the residual variance in a way that the variances of the binary traits as well as their covariances are fixed, and only the unit variance of the count trait and its covariances are estimated (see prior below).
Now I wonder how I calculate the phenotypic correlations? My guess would be summing up all (co)variance matrices including the residual (co)variance matrix. I followed Nakagawa's & Schielzeth's (2010) guide for the residual variances for binary and count data that have to be calculated separately after running the model, and I assume the same applies to covariances between two binary or two count traits (I add (pi^2)/3 to the binomial and log(1/exp(intercept)+1) to the Poisson residual (co)variance)). However, I am not sure what I should do for covariances of count traits with binary traits? Can I use sqrt((pi^2)/3) * sqrt(log(1/exp(intercept)+1))?
Probably there is a more standard way to get the phenotypic correlations that I am not aware of. In this case I would be very grateful if somebody could point me towards web resources or published papers.
Below are the prior specifications and the model formula I used:
priorIW <- list(R = list(V = diag(3)/7, n = 4, fix=2), G = list(G1 = list(V = diag(3)/7, n = 4), G2 = list(V = diag(3)/7, n = 4), G3 = list(V = diag(3)/7, n = 4), G4 = list(V = diag(3)/7, n = 4), G5 = list(V = diag(3)/7, n = 4), G6 = list(V = diag(3)/7, n = 4)))
m.GenCorr.1 <- MCMCglmm(cbind(Df,Cl,Dg) ~ trait-1, random=~us(trait):animal + us(trait):DamID + us(trait):TIDec + us(trait):Group + us(trait):DIDec + us(trait):Pop, rcov=~us(trait):units, data=dataDefense, pedigree=ped, family=c("poisson","categorical","categorical"), verbose = F, prior=priorIW, nitt=10000000, burnin = 100000, thin = 5000)

Kind regards,
Claudia Kasper


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
C?A?T?T?C?G?A?T?T?C?T?A?A?G?G?C?A?T??T?T?T?C?G?A?T 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 ~~ Claudia Kasper
       ~~ PhD candidate
 ~~ Division of Behavioural Ecology
       ~~ Institute of Ecology and Evolution
 ~~ University of Bern, Switzerland

   ><((?>    <?))><      ><((?>     <?))><      ><((?>    <?))><      ><((?>    <?))><


From davef at otter-rsch.com  Fri May 20 19:37:34 2016
From: davef at otter-rsch.com (dave fournier)
Date: Fri, 20 May 2016 10:37:34 -0700
Subject: [R-sig-ME] mixed mutlinomial regression for count data with,
 overdisperion & zero-inflation
In-Reply-To: <CAMKTVFVkAonnYTS=E4Gsa1pne0aO=pzZxUKJ6G0CB8DrXvH2cw@mail.gmail.com>
References: <CAMKTVFVkAonnYTS=E4Gsa1pne0aO=pzZxUKJ6G0CB8DrXvH2cw@mail.gmail.com>
Message-ID: <573F4B5E.6030901@otter-rsch.com>

My mac virtual machine is actually feeling more chipper than my windows 
virtual machine today
so I'll build you a special version that seems to tease out solutions 
for both nb1 and nb2 and
email it.  But the real issues I think are diagnosing problems with 
difficult data sets.

One problem is that the glmmadmb r package simply reports that the 
Hessian is not positive definite
and quits.  see this link

https://stat.ethz.ch/pipermail/r-sig-mixed-models/2016q1/024527.html

for a case where one could conclude that the problem with fitting the 
model was due to
confounding between the zero inflation and overdispersion.

Now with your model for one run I identified the negative eigenvalue  
-15.28948399 of the Hessian with the


     eigenvalues unsorted:    1.917979995e-10 -0.0004551907790 
0.001293591754 0.003821048249 0.01431672721 0.1009762164 0.03925858165 
0.07403629854 0.1091338760 0.1562519927 0.1703625637 0.1927551515 
0.2234392242 0.2309947849 0.3469581818 0.3041749405 0.3580105168 
0.3942153084 0.4397529164 0.5078767603 0.5728201455 0.6012492489 
0.6789170419 0.7369245582 0.7971275668 0.8833795401 0.9287787445 
0.9508016682 1.037844369 1.049178898 1.707802018 2.724758782 3.365700202 
-15.28948399

eigenvector
  -0.0006942405368 -0.07288724821  0.04506821612  0.08379747141 
0.1184035873   0.1124181332   0.4898312779   0.2647606687 
-0.005219962867 -0.01694772700 -0.02195235540 -0.0004078488080 
-0.1039487736   0.4007922401 -0.007979620610 -0.02801923429 
-0.03638402585 -0.0004982359168  -0.1679864668   0.6019723457 
-0.01250628628 -0.04275353216 -0.05511398984 -0.001275366327 
-0.2523634973  0.09075331140 -0.0008355685062 -0.005755760214 
-0.007503459862 0.0001200448790 -0.02765030934 0.0001257008991 
-0.009465390476 -0.07780205094

This is a more difficult case as it seems to involve almost all the 
parameters. However the largest ones are all
for the parameters of the linear predictor.  So it is saying that maybe 
your model is a bit overparameterized
or equivalently that the parameters of the linear predictor are a bit 
confounded.

Now in linear regression models one can try to deal with this situation 
by  employing ridge regression.
Really this is just putting a quadratic penalty on the parameters. We 
can do this and decrease the size of the penalty
in stages and finally if desired doing away with it entirely. I set this 
up the version of glmmadmb I am sending you.

However that does not deal with your outlier problem.  For some reason a 
lot of count data analyses get published without any analysis of the 
residuals (at this point a disparaging remark about sociology is 
probably in order).

These are the worst outliers for nb1 and nb2 models
for your data

1074 1074  413 5.13552e+01 1.36380e+01
1385 1385 4002 1.68879e+03 1.69679e+01
854   854  224 1.22219e+01 1.96515e+01
1691 1691 2713 8.33316e+02 2.27056e+01
1427 1427 1732 3.92621e+02 2.44684e+01
1433 1433 1612 3.25266e+02 2.72590e+01
1313 1313 1815 3.52356e+02 3.25137e+01
341   341 2031 3.55824e+02 4.22336e+01
191   191 5814 7.18097e+02 1.93656e+02
599   599 3586 2.68911e+02 2.19118e+02

1385 1385 4002 1.24681e+03 2.36563e+01
335   335 3012 4.87436e+02 5.08038e+01
1427 1427 1732 1.64012e+02 5.82439e+01
1433 1433 1612 1.39872e+02 6.02005e+01
1313 1313 1815 1.29395e+02 8.53171e+01
341   341 2031 1.39804e+02 9.94021e+01
1691 1691 2713 2.16615e+02 1.11783e+02
191   191 5814 6.96952e+02 1.45975e+02
599   599 3586 1.46454e+02 3.13865e+02

The term 3.13865e+02 correspond to a residual of over 17 standard 
deviations.
One might expect that the influence of these large outliers has large 
influence
on the parameter estimates and will invalidate any significance tests 
one might
want carry out.


From maldonado.aa at gmail.com  Mon May 23 17:13:13 2016
From: maldonado.aa at gmail.com (Adriana Maldonado Chaparro)
Date: Mon, 23 May 2016 17:13:13 +0200
Subject: [R-sig-ME] Question about random effects
Message-ID: <CA+P1f9V+H4TnVkSG6D4_SWSJEOb+kUOp4NrNwfR3o16xUDONvw@mail.gmail.com>

Greetings,

I want to ask for advise on the following issue:
I fitted a mixed model where I'm trying to explain variation in Litter Sex
Ratio as a function of social network position. In this model the random
effect, individual identity, explained none of the variance, and one of the
reviewers argued that I should exclude it from my model because of these
reason. I think I should keep it because I have repeated measures. What are
your thoughts on this matter?

Thanks in advance,

Adriana Maldonado
Postdoctoral Researcher

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon May 23 17:42:24 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 23 May 2016 17:42:24 +0200
Subject: [R-sig-ME] Question about random effects
In-Reply-To: <CA+P1f9V+H4TnVkSG6D4_SWSJEOb+kUOp4NrNwfR3o16xUDONvw@mail.gmail.com>
References: <CA+P1f9V+H4TnVkSG6D4_SWSJEOb+kUOp4NrNwfR3o16xUDONvw@mail.gmail.com>
Message-ID: <CAJuCY5w4zo1QveJcN4V4841TN7S5rVZwZjDdFzgfxaTg=+816A@mail.gmail.com>

If the random effect reflects the design of the study then it should remain
in the model.

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-05-23 17:13 GMT+02:00 Adriana Maldonado Chaparro <
maldonado.aa at gmail.com>:

> Greetings,
>
> I want to ask for advise on the following issue:
> I fitted a mixed model where I'm trying to explain variation in Litter Sex
> Ratio as a function of social network position. In this model the random
> effect, individual identity, explained none of the variance, and one of the
> reviewers argued that I should exclude it from my model because of these
> reason. I think I should keep it because I have repeated measures. What are
> your thoughts on this matter?
>
> Thanks in advance,
>
> Adriana Maldonado
> Postdoctoral Researcher
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon May 23 17:57:31 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 23 May 2016 11:57:31 -0400
Subject: [R-sig-ME] Question about random effects
In-Reply-To: <CAJuCY5w4zo1QveJcN4V4841TN7S5rVZwZjDdFzgfxaTg=+816A@mail.gmail.com>
References: <CA+P1f9V+H4TnVkSG6D4_SWSJEOb+kUOp4NrNwfR3o16xUDONvw@mail.gmail.com>
	<CAJuCY5w4zo1QveJcN4V4841TN7S5rVZwZjDdFzgfxaTg=+816A@mail.gmail.com>
Message-ID: <5743286B.7070004@gmail.com>


  I agree, although I'll also say that if you are faced with a power
imbalance (reviewer/supervisor/etc. insists that it should be removed),
in the case where the random effect variance is estimated as zero there
is really very little (no?) *practical* difference in this case between
keeping or removing the random effect. In particular, the estimates of
any other variance components in the model, as well as all of the
contents of summary() [point estimates and Wald standard errors of
fixed-effect of coefficients] should be identical (try it and see).

  cheers
    Ben Bolker


On 16-05-23 11:42 AM, Thierry Onkelinx wrote:
> If the random effect reflects the design of the study then it should remain
> in the model.
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> 
> 2016-05-23 17:13 GMT+02:00 Adriana Maldonado Chaparro <
> maldonado.aa at gmail.com>:
> 
>> Greetings,
>>
>> I want to ask for advise on the following issue:
>> I fitted a mixed model where I'm trying to explain variation in Litter Sex
>> Ratio as a function of social network position. In this model the random
>> effect, individual identity, explained none of the variance, and one of the
>> reviewers argued that I should exclude it from my model because of these
>> reason. I think I should keep it because I have repeated measures. What are
>> your thoughts on this matter?
>>
>> Thanks in advance,
>>
>> Adriana Maldonado
>> Postdoctoral Researcher
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From reinhold.kliegl at gmail.com  Tue May 24 07:27:59 2016
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Tue, 24 May 2016 07:27:59 +0200
Subject: [R-sig-ME] Question about random effects
In-Reply-To: <5743286B.7070004@gmail.com>
References: <CA+P1f9V+H4TnVkSG6D4_SWSJEOb+kUOp4NrNwfR3o16xUDONvw@mail.gmail.com>
	<CAJuCY5w4zo1QveJcN4V4841TN7S5rVZwZjDdFzgfxaTg=+816A@mail.gmail.com>
	<5743286B.7070004@gmail.com>
Message-ID: <CAG+WrExH+eChA0+=AEC8b10PSQOKQNyQpHAmrnUYLh1fNhFWag@mail.gmail.com>

There is another kind of power issue involved as well:  Keeping spurious
variance components in the model leads to significant loss in statistical
power.

Stroup (2012, Generalized linear mixed models: Modern concepts, methods and
applications, p. 185):
"Neither the [maximal] nor the [minimal] linear mixed models are
appropriate for most repeated measures analysis. Using the [maximal] model
is generally wasteful and costly in terms of statistical power for testing
hypotheses. On the other hand, the [minimal] model fails to account for
nontrivial correlation among repeated measurements. This results in
inflated [T]ype I error rates when non-negligible correlation does in fact
exist. We can usually find middle ground, a covariance model that
adequately accounts for correlation but is more parsimonious than the
[maximal] model. Doing so allows us full control over [T]ype I error rates
without needlessly sacrificing power."

See also:  http://arxiv.org/abs/1511.01864


On Mon, May 23, 2016 at 5:57 PM, Ben Bolker <bbolker at gmail.com> wrote:

>
>   I agree, although I'll also say that if you are faced with a power
> imbalance (reviewer/supervisor/etc. insists that it should be removed),
> in the case where the random effect variance is estimated as zero there
> is really very little (no?) *practical* difference in this case between
> keeping or removing the random effect. In particular, the estimates of
> any other variance components in the model, as well as all of the
> contents of summary() [point estimates and Wald standard errors of
> fixed-effect of coefficients] should be identical (try it and see).
>
>   cheers
>     Ben Bolker
>
>
> On 16-05-23 11:42 AM, Thierry Onkelinx wrote:
> > If the random effect reflects the design of the study then it should
> remain
> > in the model.
> >
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and
> > Forest
> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> > Kliniekstraat 25
> > 1070 Anderlecht
> > Belgium
> >
> > To call in the statistician after the experiment is done may be no more
> > than asking him to perform a post-mortem examination: he may be able to
> say
> > what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does not
> > ensure that a reasonable answer can be extracted from a given body of
> data.
> > ~ John Tukey
> >
> > 2016-05-23 17:13 GMT+02:00 Adriana Maldonado Chaparro <
> > maldonado.aa at gmail.com>:
> >
> >> Greetings,
> >>
> >> I want to ask for advise on the following issue:
> >> I fitted a mixed model where I'm trying to explain variation in Litter
> Sex
> >> Ratio as a function of social network position. In this model the random
> >> effect, individual identity, explained none of the variance, and one of
> the
> >> reviewers argued that I should exclude it from my model because of these
> >> reason. I think I should keep it because I have repeated measures. What
> are
> >> your thoughts on this matter?
> >>
> >> Thanks in advance,
> >>
> >> Adriana Maldonado
> >> Postdoctoral Researcher
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From highstat at highstat.com  Tue May 24 10:17:38 2016
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Tue, 24 May 2016 09:17:38 +0100
Subject: [R-sig-ME] Course: Introduction to Zero Inflated Models
Message-ID: <2431cbf4-2806-c7fe-05b2-1bead8343464@highstat.com>

There are places available on the following course:


Course: Introduction to Zero Inflated Models (Bayesian and frequentist 
approaches)

When: 13-17 June 2016

Where: Australian Institute of Marine Science, Perth, Australia

Course website: http://highstat.com/statscourse.htm

Course flyer: http://highstat.com/Courses/Flyers/Flyer2016_06Perth_ZI_V2.pdf

Keywords: Zero inflated count data. Zero inflated continuous data. 
Dependency. ZIP and ZAP models. Zero inflated GLMMs with random effects. 
Bayesian statistics, MCMC and JAGS. lme4, glmmADMB, JAGS. Overdispersion 
and solutions. Bayesian model selection.

Description: Suppose you want to study hippos and the effect of habitat 
variables on their distribution. When sampling, you may count zero 
hippos at many sites, potentially resulting in overdispersed Poisson 
GLMs.  In such cases zero inflated models can be applied. During the 
course several case studies are presented, in which the statistical 
theory for zero inflated models is integrated with applied analyses in a 
clear and understandable manner. Zero inflated models consist of two 
integrated GLMs and therefore we will start with a revision of GLM. Zero 
inflated GLMMs for nested data (repeated measurements, short time 
series, clustered data, etc.) are discussed in the second part of the 
course. We will focus on zero inflated count data, and zero inflated 
continuous data.




-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


	[[alternative HTML version deleted]]


From thlytras at gmail.com  Tue May 24 21:56:24 2016
From: thlytras at gmail.com (Theodore Lytras)
Date: Tue, 24 May 2016 22:56:24 +0300
Subject: [R-sig-ME] Population weights in a Poisson model with overdispersion
Message-ID: <1691590.Mh2VqCj5hA@equinox2>

Dear all,

I am having some trouble with the correct specification of a Poisson model 
(with lme4), particularly with respect to weights. 

Each observation is a rate from a single physician: number of patients with 
ILI (influenza-like illness) / total patients. There are no fixed covariates; 
I am only interested in estimating an average rate for all physicians, with an 
intercept-only Poisson model. Observations are clustered within geographic 
areas (8 in total), and have a fair amount of overdispersion, which I am 
handling with an observation-level random effect.

Thus for one geographic area only (say "U1"), the appropriate model would be:

m.U1 <- glmer( gritot ~ 1 + (1|codeiat), offset=log(totvis), 
				data=datU1, family="poisson")

Where: gritot = number of patients with ILI, per physician
totvis = total patients per physician
codeiat = physician ID (observation ID), as an R factor

Now, for all geographic areas, I would guess the model should be:

m.all <- glmer( gritot ~ 1 + (1|codeiat) + (1|area), offset=log(totvis),
				data=dat, family="poisson")

Where: area = area code, also as an R factor

Each codeiat only occurs within a given area, so if I understand correctly my 
grouping factors are nested (codeiat nested within area). Note that I am also 
interested in estimating the average rate for each area.


Question 1: Unfortunately in the above model, the variance for area is very 
very small compared to the variance for codeiat. From the output of 
summary(m.all):

Random effects:
 Groups  Name        Variance  Std.Dev. 
 codeiat (Intercept) 7.690e-01 8.769e-01
 area    (Intercept) 1.557e-10 1.248e-05
Number of obs: 108, groups:  codeiat, 108; area, 8

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept) -2.16856    0.09294  -23.33   <2e-16 ***

Is there some way (i.e. some different random-effects specification) to 
prevent the observation-level random effect from "eating away" all the 
variance? 
Background theory suggests there is a single average rate (the fixed 
intercept), around which the rate per area varies, and there is a further 
variance per physician (codeiat) around the area-specific rate. Assigning all 
the variance to the physician and none to the geographic area makes no 
theoretical or practical sense.

For example, if I drop the random effect per physician (i.e. the observation 
level random effect):

m2 <- glmer( gritot ~ 1 + (1|area), offset=log(totvis), 
				data=dat, family="poisson")

the output becomes:

Random effects:
 Groups Name        Variance Std.Dev.
 area   (Intercept) 0.05958  0.2441  
Number of obs: 108, groups:  area, 8

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept) -1.95867    0.09237   -21.2   <2e-16 ***

This makes sense, but then how would I take account of the overdispersion 
**within** each geographic area?? Shouldn't I still need to specify an 
observation-level random effect somehow?? (One that does not "eat away" all 
the variance.)


Question 2: The 8 geographic areas have different population sizes, and I 
would like my fixed intercept (the average rate across the areas) to reflect 
this as well, i.e. observations from areas with big populations should weigh 
more than observations from areas with smaller populations. How would I assign 
weights to each observation, in order to get a population-weighted average 
rate as the fixed intercept of the model (also taking account of the 
overdispersion problem above)?? I am really really stuck on this one.

My initial thought would be to fit separate models for each area (with 
observation-level random-effect) and then combine the log rates (i.e. the 
fixed intercepts) in some second-level model (maybe Poisson with identity 
link??). But I have no idea how to combine the standard error of each rate and 
its population-specific weight (as offset? as weight?). And intuition tells me 
this should be possible to do within a single model.


I really appreciate any help!

Thank you so much,

Theodore Lytras

Epidemiologist, Department of Epidemiologic Surveillance,
Hellenic Centre of Disease Control and Prevention, Athens, Greece


From y.shinohara at aoni.waseda.jp  Wed May 25 04:42:10 2016
From: y.shinohara at aoni.waseda.jp (Yasuaki SHINOHARA)
Date: Wed, 25 May 2016 11:42:10 +0900
Subject: [R-sig-ME] Orthogonal vs. Non-orthogonal contrasts
Message-ID: <web-69184710@besv02.spw.secure-premium.ne.jp>

Dear all,

Hello, I am doing research of second language acquisition.
I am wondering about the glmer in R for my analyses. Could you please 
answer my question?

I have the following logistic mixed effects model.
model<-glmer(corr ~ A + B + C + D + A:B + B:C + A:D +(1+A|subject) + 
(1+A|item:speaker),family=binomial,data=mydata,control=glmerControl(optimizer="bobyqa", 
optCtrl=list(maxfun=1000)))

I tested language learners (subjects) three time (pre-training, 
mid-training, post-training) with the "item" produced by "speaker", so 
Factor A is "testing block" which has three levels (i.e., pre, mid, 
post).
Since each subject took the test three times, the random slopes for 
the Factor A were also included as a random factor.

I made an orthogonal contrast for the Factor A (testing block) as 
follows.
PreVsMid<-c(1,-1,0)
PreMidVsPost<-c(1,1,-2)
contrasts(mydata$A)<-cbind(PreVsMid,PreMidVsPost)

The results from summary(model) function for this factor were as 
follows.
pre vs. mid test: ? = 0.22, SE = 0.05, z = 4.34, p < 0.001
pre & mid vs. post test: ? = -0.21, SE = 0.04, z = -5.96, p < 0.001.

However, I thought it would be better if I made a non-orthogonal 
contrast for this factor as "pre vs. mid" and "pre vs. post" to test 
my hypothesis. So I made a new contrast for the Factor A as follows.
PreVsMid<-c(1,-1,0)
PreVsPost<-c(1,0,-1)
contrasts(mydata$A)<-cbind(PreVsMid,PreVsPost)

The results from summary(model) function for this contrast were
pre vs. mid test: ? = -0.01, SE = 0.04, z = -0.14, p > 0.05 (=0.89),
pre vs. post test: ? = 0.42, SE = 0.07, z = 5.96, p < 0.001.

Although the first contrast (pre vs. mid) is the same for both models, 
why the results of pre vs. mid contrast are so different (one is very 
significant, but the other one is not significant)?

I really appreciate any help.

Best wishes,
Yasu


From thierry.onkelinx at inbo.be  Wed May 25 09:44:14 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 25 May 2016 09:44:14 +0200
Subject: [R-sig-ME] Orthogonal vs. Non-orthogonal contrasts
In-Reply-To: <web-69184710@besv02.spw.secure-premium.ne.jp>
References: <web-69184710@besv02.spw.secure-premium.ne.jp>
Message-ID: <CAJuCY5zeexeXpPSto7hg=QAA-yGJ+rkE0PRqhaR=gJQjGLaFSg@mail.gmail.com>

Dear Yasu,

A is part of two interactions. Hence you cannot interpret this main effect
without the interactions. Note that changing the contrast will also effect
the interactions.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-05-25 4:42 GMT+02:00 Yasuaki SHINOHARA <y.shinohara at aoni.waseda.jp>:

> Dear all,
>
> Hello, I am doing research of second language acquisition.
> I am wondering about the glmer in R for my analyses. Could you please
> answer my question?
>
> I have the following logistic mixed effects model.
> model<-glmer(corr ~ A + B + C + D + A:B + B:C + A:D +(1+A|subject) +
> (1+A|item:speaker),family=binomial,data=mydata,control=glmerControl(optimizer="bobyqa",
> optCtrl=list(maxfun=1000)))
>
> I tested language learners (subjects) three time (pre-training,
> mid-training, post-training) with the "item" produced by "speaker", so
> Factor A is "testing block" which has three levels (i.e., pre, mid, post).
> Since each subject took the test three times, the random slopes for the
> Factor A were also included as a random factor.
>
> I made an orthogonal contrast for the Factor A (testing block) as follows.
> PreVsMid<-c(1,-1,0)
> PreMidVsPost<-c(1,1,-2)
> contrasts(mydata$A)<-cbind(PreVsMid,PreMidVsPost)
>
> The results from summary(model) function for this factor were as follows.
> pre vs. mid test: ? = 0.22, SE = 0.05, z = 4.34, p < 0.001
> pre & mid vs. post test: ? = -0.21, SE = 0.04, z = -5.96, p < 0.001.
>
> However, I thought it would be better if I made a non-orthogonal contrast
> for this factor as "pre vs. mid" and "pre vs. post" to test my hypothesis.
> So I made a new contrast for the Factor A as follows.
> PreVsMid<-c(1,-1,0)
> PreVsPost<-c(1,0,-1)
> contrasts(mydata$A)<-cbind(PreVsMid,PreVsPost)
>
> The results from summary(model) function for this contrast were
> pre vs. mid test: ? = -0.01, SE = 0.04, z = -0.14, p > 0.05 (=0.89),
> pre vs. post test: ? = 0.42, SE = 0.07, z = 5.96, p < 0.001.
>
> Although the first contrast (pre vs. mid) is the same for both models, why
> the results of pre vs. mid contrast are so different (one is very
> significant, but the other one is not significant)?
>
> I really appreciate any help.
>
> Best wishes,
> Yasu
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Wed May 25 09:54:54 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 25 May 2016 09:54:54 +0200
Subject: [R-sig-ME] Population weights in a Poisson model with
	overdispersion
In-Reply-To: <1691590.Mh2VqCj5hA@equinox2>
References: <1691590.Mh2VqCj5hA@equinox2>
Message-ID: <CAJuCY5ykbgyEj9yRoQZmHPBSU2QWjpQ9BKKSB+BdH+XvcpsM_A@mail.gmail.com>

Dear Theodore,

Given that the number of patients with a disease is bounded between 0 and
the total number of patients, a binomial distribution seems to be more
reasonable. That would probably handle the overdispersion as well.

Design based weights are not straightforward in generalised linear models.
You could consider calculating an weighted average based on the model
parameters.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-05-24 21:56 GMT+02:00 Theodore Lytras <thlytras at gmail.com>:

> Dear all,
>
> I am having some trouble with the correct specification of a Poisson model
> (with lme4), particularly with respect to weights.
>
> Each observation is a rate from a single physician: number of patients with
> ILI (influenza-like illness) / total patients. There are no fixed
> covariates;
> I am only interested in estimating an average rate for all physicians,
> with an
> intercept-only Poisson model. Observations are clustered within geographic
> areas (8 in total), and have a fair amount of overdispersion, which I am
> handling with an observation-level random effect.
>
> Thus for one geographic area only (say "U1"), the appropriate model would
> be:
>
> m.U1 <- glmer( gritot ~ 1 + (1|codeiat), offset=log(totvis),
>                                 data=datU1, family="poisson")
>
> Where: gritot = number of patients with ILI, per physician
> totvis = total patients per physician
> codeiat = physician ID (observation ID), as an R factor
>
> Now, for all geographic areas, I would guess the model should be:
>
> m.all <- glmer( gritot ~ 1 + (1|codeiat) + (1|area), offset=log(totvis),
>                                 data=dat, family="poisson")
>
> Where: area = area code, also as an R factor
>
> Each codeiat only occurs within a given area, so if I understand correctly
> my
> grouping factors are nested (codeiat nested within area). Note that I am
> also
> interested in estimating the average rate for each area.
>
>
> Question 1: Unfortunately in the above model, the variance for area is very
> very small compared to the variance for codeiat. From the output of
> summary(m.all):
>
> Random effects:
>  Groups  Name        Variance  Std.Dev.
>  codeiat (Intercept) 7.690e-01 8.769e-01
>  area    (Intercept) 1.557e-10 1.248e-05
> Number of obs: 108, groups:  codeiat, 108; area, 8
>
> Fixed effects:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept) -2.16856    0.09294  -23.33   <2e-16 ***
>
> Is there some way (i.e. some different random-effects specification) to
> prevent the observation-level random effect from "eating away" all the
> variance?
> Background theory suggests there is a single average rate (the fixed
> intercept), around which the rate per area varies, and there is a further
> variance per physician (codeiat) around the area-specific rate. Assigning
> all
> the variance to the physician and none to the geographic area makes no
> theoretical or practical sense.
>
> For example, if I drop the random effect per physician (i.e. the
> observation
> level random effect):
>
> m2 <- glmer( gritot ~ 1 + (1|area), offset=log(totvis),
>                                 data=dat, family="poisson")
>
> the output becomes:
>
> Random effects:
>  Groups Name        Variance Std.Dev.
>  area   (Intercept) 0.05958  0.2441
> Number of obs: 108, groups:  area, 8
>
> Fixed effects:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept) -1.95867    0.09237   -21.2   <2e-16 ***
>
> This makes sense, but then how would I take account of the overdispersion
> **within** each geographic area?? Shouldn't I still need to specify an
> observation-level random effect somehow?? (One that does not "eat away" all
> the variance.)
>
>
> Question 2: The 8 geographic areas have different population sizes, and I
> would like my fixed intercept (the average rate across the areas) to
> reflect
> this as well, i.e. observations from areas with big populations should
> weigh
> more than observations from areas with smaller populations. How would I
> assign
> weights to each observation, in order to get a population-weighted average
> rate as the fixed intercept of the model (also taking account of the
> overdispersion problem above)?? I am really really stuck on this one.
>
> My initial thought would be to fit separate models for each area (with
> observation-level random-effect) and then combine the log rates (i.e. the
> fixed intercepts) in some second-level model (maybe Poisson with identity
> link??). But I have no idea how to combine the standard error of each rate
> and
> its population-specific weight (as offset? as weight?). And intuition
> tells me
> this should be possible to do within a single model.
>
>
> I really appreciate any help!
>
> Thank you so much,
>
> Theodore Lytras
>
> Epidemiologist, Department of Epidemiologic Surveillance,
> Hellenic Centre of Disease Control and Prevention, Athens, Greece
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From savani1987 at gmail.com  Wed May 25 21:32:07 2016
From: savani1987 at gmail.com (Savani Anbalagan)
Date: Wed, 25 May 2016 21:32:07 +0200
Subject: [R-sig-ME] Advice for analysis of biological data - Mixed model or
	NESTED-Anova?
Message-ID: <CABm7sVMNK30qsN_wv4MiCmSo0aLoN8F9UheCirp6cxu_B+bPTw@mail.gmail.com>

Dear all,

I was suggested in the stack exchange.com to consult in this maling list.

I have data from image analysis of zebrafish brain structures. I will
discuss our data below with some analogy to make my explanation clear.

   1. Data model: Group>Animal 1..2...3....10>Volume 1..2..3.....1000
   2. Data model: Group>Drug treatment..1..2>Animal 1..2...3....10>Volume
   1..2..3.....1000
   3. I am studying axonal synapses in Brain.
   4. I have 3 or more groups (Genotypes: Wild type, Hetero, Homozygous
   mutant)
   5. Animals are sacrificied to image them.
   6. I have 10+ animals from each group.
   7. The number and volume of the synapses are variable.
   8. Within the group, some animals have 300 synapses, some have 450
   synapses.
   9. The volume of the synapses range from 0.2 to 50. The histrogram is
   highly skewed towards lower values. A log transformation makes it look more
   normal.
   10. Some times, we also treat the different groups to a drug. So, it
   makes another level.
   11.

Analogy:

   1. > (Imagine a tree with fruits of different sizes. And I am interested
   in the size of the fruits)
   2. >(Lets say, I have trees of different species. example Indian Mango
   vs Brazilian Mango vs another Mango)
   3. >(To collect fruits, The trees are cut. )
   4. >(10+ trees in each groups)
   5. >(The number of fruits vary depending on tree to tree even within
   same group. The size of the fruit varies. There are relatively too many
   small fruits).
   6. >(Some times, fertilizers are added to tree, and then effect of fruit
   count/size is also checked)

My questions:
Could you please let me know,


   1. Should I perform Nested ANOVA or Mixed model analysis?
   2. If mixed model design, should I run the analysis on log transformed
   data or raw data? Is the distribution important for mixed model analysis?
   3. If drug treatment is added, Is it Nested or Mixed model design?
   4. For mixed model analysis how can I calculate p-value? Could you
   please let me know for both the cases. For experiments, without any drug.
   And for experiments with the drug treated vs control.
   5. These are the codes that I use to analyze my data: Could you check if
   it is correct?


My nested anova code I use:
logGFPVol.anova = aov(logVolume ~ Group + Error(Animal_ID/Group), data=data)
summary(logGFPHBVol.anova)


Mixed model code:
model2=lmer(logVolume ~ Group + (1|Animal_ID/Group ), data=data, REML =
FALSE)
summary(model2)


Please feel free to ask if I am unclear.

Many thanks,
Savani

--------------------------------------------------------

*Savani Anbalagan, Ph.D*

*Dept. of Mol. Cell Biology*


*Weizmann Institute of Science234 Herzl St., Rehovot 76100,*


*ISRAELPhone: +972-8934-6158*

	[[alternative HTML version deleted]]


From epalmery at cns.umass.edu  Wed May 25 21:58:14 2016
From: epalmery at cns.umass.edu (Evan Palmer-Young)
Date: Wed, 25 May 2016 15:58:14 -0400
Subject: [R-sig-ME] Advice for analysis of biological data - Mixed model
 or NESTED-Anova?
In-Reply-To: <CABm7sVMNK30qsN_wv4MiCmSo0aLoN8F9UheCirp6cxu_B+bPTw@mail.gmail.com>
References: <CABm7sVMNK30qsN_wv4MiCmSo0aLoN8F9UheCirp6cxu_B+bPTw@mail.gmail.com>
Message-ID: <CAAge6+5JNobpf-nxHaOS0NL0k2YYBAX39MdEK7shM2rBsDnrFQ@mail.gmail.com>

Dear Savani,
I think you are on the right track. If you use function nlme, you can get
your p-values straightaway.
With lme4, you have to employ another function (Likelihood ratio test on
full and reduced models, or Wald tests with Anova in car) to extract them:
see:
http://www.inside-r.org/packages/cran/lme4/docs/pvalues

For your model coding, make sure that the biggest group is listed FIRST.
So for you:
model2=lmer(logVolume ~ Group + (1|Animal_ID/Group ), data=data, REML =
FALSE)
Instead use
brainmodel<-nlme(logVolume ~ Group , random= ~Group/Animal_ID)
See some examples under "model specification" on this very helpful page:
http://glmm.wikidot.com/faq

Here are some nlme examples:
http://www.stat.ubc.ca/~lang/Stat527a/ex4.r

Good luck!

On Wed, May 25, 2016 at 3:32 PM, Savani Anbalagan <savani1987 at gmail.com>
wrote:

> Dear all,
>
> I was suggested in the stack exchange.com to consult in this maling list.
>
> I have data from image analysis of zebrafish brain structures. I will
> discuss our data below with some analogy to make my explanation clear.
>
>    1. Data model: Group>Animal 1..2...3....10>Volume 1..2..3.....1000
>    2. Data model: Group>Drug treatment..1..2>Animal 1..2...3....10>Volume
>    1..2..3.....1000
>    3. I am studying axonal synapses in Brain.
>    4. I have 3 or more groups (Genotypes: Wild type, Hetero, Homozygous
>    mutant)
>    5. Animals are sacrificied to image them.
>    6. I have 10+ animals from each group.
>    7. The number and volume of the synapses are variable.
>    8. Within the group, some animals have 300 synapses, some have 450
>    synapses.
>    9. The volume of the synapses range from 0.2 to 50. The histrogram is
>    highly skewed towards lower values. A log transformation makes it look
> more
>    normal.
>    10. Some times, we also treat the different groups to a drug. So, it
>    makes another level.
>    11.
>
> Analogy:
>
>    1. > (Imagine a tree with fruits of different sizes. And I am interested
>    in the size of the fruits)
>    2. >(Lets say, I have trees of different species. example Indian Mango
>    vs Brazilian Mango vs another Mango)
>    3. >(To collect fruits, The trees are cut. )
>    4. >(10+ trees in each groups)
>    5. >(The number of fruits vary depending on tree to tree even within
>    same group. The size of the fruit varies. There are relatively too many
>    small fruits).
>    6. >(Some times, fertilizers are added to tree, and then effect of fruit
>    count/size is also checked)
>
> My questions:
> Could you please let me know,
>
>
>    1. Should I perform Nested ANOVA or Mixed model analysis?
>    2. If mixed model design, should I run the analysis on log transformed
>    data or raw data? Is the distribution important for mixed model
> analysis?
>    3. If drug treatment is added, Is it Nested or Mixed model design?
>    4. For mixed model analysis how can I calculate p-value? Could you
>    please let me know for both the cases. For experiments, without any
> drug.
>    And for experiments with the drug treated vs control.
>    5. These are the codes that I use to analyze my data: Could you check if
>    it is correct?
>
>
> My nested anova code I use:
> logGFPVol.anova = aov(logVolume ~ Group + Error(Animal_ID/Group),
> data=data)
> summary(logGFPHBVol.anova)
>
>
> Mixed model code:
> model2=lmer(logVolume ~ Group + (1|Animal_ID/Group ), data=data, REML =
> FALSE)
> summary(model2)
>
>
> Please feel free to ask if I am unclear.
>
> Many thanks,
> Savani
>
> --------------------------------------------------------
>
> *Savani Anbalagan, Ph.D*
>
> *Dept. of Mol. Cell Biology*
>
>
> *Weizmann Institute of Science234 Herzl St., Rehovot 76100,*
>
>
> *ISRAELPhone: +972-8934-6158*
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Department of Biology
221 Morrill Science Center
611 North Pleasant St
Amherst MA 01003
https://sites.google.com/a/cornell.edu/evan-palmer-young/

	[[alternative HTML version deleted]]


From y.shinohara at aoni.waseda.jp  Thu May 26 06:31:40 2016
From: y.shinohara at aoni.waseda.jp (Yasuaki SHINOHARA)
Date: Thu, 26 May 2016 13:31:40 +0900
Subject: [R-sig-ME] Orthogonal vs. Non-orthogonal contrasts
In-Reply-To: <CAJuCY5zeexeXpPSto7hg=QAA-yGJ+rkE0PRqhaR=gJQjGLaFSg@mail.gmail.com>
References: <web-69184710@besv02.spw.secure-premium.ne.jp>
	<CAJuCY5zeexeXpPSto7hg=QAA-yGJ+rkE0PRqhaR=gJQjGLaFSg@mail.gmail.com>
Message-ID: <web-69429660@besv04.spw.secure-premium.ne.jp>

Dear Thierry,

Thank you very much for your reply.
I understood why. The interaction of blockPreVsMid:FactorD turned 
significant in the model which contrasted the testing block factor as 
PreVsMid and PreVsPost (i.e.,cbind(c(1,-1,0),c(-1,0,1))), although the 
interaction was not significant in the model with the testing block 
contrasted as PreVsMid and PreMidVsPost (i.e., 
cbind(c(1,-1,0),c(1,1,-2))).

Could I ask another question?
What is the difference in making a contrast of PreVsMid as c(1,-1,0) 
and as c(0.5, -0.5, 0)?
It seems that the beta and SE are double if I code the contrasts with 
(0.5, -0.5, 0). I hope it does not matter.

Also, I coded "contrasts(data$FactorA)<-cbind(c(1,-1,0),c(-1,0,1))" to 
test the differences between the mean of level 1 vs. the mean of level 
2 and between the mean of level 1 and the mean of level 3. Is this 
correct? Some website says something different from what I understood 
(e.g., the first Answer of 
http://stats.stackexchange.com/questions/44527/contrast-for-hypothesis-test-in-r-lmer 
).

My model includes both categorical and numeric variable, and all 
categorical variables were coded manually.

Best wishes,
Yasu

On Wed, 25 May 2016 09:44:14 +0200
  Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
> Dear Yasu,
> 
> A is part of two interactions. Hence you cannot interpret this main 
>effect
> without the interactions. Note that changing the contrast will also 
>effect
> the interactions.
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for 
>Nature and
>Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality 
>Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no 
>more
> than asking him to perform a post-mortem examination: he may be able 
>to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does 
>not
> ensure that a reasonable answer can be extracted from a given body 
>of data.
> ~ John Tukey
> 
> 2016-05-25 4:42 GMT+02:00 Yasuaki SHINOHARA 
><y.shinohara at aoni.waseda.jp>:
> 
>> Dear all,
>>
>> Hello, I am doing research of second language acquisition.
>> I am wondering about the glmer in R for my analyses. Could you 
>>please
>> answer my question?
>>
>> I have the following logistic mixed effects model.
>> model<-glmer(corr ~ A + B + C + D + A:B + B:C + A:D +(1+A|subject) +
>> (1+A|item:speaker),family=binomial,data=mydata,control=glmerControl(optimizer="bobyqa",
>> optCtrl=list(maxfun=1000)))
>>
>> I tested language learners (subjects) three time (pre-training,
>> mid-training, post-training) with the "item" produced by "speaker", 
>>so
>> Factor A is "testing block" which has three levels (i.e., pre, mid, 
>>post).
>> Since each subject took the test three times, the random slopes for 
>>the
>> Factor A were also included as a random factor.
>>
>> I made an orthogonal contrast for the Factor A (testing block) as 
>>follows.
>> PreVsMid<-c(1,-1,0)
>> PreMidVsPost<-c(1,1,-2)
>> contrasts(mydata$A)<-cbind(PreVsMid,PreMidVsPost)
>>
>> The results from summary(model) function for this factor were as 
>>follows.
>> pre vs. mid test: ? = 0.22, SE = 0.05, z = 4.34, p < 0.001
>> pre & mid vs. post test: ? = -0.21, SE = 0.04, z = -5.96, p < 0.001.
>>
>> However, I thought it would be better if I made a non-orthogonal 
>>contrast
>> for this factor as "pre vs. mid" and "pre vs. post" to test my 
>>hypothesis.
>> So I made a new contrast for the Factor A as follows.
>> PreVsMid<-c(1,-1,0)
>> PreVsPost<-c(1,0,-1)
>> contrasts(mydata$A)<-cbind(PreVsMid,PreVsPost)
>>
>> The results from summary(model) function for this contrast were
>> pre vs. mid test: ? = -0.01, SE = 0.04, z = -0.14, p > 0.05 (=0.89),
>> pre vs. post test: ? = 0.42, SE = 0.07, z = 5.96, p < 0.001.
>>
>> Although the first contrast (pre vs. mid) is the same for both 
>>models, why
>> the results of pre vs. mid contrast are so different (one is very
>> significant, but the other one is not significant)?
>>
>> I really appreciate any help.
>>
>> Best wishes,
>> Yasu
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>


************************************
Yasuaki SHINOHARA, Ph.D.
Assistant Professor
Center for English Language Education (CELESE)
Waseda University Faculty of Science and Engineering
3-4-1 Okubo, Shinjuku-ku, 169-8555, Tokyo JAPAN
email: y.shinohara at aoni.waseda.jp


From thierry.onkelinx at inbo.be  Thu May 26 08:53:44 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 26 May 2016 08:53:44 +0200
Subject: [R-sig-ME] Orthogonal vs. Non-orthogonal contrasts
In-Reply-To: <web-69429660@besv04.spw.secure-premium.ne.jp>
References: <web-69184710@besv02.spw.secure-premium.ne.jp>
	<CAJuCY5zeexeXpPSto7hg=QAA-yGJ+rkE0PRqhaR=gJQjGLaFSg@mail.gmail.com>
	<web-69429660@besv04.spw.secure-premium.ne.jp>
Message-ID: <CAJuCY5wT0XwAeD9q5Uq6Dk+K_PdhrXNDJfni9-86F4r5wGKYoQ@mail.gmail.com>

Dear Yasu,

The contrast x = c(1, -1, 0) is equivalent to beta_x * 1 * a_1 + beta_x *
(-1) * a_2 + beta_x * 0 * a_3.
Likewise contrast y = c(.5, -.5, 0) is equivalent to beta_y * 0.5 * a_1 +
beta_y * (-0.5) * a_2 + beta_y * 0 * a_3.

Since both model the same thing beta_x * 1 * a_1 + beta_x * (-1) * a_2 +
beta_x * 0 * a_3 = beta_y * 0.5 * a_1 + beta_y * (-0.5) * a_2 + beta_y * 0
* a_3.
Some simple math will show that beta_x = 2 * beta_y

Your contrasts are correct but pointless given your model. They are only
meaningful in case FactorA is only a main effect. You included FactorA in
some interactions as well. So you'll need to define contrasts on the full
set of fixed parameters to get some sensible results. You can do that with
the multcomp package. I would also suggest that you find some local
statistician to help you define the contrasts relevant for your model.

Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-05-26 6:31 GMT+02:00 Yasuaki SHINOHARA <y.shinohara at aoni.waseda.jp>:

> Dear Thierry,
>
> Thank you very much for your reply.
> I understood why. The interaction of blockPreVsMid:FactorD turned
> significant in the model which contrasted the testing block factor as
> PreVsMid and PreVsPost (i.e.,cbind(c(1,-1,0),c(-1,0,1))), although the
> interaction was not significant in the model with the testing block
> contrasted as PreVsMid and PreMidVsPost (i.e., cbind(c(1,-1,0),c(1,1,-2))).
>
> Could I ask another question?
> What is the difference in making a contrast of PreVsMid as c(1,-1,0) and
> as c(0.5, -0.5, 0)?
> It seems that the beta and SE are double if I code the contrasts with
> (0.5, -0.5, 0). I hope it does not matter.
>
> Also, I coded "contrasts(data$FactorA)<-cbind(c(1,-1,0),c(-1,0,1))" to
> test the differences between the mean of level 1 vs. the mean of level 2
> and between the mean of level 1 and the mean of level 3. Is this correct?
> Some website says something different from what I understood (e.g., the
> first Answer of
> http://stats.stackexchange.com/questions/44527/contrast-for-hypothesis-test-in-r-lmer
> ).
>
> My model includes both categorical and numeric variable, and all
> categorical variables were coded manually.
>
> Best wishes,
> Yasu
>
>
> On Wed, 25 May 2016 09:44:14 +0200
>  Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
>
>> Dear Yasu,
>>
>> A is part of two interactions. Hence you cannot interpret this main effect
>> without the interactions. Note that changing the contrast will also effect
>> the interactions.
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
>> Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to
>> say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of
>> data.
>> ~ John Tukey
>>
>> 2016-05-25 4:42 GMT+02:00 Yasuaki SHINOHARA <y.shinohara at aoni.waseda.jp>:
>>
>> Dear all,
>>>
>>> Hello, I am doing research of second language acquisition.
>>> I am wondering about the glmer in R for my analyses. Could you please
>>> answer my question?
>>>
>>> I have the following logistic mixed effects model.
>>> model<-glmer(corr ~ A + B + C + D + A:B + B:C + A:D +(1+A|subject) +
>>>
>>> (1+A|item:speaker),family=binomial,data=mydata,control=glmerControl(optimizer="bobyqa",
>>> optCtrl=list(maxfun=1000)))
>>>
>>> I tested language learners (subjects) three time (pre-training,
>>> mid-training, post-training) with the "item" produced by "speaker", so
>>> Factor A is "testing block" which has three levels (i.e., pre, mid,
>>> post).
>>> Since each subject took the test three times, the random slopes for the
>>> Factor A were also included as a random factor.
>>>
>>> I made an orthogonal contrast for the Factor A (testing block) as
>>> follows.
>>> PreVsMid<-c(1,-1,0)
>>> PreMidVsPost<-c(1,1,-2)
>>> contrasts(mydata$A)<-cbind(PreVsMid,PreMidVsPost)
>>>
>>> The results from summary(model) function for this factor were as follows.
>>> pre vs. mid test: ? = 0.22, SE = 0.05, z = 4.34, p < 0.001
>>> pre & mid vs. post test: ? = -0.21, SE = 0.04, z = -5.96, p < 0.001.
>>>
>>> However, I thought it would be better if I made a non-orthogonal contrast
>>> for this factor as "pre vs. mid" and "pre vs. post" to test my
>>> hypothesis.
>>> So I made a new contrast for the Factor A as follows.
>>> PreVsMid<-c(1,-1,0)
>>> PreVsPost<-c(1,0,-1)
>>> contrasts(mydata$A)<-cbind(PreVsMid,PreVsPost)
>>>
>>> The results from summary(model) function for this contrast were
>>> pre vs. mid test: ? = -0.01, SE = 0.04, z = -0.14, p > 0.05 (=0.89),
>>> pre vs. post test: ? = 0.42, SE = 0.07, z = 5.96, p < 0.001.
>>>
>>> Although the first contrast (pre vs. mid) is the same for both models,
>>> why
>>> the results of pre vs. mid contrast are so different (one is very
>>> significant, but the other one is not significant)?
>>>
>>> I really appreciate any help.
>>>
>>> Best wishes,
>>> Yasu
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>
> ************************************
> Yasuaki SHINOHARA, Ph.D.
> Assistant Professor
> Center for English Language Education (CELESE)
> Waseda University Faculty of Science and Engineering
> 3-4-1 Okubo, Shinjuku-ku, 169-8555, Tokyo JAPAN
> email: y.shinohara at aoni.waseda.jp
>

	[[alternative HTML version deleted]]


From savani1987 at gmail.com  Thu May 26 11:17:51 2016
From: savani1987 at gmail.com (Savani Anbalagan)
Date: Thu, 26 May 2016 11:17:51 +0200
Subject: [R-sig-ME] Advice for analysis of biological data - Mixed model
 or NESTED-Anova?
In-Reply-To: <CAAge6+5JNobpf-nxHaOS0NL0k2YYBAX39MdEK7shM2rBsDnrFQ@mail.gmail.com>
References: <CABm7sVMNK30qsN_wv4MiCmSo0aLoN8F9UheCirp6cxu_B+bPTw@mail.gmail.com>
	<CAAge6+5JNobpf-nxHaOS0NL0k2YYBAX39MdEK7shM2rBsDnrFQ@mail.gmail.com>
Message-ID: <CABm7sVNZ9QetoFqd0aXcsBEqPAfg2R=Ji+n4L96HWfzhTjyMbA@mail.gmail.com>

Hi Evan,

Thanks a lot.
When you say the biggest group. I assume it is just about the number of
animals in the group. Not about about the total number of observations for
a group.

And, when I run the code, I get the error

?
brainmodel<-nlme(logVolume ~ Group , random= ~Group/Animal_ID,
?
data=dat)
Error in model[[3]][[1]] : object of type 'symbol' is not subsettable

And

In the full or reduced models with lme4: What might be an reduced model in
my case?
Because, in expt design 1 : I only have 3 groups.


thanks,
Savani



On 25 May 2016 at 21:58, Evan Palmer-Young <epalmery at cns.umass.edu> wrote:

> Dear Savani,
> I think you are on the right track. If you use function nlme, you can get
> your p-values straightaway.
> With lme4, you have to employ another function (Likelihood ratio test on
> full and reduced models, or Wald tests with Anova in car) to extract them:
> see:
> http://www.inside-r.org/packages/cran/lme4/docs/pvalues
>
> For your model coding, make sure that the biggest group is listed FIRST.
> So for you:
> model2=lmer(logVolume ~ Group + (1|Animal_ID/Group ),
> ??
> data=dat, REML =
> FALSE)
> Instead use
> ??
> brainmodel<-nlme(logVolume ~ Group , random= ~Group/Animal_ID)
> See some examples under "model specification" on this very helpful page:
> http://glmm.wikidot.com/faq
>
> Here are some nlme examples:
> http://www.stat.ubc.ca/~lang/Stat527a/ex4.r
>
> Good luck!
>
> On Wed, May 25, 2016 at 3:32 PM, Savani Anbalagan <savani1987 at gmail.com>
> wrote:
>
>> Dear all,
>>
>> I was suggested in the stack exchange.com to consult in this maling list.
>>
>> I have data from image analysis of zebrafish brain structures. I will
>> discuss our data below with some analogy to make my explanation clear.
>>
>>    1. Data model: Group>Animal 1..2...3....10>Volume 1..2..3.....1000
>>    2. Data model: Group>Drug treatment..1..2>Animal 1..2...3....10>Volume
>>    1..2..3.....1000
>>    3. I am studying axonal synapses in Brain.
>>    4. I have 3 or more groups (Genotypes: Wild type, Hetero, Homozygous
>>    mutant)
>>    5. Animals are sacrificied to image them.
>>    6. I have 10+ animals from each group.
>>    7. The number and volume of the synapses are variable.
>>    8. Within the group, some animals have 300 synapses, some have 450
>>    synapses.
>>    9. The volume of the synapses range from 0.2 to 50. The histrogram is
>>    highly skewed towards lower values. A log transformation makes it look
>> more
>>    normal.
>>    10. Some times, we also treat the different groups to a drug. So, it
>>    makes another level.
>>    11.
>>
>> Analogy:
>>
>>    1. > (Imagine a tree with fruits of different sizes. And I am
>> interested
>>    in the size of the fruits)
>>    2. >(Lets say, I have trees of different species. example Indian Mango
>>    vs Brazilian Mango vs another Mango)
>>    3. >(To collect fruits, The trees are cut. )
>>    4. >(10+ trees in each groups)
>>    5. >(The number of fruits vary depending on tree to tree even within
>>    same group. The size of the fruit varies. There are relatively too many
>>    small fruits).
>>    6. >(Some times, fertilizers are added to tree, and then effect of
>> fruit
>>    count/size is also checked)
>>
>> My questions:
>> Could you please let me know,
>>
>>
>>    1. Should I perform Nested ANOVA or Mixed model analysis?
>>    2. If mixed model design, should I run the analysis on log transformed
>>    data or raw data? Is the distribution important for mixed model
>> analysis?
>>    3. If drug treatment is added, Is it Nested or Mixed model design?
>>    4. For mixed model analysis how can I calculate p-value? Could you
>>    please let me know for both the cases. For experiments, without any
>> drug.
>>    And for experiments with the drug treated vs control.
>>    5. These are the codes that I use to analyze my data: Could you check
>> if
>>    it is correct?
>>
>>
>> My nested anova code I use:
>> logGFPVol.anova = aov(logVolume ~ Group + Error(Animal_ID/Group),
>> data=data)
>> summary(logGFPHBVol.anova)
>>
>>
>> Mixed model code:
>> model2=lmer(logVolume ~ Group + (1|Animal_ID/Group ), data=data, REML =
>> FALSE)
>> summary(model2)
>>
>>
>> Please feel free to ask if I am unclear.
>>
>> Many thanks,
>> Savani
>>
>> --------------------------------------------------------
>>
>> *Savani Anbalagan, Ph.D*
>>
>> *Dept. of Mol. Cell Biology*
>>
>>
>> *Weizmann Institute of Science234 Herzl St., Rehovot 76100,*
>>
>>
>> *ISRAELPhone: +972-8934-6158*
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
> Department of Biology
> 221 Morrill Science Center
> 611 North Pleasant St
> Amherst MA 01003
> https://sites.google.com/a/cornell.edu/evan-palmer-young/
>

	[[alternative HTML version deleted]]


From robgriffin247 at hotmail.com  Fri May 27 12:44:26 2016
From: robgriffin247 at hotmail.com (Rob Griffin)
Date: Fri, 27 May 2016 12:44:26 +0200
Subject: [R-sig-ME] Interpreting fixed effects of mcmcglmm interaction
 and randomisation
In-Reply-To: <5739F4A3.1000903@ed.ac.uk>
References: <DUB124-W46D7062EBC22B90C54F7D9FA740@phx.gbl>,
	<5739F4A3.1000903@ed.ac.uk>
Message-ID: <DUB124-W49CD3D7E93AE7CF2936082FA420@phx.gbl>

When you suggest "Mort*SexF" do you mean 
mod1 = MCMCglmm(Life ~ Mort*Sex,
... such that the "-1" is removed from my original model specification?
Furthermore, if I added a second categorical fixed effect (e.g. whether the individual had 0, 1, or >1 older siblings [ie. whether it was the first, second, or a later offspring]) would the calculations for predictions be
first born & female: (b1 + b2) * xfirst born & male: (b1 + b3) + (b2 + b6) * xsecond born & female: (b1 + b5) + (b2 + b8) * xsecond born & male: (b1 + b3 + b5 + b10) + (b2 + b6 + b8 + b12) * xlater & female: (b1 + b4) + (b2 + b7) * xlater & male: (b1 + b3 + b4 + b9) + (b2 + b6 + b7 + b11) * x
where 
b1 = (Intercept),   b2 = Mort,   b3 = SexM,   b4 = GroupLater,   b5 = GroupSecond,   b6 = Mort:SexM,   b7 = Mort:GroupLater,   b8 = Mort:GroupSecond,   b9 = SexM:GroupLater,   b10 = SexM:GroupSecond,   b11 = Mort:SexM:GroupLater,   b12 = Mort:SexM:GroupSecond
and should I include all or just the significant effects?
Cheers, Rob
----------------------------------------------------------
Robert M. GriffinPostdoctoral Researcher, University of Turkuwww.griffinevo.wordpress.com 

> Subject: Re: [R-sig-ME] Interpreting fixed effects of mcmcglmm interaction and randomisation
> To: robgriffin247 at hotmail.com; r-sig-mixed-models at r-project.org
> From: j.hadfield at ed.ac.uk
> Date: Mon, 16 May 2016 17:26:11 +0100
> 
> Hi,
> 
> You should use ~Mort*SexF. At the moment you force the male and female 
> intercepts through the origin. You will get four terms; an intercept and
> Mort effect (which are the female intercpet and slope) and a SexM and 
> Mort:SexM effect (which are the deviations of the male inetcept and 
> slope from the female intercept and slope. The two lines will cross at 
> some value of Mort. If we denote the four effects as b1 (intercept), b2 
> (Mort), b3 (SexM) and b4 (Mort:SexM) and a value of Mort as x then
> 
> female prediction  = b1+b2*x
> male prediction  = b1+b3+(b2+b4)*x
> 
> and so the value of x when female prediction = male prediction is -b3/b4
> 
> You could test whether the posterior distribution of -b3/b4 lies outside
> the range of observed x in which case sexual-dimorophism always 
> increases as x (if -b3/b4 is smaller than the minimum of x) increases or
> always increases as x (if -b3/b4 is larger than the maximum of x) 
> decreases. If -b3/b4 lies at intermediate values of x the change in 
> sexual dimorphism will flip across the range of x.
> 
> Cheers,
> 
> Jarrod
> 
> 
> 
> 
> On 13/05/2016 13:51, Rob Griffin wrote:
> > Dear list,
> >
> > I am trying learn how to model the relationship between an environmental factor and sexual dimorphism using MCMCglmm, and have based analysis on the data in Garratt et al 2015* - a study looking at the relationship between sexual dimorphism in lifespan, and juvenile mortality. They use two populations measured over a number of years, giving cohorts (for which juvenile mortality can be estimated), and information on the identity, lifespan, and sex of each individual. The script below** creates the dummy data I am using to develop the model which is similar to the data set they would have used (though entirely artificial - I have forced a positive relationship between juvenile mortality and male lifespan, while female lifespan is random).  They fit a general linear mixed model to "assess the relationship between survival to the onset of actuarial senescence (dependent variable) and cohort-specific juvenile mortality (independent variable), while including sex as a fixed effect, year and population as random effects, with year nested within population." I have attempted to recreate this analysis (but using MCMCglmm) as the following (where 'Life' is lifespan, 'Mort' is juvenile mortality within the individuals cohort, 'Sex' is the sex of the individual, 'Pop' and 'Year' are the population and year of the individual):
> >
> >
> > mod1 = MCMCglmm(Life ~ Mort:Sex - 1,
> > random = ~ Pop:Year,
> > rcov = ~units,	
> > nitt =   13000, burnin = 3000, thin =   10,
> > prior = prior1,
> > pr = T,
> > family = "gaussian",
> > start = list(QUASI = FALSE),
> > data = DF1)	
> >
> >> summary(mod1)
> >   Iterations = 3001:12991
> >   Thinning interval  = 10
> >   Sample size  = 1000
> >
> >   DIC: 1437.558
> >
> >   G-structure:  ~Pop:Year
> >
> >           post.mean l-95% CI u-95% CI eff.samp
> > Pop:Year     34.23     19.4     55.2     1000
> >
> >   R-structure:  ~units
> >
> >        post.mean l-95% CI u-95% CI eff.samp
> > units     4.746    3.946    5.487    909.7
> >
> >   Location effects: Life ~ Mort:Sex - 1
> >
> >            post.mean l-95% CI u-95% CI eff.samp  pMCMC
> > Mort:SexF     25.17    20.61    30.46     1000 <0.001 ***
> > Mort:SexM     43.81    38.82    48.71     1000 <0.001 ***
> > ---
> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> >
> > Which brings me to my main subject(s) of interest: essentially, how to interpret the fixed effect estimates, given that I am aiming to answer the question, is juvenile mortality related to sexual dimorphism in lifespan?
> >
> > Going from 'Life ~ Mort -1' to 'Life ~ Mort:Sex -1' improves the fit of the model (DIC 1902 -> 1438), so could I conclude that there is a significant sex-specific effect/interaction with juvenile mortality on lifespan? What do the actual values of the posterior mean (post.mean) tell me - is it just that the Mort:SexM interaction effect is significantly larger than the Mort:SexF effect (CI's of the two estimates do not overlap)? Using Mort*Sex gives SexM and SexF estimates which seem to better reflect the true mean values of the population, where the post.means of Mort is ~0, SexF and SexM are ~12, and the Mort:SexM fixed effect is ~18, which makes me more inclined to think that Mort*Sex is a more appropriate model (but brings up the question what does the post.mean of ~18 for Mort:SexM actually mean?).
> >
> > I have also done randomisation where I randomise the mortality rates among cohorts for 50 chains, in the 'Mort:Sex' model this results in the Mort:SexF and Mort:SexM estimates remaining similar to the raw data model - does randomisation offer insight in to the relationship between sexual dimorphism and juvenile mortality? Using a model where 'Mort*Sex' is the fixed effect then the randomisation shifts the estimates of Mort:SexM to ~0, and that difference is absorbed in to the SexM fixed effect (because there is sexual dimorphism, but the relationship to juvenile mortality disappears). Could I effectively use this as a kind of significance test (e.g. I do 1000 randomisations, the mean Mort:SexM estimate is> the actual estimate in 11/1000 cases, thus pseudo-p is ~0.011).
> >
> > Finally, (and on a slightly different topic) I have used 'pr = T' which means I can get posterior distributions for each level of the Pop:Year combination - i.e. a posterior distribution for each cohort. Could this information be used to get an estimate of the sex-specific lifespans for each population? For example, summing the posterior distribution of 'Mort:SexM' with 'Pop:Year.A.1983' would give a distribution of the estimated lifespan for males in population A for the year 1983? I don't think this is the case - as the numbers seem too different from the data - so how could I derive cohort-sex-specific lifespans?
> >
> > Long story short - I'm looking for some insight on how to correctly define and interpret the fixed effects... Overall I'm inclined to think that 'Mort*Sex' gives the correct specification of the model, and the randomisation shows whether the environmental factor has an effect on sexual dimorphism.
> > Thanks - full script below,
> > Rob
> >
> > * Garratt et al 2015, Current Biology "High juvenile mortality is associated with sex-specific adult survival and lifespan in wild roe deer."
> >
> > **
> > #### R-SCRIPT ####
> > rm(list=ls())
> > set.seed(255)
> > library("reshape")
> > library("MCMCglmm")
> >
> > DF1 = data.frame(c(1:320), rep(c("A", "B"), each = 10), rep(1983:1998, each = 20), sample(c("M", "F"), replace = T, size = 320), rnorm(320, 12, 2), rep((1/(1+abs(rnorm(16, 2, 1 )))), each = 20))
> > colnames(DF1) = c("ID", "Pop", "Year", "Sex", "Life", "Mort")
> >
> > # Make SD related to juvenile mortality
> > DF1$Life = ifelse(DF1$Sex == "M", DF1$Life + DF1$Mort*18, DF1$Life)
> > # Mean zero, unit variance
> > DF1$Life0 = (DF1$Life-mean(DF1$Life))/sqrt(var(DF1$Life))
> >
> > prior1 = list(	G = list(G1 = list(V = 1, nu = 1, alpha.mu = 0, alpha.V = 1000)),
> > R = list(V = 1, nu = 0.002))
> >
> > mod1 = MCMCglmm(Life ~ Mort:Sex - 1,
> > random = ~ Pop:Year,
> > rcov = ~units,	
> > nitt =   13000, burnin = 3000, thin =  10,
> > prior = prior1,
> > pr = T,
> > family = "gaussian",
> > start = list(QUASI = FALSE),
> > data = DF1)	
> >
> > summary(mod1)
> >
> >
> >
> > ----------------------------------------------------------
> >
> > Robert M. Griffin
> > Postdoctoral Researcher, University of Turku
> > www.griffinevo.wordpress.com  		 	   		
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
> 
> 
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
> 
 		 	   		  
	[[alternative HTML version deleted]]


From harietrose123 at gmail.com  Sun May 29 18:24:02 2016
From: harietrose123 at gmail.com (Hariet Rose)
Date: Mon, 30 May 2016 02:24:02 +1000
Subject: [R-sig-ME] nesting hierarchy in glmer
Message-ID: <CAGPdvCdea6Bb_=Bd1+D6wQ3RjHcf0yq-c5pDjo8JYTvuX6_qKQ@mail.gmail.com>

Hi, I am a newbie at posting on this forum and relatively new to R.  My
question is about nesting in glmer and examples on the forums do not
correspond to my experiment, especially as I think I could run my design as
two separate analyses.


I have a glasshouse complex study where I have six independent rooms. Three
rooms were randomly chosen to be set at the hot temperature for the
duration of the experiment, and another three rooms were randomly chosen
and set at a cold temperature for the duration of the experiment (13
weeks).  This is why I think I could run two separate models

.

[There were other rooms that I didn?t use although they were ?available? to
be chosen randomly].


 For my question, I want to know if two populations (pops = pop1, pop2) of
seedlings respond in different ways to 3 water dosages under the
temperature regimes. The rooms were stocked evenly with seedlings from two
different populations of the same species; each seedling in each room
received only 1 of 3 water doses; local, wet or dry.  I measured
survivorship of seedlings at week 13 and the response was 1 = alive or 0 =
dead.  In the models below ?id? is the code I have given to all plants that
received the same treatment within a room (e.g.id 1=  replicate 1, all
plants from pop1 in room1 (hot)  that received the local water treatment)..


As all seedlings died when the following treatments were applied;  hot +
dry, hot +local and cool + dry, I have a very skewed response.  This
suggests to me that some model simplification may be possible...


Because the two temperatures could be seen as independent experiments and
because of the skewed response I am thinking it would be simpler to run two
separate models, one for the cool rooms and another for the hot rooms;


R version 3.1.3 (2015-03-09), library(lme4)

coolmodel <- glmer(survivorship ~ room*pops*dose * (1|room/id), family
= binomial, data = mydata1)

 mydata1 is a matrix of cool room data only and the samples from the
dry dose treatment have been removed (i.e., both pops of dry dosed
plants died).

hotmodel <- glmer(survivorship ~ room*pops * (1|room/id), family =
binomial, data = mydata2)

mydata2 is a matrix of hot room data only and the samples from the dry
and local have been removed (i.e., both pops of dry and local dosed
plants died)

in the above model, because there were only survivors for one dose
(wet) I have not specified the fixed effect of dose.

Question 1. Is the above approach correct? I am concerned that the
nesting of id may be incorrect.

For the combined cool and hot room data set, I have used this model

bothtempsmodel <- glmer(survivorship ~ temp*pops*dose *
(1|temp/room/id), family = binomial, data = mydata)

where mydata has all samples from all temps, rooms, and treatments ?
i.e., no data have been removed.


Question 2. In the bothtempsmodel, if I have explained the nesting and
everything else correctly, I end up with many significant two and the
three way interaction/s whereas coolmodel and hotmodel have outputs
that are simplified.
Would a strategy be to specify the full model (bothtempsmodel) and
then go on to explain and implement the simplified coolmodel and
hotmodel, with the removal of data as explained above.

 I can post the outputs if anyone is interested..

 Thank you very much for your time.. :) hariet-rose

	[[alternative HTML version deleted]]


From y.shinohara at aoni.waseda.jp  Mon May 30 09:30:40 2016
From: y.shinohara at aoni.waseda.jp (Yasuaki SHINOHARA)
Date: Mon, 30 May 2016 16:30:40 +0900
Subject: [R-sig-ME] Orthogonal vs. Non-orthogonal contrasts
In-Reply-To: <CAJuCY5wT0XwAeD9q5Uq6Dk+K_PdhrXNDJfni9-86F4r5wGKYoQ@mail.gmail.com>
References: <web-69184710@besv02.spw.secure-premium.ne.jp>
	<CAJuCY5zeexeXpPSto7hg=QAA-yGJ+rkE0PRqhaR=gJQjGLaFSg@mail.gmail.com>
	<web-69429660@besv04.spw.secure-premium.ne.jp>
	<CAJuCY5wT0XwAeD9q5Uq6Dk+K_PdhrXNDJfni9-86F4r5wGKYoQ@mail.gmail.com>
Message-ID: <web-69842955@besv03.spw.secure-premium.ne.jp>

Dear Thierry,

Thank you very much for your reply.

I understood that the results of each main fixed factor (e.g., Factor 
A, B, C and D) are pointless, since the interaction factors affected 
the results of the main fixed factors. Actually, I manually coded the 
contrasts for all the fixed factors based on the hypothesis I wanted 
to test, as follows.

#Factor A (testing block)
PreVsMid<-c(1,-1,0)
PreVsPost<-c(-1,0,1)
contrasts(alldata$FactorA)<-cbind(PreVsMid,PreVsPost)
#Factor B (Trainer order)
IDVsDIS<-c(1,-1)
contrasts(alldata$FactorB)<-cbind(IDVsDIS)
#Factor C (Phonetic environment)
IniVsMid<-c(1,-1,0)
IniVsCls<-c(-1,0,1)
contrasts(alldata$FactorC)<-cbind(IniVsMid, IniVsCls)
#Factor D (Length of Experience, continuous variable)
alldata$FactorD<-as.numeric(alldata$FactorD)

What I really wanted to test is the interaction between Factor A and 
Factor B. Factor A has the two contrasts (i.e., PreVsMid (1,-1,0), 
PreVsPost(-1,0,1)), and Factor B has only one contrast (i.e., IDvsDIS 
(-1,1)) since there are only two levels in the Factor B. I tested 
whether there is a significant difference in the contrast of PreVsMid 
between the two levels of Factor B (IDvsDIS). Therefore, I did not use 
the dummy (simple effect) coding but used the effect coding.

As you suggested, I tried to figure out how to use the multcomp 
package. I found that the glht function in the packages allows me to 
test a variety of contrasts with a matrix. However, I felt that the 
contrasts I coded above are maybe enough to test my hypothesis, and I 
am wondering whether I should use the glht function for the contrasts.

Could you please let me know if there are any advantage of using the 
glht function?

I really appreciate your help.

Best wishes,
Yasu


On Thu, 26 May 2016 08:53:44 +0200
  Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
> Dear Yasu,
> 
> The contrast x = c(1, -1, 0) is equivalent to beta_x * 1 * a_1 + 
>beta_x *
> (-1) * a_2 + beta_x * 0 * a_3.
> Likewise contrast y = c(.5, -.5, 0) is equivalent to beta_y * 0.5 * 
>a_1 +
> beta_y * (-0.5) * a_2 + beta_y * 0 * a_3.
> 
> Since both model the same thing beta_x * 1 * a_1 + beta_x * (-1) * 
>a_2 +
> beta_x * 0 * a_3 = beta_y * 0.5 * a_1 + beta_y * (-0.5) * a_2 + 
>beta_y * 0
> * a_3.
> Some simple math will show that beta_x = 2 * beta_y
> 
> Your contrasts are correct but pointless given your model. They are 
>only
> meaningful in case FactorA is only a main effect. You included 
>FactorA in
> some interactions as well. So you'll need to define contrasts on the 
>full
> set of fixed parameters to get some sensible results. You can do 
>that with
> the multcomp package. I would also suggest that you find some local
> statistician to help you define the contrasts relevant for your 
>model.
> 
> Best regards,
> 
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for 
>Nature and
>Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality 
>Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no 
>more
> than asking him to perform a post-mortem examination: he may be able 
>to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does 
>not
> ensure that a reasonable answer can be extracted from a given body 
>of data.
> ~ John Tukey
> 
> 2016-05-26 6:31 GMT+02:00 Yasuaki SHINOHARA 
><y.shinohara at aoni.waseda.jp>:
> 
>> Dear Thierry,
>>
>> Thank you very much for your reply.
>> I understood why. The interaction of blockPreVsMid:FactorD turned
>> significant in the model which contrasted the testing block factor 
>>as
>> PreVsMid and PreVsPost (i.e.,cbind(c(1,-1,0),c(-1,0,1))), although 
>>the
>> interaction was not significant in the model with the testing block
>> contrasted as PreVsMid and PreMidVsPost (i.e., 
>>cbind(c(1,-1,0),c(1,1,-2))).
>>
>> Could I ask another question?
>> What is the difference in making a contrast of PreVsMid as c(1,-1,0) 
>>and
>> as c(0.5, -0.5, 0)?
>> It seems that the beta and SE are double if I code the contrasts 
>>with
>> (0.5, -0.5, 0). I hope it does not matter.
>>
>> Also, I coded "contrasts(data$FactorA)<-cbind(c(1,-1,0),c(-1,0,1))" 
>>to
>> test the differences between the mean of level 1 vs. the mean of 
>>level 2
>> and between the mean of level 1 and the mean of level 3. Is this 
>>correct?
>> Some website says something different from what I understood (e.g., 
>>the
>> first Answer of
>> http://stats.stackexchange.com/questions/44527/contrast-for-hypothesis-test-in-r-lmer
>> ).
>>
>> My model includes both categorical and numeric variable, and all
>> categorical variables were coded manually.
>>
>> Best wishes,
>> Yasu
>>
>>
>> On Wed, 25 May 2016 09:44:14 +0200
>>  Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
>>
>>> Dear Yasu,
>>>
>>> A is part of two interactions. Hence you cannot interpret this main 
>>>effect
>>> without the interactions. Note that changing the contrast will also 
>>>effect
>>> the interactions.
>>>
>>> Best regards,
>>>
>>> ir. Thierry Onkelinx
>>> Instituut voor natuur- en bosonderzoek / Research Institute for 
>>>Nature and
>>> Forest
>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality 
>>>Assurance
>>> Kliniekstraat 25
>>> 1070 Anderlecht
>>> Belgium
>>>
>>> To call in the statistician after the experiment is done may be no 
>>>more
>>> than asking him to perform a post-mortem examination: he may be able 
>>>to
>>> say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does 
>>>not
>>> ensure that a reasonable answer can be extracted from a given body 
>>>of
>>> data.
>>> ~ John Tukey
>>>
>>> 2016-05-25 4:42 GMT+02:00 Yasuaki SHINOHARA 
>>><y.shinohara at aoni.waseda.jp>:
>>>
>>> Dear all,
>>>>
>>>> Hello, I am doing research of second language acquisition.
>>>> I am wondering about the glmer in R for my analyses. Could you 
>>>>please
>>>> answer my question?
>>>>
>>>> I have the following logistic mixed effects model.
>>>> model<-glmer(corr ~ A + B + C + D + A:B + B:C + A:D +(1+A|subject) +
>>>>
>>>> (1+A|item:speaker),family=binomial,data=mydata,control=glmerControl(optimizer="bobyqa",
>>>> optCtrl=list(maxfun=1000)))
>>>>
>>>> I tested language learners (subjects) three time (pre-training,
>>>> mid-training, post-training) with the "item" produced by "speaker", 
>>>>so
>>>> Factor A is "testing block" which has three levels (i.e., pre, mid,
>>>> post).
>>>> Since each subject took the test three times, the random slopes for 
>>>>the
>>>> Factor A were also included as a random factor.
>>>>
>>>> I made an orthogonal contrast for the Factor A (testing block) as
>>>> follows.
>>>> PreVsMid<-c(1,-1,0)
>>>> PreMidVsPost<-c(1,1,-2)
>>>> contrasts(mydata$A)<-cbind(PreVsMid,PreMidVsPost)
>>>>
>>>> The results from summary(model) function for this factor were as 
>>>>follows.
>>>> pre vs. mid test: ? = 0.22, SE = 0.05, z = 4.34, p < 0.001
>>>> pre & mid vs. post test: ? = -0.21, SE = 0.04, z = -5.96, p < 0.001.
>>>>
>>>> However, I thought it would be better if I made a non-orthogonal 
>>>>contrast
>>>> for this factor as "pre vs. mid" and "pre vs. post" to test my
>>>> hypothesis.
>>>> So I made a new contrast for the Factor A as follows.
>>>> PreVsMid<-c(1,-1,0)
>>>> PreVsPost<-c(1,0,-1)
>>>> contrasts(mydata$A)<-cbind(PreVsMid,PreVsPost)
>>>>
>>>> The results from summary(model) function for this contrast were
>>>> pre vs. mid test: ? = -0.01, SE = 0.04, z = -0.14, p > 0.05 (=0.89),
>>>> pre vs. post test: ? = 0.42, SE = 0.07, z = 5.96, p < 0.001.
>>>>
>>>> Although the first contrast (pre vs. mid) is the same for both 
>>>>models,
>>>> why
>>>> the results of pre vs. mid contrast are so different (one is very
>>>> significant, but the other one is not significant)?
>>>>
>>>> I really appreciate any help.
>>>>
>>>> Best wishes,
>>>> Yasu
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>>


From thierry.onkelinx at inbo.be  Mon May 30 09:47:06 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 30 May 2016 09:47:06 +0200
Subject: [R-sig-ME] Orthogonal vs. Non-orthogonal contrasts
In-Reply-To: <web-69842955@besv03.spw.secure-premium.ne.jp>
References: <web-69184710@besv02.spw.secure-premium.ne.jp>
	<CAJuCY5zeexeXpPSto7hg=QAA-yGJ+rkE0PRqhaR=gJQjGLaFSg@mail.gmail.com>
	<web-69429660@besv04.spw.secure-premium.ne.jp>
	<CAJuCY5wT0XwAeD9q5Uq6Dk+K_PdhrXNDJfni9-86F4r5wGKYoQ@mail.gmail.com>
	<web-69842955@besv03.spw.secure-premium.ne.jp>
Message-ID: <CAJuCY5xAhBfQKrsK+ivQkCTTmPd=1kvSDYWDh_YZP4kekkUZ2g@mail.gmail.com>

Dear Yasu,

I see two advantages of multcomp:

1) It can work with any parametrisation. So it doesn't matter whether you
use dummy encoding or some kind of contrast. Hence you can do any post-hoc
test without having to refit the model. Note that the specification of the
contrast will depend on the parametrisation. I find dummy encoding easier
to generate post-hoc contrasts.

2) It corrects for multiple testing.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-05-30 9:30 GMT+02:00 Yasuaki SHINOHARA <y.shinohara at aoni.waseda.jp>:

> Dear Thierry,
>
> Thank you very much for your reply.
>
> I understood that the results of each main fixed factor (e.g., Factor A,
> B, C and D) are pointless, since the interaction factors affected the
> results of the main fixed factors. Actually, I manually coded the contrasts
> for all the fixed factors based on the hypothesis I wanted to test, as
> follows.
>
> #Factor A (testing block)
> PreVsMid<-c(1,-1,0)
> PreVsPost<-c(-1,0,1)
> contrasts(alldata$FactorA)<-cbind(PreVsMid,PreVsPost)
> #Factor B (Trainer order)
> IDVsDIS<-c(1,-1)
> contrasts(alldata$FactorB)<-cbind(IDVsDIS)
> #Factor C (Phonetic environment)
> IniVsMid<-c(1,-1,0)
> IniVsCls<-c(-1,0,1)
> contrasts(alldata$FactorC)<-cbind(IniVsMid, IniVsCls)
> #Factor D (Length of Experience, continuous variable)
> alldata$FactorD<-as.numeric(alldata$FactorD)
>
> What I really wanted to test is the interaction between Factor A and
> Factor B. Factor A has the two contrasts (i.e., PreVsMid (1,-1,0),
> PreVsPost(-1,0,1)), and Factor B has only one contrast (i.e., IDvsDIS
> (-1,1)) since there are only two levels in the Factor B. I tested whether
> there is a significant difference in the contrast of PreVsMid between the
> two levels of Factor B (IDvsDIS). Therefore, I did not use the dummy
> (simple effect) coding but used the effect coding.
>
> As you suggested, I tried to figure out how to use the multcomp package. I
> found that the glht function in the packages allows me to test a variety of
> contrasts with a matrix. However, I felt that the contrasts I coded above
> are maybe enough to test my hypothesis, and I am wondering whether I should
> use the glht function for the contrasts.
>
> Could you please let me know if there are any advantage of using the glht
> function?
>
> I really appreciate your help.
>
> Best wishes,
> Yasu
>
>
> On Thu, 26 May 2016 08:53:44 +0200
>
>  Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
>
>> Dear Yasu,
>>
>> The contrast x = c(1, -1, 0) is equivalent to beta_x * 1 * a_1 + beta_x *
>> (-1) * a_2 + beta_x * 0 * a_3.
>> Likewise contrast y = c(.5, -.5, 0) is equivalent to beta_y * 0.5 * a_1 +
>> beta_y * (-0.5) * a_2 + beta_y * 0 * a_3.
>>
>> Since both model the same thing beta_x * 1 * a_1 + beta_x * (-1) * a_2 +
>> beta_x * 0 * a_3 = beta_y * 0.5 * a_1 + beta_y * (-0.5) * a_2 + beta_y * 0
>> * a_3.
>> Some simple math will show that beta_x = 2 * beta_y
>>
>> Your contrasts are correct but pointless given your model. They are only
>> meaningful in case FactorA is only a main effect. You included FactorA in
>> some interactions as well. So you'll need to define contrasts on the full
>> set of fixed parameters to get some sensible results. You can do that with
>> the multcomp package. I would also suggest that you find some local
>> statistician to help you define the contrasts relevant for your model.
>>
>> Best regards,
>>
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
>> Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to
>> say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of
>> data.
>> ~ John Tukey
>>
>> 2016-05-26 6:31 GMT+02:00 Yasuaki SHINOHARA <y.shinohara at aoni.waseda.jp>:
>>
>> Dear Thierry,
>>>
>>> Thank you very much for your reply.
>>> I understood why. The interaction of blockPreVsMid:FactorD turned
>>> significant in the model which contrasted the testing block factor as
>>> PreVsMid and PreVsPost (i.e.,cbind(c(1,-1,0),c(-1,0,1))), although the
>>> interaction was not significant in the model with the testing block
>>> contrasted as PreVsMid and PreMidVsPost (i.e.,
>>> cbind(c(1,-1,0),c(1,1,-2))).
>>>
>>> Could I ask another question?
>>> What is the difference in making a contrast of PreVsMid as c(1,-1,0) and
>>> as c(0.5, -0.5, 0)?
>>> It seems that the beta and SE are double if I code the contrasts with
>>> (0.5, -0.5, 0). I hope it does not matter.
>>>
>>> Also, I coded "contrasts(data$FactorA)<-cbind(c(1,-1,0),c(-1,0,1))" to
>>> test the differences between the mean of level 1 vs. the mean of level 2
>>> and between the mean of level 1 and the mean of level 3. Is this correct?
>>> Some website says something different from what I understood (e.g., the
>>> first Answer of
>>>
>>> http://stats.stackexchange.com/questions/44527/contrast-for-hypothesis-test-in-r-lmer
>>> ).
>>>
>>> My model includes both categorical and numeric variable, and all
>>> categorical variables were coded manually.
>>>
>>> Best wishes,
>>> Yasu
>>>
>>>
>>> On Wed, 25 May 2016 09:44:14 +0200
>>>  Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
>>>
>>> Dear Yasu,
>>>>
>>>> A is part of two interactions. Hence you cannot interpret this main
>>>> effect
>>>> without the interactions. Note that changing the contrast will also
>>>> effect
>>>> the interactions.
>>>>
>>>> Best regards,
>>>>
>>>> ir. Thierry Onkelinx
>>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>>> and
>>>> Forest
>>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>>> Kliniekstraat 25
>>>> 1070 Anderlecht
>>>> Belgium
>>>>
>>>> To call in the statistician after the experiment is done may be no more
>>>> than asking him to perform a post-mortem examination: he may be able to
>>>> say
>>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>> The combination of some data and an aching desire for an answer does not
>>>> ensure that a reasonable answer can be extracted from a given body of
>>>> data.
>>>> ~ John Tukey
>>>>
>>>> 2016-05-25 4:42 GMT+02:00 Yasuaki SHINOHARA <y.shinohara at aoni.waseda.jp
>>>> >:
>>>>
>>>> Dear all,
>>>>
>>>>>
>>>>> Hello, I am doing research of second language acquisition.
>>>>> I am wondering about the glmer in R for my analyses. Could you please
>>>>> answer my question?
>>>>>
>>>>> I have the following logistic mixed effects model.
>>>>> model<-glmer(corr ~ A + B + C + D + A:B + B:C + A:D +(1+A|subject) +
>>>>>
>>>>>
>>>>> (1+A|item:speaker),family=binomial,data=mydata,control=glmerControl(optimizer="bobyqa",
>>>>> optCtrl=list(maxfun=1000)))
>>>>>
>>>>> I tested language learners (subjects) three time (pre-training,
>>>>> mid-training, post-training) with the "item" produced by "speaker", so
>>>>> Factor A is "testing block" which has three levels (i.e., pre, mid,
>>>>> post).
>>>>> Since each subject took the test three times, the random slopes for the
>>>>> Factor A were also included as a random factor.
>>>>>
>>>>> I made an orthogonal contrast for the Factor A (testing block) as
>>>>> follows.
>>>>> PreVsMid<-c(1,-1,0)
>>>>> PreMidVsPost<-c(1,1,-2)
>>>>> contrasts(mydata$A)<-cbind(PreVsMid,PreMidVsPost)
>>>>>
>>>>> The results from summary(model) function for this factor were as
>>>>> follows.
>>>>> pre vs. mid test: ? = 0.22, SE = 0.05, z = 4.34, p < 0.001
>>>>> pre & mid vs. post test: ? = -0.21, SE = 0.04, z = -5.96, p < 0.001.
>>>>>
>>>>> However, I thought it would be better if I made a non-orthogonal
>>>>> contrast
>>>>> for this factor as "pre vs. mid" and "pre vs. post" to test my
>>>>> hypothesis.
>>>>> So I made a new contrast for the Factor A as follows.
>>>>> PreVsMid<-c(1,-1,0)
>>>>> PreVsPost<-c(1,0,-1)
>>>>> contrasts(mydata$A)<-cbind(PreVsMid,PreVsPost)
>>>>>
>>>>> The results from summary(model) function for this contrast were
>>>>> pre vs. mid test: ? = -0.01, SE = 0.04, z = -0.14, p > 0.05 (=0.89),
>>>>> pre vs. post test: ? = 0.42, SE = 0.07, z = 5.96, p < 0.001.
>>>>>
>>>>> Although the first contrast (pre vs. mid) is the same for both models,
>>>>> why
>>>>> the results of pre vs. mid contrast are so different (one is very
>>>>> significant, but the other one is not significant)?
>>>>>
>>>>> I really appreciate any help.
>>>>>
>>>>> Best wishes,
>>>>> Yasu
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>>
>>>>>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon May 30 10:26:34 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 30 May 2016 10:26:34 +0200
Subject: [R-sig-ME] nesting hierarchy in glmer
In-Reply-To: <CAGPdvCdea6Bb_=Bd1+D6wQ3RjHcf0yq-c5pDjo8JYTvuX6_qKQ@mail.gmail.com>
References: <CAGPdvCdea6Bb_=Bd1+D6wQ3RjHcf0yq-c5pDjo8JYTvuX6_qKQ@mail.gmail.com>
Message-ID: <CAJuCY5yx46c7+=3qM3uRSdVEVWpAFLd_WP0y_KTo9fYgequeHA@mail.gmail.com>

Dear Hariet Rose,

It looks like you scenario's (temperature:dose) were too extreme since all
seedlings died in some scenario's. Keep that in mind when designing your
next experiment.

First of all adding room to both the fixed effect as the random effect is
not OK in case of categorical variables:
https://rpubs.com/INBOstats/both_fixed_random

To salvage as much as possible I'd remove the scenario's in which all
seedlings died. Then fit one model:

glmer(survivorship ~ pops * scenario + (1|room/id), family = binomial, data
= all.relevant.data)

Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-05-29 18:24 GMT+02:00 Hariet Rose <harietrose123 at gmail.com>:

> Hi, I am a newbie at posting on this forum and relatively new to R.  My
> question is about nesting in glmer and examples on the forums do not
> correspond to my experiment, especially as I think I could run my design as
> two separate analyses.
>
>
> I have a glasshouse complex study where I have six independent rooms. Three
> rooms were randomly chosen to be set at the hot temperature for the
> duration of the experiment, and another three rooms were randomly chosen
> and set at a cold temperature for the duration of the experiment (13
> weeks).  This is why I think I could run two separate models
>
> .
>
> [There were other rooms that I didn?t use although they were ?available? to
> be chosen randomly].
>
>
>  For my question, I want to know if two populations (pops = pop1, pop2) of
> seedlings respond in different ways to 3 water dosages under the
> temperature regimes. The rooms were stocked evenly with seedlings from two
> different populations of the same species; each seedling in each room
> received only 1 of 3 water doses; local, wet or dry.  I measured
> survivorship of seedlings at week 13 and the response was 1 = alive or 0 =
> dead.  In the models below ?id? is the code I have given to all plants that
> received the same treatment within a room (e.g.id 1=  replicate 1, all
> plants from pop1 in room1 (hot)  that received the local water treatment)..
>
>
> As all seedlings died when the following treatments were applied;  hot +
> dry, hot +local and cool + dry, I have a very skewed response.  This
> suggests to me that some model simplification may be possible...
>
>
> Because the two temperatures could be seen as independent experiments and
> because of the skewed response I am thinking it would be simpler to run two
> separate models, one for the cool rooms and another for the hot rooms;
>
>
> R version 3.1.3 (2015-03-09), library(lme4)
>
> coolmodel <- glmer(survivorship ~ room*pops*dose * (1|room/id), family
> = binomial, data = mydata1)
>
>  mydata1 is a matrix of cool room data only and the samples from the
> dry dose treatment have been removed (i.e., both pops of dry dosed
> plants died).
>
> hotmodel <- glmer(survivorship ~ room*pops * (1|room/id), family =
> binomial, data = mydata2)
>
> mydata2 is a matrix of hot room data only and the samples from the dry
> and local have been removed (i.e., both pops of dry and local dosed
> plants died)
>
> in the above model, because there were only survivors for one dose
> (wet) I have not specified the fixed effect of dose.
>
> Question 1. Is the above approach correct? I am concerned that the
> nesting of id may be incorrect.
>
> For the combined cool and hot room data set, I have used this model
>
> bothtempsmodel <- glmer(survivorship ~ temp*pops*dose *
> (1|temp/room/id), family = binomial, data = mydata)
>
> where mydata has all samples from all temps, rooms, and treatments ?
> i.e., no data have been removed.
>
>
> Question 2. In the bothtempsmodel, if I have explained the nesting and
> everything else correctly, I end up with many significant two and the
> three way interaction/s whereas coolmodel and hotmodel have outputs
> that are simplified.
> Would a strategy be to specify the full model (bothtempsmodel) and
> then go on to explain and implement the simplified coolmodel and
> hotmodel, with the removal of data as explained above.
>
>  I can post the outputs if anyone is interested..
>
>  Thank you very much for your time.. :) hariet-rose
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From epalmery at cns.umass.edu  Wed Jun  1 00:20:27 2016
From: epalmery at cns.umass.edu (Evan Palmer-Young)
Date: Tue, 31 May 2016 18:20:27 -0400
Subject: [R-sig-ME] Advice for analysis of biological data - Mixed model
 or NESTED-Anova?
In-Reply-To: <CABm7sVNZ9QetoFqd0aXcsBEqPAfg2R=Ji+n4L96HWfzhTjyMbA@mail.gmail.com>
References: <CABm7sVMNK30qsN_wv4MiCmSo0aLoN8F9UheCirp6cxu_B+bPTw@mail.gmail.com>
	<CAAge6+5JNobpf-nxHaOS0NL0k2YYBAX39MdEK7shM2rBsDnrFQ@mail.gmail.com>
	<CABm7sVNZ9QetoFqd0aXcsBEqPAfg2R=Ji+n4L96HWfzhTjyMbA@mail.gmail.com>
Message-ID: <CAAge6+5L4uPAe2Vx1Q6mhjVusVBUOvMU59s=uwAXxPGs7JJ2tA@mail.gmail.com>

Savani,
I think your problem is that your model is using group as both fixed and
random effect.
Try this instead:
So for your experiments with NO treatment, you need a model to assess the
effect of group, if you want to say, "Did the groups differ":
simple_model<-nlme(logVolume ~ Group , random= ~Animal_ID, data=savanidata)

For your experiments WITH a treatment,
treatment_model<-nlme(logVolume ~ Treatment , random= ~Group/Animal_ID,
data=savanidata)

If you actually want to know the interaction between treatment and group,
then you must have "Group" as fixed effect:
interaction_model<-nlme(logVolume ~ Treatment*Group , random= ~Animal_ID,
data=savanidata)
Then you can test the terms like this:

model1<- update(interaction_model, ~. - Treatment:Group) #excludes
interaction

anova(interaction_model, model1) #likelihood ratio test; if p<0.05, the
interaction term is doing a good job in your model, so you should keep the
interaction term
Otherwise, you can keep simplifying, like this:
model2<-update(model1, ~. - Group)
anova(model1, model2)
And so you can test the importance of each term.

Happy modeling,
Evan






On Thu, May 26, 2016 at 5:17 AM, Savani Anbalagan <savani1987 at gmail.com>
wrote:

> Hi Evan,
>
> Thanks a lot.
> When you say the biggest group. I assume it is just about the number of
> animals in the group. Not about about the total number of observations for
> a group.
>
> And, when I run the code, I get the error
>
> ?
> brainmodel<-nlme(logVolume ~ Group , random= ~Group/Animal_ID,
> ?
> data=dat)
> Error in model[[3]][[1]] : object of type 'symbol' is not subsettable
>
> And
>
> In the full or reduced models with lme4: What might be an reduced model in
> my case?
> Because, in expt design 1 : I only have 3 groups.
>
>
> thanks,
> Savani
>
>
>
> On 25 May 2016 at 21:58, Evan Palmer-Young <epalmery at cns.umass.edu> wrote:
>
> > Dear Savani,
> > I think you are on the right track. If you use function nlme, you can get
> > your p-values straightaway.
> > With lme4, you have to employ another function (Likelihood ratio test on
> > full and reduced models, or Wald tests with Anova in car) to extract
> them:
> > see:
> > http://www.inside-r.org/packages/cran/lme4/docs/pvalues
> >
> > For your model coding, make sure that the biggest group is listed FIRST.
> > So for you:
> > model2=lmer(logVolume ~ Group + (1|Animal_ID/Group ),
> > ??
> > data=dat, REML =
> > FALSE)
> > Instead use
> > ??
> > brainmodel<-nlme(logVolume ~ Group , random= ~Group/Animal_ID)
> > See some examples under "model specification" on this very helpful page:
> > http://glmm.wikidot.com/faq
> >
> > Here are some nlme examples:
> > http://www.stat.ubc.ca/~lang/Stat527a/ex4.r
> >
> > Good luck!
> >
> > On Wed, May 25, 2016 at 3:32 PM, Savani Anbalagan <savani1987 at gmail.com>
> > wrote:
> >
> >> Dear all,
> >>
> >> I was suggested in the stack exchange.com to consult in this maling
> list.
> >>
> >> I have data from image analysis of zebrafish brain structures. I will
> >> discuss our data below with some analogy to make my explanation clear.
> >>
> >>    1. Data model: Group>Animal 1..2...3....10>Volume 1..2..3.....1000
> >>    2. Data model: Group>Drug treatment..1..2>Animal
> 1..2...3....10>Volume
> >>    1..2..3.....1000
> >>    3. I am studying axonal synapses in Brain.
> >>    4. I have 3 or more groups (Genotypes: Wild type, Hetero, Homozygous
> >>    mutant)
> >>    5. Animals are sacrificied to image them.
> >>    6. I have 10+ animals from each group.
> >>    7. The number and volume of the synapses are variable.
> >>    8. Within the group, some animals have 300 synapses, some have 450
> >>    synapses.
> >>    9. The volume of the synapses range from 0.2 to 50. The histrogram is
> >>    highly skewed towards lower values. A log transformation makes it
> look
> >> more
> >>    normal.
> >>    10. Some times, we also treat the different groups to a drug. So, it
> >>    makes another level.
> >>    11.
> >>
> >> Analogy:
> >>
> >>    1. > (Imagine a tree with fruits of different sizes. And I am
> >> interested
> >>    in the size of the fruits)
> >>    2. >(Lets say, I have trees of different species. example Indian
> Mango
> >>    vs Brazilian Mango vs another Mango)
> >>    3. >(To collect fruits, The trees are cut. )
> >>    4. >(10+ trees in each groups)
> >>    5. >(The number of fruits vary depending on tree to tree even within
> >>    same group. The size of the fruit varies. There are relatively too
> many
> >>    small fruits).
> >>    6. >(Some times, fertilizers are added to tree, and then effect of
> >> fruit
> >>    count/size is also checked)
> >>
> >> My questions:
> >> Could you please let me know,
> >>
> >>
> >>    1. Should I perform Nested ANOVA or Mixed model analysis?
> >>    2. If mixed model design, should I run the analysis on log
> transformed
> >>    data or raw data? Is the distribution important for mixed model
> >> analysis?
> >>    3. If drug treatment is added, Is it Nested or Mixed model design?
> >>    4. For mixed model analysis how can I calculate p-value? Could you
> >>    please let me know for both the cases. For experiments, without any
> >> drug.
> >>    And for experiments with the drug treated vs control.
> >>    5. These are the codes that I use to analyze my data: Could you check
> >> if
> >>    it is correct?
> >>
> >>
> >> My nested anova code I use:
> >> logGFPVol.anova = aov(logVolume ~ Group + Error(Animal_ID/Group),
> >> data=data)
> >> summary(logGFPHBVol.anova)
> >>
> >>
> >> Mixed model code:
> >> model2=lmer(logVolume ~ Group + (1|Animal_ID/Group ), data=data, REML =
> >> FALSE)
> >> summary(model2)
> >>
> >>
> >> Please feel free to ask if I am unclear.
> >>
> >> Many thanks,
> >> Savani
> >>
> >> --------------------------------------------------------
> >>
> >> *Savani Anbalagan, Ph.D*
> >>
> >> *Dept. of Mol. Cell Biology*
> >>
> >>
> >> *Weizmann Institute of Science234 Herzl St., Rehovot 76100,*
> >>
> >>
> >> *ISRAELPhone: +972-8934-6158*
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> >
> >
> > --
> > Department of Biology
> > 221 Morrill Science Center
> > 611 North Pleasant St
> > Amherst MA 01003
> > https://sites.google.com/a/cornell.edu/evan-palmer-young/
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Department of Biology
221 Morrill Science Center
611 North Pleasant St
Amherst MA 01003
https://sites.google.com/a/cornell.edu/evan-palmer-young/

	[[alternative HTML version deleted]]


From hannah.hlx at gmail.com  Wed Jun  1 23:11:43 2016
From: hannah.hlx at gmail.com (li li)
Date: Wed, 1 Jun 2016 17:11:43 -0400
Subject: [R-sig-ME] Fwd: [R] model specification using lme
In-Reply-To: <CAJuCY5wMrELKbj+SY7MeAz+qV=-Ya8GRiNRDMSV2dPr_5WJSMg@mail.gmail.com>
References: <CAHLnndYK-UEt84Mb9Rncm_Q1aTOX8EzttfE-Jt1JGN0dg0MMDg@mail.gmail.com>
	<CAJuCY5wMrELKbj+SY7MeAz+qV=-Ya8GRiNRDMSV2dPr_5WJSMg@mail.gmail.com>
Message-ID: <CAHLnndZ1jB3dyBwRTmf-xBOiJ2Q4C27i7scy3KmGC5h5G7xKSw@mail.gmail.com>

Thanks Thierry for the reply. I think I now have a better understanding for
the specification of the random effects when using lme function.
Are my interpretations below correct?

random=~ 1 | individual   (same random intercept no random slope)

random=~ 1 +method| individual    (same random intercept and same random
slope)

random=~ 1 +method:time| individual    (same random intercept and different
random slope for different method)
random=~ 1 +method + method:time| individual    (different random intercept
and different random slope for different method

 The summary results from the lme function shows whether the slopes for the
three methods are equal (parallelism). I also wanted to test the hypotheses
that each of the fixed slopes (corresponding to the three methods) equals
0, can I use multicomp package for that purpose? I am confused on how to
make correct specifications in glht function to test these hypotheses.

Hanna


> summary(mod1)
Linear mixed-effects model fit by REML
 Data: one
       AIC      BIC    logLik
  304.4703 330.1879 -140.2352

Random effects:
 Formula: ~1 + time | individual
 Structure: General positive-definite, Log-Cholesky parametrization
            StdDev       Corr
(Intercept) 0.2487869075 (Intr)
time        0.0001841179 -0.056
Residual    0.3718305953

Variance function:
 Structure: Different standard deviations per stratum
 Formula: ~1 | method
 Parameter estimates:
       3        1        2
 1.00000 26.59750 24.74476
Fixed effects: reponse ~ method * time
                Value Std.Error DF   t-value p-value(Intercept)
96.65395  3.528586 57 27.391694  0.0000
method2       1.17851  4.856026 57  0.242689  0.8091
method3       5.87505  3.528617 57  1.664973  0.1014
*time              0.07010  0.250983 57  0.279301  0.7810 method2:time
-0.12616  0.360585 57 -0.349877  0.7277 method3:time -0.08010  0.251105 57
-0.318999  0.7509*
 Correlation:
             (Intr) methd2 methd3 time   mthd2:
method2      -0.726
method3      -0.999  0.726
time         -0.779  0.566  0.779
method2:time  0.542 -0.712 -0.542 -0.696
method3:time  0.778 -0.566 -0.779 -0.999  0.696

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max
-2.67575293 -0.51633192  0.06742723  0.59706762  2.81061874

Number of Observations: 69
Number of Groups: 7 >



---------- Forwarded message ----------
From: Thierry Onkelinx <thierry.onkelinx at inbo.be>
Date: 2016-05-30 4:40 GMT-04:00
Subject: Re: [R] model specification using lme
To: li li <hannah.hlx at gmail.com>
Cc: r-help <r-help at r-project.org>



Dear Hanna,

None of the models are correct is you want the same random intercept for
the different methods but different random slope per method.

You can random = ~ 1 + time:method | individual

The easiest way to get alpha_0 and tau_i is to apply post-hoc contrasts.
That is fairly easy to do with the multcomp package.

alpha_0 = (m1 + m2 + m3) / 3
m1 = intercept
m2 = intercept + method2
m3 = intercept + method3
hence alpha_0 = intercept + method2/3 + method3/3

m1 = alpha_0 + tau_1
tau_1 = intercept - method2/3 - method3/3

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-05-29 21:23 GMT+02:00 li li <hannah.hlx at gmail.com>:


> Hi all,
>   For the following data, I consider the following random intercept and
> random slope model. Denote as y_ijk the response value from *j*th
> individual within *i*th method at time point *k*. Assume the following
> model for y_ijk:
>
>       y_ijk= (alpha_0+ tau_i +a_j(i))+(beta_i+b_j(i)) T_k + e_ijk
>
>
> Here alpha_0 is the grand mean;
>           tau_i is the fixed effect for ith method;
>           a_j(i) is random intercept corresponding to the *j*th individual
> within *i*th method, assumed to be common for all three methods;
>           beta_i is the fixed slope corresponding to the ith method;
>           b_j(i) is the random slope corresponding to jth individual for
> the ith method, assumed to be different for different methods;
>           T_k is the time corresponding to y_ijk;
>           e_ijk is the residual.
>
> For this model, I consider the three specification using  the lme function
> as follows:
>
>
> mod1 <- lme(fixed= reponse ~ method*time, random=~ 1 +time | individual,
> data=one, weights= varIdent(form=~1|method),
>             control = lmeControl(opt = "optim"))
>
> mod2 <- lme(fixed= reponse ~ method*time, random=~ 0 +time | individual,
> data=one, weights= varIdent(form=~1|method),
>             control = lmeControl(opt = "optim"))
>
> mod3 <- lme(fixed= reponse ~ method*time, random=~ method +time |
> individual, data=one, weights= varIdent(form=~1|method),
>             control = lmeControl(opt = "optim"))
>
> I think mod1 is the correct one. However, I am kind of confused with the
> right usage of lme function. Can someone familiar with this give some help
> here?
>
> Another question is regarding the fixed effect   tau_1, tau_2 and tau_3
> (corresponding to the three methods). One main question I am interested in
> is whether each of them are statistically different from zero. In the
> summary results below (shaded part), it looks that the result for method 2
> and 3 are given with reference to method 1). Is there a way to obtain
> specific result separately for alpha_0 (the overall mean) and also tau_1,
> tau_2 and tau3?
>
> Thanks very much for the help!
>    Hanna
>
>
> > summary(mod1)Linear mixed-effects model fit by REML
>  Data: one
>        AIC      BIC    logLik
>   304.4703 330.1879 -140.2352
>
> Random effects:
>  Formula: ~1 + time | individual
>  Structure: General positive-definite, Log-Cholesky parametrization
>             StdDev       Corr
> (Intercept) 0.2487869075 (Intr)
> time        0.0001841179 -0.056
> Residual    0.3718305953
>
> Variance function:
>  Structure: Different standard deviations per stratum
>  Formula: ~1 | method
>  Parameter estimates:
>        3        1        2
>  1.00000 26.59750 24.74476
> Fixed effects: reponse ~ method * time
>                 Value Std.Error DF   t-value p-value(Intercept)
> 96.65395  3.528586 57 27.391694  0.0000
> method2       1.17851  4.856026 57  0.242689  0.8091
> method3       5.87505  3.528617 57  1.664973  0.1014time
> 0.07010  0.250983 57  0.279301  0.7810
> method2:time -0.12616  0.360585 57 -0.349877  0.7277
> method3:time -0.08010  0.251105 57 -0.318999  0.7509
>  Correlation:
>              (Intr) methd2 methd3 time   mthd2:
> method2      -0.726
> method3      -0.999  0.726
> time         -0.779  0.566  0.779
> method2:time  0.542 -0.712 -0.542 -0.696
> method3:time  0.778 -0.566 -0.779 -0.999  0.696
>
> Standardized Within-Group Residuals:
>         Min          Q1         Med          Q3         Max
> -2.67575293 -0.51633192  0.06742723  0.59706762  2.81061874
>
> Number of Observations: 69
> Number of Groups: 7 >
>
>
>
>
>
> > one   response individual time method
> 1    102.9          3    0      3
> 2    103.0          3    3      3
> 3    103.0          3    6      3
> 4    102.8          3    9      3
> 5    102.2          3   12      3
> 6    102.5          3   15      3
> 7    103.0          3   18      3
> 8    102.0          3   24      3
> 9    102.8          1    0      3
> 10   102.7          1    3      3
> 11   103.0          1    6      3
> 12   102.2          1    9      3
> 13   103.0          1   12      3
> 14   102.8          1   15      3
> 15   102.8          1   18      3
> 16   102.9          1   24      3
> 17   102.2          2    0      3
> 18   102.6          2    3      3
> 19   103.4          2    6      3
> 20   102.3          2    9      3
> 21   101.3          2   12      3
> 22   102.1          2   15      3
> 23   102.1          2   18      3
> 24   102.2          2   24      3
> 25   102.7          4    0      3
> 26   102.3          4    3      3
> 27   102.6          4    6      3
> 28   102.7          4    9      3
> 29   102.8          4   12      3
> 30   102.5          5    0      3
> 31   102.4          5    3      3
> 32   102.1          5    6      3
> 33   102.3          6    0      3
> 34   102.3          6    3      3
> 35   101.9          7    0      3
> 36   102.0          7    3      3
> 37   107.4          3    0      1
> 38   101.3          3   12      1
> 39    92.8          3   15      1
> 40    73.7          3   18      1
> 41   104.7          3   24      1
> 42    92.6          1    0      1
> 43   101.9          1   12      1
> 44   106.3          1   15      1
> 45   104.1          1   18      1
> 46    95.6          1   24      1
> 47    79.8          2    0      1
> 48    89.7          2   12      1
> 49    97.0          2   15      1
> 50   108.4          2   18      1
> 51   103.5          2   24      1
> 52    96.4          4    0      1
> 53    89.3          4   12      1
> 54   112.6          5    0      1
> 55    93.3          6    0      1
> 56    99.6          7    0      1
> 57   109.5          3    0      2
> 58    98.5          3   12      2
> 59   103.5          3   24      2
> 60   113.5          1    0      2
> 61    94.5          1   12      2
> 62    88.5          1   24      2
> 63    99.5          2    0      2
> 64    97.5          2   12      2
> 65    98.5          2   24      2
> 66   103.5          4    0      2
> 67    89.5          5    0      2
> 68    87.5          6    0      2
> 69    82.5          7    0      2
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From graftedlife at gmail.com  Fri Jun  3 14:28:59 2016
From: graftedlife at gmail.com (paul)
Date: Fri, 3 Jun 2016 14:28:59 +0200
Subject: [R-sig-ME] Related fixed and random factors and planned comparisons
	in a 2x2 design
Message-ID: <CALS4JYfoTbhwhy8S0kHePuw9pPv-NTkrsLrB2Z2YO5ks5gnnOA@mail.gmail.com>

Dear All,

I am trying to use mixed-effect modeling to analyze brain wave data from
two groups of participants when they were presented with two distinct
stimulus. The data points (scalp voltage) were gathered from the same set
of 9 nearby channels from each participant. And so I have the following
factors:

   - voltage: the dependent variable
   - group: the between-participant/within-item variable for groups A and B
   - item: the within-participant variable (note there are exactly only 2
   items, P and Q)
   - participant: identifying each participant across the two groups
   - channel: identifying each channel (note that data from these channels
   in a nearby region tend to display similar, thus correlated, patterns in
   the same participant)

The hypothesis is that only group B will show difference between P and Q
(i.e., there should be an interaction effect). So I established a
mixed-effect model using the lme4 package in R:

model <- lmer(voltage~1+group+item+(group:item)+(1|participant)+(1|channel),
              data=data, REML=FALSE)

Questions:

   1.

   I'm not sure if it is reasonable to add in participant as a random
   effect, because it is related to group and seems to weaken the effects of
   group. Would it be all right if I don't add it in?
   2.

   Because the data from nearby channels of the same participant tend to be
   correlated, I'm not sure if modeling participant and channel as crossed
   random effects is all right. But meanwhile it seems also strange if I treat
   channel as nested within participant, because they are the same set of
   channels across participants.
   3.

   The interaction term is significant. But how should planned comparisons
   be done (e.g., differences between groups A and B for P) or is it even
   necessary to run planned comparisons? I saw suggestions for t-tests,
   lsmeans, glht, or for more complicated methods such as breaking down the
   model and subsetting the data:

   data[, P_True:=(item=="P")]
   posthoc<-lmer(voltage~1+group
       +(1|participant)+1|channel)
       , data=data[item=="P"]
       , subset=data$P_True
       , REML=FALSE)

   But especially here comparing only between two groups while modeling
   participant as a random effect seems detrimental to the group effects. And
   I'm not sure if it is really OK to do so. On the other hand, because the
   data still contain non-independent data points (from nearby channels), I'm
   not sure if simply using t-tests is all right. Will non-parametric tests
   (e.g., Wilcoxon tests) do in such cases?
   4.

   I suppose I don't need to model item as a random effect because there
   are only two of them, one for each level, right?

I would really appreciate your help!!

Best regards,

Paul

	[[alternative HTML version deleted]]


From hannah.hlx at gmail.com  Mon Jun  6 16:57:35 2016
From: hannah.hlx at gmail.com (li li)
Date: Mon, 6 Jun 2016 10:57:35 -0400
Subject: [R-sig-ME] multcomp package
Message-ID: <CAHLnndbpu0dX4jFXqSevkcGB26H3yh8p2VpcJZWeYpc6KgC6ag@mail.gmail.com>

Hi all,
  After fitting a random slope and random intercept model using lme
function, I want
to test whether each of the fixed slopes is equal to zero (The output of
model is below).
Can this be done (testing each individual slope) using multcomp package?
  Thanks much for the help.
   Hanna

> summary(mod1)Linear mixed-effects model fit by REML
 Data: one
       AIC      BIC    logLik
  304.4703 330.1879 -140.2352

Random effects:
 Formula: ~1 + time | individual
 Structure: General positive-definite, Log-Cholesky parametrization
            StdDev       Corr
(Intercept) 0.2487869075 (Intr)
time        0.0001841179 -0.056
Residual    0.3718305953

Variance function:
 Structure: Different standard deviations per stratum
 Formula: ~1 | method
 Parameter estimates:
       3        1        2
 1.00000 26.59750 24.74476
Fixed effects: reponse ~ method * time
                Value Std.Error DF   t-value p-value(Intercept)
96.65395  3.528586 57 27.391694  0.0000
method2       1.17851  4.856026 57  0.242689  0.8091
method3       5.87505  3.528617 57  1.664973  0.1014time
0.07010  0.250983 57  0.279301  0.7810
method2:time -0.12616  0.360585 57 -0.349877  0.7277
method3:time -0.08010  0.251105 57 -0.318999  0.7509
 Correlation:
             (Intr) methd2 methd3 time   mthd2:
method2      -0.726
method3      -0.999  0.726
time         -0.779  0.566  0.779
method2:time  0.542 -0.712 -0.542 -0.696
method3:time  0.778 -0.566 -0.779 -0.999  0.696

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max
-2.67575293 -0.51633192  0.06742723  0.59706762  2.81061874

Number of Observations: 69
Number of Groups: 7 >

	[[alternative HTML version deleted]]


From epalmery at cns.umass.edu  Mon Jun  6 17:07:57 2016
From: epalmery at cns.umass.edu (Evan Palmer-Young)
Date: Mon, 6 Jun 2016 11:07:57 -0400
Subject: [R-sig-ME] multcomp package
In-Reply-To: <CAHLnndbpu0dX4jFXqSevkcGB26H3yh8p2VpcJZWeYpc6KgC6ag@mail.gmail.com>
References: <CAHLnndbpu0dX4jFXqSevkcGB26H3yh8p2VpcJZWeYpc6KgC6ag@mail.gmail.com>
Message-ID: <CAAge6+54jWsBjJ_hr5=72T4X_HJ8joytCMOomKPx4-FhB8fnNw@mail.gmail.com>

Hanna,
If you are interested in whether effect of time varies across individuals,
why don't you fit a model with the predictors (time*individual) as fixed
effects rather than random?

On Mon, Jun 6, 2016 at 10:57 AM, li li <hannah.hlx at gmail.com> wrote:

> Hi all,
>   After fitting a random slope and random intercept model using lme
> function, I want
> to test whether each of the fixed slopes is equal to zero (The output of
> model is below).
> Can this be done (testing each individual slope) using multcomp package?
>   Thanks much for the help.
>    Hanna
>
> > summary(mod1)Linear mixed-effects model fit by REML
>  Data: one
>        AIC      BIC    logLik
>   304.4703 330.1879 -140.2352
>
> Random effects:
>  Formula: ~1 + time | individual
>  Structure: General positive-definite, Log-Cholesky parametrization
>             StdDev       Corr
> (Intercept) 0.2487869075 (Intr)
> time        0.0001841179 -0.056
> Residual    0.3718305953
>
> Variance function:
>  Structure: Different standard deviations per stratum
>  Formula: ~1 | method
>  Parameter estimates:
>        3        1        2
>  1.00000 26.59750 24.74476
> Fixed effects: reponse ~ method * time
>                 Value Std.Error DF   t-value p-value(Intercept)
> 96.65395  3.528586 57 27.391694  0.0000
> method2       1.17851  4.856026 57  0.242689  0.8091
> method3       5.87505  3.528617 57  1.664973  0.1014time
> 0.07010  0.250983 57  0.279301  0.7810
> method2:time -0.12616  0.360585 57 -0.349877  0.7277
> method3:time -0.08010  0.251105 57 -0.318999  0.7509
>  Correlation:
>              (Intr) methd2 methd3 time   mthd2:
> method2      -0.726
> method3      -0.999  0.726
> time         -0.779  0.566  0.779
> method2:time  0.542 -0.712 -0.542 -0.696
> method3:time  0.778 -0.566 -0.779 -0.999  0.696
>
> Standardized Within-Group Residuals:
>         Min          Q1         Med          Q3         Max
> -2.67575293 -0.51633192  0.06742723  0.59706762  2.81061874
>
> Number of Observations: 69
> Number of Groups: 7 >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Department of Biology
221 Morrill Science Center
611 North Pleasant St
Amherst MA 01003
https://sites.google.com/a/cornell.edu/evan-palmer-young/

	[[alternative HTML version deleted]]


From sophiepicq at gmail.com  Mon Jun  6 18:50:30 2016
From: sophiepicq at gmail.com (Sophie Picq)
Date: Mon, 6 Jun 2016 18:50:30 +0200
Subject: [R-sig-ME] ICC estimates for overdispersed proportion or count data
Message-ID: <CADYHz+LkboKAPCsHdyr8mDm-s9+CtHaxAS7geh2DYwkgNrWE5w@mail.gmail.com>

Dear all,

I am trying to compute repeatability estimates for proportion/count data
 (intra-class correlation coefficients ICC) following Nakagawa & Schielzeth
(2010) on agressive mimicry data from reef fish.

My data: I observed 19 tagged fish directly on a reef, at repeated times
over 4 months (between 5 to 12 times each). Each observation period was 45
minutes long. The response variable is proportion of time spent following
(tracking) their model species. This has a known denominator/maximum
possible value corresponding to the total time of the observation period
(45mns).

I am dealing with overdispersion: my data has a lot of 0s and is skewed to
lower values, the max being 0,15 (Some fish just don't show that behaviour;
the ones who do don't do it a lot). I started using a binomial GLMM with
either additive or multiplicative overdispersion on this tracking
proportion using fish ID as the random effect in the rptR package of
Nakagawa & Schielzeth. My estimated overdispersion parameter using the
multiplicative overdispersion model is 71 (using glmmPQL and logit link,
rpt.binomGILMM.multi)

This makes me think that using a beta-binomial model would be more correct
to deal with this overdispersion, but I can't find any information on ICC
computations for beta-binomial GLMMs.

My questions are:

1. First, how do I know whether using a multiplicative or additive
overdispersion model is more correct? I get really different repeatability
results using either (really low with multiplicative, and around 0,5 with
additive). I've gone through Browne et al (2005) but still don't get how to
choose which one makes more sense.

2. Is there any way to compute ICC for a beta-binomial model and would that
be the way to go?

3. Since all total observation times were 45 minutes, I could also just use
the count data (total number of seconds tracking per observation) instead
of proportion of time spent tracking  (I have 2 observation events that had
to be shorter than 45 mns due to field work problems which I would have to
throw out...)

If that is more correct, I could use a Poisson GLMM. I did that using the
rptR package, but I still deal with a lot of overdispersion.  The estimated
overdispersion using the multiplicative model is 70. But the repeatability
estimates are actually really close using either additive or multiplicative
(around 0.5).

4.Given this overdispersion, is it more correct to compute ICC form a
negative binomial GLMM? I've seen 2 discussions on this topic but don't
know the current state:

http://stats.stackexchange.com/questions/166699/how-compute-the-intra-class-correlation-for-a-negative-binomial-mixed-model-in-l/169722#169722

and

https://github.com/lme4/lme4/issues/329

Please feel free to ask me if this was not clear enough...

I would really appreciate any help!

Thank you so much,

Sophie Picq

	[[alternative HTML version deleted]]


From T.Houslay at exeter.ac.uk  Mon Jun  6 19:10:18 2016
From: T.Houslay at exeter.ac.uk (Houslay, Tom)
Date: Mon, 6 Jun 2016 17:10:18 +0000
Subject: [R-sig-ME] Related fixed and random factors and planned
 comparisons in a 2x2 design
In-Reply-To: <mailman.1.1465034401.21395.r-sig-mixed-models@r-project.org>
References: <mailman.1.1465034401.21395.r-sig-mixed-models@r-project.org>
Message-ID: <DB6PR0301MB23112A3EED4FF8C98B6DAD94D25C0@DB6PR0301MB2311.eurprd03.prod.outlook.com>

Hi Paul,

I don't think anyone's responded to this yet, but my main point would be that you should check out Schielzeth & Nakagawa's 2012 paper 'Nested by design' ( http://onlinelibrary.wiley.com/doi/10.1111/j.2041-210x.2012.00251.x/abstract ) for a nice rundown on structuring your model for this type of data. 

It may also be worth thinking about how random intercepts work in a visual sense; there are a variety of tools that help you do this from a model (packages sjplot, visreg, broom), or you can just plot different levels yourself (eg consider plotting the means for AP, AQ, BP, BQ; the same with mean values from each individual overplotted around these group means; and even the group means with all points shown, perhaps coloured by individual - ggplot is really useful for getting this type of figure together quickly).

As to some of your other questions:

1) You need to keep participant ID in. I'm not 100% on your data structure from the question, but you certainly seem to have repeated measures for individuals (I'm assuming that groups A and B each contain multiple individuals, none of whom were in both groups, and each of which were shown both objects P and Q, in a random order). It's not surprising that the effects of group are weakened if you remove participant ID, because you're then effectively entering pseudoreplication into your model (ie, telling your model that all the data points within a group are independent, when that isn't the case).

2) I think channel should be nested within individual, with a model something like model <- lmer(voltage ~ group * item + (1|participant/channel), data = ...)

3) This really depends on what your interest is. If you simply want to show that there is an overall interaction effect, then your p-value from a likelihood ratio test of the model with/without the interaction term gives significance of this interaction, and then a plot of predicted values for the fixed effects (w/ data overplotted if possible) should show the trends. You could also use binary dummy variables to make more explicit contrasts, but it's worth reading up on these a bit more. I don't really use these type of comparisons very much, so I can't comment further I'm afraid.

4) Your item is like treatment in this case - you appear to be more interested in the effect of different items (rather than how much variation 'item' explains), so keep this as a fixed effect and not as random.

Hope some of this is useful,

Tom


________________________________________


Message: 1
Date: Fri, 3 Jun 2016 14:28:59 +0200
From: paul <graftedlife at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Related fixed and random factors and planned
        comparisons     in a 2x2 design
Message-ID:
        <CALS4JYfoTbhwhy8S0kHePuw9pPv-NTkrsLrB2Z2YO5ks5gnnOA at mail.gmail.com>
Content-Type: text/plain; charset="UTF-8"

Dear All,

I am trying to use mixed-effect modeling to analyze brain wave data from
two groups of participants when they were presented with two distinct
stimulus. The data points (scalp voltage) were gathered from the same set
of 9 nearby channels from each participant. And so I have the following
factors:

   - voltage: the dependent variable
   - group: the between-participant/within-item variable for groups A and B
   - item: the within-participant variable (note there are exactly only 2
   items, P and Q)
   - participant: identifying each participant across the two groups
   - channel: identifying each channel (note that data from these channels
   in a nearby region tend to display similar, thus correlated, patterns in
   the same participant)

The hypothesis is that only group B will show difference between P and Q
(i.e., there should be an interaction effect). So I established a
mixed-effect model using the lme4 package in R:

model <- lmer(voltage~1+group+item+(group:item)+(1|participant)+(1|channel),
              data=data, REML=FALSE)

Questions:

   1.

   I'm not sure if it is reasonable to add in participant as a random
   effect, because it is related to group and seems to weaken the effects of
   group. Would it be all right if I don't add it in?
   2.

   Because the data from nearby channels of the same participant tend to be
   correlated, I'm not sure if modeling participant and channel as crossed
   random effects is all right. But meanwhile it seems also strange if I treat
   channel as nested within participant, because they are the same set of
   channels across participants.
   3.

   The interaction term is significant. But how should planned comparisons
   be done (e.g., differences between groups A and B for P) or is it even
   necessary to run planned comparisons? I saw suggestions for t-tests,
   lsmeans, glht, or for more complicated methods such as breaking down the
   model and subsetting the data:

   data[, P_True:=(item=="P")]
   posthoc<-lmer(voltage~1+group
       +(1|participant)+1|channel)
       , data=data[item=="P"]
       , subset=data$P_True
       , REML=FALSE)

   But especially here comparing only between two groups while modeling
   participant as a random effect seems detrimental to the group effects. And
   I'm not sure if it is really OK to do so. On the other hand, because the
   data still contain non-independent data points (from nearby channels), I'm
   not sure if simply using t-tests is all right. Will non-parametric tests
   (e.g., Wilcoxon tests) do in such cases?
   4.

   I suppose I don't need to model item as a random effect because there
   are only two of them, one for each level, right?

I would really appreciate your help!!

Best regards,

Paul

        [[alternative HTML version deleted]]


From graftedlife at gmail.com  Mon Jun  6 21:06:02 2016
From: graftedlife at gmail.com (paul)
Date: Mon, 6 Jun 2016 21:06:02 +0200
Subject: [R-sig-ME] Related fixed and random factors and planned
	comparisons in a 2x2 design
In-Reply-To: <DB6PR0301MB23112A3EED4FF8C98B6DAD94D25C0@DB6PR0301MB2311.eurprd03.prod.outlook.com>
References: <mailman.1.1465034401.21395.r-sig-mixed-models@r-project.org>
	<DB6PR0301MB23112A3EED4FF8C98B6DAD94D25C0@DB6PR0301MB2311.eurprd03.prod.outlook.com>
Message-ID: <CALS4JYeNMMNeA4pD89BKeKBWMcFoKG2x1z6XJaAq3Oa2Xxb1Gg@mail.gmail.com>

Dear Tom,

Many thanks for these very helpful comments and suggestions! Would you just
allow me to ask some further questions:

1. I've been considering whether to cross or to nest the random effects for
quite a while. Data from the same channel across participants do show
corresponding trends (thus a bit different from the case when, e.g.,
sampling nine neurons from the same individual). Would nesting channel
within participant deal with that relationship?

2. I actually also tried nesting channel within participant. However, when
I proceeded to run planned comparisons (I guess I'd better have them done
because of their theoretical significance) based on this mixed-effect
modeling approach (as illustrated in the earlier mail but with the random
factor as (1|participant/channel), to maintain consistency of analytical
methods), R gave me an error message:

Error: number of levels of each grouping factor must be < number of observations


I think this is because in my data, each participant only contributes one
data point per channel and thus the data points are not enough. I guess
that probably means I can't go on in this direction to run the planned
comparisons... (?) I'm not pretty sure how contrasts based on binary dummy
variables may be done and will try to further explore that. But before I
establish the mixed model I already set up orthogonal contrasts for group
and item in the dataset using the function contrasts(). Does this have
anything to do with what you meant?

3. I worried about pseudoreplicability when participant ID is not included.
Concerning this point, later it came to me that pseudoreplicability usually
occurred in cases when multiple responses from the same individual are
grouped in the same cell, rendering the data within the same cell
non-independent (similar to the case of repeated-measure ANOVA? sorry if I
got a wrong understanding...). But as mentioned earlier in my data, each
participant only contributes one data point per channel, when channel alone
is already modeled as a random factor, would that mean all data points
within a cell all come from different participants and thus in this case
may deal with the independence assumption? (Again I'm sorry if my concept
is wrong and would appreciate instructions on this point...)

Many, many thanks!

Paul














2016-06-06 19:10 GMT+02:00 Houslay, Tom <T.Houslay at exeter.ac.uk>:

> Hi Paul,
>
> I don't think anyone's responded to this yet, but my main point would be
> that you should check out Schielzeth & Nakagawa's 2012 paper 'Nested by
> design' (
> http://onlinelibrary.wiley.com/doi/10.1111/j.2041-210x.2012.00251.x/abstract
> ) for a nice rundown on structuring your model for this type of data.
>
> It may also be worth thinking about how random intercepts work in a visual
> sense; there are a variety of tools that help you do this from a model
> (packages sjplot, visreg, broom), or you can just plot different levels
> yourself (eg consider plotting the means for AP, AQ, BP, BQ; the same with
> mean values from each individual overplotted around these group means; and
> even the group means with all points shown, perhaps coloured by individual
> - ggplot is really useful for getting this type of figure together quickly).
>
> As to some of your other questions:
>
> 1) You need to keep participant ID in. I'm not 100% on your data structure
> from the question, but you certainly seem to have repeated measures for
> individuals (I'm assuming that groups A and B each contain multiple
> individuals, none of whom were in both groups, and each of which were shown
> both objects P and Q, in a random order). It's not surprising that the
> effects of group are weakened if you remove participant ID, because you're
> then effectively entering pseudoreplication into your model (ie, telling
> your model that all the data points within a group are independent, when
> that isn't the case).
>
> 2) I think channel should be nested within individual, with a model
> something like model <- lmer(voltage ~ group * item +
> (1|participant/channel), data = ...)
>
> 3) This really depends on what your interest is. If you simply want to
> show that there is an overall interaction effect, then your p-value from a
> likelihood ratio test of the model with/without the interaction term gives
> significance of this interaction, and then a plot of predicted values for
> the fixed effects (w/ data overplotted if possible) should show the trends.
> You could also use binary dummy variables to make more explicit contrasts,
> but it's worth reading up on these a bit more. I don't really use these
> type of comparisons very much, so I can't comment further I'm afraid.
>
> 4) Your item is like treatment in this case - you appear to be more
> interested in the effect of different items (rather than how much variation
> 'item' explains), so keep this as a fixed effect and not as random.
>
> Hope some of this is useful,
>
> Tom
>
>
> ________________________________________
>
>
> Message: 1
> Date: Fri, 3 Jun 2016 14:28:59 +0200
> From: paul <graftedlife at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Related fixed and random factors and planned
>         comparisons     in a 2x2 design
> Message-ID:
>         <
> CALS4JYfoTbhwhy8S0kHePuw9pPv-NTkrsLrB2Z2YO5ks5gnnOA at mail.gmail.com>
> Content-Type: text/plain; charset="UTF-8"
>
> Dear All,
>
> I am trying to use mixed-effect modeling to analyze brain wave data from
> two groups of participants when they were presented with two distinct
> stimulus. The data points (scalp voltage) were gathered from the same set
> of 9 nearby channels from each participant. And so I have the following
> factors:
>
>    - voltage: the dependent variable
>    - group: the between-participant/within-item variable for groups A and B
>    - item: the within-participant variable (note there are exactly only 2
>    items, P and Q)
>    - participant: identifying each participant across the two groups
>    - channel: identifying each channel (note that data from these channels
>    in a nearby region tend to display similar, thus correlated, patterns in
>    the same participant)
>
> The hypothesis is that only group B will show difference between P and Q
> (i.e., there should be an interaction effect). So I established a
> mixed-effect model using the lme4 package in R:
>
> model <-
> lmer(voltage~1+group+item+(group:item)+(1|participant)+(1|channel),
>               data=data, REML=FALSE)
>
> Questions:
>
>    1.
>
>    I'm not sure if it is reasonable to add in participant as a random
>    effect, because it is related to group and seems to weaken the effects
> of
>    group. Would it be all right if I don't add it in?
>    2.
>
>    Because the data from nearby channels of the same participant tend to be
>    correlated, I'm not sure if modeling participant and channel as crossed
>    random effects is all right. But meanwhile it seems also strange if I
> treat
>    channel as nested within participant, because they are the same set of
>    channels across participants.
>    3.
>
>    The interaction term is significant. But how should planned comparisons
>    be done (e.g., differences between groups A and B for P) or is it even
>    necessary to run planned comparisons? I saw suggestions for t-tests,
>    lsmeans, glht, or for more complicated methods such as breaking down the
>    model and subsetting the data:
>
>    data[, P_True:=(item=="P")]
>    posthoc<-lmer(voltage~1+group
>        +(1|participant)+1|channel)
>        , data=data[item=="P"]
>        , subset=data$P_True
>        , REML=FALSE)
>
>    But especially here comparing only between two groups while modeling
>    participant as a random effect seems detrimental to the group effects.
> And
>    I'm not sure if it is really OK to do so. On the other hand, because the
>    data still contain non-independent data points (from nearby channels),
> I'm
>    not sure if simply using t-tests is all right. Will non-parametric tests
>    (e.g., Wilcoxon tests) do in such cases?
>    4.
>
>    I suppose I don't need to model item as a random effect because there
>    are only two of them, one for each level, right?
>
> I would really appreciate your help!!
>
> Best regards,
>
> Paul
>
>         [[alternative HTML version deleted]]
>
>
>

	[[alternative HTML version deleted]]


From T.Houslay at exeter.ac.uk  Mon Jun  6 21:51:26 2016
From: T.Houslay at exeter.ac.uk (Houslay, Tom)
Date: Mon, 6 Jun 2016 19:51:26 +0000
Subject: [R-sig-ME] Related fixed and random factors and planned
 comparisons in a 2x2 design
In-Reply-To: <CALS4JYeNMMNeA4pD89BKeKBWMcFoKG2x1z6XJaAq3Oa2Xxb1Gg@mail.gmail.com>
References: <mailman.1.1465034401.21395.r-sig-mixed-models@r-project.org>
	<DB6PR0301MB23112A3EED4FF8C98B6DAD94D25C0@DB6PR0301MB2311.eurprd03.prod.outlook.com>,
	<CALS4JYeNMMNeA4pD89BKeKBWMcFoKG2x1z6XJaAq3Oa2Xxb1Gg@mail.gmail.com>
Message-ID: <DB6PR0301MB23116F63CE3C4C84D77D2733D25C0@DB6PR0301MB2311.eurprd03.prod.outlook.com>

Hi Paul,


I think you're right here in that actually you don't want to nest channel inside participant (which led to that error message - sorry, should have seen that coming!).


It's hard to know without seeing data plotted, but my guess from your email is that you probably see some clustering both at individual level and at channel level? Perhaps separate random effects, ie (1|Participant) + (1|Channel), is the way to go (and then you shouldn't have the problem as regards number of observations - instead you'll have an intercept deviation for each of your N individuals, and also intercept deviations for each of your 9 channels). You certainly want to keep the participant intercept in though, as each individual gets both items (right?), so you need to model that association. You can use your variance components output from lmer to determine what proportion of the phenotypic variance (conditional on your fixed effects) is explained by each of these components, eg V(individual)/(V(individual) + V(channel) + V(residual) would give you the proportion explained by differences among individuals in their voltage. It would be cool to know if differences among individuals, or among channels, is driving the variation that you find. I think using the sjplot function for lmer would be useful to look at the levels of your random effects:


http://strengejacke.de/sjPlot/sjp.lmer/


As for 'contrasts', again I haven't used that particular package, but from a brief glance it looks like you're on the right track - binary coding is the 'simple coding' as set out here:


http://www.ats.ucla.edu/stat/r/library/contrast_coding.htm


Good luck!


Tom


________________________________
From: paul <graftedlife at gmail.com>
Sent: 06 June 2016 20:06:02
To: Houslay, Tom
Cc: r-sig-mixed-models at r-project.org
Subject: Re: Related fixed and random factors and planned comparisons in a 2x2 design

Dear Tom,

Many thanks for these very helpful comments and suggestions! Would you just allow me to ask some further questions:

1. I've been considering whether to cross or to nest the random effects for quite a while. Data from the same channel across participants do show corresponding trends (thus a bit different from the case when, e.g., sampling nine neurons from the same individual). Would nesting channel within participant deal with that relationship?

2. I actually also tried nesting channel within participant. However, when I proceeded to run planned comparisons (I guess I'd better have them done because of their theoretical significance) based on this mixed-effect modeling approach (as illustrated in the earlier mail but with the random factor as (1|participant/channel), to maintain consistency of analytical methods), R gave me an error message:


Error: number of levels of each grouping factor must be < number of observations

I think this is because in my data, each participant only contributes one data point per channel and thus the data points are not enough. I guess that probably means I can't go on in this direction to run the planned comparisons... (?) I'm not pretty sure how contrasts based on binary dummy variables may be done and will try to further explore that. But before I establish the mixed model I already set up orthogonal contrasts for group and item in the dataset using the function contrasts(). Does this have anything to do with what you meant?

3. I worried about pseudoreplicability when participant ID is not included. Concerning this point, later it came to me that pseudoreplicability usually occurred in cases when multiple responses from the same individual are grouped in the same cell, rendering the data within the same cell non-independent (similar to the case of repeated-measure ANOVA? sorry if I got a wrong understanding...). But as mentioned earlier in my data, each participant only contributes one data point per channel, when channel alone is already modeled as a random factor, would that mean all data points within a cell all come from different participants and thus in this case may deal with the independence assumption? (Again I'm sorry if my concept is wrong and would appreciate instructions on this point...)

Many, many thanks!

Paul














2016-06-06 19:10 GMT+02:00 Houslay, Tom <T.Houslay at exeter.ac.uk<mailto:T.Houslay at exeter.ac.uk>>:
Hi Paul,

I don't think anyone's responded to this yet, but my main point would be that you should check out Schielzeth & Nakagawa's 2012 paper 'Nested by design' ( http://onlinelibrary.wiley.com/doi/10.1111/j.2041-210x.2012.00251.x/abstract ) for a nice rundown on structuring your model for this type of data.

It may also be worth thinking about how random intercepts work in a visual sense; there are a variety of tools that help you do this from a model (packages sjplot, visreg, broom), or you can just plot different levels yourself (eg consider plotting the means for AP, AQ, BP, BQ; the same with mean values from each individual overplotted around these group means; and even the group means with all points shown, perhaps coloured by individual - ggplot is really useful for getting this type of figure together quickly).

As to some of your other questions:

1) You need to keep participant ID in. I'm not 100% on your data structure from the question, but you certainly seem to have repeated measures for individuals (I'm assuming that groups A and B each contain multiple individuals, none of whom were in both groups, and each of which were shown both objects P and Q, in a random order). It's not surprising that the effects of group are weakened if you remove participant ID, because you're then effectively entering pseudoreplication into your model (ie, telling your model that all the data points within a group are independent, when that isn't the case).

2) I think channel should be nested within individual, with a model something like model <- lmer(voltage ~ group * item + (1|participant/channel), data = ...)

3) This really depends on what your interest is. If you simply want to show that there is an overall interaction effect, then your p-value from a likelihood ratio test of the model with/without the interaction term gives significance of this interaction, and then a plot of predicted values for the fixed effects (w/ data overplotted if possible) should show the trends. You could also use binary dummy variables to make more explicit contrasts, but it's worth reading up on these a bit more. I don't really use these type of comparisons very much, so I can't comment further I'm afraid.

4) Your item is like treatment in this case - you appear to be more interested in the effect of different items (rather than how much variation 'item' explains), so keep this as a fixed effect and not as random.

Hope some of this is useful,

Tom


________________________________________


Message: 1
Date: Fri, 3 Jun 2016 14:28:59 +0200
From: paul <graftedlife at gmail.com<mailto:graftedlife at gmail.com>>
To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] Related fixed and random factors and planned
        comparisons     in a 2x2 design
Message-ID:
        <CALS4JYfoTbhwhy8S0kHePuw9pPv-NTkrsLrB2Z2YO5ks5gnnOA at mail.gmail.com<mailto:CALS4JYfoTbhwhy8S0kHePuw9pPv-NTkrsLrB2Z2YO5ks5gnnOA at mail.gmail.com>>
Content-Type: text/plain; charset="UTF-8"

Dear All,

I am trying to use mixed-effect modeling to analyze brain wave data from
two groups of participants when they were presented with two distinct
stimulus. The data points (scalp voltage) were gathered from the same set
of 9 nearby channels from each participant. And so I have the following
factors:

   - voltage: the dependent variable
   - group: the between-participant/within-item variable for groups A and B
   - item: the within-participant variable (note there are exactly only 2
   items, P and Q)
   - participant: identifying each participant across the two groups
   - channel: identifying each channel (note that data from these channels
   in a nearby region tend to display similar, thus correlated, patterns in
   the same participant)

The hypothesis is that only group B will show difference between P and Q
(i.e., there should be an interaction effect). So I established a
mixed-effect model using the lme4 package in R:

model <- lmer(voltage~1+group+item+(group:item)+(1|participant)+(1|channel),
              data=data, REML=FALSE)

Questions:

   1.

   I'm not sure if it is reasonable to add in participant as a random
   effect, because it is related to group and seems to weaken the effects of
   group. Would it be all right if I don't add it in?
   2.

   Because the data from nearby channels of the same participant tend to be
   correlated, I'm not sure if modeling participant and channel as crossed
   random effects is all right. But meanwhile it seems also strange if I treat
   channel as nested within participant, because they are the same set of
   channels across participants.
   3.

   The interaction term is significant. But how should planned comparisons
   be done (e.g., differences between groups A and B for P) or is it even
   necessary to run planned comparisons? I saw suggestions for t-tests,
   lsmeans, glht, or for more complicated methods such as breaking down the
   model and subsetting the data:

   data[, P_True:=(item=="P")]
   posthoc<-lmer(voltage~1+group
       +(1|participant)+1|channel)
       , data=data[item=="P"]
       , subset=data$P_True
       , REML=FALSE)

   But especially here comparing only between two groups while modeling
   participant as a random effect seems detrimental to the group effects. And
   I'm not sure if it is really OK to do so. On the other hand, because the
   data still contain non-independent data points (from nearby channels), I'm
   not sure if simply using t-tests is all right. Will non-parametric tests
   (e.g., Wilcoxon tests) do in such cases?
   4.

   I suppose I don't need to model item as a random effect because there
   are only two of them, one for each level, right?

I would really appreciate your help!!

Best regards,

Paul

        [[alternative HTML version deleted]]




	[[alternative HTML version deleted]]


From graftedlife at gmail.com  Mon Jun  6 21:57:00 2016
From: graftedlife at gmail.com (paul)
Date: Mon, 6 Jun 2016 21:57:00 +0200
Subject: [R-sig-ME] Related fixed and random factors and planned
	comparisons in a 2x2 design
In-Reply-To: <DB6PR0301MB23116F63CE3C4C84D77D2733D25C0@DB6PR0301MB2311.eurprd03.prod.outlook.com>
References: <mailman.1.1465034401.21395.r-sig-mixed-models@r-project.org>
	<DB6PR0301MB23112A3EED4FF8C98B6DAD94D25C0@DB6PR0301MB2311.eurprd03.prod.outlook.com>
	<CALS4JYeNMMNeA4pD89BKeKBWMcFoKG2x1z6XJaAq3Oa2Xxb1Gg@mail.gmail.com>
	<DB6PR0301MB23116F63CE3C4C84D77D2733D25C0@DB6PR0301MB2311.eurprd03.prod.outlook.com>
Message-ID: <CALS4JYdbr_2SiM2AdKEOM14CpcSKsWXe0S09TAkXQ=awBJzOiw@mail.gmail.com>

Dear Tom,

Thank you so much for these detailed replies and I appreciate your help!

Sincerely,

Paul

2016-06-06 21:51 GMT+02:00 Houslay, Tom <T.Houslay at exeter.ac.uk>:

> Hi Paul,
>
>
> I think you're right here in that actually you don't want to nest channel
> inside participant (which led to that error message - sorry, should have
> seen that coming!).
>
>
> It's hard to know without seeing data plotted, but my guess from your
> email is that you probably see some clustering both at individual level and
> at channel level? Perhaps separate random effects, ie (1|Participant) +
> (1|Channel), is the way to go (and then you shouldn't have the problem as
> regards number of observations - instead you'll have an intercept deviation
> for each of your N individuals, and also intercept deviations for each of
> your 9 channels). You certainly want to keep the participant intercept in
> though, as each individual gets both items (right?), so you need to model
> that association. You can use your variance components output from lmer to
> determine what proportion of the phenotypic variance (conditional on your
> fixed effects) is explained by each of these components, eg
> V(individual)/(V(individual) + V(channel) + V(residual) would give you the
> proportion explained by differences among individuals in their voltage. It
> would be cool to know if differences among individuals, or among
> channels, is driving the variation that you find. I think using the sjplot
> function for lmer would be useful to look at the levels of your random
> effects:
>
>
> http://strengejacke.de/sjPlot/sjp.lmer/
>
>
> As for 'contrasts', again I haven't used that particular package, but from
> a brief glance it looks like you're on the right track - binary coding is
> the 'simple coding' as set out here:
>
>
> http://www.ats.ucla.edu/stat/r/library/contrast_coding.htm
>
>
> Good luck!
>
>
> Tom
>
>
> ------------------------------
> *From:* paul <graftedlife at gmail.com>
> *Sent:* 06 June 2016 20:06:02
> *To:* Houslay, Tom
> *Cc:* r-sig-mixed-models at r-project.org
> *Subject:* Re: Related fixed and random factors and planned comparisons
> in a 2x2 design
>
> Dear Tom,
>
> Many thanks for these very helpful comments and suggestions! Would you
> just allow me to ask some further questions:
>
> 1. I've been considering whether to cross or to nest the random effects
> for quite a while. Data from the same channel across participants do show
> corresponding trends (thus a bit different from the case when, e.g.,
> sampling nine neurons from the same individual). Would nesting channel
> within participant deal with that relationship?
>
> 2. I actually also tried nesting channel within participant. However, when
> I proceeded to run planned comparisons (I guess I'd better have them done
> because of their theoretical significance) based on this mixed-effect
> modeling approach (as illustrated in the earlier mail but with the random
> factor as (1|participant/channel), to maintain consistency of analytical
> methods), R gave me an error message:
>
> Error: number of levels of each grouping factor must be < number of observations
>
>
> I think this is because in my data, each participant only contributes one
> data point per channel and thus the data points are not enough. I guess
> that probably means I can't go on in this direction to run the planned
> comparisons... (?) I'm not pretty sure how contrasts based on binary dummy
> variables may be done and will try to further explore that. But before I
> establish the mixed model I already set up orthogonal contrasts for group
> and item in the dataset using the function contrasts(). Does this have
> anything to do with what you meant?
>
> 3. I worried about pseudoreplicability when participant ID is not
> included. Concerning this point, later it came to me that
> pseudoreplicability usually occurred in cases when multiple responses from
> the same individual are grouped in the same cell, rendering the data within
> the same cell non-independent (similar to the case of repeated-measure
> ANOVA? sorry if I got a wrong understanding...). But as mentioned earlier
> in my data, each participant only contributes one data point per channel,
> when channel alone is already modeled as a random factor, would that mean
> all data points within a cell all come from different participants and thus
> in this case may deal with the independence assumption? (Again I'm sorry if
> my concept is wrong and would appreciate instructions on this point...)
>
> Many, many thanks!
>
> Paul
>
>
>
>
>
>
>
>
>
>
>
>
>
>
> 2016-06-06 19:10 GMT+02:00 Houslay, Tom <T.Houslay at exeter.ac.uk>:
>
>> Hi Paul,
>>
>> I don't think anyone's responded to this yet, but my main point would be
>> that you should check out Schielzeth & Nakagawa's 2012 paper 'Nested by
>> design' (
>> http://onlinelibrary.wiley.com/doi/10.1111/j.2041-210x.2012.00251.x/abstract
>> ) for a nice rundown on structuring your model for this type of data.
>>
>> It may also be worth thinking about how random intercepts work in a
>> visual sense; there are a variety of tools that help you do this from a
>> model (packages sjplot, visreg, broom), or you can just plot different
>> levels yourself (eg consider plotting the means for AP, AQ, BP, BQ; the
>> same with mean values from each individual overplotted around these group
>> means; and even the group means with all points shown, perhaps coloured by
>> individual - ggplot is really useful for getting this type of figure
>> together quickly).
>>
>> As to some of your other questions:
>>
>> 1) You need to keep participant ID in. I'm not 100% on your data
>> structure from the question, but you certainly seem to have repeated
>> measures for individuals (I'm assuming that groups A and B each contain
>> multiple individuals, none of whom were in both groups, and each of which
>> were shown both objects P and Q, in a random order). It's not surprising
>> that the effects of group are weakened if you remove participant ID,
>> because you're then effectively entering pseudoreplication into your model
>> (ie, telling your model that all the data points within a group are
>> independent, when that isn't the case).
>>
>> 2) I think channel should be nested within individual, with a model
>> something like model <- lmer(voltage ~ group * item +
>> (1|participant/channel), data = ...)
>>
>> 3) This really depends on what your interest is. If you simply want to
>> show that there is an overall interaction effect, then your p-value from a
>> likelihood ratio test of the model with/without the interaction term gives
>> significance of this interaction, and then a plot of predicted values for
>> the fixed effects (w/ data overplotted if possible) should show the trends.
>> You could also use binary dummy variables to make more explicit contrasts,
>> but it's worth reading up on these a bit more. I don't really use these
>> type of comparisons very much, so I can't comment further I'm afraid.
>>
>> 4) Your item is like treatment in this case - you appear to be more
>> interested in the effect of different items (rather than how much variation
>> 'item' explains), so keep this as a fixed effect and not as random.
>>
>> Hope some of this is useful,
>>
>> Tom
>>
>>
>> ________________________________________
>>
>>
>> Message: 1
>> Date: Fri, 3 Jun 2016 14:28:59 +0200
>> From: paul <graftedlife at gmail.com>
>> To: r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] Related fixed and random factors and planned
>>         comparisons     in a 2x2 design
>> Message-ID:
>>         <
>> CALS4JYfoTbhwhy8S0kHePuw9pPv-NTkrsLrB2Z2YO5ks5gnnOA at mail.gmail.com>
>> Content-Type: text/plain; charset="UTF-8"
>>
>> Dear All,
>>
>> I am trying to use mixed-effect modeling to analyze brain wave data from
>> two groups of participants when they were presented with two distinct
>> stimulus. The data points (scalp voltage) were gathered from the same set
>> of 9 nearby channels from each participant. And so I have the following
>> factors:
>>
>>    - voltage: the dependent variable
>>    - group: the between-participant/within-item variable for groups A and
>> B
>>    - item: the within-participant variable (note there are exactly only 2
>>    items, P and Q)
>>    - participant: identifying each participant across the two groups
>>    - channel: identifying each channel (note that data from these channels
>>    in a nearby region tend to display similar, thus correlated, patterns
>> in
>>    the same participant)
>>
>> The hypothesis is that only group B will show difference between P and Q
>> (i.e., there should be an interaction effect). So I established a
>> mixed-effect model using the lme4 package in R:
>>
>> model <-
>> lmer(voltage~1+group+item+(group:item)+(1|participant)+(1|channel),
>>               data=data, REML=FALSE)
>>
>> Questions:
>>
>>    1.
>>
>>    I'm not sure if it is reasonable to add in participant as a random
>>    effect, because it is related to group and seems to weaken the effects
>> of
>>    group. Would it be all right if I don't add it in?
>>    2.
>>
>>    Because the data from nearby channels of the same participant tend to
>> be
>>    correlated, I'm not sure if modeling participant and channel as crossed
>>    random effects is all right. But meanwhile it seems also strange if I
>> treat
>>    channel as nested within participant, because they are the same set of
>>    channels across participants.
>>    3.
>>
>>    The interaction term is significant. But how should planned comparisons
>>    be done (e.g., differences between groups A and B for P) or is it even
>>    necessary to run planned comparisons? I saw suggestions for t-tests,
>>    lsmeans, glht, or for more complicated methods such as breaking down
>> the
>>    model and subsetting the data:
>>
>>    data[, P_True:=(item=="P")]
>>    posthoc<-lmer(voltage~1+group
>>        +(1|participant)+1|channel)
>>        , data=data[item=="P"]
>>        , subset=data$P_True
>>        , REML=FALSE)
>>
>>    But especially here comparing only between two groups while modeling
>>    participant as a random effect seems detrimental to the group effects.
>> And
>>    I'm not sure if it is really OK to do so. On the other hand, because
>> the
>>    data still contain non-independent data points (from nearby channels),
>> I'm
>>    not sure if simply using t-tests is all right. Will non-parametric
>> tests
>>    (e.g., Wilcoxon tests) do in such cases?
>>    4.
>>
>>    I suppose I don't need to model item as a random effect because there
>>    are only two of them, one for each level, right?
>>
>> I would really appreciate your help!!
>>
>> Best regards,
>>
>> Paul
>>
>>         [[alternative HTML version deleted]]
>>
>>
>>
>

	[[alternative HTML version deleted]]


From Phillip.Alday at unisa.edu.au  Tue Jun  7 02:57:06 2016
From: Phillip.Alday at unisa.edu.au (Phillip Alday)
Date: Tue, 7 Jun 2016 00:57:06 +0000
Subject: [R-sig-ME] Related fixed and random factors and
	planned	comparisons in a 2x2 design
In-Reply-To: <CALS4JYdbr_2SiM2AdKEOM14CpcSKsWXe0S09TAkXQ=awBJzOiw@mail.gmail.com>
References: <mailman.1.1465034401.21395.r-sig-mixed-models@r-project.org>
	<DB6PR0301MB23112A3EED4FF8C98B6DAD94D25C0@DB6PR0301MB2311.eurprd03.prod.outlook.com>
	<CALS4JYeNMMNeA4pD89BKeKBWMcFoKG2x1z6XJaAq3Oa2Xxb1Gg@mail.gmail.com>
	<DB6PR0301MB23116F63CE3C4C84D77D2733D25C0@DB6PR0301MB2311.eurprd03.prod.outlook.com>
	<CALS4JYdbr_2SiM2AdKEOM14CpcSKsWXe0S09TAkXQ=awBJzOiw@mail.gmail.com>
Message-ID: <a867be4c547740e1a7b8d47ab8ffb85b@ITUPW-EXMBOX2C.UniNet.unisa.edu.au>

In terms of contrast coding, two more helpful resources are:

http://talklab.psy.gla.ac.uk/tvw/catpred/

http://palday.bitbucket.org/stats/coding.html

Channel makes sense as a random effect / grouping term for your particular design, *not* nested within participant. The implicit crossing given by (1|Participant) + (1|Channel) models [omitting any slope terms to focus on the grouping variables] (1) interindividual differences in the EEG and (2) differences between electrodes because closely located electrodes can be thought of as samples from a population consisting of a given Region of Interest (ROI), especially if the electrode placement is somewhat symmetric. The differences resulting from variance in electrode placement between participants will be covered by the implicit crossing of these two random effects. 

Note that using channel as a random effect is somewhat more difficult if you're doing a whole scalp analysis as sampling across the whole scalp can be viewed as sampling from multiple ROIs, i.e. multiple populations. Two possible solutions are (1) to include ROI in the fixed effects and keep channel in the random effects and (2) model channel as a two or three continuous spatial variables (e.g. displacement from midline or displacement from center based on 10-20 coordinates, or spatial coordinates of the sort used in source localisation) in the fixed effects.  In the case of (1), the channel random effect would then be modelling the typical variance within ROIs (because that's hopefully the major source of variance structured  by channel left over after modelling ROI and your experimental manipulation). If this within-variance differs greatly between between ROIs, then this may be a sub-optimal modelling choice. In the case of (2), it might still make sense to additionally model channel as a random effect (i.e. the RE with the factor consisting of channel names, the FE with the continuous coordinates), see Thierry Onkelinx's posts on the subject and http://rpubs.com/INBOstats/both_fixed_random , but I haven't thought about this enough nor examined the resulting model fits.

Best,
Phillip

-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of paul
Sent: Tuesday, 7 June 2016 5:27 AM
To: Houslay, Tom <T.Houslay at exeter.ac.uk>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Related fixed and random factors and planned comparisons in a 2x2 design

Dear Tom,

Thank you so much for these detailed replies and I appreciate your help!

Sincerely,

Paul

2016-06-06 21:51 GMT+02:00 Houslay, Tom <T.Houslay at exeter.ac.uk>:

> Hi Paul,
>
>
> I think you're right here in that actually you don't want to nest 
> channel inside participant (which led to that error message - sorry, 
> should have seen that coming!).
>
>
> It's hard to know without seeing data plotted, but my guess from your 
> email is that you probably see some clustering both at individual 
> level and at channel level? Perhaps separate random effects, ie 
> (1|Participant) + (1|Channel), is the way to go (and then you 
> shouldn't have the problem as regards number of observations - instead 
> you'll have an intercept deviation for each of your N individuals, and 
> also intercept deviations for each of your 9 channels). You certainly 
> want to keep the participant intercept in though, as each individual 
> gets both items (right?), so you need to model that association. You 
> can use your variance components output from lmer to determine what 
> proportion of the phenotypic variance (conditional on your fixed 
> effects) is explained by each of these components, eg
> V(individual)/(V(individual) + V(channel) + V(residual) would give you 
> the proportion explained by differences among individuals in their 
> voltage. It would be cool to know if differences among individuals, or 
> among channels, is driving the variation that you find. I think using 
> the sjplot function for lmer would be useful to look at the levels of 
> your random
> effects:
>
>
> http://strengejacke.de/sjPlot/sjp.lmer/
>
>
> As for 'contrasts', again I haven't used that particular package, but 
> from a brief glance it looks like you're on the right track - binary 
> coding is the 'simple coding' as set out here:
>
>
> http://www.ats.ucla.edu/stat/r/library/contrast_coding.htm
>
>
> Good luck!
>
>
> Tom
>
>
> ------------------------------
> *From:* paul <graftedlife at gmail.com>
> *Sent:* 06 June 2016 20:06:02
> *To:* Houslay, Tom
> *Cc:* r-sig-mixed-models at r-project.org
> *Subject:* Re: Related fixed and random factors and planned 
> comparisons in a 2x2 design
>
> Dear Tom,
>
> Many thanks for these very helpful comments and suggestions! Would you 
> just allow me to ask some further questions:
>
> 1. I've been considering whether to cross or to nest the random 
> effects for quite a while. Data from the same channel across 
> participants do show corresponding trends (thus a bit different from 
> the case when, e.g., sampling nine neurons from the same individual). 
> Would nesting channel within participant deal with that relationship?
>
> 2. I actually also tried nesting channel within participant. However, 
> when I proceeded to run planned comparisons (I guess I'd better have 
> them done because of their theoretical significance) based on this 
> mixed-effect modeling approach (as illustrated in the earlier mail but 
> with the random factor as (1|participant/channel), to maintain 
> consistency of analytical methods), R gave me an error message:
>
> Error: number of levels of each grouping factor must be < number of 
> observations
>
>
> I think this is because in my data, each participant only contributes 
> one data point per channel and thus the data points are not enough. I 
> guess that probably means I can't go on in this direction to run the 
> planned comparisons... (?) I'm not pretty sure how contrasts based on 
> binary dummy variables may be done and will try to further explore 
> that. But before I establish the mixed model I already set up 
> orthogonal contrasts for group and item in the dataset using the 
> function contrasts(). Does this have anything to do with what you meant?
>
> 3. I worried about pseudoreplicability when participant ID is not 
> included. Concerning this point, later it came to me that 
> pseudoreplicability usually occurred in cases when multiple responses 
> from the same individual are grouped in the same cell, rendering the 
> data within the same cell non-independent (similar to the case of 
> repeated-measure ANOVA? sorry if I got a wrong understanding...). But 
> as mentioned earlier in my data, each participant only contributes one 
> data point per channel, when channel alone is already modeled as a 
> random factor, would that mean all data points within a cell all come 
> from different participants and thus in this case may deal with the 
> independence assumption? (Again I'm sorry if my concept is wrong and 
> would appreciate instructions on this point...)
>
> Many, many thanks!
>
> Paul
>
>
>
>
>
>
>
>
>
>
>
>
>
>
> 2016-06-06 19:10 GMT+02:00 Houslay, Tom <T.Houslay at exeter.ac.uk>:
>
>> Hi Paul,
>>
>> I don't think anyone's responded to this yet, but my main point would 
>> be that you should check out Schielzeth & Nakagawa's 2012 paper 
>> 'Nested by design' ( 
>> http://onlinelibrary.wiley.com/doi/10.1111/j.2041-210x.2012.00251.x/a
>> bstract
>> ) for a nice rundown on structuring your model for this type of data.
>>
>> It may also be worth thinking about how random intercepts work in a 
>> visual sense; there are a variety of tools that help you do this from 
>> a model (packages sjplot, visreg, broom), or you can just plot 
>> different levels yourself (eg consider plotting the means for AP, AQ, 
>> BP, BQ; the same with mean values from each individual overplotted 
>> around these group means; and even the group means with all points 
>> shown, perhaps coloured by individual - ggplot is really useful for 
>> getting this type of figure together quickly).
>>
>> As to some of your other questions:
>>
>> 1) You need to keep participant ID in. I'm not 100% on your data 
>> structure from the question, but you certainly seem to have repeated 
>> measures for individuals (I'm assuming that groups A and B each 
>> contain multiple individuals, none of whom were in both groups, and 
>> each of which were shown both objects P and Q, in a random order). 
>> It's not surprising that the effects of group are weakened if you 
>> remove participant ID, because you're then effectively entering 
>> pseudoreplication into your model (ie, telling your model that all 
>> the data points within a group are independent, when that isn't the case).
>>
>> 2) I think channel should be nested within individual, with a model 
>> something like model <- lmer(voltage ~ group * item + 
>> (1|participant/channel), data = ...)
>>
>> 3) This really depends on what your interest is. If you simply want 
>> to show that there is an overall interaction effect, then your 
>> p-value from a likelihood ratio test of the model with/without the 
>> interaction term gives significance of this interaction, and then a 
>> plot of predicted values for the fixed effects (w/ data overplotted if possible) should show the trends.
>> You could also use binary dummy variables to make more explicit 
>> contrasts, but it's worth reading up on these a bit more. I don't 
>> really use these type of comparisons very much, so I can't comment further I'm afraid.
>>
>> 4) Your item is like treatment in this case - you appear to be more 
>> interested in the effect of different items (rather than how much 
>> variation 'item' explains), so keep this as a fixed effect and not as random.
>>
>> Hope some of this is useful,
>>
>> Tom
>>
>>
>> ________________________________________
>>
>>
>> Message: 1
>> Date: Fri, 3 Jun 2016 14:28:59 +0200
>> From: paul <graftedlife at gmail.com>
>> To: r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] Related fixed and random factors and planned
>>         comparisons     in a 2x2 design
>> Message-ID:
>>         <
>> CALS4JYfoTbhwhy8S0kHePuw9pPv-NTkrsLrB2Z2YO5ks5gnnOA at mail.gmail.com>
>> Content-Type: text/plain; charset="UTF-8"
>>
>> Dear All,
>>
>> I am trying to use mixed-effect modeling to analyze brain wave data 
>> from two groups of participants when they were presented with two 
>> distinct stimulus. The data points (scalp voltage) were gathered from 
>> the same set of 9 nearby channels from each participant. And so I 
>> have the following
>> factors:
>>
>>    - voltage: the dependent variable
>>    - group: the between-participant/within-item variable for groups A 
>> and B
>>    - item: the within-participant variable (note there are exactly only 2
>>    items, P and Q)
>>    - participant: identifying each participant across the two groups
>>    - channel: identifying each channel (note that data from these channels
>>    in a nearby region tend to display similar, thus correlated, 
>> patterns in
>>    the same participant)
>>
>> The hypothesis is that only group B will show difference between P 
>> and Q (i.e., there should be an interaction effect). So I established 
>> a mixed-effect model using the lme4 package in R:
>>
>> model <-
>> lmer(voltage~1+group+item+(group:item)+(1|participant)+(1|channel),
>>               data=data, REML=FALSE)
>>
>> Questions:
>>
>>    1.
>>
>>    I'm not sure if it is reasonable to add in participant as a random
>>    effect, because it is related to group and seems to weaken the 
>> effects of
>>    group. Would it be all right if I don't add it in?
>>    2.
>>
>>    Because the data from nearby channels of the same participant tend 
>> to be
>>    correlated, I'm not sure if modeling participant and channel as crossed
>>    random effects is all right. But meanwhile it seems also strange 
>> if I treat
>>    channel as nested within participant, because they are the same set of
>>    channels across participants.
>>    3.
>>
>>    The interaction term is significant. But how should planned comparisons
>>    be done (e.g., differences between groups A and B for P) or is it even
>>    necessary to run planned comparisons? I saw suggestions for t-tests,
>>    lsmeans, glht, or for more complicated methods such as breaking 
>> down the
>>    model and subsetting the data:
>>
>>    data[, P_True:=(item=="P")]
>>    posthoc<-lmer(voltage~1+group
>>        +(1|participant)+1|channel)
>>        , data=data[item=="P"]
>>        , subset=data$P_True
>>        , REML=FALSE)
>>
>>    But especially here comparing only between two groups while modeling
>>    participant as a random effect seems detrimental to the group effects.
>> And
>>    I'm not sure if it is really OK to do so. On the other hand, 
>> because the
>>    data still contain non-independent data points (from nearby 
>> channels), I'm
>>    not sure if simply using t-tests is all right. Will non-parametric 
>> tests
>>    (e.g., Wilcoxon tests) do in such cases?
>>    4.
>>
>>    I suppose I don't need to model item as a random effect because there
>>    are only two of them, one for each level, right?
>>
>> I would really appreciate your help!!
>>
>> Best regards,
>>
>> Paul
>>
>>         [[alternative HTML version deleted]]
>>
>>
>>
>

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From hannah.hlx at gmail.com  Tue Jun  7 05:29:10 2016
From: hannah.hlx at gmail.com (li li)
Date: Mon, 6 Jun 2016 23:29:10 -0400
Subject: [R-sig-ME] multcomp package
In-Reply-To: <048c61a6-fbea-321f-e853-2b236cdf1ed7@hsr.it>
References: <CAHLnndbpu0dX4jFXqSevkcGB26H3yh8p2VpcJZWeYpc6KgC6ag@mail.gmail.com>
	<048c61a6-fbea-321f-e853-2b236cdf1ed7@hsr.it>
Message-ID: <CAHLnndbtTUrBL4z8HeubnA35q-o3NPh6O7K=if3VZAo6i1a3TA@mail.gmail.com>

Thanks Evan and Gabriel for the reply. I think it might help me make the
question clearer if I show the data and the model here (I actually asked
questions related to this data before but I still need some help). The data
looks like the following:

   response individual time method
1    102.9          3    0      3
2    103.0          3    3      3
3    103.0          3    6      3
4    102.8          3    9      3
5    102.2          3   12      3
6    102.5          3   15      3
7    103.0          3   18      3
8    102.0          3   24      3
9    102.8          1    0      3
10   102.7          1    3      3
11   103.0          1    6      3
12   102.2          1    9      3
13   103.0          1   12      3
14   102.8          1   15      3
15   102.8          1   18      3
16   102.9          1   24      3
17   102.2          2    0      3
18   102.6          2    3      3
19   103.4          2    6      3
20   102.3          2    9      3
21   101.3          2   12      3
22   102.1          2   15      3
23   102.1          2   18      3
24   102.2          2   24      3
25   102.7          4    0      3
26   102.3          4    3      3
27   102.6          4    6      3
28   102.7          4    9      3
29   102.8          4   12      3
30   102.5          5    0      3
31   102.4          5    3      3
32   102.1          5    6      3
33   102.3          6    0      3
34   102.3          6    3      3
35   101.9          7    0      3
36   102.0          7    3      3
37   107.4          3    0      1
38   101.3          3   12      1
39    92.8          3   15      1
40    73.7          3   18      1
41   104.7          3   24      1
42    92.6          1    0      1
43   101.9          1   12      1
44   106.3          1   15      1
45   104.1          1   18      1
46    95.6          1   24      1
47    79.8          2    0      1
48    89.7          2   12      1
49    97.0          2   15      1
50   108.4          2   18      1
51   103.5          2   24      1
52    96.4          4    0      1
53    89.3          4   12      1
54   112.6          5    0      1
55    93.3          6    0      1
56    99.6          7    0      1
57   109.5          3    0      2
58    98.5          3   12      2
59   103.5          3   24      2
60   113.5          1    0      2
61    94.5          1   12      2
62    88.5          1   24      2
63    99.5          2    0      2
64    97.5          2   12      2
65    98.5          2   24      2
66   103.5          4    0      2
67    89.5          5    0      2
68    87.5          6    0      2
69    82.5          7    0      2



I used the following random intercept and random slope model for this data.

Denote as y_ijk the response value from *j*th individual within *i*th
method at time point *k*. Assume the following model for y_ijk:

      y_ijk= (alpha_0+ tau_i +a_j(i))+(beta_i+b_j(i)) T_k + e_ijk


Here alpha_0 is the grand mean;
          tau_i is the fixed effect for ith method;
          a_j(i) is random intercept corresponding to the *j*th individual
within *i*th method, assumed to be common for all three methods;
          beta_i is the fixed slope corresponding to the ith method;
          b_j(i) is the random slope corresponding to jth individual for
the ith method, assumed to be common for all three methods;
          T_k is the time corresponding to y_ijk;
          e_ijk is the residual.

Here I used the following specification for the lme function

mod1 <- lme(fixed= reponse ~ method*time, random=~ 1 +time | individual,
data=one, weights= varIdent(form=~1|method),
            control = lmeControl(opt = "optim"))

I did not add the method in random effects  because here I assumed common
random slope for all three methods.

This model is used to initially check whether there fixed slopes are equal.
I wanted to further evaluate whether each fixed slope (beta_1, beta_2 and
beta 3) is significantly different from zero. I was hoping to evaluate this
based on the same model.

The output is as follows. Does the highlighted part below already gives the
result for testing beta_1=0; beta_2=0 and beta_3=0?

Thanks very much.
   Hanna

> summary(mod1)Linear mixed-effects model fit by REML
 Data: one
       AIC      BIC    logLik
  304.4703 330.1879 -140.2352

Random effects:
 Formula: ~1 + time | individual
 Structure: General positive-definite, Log-Cholesky parametrization
            StdDev       Corr
(Intercept) 0.2487869075 (Intr)
time        0.0001841179 -0.056
Residual    0.3718305953
Variance function:
 Structure: Different standard deviations per stratum
 Formula: ~1 | method
 Parameter estimates:
       3        1        2
 1.00000 26.59750 24.74476
Fixed effects: reponse ~ method * time
                Value Std.Error DF   t-value p-value(Intercept)
96.65395  3.528586 57 27.391694  0.0000
method2       1.17851  4.856026 57  0.242689  0.8091
method3       5.87505  3.528617 57  1.664973  0.1014time
0.07010  0.250983 57  0.279301  0.7810
method2:time -0.12616  0.360585 57 -0.349877  0.7277
method3:time -0.08010  0.251105 57 -0.318999  0.7509
 Correlation:
             (Intr) methd2 methd3 time   mthd2:
method2      -0.726
method3      -0.999  0.726
time         -0.779  0.566  0.779
method2:time  0.542 -0.712 -0.542 -0.696
method3:time  0.778 -0.566 -0.779 -0.999  0.696

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max
-2.67575293 -0.51633192  0.06742723  0.59706762  2.81061874

Number of Observations: 69
Number of Groups: 7










2016-06-06 11:21 GMT-04:00 Gabriel Baud-Bovy <baud-bovy.gabriel at hsr.it>:

> On 06/06/2016 4:57 PM, li li wrote:
>
> Hi all,
>   After fitting a random slope and random intercept model using lme
> function, I want
> to test whether each of the fixed slopes is equal to zero (The output of
> model is below).
> Can this be done (testing each individual slope) using multcomp package?
>
> I don't understand what you mean by testing individual slope ?
>
> For the fixed effects, you might test whether there is a method, time or
> interaction
> effect using one of the methods described below
>
> For the randome effects, according to your model specification, the time
> dependency might vary for each individual. the sd for the time
> (0.0001841179)
> is small.  You might want to test whether to include randome slope  by
> doing a LRT
> between a model with it and another model without.
>
> Whay not include method in the random effects ?
>
> Gabriel
>
>   Thanks much for the help.
>    Hanna
>
> To get p values:
>
>
> http://stats.stackexchange.com/questions/118416/getting-p-value-with-mixed-effect-with-lme4-package
>
>
> http://mindingthebrain.blogspot.it/2014/02/three-ways-to-get-parameter-specific-p.html
>
> Using lmerTest package
> https://cran.r-project.org/web/packages/lmerTest/lmerTest.pdf
>
> or using mixed in afex package
> http://rpackages.ianhowson.com/cran/afex/man/mixed.html
>
> both use pbkrtest packages
> https://cran.r-project.org/web/packages/pbkrtest/pbkrtest.pdf
>
> a faq
> http://glmm.wikidot.com/faq
>
>
>
>
> summary(mod1)Linear mixed-effects model fit by REML
>
>  Data: one
>        AIC      BIC    logLik
>   304.4703 330.1879 -140.2352
>
> Random effects:
>  Formula: ~1 + time | individual
>  Structure: General positive-definite, Log-Cholesky parametrization
>             StdDev       Corr
> (Intercept) 0.2487869075 (Intr)
> time        0.0001841179 -0.056
> Residual    0.3718305953
>
> Variance function:
>  Structure: Different standard deviations per stratum
>  Formula: ~1 | method
>  Parameter estimates:
>        3        1        2
>  1.00000 26.59750 24.74476
> Fixed effects: reponse ~ method * time
>                 Value Std.Error DF   t-value p-value(Intercept)
> 96.65395  3.528586 57 27.391694  0.0000
> method2       1.17851  4.856026 57  0.242689  0.8091
> method3       5.87505  3.528617 57  1.664973  0.1014time
> 0.07010  0.250983 57  0.279301  0.7810
> method2:time -0.12616  0.360585 57 -0.349877  0.7277
> method3:time -0.08010  0.251105 57 -0.318999  0.7509
>  Correlation:
>              (Intr) methd2 methd3 time   mthd2:
> method2      -0.726
> method3      -0.999  0.726
> time         -0.779  0.566  0.779
> method2:time  0.542 -0.712 -0.542 -0.696
> method3:time  0.778 -0.566 -0.779 -0.999  0.696
>
> Standardized Within-Group Residuals:
>         Min          Q1         Med          Q3         Max
> -2.67575293 -0.51633192  0.06742723  0.59706762  2.81061874
>
> Number of Observations: 69
> Number of Groups: 7 >
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________R-sig-mixed-models at r-project.org mailing listhttps://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> .
>
>
>
>
> --
> ---------------------------------------------------------------------
> Gabriel Baud-Bovy               tel.: (+39) 02 2643 4839 (office)
> UHSR University                       (+39) 02 2643 3429 (laboratory)
> via Olgettina, 58                     (+39) 02 2643 4891 (secretary)
> 20132 Milan, Italy               fax: (+39) 02 2643 4892
> ---------------------------------------------------------------------
>
>

	[[alternative HTML version deleted]]


From graftedlife at gmail.com  Tue Jun  7 10:27:53 2016
From: graftedlife at gmail.com (paul)
Date: Tue, 7 Jun 2016 10:27:53 +0200
Subject: [R-sig-ME] Related fixed and random factors and planned
 comparisons in a 2x2 design
In-Reply-To: <a867be4c547740e1a7b8d47ab8ffb85b@ITUPW-EXMBOX2C.UniNet.unisa.edu.au>
References: <mailman.1.1465034401.21395.r-sig-mixed-models@r-project.org>
	<DB6PR0301MB23112A3EED4FF8C98B6DAD94D25C0@DB6PR0301MB2311.eurprd03.prod.outlook.com>
	<CALS4JYeNMMNeA4pD89BKeKBWMcFoKG2x1z6XJaAq3Oa2Xxb1Gg@mail.gmail.com>
	<DB6PR0301MB23116F63CE3C4C84D77D2733D25C0@DB6PR0301MB2311.eurprd03.prod.outlook.com>
	<CALS4JYdbr_2SiM2AdKEOM14CpcSKsWXe0S09TAkXQ=awBJzOiw@mail.gmail.com>
	<a867be4c547740e1a7b8d47ab8ffb85b@ITUPW-EXMBOX2C.UniNet.unisa.edu.au>
Message-ID: <CALS4JYcBy+bVLZt+ACJzVRQ6y6L4qprbVE6-mmXx8z5Bzsz96g@mail.gmail.com>

Dear Phillip,

Many thanks for these resources and replies. They are indeed very helpful.
I suppose after I've done the contrast coding, I still have to subset the
data (e.g., singling out the data for P) to do planned comparisons between
groups, using a reduced mixed model as illustrated earlier, then? Or are
there any alternative ways to do so?

Best regards,

Paul

2016-06-07 2:57 GMT+02:00 Phillip Alday <Phillip.Alday at unisa.edu.au>:

> In terms of contrast coding, two more helpful resources are:
>
> http://talklab.psy.gla.ac.uk/tvw/catpred/
>
> http://palday.bitbucket.org/stats/coding.html
>
> Channel makes sense as a random effect / grouping term for your particular
> design, *not* nested within participant. The implicit crossing given by
> (1|Participant) + (1|Channel) models [omitting any slope terms to focus on
> the grouping variables] (1) interindividual differences in the EEG and (2)
> differences between electrodes because closely located electrodes can be
> thought of as samples from a population consisting of a given Region of
> Interest (ROI), especially if the electrode placement is somewhat
> symmetric. The differences resulting from variance in electrode placement
> between participants will be covered by the implicit crossing of these two
> random effects.
>
> Note that using channel as a random effect is somewhat more difficult if
> you're doing a whole scalp analysis as sampling across the whole scalp can
> be viewed as sampling from multiple ROIs, i.e. multiple populations. Two
> possible solutions are (1) to include ROI in the fixed effects and keep
> channel in the random effects and (2) model channel as a two or three
> continuous spatial variables (e.g. displacement from midline or
> displacement from center based on 10-20 coordinates, or spatial coordinates
> of the sort used in source localisation) in the fixed effects.  In the case
> of (1), the channel random effect would then be modelling the typical
> variance within ROIs (because that's hopefully the major source of variance
> structured  by channel left over after modelling ROI and your experimental
> manipulation). If this within-variance differs greatly between between
> ROIs, then this may be a sub-optimal modelling choice. In the case of (2),
> it might still make sense to additionally model channel as a random effect
> (i.e. the RE with the factor consisting of channel names, the FE with the
> continuous coordinates), see Thierry Onkelinx's posts on the subject and
> http://rpubs.com/INBOstats/both_fixed_random , but I haven't thought
> about this enough nor examined the resulting model fits.
>
> Best,
> Phillip
>
> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
> On Behalf Of paul
> Sent: Tuesday, 7 June 2016 5:27 AM
> To: Houslay, Tom <T.Houslay at exeter.ac.uk>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Related fixed and random factors and planned
> comparisons in a 2x2 design
>
> Dear Tom,
>
> Thank you so much for these detailed replies and I appreciate your help!
>
> Sincerely,
>
> Paul
>
> 2016-06-06 21:51 GMT+02:00 Houslay, Tom <T.Houslay at exeter.ac.uk>:
>
> > Hi Paul,
> >
> >
> > I think you're right here in that actually you don't want to nest
> > channel inside participant (which led to that error message - sorry,
> > should have seen that coming!).
> >
> >
> > It's hard to know without seeing data plotted, but my guess from your
> > email is that you probably see some clustering both at individual
> > level and at channel level? Perhaps separate random effects, ie
> > (1|Participant) + (1|Channel), is the way to go (and then you
> > shouldn't have the problem as regards number of observations - instead
> > you'll have an intercept deviation for each of your N individuals, and
> > also intercept deviations for each of your 9 channels). You certainly
> > want to keep the participant intercept in though, as each individual
> > gets both items (right?), so you need to model that association. You
> > can use your variance components output from lmer to determine what
> > proportion of the phenotypic variance (conditional on your fixed
> > effects) is explained by each of these components, eg
> > V(individual)/(V(individual) + V(channel) + V(residual) would give you
> > the proportion explained by differences among individuals in their
> > voltage. It would be cool to know if differences among individuals, or
> > among channels, is driving the variation that you find. I think using
> > the sjplot function for lmer would be useful to look at the levels of
> > your random
> > effects:
> >
> >
> > http://strengejacke.de/sjPlot/sjp.lmer/
> >
> >
> > As for 'contrasts', again I haven't used that particular package, but
> > from a brief glance it looks like you're on the right track - binary
> > coding is the 'simple coding' as set out here:
> >
> >
> > http://www.ats.ucla.edu/stat/r/library/contrast_coding.htm
> >
> >
> > Good luck!
> >
> >
> > Tom
> >
> >
> > ------------------------------
> > *From:* paul <graftedlife at gmail.com>
> > *Sent:* 06 June 2016 20:06:02
> > *To:* Houslay, Tom
> > *Cc:* r-sig-mixed-models at r-project.org
> > *Subject:* Re: Related fixed and random factors and planned
> > comparisons in a 2x2 design
> >
> > Dear Tom,
> >
> > Many thanks for these very helpful comments and suggestions! Would you
> > just allow me to ask some further questions:
> >
> > 1. I've been considering whether to cross or to nest the random
> > effects for quite a while. Data from the same channel across
> > participants do show corresponding trends (thus a bit different from
> > the case when, e.g., sampling nine neurons from the same individual).
> > Would nesting channel within participant deal with that relationship?
> >
> > 2. I actually also tried nesting channel within participant. However,
> > when I proceeded to run planned comparisons (I guess I'd better have
> > them done because of their theoretical significance) based on this
> > mixed-effect modeling approach (as illustrated in the earlier mail but
> > with the random factor as (1|participant/channel), to maintain
> > consistency of analytical methods), R gave me an error message:
> >
> > Error: number of levels of each grouping factor must be < number of
> > observations
> >
> >
> > I think this is because in my data, each participant only contributes
> > one data point per channel and thus the data points are not enough. I
> > guess that probably means I can't go on in this direction to run the
> > planned comparisons... (?) I'm not pretty sure how contrasts based on
> > binary dummy variables may be done and will try to further explore
> > that. But before I establish the mixed model I already set up
> > orthogonal contrasts for group and item in the dataset using the
> > function contrasts(). Does this have anything to do with what you meant?
> >
> > 3. I worried about pseudoreplicability when participant ID is not
> > included. Concerning this point, later it came to me that
> > pseudoreplicability usually occurred in cases when multiple responses
> > from the same individual are grouped in the same cell, rendering the
> > data within the same cell non-independent (similar to the case of
> > repeated-measure ANOVA? sorry if I got a wrong understanding...). But
> > as mentioned earlier in my data, each participant only contributes one
> > data point per channel, when channel alone is already modeled as a
> > random factor, would that mean all data points within a cell all come
> > from different participants and thus in this case may deal with the
> > independence assumption? (Again I'm sorry if my concept is wrong and
> > would appreciate instructions on this point...)
> >
> > Many, many thanks!
> >
> > Paul
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> > 2016-06-06 19:10 GMT+02:00 Houslay, Tom <T.Houslay at exeter.ac.uk>:
> >
> >> Hi Paul,
> >>
> >> I don't think anyone's responded to this yet, but my main point would
> >> be that you should check out Schielzeth & Nakagawa's 2012 paper
> >> 'Nested by design' (
> >> http://onlinelibrary.wiley.com/doi/10.1111/j.2041-210x.2012.00251.x/a
> >> bstract
> >> ) for a nice rundown on structuring your model for this type of data.
> >>
> >> It may also be worth thinking about how random intercepts work in a
> >> visual sense; there are a variety of tools that help you do this from
> >> a model (packages sjplot, visreg, broom), or you can just plot
> >> different levels yourself (eg consider plotting the means for AP, AQ,
> >> BP, BQ; the same with mean values from each individual overplotted
> >> around these group means; and even the group means with all points
> >> shown, perhaps coloured by individual - ggplot is really useful for
> >> getting this type of figure together quickly).
> >>
> >> As to some of your other questions:
> >>
> >> 1) You need to keep participant ID in. I'm not 100% on your data
> >> structure from the question, but you certainly seem to have repeated
> >> measures for individuals (I'm assuming that groups A and B each
> >> contain multiple individuals, none of whom were in both groups, and
> >> each of which were shown both objects P and Q, in a random order).
> >> It's not surprising that the effects of group are weakened if you
> >> remove participant ID, because you're then effectively entering
> >> pseudoreplication into your model (ie, telling your model that all
> >> the data points within a group are independent, when that isn't the
> case).
> >>
> >> 2) I think channel should be nested within individual, with a model
> >> something like model <- lmer(voltage ~ group * item +
> >> (1|participant/channel), data = ...)
> >>
> >> 3) This really depends on what your interest is. If you simply want
> >> to show that there is an overall interaction effect, then your
> >> p-value from a likelihood ratio test of the model with/without the
> >> interaction term gives significance of this interaction, and then a
> >> plot of predicted values for the fixed effects (w/ data overplotted if
> possible) should show the trends.
> >> You could also use binary dummy variables to make more explicit
> >> contrasts, but it's worth reading up on these a bit more. I don't
> >> really use these type of comparisons very much, so I can't comment
> further I'm afraid.
> >>
> >> 4) Your item is like treatment in this case - you appear to be more
> >> interested in the effect of different items (rather than how much
> >> variation 'item' explains), so keep this as a fixed effect and not as
> random.
> >>
> >> Hope some of this is useful,
> >>
> >> Tom
> >>
> >>
> >> ________________________________________
> >>
> >>
> >> Message: 1
> >> Date: Fri, 3 Jun 2016 14:28:59 +0200
> >> From: paul <graftedlife at gmail.com>
> >> To: r-sig-mixed-models at r-project.org
> >> Subject: [R-sig-ME] Related fixed and random factors and planned
> >>         comparisons     in a 2x2 design
> >> Message-ID:
> >>         <
> >> CALS4JYfoTbhwhy8S0kHePuw9pPv-NTkrsLrB2Z2YO5ks5gnnOA at mail.gmail.com>
> >> Content-Type: text/plain; charset="UTF-8"
> >>
> >> Dear All,
> >>
> >> I am trying to use mixed-effect modeling to analyze brain wave data
> >> from two groups of participants when they were presented with two
> >> distinct stimulus. The data points (scalp voltage) were gathered from
> >> the same set of 9 nearby channels from each participant. And so I
> >> have the following
> >> factors:
> >>
> >>    - voltage: the dependent variable
> >>    - group: the between-participant/within-item variable for groups A
> >> and B
> >>    - item: the within-participant variable (note there are exactly only
> 2
> >>    items, P and Q)
> >>    - participant: identifying each participant across the two groups
> >>    - channel: identifying each channel (note that data from these
> channels
> >>    in a nearby region tend to display similar, thus correlated,
> >> patterns in
> >>    the same participant)
> >>
> >> The hypothesis is that only group B will show difference between P
> >> and Q (i.e., there should be an interaction effect). So I established
> >> a mixed-effect model using the lme4 package in R:
> >>
> >> model <-
> >> lmer(voltage~1+group+item+(group:item)+(1|participant)+(1|channel),
> >>               data=data, REML=FALSE)
> >>
> >> Questions:
> >>
> >>    1.
> >>
> >>    I'm not sure if it is reasonable to add in participant as a random
> >>    effect, because it is related to group and seems to weaken the
> >> effects of
> >>    group. Would it be all right if I don't add it in?
> >>    2.
> >>
> >>    Because the data from nearby channels of the same participant tend
> >> to be
> >>    correlated, I'm not sure if modeling participant and channel as
> crossed
> >>    random effects is all right. But meanwhile it seems also strange
> >> if I treat
> >>    channel as nested within participant, because they are the same set
> of
> >>    channels across participants.
> >>    3.
> >>
> >>    The interaction term is significant. But how should planned
> comparisons
> >>    be done (e.g., differences between groups A and B for P) or is it
> even
> >>    necessary to run planned comparisons? I saw suggestions for t-tests,
> >>    lsmeans, glht, or for more complicated methods such as breaking
> >> down the
> >>    model and subsetting the data:
> >>
> >>    data[, P_True:=(item=="P")]
> >>    posthoc<-lmer(voltage~1+group
> >>        +(1|participant)+1|channel)
> >>        , data=data[item=="P"]
> >>        , subset=data$P_True
> >>        , REML=FALSE)
> >>
> >>    But especially here comparing only between two groups while modeling
> >>    participant as a random effect seems detrimental to the group
> effects.
> >> And
> >>    I'm not sure if it is really OK to do so. On the other hand,
> >> because the
> >>    data still contain non-independent data points (from nearby
> >> channels), I'm
> >>    not sure if simply using t-tests is all right. Will non-parametric
> >> tests
> >>    (e.g., Wilcoxon tests) do in such cases?
> >>    4.
> >>
> >>    I suppose I don't need to model item as a random effect because there
> >>    are only two of them, one for each level, right?
> >>
> >> I would really appreciate your help!!
> >>
> >> Best regards,
> >>
> >> Paul
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >>
> >>
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From mdevoto at agro.uba.ar  Tue Jun  7 19:31:10 2016
From: mdevoto at agro.uba.ar (Mariano Devoto)
Date: Tue, 7 Jun 2016 14:31:10 -0300
Subject: [R-sig-ME] problem extracting main effects from an updated glmm
Message-ID: <CAJRWjBZd_tL0dUN+5rMgWAeR4Ri2jUzdWVd_2mf_bWnizdJ2oA@mail.gmail.com>

Dear all,

we are trying to use a glmm to analyze sampling completeness of
interactions in ecological networks based on a literature review of several
studies each of which simultaneously sampled a given number of networks.
Our response variable is the number of interactions observed (Sobs)
compared to the number missed (Smiss).
Our explanatory variables are:
int_type: type of interaction (categorical)
n_webs: number of networks studied at the same time in each study
(numerical)
n_int: number of interactions sampled in each network (numerical)
sp_num: number of species in each network
We have random effects associated to each study ("datum") which are nested
within each research group ("author"). We hope this will account for
inherent methodological differences between research groups and
uncontrolled ecological background noise for each study.
After some exploratory analysis (following protocols in Zuur's books) we
also included in the model an interaction term ("int_type:sp_num").

After much reading (books, blogs and other online help) this is what we've
managed to put together. As this is the first time we are using glmm in our
research group, in addition to the particular problem we are having with
extracting the model's main effects (see below) we would greatly appreciate
any comments/suggestions to improve our general approach. So here's the
code:

#read data online
my.table <- read.csv(file = "
http://www.agro.uba.ar//users//mdevoto//mydata.csv")

#Initial glmm
require(lme4)
M0 <- glmer(cbind(Sobs, Smiss) ~ int_type + n_webs + n_int + sp_num +
int_type:sp_num + (1 | author/datum), data = my.table, family = binomial)

#Rescale explanatory variables after the function suggests to do so
my.table$n_webs.center <- scale(my.table$n_webs, center = T, scale = T)
my.table$n_int.center <- scale(my.table$n_int, center = T, scale = T)
my.table$sp_num.center <- scale(my.table$sp_num, center = T, scale = T)

#New model with rescaled variables
M1 <- glmer(cbind(Sobs, Smiss) ~ int_type + n_webs.center + n_int.center +
sp_num.center + int_type:sp_num.center + (1 | author/datum), data =
my.table, family = binomial)
summary(M1)

# As there seem to be convergence problems, we followed this tutorial to
deal with them:
https://rstudio-pubs-static.s3.amazonaws.com/33653_57fc7b8e5d484c909b615d8633c01d51.html
#Restarting the model seems to solve things
ss <- getME(M1, c("theta", "fixef"))
M2 <- update(M1, start = ss, control = glmerControl(optCtrl = list(maxfun =
20000)))
summary(M2)

#When we try to extract the main effects is when we run into trouble
require(effects)
my.effects <- allEffects(M2)

We looked extensively online, but can't find a solution to get beyond this
point. Any ideas would be most welcome.

Best wishes,

Mariano


*Dr. Mariano Devoto*

Profesor Adjunto - C?tedra de Bot?nica General, Facultad de Agronom?a de la
UBA
Investigador Adjunto del CONICET

Av. San Mart?n 4453 - C1417DSE - C. A. de Buenos Aires - Argentina
+5411 4524-8069
http://www.agro.uba.ar/users/mdevoto/

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Jun  7 20:22:15 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 7 Jun 2016 14:22:15 -0400
Subject: [R-sig-ME] problem extracting main effects from an updated glmm
In-Reply-To: <CAJRWjBZd_tL0dUN+5rMgWAeR4Ri2jUzdWVd_2mf_bWnizdJ2oA@mail.gmail.com>
References: <CAJRWjBZd_tL0dUN+5rMgWAeR4Ri2jUzdWVd_2mf_bWnizdJ2oA@mail.gmail.com>
Message-ID: <575710D7.1010606@gmail.com>


  Thanks for presenting a clear reproducible example.

 Depending on exactly what you need, there are other ways to "extract
the main effects"  (e.g. fixef(fitted_model),
coef(summary(fitted_model)), broom::tidy(fitted_model),
dotwhisker::dwplot(fitted_model)), but I can appreciate the convenience
of the effects package.

  The effects package is having trouble because one of its internal
functions is trying to call glm() with the arguments previously provided
to glmer, and the format of the 'start' parameter for glmer() is
inconsistent with the one glm() is expecting (the

  Here's a crude way to hack the effects package so that it will work ...

## dump the text of the offending function to a file
cat(deparse(effects:::mer.to.glm,width.cutoff=200),
    file="mer.to.glm.R",sep="\n")
## NOW EDIT THE FILE IN AN EXTERNAL TEXT EDITOR:
## (1) add "mer.to.glm <-" at the top
## (2) edit line 32; remove  "start", from argument list to be matched
## (3) l. 35, change fixmod -> effects:::fixmod
## read the file back in
source("mer.to.glm.R")
## shove it back into the package namespace
assignInNamespace("mer.to.glm",mer.to.glm,"effects")
effects:::mer.to.glm ## print the function to check that it worked

  Having done that, allEffects(M2) works.

  This should be pretty easily fixable in the next release of the
effects package, so you wouldn't have to do the hacking any more.

  cheers
    Ben Bolker




On 16-06-07 01:31 PM, Mariano Devoto wrote:
> Dear all,
> 
> we are trying to use a glmm to analyze sampling completeness of
> interactions in ecological networks based on a literature review of several
> studies each of which simultaneously sampled a given number of networks.
> Our response variable is the number of interactions observed (Sobs)
> compared to the number missed (Smiss).
> Our explanatory variables are:
> int_type: type of interaction (categorical)
> n_webs: number of networks studied at the same time in each study
> (numerical)
> n_int: number of interactions sampled in each network (numerical)
> sp_num: number of species in each network
> We have random effects associated to each study ("datum") which are nested
> within each research group ("author"). We hope this will account for
> inherent methodological differences between research groups and
> uncontrolled ecological background noise for each study.
> After some exploratory analysis (following protocols in Zuur's books) we
> also included in the model an interaction term ("int_type:sp_num").
> 
> After much reading (books, blogs and other online help) this is what we've
> managed to put together. As this is the first time we are using glmm in our
> research group, in addition to the particular problem we are having with
> extracting the model's main effects (see below) we would greatly appreciate
> any comments/suggestions to improve our general approach. So here's the
> code:
> 
> #read data online
> my.table <- read.csv(file = "
> http://www.agro.uba.ar//users//mdevoto//mydata.csv")
> 
> #Initial glmm
> require(lme4)
> M0 <- glmer(cbind(Sobs, Smiss) ~ int_type + n_webs + n_int + sp_num +
> int_type:sp_num + (1 | author/datum), data = my.table, family = binomial)
> 
> #Rescale explanatory variables after the function suggests to do so
> my.table$n_webs.center <- scale(my.table$n_webs, center = T, scale = T)
> my.table$n_int.center <- scale(my.table$n_int, center = T, scale = T)
> my.table$sp_num.center <- scale(my.table$sp_num, center = T, scale = T)
> 
> #New model with rescaled variables
> M1 <- glmer(cbind(Sobs, Smiss) ~ int_type + n_webs.center + n_int.center +
> sp_num.center + int_type:sp_num.center + (1 | author/datum), data =
> my.table, family = binomial)
> summary(M1)
> 
> # As there seem to be convergence problems, we followed this tutorial to
> deal with them:
> https://rstudio-pubs-static.s3.amazonaws.com/33653_57fc7b8e5d484c909b615d8633c01d51.html
> #Restarting the model seems to solve things
> ss <- getME(M1, c("theta", "fixef"))
> M2 <- update(M1, start = ss, control = glmerControl(optCtrl = list(maxfun =
> 20000)))
> summary(M2)
> 
> #When we try to extract the main effects is when we run into trouble
> require(effects)
> my.effects <- allEffects(M2)
> 
> We looked extensively online, but can't find a solution to get beyond this
> point. Any ideas would be most welcome.
> 
> Best wishes,
> 
> Mariano
> 
> 
> *Dr. Mariano Devoto*
> 
> Profesor Adjunto - C?tedra de Bot?nica General, Facultad de Agronom?a de la
> UBA
> Investigador Adjunto del CONICET
> 
> Av. San Mart?n 4453 - C1417DSE - C. A. de Buenos Aires - Argentina
> +5411 4524-8069
> http://www.agro.uba.ar/users/mdevoto/
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From jfox at mcmaster.ca  Tue Jun  7 21:41:21 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Tue, 7 Jun 2016 19:41:21 +0000
Subject: [R-sig-ME] problem extracting main effects from an updated glmm
In-Reply-To: <575710D7.1010606@gmail.com>
References: <CAJRWjBZd_tL0dUN+5rMgWAeR4Ri2jUzdWVd_2mf_bWnizdJ2oA@mail.gmail.com>
	<575710D7.1010606@gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC810FA8883@FHSDB2D11-2.csu.mcmaster.ca>

Dear Ben and Mariano,

Ben, thanks for figuring out the source of the error before I even had a chance to read Mariano's original message. I think that we can just adopt your fix in the effects package. I'm cc'ing Sandy Weisberg, who wrote mer.to.glm(), in case he sees a problem that I don't.

Best,
 John

> -----Original Message-----
> From: Ben Bolker [mailto:bbolker at gmail.com]
> Sent: Tuesday, June 7, 2016 2:22 PM
> To: r-sig-mixed-models at r-project.org
> Cc: Fox, John <jfox at mcmaster.ca>
> Subject: Re: [R-sig-ME] problem extracting main effects from an updated
> glmm
> 
> 
>   Thanks for presenting a clear reproducible example.
> 
>  Depending on exactly what you need, there are other ways to "extract
> the main effects"  (e.g. fixef(fitted_model),
> coef(summary(fitted_model)), broom::tidy(fitted_model),
> dotwhisker::dwplot(fitted_model)), but I can appreciate the convenience
> of the effects package.
> 
>   The effects package is having trouble because one of its internal
> functions is trying to call glm() with the arguments previously provided
> to glmer, and the format of the 'start' parameter for glmer() is
> inconsistent with the one glm() is expecting (the
> 
>   Here's a crude way to hack the effects package so that it will work
> ...
> 
> ## dump the text of the offending function to a file
> cat(deparse(effects:::mer.to.glm,width.cutoff=200),
>     file="mer.to.glm.R",sep="\n")
> ## NOW EDIT THE FILE IN AN EXTERNAL TEXT EDITOR:
> ## (1) add "mer.to.glm <-" at the top
> ## (2) edit line 32; remove  "start", from argument list to be matched
> ## (3) l. 35, change fixmod -> effects:::fixmod ## read the file back in
> source("mer.to.glm.R")
> ## shove it back into the package namespace
> assignInNamespace("mer.to.glm",mer.to.glm,"effects")
> effects:::mer.to.glm ## print the function to check that it worked
> 
>   Having done that, allEffects(M2) works.
> 
>   This should be pretty easily fixable in the next release of the
> effects package, so you wouldn't have to do the hacking any more.
> 
>   cheers
>     Ben Bolker
> 
> 
> 
> 
> On 16-06-07 01:31 PM, Mariano Devoto wrote:
> > Dear all,
> >
> > we are trying to use a glmm to analyze sampling completeness of
> > interactions in ecological networks based on a literature review of
> > several studies each of which simultaneously sampled a given number of
> networks.
> > Our response variable is the number of interactions observed (Sobs)
> > compared to the number missed (Smiss).
> > Our explanatory variables are:
> > int_type: type of interaction (categorical)
> > n_webs: number of networks studied at the same time in each study
> > (numerical)
> > n_int: number of interactions sampled in each network (numerical)
> > sp_num: number of species in each network We have random effects
> > associated to each study ("datum") which are nested within each
> > research group ("author"). We hope this will account for inherent
> > methodological differences between research groups and uncontrolled
> > ecological background noise for each study.
> > After some exploratory analysis (following protocols in Zuur's books)
> > we also included in the model an interaction term ("int_type:sp_num").
> >
> > After much reading (books, blogs and other online help) this is what
> > we've managed to put together. As this is the first time we are using
> > glmm in our research group, in addition to the particular problem we
> > are having with extracting the model's main effects (see below) we
> > would greatly appreciate any comments/suggestions to improve our
> > general approach. So here's the
> > code:
> >
> > #read data online
> > my.table <- read.csv(file = "
> > http://www.agro.uba.ar//users//mdevoto//mydata.csv")
> >
> > #Initial glmm
> > require(lme4)
> > M0 <- glmer(cbind(Sobs, Smiss) ~ int_type + n_webs + n_int + sp_num +
> > int_type:sp_num + (1 | author/datum), data = my.table, family =
> > binomial)
> >
> > #Rescale explanatory variables after the function suggests to do so
> > my.table$n_webs.center <- scale(my.table$n_webs, center = T, scale =
> > T) my.table$n_int.center <- scale(my.table$n_int, center = T, scale =
> > T) my.table$sp_num.center <- scale(my.table$sp_num, center = T, scale
> > = T)
> >
> > #New model with rescaled variables
> > M1 <- glmer(cbind(Sobs, Smiss) ~ int_type + n_webs.center +
> > n_int.center + sp_num.center + int_type:sp_num.center + (1 |
> > author/datum), data = my.table, family = binomial)
> > summary(M1)
> >
> > # As there seem to be convergence problems, we followed this tutorial
> > to deal with them:
> > https://rstudio-pubs-static.s3.amazonaws.com/33653_57fc7b8e5d484c909b6
> > 15d8633c01d51.html #Restarting the model seems to solve things ss <-
> > getME(M1, c("theta", "fixef"))
> > M2 <- update(M1, start = ss, control = glmerControl(optCtrl =
> > list(maxfun =
> > 20000)))
> > summary(M2)
> >
> > #When we try to extract the main effects is when we run into trouble
> > require(effects)
> > my.effects <- allEffects(M2)
> >
> > We looked extensively online, but can't find a solution to get beyond
> > this point. Any ideas would be most welcome.
> >
> > Best wishes,
> >
> > Mariano
> >
> >
> > *Dr. Mariano Devoto*
> >
> > Profesor Adjunto - C?tedra de Bot?nica General, Facultad de Agronom?a
> > de la UBA Investigador Adjunto del CONICET
> >
> > Av. San Mart?n 4453 - C1417DSE - C. A. de Buenos Aires - Argentina
> > +5411 4524-8069
> > http://www.agro.uba.ar/users/mdevoto/
> >
> > 	[[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >

From susanna.huneide.thorbjoernsen at imr.no  Thu Jun  9 13:46:59 2016
From: susanna.huneide.thorbjoernsen at imr.no (=?iso-8859-1?Q?Thorbj=F8rnsen_Susanna_Huneide?=)
Date: Thu, 9 Jun 2016 11:46:59 +0000
Subject: [R-sig-ME] Split within-individual and between-individual
 correlations in a bivariate mixed effects model in nlme package
Message-ID: <1465472819167.49949@imr.no>

Hello,


I'm wondering if there is a way to split between-individual and within-individual correlations in a bivariate mixed effects model when using the nlme package? I'm aware that this is possible in the MCMCglmm package, but I have autocorrelation in my data that I want to account for in the model.


Kind regards,

Susanna


From russell-lenth at uiowa.edu  Thu Jun  9 18:38:51 2016
From: russell-lenth at uiowa.edu (Lenth, Russell V)
Date: Thu, 9 Jun 2016 16:38:51 +0000
Subject: [R-sig-ME] problem extracting main effects from an updated glmm
Message-ID: <BY2PR0401MB09195A3C82DF1E56F2C69C3AF15F0@BY2PR0401MB0919.namprd04.prod.outlook.com>

You may like the ease with which the lsmeans package can handle this example. There is an 'lstrends' function that estimates slopes for each level of a factor interacting with a covariate; and a 'contrast' function for estimating contarsts thereof. In another situation where more factors are involved, the results may differ somewhat from those in the effects package because I believe the latter weights the estimates by frequency, rather than equally, across levels of uninvolved factors.


> require("lsmeans")

> M2.lst <- lstrends(M2, "int_type", var = "sp_num.center")

> M2.lst
 int_type         sp_num.center.trend         SE df  asymp.LCL  asymp.UCL
 host-parasitoid          -0.67576500 0.14786963 NA -0.9655842 -0.3859459
 plant-disperser           0.10575349 0.35028629 NA -0.5807950  0.7923020
 plant-herbivore          -0.09630775 0.20541014 NA -0.4989042  0.3062887
 plant-pollinator         -0.26938881 0.07695205 NA -0.4202121 -0.1185656

Confidence level used: 0.95 


> contrast(M2.lst, "eff")   ### Sum-to-zero effects
 contrast                   estimate        SE df z.ratio p.value
 host-parasitoid effect  -0.44183798 0.1456253 NA  -3.034  0.0097
 plant-disperser effect   0.33968051 0.2715796 NA   1.251  0.4220
 plant-herbivore effect   0.13761927 0.1769490 NA   0.778  0.5823
 plant-pollinator effect -0.03546179 0.1245606 NA  -0.285  0.7759

P value adjustment: fdr method for 4 tests 


> contrast(M2.lst, "pairwise")   ### Pairwise comparisons
 contrast                             estimate        SE df z.ratio p.value
 host-parasitoid - plant-disperser  -0.7815185 0.3793521 NA  -2.060  0.1663
 host-parasitoid - plant-herbivore  -0.5794572 0.2341922 NA  -2.474  0.0640
 host-parasitoid - plant-pollinator -0.4063762 0.1669175 NA  -2.435  0.0707
 plant-disperser - plant-herbivore   0.2020612 0.4056479 NA   0.498  0.9595
 plant-disperser - plant-pollinator  0.3751423 0.3582628 NA   1.047  0.7216
 plant-herbivore - plant-pollinator  0.1730811 0.2182572 NA   0.793  0.8577

P value adjustment: tukey method for comparing a family of 4 estimates


--
Russell V. Lenth  -  Professor Emeritus
Department of Statistics and Actuarial Science   
The University of Iowa  -  Iowa City, IA 52242  USA   
Voice (319)335-0712 (Dept. office)  -  FAX (319)335-3017

Just because you have numbers, that doesn't necessarily mean you have data.



-----Original Message-----

Message: 1
Date: Tue, 7 Jun 2016 14:31:10 -0300
From: Mariano Devoto <mdevoto at agro.uba.ar>
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] problem extracting main effects from an updated
	glmm
Message-ID:
	<CAJRWjBZd_tL0dUN+5rMgWAeR4Ri2jUzdWVd_2mf_bWnizdJ2oA at mail.gmail.com>
Content-Type: text/plain; charset="UTF-8"

Dear all,

we are trying to use a glmm to analyze sampling completeness of interactions in ecological networks based on a literature review of several studies each of which simultaneously sampled a given number of networks.
Our response variable is the number of interactions observed (Sobs) compared to the number missed (Smiss).
Our explanatory variables are:
int_type: type of interaction (categorical)
n_webs: number of networks studied at the same time in each study
(numerical)
n_int: number of interactions sampled in each network (numerical)
sp_num: number of species in each network We have random effects associated to each study ("datum") which are nested within each research group ("author"). We hope this will account for inherent methodological differences between research groups and uncontrolled ecological background noise for each study.
After some exploratory analysis (following protocols in Zuur's books) we also included in the model an interaction term ("int_type:sp_num").

After much reading (books, blogs and other online help) this is what we've managed to put together. As this is the first time we are using glmm in our research group, in addition to the particular problem we are having with extracting the model's main effects (see below) we would greatly appreciate any comments/suggestions to improve our general approach. So here's the
code:

#read data online
my.table <- read.csv(file = "
http://www.agro.uba.ar//users//mdevoto//mydata.csv")

#Initial glmm
require(lme4)
M0 <- glmer(cbind(Sobs, Smiss) ~ int_type + n_webs + n_int + sp_num + int_type:sp_num + (1 | author/datum), data = my.table, family = binomial)

#Rescale explanatory variables after the function suggests to do so my.table$n_webs.center <- scale(my.table$n_webs, center = T, scale = T) my.table$n_int.center <- scale(my.table$n_int, center = T, scale = T) my.table$sp_num.center <- scale(my.table$sp_num, center = T, scale = T)

#New model with rescaled variables
M1 <- glmer(cbind(Sobs, Smiss) ~ int_type + n_webs.center + n_int.center + sp_num.center + int_type:sp_num.center + (1 | author/datum), data = my.table, family = binomial)
summary(M1)

# As there seem to be convergence problems, we followed this tutorial to deal with them:
https://rstudio-pubs-static.s3.amazonaws.com/33653_57fc7b8e5d484c909b615d8633c01d51.html
#Restarting the model seems to solve things ss <- getME(M1, c("theta", "fixef"))
M2 <- update(M1, start = ss, control = glmerControl(optCtrl = list(maxfun =
20000)))
summary(M2)

#When we try to extract the main effects is when we run into trouble
require(effects)
my.effects <- allEffects(M2)

We looked extensively online, but can't find a solution to get beyond this point. Any ideas would be most welcome.

Best wishes,

Mariano


*Dr. Mariano Devoto*

Profesor Adjunto - C?tedra de Bot?nica General, Facultad de Agronom?a de la UBA Investigador Adjunto del CONICET

Av. San Mart?n 4453 - C1417DSE - C. A. de Buenos Aires - Argentina
+5411 4524-8069
http://www.agro.uba.ar/users/mdevoto/


From VTrifonov at gnf.org  Fri Jun 10 01:48:03 2016
From: VTrifonov at gnf.org (Vladimir Trifonov)
Date: Thu, 9 Jun 2016 23:48:03 +0000
Subject: [R-sig-ME] glmmADMB fails to fit poisson data
Message-ID: <2439E066-CB88-48EE-A84A-6D88F853167C@gnf.org>

Hi,

Why is the following  ?trivial? model fit failing? After all, we are fitting a Poisson GLM on a Poisson data.

--------
> glmmadmb(rpois(100, lambda=8000)~1, family="poisson")
 Hessian is 0 in row 1
 This means that the derivative if probably identically 0  for this parameter
Error in matrix inverse -- matrix singular in inv(dmatrix)
Estimated covariance matrix may not be positive definite
 1e+20
Estimated covariance matrix may not be positive definite
 1e+20

GLMM's in R powered by AD Model Builder:

  Family: poisson
  link = log

Fixed effects:
  Log-likelihood: -2302.59
  AIC: 4607.18
  Formula: rpois(100, lambda = 8000) ~ 1
(Intercept)
          0

Number of observations: total=100
--------

I tried varying the number of samples (100 above), the mean (8000 above) and this fails. Here is another attempt (with a different kind of fail)

--------
> glmmadmb(rpois(100, lambda=50)~1, family="poisson")
Parameters were estimated, but standard errors were not: the most likely problem is that the curvature at MLE was zero or negative
Error in glmmadmb(rpois(100, lambda = 50) ~ 1, family = "poisson") :
  The function maximizer failed (couldn't find parameter file) Troubleshooting steps include (1) run with 'save.dir' set and inspect output files; (2) change run parameters: see '?admbControl';(3) re-run with debug=TRUE for more information on failure mode
In addition: Warning message:
running command './glmmadmb -maxfn 500 -maxph 5 -noinit -shess' had status 1
--------

After some trial and error, the only thing I found that ?works? (with a warning about the covariance matrix) consistently is to set a ?mysterious? poiss_prob_bound = FALSE

--------
> glmmadmb(rpois(100, lambda=50)~1, family="poisson", admb.opts=admbControl(poiss_prob_bound=FALSE))
Estimated covariance matrix may not be positive definite
 0.020141
Estimated covariance matrix may not be positive definite
 0.020141

GLMM's in R powered by AD Model Builder:

  Family: poisson
  link = log

Fixed effects:
  Log-likelihood: -327.749
  AIC: 657.498
  Formula: rpois(100, lambda = 50) ~ 1
(Intercept)
   3.904998

Number of observations: total=100
--------

While this is a ?solution?, I would expect this kind of fit to work ?off-the-box? (it certainly does with the standard glm function). Can someone comment on this.  I am not an expert on GLMs and needed something that would fit ZINB + random effects (admittedly the deep end of GLMs) and was excited to find glmmADMB, but using it has proven rather frustrating because it often fails (with a dramatic stop that does not reach the top level and so cannot be caught with tryCatch, nonetheless) and after I found the above example, I am not so sure it is always for a good reason.

Thanks,
Vladimir



Session:

> sessionInfo()
R version 3.1.0 (2014-04-10)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] glmmADMB_0.8.3.3 MASS_7.3-31

loaded via a namespace (and not attached):
 [1] Matrix_1.1-3    R2admb_0.7.13   Rcpp_0.12.3     coda_0.17-1
 [5] grid_3.1.0      lattice_0.20-29 magrittr_1.5    nlme_3.1-117
 [9] plyr_1.8.1      stringi_0.5-5   stringr_1.0.0   tools_3.1.0

> glmmADMB:::get_bin_version()
ADMB Program: ./glmmadmbADMB-11.5 safe libraries compiled with GNU C++ 4.9.0 (64bit)Copyright (c) 2008-2015 ADMB Foundation and Regents of the University of CaliforniaBuild date: Jun  9 2016









From jmbatchou at uchicago.edu  Fri Jun 10 23:13:53 2016
From: jmbatchou at uchicago.edu (Joelle Mbatchou)
Date: Fri, 10 Jun 2016 21:13:53 +0000
Subject: [R-sig-ME] MCMCglmm: how are the predictions computed (conditional
 and marginal)?
Message-ID: <24D8F4EBBCB6E34AB77AEDAC4DBA25E038475D1A@xm-mbx-05-prod>

Hi everyone,

I have familial binary data that I fit using a logistic mixed model with MCMCglmm:

 prior1 <- list(R = list(V = 1, fix = 1),
                 G = list(G1 = list(V = 1, nu = 1, alpha.mu=0, alpha.V=10^2)))
 mMCMC<-MCMCglmm(Y ~ 1 + age, random =~idU, family = "categorical",
                  ginverse = list(idU = Prec), prior=prior1,
                  data = fam_data, nitt=500e3, thin=500, burnin=5e3, pr = T)

To get the predictions integrating out the random effects, I use:

 mar_est_pi <- predict(mMCMC, marginal = ~idU, type = "response")

To get the predictions conditional on the posterior means of the parameters, I use:

 cond_est_pi <- predict(mMCMC, posterior = "mean", type = "response")

I am trying to understand how I can compute these by hand. For the conditional predictions, I used:

 u <- mMCMC$Sol[,-(1:2)]
 b <- as.matrix(mMCMC$Sol[,1:2])
 cond_pred <- colMeans(plogis(tcrossprod(b, as.matrix(mMCMC$X)) + u))

This doesn't produce the same predictions as in cond_est_pi. I think it's because I am not also incorporating the residual error that was fixed at 1 but I don't see where to incorporate it.

Also, for the marginal predictions, I tried to use the approximation (2.14) in MCMCglmm course notes but I don't get the same predictions as in  mar_est_pi...

 k <- ((16*sqrt(3))/(15*pi))^2
 sig <- rowSums(mMCMC$VCV)
 mar_pred <- colMeans(plogis(tcrossprod(b, as.matrix(mMCMC$X))/ sqrt(1 + k * sig)))

Any guidance on how these are computed would be highly appreciated. Thanks!

Cheers,
Joelle

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Sat Jun 11 02:29:11 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 10 Jun 2016 20:29:11 -0400
Subject: [R-sig-ME] glmmADMB fails to fit poisson data
In-Reply-To: <2439E066-CB88-48EE-A84A-6D88F853167C@gnf.org>
References: <2439E066-CB88-48EE-A84A-6D88F853167C@gnf.org>
Message-ID: <575B5B57.2030101@gmail.com>


* I can appreciate your frustration that glmmADMB doesn't work
out of the box on what seems initially to be a simple problem,
and I appreciate that you are being reasonably diplomatic about
it (not everyone is), but ... it is surprisingly hard to make
a general-purpose solve that works for every data set. glm()
works so well because it uses special-purpose algorithms for
a particular class of models that's narrower than what glmmADMB
can do.

* The particular problem is that for Poisson responses with
very large means, the coefficient of variation of the data
also becomes very small.  That means that values that are a little
bit off the mean become very unlikely, so unlikely that they
underflow (the probabilities become numerically zero).  I can
get your example to work if I set the starting value close enough:

set.seed(101)
d <- data.frame(x=rpois(100, lambda=8000))

library(glmmADMB)
glmmadmb(x~1, family="poisson", data=d)
glmmadmb(x~1, family="poisson", data=d,
         start=list(fixed=log(7500)))  ## works

... it does, however, fail with fixed=log(7000).

* the "mysterious" poiss_prob_bound (which *is* documented in
?admbControl, so it may be obscure but it's not completely mysterious ...)
was added to fix a problem that another user was having with
another data set ... if you

file.show(system.file("tpl","glmmadmb.tpl",package="glmmADMB"))

and dig around, you'll find that glmmADMB bumps up the probability of
a Poisson by 1e-6 or 1e-10 (in different optimization phases) to prevent
a value of exactly zero. There *is* probably a better way to do this -
there are approximations of the Poisson that work very well in such
small ranges, and they could be used instead - but there is also
a reasonably unending number of such edge cases, and not that many
person-hours to deal with them.

* You could try the glmmTMB package, which is a more modern
eventually-replacement for glmmADMB, and which seems
to work on this particular problem -- but be warned that it's
in development, so you may find holes!

devtools::install_github("glmmTMB/glmmTMB",sub="glmmTMB")
library(glmmTMB)
glmmTMB(x~1, family="poisson", data=d)

* if you have a reproducible example of 'dramatic stop that
does not reach the top level and so cannot be caught with
tryCatch' that would be useful.  Maybe we can help resolve
that (more general) problem.

* Andrew Gelman has stated a principle called the "folk theorem of
statistical computing": When you have computational problems, often
there?s a problem with your model.
http://andrewgelman.com/2008/05/13/the_folk_theore/
In this case, I think the issue is that in real life (unless you're
in a field like particle physics), Poisson models are generally
not great models for processes with large means -- the coefficient
of variation is way too small to be realistic. This works with
a negative binomial ...

set.seed(101)
d2 <- data.frame(x=rnbinom(100, mu=8000, size=2))
glmmadmb(x~1,data=d2,family="nbinom")

(I can appreciate that you may have started with a neg binom
and come to the Poisson in part as a way of trying to simplify
your problem so you could diagnose it ...)

  cheers
    Ben Bolker

> While this is a ?solution?, I would expect this kind of fit to work
> ?off-the-box? (it certainly does with the standard glm function). Can
> someone comment on this.  I am not an expert on GLMs and needed
> something that would fit ZINB + random effects (admittedly the deep
> end of GLMs) and was excited to find glmmADMB, but using it has proven
> rather frustrating because it often fails (with a dramatic stop that
> does not reach the top level and so cannot be caught with tryCatch,
> nonetheless) and after I found the above example, I am not so sure it
> is always for a good reason.

> Thanks,
> Vladimir
>
>
>
> Session:
>
>> sessionInfo()


On 16-06-09 07:48 PM, Vladimir Trifonov wrote:
> Hi,
>
> Why is the following  ?trivial? model fit failing? After all, we are
> fitting a Poisson GLM on a Poisson data.
>
> --------
>> glmmadmb(rpois(100, lambda=8000)~1, family="poisson")
>  Hessian is 0 in row 1
>  This means that the derivative if probably identically 0  for this
parameter
> Error in matrix inverse -- matrix singular in inv(dmatrix)
> Estimated covariance matrix may not be positive definite
>  1e+20
> Estimated covariance matrix may not be positive definite
>  1e+20
>
> GLMM's in R powered by AD Model Builder:
>
>   Family: poisson
>   link = log
>
> I tried varying the number of samples (100 above), the mean (8000
  above) and this fails. Here is another attempt (with a different
  kind of fail)

>> glmmadmb(rpois(100, lambda=50)~1, family="poisson")
> Parameters were estimated, but standard errors were not: the most
likely problem is that the curvature at MLE was zero or negative
> Error in glmmadmb(rpois(100, lambda = 50) ~ 1, family = "poisson") :
>   The function maximizer failed (couldn't find parameter file)
Troubleshooting steps include (1) run with 'save.dir' set and inspect
output files; (2) change run parameters: see '?admbControl';(3) re-run
with debug=TRUE for more information on failure mode
> In addition: Warning message:
> running command './glmmadmb -maxfn 500 -maxph 5 -noinit -shess' had
status 1
> --------

> After some trial and error, the only thing I found that ?works? (with
a warning about the covariance matrix) consistently is to set a
?mysterious? poiss_prob_bound = FALSE
>
> --------
>> glmmadmb(rpois(100, lambda=50)~1, family="poisson",
admb.opts=admbControl(poiss_prob_bound=FALSE))
> Estimated covariance matrix may not be positive definite
>  0.020141
> Estimated covariance matrix may not be positive definite
>  0.020141
>
> GLMM's in R powered by AD Model Builder:
>
>   Family: poisson
>   link = log
>
> Fixed effects:
>   Log-likelihood: -327.749
>   AIC: 657.498
>   Formula: rpois(100, lambda = 50) ~ 1
> (Intercept)
>    3.904998
>
> Number of observations: total=100
> --------
>


From john.maindonald at anu.edu.au  Sat Jun 11 03:56:07 2016
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Sat, 11 Jun 2016 01:56:07 +0000
Subject: [R-sig-ME] glmmADMB fails to fit poisson data
In-Reply-To: <575B5B57.2030101@gmail.com>
References: <2439E066-CB88-48EE-A84A-6D88F853167C@gnf.org>
	<575B5B57.2030101@gmail.com>
Message-ID: <C1D42C80-D461-43E8-BF52-5A64C5C0A7ED@anu.edu.au>

With count data where the mean is large, there?s a strong case to
be made for finding a suitable power transform of (count+1) and
using a normal theory model.  If differences in residual variance
are evident, these can be accommodated by assigning weights.
Functions for getting diagnostics are better developed for the
normal theory models, and easier to interpret.

For the analysis of RNA-Seq data, there is a paper that compares
the two styles of model:

Law, CW, Chen, Y, Shi, W, Smyth, GK (2014). Voom: precision weights unlock linear model analysis tools for RNA-seq read counts. Genome Biology 15, R29.http://genomebiology.com/2014/15/2/R29

NB also the recent paper:

Schurch NJ, Schofield P, Gierli?ski M, Cole C, Sherstnev A, Singh V, Wrobel N, Gharbi K, Simpson GG, Owen-Hughes T, Blaxter M, Barton GJ (2016). How many biological replicates are needed in an RNA-seq experiment and which differential expression tool should you use? RNA http://www.rnajournal.org/cgi/doi/10.1261/rna.053959.115

The log(count+1) approach is the best, or close to the best, in the field.

John Maindonald             email: john.maindonald at anu.edu.au

> On 11/06/2016, at 12:29, Ben Bolker <bbolker at gmail.com> wrote:
> 
> 
> * I can appreciate your frustration that glmmADMB doesn't work
> out of the box on what seems initially to be a simple problem,
> and I appreciate that you are being reasonably diplomatic about
> it (not everyone is), but ... it is surprisingly hard to make
> a general-purpose solve that works for every data set. glm()
> works so well because it uses special-purpose algorithms for
> a particular class of models that's narrower than what glmmADMB
> can do.
> 
> * The particular problem is that for Poisson responses with
> very large means, the coefficient of variation of the data
> also becomes very small.  That means that values that are a little
> bit off the mean become very unlikely, so unlikely that they
> underflow (the probabilities become numerically zero).  I can
> get your example to work if I set the starting value close enough:
> 
> set.seed(101)
> d <- data.frame(x=rpois(100, lambda=8000))
> 
> library(glmmADMB)
> glmmadmb(x~1, family="poisson", data=d)
> glmmadmb(x~1, family="poisson", data=d,
>         start=list(fixed=log(7500)))  ## works
> 
> ... it does, however, fail with fixed=log(7000).
> 
> * the "mysterious" poiss_prob_bound (which *is* documented in
> ?admbControl, so it may be obscure but it's not completely mysterious ...)
> was added to fix a problem that another user was having with
> another data set ... if you
> 
> file.show(system.file("tpl","glmmadmb.tpl",package="glmmADMB"))
> 
> and dig around, you'll find that glmmADMB bumps up the probability of
> a Poisson by 1e-6 or 1e-10 (in different optimization phases) to prevent
> a value of exactly zero. There *is* probably a better way to do this -
> there are approximations of the Poisson that work very well in such
> small ranges, and they could be used instead - but there is also
> a reasonably unending number of such edge cases, and not that many
> person-hours to deal with them.
> 
> * You could try the glmmTMB package, which is a more modern
> eventually-replacement for glmmADMB, and which seems
> to work on this particular problem -- but be warned that it's
> in development, so you may find holes!
> 
> devtools::install_github("glmmTMB/glmmTMB",sub="glmmTMB")
> library(glmmTMB)
> glmmTMB(x~1, family="poisson", data=d)
> 
> * if you have a reproducible example of 'dramatic stop that
> does not reach the top level and so cannot be caught with
> tryCatch' that would be useful.  Maybe we can help resolve
> that (more general) problem.
> 
> * Andrew Gelman has stated a principle called the "folk theorem of
> statistical computing": When you have computational problems, often
> there?s a problem with your model.
> http://andrewgelman.com/2008/05/13/the_folk_theore/
> In this case, I think the issue is that in real life (unless you're
> in a field like particle physics), Poisson models are generally
> not great models for processes with large means -- the coefficient
> of variation is way too small to be realistic. This works with
> a negative binomial ...
> 
> set.seed(101)
> d2 <- data.frame(x=rnbinom(100, mu=8000, size=2))
> glmmadmb(x~1,data=d2,family="nbinom")
> 
> (I can appreciate that you may have started with a neg binom
> and come to the Poisson in part as a way of trying to simplify
> your problem so you could diagnose it ...)
> 
>  cheers
>    Ben Bolker
> 
>> While this is a ?solution?, I would expect this kind of fit to work
>> ?off-the-box? (it certainly does with the standard glm function). Can
>> someone comment on this.  I am not an expert on GLMs and needed
>> something that would fit ZINB + random effects (admittedly the deep
>> end of GLMs) and was excited to find glmmADMB, but using it has proven
>> rather frustrating because it often fails (with a dramatic stop that
>> does not reach the top level and so cannot be caught with tryCatch,
>> nonetheless) and after I found the above example, I am not so sure it
>> is always for a good reason.
> 
>> Thanks,
>> Vladimir
>> 
>> 
>> 
>> Session:
>> 
>>> sessionInfo()
> 
> 
> On 16-06-09 07:48 PM, Vladimir Trifonov wrote:
>> Hi,
>> 
>> Why is the following  ?trivial? model fit failing? After all, we are
>> fitting a Poisson GLM on a Poisson data.
>> 
>> --------
>>> glmmadmb(rpois(100, lambda=8000)~1, family="poisson")
>> Hessian is 0 in row 1
>> This means that the derivative if probably identically 0  for this
> parameter
>> Error in matrix inverse -- matrix singular in inv(dmatrix)
>> Estimated covariance matrix may not be positive definite
>> 1e+20
>> Estimated covariance matrix may not be positive definite
>> 1e+20
>> 
>> GLMM's in R powered by AD Model Builder:
>> 
>>  Family: poisson
>>  link = log
>> 
>> I tried varying the number of samples (100 above), the mean (8000
>  above) and this fails. Here is another attempt (with a different
>  kind of fail)
> 
>>> glmmadmb(rpois(100, lambda=50)~1, family="poisson")
>> Parameters were estimated, but standard errors were not: the most
> likely problem is that the curvature at MLE was zero or negative
>> Error in glmmadmb(rpois(100, lambda = 50) ~ 1, family = "poisson") :
>>  The function maximizer failed (couldn't find parameter file)
> Troubleshooting steps include (1) run with 'save.dir' set and inspect
> output files; (2) change run parameters: see '?admbControl';(3) re-run
> with debug=TRUE for more information on failure mode
>> In addition: Warning message:
>> running command './glmmadmb -maxfn 500 -maxph 5 -noinit -shess' had
> status 1
>> --------
> 
>> After some trial and error, the only thing I found that ?works? (with
> a warning about the covariance matrix) consistently is to set a
> ?mysterious? poiss_prob_bound = FALSE
>> 
>> --------
>>> glmmadmb(rpois(100, lambda=50)~1, family="poisson",
> admb.opts=admbControl(poiss_prob_bound=FALSE))
>> Estimated covariance matrix may not be positive definite
>> 0.020141
>> Estimated covariance matrix may not be positive definite
>> 0.020141
>> 
>> GLMM's in R powered by AD Model Builder:
>> 
>>  Family: poisson
>>  link = log
>> 
>> Fixed effects:
>>  Log-likelihood: -327.749
>>  AIC: 657.498
>>  Formula: rpois(100, lambda = 50) ~ 1
>> (Intercept)
>>   3.904998
>> 
>> Number of observations: total=100
>> --------
>> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Sat Jun 11 04:07:04 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 10 Jun 2016 22:07:04 -0400
Subject: [R-sig-ME] glmmADMB fails to fit poisson data
In-Reply-To: <C1D42C80-D461-43E8-BF52-5A64C5C0A7ED@anu.edu.au>
References: <2439E066-CB88-48EE-A84A-6D88F853167C@gnf.org>
	<575B5B57.2030101@gmail.com>
	<C1D42C80-D461-43E8-BF52-5A64C5C0A7ED@anu.edu.au>
Message-ID: <575B7248.2060906@gmail.com>


  I think that's very sensible, but note that if the OP thinks they need
zero-inflation (they said that's why they came to glmmADMB), then they
will probably need to go slightly beyond standard linear models ...
perhaps a two-stage (zero vs non-zero logistic model + linear model on
log(x) of positive cases)

  cheers
   Ben Bolker


On 16-06-10 09:56 PM, John Maindonald wrote:
> With count data where the mean is large, there?s a strong case to
> be made for finding a suitable power transform of (count+1) and
> using a normal theory model.  If differences in residual variance
> are evident, these can be accommodated by assigning weights.
> Functions for getting diagnostics are better developed for the
> normal theory models, and easier to interpret.
> 
> For the analysis of RNA-Seq data, there is a paper that compares
> the two styles of model:
> 
> Law, CW, Chen, Y, Shi, W, Smyth, GK (2014). Voom: precision weights unlock linear model analysis tools for RNA-seq read counts. Genome Biology 15, R29.http://genomebiology.com/2014/15/2/R29
> 
> NB also the recent paper:
> 
> Schurch NJ, Schofield P, Gierli?ski M, Cole C, Sherstnev A, Singh V, Wrobel N, Gharbi K, Simpson GG, Owen-Hughes T, Blaxter M, Barton GJ (2016). How many biological replicates are needed in an RNA-seq experiment and which differential expression tool should you use? RNA http://www.rnajournal.org/cgi/doi/10.1261/rna.053959.115
> 
> The log(count+1) approach is the best, or close to the best, in the field.
> 
> John Maindonald             email: john.maindonald at anu.edu.au
> 
>> On 11/06/2016, at 12:29, Ben Bolker <bbolker at gmail.com> wrote:
>>
>>
>> * I can appreciate your frustration that glmmADMB doesn't work
>> out of the box on what seems initially to be a simple problem,
>> and I appreciate that you are being reasonably diplomatic about
>> it (not everyone is), but ... it is surprisingly hard to make
>> a general-purpose solve that works for every data set. glm()
>> works so well because it uses special-purpose algorithms for
>> a particular class of models that's narrower than what glmmADMB
>> can do.
>>
>> * The particular problem is that for Poisson responses with
>> very large means, the coefficient of variation of the data
>> also becomes very small.  That means that values that are a little
>> bit off the mean become very unlikely, so unlikely that they
>> underflow (the probabilities become numerically zero).  I can
>> get your example to work if I set the starting value close enough:
>>
>> set.seed(101)
>> d <- data.frame(x=rpois(100, lambda=8000))
>>
>> library(glmmADMB)
>> glmmadmb(x~1, family="poisson", data=d)
>> glmmadmb(x~1, family="poisson", data=d,
>>         start=list(fixed=log(7500)))  ## works
>>
>> ... it does, however, fail with fixed=log(7000).
>>
>> * the "mysterious" poiss_prob_bound (which *is* documented in
>> ?admbControl, so it may be obscure but it's not completely mysterious ...)
>> was added to fix a problem that another user was having with
>> another data set ... if you
>>
>> file.show(system.file("tpl","glmmadmb.tpl",package="glmmADMB"))
>>
>> and dig around, you'll find that glmmADMB bumps up the probability of
>> a Poisson by 1e-6 or 1e-10 (in different optimization phases) to prevent
>> a value of exactly zero. There *is* probably a better way to do this -
>> there are approximations of the Poisson that work very well in such
>> small ranges, and they could be used instead - but there is also
>> a reasonably unending number of such edge cases, and not that many
>> person-hours to deal with them.
>>
>> * You could try the glmmTMB package, which is a more modern
>> eventually-replacement for glmmADMB, and which seems
>> to work on this particular problem -- but be warned that it's
>> in development, so you may find holes!
>>
>> devtools::install_github("glmmTMB/glmmTMB",sub="glmmTMB")
>> library(glmmTMB)
>> glmmTMB(x~1, family="poisson", data=d)
>>
>> * if you have a reproducible example of 'dramatic stop that
>> does not reach the top level and so cannot be caught with
>> tryCatch' that would be useful.  Maybe we can help resolve
>> that (more general) problem.
>>
>> * Andrew Gelman has stated a principle called the "folk theorem of
>> statistical computing": When you have computational problems, often
>> there?s a problem with your model.
>> http://andrewgelman.com/2008/05/13/the_folk_theore/
>> In this case, I think the issue is that in real life (unless you're
>> in a field like particle physics), Poisson models are generally
>> not great models for processes with large means -- the coefficient
>> of variation is way too small to be realistic. This works with
>> a negative binomial ...
>>
>> set.seed(101)
>> d2 <- data.frame(x=rnbinom(100, mu=8000, size=2))
>> glmmadmb(x~1,data=d2,family="nbinom")
>>
>> (I can appreciate that you may have started with a neg binom
>> and come to the Poisson in part as a way of trying to simplify
>> your problem so you could diagnose it ...)
>>
>>  cheers
>>    Ben Bolker
>>
>>> While this is a ?solution?, I would expect this kind of fit to work
>>> ?off-the-box? (it certainly does with the standard glm function). Can
>>> someone comment on this.  I am not an expert on GLMs and needed
>>> something that would fit ZINB + random effects (admittedly the deep
>>> end of GLMs) and was excited to find glmmADMB, but using it has proven
>>> rather frustrating because it often fails (with a dramatic stop that
>>> does not reach the top level and so cannot be caught with tryCatch,
>>> nonetheless) and after I found the above example, I am not so sure it
>>> is always for a good reason.
>>
>>> Thanks,
>>> Vladimir
>>>
>>>
>>>
>>> Session:
>>>
>>>> sessionInfo()
>>
>>
>> On 16-06-09 07:48 PM, Vladimir Trifonov wrote:
>>> Hi,
>>>
>>> Why is the following  ?trivial? model fit failing? After all, we are
>>> fitting a Poisson GLM on a Poisson data.
>>>
>>> --------
>>>> glmmadmb(rpois(100, lambda=8000)~1, family="poisson")
>>> Hessian is 0 in row 1
>>> This means that the derivative if probably identically 0  for this
>> parameter
>>> Error in matrix inverse -- matrix singular in inv(dmatrix)
>>> Estimated covariance matrix may not be positive definite
>>> 1e+20
>>> Estimated covariance matrix may not be positive definite
>>> 1e+20
>>>
>>> GLMM's in R powered by AD Model Builder:
>>>
>>>  Family: poisson
>>>  link = log
>>>
>>> I tried varying the number of samples (100 above), the mean (8000
>>  above) and this fails. Here is another attempt (with a different
>>  kind of fail)
>>
>>>> glmmadmb(rpois(100, lambda=50)~1, family="poisson")
>>> Parameters were estimated, but standard errors were not: the most
>> likely problem is that the curvature at MLE was zero or negative
>>> Error in glmmadmb(rpois(100, lambda = 50) ~ 1, family = "poisson") :
>>>  The function maximizer failed (couldn't find parameter file)
>> Troubleshooting steps include (1) run with 'save.dir' set and inspect
>> output files; (2) change run parameters: see '?admbControl';(3) re-run
>> with debug=TRUE for more information on failure mode
>>> In addition: Warning message:
>>> running command './glmmadmb -maxfn 500 -maxph 5 -noinit -shess' had
>> status 1
>>> --------
>>
>>> After some trial and error, the only thing I found that ?works? (with
>> a warning about the covariance matrix) consistently is to set a
>> ?mysterious? poiss_prob_bound = FALSE
>>>
>>> --------
>>>> glmmadmb(rpois(100, lambda=50)~1, family="poisson",
>> admb.opts=admbControl(poiss_prob_bound=FALSE))
>>> Estimated covariance matrix may not be positive definite
>>> 0.020141
>>> Estimated covariance matrix may not be positive definite
>>> 0.020141
>>>
>>> GLMM's in R powered by AD Model Builder:
>>>
>>>  Family: poisson
>>>  link = log
>>>
>>> Fixed effects:
>>>  Log-likelihood: -327.749
>>>  AIC: 657.498
>>>  Formula: rpois(100, lambda = 50) ~ 1
>>> (Intercept)
>>>   3.904998
>>>
>>> Number of observations: total=100
>>> --------
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From john.maindonald at anu.edu.au  Sat Jun 11 04:24:37 2016
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Sat, 11 Jun 2016 02:24:37 +0000
Subject: [R-sig-ME] glmmADMB fails to fit poisson data
In-Reply-To: <575B7248.2060906@gmail.com>
References: <2439E066-CB88-48EE-A84A-6D88F853167C@gnf.org>
	<575B5B57.2030101@gmail.com>
	<C1D42C80-D461-43E8-BF52-5A64C5C0A7ED@anu.edu.au>
	<575B7248.2060906@gmail.com>
Message-ID: <1C433135-1D53-4F93-B266-2FAC3360B49F@anu.edu.au>

I?d missed the ZINB bit.  There?s an issue whether the amount of
zero inflation is of interest in itself, or whether it is an annoyance
that the model needs to circumvent.  The mechanism that is
generating extra zeros (or, for that matter, deflating the zero counts)
may in any case require separate modeling,

John Maindonald             email: john.maindonald at anu.edu.au

> On 11/06/2016, at 14:07, Ben Bolker <bbolker at gmail.com> wrote:
> 
> 
>  I think that's very sensible, but note that if the OP thinks they need
> zero-inflation (they said that's why they came to glmmADMB), then they
> will probably need to go slightly beyond standard linear models ...
> perhaps a two-stage (zero vs non-zero logistic model + linear model on
> log(x) of positive cases)
> 
>  cheers
>   Ben Bolker
> 
> 
> On 16-06-10 09:56 PM, John Maindonald wrote:
>> With count data where the mean is large, there?s a strong case to
>> be made for finding a suitable power transform of (count+1) and
>> using a normal theory model.  If differences in residual variance
>> are evident, these can be accommodated by assigning weights.
>> Functions for getting diagnostics are better developed for the
>> normal theory models, and easier to interpret.
>> 
>> For the analysis of RNA-Seq data, there is a paper that compares
>> the two styles of model:
>> 
>> Law, CW, Chen, Y, Shi, W, Smyth, GK (2014). Voom: precision weights unlock linear model analysis tools for RNA-seq read counts. Genome Biology 15, R29.http://genomebiology.com/2014/15/2/R29
>> 
>> NB also the recent paper:
>> 
>> Schurch NJ, Schofield P, Gierli?ski M, Cole C, Sherstnev A, Singh V, Wrobel N, Gharbi K, Simpson GG, Owen-Hughes T, Blaxter M, Barton GJ (2016). How many biological replicates are needed in an RNA-seq experiment and which differential expression tool should you use? RNA http://www.rnajournal.org/cgi/doi/10.1261/rna.053959.115
>> 
>> The log(count+1) approach is the best, or close to the best, in the field.
>> 
>> John Maindonald             email: john.maindonald at anu.edu.au
>> 
>>> On 11/06/2016, at 12:29, Ben Bolker <bbolker at gmail.com> wrote:
>>> 
>>> 
>>> * I can appreciate your frustration that glmmADMB doesn't work
>>> out of the box on what seems initially to be a simple problem,
>>> and I appreciate that you are being reasonably diplomatic about
>>> it (not everyone is), but ... it is surprisingly hard to make
>>> a general-purpose solve that works for every data set. glm()
>>> works so well because it uses special-purpose algorithms for
>>> a particular class of models that's narrower than what glmmADMB
>>> can do.
>>> 
>>> * The particular problem is that for Poisson responses with
>>> very large means, the coefficient of variation of the data
>>> also becomes very small.  That means that values that are a little
>>> bit off the mean become very unlikely, so unlikely that they
>>> underflow (the probabilities become numerically zero).  I can
>>> get your example to work if I set the starting value close enough:
>>> 
>>> set.seed(101)
>>> d <- data.frame(x=rpois(100, lambda=8000))
>>> 
>>> library(glmmADMB)
>>> glmmadmb(x~1, family="poisson", data=d)
>>> glmmadmb(x~1, family="poisson", data=d,
>>>        start=list(fixed=log(7500)))  ## works
>>> 
>>> ... it does, however, fail with fixed=log(7000).
>>> 
>>> * the "mysterious" poiss_prob_bound (which *is* documented in
>>> ?admbControl, so it may be obscure but it's not completely mysterious ...)
>>> was added to fix a problem that another user was having with
>>> another data set ... if you
>>> 
>>> file.show(system.file("tpl","glmmadmb.tpl",package="glmmADMB"))
>>> 
>>> and dig around, you'll find that glmmADMB bumps up the probability of
>>> a Poisson by 1e-6 or 1e-10 (in different optimization phases) to prevent
>>> a value of exactly zero. There *is* probably a better way to do this -
>>> there are approximations of the Poisson that work very well in such
>>> small ranges, and they could be used instead - but there is also
>>> a reasonably unending number of such edge cases, and not that many
>>> person-hours to deal with them.
>>> 
>>> * You could try the glmmTMB package, which is a more modern
>>> eventually-replacement for glmmADMB, and which seems
>>> to work on this particular problem -- but be warned that it's
>>> in development, so you may find holes!
>>> 
>>> devtools::install_github("glmmTMB/glmmTMB",sub="glmmTMB")
>>> library(glmmTMB)
>>> glmmTMB(x~1, family="poisson", data=d)
>>> 
>>> * if you have a reproducible example of 'dramatic stop that
>>> does not reach the top level and so cannot be caught with
>>> tryCatch' that would be useful.  Maybe we can help resolve
>>> that (more general) problem.
>>> 
>>> * Andrew Gelman has stated a principle called the "folk theorem of
>>> statistical computing": When you have computational problems, often
>>> there?s a problem with your model.
>>> http://andrewgelman.com/2008/05/13/the_folk_theore/
>>> In this case, I think the issue is that in real life (unless you're
>>> in a field like particle physics), Poisson models are generally
>>> not great models for processes with large means -- the coefficient
>>> of variation is way too small to be realistic. This works with
>>> a negative binomial ...
>>> 
>>> set.seed(101)
>>> d2 <- data.frame(x=rnbinom(100, mu=8000, size=2))
>>> glmmadmb(x~1,data=d2,family="nbinom")
>>> 
>>> (I can appreciate that you may have started with a neg binom
>>> and come to the Poisson in part as a way of trying to simplify
>>> your problem so you could diagnose it ...)
>>> 
>>> cheers
>>>   Ben Bolker
>>> 
>>>> While this is a ?solution?, I would expect this kind of fit to work
>>>> ?off-the-box? (it certainly does with the standard glm function). Can
>>>> someone comment on this.  I am not an expert on GLMs and needed
>>>> something that would fit ZINB + random effects (admittedly the deep
>>>> end of GLMs) and was excited to find glmmADMB, but using it has proven
>>>> rather frustrating because it often fails (with a dramatic stop that
>>>> does not reach the top level and so cannot be caught with tryCatch,
>>>> nonetheless) and after I found the above example, I am not so sure it
>>>> is always for a good reason.
>>> 
>>>> Thanks,
>>>> Vladimir
>>>> 
>>>> 
>>>> 
>>>> Session:
>>>> 
>>>>> sessionInfo()
>>> 
>>> 
>>> On 16-06-09 07:48 PM, Vladimir Trifonov wrote:
>>>> Hi,
>>>> 
>>>> Why is the following  ?trivial? model fit failing? After all, we are
>>>> fitting a Poisson GLM on a Poisson data.
>>>> 
>>>> --------
>>>>> glmmadmb(rpois(100, lambda=8000)~1, family="poisson")
>>>> Hessian is 0 in row 1
>>>> This means that the derivative if probably identically 0  for this
>>> parameter
>>>> Error in matrix inverse -- matrix singular in inv(dmatrix)
>>>> Estimated covariance matrix may not be positive definite
>>>> 1e+20
>>>> Estimated covariance matrix may not be positive definite
>>>> 1e+20
>>>> 
>>>> GLMM's in R powered by AD Model Builder:
>>>> 
>>>> Family: poisson
>>>> link = log
>>>> 
>>>> I tried varying the number of samples (100 above), the mean (8000
>>> above) and this fails. Here is another attempt (with a different
>>> kind of fail)
>>> 
>>>>> glmmadmb(rpois(100, lambda=50)~1, family="poisson")
>>>> Parameters were estimated, but standard errors were not: the most
>>> likely problem is that the curvature at MLE was zero or negative
>>>> Error in glmmadmb(rpois(100, lambda = 50) ~ 1, family = "poisson") :
>>>> The function maximizer failed (couldn't find parameter file)
>>> Troubleshooting steps include (1) run with 'save.dir' set and inspect
>>> output files; (2) change run parameters: see '?admbControl';(3) re-run
>>> with debug=TRUE for more information on failure mode
>>>> In addition: Warning message:
>>>> running command './glmmadmb -maxfn 500 -maxph 5 -noinit -shess' had
>>> status 1
>>>> --------
>>> 
>>>> After some trial and error, the only thing I found that ?works? (with
>>> a warning about the covariance matrix) consistently is to set a
>>> ?mysterious? poiss_prob_bound = FALSE
>>>> 
>>>> --------
>>>>> glmmadmb(rpois(100, lambda=50)~1, family="poisson",
>>> admb.opts=admbControl(poiss_prob_bound=FALSE))
>>>> Estimated covariance matrix may not be positive definite
>>>> 0.020141
>>>> Estimated covariance matrix may not be positive definite
>>>> 0.020141
>>>> 
>>>> GLMM's in R powered by AD Model Builder:
>>>> 
>>>> Family: poisson
>>>> link = log
>>>> 
>>>> Fixed effects:
>>>> Log-likelihood: -327.749
>>>> AIC: 657.498
>>>> Formula: rpois(100, lambda = 50) ~ 1
>>>> (Intercept)
>>>>  3.904998
>>>> 
>>>> Number of observations: total=100
>>>> --------
>>>> 
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 


From davef at otter-rsch.com  Sat Jun 11 06:16:59 2016
From: davef at otter-rsch.com (dave fournier)
Date: Fri, 10 Jun 2016 21:16:59 -0700
Subject: [R-sig-ME] glmmADMB fails to fit poisson data
In-Reply-To: <575B5B57.2030101@gmail.com>
References: <575B5B57.2030101@gmail.com>
Message-ID: <575B90BB.2060801@otter-rsch.com>

If you look at the code for the negative binomial model in glmmadmb you 
will see that it
initially fits the

    log(Y_i+1) transformed data.  This is by far the most stable model 
numerically and good for
getting initial parameter estimates.

However for the Poisson case the code  never got around to writing itself.

I'm sure the code will rectify its oversight in good time.


From davef at otter-rsch.com  Sat Jun 11 16:38:19 2016
From: davef at otter-rsch.com (dave fournier)
Date: Sat, 11 Jun 2016 07:38:19 -0700
Subject: [R-sig-ME] glmmADMB fails to fit poisson data
In-Reply-To: <575B5B57.2030101@gmail.com>
References: <575B5B57.2030101@gmail.com>
Message-ID: <575C225B.9040703@otter-rsch.com>

On the other hand maybe the code never will write itself. The following 
change to the Poisson
model in glmmadmb  using the log(1_+y_i) transformation to get good 
initial parameter estimates
converges nicely on this data set.

     case 0:   // Poisson
       if (cph<2)
         tmpl=-square(log(1.0+y(_i,1))-log(1.0+lambda));
       else
         tmpl= log_density_poisson(y(_i,1),lambda);
       break;
     case 1:   // Binomial: y(_i,1)=#successes, y(_i,2)=#failures,


From sah74 at aber.ac.uk  Sat Jun 11 18:41:41 2016
From: sah74 at aber.ac.uk (Sam Hardman [sah74])
Date: Sat, 11 Jun 2016 16:41:41 +0000
Subject: [R-sig-ME] P-values from interaction terms using lme4
Message-ID: <DB5PR04MB14621A89AF305FEB4EDC7FE38B510@DB5PR04MB1462.eurprd04.prod.outlook.com>

Dear all,


I have some data which I would like to analyse using lme4 and I would really appreciate some help deciding what the best method is.


My experiment is as follows:


I tested the responses of urban and rural great tits to playbacks of great tit song from a loud speaker within their territories.


I created three playback song types:

-undegraded

-degraded

-very degraded


I played these to birds in 20 different cities. In each city I tested one bird in the city centre and one bird in a rural location outside of the city (i.e. paired samples). Each bird received all three playback types.


I measured five different responses to these playbacks:

-Time to sing back to playback (in seconds)

-Time to sing back to playback (in seconds)

-Time the bird spent within five metres of the speaker (in seconds)

-Number of times the bird flew over the speaker (count)

-The closest approach the bird made to the speaker (in metres)


For each of these five repsonses I would like to know if there is an interaction between habitat and playback type.


So, I have a model which looks like this:


mod1<-lmer(repsonse ~ Playback*UR + (1|ID))


Where response is one of the five repsonse behaviours, playback is the playback type, UR is habitat type (urban or rural) and ID is the ID of the bird.


This gives me results and P-Values but am not sure these P-values are valid and I think I should compare this model to a null model to get a valid P-values.


So I can use a likelihood ratio tests to test for differences in response by habitat type alone:


mod1<-lmer(approach ~ UR + (1|Location))
mod2<-lmer(approach ~ 1 + (1|Location))
anova(mod1, mod2)

or for differences in response according tom playback type alone:

mod1<-lmer(approach ~ Playback + (1|Location))
mod2<-lmer(approach ~ 1 + (1|Location))
anova(mod1, mod2)

But how should I do this when there is an interaction term? I deally I would like P-values for each playback type in interaction with habitat. e.g.

Undregraded playback * Habitat (urban/rural
Degraded playback * Habitat (urban/rural)
Very degraded playback * Habitat (urban/rural)

This would allow me to say, for example, something like "urban birds approached the speaker more closely than rural birds in response to undegraded playbacks". I would like to do this with each of the five response behaviours.

I would really appreciate any suggestions for the best way forward with this and apologies if this question is too simple for this group.

Best wishes,
Sam


--------------------------------------------------------------------
Aberystwyth - Prifysgol Gyntaf Cymru https://www.aber.ac.uk/cy/

Aberystwyth - Wales' First University https://www.aber.ac.uk/en/

	[[alternative HTML version deleted]]


From Phillip.Alday at unisa.edu.au  Sun Jun 12 10:31:20 2016
From: Phillip.Alday at unisa.edu.au (Phillip Alday)
Date: Sun, 12 Jun 2016 08:31:20 +0000
Subject: [R-sig-ME] P-values from interaction terms using lme4
In-Reply-To: <DB5PR04MB14621A89AF305FEB4EDC7FE38B510@DB5PR04MB1462.eurprd04.prod.outlook.com>
References: <DB5PR04MB14621A89AF305FEB4EDC7FE38B510@DB5PR04MB1462.eurprd04.prod.outlook.com>
Message-ID: <1465720272.24053.96.camel@loki>

Hi Sam,

if you're getting p-values from lmer outside of a likelihood-ratio test,
then you're using lmerTest, not lme4. lmerTest is designed to be a
drop-in replacement for lme4, but it does bring some extra
features/'complications' in the form of the denominator degrees of
freedom.

There are two easy options for getting ANOVA-style p-values:

1. Using lmerTest, you can just do
anova(mod1,ddf="Satterthwaite",type=2) 

If you're using vanilla lme4, then you need to do this first:

library(lmerTest)
mod1 <- as(mod1,"merModLmerTest")

which will cast your model to an lmerTest model.

2. Using the car package:

library(car)
Anova(mod1,test.statistic="F",type=2)

If you fitted your model with maximum likelihood, i.e. with REML=FALSE,
then you need to refit your model using REML first:

mod1 <- update(mod1,REML=TRUE)

For both options, you need to specify the types of test you're doing. I
highly recommend Type 2, but there is a lot of material on that debate,
search for e.g. Venables' "Exegeses on linear models", or look at the
documentation for car::Anova(). Please note that the distinction for
Type 2 vs Type 3 is *very* relevant for your question since you're
concerned about interaction terms.

For the lmerTest route, you can specify the approximation to use for the
denominator degrees of freedom: Satterthwaite is much faster, but
Kenward-Roger is more accurate. For car::Anova(), the F-statistic is
always computed with  Kenward-Roger (and only works for REML-fitted
models for reasons that I can't explain quickly), but you have the
option of using a Chisq test statistic, which is equivalent to assuming
that the denominator degrees of freedom are infinite, or equivalently,
that your t-values for the coefficients are z-values. 

These ANOVA-style tests are Wald tests and are asymptotically equivalent
to the LR-tests, but are less conservative for finite samples. 

Now, since you care about particular contrasts within the model, you may
also just want to look at your model coefficients. Depending on which
coding scheme you're using, the contrasts represented by your model
coefficients might not be the ones you want, but packages like lsmeans
(a regular mention on the list here and very well documented) can
compute all types of contrasts post-hoc. Rereading your question, this
may be the best way to go for your target conclusion/result statements.

Best,
Phillip


On Sat, 2016-06-11 at 16:41 +0000, Sam Hardman [sah74] wrote:
> Dear all,
> 
> 
> I have some data which I would like to analyse using lme4 and I would really appreciate some help deciding what the best method is.
> 
> 
> My experiment is as follows:
> 
> 
> I tested the responses of urban and rural great tits to playbacks of great tit song from a loud speaker within their territories.
> 
> 
> I created three playback song types:
> 
> -undegraded
> 
> -degraded
> 
> -very degraded
> 
> 
> I played these to birds in 20 different cities. In each city I tested one bird in the city centre and one bird in a rural location outside of the city (i.e. paired samples). Each bird received all three playback types.
> 
> 
> I measured five different responses to these playbacks:
> 
> -Time to sing back to playback (in seconds)
> 
> -Time to sing back to playback (in seconds)
> 
> -Time the bird spent within five metres of the speaker (in seconds)
> 
> -Number of times the bird flew over the speaker (count)
> 
> -The closest approach the bird made to the speaker (in metres)
> 
> 
> For each of these five repsonses I would like to know if there is an interaction between habitat and playback type.
> 
> 
> So, I have a model which looks like this:
> 
> 
> mod1<-lmer(repsonse ~ Playback*UR + (1|ID))
> 
> 
> Where response is one of the five repsonse behaviours, playback is the playback type, UR is habitat type (urban or rural) and ID is the ID of the bird.
> 
> 
> This gives me results and P-Values but am not sure these P-values are valid and I think I should compare this model to a null model to get a valid P-values.
> 
> 
> So I can use a likelihood ratio tests to test for differences in response by habitat type alone:
> 
> 
> mod1<-lmer(approach ~ UR + (1|Location))
> mod2<-lmer(approach ~ 1 + (1|Location))
> anova(mod1, mod2)
> 
> or for differences in response according tom playback type alone:
> 
> mod1<-lmer(approach ~ Playback + (1|Location))
> mod2<-lmer(approach ~ 1 + (1|Location))
> anova(mod1, mod2)
> 
> But how should I do this when there is an interaction term? I deally I would like P-values for each playback type in interaction with habitat. e.g.
> 
> Undregraded playback * Habitat (urban/rural
> Degraded playback * Habitat (urban/rural)
> Very degraded playback * Habitat (urban/rural)
> 
> This would allow me to say, for example, something like "urban birds approached the speaker more closely than rural birds in response to undegraded playbacks". I would like to do this with each of the five response behaviours.
> 
> I would really appreciate any suggestions for the best way forward with this and apologies if this question is too simple for this group.
> 
> Best wishes,
> Sam
> 
> 
> --------------------------------------------------------------------
> Aberystwyth - Prifysgol Gyntaf Cymru https://www.aber.ac.uk/cy/
> 
> Aberystwyth - Wales' First University https://www.aber.ac.uk/en/
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From abfine at gmail.com  Mon Jun 13 00:10:59 2016
From: abfine at gmail.com (Alex Fine)
Date: Sun, 12 Jun 2016 18:10:59 -0400
Subject: [R-sig-ME] P-values from interaction terms using lme4
In-Reply-To: <1465720272.24053.96.camel@loki>
References: <DB5PR04MB14621A89AF305FEB4EDC7FE38B510@DB5PR04MB1462.eurprd04.prod.outlook.com>
	<1465720272.24053.96.camel@loki>
Message-ID: <CAJ6ui+OyB_-KQ6B7oTPQ=NGRs_OV=o7DR9S=EG0vb_R-zbKAGg@mail.gmail.com>

Hey Sam,

I actually think mixed effects regression might be inappropriate in this
case.  Do I have it right that you have 40 total animals in the
experiment?  You said you had 1 bird in the city center and 1 outside the
city in 20 cities.

If that's right, then the model you described (to take one of your
examples) would be:

Approach ~ PlayBack * UrbanRural + (1|ID)

That's 3 * 2 - 1 = 5 coefficients in your model, plus a random intercept
for 20 different cities.  I don't think you have enough data to fit such a
model and trust the results.

If you have a balanced design and you have clear a priori predictions about
each of the contrasts in your design, I'd recommend just using ANOVA.  I
don't think you gain very much from using MEMs in this case.  You could use
vanilla linear regression, but setting up the coding schemes for your two
predictors is going to be so complicated that it'll actually be much
simpler to just do ANOVA + t-tests.

Alex

On Sun, Jun 12, 2016 at 4:31 AM, Phillip Alday <Phillip.Alday at unisa.edu.au>
wrote:

> Hi Sam,
>
> if you're getting p-values from lmer outside of a likelihood-ratio test,
> then you're using lmerTest, not lme4. lmerTest is designed to be a
> drop-in replacement for lme4, but it does bring some extra
> features/'complications' in the form of the denominator degrees of
> freedom.
>
> There are two easy options for getting ANOVA-style p-values:
>
> 1. Using lmerTest, you can just do
> anova(mod1,ddf="Satterthwaite",type=2)
>
> If you're using vanilla lme4, then you need to do this first:
>
> library(lmerTest)
> mod1 <- as(mod1,"merModLmerTest")
>
> which will cast your model to an lmerTest model.
>
> 2. Using the car package:
>
> library(car)
> Anova(mod1,test.statistic="F",type=2)
>
> If you fitted your model with maximum likelihood, i.e. with REML=FALSE,
> then you need to refit your model using REML first:
>
> mod1 <- update(mod1,REML=TRUE)
>
> For both options, you need to specify the types of test you're doing. I
> highly recommend Type 2, but there is a lot of material on that debate,
> search for e.g. Venables' "Exegeses on linear models", or look at the
> documentation for car::Anova(). Please note that the distinction for
> Type 2 vs Type 3 is *very* relevant for your question since you're
> concerned about interaction terms.
>
> For the lmerTest route, you can specify the approximation to use for the
> denominator degrees of freedom: Satterthwaite is much faster, but
> Kenward-Roger is more accurate. For car::Anova(), the F-statistic is
> always computed with  Kenward-Roger (and only works for REML-fitted
> models for reasons that I can't explain quickly), but you have the
> option of using a Chisq test statistic, which is equivalent to assuming
> that the denominator degrees of freedom are infinite, or equivalently,
> that your t-values for the coefficients are z-values.
>
> These ANOVA-style tests are Wald tests and are asymptotically equivalent
> to the LR-tests, but are less conservative for finite samples.
>
> Now, since you care about particular contrasts within the model, you may
> also just want to look at your model coefficients. Depending on which
> coding scheme you're using, the contrasts represented by your model
> coefficients might not be the ones you want, but packages like lsmeans
> (a regular mention on the list here and very well documented) can
> compute all types of contrasts post-hoc. Rereading your question, this
> may be the best way to go for your target conclusion/result statements.
>
> Best,
> Phillip
>
>
> On Sat, 2016-06-11 at 16:41 +0000, Sam Hardman [sah74] wrote:
> > Dear all,
> >
> >
> > I have some data which I would like to analyse using lme4 and I would
> really appreciate some help deciding what the best method is.
> >
> >
> > My experiment is as follows:
> >
> >
> > I tested the responses of urban and rural great tits to playbacks of
> great tit song from a loud speaker within their territories.
> >
> >
> > I created three playback song types:
> >
> > -undegraded
> >
> > -degraded
> >
> > -very degraded
> >
> >
> > I played these to birds in 20 different cities. In each city I tested
> one bird in the city centre and one bird in a rural location outside of the
> city (i.e. paired samples). Each bird received all three playback types.
> >
> >
> > I measured five different responses to these playbacks:
> >
> > -Time to sing back to playback (in seconds)
> >
> > -Time to sing back to playback (in seconds)
> >
> > -Time the bird spent within five metres of the speaker (in seconds)
> >
> > -Number of times the bird flew over the speaker (count)
> >
> > -The closest approach the bird made to the speaker (in metres)
> >
> >
> > For each of these five repsonses I would like to know if there is an
> interaction between habitat and playback type.
> >
> >
> > So, I have a model which looks like this:
> >
> >
> > mod1<-lmer(repsonse ~ Playback*UR + (1|ID))
> >
> >
> > Where response is one of the five repsonse behaviours, playback is the
> playback type, UR is habitat type (urban or rural) and ID is the ID of the
> bird.
> >
> >
> > This gives me results and P-Values but am not sure these P-values are
> valid and I think I should compare this model to a null model to get a
> valid P-values.
> >
> >
> > So I can use a likelihood ratio tests to test for differences in
> response by habitat type alone:
> >
> >
> > mod1<-lmer(approach ~ UR + (1|Location))
> > mod2<-lmer(approach ~ 1 + (1|Location))
> > anova(mod1, mod2)
> >
> > or for differences in response according tom playback type alone:
> >
> > mod1<-lmer(approach ~ Playback + (1|Location))
> > mod2<-lmer(approach ~ 1 + (1|Location))
> > anova(mod1, mod2)
> >
> > But how should I do this when there is an interaction term? I deally I
> would like P-values for each playback type in interaction with habitat. e.g.
> >
> > Undregraded playback * Habitat (urban/rural
> > Degraded playback * Habitat (urban/rural)
> > Very degraded playback * Habitat (urban/rural)
> >
> > This would allow me to say, for example, something like "urban birds
> approached the speaker more closely than rural birds in response to
> undegraded playbacks". I would like to do this with each of the five
> response behaviours.
> >
> > I would really appreciate any suggestions for the best way forward with
> this and apologies if this question is too simple for this group.
> >
> > Best wishes,
> > Sam
> >
> >
> > --------------------------------------------------------------------
> > Aberystwyth - Prifysgol Gyntaf Cymru https://www.aber.ac.uk/cy/
> >
> > Aberystwyth - Wales' First University https://www.aber.ac.uk/en/
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Alex Fine
Ph. (336) 302-3251
web:  http://internal.psychology.illinois.edu/~abfine/
<http://internal.psychology.illinois.edu/~abfine/AlexFineHome.html>

	[[alternative HTML version deleted]]


From dianxiangan32 at sina.cn  Mon Jun 13 15:22:42 2016
From: dianxiangan32 at sina.cn (RuiRui)
Date: Mon, 13 Jun 2016 21:22:42 +0800
Subject: [R-sig-ME] multcomp package
Message-ID: <20160613132242.7401C6C0196@webmail.sinamail.sina.com.cn>

Hi,

It seems you want to test the fixed effect. So I think the related p-value is appropriate. I'm not sure...


--------------------------------


----- Original Message -----
From: li li <hannah.hlx at gmail.com>
To: r-sig-mixed-models <r-sig-mixed-models at r-project.org>, r-help <r-help at r-project.org>, epalmery at cns.umass.edu
Subject: Re: [R-sig-ME] multcomp package
Date: 2016-06-07 11:32


Thanks Evan and Gabriel for the reply. I think it might help me make the
question clearer if I show the data and the model here (I actually asked
questions related to this data before but I still need some help). The data
looks like the following:
   response individual time method
1    102.9          3    0      3
2    103.0          3    3      3
3    103.0          3    6      3
4    102.8          3    9      3
5    102.2          3   12      3
6    102.5          3   15      3
7    103.0          3   18      3
8    102.0          3   24      3
9    102.8          1    0      3
10   102.7          1    3      3
11   103.0          1    6      3
12   102.2          1    9      3
13   103.0          1   12      3
14   102.8          1   15      3
15   102.8          1   18      3
16   102.9          1   24      3
17   102.2          2    0      3
18   102.6          2    3      3
19   103.4          2    6      3
20   102.3          2    9      3
21   101.3          2   12      3
22   102.1          2   15      3
23   102.1          2   18      3
24   102.2          2   24      3
25   102.7          4    0      3
26   102.3          4    3      3
27   102.6          4    6      3
28   102.7          4    9      3
29   102.8          4   12      3
30   102.5          5    0      3
31   102.4          5    3      3
32   102.1          5    6      3
33   102.3          6    0      3
34   102.3          6    3      3
35   101.9          7    0      3
36   102.0          7    3      3
37   107.4          3    0      1
38   101.3          3   12      1
39    92.8          3   15      1
40    73.7          3   18      1
41   104.7          3   24      1
42    92.6          1    0      1
43   101.9          1   12      1
44   106.3          1   15      1
45   104.1          1   18      1
46    95.6          1   24      1
47    79.8          2    0      1
48    89.7          2   12      1
49    97.0          2   15      1
50   108.4          2   18      1
51   103.5          2   24      1
52    96.4          4    0      1
53    89.3          4   12      1
54   112.6          5    0      1
55    93.3          6    0      1
56    99.6          7    0      1
57   109.5          3    0      2
58    98.5          3   12      2
59   103.5          3   24      2
60   113.5          1    0      2
61    94.5          1   12      2
62    88.5          1   24      2
63    99.5          2    0      2
64    97.5          2   12      2
65    98.5          2   24      2
66   103.5          4    0      2
67    89.5          5    0      2
68    87.5          6    0      2
69    82.5          7    0      2
I used the following random intercept and random slope model for this data.
Denote as y_ijk the response value from *j*th individual within *i*th
method at time point *k*. Assume the following model for y_ijk:
      y_ijk= (alpha_0+ tau_i +a_j(i))+(beta_i+b_j(i)) T_k + e_ijk
Here alpha_0 is the grand mean;
          tau_i is the fixed effect for ith method;
          a_j(i) is random intercept corresponding to the *j*th individual
within *i*th method, assumed to be common for all three methods;
          beta_i is the fixed slope corresponding to the ith method;
          b_j(i) is the random slope corresponding to jth individual for
the ith method, assumed to be common for all three methods;
          T_k is the time corresponding to y_ijk;
          e_ijk is the residual.
Here I used the following specification for the lme function
mod1 <- lme(fixed= reponse ~ method*time, random=~ 1 +time | individual,
data=one, weights= varIdent(form=~1|method),
            control = lmeControl(opt = "optim"))
I did not add the method in random effects  because here I assumed common
random slope for all three methods.
This model is used to initially check whether there fixed slopes are equal.
I wanted to further evaluate whether each fixed slope (beta_1, beta_2 and
beta 3) is significantly different from zero. I was hoping to evaluate this
based on the same model.
The output is as follows. Does the highlighted part below already gives the
result for testing beta_1=0; beta_2=0 and beta_3=0?
Thanks very much.
   Hanna
> summary(mod1)Linear mixed-effects model fit by REML
 Data: one
       AIC      BIC    logLik
  304.4703 330.1879 -140.2352
Random effects:
 Formula: ~1 + time | individual
 Structure: General positive-definite, Log-Cholesky parametrization
            StdDev       Corr
(Intercept) 0.2487869075 (Intr)
time        0.0001841179 -0.056
Residual    0.3718305953
Variance function:
 Structure: Different standard deviations per stratum
 Formula: ~1 | method
 Parameter estimates:
       3        1        2
 1.00000 26.59750 24.74476
Fixed effects: reponse ~ method * time
                Value Std.Error DF   t-value p-value(Intercept)
96.65395  3.528586 57 27.391694  0.0000
method2       1.17851  4.856026 57  0.242689  0.8091
method3       5.87505  3.528617 57  1.664973  0.1014time
0.07010  0.250983 57  0.279301  0.7810
method2:time -0.12616  0.360585 57 -0.349877  0.7277
method3:time -0.08010  0.251105 57 -0.318999  0.7509
 Correlation:
             (Intr) methd2 methd3 time   mthd2:
method2      -0.726
method3      -0.999  0.726
time         -0.779  0.566  0.779
method2:time  0.542 -0.712 -0.542 -0.696
method3:time  0.778 -0.566 -0.779 -0.999  0.696
Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max
-2.67575293 -0.51633192  0.06742723  0.59706762  2.81061874
Number of Observations: 69
Number of Groups: 7
2016-06-06 11:21 GMT-04:00 Gabriel Baud-Bovy <baud-bovy.gabriel at hsr.it>:
> On 06/06/2016 4:57 PM, li li wrote:
>
> Hi all,
>   After fitting a random slope and random intercept model using lme
> function, I want
> to test whether each of the fixed slopes is equal to zero (The output of
> model is below).
> Can this be done (testing each individual slope) using multcomp package?
>
> I don't understand what you mean by testing individual slope ?
>
> For the fixed effects, you might test whether there is a method, time or
> interaction
> effect using one of the methods described below
>
> For the randome effects, according to your model specification, the time
> dependency might vary for each individual. the sd for the time
> (0.0001841179)
> is small.  You might want to test whether to include randome slope  by
> doing a LRT
> between a model with it and another model without.
>
> Whay not include method in the random effects ?
>
> Gabriel
>
>   Thanks much for the help.
>    Hanna
>
> To get p values:
>
>
> http://stats.stackexchange.com/questions/118416/getting-p-value-with-mixed-effect-with-lme4-package
>
>
> http://mindingthebrain.blogspot.it/2014/02/three-ways-to-get-parameter-specific-p.html
>
> Using lmerTest package
> https://cran.r-project.org/web/packages/lmerTest/lmerTest.pdf
>
> or using mixed in afex package
> http://rpackages.ianhowson.com/cran/afex/man/mixed.html
>
> both use pbkrtest packages
> https://cran.r-project.org/web/packages/pbkrtest/pbkrtest.pdf
>
> a faq
> http://glmm.wikidot.com/faq
>
>
>
>
> summary(mod1)Linear mixed-effects model fit by REML
>
>  Data: one
>        AIC      BIC    logLik
>   304.4703 330.1879 -140.2352
>
> Random effects:
>  Formula: ~1 + time | individual
>  Structure: General positive-definite, Log-Cholesky parametrization
>             StdDev       Corr
> (Intercept) 0.2487869075 (Intr)
> time        0.0001841179 -0.056
> Residual    0.3718305953
>
> Variance function:
>  Structure: Different standard deviations per stratum
>  Formula: ~1 | method
>  Parameter estimates:
>        3        1        2
>  1.00000 26.59750 24.74476
> Fixed effects: reponse ~ method * time
>                 Value Std.Error DF   t-value p-value(Intercept)
> 96.65395  3.528586 57 27.391694  0.0000
> method2       1.17851  4.856026 57  0.242689  0.8091
> method3       5.87505  3.528617 57  1.664973  0.1014time
> 0.07010  0.250983 57  0.279301  0.7810
> method2:time -0.12616  0.360585 57 -0.349877  0.7277
> method3:time -0.08010  0.251105 57 -0.318999  0.7509
>  Correlation:
>              (Intr) methd2 methd3 time   mthd2:
> method2      -0.726
> method3      -0.999  0.726
> time         -0.779  0.566  0.779
> method2:time  0.542 -0.712 -0.542 -0.696
> method3:time  0.778 -0.566 -0.779 -0.999  0.696
>
> Standardized Within-Group Residuals:
>         Min          Q1         Med          Q3         Max
> -2.67575293 -0.51633192  0.06742723  0.59706762  2.81061874
>
> Number of Observations: 69
> Number of Groups: 7 >
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________R-sig-mixed-models at r-project.org mailing listhttps://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> .
>
>
>
>
> --
> ---------------------------------------------------------------------
> Gabriel Baud-Bovy               tel.: (+39) 02 2643 4839 (office)
> UHSR University                       (+39) 02 2643 3429 (laboratory)
> via Olgettina, 58                     (+39) 02 2643 4891 (secretary)
> 20132 Milan, Italy               fax: (+39) 02 2643 4892
> ---------------------------------------------------------------------
>
>
	[[alternative HTML version deleted]]
_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From sah74 at aber.ac.uk  Mon Jun 13 01:35:22 2016
From: sah74 at aber.ac.uk (Sam Hardman [sah74])
Date: Sun, 12 Jun 2016 23:35:22 +0000
Subject: [R-sig-ME] P-values from interaction terms using lme4
In-Reply-To: <1465720272.24053.96.camel@loki>
References: <DB5PR04MB14621A89AF305FEB4EDC7FE38B510@DB5PR04MB1462.eurprd04.prod.outlook.com>,
	<1465720272.24053.96.camel@loki>
Message-ID: <DB5PR04MB1462C6E366452487D097A73F8B520@DB5PR04MB1462.eurprd04.prod.outlook.com>

Dear Phillip,

Thanks for taking the time to answer my question, your answer is really helpful and has given me plenty to think about. The lsmeans package in particular sounds like just what I need and was something I hadn't heard of before.

I will work through your suggestions and see how the results look.

Best wishes,
Sam

________________________________________
Von: Phillip Alday <Phillip.Alday at unisa.edu.au>
Gesendet: Sonntag, 12. Juni 2016 09:31:20
An: Sam Hardman [sah74]
Cc: r-sig-mixed-models at r-project.org
Betreff: Re: [R-sig-ME] P-values from interaction terms using lme4

Hi Sam,

if you're getting p-values from lmer outside of a likelihood-ratio test,
then you're using lmerTest, not lme4. lmerTest is designed to be a
drop-in replacement for lme4, but it does bring some extra
features/'complications' in the form of the denominator degrees of
freedom.

There are two easy options for getting ANOVA-style p-values:

1. Using lmerTest, you can just do
anova(mod1,ddf="Satterthwaite",type=2)

If you're using vanilla lme4, then you need to do this first:

library(lmerTest)
mod1 <- as(mod1,"merModLmerTest")

which will cast your model to an lmerTest model.

2. Using the car package:

library(car)
Anova(mod1,test.statistic="F",type=2)

If you fitted your model with maximum likelihood, i.e. with REML=FALSE,
then you need to refit your model using REML first:

mod1 <- update(mod1,REML=TRUE)

For both options, you need to specify the types of test you're doing. I
highly recommend Type 2, but there is a lot of material on that debate,
search for e.g. Venables' "Exegeses on linear models", or look at the
documentation for car::Anova(). Please note that the distinction for
Type 2 vs Type 3 is *very* relevant for your question since you're
concerned about interaction terms.

For the lmerTest route, you can specify the approximation to use for the
denominator degrees of freedom: Satterthwaite is much faster, but
Kenward-Roger is more accurate. For car::Anova(), the F-statistic is
always computed with  Kenward-Roger (and only works for REML-fitted
models for reasons that I can't explain quickly), but you have the
option of using a Chisq test statistic, which is equivalent to assuming
that the denominator degrees of freedom are infinite, or equivalently,
that your t-values for the coefficients are z-values.

These ANOVA-style tests are Wald tests and are asymptotically equivalent
to the LR-tests, but are less conservative for finite samples.

Now, since you care about particular contrasts within the model, you may
also just want to look at your model coefficients. Depending on which
coding scheme you're using, the contrasts represented by your model
coefficients might not be the ones you want, but packages like lsmeans
(a regular mention on the list here and very well documented) can
compute all types of contrasts post-hoc. Rereading your question, this
may be the best way to go for your target conclusion/result statements.

Best,
Phillip


On Sat, 2016-06-11 at 16:41 +0000, Sam Hardman [sah74] wrote:
> Dear all,
>
>
> I have some data which I would like to analyse using lme4 and I would really appreciate some help deciding what the best method is.
>
>
> My experiment is as follows:
>
>
> I tested the responses of urban and rural great tits to playbacks of great tit song from a loud speaker within their territories.
>
>
> I created three playback song types:
>
> -undegraded
>
> -degraded
>
> -very degraded
>
>
> I played these to birds in 20 different cities. In each city I tested one bird in the city centre and one bird in a rural location outside of the city (i.e. paired samples). Each bird received all three playback types.
>
>
> I measured five different responses to these playbacks:
>
> -Time to sing back to playback (in seconds)
>
> -Time to sing back to playback (in seconds)
>
> -Time the bird spent within five metres of the speaker (in seconds)
>
> -Number of times the bird flew over the speaker (count)
>
> -The closest approach the bird made to the speaker (in metres)
>
>
> For each of these five repsonses I would like to know if there is an interaction between habitat and playback type.
>
>
> So, I have a model which looks like this:
>
>
> mod1<-lmer(repsonse ~ Playback*UR + (1|ID))
>
>
> Where response is one of the five repsonse behaviours, playback is the playback type, UR is habitat type (urban or rural) and ID is the ID of the bird.
>
>
> This gives me results and P-Values but am not sure these P-values are valid and I think I should compare this model to a null model to get a valid P-values.
>
>
> So I can use a likelihood ratio tests to test for differences in response by habitat type alone:
>
>
> mod1<-lmer(approach ~ UR + (1|Location))
> mod2<-lmer(approach ~ 1 + (1|Location))
> anova(mod1, mod2)
>
> or for differences in response according tom playback type alone:
>
> mod1<-lmer(approach ~ Playback + (1|Location))
> mod2<-lmer(approach ~ 1 + (1|Location))
> anova(mod1, mod2)
>
> But how should I do this when there is an interaction term? I deally I would like P-values for each playback type in interaction with habitat. e.g.
>
> Undregraded playback * Habitat (urban/rural
> Degraded playback * Habitat (urban/rural)
> Very degraded playback * Habitat (urban/rural)
>
> This would allow me to say, for example, something like "urban birds approached the speaker more closely than rural birds in response to undegraded playbacks". I would like to do this with each of the five response behaviours.
>
> I would really appreciate any suggestions for the best way forward with this and apologies if this question is too simple for this group.
>
> Best wishes,
> Sam
>
>
> --------------------------------------------------------------------
> Aberystwyth - Prifysgol Gyntaf Cymru https://www.aber.ac.uk/cy/
>
> Aberystwyth - Wales' First University https://www.aber.ac.uk/en/
>
>       [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



--------------------------------------------------------------------
Aberystwyth - Prifysgol Gyntaf Cymru https://www.aber.ac.uk/cy/

Aberystwyth ? Wales? First University https://www.aber.ac.uk/en/

From sah74 at aber.ac.uk  Mon Jun 13 01:43:47 2016
From: sah74 at aber.ac.uk (Sam Hardman [sah74])
Date: Sun, 12 Jun 2016 23:43:47 +0000
Subject: [R-sig-ME] P-values from interaction terms using lme4
In-Reply-To: <CAJ6ui+OyB_-KQ6B7oTPQ=NGRs_OV=o7DR9S=EG0vb_R-zbKAGg@mail.gmail.com>
References: <DB5PR04MB14621A89AF305FEB4EDC7FE38B510@DB5PR04MB1462.eurprd04.prod.outlook.com>
	<1465720272.24053.96.camel@loki>,
	<CAJ6ui+OyB_-KQ6B7oTPQ=NGRs_OV=o7DR9S=EG0vb_R-zbKAGg@mail.gmail.com>
Message-ID: <DB5PR04MB14625C2A380ADE88080CB9C68B520@DB5PR04MB1462.eurprd04.prod.outlook.com>

Hi Alex,


The reason I was looking at using mixed models is because I have repeated measures for indivuals (i.e. each bird was tested three times with three different playback treatments). As far as I know ANOVA can't control for this. I am wrong about this?


You are correct that I have 40 animals in the experiment, with three treatments each that makes 120 measurements per response behaviour. I agree with you that the sample size is small which could cause problems with reliability of results. If ANOVA could work then I will certainly look at that. How would I control for repeated measures?


Thanks for your help, I appreciate it.

Sam

________________________________
Von: Alex Fine <abfine at gmail.com>
Gesendet: Sonntag, 12. Juni 2016 23:10:59
An: Phillip Alday
Cc: Sam Hardman [sah74]; r-sig-mixed-models at r-project.org
Betreff: Re: [R-sig-ME] P-values from interaction terms using lme4

Hey Sam,

I actually think mixed effects regression might be inappropriate in this case.  Do I have it right that you have 40 total animals in the experiment?  You said you had 1 bird in the city center and 1 outside the city in 20 cities.

If that's right, then the model you described (to take one of your examples) would be:

Approach ~ PlayBack * UrbanRural + (1|ID)

That's 3 * 2 - 1 = 5 coefficients in your model, plus a random intercept for 20 different cities.  I don't think you have enough data to fit such a model and trust the results.

If you have a balanced design and you have clear a priori predictions about each of the contrasts in your design, I'd recommend just using ANOVA.  I don't think you gain very much from using MEMs in this case.  You could use vanilla linear regression, but setting up the coding schemes for your two predictors is going to be so complicated that it'll actually be much simpler to just do ANOVA + t-tests.

Alex

On Sun, Jun 12, 2016 at 4:31 AM, Phillip Alday <Phillip.Alday at unisa.edu.au<mailto:Phillip.Alday at unisa.edu.au>> wrote:
Hi Sam,

if you're getting p-values from lmer outside of a likelihood-ratio test,
then you're using lmerTest, not lme4. lmerTest is designed to be a
drop-in replacement for lme4, but it does bring some extra
features/'complications' in the form of the denominator degrees of
freedom.

There are two easy options for getting ANOVA-style p-values:

1. Using lmerTest, you can just do
anova(mod1,ddf="Satterthwaite",type=2)

If you're using vanilla lme4, then you need to do this first:

library(lmerTest)
mod1 <- as(mod1,"merModLmerTest")

which will cast your model to an lmerTest model.

2. Using the car package:

library(car)
Anova(mod1,test.statistic="F",type=2)

If you fitted your model with maximum likelihood, i.e. with REML=FALSE,
then you need to refit your model using REML first:

mod1 <- update(mod1,REML=TRUE)

For both options, you need to specify the types of test you're doing. I
highly recommend Type 2, but there is a lot of material on that debate,
search for e.g. Venables' "Exegeses on linear models", or look at the
documentation for car::Anova(). Please note that the distinction for
Type 2 vs Type 3 is *very* relevant for your question since you're
concerned about interaction terms.

For the lmerTest route, you can specify the approximation to use for the
denominator degrees of freedom: Satterthwaite is much faster, but
Kenward-Roger is more accurate. For car::Anova(), the F-statistic is
always computed with  Kenward-Roger (and only works for REML-fitted
models for reasons that I can't explain quickly), but you have the
option of using a Chisq test statistic, which is equivalent to assuming
that the denominator degrees of freedom are infinite, or equivalently,
that your t-values for the coefficients are z-values.

These ANOVA-style tests are Wald tests and are asymptotically equivalent
to the LR-tests, but are less conservative for finite samples.

Now, since you care about particular contrasts within the model, you may
also just want to look at your model coefficients. Depending on which
coding scheme you're using, the contrasts represented by your model
coefficients might not be the ones you want, but packages like lsmeans
(a regular mention on the list here and very well documented) can
compute all types of contrasts post-hoc. Rereading your question, this
may be the best way to go for your target conclusion/result statements.

Best,
Phillip


On Sat, 2016-06-11 at 16:41 +0000, Sam Hardman [sah74] wrote:
> Dear all,
>
>
> I have some data which I would like to analyse using lme4 and I would really appreciate some help deciding what the best method is.
>
>
> My experiment is as follows:
>
>
> I tested the responses of urban and rural great tits to playbacks of great tit song from a loud speaker within their territories.
>
>
> I created three playback song types:
>
> -undegraded
>
> -degraded
>
> -very degraded
>
>
> I played these to birds in 20 different cities. In each city I tested one bird in the city centre and one bird in a rural location outside of the city (i.e. paired samples). Each bird received all three playback types.
>
>
> I measured five different responses to these playbacks:
>
> -Time to sing back to playback (in seconds)
>
> -Time to sing back to playback (in seconds)
>
> -Time the bird spent within five metres of the speaker (in seconds)
>
> -Number of times the bird flew over the speaker (count)
>
> -The closest approach the bird made to the speaker (in metres)
>
>
> For each of these five repsonses I would like to know if there is an interaction between habitat and playback type.
>
>
> So, I have a model which looks like this:
>
>
> mod1<-lmer(repsonse ~ Playback*UR + (1|ID))
>
>
> Where response is one of the five repsonse behaviours, playback is the playback type, UR is habitat type (urban or rural) and ID is the ID of the bird.
>
>
> This gives me results and P-Values but am not sure these P-values are valid and I think I should compare this model to a null model to get a valid P-values.
>
>
> So I can use a likelihood ratio tests to test for differences in response by habitat type alone:
>
>
> mod1<-lmer(approach ~ UR + (1|Location))
> mod2<-lmer(approach ~ 1 + (1|Location))
> anova(mod1, mod2)
>
> or for differences in response according tom playback type alone:
>
> mod1<-lmer(approach ~ Playback + (1|Location))
> mod2<-lmer(approach ~ 1 + (1|Location))
> anova(mod1, mod2)
>
> But how should I do this when there is an interaction term? I deally I would like P-values for each playback type in interaction with habitat. e.g.
>
> Undregraded playback * Habitat (urban/rural
> Degraded playback * Habitat (urban/rural)
> Very degraded playback * Habitat (urban/rural)
>
> This would allow me to say, for example, something like "urban birds approached the speaker more closely than rural birds in response to undegraded playbacks". I would like to do this with each of the five response behaviours.
>
> I would really appreciate any suggestions for the best way forward with this and apologies if this question is too simple for this group.
>
> Best wishes,
> Sam
>
>
> --------------------------------------------------------------------
> Aberystwyth - Prifysgol Gyntaf Cymru https://www.aber.ac.uk/cy/
>
> Aberystwyth - Wales' First University https://www.aber.ac.uk/en/
>
>       [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



--
Alex Fine
Ph. (336) 302-3251
web:  http://internal.psychology.illinois.edu/~abfine/<http://internal.psychology.illinois.edu/~abfine/AlexFineHome.html>


--------------------------------------------------------------------
Aberystwyth - Prifysgol Gyntaf Cymru https://www.aber.ac.uk/cy/

Aberystwyth - Wales' First University https://www.aber.ac.uk/en/

	[[alternative HTML version deleted]]


From muschitiello at gmail.com  Tue Jun 14 11:14:45 2016
From: muschitiello at gmail.com (Cristina Muschitiello)
Date: Tue, 14 Jun 2016 11:14:45 +0200
Subject: [R-sig-ME] nested two level mixed model with lmer
Message-ID: <CAEzQLvjdk1gUj3hBYnXP1h2DZ0B76ndC1P8GKfQ=T+2qqo2t_w@mail.gmail.com>

I'd need to have a suggestion for my analysis:

I have two soil treatments: CT and NT.

For each treatment, I have 11 CO2 measurements taken in 7 times, i.e. 11
"replicates" for 7 dates.
Replicates are nested in the treatments.

I'd like to evaluate if the measurements are different in time for the two
treatments.

My information are:


   - replicates(11)=random factor;
   - days=repeated measure factor (fixed factor)
   - treatment = between subject factor (fixed factor)
   - CO2 = Co2 emission measures (=dependent variable)


Is it correct to consider this as a nested two-level repeated measures
ANOVA?

Is it correct to use the following R sintax?

m1 <- lmer(CO2~days*treatment+(days|replicates),mydata)

Is this a random intercept and slope model with replicates nested in
treatment?

Is it correct to say that this model accounts for:

the main effect of treatment and time and
the interaction between the two?
What would be the difference of m1 from m2?

m2 <- lmer(CO2~days*treatment+(1|replicates),mydata)

Thank you

Cristina

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Jun 14 11:52:31 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 14 Jun 2016 11:52:31 +0200
Subject: [R-sig-ME] nested two level mixed model with lmer
In-Reply-To: <CAEzQLvjdk1gUj3hBYnXP1h2DZ0B76ndC1P8GKfQ=T+2qqo2t_w@mail.gmail.com>
References: <CAEzQLvjdk1gUj3hBYnXP1h2DZ0B76ndC1P8GKfQ=T+2qqo2t_w@mail.gmail.com>
Message-ID: <CAJuCY5xGRsnc2i6BLYHASR8_F+JhQyvD6NnUqR0z5iK-de=-Gw@mail.gmail.com>

Dear Christina,

m1 assumes a linear trend along days with different slopes among treatments
and replicates. Whereas m2 assumes that the linear trend along days only
depends on treatment. So all replicates within a treatment have the same
slope.

PS Don't post in HTML as it can make the text unreadable.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-06-14 11:14 GMT+02:00 Cristina Muschitiello <muschitiello at gmail.com>:

> I'd need to have a suggestion for my analysis:
>
> I have two soil treatments: CT and NT.
>
> For each treatment, I have 11 CO2 measurements taken in 7 times, i.e. 11
> "replicates" for 7 dates.
> Replicates are nested in the treatments.
>
> I'd like to evaluate if the measurements are different in time for the two
> treatments.
>
> My information are:
>
>
>    - replicates(11)=random factor;
>    - days=repeated measure factor (fixed factor)
>    - treatment = between subject factor (fixed factor)
>    - CO2 = Co2 emission measures (=dependent variable)
>
>
> Is it correct to consider this as a nested two-level repeated measures
> ANOVA?
>
> Is it correct to use the following R sintax?
>
> m1 <- lmer(CO2~days*treatment+(days|replicates),mydata)
>
> Is this a random intercept and slope model with replicates nested in
> treatment?
>
> Is it correct to say that this model accounts for:
>
> the main effect of treatment and time and
> the interaction between the two?
> What would be the difference of m1 from m2?
>
> m2 <- lmer(CO2~days*treatment+(1|replicates),mydata)
>
> Thank you
>
> Cristina
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Jun 14 16:37:17 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 14 Jun 2016 10:37:17 -0400
Subject: [R-sig-ME] glmmADMB fails to fit poisson data
In-Reply-To: <575C225B.9040703@otter-rsch.com>
References: <575B5B57.2030101@gmail.com> <575C225B.9040703@otter-rsch.com>
Message-ID: <5760169D.7000904@gmail.com>


  Thanks Dave. Would you suggest replacing the previous Poisson code
entirely?  (That seems sensible; unfortunately I don't think we have the
test data for the previous [May 2013] example lying around ... )

   Ben

   case 0:   // Poisson
	if (poiss_prob_bound==0) {
	    tmpl =  log_density_poisson(y(_i,1),lambda);
	} else {
          if (cph<5)
	    tmpl = log(e3+exp(log_density_poisson(y(_i,1),lambda)));
          else
	    tmpl = log(e4+exp(log_density_poisson(y(_i,1),lambda)));
	}
      break;

On 16-06-11 10:38 AM, dave fournier wrote:
>   case 0:   // Poisson
>       if (cph<2)
>         tmpl=-square(log(1.0+y(_i,1))-log(1.0+lambda));
>       else
>         tmpl= log_density_poisson(y(_i,1),lambda);
>       break;


From jinjin9625 at gmail.com  Wed Jun 15 03:17:50 2016
From: jinjin9625 at gmail.com (=?UTF-8?B?7KeE7Z2s7KeE?=)
Date: Wed, 15 Jun 2016 10:17:50 +0900
Subject: [R-sig-ME] Dear nlme-authors
Message-ID: <CALSgcQwzcmNf_o=G-sB+u9zYaSMG08MhEGGzCS3rpkWQifAzSQ@mail.gmail.com>

Dear nlme-authors,

Hello my name is Heejin Jin, a master student of Seoul National
University in Korea.

I have a question about lme function in nlme package.

First, I got an error message from R such as it can't be converge.

So, I used option "singular.ok=TURE" which makes the model to converge.

I wonder that can I trust the results from this option ?

Second, there are options to control iteration numbers.

If I used too many iteration numbers, then the velocity getting slow
than default?

I look forward to hearing from you soon.

Thanks !

Sincerely
Heejin Jin

	[[alternative HTML version deleted]]


From robert.espesser at lpl-aix.fr  Wed Jun 15 23:33:06 2016
From: robert.espesser at lpl-aix.fr (espesser)
Date: Wed, 15 Jun 2016 23:33:06 +0200
Subject: [R-sig-ME] ordinal model and  lsmeans  mean class computing
Message-ID: <5761C992.3050707@lpl-aix.fr>



Dear All,


I tried to understand how the predicted mean class of an ordinal mixed 
model was computed in lsmeans().
(I want to compute mean classes from the fixed effects only; lsmeans 
included all the random terms)

# from the data wine, I estimated the model

library(ordinal)

  data(wine)

  fm22.clmm= clmm(rating~temp+contact +(1|judge),data=wine, Hess=T)

# get mean classes with lsmeans

lsmeans(fm22.clmm,   ~ temp, mode="mean.class")

  temp mean.class        SE df asymp.LCL asymp.UCL

  cold    2.339608 0.166799 NA   2.012688   2.666528

  warm    3.479936 0.201921 NA   3.084178   3.875694

  

Results are averaged over the levels of: contact

Confidence level used: 0.95

Warning message:

In is.na(x) : is.na() applied to non-(list or vector) of type 'NULL'

I supposed that the predicted mean class is the mean class number (from 
1 to 5) weighted by the estimated probabilities. Therefore I tried:

library(plyr)

wine$fitted = fm22.clmm$fitted

ddply(wine, ~temp, summarise, sum(fitted*as.numeric(rating)) /sum(fitted))

   temp       ..1

1 cold 2.269931

2 warm 3.487144

There are some discrepancies with the results of lsmeans.

I got similar (small) discrepancies for other data and clmm models.

I certainly missed something, and I would really appreciate your help!

Best regards,

Robert


here is the sessionInfo:


sessionInfo()
R version 3.2.2 (2015-08-14)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1


attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods
[7] base

other attached packages:
[1] plyr_1.8.3         ordinal_2015.6-28  lsmeans_2.23
[4] estimability_1.1-1

loaded via a namespace (and not attached):
  [1] Rcpp_0.12.2      lattice_0.20-33  codetools_0.2-14
  [4] mvtnorm_1.0-5    zoo_1.7-13       ucminf_1.1-3
  [7] MASS_7.3-45      grid_3.2.2       xtable_1.8-2
[10] nlme_3.1-121     coda_0.18-1      multcomp_1.4-5
[13] Matrix_1.2-2     sandwich_2.3-4   splines_3.2.2
[16] TH.data_1.0-7    tools_3.2.2      survival_2.38-3




-- 
Robert Espesser
CNRS UMR  7309 - Universit? Aix-Marseille
5 Avenue Pasteur
13100 AIX-EN-PROVENCE

Tel: +33 (0)413 55 36 26


	[[alternative HTML version deleted]]


From highstat at highstat.com  Thu Jun 16 13:01:26 2016
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Thu, 16 Jun 2016 19:01:26 +0800
Subject: [R-sig-ME] Mixed modelling course in Sydney
Message-ID: <2496ba86-e70e-d538-34f8-78334a10c53a@highstat.com>

We would like to announce the following statistics course:

Course: Introduction to Linear Mixed Effects Models and GLMM with R. 
Frequentist and Bayesian approaches.
Where:  UNSW, Sydney, Australia
When:   18-22 July 2016

Course website: http://www.highstat.com/statscourse.htm
Course flyer: 
http://highstat.com/Courses/Flyers/Flyer2016_07Sydney_GLMM_V2.pdf


Kind regards,

Alain Zuur


-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email:highstat at highstat.com
URL:www.highstat.com


	[[alternative HTML version deleted]]


From russell-lenth at uiowa.edu  Thu Jun 16 18:56:48 2016
From: russell-lenth at uiowa.edu (Lenth, Russell V)
Date: Thu, 16 Jun 2016 16:56:48 +0000
Subject: [R-sig-ME] ordinal model and  lsmeans  mean class computing
Message-ID: <BY2PR0401MB0919E64CC7F4CD5FD7BA96C2F1560@BY2PR0401MB0919.namprd04.prod.outlook.com>

One way to answer this is to say that `lsmeans` does not use `fm22.clmm$fitted` to obtain its predictions. Instead, it uses the regression coefficients for the fixed-effects portion of the model, along with the model matrix for each combination of `temp` and `contact`, and then uses these to obtain predictions on the cumulative logit scale (along with an artificial factor, `cut`, for which intercept is being used).  These are then suitably back-transformed to obtain the mean class for each combination of `temp` and `contact`. The random effects of `judge` are not used at all by `lsmeans` (and in general, for any mixed model, `lsmeans` always uses only the fixed effects in calculating predictions). I suspect that the regression coefficients are obtained as some kind of average of those for the judges, and that this averaging takes place on the cumulative-logit scale -- whereas your averaging with `ddply` is being done on the back-transformed-cell-probability scale. There is a nonlinear relationship between these, so you can't expect to obtain the same results.

Here are some more details of the calculations:

R> # Obtain the reference grid upon which the lsmeans are based:
R> rg <- ref.grid(fm22.clmm, mode = "linear.predictor")
R> rg
'ref.grid' object with variables:
    temp = cold, warm
    contact = no, yes
    cut = multivariate response levels: 1|2, 2|3, 3|4, 4|5
Transformation: "logit"

R> # Here are the regression coefficients used:
R> rg at bhat
       1|2        2|3        3|4        4|5   tempwarm contactyes 
 -1.623667   1.513365   4.228527   6.088773   3.062997   1.834885 

R> # Here is the model matrix used for predictions
R> rg at linfct
      1|2 2|3 3|4 4|5 tempwarm contactyes
 [1,]   1   0   0   0        0          0
 [2,]   1   0   0   0       -1          0
 [3,]   1   0   0   0        0         -1
 [4,]   1   0   0   0       -1         -1
 [5,]   0   1   0   0        0          0
 [6,]   0   1   0   0       -1          0
 [7,]   0   1   0   0        0         -1
 [8,]   0   1   0   0       -1         -1
 [9,]   0   0   1   0        0          0
[10,]   0   0   1   0       -1          0
[11,]   0   0   1   0        0         -1
[12,]   0   0   1   0       -1         -1
[13,]   0   0   0   1        0          0
[14,]   0   0   0   1       -1          0
[15,]   0   0   0   1        0         -1
[16,]   0   0   0   1       -1         -1

The linear predictions are thus `rg at linfct %*% rg at bhat`, and these are on the logit scale. Back-transform them and you get cumulative probabilities; difference those results to get cell probabilities; and then use those to obtain mean class values.

I'm dismayed to see that warning message about `is.na`, and will try to track that down and fix it in the next update.

Russell V. Lenth  -  Professor Emeritus
Department of Statistics and Actuarial Science   
The University of Iowa  -  Iowa City, IA 52242  USA   
Voice (319)335-0712 (Dept. office)  -  FAX (319)335-3017



-----Original Message-----

Date: Wed, 15 Jun 2016 23:33:06 +0200
From: espesser <robert.espesser at lpl-aix.fr>
To: R-sig-mixed-models at r-project.org
Subject: [R-sig-ME] ordinal model and  lsmeans  mean class computing
Message-ID: <5761C992.3050707 at lpl-aix.fr>
Content-Type: text/plain; charset="UTF-8"

Dear All,

I tried to understand how the predicted mean class of an ordinal mixed model was computed in lsmeans().
(I want to compute mean classes from the fixed effects only; lsmeans included all the random terms)

# from the data wine, I estimated the model
library(ordinal)
  data(wine)
  fm22.clmm= clmm(rating~temp+contact +(1|judge),data=wine, Hess=T)
# get mean classes with lsmeans
lsmeans(fm22.clmm,   ~ temp, mode="mean.class")
  temp mean.class        SE df asymp.LCL asymp.UCL
  cold    2.339608 0.166799 NA   2.012688   2.666528
  warm    3.479936 0.201921 NA   3.084178   3.875694

Results are averaged over the levels of: contact
Confidence level used: 0.95
Warning message:
In is.na(x) : is.na() applied to non-(list or vector) of type 'NULL'

I supposed that the predicted mean class is the mean class number (from
1 to 5) weighted by the estimated probabilities. Therefore I tried:

library(plyr)
wine$fitted = fm22.clmm$fitted
ddply(wine, ~temp, summarise, sum(fitted*as.numeric(rating)) /sum(fitted))
   temp       ..1
1 cold 2.269931
2 warm 3.487144

There are some discrepancies with the results of lsmeans.
I got similar (small) discrepancies for other data and clmm models.

I certainly missed something, and I would really appreciate your help!

Best regards,

Robert


From lawrence-hunsicker at uiowa.edu  Sat Jun 18 00:40:24 2016
From: lawrence-hunsicker at uiowa.edu (Hunsicker, Lawrence)
Date: Fri, 17 Jun 2016 22:40:24 +0000
Subject: [R-sig-ME] Combination of glmnet-like covariate selection with
	mixed modeling
Message-ID: <E24DA3C6DF188F4B99D6999AC54C11EC4D38F635@HC-MAILBOXC1-N6.healthcare.uiowa.edu>

Greetings, listserv members:

I am involved in the analysis of factors predictive of whether a person that dies in a hospital becomes a transplant organ donor.  To do this analysis, with the help of the NCHS we have linked the list of all organ donors over a seven year period with information of all US deaths over this period obtained from death certificates.  As you might imagine, this is a rather "big data" analysis, with nearly 40,000 donors among about 2,500,000 deaths.

There is also a very large number of ICD-9 codes (and other information) listed in the death certificates.  We anticipate that we will need to reduce the dimensionality of the problem for it to become practical, let alone intelligible, and we are planning to use the grpreg (in R) package to do a two level selection of the most relevant covariates.  But our data also have a nested structure in terms of the US geographical areas of interest -- US counties within the designated service areas of the OPOs (organ procurement organization).   I am not aware of a package that deals simultaneously with covariate selection (a la glmnet or similar packages) and mixed modeling.  I am addressing this e-mail to you all as folks that are expert in the issue of mixed models.

I have read that in fitting a mixed model, one fits first the fixed effects, and then looks for additional explanatory structure among the random effects.  This has suggested to me that one could approach the above problem in a two step manner, first reducing the dimensionality of the problem and deriving coefficients from the glmnet-type analysis, and then doing a mixed model analysis on the residuals from the above.

So the basic question is whether something along the above lines makes sense.  I would deeply appreciate any suggestions or pointers to relevant literature that I could use to understand all this better.

Many thanks in advance for your help.

Larry Hunsicker
L. G. Hunsicker, M.D., Professor (Emeritus) of Internal Medicine
U. Iowa College of Medicine
319-621-3576 (Voice)
lawrence-hunsicker at uiowa.edu<mailto:lawrence-hunsicker at uiowa.edu>


________________________________
Notice: This UI Health Care e-mail (including attachments) is covered by the Electronic Communications Privacy Act, 18 U.S.C. 2510-2521 and is intended only for the use of the individual or entity to which it is addressed, and may contain information that is privileged, confidential, and exempt from disclosure under applicable law. If you are not the intended recipient, any dissemination, distribution or copying of this communication is strictly prohibited. If you have received this communication in error, please notify the sender immediately and delete or destroy all copies of the original message and attachments thereto. Email sent to or from UI Health Care may be retained as required by law or regulation. Thank you.
________________________________

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Sat Jun 18 03:14:30 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 17 Jun 2016 21:14:30 -0400
Subject: [R-sig-ME] Combination of glmnet-like covariate selection with
 mixed modeling
In-Reply-To: <E24DA3C6DF188F4B99D6999AC54C11EC4D38F635@HC-MAILBOXC1-N6.healthcare.uiowa.edu>
References: <E24DA3C6DF188F4B99D6999AC54C11EC4D38F635@HC-MAILBOXC1-N6.healthcare.uiowa.edu>
Message-ID: <5764A076.4040007@gmail.com>


  Maybe check out the glmmLasso package?

On 16-06-17 06:40 PM, Hunsicker, Lawrence wrote:
> Greetings, listserv members:
> 
> I am involved in the analysis of factors predictive of whether a
> person that dies in a hospital becomes a transplant organ donor.  To
> do this analysis, with the help of the NCHS we have linked the list
> of all organ donors over a seven year period with information of all
> US deaths over this period obtained from death certificates.  As you
> might imagine, this is a rather "big data" analysis, with nearly
> 40,000 donors among about 2,500,000 deaths.
> 
> There is also a very large number of ICD-9 codes (and other
> information) listed in the death certificates.  We anticipate that we
> will need to reduce the dimensionality of the problem for it to
> become practical, let alone intelligible, and we are planning to use
> the grpreg (in R) package to do a two level selection of the most
> relevant covariates.  But our data also have a nested structure in
> terms of the US geographical areas of interest -- US counties within
> the designated service areas of the OPOs (organ procurement
> organization).   I am not aware of a package that deals
> simultaneously with covariate selection (a la glmnet or similar
> packages) and mixed modeling.  I am addressing this e-mail to you all
> as folks that are expert in the issue of mixed models.
> 
> I have read that in fitting a mixed model, one fits first the fixed
> effects, and then looks for additional explanatory structure among
> the random effects.  This has suggested to me that one could approach
> the above problem in a two step manner, first reducing the
> dimensionality of the problem and deriving coefficients from the
> glmnet-type analysis, and then doing a mixed model analysis on the
> residuals from the above.
> 
> So the basic question is whether something along the above lines
> makes sense.  I would deeply appreciate any suggestions or pointers
> to relevant literature that I could use to understand all this
> better.
> 
> Many thanks in advance for your help.
> 
> Larry Hunsicker L. G. Hunsicker, M.D., Professor (Emeritus) of
> Internal Medicine U. Iowa College of Medicine 319-621-3576 (Voice) 
> lawrence-hunsicker at uiowa.edu<mailto:lawrence-hunsicker at uiowa.edu>
>


From davef at otter-rsch.com  Fri Jun 17 18:32:48 2016
From: davef at otter-rsch.com (dave fournier)
Date: Fri, 17 Jun 2016 09:32:48 -0700
Subject: [R-sig-ME] glmmADMB fails to fit poisson data
In-Reply-To: <5760169D.7000904@gmail.com>
References: <5760169D.7000904@gmail.com>
Message-ID: <57642630.1050403@otter-rsch.com>

>    Thanks Dave. Would you suggest replacing the previous Poisson code
> entirely?  (That seems sensible; unfortunately I don't think we have the
> test data for the previous [May 2013] example lying around ... )
>
>     Ben
>
>     case 0:   // Poisson
> 	if (poiss_prob_bound==0) {
> 	    tmpl =  log_density_poisson(y(_i,1),lambda);
> 	} else {
>            if (cph<5)
> 	    tmpl = log(e3+exp(log_density_poisson(y(_i,1),lambda)));
>            else
> 	    tmpl = log(e4+exp(log_density_poisson(y(_i,1),lambda)));
> 	}
>        break;
>
> On 16-06-11 10:38 AM, dave fournier wrote:
> >/case 0: // Poisson />/if (cph<2) />/tmpl=-square(log(1.0+y(_i,1))-log(1.0+lambda)); />/else />/tmpl= log_density_poisson(y(_i,1),lambda); />/break;/
I would use

                   tmpl=-square(log(1.0+y(_i,1))-log(1.0+lambda));

for all cases in phase 1 of the minimization.  This provides  decent 
initial values for
the poisson_density.  However replacling

             tmpl =  log_density_poisson(y(_i,1),lambda);

with something like

     tmpl = log(e3+exp(log_density_poisson(y(_i,1),lambda)));

in some of the higher phase also serves another purpose.  Even when a 
lot of the
observations fit the model well there may be some outliers which can 
make the
arithmetic for calculating the mode of the random effects unstable for 
particular
values of the other model parameters picked by the optimization routine. 
The modification
tends to make the calculations more stable.  This was kind of a "quick 
fix"  when the code
was initially being developed. I'm sure it could be improved.






	[[alternative HTML version deleted]]


From sara.fraixedas at helsinki.fi  Sat Jun 18 17:30:24 2016
From: sara.fraixedas at helsinki.fi (Fraixedas, Sara)
Date: Sat, 18 Jun 2016 15:30:24 +0000
Subject: [R-sig-ME] Residual variance random effect GLMM
Message-ID: <AM4PR07MB1555266ECA4DAC61FFF0122B94280@AM4PR07MB1555.eurprd07.prod.outlook.com>

Dear all,

I want to calculate the percentage variance explained by a random effect in a GLMM fitted using the "glmmADMB" package. For that I would need to know what is the residual variance but it is not given in "VarCorr.glmmadmb" or in the summary output command.

How can I extract the residual variance from a random effect in this particular case?

Thank you in advance,


Sara Fraixedas
Doctoral Student
The Helsinki Lab of Ornithology (HelLO) Finnish Museum of Natural
History P.O. Box 17
00014 University of Helsinki, Finland
Tel. +358-9-19128851

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Jun 20 09:50:59 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 20 Jun 2016 09:50:59 +0200
Subject: [R-sig-ME] Residual variance random effect GLMM
In-Reply-To: <AM4PR07MB1555266ECA4DAC61FFF0122B94280@AM4PR07MB1555.eurprd07.prod.outlook.com>
References: <AM4PR07MB1555266ECA4DAC61FFF0122B94280@AM4PR07MB1555.eurprd07.prod.outlook.com>
Message-ID: <CAJuCY5wCY635q-XrQQwcoKsY8jx1YMRZ2a5DKjuRY=_5mjG2ew@mail.gmail.com>

Dear Sara,

Unlike a linear model, generalised linear models don't have a residual
variance. A linear model assumes a Gaussian distribution with two
parameters: mean and standard error which are independent. Generalised
linear models use distributions how dependent on only one parameter
(binomial, Poisson). Mean and variance of those distributions are defined
by the same parameter. In case a generalised linear model uses a two
parameter distribution (e.g. negative binomial), still the mean and
variance are influenced by a common parameter (mean = mu, var = mu + mu ^ 2
/theta).

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-06-18 17:30 GMT+02:00 Fraixedas, Sara <sara.fraixedas at helsinki.fi>:

> Dear all,
>
> I want to calculate the percentage variance explained by a random effect
> in a GLMM fitted using the "glmmADMB" package. For that I would need to
> know what is the residual variance but it is not given in
> "VarCorr.glmmadmb" or in the summary output command.
>
> How can I extract the residual variance from a random effect in this
> particular case?
>
> Thank you in advance,
>
>
> Sara Fraixedas
> Doctoral Student
> The Helsinki Lab of Ornithology (HelLO) Finnish Museum of Natural
> History P.O. Box 17
> 00014 University of Helsinki, Finland
> Tel. +358-9-19128851
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From y.shinohara at aoni.waseda.jp  Mon Jun 20 10:40:59 2016
From: y.shinohara at aoni.waseda.jp (Yasuaki SHINOHARA)
Date: Mon, 20 Jun 2016 17:40:59 +0900
Subject: [R-sig-ME] Orthogonal vs. Non-orthogonal contrasts
In-Reply-To: <CAJuCY5xAhBfQKrsK+ivQkCTTmPd=1kvSDYWDh_YZP4kekkUZ2g@mail.gmail.com>
References: <web-69184710@besv02.spw.secure-premium.ne.jp>
	<CAJuCY5zeexeXpPSto7hg=QAA-yGJ+rkE0PRqhaR=gJQjGLaFSg@mail.gmail.com>
	<web-69429660@besv04.spw.secure-premium.ne.jp>
	<CAJuCY5wT0XwAeD9q5Uq6Dk+K_PdhrXNDJfni9-86F4r5wGKYoQ@mail.gmail.com>
	<web-69842955@besv03.spw.secure-premium.ne.jp>
	<CAJuCY5xAhBfQKrsK+ivQkCTTmPd=1kvSDYWDh_YZP4kekkUZ2g@mail.gmail.com>
Message-ID: <web-70540620@besv04.spw.secure-premium.ne.jp>

Dear Thierry,

Thank you very much for your help.
I understand the advantages of multcomp!

Sorry for this late reply.
Thank you, again.

Best wishes,
Yasu

On Mon, 30 May 2016 09:47:06 +0200
  Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
> Dear Yasu,
> 
> I see two advantages of multcomp:
> 
> 1) It can work with any parametrisation. So it doesn't matter 
>whether you
> use dummy encoding or some kind of contrast. Hence you can do any 
>post-hoc
> test without having to refit the model. Note that the specification 
>of the
> contrast will depend on the parametrisation. I find dummy encoding 
>easier
> to generate post-hoc contrasts.
> 
> 2) It corrects for multiple testing.
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for 
>Nature and
>Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality 
>Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no 
>more
> than asking him to perform a post-mortem examination: he may be able 
>to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does 
>not
> ensure that a reasonable answer can be extracted from a given body 
>of data.
> ~ John Tukey
> 
> 2016-05-30 9:30 GMT+02:00 Yasuaki SHINOHARA 
><y.shinohara at aoni.waseda.jp>:
> 
>> Dear Thierry,
>>
>> Thank you very much for your reply.
>>
>> I understood that the results of each main fixed factor (e.g., 
>>Factor A,
>> B, C and D) are pointless, since the interaction factors affected 
>>the
>> results of the main fixed factors. Actually, I manually coded the 
>>contrasts
>> for all the fixed factors based on the hypothesis I wanted to test, 
>>as
>> follows.
>>
>> #Factor A (testing block)
>> PreVsMid<-c(1,-1,0)
>> PreVsPost<-c(-1,0,1)
>> contrasts(alldata$FactorA)<-cbind(PreVsMid,PreVsPost)
>> #Factor B (Trainer order)
>> IDVsDIS<-c(1,-1)
>> contrasts(alldata$FactorB)<-cbind(IDVsDIS)
>> #Factor C (Phonetic environment)
>> IniVsMid<-c(1,-1,0)
>> IniVsCls<-c(-1,0,1)
>> contrasts(alldata$FactorC)<-cbind(IniVsMid, IniVsCls)
>> #Factor D (Length of Experience, continuous variable)
>> alldata$FactorD<-as.numeric(alldata$FactorD)
>>
>> What I really wanted to test is the interaction between Factor A and
>> Factor B. Factor A has the two contrasts (i.e., PreVsMid (1,-1,0),
>> PreVsPost(-1,0,1)), and Factor B has only one contrast (i.e., 
>>IDvsDIS
>> (-1,1)) since there are only two levels in the Factor B. I tested 
>>whether
>> there is a significant difference in the contrast of PreVsMid 
>>between the
>> two levels of Factor B (IDvsDIS). Therefore, I did not use the dummy
>> (simple effect) coding but used the effect coding.
>>
>> As you suggested, I tried to figure out how to use the multcomp 
>>package. I
>> found that the glht function in the packages allows me to test a 
>>variety of
>> contrasts with a matrix. However, I felt that the contrasts I coded 
>>above
>> are maybe enough to test my hypothesis, and I am wondering whether I 
>>should
>> use the glht function for the contrasts.
>>
>> Could you please let me know if there are any advantage of using the 
>>glht
>> function?
>>
>> I really appreciate your help.
>>
>> Best wishes,
>> Yasu
>>
>>
>> On Thu, 26 May 2016 08:53:44 +0200
>>
>>  Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
>>
>>> Dear Yasu,
>>>
>>> The contrast x = c(1, -1, 0) is equivalent to beta_x * 1 * a_1 + 
>>>beta_x *
>>> (-1) * a_2 + beta_x * 0 * a_3.
>>> Likewise contrast y = c(.5, -.5, 0) is equivalent to beta_y * 0.5 * 
>>>a_1 +
>>> beta_y * (-0.5) * a_2 + beta_y * 0 * a_3.
>>>
>>> Since both model the same thing beta_x * 1 * a_1 + beta_x * (-1) * 
>>>a_2 +
>>> beta_x * 0 * a_3 = beta_y * 0.5 * a_1 + beta_y * (-0.5) * a_2 + 
>>>beta_y * 0
>>> * a_3.
>>> Some simple math will show that beta_x = 2 * beta_y
>>>
>>> Your contrasts are correct but pointless given your model. They are 
>>>only
>>> meaningful in case FactorA is only a main effect. You included 
>>>FactorA in
>>> some interactions as well. So you'll need to define contrasts on the 
>>>full
>>> set of fixed parameters to get some sensible results. You can do 
>>>that with
>>> the multcomp package. I would also suggest that you find some local
>>> statistician to help you define the contrasts relevant for your 
>>>model.
>>>
>>> Best regards,
>>>
>>>
>>> ir. Thierry Onkelinx
>>> Instituut voor natuur- en bosonderzoek / Research Institute for 
>>>Nature and
>>> Forest
>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality 
>>>Assurance
>>> Kliniekstraat 25
>>> 1070 Anderlecht
>>> Belgium
>>>
>>> To call in the statistician after the experiment is done may be no 
>>>more
>>> than asking him to perform a post-mortem examination: he may be able 
>>>to
>>> say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does 
>>>not
>>> ensure that a reasonable answer can be extracted from a given body 
>>>of
>>> data.
>>> ~ John Tukey
>>>
>>> 2016-05-26 6:31 GMT+02:00 Yasuaki SHINOHARA 
>>><y.shinohara at aoni.waseda.jp>:
>>>
>>> Dear Thierry,
>>>>
>>>> Thank you very much for your reply.
>>>> I understood why. The interaction of blockPreVsMid:FactorD turned
>>>> significant in the model which contrasted the testing block factor 
>>>>as
>>>> PreVsMid and PreVsPost (i.e.,cbind(c(1,-1,0),c(-1,0,1))), although 
>>>>the
>>>> interaction was not significant in the model with the testing block
>>>> contrasted as PreVsMid and PreMidVsPost (i.e.,
>>>> cbind(c(1,-1,0),c(1,1,-2))).
>>>>
>>>> Could I ask another question?
>>>> What is the difference in making a contrast of PreVsMid as c(1,-1,0) 
>>>>and
>>>> as c(0.5, -0.5, 0)?
>>>> It seems that the beta and SE are double if I code the contrasts 
>>>>with
>>>> (0.5, -0.5, 0). I hope it does not matter.
>>>>
>>>> Also, I coded "contrasts(data$FactorA)<-cbind(c(1,-1,0),c(-1,0,1))" 
>>>>to
>>>> test the differences between the mean of level 1 vs. the mean of 
>>>>level 2
>>>> and between the mean of level 1 and the mean of level 3. Is this 
>>>>correct?
>>>> Some website says something different from what I understood (e.g., 
>>>>the
>>>> first Answer of
>>>>
>>>> http://stats.stackexchange.com/questions/44527/contrast-for-hypothesis-test-in-r-lmer
>>>> ).
>>>>
>>>> My model includes both categorical and numeric variable, and all
>>>> categorical variables were coded manually.
>>>>
>>>> Best wishes,
>>>> Yasu
>>>>
>>>>
>>>> On Wed, 25 May 2016 09:44:14 +0200
>>>>  Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
>>>>
>>>> Dear Yasu,
>>>>>
>>>>> A is part of two interactions. Hence you cannot interpret this main
>>>>> effect
>>>>> without the interactions. Note that changing the contrast will also
>>>>> effect
>>>>> the interactions.
>>>>>
>>>>> Best regards,
>>>>>
>>>>> ir. Thierry Onkelinx
>>>>> Instituut voor natuur- en bosonderzoek / Research Institute for 
>>>>>Nature
>>>>> and
>>>>> Forest
>>>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality 
>>>>>Assurance
>>>>> Kliniekstraat 25
>>>>> 1070 Anderlecht
>>>>> Belgium
>>>>>
>>>>> To call in the statistician after the experiment is done may be no 
>>>>>more
>>>>> than asking him to perform a post-mortem examination: he may be able 
>>>>>to
>>>>> say
>>>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>>> The combination of some data and an aching desire for an answer does 
>>>>>not
>>>>> ensure that a reasonable answer can be extracted from a given body 
>>>>>of
>>>>> data.
>>>>> ~ John Tukey
>>>>>
>>>>> 2016-05-25 4:42 GMT+02:00 Yasuaki SHINOHARA 
>>>>><y.shinohara at aoni.waseda.jp
>>>>> >:
>>>>>
>>>>> Dear all,
>>>>>
>>>>>>
>>>>>> Hello, I am doing research of second language acquisition.
>>>>>> I am wondering about the glmer in R for my analyses. Could you 
>>>>>>please
>>>>>> answer my question?
>>>>>>
>>>>>> I have the following logistic mixed effects model.
>>>>>> model<-glmer(corr ~ A + B + C + D + A:B + B:C + A:D +(1+A|subject) +
>>>>>>
>>>>>>
>>>>>> (1+A|item:speaker),family=binomial,data=mydata,control=glmerControl(optimizer="bobyqa",
>>>>>> optCtrl=list(maxfun=1000)))
>>>>>>
>>>>>> I tested language learners (subjects) three time (pre-training,
>>>>>> mid-training, post-training) with the "item" produced by "speaker", 
>>>>>>so
>>>>>> Factor A is "testing block" which has three levels (i.e., pre, mid,
>>>>>> post).
>>>>>> Since each subject took the test three times, the random slopes for 
>>>>>>the
>>>>>> Factor A were also included as a random factor.
>>>>>>
>>>>>> I made an orthogonal contrast for the Factor A (testing block) as
>>>>>> follows.
>>>>>> PreVsMid<-c(1,-1,0)
>>>>>> PreMidVsPost<-c(1,1,-2)
>>>>>> contrasts(mydata$A)<-cbind(PreVsMid,PreMidVsPost)
>>>>>>
>>>>>> The results from summary(model) function for this factor were as
>>>>>> follows.
>>>>>> pre vs. mid test: ? = 0.22, SE = 0.05, z = 4.34, p < 0.001
>>>>>> pre & mid vs. post test: ? = -0.21, SE = 0.04, z = -5.96, p < 0.001.
>>>>>>
>>>>>> However, I thought it would be better if I made a non-orthogonal
>>>>>> contrast
>>>>>> for this factor as "pre vs. mid" and "pre vs. post" to test my
>>>>>> hypothesis.
>>>>>> So I made a new contrast for the Factor A as follows.
>>>>>> PreVsMid<-c(1,-1,0)
>>>>>> PreVsPost<-c(1,0,-1)
>>>>>> contrasts(mydata$A)<-cbind(PreVsMid,PreVsPost)
>>>>>>
>>>>>> The results from summary(model) function for this contrast were
>>>>>> pre vs. mid test: ? = -0.01, SE = 0.04, z = -0.14, p > 0.05 (=0.89),
>>>>>> pre vs. post test: ? = 0.42, SE = 0.07, z = 5.96, p < 0.001.
>>>>>>
>>>>>> Although the first contrast (pre vs. mid) is the same for both 
>>>>>>models,
>>>>>> why
>>>>>> the results of pre vs. mid contrast are so different (one is very
>>>>>> significant, but the other one is not significant)?
>>>>>>
>>>>>> I really appreciate any help.
>>>>>>
>>>>>> Best wishes,
>>>>>> Yasu
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>
>>>>>>
>>>>>>


From sara.fraixedas at helsinki.fi  Mon Jun 20 19:14:39 2016
From: sara.fraixedas at helsinki.fi (Fraixedas, Sara)
Date: Mon, 20 Jun 2016 17:14:39 +0000
Subject: [R-sig-ME] Residual variance random effect GLMM
In-Reply-To: <CAJuCY5wCY635q-XrQQwcoKsY8jx1YMRZ2a5DKjuRY=_5mjG2ew@mail.gmail.com>
References: <AM4PR07MB1555266ECA4DAC61FFF0122B94280@AM4PR07MB1555.eurprd07.prod.outlook.com>,
	<CAJuCY5wCY635q-XrQQwcoKsY8jx1YMRZ2a5DKjuRY=_5mjG2ew@mail.gmail.com>
Message-ID: <DB5PR07MB15579FA1407695F30E8C6007942A0@DB5PR07MB1557.eurprd07.prod.outlook.com>

Dear Thierry,

Many thanks for your reply. You are totally right (I should have checked my notes more carefully before posting this question...).

Thanks for the clarification!


Sara Fraixedas
Doctoral Student
The Helsinki Lab of Ornithology (HelLO) Finnish Museum of Natural
History P.O. Box 17
00014 University of Helsinki, Finland
Tel. +358-9-19128851

________________________________
From: Thierry Onkelinx <thierry.onkelinx at inbo.be>
Sent: 20 June 2016 09:50:59
To: Fraixedas, Sara
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Residual variance random effect GLMM

Dear Sara,

Unlike a linear model, generalised linear models don't have a residual variance. A linear model assumes a Gaussian distribution with two parameters: mean and standard error which are independent. Generalised linear models use distributions how dependent on only one parameter (binomial, Poisson). Mean and variance of those distributions are defined by the same parameter. In case a generalised linear model uses a two parameter distribution (e.g. negative binomial), still the mean and variance are influenced by a common parameter (mean = mu, var = mu + mu ^ 2 /theta).

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey

2016-06-18 17:30 GMT+02:00 Fraixedas, Sara <sara.fraixedas at helsinki.fi<mailto:sara.fraixedas at helsinki.fi>>:
Dear all,

I want to calculate the percentage variance explained by a random effect in a GLMM fitted using the "glmmADMB" package. For that I would need to know what is the residual variance but it is not given in "VarCorr.glmmadmb" or in the summary output command.

How can I extract the residual variance from a random effect in this particular case?

Thank you in advance,


Sara Fraixedas
Doctoral Student
The Helsinki Lab of Ornithology (HelLO) Finnish Museum of Natural
History P.O. Box 17
00014 University of Helsinki, Finland
Tel. +358-9-19128851<tel:%2B358-9-19128851>

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Jun 21 18:26:52 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 21 Jun 2016 12:26:52 -0400
Subject: [R-sig-ME] Residual variance random effect GLMM
In-Reply-To: <CAJuCY5wCY635q-XrQQwcoKsY8jx1YMRZ2a5DKjuRY=_5mjG2ew@mail.gmail.com>
References: <AM4PR07MB1555266ECA4DAC61FFF0122B94280@AM4PR07MB1555.eurprd07.prod.outlook.com>
	<CAJuCY5wCY635q-XrQQwcoKsY8jx1YMRZ2a5DKjuRY=_5mjG2ew@mail.gmail.com>
Message-ID: <57696ACC.2000202@gmail.com>


  I'll second Thierry's comments, but also point out that there are some
recipes for generalizing the idea of "variance explained": see papers by
Nakagawa and Schielzeth or

https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.html#how-do-i-compute-a-coefficient-of-determination-r2-or-an-analogue-for-glmms

  I've now created a tinyURL link for the GLMM FAQ:
http://tinyurl.com/glmmFAQ .  Comments, pull requests, etc. welcome!

   cheers
     Ben Bolker


On 16-06-20 03:50 AM, Thierry Onkelinx wrote:
> Dear Sara,
> 
> Unlike a linear model, generalised linear models don't have a residual
> variance. A linear model assumes a Gaussian distribution with two
> parameters: mean and standard error which are independent. Generalised
> linear models use distributions how dependent on only one parameter
> (binomial, Poisson). Mean and variance of those distributions are defined
> by the same parameter. In case a generalised linear model uses a two
> parameter distribution (e.g. negative binomial), still the mean and
> variance are influenced by a common parameter (mean = mu, var = mu + mu ^ 2
> /theta).
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> 
> 2016-06-18 17:30 GMT+02:00 Fraixedas, Sara <sara.fraixedas at helsinki.fi>:
> 
>> Dear all,
>>
>> I want to calculate the percentage variance explained by a random effect
>> in a GLMM fitted using the "glmmADMB" package. For that I would need to
>> know what is the residual variance but it is not given in
>> "VarCorr.glmmadmb" or in the summary output command.
>>
>> How can I extract the residual variance from a random effect in this
>> particular case?
>>
>> Thank you in advance,
>>
>>
>> Sara Fraixedas
>> Doctoral Student
>> The Helsinki Lab of Ornithology (HelLO) Finnish Museum of Natural
>> History P.O. Box 17
>> 00014 University of Helsinki, Finland
>> Tel. +358-9-19128851
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From r_1470 at yahoo.co.uk  Wed Jun 22 13:34:29 2016
From: r_1470 at yahoo.co.uk (r_1470)
Date: Wed, 22 Jun 2016 11:34:29 +0000 (UTC)
Subject: [R-sig-ME] How to fix individual elements of the residual
 covariance matrix in MCMCglmm
References: <1513886953.12791292.1466595269804.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1513886953.12791292.1466595269804.JavaMail.yahoo@mail.yahoo.com>

Hello list,
I am using the MCMCglmm package in R for mixed-model multi-response regression, and I am trying to fix individual elements of the residual covariance matrix (when using rcov = ~ us(trait):units). I thought it might be possible using the 'fix' argument in the prior, but it seems that this either fixes the whole residual matrix to the prior specification, or allows all elements to be estimated. This fixes the whole residual matrix:
prior <- list(R = list(V = diag(5), n = 6, fix = 1), G = list( G1 = list(V = diag(5), n = 6)))
I believe 'fix = 0' would have the same effect as not specifying 'fix' (i.e. the whole matrix is estimated).
Is there a way to fix individual elements (e.g. I may want to fix the covariance between two of my five response variables to a specific value)
Thanks,
Richard.
	[[alternative HTML version deleted]]


From killver at gmail.com  Thu Jun 23 10:07:32 2016
From: killver at gmail.com (Philipp Singer)
Date: Thu, 23 Jun 2016 10:07:32 +0200
Subject: [R-sig-ME] Question about zero-inflated Poisson glmer
Message-ID: <576B98C4.6000602@gmail.com>

Dear group - I am currently fitting a Poisson glmer where I have an 
excess of outcomes that are zero (>95%). I am now debating on how to 
proceed and came up with three options:

1.) Just fit a regular glmer to the complete data. I am not fully sure 
how interpret the coefficients then, are they more optimizing towards 
distinguishing zero and non-zero, or also capturing the differences in 
those outcomes that are non-zero?

2.) Leave all zeros out of the data and fit a glmer to only those 
outcomes that are non-zero. Then, I would only learn about differences 
in the non-zero outcomes though.

3.) Use a zero-inflated Poisson model. My data is quite large-scale, so 
I am currently playing around with the EM implementation of Bolker et 
al. that alternates between fitting a glmer with data that are weighted 
according to their zero probability, and fitting a logistic regression 
for the probability that a data point is zero. The method is elaborated 
for the OWL data in: 
https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf

I am not fully sure how to interpret the results for the zero-inflated 
version though. Would I need to interpret the coefficients for the 
result of the glmer similar to as I would do for my idea of 2)? And then 
on top of that interpret the coefficients for the logistic regression 
regarding whether something is in the perfect or imperfect state? I am 
also not quite sure what the common approach for the zformula is here. 
The OWL elaborations only use zformula=z~1, so no random effect; I would 
use the same formula as for the glmer.

I am appreciating some help and pointers.

Thanks!
Philipp


From thierry.onkelinx at inbo.be  Thu Jun 23 11:04:45 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 23 Jun 2016 11:04:45 +0200
Subject: [R-sig-ME] Question about zero-inflated Poisson glmer
In-Reply-To: <576B98C4.6000602@gmail.com>
References: <576B98C4.6000602@gmail.com>
Message-ID: <CAJuCY5xbiEjCmHjc_3wX2emzJ3NEMTA_qKgC_reWn=zqC7YEng@mail.gmail.com>

Dear Philipp,

Do you have just lots of zero's, or more zero's than the Poisson
distribution can explain? Those are two different things. The example below
generates data from a Poisson distribution and has 99% zero's but no
zero-inflation. The second example has only 1% zero's but is clearly
zero-inflated.

set.seed(1)
n <- 1e8
sim <- rpois(n, lambda = 0.01)
mean(sim == 0)
hist(sim)

sim.infl <- rbinom(n, size = 1, prob = 0.99) * rpois(n, lambda = 1000)
mean(sim.infl == 0)
hist(sim.infl)

So before looking for zero-inflated models, try to model the zero's.

Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-06-23 10:07 GMT+02:00 Philipp Singer <killver at gmail.com>:

> Dear group - I am currently fitting a Poisson glmer where I have an excess
> of outcomes that are zero (>95%). I am now debating on how to proceed and
> came up with three options:
>
> 1.) Just fit a regular glmer to the complete data. I am not fully sure how
> interpret the coefficients then, are they more optimizing towards
> distinguishing zero and non-zero, or also capturing the differences in
> those outcomes that are non-zero?
>
> 2.) Leave all zeros out of the data and fit a glmer to only those outcomes
> that are non-zero. Then, I would only learn about differences in the
> non-zero outcomes though.
>
> 3.) Use a zero-inflated Poisson model. My data is quite large-scale, so I
> am currently playing around with the EM implementation of Bolker et al.
> that alternates between fitting a glmer with data that are weighted
> according to their zero probability, and fitting a logistic regression for
> the probability that a data point is zero. The method is elaborated for the
> OWL data in:
> https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
>
> I am not fully sure how to interpret the results for the zero-inflated
> version though. Would I need to interpret the coefficients for the result
> of the glmer similar to as I would do for my idea of 2)? And then on top of
> that interpret the coefficients for the logistic regression regarding
> whether something is in the perfect or imperfect state? I am also not quite
> sure what the common approach for the zformula is here. The OWL
> elaborations only use zformula=z~1, so no random effect; I would use the
> same formula as for the glmer.
>
> I am appreciating some help and pointers.
>
> Thanks!
> Philipp
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From killver at gmail.com  Thu Jun 23 11:27:32 2016
From: killver at gmail.com (Philipp Singer)
Date: Thu, 23 Jun 2016 11:27:32 +0200
Subject: [R-sig-ME] Question about zero-inflated Poisson glmer
In-Reply-To: <CAJuCY5xbiEjCmHjc_3wX2emzJ3NEMTA_qKgC_reWn=zqC7YEng@mail.gmail.com>
References: <576B98C4.6000602@gmail.com>
	<CAJuCY5xbiEjCmHjc_3wX2emzJ3NEMTA_qKgC_reWn=zqC7YEng@mail.gmail.com>
Message-ID: <576BAB84.6080009@gmail.com>

Thanks Thierry - That totally makes sense. Is there some way of formally 
checking that, except thinking about the setting and underlying processes?

On 23.06.2016 11:04, Thierry Onkelinx wrote:
> Dear Philipp,
>
> Do you have just lots of zero's, or more zero's than the Poisson 
> distribution can explain? Those are two different things. The example 
> below generates data from a Poisson distribution and has 99% zero's 
> but no zero-inflation. The second example has only 1% zero's but is 
> clearly zero-inflated.
>
> set.seed(1)
> n <- 1e8
> sim <- rpois(n, lambda = 0.01)
> mean(sim == 0)
> hist(sim)
>
> sim.infl <- rbinom(n, size = 1, prob = 0.99) * rpois(n, lambda = 1000)
> mean(sim.infl == 0)
> hist(sim.infl)
>
> So before looking for zero-inflated models, try to model the zero's.
>
> Best regards,
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature 
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no 
> more than asking him to perform a post-mortem examination: he may be 
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does 
> not ensure that a reasonable answer can be extracted from a given body 
> of data. ~ John Tukey
>
> 2016-06-23 10:07 GMT+02:00 Philipp Singer <killver at gmail.com 
> <mailto:killver at gmail.com>>:
>
>     Dear group - I am currently fitting a Poisson glmer where I have
>     an excess of outcomes that are zero (>95%). I am now debating on
>     how to proceed and came up with three options:
>
>     1.) Just fit a regular glmer to the complete data. I am not fully
>     sure how interpret the coefficients then, are they more optimizing
>     towards distinguishing zero and non-zero, or also capturing the
>     differences in those outcomes that are non-zero?
>
>     2.) Leave all zeros out of the data and fit a glmer to only those
>     outcomes that are non-zero. Then, I would only learn about
>     differences in the non-zero outcomes though.
>
>     3.) Use a zero-inflated Poisson model. My data is quite
>     large-scale, so I am currently playing around with the EM
>     implementation of Bolker et al. that alternates between fitting a
>     glmer with data that are weighted according to their zero
>     probability, and fitting a logistic regression for the probability
>     that a data point is zero. The method is elaborated for the OWL
>     data in:
>     https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
>
>     I am not fully sure how to interpret the results for the
>     zero-inflated version though. Would I need to interpret the
>     coefficients for the result of the glmer similar to as I would do
>     for my idea of 2)? And then on top of that interpret the
>     coefficients for the logistic regression regarding whether
>     something is in the perfect or imperfect state? I am also not
>     quite sure what the common approach for the zformula is here. The
>     OWL elaborations only use zformula=z~1, so no random effect; I
>     would use the same formula as for the glmer.
>
>     I am appreciating some help and pointers.
>
>     Thanks!
>     Philipp
>
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Thu Jun 23 11:50:11 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 23 Jun 2016 11:50:11 +0200
Subject: [R-sig-ME] Question about zero-inflated Poisson glmer
In-Reply-To: <576BAB84.6080009@gmail.com>
References: <576B98C4.6000602@gmail.com>
	<CAJuCY5xbiEjCmHjc_3wX2emzJ3NEMTA_qKgC_reWn=zqC7YEng@mail.gmail.com>
	<576BAB84.6080009@gmail.com>
Message-ID: <CAJuCY5zmK1xCyWOwcCH+Hch_LSdB+AazmUDuPVP6je7ABFU5FA@mail.gmail.com>

Dear Philipp,

1. Fit a Poisson model to the data.
2. Simulate a new response vector for the dataset according to the model.
3. Count the number of zero's in the simulated response vector.
4. Repeat step 2 and 3 a decent number of time and plot a histogram of the
number of zero's in the simulation. If the number of zero's in the original
dataset is larger than those in the simulations, then the model can't
capture all zero's. In such case, first try to update the model and repeat
the procedure. If that fails, look for zero-inflated models.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-06-23 11:27 GMT+02:00 Philipp Singer <killver at gmail.com>:

> Thanks Thierry - That totally makes sense. Is there some way of formally
> checking that, except thinking about the setting and underlying processes?
>
> On 23.06.2016 11:04, Thierry Onkelinx wrote:
> > Dear Philipp,
> >
> > Do you have just lots of zero's, or more zero's than the Poisson
> > distribution can explain? Those are two different things. The example
> > below generates data from a Poisson distribution and has 99% zero's
> > but no zero-inflation. The second example has only 1% zero's but is
> > clearly zero-inflated.
> >
> > set.seed(1)
> > n <- 1e8
> > sim <- rpois(n, lambda = 0.01)
> > mean(sim == 0)
> > hist(sim)
> >
> > sim.infl <- rbinom(n, size = 1, prob = 0.99) * rpois(n, lambda = 1000)
> > mean(sim.infl == 0)
> > hist(sim.infl)
> >
> > So before looking for zero-inflated models, try to model the zero's.
> >
> > Best regards,
> >
> >
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> > and Forest
> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> > Kliniekstraat 25
> > 1070 Anderlecht
> > Belgium
> >
> > To call in the statistician after the experiment is done may be no
> > more than asking him to perform a post-mortem examination: he may be
> > able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does
> > not ensure that a reasonable answer can be extracted from a given body
> > of data. ~ John Tukey
> >
> > 2016-06-23 10:07 GMT+02:00 Philipp Singer <killver at gmail.com
> > <mailto:killver at gmail.com>>:
> >
> >     Dear group - I am currently fitting a Poisson glmer where I have
> >     an excess of outcomes that are zero (>95%). I am now debating on
> >     how to proceed and came up with three options:
> >
> >     1.) Just fit a regular glmer to the complete data. I am not fully
> >     sure how interpret the coefficients then, are they more optimizing
> >     towards distinguishing zero and non-zero, or also capturing the
> >     differences in those outcomes that are non-zero?
> >
> >     2.) Leave all zeros out of the data and fit a glmer to only those
> >     outcomes that are non-zero. Then, I would only learn about
> >     differences in the non-zero outcomes though.
> >
> >     3.) Use a zero-inflated Poisson model. My data is quite
> >     large-scale, so I am currently playing around with the EM
> >     implementation of Bolker et al. that alternates between fitting a
> >     glmer with data that are weighted according to their zero
> >     probability, and fitting a logistic regression for the probability
> >     that a data point is zero. The method is elaborated for the OWL
> >     data in:
> >
> https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
> >
> >     I am not fully sure how to interpret the results for the
> >     zero-inflated version though. Would I need to interpret the
> >     coefficients for the result of the glmer similar to as I would do
> >     for my idea of 2)? And then on top of that interpret the
> >     coefficients for the logistic regression regarding whether
> >     something is in the perfect or imperfect state? I am also not
> >     quite sure what the common approach for the zformula is here. The
> >     OWL elaborations only use zformula=z~1, so no random effect; I
> >     would use the same formula as for the glmer.
> >
> >     I am appreciating some help and pointers.
> >
> >     Thanks!
> >     Philipp
> >
> >     _______________________________________________
> >     R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From killver at gmail.com  Thu Jun 23 12:42:05 2016
From: killver at gmail.com (Philipp Singer)
Date: Thu, 23 Jun 2016 12:42:05 +0200
Subject: [R-sig-ME] Question about zero-inflated Poisson glmer
In-Reply-To: <CAJuCY5zmK1xCyWOwcCH+Hch_LSdB+AazmUDuPVP6je7ABFU5FA@mail.gmail.com>
References: <576B98C4.6000602@gmail.com>
	<CAJuCY5xbiEjCmHjc_3wX2emzJ3NEMTA_qKgC_reWn=zqC7YEng@mail.gmail.com>
	<576BAB84.6080009@gmail.com>
	<CAJuCY5zmK1xCyWOwcCH+Hch_LSdB+AazmUDuPVP6je7ABFU5FA@mail.gmail.com>
Message-ID: <576BBCFD.8040806@gmail.com>

Thanks! Actually, accounting for overdispersion is super important as it 
seems, then the zeros can be captured well.

On 23.06.2016 11:50, Thierry Onkelinx wrote:
> Dear Philipp,
>
> 1. Fit a Poisson model to the data.
> 2. Simulate a new response vector for the dataset according to the model.
> 3. Count the number of zero's in the simulated response vector.
> 4. Repeat step 2 and 3 a decent number of time and plot a histogram of 
> the number of zero's in the simulation. If the number of zero's in the 
> original dataset is larger than those in the simulations, then the 
> model can't capture all zero's. In such case, first try to update the 
> model and repeat the procedure. If that fails, look for zero-inflated 
> models.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature 
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no 
> more than asking him to perform a post-mortem examination: he may be 
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does 
> not ensure that a reasonable answer can be extracted from a given body 
> of data. ~ John Tukey
>
> 2016-06-23 11:27 GMT+02:00 Philipp Singer <killver at gmail.com 
> <mailto:killver at gmail.com>>:
>
>     Thanks Thierry - That totally makes sense. Is there some way of
>     formally
>     checking that, except thinking about the setting and underlying
>     processes?
>
>     On 23.06.2016 11:04, Thierry Onkelinx wrote:
>     > Dear Philipp,
>     >
>     > Do you have just lots of zero's, or more zero's than the Poisson
>     > distribution can explain? Those are two different things. The
>     example
>     > below generates data from a Poisson distribution and has 99% zero's
>     > but no zero-inflation. The second example has only 1% zero's but is
>     > clearly zero-inflated.
>     >
>     > set.seed(1)
>     > n <- 1e8
>     > sim <- rpois(n, lambda = 0.01)
>     > mean(sim == 0)
>     > hist(sim)
>     >
>     > sim.infl <- rbinom(n, size = 1, prob = 0.99) * rpois(n, lambda =
>     1000)
>     > mean(sim.infl == 0)
>     > hist(sim.infl)
>     >
>     > So before looking for zero-inflated models, try to model the zero's.
>     >
>     > Best regards,
>     >
>     >
>     > ir. Thierry Onkelinx
>     > Instituut voor natuur- en bosonderzoek / Research Institute for
>     Nature
>     > and Forest
>     > team Biometrie & Kwaliteitszorg / team Biometrics & Quality
>     Assurance
>     > Kliniekstraat 25
>     > 1070 Anderlecht
>     > Belgium
>     >
>     > To call in the statistician after the experiment is done may be no
>     > more than asking him to perform a post-mortem examination: he may be
>     > able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>     > The plural of anecdote is not data. ~ Roger Brinner
>     > The combination of some data and an aching desire for an answer does
>     > not ensure that a reasonable answer can be extracted from a
>     given body
>     > of data. ~ John Tukey
>     >
>     > 2016-06-23 10:07 GMT+02:00 Philipp Singer <killver at gmail.com
>     <mailto:killver at gmail.com>
>     > <mailto:killver at gmail.com <mailto:killver at gmail.com>>>:
>     >
>     >     Dear group - I am currently fitting a Poisson glmer where I have
>     >     an excess of outcomes that are zero (>95%). I am now debating on
>     >     how to proceed and came up with three options:
>     >
>     >     1.) Just fit a regular glmer to the complete data. I am not
>     fully
>     >     sure how interpret the coefficients then, are they more
>     optimizing
>     >     towards distinguishing zero and non-zero, or also capturing the
>     >     differences in those outcomes that are non-zero?
>     >
>     >     2.) Leave all zeros out of the data and fit a glmer to only
>     those
>     >     outcomes that are non-zero. Then, I would only learn about
>     >     differences in the non-zero outcomes though.
>     >
>     >     3.) Use a zero-inflated Poisson model. My data is quite
>     >     large-scale, so I am currently playing around with the EM
>     >     implementation of Bolker et al. that alternates between
>     fitting a
>     >     glmer with data that are weighted according to their zero
>     >     probability, and fitting a logistic regression for the
>     probability
>     >     that a data point is zero. The method is elaborated for the OWL
>     >     data in:
>     >
>     https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
>     >
>     >     I am not fully sure how to interpret the results for the
>     >     zero-inflated version though. Would I need to interpret the
>     >     coefficients for the result of the glmer similar to as I
>     would do
>     >     for my idea of 2)? And then on top of that interpret the
>     >     coefficients for the logistic regression regarding whether
>     >     something is in the perfect or imperfect state? I am also not
>     >     quite sure what the common approach for the zformula is
>     here. The
>     >     OWL elaborations only use zformula=z~1, so no random effect; I
>     >     would use the same formula as for the glmer.
>     >
>     >     I am appreciating some help and pointers.
>     >
>     >     Thanks!
>     >     Philipp
>     >
>     >     _______________________________________________
>     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>> mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >
>     >
>
>
>             [[alternative HTML version deleted]]
>
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Thu Jun 23 15:50:40 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 23 Jun 2016 15:50:40 +0200
Subject: [R-sig-ME] Question about zero-inflated Poisson glmer
In-Reply-To: <576BBCFD.8040806@gmail.com>
References: <576B98C4.6000602@gmail.com>
	<CAJuCY5xbiEjCmHjc_3wX2emzJ3NEMTA_qKgC_reWn=zqC7YEng@mail.gmail.com>
	<576BAB84.6080009@gmail.com>
	<CAJuCY5zmK1xCyWOwcCH+Hch_LSdB+AazmUDuPVP6je7ABFU5FA@mail.gmail.com>
	<576BBCFD.8040806@gmail.com>
Message-ID: <CAJuCY5ycRL6oXs=H5JrEqOHWzd1UsvSNVZM6-MK+V2N=pvbyQA@mail.gmail.com>

Be careful when using overdispersion to model zero-inflation. Those are two
different things.

I've put some information together in
http://rpubs.com/INBOstats/zeroinflation

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-06-23 12:42 GMT+02:00 Philipp Singer <killver at gmail.com>:

> Thanks! Actually, accounting for overdispersion is super important as it
> seems, then the zeros can be captured well.
>
>
> On 23.06.2016 11:50, Thierry Onkelinx wrote:
>
> Dear Philipp,
>
> 1. Fit a Poisson model to the data.
> 2. Simulate a new response vector for the dataset according to the model.
> 3. Count the number of zero's in the simulated response vector.
> 4. Repeat step 2 and 3 a decent number of time and plot a histogram of the
> number of zero's in the simulation. If the number of zero's in the original
> dataset is larger than those in the simulations, then the model can't
> capture all zero's. In such case, first try to update the model and repeat
> the procedure. If that fails, look for zero-inflated models.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2016-06-23 11:27 GMT+02:00 Philipp Singer <killver at gmail.com>:
>
>> Thanks Thierry - That totally makes sense. Is there some way of formally
>> checking that, except thinking about the setting and underlying processes?
>>
>> On 23.06.2016 11:04, Thierry Onkelinx wrote:
>> > Dear Philipp,
>> >
>> > Do you have just lots of zero's, or more zero's than the Poisson
>> > distribution can explain? Those are two different things. The example
>> > below generates data from a Poisson distribution and has 99% zero's
>> > but no zero-inflation. The second example has only 1% zero's but is
>> > clearly zero-inflated.
>> >
>> > set.seed(1)
>> > n <- 1e8
>> > sim <- rpois(n, lambda = 0.01)
>> > mean(sim == 0)
>> > hist(sim)
>> >
>> > sim.infl <- rbinom(n, size = 1, prob = 0.99) * rpois(n, lambda = 1000)
>> > mean(sim.infl == 0)
>> > hist(sim.infl)
>> >
>> > So before looking for zero-inflated models, try to model the zero's.
>> >
>> > Best regards,
>> >
>> >
>> > ir. Thierry Onkelinx
>> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> > and Forest
>> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> > Kliniekstraat 25
>> > 1070 Anderlecht
>> > Belgium
>> >
>> > To call in the statistician after the experiment is done may be no
>> > more than asking him to perform a post-mortem examination: he may be
>> > able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> > The plural of anecdote is not data. ~ Roger Brinner
>> > The combination of some data and an aching desire for an answer does
>> > not ensure that a reasonable answer can be extracted from a given body
>> > of data. ~ John Tukey
>> >
>> > 2016-06-23 10:07 GMT+02:00 Philipp Singer < <killver at gmail.com>
>> killver at gmail.com
>> > <mailto:killver at gmail.com>>:
>> >
>> >     Dear group - I am currently fitting a Poisson glmer where I have
>> >     an excess of outcomes that are zero (>95%). I am now debating on
>> >     how to proceed and came up with three options:
>> >
>> >     1.) Just fit a regular glmer to the complete data. I am not fully
>> >     sure how interpret the coefficients then, are they more optimizing
>> >     towards distinguishing zero and non-zero, or also capturing the
>> >     differences in those outcomes that are non-zero?
>> >
>> >     2.) Leave all zeros out of the data and fit a glmer to only those
>> >     outcomes that are non-zero. Then, I would only learn about
>> >     differences in the non-zero outcomes though.
>> >
>> >     3.) Use a zero-inflated Poisson model. My data is quite
>> >     large-scale, so I am currently playing around with the EM
>> >     implementation of Bolker et al. that alternates between fitting a
>> >     glmer with data that are weighted according to their zero
>> >     probability, and fitting a logistic regression for the probability
>> >     that a data point is zero. The method is elaborated for the OWL
>> >     data in:
>> >
>> https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
>> >
>> >     I am not fully sure how to interpret the results for the
>> >     zero-inflated version though. Would I need to interpret the
>> >     coefficients for the result of the glmer similar to as I would do
>> >     for my idea of 2)? And then on top of that interpret the
>> >     coefficients for the logistic regression regarding whether
>> >     something is in the perfect or imperfect state? I am also not
>> >     quite sure what the common approach for the zformula is here. The
>> >     OWL elaborations only use zformula=z~1, so no random effect; I
>> >     would use the same formula as for the glmer.
>> >
>> >     I am appreciating some help and pointers.
>> >
>> >     Thanks!
>> >     Philipp
>> >
>> >     _______________________________________________
>> >     R-sig-mixed-models at r-project.org
>> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
>> >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>> >
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>

	[[alternative HTML version deleted]]


From killver at gmail.com  Thu Jun 23 17:22:36 2016
From: killver at gmail.com (Philipp Singer)
Date: Thu, 23 Jun 2016 17:22:36 +0200
Subject: [R-sig-ME] Question about zero-inflated Poisson glmer
In-Reply-To: <CAJuCY5ycRL6oXs=H5JrEqOHWzd1UsvSNVZM6-MK+V2N=pvbyQA@mail.gmail.com>
References: <576B98C4.6000602@gmail.com>
	<CAJuCY5xbiEjCmHjc_3wX2emzJ3NEMTA_qKgC_reWn=zqC7YEng@mail.gmail.com>
	<576BAB84.6080009@gmail.com>
	<CAJuCY5zmK1xCyWOwcCH+Hch_LSdB+AazmUDuPVP6je7ABFU5FA@mail.gmail.com>
	<576BBCFD.8040806@gmail.com>
	<CAJuCY5ycRL6oXs=H5JrEqOHWzd1UsvSNVZM6-MK+V2N=pvbyQA@mail.gmail.com>
Message-ID: <576BFEBC.3020407@gmail.com>

Thanks, great information, that is really helpful.

I agree that those are different things, however when using a random 
effect for overdispersion, I can simulate the same number of zero 
outcomes (~95%).

On 23.06.2016 15:50, Thierry Onkelinx wrote:
> Be careful when using overdispersion to model zero-inflation. Those 
> are two different things.
>
> I've put some information together in 
> http://rpubs.com/INBOstats/zeroinflation
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature 
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no 
> more than asking him to perform a post-mortem examination: he may be 
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does 
> not ensure that a reasonable answer can be extracted from a given body 
> of data. ~ John Tukey
>
> 2016-06-23 12:42 GMT+02:00 Philipp Singer <killver at gmail.com 
> <mailto:killver at gmail.com>>:
>
>     Thanks! Actually, accounting for overdispersion is super important
>     as it seems, then the zeros can be captured well.
>
>
>     On 23.06.2016 11:50, Thierry Onkelinx wrote:
>>     Dear Philipp,
>>
>>     1. Fit a Poisson model to the data.
>>     2. Simulate a new response vector for the dataset according to
>>     the model.
>>     3. Count the number of zero's in the simulated response vector.
>>     4. Repeat step 2 and 3 a decent number of time and plot a
>>     histogram of the number of zero's in the simulation. If the
>>     number of zero's in the original dataset is larger than those in
>>     the simulations, then the model can't capture all zero's. In such
>>     case, first try to update the model and repeat the procedure. If
>>     that fails, look for zero-inflated models.
>>
>>     Best regards,
>>
>>     ir. Thierry Onkelinx
>>     Instituut voor natuur- en bosonderzoek / Research Institute for
>>     Nature and Forest
>>     team Biometrie & Kwaliteitszorg / team Biometrics & Quality
>>     Assurance
>>     Kliniekstraat 25
>>     1070 Anderlecht
>>     Belgium
>>
>>     To call in the statistician after the experiment is done may be
>>     no more than asking him to perform a post-mortem examination: he
>>     may be able to say what the experiment died of. ~ Sir Ronald
>>     Aylmer Fisher
>>     The plural of anecdote is not data. ~ Roger Brinner
>>     The combination of some data and an aching desire for an answer
>>     does not ensure that a reasonable answer can be extracted from a
>>     given body of data. ~ John Tukey
>>
>>     2016-06-23 11:27 GMT+02:00 Philipp Singer <killver at gmail.com
>>     <mailto:killver at gmail.com>>:
>>
>>         Thanks Thierry - That totally makes sense. Is there some way
>>         of formally
>>         checking that, except thinking about the setting and
>>         underlying processes?
>>
>>         On 23.06.2016 11:04, Thierry Onkelinx wrote:
>>         > Dear Philipp,
>>         >
>>         > Do you have just lots of zero's, or more zero's than the
>>         Poisson
>>         > distribution can explain? Those are two different things.
>>         The example
>>         > below generates data from a Poisson distribution and has
>>         99% zero's
>>         > but no zero-inflation. The second example has only 1%
>>         zero's but is
>>         > clearly zero-inflated.
>>         >
>>         > set.seed(1)
>>         > n <- 1e8
>>         > sim <- rpois(n, lambda = 0.01)
>>         > mean(sim == 0)
>>         > hist(sim)
>>         >
>>         > sim.infl <- rbinom(n, size = 1, prob = 0.99) * rpois(n,
>>         lambda = 1000)
>>         > mean(sim.infl == 0)
>>         > hist(sim.infl)
>>         >
>>         > So before looking for zero-inflated models, try to model
>>         the zero's.
>>         >
>>         > Best regards,
>>         >
>>         >
>>         > ir. Thierry Onkelinx
>>         > Instituut voor natuur- en bosonderzoek / Research Institute
>>         for Nature
>>         > and Forest
>>         > team Biometrie & Kwaliteitszorg / team Biometrics & Quality
>>         Assurance
>>         > Kliniekstraat 25
>>         > 1070 Anderlecht
>>         > Belgium
>>         >
>>         > To call in the statistician after the experiment is done
>>         may be no
>>         > more than asking him to perform a post-mortem examination:
>>         he may be
>>         > able to say what the experiment died of. ~ Sir Ronald
>>         Aylmer Fisher
>>         > The plural of anecdote is not data. ~ Roger Brinner
>>         > The combination of some data and an aching desire for an
>>         answer does
>>         > not ensure that a reasonable answer can be extracted from a
>>         given body
>>         > of data. ~ John Tukey
>>         >
>>         > 2016-06-23 10:07 GMT+02:00 Philipp Singer
>>         <killver at gmail.com <mailto:killver at gmail.com>
>>         > <mailto:killver at gmail.com <mailto:killver at gmail.com>>>:
>>         >
>>         >     Dear group - I am currently fitting a Poisson glmer
>>         where I have
>>         >     an excess of outcomes that are zero (>95%). I am now
>>         debating on
>>         >     how to proceed and came up with three options:
>>         >
>>         >     1.) Just fit a regular glmer to the complete data. I am
>>         not fully
>>         >     sure how interpret the coefficients then, are they more
>>         optimizing
>>         >     towards distinguishing zero and non-zero, or also
>>         capturing the
>>         >     differences in those outcomes that are non-zero?
>>         >
>>         >     2.) Leave all zeros out of the data and fit a glmer to
>>         only those
>>         >     outcomes that are non-zero. Then, I would only learn about
>>         >     differences in the non-zero outcomes though.
>>         >
>>         >     3.) Use a zero-inflated Poisson model. My data is quite
>>         >     large-scale, so I am currently playing around with the EM
>>         >     implementation of Bolker et al. that alternates between
>>         fitting a
>>         >     glmer with data that are weighted according to their zero
>>         >     probability, and fitting a logistic regression for the
>>         probability
>>         >     that a data point is zero. The method is elaborated for
>>         the OWL
>>         >     data in:
>>         >
>>         https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
>>         >
>>         >     I am not fully sure how to interpret the results for the
>>         >     zero-inflated version though. Would I need to interpret the
>>         >     coefficients for the result of the glmer similar to as
>>         I would do
>>         >     for my idea of 2)? And then on top of that interpret the
>>         >     coefficients for the logistic regression regarding whether
>>         >     something is in the perfect or imperfect state? I am
>>         also not
>>         >     quite sure what the common approach for the zformula is
>>         here. The
>>         >     OWL elaborations only use zformula=z~1, so no random
>>         effect; I
>>         >     would use the same formula as for the glmer.
>>         >
>>         >     I am appreciating some help and pointers.
>>         >
>>         >     Thanks!
>>         >     Philipp
>>         >
>>         >  _______________________________________________
>>         > R-sig-mixed-models at r-project.org
>>         <mailto:R-sig-mixed-models at r-project.org>
>>         >     <mailto:R-sig-mixed-models at r-project.org
>>         <mailto:R-sig-mixed-models at r-project.org>> mailing list
>>         > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>         >
>>         >
>>
>>
>>                 [[alternative HTML version deleted]]
>>
>>         _______________________________________________
>>         R-sig-mixed-models at r-project.org
>>         <mailto:R-sig-mixed-models at r-project.org> mailing list
>>         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
>


	[[alternative HTML version deleted]]


From mbrooks at ufl.edu  Thu Jun 23 18:47:29 2016
From: mbrooks at ufl.edu (Mollie Brooks)
Date: Thu, 23 Jun 2016 09:47:29 -0700
Subject: [R-sig-ME] Question about zero-inflated Poisson glmer
In-Reply-To: <576BFEBC.3020407@gmail.com>
References: <576B98C4.6000602@gmail.com>
	<CAJuCY5xbiEjCmHjc_3wX2emzJ3NEMTA_qKgC_reWn=zqC7YEng@mail.gmail.com>
	<576BAB84.6080009@gmail.com>
	<CAJuCY5zmK1xCyWOwcCH+Hch_LSdB+AazmUDuPVP6je7ABFU5FA@mail.gmail.com>
	<576BBCFD.8040806@gmail.com>
	<CAJuCY5ycRL6oXs=H5JrEqOHWzd1UsvSNVZM6-MK+V2N=pvbyQA@mail.gmail.com>
	<576BFEBC.3020407@gmail.com>
Message-ID: <B5AEF3F5-949F-4686-82DA-C234C3C4018B@ufl.edu>

Hi Philipp,

You could also try fitting the model with and without ZI using either glmmADMB or glmmTMB. Then compare the AICs. I believe model selection is useful for this, but I could be missing something since the simulation procedure that Thierry described seems to recommended more often.

https://github.com/glmmTMB/glmmTMB
http://glmmadmb.r-forge.r-project.org

glmmTMB is still in the development phase, but we?ve done a lot of testing.

cheers,
Mollie

------------------------
Mollie Brooks, PhD
Postdoctoral Researcher, Population Ecology Research Group
Department of Evolutionary Biology & Environmental Studies, University of Z?rich
http://www.popecol.org/team/mollie-brooks/


> On 23Jun 2016, at 8:22, Philipp Singer <killver at gmail.com> wrote:
> 
> Thanks, great information, that is really helpful.
> 
> I agree that those are different things, however when using a random 
> effect for overdispersion, I can simulate the same number of zero 
> outcomes (~95%).
> 
> On 23.06.2016 15:50, Thierry Onkelinx wrote:
>> Be careful when using overdispersion to model zero-inflation. Those 
>> are two different things.
>> 
>> I've put some information together in 
>> http://rpubs.com/INBOstats/zeroinflation
>> 
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature 
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>> 
>> To call in the statistician after the experiment is done may be no 
>> more than asking him to perform a post-mortem examination: he may be 
>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does 
>> not ensure that a reasonable answer can be extracted from a given body 
>> of data. ~ John Tukey
>> 
>> 2016-06-23 12:42 GMT+02:00 Philipp Singer <killver at gmail.com 
>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>>:
>> 
>>    Thanks! Actually, accounting for overdispersion is super important
>>    as it seems, then the zeros can be captured well.
>> 
>> 
>>    On 23.06.2016 11:50, Thierry Onkelinx wrote:
>>>    Dear Philipp,
>>> 
>>>    1. Fit a Poisson model to the data.
>>>    2. Simulate a new response vector for the dataset according to
>>>    the model.
>>>    3. Count the number of zero's in the simulated response vector.
>>>    4. Repeat step 2 and 3 a decent number of time and plot a
>>>    histogram of the number of zero's in the simulation. If the
>>>    number of zero's in the original dataset is larger than those in
>>>    the simulations, then the model can't capture all zero's. In such
>>>    case, first try to update the model and repeat the procedure. If
>>>    that fails, look for zero-inflated models.
>>> 
>>>    Best regards,
>>> 
>>>    ir. Thierry Onkelinx
>>>    Instituut voor natuur- en bosonderzoek / Research Institute for
>>>    Nature and Forest
>>>    team Biometrie & Kwaliteitszorg / team Biometrics & Quality
>>>    Assurance
>>>    Kliniekstraat 25
>>>    1070 Anderlecht
>>>    Belgium
>>> 
>>>    To call in the statistician after the experiment is done may be
>>>    no more than asking him to perform a post-mortem examination: he
>>>    may be able to say what the experiment died of. ~ Sir Ronald
>>>    Aylmer Fisher
>>>    The plural of anecdote is not data. ~ Roger Brinner
>>>    The combination of some data and an aching desire for an answer
>>>    does not ensure that a reasonable answer can be extracted from a
>>>    given body of data. ~ John Tukey
>>> 
>>>    2016-06-23 11:27 GMT+02:00 Philipp Singer <killver at gmail.com
>>>    <mailto:killver at gmail.com <mailto:killver at gmail.com>>>:
>>> 
>>>        Thanks Thierry - That totally makes sense. Is there some way
>>>        of formally
>>>        checking that, except thinking about the setting and
>>>        underlying processes?
>>> 
>>>        On 23.06.2016 11:04, Thierry Onkelinx wrote:
>>>> Dear Philipp,
>>>> 
>>>> Do you have just lots of zero's, or more zero's than the
>>>        Poisson
>>>> distribution can explain? Those are two different things.
>>>        The example
>>>> below generates data from a Poisson distribution and has
>>>        99% zero's
>>>> but no zero-inflation. The second example has only 1%
>>>        zero's but is
>>>> clearly zero-inflated.
>>>> 
>>>> set.seed(1)
>>>> n <- 1e8
>>>> sim <- rpois(n, lambda = 0.01)
>>>> mean(sim == 0)
>>>> hist(sim)
>>>> 
>>>> sim.infl <- rbinom(n, size = 1, prob = 0.99) * rpois(n,
>>>        lambda = 1000)
>>>> mean(sim.infl == 0)
>>>> hist(sim.infl)
>>>> 
>>>> So before looking for zero-inflated models, try to model
>>>        the zero's.
>>>> 
>>>> Best regards,
>>>> 
>>>> 
>>>> ir. Thierry Onkelinx
>>>> Instituut voor natuur- en bosonderzoek / Research Institute
>>>        for Nature
>>>> and Forest
>>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality
>>>        Assurance
>>>> Kliniekstraat 25
>>>> 1070 Anderlecht
>>>> Belgium
>>>> 
>>>> To call in the statistician after the experiment is done
>>>        may be no
>>>> more than asking him to perform a post-mortem examination:
>>>        he may be
>>>> able to say what the experiment died of. ~ Sir Ronald
>>>        Aylmer Fisher
>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>> The combination of some data and an aching desire for an
>>>        answer does
>>>> not ensure that a reasonable answer can be extracted from a
>>>        given body
>>>> of data. ~ John Tukey
>>>> 
>>>> 2016-06-23 10:07 GMT+02:00 Philipp Singer
>>>        <killver at gmail.com <mailto:killver at gmail.com> <mailto:killver at gmail.com <mailto:killver at gmail.com>>
>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com> <mailto:killver at gmail.com <mailto:killver at gmail.com>>>>:
>>>> 
>>>>    Dear group - I am currently fitting a Poisson glmer
>>>        where I have
>>>>    an excess of outcomes that are zero (>95%). I am now
>>>        debating on
>>>>    how to proceed and came up with three options:
>>>> 
>>>>    1.) Just fit a regular glmer to the complete data. I am
>>>        not fully
>>>>    sure how interpret the coefficients then, are they more
>>>        optimizing
>>>>    towards distinguishing zero and non-zero, or also
>>>        capturing the
>>>>    differences in those outcomes that are non-zero?
>>>> 
>>>>    2.) Leave all zeros out of the data and fit a glmer to
>>>        only those
>>>>    outcomes that are non-zero. Then, I would only learn about
>>>>    differences in the non-zero outcomes though.
>>>> 
>>>>    3.) Use a zero-inflated Poisson model. My data is quite
>>>>    large-scale, so I am currently playing around with the EM
>>>>    implementation of Bolker et al. that alternates between
>>>        fitting a
>>>>    glmer with data that are weighted according to their zero
>>>>    probability, and fitting a logistic regression for the
>>>        probability
>>>>    that a data point is zero. The method is elaborated for
>>>        the OWL
>>>>    data in:
>>>> 
>>>        https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf <https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf>
>>>> 
>>>>    I am not fully sure how to interpret the results for the
>>>>    zero-inflated version though. Would I need to interpret the
>>>>    coefficients for the result of the glmer similar to as
>>>        I would do
>>>>    for my idea of 2)? And then on top of that interpret the
>>>>    coefficients for the logistic regression regarding whether
>>>>    something is in the perfect or imperfect state? I am
>>>        also not
>>>>    quite sure what the common approach for the zformula is
>>>        here. The
>>>>    OWL elaborations only use zformula=z~1, so no random
>>>        effect; I
>>>>    would use the same formula as for the glmer.
>>>> 
>>>>    I am appreciating some help and pointers.
>>>> 
>>>>    Thanks!
>>>>    Philipp
>>>> 
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org>
>>>        <mailto:R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org>>
>>>>    <mailto:R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org>
>>>        <mailto:R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org>>> mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>> 
>>>> 
>>> 
>>> 
>>>                [[alternative HTML version deleted]]
>>> 
>>>        _______________________________________________
>>>        R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org>
>>>        <mailto:R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org>> mailing list
>>>        https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>> 
>>> 
>> 
>> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu Jun 23 19:14:33 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 23 Jun 2016 13:14:33 -0400
Subject: [R-sig-ME] Question about zero-inflated Poisson glmer
In-Reply-To: <B5AEF3F5-949F-4686-82DA-C234C3C4018B@ufl.edu>
References: <576B98C4.6000602@gmail.com>
	<CAJuCY5xbiEjCmHjc_3wX2emzJ3NEMTA_qKgC_reWn=zqC7YEng@mail.gmail.com>
	<576BAB84.6080009@gmail.com>
	<CAJuCY5zmK1xCyWOwcCH+Hch_LSdB+AazmUDuPVP6je7ABFU5FA@mail.gmail.com>
	<576BBCFD.8040806@gmail.com>
	<CAJuCY5ycRL6oXs=H5JrEqOHWzd1UsvSNVZM6-MK+V2N=pvbyQA@mail.gmail.com>
	<576BFEBC.3020407@gmail.com>
	<B5AEF3F5-949F-4686-82DA-C234C3C4018B@ufl.edu>
Message-ID: <576C18F9.9010200@gmail.com>


  I would also comment that glmmTMB is likely to be much faster than the
lme4-based EM approach ...

  cheers
    Ben B.

On 16-06-23 12:47 PM, Mollie Brooks wrote:
> Hi Philipp,
> 
> You could also try fitting the model with and without ZI using either
> glmmADMB or glmmTMB. Then compare the AICs. I believe model selection
> is useful for this, but I could be missing something since the
> simulation procedure that Thierry described seems to recommended more
> often.
> 
> https://github.com/glmmTMB/glmmTMB 
> http://glmmadmb.r-forge.r-project.org
> 
> glmmTMB is still in the development phase, but we?ve done a lot of
> testing.
> 
> cheers, Mollie
> 
> ------------------------ Mollie Brooks, PhD Postdoctoral Researcher,
> Population Ecology Research Group Department of Evolutionary Biology
> & Environmental Studies, University of Z?rich 
> http://www.popecol.org/team/mollie-brooks/
> 
> 
>> On 23Jun 2016, at 8:22, Philipp Singer <killver at gmail.com> wrote:
>> 
>> Thanks, great information, that is really helpful.
>> 
>> I agree that those are different things, however when using a
>> random effect for overdispersion, I can simulate the same number of
>> zero outcomes (~95%).
>> 
>> On 23.06.2016 15:50, Thierry Onkelinx wrote:
>>> Be careful when using overdispersion to model zero-inflation.
>>> Those are two different things.
>>> 
>>> I've put some information together in 
>>> http://rpubs.com/INBOstats/zeroinflation
>>> 
>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
>>> Research Institute for Nature and Forest team Biometrie &
>>> Kwaliteitszorg / team Biometrics & Quality Assurance 
>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>> 
>>> To call in the statistician after the experiment is done may be
>>> no more than asking him to perform a post-mortem examination: he
>>> may be able to say what the experiment died of. ~ Sir Ronald
>>> Aylmer Fisher The plural of anecdote is not data. ~ Roger
>>> Brinner The combination of some data and an aching desire for an
>>> answer does not ensure that a reasonable answer can be extracted
>>> from a given body of data. ~ John Tukey
>>> 
>>> 2016-06-23 12:42 GMT+02:00 Philipp Singer <killver at gmail.com 
>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>>:
>>> 
>>> Thanks! Actually, accounting for overdispersion is super
>>> important as it seems, then the zeros can be captured well.
>>> 
>>> 
>>> On 23.06.2016 11:50, Thierry Onkelinx wrote:
>>>> Dear Philipp,
>>>> 
>>>> 1. Fit a Poisson model to the data. 2. Simulate a new response
>>>> vector for the dataset according to the model. 3. Count the
>>>> number of zero's in the simulated response vector. 4. Repeat
>>>> step 2 and 3 a decent number of time and plot a histogram of
>>>> the number of zero's in the simulation. If the number of zero's
>>>> in the original dataset is larger than those in the
>>>> simulations, then the model can't capture all zero's. In such 
>>>> case, first try to update the model and repeat the procedure.
>>>> If that fails, look for zero-inflated models.
>>>> 
>>>> Best regards,
>>>> 
>>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
>>>> Research Institute for Nature and Forest team Biometrie &
>>>> Kwaliteitszorg / team Biometrics & Quality Assurance 
>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>>> 
>>>> To call in the statistician after the experiment is done may
>>>> be no more than asking him to perform a post-mortem
>>>> examination: he may be able to say what the experiment died of.
>>>> ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data.
>>>> ~ Roger Brinner The combination of some data and an aching
>>>> desire for an answer does not ensure that a reasonable answer
>>>> can be extracted from a given body of data. ~ John Tukey
>>>> 
>>>> 2016-06-23 11:27 GMT+02:00 Philipp Singer <killver at gmail.com 
>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>>:
>>>> 
>>>> Thanks Thierry - That totally makes sense. Is there some way of
>>>> formally checking that, except thinking about the setting and 
>>>> underlying processes?
>>>> 
>>>> On 23.06.2016 11:04, Thierry Onkelinx wrote:
>>>>> Dear Philipp,
>>>>> 
>>>>> Do you have just lots of zero's, or more zero's than the
>>>> Poisson
>>>>> distribution can explain? Those are two different things.
>>>> The example
>>>>> below generates data from a Poisson distribution and has
>>>> 99% zero's
>>>>> but no zero-inflation. The second example has only 1%
>>>> zero's but is
>>>>> clearly zero-inflated.
>>>>> 
>>>>> set.seed(1) n <- 1e8 sim <- rpois(n, lambda = 0.01) mean(sim
>>>>> == 0) hist(sim)
>>>>> 
>>>>> sim.infl <- rbinom(n, size = 1, prob = 0.99) * rpois(n,
>>>> lambda = 1000)
>>>>> mean(sim.infl == 0) hist(sim.infl)
>>>>> 
>>>>> So before looking for zero-inflated models, try to model
>>>> the zero's.
>>>>> 
>>>>> Best regards,
>>>>> 
>>>>> 
>>>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
>>>>> Research Institute
>>>> for Nature
>>>>> and Forest team Biometrie & Kwaliteitszorg / team Biometrics
>>>>> & Quality
>>>> Assurance
>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>>>> 
>>>>> To call in the statistician after the experiment is done
>>>> may be no
>>>>> more than asking him to perform a post-mortem examination:
>>>> he may be
>>>>> able to say what the experiment died of. ~ Sir Ronald
>>>> Aylmer Fisher
>>>>> The plural of anecdote is not data. ~ Roger Brinner The
>>>>> combination of some data and an aching desire for an
>>>> answer does
>>>>> not ensure that a reasonable answer can be extracted from a
>>>> given body
>>>>> of data. ~ John Tukey
>>>>> 
>>>>> 2016-06-23 10:07 GMT+02:00 Philipp Singer
>>>> <killver at gmail.com <mailto:killver at gmail.com>
>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>
>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>
>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>>>:
>>>>> 
>>>>> Dear group - I am currently fitting a Poisson glmer
>>>> where I have
>>>>> an excess of outcomes that are zero (>95%). I am now
>>>> debating on
>>>>> how to proceed and came up with three options:
>>>>> 
>>>>> 1.) Just fit a regular glmer to the complete data. I am
>>>> not fully
>>>>> sure how interpret the coefficients then, are they more
>>>> optimizing
>>>>> towards distinguishing zero and non-zero, or also
>>>> capturing the
>>>>> differences in those outcomes that are non-zero?
>>>>> 
>>>>> 2.) Leave all zeros out of the data and fit a glmer to
>>>> only those
>>>>> outcomes that are non-zero. Then, I would only learn about 
>>>>> differences in the non-zero outcomes though.
>>>>> 
>>>>> 3.) Use a zero-inflated Poisson model. My data is quite 
>>>>> large-scale, so I am currently playing around with the EM 
>>>>> implementation of Bolker et al. that alternates between
>>>> fitting a
>>>>> glmer with data that are weighted according to their zero 
>>>>> probability, and fitting a logistic regression for the
>>>> probability
>>>>> that a data point is zero. The method is elaborated for
>>>> the OWL
>>>>> data in:
>>>>> 
>>>> https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
>>>> <https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf>
>>>>>
>>>>>
>>>> 
I am not fully sure how to interpret the results for the
>>>>> zero-inflated version though. Would I need to interpret the 
>>>>> coefficients for the result of the glmer similar to as
>>>> I would do
>>>>> for my idea of 2)? And then on top of that interpret the 
>>>>> coefficients for the logistic regression regarding whether 
>>>>> something is in the perfect or imperfect state? I am
>>>> also not
>>>>> quite sure what the common approach for the zformula is
>>>> here. The
>>>>> OWL elaborations only use zformula=z~1, so no random
>>>> effect; I
>>>>> would use the same formula as for the glmer.
>>>>> 
>>>>> I am appreciating some help and pointers.
>>>>> 
>>>>> Thanks! Philipp
>>>>> 
>>>>> _______________________________________________ 
>>>>> R-sig-mixed-models at r-project.org
>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>> <mailto:R-sig-mixed-models at r-project.org
>>>> <mailto:R-sig-mixed-models at r-project.org>>
>>>>> <mailto:R-sig-mixed-models at r-project.org
>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>> <mailto:R-sig-mixed-models at r-project.org
>>>> <mailto:R-sig-mixed-models at r-project.org>>> mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>> 
>>>>> 
>>>> 
>>>> 
>>>> [[alternative HTML version deleted]]
>>>> 
>>>> _______________________________________________ 
>>>> R-sig-mixed-models at r-project.org
>>>> <mailto:R-sig-mixed-models at r-project.org> 
>>>> <mailto:R-sig-mixed-models at r-project.org
>>>> <mailto:R-sig-mixed-models at r-project.org>> mailing list 
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>> 
>>>> 
>>> 
>>> 
>> 
>> 
>> [[alternative HTML version deleted]]
>> 
>> _______________________________________________ 
>> R-sig-mixed-models at r-project.org
>> <mailto:R-sig-mixed-models at r-project.org> mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From killver at gmail.com  Thu Jun 23 19:44:42 2016
From: killver at gmail.com (Philipp Singer)
Date: Thu, 23 Jun 2016 19:44:42 +0200
Subject: [R-sig-ME] Question about zero-inflated Poisson glmer
In-Reply-To: <576C18F9.9010200@gmail.com>
References: <576B98C4.6000602@gmail.com>
	<CAJuCY5xbiEjCmHjc_3wX2emzJ3NEMTA_qKgC_reWn=zqC7YEng@mail.gmail.com>
	<576BAB84.6080009@gmail.com>
	<CAJuCY5zmK1xCyWOwcCH+Hch_LSdB+AazmUDuPVP6je7ABFU5FA@mail.gmail.com>
	<576BBCFD.8040806@gmail.com>
	<CAJuCY5ycRL6oXs=H5JrEqOHWzd1UsvSNVZM6-MK+V2N=pvbyQA@mail.gmail.com>
	<576BFEBC.3020407@gmail.com>
	<B5AEF3F5-949F-4686-82DA-C234C3C4018B@ufl.edu>
	<576C18F9.9010200@gmail.com>
Message-ID: <576C200A.1050405@gmail.com>

Did try glmmADMB but unfortunately it is way too slow for my data.

Did not know about glmmTMB, will try it out. Does it work with crossed 
random effects and how does it scale with more data? I will check the 
docu and try it though. Thanks for the info.

On 23.06.2016 19:14, Ben Bolker wrote:
>    I would also comment that glmmTMB is likely to be much faster than the
> lme4-based EM approach ...
>
>    cheers
>      Ben B.
>
> On 16-06-23 12:47 PM, Mollie Brooks wrote:
>> Hi Philipp,
>>
>> You could also try fitting the model with and without ZI using either
>> glmmADMB or glmmTMB. Then compare the AICs. I believe model selection
>> is useful for this, but I could be missing something since the
>> simulation procedure that Thierry described seems to recommended more
>> often.
>>
>> https://github.com/glmmTMB/glmmTMB
>> http://glmmadmb.r-forge.r-project.org
>>
>> glmmTMB is still in the development phase, but we?ve done a lot of
>> testing.
>>
>> cheers, Mollie
>>
>> ------------------------ Mollie Brooks, PhD Postdoctoral Researcher,
>> Population Ecology Research Group Department of Evolutionary Biology
>> & Environmental Studies, University of Z?rich
>> http://www.popecol.org/team/mollie-brooks/
>>
>>
>>> On 23Jun 2016, at 8:22, Philipp Singer <killver at gmail.com> wrote:
>>>
>>> Thanks, great information, that is really helpful.
>>>
>>> I agree that those are different things, however when using a
>>> random effect for overdispersion, I can simulate the same number of
>>> zero outcomes (~95%).
>>>
>>> On 23.06.2016 15:50, Thierry Onkelinx wrote:
>>>> Be careful when using overdispersion to model zero-inflation.
>>>> Those are two different things.
>>>>
>>>> I've put some information together in
>>>> http://rpubs.com/INBOstats/zeroinflation
>>>>
>>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
>>>> Research Institute for Nature and Forest team Biometrie &
>>>> Kwaliteitszorg / team Biometrics & Quality Assurance
>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>>>
>>>> To call in the statistician after the experiment is done may be
>>>> no more than asking him to perform a post-mortem examination: he
>>>> may be able to say what the experiment died of. ~ Sir Ronald
>>>> Aylmer Fisher The plural of anecdote is not data. ~ Roger
>>>> Brinner The combination of some data and an aching desire for an
>>>> answer does not ensure that a reasonable answer can be extracted
>>>> from a given body of data. ~ John Tukey
>>>>
>>>> 2016-06-23 12:42 GMT+02:00 Philipp Singer <killver at gmail.com
>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>>:
>>>>
>>>> Thanks! Actually, accounting for overdispersion is super
>>>> important as it seems, then the zeros can be captured well.
>>>>
>>>>
>>>> On 23.06.2016 11:50, Thierry Onkelinx wrote:
>>>>> Dear Philipp,
>>>>>
>>>>> 1. Fit a Poisson model to the data. 2. Simulate a new response
>>>>> vector for the dataset according to the model. 3. Count the
>>>>> number of zero's in the simulated response vector. 4. Repeat
>>>>> step 2 and 3 a decent number of time and plot a histogram of
>>>>> the number of zero's in the simulation. If the number of zero's
>>>>> in the original dataset is larger than those in the
>>>>> simulations, then the model can't capture all zero's. In such
>>>>> case, first try to update the model and repeat the procedure.
>>>>> If that fails, look for zero-inflated models.
>>>>>
>>>>> Best regards,
>>>>>
>>>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
>>>>> Research Institute for Nature and Forest team Biometrie &
>>>>> Kwaliteitszorg / team Biometrics & Quality Assurance
>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>>>>
>>>>> To call in the statistician after the experiment is done may
>>>>> be no more than asking him to perform a post-mortem
>>>>> examination: he may be able to say what the experiment died of.
>>>>> ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data.
>>>>> ~ Roger Brinner The combination of some data and an aching
>>>>> desire for an answer does not ensure that a reasonable answer
>>>>> can be extracted from a given body of data. ~ John Tukey
>>>>>
>>>>> 2016-06-23 11:27 GMT+02:00 Philipp Singer <killver at gmail.com
>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>>:
>>>>>
>>>>> Thanks Thierry - That totally makes sense. Is there some way of
>>>>> formally checking that, except thinking about the setting and
>>>>> underlying processes?
>>>>>
>>>>> On 23.06.2016 11:04, Thierry Onkelinx wrote:
>>>>>> Dear Philipp,
>>>>>>
>>>>>> Do you have just lots of zero's, or more zero's than the
>>>>> Poisson
>>>>>> distribution can explain? Those are two different things.
>>>>> The example
>>>>>> below generates data from a Poisson distribution and has
>>>>> 99% zero's
>>>>>> but no zero-inflation. The second example has only 1%
>>>>> zero's but is
>>>>>> clearly zero-inflated.
>>>>>>
>>>>>> set.seed(1) n <- 1e8 sim <- rpois(n, lambda = 0.01) mean(sim
>>>>>> == 0) hist(sim)
>>>>>>
>>>>>> sim.infl <- rbinom(n, size = 1, prob = 0.99) * rpois(n,
>>>>> lambda = 1000)
>>>>>> mean(sim.infl == 0) hist(sim.infl)
>>>>>>
>>>>>> So before looking for zero-inflated models, try to model
>>>>> the zero's.
>>>>>> Best regards,
>>>>>>
>>>>>>
>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
>>>>>> Research Institute
>>>>> for Nature
>>>>>> and Forest team Biometrie & Kwaliteitszorg / team Biometrics
>>>>>> & Quality
>>>>> Assurance
>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>>>>>
>>>>>> To call in the statistician after the experiment is done
>>>>> may be no
>>>>>> more than asking him to perform a post-mortem examination:
>>>>> he may be
>>>>>> able to say what the experiment died of. ~ Sir Ronald
>>>>> Aylmer Fisher
>>>>>> The plural of anecdote is not data. ~ Roger Brinner The
>>>>>> combination of some data and an aching desire for an
>>>>> answer does
>>>>>> not ensure that a reasonable answer can be extracted from a
>>>>> given body
>>>>>> of data. ~ John Tukey
>>>>>>
>>>>>> 2016-06-23 10:07 GMT+02:00 Philipp Singer
>>>>> <killver at gmail.com <mailto:killver at gmail.com>
>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>
>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>
>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>>>:
>>>>>>
>>>>>> Dear group - I am currently fitting a Poisson glmer
>>>>> where I have
>>>>>> an excess of outcomes that are zero (>95%). I am now
>>>>> debating on
>>>>>> how to proceed and came up with three options:
>>>>>>
>>>>>> 1.) Just fit a regular glmer to the complete data. I am
>>>>> not fully
>>>>>> sure how interpret the coefficients then, are they more
>>>>> optimizing
>>>>>> towards distinguishing zero and non-zero, or also
>>>>> capturing the
>>>>>> differences in those outcomes that are non-zero?
>>>>>>
>>>>>> 2.) Leave all zeros out of the data and fit a glmer to
>>>>> only those
>>>>>> outcomes that are non-zero. Then, I would only learn about
>>>>>> differences in the non-zero outcomes though.
>>>>>>
>>>>>> 3.) Use a zero-inflated Poisson model. My data is quite
>>>>>> large-scale, so I am currently playing around with the EM
>>>>>> implementation of Bolker et al. that alternates between
>>>>> fitting a
>>>>>> glmer with data that are weighted according to their zero
>>>>>> probability, and fitting a logistic regression for the
>>>>> probability
>>>>>> that a data point is zero. The method is elaborated for
>>>>> the OWL
>>>>>> data in:
>>>>>>
>>>>> https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
>>>>> <https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf>
>>>>>>
> I am not fully sure how to interpret the results for the
>>>>>> zero-inflated version though. Would I need to interpret the
>>>>>> coefficients for the result of the glmer similar to as
>>>>> I would do
>>>>>> for my idea of 2)? And then on top of that interpret the
>>>>>> coefficients for the logistic regression regarding whether
>>>>>> something is in the perfect or imperfect state? I am
>>>>> also not
>>>>>> quite sure what the common approach for the zformula is
>>>>> here. The
>>>>>> OWL elaborations only use zformula=z~1, so no random
>>>>> effect; I
>>>>>> would use the same formula as for the glmer.
>>>>>>
>>>>>> I am appreciating some help and pointers.
>>>>>>
>>>>>> Thanks! Philipp
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org
>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>>> <mailto:R-sig-mixed-models at r-project.org
>>>>> <mailto:R-sig-mixed-models at r-project.org>>
>>>>>> <mailto:R-sig-mixed-models at r-project.org
>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>>> <mailto:R-sig-mixed-models at r-project.org
>>>>> <mailto:R-sig-mixed-models at r-project.org>>> mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>>
>>>>>>
>>>>>
>>>>> [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org
>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>>> <mailto:R-sig-mixed-models at r-project.org
>>>>> <mailto:R-sig-mixed-models at r-project.org>> mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>
>>>>>
>>>>
>>>
>>> [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org
>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>> [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From mbrooks at ufl.edu  Thu Jun 23 23:07:29 2016
From: mbrooks at ufl.edu (Mollie Brooks)
Date: Thu, 23 Jun 2016 14:07:29 -0700
Subject: [R-sig-ME] Question about zero-inflated Poisson glmer
In-Reply-To: <576C200A.1050405@gmail.com>
References: <576B98C4.6000602@gmail.com>
	<CAJuCY5xbiEjCmHjc_3wX2emzJ3NEMTA_qKgC_reWn=zqC7YEng@mail.gmail.com>
	<576BAB84.6080009@gmail.com>
	<CAJuCY5zmK1xCyWOwcCH+Hch_LSdB+AazmUDuPVP6je7ABFU5FA@mail.gmail.com>
	<576BBCFD.8040806@gmail.com>
	<CAJuCY5ycRL6oXs=H5JrEqOHWzd1UsvSNVZM6-MK+V2N=pvbyQA@mail.gmail.com>
	<576BFEBC.3020407@gmail.com>
	<B5AEF3F5-949F-4686-82DA-C234C3C4018B@ufl.edu>
	<576C18F9.9010200@gmail.com> <576C200A.1050405@gmail.com>
Message-ID: <4D07695C-8CEA-4785-A5B0-46B011625DA0@ufl.edu>

glmmTMB does crossed RE. Ben did some timings in vignette("glmmTMB") and it was 2.3 times faster than glmer for one simple GLMM.


> On 23Jun 2016, at 10:44, Philipp Singer <killver at gmail.com> wrote:
> 
> Did try glmmADMB but unfortunately it is way too slow for my data.
> 
> Did not know about glmmTMB, will try it out. Does it work with crossed random effects and how does it scale with more data? I will check the docu and try it though. Thanks for the info.
> 
> On 23.06.2016 19:14, Ben Bolker wrote:
>>   I would also comment that glmmTMB is likely to be much faster than the
>> lme4-based EM approach ...
>> 
>>   cheers
>>     Ben B.
>> 
>> On 16-06-23 12:47 PM, Mollie Brooks wrote:
>>> Hi Philipp,
>>> 
>>> You could also try fitting the model with and without ZI using either
>>> glmmADMB or glmmTMB. Then compare the AICs. I believe model selection
>>> is useful for this, but I could be missing something since the
>>> simulation procedure that Thierry described seems to recommended more
>>> often.
>>> 
>>> https://github.com/glmmTMB/glmmTMB
>>> http://glmmadmb.r-forge.r-project.org
>>> 
>>> glmmTMB is still in the development phase, but we?ve done a lot of
>>> testing.
>>> 
>>> cheers, Mollie
>>> 
>>> ------------------------ Mollie Brooks, PhD Postdoctoral Researcher,
>>> Population Ecology Research Group Department of Evolutionary Biology
>>> & Environmental Studies, University of Z?rich
>>> http://www.popecol.org/team/mollie-brooks/
>>> 
>>> 
>>>> On 23Jun 2016, at 8:22, Philipp Singer <killver at gmail.com> wrote:
>>>> 
>>>> Thanks, great information, that is really helpful.
>>>> 
>>>> I agree that those are different things, however when using a
>>>> random effect for overdispersion, I can simulate the same number of
>>>> zero outcomes (~95%).
>>>> 
>>>> On 23.06.2016 15:50, Thierry Onkelinx wrote:
>>>>> Be careful when using overdispersion to model zero-inflation.
>>>>> Those are two different things.
>>>>> 
>>>>> I've put some information together in
>>>>> http://rpubs.com/INBOstats/zeroinflation
>>>>> 
>>>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
>>>>> Research Institute for Nature and Forest team Biometrie &
>>>>> Kwaliteitszorg / team Biometrics & Quality Assurance
>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>>>> 
>>>>> To call in the statistician after the experiment is done may be
>>>>> no more than asking him to perform a post-mortem examination: he
>>>>> may be able to say what the experiment died of. ~ Sir Ronald
>>>>> Aylmer Fisher The plural of anecdote is not data. ~ Roger
>>>>> Brinner The combination of some data and an aching desire for an
>>>>> answer does not ensure that a reasonable answer can be extracted
>>>>> from a given body of data. ~ John Tukey
>>>>> 
>>>>> 2016-06-23 12:42 GMT+02:00 Philipp Singer <killver at gmail.com
>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>>:
>>>>> 
>>>>> Thanks! Actually, accounting for overdispersion is super
>>>>> important as it seems, then the zeros can be captured well.
>>>>> 
>>>>> 
>>>>> On 23.06.2016 11:50, Thierry Onkelinx wrote:
>>>>>> Dear Philipp,
>>>>>> 
>>>>>> 1. Fit a Poisson model to the data. 2. Simulate a new response
>>>>>> vector for the dataset according to the model. 3. Count the
>>>>>> number of zero's in the simulated response vector. 4. Repeat
>>>>>> step 2 and 3 a decent number of time and plot a histogram of
>>>>>> the number of zero's in the simulation. If the number of zero's
>>>>>> in the original dataset is larger than those in the
>>>>>> simulations, then the model can't capture all zero's. In such
>>>>>> case, first try to update the model and repeat the procedure.
>>>>>> If that fails, look for zero-inflated models.
>>>>>> 
>>>>>> Best regards,
>>>>>> 
>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
>>>>>> Research Institute for Nature and Forest team Biometrie &
>>>>>> Kwaliteitszorg / team Biometrics & Quality Assurance
>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>>>>> 
>>>>>> To call in the statistician after the experiment is done may
>>>>>> be no more than asking him to perform a post-mortem
>>>>>> examination: he may be able to say what the experiment died of.
>>>>>> ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data.
>>>>>> ~ Roger Brinner The combination of some data and an aching
>>>>>> desire for an answer does not ensure that a reasonable answer
>>>>>> can be extracted from a given body of data. ~ John Tukey
>>>>>> 
>>>>>> 2016-06-23 11:27 GMT+02:00 Philipp Singer <killver at gmail.com
>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>>:
>>>>>> 
>>>>>> Thanks Thierry - That totally makes sense. Is there some way of
>>>>>> formally checking that, except thinking about the setting and
>>>>>> underlying processes?
>>>>>> 
>>>>>> On 23.06.2016 11:04, Thierry Onkelinx wrote:
>>>>>>> Dear Philipp,
>>>>>>> 
>>>>>>> Do you have just lots of zero's, or more zero's than the
>>>>>> Poisson
>>>>>>> distribution can explain? Those are two different things.
>>>>>> The example
>>>>>>> below generates data from a Poisson distribution and has
>>>>>> 99% zero's
>>>>>>> but no zero-inflation. The second example has only 1%
>>>>>> zero's but is
>>>>>>> clearly zero-inflated.
>>>>>>> 
>>>>>>> set.seed(1) n <- 1e8 sim <- rpois(n, lambda = 0.01) mean(sim
>>>>>>> == 0) hist(sim)
>>>>>>> 
>>>>>>> sim.infl <- rbinom(n, size = 1, prob = 0.99) * rpois(n,
>>>>>> lambda = 1000)
>>>>>>> mean(sim.infl == 0) hist(sim.infl)
>>>>>>> 
>>>>>>> So before looking for zero-inflated models, try to model
>>>>>> the zero's.
>>>>>>> Best regards,
>>>>>>> 
>>>>>>> 
>>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
>>>>>>> Research Institute
>>>>>> for Nature
>>>>>>> and Forest team Biometrie & Kwaliteitszorg / team Biometrics
>>>>>>> & Quality
>>>>>> Assurance
>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>>>>>> 
>>>>>>> To call in the statistician after the experiment is done
>>>>>> may be no
>>>>>>> more than asking him to perform a post-mortem examination:
>>>>>> he may be
>>>>>>> able to say what the experiment died of. ~ Sir Ronald
>>>>>> Aylmer Fisher
>>>>>>> The plural of anecdote is not data. ~ Roger Brinner The
>>>>>>> combination of some data and an aching desire for an
>>>>>> answer does
>>>>>>> not ensure that a reasonable answer can be extracted from a
>>>>>> given body
>>>>>>> of data. ~ John Tukey
>>>>>>> 
>>>>>>> 2016-06-23 10:07 GMT+02:00 Philipp Singer
>>>>>> <killver at gmail.com <mailto:killver at gmail.com>
>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>
>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>
>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>>>:
>>>>>>> 
>>>>>>> Dear group - I am currently fitting a Poisson glmer
>>>>>> where I have
>>>>>>> an excess of outcomes that are zero (>95%). I am now
>>>>>> debating on
>>>>>>> how to proceed and came up with three options:
>>>>>>> 
>>>>>>> 1.) Just fit a regular glmer to the complete data. I am
>>>>>> not fully
>>>>>>> sure how interpret the coefficients then, are they more
>>>>>> optimizing
>>>>>>> towards distinguishing zero and non-zero, or also
>>>>>> capturing the
>>>>>>> differences in those outcomes that are non-zero?
>>>>>>> 
>>>>>>> 2.) Leave all zeros out of the data and fit a glmer to
>>>>>> only those
>>>>>>> outcomes that are non-zero. Then, I would only learn about
>>>>>>> differences in the non-zero outcomes though.
>>>>>>> 
>>>>>>> 3.) Use a zero-inflated Poisson model. My data is quite
>>>>>>> large-scale, so I am currently playing around with the EM
>>>>>>> implementation of Bolker et al. that alternates between
>>>>>> fitting a
>>>>>>> glmer with data that are weighted according to their zero
>>>>>>> probability, and fitting a logistic regression for the
>>>>>> probability
>>>>>>> that a data point is zero. The method is elaborated for
>>>>>> the OWL
>>>>>>> data in:
>>>>>>> 
>>>>>> https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
>>>>>> <https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf>
>>>>>>> 
>> I am not fully sure how to interpret the results for the
>>>>>>> zero-inflated version though. Would I need to interpret the
>>>>>>> coefficients for the result of the glmer similar to as
>>>>>> I would do
>>>>>>> for my idea of 2)? And then on top of that interpret the
>>>>>>> coefficients for the logistic regression regarding whether
>>>>>>> something is in the perfect or imperfect state? I am
>>>>>> also not
>>>>>>> quite sure what the common approach for the zformula is
>>>>>> here. The
>>>>>>> OWL elaborations only use zformula=z~1, so no random
>>>>>> effect; I
>>>>>>> would use the same formula as for the glmer.
>>>>>>> 
>>>>>>> I am appreciating some help and pointers.
>>>>>>> 
>>>>>>> Thanks! Philipp
>>>>>>> 
>>>>>>> _______________________________________________
>>>>>>> R-sig-mixed-models at r-project.org
>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>>>> <mailto:R-sig-mixed-models at r-project.org
>>>>>> <mailto:R-sig-mixed-models at r-project.org>>
>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>>>> <mailto:R-sig-mixed-models at r-project.org
>>>>>> <mailto:R-sig-mixed-models at r-project.org>>> mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>>> 
>>>>>>> 
>>>>>> 
>>>>>> [[alternative HTML version deleted]]
>>>>>> 
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org
>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>>>> <mailto:R-sig-mixed-models at r-project.org
>>>>>> <mailto:R-sig-mixed-models at r-project.org>> mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>> 
>>>>>> 
>>>>> 
>>>> 
>>>> [[alternative HTML version deleted]]
>>>> 
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org
>>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>> [[alternative HTML version deleted]]
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From killver at gmail.com  Fri Jun 24 14:35:22 2016
From: killver at gmail.com (Philipp Singer)
Date: Fri, 24 Jun 2016 14:35:22 +0200
Subject: [R-sig-ME] Question about zero-inflated Poisson glmer
In-Reply-To: <4D07695C-8CEA-4785-A5B0-46B011625DA0@ufl.edu>
References: <576B98C4.6000602@gmail.com>
	<CAJuCY5xbiEjCmHjc_3wX2emzJ3NEMTA_qKgC_reWn=zqC7YEng@mail.gmail.com>
	<576BAB84.6080009@gmail.com>
	<CAJuCY5zmK1xCyWOwcCH+Hch_LSdB+AazmUDuPVP6je7ABFU5FA@mail.gmail.com>
	<576BBCFD.8040806@gmail.com>
	<CAJuCY5ycRL6oXs=H5JrEqOHWzd1UsvSNVZM6-MK+V2N=pvbyQA@mail.gmail.com>
	<576BFEBC.3020407@gmail.com>
	<B5AEF3F5-949F-4686-82DA-C234C3C4018B@ufl.edu>
	<576C18F9.9010200@gmail.com> <576C200A.1050405@gmail.com>
	<4D07695C-8CEA-4785-A5B0-46B011625DA0@ufl.edu>
Message-ID: <576D290A.7090102@gmail.com>

It indeed seems to run quite fast; had some trouble installing, but 
works now on my 3.3 R setup.

One question I have is regarding the specification of dispersion as I 
need to specify the dispformula. What is the difference here between 
just specifying fixed effects vs. also the random effects?

On 23.06.2016 23:07, Mollie Brooks wrote:
> glmmTMB does crossed RE. Ben did some timings in vignette("glmmTMB") 
> and it was 2.3 times faster than glmer for one simple GLMM.
>
>
>> On 23Jun 2016, at 10:44, Philipp Singer <killver at gmail.com 
>> <mailto:killver at gmail.com>> wrote:
>>
>> Did try glmmADMB but unfortunately it is way too slow for my data.
>>
>> Did not know about glmmTMB, will try it out. Does it work with 
>> crossed random effects and how does it scale with more data? I will 
>> check the docu and try it though. Thanks for the info.
>>
>> On 23.06.2016 19:14, Ben Bolker wrote:
>>>   I would also comment that glmmTMB is likely to be much faster than the
>>> lme4-based EM approach ...
>>>
>>>   cheers
>>>     Ben B.
>>>
>>> On 16-06-23 12:47 PM, Mollie Brooks wrote:
>>>> Hi Philipp,
>>>>
>>>> You could also try fitting the model with and without ZI using either
>>>> glmmADMB or glmmTMB. Then compare the AICs. I believe model selection
>>>> is useful for this, but I could be missing something since the
>>>> simulation procedure that Thierry described seems to recommended more
>>>> often.
>>>>
>>>> https://github.com/glmmTMB/glmmTMB
>>>> http://glmmadmb.r-forge.r-project.org
>>>>
>>>> glmmTMB is still in the development phase, but we?ve done a lot of
>>>> testing.
>>>>
>>>> cheers, Mollie
>>>>
>>>> ------------------------ Mollie Brooks, PhD Postdoctoral Researcher,
>>>> Population Ecology Research Group Department of Evolutionary Biology
>>>> & Environmental Studies, University of Z?rich
>>>> http://www.popecol.org/team/mollie-brooks/
>>>>
>>>>
>>>>> On 23Jun 2016, at 8:22, Philipp Singer <killver at gmail.com> wrote:
>>>>>
>>>>> Thanks, great information, that is really helpful.
>>>>>
>>>>> I agree that those are different things, however when using a
>>>>> random effect for overdispersion, I can simulate the same number of
>>>>> zero outcomes (~95%).
>>>>>
>>>>> On 23.06.2016 15:50, Thierry Onkelinx wrote:
>>>>>> Be careful when using overdispersion to model zero-inflation.
>>>>>> Those are two different things.
>>>>>>
>>>>>> I've put some information together in
>>>>>> http://rpubs.com/INBOstats/zeroinflation
>>>>>>
>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
>>>>>> Research Institute for Nature and Forest team Biometrie &
>>>>>> Kwaliteitszorg / team Biometrics & Quality Assurance
>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>>>>>
>>>>>> To call in the statistician after the experiment is done may be
>>>>>> no more than asking him to perform a post-mortem examination: he
>>>>>> may be able to say what the experiment died of. ~ Sir Ronald
>>>>>> Aylmer Fisher The plural of anecdote is not data. ~ Roger
>>>>>> Brinner The combination of some data and an aching desire for an
>>>>>> answer does not ensure that a reasonable answer can be extracted
>>>>>> from a given body of data. ~ John Tukey
>>>>>>
>>>>>> 2016-06-23 12:42 GMT+02:00 Philipp Singer <killver at gmail.com
>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>>:
>>>>>>
>>>>>> Thanks! Actually, accounting for overdispersion is super
>>>>>> important as it seems, then the zeros can be captured well.
>>>>>>
>>>>>>
>>>>>> On 23.06.2016 11:50, Thierry Onkelinx wrote:
>>>>>>> Dear Philipp,
>>>>>>>
>>>>>>> 1. Fit a Poisson model to the data. 2. Simulate a new response
>>>>>>> vector for the dataset according to the model. 3. Count the
>>>>>>> number of zero's in the simulated response vector. 4. Repeat
>>>>>>> step 2 and 3 a decent number of time and plot a histogram of
>>>>>>> the number of zero's in the simulation. If the number of zero's
>>>>>>> in the original dataset is larger than those in the
>>>>>>> simulations, then the model can't capture all zero's. In such
>>>>>>> case, first try to update the model and repeat the procedure.
>>>>>>> If that fails, look for zero-inflated models.
>>>>>>>
>>>>>>> Best regards,
>>>>>>>
>>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
>>>>>>> Research Institute for Nature and Forest team Biometrie &
>>>>>>> Kwaliteitszorg / team Biometrics & Quality Assurance
>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>>>>>>
>>>>>>> To call in the statistician after the experiment is done may
>>>>>>> be no more than asking him to perform a post-mortem
>>>>>>> examination: he may be able to say what the experiment died of.
>>>>>>> ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data.
>>>>>>> ~ Roger Brinner The combination of some data and an aching
>>>>>>> desire for an answer does not ensure that a reasonable answer
>>>>>>> can be extracted from a given body of data. ~ John Tukey
>>>>>>>
>>>>>>> 2016-06-23 11:27 GMT+02:00 Philipp Singer <killver at gmail.com
>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>>:
>>>>>>>
>>>>>>> Thanks Thierry - That totally makes sense. Is there some way of
>>>>>>> formally checking that, except thinking about the setting and
>>>>>>> underlying processes?
>>>>>>>
>>>>>>> On 23.06.2016 11:04, Thierry Onkelinx wrote:
>>>>>>>> Dear Philipp,
>>>>>>>>
>>>>>>>> Do you have just lots of zero's, or more zero's than the
>>>>>>> Poisson
>>>>>>>> distribution can explain? Those are two different things.
>>>>>>> The example
>>>>>>>> below generates data from a Poisson distribution and has
>>>>>>> 99% zero's
>>>>>>>> but no zero-inflation. The second example has only 1%
>>>>>>> zero's but is
>>>>>>>> clearly zero-inflated.
>>>>>>>>
>>>>>>>> set.seed(1) n <- 1e8 sim <- rpois(n, lambda = 0.01) mean(sim
>>>>>>>> == 0) hist(sim)
>>>>>>>>
>>>>>>>> sim.infl <- rbinom(n, size = 1, prob = 0.99) * rpois(n,
>>>>>>> lambda = 1000)
>>>>>>>> mean(sim.infl == 0) hist(sim.infl)
>>>>>>>>
>>>>>>>> So before looking for zero-inflated models, try to model
>>>>>>> the zero's.
>>>>>>>> Best regards,
>>>>>>>>
>>>>>>>>
>>>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
>>>>>>>> Research Institute
>>>>>>> for Nature
>>>>>>>> and Forest team Biometrie & Kwaliteitszorg / team Biometrics
>>>>>>>> & Quality
>>>>>>> Assurance
>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>>>>>>>
>>>>>>>> To call in the statistician after the experiment is done
>>>>>>> may be no
>>>>>>>> more than asking him to perform a post-mortem examination:
>>>>>>> he may be
>>>>>>>> able to say what the experiment died of. ~ Sir Ronald
>>>>>>> Aylmer Fisher
>>>>>>>> The plural of anecdote is not data. ~ Roger Brinner The
>>>>>>>> combination of some data and an aching desire for an
>>>>>>> answer does
>>>>>>>> not ensure that a reasonable answer can be extracted from a
>>>>>>> given body
>>>>>>>> of data. ~ John Tukey
>>>>>>>>
>>>>>>>> 2016-06-23 10:07 GMT+02:00 Philipp Singer
>>>>>>> <killver at gmail.com <mailto:killver at gmail.com>
>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>
>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>
>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>>>:
>>>>>>>>
>>>>>>>> Dear group - I am currently fitting a Poisson glmer
>>>>>>> where I have
>>>>>>>> an excess of outcomes that are zero (>95%). I am now
>>>>>>> debating on
>>>>>>>> how to proceed and came up with three options:
>>>>>>>>
>>>>>>>> 1.) Just fit a regular glmer to the complete data. I am
>>>>>>> not fully
>>>>>>>> sure how interpret the coefficients then, are they more
>>>>>>> optimizing
>>>>>>>> towards distinguishing zero and non-zero, or also
>>>>>>> capturing the
>>>>>>>> differences in those outcomes that are non-zero?
>>>>>>>>
>>>>>>>> 2.) Leave all zeros out of the data and fit a glmer to
>>>>>>> only those
>>>>>>>> outcomes that are non-zero. Then, I would only learn about
>>>>>>>> differences in the non-zero outcomes though.
>>>>>>>>
>>>>>>>> 3.) Use a zero-inflated Poisson model. My data is quite
>>>>>>>> large-scale, so I am currently playing around with the EM
>>>>>>>> implementation of Bolker et al. that alternates between
>>>>>>> fitting a
>>>>>>>> glmer with data that are weighted according to their zero
>>>>>>>> probability, and fitting a logistic regression for the
>>>>>>> probability
>>>>>>>> that a data point is zero. The method is elaborated for
>>>>>>> the OWL
>>>>>>>> data in:
>>>>>>>>
>>>>>>> https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
>>>>>>> <https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf>
>>>>>>>>
>>> I am not fully sure how to interpret the results for the
>>>>>>>> zero-inflated version though. Would I need to interpret the
>>>>>>>> coefficients for the result of the glmer similar to as
>>>>>>> I would do
>>>>>>>> for my idea of 2)? And then on top of that interpret the
>>>>>>>> coefficients for the logistic regression regarding whether
>>>>>>>> something is in the perfect or imperfect state? I am
>>>>>>> also not
>>>>>>>> quite sure what the common approach for the zformula is
>>>>>>> here. The
>>>>>>>> OWL elaborations only use zformula=z~1, so no random
>>>>>>> effect; I
>>>>>>>> would use the same formula as for the glmer.
>>>>>>>>
>>>>>>>> I am appreciating some help and pointers.
>>>>>>>>
>>>>>>>> Thanks! Philipp
>>>>>>>>
>>>>>>>> _______________________________________________
>>>>>>>> R-sig-mixed-models at r-project.org 
>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>>>>>>> <mailto:R-sig-mixed-models at r-project.org>>
>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>>>>>>> <mailto:R-sig-mixed-models at r-project.org>>> mailing list
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>>>>
>>>>>>>>
>>>>>>>
>>>>>>> [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> _______________________________________________
>>>>>>> R-sig-mixed-models at r-project.org 
>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>>>>>>> <mailto:R-sig-mixed-models at r-project.org>> mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>>>
>>>>>>>
>>>>>>
>>>>>
>>>>> [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org 
>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>> [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org 
>>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org 
>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org 
>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


	[[alternative HTML version deleted]]


From killver at gmail.com  Fri Jun 24 15:13:45 2016
From: killver at gmail.com (Philipp Singer)
Date: Fri, 24 Jun 2016 15:13:45 +0200
Subject: [R-sig-ME] Question about zero-inflated Poisson glmer
In-Reply-To: <576D290A.7090102@gmail.com>
References: <576B98C4.6000602@gmail.com>
	<CAJuCY5xbiEjCmHjc_3wX2emzJ3NEMTA_qKgC_reWn=zqC7YEng@mail.gmail.com>
	<576BAB84.6080009@gmail.com>
	<CAJuCY5zmK1xCyWOwcCH+Hch_LSdB+AazmUDuPVP6je7ABFU5FA@mail.gmail.com>
	<576BBCFD.8040806@gmail.com>
	<CAJuCY5ycRL6oXs=H5JrEqOHWzd1UsvSNVZM6-MK+V2N=pvbyQA@mail.gmail.com>
	<576BFEBC.3020407@gmail.com>
	<B5AEF3F5-949F-4686-82DA-C234C3C4018B@ufl.edu>
	<576C18F9.9010200@gmail.com> <576C200A.1050405@gmail.com>
	<4D07695C-8CEA-4785-A5B0-46B011625DA0@ufl.edu>
	<576D290A.7090102@gmail.com>
Message-ID: <576D3209.6050507@gmail.com>

Update, I tried it like that, but receive an error message.

Warning message:
In nlminb(start = par, objective = fn, gradient = gr): NA/NaN function evaluation

Error in solve.default(hessian.fixed): Lapack routine dgesv: system is exactly singular: U[3,3] = 0
Traceback:

1. glmmTMB(y ~ 1 + x + (1 | b),
  .     data = data, family = "poisson", dispformula = ~1 + x)
2. sdreport(obj)
3. solve(hessian.fixed)
4. solve(hessian.fixed)
5. solve.default(hessian.fixed)

Any ideas on that?

BTW: Is it fine to post glmmTMB questions here, or should I rather use 
the github issue page, or is there maybe a dedicated mailing list?

Thanks,
Philipp

On 24.06.2016 14:35, Philipp Singer wrote:
> It indeed seems to run quite fast; had some trouble installing, but 
> works now on my 3.3 R setup.
>
> One question I have is regarding the specification of dispersion as I 
> need to specify the dispformula. What is the difference here between 
> just specifying fixed effects vs. also the random effects?
>
> On 23.06.2016 23:07, Mollie Brooks wrote:
>> glmmTMB does crossed RE. Ben did some timings in vignette("glmmTMB") 
>> and it was 2.3 times faster than glmer for one simple GLMM.
>>
>>
>>> On 23Jun 2016, at 10:44, Philipp Singer <killver at gmail.com> wrote:
>>>
>>> Did try glmmADMB but unfortunately it is way too slow for my data.
>>>
>>> Did not know about glmmTMB, will try it out. Does it work with 
>>> crossed random effects and how does it scale with more data? I will 
>>> check the docu and try it though. Thanks for the info.
>>>
>>> On 23.06.2016 19:14, Ben Bolker wrote:
>>>>   I would also comment that glmmTMB is likely to be much faster 
>>>> than the
>>>> lme4-based EM approach ...
>>>>
>>>>   cheers
>>>>     Ben B.
>>>>
>>>> On 16-06-23 12:47 PM, Mollie Brooks wrote:
>>>>> Hi Philipp,
>>>>>
>>>>> You could also try fitting the model with and without ZI using either
>>>>> glmmADMB or glmmTMB. Then compare the AICs. I believe model selection
>>>>> is useful for this, but I could be missing something since the
>>>>> simulation procedure that Thierry described seems to recommended more
>>>>> often.
>>>>>
>>>>> https://github.com/glmmTMB/glmmTMB
>>>>> http://glmmadmb.r-forge.r-project.org
>>>>>
>>>>> glmmTMB is still in the development phase, but we?ve done a lot of
>>>>> testing.
>>>>>
>>>>> cheers, Mollie
>>>>>
>>>>> ------------------------ Mollie Brooks, PhD Postdoctoral Researcher,
>>>>> Population Ecology Research Group Department of Evolutionary Biology
>>>>> & Environmental Studies, University of Z?rich
>>>>> http://www.popecol.org/team/mollie-brooks/
>>>>>
>>>>>
>>>>>> On 23Jun 2016, at 8:22, Philipp Singer <killver at gmail.com> wrote:
>>>>>>
>>>>>> Thanks, great information, that is really helpful.
>>>>>>
>>>>>> I agree that those are different things, however when using a
>>>>>> random effect for overdispersion, I can simulate the same number of
>>>>>> zero outcomes (~95%).
>>>>>>
>>>>>> On 23.06.2016 15:50, Thierry Onkelinx wrote:
>>>>>>> Be careful when using overdispersion to model zero-inflation.
>>>>>>> Those are two different things.
>>>>>>>
>>>>>>> I've put some information together in
>>>>>>> http://rpubs.com/INBOstats/zeroinflation
>>>>>>>
>>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
>>>>>>> Research Institute for Nature and Forest team Biometrie &
>>>>>>> Kwaliteitszorg / team Biometrics & Quality Assurance
>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>>>>>>
>>>>>>> To call in the statistician after the experiment is done may be
>>>>>>> no more than asking him to perform a post-mortem examination: he
>>>>>>> may be able to say what the experiment died of. ~ Sir Ronald
>>>>>>> Aylmer Fisher The plural of anecdote is not data. ~ Roger
>>>>>>> Brinner The combination of some data and an aching desire for an
>>>>>>> answer does not ensure that a reasonable answer can be extracted
>>>>>>> from a given body of data. ~ John Tukey
>>>>>>>
>>>>>>> 2016-06-23 12:42 GMT+02:00 Philipp Singer <killver at gmail.com
>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>>:
>>>>>>>
>>>>>>> Thanks! Actually, accounting for overdispersion is super
>>>>>>> important as it seems, then the zeros can be captured well.
>>>>>>>
>>>>>>>
>>>>>>> On 23.06.2016 11:50, Thierry Onkelinx wrote:
>>>>>>>> Dear Philipp,
>>>>>>>>
>>>>>>>> 1. Fit a Poisson model to the data. 2. Simulate a new response
>>>>>>>> vector for the dataset according to the model. 3. Count the
>>>>>>>> number of zero's in the simulated response vector. 4. Repeat
>>>>>>>> step 2 and 3 a decent number of time and plot a histogram of
>>>>>>>> the number of zero's in the simulation. If the number of zero's
>>>>>>>> in the original dataset is larger than those in the
>>>>>>>> simulations, then the model can't capture all zero's. In such
>>>>>>>> case, first try to update the model and repeat the procedure.
>>>>>>>> If that fails, look for zero-inflated models.
>>>>>>>>
>>>>>>>> Best regards,
>>>>>>>>
>>>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
>>>>>>>> Research Institute for Nature and Forest team Biometrie &
>>>>>>>> Kwaliteitszorg / team Biometrics & Quality Assurance
>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>>>>>>>
>>>>>>>> To call in the statistician after the experiment is done may
>>>>>>>> be no more than asking him to perform a post-mortem
>>>>>>>> examination: he may be able to say what the experiment died of.
>>>>>>>> ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data.
>>>>>>>> ~ Roger Brinner The combination of some data and an aching
>>>>>>>> desire for an answer does not ensure that a reasonable answer
>>>>>>>> can be extracted from a given body of data. ~ John Tukey
>>>>>>>>
>>>>>>>> 2016-06-23 11:27 GMT+02:00 Philipp Singer <killver at gmail.com
>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>>:
>>>>>>>>
>>>>>>>> Thanks Thierry - That totally makes sense. Is there some way of
>>>>>>>> formally checking that, except thinking about the setting and
>>>>>>>> underlying processes?
>>>>>>>>
>>>>>>>> On 23.06.2016 11:04, Thierry Onkelinx wrote:
>>>>>>>>> Dear Philipp,
>>>>>>>>>
>>>>>>>>> Do you have just lots of zero's, or more zero's than the
>>>>>>>> Poisson
>>>>>>>>> distribution can explain? Those are two different things.
>>>>>>>> The example
>>>>>>>>> below generates data from a Poisson distribution and has
>>>>>>>> 99% zero's
>>>>>>>>> but no zero-inflation. The second example has only 1%
>>>>>>>> zero's but is
>>>>>>>>> clearly zero-inflated.
>>>>>>>>>
>>>>>>>>> set.seed(1) n <- 1e8 sim <- rpois(n, lambda = 0.01) mean(sim
>>>>>>>>> == 0) hist(sim)
>>>>>>>>>
>>>>>>>>> sim.infl <- rbinom(n, size = 1, prob = 0.99) * rpois(n,
>>>>>>>> lambda = 1000)
>>>>>>>>> mean(sim.infl == 0) hist(sim.infl)
>>>>>>>>>
>>>>>>>>> So before looking for zero-inflated models, try to model
>>>>>>>> the zero's.
>>>>>>>>> Best regards,
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
>>>>>>>>> Research Institute
>>>>>>>> for Nature
>>>>>>>>> and Forest team Biometrie & Kwaliteitszorg / team Biometrics
>>>>>>>>> & Quality
>>>>>>>> Assurance
>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>>>>>>>>
>>>>>>>>> To call in the statistician after the experiment is done
>>>>>>>> may be no
>>>>>>>>> more than asking him to perform a post-mortem examination:
>>>>>>>> he may be
>>>>>>>>> able to say what the experiment died of. ~ Sir Ronald
>>>>>>>> Aylmer Fisher
>>>>>>>>> The plural of anecdote is not data. ~ Roger Brinner The
>>>>>>>>> combination of some data and an aching desire for an
>>>>>>>> answer does
>>>>>>>>> not ensure that a reasonable answer can be extracted from a
>>>>>>>> given body
>>>>>>>>> of data. ~ John Tukey
>>>>>>>>>
>>>>>>>>> 2016-06-23 10:07 GMT+02:00 Philipp Singer
>>>>>>>> <killver at gmail.com <mailto:killver at gmail.com>
>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>
>>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>
>>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>>>:
>>>>>>>>>
>>>>>>>>> Dear group - I am currently fitting a Poisson glmer
>>>>>>>> where I have
>>>>>>>>> an excess of outcomes that are zero (>95%). I am now
>>>>>>>> debating on
>>>>>>>>> how to proceed and came up with three options:
>>>>>>>>>
>>>>>>>>> 1.) Just fit a regular glmer to the complete data. I am
>>>>>>>> not fully
>>>>>>>>> sure how interpret the coefficients then, are they more
>>>>>>>> optimizing
>>>>>>>>> towards distinguishing zero and non-zero, or also
>>>>>>>> capturing the
>>>>>>>>> differences in those outcomes that are non-zero?
>>>>>>>>>
>>>>>>>>> 2.) Leave all zeros out of the data and fit a glmer to
>>>>>>>> only those
>>>>>>>>> outcomes that are non-zero. Then, I would only learn about
>>>>>>>>> differences in the non-zero outcomes though.
>>>>>>>>>
>>>>>>>>> 3.) Use a zero-inflated Poisson model. My data is quite
>>>>>>>>> large-scale, so I am currently playing around with the EM
>>>>>>>>> implementation of Bolker et al. that alternates between
>>>>>>>> fitting a
>>>>>>>>> glmer with data that are weighted according to their zero
>>>>>>>>> probability, and fitting a logistic regression for the
>>>>>>>> probability
>>>>>>>>> that a data point is zero. The method is elaborated for
>>>>>>>> the OWL
>>>>>>>>> data in:
>>>>>>>>>
>>>>>>>> https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
>>>>>>>> <https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf>
>>>>>>>>>
>>>> I am not fully sure how to interpret the results for the
>>>>>>>>> zero-inflated version though. Would I need to interpret the
>>>>>>>>> coefficients for the result of the glmer similar to as
>>>>>>>> I would do
>>>>>>>>> for my idea of 2)? And then on top of that interpret the
>>>>>>>>> coefficients for the logistic regression regarding whether
>>>>>>>>> something is in the perfect or imperfect state? I am
>>>>>>>> also not
>>>>>>>>> quite sure what the common approach for the zformula is
>>>>>>>> here. The
>>>>>>>>> OWL elaborations only use zformula=z~1, so no random
>>>>>>>> effect; I
>>>>>>>>> would use the same formula as for the glmer.
>>>>>>>>>
>>>>>>>>> I am appreciating some help and pointers.
>>>>>>>>>
>>>>>>>>> Thanks! Philipp
>>>>>>>>>
>>>>>>>>> _______________________________________________
>>>>>>>>> R-sig-mixed-models at r-project.org 
>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>>
>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>>> mailing list
>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>
>>>>>>>> [[alternative HTML version deleted]]
>>>>>>>>
>>>>>>>> _______________________________________________
>>>>>>>> R-sig-mixed-models at r-project.org 
>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>> mailing list
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>>>>
>>>>>>>>
>>>>>>>
>>>>>>
>>>>>> [[alternative HTML version deleted]]
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org 
>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>> [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org 
>>>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org 
>>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org 
>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>


	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Jun 24 15:40:52 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 24 Jun 2016 09:40:52 -0400
Subject: [R-sig-ME] Question about zero-inflated Poisson glmer
In-Reply-To: <576D3209.6050507@gmail.com>
References: <576B98C4.6000602@gmail.com>
	<CAJuCY5xbiEjCmHjc_3wX2emzJ3NEMTA_qKgC_reWn=zqC7YEng@mail.gmail.com>
	<576BAB84.6080009@gmail.com>
	<CAJuCY5zmK1xCyWOwcCH+Hch_LSdB+AazmUDuPVP6je7ABFU5FA@mail.gmail.com>
	<576BBCFD.8040806@gmail.com>
	<CAJuCY5ycRL6oXs=H5JrEqOHWzd1UsvSNVZM6-MK+V2N=pvbyQA@mail.gmail.com>
	<576BFEBC.3020407@gmail.com>
	<B5AEF3F5-949F-4686-82DA-C234C3C4018B@ufl.edu>
	<576C18F9.9010200@gmail.com> <576C200A.1050405@gmail.com>
	<4D07695C-8CEA-4785-A5B0-46B011625DA0@ufl.edu>
	<576D290A.7090102@gmail.com> <576D3209.6050507@gmail.com>
Message-ID: <576D3864.1060001@gmail.com>

 Probably for now the glmmTMB issues page is best.

 When you go there:

  - details on installation problems/hiccups would be useful
  - a reproducible example for the problem listed below would be useful
  - dispformula is for allowing dispersion/residual variance to vary
with covariates (i.e., modeling heteroscedasticity)

  cheers
    Ben Bolker


On 16-06-24 09:13 AM, Philipp Singer wrote:
> Update, I tried it like that, but receive an error message.
> 
> Warning message:
> In nlminb(start = par, objective = fn, gradient = gr): NA/NaN function evaluation
> 
> Error in solve.default(hessian.fixed): Lapack routine dgesv: system is exactly singular: U[3,3] = 0
> Traceback:
> 
> 1. glmmTMB(y ~ 1 + x + (1 | b),
>   .     data = data, family = "poisson", dispformula = ~1 + x)
> 2. sdreport(obj)
> 3. solve(hessian.fixed)
> 4. solve(hessian.fixed)
> 5. solve.default(hessian.fixed)
> 
> Any ideas on that?
> 
> BTW: Is it fine to post glmmTMB questions here, or should I rather use 
> the github issue page, or is there maybe a dedicated mailing list?
> 
> Thanks,
> Philipp
> 
> On 24.06.2016 14:35, Philipp Singer wrote:
>> It indeed seems to run quite fast; had some trouble installing, but 
>> works now on my 3.3 R setup.
>>
>> One question I have is regarding the specification of dispersion as I 
>> need to specify the dispformula. What is the difference here between 
>> just specifying fixed effects vs. also the random effects?
>>
>> On 23.06.2016 23:07, Mollie Brooks wrote:
>>> glmmTMB does crossed RE. Ben did some timings in vignette("glmmTMB") 
>>> and it was 2.3 times faster than glmer for one simple GLMM.
>>>
>>>
>>>> On 23Jun 2016, at 10:44, Philipp Singer <killver at gmail.com> wrote:
>>>>
>>>> Did try glmmADMB but unfortunately it is way too slow for my data.
>>>>
>>>> Did not know about glmmTMB, will try it out. Does it work with 
>>>> crossed random effects and how does it scale with more data? I will 
>>>> check the docu and try it though. Thanks for the info.
>>>>
>>>> On 23.06.2016 19:14, Ben Bolker wrote:
>>>>>   I would also comment that glmmTMB is likely to be much faster 
>>>>> than the
>>>>> lme4-based EM approach ...
>>>>>
>>>>>   cheers
>>>>>     Ben B.
>>>>>
>>>>> On 16-06-23 12:47 PM, Mollie Brooks wrote:
>>>>>> Hi Philipp,
>>>>>>
>>>>>> You could also try fitting the model with and without ZI using either
>>>>>> glmmADMB or glmmTMB. Then compare the AICs. I believe model selection
>>>>>> is useful for this, but I could be missing something since the
>>>>>> simulation procedure that Thierry described seems to recommended more
>>>>>> often.
>>>>>>
>>>>>> https://github.com/glmmTMB/glmmTMB
>>>>>> http://glmmadmb.r-forge.r-project.org
>>>>>>
>>>>>> glmmTMB is still in the development phase, but we?ve done a lot of
>>>>>> testing.
>>>>>>
>>>>>> cheers, Mollie
>>>>>>
>>>>>> ------------------------ Mollie Brooks, PhD Postdoctoral Researcher,
>>>>>> Population Ecology Research Group Department of Evolutionary Biology
>>>>>> & Environmental Studies, University of Z?rich
>>>>>> http://www.popecol.org/team/mollie-brooks/
>>>>>>
>>>>>>
>>>>>>> On 23Jun 2016, at 8:22, Philipp Singer <killver at gmail.com> wrote:
>>>>>>>
>>>>>>> Thanks, great information, that is really helpful.
>>>>>>>
>>>>>>> I agree that those are different things, however when using a
>>>>>>> random effect for overdispersion, I can simulate the same number of
>>>>>>> zero outcomes (~95%).
>>>>>>>
>>>>>>> On 23.06.2016 15:50, Thierry Onkelinx wrote:
>>>>>>>> Be careful when using overdispersion to model zero-inflation.
>>>>>>>> Those are two different things.
>>>>>>>>
>>>>>>>> I've put some information together in
>>>>>>>> http://rpubs.com/INBOstats/zeroinflation
>>>>>>>>
>>>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
>>>>>>>> Research Institute for Nature and Forest team Biometrie &
>>>>>>>> Kwaliteitszorg / team Biometrics & Quality Assurance
>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>>>>>>>
>>>>>>>> To call in the statistician after the experiment is done may be
>>>>>>>> no more than asking him to perform a post-mortem examination: he
>>>>>>>> may be able to say what the experiment died of. ~ Sir Ronald
>>>>>>>> Aylmer Fisher The plural of anecdote is not data. ~ Roger
>>>>>>>> Brinner The combination of some data and an aching desire for an
>>>>>>>> answer does not ensure that a reasonable answer can be extracted
>>>>>>>> from a given body of data. ~ John Tukey
>>>>>>>>
>>>>>>>> 2016-06-23 12:42 GMT+02:00 Philipp Singer <killver at gmail.com
>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>>:
>>>>>>>>
>>>>>>>> Thanks! Actually, accounting for overdispersion is super
>>>>>>>> important as it seems, then the zeros can be captured well.
>>>>>>>>
>>>>>>>>
>>>>>>>> On 23.06.2016 11:50, Thierry Onkelinx wrote:
>>>>>>>>> Dear Philipp,
>>>>>>>>>
>>>>>>>>> 1. Fit a Poisson model to the data. 2. Simulate a new response
>>>>>>>>> vector for the dataset according to the model. 3. Count the
>>>>>>>>> number of zero's in the simulated response vector. 4. Repeat
>>>>>>>>> step 2 and 3 a decent number of time and plot a histogram of
>>>>>>>>> the number of zero's in the simulation. If the number of zero's
>>>>>>>>> in the original dataset is larger than those in the
>>>>>>>>> simulations, then the model can't capture all zero's. In such
>>>>>>>>> case, first try to update the model and repeat the procedure.
>>>>>>>>> If that fails, look for zero-inflated models.
>>>>>>>>>
>>>>>>>>> Best regards,
>>>>>>>>>
>>>>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
>>>>>>>>> Research Institute for Nature and Forest team Biometrie &
>>>>>>>>> Kwaliteitszorg / team Biometrics & Quality Assurance
>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>>>>>>>>
>>>>>>>>> To call in the statistician after the experiment is done may
>>>>>>>>> be no more than asking him to perform a post-mortem
>>>>>>>>> examination: he may be able to say what the experiment died of.
>>>>>>>>> ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data.
>>>>>>>>> ~ Roger Brinner The combination of some data and an aching
>>>>>>>>> desire for an answer does not ensure that a reasonable answer
>>>>>>>>> can be extracted from a given body of data. ~ John Tukey
>>>>>>>>>
>>>>>>>>> 2016-06-23 11:27 GMT+02:00 Philipp Singer <killver at gmail.com
>>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>>:
>>>>>>>>>
>>>>>>>>> Thanks Thierry - That totally makes sense. Is there some way of
>>>>>>>>> formally checking that, except thinking about the setting and
>>>>>>>>> underlying processes?
>>>>>>>>>
>>>>>>>>> On 23.06.2016 11:04, Thierry Onkelinx wrote:
>>>>>>>>>> Dear Philipp,
>>>>>>>>>>
>>>>>>>>>> Do you have just lots of zero's, or more zero's than the
>>>>>>>>> Poisson
>>>>>>>>>> distribution can explain? Those are two different things.
>>>>>>>>> The example
>>>>>>>>>> below generates data from a Poisson distribution and has
>>>>>>>>> 99% zero's
>>>>>>>>>> but no zero-inflation. The second example has only 1%
>>>>>>>>> zero's but is
>>>>>>>>>> clearly zero-inflated.
>>>>>>>>>>
>>>>>>>>>> set.seed(1) n <- 1e8 sim <- rpois(n, lambda = 0.01) mean(sim
>>>>>>>>>> == 0) hist(sim)
>>>>>>>>>>
>>>>>>>>>> sim.infl <- rbinom(n, size = 1, prob = 0.99) * rpois(n,
>>>>>>>>> lambda = 1000)
>>>>>>>>>> mean(sim.infl == 0) hist(sim.infl)
>>>>>>>>>>
>>>>>>>>>> So before looking for zero-inflated models, try to model
>>>>>>>>> the zero's.
>>>>>>>>>> Best regards,
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
>>>>>>>>>> Research Institute
>>>>>>>>> for Nature
>>>>>>>>>> and Forest team Biometrie & Kwaliteitszorg / team Biometrics
>>>>>>>>>> & Quality
>>>>>>>>> Assurance
>>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>>>>>>>>>
>>>>>>>>>> To call in the statistician after the experiment is done
>>>>>>>>> may be no
>>>>>>>>>> more than asking him to perform a post-mortem examination:
>>>>>>>>> he may be
>>>>>>>>>> able to say what the experiment died of. ~ Sir Ronald
>>>>>>>>> Aylmer Fisher
>>>>>>>>>> The plural of anecdote is not data. ~ Roger Brinner The
>>>>>>>>>> combination of some data and an aching desire for an
>>>>>>>>> answer does
>>>>>>>>>> not ensure that a reasonable answer can be extracted from a
>>>>>>>>> given body
>>>>>>>>>> of data. ~ John Tukey
>>>>>>>>>>
>>>>>>>>>> 2016-06-23 10:07 GMT+02:00 Philipp Singer
>>>>>>>>> <killver at gmail.com <mailto:killver at gmail.com>
>>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>
>>>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>
>>>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>>>:
>>>>>>>>>>
>>>>>>>>>> Dear group - I am currently fitting a Poisson glmer
>>>>>>>>> where I have
>>>>>>>>>> an excess of outcomes that are zero (>95%). I am now
>>>>>>>>> debating on
>>>>>>>>>> how to proceed and came up with three options:
>>>>>>>>>>
>>>>>>>>>> 1.) Just fit a regular glmer to the complete data. I am
>>>>>>>>> not fully
>>>>>>>>>> sure how interpret the coefficients then, are they more
>>>>>>>>> optimizing
>>>>>>>>>> towards distinguishing zero and non-zero, or also
>>>>>>>>> capturing the
>>>>>>>>>> differences in those outcomes that are non-zero?
>>>>>>>>>>
>>>>>>>>>> 2.) Leave all zeros out of the data and fit a glmer to
>>>>>>>>> only those
>>>>>>>>>> outcomes that are non-zero. Then, I would only learn about
>>>>>>>>>> differences in the non-zero outcomes though.
>>>>>>>>>>
>>>>>>>>>> 3.) Use a zero-inflated Poisson model. My data is quite
>>>>>>>>>> large-scale, so I am currently playing around with the EM
>>>>>>>>>> implementation of Bolker et al. that alternates between
>>>>>>>>> fitting a
>>>>>>>>>> glmer with data that are weighted according to their zero
>>>>>>>>>> probability, and fitting a logistic regression for the
>>>>>>>>> probability
>>>>>>>>>> that a data point is zero. The method is elaborated for
>>>>>>>>> the OWL
>>>>>>>>>> data in:
>>>>>>>>>>
>>>>>>>>> https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
>>>>>>>>> <https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf>
>>>>>>>>>>
>>>>> I am not fully sure how to interpret the results for the
>>>>>>>>>> zero-inflated version though. Would I need to interpret the
>>>>>>>>>> coefficients for the result of the glmer similar to as
>>>>>>>>> I would do
>>>>>>>>>> for my idea of 2)? And then on top of that interpret the
>>>>>>>>>> coefficients for the logistic regression regarding whether
>>>>>>>>>> something is in the perfect or imperfect state? I am
>>>>>>>>> also not
>>>>>>>>>> quite sure what the common approach for the zformula is
>>>>>>>>> here. The
>>>>>>>>>> OWL elaborations only use zformula=z~1, so no random
>>>>>>>>> effect; I
>>>>>>>>>> would use the same formula as for the glmer.
>>>>>>>>>>
>>>>>>>>>> I am appreciating some help and pointers.
>>>>>>>>>>
>>>>>>>>>> Thanks! Philipp
>>>>>>>>>>
>>>>>>>>>> _______________________________________________
>>>>>>>>>> R-sig-mixed-models at r-project.org 
>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>>
>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>>> mailing list
>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>
>>>>>>>>> [[alternative HTML version deleted]]
>>>>>>>>>
>>>>>>>>> _______________________________________________
>>>>>>>>> R-sig-mixed-models at r-project.org 
>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>> mailing list
>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>
>>>>>>>
>>>>>>> [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> _______________________________________________
>>>>>>> R-sig-mixed-models at r-project.org 
>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>>>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>> [[alternative HTML version deleted]]
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org 
>>>>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org 
>>>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org 
>>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From killver at gmail.com  Fri Jun 24 15:52:27 2016
From: killver at gmail.com (Philipp Singer)
Date: Fri, 24 Jun 2016 15:52:27 +0200
Subject: [R-sig-ME] Question about zero-inflated Poisson glmer
In-Reply-To: <576D3864.1060001@gmail.com>
References: <576B98C4.6000602@gmail.com>
	<CAJuCY5xbiEjCmHjc_3wX2emzJ3NEMTA_qKgC_reWn=zqC7YEng@mail.gmail.com>
	<576BAB84.6080009@gmail.com>
	<CAJuCY5zmK1xCyWOwcCH+Hch_LSdB+AazmUDuPVP6je7ABFU5FA@mail.gmail.com>
	<576BBCFD.8040806@gmail.com>
	<CAJuCY5ycRL6oXs=H5JrEqOHWzd1UsvSNVZM6-MK+V2N=pvbyQA@mail.gmail.com>
	<576BFEBC.3020407@gmail.com>
	<B5AEF3F5-949F-4686-82DA-C234C3C4018B@ufl.edu>
	<576C18F9.9010200@gmail.com> <576C200A.1050405@gmail.com>
	<4D07695C-8CEA-4785-A5B0-46B011625DA0@ufl.edu>
	<576D290A.7090102@gmail.com>
	<576D3209.6050507@gmail.com> <576D3864.1060001@gmail.com>
Message-ID: <576D3B1B.3050908@gmail.com>

Thanks - I started an issue there to answer some of my questions.

Regarding the installation: I was trying to somehow do it in anaconda 
with a specific R kernel and had some issues. I am trying to resort that 
with the anaconda guys though, if I have a tutorial on how to properly 
setup glmmTMB in anaconda, I will let you know. The install worked fine 
in my standard R environment.

On 24.06.2016 15:40, Ben Bolker wrote:
>   Probably for now the glmmTMB issues page is best.
>
>   When you go there:
>
>    - details on installation problems/hiccups would be useful
>    - a reproducible example for the problem listed below would be useful
>    - dispformula is for allowing dispersion/residual variance to vary
> with covariates (i.e., modeling heteroscedasticity)
>
>    cheers
>      Ben Bolker
>
>
> On 16-06-24 09:13 AM, Philipp Singer wrote:
>> Update, I tried it like that, but receive an error message.
>>
>> Warning message:
>> In nlminb(start = par, objective = fn, gradient = gr): NA/NaN function evaluation
>>
>> Error in solve.default(hessian.fixed): Lapack routine dgesv: system is exactly singular: U[3,3] = 0
>> Traceback:
>>
>> 1. glmmTMB(y ~ 1 + x + (1 | b),
>>    .     data = data, family = "poisson", dispformula = ~1 + x)
>> 2. sdreport(obj)
>> 3. solve(hessian.fixed)
>> 4. solve(hessian.fixed)
>> 5. solve.default(hessian.fixed)
>>
>> Any ideas on that?
>>
>> BTW: Is it fine to post glmmTMB questions here, or should I rather use
>> the github issue page, or is there maybe a dedicated mailing list?
>>
>> Thanks,
>> Philipp
>>
>> On 24.06.2016 14:35, Philipp Singer wrote:
>>> It indeed seems to run quite fast; had some trouble installing, but
>>> works now on my 3.3 R setup.
>>>
>>> One question I have is regarding the specification of dispersion as I
>>> need to specify the dispformula. What is the difference here between
>>> just specifying fixed effects vs. also the random effects?
>>>
>>> On 23.06.2016 23:07, Mollie Brooks wrote:
>>>> glmmTMB does crossed RE. Ben did some timings in vignette("glmmTMB")
>>>> and it was 2.3 times faster than glmer for one simple GLMM.
>>>>
>>>>
>>>>> On 23Jun 2016, at 10:44, Philipp Singer <killver at gmail.com> wrote:
>>>>>
>>>>> Did try glmmADMB but unfortunately it is way too slow for my data.
>>>>>
>>>>> Did not know about glmmTMB, will try it out. Does it work with
>>>>> crossed random effects and how does it scale with more data? I will
>>>>> check the docu and try it though. Thanks for the info.
>>>>>
>>>>> On 23.06.2016 19:14, Ben Bolker wrote:
>>>>>>    I would also comment that glmmTMB is likely to be much faster
>>>>>> than the
>>>>>> lme4-based EM approach ...
>>>>>>
>>>>>>    cheers
>>>>>>      Ben B.
>>>>>>
>>>>>> On 16-06-23 12:47 PM, Mollie Brooks wrote:
>>>>>>> Hi Philipp,
>>>>>>>
>>>>>>> You could also try fitting the model with and without ZI using either
>>>>>>> glmmADMB or glmmTMB. Then compare the AICs. I believe model selection
>>>>>>> is useful for this, but I could be missing something since the
>>>>>>> simulation procedure that Thierry described seems to recommended more
>>>>>>> often.
>>>>>>>
>>>>>>> https://github.com/glmmTMB/glmmTMB
>>>>>>> http://glmmadmb.r-forge.r-project.org
>>>>>>>
>>>>>>> glmmTMB is still in the development phase, but we?ve done a lot of
>>>>>>> testing.
>>>>>>>
>>>>>>> cheers, Mollie
>>>>>>>
>>>>>>> ------------------------ Mollie Brooks, PhD Postdoctoral Researcher,
>>>>>>> Population Ecology Research Group Department of Evolutionary Biology
>>>>>>> & Environmental Studies, University of Z?rich
>>>>>>> http://www.popecol.org/team/mollie-brooks/
>>>>>>>
>>>>>>>
>>>>>>>> On 23Jun 2016, at 8:22, Philipp Singer <killver at gmail.com> wrote:
>>>>>>>>
>>>>>>>> Thanks, great information, that is really helpful.
>>>>>>>>
>>>>>>>> I agree that those are different things, however when using a
>>>>>>>> random effect for overdispersion, I can simulate the same number of
>>>>>>>> zero outcomes (~95%).
>>>>>>>>
>>>>>>>> On 23.06.2016 15:50, Thierry Onkelinx wrote:
>>>>>>>>> Be careful when using overdispersion to model zero-inflation.
>>>>>>>>> Those are two different things.
>>>>>>>>>
>>>>>>>>> I've put some information together in
>>>>>>>>> http://rpubs.com/INBOstats/zeroinflation
>>>>>>>>>
>>>>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
>>>>>>>>> Research Institute for Nature and Forest team Biometrie &
>>>>>>>>> Kwaliteitszorg / team Biometrics & Quality Assurance
>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>>>>>>>>
>>>>>>>>> To call in the statistician after the experiment is done may be
>>>>>>>>> no more than asking him to perform a post-mortem examination: he
>>>>>>>>> may be able to say what the experiment died of. ~ Sir Ronald
>>>>>>>>> Aylmer Fisher The plural of anecdote is not data. ~ Roger
>>>>>>>>> Brinner The combination of some data and an aching desire for an
>>>>>>>>> answer does not ensure that a reasonable answer can be extracted
>>>>>>>>> from a given body of data. ~ John Tukey
>>>>>>>>>
>>>>>>>>> 2016-06-23 12:42 GMT+02:00 Philipp Singer <killver at gmail.com
>>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>>:
>>>>>>>>>
>>>>>>>>> Thanks! Actually, accounting for overdispersion is super
>>>>>>>>> important as it seems, then the zeros can be captured well.
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> On 23.06.2016 11:50, Thierry Onkelinx wrote:
>>>>>>>>>> Dear Philipp,
>>>>>>>>>>
>>>>>>>>>> 1. Fit a Poisson model to the data. 2. Simulate a new response
>>>>>>>>>> vector for the dataset according to the model. 3. Count the
>>>>>>>>>> number of zero's in the simulated response vector. 4. Repeat
>>>>>>>>>> step 2 and 3 a decent number of time and plot a histogram of
>>>>>>>>>> the number of zero's in the simulation. If the number of zero's
>>>>>>>>>> in the original dataset is larger than those in the
>>>>>>>>>> simulations, then the model can't capture all zero's. In such
>>>>>>>>>> case, first try to update the model and repeat the procedure.
>>>>>>>>>> If that fails, look for zero-inflated models.
>>>>>>>>>>
>>>>>>>>>> Best regards,
>>>>>>>>>>
>>>>>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
>>>>>>>>>> Research Institute for Nature and Forest team Biometrie &
>>>>>>>>>> Kwaliteitszorg / team Biometrics & Quality Assurance
>>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>>>>>>>>>
>>>>>>>>>> To call in the statistician after the experiment is done may
>>>>>>>>>> be no more than asking him to perform a post-mortem
>>>>>>>>>> examination: he may be able to say what the experiment died of.
>>>>>>>>>> ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data.
>>>>>>>>>> ~ Roger Brinner The combination of some data and an aching
>>>>>>>>>> desire for an answer does not ensure that a reasonable answer
>>>>>>>>>> can be extracted from a given body of data. ~ John Tukey
>>>>>>>>>>
>>>>>>>>>> 2016-06-23 11:27 GMT+02:00 Philipp Singer <killver at gmail.com
>>>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>>:
>>>>>>>>>>
>>>>>>>>>> Thanks Thierry - That totally makes sense. Is there some way of
>>>>>>>>>> formally checking that, except thinking about the setting and
>>>>>>>>>> underlying processes?
>>>>>>>>>>
>>>>>>>>>> On 23.06.2016 11:04, Thierry Onkelinx wrote:
>>>>>>>>>>> Dear Philipp,
>>>>>>>>>>>
>>>>>>>>>>> Do you have just lots of zero's, or more zero's than the
>>>>>>>>>> Poisson
>>>>>>>>>>> distribution can explain? Those are two different things.
>>>>>>>>>> The example
>>>>>>>>>>> below generates data from a Poisson distribution and has
>>>>>>>>>> 99% zero's
>>>>>>>>>>> but no zero-inflation. The second example has only 1%
>>>>>>>>>> zero's but is
>>>>>>>>>>> clearly zero-inflated.
>>>>>>>>>>>
>>>>>>>>>>> set.seed(1) n <- 1e8 sim <- rpois(n, lambda = 0.01) mean(sim
>>>>>>>>>>> == 0) hist(sim)
>>>>>>>>>>>
>>>>>>>>>>> sim.infl <- rbinom(n, size = 1, prob = 0.99) * rpois(n,
>>>>>>>>>> lambda = 1000)
>>>>>>>>>>> mean(sim.infl == 0) hist(sim.infl)
>>>>>>>>>>>
>>>>>>>>>>> So before looking for zero-inflated models, try to model
>>>>>>>>>> the zero's.
>>>>>>>>>>> Best regards,
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
>>>>>>>>>>> Research Institute
>>>>>>>>>> for Nature
>>>>>>>>>>> and Forest team Biometrie & Kwaliteitszorg / team Biometrics
>>>>>>>>>>> & Quality
>>>>>>>>>> Assurance
>>>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>>>>>>>>>>
>>>>>>>>>>> To call in the statistician after the experiment is done
>>>>>>>>>> may be no
>>>>>>>>>>> more than asking him to perform a post-mortem examination:
>>>>>>>>>> he may be
>>>>>>>>>>> able to say what the experiment died of. ~ Sir Ronald
>>>>>>>>>> Aylmer Fisher
>>>>>>>>>>> The plural of anecdote is not data. ~ Roger Brinner The
>>>>>>>>>>> combination of some data and an aching desire for an
>>>>>>>>>> answer does
>>>>>>>>>>> not ensure that a reasonable answer can be extracted from a
>>>>>>>>>> given body
>>>>>>>>>>> of data. ~ John Tukey
>>>>>>>>>>>
>>>>>>>>>>> 2016-06-23 10:07 GMT+02:00 Philipp Singer
>>>>>>>>>> <killver at gmail.com <mailto:killver at gmail.com>
>>>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>
>>>>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>
>>>>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>>>:
>>>>>>>>>>>
>>>>>>>>>>> Dear group - I am currently fitting a Poisson glmer
>>>>>>>>>> where I have
>>>>>>>>>>> an excess of outcomes that are zero (>95%). I am now
>>>>>>>>>> debating on
>>>>>>>>>>> how to proceed and came up with three options:
>>>>>>>>>>>
>>>>>>>>>>> 1.) Just fit a regular glmer to the complete data. I am
>>>>>>>>>> not fully
>>>>>>>>>>> sure how interpret the coefficients then, are they more
>>>>>>>>>> optimizing
>>>>>>>>>>> towards distinguishing zero and non-zero, or also
>>>>>>>>>> capturing the
>>>>>>>>>>> differences in those outcomes that are non-zero?
>>>>>>>>>>>
>>>>>>>>>>> 2.) Leave all zeros out of the data and fit a glmer to
>>>>>>>>>> only those
>>>>>>>>>>> outcomes that are non-zero. Then, I would only learn about
>>>>>>>>>>> differences in the non-zero outcomes though.
>>>>>>>>>>>
>>>>>>>>>>> 3.) Use a zero-inflated Poisson model. My data is quite
>>>>>>>>>>> large-scale, so I am currently playing around with the EM
>>>>>>>>>>> implementation of Bolker et al. that alternates between
>>>>>>>>>> fitting a
>>>>>>>>>>> glmer with data that are weighted according to their zero
>>>>>>>>>>> probability, and fitting a logistic regression for the
>>>>>>>>>> probability
>>>>>>>>>>> that a data point is zero. The method is elaborated for
>>>>>>>>>> the OWL
>>>>>>>>>>> data in:
>>>>>>>>>>>
>>>>>>>>>> https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
>>>>>>>>>> <https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf>
>>>>>> I am not fully sure how to interpret the results for the
>>>>>>>>>>> zero-inflated version though. Would I need to interpret the
>>>>>>>>>>> coefficients for the result of the glmer similar to as
>>>>>>>>>> I would do
>>>>>>>>>>> for my idea of 2)? And then on top of that interpret the
>>>>>>>>>>> coefficients for the logistic regression regarding whether
>>>>>>>>>>> something is in the perfect or imperfect state? I am
>>>>>>>>>> also not
>>>>>>>>>>> quite sure what the common approach for the zformula is
>>>>>>>>>> here. The
>>>>>>>>>>> OWL elaborations only use zformula=z~1, so no random
>>>>>>>>>> effect; I
>>>>>>>>>>> would use the same formula as for the glmer.
>>>>>>>>>>>
>>>>>>>>>>> I am appreciating some help and pointers.
>>>>>>>>>>>
>>>>>>>>>>> Thanks! Philipp
>>>>>>>>>>>
>>>>>>>>>>> _______________________________________________
>>>>>>>>>>> R-sig-mixed-models at r-project.org
>>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>>
>>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>>> mailing list
>>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>> [[alternative HTML version deleted]]
>>>>>>>>>>
>>>>>>>>>> _______________________________________________
>>>>>>>>>> R-sig-mixed-models at r-project.org
>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>> mailing list
>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>> [[alternative HTML version deleted]]
>>>>>>>>
>>>>>>>> _______________________________________________
>>>>>>>> R-sig-mixed-models at r-project.org
>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>>>>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>>> [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> _______________________________________________
>>>>>>> R-sig-mixed-models at r-project.org
>>>>>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org
>>>>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org
>>>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>


From newboch at auburn.edu  Fri Jun 24 22:02:03 2016
From: newboch at auburn.edu (Chad Newbolt)
Date: Fri, 24 Jun 2016 20:02:03 +0000
Subject: [R-sig-ME] GLMM, overdispersion,
	and method for comparing competetive models
Message-ID: <1466798523378.31942@auburn.edu>

All,

I would first like to say that I'm a relative novice with R so please take that into consideration with your responses.  Basically, give me the totally dumbed down version of answers when you can.

I have a biological data set with count data that I'm currently analyzing.  Namely, I'm interested in looking at the effects of animal age, bodysize, and antler size on annual male reproductive success (i.e. number of fawns produced).  I would also like to see how the relationships are influenced by changes in population demographics.  I have been using a GLMM to evaluate the following global model:

repro = glmer(Fawn~Age+I(Age^2)+BodySize+SSCM+AvgAge+Age*AvgAge+I(Age^2)*AvgAge+BodySize*AvgAge+SSCM*AvgAge+(1|Sire),data=datum,family=poisson)

where:

Age, BodySize, SSCM are measured characteristics
Fawn = number of fawns produced in a given year
AvgAge = Population demographic factor
(1|Sire) = Random effect for each sampled male ID

I first used the following to evaluate potential overdispersion of my data from the global model:

overdisp_fun <- function(model) {
## number of variance parameters in
##   an n-by-n variance-covariance matrix
vpars <- function(m) {
nrow(m)*(nrow(m)+1)/2
}
model.df <- sum(sapply(VarCorr(model),vpars))+length(fixef(model))
rdf <- nrow(model.frame(model))-model.df
rp <- residuals(model,type="pearson")
Pearson.chisq <- sum(rp^2)
prat <- Pearson.chisq/rdf
pval <- pchisq(Pearson.chisq, df=rdf, lower.tail=FALSE)
c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p=pval)
}

With the following result

 repro = glmer(Fawn~Age+I(Age^2)+BodySize+SSCM+AvgAge+Age*AvgAge+I(Age^2)*AvgAge+BodySize*AvgAge+SSCM*AvgAge+(1|Sire),data=datum,family=poisson)
overdisp_fun(repro)
 chisq                             ratio                          rdf                              p
1.698574e+02      1.681756e+00       1.010000e+02          2.169243e-05

Since the ratio of Pearson-statistic to rdf is 1.68 I assume that I need to take this overdispersion into account

My first inclination was to use quasipoisson distribution to account for overdispersion; however, I see that in no longer available in lme4.  I used glmmPQL in the MASS package with quasipoisson but do not receive AICc information.  I had planned on using AICc to evaluate competitive models.  My specific question is: 1) is there a way to generate the necessary information (AICc or something like) to compare competitive models from overdispersed data in a current R environment? I have read https://cran.r-project.org/web/packages/bbmle/vignettes/quasi.pdf but I'm having a difficult time understanding exactly how to implement from a technical perspective.  I'm on the path of trying to use a negative binomial (I'm not locked into this method so please provide insight if appropriate) with package glmmADMB: however, I have been unable to get this package to load successfully.  I've followed the instructions to the best of my understanding and abilities but cannot figure out where I'm going wrong.  Any advice is much appreciated as I'm totally stumped right now on many fronts.  I'm running windows 7 on 64-bit machine.  Here is what I have attempted with output:

install.packages("glmmADMB",
+     repos=c("http://glmmadmb.r-forge.r-project.org/repos",
+             getOption("repos")),
+     type="source")
Installing package into ?C:/Users/newboch/Documents/R/win-library/3.3?
(as ?lib? is unspecified)
trying URL 'http://glmmadmb.r-forge.r-project.org/repos/src/contrib/glmmADMB_0.8.3.3.tar.gz'
Content type 'application/x-gzip' length 9391177 bytes (9.0 MB)
downloaded 9.0 MB
* installing *source* package 'glmmADMB' ...
** R
** data
*** moving datasets to lazyload DB
** inst
** preparing package for lazy loading
Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :
  there is no package called 'stringi'
ERROR: lazy loading failed for package 'glmmADMB'
* removing 'C:/Users/newboch/Documents/R/win-library/3.3/glmmADMB'
The downloaded source packages are in
        ?C:\Users\newboch\AppData\Local\Temp\RtmpK23VOM\downloaded_packages?
Warning messages:
1: running command '"C:/PROGRA~1/R/R-33~1.1/bin/x64/R" CMD INSTALL -l "C:\Users\newboch\Documents\R\win-library\3.3" C:\Users\newboch\AppData\Local\Temp\RtmpK23VOM/downloaded_packages/glmmADMB_0.8.3.3.tar.gz' had status 1
2: In install.packages("glmmADMB", repos = c("http://glmmadmb.r-forge.r-project.org/repos",  :
  installation of package ?glmmADMB? had non-zero exit status
> glmmADMB:::get_bin_loc()
Error in loadNamespace(name) : there is no package called ?glmmADMB?
> library("R2admb")
> glmmADMB:::get_bin_loc()
Error in loadNamespace(name) : there is no package called ?glmmADMB?
> install.packages("glmmADMB")
Installing package into ?C:/Users/newboch/Documents/R/win-library/3.3?
(as ?lib? is unspecified)
Warning message:
package ?glmmADMB? is not available (for R version 3.3.1)
Thanks,

Chad

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Jun 24 22:57:43 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 24 Jun 2016 16:57:43 -0400
Subject: [R-sig-ME] GLMM, overdispersion,
 and method for comparing competetive models
In-Reply-To: <1466798523378.31942@auburn.edu>
References: <1466798523378.31942@auburn.edu>
Message-ID: <576D9EC7.1080102@gmail.com>

  A couple of quick comments:

  (1) try

install.packages(c("R2admb","stringr","plyr","coda"))

  before doing the glmmADMB installation.

  (2) more advice about overdispersion is available at
http://tinyurl.com/glmmFAQ#Overdispersion

 ...

On 16-06-24 04:02 PM, Chad Newbolt wrote:
> All,
> 
> I would first like to say that I'm a relative novice with R so please
> take that into consideration with your responses.  Basically, give me
> the totally dumbed down version of answers when you can.
> 
> I have a biological data set with count data that I'm currently
> analyzing.  Namely, I'm interested in looking at the effects of
> animal age, bodysize, and antler size on annual male reproductive
> success (i.e. number of fawns produced).  I would also like to see
> how the relationships are influenced by changes in population
> demographics.  I have been using a GLMM to evaluate the following
> global model:
> 
> repro =
> glmer(Fawn~Age+I(Age^2)+BodySize+SSCM+AvgAge+Age*AvgAge+I(Age^2)*AvgAge+BodySize*AvgAge+SSCM*AvgAge+(1|Sire),data=datum,family=poisson)
>
>  where:
> 
> Age, BodySize, SSCM are measured characteristics Fawn = number of
> fawns produced in a given year AvgAge = Population demographic
> factor (1|Sire) = Random effect for each sampled male ID
> 
> I first used the following to evaluate potential overdispersion of my
> data from the global model:
> 
> overdisp_fun <- function(model) { ## number of variance parameters
> in ##   an n-by-n variance-covariance matrix vpars <- function(m) { 
> nrow(m)*(nrow(m)+1)/2 } model.df <-
> sum(sapply(VarCorr(model),vpars))+length(fixef(model)) rdf <-
> nrow(model.frame(model))-model.df rp <-
> residuals(model,type="pearson") Pearson.chisq <- sum(rp^2) prat <-
> Pearson.chisq/rdf pval <- pchisq(Pearson.chisq, df=rdf,
> lower.tail=FALSE) c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p=pval) }
> 
> With the following result
> 
> repro =
> glmer(Fawn~Age+I(Age^2)+BodySize+SSCM+AvgAge+Age*AvgAge+I(Age^2)*AvgAge+BodySize*AvgAge+SSCM*AvgAge+(1|Sire),data=datum,family=poisson)
>
> 
overdisp_fun(repro)
> chisq                             ratio                          rdf
> p 1.698574e+02      1.681756e+00       1.010000e+02
> 2.169243e-05
> 
> Since the ratio of Pearson-statistic to rdf is 1.68 I assume that I
> need to take this overdispersion into account
> 
> My first inclination was to use quasipoisson distribution to account
> for overdispersion; however, I see that in no longer available in
> lme4.  I used glmmPQL in the MASS package with quasipoisson but do
> not receive AICc information.  I had planned on using AICc to
> evaluate competitive models.  My specific question is: 1) is there a
> way to generate the necessary information (AICc or something like) to
> compare competitive models from overdispersed data in a current R
> environment? I have read
> https://cran.r-project.org/web/packages/bbmle/vignettes/quasi.pdf but
> I'm having a difficult time understanding exactly how to implement
> from a technical perspective.  I'm on the path of trying to use a
> negative binomial (I'm not locked into this method so please provide
> insight if appropriate) with package glmmADMB: however, I have been
> unable to get this package to load successfully.  I've followed the
> instructions to the best of my understanding and abilities but cannot
> figure out where I'm going wrong.  Any advice is much appreciated as
> I'm totally stumped right now on many fronts.  I'm running windows 7
> on 64-bit machine.  Here is what I have attempted with output:
> 
> install.packages("glmmADMB", +
> repos=c("http://glmmadmb.r-forge.r-project.org/repos", +
> getOption("repos")), +     type="source") Installing package into
> ?C:/Users/newboch/Documents/R/win-library/3.3? (as ?lib? is
> unspecified) trying URL
> 'http://glmmadmb.r-forge.r-project.org/repos/src/contrib/glmmADMB_0.8.3.3.tar.gz'
>
> 
Content type 'application/x-gzip' length 9391177 bytes (9.0 MB)
> downloaded 9.0 MB * installing *source* package 'glmmADMB' ... ** R 
> ** data *** moving datasets to lazyload DB ** inst ** preparing
> package for lazy loading Error in loadNamespace(i, c(lib.loc,
> .libPaths()), versionCheck = vI[[i]]) : there is no package called
> 'stringi' ERROR: lazy loading failed for package 'glmmADMB' *
> removing 'C:/Users/newboch/Documents/R/win-library/3.3/glmmADMB' The
> downloaded source packages are in 
> ?C:\Users\newboch\AppData\Local\Temp\RtmpK23VOM\downloaded_packages? 
> Warning messages: 1: running command
> '"C:/PROGRA~1/R/R-33~1.1/bin/x64/R" CMD INSTALL -l
> "C:\Users\newboch\Documents\R\win-library\3.3"
> C:\Users\newboch\AppData\Local\Temp\RtmpK23VOM/downloaded_packages/glmmADMB_0.8.3.3.tar.gz'
> had status 1 2: In install.packages("glmmADMB", repos =
> c("http://glmmadmb.r-forge.r-project.org/repos",  : installation of
> package ?glmmADMB? had non-zero exit status
>> glmmADMB:::get_bin_loc()
> Error in loadNamespace(name) : there is no package called ?glmmADMB?
>> library("R2admb") glmmADMB:::get_bin_loc()
> Error in loadNamespace(name) : there is no package called ?glmmADMB?
>> install.packages("glmmADMB")
> Installing package into
> ?C:/Users/newboch/Documents/R/win-library/3.3? (as ?lib? is
> unspecified) Warning message: package ?glmmADMB? is not available
> (for R version 3.3.1) Thanks,
> 
> Chad
> 
> [[alternative HTML version deleted]]
> 
> 
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From newboch at auburn.edu  Fri Jun 24 21:52:01 2016
From: newboch at auburn.edu (Chad Newbolt)
Date: Fri, 24 Jun 2016 19:52:01 +0000
Subject: [R-sig-ME] Question about GLMM and overdispersed data
Message-ID: <1466797921766.95527@auburn.edu>

All,



I would first like to say that I'm a relative novice with R so please take that into consideration with your responses.  Basically, give me the totally dumbed down version of answers when you can.



I have a biological data set with count data that I'm currently analyzing.  Namely, I'm interested in looking at the effects of animal age, bodysize, and antler size on annual male reproductive success (i.e. number of fawns produced).  I would also like to see how the relationships are influenced by changes in population demographics.  I have been using a GLMM to evaluate the following global model:



repro = glmer(Fawn~Age+I(Age^2)+BodySize+SSCM+AvgAge+Age*AvgAge+I(Age^2)*AvgAge+BodySize*AvgAge+SSCM*AvgAge+(1|Sire),data=datum,family=poisson)



where:



Age, BodySize, SSCM are measured characteristics

Fawn = number of fawns produced in a given year

AvgAge = Population demographic factor

(1|Sire) = Random effect for each sampled male ID



I first used the following to evaluate potential overdispersion of my data from the global model:



overdisp_fun <- function(model) {
## number of variance parameters in
##   an n-by-n variance-covariance matrix
vpars <- function(m) {
nrow(m)*(nrow(m)+1)/2
}
model.df <- sum(sapply(VarCorr(model),vpars))+length(fixef(model))
rdf <- nrow(model.frame(model))-model.df
rp <- residuals(model,type="pearson")
Pearson.chisq <- sum(rp^2)
prat <- Pearson.chisq/rdf
pval <- pchisq(Pearson.chisq, df=rdf, lower.tail=FALSE)
c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p=pval)
}



With the following result



 repro = glmer(Fawn~Age+I(Age^2)+BodySize+SSCM+AvgAge+Age*AvgAge+I(Age^2)*AvgAge+BodySize*AvgAge+SSCM*AvgAge+(1|Sire),data=datum,family=poisson)
overdisp_fun(repro)
 chisq                             ratio                          rdf                              p
1.698574e+02      1.681756e+00       1.010000e+02          2.169243e-05



Since the ratio of Pearson-statistic to rdf is 1.68 I assume that I need to take this overdispersion into account



My first inclination was to use quasipoisson distribution to account for overdispersion; however, I see that in no longer available in lme4.  I used glmmPQL in the MASS package with quasipoisson but do not receive AICc information.  I had planned on using AICc to evaluate competitive models.  My specific question is: 1) is there a way to generate the necessary information (AICc or something like) to compare competitive models from overdispersed data in a current R environment? I have read https://cran.r-project.org/web/packages/bbmle/vignettes/quasi.pdf but I'm having a difficult time understanding exactly how to implement from a technical perspective.  I'm on the path of trying to use a negative binomial (I'm not locked into this method so please provide insight if appropriate) with package glmmADMB: however, I have been unable to get this package to load successfully.  I've followed the instructions to the best of my understanding and abilities but cannot figure out where I'm going wrong.  Any advice is much appreciated as I'm totally stumped right now on many fronts.  I'm running windows 7 on 64-bit machine.  Here is what I have attempted with output:



install.packages("glmmADMB",
+     repos=c("http://glmmadmb.r-forge.r-project.org/repos",
+             getOption("repos")),
+     type="source")
Installing package into ?C:/Users/newboch/Documents/R/win-library/3.3?
(as ?lib? is unspecified)
trying URL 'http://glmmadmb.r-forge.r-project.org/repos/src/contrib/glmmADMB_0.8.3.3.tar.gz'
Content type 'application/x-gzip' length 9391177 bytes (9.0 MB)
downloaded 9.0 MB

* installing *source* package 'glmmADMB' ...
** R
** data
*** moving datasets to lazyload DB
** inst
** preparing package for lazy loading
Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :
  there is no package called 'stringi'
ERROR: lazy loading failed for package 'glmmADMB'
* removing 'C:/Users/newboch/Documents/R/win-library/3.3/glmmADMB'

The downloaded source packages are in
        ?C:\Users\newboch\AppData\Local\Temp\RtmpK23VOM\downloaded_packages?
Warning messages:
1: running command '"C:/PROGRA~1/R/R-33~1.1/bin/x64/R" CMD INSTALL -l "C:\Users\newboch\Documents\R\win-library\3.3" C:\Users\newboch\AppData\Local\Temp\RtmpK23VOM/downloaded_packages/glmmADMB_0.8.3.3.tar.gz' had status 1
2: In install.packages("glmmADMB", repos = c("http://glmmadmb.r-forge.r-project.org/repos",  :
  installation of package ?glmmADMB? had non-zero exit status
> glmmADMB:::get_bin_loc()
Error in loadNamespace(name) : there is no package called ?glmmADMB?
> library("R2admb")
> glmmADMB:::get_bin_loc()
Error in loadNamespace(name) : there is no package called ?glmmADMB?
> install.packages("glmmADMB")
Installing package into ?C:/Users/newboch/Documents/R/win-library/3.3?
(as ?lib? is unspecified)
Warning message:
package ?glmmADMB? is not available (for R version 3.3.1)

Thanks,



Chad













	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Sat Jun 25 20:46:02 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Sat, 25 Jun 2016 20:46:02 +0200
Subject: [R-sig-ME] Question about GLMM and overdispersed data
In-Reply-To: <1466797921766.95527@auburn.edu>
References: <1466797921766.95527@auburn.edu>
Message-ID: <CAJuCY5wwR5NA3oK--RLfTVYtY-mco6yd9PNiYr44D6qtBYCxZQ@mail.gmail.com>

Chad,

You are reposting exactly the same question and Ben Bolker already answered
it. If Ben's reply didn't help, you need to post a follow-up question into
the original tread instead of opening a new one.


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-06-24 21:52 GMT+02:00 Chad Newbolt <newboch at auburn.edu>:

> All,
>
>
>
> I would first like to say that I'm a relative novice with R so please take
> that into consideration with your responses.  Basically, give me the
> totally dumbed down version of answers when you can.
>
>
>
> I have a biological data set with count data that I'm currently
> analyzing.  Namely, I'm interested in looking at the effects of animal age,
> bodysize, and antler size on annual male reproductive success (i.e. number
> of fawns produced).  I would also like to see how the relationships are
> influenced by changes in population demographics.  I have been using a GLMM
> to evaluate the following global model:
>
>
>
> repro =
> glmer(Fawn~Age+I(Age^2)+BodySize+SSCM+AvgAge+Age*AvgAge+I(Age^2)*AvgAge+BodySize*AvgAge+SSCM*AvgAge+(1|Sire),data=datum,family=poisson)
>
>
>
> where:
>
>
>
> Age, BodySize, SSCM are measured characteristics
>
> Fawn = number of fawns produced in a given year
>
> AvgAge = Population demographic factor
>
> (1|Sire) = Random effect for each sampled male ID
>
>
>
> I first used the following to evaluate potential overdispersion of my data
> from the global model:
>
>
>
> overdisp_fun <- function(model) {
> ## number of variance parameters in
> ##   an n-by-n variance-covariance matrix
> vpars <- function(m) {
> nrow(m)*(nrow(m)+1)/2
> }
> model.df <- sum(sapply(VarCorr(model),vpars))+length(fixef(model))
> rdf <- nrow(model.frame(model))-model.df
> rp <- residuals(model,type="pearson")
> Pearson.chisq <- sum(rp^2)
> prat <- Pearson.chisq/rdf
> pval <- pchisq(Pearson.chisq, df=rdf, lower.tail=FALSE)
> c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p=pval)
> }
>
>
>
> With the following result
>
>
>
>  repro =
> glmer(Fawn~Age+I(Age^2)+BodySize+SSCM+AvgAge+Age*AvgAge+I(Age^2)*AvgAge+BodySize*AvgAge+SSCM*AvgAge+(1|Sire),data=datum,family=poisson)
> overdisp_fun(repro)
>  chisq                             ratio                          rdf
>                         p
> 1.698574e+02      1.681756e+00       1.010000e+02          2.169243e-05
>
>
>
> Since the ratio of Pearson-statistic to rdf is 1.68 I assume that I need
> to take this overdispersion into account
>
>
>
> My first inclination was to use quasipoisson distribution to account for
> overdispersion; however, I see that in no longer available in lme4.  I used
> glmmPQL in the MASS package with quasipoisson but do not receive AICc
> information.  I had planned on using AICc to evaluate competitive models.
> My specific question is: 1) is there a way to generate the necessary
> information (AICc or something like) to compare competitive models from
> overdispersed data in a current R environment? I have read
> https://cran.r-project.org/web/packages/bbmle/vignettes/quasi.pdf but I'm
> having a difficult time understanding exactly how to implement from a
> technical perspective.  I'm on the path of trying to use a negative
> binomial (I'm not locked into this method so please provide insight if
> appropriate) with package glmmADMB: however, I have been unable to get this
> package to load successfully.  I've followed the instructions to the best
> of my understanding and abilities but cannot figure out where I'm going
> wrong.  Any advice is much appreciated as I'm totally stumped right now on
> many fronts.  I'm running windows 7 on 64-bit machine.  Here is what I have
> attempted with output:
>
>
>
> install.packages("glmmADMB",
> +     repos=c("http://glmmadmb.r-forge.r-project.org/repos",
> +             getOption("repos")),
> +     type="source")
> Installing package into ?C:/Users/newboch/Documents/R/win-library/3.3?
> (as ?lib? is unspecified)
> trying URL '
> http://glmmadmb.r-forge.r-project.org/repos/src/contrib/glmmADMB_0.8.3.3.tar.gz
> '
> Content type 'application/x-gzip' length 9391177 bytes (9.0 MB)
> downloaded 9.0 MB
>
> * installing *source* package 'glmmADMB' ...
> ** R
> ** data
> *** moving datasets to lazyload DB
> ** inst
> ** preparing package for lazy loading
> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]])
> :
>   there is no package called 'stringi'
> ERROR: lazy loading failed for package 'glmmADMB'
> * removing 'C:/Users/newboch/Documents/R/win-library/3.3/glmmADMB'
>
> The downloaded source packages are in
>
> ?C:\Users\newboch\AppData\Local\Temp\RtmpK23VOM\downloaded_packages?
> Warning messages:
> 1: running command '"C:/PROGRA~1/R/R-33~1.1/bin/x64/R" CMD INSTALL -l
> "C:\Users\newboch\Documents\R\win-library\3.3"
> C:\Users\newboch\AppData\Local\Temp\RtmpK23VOM/downloaded_packages/glmmADMB_0.8.3.3.tar.gz'
> had status 1
> 2: In install.packages("glmmADMB", repos = c("
> http://glmmadmb.r-forge.r-project.org/repos",  :
>   installation of package ?glmmADMB? had non-zero exit status
> > glmmADMB:::get_bin_loc()
> Error in loadNamespace(name) : there is no package called ?glmmADMB?
> > library("R2admb")
> > glmmADMB:::get_bin_loc()
> Error in loadNamespace(name) : there is no package called ?glmmADMB?
> > install.packages("glmmADMB")
> Installing package into ?C:/Users/newboch/Documents/R/win-library/3.3?
> (as ?lib? is unspecified)
> Warning message:
> package ?glmmADMB? is not available (for R version 3.3.1)
>
> Thanks,
>
>
>
> Chad
>
>
>
>
>
>
>
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From newboch at auburn.edu  Sat Jun 25 22:54:36 2016
From: newboch at auburn.edu (Chad Newbolt)
Date: Sat, 25 Jun 2016 20:54:36 +0000
Subject: [R-sig-ME] GLMM, overdispersion,
 and method for comparing competetive models
In-Reply-To: <576D9EC7.1080102@gmail.com>
References: <1466798523378.31942@auburn.edu>,<576D9EC7.1080102@gmail.com>
Message-ID: <1466888080252.6726@auburn.edu>

Thanks.  I'll  take this into consideration and get back to everyone.  Please disregard the other posting that was sent out today containing the exact same content.  I accidentally posted twice during the new member enrolling process.  Sorry and thanks again for the help.

Chad 
________________________________________
From: Ben Bolker <bbolker at gmail.com>
Sent: Friday, June 24, 2016 3:57 PM
To: Chad Newbolt; R-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] GLMM, overdispersion, and method for comparing competetive models

  A couple of quick comments:

  (1) try

install.packages(c("R2admb","stringr","plyr","coda"))

  before doing the glmmADMB installation.

  (2) more advice about overdispersion is available at
http://tinyurl.com/glmmFAQ#Overdispersion

 ...

On 16-06-24 04:02 PM, Chad Newbolt wrote:
> All,
>
> I would first like to say that I'm a relative novice with R so please
> take that into consideration with your responses.  Basically, give me
> the totally dumbed down version of answers when you can.
>
> I have a biological data set with count data that I'm currently
> analyzing.  Namely, I'm interested in looking at the effects of
> animal age, bodysize, and antler size on annual male reproductive
> success (i.e. number of fawns produced).  I would also like to see
> how the relationships are influenced by changes in population
> demographics.  I have been using a GLMM to evaluate the following
> global model:
>
> repro =
> glmer(Fawn~Age+I(Age^2)+BodySize+SSCM+AvgAge+Age*AvgAge+I(Age^2)*AvgAge+BodySize*AvgAge+SSCM*AvgAge+(1|Sire),data=datum,family=poisson)
>
>  where:
>
> Age, BodySize, SSCM are measured characteristics Fawn = number of
> fawns produced in a given year AvgAge = Population demographic
> factor (1|Sire) = Random effect for each sampled male ID
>
> I first used the following to evaluate potential overdispersion of my
> data from the global model:
>
> overdisp_fun <- function(model) { ## number of variance parameters
> in ##   an n-by-n variance-covariance matrix vpars <- function(m) {
> nrow(m)*(nrow(m)+1)/2 } model.df <-
> sum(sapply(VarCorr(model),vpars))+length(fixef(model)) rdf <-
> nrow(model.frame(model))-model.df rp <-
> residuals(model,type="pearson") Pearson.chisq <- sum(rp^2) prat <-
> Pearson.chisq/rdf pval <- pchisq(Pearson.chisq, df=rdf,
> lower.tail=FALSE) c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p=pval) }
>
> With the following result
>
> repro =
> glmer(Fawn~Age+I(Age^2)+BodySize+SSCM+AvgAge+Age*AvgAge+I(Age^2)*AvgAge+BodySize*AvgAge+SSCM*AvgAge+(1|Sire),data=datum,family=poisson)
>
>
overdisp_fun(repro)
> chisq                             ratio                          rdf
> p 1.698574e+02      1.681756e+00       1.010000e+02
> 2.169243e-05
>
> Since the ratio of Pearson-statistic to rdf is 1.68 I assume that I
> need to take this overdispersion into account
>
> My first inclination was to use quasipoisson distribution to account
> for overdispersion; however, I see that in no longer available in
> lme4.  I used glmmPQL in the MASS package with quasipoisson but do
> not receive AICc information.  I had planned on using AICc to
> evaluate competitive models.  My specific question is: 1) is there a
> way to generate the necessary information (AICc or something like) to
> compare competitive models from overdispersed data in a current R
> environment? I have read
> https://cran.r-project.org/web/packages/bbmle/vignettes/quasi.pdf but
> I'm having a difficult time understanding exactly how to implement
> from a technical perspective.  I'm on the path of trying to use a
> negative binomial (I'm not locked into this method so please provide
> insight if appropriate) with package glmmADMB: however, I have been
> unable to get this package to load successfully.  I've followed the
> instructions to the best of my understanding and abilities but cannot
> figure out where I'm going wrong.  Any advice is much appreciated as
> I'm totally stumped right now on many fronts.  I'm running windows 7
> on 64-bit machine.  Here is what I have attempted with output:
>
> install.packages("glmmADMB", +
> repos=c("http://glmmadmb.r-forge.r-project.org/repos", +
> getOption("repos")), +     type="source") Installing package into
> ?C:/Users/newboch/Documents/R/win-library/3.3? (as ?lib? is
> unspecified) trying URL
> 'http://glmmadmb.r-forge.r-project.org/repos/src/contrib/glmmADMB_0.8.3.3.tar.gz'
>
>
Content type 'application/x-gzip' length 9391177 bytes (9.0 MB)
> downloaded 9.0 MB * installing *source* package 'glmmADMB' ... ** R
> ** data *** moving datasets to lazyload DB ** inst ** preparing
> package for lazy loading Error in loadNamespace(i, c(lib.loc,
> .libPaths()), versionCheck = vI[[i]]) : there is no package called
> 'stringi' ERROR: lazy loading failed for package 'glmmADMB' *
> removing 'C:/Users/newboch/Documents/R/win-library/3.3/glmmADMB' The
> downloaded source packages are in
> ?C:\Users\newboch\AppData\Local\Temp\RtmpK23VOM\downloaded_packages?
> Warning messages: 1: running command
> '"C:/PROGRA~1/R/R-33~1.1/bin/x64/R" CMD INSTALL -l
> "C:\Users\newboch\Documents\R\win-library\3.3"
> C:\Users\newboch\AppData\Local\Temp\RtmpK23VOM/downloaded_packages/glmmADMB_0.8.3.3.tar.gz'
> had status 1 2: In install.packages("glmmADMB", repos =
> c("http://glmmadmb.r-forge.r-project.org/repos",  : installation of
> package ?glmmADMB? had non-zero exit status
>> glmmADMB:::get_bin_loc()
> Error in loadNamespace(name) : there is no package called ?glmmADMB?
>> library("R2admb") glmmADMB:::get_bin_loc()
> Error in loadNamespace(name) : there is no package called ?glmmADMB?
>> install.packages("glmmADMB")
> Installing package into
> ?C:/Users/newboch/Documents/R/win-library/3.3? (as ?lib? is
> unspecified) Warning message: package ?glmmADMB? is not available
> (for R version 3.3.1) Thanks,
>
> Chad
>
> [[alternative HTML version deleted]]
>
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

From claudia.kasper at iee.unibe.ch  Sun Jun 26 11:59:51 2016
From: claudia.kasper at iee.unibe.ch (claudia.kasper at iee.unibe.ch)
Date: Sun, 26 Jun 2016 09:59:51 +0000
Subject: [R-sig-ME] How to fix individual elements of the residual
 covariance matrix in MCMCglmm (r_1470)
Message-ID: <8C514C5A993CBA43A3FA8A1E242BD216308201D2@aai-exch-mbx4.campus.unibe.ch>

Dear Richard,

to fix the variance for the residual (co)variance matrix you could group the traits in a way that first you have those that should not be fixed and then those that should be fixed. For example, in a trivariate model I used fix=2 so that in a 3x3 (co)variance matrix cells nr 5,6,8,9 (numbered row-wise) are fixed. Hence, the variances of the second and third trait are fixed and their covariances whereas the other parameters are estimated. It is explained in "MCMC Methods for Multi-response Generalized Linear Mixed Models: The MCMCglmm R Package" by Jarrod Hadfield on page 9.

Best wishes,

Claudia Kasper
Institute for Ecology and Evolution
University of Bern
Switzerland

----------------------------------------------------------------------

Message: 1
Date: Wed, 22 Jun 2016 11:34:29 +0000 (UTC)
From: r_1470 <r_1470 at yahoo.co.uk>
To: "r-sig-mixed-models at r-project.org"
        <r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] How to fix individual elements of the residual
        covariance matrix in MCMCglmm
Message-ID:
        <1513886953.12791292.1466595269804.JavaMail.yahoo at mail.yahoo.com>
Content-Type: text/plain; charset="UTF-8"

Hello list,
I am using the MCMCglmm package in R for mixed-model multi-response regression, and I am trying to fix individual elements of the residual covariance matrix (when using rcov = ~ us(trait):units). I thought it might be possible using the 'fix' argument in the prior, but it seems that this either fixes the whole residual matrix to the prior specification, or allows all elements to be estimated. This fixes the whole residual matrix:
prior <- list(R = list(V = diag(5), n = 6, fix = 1), G = list( G1 = list(V = diag(5), n = 6)))
I believe 'fix = 0' would have the same effect as not specifying 'fix' (i.e. the whole matrix is estimated).
Is there a way to fix individual elements (e.g. I may want to fix the covariance between two of my five response variables to a specific value)
Thanks,
Richard.

From killver at gmail.com  Mon Jun 27 14:59:00 2016
From: killver at gmail.com (Philipp Singer)
Date: Mon, 27 Jun 2016 14:59:00 +0200
Subject: [R-sig-ME] Question about zero-inflated Poisson glmer
In-Reply-To: <576D3B1B.3050908@gmail.com>
References: <576B98C4.6000602@gmail.com>
	<CAJuCY5xbiEjCmHjc_3wX2emzJ3NEMTA_qKgC_reWn=zqC7YEng@mail.gmail.com>
	<576BAB84.6080009@gmail.com>
	<CAJuCY5zmK1xCyWOwcCH+Hch_LSdB+AazmUDuPVP6je7ABFU5FA@mail.gmail.com>
	<576BBCFD.8040806@gmail.com>
	<CAJuCY5ycRL6oXs=H5JrEqOHWzd1UsvSNVZM6-MK+V2N=pvbyQA@mail.gmail.com>
	<576BFEBC.3020407@gmail.com>
	<B5AEF3F5-949F-4686-82DA-C234C3C4018B@ufl.edu>
	<576C18F9.9010200@gmail.com> <576C200A.1050405@gmail.com>
	<4D07695C-8CEA-4785-A5B0-46B011625DA0@ufl.edu>
	<576D290A.7090102@gmail.com> <576D3209.6050507@gmail.com>
	<576D3864.1060001@gmail.com> <576D3B1B.3050908@gmail.com>
Message-ID: <CAGPhqeohy3hB8hfnNcj=6d_D=mRVG9CWk910qfSEsEnnr0N__A@mail.gmail.com>

I have now played around more with the data an the models both using lme4
and glmmTMB.

I can report the following:

Modeling the data with a zero-inflated Poisson improves the model
significantly. However, when calling predict and simulating rpoissons, I
end up with nearly no values that are zero (in the original data there are
96% zero).

When I model the data with overdisperion by including an observation-level
random effect, I can also improve the model (not surprisingly due to the
random effect). When I predict outcomes by ignoring the observation-level
random effect (in lme4), I receive bad prediction if I compare it to the
original data. While many zeros can be captured (of course), the positive
outcomes can not be captured well.

Combining zero inflation and overdispersion further improves the model, but
I can only do that with glmmTMB and then have troubles doing predictions
ignoring the observation-level random effect.

Another side question:

In lme4, when I do:

m = glm(x~1,family="poisson")
rpois(n=len(data),lambda=predict(m, type='response',re.form=NA)

vs.

simulate(1,m,re.form=NA)

I receive different outcomes? Do I understand these function wrongly?

Would appreciate some more help/pointers!

Thanks,
Philipp

2016-06-24 15:52 GMT+02:00 Philipp Singer <killver at gmail.com>:

> Thanks - I started an issue there to answer some of my questions.
>
> Regarding the installation: I was trying to somehow do it in anaconda with
> a specific R kernel and had some issues. I am trying to resort that with
> the anaconda guys though, if I have a tutorial on how to properly setup
> glmmTMB in anaconda, I will let you know. The install worked fine in my
> standard R environment.
>
>
> On 24.06.2016 15:40, Ben Bolker wrote:
>
>>   Probably for now the glmmTMB issues page is best.
>>
>>   When you go there:
>>
>>    - details on installation problems/hiccups would be useful
>>    - a reproducible example for the problem listed below would be useful
>>    - dispformula is for allowing dispersion/residual variance to vary
>> with covariates (i.e., modeling heteroscedasticity)
>>
>>    cheers
>>      Ben Bolker
>>
>>
>> On 16-06-24 09:13 AM, Philipp Singer wrote:
>>
>>> Update, I tried it like that, but receive an error message.
>>>
>>> Warning message:
>>> In nlminb(start = par, objective = fn, gradient = gr): NA/NaN function
>>> evaluation
>>>
>>> Error in solve.default(hessian.fixed): Lapack routine dgesv: system is
>>> exactly singular: U[3,3] = 0
>>> Traceback:
>>>
>>> 1. glmmTMB(y ~ 1 + x + (1 | b),
>>>    .     data = data, family = "poisson", dispformula = ~1 + x)
>>> 2. sdreport(obj)
>>> 3. solve(hessian.fixed)
>>> 4. solve(hessian.fixed)
>>> 5. solve.default(hessian.fixed)
>>>
>>> Any ideas on that?
>>>
>>> BTW: Is it fine to post glmmTMB questions here, or should I rather use
>>> the github issue page, or is there maybe a dedicated mailing list?
>>>
>>> Thanks,
>>> Philipp
>>>
>>> On 24.06.2016 14:35, Philipp Singer wrote:
>>>
>>>> It indeed seems to run quite fast; had some trouble installing, but
>>>> works now on my 3.3 R setup.
>>>>
>>>> One question I have is regarding the specification of dispersion as I
>>>> need to specify the dispformula. What is the difference here between
>>>> just specifying fixed effects vs. also the random effects?
>>>>
>>>> On 23.06.2016 23:07, Mollie Brooks wrote:
>>>>
>>>>> glmmTMB does crossed RE. Ben did some timings in vignette("glmmTMB")
>>>>> and it was 2.3 times faster than glmer for one simple GLMM.
>>>>>
>>>>>
>>>>> On 23Jun 2016, at 10:44, Philipp Singer <killver at gmail.com> wrote:
>>>>>>
>>>>>> Did try glmmADMB but unfortunately it is way too slow for my data.
>>>>>>
>>>>>> Did not know about glmmTMB, will try it out. Does it work with
>>>>>> crossed random effects and how does it scale with more data? I will
>>>>>> check the docu and try it though. Thanks for the info.
>>>>>>
>>>>>> On 23.06.2016 19:14, Ben Bolker wrote:
>>>>>>
>>>>>>>    I would also comment that glmmTMB is likely to be much faster
>>>>>>> than the
>>>>>>> lme4-based EM approach ...
>>>>>>>
>>>>>>>    cheers
>>>>>>>      Ben B.
>>>>>>>
>>>>>>> On 16-06-23 12:47 PM, Mollie Brooks wrote:
>>>>>>>
>>>>>>>> Hi Philipp,
>>>>>>>>
>>>>>>>> You could also try fitting the model with and without ZI using
>>>>>>>> either
>>>>>>>> glmmADMB or glmmTMB. Then compare the AICs. I believe model
>>>>>>>> selection
>>>>>>>> is useful for this, but I could be missing something since the
>>>>>>>> simulation procedure that Thierry described seems to recommended
>>>>>>>> more
>>>>>>>> often.
>>>>>>>>
>>>>>>>> https://github.com/glmmTMB/glmmTMB
>>>>>>>> http://glmmadmb.r-forge.r-project.org
>>>>>>>>
>>>>>>>> glmmTMB is still in the development phase, but we?ve done a lot of
>>>>>>>> testing.
>>>>>>>>
>>>>>>>> cheers, Mollie
>>>>>>>>
>>>>>>>> ------------------------ Mollie Brooks, PhD Postdoctoral Researcher,
>>>>>>>> Population Ecology Research Group Department of Evolutionary Biology
>>>>>>>> & Environmental Studies, University of Z?rich
>>>>>>>> http://www.popecol.org/team/mollie-brooks/
>>>>>>>>
>>>>>>>>
>>>>>>>> On 23Jun 2016, at 8:22, Philipp Singer <killver at gmail.com> wrote:
>>>>>>>>>
>>>>>>>>> Thanks, great information, that is really helpful.
>>>>>>>>>
>>>>>>>>> I agree that those are different things, however when using a
>>>>>>>>> random effect for overdispersion, I can simulate the same number of
>>>>>>>>> zero outcomes (~95%).
>>>>>>>>>
>>>>>>>>> On 23.06.2016 15:50, Thierry Onkelinx wrote:
>>>>>>>>>
>>>>>>>>>> Be careful when using overdispersion to model zero-inflation.
>>>>>>>>>> Those are two different things.
>>>>>>>>>>
>>>>>>>>>> I've put some information together in
>>>>>>>>>> http://rpubs.com/INBOstats/zeroinflation
>>>>>>>>>>
>>>>>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
>>>>>>>>>> Research Institute for Nature and Forest team Biometrie &
>>>>>>>>>> Kwaliteitszorg / team Biometrics & Quality Assurance
>>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>>>>>>>>>
>>>>>>>>>> To call in the statistician after the experiment is done may be
>>>>>>>>>> no more than asking him to perform a post-mortem examination: he
>>>>>>>>>> may be able to say what the experiment died of. ~ Sir Ronald
>>>>>>>>>> Aylmer Fisher The plural of anecdote is not data. ~ Roger
>>>>>>>>>> Brinner The combination of some data and an aching desire for an
>>>>>>>>>> answer does not ensure that a reasonable answer can be extracted
>>>>>>>>>> from a given body of data. ~ John Tukey
>>>>>>>>>>
>>>>>>>>>> 2016-06-23 12:42 GMT+02:00 Philipp Singer <killver at gmail.com
>>>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>>:
>>>>>>>>>>
>>>>>>>>>> Thanks! Actually, accounting for overdispersion is super
>>>>>>>>>> important as it seems, then the zeros can be captured well.
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> On 23.06.2016 11:50, Thierry Onkelinx wrote:
>>>>>>>>>>
>>>>>>>>>>> Dear Philipp,
>>>>>>>>>>>
>>>>>>>>>>> 1. Fit a Poisson model to the data. 2. Simulate a new response
>>>>>>>>>>> vector for the dataset according to the model. 3. Count the
>>>>>>>>>>> number of zero's in the simulated response vector. 4. Repeat
>>>>>>>>>>> step 2 and 3 a decent number of time and plot a histogram of
>>>>>>>>>>> the number of zero's in the simulation. If the number of zero's
>>>>>>>>>>> in the original dataset is larger than those in the
>>>>>>>>>>> simulations, then the model can't capture all zero's. In such
>>>>>>>>>>> case, first try to update the model and repeat the procedure.
>>>>>>>>>>> If that fails, look for zero-inflated models.
>>>>>>>>>>>
>>>>>>>>>>> Best regards,
>>>>>>>>>>>
>>>>>>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
>>>>>>>>>>> Research Institute for Nature and Forest team Biometrie &
>>>>>>>>>>> Kwaliteitszorg / team Biometrics & Quality Assurance
>>>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>>>>>>>>>>
>>>>>>>>>>> To call in the statistician after the experiment is done may
>>>>>>>>>>> be no more than asking him to perform a post-mortem
>>>>>>>>>>> examination: he may be able to say what the experiment died of.
>>>>>>>>>>> ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data.
>>>>>>>>>>> ~ Roger Brinner The combination of some data and an aching
>>>>>>>>>>> desire for an answer does not ensure that a reasonable answer
>>>>>>>>>>> can be extracted from a given body of data. ~ John Tukey
>>>>>>>>>>>
>>>>>>>>>>> 2016-06-23 11:27 GMT+02:00 Philipp Singer <killver at gmail.com
>>>>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>>:
>>>>>>>>>>>
>>>>>>>>>>> Thanks Thierry - That totally makes sense. Is there some way of
>>>>>>>>>>> formally checking that, except thinking about the setting and
>>>>>>>>>>> underlying processes?
>>>>>>>>>>>
>>>>>>>>>>> On 23.06.2016 11:04, Thierry Onkelinx wrote:
>>>>>>>>>>>
>>>>>>>>>>>> Dear Philipp,
>>>>>>>>>>>>
>>>>>>>>>>>> Do you have just lots of zero's, or more zero's than the
>>>>>>>>>>>>
>>>>>>>>>>> Poisson
>>>>>>>>>>>
>>>>>>>>>>>> distribution can explain? Those are two different things.
>>>>>>>>>>>>
>>>>>>>>>>> The example
>>>>>>>>>>>
>>>>>>>>>>>> below generates data from a Poisson distribution and has
>>>>>>>>>>>>
>>>>>>>>>>> 99% zero's
>>>>>>>>>>>
>>>>>>>>>>>> but no zero-inflation. The second example has only 1%
>>>>>>>>>>>>
>>>>>>>>>>> zero's but is
>>>>>>>>>>>
>>>>>>>>>>>> clearly zero-inflated.
>>>>>>>>>>>>
>>>>>>>>>>>> set.seed(1) n <- 1e8 sim <- rpois(n, lambda = 0.01) mean(sim
>>>>>>>>>>>> == 0) hist(sim)
>>>>>>>>>>>>
>>>>>>>>>>>> sim.infl <- rbinom(n, size = 1, prob = 0.99) * rpois(n,
>>>>>>>>>>>>
>>>>>>>>>>> lambda = 1000)
>>>>>>>>>>>
>>>>>>>>>>>> mean(sim.infl == 0) hist(sim.infl)
>>>>>>>>>>>>
>>>>>>>>>>>> So before looking for zero-inflated models, try to model
>>>>>>>>>>>>
>>>>>>>>>>> the zero's.
>>>>>>>>>>>
>>>>>>>>>>>> Best regards,
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
>>>>>>>>>>>> Research Institute
>>>>>>>>>>>>
>>>>>>>>>>> for Nature
>>>>>>>>>>>
>>>>>>>>>>>> and Forest team Biometrie & Kwaliteitszorg / team Biometrics
>>>>>>>>>>>> & Quality
>>>>>>>>>>>>
>>>>>>>>>>> Assurance
>>>>>>>>>>>
>>>>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>>>>>>>>>>>
>>>>>>>>>>>> To call in the statistician after the experiment is done
>>>>>>>>>>>>
>>>>>>>>>>> may be no
>>>>>>>>>>>
>>>>>>>>>>>> more than asking him to perform a post-mortem examination:
>>>>>>>>>>>>
>>>>>>>>>>> he may be
>>>>>>>>>>>
>>>>>>>>>>>> able to say what the experiment died of. ~ Sir Ronald
>>>>>>>>>>>>
>>>>>>>>>>> Aylmer Fisher
>>>>>>>>>>>
>>>>>>>>>>>> The plural of anecdote is not data. ~ Roger Brinner The
>>>>>>>>>>>> combination of some data and an aching desire for an
>>>>>>>>>>>>
>>>>>>>>>>> answer does
>>>>>>>>>>>
>>>>>>>>>>>> not ensure that a reasonable answer can be extracted from a
>>>>>>>>>>>>
>>>>>>>>>>> given body
>>>>>>>>>>>
>>>>>>>>>>>> of data. ~ John Tukey
>>>>>>>>>>>>
>>>>>>>>>>>> 2016-06-23 10:07 GMT+02:00 Philipp Singer
>>>>>>>>>>>>
>>>>>>>>>>> <killver at gmail.com <mailto:killver at gmail.com>
>>>>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>
>>>>>>>>>>>
>>>>>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>
>>>>>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>>>:
>>>>>>>>>>>>
>>>>>>>>>>>> Dear group - I am currently fitting a Poisson glmer
>>>>>>>>>>>>
>>>>>>>>>>> where I have
>>>>>>>>>>>
>>>>>>>>>>>> an excess of outcomes that are zero (>95%). I am now
>>>>>>>>>>>>
>>>>>>>>>>> debating on
>>>>>>>>>>>
>>>>>>>>>>>> how to proceed and came up with three options:
>>>>>>>>>>>>
>>>>>>>>>>>> 1.) Just fit a regular glmer to the complete data. I am
>>>>>>>>>>>>
>>>>>>>>>>> not fully
>>>>>>>>>>>
>>>>>>>>>>>> sure how interpret the coefficients then, are they more
>>>>>>>>>>>>
>>>>>>>>>>> optimizing
>>>>>>>>>>>
>>>>>>>>>>>> towards distinguishing zero and non-zero, or also
>>>>>>>>>>>>
>>>>>>>>>>> capturing the
>>>>>>>>>>>
>>>>>>>>>>>> differences in those outcomes that are non-zero?
>>>>>>>>>>>>
>>>>>>>>>>>> 2.) Leave all zeros out of the data and fit a glmer to
>>>>>>>>>>>>
>>>>>>>>>>> only those
>>>>>>>>>>>
>>>>>>>>>>>> outcomes that are non-zero. Then, I would only learn about
>>>>>>>>>>>> differences in the non-zero outcomes though.
>>>>>>>>>>>>
>>>>>>>>>>>> 3.) Use a zero-inflated Poisson model. My data is quite
>>>>>>>>>>>> large-scale, so I am currently playing around with the EM
>>>>>>>>>>>> implementation of Bolker et al. that alternates between
>>>>>>>>>>>>
>>>>>>>>>>> fitting a
>>>>>>>>>>>
>>>>>>>>>>>> glmer with data that are weighted according to their zero
>>>>>>>>>>>> probability, and fitting a logistic regression for the
>>>>>>>>>>>>
>>>>>>>>>>> probability
>>>>>>>>>>>
>>>>>>>>>>>> that a data point is zero. The method is elaborated for
>>>>>>>>>>>>
>>>>>>>>>>> the OWL
>>>>>>>>>>>
>>>>>>>>>>>> data in:
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>> https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
>>>>>>>>>>> <
>>>>>>>>>>> https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
>>>>>>>>>>> >
>>>>>>>>>>>
>>>>>>>>>> I am not fully sure how to interpret the results for the
>>>>>>>
>>>>>>>> zero-inflated version though. Would I need to interpret the
>>>>>>>>>>>> coefficients for the result of the glmer similar to as
>>>>>>>>>>>>
>>>>>>>>>>> I would do
>>>>>>>>>>>
>>>>>>>>>>>> for my idea of 2)? And then on top of that interpret the
>>>>>>>>>>>> coefficients for the logistic regression regarding whether
>>>>>>>>>>>> something is in the perfect or imperfect state? I am
>>>>>>>>>>>>
>>>>>>>>>>> also not
>>>>>>>>>>>
>>>>>>>>>>>> quite sure what the common approach for the zformula is
>>>>>>>>>>>>
>>>>>>>>>>> here. The
>>>>>>>>>>>
>>>>>>>>>>>> OWL elaborations only use zformula=z~1, so no random
>>>>>>>>>>>>
>>>>>>>>>>> effect; I
>>>>>>>>>>>
>>>>>>>>>>>> would use the same formula as for the glmer.
>>>>>>>>>>>>
>>>>>>>>>>>> I am appreciating some help and pointers.
>>>>>>>>>>>>
>>>>>>>>>>>> Thanks! Philipp
>>>>>>>>>>>>
>>>>>>>>>>>> _______________________________________________
>>>>>>>>>>>> R-sig-mixed-models at r-project.org
>>>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>>>>>>>>>>
>>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>>
>>>>>>>>>>>
>>>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>>>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>>>>>>>>>>
>>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>>> mailing list
>>>>>>>>>>>
>>>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>> [[alternative HTML version deleted]]
>>>>>>>>>>>
>>>>>>>>>>> _______________________________________________
>>>>>>>>>>> R-sig-mixed-models at r-project.org
>>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>> mailing list
>>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> [[alternative HTML version deleted]]
>>>>>>>>>
>>>>>>>>> _______________________________________________
>>>>>>>>> R-sig-mixed-models at r-project.org
>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>>>>>
>>>>>>>> [[alternative HTML version deleted]]
>>>>>>>>
>>>>>>>> _______________________________________________
>>>>>>>> R-sig-mixed-models at r-project.org
>>>>>>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>>
>>>>>>>> _______________________________________________
>>>>>>> R-sig-mixed-models at r-project.org
>>>>>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org
>>>>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>
>>>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Jun 27 15:06:45 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 27 Jun 2016 15:06:45 +0200
Subject: [R-sig-ME] Question about zero-inflated Poisson glmer
In-Reply-To: <CAGPhqeohy3hB8hfnNcj=6d_D=mRVG9CWk910qfSEsEnnr0N__A@mail.gmail.com>
References: <576B98C4.6000602@gmail.com>
	<CAJuCY5xbiEjCmHjc_3wX2emzJ3NEMTA_qKgC_reWn=zqC7YEng@mail.gmail.com>
	<576BAB84.6080009@gmail.com>
	<CAJuCY5zmK1xCyWOwcCH+Hch_LSdB+AazmUDuPVP6je7ABFU5FA@mail.gmail.com>
	<576BBCFD.8040806@gmail.com>
	<CAJuCY5ycRL6oXs=H5JrEqOHWzd1UsvSNVZM6-MK+V2N=pvbyQA@mail.gmail.com>
	<576BFEBC.3020407@gmail.com>
	<B5AEF3F5-949F-4686-82DA-C234C3C4018B@ufl.edu>
	<576C18F9.9010200@gmail.com> <576C200A.1050405@gmail.com>
	<4D07695C-8CEA-4785-A5B0-46B011625DA0@ufl.edu>
	<576D290A.7090102@gmail.com> <576D3209.6050507@gmail.com>
	<576D3864.1060001@gmail.com> <576D3B1B.3050908@gmail.com>
	<CAGPhqeohy3hB8hfnNcj=6d_D=mRVG9CWk910qfSEsEnnr0N__A@mail.gmail.com>
Message-ID: <CAJuCY5wcBboPCe58h2kYPL1+tXwe=5dmVT10n6wFCJSE+7-wnw@mail.gmail.com>

Dear Philipp,

How strong is the variance of the observation level random effect? I would
trust a model with large OLRE variance.

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-06-27 14:59 GMT+02:00 Philipp Singer <killver at gmail.com>:

> I have now played around more with the data an the models both using lme4
> and glmmTMB.
>
> I can report the following:
>
> Modeling the data with a zero-inflated Poisson improves the model
> significantly. However, when calling predict and simulating rpoissons, I
> end up with nearly no values that are zero (in the original data there are
> 96% zero).
>
> When I model the data with overdisperion by including an observation-level
> random effect, I can also improve the model (not surprisingly due to the
> random effect). When I predict outcomes by ignoring the observation-level
> random effect (in lme4), I receive bad prediction if I compare it to the
> original data. While many zeros can be captured (of course), the positive
> outcomes can not be captured well.
>
> Combining zero inflation and overdispersion further improves the model, but
> I can only do that with glmmTMB and then have troubles doing predictions
> ignoring the observation-level random effect.
>
> Another side question:
>
> In lme4, when I do:
>
> m = glm(x~1,family="poisson")
> rpois(n=len(data),lambda=predict(m, type='response',re.form=NA)
>
> vs.
>
> simulate(1,m,re.form=NA)
>
> I receive different outcomes? Do I understand these function wrongly?
>
> Would appreciate some more help/pointers!
>
> Thanks,
> Philipp
>
> 2016-06-24 15:52 GMT+02:00 Philipp Singer <killver at gmail.com>:
>
> > Thanks - I started an issue there to answer some of my questions.
> >
> > Regarding the installation: I was trying to somehow do it in anaconda
> with
> > a specific R kernel and had some issues. I am trying to resort that with
> > the anaconda guys though, if I have a tutorial on how to properly setup
> > glmmTMB in anaconda, I will let you know. The install worked fine in my
> > standard R environment.
> >
> >
> > On 24.06.2016 15:40, Ben Bolker wrote:
> >
> >>   Probably for now the glmmTMB issues page is best.
> >>
> >>   When you go there:
> >>
> >>    - details on installation problems/hiccups would be useful
> >>    - a reproducible example for the problem listed below would be useful
> >>    - dispformula is for allowing dispersion/residual variance to vary
> >> with covariates (i.e., modeling heteroscedasticity)
> >>
> >>    cheers
> >>      Ben Bolker
> >>
> >>
> >> On 16-06-24 09:13 AM, Philipp Singer wrote:
> >>
> >>> Update, I tried it like that, but receive an error message.
> >>>
> >>> Warning message:
> >>> In nlminb(start = par, objective = fn, gradient = gr): NA/NaN function
> >>> evaluation
> >>>
> >>> Error in solve.default(hessian.fixed): Lapack routine dgesv: system is
> >>> exactly singular: U[3,3] = 0
> >>> Traceback:
> >>>
> >>> 1. glmmTMB(y ~ 1 + x + (1 | b),
> >>>    .     data = data, family = "poisson", dispformula = ~1 + x)
> >>> 2. sdreport(obj)
> >>> 3. solve(hessian.fixed)
> >>> 4. solve(hessian.fixed)
> >>> 5. solve.default(hessian.fixed)
> >>>
> >>> Any ideas on that?
> >>>
> >>> BTW: Is it fine to post glmmTMB questions here, or should I rather use
> >>> the github issue page, or is there maybe a dedicated mailing list?
> >>>
> >>> Thanks,
> >>> Philipp
> >>>
> >>> On 24.06.2016 14:35, Philipp Singer wrote:
> >>>
> >>>> It indeed seems to run quite fast; had some trouble installing, but
> >>>> works now on my 3.3 R setup.
> >>>>
> >>>> One question I have is regarding the specification of dispersion as I
> >>>> need to specify the dispformula. What is the difference here between
> >>>> just specifying fixed effects vs. also the random effects?
> >>>>
> >>>> On 23.06.2016 23:07, Mollie Brooks wrote:
> >>>>
> >>>>> glmmTMB does crossed RE. Ben did some timings in vignette("glmmTMB")
> >>>>> and it was 2.3 times faster than glmer for one simple GLMM.
> >>>>>
> >>>>>
> >>>>> On 23Jun 2016, at 10:44, Philipp Singer <killver at gmail.com> wrote:
> >>>>>>
> >>>>>> Did try glmmADMB but unfortunately it is way too slow for my data.
> >>>>>>
> >>>>>> Did not know about glmmTMB, will try it out. Does it work with
> >>>>>> crossed random effects and how does it scale with more data? I will
> >>>>>> check the docu and try it though. Thanks for the info.
> >>>>>>
> >>>>>> On 23.06.2016 19:14, Ben Bolker wrote:
> >>>>>>
> >>>>>>>    I would also comment that glmmTMB is likely to be much faster
> >>>>>>> than the
> >>>>>>> lme4-based EM approach ...
> >>>>>>>
> >>>>>>>    cheers
> >>>>>>>      Ben B.
> >>>>>>>
> >>>>>>> On 16-06-23 12:47 PM, Mollie Brooks wrote:
> >>>>>>>
> >>>>>>>> Hi Philipp,
> >>>>>>>>
> >>>>>>>> You could also try fitting the model with and without ZI using
> >>>>>>>> either
> >>>>>>>> glmmADMB or glmmTMB. Then compare the AICs. I believe model
> >>>>>>>> selection
> >>>>>>>> is useful for this, but I could be missing something since the
> >>>>>>>> simulation procedure that Thierry described seems to recommended
> >>>>>>>> more
> >>>>>>>> often.
> >>>>>>>>
> >>>>>>>> https://github.com/glmmTMB/glmmTMB
> >>>>>>>> http://glmmadmb.r-forge.r-project.org
> >>>>>>>>
> >>>>>>>> glmmTMB is still in the development phase, but we?ve done a lot of
> >>>>>>>> testing.
> >>>>>>>>
> >>>>>>>> cheers, Mollie
> >>>>>>>>
> >>>>>>>> ------------------------ Mollie Brooks, PhD Postdoctoral
> Researcher,
> >>>>>>>> Population Ecology Research Group Department of Evolutionary
> Biology
> >>>>>>>> & Environmental Studies, University of Z?rich
> >>>>>>>> http://www.popecol.org/team/mollie-brooks/
> >>>>>>>>
> >>>>>>>>
> >>>>>>>> On 23Jun 2016, at 8:22, Philipp Singer <killver at gmail.com> wrote:
> >>>>>>>>>
> >>>>>>>>> Thanks, great information, that is really helpful.
> >>>>>>>>>
> >>>>>>>>> I agree that those are different things, however when using a
> >>>>>>>>> random effect for overdispersion, I can simulate the same number
> of
> >>>>>>>>> zero outcomes (~95%).
> >>>>>>>>>
> >>>>>>>>> On 23.06.2016 15:50, Thierry Onkelinx wrote:
> >>>>>>>>>
> >>>>>>>>>> Be careful when using overdispersion to model zero-inflation.
> >>>>>>>>>> Those are two different things.
> >>>>>>>>>>
> >>>>>>>>>> I've put some information together in
> >>>>>>>>>> http://rpubs.com/INBOstats/zeroinflation
> >>>>>>>>>>
> >>>>>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
> >>>>>>>>>> Research Institute for Nature and Forest team Biometrie &
> >>>>>>>>>> Kwaliteitszorg / team Biometrics & Quality Assurance
> >>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
> >>>>>>>>>>
> >>>>>>>>>> To call in the statistician after the experiment is done may be
> >>>>>>>>>> no more than asking him to perform a post-mortem examination: he
> >>>>>>>>>> may be able to say what the experiment died of. ~ Sir Ronald
> >>>>>>>>>> Aylmer Fisher The plural of anecdote is not data. ~ Roger
> >>>>>>>>>> Brinner The combination of some data and an aching desire for an
> >>>>>>>>>> answer does not ensure that a reasonable answer can be extracted
> >>>>>>>>>> from a given body of data. ~ John Tukey
> >>>>>>>>>>
> >>>>>>>>>> 2016-06-23 12:42 GMT+02:00 Philipp Singer <killver at gmail.com
> >>>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>>:
> >>>>>>>>>>
> >>>>>>>>>> Thanks! Actually, accounting for overdispersion is super
> >>>>>>>>>> important as it seems, then the zeros can be captured well.
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>> On 23.06.2016 11:50, Thierry Onkelinx wrote:
> >>>>>>>>>>
> >>>>>>>>>>> Dear Philipp,
> >>>>>>>>>>>
> >>>>>>>>>>> 1. Fit a Poisson model to the data. 2. Simulate a new response
> >>>>>>>>>>> vector for the dataset according to the model. 3. Count the
> >>>>>>>>>>> number of zero's in the simulated response vector. 4. Repeat
> >>>>>>>>>>> step 2 and 3 a decent number of time and plot a histogram of
> >>>>>>>>>>> the number of zero's in the simulation. If the number of zero's
> >>>>>>>>>>> in the original dataset is larger than those in the
> >>>>>>>>>>> simulations, then the model can't capture all zero's. In such
> >>>>>>>>>>> case, first try to update the model and repeat the procedure.
> >>>>>>>>>>> If that fails, look for zero-inflated models.
> >>>>>>>>>>>
> >>>>>>>>>>> Best regards,
> >>>>>>>>>>>
> >>>>>>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
> >>>>>>>>>>> Research Institute for Nature and Forest team Biometrie &
> >>>>>>>>>>> Kwaliteitszorg / team Biometrics & Quality Assurance
> >>>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
> >>>>>>>>>>>
> >>>>>>>>>>> To call in the statistician after the experiment is done may
> >>>>>>>>>>> be no more than asking him to perform a post-mortem
> >>>>>>>>>>> examination: he may be able to say what the experiment died of.
> >>>>>>>>>>> ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data.
> >>>>>>>>>>> ~ Roger Brinner The combination of some data and an aching
> >>>>>>>>>>> desire for an answer does not ensure that a reasonable answer
> >>>>>>>>>>> can be extracted from a given body of data. ~ John Tukey
> >>>>>>>>>>>
> >>>>>>>>>>> 2016-06-23 11:27 GMT+02:00 Philipp Singer <killver at gmail.com
> >>>>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>>:
> >>>>>>>>>>>
> >>>>>>>>>>> Thanks Thierry - That totally makes sense. Is there some way of
> >>>>>>>>>>> formally checking that, except thinking about the setting and
> >>>>>>>>>>> underlying processes?
> >>>>>>>>>>>
> >>>>>>>>>>> On 23.06.2016 11:04, Thierry Onkelinx wrote:
> >>>>>>>>>>>
> >>>>>>>>>>>> Dear Philipp,
> >>>>>>>>>>>>
> >>>>>>>>>>>> Do you have just lots of zero's, or more zero's than the
> >>>>>>>>>>>>
> >>>>>>>>>>> Poisson
> >>>>>>>>>>>
> >>>>>>>>>>>> distribution can explain? Those are two different things.
> >>>>>>>>>>>>
> >>>>>>>>>>> The example
> >>>>>>>>>>>
> >>>>>>>>>>>> below generates data from a Poisson distribution and has
> >>>>>>>>>>>>
> >>>>>>>>>>> 99% zero's
> >>>>>>>>>>>
> >>>>>>>>>>>> but no zero-inflation. The second example has only 1%
> >>>>>>>>>>>>
> >>>>>>>>>>> zero's but is
> >>>>>>>>>>>
> >>>>>>>>>>>> clearly zero-inflated.
> >>>>>>>>>>>>
> >>>>>>>>>>>> set.seed(1) n <- 1e8 sim <- rpois(n, lambda = 0.01) mean(sim
> >>>>>>>>>>>> == 0) hist(sim)
> >>>>>>>>>>>>
> >>>>>>>>>>>> sim.infl <- rbinom(n, size = 1, prob = 0.99) * rpois(n,
> >>>>>>>>>>>>
> >>>>>>>>>>> lambda = 1000)
> >>>>>>>>>>>
> >>>>>>>>>>>> mean(sim.infl == 0) hist(sim.infl)
> >>>>>>>>>>>>
> >>>>>>>>>>>> So before looking for zero-inflated models, try to model
> >>>>>>>>>>>>
> >>>>>>>>>>> the zero's.
> >>>>>>>>>>>
> >>>>>>>>>>>> Best regards,
> >>>>>>>>>>>>
> >>>>>>>>>>>>
> >>>>>>>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
> >>>>>>>>>>>> Research Institute
> >>>>>>>>>>>>
> >>>>>>>>>>> for Nature
> >>>>>>>>>>>
> >>>>>>>>>>>> and Forest team Biometrie & Kwaliteitszorg / team Biometrics
> >>>>>>>>>>>> & Quality
> >>>>>>>>>>>>
> >>>>>>>>>>> Assurance
> >>>>>>>>>>>
> >>>>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
> >>>>>>>>>>>>
> >>>>>>>>>>>> To call in the statistician after the experiment is done
> >>>>>>>>>>>>
> >>>>>>>>>>> may be no
> >>>>>>>>>>>
> >>>>>>>>>>>> more than asking him to perform a post-mortem examination:
> >>>>>>>>>>>>
> >>>>>>>>>>> he may be
> >>>>>>>>>>>
> >>>>>>>>>>>> able to say what the experiment died of. ~ Sir Ronald
> >>>>>>>>>>>>
> >>>>>>>>>>> Aylmer Fisher
> >>>>>>>>>>>
> >>>>>>>>>>>> The plural of anecdote is not data. ~ Roger Brinner The
> >>>>>>>>>>>> combination of some data and an aching desire for an
> >>>>>>>>>>>>
> >>>>>>>>>>> answer does
> >>>>>>>>>>>
> >>>>>>>>>>>> not ensure that a reasonable answer can be extracted from a
> >>>>>>>>>>>>
> >>>>>>>>>>> given body
> >>>>>>>>>>>
> >>>>>>>>>>>> of data. ~ John Tukey
> >>>>>>>>>>>>
> >>>>>>>>>>>> 2016-06-23 10:07 GMT+02:00 Philipp Singer
> >>>>>>>>>>>>
> >>>>>>>>>>> <killver at gmail.com <mailto:killver at gmail.com>
> >>>>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>
> >>>>>>>>>>>
> >>>>>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>
> >>>>>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>>>:
> >>>>>>>>>>>>
> >>>>>>>>>>>> Dear group - I am currently fitting a Poisson glmer
> >>>>>>>>>>>>
> >>>>>>>>>>> where I have
> >>>>>>>>>>>
> >>>>>>>>>>>> an excess of outcomes that are zero (>95%). I am now
> >>>>>>>>>>>>
> >>>>>>>>>>> debating on
> >>>>>>>>>>>
> >>>>>>>>>>>> how to proceed and came up with three options:
> >>>>>>>>>>>>
> >>>>>>>>>>>> 1.) Just fit a regular glmer to the complete data. I am
> >>>>>>>>>>>>
> >>>>>>>>>>> not fully
> >>>>>>>>>>>
> >>>>>>>>>>>> sure how interpret the coefficients then, are they more
> >>>>>>>>>>>>
> >>>>>>>>>>> optimizing
> >>>>>>>>>>>
> >>>>>>>>>>>> towards distinguishing zero and non-zero, or also
> >>>>>>>>>>>>
> >>>>>>>>>>> capturing the
> >>>>>>>>>>>
> >>>>>>>>>>>> differences in those outcomes that are non-zero?
> >>>>>>>>>>>>
> >>>>>>>>>>>> 2.) Leave all zeros out of the data and fit a glmer to
> >>>>>>>>>>>>
> >>>>>>>>>>> only those
> >>>>>>>>>>>
> >>>>>>>>>>>> outcomes that are non-zero. Then, I would only learn about
> >>>>>>>>>>>> differences in the non-zero outcomes though.
> >>>>>>>>>>>>
> >>>>>>>>>>>> 3.) Use a zero-inflated Poisson model. My data is quite
> >>>>>>>>>>>> large-scale, so I am currently playing around with the EM
> >>>>>>>>>>>> implementation of Bolker et al. that alternates between
> >>>>>>>>>>>>
> >>>>>>>>>>> fitting a
> >>>>>>>>>>>
> >>>>>>>>>>>> glmer with data that are weighted according to their zero
> >>>>>>>>>>>> probability, and fitting a logistic regression for the
> >>>>>>>>>>>>
> >>>>>>>>>>> probability
> >>>>>>>>>>>
> >>>>>>>>>>>> that a data point is zero. The method is elaborated for
> >>>>>>>>>>>>
> >>>>>>>>>>> the OWL
> >>>>>>>>>>>
> >>>>>>>>>>>> data in:
> >>>>>>>>>>>>
> >>>>>>>>>>>>
> >>>>>>>>>>>
> https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
> >>>>>>>>>>> <
> >>>>>>>>>>>
> https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
> >>>>>>>>>>> >
> >>>>>>>>>>>
> >>>>>>>>>> I am not fully sure how to interpret the results for the
> >>>>>>>
> >>>>>>>> zero-inflated version though. Would I need to interpret the
> >>>>>>>>>>>> coefficients for the result of the glmer similar to as
> >>>>>>>>>>>>
> >>>>>>>>>>> I would do
> >>>>>>>>>>>
> >>>>>>>>>>>> for my idea of 2)? And then on top of that interpret the
> >>>>>>>>>>>> coefficients for the logistic regression regarding whether
> >>>>>>>>>>>> something is in the perfect or imperfect state? I am
> >>>>>>>>>>>>
> >>>>>>>>>>> also not
> >>>>>>>>>>>
> >>>>>>>>>>>> quite sure what the common approach for the zformula is
> >>>>>>>>>>>>
> >>>>>>>>>>> here. The
> >>>>>>>>>>>
> >>>>>>>>>>>> OWL elaborations only use zformula=z~1, so no random
> >>>>>>>>>>>>
> >>>>>>>>>>> effect; I
> >>>>>>>>>>>
> >>>>>>>>>>>> would use the same formula as for the glmer.
> >>>>>>>>>>>>
> >>>>>>>>>>>> I am appreciating some help and pointers.
> >>>>>>>>>>>>
> >>>>>>>>>>>> Thanks! Philipp
> >>>>>>>>>>>>
> >>>>>>>>>>>> _______________________________________________
> >>>>>>>>>>>> R-sig-mixed-models at r-project.org
> >>>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
> >>>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
> >>>>>>>>>>>>
> >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
> >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>>
> >>>>>>>>>>>
> >>>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
> >>>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
> >>>>>>>>>>>>
> >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
> >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>>> mailing list
> >>>>>>>>>>>
> >>>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>>>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >>>>>>>>>>>>
> >>>>>>>>>>>>
> >>>>>>>>>>>> [[alternative HTML version deleted]]
> >>>>>>>>>>>
> >>>>>>>>>>> _______________________________________________
> >>>>>>>>>>> R-sig-mixed-models at r-project.org
> >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
> >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
> >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
> >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>> mailing list
> >>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >>>>>>>>>>>
> >>>>>>>>>>>
> >>>>>>>>>>> [[alternative HTML version deleted]]
> >>>>>>>>>
> >>>>>>>>> _______________________________________________
> >>>>>>>>> R-sig-mixed-models at r-project.org
> >>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
> >>>>>>>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
> >>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >>>>>>>>>
> >>>>>>>> [[alternative HTML version deleted]]
> >>>>>>>>
> >>>>>>>> _______________________________________________
> >>>>>>>> R-sig-mixed-models at r-project.org
> >>>>>>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
> >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>>>>>
> >>>>>>>> _______________________________________________
> >>>>>>> R-sig-mixed-models at r-project.org
> >>>>>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
> >>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>>>>
> >>>>>> _______________________________________________
> >>>>>> R-sig-mixed-models at r-project.org
> >>>>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>>>
> >>>>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>
> >>>
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From killver at gmail.com  Mon Jun 27 15:18:45 2016
From: killver at gmail.com (Philipp Singer)
Date: Mon, 27 Jun 2016 15:18:45 +0200
Subject: [R-sig-ME] Question about zero-inflated Poisson glmer
In-Reply-To: <CAJuCY5wcBboPCe58h2kYPL1+tXwe=5dmVT10n6wFCJSE+7-wnw@mail.gmail.com>
References: <576B98C4.6000602@gmail.com>
	<CAJuCY5xbiEjCmHjc_3wX2emzJ3NEMTA_qKgC_reWn=zqC7YEng@mail.gmail.com>
	<576BAB84.6080009@gmail.com>
	<CAJuCY5zmK1xCyWOwcCH+Hch_LSdB+AazmUDuPVP6je7ABFU5FA@mail.gmail.com>
	<576BBCFD.8040806@gmail.com>
	<CAJuCY5ycRL6oXs=H5JrEqOHWzd1UsvSNVZM6-MK+V2N=pvbyQA@mail.gmail.com>
	<576BFEBC.3020407@gmail.com>
	<B5AEF3F5-949F-4686-82DA-C234C3C4018B@ufl.edu>
	<576C18F9.9010200@gmail.com> <576C200A.1050405@gmail.com>
	<4D07695C-8CEA-4785-A5B0-46B011625DA0@ufl.edu>
	<576D290A.7090102@gmail.com> <576D3209.6050507@gmail.com>
	<576D3864.1060001@gmail.com> <576D3B1B.3050908@gmail.com>
	<CAGPhqeohy3hB8hfnNcj=6d_D=mRVG9CWk910qfSEsEnnr0N__A@mail.gmail.com>
	<CAJuCY5wcBboPCe58h2kYPL1+tXwe=5dmVT10n6wFCJSE+7-wnw@mail.gmail.com>
Message-ID: <CAGPhqeojDg=tXJi+oYMqAqGwCaVxkkhnhV3MBr2e9O2agEeJUA@mail.gmail.com>

The variance is:

Conditional model:
 Groups            Name        Variance  Std.Dev.
 obs               (Intercept) 8.991e+01 9.4823139



2016-06-27 15:06 GMT+02:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:

> Dear Philipp,
>
> How strong is the variance of the observation level random effect? I would
> trust a model with large OLRE variance.
>
> Best regards,
>
> Thierry
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2016-06-27 14:59 GMT+02:00 Philipp Singer <killver at gmail.com>:
>
>> I have now played around more with the data an the models both using lme4
>> and glmmTMB.
>>
>> I can report the following:
>>
>> Modeling the data with a zero-inflated Poisson improves the model
>> significantly. However, when calling predict and simulating rpoissons, I
>> end up with nearly no values that are zero (in the original data there are
>> 96% zero).
>>
>> When I model the data with overdisperion by including an observation-level
>> random effect, I can also improve the model (not surprisingly due to the
>> random effect). When I predict outcomes by ignoring the observation-level
>> random effect (in lme4), I receive bad prediction if I compare it to the
>> original data. While many zeros can be captured (of course), the positive
>> outcomes can not be captured well.
>>
>> Combining zero inflation and overdispersion further improves the model,
>> but
>> I can only do that with glmmTMB and then have troubles doing predictions
>> ignoring the observation-level random effect.
>>
>> Another side question:
>>
>> In lme4, when I do:
>>
>> m = glm(x~1,family="poisson")
>> rpois(n=len(data),lambda=predict(m, type='response',re.form=NA)
>>
>> vs.
>>
>> simulate(1,m,re.form=NA)
>>
>> I receive different outcomes? Do I understand these function wrongly?
>>
>> Would appreciate some more help/pointers!
>>
>> Thanks,
>> Philipp
>>
>> 2016-06-24 15:52 GMT+02:00 Philipp Singer <killver at gmail.com>:
>>
>> > Thanks - I started an issue there to answer some of my questions.
>> >
>> > Regarding the installation: I was trying to somehow do it in anaconda
>> with
>> > a specific R kernel and had some issues. I am trying to resort that with
>> > the anaconda guys though, if I have a tutorial on how to properly setup
>> > glmmTMB in anaconda, I will let you know. The install worked fine in my
>> > standard R environment.
>> >
>> >
>> > On 24.06.2016 15:40, Ben Bolker wrote:
>> >
>> >>   Probably for now the glmmTMB issues page is best.
>> >>
>> >>   When you go there:
>> >>
>> >>    - details on installation problems/hiccups would be useful
>> >>    - a reproducible example for the problem listed below would be
>> useful
>> >>    - dispformula is for allowing dispersion/residual variance to vary
>> >> with covariates (i.e., modeling heteroscedasticity)
>> >>
>> >>    cheers
>> >>      Ben Bolker
>> >>
>> >>
>> >> On 16-06-24 09:13 AM, Philipp Singer wrote:
>> >>
>> >>> Update, I tried it like that, but receive an error message.
>> >>>
>> >>> Warning message:
>> >>> In nlminb(start = par, objective = fn, gradient = gr): NA/NaN function
>> >>> evaluation
>> >>>
>> >>> Error in solve.default(hessian.fixed): Lapack routine dgesv: system is
>> >>> exactly singular: U[3,3] = 0
>> >>> Traceback:
>> >>>
>> >>> 1. glmmTMB(y ~ 1 + x + (1 | b),
>> >>>    .     data = data, family = "poisson", dispformula = ~1 + x)
>> >>> 2. sdreport(obj)
>> >>> 3. solve(hessian.fixed)
>> >>> 4. solve(hessian.fixed)
>> >>> 5. solve.default(hessian.fixed)
>> >>>
>> >>> Any ideas on that?
>> >>>
>> >>> BTW: Is it fine to post glmmTMB questions here, or should I rather use
>> >>> the github issue page, or is there maybe a dedicated mailing list?
>> >>>
>> >>> Thanks,
>> >>> Philipp
>> >>>
>> >>> On 24.06.2016 14:35, Philipp Singer wrote:
>> >>>
>> >>>> It indeed seems to run quite fast; had some trouble installing, but
>> >>>> works now on my 3.3 R setup.
>> >>>>
>> >>>> One question I have is regarding the specification of dispersion as I
>> >>>> need to specify the dispformula. What is the difference here between
>> >>>> just specifying fixed effects vs. also the random effects?
>> >>>>
>> >>>> On 23.06.2016 23:07, Mollie Brooks wrote:
>> >>>>
>> >>>>> glmmTMB does crossed RE. Ben did some timings in vignette("glmmTMB")
>> >>>>> and it was 2.3 times faster than glmer for one simple GLMM.
>> >>>>>
>> >>>>>
>> >>>>> On 23Jun 2016, at 10:44, Philipp Singer <killver at gmail.com> wrote:
>> >>>>>>
>> >>>>>> Did try glmmADMB but unfortunately it is way too slow for my data.
>> >>>>>>
>> >>>>>> Did not know about glmmTMB, will try it out. Does it work with
>> >>>>>> crossed random effects and how does it scale with more data? I will
>> >>>>>> check the docu and try it though. Thanks for the info.
>> >>>>>>
>> >>>>>> On 23.06.2016 19:14, Ben Bolker wrote:
>> >>>>>>
>> >>>>>>>    I would also comment that glmmTMB is likely to be much faster
>> >>>>>>> than the
>> >>>>>>> lme4-based EM approach ...
>> >>>>>>>
>> >>>>>>>    cheers
>> >>>>>>>      Ben B.
>> >>>>>>>
>> >>>>>>> On 16-06-23 12:47 PM, Mollie Brooks wrote:
>> >>>>>>>
>> >>>>>>>> Hi Philipp,
>> >>>>>>>>
>> >>>>>>>> You could also try fitting the model with and without ZI using
>> >>>>>>>> either
>> >>>>>>>> glmmADMB or glmmTMB. Then compare the AICs. I believe model
>> >>>>>>>> selection
>> >>>>>>>> is useful for this, but I could be missing something since the
>> >>>>>>>> simulation procedure that Thierry described seems to recommended
>> >>>>>>>> more
>> >>>>>>>> often.
>> >>>>>>>>
>> >>>>>>>> https://github.com/glmmTMB/glmmTMB
>> >>>>>>>> http://glmmadmb.r-forge.r-project.org
>> >>>>>>>>
>> >>>>>>>> glmmTMB is still in the development phase, but we?ve done a lot
>> of
>> >>>>>>>> testing.
>> >>>>>>>>
>> >>>>>>>> cheers, Mollie
>> >>>>>>>>
>> >>>>>>>> ------------------------ Mollie Brooks, PhD Postdoctoral
>> Researcher,
>> >>>>>>>> Population Ecology Research Group Department of Evolutionary
>> Biology
>> >>>>>>>> & Environmental Studies, University of Z?rich
>> >>>>>>>> http://www.popecol.org/team/mollie-brooks/
>> >>>>>>>>
>> >>>>>>>>
>> >>>>>>>> On 23Jun 2016, at 8:22, Philipp Singer <killver at gmail.com>
>> wrote:
>> >>>>>>>>>
>> >>>>>>>>> Thanks, great information, that is really helpful.
>> >>>>>>>>>
>> >>>>>>>>> I agree that those are different things, however when using a
>> >>>>>>>>> random effect for overdispersion, I can simulate the same
>> number of
>> >>>>>>>>> zero outcomes (~95%).
>> >>>>>>>>>
>> >>>>>>>>> On 23.06.2016 15:50, Thierry Onkelinx wrote:
>> >>>>>>>>>
>> >>>>>>>>>> Be careful when using overdispersion to model zero-inflation.
>> >>>>>>>>>> Those are two different things.
>> >>>>>>>>>>
>> >>>>>>>>>> I've put some information together in
>> >>>>>>>>>> http://rpubs.com/INBOstats/zeroinflation
>> >>>>>>>>>>
>> >>>>>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
>> >>>>>>>>>> Research Institute for Nature and Forest team Biometrie &
>> >>>>>>>>>> Kwaliteitszorg / team Biometrics & Quality Assurance
>> >>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>> >>>>>>>>>>
>> >>>>>>>>>> To call in the statistician after the experiment is done may be
>> >>>>>>>>>> no more than asking him to perform a post-mortem examination:
>> he
>> >>>>>>>>>> may be able to say what the experiment died of. ~ Sir Ronald
>> >>>>>>>>>> Aylmer Fisher The plural of anecdote is not data. ~ Roger
>> >>>>>>>>>> Brinner The combination of some data and an aching desire for
>> an
>> >>>>>>>>>> answer does not ensure that a reasonable answer can be
>> extracted
>> >>>>>>>>>> from a given body of data. ~ John Tukey
>> >>>>>>>>>>
>> >>>>>>>>>> 2016-06-23 12:42 GMT+02:00 Philipp Singer <killver at gmail.com
>> >>>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>>:
>> >>>>>>>>>>
>> >>>>>>>>>> Thanks! Actually, accounting for overdispersion is super
>> >>>>>>>>>> important as it seems, then the zeros can be captured well.
>> >>>>>>>>>>
>> >>>>>>>>>>
>> >>>>>>>>>> On 23.06.2016 11:50, Thierry Onkelinx wrote:
>> >>>>>>>>>>
>> >>>>>>>>>>> Dear Philipp,
>> >>>>>>>>>>>
>> >>>>>>>>>>> 1. Fit a Poisson model to the data. 2. Simulate a new response
>> >>>>>>>>>>> vector for the dataset according to the model. 3. Count the
>> >>>>>>>>>>> number of zero's in the simulated response vector. 4. Repeat
>> >>>>>>>>>>> step 2 and 3 a decent number of time and plot a histogram of
>> >>>>>>>>>>> the number of zero's in the simulation. If the number of
>> zero's
>> >>>>>>>>>>> in the original dataset is larger than those in the
>> >>>>>>>>>>> simulations, then the model can't capture all zero's. In such
>> >>>>>>>>>>> case, first try to update the model and repeat the procedure.
>> >>>>>>>>>>> If that fails, look for zero-inflated models.
>> >>>>>>>>>>>
>> >>>>>>>>>>> Best regards,
>> >>>>>>>>>>>
>> >>>>>>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
>> >>>>>>>>>>> Research Institute for Nature and Forest team Biometrie &
>> >>>>>>>>>>> Kwaliteitszorg / team Biometrics & Quality Assurance
>> >>>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>> >>>>>>>>>>>
>> >>>>>>>>>>> To call in the statistician after the experiment is done may
>> >>>>>>>>>>> be no more than asking him to perform a post-mortem
>> >>>>>>>>>>> examination: he may be able to say what the experiment died
>> of.
>> >>>>>>>>>>> ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data.
>> >>>>>>>>>>> ~ Roger Brinner The combination of some data and an aching
>> >>>>>>>>>>> desire for an answer does not ensure that a reasonable answer
>> >>>>>>>>>>> can be extracted from a given body of data. ~ John Tukey
>> >>>>>>>>>>>
>> >>>>>>>>>>> 2016-06-23 11:27 GMT+02:00 Philipp Singer <killver at gmail.com
>> >>>>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>>:
>> >>>>>>>>>>>
>> >>>>>>>>>>> Thanks Thierry - That totally makes sense. Is there some way
>> of
>> >>>>>>>>>>> formally checking that, except thinking about the setting and
>> >>>>>>>>>>> underlying processes?
>> >>>>>>>>>>>
>> >>>>>>>>>>> On 23.06.2016 11:04, Thierry Onkelinx wrote:
>> >>>>>>>>>>>
>> >>>>>>>>>>>> Dear Philipp,
>> >>>>>>>>>>>>
>> >>>>>>>>>>>> Do you have just lots of zero's, or more zero's than the
>> >>>>>>>>>>>>
>> >>>>>>>>>>> Poisson
>> >>>>>>>>>>>
>> >>>>>>>>>>>> distribution can explain? Those are two different things.
>> >>>>>>>>>>>>
>> >>>>>>>>>>> The example
>> >>>>>>>>>>>
>> >>>>>>>>>>>> below generates data from a Poisson distribution and has
>> >>>>>>>>>>>>
>> >>>>>>>>>>> 99% zero's
>> >>>>>>>>>>>
>> >>>>>>>>>>>> but no zero-inflation. The second example has only 1%
>> >>>>>>>>>>>>
>> >>>>>>>>>>> zero's but is
>> >>>>>>>>>>>
>> >>>>>>>>>>>> clearly zero-inflated.
>> >>>>>>>>>>>>
>> >>>>>>>>>>>> set.seed(1) n <- 1e8 sim <- rpois(n, lambda = 0.01) mean(sim
>> >>>>>>>>>>>> == 0) hist(sim)
>> >>>>>>>>>>>>
>> >>>>>>>>>>>> sim.infl <- rbinom(n, size = 1, prob = 0.99) * rpois(n,
>> >>>>>>>>>>>>
>> >>>>>>>>>>> lambda = 1000)
>> >>>>>>>>>>>
>> >>>>>>>>>>>> mean(sim.infl == 0) hist(sim.infl)
>> >>>>>>>>>>>>
>> >>>>>>>>>>>> So before looking for zero-inflated models, try to model
>> >>>>>>>>>>>>
>> >>>>>>>>>>> the zero's.
>> >>>>>>>>>>>
>> >>>>>>>>>>>> Best regards,
>> >>>>>>>>>>>>
>> >>>>>>>>>>>>
>> >>>>>>>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
>> >>>>>>>>>>>> Research Institute
>> >>>>>>>>>>>>
>> >>>>>>>>>>> for Nature
>> >>>>>>>>>>>
>> >>>>>>>>>>>> and Forest team Biometrie & Kwaliteitszorg / team Biometrics
>> >>>>>>>>>>>> & Quality
>> >>>>>>>>>>>>
>> >>>>>>>>>>> Assurance
>> >>>>>>>>>>>
>> >>>>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>> >>>>>>>>>>>>
>> >>>>>>>>>>>> To call in the statistician after the experiment is done
>> >>>>>>>>>>>>
>> >>>>>>>>>>> may be no
>> >>>>>>>>>>>
>> >>>>>>>>>>>> more than asking him to perform a post-mortem examination:
>> >>>>>>>>>>>>
>> >>>>>>>>>>> he may be
>> >>>>>>>>>>>
>> >>>>>>>>>>>> able to say what the experiment died of. ~ Sir Ronald
>> >>>>>>>>>>>>
>> >>>>>>>>>>> Aylmer Fisher
>> >>>>>>>>>>>
>> >>>>>>>>>>>> The plural of anecdote is not data. ~ Roger Brinner The
>> >>>>>>>>>>>> combination of some data and an aching desire for an
>> >>>>>>>>>>>>
>> >>>>>>>>>>> answer does
>> >>>>>>>>>>>
>> >>>>>>>>>>>> not ensure that a reasonable answer can be extracted from a
>> >>>>>>>>>>>>
>> >>>>>>>>>>> given body
>> >>>>>>>>>>>
>> >>>>>>>>>>>> of data. ~ John Tukey
>> >>>>>>>>>>>>
>> >>>>>>>>>>>> 2016-06-23 10:07 GMT+02:00 Philipp Singer
>> >>>>>>>>>>>>
>> >>>>>>>>>>> <killver at gmail.com <mailto:killver at gmail.com>
>> >>>>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>
>> >>>>>>>>>>>
>> >>>>>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>
>> >>>>>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>>>:
>> >>>>>>>>>>>>
>> >>>>>>>>>>>> Dear group - I am currently fitting a Poisson glmer
>> >>>>>>>>>>>>
>> >>>>>>>>>>> where I have
>> >>>>>>>>>>>
>> >>>>>>>>>>>> an excess of outcomes that are zero (>95%). I am now
>> >>>>>>>>>>>>
>> >>>>>>>>>>> debating on
>> >>>>>>>>>>>
>> >>>>>>>>>>>> how to proceed and came up with three options:
>> >>>>>>>>>>>>
>> >>>>>>>>>>>> 1.) Just fit a regular glmer to the complete data. I am
>> >>>>>>>>>>>>
>> >>>>>>>>>>> not fully
>> >>>>>>>>>>>
>> >>>>>>>>>>>> sure how interpret the coefficients then, are they more
>> >>>>>>>>>>>>
>> >>>>>>>>>>> optimizing
>> >>>>>>>>>>>
>> >>>>>>>>>>>> towards distinguishing zero and non-zero, or also
>> >>>>>>>>>>>>
>> >>>>>>>>>>> capturing the
>> >>>>>>>>>>>
>> >>>>>>>>>>>> differences in those outcomes that are non-zero?
>> >>>>>>>>>>>>
>> >>>>>>>>>>>> 2.) Leave all zeros out of the data and fit a glmer to
>> >>>>>>>>>>>>
>> >>>>>>>>>>> only those
>> >>>>>>>>>>>
>> >>>>>>>>>>>> outcomes that are non-zero. Then, I would only learn about
>> >>>>>>>>>>>> differences in the non-zero outcomes though.
>> >>>>>>>>>>>>
>> >>>>>>>>>>>> 3.) Use a zero-inflated Poisson model. My data is quite
>> >>>>>>>>>>>> large-scale, so I am currently playing around with the EM
>> >>>>>>>>>>>> implementation of Bolker et al. that alternates between
>> >>>>>>>>>>>>
>> >>>>>>>>>>> fitting a
>> >>>>>>>>>>>
>> >>>>>>>>>>>> glmer with data that are weighted according to their zero
>> >>>>>>>>>>>> probability, and fitting a logistic regression for the
>> >>>>>>>>>>>>
>> >>>>>>>>>>> probability
>> >>>>>>>>>>>
>> >>>>>>>>>>>> that a data point is zero. The method is elaborated for
>> >>>>>>>>>>>>
>> >>>>>>>>>>> the OWL
>> >>>>>>>>>>>
>> >>>>>>>>>>>> data in:
>> >>>>>>>>>>>>
>> >>>>>>>>>>>>
>> >>>>>>>>>>>
>> https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
>> >>>>>>>>>>> <
>> >>>>>>>>>>>
>> https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
>> >>>>>>>>>>> >
>> >>>>>>>>>>>
>> >>>>>>>>>> I am not fully sure how to interpret the results for the
>> >>>>>>>
>> >>>>>>>> zero-inflated version though. Would I need to interpret the
>> >>>>>>>>>>>> coefficients for the result of the glmer similar to as
>> >>>>>>>>>>>>
>> >>>>>>>>>>> I would do
>> >>>>>>>>>>>
>> >>>>>>>>>>>> for my idea of 2)? And then on top of that interpret the
>> >>>>>>>>>>>> coefficients for the logistic regression regarding whether
>> >>>>>>>>>>>> something is in the perfect or imperfect state? I am
>> >>>>>>>>>>>>
>> >>>>>>>>>>> also not
>> >>>>>>>>>>>
>> >>>>>>>>>>>> quite sure what the common approach for the zformula is
>> >>>>>>>>>>>>
>> >>>>>>>>>>> here. The
>> >>>>>>>>>>>
>> >>>>>>>>>>>> OWL elaborations only use zformula=z~1, so no random
>> >>>>>>>>>>>>
>> >>>>>>>>>>> effect; I
>> >>>>>>>>>>>
>> >>>>>>>>>>>> would use the same formula as for the glmer.
>> >>>>>>>>>>>>
>> >>>>>>>>>>>> I am appreciating some help and pointers.
>> >>>>>>>>>>>>
>> >>>>>>>>>>>> Thanks! Philipp
>> >>>>>>>>>>>>
>> >>>>>>>>>>>> _______________________________________________
>> >>>>>>>>>>>> R-sig-mixed-models at r-project.org
>> >>>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>> >>>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>> >>>>>>>>>>>>
>> >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>> >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>>
>> >>>>>>>>>>>
>> >>>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>> >>>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>> >>>>>>>>>>>>
>> >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>> >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>>> mailing list
>> >>>>>>>>>>>
>> >>>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>>>>>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>> >>>>>>>>>>>>
>> >>>>>>>>>>>>
>> >>>>>>>>>>>> [[alternative HTML version deleted]]
>> >>>>>>>>>>>
>> >>>>>>>>>>> _______________________________________________
>> >>>>>>>>>>> R-sig-mixed-models at r-project.org
>> >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>> >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>> >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>> >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>> mailing list
>> >>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>>>>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>> >>>>>>>>>>>
>> >>>>>>>>>>>
>> >>>>>>>>>>> [[alternative HTML version deleted]]
>> >>>>>>>>>
>> >>>>>>>>> _______________________________________________
>> >>>>>>>>> R-sig-mixed-models at r-project.org
>> >>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>> >>>>>>>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>> >>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>> >>>>>>>>>
>> >>>>>>>> [[alternative HTML version deleted]]
>> >>>>>>>>
>> >>>>>>>> _______________________________________________
>> >>>>>>>> R-sig-mixed-models at r-project.org
>> >>>>>>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>> >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>>>>>>>
>> >>>>>>>> _______________________________________________
>> >>>>>>> R-sig-mixed-models at r-project.org
>> >>>>>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>> >>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>>>>>>
>> >>>>>> _______________________________________________
>> >>>>>> R-sig-mixed-models at r-project.org
>> >>>>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>>>>>
>> >>>>>
>> >>>         [[alternative HTML version deleted]]
>> >>>
>> >>> _______________________________________________
>> >>> R-sig-mixed-models at r-project.org mailing list
>> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>>
>> >>>
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

	[[alternative HTML version deleted]]


From killver at gmail.com  Mon Jun 27 16:17:47 2016
From: killver at gmail.com (Philipp Singer)
Date: Mon, 27 Jun 2016 16:17:47 +0200
Subject: [R-sig-ME] Question about zero-inflated Poisson glmer
In-Reply-To: <CAGPhqeojDg=tXJi+oYMqAqGwCaVxkkhnhV3MBr2e9O2agEeJUA@mail.gmail.com>
References: <576B98C4.6000602@gmail.com>
	<CAJuCY5xbiEjCmHjc_3wX2emzJ3NEMTA_qKgC_reWn=zqC7YEng@mail.gmail.com>
	<576BAB84.6080009@gmail.com>
	<CAJuCY5zmK1xCyWOwcCH+Hch_LSdB+AazmUDuPVP6je7ABFU5FA@mail.gmail.com>
	<576BBCFD.8040806@gmail.com>
	<CAJuCY5ycRL6oXs=H5JrEqOHWzd1UsvSNVZM6-MK+V2N=pvbyQA@mail.gmail.com>
	<576BFEBC.3020407@gmail.com>
	<B5AEF3F5-949F-4686-82DA-C234C3C4018B@ufl.edu>
	<576C18F9.9010200@gmail.com> <576C200A.1050405@gmail.com>
	<4D07695C-8CEA-4785-A5B0-46B011625DA0@ufl.edu>
	<576D290A.7090102@gmail.com> <576D3209.6050507@gmail.com>
	<576D3864.1060001@gmail.com> <576D3B1B.3050908@gmail.com>
	<CAGPhqeohy3hB8hfnNcj=6d_D=mRVG9CWk910qfSEsEnnr0N__A@mail.gmail.com>
	<CAJuCY5wcBboPCe58h2kYPL1+tXwe=5dmVT10n6wFCJSE+7-wnw@mail.gmail.com>
	<CAGPhqeojDg=tXJi+oYMqAqGwCaVxkkhnhV3MBr2e9O2agEeJUA@mail.gmail.com>
Message-ID: <CAGPhqeok+j2mCtfSBYveSbU1iCzvZjTefeEE8f=uyyH33ctS=w@mail.gmail.com>

Here is the fitted vs. residual plot for the observation-level poisson
model where the observation level has been removed as taken from:
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q3/020817.html

So basically the prediction is always close to zero.

Note that this is just on a very small sample (1000 data points).

If I fit a nbinom2 to this smalle sample, I get predictions that are always
around ~20 (but never zero). Both plots are attached.

What I am wondering is whether I can do inference on a fixed parameter in
my model which is my main task of this study. The effect is similar in the
different models and in general I am only itnerested in whether it is
positive/negative and "significant" which it is. However, as can be seen,
the prediction looks not too good here.




2016-06-27 15:18 GMT+02:00 Philipp Singer <killver at gmail.com>:

> The variance is:
>
> Conditional model:
>  Groups            Name        Variance  Std.Dev.
>  obs               (Intercept) 8.991e+01 9.4823139
>
>
>
> 2016-06-27 15:06 GMT+02:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:
>
>> Dear Philipp,
>>
>> How strong is the variance of the observation level random effect? I
>> would trust a model with large OLRE variance.
>>
>> Best regards,
>>
>> Thierry
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2016-06-27 14:59 GMT+02:00 Philipp Singer <killver at gmail.com>:
>>
>>> I have now played around more with the data an the models both using lme4
>>> and glmmTMB.
>>>
>>> I can report the following:
>>>
>>> Modeling the data with a zero-inflated Poisson improves the model
>>> significantly. However, when calling predict and simulating rpoissons, I
>>> end up with nearly no values that are zero (in the original data there
>>> are
>>> 96% zero).
>>>
>>> When I model the data with overdisperion by including an
>>> observation-level
>>> random effect, I can also improve the model (not surprisingly due to the
>>> random effect). When I predict outcomes by ignoring the observation-level
>>> random effect (in lme4), I receive bad prediction if I compare it to the
>>> original data. While many zeros can be captured (of course), the positive
>>> outcomes can not be captured well.
>>>
>>> Combining zero inflation and overdispersion further improves the model,
>>> but
>>> I can only do that with glmmTMB and then have troubles doing predictions
>>> ignoring the observation-level random effect.
>>>
>>> Another side question:
>>>
>>> In lme4, when I do:
>>>
>>> m = glm(x~1,family="poisson")
>>> rpois(n=len(data),lambda=predict(m, type='response',re.form=NA)
>>>
>>> vs.
>>>
>>> simulate(1,m,re.form=NA)
>>>
>>> I receive different outcomes? Do I understand these function wrongly?
>>>
>>> Would appreciate some more help/pointers!
>>>
>>> Thanks,
>>> Philipp
>>>
>>> 2016-06-24 15:52 GMT+02:00 Philipp Singer <killver at gmail.com>:
>>>
>>> > Thanks - I started an issue there to answer some of my questions.
>>> >
>>> > Regarding the installation: I was trying to somehow do it in anaconda
>>> with
>>> > a specific R kernel and had some issues. I am trying to resort that
>>> with
>>> > the anaconda guys though, if I have a tutorial on how to properly setup
>>> > glmmTMB in anaconda, I will let you know. The install worked fine in my
>>> > standard R environment.
>>> >
>>> >
>>> > On 24.06.2016 15:40, Ben Bolker wrote:
>>> >
>>> >>   Probably for now the glmmTMB issues page is best.
>>> >>
>>> >>   When you go there:
>>> >>
>>> >>    - details on installation problems/hiccups would be useful
>>> >>    - a reproducible example for the problem listed below would be
>>> useful
>>> >>    - dispformula is for allowing dispersion/residual variance to vary
>>> >> with covariates (i.e., modeling heteroscedasticity)
>>> >>
>>> >>    cheers
>>> >>      Ben Bolker
>>> >>
>>> >>
>>> >> On 16-06-24 09:13 AM, Philipp Singer wrote:
>>> >>
>>> >>> Update, I tried it like that, but receive an error message.
>>> >>>
>>> >>> Warning message:
>>> >>> In nlminb(start = par, objective = fn, gradient = gr): NA/NaN
>>> function
>>> >>> evaluation
>>> >>>
>>> >>> Error in solve.default(hessian.fixed): Lapack routine dgesv: system
>>> is
>>> >>> exactly singular: U[3,3] = 0
>>> >>> Traceback:
>>> >>>
>>> >>> 1. glmmTMB(y ~ 1 + x + (1 | b),
>>> >>>    .     data = data, family = "poisson", dispformula = ~1 + x)
>>> >>> 2. sdreport(obj)
>>> >>> 3. solve(hessian.fixed)
>>> >>> 4. solve(hessian.fixed)
>>> >>> 5. solve.default(hessian.fixed)
>>> >>>
>>> >>> Any ideas on that?
>>> >>>
>>> >>> BTW: Is it fine to post glmmTMB questions here, or should I rather
>>> use
>>> >>> the github issue page, or is there maybe a dedicated mailing list?
>>> >>>
>>> >>> Thanks,
>>> >>> Philipp
>>> >>>
>>> >>> On 24.06.2016 14:35, Philipp Singer wrote:
>>> >>>
>>> >>>> It indeed seems to run quite fast; had some trouble installing, but
>>> >>>> works now on my 3.3 R setup.
>>> >>>>
>>> >>>> One question I have is regarding the specification of dispersion as
>>> I
>>> >>>> need to specify the dispformula. What is the difference here between
>>> >>>> just specifying fixed effects vs. also the random effects?
>>> >>>>
>>> >>>> On 23.06.2016 23:07, Mollie Brooks wrote:
>>> >>>>
>>> >>>>> glmmTMB does crossed RE. Ben did some timings in
>>> vignette("glmmTMB")
>>> >>>>> and it was 2.3 times faster than glmer for one simple GLMM.
>>> >>>>>
>>> >>>>>
>>> >>>>> On 23Jun 2016, at 10:44, Philipp Singer <killver at gmail.com> wrote:
>>> >>>>>>
>>> >>>>>> Did try glmmADMB but unfortunately it is way too slow for my data.
>>> >>>>>>
>>> >>>>>> Did not know about glmmTMB, will try it out. Does it work with
>>> >>>>>> crossed random effects and how does it scale with more data? I
>>> will
>>> >>>>>> check the docu and try it though. Thanks for the info.
>>> >>>>>>
>>> >>>>>> On 23.06.2016 19:14, Ben Bolker wrote:
>>> >>>>>>
>>> >>>>>>>    I would also comment that glmmTMB is likely to be much faster
>>> >>>>>>> than the
>>> >>>>>>> lme4-based EM approach ...
>>> >>>>>>>
>>> >>>>>>>    cheers
>>> >>>>>>>      Ben B.
>>> >>>>>>>
>>> >>>>>>> On 16-06-23 12:47 PM, Mollie Brooks wrote:
>>> >>>>>>>
>>> >>>>>>>> Hi Philipp,
>>> >>>>>>>>
>>> >>>>>>>> You could also try fitting the model with and without ZI using
>>> >>>>>>>> either
>>> >>>>>>>> glmmADMB or glmmTMB. Then compare the AICs. I believe model
>>> >>>>>>>> selection
>>> >>>>>>>> is useful for this, but I could be missing something since the
>>> >>>>>>>> simulation procedure that Thierry described seems to recommended
>>> >>>>>>>> more
>>> >>>>>>>> often.
>>> >>>>>>>>
>>> >>>>>>>> https://github.com/glmmTMB/glmmTMB
>>> >>>>>>>> http://glmmadmb.r-forge.r-project.org
>>> >>>>>>>>
>>> >>>>>>>> glmmTMB is still in the development phase, but we?ve done a lot
>>> of
>>> >>>>>>>> testing.
>>> >>>>>>>>
>>> >>>>>>>> cheers, Mollie
>>> >>>>>>>>
>>> >>>>>>>> ------------------------ Mollie Brooks, PhD Postdoctoral
>>> Researcher,
>>> >>>>>>>> Population Ecology Research Group Department of Evolutionary
>>> Biology
>>> >>>>>>>> & Environmental Studies, University of Z?rich
>>> >>>>>>>> http://www.popecol.org/team/mollie-brooks/
>>> >>>>>>>>
>>> >>>>>>>>
>>> >>>>>>>> On 23Jun 2016, at 8:22, Philipp Singer <killver at gmail.com>
>>> wrote:
>>> >>>>>>>>>
>>> >>>>>>>>> Thanks, great information, that is really helpful.
>>> >>>>>>>>>
>>> >>>>>>>>> I agree that those are different things, however when using a
>>> >>>>>>>>> random effect for overdispersion, I can simulate the same
>>> number of
>>> >>>>>>>>> zero outcomes (~95%).
>>> >>>>>>>>>
>>> >>>>>>>>> On 23.06.2016 15:50, Thierry Onkelinx wrote:
>>> >>>>>>>>>
>>> >>>>>>>>>> Be careful when using overdispersion to model zero-inflation.
>>> >>>>>>>>>> Those are two different things.
>>> >>>>>>>>>>
>>> >>>>>>>>>> I've put some information together in
>>> >>>>>>>>>> http://rpubs.com/INBOstats/zeroinflation
>>> >>>>>>>>>>
>>> >>>>>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
>>> >>>>>>>>>> Research Institute for Nature and Forest team Biometrie &
>>> >>>>>>>>>> Kwaliteitszorg / team Biometrics & Quality Assurance
>>> >>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>> >>>>>>>>>>
>>> >>>>>>>>>> To call in the statistician after the experiment is done may
>>> be
>>> >>>>>>>>>> no more than asking him to perform a post-mortem examination:
>>> he
>>> >>>>>>>>>> may be able to say what the experiment died of. ~ Sir Ronald
>>> >>>>>>>>>> Aylmer Fisher The plural of anecdote is not data. ~ Roger
>>> >>>>>>>>>> Brinner The combination of some data and an aching desire for
>>> an
>>> >>>>>>>>>> answer does not ensure that a reasonable answer can be
>>> extracted
>>> >>>>>>>>>> from a given body of data. ~ John Tukey
>>> >>>>>>>>>>
>>> >>>>>>>>>> 2016-06-23 12:42 GMT+02:00 Philipp Singer <killver at gmail.com
>>> >>>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>>:
>>> >>>>>>>>>>
>>> >>>>>>>>>> Thanks! Actually, accounting for overdispersion is super
>>> >>>>>>>>>> important as it seems, then the zeros can be captured well.
>>> >>>>>>>>>>
>>> >>>>>>>>>>
>>> >>>>>>>>>> On 23.06.2016 11:50, Thierry Onkelinx wrote:
>>> >>>>>>>>>>
>>> >>>>>>>>>>> Dear Philipp,
>>> >>>>>>>>>>>
>>> >>>>>>>>>>> 1. Fit a Poisson model to the data. 2. Simulate a new
>>> response
>>> >>>>>>>>>>> vector for the dataset according to the model. 3. Count the
>>> >>>>>>>>>>> number of zero's in the simulated response vector. 4. Repeat
>>> >>>>>>>>>>> step 2 and 3 a decent number of time and plot a histogram of
>>> >>>>>>>>>>> the number of zero's in the simulation. If the number of
>>> zero's
>>> >>>>>>>>>>> in the original dataset is larger than those in the
>>> >>>>>>>>>>> simulations, then the model can't capture all zero's. In such
>>> >>>>>>>>>>> case, first try to update the model and repeat the procedure.
>>> >>>>>>>>>>> If that fails, look for zero-inflated models.
>>> >>>>>>>>>>>
>>> >>>>>>>>>>> Best regards,
>>> >>>>>>>>>>>
>>> >>>>>>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
>>> >>>>>>>>>>> Research Institute for Nature and Forest team Biometrie &
>>> >>>>>>>>>>> Kwaliteitszorg / team Biometrics & Quality Assurance
>>> >>>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>> >>>>>>>>>>>
>>> >>>>>>>>>>> To call in the statistician after the experiment is done may
>>> >>>>>>>>>>> be no more than asking him to perform a post-mortem
>>> >>>>>>>>>>> examination: he may be able to say what the experiment died
>>> of.
>>> >>>>>>>>>>> ~ Sir Ronald Aylmer Fisher The plural of anecdote is not
>>> data.
>>> >>>>>>>>>>> ~ Roger Brinner The combination of some data and an aching
>>> >>>>>>>>>>> desire for an answer does not ensure that a reasonable answer
>>> >>>>>>>>>>> can be extracted from a given body of data. ~ John Tukey
>>> >>>>>>>>>>>
>>> >>>>>>>>>>> 2016-06-23 11:27 GMT+02:00 Philipp Singer <killver at gmail.com
>>> >>>>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>>:
>>> >>>>>>>>>>>
>>> >>>>>>>>>>> Thanks Thierry - That totally makes sense. Is there some way
>>> of
>>> >>>>>>>>>>> formally checking that, except thinking about the setting and
>>> >>>>>>>>>>> underlying processes?
>>> >>>>>>>>>>>
>>> >>>>>>>>>>> On 23.06.2016 11:04, Thierry Onkelinx wrote:
>>> >>>>>>>>>>>
>>> >>>>>>>>>>>> Dear Philipp,
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>>> Do you have just lots of zero's, or more zero's than the
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>> Poisson
>>> >>>>>>>>>>>
>>> >>>>>>>>>>>> distribution can explain? Those are two different things.
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>> The example
>>> >>>>>>>>>>>
>>> >>>>>>>>>>>> below generates data from a Poisson distribution and has
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>> 99% zero's
>>> >>>>>>>>>>>
>>> >>>>>>>>>>>> but no zero-inflation. The second example has only 1%
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>> zero's but is
>>> >>>>>>>>>>>
>>> >>>>>>>>>>>> clearly zero-inflated.
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>>> set.seed(1) n <- 1e8 sim <- rpois(n, lambda = 0.01) mean(sim
>>> >>>>>>>>>>>> == 0) hist(sim)
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>>> sim.infl <- rbinom(n, size = 1, prob = 0.99) * rpois(n,
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>> lambda = 1000)
>>> >>>>>>>>>>>
>>> >>>>>>>>>>>> mean(sim.infl == 0) hist(sim.infl)
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>>> So before looking for zero-inflated models, try to model
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>> the zero's.
>>> >>>>>>>>>>>
>>> >>>>>>>>>>>> Best regards,
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek
>>> /
>>> >>>>>>>>>>>> Research Institute
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>> for Nature
>>> >>>>>>>>>>>
>>> >>>>>>>>>>>> and Forest team Biometrie & Kwaliteitszorg / team Biometrics
>>> >>>>>>>>>>>> & Quality
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>> Assurance
>>> >>>>>>>>>>>
>>> >>>>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>>> To call in the statistician after the experiment is done
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>> may be no
>>> >>>>>>>>>>>
>>> >>>>>>>>>>>> more than asking him to perform a post-mortem examination:
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>> he may be
>>> >>>>>>>>>>>
>>> >>>>>>>>>>>> able to say what the experiment died of. ~ Sir Ronald
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>> Aylmer Fisher
>>> >>>>>>>>>>>
>>> >>>>>>>>>>>> The plural of anecdote is not data. ~ Roger Brinner The
>>> >>>>>>>>>>>> combination of some data and an aching desire for an
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>> answer does
>>> >>>>>>>>>>>
>>> >>>>>>>>>>>> not ensure that a reasonable answer can be extracted from a
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>> given body
>>> >>>>>>>>>>>
>>> >>>>>>>>>>>> of data. ~ John Tukey
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>>> 2016-06-23 10:07 GMT+02:00 Philipp Singer
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>> <killver at gmail.com <mailto:killver at gmail.com>
>>> >>>>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>
>>> >>>>>>>>>>>
>>> >>>>>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>
>>> >>>>>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>>>:
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>>> Dear group - I am currently fitting a Poisson glmer
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>> where I have
>>> >>>>>>>>>>>
>>> >>>>>>>>>>>> an excess of outcomes that are zero (>95%). I am now
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>> debating on
>>> >>>>>>>>>>>
>>> >>>>>>>>>>>> how to proceed and came up with three options:
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>>> 1.) Just fit a regular glmer to the complete data. I am
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>> not fully
>>> >>>>>>>>>>>
>>> >>>>>>>>>>>> sure how interpret the coefficients then, are they more
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>> optimizing
>>> >>>>>>>>>>>
>>> >>>>>>>>>>>> towards distinguishing zero and non-zero, or also
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>> capturing the
>>> >>>>>>>>>>>
>>> >>>>>>>>>>>> differences in those outcomes that are non-zero?
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>>> 2.) Leave all zeros out of the data and fit a glmer to
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>> only those
>>> >>>>>>>>>>>
>>> >>>>>>>>>>>> outcomes that are non-zero. Then, I would only learn about
>>> >>>>>>>>>>>> differences in the non-zero outcomes though.
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>>> 3.) Use a zero-inflated Poisson model. My data is quite
>>> >>>>>>>>>>>> large-scale, so I am currently playing around with the EM
>>> >>>>>>>>>>>> implementation of Bolker et al. that alternates between
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>> fitting a
>>> >>>>>>>>>>>
>>> >>>>>>>>>>>> glmer with data that are weighted according to their zero
>>> >>>>>>>>>>>> probability, and fitting a logistic regression for the
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>> probability
>>> >>>>>>>>>>>
>>> >>>>>>>>>>>> that a data point is zero. The method is elaborated for
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>> the OWL
>>> >>>>>>>>>>>
>>> >>>>>>>>>>>> data in:
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>>
>>> https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
>>> >>>>>>>>>>> <
>>> >>>>>>>>>>>
>>> https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
>>> >>>>>>>>>>> >
>>> >>>>>>>>>>>
>>> >>>>>>>>>> I am not fully sure how to interpret the results for the
>>> >>>>>>>
>>> >>>>>>>> zero-inflated version though. Would I need to interpret the
>>> >>>>>>>>>>>> coefficients for the result of the glmer similar to as
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>> I would do
>>> >>>>>>>>>>>
>>> >>>>>>>>>>>> for my idea of 2)? And then on top of that interpret the
>>> >>>>>>>>>>>> coefficients for the logistic regression regarding whether
>>> >>>>>>>>>>>> something is in the perfect or imperfect state? I am
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>> also not
>>> >>>>>>>>>>>
>>> >>>>>>>>>>>> quite sure what the common approach for the zformula is
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>> here. The
>>> >>>>>>>>>>>
>>> >>>>>>>>>>>> OWL elaborations only use zformula=z~1, so no random
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>> effect; I
>>> >>>>>>>>>>>
>>> >>>>>>>>>>>> would use the same formula as for the glmer.
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>>> I am appreciating some help and pointers.
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>>> Thanks! Philipp
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>>> _______________________________________________
>>> >>>>>>>>>>>> R-sig-mixed-models at r-project.org
>>> >>>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>> >>>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>>> >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>>
>>> >>>>>>>>>>>
>>> >>>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>>> >>>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>>> >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>>> mailing list
>>> >>>>>>>>>>>
>>> >>>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> >>>>>>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>>>
>>> >>>>>>>>>>>> [[alternative HTML version deleted]]
>>> >>>>>>>>>>>
>>> >>>>>>>>>>> _______________________________________________
>>> >>>>>>>>>>> R-sig-mixed-models at r-project.org
>>> >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>> >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>> >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>>> >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>> mailing list
>>> >>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> >>>>>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>> >>>>>>>>>>>
>>> >>>>>>>>>>>
>>> >>>>>>>>>>> [[alternative HTML version deleted]]
>>> >>>>>>>>>
>>> >>>>>>>>> _______________________________________________
>>> >>>>>>>>> R-sig-mixed-models at r-project.org
>>> >>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>> >>>>>>>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>>> >>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> >>>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>> >>>>>>>>>
>>> >>>>>>>> [[alternative HTML version deleted]]
>>> >>>>>>>>
>>> >>>>>>>> _______________________________________________
>>> >>>>>>>> R-sig-mixed-models at r-project.org
>>> >>>>>>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>>> >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> >>>>>>>>
>>> >>>>>>>> _______________________________________________
>>> >>>>>>> R-sig-mixed-models at r-project.org
>>> >>>>>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>>> >>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> >>>>>>>
>>> >>>>>> _______________________________________________
>>> >>>>>> R-sig-mixed-models at r-project.org
>>> >>>>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>>> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> >>>>>>
>>> >>>>>
>>> >>>         [[alternative HTML version deleted]]
>>> >>>
>>> >>> _______________________________________________
>>> >>> R-sig-mixed-models at r-project.org mailing list
>>> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> >>>
>>> >>>
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: fitted.png
Type: image/png
Size: 26021 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20160627/a817d3eb/attachment-0002.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: nbinom_fitted.png
Type: image/png
Size: 26194 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20160627/a817d3eb/attachment-0003.png>

From thierry.onkelinx at inbo.be  Mon Jun 27 17:31:04 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 27 Jun 2016 17:31:04 +0200
Subject: [R-sig-ME] Question about zero-inflated Poisson glmer
In-Reply-To: <CAGPhqeok+j2mCtfSBYveSbU1iCzvZjTefeEE8f=uyyH33ctS=w@mail.gmail.com>
References: <576B98C4.6000602@gmail.com>
	<CAJuCY5xbiEjCmHjc_3wX2emzJ3NEMTA_qKgC_reWn=zqC7YEng@mail.gmail.com>
	<576BAB84.6080009@gmail.com>
	<CAJuCY5zmK1xCyWOwcCH+Hch_LSdB+AazmUDuPVP6je7ABFU5FA@mail.gmail.com>
	<576BBCFD.8040806@gmail.com>
	<CAJuCY5ycRL6oXs=H5JrEqOHWzd1UsvSNVZM6-MK+V2N=pvbyQA@mail.gmail.com>
	<576BFEBC.3020407@gmail.com>
	<B5AEF3F5-949F-4686-82DA-C234C3C4018B@ufl.edu>
	<576C18F9.9010200@gmail.com> <576C200A.1050405@gmail.com>
	<4D07695C-8CEA-4785-A5B0-46B011625DA0@ufl.edu>
	<576D290A.7090102@gmail.com> <576D3209.6050507@gmail.com>
	<576D3864.1060001@gmail.com> <576D3B1B.3050908@gmail.com>
	<CAGPhqeohy3hB8hfnNcj=6d_D=mRVG9CWk910qfSEsEnnr0N__A@mail.gmail.com>
	<CAJuCY5wcBboPCe58h2kYPL1+tXwe=5dmVT10n6wFCJSE+7-wnw@mail.gmail.com>
	<CAGPhqeojDg=tXJi+oYMqAqGwCaVxkkhnhV3MBr2e9O2agEeJUA@mail.gmail.com>
	<CAGPhqeok+j2mCtfSBYveSbU1iCzvZjTefeEE8f=uyyH33ctS=w@mail.gmail.com>
Message-ID: <CAJuCY5xDPr0rBa-cCCT7+_QOefO8UT8AreP_8hMh6siuM6noBA@mail.gmail.com>

Dear Philipp,

You've been bitten by observation level random effects. I've put together a
document about it on http://rpubs.com/INBOstats/OLRE. Bottomline you're
OKish when the standard devation of the OLRE smaller than 1. You're in
trouble when it's above 3. In between you need to check the model carefully.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-06-27 16:17 GMT+02:00 Philipp Singer <killver at gmail.com>:

> Here is the fitted vs. residual plot for the observation-level poisson
> model where the observation level has been removed as taken from:
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q3/020817.html
>
> So basically the prediction is always close to zero.
>
> Note that this is just on a very small sample (1000 data points).
>
> If I fit a nbinom2 to this smalle sample, I get predictions that are
> always around ~20 (but never zero). Both plots are attached.
>
> What I am wondering is whether I can do inference on a fixed parameter in
> my model which is my main task of this study. The effect is similar in the
> different models and in general I am only itnerested in whether it is
> positive/negative and "significant" which it is. However, as can be seen,
> the prediction looks not too good here.
>
>
>
>
> 2016-06-27 15:18 GMT+02:00 Philipp Singer <killver at gmail.com>:
>
>> The variance is:
>>
>> Conditional model:
>>  Groups            Name        Variance  Std.Dev.
>>  obs               (Intercept) 8.991e+01 9.4823139
>>
>>
>>
>> 2016-06-27 15:06 GMT+02:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:
>>
>>> Dear Philipp,
>>>
>>> How strong is the variance of the observation level random effect? I
>>> would trust a model with large OLRE variance.
>>>
>>> Best regards,
>>>
>>> Thierry
>>>
>>> ir. Thierry Onkelinx
>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>> and Forest
>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>> Kliniekstraat 25
>>> 1070 Anderlecht
>>> Belgium
>>>
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of data.
>>> ~ John Tukey
>>>
>>> 2016-06-27 14:59 GMT+02:00 Philipp Singer <killver at gmail.com>:
>>>
>>>> I have now played around more with the data an the models both using
>>>> lme4
>>>> and glmmTMB.
>>>>
>>>> I can report the following:
>>>>
>>>> Modeling the data with a zero-inflated Poisson improves the model
>>>> significantly. However, when calling predict and simulating rpoissons, I
>>>> end up with nearly no values that are zero (in the original data there
>>>> are
>>>> 96% zero).
>>>>
>>>> When I model the data with overdisperion by including an
>>>> observation-level
>>>> random effect, I can also improve the model (not surprisingly due to the
>>>> random effect). When I predict outcomes by ignoring the
>>>> observation-level
>>>> random effect (in lme4), I receive bad prediction if I compare it to the
>>>> original data. While many zeros can be captured (of course), the
>>>> positive
>>>> outcomes can not be captured well.
>>>>
>>>> Combining zero inflation and overdispersion further improves the model,
>>>> but
>>>> I can only do that with glmmTMB and then have troubles doing predictions
>>>> ignoring the observation-level random effect.
>>>>
>>>> Another side question:
>>>>
>>>> In lme4, when I do:
>>>>
>>>> m = glm(x~1,family="poisson")
>>>> rpois(n=len(data),lambda=predict(m, type='response',re.form=NA)
>>>>
>>>> vs.
>>>>
>>>> simulate(1,m,re.form=NA)
>>>>
>>>> I receive different outcomes? Do I understand these function wrongly?
>>>>
>>>> Would appreciate some more help/pointers!
>>>>
>>>> Thanks,
>>>> Philipp
>>>>
>>>> 2016-06-24 15:52 GMT+02:00 Philipp Singer <killver at gmail.com>:
>>>>
>>>> > Thanks - I started an issue there to answer some of my questions.
>>>> >
>>>> > Regarding the installation: I was trying to somehow do it in anaconda
>>>> with
>>>> > a specific R kernel and had some issues. I am trying to resort that
>>>> with
>>>> > the anaconda guys though, if I have a tutorial on how to properly
>>>> setup
>>>> > glmmTMB in anaconda, I will let you know. The install worked fine in
>>>> my
>>>> > standard R environment.
>>>> >
>>>> >
>>>> > On 24.06.2016 15:40, Ben Bolker wrote:
>>>> >
>>>> >>   Probably for now the glmmTMB issues page is best.
>>>> >>
>>>> >>   When you go there:
>>>> >>
>>>> >>    - details on installation problems/hiccups would be useful
>>>> >>    - a reproducible example for the problem listed below would be
>>>> useful
>>>> >>    - dispformula is for allowing dispersion/residual variance to vary
>>>> >> with covariates (i.e., modeling heteroscedasticity)
>>>> >>
>>>> >>    cheers
>>>> >>      Ben Bolker
>>>> >>
>>>> >>
>>>> >> On 16-06-24 09:13 AM, Philipp Singer wrote:
>>>> >>
>>>> >>> Update, I tried it like that, but receive an error message.
>>>> >>>
>>>> >>> Warning message:
>>>> >>> In nlminb(start = par, objective = fn, gradient = gr): NA/NaN
>>>> function
>>>> >>> evaluation
>>>> >>>
>>>> >>> Error in solve.default(hessian.fixed): Lapack routine dgesv: system
>>>> is
>>>> >>> exactly singular: U[3,3] = 0
>>>> >>> Traceback:
>>>> >>>
>>>> >>> 1. glmmTMB(y ~ 1 + x + (1 | b),
>>>> >>>    .     data = data, family = "poisson", dispformula = ~1 + x)
>>>> >>> 2. sdreport(obj)
>>>> >>> 3. solve(hessian.fixed)
>>>> >>> 4. solve(hessian.fixed)
>>>> >>> 5. solve.default(hessian.fixed)
>>>> >>>
>>>> >>> Any ideas on that?
>>>> >>>
>>>> >>> BTW: Is it fine to post glmmTMB questions here, or should I rather
>>>> use
>>>> >>> the github issue page, or is there maybe a dedicated mailing list?
>>>> >>>
>>>> >>> Thanks,
>>>> >>> Philipp
>>>> >>>
>>>> >>> On 24.06.2016 14:35, Philipp Singer wrote:
>>>> >>>
>>>> >>>> It indeed seems to run quite fast; had some trouble installing, but
>>>> >>>> works now on my 3.3 R setup.
>>>> >>>>
>>>> >>>> One question I have is regarding the specification of dispersion
>>>> as I
>>>> >>>> need to specify the dispformula. What is the difference here
>>>> between
>>>> >>>> just specifying fixed effects vs. also the random effects?
>>>> >>>>
>>>> >>>> On 23.06.2016 23:07, Mollie Brooks wrote:
>>>> >>>>
>>>> >>>>> glmmTMB does crossed RE. Ben did some timings in
>>>> vignette("glmmTMB")
>>>> >>>>> and it was 2.3 times faster than glmer for one simple GLMM.
>>>> >>>>>
>>>> >>>>>
>>>> >>>>> On 23Jun 2016, at 10:44, Philipp Singer <killver at gmail.com>
>>>> wrote:
>>>> >>>>>>
>>>> >>>>>> Did try glmmADMB but unfortunately it is way too slow for my
>>>> data.
>>>> >>>>>>
>>>> >>>>>> Did not know about glmmTMB, will try it out. Does it work with
>>>> >>>>>> crossed random effects and how does it scale with more data? I
>>>> will
>>>> >>>>>> check the docu and try it though. Thanks for the info.
>>>> >>>>>>
>>>> >>>>>> On 23.06.2016 19:14, Ben Bolker wrote:
>>>> >>>>>>
>>>> >>>>>>>    I would also comment that glmmTMB is likely to be much faster
>>>> >>>>>>> than the
>>>> >>>>>>> lme4-based EM approach ...
>>>> >>>>>>>
>>>> >>>>>>>    cheers
>>>> >>>>>>>      Ben B.
>>>> >>>>>>>
>>>> >>>>>>> On 16-06-23 12:47 PM, Mollie Brooks wrote:
>>>> >>>>>>>
>>>> >>>>>>>> Hi Philipp,
>>>> >>>>>>>>
>>>> >>>>>>>> You could also try fitting the model with and without ZI using
>>>> >>>>>>>> either
>>>> >>>>>>>> glmmADMB or glmmTMB. Then compare the AICs. I believe model
>>>> >>>>>>>> selection
>>>> >>>>>>>> is useful for this, but I could be missing something since the
>>>> >>>>>>>> simulation procedure that Thierry described seems to
>>>> recommended
>>>> >>>>>>>> more
>>>> >>>>>>>> often.
>>>> >>>>>>>>
>>>> >>>>>>>> https://github.com/glmmTMB/glmmTMB
>>>> >>>>>>>> http://glmmadmb.r-forge.r-project.org
>>>> >>>>>>>>
>>>> >>>>>>>> glmmTMB is still in the development phase, but we?ve done a
>>>> lot of
>>>> >>>>>>>> testing.
>>>> >>>>>>>>
>>>> >>>>>>>> cheers, Mollie
>>>> >>>>>>>>
>>>> >>>>>>>> ------------------------ Mollie Brooks, PhD Postdoctoral
>>>> Researcher,
>>>> >>>>>>>> Population Ecology Research Group Department of Evolutionary
>>>> Biology
>>>> >>>>>>>> & Environmental Studies, University of Z?rich
>>>> >>>>>>>> http://www.popecol.org/team/mollie-brooks/
>>>> >>>>>>>>
>>>> >>>>>>>>
>>>> >>>>>>>> On 23Jun 2016, at 8:22, Philipp Singer <killver at gmail.com>
>>>> wrote:
>>>> >>>>>>>>>
>>>> >>>>>>>>> Thanks, great information, that is really helpful.
>>>> >>>>>>>>>
>>>> >>>>>>>>> I agree that those are different things, however when using a
>>>> >>>>>>>>> random effect for overdispersion, I can simulate the same
>>>> number of
>>>> >>>>>>>>> zero outcomes (~95%).
>>>> >>>>>>>>>
>>>> >>>>>>>>> On 23.06.2016 15:50, Thierry Onkelinx wrote:
>>>> >>>>>>>>>
>>>> >>>>>>>>>> Be careful when using overdispersion to model zero-inflation.
>>>> >>>>>>>>>> Those are two different things.
>>>> >>>>>>>>>>
>>>> >>>>>>>>>> I've put some information together in
>>>> >>>>>>>>>> http://rpubs.com/INBOstats/zeroinflation
>>>> >>>>>>>>>>
>>>> >>>>>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
>>>> >>>>>>>>>> Research Institute for Nature and Forest team Biometrie &
>>>> >>>>>>>>>> Kwaliteitszorg / team Biometrics & Quality Assurance
>>>> >>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>>> >>>>>>>>>>
>>>> >>>>>>>>>> To call in the statistician after the experiment is done may
>>>> be
>>>> >>>>>>>>>> no more than asking him to perform a post-mortem
>>>> examination: he
>>>> >>>>>>>>>> may be able to say what the experiment died of. ~ Sir Ronald
>>>> >>>>>>>>>> Aylmer Fisher The plural of anecdote is not data. ~ Roger
>>>> >>>>>>>>>> Brinner The combination of some data and an aching desire
>>>> for an
>>>> >>>>>>>>>> answer does not ensure that a reasonable answer can be
>>>> extracted
>>>> >>>>>>>>>> from a given body of data. ~ John Tukey
>>>> >>>>>>>>>>
>>>> >>>>>>>>>> 2016-06-23 12:42 GMT+02:00 Philipp Singer <killver at gmail.com
>>>> >>>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>>:
>>>> >>>>>>>>>>
>>>> >>>>>>>>>> Thanks! Actually, accounting for overdispersion is super
>>>> >>>>>>>>>> important as it seems, then the zeros can be captured well.
>>>> >>>>>>>>>>
>>>> >>>>>>>>>>
>>>> >>>>>>>>>> On 23.06.2016 11:50, Thierry Onkelinx wrote:
>>>> >>>>>>>>>>
>>>> >>>>>>>>>>> Dear Philipp,
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>> 1. Fit a Poisson model to the data. 2. Simulate a new
>>>> response
>>>> >>>>>>>>>>> vector for the dataset according to the model. 3. Count the
>>>> >>>>>>>>>>> number of zero's in the simulated response vector. 4. Repeat
>>>> >>>>>>>>>>> step 2 and 3 a decent number of time and plot a histogram of
>>>> >>>>>>>>>>> the number of zero's in the simulation. If the number of
>>>> zero's
>>>> >>>>>>>>>>> in the original dataset is larger than those in the
>>>> >>>>>>>>>>> simulations, then the model can't capture all zero's. In
>>>> such
>>>> >>>>>>>>>>> case, first try to update the model and repeat the
>>>> procedure.
>>>> >>>>>>>>>>> If that fails, look for zero-inflated models.
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>> Best regards,
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek
>>>> /
>>>> >>>>>>>>>>> Research Institute for Nature and Forest team Biometrie &
>>>> >>>>>>>>>>> Kwaliteitszorg / team Biometrics & Quality Assurance
>>>> >>>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>> To call in the statistician after the experiment is done may
>>>> >>>>>>>>>>> be no more than asking him to perform a post-mortem
>>>> >>>>>>>>>>> examination: he may be able to say what the experiment died
>>>> of.
>>>> >>>>>>>>>>> ~ Sir Ronald Aylmer Fisher The plural of anecdote is not
>>>> data.
>>>> >>>>>>>>>>> ~ Roger Brinner The combination of some data and an aching
>>>> >>>>>>>>>>> desire for an answer does not ensure that a reasonable
>>>> answer
>>>> >>>>>>>>>>> can be extracted from a given body of data. ~ John Tukey
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>> 2016-06-23 11:27 GMT+02:00 Philipp Singer <
>>>> killver at gmail.com
>>>> >>>>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>>:
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>> Thanks Thierry - That totally makes sense. Is there some
>>>> way of
>>>> >>>>>>>>>>> formally checking that, except thinking about the setting
>>>> and
>>>> >>>>>>>>>>> underlying processes?
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>> On 23.06.2016 11:04, Thierry Onkelinx wrote:
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>>> Dear Philipp,
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>>> Do you have just lots of zero's, or more zero's than the
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>> Poisson
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>>> distribution can explain? Those are two different things.
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>> The example
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>>> below generates data from a Poisson distribution and has
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>> 99% zero's
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>>> but no zero-inflation. The second example has only 1%
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>> zero's but is
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>>> clearly zero-inflated.
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>>> set.seed(1) n <- 1e8 sim <- rpois(n, lambda = 0.01)
>>>> mean(sim
>>>> >>>>>>>>>>>> == 0) hist(sim)
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>>> sim.infl <- rbinom(n, size = 1, prob = 0.99) * rpois(n,
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>> lambda = 1000)
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>>> mean(sim.infl == 0) hist(sim.infl)
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>>> So before looking for zero-inflated models, try to model
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>> the zero's.
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>>> Best regards,
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en
>>>> bosonderzoek /
>>>> >>>>>>>>>>>> Research Institute
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>> for Nature
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>>> and Forest team Biometrie & Kwaliteitszorg / team
>>>> Biometrics
>>>> >>>>>>>>>>>> & Quality
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>> Assurance
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>>> To call in the statistician after the experiment is done
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>> may be no
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>>> more than asking him to perform a post-mortem examination:
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>> he may be
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>>> able to say what the experiment died of. ~ Sir Ronald
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>> Aylmer Fisher
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>>> The plural of anecdote is not data. ~ Roger Brinner The
>>>> >>>>>>>>>>>> combination of some data and an aching desire for an
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>> answer does
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>>> not ensure that a reasonable answer can be extracted from a
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>> given body
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>>> of data. ~ John Tukey
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>>> 2016-06-23 10:07 GMT+02:00 Philipp Singer
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>> <killver at gmail.com <mailto:killver at gmail.com>
>>>> >>>>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>
>>>> >>>>>>>>>>>> <mailto:killver at gmail.com <mailto:killver at gmail.com>>>>:
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>>> Dear group - I am currently fitting a Poisson glmer
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>> where I have
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>>> an excess of outcomes that are zero (>95%). I am now
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>> debating on
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>>> how to proceed and came up with three options:
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>>> 1.) Just fit a regular glmer to the complete data. I am
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>> not fully
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>>> sure how interpret the coefficients then, are they more
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>> optimizing
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>>> towards distinguishing zero and non-zero, or also
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>> capturing the
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>>> differences in those outcomes that are non-zero?
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>>> 2.) Leave all zeros out of the data and fit a glmer to
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>> only those
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>>> outcomes that are non-zero. Then, I would only learn about
>>>> >>>>>>>>>>>> differences in the non-zero outcomes though.
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>>> 3.) Use a zero-inflated Poisson model. My data is quite
>>>> >>>>>>>>>>>> large-scale, so I am currently playing around with the EM
>>>> >>>>>>>>>>>> implementation of Bolker et al. that alternates between
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>> fitting a
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>>> glmer with data that are weighted according to their zero
>>>> >>>>>>>>>>>> probability, and fitting a logistic regression for the
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>> probability
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>>> that a data point is zero. The method is elaborated for
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>> the OWL
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>>> data in:
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>>
>>>> https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
>>>> >>>>>>>>>>> <
>>>> >>>>>>>>>>>
>>>> https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
>>>> >>>>>>>>>>> >
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>> I am not fully sure how to interpret the results for the
>>>> >>>>>>>
>>>> >>>>>>>> zero-inflated version though. Would I need to interpret the
>>>> >>>>>>>>>>>> coefficients for the result of the glmer similar to as
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>> I would do
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>>> for my idea of 2)? And then on top of that interpret the
>>>> >>>>>>>>>>>> coefficients for the logistic regression regarding whether
>>>> >>>>>>>>>>>> something is in the perfect or imperfect state? I am
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>> also not
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>>> quite sure what the common approach for the zformula is
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>> here. The
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>>> OWL elaborations only use zformula=z~1, so no random
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>> effect; I
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>>> would use the same formula as for the glmer.
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>>> I am appreciating some help and pointers.
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>>> Thanks! Philipp
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>>> _______________________________________________
>>>> >>>>>>>>>>>> R-sig-mixed-models at r-project.org
>>>> >>>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>> >>>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>>>> >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>>
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>>>> >>>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>>>> >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>>> mailing list
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> >>>>>>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>>> [[alternative HTML version deleted]]
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>> _______________________________________________
>>>> >>>>>>>>>>> R-sig-mixed-models at r-project.org
>>>> >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>> >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>> >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>>>> >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>> mailing list
>>>> >>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> >>>>>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>> [[alternative HTML version deleted]]
>>>> >>>>>>>>>
>>>> >>>>>>>>> _______________________________________________
>>>> >>>>>>>>> R-sig-mixed-models at r-project.org
>>>> >>>>>>>>> <mailto:R-sig-mixed-models at r-project.org>
>>>> >>>>>>>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>> >>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> >>>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>> >>>>>>>>>
>>>> >>>>>>>> [[alternative HTML version deleted]]
>>>> >>>>>>>>
>>>> >>>>>>>> _______________________________________________
>>>> >>>>>>>> R-sig-mixed-models at r-project.org
>>>> >>>>>>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>> >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> >>>>>>>>
>>>> >>>>>>>> _______________________________________________
>>>> >>>>>>> R-sig-mixed-models at r-project.org
>>>> >>>>>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>> >>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> >>>>>>>
>>>> >>>>>> _______________________________________________
>>>> >>>>>> R-sig-mixed-models at r-project.org
>>>> >>>>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> >>>>>>
>>>> >>>>>
>>>> >>>         [[alternative HTML version deleted]]
>>>> >>>
>>>> >>> _______________________________________________
>>>> >>> R-sig-mixed-models at r-project.org mailing list
>>>> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> >>>
>>>> >>>
>>>> >
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>>
>>
>

	[[alternative HTML version deleted]]


From killver at gmail.com  Mon Jun 27 17:46:33 2016
From: killver at gmail.com (Philipp Singer)
Date: Mon, 27 Jun 2016 17:46:33 +0200
Subject: [R-sig-ME] Question about zero-inflated Poisson glmer
In-Reply-To: <CAJuCY5xDPr0rBa-cCCT7+_QOefO8UT8AreP_8hMh6siuM6noBA@mail.gmail.com>
References: <576B98C4.6000602@gmail.com>
	<CAJuCY5xbiEjCmHjc_3wX2emzJ3NEMTA_qKgC_reWn=zqC7YEng@mail.gmail.com>
	<576BAB84.6080009@gmail.com>
	<CAJuCY5zmK1xCyWOwcCH+Hch_LSdB+AazmUDuPVP6je7ABFU5FA@mail.gmail.com>
	<576BBCFD.8040806@gmail.com>
	<CAJuCY5ycRL6oXs=H5JrEqOHWzd1UsvSNVZM6-MK+V2N=pvbyQA@mail.gmail.com>
	<576BFEBC.3020407@gmail.com>
	<B5AEF3F5-949F-4686-82DA-C234C3C4018B@ufl.edu>
	<576C18F9.9010200@gmail.com> <576C200A.1050405@gmail.com>
	<4D07695C-8CEA-4785-A5B0-46B011625DA0@ufl.edu>
	<576D290A.7090102@gmail.com>
	<576D3209.6050507@gmail.com> <576D3864.1060001@gmail.com>
	<576D3B1B.3050908@gmail.com>
	<CAGPhqeohy3hB8hfnNcj=6d_D=mRVG9CWk910qfSEsEnnr0N__A@mail.gmail.com>
	<CAJuCY5wcBboPCe58h2kYPL1+tXwe=5dmVT10n6wFCJSE+7-wnw@mail.gmail.com>
	<CAGPhqeojDg=tXJi+oYMqAqGwCaVxkkhnhV3MBr2e9O2agEeJUA@mail.gmail.com>
	<CAGPhqeok+j2mCtfSBYveSbU1iCzvZjTefeEE8f=uyyH33ctS=w@mail.gmail.com>
	<CAJuCY5xDPr0rBa-cCCT7+_QOefO8UT8AreP_8hMh6siuM6noBA@mail.gmail.com>
Message-ID: <57714A59.4060806@gmail.com>

Well, as posted beforehand the std dev is 9.5 ... so does not seem too 
good then :/

Any other idea?

On 27.06.2016 17:31, Thierry Onkelinx wrote:
> Dear Philipp,
>
> You've been bitten by observation level random effects. I've put 
> together a document about it on http://rpubs.com/INBOstats/OLRE. 
> Bottomline you're OKish when the standard devation of the OLRE smaller 
> than 1. You're in trouble when it's above 3. In between you need to 
> check the model carefully.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature 
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no 
> more than asking him to perform a post-mortem examination: he may be 
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does 
> not ensure that a reasonable answer can be extracted from a given body 
> of data. ~ John Tukey
>
> 2016-06-27 16:17 GMT+02:00 Philipp Singer <killver at gmail.com 
> <mailto:killver at gmail.com>>:
>
>     Here is the fitted vs. residual plot for the observation-level
>     poisson model where the observation level has been removed as
>     taken from:
>     https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q3/020817.html
>
>     So basically the prediction is always close to zero.
>
>     Note that this is just on a very small sample (1000 data points).
>
>     If I fit a nbinom2 to this smalle sample, I get predictions that
>     are always around ~20 (but never zero). Both plots are attached.
>
>     What I am wondering is whether I can do inference on a fixed
>     parameter in my model which is my main task of this study. The
>     effect is similar in the different models and in general I am only
>     itnerested in whether it is positive/negative and "significant"
>     which it is. However, as can be seen, the prediction looks not too
>     good here.
>
>
>
>
>     2016-06-27 15:18 GMT+02:00 Philipp Singer <killver at gmail.com
>     <mailto:killver at gmail.com>>:
>
>         The variance is:
>
>         Conditional model:
>           Groups            Name        Variance  Std.Dev.
>           obs               (Intercept) 8.991e+01 9.4823139
>
>
>
>         2016-06-27 15:06 GMT+02:00 Thierry Onkelinx
>         <thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>>:
>
>             Dear Philipp,
>
>             How strong is the variance of the observation level random
>             effect? I would trust a model with large OLRE variance.
>
>             Best regards,
>
>             Thierry
>
>             ir. Thierry Onkelinx
>             Instituut voor natuur- en bosonderzoek / Research
>             Institute for Nature and Forest
>             team Biometrie & Kwaliteitszorg / team Biometrics &
>             Quality Assurance
>             Kliniekstraat 25
>             1070 Anderlecht
>             Belgium
>
>             To call in the statistician after the experiment is done
>             may be no more than asking him to perform a post-mortem
>             examination: he may be able to say what the experiment
>             died of. ~ Sir Ronald Aylmer Fisher
>             The plural of anecdote is not data. ~ Roger Brinner
>             The combination of some data and an aching desire for an
>             answer does not ensure that a reasonable answer can be
>             extracted from a given body of data. ~ John Tukey
>
>             2016-06-27 14:59 GMT+02:00 Philipp Singer
>             <killver at gmail.com <mailto:killver at gmail.com>>:
>
>                 I have now played around more with the data an the
>                 models both using lme4
>                 and glmmTMB.
>
>                 I can report the following:
>
>                 Modeling the data with a zero-inflated Poisson
>                 improves the model
>                 significantly. However, when calling predict and
>                 simulating rpoissons, I
>                 end up with nearly no values that are zero (in the
>                 original data there are
>                 96% zero).
>
>                 When I model the data with overdisperion by including
>                 an observation-level
>                 random effect, I can also improve the model (not
>                 surprisingly due to the
>                 random effect). When I predict outcomes by ignoring
>                 the observation-level
>                 random effect (in lme4), I receive bad prediction if I
>                 compare it to the
>                 original data. While many zeros can be captured (of
>                 course), the positive
>                 outcomes can not be captured well.
>
>                 Combining zero inflation and overdispersion further
>                 improves the model, but
>                 I can only do that with glmmTMB and then have troubles
>                 doing predictions
>                 ignoring the observation-level random effect.
>
>                 Another side question:
>
>                 In lme4, when I do:
>
>                 m = glm(x~1,family="poisson")
>                 rpois(n=len(data),lambda=predict(m,
>                 type='response',re.form=NA)
>
>                 vs.
>
>                 simulate(1,m,re.form=NA)
>
>                 I receive different outcomes? Do I understand these
>                 function wrongly?
>
>                 Would appreciate some more help/pointers!
>
>                 Thanks,
>                 Philipp
>
>                 2016-06-24 15:52 GMT+02:00 Philipp Singer
>                 <killver at gmail.com <mailto:killver at gmail.com>>:
>
>                 > Thanks - I started an issue there to answer some of
>                 my questions.
>                 >
>                 > Regarding the installation: I was trying to somehow
>                 do it in anaconda with
>                 > a specific R kernel and had some issues. I am trying
>                 to resort that with
>                 > the anaconda guys though, if I have a tutorial on
>                 how to properly setup
>                 > glmmTMB in anaconda, I will let you know. The
>                 install worked fine in my
>                 > standard R environment.
>                 >
>                 >
>                 > On 24.06.2016 15 <tel:24.06.2016%2015>:40, Ben
>                 Bolker wrote:
>                 >
>                 >>   Probably for now the glmmTMB issues page is best.
>                 >>
>                 >>   When you go there:
>                 >>
>                 >>    - details on installation problems/hiccups would
>                 be useful
>                 >>    - a reproducible example for the problem listed
>                 below would be useful
>                 >>    - dispformula is for allowing
>                 dispersion/residual variance to vary
>                 >> with covariates (i.e., modeling heteroscedasticity)
>                 >>
>                 >>    cheers
>                 >>      Ben Bolker
>                 >>
>                 >>
>                 >> On 16-06-24 09:13 AM, Philipp Singer wrote:
>                 >>
>                 >>> Update, I tried it like that, but receive an error
>                 message.
>                 >>>
>                 >>> Warning message:
>                 >>> In nlminb(start = par, objective = fn, gradient =
>                 gr): NA/NaN function
>                 >>> evaluation
>                 >>>
>                 >>> Error in solve.default(hessian.fixed): Lapack
>                 routine dgesv: system is
>                 >>> exactly singular: U[3,3] = 0
>                 >>> Traceback:
>                 >>>
>                 >>> 1. glmmTMB(y ~ 1 + x + (1 | b),
>                 >>>    .  data = data, family = "poisson", dispformula
>                 = ~1 + x)
>                 >>> 2. sdreport(obj)
>                 >>> 3. solve(hessian.fixed)
>                 >>> 4. solve(hessian.fixed)
>                 >>> 5. solve.default(hessian.fixed)
>                 >>>
>                 >>> Any ideas on that?
>                 >>>
>                 >>> BTW: Is it fine to post glmmTMB questions here, or
>                 should I rather use
>                 >>> the github issue page, or is there maybe a
>                 dedicated mailing list?
>                 >>>
>                 >>> Thanks,
>                 >>> Philipp
>                 >>>
>                 >>> On 24.06.2016 14:35, Philipp Singer wrote:
>                 >>>
>                 >>>> It indeed seems to run quite fast; had some
>                 trouble installing, but
>                 >>>> works now on my 3.3 R setup.
>                 >>>>
>                 >>>> One question I have is regarding the
>                 specification of dispersion as I
>                 >>>> need to specify the dispformula. What is the
>                 difference here between
>                 >>>> just specifying fixed effects vs. also the random
>                 effects?
>                 >>>>
>                 >>>> On 23.06.2016 23:07, Mollie Brooks wrote:
>                 >>>>
>                 >>>>> glmmTMB does crossed RE. Ben did some timings in
>                 vignette("glmmTMB")
>                 >>>>> and it was 2.3 times faster than glmer for one
>                 simple GLMM.
>                 >>>>>
>                 >>>>>
>                 >>>>> On 23Jun 2016, at 10:44, Philipp Singer
>                 <killver at gmail.com <mailto:killver at gmail.com>> wrote:
>                 >>>>>>
>                 >>>>>> Did try glmmADMB but unfortunately it is way
>                 too slow for my data.
>                 >>>>>>
>                 >>>>>> Did not know about glmmTMB, will try it out.
>                 Does it work with
>                 >>>>>> crossed random effects and how does it scale
>                 with more data? I will
>                 >>>>>> check the docu and try it though. Thanks for
>                 the info.
>                 >>>>>>
>                 >>>>>> On 23.06.2016 19:14, Ben Bolker wrote:
>                 >>>>>>
>                 >>>>>>>   I would also comment that glmmTMB is likely
>                 to be much faster
>                 >>>>>>> than the
>                 >>>>>>> lme4-based EM approach ...
>                 >>>>>>>
>                 >>>>>>>   cheers
>                 >>>>>>>     Ben B.
>                 >>>>>>>
>                 >>>>>>> On 16-06-23 12:47 PM, Mollie Brooks wrote:
>                 >>>>>>>
>                 >>>>>>>> Hi Philipp,
>                 >>>>>>>>
>                 >>>>>>>> You could also try fitting the model with and
>                 without ZI using
>                 >>>>>>>> either
>                 >>>>>>>> glmmADMB or glmmTMB. Then compare the AICs. I
>                 believe model
>                 >>>>>>>> selection
>                 >>>>>>>> is useful for this, but I could be missing
>                 something since the
>                 >>>>>>>> simulation procedure that Thierry described
>                 seems to recommended
>                 >>>>>>>> more
>                 >>>>>>>> often.
>                 >>>>>>>>
>                 >>>>>>>> https://github.com/glmmTMB/glmmTMB
>                 >>>>>>>> http://glmmadmb.r-forge.r-project.org
>                 >>>>>>>>
>                 >>>>>>>> glmmTMB is still in the development phase,
>                 but we?ve done a lot of
>                 >>>>>>>> testing.
>                 >>>>>>>>
>                 >>>>>>>> cheers, Mollie
>                 >>>>>>>>
>                 >>>>>>>> ------------------------ Mollie Brooks, PhD
>                 Postdoctoral Researcher,
>                 >>>>>>>> Population Ecology Research Group Department
>                 of Evolutionary Biology
>                 >>>>>>>> & Environmental Studies, University of Z?rich
>                 >>>>>>>> http://www.popecol.org/team/mollie-brooks/
>                 >>>>>>>>
>                 >>>>>>>>
>                 >>>>>>>> On 23Jun 2016, at 8:22, Philipp Singer
>                 <killver at gmail.com <mailto:killver at gmail.com>> wrote:
>                 >>>>>>>>>
>                 >>>>>>>>> Thanks, great information, that is really
>                 helpful.
>                 >>>>>>>>>
>                 >>>>>>>>> I agree that those are different things,
>                 however when using a
>                 >>>>>>>>> random effect for overdispersion, I can
>                 simulate the same number of
>                 >>>>>>>>> zero outcomes (~95%).
>                 >>>>>>>>>
>                 >>>>>>>>> On 23.06.2016 15:50, Thierry Onkelinx wrote:
>                 >>>>>>>>>
>                 >>>>>>>>>> Be careful when using overdispersion to
>                 model zero-inflation.
>                 >>>>>>>>>> Those are two different things.
>                 >>>>>>>>>>
>                 >>>>>>>>>> I've put some information together in
>                 >>>>>>>>>> http://rpubs.com/INBOstats/zeroinflation
>                 >>>>>>>>>>
>                 >>>>>>>>>> ir. Thierry Onkelinx Instituut voor natuur-
>                 en bosonderzoek /
>                 >>>>>>>>>> Research Institute for Nature and Forest
>                 team Biometrie &
>                 >>>>>>>>>> Kwaliteitszorg / team Biometrics & Quality
>                 Assurance
>                 >>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>                 >>>>>>>>>>
>                 >>>>>>>>>> To call in the statistician after the
>                 experiment is done may be
>                 >>>>>>>>>> no more than asking him to perform a
>                 post-mortem examination: he
>                 >>>>>>>>>> may be able to say what the experiment died
>                 of. ~ Sir Ronald
>                 >>>>>>>>>> Aylmer Fisher The plural of anecdote is not
>                 data. ~ Roger
>                 >>>>>>>>>> Brinner The combination of some data and an
>                 aching desire for an
>                 >>>>>>>>>> answer does not ensure that a reasonable
>                 answer can be extracted
>                 >>>>>>>>>> from a given body of data. ~ John Tukey
>                 >>>>>>>>>>
>                 >>>>>>>>>> 2016-06-23 12:42 GMT+02:00 Philipp Singer
>                 <killver at gmail.com <mailto:killver at gmail.com>
>                 >>>>>>>>>> <mailto:killver at gmail.com
>                 <mailto:killver at gmail.com> <mailto:killver at gmail.com
>                 <mailto:killver at gmail.com>>>>:
>                 >>>>>>>>>>
>                 >>>>>>>>>> Thanks! Actually, accounting for
>                 overdispersion is super
>                 >>>>>>>>>> important as it seems, then the zeros can
>                 be captured well.
>                 >>>>>>>>>>
>                 >>>>>>>>>>
>                 >>>>>>>>>> On 23.06.2016 11:50, Thierry Onkelinx wrote:
>                 >>>>>>>>>>
>                 >>>>>>>>>>> Dear Philipp,
>                 >>>>>>>>>>>
>                 >>>>>>>>>>> 1. Fit a Poisson model to the data. 2.
>                 Simulate a new response
>                 >>>>>>>>>>> vector for the dataset according to the
>                 model. 3. Count the
>                 >>>>>>>>>>> number of zero's in the simulated response
>                 vector. 4. Repeat
>                 >>>>>>>>>>> step 2 and 3 a decent number of time and
>                 plot a histogram of
>                 >>>>>>>>>>> the number of zero's in the simulation. If
>                 the number of zero's
>                 >>>>>>>>>>> in the original dataset is larger than
>                 those in the
>                 >>>>>>>>>>> simulations, then the model can't capture
>                 all zero's. In such
>                 >>>>>>>>>>> case, first try to update the model and
>                 repeat the procedure.
>                 >>>>>>>>>>> If that fails, look for zero-inflated models.
>                 >>>>>>>>>>>
>                 >>>>>>>>>>> Best regards,
>                 >>>>>>>>>>>
>                 >>>>>>>>>>> ir. Thierry Onkelinx Instituut voor
>                 natuur- en bosonderzoek /
>                 >>>>>>>>>>> Research Institute for Nature and Forest
>                 team Biometrie &
>                 >>>>>>>>>>> Kwaliteitszorg / team Biometrics & Quality
>                 Assurance
>                 >>>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>                 >>>>>>>>>>>
>                 >>>>>>>>>>> To call in the statistician after the
>                 experiment is done may
>                 >>>>>>>>>>> be no more than asking him to perform a
>                 post-mortem
>                 >>>>>>>>>>> examination: he may be able to say what
>                 the experiment died of.
>                 >>>>>>>>>>> ~ Sir Ronald Aylmer Fisher The plural of
>                 anecdote is not data.
>                 >>>>>>>>>>> ~ Roger Brinner The combination of some
>                 data and an aching
>                 >>>>>>>>>>> desire for an answer does not ensure that
>                 a reasonable answer
>                 >>>>>>>>>>> can be extracted from a given body of
>                 data. ~ John Tukey
>                 >>>>>>>>>>>
>                 >>>>>>>>>>> 2016-06-23 11:27 GMT+02:00 Philipp Singer
>                 <killver at gmail.com <mailto:killver at gmail.com>
>                 >>>>>>>>>>> <mailto:killver at gmail.com
>                 <mailto:killver at gmail.com> <mailto:killver at gmail.com
>                 <mailto:killver at gmail.com>>>>:
>                 >>>>>>>>>>>
>                 >>>>>>>>>>> Thanks Thierry - That totally makes sense.
>                 Is there some way of
>                 >>>>>>>>>>> formally checking that, except thinking
>                 about the setting and
>                 >>>>>>>>>>> underlying processes?
>                 >>>>>>>>>>>
>                 >>>>>>>>>>> On 23.06.2016 11:04, Thierry Onkelinx wrote:
>                 >>>>>>>>>>>
>                 >>>>>>>>>>>> Dear Philipp,
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>>> Do you have just lots of zero's, or more
>                 zero's than the
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>> Poisson
>                 >>>>>>>>>>>
>                 >>>>>>>>>>>> distribution can explain? Those are two
>                 different things.
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>> The example
>                 >>>>>>>>>>>
>                 >>>>>>>>>>>> below generates data from a Poisson
>                 distribution and has
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>> 99% zero's
>                 >>>>>>>>>>>
>                 >>>>>>>>>>>> but no zero-inflation. The second example
>                 has only 1%
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>> zero's but is
>                 >>>>>>>>>>>
>                 >>>>>>>>>>>> clearly zero-inflated.
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>>> set.seed(1) n <- 1e8 sim <- rpois(n,
>                 lambda = 0.01) mean(sim
>                 >>>>>>>>>>>> == 0) hist(sim)
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>>> sim.infl <- rbinom(n, size = 1, prob =
>                 0.99) * rpois(n,
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>> lambda = 1000)
>                 >>>>>>>>>>>
>                 >>>>>>>>>>>> mean(sim.infl == 0) hist(sim.infl)
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>>> So before looking for zero-inflated
>                 models, try to model
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>> the zero's.
>                 >>>>>>>>>>>
>                 >>>>>>>>>>>> Best regards,
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>>> ir. Thierry Onkelinx Instituut voor
>                 natuur- en bosonderzoek /
>                 >>>>>>>>>>>> Research Institute
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>> for Nature
>                 >>>>>>>>>>>
>                 >>>>>>>>>>>> and Forest team Biometrie &
>                 Kwaliteitszorg / team Biometrics
>                 >>>>>>>>>>>> & Quality
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>> Assurance
>                 >>>>>>>>>>>
>                 >>>>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>>> To call in the statistician after the
>                 experiment is done
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>> may be no
>                 >>>>>>>>>>>
>                 >>>>>>>>>>>> more than asking him to perform a
>                 post-mortem examination:
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>> he may be
>                 >>>>>>>>>>>
>                 >>>>>>>>>>>> able to say what the experiment died of.
>                 ~ Sir Ronald
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>> Aylmer Fisher
>                 >>>>>>>>>>>
>                 >>>>>>>>>>>> The plural of anecdote is not data. ~
>                 Roger Brinner The
>                 >>>>>>>>>>>> combination of some data and an aching
>                 desire for an
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>> answer does
>                 >>>>>>>>>>>
>                 >>>>>>>>>>>> not ensure that a reasonable answer can
>                 be extracted from a
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>> given body
>                 >>>>>>>>>>>
>                 >>>>>>>>>>>> of data. ~ John Tukey
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>>> 2016-06-23 10:07 GMT+02:00 Philipp Singer
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>> <killver at gmail.com
>                 <mailto:killver at gmail.com> <mailto:killver at gmail.com
>                 <mailto:killver at gmail.com>>
>                 >>>>>>>>>>> <mailto:killver at gmail.com
>                 <mailto:killver at gmail.com> <mailto:killver at gmail.com
>                 <mailto:killver at gmail.com>>>
>                 >>>>>>>>>>>
>                 >>>>>>>>>>>> <mailto:killver at gmail.com
>                 <mailto:killver at gmail.com> <mailto:killver at gmail.com
>                 <mailto:killver at gmail.com>>
>                 >>>>>>>>>>>> <mailto:killver at gmail.com
>                 <mailto:killver at gmail.com> <mailto:killver at gmail.com
>                 <mailto:killver at gmail.com>>>>>:
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>>> Dear group - I am currently fitting a
>                 Poisson glmer
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>> where I have
>                 >>>>>>>>>>>
>                 >>>>>>>>>>>> an excess of outcomes that are zero
>                 (>95%). I am now
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>> debating on
>                 >>>>>>>>>>>
>                 >>>>>>>>>>>> how to proceed and came up with three
>                 options:
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>>> 1.) Just fit a regular glmer to the
>                 complete data. I am
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>> not fully
>                 >>>>>>>>>>>
>                 >>>>>>>>>>>> sure how interpret the coefficients then,
>                 are they more
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>> optimizing
>                 >>>>>>>>>>>
>                 >>>>>>>>>>>> towards distinguishing zero and non-zero,
>                 or also
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>> capturing the
>                 >>>>>>>>>>>
>                 >>>>>>>>>>>> differences in those outcomes that are
>                 non-zero?
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>>> 2.) Leave all zeros out of the data and
>                 fit a glmer to
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>> only those
>                 >>>>>>>>>>>
>                 >>>>>>>>>>>> outcomes that are non-zero. Then, I would
>                 only learn about
>                 >>>>>>>>>>>> differences in the non-zero outcomes though.
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>>> 3.) Use a zero-inflated Poisson model. My
>                 data is quite
>                 >>>>>>>>>>>> large-scale, so I am currently playing
>                 around with the EM
>                 >>>>>>>>>>>> implementation of Bolker et al. that
>                 alternates between
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>> fitting a
>                 >>>>>>>>>>>
>                 >>>>>>>>>>>> glmer with data that are weighted
>                 according to their zero
>                 >>>>>>>>>>>> probability, and fitting a logistic
>                 regression for the
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>> probability
>                 >>>>>>>>>>>
>                 >>>>>>>>>>>> that a data point is zero. The method is
>                 elaborated for
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>> the OWL
>                 >>>>>>>>>>>
>                 >>>>>>>>>>>> data in:
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>>
>                 https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
>                 >>>>>>>>>>> <
>                 >>>>>>>>>>>
>                 https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
>                 >>>>>>>>>>> >
>                 >>>>>>>>>>>
>                 >>>>>>>>>> I am not fully sure how to interpret the
>                 results for the
>                 >>>>>>>
>                 >>>>>>>> zero-inflated version though. Would I need to
>                 interpret the
>                 >>>>>>>>>>>> coefficients for the result of the glmer
>                 similar to as
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>> I would do
>                 >>>>>>>>>>>
>                 >>>>>>>>>>>> for my idea of 2)? And then on top of
>                 that interpret the
>                 >>>>>>>>>>>> coefficients for the logistic regression
>                 regarding whether
>                 >>>>>>>>>>>> something is in the perfect or imperfect
>                 state? I am
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>> also not
>                 >>>>>>>>>>>
>                 >>>>>>>>>>>> quite sure what the common approach for
>                 the zformula is
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>> here. The
>                 >>>>>>>>>>>
>                 >>>>>>>>>>>> OWL elaborations only use zformula=z~1,
>                 so no random
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>> effect; I
>                 >>>>>>>>>>>
>                 >>>>>>>>>>>> would use the same formula as for the glmer.
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>>> I am appreciating some help and pointers.
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>>> Thanks! Philipp
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>>>
>                 _______________________________________________
>                 >>>>>>>>>>>> R-sig-mixed-models at r-project.org
>                 <mailto:R-sig-mixed-models at r-project.org>
>                 >>>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>                 <mailto:R-sig-mixed-models at r-project.org>>
>                 >>>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>                 <mailto:R-sig-mixed-models at r-project.org>>
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>                 <mailto:R-sig-mixed-models at r-project.org>
>                 >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>                 <mailto:R-sig-mixed-models at r-project.org>>>
>                 >>>>>>>>>>>
>                 >>>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>                 <mailto:R-sig-mixed-models at r-project.org>
>                 >>>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>                 <mailto:R-sig-mixed-models at r-project.org>>
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>                 <mailto:R-sig-mixed-models at r-project.org>
>                 >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>                 <mailto:R-sig-mixed-models at r-project.org>>>> mailing list
>                 >>>>>>>>>>>
>                 >>>>>>>>>>>>
>                 https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>                 >>>>>>>>>>>>
>                 <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>>>
>                 >>>>>>>>>>>> [[alternative HTML version deleted]]
>                 >>>>>>>>>>>
>                 >>>>>>>>>>>
>                 _______________________________________________
>                 >>>>>>>>>>> R-sig-mixed-models at r-project.org
>                 <mailto:R-sig-mixed-models at r-project.org>
>                 >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>                 <mailto:R-sig-mixed-models at r-project.org>>
>                 >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>                 <mailto:R-sig-mixed-models at r-project.org>>
>                 >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>                 <mailto:R-sig-mixed-models at r-project.org>
>                 >>>>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>                 <mailto:R-sig-mixed-models at r-project.org>>> mailing list
>                 >>>>>>>>>>>
>                 https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>                 >>>>>>>>>>>
>                 <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>                 >>>>>>>>>>>
>                 >>>>>>>>>>>
>                 >>>>>>>>>>> [[alternative HTML version deleted]]
>                 >>>>>>>>>
>                 >>>>>>>>> _______________________________________________
>                 >>>>>>>>> R-sig-mixed-models at r-project.org
>                 <mailto:R-sig-mixed-models at r-project.org>
>                 >>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>                 <mailto:R-sig-mixed-models at r-project.org>>
>                 >>>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>                 <mailto:R-sig-mixed-models at r-project.org>> mailing list
>                 >>>>>>>>>
>                 https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>                 >>>>>>>>>
>                 <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>                 >>>>>>>>>
>                 >>>>>>>> [[alternative HTML version deleted]]
>                 >>>>>>>>
>                 >>>>>>>> _______________________________________________
>                 >>>>>>>> R-sig-mixed-models at r-project.org
>                 <mailto:R-sig-mixed-models at r-project.org>
>                 >>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>                 <mailto:R-sig-mixed-models at r-project.org>> mailing list
>                 >>>>>>>>
>                 https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>                 >>>>>>>>
>                 >>>>>>>> _______________________________________________
>                 >>>>>>> R-sig-mixed-models at r-project.org
>                 <mailto:R-sig-mixed-models at r-project.org>
>                 >>>>>>> <mailto:R-sig-mixed-models at r-project.org
>                 <mailto:R-sig-mixed-models at r-project.org>> mailing list
>                 >>>>>>>
>                 https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>                 >>>>>>>
>                 >>>>>> _______________________________________________
>                 >>>>>> R-sig-mixed-models at r-project.org
>                 <mailto:R-sig-mixed-models at r-project.org>
>                 >>>>>> <mailto:R-sig-mixed-models at r-project.org
>                 <mailto:R-sig-mixed-models at r-project.org>> mailing list
>                 >>>>>>
>                 https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>                 >>>>>>
>                 >>>>>
>                 >>>  [[alternative HTML version deleted]]
>                 >>>
>                 >>> _______________________________________________
>                 >>> R-sig-mixed-models at r-project.org
>                 <mailto:R-sig-mixed-models at r-project.org> mailing list
>                 >>>
>                 https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>                 >>>
>                 >>>
>                 >
>
>                         [[alternative HTML version deleted]]
>
>                 _______________________________________________
>                 R-sig-mixed-models at r-project.org
>                 <mailto:R-sig-mixed-models at r-project.org> mailing list
>                 https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
>
>


	[[alternative HTML version deleted]]


From newboch at auburn.edu  Mon Jun 27 19:00:00 2016
From: newboch at auburn.edu (Chad Newbolt)
Date: Mon, 27 Jun 2016 17:00:00 +0000
Subject: [R-sig-ME] GLMM, overdispersion,
 and method for comparing competetive models
In-Reply-To: <1466888080252.6726@auburn.edu>
References: <1466798523378.31942@auburn.edu>, <576D9EC7.1080102@gmail.com>,
	<1466888080252.6726@auburn.edu>
Message-ID: <1467046800121.10945@auburn.edu>

I successfully loaded the glmmADMB package using the code below so thanks for that bit of help.  

Since I have evidence for overdispersion, I'm using negative binomial distribution as opposed to Poisson.

My two questions are:

1) When I fit using the following global zero inflation model I receive the following error:

fit1=glmmadmb(Fawn~Age+I(Age^2)+BodySize+SSCM+AvgAge+Age*AvgAge+I(Age^2)*AvgAge+BodySize*AvgAge+SSCM*AvgAge+(1|Sire),data=datum,family="nbinom",zeroInflation = TRUE)
Parameters were estimated, but standard errors were not: the most likely problem is that the curvature at MLE was zero or negative
Error in glmmadmb(Fawn ~ Age + I(Age^2) + BodySize + SSCM + AvgAge + Age *  : 
  The function maximizer failed (couldn't find parameter file) Troubleshooting steps include (1) run with 'save.dir' set and inspect output files; (2) change run parameters: see '?admbControl';(3) re-run with debug=TRUE for more information on failure mode
In addition: Warning message:
running command 'C:\windows\system32\cmd.exe /c glmmadmb -maxfn 500 -maxph 5 -noinit -shess' had status 1

However, when I change to zeroInflation = FALSE, I receive no warnings and everything seems to go as should.

Does this simply mean that my data is not zero inflated, hence the zero inflated model will not run, or is this something I should be concerned about and investigate the cause further?  When I debug   I see the following warning....Warning -- Hessian does not appear to be positive definite Hessian does not appear to be positive definite. 


2) When fitting more simple versions(predictors removed) I receive the same error as above when using the family=nbinom;  however these errors disappear when using family=nbinom1.  Is this indicative of an underlying problem or am I OK to use the ouput from the later family where variance = ??.

Thanks,

Chad
 

________________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Chad Newbolt <newboch at auburn.edu>
Sent: Saturday, June 25, 2016 3:54 PM
To: R-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] GLMM, overdispersion, and method for comparing competetive models

Thanks.  I'll  take this into consideration and get back to everyone.  Please disregard the other posting that was sent out today containing the exact same content.  I accidentally posted twice during the new member enrolling process.  Sorry and thanks again for the help.

Chad
________________________________________
From: Ben Bolker <bbolker at gmail.com>
Sent: Friday, June 24, 2016 3:57 PM
To: Chad Newbolt; R-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] GLMM, overdispersion, and method for comparing competetive models

  A couple of quick comments:

  (1) try

install.packages(c("R2admb","stringr","plyr","coda"))

  before doing the glmmADMB installation.

  (2) more advice about overdispersion is available at
http://tinyurl.com/glmmFAQ#Overdispersion

 ...

On 16-06-24 04:02 PM, Chad Newbolt wrote:
> All,
>
> I would first like to say that I'm a relative novice with R so please
> take that into consideration with your responses.  Basically, give me
> the totally dumbed down version of answers when you can.
>
> I have a biological data set with count data that I'm currently
> analyzing.  Namely, I'm interested in looking at the effects of
> animal age, bodysize, and antler size on annual male reproductive
> success (i.e. number of fawns produced).  I would also like to see
> how the relationships are influenced by changes in population
> demographics.  I have been using a GLMM to evaluate the following
> global model:
>
> repro =
> glmer(Fawn~Age+I(Age^2)+BodySize+SSCM+AvgAge+Age*AvgAge+I(Age^2)*AvgAge+BodySize*AvgAge+SSCM*AvgAge+(1|Sire),data=datum,family=poisson)
>
>  where:
>
> Age, BodySize, SSCM are measured characteristics Fawn = number of
> fawns produced in a given year AvgAge = Population demographic
> factor (1|Sire) = Random effect for each sampled male ID
>
> I first used the following to evaluate potential overdispersion of my
> data from the global model:
>
> overdisp_fun <- function(model) { ## number of variance parameters
> in ##   an n-by-n variance-covariance matrix vpars <- function(m) {
> nrow(m)*(nrow(m)+1)/2 } model.df <-
> sum(sapply(VarCorr(model),vpars))+length(fixef(model)) rdf <-
> nrow(model.frame(model))-model.df rp <-
> residuals(model,type="pearson") Pearson.chisq <- sum(rp^2) prat <-
> Pearson.chisq/rdf pval <- pchisq(Pearson.chisq, df=rdf,
> lower.tail=FALSE) c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p=pval) }
>
> With the following result
>
> repro =
> glmer(Fawn~Age+I(Age^2)+BodySize+SSCM+AvgAge+Age*AvgAge+I(Age^2)*AvgAge+BodySize*AvgAge+SSCM*AvgAge+(1|Sire),data=datum,family=poisson)
>
>
overdisp_fun(repro)
> chisq                             ratio                          rdf
> p 1.698574e+02      1.681756e+00       1.010000e+02
> 2.169243e-05
>
> Since the ratio of Pearson-statistic to rdf is 1.68 I assume that I
> need to take this overdispersion into account
>
> My first inclination was to use quasipoisson distribution to account
> for overdispersion; however, I see that in no longer available in
> lme4.  I used glmmPQL in the MASS package with quasipoisson but do
> not receive AICc information.  I had planned on using AICc to
> evaluate competitive models.  My specific question is: 1) is there a
> way to generate the necessary information (AICc or something like) to
> compare competitive models from overdispersed data in a current R
> environment? I have read
> https://cran.r-project.org/web/packages/bbmle/vignettes/quasi.pdf but
> I'm having a difficult time understanding exactly how to implement
> from a technical perspective.  I'm on the path of trying to use a
> negative binomial (I'm not locked into this method so please provide
> insight if appropriate) with package glmmADMB: however, I have been
> unable to get this package to load successfully.  I've followed the
> instructions to the best of my understanding and abilities but cannot
> figure out where I'm going wrong.  Any advice is much appreciated as
> I'm totally stumped right now on many fronts.  I'm running windows 7
> on 64-bit machine.  Here is what I have attempted with output:
>
> install.packages("glmmADMB", +
> repos=c("http://glmmadmb.r-forge.r-project.org/repos", +
> getOption("repos")), +     type="source") Installing package into
> ?C:/Users/newboch/Documents/R/win-library/3.3? (as ?lib? is
> unspecified) trying URL
> 'http://glmmadmb.r-forge.r-project.org/repos/src/contrib/glmmADMB_0.8.3.3.tar.gz'
>
>
Content type 'application/x-gzip' length 9391177 bytes (9.0 MB)
> downloaded 9.0 MB * installing *source* package 'glmmADMB' ... ** R
> ** data *** moving datasets to lazyload DB ** inst ** preparing
> package for lazy loading Error in loadNamespace(i, c(lib.loc,
> .libPaths()), versionCheck = vI[[i]]) : there is no package called
> 'stringi' ERROR: lazy loading failed for package 'glmmADMB' *
> removing 'C:/Users/newboch/Documents/R/win-library/3.3/glmmADMB' The
> downloaded source packages are in
> ?C:\Users\newboch\AppData\Local\Temp\RtmpK23VOM\downloaded_packages?
> Warning messages: 1: running command
> '"C:/PROGRA~1/R/R-33~1.1/bin/x64/R" CMD INSTALL -l
> "C:\Users\newboch\Documents\R\win-library\3.3"
> C:\Users\newboch\AppData\Local\Temp\RtmpK23VOM/downloaded_packages/glmmADMB_0.8.3.3.tar.gz'
> had status 1 2: In install.packages("glmmADMB", repos =
> c("http://glmmadmb.r-forge.r-project.org/repos",  : installation of
> package ?glmmADMB? had non-zero exit status
>> glmmADMB:::get_bin_loc()
> Error in loadNamespace(name) : there is no package called ?glmmADMB?
>> library("R2admb") glmmADMB:::get_bin_loc()
> Error in loadNamespace(name) : there is no package called ?glmmADMB?
>> install.packages("glmmADMB")
> Installing package into
> ?C:/Users/newboch/Documents/R/win-library/3.3? (as ?lib? is
> unspecified) Warning message: package ?glmmADMB? is not available
> (for R version 3.3.1) Thanks,
>
> Chad
>
> [[alternative HTML version deleted]]
>
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From thierry.onkelinx at inbo.be  Mon Jun 27 21:59:34 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 27 Jun 2016 21:59:34 +0200
Subject: [R-sig-ME] Question about zero-inflated Poisson glmer
In-Reply-To: <57714A59.4060806@gmail.com>
References: <576B98C4.6000602@gmail.com>
	<CAJuCY5xbiEjCmHjc_3wX2emzJ3NEMTA_qKgC_reWn=zqC7YEng@mail.gmail.com>
	<576BAB84.6080009@gmail.com>
	<CAJuCY5zmK1xCyWOwcCH+Hch_LSdB+AazmUDuPVP6je7ABFU5FA@mail.gmail.com>
	<576BBCFD.8040806@gmail.com>
	<CAJuCY5ycRL6oXs=H5JrEqOHWzd1UsvSNVZM6-MK+V2N=pvbyQA@mail.gmail.com>
	<576BFEBC.3020407@gmail.com>
	<B5AEF3F5-949F-4686-82DA-C234C3C4018B@ufl.edu>
	<576C18F9.9010200@gmail.com> <576C200A.1050405@gmail.com>
	<4D07695C-8CEA-4785-A5B0-46B011625DA0@ufl.edu>
	<576D290A.7090102@gmail.com> <576D3209.6050507@gmail.com>
	<576D3864.1060001@gmail.com> <576D3B1B.3050908@gmail.com>
	<CAGPhqeohy3hB8hfnNcj=6d_D=mRVG9CWk910qfSEsEnnr0N__A@mail.gmail.com>
	<CAJuCY5wcBboPCe58h2kYPL1+tXwe=5dmVT10n6wFCJSE+7-wnw@mail.gmail.com>
	<CAGPhqeojDg=tXJi+oYMqAqGwCaVxkkhnhV3MBr2e9O2agEeJUA@mail.gmail.com>
	<CAGPhqeok+j2mCtfSBYveSbU1iCzvZjTefeEE8f=uyyH33ctS=w@mail.gmail.com>
	<CAJuCY5xDPr0rBa-cCCT7+_QOefO8UT8AreP_8hMh6siuM6noBA@mail.gmail.com>
	<57714A59.4060806@gmail.com>
Message-ID: <CAJuCY5yOWstEGO9wiQvrc48bFGtuz0Cfp4tzVQ67+py3rmBk0A@mail.gmail.com>

If there is overdispersion, then try a negative binomial model or a
zero-inflated negative binomial model. If not try a zero-inflated Poisson.
Adding relevant covariates can reduce overdispersion.

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-06-27 17:46 GMT+02:00 Philipp Singer <killver at gmail.com>:

> Well, as posted beforehand the std dev is 9.5 ... so does not seem too
> good then :/
>
> Any other idea?
>
>
> On 27.06.2016 17:31, Thierry Onkelinx wrote:
>
> Dear Philipp,
>
> You've been bitten by observation level random effects. I've put together
> a document about it on  <http://rpubs.com/INBOstats/OLRE>
> http://rpubs.com/INBOstats/OLRE. Bottomline you're OKish when the
> standard devation of the OLRE smaller than 1. You're in trouble when it's
> above 3. In between you need to check the model carefully.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2016-06-27 16:17 GMT+02:00 Philipp Singer <killver at gmail.com>:
>
>> Here is the fitted vs. residual plot for the observation-level poisson
>> model where the observation level has been removed as taken from:
>> <https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q3/020817.html>
>> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q3/020817.html
>>
>> So basically the prediction is always close to zero.
>>
>> Note that this is just on a very small sample (1000 data points).
>>
>> If I fit a nbinom2 to this smalle sample, I get predictions that are
>> always around ~20 (but never zero). Both plots are attached.
>>
>> What I am wondering is whether I can do inference on a fixed parameter in
>> my model which is my main task of this study. The effect is similar in the
>> different models and in general I am only itnerested in whether it is
>> positive/negative and "significant" which it is. However, as can be seen,
>> the prediction looks not too good here.
>>
>>
>>
>>
>> 2016-06-27 15:18 GMT+02:00 Philipp Singer < <killver at gmail.com>
>> killver at gmail.com>:
>>
>>> The variance is:
>>>
>>> Conditional model:
>>>  Groups            Name        Variance  Std.Dev.
>>>  obs               (Intercept) 8.991e+01 9.4823139
>>>
>>>
>>>
>>> 2016-06-27 15:06 GMT+02:00 Thierry Onkelinx < <thierry.onkelinx at inbo.be>
>>> thierry.onkelinx at inbo.be>:
>>>
>>>> Dear Philipp,
>>>>
>>>> How strong is the variance of the observation level random effect? I
>>>> would trust a model with large OLRE variance.
>>>>
>>>> Best regards,
>>>>
>>>> Thierry
>>>>
>>>> ir. Thierry Onkelinx
>>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>>> and Forest
>>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>>> Kliniekstraat 25
>>>> 1070 Anderlecht
>>>> Belgium
>>>>
>>>> To call in the statistician after the experiment is done may be no more
>>>> than asking him to perform a post-mortem examination: he may be able to say
>>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>> The combination of some data and an aching desire for an answer does
>>>> not ensure that a reasonable answer can be extracted from a given body of
>>>> data. ~ John Tukey
>>>>
>>>> 2016-06-27 14:59 GMT+02:00 Philipp Singer < <killver at gmail.com>
>>>> killver at gmail.com>:
>>>>
>>>>> I have now played around more with the data an the models both using
>>>>> lme4
>>>>> and glmmTMB.
>>>>>
>>>>> I can report the following:
>>>>>
>>>>> Modeling the data with a zero-inflated Poisson improves the model
>>>>> significantly. However, when calling predict and simulating rpoissons,
>>>>> I
>>>>> end up with nearly no values that are zero (in the original data there
>>>>> are
>>>>> 96% zero).
>>>>>
>>>>> When I model the data with overdisperion by including an
>>>>> observation-level
>>>>> random effect, I can also improve the model (not surprisingly due to
>>>>> the
>>>>> random effect). When I predict outcomes by ignoring the
>>>>> observation-level
>>>>> random effect (in lme4), I receive bad prediction if I compare it to
>>>>> the
>>>>> original data. While many zeros can be captured (of course), the
>>>>> positive
>>>>> outcomes can not be captured well.
>>>>>
>>>>> Combining zero inflation and overdispersion further improves the
>>>>> model, but
>>>>> I can only do that with glmmTMB and then have troubles doing
>>>>> predictions
>>>>> ignoring the observation-level random effect.
>>>>>
>>>>> Another side question:
>>>>>
>>>>> In lme4, when I do:
>>>>>
>>>>> m = glm(x~1,family="poisson")
>>>>> rpois(n=len(data),lambda=predict(m, type='response',re.form=NA)
>>>>>
>>>>> vs.
>>>>>
>>>>> simulate(1,m,re.form=NA)
>>>>>
>>>>> I receive different outcomes? Do I understand these function wrongly?
>>>>>
>>>>> Would appreciate some more help/pointers!
>>>>>
>>>>> Thanks,
>>>>> Philipp
>>>>>
>>>>> 2016-06-24 15:52 GMT+02:00 Philipp Singer < <killver at gmail.com>
>>>>> killver at gmail.com>:
>>>>>
>>>>> > Thanks - I started an issue there to answer some of my questions.
>>>>> >
>>>>> > Regarding the installation: I was trying to somehow do it in
>>>>> anaconda with
>>>>> > a specific R kernel and had some issues. I am trying to resort that
>>>>> with
>>>>> > the anaconda guys though, if I have a tutorial on how to properly
>>>>> setup
>>>>> > glmmTMB in anaconda, I will let you know. The install worked fine in
>>>>> my
>>>>> > standard R environment.
>>>>> >
>>>>> >
>>>>> > On 24.06.2016 15 <24.06.2016%2015>:40, Ben Bolker wrote:
>>>>> >
>>>>> >>   Probably for now the glmmTMB issues page is best.
>>>>> >>
>>>>> >>   When you go there:
>>>>> >>
>>>>> >>    - details on installation problems/hiccups would be useful
>>>>> >>    - a reproducible example for the problem listed below would be
>>>>> useful
>>>>> >>    - dispformula is for allowing dispersion/residual variance to
>>>>> vary
>>>>> >> with covariates (i.e., modeling heteroscedasticity)
>>>>> >>
>>>>> >>    cheers
>>>>> >>      Ben Bolker
>>>>> >>
>>>>> >>
>>>>> >> On 16-06-24 09:13 AM, Philipp Singer wrote:
>>>>> >>
>>>>> >>> Update, I tried it like that, but receive an error message.
>>>>> >>>
>>>>> >>> Warning message:
>>>>> >>> In nlminb(start = par, objective = fn, gradient = gr): NA/NaN
>>>>> function
>>>>> >>> evaluation
>>>>> >>>
>>>>> >>> Error in solve.default(hessian.fixed): Lapack routine dgesv:
>>>>> system is
>>>>> >>> exactly singular: U[3,3] = 0
>>>>> >>> Traceback:
>>>>> >>>
>>>>> >>> 1. glmmTMB(y ~ 1 + x + (1 | b),
>>>>> >>>    .     data = data, family = "poisson", dispformula = ~1 + x)
>>>>> >>> 2. sdreport(obj)
>>>>> >>> 3. solve(hessian.fixed)
>>>>> >>> 4. solve(hessian.fixed)
>>>>> >>> 5. solve.default(hessian.fixed)
>>>>> >>>
>>>>> >>> Any ideas on that?
>>>>> >>>
>>>>> >>> BTW: Is it fine to post glmmTMB questions here, or should I rather
>>>>> use
>>>>> >>> the github issue page, or is there maybe a dedicated mailing list?
>>>>> >>>
>>>>> >>> Thanks,
>>>>> >>> Philipp
>>>>> >>>
>>>>> >>> On 24.06.2016 14:35, Philipp Singer wrote:
>>>>> >>>
>>>>> >>>> It indeed seems to run quite fast; had some trouble installing,
>>>>> but
>>>>> >>>> works now on my 3.3 R setup.
>>>>> >>>>
>>>>> >>>> One question I have is regarding the specification of dispersion
>>>>> as I
>>>>> >>>> need to specify the dispformula. What is the difference here
>>>>> between
>>>>> >>>> just specifying fixed effects vs. also the random effects?
>>>>> >>>>
>>>>> >>>> On 23.06.2016 23:07, Mollie Brooks wrote:
>>>>> >>>>
>>>>> >>>>> glmmTMB does crossed RE. Ben did some timings in
>>>>> vignette("glmmTMB")
>>>>> >>>>> and it was 2.3 times faster than glmer for one simple GLMM.
>>>>> >>>>>
>>>>> >>>>>
>>>>> >>>>> On 23Jun 2016, at 10:44, Philipp Singer < <killver at gmail.com>
>>>>> killver at gmail.com> wrote:
>>>>> >>>>>>
>>>>> >>>>>> Did try glmmADMB but unfortunately it is way too slow for my
>>>>> data.
>>>>> >>>>>>
>>>>> >>>>>> Did not know about glmmTMB, will try it out. Does it work with
>>>>> >>>>>> crossed random effects and how does it scale with more data? I
>>>>> will
>>>>> >>>>>> check the docu and try it though. Thanks for the info.
>>>>> >>>>>>
>>>>> >>>>>> On 23.06.2016 19:14, Ben Bolker wrote:
>>>>> >>>>>>
>>>>> >>>>>>>    I would also comment that glmmTMB is likely to be much
>>>>> faster
>>>>> >>>>>>> than the
>>>>> >>>>>>> lme4-based EM approach ...
>>>>> >>>>>>>
>>>>> >>>>>>>    cheers
>>>>> >>>>>>>      Ben B.
>>>>> >>>>>>>
>>>>> >>>>>>> On 16-06-23 12:47 PM, Mollie Brooks wrote:
>>>>> >>>>>>>
>>>>> >>>>>>>> Hi Philipp,
>>>>> >>>>>>>>
>>>>> >>>>>>>> You could also try fitting the model with and without ZI using
>>>>> >>>>>>>> either
>>>>> >>>>>>>> glmmADMB or glmmTMB. Then compare the AICs. I believe model
>>>>> >>>>>>>> selection
>>>>> >>>>>>>> is useful for this, but I could be missing something since the
>>>>> >>>>>>>> simulation procedure that Thierry described seems to
>>>>> recommended
>>>>> >>>>>>>> more
>>>>> >>>>>>>> often.
>>>>> >>>>>>>>
>>>>> >>>>>>>> <https://github.com/glmmTMB/glmmTMB>
>>>>> https://github.com/glmmTMB/glmmTMB
>>>>> >>>>>>>> <http://glmmadmb.r-forge.r-project.org>
>>>>> http://glmmadmb.r-forge.r-project.org
>>>>> >>>>>>>>
>>>>> >>>>>>>> glmmTMB is still in the development phase, but we?ve done a
>>>>> lot of
>>>>> >>>>>>>> testing.
>>>>> >>>>>>>>
>>>>> >>>>>>>> cheers, Mollie
>>>>> >>>>>>>>
>>>>> >>>>>>>> ------------------------ Mollie Brooks, PhD Postdoctoral
>>>>> Researcher,
>>>>> >>>>>>>> Population Ecology Research Group Department of Evolutionary
>>>>> Biology
>>>>> >>>>>>>> & Environmental Studies, University of Z?rich
>>>>> >>>>>>>> <http://www.popecol.org/team/mollie-brooks/>
>>>>> http://www.popecol.org/team/mollie-brooks/
>>>>> >>>>>>>>
>>>>> >>>>>>>>
>>>>> >>>>>>>> On 23Jun 2016, at 8:22, Philipp Singer < <killver at gmail.com>
>>>>> killver at gmail.com> wrote:
>>>>> >>>>>>>>>
>>>>> >>>>>>>>> Thanks, great information, that is really helpful.
>>>>> >>>>>>>>>
>>>>> >>>>>>>>> I agree that those are different things, however when using a
>>>>> >>>>>>>>> random effect for overdispersion, I can simulate the same
>>>>> number of
>>>>> >>>>>>>>> zero outcomes (~95%).
>>>>> >>>>>>>>>
>>>>> >>>>>>>>> On 23.06.2016 15:50, Thierry Onkelinx wrote:
>>>>> >>>>>>>>>
>>>>> >>>>>>>>>> Be careful when using overdispersion to model
>>>>> zero-inflation.
>>>>> >>>>>>>>>> Those are two different things.
>>>>> >>>>>>>>>>
>>>>> >>>>>>>>>> I've put some information together in
>>>>> >>>>>>>>>> <http://rpubs.com/INBOstats/zeroinflation>
>>>>> http://rpubs.com/INBOstats/zeroinflation
>>>>> >>>>>>>>>>
>>>>> >>>>>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek
>>>>> /
>>>>> >>>>>>>>>> Research Institute for Nature and Forest team Biometrie &
>>>>> >>>>>>>>>> Kwaliteitszorg / team Biometrics & Quality Assurance
>>>>> >>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>>>> >>>>>>>>>>
>>>>> >>>>>>>>>> To call in the statistician after the experiment is done
>>>>> may be
>>>>> >>>>>>>>>> no more than asking him to perform a post-mortem
>>>>> examination: he
>>>>> >>>>>>>>>> may be able to say what the experiment died of. ~ Sir Ronald
>>>>> >>>>>>>>>> Aylmer Fisher The plural of anecdote is not data. ~ Roger
>>>>> >>>>>>>>>> Brinner The combination of some data and an aching desire
>>>>> for an
>>>>> >>>>>>>>>> answer does not ensure that a reasonable answer can be
>>>>> extracted
>>>>> >>>>>>>>>> from a given body of data. ~ John Tukey
>>>>> >>>>>>>>>>
>>>>> >>>>>>>>>> 2016-06-23 12:42 GMT+02:00 Philipp Singer <
>>>>> <killver at gmail.com>killver at gmail.com
>>>>> >>>>>>>>>> <mailto: <killver at gmail.com>killver at gmail.com <mailto:
>>>>> <killver at gmail.com>killver at gmail.com>>>:
>>>>> >>>>>>>>>>
>>>>> >>>>>>>>>> Thanks! Actually, accounting for overdispersion is super
>>>>> >>>>>>>>>> important as it seems, then the zeros can be captured well.
>>>>> >>>>>>>>>>
>>>>> >>>>>>>>>>
>>>>> >>>>>>>>>> On 23.06.2016 11:50, Thierry Onkelinx wrote:
>>>>> >>>>>>>>>>
>>>>> >>>>>>>>>>> Dear Philipp,
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>> 1. Fit a Poisson model to the data. 2. Simulate a new
>>>>> response
>>>>> >>>>>>>>>>> vector for the dataset according to the model. 3. Count the
>>>>> >>>>>>>>>>> number of zero's in the simulated response vector. 4.
>>>>> Repeat
>>>>> >>>>>>>>>>> step 2 and 3 a decent number of time and plot a histogram
>>>>> of
>>>>> >>>>>>>>>>> the number of zero's in the simulation. If the number of
>>>>> zero's
>>>>> >>>>>>>>>>> in the original dataset is larger than those in the
>>>>> >>>>>>>>>>> simulations, then the model can't capture all zero's. In
>>>>> such
>>>>> >>>>>>>>>>> case, first try to update the model and repeat the
>>>>> procedure.
>>>>> >>>>>>>>>>> If that fails, look for zero-inflated models.
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>> Best regards,
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en
>>>>> bosonderzoek /
>>>>> >>>>>>>>>>> Research Institute for Nature and Forest team Biometrie &
>>>>> >>>>>>>>>>> Kwaliteitszorg / team Biometrics & Quality Assurance
>>>>> >>>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>> To call in the statistician after the experiment is done
>>>>> may
>>>>> >>>>>>>>>>> be no more than asking him to perform a post-mortem
>>>>> >>>>>>>>>>> examination: he may be able to say what the experiment
>>>>> died of.
>>>>> >>>>>>>>>>> ~ Sir Ronald Aylmer Fisher The plural of anecdote is not
>>>>> data.
>>>>> >>>>>>>>>>> ~ Roger Brinner The combination of some data and an aching
>>>>> >>>>>>>>>>> desire for an answer does not ensure that a reasonable
>>>>> answer
>>>>> >>>>>>>>>>> can be extracted from a given body of data. ~ John Tukey
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>> 2016-06-23 11:27 GMT+02:00 Philipp Singer <
>>>>> <killver at gmail.com>killver at gmail.com
>>>>> >>>>>>>>>>> <mailto: <killver at gmail.com>killver at gmail.com <mailto:
>>>>> <killver at gmail.com>killver at gmail.com>>>:
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>> Thanks Thierry - That totally makes sense. Is there some
>>>>> way of
>>>>> >>>>>>>>>>> formally checking that, except thinking about the setting
>>>>> and
>>>>> >>>>>>>>>>> underlying processes?
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>> On 23.06.2016 11:04, Thierry Onkelinx wrote:
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>>> Dear Philipp,
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>>> Do you have just lots of zero's, or more zero's than the
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>> Poisson
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>>> distribution can explain? Those are two different things.
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>> The example
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>>> below generates data from a Poisson distribution and has
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>> 99% zero's
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>>> but no zero-inflation. The second example has only 1%
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>> zero's but is
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>>> clearly zero-inflated.
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>>> set.seed(1) n <- 1e8 sim <- rpois(n, lambda = 0.01)
>>>>> mean(sim
>>>>> >>>>>>>>>>>> == 0) hist(sim)
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>>> sim.infl <- rbinom(n, size = 1, prob = 0.99) * rpois(n,
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>> lambda = 1000)
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>>> mean(sim.infl == 0) hist(sim.infl)
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>>> So before looking for zero-inflated models, try to model
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>> the zero's.
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>>> Best regards,
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en
>>>>> bosonderzoek /
>>>>> >>>>>>>>>>>> Research Institute
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>> for Nature
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>>> and Forest team Biometrie & Kwaliteitszorg / team
>>>>> Biometrics
>>>>> >>>>>>>>>>>> & Quality
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>> Assurance
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>>> To call in the statistician after the experiment is done
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>> may be no
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>>> more than asking him to perform a post-mortem examination:
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>> he may be
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>>> able to say what the experiment died of. ~ Sir Ronald
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>> Aylmer Fisher
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>>> The plural of anecdote is not data. ~ Roger Brinner The
>>>>> >>>>>>>>>>>> combination of some data and an aching desire for an
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>> answer does
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>>> not ensure that a reasonable answer can be extracted from
>>>>> a
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>> given body
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>>> of data. ~ John Tukey
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>>> 2016-06-23 10:07 GMT+02:00 Philipp Singer
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>> < <killver at gmail.com>killver at gmail.com <mailto:
>>>>> <killver at gmail.com>killver at gmail.com>
>>>>> >>>>>>>>>>> <mailto: <killver at gmail.com>killver at gmail.com <mailto:
>>>>> <killver at gmail.com>killver at gmail.com>>
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>>> <mailto: <killver at gmail.com>killver at gmail.com <mailto:
>>>>> <killver at gmail.com>killver at gmail.com>
>>>>> >>>>>>>>>>>> <mailto: <killver at gmail.com>killver at gmail.com <mailto:
>>>>> <killver at gmail.com>killver at gmail.com>>>>:
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>>> Dear group - I am currently fitting a Poisson glmer
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>> where I have
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>>> an excess of outcomes that are zero (>95%). I am now
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>> debating on
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>>> how to proceed and came up with three options:
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>>> 1.) Just fit a regular glmer to the complete data. I am
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>> not fully
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>>> sure how interpret the coefficients then, are they more
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>> optimizing
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>>> towards distinguishing zero and non-zero, or also
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>> capturing the
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>>> differences in those outcomes that are non-zero?
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>>> 2.) Leave all zeros out of the data and fit a glmer to
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>> only those
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>>> outcomes that are non-zero. Then, I would only learn about
>>>>> >>>>>>>>>>>> differences in the non-zero outcomes though.
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>>> 3.) Use a zero-inflated Poisson model. My data is quite
>>>>> >>>>>>>>>>>> large-scale, so I am currently playing around with the EM
>>>>> >>>>>>>>>>>> implementation of Bolker et al. that alternates between
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>> fitting a
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>>> glmer with data that are weighted according to their zero
>>>>> >>>>>>>>>>>> probability, and fitting a logistic regression for the
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>> probability
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>>> that a data point is zero. The method is elaborated for
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>> the OWL
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>>> data in:
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>>
>>>>> <https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf>
>>>>> https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
>>>>> >>>>>>>>>>> <
>>>>> >>>>>>>>>>>
>>>>> <https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf>
>>>>> https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
>>>>> >>>>>>>>>>> >
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>> I am not fully sure how to interpret the results for the
>>>>> >>>>>>>
>>>>> >>>>>>>> zero-inflated version though. Would I need to interpret the
>>>>> >>>>>>>>>>>> coefficients for the result of the glmer similar to as
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>> I would do
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>>> for my idea of 2)? And then on top of that interpret the
>>>>> >>>>>>>>>>>> coefficients for the logistic regression regarding whether
>>>>> >>>>>>>>>>>> something is in the perfect or imperfect state? I am
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>> also not
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>>> quite sure what the common approach for the zformula is
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>> here. The
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>>> OWL elaborations only use zformula=z~1, so no random
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>> effect; I
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>>> would use the same formula as for the glmer.
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>>> I am appreciating some help and pointers.
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>>> Thanks! Philipp
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>>> _______________________________________________
>>>>> >>>>>>>>>>>> <R-sig-mixed-models at r-project.org>
>>>>> R-sig-mixed-models at r-project.org
>>>>> >>>>>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>> R-sig-mixed-models at r-project.org>
>>>>> >>>>>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>> R-sig-mixed-models at r-project.org>
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>> R-sig-mixed-models at r-project.org
>>>>> >>>>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>> R-sig-mixed-models at r-project.org>>
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>> R-sig-mixed-models at r-project.org
>>>>> >>>>>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>> R-sig-mixed-models at r-project.org>
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>> R-sig-mixed-models at r-project.org
>>>>> >>>>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>> R-sig-mixed-models at r-project.org>>> mailing list
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>>>
>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>> >>>>>>>>>>>> <
>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>>>
>>>>> >>>>>>>>>>>> [[alternative HTML version deleted]]
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>> _______________________________________________
>>>>> >>>>>>>>>>> <R-sig-mixed-models at r-project.org>
>>>>> R-sig-mixed-models at r-project.org
>>>>> >>>>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>> R-sig-mixed-models at r-project.org>
>>>>> >>>>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>> R-sig-mixed-models at r-project.org>
>>>>> >>>>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>> R-sig-mixed-models at r-project.org
>>>>> >>>>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>> R-sig-mixed-models at r-project.org>> mailing list
>>>>> >>>>>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>> >>>>>>>>>>> <
>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>>
>>>>> >>>>>>>>>>> [[alternative HTML version deleted]]
>>>>> >>>>>>>>>
>>>>> >>>>>>>>> _______________________________________________
>>>>> >>>>>>>>> <R-sig-mixed-models at r-project.org>
>>>>> R-sig-mixed-models at r-project.org
>>>>> >>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>> R-sig-mixed-models at r-project.org>
>>>>> >>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>> R-sig-mixed-models at r-project.org> mailing list
>>>>> >>>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>> >>>>>>>>> < <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>> >>>>>>>>>
>>>>> >>>>>>>> [[alternative HTML version deleted]]
>>>>> >>>>>>>>
>>>>> >>>>>>>> _______________________________________________
>>>>> >>>>>>>> <R-sig-mixed-models at r-project.org>
>>>>> R-sig-mixed-models at r-project.org
>>>>> >>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>> R-sig-mixed-models at r-project.org> mailing list
>>>>> >>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>> >>>>>>>>
>>>>> >>>>>>>> _______________________________________________
>>>>> >>>>>>> <R-sig-mixed-models at r-project.org>
>>>>> R-sig-mixed-models at r-project.org
>>>>> >>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>> R-sig-mixed-models at r-project.org> mailing list
>>>>> >>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>> >>>>>>>
>>>>> >>>>>> _______________________________________________
>>>>> >>>>>> <R-sig-mixed-models at r-project.org>
>>>>> R-sig-mixed-models at r-project.org
>>>>> >>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>> R-sig-mixed-models at r-project.org> mailing list
>>>>> >>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>> >>>>>>
>>>>> >>>>>
>>>>> >>>         [[alternative HTML version deleted]]
>>>>> >>>
>>>>> >>> _______________________________________________
>>>>> >>> <R-sig-mixed-models at r-project.org>R-sig-mixed-models at r-project.org
>>>>> mailing list
>>>>> >>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>> >>>
>>>>> >>>
>>>>> >
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> <R-sig-mixed-models at r-project.org>R-sig-mixed-models at r-project.org
>>>>> mailing list
>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>
>>>>
>>>
>>
>
>

	[[alternative HTML version deleted]]


From killver at gmail.com  Mon Jun 27 22:03:23 2016
From: killver at gmail.com (Philipp Singer)
Date: Mon, 27 Jun 2016 22:03:23 +0200
Subject: [R-sig-ME] Question about zero-inflated Poisson glmer
In-Reply-To: <CAJuCY5yOWstEGO9wiQvrc48bFGtuz0Cfp4tzVQ67+py3rmBk0A@mail.gmail.com>
References: <576B98C4.6000602@gmail.com> <576BAB84.6080009@gmail.com>
	<CAJuCY5zmK1xCyWOwcCH+Hch_LSdB+AazmUDuPVP6je7ABFU5FA@mail.gmail.com>
	<576BBCFD.8040806@gmail.com>
	<CAJuCY5ycRL6oXs=H5JrEqOHWzd1UsvSNVZM6-MK+V2N=pvbyQA@mail.gmail.com>
	<576BFEBC.3020407@gmail.com>
	<B5AEF3F5-949F-4686-82DA-C234C3C4018B@ufl.edu>
	<576C18F9.9010200@gmail.com> <576C200A.1050405@gmail.com>
	<4D07695C-8CEA-4785-A5B0-46B011625DA0@ufl.edu>
	<576D290A.7090102@gmail.com>
	<576D3209.6050507@gmail.com> <576D3864.1060001@gmail.com>
	<576D3B1B.3050908@gmail.com>
	<CAGPhqeohy3hB8hfnNcj=6d_D=mRVG9CWk910qfSEsEnnr0N__A@mail.gmail.com>
	<CAJuCY5wcBboPCe58h2kYPL1+tXwe=5dmVT10n6wFCJSE+7-wnw@mail.gmail.com>
	<CAGPhqeojDg=tXJi+oYMqAqGwCaVxkkhnhV3MBr2e9O2agEeJUA@mail.gmail.com>
	<CAGPhqeok+j2mCtfSBYveSbU1iCzvZjTefeEE8f=uyyH33ctS=w@mail.gmail.com>
	<CAJuCY5xDPr0rBa-cCCT7+_QOefO8UT8AreP_8hMh6siuM6noBA@mail.gmail.com>
	<57714A59.4060806@gmail.com>
	<CAJuCY5yOWstEGO9wiQvrc48bFGtuz0Cfp4tzVQ67+py3rmBk0A@mail.gmail.com>
Message-ID: <5771868B.5000008@gmail.com>

NBinom was not really successfull unitl now, but will try to tune. 
Thanks for your help!

One point I forgot to mention was that apart from my excess of zeros, 
the lowest data outcome is 10, so there is a gap between zeri and 10. 
Could that be somehow a problem?

On 27.06.2016 21:59, Thierry Onkelinx wrote:
> If there is overdispersion, then try a negative binomial model or a 
> zero-inflated negative binomial model. If not try a zero-inflated 
> Poisson. Adding relevant covariates can reduce overdispersion.
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature 
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no 
> more than asking him to perform a post-mortem examination: he may be 
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does 
> not ensure that a reasonable answer can be extracted from a given body 
> of data. ~ John Tukey
>
> 2016-06-27 17:46 GMT+02:00 Philipp Singer <killver at gmail.com 
> <mailto:killver at gmail.com>>:
>
>     Well, as posted beforehand the std dev is 9.5 ... so does not seem
>     too good then :/
>
>     Any other idea?
>
>
>     On 27.06.2016 17:31, Thierry Onkelinx wrote:
>>     Dear Philipp,
>>
>>     You've been bitten by observation level random effects. I've put
>>     together a document about it on http://rpubs.com/INBOstats/OLRE.
>>     Bottomline you're OKish when the standard devation of the OLRE
>>     smaller than 1. You're in trouble when it's above 3. In between
>>     you need to check the model carefully.
>>
>>     Best regards,
>>
>>     ir. Thierry Onkelinx
>>     Instituut voor natuur- en bosonderzoek / Research Institute for
>>     Nature and Forest
>>     team Biometrie & Kwaliteitszorg / team Biometrics & Quality
>>     Assurance
>>     Kliniekstraat 25
>>     1070 Anderlecht
>>     Belgium
>>
>>     To call in the statistician after the experiment is done may be
>>     no more than asking him to perform a post-mortem examination: he
>>     may be able to say what the experiment died of. ~ Sir Ronald
>>     Aylmer Fisher
>>     The plural of anecdote is not data. ~ Roger Brinner
>>     The combination of some data and an aching desire for an answer
>>     does not ensure that a reasonable answer can be extracted from a
>>     given body of data. ~ John Tukey
>>
>>     2016-06-27 16:17 GMT+02:00 Philipp Singer <killver at gmail.com
>>     <mailto:killver at gmail.com>>:
>>
>>         Here is the fitted vs. residual plot for the
>>         observation-level poisson model where the observation level
>>         has been removed as taken from:
>>         https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q3/020817.html
>>
>>         So basically the prediction is always close to zero.
>>
>>         Note that this is just on a very small sample (1000 data points).
>>
>>         If I fit a nbinom2 to this smalle sample, I get predictions
>>         that are always around ~20 (but never zero). Both plots are
>>         attached.
>>
>>         What I am wondering is whether I can do inference on a fixed
>>         parameter in my model which is my main task of this study.
>>         The effect is similar in the different models and in general
>>         I am only itnerested in whether it is positive/negative and
>>         "significant" which it is. However, as can be seen, the
>>         prediction looks not too good here.
>>
>>
>>
>>
>>         2016-06-27 15:18 GMT+02:00 Philipp Singer <killver at gmail.com
>>         <mailto:killver at gmail.com>>:
>>
>>             The variance is:
>>
>>             Conditional model:
>>               Groups            Name        Variance  Std.Dev.
>>               obs               (Intercept) 8.991e+01 9.4823139
>>
>>
>>
>>             2016-06-27 15:06 GMT+02:00 Thierry Onkelinx
>>             <thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>>:
>>
>>                 Dear Philipp,
>>
>>                 How strong is the variance of the observation level
>>                 random effect? I would trust a model with large OLRE
>>                 variance.
>>
>>                 Best regards,
>>
>>                 Thierry
>>
>>                 ir. Thierry Onkelinx
>>                 Instituut voor natuur- en bosonderzoek / Research
>>                 Institute for Nature and Forest
>>                 team Biometrie & Kwaliteitszorg / team Biometrics &
>>                 Quality Assurance
>>                 Kliniekstraat 25
>>                 1070 Anderlecht
>>                 Belgium
>>
>>                 To call in the statistician after the experiment is
>>                 done may be no more than asking him to perform a
>>                 post-mortem examination: he may be able to say what
>>                 the experiment died of. ~ Sir Ronald Aylmer Fisher
>>                 The plural of anecdote is not data. ~ Roger Brinner
>>                 The combination of some data and an aching desire for
>>                 an answer does not ensure that a reasonable answer
>>                 can be extracted from a given body of data. ~ John Tukey
>>
>>                 2016-06-27 14:59 GMT+02:00 Philipp Singer
>>                 <killver at gmail.com <mailto:killver at gmail.com>>:
>>
>>                     I have now played around more with the data an
>>                     the models both using lme4
>>                     and glmmTMB.
>>
>>                     I can report the following:
>>
>>                     Modeling the data with a zero-inflated Poisson
>>                     improves the model
>>                     significantly. However, when calling predict and
>>                     simulating rpoissons, I
>>                     end up with nearly no values that are zero (in
>>                     the original data there are
>>                     96% zero).
>>
>>                     When I model the data with overdisperion by
>>                     including an observation-level
>>                     random effect, I can also improve the model (not
>>                     surprisingly due to the
>>                     random effect). When I predict outcomes by
>>                     ignoring the observation-level
>>                     random effect (in lme4), I receive bad prediction
>>                     if I compare it to the
>>                     original data. While many zeros can be captured
>>                     (of course), the positive
>>                     outcomes can not be captured well.
>>
>>                     Combining zero inflation and overdispersion
>>                     further improves the model, but
>>                     I can only do that with glmmTMB and then have
>>                     troubles doing predictions
>>                     ignoring the observation-level random effect.
>>
>>                     Another side question:
>>
>>                     In lme4, when I do:
>>
>>                     m = glm(x~1,family="poisson")
>>                     rpois(n=len(data),lambda=predict(m,
>>                     type='response',re.form=NA)
>>
>>                     vs.
>>
>>                     simulate(1,m,re.form=NA)
>>
>>                     I receive different outcomes? Do I understand
>>                     these function wrongly?
>>
>>                     Would appreciate some more help/pointers!
>>
>>                     Thanks,
>>                     Philipp
>>
>>                     2016-06-24 15:52 GMT+02:00 Philipp Singer
>>                     <killver at gmail.com <mailto:killver at gmail.com>>:
>>
>>                     > Thanks - I started an issue there to answer
>>                     some of my questions.
>>                     >
>>                     > Regarding the installation: I was trying to
>>                     somehow do it in anaconda with
>>                     > a specific R kernel and had some issues. I am
>>                     trying to resort that with
>>                     > the anaconda guys though, if I have a tutorial
>>                     on how to properly setup
>>                     > glmmTMB in anaconda, I will let you know. The
>>                     install worked fine in my
>>                     > standard R environment.
>>                     >
>>                     >
>>                     > On 24.06.2016 15 <tel:24.06.2016%2015>:40, Ben
>>                     Bolker wrote:
>>                     >
>>                     >>  Probably for now the glmmTMB issues page is best.
>>                     >>
>>                     >>  When you go there:
>>                     >>
>>                     >>    - details on installation problems/hiccups
>>                     would be useful
>>                     >>    - a reproducible example for the problem
>>                     listed below would be useful
>>                     >>    - dispformula is for allowing
>>                     dispersion/residual variance to vary
>>                     >> with covariates (i.e., modeling
>>                     heteroscedasticity)
>>                     >>
>>                     >> cheers
>>                     >> Ben Bolker
>>                     >>
>>                     >>
>>                     >> On 16-06-24 09:13 AM, Philipp Singer wrote:
>>                     >>
>>                     >>> Update, I tried it like that, but receive an
>>                     error message.
>>                     >>>
>>                     >>> Warning message:
>>                     >>> In nlminb(start = par, objective = fn,
>>                     gradient = gr): NA/NaN function
>>                     >>> evaluation
>>                     >>>
>>                     >>> Error in solve.default(hessian.fixed): Lapack
>>                     routine dgesv: system is
>>                     >>> exactly singular: U[3,3] = 0
>>                     >>> Traceback:
>>                     >>>
>>                     >>> 1. glmmTMB(y ~ 1 + x + (1 | b),
>>                     >>>   .     data = data, family = "poisson",
>>                     dispformula = ~1 + x)
>>                     >>> 2. sdreport(obj)
>>                     >>> 3. solve(hessian.fixed)
>>                     >>> 4. solve(hessian.fixed)
>>                     >>> 5. solve.default(hessian.fixed)
>>                     >>>
>>                     >>> Any ideas on that?
>>                     >>>
>>                     >>> BTW: Is it fine to post glmmTMB questions
>>                     here, or should I rather use
>>                     >>> the github issue page, or is there maybe a
>>                     dedicated mailing list?
>>                     >>>
>>                     >>> Thanks,
>>                     >>> Philipp
>>                     >>>
>>                     >>> On 24.06.2016 14:35, Philipp Singer wrote:
>>                     >>>
>>                     >>>> It indeed seems to run quite fast; had some
>>                     trouble installing, but
>>                     >>>> works now on my 3.3 R setup.
>>                     >>>>
>>                     >>>> One question I have is regarding the
>>                     specification of dispersion as I
>>                     >>>> need to specify the dispformula. What is the
>>                     difference here between
>>                     >>>> just specifying fixed effects vs. also the
>>                     random effects?
>>                     >>>>
>>                     >>>> On 23.06.2016 23:07, Mollie Brooks wrote:
>>                     >>>>
>>                     >>>>> glmmTMB does crossed RE. Ben did some
>>                     timings in vignette("glmmTMB")
>>                     >>>>> and it was 2.3 times faster than glmer for
>>                     one simple GLMM.
>>                     >>>>>
>>                     >>>>>
>>                     >>>>> On 23Jun 2016, at 10:44, Philipp Singer
>>                     <killver at gmail.com <mailto:killver at gmail.com>> wrote:
>>                     >>>>>>
>>                     >>>>>> Did try glmmADMB but unfortunately it is
>>                     way too slow for my data.
>>                     >>>>>>
>>                     >>>>>> Did not know about glmmTMB, will try it
>>                     out. Does it work with
>>                     >>>>>> crossed random effects and how does it
>>                     scale with more data? I will
>>                     >>>>>> check the docu and try it though. Thanks
>>                     for the info.
>>                     >>>>>>
>>                     >>>>>> On 23.06.2016 19:14, Ben Bolker wrote:
>>                     >>>>>>
>>                     >>>>>>>   I would also comment that glmmTMB is
>>                     likely to be much faster
>>                     >>>>>>> than the
>>                     >>>>>>> lme4-based EM approach ...
>>                     >>>>>>>
>>                     >>>>>>>   cheers
>>                     >>>>>>>     Ben B.
>>                     >>>>>>>
>>                     >>>>>>> On 16-06-23 12:47 PM, Mollie Brooks wrote:
>>                     >>>>>>>
>>                     >>>>>>>> Hi Philipp,
>>                     >>>>>>>>
>>                     >>>>>>>> You could also try fitting the model
>>                     with and without ZI using
>>                     >>>>>>>> either
>>                     >>>>>>>> glmmADMB or glmmTMB. Then compare the
>>                     AICs. I believe model
>>                     >>>>>>>> selection
>>                     >>>>>>>> is useful for this, but I could be
>>                     missing something since the
>>                     >>>>>>>> simulation procedure that Thierry
>>                     described seems to recommended
>>                     >>>>>>>> more
>>                     >>>>>>>> often.
>>                     >>>>>>>>
>>                     >>>>>>>> https://github.com/glmmTMB/glmmTMB
>>                     >>>>>>>> http://glmmadmb.r-forge.r-project.org
>>                     >>>>>>>>
>>                     >>>>>>>> glmmTMB is still in the development
>>                     phase, but we?ve done a lot of
>>                     >>>>>>>> testing.
>>                     >>>>>>>>
>>                     >>>>>>>> cheers, Mollie
>>                     >>>>>>>>
>>                     >>>>>>>> ------------------------ Mollie Brooks,
>>                     PhD Postdoctoral Researcher,
>>                     >>>>>>>> Population Ecology Research Group
>>                     Department of Evolutionary Biology
>>                     >>>>>>>> & Environmental Studies, University of
>>                     Z?rich
>>                     >>>>>>>> http://www.popecol.org/team/mollie-brooks/
>>                     >>>>>>>>
>>                     >>>>>>>>
>>                     >>>>>>>> On 23Jun 2016, at 8:22, Philipp Singer
>>                     <killver at gmail.com <mailto:killver at gmail.com>> wrote:
>>                     >>>>>>>>>
>>                     >>>>>>>>> Thanks, great information, that is
>>                     really helpful.
>>                     >>>>>>>>>
>>                     >>>>>>>>> I agree that those are different
>>                     things, however when using a
>>                     >>>>>>>>> random effect for overdispersion, I can
>>                     simulate the same number of
>>                     >>>>>>>>> zero outcomes (~95%).
>>                     >>>>>>>>>
>>                     >>>>>>>>> On 23.06.2016 15:50, Thierry Onkelinx
>>                     wrote:
>>                     >>>>>>>>>
>>                     >>>>>>>>>> Be careful when using overdispersion
>>                     to model zero-inflation.
>>                     >>>>>>>>>> Those are two different things.
>>                     >>>>>>>>>>
>>                     >>>>>>>>>> I've put some information together in
>>                     >>>>>>>>>> http://rpubs.com/INBOstats/zeroinflation
>>                     >>>>>>>>>>
>>                     >>>>>>>>>> ir. Thierry Onkelinx Instituut voor
>>                     natuur- en bosonderzoek /
>>                     >>>>>>>>>> Research Institute for Nature and
>>                     Forest team Biometrie &
>>                     >>>>>>>>>> Kwaliteitszorg / team Biometrics &
>>                     Quality Assurance
>>                     >>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>                     >>>>>>>>>>
>>                     >>>>>>>>>> To call in the statistician after the
>>                     experiment is done may be
>>                     >>>>>>>>>> no more than asking him to perform a
>>                     post-mortem examination: he
>>                     >>>>>>>>>> may be able to say what the experiment
>>                     died of. ~ Sir Ronald
>>                     >>>>>>>>>> Aylmer Fisher The plural of anecdote
>>                     is not data. ~ Roger
>>                     >>>>>>>>>> Brinner The combination of some data
>>                     and an aching desire for an
>>                     >>>>>>>>>> answer does not ensure that a
>>                     reasonable answer can be extracted
>>                     >>>>>>>>>> from a given body of data. ~ John Tukey
>>                     >>>>>>>>>>
>>                     >>>>>>>>>> 2016-06-23 12:42 GMT+02:00 Philipp
>>                     Singer <killver at gmail.com <mailto:killver at gmail.com>
>>                     >>>>>>>>>> <mailto:killver at gmail.com
>>                     <mailto:killver at gmail.com>
>>                     <mailto:killver at gmail.com
>>                     <mailto:killver at gmail.com>>>>:
>>                     >>>>>>>>>>
>>                     >>>>>>>>>> Thanks! Actually, accounting for
>>                     overdispersion is super
>>                     >>>>>>>>>> important as it seems, then the zeros
>>                     can be captured well.
>>                     >>>>>>>>>>
>>                     >>>>>>>>>>
>>                     >>>>>>>>>> On 23.06.2016 11:50, Thierry Onkelinx
>>                     wrote:
>>                     >>>>>>>>>>
>>                     >>>>>>>>>>> Dear Philipp,
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>> 1. Fit a Poisson model to the data.
>>                     2. Simulate a new response
>>                     >>>>>>>>>>> vector for the dataset according to
>>                     the model. 3. Count the
>>                     >>>>>>>>>>> number of zero's in the simulated
>>                     response vector. 4. Repeat
>>                     >>>>>>>>>>> step 2 and 3 a decent number of time
>>                     and plot a histogram of
>>                     >>>>>>>>>>> the number of zero's in the
>>                     simulation. If the number of zero's
>>                     >>>>>>>>>>> in the original dataset is larger
>>                     than those in the
>>                     >>>>>>>>>>> simulations, then the model can't
>>                     capture all zero's. In such
>>                     >>>>>>>>>>> case, first try to update the model
>>                     and repeat the procedure.
>>                     >>>>>>>>>>> If that fails, look for zero-inflated
>>                     models.
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>> Best regards,
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>> ir. Thierry Onkelinx Instituut voor
>>                     natuur- en bosonderzoek /
>>                     >>>>>>>>>>> Research Institute for Nature and
>>                     Forest team Biometrie &
>>                     >>>>>>>>>>> Kwaliteitszorg / team Biometrics &
>>                     Quality Assurance
>>                     >>>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>> To call in the statistician after the
>>                     experiment is done may
>>                     >>>>>>>>>>> be no more than asking him to perform
>>                     a post-mortem
>>                     >>>>>>>>>>> examination: he may be able to say
>>                     what the experiment died of.
>>                     >>>>>>>>>>> ~ Sir Ronald Aylmer Fisher The plural
>>                     of anecdote is not data.
>>                     >>>>>>>>>>> ~ Roger Brinner The combination of
>>                     some data and an aching
>>                     >>>>>>>>>>> desire for an answer does not ensure
>>                     that a reasonable answer
>>                     >>>>>>>>>>> can be extracted from a given body of
>>                     data. ~ John Tukey
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>> 2016-06-23 11:27 GMT+02:00 Philipp
>>                     Singer <killver at gmail.com <mailto:killver at gmail.com>
>>                     >>>>>>>>>>> <mailto:killver at gmail.com
>>                     <mailto:killver at gmail.com>
>>                     <mailto:killver at gmail.com
>>                     <mailto:killver at gmail.com>>>>:
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>> Thanks Thierry - That totally makes
>>                     sense. Is there some way of
>>                     >>>>>>>>>>> formally checking that, except
>>                     thinking about the setting and
>>                     >>>>>>>>>>> underlying processes?
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>> On 23.06.2016 11:04, Thierry Onkelinx
>>                     wrote:
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> Dear Philipp,
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>> Do you have just lots of zero's, or
>>                     more zero's than the
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> Poisson
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> distribution can explain? Those are
>>                     two different things.
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> The example
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> below generates data from a Poisson
>>                     distribution and has
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> 99% zero's
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> but no zero-inflation. The second
>>                     example has only 1%
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> zero's but is
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> clearly zero-inflated.
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>> set.seed(1) n <- 1e8 sim <- rpois(n,
>>                     lambda = 0.01) mean(sim
>>                     >>>>>>>>>>>> == 0) hist(sim)
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>> sim.infl <- rbinom(n, size = 1, prob
>>                     = 0.99) * rpois(n,
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> lambda = 1000)
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> mean(sim.infl == 0) hist(sim.infl)
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>> So before looking for zero-inflated
>>                     models, try to model
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> the zero's.
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> Best regards,
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>> ir. Thierry Onkelinx Instituut voor
>>                     natuur- en bosonderzoek /
>>                     >>>>>>>>>>>> Research Institute
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> for Nature
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> and Forest team Biometrie &
>>                     Kwaliteitszorg / team Biometrics
>>                     >>>>>>>>>>>> & Quality
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> Assurance
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>> To call in the statistician after
>>                     the experiment is done
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> may be no
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> more than asking him to perform a
>>                     post-mortem examination:
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> he may be
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> able to say what the experiment died
>>                     of. ~ Sir Ronald
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> Aylmer Fisher
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> The plural of anecdote is not data.
>>                     ~ Roger Brinner The
>>                     >>>>>>>>>>>> combination of some data and an
>>                     aching desire for an
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> answer does
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> not ensure that a reasonable answer
>>                     can be extracted from a
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> given body
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> of data. ~ John Tukey
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>> 2016-06-23 10:07 GMT+02:00 Philipp
>>                     Singer
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> <killver at gmail.com
>>                     <mailto:killver at gmail.com>
>>                     <mailto:killver at gmail.com <mailto:killver at gmail.com>>
>>                     >>>>>>>>>>> <mailto:killver at gmail.com
>>                     <mailto:killver at gmail.com>
>>                     <mailto:killver at gmail.com
>>                     <mailto:killver at gmail.com>>>
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> <mailto:killver at gmail.com
>>                     <mailto:killver at gmail.com>
>>                     <mailto:killver at gmail.com <mailto:killver at gmail.com>>
>>                     >>>>>>>>>>>> <mailto:killver at gmail.com
>>                     <mailto:killver at gmail.com>
>>                     <mailto:killver at gmail.com
>>                     <mailto:killver at gmail.com>>>>>:
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>> Dear group - I am currently fitting
>>                     a Poisson glmer
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> where I have
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> an excess of outcomes that are zero
>>                     (>95%). I am now
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> debating on
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> how to proceed and came up with
>>                     three options:
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>> 1.) Just fit a regular glmer to the
>>                     complete data. I am
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> not fully
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> sure how interpret the coefficients
>>                     then, are they more
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> optimizing
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> towards distinguishing zero and
>>                     non-zero, or also
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> capturing the
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> differences in those outcomes that
>>                     are non-zero?
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>> 2.) Leave all zeros out of the data
>>                     and fit a glmer to
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> only those
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> outcomes that are non-zero. Then, I
>>                     would only learn about
>>                     >>>>>>>>>>>> differences in the non-zero outcomes
>>                     though.
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>> 3.) Use a zero-inflated Poisson
>>                     model. My data is quite
>>                     >>>>>>>>>>>> large-scale, so I am currently
>>                     playing around with the EM
>>                     >>>>>>>>>>>> implementation of Bolker et al. that
>>                     alternates between
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> fitting a
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> glmer with data that are weighted
>>                     according to their zero
>>                     >>>>>>>>>>>> probability, and fitting a logistic
>>                     regression for the
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> probability
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> that a data point is zero. The
>>                     method is elaborated for
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> the OWL
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> data in:
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>
>>                     https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
>>                     >>>>>>>>>>> <
>>                     >>>>>>>>>>>
>>                     https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
>>                     >>>>>>>>>>> >
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>> I am not fully sure how to interpret
>>                     the results for the
>>                     >>>>>>>
>>                     >>>>>>>> zero-inflated version though. Would I
>>                     need to interpret the
>>                     >>>>>>>>>>>> coefficients for the result of the
>>                     glmer similar to as
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> I would do
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> for my idea of 2)? And then on top
>>                     of that interpret the
>>                     >>>>>>>>>>>> coefficients for the logistic
>>                     regression regarding whether
>>                     >>>>>>>>>>>> something is in the perfect or
>>                     imperfect state? I am
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> also not
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> quite sure what the common approach
>>                     for the zformula is
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> here. The
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> OWL elaborations only use
>>                     zformula=z~1, so no random
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> effect; I
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> would use the same formula as for
>>                     the glmer.
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>> I am appreciating some help and
>>                     pointers.
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>> Thanks! Philipp
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>>
>>                     _______________________________________________
>>                     >>>>>>>>>>>> R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>
>>                     >>>>>>>>>>>>
>>                     <mailto:R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>>
>>                     >>>>>>>>>>>>
>>                     <mailto:R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>>
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>
>>                     <mailto:R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>
>>                     >>>>>>>>>>>
>>                     <mailto:R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>>>
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>>
>>                     <mailto:R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>
>>                     >>>>>>>>>>>>
>>                     <mailto:R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>>
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>
>>                     <mailto:R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>
>>                     >>>>>>>>>>>
>>                     <mailto:R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>>>>
>>                     mailing list
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>>
>>                     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>                     >>>>>>>>>>>>
>>                     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>> [[alternative HTML version deleted]]
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>
>>                     _______________________________________________
>>                     >>>>>>>>>>> R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>
>>                     >>>>>>>>>>>
>>                     <mailto:R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>>
>>                     >>>>>>>>>>>
>>                     <mailto:R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>>
>>                     >>>>>>>>>>>
>>                     <mailto:R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>
>>                     >>>>>>>>>>>
>>                     <mailto:R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>>>
>>                     mailing list
>>                     >>>>>>>>>>>
>>                     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>                     >>>>>>>>>>>
>>                     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>> [[alternative HTML version deleted]]
>>                     >>>>>>>>>
>>                     >>>>>>>>>
>>                     _______________________________________________
>>                     >>>>>>>>> R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>
>>                     >>>>>>>>>
>>                     <mailto:R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>>
>>                     >>>>>>>>>
>>                     <mailto:R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>>
>>                     mailing list
>>                     >>>>>>>>>
>>                     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>                     >>>>>>>>>
>>                     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>                     >>>>>>>>>
>>                     >>>>>>>> [[alternative HTML version deleted]]
>>                     >>>>>>>>
>>                     >>>>>>>>
>>                     _______________________________________________
>>                     >>>>>>>> R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>
>>                     >>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>>
>>                     mailing list
>>                     >>>>>>>>
>>                     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>                     >>>>>>>>
>>                     >>>>>>>>
>>                     _______________________________________________
>>                     >>>>>>> R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>
>>                     >>>>>>> <mailto:R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>>
>>                     mailing list
>>                     >>>>>>>
>>                     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>                     >>>>>>>
>>                     >>>>>>
>>                     _______________________________________________
>>                     >>>>>> R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>
>>                     >>>>>> <mailto:R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>>
>>                     mailing list
>>                     >>>>>>
>>                     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>                     >>>>>>
>>                     >>>>>
>>                     >>>  [[alternative HTML version deleted]]
>>                     >>>
>>                     >>> _______________________________________________
>>                     >>> R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org> mailing
>>                     list
>>                     >>>
>>                     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>                     >>>
>>                     >>>
>>                     >
>>
>>                     [[alternative HTML version deleted]]
>>
>>                     _______________________________________________
>>                     R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org> mailing
>>                     list
>>                     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>>
>>
>
>


	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Jun 27 22:17:58 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 27 Jun 2016 22:17:58 +0200
Subject: [R-sig-ME] Question about zero-inflated Poisson glmer
In-Reply-To: <5771868B.5000008@gmail.com>
References: <576B98C4.6000602@gmail.com> <576BAB84.6080009@gmail.com>
	<CAJuCY5zmK1xCyWOwcCH+Hch_LSdB+AazmUDuPVP6je7ABFU5FA@mail.gmail.com>
	<576BBCFD.8040806@gmail.com>
	<CAJuCY5ycRL6oXs=H5JrEqOHWzd1UsvSNVZM6-MK+V2N=pvbyQA@mail.gmail.com>
	<576BFEBC.3020407@gmail.com>
	<B5AEF3F5-949F-4686-82DA-C234C3C4018B@ufl.edu>
	<576C18F9.9010200@gmail.com> <576C200A.1050405@gmail.com>
	<4D07695C-8CEA-4785-A5B0-46B011625DA0@ufl.edu>
	<576D290A.7090102@gmail.com> <576D3209.6050507@gmail.com>
	<576D3864.1060001@gmail.com> <576D3B1B.3050908@gmail.com>
	<CAGPhqeohy3hB8hfnNcj=6d_D=mRVG9CWk910qfSEsEnnr0N__A@mail.gmail.com>
	<CAJuCY5wcBboPCe58h2kYPL1+tXwe=5dmVT10n6wFCJSE+7-wnw@mail.gmail.com>
	<CAGPhqeojDg=tXJi+oYMqAqGwCaVxkkhnhV3MBr2e9O2agEeJUA@mail.gmail.com>
	<CAGPhqeok+j2mCtfSBYveSbU1iCzvZjTefeEE8f=uyyH33ctS=w@mail.gmail.com>
	<CAJuCY5xDPr0rBa-cCCT7+_QOefO8UT8AreP_8hMh6siuM6noBA@mail.gmail.com>
	<57714A59.4060806@gmail.com>
	<CAJuCY5yOWstEGO9wiQvrc48bFGtuz0Cfp4tzVQ67+py3rmBk0A@mail.gmail.com>
	<5771868B.5000008@gmail.com>
Message-ID: <CAJuCY5ze2Z2zMXAsYH1WDeL=DVSMywPixrKGZE9bTzcg6ky2wQ@mail.gmail.com>

A gap between zero and the lowest non-zero count is normal for
zero-inflated data when the Poisson part has a high mean. In that case very
few (if any) zero's stem from the Poisson part.

Another option is to try a hurdle model. Or approximate a hurdle model by
fitting two separate models: a logistic regression (zero or not) and a
Poisson regression (count > 0). In case Prob(Poisson(mu) == 0) is small
then the approximation should be OK.

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-06-27 22:03 GMT+02:00 Philipp Singer <killver at gmail.com>:

> NBinom was not really successfull unitl now, but will try to tune. Thanks
> for your help!
>
> One point I forgot to mention was that apart from my excess of zeros, the
> lowest data outcome is 10, so there is a gap between zeri and 10. Could
> that be somehow a problem?
>
> On 27.06.2016 21:59, Thierry Onkelinx wrote:
>
> If there is overdispersion, then try a negative binomial model or a
> zero-inflated negative binomial model. If not try a zero-inflated Poisson.
> Adding relevant covariates can reduce overdispersion.
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2016-06-27 17:46 GMT+02:00 Philipp Singer <killver at gmail.com>:
>
>> Well, as posted beforehand the std dev is 9.5 ... so does not seem too
>> good then :/
>>
>> Any other idea?
>>
>>
>> On 27.06.2016 17:31, Thierry Onkelinx wrote:
>>
>> Dear Philipp,
>>
>> You've been bitten by observation level random effects. I've put together
>> a document about it on http://rpubs.com/INBOstats/OLRE. Bottomline
>> you're OKish when the standard devation of the OLRE smaller than 1. You're
>> in trouble when it's above 3. In between you need to check the model
>> carefully.
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2016-06-27 16:17 GMT+02:00 Philipp Singer < <killver at gmail.com>
>> killver at gmail.com>:
>>
>>> Here is the fitted vs. residual plot for the observation-level poisson
>>> model where the observation level has been removed as taken from:
>>> <https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q3/020817.html>
>>> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q3/020817.html
>>>
>>> So basically the prediction is always close to zero.
>>>
>>> Note that this is just on a very small sample (1000 data points).
>>>
>>> If I fit a nbinom2 to this smalle sample, I get predictions that are
>>> always around ~20 (but never zero). Both plots are attached.
>>>
>>> What I am wondering is whether I can do inference on a fixed parameter
>>> in my model which is my main task of this study. The effect is similar in
>>> the different models and in general I am only itnerested in whether it is
>>> positive/negative and "significant" which it is. However, as can be seen,
>>> the prediction looks not too good here.
>>>
>>>
>>>
>>>
>>> 2016-06-27 15:18 GMT+02:00 Philipp Singer < <killver at gmail.com>
>>> killver at gmail.com>:
>>>
>>>> The variance is:
>>>>
>>>> Conditional model:
>>>>  Groups            Name        Variance  Std.Dev.
>>>>  obs               (Intercept) 8.991e+01 9.4823139
>>>>
>>>>
>>>>
>>>> 2016-06-27 15:06 GMT+02:00 Thierry Onkelinx <
>>>> <thierry.onkelinx at inbo.be>thierry.onkelinx at inbo.be>:
>>>>
>>>>> Dear Philipp,
>>>>>
>>>>> How strong is the variance of the observation level random effect? I
>>>>> would trust a model with large OLRE variance.
>>>>>
>>>>> Best regards,
>>>>>
>>>>> Thierry
>>>>>
>>>>> ir. Thierry Onkelinx
>>>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>>>> and Forest
>>>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>>>> Kliniekstraat 25
>>>>> 1070 Anderlecht
>>>>> Belgium
>>>>>
>>>>> To call in the statistician after the experiment is done may be no
>>>>> more than asking him to perform a post-mortem examination: he may be able
>>>>> to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>>> The combination of some data and an aching desire for an answer does
>>>>> not ensure that a reasonable answer can be extracted from a given body of
>>>>> data. ~ John Tukey
>>>>>
>>>>> 2016-06-27 14:59 GMT+02:00 Philipp Singer < <killver at gmail.com>
>>>>> killver at gmail.com>:
>>>>>
>>>>>> I have now played around more with the data an the models both using
>>>>>> lme4
>>>>>> and glmmTMB.
>>>>>>
>>>>>> I can report the following:
>>>>>>
>>>>>> Modeling the data with a zero-inflated Poisson improves the model
>>>>>> significantly. However, when calling predict and simulating
>>>>>> rpoissons, I
>>>>>> end up with nearly no values that are zero (in the original data
>>>>>> there are
>>>>>> 96% zero).
>>>>>>
>>>>>> When I model the data with overdisperion by including an
>>>>>> observation-level
>>>>>> random effect, I can also improve the model (not surprisingly due to
>>>>>> the
>>>>>> random effect). When I predict outcomes by ignoring the
>>>>>> observation-level
>>>>>> random effect (in lme4), I receive bad prediction if I compare it to
>>>>>> the
>>>>>> original data. While many zeros can be captured (of course), the
>>>>>> positive
>>>>>> outcomes can not be captured well.
>>>>>>
>>>>>> Combining zero inflation and overdispersion further improves the
>>>>>> model, but
>>>>>> I can only do that with glmmTMB and then have troubles doing
>>>>>> predictions
>>>>>> ignoring the observation-level random effect.
>>>>>>
>>>>>> Another side question:
>>>>>>
>>>>>> In lme4, when I do:
>>>>>>
>>>>>> m = glm(x~1,family="poisson")
>>>>>> rpois(n=len(data),lambda=predict(m, type='response',re.form=NA)
>>>>>>
>>>>>> vs.
>>>>>>
>>>>>> simulate(1,m,re.form=NA)
>>>>>>
>>>>>> I receive different outcomes? Do I understand these function wrongly?
>>>>>>
>>>>>> Would appreciate some more help/pointers!
>>>>>>
>>>>>> Thanks,
>>>>>> Philipp
>>>>>>
>>>>>> 2016-06-24 15:52 GMT+02:00 Philipp Singer < <killver at gmail.com>
>>>>>> killver at gmail.com>:
>>>>>>
>>>>>> > Thanks - I started an issue there to answer some of my questions.
>>>>>> >
>>>>>> > Regarding the installation: I was trying to somehow do it in
>>>>>> anaconda with
>>>>>> > a specific R kernel and had some issues. I am trying to resort that
>>>>>> with
>>>>>> > the anaconda guys though, if I have a tutorial on how to properly
>>>>>> setup
>>>>>> > glmmTMB in anaconda, I will let you know. The install worked fine
>>>>>> in my
>>>>>> > standard R environment.
>>>>>> >
>>>>>> >
>>>>>> > On 24.06.2016 15 <24.06.2016%2015>:40, Ben Bolker wrote:
>>>>>> >
>>>>>> >>   Probably for now the glmmTMB issues page is best.
>>>>>> >>
>>>>>> >>   When you go there:
>>>>>> >>
>>>>>> >>    - details on installation problems/hiccups would be useful
>>>>>> >>    - a reproducible example for the problem listed below would be
>>>>>> useful
>>>>>> >>    - dispformula is for allowing dispersion/residual variance to
>>>>>> vary
>>>>>> >> with covariates (i.e., modeling heteroscedasticity)
>>>>>> >>
>>>>>> >>    cheers
>>>>>> >>      Ben Bolker
>>>>>> >>
>>>>>> >>
>>>>>> >> On 16-06-24 09:13 AM, Philipp Singer wrote:
>>>>>> >>
>>>>>> >>> Update, I tried it like that, but receive an error message.
>>>>>> >>>
>>>>>> >>> Warning message:
>>>>>> >>> In nlminb(start = par, objective = fn, gradient = gr): NA/NaN
>>>>>> function
>>>>>> >>> evaluation
>>>>>> >>>
>>>>>> >>> Error in solve.default(hessian.fixed): Lapack routine dgesv:
>>>>>> system is
>>>>>> >>> exactly singular: U[3,3] = 0
>>>>>> >>> Traceback:
>>>>>> >>>
>>>>>> >>> 1. glmmTMB(y ~ 1 + x + (1 | b),
>>>>>> >>>    .     data = data, family = "poisson", dispformula = ~1 + x)
>>>>>> >>> 2. sdreport(obj)
>>>>>> >>> 3. solve(hessian.fixed)
>>>>>> >>> 4. solve(hessian.fixed)
>>>>>> >>> 5. solve.default(hessian.fixed)
>>>>>> >>>
>>>>>> >>> Any ideas on that?
>>>>>> >>>
>>>>>> >>> BTW: Is it fine to post glmmTMB questions here, or should I
>>>>>> rather use
>>>>>> >>> the github issue page, or is there maybe a dedicated mailing list?
>>>>>> >>>
>>>>>> >>> Thanks,
>>>>>> >>> Philipp
>>>>>> >>>
>>>>>> >>> On 24.06.2016 14:35, Philipp Singer wrote:
>>>>>> >>>
>>>>>> >>>> It indeed seems to run quite fast; had some trouble installing,
>>>>>> but
>>>>>> >>>> works now on my 3.3 R setup.
>>>>>> >>>>
>>>>>> >>>> One question I have is regarding the specification of dispersion
>>>>>> as I
>>>>>> >>>> need to specify the dispformula. What is the difference here
>>>>>> between
>>>>>> >>>> just specifying fixed effects vs. also the random effects?
>>>>>> >>>>
>>>>>> >>>> On 23.06.2016 23:07, Mollie Brooks wrote:
>>>>>> >>>>
>>>>>> >>>>> glmmTMB does crossed RE. Ben did some timings in
>>>>>> vignette("glmmTMB")
>>>>>> >>>>> and it was 2.3 times faster than glmer for one simple GLMM.
>>>>>> >>>>>
>>>>>> >>>>>
>>>>>> >>>>> On 23Jun 2016, at 10:44, Philipp Singer < <killver at gmail.com>
>>>>>> killver at gmail.com> wrote:
>>>>>> >>>>>>
>>>>>> >>>>>> Did try glmmADMB but unfortunately it is way too slow for my
>>>>>> data.
>>>>>> >>>>>>
>>>>>> >>>>>> Did not know about glmmTMB, will try it out. Does it work with
>>>>>> >>>>>> crossed random effects and how does it scale with more data? I
>>>>>> will
>>>>>> >>>>>> check the docu and try it though. Thanks for the info.
>>>>>> >>>>>>
>>>>>> >>>>>> On 23.06.2016 19:14, Ben Bolker wrote:
>>>>>> >>>>>>
>>>>>> >>>>>>>    I would also comment that glmmTMB is likely to be much
>>>>>> faster
>>>>>> >>>>>>> than the
>>>>>> >>>>>>> lme4-based EM approach ...
>>>>>> >>>>>>>
>>>>>> >>>>>>>    cheers
>>>>>> >>>>>>>      Ben B.
>>>>>> >>>>>>>
>>>>>> >>>>>>> On 16-06-23 12:47 PM, Mollie Brooks wrote:
>>>>>> >>>>>>>
>>>>>> >>>>>>>> Hi Philipp,
>>>>>> >>>>>>>>
>>>>>> >>>>>>>> You could also try fitting the model with and without ZI
>>>>>> using
>>>>>> >>>>>>>> either
>>>>>> >>>>>>>> glmmADMB or glmmTMB. Then compare the AICs. I believe model
>>>>>> >>>>>>>> selection
>>>>>> >>>>>>>> is useful for this, but I could be missing something since
>>>>>> the
>>>>>> >>>>>>>> simulation procedure that Thierry described seems to
>>>>>> recommended
>>>>>> >>>>>>>> more
>>>>>> >>>>>>>> often.
>>>>>> >>>>>>>>
>>>>>> >>>>>>>> <https://github.com/glmmTMB/glmmTMB>
>>>>>> https://github.com/glmmTMB/glmmTMB
>>>>>> >>>>>>>> <http://glmmadmb.r-forge.r-project.org>
>>>>>> http://glmmadmb.r-forge.r-project.org
>>>>>> >>>>>>>>
>>>>>> >>>>>>>> glmmTMB is still in the development phase, but we?ve done a
>>>>>> lot of
>>>>>> >>>>>>>> testing.
>>>>>> >>>>>>>>
>>>>>> >>>>>>>> cheers, Mollie
>>>>>> >>>>>>>>
>>>>>> >>>>>>>> ------------------------ Mollie Brooks, PhD Postdoctoral
>>>>>> Researcher,
>>>>>> >>>>>>>> Population Ecology Research Group Department of Evolutionary
>>>>>> Biology
>>>>>> >>>>>>>> & Environmental Studies, University of Z?rich
>>>>>> >>>>>>>> <http://www.popecol.org/team/mollie-brooks/>
>>>>>> http://www.popecol.org/team/mollie-brooks/
>>>>>> >>>>>>>>
>>>>>> >>>>>>>>
>>>>>> >>>>>>>> On 23Jun 2016, at 8:22, Philipp Singer < <killver at gmail.com>
>>>>>> killver at gmail.com> wrote:
>>>>>> >>>>>>>>>
>>>>>> >>>>>>>>> Thanks, great information, that is really helpful.
>>>>>> >>>>>>>>>
>>>>>> >>>>>>>>> I agree that those are different things, however when using
>>>>>> a
>>>>>> >>>>>>>>> random effect for overdispersion, I can simulate the same
>>>>>> number of
>>>>>> >>>>>>>>> zero outcomes (~95%).
>>>>>> >>>>>>>>>
>>>>>> >>>>>>>>> On 23.06.2016 15:50, Thierry Onkelinx wrote:
>>>>>> >>>>>>>>>
>>>>>> >>>>>>>>>> Be careful when using overdispersion to model
>>>>>> zero-inflation.
>>>>>> >>>>>>>>>> Those are two different things.
>>>>>> >>>>>>>>>>
>>>>>> >>>>>>>>>> I've put some information together in
>>>>>> >>>>>>>>>> <http://rpubs.com/INBOstats/zeroinflation>
>>>>>> http://rpubs.com/INBOstats/zeroinflation
>>>>>> >>>>>>>>>>
>>>>>> >>>>>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en
>>>>>> bosonderzoek /
>>>>>> >>>>>>>>>> Research Institute for Nature and Forest team Biometrie &
>>>>>> >>>>>>>>>> Kwaliteitszorg / team Biometrics & Quality Assurance
>>>>>> >>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>>>>> >>>>>>>>>>
>>>>>> >>>>>>>>>> To call in the statistician after the experiment is done
>>>>>> may be
>>>>>> >>>>>>>>>> no more than asking him to perform a post-mortem
>>>>>> examination: he
>>>>>> >>>>>>>>>> may be able to say what the experiment died of. ~ Sir
>>>>>> Ronald
>>>>>> >>>>>>>>>> Aylmer Fisher The plural of anecdote is not data. ~ Roger
>>>>>> >>>>>>>>>> Brinner The combination of some data and an aching desire
>>>>>> for an
>>>>>> >>>>>>>>>> answer does not ensure that a reasonable answer can be
>>>>>> extracted
>>>>>> >>>>>>>>>> from a given body of data. ~ John Tukey
>>>>>> >>>>>>>>>>
>>>>>> >>>>>>>>>> 2016-06-23 12:42 GMT+02:00 Philipp Singer <
>>>>>> <killver at gmail.com>killver at gmail.com
>>>>>> >>>>>>>>>> <mailto: <killver at gmail.com>killver at gmail.com <mailto:
>>>>>> <killver at gmail.com>killver at gmail.com>>>:
>>>>>> >>>>>>>>>>
>>>>>> >>>>>>>>>> Thanks! Actually, accounting for overdispersion is super
>>>>>> >>>>>>>>>> important as it seems, then the zeros can be captured well.
>>>>>> >>>>>>>>>>
>>>>>> >>>>>>>>>>
>>>>>> >>>>>>>>>> On 23.06.2016 11:50, Thierry Onkelinx wrote:
>>>>>> >>>>>>>>>>
>>>>>> >>>>>>>>>>> Dear Philipp,
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>> 1. Fit a Poisson model to the data. 2. Simulate a new
>>>>>> response
>>>>>> >>>>>>>>>>> vector for the dataset according to the model. 3. Count
>>>>>> the
>>>>>> >>>>>>>>>>> number of zero's in the simulated response vector. 4.
>>>>>> Repeat
>>>>>> >>>>>>>>>>> step 2 and 3 a decent number of time and plot a histogram
>>>>>> of
>>>>>> >>>>>>>>>>> the number of zero's in the simulation. If the number of
>>>>>> zero's
>>>>>> >>>>>>>>>>> in the original dataset is larger than those in the
>>>>>> >>>>>>>>>>> simulations, then the model can't capture all zero's. In
>>>>>> such
>>>>>> >>>>>>>>>>> case, first try to update the model and repeat the
>>>>>> procedure.
>>>>>> >>>>>>>>>>> If that fails, look for zero-inflated models.
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>> Best regards,
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en
>>>>>> bosonderzoek /
>>>>>> >>>>>>>>>>> Research Institute for Nature and Forest team Biometrie &
>>>>>> >>>>>>>>>>> Kwaliteitszorg / team Biometrics & Quality Assurance
>>>>>> >>>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>> To call in the statistician after the experiment is done
>>>>>> may
>>>>>> >>>>>>>>>>> be no more than asking him to perform a post-mortem
>>>>>> >>>>>>>>>>> examination: he may be able to say what the experiment
>>>>>> died of.
>>>>>> >>>>>>>>>>> ~ Sir Ronald Aylmer Fisher The plural of anecdote is not
>>>>>> data.
>>>>>> >>>>>>>>>>> ~ Roger Brinner The combination of some data and an aching
>>>>>> >>>>>>>>>>> desire for an answer does not ensure that a reasonable
>>>>>> answer
>>>>>> >>>>>>>>>>> can be extracted from a given body of data. ~ John Tukey
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>> 2016-06-23 11:27 GMT+02:00 Philipp Singer <
>>>>>> <killver at gmail.com>killver at gmail.com
>>>>>> >>>>>>>>>>> <mailto: <killver at gmail.com>killver at gmail.com <mailto:
>>>>>> <killver at gmail.com>killver at gmail.com>>>:
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>> Thanks Thierry - That totally makes sense. Is there some
>>>>>> way of
>>>>>> >>>>>>>>>>> formally checking that, except thinking about the setting
>>>>>> and
>>>>>> >>>>>>>>>>> underlying processes?
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>> On 23.06.2016 11:04, Thierry Onkelinx wrote:
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> Dear Philipp,
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>>> Do you have just lots of zero's, or more zero's than the
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> Poisson
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> distribution can explain? Those are two different things.
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> The example
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> below generates data from a Poisson distribution and has
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> 99% zero's
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> but no zero-inflation. The second example has only 1%
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> zero's but is
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> clearly zero-inflated.
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>>> set.seed(1) n <- 1e8 sim <- rpois(n, lambda = 0.01)
>>>>>> mean(sim
>>>>>> >>>>>>>>>>>> == 0) hist(sim)
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>>> sim.infl <- rbinom(n, size = 1, prob = 0.99) * rpois(n,
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> lambda = 1000)
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> mean(sim.infl == 0) hist(sim.infl)
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>>> So before looking for zero-inflated models, try to model
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> the zero's.
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> Best regards,
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en
>>>>>> bosonderzoek /
>>>>>> >>>>>>>>>>>> Research Institute
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> for Nature
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> and Forest team Biometrie & Kwaliteitszorg / team
>>>>>> Biometrics
>>>>>> >>>>>>>>>>>> & Quality
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> Assurance
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>>> To call in the statistician after the experiment is done
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> may be no
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> more than asking him to perform a post-mortem
>>>>>> examination:
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> he may be
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> able to say what the experiment died of. ~ Sir Ronald
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> Aylmer Fisher
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> The plural of anecdote is not data. ~ Roger Brinner The
>>>>>> >>>>>>>>>>>> combination of some data and an aching desire for an
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> answer does
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> not ensure that a reasonable answer can be extracted
>>>>>> from a
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> given body
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> of data. ~ John Tukey
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>>> 2016-06-23 10:07 GMT+02:00 Philipp Singer
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> < <killver at gmail.com>killver at gmail.com <mailto:
>>>>>> <killver at gmail.com>killver at gmail.com>
>>>>>> >>>>>>>>>>> <mailto: <killver at gmail.com>killver at gmail.com <mailto:
>>>>>> <killver at gmail.com>killver at gmail.com>>
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> <mailto: <killver at gmail.com>killver at gmail.com <mailto:
>>>>>> <killver at gmail.com>killver at gmail.com>
>>>>>> >>>>>>>>>>>> <mailto: <killver at gmail.com>killver at gmail.com <mailto:
>>>>>> <killver at gmail.com>killver at gmail.com>>>>:
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>>> Dear group - I am currently fitting a Poisson glmer
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> where I have
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> an excess of outcomes that are zero (>95%). I am now
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> debating on
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> how to proceed and came up with three options:
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>>> 1.) Just fit a regular glmer to the complete data. I am
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> not fully
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> sure how interpret the coefficients then, are they more
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> optimizing
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> towards distinguishing zero and non-zero, or also
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> capturing the
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> differences in those outcomes that are non-zero?
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>>> 2.) Leave all zeros out of the data and fit a glmer to
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> only those
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> outcomes that are non-zero. Then, I would only learn
>>>>>> about
>>>>>> >>>>>>>>>>>> differences in the non-zero outcomes though.
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>>> 3.) Use a zero-inflated Poisson model. My data is quite
>>>>>> >>>>>>>>>>>> large-scale, so I am currently playing around with the EM
>>>>>> >>>>>>>>>>>> implementation of Bolker et al. that alternates between
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> fitting a
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> glmer with data that are weighted according to their zero
>>>>>> >>>>>>>>>>>> probability, and fitting a logistic regression for the
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> probability
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> that a data point is zero. The method is elaborated for
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> the OWL
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> data in:
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>>
>>>>>> <https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf>
>>>>>> https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
>>>>>> >>>>>>>>>>> <
>>>>>> >>>>>>>>>>>
>>>>>> <https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf>
>>>>>> https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
>>>>>> >>>>>>>>>>> >
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>> I am not fully sure how to interpret the results for the
>>>>>> >>>>>>>
>>>>>> >>>>>>>> zero-inflated version though. Would I need to interpret the
>>>>>> >>>>>>>>>>>> coefficients for the result of the glmer similar to as
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> I would do
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> for my idea of 2)? And then on top of that interpret the
>>>>>> >>>>>>>>>>>> coefficients for the logistic regression regarding
>>>>>> whether
>>>>>> >>>>>>>>>>>> something is in the perfect or imperfect state? I am
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> also not
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> quite sure what the common approach for the zformula is
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> here. The
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> OWL elaborations only use zformula=z~1, so no random
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> effect; I
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> would use the same formula as for the glmer.
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>>> I am appreciating some help and pointers.
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>>> Thanks! Philipp
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>>> _______________________________________________
>>>>>> >>>>>>>>>>>> <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org
>>>>>> >>>>>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org>
>>>>>> >>>>>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org>
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org
>>>>>> >>>>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org>>
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org
>>>>>> >>>>>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org>
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org
>>>>>> >>>>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org>>> mailing list
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>>
>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>> >>>>>>>>>>>> <
>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>>> [[alternative HTML version deleted]]
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>> _______________________________________________
>>>>>> >>>>>>>>>>> <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org
>>>>>> >>>>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org>
>>>>>> >>>>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org>
>>>>>> >>>>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org
>>>>>> >>>>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org>> mailing list
>>>>>> >>>>>>>>>>>
>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>> >>>>>>>>>>> <
>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>> [[alternative HTML version deleted]]
>>>>>> >>>>>>>>>
>>>>>> >>>>>>>>> _______________________________________________
>>>>>> >>>>>>>>> <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org
>>>>>> >>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org>
>>>>>> >>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org> mailing list
>>>>>> >>>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>> >>>>>>>>> <
>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>> >>>>>>>>>
>>>>>> >>>>>>>> [[alternative HTML version deleted]]
>>>>>> >>>>>>>>
>>>>>> >>>>>>>> _______________________________________________
>>>>>> >>>>>>>> <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org
>>>>>> >>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org> mailing list
>>>>>> >>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>> >>>>>>>>
>>>>>> >>>>>>>> _______________________________________________
>>>>>> >>>>>>> <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org
>>>>>> >>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org> mailing list
>>>>>> >>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>> >>>>>>>
>>>>>> >>>>>> _______________________________________________
>>>>>> >>>>>> <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org
>>>>>> >>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org> mailing list
>>>>>> >>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>> >>>>>>
>>>>>> >>>>>
>>>>>> >>>         [[alternative HTML version deleted]]
>>>>>> >>>
>>>>>> >>> _______________________________________________
>>>>>> >>> <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>> >>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>> >>>
>>>>>> >>>
>>>>>> >
>>>>>>
>>>>>>         [[alternative HTML version deleted]]
>>>>>>
>>>>>> _______________________________________________
>>>>>> <R-sig-mixed-models at r-project.org>R-sig-mixed-models at r-project.org
>>>>>> mailing list
>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>
>>>>>
>>>>>
>>>>
>>>
>>
>>
>
>

	[[alternative HTML version deleted]]


From killver at gmail.com  Tue Jun 28 09:39:27 2016
From: killver at gmail.com (Philipp Singer)
Date: Tue, 28 Jun 2016 09:39:27 +0200
Subject: [R-sig-ME] Question about zero-inflated Poisson glmer
In-Reply-To: <CAJuCY5yOWstEGO9wiQvrc48bFGtuz0Cfp4tzVQ67+py3rmBk0A@mail.gmail.com>
References: <576B98C4.6000602@gmail.com> <576BAB84.6080009@gmail.com>
	<CAJuCY5zmK1xCyWOwcCH+Hch_LSdB+AazmUDuPVP6je7ABFU5FA@mail.gmail.com>
	<576BBCFD.8040806@gmail.com>
	<CAJuCY5ycRL6oXs=H5JrEqOHWzd1UsvSNVZM6-MK+V2N=pvbyQA@mail.gmail.com>
	<576BFEBC.3020407@gmail.com>
	<B5AEF3F5-949F-4686-82DA-C234C3C4018B@ufl.edu>
	<576C18F9.9010200@gmail.com> <576C200A.1050405@gmail.com>
	<4D07695C-8CEA-4785-A5B0-46B011625DA0@ufl.edu>
	<576D290A.7090102@gmail.com>
	<576D3209.6050507@gmail.com> <576D3864.1060001@gmail.com>
	<576D3B1B.3050908@gmail.com>
	<CAGPhqeohy3hB8hfnNcj=6d_D=mRVG9CWk910qfSEsEnnr0N__A@mail.gmail.com>
	<CAJuCY5wcBboPCe58h2kYPL1+tXwe=5dmVT10n6wFCJSE+7-wnw@mail.gmail.com>
	<CAGPhqeojDg=tXJi+oYMqAqGwCaVxkkhnhV3MBr2e9O2agEeJUA@mail.gmail.com>
	<CAGPhqeok+j2mCtfSBYveSbU1iCzvZjTefeEE8f=uyyH33ctS=w@mail.gmail.com>
	<CAJuCY5xDPr0rBa-cCCT7+_QOefO8UT8AreP_8hMh6siuM6noBA@mail.gmail.com>
	<57714A59.4060806@gmail.com>
	<CAJuCY5yOWstEGO9wiQvrc48bFGtuz0Cfp4tzVQ67+py3rmBk0A@mail.gmail.com>
Message-ID: <577229AF.5090904@gmail.com>

Unfortunately, if I model the data with a zero-inflated negative 
binomial model (which appears to be the most appropriate model to me), 
the fitted values are never zero, but hover around a mean of 20, even 
though, as said, my data contains around 95% zeros.

I thought about hurdle models as well, but zero-inflated definitely fit 
the process better.

On 27.06.2016 21:59, Thierry Onkelinx wrote:
> If there is overdispersion, then try a negative binomial model or a 
> zero-inflated negative binomial model. If not try a zero-inflated 
> Poisson. Adding relevant covariates can reduce overdispersion.
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature 
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no 
> more than asking him to perform a post-mortem examination: he may be 
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does 
> not ensure that a reasonable answer can be extracted from a given body 
> of data. ~ John Tukey
>
> 2016-06-27 17:46 GMT+02:00 Philipp Singer <killver at gmail.com 
> <mailto:killver at gmail.com>>:
>
>     Well, as posted beforehand the std dev is 9.5 ... so does not seem
>     too good then :/
>
>     Any other idea?
>
>
>     On 27.06.2016 17:31, Thierry Onkelinx wrote:
>>     Dear Philipp,
>>
>>     You've been bitten by observation level random effects. I've put
>>     together a document about it on http://rpubs.com/INBOstats/OLRE.
>>     Bottomline you're OKish when the standard devation of the OLRE
>>     smaller than 1. You're in trouble when it's above 3. In between
>>     you need to check the model carefully.
>>
>>     Best regards,
>>
>>     ir. Thierry Onkelinx
>>     Instituut voor natuur- en bosonderzoek / Research Institute for
>>     Nature and Forest
>>     team Biometrie & Kwaliteitszorg / team Biometrics & Quality
>>     Assurance
>>     Kliniekstraat 25
>>     1070 Anderlecht
>>     Belgium
>>
>>     To call in the statistician after the experiment is done may be
>>     no more than asking him to perform a post-mortem examination: he
>>     may be able to say what the experiment died of. ~ Sir Ronald
>>     Aylmer Fisher
>>     The plural of anecdote is not data. ~ Roger Brinner
>>     The combination of some data and an aching desire for an answer
>>     does not ensure that a reasonable answer can be extracted from a
>>     given body of data. ~ John Tukey
>>
>>     2016-06-27 16:17 GMT+02:00 Philipp Singer <killver at gmail.com
>>     <mailto:killver at gmail.com>>:
>>
>>         Here is the fitted vs. residual plot for the
>>         observation-level poisson model where the observation level
>>         has been removed as taken from:
>>         https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q3/020817.html
>>
>>         So basically the prediction is always close to zero.
>>
>>         Note that this is just on a very small sample (1000 data points).
>>
>>         If I fit a nbinom2 to this smalle sample, I get predictions
>>         that are always around ~20 (but never zero). Both plots are
>>         attached.
>>
>>         What I am wondering is whether I can do inference on a fixed
>>         parameter in my model which is my main task of this study.
>>         The effect is similar in the different models and in general
>>         I am only itnerested in whether it is positive/negative and
>>         "significant" which it is. However, as can be seen, the
>>         prediction looks not too good here.
>>
>>
>>
>>
>>         2016-06-27 15:18 GMT+02:00 Philipp Singer <killver at gmail.com
>>         <mailto:killver at gmail.com>>:
>>
>>             The variance is:
>>
>>             Conditional model:
>>               Groups            Name        Variance  Std.Dev.
>>               obs               (Intercept) 8.991e+01 9.4823139
>>
>>
>>
>>             2016-06-27 15:06 GMT+02:00 Thierry Onkelinx
>>             <thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>>:
>>
>>                 Dear Philipp,
>>
>>                 How strong is the variance of the observation level
>>                 random effect? I would trust a model with large OLRE
>>                 variance.
>>
>>                 Best regards,
>>
>>                 Thierry
>>
>>                 ir. Thierry Onkelinx
>>                 Instituut voor natuur- en bosonderzoek / Research
>>                 Institute for Nature and Forest
>>                 team Biometrie & Kwaliteitszorg / team Biometrics &
>>                 Quality Assurance
>>                 Kliniekstraat 25
>>                 1070 Anderlecht
>>                 Belgium
>>
>>                 To call in the statistician after the experiment is
>>                 done may be no more than asking him to perform a
>>                 post-mortem examination: he may be able to say what
>>                 the experiment died of. ~ Sir Ronald Aylmer Fisher
>>                 The plural of anecdote is not data. ~ Roger Brinner
>>                 The combination of some data and an aching desire for
>>                 an answer does not ensure that a reasonable answer
>>                 can be extracted from a given body of data. ~ John Tukey
>>
>>                 2016-06-27 14:59 GMT+02:00 Philipp Singer
>>                 <killver at gmail.com <mailto:killver at gmail.com>>:
>>
>>                     I have now played around more with the data an
>>                     the models both using lme4
>>                     and glmmTMB.
>>
>>                     I can report the following:
>>
>>                     Modeling the data with a zero-inflated Poisson
>>                     improves the model
>>                     significantly. However, when calling predict and
>>                     simulating rpoissons, I
>>                     end up with nearly no values that are zero (in
>>                     the original data there are
>>                     96% zero).
>>
>>                     When I model the data with overdisperion by
>>                     including an observation-level
>>                     random effect, I can also improve the model (not
>>                     surprisingly due to the
>>                     random effect). When I predict outcomes by
>>                     ignoring the observation-level
>>                     random effect (in lme4), I receive bad prediction
>>                     if I compare it to the
>>                     original data. While many zeros can be captured
>>                     (of course), the positive
>>                     outcomes can not be captured well.
>>
>>                     Combining zero inflation and overdispersion
>>                     further improves the model, but
>>                     I can only do that with glmmTMB and then have
>>                     troubles doing predictions
>>                     ignoring the observation-level random effect.
>>
>>                     Another side question:
>>
>>                     In lme4, when I do:
>>
>>                     m = glm(x~1,family="poisson")
>>                     rpois(n=len(data),lambda=predict(m,
>>                     type='response',re.form=NA)
>>
>>                     vs.
>>
>>                     simulate(1,m,re.form=NA)
>>
>>                     I receive different outcomes? Do I understand
>>                     these function wrongly?
>>
>>                     Would appreciate some more help/pointers!
>>
>>                     Thanks,
>>                     Philipp
>>
>>                     2016-06-24 15:52 GMT+02:00 Philipp Singer
>>                     <killver at gmail.com <mailto:killver at gmail.com>>:
>>
>>                     > Thanks - I started an issue there to answer
>>                     some of my questions.
>>                     >
>>                     > Regarding the installation: I was trying to
>>                     somehow do it in anaconda with
>>                     > a specific R kernel and had some issues. I am
>>                     trying to resort that with
>>                     > the anaconda guys though, if I have a tutorial
>>                     on how to properly setup
>>                     > glmmTMB in anaconda, I will let you know. The
>>                     install worked fine in my
>>                     > standard R environment.
>>                     >
>>                     >
>>                     > On 24.06.2016 15 <tel:24.06.2016%2015>:40, Ben
>>                     Bolker wrote:
>>                     >
>>                     >>  Probably for now the glmmTMB issues page is best.
>>                     >>
>>                     >>  When you go there:
>>                     >>
>>                     >>    - details on installation problems/hiccups
>>                     would be useful
>>                     >>    - a reproducible example for the problem
>>                     listed below would be useful
>>                     >>    - dispformula is for allowing
>>                     dispersion/residual variance to vary
>>                     >> with covariates (i.e., modeling
>>                     heteroscedasticity)
>>                     >>
>>                     >> cheers
>>                     >> Ben Bolker
>>                     >>
>>                     >>
>>                     >> On 16-06-24 09:13 AM, Philipp Singer wrote:
>>                     >>
>>                     >>> Update, I tried it like that, but receive an
>>                     error message.
>>                     >>>
>>                     >>> Warning message:
>>                     >>> In nlminb(start = par, objective = fn,
>>                     gradient = gr): NA/NaN function
>>                     >>> evaluation
>>                     >>>
>>                     >>> Error in solve.default(hessian.fixed): Lapack
>>                     routine dgesv: system is
>>                     >>> exactly singular: U[3,3] = 0
>>                     >>> Traceback:
>>                     >>>
>>                     >>> 1. glmmTMB(y ~ 1 + x + (1 | b),
>>                     >>>   .     data = data, family = "poisson",
>>                     dispformula = ~1 + x)
>>                     >>> 2. sdreport(obj)
>>                     >>> 3. solve(hessian.fixed)
>>                     >>> 4. solve(hessian.fixed)
>>                     >>> 5. solve.default(hessian.fixed)
>>                     >>>
>>                     >>> Any ideas on that?
>>                     >>>
>>                     >>> BTW: Is it fine to post glmmTMB questions
>>                     here, or should I rather use
>>                     >>> the github issue page, or is there maybe a
>>                     dedicated mailing list?
>>                     >>>
>>                     >>> Thanks,
>>                     >>> Philipp
>>                     >>>
>>                     >>> On 24.06.2016 14:35, Philipp Singer wrote:
>>                     >>>
>>                     >>>> It indeed seems to run quite fast; had some
>>                     trouble installing, but
>>                     >>>> works now on my 3.3 R setup.
>>                     >>>>
>>                     >>>> One question I have is regarding the
>>                     specification of dispersion as I
>>                     >>>> need to specify the dispformula. What is the
>>                     difference here between
>>                     >>>> just specifying fixed effects vs. also the
>>                     random effects?
>>                     >>>>
>>                     >>>> On 23.06.2016 23:07, Mollie Brooks wrote:
>>                     >>>>
>>                     >>>>> glmmTMB does crossed RE. Ben did some
>>                     timings in vignette("glmmTMB")
>>                     >>>>> and it was 2.3 times faster than glmer for
>>                     one simple GLMM.
>>                     >>>>>
>>                     >>>>>
>>                     >>>>> On 23Jun 2016, at 10:44, Philipp Singer
>>                     <killver at gmail.com <mailto:killver at gmail.com>> wrote:
>>                     >>>>>>
>>                     >>>>>> Did try glmmADMB but unfortunately it is
>>                     way too slow for my data.
>>                     >>>>>>
>>                     >>>>>> Did not know about glmmTMB, will try it
>>                     out. Does it work with
>>                     >>>>>> crossed random effects and how does it
>>                     scale with more data? I will
>>                     >>>>>> check the docu and try it though. Thanks
>>                     for the info.
>>                     >>>>>>
>>                     >>>>>> On 23.06.2016 19:14, Ben Bolker wrote:
>>                     >>>>>>
>>                     >>>>>>>   I would also comment that glmmTMB is
>>                     likely to be much faster
>>                     >>>>>>> than the
>>                     >>>>>>> lme4-based EM approach ...
>>                     >>>>>>>
>>                     >>>>>>>   cheers
>>                     >>>>>>>     Ben B.
>>                     >>>>>>>
>>                     >>>>>>> On 16-06-23 12:47 PM, Mollie Brooks wrote:
>>                     >>>>>>>
>>                     >>>>>>>> Hi Philipp,
>>                     >>>>>>>>
>>                     >>>>>>>> You could also try fitting the model
>>                     with and without ZI using
>>                     >>>>>>>> either
>>                     >>>>>>>> glmmADMB or glmmTMB. Then compare the
>>                     AICs. I believe model
>>                     >>>>>>>> selection
>>                     >>>>>>>> is useful for this, but I could be
>>                     missing something since the
>>                     >>>>>>>> simulation procedure that Thierry
>>                     described seems to recommended
>>                     >>>>>>>> more
>>                     >>>>>>>> often.
>>                     >>>>>>>>
>>                     >>>>>>>> https://github.com/glmmTMB/glmmTMB
>>                     >>>>>>>> http://glmmadmb.r-forge.r-project.org
>>                     >>>>>>>>
>>                     >>>>>>>> glmmTMB is still in the development
>>                     phase, but we?ve done a lot of
>>                     >>>>>>>> testing.
>>                     >>>>>>>>
>>                     >>>>>>>> cheers, Mollie
>>                     >>>>>>>>
>>                     >>>>>>>> ------------------------ Mollie Brooks,
>>                     PhD Postdoctoral Researcher,
>>                     >>>>>>>> Population Ecology Research Group
>>                     Department of Evolutionary Biology
>>                     >>>>>>>> & Environmental Studies, University of
>>                     Z?rich
>>                     >>>>>>>> http://www.popecol.org/team/mollie-brooks/
>>                     >>>>>>>>
>>                     >>>>>>>>
>>                     >>>>>>>> On 23Jun 2016, at 8:22, Philipp Singer
>>                     <killver at gmail.com <mailto:killver at gmail.com>> wrote:
>>                     >>>>>>>>>
>>                     >>>>>>>>> Thanks, great information, that is
>>                     really helpful.
>>                     >>>>>>>>>
>>                     >>>>>>>>> I agree that those are different
>>                     things, however when using a
>>                     >>>>>>>>> random effect for overdispersion, I can
>>                     simulate the same number of
>>                     >>>>>>>>> zero outcomes (~95%).
>>                     >>>>>>>>>
>>                     >>>>>>>>> On 23.06.2016 15:50, Thierry Onkelinx
>>                     wrote:
>>                     >>>>>>>>>
>>                     >>>>>>>>>> Be careful when using overdispersion
>>                     to model zero-inflation.
>>                     >>>>>>>>>> Those are two different things.
>>                     >>>>>>>>>>
>>                     >>>>>>>>>> I've put some information together in
>>                     >>>>>>>>>> http://rpubs.com/INBOstats/zeroinflation
>>                     >>>>>>>>>>
>>                     >>>>>>>>>> ir. Thierry Onkelinx Instituut voor
>>                     natuur- en bosonderzoek /
>>                     >>>>>>>>>> Research Institute for Nature and
>>                     Forest team Biometrie &
>>                     >>>>>>>>>> Kwaliteitszorg / team Biometrics &
>>                     Quality Assurance
>>                     >>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>                     >>>>>>>>>>
>>                     >>>>>>>>>> To call in the statistician after the
>>                     experiment is done may be
>>                     >>>>>>>>>> no more than asking him to perform a
>>                     post-mortem examination: he
>>                     >>>>>>>>>> may be able to say what the experiment
>>                     died of. ~ Sir Ronald
>>                     >>>>>>>>>> Aylmer Fisher The plural of anecdote
>>                     is not data. ~ Roger
>>                     >>>>>>>>>> Brinner The combination of some data
>>                     and an aching desire for an
>>                     >>>>>>>>>> answer does not ensure that a
>>                     reasonable answer can be extracted
>>                     >>>>>>>>>> from a given body of data. ~ John Tukey
>>                     >>>>>>>>>>
>>                     >>>>>>>>>> 2016-06-23 12:42 GMT+02:00 Philipp
>>                     Singer <killver at gmail.com <mailto:killver at gmail.com>
>>                     >>>>>>>>>> <mailto:killver at gmail.com
>>                     <mailto:killver at gmail.com>
>>                     <mailto:killver at gmail.com
>>                     <mailto:killver at gmail.com>>>>:
>>                     >>>>>>>>>>
>>                     >>>>>>>>>> Thanks! Actually, accounting for
>>                     overdispersion is super
>>                     >>>>>>>>>> important as it seems, then the zeros
>>                     can be captured well.
>>                     >>>>>>>>>>
>>                     >>>>>>>>>>
>>                     >>>>>>>>>> On 23.06.2016 11:50, Thierry Onkelinx
>>                     wrote:
>>                     >>>>>>>>>>
>>                     >>>>>>>>>>> Dear Philipp,
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>> 1. Fit a Poisson model to the data.
>>                     2. Simulate a new response
>>                     >>>>>>>>>>> vector for the dataset according to
>>                     the model. 3. Count the
>>                     >>>>>>>>>>> number of zero's in the simulated
>>                     response vector. 4. Repeat
>>                     >>>>>>>>>>> step 2 and 3 a decent number of time
>>                     and plot a histogram of
>>                     >>>>>>>>>>> the number of zero's in the
>>                     simulation. If the number of zero's
>>                     >>>>>>>>>>> in the original dataset is larger
>>                     than those in the
>>                     >>>>>>>>>>> simulations, then the model can't
>>                     capture all zero's. In such
>>                     >>>>>>>>>>> case, first try to update the model
>>                     and repeat the procedure.
>>                     >>>>>>>>>>> If that fails, look for zero-inflated
>>                     models.
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>> Best regards,
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>> ir. Thierry Onkelinx Instituut voor
>>                     natuur- en bosonderzoek /
>>                     >>>>>>>>>>> Research Institute for Nature and
>>                     Forest team Biometrie &
>>                     >>>>>>>>>>> Kwaliteitszorg / team Biometrics &
>>                     Quality Assurance
>>                     >>>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>> To call in the statistician after the
>>                     experiment is done may
>>                     >>>>>>>>>>> be no more than asking him to perform
>>                     a post-mortem
>>                     >>>>>>>>>>> examination: he may be able to say
>>                     what the experiment died of.
>>                     >>>>>>>>>>> ~ Sir Ronald Aylmer Fisher The plural
>>                     of anecdote is not data.
>>                     >>>>>>>>>>> ~ Roger Brinner The combination of
>>                     some data and an aching
>>                     >>>>>>>>>>> desire for an answer does not ensure
>>                     that a reasonable answer
>>                     >>>>>>>>>>> can be extracted from a given body of
>>                     data. ~ John Tukey
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>> 2016-06-23 11:27 GMT+02:00 Philipp
>>                     Singer <killver at gmail.com <mailto:killver at gmail.com>
>>                     >>>>>>>>>>> <mailto:killver at gmail.com
>>                     <mailto:killver at gmail.com>
>>                     <mailto:killver at gmail.com
>>                     <mailto:killver at gmail.com>>>>:
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>> Thanks Thierry - That totally makes
>>                     sense. Is there some way of
>>                     >>>>>>>>>>> formally checking that, except
>>                     thinking about the setting and
>>                     >>>>>>>>>>> underlying processes?
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>> On 23.06.2016 11:04, Thierry Onkelinx
>>                     wrote:
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> Dear Philipp,
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>> Do you have just lots of zero's, or
>>                     more zero's than the
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> Poisson
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> distribution can explain? Those are
>>                     two different things.
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> The example
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> below generates data from a Poisson
>>                     distribution and has
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> 99% zero's
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> but no zero-inflation. The second
>>                     example has only 1%
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> zero's but is
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> clearly zero-inflated.
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>> set.seed(1) n <- 1e8 sim <- rpois(n,
>>                     lambda = 0.01) mean(sim
>>                     >>>>>>>>>>>> == 0) hist(sim)
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>> sim.infl <- rbinom(n, size = 1, prob
>>                     = 0.99) * rpois(n,
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> lambda = 1000)
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> mean(sim.infl == 0) hist(sim.infl)
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>> So before looking for zero-inflated
>>                     models, try to model
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> the zero's.
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> Best regards,
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>> ir. Thierry Onkelinx Instituut voor
>>                     natuur- en bosonderzoek /
>>                     >>>>>>>>>>>> Research Institute
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> for Nature
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> and Forest team Biometrie &
>>                     Kwaliteitszorg / team Biometrics
>>                     >>>>>>>>>>>> & Quality
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> Assurance
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>> To call in the statistician after
>>                     the experiment is done
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> may be no
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> more than asking him to perform a
>>                     post-mortem examination:
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> he may be
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> able to say what the experiment died
>>                     of. ~ Sir Ronald
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> Aylmer Fisher
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> The plural of anecdote is not data.
>>                     ~ Roger Brinner The
>>                     >>>>>>>>>>>> combination of some data and an
>>                     aching desire for an
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> answer does
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> not ensure that a reasonable answer
>>                     can be extracted from a
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> given body
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> of data. ~ John Tukey
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>> 2016-06-23 10:07 GMT+02:00 Philipp
>>                     Singer
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> <killver at gmail.com
>>                     <mailto:killver at gmail.com>
>>                     <mailto:killver at gmail.com <mailto:killver at gmail.com>>
>>                     >>>>>>>>>>> <mailto:killver at gmail.com
>>                     <mailto:killver at gmail.com>
>>                     <mailto:killver at gmail.com
>>                     <mailto:killver at gmail.com>>>
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> <mailto:killver at gmail.com
>>                     <mailto:killver at gmail.com>
>>                     <mailto:killver at gmail.com <mailto:killver at gmail.com>>
>>                     >>>>>>>>>>>> <mailto:killver at gmail.com
>>                     <mailto:killver at gmail.com>
>>                     <mailto:killver at gmail.com
>>                     <mailto:killver at gmail.com>>>>>:
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>> Dear group - I am currently fitting
>>                     a Poisson glmer
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> where I have
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> an excess of outcomes that are zero
>>                     (>95%). I am now
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> debating on
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> how to proceed and came up with
>>                     three options:
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>> 1.) Just fit a regular glmer to the
>>                     complete data. I am
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> not fully
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> sure how interpret the coefficients
>>                     then, are they more
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> optimizing
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> towards distinguishing zero and
>>                     non-zero, or also
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> capturing the
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> differences in those outcomes that
>>                     are non-zero?
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>> 2.) Leave all zeros out of the data
>>                     and fit a glmer to
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> only those
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> outcomes that are non-zero. Then, I
>>                     would only learn about
>>                     >>>>>>>>>>>> differences in the non-zero outcomes
>>                     though.
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>> 3.) Use a zero-inflated Poisson
>>                     model. My data is quite
>>                     >>>>>>>>>>>> large-scale, so I am currently
>>                     playing around with the EM
>>                     >>>>>>>>>>>> implementation of Bolker et al. that
>>                     alternates between
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> fitting a
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> glmer with data that are weighted
>>                     according to their zero
>>                     >>>>>>>>>>>> probability, and fitting a logistic
>>                     regression for the
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> probability
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> that a data point is zero. The
>>                     method is elaborated for
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> the OWL
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> data in:
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>
>>                     https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
>>                     >>>>>>>>>>> <
>>                     >>>>>>>>>>>
>>                     https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
>>                     >>>>>>>>>>> >
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>> I am not fully sure how to interpret
>>                     the results for the
>>                     >>>>>>>
>>                     >>>>>>>> zero-inflated version though. Would I
>>                     need to interpret the
>>                     >>>>>>>>>>>> coefficients for the result of the
>>                     glmer similar to as
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> I would do
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> for my idea of 2)? And then on top
>>                     of that interpret the
>>                     >>>>>>>>>>>> coefficients for the logistic
>>                     regression regarding whether
>>                     >>>>>>>>>>>> something is in the perfect or
>>                     imperfect state? I am
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> also not
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> quite sure what the common approach
>>                     for the zformula is
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> here. The
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> OWL elaborations only use
>>                     zformula=z~1, so no random
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>> effect; I
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>> would use the same formula as for
>>                     the glmer.
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>> I am appreciating some help and
>>                     pointers.
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>> Thanks! Philipp
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>>
>>                     _______________________________________________
>>                     >>>>>>>>>>>> R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>
>>                     >>>>>>>>>>>>
>>                     <mailto:R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>>
>>                     >>>>>>>>>>>>
>>                     <mailto:R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>>
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>
>>                     <mailto:R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>
>>                     >>>>>>>>>>>
>>                     <mailto:R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>>>
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>>
>>                     <mailto:R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>
>>                     >>>>>>>>>>>>
>>                     <mailto:R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>>
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>
>>                     <mailto:R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>
>>                     >>>>>>>>>>>
>>                     <mailto:R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>>>>
>>                     mailing list
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>>
>>                     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>                     >>>>>>>>>>>>
>>                     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>>
>>                     >>>>>>>>>>>> [[alternative HTML version deleted]]
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>
>>                     _______________________________________________
>>                     >>>>>>>>>>> R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>
>>                     >>>>>>>>>>>
>>                     <mailto:R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>>
>>                     >>>>>>>>>>>
>>                     <mailto:R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>>
>>                     >>>>>>>>>>>
>>                     <mailto:R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>
>>                     >>>>>>>>>>>
>>                     <mailto:R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>>>
>>                     mailing list
>>                     >>>>>>>>>>>
>>                     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>                     >>>>>>>>>>>
>>                     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>>
>>                     >>>>>>>>>>> [[alternative HTML version deleted]]
>>                     >>>>>>>>>
>>                     >>>>>>>>>
>>                     _______________________________________________
>>                     >>>>>>>>> R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>
>>                     >>>>>>>>>
>>                     <mailto:R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>>
>>                     >>>>>>>>>
>>                     <mailto:R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>>
>>                     mailing list
>>                     >>>>>>>>>
>>                     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>                     >>>>>>>>>
>>                     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>                     >>>>>>>>>
>>                     >>>>>>>> [[alternative HTML version deleted]]
>>                     >>>>>>>>
>>                     >>>>>>>>
>>                     _______________________________________________
>>                     >>>>>>>> R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>
>>                     >>>>>>>> <mailto:R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>>
>>                     mailing list
>>                     >>>>>>>>
>>                     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>                     >>>>>>>>
>>                     >>>>>>>>
>>                     _______________________________________________
>>                     >>>>>>> R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>
>>                     >>>>>>> <mailto:R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>>
>>                     mailing list
>>                     >>>>>>>
>>                     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>                     >>>>>>>
>>                     >>>>>>
>>                     _______________________________________________
>>                     >>>>>> R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>
>>                     >>>>>> <mailto:R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org>>
>>                     mailing list
>>                     >>>>>>
>>                     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>                     >>>>>>
>>                     >>>>>
>>                     >>>  [[alternative HTML version deleted]]
>>                     >>>
>>                     >>> _______________________________________________
>>                     >>> R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org> mailing
>>                     list
>>                     >>>
>>                     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>                     >>>
>>                     >>>
>>                     >
>>
>>                     [[alternative HTML version deleted]]
>>
>>                     _______________________________________________
>>                     R-sig-mixed-models at r-project.org
>>                     <mailto:R-sig-mixed-models at r-project.org> mailing
>>                     list
>>                     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>>
>>
>
>


	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Jun 28 09:57:01 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 28 Jun 2016 09:57:01 +0200
Subject: [R-sig-ME] Question about zero-inflated Poisson glmer
In-Reply-To: <577229AF.5090904@gmail.com>
References: <576B98C4.6000602@gmail.com> <576BAB84.6080009@gmail.com>
	<CAJuCY5zmK1xCyWOwcCH+Hch_LSdB+AazmUDuPVP6je7ABFU5FA@mail.gmail.com>
	<576BBCFD.8040806@gmail.com>
	<CAJuCY5ycRL6oXs=H5JrEqOHWzd1UsvSNVZM6-MK+V2N=pvbyQA@mail.gmail.com>
	<576BFEBC.3020407@gmail.com>
	<B5AEF3F5-949F-4686-82DA-C234C3C4018B@ufl.edu>
	<576C18F9.9010200@gmail.com> <576C200A.1050405@gmail.com>
	<4D07695C-8CEA-4785-A5B0-46B011625DA0@ufl.edu>
	<576D290A.7090102@gmail.com> <576D3209.6050507@gmail.com>
	<576D3864.1060001@gmail.com> <576D3B1B.3050908@gmail.com>
	<CAGPhqeohy3hB8hfnNcj=6d_D=mRVG9CWk910qfSEsEnnr0N__A@mail.gmail.com>
	<CAJuCY5wcBboPCe58h2kYPL1+tXwe=5dmVT10n6wFCJSE+7-wnw@mail.gmail.com>
	<CAGPhqeojDg=tXJi+oYMqAqGwCaVxkkhnhV3MBr2e9O2agEeJUA@mail.gmail.com>
	<CAGPhqeok+j2mCtfSBYveSbU1iCzvZjTefeEE8f=uyyH33ctS=w@mail.gmail.com>
	<CAJuCY5xDPr0rBa-cCCT7+_QOefO8UT8AreP_8hMh6siuM6noBA@mail.gmail.com>
	<57714A59.4060806@gmail.com>
	<CAJuCY5yOWstEGO9wiQvrc48bFGtuz0Cfp4tzVQ67+py3rmBk0A@mail.gmail.com>
	<577229AF.5090904@gmail.com>
Message-ID: <CAJuCY5wSj-0L5_UcMqVTPmmV+NT-KaYbdrW9Ukiy1NU+iVjj3A@mail.gmail.com>

It's hard to tell what's wrong without any knowledge of the model. A
reproducible example would be handy.

Some things to check:
- How strong is the zero-inflation according to the model?
- What are the fitted values exactly? The response? The predict mean of the
counts? The probability of extre zero's?

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-06-28 9:39 GMT+02:00 Philipp Singer <killver at gmail.com>:

> Unfortunately, if I model the data with a zero-inflated negative binomial
> model (which appears to be the most appropriate model to me), the fitted
> values are never zero, but hover around a mean of 20, even though, as said,
> my data contains around 95% zeros.
>
> I thought about hurdle models as well, but zero-inflated definitely fit
> the process better.
>
> On 27.06.2016 21:59, Thierry Onkelinx wrote:
>
> If there is overdispersion, then try a negative binomial model or a
> zero-inflated negative binomial model. If not try a zero-inflated Poisson.
> Adding relevant covariates can reduce overdispersion.
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2016-06-27 17:46 GMT+02:00 Philipp Singer <killver at gmail.com>:
>
>> Well, as posted beforehand the std dev is 9.5 ... so does not seem too
>> good then :/
>>
>> Any other idea?
>>
>>
>> On 27.06.2016 17:31, Thierry Onkelinx wrote:
>>
>> Dear Philipp,
>>
>> You've been bitten by observation level random effects. I've put together
>> a document about it on http://rpubs.com/INBOstats/OLRE. Bottomline
>> you're OKish when the standard devation of the OLRE smaller than 1. You're
>> in trouble when it's above 3. In between you need to check the model
>> carefully.
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2016-06-27 16:17 GMT+02:00 Philipp Singer < <killver at gmail.com>
>> killver at gmail.com>:
>>
>>> Here is the fitted vs. residual plot for the observation-level poisson
>>> model where the observation level has been removed as taken from:
>>> <https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q3/020817.html>
>>> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q3/020817.html
>>>
>>> So basically the prediction is always close to zero.
>>>
>>> Note that this is just on a very small sample (1000 data points).
>>>
>>> If I fit a nbinom2 to this smalle sample, I get predictions that are
>>> always around ~20 (but never zero). Both plots are attached.
>>>
>>> What I am wondering is whether I can do inference on a fixed parameter
>>> in my model which is my main task of this study. The effect is similar in
>>> the different models and in general I am only itnerested in whether it is
>>> positive/negative and "significant" which it is. However, as can be seen,
>>> the prediction looks not too good here.
>>>
>>>
>>>
>>>
>>> 2016-06-27 15:18 GMT+02:00 Philipp Singer < <killver at gmail.com>
>>> killver at gmail.com>:
>>>
>>>> The variance is:
>>>>
>>>> Conditional model:
>>>>  Groups            Name        Variance  Std.Dev.
>>>>  obs               (Intercept) 8.991e+01 9.4823139
>>>>
>>>>
>>>>
>>>> 2016-06-27 15:06 GMT+02:00 Thierry Onkelinx <
>>>> <thierry.onkelinx at inbo.be>thierry.onkelinx at inbo.be>:
>>>>
>>>>> Dear Philipp,
>>>>>
>>>>> How strong is the variance of the observation level random effect? I
>>>>> would trust a model with large OLRE variance.
>>>>>
>>>>> Best regards,
>>>>>
>>>>> Thierry
>>>>>
>>>>> ir. Thierry Onkelinx
>>>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>>>> and Forest
>>>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>>>> Kliniekstraat 25
>>>>> 1070 Anderlecht
>>>>> Belgium
>>>>>
>>>>> To call in the statistician after the experiment is done may be no
>>>>> more than asking him to perform a post-mortem examination: he may be able
>>>>> to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>>> The combination of some data and an aching desire for an answer does
>>>>> not ensure that a reasonable answer can be extracted from a given body of
>>>>> data. ~ John Tukey
>>>>>
>>>>> 2016-06-27 14:59 GMT+02:00 Philipp Singer < <killver at gmail.com>
>>>>> killver at gmail.com>:
>>>>>
>>>>>> I have now played around more with the data an the models both using
>>>>>> lme4
>>>>>> and glmmTMB.
>>>>>>
>>>>>> I can report the following:
>>>>>>
>>>>>> Modeling the data with a zero-inflated Poisson improves the model
>>>>>> significantly. However, when calling predict and simulating
>>>>>> rpoissons, I
>>>>>> end up with nearly no values that are zero (in the original data
>>>>>> there are
>>>>>> 96% zero).
>>>>>>
>>>>>> When I model the data with overdisperion by including an
>>>>>> observation-level
>>>>>> random effect, I can also improve the model (not surprisingly due to
>>>>>> the
>>>>>> random effect). When I predict outcomes by ignoring the
>>>>>> observation-level
>>>>>> random effect (in lme4), I receive bad prediction if I compare it to
>>>>>> the
>>>>>> original data. While many zeros can be captured (of course), the
>>>>>> positive
>>>>>> outcomes can not be captured well.
>>>>>>
>>>>>> Combining zero inflation and overdispersion further improves the
>>>>>> model, but
>>>>>> I can only do that with glmmTMB and then have troubles doing
>>>>>> predictions
>>>>>> ignoring the observation-level random effect.
>>>>>>
>>>>>> Another side question:
>>>>>>
>>>>>> In lme4, when I do:
>>>>>>
>>>>>> m = glm(x~1,family="poisson")
>>>>>> rpois(n=len(data),lambda=predict(m, type='response',re.form=NA)
>>>>>>
>>>>>> vs.
>>>>>>
>>>>>> simulate(1,m,re.form=NA)
>>>>>>
>>>>>> I receive different outcomes? Do I understand these function wrongly?
>>>>>>
>>>>>> Would appreciate some more help/pointers!
>>>>>>
>>>>>> Thanks,
>>>>>> Philipp
>>>>>>
>>>>>> 2016-06-24 15:52 GMT+02:00 Philipp Singer < <killver at gmail.com>
>>>>>> killver at gmail.com>:
>>>>>>
>>>>>> > Thanks - I started an issue there to answer some of my questions.
>>>>>> >
>>>>>> > Regarding the installation: I was trying to somehow do it in
>>>>>> anaconda with
>>>>>> > a specific R kernel and had some issues. I am trying to resort that
>>>>>> with
>>>>>> > the anaconda guys though, if I have a tutorial on how to properly
>>>>>> setup
>>>>>> > glmmTMB in anaconda, I will let you know. The install worked fine
>>>>>> in my
>>>>>> > standard R environment.
>>>>>> >
>>>>>> >
>>>>>> > On 24.06.2016 15 <24.06.2016%2015>:40, Ben Bolker wrote:
>>>>>> >
>>>>>> >>   Probably for now the glmmTMB issues page is best.
>>>>>> >>
>>>>>> >>   When you go there:
>>>>>> >>
>>>>>> >>    - details on installation problems/hiccups would be useful
>>>>>> >>    - a reproducible example for the problem listed below would be
>>>>>> useful
>>>>>> >>    - dispformula is for allowing dispersion/residual variance to
>>>>>> vary
>>>>>> >> with covariates (i.e., modeling heteroscedasticity)
>>>>>> >>
>>>>>> >>    cheers
>>>>>> >>      Ben Bolker
>>>>>> >>
>>>>>> >>
>>>>>> >> On 16-06-24 09:13 AM, Philipp Singer wrote:
>>>>>> >>
>>>>>> >>> Update, I tried it like that, but receive an error message.
>>>>>> >>>
>>>>>> >>> Warning message:
>>>>>> >>> In nlminb(start = par, objective = fn, gradient = gr): NA/NaN
>>>>>> function
>>>>>> >>> evaluation
>>>>>> >>>
>>>>>> >>> Error in solve.default(hessian.fixed): Lapack routine dgesv:
>>>>>> system is
>>>>>> >>> exactly singular: U[3,3] = 0
>>>>>> >>> Traceback:
>>>>>> >>>
>>>>>> >>> 1. glmmTMB(y ~ 1 + x + (1 | b),
>>>>>> >>>    .     data = data, family = "poisson", dispformula = ~1 + x)
>>>>>> >>> 2. sdreport(obj)
>>>>>> >>> 3. solve(hessian.fixed)
>>>>>> >>> 4. solve(hessian.fixed)
>>>>>> >>> 5. solve.default(hessian.fixed)
>>>>>> >>>
>>>>>> >>> Any ideas on that?
>>>>>> >>>
>>>>>> >>> BTW: Is it fine to post glmmTMB questions here, or should I
>>>>>> rather use
>>>>>> >>> the github issue page, or is there maybe a dedicated mailing list?
>>>>>> >>>
>>>>>> >>> Thanks,
>>>>>> >>> Philipp
>>>>>> >>>
>>>>>> >>> On 24.06.2016 14:35, Philipp Singer wrote:
>>>>>> >>>
>>>>>> >>>> It indeed seems to run quite fast; had some trouble installing,
>>>>>> but
>>>>>> >>>> works now on my 3.3 R setup.
>>>>>> >>>>
>>>>>> >>>> One question I have is regarding the specification of dispersion
>>>>>> as I
>>>>>> >>>> need to specify the dispformula. What is the difference here
>>>>>> between
>>>>>> >>>> just specifying fixed effects vs. also the random effects?
>>>>>> >>>>
>>>>>> >>>> On 23.06.2016 23:07, Mollie Brooks wrote:
>>>>>> >>>>
>>>>>> >>>>> glmmTMB does crossed RE. Ben did some timings in
>>>>>> vignette("glmmTMB")
>>>>>> >>>>> and it was 2.3 times faster than glmer for one simple GLMM.
>>>>>> >>>>>
>>>>>> >>>>>
>>>>>> >>>>> On 23Jun 2016, at 10:44, Philipp Singer < <killver at gmail.com>
>>>>>> killver at gmail.com> wrote:
>>>>>> >>>>>>
>>>>>> >>>>>> Did try glmmADMB but unfortunately it is way too slow for my
>>>>>> data.
>>>>>> >>>>>>
>>>>>> >>>>>> Did not know about glmmTMB, will try it out. Does it work with
>>>>>> >>>>>> crossed random effects and how does it scale with more data? I
>>>>>> will
>>>>>> >>>>>> check the docu and try it though. Thanks for the info.
>>>>>> >>>>>>
>>>>>> >>>>>> On 23.06.2016 19:14, Ben Bolker wrote:
>>>>>> >>>>>>
>>>>>> >>>>>>>    I would also comment that glmmTMB is likely to be much
>>>>>> faster
>>>>>> >>>>>>> than the
>>>>>> >>>>>>> lme4-based EM approach ...
>>>>>> >>>>>>>
>>>>>> >>>>>>>    cheers
>>>>>> >>>>>>>      Ben B.
>>>>>> >>>>>>>
>>>>>> >>>>>>> On 16-06-23 12:47 PM, Mollie Brooks wrote:
>>>>>> >>>>>>>
>>>>>> >>>>>>>> Hi Philipp,
>>>>>> >>>>>>>>
>>>>>> >>>>>>>> You could also try fitting the model with and without ZI
>>>>>> using
>>>>>> >>>>>>>> either
>>>>>> >>>>>>>> glmmADMB or glmmTMB. Then compare the AICs. I believe model
>>>>>> >>>>>>>> selection
>>>>>> >>>>>>>> is useful for this, but I could be missing something since
>>>>>> the
>>>>>> >>>>>>>> simulation procedure that Thierry described seems to
>>>>>> recommended
>>>>>> >>>>>>>> more
>>>>>> >>>>>>>> often.
>>>>>> >>>>>>>>
>>>>>> >>>>>>>> <https://github.com/glmmTMB/glmmTMB>
>>>>>> https://github.com/glmmTMB/glmmTMB
>>>>>> >>>>>>>> <http://glmmadmb.r-forge.r-project.org>
>>>>>> http://glmmadmb.r-forge.r-project.org
>>>>>> >>>>>>>>
>>>>>> >>>>>>>> glmmTMB is still in the development phase, but we?ve done a
>>>>>> lot of
>>>>>> >>>>>>>> testing.
>>>>>> >>>>>>>>
>>>>>> >>>>>>>> cheers, Mollie
>>>>>> >>>>>>>>
>>>>>> >>>>>>>> ------------------------ Mollie Brooks, PhD Postdoctoral
>>>>>> Researcher,
>>>>>> >>>>>>>> Population Ecology Research Group Department of Evolutionary
>>>>>> Biology
>>>>>> >>>>>>>> & Environmental Studies, University of Z?rich
>>>>>> >>>>>>>> <http://www.popecol.org/team/mollie-brooks/>
>>>>>> http://www.popecol.org/team/mollie-brooks/
>>>>>> >>>>>>>>
>>>>>> >>>>>>>>
>>>>>> >>>>>>>> On 23Jun 2016, at 8:22, Philipp Singer < <killver at gmail.com>
>>>>>> killver at gmail.com> wrote:
>>>>>> >>>>>>>>>
>>>>>> >>>>>>>>> Thanks, great information, that is really helpful.
>>>>>> >>>>>>>>>
>>>>>> >>>>>>>>> I agree that those are different things, however when using
>>>>>> a
>>>>>> >>>>>>>>> random effect for overdispersion, I can simulate the same
>>>>>> number of
>>>>>> >>>>>>>>> zero outcomes (~95%).
>>>>>> >>>>>>>>>
>>>>>> >>>>>>>>> On 23.06.2016 15:50, Thierry Onkelinx wrote:
>>>>>> >>>>>>>>>
>>>>>> >>>>>>>>>> Be careful when using overdispersion to model
>>>>>> zero-inflation.
>>>>>> >>>>>>>>>> Those are two different things.
>>>>>> >>>>>>>>>>
>>>>>> >>>>>>>>>> I've put some information together in
>>>>>> >>>>>>>>>> <http://rpubs.com/INBOstats/zeroinflation>
>>>>>> http://rpubs.com/INBOstats/zeroinflation
>>>>>> >>>>>>>>>>
>>>>>> >>>>>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en
>>>>>> bosonderzoek /
>>>>>> >>>>>>>>>> Research Institute for Nature and Forest team Biometrie &
>>>>>> >>>>>>>>>> Kwaliteitszorg / team Biometrics & Quality Assurance
>>>>>> >>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>>>>> >>>>>>>>>>
>>>>>> >>>>>>>>>> To call in the statistician after the experiment is done
>>>>>> may be
>>>>>> >>>>>>>>>> no more than asking him to perform a post-mortem
>>>>>> examination: he
>>>>>> >>>>>>>>>> may be able to say what the experiment died of. ~ Sir
>>>>>> Ronald
>>>>>> >>>>>>>>>> Aylmer Fisher The plural of anecdote is not data. ~ Roger
>>>>>> >>>>>>>>>> Brinner The combination of some data and an aching desire
>>>>>> for an
>>>>>> >>>>>>>>>> answer does not ensure that a reasonable answer can be
>>>>>> extracted
>>>>>> >>>>>>>>>> from a given body of data. ~ John Tukey
>>>>>> >>>>>>>>>>
>>>>>> >>>>>>>>>> 2016-06-23 12:42 GMT+02:00 Philipp Singer <
>>>>>> <killver at gmail.com>killver at gmail.com
>>>>>> >>>>>>>>>> <mailto: <killver at gmail.com>killver at gmail.com <mailto:
>>>>>> <killver at gmail.com>killver at gmail.com>>>:
>>>>>> >>>>>>>>>>
>>>>>> >>>>>>>>>> Thanks! Actually, accounting for overdispersion is super
>>>>>> >>>>>>>>>> important as it seems, then the zeros can be captured well.
>>>>>> >>>>>>>>>>
>>>>>> >>>>>>>>>>
>>>>>> >>>>>>>>>> On 23.06.2016 11:50, Thierry Onkelinx wrote:
>>>>>> >>>>>>>>>>
>>>>>> >>>>>>>>>>> Dear Philipp,
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>> 1. Fit a Poisson model to the data. 2. Simulate a new
>>>>>> response
>>>>>> >>>>>>>>>>> vector for the dataset according to the model. 3. Count
>>>>>> the
>>>>>> >>>>>>>>>>> number of zero's in the simulated response vector. 4.
>>>>>> Repeat
>>>>>> >>>>>>>>>>> step 2 and 3 a decent number of time and plot a histogram
>>>>>> of
>>>>>> >>>>>>>>>>> the number of zero's in the simulation. If the number of
>>>>>> zero's
>>>>>> >>>>>>>>>>> in the original dataset is larger than those in the
>>>>>> >>>>>>>>>>> simulations, then the model can't capture all zero's. In
>>>>>> such
>>>>>> >>>>>>>>>>> case, first try to update the model and repeat the
>>>>>> procedure.
>>>>>> >>>>>>>>>>> If that fails, look for zero-inflated models.
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>> Best regards,
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en
>>>>>> bosonderzoek /
>>>>>> >>>>>>>>>>> Research Institute for Nature and Forest team Biometrie &
>>>>>> >>>>>>>>>>> Kwaliteitszorg / team Biometrics & Quality Assurance
>>>>>> >>>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>> To call in the statistician after the experiment is done
>>>>>> may
>>>>>> >>>>>>>>>>> be no more than asking him to perform a post-mortem
>>>>>> >>>>>>>>>>> examination: he may be able to say what the experiment
>>>>>> died of.
>>>>>> >>>>>>>>>>> ~ Sir Ronald Aylmer Fisher The plural of anecdote is not
>>>>>> data.
>>>>>> >>>>>>>>>>> ~ Roger Brinner The combination of some data and an aching
>>>>>> >>>>>>>>>>> desire for an answer does not ensure that a reasonable
>>>>>> answer
>>>>>> >>>>>>>>>>> can be extracted from a given body of data. ~ John Tukey
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>> 2016-06-23 11:27 GMT+02:00 Philipp Singer <
>>>>>> <killver at gmail.com>killver at gmail.com
>>>>>> >>>>>>>>>>> <mailto: <killver at gmail.com>killver at gmail.com <mailto:
>>>>>> <killver at gmail.com>killver at gmail.com>>>:
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>> Thanks Thierry - That totally makes sense. Is there some
>>>>>> way of
>>>>>> >>>>>>>>>>> formally checking that, except thinking about the setting
>>>>>> and
>>>>>> >>>>>>>>>>> underlying processes?
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>> On 23.06.2016 11:04, Thierry Onkelinx wrote:
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> Dear Philipp,
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>>> Do you have just lots of zero's, or more zero's than the
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> Poisson
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> distribution can explain? Those are two different things.
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> The example
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> below generates data from a Poisson distribution and has
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> 99% zero's
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> but no zero-inflation. The second example has only 1%
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> zero's but is
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> clearly zero-inflated.
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>>> set.seed(1) n <- 1e8 sim <- rpois(n, lambda = 0.01)
>>>>>> mean(sim
>>>>>> >>>>>>>>>>>> == 0) hist(sim)
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>>> sim.infl <- rbinom(n, size = 1, prob = 0.99) * rpois(n,
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> lambda = 1000)
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> mean(sim.infl == 0) hist(sim.infl)
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>>> So before looking for zero-inflated models, try to model
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> the zero's.
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> Best regards,
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>>> ir. Thierry Onkelinx Instituut voor natuur- en
>>>>>> bosonderzoek /
>>>>>> >>>>>>>>>>>> Research Institute
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> for Nature
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> and Forest team Biometrie & Kwaliteitszorg / team
>>>>>> Biometrics
>>>>>> >>>>>>>>>>>> & Quality
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> Assurance
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> Kliniekstraat 25 1070 Anderlecht Belgium
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>>> To call in the statistician after the experiment is done
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> may be no
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> more than asking him to perform a post-mortem
>>>>>> examination:
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> he may be
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> able to say what the experiment died of. ~ Sir Ronald
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> Aylmer Fisher
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> The plural of anecdote is not data. ~ Roger Brinner The
>>>>>> >>>>>>>>>>>> combination of some data and an aching desire for an
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> answer does
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> not ensure that a reasonable answer can be extracted
>>>>>> from a
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> given body
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> of data. ~ John Tukey
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>>> 2016-06-23 10:07 GMT+02:00 Philipp Singer
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> < <killver at gmail.com>killver at gmail.com <mailto:
>>>>>> <killver at gmail.com>killver at gmail.com>
>>>>>> >>>>>>>>>>> <mailto: <killver at gmail.com>killver at gmail.com <mailto:
>>>>>> <killver at gmail.com>killver at gmail.com>>
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> <mailto: <killver at gmail.com>killver at gmail.com <mailto:
>>>>>> <killver at gmail.com>killver at gmail.com>
>>>>>> >>>>>>>>>>>> <mailto: <killver at gmail.com>killver at gmail.com <mailto:
>>>>>> <killver at gmail.com>killver at gmail.com>>>>:
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>>> Dear group - I am currently fitting a Poisson glmer
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> where I have
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> an excess of outcomes that are zero (>95%). I am now
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> debating on
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> how to proceed and came up with three options:
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>>> 1.) Just fit a regular glmer to the complete data. I am
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> not fully
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> sure how interpret the coefficients then, are they more
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> optimizing
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> towards distinguishing zero and non-zero, or also
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> capturing the
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> differences in those outcomes that are non-zero?
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>>> 2.) Leave all zeros out of the data and fit a glmer to
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> only those
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> outcomes that are non-zero. Then, I would only learn
>>>>>> about
>>>>>> >>>>>>>>>>>> differences in the non-zero outcomes though.
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>>> 3.) Use a zero-inflated Poisson model. My data is quite
>>>>>> >>>>>>>>>>>> large-scale, so I am currently playing around with the EM
>>>>>> >>>>>>>>>>>> implementation of Bolker et al. that alternates between
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> fitting a
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> glmer with data that are weighted according to their zero
>>>>>> >>>>>>>>>>>> probability, and fitting a logistic regression for the
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> probability
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> that a data point is zero. The method is elaborated for
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> the OWL
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> data in:
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>>
>>>>>> <https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf>
>>>>>> https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
>>>>>> >>>>>>>>>>> <
>>>>>> >>>>>>>>>>>
>>>>>> <https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf>
>>>>>> https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
>>>>>> >>>>>>>>>>> >
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>> I am not fully sure how to interpret the results for the
>>>>>> >>>>>>>
>>>>>> >>>>>>>> zero-inflated version though. Would I need to interpret the
>>>>>> >>>>>>>>>>>> coefficients for the result of the glmer similar to as
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> I would do
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> for my idea of 2)? And then on top of that interpret the
>>>>>> >>>>>>>>>>>> coefficients for the logistic regression regarding
>>>>>> whether
>>>>>> >>>>>>>>>>>> something is in the perfect or imperfect state? I am
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> also not
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> quite sure what the common approach for the zformula is
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> here. The
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> OWL elaborations only use zformula=z~1, so no random
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> effect; I
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> would use the same formula as for the glmer.
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>>> I am appreciating some help and pointers.
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>>> Thanks! Philipp
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>>> _______________________________________________
>>>>>> >>>>>>>>>>>> <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org
>>>>>> >>>>>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org>
>>>>>> >>>>>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org>
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org
>>>>>> >>>>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org>>
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org
>>>>>> >>>>>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org>
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org
>>>>>> >>>>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org>>> mailing list
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>>
>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>> >>>>>>>>>>>> <
>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>>>
>>>>>> >>>>>>>>>>>> [[alternative HTML version deleted]]
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>> _______________________________________________
>>>>>> >>>>>>>>>>> <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org
>>>>>> >>>>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org>
>>>>>> >>>>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org>
>>>>>> >>>>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org
>>>>>> >>>>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org>> mailing list
>>>>>> >>>>>>>>>>>
>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>> >>>>>>>>>>> <
>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>>
>>>>>> >>>>>>>>>>> [[alternative HTML version deleted]]
>>>>>> >>>>>>>>>
>>>>>> >>>>>>>>> _______________________________________________
>>>>>> >>>>>>>>> <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org
>>>>>> >>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org>
>>>>>> >>>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org> mailing list
>>>>>> >>>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>> >>>>>>>>> <
>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>> >>>>>>>>>
>>>>>> >>>>>>>> [[alternative HTML version deleted]]
>>>>>> >>>>>>>>
>>>>>> >>>>>>>> _______________________________________________
>>>>>> >>>>>>>> <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org
>>>>>> >>>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org> mailing list
>>>>>> >>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>> >>>>>>>>
>>>>>> >>>>>>>> _______________________________________________
>>>>>> >>>>>>> <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org
>>>>>> >>>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org> mailing list
>>>>>> >>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>> >>>>>>>
>>>>>> >>>>>> _______________________________________________
>>>>>> >>>>>> <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org
>>>>>> >>>>>> <mailto: <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org> mailing list
>>>>>> >>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>> >>>>>>
>>>>>> >>>>>
>>>>>> >>>         [[alternative HTML version deleted]]
>>>>>> >>>
>>>>>> >>> _______________________________________________
>>>>>> >>> <R-sig-mixed-models at r-project.org>
>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>> >>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>> >>>
>>>>>> >>>
>>>>>> >
>>>>>>
>>>>>>         [[alternative HTML version deleted]]
>>>>>>
>>>>>> _______________________________________________
>>>>>> <R-sig-mixed-models at r-project.org>R-sig-mixed-models at r-project.org
>>>>>> mailing list
>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>
>>>>>
>>>>>
>>>>
>>>
>>
>>
>
>

	[[alternative HTML version deleted]]


From killver at gmail.com  Tue Jun 28 10:14:04 2016
From: killver at gmail.com (Philipp Singer)
Date: Tue, 28 Jun 2016 10:14:04 +0200
Subject: [R-sig-ME] Question about zero-inflated Poisson glmer
In-Reply-To: <CAJuCY5wSj-0L5_UcMqVTPmmV+NT-KaYbdrW9Ukiy1NU+iVjj3A@mail.gmail.com>
References: <576B98C4.6000602@gmail.com> <576BBCFD.8040806@gmail.com>
	<CAJuCY5ycRL6oXs=H5JrEqOHWzd1UsvSNVZM6-MK+V2N=pvbyQA@mail.gmail.com>
	<576BFEBC.3020407@gmail.com>
	<B5AEF3F5-949F-4686-82DA-C234C3C4018B@ufl.edu>
	<576C18F9.9010200@gmail.com> <576C200A.1050405@gmail.com>
	<4D07695C-8CEA-4785-A5B0-46B011625DA0@ufl.edu>
	<576D290A.7090102@gmail.com>
	<576D3209.6050507@gmail.com> <576D3864.1060001@gmail.com>
	<576D3B1B.3050908@gmail.com>
	<CAGPhqeohy3hB8hfnNcj=6d_D=mRVG9CWk910qfSEsEnnr0N__A@mail.gmail.com>
	<CAJuCY5wcBboPCe58h2kYPL1+tXwe=5dmVT10n6wFCJSE+7-wnw@mail.gmail.com>
	<CAGPhqeojDg=tXJi+oYMqAqGwCaVxkkhnhV3MBr2e9O2agEeJUA@mail.gmail.com>
	<CAGPhqeok+j2mCtfSBYveSbU1iCzvZjTefeEE8f=uyyH33ctS=w@mail.gmail.com>
	<CAJuCY5xDPr0rBa-cCCT7+_QOefO8UT8AreP_8hMh6siuM6noBA@mail.gmail.com>
	<57714A59.4060806@gmail.com>
	<CAJuCY5yOWstEGO9wiQvrc48bFGtuz0Cfp4tzVQ67+py3rmBk0A@mail.gmail.com>
	<577229AF.5090904@gmail.com>
	<CAJuCY5wSj-0L5_UcMqVTPmmV+NT-KaYbdrW9Ukiy1NU+iVjj3A@mail.gmail.com>
Message-ID: <577231CC.8050604@gmail.com>

You can find a sample of the data here:
https://www.dropbox.com/s/kqqxmc3wp225lug/r_sample.csv.gz?dl=1

You can think of the setting as popularity of items "y" inside stores 
"id" explained by two features "a" and "b" whereas "a" is more of a 
control covariate and I am interested in whether "b" has a positive impact.

The current baseline formula would be "y~1+b+(1|id)". Extending the 
formula does improve the model, but not really my core problem of 
strange predictions e.g., "y~1+b+a+(1|id)" or "y~1+b+a+(1|id)+(0+b|id)". 
My main goal is to make inference on "a", but I cannot really trust the 
significant coefficients due to the model fit.

Thanks a lot for your help again!
Philipp

On 28.06.2016 09:57, Thierry Onkelinx wrote:
> It's hard to tell what's wrong without any knowledge of the model. A 
> reproducible example would be handy.
>
> Some things to check:
> - How strong is the zero-inflation according to the model?
> - What are the fitted values exactly? The response? The predict mean 
> of the counts? The probability of extre zero's?
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature 
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no 
> more than asking him to perform a post-mortem examination: he may be 
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does 
> not ensure that a reasonable answer can be extracted from a given body 
> of data. ~ John Tukey
>
> 2016-06-28 9:39 GMT+02:00 Philipp Singer <killver at gmail.com 
> <mailto:killver at gmail.com>>:
>
>     Unfortunately, if I model the data with a zero-inflated negative
>     binomial model (which appears to be the most appropriate model to
>     me), the fitted values are never zero, but hover around a mean of
>     20, even though, as said, my data contains around 95% zeros.
>
>     I thought about hurdle models as well, but zero-inflated
>     definitely fit the process better.
>
>     On 27.06.2016 21:59, Thierry Onkelinx wrote:
>>     If there is overdispersion, then try a negative binomial model or
>>     a zero-inflated negative binomial model. If not try a
>>     zero-inflated Poisson. Adding relevant covariates can reduce
>>     overdispersion.
>>
>>     ir. Thierry Onkelinx
>>     Instituut voor natuur- en bosonderzoek / Research Institute for
>>     Nature and Forest
>>     team Biometrie & Kwaliteitszorg / team Biometrics & Quality
>>     Assurance
>>     Kliniekstraat 25
>>     1070 Anderlecht
>>     Belgium
>>
>>     To call in the statistician after the experiment is done may be
>>     no more than asking him to perform a post-mortem examination: he
>>     may be able to say what the experiment died of. ~ Sir Ronald
>>     Aylmer Fisher
>>     The plural of anecdote is not data. ~ Roger Brinner
>>     The combination of some data and an aching desire for an answer
>>     does not ensure that a reasonable answer can be extracted from a
>>     given body of data. ~ John Tukey
>>
>>     2016-06-27 17:46 GMT+02:00 Philipp Singer <killver at gmail.com
>>     <mailto:killver at gmail.com>>:
>>
>>         Well, as posted beforehand the std dev is 9.5 ... so does not
>>         seem too good then :/
>>
>>         Any other idea?
>>
>>
>>         On 27.06.2016 17:31, Thierry Onkelinx wrote:
>>>         Dear Philipp,
>>>
>>>         You've been bitten by observation level random effects. I've
>>>         put together a document about it on
>>>         http://rpubs.com/INBOstats/OLRE. Bottomline you're OKish
>>>         when the standard devation of the OLRE smaller than 1.
>>>         You're in trouble when it's above 3. In between you need to
>>>         check the model carefully.
>>>
>>>         Best regards,
>>>
>>>         ir. Thierry Onkelinx
>>>         Instituut voor natuur- en bosonderzoek / Research Institute
>>>         for Nature and Forest
>>>         team Biometrie & Kwaliteitszorg / team Biometrics & Quality
>>>         Assurance
>>>         Kliniekstraat 25
>>>         1070 Anderlecht
>>>         Belgium
>>>
>>>         To call in the statistician after the experiment is done may
>>>         be no more than asking him to perform a post-mortem
>>>         examination: he may be able to say what the experiment died
>>>         of. ~ Sir Ronald Aylmer Fisher
>>>         The plural of anecdote is not data. ~ Roger Brinner
>>>         The combination of some data and an aching desire for an
>>>         answer does not ensure that a reasonable answer can be
>>>         extracted from a given body of data. ~ John Tukey
>>>
>>>         2016-06-27 16:17 GMT+02:00 Philipp Singer <killver at gmail.com
>>>         <mailto:killver at gmail.com>>:
>>>
>>>             Here is the fitted vs. residual plot for the
>>>             observation-level poisson model where the observation
>>>             level has been removed as taken from:
>>>             https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q3/020817.html
>>>
>>>             So basically the prediction is always close to zero.
>>>
>>>             Note that this is just on a very small sample (1000 data
>>>             points).
>>>
>>>             If I fit a nbinom2 to this smalle sample, I get
>>>             predictions that are always around ~20 (but never zero).
>>>             Both plots are attached.
>>>
>>>             What I am wondering is whether I can do inference on a
>>>             fixed parameter in my model which is my main task of
>>>             this study. The effect is similar in the different
>>>             models and in general I am only itnerested in whether it
>>>             is positive/negative and "significant" which it is.
>>>             However, as can be seen, the prediction looks not too
>>>             good here.
>>>
>>>
>>>
>>>
>>>             2016-06-27 15:18 GMT+02:00 Philipp Singer
>>>             <killver at gmail.com <mailto:killver at gmail.com>>:
>>>
>>>                 The variance is:
>>>
>>>                 Conditional model:
>>>                   Groups            Name        Variance  Std.Dev.
>>>                   obs               (Intercept) 8.991e+01 9.4823139
>>>
>>>
>>>
>>>                 2016-06-27 15:06 GMT+02:00 Thierry Onkelinx
>>>                 <thierry.onkelinx at inbo.be
>>>                 <mailto:thierry.onkelinx at inbo.be>>:
>>>
>>>                     Dear Philipp,
>>>
>>>                     How strong is the variance of the observation
>>>                     level random effect? I would trust a model with
>>>                     large OLRE variance.
>>>
>>>                     Best regards,
>>>
>>>                     Thierry
>>>
>>>                     ir. Thierry Onkelinx
>>>                     Instituut voor natuur- en bosonderzoek /
>>>                     Research Institute for Nature and Forest
>>>                     team Biometrie & Kwaliteitszorg / team
>>>                     Biometrics & Quality Assurance
>>>                     Kliniekstraat 25
>>>                     1070 Anderlecht
>>>                     Belgium
>>>
>>>                     To call in the statistician after the experiment
>>>                     is done may be no more than asking him to
>>>                     perform a post-mortem examination: he may be
>>>                     able to say what the experiment died of. ~ Sir
>>>                     Ronald Aylmer Fisher
>>>                     The plural of anecdote is not data. ~ Roger Brinner
>>>                     The combination of some data and an aching
>>>                     desire for an answer does not ensure that a
>>>                     reasonable answer can be extracted from a given
>>>                     body of data. ~ John Tukey
>>>
>>>                     2016-06-27 14:59 GMT+02:00 Philipp Singer
>>>                     <killver at gmail.com <mailto:killver at gmail.com>>:
>>>
>>>                         I have now played around more with the data
>>>                         an the models both using lme4
>>>                         and glmmTMB.
>>>
>>>                         I can report the following:
>>>
>>>                         Modeling the data with a zero-inflated
>>>                         Poisson improves the model
>>>                         significantly. However, when calling predict
>>>                         and simulating rpoissons, I
>>>                         end up with nearly no values that are zero
>>>                         (in the original data there are
>>>                         96% zero).
>>>
>>>                         When I model the data with overdisperion by
>>>                         including an observation-level
>>>                         random effect, I can also improve the model
>>>                         (not surprisingly due to the
>>>                         random effect). When I predict outcomes by
>>>                         ignoring the observation-level
>>>                         random effect (in lme4), I receive bad
>>>                         prediction if I compare it to the
>>>                         original data. While many zeros can be
>>>                         captured (of course), the positive
>>>                         outcomes can not be captured well.
>>>
>>>                         Combining zero inflation and overdispersion
>>>                         further improves the model, but
>>>                         I can only do that with glmmTMB and then
>>>                         have troubles doing predictions
>>>                         ignoring the observation-level random effect.
>>>
>>>                         Another side question:
>>>
>>>                         In lme4, when I do:
>>>
>>>                         m = glm(x~1,family="poisson")
>>>                         rpois(n=len(data),lambda=predict(m,
>>>                         type='response',re.form=NA)
>>>
>>>                         vs.
>>>
>>>                         simulate(1,m,re.form=NA)
>>>
>>>                         I receive different outcomes? Do I
>>>                         understand these function wrongly?
>>>
>>>                         Would appreciate some more help/pointers!
>>>
>>>                         Thanks,
>>>                         Philipp
>>>
>>>                         2016-06-24 15:52 GMT+02:00 Philipp Singer
>>>                         <killver at gmail.com <mailto:killver at gmail.com>>:
>>>
>>>                         > Thanks - I started an issue there to
>>>                         answer some of my questions.
>>>                         >
>>>                         > Regarding the installation: I was trying
>>>                         to somehow do it in anaconda with
>>>                         > a specific R kernel and had some issues. I
>>>                         am trying to resort that with
>>>                         > the anaconda guys though, if I have a
>>>                         tutorial on how to properly setup
>>>                         > glmmTMB in anaconda, I will let you know.
>>>                         The install worked fine in my
>>>                         > standard R environment.
>>>                         >
>>>                         >
>>>                         > On 24.06.2016 15 <tel:24.06.2016%2015>:40,
>>>                         Ben Bolker wrote:
>>>                         >
>>>                         >>  Probably for now the glmmTMB issues page
>>>                         is best.
>>>                         >>
>>>                         >>  When you go there:
>>>                         >>
>>>                         >>    - details on installation
>>>                         problems/hiccups would be useful
>>>                         >>    - a reproducible example for the
>>>                         problem listed below would be useful
>>>                         >>    - dispformula is for allowing
>>>                         dispersion/residual variance to vary
>>>                         >> with covariates (i.e., modeling
>>>                         heteroscedasticity)
>>>                         >>
>>>                         >> cheers
>>>                         >> Ben Bolker
>>>                         >>
>>>                         >>
>>>                         >> On 16-06-24 09:13 AM, Philipp Singer wrote:
>>>                         >>
>>>                         >>> Update, I tried it like that, but
>>>                         receive an error message.
>>>                         >>>
>>>                         >>> Warning message:
>>>                         >>> In nlminb(start = par, objective = fn,
>>>                         gradient = gr): NA/NaN function
>>>                         >>> evaluation
>>>                         >>>
>>>                         >>> Error in solve.default(hessian.fixed):
>>>                         Lapack routine dgesv: system is
>>>                         >>> exactly singular: U[3,3] = 0
>>>                         >>> Traceback:
>>>                         >>>
>>>                         >>> 1. glmmTMB(y ~ 1 + x + (1 | b),
>>>                         >>>   .     data = data, family = "poisson",
>>>                         dispformula = ~1 + x)
>>>                         >>> 2. sdreport(obj)
>>>                         >>> 3. solve(hessian.fixed)
>>>                         >>> 4. solve(hessian.fixed)
>>>                         >>> 5. solve.default(hessian.fixed)
>>>                         >>>
>>>                         >>> Any ideas on that?
>>>                         >>>
>>>                         >>> BTW: Is it fine to post glmmTMB
>>>                         questions here, or should I rather use
>>>                         >>> the github issue page, or is there maybe
>>>                         a dedicated mailing list?
>>>                         >>>
>>>                         >>> Thanks,
>>>                         >>> Philipp
>>>                         >>>
>>>                         >>> On 24.06.2016 14:35, Philipp Singer wrote:
>>>                         >>>
>>>                         >>>> It indeed seems to run quite fast; had
>>>                         some trouble installing, but
>>>                         >>>> works now on my 3.3 R setup.
>>>                         >>>>
>>>                         >>>> One question I have is regarding the
>>>                         specification of dispersion as I
>>>                         >>>> need to specify the dispformula. What
>>>                         is the difference here between
>>>                         >>>> just specifying fixed effects vs. also
>>>                         the random effects?
>>>                         >>>>
>>>                         >>>> On 23.06.2016 23:07, Mollie Brooks wrote:
>>>                         >>>>
>>>                         >>>>> glmmTMB does crossed RE. Ben did some
>>>                         timings in vignette("glmmTMB")
>>>                         >>>>> and it was 2.3 times faster than glmer
>>>                         for one simple GLMM.
>>>                         >>>>>
>>>                         >>>>>
>>>                         >>>>> On 23Jun 2016, at 10:44, Philipp
>>>                         Singer <killver at gmail.com
>>>                         <mailto:killver at gmail.com>> wrote:
>>>                         >>>>>>
>>>                         >>>>>> Did try glmmADMB but unfortunately it
>>>                         is way too slow for my data.
>>>                         >>>>>>
>>>                         >>>>>> Did not know about glmmTMB, will try
>>>                         it out. Does it work with
>>>                         >>>>>> crossed random effects and how does
>>>                         it scale with more data? I will
>>>                         >>>>>> check the docu and try it though.
>>>                         Thanks for the info.
>>>                         >>>>>>
>>>                         >>>>>> On 23.06.2016 19:14, Ben Bolker wrote:
>>>                         >>>>>>
>>>                         >>>>>>>   I would also comment that glmmTMB
>>>                         is likely to be much faster
>>>                         >>>>>>> than the
>>>                         >>>>>>> lme4-based EM approach ...
>>>                         >>>>>>>
>>>                         >>>>>>>   cheers
>>>                         >>>>>>>     Ben B.
>>>                         >>>>>>>
>>>                         >>>>>>> On 16-06-23 12:47 PM, Mollie Brooks
>>>                         wrote:
>>>                         >>>>>>>
>>>                         >>>>>>>> Hi Philipp,
>>>                         >>>>>>>>
>>>                         >>>>>>>> You could also try fitting the
>>>                         model with and without ZI using
>>>                         >>>>>>>> either
>>>                         >>>>>>>> glmmADMB or glmmTMB. Then compare
>>>                         the AICs. I believe model
>>>                         >>>>>>>> selection
>>>                         >>>>>>>> is useful for this, but I could be
>>>                         missing something since the
>>>                         >>>>>>>> simulation procedure that Thierry
>>>                         described seems to recommended
>>>                         >>>>>>>> more
>>>                         >>>>>>>> often.
>>>                         >>>>>>>>
>>>                         >>>>>>>> https://github.com/glmmTMB/glmmTMB
>>>                         >>>>>>>> http://glmmadmb.r-forge.r-project.org
>>>                         >>>>>>>>
>>>                         >>>>>>>> glmmTMB is still in the development
>>>                         phase, but we?ve done a lot of
>>>                         >>>>>>>> testing.
>>>                         >>>>>>>>
>>>                         >>>>>>>> cheers, Mollie
>>>                         >>>>>>>>
>>>                         >>>>>>>> ------------------------ Mollie
>>>                         Brooks, PhD Postdoctoral Researcher,
>>>                         >>>>>>>> Population Ecology Research Group
>>>                         Department of Evolutionary Biology
>>>                         >>>>>>>> & Environmental Studies, University
>>>                         of Z?rich
>>>                         >>>>>>>>
>>>                         http://www.popecol.org/team/mollie-brooks/
>>>                         >>>>>>>>
>>>                         >>>>>>>>
>>>                         >>>>>>>> On 23Jun 2016, at 8:22, Philipp
>>>                         Singer <killver at gmail.com
>>>                         <mailto:killver at gmail.com>> wrote:
>>>                         >>>>>>>>>
>>>                         >>>>>>>>> Thanks, great information, that is
>>>                         really helpful.
>>>                         >>>>>>>>>
>>>                         >>>>>>>>> I agree that those are different
>>>                         things, however when using a
>>>                         >>>>>>>>> random effect for overdispersion,
>>>                         I can simulate the same number of
>>>                         >>>>>>>>> zero outcomes (~95%).
>>>                         >>>>>>>>>
>>>                         >>>>>>>>> On 23.06.2016 15:50, Thierry
>>>                         Onkelinx wrote:
>>>                         >>>>>>>>>
>>>                         >>>>>>>>>> Be careful when using
>>>                         overdispersion to model zero-inflation.
>>>                         >>>>>>>>>> Those are two different things.
>>>                         >>>>>>>>>>
>>>                         >>>>>>>>>> I've put some information together in
>>>                         >>>>>>>>>>
>>>                         http://rpubs.com/INBOstats/zeroinflation
>>>                         >>>>>>>>>>
>>>                         >>>>>>>>>> ir. Thierry Onkelinx Instituut
>>>                         voor natuur- en bosonderzoek /
>>>                         >>>>>>>>>> Research Institute for Nature and
>>>                         Forest team Biometrie &
>>>                         >>>>>>>>>> Kwaliteitszorg / team Biometrics
>>>                         & Quality Assurance
>>>                         >>>>>>>>>> Kliniekstraat 25 1070 Anderlecht
>>>                         Belgium
>>>                         >>>>>>>>>>
>>>                         >>>>>>>>>> To call in the statistician after
>>>                         the experiment is done may be
>>>                         >>>>>>>>>> no more than asking him to
>>>                         perform a post-mortem examination: he
>>>                         >>>>>>>>>> may be able to say what the
>>>                         experiment died of. ~ Sir Ronald
>>>                         >>>>>>>>>> Aylmer Fisher The plural of
>>>                         anecdote is not data. ~ Roger
>>>                         >>>>>>>>>> Brinner The combination of some
>>>                         data and an aching desire for an
>>>                         >>>>>>>>>> answer does not ensure that a
>>>                         reasonable answer can be extracted
>>>                         >>>>>>>>>> from a given body of data. ~ John
>>>                         Tukey
>>>                         >>>>>>>>>>
>>>                         >>>>>>>>>> 2016-06-23 12:42 GMT+02:00
>>>                         Philipp Singer <killver at gmail.com
>>>                         <mailto:killver at gmail.com>
>>>                         >>>>>>>>>> <mailto:killver at gmail.com
>>>                         <mailto:killver at gmail.com>
>>>                         <mailto:killver at gmail.com
>>>                         <mailto:killver at gmail.com>>>>:
>>>                         >>>>>>>>>>
>>>                         >>>>>>>>>> Thanks! Actually, accounting for
>>>                         overdispersion is super
>>>                         >>>>>>>>>> important as it seems, then the
>>>                         zeros can be captured well.
>>>                         >>>>>>>>>>
>>>                         >>>>>>>>>>
>>>                         >>>>>>>>>> On 23.06.2016 11:50, Thierry
>>>                         Onkelinx wrote:
>>>                         >>>>>>>>>>
>>>                         >>>>>>>>>>> Dear Philipp,
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>> 1. Fit a Poisson model to the
>>>                         data. 2. Simulate a new response
>>>                         >>>>>>>>>>> vector for the dataset according
>>>                         to the model. 3. Count the
>>>                         >>>>>>>>>>> number of zero's in the
>>>                         simulated response vector. 4. Repeat
>>>                         >>>>>>>>>>> step 2 and 3 a decent number of
>>>                         time and plot a histogram of
>>>                         >>>>>>>>>>> the number of zero's in the
>>>                         simulation. If the number of zero's
>>>                         >>>>>>>>>>> in the original dataset is
>>>                         larger than those in the
>>>                         >>>>>>>>>>> simulations, then the model
>>>                         can't capture all zero's. In such
>>>                         >>>>>>>>>>> case, first try to update the
>>>                         model and repeat the procedure.
>>>                         >>>>>>>>>>> If that fails, look for
>>>                         zero-inflated models.
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>> Best regards,
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>> ir. Thierry Onkelinx Instituut
>>>                         voor natuur- en bosonderzoek /
>>>                         >>>>>>>>>>> Research Institute for Nature
>>>                         and Forest team Biometrie &
>>>                         >>>>>>>>>>> Kwaliteitszorg / team Biometrics
>>>                         & Quality Assurance
>>>                         >>>>>>>>>>> Kliniekstraat 25 1070 Anderlecht
>>>                         Belgium
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>> To call in the statistician
>>>                         after the experiment is done may
>>>                         >>>>>>>>>>> be no more than asking him to
>>>                         perform a post-mortem
>>>                         >>>>>>>>>>> examination: he may be able to
>>>                         say what the experiment died of.
>>>                         >>>>>>>>>>> ~ Sir Ronald Aylmer Fisher The
>>>                         plural of anecdote is not data.
>>>                         >>>>>>>>>>> ~ Roger Brinner The combination
>>>                         of some data and an aching
>>>                         >>>>>>>>>>> desire for an answer does not
>>>                         ensure that a reasonable answer
>>>                         >>>>>>>>>>> can be extracted from a given
>>>                         body of data. ~ John Tukey
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>> 2016-06-23 11:27 GMT+02:00
>>>                         Philipp Singer <killver at gmail.com
>>>                         <mailto:killver at gmail.com>
>>>                         >>>>>>>>>>> <mailto:killver at gmail.com
>>>                         <mailto:killver at gmail.com>
>>>                         <mailto:killver at gmail.com
>>>                         <mailto:killver at gmail.com>>>>:
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>> Thanks Thierry - That totally
>>>                         makes sense. Is there some way of
>>>                         >>>>>>>>>>> formally checking that, except
>>>                         thinking about the setting and
>>>                         >>>>>>>>>>> underlying processes?
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>> On 23.06.2016 11:04, Thierry
>>>                         Onkelinx wrote:
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>>> Dear Philipp,
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>>> Do you have just lots of
>>>                         zero's, or more zero's than the
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>> Poisson
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>>> distribution can explain? Those
>>>                         are two different things.
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>> The example
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>>> below generates data from a
>>>                         Poisson distribution and has
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>> 99% zero's
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>>> but no zero-inflation. The
>>>                         second example has only 1%
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>> zero's but is
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>>> clearly zero-inflated.
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>>> set.seed(1) n <- 1e8 sim <-
>>>                         rpois(n, lambda = 0.01) mean(sim
>>>                         >>>>>>>>>>>> == 0) hist(sim)
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>>> sim.infl <- rbinom(n, size = 1,
>>>                         prob = 0.99) * rpois(n,
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>> lambda = 1000)
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>>> mean(sim.infl == 0) hist(sim.infl)
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>>> So before looking for
>>>                         zero-inflated models, try to model
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>> the zero's.
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>>> Best regards,
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>>> ir. Thierry Onkelinx Instituut
>>>                         voor natuur- en bosonderzoek /
>>>                         >>>>>>>>>>>> Research Institute
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>> for Nature
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>>> and Forest team Biometrie &
>>>                         Kwaliteitszorg / team Biometrics
>>>                         >>>>>>>>>>>> & Quality
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>> Assurance
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>>> Kliniekstraat 25 1070
>>>                         Anderlecht Belgium
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>>> To call in the statistician
>>>                         after the experiment is done
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>> may be no
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>>> more than asking him to perform
>>>                         a post-mortem examination:
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>> he may be
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>>> able to say what the experiment
>>>                         died of. ~ Sir Ronald
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>> Aylmer Fisher
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>>> The plural of anecdote is not
>>>                         data. ~ Roger Brinner The
>>>                         >>>>>>>>>>>> combination of some data and an
>>>                         aching desire for an
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>> answer does
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>>> not ensure that a reasonable
>>>                         answer can be extracted from a
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>> given body
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>>> of data. ~ John Tukey
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>>> 2016-06-23 10:07 GMT+02:00
>>>                         Philipp Singer
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>> <killver at gmail.com
>>>                         <mailto:killver at gmail.com>
>>>                         <mailto:killver at gmail.com
>>>                         <mailto:killver at gmail.com>>
>>>                         >>>>>>>>>>> <mailto:killver at gmail.com
>>>                         <mailto:killver at gmail.com>
>>>                         <mailto:killver at gmail.com
>>>                         <mailto:killver at gmail.com>>>
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>>> <mailto:killver at gmail.com
>>>                         <mailto:killver at gmail.com>
>>>                         <mailto:killver at gmail.com
>>>                         <mailto:killver at gmail.com>>
>>>                         >>>>>>>>>>>> <mailto:killver at gmail.com
>>>                         <mailto:killver at gmail.com>
>>>                         <mailto:killver at gmail.com
>>>                         <mailto:killver at gmail.com>>>>>:
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>>> Dear group - I am currently
>>>                         fitting a Poisson glmer
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>> where I have
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>>> an excess of outcomes that are
>>>                         zero (>95%). I am now
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>> debating on
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>>> how to proceed and came up with
>>>                         three options:
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>>> 1.) Just fit a regular glmer to
>>>                         the complete data. I am
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>> not fully
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>>> sure how interpret the
>>>                         coefficients then, are they more
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>> optimizing
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>>> towards distinguishing zero and
>>>                         non-zero, or also
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>> capturing the
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>>> differences in those outcomes
>>>                         that are non-zero?
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>>> 2.) Leave all zeros out of the
>>>                         data and fit a glmer to
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>> only those
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>>> outcomes that are non-zero.
>>>                         Then, I would only learn about
>>>                         >>>>>>>>>>>> differences in the non-zero
>>>                         outcomes though.
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>>> 3.) Use a zero-inflated Poisson
>>>                         model. My data is quite
>>>                         >>>>>>>>>>>> large-scale, so I am currently
>>>                         playing around with the EM
>>>                         >>>>>>>>>>>> implementation of Bolker et al.
>>>                         that alternates between
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>> fitting a
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>>> glmer with data that are
>>>                         weighted according to their zero
>>>                         >>>>>>>>>>>> probability, and fitting a
>>>                         logistic regression for the
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>> probability
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>>> that a data point is zero. The
>>>                         method is elaborated for
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>> the OWL
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>>> data in:
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>>
>>>                         https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
>>>                         >>>>>>>>>>> <
>>>                         >>>>>>>>>>>
>>>                         https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/WRITEUP/owls.pdf
>>>                         >>>>>>>>>>> >
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>> I am not fully sure how to
>>>                         interpret the results for the
>>>                         >>>>>>>
>>>                         >>>>>>>> zero-inflated version though. Would
>>>                         I need to interpret the
>>>                         >>>>>>>>>>>> coefficients for the result of
>>>                         the glmer similar to as
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>> I would do
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>>> for my idea of 2)? And then on
>>>                         top of that interpret the
>>>                         >>>>>>>>>>>> coefficients for the logistic
>>>                         regression regarding whether
>>>                         >>>>>>>>>>>> something is in the perfect or
>>>                         imperfect state? I am
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>> also not
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>>> quite sure what the common
>>>                         approach for the zformula is
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>> here. The
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>>> OWL elaborations only use
>>>                         zformula=z~1, so no random
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>> effect; I
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>>> would use the same formula as
>>>                         for the glmer.
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>>> I am appreciating some help and
>>>                         pointers.
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>>> Thanks! Philipp
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>>>
>>>                         _______________________________________________
>>>                         >>>>>>>>>>>>
>>>                         R-sig-mixed-models at r-project.org
>>>                         <mailto:R-sig-mixed-models at r-project.org>
>>>                         >>>>>>>>>>>>
>>>                         <mailto:R-sig-mixed-models at r-project.org
>>>                         <mailto:R-sig-mixed-models at r-project.org>>
>>>                         >>>>>>>>>>>>
>>>                         <mailto:R-sig-mixed-models at r-project.org
>>>                         <mailto:R-sig-mixed-models at r-project.org>>
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>>
>>>                         <mailto:R-sig-mixed-models at r-project.org
>>>                         <mailto:R-sig-mixed-models at r-project.org>
>>>                         >>>>>>>>>>>
>>>                         <mailto:R-sig-mixed-models at r-project.org
>>>                         <mailto:R-sig-mixed-models at r-project.org>>>
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>>>
>>>                         <mailto:R-sig-mixed-models at r-project.org
>>>                         <mailto:R-sig-mixed-models at r-project.org>
>>>                         >>>>>>>>>>>>
>>>                         <mailto:R-sig-mixed-models at r-project.org
>>>                         <mailto:R-sig-mixed-models at r-project.org>>
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>>
>>>                         <mailto:R-sig-mixed-models at r-project.org
>>>                         <mailto:R-sig-mixed-models at r-project.org>
>>>                         >>>>>>>>>>>
>>>                         <mailto:R-sig-mixed-models at r-project.org
>>>                         <mailto:R-sig-mixed-models at r-project.org>>>>
>>>                         mailing list
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>>>
>>>                         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>                         >>>>>>>>>>>>
>>>                         <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>>>
>>>                         >>>>>>>>>>>> [[alternative HTML version
>>>                         deleted]]
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>>
>>>                         _______________________________________________
>>>                         >>>>>>>>>>> R-sig-mixed-models at r-project.org
>>>                         <mailto:R-sig-mixed-models at r-project.org>
>>>                         >>>>>>>>>>>
>>>                         <mailto:R-sig-mixed-models at r-project.org
>>>                         <mailto:R-sig-mixed-models at r-project.org>>
>>>                         >>>>>>>>>>>
>>>                         <mailto:R-sig-mixed-models at r-project.org
>>>                         <mailto:R-sig-mixed-models at r-project.org>>
>>>                         >>>>>>>>>>>
>>>                         <mailto:R-sig-mixed-models at r-project.org
>>>                         <mailto:R-sig-mixed-models at r-project.org>
>>>                         >>>>>>>>>>>
>>>                         <mailto:R-sig-mixed-models at r-project.org
>>>                         <mailto:R-sig-mixed-models at r-project.org>>>
>>>                         mailing list
>>>                         >>>>>>>>>>>
>>>                         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>                         >>>>>>>>>>>
>>>                         <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>>
>>>                         >>>>>>>>>>> [[alternative HTML version deleted]]
>>>                         >>>>>>>>>
>>>                         >>>>>>>>>
>>>                         _______________________________________________
>>>                         >>>>>>>>> R-sig-mixed-models at r-project.org
>>>                         <mailto:R-sig-mixed-models at r-project.org>
>>>                         >>>>>>>>>
>>>                         <mailto:R-sig-mixed-models at r-project.org
>>>                         <mailto:R-sig-mixed-models at r-project.org>>
>>>                         >>>>>>>>>
>>>                         <mailto:R-sig-mixed-models at r-project.org
>>>                         <mailto:R-sig-mixed-models at r-project.org>>
>>>                         mailing list
>>>                         >>>>>>>>>
>>>                         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>                         >>>>>>>>>
>>>                         <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>                         >>>>>>>>>
>>>                         >>>>>>>> [[alternative HTML version deleted]]
>>>                         >>>>>>>>
>>>                         >>>>>>>>
>>>                         _______________________________________________
>>>                         >>>>>>>> R-sig-mixed-models at r-project.org
>>>                         <mailto:R-sig-mixed-models at r-project.org>
>>>                         >>>>>>>>
>>>                         <mailto:R-sig-mixed-models at r-project.org
>>>                         <mailto:R-sig-mixed-models at r-project.org>>
>>>                         mailing list
>>>                         >>>>>>>>
>>>                         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>                         >>>>>>>>
>>>                         >>>>>>>>
>>>                         _______________________________________________
>>>                         >>>>>>> R-sig-mixed-models at r-project.org
>>>                         <mailto:R-sig-mixed-models at r-project.org>
>>>                         >>>>>>>
>>>                         <mailto:R-sig-mixed-models at r-project.org
>>>                         <mailto:R-sig-mixed-models at r-project.org>>
>>>                         mailing list
>>>                         >>>>>>>
>>>                         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>                         >>>>>>>
>>>                         >>>>>>
>>>                         _______________________________________________
>>>                         >>>>>> R-sig-mixed-models at r-project.org
>>>                         <mailto:R-sig-mixed-models at r-project.org>
>>>                         >>>>>>
>>>                         <mailto:R-sig-mixed-models at r-project.org
>>>                         <mailto:R-sig-mixed-models at r-project.org>>
>>>                         mailing list
>>>                         >>>>>>
>>>                         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>                         >>>>>>
>>>                         >>>>>
>>>                         >>>  [[alternative HTML version deleted]]
>>>                         >>>
>>>                         >>>
>>>                         _______________________________________________
>>>                         >>> R-sig-mixed-models at r-project.org
>>>                         <mailto:R-sig-mixed-models at r-project.org>
>>>                         mailing list
>>>                         >>>
>>>                         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>                         >>>
>>>                         >>>
>>>                         >
>>>
>>>                         [[alternative HTML version deleted]]
>>>
>>>                         _______________________________________________
>>>                         R-sig-mixed-models at r-project.org
>>>                         <mailto:R-sig-mixed-models at r-project.org>
>>>                         mailing list
>>>                         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>>
>>>
>>>
>>
>>
>
>


	[[alternative HTML version deleted]]


From David.Duffy at qimrberghofer.edu.au  Tue Jun 28 10:51:26 2016
From: David.Duffy at qimrberghofer.edu.au (David Duffy)
Date: Tue, 28 Jun 2016 18:51:26 +1000
Subject: [R-sig-ME] Question about zero-inflated Poisson glmer
In-Reply-To: <577231CC.8050604@gmail.com>
References: <576B98C4.6000602@gmail.com> <576BFEBC.3020407@gmail.com>
	<B5AEF3F5-949F-4686-82DA-C234C3C4018B@ufl.edu>
	<576C18F9.9010200@gmail.com> <576C200A.1050405@gmail.com>
	<4D07695C-8CEA-4785-A5B0-46B011625DA0@ufl.edu>
	<576D290A.7090102@gmail.com>
	<576D3209.6050507@gmail.com> <576D3864.1060001@gmail.com>
	<576D3B1B.3050908@gmail.com>
	<CAGPhqeohy3hB8hfnNcj=6d_D=mRVG9CWk910qfSEsEnnr0N__A@mail.gmail.com>
	<CAJuCY5wcBboPCe58h2kYPL1+tXwe=5dmVT10n6wFCJSE+7-wnw@mail.gmail.com>
	<CAGPhqeojDg=tXJi+oYMqAqGwCaVxkkhnhV3MBr2e9O2agEeJUA@mail.gmail.com>
	<CAGPhqeok+j2mCtfSBYveSbU1iCzvZjTefeEE8f=uyyH33ctS=w@mail.gmail.com>
	<CAJuCY5xDPr0rBa-cCCT7+_QOefO8UT8AreP_8hMh6siuM6noBA@mail.gmail.com>
	<57714A59.4060806@gmail.com>
	<CAJuCY5yOWstEGO9wiQvrc48bFGtuz0Cfp4tzVQ67+py3rmBk0A@mail.gmail.com>
	<577229AF.5090904@gmail.com>
	<CAJuCY5wSj-0L5_UcMqVTPmmV+NT-KaYbdrW9Ukiy1NU+iVjj3A@mail.gmail.com>
	<577231CC.8050604@gmail.com>
Message-ID: <alpine.LMD.2.00.1606281843230.9398@orpheus.qimr.edu.au>

On Tue, 28 Jun 2016, Philipp Singer wrote:

> You can find a sample of the data here:
> https://www.dropbox.com/s/kqqxmc3wp225lug/r_sample.csv.gz?dl=1
>
> You can think of the setting as popularity of items "y" inside stores 
> "id" explained by two features "a" and "b" whereas "a" is more of a 
> control covariate and I am interested in whether "b" has a positive impact.
>

Probably not very helpful (what a horrible distribution y has), but
library(ordinal)
x$cats <- cut(x$y, c(-1,0,10,100,1000,20000))
c1 <- clmm2(cats ~ a + (1|id), data=x)
c2 <- clmm2(cats ~ a + b + (1|id), data=x)

does run...

Cheers, David Duffy.


From thierry.onkelinx at inbo.be  Tue Jun 28 13:39:37 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 28 Jun 2016 13:39:37 +0200
Subject: [R-sig-ME] Question about zero-inflated Poisson glmer
In-Reply-To: <alpine.LMD.2.00.1606281843230.9398@orpheus.qimr.edu.au>
References: <576B98C4.6000602@gmail.com> <576BFEBC.3020407@gmail.com>
	<B5AEF3F5-949F-4686-82DA-C234C3C4018B@ufl.edu>
	<576C18F9.9010200@gmail.com> <576C200A.1050405@gmail.com>
	<4D07695C-8CEA-4785-A5B0-46B011625DA0@ufl.edu>
	<576D290A.7090102@gmail.com> <576D3209.6050507@gmail.com>
	<576D3864.1060001@gmail.com> <576D3B1B.3050908@gmail.com>
	<CAGPhqeohy3hB8hfnNcj=6d_D=mRVG9CWk910qfSEsEnnr0N__A@mail.gmail.com>
	<CAJuCY5wcBboPCe58h2kYPL1+tXwe=5dmVT10n6wFCJSE+7-wnw@mail.gmail.com>
	<CAGPhqeojDg=tXJi+oYMqAqGwCaVxkkhnhV3MBr2e9O2agEeJUA@mail.gmail.com>
	<CAGPhqeok+j2mCtfSBYveSbU1iCzvZjTefeEE8f=uyyH33ctS=w@mail.gmail.com>
	<CAJuCY5xDPr0rBa-cCCT7+_QOefO8UT8AreP_8hMh6siuM6noBA@mail.gmail.com>
	<57714A59.4060806@gmail.com>
	<CAJuCY5yOWstEGO9wiQvrc48bFGtuz0Cfp4tzVQ67+py3rmBk0A@mail.gmail.com>
	<577229AF.5090904@gmail.com>
	<CAJuCY5wSj-0L5_UcMqVTPmmV+NT-KaYbdrW9Ukiy1NU+iVjj3A@mail.gmail.com>
	<577231CC.8050604@gmail.com>
	<alpine.LMD.2.00.1606281843230.9398@orpheus.qimr.edu.au>
Message-ID: <CAJuCY5y3Qk712XqS-WX--hnPxftWtqeTkhM9xOzJ-Zu_s-=WTQ@mail.gmail.com>

Dear Philipp,

I'm wondering if there is some kind of 'detection limit' in the dataset.
After looking at the data I get the feeling that all values below 10 are
set at zero.
The relation between the counts and the covariates a and b are not linear.
They have an optimum.
The proportion of zero's is not constant but varies with the covariates. So
you need to model that can handle that. Many models assume that the
zero-inflation is constant.

I'd settle for a set of two models: a logistic regression for the zero or
count and a negative binomial for the non-zero counts. A truncate negative
binomial distribution (that doesn't have values below 10) would be ideal.

Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-06-28 10:51 GMT+02:00 David Duffy <David.Duffy at qimrberghofer.edu.au>:

> On Tue, 28 Jun 2016, Philipp Singer wrote:
>
> You can find a sample of the data here:
>> https://www.dropbox.com/s/kqqxmc3wp225lug/r_sample.csv.gz?dl=1
>>
>> You can think of the setting as popularity of items "y" inside stores
>> "id" explained by two features "a" and "b" whereas "a" is more of a control
>> covariate and I am interested in whether "b" has a positive impact.
>>
>>
> Probably not very helpful (what a horrible distribution y has), but
> library(ordinal)
> x$cats <- cut(x$y, c(-1,0,10,100,1000,20000))
> c1 <- clmm2(cats ~ a + (1|id), data=x)
> c2 <- clmm2(cats ~ a + b + (1|id), data=x)
>
> does run...
>
> Cheers, David Duffy.
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From maciej.beresewicz at gmail.com  Tue Jun 28 16:02:06 2016
From: maciej.beresewicz at gmail.com (=?UTF-8?Q?Maciej_Ber=C4=99sewicz?=)
Date: Tue, 28 Jun 2016 16:02:06 +0200
Subject: [R-sig-ME] lme function - fixed sigma - inconsistent results with
 sae and proc mixed results
Message-ID: <CAOj53i_9fSQYP+FceWTATmv17JVwNJ22UcW2qfNXLNoGJ_qdSg@mail.gmail.com>

I would like to estimate Fay-Herriot class models in nlme (small area
models). Basically, these models have fixed random error which is assumed
to be known from sample survey (sampling error). Hence, the model I would
like to specify should have sigma = 1 (it is not estimated).

I have checked new version nlme package (3.1-128) however results are
different from those from sae package and proc mixed when it comes to
fitting a small area model (in particular a Fay-Herriot area model).

I am not sure why these results differ. They should be the same because
sae::eblupFH fits s mixed model with one random effect and fixed residual
variance).

I would be grateful for any help on this matter. Please find the codes to
highlight the problem below.

##############################
## preparation
##############################

library(sae)
library(nlme)
data(milk)
milk$var <- milk$SD^2


##############################
### nlme results
##############################

> m2 <- lme(fixed = yi ~ as.factor(MajorArea),
           random = ~ 1 | SmallArea,
           control = lmeControl(sigma = 1,
                                apVar = T),
           weights = varFixed(~var),
           data = milk)


## variance (not the same as in sae and proc mixed)
0.1332918^2 = 0.0177667

> summary(m2)
Linear mixed-effects model fit by REML
 Data: milk
        AIC       BIC   logLik
  -10.69175 -2.373943 10.34588

Random effects:
 Formula: ~1 | SmallArea
        (Intercept) Residual
StdDev:   0.1332918        1

Variance function:
 Structure: fixed weights
 Formula: ~var
Fixed effects: yi ~ as.factor(MajorArea)
                           Value  Std.Error DF   t-value p-value
(Intercept)            0.9680768 0.06849017 39 14.134537  0.0000
as.factor(MajorArea)2  0.1316132 0.10183884 39  1.292367  0.2038
as.factor(MajorArea)3  0.2269008 0.09126952 39  2.486053  0.0173
as.factor(MajorArea)4 -0.2415905 0.08058755 39 -2.997863  0.0047

##############################
### results based on sae package
##############################

library(sae)
va <- eblupFH(formula = yi ~ as.factor(MajorArea), vardir = var, data =
milk, method = "REML")

> va$fit
$method
[1] "REML"

$convergence
[1] TRUE

$iterations
[1] 4

$estcoef
                            beta  std.error    tvalue       pvalue
(Intercept)            0.9681890 0.06936208 13.958476 2.793443e-44
as.factor(MajorArea)2  0.1327801 0.10300072  1.289119 1.973569e-01
as.factor(MajorArea)3  0.2269462 0.09232981  2.457995 1.397151e-02
as.factor(MajorArea)4 -0.2413011 0.08161707 -2.956503 3.111496e-03

$refvar
[1] 0.01855022

$goodness
   loglike        AIC        BIC        KIC       AICc      AICb1
AICb2       KICc
 12.677478 -15.354956  -6.548956 -10.354956         NA         NA
NA         NA
     KICb1      KICb2 nBootstrap
        NA         NA   0.000000

##############################
### Proc mixed results are consistent with sae
##############################

proc SmallArea data= milk order=data method=reml;
class SmallArea;
weight var;
model y= MajorArea2 MajorArea3  MajorArea4 / cl solution outp=predicted;
random SmallArea;
parms (1) (1) / hold=2;
run;


## Covariance Parameter Estimates
Cov Parm Estimate
SmallArea 0.01855
Residual 1.0000

### fixed effects
Intercept 0.9682
majorarea2 0.1328
majorarea3 0.2269
majorarea3 -0.2413



Best regards,
Maciej

	[[alternative HTML version deleted]]


From wolfgang.viechtbauer at maastrichtuniversity.nl  Tue Jun 28 17:29:01 2016
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Tue, 28 Jun 2016 15:29:01 +0000
Subject: [R-sig-ME] lme function - fixed sigma - inconsistent results
 with sae and proc mixed results
In-Reply-To: <CAOj53i_9fSQYP+FceWTATmv17JVwNJ22UcW2qfNXLNoGJ_qdSg@mail.gmail.com>
References: <CAOj53i_9fSQYP+FceWTATmv17JVwNJ22UcW2qfNXLNoGJ_qdSg@mail.gmail.com>
Message-ID: <e9282ecee47c483e8d27eb3dfd067304@UM-MAIL3216.unimaas.nl>

Since when does lme() in R have the 'sigma' control argument? Ah, since 2015-11-25 (https://cran.r-project.org/web/packages/nlme/ChangeLog). Very interesting!

But apparently this is not giving the right results here. Another check:

library(sae)
library(metafor)
data(milk)
milk$var <- milk$SD^2
res <- rma(yi ~ as.factor(MajorArea), var, data=milk)
res
res$tau2

Yields:

Mixed-Effects Model (k = 43; tau^2 estimator: REML)

tau^2 (estimated amount of residual heterogeneity):     0.0185 (SE = 0.0079)
tau (square root of estimated tau^2 value):             0.1362
I^2 (residual heterogeneity / unaccounted variability): 55.21%
H^2 (unaccounted variability / sampling variability):   2.23
R^2 (amount of heterogeneity accounted for):            65.85%

Test for Residual Heterogeneity: 
QE(df = 39) = 86.1840, p-val < .0001

Test of Moderators (coefficient(s) 2,3,4): 
QM(df = 3) = 46.5699, p-val < .0001

Model Results:

                       estimate      se     zval    pval    ci.lb    ci.ub     
intrcpt                  0.9682  0.0694  13.9585  <.0001   0.8322   1.1041  ***
as.factor(MajorArea)2    0.1328  0.1030   1.2891  0.1974  -0.0691   0.3347     
as.factor(MajorArea)3    0.2269  0.0923   2.4580  0.0140   0.0460   0.4079    *
as.factor(MajorArea)4   -0.2413  0.0816  -2.9565  0.0031  -0.4013  -0.0813   **

---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

> res$tau2
[1] 0.01854996

Same as in 'sae' (rounded to 6 decimals) and SAS.

Not a huge difference to lme(), but larger than one would expect due to numerical differences.

If you switch to method="ML" (for both lme() and rma()), then you get 0.1245693^2 = 0.01551751 for lme() and 0.0155174 for rma(), so that's basically the same.

Best,
Wolfgang

-- 
Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry and    
Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200 MD    
Maastricht, The Netherlands | +31 (43) 388-4170 | http://www.wvbauer.com    

> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org] On Behalf Of Maciej Beresewicz
> Sent: Tuesday, June 28, 2016 16:02
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] lme function - fixed sigma - inconsistent results
> with sae and proc mixed results
> 
> I would like to estimate Fay-Herriot class models in nlme (small area
> models). Basically, these models have fixed random error which is assumed
> to be known from sample survey (sampling error). Hence, the model I would
> like to specify should have sigma = 1 (it is not estimated).
> 
> I have checked new version nlme package (3.1-128) however results are
> different from those from sae package and proc mixed when it comes to
> fitting a small area model (in particular a Fay-Herriot area model).
> 
> I am not sure why these results differ. They should be the same because
> sae::eblupFH fits s mixed model with one random effect and fixed residual
> variance).
> 
> I would be grateful for any help on this matter. Please find the codes to
> highlight the problem below.
> 
> ##############################
> ## preparation
> ##############################
> 
> library(sae)
> library(nlme)
> data(milk)
> milk$var <- milk$SD^2
> 
> 
> ##############################
> ### nlme results
> ##############################
> 
> > m2 <- lme(fixed = yi ~ as.factor(MajorArea),
>            random = ~ 1 | SmallArea,
>            control = lmeControl(sigma = 1,
>                                 apVar = T),
>            weights = varFixed(~var),
>            data = milk)
> 
> 
> ## variance (not the same as in sae and proc mixed)
> 0.1332918^2 = 0.0177667
> 
> > summary(m2)
> Linear mixed-effects model fit by REML
>  Data: milk
>         AIC       BIC   logLik
>   -10.69175 -2.373943 10.34588
> 
> Random effects:
>  Formula: ~1 | SmallArea
>         (Intercept) Residual
> StdDev:   0.1332918        1
> 
> Variance function:
>  Structure: fixed weights
>  Formula: ~var
> Fixed effects: yi ~ as.factor(MajorArea)
>                            Value  Std.Error DF   t-value p-value
> (Intercept)            0.9680768 0.06849017 39 14.134537  0.0000
> as.factor(MajorArea)2  0.1316132 0.10183884 39  1.292367  0.2038
> as.factor(MajorArea)3  0.2269008 0.09126952 39  2.486053  0.0173
> as.factor(MajorArea)4 -0.2415905 0.08058755 39 -2.997863  0.0047
> 
> ##############################
> ### results based on sae package
> ##############################
> 
> library(sae)
> va <- eblupFH(formula = yi ~ as.factor(MajorArea), vardir = var, data =
> milk, method = "REML")
> 
> > va$fit
> $method
> [1] "REML"
> 
> $convergence
> [1] TRUE
> 
> $iterations
> [1] 4
> 
> $estcoef
>                             beta  std.error    tvalue       pvalue
> (Intercept)            0.9681890 0.06936208 13.958476 2.793443e-44
> as.factor(MajorArea)2  0.1327801 0.10300072  1.289119 1.973569e-01
> as.factor(MajorArea)3  0.2269462 0.09232981  2.457995 1.397151e-02
> as.factor(MajorArea)4 -0.2413011 0.08161707 -2.956503 3.111496e-03
> 
> $refvar
> [1] 0.01855022
> 
> $goodness
>    loglike        AIC        BIC        KIC       AICc      AICb1
> AICb2       KICc
>  12.677478 -15.354956  -6.548956 -10.354956         NA         NA
> NA         NA
>      KICb1      KICb2 nBootstrap
>         NA         NA   0.000000
> 
> ##############################
> ### Proc mixed results are consistent with sae
> ##############################
> 
> proc SmallArea data= milk order=data method=reml;
> class SmallArea;
> weight var;
> model y= MajorArea2 MajorArea3  MajorArea4 / cl solution outp=predicted;
> random SmallArea;
> parms (1) (1) / hold=2;
> run;
> 
> ## Covariance Parameter Estimates
> Cov Parm Estimate
> SmallArea 0.01855
> Residual 1.0000
> 
> ### fixed effects
> Intercept 0.9682
> majorarea2 0.1328
> majorarea3 0.2269
> majorarea3 -0.2413
> 
> Best regards,
> Maciej


From maciej.beresewicz at gmail.com  Tue Jun 28 18:16:14 2016
From: maciej.beresewicz at gmail.com (Maciej Beresewicz)
Date: Tue, 28 Jun 2016 18:16:14 +0200
Subject: [R-sig-ME] lme function - fixed sigma - inconsistent results
	with sae and proc mixed results
In-Reply-To: <e9282ecee47c483e8d27eb3dfd067304@UM-MAIL3216.unimaas.nl>
References: <CAOj53i_9fSQYP+FceWTATmv17JVwNJ22UcW2qfNXLNoGJ_qdSg@mail.gmail.com>
	<e9282ecee47c483e8d27eb3dfd067304@UM-MAIL3216.unimaas.nl>
Message-ID: <2E0837F0-C26B-439E-9B51-D88C5E545E5E@gmail.com>

Dear Viechtbauer,

Thanks! So it means that there is difference in terms of REML estimation.

> On 28 Jun 2016, at 17:29, Viechtbauer Wolfgang (STAT) <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
> 
> Since when does lme() in R have the 'sigma' control argument? Ah, since 2015-11-25 (https://cran.r-project.org/web/packages/nlme/ChangeLog). Very interesting!
> 
> But apparently this is not giving the right results here. Another check:
> 
> library(sae)
> library(metafor)
> data(milk)
> milk$var <- milk$SD^2
> res <- rma(yi ~ as.factor(MajorArea), var, data=milk)
> res
> res$tau2
> 
> Yields:
> 
> Mixed-Effects Model (k = 43; tau^2 estimator: REML)
> 
> tau^2 (estimated amount of residual heterogeneity):     0.0185 (SE = 0.0079)
> tau (square root of estimated tau^2 value):             0.1362
> I^2 (residual heterogeneity / unaccounted variability): 55.21%
> H^2 (unaccounted variability / sampling variability):   2.23
> R^2 (amount of heterogeneity accounted for):            65.85%
> 
> Test for Residual Heterogeneity: 
> QE(df = 39) = 86.1840, p-val < .0001
> 
> Test of Moderators (coefficient(s) 2,3,4): 
> QM(df = 3) = 46.5699, p-val < .0001
> 
> Model Results:
> 
>                       estimate      se     zval    pval    ci.lb    ci.ub     
> intrcpt                  0.9682  0.0694  13.9585  <.0001   0.8322   1.1041  ***
> as.factor(MajorArea)2    0.1328  0.1030   1.2891  0.1974  -0.0691   0.3347     
> as.factor(MajorArea)3    0.2269  0.0923   2.4580  0.0140   0.0460   0.4079    *
> as.factor(MajorArea)4   -0.2413  0.0816  -2.9565  0.0031  -0.4013  -0.0813   **
> 
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
> 
>> res$tau2
> [1] 0.01854996
> 
> Same as in 'sae' (rounded to 6 decimals) and SAS.
> 
> Not a huge difference to lme(), but larger than one would expect due to numerical differences.
> 
> If you switch to method="ML" (for both lme() and rma()), then you get 0.1245693^2 = 0.01551751 for lme() and 0.0155174 for rma(), so that's basically the same.
> 
> Best,
> Wolfgang
> 
> -- 
> Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry and    
> Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200 MD    
> Maastricht, The Netherlands | +31 (43) 388-4170 | http://www.wvbauer.com    
> 
>> -----Original Message-----
>> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
>> project.org] On Behalf Of Maciej Beresewicz
>> Sent: Tuesday, June 28, 2016 16:02
>> To: r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] lme function - fixed sigma - inconsistent results
>> with sae and proc mixed results
>> 
>> I would like to estimate Fay-Herriot class models in nlme (small area
>> models). Basically, these models have fixed random error which is assumed
>> to be known from sample survey (sampling error). Hence, the model I would
>> like to specify should have sigma = 1 (it is not estimated).
>> 
>> I have checked new version nlme package (3.1-128) however results are
>> different from those from sae package and proc mixed when it comes to
>> fitting a small area model (in particular a Fay-Herriot area model).
>> 
>> I am not sure why these results differ. They should be the same because
>> sae::eblupFH fits s mixed model with one random effect and fixed residual
>> variance).
>> 
>> I would be grateful for any help on this matter. Please find the codes to
>> highlight the problem below.
>> 
>> ##############################
>> ## preparation
>> ##############################
>> 
>> library(sae)
>> library(nlme)
>> data(milk)
>> milk$var <- milk$SD^2
>> 
>> 
>> ##############################
>> ### nlme results
>> ##############################
>> 
>>> m2 <- lme(fixed = yi ~ as.factor(MajorArea),
>>           random = ~ 1 | SmallArea,
>>           control = lmeControl(sigma = 1,
>>                                apVar = T),
>>           weights = varFixed(~var),
>>           data = milk)
>> 
>> 
>> ## variance (not the same as in sae and proc mixed)
>> 0.1332918^2 = 0.0177667
>> 
>>> summary(m2)
>> Linear mixed-effects model fit by REML
>> Data: milk
>>        AIC       BIC   logLik
>>  -10.69175 -2.373943 10.34588
>> 
>> Random effects:
>> Formula: ~1 | SmallArea
>>        (Intercept) Residual
>> StdDev:   0.1332918        1
>> 
>> Variance function:
>> Structure: fixed weights
>> Formula: ~var
>> Fixed effects: yi ~ as.factor(MajorArea)
>>                           Value  Std.Error DF   t-value p-value
>> (Intercept)            0.9680768 0.06849017 39 14.134537  0.0000
>> as.factor(MajorArea)2  0.1316132 0.10183884 39  1.292367  0.2038
>> as.factor(MajorArea)3  0.2269008 0.09126952 39  2.486053  0.0173
>> as.factor(MajorArea)4 -0.2415905 0.08058755 39 -2.997863  0.0047
>> 
>> ##############################
>> ### results based on sae package
>> ##############################
>> 
>> library(sae)
>> va <- eblupFH(formula = yi ~ as.factor(MajorArea), vardir = var, data =
>> milk, method = "REML")
>> 
>>> va$fit
>> $method
>> [1] "REML"
>> 
>> $convergence
>> [1] TRUE
>> 
>> $iterations
>> [1] 4
>> 
>> $estcoef
>>                            beta  std.error    tvalue       pvalue
>> (Intercept)            0.9681890 0.06936208 13.958476 2.793443e-44
>> as.factor(MajorArea)2  0.1327801 0.10300072  1.289119 1.973569e-01
>> as.factor(MajorArea)3  0.2269462 0.09232981  2.457995 1.397151e-02
>> as.factor(MajorArea)4 -0.2413011 0.08161707 -2.956503 3.111496e-03
>> 
>> $refvar
>> [1] 0.01855022
>> 
>> $goodness
>>   loglike        AIC        BIC        KIC       AICc      AICb1
>> AICb2       KICc
>> 12.677478 -15.354956  -6.548956 -10.354956         NA         NA
>> NA         NA
>>     KICb1      KICb2 nBootstrap
>>        NA         NA   0.000000
>> 
>> ##############################
>> ### Proc mixed results are consistent with sae
>> ##############################
>> 
>> proc SmallArea data= milk order=data method=reml;
>> class SmallArea;
>> weight var;
>> model y= MajorArea2 MajorArea3  MajorArea4 / cl solution outp=predicted;
>> random SmallArea;
>> parms (1) (1) / hold=2;
>> run;
>> 
>> ## Covariance Parameter Estimates
>> Cov Parm Estimate
>> SmallArea 0.01855
>> Residual 1.0000
>> 
>> ### fixed effects
>> Intercept 0.9682
>> majorarea2 0.1328
>> majorarea3 0.2269
>> majorarea3 -0.2413
>> 
>> Best regards,
>> Maciej

Pozdrawiam,
Maciej Beresewicz





	[[alternative HTML version deleted]]


From wolfgang.viechtbauer at maastrichtuniversity.nl  Tue Jun 28 19:14:35 2016
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Tue, 28 Jun 2016 17:14:35 +0000
Subject: [R-sig-ME] lme function - fixed sigma - inconsistent results
 with sae and proc mixed results
Message-ID: <ddc364267d284643ab1e5479db2cdb09@UM-MAIL3216.unimaas.nl>

Correct. Actually, I was very surprised to hear about the 'sigma' control argument being availble in R. That used to be only available in the S-Plus version of lme(). In fact, I just tried running that model in S-Plus and this is what I got:

Linear mixed-effects model fit by REML
 Data: dat 
      AIC      BIC   logLik 
  6.02487 14.34268 1.987565

Random effects:
 Formula:  ~ 1 | SmallArea
        (Intercept) Residual 
StdDev:   0.1361994        1

Variance function:
 Structure: fixed weights
 Formula:  ~ var 
Fixed effects: yi ~ as.factor(MajorArea) 
                           Value  Std.Error DF   t-value p-value 
          (Intercept)  0.9977953 0.03179340 39  31.38373  <.0001
as.factor(MajorArea)1  0.0663901 0.05150041 39   1.28912  0.2050
as.factor(MajorArea)2  0.0535187 0.02659572 39   2.01230  0.0511
as.factor(MajorArea)3 -0.0903025 0.01466646 39  -6.15707  <.0001
 Correlation: 
                      (Intr) a(MA)1 a(MA)2 
as.factor(MajorArea)1  0.075              
as.factor(MajorArea)2 -0.157 -0.060       
as.factor(MajorArea)3 -0.392 -0.054  0.113

Standardized Within-Group Residuals:
       Min         Q1       Med        Q3     Max 
 -1.702152 -0.2304439 0.2200099 0.3981538 1.22415

Number of Observations: 43
Number of Groups: 43 
> 0.1361994^2
[1] 0.01855028

So that matches what we get from the other packages.

I am curious -- why do you want to use lme() for fitting F-H models anyway? Why not stick to 'sae'?

Best,
Wolfgang

> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org] On Behalf Of Maciej Beresewicz
> Sent: Tuesday, June 28, 2016 18:16
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] lme function - fixed sigma - inconsistent results
> with sae and proc mixed results
> 
> Dear Viechtbauer,
> 
> Thanks! So it means that there is difference in terms of REML estimation.
> 
> > On 28 Jun 2016, at 17:29, Viechtbauer Wolfgang (STAT)
> <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
> >
> > Since when does lme() in R have the 'sigma' control argument? Ah, since
> 2015-11-25 (https://cran.r-project.org/web/packages/nlme/ChangeLog). Very
> interesting!
> >
> > But apparently this is not giving the right results here. Another
> check:
> >
> > library(sae)
> > library(metafor)
> > data(milk)
> > milk$var <- milk$SD^2
> > res <- rma(yi ~ as.factor(MajorArea), var, data=milk)
> > res
> > res$tau2
> >
> > Yields:
> >
> > Mixed-Effects Model (k = 43; tau^2 estimator: REML)
> >
> > tau^2 (estimated amount of residual heterogeneity):     0.0185 (SE =
> 0.0079)
> > tau (square root of estimated tau^2 value):             0.1362
> > I^2 (residual heterogeneity / unaccounted variability): 55.21%
> > H^2 (unaccounted variability / sampling variability):   2.23
> > R^2 (amount of heterogeneity accounted for):            65.85%
> >
> > Test for Residual Heterogeneity:
> > QE(df = 39) = 86.1840, p-val < .0001
> >
> > Test of Moderators (coefficient(s) 2,3,4):
> > QM(df = 3) = 46.5699, p-val < .0001
> >
> > Model Results:
> >
> >                       estimate      se     zval    pval    ci.lb
> ci.ub
> > intrcpt                  0.9682  0.0694  13.9585  <.0001   0.8322
> 1.1041  ***
> > as.factor(MajorArea)2    0.1328  0.1030   1.2891  0.1974  -0.0691
> 0.3347
> > as.factor(MajorArea)3    0.2269  0.0923   2.4580  0.0140   0.0460
> 0.4079    *
> > as.factor(MajorArea)4   -0.2413  0.0816  -2.9565  0.0031  -0.4013  -
> 0.0813   **
> >
> > ---
> > Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> >
> >> res$tau2
> > [1] 0.01854996
> >
> > Same as in 'sae' (rounded to 6 decimals) and SAS.
> >
> > Not a huge difference to lme(), but larger than one would expect due to
> numerical differences.
> >
> > If you switch to method="ML" (for both lme() and rma()), then you get
> 0.1245693^2 = 0.01551751 for lme() and 0.0155174 for rma(), so that's
> basically the same.
> >
> > Best,
> > Wolfgang
> >
> > --
> > Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry
> and
> > Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200
> MD
> > Maastricht, The Netherlands | +31 (43) 388-4170 |
> http://www.wvbauer.com
> >
> >> -----Original Message-----
> >> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> >> project.org] On Behalf Of Maciej Beresewicz
> >> Sent: Tuesday, June 28, 2016 16:02
> >> To: r-sig-mixed-models at r-project.org
> >> Subject: [R-sig-ME] lme function - fixed sigma - inconsistent results
> >> with sae and proc mixed results
> >>
> >> I would like to estimate Fay-Herriot class models in nlme (small area
> >> models). Basically, these models have fixed random error which is
> assumed
> >> to be known from sample survey (sampling error). Hence, the model I
> would
> >> like to specify should have sigma = 1 (it is not estimated).
> >>
> >> I have checked new version nlme package (3.1-128) however results are
> >> different from those from sae package and proc mixed when it comes to
> >> fitting a small area model (in particular a Fay-Herriot area model).
> >>
> >> I am not sure why these results differ. They should be the same
> because
> >> sae::eblupFH fits s mixed model with one random effect and fixed
> residual
> >> variance).
> >>
> >> I would be grateful for any help on this matter. Please find the codes
> to
> >> highlight the problem below.
> >>
> >> ##############################
> >> ## preparation
> >> ##############################
> >>
> >> library(sae)
> >> library(nlme)
> >> data(milk)
> >> milk$var <- milk$SD^2
> >>
> >>
> >> ##############################
> >> ### nlme results
> >> ##############################
> >>
> >>> m2 <- lme(fixed = yi ~ as.factor(MajorArea),
> >>           random = ~ 1 | SmallArea,
> >>           control = lmeControl(sigma = 1,
> >>                                apVar = T),
> >>           weights = varFixed(~var),
> >>           data = milk)
> >>
> >>
> >> ## variance (not the same as in sae and proc mixed)
> >> 0.1332918^2 = 0.0177667
> >>
> >>> summary(m2)
> >> Linear mixed-effects model fit by REML
> >> Data: milk
> >>        AIC       BIC   logLik
> >>  -10.69175 -2.373943 10.34588
> >>
> >> Random effects:
> >> Formula: ~1 | SmallArea
> >>        (Intercept) Residual
> >> StdDev:   0.1332918        1
> >>
> >> Variance function:
> >> Structure: fixed weights
> >> Formula: ~var
> >> Fixed effects: yi ~ as.factor(MajorArea)
> >>                           Value  Std.Error DF   t-value p-value
> >> (Intercept)            0.9680768 0.06849017 39 14.134537  0.0000
> >> as.factor(MajorArea)2  0.1316132 0.10183884 39  1.292367  0.2038
> >> as.factor(MajorArea)3  0.2269008 0.09126952 39  2.486053  0.0173
> >> as.factor(MajorArea)4 -0.2415905 0.08058755 39 -2.997863  0.0047
> >>
> >> ##############################
> >> ### results based on sae package
> >> ##############################
> >>
> >> library(sae)
> >> va <- eblupFH(formula = yi ~ as.factor(MajorArea), vardir = var, data
> =
> >> milk, method = "REML")
> >>
> >>> va$fit
> >> $method
> >> [1] "REML"
> >>
> >> $convergence
> >> [1] TRUE
> >>
> >> $iterations
> >> [1] 4
> >>
> >> $estcoef
> >>                            beta  std.error    tvalue       pvalue
> >> (Intercept)            0.9681890 0.06936208 13.958476 2.793443e-44
> >> as.factor(MajorArea)2  0.1327801 0.10300072  1.289119 1.973569e-01
> >> as.factor(MajorArea)3  0.2269462 0.09232981  2.457995 1.397151e-02
> >> as.factor(MajorArea)4 -0.2413011 0.08161707 -2.956503 3.111496e-03
> >>
> >> $refvar
> >> [1] 0.01855022
> >>
> >> $goodness
> >>   loglike        AIC        BIC        KIC       AICc      AICb1
> >> AICb2       KICc
> >> 12.677478 -15.354956  -6.548956 -10.354956         NA         NA
> >> NA         NA
> >>     KICb1      KICb2 nBootstrap
> >>        NA         NA   0.000000
> >>
> >> ##############################
> >> ### Proc mixed results are consistent with sae
> >> ##############################
> >>
> >> proc SmallArea data= milk order=data method=reml;
> >> class SmallArea;
> >> weight var;
> >> model y= MajorArea2 MajorArea3  MajorArea4 / cl solution
> outp=predicted;
> >> random SmallArea;
> >> parms (1) (1) / hold=2;
> >> run;
> >>
> >> ## Covariance Parameter Estimates
> >> Cov Parm Estimate
> >> SmallArea 0.01855
> >> Residual 1.0000
> >>
> >> ### fixed effects
> >> Intercept 0.9682
> >> majorarea2 0.1328
> >> majorarea3 0.2269
> >> majorarea3 -0.2413
> >>
> >> Best regards,
> >> Maciej


From killver at gmail.com  Wed Jun 29 18:31:11 2016
From: killver at gmail.com (Philipp Singer)
Date: Wed, 29 Jun 2016 18:31:11 +0200
Subject: [R-sig-ME] (maxstephalfit) PIRLS step-halvings failed to reduce
 deviance in pwrssUpdate
Message-ID: <5773F7CF.6050202@gmail.com>

After the discussions over the previous few days regarding my count data 
modeling, I am currently following a two-step hurdle model approach 
where my first goal is to model the binary data with a binomial model. 
However, when I incorporate one of my explanatory variables I end up 
with the following error:

Error in eval(expr, envir, enclos): (maxstephalfit) PIRLS step-halvings 
failed to reduce deviance in pwrssUpdate

For the other one, it works fine. Strangely, if I include it also as 
random effect, it also appears to work.

I have also tried to use glmmTMB, and also glmmADMB.

I have also some troubles when modeling the non-zero data with nbinom or 
truncated nbinom.

I have summarized most in a notebook:
http://nbviewer.jupyter.org/gist/psinger/4ec0a84e4c0d73be5add1c9b3109a020

Data can be found here:
https://www.dropbox.com/s/mlwopl18a1heb48/r_sample_1000.csv.gz?dl=1 
<https://www.dropbox.com/s/kqqxmc3wp225lug/r_sample.csv.gz?dl=1>

	[[alternative HTML version deleted]]


From r.travitzki at gmail.com  Thu Jun 30 03:13:10 2016
From: r.travitzki at gmail.com (Rodrigo Travitzki)
Date: Wed, 29 Jun 2016 22:13:10 -0300
Subject: [R-sig-ME] lmer confint() bootstrap doesn't match fitted values
	when weighted
In-Reply-To: <B291F8F571C9494EA3EAF8C8B471333F22E0C28A@WBF-C7001.bk.evdad.admin.ch>
References: <B291F8F571C9494EA3EAF8C8B471333F22E0C28A@WBF-C7001.bk.evdad.admin.ch>
Message-ID: <57747226.6080206@gmail.com>

Dear masters,
I found a strange behaviour in confint() bootstrap methods, maybe 
something with my data, I don't know.

My data is weighted and is something related to it, as you can see in 
code below.

Best,
Rodrigo


## run
## strange behaviour of confint()
#
# R version: 3.3.1
# lme4 version: 1.1-12

require(lme4)

dd=read.csv2(file("http://topicostropicais.net/bau/data.csv"))

m1<-lmer(NOTA~(1|ID_ESCOLA)+(1|ID_TURMA),data=dd,weights=PESO)

## pre conditions seems to be OK
plot(m1)
qqnorm(scale(resid(m1)),ylab="Residual quantiles",col="orange")
qqline(scale(resid(m1)),col="blue")

## reproducing error
VarCorr(m1) # Residual = 46.5197
# with "boot", sigma intervals doesn't match the estimated value 46.5197
confint(m1,method="boot",boot.type="norm")
confint(m1,method="boot",boot.type="basic")
confint(m1,method="boot",boot.type="perc")

## cause seems to be 'weigths'
m2<-lmer(NOTA~(1|ID_ESCOLA)+(1|ID_TURMA),data=dd)
VarCorr(m2)
confint(m2,method="boot")
confint(m2,method="profile")


From bbolker at gmail.com  Thu Jun 30 05:45:56 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 29 Jun 2016 23:45:56 -0400
Subject: [R-sig-ME] lmer confint() bootstrap doesn't match fitted values
 when weighted
In-Reply-To: <57747226.6080206@gmail.com>
References: <B291F8F571C9494EA3EAF8C8B471333F22E0C28A@WBF-C7001.bk.evdad.admin.ch>
	<57747226.6080206@gmail.com>
Message-ID: <577495F4.5080107@gmail.com>


  I'm guessing this is a bug.  Weights have to be specially handled and
we probably missed a step here.  Posted as
https://github.com/lme4/lme4/issues/386 ...

  thanks
    Ben Bolker

On 16-06-29 09:13 PM, Rodrigo Travitzki wrote:
> Dear masters,
> I found a strange behaviour in confint() bootstrap methods, maybe
> something with my data, I don't know.
> 
> My data is weighted and is something related to it, as you can see in
> code below.
> 
> Best,
> Rodrigo
> 
> 
> ## run
> ## strange behaviour of confint()
> #
> # R version: 3.3.1
> # lme4 version: 1.1-12
> 
> require(lme4)
> 
> dd=read.csv2(file("http://topicostropicais.net/bau/data.csv"))
> 
> m1<-lmer(NOTA~(1|ID_ESCOLA)+(1|ID_TURMA),data=dd,weights=PESO)
> 
> ## pre conditions seems to be OK
> plot(m1)
> qqnorm(scale(resid(m1)),ylab="Residual quantiles",col="orange")
> qqline(scale(resid(m1)),col="blue")
> 
> ## reproducing error
> VarCorr(m1) # Residual = 46.5197
> # with "boot", sigma intervals doesn't match the estimated value 46.5197
> confint(m1,method="boot",boot.type="norm")
> confint(m1,method="boot",boot.type="basic")
> confint(m1,method="boot",boot.type="perc")
> 
> ## cause seems to be 'weigths'
> m2<-lmer(NOTA~(1|ID_ESCOLA)+(1|ID_TURMA),data=dd)
> VarCorr(m2)
> confint(m2,method="boot")
> confint(m2,method="profile")
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From newboch at auburn.edu  Thu Jun 30 17:19:40 2016
From: newboch at auburn.edu (Chad Newbolt)
Date: Thu, 30 Jun 2016 15:19:40 +0000
Subject: [R-sig-ME] GLMM, overdispersion,
 and method for comparing competetive models
In-Reply-To: <1467046800121.10945@auburn.edu>
References: <1466798523378.31942@auburn.edu>, <576D9EC7.1080102@gmail.com>,
	<1466888080252.6726@auburn.edu>,<1467046800121.10945@auburn.edu>
Message-ID: <1467299980171.12784@auburn.edu>

Just reaching out one last time to see if anyone has any input regarding the question below.  I'm a bit stuck.  Thanks again for the previous help and I'll explore other outlets for future questions related to this topic if no help is available.

Thanks,

Chad 
________________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Chad Newbolt <newboch at auburn.edu>
Sent: Monday, June 27, 2016 12:00 PM
To: R-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] GLMM, overdispersion, and method for comparing competetive models

I successfully loaded the glmmADMB package using the code below so thanks for that bit of help.

Since I have evidence for overdispersion, I'm using negative binomial distribution as opposed to Poisson.

My two questions are:

1) When I fit using the following global zero inflation model I receive the following error:

fit1=glmmadmb(Fawn~Age+I(Age^2)+BodySize+SSCM+AvgAge+Age*AvgAge+I(Age^2)*AvgAge+BodySize*AvgAge+SSCM*AvgAge+(1|Sire),data=datum,family="nbinom",zeroInflation = TRUE)
Parameters were estimated, but standard errors were not: the most likely problem is that the curvature at MLE was zero or negative
Error in glmmadmb(Fawn ~ Age + I(Age^2) + BodySize + SSCM + AvgAge + Age *  :
  The function maximizer failed (couldn't find parameter file) Troubleshooting steps include (1) run with 'save.dir' set and inspect output files; (2) change run parameters: see '?admbControl';(3) re-run with debug=TRUE for more information on failure mode
In addition: Warning message:
running command 'C:\windows\system32\cmd.exe /c glmmadmb -maxfn 500 -maxph 5 -noinit -shess' had status 1

However, when I change to zeroInflation = FALSE, I receive no warnings and everything seems to go as should.

Does this simply mean that my data is not zero inflated, hence the zero inflated model will not run, or is this something I should be concerned about and investigate the cause further?  When I debug   I see the following warning....Warning -- Hessian does not appear to be positive definite Hessian does not appear to be positive definite.


2) When fitting more simple versions(predictors removed) I receive the same error as above when using the family=nbinom;  however these errors disappear when using family=nbinom1.  Is this indicative of an underlying problem or am I OK to use the ouput from the later family where variance = ??.

Thanks,

Chad


________________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Chad Newbolt <newboch at auburn.edu>
Sent: Saturday, June 25, 2016 3:54 PM
To: R-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] GLMM, overdispersion, and method for comparing competetive models

Thanks.  I'll  take this into consideration and get back to everyone.  Please disregard the other posting that was sent out today containing the exact same content.  I accidentally posted twice during the new member enrolling process.  Sorry and thanks again for the help.

Chad
________________________________________
From: Ben Bolker <bbolker at gmail.com>
Sent: Friday, June 24, 2016 3:57 PM
To: Chad Newbolt; R-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] GLMM, overdispersion, and method for comparing competetive models

  A couple of quick comments:

  (1) try

install.packages(c("R2admb","stringr","plyr","coda"))

  before doing the glmmADMB installation.

  (2) more advice about overdispersion is available at
http://tinyurl.com/glmmFAQ#Overdispersion

 ...

On 16-06-24 04:02 PM, Chad Newbolt wrote:
> All,
>
> I would first like to say that I'm a relative novice with R so please
> take that into consideration with your responses.  Basically, give me
> the totally dumbed down version of answers when you can.
>
> I have a biological data set with count data that I'm currently
> analyzing.  Namely, I'm interested in looking at the effects of
> animal age, bodysize, and antler size on annual male reproductive
> success (i.e. number of fawns produced).  I would also like to see
> how the relationships are influenced by changes in population
> demographics.  I have been using a GLMM to evaluate the following
> global model:
>
> repro =
> glmer(Fawn~Age+I(Age^2)+BodySize+SSCM+AvgAge+Age*AvgAge+I(Age^2)*AvgAge+BodySize*AvgAge+SSCM*AvgAge+(1|Sire),data=datum,family=poisson)
>
>  where:
>
> Age, BodySize, SSCM are measured characteristics Fawn = number of
> fawns produced in a given year AvgAge = Population demographic
> factor (1|Sire) = Random effect for each sampled male ID
>
> I first used the following to evaluate potential overdispersion of my
> data from the global model:
>
> overdisp_fun <- function(model) { ## number of variance parameters
> in ##   an n-by-n variance-covariance matrix vpars <- function(m) {
> nrow(m)*(nrow(m)+1)/2 } model.df <-
> sum(sapply(VarCorr(model),vpars))+length(fixef(model)) rdf <-
> nrow(model.frame(model))-model.df rp <-
> residuals(model,type="pearson") Pearson.chisq <- sum(rp^2) prat <-
> Pearson.chisq/rdf pval <- pchisq(Pearson.chisq, df=rdf,
> lower.tail=FALSE) c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p=pval) }
>
> With the following result
>
> repro =
> glmer(Fawn~Age+I(Age^2)+BodySize+SSCM+AvgAge+Age*AvgAge+I(Age^2)*AvgAge+BodySize*AvgAge+SSCM*AvgAge+(1|Sire),data=datum,family=poisson)
>
>
overdisp_fun(repro)
> chisq                             ratio                          rdf
> p 1.698574e+02      1.681756e+00       1.010000e+02
> 2.169243e-05
>
> Since the ratio of Pearson-statistic to rdf is 1.68 I assume that I
> need to take this overdispersion into account
>
> My first inclination was to use quasipoisson distribution to account
> for overdispersion; however, I see that in no longer available in
> lme4.  I used glmmPQL in the MASS package with quasipoisson but do
> not receive AICc information.  I had planned on using AICc to
> evaluate competitive models.  My specific question is: 1) is there a
> way to generate the necessary information (AICc or something like) to
> compare competitive models from overdispersed data in a current R
> environment? I have read
> https://cran.r-project.org/web/packages/bbmle/vignettes/quasi.pdf but
> I'm having a difficult time understanding exactly how to implement
> from a technical perspective.  I'm on the path of trying to use a
> negative binomial (I'm not locked into this method so please provide
> insight if appropriate) with package glmmADMB: however, I have been
> unable to get this package to load successfully.  I've followed the
> instructions to the best of my understanding and abilities but cannot
> figure out where I'm going wrong.  Any advice is much appreciated as
> I'm totally stumped right now on many fronts.  I'm running windows 7
> on 64-bit machine.  Here is what I have attempted with output:
>
> install.packages("glmmADMB", +
> repos=c("http://glmmadmb.r-forge.r-project.org/repos", +
> getOption("repos")), +     type="source") Installing package into
> ?C:/Users/newboch/Documents/R/win-library/3.3? (as ?lib? is
> unspecified) trying URL
> 'http://glmmadmb.r-forge.r-project.org/repos/src/contrib/glmmADMB_0.8.3.3.tar.gz'
>
>
Content type 'application/x-gzip' length 9391177 bytes (9.0 MB)
> downloaded 9.0 MB * installing *source* package 'glmmADMB' ... ** R
> ** data *** moving datasets to lazyload DB ** inst ** preparing
> package for lazy loading Error in loadNamespace(i, c(lib.loc,
> .libPaths()), versionCheck = vI[[i]]) : there is no package called
> 'stringi' ERROR: lazy loading failed for package 'glmmADMB' *
> removing 'C:/Users/newboch/Documents/R/win-library/3.3/glmmADMB' The
> downloaded source packages are in
> ?C:\Users\newboch\AppData\Local\Temp\RtmpK23VOM\downloaded_packages?
> Warning messages: 1: running command
> '"C:/PROGRA~1/R/R-33~1.1/bin/x64/R" CMD INSTALL -l
> "C:\Users\newboch\Documents\R\win-library\3.3"
> C:\Users\newboch\AppData\Local\Temp\RtmpK23VOM/downloaded_packages/glmmADMB_0.8.3.3.tar.gz'
> had status 1 2: In install.packages("glmmADMB", repos =
> c("http://glmmadmb.r-forge.r-project.org/repos",  : installation of
> package ?glmmADMB? had non-zero exit status
>> glmmADMB:::get_bin_loc()
> Error in loadNamespace(name) : there is no package called ?glmmADMB?
>> library("R2admb") glmmADMB:::get_bin_loc()
> Error in loadNamespace(name) : there is no package called ?glmmADMB?
>> install.packages("glmmADMB")
> Installing package into
> ?C:/Users/newboch/Documents/R/win-library/3.3? (as ?lib? is
> unspecified) Warning message: package ?glmmADMB? is not available
> (for R version 3.3.1) Thanks,
>
> Chad
>
> [[alternative HTML version deleted]]
>
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From killver at gmail.com  Thu Jun 30 17:29:14 2016
From: killver at gmail.com (Philipp Singer)
Date: Thu, 30 Jun 2016 17:29:14 +0200
Subject: [R-sig-ME] GLMM, overdispersion,
 and method for comparing competetive models
In-Reply-To: <1467299980171.12784@auburn.edu>
References: <1466798523378.31942@auburn.edu> <576D9EC7.1080102@gmail.com>
	<1466888080252.6726@auburn.edu> <1467046800121.10945@auburn.edu>
	<1467299980171.12784@auburn.edu>
Message-ID: <CAGPhqeo-HDnU34eOczQyKQ9Diukv+R3PegZ4-OwViijGbvFG=Q@mail.gmail.com>

You can try using https://github.com/glmmTMB/glmmTMB with a negative
binomial. Otherwise you can also use a random observation level effect as
explained in the faq that ben linked.

Generally you already checked for overdispersion indicating that you should
consider it. You can also compare models with anova or AIC/BIC.
On Jun 30, 2016 17:22, "Chad Newbolt" <newboch at auburn.edu> wrote:

> Just reaching out one last time to see if anyone has any input regarding
> the question below.  I'm a bit stuck.  Thanks again for the previous help
> and I'll explore other outlets for future questions related to this topic
> if no help is available.
>
> Thanks,
>
> Chad
> ________________________________________
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on
> behalf of Chad Newbolt <newboch at auburn.edu>
> Sent: Monday, June 27, 2016 12:00 PM
> To: R-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] GLMM, overdispersion, and method for comparing
> competetive models
>
> I successfully loaded the glmmADMB package using the code below so thanks
> for that bit of help.
>
> Since I have evidence for overdispersion, I'm using negative binomial
> distribution as opposed to Poisson.
>
> My two questions are:
>
> 1) When I fit using the following global zero inflation model I receive
> the following error:
>
> fit1=glmmadmb(Fawn~Age+I(Age^2)+BodySize+SSCM+AvgAge+Age*AvgAge+I(Age^2)*AvgAge+BodySize*AvgAge+SSCM*AvgAge+(1|Sire),data=datum,family="nbinom",zeroInflation
> = TRUE)
> Parameters were estimated, but standard errors were not: the most likely
> problem is that the curvature at MLE was zero or negative
> Error in glmmadmb(Fawn ~ Age + I(Age^2) + BodySize + SSCM + AvgAge + Age
> *  :
>   The function maximizer failed (couldn't find parameter file)
> Troubleshooting steps include (1) run with 'save.dir' set and inspect
> output files; (2) change run parameters: see '?admbControl';(3) re-run with
> debug=TRUE for more information on failure mode
> In addition: Warning message:
> running command 'C:\windows\system32\cmd.exe /c glmmadmb -maxfn 500 -maxph
> 5 -noinit -shess' had status 1
>
> However, when I change to zeroInflation = FALSE, I receive no warnings and
> everything seems to go as should.
>
> Does this simply mean that my data is not zero inflated, hence the zero
> inflated model will not run, or is this something I should be concerned
> about and investigate the cause further?  When I debug   I see the
> following warning....Warning -- Hessian does not appear to be positive
> definite Hessian does not appear to be positive definite.
>
>
> 2) When fitting more simple versions(predictors removed) I receive the
> same error as above when using the family=nbinom;  however these errors
> disappear when using family=nbinom1.  Is this indicative of an underlying
> problem or am I OK to use the ouput from the later family where variance =
> ??.
>
> Thanks,
>
> Chad
>
>
> ________________________________________
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on
> behalf of Chad Newbolt <newboch at auburn.edu>
> Sent: Saturday, June 25, 2016 3:54 PM
> To: R-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] GLMM, overdispersion, and method for comparing
> competetive models
>
> Thanks.  I'll  take this into consideration and get back to everyone.
> Please disregard the other posting that was sent out today containing the
> exact same content.  I accidentally posted twice during the new member
> enrolling process.  Sorry and thanks again for the help.
>
> Chad
> ________________________________________
> From: Ben Bolker <bbolker at gmail.com>
> Sent: Friday, June 24, 2016 3:57 PM
> To: Chad Newbolt; R-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] GLMM, overdispersion, and method for comparing
> competetive models
>
>   A couple of quick comments:
>
>   (1) try
>
> install.packages(c("R2admb","stringr","plyr","coda"))
>
>   before doing the glmmADMB installation.
>
>   (2) more advice about overdispersion is available at
> http://tinyurl.com/glmmFAQ#Overdispersion
>
>  ...
>
> On 16-06-24 04:02 PM, Chad Newbolt wrote:
> > All,
> >
> > I would first like to say that I'm a relative novice with R so please
> > take that into consideration with your responses.  Basically, give me
> > the totally dumbed down version of answers when you can.
> >
> > I have a biological data set with count data that I'm currently
> > analyzing.  Namely, I'm interested in looking at the effects of
> > animal age, bodysize, and antler size on annual male reproductive
> > success (i.e. number of fawns produced).  I would also like to see
> > how the relationships are influenced by changes in population
> > demographics.  I have been using a GLMM to evaluate the following
> > global model:
> >
> > repro =
> >
> glmer(Fawn~Age+I(Age^2)+BodySize+SSCM+AvgAge+Age*AvgAge+I(Age^2)*AvgAge+BodySize*AvgAge+SSCM*AvgAge+(1|Sire),data=datum,family=poisson)
> >
> >  where:
> >
> > Age, BodySize, SSCM are measured characteristics Fawn = number of
> > fawns produced in a given year AvgAge = Population demographic
> > factor (1|Sire) = Random effect for each sampled male ID
> >
> > I first used the following to evaluate potential overdispersion of my
> > data from the global model:
> >
> > overdisp_fun <- function(model) { ## number of variance parameters
> > in ##   an n-by-n variance-covariance matrix vpars <- function(m) {
> > nrow(m)*(nrow(m)+1)/2 } model.df <-
> > sum(sapply(VarCorr(model),vpars))+length(fixef(model)) rdf <-
> > nrow(model.frame(model))-model.df rp <-
> > residuals(model,type="pearson") Pearson.chisq <- sum(rp^2) prat <-
> > Pearson.chisq/rdf pval <- pchisq(Pearson.chisq, df=rdf,
> > lower.tail=FALSE) c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p=pval) }
> >
> > With the following result
> >
> > repro =
> >
> glmer(Fawn~Age+I(Age^2)+BodySize+SSCM+AvgAge+Age*AvgAge+I(Age^2)*AvgAge+BodySize*AvgAge+SSCM*AvgAge+(1|Sire),data=datum,family=poisson)
> >
> >
> overdisp_fun(repro)
> > chisq                             ratio                          rdf
> > p 1.698574e+02      1.681756e+00       1.010000e+02
> > 2.169243e-05
> >
> > Since the ratio of Pearson-statistic to rdf is 1.68 I assume that I
> > need to take this overdispersion into account
> >
> > My first inclination was to use quasipoisson distribution to account
> > for overdispersion; however, I see that in no longer available in
> > lme4.  I used glmmPQL in the MASS package with quasipoisson but do
> > not receive AICc information.  I had planned on using AICc to
> > evaluate competitive models.  My specific question is: 1) is there a
> > way to generate the necessary information (AICc or something like) to
> > compare competitive models from overdispersed data in a current R
> > environment? I have read
> > https://cran.r-project.org/web/packages/bbmle/vignettes/quasi.pdf but
> > I'm having a difficult time understanding exactly how to implement
> > from a technical perspective.  I'm on the path of trying to use a
> > negative binomial (I'm not locked into this method so please provide
> > insight if appropriate) with package glmmADMB: however, I have been
> > unable to get this package to load successfully.  I've followed the
> > instructions to the best of my understanding and abilities but cannot
> > figure out where I'm going wrong.  Any advice is much appreciated as
> > I'm totally stumped right now on many fronts.  I'm running windows 7
> > on 64-bit machine.  Here is what I have attempted with output:
> >
> > install.packages("glmmADMB", +
> > repos=c("http://glmmadmb.r-forge.r-project.org/repos", +
> > getOption("repos")), +     type="source") Installing package into
> > ?C:/Users/newboch/Documents/R/win-library/3.3? (as ?lib? is
> > unspecified) trying URL
> > '
> http://glmmadmb.r-forge.r-project.org/repos/src/contrib/glmmADMB_0.8.3.3.tar.gz
> '
> >
> >
> Content type 'application/x-gzip' length 9391177 bytes (9.0 MB)
> > downloaded 9.0 MB * installing *source* package 'glmmADMB' ... ** R
> > ** data *** moving datasets to lazyload DB ** inst ** preparing
> > package for lazy loading Error in loadNamespace(i, c(lib.loc,
> > .libPaths()), versionCheck = vI[[i]]) : there is no package called
> > 'stringi' ERROR: lazy loading failed for package 'glmmADMB' *
> > removing 'C:/Users/newboch/Documents/R/win-library/3.3/glmmADMB' The
> > downloaded source packages are in
> > ?C:\Users\newboch\AppData\Local\Temp\RtmpK23VOM\downloaded_packages?
> > Warning messages: 1: running command
> > '"C:/PROGRA~1/R/R-33~1.1/bin/x64/R" CMD INSTALL -l
> > "C:\Users\newboch\Documents\R\win-library\3.3"
> >
> C:\Users\newboch\AppData\Local\Temp\RtmpK23VOM/downloaded_packages/glmmADMB_0.8.3.3.tar.gz'
> > had status 1 2: In install.packages("glmmADMB", repos =
> > c("http://glmmadmb.r-forge.r-project.org/repos",  : installation of
> > package ?glmmADMB? had non-zero exit status
> >> glmmADMB:::get_bin_loc()
> > Error in loadNamespace(name) : there is no package called ?glmmADMB?
> >> library("R2admb") glmmADMB:::get_bin_loc()
> > Error in loadNamespace(name) : there is no package called ?glmmADMB?
> >> install.packages("glmmADMB")
> > Installing package into
> > ?C:/Users/newboch/Documents/R/win-library/3.3? (as ?lib? is
> > unspecified) Warning message: package ?glmmADMB? is not available
> > (for R version 3.3.1) Thanks,
> >
> > Chad
> >
> > [[alternative HTML version deleted]]
> >
> >
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From newboch at auburn.edu  Thu Jun 30 17:40:44 2016
From: newboch at auburn.edu (Chad Newbolt)
Date: Thu, 30 Jun 2016 15:40:44 +0000
Subject: [R-sig-ME] Negative Binomial in glmmadmb
Message-ID: <1467301244612.45391@auburn.edu>

Based upon the responses I'm receiving it does not appear that some of my responses are being sent in the email chain.  I apologize if this duplicates a previously sent question...





I successfully loaded the glmmADMB package using the code below so thanks to Ben for that bit of help.

Since I have evidence for overdispersion, I'm using negative binomial distribution as opposed to Poisson.

My two questions are:

1) When I fit using the following global zero inflation model I receive the following error:

fit1=glmmadmb(Fawn~Age+I(Age^2)+BodySize+SSCM+AvgAge+Age*AvgAge+I(Age^2)*AvgAge+BodySize*AvgAge+SSCM*AvgAge+(1|Sire),data=datum,family="nbinom",zeroInflation = TRUE)
Parameters were estimated, but standard errors were not: the most likely problem is that the curvature at MLE was zero or negative
Error in glmmadmb(Fawn ~ Age + I(Age^2) + BodySize + SSCM + AvgAge + Age *  :
  The function maximizer failed (couldn't find parameter file) Troubleshooting steps include (1) run with 'save.dir' set and inspect output files; (2) change run parameters: see '?admbControl';(3) re-run with debug=TRUE for more information on failure mode
In addition: Warning message:
running command 'C:\windows\system32\cmd.exe /c glmmadmb -maxfn 500 -maxph 5 -noinit -shess' had status 1

However, when I change to zeroInflation = FALSE, I receive no warnings and everything seems to go as should.

Does this simply mean that my data is not zero inflated, hence the zero inflated model will not run, or is this something I should be concerned about and investigate the cause further?  When I debug   I see the following warning....Warning -- Hessian does not appear to be positive definite Hessian does not appear to be positive definite.


2) When fitting more simple versions(predictors removed) I receive the same error as above when using the family=nbinom;  however these errors disappear when using family=nbinom1.  Is this indicative of an underlying problem or am I OK to use the ouput from the later family where variance = ??.

Thanks,

Chad

	[[alternative HTML version deleted]]


From mteresaoliveira92 at gmail.com  Thu Jun 30 18:40:02 2016
From: mteresaoliveira92 at gmail.com (Teresa Oliveira)
Date: Thu, 30 Jun 2016 17:40:02 +0100
Subject: [R-sig-ME] Overdispersion and R2 in GLMM
Message-ID: <CAPvMryO05ADrZ13v00R+5dSh9YJc4RWysqNQ9F5Gh82R-edvDA@mail.gmail.com>

Dear all,

I want to estimate RSF, and to obtain the relative probabilities I will use
the coefficients obtained with GLMMs. I am new in this so I hope I can
express myself well.
To construct the GLMM's, I am using glmer(). I will to use the MuMIn
package to perform model selection [using dredge()].
I have two doubts:
1) For the top models I get, in order to understand if they are really
meaningful, I need to estimate R2 [r.squaredGLMM()] and to test for
overdispersion [overdisp.glmer() with "RVAideMemoire" package], right? Is
there anything else I must consider (besides de AIC)?

2) How do I interpret the results in both tests?
For a model with all variables I wanted to include (so, before performing
model selection), I estimated R2 and overdispersion.

For overdispersion I got this:
"> overdisp.glmer(lm_set3)
Residual deviance: 8537.397 on 32658 degrees of freedom (ratio: 0.261)"
Which value for ratio is acceptable?

For R2 I got this:
"> r.squaredGLMM(lm_set3)
The result is correct only if all data used by the model has not changed
since model was fitted.
        R2m         R2c
0.006139516 0.788967246 "
Is it normal to get values so different? Should I consider both?

Thank you very much for your time and help!

Best regards,
Teresa

	[[alternative HTML version deleted]]


