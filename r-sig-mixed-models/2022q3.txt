From t|m@co|e @end|ng |rom uc|@@c@uk  Fri Jul  1 11:03:45 2022
From: t|m@co|e @end|ng |rom uc|@@c@uk (Cole, Tim)
Date: Fri, 1 Jul 2022 09:03:45 +0000
Subject: [R-sig-ME] keep.data in lme
Message-ID: <AM6PR01MB5158223B0C419C6517A31706C7BD9@AM6PR01MB5158.eurprd01.prod.exchangelabs.com>

I note that lme has an argument keep.data which saves a copy of data (if it?s a data frame) to the lme object, whereas nlme lacks this argument. I?m curious - does anyone (BB?) know why they are different?

> args(lme)
function (fixed, data = sys.frame(sys.parent()), random, correlation = NULL,
    weights = NULL, subset, method = c("REML", "ML"), na.action = na.fail,
    control = list(), contrasts = NULL, keep.data = TRUE)
NULL
> args(nlme)
function (model, data = sys.frame(sys.parent()), fixed, random = fixed,
    groups, start, correlation = NULL, weights = NULL, subset,
    method = c("ML", "REML"), na.action = na.fail, naPattern,
    control = list(), verbose = FALSE)
NULL

Best wishes,
Tim Cole

Population Policy and Practice
UCL Great Ormond Street Institute of Child Health
30 Guilford Street, London WC1N 1EH


	[[alternative HTML version deleted]]


From dmb@te@ @end|ng |rom gm@||@com  Fri Jul  1 21:07:57 2022
From: dmb@te@ @end|ng |rom gm@||@com (Douglas Bates)
Date: Fri, 1 Jul 2022 14:07:57 -0500
Subject: [R-sig-ME] keep.data in lme
In-Reply-To: <14870_1656666256_0REC00D963V3SO10_AM6PR01MB5158223B0C419C6517A31706C7BD9@AM6PR01MB5158.eurprd01.prod.exchangelabs.com>
References: <14870_1656666256_0REC00D963V3SO10_AM6PR01MB5158223B0C419C6517A31706C7BD9@AM6PR01MB5158.eurprd01.prod.exchangelabs.com>
Message-ID: <CAO7JsnQb38RVgBqd0UmT+gp+OQhquNEF2qwCFJMTgoh_t2F+2Q@mail.gmail.com>

The nlme package predated lme4 by several years and features of lme4 were
never backported to nlme.

On Fri, Jul 1, 2022 at 4:04 AM Cole, Tim <tim.cole at ucl.ac.uk> wrote:

> I note that lme has an argument keep.data which saves a copy of data (if
> it?s a data frame) to the lme object, whereas nlme lacks this argument. I?m
> curious - does anyone (BB?) know why they are different?
>
> > args(lme)
> function (fixed, data = sys.frame(sys.parent()), random, correlation =
> NULL,
>     weights = NULL, subset, method = c("REML", "ML"), na.action = na.fail,
>     control = list(), contrasts = NULL, keep.data = TRUE)
> NULL
> > args(nlme)
> function (model, data = sys.frame(sys.parent()), fixed, random = fixed,
>     groups, start, correlation = NULL, weights = NULL, subset,
>     method = c("ML", "REML"), na.action = na.fail, naPattern,
>     control = list(), verbose = FALSE)
> NULL
>
> Best wishes,
> Tim Cole
>
> Population Policy and Practice
> UCL Great Ormond Street Institute of Child Health
> 30 Guilford Street, London WC1N 1EH
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Sat Jul  2 04:46:05 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 1 Jul 2022 22:46:05 -0400
Subject: [R-sig-ME] keep.data in lme
In-Reply-To: <CAO7JsnQb38RVgBqd0UmT+gp+OQhquNEF2qwCFJMTgoh_t2F+2Q@mail.gmail.com>
References: <14870_1656666256_0REC00D963V3SO10_AM6PR01MB5158223B0C419C6517A31706C7BD9@AM6PR01MB5158.eurprd01.prod.exchangelabs.com>
 <CAO7JsnQb38RVgBqd0UmT+gp+OQhquNEF2qwCFJMTgoh_t2F+2Q@mail.gmail.com>
Message-ID: <6b8a3dae-e29e-b10c-a672-95a84b49a0fb@gmail.com>

    This is a difference between nlme and lme, not between the lme4 and 
nlme packages ... (I don't know why they're different.)

On 7/1/22 3:07 PM, Douglas Bates wrote:
> The nlme package predated lme4 by several years and features of lme4 were
> never backported to nlme.
> 
> On Fri, Jul 1, 2022 at 4:04 AM Cole, Tim <tim.cole at ucl.ac.uk> wrote:
> 
>> I note that lme has an argument keep.data which saves a copy of data (if
>> it?s a data frame) to the lme object, whereas nlme lacks this argument. I?m
>> curious - does anyone (BB?) know why they are different?
>>
>>> args(lme)
>> function (fixed, data = sys.frame(sys.parent()), random, correlation =
>> NULL,
>>      weights = NULL, subset, method = c("REML", "ML"), na.action = na.fail,
>>      control = list(), contrasts = NULL, keep.data = TRUE)
>> NULL
>>> args(nlme)
>> function (model, data = sys.frame(sys.parent()), fixed, random = fixed,
>>      groups, start, correlation = NULL, weights = NULL, subset,
>>      method = c("ML", "REML"), na.action = na.fail, naPattern,
>>      control = list(), verbose = FALSE)
>> NULL
>>
>> Best wishes,
>> Tim Cole
>>
>> Population Policy and Practice
>> UCL Great Ormond Street Institute of Child Health
>> 30 Guilford Street, London WC1N 1EH
>>
>>
>>          [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics


From t|m@co|e @end|ng |rom uc|@@c@uk  Sat Jul  2 08:21:27 2022
From: t|m@co|e @end|ng |rom uc|@@c@uk (Cole, Tim)
Date: Sat, 2 Jul 2022 06:21:27 +0000
Subject: [R-sig-ME] keep.data in lme
In-Reply-To: <CAO7JsnQb38RVgBqd0UmT+gp+OQhquNEF2qwCFJMTgoh_t2F+2Q@mail.gmail.com>
References: <14870_1656666256_0REC00D963V3SO10_AM6PR01MB5158223B0C419C6517A31706C7BD9@AM6PR01MB5158.eurprd01.prod.exchangelabs.com>
 <CAO7JsnQb38RVgBqd0UmT+gp+OQhquNEF2qwCFJMTgoh_t2F+2Q@mail.gmail.com>
Message-ID: <AM6PR01MB5158986CF0B5AA55FF0DAACBC7BC9@AM6PR01MB5158.eurprd01.prod.exchangelabs.com>

Yes, but surely lme and nlme were developed at the same time?

From: Douglas Bates <dmbates at gmail.com>
Date: Friday, 1 July 2022 at 20:08
To: Cole, Tim <tim.cole at ucl.ac.uk>
Cc: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] keep.data in lme

? Caution: External sender

The nlme package predated lme4 by several years and features of lme4 were never backported to nlme.

On Fri, Jul 1, 2022 at 4:04 AM Cole, Tim <tim.cole at ucl.ac.uk<mailto:tim.cole at ucl.ac.uk>> wrote:
I note that lme has an argument keep.data which saves a copy of data (if it?s a data frame) to the lme object, whereas nlme lacks this argument. I?m curious - does anyone (BB?) know why they are different?

> args(lme)
function (fixed, data = sys.frame(sys.parent()), random, correlation = NULL,
    weights = NULL, subset, method = c("REML", "ML"), na.action = na.fail,
    control = list(), contrasts = NULL, keep.data = TRUE)
NULL
> args(nlme)
function (model, data = sys.frame(sys.parent()), fixed, random = fixed,
    groups, start, correlation = NULL, weights = NULL, subset,
    method = c("ML", "REML"), na.action = na.fail, naPattern,
    control = list(), verbose = FALSE)
NULL

Best wishes,
Tim Cole

Population Policy and Practice
UCL Great Ormond Street Institute of Child Health
30 Guilford Street, London WC1N 1EH


        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&data=05%7C01%7Ctim.cole%40ucl.ac.uk%7C5527baf6d88442c781b608da5b950a22%7C1faf88fea9984c5b93c9210a11d9a5c2%7C0%7C0%7C637922992922800142%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=9YxP1AD8iN3jTUe2LgrdjWBMQG8ghLL7KLNC02eEQ0g%3D&reserved=0>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Sun Jul  3 00:14:41 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sat, 2 Jul 2022 18:14:41 -0400
Subject: [R-sig-ME] lme4 package
In-Reply-To: <CAJt0zy9XAb_jq=cYWMhO17ASvq3KuzoW_Jz2QykgA_Z7joDGFA@mail.gmail.com>
References: <CAJt0zy9XAb_jq=cYWMhO17ASvq3KuzoW_Jz2QykgA_Z7joDGFA@mail.gmail.com>
Message-ID: <bfcf6c2f-be61-3937-929f-5a5f91cd9b29@gmail.com>

   There are lots of answers about this on the web:

https://www.google.com/search?q=lme4+%22fixed+effect+model+matrix+is+rank+deficient%22

or to search just the R mailing lists:

https://www.google.com/search?q=site%3Astat.ethz.ch+%22fixed+effect+model+matrix+is+rank+deficient%22

  Some set of your predictors is multicollinear (i.e., one predictor is 
an exact linear combination of some other set of predictors).  This is 
not necessarily a problem.  The most common cause is including a set of 
dummy variables that describe a complete set of possibilities (e.g. if 
you have habitat types A, B, and C, then including a dummy (0/1) 
variable for whether an observation comes from each habitat type will be 
multicollinear.



On 7/1/22 3:56 PM, mina jahan wrote:
>   Hi,
> I want to run a linear mixed-effects model on the simulated data using the
> lme4 package. But after running the R code, I see this error:
> 
> *fixed effect model matrix is rank deficient so dropping 1
> column/coefficient *
> 
> How can I deal with this error?
> I look forward to receiving your reply. Thanks a lot in advance for your
> response.
> 
> Best regards,
> Mina Jahangiri
> Ph.D. student of Biostatistics
> 
> 	[[alternative HTML version deleted]]
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics


From t|bor@k|@@ @end|ng |rom ruhr-un|-bochum@de  Sun Jul  3 17:41:54 2022
From: t|bor@k|@@ @end|ng |rom ruhr-un|-bochum@de (Tibor Kiss)
Date: Sun, 3 Jul 2022 17:41:54 +0200
Subject: [R-sig-ME] Random intercept model with nested effects
Message-ID: <41BC96BF-47FF-4708-B381-D165FDAD022D@ruhr-uni-bochum.de>

Dear list members,

I am struggling with random intercept models with nested random effects. To put it simply: I do not understand why I find influential random effects in a random intercept model that cannot occur with the intercept specification. As an illustration, I am using the _dative_ data set, which is found in _languageR_ and also discussed in Baayen (2009: 278-284).

The two relevant factors are SemanticClass (fixed) and Verb (random). Verbs are sampled from the set of ditransitive verbs, but each verb in this set is a member of one of five semantic classes (SemanticClass = c(a, c, f, p, t). Verbs may also appear in more than one semantic class. In Baayen's (2009) analysis, no nesting is used (perhaps for reasons of exposition), but I assume that explicit nesting must be coded.

In order to make the model somewhat easier to interpret (in comparison to the model in Baayen (2009)), I have changed the levels of two predictors (AccessOfRec and AccessOfTheme) from three to two, and also changed the reference level of SemanticClass to _t_ (which is more plausible given the other reference levels). In addition, I am using a function to extract the random structure and calculate levels of the random effect that stay on one side of 0. The code is below.

The crucial result is shown here: 

##     name_class class names     interc   confint
## 5       feed_t     t  feed -2.0099213 1.6863733
## 8       give_t     t  give -1.1068355 0.3574284
## 12      lend_t     t  lend -2.1997060 1.3972652
## 17     offer_t     t offer -2.2969699 1.7727265
## 18       pay_t     t   pay -2.1214353 0.5253131
## 24      sell_t     t  sell  0.8782523 0.5436892
## 32      take_t     t  take  1.9223862 1.8289943
## 35     write_t     t write  1.8757040 1.3270534
## 40     allow_a     a allow -2.5067738 2.2254017
## 44     bring_a     a bring  1.4675516 1.3846133
## 50        do_a     a    do -2.4082479 1.9457716
## 54      give_a     a  give -1.7403999 0.2911642
## 59     issue_a     a issue  2.7544666 2.3742973
## 65       owe_a     a   owe -2.1404955 1.8719220
## 66       pay_a     a   pay  5.2520666 1.0379571
## 92     teach_c     c teach -2.7920566 1.4288249
## 93      tell_c     c  tell -4.1851336 1.1225658
## 101    offer_f     f offer  2.7622290 1.4753894

Recall that the reference level for SemanticClass is set to _t_. But  in addition to verbs belonging to class _t_, verbs belonging to classes _a_, _c_, and _f_ are listed as influential random effects. This strikes me as mysterious because these verbs cannot occur with the intercept.  

Perhaps there is some logical fallacy in my thinking, but I am not able to identify it and would thus appreciate your comments. 

Thanks in advance


Tibor


# libraries

library(languageR)
library(tidyverse)
library(lme4)

# function to extract relevant random effects

relevant.ranefs <- function(model) {
  randoms <- ranef(model, condVar = T)
  ranefs <- data.frame( names = rownames(randoms[[1]]))
  ranefs$interc = randoms[[1]][,1]
  variances <- attr(randoms[[1]], "postVar")
  ranefs$confint <- 1.96 * sqrt(variances[,,1:length(variances)])
  relevant.ranefs <- subset(ranefs, abs(interc)-confint > 0)

# data manipulation

dative.data <- 
  dative %>%
  mutate(AccessRec = ifelse(AccessOfRec == "given", "given", "non_given"),
         AccessTheme = ifelse(AccessOfTheme == "given", "given", "non_given"),
         SemanticClass = relevel(factor(SemanticClass), ref = "t"),
         AccessRec = relevel(factor(AccessRec), ref = "non_given"),
         DefinOfRec = relevel(factor(DefinOfRec), ref = "indefinite")
         )

# model
dative.glmm3 <- glmer(RealizationOfRecipient ~ AccessRec + AccessTheme + SemanticClass + 
                        PronomOfRec + AnimacyOfRec + AnimacyOfTheme + PronomOfTheme + DefinOfTheme + 
                        DefinOfRec + LengthOfRecipient + LengthOfTheme + Modality +
                        (1| SemanticClass:Verb), 
      data = dative.data, family = "binomial", 
      control = glmerControl(optimizer = "bobyqa", optCtrl=list(maxfun=2e4)))

## Dealing with a convergence warning, as suggested by Ben Bolker

params <- getME(dative.glmm3,c("theta","fixef"))

dative.glmm3 <- 
  update(dative.glmm3,start = params,
         control = glmerControl(optimizer = "bobyqa", optCtrl=list(maxfun=2e4)))

## Convergence warning gone

print(summary(dative.glmm3), corr = FALSE)

# extraction of relevant random effects

dative3.relevant.ranefs <- relevant.ranefs(dative.glmm3)

dative3.relevant.ranefs<-
  dative3.relevant.ranefs %>%
  separate(names, c("class", "names")) %>%
  unite(name_class, c(names, class), remove = FALSE) %>%
  mutate(name_class = factor(name_class, levels = name_class[order(interc, decreasing = TRUE)]))

dative3.relevant.ranefs


?????????
Prof. Dr. Tibor Kiss
Linguistic Data Science Lab
Ruhr-University Bochum



  

From emm@nue|@cur|@ @end|ng |rom p@r|@de@c@rte@@|r  Sun Jul  3 18:37:23 2022
From: emm@nue|@cur|@ @end|ng |rom p@r|@de@c@rte@@|r (Emmanuel Curis)
Date: Sun, 3 Jul 2022 18:37:23 +0200
Subject: [R-sig-ME] Random intercept model with nested effects
In-Reply-To: <41BC96BF-47FF-4708-B381-D165FDAD022D@ruhr-uni-bochum.de>
References: <41BC96BF-47FF-4708-B381-D165FDAD022D@ruhr-uni-bochum.de>
Message-ID: <YsHFw0WcqPL6Q+mC@info124.pharmacie.univ-paris5.fr>

Hello Tibor,

I have two questions about what you are doing:

1) In your model, if I understand correctly, you have a single random
effect, on the intercept; with a single random effect in the model,
what do you mean by "influential random effect" ?  Your code seems to
isolate the realisation of this random effects that are far from the
mean, 0, but since the random effect is expected to be Gaussian, you
expect some of them to be far just by chance, and I'm not clear with
what you are calling the "confidence interval" ?

2) Because the random intercept exists for all lines of your dataset,
there is no reason that only verbs for the reference level should
appear; the fixed effect of SemanticClass adds to the random effect,
but does not replace it.

Your model is, limited to these variables and simplified,
  Y = Y0 + delta * I[ SemanticClass ] + Random effect

where Y0 is the ? mean ? for the t class, delta the correction of the
? mean ? for other classes, and the Random effect is a random variable
which takes a different value for every single verb (eventually
differently for verbs belonging to several semantic classes, assuming
they appear on separate lines, because of the nesting).  Not really
the mean, since you have a logistic regression, but the idea is the
same.

Not sure I understood correctly your problem and model however, but
hope it may help,

?dv?zlettel,

Le Sun, Jul 03, 2022 at 05:41:54PM +0200, Tibor Kiss via R-sig-mixed-models a ?crit :
> Dear list members,
> 
> I am struggling with random intercept models with nested random effects. To put it simply: I do not understand why I find influential random effects in a random intercept model that cannot occur with the intercept specification. As an illustration, I am using the _dative_ data set, which is found in _languageR_ and also discussed in Baayen (2009: 278-284).
> 
> The two relevant factors are SemanticClass (fixed) and Verb (random). Verbs are sampled from the set of ditransitive verbs, but each verb in this set is a member of one of five semantic classes (SemanticClass = c(a, c, f, p, t). Verbs may also appear in more than one semantic class. In Baayen's (2009) analysis, no nesting is used (perhaps for reasons of exposition), but I assume that explicit nesting must be coded.
> 
> In order to make the model somewhat easier to interpret (in comparison to the model in Baayen (2009)), I have changed the levels of two predictors (AccessOfRec and AccessOfTheme) from three to two, and also changed the reference level of SemanticClass to _t_ (which is more plausible given the other reference levels). In addition, I am using a function to extract the random structure and calculate levels of the random effect that stay on one side of 0. The code is below.
> 
> The crucial result is shown here: 
> 
> ##     name_class class names     interc   confint
> ## 5       feed_t     t  feed -2.0099213 1.6863733
> ## 8       give_t     t  give -1.1068355 0.3574284
> ## 12      lend_t     t  lend -2.1997060 1.3972652
> ## 17     offer_t     t offer -2.2969699 1.7727265
> ## 18       pay_t     t   pay -2.1214353 0.5253131
> ## 24      sell_t     t  sell  0.8782523 0.5436892
> ## 32      take_t     t  take  1.9223862 1.8289943
> ## 35     write_t     t write  1.8757040 1.3270534
> ## 40     allow_a     a allow -2.5067738 2.2254017
> ## 44     bring_a     a bring  1.4675516 1.3846133
> ## 50        do_a     a    do -2.4082479 1.9457716
> ## 54      give_a     a  give -1.7403999 0.2911642
> ## 59     issue_a     a issue  2.7544666 2.3742973
> ## 65       owe_a     a   owe -2.1404955 1.8719220
> ## 66       pay_a     a   pay  5.2520666 1.0379571
> ## 92     teach_c     c teach -2.7920566 1.4288249
> ## 93      tell_c     c  tell -4.1851336 1.1225658
> ## 101    offer_f     f offer  2.7622290 1.4753894
> 
> Recall that the reference level for SemanticClass is set to _t_. But  in addition to verbs belonging to class _t_, verbs belonging to classes _a_, _c_, and _f_ are listed as influential random effects. This strikes me as mysterious because these verbs cannot occur with the intercept.  
> 
> Perhaps there is some logical fallacy in my thinking, but I am not able to identify it and would thus appreciate your comments. 
> 
> Thanks in advance
> 
> 
> Tibor
> 
> 
> # libraries
> 
> library(languageR)
> library(tidyverse)
> library(lme4)
> 
> # function to extract relevant random effects
> 
> relevant.ranefs <- function(model) {
>   randoms <- ranef(model, condVar = T)
>   ranefs <- data.frame( names = rownames(randoms[[1]]))
>   ranefs$interc = randoms[[1]][,1]
>   variances <- attr(randoms[[1]], "postVar")
>   ranefs$confint <- 1.96 * sqrt(variances[,,1:length(variances)])
>   relevant.ranefs <- subset(ranefs, abs(interc)-confint > 0)
> 
> # data manipulation
> 
> dative.data <- 
>   dative %>%
>   mutate(AccessRec = ifelse(AccessOfRec == "given", "given", "non_given"),
>          AccessTheme = ifelse(AccessOfTheme == "given", "given", "non_given"),
>          SemanticClass = relevel(factor(SemanticClass), ref = "t"),
>          AccessRec = relevel(factor(AccessRec), ref = "non_given"),
>          DefinOfRec = relevel(factor(DefinOfRec), ref = "indefinite")
>          )
> 
> # model
> dative.glmm3 <- glmer(RealizationOfRecipient ~ AccessRec + AccessTheme + SemanticClass + 
>                         PronomOfRec + AnimacyOfRec + AnimacyOfTheme + PronomOfTheme + DefinOfTheme + 
>                         DefinOfRec + LengthOfRecipient + LengthOfTheme + Modality +
>                         (1| SemanticClass:Verb), 
>       data = dative.data, family = "binomial", 
>       control = glmerControl(optimizer = "bobyqa", optCtrl=list(maxfun=2e4)))
> 
> ## Dealing with a convergence warning, as suggested by Ben Bolker
> 
> params <- getME(dative.glmm3,c("theta","fixef"))
> 
> dative.glmm3 <- 
>   update(dative.glmm3,start = params,
>          control = glmerControl(optimizer = "bobyqa", optCtrl=list(maxfun=2e4)))
> 
> ## Convergence warning gone
> 
> print(summary(dative.glmm3), corr = FALSE)
> 
> # extraction of relevant random effects
> 
> dative3.relevant.ranefs <- relevant.ranefs(dative.glmm3)
> 
> dative3.relevant.ranefs<-
>   dative3.relevant.ranefs %>%
>   separate(names, c("class", "names")) %>%
>   unite(name_class, c(names, class), remove = FALSE) %>%
>   mutate(name_class = factor(name_class, levels = name_class[order(interc, decreasing = TRUE)]))
> 
> dative3.relevant.ranefs
> 
> 
> ?????????
> Prof. Dr. Tibor Kiss
> Linguistic Data Science Lab
> Ruhr-University Bochum
> 
> 
> 
>   
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From h@@|be@k@hr@m@n @end|ng |rom mq@edu@@u  Tue Jul  5 14:14:43 2022
From: h@@|be@k@hr@m@n @end|ng |rom mq@edu@@u (Hasibe Kahraman)
Date: Tue, 5 Jul 2022 12:14:43 +0000
Subject: [R-sig-ME] significance level in lme4 and lmerTest
Message-ID: <SY4PR01MB83410CDC9711334334253002AF819@SY4PR01MB8341.ausprd01.prod.outlook.com>

Hello,

I used the lme4 package for modelling my data and ANOVA Type III (Version 3.0-12; Fox & Weisberg, 2019). I reported the results of LME analyses in my manuscript (see below):
The main effects of group and prime type were significant (F(1,139.02)=6.5005, p=.011; F(2,197.66)=8.5271, p<.001, respectively), with a robust two-way interaction between Group and Prime Type (F(2,190.45)=11.9593, p<.0001)


However, one reviewer asked that I should specify which p-value is my "significance" level. Therefore, could I possibly learn whether it is set to .05 or .01?

Thanks,
Hasibe

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Tue Jul  5 15:00:25 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 5 Jul 2022 09:00:25 -0400
Subject: [R-sig-ME] significance level in lme4 and lmerTest
In-Reply-To: <SY4PR01MB83410CDC9711334334253002AF819@SY4PR01MB8341.ausprd01.prod.outlook.com>
References: <SY4PR01MB83410CDC9711334334253002AF819@SY4PR01MB8341.ausprd01.prod.outlook.com>
Message-ID: <c43bb63d-c3d9-6da0-ba65-e180ba2c732d@gmail.com>

    These packages (lme4, lmerTest, car) follow the general R convention 
of reporting p-values but not specifying an accept/reject threshold for 
you.  When you say "the effects were significant", it is *you* making 
the decision about what threshold to use (unless you're using some other 
package, such as 'report', which might apply a cut-off for you). Either 
you or some other code you used has also done the rounding of p-values 
(to <.001, <.0001); for very small values (<2e-16) R doesn't show the 
exact p-value by default, but otherwise it does.

   (Since you are reporting an effect with a p-value of slightly greater 
than 0.01 as significant, *presumably* you are using an alpha/rejection 
threshold of 0.05, but it's not R doing it ...)

   If you can give us more detail about what you did, we might be able 
to help further, but that's all we (or at least I) can say for now.

On 7/5/22 8:14 AM, Hasibe Kahraman wrote:
> Hello,
> 
> I used the lme4 package for modelling my data and ANOVA Type III (Version 3.0-12; Fox & Weisberg, 2019). I reported the results of LME analyses in my manuscript (see below):
> The main effects of group and prime type were significant (F(1,139.02)=6.5005, p=.011; F(2,197.66)=8.5271, p<.001, respectively), with a robust two-way interaction between Group and Prime Type (F(2,190.45)=11.9593, p<.0001)
> 
> 
> However, one reviewer asked that I should specify which p-value is my "significance" level. Therefore, could I possibly learn whether it is set to .05 or .01?
> 
> Thanks,
> Hasibe
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics


From emm@nue|@cur|@ @end|ng |rom p@r|@de@c@rte@@|r  Tue Jul  5 15:02:50 2022
From: emm@nue|@cur|@ @end|ng |rom p@r|@de@c@rte@@|r (Emmanuel Curis)
Date: Tue, 5 Jul 2022 15:02:50 +0200
Subject: [R-sig-ME] significance level in lme4 and lmerTest
In-Reply-To: <SY4PR01MB83410CDC9711334334253002AF819@SY4PR01MB8341.ausprd01.prod.outlook.com>
References: <SY4PR01MB83410CDC9711334334253002AF819@SY4PR01MB8341.ausprd01.prod.outlook.com>
Message-ID: <YsQ2ejM9cdd3/MI7@info124.pharmacie.univ-paris5.fr>

Hello Hasibe,

The choice of a significance level is up to you. It is entirely your
decision, but should be done *before* any analysis is done (even
before doing the experiment, ideally).

Best regards,

Le Tue, Jul 05, 2022 at 12:14:43PM +0000, Hasibe Kahraman a ?crit :
> Hello,
> 
> I used the lme4 package for modelling my data and ANOVA Type III (Version 3.0-12; Fox & Weisberg, 2019). I reported the results of LME analyses in my manuscript (see below):
> The main effects of group and prime type were significant (F(1,139.02)=6.5005, p=.011; F(2,197.66)=8.5271, p<.001, respectively), with a robust two-way interaction between Group and Prime Type (F(2,190.45)=11.9593, p<.0001)
> 
> 
> However, one reviewer asked that I should specify which p-value is my "significance" level. Therefore, could I possibly learn whether it is set to .05 or .01?
> 
> Thanks,
> Hasibe
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From j|ox @end|ng |rom mcm@@ter@c@  Tue Jul  5 15:04:41 2022
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Tue, 5 Jul 2022 09:04:41 -0400
Subject: [R-sig-ME] significance level in lme4 and lmerTest
In-Reply-To: <8077_1657025311_265CmVEb021205_SY4PR01MB83410CDC9711334334253002AF819@SY4PR01MB8341.ausprd01.prod.outlook.com>
References: <8077_1657025311_265CmVEb021205_SY4PR01MB83410CDC9711334334253002AF819@SY4PR01MB8341.ausprd01.prod.outlook.com>
Message-ID: <da4429b5-9c46-5379-3233-e37dd298f695@mcmaster.ca>

Dear Hasibe,

On 2022-07-05 8:14 a.m., Hasibe Kahraman wrote:
> Hello,
> 
> I used the lme4 package for modelling my data and ANOVA Type III (Version 3.0-12; Fox & Weisberg, 2019). I reported the results of LME analyses in my manuscript (see below):
> The main effects of group and prime type were significant (F(1,139.02)=6.5005, p=.011; F(2,197.66)=8.5271, p<.001, respectively), with a robust two-way interaction between Group and Prime Type (F(2,190.45)=11.9593, p<.0001)
> 
> 
> However, one reviewer asked that I should specify which p-value is my "significance" level. Therefore, could I possibly learn whether it is set to .05 or .01?

This is really a statistical question and not a software question. 
lmerTest::anova() (which you mention in the subject of your message) and 
car::Anova() (which you appear to reference in the body of your message) 
both report p-values. If you have an alpha level for the tests, you 
should simply say what it is. Since you consider p = .011 "significant," 
the alpha level you have in mind is apparently .05.

I hesitate to probe below the surface, for example, to ask whether you 
coded contrasts correctly to get type-III tests from Anova() or whether 
you're really interested in the main effects in light of the interactions.

I hope this helps,
  John

> 
> Thanks,
> Hasibe
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
-- 
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/


From k|m@co|yv@@ @end|ng |rom newc@@t|e@edu@@u  Wed Jul  6 02:49:33 2022
From: k|m@co|yv@@ @end|ng |rom newc@@t|e@edu@@u (Kim Colyvas)
Date: Wed, 6 Jul 2022 00:49:33 +0000
Subject: [R-sig-ME] Dependence of difference on mean level
Message-ID: <SY4P282MB1915D8839D322FCE67559BBFD6809@SY4P282MB1915.AUSP282.PROD.OUTLOOK.COM>

I am analysing data from a study comparing 3 methods of assessing total daily nutritional intake for a person.
The study design called for 3 measurements (one per day), to be taken in the first week using method 1 (photographic recording of all meals with computer aided assessment), and similarly 3 measurements in the second week using method 2 (24 hr recall) and 3 measurements in the 3rd week using method 3 (where method 3 is method 1 repeated). The study design was not ideal for comparing methods but was the best that could be done given the practicalities of the situation.

I fitted a mixed model with 2 random effects, the first being participant to account for differences between people in daily intake and the second being week by participant to capture week to week variations in intake. The residual term representing day to day variation in daily intake as well as measurement error. The variable method (3 levels) was fit as a fixed effect to assess if there was a difference (bias) between methods. The analyses I have done indicate there is. I was happy with this till I began to wonder if the size of the bias varied with the level of intake. Would the size of the difference between methods be greater when the daily intake was large compared to when it was smaller?

What I would like help with is
a) whether there is a way that can I adapt the mixed model approach to test for the dependence of the difference between methods on the intake level (e.g. mean intake per person could be represented by the participant random effect) and
b) have a formal statistical test for whether the difference is constant or varies as a function of the intake level and
b) a reference to support the approach.

I chose a method that I thought would be suitable but I have no references to support it and I have become increasingly uneasy about the validity of what I did. My alternative was to average all measurements for a participant (not always 9 days of data due to various kinds of losses) and use that to represent a participant?s intake level. The mixed model was then modified by dropping the participant random effect and replacing it with a fixed effect in the model using the mean intake as a covariate. The second random effect (week by participant) was retained in the model. This model was equivalent to the parallel slopes model used when carrying out ANCOVA. Then the dependence of the size of the difference between methods was tested by adding an interaction term between method and mean intake to provide a test for differences between slopes. I found in several cases this term was significant indicating that the bias between methods was dependent on the mean level of a person?s intake. If there was a reference that validates this approach I would be happy with that as a solution.

Thanks,
Kim Colyvas

	[[alternative HTML version deleted]]


From rodr|gojur@m|d@m @end|ng |rom hotm@||@com  Sat Jul  9 04:29:34 2022
From: rodr|gojur@m|d@m @end|ng |rom hotm@||@com (Rodrigo Cabrera da Silva)
Date: Sat, 9 Jul 2022 02:29:34 +0000
Subject: [R-sig-ME] I need help with a GLMM
Message-ID: <CP4P284MB12522AAF25A95688AF7DD307C5859@CP4P284MB1252.BRAP284.PROD.OUTLOOK.COM>

Hello, dear. How are you. There is long since I have been trying to solve a doubt about diference between nested and crossed random effects within my study. So I am here to ask and seek for some information. I analysed in a study whether built-up areas density and open waters features quantity variation influence on breeding spot?s density of A. aegypti in municipality of Campo Grande urban area. I have applied Generalized Linear Mixed Models to test this effect from explanatory variables (NDBI and MNDWI) on features density of A. aegypti.
At the same time I have sorted neighborhoods and months/year as the random factors, and in this context we can always find the same set of Campo Grande's neighborhoods from where data were collected along different months and years (although inside a few years, or more often, a few months are found repetead).
So, according to this experimental design, I need to know, how can I sort these randon effects?

	[[alternative HTML version deleted]]


From @nu@e@ke||nen @end|ng |rom |d|v@de  Mon Jul 11 11:35:37 2022
From: @nu@e@ke||nen @end|ng |rom |d|v@de (Eskelinen, Anu)
Date: Mon, 11 Jul 2022 09:35:37 +0000
Subject: [R-sig-ME] defining nested and crossed random effects in glmer
Message-ID: <f0362307d58142daac6194338ee00b34@idiv.de>

Hello,

I have a question related to defining a random formula in a mixed effects model in glmer. I would be grateful for any help from this expert community. Thanks a lot already in advance!

My question relates to ecological plant species data from a full-factorial experiment with four treatments. In the experiment, treatment 1 is nested within treatments 2 and 3, and treatments 2 and 3 are nested within treatment 4. All treatments have two levels (manipulation, no manipulation). Treatment 1 subplots (manipulation, no manipulation) are next to each other (paired), forming bigger plots that receive a combination of treatments 2 and 3. These plots are arranged in groups of four (called blocks) that receive treatment 4. Pretty complex experiment, yes, as many ecological questions are complex.

My question concerns the following analysis. We have calculated a binary 0-1 response variable between the subplots for plant species that occur in the subplots. We call this ?species responsiveness to treatment 1?. We then explain this ?species responsiveness to treatment 1? by treatments 2, 3 and 4, and by an additional continuous variable which is a trait that describes some characteristics of the species. The main question is to assess whether species? traits affect their responsiveness to treatment 1, and whether species traits and other treatments interact to affect their responsiveness to treatment 1.

I have used this model in R to examine the above question:

model <- glmer(species_responsiveness ~ (treatment4+treatment3+treatment2+trait)^3 + (1|block/plot), family=binomial, data=traits)

As far as I understand, this random structure should take into account that 1) species observations are nested within plots, and 2) plots are nested within blocks. There are multiple species occurring in the same plots, that?s why species is nested within plots, and most species also occur in several plots but not all species occur in all plots. There are many species (~40) in the data.

My question is that does the species identity also need to be a crossed random factor in the model? Like this:

+(1|block/plot) + (1|species)

With this random formula, the model would be:

model <- glmer(species_responsiveness ~ (treatment1+treatment2+treatment3+trait)^3 + (1|block/plot) + (1|species), family=binomial, data=traits)

However, with this random structure I get a lot of complaints and sometimes the models do not converge at all. Models without species converge normally. Scaling the trait values does not help. I have several traits for the species, each analyzed in its own model, and they are all performing equally badly. I get, for example, these error messages:

Warning messages:
1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge with max|grad| = 0.0841993 (tol = 0.002, component 1)
2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model is nearly unidentifiable: very large eigenvalue
 - Rescale variables?
Or
Model failed to converge with max|grad| = 0.0841993 (tol = 0.002, component 1)
Model is nearly unidentifiable: very large eigenvalue
 - Rescale variables?

In the data, ?species? overlaps/aligns perfectly with ?trait? as each individual species has only one unique value for each trait. Here?s an example how it can look in the data:

species      trait
Antodo       0.2
Antodo       0.2
Antodo       0.2
Helpra       0.5
Helpra       0.5
Helpra       0.5
Seqvar       0.03
Seqvar       0.03
Seqvar       0.03

So, when I have ?trait? as a fixed factor and ?species? as a random factor, do they compete to explain the same variation in the data? And can that be causing problems in model convergence? What kind of random formula would be correct? I would be super grateful for any advice/thoughts. Thanks so much!

Best regards,
Anu

Assoc. Prof. Anu Eskelinen
Oulu University, Finland
iDiv and UFZ, Leipzig, Germany



	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Tue Jul 12 10:03:45 2022
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Tue, 12 Jul 2022 10:03:45 +0200
Subject: [R-sig-ME] defining nested and crossed random effects in glmer
In-Reply-To: <f0362307d58142daac6194338ee00b34@idiv.de>
References: <f0362307d58142daac6194338ee00b34@idiv.de>
Message-ID: <CAJuCY5xFQ4R4-tVXaFDfzyvz8xLPOk84mD2nOb_QvM6S7MvJ7Q@mail.gmail.com>

Dear Anu,

In case every species has a (near) unique value for trait, then trait as
factor becomes just another "label" for the species. trait + (1|species)
would be the same a species + (1|species), which clearly doesn't
make sense. trait + (1|species) makes only sense when the trait is
continuous.

Your model seems to contain a lot of parameters  and the number of
observations seems limited. I estimate your model has about 18 parameters.
As a rule of thumb, you need ten times that number of "effective
observations". In case of a Bernouilli response the number would be the
total of 0 or 1, whichever is the lowest. E.g. with 25% "1" you need 180
times "1" or 720 observations in total.
You might need to collect more data or simplify the model.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 11 jul. 2022 om 11:36 schreef Eskelinen, Anu <anu.eskelinen at idiv.de>:

> Hello,
>
> I have a question related to defining a random formula in a mixed effects
> model in glmer. I would be grateful for any help from this expert
> community. Thanks a lot already in advance!
>
> My question relates to ecological plant species data from a full-factorial
> experiment with four treatments. In the experiment, treatment 1 is nested
> within treatments 2 and 3, and treatments 2 and 3 are nested within
> treatment 4. All treatments have two levels (manipulation, no
> manipulation). Treatment 1 subplots (manipulation, no manipulation) are
> next to each other (paired), forming bigger plots that receive a
> combination of treatments 2 and 3. These plots are arranged in groups of
> four (called blocks) that receive treatment 4. Pretty complex experiment,
> yes, as many ecological questions are complex.
>
> My question concerns the following analysis. We have calculated a binary
> 0-1 response variable between the subplots for plant species that occur in
> the subplots. We call this ?species responsiveness to treatment 1?. We then
> explain this ?species responsiveness to treatment 1? by treatments 2, 3 and
> 4, and by an additional continuous variable which is a trait that describes
> some characteristics of the species. The main question is to assess whether
> species? traits affect their responsiveness to treatment 1, and whether
> species traits and other treatments interact to affect their responsiveness
> to treatment 1.
>
> I have used this model in R to examine the above question:
>
> model <- glmer(species_responsiveness ~
> (treatment4+treatment3+treatment2+trait)^3 + (1|block/plot),
> family=binomial, data=traits)
>
> As far as I understand, this random structure should take into account
> that 1) species observations are nested within plots, and 2) plots are
> nested within blocks. There are multiple species occurring in the same
> plots, that?s why species is nested within plots, and most species also
> occur in several plots but not all species occur in all plots. There are
> many species (~40) in the data.
>
> My question is that does the species identity also need to be a crossed
> random factor in the model? Like this:
>
> +(1|block/plot) + (1|species)
>
> With this random formula, the model would be:
>
> model <- glmer(species_responsiveness ~
> (treatment1+treatment2+treatment3+trait)^3 + (1|block/plot) + (1|species),
> family=binomial, data=traits)
>
> However, with this random structure I get a lot of complaints and
> sometimes the models do not converge at all. Models without species
> converge normally. Scaling the trait values does not help. I have several
> traits for the species, each analyzed in its own model, and they are all
> performing equally badly. I get, for example, these error messages:
>
> Warning messages:
> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model failed to converge with max|grad| = 0.0841993 (tol = 0.002,
> component 1)
> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model is nearly unidentifiable: very large eigenvalue
>  - Rescale variables?
> Or
> Model failed to converge with max|grad| = 0.0841993 (tol = 0.002,
> component 1)
> Model is nearly unidentifiable: very large eigenvalue
>  - Rescale variables?
>
> In the data, ?species? overlaps/aligns perfectly with ?trait? as each
> individual species has only one unique value for each trait. Here?s an
> example how it can look in the data:
>
> species      trait
> Antodo       0.2
> Antodo       0.2
> Antodo       0.2
> Helpra       0.5
> Helpra       0.5
> Helpra       0.5
> Seqvar       0.03
> Seqvar       0.03
> Seqvar       0.03
>
> So, when I have ?trait? as a fixed factor and ?species? as a random
> factor, do they compete to explain the same variation in the data? And can
> that be causing problems in model convergence? What kind of random formula
> would be correct? I would be super grateful for any advice/thoughts. Thanks
> so much!
>
> Best regards,
> Anu
>
> Assoc. Prof. Anu Eskelinen
> Oulu University, Finland
> iDiv and UFZ, Leipzig, Germany
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From njero @end|ng |rom nev@d@@unr@edu  Wed Jul 13 20:28:07 2022
From: njero @end|ng |rom nev@d@@unr@edu (Nathan Jero)
Date: Wed, 13 Jul 2022 11:28:07 -0700
Subject: [R-sig-ME] Extracting random effect variance from a MuMIn-averaged
 object of several glmer models
Message-ID: <CA+kybKfeV1ZB_AgFqUni0A5EWCmuDZh9aUKeeO_S4=Ma5cT98A@mail.gmail.com>

Hi everyone,

I'm working on analyzing the results from a trial of a new animal
management technology, with a random intercept to capture variance
between animals (I have multiple measurements of each animal).  No
single model from my candidate set is obviously the best (AIC weights
< 0.95, several models with delta AIC < 10), so I am planning on using
MuMIn::model.avg to obtain an averaged model for inference.

However, the random effect variance represents differences in how
animals respond to the technology and is therefore of interest to me.
Unfortunately, while obtaining an averaged model object and
coefficients for the fixed effects has been easy, the random effect
variance is not reported in summary(averaged.mod) and I haven't found
another way to extract it from an object of class 'averaging' created
by model.avg.  Is there a way to do this?

All candidate models were fit using the same random effect structure
and dataset in glmer() with the binomial family and logit link.

I'll freely admit my lack of statistical knowledge, so if there are
theoretical issues with this idea, I would love to learn.

Thanks!
Nathan

-- 
Nathan Jero
M.S. student, Animal & Rangeland Science
Rangeland Ecology Lab
University of Nevada, Reno


From je@@|ecom|ey44 @end|ng |rom gm@||@com  Fri Jul 15 12:06:56 2022
From: je@@|ecom|ey44 @end|ng |rom gm@||@com (jessica comley)
Date: Fri, 15 Jul 2022 12:06:56 +0200
Subject: [R-sig-ME] MCMCglmm with multinomial models
Message-ID: <CANdGWBHgzmN15cvGu7zU90o-+sZn4fUS92_nanb6OYYW8f2rog@mail.gmail.com>

Dear all,

I am hoping that someone will be able to help me with conducting MCMCglmm
multinomial models.

The data I am working with is for black-backed jackal (bbj) and carcal. For
each species we have a multinomial response variable called activity which
has four categories (dawn, diurnal, dusk, nocturnal). We have two
categorical fixed effects which are 1) culling (none, lethal) and 2)
predator presence (absent, high, low). We also have a categorical variable
called Section (made up of 14 different reserves/ farms where the activity
of caracal and bbj were recorded). There are 273 observations for caracal
and 4399 for bbj. We are wanting to test the effects of culling and
predators on caracal and bbj activity separately.

I have been working through Jarrod Hadfields course notes, particularly
with regards to Chapter 5.2. The chi-square analyses reveal that the
frequencies of culling and predators differ as do activities.

I have managed to work out the specific probabilities for the culling none
vs culling lethal for each activity (dawn, diurnal, dusk, nocturnal) for
caracal, but I'm confused as to how to determine p-values to determine
which activities culling none vs culling lethal are affecting?

Myy code and outcomes are pasted below with questions stated in bold.

caracal2 <- read.csv("caracal_new.csv", header=T)
caracal <- as.data.frame(unclass(caracal2), stringsAsFactors = TRUE)

#Chi-squared tests
Ctable1 <- table(caracal$activity, caracal$culling)
chisq.test(rowSums(Ctable1)) #strongly suggests activities differ
chisq.test(Ctable1)#strongly suggests culling category differs

Ctable2 <- table(caracal$activity, caracal$predator)
chisq.test(rowSums(Ctable2))#strongly suggests activities differ
chisq.test(Ctable2)#strongly suggests predator category differs

prior = list(R = list(fix=1, V=(1/k) * (I + J)), G = list(G1=list(V =
diag(k-1), nu=1)))
test1c.5 <- MCMCglmm(activity ~ -1 + at.level(culling,1):trait +
at.level(culling, 2):trait, random=~us(trait):Section, rcov =
~us(trait):units, data = caracal, family = "categorical", prior = prior,
burnin=5000, nitt=60000)
*##I'm not sure how to add the three predator levels to this model or if it
would be appropriate?*


k <- length(levels(caracal$activity))
I <- diag(k-1)
J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))
IJ <- (1/k) *(diag(k-1) + matrix(1,k-1, k-1))

contrasts(caracal$activity)

#culling lethal
Delta <- cbind(c(0,1,0,0), c(0,0,1,0), c(0,0,0,1))
c2 <- (16 * sqrt(3)/(15 * pi))^2
D <- ginv(Delta %*% t(Delta)) %*% Delta
Int <- t(apply(test1c.5$Sol[,1:3],1, function(x) + D %*% (x/sqrt(1 + c2 *
diag(IJ)))))
summary(mcmc(exp(Int)/rowSums(exp(Int))))

prop.table(Ctable1[,1])

#culling none
Delta <- cbind(c(0,1,0,0), c(0,0,1,0), c(0,0,0,1))
c2 <- (16 * sqrt(3)/(15 * pi))^2
D <- ginv(Delta %*% t(Delta)) %*% Delta
Int <- t(apply(test1c.5$Sol[,4:6],1, function(x) + D %*% (x/sqrt(1 + c2 *
diag(IJ)))))
summary(mcmc(exp(Int)/rowSums(exp(Int))))

prop.table((Ctable1[,2]))

HPDinterval(test1c.5$Sol)

#model summary
> summary(test1c.5)

 Iterations = 5001:59991
 Thinning interval  = 10
 Sample size  = 5500

 DIC: 699.7014

 G-structure:  ~us(trait):Section

                                                        post.mean l-95% CI
u-95% CI eff.samp
traitactivity.diurnal:traitactivity.diurnal.Section        1.8124  0.09784
   5.665    77.01
traitactivity.dusk:traitactivity.diurnal.Section           0.8450 -0.83585
   3.856    64.17
traitactivity.nocturnal:traitactivity.diurnal.Section      1.3621 -1.19129
   6.157    58.48
traitactivity.diurnal:traitactivity.dusk.Section           0.8450 -0.83585
   3.856    64.17
traitactivity.dusk:traitactivity.dusk.Section              1.2034  0.07090
   3.681   102.16
traitactivity.nocturnal:traitactivity.dusk.Section         0.7505 -1.77113
   4.524    43.53
traitactivity.diurnal:traitactivity.nocturnal.Section      1.3621 -1.19129
   6.157    58.48
traitactivity.dusk:traitactivity.nocturnal.Section         0.7505 -1.77113
   4.524    43.53
traitactivity.nocturnal:traitactivity.nocturnal.Section    2.7148  0.09401
   8.397    76.59

 R-structure:  ~us(trait):units

                                                      post.mean l-95% CI
u-95% CI eff.samp
traitactivity.diurnal:traitactivity.diurnal.units          0.50     0.50
  0.50        0
traitactivity.dusk:traitactivity.diurnal.units             0.25     0.25
  0.25        0
traitactivity.nocturnal:traitactivity.diurnal.units        0.25     0.25
  0.25        0
traitactivity.diurnal:traitactivity.dusk.units             0.25     0.25
  0.25        0
traitactivity.dusk:traitactivity.dusk.units                0.50     0.50
  0.50        0
traitactivity.nocturnal:traitactivity.dusk.units           0.25     0.25
  0.25        0
traitactivity.diurnal:traitactivity.nocturnal.units        0.25     0.25
  0.25        0
traitactivity.dusk:traitactivity.nocturnal.units           0.25     0.25
  0.25        0
traitactivity.nocturnal:traitactivity.nocturnal.units      0.50     0.50
  0.50        0

 Location effects: activity ~ -1 + at.level(culling, 1):trait +
at.level(culling, 2):trait

                                             post.mean l-95% CI u-95% CI
eff.samp  pMCMC
at.level(culling, 1):traitactivity.diurnal      1.2306  -0.0533   2.6793
145.29 0.0418 *
at.level(culling, 1):traitactivity.dusk         0.6605  -0.6006   2.0761
 92.91 0.2840
at.level(culling, 1):traitactivity.nocturnal    1.6090   0.0914   3.1356
151.02 0.0265 *
traitactivity.diurnal:at.level(culling, 2)      1.2664  -0.1552   2.7750
226.40 0.0604 .
traitactivity.dusk:at.level(culling, 2)         0.3533  -0.9898   1.5218
148.44 0.5447
traitactivity.nocturnal:at.level(culling, 2)    1.0447  -0.6405   2.8354
346.40 0.1618
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

*##So for the model summary I get that lethal culling at activity diurnal
is significantly different from lethal culling at dawn (its the base
reference), but I'm also interested in whether lethal culling at activity
diurnal is different from lethal culling at dusk for example. Is this
possible? *

#outcomes culling lethal
> summary(mcmc(exp(Int)/rowSums(exp(Int))))

Iterations = 1:5500
Thinning interval = 1
Number of chains = 1
Sample size per chain = 5500

1. Empirical mean and standard deviation for each variable,
   plus standard error of the mean:

       Mean      SD  Naive SE Time-series SE
[1,] 0.1253 0.05565 0.0007504       0.002484
[2,] 0.3748 0.10497 0.0014155       0.003204
[3,] 0.1757 0.06640 0.0008954       0.002515
[4,] 0.3242 0.11939 0.0016099       0.003514

2. Quantiles for each variable:

        2.5%     25%    50%    75%  97.5%
var1 0.03641 0.08695 0.1198 0.1554 0.2553
var2 0.17298 0.30580 0.3704 0.4431 0.5896
var3 0.06166 0.12913 0.1705 0.2161 0.3215
var4 0.12610 0.23999 0.3090 0.3901 0.6045

> prop.table(Ctable1[,1])
     dawn   diurnal      dusk nocturnal
0.1250000 0.2812500 0.1770833 0.4166667


#outcomes culling none
> summary(mcmc(exp(Int)/rowSums(exp(Int))))

Iterations = 1:5500
Thinning interval = 1
Number of chains = 1
Sample size per chain = 5500

1. Empirical mean and standard deviation for each variable,
   plus standard error of the mean:

       Mean      SD  Naive SE Time-series SE
[1,] 0.1288 0.06141 0.0008280       0.002787
[2,] 0.3804 0.10406 0.0014032       0.002662
[3,] 0.1710 0.06844 0.0009228       0.002592
[4,] 0.3198 0.11812 0.0015928       0.002956

2. Quantiles for each variable:

        2.5%     25%    50%    75%  97.5%
var1 0.02891 0.08896 0.1220 0.1594 0.2685
var2 0.18007 0.31094 0.3783 0.4474 0.5965
var3 0.05840 0.12425 0.1634 0.2083 0.3250
var4 0.12430 0.23921 0.3077 0.3862 0.5964

> prop.table((Ctable1[,2]))
     dawn   diurnal      dusk nocturnal
0.1306818 0.4375000 0.1875000 0.2443182

Any help or guidance will be greatly appreciated.

All the best,
Jess

-- 
Jessica Comley (PhD)
Research Scientist

	[[alternative HTML version deleted]]


From w@||dm@w@@@10 @end|ng |rom gm@||@com  Fri Jul 15 23:37:30 2022
From: w@||dm@w@@@10 @end|ng |rom gm@||@com (Walid Mawass)
Date: Fri, 15 Jul 2022 14:37:30 -0700
Subject: [R-sig-ME] MCMCglmm with multinomial models
In-Reply-To: <CANdGWBHgzmN15cvGu7zU90o-+sZn4fUS92_nanb6OYYW8f2rog@mail.gmail.com>
References: <CANdGWBHgzmN15cvGu7zU90o-+sZn4fUS92_nanb6OYYW8f2rog@mail.gmail.com>
Message-ID: <CAJtCY7XH=AACiNbTo4SLo4gMQnM7ub1vVEOwGGqB-AvuJf5+Jw@mail.gmail.com>

Hello,

I don't think I can specifically help you with some of your inquiries.
However, I do want to comment on a few things that might need some
attention.

First, MCMCglmm is based on a Bayesian implementation and does not compute
p-values to compare. What you need to compare are the posterior
distributions of your effect sizes. This can be done visually using the
base plot function in R. Or by comparing the HPD intervals and the mode (or
mean) of the posterior distributions.

Second, I have no idea what your data structure looks like (which makes it
hard to interpret model results), but the effective sample size (from the
5500 saved iterations sample) for your random variable Section is very low
(the same applies for your fixed effects). You should consider this issue
and look again at your assumption of correlation between activities for the
14 sections you have in your dataset. If you do not expect among activity
correlations then you can use the idh() function instead of us().

Hopefully this helps and in hope that people on this list with more
knowledge of these models will help out.

Best,
-- 
Walid Mawass
Ph.D. candidate in Evolutionary Biology - UQTR
*Currently* Postdoctoral Research Associate
Masel Lab - University of Arizona


On Fri, Jul 15, 2022 at 8:49 AM jessica comley <jessiecomley44 at gmail.com>
wrote:

> Dear all,
>
> I am hoping that someone will be able to help me with conducting MCMCglmm
> multinomial models.
>
> The data I am working with is for black-backed jackal (bbj) and carcal. For
> each species we have a multinomial response variable called activity which
> has four categories (dawn, diurnal, dusk, nocturnal). We have two
> categorical fixed effects which are 1) culling (none, lethal) and 2)
> predator presence (absent, high, low). We also have a categorical variable
> called Section (made up of 14 different reserves/ farms where the activity
> of caracal and bbj were recorded). There are 273 observations for caracal
> and 4399 for bbj. We are wanting to test the effects of culling and
> predators on caracal and bbj activity separately.
>
> I have been working through Jarrod Hadfields course notes, particularly
> with regards to Chapter 5.2. The chi-square analyses reveal that the
> frequencies of culling and predators differ as do activities.
>
> I have managed to work out the specific probabilities for the culling none
> vs culling lethal for each activity (dawn, diurnal, dusk, nocturnal) for
> caracal, but I'm confused as to how to determine p-values to determine
> which activities culling none vs culling lethal are affecting?
>
> Myy code and outcomes are pasted below with questions stated in bold.
>
> caracal2 <- read.csv("caracal_new.csv", header=T)
> caracal <- as.data.frame(unclass(caracal2), stringsAsFactors = TRUE)
>
> #Chi-squared tests
> Ctable1 <- table(caracal$activity, caracal$culling)
> chisq.test(rowSums(Ctable1)) #strongly suggests activities differ
> chisq.test(Ctable1)#strongly suggests culling category differs
>
> Ctable2 <- table(caracal$activity, caracal$predator)
> chisq.test(rowSums(Ctable2))#strongly suggests activities differ
> chisq.test(Ctable2)#strongly suggests predator category differs
>
> prior = list(R = list(fix=1, V=(1/k) * (I + J)), G = list(G1=list(V =
> diag(k-1), nu=1)))
> test1c.5 <- MCMCglmm(activity ~ -1 + at.level(culling,1):trait +
> at.level(culling, 2):trait, random=~us(trait):Section, rcov =
> ~us(trait):units, data = caracal, family = "categorical", prior = prior,
> burnin=5000, nitt=60000)
> *##I'm not sure how to add the three predator levels to this model or if it
> would be appropriate?*
>
>
> k <- length(levels(caracal$activity))
> I <- diag(k-1)
> J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))
> IJ <- (1/k) *(diag(k-1) + matrix(1,k-1, k-1))
>
> contrasts(caracal$activity)
>
> #culling lethal
> Delta <- cbind(c(0,1,0,0), c(0,0,1,0), c(0,0,0,1))
> c2 <- (16 * sqrt(3)/(15 * pi))^2
> D <- ginv(Delta %*% t(Delta)) %*% Delta
> Int <- t(apply(test1c.5$Sol[,1:3],1, function(x) + D %*% (x/sqrt(1 + c2 *
> diag(IJ)))))
> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>
> prop.table(Ctable1[,1])
>
> #culling none
> Delta <- cbind(c(0,1,0,0), c(0,0,1,0), c(0,0,0,1))
> c2 <- (16 * sqrt(3)/(15 * pi))^2
> D <- ginv(Delta %*% t(Delta)) %*% Delta
> Int <- t(apply(test1c.5$Sol[,4:6],1, function(x) + D %*% (x/sqrt(1 + c2 *
> diag(IJ)))))
> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>
> prop.table((Ctable1[,2]))
>
> HPDinterval(test1c.5$Sol)
>
> #model summary
> > summary(test1c.5)
>
>  Iterations = 5001:59991
>  Thinning interval  = 10
>  Sample size  = 5500
>
>  DIC: 699.7014
>
>  G-structure:  ~us(trait):Section
>
>                                                         post.mean l-95% CI
> u-95% CI eff.samp
> traitactivity.diurnal:traitactivity.diurnal.Section        1.8124  0.09784
>    5.665    77.01
> traitactivity.dusk:traitactivity.diurnal.Section           0.8450 -0.83585
>    3.856    64.17
> traitactivity.nocturnal:traitactivity.diurnal.Section      1.3621 -1.19129
>    6.157    58.48
> traitactivity.diurnal:traitactivity.dusk.Section           0.8450 -0.83585
>    3.856    64.17
> traitactivity.dusk:traitactivity.dusk.Section              1.2034  0.07090
>    3.681   102.16
> traitactivity.nocturnal:traitactivity.dusk.Section         0.7505 -1.77113
>    4.524    43.53
> traitactivity.diurnal:traitactivity.nocturnal.Section      1.3621 -1.19129
>    6.157    58.48
> traitactivity.dusk:traitactivity.nocturnal.Section         0.7505 -1.77113
>    4.524    43.53
> traitactivity.nocturnal:traitactivity.nocturnal.Section    2.7148  0.09401
>    8.397    76.59
>
>  R-structure:  ~us(trait):units
>
>                                                       post.mean l-95% CI
> u-95% CI eff.samp
> traitactivity.diurnal:traitactivity.diurnal.units          0.50     0.50
>   0.50        0
> traitactivity.dusk:traitactivity.diurnal.units             0.25     0.25
>   0.25        0
> traitactivity.nocturnal:traitactivity.diurnal.units        0.25     0.25
>   0.25        0
> traitactivity.diurnal:traitactivity.dusk.units             0.25     0.25
>   0.25        0
> traitactivity.dusk:traitactivity.dusk.units                0.50     0.50
>   0.50        0
> traitactivity.nocturnal:traitactivity.dusk.units           0.25     0.25
>   0.25        0
> traitactivity.diurnal:traitactivity.nocturnal.units        0.25     0.25
>   0.25        0
> traitactivity.dusk:traitactivity.nocturnal.units           0.25     0.25
>   0.25        0
> traitactivity.nocturnal:traitactivity.nocturnal.units      0.50     0.50
>   0.50        0
>
>  Location effects: activity ~ -1 + at.level(culling, 1):trait +
> at.level(culling, 2):trait
>
>                                              post.mean l-95% CI u-95% CI
> eff.samp  pMCMC
> at.level(culling, 1):traitactivity.diurnal      1.2306  -0.0533   2.6793
> 145.29 0.0418 *
> at.level(culling, 1):traitactivity.dusk         0.6605  -0.6006   2.0761
>  92.91 0.2840
> at.level(culling, 1):traitactivity.nocturnal    1.6090   0.0914   3.1356
> 151.02 0.0265 *
> traitactivity.diurnal:at.level(culling, 2)      1.2664  -0.1552   2.7750
> 226.40 0.0604 .
> traitactivity.dusk:at.level(culling, 2)         0.3533  -0.9898   1.5218
> 148.44 0.5447
> traitactivity.nocturnal:at.level(culling, 2)    1.0447  -0.6405   2.8354
> 346.40 0.1618
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> *##So for the model summary I get that lethal culling at activity diurnal
> is significantly different from lethal culling at dawn (its the base
> reference), but I'm also interested in whether lethal culling at activity
> diurnal is different from lethal culling at dusk for example. Is this
> possible? *
>
> #outcomes culling lethal
> > summary(mcmc(exp(Int)/rowSums(exp(Int))))
>
> Iterations = 1:5500
> Thinning interval = 1
> Number of chains = 1
> Sample size per chain = 5500
>
> 1. Empirical mean and standard deviation for each variable,
>    plus standard error of the mean:
>
>        Mean      SD  Naive SE Time-series SE
> [1,] 0.1253 0.05565 0.0007504       0.002484
> [2,] 0.3748 0.10497 0.0014155       0.003204
> [3,] 0.1757 0.06640 0.0008954       0.002515
> [4,] 0.3242 0.11939 0.0016099       0.003514
>
> 2. Quantiles for each variable:
>
>         2.5%     25%    50%    75%  97.5%
> var1 0.03641 0.08695 0.1198 0.1554 0.2553
> var2 0.17298 0.30580 0.3704 0.4431 0.5896
> var3 0.06166 0.12913 0.1705 0.2161 0.3215
> var4 0.12610 0.23999 0.3090 0.3901 0.6045
>
> > prop.table(Ctable1[,1])
>      dawn   diurnal      dusk nocturnal
> 0.1250000 0.2812500 0.1770833 0.4166667
>
>
> #outcomes culling none
> > summary(mcmc(exp(Int)/rowSums(exp(Int))))
>
> Iterations = 1:5500
> Thinning interval = 1
> Number of chains = 1
> Sample size per chain = 5500
>
> 1. Empirical mean and standard deviation for each variable,
>    plus standard error of the mean:
>
>        Mean      SD  Naive SE Time-series SE
> [1,] 0.1288 0.06141 0.0008280       0.002787
> [2,] 0.3804 0.10406 0.0014032       0.002662
> [3,] 0.1710 0.06844 0.0009228       0.002592
> [4,] 0.3198 0.11812 0.0015928       0.002956
>
> 2. Quantiles for each variable:
>
>         2.5%     25%    50%    75%  97.5%
> var1 0.02891 0.08896 0.1220 0.1594 0.2685
> var2 0.18007 0.31094 0.3783 0.4474 0.5965
> var3 0.05840 0.12425 0.1634 0.2083 0.3250
> var4 0.12430 0.23921 0.3077 0.3862 0.5964
>
> > prop.table((Ctable1[,2]))
>      dawn   diurnal      dusk nocturnal
> 0.1306818 0.4375000 0.1875000 0.2443182
>
> Any help or guidance will be greatly appreciated.
>
> All the best,
> Jess
>
> --
> Jessica Comley (PhD)
> Research Scientist
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From benpe|zer @end|ng |rom gm@||@com  Sat Jul 16 15:59:40 2022
From: benpe|zer @end|ng |rom gm@||@com (ben pelzer)
Date: Sat, 16 Jul 2022 15:59:40 +0200
Subject: [R-sig-ME] lme results unstructured covariance matrix
Message-ID: <CAFgPNS_zavUM8S8D=xHuiB_B77c2ebCCM4nQo1RTtL3XAZCW5A@mail.gmail.com>

Hi all,

I have a question about results from lme of package nlme.

Suppose the data consists of repeated measures at two fixed time points.

I used the following equation:



Model1 <- lme ( y ~ 1+t2 , random = ~ 0 + t1+t2|person, data=da)



y is the dependent, t1 and t2 are binary dummy variables, valued 0 or 1,
indicating the time point.  Model1 is estimated without any convergence
problems and the reproduced (co)variances found with



getVarCov(Model1, type=?marginal?, indivual=?1?)



are identical to the observed (co)variances.


My question is:  how can lme estimate 4 (co)variances with only 3 known
(co)variances?



The 4 estimates concern:

-          std. deviation of the random effect of dummy t1

-          std. deviation of the random effect of dummy t2

-          covariance of the random effects of the dummies t1 and t2 t1

-          residual std. error



Related to the question above: how can the variances of the random effects
and the residual std. error be interpreted?



Thanks for any help,



Ben.









I?m struggling with specifying a model in lme from the nlme package.



My data consists of two groups, say men and women. Each person is measured
three times at fixed occasions in time. I would like to estimate un
unstructured 3x3 (co)variance matrix for each group.  So these are the
variables involved:

dependent Y,

time (1, 2 or 3),

gender ( 0 or 1),

person ?id? variable.



I also created dummy-indicator variable t1, t2 and t3 denoting the three
points in time.



This is the script to simulate the data:



set.seed(123456)



id <- rep(1:20,each=3)

time <- rep(c(1,2,3), 20)

t1 <- ifelse(time==1, 1, 0)

t2 <- ifelse(time==2, 1, 0)

t3 <- ifelse(time==3, 1, 0)

time <- factor(time)

gender <- rep(c(0,1), each=30)



# Add random person effect.

u <- c(rep(rnorm(10,0,2), each=3), rep(rnorm(10,0,4), each=3))

e <- c(rnorm(30,0,2), rnorm(30,0,3))



y <- 1 + 2*t2 + 5*t3 + 3*gender + u + e



da <- data.frame(id, time, t1, t2, t3, gender, y)



library(nlme)

model1 <- lme(y ~ t2 + t3 + gender, random = ~ 1 + time|id, da)

summary(model1)

	[[alternative HTML version deleted]]


From benpe|zer @end|ng |rom gm@||@com  Sat Jul 16 16:05:53 2022
From: benpe|zer @end|ng |rom gm@||@com (ben pelzer)
Date: Sat, 16 Jul 2022 16:05:53 +0200
Subject: [R-sig-ME] results lme unstructured covariance matrix, again
Message-ID: <CAFgPNS_+x_ZDwaZUx0tzYs2U2D7s1roFqfcADU+_sTypf8i9jw@mail.gmail.com>

Sorry, my previous mailed contained another question which is irrelevant...
I deleted that now.


Hi all,

I have a question about results from lme of package nlme.

Suppose the data consists of repeated measures at two fixed time points.

I used the following equation:



Model1 <- lme ( y ~ 1+t2 , random = ~ 0 + t1+t2|person, data=da)



y is the dependent, t1 and t2 are binary dummy variables, valued 0 or 1,
indicating the time point.  Model1 is estimated without any convergence
problems and the reproduced (co)variances found with



getVarCov(Model1, type=?marginal?, indivual=?1?)



are identical to the observed (co)variances.


My question is:  how can lme estimate 4 (co)variances with only 3 known
(co)variances?



The 4 estimates concern:

-          std. deviation of the random effect of dummy t1

-          std. deviation of the random effect of dummy t2

-          covariance of the random effects of the dummies t1 and t2 t1

-          residual std. error



Related to the question above: how can the variances of the random effects
and the residual std. error be interpreted?



Thanks for any help,



Ben.

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Sat Jul 16 16:50:49 2022
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Sat, 16 Jul 2022 10:50:49 -0400
Subject: [R-sig-ME] results lme unstructured covariance matrix, again
In-Reply-To: <29754_1657980613_26GEACWL024787_CAFgPNS_+x_ZDwaZUx0tzYs2U2D7s1roFqfcADU+_sTypf8i9jw@mail.gmail.com>
References: <29754_1657980613_26GEACWL024787_CAFgPNS_+x_ZDwaZUx0tzYs2U2D7s1roFqfcADU+_sTypf8i9jw@mail.gmail.com>
Message-ID: <5d88d002-d568-269a-50f7-11d259ebff0d@mcmaster.ca>

Dear Ben,

First, I'll make this into a reproducible example:

 > set.seed(123)
 > t1 <- c(rep(1, 10), rep(0, 10))
 > t2 <- 1 - t1
 > person <- rep(1:10, 2)
 > y <- t2 + rnorm(20)
 > da <- data.frame(y, t1, t2, person)

 > library(nlme)

Then note that the random-effect specification 0 + t1 + t2 is simply a 
reparametrization of 1 + t2 (i.e., 1 = t1 + t2), which produces the same 
fit to the data (same fixed effects, same restricted log-likelihood):

 > m1 <- lme(y ~ 1 + t2, random = ~ 0 + t1 + t2 | person, data=da)
 > m2 <- lme(y ~ 1 + t2, random = ~ 1 + t2 | person, data=da)
 > m1
Linear mixed-effects model fit by REML
   Data: da
   Log-restricted-likelihood: -25.92726
   Fixed: y ~ 1 + t2
(Intercept)          t2
  0.07462564  1.13399632

Random effects:
  Formula: ~0 + t1 + t2 | person
  Structure: General positive-definite, Log-Cholesky parametrization
          StdDev    Corr
t1       0.8964136 t1
t2       0.9856215 0.647
Residual 0.3258015

Number of Observations: 20
Number of Groups: 10

 > m2
Linear mixed-effects model fit by REML
   Data: da
   Log-restricted-likelihood: -25.92726
   Fixed: y ~ 1 + t2
(Intercept)          t2
  0.07462564  1.13399632

Random effects:
  Formula: ~1 + t2 | person
  Structure: General positive-definite, Log-Cholesky parametrization
             StdDev    Corr
(Intercept) 0.8787887 (Intr)
t2          0.7540826 -0.302
Residual    0.3707215

Number of Observations: 20
Number of Groups: 10

Finally, it's unnecessary to supply the intercept 1 in the model formula 
since the intercept is implied if it's not explicitly excluded:

 > m3 <- lme(y ~ t2, random = ~ t2 | person, data=da)
 > m3
Linear mixed-effects model fit by REML
   Data: da
   Log-restricted-likelihood: -25.92726
   Fixed: y ~ t2
(Intercept)          t2
  0.07462564  1.13399632

Random effects:
  Formula: ~t2 | person
  Structure: General positive-definite, Log-Cholesky parametrization
             StdDev    Corr
(Intercept) 0.8787887 (Intr)
t2          0.7540826 -0.302
Residual    0.3707215

Number of Observations: 20
Number of Groups: 10

I hope this helps,
  John

On 2022-07-16 10:05 a.m., ben pelzer wrote:
> Sorry, my previous mailed contained another question which is irrelevant...
> I deleted that now.
> 
> 
> Hi all,
> 
> I have a question about results from lme of package nlme.
> 
> Suppose the data consists of repeated measures at two fixed time points.
> 
> I used the following equation:
> 
> 
> 
> Model1 <- lme ( y ~ 1+t2 , random = ~ 0 + t1+t2|person, data=da)
> 
> 
> 
> y is the dependent, t1 and t2 are binary dummy variables, valued 0 or 1,
> indicating the time point.  Model1 is estimated without any convergence
> problems and the reproduced (co)variances found with
> 
> 
> 
> getVarCov(Model1, type=?marginal?, indivual=?1?)
> 
> 
> 
> are identical to the observed (co)variances.
> 
> 
> My question is:  how can lme estimate 4 (co)variances with only 3 known
> (co)variances?
> 
> 
> 
> The 4 estimates concern:
> 
> -          std. deviation of the random effect of dummy t1
> 
> -          std. deviation of the random effect of dummy t2
> 
> -          covariance of the random effects of the dummies t1 and t2 t1
> 
> -          residual std. error
> 
> 
> 
> Related to the question above: how can the variances of the random effects
> and the residual std. error be interpreted?
> 
> 
> 
> Thanks for any help,
> 
> 
> 
> Ben.
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
-- 
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/


From @@mue|@mu|| @end|ng |rom un|-bonn@de  Sat Jul 16 23:24:53 2022
From: @@mue|@mu|| @end|ng |rom un|-bonn@de (Samuel Muli)
Date: Sat, 16 Jul 2022 23:24:53 +0200
Subject: [R-sig-ME] Glmmlasso - Fisher matrix not invertible
In-Reply-To: <00fad6b3-fbfd-2f33-75c7-aeda1c5c7bb9@uni-bonn.de>
References: <00fad6b3-fbfd-2f33-75c7-aeda1c5c7bb9@uni-bonn.de>
Message-ID: <0a4c90a3-1758-24bb-dd43-fe22c2797e9f@uni-bonn.de>

Hi,

I am fitting a glmmLasso model for feature selection before performing a 
traditional LMM for inference. My problem is that while running my 
model, it encounters a fatal error, "fisher matrix not invertible" just 
before returning the results (see Trace back results leading to the error).

I have tried to solve this problem by reducing the number of features, 
and all worked perfectly if my features are below ~110. I have 54 unique 
measurements at two time points (and since this is publicly available 
dataset,? I attach it here for your quick review, along with my code).?? 
However, since I would like to compare Glmmlasso with other methods, I 
do not want to do this prescreening (using another method).

Based on my research, another author observed similar error but 
somewhat, managed to sort it when regression could not be completed, see 
https://biodatamining.biomedcentral.com/articles/10.1186/s13040-018-0173-9 
(p. 7). Their R code is available 
https://github.com/ghedin-lab/LassoGLMMforMicrobiomes

I would really appreciate insights into this problem.


Best regards,





-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: my_code.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20220716/9e2fdadc/attachment-0001.txt>

From jh@|t|g@ @end|ng |rom gm@||@com  Sun Jul 17 03:31:20 2022
From: jh@|t|g@ @end|ng |rom gm@||@com (J.D. Haltigan)
Date: Sat, 16 Jul 2022 21:31:20 -0400
Subject: [R-sig-ME] Equivalent of STATA absorb in lme4 (or HGLM)
Message-ID: <CAH_7VOm74b7+GrC+g8T131-e3SG6qcQd7xWvM8_UgqkRRdyb8Q@mail.gmail.com>

Hi:

I am attempting to replicate some STATA analyses in R and have the
following question. In short:
https://github.com/lme4/lme4/issues/689#issuecomment-1186346282

Thanks, this is what I was trying to convey re: STATA's 'absorb' command
but failed to do.
https://stackoverflow.com/questions/49639238/r-equivalent-of-statas-absorb
<https://github.com/lme4/lme4/issues/url>

So, in STATA, absorb basically just aggregates estimates it seems across
the factor variable. I have now changed the pairID variable upstream to a
factor class which results in estimates for all 300 pairIDs. Is there
something similar to STATA's absorb in lme4? Or would it simply be | pairID
in the formula even if the original factor 'pairID' with all 300 estimates
were 'fixed effects.' Though I doubt | pairID would work with a variable
now defined as class factor which I just confirmed. So, is anything like
STATAs 'absorb' available?


-JDD

	[[alternative HTML version deleted]]


From me @end|ng |rom ph||||p@|d@y@com  Sun Jul 17 18:58:41 2022
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Sun, 17 Jul 2022 11:58:41 -0500
Subject: [R-sig-ME] 
 Extracting random effect variance from a MuMIn-averaged
 object of several glmer models
In-Reply-To: <CA+kybKfeV1ZB_AgFqUni0A5EWCmuDZh9aUKeeO_S4=Ma5cT98A@mail.gmail.com>
References: <CA+kybKfeV1ZB_AgFqUni0A5EWCmuDZh9aUKeeO_S4=Ma5cT98A@mail.gmail.com>
Message-ID: <6516e49b-7594-b61b-55fc-332c2e8d4e05@phillipalday.com>

A naive approach would be to simply compute the pooled variance for each
random effect. For example, take the between-animal variance value for
the intercept from each model and use the usual formulas for computing
pooled variance. (The formulas for pooled standard deviation involve
squaring things back to the variance scale so might as well start from
the variances.)

I haven't thought in detail about the properties of this estimator and
it won't capture the original covariance structure, but it might be
"good enough" for the task at hand.

Hope that helps
Phillip

On 13/7/22 1:28 pm, Nathan Jero wrote:
> Hi everyone,
> 
> I'm working on analyzing the results from a trial of a new animal
> management technology, with a random intercept to capture variance
> between animals (I have multiple measurements of each animal).  No
> single model from my candidate set is obviously the best (AIC weights
> < 0.95, several models with delta AIC < 10), so I am planning on using
> MuMIn::model.avg to obtain an averaged model for inference.
> 
> However, the random effect variance represents differences in how
> animals respond to the technology and is therefore of interest to me.
> Unfortunately, while obtaining an averaged model object and
> coefficients for the fixed effects has been easy, the random effect
> variance is not reported in summary(averaged.mod) and I haven't found
> another way to extract it from an object of class 'averaging' created
> by model.avg.  Is there a way to do this?
> 
> All candidate models were fit using the same random effect structure
> and dataset in glmer() with the binomial family and logit link.
> 
> I'll freely admit my lack of statistical knowledge, so if there are
> theoretical issues with this idea, I would love to learn.
> 
> Thanks!
> Nathan
>


From je@@|ecom|ey44 @end|ng |rom gm@||@com  Mon Jul 18 08:32:42 2022
From: je@@|ecom|ey44 @end|ng |rom gm@||@com (jessica comley)
Date: Mon, 18 Jul 2022 08:32:42 +0200
Subject: [R-sig-ME] MCMCglmm with multinomial models
In-Reply-To: <CAJtCY7XH=AACiNbTo4SLo4gMQnM7ub1vVEOwGGqB-AvuJf5+Jw@mail.gmail.com>
References: <CANdGWBHgzmN15cvGu7zU90o-+sZn4fUS92_nanb6OYYW8f2rog@mail.gmail.com>
 <CAJtCY7XH=AACiNbTo4SLo4gMQnM7ub1vVEOwGGqB-AvuJf5+Jw@mail.gmail.com>
Message-ID: <CANdGWBFmXtPEvaREGQenkqq403+toEFJvLMgPTzdFWGix-ggGA@mail.gmail.com>

Hi Walid,

Thank you for your reply, I greatly appreciate it. I have a few more
questions and if you could help that would be great.

I tested for correlation between activities and the 14 Sections and the
correlation comes out as low. Therefore I have changed my code to use idh()
instead of us as suggested:

test1c.5b <- MCMCglmm(activity ~ -1 + at.level(culling,1):trait +
at.level(culling, 2):trait, random=~idh(trait):Section, rcov =
~idh(trait):units, data = caracal, family = "categorical", prior = prior,
burnin=5000, nitt=80000)

1) Is this correct?

2) Increasing the number of interactions increases the effective sample
size, therefore is there a general rule of thumb as to how large your
effective sample size should be?

3) I understand how to use and interpret the results of HPDinterval (i.e.
if intervals do not overlap 0 then relationship is strong), but how am I
able to test the relationship between all four activities and fixed effects
and not just have the three categories (i.e. diurnal, dusk, nocturnal)
compared to the base category (dawn)? For example, I am also interested in
whether there is a significant/strong relationship between activities of
caracal at dusk with culling(Lethal)/no culling(none) compared to
activities of caracal at diurnal with culling(Lethal)/no culling(none).

Below is an example of our dataset:
Camera Section CameraID Animal predator culling activity
1a Bucklands Bucklands1a Caracal low Lethal diurnal
1a Bucklands Bucklands1a Caracal low Lethal dawn
2a Bucklands Bucklands2a Caracal low Lethal dusk
2a Bucklands Bucklands2a Caracal low Lethal diurnal
3a Bucklands Bucklands3a Caracal low Lethal dawn
Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
Cam 2  Colchester ColchesterCam 2  Caracal high none diurnal
Cam 2  Colchester ColchesterCam 2  Caracal high none diurnal
Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
Cam 4  Colchester ColchesterCam 4  Caracal high none diurnal
Cam 4  Colchester ColchesterCam 4  Caracal high none diurnal
Cam 4  Colchester ColchesterCam 4  Caracal high none nocturnal
1a Connaught Connaught1a Caracal low Lethal nocturnal
1a Connaught Connaught1a Caracal low Lethal nocturnal
1d Connaught Connaught1d Caracal low Lethal diurnal
3B Connaught Connaught3B Caracal low Lethal diurnal
3B Connaught Connaught3B Caracal low Lethal diurnal
4a Connaught Connaught4a Caracal low Lethal nocturnal
4a Connaught Connaught4a Caracal low Lethal nocturnal
4b Connaught Connaught4b Caracal low Lethal diurnal
6a Connaught Connaught6a Caracal low Lethal nocturnal
6b Connaught Connaught6b Caracal low Lethal diurnal
7a Connaught Connaught7a Caracal low Lethal nocturnal
9a Connaught Connaught9a Caracal low Lethal nocturnal
9d Connaught Connaught9d Caracal low Lethal nocturnal
9d Connaught Connaught9d Caracal low Lethal dusk
7d Diepdam Diepdam7d Caracal absent Lethal dusk
8d Diepdam Diepdam8d Caracal absent Lethal diurnal
9c Diepdam Diepdam9c Caracal absent Lethal nocturnal

All the best,
Jess


On Fri, Jul 15, 2022 at 11:37 PM Walid Mawass <walidmawass10 at gmail.com>
wrote:

> Hello,
>
> I don't think I can specifically help you with some of your inquiries.
> However, I do want to comment on a few things that might need some
> attention.
>
> First, MCMCglmm is based on a Bayesian implementation and does not compute
> p-values to compare. What you need to compare are the posterior
> distributions of your effect sizes. This can be done visually using the
> base plot function in R. Or by comparing the HPD intervals and the mode (or
> mean) of the posterior distributions.
>
> Second, I have no idea what your data structure looks like (which makes it
> hard to interpret model results), but the effective sample size (from the
> 5500 saved iterations sample) for your random variable Section is very low
> (the same applies for your fixed effects). You should consider this issue
> and look again at your assumption of correlation between activities for the
> 14 sections you have in your dataset. If you do not expect among activity
> correlations then you can use the idh() function instead of us().
>
> Hopefully this helps and in hope that people on this list with more
> knowledge of these models will help out.
>
> Best,
> --
> Walid Mawass
> Ph.D. candidate in Evolutionary Biology - UQTR
> *Currently* Postdoctoral Research Associate
> Masel Lab - University of Arizona
>
>
> On Fri, Jul 15, 2022 at 8:49 AM jessica comley <jessiecomley44 at gmail.com>
> wrote:
>
>> Dear all,
>>
>> I am hoping that someone will be able to help me with conducting MCMCglmm
>> multinomial models.
>>
>> The data I am working with is for black-backed jackal (bbj) and carcal.
>> For
>> each species we have a multinomial response variable called activity which
>> has four categories (dawn, diurnal, dusk, nocturnal). We have two
>> categorical fixed effects which are 1) culling (none, lethal) and 2)
>> predator presence (absent, high, low). We also have a categorical variable
>> called Section (made up of 14 different reserves/ farms where the activity
>> of caracal and bbj were recorded). There are 273 observations for caracal
>> and 4399 for bbj. We are wanting to test the effects of culling and
>> predators on caracal and bbj activity separately.
>>
>> I have been working through Jarrod Hadfields course notes, particularly
>> with regards to Chapter 5.2. The chi-square analyses reveal that the
>> frequencies of culling and predators differ as do activities.
>>
>> I have managed to work out the specific probabilities for the culling none
>> vs culling lethal for each activity (dawn, diurnal, dusk, nocturnal) for
>> caracal, but I'm confused as to how to determine p-values to determine
>> which activities culling none vs culling lethal are affecting?
>>
>> Myy code and outcomes are pasted below with questions stated in bold.
>>
>> caracal2 <- read.csv("caracal_new.csv", header=T)
>> caracal <- as.data.frame(unclass(caracal2), stringsAsFactors = TRUE)
>>
>> #Chi-squared tests
>> Ctable1 <- table(caracal$activity, caracal$culling)
>> chisq.test(rowSums(Ctable1)) #strongly suggests activities differ
>> chisq.test(Ctable1)#strongly suggests culling category differs
>>
>> Ctable2 <- table(caracal$activity, caracal$predator)
>> chisq.test(rowSums(Ctable2))#strongly suggests activities differ
>> chisq.test(Ctable2)#strongly suggests predator category differs
>>
>> prior = list(R = list(fix=1, V=(1/k) * (I + J)), G = list(G1=list(V =
>> diag(k-1), nu=1)))
>> test1c.5 <- MCMCglmm(activity ~ -1 + at.level(culling,1):trait +
>> at.level(culling, 2):trait, random=~us(trait):Section, rcov =
>> ~us(trait):units, data = caracal, family = "categorical", prior = prior,
>> burnin=5000, nitt=60000)
>> *##I'm not sure how to add the three predator levels to this model or if
>> it
>> would be appropriate?*
>>
>>
>> k <- length(levels(caracal$activity))
>> I <- diag(k-1)
>> J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))
>> IJ <- (1/k) *(diag(k-1) + matrix(1,k-1, k-1))
>>
>> contrasts(caracal$activity)
>>
>> #culling lethal
>> Delta <- cbind(c(0,1,0,0), c(0,0,1,0), c(0,0,0,1))
>> c2 <- (16 * sqrt(3)/(15 * pi))^2
>> D <- ginv(Delta %*% t(Delta)) %*% Delta
>> Int <- t(apply(test1c.5$Sol[,1:3],1, function(x) + D %*% (x/sqrt(1 + c2 *
>> diag(IJ)))))
>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>
>> prop.table(Ctable1[,1])
>>
>> #culling none
>> Delta <- cbind(c(0,1,0,0), c(0,0,1,0), c(0,0,0,1))
>> c2 <- (16 * sqrt(3)/(15 * pi))^2
>> D <- ginv(Delta %*% t(Delta)) %*% Delta
>> Int <- t(apply(test1c.5$Sol[,4:6],1, function(x) + D %*% (x/sqrt(1 + c2 *
>> diag(IJ)))))
>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>
>> prop.table((Ctable1[,2]))
>>
>> HPDinterval(test1c.5$Sol)
>>
>> #model summary
>> > summary(test1c.5)
>>
>>  Iterations = 5001:59991
>>  Thinning interval  = 10
>>  Sample size  = 5500
>>
>>  DIC: 699.7014
>>
>>  G-structure:  ~us(trait):Section
>>
>>                                                         post.mean l-95% CI
>> u-95% CI eff.samp
>> traitactivity.diurnal:traitactivity.diurnal.Section        1.8124  0.09784
>>    5.665    77.01
>> traitactivity.dusk:traitactivity.diurnal.Section           0.8450 -0.83585
>>    3.856    64.17
>> traitactivity.nocturnal:traitactivity.diurnal.Section      1.3621 -1.19129
>>    6.157    58.48
>> traitactivity.diurnal:traitactivity.dusk.Section           0.8450 -0.83585
>>    3.856    64.17
>> traitactivity.dusk:traitactivity.dusk.Section              1.2034  0.07090
>>    3.681   102.16
>> traitactivity.nocturnal:traitactivity.dusk.Section         0.7505 -1.77113
>>    4.524    43.53
>> traitactivity.diurnal:traitactivity.nocturnal.Section      1.3621 -1.19129
>>    6.157    58.48
>> traitactivity.dusk:traitactivity.nocturnal.Section         0.7505 -1.77113
>>    4.524    43.53
>> traitactivity.nocturnal:traitactivity.nocturnal.Section    2.7148  0.09401
>>    8.397    76.59
>>
>>  R-structure:  ~us(trait):units
>>
>>                                                       post.mean l-95% CI
>> u-95% CI eff.samp
>> traitactivity.diurnal:traitactivity.diurnal.units          0.50     0.50
>>   0.50        0
>> traitactivity.dusk:traitactivity.diurnal.units             0.25     0.25
>>   0.25        0
>> traitactivity.nocturnal:traitactivity.diurnal.units        0.25     0.25
>>   0.25        0
>> traitactivity.diurnal:traitactivity.dusk.units             0.25     0.25
>>   0.25        0
>> traitactivity.dusk:traitactivity.dusk.units                0.50     0.50
>>   0.50        0
>> traitactivity.nocturnal:traitactivity.dusk.units           0.25     0.25
>>   0.25        0
>> traitactivity.diurnal:traitactivity.nocturnal.units        0.25     0.25
>>   0.25        0
>> traitactivity.dusk:traitactivity.nocturnal.units           0.25     0.25
>>   0.25        0
>> traitactivity.nocturnal:traitactivity.nocturnal.units      0.50     0.50
>>   0.50        0
>>
>>  Location effects: activity ~ -1 + at.level(culling, 1):trait +
>> at.level(culling, 2):trait
>>
>>                                              post.mean l-95% CI u-95% CI
>> eff.samp  pMCMC
>> at.level(culling, 1):traitactivity.diurnal      1.2306  -0.0533   2.6793
>> 145.29 0.0418 *
>> at.level(culling, 1):traitactivity.dusk         0.6605  -0.6006   2.0761
>>  92.91 0.2840
>> at.level(culling, 1):traitactivity.nocturnal    1.6090   0.0914   3.1356
>> 151.02 0.0265 *
>> traitactivity.diurnal:at.level(culling, 2)      1.2664  -0.1552   2.7750
>> 226.40 0.0604 .
>> traitactivity.dusk:at.level(culling, 2)         0.3533  -0.9898   1.5218
>> 148.44 0.5447
>> traitactivity.nocturnal:at.level(culling, 2)    1.0447  -0.6405   2.8354
>> 346.40 0.1618
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> *##So for the model summary I get that lethal culling at activity diurnal
>> is significantly different from lethal culling at dawn (its the base
>> reference), but I'm also interested in whether lethal culling at activity
>> diurnal is different from lethal culling at dusk for example. Is this
>> possible? *
>>
>> #outcomes culling lethal
>> > summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>
>> Iterations = 1:5500
>> Thinning interval = 1
>> Number of chains = 1
>> Sample size per chain = 5500
>>
>> 1. Empirical mean and standard deviation for each variable,
>>    plus standard error of the mean:
>>
>>        Mean      SD  Naive SE Time-series SE
>> [1,] 0.1253 0.05565 0.0007504       0.002484
>> [2,] 0.3748 0.10497 0.0014155       0.003204
>> [3,] 0.1757 0.06640 0.0008954       0.002515
>> [4,] 0.3242 0.11939 0.0016099       0.003514
>>
>> 2. Quantiles for each variable:
>>
>>         2.5%     25%    50%    75%  97.5%
>> var1 0.03641 0.08695 0.1198 0.1554 0.2553
>> var2 0.17298 0.30580 0.3704 0.4431 0.5896
>> var3 0.06166 0.12913 0.1705 0.2161 0.3215
>> var4 0.12610 0.23999 0.3090 0.3901 0.6045
>>
>> > prop.table(Ctable1[,1])
>>      dawn   diurnal      dusk nocturnal
>> 0.1250000 0.2812500 0.1770833 0.4166667
>>
>>
>> #outcomes culling none
>> > summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>
>> Iterations = 1:5500
>> Thinning interval = 1
>> Number of chains = 1
>> Sample size per chain = 5500
>>
>> 1. Empirical mean and standard deviation for each variable,
>>    plus standard error of the mean:
>>
>>        Mean      SD  Naive SE Time-series SE
>> [1,] 0.1288 0.06141 0.0008280       0.002787
>> [2,] 0.3804 0.10406 0.0014032       0.002662
>> [3,] 0.1710 0.06844 0.0009228       0.002592
>> [4,] 0.3198 0.11812 0.0015928       0.002956
>>
>> 2. Quantiles for each variable:
>>
>>         2.5%     25%    50%    75%  97.5%
>> var1 0.02891 0.08896 0.1220 0.1594 0.2685
>> var2 0.18007 0.31094 0.3783 0.4474 0.5965
>> var3 0.05840 0.12425 0.1634 0.2083 0.3250
>> var4 0.12430 0.23921 0.3077 0.3862 0.5964
>>
>> > prop.table((Ctable1[,2]))
>>      dawn   diurnal      dusk nocturnal
>> 0.1306818 0.4375000 0.1875000 0.2443182
>>
>> Any help or guidance will be greatly appreciated.
>>
>> All the best,
>> Jess
>>
>> --
>> Jessica Comley (PhD)
>> Research Scientist
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

-- 
Jessica Comley (PhD)
Research Scientist

	[[alternative HTML version deleted]]


From benpe|zer @end|ng |rom gm@||@com  Mon Jul 18 12:39:19 2022
From: benpe|zer @end|ng |rom gm@||@com (ben pelzer)
Date: Mon, 18 Jul 2022 12:39:19 +0200
Subject: [R-sig-ME] results lme unstructured covariance matrix, again
In-Reply-To: <5d88d002-d568-269a-50f7-11d259ebff0d@mcmaster.ca>
References: <29754_1657980613_26GEACWL024787_CAFgPNS_+x_ZDwaZUx0tzYs2U2D7s1roFqfcADU+_sTypf8i9jw@mail.gmail.com>
 <5d88d002-d568-269a-50f7-11d259ebff0d@mcmaster.ca>
Message-ID: <CAFgPNS9QbpWOrFiw+TB_sTN0qt+U3GpKp=uwAtd971xnjJoQbQ@mail.gmail.com>

Dear John,

Thank you for answering my question and your nice example with the
alternative model formulations!!. But still I'm in doubt about the results.
The fact that there are only three observed (co)variances which are being
reproduced by four parameters estimates of lme leaves me confused.
Actually, I would think that there is no unique solution without some
constraint being applied. But I could not find something about such a
constraint in lme documentation. The random effects of t1 and t2, or of the
intercept and t2 in your alternative model, should be sufficient to
reproduce the observed (co)variances, so the residual variance is
"unnecassary". I guess that is the reason that lmer is not able to estimate
the model.

library(lme4)
m3 <- lmer(y ~ 1+t2+(1+t2|person), data=da)

Error: number of observations (=20) <= number of random effects (=20)
for term (1 + t2 | person); the random-effects parameters and the
residual variance (or scale parameter) are probably unidentifiable


It's interesting to notice that the two model specifications (t1+t2 and
1+t2) lead to different residual variances estimated by lme. What do these
residual variances mean? And of course also: what do the random effect
variances estimated by both model formulations actually mean or stand for?
Do you have any ideas? Kind regards,

Ben.

On Sat, 16 Jul 2022 at 16:50, John Fox <jfox at mcmaster.ca> wrote:

> Dear Ben,
>
> First, I'll make this into a reproducible example:
>
>  > set.seed(123)
>  > t1 <- c(rep(1, 10), rep(0, 10))
>  > t2 <- 1 - t1
>  > person <- rep(1:10, 2)
>  > y <- t2 + rnorm(20)
>  > da <- data.frame(y, t1, t2, person)
>
>  > library(nlme)
>
> Then note that the random-effect specification 0 + t1 + t2 is simply a
> reparametrization of 1 + t2 (i.e., 1 = t1 + t2), which produces the same
> fit to the data (same fixed effects, same restricted log-likelihood):
>
>  > m1 <- lme(y ~ 1 + t2, random = ~ 0 + t1 + t2 | person, data=da)
>  > m2 <- lme(y ~ 1 + t2, random = ~ 1 + t2 | person, data=da)
>  > m1
> Linear mixed-effects model fit by REML
>    Data: da
>    Log-restricted-likelihood: -25.92726
>    Fixed: y ~ 1 + t2
> (Intercept)          t2
>   0.07462564  1.13399632
>
> Random effects:
>   Formula: ~0 + t1 + t2 | person
>   Structure: General positive-definite, Log-Cholesky parametrization
>           StdDev    Corr
> t1       0.8964136 t1
> t2       0.9856215 0.647
> Residual 0.3258015
>
> Number of Observations: 20
> Number of Groups: 10
>
>  > m2
> Linear mixed-effects model fit by REML
>    Data: da
>    Log-restricted-likelihood: -25.92726
>    Fixed: y ~ 1 + t2
> (Intercept)          t2
>   0.07462564  1.13399632
>
> Random effects:
>   Formula: ~1 + t2 | person
>   Structure: General positive-definite, Log-Cholesky parametrization
>              StdDev    Corr
> (Intercept) 0.8787887 (Intr)
> t2          0.7540826 -0.302
> Residual    0.3707215
>
> Number of Observations: 20
> Number of Groups: 10
>
> Finally, it's unnecessary to supply the intercept 1 in the model formula
> since the intercept is implied if it's not explicitly excluded:
>
>  > m3 <- lme(y ~ t2, random = ~ t2 | person, data=da)
>  > m3
> Linear mixed-effects model fit by REML
>    Data: da
>    Log-restricted-likelihood: -25.92726
>    Fixed: y ~ t2
> (Intercept)          t2
>   0.07462564  1.13399632
>
> Random effects:
>   Formula: ~t2 | person
>   Structure: General positive-definite, Log-Cholesky parametrization
>              StdDev    Corr
> (Intercept) 0.8787887 (Intr)
> t2          0.7540826 -0.302
> Residual    0.3707215
>
> Number of Observations: 20
> Number of Groups: 10
>
> I hope this helps,
>   John
>
> On 2022-07-16 10:05 a.m., ben pelzer wrote:
> > Sorry, my previous mailed contained another question which is
> irrelevant...
> > I deleted that now.
> >
> >
> > Hi all,
> >
> > I have a question about results from lme of package nlme.
> >
> > Suppose the data consists of repeated measures at two fixed time points.
> >
> > I used the following equation:
> >
> >
> >
> > Model1 <- lme ( y ~ 1+t2 , random = ~ 0 + t1+t2|person, data=da)
> >
> >
> >
> > y is the dependent, t1 and t2 are binary dummy variables, valued 0 or 1,
> > indicating the time point.  Model1 is estimated without any convergence
> > problems and the reproduced (co)variances found with
> >
> >
> >
> > getVarCov(Model1, type=?marginal?, indivual=?1?)
> >
> >
> >
> > are identical to the observed (co)variances.
> >
> >
> > My question is:  how can lme estimate 4 (co)variances with only 3 known
> > (co)variances?
> >
> >
> >
> > The 4 estimates concern:
> >
> > -          std. deviation of the random effect of dummy t1
> >
> > -          std. deviation of the random effect of dummy t2
> >
> > -          covariance of the random effects of the dummies t1 and t2 t1
> >
> > -          residual std. error
> >
> >
> >
> > Related to the question above: how can the variances of the random
> effects
> > and the residual std. error be interpreted?
> >
> >
> >
> > Thanks for any help,
> >
> >
> >
> > Ben.
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> --
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> web: https://socialsciences.mcmaster.ca/jfox/
>
>

	[[alternative HTML version deleted]]


From @@mue|@mu|| @end|ng |rom un|-bonn@de  Mon Jul 18 16:53:53 2022
From: @@mue|@mu|| @end|ng |rom un|-bonn@de (Samuel Muli)
Date: Mon, 18 Jul 2022 16:53:53 +0200
Subject: [R-sig-ME] Fisher matrix not invertible - Glmmlasso
In-Reply-To: <0a4c90a3-1758-24bb-dd43-fe22c2797e9f@uni-bonn.de>
References: <0a4c90a3-1758-24bb-dd43-fe22c2797e9f@uni-bonn.de>
Message-ID: <b815715a-820c-7ad1-d96a-6038802319f0@uni-bonn.de>

Hi:

Previously, I had sought help with "fisher matrix not invertible" while 
fitting a glmmLasso but lack of reproducible example might hinder 
getting further help with what seems like a programming/data problem.? 
On this link, we provide both code and link to the publicly available 
dataset and further details: 
https://stats.stackexchange.com/questions/582255/glmmlasso-fisher-matrix-not-invertible-glmm 


In brief, after running for some time, the model encounters a fatal 
error, "fisher matrix not invertible" if the number of features is more 
than the total number of subject ids, below which it works just fine.

Best regards,

Sam






	[[alternative HTML version deleted]]


From wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n|  Mon Jul 18 17:56:06 2022
From: wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n| (Viechtbauer, Wolfgang (NP))
Date: Mon, 18 Jul 2022 15:56:06 +0000
Subject: [R-sig-ME] results lme unstructured covariance matrix, again
In-Reply-To: <CAFgPNS9QbpWOrFiw+TB_sTN0qt+U3GpKp=uwAtd971xnjJoQbQ@mail.gmail.com>
References: <29754_1657980613_26GEACWL024787_CAFgPNS_+x_ZDwaZUx0tzYs2U2D7s1roFqfcADU+_sTypf8i9jw@mail.gmail.com>
 <5d88d002-d568-269a-50f7-11d259ebff0d@mcmaster.ca>
 <CAFgPNS9QbpWOrFiw+TB_sTN0qt+U3GpKp=uwAtd971xnjJoQbQ@mail.gmail.com>
Message-ID: <e31f0efeafe7432e859aebcfdf4fc4d1@UM-MAIL3214.unimaas.nl>

Dear Ben,

The model is overparameterized. There is an infinite number of solutions that lead to the same marginal variance-covariance structure and the same log likelihood. lme() is giving you one solution, but what solution is given is essentially arbitrary and might depend on the optimizer used.

One way to show this is to examine profile likelihood plots. Although metafor wasn't designed for analyzing raw data (it's a package for meta-analysis), we can fit the same model using its rma.mv() function and then obtain profile likelihood plots. You will find that they are flat for large portions of the profiles.

set.seed(123)

t1 <- c(rep(1, 10), rep(0, 10))
t2 <- 1 - t1
person <- rep(1:10, 2)
y <- t2 + rnorm(20)
da <- data.frame(y, t1, t2, person)
da <- da[order(da$person),]

library(nlme)

model1 <- lme(y ~ t2, random = ~ 0 + t1 +t2 | person, data=da)
summary(model1)
getVarCov(model1, type="marginal", indivual="1")

da$id <- 1:nrow(da)

library(metafor)

model2 <- rma.mv(y ~ t2, V=0, random = list(~ 0 + t1 + t2 | person, ~ 1 | id), struct="GEN", data=da, control=list(REMLf=FALSE))
model2

# same log likelihoods even though the parameter estimates are different
logLik(model1)
logLik(model2)

# same marginal var-cov structure
round(vcov(model3, type="obs")[1:2,1:2], 4)

# profile likelihood plots
profile(model2)

So, the specific variance component estimates provided cannot really be interpreted in any meaningful way, or put differently, they are one of many solutions leading to the same marginal var-cov structure.

Best,
Wolfgang

>-----Original Message-----
>From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On
>Behalf Of ben pelzer
>Sent: Monday, 18 July, 2022 12:39
>To: John Fox
>Cc: r-sig-mixed-models at r-project.org
>Subject: Re: [R-sig-ME] results lme unstructured covariance matrix, again
>
>Dear John,
>
>Thank you for answering my question and your nice example with the
>alternative model formulations!!. But still I'm in doubt about the results.
>The fact that there are only three observed (co)variances which are being
>reproduced by four parameters estimates of lme leaves me confused.
>Actually, I would think that there is no unique solution without some
>constraint being applied. But I could not find something about such a
>constraint in lme documentation. The random effects of t1 and t2, or of the
>intercept and t2 in your alternative model, should be sufficient to
>reproduce the observed (co)variances, so the residual variance is
>"unnecassary". I guess that is the reason that lmer is not able to estimate
>the model.
>
>library(lme4)
>m3 <- lmer(y ~ 1+t2+(1+t2|person), data=da)
>
>Error: number of observations (=20) <= number of random effects (=20)
>for term (1 + t2 | person); the random-effects parameters and the
>residual variance (or scale parameter) are probably unidentifiable
>
>It's interesting to notice that the two model specifications (t1+t2 and
>1+t2) lead to different residual variances estimated by lme. What do these
>residual variances mean? And of course also: what do the random effect
>variances estimated by both model formulations actually mean or stand for?
>Do you have any ideas? Kind regards,
>
>Ben.
>
>On Sat, 16 Jul 2022 at 16:50, John Fox <jfox at mcmaster.ca> wrote:
>
>> Dear Ben,
>>
>> First, I'll make this into a reproducible example:
>>
>>  > set.seed(123)
>>  > t1 <- c(rep(1, 10), rep(0, 10))
>>  > t2 <- 1 - t1
>>  > person <- rep(1:10, 2)
>>  > y <- t2 + rnorm(20)
>>  > da <- data.frame(y, t1, t2, person)
>>
>>  > library(nlme)
>>
>> Then note that the random-effect specification 0 + t1 + t2 is simply a
>> reparametrization of 1 + t2 (i.e., 1 = t1 + t2), which produces the same
>> fit to the data (same fixed effects, same restricted log-likelihood):
>>
>>  > m1 <- lme(y ~ 1 + t2, random = ~ 0 + t1 + t2 | person, data=da)
>>  > m2 <- lme(y ~ 1 + t2, random = ~ 1 + t2 | person, data=da)
>>  > m1
>> Linear mixed-effects model fit by REML
>>    Data: da
>>    Log-restricted-likelihood: -25.92726
>>    Fixed: y ~ 1 + t2
>> (Intercept)          t2
>>   0.07462564  1.13399632
>>
>> Random effects:
>>   Formula: ~0 + t1 + t2 | person
>>   Structure: General positive-definite, Log-Cholesky parametrization
>>           StdDev    Corr
>> t1       0.8964136 t1
>> t2       0.9856215 0.647
>> Residual 0.3258015
>>
>> Number of Observations: 20
>> Number of Groups: 10
>>
>>  > m2
>> Linear mixed-effects model fit by REML
>>    Data: da
>>    Log-restricted-likelihood: -25.92726
>>    Fixed: y ~ 1 + t2
>> (Intercept)          t2
>>   0.07462564  1.13399632
>>
>> Random effects:
>>   Formula: ~1 + t2 | person
>>   Structure: General positive-definite, Log-Cholesky parametrization
>>              StdDev    Corr
>> (Intercept) 0.8787887 (Intr)
>> t2          0.7540826 -0.302
>> Residual    0.3707215
>>
>> Number of Observations: 20
>> Number of Groups: 10
>>
>> Finally, it's unnecessary to supply the intercept 1 in the model formula
>> since the intercept is implied if it's not explicitly excluded:
>>
>>  > m3 <- lme(y ~ t2, random = ~ t2 | person, data=da)
>>  > m3
>> Linear mixed-effects model fit by REML
>>    Data: da
>>    Log-restricted-likelihood: -25.92726
>>    Fixed: y ~ t2
>> (Intercept)          t2
>>   0.07462564  1.13399632
>>
>> Random effects:
>>   Formula: ~t2 | person
>>   Structure: General positive-definite, Log-Cholesky parametrization
>>              StdDev    Corr
>> (Intercept) 0.8787887 (Intr)
>> t2          0.7540826 -0.302
>> Residual    0.3707215
>>
>> Number of Observations: 20
>> Number of Groups: 10
>>
>> I hope this helps,
>>   John

From jepu@to @end|ng |rom gm@||@com  Mon Jul 18 18:05:21 2022
From: jepu@to @end|ng |rom gm@||@com (James Pustejovsky)
Date: Mon, 18 Jul 2022 11:05:21 -0500
Subject: [R-sig-ME] results lme unstructured covariance matrix, again
In-Reply-To: <CAFgPNS9QbpWOrFiw+TB_sTN0qt+U3GpKp=uwAtd971xnjJoQbQ@mail.gmail.com>
References: <29754_1657980613_26GEACWL024787_CAFgPNS_+x_ZDwaZUx0tzYs2U2D7s1roFqfcADU+_sTypf8i9jw@mail.gmail.com>
 <5d88d002-d568-269a-50f7-11d259ebff0d@mcmaster.ca>
 <CAFgPNS9QbpWOrFiw+TB_sTN0qt+U3GpKp=uwAtd971xnjJoQbQ@mail.gmail.com>
Message-ID: <CAFUVuJxbs5RL3zPe6N84fpxy9N7UDy2aQe0Fcv+auy_BLq7NYA@mail.gmail.com>

Hi Ben,

I agree that this model is over-parameterized, so the distinction between
the random effects variance components and the level-1 variance is
arbitrary. You can see this by re-estimating the model with a fixed sigma
that is less than or equal to the MLE. Here's an example, modified a bit
from Dr. Fox's:

library(nlme)
library(mvtnorm)
set.seed(123)
N <- 1000
t1 <- c(rep(1, N), rep(0, N))
t2 <- 1 - t1
person <- rep(1:N, 2)
e <- rmvnorm(N, mean = c(0,1), sigma = matrix(c(1, 0.4, 0.4, 0.5), 2, 2))
y <- as.vector(e)
dat <- data.frame(y, t1, t2, person)

m1 <- lme(y ~ 1 + t2, random = ~ 0 + t1 + t2 | person, data=dat)
m2 <- lme(y ~ 1 + t2, random = ~ 1 + t2 | person, data=dat)
m3 <- lme(y ~ 1 + t2, random = ~ 0 + t1 + t2 | person, data=dat,
          control = lmeControl(sigma = 0.1))

The marginal variance-covariance is identical across all three models:
getVarCov(m1, type="marginal", individual="1")
getVarCov(m2, type="marginal", individual="1")
getVarCov(m3, type="marginal", individual="1")

I would guess that the fact that lme() returns a result at all is due to
how the model is estimated. lme() profiles out the sigma estimator and then
solves for the MLEs of the random effects variance-covariance matrix. As
Wolfgang noted, the result might depend on the optimizer. One peculiarity
is that the log likelihood of m3 differs from that of the other two:
> logLik(m1)
'log Lik.' -2301.013 (df=6)
> logLik(m2)
'log Lik.' -2301.013 (df=6)
> logLik(m3)
'log Lik.' -2323.984 (df=5)

James

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Mon Jul 18 18:18:04 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 18 Jul 2022 12:18:04 -0400
Subject: [R-sig-ME] results lme unstructured covariance matrix, again
In-Reply-To: <CAFUVuJxbs5RL3zPe6N84fpxy9N7UDy2aQe0Fcv+auy_BLq7NYA@mail.gmail.com>
References: <29754_1657980613_26GEACWL024787_CAFgPNS_+x_ZDwaZUx0tzYs2U2D7s1roFqfcADU+_sTypf8i9jw@mail.gmail.com>
 <5d88d002-d568-269a-50f7-11d259ebff0d@mcmaster.ca>
 <CAFgPNS9QbpWOrFiw+TB_sTN0qt+U3GpKp=uwAtd971xnjJoQbQ@mail.gmail.com>
 <CAFUVuJxbs5RL3zPe6N84fpxy9N7UDy2aQe0Fcv+auy_BLq7NYA@mail.gmail.com>
Message-ID: <58e1f617-db46-c48c-d52c-a19989dd6150@gmail.com>

 ? For what it's worth you *can* fit this overparameterized model in 
lmer as well, you just have to override some controls

m4 <- lmer(y ~ 1 + t2 + (0 + t1 + t2 | person), data? = dat,
 ?????????? control = lmerControl(check.nobs.vs.nRE = "ignore"))


preds <- cbind(sapply(list(m1, m2, m3), predict, level = 0),
 ????? predict(m4, re.form = NA))

 ?The predictions are all the same **if you predict at the population 
level**; if you try to make predictions taking the random effects into 
account, the results differ because what is counted as "residual error" 
vs "random effects variation" differs among the models.

On 2022-07-18 12:05 PM, James Pustejovsky wrote:
> Hi Ben,
>
> I agree that this model is over-parameterized, so the distinction between
> the random effects variance components and the level-1 variance is
> arbitrary. You can see this by re-estimating the model with a fixed sigma
> that is less than or equal to the MLE. Here's an example, modified a bit
> from Dr. Fox's:
>
> library(nlme)
> library(mvtnorm)
> set.seed(123)
> N <- 1000
> t1 <- c(rep(1, N), rep(0, N))
> t2 <- 1 - t1
> person <- rep(1:N, 2)
> e <- rmvnorm(N, mean = c(0,1), sigma = matrix(c(1, 0.4, 0.4, 0.5), 2, 2))
> y <- as.vector(e)
> dat <- data.frame(y, t1, t2, person)
>
> m1 <- lme(y ~ 1 + t2, random = ~ 0 + t1 + t2 | person, data=dat)
> m2 <- lme(y ~ 1 + t2, random = ~ 1 + t2 | person, data=dat)
> m3 <- lme(y ~ 1 + t2, random = ~ 0 + t1 + t2 | person, data=dat,
>            control = lmeControl(sigma = 0.1))
>
> The marginal variance-covariance is identical across all three models:
> getVarCov(m1, type="marginal", individual="1")
> getVarCov(m2, type="marginal", individual="1")
> getVarCov(m3, type="marginal", individual="1")
>
> I would guess that the fact that lme() returns a result at all is due to
> how the model is estimated. lme() profiles out the sigma estimator and then
> solves for the MLEs of the random effects variance-covariance matrix. As
> Wolfgang noted, the result might depend on the optimizer. One peculiarity
> is that the log likelihood of m3 differs from that of the other two:
>> logLik(m1)
> 'log Lik.' -2301.013 (df=6)
>> logLik(m2)
> 'log Lik.' -2301.013 (df=6)
>> logLik(m3)
> 'log Lik.' -2323.984 (df=5)
>
> James
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From j|ox @end|ng |rom mcm@@ter@c@  Mon Jul 18 19:32:04 2022
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Mon, 18 Jul 2022 13:32:04 -0400
Subject: [R-sig-ME] results lme unstructured covariance matrix, again
In-Reply-To: <CAFgPNS9QbpWOrFiw+TB_sTN0qt+U3GpKp=uwAtd971xnjJoQbQ@mail.gmail.com>
References: <29754_1657980613_26GEACWL024787_CAFgPNS_+x_ZDwaZUx0tzYs2U2D7s1roFqfcADU+_sTypf8i9jw@mail.gmail.com>
 <5d88d002-d568-269a-50f7-11d259ebff0d@mcmaster.ca>
 <CAFgPNS9QbpWOrFiw+TB_sTN0qt+U3GpKp=uwAtd971xnjJoQbQ@mail.gmail.com>
Message-ID: <dfe266dd-b96a-c28f-9cdd-121634019be9@mcmaster.ca>

Dear Ben,

My apologies---I paid attention to the inessential part of your message, 
which was the parametrization of the model rather than the 
variance-covariance structure.

This is a little awkward because of the LaTeX (and as far as I know, I 
can't attach a PDF, but maybe you can paste this into a LaTeX editor):

The model is $Y_{ij} = \alpha + \beta x_{ij} + \delta_{1i} + \delta_{2i} 
x_{ij} + \varepsilon_{ij}$ for $i = 1, \ldots, n$ and $j = 1,2$, where 
$x_{i1} = 1$ and $x_{i2} = 0$.

The variances of the random effects are $V(\delta_{1i}) = \psi_1^2$ and 
$V(\delta_{2i}) = \psi_2^2$, and their covariance is $C(\delta_{1i}, 
\delta_{2i}) = \psi_{12}$. The observation-level error variance is 
$V(\varepsilon_{ij}) = \sigma^2$.

Then the composite error is $\zeta_{ij} = \delta_{1i} + \delta_{2i} 
x_{ij} + \varepsilon_{ij}$ with variance $V(\zeta_{ij}) =    \psi_1^2 + 
x^2_{ij} \psi_2^2 + 2 x_{ij} \psi_{12} + \sigma^2$, which is 
$V(\zeta_{i1}) = \psi_1^2 + \psi_2^2 + 2\psi_{12} + \sigma^2$ for $j = 
1$ and  $V(\zeta_{i2}) =   \psi_1^2  + \sigma^2$ for $j = 2$, and 
covariance $C(\zeta_{i1}, \zeta_{i2}) = \psi_1^2 + \psi_2^2$.

There are, as you say, 4 variance-covariance components, $\psi_1^2, 
\psi_2^2, \psi_{12}, \sigma^2$, and just 3 variances and covariances 
among the composite disturbances, $V(\zeta_{i1}), V(\zeta_{i2}), 
C(\zeta_{i1}, \zeta_{i2})$, and so---as you and several others have 
noted (but I missed)---the variance-covariance components are 
underidentified.

lmer(), but not lme(), appears to use a heuristic, counting the number 
of random effects and observations, to detect underidentification. I 
don't know whether that's bullet-proof, but it works in this case. Maybe 
Ben Bolker, who has already responded, can comment further.

Best,
  John

John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/

On 2022-07-18 6:39 a.m., ben pelzer wrote:
> Dear John,
> 
> Thank you for answering my question and your nice example with the 
> alternative model formulations!!. But still I'm in doubt about the 
> results. The fact that there are only three observed (co)variances which 
> are being reproduced by four parameters estimates of lme leaves me 
> confused. Actually, I would think that there is no unique solution 
> without some constraint being applied. But I could not find something 
> about such a constraint in lme documentation. The random effects of t1 
> and t2, or of the intercept and t2 in your alternative model, should be 
> sufficient to reproduce the observed (co)variances, so the residual 
> variance is "unnecassary". I guess that is the reason that lmer is not 
> able to estimate the model.
> 
> library(lme4)
> m3 <- lmer(y ~ 1+t2+(1+t2|person), data=da)
> 
> Error: number of observations (=20) <= number of random effects (=20) 
> for term (1 + t2 | person); the random-effects parameters and the 
> residual variance (or scale parameter) are probably unidentifiable
> 
> 
> It's interesting to notice that the two model specifications (t1+t2 and 
> 1+t2) lead to different residual variances estimated by lme. What do 
> these residual variances mean? And of course also: what do the random 
> effect variances estimated by both model formulations actually mean or 
> stand for? Do you have any ideas? Kind regards,
> 
> Ben.
> 
> On Sat, 16 Jul 2022 at 16:50, John Fox <jfox at mcmaster.ca 
> <mailto:jfox at mcmaster.ca>> wrote:
> 
>     Dear Ben,
> 
>     First, I'll make this into a reproducible example:
> 
>      ?> set.seed(123)
>      ?> t1 <- c(rep(1, 10), rep(0, 10))
>      ?> t2 <- 1 - t1
>      ?> person <- rep(1:10, 2)
>      ?> y <- t2 + rnorm(20)
>      ?> da <- data.frame(y, t1, t2, person)
> 
>      ?> library(nlme)
> 
>     Then note that the random-effect specification 0 + t1 + t2 is simply a
>     reparametrization of 1 + t2 (i.e., 1 = t1 + t2), which produces the
>     same
>     fit to the data (same fixed effects, same restricted log-likelihood):
> 
>      ?> m1 <- lme(y ~ 1 + t2, random = ~ 0 + t1 + t2 | person, data=da)
>      ?> m2 <- lme(y ~ 1 + t2, random = ~ 1 + t2 | person, data=da)
>      ?> m1
>     Linear mixed-effects model fit by REML
>      ? ?Data: da
>      ? ?Log-restricted-likelihood: -25.92726
>      ? ?Fixed: y ~ 1 + t2
>     (Intercept)? ? ? ? ? t2
>      ? 0.07462564? 1.13399632
> 
>     Random effects:
>      ? Formula: ~0 + t1 + t2 | person
>      ? Structure: General positive-definite, Log-Cholesky parametrization
>      ? ? ? ? ? StdDev? ? Corr
>     t1? ? ? ?0.8964136 t1
>     t2? ? ? ?0.9856215 0.647
>     Residual 0.3258015
> 
>     Number of Observations: 20
>     Number of Groups: 10
> 
>      ?> m2
>     Linear mixed-effects model fit by REML
>      ? ?Data: da
>      ? ?Log-restricted-likelihood: -25.92726
>      ? ?Fixed: y ~ 1 + t2
>     (Intercept)? ? ? ? ? t2
>      ? 0.07462564? 1.13399632
> 
>     Random effects:
>      ? Formula: ~1 + t2 | person
>      ? Structure: General positive-definite, Log-Cholesky parametrization
>      ? ? ? ? ? ? ?StdDev? ? Corr
>     (Intercept) 0.8787887 (Intr)
>     t2? ? ? ? ? 0.7540826 -0.302
>     Residual? ? 0.3707215
> 
>     Number of Observations: 20
>     Number of Groups: 10
> 
>     Finally, it's unnecessary to supply the intercept 1 in the model
>     formula
>     since the intercept is implied if it's not explicitly excluded:
> 
>      ?> m3 <- lme(y ~ t2, random = ~ t2 | person, data=da)
>      ?> m3
>     Linear mixed-effects model fit by REML
>      ? ?Data: da
>      ? ?Log-restricted-likelihood: -25.92726
>      ? ?Fixed: y ~ t2
>     (Intercept)? ? ? ? ? t2
>      ? 0.07462564? 1.13399632
> 
>     Random effects:
>      ? Formula: ~t2 | person
>      ? Structure: General positive-definite, Log-Cholesky parametrization
>      ? ? ? ? ? ? ?StdDev? ? Corr
>     (Intercept) 0.8787887 (Intr)
>     t2? ? ? ? ? 0.7540826 -0.302
>     Residual? ? 0.3707215
> 
>     Number of Observations: 20
>     Number of Groups: 10
> 
>     I hope this helps,
>      ? John
> 
>     On 2022-07-16 10:05 a.m., ben pelzer wrote:
>      > Sorry, my previous mailed contained another question which is
>     irrelevant...
>      > I deleted that now.
>      >
>      >
>      > Hi all,
>      >
>      > I have a question about results from lme of package nlme.
>      >
>      > Suppose the data consists of repeated measures at two fixed time
>     points.
>      >
>      > I used the following equation:
>      >
>      >
>      >
>      > Model1 <- lme ( y ~ 1+t2 , random = ~ 0 + t1+t2|person, data=da)
>      >
>      >
>      >
>      > y is the dependent, t1 and t2 are binary dummy variables, valued
>     0 or 1,
>      > indicating the time point.? Model1 is estimated without any
>     convergence
>      > problems and the reproduced (co)variances found with
>      >
>      >
>      >
>      > getVarCov(Model1, type=?marginal?, indivual=?1?)
>      >
>      >
>      >
>      > are identical to the observed (co)variances.
>      >
>      >
>      > My question is:? how can lme estimate 4 (co)variances with only 3
>     known
>      > (co)variances?
>      >
>      >
>      >
>      > The 4 estimates concern:
>      >
>      > -? ? ? ? ? std. deviation of the random effect of dummy t1
>      >
>      > -? ? ? ? ? std. deviation of the random effect of dummy t2
>      >
>      > -? ? ? ? ? covariance of the random effects of the dummies t1 and
>     t2 t1
>      >
>      > -? ? ? ? ? residual std. error
>      >
>      >
>      >
>      > Related to the question above: how can the variances of the
>     random effects
>      > and the residual std. error be interpreted?
>      >
>      >
>      >
>      > Thanks for any help,
>      >
>      >
>      >
>      > Ben.
>      >
>      >? ? ? ?[[alternative HTML version deleted]]
>      >
>      > _______________________________________________
>      > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     -- 
>     John Fox, Professor Emeritus
>     McMaster University
>     Hamilton, Ontario, Canada
>     web: https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>
>


From j|ox @end|ng |rom mcm@@ter@c@  Tue Jul 19 04:15:53 2022
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Mon, 18 Jul 2022 22:15:53 -0400
Subject: [R-sig-ME] results lme unstructured covariance matrix, again
In-Reply-To: <14495_1658165552_26IHWWJ9018805_dfe266dd-b96a-c28f-9cdd-121634019be9@mcmaster.ca>
References: <29754_1657980613_26GEACWL024787_CAFgPNS_+x_ZDwaZUx0tzYs2U2D7s1roFqfcADU+_sTypf8i9jw@mail.gmail.com>
 <5d88d002-d568-269a-50f7-11d259ebff0d@mcmaster.ca>
 <CAFgPNS9QbpWOrFiw+TB_sTN0qt+U3GpKp=uwAtd971xnjJoQbQ@mail.gmail.com>
 <14495_1658165552_26IHWWJ9018805_dfe266dd-b96a-c28f-9cdd-121634019be9@mcmaster.ca>
Message-ID: <264bc675-51d7-a1d3-b67e-13635140754a@mcmaster.ca>

Dear Ben,

On 2022-07-18 1:32 p.m., John Fox wrote:
> Dear Ben,
> 
> My apologies---I paid attention to the inessential part of your message, 
> which was the parametrization of the model rather than the 
> variance-covariance structure.
> 
> This is a little awkward because of the LaTeX (and as far as I know, I 
> can't attach a PDF, but maybe you can paste this into a LaTeX editor):

Rolf Turner pointed out to me that PDF attachments *are* acceptable, and 
so I've attached a PDF with the LaTeX part of my message.

Best,
John

> 
> The model is $Y_{ij} = \alpha + \beta x_{ij} + \delta_{1i} + \delta_{2i} 
> x_{ij} + \varepsilon_{ij}$ for $i = 1, \ldots, n$ and $j = 1,2$, where 
> $x_{i1} = 1$ and $x_{i2} = 0$.
> 
> The variances of the random effects are $V(\delta_{1i}) = \psi_1^2$ and 
> $V(\delta_{2i}) = \psi_2^2$, and their covariance is $C(\delta_{1i}, 
> \delta_{2i}) = \psi_{12}$. The observation-level error variance is 
> $V(\varepsilon_{ij}) = \sigma^2$.
> 
> Then the composite error is $\zeta_{ij} = \delta_{1i} + \delta_{2i} 
> x_{ij} + \varepsilon_{ij}$ with variance $V(\zeta_{ij}) =??? \psi_1^2 + 
> x^2_{ij} \psi_2^2 + 2 x_{ij} \psi_{12} + \sigma^2$, which is 
> $V(\zeta_{i1}) = \psi_1^2 + \psi_2^2 + 2\psi_{12} + \sigma^2$ for $j = 
> 1$ and? $V(\zeta_{i2}) =?? \psi_1^2? + \sigma^2$ for $j = 2$, and 
> covariance $C(\zeta_{i1}, \zeta_{i2}) = \psi_1^2 + \psi_2^2$.
> 
> There are, as you say, 4 variance-covariance components, $\psi_1^2, 
> \psi_2^2, \psi_{12}, \sigma^2$, and just 3 variances and covariances 
> among the composite disturbances, $V(\zeta_{i1}), V(\zeta_{i2}), 
> C(\zeta_{i1}, \zeta_{i2})$, and so---as you and several others have 
> noted (but I missed)---the variance-covariance components are 
> underidentified.
> 
> lmer(), but not lme(), appears to use a heuristic, counting the number 
> of random effects and observations, to detect underidentification. I 
> don't know whether that's bullet-proof, but it works in this case. Maybe 
> Ben Bolker, who has already responded, can comment further.
> 
> Best,
>  ?John
> 
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> web: https://socialsciences.mcmaster.ca/jfox/
> 
> On 2022-07-18 6:39 a.m., ben pelzer wrote:
>> Dear John,
>>
>> Thank you for answering my question and your nice example with the 
>> alternative model formulations!!. But still I'm in doubt about the 
>> results. The fact that there are only three observed (co)variances 
>> which are being reproduced by four parameters estimates of lme leaves 
>> me confused. Actually, I would think that there is no unique solution 
>> without some constraint being applied. But I could not find something 
>> about such a constraint in lme documentation. The random effects of t1 
>> and t2, or of the intercept and t2 in your alternative model, should 
>> be sufficient to reproduce the observed (co)variances, so the residual 
>> variance is "unnecassary". I guess that is the reason that lmer is not 
>> able to estimate the model.
>>
>> library(lme4)
>> m3 <- lmer(y ~ 1+t2+(1+t2|person), data=da)
>>
>> Error: number of observations (=20) <= number of random effects (=20) 
>> for term (1 + t2 | person); the random-effects parameters and the 
>> residual variance (or scale parameter) are probably unidentifiable
>>
>>
>> It's interesting to notice that the two model specifications (t1+t2 
>> and 1+t2) lead to different residual variances estimated by lme. What 
>> do these residual variances mean? And of course also: what do the 
>> random effect variances estimated by both model formulations actually 
>> mean or stand for? Do you have any ideas? Kind regards,
>>
>> Ben.
>>
>> On Sat, 16 Jul 2022 at 16:50, John Fox <jfox at mcmaster.ca 
>> <mailto:jfox at mcmaster.ca>> wrote:
>>
>> ??? Dear Ben,
>>
>> ??? First, I'll make this into a reproducible example:
>>
>> ???? ?> set.seed(123)
>> ???? ?> t1 <- c(rep(1, 10), rep(0, 10))
>> ???? ?> t2 <- 1 - t1
>> ???? ?> person <- rep(1:10, 2)
>> ???? ?> y <- t2 + rnorm(20)
>> ???? ?> da <- data.frame(y, t1, t2, person)
>>
>> ???? ?> library(nlme)
>>
>> ??? Then note that the random-effect specification 0 + t1 + t2 is 
>> simply a
>> ??? reparametrization of 1 + t2 (i.e., 1 = t1 + t2), which produces the
>> ??? same
>> ??? fit to the data (same fixed effects, same restricted log-likelihood):
>>
>> ???? ?> m1 <- lme(y ~ 1 + t2, random = ~ 0 + t1 + t2 | person, data=da)
>> ???? ?> m2 <- lme(y ~ 1 + t2, random = ~ 1 + t2 | person, data=da)
>> ???? ?> m1
>> ??? Linear mixed-effects model fit by REML
>> ???? ? ?Data: da
>> ???? ? ?Log-restricted-likelihood: -25.92726
>> ???? ? ?Fixed: y ~ 1 + t2
>> ??? (Intercept)? ? ? ? ? t2
>> ???? ? 0.07462564? 1.13399632
>>
>> ??? Random effects:
>> ???? ? Formula: ~0 + t1 + t2 | person
>> ???? ? Structure: General positive-definite, Log-Cholesky parametrization
>> ???? ? ? ? ? ? StdDev? ? Corr
>> ??? t1? ? ? ?0.8964136 t1
>> ??? t2? ? ? ?0.9856215 0.647
>> ??? Residual 0.3258015
>>
>> ??? Number of Observations: 20
>> ??? Number of Groups: 10
>>
>> ???? ?> m2
>> ??? Linear mixed-effects model fit by REML
>> ???? ? ?Data: da
>> ???? ? ?Log-restricted-likelihood: -25.92726
>> ???? ? ?Fixed: y ~ 1 + t2
>> ??? (Intercept)? ? ? ? ? t2
>> ???? ? 0.07462564? 1.13399632
>>
>> ??? Random effects:
>> ???? ? Formula: ~1 + t2 | person
>> ???? ? Structure: General positive-definite, Log-Cholesky parametrization
>> ???? ? ? ? ? ? ? ?StdDev? ? Corr
>> ??? (Intercept) 0.8787887 (Intr)
>> ??? t2? ? ? ? ? 0.7540826 -0.302
>> ??? Residual? ? 0.3707215
>>
>> ??? Number of Observations: 20
>> ??? Number of Groups: 10
>>
>> ??? Finally, it's unnecessary to supply the intercept 1 in the model
>> ??? formula
>> ??? since the intercept is implied if it's not explicitly excluded:
>>
>> ???? ?> m3 <- lme(y ~ t2, random = ~ t2 | person, data=da)
>> ???? ?> m3
>> ??? Linear mixed-effects model fit by REML
>> ???? ? ?Data: da
>> ???? ? ?Log-restricted-likelihood: -25.92726
>> ???? ? ?Fixed: y ~ t2
>> ??? (Intercept)? ? ? ? ? t2
>> ???? ? 0.07462564? 1.13399632
>>
>> ??? Random effects:
>> ???? ? Formula: ~t2 | person
>> ???? ? Structure: General positive-definite, Log-Cholesky parametrization
>> ???? ? ? ? ? ? ? ?StdDev? ? Corr
>> ??? (Intercept) 0.8787887 (Intr)
>> ??? t2? ? ? ? ? 0.7540826 -0.302
>> ??? Residual? ? 0.3707215
>>
>> ??? Number of Observations: 20
>> ??? Number of Groups: 10
>>
>> ??? I hope this helps,
>> ???? ? John
>>
>> ??? On 2022-07-16 10:05 a.m., ben pelzer wrote:
>> ???? > Sorry, my previous mailed contained another question which is
>> ??? irrelevant...
>> ???? > I deleted that now.
>> ???? >
>> ???? >
>> ???? > Hi all,
>> ???? >
>> ???? > I have a question about results from lme of package nlme.
>> ???? >
>> ???? > Suppose the data consists of repeated measures at two fixed time
>> ??? points.
>> ???? >
>> ???? > I used the following equation:
>> ???? >
>> ???? >
>> ???? >
>> ???? > Model1 <- lme ( y ~ 1+t2 , random = ~ 0 + t1+t2|person, data=da)
>> ???? >
>> ???? >
>> ???? >
>> ???? > y is the dependent, t1 and t2 are binary dummy variables, valued
>> ??? 0 or 1,
>> ???? > indicating the time point.? Model1 is estimated without any
>> ??? convergence
>> ???? > problems and the reproduced (co)variances found with
>> ???? >
>> ???? >
>> ???? >
>> ???? > getVarCov(Model1, type=?marginal?, indivual=?1?)
>> ???? >
>> ???? >
>> ???? >
>> ???? > are identical to the observed (co)variances.
>> ???? >
>> ???? >
>> ???? > My question is:? how can lme estimate 4 (co)variances with only 3
>> ??? known
>> ???? > (co)variances?
>> ???? >
>> ???? >
>> ???? >
>> ???? > The 4 estimates concern:
>> ???? >
>> ???? > -? ? ? ? ? std. deviation of the random effect of dummy t1
>> ???? >
>> ???? > -? ? ? ? ? std. deviation of the random effect of dummy t2
>> ???? >
>> ???? > -? ? ? ? ? covariance of the random effects of the dummies t1 and
>> ??? t2 t1
>> ???? >
>> ???? > -? ? ? ? ? residual std. error
>> ???? >
>> ???? >
>> ???? >
>> ???? > Related to the question above: how can the variances of the
>> ??? random effects
>> ???? > and the residual std. error be interpreted?
>> ???? >
>> ???? >
>> ???? >
>> ???? > Thanks for any help,
>> ???? >
>> ???? >
>> ???? >
>> ???? > Ben.
>> ???? >
>> ???? >? ? ? ?[[alternative HTML version deleted]]
>> ???? >
>> ???? > _______________________________________________
>> ???? > R-sig-mixed-models at r-project.org
>> ??? <mailto:R-sig-mixed-models at r-project.org> mailing list
>> ???? > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> ??? <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>> ??? -- ??? John Fox, Professor Emeritus
>> ??? McMaster University
>> ??? Hamilton, Ontario, Canada
>> ??? web: https://socialsciences.mcmaster.ca/jfox/
>> ??? <https://socialsciences.mcmaster.ca/jfox/>
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
-- 
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/

-------------- next part --------------
A non-text attachment was scrubbed...
Name: mixed-model.pdf
Type: application/pdf
Size: 44332 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20220718/71e792e8/attachment-0001.pdf>

From benpe|zer @end|ng |rom gm@||@com  Tue Jul 19 14:50:47 2022
From: benpe|zer @end|ng |rom gm@||@com (ben pelzer)
Date: Tue, 19 Jul 2022 14:50:47 +0200
Subject: [R-sig-ME] results lme unstructured covariance matrix, again
In-Reply-To: <264bc675-51d7-a1d3-b67e-13635140754a@mcmaster.ca>
References: <29754_1657980613_26GEACWL024787_CAFgPNS_+x_ZDwaZUx0tzYs2U2D7s1roFqfcADU+_sTypf8i9jw@mail.gmail.com>
 <5d88d002-d568-269a-50f7-11d259ebff0d@mcmaster.ca>
 <CAFgPNS9QbpWOrFiw+TB_sTN0qt+U3GpKp=uwAtd971xnjJoQbQ@mail.gmail.com>
 <14495_1658165552_26IHWWJ9018805_dfe266dd-b96a-c28f-9cdd-121634019be9@mcmaster.ca>
 <264bc675-51d7-a1d3-b67e-13635140754a@mcmaster.ca>
Message-ID: <CAFgPNS-B7r1Q+a9-f6rvesZTAhiAM0_UdZyvHPiFBcfheozkkA@mail.gmail.com>

Dear John, Wolfgang, James and Ben,

Thanks to you all for your explanations and examples! As I understand it
now, cancelling the estimation of the sigma, by fixing it to a small
positive number close to zero, produces random effects estimates of the
intercept and t2 (or of t1 and t2) which make sense. However, the
loglikelihood doesn't make sense. I guess that with sigma fixed to nearly
zero, the predictions will be meaningful too, even when including the
random effects in the predictions, though I did not verify that yet.

All in all, I think that for a model with an unstructured covariance
matrix, "gls" is more straightforward. For the example of John:

da$time <- da$t2 + 1
m4 <- gls(y ~ 1 + t2,
          correlation=corSymm(form= ~time|person),
          weights=varIdent(form= ~1|time),
          data=da)

and the results are equal to e.g.

m2 <- lme(y ~ 1 + t2, random = ~ 1 + t2 | person, data=da)

as far as the loglikelihood and the estimated (co)variances (getVarCov) are
concerned.

My question about "lme" arose when helping someone with such an
unstructured covariances model, for data with three fixed occasions. With
"many" occasions, a random linear effect of time is often employed, or
maybe a random quadratic time effect or cubic... Anyway, time is used as a
random (linear etc) effect in such models. But with only three occasions,
and with the time effect not being linear but quadratic, the model turns
into the kind of model I was questioning about, but with three occasions
instead of two. So, instead of

modelA <- lme(y ~ 1+time+timesquared, random= ~ 1+time+timesquared |
person, data=da)

one could then use

modelB <- lme(y ~ 1+t2+t3, random= ~ 1+t2+t3 | person, data=da)

But the random effect variances of t2 and t3 are not meaningful, as I know
now. And with the often used "lmer" the model is not estimated (except when
avoiding the "counting check" as Ben Bolker explained). This means that the
"random time effect" models, which I explain to students in a course, is
not applicable to such data. I thought/hoped that "lme" could be used, and
in a way it can, with fixing the sigma, but apparently this also leads to
some "unexpected" results. On the other hand, "gls" is a new method for
students used to the "random time effect" models. So I have to choose among
these two possibilities.

Thanks again everyone, time to switch off the computer and enjoy the sun.
It's almost 40 degrees Celsius or 104 Farenheit in The Netherlands now, so
maybe enjoying is not the right word. Best to you all,

Ben Pelzer.





On Tue, 19 Jul 2022 at 04:15, John Fox <jfox at mcmaster.ca> wrote:

> Dear Ben,
>
> On 2022-07-18 1:32 p.m., John Fox wrote:
> > Dear Ben,
> >
> > My apologies---I paid attention to the inessential part of your message,
> > which was the parametrization of the model rather than the
> > variance-covariance structure.
> >
> > This is a little awkward because of the LaTeX (and as far as I know, I
> > can't attach a PDF, but maybe you can paste this into a LaTeX editor):
>
> Rolf Turner pointed out to me that PDF attachments *are* acceptable, and
> so I've attached a PDF with the LaTeX part of my message.
>
> Best,
> John
>
> >
> > The model is $Y_{ij} = \alpha + \beta x_{ij} + \delta_{1i} + \delta_{2i}
> > x_{ij} + \varepsilon_{ij}$ for $i = 1, \ldots, n$ and $j = 1,2$, where
> > $x_{i1} = 1$ and $x_{i2} = 0$.
> >
> > The variances of the random effects are $V(\delta_{1i}) = \psi_1^2$ and
> > $V(\delta_{2i}) = \psi_2^2$, and their covariance is $C(\delta_{1i},
> > \delta_{2i}) = \psi_{12}$. The observation-level error variance is
> > $V(\varepsilon_{ij}) = \sigma^2$.
> >
> > Then the composite error is $\zeta_{ij} = \delta_{1i} + \delta_{2i}
> > x_{ij} + \varepsilon_{ij}$ with variance $V(\zeta_{ij}) =    \psi_1^2 +
> > x^2_{ij} \psi_2^2 + 2 x_{ij} \psi_{12} + \sigma^2$, which is
> > $V(\zeta_{i1}) = \psi_1^2 + \psi_2^2 + 2\psi_{12} + \sigma^2$ for $j =
> > 1$ and  $V(\zeta_{i2}) =   \psi_1^2  + \sigma^2$ for $j = 2$, and
> > covariance $C(\zeta_{i1}, \zeta_{i2}) = \psi_1^2 + \psi_2^2$.
> >
> > There are, as you say, 4 variance-covariance components, $\psi_1^2,
> > \psi_2^2, \psi_{12}, \sigma^2$, and just 3 variances and covariances
> > among the composite disturbances, $V(\zeta_{i1}), V(\zeta_{i2}),
> > C(\zeta_{i1}, \zeta_{i2})$, and so---as you and several others have
> > noted (but I missed)---the variance-covariance components are
> > underidentified.
> >
> > lmer(), but not lme(), appears to use a heuristic, counting the number
> > of random effects and observations, to detect underidentification. I
> > don't know whether that's bullet-proof, but it works in this case. Maybe
> > Ben Bolker, who has already responded, can comment further.
> >
> > Best,
> >   John
> >
> > John Fox, Professor Emeritus
> > McMaster University
> > Hamilton, Ontario, Canada
> > web: https://socialsciences.mcmaster.ca/jfox/
> >
> > On 2022-07-18 6:39 a.m., ben pelzer wrote:
> >> Dear John,
> >>
> >> Thank you for answering my question and your nice example with the
> >> alternative model formulations!!. But still I'm in doubt about the
> >> results. The fact that there are only three observed (co)variances
> >> which are being reproduced by four parameters estimates of lme leaves
> >> me confused. Actually, I would think that there is no unique solution
> >> without some constraint being applied. But I could not find something
> >> about such a constraint in lme documentation. The random effects of t1
> >> and t2, or of the intercept and t2 in your alternative model, should
> >> be sufficient to reproduce the observed (co)variances, so the residual
> >> variance is "unnecassary". I guess that is the reason that lmer is not
> >> able to estimate the model.
> >>
> >> library(lme4)
> >> m3 <- lmer(y ~ 1+t2+(1+t2|person), data=da)
> >>
> >> Error: number of observations (=20) <= number of random effects (=20)
> >> for term (1 + t2 | person); the random-effects parameters and the
> >> residual variance (or scale parameter) are probably unidentifiable
> >>
> >>
> >> It's interesting to notice that the two model specifications (t1+t2
> >> and 1+t2) lead to different residual variances estimated by lme. What
> >> do these residual variances mean? And of course also: what do the
> >> random effect variances estimated by both model formulations actually
> >> mean or stand for? Do you have any ideas? Kind regards,
> >>
> >> Ben.
> >>
> >> On Sat, 16 Jul 2022 at 16:50, John Fox <jfox at mcmaster.ca
> >> <mailto:jfox at mcmaster.ca>> wrote:
> >>
> >>     Dear Ben,
> >>
> >>     First, I'll make this into a reproducible example:
> >>
> >>       > set.seed(123)
> >>       > t1 <- c(rep(1, 10), rep(0, 10))
> >>       > t2 <- 1 - t1
> >>       > person <- rep(1:10, 2)
> >>       > y <- t2 + rnorm(20)
> >>       > da <- data.frame(y, t1, t2, person)
> >>
> >>       > library(nlme)
> >>
> >>     Then note that the random-effect specification 0 + t1 + t2 is
> >> simply a
> >>     reparametrization of 1 + t2 (i.e., 1 = t1 + t2), which produces the
> >>     same
> >>     fit to the data (same fixed effects, same restricted
> log-likelihood):
> >>
> >>       > m1 <- lme(y ~ 1 + t2, random = ~ 0 + t1 + t2 | person, data=da)
> >>       > m2 <- lme(y ~ 1 + t2, random = ~ 1 + t2 | person, data=da)
> >>       > m1
> >>     Linear mixed-effects model fit by REML
> >>         Data: da
> >>         Log-restricted-likelihood: -25.92726
> >>         Fixed: y ~ 1 + t2
> >>     (Intercept)          t2
> >>        0.07462564  1.13399632
> >>
> >>     Random effects:
> >>        Formula: ~0 + t1 + t2 | person
> >>        Structure: General positive-definite, Log-Cholesky
> parametrization
> >>                StdDev    Corr
> >>     t1       0.8964136 t1
> >>     t2       0.9856215 0.647
> >>     Residual 0.3258015
> >>
> >>     Number of Observations: 20
> >>     Number of Groups: 10
> >>
> >>       > m2
> >>     Linear mixed-effects model fit by REML
> >>         Data: da
> >>         Log-restricted-likelihood: -25.92726
> >>         Fixed: y ~ 1 + t2
> >>     (Intercept)          t2
> >>        0.07462564  1.13399632
> >>
> >>     Random effects:
> >>        Formula: ~1 + t2 | person
> >>        Structure: General positive-definite, Log-Cholesky
> parametrization
> >>                   StdDev    Corr
> >>     (Intercept) 0.8787887 (Intr)
> >>     t2          0.7540826 -0.302
> >>     Residual    0.3707215
> >>
> >>     Number of Observations: 20
> >>     Number of Groups: 10
> >>
> >>     Finally, it's unnecessary to supply the intercept 1 in the model
> >>     formula
> >>     since the intercept is implied if it's not explicitly excluded:
> >>
> >>       > m3 <- lme(y ~ t2, random = ~ t2 | person, data=da)
> >>       > m3
> >>     Linear mixed-effects model fit by REML
> >>         Data: da
> >>         Log-restricted-likelihood: -25.92726
> >>         Fixed: y ~ t2
> >>     (Intercept)          t2
> >>        0.07462564  1.13399632
> >>
> >>     Random effects:
> >>        Formula: ~t2 | person
> >>        Structure: General positive-definite, Log-Cholesky
> parametrization
> >>                   StdDev    Corr
> >>     (Intercept) 0.8787887 (Intr)
> >>     t2          0.7540826 -0.302
> >>     Residual    0.3707215
> >>
> >>     Number of Observations: 20
> >>     Number of Groups: 10
> >>
> >>     I hope this helps,
> >>        John
> >>
> >>     On 2022-07-16 10:05 a.m., ben pelzer wrote:
> >>      > Sorry, my previous mailed contained another question which is
> >>     irrelevant...
> >>      > I deleted that now.
> >>      >
> >>      >
> >>      > Hi all,
> >>      >
> >>      > I have a question about results from lme of package nlme.
> >>      >
> >>      > Suppose the data consists of repeated measures at two fixed time
> >>     points.
> >>      >
> >>      > I used the following equation:
> >>      >
> >>      >
> >>      >
> >>      > Model1 <- lme ( y ~ 1+t2 , random = ~ 0 + t1+t2|person, data=da)
> >>      >
> >>      >
> >>      >
> >>      > y is the dependent, t1 and t2 are binary dummy variables, valued
> >>     0 or 1,
> >>      > indicating the time point.  Model1 is estimated without any
> >>     convergence
> >>      > problems and the reproduced (co)variances found with
> >>      >
> >>      >
> >>      >
> >>      > getVarCov(Model1, type=?marginal?, indivual=?1?)
> >>      >
> >>      >
> >>      >
> >>      > are identical to the observed (co)variances.
> >>      >
> >>      >
> >>      > My question is:  how can lme estimate 4 (co)variances with only 3
> >>     known
> >>      > (co)variances?
> >>      >
> >>      >
> >>      >
> >>      > The 4 estimates concern:
> >>      >
> >>      > -          std. deviation of the random effect of dummy t1
> >>      >
> >>      > -          std. deviation of the random effect of dummy t2
> >>      >
> >>      > -          covariance of the random effects of the dummies t1 and
> >>     t2 t1
> >>      >
> >>      > -          residual std. error
> >>      >
> >>      >
> >>      >
> >>      > Related to the question above: how can the variances of the
> >>     random effects
> >>      > and the residual std. error be interpreted?
> >>      >
> >>      >
> >>      >
> >>      > Thanks for any help,
> >>      >
> >>      >
> >>      >
> >>      > Ben.
> >>      >
> >>      >       [[alternative HTML version deleted]]
> >>      >
> >>      > _______________________________________________
> >>      > R-sig-mixed-models at r-project.org
> >>     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >>      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >>     --     John Fox, Professor Emeritus
> >>     McMaster University
> >>     Hamilton, Ontario, Canada
> >>     web: https://socialsciences.mcmaster.ca/jfox/
> >>     <https://socialsciences.mcmaster.ca/jfox/>
> >>
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> --
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> web: https://socialsciences.mcmaster.ca/jfox/
>

	[[alternative HTML version deleted]]


From w@||dm@w@@@10 @end|ng |rom gm@||@com  Tue Jul 19 19:17:51 2022
From: w@||dm@w@@@10 @end|ng |rom gm@||@com (Walid Mawass)
Date: Tue, 19 Jul 2022 10:17:51 -0700
Subject: [R-sig-ME] MCMCglmm with multinomial models
In-Reply-To: <CANdGWBFmXtPEvaREGQenkqq403+toEFJvLMgPTzdFWGix-ggGA@mail.gmail.com>
References: <CANdGWBHgzmN15cvGu7zU90o-+sZn4fUS92_nanb6OYYW8f2rog@mail.gmail.com>
 <CAJtCY7XH=AACiNbTo4SLo4gMQnM7ub1vVEOwGGqB-AvuJf5+Jw@mail.gmail.com>
 <CANdGWBFmXtPEvaREGQenkqq403+toEFJvLMgPTzdFWGix-ggGA@mail.gmail.com>
Message-ID: <CAJtCY7XW=aT50ZCGUr2Y8ERPT1x2UC686Odti8n1kTRj4hC+LQ@mail.gmail.com>

Hey Jess,

1) Yes that is correct

2) To my knowledge there is a rule of thumb, where you set the nitt (# of
iterations) to a large number that includes the burnin amount, then you
choose your thinning interval (sampling of the chain). For example, this is
what I would use: nitt= 150000, burnin=50000, thin=100. This will give you
a decent burnin and a final sample of 1000 saved iterations. Note however
that this does not have to increase the effective sample size for certain
variables, but it might do the trick.

3) hmm...I think one way to do it is to make predictions using the above
model and interpret the patterns you see for each relationship you are
interested in. Another way to compare effect size would be to use bayesian
posterior indices. I suggest these two papers by Makowski et al. (2019a &
b) that present both interesting posterior indices to use with Bayesian
statistical analysis and an associated R package that does the job of
computing these indices, *bayestestR*.

Good luck
-- 
Walid Mawass
Ph.D. candidate in Evolutionary Biology - UQTR
*Currently* Postdoctoral Research Associate
Masel Lab - University of Arizona


On Sun, Jul 17, 2022 at 11:32 PM jessica comley <jessiecomley44 at gmail.com>
wrote:

> Hi Walid,
>
> Thank you for your reply, I greatly appreciate it. I have a few more
> questions and if you could help that would be great.
>
> I tested for correlation between activities and the 14 Sections and the
> correlation comes out as low. Therefore I have changed my code to use idh()
> instead of us as suggested:
>
> test1c.5b <- MCMCglmm(activity ~ -1 + at.level(culling,1):trait +
> at.level(culling, 2):trait, random=~idh(trait):Section, rcov =
> ~idh(trait):units, data = caracal, family = "categorical", prior = prior,
> burnin=5000, nitt=80000)
>
> 1) Is this correct?
>
> 2) Increasing the number of interactions increases the effective sample
> size, therefore is there a general rule of thumb as to how large your
> effective sample size should be?
>
> 3) I understand how to use and interpret the results of HPDinterval (i.e.
> if intervals do not overlap 0 then relationship is strong), but how am I
> able to test the relationship between all four activities and fixed effects
> and not just have the three categories (i.e. diurnal, dusk, nocturnal)
> compared to the base category (dawn)? For example, I am also interested in
> whether there is a significant/strong relationship between activities of
> caracal at dusk with culling(Lethal)/no culling(none) compared to
> activities of caracal at diurnal with culling(Lethal)/no culling(none).
>
> Below is an example of our dataset:
> Camera Section CameraID Animal predator culling activity
> 1a Bucklands Bucklands1a Caracal low Lethal diurnal
> 1a Bucklands Bucklands1a Caracal low Lethal dawn
> 2a Bucklands Bucklands2a Caracal low Lethal dusk
> 2a Bucklands Bucklands2a Caracal low Lethal diurnal
> 3a Bucklands Bucklands3a Caracal low Lethal dawn
> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
> Cam 2  Colchester ColchesterCam 2  Caracal high none diurnal
> Cam 2  Colchester ColchesterCam 2  Caracal high none diurnal
> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
> Cam 4  Colchester ColchesterCam 4  Caracal high none diurnal
> Cam 4  Colchester ColchesterCam 4  Caracal high none diurnal
> Cam 4  Colchester ColchesterCam 4  Caracal high none nocturnal
> 1a Connaught Connaught1a Caracal low Lethal nocturnal
> 1a Connaught Connaught1a Caracal low Lethal nocturnal
> 1d Connaught Connaught1d Caracal low Lethal diurnal
> 3B Connaught Connaught3B Caracal low Lethal diurnal
> 3B Connaught Connaught3B Caracal low Lethal diurnal
> 4a Connaught Connaught4a Caracal low Lethal nocturnal
> 4a Connaught Connaught4a Caracal low Lethal nocturnal
> 4b Connaught Connaught4b Caracal low Lethal diurnal
> 6a Connaught Connaught6a Caracal low Lethal nocturnal
> 6b Connaught Connaught6b Caracal low Lethal diurnal
> 7a Connaught Connaught7a Caracal low Lethal nocturnal
> 9a Connaught Connaught9a Caracal low Lethal nocturnal
> 9d Connaught Connaught9d Caracal low Lethal nocturnal
> 9d Connaught Connaught9d Caracal low Lethal dusk
> 7d Diepdam Diepdam7d Caracal absent Lethal dusk
> 8d Diepdam Diepdam8d Caracal absent Lethal diurnal
> 9c Diepdam Diepdam9c Caracal absent Lethal nocturnal
>
> All the best,
> Jess
>
>
> On Fri, Jul 15, 2022 at 11:37 PM Walid Mawass <walidmawass10 at gmail.com>
> wrote:
>
>> Hello,
>>
>> I don't think I can specifically help you with some of your inquiries.
>> However, I do want to comment on a few things that might need some
>> attention.
>>
>> First, MCMCglmm is based on a Bayesian implementation and does not
>> compute p-values to compare. What you need to compare are the posterior
>> distributions of your effect sizes. This can be done visually using the
>> base plot function in R. Or by comparing the HPD intervals and the mode (or
>> mean) of the posterior distributions.
>>
>> Second, I have no idea what your data structure looks like (which makes
>> it hard to interpret model results), but the effective sample size (from
>> the 5500 saved iterations sample) for your random variable Section is very
>> low (the same applies for your fixed effects). You should consider this
>> issue and look again at your assumption of correlation between
>> activities for the 14 sections you have in your dataset. If you do not
>> expect among activity correlations then you can use the idh() function
>> instead of us().
>>
>> Hopefully this helps and in hope that people on this list with more
>> knowledge of these models will help out.
>>
>> Best,
>> --
>> Walid Mawass
>> Ph.D. candidate in Evolutionary Biology - UQTR
>> *Currently* Postdoctoral Research Associate
>> Masel Lab - University of Arizona
>>
>>
>> On Fri, Jul 15, 2022 at 8:49 AM jessica comley <jessiecomley44 at gmail.com>
>> wrote:
>>
>>> Dear all,
>>>
>>> I am hoping that someone will be able to help me with conducting MCMCglmm
>>> multinomial models.
>>>
>>> The data I am working with is for black-backed jackal (bbj) and carcal.
>>> For
>>> each species we have a multinomial response variable called activity
>>> which
>>> has four categories (dawn, diurnal, dusk, nocturnal). We have two
>>> categorical fixed effects which are 1) culling (none, lethal) and 2)
>>> predator presence (absent, high, low). We also have a categorical
>>> variable
>>> called Section (made up of 14 different reserves/ farms where the
>>> activity
>>> of caracal and bbj were recorded). There are 273 observations for caracal
>>> and 4399 for bbj. We are wanting to test the effects of culling and
>>> predators on caracal and bbj activity separately.
>>>
>>> I have been working through Jarrod Hadfields course notes, particularly
>>> with regards to Chapter 5.2. The chi-square analyses reveal that the
>>> frequencies of culling and predators differ as do activities.
>>>
>>> I have managed to work out the specific probabilities for the culling
>>> none
>>> vs culling lethal for each activity (dawn, diurnal, dusk, nocturnal) for
>>> caracal, but I'm confused as to how to determine p-values to determine
>>> which activities culling none vs culling lethal are affecting?
>>>
>>> Myy code and outcomes are pasted below with questions stated in bold.
>>>
>>> caracal2 <- read.csv("caracal_new.csv", header=T)
>>> caracal <- as.data.frame(unclass(caracal2), stringsAsFactors = TRUE)
>>>
>>> #Chi-squared tests
>>> Ctable1 <- table(caracal$activity, caracal$culling)
>>> chisq.test(rowSums(Ctable1)) #strongly suggests activities differ
>>> chisq.test(Ctable1)#strongly suggests culling category differs
>>>
>>> Ctable2 <- table(caracal$activity, caracal$predator)
>>> chisq.test(rowSums(Ctable2))#strongly suggests activities differ
>>> chisq.test(Ctable2)#strongly suggests predator category differs
>>>
>>> prior = list(R = list(fix=1, V=(1/k) * (I + J)), G = list(G1=list(V =
>>> diag(k-1), nu=1)))
>>> test1c.5 <- MCMCglmm(activity ~ -1 + at.level(culling,1):trait +
>>> at.level(culling, 2):trait, random=~us(trait):Section, rcov =
>>> ~us(trait):units, data = caracal, family = "categorical", prior = prior,
>>> burnin=5000, nitt=60000)
>>> *##I'm not sure how to add the three predator levels to this model or if
>>> it
>>> would be appropriate?*
>>>
>>>
>>> k <- length(levels(caracal$activity))
>>> I <- diag(k-1)
>>> J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))
>>> IJ <- (1/k) *(diag(k-1) + matrix(1,k-1, k-1))
>>>
>>> contrasts(caracal$activity)
>>>
>>> #culling lethal
>>> Delta <- cbind(c(0,1,0,0), c(0,0,1,0), c(0,0,0,1))
>>> c2 <- (16 * sqrt(3)/(15 * pi))^2
>>> D <- ginv(Delta %*% t(Delta)) %*% Delta
>>> Int <- t(apply(test1c.5$Sol[,1:3],1, function(x) + D %*% (x/sqrt(1 + c2 *
>>> diag(IJ)))))
>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>
>>> prop.table(Ctable1[,1])
>>>
>>> #culling none
>>> Delta <- cbind(c(0,1,0,0), c(0,0,1,0), c(0,0,0,1))
>>> c2 <- (16 * sqrt(3)/(15 * pi))^2
>>> D <- ginv(Delta %*% t(Delta)) %*% Delta
>>> Int <- t(apply(test1c.5$Sol[,4:6],1, function(x) + D %*% (x/sqrt(1 + c2 *
>>> diag(IJ)))))
>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>
>>> prop.table((Ctable1[,2]))
>>>
>>> HPDinterval(test1c.5$Sol)
>>>
>>> #model summary
>>> > summary(test1c.5)
>>>
>>>  Iterations = 5001:59991
>>>  Thinning interval  = 10
>>>  Sample size  = 5500
>>>
>>>  DIC: 699.7014
>>>
>>>  G-structure:  ~us(trait):Section
>>>
>>>                                                         post.mean l-95%
>>> CI
>>> u-95% CI eff.samp
>>> traitactivity.diurnal:traitactivity.diurnal.Section        1.8124
>>> 0.09784
>>>    5.665    77.01
>>> traitactivity.dusk:traitactivity.diurnal.Section           0.8450
>>> -0.83585
>>>    3.856    64.17
>>> traitactivity.nocturnal:traitactivity.diurnal.Section      1.3621
>>> -1.19129
>>>    6.157    58.48
>>> traitactivity.diurnal:traitactivity.dusk.Section           0.8450
>>> -0.83585
>>>    3.856    64.17
>>> traitactivity.dusk:traitactivity.dusk.Section              1.2034
>>> 0.07090
>>>    3.681   102.16
>>> traitactivity.nocturnal:traitactivity.dusk.Section         0.7505
>>> -1.77113
>>>    4.524    43.53
>>> traitactivity.diurnal:traitactivity.nocturnal.Section      1.3621
>>> -1.19129
>>>    6.157    58.48
>>> traitactivity.dusk:traitactivity.nocturnal.Section         0.7505
>>> -1.77113
>>>    4.524    43.53
>>> traitactivity.nocturnal:traitactivity.nocturnal.Section    2.7148
>>> 0.09401
>>>    8.397    76.59
>>>
>>>  R-structure:  ~us(trait):units
>>>
>>>                                                       post.mean l-95% CI
>>> u-95% CI eff.samp
>>> traitactivity.diurnal:traitactivity.diurnal.units          0.50     0.50
>>>   0.50        0
>>> traitactivity.dusk:traitactivity.diurnal.units             0.25     0.25
>>>   0.25        0
>>> traitactivity.nocturnal:traitactivity.diurnal.units        0.25     0.25
>>>   0.25        0
>>> traitactivity.diurnal:traitactivity.dusk.units             0.25     0.25
>>>   0.25        0
>>> traitactivity.dusk:traitactivity.dusk.units                0.50     0.50
>>>   0.50        0
>>> traitactivity.nocturnal:traitactivity.dusk.units           0.25     0.25
>>>   0.25        0
>>> traitactivity.diurnal:traitactivity.nocturnal.units        0.25     0.25
>>>   0.25        0
>>> traitactivity.dusk:traitactivity.nocturnal.units           0.25     0.25
>>>   0.25        0
>>> traitactivity.nocturnal:traitactivity.nocturnal.units      0.50     0.50
>>>   0.50        0
>>>
>>>  Location effects: activity ~ -1 + at.level(culling, 1):trait +
>>> at.level(culling, 2):trait
>>>
>>>                                              post.mean l-95% CI u-95% CI
>>> eff.samp  pMCMC
>>> at.level(culling, 1):traitactivity.diurnal      1.2306  -0.0533   2.6793
>>> 145.29 0.0418 *
>>> at.level(culling, 1):traitactivity.dusk         0.6605  -0.6006   2.0761
>>>  92.91 0.2840
>>> at.level(culling, 1):traitactivity.nocturnal    1.6090   0.0914   3.1356
>>> 151.02 0.0265 *
>>> traitactivity.diurnal:at.level(culling, 2)      1.2664  -0.1552   2.7750
>>> 226.40 0.0604 .
>>> traitactivity.dusk:at.level(culling, 2)         0.3533  -0.9898   1.5218
>>> 148.44 0.5447
>>> traitactivity.nocturnal:at.level(culling, 2)    1.0447  -0.6405   2.8354
>>> 346.40 0.1618
>>> ---
>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>
>>> *##So for the model summary I get that lethal culling at activity diurnal
>>> is significantly different from lethal culling at dawn (its the base
>>> reference), but I'm also interested in whether lethal culling at activity
>>> diurnal is different from lethal culling at dusk for example. Is this
>>> possible? *
>>>
>>> #outcomes culling lethal
>>> > summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>
>>> Iterations = 1:5500
>>> Thinning interval = 1
>>> Number of chains = 1
>>> Sample size per chain = 5500
>>>
>>> 1. Empirical mean and standard deviation for each variable,
>>>    plus standard error of the mean:
>>>
>>>        Mean      SD  Naive SE Time-series SE
>>> [1,] 0.1253 0.05565 0.0007504       0.002484
>>> [2,] 0.3748 0.10497 0.0014155       0.003204
>>> [3,] 0.1757 0.06640 0.0008954       0.002515
>>> [4,] 0.3242 0.11939 0.0016099       0.003514
>>>
>>> 2. Quantiles for each variable:
>>>
>>>         2.5%     25%    50%    75%  97.5%
>>> var1 0.03641 0.08695 0.1198 0.1554 0.2553
>>> var2 0.17298 0.30580 0.3704 0.4431 0.5896
>>> var3 0.06166 0.12913 0.1705 0.2161 0.3215
>>> var4 0.12610 0.23999 0.3090 0.3901 0.6045
>>>
>>> > prop.table(Ctable1[,1])
>>>      dawn   diurnal      dusk nocturnal
>>> 0.1250000 0.2812500 0.1770833 0.4166667
>>>
>>>
>>> #outcomes culling none
>>> > summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>
>>> Iterations = 1:5500
>>> Thinning interval = 1
>>> Number of chains = 1
>>> Sample size per chain = 5500
>>>
>>> 1. Empirical mean and standard deviation for each variable,
>>>    plus standard error of the mean:
>>>
>>>        Mean      SD  Naive SE Time-series SE
>>> [1,] 0.1288 0.06141 0.0008280       0.002787
>>> [2,] 0.3804 0.10406 0.0014032       0.002662
>>> [3,] 0.1710 0.06844 0.0009228       0.002592
>>> [4,] 0.3198 0.11812 0.0015928       0.002956
>>>
>>> 2. Quantiles for each variable:
>>>
>>>         2.5%     25%    50%    75%  97.5%
>>> var1 0.02891 0.08896 0.1220 0.1594 0.2685
>>> var2 0.18007 0.31094 0.3783 0.4474 0.5965
>>> var3 0.05840 0.12425 0.1634 0.2083 0.3250
>>> var4 0.12430 0.23921 0.3077 0.3862 0.5964
>>>
>>> > prop.table((Ctable1[,2]))
>>>      dawn   diurnal      dusk nocturnal
>>> 0.1306818 0.4375000 0.1875000 0.2443182
>>>
>>> Any help or guidance will be greatly appreciated.
>>>
>>> All the best,
>>> Jess
>>>
>>> --
>>> Jessica Comley (PhD)
>>> Research Scientist
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>
> --
> Jessica Comley (PhD)
> Research Scientist
>
>

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Tue Jul 19 19:23:04 2022
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Tue, 19 Jul 2022 13:23:04 -0400
Subject: [R-sig-ME] results lme unstructured covariance matrix, again
In-Reply-To: <7232_1658235102_26JCpfYa001214_CAFgPNS-B7r1Q+a9-f6rvesZTAhiAM0_UdZyvHPiFBcfheozkkA@mail.gmail.com>
References: <29754_1657980613_26GEACWL024787_CAFgPNS_+x_ZDwaZUx0tzYs2U2D7s1roFqfcADU+_sTypf8i9jw@mail.gmail.com>
 <5d88d002-d568-269a-50f7-11d259ebff0d@mcmaster.ca>
 <CAFgPNS9QbpWOrFiw+TB_sTN0qt+U3GpKp=uwAtd971xnjJoQbQ@mail.gmail.com>
 <14495_1658165552_26IHWWJ9018805_dfe266dd-b96a-c28f-9cdd-121634019be9@mcmaster.ca>
 <264bc675-51d7-a1d3-b67e-13635140754a@mcmaster.ca>
 <7232_1658235102_26JCpfYa001214_CAFgPNS-B7r1Q+a9-f6rvesZTAhiAM0_UdZyvHPiFBcfheozkkA@mail.gmail.com>
Message-ID: <2fbf2ced-4fe3-7f72-145d-2ba6a8299be5@mcmaster.ca>

Dear Ben,

The discussion is starting to stray from software issues, so I'll try to 
answer briefly.

I think that you're emphasizing the wrong point, which is how to specify 
a model that produces estimates, rather than specifying a random-effects 
structure that's reasonable for the data.

As you point out, an unrestricted variance-covariance structure for the 
model you originally specified is underidentified, as is a similar model 
with 3 within-subjects measurements. As you also correctly point out, 
fitting 3 occasions with 2 dummy regressors is equivalent to fitting a 
quadratic -- both have 3 parameters (including the intercept).

Placing a restriction on the random effects, such as setting the 
observation-level error variance to 0, can identify the 
variance-covariance parameters, as can other sorts of restrictions. If 
just one constraint is placed on the variances and covariances of the 
random effects, the resulting variance-covariance parameters will be 
just-identified, and different such constraints are equivalent, in the 
sense of producing the same likelihood and fixed-effects estimates. You 
can see how this works by looking at the equations I wrote out for the 
variance-covariance components.

This is simply a mechanical point, and in general there's no reason to 
prefer one constraint to another, but in a real application one model 
may be more reasonable than another for the data at hand. For example, 
the data I generated has only one true random effect -- the observation 
level error -- and so a correct model for the data has only one 
variance-covariance component -- the error variance. lm(y ~ t2, data=da) 
fits this model, which is much more restrictive than a single constraint 
on the more general mixed model. More elaborate random-effect 
specifications for my data have superfluous parameters, whether or not 
they're identified.

Best,
  John

On 2022-07-19 8:50 a.m., ben pelzer wrote:
> Dear John, Wolfgang, James and Ben,
> 
> Thanks to you all for your explanations and examples! As I understand it
> now, cancelling the estimation of the sigma, by fixing it to a small
> positive number close to zero, produces random effects estimates of the
> intercept and t2 (or of t1 and t2) which make sense. However, the
> loglikelihood doesn't make sense. I guess that with sigma fixed to nearly
> zero, the predictions will be meaningful too, even when including the
> random effects in the predictions, though I did not verify that yet.
> 
> All in all, I think that for a model with an unstructured covariance
> matrix, "gls" is more straightforward. For the example of John:
> 
> da$time <- da$t2 + 1
> m4 <- gls(y ~ 1 + t2,
>            correlation=corSymm(form= ~time|person),
>            weights=varIdent(form= ~1|time),
>            data=da)
> 
> and the results are equal to e.g.
> 
> m2 <- lme(y ~ 1 + t2, random = ~ 1 + t2 | person, data=da)
> 
> as far as the loglikelihood and the estimated (co)variances (getVarCov) are
> concerned.
> 
> My question about "lme" arose when helping someone with such an
> unstructured covariances model, for data with three fixed occasions. With
> "many" occasions, a random linear effect of time is often employed, or
> maybe a random quadratic time effect or cubic... Anyway, time is used as a
> random (linear etc) effect in such models. But with only three occasions,
> and with the time effect not being linear but quadratic, the model turns
> into the kind of model I was questioning about, but with three occasions
> instead of two. So, instead of
> 
> modelA <- lme(y ~ 1+time+timesquared, random= ~ 1+time+timesquared |
> person, data=da)
> 
> one could then use
> 
> modelB <- lme(y ~ 1+t2+t3, random= ~ 1+t2+t3 | person, data=da)
> 
> But the random effect variances of t2 and t3 are not meaningful, as I know
> now. And with the often used "lmer" the model is not estimated (except when
> avoiding the "counting check" as Ben Bolker explained). This means that the
> "random time effect" models, which I explain to students in a course, is
> not applicable to such data. I thought/hoped that "lme" could be used, and
> in a way it can, with fixing the sigma, but apparently this also leads to
> some "unexpected" results. On the other hand, "gls" is a new method for
> students used to the "random time effect" models. So I have to choose among
> these two possibilities.
> 
> Thanks again everyone, time to switch off the computer and enjoy the sun.
> It's almost 40 degrees Celsius or 104 Farenheit in The Netherlands now, so
> maybe enjoying is not the right word. Best to you all,
> 
> Ben Pelzer.
> 
> 
> 
> 
> 
> On Tue, 19 Jul 2022 at 04:15, John Fox <jfox at mcmaster.ca> wrote:
> 
>> Dear Ben,
>>
>> On 2022-07-18 1:32 p.m., John Fox wrote:
>>> Dear Ben,
>>>
>>> My apologies---I paid attention to the inessential part of your message,
>>> which was the parametrization of the model rather than the
>>> variance-covariance structure.
>>>
>>> This is a little awkward because of the LaTeX (and as far as I know, I
>>> can't attach a PDF, but maybe you can paste this into a LaTeX editor):
>>
>> Rolf Turner pointed out to me that PDF attachments *are* acceptable, and
>> so I've attached a PDF with the LaTeX part of my message.
>>
>> Best,
>> John
>>
>>>
>>> The model is $Y_{ij} = \alpha + \beta x_{ij} + \delta_{1i} + \delta_{2i}
>>> x_{ij} + \varepsilon_{ij}$ for $i = 1, \ldots, n$ and $j = 1,2$, where
>>> $x_{i1} = 1$ and $x_{i2} = 0$.
>>>
>>> The variances of the random effects are $V(\delta_{1i}) = \psi_1^2$ and
>>> $V(\delta_{2i}) = \psi_2^2$, and their covariance is $C(\delta_{1i},
>>> \delta_{2i}) = \psi_{12}$. The observation-level error variance is
>>> $V(\varepsilon_{ij}) = \sigma^2$.
>>>
>>> Then the composite error is $\zeta_{ij} = \delta_{1i} + \delta_{2i}
>>> x_{ij} + \varepsilon_{ij}$ with variance $V(\zeta_{ij}) =    \psi_1^2 +
>>> x^2_{ij} \psi_2^2 + 2 x_{ij} \psi_{12} + \sigma^2$, which is
>>> $V(\zeta_{i1}) = \psi_1^2 + \psi_2^2 + 2\psi_{12} + \sigma^2$ for $j =
>>> 1$ and  $V(\zeta_{i2}) =   \psi_1^2  + \sigma^2$ for $j = 2$, and
>>> covariance $C(\zeta_{i1}, \zeta_{i2}) = \psi_1^2 + \psi_2^2$.
>>>
>>> There are, as you say, 4 variance-covariance components, $\psi_1^2,
>>> \psi_2^2, \psi_{12}, \sigma^2$, and just 3 variances and covariances
>>> among the composite disturbances, $V(\zeta_{i1}), V(\zeta_{i2}),
>>> C(\zeta_{i1}, \zeta_{i2})$, and so---as you and several others have
>>> noted (but I missed)---the variance-covariance components are
>>> underidentified.
>>>
>>> lmer(), but not lme(), appears to use a heuristic, counting the number
>>> of random effects and observations, to detect underidentification. I
>>> don't know whether that's bullet-proof, but it works in this case. Maybe
>>> Ben Bolker, who has already responded, can comment further.
>>>
>>> Best,
>>>    John
>>>
>>> John Fox, Professor Emeritus
>>> McMaster University
>>> Hamilton, Ontario, Canada
>>> web: https://socialsciences.mcmaster.ca/jfox/
>>>
>>> On 2022-07-18 6:39 a.m., ben pelzer wrote:
>>>> Dear John,
>>>>
>>>> Thank you for answering my question and your nice example with the
>>>> alternative model formulations!!. But still I'm in doubt about the
>>>> results. The fact that there are only three observed (co)variances
>>>> which are being reproduced by four parameters estimates of lme leaves
>>>> me confused. Actually, I would think that there is no unique solution
>>>> without some constraint being applied. But I could not find something
>>>> about such a constraint in lme documentation. The random effects of t1
>>>> and t2, or of the intercept and t2 in your alternative model, should
>>>> be sufficient to reproduce the observed (co)variances, so the residual
>>>> variance is "unnecassary". I guess that is the reason that lmer is not
>>>> able to estimate the model.
>>>>
>>>> library(lme4)
>>>> m3 <- lmer(y ~ 1+t2+(1+t2|person), data=da)
>>>>
>>>> Error: number of observations (=20) <= number of random effects (=20)
>>>> for term (1 + t2 | person); the random-effects parameters and the
>>>> residual variance (or scale parameter) are probably unidentifiable
>>>>
>>>>
>>>> It's interesting to notice that the two model specifications (t1+t2
>>>> and 1+t2) lead to different residual variances estimated by lme. What
>>>> do these residual variances mean? And of course also: what do the
>>>> random effect variances estimated by both model formulations actually
>>>> mean or stand for? Do you have any ideas? Kind regards,
>>>>
>>>> Ben.
>>>>
>>>> On Sat, 16 Jul 2022 at 16:50, John Fox <jfox at mcmaster.ca
>>>> <mailto:jfox at mcmaster.ca>> wrote:
>>>>
>>>>      Dear Ben,
>>>>
>>>>      First, I'll make this into a reproducible example:
>>>>
>>>>        > set.seed(123)
>>>>        > t1 <- c(rep(1, 10), rep(0, 10))
>>>>        > t2 <- 1 - t1
>>>>        > person <- rep(1:10, 2)
>>>>        > y <- t2 + rnorm(20)
>>>>        > da <- data.frame(y, t1, t2, person)
>>>>
>>>>        > library(nlme)
>>>>
>>>>      Then note that the random-effect specification 0 + t1 + t2 is
>>>> simply a
>>>>      reparametrization of 1 + t2 (i.e., 1 = t1 + t2), which produces the
>>>>      same
>>>>      fit to the data (same fixed effects, same restricted
>> log-likelihood):
>>>>
>>>>        > m1 <- lme(y ~ 1 + t2, random = ~ 0 + t1 + t2 | person, data=da)
>>>>        > m2 <- lme(y ~ 1 + t2, random = ~ 1 + t2 | person, data=da)
>>>>        > m1
>>>>      Linear mixed-effects model fit by REML
>>>>          Data: da
>>>>          Log-restricted-likelihood: -25.92726
>>>>          Fixed: y ~ 1 + t2
>>>>      (Intercept)          t2
>>>>         0.07462564  1.13399632
>>>>
>>>>      Random effects:
>>>>         Formula: ~0 + t1 + t2 | person
>>>>         Structure: General positive-definite, Log-Cholesky
>> parametrization
>>>>                 StdDev    Corr
>>>>      t1       0.8964136 t1
>>>>      t2       0.9856215 0.647
>>>>      Residual 0.3258015
>>>>
>>>>      Number of Observations: 20
>>>>      Number of Groups: 10
>>>>
>>>>        > m2
>>>>      Linear mixed-effects model fit by REML
>>>>          Data: da
>>>>          Log-restricted-likelihood: -25.92726
>>>>          Fixed: y ~ 1 + t2
>>>>      (Intercept)          t2
>>>>         0.07462564  1.13399632
>>>>
>>>>      Random effects:
>>>>         Formula: ~1 + t2 | person
>>>>         Structure: General positive-definite, Log-Cholesky
>> parametrization
>>>>                    StdDev    Corr
>>>>      (Intercept) 0.8787887 (Intr)
>>>>      t2          0.7540826 -0.302
>>>>      Residual    0.3707215
>>>>
>>>>      Number of Observations: 20
>>>>      Number of Groups: 10
>>>>
>>>>      Finally, it's unnecessary to supply the intercept 1 in the model
>>>>      formula
>>>>      since the intercept is implied if it's not explicitly excluded:
>>>>
>>>>        > m3 <- lme(y ~ t2, random = ~ t2 | person, data=da)
>>>>        > m3
>>>>      Linear mixed-effects model fit by REML
>>>>          Data: da
>>>>          Log-restricted-likelihood: -25.92726
>>>>          Fixed: y ~ t2
>>>>      (Intercept)          t2
>>>>         0.07462564  1.13399632
>>>>
>>>>      Random effects:
>>>>         Formula: ~t2 | person
>>>>         Structure: General positive-definite, Log-Cholesky
>> parametrization
>>>>                    StdDev    Corr
>>>>      (Intercept) 0.8787887 (Intr)
>>>>      t2          0.7540826 -0.302
>>>>      Residual    0.3707215
>>>>
>>>>      Number of Observations: 20
>>>>      Number of Groups: 10
>>>>
>>>>      I hope this helps,
>>>>         John
>>>>
>>>>      On 2022-07-16 10:05 a.m., ben pelzer wrote:
>>>>       > Sorry, my previous mailed contained another question which is
>>>>      irrelevant...
>>>>       > I deleted that now.
>>>>       >
>>>>       >
>>>>       > Hi all,
>>>>       >
>>>>       > I have a question about results from lme of package nlme.
>>>>       >
>>>>       > Suppose the data consists of repeated measures at two fixed time
>>>>      points.
>>>>       >
>>>>       > I used the following equation:
>>>>       >
>>>>       >
>>>>       >
>>>>       > Model1 <- lme ( y ~ 1+t2 , random = ~ 0 + t1+t2|person, data=da)
>>>>       >
>>>>       >
>>>>       >
>>>>       > y is the dependent, t1 and t2 are binary dummy variables, valued
>>>>      0 or 1,
>>>>       > indicating the time point.  Model1 is estimated without any
>>>>      convergence
>>>>       > problems and the reproduced (co)variances found with
>>>>       >
>>>>       >
>>>>       >
>>>>       > getVarCov(Model1, type=?marginal?, indivual=?1?)
>>>>       >
>>>>       >
>>>>       >
>>>>       > are identical to the observed (co)variances.
>>>>       >
>>>>       >
>>>>       > My question is:  how can lme estimate 4 (co)variances with only 3
>>>>      known
>>>>       > (co)variances?
>>>>       >
>>>>       >
>>>>       >
>>>>       > The 4 estimates concern:
>>>>       >
>>>>       > -          std. deviation of the random effect of dummy t1
>>>>       >
>>>>       > -          std. deviation of the random effect of dummy t2
>>>>       >
>>>>       > -          covariance of the random effects of the dummies t1 and
>>>>      t2 t1
>>>>       >
>>>>       > -          residual std. error
>>>>       >
>>>>       >
>>>>       >
>>>>       > Related to the question above: how can the variances of the
>>>>      random effects
>>>>       > and the residual std. error be interpreted?
>>>>       >
>>>>       >
>>>>       >
>>>>       > Thanks for any help,
>>>>       >
>>>>       >
>>>>       >
>>>>       > Ben.
>>>>       >
>>>>       >       [[alternative HTML version deleted]]
>>>>       >
>>>>       > _______________________________________________
>>>>       > R-sig-mixed-models at r-project.org
>>>>      <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>>       > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>      --     John Fox, Professor Emeritus
>>>>      McMaster University
>>>>      Hamilton, Ontario, Canada
>>>>      web: https://socialsciences.mcmaster.ca/jfox/
>>>>      <https://socialsciences.mcmaster.ca/jfox/>
>>>>
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> --
>> John Fox, Professor Emeritus
>> McMaster University
>> Hamilton, Ontario, Canada
>> web: https://socialsciences.mcmaster.ca/jfox/
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
-- 
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/


From jh@|t|g@ @end|ng |rom gm@||@com  Wed Jul 20 06:19:19 2022
From: jh@|t|g@ @end|ng |rom gm@||@com (J.D. Haltigan)
Date: Wed, 20 Jul 2022 00:19:19 -0400
Subject: [R-sig-ME] Choice of distribution for random effects
Message-ID: <CAH_7VOmFG=iwiwPdBR6Loj9FXeic41UQ-aBUg0a3b6qE_eh-gQ@mail.gmail.com>

Hi:

Is there clear best practice or guidance when it comes to choosing the
distribution of random effects where multiple choices exist (e.g.,
gaussian, gamma, etc.)? I ask in the context of extending some analyses
from an RCT in which the outcome is symptomatic seropositivity (so a
count). The random effects I am modeling are village cluster [union] (it's
a cluster randomized trial). I get different results (significance-wise)
depending on whether I choose a normal or gamma distribution for the random
effects.

The basic model (proportional outcome) is:

lme4_5_B = glmer(posXsymp~ treatment+proper_mask_base+prop_resp_ill_base_2
+ pairID + (1 | union), family = "poisson", nAGQ=0, data = bdata.raw3)#lme4
package using glmer


HGLM2_5_A = hglm2(posXsymp~ treatment+proper_mask_base+prop_resp_ill_base_2
+ pairID + (1 | union), family =poisson (link = log), rand.family
=Gamma(link=log),
                  data = bdata.raw3)#HGLM package using hglm2

Does, for example, the choice of distribution for the fixed effects portion
of the model inform the choice for the random effects?

Thank you for any insights.

Best regards,
J.D.

	[[alternative HTML version deleted]]


From j@h@d||e|d @end|ng |rom ed@@c@uk  Wed Jul 20 09:05:44 2022
From: j@h@d||e|d @end|ng |rom ed@@c@uk (Jarrod Hadfield)
Date: Wed, 20 Jul 2022 07:05:44 +0000
Subject: [R-sig-ME] MCMCglmm with multinomial models
In-Reply-To: <CAJtCY7XW=aT50ZCGUr2Y8ERPT1x2UC686Odti8n1kTRj4hC+LQ@mail.gmail.com>
References: <CANdGWBHgzmN15cvGu7zU90o-+sZn4fUS92_nanb6OYYW8f2rog@mail.gmail.com>
 <CAJtCY7XH=AACiNbTo4SLo4gMQnM7ub1vVEOwGGqB-AvuJf5+Jw@mail.gmail.com>
 <CANdGWBFmXtPEvaREGQenkqq403+toEFJvLMgPTzdFWGix-ggGA@mail.gmail.com>
 <CAJtCY7XW=aT50ZCGUr2Y8ERPT1x2UC686Odti8n1kTRj4hC+LQ@mail.gmail.com>
Message-ID: <57338F74-D980-4078-A389-EDA67E79C1A6@ed.ac.uk>

Hi Jess

In multinomial models the linear model is set up as a (logit) difference in probability between an outcome and some base-line outcome. Often, as here, the base-line outcome is arbitrary, and so the idh structure is a little odd. For example, if A is the base line category, idh assumes COV(B-A, C-A) = 0 which therefore assumes
COV(B,C)+VAR(A) =COV(A,B)+COV(C,A). It's not clear why this would be the case. Perhaps a more reasonable, but less parameter rich, option would be to have:

~idv(Section+trait:Section)

which parameterises the Section covariance matrix by a single parameter (rather than 6). The term idv(Section+trait:Section) fits a 3x3 covariance matrix of the form v*(I+J) where v is the estimated variance. This assumes i) Sections are repeatable in outcome, but knowing that a Section has an increased 'preference' for A doesn?t tell you whether it also has an increased preference for one of the other categories and ii) the repeatability for each outcome within sites is the same (on the latent scale).

To test groups of effects (in your case the 3 culling:trait effects), I usually use a Wald test and the posterior covariances (see here https://stat.ethz.ch/pipermail/r-sig-mixed-models/2017q3/025930.html). It's far from correct and so Walid's suggestions may be better, but small-scale simulations suggests it has good frequentist properties.

To add predator presence you can just add a predator:trait effect into the linear model. If the culling and predator factors do not vary within sites then you probably don't have enough information to reliably estimate these effects.

Cheers,

Jarrod






> On 19 Jul 2022, at 18:17, Walid Mawass <walidmawass10 at gmail.com> wrote:
>
> This email was sent to you by someone outside the University.
> You should only click on links or attachments if you are certain that the email is genuine and the content is safe.
>
> Hey Jess,
>
> 1) Yes that is correct
>
> 2) To my knowledge there is a rule of thumb, where you set the nitt (# of
> iterations) to a large number that includes the burnin amount, then you
> choose your thinning interval (sampling of the chain). For example, this is
> what I would use: nitt= 150000, burnin=50000, thin=100. This will give you
> a decent burnin and a final sample of 1000 saved iterations. Note however
> that this does not have to increase the effective sample size for certain
> variables, but it might do the trick.
>
> 3) hmm...I think one way to do it is to make predictions using the above
> model and interpret the patterns you see for each relationship you are
> interested in. Another way to compare effect size would be to use bayesian
> posterior indices. I suggest these two papers by Makowski et al. (2019a &
> b) that present both interesting posterior indices to use with Bayesian
> statistical analysis and an associated R package that does the job of
> computing these indices, *bayestestR*.
>
> Good luck
> --
> Walid Mawass
> Ph.D. candidate in Evolutionary Biology - UQTR
> *Currently* Postdoctoral Research Associate
> Masel Lab - University of Arizona
>
>
> On Sun, Jul 17, 2022 at 11:32 PM jessica comley <jessiecomley44 at gmail.com>
> wrote:
>
>> Hi Walid,
>>
>> Thank you for your reply, I greatly appreciate it. I have a few more
>> questions and if you could help that would be great.
>>
>> I tested for correlation between activities and the 14 Sections and the
>> correlation comes out as low. Therefore I have changed my code to use idh()
>> instead of us as suggested:
>>
>> test1c.5b <- MCMCglmm(activity ~ -1 + at.level(culling,1):trait +
>> at.level(culling, 2):trait, random=~idh(trait):Section, rcov =
>> ~idh(trait):units, data = caracal, family = "categorical", prior = prior,
>> burnin=5000, nitt=80000)
>>
>> 1) Is this correct?
>>
>> 2) Increasing the number of interactions increases the effective sample
>> size, therefore is there a general rule of thumb as to how large your
>> effective sample size should be?
>>
>> 3) I understand how to use and interpret the results of HPDinterval (i.e.
>> if intervals do not overlap 0 then relationship is strong), but how am I
>> able to test the relationship between all four activities and fixed effects
>> and not just have the three categories (i.e. diurnal, dusk, nocturnal)
>> compared to the base category (dawn)? For example, I am also interested in
>> whether there is a significant/strong relationship between activities of
>> caracal at dusk with culling(Lethal)/no culling(none) compared to
>> activities of caracal at diurnal with culling(Lethal)/no culling(none).
>>
>> Below is an example of our dataset:
>> Camera Section CameraID Animal predator culling activity
>> 1a Bucklands Bucklands1a Caracal low Lethal diurnal
>> 1a Bucklands Bucklands1a Caracal low Lethal dawn
>> 2a Bucklands Bucklands2a Caracal low Lethal dusk
>> 2a Bucklands Bucklands2a Caracal low Lethal diurnal
>> 3a Bucklands Bucklands3a Caracal low Lethal dawn
>> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>> Cam 2  Colchester ColchesterCam 2  Caracal high none diurnal
>> Cam 2  Colchester ColchesterCam 2  Caracal high none diurnal
>> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
>> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
>> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
>> Cam 4  Colchester ColchesterCam 4  Caracal high none diurnal
>> Cam 4  Colchester ColchesterCam 4  Caracal high none diurnal
>> Cam 4  Colchester ColchesterCam 4  Caracal high none nocturnal
>> 1a Connaught Connaught1a Caracal low Lethal nocturnal
>> 1a Connaught Connaught1a Caracal low Lethal nocturnal
>> 1d Connaught Connaught1d Caracal low Lethal diurnal
>> 3B Connaught Connaught3B Caracal low Lethal diurnal
>> 3B Connaught Connaught3B Caracal low Lethal diurnal
>> 4a Connaught Connaught4a Caracal low Lethal nocturnal
>> 4a Connaught Connaught4a Caracal low Lethal nocturnal
>> 4b Connaught Connaught4b Caracal low Lethal diurnal
>> 6a Connaught Connaught6a Caracal low Lethal nocturnal
>> 6b Connaught Connaught6b Caracal low Lethal diurnal
>> 7a Connaught Connaught7a Caracal low Lethal nocturnal
>> 9a Connaught Connaught9a Caracal low Lethal nocturnal
>> 9d Connaught Connaught9d Caracal low Lethal nocturnal
>> 9d Connaught Connaught9d Caracal low Lethal dusk
>> 7d Diepdam Diepdam7d Caracal absent Lethal dusk
>> 8d Diepdam Diepdam8d Caracal absent Lethal diurnal
>> 9c Diepdam Diepdam9c Caracal absent Lethal nocturnal
>>
>> All the best,
>> Jess
>>
>>
>> On Fri, Jul 15, 2022 at 11:37 PM Walid Mawass <walidmawass10 at gmail.com>
>> wrote:
>>
>>> Hello,
>>>
>>> I don't think I can specifically help you with some of your inquiries.
>>> However, I do want to comment on a few things that might need some
>>> attention.
>>>
>>> First, MCMCglmm is based on a Bayesian implementation and does not
>>> compute p-values to compare. What you need to compare are the posterior
>>> distributions of your effect sizes. This can be done visually using the
>>> base plot function in R. Or by comparing the HPD intervals and the mode (or
>>> mean) of the posterior distributions.
>>>
>>> Second, I have no idea what your data structure looks like (which makes
>>> it hard to interpret model results), but the effective sample size (from
>>> the 5500 saved iterations sample) for your random variable Section is very
>>> low (the same applies for your fixed effects). You should consider this
>>> issue and look again at your assumption of correlation between
>>> activities for the 14 sections you have in your dataset. If you do not
>>> expect among activity correlations then you can use the idh() function
>>> instead of us().
>>>
>>> Hopefully this helps and in hope that people on this list with more
>>> knowledge of these models will help out.
>>>
>>> Best,
>>> --
>>> Walid Mawass
>>> Ph.D. candidate in Evolutionary Biology - UQTR
>>> *Currently* Postdoctoral Research Associate
>>> Masel Lab - University of Arizona
>>>
>>>
>>> On Fri, Jul 15, 2022 at 8:49 AM jessica comley <jessiecomley44 at gmail.com>
>>> wrote:
>>>
>>>> Dear all,
>>>>
>>>> I am hoping that someone will be able to help me with conducting MCMCglmm
>>>> multinomial models.
>>>>
>>>> The data I am working with is for black-backed jackal (bbj) and carcal.
>>>> For
>>>> each species we have a multinomial response variable called activity
>>>> which
>>>> has four categories (dawn, diurnal, dusk, nocturnal). We have two
>>>> categorical fixed effects which are 1) culling (none, lethal) and 2)
>>>> predator presence (absent, high, low). We also have a categorical
>>>> variable
>>>> called Section (made up of 14 different reserves/ farms where the
>>>> activity
>>>> of caracal and bbj were recorded). There are 273 observations for caracal
>>>> and 4399 for bbj. We are wanting to test the effects of culling and
>>>> predators on caracal and bbj activity separately.
>>>>
>>>> I have been working through Jarrod Hadfields course notes, particularly
>>>> with regards to Chapter 5.2. The chi-square analyses reveal that the
>>>> frequencies of culling and predators differ as do activities.
>>>>
>>>> I have managed to work out the specific probabilities for the culling
>>>> none
>>>> vs culling lethal for each activity (dawn, diurnal, dusk, nocturnal) for
>>>> caracal, but I'm confused as to how to determine p-values to determine
>>>> which activities culling none vs culling lethal are affecting?
>>>>
>>>> Myy code and outcomes are pasted below with questions stated in bold.
>>>>
>>>> caracal2 <- read.csv("caracal_new.csv", header=T)
>>>> caracal <- as.data.frame(unclass(caracal2), stringsAsFactors = TRUE)
>>>>
>>>> #Chi-squared tests
>>>> Ctable1 <- table(caracal$activity, caracal$culling)
>>>> chisq.test(rowSums(Ctable1)) #strongly suggests activities differ
>>>> chisq.test(Ctable1)#strongly suggests culling category differs
>>>>
>>>> Ctable2 <- table(caracal$activity, caracal$predator)
>>>> chisq.test(rowSums(Ctable2))#strongly suggests activities differ
>>>> chisq.test(Ctable2)#strongly suggests predator category differs
>>>>
>>>> prior = list(R = list(fix=1, V=(1/k) * (I + J)), G = list(G1=list(V =
>>>> diag(k-1), nu=1)))
>>>> test1c.5 <- MCMCglmm(activity ~ -1 + at.level(culling,1):trait +
>>>> at.level(culling, 2):trait, random=~us(trait):Section, rcov =
>>>> ~us(trait):units, data = caracal, family = "categorical", prior = prior,
>>>> burnin=5000, nitt=60000)
>>>> *##I'm not sure how to add the three predator levels to this model or if
>>>> it
>>>> would be appropriate?*
>>>>
>>>>
>>>> k <- length(levels(caracal$activity))
>>>> I <- diag(k-1)
>>>> J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))
>>>> IJ <- (1/k) *(diag(k-1) + matrix(1,k-1, k-1))
>>>>
>>>> contrasts(caracal$activity)
>>>>
>>>> #culling lethal
>>>> Delta <- cbind(c(0,1,0,0), c(0,0,1,0), c(0,0,0,1))
>>>> c2 <- (16 * sqrt(3)/(15 * pi))^2
>>>> D <- ginv(Delta %*% t(Delta)) %*% Delta
>>>> Int <- t(apply(test1c.5$Sol[,1:3],1, function(x) + D %*% (x/sqrt(1 + c2 *
>>>> diag(IJ)))))
>>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>>
>>>> prop.table(Ctable1[,1])
>>>>
>>>> #culling none
>>>> Delta <- cbind(c(0,1,0,0), c(0,0,1,0), c(0,0,0,1))
>>>> c2 <- (16 * sqrt(3)/(15 * pi))^2
>>>> D <- ginv(Delta %*% t(Delta)) %*% Delta
>>>> Int <- t(apply(test1c.5$Sol[,4:6],1, function(x) + D %*% (x/sqrt(1 + c2 *
>>>> diag(IJ)))))
>>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>>
>>>> prop.table((Ctable1[,2]))
>>>>
>>>> HPDinterval(test1c.5$Sol)
>>>>
>>>> #model summary
>>>>> summary(test1c.5)
>>>>
>>>> Iterations = 5001:59991
>>>> Thinning interval  = 10
>>>> Sample size  = 5500
>>>>
>>>> DIC: 699.7014
>>>>
>>>> G-structure:  ~us(trait):Section
>>>>
>>>>                                                        post.mean l-95%
>>>> CI
>>>> u-95% CI eff.samp
>>>> traitactivity.diurnal:traitactivity.diurnal.Section        1.8124
>>>> 0.09784
>>>>   5.665    77.01
>>>> traitactivity.dusk:traitactivity.diurnal.Section           0.8450
>>>> -0.83585
>>>>   3.856    64.17
>>>> traitactivity.nocturnal:traitactivity.diurnal.Section      1.3621
>>>> -1.19129
>>>>   6.157    58.48
>>>> traitactivity.diurnal:traitactivity.dusk.Section           0.8450
>>>> -0.83585
>>>>   3.856    64.17
>>>> traitactivity.dusk:traitactivity.dusk.Section              1.2034
>>>> 0.07090
>>>>   3.681   102.16
>>>> traitactivity.nocturnal:traitactivity.dusk.Section         0.7505
>>>> -1.77113
>>>>   4.524    43.53
>>>> traitactivity.diurnal:traitactivity.nocturnal.Section      1.3621
>>>> -1.19129
>>>>   6.157    58.48
>>>> traitactivity.dusk:traitactivity.nocturnal.Section         0.7505
>>>> -1.77113
>>>>   4.524    43.53
>>>> traitactivity.nocturnal:traitactivity.nocturnal.Section    2.7148
>>>> 0.09401
>>>>   8.397    76.59
>>>>
>>>> R-structure:  ~us(trait):units
>>>>
>>>>                                                      post.mean l-95% CI
>>>> u-95% CI eff.samp
>>>> traitactivity.diurnal:traitactivity.diurnal.units          0.50     0.50
>>>>  0.50        0
>>>> traitactivity.dusk:traitactivity.diurnal.units             0.25     0.25
>>>>  0.25        0
>>>> traitactivity.nocturnal:traitactivity.diurnal.units        0.25     0.25
>>>>  0.25        0
>>>> traitactivity.diurnal:traitactivity.dusk.units             0.25     0.25
>>>>  0.25        0
>>>> traitactivity.dusk:traitactivity.dusk.units                0.50     0.50
>>>>  0.50        0
>>>> traitactivity.nocturnal:traitactivity.dusk.units           0.25     0.25
>>>>  0.25        0
>>>> traitactivity.diurnal:traitactivity.nocturnal.units        0.25     0.25
>>>>  0.25        0
>>>> traitactivity.dusk:traitactivity.nocturnal.units           0.25     0.25
>>>>  0.25        0
>>>> traitactivity.nocturnal:traitactivity.nocturnal.units      0.50     0.50
>>>>  0.50        0
>>>>
>>>> Location effects: activity ~ -1 + at.level(culling, 1):trait +
>>>> at.level(culling, 2):trait
>>>>
>>>>                                             post.mean l-95% CI u-95% CI
>>>> eff.samp  pMCMC
>>>> at.level(culling, 1):traitactivity.diurnal      1.2306  -0.0533   2.6793
>>>> 145.29 0.0418 *
>>>> at.level(culling, 1):traitactivity.dusk         0.6605  -0.6006   2.0761
>>>> 92.91 0.2840
>>>> at.level(culling, 1):traitactivity.nocturnal    1.6090   0.0914   3.1356
>>>> 151.02 0.0265 *
>>>> traitactivity.diurnal:at.level(culling, 2)      1.2664  -0.1552   2.7750
>>>> 226.40 0.0604 .
>>>> traitactivity.dusk:at.level(culling, 2)         0.3533  -0.9898   1.5218
>>>> 148.44 0.5447
>>>> traitactivity.nocturnal:at.level(culling, 2)    1.0447  -0.6405   2.8354
>>>> 346.40 0.1618
>>>> ---
>>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>>
>>>> *##So for the model summary I get that lethal culling at activity diurnal
>>>> is significantly different from lethal culling at dawn (its the base
>>>> reference), but I'm also interested in whether lethal culling at activity
>>>> diurnal is different from lethal culling at dusk for example. Is this
>>>> possible? *
>>>>
>>>> #outcomes culling lethal
>>>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>>
>>>> Iterations = 1:5500
>>>> Thinning interval = 1
>>>> Number of chains = 1
>>>> Sample size per chain = 5500
>>>>
>>>> 1. Empirical mean and standard deviation for each variable,
>>>>   plus standard error of the mean:
>>>>
>>>>       Mean      SD  Naive SE Time-series SE
>>>> [1,] 0.1253 0.05565 0.0007504       0.002484
>>>> [2,] 0.3748 0.10497 0.0014155       0.003204
>>>> [3,] 0.1757 0.06640 0.0008954       0.002515
>>>> [4,] 0.3242 0.11939 0.0016099       0.003514
>>>>
>>>> 2. Quantiles for each variable:
>>>>
>>>>        2.5%     25%    50%    75%  97.5%
>>>> var1 0.03641 0.08695 0.1198 0.1554 0.2553
>>>> var2 0.17298 0.30580 0.3704 0.4431 0.5896
>>>> var3 0.06166 0.12913 0.1705 0.2161 0.3215
>>>> var4 0.12610 0.23999 0.3090 0.3901 0.6045
>>>>
>>>>> prop.table(Ctable1[,1])
>>>>     dawn   diurnal      dusk nocturnal
>>>> 0.1250000 0.2812500 0.1770833 0.4166667
>>>>
>>>>
>>>> #outcomes culling none
>>>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>>
>>>> Iterations = 1:5500
>>>> Thinning interval = 1
>>>> Number of chains = 1
>>>> Sample size per chain = 5500
>>>>
>>>> 1. Empirical mean and standard deviation for each variable,
>>>>   plus standard error of the mean:
>>>>
>>>>       Mean      SD  Naive SE Time-series SE
>>>> [1,] 0.1288 0.06141 0.0008280       0.002787
>>>> [2,] 0.3804 0.10406 0.0014032       0.002662
>>>> [3,] 0.1710 0.06844 0.0009228       0.002592
>>>> [4,] 0.3198 0.11812 0.0015928       0.002956
>>>>
>>>> 2. Quantiles for each variable:
>>>>
>>>>        2.5%     25%    50%    75%  97.5%
>>>> var1 0.02891 0.08896 0.1220 0.1594 0.2685
>>>> var2 0.18007 0.31094 0.3783 0.4474 0.5965
>>>> var3 0.05840 0.12425 0.1634 0.2083 0.3250
>>>> var4 0.12430 0.23921 0.3077 0.3862 0.5964
>>>>
>>>>> prop.table((Ctable1[,2]))
>>>>     dawn   diurnal      dusk nocturnal
>>>> 0.1306818 0.4375000 0.1875000 0.2443182
>>>>
>>>> Any help or guidance will be greatly appreciated.
>>>>
>>>> All the best,
>>>> Jess
>>>>
>>>> --
>>>> Jessica Comley (PhD)
>>>> Research Scientist
>>>>
>>>>        [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>
>> --
>> Jessica Comley (PhD)
>> Research Scientist
>>
>>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

The University of Edinburgh is a charitable body, registered in Scotland, with registration number SC005336. Is e buidheann carthannais a th? ann an Oilthigh Dh?n ?ideann, cl?raichte an Alba, ?ireamh cl?raidh SC005336.

From @pro @end|ng |rom un|me|b@edu@@u  Wed Jul 20 09:40:17 2022
From: @pro @end|ng |rom un|me|b@edu@@u (Andrew Robinson)
Date: Wed, 20 Jul 2022 07:40:17 +0000
Subject: [R-sig-ME] Choice of distribution for random effects
In-Reply-To: <CAH_7VOmFG=iwiwPdBR6Loj9FXeic41UQ-aBUg0a3b6qE_eh-gQ@mail.gmail.com>
References: <CAH_7VOmFG=iwiwPdBR6Loj9FXeic41UQ-aBUg0a3b6qE_eh-gQ@mail.gmail.com>
Message-ID: <fc0fdf63-fa89-44da-8739-9ec115b42e4a@Spark>

You can use a qq-plot of the BLUPS to guide that decision.

The difference might also be due to something else, though.  Have you tried the call to hglm2 with a gaussian random effects family?  Does it give the same output as the glmer?

For: does the choice of distribution for the fixed effects portion of the model inform the choice for the random effects?  I?m not sure what you mean - do you mean the exponential family for the response variable?


Cheers,

Andrew

--
Andrew Robinson
Chief Executive Officer, CEBRA and Professor of Biosecurity,
School/s of BioSciences and Mathematics & Statistics
University of Melbourne, VIC 3010 Australia
Tel: (+61) 0403 138 955
Email: apro at unimelb.edu.au
Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/

I acknowledge the Traditional Owners of the land I inhabit, and pay my respects to their Elders.
On 20 Jul 2022, 2:27 PM +1000, J.D. Haltigan <jhaltiga at gmail.com>, wrote:
Hi:

Is there clear best practice or guidance when it comes to choosing the
distribution of random effects where multiple choices exist (e.g.,
gaussian, gamma, etc.)? I ask in the context of extending some analyses
from an RCT in which the outcome is symptomatic seropositivity (so a
count). The random effects I am modeling are village cluster [union] (it's
a cluster randomized trial). I get different results (significance-wise)
depending on whether I choose a normal or gamma distribution for the random
effects.

The basic model (proportional outcome) is:

lme4_5_B = glmer(posXsymp~ treatment+proper_mask_base+prop_resp_ill_base_2
+ pairID + (1 | union), family = "poisson", nAGQ=0, data = bdata.raw3)#lme4
package using glmer


HGLM2_5_A = hglm2(posXsymp~ treatment+proper_mask_base+prop_resp_ill_base_2
+ pairID + (1 | union), family =poisson (link = log), rand.family
=Gamma(link=log),
data = bdata.raw3)#HGLM package using hglm2

Does, for example, the choice of distribution for the fixed effects portion
of the model inform the choice for the random effects?

Thank you for any insights.

Best regards,
J.D.

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From jh@|t|g@ @end|ng |rom gm@||@com  Wed Jul 20 10:39:52 2022
From: jh@|t|g@ @end|ng |rom gm@||@com (J.D. Haltigan)
Date: Wed, 20 Jul 2022 04:39:52 -0400
Subject: [R-sig-ME] Choice of distribution for random effects
In-Reply-To: <fc0fdf63-fa89-44da-8739-9ec115b42e4a@Spark>
References: <CAH_7VOmFG=iwiwPdBR6Loj9FXeic41UQ-aBUg0a3b6qE_eh-gQ@mail.gmail.com>
 <fc0fdf63-fa89-44da-8739-9ec115b42e4a@Spark>
Message-ID: <CAH_7VOkBvC56rWewTLvQggDWu2EdKGn+ZzKyuE+O2z4mgNZ-zw@mail.gmail.com>

Thanks, I will inspect the BLUPS.

Re: choice of distribution, what I meant was, for example, if my fixed
effects family is estimated using a Poisson model, does that inform the
choice for random effects as well? (i.e., why would one invoke a gaussian
distribution for random effects if the response variable is, say,
categorical, or a count?)

On Wed, Jul 20, 2022 at 3:40 AM Andrew Robinson <apro at unimelb.edu.au> wrote:

> You can use a qq-plot of the BLUPS to guide that decision.
>
> The difference might also be due to something else, though.  Have you
> tried the call to hglm2 with a gaussian random effects family?  Does it
> give the same output as the glmer?
>
> For: does the choice of distribution for the fixed effects portion of the
> model inform the choice for the random effects?  I?m not sure what you mean
> - do you mean the exponential family for the response variable?
>
>
> Cheers,
>
> Andrew
>
> --
> Andrew Robinson
> Chief Executive Officer, CEBRA and Professor of Biosecurity,
> School/s of BioSciences and Mathematics & Statistics
> University of Melbourne, VIC 3010 Australia
> Tel: (+61) 0403 138 955
> Email: apro at unimelb.edu.au
> Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/
>
> I acknowledge the Traditional Owners of the land I inhabit, and pay my
> respects to their Elders.
> On 20 Jul 2022, 2:27 PM +1000, J.D. Haltigan <jhaltiga at gmail.com>, wrote:
>
> Hi:
>
> Is there clear best practice or guidance when it comes to choosing the
> distribution of random effects where multiple choices exist (e.g.,
> gaussian, gamma, etc.)? I ask in the context of extending some analyses
> from an RCT in which the outcome is symptomatic seropositivity (so a
> count). The random effects I am modeling are village cluster [union] (it's
> a cluster randomized trial). I get different results (significance-wise)
> depending on whether I choose a normal or gamma distribution for the random
> effects.
>
> The basic model (proportional outcome) is:
>
> lme4_5_B = glmer(posXsymp~ treatment+proper_mask_base+prop_resp_ill_base_2
> + pairID + (1 | union), family = "poisson", nAGQ=0, data = bdata.raw3)#lme4
> package using glmer
>
>
> HGLM2_5_A = hglm2(posXsymp~ treatment+proper_mask_base+prop_resp_ill_base_2
> + pairID + (1 | union), family =poisson (link = log), rand.family
> =Gamma(link=log),
> data = bdata.raw3)#HGLM package using hglm2
>
> Does, for example, the choice of distribution for the fixed effects portion
> of the model inform the choice for the random effects?
>
> Thank you for any insights.
>
> Best regards,
> J.D.
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

	[[alternative HTML version deleted]]


From @pro @end|ng |rom un|me|b@edu@@u  Wed Jul 20 11:26:37 2022
From: @pro @end|ng |rom un|me|b@edu@@u (Andrew Robinson)
Date: Wed, 20 Jul 2022 09:26:37 +0000
Subject: [R-sig-ME] [EXT] Re:  Choice of distribution for random effects
In-Reply-To: <CAH_7VOkBvC56rWewTLvQggDWu2EdKGn+ZzKyuE+O2z4mgNZ-zw@mail.gmail.com>
References: <CAH_7VOmFG=iwiwPdBR6Loj9FXeic41UQ-aBUg0a3b6qE_eh-gQ@mail.gmail.com>
 <fc0fdf63-fa89-44da-8739-9ec115b42e4a@Spark>
 <CAH_7VOkBvC56rWewTLvQggDWu2EdKGn+ZzKyuE+O2z4mgNZ-zw@mail.gmail.com>
Message-ID: <bb2aa1d1-8c58-408f-b701-e4e16bac1ba8@Spark>

You should really also verify that the hglm is doing what you expect by fitting with Gaussian random effects.

The random effects in glmer are Gaussian. The effects enter the model via the linear predictor, which is then translated to the mean function of the chosen distribution of the response variable via the link function (NB this is a conceptual explanation, not an algorithmic one).

Cheers,

Andrew
On 20 Jul 2022, 6:40 PM +1000, J.D. Haltigan <jhaltiga at gmail.com>, wrote:
External email: Please exercise caution

________________________________
Thanks, I will inspect the BLUPS.

Re: choice of distribution, what I meant was, for example, if my fixed effects family is estimated using a Poisson model, does that inform the choice for random effects as well? (i.e., why would one invoke a gaussian distribution for random effects if the response variable is, say, categorical, or a count?)

On Wed, Jul 20, 2022 at 3:40 AM Andrew Robinson <apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>> wrote:
You can use a qq-plot of the BLUPS to guide that decision.

The difference might also be due to something else, though.  Have you tried the call to hglm2 with a gaussian random effects family?  Does it give the same output as the glmer?

For: does the choice of distribution for the fixed effects portion of the model inform the choice for the random effects?  I?m not sure what you mean - do you mean the exponential family for the response variable?


Cheers,

Andrew

--
Andrew Robinson
Chief Executive Officer, CEBRA and Professor of Biosecurity,
School/s of BioSciences and Mathematics & Statistics
University of Melbourne, VIC 3010 Australia
Tel: (+61) 0403 138 955
Email: apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>
Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/

I acknowledge the Traditional Owners of the land I inhabit, and pay my respects to their Elders.
On 20 Jul 2022, 2:27 PM +1000, J.D. Haltigan <jhaltiga at gmail.com<mailto:jhaltiga at gmail.com>>, wrote:
Hi:

Is there clear best practice or guidance when it comes to choosing the
distribution of random effects where multiple choices exist (e.g.,
gaussian, gamma, etc.)? I ask in the context of extending some analyses
from an RCT in which the outcome is symptomatic seropositivity (so a
count). The random effects I am modeling are village cluster [union] (it's
a cluster randomized trial). I get different results (significance-wise)
depending on whether I choose a normal or gamma distribution for the random
effects.

The basic model (proportional outcome) is:

lme4_5_B = glmer(posXsymp~ treatment+proper_mask_base+prop_resp_ill_base_2
+ pairID + (1 | union), family = "poisson", nAGQ=0, data = bdata.raw3)#lme4
package using glmer


HGLM2_5_A = hglm2(posXsymp~ treatment+proper_mask_base+prop_resp_ill_base_2
+ pairID + (1 | union), family =poisson (link = log), rand.family
=Gamma(link=log),
data = bdata.raw3)#HGLM package using hglm2

Does, for example, the choice of distribution for the fixed effects portion
of the model inform the choice for the random effects?

Thank you for any insights.

Best regards,
J.D.

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>


	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Wed Jul 20 16:41:37 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 20 Jul 2022 10:41:37 -0400
Subject: [R-sig-ME] [EXT] Re: Choice of distribution for random effects
In-Reply-To: <bb2aa1d1-8c58-408f-b701-e4e16bac1ba8@Spark>
References: <CAH_7VOmFG=iwiwPdBR6Loj9FXeic41UQ-aBUg0a3b6qE_eh-gQ@mail.gmail.com>
 <fc0fdf63-fa89-44da-8739-9ec115b42e4a@Spark>
 <CAH_7VOkBvC56rWewTLvQggDWu2EdKGn+ZzKyuE+O2z4mgNZ-zw@mail.gmail.com>
 <bb2aa1d1-8c58-408f-b701-e4e16bac1ba8@Spark>
Message-ID: <297201de-5577-d813-f872-ef035b0f1b9b@gmail.com>

   I believe that there are some mathematically natural pairings (i.e. a 
Gamma random effect + a Poisson response, a Beta-distributed random 
effect + a binomial response), but I don't know if there's much 
theoretical justification other than analytical convenience.

   (If you have a categorical response then the natural random effect 
would be Dirichlet, i.e. a Dirichlet-multinomial marginal distribution, 
but do you really want to go down that rabbit hole?)

    I strongly second Andrew's recommendation to check that the 
difference is not a difference between packages/estimation procedures.

On 2022-07-20 5:26 a.m., Andrew Robinson wrote:
> You should really also verify that the hglm is doing what you expect by fitting with Gaussian random effects.
> 
> The random effects in glmer are Gaussian. The effects enter the model via the linear predictor, which is then translated to the mean function of the chosen distribution of the response variable via the link function (NB this is a conceptual explanation, not an algorithmic one).
> 
> Cheers,
> 
> Andrew
> On 20 Jul 2022, 6:40 PM +1000, J.D. Haltigan <jhaltiga at gmail.com>, wrote:
> External email: Please exercise caution
> 
> ________________________________
> Thanks, I will inspect the BLUPS.
> 
> Re: choice of distribution, what I meant was, for example, if my fixed effects family is estimated using a Poisson model, does that inform the choice for random effects as well? (i.e., why would one invoke a gaussian distribution for random effects if the response variable is, say, categorical, or a count?)
> 
> On Wed, Jul 20, 2022 at 3:40 AM Andrew Robinson <apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>> wrote:
> You can use a qq-plot of the BLUPS to guide that decision.
> 
> The difference might also be due to something else, though.  Have you tried the call to hglm2 with a gaussian random effects family?  Does it give the same output as the glmer?
> 
> For: does the choice of distribution for the fixed effects portion of the model inform the choice for the random effects?  I?m not sure what you mean - do you mean the exponential family for the response variable?
> 
> 
> Cheers,
> 
> Andrew
> 
> --
> Andrew Robinson
> Chief Executive Officer, CEBRA and Professor of Biosecurity,
> School/s of BioSciences and Mathematics & Statistics
> University of Melbourne, VIC 3010 Australia
> Tel: (+61) 0403 138 955
> Email: apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>
> Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/
> 
> I acknowledge the Traditional Owners of the land I inhabit, and pay my respects to their Elders.
> On 20 Jul 2022, 2:27 PM +1000, J.D. Haltigan <jhaltiga at gmail.com<mailto:jhaltiga at gmail.com>>, wrote:
> Hi:
> 
> Is there clear best practice or guidance when it comes to choosing the
> distribution of random effects where multiple choices exist (e.g.,
> gaussian, gamma, etc.)? I ask in the context of extending some analyses
> from an RCT in which the outcome is symptomatic seropositivity (so a
> count). The random effects I am modeling are village cluster [union] (it's
> a cluster randomized trial). I get different results (significance-wise)
> depending on whether I choose a normal or gamma distribution for the random
> effects.
> 
> The basic model (proportional outcome) is:
> 
> lme4_5_B = glmer(posXsymp~ treatment+proper_mask_base+prop_resp_ill_base_2
> + pairID + (1 | union), family = "poisson", nAGQ=0, data = bdata.raw3)#lme4
> package using glmer
> 
> 
> HGLM2_5_A = hglm2(posXsymp~ treatment+proper_mask_base+prop_resp_ill_base_2
> + pairID + (1 | union), family =poisson (link = log), rand.family
> =Gamma(link=log),
> data = bdata.raw3)#HGLM package using hglm2
> 
> Does, for example, the choice of distribution for the fixed effects portion
> of the model inform the choice for the random effects?
> 
> Thank you for any insights.
> 
> Best regards,
> J.D.
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics


From jh@|t|g@ @end|ng |rom gm@||@com  Thu Jul 21 02:23:48 2022
From: jh@|t|g@ @end|ng |rom gm@||@com (J.D. Haltigan)
Date: Wed, 20 Jul 2022 20:23:48 -0400
Subject: [R-sig-ME] [EXT] Re: Choice of distribution for random effects
In-Reply-To: <297201de-5577-d813-f872-ef035b0f1b9b@gmail.com>
References: <CAH_7VOmFG=iwiwPdBR6Loj9FXeic41UQ-aBUg0a3b6qE_eh-gQ@mail.gmail.com>
 <fc0fdf63-fa89-44da-8739-9ec115b42e4a@Spark>
 <CAH_7VOkBvC56rWewTLvQggDWu2EdKGn+ZzKyuE+O2z4mgNZ-zw@mail.gmail.com>
 <bb2aa1d1-8c58-408f-b701-e4e16bac1ba8@Spark>
 <297201de-5577-d813-f872-ef035b0f1b9b@gmail.com>
Message-ID: <CAH_7VOnnOJPu9+fwr6pA2Z4nGmmw5x_82CSsDqirfBMP0tn_Vw@mail.gmail.com>

Thanks, Ben. For example, here is a comparison of glmer & HGLM using
Guassian random effects for HGLM as suggested by Andrew. The magnitude of
the point estimates are about the same, but the nominal significance for
'treatment' is only significant when considering the Gaussian random
effects from lmer.

NB: In the project I am working on, the point is to show sensitivity of
results to different parameterizations of models. I understand the point
estimate magnitudes are about the same, but that is less relevant to this
exercise.

*lme4_5_B = glmer(posXsymp~ treatment+proper_mask_base+prop_resp_ill_base_2
+ pairID + (1 | union), family = "poisson", nAGQ=0, data = bdata.raw3)#lme4
package using glmer*

> summary(lme4_5_B)
Generalized linear mixed model fit by maximum likelihood (Adaptive
Gauss-Hermite Quadrature, nAGQ = 0) ['glmerMod']
 Family: poisson  ( log )
Formula: posXsymp ~ treatment + proper_mask_base + prop_resp_ill_base_2 +
   pairID + (1 | union)
   Data: bdata.raw3

     AIC      BIC   logLik deviance df.resid
 25054.5  27939.7 -12254.2  24508.5   287075

Scaled residuals:
      Min        1Q    Median        3Q       Max
-0.214597 -0.100237 -0.078562 -0.054499 40.646525

Random effects:
 Groups Name        Variance    Std.Dev.
 union  (Intercept) 0.007269442 0.08526102
Number of obs: 287348, groups:  union, 538

Fixed effects:
                         Estimate   Std. Error   z value
Pr(>|z|)
(Intercept)          -5.987724526  0.581280589 -10.30092 <
0.000000000000000222 ***
treatment            -0.094657198  0.044546951  -2.12489
0.03359612 *

***********************************************************************************************************************************************************************************************************************************

*HGLM2_5_Test = hglm2(posXsymp~
treatment+proper_mask_base+prop_resp_ill_base_2 + pairID + (1 | union),
family =poisson (link = log), rand.family =gaussian(link=identity),
          data = bdata.raw3)#HGLM package using hglm2*

> summary(HGLM2_5_Test)
Call:
hglm2.formula(meanmodel = posXsymp ~ treatment + proper_mask_base +
    prop_resp_ill_base_2 + pairID + (1 | union), data = bdata.raw3,
    family = poisson(link = log), rand.family = gaussian(link = identity))

----------
MEAN MODEL
----------

Summary of the fixed effects estimates:

                     Estimate Std. Error t-value     Pr(>|t|)
(Intercept)          -6.02638    1.09414  -5.508 0.0000000364 ***
treatment            -0.02977    0.13624  -0.218       0.8271

On Wed, Jul 20, 2022 at 10:42 AM Ben Bolker <bbolker at gmail.com> wrote:

>    I believe that there are some mathematically natural pairings (i.e. a
> Gamma random effect + a Poisson response, a Beta-distributed random
> effect + a binomial response), but I don't know if there's much
> theoretical justification other than analytical convenience.
>
>    (If you have a categorical response then the natural random effect
> would be Dirichlet, i.e. a Dirichlet-multinomial marginal distribution,
> but do you really want to go down that rabbit hole?)
>
>     I strongly second Andrew's recommendation to check that the
> difference is not a difference between packages/estimation procedures.
>
> On 2022-07-20 5:26 a.m., Andrew Robinson wrote:
> > You should really also verify that the hglm is doing what you expect by
> fitting with Gaussian random effects.
> >
> > The random effects in glmer are Gaussian. The effects enter the model
> via the linear predictor, which is then translated to the mean function of
> the chosen distribution of the response variable via the link function (NB
> this is a conceptual explanation, not an algorithmic one).
> >
> > Cheers,
> >
> > Andrew
> > On 20 Jul 2022, 6:40 PM +1000, J.D. Haltigan <jhaltiga at gmail.com>,
> wrote:
> > External email: Please exercise caution
> >
> > ________________________________
> > Thanks, I will inspect the BLUPS.
> >
> > Re: choice of distribution, what I meant was, for example, if my fixed
> effects family is estimated using a Poisson model, does that inform the
> choice for random effects as well? (i.e., why would one invoke a gaussian
> distribution for random effects if the response variable is, say,
> categorical, or a count?)
> >
> > On Wed, Jul 20, 2022 at 3:40 AM Andrew Robinson <apro at unimelb.edu.au
> <mailto:apro at unimelb.edu.au>> wrote:
> > You can use a qq-plot of the BLUPS to guide that decision.
> >
> > The difference might also be due to something else, though.  Have you
> tried the call to hglm2 with a gaussian random effects family?  Does it
> give the same output as the glmer?
> >
> > For: does the choice of distribution for the fixed effects portion of
> the model inform the choice for the random effects?  I?m not sure what you
> mean - do you mean the exponential family for the response variable?
> >
> >
> > Cheers,
> >
> > Andrew
> >
> > --
> > Andrew Robinson
> > Chief Executive Officer, CEBRA and Professor of Biosecurity,
> > School/s of BioSciences and Mathematics & Statistics
> > University of Melbourne, VIC 3010 Australia
> > Tel: (+61) 0403 138 955
> > Email: apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>
> > Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/
> >
> > I acknowledge the Traditional Owners of the land I inhabit, and pay my
> respects to their Elders.
> > On 20 Jul 2022, 2:27 PM +1000, J.D. Haltigan <jhaltiga at gmail.com<mailto:
> jhaltiga at gmail.com>>, wrote:
> > Hi:
> >
> > Is there clear best practice or guidance when it comes to choosing the
> > distribution of random effects where multiple choices exist (e.g.,
> > gaussian, gamma, etc.)? I ask in the context of extending some analyses
> > from an RCT in which the outcome is symptomatic seropositivity (so a
> > count). The random effects I am modeling are village cluster [union]
> (it's
> > a cluster randomized trial). I get different results (significance-wise)
> > depending on whether I choose a normal or gamma distribution for the
> random
> > effects.
> >
> > The basic model (proportional outcome) is:
> >
> > lme4_5_B = glmer(posXsymp~
> treatment+proper_mask_base+prop_resp_ill_base_2
> > + pairID + (1 | union), family = "poisson", nAGQ=0, data =
> bdata.raw3)#lme4
> > package using glmer
> >
> >
> > HGLM2_5_A = hglm2(posXsymp~
> treatment+proper_mask_base+prop_resp_ill_base_2
> > + pairID + (1 | union), family =poisson (link = log), rand.family
> > =Gamma(link=log),
> > data = bdata.raw3)#HGLM package using hglm2
> >
> > Does, for example, the choice of distribution for the fixed effects
> portion
> > of the model inform the choice for the random effects?
> >
> > Thank you for any insights.
> >
> > Best regards,
> > J.D.
> >
> > [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> (Acting) Graduate chair, Mathematics & Statistics
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From @pro @end|ng |rom un|me|b@edu@@u  Thu Jul 21 02:34:55 2022
From: @pro @end|ng |rom un|me|b@edu@@u (Andrew Robinson)
Date: Thu, 21 Jul 2022 00:34:55 +0000
Subject: [R-sig-ME] [EXT] Re: Choice of distribution for random effects
In-Reply-To: <CAH_7VOnnOJPu9+fwr6pA2Z4nGmmw5x_82CSsDqirfBMP0tn_Vw@mail.gmail.com>
References: <CAH_7VOmFG=iwiwPdBR6Loj9FXeic41UQ-aBUg0a3b6qE_eh-gQ@mail.gmail.com>
 <fc0fdf63-fa89-44da-8739-9ec115b42e4a@Spark>
 <CAH_7VOkBvC56rWewTLvQggDWu2EdKGn+ZzKyuE+O2z4mgNZ-zw@mail.gmail.com>
 <bb2aa1d1-8c58-408f-b701-e4e16bac1ba8@Spark>
 <297201de-5577-d813-f872-ef035b0f1b9b@gmail.com>
 <CAH_7VOnnOJPu9+fwr6pA2Z4nGmmw5x_82CSsDqirfBMP0tn_Vw@mail.gmail.com>
Message-ID: <707277e8-f6c9-4606-b017-72fd05bb22f3@Spark>

Ben is correct that the traditional alignment of certain link functions with certain members of the exponential family (the so-called 'canonical' links) are merely for analytical convenience and have no statistical justification.

Canonical link functions exercise an unhealthy influence on statistical practice, IMO.  OTOH, there are circumstances in which they may afford parameter estimates that are easier to interpret.

I'm not familiar with hglm but I suspect you may need to use the log-link function for the random effects in order to get something like the glmer output.

Cheers,

Andrew

--
Andrew Robinson
Chief Executive Officer, CEBRA and Professor of Biosecurity,
School/s of BioSciences and Mathematics & Statistics
University of Melbourne, VIC 3010 Australia
Tel: (+61) 0403 138 955
Email: apro at unimelb.edu.au
Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/

I acknowledge the Traditional Owners of the land I inhabit, and pay my respects to their Elders.
On 21 Jul 2022, 10:24 AM +1000, J.D. Haltigan <jhaltiga at gmail.com>, wrote:
Thanks, Ben. For example, here is a comparison of glmer & HGLM using
Guassian random effects for HGLM as suggested by Andrew. The magnitude of
the point estimates are about the same, but the nominal significance for
'treatment' is only significant when considering the Gaussian random
effects from lmer.

NB: In the project I am working on, the point is to show sensitivity of
results to different parameterizations of models. I understand the point
estimate magnitudes are about the same, but that is less relevant to this
exercise.

*lme4_5_B = glmer(posXsymp~ treatment+proper_mask_base+prop_resp_ill_base_2
+ pairID + (1 | union), family = "poisson", nAGQ=0, data = bdata.raw3)#lme4
package using glmer*

summary(lme4_5_B)
Generalized linear mixed model fit by maximum likelihood (Adaptive
Gauss-Hermite Quadrature, nAGQ = 0) ['glmerMod']
Family: poisson ( log )
Formula: posXsymp ~ treatment + proper_mask_base + prop_resp_ill_base_2 +
pairID + (1 | union)
Data: bdata.raw3

AIC BIC logLik deviance df.resid
25054.5 27939.7 -12254.2 24508.5 287075

Scaled residuals:
Min 1Q Median 3Q Max
-0.214597 -0.100237 -0.078562 -0.054499 40.646525

Random effects:
Groups Name Variance Std.Dev.
union (Intercept) 0.007269442 0.08526102
Number of obs: 287348, groups: union, 538

Fixed effects:
Estimate Std. Error z value
Pr(>|z|)
(Intercept) -5.987724526 0.581280589 -10.30092 <
0.000000000000000222 ***
treatment -0.094657198 0.044546951 -2.12489
0.03359612 *

***********************************************************************************************************************************************************************************************************************************

*HGLM2_5_Test = hglm2(posXsymp~
treatment+proper_mask_base+prop_resp_ill_base_2 + pairID + (1 | union),
family =poisson (link = log), rand.family =gaussian(link=identity),
data = bdata.raw3)#HGLM package using hglm2*

summary(HGLM2_5_Test)
Call:
hglm2.formula(meanmodel = posXsymp ~ treatment + proper_mask_base +
prop_resp_ill_base_2 + pairID + (1 | union), data = bdata.raw3,
family = poisson(link = log), rand.family = gaussian(link = identity))

----------
MEAN MODEL
----------

Summary of the fixed effects estimates:

Estimate Std. Error t-value Pr(>|t|)
(Intercept) -6.02638 1.09414 -5.508 0.0000000364 ***
treatment -0.02977 0.13624 -0.218 0.8271

On Wed, Jul 20, 2022 at 10:42 AM Ben Bolker <bbolker at gmail.com> wrote:

I believe that there are some mathematically natural pairings (i.e. a
Gamma random effect + a Poisson response, a Beta-distributed random
effect + a binomial response), but I don't know if there's much
theoretical justification other than analytical convenience.

(If you have a categorical response then the natural random effect
would be Dirichlet, i.e. a Dirichlet-multinomial marginal distribution,
but do you really want to go down that rabbit hole?)

I strongly second Andrew's recommendation to check that the
difference is not a difference between packages/estimation procedures.

On 2022-07-20 5:26 a.m., Andrew Robinson wrote:
You should really also verify that the hglm is doing what you expect by
fitting with Gaussian random effects.

The random effects in glmer are Gaussian. The effects enter the model
via the linear predictor, which is then translated to the mean function of
the chosen distribution of the response variable via the link function (NB
this is a conceptual explanation, not an algorithmic one).

Cheers,

Andrew
On 20 Jul 2022, 6:40 PM +1000, J.D. Haltigan <jhaltiga at gmail.com>,
wrote:
External email: Please exercise caution

________________________________
Thanks, I will inspect the BLUPS.

Re: choice of distribution, what I meant was, for example, if my fixed
effects family is estimated using a Poisson model, does that inform the
choice for random effects as well? (i.e., why would one invoke a gaussian
distribution for random effects if the response variable is, say,
categorical, or a count?)

On Wed, Jul 20, 2022 at 3:40 AM Andrew Robinson <apro at unimelb.edu.au
<mailto:apro at unimelb.edu.au>> wrote:
You can use a qq-plot of the BLUPS to guide that decision.

The difference might also be due to something else, though. Have you
tried the call to hglm2 with a gaussian random effects family? Does it
give the same output as the glmer?

For: does the choice of distribution for the fixed effects portion of
the model inform the choice for the random effects? I?m not sure what you
mean - do you mean the exponential family for the response variable?


Cheers,

Andrew

--
Andrew Robinson
Chief Executive Officer, CEBRA and Professor of Biosecurity,
School/s of BioSciences and Mathematics & Statistics
University of Melbourne, VIC 3010 Australia
Tel: (+61) 0403 138 955
Email: apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>
Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/

I acknowledge the Traditional Owners of the land I inhabit, and pay my
respects to their Elders.
On 20 Jul 2022, 2:27 PM +1000, J.D. Haltigan <jhaltiga at gmail.com<mailto:
jhaltiga at gmail.com>>, wrote:
Hi:

Is there clear best practice or guidance when it comes to choosing the
distribution of random effects where multiple choices exist (e.g.,
gaussian, gamma, etc.)? I ask in the context of extending some analyses
from an RCT in which the outcome is symptomatic seropositivity (so a
count). The random effects I am modeling are village cluster [union]
(it's
a cluster randomized trial). I get different results (significance-wise)
depending on whether I choose a normal or gamma distribution for the
random
effects.

The basic model (proportional outcome) is:

lme4_5_B = glmer(posXsymp~
treatment+proper_mask_base+prop_resp_ill_base_2
+ pairID + (1 | union), family = "poisson", nAGQ=0, data =
bdata.raw3)#lme4
package using glmer


HGLM2_5_A = hglm2(posXsymp~
treatment+proper_mask_base+prop_resp_ill_base_2
+ pairID + (1 | union), family =poisson (link = log), rand.family
=Gamma(link=log),
data = bdata.raw3)#HGLM package using hglm2

Does, for example, the choice of distribution for the fixed effects
portion
of the model inform the choice for the random effects?

Thank you for any insights.

Best regards,
J.D.

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>


[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From jh@|t|g@ @end|ng |rom gm@||@com  Thu Jul 21 05:03:46 2022
From: jh@|t|g@ @end|ng |rom gm@||@com (J.D. Haltigan)
Date: Wed, 20 Jul 2022 23:03:46 -0400
Subject: [R-sig-ME] [EXT] Re: Choice of distribution for random effects
In-Reply-To: <707277e8-f6c9-4606-b017-72fd05bb22f3@Spark>
References: <CAH_7VOmFG=iwiwPdBR6Loj9FXeic41UQ-aBUg0a3b6qE_eh-gQ@mail.gmail.com>
 <fc0fdf63-fa89-44da-8739-9ec115b42e4a@Spark>
 <CAH_7VOkBvC56rWewTLvQggDWu2EdKGn+ZzKyuE+O2z4mgNZ-zw@mail.gmail.com>
 <bb2aa1d1-8c58-408f-b701-e4e16bac1ba8@Spark>
 <297201de-5577-d813-f872-ef035b0f1b9b@gmail.com>
 <CAH_7VOnnOJPu9+fwr6pA2Z4nGmmw5x_82CSsDqirfBMP0tn_Vw@mail.gmail.com>
 <707277e8-f6c9-4606-b017-72fd05bb22f3@Spark>
Message-ID: <CAH_7VOkMyLNVnMyuABvJQaRraKyCfFiErq+XQ0NxwyKpnw-MHw@mail.gmail.com>

This cross-validated post seemed helpful and aligned with everything
previously mentioned here, and I wanted to share.
https://stats.stackexchange.com/questions/190763/how-to-decide-which-glm-family-to-use

Thanks for all of your insights as this is quite a deep dive for me.

To be sure: in glmer, when one specifies the GLM family, that then applies
to both fixed & random effects, correct? In other words, there is no way to
separately specify a distribution for the random effects in glmer? I know I
asked this question to Ben on the lme4 Git, but I wanted to confirm again.

JD

On Wed, Jul 20, 2022 at 8:35 PM Andrew Robinson <apro at unimelb.edu.au> wrote:

> Ben is correct that the traditional alignment of certain link functions
> with certain members of the exponential family (the so-called 'canonical'
> links) are merely for analytical convenience and have no statistical
> justification.
>
> Canonical link functions exercise an unhealthy influence on statistical
> practice, IMO.  OTOH, there are circumstances in which they may afford
> parameter estimates that are easier to interpret.
>
> I'm not familiar with hglm but I suspect you may need to use the log-link
> function for the random effects in order to get something like the glmer
> output.
>
> Cheers,
>
> Andrew
>
> --
> Andrew Robinson
> Chief Executive Officer, CEBRA and Professor of Biosecurity,
> School/s of BioSciences and Mathematics & Statistics
> University of Melbourne, VIC 3010 Australia
> Tel: (+61) 0403 138 955
> Email: apro at unimelb.edu.au
> Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/
>
> I acknowledge the Traditional Owners of the land I inhabit, and pay my
> respects to their Elders.
> On 21 Jul 2022, 10:24 AM +1000, J.D. Haltigan <jhaltiga at gmail.com>, wrote:
>
> Thanks, Ben. For example, here is a comparison of glmer & HGLM using
> Guassian random effects for HGLM as suggested by Andrew. The magnitude of
> the point estimates are about the same, but the nominal significance for
> 'treatment' is only significant when considering the Gaussian random
> effects from lmer.
>
> NB: In the project I am working on, the point is to show sensitivity of
> results to different parameterizations of models. I understand the point
> estimate magnitudes are about the same, but that is less relevant to this
> exercise.
>
> *lme4_5_B = glmer(posXsymp~ treatment+proper_mask_base+prop_resp_ill_base_2
> + pairID + (1 | union), family = "poisson", nAGQ=0, data = bdata.raw3)#lme4
> package using glmer*
>
> summary(lme4_5_B)
>
> Generalized linear mixed model fit by maximum likelihood (Adaptive
> Gauss-Hermite Quadrature, nAGQ = 0) ['glmerMod']
> Family: poisson ( log )
> Formula: posXsymp ~ treatment + proper_mask_base + prop_resp_ill_base_2 +
> pairID + (1 | union)
> Data: bdata.raw3
>
> AIC BIC logLik deviance df.resid
> 25054.5 27939.7 -12254.2 24508.5 287075
>
> Scaled residuals:
> Min 1Q Median 3Q Max
> -0.214597 -0.100237 -0.078562 -0.054499 40.646525
>
> Random effects:
> Groups Name Variance Std.Dev.
> union (Intercept) 0.007269442 0.08526102
> Number of obs: 287348, groups: union, 538
>
> Fixed effects:
> Estimate Std. Error z value
> Pr(>|z|)
> (Intercept) -5.987724526 0.581280589 -10.30092 <
> 0.000000000000000222 ***
> treatment -0.094657198 0.044546951 -2.12489
> 0.03359612 *
>
>
> ***********************************************************************************************************************************************************************************************************************************
>
> *HGLM2_5_Test = hglm2(posXsymp~
> treatment+proper_mask_base+prop_resp_ill_base_2 + pairID + (1 | union),
> family =poisson (link = log), rand.family =gaussian(link=identity),
> data = bdata.raw3)#HGLM package using hglm2*
>
> summary(HGLM2_5_Test)
>
> Call:
> hglm2.formula(meanmodel = posXsymp ~ treatment + proper_mask_base +
> prop_resp_ill_base_2 + pairID + (1 | union), data = bdata.raw3,
> family = poisson(link = log), rand.family = gaussian(link = identity))
>
> ----------
> MEAN MODEL
> ----------
>
> Summary of the fixed effects estimates:
>
> Estimate Std. Error t-value Pr(>|t|)
> (Intercept) -6.02638 1.09414 -5.508 0.0000000364 ***
> treatment -0.02977 0.13624 -0.218 0.8271
>
> On Wed, Jul 20, 2022 at 10:42 AM Ben Bolker <bbolker at gmail.com> wrote:
>
> I believe that there are some mathematically natural pairings (i.e. a
> Gamma random effect + a Poisson response, a Beta-distributed random
> effect + a binomial response), but I don't know if there's much
> theoretical justification other than analytical convenience.
>
> (If you have a categorical response then the natural random effect
> would be Dirichlet, i.e. a Dirichlet-multinomial marginal distribution,
> but do you really want to go down that rabbit hole?)
>
> I strongly second Andrew's recommendation to check that the
> difference is not a difference between packages/estimation procedures.
>
> On 2022-07-20 5:26 a.m., Andrew Robinson wrote:
>
> You should really also verify that the hglm is doing what you expect by
>
> fitting with Gaussian random effects.
>
>
> The random effects in glmer are Gaussian. The effects enter the model
>
> via the linear predictor, which is then translated to the mean function of
> the chosen distribution of the response variable via the link function (NB
> this is a conceptual explanation, not an algorithmic one).
>
>
> Cheers,
>
> Andrew
> On 20 Jul 2022, 6:40 PM +1000, J.D. Haltigan <jhaltiga at gmail.com>,
>
> wrote:
>
> External email: Please exercise caution
>
> ________________________________
> Thanks, I will inspect the BLUPS.
>
> Re: choice of distribution, what I meant was, for example, if my fixed
>
> effects family is estimated using a Poisson model, does that inform the
> choice for random effects as well? (i.e., why would one invoke a gaussian
> distribution for random effects if the response variable is, say,
> categorical, or a count?)
>
>
> On Wed, Jul 20, 2022 at 3:40 AM Andrew Robinson <apro at unimelb.edu.au
>
> <mailto:apro at unimelb.edu.au>> wrote:
>
> You can use a qq-plot of the BLUPS to guide that decision.
>
> The difference might also be due to something else, though. Have you
>
> tried the call to hglm2 with a gaussian random effects family? Does it
> give the same output as the glmer?
>
>
> For: does the choice of distribution for the fixed effects portion of
>
> the model inform the choice for the random effects? I?m not sure what you
> mean - do you mean the exponential family for the response variable?
>
>
>
> Cheers,
>
> Andrew
>
> --
> Andrew Robinson
> Chief Executive Officer, CEBRA and Professor of Biosecurity,
> School/s of BioSciences and Mathematics & Statistics
> University of Melbourne, VIC 3010 Australia
> Tel: (+61) 0403 138 955
> Email: apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>
> Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/
>
> I acknowledge the Traditional Owners of the land I inhabit, and pay my
>
> respects to their Elders.
>
> On 20 Jul 2022, 2:27 PM +1000, J.D. Haltigan <jhaltiga at gmail.com<mailto:
>
> jhaltiga at gmail.com>>, wrote:
>
> Hi:
>
> Is there clear best practice or guidance when it comes to choosing the
> distribution of random effects where multiple choices exist (e.g.,
> gaussian, gamma, etc.)? I ask in the context of extending some analyses
> from an RCT in which the outcome is symptomatic seropositivity (so a
> count). The random effects I am modeling are village cluster [union]
>
> (it's
>
> a cluster randomized trial). I get different results (significance-wise)
> depending on whether I choose a normal or gamma distribution for the
>
> random
>
> effects.
>
> The basic model (proportional outcome) is:
>
> lme4_5_B = glmer(posXsymp~
>
> treatment+proper_mask_base+prop_resp_ill_base_2
>
> + pairID + (1 | union), family = "poisson", nAGQ=0, data =
>
> bdata.raw3)#lme4
>
> package using glmer
>
>
> HGLM2_5_A = hglm2(posXsymp~
>
> treatment+proper_mask_base+prop_resp_ill_base_2
>
> + pairID + (1 | union), family =poisson (link = log), rand.family
> =Gamma(link=log),
> data = bdata.raw3)#HGLM package using hglm2
>
> Does, for example, the choice of distribution for the fixed effects
>
> portion
>
> of the model inform the choice for the random effects?
>
> Thank you for any insights.
>
> Best regards,
> J.D.
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
>
> mailing list
>
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<
>
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>
>
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> --
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> (Acting) Graduate chair, Mathematics & Statistics
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

	[[alternative HTML version deleted]]


From @pro @end|ng |rom un|me|b@edu@@u  Thu Jul 21 05:36:49 2022
From: @pro @end|ng |rom un|me|b@edu@@u (Andrew Robinson)
Date: Thu, 21 Jul 2022 03:36:49 +0000
Subject: [R-sig-ME] [EXT] Re: Choice of distribution for random effects
In-Reply-To: <CAH_7VOkMyLNVnMyuABvJQaRraKyCfFiErq+XQ0NxwyKpnw-MHw@mail.gmail.com>
References: <CAH_7VOmFG=iwiwPdBR6Loj9FXeic41UQ-aBUg0a3b6qE_eh-gQ@mail.gmail.com>
 <fc0fdf63-fa89-44da-8739-9ec115b42e4a@Spark>
 <CAH_7VOkBvC56rWewTLvQggDWu2EdKGn+ZzKyuE+O2z4mgNZ-zw@mail.gmail.com>
 <bb2aa1d1-8c58-408f-b701-e4e16bac1ba8@Spark>
 <297201de-5577-d813-f872-ef035b0f1b9b@gmail.com>
 <CAH_7VOnnOJPu9+fwr6pA2Z4nGmmw5x_82CSsDqirfBMP0tn_Vw@mail.gmail.com>
 <707277e8-f6c9-4606-b017-72fd05bb22f3@Spark>
 <CAH_7VOkMyLNVnMyuABvJQaRraKyCfFiErq+XQ0NxwyKpnw-MHw@mail.gmail.com>
Message-ID: <ae0f8c6a-05e5-4cdf-9000-4705b1091e18@Spark>

That is correct.

Cheers,

Andrew

--
Andrew Robinson
Chief Executive Officer, CEBRA and Professor of Biosecurity,
School/s of BioSciences and Mathematics & Statistics
University of Melbourne, VIC 3010 Australia
Tel: (+61) 0403 138 955
Email: apro at unimelb.edu.au
Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/

I acknowledge the Traditional Owners of the land I inhabit, and pay my respects to their Elders.
On 21 Jul 2022, 1:04 PM +1000, J.D. Haltigan <jhaltiga at gmail.com>, wrote:
This cross-validated post seemed helpful and aligned with everything
previously mentioned here, and I wanted to share.
https://stats.stackexchange.com/questions/190763/how-to-decide-which-glm-family-to-use

Thanks for all of your insights as this is quite a deep dive for me.

To be sure: in glmer, when one specifies the GLM family, that then applies
to both fixed & random effects, correct? In other words, there is no way to
separately specify a distribution for the random effects in glmer? I know I
asked this question to Ben on the lme4 Git, but I wanted to confirm again.

JD

On Wed, Jul 20, 2022 at 8:35 PM Andrew Robinson <apro at unimelb.edu.au> wrote:

Ben is correct that the traditional alignment of certain link functions
with certain members of the exponential family (the so-called 'canonical'
links) are merely for analytical convenience and have no statistical
justification.

Canonical link functions exercise an unhealthy influence on statistical
practice, IMO. OTOH, there are circumstances in which they may afford
parameter estimates that are easier to interpret.

I'm not familiar with hglm but I suspect you may need to use the log-link
function for the random effects in order to get something like the glmer
output.

Cheers,

Andrew

--
Andrew Robinson
Chief Executive Officer, CEBRA and Professor of Biosecurity,
School/s of BioSciences and Mathematics & Statistics
University of Melbourne, VIC 3010 Australia
Tel: (+61) 0403 138 955
Email: apro at unimelb.edu.au
Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/

I acknowledge the Traditional Owners of the land I inhabit, and pay my
respects to their Elders.
On 21 Jul 2022, 10:24 AM +1000, J.D. Haltigan <jhaltiga at gmail.com>, wrote:

Thanks, Ben. For example, here is a comparison of glmer & HGLM using
Guassian random effects for HGLM as suggested by Andrew. The magnitude of
the point estimates are about the same, but the nominal significance for
'treatment' is only significant when considering the Gaussian random
effects from lmer.

NB: In the project I am working on, the point is to show sensitivity of
results to different parameterizations of models. I understand the point
estimate magnitudes are about the same, but that is less relevant to this
exercise.

*lme4_5_B = glmer(posXsymp~ treatment+proper_mask_base+prop_resp_ill_base_2
+ pairID + (1 | union), family = "poisson", nAGQ=0, data = bdata.raw3)#lme4
package using glmer*

summary(lme4_5_B)

Generalized linear mixed model fit by maximum likelihood (Adaptive
Gauss-Hermite Quadrature, nAGQ = 0) ['glmerMod']
Family: poisson ( log )
Formula: posXsymp ~ treatment + proper_mask_base + prop_resp_ill_base_2 +
pairID + (1 | union)
Data: bdata.raw3

AIC BIC logLik deviance df.resid
25054.5 27939.7 -12254.2 24508.5 287075

Scaled residuals:
Min 1Q Median 3Q Max
-0.214597 -0.100237 -0.078562 -0.054499 40.646525

Random effects:
Groups Name Variance Std.Dev.
union (Intercept) 0.007269442 0.08526102
Number of obs: 287348, groups: union, 538

Fixed effects:
Estimate Std. Error z value
Pr(>|z|)
(Intercept) -5.987724526 0.581280589 -10.30092 <
0.000000000000000222 ***
treatment -0.094657198 0.044546951 -2.12489
0.03359612 *


***********************************************************************************************************************************************************************************************************************************

*HGLM2_5_Test = hglm2(posXsymp~
treatment+proper_mask_base+prop_resp_ill_base_2 + pairID + (1 | union),
family =poisson (link = log), rand.family =gaussian(link=identity),
data = bdata.raw3)#HGLM package using hglm2*

summary(HGLM2_5_Test)

Call:
hglm2.formula(meanmodel = posXsymp ~ treatment + proper_mask_base +
prop_resp_ill_base_2 + pairID + (1 | union), data = bdata.raw3,
family = poisson(link = log), rand.family = gaussian(link = identity))

----------
MEAN MODEL
----------

Summary of the fixed effects estimates:

Estimate Std. Error t-value Pr(>|t|)
(Intercept) -6.02638 1.09414 -5.508 0.0000000364 ***
treatment -0.02977 0.13624 -0.218 0.8271

On Wed, Jul 20, 2022 at 10:42 AM Ben Bolker <bbolker at gmail.com> wrote:

I believe that there are some mathematically natural pairings (i.e. a
Gamma random effect + a Poisson response, a Beta-distributed random
effect + a binomial response), but I don't know if there's much
theoretical justification other than analytical convenience.

(If you have a categorical response then the natural random effect
would be Dirichlet, i.e. a Dirichlet-multinomial marginal distribution,
but do you really want to go down that rabbit hole?)

I strongly second Andrew's recommendation to check that the
difference is not a difference between packages/estimation procedures.

On 2022-07-20 5:26 a.m., Andrew Robinson wrote:

You should really also verify that the hglm is doing what you expect by

fitting with Gaussian random effects.


The random effects in glmer are Gaussian. The effects enter the model

via the linear predictor, which is then translated to the mean function of
the chosen distribution of the response variable via the link function (NB
this is a conceptual explanation, not an algorithmic one).


Cheers,

Andrew
On 20 Jul 2022, 6:40 PM +1000, J.D. Haltigan <jhaltiga at gmail.com>,

wrote:

External email: Please exercise caution

________________________________
Thanks, I will inspect the BLUPS.

Re: choice of distribution, what I meant was, for example, if my fixed

effects family is estimated using a Poisson model, does that inform the
choice for random effects as well? (i.e., why would one invoke a gaussian
distribution for random effects if the response variable is, say,
categorical, or a count?)


On Wed, Jul 20, 2022 at 3:40 AM Andrew Robinson <apro at unimelb.edu.au

<mailto:apro at unimelb.edu.au>> wrote:

You can use a qq-plot of the BLUPS to guide that decision.

The difference might also be due to something else, though. Have you

tried the call to hglm2 with a gaussian random effects family? Does it
give the same output as the glmer?


For: does the choice of distribution for the fixed effects portion of

the model inform the choice for the random effects? I?m not sure what you
mean - do you mean the exponential family for the response variable?



Cheers,

Andrew

--
Andrew Robinson
Chief Executive Officer, CEBRA and Professor of Biosecurity,
School/s of BioSciences and Mathematics & Statistics
University of Melbourne, VIC 3010 Australia
Tel: (+61) 0403 138 955
Email: apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>
Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/

I acknowledge the Traditional Owners of the land I inhabit, and pay my

respects to their Elders.

On 20 Jul 2022, 2:27 PM +1000, J.D. Haltigan <jhaltiga at gmail.com<mailto:

jhaltiga at gmail.com>>, wrote:

Hi:

Is there clear best practice or guidance when it comes to choosing the
distribution of random effects where multiple choices exist (e.g.,
gaussian, gamma, etc.)? I ask in the context of extending some analyses
from an RCT in which the outcome is symptomatic seropositivity (so a
count). The random effects I am modeling are village cluster [union]

(it's

a cluster randomized trial). I get different results (significance-wise)
depending on whether I choose a normal or gamma distribution for the

random

effects.

The basic model (proportional outcome) is:

lme4_5_B = glmer(posXsymp~

treatment+proper_mask_base+prop_resp_ill_base_2

+ pairID + (1 | union), family = "poisson", nAGQ=0, data =

bdata.raw3)#lme4

package using glmer


HGLM2_5_A = hglm2(posXsymp~

treatment+proper_mask_base+prop_resp_ill_base_2

+ pairID + (1 | union), family =poisson (link = log), rand.family
=Gamma(link=log),
data = bdata.raw3)#HGLM package using hglm2

Does, for example, the choice of distribution for the fixed effects

portion

of the model inform the choice for the random effects?

Thank you for any insights.

Best regards,
J.D.

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>

mailing list

https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<

https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>



[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


--
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From benpe|zer @end|ng |rom gm@||@com  Thu Jul 21 11:24:27 2022
From: benpe|zer @end|ng |rom gm@||@com (ben pelzer)
Date: Thu, 21 Jul 2022 11:24:27 +0200
Subject: [R-sig-ME] results lme unstructured covariance matrix, again
In-Reply-To: <2fbf2ced-4fe3-7f72-145d-2ba6a8299be5@mcmaster.ca>
References: <29754_1657980613_26GEACWL024787_CAFgPNS_+x_ZDwaZUx0tzYs2U2D7s1roFqfcADU+_sTypf8i9jw@mail.gmail.com>
 <5d88d002-d568-269a-50f7-11d259ebff0d@mcmaster.ca>
 <CAFgPNS9QbpWOrFiw+TB_sTN0qt+U3GpKp=uwAtd971xnjJoQbQ@mail.gmail.com>
 <14495_1658165552_26IHWWJ9018805_dfe266dd-b96a-c28f-9cdd-121634019be9@mcmaster.ca>
 <264bc675-51d7-a1d3-b67e-13635140754a@mcmaster.ca>
 <7232_1658235102_26JCpfYa001214_CAFgPNS-B7r1Q+a9-f6rvesZTAhiAM0_UdZyvHPiFBcfheozkkA@mail.gmail.com>
 <2fbf2ced-4fe3-7f72-145d-2ba6a8299be5@mcmaster.ca>
Message-ID: <CAFgPNS9w0s6DgrsVAu88A5n=eDB+kUDHqz3-7YDAG2frTkvRqg@mail.gmail.com>

Dear John,

Thanks again for your reply and good advice. Indeed, the choice of model
should be guided by theory or, say, practical knowledge of the data at
hand. And indeed, the "random time" approach could definitely be a good way
to think of the underlying mechanism that generated the data, apart from
whether or not lme or lmer is able to produce meaningful estimates. That
would only be a technical issue. Thanks for making this more clear!

Ben.


On Tue, 19 Jul 2022 at 19:23, John Fox <jfox at mcmaster.ca> wrote:

> Dear Ben,
>
> The discussion is starting to stray from software issues, so I'll try to
> answer briefly.
>
> I think that you're emphasizing the wrong point, which is how to specify
> a model that produces estimates, rather than specifying a random-effects
> structure that's reasonable for the data.
>
> As you point out, an unrestricted variance-covariance structure for the
> model you originally specified is underidentified, as is a similar model
> with 3 within-subjects measurements. As you also correctly point out,
> fitting 3 occasions with 2 dummy regressors is equivalent to fitting a
> quadratic -- both have 3 parameters (including the intercept).
>
> Placing a restriction on the random effects, such as setting the
> observation-level error variance to 0, can identify the
> variance-covariance parameters, as can other sorts of restrictions. If
> just one constraint is placed on the variances and covariances of the
> random effects, the resulting variance-covariance parameters will be
> just-identified, and different such constraints are equivalent, in the
> sense of producing the same likelihood and fixed-effects estimates. You
> can see how this works by looking at the equations I wrote out for the
> variance-covariance components.
>
> This is simply a mechanical point, and in general there's no reason to
> prefer one constraint to another, but in a real application one model
> may be more reasonable than another for the data at hand. For example,
> the data I generated has only one true random effect -- the observation
> level error -- and so a correct model for the data has only one
> variance-covariance component -- the error variance. lm(y ~ t2, data=da)
> fits this model, which is much more restrictive than a single constraint
> on the more general mixed model. More elaborate random-effect
> specifications for my data have superfluous parameters, whether or not
> they're identified.
>
> Best,
>   John
>
> On 2022-07-19 8:50 a.m., ben pelzer wrote:
> > Dear John, Wolfgang, James and Ben,
> >
> > Thanks to you all for your explanations and examples! As I understand it
> > now, cancelling the estimation of the sigma, by fixing it to a small
> > positive number close to zero, produces random effects estimates of the
> > intercept and t2 (or of t1 and t2) which make sense. However, the
> > loglikelihood doesn't make sense. I guess that with sigma fixed to nearly
> > zero, the predictions will be meaningful too, even when including the
> > random effects in the predictions, though I did not verify that yet.
> >
> > All in all, I think that for a model with an unstructured covariance
> > matrix, "gls" is more straightforward. For the example of John:
> >
> > da$time <- da$t2 + 1
> > m4 <- gls(y ~ 1 + t2,
> >            correlation=corSymm(form= ~time|person),
> >            weights=varIdent(form= ~1|time),
> >            data=da)
> >
> > and the results are equal to e.g.
> >
> > m2 <- lme(y ~ 1 + t2, random = ~ 1 + t2 | person, data=da)
> >
> > as far as the loglikelihood and the estimated (co)variances (getVarCov)
> are
> > concerned.
> >
> > My question about "lme" arose when helping someone with such an
> > unstructured covariances model, for data with three fixed occasions. With
> > "many" occasions, a random linear effect of time is often employed, or
> > maybe a random quadratic time effect or cubic... Anyway, time is used as
> a
> > random (linear etc) effect in such models. But with only three occasions,
> > and with the time effect not being linear but quadratic, the model turns
> > into the kind of model I was questioning about, but with three occasions
> > instead of two. So, instead of
> >
> > modelA <- lme(y ~ 1+time+timesquared, random= ~ 1+time+timesquared |
> > person, data=da)
> >
> > one could then use
> >
> > modelB <- lme(y ~ 1+t2+t3, random= ~ 1+t2+t3 | person, data=da)
> >
> > But the random effect variances of t2 and t3 are not meaningful, as I
> know
> > now. And with the often used "lmer" the model is not estimated (except
> when
> > avoiding the "counting check" as Ben Bolker explained). This means that
> the
> > "random time effect" models, which I explain to students in a course, is
> > not applicable to such data. I thought/hoped that "lme" could be used,
> and
> > in a way it can, with fixing the sigma, but apparently this also leads to
> > some "unexpected" results. On the other hand, "gls" is a new method for
> > students used to the "random time effect" models. So I have to choose
> among
> > these two possibilities.
> >
> > Thanks again everyone, time to switch off the computer and enjoy the sun.
> > It's almost 40 degrees Celsius or 104 Farenheit in The Netherlands now,
> so
> > maybe enjoying is not the right word. Best to you all,
> >
> > Ben Pelzer.
> >
> >
> >
> >
> >
> > On Tue, 19 Jul 2022 at 04:15, John Fox <jfox at mcmaster.ca> wrote:
> >
> >> Dear Ben,
> >>
> >> On 2022-07-18 1:32 p.m., John Fox wrote:
> >>> Dear Ben,
> >>>
> >>> My apologies---I paid attention to the inessential part of your
> message,
> >>> which was the parametrization of the model rather than the
> >>> variance-covariance structure.
> >>>
> >>> This is a little awkward because of the LaTeX (and as far as I know, I
> >>> can't attach a PDF, but maybe you can paste this into a LaTeX editor):
> >>
> >> Rolf Turner pointed out to me that PDF attachments *are* acceptable, and
> >> so I've attached a PDF with the LaTeX part of my message.
> >>
> >> Best,
> >> John
> >>
> >>>
> >>> The model is $Y_{ij} = \alpha + \beta x_{ij} + \delta_{1i} +
> \delta_{2i}
> >>> x_{ij} + \varepsilon_{ij}$ for $i = 1, \ldots, n$ and $j = 1,2$, where
> >>> $x_{i1} = 1$ and $x_{i2} = 0$.
> >>>
> >>> The variances of the random effects are $V(\delta_{1i}) = \psi_1^2$ and
> >>> $V(\delta_{2i}) = \psi_2^2$, and their covariance is $C(\delta_{1i},
> >>> \delta_{2i}) = \psi_{12}$. The observation-level error variance is
> >>> $V(\varepsilon_{ij}) = \sigma^2$.
> >>>
> >>> Then the composite error is $\zeta_{ij} = \delta_{1i} + \delta_{2i}
> >>> x_{ij} + \varepsilon_{ij}$ with variance $V(\zeta_{ij}) =    \psi_1^2 +
> >>> x^2_{ij} \psi_2^2 + 2 x_{ij} \psi_{12} + \sigma^2$, which is
> >>> $V(\zeta_{i1}) = \psi_1^2 + \psi_2^2 + 2\psi_{12} + \sigma^2$ for $j =
> >>> 1$ and  $V(\zeta_{i2}) =   \psi_1^2  + \sigma^2$ for $j = 2$, and
> >>> covariance $C(\zeta_{i1}, \zeta_{i2}) = \psi_1^2 + \psi_2^2$.
> >>>
> >>> There are, as you say, 4 variance-covariance components, $\psi_1^2,
> >>> \psi_2^2, \psi_{12}, \sigma^2$, and just 3 variances and covariances
> >>> among the composite disturbances, $V(\zeta_{i1}), V(\zeta_{i2}),
> >>> C(\zeta_{i1}, \zeta_{i2})$, and so---as you and several others have
> >>> noted (but I missed)---the variance-covariance components are
> >>> underidentified.
> >>>
> >>> lmer(), but not lme(), appears to use a heuristic, counting the number
> >>> of random effects and observations, to detect underidentification. I
> >>> don't know whether that's bullet-proof, but it works in this case.
> Maybe
> >>> Ben Bolker, who has already responded, can comment further.
> >>>
> >>> Best,
> >>>    John
> >>>
> >>> John Fox, Professor Emeritus
> >>> McMaster University
> >>> Hamilton, Ontario, Canada
> >>> web: https://socialsciences.mcmaster.ca/jfox/
> >>>
> >>> On 2022-07-18 6:39 a.m., ben pelzer wrote:
> >>>> Dear John,
> >>>>
> >>>> Thank you for answering my question and your nice example with the
> >>>> alternative model formulations!!. But still I'm in doubt about the
> >>>> results. The fact that there are only three observed (co)variances
> >>>> which are being reproduced by four parameters estimates of lme leaves
> >>>> me confused. Actually, I would think that there is no unique solution
> >>>> without some constraint being applied. But I could not find something
> >>>> about such a constraint in lme documentation. The random effects of t1
> >>>> and t2, or of the intercept and t2 in your alternative model, should
> >>>> be sufficient to reproduce the observed (co)variances, so the residual
> >>>> variance is "unnecassary". I guess that is the reason that lmer is not
> >>>> able to estimate the model.
> >>>>
> >>>> library(lme4)
> >>>> m3 <- lmer(y ~ 1+t2+(1+t2|person), data=da)
> >>>>
> >>>> Error: number of observations (=20) <= number of random effects (=20)
> >>>> for term (1 + t2 | person); the random-effects parameters and the
> >>>> residual variance (or scale parameter) are probably unidentifiable
> >>>>
> >>>>
> >>>> It's interesting to notice that the two model specifications (t1+t2
> >>>> and 1+t2) lead to different residual variances estimated by lme. What
> >>>> do these residual variances mean? And of course also: what do the
> >>>> random effect variances estimated by both model formulations actually
> >>>> mean or stand for? Do you have any ideas? Kind regards,
> >>>>
> >>>> Ben.
> >>>>
> >>>> On Sat, 16 Jul 2022 at 16:50, John Fox <jfox at mcmaster.ca
> >>>> <mailto:jfox at mcmaster.ca>> wrote:
> >>>>
> >>>>      Dear Ben,
> >>>>
> >>>>      First, I'll make this into a reproducible example:
> >>>>
> >>>>        > set.seed(123)
> >>>>        > t1 <- c(rep(1, 10), rep(0, 10))
> >>>>        > t2 <- 1 - t1
> >>>>        > person <- rep(1:10, 2)
> >>>>        > y <- t2 + rnorm(20)
> >>>>        > da <- data.frame(y, t1, t2, person)
> >>>>
> >>>>        > library(nlme)
> >>>>
> >>>>      Then note that the random-effect specification 0 + t1 + t2 is
> >>>> simply a
> >>>>      reparametrization of 1 + t2 (i.e., 1 = t1 + t2), which produces
> the
> >>>>      same
> >>>>      fit to the data (same fixed effects, same restricted
> >> log-likelihood):
> >>>>
> >>>>        > m1 <- lme(y ~ 1 + t2, random = ~ 0 + t1 + t2 | person,
> data=da)
> >>>>        > m2 <- lme(y ~ 1 + t2, random = ~ 1 + t2 | person, data=da)
> >>>>        > m1
> >>>>      Linear mixed-effects model fit by REML
> >>>>          Data: da
> >>>>          Log-restricted-likelihood: -25.92726
> >>>>          Fixed: y ~ 1 + t2
> >>>>      (Intercept)          t2
> >>>>         0.07462564  1.13399632
> >>>>
> >>>>      Random effects:
> >>>>         Formula: ~0 + t1 + t2 | person
> >>>>         Structure: General positive-definite, Log-Cholesky
> >> parametrization
> >>>>                 StdDev    Corr
> >>>>      t1       0.8964136 t1
> >>>>      t2       0.9856215 0.647
> >>>>      Residual 0.3258015
> >>>>
> >>>>      Number of Observations: 20
> >>>>      Number of Groups: 10
> >>>>
> >>>>        > m2
> >>>>      Linear mixed-effects model fit by REML
> >>>>          Data: da
> >>>>          Log-restricted-likelihood: -25.92726
> >>>>          Fixed: y ~ 1 + t2
> >>>>      (Intercept)          t2
> >>>>         0.07462564  1.13399632
> >>>>
> >>>>      Random effects:
> >>>>         Formula: ~1 + t2 | person
> >>>>         Structure: General positive-definite, Log-Cholesky
> >> parametrization
> >>>>                    StdDev    Corr
> >>>>      (Intercept) 0.8787887 (Intr)
> >>>>      t2          0.7540826 -0.302
> >>>>      Residual    0.3707215
> >>>>
> >>>>      Number of Observations: 20
> >>>>      Number of Groups: 10
> >>>>
> >>>>      Finally, it's unnecessary to supply the intercept 1 in the model
> >>>>      formula
> >>>>      since the intercept is implied if it's not explicitly excluded:
> >>>>
> >>>>        > m3 <- lme(y ~ t2, random = ~ t2 | person, data=da)
> >>>>        > m3
> >>>>      Linear mixed-effects model fit by REML
> >>>>          Data: da
> >>>>          Log-restricted-likelihood: -25.92726
> >>>>          Fixed: y ~ t2
> >>>>      (Intercept)          t2
> >>>>         0.07462564  1.13399632
> >>>>
> >>>>      Random effects:
> >>>>         Formula: ~t2 | person
> >>>>         Structure: General positive-definite, Log-Cholesky
> >> parametrization
> >>>>                    StdDev    Corr
> >>>>      (Intercept) 0.8787887 (Intr)
> >>>>      t2          0.7540826 -0.302
> >>>>      Residual    0.3707215
> >>>>
> >>>>      Number of Observations: 20
> >>>>      Number of Groups: 10
> >>>>
> >>>>      I hope this helps,
> >>>>         John
> >>>>
> >>>>      On 2022-07-16 10:05 a.m., ben pelzer wrote:
> >>>>       > Sorry, my previous mailed contained another question which is
> >>>>      irrelevant...
> >>>>       > I deleted that now.
> >>>>       >
> >>>>       >
> >>>>       > Hi all,
> >>>>       >
> >>>>       > I have a question about results from lme of package nlme.
> >>>>       >
> >>>>       > Suppose the data consists of repeated measures at two fixed
> time
> >>>>      points.
> >>>>       >
> >>>>       > I used the following equation:
> >>>>       >
> >>>>       >
> >>>>       >
> >>>>       > Model1 <- lme ( y ~ 1+t2 , random = ~ 0 + t1+t2|person,
> data=da)
> >>>>       >
> >>>>       >
> >>>>       >
> >>>>       > y is the dependent, t1 and t2 are binary dummy variables,
> valued
> >>>>      0 or 1,
> >>>>       > indicating the time point.  Model1 is estimated without any
> >>>>      convergence
> >>>>       > problems and the reproduced (co)variances found with
> >>>>       >
> >>>>       >
> >>>>       >
> >>>>       > getVarCov(Model1, type=?marginal?, indivual=?1?)
> >>>>       >
> >>>>       >
> >>>>       >
> >>>>       > are identical to the observed (co)variances.
> >>>>       >
> >>>>       >
> >>>>       > My question is:  how can lme estimate 4 (co)variances with
> only 3
> >>>>      known
> >>>>       > (co)variances?
> >>>>       >
> >>>>       >
> >>>>       >
> >>>>       > The 4 estimates concern:
> >>>>       >
> >>>>       > -          std. deviation of the random effect of dummy t1
> >>>>       >
> >>>>       > -          std. deviation of the random effect of dummy t2
> >>>>       >
> >>>>       > -          covariance of the random effects of the dummies t1
> and
> >>>>      t2 t1
> >>>>       >
> >>>>       > -          residual std. error
> >>>>       >
> >>>>       >
> >>>>       >
> >>>>       > Related to the question above: how can the variances of the
> >>>>      random effects
> >>>>       > and the residual std. error be interpreted?
> >>>>       >
> >>>>       >
> >>>>       >
> >>>>       > Thanks for any help,
> >>>>       >
> >>>>       >
> >>>>       >
> >>>>       > Ben.
> >>>>       >
> >>>>       >       [[alternative HTML version deleted]]
> >>>>       >
> >>>>       > _______________________________________________
> >>>>       > R-sig-mixed-models at r-project.org
> >>>>      <mailto:R-sig-mixed-models at r-project.org> mailing list
> >>>>       > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >>>>      --     John Fox, Professor Emeritus
> >>>>      McMaster University
> >>>>      Hamilton, Ontario, Canada
> >>>>      web: https://socialsciences.mcmaster.ca/jfox/
> >>>>      <https://socialsciences.mcmaster.ca/jfox/>
> >>>>
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> --
> >> John Fox, Professor Emeritus
> >> McMaster University
> >> Hamilton, Ontario, Canada
> >> web: https://socialsciences.mcmaster.ca/jfox/
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> --
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> web: https://socialsciences.mcmaster.ca/jfox/
>
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Thu Jul 21 18:03:32 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 21 Jul 2022 12:03:32 -0400
Subject: [R-sig-ME] [EXT] Re: Choice of distribution for random effects
In-Reply-To: <ae0f8c6a-05e5-4cdf-9000-4705b1091e18@Spark>
References: <CAH_7VOmFG=iwiwPdBR6Loj9FXeic41UQ-aBUg0a3b6qE_eh-gQ@mail.gmail.com>
 <fc0fdf63-fa89-44da-8739-9ec115b42e4a@Spark>
 <CAH_7VOkBvC56rWewTLvQggDWu2EdKGn+ZzKyuE+O2z4mgNZ-zw@mail.gmail.com>
 <bb2aa1d1-8c58-408f-b701-e4e16bac1ba8@Spark>
 <297201de-5577-d813-f872-ef035b0f1b9b@gmail.com>
 <CAH_7VOnnOJPu9+fwr6pA2Z4nGmmw5x_82CSsDqirfBMP0tn_Vw@mail.gmail.com>
 <707277e8-f6c9-4606-b017-72fd05bb22f3@Spark>
 <CAH_7VOkMyLNVnMyuABvJQaRraKyCfFiErq+XQ0NxwyKpnw-MHw@mail.gmail.com>
 <ae0f8c6a-05e5-4cdf-9000-4705b1091e18@Spark>
Message-ID: <13d0fd40-4444-24a3-f931-52d6b21ef1a8@gmail.com>

   I want to clarify one tiny thing.

   The family typically specifies the *link function* as well as the 
conditional distribution, although this is often done by default (e.g. 
poisson -> log, binomial -> logit/log-odds).  The link function 
specifies the scale on which the data are fitted, so although the random 
effects are always Gaussian *on the scale of the linear predictor* 
(i.e., the transformed scale), they vary on the scale of the data.  If 
the distribution of group-level intercepts is Gaussian on the log scale, 
then it's log-Normal on the data (count) scale.


On 2022-07-20 11:36 p.m., Andrew Robinson wrote:
> That is correct.
> 
> Cheers,
> 
> Andrew
> 
> --
> Andrew Robinson
> Chief Executive Officer, CEBRA and Professor of Biosecurity,
> School/s of BioSciences and Mathematics & Statistics
> University of Melbourne, VIC 3010 Australia
> Tel: (+61) 0403 138 955
> Email: apro at unimelb.edu.au
> Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/
> 
> I acknowledge the Traditional Owners of the land I inhabit, and pay my respects to their Elders.
> On 21 Jul 2022, 1:04 PM +1000, J.D. Haltigan <jhaltiga at gmail.com>, wrote:
> This cross-validated post seemed helpful and aligned with everything
> previously mentioned here, and I wanted to share.
> https://stats.stackexchange.com/questions/190763/how-to-decide-which-glm-family-to-use
> 
> Thanks for all of your insights as this is quite a deep dive for me.
> 
> To be sure: in glmer, when one specifies the GLM family, that then applies
> to both fixed & random effects, correct? In other words, there is no way to
> separately specify a distribution for the random effects in glmer? I know I
> asked this question to Ben on the lme4 Git, but I wanted to confirm again.
> 
> JD
> 
> On Wed, Jul 20, 2022 at 8:35 PM Andrew Robinson <apro at unimelb.edu.au> wrote:
> 
> Ben is correct that the traditional alignment of certain link functions
> with certain members of the exponential family (the so-called 'canonical'
> links) are merely for analytical convenience and have no statistical
> justification.
> 
> Canonical link functions exercise an unhealthy influence on statistical
> practice, IMO. OTOH, there are circumstances in which they may afford
> parameter estimates that are easier to interpret.
> 
> I'm not familiar with hglm but I suspect you may need to use the log-link
> function for the random effects in order to get something like the glmer
> output.
> 
> Cheers,
> 
> Andrew
> 
> --
> Andrew Robinson
> Chief Executive Officer, CEBRA and Professor of Biosecurity,
> School/s of BioSciences and Mathematics & Statistics
> University of Melbourne, VIC 3010 Australia
> Tel: (+61) 0403 138 955
> Email: apro at unimelb.edu.au
> Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/
> 
> I acknowledge the Traditional Owners of the land I inhabit, and pay my
> respects to their Elders.
> On 21 Jul 2022, 10:24 AM +1000, J.D. Haltigan <jhaltiga at gmail.com>, wrote:
> 
> Thanks, Ben. For example, here is a comparison of glmer & HGLM using
> Guassian random effects for HGLM as suggested by Andrew. The magnitude of
> the point estimates are about the same, but the nominal significance for
> 'treatment' is only significant when considering the Gaussian random
> effects from lmer.
> 
> NB: In the project I am working on, the point is to show sensitivity of
> results to different parameterizations of models. I understand the point
> estimate magnitudes are about the same, but that is less relevant to this
> exercise.
> 
> *lme4_5_B = glmer(posXsymp~ treatment+proper_mask_base+prop_resp_ill_base_2
> + pairID + (1 | union), family = "poisson", nAGQ=0, data = bdata.raw3)#lme4
> package using glmer*
> 
> summary(lme4_5_B)
> 
> Generalized linear mixed model fit by maximum likelihood (Adaptive
> Gauss-Hermite Quadrature, nAGQ = 0) ['glmerMod']
> Family: poisson ( log )
> Formula: posXsymp ~ treatment + proper_mask_base + prop_resp_ill_base_2 +
> pairID + (1 | union)
> Data: bdata.raw3
> 
> AIC BIC logLik deviance df.resid
> 25054.5 27939.7 -12254.2 24508.5 287075
> 
> Scaled residuals:
> Min 1Q Median 3Q Max
> -0.214597 -0.100237 -0.078562 -0.054499 40.646525
> 
> Random effects:
> Groups Name Variance Std.Dev.
> union (Intercept) 0.007269442 0.08526102
> Number of obs: 287348, groups: union, 538
> 
> Fixed effects:
> Estimate Std. Error z value
> Pr(>|z|)
> (Intercept) -5.987724526 0.581280589 -10.30092 <
> 0.000000000000000222 ***
> treatment -0.094657198 0.044546951 -2.12489
> 0.03359612 *
> 
> 
> ***********************************************************************************************************************************************************************************************************************************
> 
> *HGLM2_5_Test = hglm2(posXsymp~
> treatment+proper_mask_base+prop_resp_ill_base_2 + pairID + (1 | union),
> family =poisson (link = log), rand.family =gaussian(link=identity),
> data = bdata.raw3)#HGLM package using hglm2*
> 
> summary(HGLM2_5_Test)
> 
> Call:
> hglm2.formula(meanmodel = posXsymp ~ treatment + proper_mask_base +
> prop_resp_ill_base_2 + pairID + (1 | union), data = bdata.raw3,
> family = poisson(link = log), rand.family = gaussian(link = identity))
> 
> ----------
> MEAN MODEL
> ----------
> 
> Summary of the fixed effects estimates:
> 
> Estimate Std. Error t-value Pr(>|t|)
> (Intercept) -6.02638 1.09414 -5.508 0.0000000364 ***
> treatment -0.02977 0.13624 -0.218 0.8271
> 
> On Wed, Jul 20, 2022 at 10:42 AM Ben Bolker <bbolker at gmail.com> wrote:
> 
> I believe that there are some mathematically natural pairings (i.e. a
> Gamma random effect + a Poisson response, a Beta-distributed random
> effect + a binomial response), but I don't know if there's much
> theoretical justification other than analytical convenience.
> 
> (If you have a categorical response then the natural random effect
> would be Dirichlet, i.e. a Dirichlet-multinomial marginal distribution,
> but do you really want to go down that rabbit hole?)
> 
> I strongly second Andrew's recommendation to check that the
> difference is not a difference between packages/estimation procedures.
> 
> On 2022-07-20 5:26 a.m., Andrew Robinson wrote:
> 
> You should really also verify that the hglm is doing what you expect by
> 
> fitting with Gaussian random effects.
> 
> 
> The random effects in glmer are Gaussian. The effects enter the model
> 
> via the linear predictor, which is then translated to the mean function of
> the chosen distribution of the response variable via the link function (NB
> this is a conceptual explanation, not an algorithmic one).
> 
> 
> Cheers,
> 
> Andrew
> On 20 Jul 2022, 6:40 PM +1000, J.D. Haltigan <jhaltiga at gmail.com>,
> 
> wrote:
> 
> External email: Please exercise caution
> 
> ________________________________
> Thanks, I will inspect the BLUPS.
> 
> Re: choice of distribution, what I meant was, for example, if my fixed
> 
> effects family is estimated using a Poisson model, does that inform the
> choice for random effects as well? (i.e., why would one invoke a gaussian
> distribution for random effects if the response variable is, say,
> categorical, or a count?)
> 
> 
> On Wed, Jul 20, 2022 at 3:40 AM Andrew Robinson <apro at unimelb.edu.au
> 
> <mailto:apro at unimelb.edu.au>> wrote:
> 
> You can use a qq-plot of the BLUPS to guide that decision.
> 
> The difference might also be due to something else, though. Have you
> 
> tried the call to hglm2 with a gaussian random effects family? Does it
> give the same output as the glmer?
> 
> 
> For: does the choice of distribution for the fixed effects portion of
> 
> the model inform the choice for the random effects? I?m not sure what you
> mean - do you mean the exponential family for the response variable?
> 
> 
> 
> Cheers,
> 
> Andrew
> 
> --
> Andrew Robinson
> Chief Executive Officer, CEBRA and Professor of Biosecurity,
> School/s of BioSciences and Mathematics & Statistics
> University of Melbourne, VIC 3010 Australia
> Tel: (+61) 0403 138 955
> Email: apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>
> Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/
> 
> I acknowledge the Traditional Owners of the land I inhabit, and pay my
> 
> respects to their Elders.
> 
> On 20 Jul 2022, 2:27 PM +1000, J.D. Haltigan <jhaltiga at gmail.com<mailto:
> 
> jhaltiga at gmail.com>>, wrote:
> 
> Hi:
> 
> Is there clear best practice or guidance when it comes to choosing the
> distribution of random effects where multiple choices exist (e.g.,
> gaussian, gamma, etc.)? I ask in the context of extending some analyses
> from an RCT in which the outcome is symptomatic seropositivity (so a
> count). The random effects I am modeling are village cluster [union]
> 
> (it's
> 
> a cluster randomized trial). I get different results (significance-wise)
> depending on whether I choose a normal or gamma distribution for the
> 
> random
> 
> effects.
> 
> The basic model (proportional outcome) is:
> 
> lme4_5_B = glmer(posXsymp~
> 
> treatment+proper_mask_base+prop_resp_ill_base_2
> 
> + pairID + (1 | union), family = "poisson", nAGQ=0, data =
> 
> bdata.raw3)#lme4
> 
> package using glmer
> 
> 
> HGLM2_5_A = hglm2(posXsymp~
> 
> treatment+proper_mask_base+prop_resp_ill_base_2
> 
> + pairID + (1 | union), family =poisson (link = log), rand.family
> =Gamma(link=log),
> data = bdata.raw3)#HGLM package using hglm2
> 
> Does, for example, the choice of distribution for the fixed effects
> 
> portion
> 
> of the model inform the choice for the random effects?
> 
> Thank you for any insights.
> 
> Best regards,
> J.D.
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
> 
> mailing list
> 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<
> 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> 
> 
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> --
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> (Acting) Graduate chair, Mathematics & Statistics
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics


From @pro @end|ng |rom un|me|b@edu@@u  Thu Jul 21 22:17:54 2022
From: @pro @end|ng |rom un|me|b@edu@@u (Andrew Robinson)
Date: Thu, 21 Jul 2022 20:17:54 +0000
Subject: [R-sig-ME] [EXT] Re: Choice of distribution for random effects
In-Reply-To: <13d0fd40-4444-24a3-f931-52d6b21ef1a8@gmail.com>
References: <CAH_7VOmFG=iwiwPdBR6Loj9FXeic41UQ-aBUg0a3b6qE_eh-gQ@mail.gmail.com>
 <fc0fdf63-fa89-44da-8739-9ec115b42e4a@Spark>
 <CAH_7VOkBvC56rWewTLvQggDWu2EdKGn+ZzKyuE+O2z4mgNZ-zw@mail.gmail.com>
 <bb2aa1d1-8c58-408f-b701-e4e16bac1ba8@Spark>
 <297201de-5577-d813-f872-ef035b0f1b9b@gmail.com>
 <CAH_7VOnnOJPu9+fwr6pA2Z4nGmmw5x_82CSsDqirfBMP0tn_Vw@mail.gmail.com>
 <707277e8-f6c9-4606-b017-72fd05bb22f3@Spark>
 <CAH_7VOkMyLNVnMyuABvJQaRraKyCfFiErq+XQ0NxwyKpnw-MHw@mail.gmail.com>
 <ae0f8c6a-05e5-4cdf-9000-4705b1091e18@Spark>
 <13d0fd40-4444-24a3-f931-52d6b21ef1a8@gmail.com>
Message-ID: <7b42cbef-11b3-4ce3-bc74-9bb4efac8697@Spark>

And, with my apologies for being fastidious, as you say the family typically specifies the link function *in the software*, selecting the (so-called) canonical link.

That doesn?t make it the right link function for any given modeling exercise. See, e.g., https://aip.scitation.org/doi/pdf/10.1063/1.5139815, and particularly Figure 1.

As Joe Hilbe and I wrote, it is not clear that there is any statistical benefit in the canonization of a particular link function for each family.

Cheers,

Andrew
On 22 Jul 2022, 2:04 AM +1000, Ben Bolker <bbolker at gmail.com>, wrote:
I want to clarify one tiny thing.

The family typically specifies the *link function* as well as the
conditional distribution, although this is often done by default (e.g.
poisson -> log, binomial -> logit/log-odds). The link function
specifies the scale on which the data are fitted, so although the random
effects are always Gaussian *on the scale of the linear predictor*
(i.e., the transformed scale), they vary on the scale of the data. If
the distribution of group-level intercepts is Gaussian on the log scale,
then it's log-Normal on the data (count) scale.


On 2022-07-20 11:36 p.m., Andrew Robinson wrote:
That is correct.

Cheers,

Andrew

--
Andrew Robinson
Chief Executive Officer, CEBRA and Professor of Biosecurity,
School/s of BioSciences and Mathematics & Statistics
University of Melbourne, VIC 3010 Australia
Tel: (+61) 0403 138 955
Email: apro at unimelb.edu.au
Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/

I acknowledge the Traditional Owners of the land I inhabit, and pay my respects to their Elders.
On 21 Jul 2022, 1:04 PM +1000, J.D. Haltigan <jhaltiga at gmail.com>, wrote:
This cross-validated post seemed helpful and aligned with everything
previously mentioned here, and I wanted to share.
https://stats.stackexchange.com/questions/190763/how-to-decide-which-glm-family-to-use

Thanks for all of your insights as this is quite a deep dive for me.

To be sure: in glmer, when one specifies the GLM family, that then applies
to both fixed & random effects, correct? In other words, there is no way to
separately specify a distribution for the random effects in glmer? I know I
asked this question to Ben on the lme4 Git, but I wanted to confirm again.

JD

On Wed, Jul 20, 2022 at 8:35 PM Andrew Robinson <apro at unimelb.edu.au> wrote:

Ben is correct that the traditional alignment of certain link functions
with certain members of the exponential family (the so-called 'canonical'
links) are merely for analytical convenience and have no statistical
justification.

Canonical link functions exercise an unhealthy influence on statistical
practice, IMO. OTOH, there are circumstances in which they may afford
parameter estimates that are easier to interpret.

I'm not familiar with hglm but I suspect you may need to use the log-link
function for the random effects in order to get something like the glmer
output.

Cheers,

Andrew

--
Andrew Robinson
Chief Executive Officer, CEBRA and Professor of Biosecurity,
School/s of BioSciences and Mathematics & Statistics
University of Melbourne, VIC 3010 Australia
Tel: (+61) 0403 138 955
Email: apro at unimelb.edu.au
Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/

I acknowledge the Traditional Owners of the land I inhabit, and pay my
respects to their Elders.
On 21 Jul 2022, 10:24 AM +1000, J.D. Haltigan <jhaltiga at gmail.com>, wrote:

Thanks, Ben. For example, here is a comparison of glmer & HGLM using
Guassian random effects for HGLM as suggested by Andrew. The magnitude of
the point estimates are about the same, but the nominal significance for
'treatment' is only significant when considering the Gaussian random
effects from lmer.

NB: In the project I am working on, the point is to show sensitivity of
results to different parameterizations of models. I understand the point
estimate magnitudes are about the same, but that is less relevant to this
exercise.

*lme4_5_B = glmer(posXsymp~ treatment+proper_mask_base+prop_resp_ill_base_2
+ pairID + (1 | union), family = "poisson", nAGQ=0, data = bdata.raw3)#lme4
package using glmer*

summary(lme4_5_B)

Generalized linear mixed model fit by maximum likelihood (Adaptive
Gauss-Hermite Quadrature, nAGQ = 0) ['glmerMod']
Family: poisson ( log )
Formula: posXsymp ~ treatment + proper_mask_base + prop_resp_ill_base_2 +
pairID + (1 | union)
Data: bdata.raw3

AIC BIC logLik deviance df.resid
25054.5 27939.7 -12254.2 24508.5 287075

Scaled residuals:
Min 1Q Median 3Q Max
-0.214597 -0.100237 -0.078562 -0.054499 40.646525

Random effects:
Groups Name Variance Std.Dev.
union (Intercept) 0.007269442 0.08526102
Number of obs: 287348, groups: union, 538

Fixed effects:
Estimate Std. Error z value
Pr(>|z|)
(Intercept) -5.987724526 0.581280589 -10.30092 <
0.000000000000000222 ***
treatment -0.094657198 0.044546951 -2.12489
0.03359612 *


***********************************************************************************************************************************************************************************************************************************

*HGLM2_5_Test = hglm2(posXsymp~
treatment+proper_mask_base+prop_resp_ill_base_2 + pairID + (1 | union),
family =poisson (link = log), rand.family =gaussian(link=identity),
data = bdata.raw3)#HGLM package using hglm2*

summary(HGLM2_5_Test)

Call:
hglm2.formula(meanmodel = posXsymp ~ treatment + proper_mask_base +
prop_resp_ill_base_2 + pairID + (1 | union), data = bdata.raw3,
family = poisson(link = log), rand.family = gaussian(link = identity))

----------
MEAN MODEL
----------

Summary of the fixed effects estimates:

Estimate Std. Error t-value Pr(>|t|)
(Intercept) -6.02638 1.09414 -5.508 0.0000000364 ***
treatment -0.02977 0.13624 -0.218 0.8271

On Wed, Jul 20, 2022 at 10:42 AM Ben Bolker <bbolker at gmail.com> wrote:

I believe that there are some mathematically natural pairings (i.e. a
Gamma random effect + a Poisson response, a Beta-distributed random
effect + a binomial response), but I don't know if there's much
theoretical justification other than analytical convenience.

(If you have a categorical response then the natural random effect
would be Dirichlet, i.e. a Dirichlet-multinomial marginal distribution,
but do you really want to go down that rabbit hole?)

I strongly second Andrew's recommendation to check that the
difference is not a difference between packages/estimation procedures.

On 2022-07-20 5:26 a.m., Andrew Robinson wrote:

You should really also verify that the hglm is doing what you expect by

fitting with Gaussian random effects.


The random effects in glmer are Gaussian. The effects enter the model

via the linear predictor, which is then translated to the mean function of
the chosen distribution of the response variable via the link function (NB
this is a conceptual explanation, not an algorithmic one).


Cheers,

Andrew
On 20 Jul 2022, 6:40 PM +1000, J.D. Haltigan <jhaltiga at gmail.com>,

wrote:

External email: Please exercise caution

________________________________
Thanks, I will inspect the BLUPS.

Re: choice of distribution, what I meant was, for example, if my fixed

effects family is estimated using a Poisson model, does that inform the
choice for random effects as well? (i.e., why would one invoke a gaussian
distribution for random effects if the response variable is, say,
categorical, or a count?)


On Wed, Jul 20, 2022 at 3:40 AM Andrew Robinson <apro at unimelb.edu.au

<mailto:apro at unimelb.edu.au>> wrote:

You can use a qq-plot of the BLUPS to guide that decision.

The difference might also be due to something else, though. Have you

tried the call to hglm2 with a gaussian random effects family? Does it
give the same output as the glmer?


For: does the choice of distribution for the fixed effects portion of

the model inform the choice for the random effects? I?m not sure what you
mean - do you mean the exponential family for the response variable?



Cheers,

Andrew

--
Andrew Robinson
Chief Executive Officer, CEBRA and Professor of Biosecurity,
School/s of BioSciences and Mathematics & Statistics
University of Melbourne, VIC 3010 Australia
Tel: (+61) 0403 138 955
Email: apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>
Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/

I acknowledge the Traditional Owners of the land I inhabit, and pay my

respects to their Elders.

On 20 Jul 2022, 2:27 PM +1000, J.D. Haltigan <jhaltiga at gmail.com<mailto:

jhaltiga at gmail.com>>, wrote:

Hi:

Is there clear best practice or guidance when it comes to choosing the
distribution of random effects where multiple choices exist (e.g.,
gaussian, gamma, etc.)? I ask in the context of extending some analyses
from an RCT in which the outcome is symptomatic seropositivity (so a
count). The random effects I am modeling are village cluster [union]

(it's

a cluster randomized trial). I get different results (significance-wise)
depending on whether I choose a normal or gamma distribution for the

random

effects.

The basic model (proportional outcome) is:

lme4_5_B = glmer(posXsymp~

treatment+proper_mask_base+prop_resp_ill_base_2

+ pairID + (1 | union), family = "poisson", nAGQ=0, data =

bdata.raw3)#lme4

package using glmer


HGLM2_5_A = hglm2(posXsymp~

treatment+proper_mask_base+prop_resp_ill_base_2

+ pairID + (1 | union), family =poisson (link = log), rand.family
=Gamma(link=log),
data = bdata.raw3)#HGLM package using hglm2

Does, for example, the choice of distribution for the fixed effects

portion

of the model inform the choice for the random effects?

Thank you for any insights.

Best regards,
J.D.

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>

mailing list

https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<

https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>



[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


--
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From jh@|t|g@ @end|ng |rom gm@||@com  Thu Jul 21 23:45:01 2022
From: jh@|t|g@ @end|ng |rom gm@||@com (J.D. Haltigan)
Date: Thu, 21 Jul 2022 17:45:01 -0400
Subject: [R-sig-ME] [EXT] Re: Choice of distribution for random effects
In-Reply-To: <7b42cbef-11b3-4ce3-bc74-9bb4efac8697@Spark>
References: <CAH_7VOmFG=iwiwPdBR6Loj9FXeic41UQ-aBUg0a3b6qE_eh-gQ@mail.gmail.com>
 <fc0fdf63-fa89-44da-8739-9ec115b42e4a@Spark>
 <CAH_7VOkBvC56rWewTLvQggDWu2EdKGn+ZzKyuE+O2z4mgNZ-zw@mail.gmail.com>
 <bb2aa1d1-8c58-408f-b701-e4e16bac1ba8@Spark>
 <297201de-5577-d813-f872-ef035b0f1b9b@gmail.com>
 <CAH_7VOnnOJPu9+fwr6pA2Z4nGmmw5x_82CSsDqirfBMP0tn_Vw@mail.gmail.com>
 <707277e8-f6c9-4606-b017-72fd05bb22f3@Spark>
 <CAH_7VOkMyLNVnMyuABvJQaRraKyCfFiErq+XQ0NxwyKpnw-MHw@mail.gmail.com>
 <ae0f8c6a-05e5-4cdf-9000-4705b1091e18@Spark>
 <13d0fd40-4444-24a3-f931-52d6b21ef1a8@gmail.com>
 <7b42cbef-11b3-4ce3-bc74-9bb4efac8697@Spark>
Message-ID: <CAH_7VOn0nM8Zindz0b_zceXzQ-Yt7szx3b=zDx1C8otMFwiqmw@mail.gmail.com>

Thanks for this continued deep dive as it is very instructive for me. I am
currently also reading the Wood GAM book which is very helpful.

As an aside, and perhaps relevant to the link discourse, in the current
project I am working on, I fit an lmer with:

***lme4_1_B = lmer(posXsymp~treatment+proper_mask_base+prop_resp_ill_base_2
+ pairID + (1 | union), data = bdata.raw1)#lme4 package***
which converges and provides results that are sensible (compared to models
that have been run using fixed effects only).

However, when I try to use HGLM to fit this model, it does not want to
cooperate and I am wondering why. If I specify the HGLM as should be the
case for linear models with family = Guassian, as:

***HGLM2_1_A = hglm2(posXsymp~
treatment+proper_mask_base+prop_resp_ill_base_2 + pairID + (1 | union),
family=gaussian(link=identity),
                  rand.family=Beta(link=logit), maxit = 100, data =
bdata.raw1)#HGLM package using hglm2***

I get: Error in glm.fit(x = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1,  :
  NA/NaN/Inf in 'x'
In addition: Warning message:
In hglm.default(X = X, y = Y, Z = Z, family = family, rand.family =
rand.family,  :
  Residuals numerically 0 are replaced by 1e-8
>

I am wondering if this is b/c "pairID" is a factor variable. I simply don't
understand why lmer would fit this but HGLM returns that error.

On Thu, Jul 21, 2022 at 4:18 PM Andrew Robinson <apro at unimelb.edu.au> wrote:

> And, with my apologies for being fastidious, as you say the family
> typically specifies the link function *in the software*, selecting the
> (so-called) canonical link.
>
> That doesn?t make it the right link function for any given modeling
> exercise. See, e.g., https://aip.scitation.org/doi/pdf/10.1063/1.5139815,
> and particularly Figure 1.
>
> As Joe Hilbe and I wrote, it is not clear that there is any statistical
> benefit in the canonization of a particular link function for each family.
>
> Cheers,
>
> Andrew
> On 22 Jul 2022, 2:04 AM +1000, Ben Bolker <bbolker at gmail.com>, wrote:
> I want to clarify one tiny thing.
>
> The family typically specifies the *link function* as well as the
> conditional distribution, although this is often done by default (e.g.
> poisson -> log, binomial -> logit/log-odds). The link function
> specifies the scale on which the data are fitted, so although the random
> effects are always Gaussian *on the scale of the linear predictor*
> (i.e., the transformed scale), they vary on the scale of the data. If
> the distribution of group-level intercepts is Gaussian on the log scale,
> then it's log-Normal on the data (count) scale.
>
>
> On 2022-07-20 11:36 p.m., Andrew Robinson wrote:
> That is correct.
>
> Cheers,
>
> Andrew
>
> --
> Andrew Robinson
> Chief Executive Officer, CEBRA and Professor of Biosecurity,
> School/s of BioSciences and Mathematics & Statistics
> University of Melbourne, VIC 3010 Australia
> Tel: (+61) 0403 138 955
> Email: apro at unimelb.edu.au
> Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/
>
> I acknowledge the Traditional Owners of the land I inhabit, and pay my
> respects to their Elders.
> On 21 Jul 2022, 1:04 PM +1000, J.D. Haltigan <jhaltiga at gmail.com>, wrote:
> This cross-validated post seemed helpful and aligned with everything
> previously mentioned here, and I wanted to share.
>
> https://stats.stackexchange.com/questions/190763/how-to-decide-which-glm-family-to-use
>
> Thanks for all of your insights as this is quite a deep dive for me.
>
> To be sure: in glmer, when one specifies the GLM family, that then applies
> to both fixed & random effects, correct? In other words, there is no way to
> separately specify a distribution for the random effects in glmer? I know I
> asked this question to Ben on the lme4 Git, but I wanted to confirm again.
>
> JD
>
> On Wed, Jul 20, 2022 at 8:35 PM Andrew Robinson <apro at unimelb.edu.au>
> wrote:
>
> Ben is correct that the traditional alignment of certain link functions
> with certain members of the exponential family (the so-called 'canonical'
> links) are merely for analytical convenience and have no statistical
> justification.
>
> Canonical link functions exercise an unhealthy influence on statistical
> practice, IMO. OTOH, there are circumstances in which they may afford
> parameter estimates that are easier to interpret.
>
> I'm not familiar with hglm but I suspect you may need to use the log-link
> function for the random effects in order to get something like the glmer
> output.
>
> Cheers,
>
> Andrew
>
> --
> Andrew Robinson
> Chief Executive Officer, CEBRA and Professor of Biosecurity,
> School/s of BioSciences and Mathematics & Statistics
> University of Melbourne, VIC 3010 Australia
> Tel: (+61) 0403 138 955
> Email: apro at unimelb.edu.au
> Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/
>
> I acknowledge the Traditional Owners of the land I inhabit, and pay my
> respects to their Elders.
> On 21 Jul 2022, 10:24 AM +1000, J.D. Haltigan <jhaltiga at gmail.com>, wrote:
>
> Thanks, Ben. For example, here is a comparison of glmer & HGLM using
> Guassian random effects for HGLM as suggested by Andrew. The magnitude of
> the point estimates are about the same, but the nominal significance for
> 'treatment' is only significant when considering the Gaussian random
> effects from lmer.
>
> NB: In the project I am working on, the point is to show sensitivity of
> results to different parameterizations of models. I understand the point
> estimate magnitudes are about the same, but that is less relevant to this
> exercise.
>
> *lme4_5_B = glmer(posXsymp~ treatment+proper_mask_base+prop_resp_ill_base_2
> + pairID + (1 | union), family = "poisson", nAGQ=0, data = bdata.raw3)#lme4
> package using glmer*
>
> summary(lme4_5_B)
>
> Generalized linear mixed model fit by maximum likelihood (Adaptive
> Gauss-Hermite Quadrature, nAGQ = 0) ['glmerMod']
> Family: poisson ( log )
> Formula: posXsymp ~ treatment + proper_mask_base + prop_resp_ill_base_2 +
> pairID + (1 | union)
> Data: bdata.raw3
>
> AIC BIC logLik deviance df.resid
> 25054.5 27939.7 -12254.2 24508.5 287075
>
> Scaled residuals:
> Min 1Q Median 3Q Max
> -0.214597 -0.100237 -0.078562 -0.054499 40.646525
>
> Random effects:
> Groups Name Variance Std.Dev.
> union (Intercept) 0.007269442 0.08526102
> Number of obs: 287348, groups: union, 538
>
> Fixed effects:
> Estimate Std. Error z value
> Pr(>|z|)
> (Intercept) -5.987724526 0.581280589 -10.30092 <
> 0.000000000000000222 ***
> treatment -0.094657198 0.044546951 -2.12489
> 0.03359612 *
>
>
>
> ***********************************************************************************************************************************************************************************************************************************
>
> *HGLM2_5_Test = hglm2(posXsymp~
> treatment+proper_mask_base+prop_resp_ill_base_2 + pairID + (1 | union),
> family =poisson (link = log), rand.family =gaussian(link=identity),
> data = bdata.raw3)#HGLM package using hglm2*
>
> summary(HGLM2_5_Test)
>
> Call:
> hglm2.formula(meanmodel = posXsymp ~ treatment + proper_mask_base +
> prop_resp_ill_base_2 + pairID + (1 | union), data = bdata.raw3,
> family = poisson(link = log), rand.family = gaussian(link = identity))
>
> ----------
> MEAN MODEL
> ----------
>
> Summary of the fixed effects estimates:
>
> Estimate Std. Error t-value Pr(>|t|)
> (Intercept) -6.02638 1.09414 -5.508 0.0000000364 ***
> treatment -0.02977 0.13624 -0.218 0.8271
>
> On Wed, Jul 20, 2022 at 10:42 AM Ben Bolker <bbolker at gmail.com> wrote:
>
> I believe that there are some mathematically natural pairings (i.e. a
> Gamma random effect + a Poisson response, a Beta-distributed random
> effect + a binomial response), but I don't know if there's much
> theoretical justification other than analytical convenience.
>
> (If you have a categorical response then the natural random effect
> would be Dirichlet, i.e. a Dirichlet-multinomial marginal distribution,
> but do you really want to go down that rabbit hole?)
>
> I strongly second Andrew's recommendation to check that the
> difference is not a difference between packages/estimation procedures.
>
> On 2022-07-20 5:26 a.m., Andrew Robinson wrote:
>
> You should really also verify that the hglm is doing what you expect by
>
> fitting with Gaussian random effects.
>
>
> The random effects in glmer are Gaussian. The effects enter the model
>
> via the linear predictor, which is then translated to the mean function of
> the chosen distribution of the response variable via the link function (NB
> this is a conceptual explanation, not an algorithmic one).
>
>
> Cheers,
>
> Andrew
> On 20 Jul 2022, 6:40 PM +1000, J.D. Haltigan <jhaltiga at gmail.com>,
>
> wrote:
>
> External email: Please exercise caution
>
> ________________________________
> Thanks, I will inspect the BLUPS.
>
> Re: choice of distribution, what I meant was, for example, if my fixed
>
> effects family is estimated using a Poisson model, does that inform the
> choice for random effects as well? (i.e., why would one invoke a gaussian
> distribution for random effects if the response variable is, say,
> categorical, or a count?)
>
>
> On Wed, Jul 20, 2022 at 3:40 AM Andrew Robinson <apro at unimelb.edu.au
>
> <mailto:apro at unimelb.edu.au>> wrote:
>
> You can use a qq-plot of the BLUPS to guide that decision.
>
> The difference might also be due to something else, though. Have you
>
> tried the call to hglm2 with a gaussian random effects family? Does it
> give the same output as the glmer?
>
>
> For: does the choice of distribution for the fixed effects portion of
>
> the model inform the choice for the random effects? I?m not sure what you
> mean - do you mean the exponential family for the response variable?
>
>
>
> Cheers,
>
> Andrew
>
> --
> Andrew Robinson
> Chief Executive Officer, CEBRA and Professor of Biosecurity,
> School/s of BioSciences and Mathematics & Statistics
> University of Melbourne, VIC 3010 Australia
> Tel: (+61) 0403 138 955
> Email: apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>
> Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/
>
> I acknowledge the Traditional Owners of the land I inhabit, and pay my
>
> respects to their Elders.
>
> On 20 Jul 2022, 2:27 PM +1000, J.D. Haltigan <jhaltiga at gmail.com<mailto:
>
> jhaltiga at gmail.com>>, wrote:
>
> Hi:
>
> Is there clear best practice or guidance when it comes to choosing the
> distribution of random effects where multiple choices exist (e.g.,
> gaussian, gamma, etc.)? I ask in the context of extending some analyses
> from an RCT in which the outcome is symptomatic seropositivity (so a
> count). The random effects I am modeling are village cluster [union]
>
> (it's
>
> a cluster randomized trial). I get different results (significance-wise)
> depending on whether I choose a normal or gamma distribution for the
>
> random
>
> effects.
>
> The basic model (proportional outcome) is:
>
> lme4_5_B = glmer(posXsymp~
>
> treatment+proper_mask_base+prop_resp_ill_base_2
>
> + pairID + (1 | union), family = "poisson", nAGQ=0, data =
>
> bdata.raw3)#lme4
>
> package using glmer
>
>
> HGLM2_5_A = hglm2(posXsymp~
>
> treatment+proper_mask_base+prop_resp_ill_base_2
>
> + pairID + (1 | union), family =poisson (link = log), rand.family
> =Gamma(link=log),
> data = bdata.raw3)#HGLM package using hglm2
>
> Does, for example, the choice of distribution for the fixed effects
>
> portion
>
> of the model inform the choice for the random effects?
>
> Thank you for any insights.
>
> Best regards,
> J.D.
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
>
> mailing list
>
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<
>
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>
>
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> --
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> (Acting) Graduate chair, Mathematics & Statistics
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> (Acting) Graduate chair, Mathematics & Statistics
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From @pro @end|ng |rom un|me|b@edu@@u  Fri Jul 22 00:11:26 2022
From: @pro @end|ng |rom un|me|b@edu@@u (Andrew Robinson)
Date: Thu, 21 Jul 2022 22:11:26 +0000
Subject: [R-sig-ME] [EXT] Re: Choice of distribution for random effects
In-Reply-To: <CAH_7VOn0nM8Zindz0b_zceXzQ-Yt7szx3b=zDx1C8otMFwiqmw@mail.gmail.com>
References: <CAH_7VOmFG=iwiwPdBR6Loj9FXeic41UQ-aBUg0a3b6qE_eh-gQ@mail.gmail.com>
 <fc0fdf63-fa89-44da-8739-9ec115b42e4a@Spark>
 <CAH_7VOkBvC56rWewTLvQggDWu2EdKGn+ZzKyuE+O2z4mgNZ-zw@mail.gmail.com>
 <bb2aa1d1-8c58-408f-b701-e4e16bac1ba8@Spark>
 <297201de-5577-d813-f872-ef035b0f1b9b@gmail.com>
 <CAH_7VOnnOJPu9+fwr6pA2Z4nGmmw5x_82CSsDqirfBMP0tn_Vw@mail.gmail.com>
 <707277e8-f6c9-4606-b017-72fd05bb22f3@Spark>
 <CAH_7VOkMyLNVnMyuABvJQaRraKyCfFiErq+XQ0NxwyKpnw-MHw@mail.gmail.com>
 <ae0f8c6a-05e5-4cdf-9000-4705b1091e18@Spark>
 <13d0fd40-4444-24a3-f931-52d6b21ef1a8@gmail.com>
 <7b42cbef-11b3-4ce3-bc74-9bb4efac8697@Spark>
 <CAH_7VOn0nM8Zindz0b_zceXzQ-Yt7szx3b=zDx1C8otMFwiqmw@mail.gmail.com>
Message-ID: <a6c22b40-11df-46df-befa-2de4d5fe14d5@Spark>

As noted earlier, I?m not familiar with hglm, but a cursory glance suggests that those are not the same model.  You appear to have specified Beta distributed random effects in the call to hglm2.

Cheers,

Andrew

--
Andrew Robinson
Chief Executive Officer, CEBRA and Professor of Biosecurity,
School/s of BioSciences and Mathematics & Statistics
University of Melbourne, VIC 3010 Australia
Tel: (+61) 0403 138 955
Email: apro at unimelb.edu.au
Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/

I acknowledge the Traditional Owners of the land I inhabit, and pay my respects to their Elders.
On 22 Jul 2022, 7:45 AM +1000, J.D. Haltigan <jhaltiga at gmail.com>, wrote:
External email: Please exercise caution

________________________________
Thanks for this continued deep dive as it is very instructive for me. I am currently also reading the Wood GAM book which is very helpful.

As an aside, and perhaps relevant to the link discourse, in the current project I am working on, I fit an lmer with:

***lme4_1_B = lmer(posXsymp~treatment+proper_mask_base+prop_resp_ill_base_2 + pairID + (1 | union), data = bdata.raw1)#lme4 package***
which converges and provides results that are sensible (compared to models that have been run using fixed effects only).

However, when I try to use HGLM to fit this model, it does not want to cooperate and I am wondering why. If I specify the HGLM as should be the case for linear models with family = Guassian, as:

***HGLM2_1_A = hglm2(posXsymp~ treatment+proper_mask_base+prop_resp_ill_base_2 + pairID + (1 | union), family=gaussian(link=identity),
                  rand.family=Beta(link=logit), maxit = 100, data = bdata.raw1)#HGLM package using hglm2***

I get: Error in glm.fit(x = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  :
  NA/NaN/Inf in 'x'
In addition: Warning message:
In hglm.default(X = X, y = Y, Z = Z, family = family, rand.family = rand.family,  :
  Residuals numerically 0 are replaced by 1e-8
>

I am wondering if this is b/c "pairID" is a factor variable. I simply don't understand why lmer would fit this but HGLM returns that error.

On Thu, Jul 21, 2022 at 4:18 PM Andrew Robinson <apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>> wrote:
And, with my apologies for being fastidious, as you say the family typically specifies the link function *in the software*, selecting the (so-called) canonical link.

That doesn?t make it the right link function for any given modeling exercise. See, e.g., https://aip.scitation.org/doi/pdf/10.1063/1.5139815<https://aip.scitation.org/doi/pdf/10.1063/1.5139815>, and particularly Figure 1.

As Joe Hilbe and I wrote, it is not clear that there is any statistical benefit in the canonization of a particular link function for each family.

Cheers,

Andrew
On 22 Jul 2022, 2:04 AM +1000, Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com>>, wrote:
I want to clarify one tiny thing.

The family typically specifies the *link function* as well as the
conditional distribution, although this is often done by default (e.g.
poisson -> log, binomial -> logit/log-odds). The link function
specifies the scale on which the data are fitted, so although the random
effects are always Gaussian *on the scale of the linear predictor*
(i.e., the transformed scale), they vary on the scale of the data. If
the distribution of group-level intercepts is Gaussian on the log scale,
then it's log-Normal on the data (count) scale.


On 2022-07-20 11:36 p.m., Andrew Robinson wrote:
That is correct.

Cheers,

Andrew

--
Andrew Robinson
Chief Executive Officer, CEBRA and Professor of Biosecurity,
School/s of BioSciences and Mathematics & Statistics
University of Melbourne, VIC 3010 Australia
Tel: (+61) 0403 138 955
Email: apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>
Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/

I acknowledge the Traditional Owners of the land I inhabit, and pay my respects to their Elders.
On 21 Jul 2022, 1:04 PM +1000, J.D. Haltigan <jhaltiga at gmail.com<mailto:jhaltiga at gmail.com>>, wrote:
This cross-validated post seemed helpful and aligned with everything
previously mentioned here, and I wanted to share.
https://stats.stackexchange.com/questions/190763/how-to-decide-which-glm-family-to-use<https://stats.stackexchange.com/questions/190763/how-to-decide-which-glm-family-to-use>

Thanks for all of your insights as this is quite a deep dive for me.

To be sure: in glmer, when one specifies the GLM family, that then applies
to both fixed & random effects, correct? In other words, there is no way to
separately specify a distribution for the random effects in glmer? I know I
asked this question to Ben on the lme4 Git, but I wanted to confirm again.

JD

On Wed, Jul 20, 2022 at 8:35 PM Andrew Robinson <apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>> wrote:

Ben is correct that the traditional alignment of certain link functions
with certain members of the exponential family (the so-called 'canonical'
links) are merely for analytical convenience and have no statistical
justification.

Canonical link functions exercise an unhealthy influence on statistical
practice, IMO. OTOH, there are circumstances in which they may afford
parameter estimates that are easier to interpret.

I'm not familiar with hglm but I suspect you may need to use the log-link
function for the random effects in order to get something like the glmer
output.

Cheers,

Andrew

--
Andrew Robinson
Chief Executive Officer, CEBRA and Professor of Biosecurity,
School/s of BioSciences and Mathematics & Statistics
University of Melbourne, VIC 3010 Australia
Tel: (+61) 0403 138 955
Email: apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>
Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/

I acknowledge the Traditional Owners of the land I inhabit, and pay my
respects to their Elders.
On 21 Jul 2022, 10:24 AM +1000, J.D. Haltigan <jhaltiga at gmail.com<mailto:jhaltiga at gmail.com>>, wrote:

Thanks, Ben. For example, here is a comparison of glmer & HGLM using
Guassian random effects for HGLM as suggested by Andrew. The magnitude of
the point estimates are about the same, but the nominal significance for
'treatment' is only significant when considering the Gaussian random
effects from lmer.

NB: In the project I am working on, the point is to show sensitivity of
results to different parameterizations of models. I understand the point
estimate magnitudes are about the same, but that is less relevant to this
exercise.

*lme4_5_B = glmer(posXsymp~ treatment+proper_mask_base+prop_resp_ill_base_2
+ pairID + (1 | union), family = "poisson", nAGQ=0, data = bdata.raw3)#lme4
package using glmer*

summary(lme4_5_B)

Generalized linear mixed model fit by maximum likelihood (Adaptive
Gauss-Hermite Quadrature, nAGQ = 0) ['glmerMod']
Family: poisson ( log )
Formula: posXsymp ~ treatment + proper_mask_base + prop_resp_ill_base_2 +
pairID + (1 | union)
Data: bdata.raw3

AIC BIC logLik deviance df.resid
25054.5 27939.7 -12254.2 24508.5 287075

Scaled residuals:
Min 1Q Median 3Q Max
-0.214597 -0.100237 -0.078562 -0.054499 40.646525

Random effects:
Groups Name Variance Std.Dev.
union (Intercept) 0.007269442 0.08526102
Number of obs: 287348, groups: union, 538

Fixed effects:
Estimate Std. Error z value
Pr(>|z|)
(Intercept) -5.987724526 0.581280589 -10.30092 <
0.000000000000000222 ***
treatment -0.094657198 0.044546951 -2.12489
0.03359612 *


***********************************************************************************************************************************************************************************************************************************

*HGLM2_5_Test = hglm2(posXsymp~
treatment+proper_mask_base+prop_resp_ill_base_2 + pairID + (1 | union),
family =poisson (link = log), rand.family =gaussian(link=identity),
data = bdata.raw3)#HGLM package using hglm2*

summary(HGLM2_5_Test)

Call:
hglm2.formula(meanmodel = posXsymp ~ treatment + proper_mask_base +
prop_resp_ill_base_2 + pairID + (1 | union), data = bdata.raw3,
family = poisson(link = log), rand.family = gaussian(link = identity))

----------
MEAN MODEL
----------

Summary of the fixed effects estimates:

Estimate Std. Error t-value Pr(>|t|)
(Intercept) -6.02638 1.09414 -5.508 0.0000000364 ***
treatment -0.02977 0.13624 -0.218 0.8271

On Wed, Jul 20, 2022 at 10:42 AM Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com>> wrote:

I believe that there are some mathematically natural pairings (i.e. a
Gamma random effect + a Poisson response, a Beta-distributed random
effect + a binomial response), but I don't know if there's much
theoretical justification other than analytical convenience.

(If you have a categorical response then the natural random effect
would be Dirichlet, i.e. a Dirichlet-multinomial marginal distribution,
but do you really want to go down that rabbit hole?)

I strongly second Andrew's recommendation to check that the
difference is not a difference between packages/estimation procedures.

On 2022-07-20 5:26 a.m., Andrew Robinson wrote:

You should really also verify that the hglm is doing what you expect by

fitting with Gaussian random effects.


The random effects in glmer are Gaussian. The effects enter the model

via the linear predictor, which is then translated to the mean function of
the chosen distribution of the response variable via the link function (NB
this is a conceptual explanation, not an algorithmic one).


Cheers,

Andrew
On 20 Jul 2022, 6:40 PM +1000, J.D. Haltigan <jhaltiga at gmail.com<mailto:jhaltiga at gmail.com>>,

wrote:

External email: Please exercise caution

________________________________
Thanks, I will inspect the BLUPS.

Re: choice of distribution, what I meant was, for example, if my fixed

effects family is estimated using a Poisson model, does that inform the
choice for random effects as well? (i.e., why would one invoke a gaussian
distribution for random effects if the response variable is, say,
categorical, or a count?)


On Wed, Jul 20, 2022 at 3:40 AM Andrew Robinson <apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>

<mailto:apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>>> wrote:

You can use a qq-plot of the BLUPS to guide that decision.

The difference might also be due to something else, though. Have you

tried the call to hglm2 with a gaussian random effects family? Does it
give the same output as the glmer?


For: does the choice of distribution for the fixed effects portion of

the model inform the choice for the random effects? I?m not sure what you
mean - do you mean the exponential family for the response variable?



Cheers,

Andrew

--
Andrew Robinson
Chief Executive Officer, CEBRA and Professor of Biosecurity,
School/s of BioSciences and Mathematics & Statistics
University of Melbourne, VIC 3010 Australia
Tel: (+61) 0403 138 955
Email: apro at unimelb.edu.au<mailto:apro at unimelb.edu.au><mailto:apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>>
Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/

I acknowledge the Traditional Owners of the land I inhabit, and pay my

respects to their Elders.

On 20 Jul 2022, 2:27 PM +1000, J.D. Haltigan <jhaltiga at gmail.com<mailto:jhaltiga at gmail.com><mailto:

jhaltiga at gmail.com<mailto:jhaltiga at gmail.com>>>, wrote:

Hi:

Is there clear best practice or guidance when it comes to choosing the
distribution of random effects where multiple choices exist (e.g.,
gaussian, gamma, etc.)? I ask in the context of extending some analyses
from an RCT in which the outcome is symptomatic seropositivity (so a
count). The random effects I am modeling are village cluster [union]

(it's

a cluster randomized trial). I get different results (significance-wise)
depending on whether I choose a normal or gamma distribution for the

random

effects.

The basic model (proportional outcome) is:

lme4_5_B = glmer(posXsymp~

treatment+proper_mask_base+prop_resp_ill_base_2

+ pairID + (1 | union), family = "poisson", nAGQ=0, data =

bdata.raw3)#lme4

package using glmer


HGLM2_5_A = hglm2(posXsymp~

treatment+proper_mask_base+prop_resp_ill_base_2

+ pairID + (1 | union), family =poisson (link = log), rand.family
=Gamma(link=log),
data = bdata.raw3)#HGLM package using hglm2

Does, for example, the choice of distribution for the fixed effects

portion

of the model inform the choice for the random effects?

Thank you for any insights.

Best regards,
J.D.

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org><mailto:R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>>

mailing list

https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models><

https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>



[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>


--
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>


[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>



[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>


[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>

--
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>


        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>

	[[alternative HTML version deleted]]


From jh@|t|g@ @end|ng |rom gm@||@com  Fri Jul 22 00:36:03 2022
From: jh@|t|g@ @end|ng |rom gm@||@com (J.D. Haltigan)
Date: Thu, 21 Jul 2022 18:36:03 -0400
Subject: [R-sig-ME] [EXT] Re: Choice of distribution for random effects
In-Reply-To: <a6c22b40-11df-46df-befa-2de4d5fe14d5@Spark>
References: <CAH_7VOmFG=iwiwPdBR6Loj9FXeic41UQ-aBUg0a3b6qE_eh-gQ@mail.gmail.com>
 <fc0fdf63-fa89-44da-8739-9ec115b42e4a@Spark>
 <CAH_7VOkBvC56rWewTLvQggDWu2EdKGn+ZzKyuE+O2z4mgNZ-zw@mail.gmail.com>
 <bb2aa1d1-8c58-408f-b701-e4e16bac1ba8@Spark>
 <297201de-5577-d813-f872-ef035b0f1b9b@gmail.com>
 <CAH_7VOnnOJPu9+fwr6pA2Z4nGmmw5x_82CSsDqirfBMP0tn_Vw@mail.gmail.com>
 <707277e8-f6c9-4606-b017-72fd05bb22f3@Spark>
 <CAH_7VOkMyLNVnMyuABvJQaRraKyCfFiErq+XQ0NxwyKpnw-MHw@mail.gmail.com>
 <ae0f8c6a-05e5-4cdf-9000-4705b1091e18@Spark>
 <13d0fd40-4444-24a3-f931-52d6b21ef1a8@gmail.com>
 <7b42cbef-11b3-4ce3-bc74-9bb4efac8697@Spark>
 <CAH_7VOn0nM8Zindz0b_zceXzQ-Yt7szx3b=zDx1C8otMFwiqmw@mail.gmail.com>
 <a6c22b40-11df-46df-befa-2de4d5fe14d5@Spark>
Message-ID: <CAH_7VOn4eMMUmfJ-K2=EC0Jr92wCo8aSX62Cy9s=V8RCL32Lhg@mail.gmail.com>

Correct. The idea was to replicate the lmer *with the addition of a random
effects distribution* which is not possible in lmer (to see what numeric
differences in estimate effects might arise).

So, the fixed portion of the model, if I understand lmer correctly, should
be the same here. Whether I specify Beta or Gamma for the random effects
(in hglm2) yields the same error. I am wondering what might be the reason
for this.

At the risk of asking an elementary question here: When I add the random
effects specification for this model, I understand it as accounting for the
B/W cluster variance (union). In effect, by adding this random effects
component, I am saying that unions are *not* interchangeable and are drawn
from a universe of random draws of unions. I am borrowing a bit from the
parlance of Generalizability Theory, so apologies in advance if my language
is a bit cryptic.

JD

On Thu, Jul 21, 2022 at 6:11 PM Andrew Robinson <apro at unimelb.edu.au> wrote:

> As noted earlier, I?m not familiar with hglm, but a cursory glance
> suggests that those are not the same model.  You appear to have specified
> Beta distributed random effects in the call to hglm2.
>
> Cheers,
>
> Andrew
>
> --
> Andrew Robinson
> Chief Executive Officer, CEBRA and Professor of Biosecurity,
> School/s of BioSciences and Mathematics & Statistics
> University of Melbourne, VIC 3010 Australia
> Tel: (+61) 0403 138 955
> Email: apro at unimelb.edu.au
> Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/
>
> I acknowledge the Traditional Owners of the land I inhabit, and pay my
> respects to their Elders.
> On 22 Jul 2022, 7:45 AM +1000, J.D. Haltigan <jhaltiga at gmail.com>, wrote:
>
> *External email:* Please exercise caution
> ------------------------------
> Thanks for this continued deep dive as it is very instructive for me. I am
> currently also reading the Wood GAM book which is very helpful.
>
> As an aside, and perhaps relevant to the link discourse, in the current
> project I am working on, I fit an lmer with:
>
> ***lme4_1_B =
> lmer(posXsymp~treatment+proper_mask_base+prop_resp_ill_base_2 + pairID + (1
> | union), data = bdata.raw1)#lme4 package***
> which converges and provides results that are sensible (compared to models
> that have been run using fixed effects only).
>
> However, when I try to use HGLM to fit this model, it does not want to
> cooperate and I am wondering why. If I specify the HGLM as should be the
> case for linear models with family = Guassian, as:
>
> ***HGLM2_1_A = hglm2(posXsymp~
> treatment+proper_mask_base+prop_resp_ill_base_2 + pairID + (1 | union),
> family=gaussian(link=identity),
>                   rand.family=Beta(link=logit), maxit = 100, data =
> bdata.raw1)#HGLM package using hglm2***
>
> I get: Error in glm.fit(x = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1,  :
>   NA/NaN/Inf in 'x'
> In addition: Warning message:
> In hglm.default(X = X, y = Y, Z = Z, family = family, rand.family =
> rand.family,  :
>   Residuals numerically 0 are replaced by 1e-8
> >
>
> I am wondering if this is b/c "pairID" is a factor variable. I simply
> don't understand why lmer would fit this but HGLM returns that error.
>
> On Thu, Jul 21, 2022 at 4:18 PM Andrew Robinson <apro at unimelb.edu.au>
> wrote:
>
>> And, with my apologies for being fastidious, as you say the family
>> typically specifies the link function *in the software*, selecting the
>> (so-called) canonical link.
>>
>> That doesn?t make it the right link function for any given modeling
>> exercise. See, e.g., https://aip.scitation.org/doi/pdf/10.1063/1.5139815,
>> and particularly Figure 1.
>>
>> As Joe Hilbe and I wrote, it is not clear that there is any statistical
>> benefit in the canonization of a particular link function for each family.
>>
>> Cheers,
>>
>> Andrew
>> On 22 Jul 2022, 2:04 AM +1000, Ben Bolker <bbolker at gmail.com>, wrote:
>> I want to clarify one tiny thing.
>>
>> The family typically specifies the *link function* as well as the
>> conditional distribution, although this is often done by default (e.g.
>> poisson -> log, binomial -> logit/log-odds). The link function
>> specifies the scale on which the data are fitted, so although the random
>> effects are always Gaussian *on the scale of the linear predictor*
>> (i.e., the transformed scale), they vary on the scale of the data. If
>> the distribution of group-level intercepts is Gaussian on the log scale,
>> then it's log-Normal on the data (count) scale.
>>
>>
>> On 2022-07-20 11:36 p.m., Andrew Robinson wrote:
>> That is correct.
>>
>> Cheers,
>>
>> Andrew
>>
>> --
>> Andrew Robinson
>> Chief Executive Officer, CEBRA and Professor of Biosecurity,
>> School/s of BioSciences and Mathematics & Statistics
>> University of Melbourne, VIC 3010 Australia
>> Tel: (+61) 0403 138 955
>> Email: apro at unimelb.edu.au
>> Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/
>>
>> I acknowledge the Traditional Owners of the land I inhabit, and pay my
>> respects to their Elders.
>> On 21 Jul 2022, 1:04 PM +1000, J.D. Haltigan <jhaltiga at gmail.com>, wrote:
>> This cross-validated post seemed helpful and aligned with everything
>> previously mentioned here, and I wanted to share.
>>
>> https://stats.stackexchange.com/questions/190763/how-to-decide-which-glm-family-to-use
>>
>> Thanks for all of your insights as this is quite a deep dive for me.
>>
>> To be sure: in glmer, when one specifies the GLM family, that then applies
>> to both fixed & random effects, correct? In other words, there is no way
>> to
>> separately specify a distribution for the random effects in glmer? I know
>> I
>> asked this question to Ben on the lme4 Git, but I wanted to confirm again.
>>
>> JD
>>
>> On Wed, Jul 20, 2022 at 8:35 PM Andrew Robinson <apro at unimelb.edu.au>
>> wrote:
>>
>> Ben is correct that the traditional alignment of certain link functions
>> with certain members of the exponential family (the so-called 'canonical'
>> links) are merely for analytical convenience and have no statistical
>> justification.
>>
>> Canonical link functions exercise an unhealthy influence on statistical
>> practice, IMO. OTOH, there are circumstances in which they may afford
>> parameter estimates that are easier to interpret.
>>
>> I'm not familiar with hglm but I suspect you may need to use the log-link
>> function for the random effects in order to get something like the glmer
>> output.
>>
>> Cheers,
>>
>> Andrew
>>
>> --
>> Andrew Robinson
>> Chief Executive Officer, CEBRA and Professor of Biosecurity,
>> School/s of BioSciences and Mathematics & Statistics
>> University of Melbourne, VIC 3010 Australia
>> Tel: (+61) 0403 138 955
>> Email: apro at unimelb.edu.au
>> Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/
>>
>> I acknowledge the Traditional Owners of the land I inhabit, and pay my
>> respects to their Elders.
>> On 21 Jul 2022, 10:24 AM +1000, J.D. Haltigan <jhaltiga at gmail.com>,
>> wrote:
>>
>> Thanks, Ben. For example, here is a comparison of glmer & HGLM using
>> Guassian random effects for HGLM as suggested by Andrew. The magnitude of
>> the point estimates are about the same, but the nominal significance for
>> 'treatment' is only significant when considering the Gaussian random
>> effects from lmer.
>>
>> NB: In the project I am working on, the point is to show sensitivity of
>> results to different parameterizations of models. I understand the point
>> estimate magnitudes are about the same, but that is less relevant to this
>> exercise.
>>
>> *lme4_5_B = glmer(posXsymp~
>> treatment+proper_mask_base+prop_resp_ill_base_2
>> + pairID + (1 | union), family = "poisson", nAGQ=0, data =
>> bdata.raw3)#lme4
>> package using glmer*
>>
>> summary(lme4_5_B)
>>
>> Generalized linear mixed model fit by maximum likelihood (Adaptive
>> Gauss-Hermite Quadrature, nAGQ = 0) ['glmerMod']
>> Family: poisson ( log )
>> Formula: posXsymp ~ treatment + proper_mask_base + prop_resp_ill_base_2 +
>> pairID + (1 | union)
>> Data: bdata.raw3
>>
>> AIC BIC logLik deviance df.resid
>> 25054.5 27939.7 -12254.2 24508.5 287075
>>
>> Scaled residuals:
>> Min 1Q Median 3Q Max
>> -0.214597 -0.100237 -0.078562 -0.054499 40.646525
>>
>> Random effects:
>> Groups Name Variance Std.Dev.
>> union (Intercept) 0.007269442 0.08526102
>> Number of obs: 287348, groups: union, 538
>>
>> Fixed effects:
>> Estimate Std. Error z value
>> Pr(>|z|)
>> (Intercept) -5.987724526 0.581280589 -10.30092 <
>> 0.000000000000000222 ***
>> treatment -0.094657198 0.044546951 -2.12489
>> 0.03359612 *
>>
>>
>>
>> ***********************************************************************************************************************************************************************************************************************************
>>
>> *HGLM2_5_Test = hglm2(posXsymp~
>> treatment+proper_mask_base+prop_resp_ill_base_2 + pairID + (1 | union),
>> family =poisson (link = log), rand.family =gaussian(link=identity),
>> data = bdata.raw3)#HGLM package using hglm2*
>>
>> summary(HGLM2_5_Test)
>>
>> Call:
>> hglm2.formula(meanmodel = posXsymp ~ treatment + proper_mask_base +
>> prop_resp_ill_base_2 + pairID + (1 | union), data = bdata.raw3,
>> family = poisson(link = log), rand.family = gaussian(link = identity))
>>
>> ----------
>> MEAN MODEL
>> ----------
>>
>> Summary of the fixed effects estimates:
>>
>> Estimate Std. Error t-value Pr(>|t|)
>> (Intercept) -6.02638 1.09414 -5.508 0.0000000364 ***
>> treatment -0.02977 0.13624 -0.218 0.8271
>>
>> On Wed, Jul 20, 2022 at 10:42 AM Ben Bolker <bbolker at gmail.com> wrote:
>>
>> I believe that there are some mathematically natural pairings (i.e. a
>> Gamma random effect + a Poisson response, a Beta-distributed random
>> effect + a binomial response), but I don't know if there's much
>> theoretical justification other than analytical convenience.
>>
>> (If you have a categorical response then the natural random effect
>> would be Dirichlet, i.e. a Dirichlet-multinomial marginal distribution,
>> but do you really want to go down that rabbit hole?)
>>
>> I strongly second Andrew's recommendation to check that the
>> difference is not a difference between packages/estimation procedures.
>>
>> On 2022-07-20 5:26 a.m., Andrew Robinson wrote:
>>
>> You should really also verify that the hglm is doing what you expect by
>>
>> fitting with Gaussian random effects.
>>
>>
>> The random effects in glmer are Gaussian. The effects enter the model
>>
>> via the linear predictor, which is then translated to the mean function of
>> the chosen distribution of the response variable via the link function (NB
>> this is a conceptual explanation, not an algorithmic one).
>>
>>
>> Cheers,
>>
>> Andrew
>> On 20 Jul 2022, 6:40 PM +1000, J.D. Haltigan <jhaltiga at gmail.com>,
>>
>> wrote:
>>
>> External email: Please exercise caution
>>
>> ________________________________
>> Thanks, I will inspect the BLUPS.
>>
>> Re: choice of distribution, what I meant was, for example, if my fixed
>>
>> effects family is estimated using a Poisson model, does that inform the
>> choice for random effects as well? (i.e., why would one invoke a gaussian
>> distribution for random effects if the response variable is, say,
>> categorical, or a count?)
>>
>>
>> On Wed, Jul 20, 2022 at 3:40 AM Andrew Robinson <apro at unimelb.edu.au
>>
>> <mailto:apro at unimelb.edu.au>> wrote:
>>
>> You can use a qq-plot of the BLUPS to guide that decision.
>>
>> The difference might also be due to something else, though. Have you
>>
>> tried the call to hglm2 with a gaussian random effects family? Does it
>> give the same output as the glmer?
>>
>>
>> For: does the choice of distribution for the fixed effects portion of
>>
>> the model inform the choice for the random effects? I?m not sure what you
>> mean - do you mean the exponential family for the response variable?
>>
>>
>>
>> Cheers,
>>
>> Andrew
>>
>> --
>> Andrew Robinson
>> Chief Executive Officer, CEBRA and Professor of Biosecurity,
>> School/s of BioSciences and Mathematics & Statistics
>> University of Melbourne, VIC 3010 Australia
>> Tel: (+61) 0403 138 955
>> Email: apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>
>> Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/
>>
>> I acknowledge the Traditional Owners of the land I inhabit, and pay my
>>
>> respects to their Elders.
>>
>> On 20 Jul 2022, 2:27 PM +1000, J.D. Haltigan <jhaltiga at gmail.com<mailto:
>>
>> jhaltiga at gmail.com>>, wrote:
>>
>> Hi:
>>
>> Is there clear best practice or guidance when it comes to choosing the
>> distribution of random effects where multiple choices exist (e.g.,
>> gaussian, gamma, etc.)? I ask in the context of extending some analyses
>> from an RCT in which the outcome is symptomatic seropositivity (so a
>> count). The random effects I am modeling are village cluster [union]
>>
>> (it's
>>
>> a cluster randomized trial). I get different results (significance-wise)
>> depending on whether I choose a normal or gamma distribution for the
>>
>> random
>>
>> effects.
>>
>> The basic model (proportional outcome) is:
>>
>> lme4_5_B = glmer(posXsymp~
>>
>> treatment+proper_mask_base+prop_resp_ill_base_2
>>
>> + pairID + (1 | union), family = "poisson", nAGQ=0, data =
>>
>> bdata.raw3)#lme4
>>
>> package using glmer
>>
>>
>> HGLM2_5_A = hglm2(posXsymp~
>>
>> treatment+proper_mask_base+prop_resp_ill_base_2
>>
>> + pairID + (1 | union), family =poisson (link = log), rand.family
>> =Gamma(link=log),
>> data = bdata.raw3)#HGLM package using hglm2
>>
>> Does, for example, the choice of distribution for the fixed effects
>>
>> portion
>>
>> of the model inform the choice for the random effects?
>>
>> Thank you for any insights.
>>
>> Best regards,
>> J.D.
>>
>> [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
>>
>> mailing list
>>
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<
>>
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>
>>
>>
>> [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>> --
>> Dr. Benjamin Bolker
>> Professor, Mathematics & Statistics and Biology, McMaster University
>> Director, School of Computational Science and Engineering
>> (Acting) Graduate chair, Mathematics & Statistics
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>> [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>> [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>> [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> --
>> Dr. Benjamin Bolker
>> Professor, Mathematics & Statistics and Biology, McMaster University
>> Director, School of Computational Science and Engineering
>> (Acting) Graduate chair, Mathematics & Statistics
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

	[[alternative HTML version deleted]]


From @pro @end|ng |rom un|me|b@edu@@u  Fri Jul 22 00:48:37 2022
From: @pro @end|ng |rom un|me|b@edu@@u (Andrew Robinson)
Date: Thu, 21 Jul 2022 22:48:37 +0000
Subject: [R-sig-ME] [EXT] Re: Choice of distribution for random effects
In-Reply-To: <CAH_7VOn4eMMUmfJ-K2=EC0Jr92wCo8aSX62Cy9s=V8RCL32Lhg@mail.gmail.com>
References: <CAH_7VOmFG=iwiwPdBR6Loj9FXeic41UQ-aBUg0a3b6qE_eh-gQ@mail.gmail.com>
 <fc0fdf63-fa89-44da-8739-9ec115b42e4a@Spark>
 <CAH_7VOkBvC56rWewTLvQggDWu2EdKGn+ZzKyuE+O2z4mgNZ-zw@mail.gmail.com>
 <bb2aa1d1-8c58-408f-b701-e4e16bac1ba8@Spark>
 <297201de-5577-d813-f872-ef035b0f1b9b@gmail.com>
 <CAH_7VOnnOJPu9+fwr6pA2Z4nGmmw5x_82CSsDqirfBMP0tn_Vw@mail.gmail.com>
 <707277e8-f6c9-4606-b017-72fd05bb22f3@Spark>
 <CAH_7VOkMyLNVnMyuABvJQaRraKyCfFiErq+XQ0NxwyKpnw-MHw@mail.gmail.com>
 <ae0f8c6a-05e5-4cdf-9000-4705b1091e18@Spark>
 <13d0fd40-4444-24a3-f931-52d6b21ef1a8@gmail.com>
 <7b42cbef-11b3-4ce3-bc74-9bb4efac8697@Spark>
 <CAH_7VOn0nM8Zindz0b_zceXzQ-Yt7szx3b=zDx1C8otMFwiqmw@mail.gmail.com>
 <a6c22b40-11df-46df-befa-2de4d5fe14d5@Spark>
 <CAH_7VOn4eMMUmfJ-K2=EC0Jr92wCo8aSX62Cy9s=V8RCL32Lhg@mail.gmail.com>
Message-ID: <232f1fc6-2315-4712-8a81-c74e37d4e17e@Spark>

Well, earlier you wrote "when I try to use HGLM to fit this model?. It?s not the same model. The fixed portion is the same but the random portion is not. If you want to know why hglm2 is failing to fit your different model, that?s a different question.  Possible the families that you elect are not compatible with the data.

I don?t have an opinion on the question because it is not framed in a language that is familiar to me.

Andrew

--
Andrew Robinson
Chief Executive Officer, CEBRA and Professor of Biosecurity,
School/s of BioSciences and Mathematics & Statistics
University of Melbourne, VIC 3010 Australia
Tel: (+61) 0403 138 955
Email: apro at unimelb.edu.au
Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/

I acknowledge the Traditional Owners of the land I inhabit, and pay my respects to their Elders.
On 22 Jul 2022, 8:36 AM +1000, J.D. Haltigan <jhaltiga at gmail.com>, wrote:
External email: Please exercise caution

________________________________
Correct. The idea was to replicate the lmer *with the addition of a random effects distribution* which is not possible in lmer (to see what numeric differences in estimate effects might arise).

So, the fixed portion of the model, if I understand lmer correctly, should be the same here. Whether I specify Beta or Gamma for the random effects (in hglm2) yields the same error. I am wondering what might be the reason for this.

At the risk of asking an elementary question here: When I add the random effects specification for this model, I understand it as accounting for the B/W cluster variance (union). In effect, by adding this random effects component, I am saying that unions are *not* interchangeable and are drawn from a universe of random draws of unions. I am borrowing a bit from the parlance of Generalizability Theory, so apologies in advance if my language is a bit cryptic.

JD

On Thu, Jul 21, 2022 at 6:11 PM Andrew Robinson <apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>> wrote:
As noted earlier, I?m not familiar with hglm, but a cursory glance suggests that those are not the same model.  You appear to have specified Beta distributed random effects in the call to hglm2.

Cheers,

Andrew

--
Andrew Robinson
Chief Executive Officer, CEBRA and Professor of Biosecurity,
School/s of BioSciences and Mathematics & Statistics
University of Melbourne, VIC 3010 Australia
Tel: (+61) 0403 138 955
Email: apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>
Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/

I acknowledge the Traditional Owners of the land I inhabit, and pay my respects to their Elders.
On 22 Jul 2022, 7:45 AM +1000, J.D. Haltigan <jhaltiga at gmail.com<mailto:jhaltiga at gmail.com>>, wrote:
External email: Please exercise caution

________________________________
Thanks for this continued deep dive as it is very instructive for me. I am currently also reading the Wood GAM book which is very helpful.

As an aside, and perhaps relevant to the link discourse, in the current project I am working on, I fit an lmer with:

***lme4_1_B = lmer(posXsymp~treatment+proper_mask_base+prop_resp_ill_base_2 + pairID + (1 | union), data = bdata.raw1)#lme4 package***
which converges and provides results that are sensible (compared to models that have been run using fixed effects only).

However, when I try to use HGLM to fit this model, it does not want to cooperate and I am wondering why. If I specify the HGLM as should be the case for linear models with family = Guassian, as:

***HGLM2_1_A = hglm2(posXsymp~ treatment+proper_mask_base+prop_resp_ill_base_2 + pairID + (1 | union), family=gaussian(link=identity),
                  rand.family=Beta(link=logit), maxit = 100, data = bdata.raw1)#HGLM package using hglm2***

I get: Error in glm.fit(x = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  :
  NA/NaN/Inf in 'x'
In addition: Warning message:
In hglm.default(X = X, y = Y, Z = Z, family = family, rand.family = rand.family,  :
  Residuals numerically 0 are replaced by 1e-8
>

I am wondering if this is b/c "pairID" is a factor variable. I simply don't understand why lmer would fit this but HGLM returns that error.

On Thu, Jul 21, 2022 at 4:18 PM Andrew Robinson <apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>> wrote:
And, with my apologies for being fastidious, as you say the family typically specifies the link function *in the software*, selecting the (so-called) canonical link.

That doesn?t make it the right link function for any given modeling exercise. See, e.g., https://aip.scitation.org/doi/pdf/10.1063/1.5139815<https://aip.scitation.org/doi/pdf/10.1063/1.5139815>, and particularly Figure 1.

As Joe Hilbe and I wrote, it is not clear that there is any statistical benefit in the canonization of a particular link function for each family.

Cheers,

Andrew
On 22 Jul 2022, 2:04 AM +1000, Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com>>, wrote:
I want to clarify one tiny thing.

The family typically specifies the *link function* as well as the
conditional distribution, although this is often done by default (e.g.
poisson -> log, binomial -> logit/log-odds). The link function
specifies the scale on which the data are fitted, so although the random
effects are always Gaussian *on the scale of the linear predictor*
(i.e., the transformed scale), they vary on the scale of the data. If
the distribution of group-level intercepts is Gaussian on the log scale,
then it's log-Normal on the data (count) scale.


On 2022-07-20 11:36 p.m., Andrew Robinson wrote:
That is correct.

Cheers,

Andrew

--
Andrew Robinson
Chief Executive Officer, CEBRA and Professor of Biosecurity,
School/s of BioSciences and Mathematics & Statistics
University of Melbourne, VIC 3010 Australia
Tel: (+61) 0403 138 955
Email: apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>
Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/

I acknowledge the Traditional Owners of the land I inhabit, and pay my respects to their Elders.
On 21 Jul 2022, 1:04 PM +1000, J.D. Haltigan <jhaltiga at gmail.com<mailto:jhaltiga at gmail.com>>, wrote:
This cross-validated post seemed helpful and aligned with everything
previously mentioned here, and I wanted to share.
https://stats.stackexchange.com/questions/190763/how-to-decide-which-glm-family-to-use<https://stats.stackexchange.com/questions/190763/how-to-decide-which-glm-family-to-use>

Thanks for all of your insights as this is quite a deep dive for me.

To be sure: in glmer, when one specifies the GLM family, that then applies
to both fixed & random effects, correct? In other words, there is no way to
separately specify a distribution for the random effects in glmer? I know I
asked this question to Ben on the lme4 Git, but I wanted to confirm again.

JD

On Wed, Jul 20, 2022 at 8:35 PM Andrew Robinson <apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>> wrote:

Ben is correct that the traditional alignment of certain link functions
with certain members of the exponential family (the so-called 'canonical'
links) are merely for analytical convenience and have no statistical
justification.

Canonical link functions exercise an unhealthy influence on statistical
practice, IMO. OTOH, there are circumstances in which they may afford
parameter estimates that are easier to interpret.

I'm not familiar with hglm but I suspect you may need to use the log-link
function for the random effects in order to get something like the glmer
output.

Cheers,

Andrew

--
Andrew Robinson
Chief Executive Officer, CEBRA and Professor of Biosecurity,
School/s of BioSciences and Mathematics & Statistics
University of Melbourne, VIC 3010 Australia
Tel: (+61) 0403 138 955
Email: apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>
Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/

I acknowledge the Traditional Owners of the land I inhabit, and pay my
respects to their Elders.
On 21 Jul 2022, 10:24 AM +1000, J.D. Haltigan <jhaltiga at gmail.com<mailto:jhaltiga at gmail.com>>, wrote:

Thanks, Ben. For example, here is a comparison of glmer & HGLM using
Guassian random effects for HGLM as suggested by Andrew. The magnitude of
the point estimates are about the same, but the nominal significance for
'treatment' is only significant when considering the Gaussian random
effects from lmer.

NB: In the project I am working on, the point is to show sensitivity of
results to different parameterizations of models. I understand the point
estimate magnitudes are about the same, but that is less relevant to this
exercise.

*lme4_5_B = glmer(posXsymp~ treatment+proper_mask_base+prop_resp_ill_base_2
+ pairID + (1 | union), family = "poisson", nAGQ=0, data = bdata.raw3)#lme4
package using glmer*

summary(lme4_5_B)

Generalized linear mixed model fit by maximum likelihood (Adaptive
Gauss-Hermite Quadrature, nAGQ = 0) ['glmerMod']
Family: poisson ( log )
Formula: posXsymp ~ treatment + proper_mask_base + prop_resp_ill_base_2 +
pairID + (1 | union)
Data: bdata.raw3

AIC BIC logLik deviance df.resid
25054.5 27939.7 -12254.2 24508.5 287075

Scaled residuals:
Min 1Q Median 3Q Max
-0.214597 -0.100237 -0.078562 -0.054499 40.646525

Random effects:
Groups Name Variance Std.Dev.
union (Intercept) 0.007269442 0.08526102
Number of obs: 287348, groups: union, 538

Fixed effects:
Estimate Std. Error z value
Pr(>|z|)
(Intercept) -5.987724526 0.581280589 -10.30092 <
0.000000000000000222 ***
treatment -0.094657198 0.044546951 -2.12489
0.03359612 *


***********************************************************************************************************************************************************************************************************************************

*HGLM2_5_Test = hglm2(posXsymp~
treatment+proper_mask_base+prop_resp_ill_base_2 + pairID + (1 | union),
family =poisson (link = log), rand.family =gaussian(link=identity),
data = bdata.raw3)#HGLM package using hglm2*

summary(HGLM2_5_Test)

Call:
hglm2.formula(meanmodel = posXsymp ~ treatment + proper_mask_base +
prop_resp_ill_base_2 + pairID + (1 | union), data = bdata.raw3,
family = poisson(link = log), rand.family = gaussian(link = identity))

----------
MEAN MODEL
----------

Summary of the fixed effects estimates:

Estimate Std. Error t-value Pr(>|t|)
(Intercept) -6.02638 1.09414 -5.508 0.0000000364 ***
treatment -0.02977 0.13624 -0.218 0.8271

On Wed, Jul 20, 2022 at 10:42 AM Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com>> wrote:

I believe that there are some mathematically natural pairings (i.e. a
Gamma random effect + a Poisson response, a Beta-distributed random
effect + a binomial response), but I don't know if there's much
theoretical justification other than analytical convenience.

(If you have a categorical response then the natural random effect
would be Dirichlet, i.e. a Dirichlet-multinomial marginal distribution,
but do you really want to go down that rabbit hole?)

I strongly second Andrew's recommendation to check that the
difference is not a difference between packages/estimation procedures.

On 2022-07-20 5:26 a.m., Andrew Robinson wrote:

You should really also verify that the hglm is doing what you expect by

fitting with Gaussian random effects.


The random effects in glmer are Gaussian. The effects enter the model

via the linear predictor, which is then translated to the mean function of
the chosen distribution of the response variable via the link function (NB
this is a conceptual explanation, not an algorithmic one).


Cheers,

Andrew
On 20 Jul 2022, 6:40 PM +1000, J.D. Haltigan <jhaltiga at gmail.com<mailto:jhaltiga at gmail.com>>,

wrote:

External email: Please exercise caution

________________________________
Thanks, I will inspect the BLUPS.

Re: choice of distribution, what I meant was, for example, if my fixed

effects family is estimated using a Poisson model, does that inform the
choice for random effects as well? (i.e., why would one invoke a gaussian
distribution for random effects if the response variable is, say,
categorical, or a count?)


On Wed, Jul 20, 2022 at 3:40 AM Andrew Robinson <apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>

<mailto:apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>>> wrote:

You can use a qq-plot of the BLUPS to guide that decision.

The difference might also be due to something else, though. Have you

tried the call to hglm2 with a gaussian random effects family? Does it
give the same output as the glmer?


For: does the choice of distribution for the fixed effects portion of

the model inform the choice for the random effects? I?m not sure what you
mean - do you mean the exponential family for the response variable?



Cheers,

Andrew

--
Andrew Robinson
Chief Executive Officer, CEBRA and Professor of Biosecurity,
School/s of BioSciences and Mathematics & Statistics
University of Melbourne, VIC 3010 Australia
Tel: (+61) 0403 138 955
Email: apro at unimelb.edu.au<mailto:apro at unimelb.edu.au><mailto:apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>>
Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/

I acknowledge the Traditional Owners of the land I inhabit, and pay my

respects to their Elders.

On 20 Jul 2022, 2:27 PM +1000, J.D. Haltigan <jhaltiga at gmail.com<mailto:jhaltiga at gmail.com><mailto:

jhaltiga at gmail.com<mailto:jhaltiga at gmail.com>>>, wrote:

Hi:

Is there clear best practice or guidance when it comes to choosing the
distribution of random effects where multiple choices exist (e.g.,
gaussian, gamma, etc.)? I ask in the context of extending some analyses
from an RCT in which the outcome is symptomatic seropositivity (so a
count). The random effects I am modeling are village cluster [union]

(it's

a cluster randomized trial). I get different results (significance-wise)
depending on whether I choose a normal or gamma distribution for the

random

effects.

The basic model (proportional outcome) is:

lme4_5_B = glmer(posXsymp~

treatment+proper_mask_base+prop_resp_ill_base_2

+ pairID + (1 | union), family = "poisson", nAGQ=0, data =

bdata.raw3)#lme4

package using glmer


HGLM2_5_A = hglm2(posXsymp~

treatment+proper_mask_base+prop_resp_ill_base_2

+ pairID + (1 | union), family =poisson (link = log), rand.family
=Gamma(link=log),
data = bdata.raw3)#HGLM package using hglm2

Does, for example, the choice of distribution for the fixed effects

portion

of the model inform the choice for the random effects?

Thank you for any insights.

Best regards,
J.D.

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org><mailto:R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>>

mailing list

https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models><

https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>



[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>


--
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>


[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>



[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>


[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>

--
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>


        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>

	[[alternative HTML version deleted]]


From jh@|t|g@ @end|ng |rom gm@||@com  Fri Jul 22 00:51:46 2022
From: jh@|t|g@ @end|ng |rom gm@||@com (J.D. Haltigan)
Date: Thu, 21 Jul 2022 18:51:46 -0400
Subject: [R-sig-ME] [EXT] Re: Choice of distribution for random effects
In-Reply-To: <232f1fc6-2315-4712-8a81-c74e37d4e17e@Spark>
References: <CAH_7VOmFG=iwiwPdBR6Loj9FXeic41UQ-aBUg0a3b6qE_eh-gQ@mail.gmail.com>
 <fc0fdf63-fa89-44da-8739-9ec115b42e4a@Spark>
 <CAH_7VOkBvC56rWewTLvQggDWu2EdKGn+ZzKyuE+O2z4mgNZ-zw@mail.gmail.com>
 <bb2aa1d1-8c58-408f-b701-e4e16bac1ba8@Spark>
 <297201de-5577-d813-f872-ef035b0f1b9b@gmail.com>
 <CAH_7VOnnOJPu9+fwr6pA2Z4nGmmw5x_82CSsDqirfBMP0tn_Vw@mail.gmail.com>
 <707277e8-f6c9-4606-b017-72fd05bb22f3@Spark>
 <CAH_7VOkMyLNVnMyuABvJQaRraKyCfFiErq+XQ0NxwyKpnw-MHw@mail.gmail.com>
 <ae0f8c6a-05e5-4cdf-9000-4705b1091e18@Spark>
 <13d0fd40-4444-24a3-f931-52d6b21ef1a8@gmail.com>
 <7b42cbef-11b3-4ce3-bc74-9bb4efac8697@Spark>
 <CAH_7VOn0nM8Zindz0b_zceXzQ-Yt7szx3b=zDx1C8otMFwiqmw@mail.gmail.com>
 <a6c22b40-11df-46df-befa-2de4d5fe14d5@Spark>
 <CAH_7VOn4eMMUmfJ-K2=EC0Jr92wCo8aSX62Cy9s=V8RCL32Lhg@mail.gmail.com>
 <232f1fc6-2315-4712-8a81-c74e37d4e17e@Spark>
Message-ID: <CAH_7VOmC0Q8Jdw0+TH1HpLoVLQt3ZxD3q2oC1M_xknz4d_A8NQ@mail.gmail.com>

Thanks for the clarification. It is reassuring at this point to know that
the fixed portion 'of the model(s)' is the same.

On Thu, Jul 21, 2022 at 6:48 PM Andrew Robinson <apro at unimelb.edu.au> wrote:

> Well, earlier you wrote "when I try to use HGLM to fit this model?. It?s
> not the same model. The fixed portion is the same but the random portion is
> not. If you want to know why hglm2 is failing to fit your different model,
> that?s a different question.  Possible the families that you elect are not
> compatible with the data.
>
> I don?t have an opinion on the question because it is not framed in a
> language that is familiar to me.
>
> Andrew
>
> --
> Andrew Robinson
> Chief Executive Officer, CEBRA and Professor of Biosecurity,
> School/s of BioSciences and Mathematics & Statistics
> University of Melbourne, VIC 3010 Australia
> Tel: (+61) 0403 138 955
> Email: apro at unimelb.edu.au
> Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/
>
> I acknowledge the Traditional Owners of the land I inhabit, and pay my
> respects to their Elders.
> On 22 Jul 2022, 8:36 AM +1000, J.D. Haltigan <jhaltiga at gmail.com>, wrote:
>
> *External email:* Please exercise caution
> ------------------------------
> Correct. The idea was to replicate the lmer *with the addition of a random
> effects distribution* which is not possible in lmer (to see what numeric
> differences in estimate effects might arise).
>
> So, the fixed portion of the model, if I understand lmer correctly, should
> be the same here. Whether I specify Beta or Gamma for the random effects
> (in hglm2) yields the same error. I am wondering what might be the reason
> for this.
>
> At the risk of asking an elementary question here: When I add the random
> effects specification for this model, I understand it as accounting for the
> B/W cluster variance (union). In effect, by adding this random effects
> component, I am saying that unions are *not* interchangeable and are drawn
> from a universe of random draws of unions. I am borrowing a bit from the
> parlance of Generalizability Theory, so apologies in advance if my language
> is a bit cryptic.
>
> JD
>
> On Thu, Jul 21, 2022 at 6:11 PM Andrew Robinson <apro at unimelb.edu.au>
> wrote:
>
>> As noted earlier, I?m not familiar with hglm, but a cursory glance
>> suggests that those are not the same model.  You appear to have specified
>> Beta distributed random effects in the call to hglm2.
>>
>> Cheers,
>>
>> Andrew
>>
>> --
>> Andrew Robinson
>> Chief Executive Officer, CEBRA and Professor of Biosecurity,
>> School/s of BioSciences and Mathematics & Statistics
>> University of Melbourne, VIC 3010 Australia
>> Tel: (+61) 0403 138 955
>> Email: apro at unimelb.edu.au
>> Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/
>>
>> I acknowledge the Traditional Owners of the land I inhabit, and pay my
>> respects to their Elders.
>> On 22 Jul 2022, 7:45 AM +1000, J.D. Haltigan <jhaltiga at gmail.com>, wrote:
>>
>> *External email:* Please exercise caution
>> ------------------------------
>> Thanks for this continued deep dive as it is very instructive for me. I
>> am currently also reading the Wood GAM book which is very helpful.
>>
>> As an aside, and perhaps relevant to the link discourse, in the current
>> project I am working on, I fit an lmer with:
>>
>> ***lme4_1_B =
>> lmer(posXsymp~treatment+proper_mask_base+prop_resp_ill_base_2 + pairID + (1
>> | union), data = bdata.raw1)#lme4 package***
>> which converges and provides results that are sensible (compared to
>> models that have been run using fixed effects only).
>>
>> However, when I try to use HGLM to fit this model, it does not want to
>> cooperate and I am wondering why. If I specify the HGLM as should be the
>> case for linear models with family = Guassian, as:
>>
>> ***HGLM2_1_A = hglm2(posXsymp~
>> treatment+proper_mask_base+prop_resp_ill_base_2 + pairID + (1 | union),
>> family=gaussian(link=identity),
>>                   rand.family=Beta(link=logit), maxit = 100, data =
>> bdata.raw1)#HGLM package using hglm2***
>>
>> I get: Error in glm.fit(x = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>> 1, 1,  :
>>   NA/NaN/Inf in 'x'
>> In addition: Warning message:
>> In hglm.default(X = X, y = Y, Z = Z, family = family, rand.family =
>> rand.family,  :
>>   Residuals numerically 0 are replaced by 1e-8
>> >
>>
>> I am wondering if this is b/c "pairID" is a factor variable. I simply
>> don't understand why lmer would fit this but HGLM returns that error.
>>
>> On Thu, Jul 21, 2022 at 4:18 PM Andrew Robinson <apro at unimelb.edu.au>
>> wrote:
>>
>>> And, with my apologies for being fastidious, as you say the family
>>> typically specifies the link function *in the software*, selecting the
>>> (so-called) canonical link.
>>>
>>> That doesn?t make it the right link function for any given modeling
>>> exercise. See, e.g., https://aip.scitation.org/doi/pdf/10.1063/1.5139815,
>>> and particularly Figure 1.
>>>
>>> As Joe Hilbe and I wrote, it is not clear that there is any statistical
>>> benefit in the canonization of a particular link function for each family.
>>>
>>> Cheers,
>>>
>>> Andrew
>>> On 22 Jul 2022, 2:04 AM +1000, Ben Bolker <bbolker at gmail.com>, wrote:
>>> I want to clarify one tiny thing.
>>>
>>> The family typically specifies the *link function* as well as the
>>> conditional distribution, although this is often done by default (e.g.
>>> poisson -> log, binomial -> logit/log-odds). The link function
>>> specifies the scale on which the data are fitted, so although the random
>>> effects are always Gaussian *on the scale of the linear predictor*
>>> (i.e., the transformed scale), they vary on the scale of the data. If
>>> the distribution of group-level intercepts is Gaussian on the log scale,
>>> then it's log-Normal on the data (count) scale.
>>>
>>>
>>> On 2022-07-20 11:36 p.m., Andrew Robinson wrote:
>>> That is correct.
>>>
>>> Cheers,
>>>
>>> Andrew
>>>
>>> --
>>> Andrew Robinson
>>> Chief Executive Officer, CEBRA and Professor of Biosecurity,
>>> School/s of BioSciences and Mathematics & Statistics
>>> University of Melbourne, VIC 3010 Australia
>>> Tel: (+61) 0403 138 955
>>> Email: apro at unimelb.edu.au
>>> Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/
>>>
>>> I acknowledge the Traditional Owners of the land I inhabit, and pay my
>>> respects to their Elders.
>>> On 21 Jul 2022, 1:04 PM +1000, J.D. Haltigan <jhaltiga at gmail.com>,
>>> wrote:
>>> This cross-validated post seemed helpful and aligned with everything
>>> previously mentioned here, and I wanted to share.
>>>
>>> https://stats.stackexchange.com/questions/190763/how-to-decide-which-glm-family-to-use
>>>
>>> Thanks for all of your insights as this is quite a deep dive for me.
>>>
>>> To be sure: in glmer, when one specifies the GLM family, that then
>>> applies
>>> to both fixed & random effects, correct? In other words, there is no way
>>> to
>>> separately specify a distribution for the random effects in glmer? I
>>> know I
>>> asked this question to Ben on the lme4 Git, but I wanted to confirm
>>> again.
>>>
>>> JD
>>>
>>> On Wed, Jul 20, 2022 at 8:35 PM Andrew Robinson <apro at unimelb.edu.au>
>>> wrote:
>>>
>>> Ben is correct that the traditional alignment of certain link functions
>>> with certain members of the exponential family (the so-called 'canonical'
>>> links) are merely for analytical convenience and have no statistical
>>> justification.
>>>
>>> Canonical link functions exercise an unhealthy influence on statistical
>>> practice, IMO. OTOH, there are circumstances in which they may afford
>>> parameter estimates that are easier to interpret.
>>>
>>> I'm not familiar with hglm but I suspect you may need to use the log-link
>>> function for the random effects in order to get something like the glmer
>>> output.
>>>
>>> Cheers,
>>>
>>> Andrew
>>>
>>> --
>>> Andrew Robinson
>>> Chief Executive Officer, CEBRA and Professor of Biosecurity,
>>> School/s of BioSciences and Mathematics & Statistics
>>> University of Melbourne, VIC 3010 Australia
>>> Tel: (+61) 0403 138 955
>>> Email: apro at unimelb.edu.au
>>> Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/
>>>
>>> I acknowledge the Traditional Owners of the land I inhabit, and pay my
>>> respects to their Elders.
>>> On 21 Jul 2022, 10:24 AM +1000, J.D. Haltigan <jhaltiga at gmail.com>,
>>> wrote:
>>>
>>> Thanks, Ben. For example, here is a comparison of glmer & HGLM using
>>> Guassian random effects for HGLM as suggested by Andrew. The magnitude of
>>> the point estimates are about the same, but the nominal significance for
>>> 'treatment' is only significant when considering the Gaussian random
>>> effects from lmer.
>>>
>>> NB: In the project I am working on, the point is to show sensitivity of
>>> results to different parameterizations of models. I understand the point
>>> estimate magnitudes are about the same, but that is less relevant to this
>>> exercise.
>>>
>>> *lme4_5_B = glmer(posXsymp~
>>> treatment+proper_mask_base+prop_resp_ill_base_2
>>> + pairID + (1 | union), family = "poisson", nAGQ=0, data =
>>> bdata.raw3)#lme4
>>> package using glmer*
>>>
>>> summary(lme4_5_B)
>>>
>>> Generalized linear mixed model fit by maximum likelihood (Adaptive
>>> Gauss-Hermite Quadrature, nAGQ = 0) ['glmerMod']
>>> Family: poisson ( log )
>>> Formula: posXsymp ~ treatment + proper_mask_base + prop_resp_ill_base_2 +
>>> pairID + (1 | union)
>>> Data: bdata.raw3
>>>
>>> AIC BIC logLik deviance df.resid
>>> 25054.5 27939.7 -12254.2 24508.5 287075
>>>
>>> Scaled residuals:
>>> Min 1Q Median 3Q Max
>>> -0.214597 -0.100237 -0.078562 -0.054499 40.646525
>>>
>>> Random effects:
>>> Groups Name Variance Std.Dev.
>>> union (Intercept) 0.007269442 0.08526102
>>> Number of obs: 287348, groups: union, 538
>>>
>>> Fixed effects:
>>> Estimate Std. Error z value
>>> Pr(>|z|)
>>> (Intercept) -5.987724526 0.581280589 -10.30092 <
>>> 0.000000000000000222 ***
>>> treatment -0.094657198 0.044546951 -2.12489
>>> 0.03359612 *
>>>
>>>
>>>
>>> ***********************************************************************************************************************************************************************************************************************************
>>>
>>> *HGLM2_5_Test = hglm2(posXsymp~
>>> treatment+proper_mask_base+prop_resp_ill_base_2 + pairID + (1 | union),
>>> family =poisson (link = log), rand.family =gaussian(link=identity),
>>> data = bdata.raw3)#HGLM package using hglm2*
>>>
>>> summary(HGLM2_5_Test)
>>>
>>> Call:
>>> hglm2.formula(meanmodel = posXsymp ~ treatment + proper_mask_base +
>>> prop_resp_ill_base_2 + pairID + (1 | union), data = bdata.raw3,
>>> family = poisson(link = log), rand.family = gaussian(link = identity))
>>>
>>> ----------
>>> MEAN MODEL
>>> ----------
>>>
>>> Summary of the fixed effects estimates:
>>>
>>> Estimate Std. Error t-value Pr(>|t|)
>>> (Intercept) -6.02638 1.09414 -5.508 0.0000000364 ***
>>> treatment -0.02977 0.13624 -0.218 0.8271
>>>
>>> On Wed, Jul 20, 2022 at 10:42 AM Ben Bolker <bbolker at gmail.com> wrote:
>>>
>>> I believe that there are some mathematically natural pairings (i.e. a
>>> Gamma random effect + a Poisson response, a Beta-distributed random
>>> effect + a binomial response), but I don't know if there's much
>>> theoretical justification other than analytical convenience.
>>>
>>> (If you have a categorical response then the natural random effect
>>> would be Dirichlet, i.e. a Dirichlet-multinomial marginal distribution,
>>> but do you really want to go down that rabbit hole?)
>>>
>>> I strongly second Andrew's recommendation to check that the
>>> difference is not a difference between packages/estimation procedures.
>>>
>>> On 2022-07-20 5:26 a.m., Andrew Robinson wrote:
>>>
>>> You should really also verify that the hglm is doing what you expect by
>>>
>>> fitting with Gaussian random effects.
>>>
>>>
>>> The random effects in glmer are Gaussian. The effects enter the model
>>>
>>> via the linear predictor, which is then translated to the mean function
>>> of
>>> the chosen distribution of the response variable via the link function
>>> (NB
>>> this is a conceptual explanation, not an algorithmic one).
>>>
>>>
>>> Cheers,
>>>
>>> Andrew
>>> On 20 Jul 2022, 6:40 PM +1000, J.D. Haltigan <jhaltiga at gmail.com>,
>>>
>>> wrote:
>>>
>>> External email: Please exercise caution
>>>
>>> ________________________________
>>> Thanks, I will inspect the BLUPS.
>>>
>>> Re: choice of distribution, what I meant was, for example, if my fixed
>>>
>>> effects family is estimated using a Poisson model, does that inform the
>>> choice for random effects as well? (i.e., why would one invoke a gaussian
>>> distribution for random effects if the response variable is, say,
>>> categorical, or a count?)
>>>
>>>
>>> On Wed, Jul 20, 2022 at 3:40 AM Andrew Robinson <apro at unimelb.edu.au
>>>
>>> <mailto:apro at unimelb.edu.au>> wrote:
>>>
>>> You can use a qq-plot of the BLUPS to guide that decision.
>>>
>>> The difference might also be due to something else, though. Have you
>>>
>>> tried the call to hglm2 with a gaussian random effects family? Does it
>>> give the same output as the glmer?
>>>
>>>
>>> For: does the choice of distribution for the fixed effects portion of
>>>
>>> the model inform the choice for the random effects? I?m not sure what you
>>> mean - do you mean the exponential family for the response variable?
>>>
>>>
>>>
>>> Cheers,
>>>
>>> Andrew
>>>
>>> --
>>> Andrew Robinson
>>> Chief Executive Officer, CEBRA and Professor of Biosecurity,
>>> School/s of BioSciences and Mathematics & Statistics
>>> University of Melbourne, VIC 3010 Australia
>>> Tel: (+61) 0403 138 955
>>> Email: apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>
>>> Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/
>>>
>>> I acknowledge the Traditional Owners of the land I inhabit, and pay my
>>>
>>> respects to their Elders.
>>>
>>> On 20 Jul 2022, 2:27 PM +1000, J.D. Haltigan <jhaltiga at gmail.com<mailto:
>>>
>>> jhaltiga at gmail.com>>, wrote:
>>>
>>> Hi:
>>>
>>> Is there clear best practice or guidance when it comes to choosing the
>>> distribution of random effects where multiple choices exist (e.g.,
>>> gaussian, gamma, etc.)? I ask in the context of extending some analyses
>>> from an RCT in which the outcome is symptomatic seropositivity (so a
>>> count). The random effects I am modeling are village cluster [union]
>>>
>>> (it's
>>>
>>> a cluster randomized trial). I get different results (significance-wise)
>>> depending on whether I choose a normal or gamma distribution for the
>>>
>>> random
>>>
>>> effects.
>>>
>>> The basic model (proportional outcome) is:
>>>
>>> lme4_5_B = glmer(posXsymp~
>>>
>>> treatment+proper_mask_base+prop_resp_ill_base_2
>>>
>>> + pairID + (1 | union), family = "poisson", nAGQ=0, data =
>>>
>>> bdata.raw3)#lme4
>>>
>>> package using glmer
>>>
>>>
>>> HGLM2_5_A = hglm2(posXsymp~
>>>
>>> treatment+proper_mask_base+prop_resp_ill_base_2
>>>
>>> + pairID + (1 | union), family =poisson (link = log), rand.family
>>> =Gamma(link=log),
>>> data = bdata.raw3)#HGLM package using hglm2
>>>
>>> Does, for example, the choice of distribution for the fixed effects
>>>
>>> portion
>>>
>>> of the model inform the choice for the random effects?
>>>
>>> Thank you for any insights.
>>>
>>> Best regards,
>>> J.D.
>>>
>>> [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org
>>> >
>>>
>>> mailing list
>>>
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<
>>>
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>
>>>
>>>
>>> [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>> --
>>> Dr. Benjamin Bolker
>>> Professor, Mathematics & Statistics and Biology, McMaster University
>>> Director, School of Computational Science and Engineering
>>> (Acting) Graduate chair, Mathematics & Statistics
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>> [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>>
>>> [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>> [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>> --
>>> Dr. Benjamin Bolker
>>> Professor, Mathematics & Statistics and Biology, McMaster University
>>> Director, School of Computational Science and Engineering
>>> (Acting) Graduate chair, Mathematics & Statistics
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>

	[[alternative HTML version deleted]]


From je@@|ecom|ey44 @end|ng |rom gm@||@com  Mon Jul 25 04:52:49 2022
From: je@@|ecom|ey44 @end|ng |rom gm@||@com (jessica comley)
Date: Mon, 25 Jul 2022 10:52:49 +0800
Subject: [R-sig-ME] MCMCglmm with multinomial models
In-Reply-To: <57338F74-D980-4078-A389-EDA67E79C1A6@ed.ac.uk>
References: <CANdGWBHgzmN15cvGu7zU90o-+sZn4fUS92_nanb6OYYW8f2rog@mail.gmail.com>
 <CAJtCY7XH=AACiNbTo4SLo4gMQnM7ub1vVEOwGGqB-AvuJf5+Jw@mail.gmail.com>
 <CANdGWBFmXtPEvaREGQenkqq403+toEFJvLMgPTzdFWGix-ggGA@mail.gmail.com>
 <CAJtCY7XW=aT50ZCGUr2Y8ERPT1x2UC686Odti8n1kTRj4hC+LQ@mail.gmail.com>
 <57338F74-D980-4078-A389-EDA67E79C1A6@ed.ac.uk>
Message-ID: <CANdGWBF3uc7SM0-a7uW54iNBPvRHPTTG+jd8-yjYzUz49o-N4g@mail.gmail.com>

Dear Jarrod and Walid,

Thank you for your replies, it is greatly appreciated.

The predator and culling factors do not vary within sites. As shown in the
example data in one of my previous emails, Bucklands only has culling as
lethal and predator as low, whereas Colchester only has predator as high
and culling as none.

We are trying to submit a paper on black-backed jackal and caracal activity
in the presence of different culling practices and predator presence. The
reviewers want us to try a GLMM approach to determine whether culling or
predators have an effect on black-backed jackal or caracal activity.

Therefore, in your opinion how could be go about this given our data? Would
it be advisable to leave out the random effect of Section?

All the best,
Jess

On Wed, Jul 20, 2022 at 3:06 PM Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:

> Hi Jess
>
> In multinomial models the linear model is set up as a (logit) difference
> in probability between an outcome and some base-line outcome. Often, as
> here, the base-line outcome is arbitrary, and so the idh structure is a
> little odd. For example, if A is the base line category, idh assumes
> COV(B-A, C-A) = 0 which therefore assumes
> COV(B,C)+VAR(A) =COV(A,B)+COV(C,A). It's not clear why this would be the
> case. Perhaps a more reasonable, but less parameter rich, option would be
> to have:
>
> ~idv(Section+trait:Section)
>
> which parameterises the Section covariance matrix by a single parameter
> (rather than 6). The term idv(Section+trait:Section) fits a 3x3 covariance
> matrix of the form v*(I+J) where v is the estimated variance. This assumes
> i) Sections are repeatable in outcome, but knowing that a Section has an
> increased 'preference' for A doesn?t tell you whether it also has an
> increased preference for one of the other categories and ii) the
> repeatability for each outcome within sites is the same (on the latent
> scale).
>
> To test groups of effects (in your case the 3 culling:trait effects), I
> usually use a Wald test and the posterior covariances (see here
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2017q3/025930.html).
> It's far from correct and so Walid's suggestions may be better, but
> small-scale simulations suggests it has good frequentist properties.
>
> To add predator presence you can just add a predator:trait effect into the
> linear model. If the culling and predator factors do not vary within sites
> then you probably don't have enough information to reliably estimate these
> effects.
>
> Cheers,
>
> Jarrod
>
>
>
>
>
>
> > On 19 Jul 2022, at 18:17, Walid Mawass <walidmawass10 at gmail.com> wrote:
> >
> > This email was sent to you by someone outside the University.
> > You should only click on links or attachments if you are certain that
> the email is genuine and the content is safe.
> >
> > Hey Jess,
> >
> > 1) Yes that is correct
> >
> > 2) To my knowledge there is a rule of thumb, where you set the nitt (# of
> > iterations) to a large number that includes the burnin amount, then you
> > choose your thinning interval (sampling of the chain). For example, this
> is
> > what I would use: nitt= 150000, burnin=50000, thin=100. This will give
> you
> > a decent burnin and a final sample of 1000 saved iterations. Note however
> > that this does not have to increase the effective sample size for certain
> > variables, but it might do the trick.
> >
> > 3) hmm...I think one way to do it is to make predictions using the above
> > model and interpret the patterns you see for each relationship you are
> > interested in. Another way to compare effect size would be to use
> bayesian
> > posterior indices. I suggest these two papers by Makowski et al. (2019a &
> > b) that present both interesting posterior indices to use with Bayesian
> > statistical analysis and an associated R package that does the job of
> > computing these indices, *bayestestR*.
> >
> > Good luck
> > --
> > Walid Mawass
> > Ph.D. candidate in Evolutionary Biology - UQTR
> > *Currently* Postdoctoral Research Associate
> > Masel Lab - University of Arizona
> >
> >
> > On Sun, Jul 17, 2022 at 11:32 PM jessica comley <
> jessiecomley44 at gmail.com>
> > wrote:
> >
> >> Hi Walid,
> >>
> >> Thank you for your reply, I greatly appreciate it. I have a few more
> >> questions and if you could help that would be great.
> >>
> >> I tested for correlation between activities and the 14 Sections and the
> >> correlation comes out as low. Therefore I have changed my code to use
> idh()
> >> instead of us as suggested:
> >>
> >> test1c.5b <- MCMCglmm(activity ~ -1 + at.level(culling,1):trait +
> >> at.level(culling, 2):trait, random=~idh(trait):Section, rcov =
> >> ~idh(trait):units, data = caracal, family = "categorical", prior =
> prior,
> >> burnin=5000, nitt=80000)
> >>
> >> 1) Is this correct?
> >>
> >> 2) Increasing the number of interactions increases the effective sample
> >> size, therefore is there a general rule of thumb as to how large your
> >> effective sample size should be?
> >>
> >> 3) I understand how to use and interpret the results of HPDinterval
> (i.e.
> >> if intervals do not overlap 0 then relationship is strong), but how am I
> >> able to test the relationship between all four activities and fixed
> effects
> >> and not just have the three categories (i.e. diurnal, dusk, nocturnal)
> >> compared to the base category (dawn)? For example, I am also interested
> in
> >> whether there is a significant/strong relationship between activities of
> >> caracal at dusk with culling(Lethal)/no culling(none) compared to
> >> activities of caracal at diurnal with culling(Lethal)/no culling(none).
> >>
> >> Below is an example of our dataset:
> >> Camera Section CameraID Animal predator culling activity
> >> 1a Bucklands Bucklands1a Caracal low Lethal diurnal
> >> 1a Bucklands Bucklands1a Caracal low Lethal dawn
> >> 2a Bucklands Bucklands2a Caracal low Lethal dusk
> >> 2a Bucklands Bucklands2a Caracal low Lethal diurnal
> >> 3a Bucklands Bucklands3a Caracal low Lethal dawn
> >> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
> >> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
> >> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
> >> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
> >> Cam 2  Colchester ColchesterCam 2  Caracal high none diurnal
> >> Cam 2  Colchester ColchesterCam 2  Caracal high none diurnal
> >> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
> >> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
> >> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
> >> Cam 4  Colchester ColchesterCam 4  Caracal high none diurnal
> >> Cam 4  Colchester ColchesterCam 4  Caracal high none diurnal
> >> Cam 4  Colchester ColchesterCam 4  Caracal high none nocturnal
> >> 1a Connaught Connaught1a Caracal low Lethal nocturnal
> >> 1a Connaught Connaught1a Caracal low Lethal nocturnal
> >> 1d Connaught Connaught1d Caracal low Lethal diurnal
> >> 3B Connaught Connaught3B Caracal low Lethal diurnal
> >> 3B Connaught Connaught3B Caracal low Lethal diurnal
> >> 4a Connaught Connaught4a Caracal low Lethal nocturnal
> >> 4a Connaught Connaught4a Caracal low Lethal nocturnal
> >> 4b Connaught Connaught4b Caracal low Lethal diurnal
> >> 6a Connaught Connaught6a Caracal low Lethal nocturnal
> >> 6b Connaught Connaught6b Caracal low Lethal diurnal
> >> 7a Connaught Connaught7a Caracal low Lethal nocturnal
> >> 9a Connaught Connaught9a Caracal low Lethal nocturnal
> >> 9d Connaught Connaught9d Caracal low Lethal nocturnal
> >> 9d Connaught Connaught9d Caracal low Lethal dusk
> >> 7d Diepdam Diepdam7d Caracal absent Lethal dusk
> >> 8d Diepdam Diepdam8d Caracal absent Lethal diurnal
> >> 9c Diepdam Diepdam9c Caracal absent Lethal nocturnal
> >>
> >> All the best,
> >> Jess
> >>
> >>
> >> On Fri, Jul 15, 2022 at 11:37 PM Walid Mawass <walidmawass10 at gmail.com>
> >> wrote:
> >>
> >>> Hello,
> >>>
> >>> I don't think I can specifically help you with some of your inquiries.
> >>> However, I do want to comment on a few things that might need some
> >>> attention.
> >>>
> >>> First, MCMCglmm is based on a Bayesian implementation and does not
> >>> compute p-values to compare. What you need to compare are the posterior
> >>> distributions of your effect sizes. This can be done visually using the
> >>> base plot function in R. Or by comparing the HPD intervals and the
> mode (or
> >>> mean) of the posterior distributions.
> >>>
> >>> Second, I have no idea what your data structure looks like (which makes
> >>> it hard to interpret model results), but the effective sample size
> (from
> >>> the 5500 saved iterations sample) for your random variable Section is
> very
> >>> low (the same applies for your fixed effects). You should consider this
> >>> issue and look again at your assumption of correlation between
> >>> activities for the 14 sections you have in your dataset. If you do not
> >>> expect among activity correlations then you can use the idh() function
> >>> instead of us().
> >>>
> >>> Hopefully this helps and in hope that people on this list with more
> >>> knowledge of these models will help out.
> >>>
> >>> Best,
> >>> --
> >>> Walid Mawass
> >>> Ph.D. candidate in Evolutionary Biology - UQTR
> >>> *Currently* Postdoctoral Research Associate
> >>> Masel Lab - University of Arizona
> >>>
> >>>
> >>> On Fri, Jul 15, 2022 at 8:49 AM jessica comley <
> jessiecomley44 at gmail.com>
> >>> wrote:
> >>>
> >>>> Dear all,
> >>>>
> >>>> I am hoping that someone will be able to help me with conducting
> MCMCglmm
> >>>> multinomial models.
> >>>>
> >>>> The data I am working with is for black-backed jackal (bbj) and
> carcal.
> >>>> For
> >>>> each species we have a multinomial response variable called activity
> >>>> which
> >>>> has four categories (dawn, diurnal, dusk, nocturnal). We have two
> >>>> categorical fixed effects which are 1) culling (none, lethal) and 2)
> >>>> predator presence (absent, high, low). We also have a categorical
> >>>> variable
> >>>> called Section (made up of 14 different reserves/ farms where the
> >>>> activity
> >>>> of caracal and bbj were recorded). There are 273 observations for
> caracal
> >>>> and 4399 for bbj. We are wanting to test the effects of culling and
> >>>> predators on caracal and bbj activity separately.
> >>>>
> >>>> I have been working through Jarrod Hadfields course notes,
> particularly
> >>>> with regards to Chapter 5.2. The chi-square analyses reveal that the
> >>>> frequencies of culling and predators differ as do activities.
> >>>>
> >>>> I have managed to work out the specific probabilities for the culling
> >>>> none
> >>>> vs culling lethal for each activity (dawn, diurnal, dusk, nocturnal)
> for
> >>>> caracal, but I'm confused as to how to determine p-values to determine
> >>>> which activities culling none vs culling lethal are affecting?
> >>>>
> >>>> Myy code and outcomes are pasted below with questions stated in bold.
> >>>>
> >>>> caracal2 <- read.csv("caracal_new.csv", header=T)
> >>>> caracal <- as.data.frame(unclass(caracal2), stringsAsFactors = TRUE)
> >>>>
> >>>> #Chi-squared tests
> >>>> Ctable1 <- table(caracal$activity, caracal$culling)
> >>>> chisq.test(rowSums(Ctable1)) #strongly suggests activities differ
> >>>> chisq.test(Ctable1)#strongly suggests culling category differs
> >>>>
> >>>> Ctable2 <- table(caracal$activity, caracal$predator)
> >>>> chisq.test(rowSums(Ctable2))#strongly suggests activities differ
> >>>> chisq.test(Ctable2)#strongly suggests predator category differs
> >>>>
> >>>> prior = list(R = list(fix=1, V=(1/k) * (I + J)), G = list(G1=list(V =
> >>>> diag(k-1), nu=1)))
> >>>> test1c.5 <- MCMCglmm(activity ~ -1 + at.level(culling,1):trait +
> >>>> at.level(culling, 2):trait, random=~us(trait):Section, rcov =
> >>>> ~us(trait):units, data = caracal, family = "categorical", prior =
> prior,
> >>>> burnin=5000, nitt=60000)
> >>>> *##I'm not sure how to add the three predator levels to this model or
> if
> >>>> it
> >>>> would be appropriate?*
> >>>>
> >>>>
> >>>> k <- length(levels(caracal$activity))
> >>>> I <- diag(k-1)
> >>>> J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))
> >>>> IJ <- (1/k) *(diag(k-1) + matrix(1,k-1, k-1))
> >>>>
> >>>> contrasts(caracal$activity)
> >>>>
> >>>> #culling lethal
> >>>> Delta <- cbind(c(0,1,0,0), c(0,0,1,0), c(0,0,0,1))
> >>>> c2 <- (16 * sqrt(3)/(15 * pi))^2
> >>>> D <- ginv(Delta %*% t(Delta)) %*% Delta
> >>>> Int <- t(apply(test1c.5$Sol[,1:3],1, function(x) + D %*% (x/sqrt(1 +
> c2 *
> >>>> diag(IJ)))))
> >>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
> >>>>
> >>>> prop.table(Ctable1[,1])
> >>>>
> >>>> #culling none
> >>>> Delta <- cbind(c(0,1,0,0), c(0,0,1,0), c(0,0,0,1))
> >>>> c2 <- (16 * sqrt(3)/(15 * pi))^2
> >>>> D <- ginv(Delta %*% t(Delta)) %*% Delta
> >>>> Int <- t(apply(test1c.5$Sol[,4:6],1, function(x) + D %*% (x/sqrt(1 +
> c2 *
> >>>> diag(IJ)))))
> >>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
> >>>>
> >>>> prop.table((Ctable1[,2]))
> >>>>
> >>>> HPDinterval(test1c.5$Sol)
> >>>>
> >>>> #model summary
> >>>>> summary(test1c.5)
> >>>>
> >>>> Iterations = 5001:59991
> >>>> Thinning interval  = 10
> >>>> Sample size  = 5500
> >>>>
> >>>> DIC: 699.7014
> >>>>
> >>>> G-structure:  ~us(trait):Section
> >>>>
> >>>>                                                        post.mean l-95%
> >>>> CI
> >>>> u-95% CI eff.samp
> >>>> traitactivity.diurnal:traitactivity.diurnal.Section        1.8124
> >>>> 0.09784
> >>>>   5.665    77.01
> >>>> traitactivity.dusk:traitactivity.diurnal.Section           0.8450
> >>>> -0.83585
> >>>>   3.856    64.17
> >>>> traitactivity.nocturnal:traitactivity.diurnal.Section      1.3621
> >>>> -1.19129
> >>>>   6.157    58.48
> >>>> traitactivity.diurnal:traitactivity.dusk.Section           0.8450
> >>>> -0.83585
> >>>>   3.856    64.17
> >>>> traitactivity.dusk:traitactivity.dusk.Section              1.2034
> >>>> 0.07090
> >>>>   3.681   102.16
> >>>> traitactivity.nocturnal:traitactivity.dusk.Section         0.7505
> >>>> -1.77113
> >>>>   4.524    43.53
> >>>> traitactivity.diurnal:traitactivity.nocturnal.Section      1.3621
> >>>> -1.19129
> >>>>   6.157    58.48
> >>>> traitactivity.dusk:traitactivity.nocturnal.Section         0.7505
> >>>> -1.77113
> >>>>   4.524    43.53
> >>>> traitactivity.nocturnal:traitactivity.nocturnal.Section    2.7148
> >>>> 0.09401
> >>>>   8.397    76.59
> >>>>
> >>>> R-structure:  ~us(trait):units
> >>>>
> >>>>                                                      post.mean l-95%
> CI
> >>>> u-95% CI eff.samp
> >>>> traitactivity.diurnal:traitactivity.diurnal.units          0.50
>  0.50
> >>>>  0.50        0
> >>>> traitactivity.dusk:traitactivity.diurnal.units             0.25
>  0.25
> >>>>  0.25        0
> >>>> traitactivity.nocturnal:traitactivity.diurnal.units        0.25
>  0.25
> >>>>  0.25        0
> >>>> traitactivity.diurnal:traitactivity.dusk.units             0.25
>  0.25
> >>>>  0.25        0
> >>>> traitactivity.dusk:traitactivity.dusk.units                0.50
>  0.50
> >>>>  0.50        0
> >>>> traitactivity.nocturnal:traitactivity.dusk.units           0.25
>  0.25
> >>>>  0.25        0
> >>>> traitactivity.diurnal:traitactivity.nocturnal.units        0.25
>  0.25
> >>>>  0.25        0
> >>>> traitactivity.dusk:traitactivity.nocturnal.units           0.25
>  0.25
> >>>>  0.25        0
> >>>> traitactivity.nocturnal:traitactivity.nocturnal.units      0.50
>  0.50
> >>>>  0.50        0
> >>>>
> >>>> Location effects: activity ~ -1 + at.level(culling, 1):trait +
> >>>> at.level(culling, 2):trait
> >>>>
> >>>>                                             post.mean l-95% CI u-95%
> CI
> >>>> eff.samp  pMCMC
> >>>> at.level(culling, 1):traitactivity.diurnal      1.2306  -0.0533
>  2.6793
> >>>> 145.29 0.0418 *
> >>>> at.level(culling, 1):traitactivity.dusk         0.6605  -0.6006
>  2.0761
> >>>> 92.91 0.2840
> >>>> at.level(culling, 1):traitactivity.nocturnal    1.6090   0.0914
>  3.1356
> >>>> 151.02 0.0265 *
> >>>> traitactivity.diurnal:at.level(culling, 2)      1.2664  -0.1552
>  2.7750
> >>>> 226.40 0.0604 .
> >>>> traitactivity.dusk:at.level(culling, 2)         0.3533  -0.9898
>  1.5218
> >>>> 148.44 0.5447
> >>>> traitactivity.nocturnal:at.level(culling, 2)    1.0447  -0.6405
>  2.8354
> >>>> 346.40 0.1618
> >>>> ---
> >>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >>>>
> >>>> *##So for the model summary I get that lethal culling at activity
> diurnal
> >>>> is significantly different from lethal culling at dawn (its the base
> >>>> reference), but I'm also interested in whether lethal culling at
> activity
> >>>> diurnal is different from lethal culling at dusk for example. Is this
> >>>> possible? *
> >>>>
> >>>> #outcomes culling lethal
> >>>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
> >>>>
> >>>> Iterations = 1:5500
> >>>> Thinning interval = 1
> >>>> Number of chains = 1
> >>>> Sample size per chain = 5500
> >>>>
> >>>> 1. Empirical mean and standard deviation for each variable,
> >>>>   plus standard error of the mean:
> >>>>
> >>>>       Mean      SD  Naive SE Time-series SE
> >>>> [1,] 0.1253 0.05565 0.0007504       0.002484
> >>>> [2,] 0.3748 0.10497 0.0014155       0.003204
> >>>> [3,] 0.1757 0.06640 0.0008954       0.002515
> >>>> [4,] 0.3242 0.11939 0.0016099       0.003514
> >>>>
> >>>> 2. Quantiles for each variable:
> >>>>
> >>>>        2.5%     25%    50%    75%  97.5%
> >>>> var1 0.03641 0.08695 0.1198 0.1554 0.2553
> >>>> var2 0.17298 0.30580 0.3704 0.4431 0.5896
> >>>> var3 0.06166 0.12913 0.1705 0.2161 0.3215
> >>>> var4 0.12610 0.23999 0.3090 0.3901 0.6045
> >>>>
> >>>>> prop.table(Ctable1[,1])
> >>>>     dawn   diurnal      dusk nocturnal
> >>>> 0.1250000 0.2812500 0.1770833 0.4166667
> >>>>
> >>>>
> >>>> #outcomes culling none
> >>>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
> >>>>
> >>>> Iterations = 1:5500
> >>>> Thinning interval = 1
> >>>> Number of chains = 1
> >>>> Sample size per chain = 5500
> >>>>
> >>>> 1. Empirical mean and standard deviation for each variable,
> >>>>   plus standard error of the mean:
> >>>>
> >>>>       Mean      SD  Naive SE Time-series SE
> >>>> [1,] 0.1288 0.06141 0.0008280       0.002787
> >>>> [2,] 0.3804 0.10406 0.0014032       0.002662
> >>>> [3,] 0.1710 0.06844 0.0009228       0.002592
> >>>> [4,] 0.3198 0.11812 0.0015928       0.002956
> >>>>
> >>>> 2. Quantiles for each variable:
> >>>>
> >>>>        2.5%     25%    50%    75%  97.5%
> >>>> var1 0.02891 0.08896 0.1220 0.1594 0.2685
> >>>> var2 0.18007 0.31094 0.3783 0.4474 0.5965
> >>>> var3 0.05840 0.12425 0.1634 0.2083 0.3250
> >>>> var4 0.12430 0.23921 0.3077 0.3862 0.5964
> >>>>
> >>>>> prop.table((Ctable1[,2]))
> >>>>     dawn   diurnal      dusk nocturnal
> >>>> 0.1306818 0.4375000 0.1875000 0.2443182
> >>>>
> >>>> Any help or guidance will be greatly appreciated.
> >>>>
> >>>> All the best,
> >>>> Jess
> >>>>
> >>>> --
> >>>> Jessica Comley (PhD)
> >>>> Research Scientist
> >>>>
> >>>>        [[alternative HTML version deleted]]
> >>>>
> >>>> _______________________________________________
> >>>> R-sig-mixed-models at r-project.org mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>
> >>>
> >>
> >> --
> >> Jessica Comley (PhD)
> >> Research Scientist
> >>
> >>
> >
> >        [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> The University of Edinburgh is a charitable body, registered in Scotland,
> with registration number SC005336. Is e buidheann carthannais a th? ann an
> Oilthigh Dh?n ?ideann, cl?raichte an Alba, ?ireamh cl?raidh SC005336.
>


-- 
Jessica Comley (PhD)
Research Scientist

	[[alternative HTML version deleted]]


From jh@|t|g@ @end|ng |rom gm@||@com  Tue Jul 26 04:37:33 2022
From: jh@|t|g@ @end|ng |rom gm@||@com (J.D. Haltigan)
Date: Mon, 25 Jul 2022 22:37:33 -0400
Subject: [R-sig-ME] Cluster-robust SEs & random effects -- seeking some
 clarification
Message-ID: <CAH_7VOkx8+Pwpx+Rovgm0=k2Nde3TvmJpAQ_28O_NjQTY82h4g@mail.gmail.com>

Hi:

I am seeking some pedagogical guidance around the conceptual
relationship--if any--between accounting for non-independence of error
residuals in cluster designs via cluster-robust SE approaches & formally
modeling cluster variation (say, villages) using a random effects
parameter. This would be in contrast to a purely fixed effects design,
where the random effects of the cluster-level variable is not modeled (but
cluster-robust SEs are used for the fixed effects).

I realize what I am trying to articulate above may be unclear or garbled,
but what I am asking/trying to better understand is whether if modeling the
random effects formally obviates the need to worry about/account for error
residuals within cluster (e.g., via cluster-robust SEs). Trying to
articulate my wondering in another way: does accounting for cluster
residual non-independence fully address the issue of heteroskedasticity
concerns IF random effects are not formally modeled.

Thanks for any insights in advance.

-JD

	[[alternative HTML version deleted]]


From jepu@to @end|ng |rom gm@||@com  Tue Jul 26 05:18:13 2022
From: jepu@to @end|ng |rom gm@||@com (James Pustejovsky)
Date: Mon, 25 Jul 2022 22:18:13 -0500
Subject: [R-sig-ME] Cluster-robust SEs & random effects -- seeking some
 clarification
In-Reply-To: <CAH_7VOkx8+Pwpx+Rovgm0=k2Nde3TvmJpAQ_28O_NjQTY82h4g@mail.gmail.com>
References: <CAH_7VOkx8+Pwpx+Rovgm0=k2Nde3TvmJpAQ_28O_NjQTY82h4g@mail.gmail.com>
Message-ID: <CAFUVuJyh56KYctgrB1TSn8JB01h+Lh93Oh--dPvOK616b=x3LQ@mail.gmail.com>

Hi J.D.,

I expect you may find a variety of takes on your question. I'll offer my
own, as someone who's interested in mixed effects models and cluster robust
standard errors (http://jepusto.github.io/clubSandwich/). There's really
two things going on here. First is the choice between using a regular
linear regression model or using a random effects model. Second is how you
conduct inference (hypothesis tests, confidence intervals, etc.) on the
regression coefficients, where you can either use model-based methods or
cluster-robust methods. Cross those choices and you get four logical
possibilities:
1. Regular linear regression, model-based standard errors (i.e., classical
OLS t-tests/F-tests/CIs). This is clearly not going to work because it
doesn't account for dependence in the errors.
2. Regular linear regression, cluster-robust standard errors.
Cluster-robust methods handle dependence in the errors, so you can trust
the inferences. Regular linear regression may not provide the most
efficient coefficient estimates if you've got dependent error terms and
unequally sized clusters. But, on the plus side, you can easily incorporate
sampling weights. And if you include fixed effects (cluster-specific
dummies), then this lessens concerns about potential cluster-level
confounders of the predictor(s) of interest.
3. Linear mixed model (aka random effects model), model-based standard
errors (i.e., what lmer() spits out automatically). Using random effects
can improve the efficiency of coefficient estimates when you've got
clusters of varying size. But, you can run into trouble if there are
cluster-level confounders of the predictor(s) of interest (which is why
many economists spurn the random effects model). And, it can be tricky to
incorporate sampling weights if those are relevant. Furthermore, using
model-based standard errors for inference amounts to asserting that you
have correctly specified the model in pretty much all respects, including
any random slopes, correlation between level-1 errors, homoskedasticity of
errors at each level of the model, etc. Violation of any of the modeling
assumptions (omitted levels of dependence, omitted random slopes,
heteroskedastic cluster-level variances) could throw off the inferences to
some extent.
4. Linear mixed model, cluster-robust standard errors (using, e.g.,
nlme::lme() or lme4::lmer() with the clubSandwich package linked above).
Using a random effects model to obtain point estimates of the coefficients
has the same benefits and drawbacks in terms of efficiency, potential
confounding concerns, etc. But, you can still use cluster-robust methods
for inference, so that your hypothesis tests and confidence intervals will
be valid even if some aspect of the random effect structure is
mis-specified. For example, cluster-robust methods will work even if you've
omitted a random slope that should actually be there.

So in practice, I would suggest choosing between regular linear regression
or a linear mixed model based on considerations of efficiency and bias from
potential confounding. Then, if using a linear mixed model, choose an
inference approach based on how much you trust the assumptions you lay out
regarding the random effects structure.

James

On Mon, Jul 25, 2022 at 9:38 PM J.D. Haltigan <jhaltiga at gmail.com> wrote:

> Hi:
>
> I am seeking some pedagogical guidance around the conceptual
> relationship--if any--between accounting for non-independence of error
> residuals in cluster designs via cluster-robust SE approaches & formally
> modeling cluster variation (say, villages) using a random effects
> parameter. This would be in contrast to a purely fixed effects design,
> where the random effects of the cluster-level variable is not modeled (but
> cluster-robust SEs are used for the fixed effects).
>
> I realize what I am trying to articulate above may be unclear or garbled,
> but what I am asking/trying to better understand is whether if modeling the
> random effects formally obviates the need to worry about/account for error
> residuals within cluster (e.g., via cluster-robust SEs). Trying to
> articulate my wondering in another way: does accounting for cluster
> residual non-independence fully address the issue of heteroskedasticity
> concerns IF random effects are not formally modeled.
>
> Thanks for any insights in advance.
>
> -JD
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From j@h@d||e|d @end|ng |rom ed@@c@uk  Tue Jul 26 21:32:19 2022
From: j@h@d||e|d @end|ng |rom ed@@c@uk (Jarrod Hadfield)
Date: Tue, 26 Jul 2022 19:32:19 +0000
Subject: [R-sig-ME] MCMCglmm with multinomial models
In-Reply-To: <CANdGWBF3uc7SM0-a7uW54iNBPvRHPTTG+jd8-yjYzUz49o-N4g@mail.gmail.com>
References: <CANdGWBHgzmN15cvGu7zU90o-+sZn4fUS92_nanb6OYYW8f2rog@mail.gmail.com>
 <CAJtCY7XH=AACiNbTo4SLo4gMQnM7ub1vVEOwGGqB-AvuJf5+Jw@mail.gmail.com>
 <CANdGWBFmXtPEvaREGQenkqq403+toEFJvLMgPTzdFWGix-ggGA@mail.gmail.com>
 <CAJtCY7XW=aT50ZCGUr2Y8ERPT1x2UC686Odti8n1kTRj4hC+LQ@mail.gmail.com>
 <57338F74-D980-4078-A389-EDA67E79C1A6@ed.ac.uk>
 <CANdGWBF3uc7SM0-a7uW54iNBPvRHPTTG+jd8-yjYzUz49o-N4g@mail.gmail.com>
Message-ID: <63B269B7-6C5F-4A0C-BC08-51FE97C621BF@ed.ac.uk>

Hi Jess,

Section should definitely not be left out, but I would imagine it is going to be very difficult to separate culling, predator and Section effects - I would expect the credible intervals to be large.

As mentioned in my previous post you can test for an effect of culling by fitting the model

~trait+trait:culling+trait:predator

And then fitting a Wald test to the three terms with 'culling' in. The effect of predator can be tested similarly but with the 3 terms with 'predator' in.

Since your covariates do not vary within Section it will be much easier to aggregate the counts at the Section level (i.e have a data frame with 14 rows and 1 column for each activity with the number observed for each activity) and fit family="multinomial". You can then get rid of the random formula as the Section effects are now effectively the residuals. Given the lack of replication I would advise using the idv formula that I suggested previously and hope the model isn't too misspecified:

prior=list(R=list(V=1, nu=0.002))

m1<-MCMCglmm(cbind(dawn, diurnal, dusk, nocturnal)~trait+trait:culling+trait:predator, rcov=~idv(units+trait:units), prior=prior, ...)

Note this models is identical to the original model, it's just parameterised in a more efficient way.

Cheers,

Jarrod




On 25 Jul 2022, at 03:52, jessica comley <jessiecomley44 at gmail.com<mailto:jessiecomley44 at gmail.com>> wrote:

This email was sent to you by someone outside the University.
You should only click on links or attachments if you are certain that the email is genuine and the content is safe.
Dear Jarrod and Walid,

Thank you for your replies, it is greatly appreciated.

The predator and culling factors do not vary within sites. As shown in the example data in one of my previous emails, Bucklands only has culling as lethal and predator as low, whereas Colchester only has predator as high and culling as none.

We are trying to submit a paper on black-backed jackal and caracal activity in the presence of different culling practices and predator presence. The reviewers want us to try a GLMM approach to determine whether culling or predators have an effect on black-backed jackal or caracal activity.

Therefore, in your opinion how could be go about this given our data? Would it be advisable to leave out the random effect of Section?

All the best,
Jess

On Wed, Jul 20, 2022 at 3:06 PM Jarrod Hadfield <j.hadfield at ed.ac.uk<mailto:j.hadfield at ed.ac.uk>> wrote:
Hi Jess

In multinomial models the linear model is set up as a (logit) difference in probability between an outcome and some base-line outcome. Often, as here, the base-line outcome is arbitrary, and so the idh structure is a little odd. For example, if A is the base line category, idh assumes COV(B-A, C-A) = 0 which therefore assumes
COV(B,C)+VAR(A) =COV(A,B)+COV(C,A). It's not clear why this would be the case. Perhaps a more reasonable, but less parameter rich, option would be to have:

~idv(Section+trait:Section)

which parameterises the Section covariance matrix by a single parameter (rather than 6). The term idv(Section+trait:Section) fits a 3x3 covariance matrix of the form v*(I+J) where v is the estimated variance. This assumes i) Sections are repeatable in outcome, but knowing that a Section has an increased 'preference' for A doesn?t tell you whether it also has an increased preference for one of the other categories and ii) the repeatability for each outcome within sites is the same (on the latent scale).

To test groups of effects (in your case the 3 culling:trait effects), I usually use a Wald test and the posterior covariances (see here https://stat.ethz.ch/pipermail/r-sig-mixed-models/2017q3/025930.html). It's far from correct and so Walid's suggestions may be better, but small-scale simulations suggests it has good frequentist properties.

To add predator presence you can just add a predator:trait effect into the linear model. If the culling and predator factors do not vary within sites then you probably don't have enough information to reliably estimate these effects.

Cheers,

Jarrod






> On 19 Jul 2022, at 18:17, Walid Mawass <walidmawass10 at gmail.com<mailto:walidmawass10 at gmail.com>> wrote:
>
> This email was sent to you by someone outside the University.
> You should only click on links or attachments if you are certain that the email is genuine and the content is safe.
>
> Hey Jess,
>
> 1) Yes that is correct
>
> 2) To my knowledge there is a rule of thumb, where you set the nitt (# of
> iterations) to a large number that includes the burnin amount, then you
> choose your thinning interval (sampling of the chain). For example, this is
> what I would use: nitt= 150000, burnin=50000, thin=100. This will give you
> a decent burnin and a final sample of 1000 saved iterations. Note however
> that this does not have to increase the effective sample size for certain
> variables, but it might do the trick.
>
> 3) hmm...I think one way to do it is to make predictions using the above
> model and interpret the patterns you see for each relationship you are
> interested in. Another way to compare effect size would be to use bayesian
> posterior indices. I suggest these two papers by Makowski et al. (2019a &
> b) that present both interesting posterior indices to use with Bayesian
> statistical analysis and an associated R package that does the job of
> computing these indices, *bayestestR*.
>
> Good luck
> --
> Walid Mawass
> Ph.D. candidate in Evolutionary Biology - UQTR
> *Currently* Postdoctoral Research Associate
> Masel Lab - University of Arizona
>
>
> On Sun, Jul 17, 2022 at 11:32 PM jessica comley <jessiecomley44 at gmail.com<mailto:jessiecomley44 at gmail.com>>
> wrote:
>
>> Hi Walid,
>>
>> Thank you for your reply, I greatly appreciate it. I have a few more
>> questions and if you could help that would be great.
>>
>> I tested for correlation between activities and the 14 Sections and the
>> correlation comes out as low. Therefore I have changed my code to use idh()
>> instead of us as suggested:
>>
>> test1c.5b <- MCMCglmm(activity ~ -1 + at.level(culling,1):trait +
>> at.level(culling, 2):trait, random=~idh(trait):Section, rcov =
>> ~idh(trait):units, data = caracal, family = "categorical", prior = prior,
>> burnin=5000, nitt=80000)
>>
>> 1) Is this correct?
>>
>> 2) Increasing the number of interactions increases the effective sample
>> size, therefore is there a general rule of thumb as to how large your
>> effective sample size should be?
>>
>> 3) I understand how to use and interpret the results of HPDinterval (i.e.
>> if intervals do not overlap 0 then relationship is strong), but how am I
>> able to test the relationship between all four activities and fixed effects
>> and not just have the three categories (i.e. diurnal, dusk, nocturnal)
>> compared to the base category (dawn)? For example, I am also interested in
>> whether there is a significant/strong relationship between activities of
>> caracal at dusk with culling(Lethal)/no culling(none) compared to
>> activities of caracal at diurnal with culling(Lethal)/no culling(none).
>>
>> Below is an example of our dataset:
>> Camera Section CameraID Animal predator culling activity
>> 1a Bucklands Bucklands1a Caracal low Lethal diurnal
>> 1a Bucklands Bucklands1a Caracal low Lethal dawn
>> 2a Bucklands Bucklands2a Caracal low Lethal dusk
>> 2a Bucklands Bucklands2a Caracal low Lethal diurnal
>> 3a Bucklands Bucklands3a Caracal low Lethal dawn
>> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>> Cam 2  Colchester ColchesterCam 2  Caracal high none diurnal
>> Cam 2  Colchester ColchesterCam 2  Caracal high none diurnal
>> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
>> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
>> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
>> Cam 4  Colchester ColchesterCam 4  Caracal high none diurnal
>> Cam 4  Colchester ColchesterCam 4  Caracal high none diurnal
>> Cam 4  Colchester ColchesterCam 4  Caracal high none nocturnal
>> 1a Connaught Connaught1a Caracal low Lethal nocturnal
>> 1a Connaught Connaught1a Caracal low Lethal nocturnal
>> 1d Connaught Connaught1d Caracal low Lethal diurnal
>> 3B Connaught Connaught3B Caracal low Lethal diurnal
>> 3B Connaught Connaught3B Caracal low Lethal diurnal
>> 4a Connaught Connaught4a Caracal low Lethal nocturnal
>> 4a Connaught Connaught4a Caracal low Lethal nocturnal
>> 4b Connaught Connaught4b Caracal low Lethal diurnal
>> 6a Connaught Connaught6a Caracal low Lethal nocturnal
>> 6b Connaught Connaught6b Caracal low Lethal diurnal
>> 7a Connaught Connaught7a Caracal low Lethal nocturnal
>> 9a Connaught Connaught9a Caracal low Lethal nocturnal
>> 9d Connaught Connaught9d Caracal low Lethal nocturnal
>> 9d Connaught Connaught9d Caracal low Lethal dusk
>> 7d Diepdam Diepdam7d Caracal absent Lethal dusk
>> 8d Diepdam Diepdam8d Caracal absent Lethal diurnal
>> 9c Diepdam Diepdam9c Caracal absent Lethal nocturnal
>>
>> All the best,
>> Jess
>>
>>
>> On Fri, Jul 15, 2022 at 11:37 PM Walid Mawass <walidmawass10 at gmail.com<mailto:walidmawass10 at gmail.com>>
>> wrote:
>>
>>> Hello,
>>>
>>> I don't think I can specifically help you with some of your inquiries.
>>> However, I do want to comment on a few things that might need some
>>> attention.
>>>
>>> First, MCMCglmm is based on a Bayesian implementation and does not
>>> compute p-values to compare. What you need to compare are the posterior
>>> distributions of your effect sizes. This can be done visually using the
>>> base plot function in R. Or by comparing the HPD intervals and the mode (or
>>> mean) of the posterior distributions.
>>>
>>> Second, I have no idea what your data structure looks like (which makes
>>> it hard to interpret model results), but the effective sample size (from
>>> the 5500 saved iterations sample) for your random variable Section is very
>>> low (the same applies for your fixed effects). You should consider this
>>> issue and look again at your assumption of correlation between
>>> activities for the 14 sections you have in your dataset. If you do not
>>> expect among activity correlations then you can use the idh() function
>>> instead of us().
>>>
>>> Hopefully this helps and in hope that people on this list with more
>>> knowledge of these models will help out.
>>>
>>> Best,
>>> --
>>> Walid Mawass
>>> Ph.D. candidate in Evolutionary Biology - UQTR
>>> *Currently* Postdoctoral Research Associate
>>> Masel Lab - University of Arizona
>>>
>>>
>>> On Fri, Jul 15, 2022 at 8:49 AM jessica comley <jessiecomley44 at gmail.com<mailto:jessiecomley44 at gmail.com>>
>>> wrote:
>>>
>>>> Dear all,
>>>>
>>>> I am hoping that someone will be able to help me with conducting MCMCglmm
>>>> multinomial models.
>>>>
>>>> The data I am working with is for black-backed jackal (bbj) and carcal.
>>>> For
>>>> each species we have a multinomial response variable called activity
>>>> which
>>>> has four categories (dawn, diurnal, dusk, nocturnal). We have two
>>>> categorical fixed effects which are 1) culling (none, lethal) and 2)
>>>> predator presence (absent, high, low). We also have a categorical
>>>> variable
>>>> called Section (made up of 14 different reserves/ farms where the
>>>> activity
>>>> of caracal and bbj were recorded). There are 273 observations for caracal
>>>> and 4399 for bbj. We are wanting to test the effects of culling and
>>>> predators on caracal and bbj activity separately.
>>>>
>>>> I have been working through Jarrod Hadfields course notes, particularly
>>>> with regards to Chapter 5.2. The chi-square analyses reveal that the
>>>> frequencies of culling and predators differ as do activities.
>>>>
>>>> I have managed to work out the specific probabilities for the culling
>>>> none
>>>> vs culling lethal for each activity (dawn, diurnal, dusk, nocturnal) for
>>>> caracal, but I'm confused as to how to determine p-values to determine
>>>> which activities culling none vs culling lethal are affecting?
>>>>
>>>> Myy code and outcomes are pasted below with questions stated in bold.
>>>>
>>>> caracal2 <- read.csv("caracal_new.csv", header=T)
>>>> caracal <- as.data.frame(unclass(caracal2), stringsAsFactors = TRUE)
>>>>
>>>> #Chi-squared tests
>>>> Ctable1 <- table(caracal$activity, caracal$culling)
>>>> chisq.test(rowSums(Ctable1)) #strongly suggests activities differ
>>>> chisq.test(Ctable1)#strongly suggests culling category differs
>>>>
>>>> Ctable2 <- table(caracal$activity, caracal$predator)
>>>> chisq.test(rowSums(Ctable2))#strongly suggests activities differ
>>>> chisq.test(Ctable2)#strongly suggests predator category differs
>>>>
>>>> prior = list(R = list(fix=1, V=(1/k) * (I + J)), G = list(G1=list(V =
>>>> diag(k-1), nu=1)))
>>>> test1c.5 <- MCMCglmm(activity ~ -1 + at.level(culling,1):trait +
>>>> at.level(culling, 2):trait, random=~us(trait):Section, rcov =
>>>> ~us(trait):units, data = caracal, family = "categorical", prior = prior,
>>>> burnin=5000, nitt=60000)
>>>> *##I'm not sure how to add the three predator levels to this model or if
>>>> it
>>>> would be appropriate?*
>>>>
>>>>
>>>> k <- length(levels(caracal$activity))
>>>> I <- diag(k-1)
>>>> J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))
>>>> IJ <- (1/k) *(diag(k-1) + matrix(1,k-1, k-1))
>>>>
>>>> contrasts(caracal$activity)
>>>>
>>>> #culling lethal
>>>> Delta <- cbind(c(0,1,0,0), c(0,0,1,0), c(0,0,0,1))
>>>> c2 <- (16 * sqrt(3)/(15 * pi))^2
>>>> D <- ginv(Delta %*% t(Delta)) %*% Delta
>>>> Int <- t(apply(test1c.5$Sol[,1:3],1, function(x) + D %*% (x/sqrt(1 + c2 *
>>>> diag(IJ)))))
>>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>>
>>>> prop.table(Ctable1[,1])
>>>>
>>>> #culling none
>>>> Delta <- cbind(c(0,1,0,0), c(0,0,1,0), c(0,0,0,1))
>>>> c2 <- (16 * sqrt(3)/(15 * pi))^2
>>>> D <- ginv(Delta %*% t(Delta)) %*% Delta
>>>> Int <- t(apply(test1c.5$Sol[,4:6],1, function(x) + D %*% (x/sqrt(1 + c2 *
>>>> diag(IJ)))))
>>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>>
>>>> prop.table((Ctable1[,2]))
>>>>
>>>> HPDinterval(test1c.5$Sol)
>>>>
>>>> #model summary
>>>>> summary(test1c.5)
>>>>
>>>> Iterations = 5001:59991
>>>> Thinning interval  = 10
>>>> Sample size  = 5500
>>>>
>>>> DIC: 699.7014
>>>>
>>>> G-structure:  ~us(trait):Section
>>>>
>>>>                                                        post.mean l-95%
>>>> CI
>>>> u-95% CI eff.samp
>>>> traitactivity.diurnal:traitactivity.diurnal.Section        1.8124
>>>> 0.09784
>>>>   5.665    77.01
>>>> traitactivity.dusk:traitactivity.diurnal.Section           0.8450
>>>> -0.83585
>>>>   3.856    64.17
>>>> traitactivity.nocturnal:traitactivity.diurnal.Section      1.3621
>>>> -1.19129
>>>>   6.157    58.48
>>>> traitactivity.diurnal:traitactivity.dusk.Section           0.8450
>>>> -0.83585
>>>>   3.856    64.17
>>>> traitactivity.dusk:traitactivity.dusk.Section              1.2034
>>>> 0.07090
>>>>   3.681   102.16
>>>> traitactivity.nocturnal:traitactivity.dusk.Section         0.7505
>>>> -1.77113
>>>>   4.524    43.53
>>>> traitactivity.diurnal:traitactivity.nocturnal.Section      1.3621
>>>> -1.19129
>>>>   6.157    58.48
>>>> traitactivity.dusk:traitactivity.nocturnal.Section         0.7505
>>>> -1.77113
>>>>   4.524    43.53
>>>> traitactivity.nocturnal:traitactivity.nocturnal.Section    2.7148
>>>> 0.09401
>>>>   8.397    76.59
>>>>
>>>> R-structure:  ~us(trait):units
>>>>
>>>>                                                      post.mean l-95% CI
>>>> u-95% CI eff.samp
>>>> traitactivity.diurnal:traitactivity.diurnal.units          0.50     0.50
>>>>  0.50        0
>>>> traitactivity.dusk:traitactivity.diurnal.units             0.25     0.25
>>>>  0.25        0
>>>> traitactivity.nocturnal:traitactivity.diurnal.units        0.25     0.25
>>>>  0.25        0
>>>> traitactivity.diurnal:traitactivity.dusk.units             0.25     0.25
>>>>  0.25        0
>>>> traitactivity.dusk:traitactivity.dusk.units                0.50     0.50
>>>>  0.50        0
>>>> traitactivity.nocturnal:traitactivity.dusk.units           0.25     0.25
>>>>  0.25        0
>>>> traitactivity.diurnal:traitactivity.nocturnal.units        0.25     0.25
>>>>  0.25        0
>>>> traitactivity.dusk:traitactivity.nocturnal.units           0.25     0.25
>>>>  0.25        0
>>>> traitactivity.nocturnal:traitactivity.nocturnal.units      0.50     0.50
>>>>  0.50        0
>>>>
>>>> Location effects: activity ~ -1 + at.level(culling, 1):trait +
>>>> at.level(culling, 2):trait
>>>>
>>>>                                             post.mean l-95% CI u-95% CI
>>>> eff.samp  pMCMC
>>>> at.level(culling, 1):traitactivity.diurnal      1.2306  -0.0533   2.6793
>>>> 145.29 0.0418 *
>>>> at.level(culling, 1):traitactivity.dusk         0.6605  -0.6006   2.0761
>>>> 92.91 0.2840
>>>> at.level(culling, 1):traitactivity.nocturnal    1.6090   0.0914   3.1356
>>>> 151.02 0.0265 *
>>>> traitactivity.diurnal:at.level(culling, 2)      1.2664  -0.1552   2.7750
>>>> 226.40 0.0604 .
>>>> traitactivity.dusk:at.level(culling, 2)         0.3533  -0.9898   1.5218
>>>> 148.44 0.5447
>>>> traitactivity.nocturnal:at.level(culling, 2)    1.0447  -0.6405   2.8354
>>>> 346.40 0.1618
>>>> ---
>>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>>
>>>> *##So for the model summary I get that lethal culling at activity diurnal
>>>> is significantly different from lethal culling at dawn (its the base
>>>> reference), but I'm also interested in whether lethal culling at activity
>>>> diurnal is different from lethal culling at dusk for example. Is this
>>>> possible? *
>>>>
>>>> #outcomes culling lethal
>>>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>>
>>>> Iterations = 1:5500
>>>> Thinning interval = 1
>>>> Number of chains = 1
>>>> Sample size per chain = 5500
>>>>
>>>> 1. Empirical mean and standard deviation for each variable,
>>>>   plus standard error of the mean:
>>>>
>>>>       Mean      SD  Naive SE Time-series SE
>>>> [1,] 0.1253 0.05565 0.0007504       0.002484
>>>> [2,] 0.3748 0.10497 0.0014155       0.003204
>>>> [3,] 0.1757 0.06640 0.0008954       0.002515
>>>> [4,] 0.3242 0.11939 0.0016099       0.003514
>>>>
>>>> 2. Quantiles for each variable:
>>>>
>>>>        2.5%     25%    50%    75%  97.5%
>>>> var1 0.03641 0.08695 0.1198 0.1554 0.2553
>>>> var2 0.17298 0.30580 0.3704 0.4431 0.5896
>>>> var3 0.06166 0.12913 0.1705 0.2161 0.3215
>>>> var4 0.12610 0.23999 0.3090 0.3901 0.6045
>>>>
>>>>> prop.table(Ctable1[,1])
>>>>     dawn   diurnal      dusk nocturnal
>>>> 0.1250000 0.2812500 0.1770833 0.4166667
>>>>
>>>>
>>>> #outcomes culling none
>>>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>>
>>>> Iterations = 1:5500
>>>> Thinning interval = 1
>>>> Number of chains = 1
>>>> Sample size per chain = 5500
>>>>
>>>> 1. Empirical mean and standard deviation for each variable,
>>>>   plus standard error of the mean:
>>>>
>>>>       Mean      SD  Naive SE Time-series SE
>>>> [1,] 0.1288 0.06141 0.0008280       0.002787
>>>> [2,] 0.3804 0.10406 0.0014032       0.002662
>>>> [3,] 0.1710 0.06844 0.0009228       0.002592
>>>> [4,] 0.3198 0.11812 0.0015928       0.002956
>>>>
>>>> 2. Quantiles for each variable:
>>>>
>>>>        2.5%     25%    50%    75%  97.5%
>>>> var1 0.02891 0.08896 0.1220 0.1594 0.2685
>>>> var2 0.18007 0.31094 0.3783 0.4474 0.5965
>>>> var3 0.05840 0.12425 0.1634 0.2083 0.3250
>>>> var4 0.12430 0.23921 0.3077 0.3862 0.5964
>>>>
>>>>> prop.table((Ctable1[,2]))
>>>>     dawn   diurnal      dusk nocturnal
>>>> 0.1306818 0.4375000 0.1875000 0.2443182
>>>>
>>>> Any help or guidance will be greatly appreciated.
>>>>
>>>> All the best,
>>>> Jess
>>>>
>>>> --
>>>> Jessica Comley (PhD)
>>>> Research Scientist
>>>>
>>>>        [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>
>> --
>> Jessica Comley (PhD)
>> Research Scientist
>>
>>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

The University of Edinburgh is a charitable body, registered in Scotland, with registration number SC005336. Is e buidheann carthannais a th? ann an Oilthigh Dh?n ?ideann, cl?raichte an Alba, ?ireamh cl?raidh SC005336.


--
Jessica Comley (PhD)
Research Scientist



	[[alternative HTML version deleted]]


From je@@|ecom|ey44 @end|ng |rom gm@||@com  Wed Jul 27 02:20:36 2022
From: je@@|ecom|ey44 @end|ng |rom gm@||@com (jessica comley)
Date: Wed, 27 Jul 2022 08:20:36 +0800
Subject: [R-sig-ME] MCMCglmm with multinomial models
In-Reply-To: <63B269B7-6C5F-4A0C-BC08-51FE97C621BF@ed.ac.uk>
References: <CANdGWBHgzmN15cvGu7zU90o-+sZn4fUS92_nanb6OYYW8f2rog@mail.gmail.com>
 <CAJtCY7XH=AACiNbTo4SLo4gMQnM7ub1vVEOwGGqB-AvuJf5+Jw@mail.gmail.com>
 <CANdGWBFmXtPEvaREGQenkqq403+toEFJvLMgPTzdFWGix-ggGA@mail.gmail.com>
 <CAJtCY7XW=aT50ZCGUr2Y8ERPT1x2UC686Odti8n1kTRj4hC+LQ@mail.gmail.com>
 <57338F74-D980-4078-A389-EDA67E79C1A6@ed.ac.uk>
 <CANdGWBF3uc7SM0-a7uW54iNBPvRHPTTG+jd8-yjYzUz49o-N4g@mail.gmail.com>
 <63B269B7-6C5F-4A0C-BC08-51FE97C621BF@ed.ac.uk>
Message-ID: <CANdGWBE5fEdZpnKiJ8ZgaRgFChG4=K5zp2Gpufq-p8KRddX7fw@mail.gmail.com>

Dear Jarrod,

Thank you so much for your help, I greatly appreciate it!

All the best,
Jess

On Wed, Jul 27, 2022 at 3:32 AM Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:

> Hi Jess,
>
> Section should definitely not be left out, but I would imagine it is going
> to be very difficult to separate culling, predator and Section effects - I
> would expect the credible intervals to be large.
>
> As mentioned in my previous post you can test for an effect of culling by
> fitting the model
>
> ~trait+trait:culling+trait:predator
>
> And then fitting a Wald test to the three terms with 'culling' in. The
> effect of predator can be tested similarly but with the 3 terms with
> 'predator' in.
>
> Since your covariates do not vary within Section it will be much easier to
> aggregate the counts at the Section level (i.e have a data frame with 14
> rows and 1 column for each activity with the number observed for each
> activity) and fit family="multinomial". You can then get rid of the random
> formula as the Section effects are now effectively the residuals. Given the
> lack of replication I would advise using the idv formula that I suggested
> previously and hope the model isn't too misspecified:
>
> prior=list(R=list(V=1, nu=0.002))
>
> m1<-MCMCglmm(cbind(dawn, diurnal, dusk,
> nocturnal)~trait+trait:culling+trait:predator,
> rcov=~idv(units+trait:units), prior=prior, ...)
>
> Note this models is identical to the original model, it's just
> parameterised in a more efficient way.
>
> Cheers,
>
> Jarrod
>
>
>
>
> On 25 Jul 2022, at 03:52, jessica comley <jessiecomley44 at gmail.com> wrote:
>
> This email was sent to you by someone outside the University.
> You should only click on links or attachments if you are certain that the
> email is genuine and the content is safe.
> Dear Jarrod and Walid,
>
> Thank you for your replies, it is greatly appreciated.
>
> The predator and culling factors do not vary within sites. As shown in the
> example data in one of my previous emails, Bucklands only has culling as
> lethal and predator as low, whereas Colchester only has predator as high
> and culling as none.
>
> We are trying to submit a paper on black-backed jackal and caracal
> activity in the presence of different culling practices and
> predator presence. The reviewers want us to try a GLMM approach to
> determine whether culling or predators have an effect on black-backed
> jackal or caracal activity.
>
> Therefore, in your opinion how could be go about this given our data?
> Would it be advisable to leave out the random effect of Section?
>
> All the best,
> Jess
>
> On Wed, Jul 20, 2022 at 3:06 PM Jarrod Hadfield <j.hadfield at ed.ac.uk>
> wrote:
>
>> Hi Jess
>>
>> In multinomial models the linear model is set up as a (logit) difference
>> in probability between an outcome and some base-line outcome. Often, as
>> here, the base-line outcome is arbitrary, and so the idh structure is a
>> little odd. For example, if A is the base line category, idh assumes
>> COV(B-A, C-A) = 0 which therefore assumes
>> COV(B,C)+VAR(A) =COV(A,B)+COV(C,A). It's not clear why this would be the
>> case. Perhaps a more reasonable, but less parameter rich, option would be
>> to have:
>>
>> ~idv(Section+trait:Section)
>>
>> which parameterises the Section covariance matrix by a single parameter
>> (rather than 6). The term idv(Section+trait:Section) fits a 3x3 covariance
>> matrix of the form v*(I+J) where v is the estimated variance. This assumes
>> i) Sections are repeatable in outcome, but knowing that a Section has an
>> increased 'preference' for A doesn?t tell you whether it also has an
>> increased preference for one of the other categories and ii) the
>> repeatability for each outcome within sites is the same (on the latent
>> scale).
>>
>> To test groups of effects (in your case the 3 culling:trait effects), I
>> usually use a Wald test and the posterior covariances (see here
>> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2017q3/025930.html).
>> It's far from correct and so Walid's suggestions may be better, but
>> small-scale simulations suggests it has good frequentist properties.
>>
>> To add predator presence you can just add a predator:trait effect into
>> the linear model. If the culling and predator factors do not vary within
>> sites then you probably don't have enough information to reliably estimate
>> these effects.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>>
>>
>>
>> > On 19 Jul 2022, at 18:17, Walid Mawass <walidmawass10 at gmail.com> wrote:
>> >
>> > This email was sent to you by someone outside the University.
>> > You should only click on links or attachments if you are certain that
>> the email is genuine and the content is safe.
>> >
>> > Hey Jess,
>> >
>> > 1) Yes that is correct
>> >
>> > 2) To my knowledge there is a rule of thumb, where you set the nitt (#
>> of
>> > iterations) to a large number that includes the burnin amount, then you
>> > choose your thinning interval (sampling of the chain). For example,
>> this is
>> > what I would use: nitt= 150000, burnin=50000, thin=100. This will give
>> you
>> > a decent burnin and a final sample of 1000 saved iterations. Note
>> however
>> > that this does not have to increase the effective sample size for
>> certain
>> > variables, but it might do the trick.
>> >
>> > 3) hmm...I think one way to do it is to make predictions using the above
>> > model and interpret the patterns you see for each relationship you are
>> > interested in. Another way to compare effect size would be to use
>> bayesian
>> > posterior indices. I suggest these two papers by Makowski et al. (2019a
>> &
>> > b) that present both interesting posterior indices to use with Bayesian
>> > statistical analysis and an associated R package that does the job of
>> > computing these indices, *bayestestR*.
>> >
>> > Good luck
>> > --
>> > Walid Mawass
>> > Ph.D. candidate in Evolutionary Biology - UQTR
>> > *Currently* Postdoctoral Research Associate
>> > Masel Lab - University of Arizona
>> >
>> >
>> > On Sun, Jul 17, 2022 at 11:32 PM jessica comley <
>> jessiecomley44 at gmail.com>
>> > wrote:
>> >
>> >> Hi Walid,
>> >>
>> >> Thank you for your reply, I greatly appreciate it. I have a few more
>> >> questions and if you could help that would be great.
>> >>
>> >> I tested for correlation between activities and the 14 Sections and the
>> >> correlation comes out as low. Therefore I have changed my code to use
>> idh()
>> >> instead of us as suggested:
>> >>
>> >> test1c.5b <- MCMCglmm(activity ~ -1 + at.level(culling,1):trait +
>> >> at.level(culling, 2):trait, random=~idh(trait):Section, rcov =
>> >> ~idh(trait):units, data = caracal, family = "categorical", prior =
>> prior,
>> >> burnin=5000, nitt=80000)
>> >>
>> >> 1) Is this correct?
>> >>
>> >> 2) Increasing the number of interactions increases the effective sample
>> >> size, therefore is there a general rule of thumb as to how large your
>> >> effective sample size should be?
>> >>
>> >> 3) I understand how to use and interpret the results of HPDinterval
>> (i.e.
>> >> if intervals do not overlap 0 then relationship is strong), but how am
>> I
>> >> able to test the relationship between all four activities and fixed
>> effects
>> >> and not just have the three categories (i.e. diurnal, dusk, nocturnal)
>> >> compared to the base category (dawn)? For example, I am also
>> interested in
>> >> whether there is a significant/strong relationship between activities
>> of
>> >> caracal at dusk with culling(Lethal)/no culling(none) compared to
>> >> activities of caracal at diurnal with culling(Lethal)/no culling(none).
>> >>
>> >> Below is an example of our dataset:
>> >> Camera Section CameraID Animal predator culling activity
>> >> 1a Bucklands Bucklands1a Caracal low Lethal diurnal
>> >> 1a Bucklands Bucklands1a Caracal low Lethal dawn
>> >> 2a Bucklands Bucklands2a Caracal low Lethal dusk
>> >> 2a Bucklands Bucklands2a Caracal low Lethal diurnal
>> >> 3a Bucklands Bucklands3a Caracal low Lethal dawn
>> >> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>> >> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>> >> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>> >> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>> >> Cam 2  Colchester ColchesterCam 2  Caracal high none diurnal
>> >> Cam 2  Colchester ColchesterCam 2  Caracal high none diurnal
>> >> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
>> >> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
>> >> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
>> >> Cam 4  Colchester ColchesterCam 4  Caracal high none diurnal
>> >> Cam 4  Colchester ColchesterCam 4  Caracal high none diurnal
>> >> Cam 4  Colchester ColchesterCam 4  Caracal high none nocturnal
>> >> 1a Connaught Connaught1a Caracal low Lethal nocturnal
>> >> 1a Connaught Connaught1a Caracal low Lethal nocturnal
>> >> 1d Connaught Connaught1d Caracal low Lethal diurnal
>> >> 3B Connaught Connaught3B Caracal low Lethal diurnal
>> >> 3B Connaught Connaught3B Caracal low Lethal diurnal
>> >> 4a Connaught Connaught4a Caracal low Lethal nocturnal
>> >> 4a Connaught Connaught4a Caracal low Lethal nocturnal
>> >> 4b Connaught Connaught4b Caracal low Lethal diurnal
>> >> 6a Connaught Connaught6a Caracal low Lethal nocturnal
>> >> 6b Connaught Connaught6b Caracal low Lethal diurnal
>> >> 7a Connaught Connaught7a Caracal low Lethal nocturnal
>> >> 9a Connaught Connaught9a Caracal low Lethal nocturnal
>> >> 9d Connaught Connaught9d Caracal low Lethal nocturnal
>> >> 9d Connaught Connaught9d Caracal low Lethal dusk
>> >> 7d Diepdam Diepdam7d Caracal absent Lethal dusk
>> >> 8d Diepdam Diepdam8d Caracal absent Lethal diurnal
>> >> 9c Diepdam Diepdam9c Caracal absent Lethal nocturnal
>> >>
>> >> All the best,
>> >> Jess
>> >>
>> >>
>> >> On Fri, Jul 15, 2022 at 11:37 PM Walid Mawass <walidmawass10 at gmail.com
>> >
>> >> wrote:
>> >>
>> >>> Hello,
>> >>>
>> >>> I don't think I can specifically help you with some of your inquiries.
>> >>> However, I do want to comment on a few things that might need some
>> >>> attention.
>> >>>
>> >>> First, MCMCglmm is based on a Bayesian implementation and does not
>> >>> compute p-values to compare. What you need to compare are the
>> posterior
>> >>> distributions of your effect sizes. This can be done visually using
>> the
>> >>> base plot function in R. Or by comparing the HPD intervals and the
>> mode (or
>> >>> mean) of the posterior distributions.
>> >>>
>> >>> Second, I have no idea what your data structure looks like (which
>> makes
>> >>> it hard to interpret model results), but the effective sample size
>> (from
>> >>> the 5500 saved iterations sample) for your random variable Section is
>> very
>> >>> low (the same applies for your fixed effects). You should consider
>> this
>> >>> issue and look again at your assumption of correlation between
>> >>> activities for the 14 sections you have in your dataset. If you do not
>> >>> expect among activity correlations then you can use the idh() function
>> >>> instead of us().
>> >>>
>> >>> Hopefully this helps and in hope that people on this list with more
>> >>> knowledge of these models will help out.
>> >>>
>> >>> Best,
>> >>> --
>> >>> Walid Mawass
>> >>> Ph.D. candidate in Evolutionary Biology - UQTR
>> >>> *Currently* Postdoctoral Research Associate
>> >>> Masel Lab - University of Arizona
>> >>>
>> >>>
>> >>> On Fri, Jul 15, 2022 at 8:49 AM jessica comley <
>> jessiecomley44 at gmail.com>
>> >>> wrote:
>> >>>
>> >>>> Dear all,
>> >>>>
>> >>>> I am hoping that someone will be able to help me with conducting
>> MCMCglmm
>> >>>> multinomial models.
>> >>>>
>> >>>> The data I am working with is for black-backed jackal (bbj) and
>> carcal.
>> >>>> For
>> >>>> each species we have a multinomial response variable called activity
>> >>>> which
>> >>>> has four categories (dawn, diurnal, dusk, nocturnal). We have two
>> >>>> categorical fixed effects which are 1) culling (none, lethal) and 2)
>> >>>> predator presence (absent, high, low). We also have a categorical
>> >>>> variable
>> >>>> called Section (made up of 14 different reserves/ farms where the
>> >>>> activity
>> >>>> of caracal and bbj were recorded). There are 273 observations for
>> caracal
>> >>>> and 4399 for bbj. We are wanting to test the effects of culling and
>> >>>> predators on caracal and bbj activity separately.
>> >>>>
>> >>>> I have been working through Jarrod Hadfields course notes,
>> particularly
>> >>>> with regards to Chapter 5.2. The chi-square analyses reveal that the
>> >>>> frequencies of culling and predators differ as do activities.
>> >>>>
>> >>>> I have managed to work out the specific probabilities for the culling
>> >>>> none
>> >>>> vs culling lethal for each activity (dawn, diurnal, dusk, nocturnal)
>> for
>> >>>> caracal, but I'm confused as to how to determine p-values to
>> determine
>> >>>> which activities culling none vs culling lethal are affecting?
>> >>>>
>> >>>> Myy code and outcomes are pasted below with questions stated in bold.
>> >>>>
>> >>>> caracal2 <- read.csv("caracal_new.csv", header=T)
>> >>>> caracal <- as.data.frame(unclass(caracal2), stringsAsFactors = TRUE)
>> >>>>
>> >>>> #Chi-squared tests
>> >>>> Ctable1 <- table(caracal$activity, caracal$culling)
>> >>>> chisq.test(rowSums(Ctable1)) #strongly suggests activities differ
>> >>>> chisq.test(Ctable1)#strongly suggests culling category differs
>> >>>>
>> >>>> Ctable2 <- table(caracal$activity, caracal$predator)
>> >>>> chisq.test(rowSums(Ctable2))#strongly suggests activities differ
>> >>>> chisq.test(Ctable2)#strongly suggests predator category differs
>> >>>>
>> >>>> prior = list(R = list(fix=1, V=(1/k) * (I + J)), G = list(G1=list(V =
>> >>>> diag(k-1), nu=1)))
>> >>>> test1c.5 <- MCMCglmm(activity ~ -1 + at.level(culling,1):trait +
>> >>>> at.level(culling, 2):trait, random=~us(trait):Section, rcov =
>> >>>> ~us(trait):units, data = caracal, family = "categorical", prior =
>> prior,
>> >>>> burnin=5000, nitt=60000)
>> >>>> *##I'm not sure how to add the three predator levels to this model
>> or if
>> >>>> it
>> >>>> would be appropriate?*
>> >>>>
>> >>>>
>> >>>> k <- length(levels(caracal$activity))
>> >>>> I <- diag(k-1)
>> >>>> J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))
>> >>>> IJ <- (1/k) *(diag(k-1) + matrix(1,k-1, k-1))
>> >>>>
>> >>>> contrasts(caracal$activity)
>> >>>>
>> >>>> #culling lethal
>> >>>> Delta <- cbind(c(0,1,0,0), c(0,0,1,0), c(0,0,0,1))
>> >>>> c2 <- (16 * sqrt(3)/(15 * pi))^2
>> >>>> D <- ginv(Delta %*% t(Delta)) %*% Delta
>> >>>> Int <- t(apply(test1c.5$Sol[,1:3],1, function(x) + D %*% (x/sqrt(1 +
>> c2 *
>> >>>> diag(IJ)))))
>> >>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>> >>>>
>> >>>> prop.table(Ctable1[,1])
>> >>>>
>> >>>> #culling none
>> >>>> Delta <- cbind(c(0,1,0,0), c(0,0,1,0), c(0,0,0,1))
>> >>>> c2 <- (16 * sqrt(3)/(15 * pi))^2
>> >>>> D <- ginv(Delta %*% t(Delta)) %*% Delta
>> >>>> Int <- t(apply(test1c.5$Sol[,4:6],1, function(x) + D %*% (x/sqrt(1 +
>> c2 *
>> >>>> diag(IJ)))))
>> >>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>> >>>>
>> >>>> prop.table((Ctable1[,2]))
>> >>>>
>> >>>> HPDinterval(test1c.5$Sol)
>> >>>>
>> >>>> #model summary
>> >>>>> summary(test1c.5)
>> >>>>
>> >>>> Iterations = 5001:59991
>> >>>> Thinning interval  = 10
>> >>>> Sample size  = 5500
>> >>>>
>> >>>> DIC: 699.7014
>> >>>>
>> >>>> G-structure:  ~us(trait):Section
>> >>>>
>> >>>>                                                        post.mean
>> l-95%
>> >>>> CI
>> >>>> u-95% CI eff.samp
>> >>>> traitactivity.diurnal:traitactivity.diurnal.Section        1.8124
>> >>>> 0.09784
>> >>>>   5.665    77.01
>> >>>> traitactivity.dusk:traitactivity.diurnal.Section           0.8450
>> >>>> -0.83585
>> >>>>   3.856    64.17
>> >>>> traitactivity.nocturnal:traitactivity.diurnal.Section      1.3621
>> >>>> -1.19129
>> >>>>   6.157    58.48
>> >>>> traitactivity.diurnal:traitactivity.dusk.Section           0.8450
>> >>>> -0.83585
>> >>>>   3.856    64.17
>> >>>> traitactivity.dusk:traitactivity.dusk.Section              1.2034
>> >>>> 0.07090
>> >>>>   3.681   102.16
>> >>>> traitactivity.nocturnal:traitactivity.dusk.Section         0.7505
>> >>>> -1.77113
>> >>>>   4.524    43.53
>> >>>> traitactivity.diurnal:traitactivity.nocturnal.Section      1.3621
>> >>>> -1.19129
>> >>>>   6.157    58.48
>> >>>> traitactivity.dusk:traitactivity.nocturnal.Section         0.7505
>> >>>> -1.77113
>> >>>>   4.524    43.53
>> >>>> traitactivity.nocturnal:traitactivity.nocturnal.Section    2.7148
>> >>>> 0.09401
>> >>>>   8.397    76.59
>> >>>>
>> >>>> R-structure:  ~us(trait):units
>> >>>>
>> >>>>                                                      post.mean l-95%
>> CI
>> >>>> u-95% CI eff.samp
>> >>>> traitactivity.diurnal:traitactivity.diurnal.units          0.50
>>  0.50
>> >>>>  0.50        0
>> >>>> traitactivity.dusk:traitactivity.diurnal.units             0.25
>>  0.25
>> >>>>  0.25        0
>> >>>> traitactivity.nocturnal:traitactivity.diurnal.units        0.25
>>  0.25
>> >>>>  0.25        0
>> >>>> traitactivity.diurnal:traitactivity.dusk.units             0.25
>>  0.25
>> >>>>  0.25        0
>> >>>> traitactivity.dusk:traitactivity.dusk.units                0.50
>>  0.50
>> >>>>  0.50        0
>> >>>> traitactivity.nocturnal:traitactivity.dusk.units           0.25
>>  0.25
>> >>>>  0.25        0
>> >>>> traitactivity.diurnal:traitactivity.nocturnal.units        0.25
>>  0.25
>> >>>>  0.25        0
>> >>>> traitactivity.dusk:traitactivity.nocturnal.units           0.25
>>  0.25
>> >>>>  0.25        0
>> >>>> traitactivity.nocturnal:traitactivity.nocturnal.units      0.50
>>  0.50
>> >>>>  0.50        0
>> >>>>
>> >>>> Location effects: activity ~ -1 + at.level(culling, 1):trait +
>> >>>> at.level(culling, 2):trait
>> >>>>
>> >>>>                                             post.mean l-95% CI u-95%
>> CI
>> >>>> eff.samp  pMCMC
>> >>>> at.level(culling, 1):traitactivity.diurnal      1.2306  -0.0533
>>  2.6793
>> >>>> 145.29 0.0418 *
>> >>>> at.level(culling, 1):traitactivity.dusk         0.6605  -0.6006
>>  2.0761
>> >>>> 92.91 0.2840
>> >>>> at.level(culling, 1):traitactivity.nocturnal    1.6090   0.0914
>>  3.1356
>> >>>> 151.02 0.0265 *
>> >>>> traitactivity.diurnal:at.level(culling, 2)      1.2664  -0.1552
>>  2.7750
>> >>>> 226.40 0.0604 .
>> >>>> traitactivity.dusk:at.level(culling, 2)         0.3533  -0.9898
>>  1.5218
>> >>>> 148.44 0.5447
>> >>>> traitactivity.nocturnal:at.level(culling, 2)    1.0447  -0.6405
>>  2.8354
>> >>>> 346.40 0.1618
>> >>>> ---
>> >>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> >>>>
>> >>>> *##So for the model summary I get that lethal culling at activity
>> diurnal
>> >>>> is significantly different from lethal culling at dawn (its the base
>> >>>> reference), but I'm also interested in whether lethal culling at
>> activity
>> >>>> diurnal is different from lethal culling at dusk for example. Is this
>> >>>> possible? *
>> >>>>
>> >>>> #outcomes culling lethal
>> >>>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>> >>>>
>> >>>> Iterations = 1:5500
>> >>>> Thinning interval = 1
>> >>>> Number of chains = 1
>> >>>> Sample size per chain = 5500
>> >>>>
>> >>>> 1. Empirical mean and standard deviation for each variable,
>> >>>>   plus standard error of the mean:
>> >>>>
>> >>>>       Mean      SD  Naive SE Time-series SE
>> >>>> [1,] 0.1253 0.05565 0.0007504       0.002484
>> >>>> [2,] 0.3748 0.10497 0.0014155       0.003204
>> >>>> [3,] 0.1757 0.06640 0.0008954       0.002515
>> >>>> [4,] 0.3242 0.11939 0.0016099       0.003514
>> >>>>
>> >>>> 2. Quantiles for each variable:
>> >>>>
>> >>>>        2.5%     25%    50%    75%  97.5%
>> >>>> var1 0.03641 0.08695 0.1198 0.1554 0.2553
>> >>>> var2 0.17298 0.30580 0.3704 0.4431 0.5896
>> >>>> var3 0.06166 0.12913 0.1705 0.2161 0.3215
>> >>>> var4 0.12610 0.23999 0.3090 0.3901 0.6045
>> >>>>
>> >>>>> prop.table(Ctable1[,1])
>> >>>>     dawn   diurnal      dusk nocturnal
>> >>>> 0.1250000 0.2812500 0.1770833 0.4166667
>> >>>>
>> >>>>
>> >>>> #outcomes culling none
>> >>>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>> >>>>
>> >>>> Iterations = 1:5500
>> >>>> Thinning interval = 1
>> >>>> Number of chains = 1
>> >>>> Sample size per chain = 5500
>> >>>>
>> >>>> 1. Empirical mean and standard deviation for each variable,
>> >>>>   plus standard error of the mean:
>> >>>>
>> >>>>       Mean      SD  Naive SE Time-series SE
>> >>>> [1,] 0.1288 0.06141 0.0008280       0.002787
>> >>>> [2,] 0.3804 0.10406 0.0014032       0.002662
>> >>>> [3,] 0.1710 0.06844 0.0009228       0.002592
>> >>>> [4,] 0.3198 0.11812 0.0015928       0.002956
>> >>>>
>> >>>> 2. Quantiles for each variable:
>> >>>>
>> >>>>        2.5%     25%    50%    75%  97.5%
>> >>>> var1 0.02891 0.08896 0.1220 0.1594 0.2685
>> >>>> var2 0.18007 0.31094 0.3783 0.4474 0.5965
>> >>>> var3 0.05840 0.12425 0.1634 0.2083 0.3250
>> >>>> var4 0.12430 0.23921 0.3077 0.3862 0.5964
>> >>>>
>> >>>>> prop.table((Ctable1[,2]))
>> >>>>     dawn   diurnal      dusk nocturnal
>> >>>> 0.1306818 0.4375000 0.1875000 0.2443182
>> >>>>
>> >>>> Any help or guidance will be greatly appreciated.
>> >>>>
>> >>>> All the best,
>> >>>> Jess
>> >>>>
>> >>>> --
>> >>>> Jessica Comley (PhD)
>> >>>> Research Scientist
>> >>>>
>> >>>>        [[alternative HTML version deleted]]
>> >>>>
>> >>>> _______________________________________________
>> >>>> R-sig-mixed-models at r-project.org mailing list
>> >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>>>
>> >>>
>> >>
>> >> --
>> >> Jessica Comley (PhD)
>> >> Research Scientist
>> >>
>> >>
>> >
>> >        [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> The University of Edinburgh is a charitable body, registered in Scotland,
>> with registration number SC005336. Is e buidheann carthannais a th? ann an
>> Oilthigh Dh?n ?ideann, cl?raichte an Alba, ?ireamh cl?raidh SC005336.
>>
>
>
> --
> Jessica Comley (PhD)
> Research Scientist
>
>
>

-- 
Dr Jessica Comley
Lecturer: Environmental and Life Sciences
Faculty of Science
Universiti Brunei Darussalam

Email: jessica.comley at ubd.edu.bn

	[[alternative HTML version deleted]]


From jh@|t|g@ @end|ng |rom gm@||@com  Wed Jul 27 05:41:36 2022
From: jh@|t|g@ @end|ng |rom gm@||@com (J.D. Haltigan)
Date: Tue, 26 Jul 2022 23:41:36 -0400
Subject: [R-sig-ME] Cluster-robust SEs & random effects -- seeking some
 clarification
In-Reply-To: <CAFUVuJyh56KYctgrB1TSn8JB01h+Lh93Oh--dPvOK616b=x3LQ@mail.gmail.com>
References: <CAH_7VOkx8+Pwpx+Rovgm0=k2Nde3TvmJpAQ_28O_NjQTY82h4g@mail.gmail.com>
 <CAFUVuJyh56KYctgrB1TSn8JB01h+Lh93Oh--dPvOK616b=x3LQ@mail.gmail.com>
Message-ID: <CAH_7VO=aOOhT8TWJ7rAfY4EC+8yOepLpkpg0TcXgjN+wwk2c=w@mail.gmail.com>

Many thanks for this detailed and insightful exposition, James.

A few follow-ups:

I had previously tried cluster-robust SEs with both the robustlmm package
and now yours, and it appears I don't have the memory needed given the size
of the data as I receive the following error:
#Error in .local(x, y, ...) :
#Cholmod error 'problem too large' at file ../Core/cholmod_sparse.c, line 89
In Googling this error message, I see it is likely due to the computational
demands of a sparse matrix estimation, but was wondering if there were any
other aspects of this I could explore.

In regards to #4: I am invoking random effects to see how sensitive a fixed
effects model (with cluster robust SEs) is to formally estimating the
random cluster effect (so between-cluster variance). In the fixed effects
model, the investigators did include a factor variable (i.e., cluster
dummies as you describe below) that is nested within cluster (so, a pair
variable indicating treatment-control village), but my predilection is that
despite this, there are other sources of between-cluster variance that will
likely nullify the point estimates of the fixed effects (in this case, a
mask intervention). So, if I am formally modeling the random cluster
component, what does adding cluster-robust SEs in this case provide in
terms of inference--both for the fixed effects and for the random effects?

Hoping this is clear and if not will try to clarify.

-JD

On Mon, Jul 25, 2022 at 11:18 PM James Pustejovsky <jepusto at gmail.com>
wrote:

> Hi J.D.,
>
> I expect you may find a variety of takes on your question. I'll offer my
> own, as someone who's interested in mixed effects models and cluster robust
> standard errors (http://jepusto.github.io/clubSandwich/). There's really
> two things going on here. First is the choice between using a regular
> linear regression model or using a random effects model. Second is how you
> conduct inference (hypothesis tests, confidence intervals, etc.) on the
> regression coefficients, where you can either use model-based methods or
> cluster-robust methods. Cross those choices and you get four logical
> possibilities:
> 1. Regular linear regression, model-based standard errors (i.e., classical
> OLS t-tests/F-tests/CIs). This is clearly not going to work because it
> doesn't account for dependence in the errors.
> 2. Regular linear regression, cluster-robust standard errors.
> Cluster-robust methods handle dependence in the errors, so you can trust
> the inferences. Regular linear regression may not provide the most
> efficient coefficient estimates if you've got dependent error terms and
> unequally sized clusters. But, on the plus side, you can easily incorporate
> sampling weights. And if you include fixed effects (cluster-specific
> dummies), then this lessens concerns about potential cluster-level
> confounders of the predictor(s) of interest.
> 3. Linear mixed model (aka random effects model), model-based standard
> errors (i.e., what lmer() spits out automatically). Using random effects
> can improve the efficiency of coefficient estimates when you've got
> clusters of varying size. But, you can run into trouble if there are
> cluster-level confounders of the predictor(s) of interest (which is why
> many economists spurn the random effects model). And, it can be tricky to
> incorporate sampling weights if those are relevant. Furthermore, using
> model-based standard errors for inference amounts to asserting that you
> have correctly specified the model in pretty much all respects, including
> any random slopes, correlation between level-1 errors, homoskedasticity of
> errors at each level of the model, etc. Violation of any of the modeling
> assumptions (omitted levels of dependence, omitted random slopes,
> heteroskedastic cluster-level variances) could throw off the inferences to
> some extent.
> 4. Linear mixed model, cluster-robust standard errors (using, e.g.,
> nlme::lme() or lme4::lmer() with the clubSandwich package linked above).
> Using a random effects model to obtain point estimates of the coefficients
> has the same benefits and drawbacks in terms of efficiency, potential
> confounding concerns, etc. But, you can still use cluster-robust methods
> for inference, so that your hypothesis tests and confidence intervals will
> be valid even if some aspect of the random effect structure is
> mis-specified. For example, cluster-robust methods will work even if you've
> omitted a random slope that should actually be there.
>
> So in practice, I would suggest choosing between regular linear regression
> or a linear mixed model based on considerations of efficiency and bias from
> potential confounding. Then, if using a linear mixed model, choose an
> inference approach based on how much you trust the assumptions you lay out
> regarding the random effects structure.
>
> James
>
> On Mon, Jul 25, 2022 at 9:38 PM J.D. Haltigan <jhaltiga at gmail.com> wrote:
>
>> Hi:
>>
>> I am seeking some pedagogical guidance around the conceptual
>> relationship--if any--between accounting for non-independence of error
>> residuals in cluster designs via cluster-robust SE approaches & formally
>> modeling cluster variation (say, villages) using a random effects
>> parameter. This would be in contrast to a purely fixed effects design,
>> where the random effects of the cluster-level variable is not modeled (but
>> cluster-robust SEs are used for the fixed effects).
>>
>> I realize what I am trying to articulate above may be unclear or garbled,
>> but what I am asking/trying to better understand is whether if modeling
>> the
>> random effects formally obviates the need to worry about/account for error
>> residuals within cluster (e.g., via cluster-robust SEs). Trying to
>> articulate my wondering in another way: does accounting for cluster
>> residual non-independence fully address the issue of heteroskedasticity
>> concerns IF random effects are not formally modeled.
>>
>> Thanks for any insights in advance.
>>
>> -JD
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

	[[alternative HTML version deleted]]


From je@@|ecom|ey44 @end|ng |rom gm@||@com  Wed Jul 27 05:42:21 2022
From: je@@|ecom|ey44 @end|ng |rom gm@||@com (jessica comley)
Date: Wed, 27 Jul 2022 11:42:21 +0800
Subject: [R-sig-ME] MCMCglmm with multinomial models
In-Reply-To: <CANdGWBE5fEdZpnKiJ8ZgaRgFChG4=K5zp2Gpufq-p8KRddX7fw@mail.gmail.com>
References: <CANdGWBHgzmN15cvGu7zU90o-+sZn4fUS92_nanb6OYYW8f2rog@mail.gmail.com>
 <CAJtCY7XH=AACiNbTo4SLo4gMQnM7ub1vVEOwGGqB-AvuJf5+Jw@mail.gmail.com>
 <CANdGWBFmXtPEvaREGQenkqq403+toEFJvLMgPTzdFWGix-ggGA@mail.gmail.com>
 <CAJtCY7XW=aT50ZCGUr2Y8ERPT1x2UC686Odti8n1kTRj4hC+LQ@mail.gmail.com>
 <57338F74-D980-4078-A389-EDA67E79C1A6@ed.ac.uk>
 <CANdGWBF3uc7SM0-a7uW54iNBPvRHPTTG+jd8-yjYzUz49o-N4g@mail.gmail.com>
 <63B269B7-6C5F-4A0C-BC08-51FE97C621BF@ed.ac.uk>
 <CANdGWBE5fEdZpnKiJ8ZgaRgFChG4=K5zp2Gpufq-p8KRddX7fw@mail.gmail.com>
Message-ID: <CANdGWBFY0s2y=qaKhwKAU5cvg2xW5rQ_3CmmXvvj+q5v-Fee3g@mail.gmail.com>

Dear Jarrod,

Sorry to bother you again, I just want to make sure I am doing this
correctly and understanding my results.

I used the model you suggested:

*prior1=list(R=list(V=1, nu=0.002))m1<-MCMCglmm(cbind(dawn, diurnal, dusk,
nocturnal)~trait+trait:culling+trait:predator,
rcov=~idv(units+trait:units), prior=prior1, data=bbj,
family="multinomial4", nitt= 150000)*

And this is my outcome:






























*Iterations = 3001:149991 Thinning interval  = 10 Sample size  = 14700
 DIC: 10312.95  R-structure:  ~idv(units + trait:units)
post.mean  l-95% CI u-95% CI eff.samptrait:units   0.01932 0.0002102
 0.07042      441 Location effects: cbind(dawn, diurnal, dusk, nocturnal) ~
trait + trait:culling + trait:predator                            post.mean
 l-95% CI  u-95% CI eff.samp   pMCMC    (Intercept)
 -2.018903 -2.677830 -1.335305    609.1 < 7e-05 ***traitdiurnal
   0.542636 -0.363766  1.405230    644.6 0.22068    traitdusk
   -0.047952 -0.984923  0.917710    374.6 0.91850
 traitdawn:cullingLethal     0.534474  0.003076  1.058211    596.8 0.05524
.  traitdiurnal:cullingLethal  0.232597 -0.369959  0.834347    404.7
0.42789    traitdusk:cullingLethal     0.376191 -0.217707  0.964636
 408.2 0.19782    traitdawn:cullingnone      -0.163961 -0.573477  0.298182
  2945.5 0.38245    traitdiurnal:cullingnone    0.674041  0.247724
 1.101917   2825.0 0.00952 ** traitdusk:cullingnone       0.449710
-0.014263  0.874925   1683.9 0.05102 .  traitdawn:predatorhigh
 0.456119 -0.206435  1.151283    561.7 0.18531    traitdiurnal:predatorhigh
 -0.303114 -0.976842  0.377294    479.9 0.36939    traitdusk:predatorhigh
   0.108262 -0.674552  0.895819    256.7 0.76122    traitdawn:predatorlow
    0.756262  0.160407  1.323520    418.1 0.01279 *
 traitdiurnal:predatorlow    0.136875 -0.446984  0.750518    305.7 0.65619
   traitdusk:predatorlow       0.422497 -0.303586  1.145038    194.9
0.22857    ---Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ?
1*

1) Why do the 2 categories for culling both show up but then only 2 of the
three categories for predator show up? i.e. predatorabsent is missing?

2) Do these results mean that i) diurnal activity and lethal culling is sig
different from nocturnal activity and lethal culling; ii) dawn activity and
predator low is sig different from nocturnal activity and predator low?

3) Is this the correct way and interpretation of the within group effects?
*##culling lethal*


* aod::wald.test(cov(m1$Sol[,3:5]),
colMeans(m1$Sol[,3:5]),Terms=1:3)$result$chi2["P"]        P 0.1638938*




*##culling  noneaod::wald.test(cov(m1$Sol[,6:8]),
colMeans(m1$Sol[,6:8]),Terms=1:3)$result$chi2["P"]          P 0.006497424*

So these results show us that culling none has an effect on activity?

Thank you in advance,
Jess

On Wed, Jul 27, 2022 at 8:20 AM jessica comley <jessiecomley44 at gmail.com>
wrote:

> Dear Jarrod,
>
> Thank you so much for your help, I greatly appreciate it!
>
> All the best,
> Jess
>
> On Wed, Jul 27, 2022 at 3:32 AM Jarrod Hadfield <j.hadfield at ed.ac.uk>
> wrote:
>
>> Hi Jess,
>>
>> Section should definitely not be left out, but I would imagine it is
>> going to be very difficult to separate culling, predator and Section
>> effects - I would expect the credible intervals to be large.
>>
>> As mentioned in my previous post you can test for an effect of culling by
>> fitting the model
>>
>> ~trait+trait:culling+trait:predator
>>
>> And then fitting a Wald test to the three terms with 'culling' in. The
>> effect of predator can be tested similarly but with the 3 terms with
>> 'predator' in.
>>
>> Since your covariates do not vary within Section it will be much easier
>> to aggregate the counts at the Section level (i.e have a data frame with 14
>> rows and 1 column for each activity with the number observed for each
>> activity) and fit family="multinomial". You can then get rid of the random
>> formula as the Section effects are now effectively the residuals. Given the
>> lack of replication I would advise using the idv formula that I suggested
>> previously and hope the model isn't too misspecified:
>>
>> prior=list(R=list(V=1, nu=0.002))
>>
>> m1<-MCMCglmm(cbind(dawn, diurnal, dusk,
>> nocturnal)~trait+trait:culling+trait:predator,
>> rcov=~idv(units+trait:units), prior=prior, ...)
>>
>> Note this models is identical to the original model, it's just
>> parameterised in a more efficient way.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>>
>> On 25 Jul 2022, at 03:52, jessica comley <jessiecomley44 at gmail.com>
>> wrote:
>>
>> This email was sent to you by someone outside the University.
>> You should only click on links or attachments if you are certain that the
>> email is genuine and the content is safe.
>> Dear Jarrod and Walid,
>>
>> Thank you for your replies, it is greatly appreciated.
>>
>> The predator and culling factors do not vary within sites. As shown in
>> the example data in one of my previous emails, Bucklands only has culling
>> as lethal and predator as low, whereas Colchester only has predator as high
>> and culling as none.
>>
>> We are trying to submit a paper on black-backed jackal and caracal
>> activity in the presence of different culling practices and
>> predator presence. The reviewers want us to try a GLMM approach to
>> determine whether culling or predators have an effect on black-backed
>> jackal or caracal activity.
>>
>> Therefore, in your opinion how could be go about this given our data?
>> Would it be advisable to leave out the random effect of Section?
>>
>> All the best,
>> Jess
>>
>> On Wed, Jul 20, 2022 at 3:06 PM Jarrod Hadfield <j.hadfield at ed.ac.uk>
>> wrote:
>>
>>> Hi Jess
>>>
>>> In multinomial models the linear model is set up as a (logit) difference
>>> in probability between an outcome and some base-line outcome. Often, as
>>> here, the base-line outcome is arbitrary, and so the idh structure is a
>>> little odd. For example, if A is the base line category, idh assumes
>>> COV(B-A, C-A) = 0 which therefore assumes
>>> COV(B,C)+VAR(A) =COV(A,B)+COV(C,A). It's not clear why this would be the
>>> case. Perhaps a more reasonable, but less parameter rich, option would be
>>> to have:
>>>
>>> ~idv(Section+trait:Section)
>>>
>>> which parameterises the Section covariance matrix by a single parameter
>>> (rather than 6). The term idv(Section+trait:Section) fits a 3x3 covariance
>>> matrix of the form v*(I+J) where v is the estimated variance. This assumes
>>> i) Sections are repeatable in outcome, but knowing that a Section has an
>>> increased 'preference' for A doesn?t tell you whether it also has an
>>> increased preference for one of the other categories and ii) the
>>> repeatability for each outcome within sites is the same (on the latent
>>> scale).
>>>
>>> To test groups of effects (in your case the 3 culling:trait effects), I
>>> usually use a Wald test and the posterior covariances (see here
>>> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2017q3/025930.html).
>>> It's far from correct and so Walid's suggestions may be better, but
>>> small-scale simulations suggests it has good frequentist properties.
>>>
>>> To add predator presence you can just add a predator:trait effect into
>>> the linear model. If the culling and predator factors do not vary within
>>> sites then you probably don't have enough information to reliably estimate
>>> these effects.
>>>
>>> Cheers,
>>>
>>> Jarrod
>>>
>>>
>>>
>>>
>>>
>>>
>>> > On 19 Jul 2022, at 18:17, Walid Mawass <walidmawass10 at gmail.com>
>>> wrote:
>>> >
>>> > This email was sent to you by someone outside the University.
>>> > You should only click on links or attachments if you are certain that
>>> the email is genuine and the content is safe.
>>> >
>>> > Hey Jess,
>>> >
>>> > 1) Yes that is correct
>>> >
>>> > 2) To my knowledge there is a rule of thumb, where you set the nitt (#
>>> of
>>> > iterations) to a large number that includes the burnin amount, then you
>>> > choose your thinning interval (sampling of the chain). For example,
>>> this is
>>> > what I would use: nitt= 150000, burnin=50000, thin=100. This will give
>>> you
>>> > a decent burnin and a final sample of 1000 saved iterations. Note
>>> however
>>> > that this does not have to increase the effective sample size for
>>> certain
>>> > variables, but it might do the trick.
>>> >
>>> > 3) hmm...I think one way to do it is to make predictions using the
>>> above
>>> > model and interpret the patterns you see for each relationship you are
>>> > interested in. Another way to compare effect size would be to use
>>> bayesian
>>> > posterior indices. I suggest these two papers by Makowski et al.
>>> (2019a &
>>> > b) that present both interesting posterior indices to use with Bayesian
>>> > statistical analysis and an associated R package that does the job of
>>> > computing these indices, *bayestestR*.
>>> >
>>> > Good luck
>>> > --
>>> > Walid Mawass
>>> > Ph.D. candidate in Evolutionary Biology - UQTR
>>> > *Currently* Postdoctoral Research Associate
>>> > Masel Lab - University of Arizona
>>> >
>>> >
>>> > On Sun, Jul 17, 2022 at 11:32 PM jessica comley <
>>> jessiecomley44 at gmail.com>
>>> > wrote:
>>> >
>>> >> Hi Walid,
>>> >>
>>> >> Thank you for your reply, I greatly appreciate it. I have a few more
>>> >> questions and if you could help that would be great.
>>> >>
>>> >> I tested for correlation between activities and the 14 Sections and
>>> the
>>> >> correlation comes out as low. Therefore I have changed my code to use
>>> idh()
>>> >> instead of us as suggested:
>>> >>
>>> >> test1c.5b <- MCMCglmm(activity ~ -1 + at.level(culling,1):trait +
>>> >> at.level(culling, 2):trait, random=~idh(trait):Section, rcov =
>>> >> ~idh(trait):units, data = caracal, family = "categorical", prior =
>>> prior,
>>> >> burnin=5000, nitt=80000)
>>> >>
>>> >> 1) Is this correct?
>>> >>
>>> >> 2) Increasing the number of interactions increases the effective
>>> sample
>>> >> size, therefore is there a general rule of thumb as to how large your
>>> >> effective sample size should be?
>>> >>
>>> >> 3) I understand how to use and interpret the results of HPDinterval
>>> (i.e.
>>> >> if intervals do not overlap 0 then relationship is strong), but how
>>> am I
>>> >> able to test the relationship between all four activities and fixed
>>> effects
>>> >> and not just have the three categories (i.e. diurnal, dusk, nocturnal)
>>> >> compared to the base category (dawn)? For example, I am also
>>> interested in
>>> >> whether there is a significant/strong relationship between activities
>>> of
>>> >> caracal at dusk with culling(Lethal)/no culling(none) compared to
>>> >> activities of caracal at diurnal with culling(Lethal)/no
>>> culling(none).
>>> >>
>>> >> Below is an example of our dataset:
>>> >> Camera Section CameraID Animal predator culling activity
>>> >> 1a Bucklands Bucklands1a Caracal low Lethal diurnal
>>> >> 1a Bucklands Bucklands1a Caracal low Lethal dawn
>>> >> 2a Bucklands Bucklands2a Caracal low Lethal dusk
>>> >> 2a Bucklands Bucklands2a Caracal low Lethal diurnal
>>> >> 3a Bucklands Bucklands3a Caracal low Lethal dawn
>>> >> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>>> >> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>>> >> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>>> >> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>>> >> Cam 2  Colchester ColchesterCam 2  Caracal high none diurnal
>>> >> Cam 2  Colchester ColchesterCam 2  Caracal high none diurnal
>>> >> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
>>> >> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
>>> >> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
>>> >> Cam 4  Colchester ColchesterCam 4  Caracal high none diurnal
>>> >> Cam 4  Colchester ColchesterCam 4  Caracal high none diurnal
>>> >> Cam 4  Colchester ColchesterCam 4  Caracal high none nocturnal
>>> >> 1a Connaught Connaught1a Caracal low Lethal nocturnal
>>> >> 1a Connaught Connaught1a Caracal low Lethal nocturnal
>>> >> 1d Connaught Connaught1d Caracal low Lethal diurnal
>>> >> 3B Connaught Connaught3B Caracal low Lethal diurnal
>>> >> 3B Connaught Connaught3B Caracal low Lethal diurnal
>>> >> 4a Connaught Connaught4a Caracal low Lethal nocturnal
>>> >> 4a Connaught Connaught4a Caracal low Lethal nocturnal
>>> >> 4b Connaught Connaught4b Caracal low Lethal diurnal
>>> >> 6a Connaught Connaught6a Caracal low Lethal nocturnal
>>> >> 6b Connaught Connaught6b Caracal low Lethal diurnal
>>> >> 7a Connaught Connaught7a Caracal low Lethal nocturnal
>>> >> 9a Connaught Connaught9a Caracal low Lethal nocturnal
>>> >> 9d Connaught Connaught9d Caracal low Lethal nocturnal
>>> >> 9d Connaught Connaught9d Caracal low Lethal dusk
>>> >> 7d Diepdam Diepdam7d Caracal absent Lethal dusk
>>> >> 8d Diepdam Diepdam8d Caracal absent Lethal diurnal
>>> >> 9c Diepdam Diepdam9c Caracal absent Lethal nocturnal
>>> >>
>>> >> All the best,
>>> >> Jess
>>> >>
>>> >>
>>> >> On Fri, Jul 15, 2022 at 11:37 PM Walid Mawass <
>>> walidmawass10 at gmail.com>
>>> >> wrote:
>>> >>
>>> >>> Hello,
>>> >>>
>>> >>> I don't think I can specifically help you with some of your
>>> inquiries.
>>> >>> However, I do want to comment on a few things that might need some
>>> >>> attention.
>>> >>>
>>> >>> First, MCMCglmm is based on a Bayesian implementation and does not
>>> >>> compute p-values to compare. What you need to compare are the
>>> posterior
>>> >>> distributions of your effect sizes. This can be done visually using
>>> the
>>> >>> base plot function in R. Or by comparing the HPD intervals and the
>>> mode (or
>>> >>> mean) of the posterior distributions.
>>> >>>
>>> >>> Second, I have no idea what your data structure looks like (which
>>> makes
>>> >>> it hard to interpret model results), but the effective sample size
>>> (from
>>> >>> the 5500 saved iterations sample) for your random variable Section
>>> is very
>>> >>> low (the same applies for your fixed effects). You should consider
>>> this
>>> >>> issue and look again at your assumption of correlation between
>>> >>> activities for the 14 sections you have in your dataset. If you do
>>> not
>>> >>> expect among activity correlations then you can use the idh()
>>> function
>>> >>> instead of us().
>>> >>>
>>> >>> Hopefully this helps and in hope that people on this list with more
>>> >>> knowledge of these models will help out.
>>> >>>
>>> >>> Best,
>>> >>> --
>>> >>> Walid Mawass
>>> >>> Ph.D. candidate in Evolutionary Biology - UQTR
>>> >>> *Currently* Postdoctoral Research Associate
>>> >>> Masel Lab - University of Arizona
>>> >>>
>>> >>>
>>> >>> On Fri, Jul 15, 2022 at 8:49 AM jessica comley <
>>> jessiecomley44 at gmail.com>
>>> >>> wrote:
>>> >>>
>>> >>>> Dear all,
>>> >>>>
>>> >>>> I am hoping that someone will be able to help me with conducting
>>> MCMCglmm
>>> >>>> multinomial models.
>>> >>>>
>>> >>>> The data I am working with is for black-backed jackal (bbj) and
>>> carcal.
>>> >>>> For
>>> >>>> each species we have a multinomial response variable called activity
>>> >>>> which
>>> >>>> has four categories (dawn, diurnal, dusk, nocturnal). We have two
>>> >>>> categorical fixed effects which are 1) culling (none, lethal) and 2)
>>> >>>> predator presence (absent, high, low). We also have a categorical
>>> >>>> variable
>>> >>>> called Section (made up of 14 different reserves/ farms where the
>>> >>>> activity
>>> >>>> of caracal and bbj were recorded). There are 273 observations for
>>> caracal
>>> >>>> and 4399 for bbj. We are wanting to test the effects of culling and
>>> >>>> predators on caracal and bbj activity separately.
>>> >>>>
>>> >>>> I have been working through Jarrod Hadfields course notes,
>>> particularly
>>> >>>> with regards to Chapter 5.2. The chi-square analyses reveal that the
>>> >>>> frequencies of culling and predators differ as do activities.
>>> >>>>
>>> >>>> I have managed to work out the specific probabilities for the
>>> culling
>>> >>>> none
>>> >>>> vs culling lethal for each activity (dawn, diurnal, dusk,
>>> nocturnal) for
>>> >>>> caracal, but I'm confused as to how to determine p-values to
>>> determine
>>> >>>> which activities culling none vs culling lethal are affecting?
>>> >>>>
>>> >>>> Myy code and outcomes are pasted below with questions stated in
>>> bold.
>>> >>>>
>>> >>>> caracal2 <- read.csv("caracal_new.csv", header=T)
>>> >>>> caracal <- as.data.frame(unclass(caracal2), stringsAsFactors = TRUE)
>>> >>>>
>>> >>>> #Chi-squared tests
>>> >>>> Ctable1 <- table(caracal$activity, caracal$culling)
>>> >>>> chisq.test(rowSums(Ctable1)) #strongly suggests activities differ
>>> >>>> chisq.test(Ctable1)#strongly suggests culling category differs
>>> >>>>
>>> >>>> Ctable2 <- table(caracal$activity, caracal$predator)
>>> >>>> chisq.test(rowSums(Ctable2))#strongly suggests activities differ
>>> >>>> chisq.test(Ctable2)#strongly suggests predator category differs
>>> >>>>
>>> >>>> prior = list(R = list(fix=1, V=(1/k) * (I + J)), G = list(G1=list(V
>>> =
>>> >>>> diag(k-1), nu=1)))
>>> >>>> test1c.5 <- MCMCglmm(activity ~ -1 + at.level(culling,1):trait +
>>> >>>> at.level(culling, 2):trait, random=~us(trait):Section, rcov =
>>> >>>> ~us(trait):units, data = caracal, family = "categorical", prior =
>>> prior,
>>> >>>> burnin=5000, nitt=60000)
>>> >>>> *##I'm not sure how to add the three predator levels to this model
>>> or if
>>> >>>> it
>>> >>>> would be appropriate?*
>>> >>>>
>>> >>>>
>>> >>>> k <- length(levels(caracal$activity))
>>> >>>> I <- diag(k-1)
>>> >>>> J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))
>>> >>>> IJ <- (1/k) *(diag(k-1) + matrix(1,k-1, k-1))
>>> >>>>
>>> >>>> contrasts(caracal$activity)
>>> >>>>
>>> >>>> #culling lethal
>>> >>>> Delta <- cbind(c(0,1,0,0), c(0,0,1,0), c(0,0,0,1))
>>> >>>> c2 <- (16 * sqrt(3)/(15 * pi))^2
>>> >>>> D <- ginv(Delta %*% t(Delta)) %*% Delta
>>> >>>> Int <- t(apply(test1c.5$Sol[,1:3],1, function(x) + D %*% (x/sqrt(1
>>> + c2 *
>>> >>>> diag(IJ)))))
>>> >>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>> >>>>
>>> >>>> prop.table(Ctable1[,1])
>>> >>>>
>>> >>>> #culling none
>>> >>>> Delta <- cbind(c(0,1,0,0), c(0,0,1,0), c(0,0,0,1))
>>> >>>> c2 <- (16 * sqrt(3)/(15 * pi))^2
>>> >>>> D <- ginv(Delta %*% t(Delta)) %*% Delta
>>> >>>> Int <- t(apply(test1c.5$Sol[,4:6],1, function(x) + D %*% (x/sqrt(1
>>> + c2 *
>>> >>>> diag(IJ)))))
>>> >>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>> >>>>
>>> >>>> prop.table((Ctable1[,2]))
>>> >>>>
>>> >>>> HPDinterval(test1c.5$Sol)
>>> >>>>
>>> >>>> #model summary
>>> >>>>> summary(test1c.5)
>>> >>>>
>>> >>>> Iterations = 5001:59991
>>> >>>> Thinning interval  = 10
>>> >>>> Sample size  = 5500
>>> >>>>
>>> >>>> DIC: 699.7014
>>> >>>>
>>> >>>> G-structure:  ~us(trait):Section
>>> >>>>
>>> >>>>                                                        post.mean
>>> l-95%
>>> >>>> CI
>>> >>>> u-95% CI eff.samp
>>> >>>> traitactivity.diurnal:traitactivity.diurnal.Section        1.8124
>>> >>>> 0.09784
>>> >>>>   5.665    77.01
>>> >>>> traitactivity.dusk:traitactivity.diurnal.Section           0.8450
>>> >>>> -0.83585
>>> >>>>   3.856    64.17
>>> >>>> traitactivity.nocturnal:traitactivity.diurnal.Section      1.3621
>>> >>>> -1.19129
>>> >>>>   6.157    58.48
>>> >>>> traitactivity.diurnal:traitactivity.dusk.Section           0.8450
>>> >>>> -0.83585
>>> >>>>   3.856    64.17
>>> >>>> traitactivity.dusk:traitactivity.dusk.Section              1.2034
>>> >>>> 0.07090
>>> >>>>   3.681   102.16
>>> >>>> traitactivity.nocturnal:traitactivity.dusk.Section         0.7505
>>> >>>> -1.77113
>>> >>>>   4.524    43.53
>>> >>>> traitactivity.diurnal:traitactivity.nocturnal.Section      1.3621
>>> >>>> -1.19129
>>> >>>>   6.157    58.48
>>> >>>> traitactivity.dusk:traitactivity.nocturnal.Section         0.7505
>>> >>>> -1.77113
>>> >>>>   4.524    43.53
>>> >>>> traitactivity.nocturnal:traitactivity.nocturnal.Section    2.7148
>>> >>>> 0.09401
>>> >>>>   8.397    76.59
>>> >>>>
>>> >>>> R-structure:  ~us(trait):units
>>> >>>>
>>> >>>>                                                      post.mean
>>> l-95% CI
>>> >>>> u-95% CI eff.samp
>>> >>>> traitactivity.diurnal:traitactivity.diurnal.units          0.50
>>>  0.50
>>> >>>>  0.50        0
>>> >>>> traitactivity.dusk:traitactivity.diurnal.units             0.25
>>>  0.25
>>> >>>>  0.25        0
>>> >>>> traitactivity.nocturnal:traitactivity.diurnal.units        0.25
>>>  0.25
>>> >>>>  0.25        0
>>> >>>> traitactivity.diurnal:traitactivity.dusk.units             0.25
>>>  0.25
>>> >>>>  0.25        0
>>> >>>> traitactivity.dusk:traitactivity.dusk.units                0.50
>>>  0.50
>>> >>>>  0.50        0
>>> >>>> traitactivity.nocturnal:traitactivity.dusk.units           0.25
>>>  0.25
>>> >>>>  0.25        0
>>> >>>> traitactivity.diurnal:traitactivity.nocturnal.units        0.25
>>>  0.25
>>> >>>>  0.25        0
>>> >>>> traitactivity.dusk:traitactivity.nocturnal.units           0.25
>>>  0.25
>>> >>>>  0.25        0
>>> >>>> traitactivity.nocturnal:traitactivity.nocturnal.units      0.50
>>>  0.50
>>> >>>>  0.50        0
>>> >>>>
>>> >>>> Location effects: activity ~ -1 + at.level(culling, 1):trait +
>>> >>>> at.level(culling, 2):trait
>>> >>>>
>>> >>>>                                             post.mean l-95% CI
>>> u-95% CI
>>> >>>> eff.samp  pMCMC
>>> >>>> at.level(culling, 1):traitactivity.diurnal      1.2306  -0.0533
>>>  2.6793
>>> >>>> 145.29 0.0418 *
>>> >>>> at.level(culling, 1):traitactivity.dusk         0.6605  -0.6006
>>>  2.0761
>>> >>>> 92.91 0.2840
>>> >>>> at.level(culling, 1):traitactivity.nocturnal    1.6090   0.0914
>>>  3.1356
>>> >>>> 151.02 0.0265 *
>>> >>>> traitactivity.diurnal:at.level(culling, 2)      1.2664  -0.1552
>>>  2.7750
>>> >>>> 226.40 0.0604 .
>>> >>>> traitactivity.dusk:at.level(culling, 2)         0.3533  -0.9898
>>>  1.5218
>>> >>>> 148.44 0.5447
>>> >>>> traitactivity.nocturnal:at.level(culling, 2)    1.0447  -0.6405
>>>  2.8354
>>> >>>> 346.40 0.1618
>>> >>>> ---
>>> >>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>> >>>>
>>> >>>> *##So for the model summary I get that lethal culling at activity
>>> diurnal
>>> >>>> is significantly different from lethal culling at dawn (its the base
>>> >>>> reference), but I'm also interested in whether lethal culling at
>>> activity
>>> >>>> diurnal is different from lethal culling at dusk for example. Is
>>> this
>>> >>>> possible? *
>>> >>>>
>>> >>>> #outcomes culling lethal
>>> >>>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>> >>>>
>>> >>>> Iterations = 1:5500
>>> >>>> Thinning interval = 1
>>> >>>> Number of chains = 1
>>> >>>> Sample size per chain = 5500
>>> >>>>
>>> >>>> 1. Empirical mean and standard deviation for each variable,
>>> >>>>   plus standard error of the mean:
>>> >>>>
>>> >>>>       Mean      SD  Naive SE Time-series SE
>>> >>>> [1,] 0.1253 0.05565 0.0007504       0.002484
>>> >>>> [2,] 0.3748 0.10497 0.0014155       0.003204
>>> >>>> [3,] 0.1757 0.06640 0.0008954       0.002515
>>> >>>> [4,] 0.3242 0.11939 0.0016099       0.003514
>>> >>>>
>>> >>>> 2. Quantiles for each variable:
>>> >>>>
>>> >>>>        2.5%     25%    50%    75%  97.5%
>>> >>>> var1 0.03641 0.08695 0.1198 0.1554 0.2553
>>> >>>> var2 0.17298 0.30580 0.3704 0.4431 0.5896
>>> >>>> var3 0.06166 0.12913 0.1705 0.2161 0.3215
>>> >>>> var4 0.12610 0.23999 0.3090 0.3901 0.6045
>>> >>>>
>>> >>>>> prop.table(Ctable1[,1])
>>> >>>>     dawn   diurnal      dusk nocturnal
>>> >>>> 0.1250000 0.2812500 0.1770833 0.4166667
>>> >>>>
>>> >>>>
>>> >>>> #outcomes culling none
>>> >>>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>> >>>>
>>> >>>> Iterations = 1:5500
>>> >>>> Thinning interval = 1
>>> >>>> Number of chains = 1
>>> >>>> Sample size per chain = 5500
>>> >>>>
>>> >>>> 1. Empirical mean and standard deviation for each variable,
>>> >>>>   plus standard error of the mean:
>>> >>>>
>>> >>>>       Mean      SD  Naive SE Time-series SE
>>> >>>> [1,] 0.1288 0.06141 0.0008280       0.002787
>>> >>>> [2,] 0.3804 0.10406 0.0014032       0.002662
>>> >>>> [3,] 0.1710 0.06844 0.0009228       0.002592
>>> >>>> [4,] 0.3198 0.11812 0.0015928       0.002956
>>> >>>>
>>> >>>> 2. Quantiles for each variable:
>>> >>>>
>>> >>>>        2.5%     25%    50%    75%  97.5%
>>> >>>> var1 0.02891 0.08896 0.1220 0.1594 0.2685
>>> >>>> var2 0.18007 0.31094 0.3783 0.4474 0.5965
>>> >>>> var3 0.05840 0.12425 0.1634 0.2083 0.3250
>>> >>>> var4 0.12430 0.23921 0.3077 0.3862 0.5964
>>> >>>>
>>> >>>>> prop.table((Ctable1[,2]))
>>> >>>>     dawn   diurnal      dusk nocturnal
>>> >>>> 0.1306818 0.4375000 0.1875000 0.2443182
>>> >>>>
>>> >>>> Any help or guidance will be greatly appreciated.
>>> >>>>
>>> >>>> All the best,
>>> >>>> Jess
>>> >>>>
>>> >>>> --
>>> >>>> Jessica Comley (PhD)
>>> >>>> Research Scientist
>>> >>>>
>>> >>>>        [[alternative HTML version deleted]]
>>> >>>>
>>> >>>> _______________________________________________
>>> >>>> R-sig-mixed-models at r-project.org mailing list
>>> >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> >>>>
>>> >>>
>>> >>
>>> >> --
>>> >> Jessica Comley (PhD)
>>> >> Research Scientist
>>> >>
>>> >>
>>> >
>>> >        [[alternative HTML version deleted]]
>>> >
>>> > _______________________________________________
>>> > R-sig-mixed-models at r-project.org mailing list
>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>> The University of Edinburgh is a charitable body, registered in
>>> Scotland, with registration number SC005336. Is e buidheann carthannais a
>>> th? ann an Oilthigh Dh?n ?ideann, cl?raichte an Alba, ?ireamh cl?raidh
>>> SC005336.
>>>
>>
>>
>> --
>> Jessica Comley (PhD)
>> Research Scientist
>>
>>
>>
>
> --
> Dr Jessica Comley
> Lecturer: Environmental and Life Sciences
> Faculty of Science
> Universiti Brunei Darussalam
>
> Email: jessica.comley at ubd.edu.bn
>
>

-- 
Dr Jessica Comley
Lecturer: Environmental and Life Sciences
Faculty of Science
Universiti Brunei Darussalam

Email: jessica.comley at ubd.edu.bn

	[[alternative HTML version deleted]]


From j@h@d||e|d @end|ng |rom ed@@c@uk  Wed Jul 27 06:14:30 2022
From: j@h@d||e|d @end|ng |rom ed@@c@uk (Jarrod Hadfield)
Date: Wed, 27 Jul 2022 04:14:30 +0000
Subject: [R-sig-ME] MCMCglmm with multinomial models
In-Reply-To: <CANdGWBFY0s2y=qaKhwKAU5cvg2xW5rQ_3CmmXvvj+q5v-Fee3g@mail.gmail.com>
References: <CANdGWBHgzmN15cvGu7zU90o-+sZn4fUS92_nanb6OYYW8f2rog@mail.gmail.com>
 <CAJtCY7XH=AACiNbTo4SLo4gMQnM7ub1vVEOwGGqB-AvuJf5+Jw@mail.gmail.com>
 <CANdGWBFmXtPEvaREGQenkqq403+toEFJvLMgPTzdFWGix-ggGA@mail.gmail.com>
 <CAJtCY7XW=aT50ZCGUr2Y8ERPT1x2UC686Odti8n1kTRj4hC+LQ@mail.gmail.com>
 <57338F74-D980-4078-A389-EDA67E79C1A6@ed.ac.uk>
 <CANdGWBF3uc7SM0-a7uW54iNBPvRHPTTG+jd8-yjYzUz49o-N4g@mail.gmail.com>
 <63B269B7-6C5F-4A0C-BC08-51FE97C621BF@ed.ac.uk>
 <CANdGWBE5fEdZpnKiJ8ZgaRgFChG4=K5zp2Gpufq-p8KRddX7fw@mail.gmail.com>
 <CANdGWBFY0s2y=qaKhwKAU5cvg2xW5rQ_3CmmXvvj+q5v-Fee3g@mail.gmail.com>
Message-ID: <56260042-774A-4135-9E38-986F98546F45@ed.ac.uk>

Hi,

1/ My guess is that there is a mistake/typo in your data.frame: culling has 3 levels not 2. Does table(bbj$culling) return what you expect?

2/ They mean i) there is more diurnal activity under culling compared to whatever the mystery level of culling is. ii) there is more dawn activity when predators is low compared to absent.

3/ The indices should be for all terms involving the thing to be tested. So in the current model they should be 4:9 and 10:15 (not 3:5 and 6:8). This will change when you sort out your culling column (probably to 4:6 and 7:12). In my previous email I said you should be testing 3 effects for predator, but in fact there should be 6 (I thought predator had 3 levels not 2).

You might want a -1 in your model formula (i.e trait-1+trait:culling+trait:predator) to make the interpretation of the first 3 terms a little easier, but up to you.

Cheers,

Jarrod






On 27 Jul 2022, at 04:42, jessica comley <jessiecomley44 at gmail.com<mailto:jessiecomley44 at gmail.com>> wrote:

This email was sent to you by someone outside the University.
You should only click on links or attachments if you are certain that the email is genuine and the content is safe.
Dear Jarrod,

Sorry to bother you again, I just want to make sure I am doing this correctly and understanding my results.

I used the model you suggested:
prior1=list(R=list(V=1, nu=0.002))
m1<-MCMCglmm(cbind(dawn, diurnal, dusk, nocturnal)~trait+trait:culling+trait:predator, rcov=~idv(units+trait:units), prior=prior1, data=bbj, family="multinomial4", nitt= 150000)

And this is my outcome:
Iterations = 3001:149991
 Thinning interval  = 10
 Sample size  = 14700

 DIC: 10312.95

 R-structure:  ~idv(units + trait:units)

            post.mean  l-95% CI u-95% CI eff.samp
trait:units   0.01932 0.0002102  0.07042      441

 Location effects: cbind(dawn, diurnal, dusk, nocturnal) ~ trait + trait:culling + trait:predator

                           post.mean  l-95% CI  u-95% CI eff.samp   pMCMC
(Intercept)                -2.018903 -2.677830 -1.335305    609.1 < 7e-05 ***
traitdiurnal                0.542636 -0.363766  1.405230    644.6 0.22068
traitdusk                  -0.047952 -0.984923  0.917710    374.6 0.91850
traitdawn:cullingLethal     0.534474  0.003076  1.058211    596.8 0.05524 .
traitdiurnal:cullingLethal  0.232597 -0.369959  0.834347    404.7 0.42789
traitdusk:cullingLethal     0.376191 -0.217707  0.964636    408.2 0.19782
traitdawn:cullingnone      -0.163961 -0.573477  0.298182   2945.5 0.38245
traitdiurnal:cullingnone    0.674041  0.247724  1.101917   2825.0 0.00952 **
traitdusk:cullingnone       0.449710 -0.014263  0.874925   1683.9 0.05102 .
traitdawn:predatorhigh      0.456119 -0.206435  1.151283    561.7 0.18531
traitdiurnal:predatorhigh  -0.303114 -0.976842  0.377294    479.9 0.36939
traitdusk:predatorhigh      0.108262 -0.674552  0.895819    256.7 0.76122
traitdawn:predatorlow       0.756262  0.160407  1.323520    418.1 0.01279 *
traitdiurnal:predatorlow    0.136875 -0.446984  0.750518    305.7 0.65619
traitdusk:predatorlow       0.422497 -0.303586  1.145038    194.9 0.22857
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

1) Why do the 2 categories for culling both show up but then only 2 of the three categories for predator show up? i.e. predatorabsent is missing?

2) Do these results mean that i) diurnal activity and lethal culling is sig different from nocturnal activity and lethal culling; ii) dawn activity and predator low is sig different from nocturnal activity and predator low?

3) Is this the correct way and interpretation of the within group effects?
##culling lethal
 aod::wald.test(cov(m1$Sol[,3:5]), colMeans(m1$Sol[,3:5]),Terms=1:3)$result$chi2["P"]
        P
0.1638938

##culling  none
aod::wald.test(cov(m1$Sol[,6:8]), colMeans(m1$Sol[,6:8]),Terms=1:3)$result$chi2["P"]
          P
0.006497424

So these results show us that culling none has an effect on activity?

Thank you in advance,
Jess

On Wed, Jul 27, 2022 at 8:20 AM jessica comley <jessiecomley44 at gmail.com<mailto:jessiecomley44 at gmail.com>> wrote:
Dear Jarrod,

Thank you so much for your help, I greatly appreciate it!

All the best,
Jess

On Wed, Jul 27, 2022 at 3:32 AM Jarrod Hadfield <j.hadfield at ed.ac.uk<mailto:j.hadfield at ed.ac.uk>> wrote:
Hi Jess,

Section should definitely not be left out, but I would imagine it is going to be very difficult to separate culling, predator and Section effects - I would expect the credible intervals to be large.

As mentioned in my previous post you can test for an effect of culling by fitting the model

~trait+trait:culling+trait:predator

And then fitting a Wald test to the three terms with 'culling' in. The effect of predator can be tested similarly but with the 3 terms with 'predator' in.

Since your covariates do not vary within Section it will be much easier to aggregate the counts at the Section level (i.e have a data frame with 14 rows and 1 column for each activity with the number observed for each activity) and fit family="multinomial". You can then get rid of the random formula as the Section effects are now effectively the residuals. Given the lack of replication I would advise using the idv formula that I suggested previously and hope the model isn't too misspecified:

prior=list(R=list(V=1, nu=0.002))

m1<-MCMCglmm(cbind(dawn, diurnal, dusk, nocturnal)~trait+trait:culling+trait:predator, rcov=~idv(units+trait:units), prior=prior, ...)

Note this models is identical to the original model, it's just parameterised in a more efficient way.

Cheers,

Jarrod




On 25 Jul 2022, at 03:52, jessica comley <jessiecomley44 at gmail.com<mailto:jessiecomley44 at gmail.com>> wrote:

This email was sent to you by someone outside the University.
You should only click on links or attachments if you are certain that the email is genuine and the content is safe.
Dear Jarrod and Walid,

Thank you for your replies, it is greatly appreciated.

The predator and culling factors do not vary within sites. As shown in the example data in one of my previous emails, Bucklands only has culling as lethal and predator as low, whereas Colchester only has predator as high and culling as none.

We are trying to submit a paper on black-backed jackal and caracal activity in the presence of different culling practices and predator presence. The reviewers want us to try a GLMM approach to determine whether culling or predators have an effect on black-backed jackal or caracal activity.

Therefore, in your opinion how could be go about this given our data? Would it be advisable to leave out the random effect of Section?

All the best,
Jess

On Wed, Jul 20, 2022 at 3:06 PM Jarrod Hadfield <j.hadfield at ed.ac.uk<mailto:j.hadfield at ed.ac.uk>> wrote:
Hi Jess

In multinomial models the linear model is set up as a (logit) difference in probability between an outcome and some base-line outcome. Often, as here, the base-line outcome is arbitrary, and so the idh structure is a little odd. For example, if A is the base line category, idh assumes COV(B-A, C-A) = 0 which therefore assumes
COV(B,C)+VAR(A) =COV(A,B)+COV(C,A). It's not clear why this would be the case. Perhaps a more reasonable, but less parameter rich, option would be to have:

~idv(Section+trait:Section)

which parameterises the Section covariance matrix by a single parameter (rather than 6). The term idv(Section+trait:Section) fits a 3x3 covariance matrix of the form v*(I+J) where v is the estimated variance. This assumes i) Sections are repeatable in outcome, but knowing that a Section has an increased 'preference' for A doesn?t tell you whether it also has an increased preference for one of the other categories and ii) the repeatability for each outcome within sites is the same (on the latent scale).

To test groups of effects (in your case the 3 culling:trait effects), I usually use a Wald test and the posterior covariances (see here https://stat.ethz.ch/pipermail/r-sig-mixed-models/2017q3/025930.html). It's far from correct and so Walid's suggestions may be better, but small-scale simulations suggests it has good frequentist properties.

To add predator presence you can just add a predator:trait effect into the linear model. If the culling and predator factors do not vary within sites then you probably don't have enough information to reliably estimate these effects.

Cheers,

Jarrod






> On 19 Jul 2022, at 18:17, Walid Mawass <walidmawass10 at gmail.com<mailto:walidmawass10 at gmail.com>> wrote:
>
> This email was sent to you by someone outside the University.
> You should only click on links or attachments if you are certain that the email is genuine and the content is safe.
>
> Hey Jess,
>
> 1) Yes that is correct
>
> 2) To my knowledge there is a rule of thumb, where you set the nitt (# of
> iterations) to a large number that includes the burnin amount, then you
> choose your thinning interval (sampling of the chain). For example, this is
> what I would use: nitt= 150000, burnin=50000, thin=100. This will give you
> a decent burnin and a final sample of 1000 saved iterations. Note however
> that this does not have to increase the effective sample size for certain
> variables, but it might do the trick.
>
> 3) hmm...I think one way to do it is to make predictions using the above
> model and interpret the patterns you see for each relationship you are
> interested in. Another way to compare effect size would be to use bayesian
> posterior indices. I suggest these two papers by Makowski et al. (2019a &
> b) that present both interesting posterior indices to use with Bayesian
> statistical analysis and an associated R package that does the job of
> computing these indices, *bayestestR*.
>
> Good luck
> --
> Walid Mawass
> Ph.D. candidate in Evolutionary Biology - UQTR
> *Currently* Postdoctoral Research Associate
> Masel Lab - University of Arizona
>
>
> On Sun, Jul 17, 2022 at 11:32 PM jessica comley <jessiecomley44 at gmail.com<mailto:jessiecomley44 at gmail.com>>
> wrote:
>
>> Hi Walid,
>>
>> Thank you for your reply, I greatly appreciate it. I have a few more
>> questions and if you could help that would be great.
>>
>> I tested for correlation between activities and the 14 Sections and the
>> correlation comes out as low. Therefore I have changed my code to use idh()
>> instead of us as suggested:
>>
>> test1c.5b <- MCMCglmm(activity ~ -1 + at.level(culling,1):trait +
>> at.level(culling, 2):trait, random=~idh(trait):Section, rcov =
>> ~idh(trait):units, data = caracal, family = "categorical", prior = prior,
>> burnin=5000, nitt=80000)
>>
>> 1) Is this correct?
>>
>> 2) Increasing the number of interactions increases the effective sample
>> size, therefore is there a general rule of thumb as to how large your
>> effective sample size should be?
>>
>> 3) I understand how to use and interpret the results of HPDinterval (i.e.
>> if intervals do not overlap 0 then relationship is strong), but how am I
>> able to test the relationship between all four activities and fixed effects
>> and not just have the three categories (i.e. diurnal, dusk, nocturnal)
>> compared to the base category (dawn)? For example, I am also interested in
>> whether there is a significant/strong relationship between activities of
>> caracal at dusk with culling(Lethal)/no culling(none) compared to
>> activities of caracal at diurnal with culling(Lethal)/no culling(none).
>>
>> Below is an example of our dataset:
>> Camera Section CameraID Animal predator culling activity
>> 1a Bucklands Bucklands1a Caracal low Lethal diurnal
>> 1a Bucklands Bucklands1a Caracal low Lethal dawn
>> 2a Bucklands Bucklands2a Caracal low Lethal dusk
>> 2a Bucklands Bucklands2a Caracal low Lethal diurnal
>> 3a Bucklands Bucklands3a Caracal low Lethal dawn
>> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>> Cam 2  Colchester ColchesterCam 2  Caracal high none diurnal
>> Cam 2  Colchester ColchesterCam 2  Caracal high none diurnal
>> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
>> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
>> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
>> Cam 4  Colchester ColchesterCam 4  Caracal high none diurnal
>> Cam 4  Colchester ColchesterCam 4  Caracal high none diurnal
>> Cam 4  Colchester ColchesterCam 4  Caracal high none nocturnal
>> 1a Connaught Connaught1a Caracal low Lethal nocturnal
>> 1a Connaught Connaught1a Caracal low Lethal nocturnal
>> 1d Connaught Connaught1d Caracal low Lethal diurnal
>> 3B Connaught Connaught3B Caracal low Lethal diurnal
>> 3B Connaught Connaught3B Caracal low Lethal diurnal
>> 4a Connaught Connaught4a Caracal low Lethal nocturnal
>> 4a Connaught Connaught4a Caracal low Lethal nocturnal
>> 4b Connaught Connaught4b Caracal low Lethal diurnal
>> 6a Connaught Connaught6a Caracal low Lethal nocturnal
>> 6b Connaught Connaught6b Caracal low Lethal diurnal
>> 7a Connaught Connaught7a Caracal low Lethal nocturnal
>> 9a Connaught Connaught9a Caracal low Lethal nocturnal
>> 9d Connaught Connaught9d Caracal low Lethal nocturnal
>> 9d Connaught Connaught9d Caracal low Lethal dusk
>> 7d Diepdam Diepdam7d Caracal absent Lethal dusk
>> 8d Diepdam Diepdam8d Caracal absent Lethal diurnal
>> 9c Diepdam Diepdam9c Caracal absent Lethal nocturnal
>>
>> All the best,
>> Jess
>>
>>
>> On Fri, Jul 15, 2022 at 11:37 PM Walid Mawass <walidmawass10 at gmail.com<mailto:walidmawass10 at gmail.com>>
>> wrote:
>>
>>> Hello,
>>>
>>> I don't think I can specifically help you with some of your inquiries.
>>> However, I do want to comment on a few things that might need some
>>> attention.
>>>
>>> First, MCMCglmm is based on a Bayesian implementation and does not
>>> compute p-values to compare. What you need to compare are the posterior
>>> distributions of your effect sizes. This can be done visually using the
>>> base plot function in R. Or by comparing the HPD intervals and the mode (or
>>> mean) of the posterior distributions.
>>>
>>> Second, I have no idea what your data structure looks like (which makes
>>> it hard to interpret model results), but the effective sample size (from
>>> the 5500 saved iterations sample) for your random variable Section is very
>>> low (the same applies for your fixed effects). You should consider this
>>> issue and look again at your assumption of correlation between
>>> activities for the 14 sections you have in your dataset. If you do not
>>> expect among activity correlations then you can use the idh() function
>>> instead of us().
>>>
>>> Hopefully this helps and in hope that people on this list with more
>>> knowledge of these models will help out.
>>>
>>> Best,
>>> --
>>> Walid Mawass
>>> Ph.D. candidate in Evolutionary Biology - UQTR
>>> *Currently* Postdoctoral Research Associate
>>> Masel Lab - University of Arizona
>>>
>>>
>>> On Fri, Jul 15, 2022 at 8:49 AM jessica comley <jessiecomley44 at gmail.com<mailto:jessiecomley44 at gmail.com>>
>>> wrote:
>>>
>>>> Dear all,
>>>>
>>>> I am hoping that someone will be able to help me with conducting MCMCglmm
>>>> multinomial models.
>>>>
>>>> The data I am working with is for black-backed jackal (bbj) and carcal.
>>>> For
>>>> each species we have a multinomial response variable called activity
>>>> which
>>>> has four categories (dawn, diurnal, dusk, nocturnal). We have two
>>>> categorical fixed effects which are 1) culling (none, lethal) and 2)
>>>> predator presence (absent, high, low). We also have a categorical
>>>> variable
>>>> called Section (made up of 14 different reserves/ farms where the
>>>> activity
>>>> of caracal and bbj were recorded). There are 273 observations for caracal
>>>> and 4399 for bbj. We are wanting to test the effects of culling and
>>>> predators on caracal and bbj activity separately.
>>>>
>>>> I have been working through Jarrod Hadfields course notes, particularly
>>>> with regards to Chapter 5.2. The chi-square analyses reveal that the
>>>> frequencies of culling and predators differ as do activities.
>>>>
>>>> I have managed to work out the specific probabilities for the culling
>>>> none
>>>> vs culling lethal for each activity (dawn, diurnal, dusk, nocturnal) for
>>>> caracal, but I'm confused as to how to determine p-values to determine
>>>> which activities culling none vs culling lethal are affecting?
>>>>
>>>> Myy code and outcomes are pasted below with questions stated in bold.
>>>>
>>>> caracal2 <- read.csv("caracal_new.csv", header=T)
>>>> caracal <- as.data.frame(unclass(caracal2), stringsAsFactors = TRUE)
>>>>
>>>> #Chi-squared tests
>>>> Ctable1 <- table(caracal$activity, caracal$culling)
>>>> chisq.test(rowSums(Ctable1)) #strongly suggests activities differ
>>>> chisq.test(Ctable1)#strongly suggests culling category differs
>>>>
>>>> Ctable2 <- table(caracal$activity, caracal$predator)
>>>> chisq.test(rowSums(Ctable2))#strongly suggests activities differ
>>>> chisq.test(Ctable2)#strongly suggests predator category differs
>>>>
>>>> prior = list(R = list(fix=1, V=(1/k) * (I + J)), G = list(G1=list(V =
>>>> diag(k-1), nu=1)))
>>>> test1c.5 <- MCMCglmm(activity ~ -1 + at.level(culling,1):trait +
>>>> at.level(culling, 2):trait, random=~us(trait):Section, rcov =
>>>> ~us(trait):units, data = caracal, family = "categorical", prior = prior,
>>>> burnin=5000, nitt=60000)
>>>> *##I'm not sure how to add the three predator levels to this model or if
>>>> it
>>>> would be appropriate?*
>>>>
>>>>
>>>> k <- length(levels(caracal$activity))
>>>> I <- diag(k-1)
>>>> J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))
>>>> IJ <- (1/k) *(diag(k-1) + matrix(1,k-1, k-1))
>>>>
>>>> contrasts(caracal$activity)
>>>>
>>>> #culling lethal
>>>> Delta <- cbind(c(0,1,0,0), c(0,0,1,0), c(0,0,0,1))
>>>> c2 <- (16 * sqrt(3)/(15 * pi))^2
>>>> D <- ginv(Delta %*% t(Delta)) %*% Delta
>>>> Int <- t(apply(test1c.5$Sol[,1:3],1, function(x) + D %*% (x/sqrt(1 + c2 *
>>>> diag(IJ)))))
>>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>>
>>>> prop.table(Ctable1[,1])
>>>>
>>>> #culling none
>>>> Delta <- cbind(c(0,1,0,0), c(0,0,1,0), c(0,0,0,1))
>>>> c2 <- (16 * sqrt(3)/(15 * pi))^2
>>>> D <- ginv(Delta %*% t(Delta)) %*% Delta
>>>> Int <- t(apply(test1c.5$Sol[,4:6],1, function(x) + D %*% (x/sqrt(1 + c2 *
>>>> diag(IJ)))))
>>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>>
>>>> prop.table((Ctable1[,2]))
>>>>
>>>> HPDinterval(test1c.5$Sol)
>>>>
>>>> #model summary
>>>>> summary(test1c.5)
>>>>
>>>> Iterations = 5001:59991
>>>> Thinning interval  = 10
>>>> Sample size  = 5500
>>>>
>>>> DIC: 699.7014
>>>>
>>>> G-structure:  ~us(trait):Section
>>>>
>>>>                                                        post.mean l-95%
>>>> CI
>>>> u-95% CI eff.samp
>>>> traitactivity.diurnal:traitactivity.diurnal.Section        1.8124
>>>> 0.09784
>>>>   5.665    77.01
>>>> traitactivity.dusk:traitactivity.diurnal.Section           0.8450
>>>> -0.83585
>>>>   3.856    64.17
>>>> traitactivity.nocturnal:traitactivity.diurnal.Section      1.3621
>>>> -1.19129
>>>>   6.157    58.48
>>>> traitactivity.diurnal:traitactivity.dusk.Section           0.8450
>>>> -0.83585
>>>>   3.856    64.17
>>>> traitactivity.dusk:traitactivity.dusk.Section              1.2034
>>>> 0.07090
>>>>   3.681   102.16
>>>> traitactivity.nocturnal:traitactivity.dusk.Section         0.7505
>>>> -1.77113
>>>>   4.524    43.53
>>>> traitactivity.diurnal:traitactivity.nocturnal.Section      1.3621
>>>> -1.19129
>>>>   6.157    58.48
>>>> traitactivity.dusk:traitactivity.nocturnal.Section         0.7505
>>>> -1.77113
>>>>   4.524    43.53
>>>> traitactivity.nocturnal:traitactivity.nocturnal.Section    2.7148
>>>> 0.09401
>>>>   8.397    76.59
>>>>
>>>> R-structure:  ~us(trait):units
>>>>
>>>>                                                      post.mean l-95% CI
>>>> u-95% CI eff.samp
>>>> traitactivity.diurnal:traitactivity.diurnal.units          0.50     0.50
>>>>  0.50        0
>>>> traitactivity.dusk:traitactivity.diurnal.units             0.25     0.25
>>>>  0.25        0
>>>> traitactivity.nocturnal:traitactivity.diurnal.units        0.25     0.25
>>>>  0.25        0
>>>> traitactivity.diurnal:traitactivity.dusk.units             0.25     0.25
>>>>  0.25        0
>>>> traitactivity.dusk:traitactivity.dusk.units                0.50     0.50
>>>>  0.50        0
>>>> traitactivity.nocturnal:traitactivity.dusk.units           0.25     0.25
>>>>  0.25        0
>>>> traitactivity.diurnal:traitactivity.nocturnal.units        0.25     0.25
>>>>  0.25        0
>>>> traitactivity.dusk:traitactivity.nocturnal.units           0.25     0.25
>>>>  0.25        0
>>>> traitactivity.nocturnal:traitactivity.nocturnal.units      0.50     0.50
>>>>  0.50        0
>>>>
>>>> Location effects: activity ~ -1 + at.level(culling, 1):trait +
>>>> at.level(culling, 2):trait
>>>>
>>>>                                             post.mean l-95% CI u-95% CI
>>>> eff.samp  pMCMC
>>>> at.level(culling, 1):traitactivity.diurnal      1.2306  -0.0533   2.6793
>>>> 145.29 0.0418 *
>>>> at.level(culling, 1):traitactivity.dusk         0.6605  -0.6006   2.0761
>>>> 92.91 0.2840
>>>> at.level(culling, 1):traitactivity.nocturnal    1.6090   0.0914   3.1356
>>>> 151.02 0.0265 *
>>>> traitactivity.diurnal:at.level(culling, 2)      1.2664  -0.1552   2.7750
>>>> 226.40 0.0604 .
>>>> traitactivity.dusk:at.level(culling, 2)         0.3533  -0.9898   1.5218
>>>> 148.44 0.5447
>>>> traitactivity.nocturnal:at.level(culling, 2)    1.0447  -0.6405   2.8354
>>>> 346.40 0.1618
>>>> ---
>>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>>
>>>> *##So for the model summary I get that lethal culling at activity diurnal
>>>> is significantly different from lethal culling at dawn (its the base
>>>> reference), but I'm also interested in whether lethal culling at activity
>>>> diurnal is different from lethal culling at dusk for example. Is this
>>>> possible? *
>>>>
>>>> #outcomes culling lethal
>>>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>>
>>>> Iterations = 1:5500
>>>> Thinning interval = 1
>>>> Number of chains = 1
>>>> Sample size per chain = 5500
>>>>
>>>> 1. Empirical mean and standard deviation for each variable,
>>>>   plus standard error of the mean:
>>>>
>>>>       Mean      SD  Naive SE Time-series SE
>>>> [1,] 0.1253 0.05565 0.0007504       0.002484
>>>> [2,] 0.3748 0.10497 0.0014155       0.003204
>>>> [3,] 0.1757 0.06640 0.0008954       0.002515
>>>> [4,] 0.3242 0.11939 0.0016099       0.003514
>>>>
>>>> 2. Quantiles for each variable:
>>>>
>>>>        2.5%     25%    50%    75%  97.5%
>>>> var1 0.03641 0.08695 0.1198 0.1554 0.2553
>>>> var2 0.17298 0.30580 0.3704 0.4431 0.5896
>>>> var3 0.06166 0.12913 0.1705 0.2161 0.3215
>>>> var4 0.12610 0.23999 0.3090 0.3901 0.6045
>>>>
>>>>> prop.table(Ctable1[,1])
>>>>     dawn   diurnal      dusk nocturnal
>>>> 0.1250000 0.2812500 0.1770833 0.4166667
>>>>
>>>>
>>>> #outcomes culling none
>>>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>>
>>>> Iterations = 1:5500
>>>> Thinning interval = 1
>>>> Number of chains = 1
>>>> Sample size per chain = 5500
>>>>
>>>> 1. Empirical mean and standard deviation for each variable,
>>>>   plus standard error of the mean:
>>>>
>>>>       Mean      SD  Naive SE Time-series SE
>>>> [1,] 0.1288 0.06141 0.0008280       0.002787
>>>> [2,] 0.3804 0.10406 0.0014032       0.002662
>>>> [3,] 0.1710 0.06844 0.0009228       0.002592
>>>> [4,] 0.3198 0.11812 0.0015928       0.002956
>>>>
>>>> 2. Quantiles for each variable:
>>>>
>>>>        2.5%     25%    50%    75%  97.5%
>>>> var1 0.02891 0.08896 0.1220 0.1594 0.2685
>>>> var2 0.18007 0.31094 0.3783 0.4474 0.5965
>>>> var3 0.05840 0.12425 0.1634 0.2083 0.3250
>>>> var4 0.12430 0.23921 0.3077 0.3862 0.5964
>>>>
>>>>> prop.table((Ctable1[,2]))
>>>>     dawn   diurnal      dusk nocturnal
>>>> 0.1306818 0.4375000 0.1875000 0.2443182
>>>>
>>>> Any help or guidance will be greatly appreciated.
>>>>
>>>> All the best,
>>>> Jess
>>>>
>>>> --
>>>> Jessica Comley (PhD)
>>>> Research Scientist
>>>>
>>>>        [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>
>> --
>> Jessica Comley (PhD)
>> Research Scientist
>>
>>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

The University of Edinburgh is a charitable body, registered in Scotland, with registration number SC005336. Is e buidheann carthannais a th? ann an Oilthigh Dh?n ?ideann, cl?raichte an Alba, ?ireamh cl?raidh SC005336.


--
Jessica Comley (PhD)
Research Scientist




--
Dr Jessica Comley
Lecturer: Environmental and Life Sciences
Faculty of Science
Universiti Brunei Darussalam

Email: jessica.comley at ubd.edu.bn<mailto:jessica.comley at ubd.edu.bn>



--
Dr Jessica Comley
Lecturer: Environmental and Life Sciences
Faculty of Science
Universiti Brunei Darussalam

Email: jessica.comley at ubd.edu.bn<mailto:jessica.comley at ubd.edu.bn>


	[[alternative HTML version deleted]]


From je@@|ecom|ey44 @end|ng |rom gm@||@com  Wed Jul 27 06:24:43 2022
From: je@@|ecom|ey44 @end|ng |rom gm@||@com (jessica comley)
Date: Wed, 27 Jul 2022 12:24:43 +0800
Subject: [R-sig-ME] MCMCglmm with multinomial models
In-Reply-To: <56260042-774A-4135-9E38-986F98546F45@ed.ac.uk>
References: <CANdGWBHgzmN15cvGu7zU90o-+sZn4fUS92_nanb6OYYW8f2rog@mail.gmail.com>
 <CAJtCY7XH=AACiNbTo4SLo4gMQnM7ub1vVEOwGGqB-AvuJf5+Jw@mail.gmail.com>
 <CANdGWBFmXtPEvaREGQenkqq403+toEFJvLMgPTzdFWGix-ggGA@mail.gmail.com>
 <CAJtCY7XW=aT50ZCGUr2Y8ERPT1x2UC686Odti8n1kTRj4hC+LQ@mail.gmail.com>
 <57338F74-D980-4078-A389-EDA67E79C1A6@ed.ac.uk>
 <CANdGWBF3uc7SM0-a7uW54iNBPvRHPTTG+jd8-yjYzUz49o-N4g@mail.gmail.com>
 <63B269B7-6C5F-4A0C-BC08-51FE97C621BF@ed.ac.uk>
 <CANdGWBE5fEdZpnKiJ8ZgaRgFChG4=K5zp2Gpufq-p8KRddX7fw@mail.gmail.com>
 <CANdGWBFY0s2y=qaKhwKAU5cvg2xW5rQ_3CmmXvvj+q5v-Fee3g@mail.gmail.com>
 <56260042-774A-4135-9E38-986F98546F45@ed.ac.uk>
Message-ID: <CANdGWBFRhtZLV3U4QmP9FmZPFmw_6Ht5x9WiyiyV2ao_D9KimA@mail.gmail.com>

Hi Jarrod,

Yes I did have a typo in my data, which I have corrected and now all is
working well.

Thank you very much for your help, I really do appreciate your responses!

Cheers,
Jess

On Wed, Jul 27, 2022 at 12:14 PM Jarrod Hadfield <j.hadfield at ed.ac.uk>
wrote:

> Hi,
>
> 1/ My guess is that there is a mistake/typo in your data.frame: culling
> has 3 levels not 2. Does table(bbj$culling) return what you expect?
>
> 2/ They mean i) there is more diurnal activity under culling compared to
> whatever the mystery level of culling is. ii) there is more dawn activity
> when predators is low compared to absent.
>
> 3/ The indices should be for all terms involving the thing to be tested.
> So in the current model they should be 4:9 and 10:15 (not 3:5 and 6:8).
> This will change when you sort out your culling column (probably to 4:6 and
> 7:12). In my previous email I said you should be testing 3 effects for
> predator, but in fact there should be 6 (I thought predator had 3 levels
> not 2).
>
> You might want a -1 in your model formula (i.e
> trait-1+trait:culling+trait:predator) to make the interpretation of the
> first 3 terms a little easier, but up to you.
>
> Cheers,
>
> Jarrod
>
>
>
>
>
>
> On 27 Jul 2022, at 04:42, jessica comley <jessiecomley44 at gmail.com> wrote:
>
> This email was sent to you by someone outside the University.
> You should only click on links or attachments if you are certain that the
> email is genuine and the content is safe.
> Dear Jarrod,
>
> Sorry to bother you again, I just want to make sure I am doing this
> correctly and understanding my results.
>
> I used the model you suggested:
>
> *prior1=list(R=list(V=1, nu=0.002)) m1<-MCMCglmm(cbind(dawn, diurnal,
> dusk, nocturnal)~trait+trait:culling+trait:predator,
> rcov=~idv(units+trait:units), prior=prior1, data=bbj,
> family="multinomial4", nitt= 150000)*
>
> And this is my outcome:
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
> *Iterations = 3001:149991  Thinning interval  = 10  Sample size  = 14700
>  DIC: 10312.95   R-structure:  ~idv(units + trait:units)
> post.mean  l-95% CI u-95% CI eff.samp trait:units   0.01932 0.0002102
>  0.07042      441  Location effects: cbind(dawn, diurnal, dusk, nocturnal)
> ~ trait + trait:culling + trait:predator
>  post.mean  l-95% CI  u-95% CI eff.samp   pMCMC     (Intercept)
>    -2.018903 -2.677830 -1.335305    609.1 < 7e-05 *** traitdiurnal
>        0.542636 -0.363766  1.405230    644.6 0.22068     traitdusk
>          -0.047952 -0.984923  0.917710    374.6 0.91850
> traitdawn:cullingLethal     0.534474  0.003076  1.058211    596.8 0.05524 .
>   traitdiurnal:cullingLethal  0.232597 -0.369959  0.834347    404.7 0.42789
>     traitdusk:cullingLethal     0.376191 -0.217707  0.964636    408.2
> 0.19782     traitdawn:cullingnone      -0.163961 -0.573477  0.298182
> 2945.5 0.38245     traitdiurnal:cullingnone    0.674041  0.247724  1.101917
>   2825.0 0.00952 **  traitdusk:cullingnone       0.449710 -0.014263
>  0.874925   1683.9 0.05102 .   traitdawn:predatorhigh      0.456119
> -0.206435  1.151283    561.7 0.18531     traitdiurnal:predatorhigh
>  -0.303114 -0.976842  0.377294    479.9 0.36939     traitdusk:predatorhigh
>      0.108262 -0.674552  0.895819    256.7 0.76122
> traitdawn:predatorlow       0.756262  0.160407  1.323520    418.1 0.01279 *
>   traitdiurnal:predatorlow    0.136875 -0.446984  0.750518    305.7 0.65619
>     traitdusk:predatorlow       0.422497 -0.303586  1.145038    194.9
> 0.22857     --- Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ?
> ? 1*
>
> 1) Why do the 2 categories for culling both show up but then only 2 of the
> three categories for predator show up? i.e. predatorabsent is missing?
>
> 2) Do these results mean that i) diurnal activity and lethal culling is
> sig different from nocturnal activity and lethal culling; ii) dawn activity
> and predator low is sig different from nocturnal activity and predator low?
>
> 3) Is this the correct way and interpretation of the within group effects?
> *##culling lethal*
>
>
> * aod::wald.test(cov(m1$Sol[,3:5]),
> colMeans(m1$Sol[,3:5]),Terms=1:3)$result$chi2["P"]         P  0.1638938*
>
>
>
>
> * ##culling  none aod::wald.test(cov(m1$Sol[,6:8]),
> colMeans(m1$Sol[,6:8]),Terms=1:3)$result$chi2["P"]           P  0.006497424*
>
>
> So these results show us that culling none has an effect on activity?
>
> Thank you in advance,
> Jess
>
> On Wed, Jul 27, 2022 at 8:20 AM jessica comley <jessiecomley44 at gmail.com>
> wrote:
>
>> Dear Jarrod,
>>
>> Thank you so much for your help, I greatly appreciate it!
>>
>> All the best,
>> Jess
>>
>> On Wed, Jul 27, 2022 at 3:32 AM Jarrod Hadfield <j.hadfield at ed.ac.uk>
>> wrote:
>>
>>> Hi Jess,
>>>
>>> Section should definitely not be left out, but I would imagine it is
>>> going to be very difficult to separate culling, predator and Section
>>> effects - I would expect the credible intervals to be large.
>>>
>>> As mentioned in my previous post you can test for an effect of culling
>>> by fitting the model
>>>
>>> ~trait+trait:culling+trait:predator
>>>
>>> And then fitting a Wald test to the three terms with 'culling' in. The
>>> effect of predator can be tested similarly but with the 3 terms with
>>> 'predator' in.
>>>
>>> Since your covariates do not vary within Section it will be much easier
>>> to aggregate the counts at the Section level (i.e have a data frame with 14
>>> rows and 1 column for each activity with the number observed for each
>>> activity) and fit family="multinomial". You can then get rid of the random
>>> formula as the Section effects are now effectively the residuals. Given the
>>> lack of replication I would advise using the idv formula that I suggested
>>> previously and hope the model isn't too misspecified:
>>>
>>> prior=list(R=list(V=1, nu=0.002))
>>>
>>> m1<-MCMCglmm(cbind(dawn, diurnal, dusk,
>>> nocturnal)~trait+trait:culling+trait:predator,
>>> rcov=~idv(units+trait:units), prior=prior, ...)
>>>
>>> Note this models is identical to the original model, it's just
>>> parameterised in a more efficient way.
>>>
>>> Cheers,
>>>
>>> Jarrod
>>>
>>>
>>>
>>>
>>> On 25 Jul 2022, at 03:52, jessica comley <jessiecomley44 at gmail.com>
>>> wrote:
>>>
>>> This email was sent to you by someone outside the University.
>>> You should only click on links or attachments if you are certain that
>>> the email is genuine and the content is safe.
>>> Dear Jarrod and Walid,
>>>
>>> Thank you for your replies, it is greatly appreciated.
>>>
>>> The predator and culling factors do not vary within sites. As shown in
>>> the example data in one of my previous emails, Bucklands only has culling
>>> as lethal and predator as low, whereas Colchester only has predator as high
>>> and culling as none.
>>>
>>> We are trying to submit a paper on black-backed jackal and caracal
>>> activity in the presence of different culling practices and
>>> predator presence. The reviewers want us to try a GLMM approach to
>>> determine whether culling or predators have an effect on black-backed
>>> jackal or caracal activity.
>>>
>>> Therefore, in your opinion how could be go about this given our data?
>>> Would it be advisable to leave out the random effect of Section?
>>>
>>> All the best,
>>> Jess
>>>
>>> On Wed, Jul 20, 2022 at 3:06 PM Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>> wrote:
>>>
>>>> Hi Jess
>>>>
>>>> In multinomial models the linear model is set up as a (logit)
>>>> difference in probability between an outcome and some base-line outcome.
>>>> Often, as here, the base-line outcome is arbitrary, and so the idh
>>>> structure is a little odd. For example, if A is the base line category, idh
>>>> assumes COV(B-A, C-A) = 0 which therefore assumes
>>>> COV(B,C)+VAR(A) =COV(A,B)+COV(C,A). It's not clear why this would be
>>>> the case. Perhaps a more reasonable, but less parameter rich, option would
>>>> be to have:
>>>>
>>>> ~idv(Section+trait:Section)
>>>>
>>>> which parameterises the Section covariance matrix by a single parameter
>>>> (rather than 6). The term idv(Section+trait:Section) fits a 3x3 covariance
>>>> matrix of the form v*(I+J) where v is the estimated variance. This assumes
>>>> i) Sections are repeatable in outcome, but knowing that a Section has an
>>>> increased 'preference' for A doesn?t tell you whether it also has an
>>>> increased preference for one of the other categories and ii) the
>>>> repeatability for each outcome within sites is the same (on the latent
>>>> scale).
>>>>
>>>> To test groups of effects (in your case the 3 culling:trait effects), I
>>>> usually use a Wald test and the posterior covariances (see here
>>>> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2017q3/025930.html).
>>>> It's far from correct and so Walid's suggestions may be better, but
>>>> small-scale simulations suggests it has good frequentist properties.
>>>>
>>>> To add predator presence you can just add a predator:trait effect into
>>>> the linear model. If the culling and predator factors do not vary within
>>>> sites then you probably don't have enough information to reliably estimate
>>>> these effects.
>>>>
>>>> Cheers,
>>>>
>>>> Jarrod
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> > On 19 Jul 2022, at 18:17, Walid Mawass <walidmawass10 at gmail.com>
>>>> wrote:
>>>> >
>>>> > This email was sent to you by someone outside the University.
>>>> > You should only click on links or attachments if you are certain that
>>>> the email is genuine and the content is safe.
>>>> >
>>>> > Hey Jess,
>>>> >
>>>> > 1) Yes that is correct
>>>> >
>>>> > 2) To my knowledge there is a rule of thumb, where you set the nitt
>>>> (# of
>>>> > iterations) to a large number that includes the burnin amount, then
>>>> you
>>>> > choose your thinning interval (sampling of the chain). For example,
>>>> this is
>>>> > what I would use: nitt= 150000, burnin=50000, thin=100. This will
>>>> give you
>>>> > a decent burnin and a final sample of 1000 saved iterations. Note
>>>> however
>>>> > that this does not have to increase the effective sample size for
>>>> certain
>>>> > variables, but it might do the trick.
>>>> >
>>>> > 3) hmm...I think one way to do it is to make predictions using the
>>>> above
>>>> > model and interpret the patterns you see for each relationship you are
>>>> > interested in. Another way to compare effect size would be to use
>>>> bayesian
>>>> > posterior indices. I suggest these two papers by Makowski et al.
>>>> (2019a &
>>>> > b) that present both interesting posterior indices to use with
>>>> Bayesian
>>>> > statistical analysis and an associated R package that does the job of
>>>> > computing these indices, *bayestestR*.
>>>> >
>>>> > Good luck
>>>> > --
>>>> > Walid Mawass
>>>> > Ph.D. candidate in Evolutionary Biology - UQTR
>>>> > *Currently* Postdoctoral Research Associate
>>>> > Masel Lab - University of Arizona
>>>> >
>>>> >
>>>> > On Sun, Jul 17, 2022 at 11:32 PM jessica comley <
>>>> jessiecomley44 at gmail.com>
>>>> > wrote:
>>>> >
>>>> >> Hi Walid,
>>>> >>
>>>> >> Thank you for your reply, I greatly appreciate it. I have a few more
>>>> >> questions and if you could help that would be great.
>>>> >>
>>>> >> I tested for correlation between activities and the 14 Sections and
>>>> the
>>>> >> correlation comes out as low. Therefore I have changed my code to
>>>> use idh()
>>>> >> instead of us as suggested:
>>>> >>
>>>> >> test1c.5b <- MCMCglmm(activity ~ -1 + at.level(culling,1):trait +
>>>> >> at.level(culling, 2):trait, random=~idh(trait):Section, rcov =
>>>> >> ~idh(trait):units, data = caracal, family = "categorical", prior =
>>>> prior,
>>>> >> burnin=5000, nitt=80000)
>>>> >>
>>>> >> 1) Is this correct?
>>>> >>
>>>> >> 2) Increasing the number of interactions increases the effective
>>>> sample
>>>> >> size, therefore is there a general rule of thumb as to how large your
>>>> >> effective sample size should be?
>>>> >>
>>>> >> 3) I understand how to use and interpret the results of HPDinterval
>>>> (i.e.
>>>> >> if intervals do not overlap 0 then relationship is strong), but how
>>>> am I
>>>> >> able to test the relationship between all four activities and fixed
>>>> effects
>>>> >> and not just have the three categories (i.e. diurnal, dusk,
>>>> nocturnal)
>>>> >> compared to the base category (dawn)? For example, I am also
>>>> interested in
>>>> >> whether there is a significant/strong relationship between
>>>> activities of
>>>> >> caracal at dusk with culling(Lethal)/no culling(none) compared to
>>>> >> activities of caracal at diurnal with culling(Lethal)/no
>>>> culling(none).
>>>> >>
>>>> >> Below is an example of our dataset:
>>>> >> Camera Section CameraID Animal predator culling activity
>>>> >> 1a Bucklands Bucklands1a Caracal low Lethal diurnal
>>>> >> 1a Bucklands Bucklands1a Caracal low Lethal dawn
>>>> >> 2a Bucklands Bucklands2a Caracal low Lethal dusk
>>>> >> 2a Bucklands Bucklands2a Caracal low Lethal diurnal
>>>> >> 3a Bucklands Bucklands3a Caracal low Lethal dawn
>>>> >> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>>>> >> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>>>> >> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>>>> >> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>>>> >> Cam 2  Colchester ColchesterCam 2  Caracal high none diurnal
>>>> >> Cam 2  Colchester ColchesterCam 2  Caracal high none diurnal
>>>> >> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
>>>> >> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
>>>> >> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
>>>> >> Cam 4  Colchester ColchesterCam 4  Caracal high none diurnal
>>>> >> Cam 4  Colchester ColchesterCam 4  Caracal high none diurnal
>>>> >> Cam 4  Colchester ColchesterCam 4  Caracal high none nocturnal
>>>> >> 1a Connaught Connaught1a Caracal low Lethal nocturnal
>>>> >> 1a Connaught Connaught1a Caracal low Lethal nocturnal
>>>> >> 1d Connaught Connaught1d Caracal low Lethal diurnal
>>>> >> 3B Connaught Connaught3B Caracal low Lethal diurnal
>>>> >> 3B Connaught Connaught3B Caracal low Lethal diurnal
>>>> >> 4a Connaught Connaught4a Caracal low Lethal nocturnal
>>>> >> 4a Connaught Connaught4a Caracal low Lethal nocturnal
>>>> >> 4b Connaught Connaught4b Caracal low Lethal diurnal
>>>> >> 6a Connaught Connaught6a Caracal low Lethal nocturnal
>>>> >> 6b Connaught Connaught6b Caracal low Lethal diurnal
>>>> >> 7a Connaught Connaught7a Caracal low Lethal nocturnal
>>>> >> 9a Connaught Connaught9a Caracal low Lethal nocturnal
>>>> >> 9d Connaught Connaught9d Caracal low Lethal nocturnal
>>>> >> 9d Connaught Connaught9d Caracal low Lethal dusk
>>>> >> 7d Diepdam Diepdam7d Caracal absent Lethal dusk
>>>> >> 8d Diepdam Diepdam8d Caracal absent Lethal diurnal
>>>> >> 9c Diepdam Diepdam9c Caracal absent Lethal nocturnal
>>>> >>
>>>> >> All the best,
>>>> >> Jess
>>>> >>
>>>> >>
>>>> >> On Fri, Jul 15, 2022 at 11:37 PM Walid Mawass <
>>>> walidmawass10 at gmail.com>
>>>> >> wrote:
>>>> >>
>>>> >>> Hello,
>>>> >>>
>>>> >>> I don't think I can specifically help you with some of your
>>>> inquiries.
>>>> >>> However, I do want to comment on a few things that might need some
>>>> >>> attention.
>>>> >>>
>>>> >>> First, MCMCglmm is based on a Bayesian implementation and does not
>>>> >>> compute p-values to compare. What you need to compare are the
>>>> posterior
>>>> >>> distributions of your effect sizes. This can be done visually using
>>>> the
>>>> >>> base plot function in R. Or by comparing the HPD intervals and the
>>>> mode (or
>>>> >>> mean) of the posterior distributions.
>>>> >>>
>>>> >>> Second, I have no idea what your data structure looks like (which
>>>> makes
>>>> >>> it hard to interpret model results), but the effective sample size
>>>> (from
>>>> >>> the 5500 saved iterations sample) for your random variable Section
>>>> is very
>>>> >>> low (the same applies for your fixed effects). You should consider
>>>> this
>>>> >>> issue and look again at your assumption of correlation between
>>>> >>> activities for the 14 sections you have in your dataset. If you do
>>>> not
>>>> >>> expect among activity correlations then you can use the idh()
>>>> function
>>>> >>> instead of us().
>>>> >>>
>>>> >>> Hopefully this helps and in hope that people on this list with more
>>>> >>> knowledge of these models will help out.
>>>> >>>
>>>> >>> Best,
>>>> >>> --
>>>> >>> Walid Mawass
>>>> >>> Ph.D. candidate in Evolutionary Biology - UQTR
>>>> >>> *Currently* Postdoctoral Research Associate
>>>> >>> Masel Lab - University of Arizona
>>>> >>>
>>>> >>>
>>>> >>> On Fri, Jul 15, 2022 at 8:49 AM jessica comley <
>>>> jessiecomley44 at gmail.com>
>>>> >>> wrote:
>>>> >>>
>>>> >>>> Dear all,
>>>> >>>>
>>>> >>>> I am hoping that someone will be able to help me with conducting
>>>> MCMCglmm
>>>> >>>> multinomial models.
>>>> >>>>
>>>> >>>> The data I am working with is for black-backed jackal (bbj) and
>>>> carcal.
>>>> >>>> For
>>>> >>>> each species we have a multinomial response variable called
>>>> activity
>>>> >>>> which
>>>> >>>> has four categories (dawn, diurnal, dusk, nocturnal). We have two
>>>> >>>> categorical fixed effects which are 1) culling (none, lethal) and
>>>> 2)
>>>> >>>> predator presence (absent, high, low). We also have a categorical
>>>> >>>> variable
>>>> >>>> called Section (made up of 14 different reserves/ farms where the
>>>> >>>> activity
>>>> >>>> of caracal and bbj were recorded). There are 273 observations for
>>>> caracal
>>>> >>>> and 4399 for bbj. We are wanting to test the effects of culling and
>>>> >>>> predators on caracal and bbj activity separately.
>>>> >>>>
>>>> >>>> I have been working through Jarrod Hadfields course notes,
>>>> particularly
>>>> >>>> with regards to Chapter 5.2. The chi-square analyses reveal that
>>>> the
>>>> >>>> frequencies of culling and predators differ as do activities.
>>>> >>>>
>>>> >>>> I have managed to work out the specific probabilities for the
>>>> culling
>>>> >>>> none
>>>> >>>> vs culling lethal for each activity (dawn, diurnal, dusk,
>>>> nocturnal) for
>>>> >>>> caracal, but I'm confused as to how to determine p-values to
>>>> determine
>>>> >>>> which activities culling none vs culling lethal are affecting?
>>>> >>>>
>>>> >>>> Myy code and outcomes are pasted below with questions stated in
>>>> bold.
>>>> >>>>
>>>> >>>> caracal2 <- read.csv("caracal_new.csv", header=T)
>>>> >>>> caracal <- as.data.frame(unclass(caracal2), stringsAsFactors =
>>>> TRUE)
>>>> >>>>
>>>> >>>> #Chi-squared tests
>>>> >>>> Ctable1 <- table(caracal$activity, caracal$culling)
>>>> >>>> chisq.test(rowSums(Ctable1)) #strongly suggests activities differ
>>>> >>>> chisq.test(Ctable1)#strongly suggests culling category differs
>>>> >>>>
>>>> >>>> Ctable2 <- table(caracal$activity, caracal$predator)
>>>> >>>> chisq.test(rowSums(Ctable2))#strongly suggests activities differ
>>>> >>>> chisq.test(Ctable2)#strongly suggests predator category differs
>>>> >>>>
>>>> >>>> prior = list(R = list(fix=1, V=(1/k) * (I + J)), G =
>>>> list(G1=list(V =
>>>> >>>> diag(k-1), nu=1)))
>>>> >>>> test1c.5 <- MCMCglmm(activity ~ -1 + at.level(culling,1):trait +
>>>> >>>> at.level(culling, 2):trait, random=~us(trait):Section, rcov =
>>>> >>>> ~us(trait):units, data = caracal, family = "categorical", prior =
>>>> prior,
>>>> >>>> burnin=5000, nitt=60000)
>>>> >>>> *##I'm not sure how to add the three predator levels to this model
>>>> or if
>>>> >>>> it
>>>> >>>> would be appropriate?*
>>>> >>>>
>>>> >>>>
>>>> >>>> k <- length(levels(caracal$activity))
>>>> >>>> I <- diag(k-1)
>>>> >>>> J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))
>>>> >>>> IJ <- (1/k) *(diag(k-1) + matrix(1,k-1, k-1))
>>>> >>>>
>>>> >>>> contrasts(caracal$activity)
>>>> >>>>
>>>> >>>> #culling lethal
>>>> >>>> Delta <- cbind(c(0,1,0,0), c(0,0,1,0), c(0,0,0,1))
>>>> >>>> c2 <- (16 * sqrt(3)/(15 * pi))^2
>>>> >>>> D <- ginv(Delta %*% t(Delta)) %*% Delta
>>>> >>>> Int <- t(apply(test1c.5$Sol[,1:3],1, function(x) + D %*% (x/sqrt(1
>>>> + c2 *
>>>> >>>> diag(IJ)))))
>>>> >>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>> >>>>
>>>> >>>> prop.table(Ctable1[,1])
>>>> >>>>
>>>> >>>> #culling none
>>>> >>>> Delta <- cbind(c(0,1,0,0), c(0,0,1,0), c(0,0,0,1))
>>>> >>>> c2 <- (16 * sqrt(3)/(15 * pi))^2
>>>> >>>> D <- ginv(Delta %*% t(Delta)) %*% Delta
>>>> >>>> Int <- t(apply(test1c.5$Sol[,4:6],1, function(x) + D %*% (x/sqrt(1
>>>> + c2 *
>>>> >>>> diag(IJ)))))
>>>> >>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>> >>>>
>>>> >>>> prop.table((Ctable1[,2]))
>>>> >>>>
>>>> >>>> HPDinterval(test1c.5$Sol)
>>>> >>>>
>>>> >>>> #model summary
>>>> >>>>> summary(test1c.5)
>>>> >>>>
>>>> >>>> Iterations = 5001:59991
>>>> >>>> Thinning interval  = 10
>>>> >>>> Sample size  = 5500
>>>> >>>>
>>>> >>>> DIC: 699.7014
>>>> >>>>
>>>> >>>> G-structure:  ~us(trait):Section
>>>> >>>>
>>>> >>>>                                                        post.mean
>>>> l-95%
>>>> >>>> CI
>>>> >>>> u-95% CI eff.samp
>>>> >>>> traitactivity.diurnal:traitactivity.diurnal.Section        1.8124
>>>> >>>> 0.09784
>>>> >>>>   5.665    77.01
>>>> >>>> traitactivity.dusk:traitactivity.diurnal.Section           0.8450
>>>> >>>> -0.83585
>>>> >>>>   3.856    64.17
>>>> >>>> traitactivity.nocturnal:traitactivity.diurnal.Section      1.3621
>>>> >>>> -1.19129
>>>> >>>>   6.157    58.48
>>>> >>>> traitactivity.diurnal:traitactivity.dusk.Section           0.8450
>>>> >>>> -0.83585
>>>> >>>>   3.856    64.17
>>>> >>>> traitactivity.dusk:traitactivity.dusk.Section              1.2034
>>>> >>>> 0.07090
>>>> >>>>   3.681   102.16
>>>> >>>> traitactivity.nocturnal:traitactivity.dusk.Section         0.7505
>>>> >>>> -1.77113
>>>> >>>>   4.524    43.53
>>>> >>>> traitactivity.diurnal:traitactivity.nocturnal.Section      1.3621
>>>> >>>> -1.19129
>>>> >>>>   6.157    58.48
>>>> >>>> traitactivity.dusk:traitactivity.nocturnal.Section         0.7505
>>>> >>>> -1.77113
>>>> >>>>   4.524    43.53
>>>> >>>> traitactivity.nocturnal:traitactivity.nocturnal.Section    2.7148
>>>> >>>> 0.09401
>>>> >>>>   8.397    76.59
>>>> >>>>
>>>> >>>> R-structure:  ~us(trait):units
>>>> >>>>
>>>> >>>>                                                      post.mean
>>>> l-95% CI
>>>> >>>> u-95% CI eff.samp
>>>> >>>> traitactivity.diurnal:traitactivity.diurnal.units          0.50
>>>>  0.50
>>>> >>>>  0.50        0
>>>> >>>> traitactivity.dusk:traitactivity.diurnal.units             0.25
>>>>  0.25
>>>> >>>>  0.25        0
>>>> >>>> traitactivity.nocturnal:traitactivity.diurnal.units        0.25
>>>>  0.25
>>>> >>>>  0.25        0
>>>> >>>> traitactivity.diurnal:traitactivity.dusk.units             0.25
>>>>  0.25
>>>> >>>>  0.25        0
>>>> >>>> traitactivity.dusk:traitactivity.dusk.units                0.50
>>>>  0.50
>>>> >>>>  0.50        0
>>>> >>>> traitactivity.nocturnal:traitactivity.dusk.units           0.25
>>>>  0.25
>>>> >>>>  0.25        0
>>>> >>>> traitactivity.diurnal:traitactivity.nocturnal.units        0.25
>>>>  0.25
>>>> >>>>  0.25        0
>>>> >>>> traitactivity.dusk:traitactivity.nocturnal.units           0.25
>>>>  0.25
>>>> >>>>  0.25        0
>>>> >>>> traitactivity.nocturnal:traitactivity.nocturnal.units      0.50
>>>>  0.50
>>>> >>>>  0.50        0
>>>> >>>>
>>>> >>>> Location effects: activity ~ -1 + at.level(culling, 1):trait +
>>>> >>>> at.level(culling, 2):trait
>>>> >>>>
>>>> >>>>                                             post.mean l-95% CI
>>>> u-95% CI
>>>> >>>> eff.samp  pMCMC
>>>> >>>> at.level(culling, 1):traitactivity.diurnal      1.2306  -0.0533
>>>>  2.6793
>>>> >>>> 145.29 0.0418 *
>>>> >>>> at.level(culling, 1):traitactivity.dusk         0.6605  -0.6006
>>>>  2.0761
>>>> >>>> 92.91 0.2840
>>>> >>>> at.level(culling, 1):traitactivity.nocturnal    1.6090   0.0914
>>>>  3.1356
>>>> >>>> 151.02 0.0265 *
>>>> >>>> traitactivity.diurnal:at.level(culling, 2)      1.2664  -0.1552
>>>>  2.7750
>>>> >>>> 226.40 0.0604 .
>>>> >>>> traitactivity.dusk:at.level(culling, 2)         0.3533  -0.9898
>>>>  1.5218
>>>> >>>> 148.44 0.5447
>>>> >>>> traitactivity.nocturnal:at.level(culling, 2)    1.0447  -0.6405
>>>>  2.8354
>>>> >>>> 346.40 0.1618
>>>> >>>> ---
>>>> >>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>> >>>>
>>>> >>>> *##So for the model summary I get that lethal culling at activity
>>>> diurnal
>>>> >>>> is significantly different from lethal culling at dawn (its the
>>>> base
>>>> >>>> reference), but I'm also interested in whether lethal culling at
>>>> activity
>>>> >>>> diurnal is different from lethal culling at dusk for example. Is
>>>> this
>>>> >>>> possible? *
>>>> >>>>
>>>> >>>> #outcomes culling lethal
>>>> >>>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>> >>>>
>>>> >>>> Iterations = 1:5500
>>>> >>>> Thinning interval = 1
>>>> >>>> Number of chains = 1
>>>> >>>> Sample size per chain = 5500
>>>> >>>>
>>>> >>>> 1. Empirical mean and standard deviation for each variable,
>>>> >>>>   plus standard error of the mean:
>>>> >>>>
>>>> >>>>       Mean      SD  Naive SE Time-series SE
>>>> >>>> [1,] 0.1253 0.05565 0.0007504       0.002484
>>>> >>>> [2,] 0.3748 0.10497 0.0014155       0.003204
>>>> >>>> [3,] 0.1757 0.06640 0.0008954       0.002515
>>>> >>>> [4,] 0.3242 0.11939 0.0016099       0.003514
>>>> >>>>
>>>> >>>> 2. Quantiles for each variable:
>>>> >>>>
>>>> >>>>        2.5%     25%    50%    75%  97.5%
>>>> >>>> var1 0.03641 0.08695 0.1198 0.1554 0.2553
>>>> >>>> var2 0.17298 0.30580 0.3704 0.4431 0.5896
>>>> >>>> var3 0.06166 0.12913 0.1705 0.2161 0.3215
>>>> >>>> var4 0.12610 0.23999 0.3090 0.3901 0.6045
>>>> >>>>
>>>> >>>>> prop.table(Ctable1[,1])
>>>> >>>>     dawn   diurnal      dusk nocturnal
>>>> >>>> 0.1250000 0.2812500 0.1770833 0.4166667
>>>> >>>>
>>>> >>>>
>>>> >>>> #outcomes culling none
>>>> >>>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>> >>>>
>>>> >>>> Iterations = 1:5500
>>>> >>>> Thinning interval = 1
>>>> >>>> Number of chains = 1
>>>> >>>> Sample size per chain = 5500
>>>> >>>>
>>>> >>>> 1. Empirical mean and standard deviation for each variable,
>>>> >>>>   plus standard error of the mean:
>>>> >>>>
>>>> >>>>       Mean      SD  Naive SE Time-series SE
>>>> >>>> [1,] 0.1288 0.06141 0.0008280       0.002787
>>>> >>>> [2,] 0.3804 0.10406 0.0014032       0.002662
>>>> >>>> [3,] 0.1710 0.06844 0.0009228       0.002592
>>>> >>>> [4,] 0.3198 0.11812 0.0015928       0.002956
>>>> >>>>
>>>> >>>> 2. Quantiles for each variable:
>>>> >>>>
>>>> >>>>        2.5%     25%    50%    75%  97.5%
>>>> >>>> var1 0.02891 0.08896 0.1220 0.1594 0.2685
>>>> >>>> var2 0.18007 0.31094 0.3783 0.4474 0.5965
>>>> >>>> var3 0.05840 0.12425 0.1634 0.2083 0.3250
>>>> >>>> var4 0.12430 0.23921 0.3077 0.3862 0.5964
>>>> >>>>
>>>> >>>>> prop.table((Ctable1[,2]))
>>>> >>>>     dawn   diurnal      dusk nocturnal
>>>> >>>> 0.1306818 0.4375000 0.1875000 0.2443182
>>>> >>>>
>>>> >>>> Any help or guidance will be greatly appreciated.
>>>> >>>>
>>>> >>>> All the best,
>>>> >>>> Jess
>>>> >>>>
>>>> >>>> --
>>>> >>>> Jessica Comley (PhD)
>>>> >>>> Research Scientist
>>>> >>>>
>>>> >>>>        [[alternative HTML version deleted]]
>>>> >>>>
>>>> >>>> _______________________________________________
>>>> >>>> R-sig-mixed-models at r-project.org mailing list
>>>> >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> >>>>
>>>> >>>
>>>> >>
>>>> >> --
>>>> >> Jessica Comley (PhD)
>>>> >> Research Scientist
>>>> >>
>>>> >>
>>>> >
>>>> >        [[alternative HTML version deleted]]
>>>> >
>>>> > _______________________________________________
>>>> > R-sig-mixed-models at r-project.org mailing list
>>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>> The University of Edinburgh is a charitable body, registered in
>>>> Scotland, with registration number SC005336. Is e buidheann carthannais a
>>>> th? ann an Oilthigh Dh?n ?ideann, cl?raichte an Alba, ?ireamh cl?raidh
>>>> SC005336.
>>>>
>>>
>>>
>>> --
>>> Jessica Comley (PhD)
>>> Research Scientist
>>>
>>>
>>>
>>
>> --
>> Dr Jessica Comley
>> Lecturer: Environmental and Life Sciences
>> Faculty of Science
>> Universiti Brunei Darussalam
>>
>> Email: jessica.comley at ubd.edu.bn
>>
>>
>
> --
> Dr Jessica Comley
> Lecturer: Environmental and Life Sciences
> Faculty of Science
> Universiti Brunei Darussalam
>
> Email: jessica.comley at ubd.edu.bn
>
>
>

-- 
Dr Jessica Comley
Lecturer: Environmental and Life Sciences
Faculty of Science
Universiti Brunei Darussalam

Email: jessica.comley at ubd.edu.bn

	[[alternative HTML version deleted]]


From je@@|ecom|ey44 @end|ng |rom gm@||@com  Wed Jul 27 06:48:41 2022
From: je@@|ecom|ey44 @end|ng |rom gm@||@com (jessica comley)
Date: Wed, 27 Jul 2022 12:48:41 +0800
Subject: [R-sig-ME] MCMCglmm with multinomial models
In-Reply-To: <CANdGWBFRhtZLV3U4QmP9FmZPFmw_6Ht5x9WiyiyV2ao_D9KimA@mail.gmail.com>
References: <CANdGWBHgzmN15cvGu7zU90o-+sZn4fUS92_nanb6OYYW8f2rog@mail.gmail.com>
 <CAJtCY7XH=AACiNbTo4SLo4gMQnM7ub1vVEOwGGqB-AvuJf5+Jw@mail.gmail.com>
 <CANdGWBFmXtPEvaREGQenkqq403+toEFJvLMgPTzdFWGix-ggGA@mail.gmail.com>
 <CAJtCY7XW=aT50ZCGUr2Y8ERPT1x2UC686Odti8n1kTRj4hC+LQ@mail.gmail.com>
 <57338F74-D980-4078-A389-EDA67E79C1A6@ed.ac.uk>
 <CANdGWBF3uc7SM0-a7uW54iNBPvRHPTTG+jd8-yjYzUz49o-N4g@mail.gmail.com>
 <63B269B7-6C5F-4A0C-BC08-51FE97C621BF@ed.ac.uk>
 <CANdGWBE5fEdZpnKiJ8ZgaRgFChG4=K5zp2Gpufq-p8KRddX7fw@mail.gmail.com>
 <CANdGWBFY0s2y=qaKhwKAU5cvg2xW5rQ_3CmmXvvj+q5v-Fee3g@mail.gmail.com>
 <56260042-774A-4135-9E38-986F98546F45@ed.ac.uk>
 <CANdGWBFRhtZLV3U4QmP9FmZPFmw_6Ht5x9WiyiyV2ao_D9KimA@mail.gmail.com>
Message-ID: <CANdGWBFJ30UCL3pXXPzn3fQT54vcQXvrdn2vsg_0B-XcYV2sHw@mail.gmail.com>

Sorry Jarrod, one last question I swear.

From my corrected outcome:

*Location effects: cbind(dawn, diurnal, dusk, nocturnal) ~ trait - 1 +
trait:culling + trait:predator *



*                          post.mean l-95% CI u-95% CI eff.samp   pMCMC    *

*traitdawn                  -1.49696 -1.91443 -1.03494    449.8 < 7e-05 ****

*traitdiurnal               -1.26128 -1.65569 -0.87573    173.7 < 7e-05 ****

*traitdusk                  -1.69165 -2.14582 -1.25074    304.0 < 7e-05 ****

*traitdawn:cullingnone      -0.35018 -0.75539  0.03488   1453.5 0.06068 .  *

*traitdiurnal:cullingnone    0.61075  0.22682  0.99247    646.2 0.00653 ** *

*traitdusk:cullingnone       0.32833 -0.07876  0.72035   1218.7 0.10136    *

*traitdawn:predatorhigh      0.12826 -0.48062  0.81929    696.5 0.70884    *

*traitdiurnal:predatorhigh  -0.45382 -1.03340  0.15183    293.7 0.12313    *

*traitdusk:predatorhigh     -0.14870 -0.77156  0.49585    475.2 0.62830    *

*traitdawn:predatorlow       0.41706 -0.11004  0.93341    579.5 0.10626    *

*traitdiurnal:predatorlow   -0.01279 -0.47660  0.49818    206.6 0.95741    *
*traitdusk:predatorlow       0.16600 -0.36760  0.71419    323.0 0.55102    *

How would I work out whether traitnocturnal:cullingnone occured more or
less than cullinglethal? Is this something that can be done?

Cheers,
Jess

On Wed, Jul 27, 2022 at 12:24 PM jessica comley <jessiecomley44 at gmail.com>
wrote:

> Hi Jarrod,
>
> Yes I did have a typo in my data, which I have corrected and now all is
> working well.
>
> Thank you very much for your help, I really do appreciate your responses!
>
> Cheers,
> Jess
>
> On Wed, Jul 27, 2022 at 12:14 PM Jarrod Hadfield <j.hadfield at ed.ac.uk>
> wrote:
>
>> Hi,
>>
>> 1/ My guess is that there is a mistake/typo in your data.frame: culling
>> has 3 levels not 2. Does table(bbj$culling) return what you expect?
>>
>> 2/ They mean i) there is more diurnal activity under culling compared to
>> whatever the mystery level of culling is. ii) there is more dawn activity
>> when predators is low compared to absent.
>>
>> 3/ The indices should be for all terms involving the thing to be tested.
>> So in the current model they should be 4:9 and 10:15 (not 3:5 and 6:8).
>> This will change when you sort out your culling column (probably to 4:6 and
>> 7:12). In my previous email I said you should be testing 3 effects for
>> predator, but in fact there should be 6 (I thought predator had 3 levels
>> not 2).
>>
>> You might want a -1 in your model formula (i.e
>> trait-1+trait:culling+trait:predator) to make the interpretation of the
>> first 3 terms a little easier, but up to you.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>>
>>
>>
>> On 27 Jul 2022, at 04:42, jessica comley <jessiecomley44 at gmail.com>
>> wrote:
>>
>> This email was sent to you by someone outside the University.
>> You should only click on links or attachments if you are certain that the
>> email is genuine and the content is safe.
>> Dear Jarrod,
>>
>> Sorry to bother you again, I just want to make sure I am doing this
>> correctly and understanding my results.
>>
>> I used the model you suggested:
>>
>> *prior1=list(R=list(V=1, nu=0.002)) m1<-MCMCglmm(cbind(dawn, diurnal,
>> dusk, nocturnal)~trait+trait:culling+trait:predator,
>> rcov=~idv(units+trait:units), prior=prior1, data=bbj,
>> family="multinomial4", nitt= 150000)*
>>
>> And this is my outcome:
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> *Iterations = 3001:149991  Thinning interval  = 10  Sample size  = 14700
>>  DIC: 10312.95   R-structure:  ~idv(units + trait:units)
>> post.mean  l-95% CI u-95% CI eff.samp trait:units   0.01932 0.0002102
>>  0.07042      441  Location effects: cbind(dawn, diurnal, dusk, nocturnal)
>> ~ trait + trait:culling + trait:predator
>>  post.mean  l-95% CI  u-95% CI eff.samp   pMCMC     (Intercept)
>>    -2.018903 -2.677830 -1.335305    609.1 < 7e-05 *** traitdiurnal
>>        0.542636 -0.363766  1.405230    644.6 0.22068     traitdusk
>>          -0.047952 -0.984923  0.917710    374.6 0.91850
>> traitdawn:cullingLethal     0.534474  0.003076  1.058211    596.8 0.05524 .
>>   traitdiurnal:cullingLethal  0.232597 -0.369959  0.834347    404.7 0.42789
>>     traitdusk:cullingLethal     0.376191 -0.217707  0.964636    408.2
>> 0.19782     traitdawn:cullingnone      -0.163961 -0.573477  0.298182
>> 2945.5 0.38245     traitdiurnal:cullingnone    0.674041  0.247724  1.101917
>>   2825.0 0.00952 **  traitdusk:cullingnone       0.449710 -0.014263
>>  0.874925   1683.9 0.05102 .   traitdawn:predatorhigh      0.456119
>> -0.206435  1.151283    561.7 0.18531     traitdiurnal:predatorhigh
>>  -0.303114 -0.976842  0.377294    479.9 0.36939     traitdusk:predatorhigh
>>      0.108262 -0.674552  0.895819    256.7 0.76122
>> traitdawn:predatorlow       0.756262  0.160407  1.323520    418.1 0.01279 *
>>   traitdiurnal:predatorlow    0.136875 -0.446984  0.750518    305.7 0.65619
>>     traitdusk:predatorlow       0.422497 -0.303586  1.145038    194.9
>> 0.22857     --- Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ?
>> ? 1*
>>
>> 1) Why do the 2 categories for culling both show up but then only 2 of
>> the three categories for predator show up? i.e. predatorabsent is missing?
>>
>> 2) Do these results mean that i) diurnal activity and lethal culling is
>> sig different from nocturnal activity and lethal culling; ii) dawn activity
>> and predator low is sig different from nocturnal activity and predator low?
>>
>> 3) Is this the correct way and interpretation of the within group effects?
>> *##culling lethal*
>>
>>
>> * aod::wald.test(cov(m1$Sol[,3:5]),
>> colMeans(m1$Sol[,3:5]),Terms=1:3)$result$chi2["P"]         P  0.1638938*
>>
>>
>>
>>
>> * ##culling  none aod::wald.test(cov(m1$Sol[,6:8]),
>> colMeans(m1$Sol[,6:8]),Terms=1:3)$result$chi2["P"]           P  0.006497424*
>>
>>
>> So these results show us that culling none has an effect on activity?
>>
>> Thank you in advance,
>> Jess
>>
>> On Wed, Jul 27, 2022 at 8:20 AM jessica comley <jessiecomley44 at gmail.com>
>> wrote:
>>
>>> Dear Jarrod,
>>>
>>> Thank you so much for your help, I greatly appreciate it!
>>>
>>> All the best,
>>> Jess
>>>
>>> On Wed, Jul 27, 2022 at 3:32 AM Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>> wrote:
>>>
>>>> Hi Jess,
>>>>
>>>> Section should definitely not be left out, but I would imagine it is
>>>> going to be very difficult to separate culling, predator and Section
>>>> effects - I would expect the credible intervals to be large.
>>>>
>>>> As mentioned in my previous post you can test for an effect of culling
>>>> by fitting the model
>>>>
>>>> ~trait+trait:culling+trait:predator
>>>>
>>>> And then fitting a Wald test to the three terms with 'culling' in. The
>>>> effect of predator can be tested similarly but with the 3 terms with
>>>> 'predator' in.
>>>>
>>>> Since your covariates do not vary within Section it will be much easier
>>>> to aggregate the counts at the Section level (i.e have a data frame with 14
>>>> rows and 1 column for each activity with the number observed for each
>>>> activity) and fit family="multinomial". You can then get rid of the random
>>>> formula as the Section effects are now effectively the residuals. Given the
>>>> lack of replication I would advise using the idv formula that I suggested
>>>> previously and hope the model isn't too misspecified:
>>>>
>>>> prior=list(R=list(V=1, nu=0.002))
>>>>
>>>> m1<-MCMCglmm(cbind(dawn, diurnal, dusk,
>>>> nocturnal)~trait+trait:culling+trait:predator,
>>>> rcov=~idv(units+trait:units), prior=prior, ...)
>>>>
>>>> Note this models is identical to the original model, it's just
>>>> parameterised in a more efficient way.
>>>>
>>>> Cheers,
>>>>
>>>> Jarrod
>>>>
>>>>
>>>>
>>>>
>>>> On 25 Jul 2022, at 03:52, jessica comley <jessiecomley44 at gmail.com>
>>>> wrote:
>>>>
>>>> This email was sent to you by someone outside the University.
>>>> You should only click on links or attachments if you are certain that
>>>> the email is genuine and the content is safe.
>>>> Dear Jarrod and Walid,
>>>>
>>>> Thank you for your replies, it is greatly appreciated.
>>>>
>>>> The predator and culling factors do not vary within sites. As shown in
>>>> the example data in one of my previous emails, Bucklands only has culling
>>>> as lethal and predator as low, whereas Colchester only has predator as high
>>>> and culling as none.
>>>>
>>>> We are trying to submit a paper on black-backed jackal and caracal
>>>> activity in the presence of different culling practices and
>>>> predator presence. The reviewers want us to try a GLMM approach to
>>>> determine whether culling or predators have an effect on black-backed
>>>> jackal or caracal activity.
>>>>
>>>> Therefore, in your opinion how could be go about this given our data?
>>>> Would it be advisable to leave out the random effect of Section?
>>>>
>>>> All the best,
>>>> Jess
>>>>
>>>> On Wed, Jul 20, 2022 at 3:06 PM Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>>> wrote:
>>>>
>>>>> Hi Jess
>>>>>
>>>>> In multinomial models the linear model is set up as a (logit)
>>>>> difference in probability between an outcome and some base-line outcome.
>>>>> Often, as here, the base-line outcome is arbitrary, and so the idh
>>>>> structure is a little odd. For example, if A is the base line category, idh
>>>>> assumes COV(B-A, C-A) = 0 which therefore assumes
>>>>> COV(B,C)+VAR(A) =COV(A,B)+COV(C,A). It's not clear why this would be
>>>>> the case. Perhaps a more reasonable, but less parameter rich, option would
>>>>> be to have:
>>>>>
>>>>> ~idv(Section+trait:Section)
>>>>>
>>>>> which parameterises the Section covariance matrix by a single
>>>>> parameter (rather than 6). The term idv(Section+trait:Section) fits a 3x3
>>>>> covariance matrix of the form v*(I+J) where v is the estimated variance.
>>>>> This assumes i) Sections are repeatable in outcome, but knowing that a
>>>>> Section has an increased 'preference' for A doesn?t tell you whether it
>>>>> also has an increased preference for one of the other categories and ii)
>>>>> the repeatability for each outcome within sites is the same (on the latent
>>>>> scale).
>>>>>
>>>>> To test groups of effects (in your case the 3 culling:trait effects),
>>>>> I usually use a Wald test and the posterior covariances (see here
>>>>> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2017q3/025930.html).
>>>>> It's far from correct and so Walid's suggestions may be better, but
>>>>> small-scale simulations suggests it has good frequentist properties.
>>>>>
>>>>> To add predator presence you can just add a predator:trait effect into
>>>>> the linear model. If the culling and predator factors do not vary within
>>>>> sites then you probably don't have enough information to reliably estimate
>>>>> these effects.
>>>>>
>>>>> Cheers,
>>>>>
>>>>> Jarrod
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> > On 19 Jul 2022, at 18:17, Walid Mawass <walidmawass10 at gmail.com>
>>>>> wrote:
>>>>> >
>>>>> > This email was sent to you by someone outside the University.
>>>>> > You should only click on links or attachments if you are certain
>>>>> that the email is genuine and the content is safe.
>>>>> >
>>>>> > Hey Jess,
>>>>> >
>>>>> > 1) Yes that is correct
>>>>> >
>>>>> > 2) To my knowledge there is a rule of thumb, where you set the nitt
>>>>> (# of
>>>>> > iterations) to a large number that includes the burnin amount, then
>>>>> you
>>>>> > choose your thinning interval (sampling of the chain). For example,
>>>>> this is
>>>>> > what I would use: nitt= 150000, burnin=50000, thin=100. This will
>>>>> give you
>>>>> > a decent burnin and a final sample of 1000 saved iterations. Note
>>>>> however
>>>>> > that this does not have to increase the effective sample size for
>>>>> certain
>>>>> > variables, but it might do the trick.
>>>>> >
>>>>> > 3) hmm...I think one way to do it is to make predictions using the
>>>>> above
>>>>> > model and interpret the patterns you see for each relationship you
>>>>> are
>>>>> > interested in. Another way to compare effect size would be to use
>>>>> bayesian
>>>>> > posterior indices. I suggest these two papers by Makowski et al.
>>>>> (2019a &
>>>>> > b) that present both interesting posterior indices to use with
>>>>> Bayesian
>>>>> > statistical analysis and an associated R package that does the job of
>>>>> > computing these indices, *bayestestR*.
>>>>> >
>>>>> > Good luck
>>>>> > --
>>>>> > Walid Mawass
>>>>> > Ph.D. candidate in Evolutionary Biology - UQTR
>>>>> > *Currently* Postdoctoral Research Associate
>>>>> > Masel Lab - University of Arizona
>>>>> >
>>>>> >
>>>>> > On Sun, Jul 17, 2022 at 11:32 PM jessica comley <
>>>>> jessiecomley44 at gmail.com>
>>>>> > wrote:
>>>>> >
>>>>> >> Hi Walid,
>>>>> >>
>>>>> >> Thank you for your reply, I greatly appreciate it. I have a few more
>>>>> >> questions and if you could help that would be great.
>>>>> >>
>>>>> >> I tested for correlation between activities and the 14 Sections and
>>>>> the
>>>>> >> correlation comes out as low. Therefore I have changed my code to
>>>>> use idh()
>>>>> >> instead of us as suggested:
>>>>> >>
>>>>> >> test1c.5b <- MCMCglmm(activity ~ -1 + at.level(culling,1):trait +
>>>>> >> at.level(culling, 2):trait, random=~idh(trait):Section, rcov =
>>>>> >> ~idh(trait):units, data = caracal, family = "categorical", prior =
>>>>> prior,
>>>>> >> burnin=5000, nitt=80000)
>>>>> >>
>>>>> >> 1) Is this correct?
>>>>> >>
>>>>> >> 2) Increasing the number of interactions increases the effective
>>>>> sample
>>>>> >> size, therefore is there a general rule of thumb as to how large
>>>>> your
>>>>> >> effective sample size should be?
>>>>> >>
>>>>> >> 3) I understand how to use and interpret the results of HPDinterval
>>>>> (i.e.
>>>>> >> if intervals do not overlap 0 then relationship is strong), but how
>>>>> am I
>>>>> >> able to test the relationship between all four activities and fixed
>>>>> effects
>>>>> >> and not just have the three categories (i.e. diurnal, dusk,
>>>>> nocturnal)
>>>>> >> compared to the base category (dawn)? For example, I am also
>>>>> interested in
>>>>> >> whether there is a significant/strong relationship between
>>>>> activities of
>>>>> >> caracal at dusk with culling(Lethal)/no culling(none) compared to
>>>>> >> activities of caracal at diurnal with culling(Lethal)/no
>>>>> culling(none).
>>>>> >>
>>>>> >> Below is an example of our dataset:
>>>>> >> Camera Section CameraID Animal predator culling activity
>>>>> >> 1a Bucklands Bucklands1a Caracal low Lethal diurnal
>>>>> >> 1a Bucklands Bucklands1a Caracal low Lethal dawn
>>>>> >> 2a Bucklands Bucklands2a Caracal low Lethal dusk
>>>>> >> 2a Bucklands Bucklands2a Caracal low Lethal diurnal
>>>>> >> 3a Bucklands Bucklands3a Caracal low Lethal dawn
>>>>> >> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>>>>> >> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>>>>> >> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>>>>> >> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>>>>> >> Cam 2  Colchester ColchesterCam 2  Caracal high none diurnal
>>>>> >> Cam 2  Colchester ColchesterCam 2  Caracal high none diurnal
>>>>> >> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
>>>>> >> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
>>>>> >> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
>>>>> >> Cam 4  Colchester ColchesterCam 4  Caracal high none diurnal
>>>>> >> Cam 4  Colchester ColchesterCam 4  Caracal high none diurnal
>>>>> >> Cam 4  Colchester ColchesterCam 4  Caracal high none nocturnal
>>>>> >> 1a Connaught Connaught1a Caracal low Lethal nocturnal
>>>>> >> 1a Connaught Connaught1a Caracal low Lethal nocturnal
>>>>> >> 1d Connaught Connaught1d Caracal low Lethal diurnal
>>>>> >> 3B Connaught Connaught3B Caracal low Lethal diurnal
>>>>> >> 3B Connaught Connaught3B Caracal low Lethal diurnal
>>>>> >> 4a Connaught Connaught4a Caracal low Lethal nocturnal
>>>>> >> 4a Connaught Connaught4a Caracal low Lethal nocturnal
>>>>> >> 4b Connaught Connaught4b Caracal low Lethal diurnal
>>>>> >> 6a Connaught Connaught6a Caracal low Lethal nocturnal
>>>>> >> 6b Connaught Connaught6b Caracal low Lethal diurnal
>>>>> >> 7a Connaught Connaught7a Caracal low Lethal nocturnal
>>>>> >> 9a Connaught Connaught9a Caracal low Lethal nocturnal
>>>>> >> 9d Connaught Connaught9d Caracal low Lethal nocturnal
>>>>> >> 9d Connaught Connaught9d Caracal low Lethal dusk
>>>>> >> 7d Diepdam Diepdam7d Caracal absent Lethal dusk
>>>>> >> 8d Diepdam Diepdam8d Caracal absent Lethal diurnal
>>>>> >> 9c Diepdam Diepdam9c Caracal absent Lethal nocturnal
>>>>> >>
>>>>> >> All the best,
>>>>> >> Jess
>>>>> >>
>>>>> >>
>>>>> >> On Fri, Jul 15, 2022 at 11:37 PM Walid Mawass <
>>>>> walidmawass10 at gmail.com>
>>>>> >> wrote:
>>>>> >>
>>>>> >>> Hello,
>>>>> >>>
>>>>> >>> I don't think I can specifically help you with some of your
>>>>> inquiries.
>>>>> >>> However, I do want to comment on a few things that might need some
>>>>> >>> attention.
>>>>> >>>
>>>>> >>> First, MCMCglmm is based on a Bayesian implementation and does not
>>>>> >>> compute p-values to compare. What you need to compare are the
>>>>> posterior
>>>>> >>> distributions of your effect sizes. This can be done visually
>>>>> using the
>>>>> >>> base plot function in R. Or by comparing the HPD intervals and the
>>>>> mode (or
>>>>> >>> mean) of the posterior distributions.
>>>>> >>>
>>>>> >>> Second, I have no idea what your data structure looks like (which
>>>>> makes
>>>>> >>> it hard to interpret model results), but the effective sample size
>>>>> (from
>>>>> >>> the 5500 saved iterations sample) for your random variable Section
>>>>> is very
>>>>> >>> low (the same applies for your fixed effects). You should consider
>>>>> this
>>>>> >>> issue and look again at your assumption of correlation between
>>>>> >>> activities for the 14 sections you have in your dataset. If you do
>>>>> not
>>>>> >>> expect among activity correlations then you can use the idh()
>>>>> function
>>>>> >>> instead of us().
>>>>> >>>
>>>>> >>> Hopefully this helps and in hope that people on this list with more
>>>>> >>> knowledge of these models will help out.
>>>>> >>>
>>>>> >>> Best,
>>>>> >>> --
>>>>> >>> Walid Mawass
>>>>> >>> Ph.D. candidate in Evolutionary Biology - UQTR
>>>>> >>> *Currently* Postdoctoral Research Associate
>>>>> >>> Masel Lab - University of Arizona
>>>>> >>>
>>>>> >>>
>>>>> >>> On Fri, Jul 15, 2022 at 8:49 AM jessica comley <
>>>>> jessiecomley44 at gmail.com>
>>>>> >>> wrote:
>>>>> >>>
>>>>> >>>> Dear all,
>>>>> >>>>
>>>>> >>>> I am hoping that someone will be able to help me with conducting
>>>>> MCMCglmm
>>>>> >>>> multinomial models.
>>>>> >>>>
>>>>> >>>> The data I am working with is for black-backed jackal (bbj) and
>>>>> carcal.
>>>>> >>>> For
>>>>> >>>> each species we have a multinomial response variable called
>>>>> activity
>>>>> >>>> which
>>>>> >>>> has four categories (dawn, diurnal, dusk, nocturnal). We have two
>>>>> >>>> categorical fixed effects which are 1) culling (none, lethal) and
>>>>> 2)
>>>>> >>>> predator presence (absent, high, low). We also have a categorical
>>>>> >>>> variable
>>>>> >>>> called Section (made up of 14 different reserves/ farms where the
>>>>> >>>> activity
>>>>> >>>> of caracal and bbj were recorded). There are 273 observations for
>>>>> caracal
>>>>> >>>> and 4399 for bbj. We are wanting to test the effects of culling
>>>>> and
>>>>> >>>> predators on caracal and bbj activity separately.
>>>>> >>>>
>>>>> >>>> I have been working through Jarrod Hadfields course notes,
>>>>> particularly
>>>>> >>>> with regards to Chapter 5.2. The chi-square analyses reveal that
>>>>> the
>>>>> >>>> frequencies of culling and predators differ as do activities.
>>>>> >>>>
>>>>> >>>> I have managed to work out the specific probabilities for the
>>>>> culling
>>>>> >>>> none
>>>>> >>>> vs culling lethal for each activity (dawn, diurnal, dusk,
>>>>> nocturnal) for
>>>>> >>>> caracal, but I'm confused as to how to determine p-values to
>>>>> determine
>>>>> >>>> which activities culling none vs culling lethal are affecting?
>>>>> >>>>
>>>>> >>>> Myy code and outcomes are pasted below with questions stated in
>>>>> bold.
>>>>> >>>>
>>>>> >>>> caracal2 <- read.csv("caracal_new.csv", header=T)
>>>>> >>>> caracal <- as.data.frame(unclass(caracal2), stringsAsFactors =
>>>>> TRUE)
>>>>> >>>>
>>>>> >>>> #Chi-squared tests
>>>>> >>>> Ctable1 <- table(caracal$activity, caracal$culling)
>>>>> >>>> chisq.test(rowSums(Ctable1)) #strongly suggests activities differ
>>>>> >>>> chisq.test(Ctable1)#strongly suggests culling category differs
>>>>> >>>>
>>>>> >>>> Ctable2 <- table(caracal$activity, caracal$predator)
>>>>> >>>> chisq.test(rowSums(Ctable2))#strongly suggests activities differ
>>>>> >>>> chisq.test(Ctable2)#strongly suggests predator category differs
>>>>> >>>>
>>>>> >>>> prior = list(R = list(fix=1, V=(1/k) * (I + J)), G =
>>>>> list(G1=list(V =
>>>>> >>>> diag(k-1), nu=1)))
>>>>> >>>> test1c.5 <- MCMCglmm(activity ~ -1 + at.level(culling,1):trait +
>>>>> >>>> at.level(culling, 2):trait, random=~us(trait):Section, rcov =
>>>>> >>>> ~us(trait):units, data = caracal, family = "categorical", prior =
>>>>> prior,
>>>>> >>>> burnin=5000, nitt=60000)
>>>>> >>>> *##I'm not sure how to add the three predator levels to this
>>>>> model or if
>>>>> >>>> it
>>>>> >>>> would be appropriate?*
>>>>> >>>>
>>>>> >>>>
>>>>> >>>> k <- length(levels(caracal$activity))
>>>>> >>>> I <- diag(k-1)
>>>>> >>>> J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))
>>>>> >>>> IJ <- (1/k) *(diag(k-1) + matrix(1,k-1, k-1))
>>>>> >>>>
>>>>> >>>> contrasts(caracal$activity)
>>>>> >>>>
>>>>> >>>> #culling lethal
>>>>> >>>> Delta <- cbind(c(0,1,0,0), c(0,0,1,0), c(0,0,0,1))
>>>>> >>>> c2 <- (16 * sqrt(3)/(15 * pi))^2
>>>>> >>>> D <- ginv(Delta %*% t(Delta)) %*% Delta
>>>>> >>>> Int <- t(apply(test1c.5$Sol[,1:3],1, function(x) + D %*%
>>>>> (x/sqrt(1 + c2 *
>>>>> >>>> diag(IJ)))))
>>>>> >>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>>> >>>>
>>>>> >>>> prop.table(Ctable1[,1])
>>>>> >>>>
>>>>> >>>> #culling none
>>>>> >>>> Delta <- cbind(c(0,1,0,0), c(0,0,1,0), c(0,0,0,1))
>>>>> >>>> c2 <- (16 * sqrt(3)/(15 * pi))^2
>>>>> >>>> D <- ginv(Delta %*% t(Delta)) %*% Delta
>>>>> >>>> Int <- t(apply(test1c.5$Sol[,4:6],1, function(x) + D %*%
>>>>> (x/sqrt(1 + c2 *
>>>>> >>>> diag(IJ)))))
>>>>> >>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>>> >>>>
>>>>> >>>> prop.table((Ctable1[,2]))
>>>>> >>>>
>>>>> >>>> HPDinterval(test1c.5$Sol)
>>>>> >>>>
>>>>> >>>> #model summary
>>>>> >>>>> summary(test1c.5)
>>>>> >>>>
>>>>> >>>> Iterations = 5001:59991
>>>>> >>>> Thinning interval  = 10
>>>>> >>>> Sample size  = 5500
>>>>> >>>>
>>>>> >>>> DIC: 699.7014
>>>>> >>>>
>>>>> >>>> G-structure:  ~us(trait):Section
>>>>> >>>>
>>>>> >>>>                                                        post.mean
>>>>> l-95%
>>>>> >>>> CI
>>>>> >>>> u-95% CI eff.samp
>>>>> >>>> traitactivity.diurnal:traitactivity.diurnal.Section        1.8124
>>>>> >>>> 0.09784
>>>>> >>>>   5.665    77.01
>>>>> >>>> traitactivity.dusk:traitactivity.diurnal.Section           0.8450
>>>>> >>>> -0.83585
>>>>> >>>>   3.856    64.17
>>>>> >>>> traitactivity.nocturnal:traitactivity.diurnal.Section      1.3621
>>>>> >>>> -1.19129
>>>>> >>>>   6.157    58.48
>>>>> >>>> traitactivity.diurnal:traitactivity.dusk.Section           0.8450
>>>>> >>>> -0.83585
>>>>> >>>>   3.856    64.17
>>>>> >>>> traitactivity.dusk:traitactivity.dusk.Section              1.2034
>>>>> >>>> 0.07090
>>>>> >>>>   3.681   102.16
>>>>> >>>> traitactivity.nocturnal:traitactivity.dusk.Section         0.7505
>>>>> >>>> -1.77113
>>>>> >>>>   4.524    43.53
>>>>> >>>> traitactivity.diurnal:traitactivity.nocturnal.Section      1.3621
>>>>> >>>> -1.19129
>>>>> >>>>   6.157    58.48
>>>>> >>>> traitactivity.dusk:traitactivity.nocturnal.Section         0.7505
>>>>> >>>> -1.77113
>>>>> >>>>   4.524    43.53
>>>>> >>>> traitactivity.nocturnal:traitactivity.nocturnal.Section    2.7148
>>>>> >>>> 0.09401
>>>>> >>>>   8.397    76.59
>>>>> >>>>
>>>>> >>>> R-structure:  ~us(trait):units
>>>>> >>>>
>>>>> >>>>                                                      post.mean
>>>>> l-95% CI
>>>>> >>>> u-95% CI eff.samp
>>>>> >>>> traitactivity.diurnal:traitactivity.diurnal.units          0.50
>>>>>    0.50
>>>>> >>>>  0.50        0
>>>>> >>>> traitactivity.dusk:traitactivity.diurnal.units             0.25
>>>>>    0.25
>>>>> >>>>  0.25        0
>>>>> >>>> traitactivity.nocturnal:traitactivity.diurnal.units        0.25
>>>>>    0.25
>>>>> >>>>  0.25        0
>>>>> >>>> traitactivity.diurnal:traitactivity.dusk.units             0.25
>>>>>    0.25
>>>>> >>>>  0.25        0
>>>>> >>>> traitactivity.dusk:traitactivity.dusk.units                0.50
>>>>>    0.50
>>>>> >>>>  0.50        0
>>>>> >>>> traitactivity.nocturnal:traitactivity.dusk.units           0.25
>>>>>    0.25
>>>>> >>>>  0.25        0
>>>>> >>>> traitactivity.diurnal:traitactivity.nocturnal.units        0.25
>>>>>    0.25
>>>>> >>>>  0.25        0
>>>>> >>>> traitactivity.dusk:traitactivity.nocturnal.units           0.25
>>>>>    0.25
>>>>> >>>>  0.25        0
>>>>> >>>> traitactivity.nocturnal:traitactivity.nocturnal.units      0.50
>>>>>    0.50
>>>>> >>>>  0.50        0
>>>>> >>>>
>>>>> >>>> Location effects: activity ~ -1 + at.level(culling, 1):trait +
>>>>> >>>> at.level(culling, 2):trait
>>>>> >>>>
>>>>> >>>>                                             post.mean l-95% CI
>>>>> u-95% CI
>>>>> >>>> eff.samp  pMCMC
>>>>> >>>> at.level(culling, 1):traitactivity.diurnal      1.2306  -0.0533
>>>>>  2.6793
>>>>> >>>> 145.29 0.0418 *
>>>>> >>>> at.level(culling, 1):traitactivity.dusk         0.6605  -0.6006
>>>>>  2.0761
>>>>> >>>> 92.91 0.2840
>>>>> >>>> at.level(culling, 1):traitactivity.nocturnal    1.6090   0.0914
>>>>>  3.1356
>>>>> >>>> 151.02 0.0265 *
>>>>> >>>> traitactivity.diurnal:at.level(culling, 2)      1.2664  -0.1552
>>>>>  2.7750
>>>>> >>>> 226.40 0.0604 .
>>>>> >>>> traitactivity.dusk:at.level(culling, 2)         0.3533  -0.9898
>>>>>  1.5218
>>>>> >>>> 148.44 0.5447
>>>>> >>>> traitactivity.nocturnal:at.level(culling, 2)    1.0447  -0.6405
>>>>>  2.8354
>>>>> >>>> 346.40 0.1618
>>>>> >>>> ---
>>>>> >>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>>> >>>>
>>>>> >>>> *##So for the model summary I get that lethal culling at activity
>>>>> diurnal
>>>>> >>>> is significantly different from lethal culling at dawn (its the
>>>>> base
>>>>> >>>> reference), but I'm also interested in whether lethal culling at
>>>>> activity
>>>>> >>>> diurnal is different from lethal culling at dusk for example. Is
>>>>> this
>>>>> >>>> possible? *
>>>>> >>>>
>>>>> >>>> #outcomes culling lethal
>>>>> >>>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>>> >>>>
>>>>> >>>> Iterations = 1:5500
>>>>> >>>> Thinning interval = 1
>>>>> >>>> Number of chains = 1
>>>>> >>>> Sample size per chain = 5500
>>>>> >>>>
>>>>> >>>> 1. Empirical mean and standard deviation for each variable,
>>>>> >>>>   plus standard error of the mean:
>>>>> >>>>
>>>>> >>>>       Mean      SD  Naive SE Time-series SE
>>>>> >>>> [1,] 0.1253 0.05565 0.0007504       0.002484
>>>>> >>>> [2,] 0.3748 0.10497 0.0014155       0.003204
>>>>> >>>> [3,] 0.1757 0.06640 0.0008954       0.002515
>>>>> >>>> [4,] 0.3242 0.11939 0.0016099       0.003514
>>>>> >>>>
>>>>> >>>> 2. Quantiles for each variable:
>>>>> >>>>
>>>>> >>>>        2.5%     25%    50%    75%  97.5%
>>>>> >>>> var1 0.03641 0.08695 0.1198 0.1554 0.2553
>>>>> >>>> var2 0.17298 0.30580 0.3704 0.4431 0.5896
>>>>> >>>> var3 0.06166 0.12913 0.1705 0.2161 0.3215
>>>>> >>>> var4 0.12610 0.23999 0.3090 0.3901 0.6045
>>>>> >>>>
>>>>> >>>>> prop.table(Ctable1[,1])
>>>>> >>>>     dawn   diurnal      dusk nocturnal
>>>>> >>>> 0.1250000 0.2812500 0.1770833 0.4166667
>>>>> >>>>
>>>>> >>>>
>>>>> >>>> #outcomes culling none
>>>>> >>>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>>> >>>>
>>>>> >>>> Iterations = 1:5500
>>>>> >>>> Thinning interval = 1
>>>>> >>>> Number of chains = 1
>>>>> >>>> Sample size per chain = 5500
>>>>> >>>>
>>>>> >>>> 1. Empirical mean and standard deviation for each variable,
>>>>> >>>>   plus standard error of the mean:
>>>>> >>>>
>>>>> >>>>       Mean      SD  Naive SE Time-series SE
>>>>> >>>> [1,] 0.1288 0.06141 0.0008280       0.002787
>>>>> >>>> [2,] 0.3804 0.10406 0.0014032       0.002662
>>>>> >>>> [3,] 0.1710 0.06844 0.0009228       0.002592
>>>>> >>>> [4,] 0.3198 0.11812 0.0015928       0.002956
>>>>> >>>>
>>>>> >>>> 2. Quantiles for each variable:
>>>>> >>>>
>>>>> >>>>        2.5%     25%    50%    75%  97.5%
>>>>> >>>> var1 0.02891 0.08896 0.1220 0.1594 0.2685
>>>>> >>>> var2 0.18007 0.31094 0.3783 0.4474 0.5965
>>>>> >>>> var3 0.05840 0.12425 0.1634 0.2083 0.3250
>>>>> >>>> var4 0.12430 0.23921 0.3077 0.3862 0.5964
>>>>> >>>>
>>>>> >>>>> prop.table((Ctable1[,2]))
>>>>> >>>>     dawn   diurnal      dusk nocturnal
>>>>> >>>> 0.1306818 0.4375000 0.1875000 0.2443182
>>>>> >>>>
>>>>> >>>> Any help or guidance will be greatly appreciated.
>>>>> >>>>
>>>>> >>>> All the best,
>>>>> >>>> Jess
>>>>> >>>>
>>>>> >>>> --
>>>>> >>>> Jessica Comley (PhD)
>>>>> >>>> Research Scientist
>>>>> >>>>
>>>>> >>>>        [[alternative HTML version deleted]]
>>>>> >>>>
>>>>> >>>> _______________________________________________
>>>>> >>>> R-sig-mixed-models at r-project.org mailing list
>>>>> >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>> >>>>
>>>>> >>>
>>>>> >>
>>>>> >> --
>>>>> >> Jessica Comley (PhD)
>>>>> >> Research Scientist
>>>>> >>
>>>>> >>
>>>>> >
>>>>> >        [[alternative HTML version deleted]]
>>>>> >
>>>>> > _______________________________________________
>>>>> > R-sig-mixed-models at r-project.org mailing list
>>>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>> The University of Edinburgh is a charitable body, registered in
>>>>> Scotland, with registration number SC005336. Is e buidheann carthannais a
>>>>> th? ann an Oilthigh Dh?n ?ideann, cl?raichte an Alba, ?ireamh cl?raidh
>>>>> SC005336.
>>>>>
>>>>
>>>>
>>>> --
>>>> Jessica Comley (PhD)
>>>> Research Scientist
>>>>
>>>>
>>>>
>>>
>>> --
>>> Dr Jessica Comley
>>> Lecturer: Environmental and Life Sciences
>>> Faculty of Science
>>> Universiti Brunei Darussalam
>>>
>>> Email: jessica.comley at ubd.edu.bn
>>>
>>>
>>
>> --
>> Dr Jessica Comley
>> Lecturer: Environmental and Life Sciences
>> Faculty of Science
>> Universiti Brunei Darussalam
>>
>> Email: jessica.comley at ubd.edu.bn
>>
>>
>>
>
> --
> Dr Jessica Comley
> Lecturer: Environmental and Life Sciences
> Faculty of Science
> Universiti Brunei Darussalam
>
> Email: jessica.comley at ubd.edu.bn
>
>

-- 
Dr Jessica Comley
Lecturer: Environmental and Life Sciences
Faculty of Science
Universiti Brunei Darussalam

Email: jessica.comley at ubd.edu.bn

	[[alternative HTML version deleted]]


From je@@|ecom|ey44 @end|ng |rom gm@||@com  Wed Jul 27 07:31:42 2022
From: je@@|ecom|ey44 @end|ng |rom gm@||@com (jessica comley)
Date: Wed, 27 Jul 2022 13:31:42 +0800
Subject: [R-sig-ME] MCMCglmm with multinomial models
In-Reply-To: <5FBB3A08-E3BA-4925-8A64-DC6753C0BA5B@ed.ac.uk>
References: <CANdGWBHgzmN15cvGu7zU90o-+sZn4fUS92_nanb6OYYW8f2rog@mail.gmail.com>
 <CAJtCY7XH=AACiNbTo4SLo4gMQnM7ub1vVEOwGGqB-AvuJf5+Jw@mail.gmail.com>
 <CANdGWBFmXtPEvaREGQenkqq403+toEFJvLMgPTzdFWGix-ggGA@mail.gmail.com>
 <CAJtCY7XW=aT50ZCGUr2Y8ERPT1x2UC686Odti8n1kTRj4hC+LQ@mail.gmail.com>
 <57338F74-D980-4078-A389-EDA67E79C1A6@ed.ac.uk>
 <CANdGWBF3uc7SM0-a7uW54iNBPvRHPTTG+jd8-yjYzUz49o-N4g@mail.gmail.com>
 <63B269B7-6C5F-4A0C-BC08-51FE97C621BF@ed.ac.uk>
 <CANdGWBE5fEdZpnKiJ8ZgaRgFChG4=K5zp2Gpufq-p8KRddX7fw@mail.gmail.com>
 <CANdGWBFY0s2y=qaKhwKAU5cvg2xW5rQ_3CmmXvvj+q5v-Fee3g@mail.gmail.com>
 <56260042-774A-4135-9E38-986F98546F45@ed.ac.uk>
 <CANdGWBFRhtZLV3U4QmP9FmZPFmw_6Ht5x9WiyiyV2ao_D9KimA@mail.gmail.com>
 <CANdGWBFJ30UCL3pXXPzn3fQT54vcQXvrdn2vsg_0B-XcYV2sHw@mail.gmail.com>
 <5FBB3A08-E3BA-4925-8A64-DC6753C0BA5B@ed.ac.uk>
Message-ID: <CANdGWBEPE2=pbb5Y2J3jcjmoCbfbUyOM89LrkuDhduZUqnXMKw@mail.gmail.com>

Sorry, let me try rephrasing my question. From my results, how do I
interpret the base activity nocturnal. Does the significant result of
*traitdiurnal:cullingnone
*mean that there is more diurnal activity than nocturnal activity when
culling is none compared to lethal?

On Wed, Jul 27, 2022 at 12:54 PM Jarrod Hadfield <j.hadfield at ed.ac.uk>
wrote:

> The trait:culling interactions are the degree to which activity is higher
> when culling is none rather than lethal. If you exponentiate the effects
> you get the promotional change in the odds ratio none:lethal.
>
>
>
> On 27 Jul 2022, at 05:48, jessica comley <jessiecomley44 at gmail.com> wrote:
>
> This email was sent to you by someone outside the University.
> You should only click on links or attachments if you are certain that the
> email is genuine and the content is safe.
> Sorry Jarrod, one last question I swear.
>
> From my corrected outcome:
>
> *Location effects: cbind(dawn, diurnal, dusk, nocturnal) ~ trait - 1 +
> trait:culling + trait:predator*
>
> *                          post.mean l-95% CI u-95% CI eff.samp   pMCMC   *
> *traitdawn                  -1.49696 -1.91443 -1.03494    449.8 < 7e-05
> ****
> *traitdiurnal               -1.26128 -1.65569 -0.87573    173.7 < 7e-05
> ****
> *traitdusk                  -1.69165 -2.14582 -1.25074    304.0 < 7e-05
> ****
> *traitdawn:cullingnone      -0.35018 -0.75539  0.03488   1453.5 0.06068 . *
> *traitdiurnal:cullingnone    0.61075  0.22682  0.99247    646.2 0.00653 ***
> *traitdusk:cullingnone       0.32833 -0.07876  0.72035   1218.7 0.10136   *
> *traitdawn:predatorhigh      0.12826 -0.48062  0.81929    696.5 0.70884   *
> *traitdiurnal:predatorhigh  -0.45382 -1.03340  0.15183    293.7 0.12313   *
> *traitdusk:predatorhigh     -0.14870 -0.77156  0.49585    475.2 0.62830   *
> *traitdawn:predatorlow       0.41706 -0.11004  0.93341    579.5 0.10626   *
> *traitdiurnal:predatorlow   -0.01279 -0.47660  0.49818    206.6 0.95741   *
> *traitdusk:predatorlow       0.16600 -0.36760  0.71419    323.0 0.55102
>   *
>
> How would I work out whether traitnocturnal:cullingnone occured more or
> less than cullinglethal? Is this something that can be done?
>
> Cheers,
> Jess
>
> On Wed, Jul 27, 2022 at 12:24 PM jessica comley <jessiecomley44 at gmail.com>
> wrote:
>
>> Hi Jarrod,
>>
>> Yes I did have a typo in my data, which I have corrected and now all is
>> working well.
>>
>> Thank you very much for your help, I really do appreciate your responses!
>>
>> Cheers,
>> Jess
>>
>> On Wed, Jul 27, 2022 at 12:14 PM Jarrod Hadfield <j.hadfield at ed.ac.uk>
>> wrote:
>>
>>> Hi,
>>>
>>> 1/ My guess is that there is a mistake/typo in your data.frame: culling
>>> has 3 levels not 2. Does table(bbj$culling) return what you expect?
>>>
>>> 2/ They mean i) there is more diurnal activity under culling compared to
>>> whatever the mystery level of culling is. ii) there is more dawn activity
>>> when predators is low compared to absent.
>>>
>>> 3/ The indices should be for all terms involving the thing to be tested.
>>> So in the current model they should be 4:9 and 10:15 (not 3:5 and 6:8).
>>> This will change when you sort out your culling column (probably to 4:6 and
>>> 7:12). In my previous email I said you should be testing 3 effects for
>>> predator, but in fact there should be 6 (I thought predator had 3 levels
>>> not 2).
>>>
>>> You might want a -1 in your model formula (i.e
>>> trait-1+trait:culling+trait:predator) to make the interpretation of the
>>> first 3 terms a little easier, but up to you.
>>>
>>> Cheers,
>>>
>>> Jarrod
>>>
>>>
>>>
>>>
>>>
>>>
>>> On 27 Jul 2022, at 04:42, jessica comley <jessiecomley44 at gmail.com>
>>> wrote:
>>>
>>> This email was sent to you by someone outside the University.
>>> You should only click on links or attachments if you are certain that
>>> the email is genuine and the content is safe.
>>> Dear Jarrod,
>>>
>>> Sorry to bother you again, I just want to make sure I am doing this
>>> correctly and understanding my results.
>>>
>>> I used the model you suggested:
>>>
>>> *prior1=list(R=list(V=1, nu=0.002)) m1<-MCMCglmm(cbind(dawn, diurnal,
>>> dusk, nocturnal)~trait+trait:culling+trait:predator,
>>> rcov=~idv(units+trait:units), prior=prior1, data=bbj,
>>> family="multinomial4", nitt= 150000)*
>>>
>>> And this is my outcome:
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> *Iterations = 3001:149991  Thinning interval  = 10  Sample size  =
>>> 14700   DIC: 10312.95   R-structure:  ~idv(units + trait:units)
>>> post.mean  l-95% CI u-95% CI eff.samp trait:units   0.01932 0.0002102
>>>  0.07042      441  Location effects: cbind(dawn, diurnal, dusk, nocturnal)
>>> ~ trait + trait:culling + trait:predator
>>>  post.mean  l-95% CI  u-95% CI eff.samp   pMCMC     (Intercept)
>>>    -2.018903 -2.677830 -1.335305    609.1 < 7e-05 *** traitdiurnal
>>>        0.542636 -0.363766  1.405230    644.6 0.22068     traitdusk
>>>          -0.047952 -0.984923  0.917710    374.6 0.91850
>>> traitdawn:cullingLethal     0.534474  0.003076  1.058211    596.8 0.05524 .
>>>   traitdiurnal:cullingLethal  0.232597 -0.369959  0.834347    404.7 0.42789
>>>     traitdusk:cullingLethal     0.376191 -0.217707  0.964636    408.2
>>> 0.19782     traitdawn:cullingnone      -0.163961 -0.573477  0.298182
>>> 2945.5 0.38245     traitdiurnal:cullingnone    0.674041  0.247724  1.101917
>>>   2825.0 0.00952 **  traitdusk:cullingnone       0.449710 -0.014263
>>>  0.874925   1683.9 0.05102 .   traitdawn:predatorhigh      0.456119
>>> -0.206435  1.151283    561.7 0.18531     traitdiurnal:predatorhigh
>>>  -0.303114 -0.976842  0.377294    479.9 0.36939     traitdusk:predatorhigh
>>>      0.108262 -0.674552  0.895819    256.7 0.76122
>>> traitdawn:predatorlow       0.756262  0.160407  1.323520    418.1 0.01279 *
>>>   traitdiurnal:predatorlow    0.136875 -0.446984  0.750518    305.7 0.65619
>>>     traitdusk:predatorlow       0.422497 -0.303586  1.145038    194.9
>>> 0.22857     --- Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ?
>>> ? 1*
>>>
>>> 1) Why do the 2 categories for culling both show up but then only 2 of
>>> the three categories for predator show up? i.e. predatorabsent is missing?
>>>
>>> 2) Do these results mean that i) diurnal activity and lethal culling is
>>> sig different from nocturnal activity and lethal culling; ii) dawn activity
>>> and predator low is sig different from nocturnal activity and predator low?
>>>
>>> 3) Is this the correct way and interpretation of the within group
>>> effects?
>>> *##culling lethal*
>>>
>>>
>>> * aod::wald.test(cov(m1$Sol[,3:5]),
>>> colMeans(m1$Sol[,3:5]),Terms=1:3)$result$chi2["P"]         P  0.1638938*
>>>
>>>
>>>
>>>
>>> * ##culling  none aod::wald.test(cov(m1$Sol[,6:8]),
>>> colMeans(m1$Sol[,6:8]),Terms=1:3)$result$chi2["P"]           P  0.006497424*
>>>
>>>
>>> So these results show us that culling none has an effect on activity?
>>>
>>> Thank you in advance,
>>> Jess
>>>
>>> On Wed, Jul 27, 2022 at 8:20 AM jessica comley <jessiecomley44 at gmail.com>
>>> wrote:
>>>
>>>> Dear Jarrod,
>>>>
>>>> Thank you so much for your help, I greatly appreciate it!
>>>>
>>>> All the best,
>>>> Jess
>>>>
>>>> On Wed, Jul 27, 2022 at 3:32 AM Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>>> wrote:
>>>>
>>>>> Hi Jess,
>>>>>
>>>>> Section should definitely not be left out, but I would imagine it is
>>>>> going to be very difficult to separate culling, predator and Section
>>>>> effects - I would expect the credible intervals to be large.
>>>>>
>>>>> As mentioned in my previous post you can test for an effect of culling
>>>>> by fitting the model
>>>>>
>>>>> ~trait+trait:culling+trait:predator
>>>>>
>>>>> And then fitting a Wald test to the three terms with 'culling' in. The
>>>>> effect of predator can be tested similarly but with the 3 terms with
>>>>> 'predator' in.
>>>>>
>>>>> Since your covariates do not vary within Section it will be much
>>>>> easier to aggregate the counts at the Section level (i.e have a data frame
>>>>> with 14 rows and 1 column for each activity with the number observed for
>>>>> each activity) and fit family="multinomial". You can then get rid of the
>>>>> random formula as the Section effects are now effectively the residuals.
>>>>> Given the lack of replication I would advise using the idv formula that I
>>>>> suggested previously and hope the model isn't too misspecified:
>>>>>
>>>>> prior=list(R=list(V=1, nu=0.002))
>>>>>
>>>>> m1<-MCMCglmm(cbind(dawn, diurnal, dusk,
>>>>> nocturnal)~trait+trait:culling+trait:predator,
>>>>> rcov=~idv(units+trait:units), prior=prior, ...)
>>>>>
>>>>> Note this models is identical to the original model, it's just
>>>>> parameterised in a more efficient way.
>>>>>
>>>>> Cheers,
>>>>>
>>>>> Jarrod
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> On 25 Jul 2022, at 03:52, jessica comley <jessiecomley44 at gmail.com>
>>>>> wrote:
>>>>>
>>>>> This email was sent to you by someone outside the University.
>>>>> You should only click on links or attachments if you are certain that
>>>>> the email is genuine and the content is safe.
>>>>> Dear Jarrod and Walid,
>>>>>
>>>>> Thank you for your replies, it is greatly appreciated.
>>>>>
>>>>> The predator and culling factors do not vary within sites. As shown in
>>>>> the example data in one of my previous emails, Bucklands only has culling
>>>>> as lethal and predator as low, whereas Colchester only has predator as high
>>>>> and culling as none.
>>>>>
>>>>> We are trying to submit a paper on black-backed jackal and caracal
>>>>> activity in the presence of different culling practices and
>>>>> predator presence. The reviewers want us to try a GLMM approach to
>>>>> determine whether culling or predators have an effect on black-backed
>>>>> jackal or caracal activity.
>>>>>
>>>>> Therefore, in your opinion how could be go about this given our data?
>>>>> Would it be advisable to leave out the random effect of Section?
>>>>>
>>>>> All the best,
>>>>> Jess
>>>>>
>>>>> On Wed, Jul 20, 2022 at 3:06 PM Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>>>> wrote:
>>>>>
>>>>>> Hi Jess
>>>>>>
>>>>>> In multinomial models the linear model is set up as a (logit)
>>>>>> difference in probability between an outcome and some base-line outcome.
>>>>>> Often, as here, the base-line outcome is arbitrary, and so the idh
>>>>>> structure is a little odd. For example, if A is the base line category, idh
>>>>>> assumes COV(B-A, C-A) = 0 which therefore assumes
>>>>>> COV(B,C)+VAR(A) =COV(A,B)+COV(C,A). It's not clear why this would be
>>>>>> the case. Perhaps a more reasonable, but less parameter rich, option would
>>>>>> be to have:
>>>>>>
>>>>>> ~idv(Section+trait:Section)
>>>>>>
>>>>>> which parameterises the Section covariance matrix by a single
>>>>>> parameter (rather than 6). The term idv(Section+trait:Section) fits a 3x3
>>>>>> covariance matrix of the form v*(I+J) where v is the estimated variance.
>>>>>> This assumes i) Sections are repeatable in outcome, but knowing that a
>>>>>> Section has an increased 'preference' for A doesn?t tell you whether it
>>>>>> also has an increased preference for one of the other categories and ii)
>>>>>> the repeatability for each outcome within sites is the same (on the latent
>>>>>> scale).
>>>>>>
>>>>>> To test groups of effects (in your case the 3 culling:trait effects),
>>>>>> I usually use a Wald test and the posterior covariances (see here
>>>>>> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2017q3/025930.html).
>>>>>> It's far from correct and so Walid's suggestions may be better, but
>>>>>> small-scale simulations suggests it has good frequentist properties.
>>>>>>
>>>>>> To add predator presence you can just add a predator:trait effect
>>>>>> into the linear model. If the culling and predator factors do not vary
>>>>>> within sites then you probably don't have enough information to reliably
>>>>>> estimate these effects.
>>>>>>
>>>>>> Cheers,
>>>>>>
>>>>>> Jarrod
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> > On 19 Jul 2022, at 18:17, Walid Mawass <walidmawass10 at gmail.com>
>>>>>> wrote:
>>>>>> >
>>>>>> > This email was sent to you by someone outside the University.
>>>>>> > You should only click on links or attachments if you are certain
>>>>>> that the email is genuine and the content is safe.
>>>>>> >
>>>>>> > Hey Jess,
>>>>>> >
>>>>>> > 1) Yes that is correct
>>>>>> >
>>>>>> > 2) To my knowledge there is a rule of thumb, where you set the nitt
>>>>>> (# of
>>>>>> > iterations) to a large number that includes the burnin amount, then
>>>>>> you
>>>>>> > choose your thinning interval (sampling of the chain). For example,
>>>>>> this is
>>>>>> > what I would use: nitt= 150000, burnin=50000, thin=100. This will
>>>>>> give you
>>>>>> > a decent burnin and a final sample of 1000 saved iterations. Note
>>>>>> however
>>>>>> > that this does not have to increase the effective sample size for
>>>>>> certain
>>>>>> > variables, but it might do the trick.
>>>>>> >
>>>>>> > 3) hmm...I think one way to do it is to make predictions using the
>>>>>> above
>>>>>> > model and interpret the patterns you see for each relationship you
>>>>>> are
>>>>>> > interested in. Another way to compare effect size would be to use
>>>>>> bayesian
>>>>>> > posterior indices. I suggest these two papers by Makowski et al.
>>>>>> (2019a &
>>>>>> > b) that present both interesting posterior indices to use with
>>>>>> Bayesian
>>>>>> > statistical analysis and an associated R package that does the job
>>>>>> of
>>>>>> > computing these indices, *bayestestR*.
>>>>>> >
>>>>>> > Good luck
>>>>>> > --
>>>>>> > Walid Mawass
>>>>>> > Ph.D. candidate in Evolutionary Biology - UQTR
>>>>>> > *Currently* Postdoctoral Research Associate
>>>>>> > Masel Lab - University of Arizona
>>>>>> >
>>>>>> >
>>>>>> > On Sun, Jul 17, 2022 at 11:32 PM jessica comley <
>>>>>> jessiecomley44 at gmail.com>
>>>>>> > wrote:
>>>>>> >
>>>>>> >> Hi Walid,
>>>>>> >>
>>>>>> >> Thank you for your reply, I greatly appreciate it. I have a few
>>>>>> more
>>>>>> >> questions and if you could help that would be great.
>>>>>> >>
>>>>>> >> I tested for correlation between activities and the 14 Sections
>>>>>> and the
>>>>>> >> correlation comes out as low. Therefore I have changed my code to
>>>>>> use idh()
>>>>>> >> instead of us as suggested:
>>>>>> >>
>>>>>> >> test1c.5b <- MCMCglmm(activity ~ -1 + at.level(culling,1):trait +
>>>>>> >> at.level(culling, 2):trait, random=~idh(trait):Section, rcov =
>>>>>> >> ~idh(trait):units, data = caracal, family = "categorical", prior =
>>>>>> prior,
>>>>>> >> burnin=5000, nitt=80000)
>>>>>> >>
>>>>>> >> 1) Is this correct?
>>>>>> >>
>>>>>> >> 2) Increasing the number of interactions increases the effective
>>>>>> sample
>>>>>> >> size, therefore is there a general rule of thumb as to how large
>>>>>> your
>>>>>> >> effective sample size should be?
>>>>>> >>
>>>>>> >> 3) I understand how to use and interpret the results of
>>>>>> HPDinterval (i.e.
>>>>>> >> if intervals do not overlap 0 then relationship is strong), but
>>>>>> how am I
>>>>>> >> able to test the relationship between all four activities and
>>>>>> fixed effects
>>>>>> >> and not just have the three categories (i.e. diurnal, dusk,
>>>>>> nocturnal)
>>>>>> >> compared to the base category (dawn)? For example, I am also
>>>>>> interested in
>>>>>> >> whether there is a significant/strong relationship between
>>>>>> activities of
>>>>>> >> caracal at dusk with culling(Lethal)/no culling(none) compared to
>>>>>> >> activities of caracal at diurnal with culling(Lethal)/no
>>>>>> culling(none).
>>>>>> >>
>>>>>> >> Below is an example of our dataset:
>>>>>> >> Camera Section CameraID Animal predator culling activity
>>>>>> >> 1a Bucklands Bucklands1a Caracal low Lethal diurnal
>>>>>> >> 1a Bucklands Bucklands1a Caracal low Lethal dawn
>>>>>> >> 2a Bucklands Bucklands2a Caracal low Lethal dusk
>>>>>> >> 2a Bucklands Bucklands2a Caracal low Lethal diurnal
>>>>>> >> 3a Bucklands Bucklands3a Caracal low Lethal dawn
>>>>>> >> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>>>>>> >> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>>>>>> >> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>>>>>> >> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>>>>>> >> Cam 2  Colchester ColchesterCam 2  Caracal high none diurnal
>>>>>> >> Cam 2  Colchester ColchesterCam 2  Caracal high none diurnal
>>>>>> >> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
>>>>>> >> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
>>>>>> >> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
>>>>>> >> Cam 4  Colchester ColchesterCam 4  Caracal high none diurnal
>>>>>> >> Cam 4  Colchester ColchesterCam 4  Caracal high none diurnal
>>>>>> >> Cam 4  Colchester ColchesterCam 4  Caracal high none nocturnal
>>>>>> >> 1a Connaught Connaught1a Caracal low Lethal nocturnal
>>>>>> >> 1a Connaught Connaught1a Caracal low Lethal nocturnal
>>>>>> >> 1d Connaught Connaught1d Caracal low Lethal diurnal
>>>>>> >> 3B Connaught Connaught3B Caracal low Lethal diurnal
>>>>>> >> 3B Connaught Connaught3B Caracal low Lethal diurnal
>>>>>> >> 4a Connaught Connaught4a Caracal low Lethal nocturnal
>>>>>> >> 4a Connaught Connaught4a Caracal low Lethal nocturnal
>>>>>> >> 4b Connaught Connaught4b Caracal low Lethal diurnal
>>>>>> >> 6a Connaught Connaught6a Caracal low Lethal nocturnal
>>>>>> >> 6b Connaught Connaught6b Caracal low Lethal diurnal
>>>>>> >> 7a Connaught Connaught7a Caracal low Lethal nocturnal
>>>>>> >> 9a Connaught Connaught9a Caracal low Lethal nocturnal
>>>>>> >> 9d Connaught Connaught9d Caracal low Lethal nocturnal
>>>>>> >> 9d Connaught Connaught9d Caracal low Lethal dusk
>>>>>> >> 7d Diepdam Diepdam7d Caracal absent Lethal dusk
>>>>>> >> 8d Diepdam Diepdam8d Caracal absent Lethal diurnal
>>>>>> >> 9c Diepdam Diepdam9c Caracal absent Lethal nocturnal
>>>>>> >>
>>>>>> >> All the best,
>>>>>> >> Jess
>>>>>> >>
>>>>>> >>
>>>>>> >> On Fri, Jul 15, 2022 at 11:37 PM Walid Mawass <
>>>>>> walidmawass10 at gmail.com>
>>>>>> >> wrote:
>>>>>> >>
>>>>>> >>> Hello,
>>>>>> >>>
>>>>>> >>> I don't think I can specifically help you with some of your
>>>>>> inquiries.
>>>>>> >>> However, I do want to comment on a few things that might need some
>>>>>> >>> attention.
>>>>>> >>>
>>>>>> >>> First, MCMCglmm is based on a Bayesian implementation and does not
>>>>>> >>> compute p-values to compare. What you need to compare are the
>>>>>> posterior
>>>>>> >>> distributions of your effect sizes. This can be done visually
>>>>>> using the
>>>>>> >>> base plot function in R. Or by comparing the HPD intervals and
>>>>>> the mode (or
>>>>>> >>> mean) of the posterior distributions.
>>>>>> >>>
>>>>>> >>> Second, I have no idea what your data structure looks like (which
>>>>>> makes
>>>>>> >>> it hard to interpret model results), but the effective sample
>>>>>> size (from
>>>>>> >>> the 5500 saved iterations sample) for your random variable
>>>>>> Section is very
>>>>>> >>> low (the same applies for your fixed effects). You should
>>>>>> consider this
>>>>>> >>> issue and look again at your assumption of correlation between
>>>>>> >>> activities for the 14 sections you have in your dataset. If you
>>>>>> do not
>>>>>> >>> expect among activity correlations then you can use the idh()
>>>>>> function
>>>>>> >>> instead of us().
>>>>>> >>>
>>>>>> >>> Hopefully this helps and in hope that people on this list with
>>>>>> more
>>>>>> >>> knowledge of these models will help out.
>>>>>> >>>
>>>>>> >>> Best,
>>>>>> >>> --
>>>>>> >>> Walid Mawass
>>>>>> >>> Ph.D. candidate in Evolutionary Biology - UQTR
>>>>>> >>> *Currently* Postdoctoral Research Associate
>>>>>> >>> Masel Lab - University of Arizona
>>>>>> >>>
>>>>>> >>>
>>>>>> >>> On Fri, Jul 15, 2022 at 8:49 AM jessica comley <
>>>>>> jessiecomley44 at gmail.com>
>>>>>> >>> wrote:
>>>>>> >>>
>>>>>> >>>> Dear all,
>>>>>> >>>>
>>>>>> >>>> I am hoping that someone will be able to help me with conducting
>>>>>> MCMCglmm
>>>>>> >>>> multinomial models.
>>>>>> >>>>
>>>>>> >>>> The data I am working with is for black-backed jackal (bbj) and
>>>>>> carcal.
>>>>>> >>>> For
>>>>>> >>>> each species we have a multinomial response variable called
>>>>>> activity
>>>>>> >>>> which
>>>>>> >>>> has four categories (dawn, diurnal, dusk, nocturnal). We have two
>>>>>> >>>> categorical fixed effects which are 1) culling (none, lethal)
>>>>>> and 2)
>>>>>> >>>> predator presence (absent, high, low). We also have a categorical
>>>>>> >>>> variable
>>>>>> >>>> called Section (made up of 14 different reserves/ farms where the
>>>>>> >>>> activity
>>>>>> >>>> of caracal and bbj were recorded). There are 273 observations
>>>>>> for caracal
>>>>>> >>>> and 4399 for bbj. We are wanting to test the effects of culling
>>>>>> and
>>>>>> >>>> predators on caracal and bbj activity separately.
>>>>>> >>>>
>>>>>> >>>> I have been working through Jarrod Hadfields course notes,
>>>>>> particularly
>>>>>> >>>> with regards to Chapter 5.2. The chi-square analyses reveal that
>>>>>> the
>>>>>> >>>> frequencies of culling and predators differ as do activities.
>>>>>> >>>>
>>>>>> >>>> I have managed to work out the specific probabilities for the
>>>>>> culling
>>>>>> >>>> none
>>>>>> >>>> vs culling lethal for each activity (dawn, diurnal, dusk,
>>>>>> nocturnal) for
>>>>>> >>>> caracal, but I'm confused as to how to determine p-values to
>>>>>> determine
>>>>>> >>>> which activities culling none vs culling lethal are affecting?
>>>>>> >>>>
>>>>>> >>>> Myy code and outcomes are pasted below with questions stated in
>>>>>> bold.
>>>>>> >>>>
>>>>>> >>>> caracal2 <- read.csv("caracal_new.csv", header=T)
>>>>>> >>>> caracal <- as.data.frame(unclass(caracal2), stringsAsFactors =
>>>>>> TRUE)
>>>>>> >>>>
>>>>>> >>>> #Chi-squared tests
>>>>>> >>>> Ctable1 <- table(caracal$activity, caracal$culling)
>>>>>> >>>> chisq.test(rowSums(Ctable1)) #strongly suggests activities differ
>>>>>> >>>> chisq.test(Ctable1)#strongly suggests culling category differs
>>>>>> >>>>
>>>>>> >>>> Ctable2 <- table(caracal$activity, caracal$predator)
>>>>>> >>>> chisq.test(rowSums(Ctable2))#strongly suggests activities differ
>>>>>> >>>> chisq.test(Ctable2)#strongly suggests predator category differs
>>>>>> >>>>
>>>>>> >>>> prior = list(R = list(fix=1, V=(1/k) * (I + J)), G =
>>>>>> list(G1=list(V =
>>>>>> >>>> diag(k-1), nu=1)))
>>>>>> >>>> test1c.5 <- MCMCglmm(activity ~ -1 + at.level(culling,1):trait +
>>>>>> >>>> at.level(culling, 2):trait, random=~us(trait):Section, rcov =
>>>>>> >>>> ~us(trait):units, data = caracal, family = "categorical", prior
>>>>>> = prior,
>>>>>> >>>> burnin=5000, nitt=60000)
>>>>>> >>>> *##I'm not sure how to add the three predator levels to this
>>>>>> model or if
>>>>>> >>>> it
>>>>>> >>>> would be appropriate?*
>>>>>> >>>>
>>>>>> >>>>
>>>>>> >>>> k <- length(levels(caracal$activity))
>>>>>> >>>> I <- diag(k-1)
>>>>>> >>>> J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))
>>>>>> >>>> IJ <- (1/k) *(diag(k-1) + matrix(1,k-1, k-1))
>>>>>> >>>>
>>>>>> >>>> contrasts(caracal$activity)
>>>>>> >>>>
>>>>>> >>>> #culling lethal
>>>>>> >>>> Delta <- cbind(c(0,1,0,0), c(0,0,1,0), c(0,0,0,1))
>>>>>> >>>> c2 <- (16 * sqrt(3)/(15 * pi))^2
>>>>>> >>>> D <- ginv(Delta %*% t(Delta)) %*% Delta
>>>>>> >>>> Int <- t(apply(test1c.5$Sol[,1:3],1, function(x) + D %*%
>>>>>> (x/sqrt(1 + c2 *
>>>>>> >>>> diag(IJ)))))
>>>>>> >>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>>>> >>>>
>>>>>> >>>> prop.table(Ctable1[,1])
>>>>>> >>>>
>>>>>> >>>> #culling none
>>>>>> >>>> Delta <- cbind(c(0,1,0,0), c(0,0,1,0), c(0,0,0,1))
>>>>>> >>>> c2 <- (16 * sqrt(3)/(15 * pi))^2
>>>>>> >>>> D <- ginv(Delta %*% t(Delta)) %*% Delta
>>>>>> >>>> Int <- t(apply(test1c.5$Sol[,4:6],1, function(x) + D %*%
>>>>>> (x/sqrt(1 + c2 *
>>>>>> >>>> diag(IJ)))))
>>>>>> >>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>>>> >>>>
>>>>>> >>>> prop.table((Ctable1[,2]))
>>>>>> >>>>
>>>>>> >>>> HPDinterval(test1c.5$Sol)
>>>>>> >>>>
>>>>>> >>>> #model summary
>>>>>> >>>>> summary(test1c.5)
>>>>>> >>>>
>>>>>> >>>> Iterations = 5001:59991
>>>>>> >>>> Thinning interval  = 10
>>>>>> >>>> Sample size  = 5500
>>>>>> >>>>
>>>>>> >>>> DIC: 699.7014
>>>>>> >>>>
>>>>>> >>>> G-structure:  ~us(trait):Section
>>>>>> >>>>
>>>>>> >>>>                                                        post.mean
>>>>>> l-95%
>>>>>> >>>> CI
>>>>>> >>>> u-95% CI eff.samp
>>>>>> >>>> traitactivity.diurnal:traitactivity.diurnal.Section        1.8124
>>>>>> >>>> 0.09784
>>>>>> >>>>   5.665    77.01
>>>>>> >>>> traitactivity.dusk:traitactivity.diurnal.Section           0.8450
>>>>>> >>>> -0.83585
>>>>>> >>>>   3.856    64.17
>>>>>> >>>> traitactivity.nocturnal:traitactivity.diurnal.Section      1.3621
>>>>>> >>>> -1.19129
>>>>>> >>>>   6.157    58.48
>>>>>> >>>> traitactivity.diurnal:traitactivity.dusk.Section           0.8450
>>>>>> >>>> -0.83585
>>>>>> >>>>   3.856    64.17
>>>>>> >>>> traitactivity.dusk:traitactivity.dusk.Section              1.2034
>>>>>> >>>> 0.07090
>>>>>> >>>>   3.681   102.16
>>>>>> >>>> traitactivity.nocturnal:traitactivity.dusk.Section         0.7505
>>>>>> >>>> -1.77113
>>>>>> >>>>   4.524    43.53
>>>>>> >>>> traitactivity.diurnal:traitactivity.nocturnal.Section      1.3621
>>>>>> >>>> -1.19129
>>>>>> >>>>   6.157    58.48
>>>>>> >>>> traitactivity.dusk:traitactivity.nocturnal.Section         0.7505
>>>>>> >>>> -1.77113
>>>>>> >>>>   4.524    43.53
>>>>>> >>>> traitactivity.nocturnal:traitactivity.nocturnal.Section    2.7148
>>>>>> >>>> 0.09401
>>>>>> >>>>   8.397    76.59
>>>>>> >>>>
>>>>>> >>>> R-structure:  ~us(trait):units
>>>>>> >>>>
>>>>>> >>>>                                                      post.mean
>>>>>> l-95% CI
>>>>>> >>>> u-95% CI eff.samp
>>>>>> >>>> traitactivity.diurnal:traitactivity.diurnal.units          0.50
>>>>>>    0.50
>>>>>> >>>>  0.50        0
>>>>>> >>>> traitactivity.dusk:traitactivity.diurnal.units             0.25
>>>>>>    0.25
>>>>>> >>>>  0.25        0
>>>>>> >>>> traitactivity.nocturnal:traitactivity.diurnal.units        0.25
>>>>>>    0.25
>>>>>> >>>>  0.25        0
>>>>>> >>>> traitactivity.diurnal:traitactivity.dusk.units             0.25
>>>>>>    0.25
>>>>>> >>>>  0.25        0
>>>>>> >>>> traitactivity.dusk:traitactivity.dusk.units                0.50
>>>>>>    0.50
>>>>>> >>>>  0.50        0
>>>>>> >>>> traitactivity.nocturnal:traitactivity.dusk.units           0.25
>>>>>>    0.25
>>>>>> >>>>  0.25        0
>>>>>> >>>> traitactivity.diurnal:traitactivity.nocturnal.units        0.25
>>>>>>    0.25
>>>>>> >>>>  0.25        0
>>>>>> >>>> traitactivity.dusk:traitactivity.nocturnal.units           0.25
>>>>>>    0.25
>>>>>> >>>>  0.25        0
>>>>>> >>>> traitactivity.nocturnal:traitactivity.nocturnal.units      0.50
>>>>>>    0.50
>>>>>> >>>>  0.50        0
>>>>>> >>>>
>>>>>> >>>> Location effects: activity ~ -1 + at.level(culling, 1):trait +
>>>>>> >>>> at.level(culling, 2):trait
>>>>>> >>>>
>>>>>> >>>>                                             post.mean l-95% CI
>>>>>> u-95% CI
>>>>>> >>>> eff.samp  pMCMC
>>>>>> >>>> at.level(culling, 1):traitactivity.diurnal      1.2306  -0.0533
>>>>>>  2.6793
>>>>>> >>>> 145.29 0.0418 *
>>>>>> >>>> at.level(culling, 1):traitactivity.dusk         0.6605  -0.6006
>>>>>>  2.0761
>>>>>> >>>> 92.91 0.2840
>>>>>> >>>> at.level(culling, 1):traitactivity.nocturnal    1.6090   0.0914
>>>>>>  3.1356
>>>>>> >>>> 151.02 0.0265 *
>>>>>> >>>> traitactivity.diurnal:at.level(culling, 2)      1.2664  -0.1552
>>>>>>  2.7750
>>>>>> >>>> 226.40 0.0604 .
>>>>>> >>>> traitactivity.dusk:at.level(culling, 2)         0.3533  -0.9898
>>>>>>  1.5218
>>>>>> >>>> 148.44 0.5447
>>>>>> >>>> traitactivity.nocturnal:at.level(culling, 2)    1.0447  -0.6405
>>>>>>  2.8354
>>>>>> >>>> 346.40 0.1618
>>>>>> >>>> ---
>>>>>> >>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>>>> >>>>
>>>>>> >>>> *##So for the model summary I get that lethal culling at
>>>>>> activity diurnal
>>>>>> >>>> is significantly different from lethal culling at dawn (its the
>>>>>> base
>>>>>> >>>> reference), but I'm also interested in whether lethal culling at
>>>>>> activity
>>>>>> >>>> diurnal is different from lethal culling at dusk for example. Is
>>>>>> this
>>>>>> >>>> possible? *
>>>>>> >>>>
>>>>>> >>>> #outcomes culling lethal
>>>>>> >>>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>>>> >>>>
>>>>>> >>>> Iterations = 1:5500
>>>>>> >>>> Thinning interval = 1
>>>>>> >>>> Number of chains = 1
>>>>>> >>>> Sample size per chain = 5500
>>>>>> >>>>
>>>>>> >>>> 1. Empirical mean and standard deviation for each variable,
>>>>>> >>>>   plus standard error of the mean:
>>>>>> >>>>
>>>>>> >>>>       Mean      SD  Naive SE Time-series SE
>>>>>> >>>> [1,] 0.1253 0.05565 0.0007504       0.002484
>>>>>> >>>> [2,] 0.3748 0.10497 0.0014155       0.003204
>>>>>> >>>> [3,] 0.1757 0.06640 0.0008954       0.002515
>>>>>> >>>> [4,] 0.3242 0.11939 0.0016099       0.003514
>>>>>> >>>>
>>>>>> >>>> 2. Quantiles for each variable:
>>>>>> >>>>
>>>>>> >>>>        2.5%     25%    50%    75%  97.5%
>>>>>> >>>> var1 0.03641 0.08695 0.1198 0.1554 0.2553
>>>>>> >>>> var2 0.17298 0.30580 0.3704 0.4431 0.5896
>>>>>> >>>> var3 0.06166 0.12913 0.1705 0.2161 0.3215
>>>>>> >>>> var4 0.12610 0.23999 0.3090 0.3901 0.6045
>>>>>> >>>>
>>>>>> >>>>> prop.table(Ctable1[,1])
>>>>>> >>>>     dawn   diurnal      dusk nocturnal
>>>>>> >>>> 0.1250000 0.2812500 0.1770833 0.4166667
>>>>>> >>>>
>>>>>> >>>>
>>>>>> >>>> #outcomes culling none
>>>>>> >>>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>>>> >>>>
>>>>>> >>>> Iterations = 1:5500
>>>>>> >>>> Thinning interval = 1
>>>>>> >>>> Number of chains = 1
>>>>>> >>>> Sample size per chain = 5500
>>>>>> >>>>
>>>>>> >>>> 1. Empirical mean and standard deviation for each variable,
>>>>>> >>>>   plus standard error of the mean:
>>>>>> >>>>
>>>>>> >>>>       Mean      SD  Naive SE Time-series SE
>>>>>> >>>> [1,] 0.1288 0.06141 0.0008280       0.002787
>>>>>> >>>> [2,] 0.3804 0.10406 0.0014032       0.002662
>>>>>> >>>> [3,] 0.1710 0.06844 0.0009228       0.002592
>>>>>> >>>> [4,] 0.3198 0.11812 0.0015928       0.002956
>>>>>> >>>>
>>>>>> >>>> 2. Quantiles for each variable:
>>>>>> >>>>
>>>>>> >>>>        2.5%     25%    50%    75%  97.5%
>>>>>> >>>> var1 0.02891 0.08896 0.1220 0.1594 0.2685
>>>>>> >>>> var2 0.18007 0.31094 0.3783 0.4474 0.5965
>>>>>> >>>> var3 0.05840 0.12425 0.1634 0.2083 0.3250
>>>>>> >>>> var4 0.12430 0.23921 0.3077 0.3862 0.5964
>>>>>> >>>>
>>>>>> >>>>> prop.table((Ctable1[,2]))
>>>>>> >>>>     dawn   diurnal      dusk nocturnal
>>>>>> >>>> 0.1306818 0.4375000 0.1875000 0.2443182
>>>>>> >>>>
>>>>>> >>>> Any help or guidance will be greatly appreciated.
>>>>>> >>>>
>>>>>> >>>> All the best,
>>>>>> >>>> Jess
>>>>>> >>>>
>>>>>> >>>> --
>>>>>> >>>> Jessica Comley (PhD)
>>>>>> >>>> Research Scientist
>>>>>> >>>>
>>>>>> >>>>        [[alternative HTML version deleted]]
>>>>>> >>>>
>>>>>> >>>> _______________________________________________
>>>>>> >>>> R-sig-mixed-models at r-project.org mailing list
>>>>>> >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>> >>>>
>>>>>> >>>
>>>>>> >>
>>>>>> >> --
>>>>>> >> Jessica Comley (PhD)
>>>>>> >> Research Scientist
>>>>>> >>
>>>>>> >>
>>>>>> >
>>>>>> >        [[alternative HTML version deleted]]
>>>>>> >
>>>>>> > _______________________________________________
>>>>>> > R-sig-mixed-models at r-project.org mailing list
>>>>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>
>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>> Scotland, with registration number SC005336. Is e buidheann carthannais a
>>>>>> th? ann an Oilthigh Dh?n ?ideann, cl?raichte an Alba, ?ireamh cl?raidh
>>>>>> SC005336.
>>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> Jessica Comley (PhD)
>>>>> Research Scientist
>>>>>
>>>>>
>>>>>
>>>>
>>>> --
>>>> Dr Jessica Comley
>>>> Lecturer: Environmental and Life Sciences
>>>> Faculty of Science
>>>> Universiti Brunei Darussalam
>>>>
>>>> Email: jessica.comley at ubd.edu.bn
>>>>
>>>>
>>>
>>> --
>>> Dr Jessica Comley
>>> Lecturer: Environmental and Life Sciences
>>> Faculty of Science
>>> Universiti Brunei Darussalam
>>>
>>> Email: jessica.comley at ubd.edu.bn
>>>
>>>
>>>
>>
>> --
>> Dr Jessica Comley
>> Lecturer: Environmental and Life Sciences
>> Faculty of Science
>> Universiti Brunei Darussalam
>>
>> Email: jessica.comley at ubd.edu.bn
>>
>>
>
> --
> Dr Jessica Comley
> Lecturer: Environmental and Life Sciences
> Faculty of Science
> Universiti Brunei Darussalam
>
> Email: jessica.comley at ubd.edu.bn
>
>
>

-- 
Dr Jessica Comley
Lecturer: Environmental and Life Sciences
Faculty of Science
Universiti Brunei Darussalam

Email: jessica.comley at ubd.edu.bn

	[[alternative HTML version deleted]]


From j@h@d||e|d @end|ng |rom ed@@c@uk  Wed Jul 27 06:54:17 2022
From: j@h@d||e|d @end|ng |rom ed@@c@uk (Jarrod Hadfield)
Date: Wed, 27 Jul 2022 04:54:17 +0000
Subject: [R-sig-ME] MCMCglmm with multinomial models
In-Reply-To: <CANdGWBFJ30UCL3pXXPzn3fQT54vcQXvrdn2vsg_0B-XcYV2sHw@mail.gmail.com>
References: <CANdGWBHgzmN15cvGu7zU90o-+sZn4fUS92_nanb6OYYW8f2rog@mail.gmail.com>
 <CAJtCY7XH=AACiNbTo4SLo4gMQnM7ub1vVEOwGGqB-AvuJf5+Jw@mail.gmail.com>
 <CANdGWBFmXtPEvaREGQenkqq403+toEFJvLMgPTzdFWGix-ggGA@mail.gmail.com>
 <CAJtCY7XW=aT50ZCGUr2Y8ERPT1x2UC686Odti8n1kTRj4hC+LQ@mail.gmail.com>
 <57338F74-D980-4078-A389-EDA67E79C1A6@ed.ac.uk>
 <CANdGWBF3uc7SM0-a7uW54iNBPvRHPTTG+jd8-yjYzUz49o-N4g@mail.gmail.com>
 <63B269B7-6C5F-4A0C-BC08-51FE97C621BF@ed.ac.uk>
 <CANdGWBE5fEdZpnKiJ8ZgaRgFChG4=K5zp2Gpufq-p8KRddX7fw@mail.gmail.com>
 <CANdGWBFY0s2y=qaKhwKAU5cvg2xW5rQ_3CmmXvvj+q5v-Fee3g@mail.gmail.com>
 <56260042-774A-4135-9E38-986F98546F45@ed.ac.uk>
 <CANdGWBFRhtZLV3U4QmP9FmZPFmw_6Ht5x9WiyiyV2ao_D9KimA@mail.gmail.com>
 <CANdGWBFJ30UCL3pXXPzn3fQT54vcQXvrdn2vsg_0B-XcYV2sHw@mail.gmail.com>
Message-ID: <5FBB3A08-E3BA-4925-8A64-DC6753C0BA5B@ed.ac.uk>

The trait:culling interactions are the degree to which activity is higher when culling is none rather than lethal. If you exponentiate the effects you get the promotional change in the odds ratio none:lethal.



On 27 Jul 2022, at 05:48, jessica comley <jessiecomley44 at gmail.com<mailto:jessiecomley44 at gmail.com>> wrote:

This email was sent to you by someone outside the University.
You should only click on links or attachments if you are certain that the email is genuine and the content is safe.
Sorry Jarrod, one last question I swear.

From my corrected outcome:

Location effects: cbind(dawn, diurnal, dusk, nocturnal) ~ trait - 1 + trait:culling + trait:predator

                          post.mean l-95% CI u-95% CI eff.samp   pMCMC
traitdawn                  -1.49696 -1.91443 -1.03494    449.8 < 7e-05 ***
traitdiurnal               -1.26128 -1.65569 -0.87573    173.7 < 7e-05 ***
traitdusk                  -1.69165 -2.14582 -1.25074    304.0 < 7e-05 ***
traitdawn:cullingnone      -0.35018 -0.75539  0.03488   1453.5 0.06068 .
traitdiurnal:cullingnone    0.61075  0.22682  0.99247    646.2 0.00653 **
traitdusk:cullingnone       0.32833 -0.07876  0.72035   1218.7 0.10136
traitdawn:predatorhigh      0.12826 -0.48062  0.81929    696.5 0.70884
traitdiurnal:predatorhigh  -0.45382 -1.03340  0.15183    293.7 0.12313
traitdusk:predatorhigh     -0.14870 -0.77156  0.49585    475.2 0.62830
traitdawn:predatorlow       0.41706 -0.11004  0.93341    579.5 0.10626
traitdiurnal:predatorlow   -0.01279 -0.47660  0.49818    206.6 0.95741
traitdusk:predatorlow       0.16600 -0.36760  0.71419    323.0 0.55102

How would I work out whether traitnocturnal:cullingnone occured more or less than cullinglethal? Is this something that can be done?

Cheers,
Jess

On Wed, Jul 27, 2022 at 12:24 PM jessica comley <jessiecomley44 at gmail.com<mailto:jessiecomley44 at gmail.com>> wrote:
Hi Jarrod,

Yes I did have a typo in my data, which I have corrected and now all is working well.

Thank you very much for your help, I really do appreciate your responses!

Cheers,
Jess

On Wed, Jul 27, 2022 at 12:14 PM Jarrod Hadfield <j.hadfield at ed.ac.uk<mailto:j.hadfield at ed.ac.uk>> wrote:
Hi,

1/ My guess is that there is a mistake/typo in your data.frame: culling has 3 levels not 2. Does table(bbj$culling) return what you expect?

2/ They mean i) there is more diurnal activity under culling compared to whatever the mystery level of culling is. ii) there is more dawn activity when predators is low compared to absent.

3/ The indices should be for all terms involving the thing to be tested. So in the current model they should be 4:9 and 10:15 (not 3:5 and 6:8). This will change when you sort out your culling column (probably to 4:6 and 7:12). In my previous email I said you should be testing 3 effects for predator, but in fact there should be 6 (I thought predator had 3 levels not 2).

You might want a -1 in your model formula (i.e trait-1+trait:culling+trait:predator) to make the interpretation of the first 3 terms a little easier, but up to you.

Cheers,

Jarrod






On 27 Jul 2022, at 04:42, jessica comley <jessiecomley44 at gmail.com<mailto:jessiecomley44 at gmail.com>> wrote:

This email was sent to you by someone outside the University.
You should only click on links or attachments if you are certain that the email is genuine and the content is safe.
Dear Jarrod,

Sorry to bother you again, I just want to make sure I am doing this correctly and understanding my results.

I used the model you suggested:
prior1=list(R=list(V=1, nu=0.002))
m1<-MCMCglmm(cbind(dawn, diurnal, dusk, nocturnal)~trait+trait:culling+trait:predator, rcov=~idv(units+trait:units), prior=prior1, data=bbj, family="multinomial4", nitt= 150000)

And this is my outcome:
Iterations = 3001:149991
 Thinning interval  = 10
 Sample size  = 14700

 DIC: 10312.95

 R-structure:  ~idv(units + trait:units)

            post.mean  l-95% CI u-95% CI eff.samp
trait:units   0.01932 0.0002102  0.07042      441

 Location effects: cbind(dawn, diurnal, dusk, nocturnal) ~ trait + trait:culling + trait:predator

                           post.mean  l-95% CI  u-95% CI eff.samp   pMCMC
(Intercept)                -2.018903 -2.677830 -1.335305    609.1 < 7e-05 ***
traitdiurnal                0.542636 -0.363766  1.405230    644.6 0.22068
traitdusk                  -0.047952 -0.984923  0.917710    374.6 0.91850
traitdawn:cullingLethal     0.534474  0.003076  1.058211    596.8 0.05524 .
traitdiurnal:cullingLethal  0.232597 -0.369959  0.834347    404.7 0.42789
traitdusk:cullingLethal     0.376191 -0.217707  0.964636    408.2 0.19782
traitdawn:cullingnone      -0.163961 -0.573477  0.298182   2945.5 0.38245
traitdiurnal:cullingnone    0.674041  0.247724  1.101917   2825.0 0.00952 **
traitdusk:cullingnone       0.449710 -0.014263  0.874925   1683.9 0.05102 .
traitdawn:predatorhigh      0.456119 -0.206435  1.151283    561.7 0.18531
traitdiurnal:predatorhigh  -0.303114 -0.976842  0.377294    479.9 0.36939
traitdusk:predatorhigh      0.108262 -0.674552  0.895819    256.7 0.76122
traitdawn:predatorlow       0.756262  0.160407  1.323520    418.1 0.01279 *
traitdiurnal:predatorlow    0.136875 -0.446984  0.750518    305.7 0.65619
traitdusk:predatorlow       0.422497 -0.303586  1.145038    194.9 0.22857
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

1) Why do the 2 categories for culling both show up but then only 2 of the three categories for predator show up? i.e. predatorabsent is missing?

2) Do these results mean that i) diurnal activity and lethal culling is sig different from nocturnal activity and lethal culling; ii) dawn activity and predator low is sig different from nocturnal activity and predator low?

3) Is this the correct way and interpretation of the within group effects?
##culling lethal
 aod::wald.test(cov(m1$Sol[,3:5]), colMeans(m1$Sol[,3:5]),Terms=1:3)$result$chi2["P"]
        P
0.1638938

##culling  none
aod::wald.test(cov(m1$Sol[,6:8]), colMeans(m1$Sol[,6:8]),Terms=1:3)$result$chi2["P"]
          P
0.006497424

So these results show us that culling none has an effect on activity?

Thank you in advance,
Jess

On Wed, Jul 27, 2022 at 8:20 AM jessica comley <jessiecomley44 at gmail.com<mailto:jessiecomley44 at gmail.com>> wrote:
Dear Jarrod,

Thank you so much for your help, I greatly appreciate it!

All the best,
Jess

On Wed, Jul 27, 2022 at 3:32 AM Jarrod Hadfield <j.hadfield at ed.ac.uk<mailto:j.hadfield at ed.ac.uk>> wrote:
Hi Jess,

Section should definitely not be left out, but I would imagine it is going to be very difficult to separate culling, predator and Section effects - I would expect the credible intervals to be large.

As mentioned in my previous post you can test for an effect of culling by fitting the model

~trait+trait:culling+trait:predator

And then fitting a Wald test to the three terms with 'culling' in. The effect of predator can be tested similarly but with the 3 terms with 'predator' in.

Since your covariates do not vary within Section it will be much easier to aggregate the counts at the Section level (i.e have a data frame with 14 rows and 1 column for each activity with the number observed for each activity) and fit family="multinomial". You can then get rid of the random formula as the Section effects are now effectively the residuals. Given the lack of replication I would advise using the idv formula that I suggested previously and hope the model isn't too misspecified:

prior=list(R=list(V=1, nu=0.002))

m1<-MCMCglmm(cbind(dawn, diurnal, dusk, nocturnal)~trait+trait:culling+trait:predator, rcov=~idv(units+trait:units), prior=prior, ...)

Note this models is identical to the original model, it's just parameterised in a more efficient way.

Cheers,

Jarrod




On 25 Jul 2022, at 03:52, jessica comley <jessiecomley44 at gmail.com<mailto:jessiecomley44 at gmail.com>> wrote:

This email was sent to you by someone outside the University.
You should only click on links or attachments if you are certain that the email is genuine and the content is safe.
Dear Jarrod and Walid,

Thank you for your replies, it is greatly appreciated.

The predator and culling factors do not vary within sites. As shown in the example data in one of my previous emails, Bucklands only has culling as lethal and predator as low, whereas Colchester only has predator as high and culling as none.

We are trying to submit a paper on black-backed jackal and caracal activity in the presence of different culling practices and predator presence. The reviewers want us to try a GLMM approach to determine whether culling or predators have an effect on black-backed jackal or caracal activity.

Therefore, in your opinion how could be go about this given our data? Would it be advisable to leave out the random effect of Section?

All the best,
Jess

On Wed, Jul 20, 2022 at 3:06 PM Jarrod Hadfield <j.hadfield at ed.ac.uk<mailto:j.hadfield at ed.ac.uk>> wrote:
Hi Jess

In multinomial models the linear model is set up as a (logit) difference in probability between an outcome and some base-line outcome. Often, as here, the base-line outcome is arbitrary, and so the idh structure is a little odd. For example, if A is the base line category, idh assumes COV(B-A, C-A) = 0 which therefore assumes
COV(B,C)+VAR(A) =COV(A,B)+COV(C,A). It's not clear why this would be the case. Perhaps a more reasonable, but less parameter rich, option would be to have:

~idv(Section+trait:Section)

which parameterises the Section covariance matrix by a single parameter (rather than 6). The term idv(Section+trait:Section) fits a 3x3 covariance matrix of the form v*(I+J) where v is the estimated variance. This assumes i) Sections are repeatable in outcome, but knowing that a Section has an increased 'preference' for A doesn?t tell you whether it also has an increased preference for one of the other categories and ii) the repeatability for each outcome within sites is the same (on the latent scale).

To test groups of effects (in your case the 3 culling:trait effects), I usually use a Wald test and the posterior covariances (see here https://stat.ethz.ch/pipermail/r-sig-mixed-models/2017q3/025930.html). It's far from correct and so Walid's suggestions may be better, but small-scale simulations suggests it has good frequentist properties.

To add predator presence you can just add a predator:trait effect into the linear model. If the culling and predator factors do not vary within sites then you probably don't have enough information to reliably estimate these effects.

Cheers,

Jarrod






> On 19 Jul 2022, at 18:17, Walid Mawass <walidmawass10 at gmail.com<mailto:walidmawass10 at gmail.com>> wrote:
>
> This email was sent to you by someone outside the University.
> You should only click on links or attachments if you are certain that the email is genuine and the content is safe.
>
> Hey Jess,
>
> 1) Yes that is correct
>
> 2) To my knowledge there is a rule of thumb, where you set the nitt (# of
> iterations) to a large number that includes the burnin amount, then you
> choose your thinning interval (sampling of the chain). For example, this is
> what I would use: nitt= 150000, burnin=50000, thin=100. This will give you
> a decent burnin and a final sample of 1000 saved iterations. Note however
> that this does not have to increase the effective sample size for certain
> variables, but it might do the trick.
>
> 3) hmm...I think one way to do it is to make predictions using the above
> model and interpret the patterns you see for each relationship you are
> interested in. Another way to compare effect size would be to use bayesian
> posterior indices. I suggest these two papers by Makowski et al. (2019a &
> b) that present both interesting posterior indices to use with Bayesian
> statistical analysis and an associated R package that does the job of
> computing these indices, *bayestestR*.
>
> Good luck
> --
> Walid Mawass
> Ph.D. candidate in Evolutionary Biology - UQTR
> *Currently* Postdoctoral Research Associate
> Masel Lab - University of Arizona
>
>
> On Sun, Jul 17, 2022 at 11:32 PM jessica comley <jessiecomley44 at gmail.com<mailto:jessiecomley44 at gmail.com>>
> wrote:
>
>> Hi Walid,
>>
>> Thank you for your reply, I greatly appreciate it. I have a few more
>> questions and if you could help that would be great.
>>
>> I tested for correlation between activities and the 14 Sections and the
>> correlation comes out as low. Therefore I have changed my code to use idh()
>> instead of us as suggested:
>>
>> test1c.5b <- MCMCglmm(activity ~ -1 + at.level(culling,1):trait +
>> at.level(culling, 2):trait, random=~idh(trait):Section, rcov =
>> ~idh(trait):units, data = caracal, family = "categorical", prior = prior,
>> burnin=5000, nitt=80000)
>>
>> 1) Is this correct?
>>
>> 2) Increasing the number of interactions increases the effective sample
>> size, therefore is there a general rule of thumb as to how large your
>> effective sample size should be?
>>
>> 3) I understand how to use and interpret the results of HPDinterval (i.e.
>> if intervals do not overlap 0 then relationship is strong), but how am I
>> able to test the relationship between all four activities and fixed effects
>> and not just have the three categories (i.e. diurnal, dusk, nocturnal)
>> compared to the base category (dawn)? For example, I am also interested in
>> whether there is a significant/strong relationship between activities of
>> caracal at dusk with culling(Lethal)/no culling(none) compared to
>> activities of caracal at diurnal with culling(Lethal)/no culling(none).
>>
>> Below is an example of our dataset:
>> Camera Section CameraID Animal predator culling activity
>> 1a Bucklands Bucklands1a Caracal low Lethal diurnal
>> 1a Bucklands Bucklands1a Caracal low Lethal dawn
>> 2a Bucklands Bucklands2a Caracal low Lethal dusk
>> 2a Bucklands Bucklands2a Caracal low Lethal diurnal
>> 3a Bucklands Bucklands3a Caracal low Lethal dawn
>> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>> Cam 2  Colchester ColchesterCam 2  Caracal high none diurnal
>> Cam 2  Colchester ColchesterCam 2  Caracal high none diurnal
>> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
>> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
>> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
>> Cam 4  Colchester ColchesterCam 4  Caracal high none diurnal
>> Cam 4  Colchester ColchesterCam 4  Caracal high none diurnal
>> Cam 4  Colchester ColchesterCam 4  Caracal high none nocturnal
>> 1a Connaught Connaught1a Caracal low Lethal nocturnal
>> 1a Connaught Connaught1a Caracal low Lethal nocturnal
>> 1d Connaught Connaught1d Caracal low Lethal diurnal
>> 3B Connaught Connaught3B Caracal low Lethal diurnal
>> 3B Connaught Connaught3B Caracal low Lethal diurnal
>> 4a Connaught Connaught4a Caracal low Lethal nocturnal
>> 4a Connaught Connaught4a Caracal low Lethal nocturnal
>> 4b Connaught Connaught4b Caracal low Lethal diurnal
>> 6a Connaught Connaught6a Caracal low Lethal nocturnal
>> 6b Connaught Connaught6b Caracal low Lethal diurnal
>> 7a Connaught Connaught7a Caracal low Lethal nocturnal
>> 9a Connaught Connaught9a Caracal low Lethal nocturnal
>> 9d Connaught Connaught9d Caracal low Lethal nocturnal
>> 9d Connaught Connaught9d Caracal low Lethal dusk
>> 7d Diepdam Diepdam7d Caracal absent Lethal dusk
>> 8d Diepdam Diepdam8d Caracal absent Lethal diurnal
>> 9c Diepdam Diepdam9c Caracal absent Lethal nocturnal
>>
>> All the best,
>> Jess
>>
>>
>> On Fri, Jul 15, 2022 at 11:37 PM Walid Mawass <walidmawass10 at gmail.com<mailto:walidmawass10 at gmail.com>>
>> wrote:
>>
>>> Hello,
>>>
>>> I don't think I can specifically help you with some of your inquiries.
>>> However, I do want to comment on a few things that might need some
>>> attention.
>>>
>>> First, MCMCglmm is based on a Bayesian implementation and does not
>>> compute p-values to compare. What you need to compare are the posterior
>>> distributions of your effect sizes. This can be done visually using the
>>> base plot function in R. Or by comparing the HPD intervals and the mode (or
>>> mean) of the posterior distributions.
>>>
>>> Second, I have no idea what your data structure looks like (which makes
>>> it hard to interpret model results), but the effective sample size (from
>>> the 5500 saved iterations sample) for your random variable Section is very
>>> low (the same applies for your fixed effects). You should consider this
>>> issue and look again at your assumption of correlation between
>>> activities for the 14 sections you have in your dataset. If you do not
>>> expect among activity correlations then you can use the idh() function
>>> instead of us().
>>>
>>> Hopefully this helps and in hope that people on this list with more
>>> knowledge of these models will help out.
>>>
>>> Best,
>>> --
>>> Walid Mawass
>>> Ph.D. candidate in Evolutionary Biology - UQTR
>>> *Currently* Postdoctoral Research Associate
>>> Masel Lab - University of Arizona
>>>
>>>
>>> On Fri, Jul 15, 2022 at 8:49 AM jessica comley <jessiecomley44 at gmail.com<mailto:jessiecomley44 at gmail.com>>
>>> wrote:
>>>
>>>> Dear all,
>>>>
>>>> I am hoping that someone will be able to help me with conducting MCMCglmm
>>>> multinomial models.
>>>>
>>>> The data I am working with is for black-backed jackal (bbj) and carcal.
>>>> For
>>>> each species we have a multinomial response variable called activity
>>>> which
>>>> has four categories (dawn, diurnal, dusk, nocturnal). We have two
>>>> categorical fixed effects which are 1) culling (none, lethal) and 2)
>>>> predator presence (absent, high, low). We also have a categorical
>>>> variable
>>>> called Section (made up of 14 different reserves/ farms where the
>>>> activity
>>>> of caracal and bbj were recorded). There are 273 observations for caracal
>>>> and 4399 for bbj. We are wanting to test the effects of culling and
>>>> predators on caracal and bbj activity separately.
>>>>
>>>> I have been working through Jarrod Hadfields course notes, particularly
>>>> with regards to Chapter 5.2. The chi-square analyses reveal that the
>>>> frequencies of culling and predators differ as do activities.
>>>>
>>>> I have managed to work out the specific probabilities for the culling
>>>> none
>>>> vs culling lethal for each activity (dawn, diurnal, dusk, nocturnal) for
>>>> caracal, but I'm confused as to how to determine p-values to determine
>>>> which activities culling none vs culling lethal are affecting?
>>>>
>>>> Myy code and outcomes are pasted below with questions stated in bold.
>>>>
>>>> caracal2 <- read.csv("caracal_new.csv", header=T)
>>>> caracal <- as.data.frame(unclass(caracal2), stringsAsFactors = TRUE)
>>>>
>>>> #Chi-squared tests
>>>> Ctable1 <- table(caracal$activity, caracal$culling)
>>>> chisq.test(rowSums(Ctable1)) #strongly suggests activities differ
>>>> chisq.test(Ctable1)#strongly suggests culling category differs
>>>>
>>>> Ctable2 <- table(caracal$activity, caracal$predator)
>>>> chisq.test(rowSums(Ctable2))#strongly suggests activities differ
>>>> chisq.test(Ctable2)#strongly suggests predator category differs
>>>>
>>>> prior = list(R = list(fix=1, V=(1/k) * (I + J)), G = list(G1=list(V =
>>>> diag(k-1), nu=1)))
>>>> test1c.5 <- MCMCglmm(activity ~ -1 + at.level(culling,1):trait +
>>>> at.level(culling, 2):trait, random=~us(trait):Section, rcov =
>>>> ~us(trait):units, data = caracal, family = "categorical", prior = prior,
>>>> burnin=5000, nitt=60000)
>>>> *##I'm not sure how to add the three predator levels to this model or if
>>>> it
>>>> would be appropriate?*
>>>>
>>>>
>>>> k <- length(levels(caracal$activity))
>>>> I <- diag(k-1)
>>>> J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))
>>>> IJ <- (1/k) *(diag(k-1) + matrix(1,k-1, k-1))
>>>>
>>>> contrasts(caracal$activity)
>>>>
>>>> #culling lethal
>>>> Delta <- cbind(c(0,1,0,0), c(0,0,1,0), c(0,0,0,1))
>>>> c2 <- (16 * sqrt(3)/(15 * pi))^2
>>>> D <- ginv(Delta %*% t(Delta)) %*% Delta
>>>> Int <- t(apply(test1c.5$Sol[,1:3],1, function(x) + D %*% (x/sqrt(1 + c2 *
>>>> diag(IJ)))))
>>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>>
>>>> prop.table(Ctable1[,1])
>>>>
>>>> #culling none
>>>> Delta <- cbind(c(0,1,0,0), c(0,0,1,0), c(0,0,0,1))
>>>> c2 <- (16 * sqrt(3)/(15 * pi))^2
>>>> D <- ginv(Delta %*% t(Delta)) %*% Delta
>>>> Int <- t(apply(test1c.5$Sol[,4:6],1, function(x) + D %*% (x/sqrt(1 + c2 *
>>>> diag(IJ)))))
>>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>>
>>>> prop.table((Ctable1[,2]))
>>>>
>>>> HPDinterval(test1c.5$Sol)
>>>>
>>>> #model summary
>>>>> summary(test1c.5)
>>>>
>>>> Iterations = 5001:59991
>>>> Thinning interval  = 10
>>>> Sample size  = 5500
>>>>
>>>> DIC: 699.7014
>>>>
>>>> G-structure:  ~us(trait):Section
>>>>
>>>>                                                        post.mean l-95%
>>>> CI
>>>> u-95% CI eff.samp
>>>> traitactivity.diurnal:traitactivity.diurnal.Section        1.8124
>>>> 0.09784
>>>>   5.665    77.01
>>>> traitactivity.dusk:traitactivity.diurnal.Section           0.8450
>>>> -0.83585
>>>>   3.856    64.17
>>>> traitactivity.nocturnal:traitactivity.diurnal.Section      1.3621
>>>> -1.19129
>>>>   6.157    58.48
>>>> traitactivity.diurnal:traitactivity.dusk.Section           0.8450
>>>> -0.83585
>>>>   3.856    64.17
>>>> traitactivity.dusk:traitactivity.dusk.Section              1.2034
>>>> 0.07090
>>>>   3.681   102.16
>>>> traitactivity.nocturnal:traitactivity.dusk.Section         0.7505
>>>> -1.77113
>>>>   4.524    43.53
>>>> traitactivity.diurnal:traitactivity.nocturnal.Section      1.3621
>>>> -1.19129
>>>>   6.157    58.48
>>>> traitactivity.dusk:traitactivity.nocturnal.Section         0.7505
>>>> -1.77113
>>>>   4.524    43.53
>>>> traitactivity.nocturnal:traitactivity.nocturnal.Section    2.7148
>>>> 0.09401
>>>>   8.397    76.59
>>>>
>>>> R-structure:  ~us(trait):units
>>>>
>>>>                                                      post.mean l-95% CI
>>>> u-95% CI eff.samp
>>>> traitactivity.diurnal:traitactivity.diurnal.units          0.50     0.50
>>>>  0.50        0
>>>> traitactivity.dusk:traitactivity.diurnal.units             0.25     0.25
>>>>  0.25        0
>>>> traitactivity.nocturnal:traitactivity.diurnal.units        0.25     0.25
>>>>  0.25        0
>>>> traitactivity.diurnal:traitactivity.dusk.units             0.25     0.25
>>>>  0.25        0
>>>> traitactivity.dusk:traitactivity.dusk.units                0.50     0.50
>>>>  0.50        0
>>>> traitactivity.nocturnal:traitactivity.dusk.units           0.25     0.25
>>>>  0.25        0
>>>> traitactivity.diurnal:traitactivity.nocturnal.units        0.25     0.25
>>>>  0.25        0
>>>> traitactivity.dusk:traitactivity.nocturnal.units           0.25     0.25
>>>>  0.25        0
>>>> traitactivity.nocturnal:traitactivity.nocturnal.units      0.50     0.50
>>>>  0.50        0
>>>>
>>>> Location effects: activity ~ -1 + at.level(culling, 1):trait +
>>>> at.level(culling, 2):trait
>>>>
>>>>                                             post.mean l-95% CI u-95% CI
>>>> eff.samp  pMCMC
>>>> at.level(culling, 1):traitactivity.diurnal      1.2306  -0.0533   2.6793
>>>> 145.29 0.0418 *
>>>> at.level(culling, 1):traitactivity.dusk         0.6605  -0.6006   2.0761
>>>> 92.91 0.2840
>>>> at.level(culling, 1):traitactivity.nocturnal    1.6090   0.0914   3.1356
>>>> 151.02 0.0265 *
>>>> traitactivity.diurnal:at.level(culling, 2)      1.2664  -0.1552   2.7750
>>>> 226.40 0.0604 .
>>>> traitactivity.dusk:at.level(culling, 2)         0.3533  -0.9898   1.5218
>>>> 148.44 0.5447
>>>> traitactivity.nocturnal:at.level(culling, 2)    1.0447  -0.6405   2.8354
>>>> 346.40 0.1618
>>>> ---
>>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>>
>>>> *##So for the model summary I get that lethal culling at activity diurnal
>>>> is significantly different from lethal culling at dawn (its the base
>>>> reference), but I'm also interested in whether lethal culling at activity
>>>> diurnal is different from lethal culling at dusk for example. Is this
>>>> possible? *
>>>>
>>>> #outcomes culling lethal
>>>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>>
>>>> Iterations = 1:5500
>>>> Thinning interval = 1
>>>> Number of chains = 1
>>>> Sample size per chain = 5500
>>>>
>>>> 1. Empirical mean and standard deviation for each variable,
>>>>   plus standard error of the mean:
>>>>
>>>>       Mean      SD  Naive SE Time-series SE
>>>> [1,] 0.1253 0.05565 0.0007504       0.002484
>>>> [2,] 0.3748 0.10497 0.0014155       0.003204
>>>> [3,] 0.1757 0.06640 0.0008954       0.002515
>>>> [4,] 0.3242 0.11939 0.0016099       0.003514
>>>>
>>>> 2. Quantiles for each variable:
>>>>
>>>>        2.5%     25%    50%    75%  97.5%
>>>> var1 0.03641 0.08695 0.1198 0.1554 0.2553
>>>> var2 0.17298 0.30580 0.3704 0.4431 0.5896
>>>> var3 0.06166 0.12913 0.1705 0.2161 0.3215
>>>> var4 0.12610 0.23999 0.3090 0.3901 0.6045
>>>>
>>>>> prop.table(Ctable1[,1])
>>>>     dawn   diurnal      dusk nocturnal
>>>> 0.1250000 0.2812500 0.1770833 0.4166667
>>>>
>>>>
>>>> #outcomes culling none
>>>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>>
>>>> Iterations = 1:5500
>>>> Thinning interval = 1
>>>> Number of chains = 1
>>>> Sample size per chain = 5500
>>>>
>>>> 1. Empirical mean and standard deviation for each variable,
>>>>   plus standard error of the mean:
>>>>
>>>>       Mean      SD  Naive SE Time-series SE
>>>> [1,] 0.1288 0.06141 0.0008280       0.002787
>>>> [2,] 0.3804 0.10406 0.0014032       0.002662
>>>> [3,] 0.1710 0.06844 0.0009228       0.002592
>>>> [4,] 0.3198 0.11812 0.0015928       0.002956
>>>>
>>>> 2. Quantiles for each variable:
>>>>
>>>>        2.5%     25%    50%    75%  97.5%
>>>> var1 0.02891 0.08896 0.1220 0.1594 0.2685
>>>> var2 0.18007 0.31094 0.3783 0.4474 0.5965
>>>> var3 0.05840 0.12425 0.1634 0.2083 0.3250
>>>> var4 0.12430 0.23921 0.3077 0.3862 0.5964
>>>>
>>>>> prop.table((Ctable1[,2]))
>>>>     dawn   diurnal      dusk nocturnal
>>>> 0.1306818 0.4375000 0.1875000 0.2443182
>>>>
>>>> Any help or guidance will be greatly appreciated.
>>>>
>>>> All the best,
>>>> Jess
>>>>
>>>> --
>>>> Jessica Comley (PhD)
>>>> Research Scientist
>>>>
>>>>        [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>
>> --
>> Jessica Comley (PhD)
>> Research Scientist
>>
>>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

The University of Edinburgh is a charitable body, registered in Scotland, with registration number SC005336. Is e buidheann carthannais a th? ann an Oilthigh Dh?n ?ideann, cl?raichte an Alba, ?ireamh cl?raidh SC005336.


--
Jessica Comley (PhD)
Research Scientist




--
Dr Jessica Comley
Lecturer: Environmental and Life Sciences
Faculty of Science
Universiti Brunei Darussalam

Email: jessica.comley at ubd.edu.bn<mailto:jessica.comley at ubd.edu.bn>



--
Dr Jessica Comley
Lecturer: Environmental and Life Sciences
Faculty of Science
Universiti Brunei Darussalam

Email: jessica.comley at ubd.edu.bn<mailto:jessica.comley at ubd.edu.bn>



--
Dr Jessica Comley
Lecturer: Environmental and Life Sciences
Faculty of Science
Universiti Brunei Darussalam

Email: jessica.comley at ubd.edu.bn<mailto:jessica.comley at ubd.edu.bn>



--
Dr Jessica Comley
Lecturer: Environmental and Life Sciences
Faculty of Science
Universiti Brunei Darussalam

Email: jessica.comley at ubd.edu.bn<mailto:jessica.comley at ubd.edu.bn>


	[[alternative HTML version deleted]]


From j@h@d||e|d @end|ng |rom ed@@c@uk  Wed Jul 27 10:35:19 2022
From: j@h@d||e|d @end|ng |rom ed@@c@uk (Jarrod Hadfield)
Date: Wed, 27 Jul 2022 09:35:19 +0100
Subject: [R-sig-ME] MCMCglmm with multinomial models
In-Reply-To: <CANdGWBEPE2=pbb5Y2J3jcjmoCbfbUyOM89LrkuDhduZUqnXMKw@mail.gmail.com>
References: <CANdGWBHgzmN15cvGu7zU90o-+sZn4fUS92_nanb6OYYW8f2rog@mail.gmail.com>
 <CAJtCY7XH=AACiNbTo4SLo4gMQnM7ub1vVEOwGGqB-AvuJf5+Jw@mail.gmail.com>
 <CANdGWBFmXtPEvaREGQenkqq403+toEFJvLMgPTzdFWGix-ggGA@mail.gmail.com>
 <CAJtCY7XW=aT50ZCGUr2Y8ERPT1x2UC686Odti8n1kTRj4hC+LQ@mail.gmail.com>
 <57338F74-D980-4078-A389-EDA67E79C1A6@ed.ac.uk>
 <CANdGWBF3uc7SM0-a7uW54iNBPvRHPTTG+jd8-yjYzUz49o-N4g@mail.gmail.com>
 <63B269B7-6C5F-4A0C-BC08-51FE97C621BF@ed.ac.uk>
 <CANdGWBE5fEdZpnKiJ8ZgaRgFChG4=K5zp2Gpufq-p8KRddX7fw@mail.gmail.com>
 <CANdGWBFY0s2y=qaKhwKAU5cvg2xW5rQ_3CmmXvvj+q5v-Fee3g@mail.gmail.com>
 <56260042-774A-4135-9E38-986F98546F45@ed.ac.uk>
 <CANdGWBFRhtZLV3U4QmP9FmZPFmw_6Ht5x9WiyiyV2ao_D9KimA@mail.gmail.com>
 <CANdGWBFJ30UCL3pXXPzn3fQT54vcQXvrdn2vsg_0B-XcYV2sHw@mail.gmail.com>
 <5FBB3A08-E3BA-4925-8A64-DC6753C0BA5B@ed.ac.uk>
 <CANdGWBEPE2=pbb5Y2J3jcjmoCbfbUyOM89LrkuDhduZUqnXMKw@mail.gmail.com>
Message-ID: <45DC4F2C-0720-4193-9CBB-675B48873A8D@ed.ac.uk>

Not quite -  it means the odds of diurnal activity compared to nocturnal activity is greater when there is no culling compared to lethal culling. However, I would do the omnibus Wald test before interpreting the significance of individual tests.  


> On 27 Jul 2022, at 06:31, jessica comley <jessiecomley44 at gmail.com> wrote:
> 
> This email was sent to you by someone outside the University.
> You should only click on links or attachments if you are certain that the email is genuine and the content is safe.
> Sorry, let me try rephrasing my question. From my results, how do I interpret the base activity nocturnal. Does the significant result of  traitdiurnal:cullingnone mean that there is more diurnal activity than nocturnal activity when culling is none compared to lethal? 
> 
> On Wed, Jul 27, 2022 at 12:54 PM Jarrod Hadfield <j.hadfield at ed.ac.uk <mailto:j.hadfield at ed.ac.uk>> wrote:
> The trait:culling interactions are the degree to which activity is higher when culling is none rather than lethal. If you exponentiate the effects you get the promotional change in the odds ratio none:lethal. 
> 
> 
> 
>> On 27 Jul 2022, at 05:48, jessica comley <jessiecomley44 at gmail.com <mailto:jessiecomley44 at gmail.com>> wrote:
>> 
>> This email was sent to you by someone outside the University.
>> You should only click on links or attachments if you are certain that the email is genuine and the content is safe.
>> Sorry Jarrod, one last question I swear.
>> 
>> From my corrected outcome:
>> 
>> Location effects: cbind(dawn, diurnal, dusk, nocturnal) ~ trait - 1 + trait:culling + trait:predator
>>  
>>                           post.mean l-95% CI u-95% CI eff.samp   pMCMC   
>> traitdawn                  -1.49696 -1.91443 -1.03494    449.8 < 7e-05 ***
>> traitdiurnal               -1.26128 -1.65569 -0.87573    173.7 < 7e-05 ***
>> traitdusk                  -1.69165 -2.14582 -1.25074    304.0 < 7e-05 ***
>> traitdawn:cullingnone      -0.35018 -0.75539  0.03488   1453.5 0.06068 . 
>> traitdiurnal:cullingnone    0.61075  0.22682  0.99247    646.2 0.00653 **
>> traitdusk:cullingnone       0.32833 -0.07876  0.72035   1218.7 0.10136   
>> traitdawn:predatorhigh      0.12826 -0.48062  0.81929    696.5 0.70884   
>> traitdiurnal:predatorhigh  -0.45382 -1.03340  0.15183    293.7 0.12313   
>> traitdusk:predatorhigh     -0.14870 -0.77156  0.49585    475.2 0.62830   
>> traitdawn:predatorlow       0.41706 -0.11004  0.93341    579.5 0.10626   
>> traitdiurnal:predatorlow   -0.01279 -0.47660  0.49818    206.6 0.95741   
>> traitdusk:predatorlow       0.16600 -0.36760  0.71419    323.0 0.55102    
>> 
>> How would I work out whether traitnocturnal:cullingnone occured more or less than cullinglethal? Is this something that can be done?
>> 
>> Cheers,
>> Jess
>> 
>> On Wed, Jul 27, 2022 at 12:24 PM jessica comley <jessiecomley44 at gmail.com <mailto:jessiecomley44 at gmail.com>> wrote:
>> Hi Jarrod,
>> 
>> Yes I did have a typo in my data, which I have corrected and now all is working well.
>> 
>> Thank you very much for your help, I really do appreciate your responses!
>> 
>> Cheers,
>> Jess
>> 
>> On Wed, Jul 27, 2022 at 12:14 PM Jarrod Hadfield <j.hadfield at ed.ac.uk <mailto:j.hadfield at ed.ac.uk>> wrote:
>> Hi, 
>> 
>> 1/ My guess is that there is a mistake/typo in your data.frame: culling has 3 levels not 2. Does table(bbj$culling) return what you expect?
>> 
>> 2/ They mean i) there is more diurnal activity under culling compared to whatever the mystery level of culling is. ii) there is more dawn activity when predators is low compared to absent.
>> 
>> 3/ The indices should be for all terms involving the thing to be tested. So in the current model they should be 4:9 and 10:15 (not 3:5 and 6:8). This will change when you sort out your culling column (probably to 4:6 and 7:12). In my previous email I said you should be testing 3 effects for predator, but in fact there should be 6 (I thought predator had 3 levels not 2).
>> 
>> You might want a -1 in your model formula (i.e trait-1+trait:culling+trait:predator) to make the interpretation of the first 3 terms a little easier, but up to you.
>> 
>> Cheers,
>> 
>> Jarrod
>> 
>> 
>> 
>> 
>> 
>> 
>>> On 27 Jul 2022, at 04:42, jessica comley <jessiecomley44 at gmail.com <mailto:jessiecomley44 at gmail.com>> wrote:
>>> 
>>> This email was sent to you by someone outside the University.
>>> You should only click on links or attachments if you are certain that the email is genuine and the content is safe.
>>> Dear Jarrod,
>>> 
>>> Sorry to bother you again, I just want to make sure I am doing this correctly and understanding my results. 
>>> 
>>> I used the model you suggested:
>>> prior1=list(R=list(V=1, nu=0.002))
>>> m1<-MCMCglmm(cbind(dawn, diurnal, dusk, nocturnal)~trait+trait:culling+trait:predator, rcov=~idv(units+trait:units), prior=prior1, data=bbj, family="multinomial4", nitt= 150000)
>>> 
>>> And this is my outcome:
>>> Iterations = 3001:149991
>>>  Thinning interval  = 10
>>>  Sample size  = 14700 
>>> 
>>>  DIC: 10312.95 
>>> 
>>>  R-structure:  ~idv(units + trait:units)
>>> 
>>>             post.mean  l-95% CI u-95% CI eff.samp
>>> trait:units   0.01932 0.0002102  0.07042      441
>>> 
>>>  Location effects: cbind(dawn, diurnal, dusk, nocturnal) ~ trait + trait:culling + trait:predator 
>>> 
>>>                            post.mean  l-95% CI  u-95% CI eff.samp   pMCMC    
>>> (Intercept)                -2.018903 -2.677830 -1.335305    609.1 < 7e-05 ***
>>> traitdiurnal                0.542636 -0.363766  1.405230    644.6 0.22068    
>>> traitdusk                  -0.047952 -0.984923  0.917710    374.6 0.91850    
>>> traitdawn:cullingLethal     0.534474  0.003076  1.058211    596.8 0.05524 .  
>>> traitdiurnal:cullingLethal  0.232597 -0.369959  0.834347    404.7 0.42789    
>>> traitdusk:cullingLethal     0.376191 -0.217707  0.964636    408.2 0.19782    
>>> traitdawn:cullingnone      -0.163961 -0.573477  0.298182   2945.5 0.38245    
>>> traitdiurnal:cullingnone    0.674041  0.247724  1.101917   2825.0 0.00952 ** 
>>> traitdusk:cullingnone       0.449710 -0.014263  0.874925   1683.9 0.05102 .  
>>> traitdawn:predatorhigh      0.456119 -0.206435  1.151283    561.7 0.18531    
>>> traitdiurnal:predatorhigh  -0.303114 -0.976842  0.377294    479.9 0.36939    
>>> traitdusk:predatorhigh      0.108262 -0.674552  0.895819    256.7 0.76122    
>>> traitdawn:predatorlow       0.756262  0.160407  1.323520    418.1 0.01279 *  
>>> traitdiurnal:predatorlow    0.136875 -0.446984  0.750518    305.7 0.65619    
>>> traitdusk:predatorlow       0.422497 -0.303586  1.145038    194.9 0.22857    
>>> ---
>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>> 
>>> 1) Why do the 2 categories for culling both show up but then only 2 of the three categories for predator show up? i.e. predatorabsent is missing?
>>> 
>>> 2) Do these results mean that i) diurnal activity and lethal culling is sig different from nocturnal activity and lethal culling; ii) dawn activity and predator low is sig different from nocturnal activity and predator low?
>>> 
>>> 3) Is this the correct way and interpretation of the within group effects?
>>> ##culling lethal
>>>  aod::wald.test(cov(m1$Sol[,3:5]), colMeans(m1$Sol[,3:5]),Terms=1:3)$result$chi2["P"]
>>>         P 
>>> 0.1638938
>>> 
>>> ##culling  none
>>> aod::wald.test(cov(m1$Sol[,6:8]), colMeans(m1$Sol[,6:8]),Terms=1:3)$result$chi2["P"]
>>>           P 
>>> 0.006497424 
>>> 
>>> So these results show us that culling none has an effect on activity?
>>> 
>>> Thank you in advance,
>>> Jess
>>> 
>>> On Wed, Jul 27, 2022 at 8:20 AM jessica comley <jessiecomley44 at gmail.com <mailto:jessiecomley44 at gmail.com>> wrote:
>>> Dear Jarrod,
>>> 
>>> Thank you so much for your help, I greatly appreciate it!
>>> 
>>> All the best,
>>> Jess
>>> 
>>> On Wed, Jul 27, 2022 at 3:32 AM Jarrod Hadfield <j.hadfield at ed.ac.uk <mailto:j.hadfield at ed.ac.uk>> wrote:
>>> Hi Jess, 
>>> 
>>> Section should definitely not be left out, but I would imagine it is going to be very difficult to separate culling, predator and Section effects - I would expect the credible intervals to be large.
>>> 
>>> As mentioned in my previous post you can test for an effect of culling by fitting the model
>>> 
>>> ~trait+trait:culling+trait:predator
>>> 
>>> And then fitting a Wald test to the three terms with 'culling' in. The effect of predator can be tested similarly but with the 3 terms with 'predator' in.
>>> 
>>> Since your covariates do not vary within Section it will be much easier to aggregate the counts at the Section level (i.e have a data frame with 14 rows and 1 column for each activity with the number observed for each activity) and fit family="multinomial". You can then get rid of the random formula as the Section effects are now effectively the residuals. Given the lack of replication I would advise using the idv formula that I suggested previously and hope the model isn't too misspecified:
>>> 
>>> prior=list(R=list(V=1, nu=0.002))
>>> 
>>> m1<-MCMCglmm(cbind(dawn, diurnal, dusk, nocturnal)~trait+trait:culling+trait:predator, rcov=~idv(units+trait:units), prior=prior, ...)
>>> 
>>> Note this models is identical to the original model, it's just parameterised in a more efficient way. 
>>> 
>>> Cheers,
>>> 
>>> Jarrod
>>> 
>>> 
>>> 
>>> 
>>>> On 25 Jul 2022, at 03:52, jessica comley <jessiecomley44 at gmail.com <mailto:jessiecomley44 at gmail.com>> wrote:
>>>> 
>>>> This email was sent to you by someone outside the University.
>>>> You should only click on links or attachments if you are certain that the email is genuine and the content is safe.
>>>> Dear Jarrod and Walid,
>>>> 
>>>> Thank you for your replies, it is greatly appreciated.
>>>> 
>>>> The predator and culling factors do not vary within sites. As shown in the example data in one of my previous emails, Bucklands only has culling as lethal and predator as low, whereas Colchester only has predator as high and culling as none. 
>>>> 
>>>> We are trying to submit a paper on black-backed jackal and caracal activity in the presence of different culling practices and predator presence. The reviewers want us to try a GLMM approach to determine whether culling or predators have an effect on black-backed jackal or caracal activity. 
>>>> 
>>>> Therefore, in your opinion how could be go about this given our data? Would it be advisable to leave out the random effect of Section? 
>>>> 
>>>> All the best,
>>>> Jess
>>>> 
>>>> On Wed, Jul 20, 2022 at 3:06 PM Jarrod Hadfield <j.hadfield at ed.ac.uk <mailto:j.hadfield at ed.ac.uk>> wrote:
>>>> Hi Jess
>>>> 
>>>> In multinomial models the linear model is set up as a (logit) difference in probability between an outcome and some base-line outcome. Often, as here, the base-line outcome is arbitrary, and so the idh structure is a little odd. For example, if A is the base line category, idh assumes COV(B-A, C-A) = 0 which therefore assumes
>>>> COV(B,C)+VAR(A) =COV(A,B)+COV(C,A). It's not clear why this would be the case. Perhaps a more reasonable, but less parameter rich, option would be to have:
>>>> 
>>>> ~idv(Section+trait:Section)
>>>> 
>>>> which parameterises the Section covariance matrix by a single parameter (rather than 6). The term idv(Section+trait:Section) fits a 3x3 covariance matrix of the form v*(I+J) where v is the estimated variance. This assumes i) Sections are repeatable in outcome, but knowing that a Section has an increased 'preference' for A doesn?t tell you whether it also has an increased preference for one of the other categories and ii) the repeatability for each outcome within sites is the same (on the latent scale).
>>>> 
>>>> To test groups of effects (in your case the 3 culling:trait effects), I usually use a Wald test and the posterior covariances (see here https://stat.ethz.ch/pipermail/r-sig-mixed-models/2017q3/025930.html <https://stat.ethz.ch/pipermail/r-sig-mixed-models/2017q3/025930.html>). It's far from correct and so Walid's suggestions may be better, but small-scale simulations suggests it has good frequentist properties.
>>>> 
>>>> To add predator presence you can just add a predator:trait effect into the linear model. If the culling and predator factors do not vary within sites then you probably don't have enough information to reliably estimate these effects.
>>>> 
>>>> Cheers,
>>>> 
>>>> Jarrod
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> > On 19 Jul 2022, at 18:17, Walid Mawass <walidmawass10 at gmail.com <mailto:walidmawass10 at gmail.com>> wrote:
>>>> >
>>>> > This email was sent to you by someone outside the University.
>>>> > You should only click on links or attachments if you are certain that the email is genuine and the content is safe.
>>>> >
>>>> > Hey Jess,
>>>> >
>>>> > 1) Yes that is correct
>>>> >
>>>> > 2) To my knowledge there is a rule of thumb, where you set the nitt (# of
>>>> > iterations) to a large number that includes the burnin amount, then you
>>>> > choose your thinning interval (sampling of the chain). For example, this is
>>>> > what I would use: nitt= 150000, burnin=50000, thin=100. This will give you
>>>> > a decent burnin and a final sample of 1000 saved iterations. Note however
>>>> > that this does not have to increase the effective sample size for certain
>>>> > variables, but it might do the trick.
>>>> >
>>>> > 3) hmm...I think one way to do it is to make predictions using the above
>>>> > model and interpret the patterns you see for each relationship you are
>>>> > interested in. Another way to compare effect size would be to use bayesian
>>>> > posterior indices. I suggest these two papers by Makowski et al. (2019a &
>>>> > b) that present both interesting posterior indices to use with Bayesian
>>>> > statistical analysis and an associated R package that does the job of
>>>> > computing these indices, *bayestestR*.
>>>> >
>>>> > Good luck
>>>> > --
>>>> > Walid Mawass
>>>> > Ph.D. candidate in Evolutionary Biology - UQTR
>>>> > *Currently* Postdoctoral Research Associate
>>>> > Masel Lab - University of Arizona
>>>> >
>>>> >
>>>> > On Sun, Jul 17, 2022 at 11:32 PM jessica comley <jessiecomley44 at gmail.com <mailto:jessiecomley44 at gmail.com>>
>>>> > wrote:
>>>> >
>>>> >> Hi Walid,
>>>> >>
>>>> >> Thank you for your reply, I greatly appreciate it. I have a few more
>>>> >> questions and if you could help that would be great.
>>>> >>
>>>> >> I tested for correlation between activities and the 14 Sections and the
>>>> >> correlation comes out as low. Therefore I have changed my code to use idh()
>>>> >> instead of us as suggested:
>>>> >>
>>>> >> test1c.5b <- MCMCglmm(activity ~ -1 + at.level(culling,1):trait +
>>>> >> at.level(culling, 2):trait, random=~idh(trait):Section, rcov =
>>>> >> ~idh(trait):units, data = caracal, family = "categorical", prior = prior,
>>>> >> burnin=5000, nitt=80000)
>>>> >>
>>>> >> 1) Is this correct?
>>>> >>
>>>> >> 2) Increasing the number of interactions increases the effective sample
>>>> >> size, therefore is there a general rule of thumb as to how large your
>>>> >> effective sample size should be?
>>>> >>
>>>> >> 3) I understand how to use and interpret the results of HPDinterval (i.e.
>>>> >> if intervals do not overlap 0 then relationship is strong), but how am I
>>>> >> able to test the relationship between all four activities and fixed effects
>>>> >> and not just have the three categories (i.e. diurnal, dusk, nocturnal)
>>>> >> compared to the base category (dawn)? For example, I am also interested in
>>>> >> whether there is a significant/strong relationship between activities of
>>>> >> caracal at dusk with culling(Lethal)/no culling(none) compared to
>>>> >> activities of caracal at diurnal with culling(Lethal)/no culling(none).
>>>> >>
>>>> >> Below is an example of our dataset:
>>>> >> Camera Section CameraID Animal predator culling activity
>>>> >> 1a Bucklands Bucklands1a Caracal low Lethal diurnal
>>>> >> 1a Bucklands Bucklands1a Caracal low Lethal dawn
>>>> >> 2a Bucklands Bucklands2a Caracal low Lethal dusk
>>>> >> 2a Bucklands Bucklands2a Caracal low Lethal diurnal
>>>> >> 3a Bucklands Bucklands3a Caracal low Lethal dawn
>>>> >> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>>>> >> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>>>> >> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>>>> >> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>>>> >> Cam 2  Colchester ColchesterCam 2  Caracal high none diurnal
>>>> >> Cam 2  Colchester ColchesterCam 2  Caracal high none diurnal
>>>> >> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
>>>> >> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
>>>> >> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
>>>> >> Cam 4  Colchester ColchesterCam 4  Caracal high none diurnal
>>>> >> Cam 4  Colchester ColchesterCam 4  Caracal high none diurnal
>>>> >> Cam 4  Colchester ColchesterCam 4  Caracal high none nocturnal
>>>> >> 1a Connaught Connaught1a Caracal low Lethal nocturnal
>>>> >> 1a Connaught Connaught1a Caracal low Lethal nocturnal
>>>> >> 1d Connaught Connaught1d Caracal low Lethal diurnal
>>>> >> 3B Connaught Connaught3B Caracal low Lethal diurnal
>>>> >> 3B Connaught Connaught3B Caracal low Lethal diurnal
>>>> >> 4a Connaught Connaught4a Caracal low Lethal nocturnal
>>>> >> 4a Connaught Connaught4a Caracal low Lethal nocturnal
>>>> >> 4b Connaught Connaught4b Caracal low Lethal diurnal
>>>> >> 6a Connaught Connaught6a Caracal low Lethal nocturnal
>>>> >> 6b Connaught Connaught6b Caracal low Lethal diurnal
>>>> >> 7a Connaught Connaught7a Caracal low Lethal nocturnal
>>>> >> 9a Connaught Connaught9a Caracal low Lethal nocturnal
>>>> >> 9d Connaught Connaught9d Caracal low Lethal nocturnal
>>>> >> 9d Connaught Connaught9d Caracal low Lethal dusk
>>>> >> 7d Diepdam Diepdam7d Caracal absent Lethal dusk
>>>> >> 8d Diepdam Diepdam8d Caracal absent Lethal diurnal
>>>> >> 9c Diepdam Diepdam9c Caracal absent Lethal nocturnal
>>>> >>
>>>> >> All the best,
>>>> >> Jess
>>>> >>
>>>> >>
>>>> >> On Fri, Jul 15, 2022 at 11:37 PM Walid Mawass <walidmawass10 at gmail.com <mailto:walidmawass10 at gmail.com>>
>>>> >> wrote:
>>>> >>
>>>> >>> Hello,
>>>> >>>
>>>> >>> I don't think I can specifically help you with some of your inquiries.
>>>> >>> However, I do want to comment on a few things that might need some
>>>> >>> attention.
>>>> >>>
>>>> >>> First, MCMCglmm is based on a Bayesian implementation and does not
>>>> >>> compute p-values to compare. What you need to compare are the posterior
>>>> >>> distributions of your effect sizes. This can be done visually using the
>>>> >>> base plot function in R. Or by comparing the HPD intervals and the mode (or
>>>> >>> mean) of the posterior distributions.
>>>> >>>
>>>> >>> Second, I have no idea what your data structure looks like (which makes
>>>> >>> it hard to interpret model results), but the effective sample size (from
>>>> >>> the 5500 saved iterations sample) for your random variable Section is very
>>>> >>> low (the same applies for your fixed effects). You should consider this
>>>> >>> issue and look again at your assumption of correlation between
>>>> >>> activities for the 14 sections you have in your dataset. If you do not
>>>> >>> expect among activity correlations then you can use the idh() function
>>>> >>> instead of us().
>>>> >>>
>>>> >>> Hopefully this helps and in hope that people on this list with more
>>>> >>> knowledge of these models will help out.
>>>> >>>
>>>> >>> Best,
>>>> >>> --
>>>> >>> Walid Mawass
>>>> >>> Ph.D. candidate in Evolutionary Biology - UQTR
>>>> >>> *Currently* Postdoctoral Research Associate
>>>> >>> Masel Lab - University of Arizona
>>>> >>>
>>>> >>>
>>>> >>> On Fri, Jul 15, 2022 at 8:49 AM jessica comley <jessiecomley44 at gmail.com <mailto:jessiecomley44 at gmail.com>>
>>>> >>> wrote:
>>>> >>>
>>>> >>>> Dear all,
>>>> >>>>
>>>> >>>> I am hoping that someone will be able to help me with conducting MCMCglmm
>>>> >>>> multinomial models.
>>>> >>>>
>>>> >>>> The data I am working with is for black-backed jackal (bbj) and carcal.
>>>> >>>> For
>>>> >>>> each species we have a multinomial response variable called activity
>>>> >>>> which
>>>> >>>> has four categories (dawn, diurnal, dusk, nocturnal). We have two
>>>> >>>> categorical fixed effects which are 1) culling (none, lethal) and 2)
>>>> >>>> predator presence (absent, high, low). We also have a categorical
>>>> >>>> variable
>>>> >>>> called Section (made up of 14 different reserves/ farms where the
>>>> >>>> activity
>>>> >>>> of caracal and bbj were recorded). There are 273 observations for caracal
>>>> >>>> and 4399 for bbj. We are wanting to test the effects of culling and
>>>> >>>> predators on caracal and bbj activity separately.
>>>> >>>>
>>>> >>>> I have been working through Jarrod Hadfields course notes, particularly
>>>> >>>> with regards to Chapter 5.2. The chi-square analyses reveal that the
>>>> >>>> frequencies of culling and predators differ as do activities.
>>>> >>>>
>>>> >>>> I have managed to work out the specific probabilities for the culling
>>>> >>>> none
>>>> >>>> vs culling lethal for each activity (dawn, diurnal, dusk, nocturnal) for
>>>> >>>> caracal, but I'm confused as to how to determine p-values to determine
>>>> >>>> which activities culling none vs culling lethal are affecting?
>>>> >>>>
>>>> >>>> Myy code and outcomes are pasted below with questions stated in bold.
>>>> >>>>
>>>> >>>> caracal2 <- read.csv("caracal_new.csv", header=T)
>>>> >>>> caracal <- as.data.frame(unclass(caracal2), stringsAsFactors = TRUE)
>>>> >>>>
>>>> >>>> #Chi-squared tests
>>>> >>>> Ctable1 <- table(caracal$activity, caracal$culling)
>>>> >>>> chisq.test(rowSums(Ctable1)) #strongly suggests activities differ
>>>> >>>> chisq.test(Ctable1)#strongly suggests culling category differs
>>>> >>>>
>>>> >>>> Ctable2 <- table(caracal$activity, caracal$predator)
>>>> >>>> chisq.test(rowSums(Ctable2))#strongly suggests activities differ
>>>> >>>> chisq.test(Ctable2)#strongly suggests predator category differs
>>>> >>>>
>>>> >>>> prior = list(R = list(fix=1, V=(1/k) * (I + J)), G = list(G1=list(V =
>>>> >>>> diag(k-1), nu=1)))
>>>> >>>> test1c.5 <- MCMCglmm(activity ~ -1 + at.level(culling,1):trait +
>>>> >>>> at.level(culling, 2):trait, random=~us(trait):Section, rcov =
>>>> >>>> ~us(trait):units, data = caracal, family = "categorical", prior = prior,
>>>> >>>> burnin=5000, nitt=60000)
>>>> >>>> *##I'm not sure how to add the three predator levels to this model or if
>>>> >>>> it
>>>> >>>> would be appropriate?*
>>>> >>>>
>>>> >>>>
>>>> >>>> k <- length(levels(caracal$activity))
>>>> >>>> I <- diag(k-1)
>>>> >>>> J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))
>>>> >>>> IJ <- (1/k) *(diag(k-1) + matrix(1,k-1, k-1))
>>>> >>>>
>>>> >>>> contrasts(caracal$activity)
>>>> >>>>
>>>> >>>> #culling lethal
>>>> >>>> Delta <- cbind(c(0,1,0,0), c(0,0,1,0), c(0,0,0,1))
>>>> >>>> c2 <- (16 * sqrt(3)/(15 * pi))^2
>>>> >>>> D <- ginv(Delta %*% t(Delta)) %*% Delta
>>>> >>>> Int <- t(apply(test1c.5$Sol[,1:3],1, function(x) + D %*% (x/sqrt(1 + c2 *
>>>> >>>> diag(IJ)))))
>>>> >>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>> >>>>
>>>> >>>> prop.table(Ctable1[,1])
>>>> >>>>
>>>> >>>> #culling none
>>>> >>>> Delta <- cbind(c(0,1,0,0), c(0,0,1,0), c(0,0,0,1))
>>>> >>>> c2 <- (16 * sqrt(3)/(15 * pi))^2
>>>> >>>> D <- ginv(Delta %*% t(Delta)) %*% Delta
>>>> >>>> Int <- t(apply(test1c.5$Sol[,4:6],1, function(x) + D %*% (x/sqrt(1 + c2 *
>>>> >>>> diag(IJ)))))
>>>> >>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>> >>>>
>>>> >>>> prop.table((Ctable1[,2]))
>>>> >>>>
>>>> >>>> HPDinterval(test1c.5$Sol)
>>>> >>>>
>>>> >>>> #model summary
>>>> >>>>> summary(test1c.5)
>>>> >>>>
>>>> >>>> Iterations = 5001:59991
>>>> >>>> Thinning interval  = 10
>>>> >>>> Sample size  = 5500
>>>> >>>>
>>>> >>>> DIC: 699.7014
>>>> >>>>
>>>> >>>> G-structure:  ~us(trait):Section
>>>> >>>>
>>>> >>>>                                                        post.mean l-95%
>>>> >>>> CI
>>>> >>>> u-95% CI eff.samp
>>>> >>>> traitactivity.diurnal:traitactivity.diurnal.Section        1.8124
>>>> >>>> 0.09784
>>>> >>>>   5.665    77.01
>>>> >>>> traitactivity.dusk:traitactivity.diurnal.Section           0.8450
>>>> >>>> -0.83585
>>>> >>>>   3.856    64.17
>>>> >>>> traitactivity.nocturnal:traitactivity.diurnal.Section      1.3621
>>>> >>>> -1.19129
>>>> >>>>   6.157    58.48
>>>> >>>> traitactivity.diurnal:traitactivity.dusk.Section           0.8450
>>>> >>>> -0.83585
>>>> >>>>   3.856    64.17
>>>> >>>> traitactivity.dusk:traitactivity.dusk.Section              1.2034
>>>> >>>> 0.07090
>>>> >>>>   3.681   102.16
>>>> >>>> traitactivity.nocturnal:traitactivity.dusk.Section         0.7505
>>>> >>>> -1.77113
>>>> >>>>   4.524    43.53
>>>> >>>> traitactivity.diurnal:traitactivity.nocturnal.Section      1.3621
>>>> >>>> -1.19129
>>>> >>>>   6.157    58.48
>>>> >>>> traitactivity.dusk:traitactivity.nocturnal.Section         0.7505
>>>> >>>> -1.77113
>>>> >>>>   4.524    43.53
>>>> >>>> traitactivity.nocturnal:traitactivity.nocturnal.Section    2.7148
>>>> >>>> 0.09401
>>>> >>>>   8.397    76.59
>>>> >>>>
>>>> >>>> R-structure:  ~us(trait):units
>>>> >>>>
>>>> >>>>                                                      post.mean l-95% CI
>>>> >>>> u-95% CI eff.samp
>>>> >>>> traitactivity.diurnal:traitactivity.diurnal.units          0.50     0.50
>>>> >>>>  0.50        0
>>>> >>>> traitactivity.dusk:traitactivity.diurnal.units             0.25     0.25
>>>> >>>>  0.25        0
>>>> >>>> traitactivity.nocturnal:traitactivity.diurnal.units        0.25     0.25
>>>> >>>>  0.25        0
>>>> >>>> traitactivity.diurnal:traitactivity.dusk.units             0.25     0.25
>>>> >>>>  0.25        0
>>>> >>>> traitactivity.dusk:traitactivity.dusk.units                0.50     0.50
>>>> >>>>  0.50        0
>>>> >>>> traitactivity.nocturnal:traitactivity.dusk.units           0.25     0.25
>>>> >>>>  0.25        0
>>>> >>>> traitactivity.diurnal:traitactivity.nocturnal.units        0.25     0.25
>>>> >>>>  0.25        0
>>>> >>>> traitactivity.dusk:traitactivity.nocturnal.units           0.25     0.25
>>>> >>>>  0.25        0
>>>> >>>> traitactivity.nocturnal:traitactivity.nocturnal.units      0.50     0.50
>>>> >>>>  0.50        0
>>>> >>>>
>>>> >>>> Location effects: activity ~ -1 + at.level(culling, 1):trait +
>>>> >>>> at.level(culling, 2):trait
>>>> >>>>
>>>> >>>>                                             post.mean l-95% CI u-95% CI
>>>> >>>> eff.samp  pMCMC
>>>> >>>> at.level(culling, 1):traitactivity.diurnal      1.2306  -0.0533   2.6793
>>>> >>>> 145.29 0.0418 *
>>>> >>>> at.level(culling, 1):traitactivity.dusk         0.6605  -0.6006   2.0761
>>>> >>>> 92.91 0.2840
>>>> >>>> at.level(culling, 1):traitactivity.nocturnal    1.6090   0.0914   3.1356
>>>> >>>> 151.02 0.0265 *
>>>> >>>> traitactivity.diurnal:at.level(culling, 2)      1.2664  -0.1552   2.7750
>>>> >>>> 226.40 0.0604 .
>>>> >>>> traitactivity.dusk:at.level(culling, 2)         0.3533  -0.9898   1.5218
>>>> >>>> 148.44 0.5447
>>>> >>>> traitactivity.nocturnal:at.level(culling, 2)    1.0447  -0.6405   2.8354
>>>> >>>> 346.40 0.1618
>>>> >>>> ---
>>>> >>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>> >>>>
>>>> >>>> *##So for the model summary I get that lethal culling at activity diurnal
>>>> >>>> is significantly different from lethal culling at dawn (its the base
>>>> >>>> reference), but I'm also interested in whether lethal culling at activity
>>>> >>>> diurnal is different from lethal culling at dusk for example. Is this
>>>> >>>> possible? *
>>>> >>>>
>>>> >>>> #outcomes culling lethal
>>>> >>>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>> >>>>
>>>> >>>> Iterations = 1:5500
>>>> >>>> Thinning interval = 1
>>>> >>>> Number of chains = 1
>>>> >>>> Sample size per chain = 5500
>>>> >>>>
>>>> >>>> 1. Empirical mean and standard deviation for each variable,
>>>> >>>>   plus standard error of the mean:
>>>> >>>>
>>>> >>>>       Mean      SD  Naive SE Time-series SE
>>>> >>>> [1,] 0.1253 0.05565 0.0007504       0.002484
>>>> >>>> [2,] 0.3748 0.10497 0.0014155       0.003204
>>>> >>>> [3,] 0.1757 0.06640 0.0008954       0.002515
>>>> >>>> [4,] 0.3242 0.11939 0.0016099       0.003514
>>>> >>>>
>>>> >>>> 2. Quantiles for each variable:
>>>> >>>>
>>>> >>>>        2.5%     25%    50%    75%  97.5%
>>>> >>>> var1 0.03641 0.08695 0.1198 0.1554 0.2553
>>>> >>>> var2 0.17298 0.30580 0.3704 0.4431 0.5896
>>>> >>>> var3 0.06166 0.12913 0.1705 0.2161 0.3215
>>>> >>>> var4 0.12610 0.23999 0.3090 0.3901 0.6045
>>>> >>>>
>>>> >>>>> prop.table(Ctable1[,1])
>>>> >>>>     dawn   diurnal      dusk nocturnal
>>>> >>>> 0.1250000 0.2812500 0.1770833 0.4166667
>>>> >>>>
>>>> >>>>
>>>> >>>> #outcomes culling none
>>>> >>>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>> >>>>
>>>> >>>> Iterations = 1:5500
>>>> >>>> Thinning interval = 1
>>>> >>>> Number of chains = 1
>>>> >>>> Sample size per chain = 5500
>>>> >>>>
>>>> >>>> 1. Empirical mean and standard deviation for each variable,
>>>> >>>>   plus standard error of the mean:
>>>> >>>>
>>>> >>>>       Mean      SD  Naive SE Time-series SE
>>>> >>>> [1,] 0.1288 0.06141 0.0008280       0.002787
>>>> >>>> [2,] 0.3804 0.10406 0.0014032       0.002662
>>>> >>>> [3,] 0.1710 0.06844 0.0009228       0.002592
>>>> >>>> [4,] 0.3198 0.11812 0.0015928       0.002956
>>>> >>>>
>>>> >>>> 2. Quantiles for each variable:
>>>> >>>>
>>>> >>>>        2.5%     25%    50%    75%  97.5%
>>>> >>>> var1 0.02891 0.08896 0.1220 0.1594 0.2685
>>>> >>>> var2 0.18007 0.31094 0.3783 0.4474 0.5965
>>>> >>>> var3 0.05840 0.12425 0.1634 0.2083 0.3250
>>>> >>>> var4 0.12430 0.23921 0.3077 0.3862 0.5964
>>>> >>>>
>>>> >>>>> prop.table((Ctable1[,2]))
>>>> >>>>     dawn   diurnal      dusk nocturnal
>>>> >>>> 0.1306818 0.4375000 0.1875000 0.2443182
>>>> >>>>
>>>> >>>> Any help or guidance will be greatly appreciated.
>>>> >>>>
>>>> >>>> All the best,
>>>> >>>> Jess
>>>> >>>>
>>>> >>>> --
>>>> >>>> Jessica Comley (PhD)
>>>> >>>> Research Scientist
>>>> >>>>
>>>> >>>>        [[alternative HTML version deleted]]
>>>> >>>>
>>>> >>>> _______________________________________________
>>>> >>>> R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>> >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>> >>>>
>>>> >>>
>>>> >>
>>>> >> --
>>>> >> Jessica Comley (PhD)
>>>> >> Research Scientist
>>>> >>
>>>> >>
>>>> >
>>>> >        [[alternative HTML version deleted]]
>>>> >
>>>> > _______________________________________________
>>>> > R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>> 
>>>> The University of Edinburgh is a charitable body, registered in Scotland, with registration number SC005336. Is e buidheann carthannais a th? ann an Oilthigh Dh?n ?ideann, cl?raichte an Alba, ?ireamh cl?raidh SC005336.
>>>> 
>>>> 
>>>> -- 
>>>> Jessica Comley (PhD)
>>>> Research Scientist
>>>> 
>>> 
>>> 
>>> 
>>> -- 
>>> Dr Jessica Comley
>>> Lecturer: Environmental and Life Sciences
>>> Faculty of Science
>>> Universiti Brunei Darussalam
>>> 
>>> Email: jessica.comley at ubd.edu.bn <mailto:jessica.comley at ubd.edu.bn>
>>> 
>>> 
>>> 
>>> -- 
>>> Dr Jessica Comley
>>> Lecturer: Environmental and Life Sciences
>>> Faculty of Science
>>> Universiti Brunei Darussalam
>>> 
>>> Email: jessica.comley at ubd.edu.bn <mailto:jessica.comley at ubd.edu.bn>
>> 
>> 
>> -- 
>> Dr Jessica Comley
>> Lecturer: Environmental and Life Sciences
>> Faculty of Science
>> Universiti Brunei Darussalam
>> 
>> Email: jessica.comley at ubd.edu.bn <mailto:jessica.comley at ubd.edu.bn>
>> 
>> 
>> 
>> -- 
>> Dr Jessica Comley
>> Lecturer: Environmental and Life Sciences
>> Faculty of Science
>> Universiti Brunei Darussalam
>> 
>> Email: jessica.comley at ubd.edu.bn <mailto:jessica.comley at ubd.edu.bn>
> 
> 
> -- 
> Dr Jessica Comley
> Lecturer: Environmental and Life Sciences
> Faculty of Science
> Universiti Brunei Darussalam
> 
> Email: jessica.comley at ubd.edu.bn <mailto:jessica.comley at ubd.edu.bn>
> 


	[[alternative HTML version deleted]]


From @|ex@ndre@@nto@br @end|ng |rom y@hoo@com@br  Wed Jul 27 14:40:32 2022
From: @|ex@ndre@@nto@br @end|ng |rom y@hoo@com@br (Alexandre Santos)
Date: Wed, 27 Jul 2022 12:40:32 +0000 (UTC)
Subject: [R-sig-ME] Model approach for pairwise comparison post-hoc
References: <1309771597.2820689.1658925632725.ref@mail.yahoo.com>
Message-ID: <1309771597.2820689.1658925632725@mail.yahoo.com>

In my example: 


? ? # Packages
? ? library(glmmTMB)
? ? library(multcomp)
? ? library(lsmeans)
? ? library(car)
? ? 
? ? # My data set
? ? ds <- read.csv("https://raw.githubusercontent.com/Leprechault/trash/main/temp_ger_ds.csv")
? ? str(ds)
? ? #'data.frame': ?140 obs. of ?4 variables:
? ? # $ temp ? ? ? : chr ?"constante" "constante" "constante" "constante" ...
? ? # $ generation : chr ?"G0" "G0" "G0" "G0" ...
? ? # $ development: int ?22 24 22 27 27 24 25 26 27 18 ...


First fit the ziGamma model:


? ? mTCFd <- glmmTMB(development ~ temp * generation + (1 | generation), data = ds,
? ? ? ? ? ? ? ? ? ?family = ziGamma(link = "log")) 
? ? Anova(mTCFd,test="Chi")
# Analysis of Deviance Table (Type II Wald chisquare tests)


# Response: development
# ? ? ? ? ? ? ? ? ? Chisq Df Pr(>Chisq) ? ?
# temp ? ? ? ? ? ?198.412 ?1 ?< 2.2e-16 ***
# generation ? ? ? 18.346 ?4 ? 0.001056 ** 
# temp:generation ?31.250 ?4 ?2.723e-06 ***
# ---
# Signif. codes: ?0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


Pairwise Comparison Post Hoc Tests:


? ? 1) For temp:
? ? lsm.TCFd.temp <- lsmeans(mTCFd, c("temp"))
? ? cld(lsm.TCFd.temp, Letters=letters)
# ?temp ? ? ?lsmean ? ? SE ?df lower.CL upper.CL .group
# ?constante ? 3.18 0.0082 128 ? ? 3.17 ? ? 3.20 ?a ? ?
# ?flutuante ? 3.37 0.0131 128 ? ? 3.34 ? ? 3.39 ? b ? 
? ? 
? ? 2) For generation:
? ? lsm.TCFd.gen <- lsmeans(mTCFd, c("generation"))
? ? cld(lsm.TCFd.gen, Letters=letters)
# ?generation lsmean ? ? SE ?df lower.CL upper.CL .group
# ?G3 ? ? ? ? ? 3.23 0.0159 128 ? ? 3.20 ? ? 3.26 ?a ? ?
# ?G1 ? ? ? ? ? 3.27 0.0198 128 ? ? 3.23 ? ? 3.31 ?ab ? 
# ?G0 ? ? ? ? ? 3.27 0.0135 128 ? ? 3.25 ? ? 3.30 ?ab ? 
# ?G4 ? ? ? ? ? 3.29 0.0217 128 ? ? 3.25 ? ? 3.34 ?ab ? 
# ?G2 ? ? ? ? ? 3.31 0.0141 128 ? ? 3.28 ? ? 3.34 ? b ? 
? ? 3) For temp:generation interaction:
? ? ds$temp_gen <- paste0(ds$temp,"_",ds$generation)
? ? mTCFd.int <- glmmTMB(development ~ temp_gen + (1 | generation), data = ds,
? ? ? ? ? ? ? ? ? ?family = ziGamma(link = "log")) 
? ? lsm.TCFd.temp.gen <- lsmeans(mTCFd.int, c("temp_gen"))
? ? cld(lsm.TCFd.temp.gen, Letters=letters)
# ?temp_gen ? ? lsmean ? ? SE ?df lower.CL upper.CL .group 
# ?constante_G3 ? 3.13 0.0180 128 ? ? 3.09 ? ? 3.16 ?a ? ? 
# ?constante_G2 ? 3.14 0.0180 128 ? ? 3.11 ? ? 3.18 ?ab ? ?
# ?constante_G0 ? 3.19 0.0191 128 ? ? 3.15 ? ? 3.23 ?abc ? 
# ?constante_G1 ? 3.22 0.0180 128 ? ? 3.18 ? ? 3.25 ? bc ? 
# ?constante_G4 ? 3.23 0.0185 128 ? ? 3.19 ? ? 3.27 ? ?cd ?
# ?flutuante_G1 ? 3.32 0.0352 128 ? ? 3.25 ? ? 3.39 ? ?cde 
# ?flutuante_G3 ? 3.34 0.0262 128 ? ? 3.28 ? ? 3.39 ? ? ?e 
# ?flutuante_G0 ? 3.36 0.0191 128 ? ? 3.32 ? ? 3.39 ? ? ?e 
# ?flutuante_G4 ? 3.36 0.0393 128 ? ? 3.28 ? ? 3.44 ? ? def
# ?flutuante_G2 ? 3.47 0.0218 128 ? ? 3.43 ? ? 3.52 ? ? ? f


Ok, it works, but I'd like to know if is possible for the pairwise comparison
directly with the final model (`mTCFd`) without a new interaction model adjustment (`mTCFd.int`).
This is because different models have different parameters and I'm interesting in the `mTCFd` adjustment.


Please, any help with it?


From je@@|ecom|ey44 @end|ng |rom gm@||@com  Wed Jul 27 14:36:48 2022
From: je@@|ecom|ey44 @end|ng |rom gm@||@com (jessica comley)
Date: Wed, 27 Jul 2022 20:36:48 +0800
Subject: [R-sig-ME] MCMCglmm with multinomial models
In-Reply-To: <45DC4F2C-0720-4193-9CBB-675B48873A8D@ed.ac.uk>
References: <CANdGWBHgzmN15cvGu7zU90o-+sZn4fUS92_nanb6OYYW8f2rog@mail.gmail.com>
 <CAJtCY7XH=AACiNbTo4SLo4gMQnM7ub1vVEOwGGqB-AvuJf5+Jw@mail.gmail.com>
 <CANdGWBFmXtPEvaREGQenkqq403+toEFJvLMgPTzdFWGix-ggGA@mail.gmail.com>
 <CAJtCY7XW=aT50ZCGUr2Y8ERPT1x2UC686Odti8n1kTRj4hC+LQ@mail.gmail.com>
 <57338F74-D980-4078-A389-EDA67E79C1A6@ed.ac.uk>
 <CANdGWBF3uc7SM0-a7uW54iNBPvRHPTTG+jd8-yjYzUz49o-N4g@mail.gmail.com>
 <63B269B7-6C5F-4A0C-BC08-51FE97C621BF@ed.ac.uk>
 <CANdGWBE5fEdZpnKiJ8ZgaRgFChG4=K5zp2Gpufq-p8KRddX7fw@mail.gmail.com>
 <CANdGWBFY0s2y=qaKhwKAU5cvg2xW5rQ_3CmmXvvj+q5v-Fee3g@mail.gmail.com>
 <56260042-774A-4135-9E38-986F98546F45@ed.ac.uk>
 <CANdGWBFRhtZLV3U4QmP9FmZPFmw_6Ht5x9WiyiyV2ao_D9KimA@mail.gmail.com>
 <CANdGWBFJ30UCL3pXXPzn3fQT54vcQXvrdn2vsg_0B-XcYV2sHw@mail.gmail.com>
 <5FBB3A08-E3BA-4925-8A64-DC6753C0BA5B@ed.ac.uk>
 <CANdGWBEPE2=pbb5Y2J3jcjmoCbfbUyOM89LrkuDhduZUqnXMKw@mail.gmail.com>
 <45DC4F2C-0720-4193-9CBB-675B48873A8D@ed.ac.uk>
Message-ID: <CANdGWBFLdWxDmhfpBWkjQJgRf9RBGHtic5ZxZyyKQPm5CLhWbQ@mail.gmail.com>

Okay great, thank you. I have run Wald tests and they show that culling is
significant but predator presence is not.

On Wed, Jul 27, 2022 at 4:35 PM Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:

> Not quite -  it means the odds of diurnal activity compared to nocturnal
> activity is greater when there is no culling compared to lethal culling.
> However, I would do the omnibus Wald test before interpreting the
> significance of individual tests.
>
>
> On 27 Jul 2022, at 06:31, jessica comley <jessiecomley44 at gmail.com> wrote:
>
> This email was sent to you by someone outside the University.
> You should only click on links or attachments if you are certain that the
> email is genuine and the content is safe.
> Sorry, let me try rephrasing my question. From my results, how do I
> interpret the base activity nocturnal. Does the significant result of  *traitdiurnal:cullingnone
> *mean that there is more diurnal activity than nocturnal activity when
> culling is none compared to lethal?
>
> On Wed, Jul 27, 2022 at 12:54 PM Jarrod Hadfield <j.hadfield at ed.ac.uk>
> wrote:
>
>> The trait:culling interactions are the degree to which activity is higher
>> when culling is none rather than lethal. If you exponentiate the effects
>> you get the promotional change in the odds ratio none:lethal.
>>
>>
>>
>> On 27 Jul 2022, at 05:48, jessica comley <jessiecomley44 at gmail.com>
>> wrote:
>>
>> This email was sent to you by someone outside the University.
>> You should only click on links or attachments if you are certain that the
>> email is genuine and the content is safe.
>> Sorry Jarrod, one last question I swear.
>>
>> From my corrected outcome:
>>
>> *Location effects: cbind(dawn, diurnal, dusk, nocturnal) ~ trait - 1 +
>> trait:culling + trait:predator*
>>
>> *                          post.mean l-95% CI u-95% CI eff.samp
>> pMCMC   *
>> *traitdawn                  -1.49696 -1.91443 -1.03494    449.8 < 7e-05
>> ****
>> *traitdiurnal               -1.26128 -1.65569 -0.87573    173.7 < 7e-05
>> ****
>> *traitdusk                  -1.69165 -2.14582 -1.25074    304.0 < 7e-05
>> ****
>> *traitdawn:cullingnone      -0.35018 -0.75539  0.03488   1453.5 0.06068
>> . *
>> *traitdiurnal:cullingnone    0.61075  0.22682  0.99247    646.2 0.00653
>> ***
>> *traitdusk:cullingnone       0.32833 -0.07876  0.72035   1218.7
>> 0.10136   *
>> *traitdawn:predatorhigh      0.12826 -0.48062  0.81929    696.5
>> 0.70884   *
>> *traitdiurnal:predatorhigh  -0.45382 -1.03340  0.15183    293.7
>> 0.12313   *
>> *traitdusk:predatorhigh     -0.14870 -0.77156  0.49585    475.2
>> 0.62830   *
>> *traitdawn:predatorlow       0.41706 -0.11004  0.93341    579.5
>> 0.10626   *
>> *traitdiurnal:predatorlow   -0.01279 -0.47660  0.49818    206.6
>> 0.95741   *
>> *traitdusk:predatorlow       0.16600 -0.36760  0.71419    323.0 0.55102
>>   *
>>
>> How would I work out whether traitnocturnal:cullingnone occured more or
>> less than cullinglethal? Is this something that can be done?
>>
>> Cheers,
>> Jess
>>
>> On Wed, Jul 27, 2022 at 12:24 PM jessica comley <jessiecomley44 at gmail.com>
>> wrote:
>>
>>> Hi Jarrod,
>>>
>>> Yes I did have a typo in my data, which I have corrected and now all is
>>> working well.
>>>
>>> Thank you very much for your help, I really do appreciate your responses!
>>>
>>> Cheers,
>>> Jess
>>>
>>> On Wed, Jul 27, 2022 at 12:14 PM Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>> wrote:
>>>
>>>> Hi,
>>>>
>>>> 1/ My guess is that there is a mistake/typo in your data.frame: culling
>>>> has 3 levels not 2. Does table(bbj$culling) return what you expect?
>>>>
>>>> 2/ They mean i) there is more diurnal activity under culling compared
>>>> to whatever the mystery level of culling is. ii) there is more dawn
>>>> activity when predators is low compared to absent.
>>>>
>>>> 3/ The indices should be for all terms involving the thing to be
>>>> tested. So in the current model they should be 4:9 and 10:15 (not 3:5 and
>>>> 6:8). This will change when you sort out your culling column (probably to
>>>> 4:6 and 7:12). In my previous email I said you should be testing 3 effects
>>>> for predator, but in fact there should be 6 (I thought predator had 3
>>>> levels not 2).
>>>>
>>>> You might want a -1 in your model formula (i.e
>>>> trait-1+trait:culling+trait:predator) to make the interpretation of
>>>> the first 3 terms a little easier, but up to you.
>>>>
>>>> Cheers,
>>>>
>>>> Jarrod
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> On 27 Jul 2022, at 04:42, jessica comley <jessiecomley44 at gmail.com>
>>>> wrote:
>>>>
>>>> This email was sent to you by someone outside the University.
>>>> You should only click on links or attachments if you are certain that
>>>> the email is genuine and the content is safe.
>>>> Dear Jarrod,
>>>>
>>>> Sorry to bother you again, I just want to make sure I am doing this
>>>> correctly and understanding my results.
>>>>
>>>> I used the model you suggested:
>>>>
>>>> *prior1=list(R=list(V=1, nu=0.002)) m1<-MCMCglmm(cbind(dawn, diurnal,
>>>> dusk, nocturnal)~trait+trait:culling+trait:predator,
>>>> rcov=~idv(units+trait:units), prior=prior1, data=bbj,
>>>> family="multinomial4", nitt= 150000)*
>>>>
>>>> And this is my outcome:
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> *Iterations = 3001:149991  Thinning interval  = 10  Sample size  =
>>>> 14700   DIC: 10312.95   R-structure:  ~idv(units + trait:units)
>>>> post.mean  l-95% CI u-95% CI eff.samp trait:units   0.01932 0.0002102
>>>>  0.07042      441  Location effects: cbind(dawn, diurnal, dusk, nocturnal)
>>>> ~ trait + trait:culling + trait:predator
>>>>  post.mean  l-95% CI  u-95% CI eff.samp   pMCMC     (Intercept)
>>>>    -2.018903 -2.677830 -1.335305    609.1 < 7e-05 *** traitdiurnal
>>>>        0.542636 -0.363766  1.405230    644.6 0.22068     traitdusk
>>>>          -0.047952 -0.984923  0.917710    374.6 0.91850
>>>> traitdawn:cullingLethal     0.534474  0.003076  1.058211    596.8 0.05524 .
>>>>   traitdiurnal:cullingLethal  0.232597 -0.369959  0.834347    404.7 0.42789
>>>>     traitdusk:cullingLethal     0.376191 -0.217707  0.964636    408.2
>>>> 0.19782     traitdawn:cullingnone      -0.163961 -0.573477  0.298182
>>>> 2945.5 0.38245     traitdiurnal:cullingnone    0.674041  0.247724  1.101917
>>>>   2825.0 0.00952 **  traitdusk:cullingnone       0.449710 -0.014263
>>>>  0.874925   1683.9 0.05102 .   traitdawn:predatorhigh      0.456119
>>>> -0.206435  1.151283    561.7 0.18531     traitdiurnal:predatorhigh
>>>>  -0.303114 -0.976842  0.377294    479.9 0.36939     traitdusk:predatorhigh
>>>>      0.108262 -0.674552  0.895819    256.7 0.76122
>>>> traitdawn:predatorlow       0.756262  0.160407  1.323520    418.1 0.01279 *
>>>>   traitdiurnal:predatorlow    0.136875 -0.446984  0.750518    305.7 0.65619
>>>>     traitdusk:predatorlow       0.422497 -0.303586  1.145038    194.9
>>>> 0.22857     --- Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ?
>>>> ? 1*
>>>>
>>>> 1) Why do the 2 categories for culling both show up but then only 2 of
>>>> the three categories for predator show up? i.e. predatorabsent is missing?
>>>>
>>>> 2) Do these results mean that i) diurnal activity and lethal culling is
>>>> sig different from nocturnal activity and lethal culling; ii) dawn activity
>>>> and predator low is sig different from nocturnal activity and predator low?
>>>>
>>>> 3) Is this the correct way and interpretation of the within group
>>>> effects?
>>>> *##culling lethal*
>>>>
>>>>
>>>> * aod::wald.test(cov(m1$Sol[,3:5]),
>>>> colMeans(m1$Sol[,3:5]),Terms=1:3)$result$chi2["P"]         P  0.1638938*
>>>>
>>>>
>>>>
>>>>
>>>> * ##culling  none aod::wald.test(cov(m1$Sol[,6:8]),
>>>> colMeans(m1$Sol[,6:8]),Terms=1:3)$result$chi2["P"]           P  0.006497424*
>>>>
>>>>
>>>> So these results show us that culling none has an effect on activity?
>>>>
>>>> Thank you in advance,
>>>> Jess
>>>>
>>>> On Wed, Jul 27, 2022 at 8:20 AM jessica comley <
>>>> jessiecomley44 at gmail.com> wrote:
>>>>
>>>>> Dear Jarrod,
>>>>>
>>>>> Thank you so much for your help, I greatly appreciate it!
>>>>>
>>>>> All the best,
>>>>> Jess
>>>>>
>>>>> On Wed, Jul 27, 2022 at 3:32 AM Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>>>> wrote:
>>>>>
>>>>>> Hi Jess,
>>>>>>
>>>>>> Section should definitely not be left out, but I would imagine it is
>>>>>> going to be very difficult to separate culling, predator and Section
>>>>>> effects - I would expect the credible intervals to be large.
>>>>>>
>>>>>> As mentioned in my previous post you can test for an effect of
>>>>>> culling by fitting the model
>>>>>>
>>>>>> ~trait+trait:culling+trait:predator
>>>>>>
>>>>>> And then fitting a Wald test to the three terms with 'culling' in.
>>>>>> The effect of predator can be tested similarly but with the 3 terms with
>>>>>> 'predator' in.
>>>>>>
>>>>>> Since your covariates do not vary within Section it will be much
>>>>>> easier to aggregate the counts at the Section level (i.e have a data frame
>>>>>> with 14 rows and 1 column for each activity with the number observed for
>>>>>> each activity) and fit family="multinomial". You can then get rid of the
>>>>>> random formula as the Section effects are now effectively the residuals.
>>>>>> Given the lack of replication I would advise using the idv formula that I
>>>>>> suggested previously and hope the model isn't too misspecified:
>>>>>>
>>>>>> prior=list(R=list(V=1, nu=0.002))
>>>>>>
>>>>>> m1<-MCMCglmm(cbind(dawn, diurnal, dusk,
>>>>>> nocturnal)~trait+trait:culling+trait:predator,
>>>>>> rcov=~idv(units+trait:units), prior=prior, ...)
>>>>>>
>>>>>> Note this models is identical to the original model, it's just
>>>>>> parameterised in a more efficient way.
>>>>>>
>>>>>> Cheers,
>>>>>>
>>>>>> Jarrod
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> On 25 Jul 2022, at 03:52, jessica comley <jessiecomley44 at gmail.com>
>>>>>> wrote:
>>>>>>
>>>>>> This email was sent to you by someone outside the University.
>>>>>> You should only click on links or attachments if you are certain that
>>>>>> the email is genuine and the content is safe.
>>>>>> Dear Jarrod and Walid,
>>>>>>
>>>>>> Thank you for your replies, it is greatly appreciated.
>>>>>>
>>>>>> The predator and culling factors do not vary within sites. As shown
>>>>>> in the example data in one of my previous emails, Bucklands only has
>>>>>> culling as lethal and predator as low, whereas Colchester only has predator
>>>>>> as high and culling as none.
>>>>>>
>>>>>> We are trying to submit a paper on black-backed jackal and caracal
>>>>>> activity in the presence of different culling practices and
>>>>>> predator presence. The reviewers want us to try a GLMM approach to
>>>>>> determine whether culling or predators have an effect on black-backed
>>>>>> jackal or caracal activity.
>>>>>>
>>>>>> Therefore, in your opinion how could be go about this given our data?
>>>>>> Would it be advisable to leave out the random effect of Section?
>>>>>>
>>>>>> All the best,
>>>>>> Jess
>>>>>>
>>>>>> On Wed, Jul 20, 2022 at 3:06 PM Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>>>>> wrote:
>>>>>>
>>>>>>> Hi Jess
>>>>>>>
>>>>>>> In multinomial models the linear model is set up as a (logit)
>>>>>>> difference in probability between an outcome and some base-line outcome.
>>>>>>> Often, as here, the base-line outcome is arbitrary, and so the idh
>>>>>>> structure is a little odd. For example, if A is the base line category, idh
>>>>>>> assumes COV(B-A, C-A) = 0 which therefore assumes
>>>>>>> COV(B,C)+VAR(A) =COV(A,B)+COV(C,A). It's not clear why this would be
>>>>>>> the case. Perhaps a more reasonable, but less parameter rich, option would
>>>>>>> be to have:
>>>>>>>
>>>>>>> ~idv(Section+trait:Section)
>>>>>>>
>>>>>>> which parameterises the Section covariance matrix by a single
>>>>>>> parameter (rather than 6). The term idv(Section+trait:Section) fits a 3x3
>>>>>>> covariance matrix of the form v*(I+J) where v is the estimated variance.
>>>>>>> This assumes i) Sections are repeatable in outcome, but knowing that a
>>>>>>> Section has an increased 'preference' for A doesn?t tell you whether it
>>>>>>> also has an increased preference for one of the other categories and ii)
>>>>>>> the repeatability for each outcome within sites is the same (on the latent
>>>>>>> scale).
>>>>>>>
>>>>>>> To test groups of effects (in your case the 3 culling:trait
>>>>>>> effects), I usually use a Wald test and the posterior covariances (see here
>>>>>>>
>>>>>>> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2017q3/025930.html).
>>>>>>> It's far from correct and so Walid's suggestions may be better, but
>>>>>>> small-scale simulations suggests it has good frequentist properties.
>>>>>>>
>>>>>>> To add predator presence you can just add a predator:trait effect
>>>>>>> into the linear model. If the culling and predator factors do not vary
>>>>>>> within sites then you probably don't have enough information to reliably
>>>>>>> estimate these effects.
>>>>>>>
>>>>>>> Cheers,
>>>>>>>
>>>>>>> Jarrod
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> > On 19 Jul 2022, at 18:17, Walid Mawass <walidmawass10 at gmail.com>
>>>>>>> wrote:
>>>>>>> >
>>>>>>> > This email was sent to you by someone outside the University.
>>>>>>> > You should only click on links or attachments if you are certain
>>>>>>> that the email is genuine and the content is safe.
>>>>>>> >
>>>>>>> > Hey Jess,
>>>>>>> >
>>>>>>> > 1) Yes that is correct
>>>>>>> >
>>>>>>> > 2) To my knowledge there is a rule of thumb, where you set the
>>>>>>> nitt (# of
>>>>>>> > iterations) to a large number that includes the burnin amount,
>>>>>>> then you
>>>>>>> > choose your thinning interval (sampling of the chain). For
>>>>>>> example, this is
>>>>>>> > what I would use: nitt= 150000, burnin=50000, thin=100. This will
>>>>>>> give you
>>>>>>> > a decent burnin and a final sample of 1000 saved iterations. Note
>>>>>>> however
>>>>>>> > that this does not have to increase the effective sample size for
>>>>>>> certain
>>>>>>> > variables, but it might do the trick.
>>>>>>> >
>>>>>>> > 3) hmm...I think one way to do it is to make predictions using the
>>>>>>> above
>>>>>>> > model and interpret the patterns you see for each relationship you
>>>>>>> are
>>>>>>> > interested in. Another way to compare effect size would be to use
>>>>>>> bayesian
>>>>>>> > posterior indices. I suggest these two papers by Makowski et al.
>>>>>>> (2019a &
>>>>>>> > b) that present both interesting posterior indices to use with
>>>>>>> Bayesian
>>>>>>> > statistical analysis and an associated R package that does the job
>>>>>>> of
>>>>>>> > computing these indices, *bayestestR*.
>>>>>>> >
>>>>>>> > Good luck
>>>>>>> > --
>>>>>>> > Walid Mawass
>>>>>>> > Ph.D. candidate in Evolutionary Biology - UQTR
>>>>>>> > *Currently* Postdoctoral Research Associate
>>>>>>> > Masel Lab - University of Arizona
>>>>>>> >
>>>>>>> >
>>>>>>> > On Sun, Jul 17, 2022 at 11:32 PM jessica comley <
>>>>>>> jessiecomley44 at gmail.com>
>>>>>>> > wrote:
>>>>>>> >
>>>>>>> >> Hi Walid,
>>>>>>> >>
>>>>>>> >> Thank you for your reply, I greatly appreciate it. I have a few
>>>>>>> more
>>>>>>> >> questions and if you could help that would be great.
>>>>>>> >>
>>>>>>> >> I tested for correlation between activities and the 14 Sections
>>>>>>> and the
>>>>>>> >> correlation comes out as low. Therefore I have changed my code to
>>>>>>> use idh()
>>>>>>> >> instead of us as suggested:
>>>>>>> >>
>>>>>>> >> test1c.5b <- MCMCglmm(activity ~ -1 + at.level(culling,1):trait +
>>>>>>> >> at.level(culling, 2):trait, random=~idh(trait):Section, rcov =
>>>>>>> >> ~idh(trait):units, data = caracal, family = "categorical", prior
>>>>>>> = prior,
>>>>>>> >> burnin=5000, nitt=80000)
>>>>>>> >>
>>>>>>> >> 1) Is this correct?
>>>>>>> >>
>>>>>>> >> 2) Increasing the number of interactions increases the effective
>>>>>>> sample
>>>>>>> >> size, therefore is there a general rule of thumb as to how large
>>>>>>> your
>>>>>>> >> effective sample size should be?
>>>>>>> >>
>>>>>>> >> 3) I understand how to use and interpret the results of
>>>>>>> HPDinterval (i.e.
>>>>>>> >> if intervals do not overlap 0 then relationship is strong), but
>>>>>>> how am I
>>>>>>> >> able to test the relationship between all four activities and
>>>>>>> fixed effects
>>>>>>> >> and not just have the three categories (i.e. diurnal, dusk,
>>>>>>> nocturnal)
>>>>>>> >> compared to the base category (dawn)? For example, I am also
>>>>>>> interested in
>>>>>>> >> whether there is a significant/strong relationship between
>>>>>>> activities of
>>>>>>> >> caracal at dusk with culling(Lethal)/no culling(none) compared to
>>>>>>> >> activities of caracal at diurnal with culling(Lethal)/no
>>>>>>> culling(none).
>>>>>>> >>
>>>>>>> >> Below is an example of our dataset:
>>>>>>> >> Camera Section CameraID Animal predator culling activity
>>>>>>> >> 1a Bucklands Bucklands1a Caracal low Lethal diurnal
>>>>>>> >> 1a Bucklands Bucklands1a Caracal low Lethal dawn
>>>>>>> >> 2a Bucklands Bucklands2a Caracal low Lethal dusk
>>>>>>> >> 2a Bucklands Bucklands2a Caracal low Lethal diurnal
>>>>>>> >> 3a Bucklands Bucklands3a Caracal low Lethal dawn
>>>>>>> >> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>>>>>>> >> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>>>>>>> >> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>>>>>>> >> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>>>>>>> >> Cam 2  Colchester ColchesterCam 2  Caracal high none diurnal
>>>>>>> >> Cam 2  Colchester ColchesterCam 2  Caracal high none diurnal
>>>>>>> >> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
>>>>>>> >> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
>>>>>>> >> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
>>>>>>> >> Cam 4  Colchester ColchesterCam 4  Caracal high none diurnal
>>>>>>> >> Cam 4  Colchester ColchesterCam 4  Caracal high none diurnal
>>>>>>> >> Cam 4  Colchester ColchesterCam 4  Caracal high none nocturnal
>>>>>>> >> 1a Connaught Connaught1a Caracal low Lethal nocturnal
>>>>>>> >> 1a Connaught Connaught1a Caracal low Lethal nocturnal
>>>>>>> >> 1d Connaught Connaught1d Caracal low Lethal diurnal
>>>>>>> >> 3B Connaught Connaught3B Caracal low Lethal diurnal
>>>>>>> >> 3B Connaught Connaught3B Caracal low Lethal diurnal
>>>>>>> >> 4a Connaught Connaught4a Caracal low Lethal nocturnal
>>>>>>> >> 4a Connaught Connaught4a Caracal low Lethal nocturnal
>>>>>>> >> 4b Connaught Connaught4b Caracal low Lethal diurnal
>>>>>>> >> 6a Connaught Connaught6a Caracal low Lethal nocturnal
>>>>>>> >> 6b Connaught Connaught6b Caracal low Lethal diurnal
>>>>>>> >> 7a Connaught Connaught7a Caracal low Lethal nocturnal
>>>>>>> >> 9a Connaught Connaught9a Caracal low Lethal nocturnal
>>>>>>> >> 9d Connaught Connaught9d Caracal low Lethal nocturnal
>>>>>>> >> 9d Connaught Connaught9d Caracal low Lethal dusk
>>>>>>> >> 7d Diepdam Diepdam7d Caracal absent Lethal dusk
>>>>>>> >> 8d Diepdam Diepdam8d Caracal absent Lethal diurnal
>>>>>>> >> 9c Diepdam Diepdam9c Caracal absent Lethal nocturnal
>>>>>>> >>
>>>>>>> >> All the best,
>>>>>>> >> Jess
>>>>>>> >>
>>>>>>> >>
>>>>>>> >> On Fri, Jul 15, 2022 at 11:37 PM Walid Mawass <
>>>>>>> walidmawass10 at gmail.com>
>>>>>>> >> wrote:
>>>>>>> >>
>>>>>>> >>> Hello,
>>>>>>> >>>
>>>>>>> >>> I don't think I can specifically help you with some of your
>>>>>>> inquiries.
>>>>>>> >>> However, I do want to comment on a few things that might need
>>>>>>> some
>>>>>>> >>> attention.
>>>>>>> >>>
>>>>>>> >>> First, MCMCglmm is based on a Bayesian implementation and does
>>>>>>> not
>>>>>>> >>> compute p-values to compare. What you need to compare are the
>>>>>>> posterior
>>>>>>> >>> distributions of your effect sizes. This can be done visually
>>>>>>> using the
>>>>>>> >>> base plot function in R. Or by comparing the HPD intervals and
>>>>>>> the mode (or
>>>>>>> >>> mean) of the posterior distributions.
>>>>>>> >>>
>>>>>>> >>> Second, I have no idea what your data structure looks like
>>>>>>> (which makes
>>>>>>> >>> it hard to interpret model results), but the effective sample
>>>>>>> size (from
>>>>>>> >>> the 5500 saved iterations sample) for your random variable
>>>>>>> Section is very
>>>>>>> >>> low (the same applies for your fixed effects). You should
>>>>>>> consider this
>>>>>>> >>> issue and look again at your assumption of correlation between
>>>>>>> >>> activities for the 14 sections you have in your dataset. If you
>>>>>>> do not
>>>>>>> >>> expect among activity correlations then you can use the idh()
>>>>>>> function
>>>>>>> >>> instead of us().
>>>>>>> >>>
>>>>>>> >>> Hopefully this helps and in hope that people on this list with
>>>>>>> more
>>>>>>> >>> knowledge of these models will help out.
>>>>>>> >>>
>>>>>>> >>> Best,
>>>>>>> >>> --
>>>>>>> >>> Walid Mawass
>>>>>>> >>> Ph.D. candidate in Evolutionary Biology - UQTR
>>>>>>> >>> *Currently* Postdoctoral Research Associate
>>>>>>> >>> Masel Lab - University of Arizona
>>>>>>> >>>
>>>>>>> >>>
>>>>>>> >>> On Fri, Jul 15, 2022 at 8:49 AM jessica comley <
>>>>>>> jessiecomley44 at gmail.com>
>>>>>>> >>> wrote:
>>>>>>> >>>
>>>>>>> >>>> Dear all,
>>>>>>> >>>>
>>>>>>> >>>> I am hoping that someone will be able to help me with
>>>>>>> conducting MCMCglmm
>>>>>>> >>>> multinomial models.
>>>>>>> >>>>
>>>>>>> >>>> The data I am working with is for black-backed jackal (bbj) and
>>>>>>> carcal.
>>>>>>> >>>> For
>>>>>>> >>>> each species we have a multinomial response variable called
>>>>>>> activity
>>>>>>> >>>> which
>>>>>>> >>>> has four categories (dawn, diurnal, dusk, nocturnal). We have
>>>>>>> two
>>>>>>> >>>> categorical fixed effects which are 1) culling (none, lethal)
>>>>>>> and 2)
>>>>>>> >>>> predator presence (absent, high, low). We also have a
>>>>>>> categorical
>>>>>>> >>>> variable
>>>>>>> >>>> called Section (made up of 14 different reserves/ farms where
>>>>>>> the
>>>>>>> >>>> activity
>>>>>>> >>>> of caracal and bbj were recorded). There are 273 observations
>>>>>>> for caracal
>>>>>>> >>>> and 4399 for bbj. We are wanting to test the effects of culling
>>>>>>> and
>>>>>>> >>>> predators on caracal and bbj activity separately.
>>>>>>> >>>>
>>>>>>> >>>> I have been working through Jarrod Hadfields course notes,
>>>>>>> particularly
>>>>>>> >>>> with regards to Chapter 5.2. The chi-square analyses reveal
>>>>>>> that the
>>>>>>> >>>> frequencies of culling and predators differ as do activities.
>>>>>>> >>>>
>>>>>>> >>>> I have managed to work out the specific probabilities for the
>>>>>>> culling
>>>>>>> >>>> none
>>>>>>> >>>> vs culling lethal for each activity (dawn, diurnal, dusk,
>>>>>>> nocturnal) for
>>>>>>> >>>> caracal, but I'm confused as to how to determine p-values to
>>>>>>> determine
>>>>>>> >>>> which activities culling none vs culling lethal are affecting?
>>>>>>> >>>>
>>>>>>> >>>> Myy code and outcomes are pasted below with questions stated in
>>>>>>> bold.
>>>>>>> >>>>
>>>>>>> >>>> caracal2 <- read.csv("caracal_new.csv", header=T)
>>>>>>> >>>> caracal <- as.data.frame(unclass(caracal2), stringsAsFactors =
>>>>>>> TRUE)
>>>>>>> >>>>
>>>>>>> >>>> #Chi-squared tests
>>>>>>> >>>> Ctable1 <- table(caracal$activity, caracal$culling)
>>>>>>> >>>> chisq.test(rowSums(Ctable1)) #strongly suggests activities
>>>>>>> differ
>>>>>>> >>>> chisq.test(Ctable1)#strongly suggests culling category differs
>>>>>>> >>>>
>>>>>>> >>>> Ctable2 <- table(caracal$activity, caracal$predator)
>>>>>>> >>>> chisq.test(rowSums(Ctable2))#strongly suggests activities differ
>>>>>>> >>>> chisq.test(Ctable2)#strongly suggests predator category differs
>>>>>>> >>>>
>>>>>>> >>>> prior = list(R = list(fix=1, V=(1/k) * (I + J)), G =
>>>>>>> list(G1=list(V =
>>>>>>> >>>> diag(k-1), nu=1)))
>>>>>>> >>>> test1c.5 <- MCMCglmm(activity ~ -1 + at.level(culling,1):trait +
>>>>>>> >>>> at.level(culling, 2):trait, random=~us(trait):Section, rcov =
>>>>>>> >>>> ~us(trait):units, data = caracal, family = "categorical", prior
>>>>>>> = prior,
>>>>>>> >>>> burnin=5000, nitt=60000)
>>>>>>> >>>> *##I'm not sure how to add the three predator levels to this
>>>>>>> model or if
>>>>>>> >>>> it
>>>>>>> >>>> would be appropriate?*
>>>>>>> >>>>
>>>>>>> >>>>
>>>>>>> >>>> k <- length(levels(caracal$activity))
>>>>>>> >>>> I <- diag(k-1)
>>>>>>> >>>> J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))
>>>>>>> >>>> IJ <- (1/k) *(diag(k-1) + matrix(1,k-1, k-1))
>>>>>>> >>>>
>>>>>>> >>>> contrasts(caracal$activity)
>>>>>>> >>>>
>>>>>>> >>>> #culling lethal
>>>>>>> >>>> Delta <- cbind(c(0,1,0,0), c(0,0,1,0), c(0,0,0,1))
>>>>>>> >>>> c2 <- (16 * sqrt(3)/(15 * pi))^2
>>>>>>> >>>> D <- ginv(Delta %*% t(Delta)) %*% Delta
>>>>>>> >>>> Int <- t(apply(test1c.5$Sol[,1:3],1, function(x) + D %*%
>>>>>>> (x/sqrt(1 + c2 *
>>>>>>> >>>> diag(IJ)))))
>>>>>>> >>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>>>>> >>>>
>>>>>>> >>>> prop.table(Ctable1[,1])
>>>>>>> >>>>
>>>>>>> >>>> #culling none
>>>>>>> >>>> Delta <- cbind(c(0,1,0,0), c(0,0,1,0), c(0,0,0,1))
>>>>>>> >>>> c2 <- (16 * sqrt(3)/(15 * pi))^2
>>>>>>> >>>> D <- ginv(Delta %*% t(Delta)) %*% Delta
>>>>>>> >>>> Int <- t(apply(test1c.5$Sol[,4:6],1, function(x) + D %*%
>>>>>>> (x/sqrt(1 + c2 *
>>>>>>> >>>> diag(IJ)))))
>>>>>>> >>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>>>>> >>>>
>>>>>>> >>>> prop.table((Ctable1[,2]))
>>>>>>> >>>>
>>>>>>> >>>> HPDinterval(test1c.5$Sol)
>>>>>>> >>>>
>>>>>>> >>>> #model summary
>>>>>>> >>>>> summary(test1c.5)
>>>>>>> >>>>
>>>>>>> >>>> Iterations = 5001:59991
>>>>>>> >>>> Thinning interval  = 10
>>>>>>> >>>> Sample size  = 5500
>>>>>>> >>>>
>>>>>>> >>>> DIC: 699.7014
>>>>>>> >>>>
>>>>>>> >>>> G-structure:  ~us(trait):Section
>>>>>>> >>>>
>>>>>>> >>>>
>>>>>>> post.mean l-95%
>>>>>>> >>>> CI
>>>>>>> >>>> u-95% CI eff.samp
>>>>>>> >>>> traitactivity.diurnal:traitactivity.diurnal.Section
>>>>>>> 1.8124
>>>>>>> >>>> 0.09784
>>>>>>> >>>>   5.665    77.01
>>>>>>> >>>> traitactivity.dusk:traitactivity.diurnal.Section
>>>>>>>  0.8450
>>>>>>> >>>> -0.83585
>>>>>>> >>>>   3.856    64.17
>>>>>>> >>>> traitactivity.nocturnal:traitactivity.diurnal.Section
>>>>>>> 1.3621
>>>>>>> >>>> -1.19129
>>>>>>> >>>>   6.157    58.48
>>>>>>> >>>> traitactivity.diurnal:traitactivity.dusk.Section
>>>>>>>  0.8450
>>>>>>> >>>> -0.83585
>>>>>>> >>>>   3.856    64.17
>>>>>>> >>>> traitactivity.dusk:traitactivity.dusk.Section
>>>>>>> 1.2034
>>>>>>> >>>> 0.07090
>>>>>>> >>>>   3.681   102.16
>>>>>>> >>>> traitactivity.nocturnal:traitactivity.dusk.Section
>>>>>>>  0.7505
>>>>>>> >>>> -1.77113
>>>>>>> >>>>   4.524    43.53
>>>>>>> >>>> traitactivity.diurnal:traitactivity.nocturnal.Section
>>>>>>> 1.3621
>>>>>>> >>>> -1.19129
>>>>>>> >>>>   6.157    58.48
>>>>>>> >>>> traitactivity.dusk:traitactivity.nocturnal.Section
>>>>>>>  0.7505
>>>>>>> >>>> -1.77113
>>>>>>> >>>>   4.524    43.53
>>>>>>> >>>> traitactivity.nocturnal:traitactivity.nocturnal.Section
>>>>>>> 2.7148
>>>>>>> >>>> 0.09401
>>>>>>> >>>>   8.397    76.59
>>>>>>> >>>>
>>>>>>> >>>> R-structure:  ~us(trait):units
>>>>>>> >>>>
>>>>>>> >>>>                                                      post.mean
>>>>>>> l-95% CI
>>>>>>> >>>> u-95% CI eff.samp
>>>>>>> >>>> traitactivity.diurnal:traitactivity.diurnal.units
>>>>>>> 0.50     0.50
>>>>>>> >>>>  0.50        0
>>>>>>> >>>> traitactivity.dusk:traitactivity.diurnal.units
>>>>>>>  0.25     0.25
>>>>>>> >>>>  0.25        0
>>>>>>> >>>> traitactivity.nocturnal:traitactivity.diurnal.units
>>>>>>> 0.25     0.25
>>>>>>> >>>>  0.25        0
>>>>>>> >>>> traitactivity.diurnal:traitactivity.dusk.units
>>>>>>>  0.25     0.25
>>>>>>> >>>>  0.25        0
>>>>>>> >>>> traitactivity.dusk:traitactivity.dusk.units
>>>>>>> 0.50     0.50
>>>>>>> >>>>  0.50        0
>>>>>>> >>>> traitactivity.nocturnal:traitactivity.dusk.units
>>>>>>>  0.25     0.25
>>>>>>> >>>>  0.25        0
>>>>>>> >>>> traitactivity.diurnal:traitactivity.nocturnal.units
>>>>>>> 0.25     0.25
>>>>>>> >>>>  0.25        0
>>>>>>> >>>> traitactivity.dusk:traitactivity.nocturnal.units
>>>>>>>  0.25     0.25
>>>>>>> >>>>  0.25        0
>>>>>>> >>>> traitactivity.nocturnal:traitactivity.nocturnal.units
>>>>>>> 0.50     0.50
>>>>>>> >>>>  0.50        0
>>>>>>> >>>>
>>>>>>> >>>> Location effects: activity ~ -1 + at.level(culling, 1):trait +
>>>>>>> >>>> at.level(culling, 2):trait
>>>>>>> >>>>
>>>>>>> >>>>                                             post.mean l-95% CI
>>>>>>> u-95% CI
>>>>>>> >>>> eff.samp  pMCMC
>>>>>>> >>>> at.level(culling, 1):traitactivity.diurnal      1.2306
>>>>>>> -0.0533   2.6793
>>>>>>> >>>> 145.29 0.0418 *
>>>>>>> >>>> at.level(culling, 1):traitactivity.dusk         0.6605
>>>>>>> -0.6006   2.0761
>>>>>>> >>>> 92.91 0.2840
>>>>>>> >>>> at.level(culling, 1):traitactivity.nocturnal    1.6090
>>>>>>>  0.0914   3.1356
>>>>>>> >>>> 151.02 0.0265 *
>>>>>>> >>>> traitactivity.diurnal:at.level(culling, 2)      1.2664
>>>>>>> -0.1552   2.7750
>>>>>>> >>>> 226.40 0.0604 .
>>>>>>> >>>> traitactivity.dusk:at.level(culling, 2)         0.3533
>>>>>>> -0.9898   1.5218
>>>>>>> >>>> 148.44 0.5447
>>>>>>> >>>> traitactivity.nocturnal:at.level(culling, 2)    1.0447
>>>>>>> -0.6405   2.8354
>>>>>>> >>>> 346.40 0.1618
>>>>>>> >>>> ---
>>>>>>> >>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>>>>> >>>>
>>>>>>> >>>> *##So for the model summary I get that lethal culling at
>>>>>>> activity diurnal
>>>>>>> >>>> is significantly different from lethal culling at dawn (its the
>>>>>>> base
>>>>>>> >>>> reference), but I'm also interested in whether lethal culling
>>>>>>> at activity
>>>>>>> >>>> diurnal is different from lethal culling at dusk for example.
>>>>>>> Is this
>>>>>>> >>>> possible? *
>>>>>>> >>>>
>>>>>>> >>>> #outcomes culling lethal
>>>>>>> >>>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>>>>> >>>>
>>>>>>> >>>> Iterations = 1:5500
>>>>>>> >>>> Thinning interval = 1
>>>>>>> >>>> Number of chains = 1
>>>>>>> >>>> Sample size per chain = 5500
>>>>>>> >>>>
>>>>>>> >>>> 1. Empirical mean and standard deviation for each variable,
>>>>>>> >>>>   plus standard error of the mean:
>>>>>>> >>>>
>>>>>>> >>>>       Mean      SD  Naive SE Time-series SE
>>>>>>> >>>> [1,] 0.1253 0.05565 0.0007504       0.002484
>>>>>>> >>>> [2,] 0.3748 0.10497 0.0014155       0.003204
>>>>>>> >>>> [3,] 0.1757 0.06640 0.0008954       0.002515
>>>>>>> >>>> [4,] 0.3242 0.11939 0.0016099       0.003514
>>>>>>> >>>>
>>>>>>> >>>> 2. Quantiles for each variable:
>>>>>>> >>>>
>>>>>>> >>>>        2.5%     25%    50%    75%  97.5%
>>>>>>> >>>> var1 0.03641 0.08695 0.1198 0.1554 0.2553
>>>>>>> >>>> var2 0.17298 0.30580 0.3704 0.4431 0.5896
>>>>>>> >>>> var3 0.06166 0.12913 0.1705 0.2161 0.3215
>>>>>>> >>>> var4 0.12610 0.23999 0.3090 0.3901 0.6045
>>>>>>> >>>>
>>>>>>> >>>>> prop.table(Ctable1[,1])
>>>>>>> >>>>     dawn   diurnal      dusk nocturnal
>>>>>>> >>>> 0.1250000 0.2812500 0.1770833 0.4166667
>>>>>>> >>>>
>>>>>>> >>>>
>>>>>>> >>>> #outcomes culling none
>>>>>>> >>>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>>>>> >>>>
>>>>>>> >>>> Iterations = 1:5500
>>>>>>> >>>> Thinning interval = 1
>>>>>>> >>>> Number of chains = 1
>>>>>>> >>>> Sample size per chain = 5500
>>>>>>> >>>>
>>>>>>> >>>> 1. Empirical mean and standard deviation for each variable,
>>>>>>> >>>>   plus standard error of the mean:
>>>>>>> >>>>
>>>>>>> >>>>       Mean      SD  Naive SE Time-series SE
>>>>>>> >>>> [1,] 0.1288 0.06141 0.0008280       0.002787
>>>>>>> >>>> [2,] 0.3804 0.10406 0.0014032       0.002662
>>>>>>> >>>> [3,] 0.1710 0.06844 0.0009228       0.002592
>>>>>>> >>>> [4,] 0.3198 0.11812 0.0015928       0.002956
>>>>>>> >>>>
>>>>>>> >>>> 2. Quantiles for each variable:
>>>>>>> >>>>
>>>>>>> >>>>        2.5%     25%    50%    75%  97.5%
>>>>>>> >>>> var1 0.02891 0.08896 0.1220 0.1594 0.2685
>>>>>>> >>>> var2 0.18007 0.31094 0.3783 0.4474 0.5965
>>>>>>> >>>> var3 0.05840 0.12425 0.1634 0.2083 0.3250
>>>>>>> >>>> var4 0.12430 0.23921 0.3077 0.3862 0.5964
>>>>>>> >>>>
>>>>>>> >>>>> prop.table((Ctable1[,2]))
>>>>>>> >>>>     dawn   diurnal      dusk nocturnal
>>>>>>> >>>> 0.1306818 0.4375000 0.1875000 0.2443182
>>>>>>> >>>>
>>>>>>> >>>> Any help or guidance will be greatly appreciated.
>>>>>>> >>>>
>>>>>>> >>>> All the best,
>>>>>>> >>>> Jess
>>>>>>> >>>>
>>>>>>> >>>> --
>>>>>>> >>>> Jessica Comley (PhD)
>>>>>>> >>>> Research Scientist
>>>>>>> >>>>
>>>>>>> >>>>        [[alternative HTML version deleted]]
>>>>>>> >>>>
>>>>>>> >>>> _______________________________________________
>>>>>>> >>>> R-sig-mixed-models at r-project.org mailing list
>>>>>>> >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>> >>>>
>>>>>>> >>>
>>>>>>> >>
>>>>>>> >> --
>>>>>>> >> Jessica Comley (PhD)
>>>>>>> >> Research Scientist
>>>>>>> >>
>>>>>>> >>
>>>>>>> >
>>>>>>> >        [[alternative HTML version deleted]]
>>>>>>> >
>>>>>>> > _______________________________________________
>>>>>>> > R-sig-mixed-models at r-project.org mailing list
>>>>>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>
>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>> Scotland, with registration number SC005336. Is e buidheann carthannais a
>>>>>>> th? ann an Oilthigh Dh?n ?ideann, cl?raichte an Alba, ?ireamh cl?raidh
>>>>>>> SC005336.
>>>>>>>
>>>>>>
>>>>>>
>>>>>> --
>>>>>> Jessica Comley (PhD)
>>>>>> Research Scientist
>>>>>>
>>>>>>
>>>>>>
>>>>>
>>>>> --
>>>>> Dr Jessica Comley
>>>>> Lecturer: Environmental and Life Sciences
>>>>> Faculty of Science
>>>>> Universiti Brunei Darussalam
>>>>>
>>>>> Email: jessica.comley at ubd.edu.bn
>>>>>
>>>>>
>>>>
>>>> --
>>>> Dr Jessica Comley
>>>> Lecturer: Environmental and Life Sciences
>>>> Faculty of Science
>>>> Universiti Brunei Darussalam
>>>>
>>>> Email: jessica.comley at ubd.edu.bn
>>>>
>>>>
>>>>
>>>
>>> --
>>> Dr Jessica Comley
>>> Lecturer: Environmental and Life Sciences
>>> Faculty of Science
>>> Universiti Brunei Darussalam
>>>
>>> Email: jessica.comley at ubd.edu.bn
>>>
>>>
>>
>> --
>> Dr Jessica Comley
>> Lecturer: Environmental and Life Sciences
>> Faculty of Science
>> Universiti Brunei Darussalam
>>
>> Email: jessica.comley at ubd.edu.bn
>>
>>
>>
>
> --
> Dr Jessica Comley
> Lecturer: Environmental and Life Sciences
> Faculty of Science
> Universiti Brunei Darussalam
>
> Email: jessica.comley at ubd.edu.bn
>
>
>

-- 
Dr Jessica Comley
Lecturer: Environmental and Life Sciences
Faculty of Science
Universiti Brunei Darussalam

Email: jessica.comley at ubd.edu.bn

	[[alternative HTML version deleted]]


From jepu@to @end|ng |rom gm@||@com  Wed Jul 27 18:04:51 2022
From: jepu@to @end|ng |rom gm@||@com (James Pustejovsky)
Date: Wed, 27 Jul 2022 11:04:51 -0500
Subject: [R-sig-ME] Cluster-robust SEs & random effects -- seeking some
 clarification
In-Reply-To: <CAH_7VO=aOOhT8TWJ7rAfY4EC+8yOepLpkpg0TcXgjN+wwk2c=w@mail.gmail.com>
References: <CAH_7VOkx8+Pwpx+Rovgm0=k2Nde3TvmJpAQ_28O_NjQTY82h4g@mail.gmail.com>
 <CAFUVuJyh56KYctgrB1TSn8JB01h+Lh93Oh--dPvOK616b=x3LQ@mail.gmail.com>
 <CAH_7VO=aOOhT8TWJ7rAfY4EC+8yOepLpkpg0TcXgjN+wwk2c=w@mail.gmail.com>
Message-ID: <CAFUVuJztqcXppr8VSDUXWYmTtcyDk+TVXDc3WPNkfcPJNRmaGA@mail.gmail.com>

Hi J.D.,

Responses inline below.

James

On Tue, Jul 26, 2022 at 10:42 PM J.D. Haltigan <jhaltiga at gmail.com> wrote:

> Many thanks for this detailed and insightful exposition, James.
>
> A few follow-ups:
>
> I had previously tried cluster-robust SEs with both the robustlmm package
> and now yours, and it appears I don't have the memory needed given the size
> of the data as I receive the following error:
> #Error in .local(x, y, ...) :
> #Cholmod error 'problem too large' at file ../Core/cholmod_sparse.c, line
> 89
> In Googling this error message, I see it is likely due to the computational
> demands of a sparse matrix estimation, but was wondering if there were any
> other aspects of this I could explore.
>
>
To figure out what's going on, we need to know the dimensions of your
model. How many coefficients (fixed effects) are in your regression
specification? How many clusters do you have? What is the range of cluster
sizes?


> In regards to #4: I am invoking random effects to see how sensitive a fixed
> effects model (with cluster robust SEs) is to formally estimating the
> random cluster effect (so between-cluster variance). In the fixed effects
> model, the investigators did include a factor variable (i.e., cluster
> dummies as you describe below) that is nested within cluster (so, a pair
> variable indicating treatment-control village), but my predilection is that
> despite this, there are other sources of between-cluster variance that will
> likely nullify the point estimates of the fixed effects (in this case, a
> mask intervention).


I'm not sure what you mean by "other sources of between-cluster variance
that will likely nullify the point estimates of the fixed effects." Can you
explain in a bit more detail?


> So, if I am formally modeling the random cluster
> component, what does adding cluster-robust SEs in this case provide in
> terms of inference--both for the fixed effects and for the random effects?
>

Cluster-robust SEs are only relevant for inference on the regression
coefficients (fixed effects)--not for the random effects. For the fixed
effects, using cluster-robust SEs provides robustness to misspecification
of the random effects model, such as omission of a random slope that should
be there. In the context of your example, there might be heterogeneity of
intervention effects across pairs of villages. A random effects model that
only includes random intercepts for each village will not "catch" this sort
of treatment effect heterogeneity, and model-based SEs could be invalidated
by it. Cluster-robust SEs will account for that sort of heterogeneity (and
be larger than the model-based SEs as a consequence).

	[[alternative HTML version deleted]]


From ru@@e||-|enth @end|ng |rom u|ow@@edu  Wed Jul 27 18:10:18 2022
From: ru@@e||-|enth @end|ng |rom u|ow@@edu (Lenth, Russell V)
Date: Wed, 27 Jul 2022 16:10:18 +0000
Subject: [R-sig-ME] Model approach for pairwise comparison post-hoc
In-Reply-To: <mailman.19804.1603.1658928544.1226.r-sig-mixed-models@r-project.org>
References: <mailman.19804.1603.1658928544.1226.r-sig-mixed-models@r-project.org>
Message-ID: <DM6PR04MB4474003E758D5DBD6E27C170F1979@DM6PR04MB4474.namprd04.prod.outlook.com>

Just use

    lsm.both <- lsmeans(mTCFd, c("temp", "generation"))
    cld(lsm.both)

-----Original Message-----

Message: 1
Date: Wed, 27 Jul 2022 12:40:32 +0000 (UTC)
From: Alexandre Santos <alexandresantosbr at yahoo.com.br>
To: "r-sig-mixed-models at r-project.org"
	<r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] Model approach for pairwise comparison post-hoc
Message-ID: <1309771597.2820689.1658925632725 at mail.yahoo.com>
Content-Type: text/plain; charset="utf-8"

In my example: 


? ? # Packages
? ? library(glmmTMB)
? ? library(multcomp)
? ? library(lsmeans)
? ? library(car)
? ? 
? ? # My data set
? ? ds <- read.csv("https://raw.githubusercontent.com/Leprechault/trash/main/temp_ger_ds.csv")
? ? str(ds)
? ? #'data.frame': ?140 obs. of ?4 variables:
? ? # $ temp ? ? ? : chr ?"constante" "constante" "constante" "constante" ...
? ? # $ generation : chr ?"G0" "G0" "G0" "G0" ...
? ? # $ development: int ?22 24 22 27 27 24 25 26 27 18 ...


First fit the ziGamma model:


? ? mTCFd <- glmmTMB(development ~ temp * generation + (1 | generation), data = ds,
? ? ? ? ? ? ? ? ? ?family = ziGamma(link = "log"))
? ? Anova(mTCFd,test="Chi")
# Analysis of Deviance Table (Type II Wald chisquare tests)


# Response: development
# ? ? ? ? ? ? ? ? ? Chisq Df Pr(>Chisq) ? ?
# temp ? ? ? ? ? ?198.412 ?1 ?< 2.2e-16 ***
# generation ? ? ? 18.346 ?4 ? 0.001056 ** 
# temp:generation ?31.250 ?4 ?2.723e-06 ***
# ---
# Signif. codes: ?0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


Pairwise Comparison Post Hoc Tests:


? ? 1) For temp:
? ? lsm.TCFd.temp <- lsmeans(mTCFd, c("temp"))
? ? cld(lsm.TCFd.temp, Letters=letters)
# ?temp ? ? ?lsmean ? ? SE ?df lower.CL upper.CL .group
# ?constante ? 3.18 0.0082 128 ? ? 3.17 ? ? 3.20 ?a ? ?
# ?flutuante ? 3.37 0.0131 128 ? ? 3.34 ? ? 3.39 ? b ? 
? ? 
? ? 2) For generation:
? ? lsm.TCFd.gen <- lsmeans(mTCFd, c("generation"))
? ? cld(lsm.TCFd.gen, Letters=letters)
# ?generation lsmean ? ? SE ?df lower.CL upper.CL .group
# ?G3 ? ? ? ? ? 3.23 0.0159 128 ? ? 3.20 ? ? 3.26 ?a ? ?
# ?G1 ? ? ? ? ? 3.27 0.0198 128 ? ? 3.23 ? ? 3.31 ?ab ? 
# ?G0 ? ? ? ? ? 3.27 0.0135 128 ? ? 3.25 ? ? 3.30 ?ab ? 
# ?G4 ? ? ? ? ? 3.29 0.0217 128 ? ? 3.25 ? ? 3.34 ?ab ? 
# ?G2 ? ? ? ? ? 3.31 0.0141 128 ? ? 3.28 ? ? 3.34 ? b ? 
? ? 3) For temp:generation interaction:
? ? ds$temp_gen <- paste0(ds$temp,"_",ds$generation)
? ? mTCFd.int <- glmmTMB(development ~ temp_gen + (1 | generation), data = ds,
? ? ? ? ? ? ? ? ? ?family = ziGamma(link = "log")) 
? ? lsm.TCFd.temp.gen <- lsmeans(mTCFd.int, c("temp_gen"))
? ? cld(lsm.TCFd.temp.gen, Letters=letters)
# ?temp_gen ? ? lsmean ? ? SE ?df lower.CL upper.CL .group 
# ?constante_G3 ? 3.13 0.0180 128 ? ? 3.09 ? ? 3.16 ?a ? ? 
# ?constante_G2 ? 3.14 0.0180 128 ? ? 3.11 ? ? 3.18 ?ab ? ?
# ?constante_G0 ? 3.19 0.0191 128 ? ? 3.15 ? ? 3.23 ?abc ? 
# ?constante_G1 ? 3.22 0.0180 128 ? ? 3.18 ? ? 3.25 ? bc ? 
# ?constante_G4 ? 3.23 0.0185 128 ? ? 3.19 ? ? 3.27 ? ?cd ?
# ?flutuante_G1 ? 3.32 0.0352 128 ? ? 3.25 ? ? 3.39 ? ?cde 
# ?flutuante_G3 ? 3.34 0.0262 128 ? ? 3.28 ? ? 3.39 ? ? ?e 
# ?flutuante_G0 ? 3.36 0.0191 128 ? ? 3.32 ? ? 3.39 ? ? ?e 
# ?flutuante_G4 ? 3.36 0.0393 128 ? ? 3.28 ? ? 3.44 ? ? def
# ?flutuante_G2 ? 3.47 0.0218 128 ? ? 3.43 ? ? 3.52 ? ? ? f


Ok, it works, but I'd like to know if is possible for the pairwise comparison
directly with the final model (`mTCFd`) without a new interaction model adjustment (`mTCFd.int`).
This is because different models have different parameters and I'm interesting in the `mTCFd` adjustment.


Please, any help with it?

From @|ex@ndre@@nto@br @end|ng |rom y@hoo@com@br  Wed Jul 27 20:02:15 2022
From: @|ex@ndre@@nto@br @end|ng |rom y@hoo@com@br (Alexandre Santos)
Date: Wed, 27 Jul 2022 18:02:15 +0000 (UTC)
Subject: [R-sig-ME] Model approach for pairwise comparison post-hoc
In-Reply-To: <DM6PR04MB4474003E758D5DBD6E27C170F1979@DM6PR04MB4474.namprd04.prod.outlook.com>
References: <mailman.19804.1603.1658928544.1226.r-sig-mixed-models@r-project.org>
 <DM6PR04MB4474003E758D5DBD6E27C170F1979@DM6PR04MB4474.namprd04.prod.outlook.com>
Message-ID: <30412679.2978423.1658944935913@mail.yahoo.com>

Hi Russel,

Thank you for the solution!!

Best wishes,

Alexandre





Em quarta-feira, 27 de julho de 2022 12:10:21 AMT, Lenth, Russell V <russell-lenth at uiowa.edu> escreveu: 





Just use

? ? lsm.both <- lsmeans(mTCFd, c("temp", "generation"))
? ? cld(lsm.both)

-----Original Message-----

Message: 1
Date: Wed, 27 Jul 2022 12:40:32 +0000 (UTC)
From: Alexandre Santos <alexandresantosbr at yahoo.com.br>
To: "r-sig-mixed-models at r-project.org"
??? <r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] Model approach for pairwise comparison post-hoc
Message-ID: <1309771597.2820689.1658925632725 at mail.yahoo.com>
Content-Type: text/plain; charset="utf-8"

In my example: 


? ? # Packages
? ? library(glmmTMB)
? ? library(multcomp)
? ? library(lsmeans)
? ? library(car)
? ? 
? ? # My data set
? ? ds <- read.csv("https://raw.githubusercontent.com/Leprechault/trash/main/temp_ger_ds.csv")
? ? str(ds)
? ? #'data.frame': ?140 obs. of ?4 variables:
? ? # $ temp ? ? ? : chr ?"constante" "constante" "constante" "constante" ...
? ? # $ generation : chr ?"G0" "G0" "G0" "G0" ...
? ? # $ development: int ?22 24 22 27 27 24 25 26 27 18 ...


First fit the ziGamma model:


? ? mTCFd <- glmmTMB(development ~ temp * generation + (1 | generation), data = ds,
? ? ? ? ? ? ? ? ? ?family = ziGamma(link = "log"))
? ? Anova(mTCFd,test="Chi")
# Analysis of Deviance Table (Type II Wald chisquare tests)


# Response: development
# ? ? ? ? ? ? ? ? ? Chisq Df Pr(>Chisq) ? ?
# temp ? ? ? ? ? ?198.412 ?1 ?< 2.2e-16 ***
# generation ? ? ? 18.346 ?4 ? 0.001056 ** 
# temp:generation ?31.250 ?4 ?2.723e-06 ***
# ---
# Signif. codes: ?0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


Pairwise Comparison Post Hoc Tests:


? ? 1) For temp:
? ? lsm.TCFd.temp <- lsmeans(mTCFd, c("temp"))
? ? cld(lsm.TCFd.temp, Letters=letters)
# ?temp ? ? ?lsmean ? ? SE ?df lower.CL upper.CL .group
# ?constante ? 3.18 0.0082 128 ? ? 3.17 ? ? 3.20 ?a ? ?
# ?flutuante ? 3.37 0.0131 128 ? ? 3.34 ? ? 3.39 ? b ? 
? ? 
? ? 2) For generation:
? ? lsm.TCFd.gen <- lsmeans(mTCFd, c("generation"))
? ? cld(lsm.TCFd.gen, Letters=letters)
# ?generation lsmean ? ? SE ?df lower.CL upper.CL .group
# ?G3 ? ? ? ? ? 3.23 0.0159 128 ? ? 3.20 ? ? 3.26 ?a ? ?
# ?G1 ? ? ? ? ? 3.27 0.0198 128 ? ? 3.23 ? ? 3.31 ?ab ? 
# ?G0 ? ? ? ? ? 3.27 0.0135 128 ? ? 3.25 ? ? 3.30 ?ab ? 
# ?G4 ? ? ? ? ? 3.29 0.0217 128 ? ? 3.25 ? ? 3.34 ?ab ? 
# ?G2 ? ? ? ? ? 3.31 0.0141 128 ? ? 3.28 ? ? 3.34 ? b ? 
? ? 3) For temp:generation interaction:
? ? ds$temp_gen <- paste0(ds$temp,"_",ds$generation)
? ? mTCFd.int <- glmmTMB(development ~ temp_gen + (1 | generation), data = ds,
? ? ? ? ? ? ? ? ? ?family = ziGamma(link = "log")) 
? ? lsm.TCFd.temp.gen <- lsmeans(mTCFd.int, c("temp_gen"))
? ? cld(lsm.TCFd.temp.gen, Letters=letters)
# ?temp_gen ? ? lsmean ? ? SE ?df lower.CL upper.CL .group 
# ?constante_G3 ? 3.13 0.0180 128 ? ? 3.09 ? ? 3.16 ?a ? ? 
# ?constante_G2 ? 3.14 0.0180 128 ? ? 3.11 ? ? 3.18 ?ab ? ?
# ?constante_G0 ? 3.19 0.0191 128 ? ? 3.15 ? ? 3.23 ?abc ? 
# ?constante_G1 ? 3.22 0.0180 128 ? ? 3.18 ? ? 3.25 ? bc ? 
# ?constante_G4 ? 3.23 0.0185 128 ? ? 3.19 ? ? 3.27 ? ?cd ?
# ?flutuante_G1 ? 3.32 0.0352 128 ? ? 3.25 ? ? 3.39 ? ?cde 
# ?flutuante_G3 ? 3.34 0.0262 128 ? ? 3.28 ? ? 3.39 ? ? ?e 
# ?flutuante_G0 ? 3.36 0.0191 128 ? ? 3.32 ? ? 3.39 ? ? ?e 
# ?flutuante_G4 ? 3.36 0.0393 128 ? ? 3.28 ? ? 3.44 ? ? def
# ?flutuante_G2 ? 3.47 0.0218 128 ? ? 3.43 ? ? 3.52 ? ? ? f


Ok, it works, but I'd like to know if is possible for the pairwise comparison
directly with the final model (`mTCFd`) without a new interaction model adjustment (`mTCFd.int`).
This is because different models have different parameters and I'm interesting in the `mTCFd` adjustment.


Please, any help with it?


From jh@|t|g@ @end|ng |rom gm@||@com  Thu Jul 28 01:11:52 2022
From: jh@|t|g@ @end|ng |rom gm@||@com (J.D. Haltigan)
Date: Wed, 27 Jul 2022 19:11:52 -0400
Subject: [R-sig-ME] Cluster-robust SEs & random effects -- seeking some
 clarification
In-Reply-To: <CAH_7VO=pDmKDbpy8CfOTewcqXvwcfa1CRyRoohcRbQ=zz5ayOQ@mail.gmail.com>
References: <CAH_7VOkx8+Pwpx+Rovgm0=k2Nde3TvmJpAQ_28O_NjQTY82h4g@mail.gmail.com>
 <CAFUVuJyh56KYctgrB1TSn8JB01h+Lh93Oh--dPvOK616b=x3LQ@mail.gmail.com>
 <CAH_7VO=aOOhT8TWJ7rAfY4EC+8yOepLpkpg0TcXgjN+wwk2c=w@mail.gmail.com>
 <CAFUVuJztqcXppr8VSDUXWYmTtcyDk+TVXDc3WPNkfcPJNRmaGA@mail.gmail.com>
 <CAH_7VO=pDmKDbpy8CfOTewcqXvwcfa1CRyRoohcRbQ=zz5ayOQ@mail.gmail.com>
Message-ID: <CAH_7VOmbxTp=TrK9r6PpvZ=PXxoSmFqGDxGCUWdOROLSxNaCcg@mail.gmail.com>

>
> Thanks for walking through this with me, James.
>
> I appreciate it. So: the goal of the current project I am involved in is
> to make some conceptual arguments in the context of Generalizability Theory
> about the Bangladesh mask RCT study (you may have heard of the study, here
> is the DOI link: https://www.science.org/doi/10.1126/science.abi9069).
>
> 600 villages (300/300)
>
> the 'pairID' variable is a control the authors used to control for fixed
> effects of treatment-control pair (so, we have 300 pairIDs in total). In
> the original investigation, the authors did not invoke a random effects
> model (but did use the pairIDs to control for fixed effects as noted and
> with robust SEs). Thus, in the original investigation there was *no*
> specification of a random effects model for the 'cluster' variable. We know
> from some other work there were some biases in village mapping and other
> possible sources of between-cluster variation that might be anticipated to
> have influence--at the random intercepts level--so we are looking into how
> specifying 'cluster' as a random effect might change the fixed effects
> estimates for the treatment intervention effect. In the Hamaker et al.
> language, it is indeed a 'random intercepts' only model. Given this,
> however, does it also make sense to include the cluster robust SEs for the
> fixed effects which would account for possible heterogeneity of treatment
> effects (i.e., slopes) across clusters?s
>
> Bottom line: in their original analyses, clusters are seen as
> interchangeable from a conceptual perspective (rather than drawn from a
> random universe of observations). When one scales up evidence to a universe
> of observations that are random (as they would be in the intended universe
> of inference in the real-world), then we are better positioned, I think, to
> adjudicate whether the mask intervention effect is 'practically
> significant' (in addition to whether the focal effect remains marginally
> significant from a frequentist perspective).
>
> Hope this is somewhat clarifying.
>
>
> On Wed, Jul 27, 2022 at 12:05 PM James Pustejovsky <jepusto at gmail.com>
> wrote:
>
>> Hi J.D.,
>>
>> Responses inline below.
>>
>> James
>>
>> On Tue, Jul 26, 2022 at 10:42 PM J.D. Haltigan <jhaltiga at gmail.com>
>> wrote:
>>
>>> Many thanks for this detailed and insightful exposition, James.
>>>
>>> A few follow-ups:
>>>
>>> I had previously tried cluster-robust SEs with both the robustlmm package
>>> and now yours, and it appears I don't have the memory needed given the
>>> size
>>> of the data as I receive the following error:
>>> #Error in .local(x, y, ...) :
>>> #Cholmod error 'problem too large' at file ../Core/cholmod_sparse.c,
>>> line 89
>>> In Googling this error message, I see it is likely due to the
>>> computational
>>> demands of a sparse matrix estimation, but was wondering if there were
>>> any
>>> other aspects of this I could explore.
>>>
>>>
>> To figure out what's going on, we need to know the dimensions of your
>> model. How many coefficients (fixed effects) are in your regression
>> specification? How many clusters do you have? What is the range of cluster
>> sizes?
>>
>>
>>> In regards to #4: I am invoking random effects to see how sensitive a
>>> fixed
>>> effects model (with cluster robust SEs) is to formally estimating the
>>> random cluster effect (so between-cluster variance). In the fixed effects
>>> model, the investigators did include a factor variable (i.e., cluster
>>> dummies as you describe below) that is nested within cluster (so, a pair
>>> variable indicating treatment-control village), but my predilection is
>>> that
>>> despite this, there are other sources of between-cluster variance that
>>> will
>>> likely nullify the point estimates of the fixed effects (in this case, a
>>> mask intervention).
>>
>>
>> I'm not sure what you mean by "other sources of between-cluster variance
>> that will likely nullify the point estimates of the fixed effects." Can you
>> explain in a bit more detail?
>>
>>
>>> So, if I am formally modeling the random cluster
>>> component, what does adding cluster-robust SEs in this case provide in
>>> terms of inference--both for the fixed effects and for the random
>>> effects?
>>>
>>
>> Cluster-robust SEs are only relevant for inference on the regression
>> coefficients (fixed effects)--not for the random effects. For the fixed
>> effects, using cluster-robust SEs provides robustness to misspecification
>> of the random effects model, such as omission of a random slope that should
>> be there. In the context of your example, there might be heterogeneity of
>> intervention effects across pairs of villages. A random effects model that
>> only includes random intercepts for each village will not "catch" this sort
>> of treatment effect heterogeneity, and model-based SEs could be invalidated
>> by it. Cluster-robust SEs will account for that sort of heterogeneity (and
>> be larger than the model-based SEs as a consequence).
>>
>

	[[alternative HTML version deleted]]


From jepu@to @end|ng |rom gm@||@com  Sat Jul 30 21:01:46 2022
From: jepu@to @end|ng |rom gm@||@com (James Pustejovsky)
Date: Sat, 30 Jul 2022 14:01:46 -0500
Subject: [R-sig-ME] Cluster-robust SEs & random effects -- seeking some
 clarification
In-Reply-To: <CAH_7VO=pDmKDbpy8CfOTewcqXvwcfa1CRyRoohcRbQ=zz5ayOQ@mail.gmail.com>
References: <CAH_7VOkx8+Pwpx+Rovgm0=k2Nde3TvmJpAQ_28O_NjQTY82h4g@mail.gmail.com>
 <CAFUVuJyh56KYctgrB1TSn8JB01h+Lh93Oh--dPvOK616b=x3LQ@mail.gmail.com>
 <CAH_7VO=aOOhT8TWJ7rAfY4EC+8yOepLpkpg0TcXgjN+wwk2c=w@mail.gmail.com>
 <CAFUVuJztqcXppr8VSDUXWYmTtcyDk+TVXDc3WPNkfcPJNRmaGA@mail.gmail.com>
 <CAH_7VO=pDmKDbpy8CfOTewcqXvwcfa1CRyRoohcRbQ=zz5ayOQ@mail.gmail.com>
Message-ID: <CAFUVuJzXv6Ggz9iSMm6ehUVeNSFY3t-mn=jh7QqTiDuUBmzDCg@mail.gmail.com>

Hi J.D.,
A few comments/reactions inline below.
James

On Wed, Jul 27, 2022 at 5:37 PM J.D. Haltigan <jhaltiga at gmail.com> wrote:

> ...
>
In the original investigation, the authors did not invoke a random effects
> model (but did use the pairIDs to control for fixed effects as noted and
> with robust SEs). Thus, in the original investigation there was *no*
> specification of a random effects model for the 'cluster' variable. We know
> from some other work there were some biases in village mapping and other
> possible sources of between-cluster variation that might be anticipated to
> have influence--at the random intercepts level--so we are looking into how
> specifying 'cluster' as a random effect might change the fixed effects
> estimates for the treatment intervention effect. In the Hamaker et al.
> language, it is indeed a 'random intercepts' only model.
>

I don't follow how using a random intercepts model improves the
generalizability warrant here. The random intercepts model is essentially
just a re-weighted average of the pair-specific effects in the original
analysis, where the weights are optimally efficient if the model is
correctly specified. That last clause carries a lot of weight here--correct
specification means 1) treatment assignment is unrelated to the random
effects, 2) the treatment effect is constant across clusters, 3)
distributional assumptions are valid (i.e., homoskedasticity at each level
of the model).

If the effects are heterogeneous, then I would think that including random
slopes on the treatment indicator would provide a better basis for
generalization. But even then, the warrant is still pretty vague---what is
the hypothetical population of villages from which the observed villages
are sampled?


> Given this, however, does it also make sense to include the cluster robust
> SEs for the fixed effects which would account for possible heterogeneity of
> treatment effects (i.e., slopes) across clusters?s
>
> If you're committed to the random intercepts model, then yes I think so
because using cluster robust SEs at least acknowledges the possibility of
heterogeneous treatment effects.


> Bottom line: in their original analyses, clusters are seen as
> interchangeable from a conceptual perspective (rather than drawn from a
> random universe of observations). When one scales up evidence to a universe
> of observations that are random (as they would be in the intended universe
> of inference in the real-world), then we are better positioned, I think, to
> adjudicate whether the mask intervention effect is 'practically
> significant' (in addition to whether the focal effect remains marginally
> significant from a frequentist perspective).
>
As noted above, this argument is a bit vague to me. If there's concern
about generalizability, then my first question would be: what is the target
population to which you are trying to generalize?

	[[alternative HTML version deleted]]


From jh@|t|g@ @end|ng |rom gm@||@com  Sat Jul 30 23:25:12 2022
From: jh@|t|g@ @end|ng |rom gm@||@com (J.D. Haltigan)
Date: Sat, 30 Jul 2022 17:25:12 -0400
Subject: [R-sig-ME] Cluster-robust SEs & random effects -- seeking some
 clarification
In-Reply-To: <CAFUVuJzXv6Ggz9iSMm6ehUVeNSFY3t-mn=jh7QqTiDuUBmzDCg@mail.gmail.com>
References: <CAH_7VOkx8+Pwpx+Rovgm0=k2Nde3TvmJpAQ_28O_NjQTY82h4g@mail.gmail.com>
 <CAFUVuJyh56KYctgrB1TSn8JB01h+Lh93Oh--dPvOK616b=x3LQ@mail.gmail.com>
 <CAH_7VO=aOOhT8TWJ7rAfY4EC+8yOepLpkpg0TcXgjN+wwk2c=w@mail.gmail.com>
 <CAFUVuJztqcXppr8VSDUXWYmTtcyDk+TVXDc3WPNkfcPJNRmaGA@mail.gmail.com>
 <CAH_7VO=pDmKDbpy8CfOTewcqXvwcfa1CRyRoohcRbQ=zz5ayOQ@mail.gmail.com>
 <CAFUVuJzXv6Ggz9iSMm6ehUVeNSFY3t-mn=jh7QqTiDuUBmzDCg@mail.gmail.com>
Message-ID: <CAH_7VOnDW0Y7vXUZfChaM_JRgRg6c9uXs6+RzHt886fxo4AsUw@mail.gmail.com>

This is a very helpful walkthrough, James. My responses are italicized
under yours to maintain thread readability. The key is Generalizability
here and (as I also note in my last reply) the idea is to Generalize to a
universe of "any villages or clusters." That is, the target population we
are generalizing to is *any* random population.

On Sat, Jul 30, 2022 at 3:01 PM James Pustejovsky <jepusto at gmail.com> wrote:

> Hi J.D.,
> A few comments/reactions inline below.
> James
>
> On Wed, Jul 27, 2022 at 5:37 PM J.D. Haltigan <jhaltiga at gmail.com> wrote:
>
>> ...
>>
> In the original investigation, the authors did not invoke a random effects
>> model (but did use the pairIDs to control for fixed effects as noted and
>> with robust SEs). Thus, in the original investigation there was *no*
>> specification of a random effects model for the 'cluster' variable. We know
>> from some other work there were some biases in village mapping and other
>> possible sources of between-cluster variation that might be anticipated to
>> have influence--at the random intercepts level--so we are looking into how
>> specifying 'cluster' as a random effect might change the fixed effects
>> estimates for the treatment intervention effect. In the Hamaker et al.
>> language, it is indeed a 'random intercepts' only model.
>>
>
> I don't follow how using a random intercepts model improves the
> generalizability warrant here. The random intercepts model is essentially
> just a re-weighted average of the pair-specific effects in the original
> analysis, where the weights are optimally efficient if the model is
> correctly specified. That last clause carries a lot of weight here--correct
> specification means 1) treatment assignment is unrelated to the random
> effects, 2) the treatment effect is constant across clusters, 3)
> distributional assumptions are valid (i.e., homoskedasticity at each level
> of the model).
>
> If the effects are heterogeneous, then I would think that including random
> slopes on the treatment indicator would provide a better basis for
> generalization. But even then, the warrant is still pretty vague---what is
> the hypothetical population of villages from which the observed villages
> are sampled?
>

*In the most basic model (without baseline controls) the model takes the
form: myModel = lmer(posXsymp~treatment + pairID + (1 | union), data =
myData). I believe--correct me if I am wrong--that this reflects a
random-intercepts only model, but I may be mistaken. If I am, and this is
allowing for random slopes on the treatment indicator, then I will need to
rethink my statements.  *

>
>
>> Given this, however, does it also make sense to include the cluster
>> robust SEs for the fixed effects which would account for possible
>> heterogeneity of treatment effects (i.e., slopes) across clusters?s
>>
>> If you're committed to the random intercepts model, then yes I think so
> because using cluster robust SEs at least acknowledges the possibility of
> heterogeneous treatment effects.
>

*If the above model does allow for both random intercepts and slopes, then
perhaps the use of cluster robust SEs is redundant in some sense since the
random slopes would be modeling the heterogeneity in treatment effects?*

>
>
>
>> Bottom line: in their original analyses, clusters are seen as
>> interchangeable from a conceptual perspective (rather than drawn from a
>> random universe of observations). When one scales up evidence to a universe
>> of observations that are random (as they would be in the intended universe
>> of inference in the real-world), then we are better positioned, I think, to
>> adjudicate whether the mask intervention effect is 'practically
>> significant' (in addition to whether the focal effect remains marginally
>> significant from a frequentist perspective).
>>
> As noted above, this argument is a bit vague to me. If there's concern
> about generalizability, then my first question would be: what is the target
> population to which you are trying to generalize?
>

*Essentially, the target population we are trying to generalize to is a
random selection of villages. Any random selection of villages. In other
words, villages should not be seen as interchangeable. We are interested in
whether the effects generalize to any randomly selected village. *

>
>

	[[alternative HTML version deleted]]


From jh@|t|g@ @end|ng |rom gm@||@com  Sun Jul 31 01:43:04 2022
From: jh@|t|g@ @end|ng |rom gm@||@com (J.D. Haltigan)
Date: Sat, 30 Jul 2022 19:43:04 -0400
Subject: [R-sig-ME] Cluster-robust SEs & random effects -- seeking some
 clarification
In-Reply-To: <CAH_7VOnDW0Y7vXUZfChaM_JRgRg6c9uXs6+RzHt886fxo4AsUw@mail.gmail.com>
References: <CAH_7VOkx8+Pwpx+Rovgm0=k2Nde3TvmJpAQ_28O_NjQTY82h4g@mail.gmail.com>
 <CAFUVuJyh56KYctgrB1TSn8JB01h+Lh93Oh--dPvOK616b=x3LQ@mail.gmail.com>
 <CAH_7VO=aOOhT8TWJ7rAfY4EC+8yOepLpkpg0TcXgjN+wwk2c=w@mail.gmail.com>
 <CAFUVuJztqcXppr8VSDUXWYmTtcyDk+TVXDc3WPNkfcPJNRmaGA@mail.gmail.com>
 <CAH_7VO=pDmKDbpy8CfOTewcqXvwcfa1CRyRoohcRbQ=zz5ayOQ@mail.gmail.com>
 <CAFUVuJzXv6Ggz9iSMm6ehUVeNSFY3t-mn=jh7QqTiDuUBmzDCg@mail.gmail.com>
 <CAH_7VOnDW0Y7vXUZfChaM_JRgRg6c9uXs6+RzHt886fxo4AsUw@mail.gmail.com>
Message-ID: <CAH_7VOmxzQcF7nNcDC42AeSZGFNdMO0O98zb9AroxPz51zHR1Q@mail.gmail.com>

Addendum:

It just occurred to me on my walk that I think I am getting a bit lost in
some of the differences in nomenclature across scientific silos. In the
original model that they specified, which treated the 'pairID' variable as
a control variable for which they controlled for 'fixed effects' of
control/treatment villages (in their own language in the paper) using
cluster-robust SEs, I think this is indeed a 'random-intercepts only' model
in the language of Hamaker et al. They implement the 'absorb' command in
STATA which I believe aggregates across the pairIDs to generate an
'omnibus' F-test of sorts for the pairID variable (in the ANOVA
nomenclature). I say this as when I specify the pairID variable in the lmer
model I shared (or in a fixest model I conducted to replicate the original
Abalauck results in R), I get the estimates for all the pairs (i.e., there
is no way to aggregate across them--though I think formally the models are
the same if we are unconcerned about any one pairID [treatment/control
village pair].

So, in the lmer model I shared where I specify a specific random effects
term for the 'cluster' variable, I think this indeed is allowing for random
slopes across the clusters which implies the treatment effect may vary
across the clusters (and we might anticipate it will for various reasons I
can elaborate on). More generally: we are generalizing to *any* universe of
villages (say in the entire world) where the treatment intervention (masks)
may vary across villages. This is the crux of invoking the random effects
model (i.e., random slopes model).

I realize this is a mouthful, but I think the way these terms (e.g.,
random/fixed effects models etc.) are used across disciplines makes things
a bit confusing.

On Sat, Jul 30, 2022 at 5:25 PM J.D. Haltigan <jhaltiga at gmail.com> wrote:

> This is a very helpful walkthrough, James. My responses are italicized
> under yours to maintain thread readability. The key is Generalizability
> here and (as I also note in my last reply) the idea is to Generalize to a
> universe of "any villages or clusters." That is, the target population we
> are generalizing to is *any* random population.
>
> On Sat, Jul 30, 2022 at 3:01 PM James Pustejovsky <jepusto at gmail.com>
> wrote:
>
>> Hi J.D.,
>> A few comments/reactions inline below.
>> James
>>
>> On Wed, Jul 27, 2022 at 5:37 PM J.D. Haltigan <jhaltiga at gmail.com> wrote:
>>
>>> ...
>>>
>> In the original investigation, the authors did not invoke a random
>>> effects model (but did use the pairIDs to control for fixed effects as
>>> noted and with robust SEs). Thus, in the original investigation there was
>>> *no* specification of a random effects model for the 'cluster' variable. We
>>> know from some other work there were some biases in village mapping and
>>> other possible sources of between-cluster variation that might be
>>> anticipated to have influence--at the random intercepts level--so we are
>>> looking into how specifying 'cluster' as a random effect might change the
>>> fixed effects estimates for the treatment intervention effect. In the
>>> Hamaker et al. language, it is indeed a 'random intercepts' only model.
>>>
>>
>> I don't follow how using a random intercepts model improves the
>> generalizability warrant here. The random intercepts model is essentially
>> just a re-weighted average of the pair-specific effects in the original
>> analysis, where the weights are optimally efficient if the model is
>> correctly specified. That last clause carries a lot of weight here--correct
>> specification means 1) treatment assignment is unrelated to the random
>> effects, 2) the treatment effect is constant across clusters, 3)
>> distributional assumptions are valid (i.e., homoskedasticity at each level
>> of the model).
>>
>> If the effects are heterogeneous, then I would think that including
>> random slopes on the treatment indicator would provide a better basis for
>> generalization. But even then, the warrant is still pretty vague---what is
>> the hypothetical population of villages from which the observed villages
>> are sampled?
>>
>
> *In the most basic model (without baseline controls) the model takes the
> form: myModel = lmer(posXsymp~treatment + pairID + (1 | union), data =
> myData). I believe--correct me if I am wrong--that this reflects a
> random-intercepts only model, but I may be mistaken. If I am, and this is
> allowing for random slopes on the treatment indicator, then I will need to
> rethink my statements.  *
>
>>
>>
>>> Given this, however, does it also make sense to include the cluster
>>> robust SEs for the fixed effects which would account for possible
>>> heterogeneity of treatment effects (i.e., slopes) across clusters?s
>>>
>>> If you're committed to the random intercepts model, then yes I think so
>> because using cluster robust SEs at least acknowledges the possibility of
>> heterogeneous treatment effects.
>>
>
> *If the above model does allow for both random intercepts and slopes, then
> perhaps the use of cluster robust SEs is redundant in some sense since the
> random slopes would be modeling the heterogeneity in treatment effects?*
>
>>
>>
>>
>>> Bottom line: in their original analyses, clusters are seen as
>>> interchangeable from a conceptual perspective (rather than drawn from a
>>> random universe of observations). When one scales up evidence to a universe
>>> of observations that are random (as they would be in the intended universe
>>> of inference in the real-world), then we are better positioned, I think, to
>>> adjudicate whether the mask intervention effect is 'practically
>>> significant' (in addition to whether the focal effect remains marginally
>>> significant from a frequentist perspective).
>>>
>> As noted above, this argument is a bit vague to me. If there's concern
>> about generalizability, then my first question would be: what is the target
>> population to which you are trying to generalize?
>>
>
> *Essentially, the target population we are trying to generalize to is a
> random selection of villages. Any random selection of villages. In other
> words, villages should not be seen as interchangeable. We are interested in
> whether the effects generalize to any randomly selected village. *
>
>>
>>
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Sun Jul 31 01:48:35 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sat, 30 Jul 2022 19:48:35 -0400
Subject: [R-sig-ME] Cluster-robust SEs & random effects -- seeking some
 clarification
In-Reply-To: <CAH_7VOmxzQcF7nNcDC42AeSZGFNdMO0O98zb9AroxPz51zHR1Q@mail.gmail.com>
References: <CAH_7VOkx8+Pwpx+Rovgm0=k2Nde3TvmJpAQ_28O_NjQTY82h4g@mail.gmail.com>
 <CAFUVuJyh56KYctgrB1TSn8JB01h+Lh93Oh--dPvOK616b=x3LQ@mail.gmail.com>
 <CAH_7VO=aOOhT8TWJ7rAfY4EC+8yOepLpkpg0TcXgjN+wwk2c=w@mail.gmail.com>
 <CAFUVuJztqcXppr8VSDUXWYmTtcyDk+TVXDc3WPNkfcPJNRmaGA@mail.gmail.com>
 <CAH_7VO=pDmKDbpy8CfOTewcqXvwcfa1CRyRoohcRbQ=zz5ayOQ@mail.gmail.com>
 <CAFUVuJzXv6Ggz9iSMm6ehUVeNSFY3t-mn=jh7QqTiDuUBmzDCg@mail.gmail.com>
 <CAH_7VOnDW0Y7vXUZfChaM_JRgRg6c9uXs6+RzHt886fxo4AsUw@mail.gmail.com>
 <CAH_7VOmxzQcF7nNcDC42AeSZGFNdMO0O98zb9AroxPz51zHR1Q@mail.gmail.com>
Message-ID: <883b38be-eeb7-8052-4395-618484a5ef97@gmail.com>

I haven't been following the whole thread that carefully, but I want to 
emphasize that

   posXsymp~treatment + pairID + (1 | union)

is *not*, by any definition I'm familiar with, a "random-slopes model"; 
that is, it only estimates a single population-level treatment 
effect/doesn't allow the effect of treatment to vary across groups 
defined by 'union'.  You would need a random-effect term of the form 
(treatment | union).

   Reasons why you might *not* want to do this:

  * if treatment only varies across and not within levels of union 
("union is nested within treatment" according to some terminology), then 
this variation is unidentifiable
  * maybe you have decided that you don't have enough data/want a more 
parsimonious model.

   Schielzeth and Forstmeier, among many others (this is the example I 
know of), have cautioned about the consequences of leaving out 
random-slopes terms.

Schielzeth, Holger, and Wolfgang Forstmeier. ?Conclusions beyond 
Support: Overconfident Estimates in Mixed Models.? Behavioral Ecology 
20, no. 2 (March 1, 2009): 416?20. https://doi.org/10.1093/beheco/arn145.


On 2022-07-30 7:43 p.m., J.D. Haltigan wrote:
> Addendum:
> 
> It just occurred to me on my walk that I think I am getting a bit lost in
> some of the differences in nomenclature across scientific silos. In the
> original model that they specified, which treated the 'pairID' variable as
> a control variable for which they controlled for 'fixed effects' of
> control/treatment villages (in their own language in the paper) using
> cluster-robust SEs, I think this is indeed a 'random-intercepts only' model
> in the language of Hamaker et al. They implement the 'absorb' command in
> STATA which I believe aggregates across the pairIDs to generate an
> 'omnibus' F-test of sorts for the pairID variable (in the ANOVA
> nomenclature). I say this as when I specify the pairID variable in the lmer
> model I shared (or in a fixest model I conducted to replicate the original
> Abalauck results in R), I get the estimates for all the pairs (i.e., there
> is no way to aggregate across them--though I think formally the models are
> the same if we are unconcerned about any one pairID [treatment/control
> village pair].
> 
> So, in the lmer model I shared where I specify a specific random effects
> term for the 'cluster' variable, I think this indeed is allowing for random
> slopes across the clusters which implies the treatment effect may vary
> across the clusters (and we might anticipate it will for various reasons I
> can elaborate on). More generally: we are generalizing to *any* universe of
> villages (say in the entire world) where the treatment intervention (masks)
> may vary across villages. This is the crux of invoking the random effects
> model (i.e., random slopes model).
> 
> I realize this is a mouthful, but I think the way these terms (e.g.,
> random/fixed effects models etc.) are used across disciplines makes things
> a bit confusing.
> 
> On Sat, Jul 30, 2022 at 5:25 PM J.D. Haltigan <jhaltiga at gmail.com> wrote:
> 
>> This is a very helpful walkthrough, James. My responses are italicized
>> under yours to maintain thread readability. The key is Generalizability
>> here and (as I also note in my last reply) the idea is to Generalize to a
>> universe of "any villages or clusters." That is, the target population we
>> are generalizing to is *any* random population.
>>
>> On Sat, Jul 30, 2022 at 3:01 PM James Pustejovsky <jepusto at gmail.com>
>> wrote:
>>
>>> Hi J.D.,
>>> A few comments/reactions inline below.
>>> James
>>>
>>> On Wed, Jul 27, 2022 at 5:37 PM J.D. Haltigan <jhaltiga at gmail.com> wrote:
>>>
>>>> ...
>>>>
>>> In the original investigation, the authors did not invoke a random
>>>> effects model (but did use the pairIDs to control for fixed effects as
>>>> noted and with robust SEs). Thus, in the original investigation there was
>>>> *no* specification of a random effects model for the 'cluster' variable. We
>>>> know from some other work there were some biases in village mapping and
>>>> other possible sources of between-cluster variation that might be
>>>> anticipated to have influence--at the random intercepts level--so we are
>>>> looking into how specifying 'cluster' as a random effect might change the
>>>> fixed effects estimates for the treatment intervention effect. In the
>>>> Hamaker et al. language, it is indeed a 'random intercepts' only model.
>>>>
>>>
>>> I don't follow how using a random intercepts model improves the
>>> generalizability warrant here. The random intercepts model is essentially
>>> just a re-weighted average of the pair-specific effects in the original
>>> analysis, where the weights are optimally efficient if the model is
>>> correctly specified. That last clause carries a lot of weight here--correct
>>> specification means 1) treatment assignment is unrelated to the random
>>> effects, 2) the treatment effect is constant across clusters, 3)
>>> distributional assumptions are valid (i.e., homoskedasticity at each level
>>> of the model).
>>>
>>> If the effects are heterogeneous, then I would think that including
>>> random slopes on the treatment indicator would provide a better basis for
>>> generalization. But even then, the warrant is still pretty vague---what is
>>> the hypothetical population of villages from which the observed villages
>>> are sampled?
>>>
>>
>> *In the most basic model (without baseline controls) the model takes the
>> form: myModel = lmer(posXsymp~treatment + pairID + (1 | union), data =
>> myData). I believe--correct me if I am wrong--that this reflects a
>> random-intercepts only model, but I may be mistaken. If I am, and this is
>> allowing for random slopes on the treatment indicator, then I will need to
>> rethink my statements.  *
>>
>>>
>>>
>>>> Given this, however, does it also make sense to include the cluster
>>>> robust SEs for the fixed effects which would account for possible
>>>> heterogeneity of treatment effects (i.e., slopes) across clusters?s
>>>>
>>>> If you're committed to the random intercepts model, then yes I think so
>>> because using cluster robust SEs at least acknowledges the possibility of
>>> heterogeneous treatment effects.
>>>
>>
>> *If the above model does allow for both random intercepts and slopes, then
>> perhaps the use of cluster robust SEs is redundant in some sense since the
>> random slopes would be modeling the heterogeneity in treatment effects?*
>>
>>>
>>>
>>>
>>>> Bottom line: in their original analyses, clusters are seen as
>>>> interchangeable from a conceptual perspective (rather than drawn from a
>>>> random universe of observations). When one scales up evidence to a universe
>>>> of observations that are random (as they would be in the intended universe
>>>> of inference in the real-world), then we are better positioned, I think, to
>>>> adjudicate whether the mask intervention effect is 'practically
>>>> significant' (in addition to whether the focal effect remains marginally
>>>> significant from a frequentist perspective).
>>>>
>>> As noted above, this argument is a bit vague to me. If there's concern
>>> about generalizability, then my first question would be: what is the target
>>> population to which you are trying to generalize?
>>>
>>
>> *Essentially, the target population we are trying to generalize to is a
>> random selection of villages. Any random selection of villages. In other
>> words, villages should not be seen as interchangeable. We are interested in
>> whether the effects generalize to any randomly selected village. *
>>
>>>
>>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics


From jh@|t|g@ @end|ng |rom gm@||@com  Sun Jul 31 02:12:41 2022
From: jh@|t|g@ @end|ng |rom gm@||@com (J.D. Haltigan)
Date: Sat, 30 Jul 2022 20:12:41 -0400
Subject: [R-sig-ME] Cluster-robust SEs & random effects -- seeking some
 clarification
In-Reply-To: <883b38be-eeb7-8052-4395-618484a5ef97@gmail.com>
References: <CAH_7VOkx8+Pwpx+Rovgm0=k2Nde3TvmJpAQ_28O_NjQTY82h4g@mail.gmail.com>
 <CAFUVuJyh56KYctgrB1TSn8JB01h+Lh93Oh--dPvOK616b=x3LQ@mail.gmail.com>
 <CAH_7VO=aOOhT8TWJ7rAfY4EC+8yOepLpkpg0TcXgjN+wwk2c=w@mail.gmail.com>
 <CAFUVuJztqcXppr8VSDUXWYmTtcyDk+TVXDc3WPNkfcPJNRmaGA@mail.gmail.com>
 <CAH_7VO=pDmKDbpy8CfOTewcqXvwcfa1CRyRoohcRbQ=zz5ayOQ@mail.gmail.com>
 <CAFUVuJzXv6Ggz9iSMm6ehUVeNSFY3t-mn=jh7QqTiDuUBmzDCg@mail.gmail.com>
 <CAH_7VOnDW0Y7vXUZfChaM_JRgRg6c9uXs6+RzHt886fxo4AsUw@mail.gmail.com>
 <CAH_7VOmxzQcF7nNcDC42AeSZGFNdMO0O98zb9AroxPz51zHR1Q@mail.gmail.com>
 <883b38be-eeb7-8052-4395-618484a5ef97@gmail.com>
Message-ID: <CAH_7VOnnkY2ee1QXVbZ+VzNLJg2bZVPjdKpVqkGoc=ZyKj635Q@mail.gmail.com>

Thanks, Ben. So in the model you remarked on, would that be a
'random-intercepts only' model?


On Sat, Jul 30, 2022 at 7:53 PM Ben Bolker <bbolker at gmail.com> wrote:

> I haven't been following the whole thread that carefully, but I want to
> emphasize that
>
>    posXsymp~treatment + pairID + (1 | union)
>
> is *not*, by any definition I'm familiar with, a "random-slopes model";
> that is, it only estimates a single population-level treatment
> effect/doesn't allow the effect of treatment to vary across groups
> defined by 'union'.  You would need a random-effect term of the form
> (treatment | union).
>
>    Reasons why you might *not* want to do this:
>
>   * if treatment only varies across and not within levels of union
> ("union is nested within treatment" according to some terminology), then
> this variation is unidentifiable
>   * maybe you have decided that you don't have enough data/want a more
> parsimonious model.
>
>    Schielzeth and Forstmeier, among many others (this is the example I
> know of), have cautioned about the consequences of leaving out
> random-slopes terms.
>
> Schielzeth, Holger, and Wolfgang Forstmeier. ?Conclusions beyond
> Support: Overconfident Estimates in Mixed Models.? Behavioral Ecology
> 20, no. 2 (March 1, 2009): 416?20. https://doi.org/10.1093/beheco/arn145.
>
>
> On 2022-07-30 7:43 p.m., J.D. Haltigan wrote:
> > Addendum:
> >
> > It just occurred to me on my walk that I think I am getting a bit lost in
> > some of the differences in nomenclature across scientific silos. In the
> > original model that they specified, which treated the 'pairID' variable
> as
> > a control variable for which they controlled for 'fixed effects' of
> > control/treatment villages (in their own language in the paper) using
> > cluster-robust SEs, I think this is indeed a 'random-intercepts only'
> model
> > in the language of Hamaker et al. They implement the 'absorb' command in
> > STATA which I believe aggregates across the pairIDs to generate an
> > 'omnibus' F-test of sorts for the pairID variable (in the ANOVA
> > nomenclature). I say this as when I specify the pairID variable in the
> lmer
> > model I shared (or in a fixest model I conducted to replicate the
> original
> > Abalauck results in R), I get the estimates for all the pairs (i.e.,
> there
> > is no way to aggregate across them--though I think formally the models
> are
> > the same if we are unconcerned about any one pairID [treatment/control
> > village pair].
> >
> > So, in the lmer model I shared where I specify a specific random effects
> > term for the 'cluster' variable, I think this indeed is allowing for
> random
> > slopes across the clusters which implies the treatment effect may vary
> > across the clusters (and we might anticipate it will for various reasons
> I
> > can elaborate on). More generally: we are generalizing to *any* universe
> of
> > villages (say in the entire world) where the treatment intervention
> (masks)
> > may vary across villages. This is the crux of invoking the random effects
> > model (i.e., random slopes model).
> >
> > I realize this is a mouthful, but I think the way these terms (e.g.,
> > random/fixed effects models etc.) are used across disciplines makes
> things
> > a bit confusing.
> >
> > On Sat, Jul 30, 2022 at 5:25 PM J.D. Haltigan <jhaltiga at gmail.com>
> wrote:
> >
> >> This is a very helpful walkthrough, James. My responses are italicized
> >> under yours to maintain thread readability. The key is Generalizability
> >> here and (as I also note in my last reply) the idea is to Generalize to
> a
> >> universe of "any villages or clusters." That is, the target population
> we
> >> are generalizing to is *any* random population.
> >>
> >> On Sat, Jul 30, 2022 at 3:01 PM James Pustejovsky <jepusto at gmail.com>
> >> wrote:
> >>
> >>> Hi J.D.,
> >>> A few comments/reactions inline below.
> >>> James
> >>>
> >>> On Wed, Jul 27, 2022 at 5:37 PM J.D. Haltigan <jhaltiga at gmail.com>
> wrote:
> >>>
> >>>> ...
> >>>>
> >>> In the original investigation, the authors did not invoke a random
> >>>> effects model (but did use the pairIDs to control for fixed effects as
> >>>> noted and with robust SEs). Thus, in the original investigation there
> was
> >>>> *no* specification of a random effects model for the 'cluster'
> variable. We
> >>>> know from some other work there were some biases in village mapping
> and
> >>>> other possible sources of between-cluster variation that might be
> >>>> anticipated to have influence--at the random intercepts level--so we
> are
> >>>> looking into how specifying 'cluster' as a random effect might change
> the
> >>>> fixed effects estimates for the treatment intervention effect. In the
> >>>> Hamaker et al. language, it is indeed a 'random intercepts' only
> model.
> >>>>
> >>>
> >>> I don't follow how using a random intercepts model improves the
> >>> generalizability warrant here. The random intercepts model is
> essentially
> >>> just a re-weighted average of the pair-specific effects in the original
> >>> analysis, where the weights are optimally efficient if the model is
> >>> correctly specified. That last clause carries a lot of weight
> here--correct
> >>> specification means 1) treatment assignment is unrelated to the random
> >>> effects, 2) the treatment effect is constant across clusters, 3)
> >>> distributional assumptions are valid (i.e., homoskedasticity at each
> level
> >>> of the model).
> >>>
> >>> If the effects are heterogeneous, then I would think that including
> >>> random slopes on the treatment indicator would provide a better basis
> for
> >>> generalization. But even then, the warrant is still pretty
> vague---what is
> >>> the hypothetical population of villages from which the observed
> villages
> >>> are sampled?
> >>>
> >>
> >> *In the most basic model (without baseline controls) the model takes the
> >> form: myModel = lmer(posXsymp~treatment + pairID + (1 | union), data =
> >> myData). I believe--correct me if I am wrong--that this reflects a
> >> random-intercepts only model, but I may be mistaken. If I am, and this
> is
> >> allowing for random slopes on the treatment indicator, then I will need
> to
> >> rethink my statements.  *
> >>
> >>>
> >>>
> >>>> Given this, however, does it also make sense to include the cluster
> >>>> robust SEs for the fixed effects which would account for possible
> >>>> heterogeneity of treatment effects (i.e., slopes) across clusters?s
> >>>>
> >>>> If you're committed to the random intercepts model, then yes I think
> so
> >>> because using cluster robust SEs at least acknowledges the possibility
> of
> >>> heterogeneous treatment effects.
> >>>
> >>
> >> *If the above model does allow for both random intercepts and slopes,
> then
> >> perhaps the use of cluster robust SEs is redundant in some sense since
> the
> >> random slopes would be modeling the heterogeneity in treatment effects?*
> >>
> >>>
> >>>
> >>>
> >>>> Bottom line: in their original analyses, clusters are seen as
> >>>> interchangeable from a conceptual perspective (rather than drawn from
> a
> >>>> random universe of observations). When one scales up evidence to a
> universe
> >>>> of observations that are random (as they would be in the intended
> universe
> >>>> of inference in the real-world), then we are better positioned, I
> think, to
> >>>> adjudicate whether the mask intervention effect is 'practically
> >>>> significant' (in addition to whether the focal effect remains
> marginally
> >>>> significant from a frequentist perspective).
> >>>>
> >>> As noted above, this argument is a bit vague to me. If there's concern
> >>> about generalizability, then my first question would be: what is the
> target
> >>> population to which you are trying to generalize?
> >>>
> >>
> >> *Essentially, the target population we are trying to generalize to is a
> >> random selection of villages. Any random selection of villages. In other
> >> words, villages should not be seen as interchangeable. We are
> interested in
> >> whether the effects generalize to any randomly selected village. *
> >>
> >>>
> >>>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> (Acting) Graduate chair, Mathematics & Statistics
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Sun Jul 31 02:36:11 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sat, 30 Jul 2022 20:36:11 -0400
Subject: [R-sig-ME] Cluster-robust SEs & random effects -- seeking some
 clarification
In-Reply-To: <CAH_7VOnnkY2ee1QXVbZ+VzNLJg2bZVPjdKpVqkGoc=ZyKj635Q@mail.gmail.com>
References: <CAH_7VOkx8+Pwpx+Rovgm0=k2Nde3TvmJpAQ_28O_NjQTY82h4g@mail.gmail.com>
 <CAFUVuJyh56KYctgrB1TSn8JB01h+Lh93Oh--dPvOK616b=x3LQ@mail.gmail.com>
 <CAH_7VO=aOOhT8TWJ7rAfY4EC+8yOepLpkpg0TcXgjN+wwk2c=w@mail.gmail.com>
 <CAFUVuJztqcXppr8VSDUXWYmTtcyDk+TVXDc3WPNkfcPJNRmaGA@mail.gmail.com>
 <CAH_7VO=pDmKDbpy8CfOTewcqXvwcfa1CRyRoohcRbQ=zz5ayOQ@mail.gmail.com>
 <CAFUVuJzXv6Ggz9iSMm6ehUVeNSFY3t-mn=jh7QqTiDuUBmzDCg@mail.gmail.com>
 <CAH_7VOnDW0Y7vXUZfChaM_JRgRg6c9uXs6+RzHt886fxo4AsUw@mail.gmail.com>
 <CAH_7VOmxzQcF7nNcDC42AeSZGFNdMO0O98zb9AroxPz51zHR1Q@mail.gmail.com>
 <883b38be-eeb7-8052-4395-618484a5ef97@gmail.com>
 <CAH_7VOnnkY2ee1QXVbZ+VzNLJg2bZVPjdKpVqkGoc=ZyKj635Q@mail.gmail.com>
Message-ID: <c85ebe15-38fc-9b66-3a67-656a9b969f88@gmail.com>

   Yes.

On 2022-07-30 8:12 p.m., J.D. Haltigan wrote:
> Thanks, Ben. So in the model you remarked on, would that be a 
> 'random-intercepts only' model?
> 
> 
> On Sat, Jul 30, 2022 at 7:53 PM Ben Bolker <bbolker at gmail.com 
> <mailto:bbolker at gmail.com>> wrote:
> 
>     I haven't been following the whole thread that carefully, but I want to
>     emphasize that
> 
>      ? ?posXsymp~treatment + pairID + (1 | union)
> 
>     is *not*, by any definition I'm familiar with, a "random-slopes model";
>     that is, it only estimates a single population-level treatment
>     effect/doesn't allow the effect of treatment to vary across groups
>     defined by 'union'.? You would need a random-effect term of the form
>     (treatment | union).
> 
>      ? ?Reasons why you might *not* want to do this:
> 
>      ? * if treatment only varies across and not within levels of union
>     ("union is nested within treatment" according to some terminology),
>     then
>     this variation is unidentifiable
>      ? * maybe you have decided that you don't have enough data/want a more
>     parsimonious model.
> 
>      ? ?Schielzeth and Forstmeier, among many others (this is the example I
>     know of), have cautioned about the consequences of leaving out
>     random-slopes terms.
> 
>     Schielzeth, Holger, and Wolfgang Forstmeier. ?Conclusions beyond
>     Support: Overconfident Estimates in Mixed Models.? Behavioral Ecology
>     20, no. 2 (March 1, 2009): 416?20.
>     https://doi.org/10.1093/beheco/arn145
>     <https://doi.org/10.1093/beheco/arn145>.
> 
> 
>     On 2022-07-30 7:43 p.m., J.D. Haltigan wrote:
>      > Addendum:
>      >
>      > It just occurred to me on my walk that I think I am getting a bit
>     lost in
>      > some of the differences in nomenclature across scientific silos.
>     In the
>      > original model that they specified, which treated the 'pairID'
>     variable as
>      > a control variable for which they controlled for 'fixed effects' of
>      > control/treatment villages (in their own language in the paper) using
>      > cluster-robust SEs, I think this is indeed a 'random-intercepts
>     only' model
>      > in the language of Hamaker et al. They implement the 'absorb'
>     command in
>      > STATA which I believe aggregates across the pairIDs to generate an
>      > 'omnibus' F-test of sorts for the pairID variable (in the ANOVA
>      > nomenclature). I say this as when I specify the pairID variable
>     in the lmer
>      > model I shared (or in a fixest model I conducted to replicate the
>     original
>      > Abalauck results in R), I get the estimates for all the pairs
>     (i.e., there
>      > is no way to aggregate across them--though I think formally the
>     models are
>      > the same if we are unconcerned about any one pairID
>     [treatment/control
>      > village pair].
>      >
>      > So, in the lmer model I shared where I specify a specific random
>     effects
>      > term for the 'cluster' variable, I think this indeed is allowing
>     for random
>      > slopes across the clusters which implies the treatment effect may
>     vary
>      > across the clusters (and we might anticipate it will for various
>     reasons I
>      > can elaborate on). More generally: we are generalizing to *any*
>     universe of
>      > villages (say in the entire world) where the treatment
>     intervention (masks)
>      > may vary across villages. This is the crux of invoking the random
>     effects
>      > model (i.e., random slopes model).
>      >
>      > I realize this is a mouthful, but I think the way these terms (e.g.,
>      > random/fixed effects models etc.) are used across disciplines
>     makes things
>      > a bit confusing.
>      >
>      > On Sat, Jul 30, 2022 at 5:25 PM J.D. Haltigan <jhaltiga at gmail.com
>     <mailto:jhaltiga at gmail.com>> wrote:
>      >
>      >> This is a very helpful walkthrough, James. My responses are
>     italicized
>      >> under yours to maintain thread readability. The key is
>     Generalizability
>      >> here and (as I also note in my last reply) the idea is to
>     Generalize to a
>      >> universe of "any villages or clusters." That is, the target
>     population we
>      >> are generalizing to is *any* random population.
>      >>
>      >> On Sat, Jul 30, 2022 at 3:01 PM James Pustejovsky
>     <jepusto at gmail.com <mailto:jepusto at gmail.com>>
>      >> wrote:
>      >>
>      >>> Hi J.D.,
>      >>> A few comments/reactions inline below.
>      >>> James
>      >>>
>      >>> On Wed, Jul 27, 2022 at 5:37 PM J.D. Haltigan
>     <jhaltiga at gmail.com <mailto:jhaltiga at gmail.com>> wrote:
>      >>>
>      >>>> ...
>      >>>>
>      >>> In the original investigation, the authors did not invoke a random
>      >>>> effects model (but did use the pairIDs to control for fixed
>     effects as
>      >>>> noted and with robust SEs). Thus, in the original
>     investigation there was
>      >>>> *no* specification of a random effects model for the 'cluster'
>     variable. We
>      >>>> know from some other work there were some biases in village
>     mapping and
>      >>>> other possible sources of between-cluster variation that might be
>      >>>> anticipated to have influence--at the random intercepts
>     level--so we are
>      >>>> looking into how specifying 'cluster' as a random effect might
>     change the
>      >>>> fixed effects estimates for the treatment intervention effect.
>     In the
>      >>>> Hamaker et al. language, it is indeed a 'random intercepts'
>     only model.
>      >>>>
>      >>>
>      >>> I don't follow how using a random intercepts model improves the
>      >>> generalizability warrant here. The random intercepts model is
>     essentially
>      >>> just a re-weighted average of the pair-specific effects in the
>     original
>      >>> analysis, where the weights are optimally efficient if the model is
>      >>> correctly specified. That last clause carries a lot of weight
>     here--correct
>      >>> specification means 1) treatment assignment is unrelated to the
>     random
>      >>> effects, 2) the treatment effect is constant across clusters, 3)
>      >>> distributional assumptions are valid (i.e., homoskedasticity at
>     each level
>      >>> of the model).
>      >>>
>      >>> If the effects are heterogeneous, then I would think that including
>      >>> random slopes on the treatment indicator would provide a better
>     basis for
>      >>> generalization. But even then, the warrant is still pretty
>     vague---what is
>      >>> the hypothetical population of villages from which the observed
>     villages
>      >>> are sampled?
>      >>>
>      >>
>      >> *In the most basic model (without baseline controls) the model
>     takes the
>      >> form: myModel = lmer(posXsymp~treatment + pairID + (1 | union),
>     data =
>      >> myData). I believe--correct me if I am wrong--that this reflects a
>      >> random-intercepts only model, but I may be mistaken. If I am,
>     and this is
>      >> allowing for random slopes on the treatment indicator, then I
>     will need to
>      >> rethink my statements.? *
>      >>
>      >>>
>      >>>
>      >>>> Given this, however, does it also make sense to include the
>     cluster
>      >>>> robust SEs for the fixed effects which would account for possible
>      >>>> heterogeneity of treatment effects (i.e., slopes) across
>     clusters?s
>      >>>>
>      >>>> If you're committed to the random intercepts model, then yes I
>     think so
>      >>> because using cluster robust SEs at least acknowledges the
>     possibility of
>      >>> heterogeneous treatment effects.
>      >>>
>      >>
>      >> *If the above model does allow for both random intercepts and
>     slopes, then
>      >> perhaps the use of cluster robust SEs is redundant in some sense
>     since the
>      >> random slopes would be modeling the heterogeneity in treatment
>     effects?*
>      >>
>      >>>
>      >>>
>      >>>
>      >>>> Bottom line: in their original analyses, clusters are seen as
>      >>>> interchangeable from a conceptual perspective (rather than
>     drawn from a
>      >>>> random universe of observations). When one scales up evidence
>     to a universe
>      >>>> of observations that are random (as they would be in the
>     intended universe
>      >>>> of inference in the real-world), then we are better
>     positioned, I think, to
>      >>>> adjudicate whether the mask intervention effect is 'practically
>      >>>> significant' (in addition to whether the focal effect remains
>     marginally
>      >>>> significant from a frequentist perspective).
>      >>>>
>      >>> As noted above, this argument is a bit vague to me. If there's
>     concern
>      >>> about generalizability, then my first question would be: what
>     is the target
>      >>> population to which you are trying to generalize?
>      >>>
>      >>
>      >> *Essentially, the target population we are trying to generalize
>     to is a
>      >> random selection of villages. Any random selection of villages.
>     In other
>      >> words, villages should not be seen as interchangeable. We are
>     interested in
>      >> whether the effects generalize to any randomly selected village. *
>      >>
>      >>>
>      >>>
>      >>
>      >
>      >? ? ? ?[[alternative HTML version deleted]]
>      >
>      > _______________________________________________
>      > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> 
>     -- 
>     Dr. Benjamin Bolker
>     Professor, Mathematics & Statistics and Biology, McMaster University
>     Director, School of Computational Science and Engineering
>     (Acting) Graduate chair, Mathematics & Statistics
> 
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics


From jh@|t|g@ @end|ng |rom gm@||@com  Sun Jul 31 02:43:59 2022
From: jh@|t|g@ @end|ng |rom gm@||@com (J.D. Haltigan)
Date: Sat, 30 Jul 2022 20:43:59 -0400
Subject: [R-sig-ME] Cluster-robust SEs & random effects -- seeking some
 clarification
In-Reply-To: <c85ebe15-38fc-9b66-3a67-656a9b969f88@gmail.com>
References: <CAH_7VOkx8+Pwpx+Rovgm0=k2Nde3TvmJpAQ_28O_NjQTY82h4g@mail.gmail.com>
 <CAFUVuJyh56KYctgrB1TSn8JB01h+Lh93Oh--dPvOK616b=x3LQ@mail.gmail.com>
 <CAH_7VO=aOOhT8TWJ7rAfY4EC+8yOepLpkpg0TcXgjN+wwk2c=w@mail.gmail.com>
 <CAFUVuJztqcXppr8VSDUXWYmTtcyDk+TVXDc3WPNkfcPJNRmaGA@mail.gmail.com>
 <CAH_7VO=pDmKDbpy8CfOTewcqXvwcfa1CRyRoohcRbQ=zz5ayOQ@mail.gmail.com>
 <CAFUVuJzXv6Ggz9iSMm6ehUVeNSFY3t-mn=jh7QqTiDuUBmzDCg@mail.gmail.com>
 <CAH_7VOnDW0Y7vXUZfChaM_JRgRg6c9uXs6+RzHt886fxo4AsUw@mail.gmail.com>
 <CAH_7VOmxzQcF7nNcDC42AeSZGFNdMO0O98zb9AroxPz51zHR1Q@mail.gmail.com>
 <883b38be-eeb7-8052-4395-618484a5ef97@gmail.com>
 <CAH_7VOnnkY2ee1QXVbZ+VzNLJg2bZVPjdKpVqkGoc=ZyKj635Q@mail.gmail.com>
 <c85ebe15-38fc-9b66-3a67-656a9b969f88@gmail.com>
Message-ID: <CAH_7VOks9qCDhRzKWC2vxp2OYfLAqcdFuRRuMtB3=0dQ9nSJGQ@mail.gmail.com>

And to take one more step: the inference is that the single
population-level treatment effect is drawing from a 'random sample' of
unions (clusters). That is, one can not assume that union's are the same.
They are not interchangeable. They are drawn from a random population. This
is the point of the exercise for me. If we remove the random effect for
union in the model I shared, we end up with a model in which only the fixed
effects of pairID (treatment-control pairs for each pair of treatment
control villages) are estimated (albeit using cluster-robust SEs). So, if
by adding that random effect for union the treatment intervention is no
longer significant (as opposed to a model in which there is no random
effect of union modeled), what is that telling us? That some of the between
cluster (union) variance in intercepts is contributing to variation in the
response variable, yes?

I realize you have not read the paper, nor are necessarily interested in
this discourse, but any remarks are greatly appreciated.


On Sat, Jul 30, 2022 at 8:36 PM Ben Bolker <bbolker at gmail.com> wrote:

>    Yes.
>
> On 2022-07-30 8:12 p.m., J.D. Haltigan wrote:
> > Thanks, Ben. So in the model you remarked on, would that be a
> > 'random-intercepts only' model?
> >
> >
> > On Sat, Jul 30, 2022 at 7:53 PM Ben Bolker <bbolker at gmail.com
> > <mailto:bbolker at gmail.com>> wrote:
> >
> >     I haven't been following the whole thread that carefully, but I want
> to
> >     emphasize that
> >
> >         posXsymp~treatment + pairID + (1 | union)
> >
> >     is *not*, by any definition I'm familiar with, a "random-slopes
> model";
> >     that is, it only estimates a single population-level treatment
> >     effect/doesn't allow the effect of treatment to vary across groups
> >     defined by 'union'.  You would need a random-effect term of the form
> >     (treatment | union).
> >
> >         Reasons why you might *not* want to do this:
> >
> >        * if treatment only varies across and not within levels of union
> >     ("union is nested within treatment" according to some terminology),
> >     then
> >     this variation is unidentifiable
> >        * maybe you have decided that you don't have enough data/want a
> more
> >     parsimonious model.
> >
> >         Schielzeth and Forstmeier, among many others (this is the
> example I
> >     know of), have cautioned about the consequences of leaving out
> >     random-slopes terms.
> >
> >     Schielzeth, Holger, and Wolfgang Forstmeier. ?Conclusions beyond
> >     Support: Overconfident Estimates in Mixed Models.? Behavioral Ecology
> >     20, no. 2 (March 1, 2009): 416?20.
> >     https://doi.org/10.1093/beheco/arn145
> >     <https://doi.org/10.1093/beheco/arn145>.
> >
> >
> >     On 2022-07-30 7:43 p.m., J.D. Haltigan wrote:
> >      > Addendum:
> >      >
> >      > It just occurred to me on my walk that I think I am getting a bit
> >     lost in
> >      > some of the differences in nomenclature across scientific silos.
> >     In the
> >      > original model that they specified, which treated the 'pairID'
> >     variable as
> >      > a control variable for which they controlled for 'fixed effects'
> of
> >      > control/treatment villages (in their own language in the paper)
> using
> >      > cluster-robust SEs, I think this is indeed a 'random-intercepts
> >     only' model
> >      > in the language of Hamaker et al. They implement the 'absorb'
> >     command in
> >      > STATA which I believe aggregates across the pairIDs to generate an
> >      > 'omnibus' F-test of sorts for the pairID variable (in the ANOVA
> >      > nomenclature). I say this as when I specify the pairID variable
> >     in the lmer
> >      > model I shared (or in a fixest model I conducted to replicate the
> >     original
> >      > Abalauck results in R), I get the estimates for all the pairs
> >     (i.e., there
> >      > is no way to aggregate across them--though I think formally the
> >     models are
> >      > the same if we are unconcerned about any one pairID
> >     [treatment/control
> >      > village pair].
> >      >
> >      > So, in the lmer model I shared where I specify a specific random
> >     effects
> >      > term for the 'cluster' variable, I think this indeed is allowing
> >     for random
> >      > slopes across the clusters which implies the treatment effect may
> >     vary
> >      > across the clusters (and we might anticipate it will for various
> >     reasons I
> >      > can elaborate on). More generally: we are generalizing to *any*
> >     universe of
> >      > villages (say in the entire world) where the treatment
> >     intervention (masks)
> >      > may vary across villages. This is the crux of invoking the random
> >     effects
> >      > model (i.e., random slopes model).
> >      >
> >      > I realize this is a mouthful, but I think the way these terms
> (e.g.,
> >      > random/fixed effects models etc.) are used across disciplines
> >     makes things
> >      > a bit confusing.
> >      >
> >      > On Sat, Jul 30, 2022 at 5:25 PM J.D. Haltigan <jhaltiga at gmail.com
> >     <mailto:jhaltiga at gmail.com>> wrote:
> >      >
> >      >> This is a very helpful walkthrough, James. My responses are
> >     italicized
> >      >> under yours to maintain thread readability. The key is
> >     Generalizability
> >      >> here and (as I also note in my last reply) the idea is to
> >     Generalize to a
> >      >> universe of "any villages or clusters." That is, the target
> >     population we
> >      >> are generalizing to is *any* random population.
> >      >>
> >      >> On Sat, Jul 30, 2022 at 3:01 PM James Pustejovsky
> >     <jepusto at gmail.com <mailto:jepusto at gmail.com>>
> >      >> wrote:
> >      >>
> >      >>> Hi J.D.,
> >      >>> A few comments/reactions inline below.
> >      >>> James
> >      >>>
> >      >>> On Wed, Jul 27, 2022 at 5:37 PM J.D. Haltigan
> >     <jhaltiga at gmail.com <mailto:jhaltiga at gmail.com>> wrote:
> >      >>>
> >      >>>> ...
> >      >>>>
> >      >>> In the original investigation, the authors did not invoke a
> random
> >      >>>> effects model (but did use the pairIDs to control for fixed
> >     effects as
> >      >>>> noted and with robust SEs). Thus, in the original
> >     investigation there was
> >      >>>> *no* specification of a random effects model for the 'cluster'
> >     variable. We
> >      >>>> know from some other work there were some biases in village
> >     mapping and
> >      >>>> other possible sources of between-cluster variation that might
> be
> >      >>>> anticipated to have influence--at the random intercepts
> >     level--so we are
> >      >>>> looking into how specifying 'cluster' as a random effect might
> >     change the
> >      >>>> fixed effects estimates for the treatment intervention effect.
> >     In the
> >      >>>> Hamaker et al. language, it is indeed a 'random intercepts'
> >     only model.
> >      >>>>
> >      >>>
> >      >>> I don't follow how using a random intercepts model improves the
> >      >>> generalizability warrant here. The random intercepts model is
> >     essentially
> >      >>> just a re-weighted average of the pair-specific effects in the
> >     original
> >      >>> analysis, where the weights are optimally efficient if the
> model is
> >      >>> correctly specified. That last clause carries a lot of weight
> >     here--correct
> >      >>> specification means 1) treatment assignment is unrelated to the
> >     random
> >      >>> effects, 2) the treatment effect is constant across clusters, 3)
> >      >>> distributional assumptions are valid (i.e., homoskedasticity at
> >     each level
> >      >>> of the model).
> >      >>>
> >      >>> If the effects are heterogeneous, then I would think that
> including
> >      >>> random slopes on the treatment indicator would provide a better
> >     basis for
> >      >>> generalization. But even then, the warrant is still pretty
> >     vague---what is
> >      >>> the hypothetical population of villages from which the observed
> >     villages
> >      >>> are sampled?
> >      >>>
> >      >>
> >      >> *In the most basic model (without baseline controls) the model
> >     takes the
> >      >> form: myModel = lmer(posXsymp~treatment + pairID + (1 | union),
> >     data =
> >      >> myData). I believe--correct me if I am wrong--that this reflects
> a
> >      >> random-intercepts only model, but I may be mistaken. If I am,
> >     and this is
> >      >> allowing for random slopes on the treatment indicator, then I
> >     will need to
> >      >> rethink my statements.  *
> >      >>
> >      >>>
> >      >>>
> >      >>>> Given this, however, does it also make sense to include the
> >     cluster
> >      >>>> robust SEs for the fixed effects which would account for
> possible
> >      >>>> heterogeneity of treatment effects (i.e., slopes) across
> >     clusters?s
> >      >>>>
> >      >>>> If you're committed to the random intercepts model, then yes I
> >     think so
> >      >>> because using cluster robust SEs at least acknowledges the
> >     possibility of
> >      >>> heterogeneous treatment effects.
> >      >>>
> >      >>
> >      >> *If the above model does allow for both random intercepts and
> >     slopes, then
> >      >> perhaps the use of cluster robust SEs is redundant in some sense
> >     since the
> >      >> random slopes would be modeling the heterogeneity in treatment
> >     effects?*
> >      >>
> >      >>>
> >      >>>
> >      >>>
> >      >>>> Bottom line: in their original analyses, clusters are seen as
> >      >>>> interchangeable from a conceptual perspective (rather than
> >     drawn from a
> >      >>>> random universe of observations). When one scales up evidence
> >     to a universe
> >      >>>> of observations that are random (as they would be in the
> >     intended universe
> >      >>>> of inference in the real-world), then we are better
> >     positioned, I think, to
> >      >>>> adjudicate whether the mask intervention effect is 'practically
> >      >>>> significant' (in addition to whether the focal effect remains
> >     marginally
> >      >>>> significant from a frequentist perspective).
> >      >>>>
> >      >>> As noted above, this argument is a bit vague to me. If there's
> >     concern
> >      >>> about generalizability, then my first question would be: what
> >     is the target
> >      >>> population to which you are trying to generalize?
> >      >>>
> >      >>
> >      >> *Essentially, the target population we are trying to generalize
> >     to is a
> >      >> random selection of villages. Any random selection of villages.
> >     In other
> >      >> words, villages should not be seen as interchangeable. We are
> >     interested in
> >      >> whether the effects generalize to any randomly selected village.
> *
> >      >>
> >      >>>
> >      >>>
> >      >>
> >      >
> >      >       [[alternative HTML version deleted]]
> >      >
> >      > _______________________________________________
> >      > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >
> >     --
> >     Dr. Benjamin Bolker
> >     Professor, Mathematics & Statistics and Biology, McMaster University
> >     Director, School of Computational Science and Engineering
> >     (Acting) Graduate chair, Mathematics & Statistics
> >
> >     _______________________________________________
> >     R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >
>
> --
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> (Acting) Graduate chair, Mathematics & Statistics
>

	[[alternative HTML version deleted]]


From juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com  Wed Aug  3 21:10:18 2022
From: juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com (Juho Kristian Ruohonen)
Date: Wed, 3 Aug 2022 22:10:18 +0300
Subject: [R-sig-ME] Problem specifying uncorrelated random intercepts and
 slopes for a multi-df covariate
Message-ID: <CAG_dBVdx-+dH5yxn-YVCuOi4m9Ve18-2Ewv-F9wCx4+U8JfL=g@mail.gmail.com>

Dear List,

This is a logistic GLMM with 1 grouping factor + 8 fixed-effect covariates.
One of the fixed effects, namely x2, has three unordered categories. This
is the covariate for whose 2 non-reference categories I want to estimate
random slopes, along with the random intercepts with which I don't expect
the slopes to be correlated. But I fail:



*> VarCorr(glmer(y ~ (x2||id) + x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8,
family = binomial, data = mydata, control = glmerControl(optimizer =
"optimx", optCtrl = list(method = "nlm")), nAGQ = 1))*


*boundary (singular) fit: see help('isSingular')*




* Groups Name        Std.Dev. Corr        id     (Intercept) 0.00000
       id.1   x2A         0.76331                     x2B         0.75422
 0.931              x2C         0.56139  0.807 0.967*

^ Why is it reporting correlations when I told it not to? And why is it
reporting the intercept variance as zero (which is wholly implausible)? And
why is it reporting a "random slope" for the reference category of x2? It's
the reference category, for crying out loud! It's not supposed to get an
estimate.

Consultation of the lme4 manual
<https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf> (page 7)
suggests the following alternative syntax for specifying random slopes
uncorrelated with the random intercepts:

*> VarCorr(glmer(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + (1|id) +
(0+x2|id), family = binomial, data = mydata, control =
glmerControl(optimizer = "optimx", optCtrl = list(method = "nlm")), nAGQ =
1))*

*boundary (singular) fit: see help('isSingular')*





* Groups Name        Std.Dev. Corr        id     (Intercept) 0.00000
       id.1   x2A         0.76331                     x2B         0.75422
 0.931              x2C         0.56139  0.807 0.967*

^ The exact same strangeness persists. Correlations are being estimated
against my wishes, and there's a nonsensical parameter supposedly
ostensibly representing the reference category, plus an implausible zero
value reported on the random intercepts. What am I doing wrong?

Best,

Juho

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Wed Aug  3 21:15:26 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 3 Aug 2022 15:15:26 -0400
Subject: [R-sig-ME] 
 Problem specifying uncorrelated random intercepts and
 slopes for a multi-df covariate
In-Reply-To: <CAG_dBVdx-+dH5yxn-YVCuOi4m9Ve18-2Ewv-F9wCx4+U8JfL=g@mail.gmail.com>
References: <CAG_dBVdx-+dH5yxn-YVCuOi4m9Ve18-2Ewv-F9wCx4+U8JfL=g@mail.gmail.com>
Message-ID: <37173026-2589-8700-12f0-0565d8d04f13@gmail.com>

 ?? From the help file (help("||", package = "lme4"):

Because ?||? works at the level of formula parsing, it has no way
 ???? of knowing whether a variable is a factor. It just takes the terms
 ???? within a random-effects term and literally splits them into the
 ???? intercept and separate no-intercept terms, e.g. ?(1+x+y|f)? would
 ???? be split into ?(1|f) + (0+x|f) + (0+y|f)?.? However, ?||? will
 ???? fail to break up factors into separate terms; the ?dummy? function
 ???? can be useful in this case, although it is not as convenient as
 ???? ?||?.

afex::lmer_alt() may do what you want:

 ??lmer_alt? is simply a wrapper for mixed that only returns the
 ???? ?"lmerModLmerTest"? or ?"merMod"? object and correctly uses the
 ???? ?||? notation for removing correlations among factors. This
 ???? function otherwise behaves like ?g/lmer? (as for ?mixed?, it calls
 ???? ?glmer? as soon as a ?family? argument is present). Use
 ???? ?afex_options??("lmer_function")? to set which function for
 ???? estimation should be used. This option determines the class of the
 ???? returned object (i.e., ?"lmerModLmerTest"? or ?"merMod"?).


On 2022-08-03 3:10 PM, Juho Kristian Ruohonen wrote:
> Dear List,
>
> This is a logistic GLMM with 1 grouping factor + 8 fixed-effect covariates.
> One of the fixed effects, namely x2, has three unordered categories. This
> is the covariate for whose 2 non-reference categories I want to estimate
> random slopes, along with the random intercepts with which I don't expect
> the slopes to be correlated. But I fail:
>
>
>
> *> VarCorr(glmer(y ~ (x2||id) + x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8,
> family = binomial, data = mydata, control = glmerControl(optimizer =
> "optimx", optCtrl = list(method = "nlm")), nAGQ = 1))*
>
>
> *boundary (singular) fit: see help('isSingular')*
>
>
>
>
> * Groups Name        Std.Dev. Corr        id     (Intercept) 0.00000
>         id.1   x2A         0.76331                     x2B         0.75422
>   0.931              x2C         0.56139  0.807 0.967*
>
> ^ Why is it reporting correlations when I told it not to? And why is it
> reporting the intercept variance as zero (which is wholly implausible)? And
> why is it reporting a "random slope" for the reference category of x2? It's
> the reference category, for crying out loud! It's not supposed to get an
> estimate.
>
> Consultation of the lme4 manual
> <https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf> (page 7)
> suggests the following alternative syntax for specifying random slopes
> uncorrelated with the random intercepts:
>
> *> VarCorr(glmer(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + (1|id) +
> (0+x2|id), family = binomial, data = mydata, control =
> glmerControl(optimizer = "optimx", optCtrl = list(method = "nlm")), nAGQ =
> 1))*
>
> *boundary (singular) fit: see help('isSingular')*
>
>
>
>
>
> * Groups Name        Std.Dev. Corr        id     (Intercept) 0.00000
>         id.1   x2A         0.76331                     x2B         0.75422
>   0.931              x2C         0.56139  0.807 0.967*
>
> ^ The exact same strangeness persists. Correlations are being estimated
> against my wishes, and there's a nonsensical parameter supposedly
> ostensibly representing the reference category, plus an implausible zero
> value reported on the random intercepts. What am I doing wrong?
>
> Best,
>
> Juho
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From j|@ver|@@|mo @end|ng |rom gm@||@com  Wed Aug  3 23:30:12 2022
From: j|@ver|@@|mo @end|ng |rom gm@||@com (=?UTF-8?Q?Jo=c3=a3o_Ver=c3=adssimo?=)
Date: Wed, 3 Aug 2022 23:30:12 +0200
Subject: [R-sig-ME] 
 Problem specifying uncorrelated random intercepts and
 slopes for a multi-df covariate
In-Reply-To: <CAG_dBVdx-+dH5yxn-YVCuOi4m9Ve18-2Ewv-F9wCx4+U8JfL=g@mail.gmail.com>
References: <CAG_dBVdx-+dH5yxn-YVCuOi4m9Ve18-2Ewv-F9wCx4+U8JfL=g@mail.gmail.com>
Message-ID: <90cfef32-6f08-f853-39bb-3cc8c8dc026f@gmail.com>

(1+x2 || id) is shorter notation for (1 | id) + (0 + x2 | id ).
And because x2 is a factor, suppressing the intercept leads to the 
'cell-mean coding' of x2: what is being estimated is the between-id 
variation around the means of each level, A, B, and C (and their 
correlation).

In order to get what you want, turn x2 into two numeric variables 
according to its contrasts. For example:
x2num1 <- ifelse(x2=="B", 1, 0)
x2num2 <- ifelse(x2=="C", 1, 0)

Then (1 + x2num1 + x2num2 || id) will give you the random intercept, two 
random slopes and no correlations.

Jo?o

On 03/08/2022 21:10, Juho Kristian Ruohonen wrote:
> Dear List,
>
> This is a logistic GLMM with 1 grouping factor + 8 fixed-effect covariates.
> One of the fixed effects, namely x2, has three unordered categories. This
> is the covariate for whose 2 non-reference categories I want to estimate
> random slopes, along with the random intercepts with which I don't expect
> the slopes to be correlated. But I fail:
>
>
>
> *> VarCorr(glmer(y ~ (x2||id) + x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8,
> family = binomial, data = mydata, control = glmerControl(optimizer =
> "optimx", optCtrl = list(method = "nlm")), nAGQ = 1))*
>
>
> *boundary (singular) fit: see help('isSingular')*
>
>
>
>
> * Groups Name        Std.Dev. Corr        id     (Intercept) 0.00000
>         id.1   x2A         0.76331                     x2B         0.75422
>   0.931              x2C         0.56139  0.807 0.967*
>
> ^ Why is it reporting correlations when I told it not to? And why is it
> reporting the intercept variance as zero (which is wholly implausible)? And
> why is it reporting a "random slope" for the reference category of x2? It's
> the reference category, for crying out loud! It's not supposed to get an
> estimate.
>
> Consultation of the lme4 manual
> <https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf> (page 7)
> suggests the following alternative syntax for specifying random slopes
> uncorrelated with the random intercepts:
>
> *> VarCorr(glmer(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + (1|id) +
> (0+x2|id), family = binomial, data = mydata, control =
> glmerControl(optimizer = "optimx", optCtrl = list(method = "nlm")), nAGQ =
> 1))*
>
> *boundary (singular) fit: see help('isSingular')*
>
>
>
>
>
> * Groups Name        Std.Dev. Corr        id     (Intercept) 0.00000
>         id.1   x2A         0.76331                     x2B         0.75422
>   0.931              x2C         0.56139  0.807 0.967*
>
> ^ The exact same strangeness persists. Correlations are being estimated
> against my wishes, and there's a nonsensical parameter supposedly
> ostensibly representing the reference category, plus an implausible zero
> value reported on the random intercepts. What am I doing wrong?
>
> Best,
>
> Juho
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From jh@|t|g@ @end|ng |rom gm@||@com  Thu Aug  4 05:46:30 2022
From: jh@|t|g@ @end|ng |rom gm@||@com (J.D. Haltigan)
Date: Wed, 3 Aug 2022 23:46:30 -0400
Subject: [R-sig-ME] Cluster-robust SEs & random effects -- seeking some
 clarification
In-Reply-To: <CAH_7VOks9qCDhRzKWC2vxp2OYfLAqcdFuRRuMtB3=0dQ9nSJGQ@mail.gmail.com>
References: <CAH_7VOkx8+Pwpx+Rovgm0=k2Nde3TvmJpAQ_28O_NjQTY82h4g@mail.gmail.com>
 <CAFUVuJyh56KYctgrB1TSn8JB01h+Lh93Oh--dPvOK616b=x3LQ@mail.gmail.com>
 <CAH_7VO=aOOhT8TWJ7rAfY4EC+8yOepLpkpg0TcXgjN+wwk2c=w@mail.gmail.com>
 <CAFUVuJztqcXppr8VSDUXWYmTtcyDk+TVXDc3WPNkfcPJNRmaGA@mail.gmail.com>
 <CAH_7VO=pDmKDbpy8CfOTewcqXvwcfa1CRyRoohcRbQ=zz5ayOQ@mail.gmail.com>
 <CAFUVuJzXv6Ggz9iSMm6ehUVeNSFY3t-mn=jh7QqTiDuUBmzDCg@mail.gmail.com>
 <CAH_7VOnDW0Y7vXUZfChaM_JRgRg6c9uXs6+RzHt886fxo4AsUw@mail.gmail.com>
 <CAH_7VOmxzQcF7nNcDC42AeSZGFNdMO0O98zb9AroxPz51zHR1Q@mail.gmail.com>
 <883b38be-eeb7-8052-4395-618484a5ef97@gmail.com>
 <CAH_7VOnnkY2ee1QXVbZ+VzNLJg2bZVPjdKpVqkGoc=ZyKj635Q@mail.gmail.com>
 <c85ebe15-38fc-9b66-3a67-656a9b969f88@gmail.com>
 <CAH_7VOks9qCDhRzKWC2vxp2OYfLAqcdFuRRuMtB3=0dQ9nSJGQ@mail.gmail.com>
Message-ID: <CAH_7VO=FQmm_qVQ4aBw0Krmza61TAz3U97JWx9wNbdSPACY7AQ@mail.gmail.com>

Thought I would bump my last post to see if anyone might weigh in on my
more general statements about re: unions (clusters). Would be most
appreciated as I continue to wrap my head around some things.

Thanks in advance for any thoughts. I appreciate your time.

On Sat, Jul 30, 2022 at 8:43 PM J.D. Haltigan <jhaltiga at gmail.com> wrote:

> And to take one more step: the inference is that the single
> population-level treatment effect is drawing from a 'random sample' of
> unions (clusters). That is, one can not assume that union's are the same.
> They are not interchangeable. They are drawn from a random population. This
> is the point of the exercise for me. If we remove the random effect for
> union in the model I shared, we end up with a model in which only the fixed
> effects of pairID (treatment-control pairs for each pair of treatment
> control villages) are estimated (albeit using cluster-robust SEs). So, if
> by adding that random effect for union the treatment intervention is no
> longer significant (as opposed to a model in which there is no random
> effect of union modeled), what is that telling us? That some of the between
> cluster (union) variance in intercepts is contributing to variation in the
> response variable, yes?
>
> I realize you have not read the paper, nor are necessarily interested in
> this discourse, but any remarks are greatly appreciated.
>
>
> On Sat, Jul 30, 2022 at 8:36 PM Ben Bolker <bbolker at gmail.com> wrote:
>
>>    Yes.
>>
>> On 2022-07-30 8:12 p.m., J.D. Haltigan wrote:
>> > Thanks, Ben. So in the model you remarked on, would that be a
>> > 'random-intercepts only' model?
>> >
>> >
>> > On Sat, Jul 30, 2022 at 7:53 PM Ben Bolker <bbolker at gmail.com
>> > <mailto:bbolker at gmail.com>> wrote:
>> >
>> >     I haven't been following the whole thread that carefully, but I
>> want to
>> >     emphasize that
>> >
>> >         posXsymp~treatment + pairID + (1 | union)
>> >
>> >     is *not*, by any definition I'm familiar with, a "random-slopes
>> model";
>> >     that is, it only estimates a single population-level treatment
>> >     effect/doesn't allow the effect of treatment to vary across groups
>> >     defined by 'union'.  You would need a random-effect term of the form
>> >     (treatment | union).
>> >
>> >         Reasons why you might *not* want to do this:
>> >
>> >        * if treatment only varies across and not within levels of union
>> >     ("union is nested within treatment" according to some terminology),
>> >     then
>> >     this variation is unidentifiable
>> >        * maybe you have decided that you don't have enough data/want a
>> more
>> >     parsimonious model.
>> >
>> >         Schielzeth and Forstmeier, among many others (this is the
>> example I
>> >     know of), have cautioned about the consequences of leaving out
>> >     random-slopes terms.
>> >
>> >     Schielzeth, Holger, and Wolfgang Forstmeier. ?Conclusions beyond
>> >     Support: Overconfident Estimates in Mixed Models.? Behavioral
>> Ecology
>> >     20, no. 2 (March 1, 2009): 416?20.
>> >     https://doi.org/10.1093/beheco/arn145
>> >     <https://doi.org/10.1093/beheco/arn145>.
>> >
>> >
>> >     On 2022-07-30 7:43 p.m., J.D. Haltigan wrote:
>> >      > Addendum:
>> >      >
>> >      > It just occurred to me on my walk that I think I am getting a bit
>> >     lost in
>> >      > some of the differences in nomenclature across scientific silos.
>> >     In the
>> >      > original model that they specified, which treated the 'pairID'
>> >     variable as
>> >      > a control variable for which they controlled for 'fixed effects'
>> of
>> >      > control/treatment villages (in their own language in the paper)
>> using
>> >      > cluster-robust SEs, I think this is indeed a 'random-intercepts
>> >     only' model
>> >      > in the language of Hamaker et al. They implement the 'absorb'
>> >     command in
>> >      > STATA which I believe aggregates across the pairIDs to generate
>> an
>> >      > 'omnibus' F-test of sorts for the pairID variable (in the ANOVA
>> >      > nomenclature). I say this as when I specify the pairID variable
>> >     in the lmer
>> >      > model I shared (or in a fixest model I conducted to replicate the
>> >     original
>> >      > Abalauck results in R), I get the estimates for all the pairs
>> >     (i.e., there
>> >      > is no way to aggregate across them--though I think formally the
>> >     models are
>> >      > the same if we are unconcerned about any one pairID
>> >     [treatment/control
>> >      > village pair].
>> >      >
>> >      > So, in the lmer model I shared where I specify a specific random
>> >     effects
>> >      > term for the 'cluster' variable, I think this indeed is allowing
>> >     for random
>> >      > slopes across the clusters which implies the treatment effect may
>> >     vary
>> >      > across the clusters (and we might anticipate it will for various
>> >     reasons I
>> >      > can elaborate on). More generally: we are generalizing to *any*
>> >     universe of
>> >      > villages (say in the entire world) where the treatment
>> >     intervention (masks)
>> >      > may vary across villages. This is the crux of invoking the random
>> >     effects
>> >      > model (i.e., random slopes model).
>> >      >
>> >      > I realize this is a mouthful, but I think the way these terms
>> (e.g.,
>> >      > random/fixed effects models etc.) are used across disciplines
>> >     makes things
>> >      > a bit confusing.
>> >      >
>> >      > On Sat, Jul 30, 2022 at 5:25 PM J.D. Haltigan <
>> jhaltiga at gmail.com
>> >     <mailto:jhaltiga at gmail.com>> wrote:
>> >      >
>> >      >> This is a very helpful walkthrough, James. My responses are
>> >     italicized
>> >      >> under yours to maintain thread readability. The key is
>> >     Generalizability
>> >      >> here and (as I also note in my last reply) the idea is to
>> >     Generalize to a
>> >      >> universe of "any villages or clusters." That is, the target
>> >     population we
>> >      >> are generalizing to is *any* random population.
>> >      >>
>> >      >> On Sat, Jul 30, 2022 at 3:01 PM James Pustejovsky
>> >     <jepusto at gmail.com <mailto:jepusto at gmail.com>>
>> >      >> wrote:
>> >      >>
>> >      >>> Hi J.D.,
>> >      >>> A few comments/reactions inline below.
>> >      >>> James
>> >      >>>
>> >      >>> On Wed, Jul 27, 2022 at 5:37 PM J.D. Haltigan
>> >     <jhaltiga at gmail.com <mailto:jhaltiga at gmail.com>> wrote:
>> >      >>>
>> >      >>>> ...
>> >      >>>>
>> >      >>> In the original investigation, the authors did not invoke a
>> random
>> >      >>>> effects model (but did use the pairIDs to control for fixed
>> >     effects as
>> >      >>>> noted and with robust SEs). Thus, in the original
>> >     investigation there was
>> >      >>>> *no* specification of a random effects model for the 'cluster'
>> >     variable. We
>> >      >>>> know from some other work there were some biases in village
>> >     mapping and
>> >      >>>> other possible sources of between-cluster variation that
>> might be
>> >      >>>> anticipated to have influence--at the random intercepts
>> >     level--so we are
>> >      >>>> looking into how specifying 'cluster' as a random effect might
>> >     change the
>> >      >>>> fixed effects estimates for the treatment intervention effect.
>> >     In the
>> >      >>>> Hamaker et al. language, it is indeed a 'random intercepts'
>> >     only model.
>> >      >>>>
>> >      >>>
>> >      >>> I don't follow how using a random intercepts model improves the
>> >      >>> generalizability warrant here. The random intercepts model is
>> >     essentially
>> >      >>> just a re-weighted average of the pair-specific effects in the
>> >     original
>> >      >>> analysis, where the weights are optimally efficient if the
>> model is
>> >      >>> correctly specified. That last clause carries a lot of weight
>> >     here--correct
>> >      >>> specification means 1) treatment assignment is unrelated to the
>> >     random
>> >      >>> effects, 2) the treatment effect is constant across clusters,
>> 3)
>> >      >>> distributional assumptions are valid (i.e., homoskedasticity at
>> >     each level
>> >      >>> of the model).
>> >      >>>
>> >      >>> If the effects are heterogeneous, then I would think that
>> including
>> >      >>> random slopes on the treatment indicator would provide a better
>> >     basis for
>> >      >>> generalization. But even then, the warrant is still pretty
>> >     vague---what is
>> >      >>> the hypothetical population of villages from which the observed
>> >     villages
>> >      >>> are sampled?
>> >      >>>
>> >      >>
>> >      >> *In the most basic model (without baseline controls) the model
>> >     takes the
>> >      >> form: myModel = lmer(posXsymp~treatment + pairID + (1 | union),
>> >     data =
>> >      >> myData). I believe--correct me if I am wrong--that this
>> reflects a
>> >      >> random-intercepts only model, but I may be mistaken. If I am,
>> >     and this is
>> >      >> allowing for random slopes on the treatment indicator, then I
>> >     will need to
>> >      >> rethink my statements.  *
>> >      >>
>> >      >>>
>> >      >>>
>> >      >>>> Given this, however, does it also make sense to include the
>> >     cluster
>> >      >>>> robust SEs for the fixed effects which would account for
>> possible
>> >      >>>> heterogeneity of treatment effects (i.e., slopes) across
>> >     clusters?s
>> >      >>>>
>> >      >>>> If you're committed to the random intercepts model, then yes I
>> >     think so
>> >      >>> because using cluster robust SEs at least acknowledges the
>> >     possibility of
>> >      >>> heterogeneous treatment effects.
>> >      >>>
>> >      >>
>> >      >> *If the above model does allow for both random intercepts and
>> >     slopes, then
>> >      >> perhaps the use of cluster robust SEs is redundant in some sense
>> >     since the
>> >      >> random slopes would be modeling the heterogeneity in treatment
>> >     effects?*
>> >      >>
>> >      >>>
>> >      >>>
>> >      >>>
>> >      >>>> Bottom line: in their original analyses, clusters are seen as
>> >      >>>> interchangeable from a conceptual perspective (rather than
>> >     drawn from a
>> >      >>>> random universe of observations). When one scales up evidence
>> >     to a universe
>> >      >>>> of observations that are random (as they would be in the
>> >     intended universe
>> >      >>>> of inference in the real-world), then we are better
>> >     positioned, I think, to
>> >      >>>> adjudicate whether the mask intervention effect is
>> 'practically
>> >      >>>> significant' (in addition to whether the focal effect remains
>> >     marginally
>> >      >>>> significant from a frequentist perspective).
>> >      >>>>
>> >      >>> As noted above, this argument is a bit vague to me. If there's
>> >     concern
>> >      >>> about generalizability, then my first question would be: what
>> >     is the target
>> >      >>> population to which you are trying to generalize?
>> >      >>>
>> >      >>
>> >      >> *Essentially, the target population we are trying to generalize
>> >     to is a
>> >      >> random selection of villages. Any random selection of villages.
>> >     In other
>> >      >> words, villages should not be seen as interchangeable. We are
>> >     interested in
>> >      >> whether the effects generalize to any randomly selected
>> village. *
>> >      >>
>> >      >>>
>> >      >>>
>> >      >>
>> >      >
>> >      >       [[alternative HTML version deleted]]
>> >      >
>> >      > _______________________________________________
>> >      > R-sig-mixed-models at r-project.org
>> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
>> >      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>> >
>> >     --
>> >     Dr. Benjamin Bolker
>> >     Professor, Mathematics & Statistics and Biology, McMaster University
>> >     Director, School of Computational Science and Engineering
>> >     (Acting) Graduate chair, Mathematics & Statistics
>> >
>> >     _______________________________________________
>> >     R-sig-mixed-models at r-project.org
>> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
>> >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>> >
>>
>> --
>> Dr. Benjamin Bolker
>> Professor, Mathematics & Statistics and Biology, McMaster University
>> Director, School of Computational Science and Engineering
>> (Acting) Graduate chair, Mathematics & Statistics
>>
>

	[[alternative HTML version deleted]]


From juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com  Thu Aug  4 17:07:39 2022
From: juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com (Juho Kristian Ruohonen)
Date: Thu, 4 Aug 2022 18:07:39 +0300
Subject: [R-sig-ME] 
 Problem specifying uncorrelated random intercepts and
 slopes for a multi-df covariate
In-Reply-To: <90cfef32-6f08-f853-39bb-3cc8c8dc026f@gmail.com>
References: <CAG_dBVdx-+dH5yxn-YVCuOi4m9Ve18-2Ewv-F9wCx4+U8JfL=g@mail.gmail.com>
 <90cfef32-6f08-f853-39bb-3cc8c8dc026f@gmail.com>
Message-ID: <CAG_dBVdk7XLaSxOOkwG_LEiSwff2tfEW8EADcUgtbPU7navJWw@mail.gmail.com>

Many thanks, Ben and Jo?o. I did as advised, converting x2 into two dummies
and specifying the random effects as *(x2B+x2C||id)*. This yields the
correct number of estimated parameters (1 random intercepts, 2 random
slopes). However, there's something I don't understand about the results.

Firstly, there's a warning about a singular fit, which I take to mean that
some parameters are inestimable. Judging from the following output, I
gather that it must be the 2 random slopes, which are estimated at
essentially zero:

*> summary(slopes.nocorr)*
*...*


















*Random effects: Groups Name        Variance  Std.Dev.  id     (Intercept)
5.539e-01 7.443e-01 id.1   x2B         1.546e-14 1.243e-07 id.2   x2C
  0.000e+00 0.000e+00Number of obs: 1405, groups:  id, 292Fixed effects:
        Estimate Std. Error z value Pr(>|z|)    (Intercept) -0.93057
 0.27450  -3.390 0.000699 ***x1           0.51158    0.26550   1.927
0.053997 .  x2B          2.54505    0.20936  12.156  < 2e-16 ***x2C
 2.30179    0.30480   7.552 4.29e-14 ***x3          -0.77494    0.11660
 -6.646 3.01e-11 ***x4           0.24489    0.04957   4.940 7.80e-07 ***x5
          0.28619    0.13810   2.072 0.038235 *  x6          -1.07816
 0.90224  -1.195 0.232091    x7          -0.67521    0.32810  -2.058
0.039595 *  *
*x8          -0.76275    0.28824  -2.646 0.008138 ** *

It seems very strange that the random slopes should be inestimable: x2B and
x2C are not exceedingly scarce conditions: there are 277 observations of
the former, 91 of the latter. There are 52 IDs with observations of both xB
= 1 and xB = 0. And there are 33 IDs with observations of both xC = 1 and
xC = 0. So, I don't understand why the random slopes couldn't be estimated.

Stranger still, if I fit an otherwise identical model with *correlated* random
effects, the random-slope estimates suddenly do differ from 0 (although
there's still a singularity warning). Like so:

*> slopes.corr <-   glmer(y ~ (x2B+x2C|id)  + x1 + x2B + x2C + x3 + x4 + x5
+ x6 + x7 + x8, family = binomial, data = mydata, control =
glmerControl(optimizer = "optimx", optCtrl = list(method = "nlm")), nAGQ =
1)*
*...*






*Random effects: Groups Name        Variance Std.Dev. Corr        id
(Intercept) 0.5827   0.7633                      x2B         0.0798
0.2825   -0.22              x2C         0.2060   0.4539   -0.68  0.86Number
of obs: 1405, groups:  id, 292*












*Fixed effects:            Estimate Std. Error z value Pr(>|z|)
 (Intercept) -0.98131    0.30416  -3.226  0.00125 ** x1           0.56391
 0.29692   1.899  0.05754 .  x2B          2.56529    0.28735   8.928  <
2e-16 ***x2C          2.17394    0.41814   5.199 2.00e-07 ***x3
 -0.77852    0.11699  -6.655 2.84e-11 ***x4           0.24384    0.04982
4.895 9.84e-07 ***x5           0.28790    0.14005   2.056  0.03981 *  x6
       -1.08438    0.91036  -1.191  0.23359    x7          -0.66753
 0.32962  -2.025  0.04285 *  x8          -0.75425    0.28913  -2.609
 0.00909 ** *

It boggles my mind that the 2 random slopes should be inestimable in the
simpler model (with no correlation params) but somehow become estimable
when you introduce 3 more parameters by allowing random-effect
correlations. My brain has melted. Does anyone have a clue what's going on?
The anonymized datafile is available here <https://file.io/VKruszwJBwcK>.

Best,

Juho



to 4. elok. 2022 klo 0.30 Jo?o Ver?ssimo (jl.verissimo at gmail.com) kirjoitti:

> (1+x2 || id) is shorter notation for (1 | id) + (0 + x2 | id ).
> And because x2 is a factor, suppressing the intercept leads to the
> 'cell-mean coding' of x2: what is being estimated is the between-id
> variation around the means of each level, A, B, and C (and their
> correlation).
>
> In order to get what you want, turn x2 into two numeric variables
> according to its contrasts. For example:
> x2num1 <- ifelse(x2=="B", 1, 0)
> x2num2 <- ifelse(x2=="C", 1, 0)
>
> Then (1 + x2num1 + x2num2 || id) will give you the random intercept, two
> random slopes and no correlations.
>
> Jo?o
>
> On 03/08/2022 21:10, Juho Kristian Ruohonen wrote:
> > Dear List,
> >
> > This is a logistic GLMM with 1 grouping factor + 8 fixed-effect
> covariates.
> > One of the fixed effects, namely x2, has three unordered categories. This
> > is the covariate for whose 2 non-reference categories I want to estimate
> > random slopes, along with the random intercepts with which I don't expect
> > the slopes to be correlated. But I fail:
> >
> >
> >
> > *> VarCorr(glmer(y ~ (x2||id) + x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8,
> > family = binomial, data = mydata, control = glmerControl(optimizer =
> > "optimx", optCtrl = list(method = "nlm")), nAGQ = 1))*
> >
> >
> > *boundary (singular) fit: see help('isSingular')*
> >
> >
> >
> >
> > * Groups Name        Std.Dev. Corr        id     (Intercept) 0.00000
> >         id.1   x2A         0.76331                     x2B
>  0.75422
> >   0.931              x2C         0.56139  0.807 0.967*
> >
> > ^ Why is it reporting correlations when I told it not to? And why is it
> > reporting the intercept variance as zero (which is wholly implausible)?
> And
> > why is it reporting a "random slope" for the reference category of x2?
> It's
> > the reference category, for crying out loud! It's not supposed to get an
> > estimate.
> >
> > Consultation of the lme4 manual
> > <https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf> (page
> 7)
> > suggests the following alternative syntax for specifying random slopes
> > uncorrelated with the random intercepts:
> >
> > *> VarCorr(glmer(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + (1|id) +
> > (0+x2|id), family = binomial, data = mydata, control =
> > glmerControl(optimizer = "optimx", optCtrl = list(method = "nlm")), nAGQ
> =
> > 1))*
> >
> > *boundary (singular) fit: see help('isSingular')*
> >
> >
> >
> >
> >
> > * Groups Name        Std.Dev. Corr        id     (Intercept) 0.00000
> >         id.1   x2A         0.76331                     x2B
>  0.75422
> >   0.931              x2C         0.56139  0.807 0.967*
> >
> > ^ The exact same strangeness persists. Correlations are being estimated
> > against my wishes, and there's a nonsensical parameter supposedly
> > ostensibly representing the reference category, plus an implausible zero
> > value reported on the random intercepts. What am I doing wrong?
> >
> > Best,
> >
> > Juho
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Fri Aug  5 00:12:23 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 4 Aug 2022 18:12:23 -0400
Subject: [R-sig-ME] 
 Problem specifying uncorrelated random intercepts and
 slopes for a multi-df covariate
In-Reply-To: <CAG_dBVdk7XLaSxOOkwG_LEiSwff2tfEW8EADcUgtbPU7navJWw@mail.gmail.com>
References: <CAG_dBVdx-+dH5yxn-YVCuOi4m9Ve18-2Ewv-F9wCx4+U8JfL=g@mail.gmail.com>
 <90cfef32-6f08-f853-39bb-3cc8c8dc026f@gmail.com>
 <CAG_dBVdk7XLaSxOOkwG_LEiSwff2tfEW8EADcUgtbPU7navJWw@mail.gmail.com>
Message-ID: <c725f0e4-8b52-c9b4-d24d-3da6d3eb1b03@gmail.com>

   I will take a look if I get a chance.

   "Singular" isn't quite the same as "inestimable", I think (although 
to be honest I'm not sure what your definition of "inestimable" is). It 
just means that the best estimate is on the boundary of the feasible 
space. There are various more and less mathy ways of 
restating/explaining that, one simple example is if you have a single 
grouping variable; if true between-group variance is v_b and true 
within-group variance is v_w, and there are N samples per group, the 
expected *observed* among-group variation+ is v_b + v_w/n. If the sample 
variance within groups is v'_w and the sample variance among groups is 
LESS THAN v'_w/n, then your best conclusion is that the between-group 
variance is negative! (or zero, if you're not allowing such 
impossibilities).

   Singular fits are most common when the model is overfitted (too much 
complexity/too much noise/not enough signal/not enough groups), but can 
happen in many different circumstances.

   When I try to retrieve your data file the web page says it has been 
deleted.



On 2022-08-04 11:07 a.m., Juho Kristian Ruohonen wrote:
> Many thanks, Ben and Jo?o. I did as advised, converting x2 into two dummies
> and specifying the random effects as *(x2B+x2C||id)*. This yields the
> correct number of estimated parameters (1 random intercepts, 2 random
> slopes). However, there's something I don't understand about the results.
> 
> Firstly, there's a warning about a singular fit, which I take to mean that
> some parameters are inestimable. Judging from the following output, I
> gather that it must be the 2 random slopes, which are estimated at
> essentially zero:
> 
> *> summary(slopes.nocorr)*
> *...*
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> *Random effects: Groups Name        Variance  Std.Dev.  id     (Intercept)
> 5.539e-01 7.443e-01 id.1   x2B         1.546e-14 1.243e-07 id.2   x2C
>    0.000e+00 0.000e+00Number of obs: 1405, groups:  id, 292Fixed effects:
>          Estimate Std. Error z value Pr(>|z|)    (Intercept) -0.93057
>   0.27450  -3.390 0.000699 ***x1           0.51158    0.26550   1.927
> 0.053997 .  x2B          2.54505    0.20936  12.156  < 2e-16 ***x2C
>   2.30179    0.30480   7.552 4.29e-14 ***x3          -0.77494    0.11660
>   -6.646 3.01e-11 ***x4           0.24489    0.04957   4.940 7.80e-07 ***x5
>            0.28619    0.13810   2.072 0.038235 *  x6          -1.07816
>   0.90224  -1.195 0.232091    x7          -0.67521    0.32810  -2.058
> 0.039595 *  *
> *x8          -0.76275    0.28824  -2.646 0.008138 ** *
> 
> It seems very strange that the random slopes should be inestimable: x2B and
> x2C are not exceedingly scarce conditions: there are 277 observations of
> the former, 91 of the latter. There are 52 IDs with observations of both xB
> = 1 and xB = 0. And there are 33 IDs with observations of both xC = 1 and
> xC = 0. So, I don't understand why the random slopes couldn't be estimated.
> 
> Stranger still, if I fit an otherwise identical model with *correlated* random
> effects, the random-slope estimates suddenly do differ from 0 (although
> there's still a singularity warning). Like so:
> 
> *> slopes.corr <-   glmer(y ~ (x2B+x2C|id)  + x1 + x2B + x2C + x3 + x4 + x5
> + x6 + x7 + x8, family = binomial, data = mydata, control =
> glmerControl(optimizer = "optimx", optCtrl = list(method = "nlm")), nAGQ =
> 1)*
> *...*
> 
> 
> 
> 
> 
> 
> *Random effects: Groups Name        Variance Std.Dev. Corr        id
> (Intercept) 0.5827   0.7633                      x2B         0.0798
> 0.2825   -0.22              x2C         0.2060   0.4539   -0.68  0.86Number
> of obs: 1405, groups:  id, 292*
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> *Fixed effects:            Estimate Std. Error z value Pr(>|z|)
>   (Intercept) -0.98131    0.30416  -3.226  0.00125 ** x1           0.56391
>   0.29692   1.899  0.05754 .  x2B          2.56529    0.28735   8.928  <
> 2e-16 ***x2C          2.17394    0.41814   5.199 2.00e-07 ***x3
>   -0.77852    0.11699  -6.655 2.84e-11 ***x4           0.24384    0.04982
> 4.895 9.84e-07 ***x5           0.28790    0.14005   2.056  0.03981 *  x6
>         -1.08438    0.91036  -1.191  0.23359    x7          -0.66753
>   0.32962  -2.025  0.04285 *  x8          -0.75425    0.28913  -2.609
>   0.00909 ** *
> 
> It boggles my mind that the 2 random slopes should be inestimable in the
> simpler model (with no correlation params) but somehow become estimable
> when you introduce 3 more parameters by allowing random-effect
> correlations. My brain has melted. Does anyone have a clue what's going on?
> The anonymized datafile is available here <https://file.io/VKruszwJBwcK>.
> 
> Best,
> 
> Juho
> 
> 
> 
> to 4. elok. 2022 klo 0.30 Jo?o Ver?ssimo (jl.verissimo at gmail.com) kirjoitti:
> 
>> (1+x2 || id) is shorter notation for (1 | id) + (0 + x2 | id ).
>> And because x2 is a factor, suppressing the intercept leads to the
>> 'cell-mean coding' of x2: what is being estimated is the between-id
>> variation around the means of each level, A, B, and C (and their
>> correlation).
>>
>> In order to get what you want, turn x2 into two numeric variables
>> according to its contrasts. For example:
>> x2num1 <- ifelse(x2=="B", 1, 0)
>> x2num2 <- ifelse(x2=="C", 1, 0)
>>
>> Then (1 + x2num1 + x2num2 || id) will give you the random intercept, two
>> random slopes and no correlations.
>>
>> Jo?o
>>
>> On 03/08/2022 21:10, Juho Kristian Ruohonen wrote:
>>> Dear List,
>>>
>>> This is a logistic GLMM with 1 grouping factor + 8 fixed-effect
>> covariates.
>>> One of the fixed effects, namely x2, has three unordered categories. This
>>> is the covariate for whose 2 non-reference categories I want to estimate
>>> random slopes, along with the random intercepts with which I don't expect
>>> the slopes to be correlated. But I fail:
>>>
>>>
>>>
>>> *> VarCorr(glmer(y ~ (x2||id) + x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8,
>>> family = binomial, data = mydata, control = glmerControl(optimizer =
>>> "optimx", optCtrl = list(method = "nlm")), nAGQ = 1))*
>>>
>>>
>>> *boundary (singular) fit: see help('isSingular')*
>>>
>>>
>>>
>>>
>>> * Groups Name        Std.Dev. Corr        id     (Intercept) 0.00000
>>>          id.1   x2A         0.76331                     x2B
>>   0.75422
>>>    0.931              x2C         0.56139  0.807 0.967*
>>>
>>> ^ Why is it reporting correlations when I told it not to? And why is it
>>> reporting the intercept variance as zero (which is wholly implausible)?
>> And
>>> why is it reporting a "random slope" for the reference category of x2?
>> It's
>>> the reference category, for crying out loud! It's not supposed to get an
>>> estimate.
>>>
>>> Consultation of the lme4 manual
>>> <https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf> (page
>> 7)
>>> suggests the following alternative syntax for specifying random slopes
>>> uncorrelated with the random intercepts:
>>>
>>> *> VarCorr(glmer(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + (1|id) +
>>> (0+x2|id), family = binomial, data = mydata, control =
>>> glmerControl(optimizer = "optimx", optCtrl = list(method = "nlm")), nAGQ
>> =
>>> 1))*
>>>
>>> *boundary (singular) fit: see help('isSingular')*
>>>
>>>
>>>
>>>
>>>
>>> * Groups Name        Std.Dev. Corr        id     (Intercept) 0.00000
>>>          id.1   x2A         0.76331                     x2B
>>   0.75422
>>>    0.931              x2C         0.56139  0.807 0.967*
>>>
>>> ^ The exact same strangeness persists. Correlations are being estimated
>>> against my wishes, and there's a nonsensical parameter supposedly
>>> ostensibly representing the reference category, plus an implausible zero
>>> value reported on the random intercepts. What am I doing wrong?
>>>
>>> Best,
>>>
>>> Juho
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics
 > E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From r@turner @end|ng |rom @uck|@nd@@c@nz  Fri Aug  5 08:10:19 2022
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Fri, 5 Aug 2022 18:10:19 +1200
Subject: [R-sig-ME] Cannot grok the newdata argument in simulate.merMod(),
 package  lme4
Message-ID: <20220805181019.7c10f198@rolf-Latitude-E7470>



I wish to assess, via simulation, the impact of certain aspects
of the experimental design on the precision of the estimates of
a rather intricate parameter, the details of which I won't go into.

To this end I need to fit a model (generalised linear mixed model,
binomial family) to a data set, and then simulate other data sets,
reflecting a number of different experimental designs, from the given
fit.  I thought that the "newdata" argument of the simulate.merMod()
method would provide me with the means to accomplish my goal, but I
cannot get it to work.  I cannot properly comprehend the documentation
of the "newdata" argument in the help file.

To start with, to make sure (???) that I understood what was going on
I just simulated a data set from a model fitted to the cbpp data,
using a "roll-your-own" procedure, and then re-did the simulation
using simulate.merMod().  I set seeds appropriately so that I would get
the same results, given that my roll-your-own procedure was correct.
After many false starts and excursions down blind alleys, I got the two
procedures to agree.  The details of what I did are to be found in the
attached sourceable script "demo.txt".

I then attempted to effect simulations using a different data set "X"
(just including predictors, no responses) constructed according to
a different experimental design.

I tried two different approaches.  The first approach:

s.mer1 <- simulate(fit,newdata=X,allow.new.levels=TRUE)

This produced an ominous warning:
> In wts - Y :
>   longer object length is not a multiple of shorter object length

The second approach:

newpar <- list(theta=getME(fit,"theta"),beta=getME(fit,"beta"))
set.seed(101)
s.mer2 <- simulate(~0+period +(1|herd),newdata=X,newparams=newpar)

This produced warnings:

> beta parameter vector not named: assuming same order as internal
> vector
> Warning message:
> In setParams(object, newparams) :
>   some parameters not specified in setParams()

The first bit ("beta parameter vector not named ...") also happens if I
try to reproduce exactly an example given in the help, so perhaps I
should not be too worried by it.  The second bit is ominous (and to
me mysterious).

The result of the first approach is incomprehensible to me, and bears
no relationship that I can discern to the results of a roll-your-own
approach that I also tried.  The result of the second approach is all
NAs, so something is clearly wrong.

The details of what I did are given in the attached file
"try.newdata.txt".

I would be ever-so-humbly grateful if someone could explain to me what
I am doing wrong in my attempts to use the "newdata" argument of
simulate.merMod().

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: demo.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20220805/0dd21eaf/attachment-0002.txt>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: try.newdata.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20220805/0dd21eaf/attachment-0003.txt>

From juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com  Fri Aug  5 16:16:54 2022
From: juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com (Juho Kristian Ruohonen)
Date: Fri, 5 Aug 2022 17:16:54 +0300
Subject: [R-sig-ME] 
 Problem specifying uncorrelated random intercepts and
 slopes for a multi-df covariate
In-Reply-To: <c725f0e4-8b52-c9b4-d24d-3da6d3eb1b03@gmail.com>
References: <CAG_dBVdx-+dH5yxn-YVCuOi4m9Ve18-2Ewv-F9wCx4+U8JfL=g@mail.gmail.com>
 <90cfef32-6f08-f853-39bb-3cc8c8dc026f@gmail.com>
 <CAG_dBVdk7XLaSxOOkwG_LEiSwff2tfEW8EADcUgtbPU7navJWw@mail.gmail.com>
 <c725f0e4-8b52-c9b4-d24d-3da6d3eb1b03@gmail.com>
Message-ID: <CAG_dBVftG4FxbPtT89zXXBP3GdheFOHsjw+X-9uQLPGdkw6WBw@mail.gmail.com>

Many thanks, Ben. While I find your example of singularity a bit hard to
follow, I hope to have correctly identified a gist of "not enough data to
observe/estimate between-cluster variation in the slopes of x2B and x2C."

Even if that explains the zero estimates though, the fact that those
estimates become non-zero after adding correlation parameters remains
completely mystifying to me.

I've now switched to a different file hosting service: hopefully my dataset
<https://gofile.io/d/pS7O1Q> doesn't get deleted this time.

Best,

Juho



pe 5. elok. 2022 klo 1.12 Ben Bolker (bbolker at gmail.com) kirjoitti:

>    I will take a look if I get a chance.
>
>    "Singular" isn't quite the same as "inestimable", I think (although
> to be honest I'm not sure what your definition of "inestimable" is). It
> just means that the best estimate is on the boundary of the feasible
> space. There are various more and less mathy ways of
> restating/explaining that, one simple example is if you have a single
> grouping variable; if true between-group variance is v_b and true
> within-group variance is v_w, and there are N samples per group, the
> expected *observed* among-group variation+ is v_b + v_w/n. If the sample
> variance within groups is v'_w and the sample variance among groups is
> LESS THAN v'_w/n, then your best conclusion is that the between-group
> variance is negative! (or zero, if you're not allowing such
> impossibilities).
>
>    Singular fits are most common when the model is overfitted (too much
> complexity/too much noise/not enough signal/not enough groups), but can
> happen in many different circumstances.
>
>    When I try to retrieve your data file the web page says it has been
> deleted.
>
>
>
> On 2022-08-04 11:07 a.m., Juho Kristian Ruohonen wrote:
> > Many thanks, Ben and Jo?o. I did as advised, converting x2 into two
> dummies
> > and specifying the random effects as *(x2B+x2C||id)*. This yields the
> > correct number of estimated parameters (1 random intercepts, 2 random
> > slopes). However, there's something I don't understand about the results.
> >
> > Firstly, there's a warning about a singular fit, which I take to mean
> that
> > some parameters are inestimable. Judging from the following output, I
> > gather that it must be the 2 random slopes, which are estimated at
> > essentially zero:
> >
> > *> summary(slopes.nocorr)*
> > *...*
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> > *Random effects: Groups Name        Variance  Std.Dev.  id
>  (Intercept)
> > 5.539e-01 7.443e-01 id.1   x2B         1.546e-14 1.243e-07 id.2   x2C
> >    0.000e+00 0.000e+00Number of obs: 1405, groups:  id, 292Fixed effects:
> >          Estimate Std. Error z value Pr(>|z|)    (Intercept) -0.93057
> >   0.27450  -3.390 0.000699 ***x1           0.51158    0.26550   1.927
> > 0.053997 .  x2B          2.54505    0.20936  12.156  < 2e-16 ***x2C
> >   2.30179    0.30480   7.552 4.29e-14 ***x3          -0.77494    0.11660
> >   -6.646 3.01e-11 ***x4           0.24489    0.04957   4.940 7.80e-07
> ***x5
> >            0.28619    0.13810   2.072 0.038235 *  x6          -1.07816
> >   0.90224  -1.195 0.232091    x7          -0.67521    0.32810  -2.058
> > 0.039595 *  *
> > *x8          -0.76275    0.28824  -2.646 0.008138 ** *
> >
> > It seems very strange that the random slopes should be inestimable: x2B
> and
> > x2C are not exceedingly scarce conditions: there are 277 observations of
> > the former, 91 of the latter. There are 52 IDs with observations of both
> xB
> > = 1 and xB = 0. And there are 33 IDs with observations of both xC = 1 and
> > xC = 0. So, I don't understand why the random slopes couldn't be
> estimated.
> >
> > Stranger still, if I fit an otherwise identical model with *correlated*
> random
> > effects, the random-slope estimates suddenly do differ from 0 (although
> > there's still a singularity warning). Like so:
> >
> > *> slopes.corr <-   glmer(y ~ (x2B+x2C|id)  + x1 + x2B + x2C + x3 + x4 +
> x5
> > + x6 + x7 + x8, family = binomial, data = mydata, control =
> > glmerControl(optimizer = "optimx", optCtrl = list(method = "nlm")), nAGQ
> =
> > 1)*
> > *...*
> >
> >
> >
> >
> >
> >
> > *Random effects: Groups Name        Variance Std.Dev. Corr        id
> > (Intercept) 0.5827   0.7633                      x2B         0.0798
> > 0.2825   -0.22              x2C         0.2060   0.4539   -0.68
> 0.86Number
> > of obs: 1405, groups:  id, 292*
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> > *Fixed effects:            Estimate Std. Error z value Pr(>|z|)
> >   (Intercept) -0.98131    0.30416  -3.226  0.00125 ** x1
>  0.56391
> >   0.29692   1.899  0.05754 .  x2B          2.56529    0.28735   8.928  <
> > 2e-16 ***x2C          2.17394    0.41814   5.199 2.00e-07 ***x3
> >   -0.77852    0.11699  -6.655 2.84e-11 ***x4           0.24384    0.04982
> > 4.895 9.84e-07 ***x5           0.28790    0.14005   2.056  0.03981 *  x6
> >         -1.08438    0.91036  -1.191  0.23359    x7          -0.66753
> >   0.32962  -2.025  0.04285 *  x8          -0.75425    0.28913  -2.609
> >   0.00909 ** *
> >
> > It boggles my mind that the 2 random slopes should be inestimable in the
> > simpler model (with no correlation params) but somehow become estimable
> > when you introduce 3 more parameters by allowing random-effect
> > correlations. My brain has melted. Does anyone have a clue what's going
> on?
> > The anonymized datafile is available here <https://file.io/VKruszwJBwcK
> >.
> >
> > Best,
> >
> > Juho
> >
> >
> >
> > to 4. elok. 2022 klo 0.30 Jo?o Ver?ssimo (jl.verissimo at gmail.com)
> kirjoitti:
> >
> >> (1+x2 || id) is shorter notation for (1 | id) + (0 + x2 | id ).
> >> And because x2 is a factor, suppressing the intercept leads to the
> >> 'cell-mean coding' of x2: what is being estimated is the between-id
> >> variation around the means of each level, A, B, and C (and their
> >> correlation).
> >>
> >> In order to get what you want, turn x2 into two numeric variables
> >> according to its contrasts. For example:
> >> x2num1 <- ifelse(x2=="B", 1, 0)
> >> x2num2 <- ifelse(x2=="C", 1, 0)
> >>
> >> Then (1 + x2num1 + x2num2 || id) will give you the random intercept, two
> >> random slopes and no correlations.
> >>
> >> Jo?o
> >>
> >> On 03/08/2022 21:10, Juho Kristian Ruohonen wrote:
> >>> Dear List,
> >>>
> >>> This is a logistic GLMM with 1 grouping factor + 8 fixed-effect
> >> covariates.
> >>> One of the fixed effects, namely x2, has three unordered categories.
> This
> >>> is the covariate for whose 2 non-reference categories I want to
> estimate
> >>> random slopes, along with the random intercepts with which I don't
> expect
> >>> the slopes to be correlated. But I fail:
> >>>
> >>>
> >>>
> >>> *> VarCorr(glmer(y ~ (x2||id) + x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8,
> >>> family = binomial, data = mydata, control = glmerControl(optimizer =
> >>> "optimx", optCtrl = list(method = "nlm")), nAGQ = 1))*
> >>>
> >>>
> >>> *boundary (singular) fit: see help('isSingular')*
> >>>
> >>>
> >>>
> >>>
> >>> * Groups Name        Std.Dev. Corr        id     (Intercept) 0.00000
> >>>          id.1   x2A         0.76331                     x2B
> >>   0.75422
> >>>    0.931              x2C         0.56139  0.807 0.967*
> >>>
> >>> ^ Why is it reporting correlations when I told it not to? And why is it
> >>> reporting the intercept variance as zero (which is wholly implausible)?
> >> And
> >>> why is it reporting a "random slope" for the reference category of x2?
> >> It's
> >>> the reference category, for crying out loud! It's not supposed to get
> an
> >>> estimate.
> >>>
> >>> Consultation of the lme4 manual
> >>> <https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf>
> (page
> >> 7)
> >>> suggests the following alternative syntax for specifying random slopes
> >>> uncorrelated with the random intercepts:
> >>>
> >>> *> VarCorr(glmer(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + (1|id) +
> >>> (0+x2|id), family = binomial, data = mydata, control =
> >>> glmerControl(optimizer = "optimx", optCtrl = list(method = "nlm")),
> nAGQ
> >> =
> >>> 1))*
> >>>
> >>> *boundary (singular) fit: see help('isSingular')*
> >>>
> >>>
> >>>
> >>>
> >>>
> >>> * Groups Name        Std.Dev. Corr        id     (Intercept) 0.00000
> >>>          id.1   x2A         0.76331                     x2B
> >>   0.75422
> >>>    0.931              x2C         0.56139  0.807 0.967*
> >>>
> >>> ^ The exact same strangeness persists. Correlations are being estimated
> >>> against my wishes, and there's a nonsensical parameter supposedly
> >>> ostensibly representing the reference category, plus an implausible
> zero
> >>> value reported on the random intercepts. What am I doing wrong?
> >>>
> >>> Best,
> >>>
> >>> Juho
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> (Acting) Graduate chair, Mathematics & Statistics
>  > E-mail is sent at my convenience; I don't expect replies outside of
> working hours.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From j|@ver|@@|mo @end|ng |rom gm@||@com  Fri Aug  5 16:57:34 2022
From: j|@ver|@@|mo @end|ng |rom gm@||@com (=?UTF-8?Q?Jo=c3=a3o_Ver=c3=adssimo?=)
Date: Fri, 5 Aug 2022 16:57:34 +0200
Subject: [R-sig-ME] 
 Problem specifying uncorrelated random intercepts and
 slopes for a multi-df covariate
In-Reply-To: <CAG_dBVftG4FxbPtT89zXXBP3GdheFOHsjw+X-9uQLPGdkw6WBw@mail.gmail.com>
References: <CAG_dBVdx-+dH5yxn-YVCuOi4m9Ve18-2Ewv-F9wCx4+U8JfL=g@mail.gmail.com>
 <90cfef32-6f08-f853-39bb-3cc8c8dc026f@gmail.com>
 <CAG_dBVdk7XLaSxOOkwG_LEiSwff2tfEW8EADcUgtbPU7navJWw@mail.gmail.com>
 <c725f0e4-8b52-c9b4-d24d-3da6d3eb1b03@gmail.com>
 <CAG_dBVftG4FxbPtT89zXXBP3GdheFOHsjw+X-9uQLPGdkw6WBw@mail.gmail.com>
Message-ID: <59d70248-befa-a00b-f936-e72bbaf754c1@gmail.com>

Including correlation parameters can "pull" random effects (so to speak) 
in the direction of the estimated correlation. See here:
https://doingbayesiandataanalysis.blogspot.com/2019/07/shrinkage-in-hierarchical-models-random.html

So perhaps the slopes are changing quite a bit due to their correlation 
with the intercept?
You could do some experimentation to test this, for example, keeping the 
correlation between slopes, but removing the intercept-slope correlations.
Maybe something like this would do it: (1 | id) + (0 + x2B + x2C | id)

(that said, it does seem a bit strange to me that both of them are zero 
when not estimating correlations)

Jo?o

On 05/08/2022 16:16, Juho Kristian Ruohonen wrote:
> Many thanks, Ben. While I find your example of singularity a bit hard to
> follow, I hope to have correctly identified a gist of "not enough data to
> observe/estimate between-cluster variation in the slopes of x2B and x2C."
>
> Even if that explains the zero estimates though, the fact that those
> estimates become non-zero after adding correlation parameters remains
> completely mystifying to me.
>
> I've now switched to a different file hosting service: hopefully my dataset
> <https://gofile.io/d/pS7O1Q> doesn't get deleted this time.
>
> Best,
>
> Juho
>
>
>
> pe 5. elok. 2022 klo 1.12 Ben Bolker (bbolker at gmail.com) kirjoitti:
>
>>     I will take a look if I get a chance.
>>
>>     "Singular" isn't quite the same as "inestimable", I think (although
>> to be honest I'm not sure what your definition of "inestimable" is). It
>> just means that the best estimate is on the boundary of the feasible
>> space. There are various more and less mathy ways of
>> restating/explaining that, one simple example is if you have a single
>> grouping variable; if true between-group variance is v_b and true
>> within-group variance is v_w, and there are N samples per group, the
>> expected *observed* among-group variation+ is v_b + v_w/n. If the sample
>> variance within groups is v'_w and the sample variance among groups is
>> LESS THAN v'_w/n, then your best conclusion is that the between-group
>> variance is negative! (or zero, if you're not allowing such
>> impossibilities).
>>
>>     Singular fits are most common when the model is overfitted (too much
>> complexity/too much noise/not enough signal/not enough groups), but can
>> happen in many different circumstances.
>>
>>     When I try to retrieve your data file the web page says it has been
>> deleted.
>>
>>
>>
>> On 2022-08-04 11:07 a.m., Juho Kristian Ruohonen wrote:
>>> Many thanks, Ben and Jo?o. I did as advised, converting x2 into two
>> dummies
>>> and specifying the random effects as *(x2B+x2C||id)*. This yields the
>>> correct number of estimated parameters (1 random intercepts, 2 random
>>> slopes). However, there's something I don't understand about the results.
>>>
>>> Firstly, there's a warning about a singular fit, which I take to mean
>> that
>>> some parameters are inestimable. Judging from the following output, I
>>> gather that it must be the 2 random slopes, which are estimated at
>>> essentially zero:
>>>
>>> *> summary(slopes.nocorr)*
>>> *...*
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> *Random effects: Groups Name        Variance  Std.Dev.  id
>>   (Intercept)
>>> 5.539e-01 7.443e-01 id.1   x2B         1.546e-14 1.243e-07 id.2   x2C
>>>     0.000e+00 0.000e+00Number of obs: 1405, groups:  id, 292Fixed effects:
>>>           Estimate Std. Error z value Pr(>|z|)    (Intercept) -0.93057
>>>    0.27450  -3.390 0.000699 ***x1           0.51158    0.26550   1.927
>>> 0.053997 .  x2B          2.54505    0.20936  12.156  < 2e-16 ***x2C
>>>    2.30179    0.30480   7.552 4.29e-14 ***x3          -0.77494    0.11660
>>>    -6.646 3.01e-11 ***x4           0.24489    0.04957   4.940 7.80e-07
>> ***x5
>>>             0.28619    0.13810   2.072 0.038235 *  x6          -1.07816
>>>    0.90224  -1.195 0.232091    x7          -0.67521    0.32810  -2.058
>>> 0.039595 *  *
>>> *x8          -0.76275    0.28824  -2.646 0.008138 ** *
>>>
>>> It seems very strange that the random slopes should be inestimable: x2B
>> and
>>> x2C are not exceedingly scarce conditions: there are 277 observations of
>>> the former, 91 of the latter. There are 52 IDs with observations of both
>> xB
>>> = 1 and xB = 0. And there are 33 IDs with observations of both xC = 1 and
>>> xC = 0. So, I don't understand why the random slopes couldn't be
>> estimated.
>>> Stranger still, if I fit an otherwise identical model with *correlated*
>> random
>>> effects, the random-slope estimates suddenly do differ from 0 (although
>>> there's still a singularity warning). Like so:
>>>
>>> *> slopes.corr <-   glmer(y ~ (x2B+x2C|id)  + x1 + x2B + x2C + x3 + x4 +
>> x5
>>> + x6 + x7 + x8, family = binomial, data = mydata, control =
>>> glmerControl(optimizer = "optimx", optCtrl = list(method = "nlm")), nAGQ
>> =
>>> 1)*
>>> *...*
>>>
>>>
>>>
>>>
>>>
>>>
>>> *Random effects: Groups Name        Variance Std.Dev. Corr        id
>>> (Intercept) 0.5827   0.7633                      x2B         0.0798
>>> 0.2825   -0.22              x2C         0.2060   0.4539   -0.68
>> 0.86Number
>>> of obs: 1405, groups:  id, 292*
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> *Fixed effects:            Estimate Std. Error z value Pr(>|z|)
>>>    (Intercept) -0.98131    0.30416  -3.226  0.00125 ** x1
>>   0.56391
>>>    0.29692   1.899  0.05754 .  x2B          2.56529    0.28735   8.928  <
>>> 2e-16 ***x2C          2.17394    0.41814   5.199 2.00e-07 ***x3
>>>    -0.77852    0.11699  -6.655 2.84e-11 ***x4           0.24384    0.04982
>>> 4.895 9.84e-07 ***x5           0.28790    0.14005   2.056  0.03981 *  x6
>>>          -1.08438    0.91036  -1.191  0.23359    x7          -0.66753
>>>    0.32962  -2.025  0.04285 *  x8          -0.75425    0.28913  -2.609
>>>    0.00909 ** *
>>>
>>> It boggles my mind that the 2 random slopes should be inestimable in the
>>> simpler model (with no correlation params) but somehow become estimable
>>> when you introduce 3 more parameters by allowing random-effect
>>> correlations. My brain has melted. Does anyone have a clue what's going
>> on?
>>> The anonymized datafile is available here <https://file.io/VKruszwJBwcK
>>> .
>>>
>>> Best,
>>>
>>> Juho
>>>
>>>
>>>
>>> to 4. elok. 2022 klo 0.30 Jo?o Ver?ssimo (jl.verissimo at gmail.com)
>> kirjoitti:
>>>> (1+x2 || id) is shorter notation for (1 | id) + (0 + x2 | id ).
>>>> And because x2 is a factor, suppressing the intercept leads to the
>>>> 'cell-mean coding' of x2: what is being estimated is the between-id
>>>> variation around the means of each level, A, B, and C (and their
>>>> correlation).
>>>>
>>>> In order to get what you want, turn x2 into two numeric variables
>>>> according to its contrasts. For example:
>>>> x2num1 <- ifelse(x2=="B", 1, 0)
>>>> x2num2 <- ifelse(x2=="C", 1, 0)
>>>>
>>>> Then (1 + x2num1 + x2num2 || id) will give you the random intercept, two
>>>> random slopes and no correlations.
>>>>
>>>> Jo?o
>>>>
>>>> On 03/08/2022 21:10, Juho Kristian Ruohonen wrote:
>>>>> Dear List,
>>>>>
>>>>> This is a logistic GLMM with 1 grouping factor + 8 fixed-effect
>>>> covariates.
>>>>> One of the fixed effects, namely x2, has three unordered categories.
>> This
>>>>> is the covariate for whose 2 non-reference categories I want to
>> estimate
>>>>> random slopes, along with the random intercepts with which I don't
>> expect
>>>>> the slopes to be correlated. But I fail:
>>>>>
>>>>>
>>>>>
>>>>> *> VarCorr(glmer(y ~ (x2||id) + x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8,
>>>>> family = binomial, data = mydata, control = glmerControl(optimizer =
>>>>> "optimx", optCtrl = list(method = "nlm")), nAGQ = 1))*
>>>>>
>>>>>
>>>>> *boundary (singular) fit: see help('isSingular')*
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> * Groups Name        Std.Dev. Corr        id     (Intercept) 0.00000
>>>>>           id.1   x2A         0.76331                     x2B
>>>>    0.75422
>>>>>     0.931              x2C         0.56139  0.807 0.967*
>>>>>
>>>>> ^ Why is it reporting correlations when I told it not to? And why is it
>>>>> reporting the intercept variance as zero (which is wholly implausible)?
>>>> And
>>>>> why is it reporting a "random slope" for the reference category of x2?
>>>> It's
>>>>> the reference category, for crying out loud! It's not supposed to get
>> an
>>>>> estimate.
>>>>>
>>>>> Consultation of the lme4 manual
>>>>> <https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf>
>> (page
>>>> 7)
>>>>> suggests the following alternative syntax for specifying random slopes
>>>>> uncorrelated with the random intercepts:
>>>>>
>>>>> *> VarCorr(glmer(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + (1|id) +
>>>>> (0+x2|id), family = binomial, data = mydata, control =
>>>>> glmerControl(optimizer = "optimx", optCtrl = list(method = "nlm")),
>> nAGQ
>>>> =
>>>>> 1))*
>>>>>
>>>>> *boundary (singular) fit: see help('isSingular')*
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> * Groups Name        Std.Dev. Corr        id     (Intercept) 0.00000
>>>>>           id.1   x2A         0.76331                     x2B
>>>>    0.75422
>>>>>     0.931              x2C         0.56139  0.807 0.967*
>>>>>
>>>>> ^ The exact same strangeness persists. Correlations are being estimated
>>>>> against my wishes, and there's a nonsensical parameter supposedly
>>>>> ostensibly representing the reference category, plus an implausible
>> zero
>>>>> value reported on the random intercepts. What am I doing wrong?
>>>>>
>>>>> Best,
>>>>>
>>>>> Juho
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> --
>> Dr. Benjamin Bolker
>> Professor, Mathematics & Statistics and Biology, McMaster University
>> Director, School of Computational Science and Engineering
>> (Acting) Graduate chair, Mathematics & Statistics
>>   > E-mail is sent at my convenience; I don't expect replies outside of
>> working hours.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com  Sun Aug  7 16:25:28 2022
From: juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com (Juho Kristian Ruohonen)
Date: Sun, 7 Aug 2022 17:25:28 +0300
Subject: [R-sig-ME] 
 Problem specifying uncorrelated random intercepts and
 slopes for a multi-df covariate
In-Reply-To: <59d70248-befa-a00b-f936-e72bbaf754c1@gmail.com>
References: <CAG_dBVdx-+dH5yxn-YVCuOi4m9Ve18-2Ewv-F9wCx4+U8JfL=g@mail.gmail.com>
 <90cfef32-6f08-f853-39bb-3cc8c8dc026f@gmail.com>
 <CAG_dBVdk7XLaSxOOkwG_LEiSwff2tfEW8EADcUgtbPU7navJWw@mail.gmail.com>
 <c725f0e4-8b52-c9b4-d24d-3da6d3eb1b03@gmail.com>
 <CAG_dBVftG4FxbPtT89zXXBP3GdheFOHsjw+X-9uQLPGdkw6WBw@mail.gmail.com>
 <59d70248-befa-a00b-f936-e72bbaf754c1@gmail.com>
Message-ID: <CAG_dBVeybLn0xpYOA8i8gH_qFf0JGTRMfvYwcjsa0Jiy8mMJGg@mail.gmail.com>

Thanks Jo?o. That's a cool page with all the illustrations, although I
still can't claim to quite get it.

I'd assume that in order for the random slopes to correlate with the
intercepts, they would first have to be estimated at some non-zero value.
THEN I see how a correlation could arise and how the slopes could perhaps
be pulled towards that correlation. In the case at hand though, we have
random slopes that are essentially zero. Hence, I don't see how a
correlation with the intercepts could possibly arise. And without such a
correlation, I don't see how the slope estimates could be pulled towards
one.

I wonder if I'm missing something.

Best,

J



pe 5. elok. 2022 klo 17.57 Jo?o Ver?ssimo (jl.verissimo at gmail.com)
kirjoitti:

> Including correlation parameters can "pull" random effects (so to speak)
> in the direction of the estimated correlation. See here:
>
> https://doingbayesiandataanalysis.blogspot.com/2019/07/shrinkage-in-hierarchical-models-random.html
>
> So perhaps the slopes are changing quite a bit due to their correlation
> with the intercept?
> You could do some experimentation to test this, for example, keeping the
> correlation between slopes, but removing the intercept-slope correlations.
> Maybe something like this would do it: (1 | id) + (0 + x2B + x2C | id)
>
> (that said, it does seem a bit strange to me that both of them are zero
> when not estimating correlations)
>
> Jo?o
>
> On 05/08/2022 16:16, Juho Kristian Ruohonen wrote:
> > Many thanks, Ben. While I find your example of singularity a bit hard to
> > follow, I hope to have correctly identified a gist of "not enough data to
> > observe/estimate between-cluster variation in the slopes of x2B and x2C."
> >
> > Even if that explains the zero estimates though, the fact that those
> > estimates become non-zero after adding correlation parameters remains
> > completely mystifying to me.
> >
> > I've now switched to a different file hosting service: hopefully my
> dataset
> > <https://gofile.io/d/pS7O1Q> doesn't get deleted this time.
> >
> > Best,
> >
> > Juho
> >
> >
> >
> > pe 5. elok. 2022 klo 1.12 Ben Bolker (bbolker at gmail.com) kirjoitti:
> >
> >>     I will take a look if I get a chance.
> >>
> >>     "Singular" isn't quite the same as "inestimable", I think (although
> >> to be honest I'm not sure what your definition of "inestimable" is). It
> >> just means that the best estimate is on the boundary of the feasible
> >> space. There are various more and less mathy ways of
> >> restating/explaining that, one simple example is if you have a single
> >> grouping variable; if true between-group variance is v_b and true
> >> within-group variance is v_w, and there are N samples per group, the
> >> expected *observed* among-group variation+ is v_b + v_w/n. If the sample
> >> variance within groups is v'_w and the sample variance among groups is
> >> LESS THAN v'_w/n, then your best conclusion is that the between-group
> >> variance is negative! (or zero, if you're not allowing such
> >> impossibilities).
> >>
> >>     Singular fits are most common when the model is overfitted (too much
> >> complexity/too much noise/not enough signal/not enough groups), but can
> >> happen in many different circumstances.
> >>
> >>     When I try to retrieve your data file the web page says it has been
> >> deleted.
> >>
> >>
> >>
> >> On 2022-08-04 11:07 a.m., Juho Kristian Ruohonen wrote:
> >>> Many thanks, Ben and Jo?o. I did as advised, converting x2 into two
> >> dummies
> >>> and specifying the random effects as *(x2B+x2C||id)*. This yields the
> >>> correct number of estimated parameters (1 random intercepts, 2 random
> >>> slopes). However, there's something I don't understand about the
> results.
> >>>
> >>> Firstly, there's a warning about a singular fit, which I take to mean
> >> that
> >>> some parameters are inestimable. Judging from the following output, I
> >>> gather that it must be the 2 random slopes, which are estimated at
> >>> essentially zero:
> >>>
> >>> *> summary(slopes.nocorr)*
> >>> *...*
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>> *Random effects: Groups Name        Variance  Std.Dev.  id
> >>   (Intercept)
> >>> 5.539e-01 7.443e-01 id.1   x2B         1.546e-14 1.243e-07 id.2   x2C
> >>>     0.000e+00 0.000e+00Number of obs: 1405, groups:  id, 292Fixed
> effects:
> >>>           Estimate Std. Error z value Pr(>|z|)    (Intercept) -0.93057
> >>>    0.27450  -3.390 0.000699 ***x1           0.51158    0.26550   1.927
> >>> 0.053997 .  x2B          2.54505    0.20936  12.156  < 2e-16 ***x2C
> >>>    2.30179    0.30480   7.552 4.29e-14 ***x3          -0.77494
> 0.11660
> >>>    -6.646 3.01e-11 ***x4           0.24489    0.04957   4.940 7.80e-07
> >> ***x5
> >>>             0.28619    0.13810   2.072 0.038235 *  x6          -1.07816
> >>>    0.90224  -1.195 0.232091    x7          -0.67521    0.32810  -2.058
> >>> 0.039595 *  *
> >>> *x8          -0.76275    0.28824  -2.646 0.008138 ** *
> >>>
> >>> It seems very strange that the random slopes should be inestimable: x2B
> >> and
> >>> x2C are not exceedingly scarce conditions: there are 277 observations
> of
> >>> the former, 91 of the latter. There are 52 IDs with observations of
> both
> >> xB
> >>> = 1 and xB = 0. And there are 33 IDs with observations of both xC = 1
> and
> >>> xC = 0. So, I don't understand why the random slopes couldn't be
> >> estimated.
> >>> Stranger still, if I fit an otherwise identical model with *correlated*
> >> random
> >>> effects, the random-slope estimates suddenly do differ from 0 (although
> >>> there's still a singularity warning). Like so:
> >>>
> >>> *> slopes.corr <-   glmer(y ~ (x2B+x2C|id)  + x1 + x2B + x2C + x3 + x4
> +
> >> x5
> >>> + x6 + x7 + x8, family = binomial, data = mydata, control =
> >>> glmerControl(optimizer = "optimx", optCtrl = list(method = "nlm")),
> nAGQ
> >> =
> >>> 1)*
> >>> *...*
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>> *Random effects: Groups Name        Variance Std.Dev. Corr        id
> >>> (Intercept) 0.5827   0.7633                      x2B         0.0798
> >>> 0.2825   -0.22              x2C         0.2060   0.4539   -0.68
> >> 0.86Number
> >>> of obs: 1405, groups:  id, 292*
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>> *Fixed effects:            Estimate Std. Error z value Pr(>|z|)
> >>>    (Intercept) -0.98131    0.30416  -3.226  0.00125 ** x1
> >>   0.56391
> >>>    0.29692   1.899  0.05754 .  x2B          2.56529    0.28735
>  8.928  <
> >>> 2e-16 ***x2C          2.17394    0.41814   5.199 2.00e-07 ***x3
> >>>    -0.77852    0.11699  -6.655 2.84e-11 ***x4           0.24384
> 0.04982
> >>> 4.895 9.84e-07 ***x5           0.28790    0.14005   2.056  0.03981 *
> x6
> >>>          -1.08438    0.91036  -1.191  0.23359    x7          -0.66753
> >>>    0.32962  -2.025  0.04285 *  x8          -0.75425    0.28913  -2.609
> >>>    0.00909 ** *
> >>>
> >>> It boggles my mind that the 2 random slopes should be inestimable in
> the
> >>> simpler model (with no correlation params) but somehow become estimable
> >>> when you introduce 3 more parameters by allowing random-effect
> >>> correlations. My brain has melted. Does anyone have a clue what's going
> >> on?
> >>> The anonymized datafile is available here <
> https://file.io/VKruszwJBwcK
> >>> .
> >>>
> >>> Best,
> >>>
> >>> Juho
> >>>
> >>>
> >>>
> >>> to 4. elok. 2022 klo 0.30 Jo?o Ver?ssimo (jl.verissimo at gmail.com)
> >> kirjoitti:
> >>>> (1+x2 || id) is shorter notation for (1 | id) + (0 + x2 | id ).
> >>>> And because x2 is a factor, suppressing the intercept leads to the
> >>>> 'cell-mean coding' of x2: what is being estimated is the between-id
> >>>> variation around the means of each level, A, B, and C (and their
> >>>> correlation).
> >>>>
> >>>> In order to get what you want, turn x2 into two numeric variables
> >>>> according to its contrasts. For example:
> >>>> x2num1 <- ifelse(x2=="B", 1, 0)
> >>>> x2num2 <- ifelse(x2=="C", 1, 0)
> >>>>
> >>>> Then (1 + x2num1 + x2num2 || id) will give you the random intercept,
> two
> >>>> random slopes and no correlations.
> >>>>
> >>>> Jo?o
> >>>>
> >>>> On 03/08/2022 21:10, Juho Kristian Ruohonen wrote:
> >>>>> Dear List,
> >>>>>
> >>>>> This is a logistic GLMM with 1 grouping factor + 8 fixed-effect
> >>>> covariates.
> >>>>> One of the fixed effects, namely x2, has three unordered categories.
> >> This
> >>>>> is the covariate for whose 2 non-reference categories I want to
> >> estimate
> >>>>> random slopes, along with the random intercepts with which I don't
> >> expect
> >>>>> the slopes to be correlated. But I fail:
> >>>>>
> >>>>>
> >>>>>
> >>>>> *> VarCorr(glmer(y ~ (x2||id) + x1 + x2 + x3 + x4 + x5 + x6 + x7 +
> x8,
> >>>>> family = binomial, data = mydata, control = glmerControl(optimizer =
> >>>>> "optimx", optCtrl = list(method = "nlm")), nAGQ = 1))*
> >>>>>
> >>>>>
> >>>>> *boundary (singular) fit: see help('isSingular')*
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>> * Groups Name        Std.Dev. Corr        id     (Intercept) 0.00000
> >>>>>           id.1   x2A         0.76331                     x2B
> >>>>    0.75422
> >>>>>     0.931              x2C         0.56139  0.807 0.967*
> >>>>>
> >>>>> ^ Why is it reporting correlations when I told it not to? And why is
> it
> >>>>> reporting the intercept variance as zero (which is wholly
> implausible)?
> >>>> And
> >>>>> why is it reporting a "random slope" for the reference category of
> x2?
> >>>> It's
> >>>>> the reference category, for crying out loud! It's not supposed to get
> >> an
> >>>>> estimate.
> >>>>>
> >>>>> Consultation of the lme4 manual
> >>>>> <https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf>
> >> (page
> >>>> 7)
> >>>>> suggests the following alternative syntax for specifying random
> slopes
> >>>>> uncorrelated with the random intercepts:
> >>>>>
> >>>>> *> VarCorr(glmer(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + (1|id) +
> >>>>> (0+x2|id), family = binomial, data = mydata, control =
> >>>>> glmerControl(optimizer = "optimx", optCtrl = list(method = "nlm")),
> >> nAGQ
> >>>> =
> >>>>> 1))*
> >>>>>
> >>>>> *boundary (singular) fit: see help('isSingular')*
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>> * Groups Name        Std.Dev. Corr        id     (Intercept) 0.00000
> >>>>>           id.1   x2A         0.76331                     x2B
> >>>>    0.75422
> >>>>>     0.931              x2C         0.56139  0.807 0.967*
> >>>>>
> >>>>> ^ The exact same strangeness persists. Correlations are being
> estimated
> >>>>> against my wishes, and there's a nonsensical parameter supposedly
> >>>>> ostensibly representing the reference category, plus an implausible
> >> zero
> >>>>> value reported on the random intercepts. What am I doing wrong?
> >>>>>
> >>>>> Best,
> >>>>>
> >>>>> Juho
> >>>>>
> >>>>>         [[alternative HTML version deleted]]
> >>>>>
> >>>>> _______________________________________________
> >>>>> R-sig-mixed-models at r-project.org mailing list
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> --
> >> Dr. Benjamin Bolker
> >> Professor, Mathematics & Statistics and Biology, McMaster University
> >> Director, School of Computational Science and Engineering
> >> (Acting) Graduate chair, Mathematics & Statistics
> >>   > E-mail is sent at my convenience; I don't expect replies outside of
> >> working hours.
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Mon Aug  8 01:13:50 2022
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Mon, 8 Aug 2022 11:13:50 +1200
Subject: [R-sig-ME] Radio silence in re "newdata" argument of
 simulate.merMod().
Message-ID: <20220808111350.187cfc02@rolf-Latitude-E7470>


Three days ago I sent an email to r-sig-mixed-models asking what I was
doing wrong in my use of the "newdata" argument of simulate.merMod().

So far I have received no response at all.  This surprises me.  I
expected a quick reply, from Ben Bolker (or someone like him) to the
effect of "You absolute ninny.  *This* is (obviously!) the syntax that
you should be using."

Was my question unclear or too obscure or arcane?  If so, are there any
suggestions as to how I could be more perspicuous?

I really would appreciate some help.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From jhm@|ndon@|d @end|ng |rom gm@||@com  Mon Aug  8 04:12:40 2022
From: jhm@|ndon@|d @end|ng |rom gm@||@com (John H Maindonald)
Date: Mon, 8 Aug 2022 14:12:40 +1200
Subject: [R-sig-ME] Radio silence in re "newdata" argument of
 simulate.merMod().
In-Reply-To: <20220808111350.187cfc02@rolf-Latitude-E7470>
References: <20220808111350.187cfc02@rolf-Latitude-E7470>
Message-ID: <6651DD91-D166-4626-9120-3E3AB17634E9@gmail.com>

Assuming that you are simulating to allow "allow previously unobserved levels 
in random-effects variables?, have you set the factor level for the relevant factor
to ?new?. See the vignette `timeMortality` in the qra package for an example.

John Maindonald.

> On 8/08/2022, at 11:13, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> 
> Three days ago I sent an email to r-sig-mixed-models asking what I was
> doing wrong in my use of the "newdata" argument of simulate.merMod().
> 
> So far I have received no response at all.  This surprises me.  I
> expected a quick reply, from Ben Bolker (or someone like him) to the
> effect of "You absolute ninny.  *This* is (obviously!) the syntax that
> you should be using."
> 
> Was my question unclear or too obscure or arcane?  If so, are there any
> suggestions as to how I could be more perspicuous?
> 
> I really would appreciate some help.
> 
> cheers,
> 
> Rolf Turner
> 
> -- 
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From jhm@|ndon@|d @end|ng |rom gm@||@com  Mon Aug  8 05:00:26 2022
From: jhm@|ndon@|d @end|ng |rom gm@||@com (John H Maindonald)
Date: Mon, 8 Aug 2022 15:00:26 +1200
Subject: [R-sig-ME] Radio silence in re "newdata" argument of
 simulate.merMod(): PS
In-Reply-To: <20220808111350.187cfc02@rolf-Latitude-E7470>
References: <20220808111350.187cfc02@rolf-Latitude-E7470>
Message-ID: <E4C644C1-4C24-4E80-AF8E-33508146A3CA@gmail.com>

I read your message too casually, and failed to notice the attachments.
The issues may be that levels of `period` are not balanced within levels of
`herd`, either in `cbpp` or in `X`.  The following works:

library(lme4)
fit   <- glmer(cbind(incidence, size - incidence) ~ 0 + period + (1 | herd),
               family = binomial, data = cbpp)
X     <- subset(data.frame(herd=factor(rep(1:30,each=4)),size=rep(40,120), 
                        period=factor(rep(1:4,30))), herd==1)
X[,'herd'] <- rep(factor('new'),nrow(X))
s.mer1 <- simulate(fit,newdata=X,allow.new.levels=TRUE)

John Maindonald.

> On 8/08/2022, at 11:13, Rolf Turner <r.turner at auckland.ac.nz <mailto:r.turner at auckland.ac.nz>> wrote:
> 
> 
> Three days ago I sent an email to r-sig-mixed-models asking what I was
> doing wrong in my use of the "newdata" argument of simulate.merMod().
> 
> So far I have received no response at all.  This surprises me.  I
> expected a quick reply, from Ben Bolker (or someone like him) to the
> effect of "You absolute ninny.  *This* is (obviously!) the syntax that
> you should be using."
> 
> Was my question unclear or too obscure or arcane?  If so, are there any
> suggestions as to how I could be more perspicuous?
> 
> I really would appreciate some help.
> 
> cheers,
> 
> Rolf Turner
> 
> -- 
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>


	[[alternative HTML version deleted]]


From jhm@|ndon@|d @end|ng |rom gm@||@com  Mon Aug  8 08:02:10 2022
From: jhm@|ndon@|d @end|ng |rom gm@||@com (John H Maindonald)
Date: Mon, 8 Aug 2022 18:02:10 +1200
Subject: [R-sig-ME] Radio silence in re "newdata" argument of
 simulate.merMod(): PS2
In-Reply-To: <20220808111350.187cfc02@rolf-Latitude-E7470>
References: <20220808111350.187cfc02@rolf-Latitude-E7470>
Message-ID: <225DA381-09BE-4337-B5CD-E57F976DE8B1@gmail.com>

Maybe I will get it right this time:

The imbalance in cbpp is a side issue.  As I understand it, the issue
 is that one has the choice of simulating for a new level of herd,
(existing levels of herd are then for purposes of simulation irrelevant),
or simulating for existing levels. Rolf?s X, has 1:15 existing, and 16:30 new.

At least with the cbpp data, it appears that the newdata argument only works
with allow.new.levels=TRUE. I assume that one gets a new level for each
new simulation.

The following is a bit worrying:

X <- data.frame(herd=rep('new',4), size=rep(40,4), period=1:4)
s.mer1 <- simulate(fit,nsim=2,newdata=X,allow.new.levels=TRUE)
> s.mer1
  sim_1.incidence sim_1.V2 sim_2.incidence sim_2.V2
1               3       11               1       21
2               2       10               1       17
3               2        7               1       20
4               0        5               1       21
Warning message:
In format.data.frame(if (omit) x[seq_len(n0), , drop = FALSE] else x,  :
  corrupt data frame: columns will be truncated or padded with NAs

 I have lme4_1.1-30  and Matrix_1.4-1.

John Maindonald

> On 8/08/2022, at 11:13, Rolf Turner <r.turner at auckland.ac.nz <mailto:r.turner at auckland.ac.nz>> wrote:
> 
> 
> Three days ago I sent an email to r-sig-mixed-models asking what I was
> doing wrong in my use of the "newdata" argument of simulate.merMod().
> 
> So far I have received no response at all.  This surprises me.  I
> expected a quick reply, from Ben Bolker (or someone like him) to the
> effect of "You absolute ninny.  *This* is (obviously!) the syntax that
> you should be using."
> 
> Was my question unclear or too obscure or arcane?  If so, are there any
> suggestions as to how I could be more perspicuous?
> 
> I really would appreciate some help.
> 
> cheers,
> 
> Rolf Turner
> 
> -- 
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>


	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Tue Aug  9 07:19:48 2022
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Tue, 9 Aug 2022 17:19:48 +1200
Subject: [R-sig-ME] Simulating from a fitted genealised linear mixed model.
Message-ID: <20220809171948.30c4862d@rolf-Latitude-E7470>



This is a second try at conveying what I am trying to do, my first try
("newdata" argument of simulate.merMod()) having failed.

John Maindonald tried to help me in respect of my first attempt, but I
think that his response missed the point.  Or maybe I'm just being
thick, as is so often the case.

My eventual goal is to take the parameters of a fitted generalised
linear mixed model (binomial) and using those parameters simulate data
from a different experimental design.  (Say one with a greater number
of replicates and/or a larger number of binomial trials for each
observation.)

Note that the experimental design is determined by the predictors
in the data set in question, and the binomial "size", i.e. the
totals of successes and failures corresponding to each observation.

As I said in my previous (failed) attempt to explain myself, I thought
or hoped to be able to adjust the experimental design by providing a
"newdata" data set to simulate.merMod() where the new data set
conformed to the desired design.  However I have not been able to
get this to work.

In this current email I suppress the issue of dealing with the "newdata"
argument and simply focus on the problem of simulating data from
a fitted generalised linear model.

I have implemented a "roll-your-own" procedure wherein I construct
a linear predictor using

    * fitted fixed effect coefficients from the fitted mode
    * random effects simulated on the basis of the fitted
      random effects variances and covarances

I then form probabilities as the logistic function of the linear
predictor, and finally use rbinom() to generate a random sample
from these probabilities and the desired "sizes".

I illustrated this procedure in the file "demo.txt" that I attached
to my previous post.  I have reattached demo.txt to this current
post as "demo01.txt".

In demo01.txt the model is fitted (to the cbpp data from the lme4
package) using the formula:

    cbind(incidence, size - incidence) ~ 0 + period + (1 | herd)

The value of the linear predictor corresponding to the i-th row of the
underlying data frame is

    coef_j(i) + Z_k(i)

where coef_j(i) is the estimated fixed effect coefficient for the
j-th level of the fixed effect where the j-th level is that found
in the i-th row of the data.  Likewise Z_k(i) is the k-th entry of a
vector of N(0,sigma^2) values generated using rnorm(nrep,0,sigma) where
nrep is the number of replicates.  The index k(i) is the index of the
level of "Rep" that is found in the i-th row of the data.

For a *single* random effect the roll-your-own results agree with
the results from simulate.merMod(), provided that seeds are properly
set (and provided that the experimental design is unchanged from that of
the data set to which the model was fitted ---  no "newdata" involved.)

However I cannot get roll-your-own to agree with simulate.merMod() when
there are *two* random effects in the model.  I have illustrated this in
the attached file demo02.txt.  In this example there is a numeric
predictor "x", a treatment factor "trtmnt" (with four levels) and
a random effect "batch".

The model is fitted using the formula

    cbind(Good,Bad) ~ (trtment + 0)/x + (x | batch)

so there are two random effects; an intercept and a slope corresponding
to each batch.

The linear predictor must (I think) take the form

    alpha_j(i) + beta_j(i)*x + Z[k(i),1] + Z[k(i),2]*x

Here Z is an nbatch x 2 matrix of randomly generated values produced
by mvrnorm(nbatch,c(0,0),Sigma) where Sigma is the estimated covariance
matrix of the random effects, obtained from the fitted model.  Of course
"nbatch" is the number of levels of the random batch effect.

The results from simulate.merMod() differ here from my roll-your-own
results, although they are not "too different".  Plotting s.mer against
s.ryo produces a scatter which is "close" to a straight line.  For some
value of "close".

It seems that simulate.merMod() is not doing (quite) what my
roll-your-own procedure does.  Why not? Am I misunderstanding what the
random effects are, in the second, slightly more complicated model?

I would like to be confident that my roll-your-own procedure is
actually correct, because I can very easily apply my roll-your-own
procedure to a new data set corresponding to a different experimental
design.

I would be grateful for any enlightenment.

cheers,

Rolf Turner

P.S. It is probably  easier to understand the code in demo01.txt and
demo02.txt than it is to understand my somewhat prolix explanation
given above.

R. T.

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: demo01.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20220809/d3ff5e8f/attachment.txt>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: demo02.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20220809/d3ff5e8f/attachment-0001.txt>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: data.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20220809/d3ff5e8f/attachment-0002.txt>

From mom@e1112 @end|ng |rom gm@||@com  Wed Aug 10 13:44:10 2022
From: mom@e1112 @end|ng |rom gm@||@com (Elena Moreno)
Date: Wed, 10 Aug 2022 13:44:10 +0200
Subject: [R-sig-ME] lmer under "single" nests
Message-ID: <CABUvszxB1_SZmzvMWrohGyZmo50Kms+Hn+xYQTzS0=Um6Mg8GA@mail.gmail.com>

Dear R-sig-mixed-models list:

I first want to thank you for your attention and willingness to help people
like me. I hope to get some light with my question:

I am applying a nested model as "(1|A/B)", having two individuals per nest
in most of the cases. However, some nests only have one individual. This is
because I'm working with kidney transplant data: there are cases when two
patients receive a kidney from the same donor (the donor gives both
kidneys), but there are cases where the donor gives just one kidney (so the
recipient doesn't share donor with anyone else).

Patients have several measures of renal function (creatinine) over time.

How does "lmer" handle this kind of situation when having some "single"
(with just one individual) nests in combination with non-single nests? It
is worth it to nest when, at most, there are only two patients per nest
(donor)?


If you need more details regarding the study design or even a sample of the
data, please tell me. By the way, I am not mathematician so I find
demonstrations difficult to understand but I am always eager and open to
learn.

Thank you very much and sorry for this naive question,


Elena

	[[alternative HTML version deleted]]


From p|erce@1 @end|ng |rom m@u@edu  Thu Aug 11 14:58:12 2022
From: p|erce@1 @end|ng |rom m@u@edu (Pierce, Steven)
Date: Thu, 11 Aug 2022 12:58:12 +0000
Subject: [R-sig-ME] lmer under "single" nests
In-Reply-To: <CABUvszxB1_SZmzvMWrohGyZmo50Kms+Hn+xYQTzS0=Um6Mg8GA@mail.gmail.com>
References: <CABUvszxB1_SZmzvMWrohGyZmo50Kms+Hn+xYQTzS0=Um6Mg8GA@mail.gmail.com>
Message-ID: <CH2PR12MB3736A1E42479442CE7B4C2AC81649@CH2PR12MB3736.namprd12.prod.outlook.com>

Elena,

You have what is sometimes called "sparsely clustered" data. Below are a couple methodology papers relevant to this situation.

Clarke, P. (2008). When can group level clustering be ignored? Multilevel models versus single-level models with sparse data. Journal of Epidemiology and Community Health, 62, 752-758. https://doi.org/10.1136/jech.2007.060798

McNeish, D. M. (2014). Modeling sparsely clustered data: Design-based, model based, and single-level methods. Psychological Methods, 19(4), 552-563. https://doi.org/10.1037/met0000024


Steven J. Pierce, Ph.D.
Associate Director
Center for Statistical Training & Consulting (CSTAT)
Michigan State University

-----Original Message-----
From: Elena Moreno <momae1112 at gmail.com> 
Sent: Wednesday, August 10, 2022 7:44 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] lmer under "single" nests

Dear R-sig-mixed-models list:

I first want to thank you for your attention and willingness to help people
like me. I hope to get some light with my question:

I am applying a nested model as "(1|A/B)", having two individuals per nest
in most of the cases. However, some nests only have one individual. This is
because I'm working with kidney transplant data: there are cases when two
patients receive a kidney from the same donor (the donor gives both
kidneys), but there are cases where the donor gives just one kidney (so the
recipient doesn't share donor with anyone else).

Patients have several measures of renal function (creatinine) over time.

How does "lmer" handle this kind of situation when having some "single"
(with just one individual) nests in combination with non-single nests? It
is worth it to nest when, at most, there are only two patients per nest
(donor)?


If you need more details regarding the study design or even a sample of the
data, please tell me. By the way, I am not mathematician so I find
demonstrations difficult to understand but I am always eager and open to
learn.

Thank you very much and sorry for this naive question,


Elena

	[[alternative HTML version deleted]]



From jh@|t|g@ @end|ng |rom gm@||@com  Sun Aug 14 01:32:52 2022
From: jh@|t|g@ @end|ng |rom gm@||@com (J.D. Haltigan)
Date: Sat, 13 Aug 2022 19:32:52 -0400
Subject: [R-sig-ME] Cluster-robust SEs & random effects -- seeking some
 clarification
In-Reply-To: <CAH_7VO=FQmm_qVQ4aBw0Krmza61TAz3U97JWx9wNbdSPACY7AQ@mail.gmail.com>
References: <CAH_7VOkx8+Pwpx+Rovgm0=k2Nde3TvmJpAQ_28O_NjQTY82h4g@mail.gmail.com>
 <CAFUVuJyh56KYctgrB1TSn8JB01h+Lh93Oh--dPvOK616b=x3LQ@mail.gmail.com>
 <CAH_7VO=aOOhT8TWJ7rAfY4EC+8yOepLpkpg0TcXgjN+wwk2c=w@mail.gmail.com>
 <CAFUVuJztqcXppr8VSDUXWYmTtcyDk+TVXDc3WPNkfcPJNRmaGA@mail.gmail.com>
 <CAH_7VO=pDmKDbpy8CfOTewcqXvwcfa1CRyRoohcRbQ=zz5ayOQ@mail.gmail.com>
 <CAFUVuJzXv6Ggz9iSMm6ehUVeNSFY3t-mn=jh7QqTiDuUBmzDCg@mail.gmail.com>
 <CAH_7VOnDW0Y7vXUZfChaM_JRgRg6c9uXs6+RzHt886fxo4AsUw@mail.gmail.com>
 <CAH_7VOmxzQcF7nNcDC42AeSZGFNdMO0O98zb9AroxPz51zHR1Q@mail.gmail.com>
 <883b38be-eeb7-8052-4395-618484a5ef97@gmail.com>
 <CAH_7VOnnkY2ee1QXVbZ+VzNLJg2bZVPjdKpVqkGoc=ZyKj635Q@mail.gmail.com>
 <c85ebe15-38fc-9b66-3a67-656a9b969f88@gmail.com>
 <CAH_7VOks9qCDhRzKWC2vxp2OYfLAqcdFuRRuMtB3=0dQ9nSJGQ@mail.gmail.com>
 <CAH_7VO=FQmm_qVQ4aBw0Krmza61TAz3U97JWx9wNbdSPACY7AQ@mail.gmail.com>
Message-ID: <CAH_7VOm-RbYEyhCa-okvMCTMCHLsnqgEcCLH8JOQhLHDArsZsA@mail.gmail.com>

One further post perhaps framing my question slightly differently (or
altogether more generally):

What, specifically, do cluster-robust/robust SEs allow one to do with more
accuracy/precision *if* they are already using both random effects and
slopes to model relevant cluster-specific effects. Is it the case that
there may be any number of sources that could potentially account for
sources of heteroskedasticity (i.e., autoregressive structure in the case
of repeated measurements/time variables) that using the cluster robust SEs
would be of value for in making more precise inference assuming some
misspecification of the random effects structure of the model?

Relatedly, is there a 'seminal' or 'key' paper that provides a deep dive on
the concept of heteroskedasticity? I have a few on hand, but wanted to see
if there was something I might not be aware of .

On Wed, Aug 3, 2022 at 11:46 PM J.D. Haltigan <jhaltiga at gmail.com> wrote:

> Thought I would bump my last post to see if anyone might weigh in on my
> more general statements about re: unions (clusters). Would be most
> appreciated as I continue to wrap my head around some things.
>
> Thanks in advance for any thoughts. I appreciate your time.
>
> On Sat, Jul 30, 2022 at 8:43 PM J.D. Haltigan <jhaltiga at gmail.com> wrote:
>
>> And to take one more step: the inference is that the single
>> population-level treatment effect is drawing from a 'random sample' of
>> unions (clusters). That is, one can not assume that union's are the same.
>> They are not interchangeable. They are drawn from a random population. This
>> is the point of the exercise for me. If we remove the random effect for
>> union in the model I shared, we end up with a model in which only the fixed
>> effects of pairID (treatment-control pairs for each pair of treatment
>> control villages) are estimated (albeit using cluster-robust SEs). So, if
>> by adding that random effect for union the treatment intervention is no
>> longer significant (as opposed to a model in which there is no random
>> effect of union modeled), what is that telling us? That some of the between
>> cluster (union) variance in intercepts is contributing to variation in the
>> response variable, yes?
>>
>> I realize you have not read the paper, nor are necessarily interested in
>> this discourse, but any remarks are greatly appreciated.
>>
>>
>> On Sat, Jul 30, 2022 at 8:36 PM Ben Bolker <bbolker at gmail.com> wrote:
>>
>>>    Yes.
>>>
>>> On 2022-07-30 8:12 p.m., J.D. Haltigan wrote:
>>> > Thanks, Ben. So in the model you remarked on, would that be a
>>> > 'random-intercepts only' model?
>>> >
>>> >
>>> > On Sat, Jul 30, 2022 at 7:53 PM Ben Bolker <bbolker at gmail.com
>>> > <mailto:bbolker at gmail.com>> wrote:
>>> >
>>> >     I haven't been following the whole thread that carefully, but I
>>> want to
>>> >     emphasize that
>>> >
>>> >         posXsymp~treatment + pairID + (1 | union)
>>> >
>>> >     is *not*, by any definition I'm familiar with, a "random-slopes
>>> model";
>>> >     that is, it only estimates a single population-level treatment
>>> >     effect/doesn't allow the effect of treatment to vary across groups
>>> >     defined by 'union'.  You would need a random-effect term of the
>>> form
>>> >     (treatment | union).
>>> >
>>> >         Reasons why you might *not* want to do this:
>>> >
>>> >        * if treatment only varies across and not within levels of union
>>> >     ("union is nested within treatment" according to some terminology),
>>> >     then
>>> >     this variation is unidentifiable
>>> >        * maybe you have decided that you don't have enough data/want a
>>> more
>>> >     parsimonious model.
>>> >
>>> >         Schielzeth and Forstmeier, among many others (this is the
>>> example I
>>> >     know of), have cautioned about the consequences of leaving out
>>> >     random-slopes terms.
>>> >
>>> >     Schielzeth, Holger, and Wolfgang Forstmeier. ?Conclusions beyond
>>> >     Support: Overconfident Estimates in Mixed Models.? Behavioral
>>> Ecology
>>> >     20, no. 2 (March 1, 2009): 416?20.
>>> >     https://doi.org/10.1093/beheco/arn145
>>> >     <https://doi.org/10.1093/beheco/arn145>.
>>> >
>>> >
>>> >     On 2022-07-30 7:43 p.m., J.D. Haltigan wrote:
>>> >      > Addendum:
>>> >      >
>>> >      > It just occurred to me on my walk that I think I am getting a
>>> bit
>>> >     lost in
>>> >      > some of the differences in nomenclature across scientific silos.
>>> >     In the
>>> >      > original model that they specified, which treated the 'pairID'
>>> >     variable as
>>> >      > a control variable for which they controlled for 'fixed
>>> effects' of
>>> >      > control/treatment villages (in their own language in the paper)
>>> using
>>> >      > cluster-robust SEs, I think this is indeed a 'random-intercepts
>>> >     only' model
>>> >      > in the language of Hamaker et al. They implement the 'absorb'
>>> >     command in
>>> >      > STATA which I believe aggregates across the pairIDs to generate
>>> an
>>> >      > 'omnibus' F-test of sorts for the pairID variable (in the ANOVA
>>> >      > nomenclature). I say this as when I specify the pairID variable
>>> >     in the lmer
>>> >      > model I shared (or in a fixest model I conducted to replicate
>>> the
>>> >     original
>>> >      > Abalauck results in R), I get the estimates for all the pairs
>>> >     (i.e., there
>>> >      > is no way to aggregate across them--though I think formally the
>>> >     models are
>>> >      > the same if we are unconcerned about any one pairID
>>> >     [treatment/control
>>> >      > village pair].
>>> >      >
>>> >      > So, in the lmer model I shared where I specify a specific random
>>> >     effects
>>> >      > term for the 'cluster' variable, I think this indeed is allowing
>>> >     for random
>>> >      > slopes across the clusters which implies the treatment effect
>>> may
>>> >     vary
>>> >      > across the clusters (and we might anticipate it will for various
>>> >     reasons I
>>> >      > can elaborate on). More generally: we are generalizing to *any*
>>> >     universe of
>>> >      > villages (say in the entire world) where the treatment
>>> >     intervention (masks)
>>> >      > may vary across villages. This is the crux of invoking the
>>> random
>>> >     effects
>>> >      > model (i.e., random slopes model).
>>> >      >
>>> >      > I realize this is a mouthful, but I think the way these terms
>>> (e.g.,
>>> >      > random/fixed effects models etc.) are used across disciplines
>>> >     makes things
>>> >      > a bit confusing.
>>> >      >
>>> >      > On Sat, Jul 30, 2022 at 5:25 PM J.D. Haltigan <
>>> jhaltiga at gmail.com
>>> >     <mailto:jhaltiga at gmail.com>> wrote:
>>> >      >
>>> >      >> This is a very helpful walkthrough, James. My responses are
>>> >     italicized
>>> >      >> under yours to maintain thread readability. The key is
>>> >     Generalizability
>>> >      >> here and (as I also note in my last reply) the idea is to
>>> >     Generalize to a
>>> >      >> universe of "any villages or clusters." That is, the target
>>> >     population we
>>> >      >> are generalizing to is *any* random population.
>>> >      >>
>>> >      >> On Sat, Jul 30, 2022 at 3:01 PM James Pustejovsky
>>> >     <jepusto at gmail.com <mailto:jepusto at gmail.com>>
>>> >      >> wrote:
>>> >      >>
>>> >      >>> Hi J.D.,
>>> >      >>> A few comments/reactions inline below.
>>> >      >>> James
>>> >      >>>
>>> >      >>> On Wed, Jul 27, 2022 at 5:37 PM J.D. Haltigan
>>> >     <jhaltiga at gmail.com <mailto:jhaltiga at gmail.com>> wrote:
>>> >      >>>
>>> >      >>>> ...
>>> >      >>>>
>>> >      >>> In the original investigation, the authors did not invoke a
>>> random
>>> >      >>>> effects model (but did use the pairIDs to control for fixed
>>> >     effects as
>>> >      >>>> noted and with robust SEs). Thus, in the original
>>> >     investigation there was
>>> >      >>>> *no* specification of a random effects model for the
>>> 'cluster'
>>> >     variable. We
>>> >      >>>> know from some other work there were some biases in village
>>> >     mapping and
>>> >      >>>> other possible sources of between-cluster variation that
>>> might be
>>> >      >>>> anticipated to have influence--at the random intercepts
>>> >     level--so we are
>>> >      >>>> looking into how specifying 'cluster' as a random effect
>>> might
>>> >     change the
>>> >      >>>> fixed effects estimates for the treatment intervention
>>> effect.
>>> >     In the
>>> >      >>>> Hamaker et al. language, it is indeed a 'random intercepts'
>>> >     only model.
>>> >      >>>>
>>> >      >>>
>>> >      >>> I don't follow how using a random intercepts model improves
>>> the
>>> >      >>> generalizability warrant here. The random intercepts model is
>>> >     essentially
>>> >      >>> just a re-weighted average of the pair-specific effects in the
>>> >     original
>>> >      >>> analysis, where the weights are optimally efficient if the
>>> model is
>>> >      >>> correctly specified. That last clause carries a lot of weight
>>> >     here--correct
>>> >      >>> specification means 1) treatment assignment is unrelated to
>>> the
>>> >     random
>>> >      >>> effects, 2) the treatment effect is constant across clusters,
>>> 3)
>>> >      >>> distributional assumptions are valid (i.e., homoskedasticity
>>> at
>>> >     each level
>>> >      >>> of the model).
>>> >      >>>
>>> >      >>> If the effects are heterogeneous, then I would think that
>>> including
>>> >      >>> random slopes on the treatment indicator would provide a
>>> better
>>> >     basis for
>>> >      >>> generalization. But even then, the warrant is still pretty
>>> >     vague---what is
>>> >      >>> the hypothetical population of villages from which the
>>> observed
>>> >     villages
>>> >      >>> are sampled?
>>> >      >>>
>>> >      >>
>>> >      >> *In the most basic model (without baseline controls) the model
>>> >     takes the
>>> >      >> form: myModel = lmer(posXsymp~treatment + pairID + (1 | union),
>>> >     data =
>>> >      >> myData). I believe--correct me if I am wrong--that this
>>> reflects a
>>> >      >> random-intercepts only model, but I may be mistaken. If I am,
>>> >     and this is
>>> >      >> allowing for random slopes on the treatment indicator, then I
>>> >     will need to
>>> >      >> rethink my statements.  *
>>> >      >>
>>> >      >>>
>>> >      >>>
>>> >      >>>> Given this, however, does it also make sense to include the
>>> >     cluster
>>> >      >>>> robust SEs for the fixed effects which would account for
>>> possible
>>> >      >>>> heterogeneity of treatment effects (i.e., slopes) across
>>> >     clusters?s
>>> >      >>>>
>>> >      >>>> If you're committed to the random intercepts model, then yes
>>> I
>>> >     think so
>>> >      >>> because using cluster robust SEs at least acknowledges the
>>> >     possibility of
>>> >      >>> heterogeneous treatment effects.
>>> >      >>>
>>> >      >>
>>> >      >> *If the above model does allow for both random intercepts and
>>> >     slopes, then
>>> >      >> perhaps the use of cluster robust SEs is redundant in some
>>> sense
>>> >     since the
>>> >      >> random slopes would be modeling the heterogeneity in treatment
>>> >     effects?*
>>> >      >>
>>> >      >>>
>>> >      >>>
>>> >      >>>
>>> >      >>>> Bottom line: in their original analyses, clusters are seen as
>>> >      >>>> interchangeable from a conceptual perspective (rather than
>>> >     drawn from a
>>> >      >>>> random universe of observations). When one scales up evidence
>>> >     to a universe
>>> >      >>>> of observations that are random (as they would be in the
>>> >     intended universe
>>> >      >>>> of inference in the real-world), then we are better
>>> >     positioned, I think, to
>>> >      >>>> adjudicate whether the mask intervention effect is
>>> 'practically
>>> >      >>>> significant' (in addition to whether the focal effect remains
>>> >     marginally
>>> >      >>>> significant from a frequentist perspective).
>>> >      >>>>
>>> >      >>> As noted above, this argument is a bit vague to me. If there's
>>> >     concern
>>> >      >>> about generalizability, then my first question would be: what
>>> >     is the target
>>> >      >>> population to which you are trying to generalize?
>>> >      >>>
>>> >      >>
>>> >      >> *Essentially, the target population we are trying to generalize
>>> >     to is a
>>> >      >> random selection of villages. Any random selection of villages.
>>> >     In other
>>> >      >> words, villages should not be seen as interchangeable. We are
>>> >     interested in
>>> >      >> whether the effects generalize to any randomly selected
>>> village. *
>>> >      >>
>>> >      >>>
>>> >      >>>
>>> >      >>
>>> >      >
>>> >      >       [[alternative HTML version deleted]]
>>> >      >
>>> >      > _______________________________________________
>>> >      > R-sig-mixed-models at r-project.org
>>> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
>>> >      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>> >
>>> >     --
>>> >     Dr. Benjamin Bolker
>>> >     Professor, Mathematics & Statistics and Biology, McMaster
>>> University
>>> >     Director, School of Computational Science and Engineering
>>> >     (Acting) Graduate chair, Mathematics & Statistics
>>> >
>>> >     _______________________________________________
>>> >     R-sig-mixed-models at r-project.org
>>> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
>>> >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>> >
>>>
>>> --
>>> Dr. Benjamin Bolker
>>> Professor, Mathematics & Statistics and Biology, McMaster University
>>> Director, School of Computational Science and Engineering
>>> (Acting) Graduate chair, Mathematics & Statistics
>>>
>>

	[[alternative HTML version deleted]]


From |@brun@ @end|ng |rom udc@e@  Sun Aug 14 13:56:38 2022
From: |@brun@ @end|ng |rom udc@e@ (Fernando Pedro Bruna Quintas)
Date: Sun, 14 Aug 2022 11:56:38 +0000
Subject: [R-sig-ME] Cluster-robust SEs & random effects -- seeking some
 clarification
In-Reply-To: <CAH_7VOm-RbYEyhCa-okvMCTMCHLsnqgEcCLH8JOQhLHDArsZsA@mail.gmail.com>
References: <CAH_7VOkx8+Pwpx+Rovgm0=k2Nde3TvmJpAQ_28O_NjQTY82h4g@mail.gmail.com>
 <CAFUVuJyh56KYctgrB1TSn8JB01h+Lh93Oh--dPvOK616b=x3LQ@mail.gmail.com>
 <CAH_7VO=aOOhT8TWJ7rAfY4EC+8yOepLpkpg0TcXgjN+wwk2c=w@mail.gmail.com>
 <CAFUVuJztqcXppr8VSDUXWYmTtcyDk+TVXDc3WPNkfcPJNRmaGA@mail.gmail.com>
 <CAH_7VO=pDmKDbpy8CfOTewcqXvwcfa1CRyRoohcRbQ=zz5ayOQ@mail.gmail.com>
 <CAFUVuJzXv6Ggz9iSMm6ehUVeNSFY3t-mn=jh7QqTiDuUBmzDCg@mail.gmail.com>
 <CAH_7VOnDW0Y7vXUZfChaM_JRgRg6c9uXs6+RzHt886fxo4AsUw@mail.gmail.com>
 <CAH_7VOmxzQcF7nNcDC42AeSZGFNdMO0O98zb9AroxPz51zHR1Q@mail.gmail.com>
 <883b38be-eeb7-8052-4395-618484a5ef97@gmail.com>
 <CAH_7VOnnkY2ee1QXVbZ+VzNLJg2bZVPjdKpVqkGoc=ZyKj635Q@mail.gmail.com>
 <c85ebe15-38fc-9b66-3a67-656a9b969f88@gmail.com>
 <CAH_7VOks9qCDhRzKWC2vxp2OYfLAqcdFuRRuMtB3=0dQ9nSJGQ@mail.gmail.com>
 <CAH_7VO=FQmm_qVQ4aBw0Krmza61TAz3U97JWx9wNbdSPACY7AQ@mail.gmail.com>
 <CAH_7VOm-RbYEyhCa-okvMCTMCHLsnqgEcCLH8JOQhLHDArsZsA@mail.gmail.com>
Message-ID: <PAXPR02MB7181766DC8C9020FEDD0FBA892699@PAXPR02MB7181.eurprd02.prod.outlook.com>

Hi,

I have followed only partially this thread. I also fail to understand the point of using clustered errors with mixed models People using Stata often calculate those cluster standard errors, at least in my disciplines in social sciences, using the "mixed" function. In R that was not possible until recently, as far as I know. For instance, tab_model() function from sjPlot does not allow calculation of clustered standard errors for models estimated with lme4 package. The recent package WeMix allows for that calculation, but only because it replicates what Stata mixed function does, but the authors do not justify why that calculation may be useful.

The calculation of clustered standard errors is a way of capturing the effects of a smaller effective sample size when there are correlations by groups. However, that corrections is one of the main concerns of mixed modelling, as far as I understand.

Abadie et al. 2022 do not recommend applying clustered standard error by default in standard regressions, and I understand that there are still less reasons to do it in mixed models.
https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwjVi57ioMb5AhVFnf0HHUAkCwkQFnoECAMQAQ&url=https%3A%2F%2Feconomics.mit.edu%2Ffiles%2F13927&usg=AOvVaw0vtAkWz0AFlwAPOEKYQgNq

I appreciate more comments regarding this topic.

Thank you

Fernando Bruna
Department of Economics
Universidade da Corunna, Spain

________________________________
De: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> en nombre de J.D. Haltigan <jhaltiga at gmail.com>
Enviado: domingo, 14 de agosto de 2022 1:32
Para: Ben Bolker <bbolker at gmail.com>
Cc: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Asunto: Re: [R-sig-ME] Cluster-robust SEs & random effects -- seeking some clarification

One further post perhaps framing my question slightly differently (or
altogether more generally):

What, specifically, do cluster-robust/robust SEs allow one to do with more
accuracy/precision *if* they are already using both random effects and
slopes to model relevant cluster-specific effects. Is it the case that
there may be any number of sources that could potentially account for
sources of heteroskedasticity (i.e., autoregressive structure in the case
of repeated measurements/time variables) that using the cluster robust SEs
would be of value for in making more precise inference assuming some
misspecification of the random effects structure of the model?

Relatedly, is there a 'seminal' or 'key' paper that provides a deep dive on
the concept of heteroskedasticity? I have a few on hand, but wanted to see
if there was something I might not be aware of .

On Wed, Aug 3, 2022 at 11:46 PM J.D. Haltigan <jhaltiga at gmail.com> wrote:

> Thought I would bump my last post to see if anyone might weigh in on my
> more general statements about re: unions (clusters). Would be most
> appreciated as I continue to wrap my head around some things.
>
> Thanks in advance for any thoughts. I appreciate your time.
>
> On Sat, Jul 30, 2022 at 8:43 PM J.D. Haltigan <jhaltiga at gmail.com> wrote:
>
>> And to take one more step: the inference is that the single
>> population-level treatment effect is drawing from a 'random sample' of
>> unions (clusters). That is, one can not assume that union's are the same.
>> They are not interchangeable. They are drawn from a random population. This
>> is the point of the exercise for me. If we remove the random effect for
>> union in the model I shared, we end up with a model in which only the fixed
>> effects of pairID (treatment-control pairs for each pair of treatment
>> control villages) are estimated (albeit using cluster-robust SEs). So, if
>> by adding that random effect for union the treatment intervention is no
>> longer significant (as opposed to a model in which there is no random
>> effect of union modeled), what is that telling us? That some of the between
>> cluster (union) variance in intercepts is contributing to variation in the
>> response variable, yes?
>>
>> I realize you have not read the paper, nor are necessarily interested in
>> this discourse, but any remarks are greatly appreciated.
>>
>>
>> On Sat, Jul 30, 2022 at 8:36 PM Ben Bolker <bbolker at gmail.com> wrote:
>>
>>>    Yes.
>>>
>>> On 2022-07-30 8:12 p.m., J.D. Haltigan wrote:
>>> > Thanks, Ben. So in the model you remarked on, would that be a
>>> > 'random-intercepts only' model?
>>> >
>>> >
>>> > On Sat, Jul 30, 2022 at 7:53 PM Ben Bolker <bbolker at gmail.com
>>> > <mailto:bbolker at gmail.com>> wrote:
>>> >
>>> >     I haven't been following the whole thread that carefully, but I
>>> want to
>>> >     emphasize that
>>> >
>>> >         posXsymp~treatment + pairID + (1 | union)
>>> >
>>> >     is *not*, by any definition I'm familiar with, a "random-slopes
>>> model";
>>> >     that is, it only estimates a single population-level treatment
>>> >     effect/doesn't allow the effect of treatment to vary across groups
>>> >     defined by 'union'.  You would need a random-effect term of the
>>> form
>>> >     (treatment | union).
>>> >
>>> >         Reasons why you might *not* want to do this:
>>> >
>>> >        * if treatment only varies across and not within levels of union
>>> >     ("union is nested within treatment" according to some terminology),
>>> >     then
>>> >     this variation is unidentifiable
>>> >        * maybe you have decided that you don't have enough data/want a
>>> more
>>> >     parsimonious model.
>>> >
>>> >         Schielzeth and Forstmeier, among many others (this is the
>>> example I
>>> >     know of), have cautioned about the consequences of leaving out
>>> >     random-slopes terms.
>>> >
>>> >     Schielzeth, Holger, and Wolfgang Forstmeier. ?Conclusions beyond
>>> >     Support: Overconfident Estimates in Mixed Models.? Behavioral
>>> Ecology
>>> >     20, no. 2 (March 1, 2009): 416?20.
>>> >     https://eur02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fdoi.org%2F10.1093%2Fbeheco%2Farn145&amp;data=05%7C01%7Cf.bruna%40udc.es%7Ccff181a16d084542b64e08da7d843c79%7Ccea1ea3e60b24f75a6c2a6022e8f961b%7C0%7C0%7C637960304201466714%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=HIiZ5D1zlFIyoL9ZHv%2Fv%2F3sJW6ecsXtCU3wduKtZRS4%3D&amp;reserved=0
>>> >     <https://eur02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fdoi.org%2F10.1093%2Fbeheco%2Farn145&amp;data=05%7C01%7Cf.bruna%40udc.es%7Ccff181a16d084542b64e08da7d843c79%7Ccea1ea3e60b24f75a6c2a6022e8f961b%7C0%7C0%7C637960304201466714%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=HIiZ5D1zlFIyoL9ZHv%2Fv%2F3sJW6ecsXtCU3wduKtZRS4%3D&amp;reserved=0>.
>>> >
>>> >
>>> >     On 2022-07-30 7:43 p.m., J.D. Haltigan wrote:
>>> >      > Addendum:
>>> >      >
>>> >      > It just occurred to me on my walk that I think I am getting a
>>> bit
>>> >     lost in
>>> >      > some of the differences in nomenclature across scientific silos.
>>> >     In the
>>> >      > original model that they specified, which treated the 'pairID'
>>> >     variable as
>>> >      > a control variable for which they controlled for 'fixed
>>> effects' of
>>> >      > control/treatment villages (in their own language in the paper)
>>> using
>>> >      > cluster-robust SEs, I think this is indeed a 'random-intercepts
>>> >     only' model
>>> >      > in the language of Hamaker et al. They implement the 'absorb'
>>> >     command in
>>> >      > STATA which I believe aggregates across the pairIDs to generate
>>> an
>>> >      > 'omnibus' F-test of sorts for the pairID variable (in the ANOVA
>>> >      > nomenclature). I say this as when I specify the pairID variable
>>> >     in the lmer
>>> >      > model I shared (or in a fixest model I conducted to replicate
>>> the
>>> >     original
>>> >      > Abalauck results in R), I get the estimates for all the pairs
>>> >     (i.e., there
>>> >      > is no way to aggregate across them--though I think formally the
>>> >     models are
>>> >      > the same if we are unconcerned about any one pairID
>>> >     [treatment/control
>>> >      > village pair].
>>> >      >
>>> >      > So, in the lmer model I shared where I specify a specific random
>>> >     effects
>>> >      > term for the 'cluster' variable, I think this indeed is allowing
>>> >     for random
>>> >      > slopes across the clusters which implies the treatment effect
>>> may
>>> >     vary
>>> >      > across the clusters (and we might anticipate it will for various
>>> >     reasons I
>>> >      > can elaborate on). More generally: we are generalizing to *any*
>>> >     universe of
>>> >      > villages (say in the entire world) where the treatment
>>> >     intervention (masks)
>>> >      > may vary across villages. This is the crux of invoking the
>>> random
>>> >     effects
>>> >      > model (i.e., random slopes model).
>>> >      >
>>> >      > I realize this is a mouthful, but I think the way these terms
>>> (e.g.,
>>> >      > random/fixed effects models etc.) are used across disciplines
>>> >     makes things
>>> >      > a bit confusing.
>>> >      >
>>> >      > On Sat, Jul 30, 2022 at 5:25 PM J.D. Haltigan <
>>> jhaltiga at gmail.com
>>> >     <mailto:jhaltiga at gmail.com>> wrote:
>>> >      >
>>> >      >> This is a very helpful walkthrough, James. My responses are
>>> >     italicized
>>> >      >> under yours to maintain thread readability. The key is
>>> >     Generalizability
>>> >      >> here and (as I also note in my last reply) the idea is to
>>> >     Generalize to a
>>> >      >> universe of "any villages or clusters." That is, the target
>>> >     population we
>>> >      >> are generalizing to is *any* random population.
>>> >      >>
>>> >      >> On Sat, Jul 30, 2022 at 3:01 PM James Pustejovsky
>>> >     <jepusto at gmail.com <mailto:jepusto at gmail.com>>
>>> >      >> wrote:
>>> >      >>
>>> >      >>> Hi J.D.,
>>> >      >>> A few comments/reactions inline below.
>>> >      >>> James
>>> >      >>>
>>> >      >>> On Wed, Jul 27, 2022 at 5:37 PM J.D. Haltigan
>>> >     <jhaltiga at gmail.com <mailto:jhaltiga at gmail.com>> wrote:
>>> >      >>>
>>> >      >>>> ...
>>> >      >>>>
>>> >      >>> In the original investigation, the authors did not invoke a
>>> random
>>> >      >>>> effects model (but did use the pairIDs to control for fixed
>>> >     effects as
>>> >      >>>> noted and with robust SEs). Thus, in the original
>>> >     investigation there was
>>> >      >>>> *no* specification of a random effects model for the
>>> 'cluster'
>>> >     variable. We
>>> >      >>>> know from some other work there were some biases in village
>>> >     mapping and
>>> >      >>>> other possible sources of between-cluster variation that
>>> might be
>>> >      >>>> anticipated to have influence--at the random intercepts
>>> >     level--so we are
>>> >      >>>> looking into how specifying 'cluster' as a random effect
>>> might
>>> >     change the
>>> >      >>>> fixed effects estimates for the treatment intervention
>>> effect.
>>> >     In the
>>> >      >>>> Hamaker et al. language, it is indeed a 'random intercepts'
>>> >     only model.
>>> >      >>>>
>>> >      >>>
>>> >      >>> I don't follow how using a random intercepts model improves
>>> the
>>> >      >>> generalizability warrant here. The random intercepts model is
>>> >     essentially
>>> >      >>> just a re-weighted average of the pair-specific effects in the
>>> >     original
>>> >      >>> analysis, where the weights are optimally efficient if the
>>> model is
>>> >      >>> correctly specified. That last clause carries a lot of weight
>>> >     here--correct
>>> >      >>> specification means 1) treatment assignment is unrelated to
>>> the
>>> >     random
>>> >      >>> effects, 2) the treatment effect is constant across clusters,
>>> 3)
>>> >      >>> distributional assumptions are valid (i.e., homoskedasticity
>>> at
>>> >     each level
>>> >      >>> of the model).
>>> >      >>>
>>> >      >>> If the effects are heterogeneous, then I would think that
>>> including
>>> >      >>> random slopes on the treatment indicator would provide a
>>> better
>>> >     basis for
>>> >      >>> generalization. But even then, the warrant is still pretty
>>> >     vague---what is
>>> >      >>> the hypothetical population of villages from which the
>>> observed
>>> >     villages
>>> >      >>> are sampled?
>>> >      >>>
>>> >      >>
>>> >      >> *In the most basic model (without baseline controls) the model
>>> >     takes the
>>> >      >> form: myModel = lmer(posXsymp~treatment + pairID + (1 | union),
>>> >     data =
>>> >      >> myData). I believe--correct me if I am wrong--that this
>>> reflects a
>>> >      >> random-intercepts only model, but I may be mistaken. If I am,
>>> >     and this is
>>> >      >> allowing for random slopes on the treatment indicator, then I
>>> >     will need to
>>> >      >> rethink my statements.  *
>>> >      >>
>>> >      >>>
>>> >      >>>
>>> >      >>>> Given this, however, does it also make sense to include the
>>> >     cluster
>>> >      >>>> robust SEs for the fixed effects which would account for
>>> possible
>>> >      >>>> heterogeneity of treatment effects (i.e., slopes) across
>>> >     clusters?s
>>> >      >>>>
>>> >      >>>> If you're committed to the random intercepts model, then yes
>>> I
>>> >     think so
>>> >      >>> because using cluster robust SEs at least acknowledges the
>>> >     possibility of
>>> >      >>> heterogeneous treatment effects.
>>> >      >>>
>>> >      >>
>>> >      >> *If the above model does allow for both random intercepts and
>>> >     slopes, then
>>> >      >> perhaps the use of cluster robust SEs is redundant in some
>>> sense
>>> >     since the
>>> >      >> random slopes would be modeling the heterogeneity in treatment
>>> >     effects?*
>>> >      >>
>>> >      >>>
>>> >      >>>
>>> >      >>>
>>> >      >>>> Bottom line: in their original analyses, clusters are seen as
>>> >      >>>> interchangeable from a conceptual perspective (rather than
>>> >     drawn from a
>>> >      >>>> random universe of observations). When one scales up evidence
>>> >     to a universe
>>> >      >>>> of observations that are random (as they would be in the
>>> >     intended universe
>>> >      >>>> of inference in the real-world), then we are better
>>> >     positioned, I think, to
>>> >      >>>> adjudicate whether the mask intervention effect is
>>> 'practically
>>> >      >>>> significant' (in addition to whether the focal effect remains
>>> >     marginally
>>> >      >>>> significant from a frequentist perspective).
>>> >      >>>>
>>> >      >>> As noted above, this argument is a bit vague to me. If there's
>>> >     concern
>>> >      >>> about generalizability, then my first question would be: what
>>> >     is the target
>>> >      >>> population to which you are trying to generalize?
>>> >      >>>
>>> >      >>
>>> >      >> *Essentially, the target population we are trying to generalize
>>> >     to is a
>>> >      >> random selection of villages. Any random selection of villages.
>>> >     In other
>>> >      >> words, villages should not be seen as interchangeable. We are
>>> >     interested in
>>> >      >> whether the effects generalize to any randomly selected
>>> village. *
>>> >      >>
>>> >      >>>
>>> >      >>>
>>> >      >>
>>> >      >
>>> >      >       [[alternative HTML version deleted]]
>>> >      >
>>> >      > _______________________________________________
>>> >      > R-sig-mixed-models at r-project.org
>>> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
>>> >      > https://eur02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=05%7C01%7Cf.bruna%40udc.es%7Ccff181a16d084542b64e08da7d843c79%7Ccea1ea3e60b24f75a6c2a6022e8f961b%7C0%7C0%7C637960304201466714%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=YM5skHwDtAoKz1KVXrCB1bjBRLvTE8UMuZjaE964iBY%3D&amp;reserved=0
>>> >     <https://eur02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=05%7C01%7Cf.bruna%40udc.es%7Ccff181a16d084542b64e08da7d843c79%7Ccea1ea3e60b24f75a6c2a6022e8f961b%7C0%7C0%7C637960304201466714%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=YM5skHwDtAoKz1KVXrCB1bjBRLvTE8UMuZjaE964iBY%3D&amp;reserved=0>
>>> >
>>> >     --
>>> >     Dr. Benjamin Bolker
>>> >     Professor, Mathematics & Statistics and Biology, McMaster
>>> University
>>> >     Director, School of Computational Science and Engineering
>>> >     (Acting) Graduate chair, Mathematics & Statistics
>>> >
>>> >     _______________________________________________
>>> >     R-sig-mixed-models at r-project.org
>>> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
>>> >     https://eur02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=05%7C01%7Cf.bruna%40udc.es%7Ccff181a16d084542b64e08da7d843c79%7Ccea1ea3e60b24f75a6c2a6022e8f961b%7C0%7C0%7C637960304201466714%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=YM5skHwDtAoKz1KVXrCB1bjBRLvTE8UMuZjaE964iBY%3D&amp;reserved=0
>>> >     <https://eur02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=05%7C01%7Cf.bruna%40udc.es%7Ccff181a16d084542b64e08da7d843c79%7Ccea1ea3e60b24f75a6c2a6022e8f961b%7C0%7C0%7C637960304201466714%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=YM5skHwDtAoKz1KVXrCB1bjBRLvTE8UMuZjaE964iBY%3D&amp;reserved=0>
>>> >
>>>
>>> --
>>> Dr. Benjamin Bolker
>>> Professor, Mathematics & Statistics and Biology, McMaster University
>>> Director, School of Computational Science and Engineering
>>> (Acting) Graduate chair, Mathematics & Statistics
>>>
>>

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://eur02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=05%7C01%7Cf.bruna%40udc.es%7Ccff181a16d084542b64e08da7d843c79%7Ccea1ea3e60b24f75a6c2a6022e8f961b%7C0%7C0%7C637960304201466714%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=YM5skHwDtAoKz1KVXrCB1bjBRLvTE8UMuZjaE964iBY%3D&amp;reserved=0

	[[alternative HTML version deleted]]


From jh@|t|g@ @end|ng |rom gm@||@com  Sun Aug 14 23:36:36 2022
From: jh@|t|g@ @end|ng |rom gm@||@com (J.D. Haltigan)
Date: Sun, 14 Aug 2022 17:36:36 -0400
Subject: [R-sig-ME] Cluster-robust SEs & random effects -- seeking some
 clarification
In-Reply-To: <PAXPR02MB7181766DC8C9020FEDD0FBA892699@PAXPR02MB7181.eurprd02.prod.outlook.com>
References: <CAH_7VOkx8+Pwpx+Rovgm0=k2Nde3TvmJpAQ_28O_NjQTY82h4g@mail.gmail.com>
 <CAFUVuJyh56KYctgrB1TSn8JB01h+Lh93Oh--dPvOK616b=x3LQ@mail.gmail.com>
 <CAH_7VO=aOOhT8TWJ7rAfY4EC+8yOepLpkpg0TcXgjN+wwk2c=w@mail.gmail.com>
 <CAFUVuJztqcXppr8VSDUXWYmTtcyDk+TVXDc3WPNkfcPJNRmaGA@mail.gmail.com>
 <CAH_7VO=pDmKDbpy8CfOTewcqXvwcfa1CRyRoohcRbQ=zz5ayOQ@mail.gmail.com>
 <CAFUVuJzXv6Ggz9iSMm6ehUVeNSFY3t-mn=jh7QqTiDuUBmzDCg@mail.gmail.com>
 <CAH_7VOnDW0Y7vXUZfChaM_JRgRg6c9uXs6+RzHt886fxo4AsUw@mail.gmail.com>
 <CAH_7VOmxzQcF7nNcDC42AeSZGFNdMO0O98zb9AroxPz51zHR1Q@mail.gmail.com>
 <883b38be-eeb7-8052-4395-618484a5ef97@gmail.com>
 <CAH_7VOnnkY2ee1QXVbZ+VzNLJg2bZVPjdKpVqkGoc=ZyKj635Q@mail.gmail.com>
 <c85ebe15-38fc-9b66-3a67-656a9b969f88@gmail.com>
 <CAH_7VOks9qCDhRzKWC2vxp2OYfLAqcdFuRRuMtB3=0dQ9nSJGQ@mail.gmail.com>
 <CAH_7VO=FQmm_qVQ4aBw0Krmza61TAz3U97JWx9wNbdSPACY7AQ@mail.gmail.com>
 <CAH_7VOm-RbYEyhCa-okvMCTMCHLsnqgEcCLH8JOQhLHDArsZsA@mail.gmail.com>
 <PAXPR02MB7181766DC8C9020FEDD0FBA892699@PAXPR02MB7181.eurprd02.prod.outlook.com>
Message-ID: <CAH_7VOmAcW0HjfADb_34aRNAWCn-78wBjEntiAMFX=gRijXL7g@mail.gmail.com>

Thank you for these thoughts. One thing that comes to mind in mixed models
for me is that not all mixed models incorporate both random intercepts and
slopes, so there may be a need to account for additional heteroskedasticity
in the case of random-intercepts only models?

There is also the consideration one has to make with predictors that are
factors vs. continuous (where one aggregates over the factor levels to
arrive at an estimate--I think this relates to the absorb command in STATA
whether in fixed or random models).

This paper by Cameron & Miller (which includes STATA relevant code) I also
found valuable, but have had to reread several times to fully appreciate
the complexity of this discourse:
http://jhr.uwpress.org/content/50/2/317.short?casa_token=Bo1aDvwZErEAAAAA:0sIhoGcywMWMXC1mnhqwW8cLNkoY-R8aOXqcMiFGISWYNaRP2nYIhzCbbRJ21GtKdRXa46hK4g

Best regards,
J.D.

On Sun, Aug 14, 2022 at 7:56 AM Fernando Pedro Bruna Quintas <f.bruna at udc.es>
wrote:

> Hi,
>
> I have followed only partially this thread. I also fail to understand the
> point of using clustered errors with mixed models People using Stata often
> calculate those cluster standard errors, at least in my disciplines in
> social sciences, using the "mixed" function. In R that was not possible
> until recently, as far as I know. For instance, tab_model() function from
> sjPlot does not allow calculation of clustered standard errors for models
> estimated with lme4 package. The recent package WeMix allows for that
> calculation, but only because it replicates what Stata mixed function does,
> but the authors do not justify why that calculation may be useful.
>
> The calculation of clustered standard errors is a way of capturing the
> effects of a smaller effective sample size when there are correlations by
> groups. However, that corrections is one of the main concerns of mixed
> modelling, as far as I understand.
>
> Abadie et al. 2022 do not recommend applying clustered standard error by
> default in standard regressions, and I understand that there are still less
> reasons to do it in mixed models.
>
> https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwjVi57ioMb5AhVFnf0HHUAkCwkQFnoECAMQAQ&url=https%3A%2F%2Feconomics.mit.edu%2Ffiles%2F13927&usg=AOvVaw0vtAkWz0AFlwAPOEKYQgNq
>
> I appreciate more comments regarding this topic.
>
> Thank you
>
> Fernando Bruna
> Department of Economics
> Universidade da Corunna, Spain
>
> ------------------------------
> *De:* R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> en
> nombre de J.D. Haltigan <jhaltiga at gmail.com>
> *Enviado:* domingo, 14 de agosto de 2022 1:32
> *Para:* Ben Bolker <bbolker at gmail.com>
> *Cc:* r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
> *Asunto:* Re: [R-sig-ME] Cluster-robust SEs & random effects -- seeking
> some clarification
>
> One further post perhaps framing my question slightly differently (or
> altogether more generally):
>
> What, specifically, do cluster-robust/robust SEs allow one to do with more
> accuracy/precision *if* they are already using both random effects and
> slopes to model relevant cluster-specific effects. Is it the case that
> there may be any number of sources that could potentially account for
> sources of heteroskedasticity (i.e., autoregressive structure in the case
> of repeated measurements/time variables) that using the cluster robust SEs
> would be of value for in making more precise inference assuming some
> misspecification of the random effects structure of the model?
>
> Relatedly, is there a 'seminal' or 'key' paper that provides a deep dive on
> the concept of heteroskedasticity? I have a few on hand, but wanted to see
> if there was something I might not be aware of .
>
> On Wed, Aug 3, 2022 at 11:46 PM J.D. Haltigan <jhaltiga at gmail.com> wrote:
>
> > Thought I would bump my last post to see if anyone might weigh in on my
> > more general statements about re: unions (clusters). Would be most
> > appreciated as I continue to wrap my head around some things.
> >
> > Thanks in advance for any thoughts. I appreciate your time.
> >
> > On Sat, Jul 30, 2022 at 8:43 PM J.D. Haltigan <jhaltiga at gmail.com>
> wrote:
> >
> >> And to take one more step: the inference is that the single
> >> population-level treatment effect is drawing from a 'random sample' of
> >> unions (clusters). That is, one can not assume that union's are the
> same.
> >> They are not interchangeable. They are drawn from a random population.
> This
> >> is the point of the exercise for me. If we remove the random effect for
> >> union in the model I shared, we end up with a model in which only the
> fixed
> >> effects of pairID (treatment-control pairs for each pair of treatment
> >> control villages) are estimated (albeit using cluster-robust SEs). So,
> if
> >> by adding that random effect for union the treatment intervention is no
> >> longer significant (as opposed to a model in which there is no random
> >> effect of union modeled), what is that telling us? That some of the
> between
> >> cluster (union) variance in intercepts is contributing to variation in
> the
> >> response variable, yes?
> >>
> >> I realize you have not read the paper, nor are necessarily interested in
> >> this discourse, but any remarks are greatly appreciated.
> >>
> >>
> >> On Sat, Jul 30, 2022 at 8:36 PM Ben Bolker <bbolker at gmail.com> wrote:
> >>
> >>>    Yes.
> >>>
> >>> On 2022-07-30 8:12 p.m., J.D. Haltigan wrote:
> >>> > Thanks, Ben. So in the model you remarked on, would that be a
> >>> > 'random-intercepts only' model?
> >>> >
> >>> >
> >>> > On Sat, Jul 30, 2022 at 7:53 PM Ben Bolker <bbolker at gmail.com
> >>> > <mailto:bbolker at gmail.com <bbolker at gmail.com>>> wrote:
> >>> >
> >>> >     I haven't been following the whole thread that carefully, but I
> >>> want to
> >>> >     emphasize that
> >>> >
> >>> >         posXsymp~treatment + pairID + (1 | union)
> >>> >
> >>> >     is *not*, by any definition I'm familiar with, a "random-slopes
> >>> model";
> >>> >     that is, it only estimates a single population-level treatment
> >>> >     effect/doesn't allow the effect of treatment to vary across
> groups
> >>> >     defined by 'union'.  You would need a random-effect term of the
> >>> form
> >>> >     (treatment | union).
> >>> >
> >>> >         Reasons why you might *not* want to do this:
> >>> >
> >>> >        * if treatment only varies across and not within levels of
> union
> >>> >     ("union is nested within treatment" according to some
> terminology),
> >>> >     then
> >>> >     this variation is unidentifiable
> >>> >        * maybe you have decided that you don't have enough data/want
> a
> >>> more
> >>> >     parsimonious model.
> >>> >
> >>> >         Schielzeth and Forstmeier, among many others (this is the
> >>> example I
> >>> >     know of), have cautioned about the consequences of leaving out
> >>> >     random-slopes terms.
> >>> >
> >>> >     Schielzeth, Holger, and Wolfgang Forstmeier. ?Conclusions beyond
> >>> >     Support: Overconfident Estimates in Mixed Models.? Behavioral
> >>> Ecology
> >>> >     20, no. 2 (March 1, 2009): 416?20.
> >>> >
> https://eur02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fdoi.org%2F10.1093%2Fbeheco%2Farn145&amp;data=05%7C01%7Cf.bruna%40udc.es%7Ccff181a16d084542b64e08da7d843c79%7Ccea1ea3e60b24f75a6c2a6022e8f961b%7C0%7C0%7C637960304201466714%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=HIiZ5D1zlFIyoL9ZHv%2Fv%2F3sJW6ecsXtCU3wduKtZRS4%3D&amp;reserved=0
> >>> >     <
> https://eur02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fdoi.org%2F10.1093%2Fbeheco%2Farn145&amp;data=05%7C01%7Cf.bruna%40udc.es%7Ccff181a16d084542b64e08da7d843c79%7Ccea1ea3e60b24f75a6c2a6022e8f961b%7C0%7C0%7C637960304201466714%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=HIiZ5D1zlFIyoL9ZHv%2Fv%2F3sJW6ecsXtCU3wduKtZRS4%3D&amp;reserved=0
> >.
> >>> >
> >>> >
> >>> >     On 2022-07-30 7:43 p.m., J.D. Haltigan wrote:
> >>> >      > Addendum:
> >>> >      >
> >>> >      > It just occurred to me on my walk that I think I am getting a
> >>> bit
> >>> >     lost in
> >>> >      > some of the differences in nomenclature across scientific
> silos.
> >>> >     In the
> >>> >      > original model that they specified, which treated the 'pairID'
> >>> >     variable as
> >>> >      > a control variable for which they controlled for 'fixed
> >>> effects' of
> >>> >      > control/treatment villages (in their own language in the
> paper)
> >>> using
> >>> >      > cluster-robust SEs, I think this is indeed a
> 'random-intercepts
> >>> >     only' model
> >>> >      > in the language of Hamaker et al. They implement the 'absorb'
> >>> >     command in
> >>> >      > STATA which I believe aggregates across the pairIDs to
> generate
> >>> an
> >>> >      > 'omnibus' F-test of sorts for the pairID variable (in the
> ANOVA
> >>> >      > nomenclature). I say this as when I specify the pairID
> variable
> >>> >     in the lmer
> >>> >      > model I shared (or in a fixest model I conducted to replicate
> >>> the
> >>> >     original
> >>> >      > Abalauck results in R), I get the estimates for all the pairs
> >>> >     (i.e., there
> >>> >      > is no way to aggregate across them--though I think formally
> the
> >>> >     models are
> >>> >      > the same if we are unconcerned about any one pairID
> >>> >     [treatment/control
> >>> >      > village pair].
> >>> >      >
> >>> >      > So, in the lmer model I shared where I specify a specific
> random
> >>> >     effects
> >>> >      > term for the 'cluster' variable, I think this indeed is
> allowing
> >>> >     for random
> >>> >      > slopes across the clusters which implies the treatment effect
> >>> may
> >>> >     vary
> >>> >      > across the clusters (and we might anticipate it will for
> various
> >>> >     reasons I
> >>> >      > can elaborate on). More generally: we are generalizing to
> *any*
> >>> >     universe of
> >>> >      > villages (say in the entire world) where the treatment
> >>> >     intervention (masks)
> >>> >      > may vary across villages. This is the crux of invoking the
> >>> random
> >>> >     effects
> >>> >      > model (i.e., random slopes model).
> >>> >      >
> >>> >      > I realize this is a mouthful, but I think the way these terms
> >>> (e.g.,
> >>> >      > random/fixed effects models etc.) are used across disciplines
> >>> >     makes things
> >>> >      > a bit confusing.
> >>> >      >
> >>> >      > On Sat, Jul 30, 2022 at 5:25 PM J.D. Haltigan <
> >>> jhaltiga at gmail.com
> >>> >     <mailto:jhaltiga at gmail.com <jhaltiga at gmail.com>>> wrote:
> >>> >      >
> >>> >      >> This is a very helpful walkthrough, James. My responses are
> >>> >     italicized
> >>> >      >> under yours to maintain thread readability. The key is
> >>> >     Generalizability
> >>> >      >> here and (as I also note in my last reply) the idea is to
> >>> >     Generalize to a
> >>> >      >> universe of "any villages or clusters." That is, the target
> >>> >     population we
> >>> >      >> are generalizing to is *any* random population.
> >>> >      >>
> >>> >      >> On Sat, Jul 30, 2022 at 3:01 PM James Pustejovsky
> >>> >     <jepusto at gmail.com <mailto:jepusto at gmail.com <jepusto at gmail.com>
> >>
> >>> >      >> wrote:
> >>> >      >>
> >>> >      >>> Hi J.D.,
> >>> >      >>> A few comments/reactions inline below.
> >>> >      >>> James
> >>> >      >>>
> >>> >      >>> On Wed, Jul 27, 2022 at 5:37 PM J.D. Haltigan
> >>> >     <jhaltiga at gmail.com <mailto:jhaltiga at gmail.com
> <jhaltiga at gmail.com>>> wrote:
> >>> >      >>>
> >>> >      >>>> ...
> >>> >      >>>>
> >>> >      >>> In the original investigation, the authors did not invoke a
> >>> random
> >>> >      >>>> effects model (but did use the pairIDs to control for fixed
> >>> >     effects as
> >>> >      >>>> noted and with robust SEs). Thus, in the original
> >>> >     investigation there was
> >>> >      >>>> *no* specification of a random effects model for the
> >>> 'cluster'
> >>> >     variable. We
> >>> >      >>>> know from some other work there were some biases in village
> >>> >     mapping and
> >>> >      >>>> other possible sources of between-cluster variation that
> >>> might be
> >>> >      >>>> anticipated to have influence--at the random intercepts
> >>> >     level--so we are
> >>> >      >>>> looking into how specifying 'cluster' as a random effect
> >>> might
> >>> >     change the
> >>> >      >>>> fixed effects estimates for the treatment intervention
> >>> effect.
> >>> >     In the
> >>> >      >>>> Hamaker et al. language, it is indeed a 'random intercepts'
> >>> >     only model.
> >>> >      >>>>
> >>> >      >>>
> >>> >      >>> I don't follow how using a random intercepts model improves
> >>> the
> >>> >      >>> generalizability warrant here. The random intercepts model
> is
> >>> >     essentially
> >>> >      >>> just a re-weighted average of the pair-specific effects in
> the
> >>> >     original
> >>> >      >>> analysis, where the weights are optimally efficient if the
> >>> model is
> >>> >      >>> correctly specified. That last clause carries a lot of
> weight
> >>> >     here--correct
> >>> >      >>> specification means 1) treatment assignment is unrelated to
> >>> the
> >>> >     random
> >>> >      >>> effects, 2) the treatment effect is constant across
> clusters,
> >>> 3)
> >>> >      >>> distributional assumptions are valid (i.e., homoskedasticity
> >>> at
> >>> >     each level
> >>> >      >>> of the model).
> >>> >      >>>
> >>> >      >>> If the effects are heterogeneous, then I would think that
> >>> including
> >>> >      >>> random slopes on the treatment indicator would provide a
> >>> better
> >>> >     basis for
> >>> >      >>> generalization. But even then, the warrant is still pretty
> >>> >     vague---what is
> >>> >      >>> the hypothetical population of villages from which the
> >>> observed
> >>> >     villages
> >>> >      >>> are sampled?
> >>> >      >>>
> >>> >      >>
> >>> >      >> *In the most basic model (without baseline controls) the
> model
> >>> >     takes the
> >>> >      >> form: myModel = lmer(posXsymp~treatment + pairID + (1 |
> union),
> >>> >     data =
> >>> >      >> myData). I believe--correct me if I am wrong--that this
> >>> reflects a
> >>> >      >> random-intercepts only model, but I may be mistaken. If I am,
> >>> >     and this is
> >>> >      >> allowing for random slopes on the treatment indicator, then I
> >>> >     will need to
> >>> >      >> rethink my statements.  *
> >>> >      >>
> >>> >      >>>
> >>> >      >>>
> >>> >      >>>> Given this, however, does it also make sense to include the
> >>> >     cluster
> >>> >      >>>> robust SEs for the fixed effects which would account for
> >>> possible
> >>> >      >>>> heterogeneity of treatment effects (i.e., slopes) across
> >>> >     clusters?s
> >>> >      >>>>
> >>> >      >>>> If you're committed to the random intercepts model, then
> yes
> >>> I
> >>> >     think so
> >>> >      >>> because using cluster robust SEs at least acknowledges the
> >>> >     possibility of
> >>> >      >>> heterogeneous treatment effects.
> >>> >      >>>
> >>> >      >>
> >>> >      >> *If the above model does allow for both random intercepts and
> >>> >     slopes, then
> >>> >      >> perhaps the use of cluster robust SEs is redundant in some
> >>> sense
> >>> >     since the
> >>> >      >> random slopes would be modeling the heterogeneity in
> treatment
> >>> >     effects?*
> >>> >      >>
> >>> >      >>>
> >>> >      >>>
> >>> >      >>>
> >>> >      >>>> Bottom line: in their original analyses, clusters are seen
> as
> >>> >      >>>> interchangeable from a conceptual perspective (rather than
> >>> >     drawn from a
> >>> >      >>>> random universe of observations). When one scales up
> evidence
> >>> >     to a universe
> >>> >      >>>> of observations that are random (as they would be in the
> >>> >     intended universe
> >>> >      >>>> of inference in the real-world), then we are better
> >>> >     positioned, I think, to
> >>> >      >>>> adjudicate whether the mask intervention effect is
> >>> 'practically
> >>> >      >>>> significant' (in addition to whether the focal effect
> remains
> >>> >     marginally
> >>> >      >>>> significant from a frequentist perspective).
> >>> >      >>>>
> >>> >      >>> As noted above, this argument is a bit vague to me. If
> there's
> >>> >     concern
> >>> >      >>> about generalizability, then my first question would be:
> what
> >>> >     is the target
> >>> >      >>> population to which you are trying to generalize?
> >>> >      >>>
> >>> >      >>
> >>> >      >> *Essentially, the target population we are trying to
> generalize
> >>> >     to is a
> >>> >      >> random selection of villages. Any random selection of
> villages.
> >>> >     In other
> >>> >      >> words, villages should not be seen as interchangeable. We are
> >>> >     interested in
> >>> >      >> whether the effects generalize to any randomly selected
> >>> village. *
> >>> >      >>
> >>> >      >>>
> >>> >      >>>
> >>> >      >>
> >>> >      >
> >>> >      >       [[alternative HTML version deleted]]
> >>> >      >
> >>> >      > _______________________________________________
> >>> >      > R-sig-mixed-models at r-project.org
> >>> >     <mailto:R-sig-mixed-models at r-project.org
> <R-sig-mixed-models at r-project.org>> mailing list
> >>> >      >
> https://eur02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=05%7C01%7Cf.bruna%40udc.es%7Ccff181a16d084542b64e08da7d843c79%7Ccea1ea3e60b24f75a6c2a6022e8f961b%7C0%7C0%7C637960304201466714%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=YM5skHwDtAoKz1KVXrCB1bjBRLvTE8UMuZjaE964iBY%3D&amp;reserved=0
> >>> >     <
> https://eur02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=05%7C01%7Cf.bruna%40udc.es%7Ccff181a16d084542b64e08da7d843c79%7Ccea1ea3e60b24f75a6c2a6022e8f961b%7C0%7C0%7C637960304201466714%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=YM5skHwDtAoKz1KVXrCB1bjBRLvTE8UMuZjaE964iBY%3D&amp;reserved=0
> >
> >>> >
> >>> >     --
> >>> >     Dr. Benjamin Bolker
> >>> >     Professor, Mathematics & Statistics and Biology, McMaster
> >>> University
> >>> >     Director, School of Computational Science and Engineering
> >>> >     (Acting) Graduate chair, Mathematics & Statistics
> >>> >
> >>> >     _______________________________________________
> >>> >     R-sig-mixed-models at r-project.org
> >>> >     <mailto:R-sig-mixed-models at r-project.org
> <R-sig-mixed-models at r-project.org>> mailing list
> >>> >
> https://eur02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=05%7C01%7Cf.bruna%40udc.es%7Ccff181a16d084542b64e08da7d843c79%7Ccea1ea3e60b24f75a6c2a6022e8f961b%7C0%7C0%7C637960304201466714%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=YM5skHwDtAoKz1KVXrCB1bjBRLvTE8UMuZjaE964iBY%3D&amp;reserved=0
> >>> >     <
> https://eur02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=05%7C01%7Cf.bruna%40udc.es%7Ccff181a16d084542b64e08da7d843c79%7Ccea1ea3e60b24f75a6c2a6022e8f961b%7C0%7C0%7C637960304201466714%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=YM5skHwDtAoKz1KVXrCB1bjBRLvTE8UMuZjaE964iBY%3D&amp;reserved=0
> >
> >>> >
> >>>
> >>> --
> >>> Dr. Benjamin Bolker
> >>> Professor, Mathematics & Statistics and Biology, McMaster University
> >>> Director, School of Computational Science and Engineering
> >>> (Acting) Graduate chair, Mathematics & Statistics
> >>>
> >>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
>
> https://eur02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=05%7C01%7Cf.bruna%40udc.es%7Ccff181a16d084542b64e08da7d843c79%7Ccea1ea3e60b24f75a6c2a6022e8f961b%7C0%7C0%7C637960304201466714%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=YM5skHwDtAoKz1KVXrCB1bjBRLvTE8UMuZjaE964iBY%3D&amp;reserved=0
>

	[[alternative HTML version deleted]]


From jepu@to @end|ng |rom gm@||@com  Mon Aug 15 21:18:31 2022
From: jepu@to @end|ng |rom gm@||@com (James Pustejovsky)
Date: Mon, 15 Aug 2022 14:18:31 -0500
Subject: [R-sig-ME] Cluster-robust SEs & random effects -- seeking some
 clarification
In-Reply-To: <CAH_7VOm-RbYEyhCa-okvMCTMCHLsnqgEcCLH8JOQhLHDArsZsA@mail.gmail.com>
References: <CAH_7VOkx8+Pwpx+Rovgm0=k2Nde3TvmJpAQ_28O_NjQTY82h4g@mail.gmail.com>
 <CAFUVuJyh56KYctgrB1TSn8JB01h+Lh93Oh--dPvOK616b=x3LQ@mail.gmail.com>
 <CAH_7VO=aOOhT8TWJ7rAfY4EC+8yOepLpkpg0TcXgjN+wwk2c=w@mail.gmail.com>
 <CAFUVuJztqcXppr8VSDUXWYmTtcyDk+TVXDc3WPNkfcPJNRmaGA@mail.gmail.com>
 <CAH_7VO=pDmKDbpy8CfOTewcqXvwcfa1CRyRoohcRbQ=zz5ayOQ@mail.gmail.com>
 <CAFUVuJzXv6Ggz9iSMm6ehUVeNSFY3t-mn=jh7QqTiDuUBmzDCg@mail.gmail.com>
 <CAH_7VOnDW0Y7vXUZfChaM_JRgRg6c9uXs6+RzHt886fxo4AsUw@mail.gmail.com>
 <CAH_7VOmxzQcF7nNcDC42AeSZGFNdMO0O98zb9AroxPz51zHR1Q@mail.gmail.com>
 <883b38be-eeb7-8052-4395-618484a5ef97@gmail.com>
 <CAH_7VOnnkY2ee1QXVbZ+VzNLJg2bZVPjdKpVqkGoc=ZyKj635Q@mail.gmail.com>
 <c85ebe15-38fc-9b66-3a67-656a9b969f88@gmail.com>
 <CAH_7VOks9qCDhRzKWC2vxp2OYfLAqcdFuRRuMtB3=0dQ9nSJGQ@mail.gmail.com>
 <CAH_7VO=FQmm_qVQ4aBw0Krmza61TAz3U97JWx9wNbdSPACY7AQ@mail.gmail.com>
 <CAH_7VOm-RbYEyhCa-okvMCTMCHLsnqgEcCLH8JOQhLHDArsZsA@mail.gmail.com>
Message-ID: <CAFUVuJwwX9deQBAysGMEjT5=cU4ujjNOveGto_KayEhhdLL1Ew@mail.gmail.com>

Hi JD,

Below are a couple of further thoughts on the questions you posed.

James

On Sat, Aug 13, 2022 at 6:33 PM J.D. Haltigan <jhaltiga at gmail.com> wrote:

> One further post perhaps framing my question slightly differently (or
> altogether more generally):
>
> What, specifically, do cluster-robust/robust SEs allow one to do with more
> accuracy/precision *if* they are already using both random effects and
> slopes to model relevant cluster-specific effects.


Just to be clear, using cluster-robust SEs does not change anything about
the accuracy or precision of the model's coefficient estimates. Using them
or not using them is purely a matter of how to estimate standard errors
(and thus build test statistics or confidence intervals) for those
coefficient estimates.

The advantage of using clustered SEs in a random effects model is that
doing so captures unmodeled sources of dependence or heteroskedasticity in
the errors. Thus, if you trust the specification of your random effects
structure, then there is no need to use clustered SEs. On the other hand,
if you (or your audience) are skeptical that you've got the right
specification, then clustered SEs are helpful. Think of them as an
insurance policy for your SEs/t-statistics/CIs, so that they remain valid
even in the event that your model might be incorrectly specified in some
respects.


> Is it the case that
> there may be any number of sources that could potentially account for
> sources of heteroskedasticity (i.e., autoregressive structure in the case
> of repeated measurements/time variables) that using the cluster robust SEs
> would be of value for in making more precise inference assuming some
> misspecification of the random effects structure of the model?
>
>
Yes.


> Relatedly, is there a 'seminal' or 'key' paper that provides a deep dive on
> the concept of heteroskedasticity? I have a few on hand, but wanted to see
> if there was something I might not be aware of .
>

Cameron and Miller (noted in your subsequent paper) is an excellent,
thorough survey from the econometric perspective. McNeish and Kelley (2019;
https://doi.org/10.1037/met0000182) is a great resource that addresses the
fixed effects vs mixed effects modeling contexts. To be a bit
self-promotional, I have a working paper with Young Ri Lee that looks at
these issues in the context of multi-way clustering:
https://psyarxiv.com/f9mr2
The simulations in the paper illustrate the consequences of several
different forms of model mis-specification (such as omission of random
slopes).

	[[alternative HTML version deleted]]


From jh@|t|g@ @end|ng |rom gm@||@com  Mon Aug 15 23:01:35 2022
From: jh@|t|g@ @end|ng |rom gm@||@com (J.D. Haltigan)
Date: Mon, 15 Aug 2022 17:01:35 -0400
Subject: [R-sig-ME] Cluster-robust SEs & random effects -- seeking some
 clarification
In-Reply-To: <CAFUVuJwwX9deQBAysGMEjT5=cU4ujjNOveGto_KayEhhdLL1Ew@mail.gmail.com>
References: <CAH_7VOkx8+Pwpx+Rovgm0=k2Nde3TvmJpAQ_28O_NjQTY82h4g@mail.gmail.com>
 <CAFUVuJyh56KYctgrB1TSn8JB01h+Lh93Oh--dPvOK616b=x3LQ@mail.gmail.com>
 <CAH_7VO=aOOhT8TWJ7rAfY4EC+8yOepLpkpg0TcXgjN+wwk2c=w@mail.gmail.com>
 <CAFUVuJztqcXppr8VSDUXWYmTtcyDk+TVXDc3WPNkfcPJNRmaGA@mail.gmail.com>
 <CAH_7VO=pDmKDbpy8CfOTewcqXvwcfa1CRyRoohcRbQ=zz5ayOQ@mail.gmail.com>
 <CAFUVuJzXv6Ggz9iSMm6ehUVeNSFY3t-mn=jh7QqTiDuUBmzDCg@mail.gmail.com>
 <CAH_7VOnDW0Y7vXUZfChaM_JRgRg6c9uXs6+RzHt886fxo4AsUw@mail.gmail.com>
 <CAH_7VOmxzQcF7nNcDC42AeSZGFNdMO0O98zb9AroxPz51zHR1Q@mail.gmail.com>
 <883b38be-eeb7-8052-4395-618484a5ef97@gmail.com>
 <CAH_7VOnnkY2ee1QXVbZ+VzNLJg2bZVPjdKpVqkGoc=ZyKj635Q@mail.gmail.com>
 <c85ebe15-38fc-9b66-3a67-656a9b969f88@gmail.com>
 <CAH_7VOks9qCDhRzKWC2vxp2OYfLAqcdFuRRuMtB3=0dQ9nSJGQ@mail.gmail.com>
 <CAH_7VO=FQmm_qVQ4aBw0Krmza61TAz3U97JWx9wNbdSPACY7AQ@mail.gmail.com>
 <CAH_7VOm-RbYEyhCa-okvMCTMCHLsnqgEcCLH8JOQhLHDArsZsA@mail.gmail.com>
 <CAFUVuJwwX9deQBAysGMEjT5=cU4ujjNOveGto_KayEhhdLL1Ew@mail.gmail.com>
Message-ID: <CAH_7VOnVK=n77F-KT3irQp4YJfq=TwAq-=v3_7hDJy4DcOZUgw@mail.gmail.com>

Thanks for this further clarification, James.

By precision I meant accuracy of inference which, I believe, is what more
'robust' SEs that account for umodeled heteroskedasticity, will allow for,
correct? "Accurate statistical inference" in the language of Cameron &
Miller (2015).

When you note, 'if you trust the specification of your random effects
structure' can you elaborate on this? I imagine in the extreme, no random
effects structure will ever truly be perfect, so I guess it comes down to
some combination of theory, practicality, and model tractability?

JD

On Mon, Aug 15, 2022 at 3:18 PM James Pustejovsky <jepusto at gmail.com> wrote:

> Hi JD,
>
> Below are a couple of further thoughts on the questions you posed.
>
> James
>
> On Sat, Aug 13, 2022 at 6:33 PM J.D. Haltigan <jhaltiga at gmail.com> wrote:
>
>> One further post perhaps framing my question slightly differently (or
>> altogether more generally):
>>
>> What, specifically, do cluster-robust/robust SEs allow one to do with more
>> accuracy/precision *if* they are already using both random effects and
>> slopes to model relevant cluster-specific effects.
>
>
> Just to be clear, using cluster-robust SEs does not change anything about
> the accuracy or precision of the model's coefficient estimates. Using them
> or not using them is purely a matter of how to estimate standard errors
> (and thus build test statistics or confidence intervals) for those
> coefficient estimates.
>
> The advantage of using clustered SEs in a random effects model is that
> doing so captures unmodeled sources of dependence or heteroskedasticity in
> the errors. Thus, if you trust the specification of your random effects
> structure, then there is no need to use clustered SEs. On the other hand,
> if you (or your audience) are skeptical that you've got the right
> specification, then clustered SEs are helpful. Think of them as an
> insurance policy for your SEs/t-statistics/CIs, so that they remain valid
> even in the event that your model might be incorrectly specified in some
> respects.
>
>
>> Is it the case that
>> there may be any number of sources that could potentially account for
>> sources of heteroskedasticity (i.e., autoregressive structure in the case
>> of repeated measurements/time variables) that using the cluster robust SEs
>> would be of value for in making more precise inference assuming some
>> misspecification of the random effects structure of the model?
>>
>>
> Yes.
>
>
>> Relatedly, is there a 'seminal' or 'key' paper that provides a deep dive
>> on
>> the concept of heteroskedasticity? I have a few on hand, but wanted to see
>> if there was something I might not be aware of .
>>
>
> Cameron and Miller (noted in your subsequent paper) is an excellent,
> thorough survey from the econometric perspective. McNeish and Kelley (2019;
> https://doi.org/10.1037/met0000182) is a great resource that addresses
> the fixed effects vs mixed effects modeling contexts. To be a bit
> self-promotional, I have a working paper with Young Ri Lee that looks at
> these issues in the context of multi-way clustering:
> https://psyarxiv.com/f9mr2
> The simulations in the paper illustrate the consequences of several
> different forms of model mis-specification (such as omission of random
> slopes).
>
>

	[[alternative HTML version deleted]]


From jepu@to @end|ng |rom gm@||@com  Tue Aug 16 04:00:44 2022
From: jepu@to @end|ng |rom gm@||@com (James Pustejovsky)
Date: Mon, 15 Aug 2022 21:00:44 -0500
Subject: [R-sig-ME] Cluster-robust SEs & random effects -- seeking some
 clarification
In-Reply-To: <CAH_7VOnVK=n77F-KT3irQp4YJfq=TwAq-=v3_7hDJy4DcOZUgw@mail.gmail.com>
References: <CAH_7VOkx8+Pwpx+Rovgm0=k2Nde3TvmJpAQ_28O_NjQTY82h4g@mail.gmail.com>
 <CAFUVuJyh56KYctgrB1TSn8JB01h+Lh93Oh--dPvOK616b=x3LQ@mail.gmail.com>
 <CAH_7VO=aOOhT8TWJ7rAfY4EC+8yOepLpkpg0TcXgjN+wwk2c=w@mail.gmail.com>
 <CAFUVuJztqcXppr8VSDUXWYmTtcyDk+TVXDc3WPNkfcPJNRmaGA@mail.gmail.com>
 <CAH_7VO=pDmKDbpy8CfOTewcqXvwcfa1CRyRoohcRbQ=zz5ayOQ@mail.gmail.com>
 <CAFUVuJzXv6Ggz9iSMm6ehUVeNSFY3t-mn=jh7QqTiDuUBmzDCg@mail.gmail.com>
 <CAH_7VOnDW0Y7vXUZfChaM_JRgRg6c9uXs6+RzHt886fxo4AsUw@mail.gmail.com>
 <CAH_7VOmxzQcF7nNcDC42AeSZGFNdMO0O98zb9AroxPz51zHR1Q@mail.gmail.com>
 <883b38be-eeb7-8052-4395-618484a5ef97@gmail.com>
 <CAH_7VOnnkY2ee1QXVbZ+VzNLJg2bZVPjdKpVqkGoc=ZyKj635Q@mail.gmail.com>
 <c85ebe15-38fc-9b66-3a67-656a9b969f88@gmail.com>
 <CAH_7VOks9qCDhRzKWC2vxp2OYfLAqcdFuRRuMtB3=0dQ9nSJGQ@mail.gmail.com>
 <CAH_7VO=FQmm_qVQ4aBw0Krmza61TAz3U97JWx9wNbdSPACY7AQ@mail.gmail.com>
 <CAH_7VOm-RbYEyhCa-okvMCTMCHLsnqgEcCLH8JOQhLHDArsZsA@mail.gmail.com>
 <CAFUVuJwwX9deQBAysGMEjT5=cU4ujjNOveGto_KayEhhdLL1Ew@mail.gmail.com>
 <CAH_7VOnVK=n77F-KT3irQp4YJfq=TwAq-=v3_7hDJy4DcOZUgw@mail.gmail.com>
Message-ID: <CAFUVuJyf+rYk8uk89SLaSEcT1XA0xD0F7f4HhK6q5ds5CA2H-w@mail.gmail.com>

>
>
> When you note, 'if you trust the specification of your random effects
> structure' can you elaborate on this? I imagine in the extreme, no random
> effects structure will ever truly be perfect, so I guess it comes down to
> some combination of theory, practicality, and model tractability?
>

Sure. Clearly, any model is a stylized and approximate representation of
the true process. By "trust the specification" I just mean that you--and
usually, also readers or potential critics--think that the random effects
structure of the model is an adequate representation of the features of the
data-generating process. In more colloquial terms, did you (the analyst) do
a good job of developing the model?

I think it's pretty helpful to think about this stuff in terms of
convincing an audience. In practice, and given the current reporting
conventions in social science disciplines, it's often pretty hard for
readers/reviewers/critics to gauge whether an analyst has done a good job.
In such contexts, cluster-robust SEs give some additional assurance (or
insurance, the analogy in my previous message) that the inferences can be
trusted even if the analyst didn't engage in a thorough, diligent
model-building process.

James

	[[alternative HTML version deleted]]


From jh@|t|g@ @end|ng |rom gm@||@com  Tue Aug 16 23:47:00 2022
From: jh@|t|g@ @end|ng |rom gm@||@com (J.D. Haltigan)
Date: Tue, 16 Aug 2022 17:47:00 -0400
Subject: [R-sig-ME] Cluster-robust SEs & random effects -- seeking some
 clarification
In-Reply-To: <CAFUVuJyf+rYk8uk89SLaSEcT1XA0xD0F7f4HhK6q5ds5CA2H-w@mail.gmail.com>
References: <CAH_7VOkx8+Pwpx+Rovgm0=k2Nde3TvmJpAQ_28O_NjQTY82h4g@mail.gmail.com>
 <CAFUVuJyh56KYctgrB1TSn8JB01h+Lh93Oh--dPvOK616b=x3LQ@mail.gmail.com>
 <CAH_7VO=aOOhT8TWJ7rAfY4EC+8yOepLpkpg0TcXgjN+wwk2c=w@mail.gmail.com>
 <CAFUVuJztqcXppr8VSDUXWYmTtcyDk+TVXDc3WPNkfcPJNRmaGA@mail.gmail.com>
 <CAH_7VO=pDmKDbpy8CfOTewcqXvwcfa1CRyRoohcRbQ=zz5ayOQ@mail.gmail.com>
 <CAFUVuJzXv6Ggz9iSMm6ehUVeNSFY3t-mn=jh7QqTiDuUBmzDCg@mail.gmail.com>
 <CAH_7VOnDW0Y7vXUZfChaM_JRgRg6c9uXs6+RzHt886fxo4AsUw@mail.gmail.com>
 <CAH_7VOmxzQcF7nNcDC42AeSZGFNdMO0O98zb9AroxPz51zHR1Q@mail.gmail.com>
 <883b38be-eeb7-8052-4395-618484a5ef97@gmail.com>
 <CAH_7VOnnkY2ee1QXVbZ+VzNLJg2bZVPjdKpVqkGoc=ZyKj635Q@mail.gmail.com>
 <c85ebe15-38fc-9b66-3a67-656a9b969f88@gmail.com>
 <CAH_7VOks9qCDhRzKWC2vxp2OYfLAqcdFuRRuMtB3=0dQ9nSJGQ@mail.gmail.com>
 <CAH_7VO=FQmm_qVQ4aBw0Krmza61TAz3U97JWx9wNbdSPACY7AQ@mail.gmail.com>
 <CAH_7VOm-RbYEyhCa-okvMCTMCHLsnqgEcCLH8JOQhLHDArsZsA@mail.gmail.com>
 <CAFUVuJwwX9deQBAysGMEjT5=cU4ujjNOveGto_KayEhhdLL1Ew@mail.gmail.com>
 <CAH_7VOnVK=n77F-KT3irQp4YJfq=TwAq-=v3_7hDJy4DcOZUgw@mail.gmail.com>
 <CAFUVuJyf+rYk8uk89SLaSEcT1XA0xD0F7f4HhK6q5ds5CA2H-w@mail.gmail.com>
Message-ID: <CAH_7VOm6-vFNb_GWnscFz0_fUCY2E4x8qe_Gixv0UBVZv8=5DQ@mail.gmail.com>

Thanks, James The McNeish & Kelley (2019) paper is one I was not aware of
despite my read of several other Kelley-authored articles.

Indeed, that paper provides a point of departure for a question on my work
on the Bangladesh RCT mask-intervention study mentioned earlier.

In short: they used cluster-affiliated dummy variables (read: the pairID
variable) in a fixed effect model. For their linear run with baseline
controls, their STATA code was:
reghdfe posXsymp treatment proper_mask_base prop_resp_ill_base_2,
absorb(pairID) vce(cluster union)

In translating this to a random-effects model using lmer, does it make
sense to include the pairID variable in the model *if* I treat the cluster
variable as its own random effect as:

lme4_1_B = lmer(posXsymp~treatment+proper_mask_base+prop_resp_ill_base_2 +
pairID + (1 | union), data = bdata.raw1)#lme4 package

I have mentioned previously that the lmer code above is a random-intercepts
only model. This is by design as there are mean-level differences in the
clusters to begin with on several background variables that are captured by
the random effects. I also am making a conceptual case that in order for
the mask study to have appropriate generalizability, one must assume or
treat clusters as *randomly* selected from a larger population of clusters.
Otherwise, any marginal effect of the mask-intervention (while perhaps more
accurately estimated in a fixed model), is not going to have the
generalizability to any population of human interactions. My focal question
nonetheless concerns how to treat the pairID variable in my translation of
their fixed effects model to a random effects model in lmer. If I include
the pairID variable as above, what does it reflect given that cluster is
treated as a random effect? I have a separate model where I eliminate the
pairID variable as:

lme4_1 = lmer(posXsymp~treatment+proper_mask_base+prop_resp_ill_base_2 + (1
| union), data = bdata.raw1)#lme4 package

*What is the substantive difference between these two models? *My sense is
that this gets at the separation of between/within effects and that the
pairID variable in their original STATA fixed effects model (a
cluster-affiliated variable in the language of McNeish & Kelley) is
analogous to the cluster variable itself BUT in their model, a) the
assumption is that clusters are interchangeable (not drawn from a random
population); and b) one can not estimate within-cluster/between cluster
effects using their parameterization (i.e., random effects--in my case
intercepts--for the clusters).

I realize this is a bit of a mouthful, but I was inspired to post after
reading the McNeish & Kelley and needed to get this out for my own thinking.

-JD

On Mon, Aug 15, 2022 at 10:00 PM James Pustejovsky <jepusto at gmail.com>
wrote:

>
>> When you note, 'if you trust the specification of your random effects
>> structure' can you elaborate on this? I imagine in the extreme, no random
>> effects structure will ever truly be perfect, so I guess it comes down to
>> some combination of theory, practicality, and model tractability?
>>
>
> Sure. Clearly, any model is a stylized and approximate representation of
> the true process. By "trust the specification" I just mean that you--and
> usually, also readers or potential critics--think that the random effects
> structure of the model is an adequate representation of the features of the
> data-generating process. In more colloquial terms, did you (the analyst) do
> a good job of developing the model?
>
> I think it's pretty helpful to think about this stuff in terms of
> convincing an audience. In practice, and given the current reporting
> conventions in social science disciplines, it's often pretty hard for
> readers/reviewers/critics to gauge whether an analyst has done a good job.
> In such contexts, cluster-robust SEs give some additional assurance (or
> insurance, the analogy in my previous message) that the inferences can be
> trusted even if the analyst didn't engage in a thorough, diligent
> model-building process.
>
> James
>

	[[alternative HTML version deleted]]


From kenj|ro @end|ng |rom @ho|n@@c@jp  Sat Aug 20 10:40:36 2022
From: kenj|ro @end|ng |rom @ho|n@@c@jp (N o s t a l g i a)
Date: Sat, 20 Aug 2022 17:40:36 +0900
Subject: [R-sig-ME] A question about multicollinear fixed/random factors
Message-ID: <aaa95994-803b-8390-472a-ed53aa42d21f@shoin.ac.jp>

Hi,

I am looking at a character variation in Japanese parliamentary 
minutes where the same character appears in two forms. In the 
parliament, there are a number of different committee meetings within 
the same session, and I am looking at 31 sessions over 10 years. The 
factors I am considering are: upper/lower house distinction, meetings 
(meetings within each session, which are different from session to 
session), days between 1949/5/20 (when the first parliament was held) 
and the meeting, and the word within which the character appears. Of 
these, meetings and the words are random factors, and they have 
hundreds of levels. The total number of cases is over one million.

The model I am considering is:

glmer (character ~ ul + days + (1|word) + (1|meeting), data = 
glmmdata.1, family = binomial)

And here is my question: Since a given meeting is a unique one not 
only in each session but in all the data, there would be a 
multicollinear relationship between the days and the meeting, so that 
specification of some meeting would necessarily result in a specific 
value of days. Is it a problem in GLMM to have such pair of fixed and 
random factors? If it is so, is there any ways to avoid the problem?

Thanks in advance,

Kenjiro Matsuda
Professor in Linguistics
Kobe Shoin Women's University
Kobe, Japan


From j|@ver|@@|mo @end|ng |rom gm@||@com  Sat Aug 20 12:15:10 2022
From: j|@ver|@@|mo @end|ng |rom gm@||@com (=?UTF-8?Q?Jo=c3=a3o_Ver=c3=adssimo?=)
Date: Sat, 20 Aug 2022 11:15:10 +0100
Subject: [R-sig-ME] A question about multicollinear fixed/random factors
In-Reply-To: <aaa95994-803b-8390-472a-ed53aa42d21f@shoin.ac.jp>
References: <aaa95994-803b-8390-472a-ed53aa42d21f@shoin.ac.jp>
Message-ID: <b4be3d3c-8e98-ccea-3c0b-52043ca5544d@gmail.com>

If I'm understanding this right, I don't think there is a problem at all.
Mixed-effects models can accommodate fixed effects at different levels 
and these can coexist with the random effects without any issues. Number 
of days is simply a 'Level-2' predictor, with a unique value for each 
meeting.

(for more complex random-effects structures, you might want to consider 
the inclusion of session as another random factor and/or of by-word 
random slopes)

Jo?o

On 20/08/2022 09:40, N o s t a l g i a wrote:
> Hi,
>
> I am looking at a character variation in Japanese parliamentary 
> minutes where the same character appears in two forms. In the 
> parliament, there are a number of different committee meetings within 
> the same session, and I am looking at 31 sessions over 10 years. The 
> factors I am considering are: upper/lower house distinction, meetings 
> (meetings within each session, which are different from session to 
> session), days between 1949/5/20 (when the first parliament was held) 
> and the meeting, and the word within which the character appears. Of 
> these, meetings and the words are random factors, and they have 
> hundreds of levels. The total number of cases is over one million.
>
> The model I am considering is:
>
> glmer (character ~ ul + days + (1|word) + (1|meeting), data = 
> glmmdata.1, family = binomial)
>
> And here is my question: Since a given meeting is a unique one not 
> only in each session but in all the data, there would be a 
> multicollinear relationship between the days and the meeting, so that 
> specification of some meeting would necessarily result in a specific 
> value of days. Is it a problem in GLMM to have such pair of fixed and 
> random factors? If it is so, is there any ways to avoid the problem?
>
> Thanks in advance,
>
> Kenjiro Matsuda
> Professor in Linguistics
> Kobe Shoin Women's University
> Kobe, Japan
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From kenj|ro @end|ng |rom @ho|n@@c@jp  Mon Aug 22 09:02:26 2022
From: kenj|ro @end|ng |rom @ho|n@@c@jp (N o s t a l g i a)
Date: Mon, 22 Aug 2022 16:02:26 +0900
Subject: [R-sig-ME] A question about multicollinear fixed/random factors
In-Reply-To: <b4be3d3c-8e98-ccea-3c0b-52043ca5544d@gmail.com>
References: <aaa95994-803b-8390-472a-ed53aa42d21f@shoin.ac.jp>
 <b4be3d3c-8e98-ccea-3c0b-52043ca5544d@gmail.com>
Message-ID: <a277bbf2-0560-8806-b807-eada37fe90a3@shoin.ac.jp>

Dear Prof. Ver?ssimo,

Thanks for your prompt reply. I will proceed to analyze the data with 
both days (as fixed) and the meeting (as random) included. Yes, I 
understand the inclusion of session as another random factor and 
by-word random slopes should be considered seriously.

Thanks again,

- Kenjiro Matsuda


On 2022/08/20 19:15, Jo?o Ver?ssimo wrote:
> If I'm understanding this right, I don't think there is a problem at all.
> Mixed-effects models can accommodate fixed effects at different levels 
> and these can coexist with the random effects without any issues. 
> Number of days is simply a 'Level-2' predictor, with a unique value 
> for each meeting.
> 
> (for more complex random-effects structures, you might want to 
> consider the inclusion of session as another random factor and/or of 
> by-word random slopes)
> 
> Jo?o
> 
> On 20/08/2022 09:40, N o s t a l g i a wrote:
>> Hi,
>>
>> I am looking at a character variation in Japanese parliamentary 
>> minutes where the same character appears in two forms. In the 
>> parliament, there are a number of different committee meetings 
>> within the same session, and I am looking at 31 sessions over 10 
>> years. The factors I am considering are: upper/lower house 
>> distinction, meetings (meetings within each session, which are 
>> different from session to session), days between 1949/5/20 (when the 
>> first parliament was held) and the meeting, and the word within 
>> which the character appears. Of these, meetings and the words are 
>> random factors, and they have hundreds of levels. The total number 
>> of cases is over one million.
>>
>> The model I am considering is:
>>
>> glmer (character ~ ul + days + (1|word) + (1|meeting), data = 
>> glmmdata.1, family = binomial)
>>
>> And here is my question: Since a given meeting is a unique one not 
>> only in each session but in all the data, there would be a 
>> multicollinear relationship between the days and the meeting, so 
>> that specification of some meeting would necessarily result in a 
>> specific value of days. Is it a problem in GLMM to have such pair of 
>> fixed and random factors? If it is so, is there any ways to avoid 
>> the problem?
>>
>> Thanks in advance,
>>
>> Kenjiro Matsuda
>> Professor in Linguistics
>> Kobe Shoin Women's University
>> Kobe, Japan
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 


From bbo|ker @end|ng |rom gm@||@com  Mon Aug 22 23:48:38 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 22 Aug 2022 17:48:38 -0400
Subject: [R-sig-ME] lmer under "single" nests
In-Reply-To: <CH2PR12MB3736A1E42479442CE7B4C2AC81649@CH2PR12MB3736.namprd12.prod.outlook.com>
References: <CABUvszxB1_SZmzvMWrohGyZmo50Kms+Hn+xYQTzS0=Um6Mg8GA@mail.gmail.com>
 <CH2PR12MB3736A1E42479442CE7B4C2AC81649@CH2PR12MB3736.namprd12.prod.outlook.com>
Message-ID: <CABghstS0J=oBZjKj6B5nm7vzBsR-429zvuF5bQGG_bhTkzzipA@mail.gmail.com>

  The 2008 reference looks a little bit naive/old-fashioned to me; the
2014 paper looks more useful.

  The answers to your questions (what methods should you use etc.)
will depend on the answers to some of these questions:

* are you more interested in fixed/population-level effects or in the
variance components? (The former are easier.)
* how many groups do you have at both levels? (I think but am not not
quite sure that 'B' represents donors and 'A' represents some
higher-level grouping variable [hospital etc.]?)
* how many observations *per group*? (i.e. having 1-2 kidneys per
donor, but 4-5 measurements per kidney, is much better than having a
single kidney per donor)
* the responses are continuous/will be treated as Gaussian? That makes
things *much* easier/better than if they were binary outcomes (which
is sort of a worst-case scenario)


On Thu, Aug 11, 2022 at 8:58 AM Pierce, Steven <pierces1 at msu.edu> wrote:
>
> Elena,
>
> You have what is sometimes called "sparsely clustered" data. Below are a couple methodology papers relevant to this situation.
>
> Clarke, P. (2008). When can group level clustering be ignored? Multilevel models versus single-level models with sparse data. Journal of Epidemiology and Community Health, 62, 752-758. https://doi.org/10.1136/jech.2007.060798
>
> McNeish, D. M. (2014). Modeling sparsely clustered data: Design-based, model based, and single-level methods. Psychological Methods, 19(4), 552-563. https://doi.org/10.1037/met0000024
>
>
> Steven J. Pierce, Ph.D.
> Associate Director
> Center for Statistical Training & Consulting (CSTAT)
> Michigan State University
>
> -----Original Message-----
> From: Elena Moreno <momae1112 at gmail.com>
> Sent: Wednesday, August 10, 2022 7:44 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] lmer under "single" nests
>
> Dear R-sig-mixed-models list:
>
> I first want to thank you for your attention and willingness to help people
> like me. I hope to get some light with my question:
>
> I am applying a nested model as "(1|A/B)", having two individuals per nest
> in most of the cases. However, some nests only have one individual. This is
> because I'm working with kidney transplant data: there are cases when two
> patients receive a kidney from the same donor (the donor gives both
> kidneys), but there are cases where the donor gives just one kidney (so the
> recipient doesn't share donor with anyone else).
>
> Patients have several measures of renal function (creatinine) over time.
>
> How does "lmer" handle this kind of situation when having some "single"
> (with just one individual) nests in combination with non-single nests? It
> is worth it to nest when, at most, there are only two patients per nest
> (donor)?
>
>
> If you need more details regarding the study design or even a sample of the
> data, please tell me. By the way, I am not mathematician so I find
> demonstrations difficult to understand but I am always eager and open to
> learn.
>
> Thank you very much and sorry for this naive question,
>
>
> Elena
>
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From @nge|o@@@mynt@@ @end|ng |rom |d|v@de  Thu Aug 25 19:20:41 2022
From: @nge|o@@@mynt@@ @end|ng |rom |d|v@de (Amyntas, Angelos)
Date: Thu, 25 Aug 2022 19:20:41 +0200
Subject: [R-sig-ME] multilevel model for split plot design
Message-ID: <85c655bd-b4ed-025a-dc66-f44d29bc3f7c@idiv.de>

Hello,

I am trying to figure out the correct specification of a multilevel 
model for a split plot design experiment (using dummy data). Here is a 
description of a simplified version of the design (code below): Each 
plot (i) has 2, 4, 8 or 16 plant species. In every plot, a subplot has 
remained as is (c), the other half received the treatment (t). Our 
hypothesis is that the effect of the treatment (z) on the response (y) 
in a plot will differ depending on species richness (x). I would 
therefore specify the treatment effect to vary by plot. When I do this 
using glmmTMB (or brms) the model fits without an issue. However lme4 
gives an error:

"number of observations (=160) <= number of random effects (=160) for 
term (1 + z | i); the random-effects parameters and the residual 
variance (or scale parameter) are probably unidentifiable"

To see if I understand that error, I tried changing the design to 3 
control and 3 treatment subplots per plot. (Which is not really an 
option for the experiment.)

Sure enough, lme4 fits the model without errors (but I do get a singular 
fit warning).

So my question is, is the random effect specification appropriate for 
the first version of the data? And if yes/no what should I make of the 
different behaviour of the two packages? (I have also tried regressing 
the c-t difference directly on richness, with results consistent with 
the mixed model; which makes me think that the model specification is fine?)

Thank you,

Angelos Amyntas

Here is a reprex:

library(tidyverse)
library(glmmTMB)
library(lme4)

set.seed(321)

d=data.frame(x = rep(c(2,4,8,16), each = 40),
 ???????????? y = NA,
 ???????????? z = rep(c("c","t"), 80),
 ???????????? i = as.factor(rep(1:80, each = 2)))

d$y[d$z=="c"] = 5 + .5*d$x[d$z=="c"] + rnorm(80)
d$y[d$z=="t"] = 4 + .25*d$x[d$z=="t"] + rnorm(80)

d$x=(d$x - mean(d$x))/sd(d$x)


m=glmmTMB(y ~ 1 + x + z + z:x + (1 + z|i), data = d)
summary(m)

m=lmer(y~1 + x + z + z:x + (1 + z|i), data = d)

# modeling the difference directly
d. = d %>%
 ? group_by(i) %>%
 ? summarise(x=first(x),
 ??????????? diff = y[z=="t"] - y[z=="c"])
m=glmmTMB(diff ~ 1 + x, data = d.)
summary(m)

# trying 3 replicates in each subplot
d=data.frame(x = rep(c(2,4,8,16), each = 40*3),
 ???????????? y = NA,
 ???????????? z = rep(rep(c("c","t"),each = 3), 80),
 ???????????? z_i = rep(c("c1","c2","c3","t1","t2","t3"), 80),
 ???????????? i = as.factor(rep(1:80, each = 2*3)))

d$y[d$z=="c"] = 5 + .5*d$x[d$z=="c"] + rnorm(240)
d$y[d$z=="t"] = 4 + .25*d$x[d$z=="t"] + rnorm(240)

d$x=(d$x - mean(d$x))/sd(d$x)

m=lmer(y ~ 1 + x + z + z:x + (1 + z|i), data = d)
summary(m)


	[[alternative HTML version deleted]]


From jorgemmtte|xe|r@ @end|ng |rom gm@||@com  Mon Aug 29 12:53:00 2022
From: jorgemmtte|xe|r@ @end|ng |rom gm@||@com (Jorge Teixeira)
Date: Mon, 29 Aug 2022 11:53:00 +0100
Subject: [R-sig-ME] time*treatment vs time + time:treatment in RCTs
Message-ID: <CAOYO_yBRJu0W0g4TfrGH2wQuzFzqT1_3OcZfNGmVC7unMWqAtA@mail.gmail.com>

Hi. In medicine's RCTs, with 3 or more time-points, whenever LMMs are used
and the code is available, a variation of  y ~ time*treatment + (1 | ID)
*(M1)* is always used (from what I have seen).

Recently I came across the model  time + time:treatment + (1 | ID)* (M2)*
in Solomun Kurz's blog and in the book of Galecki (LMMs using R).

Questions:
*1)* Are there any modelling reasons for M2 to be less used in medicine's
RCTs?

*2)* Can anyone explain, in layman terms, what is the estimand in M2? I
still struggle to understand what model is really measuring.

*3)* On a general basis, in a RCT with 3 time points (baseline, 3-month and
4-month), would you tend to gravitate more towards model 1 or 2?

Thank you
Jorge

	[[alternative HTML version deleted]]


From me @end|ng |rom ph||||p@|d@y@com  Mon Aug 29 15:28:20 2022
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Mon, 29 Aug 2022 07:28:20 -0600
Subject: [R-sig-ME] time*treatment vs time + time:treatment in RCTs
In-Reply-To: <CAOYO_yBRJu0W0g4TfrGH2wQuzFzqT1_3OcZfNGmVC7unMWqAtA@mail.gmail.com>
References: <CAOYO_yBRJu0W0g4TfrGH2wQuzFzqT1_3OcZfNGmVC7unMWqAtA@mail.gmail.com>
Message-ID: <aba5ee11-3934-fb92-1231-d559e1d8aa50@phillipalday.com>


On 8/29/22 05:53, Jorge Teixeira wrote:
> Hi. In medicine's RCTs, with 3 or more time-points, whenever LMMs are used
> and the code is available, a variation of  y ~ time*treatment + (1 | ID)
> *(M1)* is always used (from what I have seen).
>
> Recently I came across the model  time + time:treatment + (1 | ID)* (M2)*
> in Solomun Kurz's blog and in the book of Galecki (LMMs using R).
>
> Questions:
> *1)* Are there any modelling reasons for M2 to be less used in medicine's
> RCTs?

It depends a bit on what `y` is: change from baseline or the 'raw'
measure. If it's the raw measure, then (M2) doesn't include a
description of differences at baseline between the groups.

Perhaps most importantly though: (M2) violates the principle of
marginality discussed e.g. in Venables' Exegeses on Linear Models
(https://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf)

>
> *2)* Can anyone explain, in layman terms, what is the estimand in M2? I
> still struggle to understand what model is really measuring.

Approximately the same thing as M1, except that the "overall" effect of
treatment is assumed to be zero. "Overall" is a bit vague because it
depends on the contrast coding used for time and treatment.

You can see this for yourself. M1 can also be written as:

y ~ time + time:treatment + treatment + (1|ID).

If you force the coefficient on treatment to be zero, then you have M2.

>
> *3)* On a general basis, in a RCT with 3 time points (baseline, 3-month and
> 4-month), would you tend to gravitate more towards model 1 or 2?

Definitely (1).

PS: When referencing a blog entry, please provide a link to it. :)

>
> Thank you
> Jorge
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From dmb@te@ @end|ng |rom gm@||@com  Mon Aug 29 16:14:11 2022
From: dmb@te@ @end|ng |rom gm@||@com (Douglas Bates)
Date: Mon, 29 Aug 2022 09:14:11 -0500
Subject: [R-sig-ME] time*treatment vs time + time:treatment in RCTs
In-Reply-To: <12130_1661779721_0RHD0087DPFSUJ00_aba5ee11-3934-fb92-1231-d559e1d8aa50@phillipalday.com>
References: <CAOYO_yBRJu0W0g4TfrGH2wQuzFzqT1_3OcZfNGmVC7unMWqAtA@mail.gmail.com>
 <12130_1661779721_0RHD0087DPFSUJ00_aba5ee11-3934-fb92-1231-d559e1d8aa50@phillipalday.com>
Message-ID: <CAO7JsnRGXtOee0T-hQjVnqtBcn3TrkfOHYqbqEOvudrhTArnBg@mail.gmail.com>

M2 is an appropriate model if time corresponds to "time on treatment" or in
general if the covariate over which the measurements are repeated has a
scale where 0 is meaningful.  I think of it as the "zero dose" model
because zero dose of treatment 1 is the same as zero dose of treatment 2 is
the same as zero dose of the placebo.  Similarly zero time on treatment is
the same for any of the treatments or the placebo.

In those cases we would not expect a main effect for treatment because that
corresponds to systematic differences before the study begins (or at zero
dose), but we would expect an interaction of time (or dose) with treatment.

On Mon, Aug 29, 2022 at 8:28 AM Phillip Alday <me at phillipalday.com> wrote:

>
> On 8/29/22 05:53, Jorge Teixeira wrote:
> > Hi. In medicine's RCTs, with 3 or more time-points, whenever LMMs are
> used
> > and the code is available, a variation of  y ~ time*treatment + (1 | ID)
> > *(M1)* is always used (from what I have seen).
> >
> > Recently I came across the model  time + time:treatment + (1 | ID)* (M2)*
> > in Solomun Kurz's blog and in the book of Galecki (LMMs using R).
> >
> > Questions:
> > *1)* Are there any modelling reasons for M2 to be less used in medicine's
> > RCTs?
>
> It depends a bit on what `y` is: change from baseline or the 'raw'
> measure. If it's the raw measure, then (M2) doesn't include a
> description of differences at baseline between the groups.
>
> Perhaps most importantly though: (M2) violates the principle of
> marginality discussed e.g. in Venables' Exegeses on Linear Models
> (https://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf)
>
> >
> > *2)* Can anyone explain, in layman terms, what is the estimand in M2? I
> > still struggle to understand what model is really measuring.
>
> Approximately the same thing as M1, except that the "overall" effect of
> treatment is assumed to be zero. "Overall" is a bit vague because it
> depends on the contrast coding used for time and treatment.
>
> You can see this for yourself. M1 can also be written as:
>
> y ~ time + time:treatment + treatment + (1|ID).
>
> If you force the coefficient on treatment to be zero, then you have M2.
>
> >
> > *3)* On a general basis, in a RCT with 3 time points (baseline, 3-month
> and
> > 4-month), would you tend to gravitate more towards model 1 or 2?
>
> Definitely (1).
>
> PS: When referencing a blog entry, please provide a link to it. :)
>
> >
> > Thank you
> > Jorge
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n|  Mon Aug 29 17:11:28 2022
From: wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n| (Viechtbauer, Wolfgang (NP))
Date: Mon, 29 Aug 2022 15:11:28 +0000
Subject: [R-sig-ME] time*treatment vs time + time:treatment in RCTs
In-Reply-To: <CAO7JsnRGXtOee0T-hQjVnqtBcn3TrkfOHYqbqEOvudrhTArnBg@mail.gmail.com>
References: <CAOYO_yBRJu0W0g4TfrGH2wQuzFzqT1_3OcZfNGmVC7unMWqAtA@mail.gmail.com>
 <12130_1661779721_0RHD0087DPFSUJ00_aba5ee11-3934-fb92-1231-d559e1d8aa50@phillipalday.com>
 <CAO7JsnRGXtOee0T-hQjVnqtBcn3TrkfOHYqbqEOvudrhTArnBg@mail.gmail.com>
Message-ID: <66d905e97e424826b74edca52a4d6eff@UM-MAIL3214.unimaas.nl>

I strongly suspect that 'time' is treated as a factor in the examples Jorge is referring to. In this case, the two formulations are just different parameterizations of the same model. We can use the 'Orthodont' data to illustrate this. Think of 'age' as the time variable (as a four-level factor) and 'Sex' as the treatment variable (as a two-level factor). In fact, I will throw in a third parameterization, which I think is even more intuitive.

library(lme4)

data("Orthodont", package="nlme")

Orthodont$age <- factor(Orthodont$age)

res1 <- lmer(distance ~ age*Sex + (1 | Subject), data=Orthodont)
summary(res1)

res2 <- lmer(distance ~ age + age:Sex + (1 | Subject), data=Orthodont)
summary(res2)

res3 <- lmer(distance ~ 0 + age + age:Sex + (1 | Subject), data=Orthodont)
summary(res3)

logLik(res1)
logLik(res2)
logLik(res3)

The fit is identical.

In 'res3', we get the estimated intercepts (means) of the reference group (in this case for 'Male') at all 4 timepoints and the age:Sex coefficients are the difference between the Female and Male groups at those 4 timepoints.

Since these are just all different parameterizations of the same model, there is no reasons for preferring one over the other.

One has to be careful though when using anova() on those models, esp. with respect to the age:Sex test. In anova(res1), the test examines if the difference between males and females is the same at all 4 timepoints, while in anova(res2) and anova(res3) the test examines if the difference is 0 at all 4 timepoints. However, one could get either test out of all three parameterizations, by forming appropriate contrasts. So again, no reason to prefer one over the other (except maybe convenience depending on what one would like to test).

Best,
Wolfgang

>-----Original Message-----
>From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On
>Behalf Of Douglas Bates
>Sent: Monday, 29 August, 2022 16:14
>To: Phillip Alday
>Cc: R-mixed models mailing list; Jorge Teixeira
>Subject: Re: [R-sig-ME] time*treatment vs time + time:treatment in RCTs
>
>M2 is an appropriate model if time corresponds to "time on treatment" or in
>general if the covariate over which the measurements are repeated has a
>scale where 0 is meaningful.  I think of it as the "zero dose" model
>because zero dose of treatment 1 is the same as zero dose of treatment 2 is
>the same as zero dose of the placebo.  Similarly zero time on treatment is
>the same for any of the treatments or the placebo.
>
>In those cases we would not expect a main effect for treatment because that
>corresponds to systematic differences before the study begins (or at zero
>dose), but we would expect an interaction of time (or dose) with treatment.
>
>On Mon, Aug 29, 2022 at 8:28 AM Phillip Alday <me at phillipalday.com> wrote:
>
>> On 8/29/22 05:53, Jorge Teixeira wrote:
>> > Hi. In medicine's RCTs, with 3 or more time-points, whenever LMMs are
>> used
>> > and the code is available, a variation of  y ~ time*treatment + (1 | ID)
>> > *(M1)* is always used (from what I have seen).
>> >
>> > Recently I came across the model  time + time:treatment + (1 | ID)* (M2)*
>> > in Solomun Kurz's blog and in the book of Galecki (LMMs using R).
>> >
>> > Questions:
>> > *1)* Are there any modelling reasons for M2 to be less used in medicine's
>> > RCTs?
>>
>> It depends a bit on what `y` is: change from baseline or the 'raw'
>> measure. If it's the raw measure, then (M2) doesn't include a
>> description of differences at baseline between the groups.
>>
>> Perhaps most importantly though: (M2) violates the principle of
>> marginality discussed e.g. in Venables' Exegeses on Linear Models
>> (https://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf)
>>
>> > *2)* Can anyone explain, in layman terms, what is the estimand in M2? I
>> > still struggle to understand what model is really measuring.
>>
>> Approximately the same thing as M1, except that the "overall" effect of
>> treatment is assumed to be zero. "Overall" is a bit vague because it
>> depends on the contrast coding used for time and treatment.
>>
>> You can see this for yourself. M1 can also be written as:
>>
>> y ~ time + time:treatment + treatment + (1|ID).
>>
>> If you force the coefficient on treatment to be zero, then you have M2.
>>
>> > *3)* On a general basis, in a RCT with 3 time points (baseline, 3-month
>> and
>> > 4-month), would you tend to gravitate more towards model 1 or 2?
>>
>> Definitely (1).
>>
>> PS: When referencing a blog entry, please provide a link to it. :)
>>
>> > Thank you
>> > Jorge


From jorgemmtte|xe|r@ @end|ng |rom gm@||@com  Mon Aug 29 20:20:58 2022
From: jorgemmtte|xe|r@ @end|ng |rom gm@||@com (Jorge Teixeira)
Date: Mon, 29 Aug 2022 19:20:58 +0100
Subject: [R-sig-ME] time*treatment vs time + time:treatment in RCTs
In-Reply-To: <66d905e97e424826b74edca52a4d6eff@UM-MAIL3214.unimaas.nl>
References: <CAOYO_yBRJu0W0g4TfrGH2wQuzFzqT1_3OcZfNGmVC7unMWqAtA@mail.gmail.com>
 <12130_1661779721_0RHD0087DPFSUJ00_aba5ee11-3934-fb92-1231-d559e1d8aa50@phillipalday.com>
 <CAO7JsnRGXtOee0T-hQjVnqtBcn3TrkfOHYqbqEOvudrhTArnBg@mail.gmail.com>
 <66d905e97e424826b74edca52a4d6eff@UM-MAIL3214.unimaas.nl>
Message-ID: <CAOYO_yDAd3OG7_pWzcSrfnn8mj54D2D9HN8mPVLJW00kPHyLYw@mail.gmail.com>

Thank you all for the replies. Still processing them...

Indeed, Wolfgang, I was mainly thinking of time as a factor. Although, I
welcome comments as if it was numeric as well.

Your reply is surprising to me, because in my data I get different results.
The ES and p-values are very different regarding the interactions at 3 and
4-months, which are the relevant data to me. My df has 3 time points.

 res1 <- lmer(vo2 ~  group*time + ( 1  | ID  ), data =  dat_long )

   res2 <- lmer(vo2 ~  time + group:time + ( 1 | ID  ), data =  dat_long )


*res1:*
Fixed effects:
                       Estimate Std. Error      df t value Pr(>|t|)
(Intercept)             29.0705     0.9998 61.4510  29.076  < 2e-16 ***
groupFUT              1.0395     1.4140 61.4510   0.735 0.465036
time3month              -4.4917     1.0918 64.1740  -4.114 0.000113 ***
time4month              -5.0305     1.0622 63.8295  -4.736 1.26e-05 ***
*groupFUT:time3month *  2.5467     1.4396 61.8093   1.769 0.081822 .
*groupFUT:time4month*   1.7643     1.4424 61.8409   1.223 0.225909


*res2:*
Fixed effects:
                       Estimate Std. Error      df t value Pr(>|t|)
(Intercept)             29.0705     0.9998 61.4510  29.076  < 2e-16 ***
time3month              -4.4917     1.0918 64.1740  -4.114 0.000113 ***
time4month              -5.0305     1.0622 63.8295  -4.736 1.26e-05 ***
time0month:groupFUT   1.0395     1.4140 61.4510   0.735 0.465036
*time3month:groupFUT*   3.5862     1.5402 73.4895   2.328 0.022643 *
*time4month:groupFUT*  2.8038     1.5428 73.7427   1.817 0.073226 .



Viechtbauer, Wolfgang (NP) <wolfgang.viechtbauer at maastrichtuniversity.nl>
escreveu no dia segunda, 29/08/2022 ?(s) 16:11:

> I strongly suspect that 'time' is treated as a factor in the examples
> Jorge is referring to. In this case, the two formulations are just
> different parameterizations of the same model. We can use the 'Orthodont'
> data to illustrate this. Think of 'age' as the time variable (as a
> four-level factor) and 'Sex' as the treatment variable (as a two-level
> factor). In fact, I will throw in a third parameterization, which I think
> is even more intuitive.
>
> library(lme4)
>
> data("Orthodont", package="nlme")
>
> Orthodont$age <- factor(Orthodont$age)
>
> res1 <- lmer(distance ~ age*Sex + (1 | Subject), data=Orthodont)
> summary(res1)
>
> res2 <- lmer(distance ~ age + age:Sex + (1 | Subject), data=Orthodont)
> summary(res2)
>
> res3 <- lmer(distance ~ 0 + age + age:Sex + (1 | Subject), data=Orthodont)
> summary(res3)
>
> logLik(res1)
> logLik(res2)
> logLik(res3)
>
> The fit is identical.
>
> In 'res3', we get the estimated intercepts (means) of the reference group
> (in this case for 'Male') at all 4 timepoints and the age:Sex coefficients
> are the difference between the Female and Male groups at those 4 timepoints.
>
> Since these are just all different parameterizations of the same model,
> there is no reasons for preferring one over the other.
>
> One has to be careful though when using anova() on those models, esp. with
> respect to the age:Sex test. In anova(res1), the test examines if the
> difference between males and females is the same at all 4 timepoints, while
> in anova(res2) and anova(res3) the test examines if the difference is 0 at
> all 4 timepoints. However, one could get either test out of all three
> parameterizations, by forming appropriate contrasts. So again, no reason to
> prefer one over the other (except maybe convenience depending on what one
> would like to test).
>
> Best,
> Wolfgang
>
> >-----Original Message-----
> >From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
> On
> >Behalf Of Douglas Bates
> >Sent: Monday, 29 August, 2022 16:14
> >To: Phillip Alday
> >Cc: R-mixed models mailing list; Jorge Teixeira
> >Subject: Re: [R-sig-ME] time*treatment vs time + time:treatment in RCTs
> >
> >M2 is an appropriate model if time corresponds to "time on treatment" or
> in
> >general if the covariate over which the measurements are repeated has a
> >scale where 0 is meaningful.  I think of it as the "zero dose" model
> >because zero dose of treatment 1 is the same as zero dose of treatment 2
> is
> >the same as zero dose of the placebo.  Similarly zero time on treatment is
> >the same for any of the treatments or the placebo.
> >
> >In those cases we would not expect a main effect for treatment because
> that
> >corresponds to systematic differences before the study begins (or at zero
> >dose), but we would expect an interaction of time (or dose) with
> treatment.
> >
> >On Mon, Aug 29, 2022 at 8:28 AM Phillip Alday <me at phillipalday.com>
> wrote:
> >
> >> On 8/29/22 05:53, Jorge Teixeira wrote:
> >> > Hi. In medicine's RCTs, with 3 or more time-points, whenever LMMs are
> >> used
> >> > and the code is available, a variation of  y ~ time*treatment + (1 |
> ID)
> >> > *(M1)* is always used (from what I have seen).
> >> >
> >> > Recently I came across the model  time + time:treatment + (1 | ID)*
> (M2)*
> >> > in Solomun Kurz's blog and in the book of Galecki (LMMs using R).
> >> >
> >> > Questions:
> >> > *1)* Are there any modelling reasons for M2 to be less used in
> medicine's
> >> > RCTs?
> >>
> >> It depends a bit on what `y` is: change from baseline or the 'raw'
> >> measure. If it's the raw measure, then (M2) doesn't include a
> >> description of differences at baseline between the groups.
> >>
> >> Perhaps most importantly though: (M2) violates the principle of
> >> marginality discussed e.g. in Venables' Exegeses on Linear Models
> >> (https://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf)
> >>
> >> > *2)* Can anyone explain, in layman terms, what is the estimand in M2?
> I
> >> > still struggle to understand what model is really measuring.
> >>
> >> Approximately the same thing as M1, except that the "overall" effect of
> >> treatment is assumed to be zero. "Overall" is a bit vague because it
> >> depends on the contrast coding used for time and treatment.
> >>
> >> You can see this for yourself. M1 can also be written as:
> >>
> >> y ~ time + time:treatment + treatment + (1|ID).
> >>
> >> If you force the coefficient on treatment to be zero, then you have M2.
> >>
> >> > *3)* On a general basis, in a RCT with 3 time points (baseline,
> 3-month
> >> and
> >> > 4-month), would you tend to gravitate more towards model 1 or 2?
> >>
> >> Definitely (1).
> >>
> >> PS: When referencing a blog entry, please provide a link to it. :)
> >>
> >> > Thank you
> >> > Jorge
>

	[[alternative HTML version deleted]]


From k@r| @end|ng |rom hu|t|@@org  Mon Aug 29 20:56:02 2022
From: k@r| @end|ng |rom hu|t|@@org (Karl Ove Hufthammer)
Date: Mon, 29 Aug 2022 20:56:02 +0200
Subject: [R-sig-ME] time*treatment vs time + time:treatment in RCTs
In-Reply-To: <CAOYO_yDAd3OG7_pWzcSrfnn8mj54D2D9HN8mPVLJW00kPHyLYw@mail.gmail.com>
References: <CAOYO_yBRJu0W0g4TfrGH2wQuzFzqT1_3OcZfNGmVC7unMWqAtA@mail.gmail.com>
 <12130_1661779721_0RHD0087DPFSUJ00_aba5ee11-3934-fb92-1231-d559e1d8aa50@phillipalday.com>
 <CAO7JsnRGXtOee0T-hQjVnqtBcn3TrkfOHYqbqEOvudrhTArnBg@mail.gmail.com>
 <66d905e97e424826b74edca52a4d6eff@UM-MAIL3214.unimaas.nl>
 <CAOYO_yDAd3OG7_pWzcSrfnn8mj54D2D9HN8mPVLJW00kPHyLYw@mail.gmail.com>
Message-ID: <b3faff1a-8e4c-c8a7-8a36-0def93d25655@huftis.org>

No, you actually get equivalent results for your two models (which is 
really one model, just parametrised differently). The likelihood for the 
two models should be identical, and the P-value for testing whether 
there is an interaction should be identical. Here?s a simple simulation 
for data very similar to the ones you have:

|library(lmerTest) 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-13>d_temp 
= expand.grid(group = c("PLA", "FUT"), 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-14> 
time = c("Baseline", "3month", "4month")) 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-15>n_varcombo 
= nrow(d_temp) 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-16>d_temp$exp 
= c(29, 30, 24.5, 28, 24, 27) 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-17>n_ind 
= 30 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-18>dat_long 
= d_temp[rep(1:n_varcombo, each = n_ind), ] 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-19>dat_long$ID 
= rep(1:n_ind, each = n_varcombo) 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-20>set.seed(6) 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-21>dat_long$ID_effect 
= rep(rnorm(n_ind, sd = 3), each = n_varcombo) 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-22>dat_long$vo2 
= dat_long$exp + rnorm(n_varcombo * n_ind, sd = 3) 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-23> 
# Model without interaction 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-25>res0 
<- lmer(vo2 ~ group + time + (1 | ID), data = dat_long) 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-26> 
# Two (equivalent) models with interaction 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-28>res1 
<- lmer(vo2 ~ group * time + (1 | ID), data = dat_long) 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-29>summary(res1) 
#> Fixed effects: 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-48>#> 
Estimate Std. Error df t value Pr(>|t|) 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-49>#> 
(Intercept) 28.6258 0.5439 24.0000 52.635 < 2e-16 *** 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-50>#> 
groupFUT 1.2876 0.7691 24.0000 1.674 0.1071 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-51>#> 
time3month -4.8032 0.7691 24.0000 -6.245 1.87e-06 *** 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-52>#> 
time4month -4.8628 0.7691 24.0000 -6.322 1.55e-06 *** 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-53>#> 
groupFUT:time3month 2.7573 1.0877 24.0000 2.535 0.0182 * 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-54>#> 
groupFUT:time4month 1.5326 1.0877 24.0000 1.409 0.1717 #> 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-65>res2 
<- lmer(vo2 ~ time + group:time + (1 | ID), data = dat_long) 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-66>summary(res2) 
#> Fixed effects: 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-85>#> 
Estimate Std. Error df t value Pr(>|t|) 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-86>#> 
(Intercept) 28.6258 0.5439 24.0000 52.635 < 2e-16 *** 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-87>#> 
time3month -4.8032 0.7691 24.0000 -6.245 1.87e-06 *** 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-88>#> 
time4month -4.8628 0.7691 24.0000 -6.322 1.55e-06 *** 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-89>#> 
timeBaseline:groupFUT 1.2876 0.7691 24.0000 1.674 0.10710 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-90>#> 
time3month:groupFUT 4.0449 0.7691 24.0000 5.259 2.16e-05 *** 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-91>#> 
time4month:groupFUT 2.8202 0.7691 24.0000 3.667 0.00122 ** # The models 
have the same log likelihood (and degrees of freedom) 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-104>logLik(res1) 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-105>#> 
'log Lik.' -442.2284 (df=8) 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-106>logLik(res2) 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-107>#> 
'log Lik.' -442.2284 (df=8) 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-108> 
# And the P-values for the interaction are exactly the same 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-110>anova(res0, 
res1) 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-111>#> 
refitting model(s) with ML (instead of REML) 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-112>#> 
Data: dat_long 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-113>#> 
Models: 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-114>#> 
res0: vo2 ~ group + time + (1 | ID) 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-115>#> 
res1: vo2 ~ group * time + (1 | ID) 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-116>#> 
npar AIC BIC logLik deviance Chisq Df Pr(>Chisq) 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-117>#> 
res0 6 906.62 925.78 -447.31 894.62 #> res1 8 903.79 929.33 -443.89 
887.79 6.8379 2 0.03275 * 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-119>#> 
--- 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-120>#> 
Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-121>anova(res0, 
res2) 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-122>#> 
refitting model(s) with ML (instead of REML) 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-123>#> 
Data: dat_long 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-124>#> 
Models: 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-125>#> 
res0: vo2 ~ group + time + (1 | ID) 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-126>#> 
res2: vo2 ~ time + group:time + (1 | ID) 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-127>#> 
npar AIC BIC logLik deviance Chisq Df Pr(>Chisq) 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-128>#> 
res0 6 906.62 925.78 -447.31 894.62 #> res2 8 903.79 929.33 -443.89 
887.79 6.8379 2 0.03275 * 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-130>#> 
--- 
<http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-131>#> 
Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1|


As you can see, the two models are actually equivalent, and any 
inference based on the models should give the same results.


Karl Ove Hufthammer

Jorge Teixeira skreiv 29.08.2022 20:20:
> Thank you all for the replies. Still processing them...
>
> Indeed, Wolfgang, I was mainly thinking of time as a factor. Although, I
> welcome comments as if it was numeric as well.
>
> Your reply is surprising to me, because in my data I get different results.
> The ES and p-values are very different regarding the interactions at 3 and
> 4-months, which are the relevant data to me. My df has 3 time points.
>
>   res1 <- lmer(vo2 ~  group*time + ( 1  | ID  ), data =  dat_long )
>
>     res2 <- lmer(vo2 ~  time + group:time + ( 1 | ID  ), data =  dat_long )
>
>
> *res1:*
> Fixed effects:
>                         Estimate Std. Error      df t value Pr(>|t|)
> (Intercept)             29.0705     0.9998 61.4510  29.076  < 2e-16 ***
> groupFUT              1.0395     1.4140 61.4510   0.735 0.465036
> time3month              -4.4917     1.0918 64.1740  -4.114 0.000113 ***
> time4month              -5.0305     1.0622 63.8295  -4.736 1.26e-05 ***
> *groupFUT:time3month *  2.5467     1.4396 61.8093   1.769 0.081822 .
> *groupFUT:time4month*   1.7643     1.4424 61.8409   1.223 0.225909
>
>
> *res2:*
> Fixed effects:
>                         Estimate Std. Error      df t value Pr(>|t|)
> (Intercept)             29.0705     0.9998 61.4510  29.076  < 2e-16 ***
> time3month              -4.4917     1.0918 64.1740  -4.114 0.000113 ***
> time4month              -5.0305     1.0622 63.8295  -4.736 1.26e-05 ***
> time0month:groupFUT   1.0395     1.4140 61.4510   0.735 0.465036
> *time3month:groupFUT*   3.5862     1.5402 73.4895   2.328 0.022643 *
> *time4month:groupFUT*  2.8038     1.5428 73.7427   1.817 0.073226 .
>
>
>
> Viechtbauer, Wolfgang (NP)<wolfgang.viechtbauer at maastrichtuniversity.nl>
> escreveu no dia segunda, 29/08/2022 ?(s) 16:11:
>
>> I strongly suspect that 'time' is treated as a factor in the examples
>> Jorge is referring to. In this case, the two formulations are just
>> different parameterizations of the same model. We can use the 'Orthodont'
>> data to illustrate this. Think of 'age' as the time variable (as a
>> four-level factor) and 'Sex' as the treatment variable (as a two-level
>> factor). In fact, I will throw in a third parameterization, which I think
>> is even more intuitive.
>>
>> library(lme4)
>>
>> data("Orthodont", package="nlme")
>>
>> Orthodont$age <- factor(Orthodont$age)
>>
>> res1 <- lmer(distance ~ age*Sex + (1 | Subject), data=Orthodont)
>> summary(res1)
>>
>> res2 <- lmer(distance ~ age + age:Sex + (1 | Subject), data=Orthodont)
>> summary(res2)
>>
>> res3 <- lmer(distance ~ 0 + age + age:Sex + (1 | Subject), data=Orthodont)
>> summary(res3)
>>
>> logLik(res1)
>> logLik(res2)
>> logLik(res3)
>>
>> The fit is identical.
>>
>> In 'res3', we get the estimated intercepts (means) of the reference group
>> (in this case for 'Male') at all 4 timepoints and the age:Sex coefficients
>> are the difference between the Female and Male groups at those 4 timepoints.
>>
>> Since these are just all different parameterizations of the same model,
>> there is no reasons for preferring one over the other.
>>
>> One has to be careful though when using anova() on those models, esp. with
>> respect to the age:Sex test. In anova(res1), the test examines if the
>> difference between males and females is the same at all 4 timepoints, while
>> in anova(res2) and anova(res3) the test examines if the difference is 0 at
>> all 4 timepoints. However, one could get either test out of all three
>> parameterizations, by forming appropriate contrasts. So again, no reason to
>> prefer one over the other (except maybe convenience depending on what one
>> would like to test).
>>
>> Best,
>> Wolfgang
>>
>>> -----Original Message-----
>>> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
>> On
>>> Behalf Of Douglas Bates
>>> Sent: Monday, 29 August, 2022 16:14
>>> To: Phillip Alday
>>> Cc: R-mixed models mailing list; Jorge Teixeira
>>> Subject: Re: [R-sig-ME] time*treatment vs time + time:treatment in RCTs
>>>
>>> M2 is an appropriate model if time corresponds to "time on treatment" or
>> in
>>> general if the covariate over which the measurements are repeated has a
>>> scale where 0 is meaningful.  I think of it as the "zero dose" model
>>> because zero dose of treatment 1 is the same as zero dose of treatment 2
>> is
>>> the same as zero dose of the placebo.  Similarly zero time on treatment is
>>> the same for any of the treatments or the placebo.
>>>
>>> In those cases we would not expect a main effect for treatment because
>> that
>>> corresponds to systematic differences before the study begins (or at zero
>>> dose), but we would expect an interaction of time (or dose) with
>> treatment.
>>> On Mon, Aug 29, 2022 at 8:28 AM Phillip Alday<me at phillipalday.com>
>> wrote:
>>>> On 8/29/22 05:53, Jorge Teixeira wrote:
>>>>> Hi. In medicine's RCTs, with 3 or more time-points, whenever LMMs are
>>>> used
>>>>> and the code is available, a variation of  y ~ time*treatment + (1 |
>> ID)
>>>>> *(M1)* is always used (from what I have seen).
>>>>>
>>>>> Recently I came across the model  time + time:treatment + (1 | ID)*
>> (M2)*
>>>>> in Solomun Kurz's blog and in the book of Galecki (LMMs using R).
>>>>>
>>>>> Questions:
>>>>> *1)* Are there any modelling reasons for M2 to be less used in
>> medicine's
>>>>> RCTs?
>>>> It depends a bit on what `y` is: change from baseline or the 'raw'
>>>> measure. If it's the raw measure, then (M2) doesn't include a
>>>> description of differences at baseline between the groups.
>>>>
>>>> Perhaps most importantly though: (M2) violates the principle of
>>>> marginality discussed e.g. in Venables' Exegeses on Linear Models
>>>> (https://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf)
>>>>
>>>>> *2)* Can anyone explain, in layman terms, what is the estimand in M2?
>> I
>>>>> still struggle to understand what model is really measuring.
>>>> Approximately the same thing as M1, except that the "overall" effect of
>>>> treatment is assumed to be zero. "Overall" is a bit vague because it
>>>> depends on the contrast coding used for time and treatment.
>>>>
>>>> You can see this for yourself. M1 can also be written as:
>>>>
>>>> y ~ time + time:treatment + treatment + (1|ID).
>>>>
>>>> If you force the coefficient on treatment to be zero, then you have M2.
>>>>
>>>>> *3)* On a general basis, in a RCT with 3 time points (baseline,
>> 3-month
>>>> and
>>>>> 4-month), would you tend to gravitate more towards model 1 or 2?
>>>> Definitely (1).
>>>>
>>>> PS: When referencing a blog entry, please provide a link to it. :)
>>>>
>>>>> Thank you
>>>>> Jorge
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

-- 
Karl Ove Hufthammer

	[[alternative HTML version deleted]]


From k@r| @end|ng |rom hu|t|@@org  Mon Aug 29 20:59:41 2022
From: k@r| @end|ng |rom hu|t|@@org (Karl Ove Hufthammer)
Date: Mon, 29 Aug 2022 20:59:41 +0200
Subject: [R-sig-ME] time*treatment vs time + time:treatment in RCTs
In-Reply-To: <b3faff1a-8e4c-c8a7-8a36-0def93d25655@huftis.org>
References: <CAOYO_yBRJu0W0g4TfrGH2wQuzFzqT1_3OcZfNGmVC7unMWqAtA@mail.gmail.com>
 <12130_1661779721_0RHD0087DPFSUJ00_aba5ee11-3934-fb92-1231-d559e1d8aa50@phillipalday.com>
 <CAO7JsnRGXtOee0T-hQjVnqtBcn3TrkfOHYqbqEOvudrhTArnBg@mail.gmail.com>
 <66d905e97e424826b74edca52a4d6eff@UM-MAIL3214.unimaas.nl>
 <CAOYO_yDAd3OG7_pWzcSrfnn8mj54D2D9HN8mPVLJW00kPHyLYw@mail.gmail.com>
 <b3faff1a-8e4c-c8a7-8a36-0def93d25655@huftis.org>
Message-ID: <2d9138fd-491e-3a93-a629-b25c8e49ad85@huftis.org>

Hmm, the automatic HTML-to-plaintext conversion didn?t work too well. 
Here?s a plaintext version:

No, you actually get equivalent results for your two models (which is 
really one model, just parametrised differently). The likelihood for the 
two models should be identical, and the P-value for testing whether 
there is an interaction should be identical. Here?s a simple simulation 
for data very similar to the ones you have:

library(lmerTest)

d_temp = expand.grid(group = c("PLA", "FUT"),
 ???????????????????? time = c("Baseline", "3month", "4month"))
n_varcombo = nrow(d_temp)
d_temp$exp = c(29, 30, 24.5, 28, 24, 27)
n_ind = 30
dat_long = d_temp[rep(1:n_varcombo, each = n_ind), ]
dat_long$ID = rep(1:n_ind, each = n_varcombo)
set.seed(6)
dat_long$ID_effect = rep(rnorm(n_ind, sd = 3), each = n_varcombo)
dat_long$vo2 = dat_long$exp + rnorm(n_varcombo * n_ind, sd = 3)

# Model without interaction
res0 <- lmer(vo2 ~ group + time + (1 | ID), data = dat_long)

# Two (equivalent) models with interaction
res1 <- lmer(vo2 ~? group * time + (1? | ID), data = dat_long)
summary(res1)
#> Fixed effects:
#>???????????????????? Estimate Std. Error????? df t value Pr(>|t|)
#> (Intercept)????????? 28.6258???? 0.5439 24.0000? 52.635 < 2e-16 ***
#> groupFUT????????????? 1.2876???? 0.7691 24.0000?? 1.674 0.1071
#> time3month?????????? -4.8032???? 0.7691 24.0000? -6.245 1.87e-06 ***
#> time4month?????????? -4.8628???? 0.7691 24.0000? -6.322 1.55e-06 ***
#> groupFUT:time3month?? 2.7573???? 1.0877 24.0000?? 2.535 0.0182 *
#> groupFUT:time4month?? 1.5326???? 1.0877 24.0000?? 1.409 0.1717
#>

res2 <- lmer(vo2 ~? time + group:time + (1 | ID), data = dat_long)
summary(res2)
#> Fixed effects:
#>?????????????????????? Estimate Std. Error????? df t value Pr(>|t|)
#> (Intercept)??????????? 28.6258???? 0.5439 24.0000? 52.635 < 2e-16 ***
#> time3month???????????? -4.8032???? 0.7691 24.0000? -6.245 1.87e-06 ***
#> time4month???????????? -4.8628???? 0.7691 24.0000? -6.322 1.55e-06 ***
#> timeBaseline:groupFUT?? 1.2876???? 0.7691 24.0000?? 1.674 0.10710
#> time3month:groupFUT???? 4.0449???? 0.7691 24.0000?? 5.259 2.16e-05 ***
#> time4month:groupFUT???? 2.8202???? 0.7691 24.0000?? 3.667 0.00122 **

# The models have the same log likelihood (and degrees of freedom)
logLik(res1)
#> 'log Lik.' -442.2284 (df=8)
logLik(res2)
#> 'log Lik.' -442.2284 (df=8)

# And the P-values for the interaction are exactly the same
anova(res0, res1)
#> refitting model(s) with ML (instead of REML)
#> Data: dat_long
#> Models:
#> res0: vo2 ~ group + time + (1 | ID)
#> res1: vo2 ~ group * time + (1 | ID)
#>????? npar??? AIC??? BIC? logLik deviance? Chisq Df Pr(>Chisq)
#> res0??? 6 906.62 925.78 -447.31 894.62
#> res1??? 8 903.79 929.33 -443.89?? 887.79 6.8379? 2 0.03275 *
#> ---
#> Signif. codes:? 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

anova(res0, res2)
#> refitting model(s) with ML (instead of REML)
#> Data: dat_long
#> Models:
#> res0: vo2 ~ group + time + (1 | ID)
#> res2: vo2 ~ time + group:time + (1 | ID)
#>????? npar??? AIC??? BIC? logLik deviance? Chisq Df Pr(>Chisq)
#> res0??? 6 906.62 925.78 -447.31 894.62
#> res2??? 8 903.79 929.33 -443.89?? 887.79 6.8379? 2 0.03275 *
#> ---
#> Signif. codes:? 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1


As you can see, the two models are actually equivalent, and any 
inference based on the models should give the same results.


Karl Ove Hufthammer


Karl Ove Hufthammer skreiv 29.08.2022 20:56:
> No, you actually get equivalent results for your two models (which is
> really one model, just parametrised differently). The likelihood for the
> two models should be identical, and the P-value for testing whether
> there is an interaction should be identical. Here?s a simple simulation
> for data very similar to the ones you have:
>
> |library(lmerTest)
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-13>d_temp
> = expand.grid(group = c("PLA", "FUT"),
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-14>
> time = c("Baseline", "3month", "4month"))
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-15>n_varcombo
> = nrow(d_temp)
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-16>d_temp$exp
> = c(29, 30, 24.5, 28, 24, 27)
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-17>n_ind
> = 30
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-18>dat_long
> = d_temp[rep(1:n_varcombo, each = n_ind), ]
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-19>dat_long$ID
> = rep(1:n_ind, each = n_varcombo)
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-20>set.seed(6)
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-21>dat_long$ID_effect
> = rep(rnorm(n_ind, sd = 3), each = n_varcombo)
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-22>dat_long$vo2
> = dat_long$exp + rnorm(n_varcombo * n_ind, sd = 3)
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-23>
> # Model without interaction
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-25>res0
> <- lmer(vo2 ~ group + time + (1 | ID), data = dat_long)
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-26>
> # Two (equivalent) models with interaction
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-28>res1
> <- lmer(vo2 ~ group * time + (1 | ID), data = dat_long)
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-29>summary(res1)
> #> Fixed effects:
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-48>#>
> Estimate Std. Error df t value Pr(>|t|)
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-49>#>
> (Intercept) 28.6258 0.5439 24.0000 52.635 < 2e-16 ***
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-50>#>
> groupFUT 1.2876 0.7691 24.0000 1.674 0.1071
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-51>#>
> time3month -4.8032 0.7691 24.0000 -6.245 1.87e-06 ***
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-52>#>
> time4month -4.8628 0.7691 24.0000 -6.322 1.55e-06 ***
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-53>#>
> groupFUT:time3month 2.7573 1.0877 24.0000 2.535 0.0182 *
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-54>#>
> groupFUT:time4month 1.5326 1.0877 24.0000 1.409 0.1717 #>
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-65>res2
> <- lmer(vo2 ~ time + group:time + (1 | ID), data = dat_long)
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-66>summary(res2)
> #> Fixed effects:
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-85>#>
> Estimate Std. Error df t value Pr(>|t|)
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-86>#>
> (Intercept) 28.6258 0.5439 24.0000 52.635 < 2e-16 ***
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-87>#>
> time3month -4.8032 0.7691 24.0000 -6.245 1.87e-06 ***
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-88>#>
> time4month -4.8628 0.7691 24.0000 -6.322 1.55e-06 ***
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-89>#>
> timeBaseline:groupFUT 1.2876 0.7691 24.0000 1.674 0.10710
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-90>#>
> time3month:groupFUT 4.0449 0.7691 24.0000 5.259 2.16e-05 ***
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-91>#>
> time4month:groupFUT 2.8202 0.7691 24.0000 3.667 0.00122 ** # The models
> have the same log likelihood (and degrees of freedom)
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-104>logLik(res1)
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-105>#>
> 'log Lik.' -442.2284 (df=8)
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-106>logLik(res2)
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-107>#>
> 'log Lik.' -442.2284 (df=8)
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-108>
> # And the P-values for the interaction are exactly the same
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-110>anova(res0,
> res1)
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-111>#>
> refitting model(s) with ML (instead of REML)
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-112>#>
> Data: dat_long
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-113>#>
> Models:
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-114>#>
> res0: vo2 ~ group + time + (1 | ID)
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-115>#>
> res1: vo2 ~ group * time + (1 | ID)
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-116>#>
> npar AIC BIC logLik deviance Chisq Df Pr(>Chisq)
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-117>#>
> res0 6 906.62 925.78 -447.31 894.62 #> res1 8 903.79 929.33 -443.89
> 887.79 6.8379 2 0.03275 *
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-119>#>
> ---
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-120>#>
> Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-121>anova(res0,
> res2)
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-122>#>
> refitting model(s) with ML (instead of REML)
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-123>#>
> Data: dat_long
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-124>#>
> Models:
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-125>#>
> res0: vo2 ~ group + time + (1 | ID)
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-126>#>
> res2: vo2 ~ time + group:time + (1 | ID)
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-127>#>
> npar AIC BIC logLik deviance Chisq Df Pr(>Chisq)
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-128>#>
> res0 6 906.62 925.78 -447.31 894.62 #> res2 8 903.79 929.33 -443.89
> 887.79 6.8379 2 0.03275 *
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-130>#>
> ---
> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-131>#>
> Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1|
>
>
> As you can see, the two models are actually equivalent, and any
> inference based on the models should give the same results.
>
>
> Karl Ove Hufthammer
>
> Jorge Teixeira skreiv 29.08.2022 20:20:
>> Thank you all for the replies. Still processing them...
>>
>> Indeed, Wolfgang, I was mainly thinking of time as a factor. Although, I
>> welcome comments as if it was numeric as well.
>>
>> Your reply is surprising to me, because in my data I get different results.
>> The ES and p-values are very different regarding the interactions at 3 and
>> 4-months, which are the relevant data to me. My df has 3 time points.
>>
>>    res1 <- lmer(vo2 ~  group*time + ( 1  | ID  ), data =  dat_long )
>>
>>      res2 <- lmer(vo2 ~  time + group:time + ( 1 | ID  ), data =  dat_long )
>>
>>
>> *res1:*
>> Fixed effects:
>>                          Estimate Std. Error      df t value Pr(>|t|)
>> (Intercept)             29.0705     0.9998 61.4510  29.076  < 2e-16 ***
>> groupFUT              1.0395     1.4140 61.4510   0.735 0.465036
>> time3month              -4.4917     1.0918 64.1740  -4.114 0.000113 ***
>> time4month              -5.0305     1.0622 63.8295  -4.736 1.26e-05 ***
>> *groupFUT:time3month *  2.5467     1.4396 61.8093   1.769 0.081822 .
>> *groupFUT:time4month*   1.7643     1.4424 61.8409   1.223 0.225909
>>
>>
>> *res2:*
>> Fixed effects:
>>                          Estimate Std. Error      df t value Pr(>|t|)
>> (Intercept)             29.0705     0.9998 61.4510  29.076  < 2e-16 ***
>> time3month              -4.4917     1.0918 64.1740  -4.114 0.000113 ***
>> time4month              -5.0305     1.0622 63.8295  -4.736 1.26e-05 ***
>> time0month:groupFUT   1.0395     1.4140 61.4510   0.735 0.465036
>> *time3month:groupFUT*   3.5862     1.5402 73.4895   2.328 0.022643 *
>> *time4month:groupFUT*  2.8038     1.5428 73.7427   1.817 0.073226 .
>>
>>
>>
>> Viechtbauer, Wolfgang (NP)<wolfgang.viechtbauer at maastrichtuniversity.nl>
>> escreveu no dia segunda, 29/08/2022 ?(s) 16:11:
>>
>>> I strongly suspect that 'time' is treated as a factor in the examples
>>> Jorge is referring to. In this case, the two formulations are just
>>> different parameterizations of the same model. We can use the 'Orthodont'
>>> data to illustrate this. Think of 'age' as the time variable (as a
>>> four-level factor) and 'Sex' as the treatment variable (as a two-level
>>> factor). In fact, I will throw in a third parameterization, which I think
>>> is even more intuitive.
>>>
>>> library(lme4)
>>>
>>> data("Orthodont", package="nlme")
>>>
>>> Orthodont$age <- factor(Orthodont$age)
>>>
>>> res1 <- lmer(distance ~ age*Sex + (1 | Subject), data=Orthodont)
>>> summary(res1)
>>>
>>> res2 <- lmer(distance ~ age + age:Sex + (1 | Subject), data=Orthodont)
>>> summary(res2)
>>>
>>> res3 <- lmer(distance ~ 0 + age + age:Sex + (1 | Subject), data=Orthodont)
>>> summary(res3)
>>>
>>> logLik(res1)
>>> logLik(res2)
>>> logLik(res3)
>>>
>>> The fit is identical.
>>>
>>> In 'res3', we get the estimated intercepts (means) of the reference group
>>> (in this case for 'Male') at all 4 timepoints and the age:Sex coefficients
>>> are the difference between the Female and Male groups at those 4 timepoints.
>>>
>>> Since these are just all different parameterizations of the same model,
>>> there is no reasons for preferring one over the other.
>>>
>>> One has to be careful though when using anova() on those models, esp. with
>>> respect to the age:Sex test. In anova(res1), the test examines if the
>>> difference between males and females is the same at all 4 timepoints, while
>>> in anova(res2) and anova(res3) the test examines if the difference is 0 at
>>> all 4 timepoints. However, one could get either test out of all three
>>> parameterizations, by forming appropriate contrasts. So again, no reason to
>>> prefer one over the other (except maybe convenience depending on what one
>>> would like to test).
>>>
>>> Best,
>>> Wolfgang
>>>
>>>> -----Original Message-----
>>>> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
>>> On
>>>> Behalf Of Douglas Bates
>>>> Sent: Monday, 29 August, 2022 16:14
>>>> To: Phillip Alday
>>>> Cc: R-mixed models mailing list; Jorge Teixeira
>>>> Subject: Re: [R-sig-ME] time*treatment vs time + time:treatment in RCTs
>>>>
>>>> M2 is an appropriate model if time corresponds to "time on treatment" or
>>> in
>>>> general if the covariate over which the measurements are repeated has a
>>>> scale where 0 is meaningful.  I think of it as the "zero dose" model
>>>> because zero dose of treatment 1 is the same as zero dose of treatment 2
>>> is
>>>> the same as zero dose of the placebo.  Similarly zero time on treatment is
>>>> the same for any of the treatments or the placebo.
>>>>
>>>> In those cases we would not expect a main effect for treatment because
>>> that
>>>> corresponds to systematic differences before the study begins (or at zero
>>>> dose), but we would expect an interaction of time (or dose) with
>>> treatment.
>>>> On Mon, Aug 29, 2022 at 8:28 AM Phillip Alday<me at phillipalday.com>
>>> wrote:
>>>>> On 8/29/22 05:53, Jorge Teixeira wrote:
>>>>>> Hi. In medicine's RCTs, with 3 or more time-points, whenever LMMs are
>>>>> used
>>>>>> and the code is available, a variation of  y ~ time*treatment + (1 |
>>> ID)
>>>>>> *(M1)* is always used (from what I have seen).
>>>>>>
>>>>>> Recently I came across the model  time + time:treatment + (1 | ID)*
>>> (M2)*
>>>>>> in Solomun Kurz's blog and in the book of Galecki (LMMs using R).
>>>>>>
>>>>>> Questions:
>>>>>> *1)* Are there any modelling reasons for M2 to be less used in
>>> medicine's
>>>>>> RCTs?
>>>>> It depends a bit on what `y` is: change from baseline or the 'raw'
>>>>> measure. If it's the raw measure, then (M2) doesn't include a
>>>>> description of differences at baseline between the groups.
>>>>>
>>>>> Perhaps most importantly though: (M2) violates the principle of
>>>>> marginality discussed e.g. in Venables' Exegeses on Linear Models
>>>>> (https://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf)
>>>>>
>>>>>> *2)* Can anyone explain, in layman terms, what is the estimand in M2?
>>> I
>>>>>> still struggle to understand what model is really measuring.
>>>>> Approximately the same thing as M1, except that the "overall" effect of
>>>>> treatment is assumed to be zero. "Overall" is a bit vague because it
>>>>> depends on the contrast coding used for time and treatment.
>>>>>
>>>>> You can see this for yourself. M1 can also be written as:
>>>>>
>>>>> y ~ time + time:treatment + treatment + (1|ID).
>>>>>
>>>>> If you force the coefficient on treatment to be zero, then you have M2.
>>>>>
>>>>>> *3)* On a general basis, in a RCT with 3 time points (baseline,
>>> 3-month
>>>>> and
>>>>>> 4-month), would you tend to gravitate more towards model 1 or 2?
>>>>> Definitely (1).
>>>>>
>>>>> PS: When referencing a blog entry, please provide a link to it. :)
>>>>>
>>>>>> Thank you
>>>>>> Jorge
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org  mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>

-- 
Karl Ove Hufthammer


From k@r| @end|ng |rom hu|t|@@org  Mon Aug 29 21:25:34 2022
From: k@r| @end|ng |rom hu|t|@@org (Karl Ove Hufthammer)
Date: Mon, 29 Aug 2022 21:25:34 +0200
Subject: [R-sig-ME] time*treatment vs time + time:treatment in RCTs
In-Reply-To: <2d9138fd-491e-3a93-a629-b25c8e49ad85@huftis.org>
References: <CAOYO_yBRJu0W0g4TfrGH2wQuzFzqT1_3OcZfNGmVC7unMWqAtA@mail.gmail.com>
 <12130_1661779721_0RHD0087DPFSUJ00_aba5ee11-3934-fb92-1231-d559e1d8aa50@phillipalday.com>
 <CAO7JsnRGXtOee0T-hQjVnqtBcn3TrkfOHYqbqEOvudrhTArnBg@mail.gmail.com>
 <66d905e97e424826b74edca52a4d6eff@UM-MAIL3214.unimaas.nl>
 <CAOYO_yDAd3OG7_pWzcSrfnn8mj54D2D9HN8mPVLJW00kPHyLYw@mail.gmail.com>
 <b3faff1a-8e4c-c8a7-8a36-0def93d25655@huftis.org>
 <2d9138fd-491e-3a93-a629-b25c8e49ad85@huftis.org>
Message-ID: <03270bfc-62de-3ac8-29ba-0e66095264c7@huftis.org>

BTW, this is actually a rather annoying feature of the ways model 
formulas work in R. For a *randomised* longitudinal study, the 
population means for the randomisation groups are *identical* at 
baseline (due to the randomisation). So to properly *adjust* for any 
(random) group unbalances at baseline in the samples, one should fit a 
model *without* a ?group? effect at baseline. (I know it sounds strange 
to fit a model without group differences at baseline to *adjust* for any 
baseline differences, but if you think about it for a while, it makes 
sense ?)

So instead of fitting

time + group + time:group + ...

(where ?group? represents the population differences at baseline)

one would naively *think* that one should fit a

time + time:group + ...

model. But R changes the *meaning* of the ?time:group? term in the 
second model, so one ends up fitting the exact same model as the first 
model (though with a different parametrisation), i.e., a model *not* 
adjusting for any sample differences at baseline.

The only way I?ve found to easily fit the proper model, is to create a 
factor of all ?interaction(time, group)? values and manually collapse 
the baseline groups to have the same level. That works fine, but it 
makes some tests *much* more complication, as you can no longer use R?s 
formula handling for simplifying models.


Karl Ove Hufthammer

Karl Ove Hufthammer skreiv 29.08.2022 20:59:
> Hmm, the automatic HTML-to-plaintext conversion didn?t work too well. 
> Here?s a plaintext version:
>
> No, you actually get equivalent results for your two models (which is 
> really one model, just parametrised differently). The likelihood for 
> the two models should be identical, and the P-value for testing 
> whether there is an interaction should be identical. Here?s a simple 
> simulation for data very similar to the ones you have:
>
> library(lmerTest)
>
> d_temp = expand.grid(group = c("PLA", "FUT"),
> ???????????????????? time = c("Baseline", "3month", "4month"))
> n_varcombo = nrow(d_temp)
> d_temp$exp = c(29, 30, 24.5, 28, 24, 27)
> n_ind = 30
> dat_long = d_temp[rep(1:n_varcombo, each = n_ind), ]
> dat_long$ID = rep(1:n_ind, each = n_varcombo)
> set.seed(6)
> dat_long$ID_effect = rep(rnorm(n_ind, sd = 3), each = n_varcombo)
> dat_long$vo2 = dat_long$exp + rnorm(n_varcombo * n_ind, sd = 3)
>
> # Model without interaction
> res0 <- lmer(vo2 ~ group + time + (1 | ID), data = dat_long)
>
> # Two (equivalent) models with interaction
> res1 <- lmer(vo2 ~? group * time + (1? | ID), data = dat_long)
> summary(res1)
> #> Fixed effects:
> #>???????????????????? Estimate Std. Error????? df t value Pr(>|t|)
> #> (Intercept)????????? 28.6258???? 0.5439 24.0000? 52.635 < 2e-16 ***
> #> groupFUT????????????? 1.2876???? 0.7691 24.0000?? 1.674 0.1071
> #> time3month?????????? -4.8032???? 0.7691 24.0000? -6.245 1.87e-06 ***
> #> time4month?????????? -4.8628???? 0.7691 24.0000? -6.322 1.55e-06 ***
> #> groupFUT:time3month?? 2.7573???? 1.0877 24.0000?? 2.535 0.0182 *
> #> groupFUT:time4month?? 1.5326???? 1.0877 24.0000?? 1.409 0.1717
> #>
>
> res2 <- lmer(vo2 ~? time + group:time + (1 | ID), data = dat_long)
> summary(res2)
> #> Fixed effects:
> #>?????????????????????? Estimate Std. Error????? df t value Pr(>|t|)
> #> (Intercept)??????????? 28.6258???? 0.5439 24.0000? 52.635 < 2e-16 ***
> #> time3month???????????? -4.8032???? 0.7691 24.0000? -6.245 1.87e-06 ***
> #> time4month???????????? -4.8628???? 0.7691 24.0000? -6.322 1.55e-06 ***
> #> timeBaseline:groupFUT?? 1.2876???? 0.7691 24.0000?? 1.674 0.10710
> #> time3month:groupFUT???? 4.0449???? 0.7691 24.0000?? 5.259 2.16e-05 ***
> #> time4month:groupFUT???? 2.8202???? 0.7691 24.0000?? 3.667 0.00122 **
>
> # The models have the same log likelihood (and degrees of freedom)
> logLik(res1)
> #> 'log Lik.' -442.2284 (df=8)
> logLik(res2)
> #> 'log Lik.' -442.2284 (df=8)
>
> # And the P-values for the interaction are exactly the same
> anova(res0, res1)
> #> refitting model(s) with ML (instead of REML)
> #> Data: dat_long
> #> Models:
> #> res0: vo2 ~ group + time + (1 | ID)
> #> res1: vo2 ~ group * time + (1 | ID)
> #>????? npar??? AIC??? BIC? logLik deviance? Chisq Df Pr(>Chisq)
> #> res0??? 6 906.62 925.78 -447.31 894.62
> #> res1??? 8 903.79 929.33 -443.89?? 887.79 6.8379? 2 0.03275 *
> #> ---
> #> Signif. codes:? 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
> anova(res0, res2)
> #> refitting model(s) with ML (instead of REML)
> #> Data: dat_long
> #> Models:
> #> res0: vo2 ~ group + time + (1 | ID)
> #> res2: vo2 ~ time + group:time + (1 | ID)
> #>????? npar??? AIC??? BIC? logLik deviance? Chisq Df Pr(>Chisq)
> #> res0??? 6 906.62 925.78 -447.31 894.62
> #> res2??? 8 903.79 929.33 -443.89?? 887.79 6.8379? 2 0.03275 *
> #> ---
> #> Signif. codes:? 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
>
> As you can see, the two models are actually equivalent, and any 
> inference based on the models should give the same results.
>
>
> Karl Ove Hufthammer
>
>
> Karl Ove Hufthammer skreiv 29.08.2022 20:56:
>> No, you actually get equivalent results for your two models (which is
>> really one model, just parametrised differently). The likelihood for the
>> two models should be identical, and the P-value for testing whether
>> there is an interaction should be identical. Here?s a simple simulation
>> for data very similar to the ones you have:
>>
>> |library(lmerTest)
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-13>d_temp 
>>
>> = expand.grid(group = c("PLA", "FUT"),
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-14> 
>>
>> time = c("Baseline", "3month", "4month"))
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-15>n_varcombo 
>>
>> = nrow(d_temp)
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-16>d_temp$exp 
>>
>> = c(29, 30, 24.5, 28, 24, 27)
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-17>n_ind 
>>
>> = 30
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-18>dat_long 
>>
>> = d_temp[rep(1:n_varcombo, each = n_ind), ]
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-19>dat_long$ID 
>>
>> = rep(1:n_ind, each = n_varcombo)
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-20>set.seed(6) 
>>
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-21>dat_long$ID_effect 
>>
>> = rep(rnorm(n_ind, sd = 3), each = n_varcombo)
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-22>dat_long$vo2 
>>
>> = dat_long$exp + rnorm(n_varcombo * n_ind, sd = 3)
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-23> 
>>
>> # Model without interaction
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-25>res0 
>>
>> <- lmer(vo2 ~ group + time + (1 | ID), data = dat_long)
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-26> 
>>
>> # Two (equivalent) models with interaction
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-28>res1 
>>
>> <- lmer(vo2 ~ group * time + (1 | ID), data = dat_long)
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-29>summary(res1) 
>>
>> #> Fixed effects:
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-48>#> 
>>
>> Estimate Std. Error df t value Pr(>|t|)
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-49>#> 
>>
>> (Intercept) 28.6258 0.5439 24.0000 52.635 < 2e-16 ***
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-50>#> 
>>
>> groupFUT 1.2876 0.7691 24.0000 1.674 0.1071
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-51>#> 
>>
>> time3month -4.8032 0.7691 24.0000 -6.245 1.87e-06 ***
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-52>#> 
>>
>> time4month -4.8628 0.7691 24.0000 -6.322 1.55e-06 ***
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-53>#> 
>>
>> groupFUT:time3month 2.7573 1.0877 24.0000 2.535 0.0182 *
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-54>#> 
>>
>> groupFUT:time4month 1.5326 1.0877 24.0000 1.409 0.1717 #>
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-65>res2 
>>
>> <- lmer(vo2 ~ time + group:time + (1 | ID), data = dat_long)
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-66>summary(res2) 
>>
>> #> Fixed effects:
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-85>#> 
>>
>> Estimate Std. Error df t value Pr(>|t|)
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-86>#> 
>>
>> (Intercept) 28.6258 0.5439 24.0000 52.635 < 2e-16 ***
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-87>#> 
>>
>> time3month -4.8032 0.7691 24.0000 -6.245 1.87e-06 ***
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-88>#> 
>>
>> time4month -4.8628 0.7691 24.0000 -6.322 1.55e-06 ***
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-89>#> 
>>
>> timeBaseline:groupFUT 1.2876 0.7691 24.0000 1.674 0.10710
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-90>#> 
>>
>> time3month:groupFUT 4.0449 0.7691 24.0000 5.259 2.16e-05 ***
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-91>#> 
>>
>> time4month:groupFUT 2.8202 0.7691 24.0000 3.667 0.00122 ** # The models
>> have the same log likelihood (and degrees of freedom)
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-104>logLik(res1) 
>>
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-105>#> 
>>
>> 'log Lik.' -442.2284 (df=8)
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-106>logLik(res2) 
>>
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-107>#> 
>>
>> 'log Lik.' -442.2284 (df=8)
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-108> 
>>
>> # And the P-values for the interaction are exactly the same
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-110>anova(res0, 
>>
>> res1)
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-111>#> 
>>
>> refitting model(s) with ML (instead of REML)
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-112>#> 
>>
>> Data: dat_long
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-113>#> 
>>
>> Models:
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-114>#> 
>>
>> res0: vo2 ~ group + time + (1 | ID)
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-115>#> 
>>
>> res1: vo2 ~ group * time + (1 | ID)
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-116>#> 
>>
>> npar AIC BIC logLik deviance Chisq Df Pr(>Chisq)
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-117>#> 
>>
>> res0 6 906.62 925.78 -447.31 894.62 #> res1 8 903.79 929.33 -443.89
>> 887.79 6.8379 2 0.03275 *
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-119>#> 
>>
>> ---
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-120>#> 
>>
>> Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-121>anova(res0, 
>>
>> res2)
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-122>#> 
>>
>> refitting model(s) with ML (instead of REML)
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-123>#> 
>>
>> Data: dat_long
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-124>#> 
>>
>> Models:
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-125>#> 
>>
>> res0: vo2 ~ group + time + (1 | ID)
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-126>#> 
>>
>> res2: vo2 ~ time + group:time + (1 | ID)
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-127>#> 
>>
>> npar AIC BIC logLik deviance Chisq Df Pr(>Chisq)
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-128>#> 
>>
>> res0 6 906.62 925.78 -447.31 894.62 #> res2 8 903.79 929.33 -443.89
>> 887.79 6.8379 2 0.03275 *
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-130>#> 
>>
>> ---
>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-131>#> 
>>
>> Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1|
>>
>>
>> As you can see, the two models are actually equivalent, and any
>> inference based on the models should give the same results.
>>
>>
>> Karl Ove Hufthammer
>>
>> Jorge Teixeira skreiv 29.08.2022 20:20:
>>> Thank you all for the replies. Still processing them...
>>>
>>> Indeed, Wolfgang, I was mainly thinking of time as a factor. 
>>> Although, I
>>> welcome comments as if it was numeric as well.
>>>
>>> Your reply is surprising to me, because in my data I get different 
>>> results.
>>> The ES and p-values are very different regarding the interactions at 
>>> 3 and
>>> 4-months, which are the relevant data to me. My df has 3 time points.
>>>
>>> ?? res1 <- lmer(vo2 ~? group*time + ( 1? | ID? ), data = dat_long )
>>>
>>> ???? res2 <- lmer(vo2 ~? time + group:time + ( 1 | ID? ), data =? 
>>> dat_long )
>>>
>>>
>>> *res1:*
>>> Fixed effects:
>>> ???????????????????????? Estimate Std. Error????? df t value Pr(>|t|)
>>> (Intercept)???????????? 29.0705???? 0.9998 61.4510? 29.076 < 2e-16 ***
>>> groupFUT????????????? 1.0395???? 1.4140 61.4510?? 0.735 0.465036
>>> time3month????????????? -4.4917???? 1.0918 64.1740? -4.114 0.000113 ***
>>> time4month????????????? -5.0305???? 1.0622 63.8295? -4.736 1.26e-05 ***
>>> *groupFUT:time3month *? 2.5467???? 1.4396 61.8093?? 1.769 0.081822 .
>>> *groupFUT:time4month*?? 1.7643???? 1.4424 61.8409?? 1.223 0.225909
>>>
>>>
>>> *res2:*
>>> Fixed effects:
>>> ???????????????????????? Estimate Std. Error????? df t value Pr(>|t|)
>>> (Intercept)???????????? 29.0705???? 0.9998 61.4510? 29.076 < 2e-16 ***
>>> time3month????????????? -4.4917???? 1.0918 64.1740? -4.114 0.000113 ***
>>> time4month????????????? -5.0305???? 1.0622 63.8295? -4.736 1.26e-05 ***
>>> time0month:groupFUT?? 1.0395???? 1.4140 61.4510?? 0.735 0.465036
>>> *time3month:groupFUT*?? 3.5862???? 1.5402 73.4895?? 2.328 0.022643 *
>>> *time4month:groupFUT*? 2.8038???? 1.5428 73.7427?? 1.817 0.073226 .
>>>
>>>
>>>
>>> Viechtbauer, Wolfgang 
>>> (NP)<wolfgang.viechtbauer at maastrichtuniversity.nl>
>>> escreveu no dia segunda, 29/08/2022 ?(s) 16:11:
>>>
>>>> I strongly suspect that 'time' is treated as a factor in the examples
>>>> Jorge is referring to. In this case, the two formulations are just
>>>> different parameterizations of the same model. We can use the 
>>>> 'Orthodont'
>>>> data to illustrate this. Think of 'age' as the time variable (as a
>>>> four-level factor) and 'Sex' as the treatment variable (as a two-level
>>>> factor). In fact, I will throw in a third parameterization, which I 
>>>> think
>>>> is even more intuitive.
>>>>
>>>> library(lme4)
>>>>
>>>> data("Orthodont", package="nlme")
>>>>
>>>> Orthodont$age <- factor(Orthodont$age)
>>>>
>>>> res1 <- lmer(distance ~ age*Sex + (1 | Subject), data=Orthodont)
>>>> summary(res1)
>>>>
>>>> res2 <- lmer(distance ~ age + age:Sex + (1 | Subject), data=Orthodont)
>>>> summary(res2)
>>>>
>>>> res3 <- lmer(distance ~ 0 + age + age:Sex + (1 | Subject), 
>>>> data=Orthodont)
>>>> summary(res3)
>>>>
>>>> logLik(res1)
>>>> logLik(res2)
>>>> logLik(res3)
>>>>
>>>> The fit is identical.
>>>>
>>>> In 'res3', we get the estimated intercepts (means) of the reference 
>>>> group
>>>> (in this case for 'Male') at all 4 timepoints and the age:Sex 
>>>> coefficients
>>>> are the difference between the Female and Male groups at those 4 
>>>> timepoints.
>>>>
>>>> Since these are just all different parameterizations of the same 
>>>> model,
>>>> there is no reasons for preferring one over the other.
>>>>
>>>> One has to be careful though when using anova() on those models, 
>>>> esp. with
>>>> respect to the age:Sex test. In anova(res1), the test examines if the
>>>> difference between males and females is the same at all 4 
>>>> timepoints, while
>>>> in anova(res2) and anova(res3) the test examines if the difference 
>>>> is 0 at
>>>> all 4 timepoints. However, one could get either test out of all three
>>>> parameterizations, by forming appropriate contrasts. So again, no 
>>>> reason to
>>>> prefer one over the other (except maybe convenience depending on 
>>>> what one
>>>> would like to test).
>>>>
>>>> Best,
>>>> Wolfgang
>>>>
>>>>> -----Original Message-----
>>>>> From: R-sig-mixed-models 
>>>>> [mailto:r-sig-mixed-models-bounces at r-project.org]
>>>> On
>>>>> Behalf Of Douglas Bates
>>>>> Sent: Monday, 29 August, 2022 16:14
>>>>> To: Phillip Alday
>>>>> Cc: R-mixed models mailing list; Jorge Teixeira
>>>>> Subject: Re: [R-sig-ME] time*treatment vs time + time:treatment in 
>>>>> RCTs
>>>>>
>>>>> M2 is an appropriate model if time corresponds to "time on 
>>>>> treatment" or
>>>> in
>>>>> general if the covariate over which the measurements are repeated 
>>>>> has a
>>>>> scale where 0 is meaningful.? I think of it as the "zero dose" model
>>>>> because zero dose of treatment 1 is the same as zero dose of 
>>>>> treatment 2
>>>> is
>>>>> the same as zero dose of the placebo.? Similarly zero time on 
>>>>> treatment is
>>>>> the same for any of the treatments or the placebo.
>>>>>
>>>>> In those cases we would not expect a main effect for treatment 
>>>>> because
>>>> that
>>>>> corresponds to systematic differences before the study begins (or 
>>>>> at zero
>>>>> dose), but we would expect an interaction of time (or dose) with
>>>> treatment.
>>>>> On Mon, Aug 29, 2022 at 8:28 AM Phillip Alday<me at phillipalday.com>
>>>> wrote:
>>>>>> On 8/29/22 05:53, Jorge Teixeira wrote:
>>>>>>> Hi. In medicine's RCTs, with 3 or more time-points, whenever 
>>>>>>> LMMs are
>>>>>> used
>>>>>>> and the code is available, a variation of? y ~ time*treatment + 
>>>>>>> (1 |
>>>> ID)
>>>>>>> *(M1)* is always used (from what I have seen).
>>>>>>>
>>>>>>> Recently I came across the model? time + time:treatment + (1 | ID)*
>>>> (M2)*
>>>>>>> in Solomun Kurz's blog and in the book of Galecki (LMMs using R).
>>>>>>>
>>>>>>> Questions:
>>>>>>> *1)* Are there any modelling reasons for M2 to be less used in
>>>> medicine's
>>>>>>> RCTs?
>>>>>> It depends a bit on what `y` is: change from baseline or the 'raw'
>>>>>> measure. If it's the raw measure, then (M2) doesn't include a
>>>>>> description of differences at baseline between the groups.
>>>>>>
>>>>>> Perhaps most importantly though: (M2) violates the principle of
>>>>>> marginality discussed e.g. in Venables' Exegeses on Linear Models
>>>>>> (https://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf)
>>>>>>
>>>>>>> *2)* Can anyone explain, in layman terms, what is the estimand 
>>>>>>> in M2?
>>>> I
>>>>>>> still struggle to understand what model is really measuring.
>>>>>> Approximately the same thing as M1, except that the "overall" 
>>>>>> effect of
>>>>>> treatment is assumed to be zero. "Overall" is a bit vague because it
>>>>>> depends on the contrast coding used for time and treatment.
>>>>>>
>>>>>> You can see this for yourself. M1 can also be written as:
>>>>>>
>>>>>> y ~ time + time:treatment + treatment + (1|ID).
>>>>>>
>>>>>> If you force the coefficient on treatment to be zero, then you 
>>>>>> have M2.
>>>>>>
>>>>>>> *3)* On a general basis, in a RCT with 3 time points (baseline,
>>>> 3-month
>>>>>> and
>>>>>>> 4-month), would you tend to gravitate more towards model 1 or 2?
>>>>>> Definitely (1).
>>>>>>
>>>>>> PS: When referencing a blog entry, please provide a link to it. :)
>>>>>>
>>>>>>> Thank you
>>>>>>> Jorge
>>> ????[[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org? mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>

-- 
Karl Ove Hufthammer


From re|nho|d@k||eg| @end|ng |rom gm@||@com  Mon Aug 29 22:19:39 2022
From: re|nho|d@k||eg| @end|ng |rom gm@||@com (Reinhold Kliegl)
Date: Mon, 29 Aug 2022 22:19:39 +0200
Subject: [R-sig-ME] time*treatment vs time + time:treatment in RCTs
In-Reply-To: <03270bfc-62de-3ac8-29ba-0e66095264c7@huftis.org>
References: <CAOYO_yBRJu0W0g4TfrGH2wQuzFzqT1_3OcZfNGmVC7unMWqAtA@mail.gmail.com>
 <12130_1661779721_0RHD0087DPFSUJ00_aba5ee11-3934-fb92-1231-d559e1d8aa50@phillipalday.com>
 <CAO7JsnRGXtOee0T-hQjVnqtBcn3TrkfOHYqbqEOvudrhTArnBg@mail.gmail.com>
 <66d905e97e424826b74edca52a4d6eff@UM-MAIL3214.unimaas.nl>
 <CAOYO_yDAd3OG7_pWzcSrfnn8mj54D2D9HN8mPVLJW00kPHyLYw@mail.gmail.com>
 <b3faff1a-8e4c-c8a7-8a36-0def93d25655@huftis.org>
 <2d9138fd-491e-3a93-a629-b25c8e49ad85@huftis.org>
 <03270bfc-62de-3ac8-29ba-0e66095264c7@huftis.org>
Message-ID: <E0D5E2FA-66B3-470F-86FD-BBC89ABE4230@gmail.com>

Instead of combining the groups at pretest, you could also switch to indicator variables. 

dat_long$Subj <- factor(dat_long$ID)

mm <- model.matrix(~ 1 + time*group, data=dat_long)
t <- mm[,2]
t_x_g <- mm[,4]
res3 <- lmer(vo2 ~  1 + t + t_x_g + (1 | Subj),
             data = dat_long, REML=FALSE,
             control=lmerControl(calc.derivs = FALSE))

anova(res3, res2)

#Data: dat_long
#Models:
#res3: vo2 ~ 1 + t + t_x_g + (1 | Subj)
#res2: vo2 ~ 1 + time + group:time + (1 | Subj)
#     npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)  
#res3    5 600.56 614.49 -295.28   590.56                       
#res2    6 599.81 616.54 -293.91   587.81 2.7446  1    0.09758 .
#---
#Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

> On 29. Aug 2022, at 21:25, Karl Ove Hufthammer <karl at huftis.org> wrote:
> 
> BTW, this is actually a rather annoying feature of the ways model formulas work in R. For a *randomised* longitudinal study, the population means for the randomisation groups are *identical* at baseline (due to the randomisation). So to properly *adjust* for any (random) group unbalances at baseline in the samples, one should fit a model *without* a ?group? effect at baseline. (I know it sounds strange to fit a model without group differences at baseline to *adjust* for any baseline differences, but if you think about it for a while, it makes sense ?)
> 
> So instead of fitting
> 
> time + group + time:group + ...
> 
> (where ?group? represents the population differences at baseline)
> 
> one would naively *think* that one should fit a
> 
> time + time:group + ...
> 
> model. But R changes the *meaning* of the ?time:group? term in the second model, so one ends up fitting the exact same model as the first model (though with a different parametrisation), i.e., a model *not* adjusting for any sample differences at baseline.
> 
> The only way I?ve found to easily fit the proper model, is to create a factor of all ?interaction(time, group)? values and manually collapse the baseline groups to have the same level. That works fine, but it makes some tests *much* more complication, as you can no longer use R?s formula handling for simplifying models.
> 
> 
> Karl Ove Hufthammer
> 
> Karl Ove Hufthammer skreiv 29.08.2022 20:59:
>> Hmm, the automatic HTML-to-plaintext conversion didn?t work too well. Here?s a plaintext version:
>> 
>> No, you actually get equivalent results for your two models (which is really one model, just parametrised differently). The likelihood for the two models should be identical, and the P-value for testing whether there is an interaction should be identical. Here?s a simple simulation for data very similar to the ones you have:
>> 
>> library(lmerTest)
>> 
>> d_temp = expand.grid(group = c("PLA", "FUT"),
>>                      time = c("Baseline", "3month", "4month"))
>> n_varcombo = nrow(d_temp)
>> d_temp$exp = c(29, 30, 24.5, 28, 24, 27)
>> n_ind = 30
>> dat_long = d_temp[rep(1:n_varcombo, each = n_ind), ]
>> dat_long$ID = rep(1:n_ind, each = n_varcombo)
>> set.seed(6)
>> dat_long$ID_effect = rep(rnorm(n_ind, sd = 3), each = n_varcombo)
>> dat_long$vo2 = dat_long$exp + rnorm(n_varcombo * n_ind, sd = 3)
>> 
>> # Model without interaction
>> res0 <- lmer(vo2 ~ group + time + (1 | ID), data = dat_long)
>> 
>> # Two (equivalent) models with interaction
>> res1 <- lmer(vo2 ~  group * time + (1  | ID), data = dat_long)
>> summary(res1)
>> #> Fixed effects:
>> #>                     Estimate Std. Error      df t value Pr(>|t|)
>> #> (Intercept)          28.6258     0.5439 24.0000  52.635 < 2e-16 ***
>> #> groupFUT              1.2876     0.7691 24.0000   1.674 0.1071
>> #> time3month           -4.8032     0.7691 24.0000  -6.245 1.87e-06 ***
>> #> time4month           -4.8628     0.7691 24.0000  -6.322 1.55e-06 ***
>> #> groupFUT:time3month   2.7573     1.0877 24.0000   2.535 0.0182 *
>> #> groupFUT:time4month   1.5326     1.0877 24.0000   1.409 0.1717
>> #>
>> 
>> res2 <- lmer(vo2 ~  time + group:time + (1 | ID), data = dat_long)
>> summary(res2)
>> #> Fixed effects:
>> #>                       Estimate Std. Error      df t value Pr(>|t|)
>> #> (Intercept)            28.6258     0.5439 24.0000  52.635 < 2e-16 ***
>> #> time3month             -4.8032     0.7691 24.0000  -6.245 1.87e-06 ***
>> #> time4month             -4.8628     0.7691 24.0000  -6.322 1.55e-06 ***
>> #> timeBaseline:groupFUT   1.2876     0.7691 24.0000   1.674 0.10710
>> #> time3month:groupFUT     4.0449     0.7691 24.0000   5.259 2.16e-05 ***
>> #> time4month:groupFUT     2.8202     0.7691 24.0000   3.667 0.00122 **
>> 
>> # The models have the same log likelihood (and degrees of freedom)
>> logLik(res1)
>> #> 'log Lik.' -442.2284 (df=8)
>> logLik(res2)
>> #> 'log Lik.' -442.2284 (df=8)
>> 
>> # And the P-values for the interaction are exactly the same
>> anova(res0, res1)
>> #> refitting model(s) with ML (instead of REML)
>> #> Data: dat_long
>> #> Models:
>> #> res0: vo2 ~ group + time + (1 | ID)
>> #> res1: vo2 ~ group * time + (1 | ID)
>> #>      npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)
>> #> res0    6 906.62 925.78 -447.31 894.62
>> #> res1    8 903.79 929.33 -443.89   887.79 6.8379  2 0.03275 *
>> #> ---
>> #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>> 
>> anova(res0, res2)
>> #> refitting model(s) with ML (instead of REML)
>> #> Data: dat_long
>> #> Models:
>> #> res0: vo2 ~ group + time + (1 | ID)
>> #> res2: vo2 ~ time + group:time + (1 | ID)
>> #>      npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)
>> #> res0    6 906.62 925.78 -447.31 894.62
>> #> res2    8 903.79 929.33 -443.89   887.79 6.8379  2 0.03275 *
>> #> ---
>> #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>> 
>> 
>> As you can see, the two models are actually equivalent, and any inference based on the models should give the same results.
>> 
>> 
>> Karl Ove Hufthammer
>> 
>> 
>> Karl Ove Hufthammer skreiv 29.08.2022 20:56:
>>> No, you actually get equivalent results for your two models (which is
>>> really one model, just parametrised differently). The likelihood for the
>>> two models should be identical, and the P-value for testing whether
>>> there is an interaction should be identical. Here?s a simple simulation
>>> for data very similar to the ones you have:
>>> 
>>> |library(lmerTest)
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-13>d_temp 
>>> = expand.grid(group = c("PLA", "FUT"),
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-14> 
>>> time = c("Baseline", "3month", "4month"))
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-15>n_varcombo 
>>> = nrow(d_temp)
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-16>d_temp$exp 
>>> = c(29, 30, 24.5, 28, 24, 27)
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-17>n_ind 
>>> = 30
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-18>dat_long 
>>> = d_temp[rep(1:n_varcombo, each = n_ind), ]
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-19>dat_long$ID 
>>> = rep(1:n_ind, each = n_varcombo)
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-20>set.seed(6) 
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-21>dat_long$ID_effect 
>>> = rep(rnorm(n_ind, sd = 3), each = n_varcombo)
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-22>dat_long$vo2 
>>> = dat_long$exp + rnorm(n_varcombo * n_ind, sd = 3)
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-23> 
>>> # Model without interaction
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-25>res0 
>>> <- lmer(vo2 ~ group + time + (1 | ID), data = dat_long)
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-26> 
>>> # Two (equivalent) models with interaction
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-28>res1 
>>> <- lmer(vo2 ~ group * time + (1 | ID), data = dat_long)
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-29>summary(res1) 
>>> #> Fixed effects:
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-48>#> 
>>> Estimate Std. Error df t value Pr(>|t|)
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-49>#> 
>>> (Intercept) 28.6258 0.5439 24.0000 52.635 < 2e-16 ***
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-50>#> 
>>> groupFUT 1.2876 0.7691 24.0000 1.674 0.1071
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-51>#> 
>>> time3month -4.8032 0.7691 24.0000 -6.245 1.87e-06 ***
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-52>#> 
>>> time4month -4.8628 0.7691 24.0000 -6.322 1.55e-06 ***
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-53>#> 
>>> groupFUT:time3month 2.7573 1.0877 24.0000 2.535 0.0182 *
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-54>#> 
>>> groupFUT:time4month 1.5326 1.0877 24.0000 1.409 0.1717 #>
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-65>res2 
>>> <- lmer(vo2 ~ time + group:time + (1 | ID), data = dat_long)
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-66>summary(res2) 
>>> #> Fixed effects:
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-85>#> 
>>> Estimate Std. Error df t value Pr(>|t|)
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-86>#> 
>>> (Intercept) 28.6258 0.5439 24.0000 52.635 < 2e-16 ***
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-87>#> 
>>> time3month -4.8032 0.7691 24.0000 -6.245 1.87e-06 ***
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-88>#> 
>>> time4month -4.8628 0.7691 24.0000 -6.322 1.55e-06 ***
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-89>#> 
>>> timeBaseline:groupFUT 1.2876 0.7691 24.0000 1.674 0.10710
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-90>#> 
>>> time3month:groupFUT 4.0449 0.7691 24.0000 5.259 2.16e-05 ***
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-91>#> 
>>> time4month:groupFUT 2.8202 0.7691 24.0000 3.667 0.00122 ** # The models
>>> have the same log likelihood (and degrees of freedom)
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-104>logLik(res1) 
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-105>#> 
>>> 'log Lik.' -442.2284 (df=8)
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-106>logLik(res2) 
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-107>#> 
>>> 'log Lik.' -442.2284 (df=8)
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-108> 
>>> # And the P-values for the interaction are exactly the same
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-110>anova(res0, 
>>> res1)
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-111>#> 
>>> refitting model(s) with ML (instead of REML)
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-112>#> 
>>> Data: dat_long
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-113>#> 
>>> Models:
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-114>#> 
>>> res0: vo2 ~ group + time + (1 | ID)
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-115>#> 
>>> res1: vo2 ~ group * time + (1 | ID)
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-116>#> 
>>> npar AIC BIC logLik deviance Chisq Df Pr(>Chisq)
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-117>#> 
>>> res0 6 906.62 925.78 -447.31 894.62 #> res1 8 903.79 929.33 -443.89
>>> 887.79 6.8379 2 0.03275 *
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-119>#> 
>>> ---
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-120>#> 
>>> Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-121>anova(res0, 
>>> res2)
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-122>#> 
>>> refitting model(s) with ML (instead of REML)
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-123>#> 
>>> Data: dat_long
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-124>#> 
>>> Models:
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-125>#> 
>>> res0: vo2 ~ group + time + (1 | ID)
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-126>#> 
>>> res2: vo2 ~ time + group:time + (1 | ID)
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-127>#> 
>>> npar AIC BIC logLik deviance Chisq Df Pr(>Chisq)
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-128>#> 
>>> res0 6 906.62 925.78 -447.31 894.62 #> res2 8 903.79 929.33 -443.89
>>> 887.79 6.8379 2 0.03275 *
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-130>#> 
>>> ---
>>> <http://localhost:28019/session/grave-cobra_reprex_preview.html?viewer_pane=1&capabilities=1&host=http%3A%2F%2F127.0.0.1%3A55034#cb1-131>#> 
>>> Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1|
>>> 
>>> 
>>> As you can see, the two models are actually equivalent, and any
>>> inference based on the models should give the same results.
>>> 
>>> 
>>> Karl Ove Hufthammer
>>> 
>>> Jorge Teixeira skreiv 29.08.2022 20:20:
>>>> Thank you all for the replies. Still processing them...
>>>> 
>>>> Indeed, Wolfgang, I was mainly thinking of time as a factor. Although, I
>>>> welcome comments as if it was numeric as well.
>>>> 
>>>> Your reply is surprising to me, because in my data I get different results.
>>>> The ES and p-values are very different regarding the interactions at 3 and
>>>> 4-months, which are the relevant data to me. My df has 3 time points.
>>>> 
>>>>    res1 <- lmer(vo2 ~  group*time + ( 1  | ID  ), data = dat_long )
>>>> 
>>>>      res2 <- lmer(vo2 ~  time + group:time + ( 1 | ID  ), data =  dat_long )
>>>> 
>>>> 
>>>> *res1:*
>>>> Fixed effects:
>>>>                          Estimate Std. Error      df t value Pr(>|t|)
>>>> (Intercept)             29.0705     0.9998 61.4510  29.076 < 2e-16 ***
>>>> groupFUT              1.0395     1.4140 61.4510   0.735 0.465036
>>>> time3month              -4.4917     1.0918 64.1740  -4.114 0.000113 ***
>>>> time4month              -5.0305     1.0622 63.8295  -4.736 1.26e-05 ***
>>>> *groupFUT:time3month *  2.5467     1.4396 61.8093   1.769 0.081822 .
>>>> *groupFUT:time4month*   1.7643     1.4424 61.8409   1.223 0.225909
>>>> 
>>>> 
>>>> *res2:*
>>>> Fixed effects:
>>>>                          Estimate Std. Error      df t value Pr(>|t|)
>>>> (Intercept)             29.0705     0.9998 61.4510  29.076 < 2e-16 ***
>>>> time3month              -4.4917     1.0918 64.1740  -4.114 0.000113 ***
>>>> time4month              -5.0305     1.0622 63.8295  -4.736 1.26e-05 ***
>>>> time0month:groupFUT   1.0395     1.4140 61.4510   0.735 0.465036
>>>> *time3month:groupFUT*   3.5862     1.5402 73.4895   2.328 0.022643 *
>>>> *time4month:groupFUT*  2.8038     1.5428 73.7427   1.817 0.073226 .
>>>> 
>>>> 
>>>> 
>>>> Viechtbauer, Wolfgang (NP)<wolfgang.viechtbauer at maastrichtuniversity.nl>
>>>> escreveu no dia segunda, 29/08/2022 ?(s) 16:11:
>>>> 
>>>>> I strongly suspect that 'time' is treated as a factor in the examples
>>>>> Jorge is referring to. In this case, the two formulations are just
>>>>> different parameterizations of the same model. We can use the 'Orthodont'
>>>>> data to illustrate this. Think of 'age' as the time variable (as a
>>>>> four-level factor) and 'Sex' as the treatment variable (as a two-level
>>>>> factor). In fact, I will throw in a third parameterization, which I think
>>>>> is even more intuitive.
>>>>> 
>>>>> library(lme4)
>>>>> 
>>>>> data("Orthodont", package="nlme")
>>>>> 
>>>>> Orthodont$age <- factor(Orthodont$age)
>>>>> 
>>>>> res1 <- lmer(distance ~ age*Sex + (1 | Subject), data=Orthodont)
>>>>> summary(res1)
>>>>> 
>>>>> res2 <- lmer(distance ~ age + age:Sex + (1 | Subject), data=Orthodont)
>>>>> summary(res2)
>>>>> 
>>>>> res3 <- lmer(distance ~ 0 + age + age:Sex + (1 | Subject), data=Orthodont)
>>>>> summary(res3)
>>>>> 
>>>>> logLik(res1)
>>>>> logLik(res2)
>>>>> logLik(res3)
>>>>> 
>>>>> The fit is identical.
>>>>> 
>>>>> In 'res3', we get the estimated intercepts (means) of the reference group
>>>>> (in this case for 'Male') at all 4 timepoints and the age:Sex coefficients
>>>>> are the difference between the Female and Male groups at those 4 timepoints.
>>>>> 
>>>>> Since these are just all different parameterizations of the same model,
>>>>> there is no reasons for preferring one over the other.
>>>>> 
>>>>> One has to be careful though when using anova() on those models, esp. with
>>>>> respect to the age:Sex test. In anova(res1), the test examines if the
>>>>> difference between males and females is the same at all 4 timepoints, while
>>>>> in anova(res2) and anova(res3) the test examines if the difference is 0 at
>>>>> all 4 timepoints. However, one could get either test out of all three
>>>>> parameterizations, by forming appropriate contrasts. So again, no reason to
>>>>> prefer one over the other (except maybe convenience depending on what one
>>>>> would like to test).
>>>>> 
>>>>> Best,
>>>>> Wolfgang
>>>>> 
>>>>>> -----Original Message-----
>>>>>> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
>>>>> On
>>>>>> Behalf Of Douglas Bates
>>>>>> Sent: Monday, 29 August, 2022 16:14
>>>>>> To: Phillip Alday
>>>>>> Cc: R-mixed models mailing list; Jorge Teixeira
>>>>>> Subject: Re: [R-sig-ME] time*treatment vs time + time:treatment in RCTs
>>>>>> 
>>>>>> M2 is an appropriate model if time corresponds to "time on treatment" or
>>>>> in
>>>>>> general if the covariate over which the measurements are repeated has a
>>>>>> scale where 0 is meaningful.  I think of it as the "zero dose" model
>>>>>> because zero dose of treatment 1 is the same as zero dose of treatment 2
>>>>> is
>>>>>> the same as zero dose of the placebo.  Similarly zero time on treatment is
>>>>>> the same for any of the treatments or the placebo.
>>>>>> 
>>>>>> In those cases we would not expect a main effect for treatment because
>>>>> that
>>>>>> corresponds to systematic differences before the study begins (or at zero
>>>>>> dose), but we would expect an interaction of time (or dose) with
>>>>> treatment.
>>>>>> On Mon, Aug 29, 2022 at 8:28 AM Phillip Alday<me at phillipalday.com>
>>>>> wrote:
>>>>>>> On 8/29/22 05:53, Jorge Teixeira wrote:
>>>>>>>> Hi. In medicine's RCTs, with 3 or more time-points, whenever LMMs are
>>>>>>> used
>>>>>>>> and the code is available, a variation of  y ~ time*treatment + (1 |
>>>>> ID)
>>>>>>>> *(M1)* is always used (from what I have seen).
>>>>>>>> 
>>>>>>>> Recently I came across the model  time + time:treatment + (1 | ID)*
>>>>> (M2)*
>>>>>>>> in Solomun Kurz's blog and in the book of Galecki (LMMs using R).
>>>>>>>> 
>>>>>>>> Questions:
>>>>>>>> *1)* Are there any modelling reasons for M2 to be less used in
>>>>> medicine's
>>>>>>>> RCTs?
>>>>>>> It depends a bit on what `y` is: change from baseline or the 'raw'
>>>>>>> measure. If it's the raw measure, then (M2) doesn't include a
>>>>>>> description of differences at baseline between the groups.
>>>>>>> 
>>>>>>> Perhaps most importantly though: (M2) violates the principle of
>>>>>>> marginality discussed e.g. in Venables' Exegeses on Linear Models
>>>>>>> (https://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf)
>>>>>>> 
>>>>>>>> *2)* Can anyone explain, in layman terms, what is the estimand in M2?
>>>>> I
>>>>>>>> still struggle to understand what model is really measuring.
>>>>>>> Approximately the same thing as M1, except that the "overall" effect of
>>>>>>> treatment is assumed to be zero. "Overall" is a bit vague because it
>>>>>>> depends on the contrast coding used for time and treatment.
>>>>>>> 
>>>>>>> You can see this for yourself. M1 can also be written as:
>>>>>>> 
>>>>>>> y ~ time + time:treatment + treatment + (1|ID).
>>>>>>> 
>>>>>>> If you force the coefficient on treatment to be zero, then you have M2.
>>>>>>> 
>>>>>>>> *3)* On a general basis, in a RCT with 3 time points (baseline,
>>>>> 3-month
>>>>>>> and
>>>>>>>> 4-month), would you tend to gravitate more towards model 1 or 2?
>>>>>>> Definitely (1).
>>>>>>> 
>>>>>>> PS: When referencing a blog entry, please provide a link to it. :)
>>>>>>> 
>>>>>>>> Thank you
>>>>>>>> Jorge
>>>>     [[alternative HTML version deleted]]
>>>> 
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org  mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> 
>> 
> 
> -- 
> Karl Ove Hufthammer
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From jorgemmtte|xe|r@ @end|ng |rom gm@||@com  Tue Aug 30 12:13:17 2022
From: jorgemmtte|xe|r@ @end|ng |rom gm@||@com (Jorge Teixeira)
Date: Tue, 30 Aug 2022 11:13:17 +0100
Subject: [R-sig-ME] time*treatment vs time + time:treatment in RCTs
In-Reply-To: <4ff8a3cf-1610-bc52-4f64-10241c9e740e@phillipalday.com>
References: <CAOYO_yBRJu0W0g4TfrGH2wQuzFzqT1_3OcZfNGmVC7unMWqAtA@mail.gmail.com>
 <4ff8a3cf-1610-bc52-4f64-10241c9e740e@phillipalday.com>
Message-ID: <CAOYO_yAqRRmkbAwHMuT1fjW7OVo6JLyung8i8LPEygS3qgfbpw@mail.gmail.com>

Thank you, Philip.

1) would the model y (y1, y2 - but not y0) ~ y0 + time + time:treatment +
(1|ID) (*m3*) also violate the  principle of
marginality, in your opinion?

1.1) Would you still prefer m1 compared to m3?


*Final notes*:
Here is an interesting stata (sorry) about this:
https://stats.oarc.ucla.edu/stata/faq/what-happens-if-you-omit-the-main-effect-in-a-regression-model-with-an-interaction/


Solomon's post.
https://solomonkurz.netlify.app/post/2022-06-13-just-use-multilevel-models-for-your-pre-post-rct-data/

Thanks!




Phillip Alday <me at phillipalday.com> escreveu no dia segunda, 29/08/2022
?(s) 14:26:

>
> On 8/29/22 05:53, Jorge Teixeira wrote:
> > Hi. In medicine's RCTs, with 3 or more time-points, whenever LMMs are
> used
> > and the code is available, a variation of  y ~ time*treatment + (1 | ID)
> > *(M1)* is always used (from what I have seen).
> >
> > Recently I came across the model  time + time:treatment + (1 | ID)* (M2)*
> > in Solomun Kurz's blog and in the book of Galecki (LMMs using R).
> >
> > Questions:
> > *1)* Are there any modelling reasons for M2 to be less used in medicine's
> > RCTs?
>
> It depends a bit on what `y` is: change from baseline or the 'raw'
> measure. If it's the raw measure, then (M2) doesn't include a
> description of differences at baseline between the groups.
>
> Perhaps most importantly though: (M2) violates the principle of
> marginality discussed e.g. in Venables' Exegeses on Linear Models
> (https://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf)
>
> > *2)* Can anyone explain, in layman terms, what is the estimand in M2? I
> > still struggle to understand what model is really measuring.
>
> Approximately the same thing as M1, except that the "overall" effect of
> treatment is assumed to be zero. "Overall" is a bit vague because it
> depends on the contrast coding used for time and treatment.
>
> You can see this for yourself. M1 can also be written as:
>
> y ~ time + time:treatment + treatment + (1|ID).
>
> If you force the coefficient on treatment to be zero, then you have M2.
>
> >
> > *3)* On a general basis, in a RCT with 3 time points (baseline, 3-month
> and
> > 4-month), would you tend to gravitate more towards model 1 or 2?
>
> Definitely (1).
>
> > Thank you
> > Jorge
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n|  Tue Aug 30 13:39:10 2022
From: wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n| (Viechtbauer, Wolfgang (NP))
Date: Tue, 30 Aug 2022 11:39:10 +0000
Subject: [R-sig-ME] time*treatment vs time + time:treatment in RCTs
In-Reply-To: <CAOYO_yAqRRmkbAwHMuT1fjW7OVo6JLyung8i8LPEygS3qgfbpw@mail.gmail.com>
References: <CAOYO_yBRJu0W0g4TfrGH2wQuzFzqT1_3OcZfNGmVC7unMWqAtA@mail.gmail.com>
 <4ff8a3cf-1610-bc52-4f64-10241c9e740e@phillipalday.com>
 <CAOYO_yAqRRmkbAwHMuT1fjW7OVo6JLyung8i8LPEygS3qgfbpw@mail.gmail.com>
Message-ID: <998614f7a8bd407faa490e756482a323@UM-MAIL3214.unimaas.nl>

If 'time' is categorical, then neither m2 nor m3 violate the 'principle of marginality'.

Best,
Wolfgang

>-----Original Message-----
>From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On
>Behalf Of Jorge Teixeira
>Sent: Tuesday, 30 August, 2022 12:13
>To: Phillip Alday
>Cc: R-mixed models mailing list
>Subject: Re: [R-sig-ME] time*treatment vs time + time:treatment in RCTs
>
>Thank you, Philip.
>
>1) would the model y (y1, y2 - but not y0) ~ y0 + time + time:treatment +
>(1|ID) (*m3*) also violate the  principle of marginality, in your opinion?
>
>1.1) Would you still prefer m1 compared to m3?
>
>*Final notes*:
>Here is an interesting stata (sorry) about this:
>https://stats.oarc.ucla.edu/stata/faq/what-happens-if-you-omit-the-main-effect-
>in-a-regression-model-with-an-interaction/
>
>Solomon's post.
>https://solomonkurz.netlify.app/post/2022-06-13-just-use-multilevel-models-for-
>your-pre-post-rct-data/
>
>Thanks!
>
>Phillip Alday <me at phillipalday.com> escreveu no dia segunda, 29/08/2022
>?(s) 14:26:
>
>> On 8/29/22 05:53, Jorge Teixeira wrote:
>> > Hi. In medicine's RCTs, with 3 or more time-points, whenever LMMs are
>> used
>> > and the code is available, a variation of  y ~ time*treatment + (1 | ID)
>> > *(M1)* is always used (from what I have seen).
>> >
>> > Recently I came across the model  time + time:treatment + (1 | ID)* (M2)*
>> > in Solomun Kurz's blog and in the book of Galecki (LMMs using R).
>> >
>> > Questions:
>> > *1)* Are there any modelling reasons for M2 to be less used in medicine's
>> > RCTs?
>>
>> It depends a bit on what `y` is: change from baseline or the 'raw'
>> measure. If it's the raw measure, then (M2) doesn't include a
>> description of differences at baseline between the groups.
>>
>> Perhaps most importantly though: (M2) violates the principle of
>> marginality discussed e.g. in Venables' Exegeses on Linear Models
>> (https://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf)
>>
>> > *2)* Can anyone explain, in layman terms, what is the estimand in M2? I
>> > still struggle to understand what model is really measuring.
>>
>> Approximately the same thing as M1, except that the "overall" effect of
>> treatment is assumed to be zero. "Overall" is a bit vague because it
>> depends on the contrast coding used for time and treatment.
>>
>> You can see this for yourself. M1 can also be written as:
>>
>> y ~ time + time:treatment + treatment + (1|ID).
>>
>> If you force the coefficient on treatment to be zero, then you have M2.
>>
>> >
>> > *3)* On a general basis, in a RCT with 3 time points (baseline, 3-month
>> and
>> > 4-month), would you tend to gravitate more towards model 1 or 2?
>>
>> Definitely (1).
>>
>> > Thank you
>> > Jorge

From @dh@n333 @end|ng |rom gm@||@com  Thu Sep  1 11:09:27 2022
From: @dh@n333 @end|ng |rom gm@||@com (=?UTF-8?B?U2HDomQgSEFOQU5F?=)
Date: Thu, 1 Sep 2022 11:09:27 +0200
Subject: [R-sig-ME] Plot glmm full-average model
Message-ID: <CA+QAJT5TZPCDEYxGsD1KVVRFZOAZ7joDTw7pcDgntq4nZjhXjQ@mail.gmail.com>

Hi,

I'm performing a glmm modelling using the following script:

aa=read.table("tac.txt", h=T)
attach(aa)
mod=glmer(p~x1+x2*a +x3*as.factor(y)+x4+x5+x6+(1|id), family=binomial,
data=aa)
model.set <- dredge(mod, rank="AICc")
mo <- subset(model.set, !nested(.))
mo
write.csv2(mo,'moo.csv')
top.models <- get.models(mo, subset = delta <2)
top.models
summary(top.models)
mod1<- model.avg(top.models,revised.var = TRUE, adjusted = TRUE, rank =
"AICc")
mod1
summary(mod1)
pred=predict(mod1, type="response")

I'm wondering if any one can help me to plot the "p" (probability of
presence) according x1, x2*a, and x3*as.factor(y).

bestmod (1) :  x1+ x2*a + x3 * as.factor(y)
bestmod (2) :  x1+ x2*a

Thanks

-- 
Sa?d Hanane, PhD
Service d'?cologie, de Biodiversit? et de Conservation des Sols
Centre de Recherche Foresti?re
Chariae Omar Ibn Al Khattab, BP 763, Rabat-Agdal/Maroc.

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Fri Sep  2 02:55:18 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 1 Sep 2022 20:55:18 -0400
Subject: [R-sig-ME] 
 Cannot grok the newdata argument in simulate.merMod(), package lme4
In-Reply-To: <20220805181019.7c10f198@rolf-Latitude-E7470>
References: <20220805181019.7c10f198@rolf-Latitude-E7470>
Message-ID: <196aaeae-afa5-1c34-d78e-e2a8646b9bcc@gmail.com>

   With apologies for delayed response.

   The answer to the "why doesn't roll-your-own match simulate()" is on 
Stack Overflow now: https://stackoverflow.com/a/73576691/190277. The 
short answer is that the differences are harmless and caused by 
differences in the procedures used to pick multivariate Normal deviates 
(which give the same *distributions*, just not the same specific values 
for any given realization/random number seed).

   The answer to "why doesn't simulate() + newdata do what I want" is 
simple **IF YOU KNOW THE ANSWER ALREADY**, which is that for binomial 
responses, the number of trials per observation needs to be specified 
somehow.  Your experience reflects arguably a bug in the code, the 
documentation, or the user interface design (or some combination), but 
the solution is to specify something like

   weights = rep(50, nrow(X))

if (for example) you want all of the binomial samples to be out of 50. 
Or whatever makes sense for your application.  (And good for you for 
paying attention to the "ominous warning"!)

   Hope that helps.

  cheers
    Ben Bolker


On 2022-08-05 2:10 a.m., Rolf Turner wrote:
> 
> 
> I wish to assess, via simulation, the impact of certain aspects
> of the experimental design on the precision of the estimates of
> a rather intricate parameter, the details of which I won't go into.
> 
> To this end I need to fit a model (generalised linear mixed model,
> binomial family) to a data set, and then simulate other data sets,
> reflecting a number of different experimental designs, from the given
> fit.  I thought that the "newdata" argument of the simulate.merMod()
> method would provide me with the means to accomplish my goal, but I
> cannot get it to work.  I cannot properly comprehend the documentation
> of the "newdata" argument in the help file.
> 
> To start with, to make sure (???) that I understood what was going on
> I just simulated a data set from a model fitted to the cbpp data,
> using a "roll-your-own" procedure, and then re-did the simulation
> using simulate.merMod().  I set seeds appropriately so that I would get
> the same results, given that my roll-your-own procedure was correct.
> After many false starts and excursions down blind alleys, I got the two
> procedures to agree.  The details of what I did are to be found in the
> attached sourceable script "demo.txt".
> 
> I then attempted to effect simulations using a different data set "X"
> (just including predictors, no responses) constructed according to
> a different experimental design.
> 
> I tried two different approaches.  The first approach:
> 
> s.mer1 <- simulate(fit,newdata=X,allow.new.levels=TRUE)
> 
> This produced an ominous warning:
>> In wts - Y :
>>    longer object length is not a multiple of shorter object length
> 
> The second approach:
> 
> newpar <- list(theta=getME(fit,"theta"),beta=getME(fit,"beta"))
> set.seed(101)
> s.mer2 <- simulate(~0+period +(1|herd),newdata=X,newparams=newpar)
> 
> This produced warnings:
> 
>> beta parameter vector not named: assuming same order as internal
>> vector
>> Warning message:
>> In setParams(object, newparams) :
>>    some parameters not specified in setParams()
> 
> The first bit ("beta parameter vector not named ...") also happens if I
> try to reproduce exactly an example given in the help, so perhaps I
> should not be too worried by it.  The second bit is ominous (and to
> me mysterious).
> 
> The result of the first approach is incomprehensible to me, and bears
> no relationship that I can discern to the results of a roll-your-own
> approach that I also tried.  The result of the second approach is all
> NAs, so something is clearly wrong.
> 
> The details of what I did are given in the attached file
> "try.newdata.txt".
> 
> I would be ever-so-humbly grateful if someone could explain to me what
> I am doing wrong in my attempts to use the "newdata" argument of
> simulate.merMod().
> 
> cheers,
> 
> Rolf Turner
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics
 > E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From n@ver@noc @end|ng |rom un@|@edu@co  Mon Sep  5 03:56:11 2022
From: n@ver@noc @end|ng |rom un@|@edu@co (Nicolas Alfonso Verano Camacho)
Date: Sun, 4 Sep 2022 20:56:11 -0500
Subject: [R-sig-ME] model validation with weights
Message-ID: <CAK6Av5K7Uwe3wRe41UAsxfSr4P=ve+31Z9RNr199G7YWriKNyw@mail.gmail.com>

Hi, my name is Nicolas and I have a question.

Reviewing the documentation for both gmmTMB and DHARMa, when you have
weights (in my case the weight represents a repeated observation, I only
use fixed effects) it seems that gmmTMB ignores them. That said, it is not
clear to me if I can use DHARMa to validate the models obtained with
glmmTMB or how I could generate appropriate validation strategies in this
case.

Thank you very much for your help

-- 
*Aviso legal:*?El contenido de este mensaje y los archivos adjuntos son 
confidenciales y de uso exclusivo de la Universidad Nacional de Colombia. 
Se encuentran dirigidos s?lo para el uso del destinatario al cual van 
enviados. La reproducci?n, lectura y/o copia se encuentran prohibidas a 
cualquier persona diferente a este y puede ser ilegal. Si usted lo ha 
recibido por error, inf?rmenos y elim?nelo de su correo. Los Datos 
Personales ser?n tratados conforme a la Ley 1581 de 2012 y a nuestra 
Pol?tica de Datos Personales que podr? consultar en la p?gina web?
www.unal.edu.co <http://www.unal.edu.co/>.*?*Las opiniones, informaciones, 
conclusiones y cualquier otro tipo de dato contenido en este correo 
electr?nico, no relacionados con la actividad de la Universidad Nacional de 
Colombia, se entender? como personales y de ninguna manera son avaladas por 
la Universidad.

	[[alternative HTML version deleted]]


From o||ve|r@r|@ue@b @end|ng |rom gm@||@com  Tue Sep  6 15:04:04 2022
From: o||ve|r@r|@ue@b @end|ng |rom gm@||@com (Rafael Lima Oliveira)
Date: Tue, 6 Sep 2022 10:04:04 -0300
Subject: [R-sig-ME] Random effect variance = zero
Message-ID: <CAKmKTvEKgHz09qxqGyGobXg8xC8XMWO928DrprPv54q4UzdOgQ@mail.gmail.com>

Hello everyone. I have a dataset of  environmental variables
(salinity, temperature, pH, dissolved oxygen, turbidity and depth) as
predictors and as response variables fish densities and rarefied
species richness.

Initially, I run a Gamma-GLMM with log link function using as response
variable fish density and it came up with the error "*Error in
pwrssUpdate(pp, resp, tol = tolPwrss, GQmat = GHrule(0L), compDev =
compDev, : pwrssUpdate did not converge in (maxit) iterations*"

As suggested by Ben Bolker comments, I created two model as follow:

m1 <- glm(Density ~ Locality +Salinity + Temperature +pH + DO +
Turbidity + Depth, family= Gamma(link= log), data = dados)

m2<- glmer(Density ~ Salinity + Temperature +pH + DO + Turbidity +
Depth + (1 |Month) + (1|Locality/Site), family= Gamma(link= log), data
= dados, start=list(fixef=coef(gama1)),
control=glmerControl(nAGQ0initStep=FALSE), verbose = 100)

In this case, the first model was fitted to get starting values.

Now, I change my response variable and I'm using  Rarefied Species
Richness. I used, initially, Poisson distribution to my count data
(Richness). However, to avoid comparison bias caused by differences in
total abundance among samples I'm using rarefied fish species richness
(based on 10 individuals).

When I run the model, this warning message appears repeatedly:

- Boundary (singular) fit: see help('isSingular')

Warning messages:
1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge with max|grad| = 0.0529464 (tol = 0.002, component 1)
2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :

I'm using gamma distribution instead of Poisson to fit rarefied
species richness. The summary output showed random-effect variance and
Std.Dev values as zero.

The random-effect variances being estimated as zero indicates that my model
should be simplified? Should I remove the random effects terms without
substantial loss of fidelity to the data? The Random structure that I
created in my model account for my nested design, where: (1 |Month) account
for temporal variability of my dataset collected montly during 1 year and
(1|Locality/Site) where a indicated that , spatially my data are nested, in
this case "Site" nested in "Locality".

If any anybody has any tips on this please give me a hand.
Hope you can understand it.
Thanks.

-- 
*Rafael Lima Oliveira*
Doutorando em Biologia Animal
Universidade Federal do Esp?rito Santo - UFES
Laborat?rio de Ecologia de peixes marinhos - CEUNES/UFES
*Contato:* (75) 98873-1548 / (27) 99526-3612
*E-mail alternativo:* rafael.l.oliveira at edu.ufes.br
*Curr?culo Lattes*:  http://lattes.cnpq.br/5215941704013482

>)))?>               >)))?>               >)))?>                   >)))?>

	[[alternative HTML version deleted]]


From |ouc@y@te@22 @end|ng |rom gm@||@com  Fri Sep  9 13:12:03 2022
From: |ouc@y@te@22 @end|ng |rom gm@||@com (Louc Yates)
Date: Fri, 9 Sep 2022 12:12:03 +0100
Subject: [R-sig-ME] Bivariate MCMCglmm with uneven number of repeats
Message-ID: <CA+uEwdYpm_p9-XZQg_rOxzKgca6Q7oRDGZq1dBPWshpxk_k+Bg@mail.gmail.com>

Dear list,

I would like to test for covariation between two traits, aggression (count
data, poisson distribution) and glucocorticoids (gaussian), using a
bivariate MCMCglmm.

During data collection, aggression assays were conducted immediately after
collection of samples for glucocorticoids. However, additional
glucocorticoid samples were also collected without any aggression assays
being collected. Therefore, I have more glucocorticoid values than I do
aggression scores. If possible, I would like to include all
glucocorticoid values,
rather than just the samples that were collected at the same time
aggression assays were performed.

I have tried running a bivariate MCMCglmm using a wide data frame, where
each row contains an aggression and glucocorticoid value (both collected at
the same time) and the remaining glucocorticoid values on rows that contain
an NA where the paired aggression data should be. However, MCMCglmm will
not run models using this data format as it does not accept NAs.

I have also restructured my data to a long/stacked format, where each row
contains information on a single trait (similar to the data structure
needed for the 'covu' method) and the model runs successfully and the
diagnostics look fine.

My question is: is running a bivariate model with an uneven number of
repeats for either trait statistically 'sound'? Am I unknowingly violating
any assumptions? I only ask as I have not run bivariate models using this
data structure before and want to make sure it is fine to do it this way.

Best wishes
Lou


In case this provides any useful info, below is an example of my prior
specification and model structure.

prior <- list(G = list(G1 = list(V = diag(2), nu = 1.002), *#2-way var-cov
matrix of IndividualID for AGGRESSION + CORT*
                                  G2 = list(V = diag(1), nu = 0.002), *#rand
effect for TestChamber (fitted for AGGRESSION)*
                                  G3 = list(V = diag(1), nu = 0.002),*#rand
effect for BirthYear (fitted for CORT)*
                                  G4 = list(V = diag(1), nu = 0.002)), *#rand
effect for LabID (CORT)*
                     R = list(R1 = list(V = diag(2), nu = 1.002)))  *#2-way
var-cov matrix of resid for AGGRESSION + CORT*


m1<- MCMCglmm(Aggression.CORT.data ~ variable - 1 +
at.level(variable, "AGGRESSION"):rescale(Sex) +
at.level(variable, "AGGRESSION"):rescale(Age_years) +
at.level(variable, "CORT"):rescale(Age_years),
random = ~us(variable):IndividualID +
us(at.level(variable,"AGGRESSION")):TestChamber+
us(at.level(variable,"CORT")):BirthYear+
us(at.level(variable,"CORT")):LabID,
rcov = ~idh(variable):units,
family = NULL, # specified already in the data
prior = prior,
nitt=5000000,
burnin=50000,
thin=500,
verbose = FALSE,
pr=FALSE,
data = data)

	[[alternative HTML version deleted]]


From j@h@d||e|d @end|ng |rom ed@@c@uk  Fri Sep  9 16:18:13 2022
From: j@h@d||e|d @end|ng |rom ed@@c@uk (Jarrod Hadfield)
Date: Fri, 9 Sep 2022 14:18:13 +0000
Subject: [R-sig-ME] Bivariate MCMCglmm with uneven number of repeats
In-Reply-To: <CA+uEwdYpm_p9-XZQg_rOxzKgca6Q7oRDGZq1dBPWshpxk_k+Bg@mail.gmail.com>
References: <CA+uEwdYpm_p9-XZQg_rOxzKgca6Q7oRDGZq1dBPWshpxk_k+Bg@mail.gmail.com>
Message-ID: <3B9C2332-181C-4305-A181-6FBFE3324FB2@ed.ac.uk>

Hi Lou,

Doing the analyses the way you have done - long format  - is statistically should and should give exactly the same answer as a wide format data set padded with NA?s. However, the long-format method is computationally more efficient, especially when the number of repeats is highly uneven between the traits.

MCMCglmm should have accepted the wide format and padded NA?s, however - could you send me code/data/error-message so I can take a look?

Cheers,

Jarrod

> On 9 Sep 2022, at 12:12, Louc Yates <louc.yates22 at gmail.com> wrote:
>
> This email was sent to you by someone outside the University.
> You should only click on links or attachments if you are certain that the email is genuine and the content is safe.
>
> Dear list,
>
> I would like to test for covariation between two traits, aggression (count
> data, poisson distribution) and glucocorticoids (gaussian), using a
> bivariate MCMCglmm.
>
> During data collection, aggression assays were conducted immediately after
> collection of samples for glucocorticoids. However, additional
> glucocorticoid samples were also collected without any aggression assays
> being collected. Therefore, I have more glucocorticoid values than I do
> aggression scores. If possible, I would like to include all
> glucocorticoid values,
> rather than just the samples that were collected at the same time
> aggression assays were performed.
>
> I have tried running a bivariate MCMCglmm using a wide data frame, where
> each row contains an aggression and glucocorticoid value (both collected at
> the same time) and the remaining glucocorticoid values on rows that contain
> an NA where the paired aggression data should be. However, MCMCglmm will
> not run models using this data format as it does not accept NAs.
>
> I have also restructured my data to a long/stacked format, where each row
> contains information on a single trait (similar to the data structure
> needed for the 'covu' method) and the model runs successfully and the
> diagnostics look fine.
>
> My question is: is running a bivariate model with an uneven number of
> repeats for either trait statistically 'sound'? Am I unknowingly violating
> any assumptions? I only ask as I have not run bivariate models using this
> data structure before and want to make sure it is fine to do it this way.
>
> Best wishes
> Lou
>
>
> In case this provides any useful info, below is an example of my prior
> specification and model structure.
>
> prior <- list(G = list(G1 = list(V = diag(2), nu = 1.002), *#2-way var-cov
> matrix of IndividualID for AGGRESSION + CORT*
>                                  G2 = list(V = diag(1), nu = 0.002), *#rand
> effect for TestChamber (fitted for AGGRESSION)*
>                                  G3 = list(V = diag(1), nu = 0.002),*#rand
> effect for BirthYear (fitted for CORT)*
>                                  G4 = list(V = diag(1), nu = 0.002)), *#rand
> effect for LabID (CORT)*
>                     R = list(R1 = list(V = diag(2), nu = 1.002)))  *#2-way
> var-cov matrix of resid for AGGRESSION + CORT*
>
>
> m1<- MCMCglmm(Aggression.CORT.data ~ variable - 1 +
> at.level(variable, "AGGRESSION"):rescale(Sex) +
> at.level(variable, "AGGRESSION"):rescale(Age_years) +
> at.level(variable, "CORT"):rescale(Age_years),
> random = ~us(variable):IndividualID +
> us(at.level(variable,"AGGRESSION")):TestChamber+
> us(at.level(variable,"CORT")):BirthYear+
> us(at.level(variable,"CORT")):LabID,
> rcov = ~idh(variable):units,
> family = NULL, # specified already in the data
> prior = prior,
> nitt=5000000,
> burnin=50000,
> thin=500,
> verbose = FALSE,
> pr=FALSE,
> data = data)
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

The University of Edinburgh is a charitable body, registered in Scotland, with registration number SC005336. Is e buidheann carthannais a th? ann an Oilthigh Dh?n ?ideann, cl?raichte an Alba, ?ireamh cl?raidh SC005336.

From veren@@h|nze @end|ng |rom p@ych@ox@@c@uk  Mon Sep 12 19:41:56 2022
From: veren@@h|nze @end|ng |rom p@ych@ox@@c@uk (Verena Hinze)
Date: Mon, 12 Sep 2022 17:41:56 +0000
Subject: [R-sig-ME] A question about multilevel models using the lmer
 package in R
Message-ID: <LO2P265MB3610FC72C63AE97791F3989FFB449@LO2P265MB3610.GBRP265.PROD.OUTLOOK.COM>

Dear mailing list at R-sig-mixed-models,

I am a postdoctoral researcher at the University of Oxford (UK) and I am very interested in using multilevel growth analyses for my research.
I have come across a lot of very helpful tutorials on the internet, recommending the lmer package.
However, I have one question for which I didn't manage to find the answer yet, and I was wondering whether you might be able to point me in the right direction...

Specifically, I am interested in modelling three-level data (students nested within schools and within time). I am hoping to predict student outcomes by student-level and school-level predictors, and I have been using the lmer package in R to model the data.

However, in the model output, I have noticed that sometimes the variance (for the student- or school-level intercepts or slopes) increases instead of decreases, compared to the simpler model without the respective predictor. This is contrary to what we would expect from ordinary regression analyses, where we expect the variance to decrease, if we add predictors to the model that help us to explain such variance.

I was wondering what might be going on here? Have you encountered something similar before? And how could we evaluate the impact of a predictor on these student-/school-level intercepts and slopes in multi-level models instead?

Any advice would be highly appreciated.

With many thanks and kind regards,

Verena

Verena Hinze
Postdoctoral Research Fellow
Oxford Precision Psychiatry Lab
University of Oxford, Department of Psychiatry
Warneford Lane, Oxford, OX3 7JX ?
E: verena.hinze at psych.ox.ac.uk

	[[alternative HTML version deleted]]


From o||ve|r@r|@ue@b @end|ng |rom gm@||@com  Tue Sep 13 16:25:08 2022
From: o||ve|r@r|@ue@b @end|ng |rom gm@||@com (Rafael Lima Oliveira)
Date: Tue, 13 Sep 2022 11:25:08 -0300
Subject: [R-sig-ME] boundary (singular) fit and failure to converge
Message-ID: <CAKmKTvFpp1e=LHzyRDi1=Ar0pX2r+fRmHL_Ru=wwfVigq3+-2A@mail.gmail.com>

Dear mailing list at R-sig-mixed-models,



I have a dataset of environmental variables (salinity, temperature, pH,
dissolved oxygen, turbidity and depth) as predictors and as response
variables fish species richness.



Initially, I ran a Poisson-GLMM and this is my model:



poissonmodel<- glmer(Richness~ Salinity*Locality + Temperature*Locality +
pH*Locality + DO*Locality + Turbidity*Locality + Depth*Locality + (1
|Month) + (1|Locality/Site), family="poisson", data = dados)



Warning message:

In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :

  Model failed to converge with max|grad| = 0.00485978 (tol = 0.002,
component 1)



The random-effect variances being estimated as zero (or close to 0)
indicates that my model should be simplified? Should I remove the random
effects terms without substantial loss of fidelity to the data?



The Random structure that I created in my model account for my nested
design, where: (1 |Month) account for temporal variability of my dataset
collected monthly during 1 year and (1|Locality/Site) where indicated that,
spatially my data are nested, in this case "Site" nested in "Locality".



Overdispersion test to Poisson model indicated a dispersion rate of 1.632.
Once overdispersion is detected, I?m refitting my model with negative
binomial distribution (function ?glmer.nb) and variance of the random
effects also was close to 0.



*This is my negative binomial model:*



binomialmodel<- glmer.nb(Richness~ Locality + Salinity*Locality +
Temperature*Locality + pH*Locality + DO*Locality + Turbidity*Locality +
Depth*Locality + (1 |Month) + (1|Locality/Site), data = dados)



After run my model some warnings appeared:



*- boundary (singular) fit: see help('isSingular')*



and two warnings about Convergence:



*1:* In optTheta(g1, interval = interval, tol = tol, verbose = verbose,
failure to converge in 10000 evaluations

*2:* In optTheta(g1, interval = interval, tol = tol, verbose = verbose,  :
convergence code 4 from Nelder_Mead: failure to converge in 10000
evaluations



The random effects that I specified in my model are not really needed? If I
remove the random effects, can I change the GLMM approach to GLM approach?



If anybody has any tips on this please give me a hand.

Hope you can understand it.



With many thanks and kind regards,



Rafael

-- 
*Rafael Lima Oliveira*
Doutorando em Biologia Animal
Universidade Federal do Esp?rito Santo - UFES
Laborat?rio de Ecologia de peixes marinhos - CEUNES/UFES
*Contato:* (75) 98873-1548 / (27) 99526-3612
*E-mail alternativo:* rafael.l.oliveira at edu.ufes.br
*Curr?culo Lattes*:  http://lattes.cnpq.br/5215941704013482

>)))?>               >)))?>               >)))?>                   >)))?>

	[[alternative HTML version deleted]]


From veren@@h|nze @end|ng |rom p@ych@ox@@c@uk  Tue Sep 13 16:46:59 2022
From: veren@@h|nze @end|ng |rom p@ych@ox@@c@uk (Verena Hinze)
Date: Tue, 13 Sep 2022 14:46:59 +0000
Subject: [R-sig-ME] A question about multilevel models using the lmer
 package in R
In-Reply-To: <LO2P265MB3610FC72C63AE97791F3989FFB449@LO2P265MB3610.GBRP265.PROD.OUTLOOK.COM>
References: <LO2P265MB3610FC72C63AE97791F3989FFB449@LO2P265MB3610.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <LO2P265MB361066AC6537A33FD7515C4FFB479@LO2P265MB3610.GBRP265.PROD.OUTLOOK.COM>

Dear mailing list at R-sig-mixed-models,

I am very interested in using multilevel growth analyses for my research.
I have come across a lot of very helpful tutorials on the internet, recommending the lmer package.
However, I have one question for which I didn't manage to find the answer yet, and I was wondering whether you might be able to point me in the right direction...

Specifically, I am interested in modelling three-level data (students nested within schools and within time). I am hoping to predict student outcomes by student-level and school-level predictors, and I have been using the lmer package in R to model the data.

However, in the model output, I have noticed that sometimes the variance (for the student- or school-level intercepts or slopes) increases instead of decreases, compared to the simpler model without the respective predictor. This is contrary to what we would expect from ordinary regression analyses, where we expect the variance to decrease, if we add predictors to the model that help us to explain such variance.

I was wondering what might be going on here? Have you encountered something similar before? And how could we evaluate the impact of a predictor on these student-/school-level intercepts and slopes in multi-level models instead?

Any advice would be highly appreciated.

With many thanks and kind regards,

Verena

Verena Hinze
Postdoctoral Research Fellow
Oxford Precision Psychiatry Lab
University of Oxford, Department of Psychiatry
Warneford Lane, Oxford, OX3 7JX ?
E: verena.hinze at psych.ox.ac.uk

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Tue Sep 13 16:56:35 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 13 Sep 2022 10:56:35 -0400
Subject: [R-sig-ME] A question about multilevel models using the lmer
 package in R
In-Reply-To: <LO2P265MB361066AC6537A33FD7515C4FFB479@LO2P265MB3610.GBRP265.PROD.OUTLOOK.COM>
References: <LO2P265MB3610FC72C63AE97791F3989FFB449@LO2P265MB3610.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB361066AC6537A33FD7515C4FFB479@LO2P265MB3610.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <f50925a0-f635-5444-3983-81ce4ef60b4c@gmail.com>

   (This came through twice, for what it's worth.)

   I can't immediately explain the phenomenon you observed (variance at 
an upper level increasing when a covariate is added), but I'm not 
shocked -- when there are multiple levels of variation, variation can 
shift among them in surprising ways.

   Can you clarify/expand on what you mean by "[evaluating] the impact 
of a predictor on student/school-level intercepts"?

On 2022-09-13 10:46 a.m., Verena Hinze wrote:
> Dear mailing list at R-sig-mixed-models,
> 
> I am very interested in using multilevel growth analyses for my research.
> I have come across a lot of very helpful tutorials on the internet, recommending the lmer package.
> However, I have one question for which I didn't manage to find the answer yet, and I was wondering whether you might be able to point me in the right direction...
> 
> Specifically, I am interested in modelling three-level data (students nested within schools and within time). I am hoping to predict student outcomes by student-level and school-level predictors, and I have been using the lmer package in R to model the data.
> 
> However, in the model output, I have noticed that sometimes the variance (for the student- or school-level intercepts or slopes) increases instead of decreases, compared to the simpler model without the respective predictor. This is contrary to what we would expect from ordinary regression analyses, where we expect the variance to decrease, if we add predictors to the model that help us to explain such variance.
> 
> I was wondering what might be going on here? Have you encountered something similar before? And how could we evaluate the impact of a predictor on these student-/school-level intercepts and slopes in multi-level models instead?
> 
> Any advice would be highly appreciated.
> 
> With many thanks and kind regards,
> 
> Verena
> 
> Verena Hinze
> Postdoctoral Research Fellow
> Oxford Precision Psychiatry Lab
> University of Oxford, Department of Psychiatry
> Warneford Lane, Oxford, OX3 7JX ?
> E: verena.hinze at psych.ox.ac.uk
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics
 > E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From bbo|ker @end|ng |rom gm@||@com  Tue Sep 13 17:01:43 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 13 Sep 2022 11:01:43 -0400
Subject: [R-sig-ME] boundary (singular) fit and failure to converge
In-Reply-To: <CAKmKTvFpp1e=LHzyRDi1=Ar0pX2r+fRmHL_Ru=wwfVigq3+-2A@mail.gmail.com>
References: <CAKmKTvFpp1e=LHzyRDi1=Ar0pX2r+fRmHL_Ru=wwfVigq3+-2A@mail.gmail.com>
Message-ID: <e3ddbeb6-6272-e086-8eda-89c61963c0ee@gmail.com>



On 2022-09-13 10:25 a.m., Rafael Lima Oliveira wrote:
> Dear mailing list at R-sig-mixed-models,
> 
> 
> 
> I have a dataset of environmental variables (salinity, temperature, pH,
> dissolved oxygen, turbidity and depth) as predictors and as response
> variables fish species richness.
> 
> 
> 
> Initially, I ran a Poisson-GLMM and this is my model:
> 
> 
> 
> poissonmodel<- glmer(Richness~ Salinity*Locality + Temperature*Locality +
> pH*Locality + DO*Locality + Turbidity*Locality + Depth*Locality + (1
> |Month) + (1|Locality/Site), family="poisson", data = dados)
> 
> 
> 
> Warning message:
> 
> In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
> 
>    Model failed to converge with max|grad| = 0.00485978 (tol = 0.002,
> component 1)
> 
> 
> 
> The random-effect variances being estimated as zero (or close to 0)
> indicates that my model should be simplified? Should I remove the random
> effects terms without substantial loss of fidelity to the data?

   If you remove a term whose variance is estimated as zero, you're not 
losing *any* fidelity to the data ... in general, the recommendation is 
that terms that are fitted as singular probably indicate an 
overfitted/overly complex model (see e.g. Barr et al 2013 "Keep it 
maximal", Matuschek et al 2017 "Balancing Type I error" -- both agree 
that singular terms can be removed)

> 
> 
> 
> The Random structure that I created in my model account for my nested
> design, where: (1 |Month) account for temporal variability of my dataset
> collected monthly during 1 year and (1|Locality/Site) where indicated that,
> spatially my data are nested, in this case "Site" nested in "Locality".
> 
> 
> 
> Overdispersion test to Poisson model indicated a dispersion rate of 1.632.
> Once overdispersion is detected, I?m refitting my model with negative
> binomial distribution (function ?glmer.nb) and variance of the random
> effects also was close to 0.
> 
> 
> 
> *This is my negative binomial model:*
> 
> 
> 
> binomialmodel<- glmer.nb(Richness~ Locality + Salinity*Locality +
> Temperature*Locality + pH*Locality + DO*Locality + Turbidity*Locality +
> Depth*Locality + (1 |Month) + (1|Locality/Site), data = dados)
> 
> 
> 
> After run my model some warnings appeared:
> 
> 
> 
> *- boundary (singular) fit: see help('isSingular')*
> 
> 
> 
> and two warnings about Convergence:
> 
> 
> 
> *1:* In optTheta(g1, interval = interval, tol = tol, verbose = verbose,
> failure to converge in 10000 evaluations
> 
> *2:* In optTheta(g1, interval = interval, tol = tol, verbose = verbose,  :
> convergence code 4 from Nelder_Mead: failure to converge in 10000
> evaluations
> 
> 

    You should definitely increase the number of function evaluations. 
(Not sure why this is using Nelder-Mead, which is usually *not* the most 
robust of the available options ... ?)

   You could also try glmmTMB, which is a bit faster/more robust when 
fitting negative binomial models.



> 
> The random effects that I specified in my model are not really needed? If I
> remove the random effects, can I change the GLMM approach to GLM approach?

   If *all* of your REs have variance zero then yes, you probably won't 
lose anything by dropping back from GLMMs to GLMs.

> 
> 
> 
> If anybody has any tips on this please give me a hand.
> 
> Hope you can understand it.
> 
> 
> 
> With many thanks and kind regards,
> 
> 
> 
> Rafael
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics
 > E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From me @end|ng |rom ph||||p@|d@y@com  Wed Sep 14 10:30:37 2022
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Wed, 14 Sep 2022 10:30:37 +0200
Subject: [R-sig-ME] A question about multilevel models using the lmer
 package in R
In-Reply-To: <f50925a0-f635-5444-3983-81ce4ef60b4c@gmail.com>
References: <LO2P265MB3610FC72C63AE97791F3989FFB449@LO2P265MB3610.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB361066AC6537A33FD7515C4FFB479@LO2P265MB3610.GBRP265.PROD.OUTLOOK.COM>
 <f50925a0-f635-5444-3983-81ce4ef60b4c@gmail.com>
Message-ID: <090f5721-94dc-c7a2-5f6a-2ec02d075e55@phillipalday.com>

This sounds a bit like Hedge's Reliability Paradox:

Hedge, C., Powell, G. & Sumner, P. The reliability paradox: Why robust
cognitive tasks do not produce reliable individual differences. /Behav
Res / *50*, 1166?1186 (2018). https://doi.org/10.3758/s13428-017-0935-1

There is also an older result due to Spearman about bias of variance
estimates under certain conditions, though I can't recall the details
off the top of my head.

(sent a second time without PGP signing -- would it be possible to allow
PGP to the allowed MIME types?)

On 9/13/22 16:56, Ben Bolker wrote:
> ? (This came through twice, for what it's worth.)
>
> ? I can't immediately explain the phenomenon you observed (variance at
> an upper level increasing when a covariate is added), but I'm not
> shocked -- when there are multiple levels of variation, variation can
> shift among them in surprising ways.
>
> ? Can you clarify/expand on what you mean by "[evaluating] the impact
> of a predictor on student/school-level intercepts"?
>
> On 2022-09-13 10:46 a.m., Verena Hinze wrote:
>> Dear mailing list at R-sig-mixed-models,
>>
>> I am very interested in using multilevel growth analyses for my
>> research.
>> I have come across a lot of very helpful tutorials on the internet,
>> recommending the lmer package.
>> However, I have one question for which I didn't manage to find the
>> answer yet, and I was wondering whether you might be able to point me
>> in the right direction...
>>
>> Specifically, I am interested in modelling three-level data (students
>> nested within schools and within time). I am hoping to predict
>> student outcomes by student-level and school-level predictors, and I
>> have been using the lmer package in R to model the data.
>>
>> However, in the model output, I have noticed that sometimes the
>> variance (for the student- or school-level intercepts or slopes)
>> increases instead of decreases, compared to the simpler model without
>> the respective predictor. This is contrary to what we would expect
>> from ordinary regression analyses, where we expect the variance to
>> decrease, if we add predictors to the model that help us to explain
>> such variance.
>>
>> I was wondering what might be going on here? Have you encountered
>> something similar before? And how could we evaluate the impact of a
>> predictor on these student-/school-level intercepts and slopes in
>> multi-level models instead?
>>
>> Any advice would be highly appreciated.
>>
>> With many thanks and kind regards,
>>
>> Verena
>>
>> Verena Hinze
>> Postdoctoral Research Fellow
>> Oxford Precision Psychiatry Lab
>> University of Oxford, Department of Psychiatry
>> Warneford Lane, Oxford, OX3 7JX ?
>> E: verena.hinze at psych.ox.ac.uk
>>
>> ????[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
	[[alternative HTML version deleted]]


From j@un20 @end|ng |rom @|b@ny@edu  Mon Sep 19 20:53:53 2022
From: j@un20 @end|ng |rom @|b@ny@edu (Sun, John)
Date: Mon, 19 Sep 2022 18:53:53 +0000
Subject: [R-sig-ME] Is it possible to use newey-west (heteroscedasticity and
 autocorrelation consistent) standard errors using a generalized linear
 mixed-model or generalized estimating equation?
Message-ID: <BL0PR04MB4563318A1040C288C6FCF690B94D9@BL0PR04MB4563.namprd04.prod.outlook.com>

Dear All,

I am writing to ask whether it is possible to obtain robust standard error corrections when using a generalized linear mixed model or generalized estimating equation via the Econometrics Newey-West method.

I ask this because I think it is safer to assume that the generalized linear model in glmer or glmmTMB does not perform well when the errors have autocorrelation and heteroscedasticity and/or the random-effects have a non diagonal correlation structure.

I am also concerned with generalized estimating equations in that the working-correlation which one uses to obtain standard errors for regression coefficients is a guess based on what I've read and there's no proof according to what I know that generalized estimating equation is robust to model errors having autocorrelation.

Best regards,
John


	[[alternative HTML version deleted]]


From j@un20 @end|ng |rom @|b@ny@edu  Sat Sep 24 16:22:12 2022
From: j@un20 @end|ng |rom @|b@ny@edu (Sun, John)
Date: Sat, 24 Sep 2022 14:22:12 +0000
Subject: [R-sig-ME] Condition number of Hessian in glmmTMB
Message-ID: <BL0PR04MB456320091BFB3064A7ACCC64B9509@BL0PR04MB4563.namprd04.prod.outlook.com>

Dear All,

I am writing to ask how to have glmmTMB package give me the condition number of the Hessian so I can diagnose whether I am losing to many significant figures when using a more complicated model.

Best regards,
John 


From j@un20 @end|ng |rom @|b@ny@edu  Sat Sep 24 18:25:39 2022
From: j@un20 @end|ng |rom @|b@ny@edu (Sun, John)
Date: Sat, 24 Sep 2022 16:25:39 +0000
Subject: [R-sig-ME] Find Hessian in MixCat and glmmTMB packages
Message-ID: <BL0PR04MB4563778B131E342C305020ACB9509@BL0PR04MB4563.namprd04.prod.outlook.com>

Dear All,

I am writing to ask how to find the hessian from these fitted objects to calculate the condition number of the hessian to diagnose loss of precision.
Please let me know if you know any information.

library(mixcat)
data(schizo)
attach(schizo)
a<-npmlt(y~trt*sqrt(wk),formula.npo=~trt,random=~1+trt,id=id,k=2,EB=FALSE)

library(glmmTMB)
(m1 <- glmmTMB(count ~ mined + (1|site),
  zi=~mined,
  family=poisson, data=Salamanders))

I cannot find how to find the hessian from these fitted objects.

Best regards,
John 


From bbo|ker @end|ng |rom gm@||@com  Sun Sep 25 00:58:41 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sat, 24 Sep 2022 18:58:41 -0400
Subject: [R-sig-ME] Find Hessian in MixCat and glmmTMB packages
In-Reply-To: <BL0PR04MB4563778B131E342C305020ACB9509@BL0PR04MB4563.namprd04.prod.outlook.com>
References: <BL0PR04MB4563778B131E342C305020ACB9509@BL0PR04MB4563.namprd04.prod.outlook.com>
Message-ID: <62fc69c1-698f-2b94-aea4-4b5ec2e10a6f@gmail.com>

 From ?npmlt,

## CVmat: the inverse of the observed information matrix of the model.
rcond(solve(a$CVmat))

   (this is the inverse condition number)


  For glmmTMB: the Hessian isn't stored in the object, here is one way 
to compute it:

hessian.glmmTMB <- function(fit) {
     obj <- fit$obj
     ee <- obj$env
     pp <- ee$last.par.best
     if (!is.null(r <- ee$random)) {
         pp <- pp[-r]
     }
     h <- numDeriv::jacobian(obj$gr, pp)
     return(h)
}
rcond(hessian.glmmTMB(m1))


On 2022-09-24 12:25 p.m., Sun, John wrote:
> Dear All,
> 
> I am writing to ask how to find the hessian from these fitted objects to calculate the condition number of the hessian to diagnose loss of precision.
> Please let me know if you know any information.
> 
> library(mixcat)
> data(schizo)
> attach(schizo)
> a<-npmlt(y~trt*sqrt(wk),formula.npo=~trt,random=~1+trt,id=id,k=2,EB=FALSE)
> 
> library(glmmTMB)
> (m1 <- glmmTMB(count ~ mined + (1|site),
>    zi=~mined,
>    family=poisson, data=Salamanders))
> 
> I cannot find how to find the hessian from these fitted objects.
> 
> Best regards,
> John
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics
 > E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From j@un20 @end|ng |rom @|b@ny@edu  Sun Sep 25 17:11:06 2022
From: j@un20 @end|ng |rom @|b@ny@edu (Sun, John)
Date: Sun, 25 Sep 2022 15:11:06 +0000
Subject: [R-sig-ME] What does the "effects" vector from geepack fitted
 object mean?
Message-ID: <BL0PR04MB45631CDD8FD027FCA9650B7EB9539@BL0PR04MB4563.namprd04.prod.outlook.com>

Dear All,

I am writing to ask what the " gee1[["effects"]]" vector calculates in the geepack package. 

library(geepack)
data(dietox)
dietox$Cu     <- as.factor(dietox$Cu)
mf <- formula(Weight ~ Cu * (Time + I(Time^2) + I(Time^3)))
gee1 <- geeglm(mf, data=dietox, id=Pig, family=poisson("identity"), corstr="ar1")
gee1[["effects"]]# a vector of the regression coefficients plus ~848 estimated "effects" that are not residuals. I have no idea what they mean.
View(gee1)

Best regards,
John 


