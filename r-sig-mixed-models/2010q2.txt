From adik at ilovebacon.org  Thu Apr  1 01:38:04 2010
From: adik at ilovebacon.org (Adam D. I. Kramer)
Date: Wed, 31 Mar 2010 16:38:04 -0700 (PDT)
Subject: [R-sig-ME] Increasing iteration limit / lmer bug
Message-ID: <Pine.LNX.4.64.1003311326250.6926@ilovebacon.org>

Dear colleagues,

 	I am attempting to fit a model in this manner:

l3 <- glmer(mug ~ condition*time +
(time|cafe),family=binomial,data=data)

...the model fails to fit, however, noting:

In mer_finalize(ans) : iteration limit reached without convergence (9)

...so, of course, I read the man page for glmer and added
control=list(maxIter=3000). However, the program ran for the same amount of
time (about 10 minutes) and produced the same error (and, incidentally, the
same output).

So, I believe there to be a bug in glmer such that maxIter is not
functioning.

I then upped maxFN, too, (also to 3000) in case that was the problem, but
found no meaningful difference in the model produced or the time taken to
fit the model.

Could somebody recommend a workaround? I would like to fit this model.

(running R 2.10.1, lme4 v. 0.999375-32)

Also, in case it matters, 'time' here is a categorical variable
reperesenting several within-subjects timepoints--there are some other
(unanswered) posts to this list in which people appear to have fairly
complex within-subjects effects. Perhaps the issue is that the defaults
which are in place are insufficiently high for moderately complex
within-subjects models?

Cordially,
Adam D. I. Kramer



From adik at ilovebacon.org  Thu Apr  1 02:14:59 2010
From: adik at ilovebacon.org (Adam D. I. Kramer)
Date: Wed, 31 Mar 2010 17:14:59 -0700 (PDT)
Subject: [R-sig-ME] Increasing iteration limit / lmer bug
In-Reply-To: <Pine.LNX.4.64.1003311326250.6926@ilovebacon.org>
References: <Pine.LNX.4.64.1003311326250.6926@ilovebacon.org>
Message-ID: <Pine.LNX.4.64.1003311712080.6926@ilovebacon.org>

With apologies, after a lot of grepping around and reading pages on the
internet, yes, as you expected, my model is to blame.

That said, I think that it is quite appropriate for commands listed in the
?help page to actually work or do what they say--in the below case, it is
clear that maxIter is being ignored.

If it is the case that a "valid" or "good" or "non-stupid" model will easily
be fit with maxIter=300 and maxFN=900, then there is no reason to allow
users to think they have changed this value when they have not.

Cordially,
Adam

On Wed, 31 Mar 2010, Adam D. I. Kramer wrote:

> Dear colleagues,
>
> 	I am attempting to fit a model in this manner:
>
> l3 <- glmer(mug ~ condition*time +
> (time|cafe),family=binomial,data=data)
>
> ...the model fails to fit, however, noting:
>
> In mer_finalize(ans) : iteration limit reached without convergence (9)
>
> ...so, of course, I read the man page for glmer and added
> control=list(maxIter=3000). However, the program ran for the same amount of
> time (about 10 minutes) and produced the same error (and, incidentally, the
> same output).
>
> So, I believe there to be a bug in glmer such that maxIter is not
> functioning.
>
> I then upped maxFN, too, (also to 3000) in case that was the problem, but
> found no meaningful difference in the model produced or the time taken to
> fit the model.
>
> Could somebody recommend a workaround? I would like to fit this model.
>
> (running R 2.10.1, lme4 v. 0.999375-32)
>
> Also, in case it matters, 'time' here is a categorical variable
> reperesenting several within-subjects timepoints--there are some other
> (unanswered) posts to this list in which people appear to have fairly
> complex within-subjects effects. Perhaps the issue is that the defaults
> which are in place are insufficiently high for moderately complex
> within-subjects models?
>
> Cordially,
> Adam D. I. Kramer
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From lborger at uoguelph.ca  Thu Apr  1 04:32:30 2010
From: lborger at uoguelph.ca (Luca Borger)
Date: Wed, 31 Mar 2010 22:32:30 -0400
Subject: [R-sig-ME] Increasing iteration limit / lmer bug
References: <Pine.LNX.4.64.1003311326250.6926@ilovebacon.org>
	<Pine.LNX.4.64.1003311712080.6926@ilovebacon.org>
Message-ID: <2F3CE3947B8D41C2B67BF6A531936CDB@lborger>

Hello,

this same issue has been reported quite recently (29 March 2010), Ben Bolker 
found that there is indeed a bug and provided also a fix for it. Here is the 
link to the mail archives:

https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q1/003547.html


Cheers,

Luca


----- Original Message ----- 
From: "Adam D. I. Kramer" <adik at ilovebacon.org>
To: <r-sig-mixed-models at r-project.org>
Sent: Wednesday, March 31, 2010 8:14 PM
Subject: Re: [R-sig-ME] Increasing iteration limit / lmer bug


> With apologies, after a lot of grepping around and reading pages on the
> internet, yes, as you expected, my model is to blame.
>
> That said, I think that it is quite appropriate for commands listed in the
> ?help page to actually work or do what they say--in the below case, it is
> clear that maxIter is being ignored.
>
> If it is the case that a "valid" or "good" or "non-stupid" model will 
> easily
> be fit with maxIter=300 and maxFN=900, then there is no reason to allow
> users to think they have changed this value when they have not.
>
> Cordially,
> Adam
>
> On Wed, 31 Mar 2010, Adam D. I. Kramer wrote:
>
>> Dear colleagues,
>>
>> I am attempting to fit a model in this manner:
>>
>> l3 <- glmer(mug ~ condition*time +
>> (time|cafe),family=binomial,data=data)
>>
>> ...the model fails to fit, however, noting:
>>
>> In mer_finalize(ans) : iteration limit reached without convergence (9)
>>
>> ...so, of course, I read the man page for glmer and added
>> control=list(maxIter=3000). However, the program ran for the same amount 
>> of
>> time (about 10 minutes) and produced the same error (and, incidentally, 
>> the
>> same output).
>>
>> So, I believe there to be a bug in glmer such that maxIter is not
>> functioning.
>>
>> I then upped maxFN, too, (also to 3000) in case that was the problem, but
>> found no meaningful difference in the model produced or the time taken to
>> fit the model.
>>
>> Could somebody recommend a workaround? I would like to fit this model.
>>
>> (running R 2.10.1, lme4 v. 0.999375-32)
>>
>> Also, in case it matters, 'time' here is a categorical variable
>> reperesenting several within-subjects timepoints--there are some other
>> (unanswered) posts to this list in which people appear to have fairly
>> complex within-subjects effects. Perhaps the issue is that the defaults
>> which are in place are insufficiently high for moderately complex
>> within-subjects models?
>>
>> Cordially,
>> Adam D. I. Kramer
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bolker at ufl.edu  Thu Apr  1 05:15:49 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Wed, 31 Mar 2010 23:15:49 -0400
Subject: [R-sig-ME] Increasing iteration limit / lmer bug
In-Reply-To: <2F3CE3947B8D41C2B67BF6A531936CDB@lborger>
References: <Pine.LNX.4.64.1003311326250.6926@ilovebacon.org>	<Pine.LNX.4.64.1003311712080.6926@ilovebacon.org>
	<2F3CE3947B8D41C2B67BF6A531936CDB@lborger>
Message-ID: <4BB40FE5.1060901@ufl.edu>

  Furthermore, I think the patch has already been incorporated in the
development (r-forge) version.

 Try

install.packages("lme4",repos="http://r-forge.r-project.org")

and see if that makes a difference.

Luca Borger wrote:
> Hello,
> 
> this same issue has been reported quite recently (29 March 2010), Ben Bolker 
> found that there is indeed a bug and provided also a fix for it. Here is the 
> link to the mail archives:
> 
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q1/003547.html
> 
> 
> Cheers,
> 
> Luca
> 
> 
> ----- Original Message ----- 
> From: "Adam D. I. Kramer" <adik at ilovebacon.org>
> To: <r-sig-mixed-models at r-project.org>
> Sent: Wednesday, March 31, 2010 8:14 PM
> Subject: Re: [R-sig-ME] Increasing iteration limit / lmer bug
> 
> 
>> With apologies, after a lot of grepping around and reading pages on the
>> internet, yes, as you expected, my model is to blame.
>>
>> That said, I think that it is quite appropriate for commands listed in the
>> ?help page to actually work or do what they say--in the below case, it is
>> clear that maxIter is being ignored.
>>
>> If it is the case that a "valid" or "good" or "non-stupid" model will 
>> easily
>> be fit with maxIter=300 and maxFN=900, then there is no reason to allow
>> users to think they have changed this value when they have not.
>>
>> Cordially,
>> Adam
>>
>> On Wed, 31 Mar 2010, Adam D. I. Kramer wrote:
>>
>>> Dear colleagues,
>>>
>>> I am attempting to fit a model in this manner:
>>>
>>> l3 <- glmer(mug ~ condition*time +
>>> (time|cafe),family=binomial,data=data)
>>>
>>> ...the model fails to fit, however, noting:
>>>
>>> In mer_finalize(ans) : iteration limit reached without convergence (9)
>>>
>>> ...so, of course, I read the man page for glmer and added
>>> control=list(maxIter=3000). However, the program ran for the same amount 
>>> of
>>> time (about 10 minutes) and produced the same error (and, incidentally, 
>>> the
>>> same output).
>>>
>>> So, I believe there to be a bug in glmer such that maxIter is not
>>> functioning.
>>>
>>> I then upped maxFN, too, (also to 3000) in case that was the problem, but
>>> found no meaningful difference in the model produced or the time taken to
>>> fit the model.
>>>
>>> Could somebody recommend a workaround? I would like to fit this model.
>>>
>>> (running R 2.10.1, lme4 v. 0.999375-32)
>>>
>>> Also, in case it matters, 'time' here is a categorical variable
>>> reperesenting several within-subjects timepoints--there are some other
>>> (unanswered) posts to this list in which people appear to have fairly
>>> complex within-subjects effects. Perhaps the issue is that the defaults
>>> which are in place are insufficiently high for moderately complex
>>> within-subjects models?
>>>
>>> Cordially,
>>> Adam D. I. Kramer
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From charpent at bacbuc.dyndns.org  Thu Apr  1 00:04:11 2010
From: charpent at bacbuc.dyndns.org (Emmanuel Charpentier)
Date: Thu, 01 Apr 2010 00:04:11 +0200
Subject: [R-sig-ME] missing data + explanatory variables
In-Reply-To: <t2rc8e8cd3d1003300157zeac12383u39afc1b1c5013366@mail.gmail.com>
References: <c8e8cd3d1003240409r27cfb4c0w897cae92d391942f@mail.gmail.com>
	<Pine.LNX.4.64.1003250727070.15751@orpheus.qimr.edu.au>
	<6A2368B1-6ED7-48EF-AECC-712AA6865D26@gmail.com>
	<Pine.LNX.4.64.1003261003520.22301@orpheus.qimr.edu.au>
	<w2uc8e8cd3d1003261015j3e52c20dmde89ec65ac2c1c4c@mail.gmail.com>
	<AF1F2446D9EF402AA3D10A0559F9D22A@lborger>
	<2FAAA29A-DA86-4F5E-86A4-5F87729ED63C@gmail.com>
	<t2rc8e8cd3d1003300157zeac12383u39afc1b1c5013366@mail.gmail.com>
Message-ID: <1270073051.3449.158.camel@PortableToshiba>

Dear list, dear Christophe,

Le mardi 30 mars 2010 ? 10:57 +0200, christophe dutang a ?crit :
> Dear list,
> 
> Emmanuel, thank you for your long answer.
> 
> See below,

Fair warning : this is another long response, probably unuseful and
tedious to most list's members. But I remember researching this kind of
questions, and tried to answer the way I would have liked to be answered
back then...

Christophe, if you have further questions, please fee free to mail me at
ChaRpEnT [at] BAcbUc <dot> DYNdns <dot> orG (all lowercase of course :
the brokenCamelBackCapItalizaTion being a feeble attempt at foiling
spammers' spiders...).

I take the liberty to [ Snip... ] what has already been said...

> Just to be sure to understand what you are talking about. Repeated-measures
> ANOVA are modelled by
> 
> Y_it = mu + alpha_i + e_it ?

That is correct for a one-way, UNrepeated-mesures ANOVA. But it is much
better to use vector/matrix notation and save the indices to denote
various variables.

Furthermore, the distinction between class variable (qualitative data)
and quantitative variables is somewhat artificial : class variables with
n levels are (behind the scene) replaced with n-1 semi-quantitative
variables (0 or 1), the exact transformation depending of a choice on
contrasts.

Please see MASS 4 for further (much needed) explanations on this
subject.

> > Mixed-model ANOVA : manually intractable, accepts unbalanced datasets but
> > does not allow for partial observations, therefore forces you to ignore
> > incomplete *observations*. Modern solution, but does not accounts for
> > possible bias due to *missing* *data*.
> >
> Y_it = Z_it . alpha_i + X_it . beta + e_it

That would be one way to denote a mixed model, the point being that both
e_it and Z_it are considered source of randomness (i. e. the "Z" are
*not* directly reproductible, their values are not of direct interest,
but they are interesting in partially explaining away part of the
variability of Y (=Z.alpha+e) and allowing to reduce the estimation of
the residual variance to e, thus  allowing for more powerful comparisons
on X.

You'd better read the lmer vignettes and, even better, both Pinhero &
Bates (2000) and the draft chapters of Bates (201x) that Douglas Bates
offered for comment a short while ago... A full explanation of this
subject is *long* and implies difficult concepts, both probabilistic and
geometrical (linear algebra being of a big help for bridging the
two...).

Furthermore, I'm not a tenured statistics professor (I'm a dental
surgeon :-) among other things...).

> Is that correct? by the way, why we call them ANOVA models? (in my
> scolarship, anova was introduced for anova table.)

ANOVA (ANalysis Of VAriance), ANCOVA (ANalysis Of COVariance) and other
*algorithms'* names are a bit of a leftover of manual computation times,
where very different algorithms were necessary to treat each special
case of decomposition of the total variance in "factors" and "residual"
parts. See for example Winer (1957, IIRC) if you want a nice example of
what it meant in those days to (literally) analyze variance in various
models, and have pleasant nightmares ...

Nowadays, modern software allows you to think in the overall framework
(the linear model) and does the button-sorting for you. lm() and lmer()
(and, by the way, lme()) do this kind of sorting, the second allowing to
decompose the "natural" variability according to more than one source of
variability.

You should really have at least  peek at MASS4 and the references it
points to for better explanations.

On the other hand, the "anova table" concept is, indeed, a byproduct of
the anova, but is also a way to summarize the result of a linear model
analysis, in breaking the total variability of Y between "interesting"
sources (the factor(s)) and the "residual" variability (resulting of
"natural variability").

[ Digression : why this "anova table" allows you to "test" your factor
effects, and why this table is no longer deemed the necessary endpoint
of a linear model analysis ]

This breakup allows you to compare the between-factor-levels and the
"residual" variability : the formal ANOVA test (Fisher's test, alias
F-test) I was taught compares this residual variability to another
estimation of the natural variability, indirectly derived from the
differences between group means.  If the average difference between
group means is zero (that is you null hypothesis), the ratio of these
two quantities will "naturally" fluctuate about 1 ((following a F
density) ; if this latter estimate is much greater than the residual
variability (i. e. the ratio being "significantly" greater than 1), you
can reject the null hypothesis.

It can be shown that this test is related to what is known as "Wald"
tests (grossly : the ratio of an effect estimate to the "natural"
variability estimate under the null hypothesis of no effect, leading to
rejection of the null hypothesis if the ratio is "too different from
0"), whose easiest, best-known simple case is the Student's t test.

Other test families do exist, based on the assessment of the shape of
the likelihood of the sample as expressed by you model ; the score test
is based on the size (the norm) of likelihood's firs derivative at the
point representing the null hypothesis ; the likelihood ratio test
(which is "optimal" in various cases, according to the dreaded
Neyman-Pearson lemma) is based on the ratio of the likelihood of the
sample computed according to two *nested* models, the second (simpler)
one representing the "null hypothesis" imposed on the first.

This idea of model comparison", is much more general than the
special-case "analysis of variance" idea, and can be applied in very
many situations ; it is therefore  much more important thing to
understand than ANOVA technicalities (but please understand that these
"technicalities" are nothing to sneer at, and that Douglas
Bates' (enormous) work is key to be able those "simple" ideas to
complicated situations)

Reference : any good and recent mathematical statistics handbook. My
personal references (Kendall & Stuart 1957, Cox & Hinckley 1974) are
neither fun nor very pedagogic, and suppose a non-negligible deal of
probability theory. Williams (2000 ?) is far from being a bad book, but
I didn't really peruse it and will refrain from expressing a "hard"
opinion.

See also MASS4 and Bill Venables' "Exegeses on the linear
model" (available on Brian Ripley's Web page) on what model comparisons
are legitimate (= meaningful).

I will refrain to comment further on the issue of the "necessity" of
hypothesis testing, which is a horse of another color (and very
different feathers :-)...

[ End of digression. ]

[ and another Snip ... ]

> Do you have any good reference on this topic?

That's a hard one ! So far, I've seen various introductions to the
subject, and most of them presuppose a reader already familiar with
"classical" procedures (and ogten working knowledge of linear algebra
and not-so-trivial calculus).

Williams (2000 ?) is  general introduction that gives a good deal of
explanation to Bayesian thinking, but is terse on practical issues.
Gelman & al (2004) is a very good textbook on Bayesian data analysis,
supposes some knowledge of probability theory, works up long non-trivial
examples using mostly direct R programing (and gives very interesting,
sometimes downright intriguing exercises), but skims on practical tools,
relying mostly on R. Albert (2007) is  much shorter book, quite
readable, introduces important concepts very well but does not delve in
deep theoretical development. As Gelman & al. (2004), it relies almost
exclusively on direct R computation.

On the other hand, Gelman & Hill (2007 ?) is  *very* good *modern* book
on regression, which introduces fixed-effects linear models, then
mixed-effects models, then Bayesian modeling for regression, using both
R and BUGS. I *strongly* recommend reading this book if you have
anything to do with regression, but be prepaed to dive in Gelman & al
(2004) if you want further explanation on Bayesian thinking. Be also
prepared to read Frank Harrell's (2002) book, not only as an antidote,
but also to grasp important concepts in regression modeling.

But none of these books will give you what Spiegelhalter's WinBUGS
examples volumes (now 3 of them, plus 2 for the old command-line BUGS
examples) may easily convey : the extraordinary flexibility of BUGS as a
modeling language. These examples are a sufficient reason to download
WinBUGS and start playing with it. I do not appreciate much the
graphical interface, but the facility to interact with a model and
progressively enhance it has few equivalent (R + Emacs + ESS + rjags +
JAGS, perhaps ... and you still need Spiegelhalter's examples !).


The report Spiegelhalter & his colleagues prepared in 2002 for the
British MRC should also be required reading if your field has anything
to do with biostatistics : it provides you a very good view of *wht*
Bayesian analysis can do in this field (while being quite terse on *how*
to do it...). ISTR that this report was later (2004 ?) expanded into a
book.

>                                                a good implementation of this
> approach is the MCMCpack?

No. MCMCpack does indeed model the dependent variable and gives you
Bayesian estimates of your parameters (and does this efficiently), and
allows for direct (= Bayes factor) model comparison, but do not model
the covariates, which is the key point if you have to impute them. As
far as I can tell, it also eliminates data points with missing dependent
variables (for lm()'s compatibility's sake ?). Last time I looked, it
did not have general purpose multilevel (=mixed-model) functions.

However, MCMCpack implements interesting models for the social sciences,
which might be useful if they are also relevant to your field.

As far as I know, the only multiple imputation package that uses
Bayesian methods is mi (it's probably not by chance that this package is
from Gelman and his colleagues...). It is tempting ... But (again !) I
did not (yet) explore it sufficiently to give an *enlightened* opinion.

Trying to "roll your own" imputation and analysis model(s) in BUGS would
probably difficult (and *quite* time consuming), but it *certainly*
would be educational... and fun !

> > HTH,
> >
> > Emmanuel Charpentier
> >
> > PS : since "manual" algorithms are out of practical use since the end of
> > the 70s and the inception of what was then called "personal computers", I'm
> > a bit surprised that a paper published in 2004 still invokes that issue...
> > Is your domain special (or especially conservative) ?
> >
> I'm working in actuarial science. But I had just googled the paper and have
> no particular link to that domain.

Aha ! Then you might try to buttonhole Vincent Goulet, which is
(associate ?) professor of Actuarial Sciences in Canada. He is most
certainly better than me at practical issues (he is part of the gang
that maintains the 64-bit Debian and Ubuntu ports of R-CRAN, which is
quite a feat....), and indisputably know infinitely more than I do about
actuarial statistics.

HTH,

					Emmanuel Charpentier



From tahirajamil at yahoo.com  Thu Apr  1 16:41:27 2010
From: tahirajamil at yahoo.com (Tahira Jamil)
Date: Thu, 1 Apr 2010 07:41:27 -0700 (PDT)
Subject: [R-sig-ME] Standard errors for random effects
Message-ID: <327708.4826.qm@web113501.mail.gq1.yahoo.com>

Hi
I am wondering how can we extract standard errors of random effects. Is it possible or not in lme4. 
Best regards

Tahira Jamil
PhD student 
Biometris Wageningen



From lborger at uoguelph.ca  Thu Apr  1 16:55:01 2010
From: lborger at uoguelph.ca (Luca Borger)
Date: Thu, 1 Apr 2010 10:55:01 -0400
Subject: [R-sig-ME] Standard errors for random effects
References: <327708.4826.qm@web113501.mail.gq1.yahoo.com>
Message-ID: <291F5C0A789C447AA9099EF9572E5035@lborger>

Hello,

no, as the sampling distribution of random effects/variance estimates is 
usually strongly asymmetric and thus better alternatives should be used. See 
the mail archives for posts by Douglas Bates or the drafts of his 
forthcoming book or the wiki for mixed models:

http://glmm.wikidot.com/faq
Standard errors of variance estimates
  a.. Paraphrasing Doug Bates: the sampling distribution of variance 
estimates is in general strongly asymmetric: the standard error may be a 
poor characterization of the uncertainty.
  b.. Alternatives?
    a.. The development version of lme4, lme4a, allows for computing 
likelihood profiles of variances.
    b.. An MCMC-based approach (MCMCglmm, etc.) will provide posterior 
distributions of the variance parameters: quantiles or credible intervals 
(HPDinterval() in coda()) will characterize the uncertainty.



HTH,

Cheers,

Luca


----- Original Message ----- 
From: "Tahira Jamil" <tahirajamil at yahoo.com>
To: <r-sig-mixed-models at r-project.org>
Sent: Thursday, April 01, 2010 10:41 AM
Subject: [R-sig-ME] Standard errors for random effects


> Hi
> I am wondering how can we extract standard errors of random effects. Is it 
> possible or not in lme4.
> Best regards
>
> Tahira Jamil
> PhD student
> Biometris Wageningen
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Thu Apr  1 17:03:33 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 1 Apr 2010 09:03:33 -0600
Subject: [R-sig-ME] Standard errors for random effects
In-Reply-To: <327708.4826.qm@web113501.mail.gq1.yahoo.com>
References: <327708.4826.qm@web113501.mail.gq1.yahoo.com>
Message-ID: <l2u40e66e0b1004010803wb6200122mf13b927da92740ba@mail.gmail.com>

On Thu, Apr 1, 2010 at 8:41 AM, Tahira Jamil <tahirajamil at yahoo.com> wrote:

> I am wondering how can we extract standard errors of random effects. Is it possible or not in lme4.

Technically the random effects don't have standard errors because they
are not parameters in the model.  If you use

ranef(mylmermodel, postVar = TRUE)

there will be an attribute attached to the random effects that is part
of the conditional variance-covariance matrix of the random effects.
It is used, for example, to calculate the prediction intervals on the
random effects shown in the dotplot or qqmath plots for them.  Check

library(lme4)
example(ranef)

or even

?ranef



From HDoran at air.org  Thu Apr  1 17:06:16 2010
From: HDoran at air.org (Doran, Harold)
Date: Thu, 1 Apr 2010 11:06:16 -0400
Subject: [R-sig-ME] Standard errors for random effects
In-Reply-To: <291F5C0A789C447AA9099EF9572E5035@lborger>
References: <327708.4826.qm@web113501.mail.gq1.yahoo.com>
	<291F5C0A789C447AA9099EF9572E5035@lborger>
Message-ID: <C0772C7568B5374481D2F8A880E9BBDF046266349A@DC1EX07CMS.air.org>

I don't think this is what the OP is referring to. If you want the standard errors of the conditional means, then you can extract them as follows:

(fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
attr( ranef(fm1, postVar = TRUE)[[1]], "postVar")

This is the variance/covariance matrix of the conditional means. So, grab what you need from the array here. The postVar argument is used to get the so called posterior means. However, I ssuepcta t some point this term will be deprecated and replaced with something more appropriate. 

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Luca Borger
Sent: Thursday, April 01, 2010 10:55 AM
To: Tahira Jamil; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Standard errors for random effects

Hello,

no, as the sampling distribution of random effects/variance estimates is 
usually strongly asymmetric and thus better alternatives should be used. See 
the mail archives for posts by Douglas Bates or the drafts of his 
forthcoming book or the wiki for mixed models:

http://glmm.wikidot.com/faq
Standard errors of variance estimates
  a.. Paraphrasing Doug Bates: the sampling distribution of variance 
estimates is in general strongly asymmetric: the standard error may be a 
poor characterization of the uncertainty.
  b.. Alternatives?
    a.. The development version of lme4, lme4a, allows for computing 
likelihood profiles of variances.
    b.. An MCMC-based approach (MCMCglmm, etc.) will provide posterior 
distributions of the variance parameters: quantiles or credible intervals 
(HPDinterval() in coda()) will characterize the uncertainty.



HTH,

Cheers,

Luca


----- Original Message ----- 
From: "Tahira Jamil" <tahirajamil at yahoo.com>
To: <r-sig-mixed-models at r-project.org>
Sent: Thursday, April 01, 2010 10:41 AM
Subject: [R-sig-ME] Standard errors for random effects


> Hi
> I am wondering how can we extract standard errors of random effects. Is it 
> possible or not in lme4.
> Best regards
>
> Tahira Jamil
> PhD student
> Biometris Wageningen
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bates at stat.wisc.edu  Thu Apr  1 17:19:22 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 1 Apr 2010 09:19:22 -0600
Subject: [R-sig-ME] About lmer function
In-Reply-To: <20100401103224.77811jcs7cuepb1c@efflammail.ifremer.fr>
References: <20100401103224.77811jcs7cuepb1c@efflammail.ifremer.fr>
Message-ID: <i2w40e66e0b1004010819kb07859f6n42dc14c255e8a5fc@mail.gmail.com>

I suggest sending queries like this to the
R-SIG-Mixed-Models at R-project.org mailing list, which I am taking the
liberty of cc:'ing on this reply.

On Thu, Apr 1, 2010 at 2:32 AM,  <Edgar.Torres at ifremer.fr> wrote:
> Hello professor Bates,
>
> I have had problems with the function lmer in the package lme4, I'm trying
> to run a GLMM with a poisson distribution. But I receive the warning message
>
> Warning message: In mer_finalize(ans) : iteration limit reached without
> convergence (9)
>
> I tried to put more iteration with control=list(maxIter=500), but actually
> the program justo run 300 times, as the default.
>
> the code that I wrote is this:
>
> GLMM1 <- lmer(OPTOT ~ fYEAR + (fYEAR | BOAT), data=DATA1, family=poisson,
> na.action=na.omit, control=list(maxIter=500,msVerbose=T), verbose=T)

Ben Bolker contributed a patch for this that Martin Maechler
incorporated in a new release of lme4.  The release has been uploaded
to CRAN but not yet installed (I think the CRAN maintainers are taking
a well-deserved vacation).

>
> I am not really sure that the way that I wrote the control statement is the
> right one.
>
> Thanks a lot
>
> Edgar TORRES
> Phd student in Ecosystems
> Centre de Recherche Halieutique ?(IRD)
> Avenue Jean Monnet BP 171
> 34203 S??te cedex France
>
>



From bates at stat.wisc.edu  Thu Apr  1 17:20:44 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 1 Apr 2010 09:20:44 -0600
Subject: [R-sig-ME] About lmer function
In-Reply-To: <i2w40e66e0b1004010819kb07859f6n42dc14c255e8a5fc@mail.gmail.com>
References: <20100401103224.77811jcs7cuepb1c@efflammail.ifremer.fr>
	<i2w40e66e0b1004010819kb07859f6n42dc14c255e8a5fc@mail.gmail.com>
Message-ID: <u2h40e66e0b1004010820kdebbcc64i5dd344ed58e99f25@mail.gmail.com>

On Thu, Apr 1, 2010 at 9:19 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
> I suggest sending queries like this to the
> R-SIG-Mixed-Models at R-project.org mailing list, which I am taking the
> liberty of cc:'ing on this reply.
>
> On Thu, Apr 1, 2010 at 2:32 AM, ?<Edgar.Torres at ifremer.fr> wrote:
>> Hello professor Bates,
>>
>> I have had problems with the function lmer in the package lme4, I'm trying
>> to run a GLMM with a poisson distribution. But I receive the warning message
>>
>> Warning message: In mer_finalize(ans) : iteration limit reached without
>> convergence (9)
>>
>> I tried to put more iteration with control=list(maxIter=500), but actually
>> the program justo run 300 times, as the default.
>>
>> the code that I wrote is this:
>>
>> GLMM1 <- lmer(OPTOT ~ fYEAR + (fYEAR | BOAT), data=DATA1, family=poisson,
>> na.action=na.omit, control=list(maxIter=500,msVerbose=T), verbose=T)
>
> Ben Bolker contributed a patch for this that Martin Maechler
> incorporated in a new release of lme4. ?The release has been uploaded
> to CRAN but not yet installed (I think the CRAN maintainers are taking
> a well-deserved vacation).

By the way, before trying to increase the maximum number of iterations
I would first use verbose = TRUE in the current call to see where the
iterations are going.

>
>>
>> I am not really sure that the way that I wrote the control statement is the
>> right one.
>>
>> Thanks a lot
>>
>> Edgar TORRES
>> Phd student in Ecosystems
>> Centre de Recherche Halieutique ?(IRD)
>> Avenue Jean Monnet BP 171
>> 34203 S??te cedex France
>>
>>
>



From bolker at ufl.edu  Thu Apr  1 17:21:47 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 01 Apr 2010 11:21:47 -0400
Subject: [R-sig-ME] Standard errors for random effects
In-Reply-To: <C0772C7568B5374481D2F8A880E9BBDF046266349A@DC1EX07CMS.air.org>
References: <327708.4826.qm@web113501.mail.gq1.yahoo.com>	<291F5C0A789C447AA9099EF9572E5035@lborger>
	<C0772C7568B5374481D2F8A880E9BBDF046266349A@DC1EX07CMS.air.org>
Message-ID: <4BB4BA0B.70402@ufl.edu>

  I can't tell what the OP wanted.

  I added a bullet point to the FAQ explaining (*after* explaining that
it's a questionable thing to do) how you can get the (quadratic
approximation of) the standard deviations of the random effects
*variances* derived from the (numerical approximations of the) second
derivatives of the likelihood surface from an nlme fit.

  I've also (hope that's OK) added your comment below to the FAQ, under
a separate section.

Doran, Harold wrote:
> I don't think this is what the OP is referring to. If you want the standard errors of the conditional means, then you can extract them as follows:
> 
> (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
> attr( ranef(fm1, postVar = TRUE)[[1]], "postVar")
> 
> This is the variance/covariance matrix of the conditional means. So, grab what you need from the array here. The postVar argument is used to get the so called posterior means. However, I ssuepcta t some point this term will be deprecated and replaced with something more appropriate. 
> 
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Luca Borger
> Sent: Thursday, April 01, 2010 10:55 AM
> To: Tahira Jamil; r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Standard errors for random effects
> 
> Hello,
> 
> no, as the sampling distribution of random effects/variance estimates is 
> usually strongly asymmetric and thus better alternatives should be used. See 
> the mail archives for posts by Douglas Bates or the drafts of his 
> forthcoming book or the wiki for mixed models:
> 
> http://glmm.wikidot.com/faq
> Standard errors of variance estimates
>   a.. Paraphrasing Doug Bates: the sampling distribution of variance 
> estimates is in general strongly asymmetric: the standard error may be a 
> poor characterization of the uncertainty.
>   b.. Alternatives?
>     a.. The development version of lme4, lme4a, allows for computing 
> likelihood profiles of variances.
>     b.. An MCMC-based approach (MCMCglmm, etc.) will provide posterior 
> distributions of the variance parameters: quantiles or credible intervals 
> (HPDinterval() in coda()) will characterize the uncertainty.
> 
> 
> 
> HTH,
> 
> Cheers,
> 
> Luca
> 
> 
> ----- Original Message ----- 
> From: "Tahira Jamil" <tahirajamil at yahoo.com>
> To: <r-sig-mixed-models at r-project.org>
> Sent: Thursday, April 01, 2010 10:41 AM
> Subject: [R-sig-ME] Standard errors for random effects
> 
> 
>> Hi
>> I am wondering how can we extract standard errors of random effects. Is it 
>> possible or not in lme4.
>> Best regards
>>
>> Tahira Jamil
>> PhD student
>> Biometris Wageningen
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From Edgar.Torres at ifremer.fr  Thu Apr  1 17:56:22 2010
From: Edgar.Torres at ifremer.fr (Edgar.Torres at ifremer.fr)
Date: Thu, 01 Apr 2010 17:56:22 +0200
Subject: [R-sig-ME] About lmer() function in package lme4
Message-ID: <20100401175622.901117rit7ssfns0@efflammail.ifremer.fr>


Hello,

I have had problems with the function lmer in the package lme4, I'm  
trying to run a GLMM with a poisson distribution. But I receive the  
warning message

Warning message: In mer_finalize(ans) : iteration limit reached  
without convergence (9)

I tried to put more iteration with control=list(maxIter=500), but  
actually the program justo run 300 times, as the default.

the code that I wrote is this:

GLMM1 <- lmer(OPTOT ~ fYEAR + (fYEAR | BOAT), data=DATA1,  
family=poisson, na.action=na.omit,  
control=list(maxIter=500,msVerbose=T), verbose=T)


I am not really sure that the way that I wrote the control statement  
is the right one.

Thanks a lot

Edgar TORRES
Phd student in Ecosystems
Centre de Recherche Halieutique  (IRD)
Avenue Jean Monnet BP 171
34203 S????te cedex France



From maechler at stat.math.ethz.ch  Thu Apr  1 18:19:57 2010
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 1 Apr 2010 18:19:57 +0200
Subject: [R-sig-ME] About lmer() function in package lme4
In-Reply-To: <20100401175622.901117rit7ssfns0@efflammail.ifremer.fr>
References: <20100401175622.901117rit7ssfns0@efflammail.ifremer.fr>
Message-ID: <19380.51117.136183.201426@lynne.math.ethz.ch>

>>>>> "ET" == Edgar Torres <Edgar.Torres at ifremer.fr>
>>>>>     on Thu, 01 Apr 2010 17:56:22 +0200 writes:

    ET> Hello,

    ET> I have had problems with the function lmer in the package lme4, I'm  
    ET> trying to run a GLMM with a poisson distribution. But I receive the  
    ET> warning message

    ET> Warning message: In mer_finalize(ans) : iteration limit reached  
    ET> without convergence (9)

    ET> I tried to put more iteration with control=list(maxIter=500), but  
    ET> actually the program justo run 300 times, as the default.

    ET> the code that I wrote is this:

    ET> GLMM1 <- lmer(OPTOT ~ fYEAR + (fYEAR | BOAT), data=DATA1,  
    ET> family=poisson, na.action=na.omit,  
    ET> control=list(maxIter=500,msVerbose=T), verbose=T)

Coincidence ?

Just Tuesday and yesterday, Doug Bates and were prompted to fix
this thanks to an (R-forge) bug report + e-mail from Ben Bolker.
Doug released the new version of lme4 to CRAN's incoming,
but because of Easter holidays, those packages are not yet
available for installation.

However, if you install lme4 from R-forge,
you should get a version that fixes your problem.

After you do
  >  install.packages("lme4", repos="http://r-forge.r-project.org")

  >  packageDescription("lme4")

should contain
       Repository/R-Forge/Revision: 716
(or a higher number than 716).
In that case, you should be fine.

Can you confirm?

Regards,
Martin Maechler


    ET> I am not really sure that the way that I wrote the control statement  
    ET> is the right one.

    ET> Thanks a lot

    ET> Edgar TORRES
    ET> Phd student in Ecosystems
    ET> Centre de Recherche Halieutique  (IRD)
    ET> Avenue Jean Monnet BP 171
    ET> 34203 S????te cedex France



From edeline at biologie.ens.fr  Thu Apr  1 18:51:55 2010
From: edeline at biologie.ens.fr (Eric Edeline)
Date: Thu, 01 Apr 2010 18:51:55 +0200
Subject: [R-sig-ME] SE of predictions from lme
Message-ID: <4BB4CF2B.80101@biologie.ens.fr>

Dear list,

could anyone point to me a method to extract SE of predictions from a 
lme? I have pasted the model below.

Thanks!

Eric

m06<-lme(log(Length) ~ 
log(Slope)+log(Width)+log(Depth)+log(Mu)+log(D)+log(Compint2)+log(Pred2)*log(Temp)+Year, 
data=Data, na.action=na.omit,
random=list(Strategy=pdDiag(form=~1), Method=pdDiag(form=~1), 
Species=pdDiag(form=~1), Station=pdDiag(form=~1)),
weights=varComb(varPower(form=~D), varPower(form=~Pred2)))   

-- 
Eric Edeline
Assistant Professor
UMR 7618 BIOEMCO
Ecole Normale Sup?rieure
46 rue d'Ulm
75230 Paris cedex 05
France

Tel: +33 (0)1 44 32 38 84
Fax: +33 (0)1 44 32 38 85

http://www.biologie.ens.fr/bioemco/biodiversite/edeline.html



From walmeszeviani at yahoo.com.br  Thu Apr  1 19:37:27 2010
From: walmeszeviani at yahoo.com.br (walmes zeviani)
Date: Thu, 1 Apr 2010 10:37:27 -0700 (PDT)
Subject: [R-sig-ME] Res:  SE of predictions from lme
In-Reply-To: <4BB4CF2B.80101@biologie.ens.fr>
References: <4BB4CF2B.80101@biologie.ens.fr>
Message-ID: <633354.43615.qm@web111703.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100401/0b0c5ce4/attachment.pl>

From bolker at ufl.edu  Thu Apr  1 20:00:02 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 01 Apr 2010 14:00:02 -0400
Subject: [R-sig-ME] Res:  SE of predictions from lme
In-Reply-To: <633354.43615.qm@web111703.mail.gq1.yahoo.com>
References: <4BB4CF2B.80101@biologie.ens.fr>
	<633354.43615.qm@web111703.mail.gq1.yahoo.com>
Message-ID: <4BB4DF22.80907@ufl.edu>

 now added to http://glmm.wikidot.com/faq

walmes zeviani wrote:
> This topic was answered before. I suggest you take a look at the past discussion:
> 
> http://markmail.org/message/lhtols3t5wrleewc
> 
> Walmes.
> 
> 
> 
> 
> ________________________________
> De: Eric Edeline <edeline at biologie.ens.fr>
> Para: r-sig-mixed-models at r-project.org
> Enviadas: Quinta-feira, 1 de Abril de 2010 13:51:55
> Assunto: [R-sig-ME] SE of predictions from lme
> 
> Dear list,
> 
> could anyone point to me a method to extract SE of predictions from a lme? I have pasted the model below.
> 
> Thanks!
> 
> Eric
> 
> m06<-lme(log(Length) ~ log(Slope)+log(Width)+log(Depth)+log(Mu)+log(D)+log(Compint2)+log(Pred2)*log(Temp)+Year, data=Data, na.action=na.omit,
> random=list(Strategy=pdDiag(form=~1), Method=pdDiag(form=~1), Species=pdDiag(form=~1), Station=pdDiag(form=~1)),
> weights=varComb(varPower(form=~D), varPower(form=~Pred2)))  
> -- Eric Edeline
> Assistant Professor
> UMR 7618 BIOEMCO
> Ecole Normale Sup?rieure
> 46 rue d'Ulm
> 75230 Paris cedex 05
> France
> 
> Tel: +33 (0)1 44 32 38 84
> Fax: +33 (0)1 44 32 38 85
> 
> http://www.biologie.ens.fr/bioemco/biodiversite/edeline.html
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 
>       ____________________________________________________________________________________
> [[elided Yahoo spam]]
> 
> 	[[alternative HTML version deleted]]
> 
> 


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From tim.carnus at gmail.com  Thu Apr  1 20:12:55 2010
From: tim.carnus at gmail.com (Tim Carnus)
Date: Thu, 01 Apr 2010 19:12:55 +0100
Subject: [R-sig-ME] poisson GLMER with identity link
In-Reply-To: <1269881108.3596.24.camel@tim-laptop>
References: <1269881108.3596.24.camel@tim-laptop>
Message-ID: <1270145575.7583.16.camel@tim-laptop>

Dear list,

Just adding an example of the model I am fitting, and session info.

model<-glmer(count~-1+X1+X2+X3+X4+(1|plot),poisson(link='identity'),
REML=TRUE)

where I am interested in the additive effects of X1-X4 on the count per
plot response. The random effect is simply there to account for the
repeated measures taken over time on each plot.

R version 2.10.1 (2009-12-14) 
i486-pc-linux-gnu 



On Mon, 2010-03-29 at 17:45 +0100, Tim Carnus wrote:
> Dear list,
> 
> I am trying to fit a number of GLMERs to count data with an additive
> model (in the predictors) that requires the use of the identity link
> function. For about half of my response variables this causes no
> problems. However in a number of cases the model fitting runs into
> problems with regards estimation of negative mean (for e.g. the error
> message in mer_finalize: mu[i] must be positive: mu = 1.76267e-312, i =
> 13075456). As far as I understand this is well known and documented, and
> guarding against that possibility is necessary, and built in to say the
> glm() function.
> 
> My question then is, how can I do this with lmer? (ie how can I specify
> the constraints necessary to fit these types of models, if at all
> possible)
> 
> Best regards,
> 
> Tim Carnus
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bolker at ufl.edu  Fri Apr  2 17:39:22 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Fri, 02 Apr 2010 11:39:22 -0400
Subject: [R-sig-ME] poisson GLMER with identity link
In-Reply-To: <1270145575.7583.16.camel@tim-laptop>
References: <1269881108.3596.24.camel@tim-laptop>
	<1270145575.7583.16.camel@tim-laptop>
Message-ID: <4BB60FAA.1030004@ufl.edu>


  I don't think there is a way to do this without hacking.
  I don't know what glm.fit does, internally, to address this situation
-- certainly one gets a lot of warnings, but it does come up with a
reasonably sensible answer (once reasonable starting values have been
specified).
  If I were going to hack this I would go into lmer.c , find the
location where the warning occurred, and change the code to set the
offending value to a feasible (non-negative) value instead (giving a
warning).  Slightly more conservatively you could set a threshold below
which the value was adjusted with a warning and above which an error
occurred.

> x = runif(100)
> y = rpois(100,4*x)
> glm(y~x,family=poisson(link="identity"))
Error: no valid set of coefficients has been found: please supply
starting values
In addition: Warning message:
In log(ifelse(y == 0, 1, y/mu)) : NaNs produced
> glm(y~x,family=poisson(link="identity"),start=c(0.1,4))

Call:  glm(formula = y ~ x, family = poisson(link = "identity"), start =
c(0.1,      4))

Coefficients:
(Intercept)            x
   -0.01669      4.28255

Degrees of Freedom: 99 Total (i.e. Null);  98 Residual
Null Deviance:	    176.8
Residual Deviance: 87.02 	AIC: 295
There were 15 warnings (use warnings() to see them)
> warnings()
Warning messages:
1: step size truncated: out of bounds
2: step size truncated: out of bounds
3: step size truncated: out of bounds
4: step size truncated: out of bounds
5: step size truncated: out of bounds
6: step size truncated: out of bounds
7: step size truncated: out of bounds
8: step size truncated: out of bounds
9: step size truncated: out of bounds
10: step size truncated: out of bounds
11: step size truncated: out of bounds
12: step size truncated: out of bounds
13: step size truncated: out of bounds
14: In glm.fit(x = X, y = Y, weights = weights, start = start,  ... :
  algorithm stopped at boundary value
15: In glm.fit(x = X, y = Y, weights = weights, start = start,  ... :
  fitted rates numerically 0 occurred


Tim Carnus wrote:
> Dear list,
> 
> Just adding an example of the model I am fitting, and session info.
> 
> model<-glmer(count~-1+X1+X2+X3+X4+(1|plot),poisson(link='identity'),
> REML=TRUE)
> 
> where I am interested in the additive effects of X1-X4 on the count per
> plot response. The random effect is simply there to account for the
> repeated measures taken over time on each plot.
> 
> R version 2.10.1 (2009-12-14) 
> i486-pc-linux-gnu 
> 
> 
> 
> On Mon, 2010-03-29 at 17:45 +0100, Tim Carnus wrote:
>> Dear list,
>>
>> I am trying to fit a number of GLMERs to count data with an additive
>> model (in the predictors) that requires the use of the identity link
>> function. For about half of my response variables this causes no
>> problems. However in a number of cases the model fitting runs into
>> problems with regards estimation of negative mean (for e.g. the error
>> message in mer_finalize: mu[i] must be positive: mu = 1.76267e-312, i =
>> 13075456). As far as I understand this is well known and documented, and
>> guarding against that possibility is necessary, and built in to say the
>> glm() function.
>>
>> My question then is, how can I do this with lmer? (ie how can I specify
>> the constraints necessary to fit these types of models, if at all
>> possible)
>>
>> Best regards,
>>
>> Tim Carnus
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From cat.dev.urandom at gmail.com  Sun Apr  4 07:12:52 2010
From: cat.dev.urandom at gmail.com (D Chaws)
Date: Sun, 4 Apr 2010 01:12:52 -0400
Subject: [R-sig-ME] lme and prediction intervals
In-Reply-To: <dcf23fb81002252132u7fd4b01ft5a3232e51fcfc73@mail.gmail.com>
References: <dcf23fb81002180925o2a82d2a4xea95799c547753c5@mail.gmail.com>
	<dcf23fb81002252132u7fd4b01ft5a3232e51fcfc73@mail.gmail.com>
Message-ID: <t2ydcf23fb81004032212p656253e4v42234d8a5b90a669@mail.gmail.com>

Ok, issue solved for the most straightforward random effects cases.
Not sure about nested random effects or more complex cases.

vcov(fm1) will give you the appropriate covariance matrix that can
then be applied to the design matrix to get SEs.

Brian S. Yandell has a nice version of lsmean for his pda package that
handles prediction SEs
well, and which appear match very closely to those computed from SAS.

The link is:

http://r-forge.r-project.org/plugins/scmsvn/viewcvs.php/*checkout*/pkg/R/lsmean.R?rev=2&root=pda

-- DC

On Fri, Feb 26, 2010 at 12:32 AM, D Chaws <cat.dev.urandom at gmail.com> wrote:
> And the saga continues...
>
> I checked on the SAS website to see how they compute standard errors
> for predictions in LSMEANS, just for giggles.  According to
> http://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/statug_mixed_sect014.htm
>
> SE = L(X'V-1X)-L'
>
> or in R terms
>
> SE = Designmat %*% solve(formXtViX(extract.lme.cov2(fm1, Orthodont),
> extract.lmeDesign(fm1)$X), t(Designmat))
>
> which is, yes...you guessed it, the exact same thing as Designmat %*%
> fm1$varFix %*% t(Designmat).
>
> And of course, the SE's don't match those in LSMEANS.  Any thoughts?
> I can't believe a solution to this has never come up.  I don't care
> about replicating LSMEANS, I just want to be confident that the SE's I
> present are accurate and meaningful.  Since they currently leave out
> random-effects variance, I suspect something important is missing.
>
> -- DC
>
> On Thu, Feb 18, 2010 at 12:25 PM, D Chaws <cat.dev.urandom at gmail.com> wrote:
>> Dear lme(r) users,
>>
>> I have seen this issue come up many times over the years, but haven't
>> come across an answer as of yet.
>> Take for example the growth model:
>>
>> fm1 <- lme(distance ~ age*Sex, random = ~ 1 + age | Subject, data = Orthodont)
>>
>> Distance increases with age, but more so in Males.
>>
>> I want to obtain the model predicted values of distance at each age
>> (c(8,10,12,14)) for males and female separately to explore this
>> interaction.
>>
>> So,
>>
>> newdat <- expand.grid(age=c(8,10,12,14), Sex=c("Male","Female"))
>> newdat$pred <- predict(fm1, newdat, level = 0)
>>
>> R# newdat
>>  age    Sex  pred
>> 1   8   Male 22.62
>> 2  10   Male 24.18
>> 3  12   Male 25.75
>> 4  14   Male 27.32
>> 5   8 Female 21.21
>> 6  10 Female 22.17
>> 7  12 Female 23.13
>> 8  14 Female 24.09
>>
>> Yup, males have a steeper increase with age than females.
>>
>> The question is, how to go about getting prediction intervals around
>> these predictions.  It seems reasonable to need to know
>> the precision of these predictions, and of course most journals
>> require the reporting of error bars etc...  However, predict.lme
>> doesn't
>> have a se.fit or intervals argument.
>>
>> The only answer I have found at the moment is to use the design matrix
>> and $varFix from the model.
>>
>> So,
>>
>> Designmat <- model.matrix(eval(eval(fm1$call$fixed)[-2]), newdat[-3])
>> R# Designmat
>>  (Intercept) age SexFemale age:SexFemale
>> 1           1   8         0             0
>> 2           1  10         0             0
>> 3           1  12         0             0
>> 4           1  14         0             0
>> 5           1   8         1             8
>> 6           1  10         1            10
>> 7           1  12         1            12
>> 8           1  14         1            14
>>
>> newdat$SE <- sqrt(diag(Designmat %*% fm1$varFix %*% t(Designmat)))
>> R# newdat
>>  age    Sex  pred     SE
>> 1   8   Male 22.62 0.5265
>> 2  10   Male 24.18 0.4848
>> 3  12   Male 25.75 0.5021
>> 4  14   Male 27.32 0.5730
>> 5   8 Female 21.21 0.6350
>> 6  10 Female 22.17 0.5847
>> 7  12 Female 23.13 0.6056
>> 8  14 Female 24.09 0.6910
>>
>> Are these true pointwise prediction intervals?
>>
>> Any help would be greatly appreciated.  I refuse to use SAS for this!
>>
>> -- D. Chaws
>>
>



From bates at stat.wisc.edu  Sun Apr  4 14:38:33 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 4 Apr 2010 07:38:33 -0500
Subject: [R-sig-ME] lme and prediction intervals
In-Reply-To: <t2ydcf23fb81004032212p656253e4v42234d8a5b90a669@mail.gmail.com>
References: <dcf23fb81002180925o2a82d2a4xea95799c547753c5@mail.gmail.com>
	<dcf23fb81002252132u7fd4b01ft5a3232e51fcfc73@mail.gmail.com>
	<t2ydcf23fb81004032212p656253e4v42234d8a5b90a669@mail.gmail.com>
Message-ID: <v2y40e66e0b1004040538qc2cfe08ag975cbdc65a9e4326@mail.gmail.com>

On Sat, Apr 3, 2010 at 11:12 PM, D Chaws <cat.dev.urandom at gmail.com> wrote:
> Ok, issue solved for the most straightforward random effects cases.
> Not sure about nested random effects or more complex cases.

Assuming that you can make sense of lsmeans in such a case.  You may
notice that lsmeans are not provided in base and recommended R
packages.  That isn't an oversight.  Try to explain what lsmeans are
in terms of the probability model.

Anyway, if you are happy with it, then go for it.  I'll just give you
a warning from a professional statistician that they are a nonsensical
construction.

> vcov(fm1) will give you the appropriate covariance matrix that can
> then be applied to the design matrix to get SEs.
>
> Brian S. Yandell has a nice version of lsmean for his pda package that
> handles prediction SEs
> well, and which appear match very closely to those computed from SAS.
>
> The link is:
>
> http://r-forge.r-project.org/plugins/scmsvn/viewcvs.php/*checkout*/pkg/R/lsmean.R?rev=2&root=pda
>
> -- DC
>
> On Fri, Feb 26, 2010 at 12:32 AM, D Chaws <cat.dev.urandom at gmail.com> wrote:
>> And the saga continues...
>>
>> I checked on the SAS website to see how they compute standard errors
>> for predictions in LSMEANS, just for giggles. ?According to
>> http://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/statug_mixed_sect014.htm
>>
>> SE = L(X'V-1X)-L'
>>
>> or in R terms
>>
>> SE = Designmat %*% solve(formXtViX(extract.lme.cov2(fm1, Orthodont),
>> extract.lmeDesign(fm1)$X), t(Designmat))
>>
>> which is, yes...you guessed it, the exact same thing as Designmat %*%
>> fm1$varFix %*% t(Designmat).
>>
>> And of course, the SE's don't match those in LSMEANS. ?Any thoughts?
>> I can't believe a solution to this has never come up. ?I don't care
>> about replicating LSMEANS, I just want to be confident that the SE's I
>> present are accurate and meaningful. ?Since they currently leave out
>> random-effects variance, I suspect something important is missing.
>>
>> -- DC
>>
>> On Thu, Feb 18, 2010 at 12:25 PM, D Chaws <cat.dev.urandom at gmail.com> wrote:
>>> Dear lme(r) users,
>>>
>>> I have seen this issue come up many times over the years, but haven't
>>> come across an answer as of yet.
>>> Take for example the growth model:
>>>
>>> fm1 <- lme(distance ~ age*Sex, random = ~ 1 + age | Subject, data = Orthodont)
>>>
>>> Distance increases with age, but more so in Males.
>>>
>>> I want to obtain the model predicted values of distance at each age
>>> (c(8,10,12,14)) for males and female separately to explore this
>>> interaction.
>>>
>>> So,
>>>
>>> newdat <- expand.grid(age=c(8,10,12,14), Sex=c("Male","Female"))
>>> newdat$pred <- predict(fm1, newdat, level = 0)
>>>
>>> R# newdat
>>> ?age ? ?Sex ?pred
>>> 1 ? 8 ? Male 22.62
>>> 2 ?10 ? Male 24.18
>>> 3 ?12 ? Male 25.75
>>> 4 ?14 ? Male 27.32
>>> 5 ? 8 Female 21.21
>>> 6 ?10 Female 22.17
>>> 7 ?12 Female 23.13
>>> 8 ?14 Female 24.09
>>>
>>> Yup, males have a steeper increase with age than females.
>>>
>>> The question is, how to go about getting prediction intervals around
>>> these predictions. ?It seems reasonable to need to know
>>> the precision of these predictions, and of course most journals
>>> require the reporting of error bars etc... ?However, predict.lme
>>> doesn't
>>> have a se.fit or intervals argument.
>>>
>>> The only answer I have found at the moment is to use the design matrix
>>> and $varFix from the model.
>>>
>>> So,
>>>
>>> Designmat <- model.matrix(eval(eval(fm1$call$fixed)[-2]), newdat[-3])
>>> R# Designmat
>>> ?(Intercept) age SexFemale age:SexFemale
>>> 1 ? ? ? ? ? 1 ? 8 ? ? ? ? 0 ? ? ? ? ? ? 0
>>> 2 ? ? ? ? ? 1 ?10 ? ? ? ? 0 ? ? ? ? ? ? 0
>>> 3 ? ? ? ? ? 1 ?12 ? ? ? ? 0 ? ? ? ? ? ? 0
>>> 4 ? ? ? ? ? 1 ?14 ? ? ? ? 0 ? ? ? ? ? ? 0
>>> 5 ? ? ? ? ? 1 ? 8 ? ? ? ? 1 ? ? ? ? ? ? 8
>>> 6 ? ? ? ? ? 1 ?10 ? ? ? ? 1 ? ? ? ? ? ?10
>>> 7 ? ? ? ? ? 1 ?12 ? ? ? ? 1 ? ? ? ? ? ?12
>>> 8 ? ? ? ? ? 1 ?14 ? ? ? ? 1 ? ? ? ? ? ?14
>>>
>>> newdat$SE <- sqrt(diag(Designmat %*% fm1$varFix %*% t(Designmat)))
>>> R# newdat
>>> ?age ? ?Sex ?pred ? ? SE
>>> 1 ? 8 ? Male 22.62 0.5265
>>> 2 ?10 ? Male 24.18 0.4848
>>> 3 ?12 ? Male 25.75 0.5021
>>> 4 ?14 ? Male 27.32 0.5730
>>> 5 ? 8 Female 21.21 0.6350
>>> 6 ?10 Female 22.17 0.5847
>>> 7 ?12 Female 23.13 0.6056
>>> 8 ?14 Female 24.09 0.6910
>>>
>>> Are these true pointwise prediction intervals?
>>>
>>> Any help would be greatly appreciated. ?I refuse to use SAS for this!
>>>
>>> -- D. Chaws
>>>
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From lamprianou at yahoo.com  Sun Apr  4 17:49:06 2010
From: lamprianou at yahoo.com (Iasonas Lamprianou)
Date: Sun, 4 Apr 2010 08:49:06 -0700 (PDT)
Subject: [R-sig-ME] Likelihood Ratio
In-Reply-To: <mailman.1.1270375202.14388.r-sig-mixed-models@r-project.org>
Message-ID: <274417.49634.qm@web58908.mail.re1.yahoo.com>

Dear all,
the good old advice of using

sm1 <- mcmcsamp(m3_06, 10)
HPDinterval(sm1)

to evaluate the confidence intervals of the random variance do not seem to work any more. What is the new acceptable advice, other than running simulations with the likelihood ratio test? Or maybe there is no additional/new advice on this?

jason

Dr. Iasonas Lamprianou


Assistant Professor (Educational Research and Evaluation)
Department of Education Sciences
European University-Cyprus
P.O. Box 22006
1516 Nicosia
Cyprus 
Tel.: +357-22-713178
Fax: +357-22-590539


Honorary Research Fellow
Department of Education
The University of Manchester
Oxford Road, Manchester M13 9PL, UK
Tel. 0044  161 275 3485
iasonas.lamprianou at manchester.ac.uk


--- On Sun, 4/4/10, r-sig-mixed-models-request at r-project.org <r-sig-mixed-models-request at r-project.org> wrote:

> From: r-sig-mixed-models-request at r-project.org <r-sig-mixed-models-request at r-project.org>
> Subject: R-sig-mixed-models Digest, Vol 40, Issue 6
> To: r-sig-mixed-models at r-project.org
> Date: Sunday, 4 April, 2010, 11:00
> Send R-sig-mixed-models mailing list
> submissions to
> ??? r-sig-mixed-models at r-project.org
> 
> To subscribe or unsubscribe via the World Wide Web, visit
> ??? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help'
> to
> ??? r-sig-mixed-models-request at r-project.org
> 
> You can reach the person managing the list at
> ??? r-sig-mixed-models-owner at r-project.org
> 
> When replying, please edit your Subject line so it is more
> specific
> than "Re: Contents of R-sig-mixed-models digest..."
> 
> 
> Today's Topics:
> 
> ???1. Re: lme and prediction intervals (D
> Chaws)
> 
> 
> ----------------------------------------------------------------------
> 
> Message: 1
> Date: Sun, 4 Apr 2010 01:12:52 -0400
> From: D Chaws <cat.dev.urandom at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] lme and prediction intervals
> Message-ID:
> ??? <t2ydcf23fb81004032212p656253e4v42234d8a5b90a669 at mail.gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1
> 
> Ok, issue solved for the most straightforward random
> effects cases.
> Not sure about nested random effects or more complex
> cases.
> 
> vcov(fm1) will give you the appropriate covariance matrix
> that can
> then be applied to the design matrix to get SEs.
> 
> Brian S. Yandell has a nice version of lsmean for his pda
> package that
> handles prediction SEs
> well, and which appear match very closely to those computed
> from SAS.
> 
> The link is:
> 
> http://r-forge.r-project.org/plugins/scmsvn/viewcvs.php/*checkout*/pkg/R/lsmean.R?rev=2&root=pda
> 
> -- DC
> 
> On Fri, Feb 26, 2010 at 12:32 AM, D Chaws <cat.dev.urandom at gmail.com>
> wrote:
> > And the saga continues...
> >
> > I checked on the SAS website to see how they compute
> standard errors
> > for predictions in LSMEANS, just for giggles.?
> According to
> > http://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/statug_mixed_sect014.htm
> >
> > SE = L(X'V-1X)-L'
> >
> > or in R terms
> >
> > SE = Designmat %*%
> solve(formXtViX(extract.lme.cov2(fm1, Orthodont),
> > extract.lmeDesign(fm1)$X), t(Designmat))
> >
> > which is, yes...you guessed it, the exact same thing
> as Designmat %*%
> > fm1$varFix %*% t(Designmat).
> >
> > And of course, the SE's don't match those in
> LSMEANS.? Any thoughts?
> > I can't believe a solution to this has never come
> up.? I don't care
> > about replicating LSMEANS, I just want to be confident
> that the SE's I
> > present are accurate and meaningful.? Since they
> currently leave out
> > random-effects variance, I suspect something important
> is missing.
> >
> > -- DC
> >
> > On Thu, Feb 18, 2010 at 12:25 PM, D Chaws <cat.dev.urandom at gmail.com>
> wrote:
> >> Dear lme(r) users,
> >>
> >> I have seen this issue come up many times over the
> years, but haven't
> >> come across an answer as of yet.
> >> Take for example the growth model:
> >>
> >> fm1 <- lme(distance ~ age*Sex, random = ~ 1 +
> age | Subject, data = Orthodont)
> >>
> >> Distance increases with age, but more so in
> Males.
> >>
> >> I want to obtain the model predicted values of
> distance at each age
> >> (c(8,10,12,14)) for males and female separately to
> explore this
> >> interaction.
> >>
> >> So,
> >>
> >> newdat <- expand.grid(age=c(8,10,12,14),
> Sex=c("Male","Female"))
> >> newdat$pred <- predict(fm1, newdat, level = 0)
> >>
> >> R# newdat
> >>? age? ? Sex? pred
> >> 1???8???Male 22.62
> >> 2? 10???Male 24.18
> >> 3? 12???Male 25.75
> >> 4? 14???Male 27.32
> >> 5???8 Female 21.21
> >> 6? 10 Female 22.17
> >> 7? 12 Female 23.13
> >> 8? 14 Female 24.09
> >>
> >> Yup, males have a steeper increase with age than
> females.
> >>
> >> The question is, how to go about getting
> prediction intervals around
> >> these predictions.? It seems reasonable to
> need to know
> >> the precision of these predictions, and of course
> most journals
> >> require the reporting of error bars etc...?
> However, predict.lme
> >> doesn't
> >> have a se.fit or intervals argument.
> >>
> >> The only answer I have found at the moment is to
> use the design matrix
> >> and $varFix from the model.
> >>
> >> So,
> >>
> >> Designmat <-
> model.matrix(eval(eval(fm1$call$fixed)[-2]), newdat[-3])
> >> R# Designmat
> >>? (Intercept) age SexFemale age:SexFemale
> >> 1? ? ? ?
> ???1???8? ? ?
> ???0? ? ? ? ?
> ???0
> >> 2? ? ? ?
> ???1? 10? ? ?
> ???0? ? ? ? ?
> ???0
> >> 3? ? ? ?
> ???1? 12? ? ?
> ???0? ? ? ? ?
> ???0
> >> 4? ? ? ?
> ???1? 14? ? ?
> ???0? ? ? ? ?
> ???0
> >> 5? ? ? ?
> ???1???8? ? ?
> ???1? ? ? ? ?
> ???8
> >> 6? ? ? ?
> ???1? 10? ? ?
> ???1? ? ? ? ? ?
> 10
> >> 7? ? ? ?
> ???1? 12? ? ?
> ???1? ? ? ? ? ?
> 12
> >> 8? ? ? ?
> ???1? 14? ? ?
> ???1? ? ? ? ? ?
> 14
> >>
> >> newdat$SE <- sqrt(diag(Designmat %*% fm1$varFix
> %*% t(Designmat)))
> >> R# newdat
> >>? age? ? Sex? pred?
> ???SE
> >> 1???8???Male 22.62
> 0.5265
> >> 2? 10???Male 24.18 0.4848
> >> 3? 12???Male 25.75 0.5021
> >> 4? 14???Male 27.32 0.5730
> >> 5???8 Female 21.21 0.6350
> >> 6? 10 Female 22.17 0.5847
> >> 7? 12 Female 23.13 0.6056
> >> 8? 14 Female 24.09 0.6910
> >>
> >> Are these true pointwise prediction intervals?
> >>
> >> Any help would be greatly appreciated.? I
> refuse to use SAS for this!
> >>
> >> -- D. Chaws
> >>
> >
> 
> 
> 
> ------------------------------
> 
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> End of R-sig-mixed-models Digest, Vol 40, Issue 6
> *************************************************
> 






From kushler at oakland.edu  Sun Apr  4 18:38:18 2010
From: kushler at oakland.edu (Robert Kushler)
Date: Sun, 04 Apr 2010 12:38:18 -0400
Subject: [R-sig-ME] plotting random effects; lme4(a) inference methods
Message-ID: <4BB8C07A.7080302@oakland.edu>


Page 70 of "Ch4.pdf" (the draft of the new book) says:

"The plot method for "ranef.mer" objects produces one plot
for each grouping factor."

Unfortunately the plots for all but the last grouping factor
are instantly replaced in the plot window.  My attempts to
work around this have so far failed.  Am I missing something
obvious?  (Wouldn't be the first time.) Any help would be
appreciated.


As long as I am posting, I will express my hope that Doug Bates
will weigh in on the recent post by Iasonas (Jason) Lamprianou, and
indicate where lme4a is heading.  The new book indicates that Doug
has (re)turned to favoring likelihood based inference methods, but
it would be nice to know the status of the Bayesian approach as well.

The latest version of mcmcsamp in lme4 seems much less prone to the
"stuck at zero" issue that occurred in earlier versions, but in my
experience (with a number of "toy problems" from linear models texts)
the estimates produced by lmer are near, or even above, the upper end
of the HPD intervals, which leads to a certain lack of "confidence"
(sic) in those intervals.

Perhaps this is a consequence of the prior that is used, but that
just raises another question:  will a future version allow user
control of the specification of the prior?

Regards,   Rob Kushler



From kushler at oakland.edu  Sun Apr  4 19:57:32 2010
From: kushler at oakland.edu (Robert Kushler)
Date: Sun, 04 Apr 2010 13:57:32 -0400
Subject: [R-sig-ME] plotting random effects, continued
Message-ID: <4BB8D30C.3090903@oakland.edu>


I have found a solution to my plotting problem (thanks to Dennis Murphy
for a helpful nudge).  The solution is to store the list of plots and
then call plot yourself.  I wanted to combine the plots on a single page;
putting them on separate pages is actually easier.

ppp <- dotplot(ranef(mod,postVar=TRUE))
plot(ppp$factor1,split=c(1,1,2,1))
plot(ppp$factor2,newpage=FALSE,split=c(2,1,2,1))

Doug, is this obscure enough to warrant expanding the comment in your book?

Regards,   Rob Kushler



From bolker at ufl.edu  Mon Apr  5 03:54:18 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Sun, 04 Apr 2010 21:54:18 -0400
Subject: [R-sig-ME] lme and prediction intervals
In-Reply-To: <v2y40e66e0b1004040538qc2cfe08ag975cbdc65a9e4326@mail.gmail.com>
References: <dcf23fb81002180925o2a82d2a4xea95799c547753c5@mail.gmail.com>	<dcf23fb81002252132u7fd4b01ft5a3232e51fcfc73@mail.gmail.com>	<t2ydcf23fb81004032212p656253e4v42234d8a5b90a669@mail.gmail.com>
	<v2y40e66e0b1004040538qc2cfe08ag975cbdc65a9e4326@mail.gmail.com>
Message-ID: <4BB942CA.1040909@ufl.edu>

Douglas Bates wrote:
> On Sat, Apr 3, 2010 at 11:12 PM, D Chaws <cat.dev.urandom at gmail.com> wrote:
>> Ok, issue solved for the most straightforward random effects cases.
>> Not sure about nested random effects or more complex cases.
> 
> Assuming that you can make sense of lsmeans in such a case.  You may
> notice that lsmeans are not provided in base and recommended R
> packages.  That isn't an oversight.  Try to explain what lsmeans are
> in terms of the probability model.
> 
> Anyway, if you are happy with it, then go for it.  I'll just give you
> a warning from a professional statistician that they are a nonsensical
> construction.

  lsmeans may not make sense in general (I don't really know, I have a
somewhat weird background that mostly doesn't include SAS), but there's
nothing wrong with wanting predictions and standard errors of
predictions, which be definable (?) if one can specify (a) whether a
given random effect is set to zero or included at its conditional
mean/mode value (or, for a simulation, chosen from a normal distribution
with the appropriate variance-covariance structure (b) whether random
effects not included in the prediction (and the residual error) are
included in the SE or not.  I agree that specifying all this is not as
easy as specifying "level", but can't one in principle do this by
specifying which random effects are in/out of the prediction or the SE?

  My hope is that, after building code for a reasonable number of
examples, the general principles will become sufficiently clear that a
method with an appropriate interface can then be written (note use of
the passive voice).  The hardest part I discovered for doing this with
existing lme and lme4 objects is recalculating the random-effects design
matrix appropriately when a new set of data (with different
random-effects factor structure) is specified ...

  Ben Bolker



From chris.eckert at queensu.ca  Mon Apr  5 05:39:35 2010
From: chris.eckert at queensu.ca (Christopher Eckert)
Date: Sun, 04 Apr 2010 23:39:35 -0400
Subject: [R-sig-ME] Interactions between fixed and random effects
Message-ID: <FA03F24C-F8AC-4804-9ED5-58FD658E4E91@queensu.ca>

I apologize if the answer to this query is somewhere totally obvious, but i couldn't find it.

I am trying to analyze an experiment where a set of 22 populations of a dune plant species (populations were randomly chosen from across the species' geographic range) were grown in a glasshouse under two different watering regimes (Water = Control vs. Drought). DryMass is the response variable. There was about 20 individuals from each population grown in each Water treatment.

Population is a random effect, but I would like to test for an interaction between Population and Water -to ask the question: do different populations respond differently to drought?

>From what I can gather this is analogous the random intercepts and slopes model discussed in Zuur et al and elsewhere, except that I am examining a categorical predictor (Water) rather than a continuous predictor.

Am I right in thinking that the basic syntax using lme is:

lme(DryMass~Water,random=~Water|Population)

and the syntax using lmer is:

lmer(DryMass~Water+(Water|Population))

Thanks very much for any clarification you can send my way.

Chris Eckert
Department of Biology
Queen's University
Kingston, Ontario K7L 3N6 Canada
chris.eckert at queensu.ca



From dutangc at gmail.com  Mon Apr  5 09:50:05 2010
From: dutangc at gmail.com (christophe dutang)
Date: Mon, 5 Apr 2010 09:50:05 +0200
Subject: [R-sig-ME] missing data + explanatory variables
In-Reply-To: <Pine.LNX.4.64.1003270834240.18180@orpheus.qimr.edu.au>
References: <c8e8cd3d1003240409r27cfb4c0w897cae92d391942f@mail.gmail.com>
	<Pine.LNX.4.64.1003250727070.15751@orpheus.qimr.edu.au>
	<6A2368B1-6ED7-48EF-AECC-712AA6865D26@gmail.com>
	<Pine.LNX.4.64.1003261003520.22301@orpheus.qimr.edu.au>
	<w2uc8e8cd3d1003261015j3e52c20dmde89ec65ac2c1c4c@mail.gmail.com>
	<AF1F2446D9EF402AA3D10A0559F9D22A@lborger>
	<Pine.LNX.4.64.1003270834240.18180@orpheus.qimr.edu.au>
Message-ID: <y2oc8e8cd3d1004050050gd4c25859ge96eac132420dd1f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100405/cccab245/attachment.pl>

From julien.beguin.1 at ulaval.ca  Mon Apr  5 13:23:13 2010
From: julien.beguin.1 at ulaval.ca (Julien Beguin)
Date: Mon, 5 Apr 2010 07:23:13 -0400
Subject: [R-sig-ME] RE :  Interactions between fixed and random effects
In-Reply-To: <FA03F24C-F8AC-4804-9ED5-58FD658E4E91@queensu.ca>
References: <FA03F24C-F8AC-4804-9ED5-58FD658E4E91@queensu.ca>
Message-ID: <B56D7C27B4408243B93FBC46ABECB5A0011A83C8F697@EXCH-MBX-F.ulaval.ca>

If you have 22 populations, and assuming that each indivudual in each population is randomly distributed within you water treatment (you did not specify your experimenta design... so I guess), you might have enough power to test the interaction between plant population and water treatment (21 df) in a similar way than in a classic ANOVA. So why to specify plant population as a random variable, rather than a fixed factor? are you (not) intersted to know which plant population respond differently regarding watering regimes? 

proposition:

> lm(DryMass~Water*Population) 


just a thought...

Julien Beguin  

________________________________________
De : r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] de la part de Christopher Eckert [chris.eckert at queensu.ca]
Date d'envoi : 4 avril 2010 23:39
? : r-sig-mixed-models at r-project.org
Objet : [R-sig-ME] Interactions between fixed and random effects

I apologize if the answer to this query is somewhere totally obvious, but i couldn't find it.

I am trying to analyze an experiment where a set of 22 populations of a dune plant species (populations were randomly chosen from across the species' geographic range) were grown in a glasshouse under two different watering regimes (Water = Control vs. Drought). DryMass is the response variable. There was about 20 individuals from each population grown in each Water treatment.

Population is a random effect, but I would like to test for an interaction between Population and Water -to ask the question: do different populations respond differently to drought?

>From what I can gather this is analogous the random intercepts and slopes model discussed in Zuur et al and elsewhere, except that I am examining a categorical predictor (Water) rather than a continuous predictor.

Am I right in thinking that the basic syntax using lme is:

lme(DryMass~Water,random=~Water|Population)

and the syntax using lmer is:

lmer(DryMass~Water+(Water|Population))

Thanks very much for any clarification you can send my way.

Chris Eckert
Department of Biology
Queen's University
Kingston, Ontario K7L 3N6 Canada
chris.eckert at queensu.ca

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bolker at ufl.edu  Mon Apr  5 13:28:13 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Mon, 05 Apr 2010 07:28:13 -0400
Subject: [R-sig-ME] Interactions between fixed and random effects
In-Reply-To: <FA03F24C-F8AC-4804-9ED5-58FD658E4E91@queensu.ca>
References: <FA03F24C-F8AC-4804-9ED5-58FD658E4E91@queensu.ca>
Message-ID: <4BB9C94D.1000101@ufl.edu>

Christopher Eckert wrote:
> I apologize if the answer to this query is somewhere totally obvious,
> but i couldn't find it.
> 
> I am trying to analyze an experiment where a set of 22 populations of
> a dune plant species (populations were randomly chosen from across
> the species' geographic range) were grown in a glasshouse under two
> different watering regimes (Water = Control vs. Drought). DryMass is
> the response variable. There was about 20 individuals from each
> population grown in each Water treatment.
> 
> Population is a random effect, but I would like to test for an
> interaction between Population and Water -to ask the question: do
> different populations respond differently to drought?
> 
>> From what I can gather this is analogous the random intercepts and
>> slopes model discussed in Zuur et al and elsewhere, except that I
>> am examining a categorical predictor (Water) rather than a
>> continuous predictor.
> 
> Am I right in thinking that the basic syntax using lme is:
> 
> lme(DryMass~Water,random=~Water|Population)
> 
> and the syntax using lmer is:
> 
> lmer(DryMass~Water+(Water|Population))

  I think this is exactly right (and I disagree with the other
respondent who thought you should just use a fixed effect: you may well
be interested in the among-population variation within the species in
drought response).  One of the nice things about this formulation is
that it allows you to look at/test the relationship between variation in
Control growth and drought response -- i.e., is there a tradeoff between
 growth under good conditions and drought tolerance? -- by looking at
the covariance in the random effects.



From j.hadfield at ed.ac.uk  Mon Apr  5 13:51:59 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 5 Apr 2010 12:51:59 +0100
Subject: [R-sig-ME] Interactions between fixed and random effects
In-Reply-To: <4BB9C94D.1000101@ufl.edu>
References: <FA03F24C-F8AC-4804-9ED5-58FD658E4E91@queensu.ca>
	<4BB9C94D.1000101@ufl.edu>
Message-ID: <B29A98F0-6001-4460-9608-8B58E61A57D6@ed.ac.uk>

Hi,

I agree with Ben, although I find the parameterisation:

lmer(DryMass~Water+(Water-1|Popuation))

easier to interpret. The 2 variances are then the between population  
variances for each treatment, and the correlation is the correlation  
in the effects of the two treatments over populations.

I also recommend fitting different residual variances for the two  
treatments because if differences do exist (eg simple scaling effects)  
you can get incorrect estimates of the interaction. I do not think you  
can do this in lmer, but I think it is possible in lme.

Cheers,

Jarrod



On 5 Apr 2010, at 12:28, Ben Bolker wrote:

> Christopher Eckert wrote:
>> I apologize if the answer to this query is somewhere totally obvious,
>> but i couldn't find it.
>>
>> I am trying to analyze an experiment where a set of 22 populations of
>> a dune plant species (populations were randomly chosen from across
>> the species' geographic range) were grown in a glasshouse under two
>> different watering regimes (Water = Control vs. Drought). DryMass is
>> the response variable. There was about 20 individuals from each
>> population grown in each Water treatment.
>>
>> Population is a random effect, but I would like to test for an
>> interaction between Population and Water -to ask the question: do
>> different populations respond differently to drought?
>>
>>> From what I can gather this is analogous the random intercepts and
>>> slopes model discussed in Zuur et al and elsewhere, except that I
>>> am examining a categorical predictor (Water) rather than a
>>> continuous predictor.
>>
>> Am I right in thinking that the basic syntax using lme is:
>>
>> lme(DryMass~Water,random=~Water|Population)
>>
>> and the syntax using lmer is:
>>
>> lmer(DryMass~Water+(Water|Population))
>
>  I think this is exactly right (and I disagree with the other
> respondent who thought you should just use a fixed effect: you may  
> well
> be interested in the among-population variation within the species in
> drought response).  One of the nice things about this formulation is
> that it allows you to look at/test the relationship between  
> variation in
> Control growth and drought response -- i.e., is there a tradeoff  
> between
> growth under good conditions and drought tolerance? -- by looking at
> the covariance in the random effects.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From bolker at ufl.edu  Mon Apr  5 13:55:07 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Mon, 05 Apr 2010 07:55:07 -0400
Subject: [R-sig-ME] Interactions between fixed and random effects
In-Reply-To: <7B489AAD-4AF9-4F94-BEEB-2136C463E4F3@queensu.ca>
References: <FA03F24C-F8AC-4804-9ED5-58FD658E4E91@queensu.ca>
	<4BB9C94D.1000101@ufl.edu>
	<7B489AAD-4AF9-4F94-BEEB-2136C463E4F3@queensu.ca>
Message-ID: <4BB9CF9B.9050409@ufl.edu>


  [cc'ing back to r-sig-mixed]

Christopher Eckert wrote:

> Among the populations sampled we do have an expectation of the form
> of the interaction. Populations were sampled across a latitudinal
> gradient and those from further south (these plants are on the
> California coast) should be less affected to a lesser extent by
> drought. Given that, do you think the random effects model is still
> best.

  I would add consider adding latitude in the model as a (continuous)
fixed effect; the random effects are then interpreted as
population-level deviations from the expectation based on the
latitudinal gradient.

 lmer(DryMass~Water*Latitude+(Water|Population))



From bates at stat.wisc.edu  Mon Apr  5 16:40:02 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 5 Apr 2010 09:40:02 -0500
Subject: [R-sig-ME] lme and prediction intervals
In-Reply-To: <4BB942CA.1040909@ufl.edu>
References: <dcf23fb81002180925o2a82d2a4xea95799c547753c5@mail.gmail.com>
	<dcf23fb81002252132u7fd4b01ft5a3232e51fcfc73@mail.gmail.com>
	<t2ydcf23fb81004032212p656253e4v42234d8a5b90a669@mail.gmail.com>
	<v2y40e66e0b1004040538qc2cfe08ag975cbdc65a9e4326@mail.gmail.com>
	<4BB942CA.1040909@ufl.edu>
Message-ID: <r2n40e66e0b1004050740wcb2f1317m6d29ed4b288d262f@mail.gmail.com>

On Sun, Apr 4, 2010 at 8:54 PM, Ben Bolker <bolker at ufl.edu> wrote:
> Douglas Bates wrote:
>> On Sat, Apr 3, 2010 at 11:12 PM, D Chaws <cat.dev.urandom at gmail.com> wrote:
>>> Ok, issue solved for the most straightforward random effects cases.
>>> Not sure about nested random effects or more complex cases.
>>
>> Assuming that you can make sense of lsmeans in such a case. ?You may
>> notice that lsmeans are not provided in base and recommended R
>> packages. ?That isn't an oversight. ?Try to explain what lsmeans are
>> in terms of the probability model.
>>
>> Anyway, if you are happy with it, then go for it. ?I'll just give you
>> a warning from a professional statistician that they are a nonsensical
>> construction.
>
> ?lsmeans may not make sense in general (I don't really know, I have a
> somewhat weird background that mostly doesn't include SAS), but there's
> nothing wrong with wanting predictions and standard errors of
> predictions, which be definable (?) if one can specify (a) whether a
> given random effect is set to zero or included at its conditional
> mean/mode value (or, for a simulation, chosen from a normal distribution
> with the appropriate variance-covariance structure (b) whether random
> effects not included in the prediction (and the residual error) are
> included in the SE or not. ?I agree that specifying all this is not as
> easy as specifying "level", but can't one in principle do this by
> specifying which random effects are in/out of the prediction or the SE?

Your first sentence is absolutely right - those whose backgrounds do
not include an introduction to SASspeak have difficulty in
understanding what lsmeans are, and that group includes me.  Once
again, I have phrased my objections poorly.  What I should have said
is that I do not understand what lsmeans are.  I have tried to read
the documentation on them in various SAS publications and also in some
books and I still can't make sense of them.

I have a strong suspicion that, for most users, the definition of
lsmeans is "the numbers that I get from SAS when I use an lsmeans
statement".  My suggestion for obtaining such numbers is to buy a SAS
license and use SAS to fit your models.

Those who have read Bill Venables unpublished paper, "Exegeses on
Linear Models" (just put the title into a search engine) will
recognize this situation.  Insightfull or whatever their name was at
the time had important customers (read "pharmaceutical companies") who
wanted them to change S-PLUS so that it created both Type I and Type
III sums of squares.  They consulted with statisticians who knew
S-PLUS well who told them "don't do that, it doesn't make sense".  Of
course the marketing folks won out and the company proceeded to ignore
this advice and implement (poorly) the Type X sums of squares where X
is the number that means "give me something that I will regard as a
marginal sum of squares for a factor in the presence of non-ignorable
interactions".  Apparently the fact that such a concept doesn't make
sense is not an adequate reason to avoid emulating SAS in producing
these numbers.

I should have phrased my objection as a deficiency in my background.
I don't know what lsmeans are and therefore cannot advise anyone on
how to calculate them.  If you or anyone else can explain to me - in
terms of the random variables Y and B and the model parameters - what
you wish to calculate then I can indicate how it could be calculated.
I think that lsmeans are, in some sense, elements of the mean of Y but
I don't know if they are conditional on a value of B or not.  If they
are means of Y then there must be a parameter vector beta specified.
This is where I begin to lose it.  Many people believe that they can
specify an incomplete parameter vector and evaluate something that
represents means.  In other words, many people believe that when there
are multiple factors in the fixed-effects formula they can evaluate
the mean response for levels of factor A in some way that is marginal
with respect to the levels of the other factors or numerical
covariates.  I can't understand how that can be done.

So I need to know what the values of the fixed-effects parameters,
beta, should be and whether you want to condition on a particular
value, B = b, or evaluate the mean of the marginal distribution of Y,
in the sense of integrating with respect to the distribution of B.  If
the latter, then you need to specify the parameters that determine the
distribution of B.  If the former, then I imagine that you wish to
evaluate the mean of the distribution of Y conditional on B at the
BLUPs.  As you know I prefer to use the term "conditional means" or,
for more general models like GLMMs, "conditional modes", instead of
BLUPs.  The values returned by ranef for a linear mixed model are the
conditional means of B given the observed value Y = y evaluated at the
parameter estimates.  To say that you want the conditional mean of Y
given B = the conditional mean of B given the observed y is a bit too
intricate for me to understand.  I really don't know how to interpret
such a concept.

> ?My hope is that, after building code for a reasonable number of
> examples, the general principles will become sufficiently clear that a
> method with an appropriate interface can then be written (note use of
> the passive voice). ?The hardest part I discovered for doing this with
> existing lme and lme4 objects is recalculating the random-effects design
> matrix appropriately when a new set of data (with different
> random-effects factor structure) is specified ...

You may find the sparse.model.matrix function in the Matrix package helpful.



From cat.dev.urandom at gmail.com  Tue Apr  6 04:48:33 2010
From: cat.dev.urandom at gmail.com (D Chaws)
Date: Mon, 5 Apr 2010 22:48:33 -0400
Subject: [R-sig-ME] lme and prediction intervals
In-Reply-To: <r2n40e66e0b1004050740wcb2f1317m6d29ed4b288d262f@mail.gmail.com>
References: <dcf23fb81002180925o2a82d2a4xea95799c547753c5@mail.gmail.com>
	<dcf23fb81002252132u7fd4b01ft5a3232e51fcfc73@mail.gmail.com>
	<t2ydcf23fb81004032212p656253e4v42234d8a5b90a669@mail.gmail.com>
	<v2y40e66e0b1004040538qc2cfe08ag975cbdc65a9e4326@mail.gmail.com>
	<4BB942CA.1040909@ufl.edu>
	<r2n40e66e0b1004050740wcb2f1317m6d29ed4b288d262f@mail.gmail.com>
Message-ID: <t2zdcf23fb81004051948n7ad56e91tf0d987b1a6e648e2@mail.gmail.com>

I knew bringing up lsmeans would get a response out of Doug :)

I certainly believe that lsmeans can spit out garbage, like any other
function (including
R/lme/etc...), but how is the routine a "nonsensical construction"?
It generates a list of
values associated with a design matrix and set of model parameters.  That seems
reasonable, as long as you request something reasonable.  It it also
seems reasonable
to want to know the SEs of such values.  Sure lsmeans has a bunch of
crazy bells and
whistles that may be questionable, and I realize the name "least
squares means" doesn't
mean much of anything I can understand, but at its base the routine
appears to be the
same as predict.lme.  What's so wrong with that?

At the very beginning of this thread I listed exactly what I wanted to calculate
based on data in lme, a known model, set of parameters, and design
matrix.  Others
have been asking about this for years, with no solution.  Again, take the model:

fm1 <- lme(distance ~ age*Sex, random = ~ 1 + age | Subject, data = Orthodont)

Wouldn't it be interesting to see how the distance/age relationships changes
for Males and Females?  Ok, then:

newdat <- expand.grid(age=c(8,10,12,14), Sex=c("Male","Female"))
newdat$pred <- predict(fm1, newdat, level = 0)
R# newdat
 age    Sex  pred
1   8   Male 22.62
2  10   Male 24.18
3  12   Male 25.75
4  14   Male 27.32
5   8 Female 21.21
6  10 Female 22.17
7  12 Female 23.13
8  14 Female 24.09

As a professional statistician, what is the appropriate method to
compute the SE of these predictions which accounts for the variance of
the fixed and random effects?

-- DC

On Mon, Apr 5, 2010 at 10:40 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
> On Sun, Apr 4, 2010 at 8:54 PM, Ben Bolker <bolker at ufl.edu> wrote:
>> Douglas Bates wrote:
>>> On Sat, Apr 3, 2010 at 11:12 PM, D Chaws <cat.dev.urandom at gmail.com> wrote:
>>>> Ok, issue solved for the most straightforward random effects cases.
>>>> Not sure about nested random effects or more complex cases.
>>>
>>> Assuming that you can make sense of lsmeans in such a case.  You may
>>> notice that lsmeans are not provided in base and recommended R
>>> packages.  That isn't an oversight.  Try to explain what lsmeans are
>>> in terms of the probability model.
>>>
>>> Anyway, if you are happy with it, then go for it.  I'll just give you
>>> a warning from a professional statistician that they are a nonsensical
>>> construction.
>>
>>  lsmeans may not make sense in general (I don't really know, I have a
>> somewhat weird background that mostly doesn't include SAS), but there's
>> nothing wrong with wanting predictions and standard errors of
>> predictions, which be definable (?) if one can specify (a) whether a
>> given random effect is set to zero or included at its conditional
>> mean/mode value (or, for a simulation, chosen from a normal distribution
>> with the appropriate variance-covariance structure (b) whether random
>> effects not included in the prediction (and the residual error) are
>> included in the SE or not.  I agree that specifying all this is not as
>> easy as specifying "level", but can't one in principle do this by
>> specifying which random effects are in/out of the prediction or the SE?
>
> Your first sentence is absolutely right - those whose backgrounds do
> not include an introduction to SASspeak have difficulty in
> understanding what lsmeans are, and that group includes me.  Once
> again, I have phrased my objections poorly.  What I should have said
> is that I do not understand what lsmeans are.  I have tried to read
> the documentation on them in various SAS publications and also in some
> books and I still can't make sense of them.
>
> I have a strong suspicion that, for most users, the definition of
> lsmeans is "the numbers that I get from SAS when I use an lsmeans
> statement".  My suggestion for obtaining such numbers is to buy a SAS
> license and use SAS to fit your models.
>
> Those who have read Bill Venables unpublished paper, "Exegeses on
> Linear Models" (just put the title into a search engine) will
> recognize this situation.  Insightfull or whatever their name was at
> the time had important customers (read "pharmaceutical companies") who
> wanted them to change S-PLUS so that it created both Type I and Type
> III sums of squares.  They consulted with statisticians who knew
> S-PLUS well who told them "don't do that, it doesn't make sense".  Of
> course the marketing folks won out and the company proceeded to ignore
> this advice and implement (poorly) the Type X sums of squares where X
> is the number that means "give me something that I will regard as a
> marginal sum of squares for a factor in the presence of non-ignorable
> interactions".  Apparently the fact that such a concept doesn't make
> sense is not an adequate reason to avoid emulating SAS in producing
> these numbers.
>
> I should have phrased my objection as a deficiency in my background.
> I don't know what lsmeans are and therefore cannot advise anyone on
> how to calculate them.  If you or anyone else can explain to me - in
> terms of the random variables Y and B and the model parameters - what
> you wish to calculate then I can indicate how it could be calculated.
> I think that lsmeans are, in some sense, elements of the mean of Y but
> I don't know if they are conditional on a value of B or not.  If they
> are means of Y then there must be a parameter vector beta specified.
> This is where I begin to lose it.  Many people believe that they can
> specify an incomplete parameter vector and evaluate something that
> represents means.  In other words, many people believe that when there
> are multiple factors in the fixed-effects formula they can evaluate
> the mean response for levels of factor A in some way that is marginal
> with respect to the levels of the other factors or numerical
> covariates.  I can't understand how that can be done.
>
> So I need to know what the values of the fixed-effects parameters,
> beta, should be and whether you want to condition on a particular
> value, B = b, or evaluate the mean of the marginal distribution of Y,
> in the sense of integrating with respect to the distribution of B.  If
> the latter, then you need to specify the parameters that determine the
> distribution of B.  If the former, then I imagine that you wish to
> evaluate the mean of the distribution of Y conditional on B at the
> BLUPs.  As you know I prefer to use the term "conditional means" or,
> for more general models like GLMMs, "conditional modes", instead of
> BLUPs.  The values returned by ranef for a linear mixed model are the
> conditional means of B given the observed value Y = y evaluated at the
> parameter estimates.  To say that you want the conditional mean of Y
> given B = the conditional mean of B given the observed y is a bit too
> intricate for me to understand.  I really don't know how to interpret
> such a concept.
>
>>  My hope is that, after building code for a reasonable number of
>> examples, the general principles will become sufficiently clear that a
>> method with an appropriate interface can then be written (note use of
>> the passive voice).  The hardest part I discovered for doing this with
>> existing lme and lme4 objects is recalculating the random-effects design
>> matrix appropriately when a new set of data (with different
>> random-effects factor structure) is specified ...
>
> You may find the sparse.model.matrix function in the Matrix package helpful.
>



From acdelre at gmail.com  Tue Apr  6 16:31:24 2010
From: acdelre at gmail.com (AC Del Re)
Date: Tue, 6 Apr 2010 09:31:24 -0500
Subject: [R-sig-ME] MLM of Longitudinal Data
Message-ID: <y2k85cf8f8d1004060731ia029b017m5916fc0e307fd79b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100406/9c73e06e/attachment.pl>

From tim.carnus at gmail.com  Tue Apr  6 16:34:17 2010
From: tim.carnus at gmail.com (Tim Carnus)
Date: Tue, 06 Apr 2010 15:34:17 +0100
Subject: [R-sig-ME] poisson GLMER with identity link
In-Reply-To: <4BB60FAA.1030004@ufl.edu>
References: <1269881108.3596.24.camel@tim-laptop>
	<1270145575.7583.16.camel@tim-laptop>  <4BB60FAA.1030004@ufl.edu>
Message-ID: <1270564457.1975.26.camel@tim-laptop>


Thanks for response and simulation example.
The problem was in all cases very simply solved by following the error
instructions to provide starting values... those from the canonical
poisson family did the trick nicely. 


On Fri, 2010-04-02 at 11:39 -0400, Ben Bolker wrote:
> I don't think there is a way to do this without hacking.
>   I don't know what glm.fit does, internally, to address this situation
> -- certainly one gets a lot of warnings, but it does come up with a
> reasonably sensible answer (once reasonable starting values have been
> specified).
>   If I were going to hack this I would go into lmer.c , find the
> location where the warning occurred, and change the code to set the
> offending value to a feasible (non-negative) value instead (giving a
> warning).  Slightly more conservatively you could set a threshold below
> which the value was adjusted with a warning and above which an error
> occurred.
> 
> > x = runif(100)
> > y = rpois(100,4*x)
> > glm(y~x,family=poisson(link="identity"))
> Error: no valid set of coefficients has been found: please supply
> starting values
> In addition: Warning message:
> In log(ifelse(y == 0, 1, y/mu)) : NaNs produced
> > glm(y~x,family=poisson(link="identity"),start=c(0.1,4))
> 
> Call:  glm(formula = y ~ x, family = poisson(link = "identity"), start =
> c(0.1,      4))
> 
> Coefficients:
> (Intercept)            x
>    -0.01669      4.28255
> 
> Degrees of Freedom: 99 Total (i.e. Null);  98 Residual
> Null Deviance:	    176.8
> Residual Deviance: 87.02 	AIC: 295
> There were 15 warnings (use warnings() to see them)
> > warnings()
> Warning messages:
> 1: step size truncated: out of bounds
> 2: step size truncated: out of bounds
> 3: step size truncated: out of bounds
> 4: step size truncated: out of bounds
> 5: step size truncated: out of bounds
> 6: step size truncated: out of bounds
> 7: step size truncated: out of bounds
> 8: step size truncated: out of bounds
> 9: step size truncated: out of bounds
> 10: step size truncated: out of bounds
> 11: step size truncated: out of bounds
> 12: step size truncated: out of bounds
> 13: step size truncated: out of bounds
> 14: In glm.fit(x = X, y = Y, weights = weights, start = start,  ... :
>   algorithm stopped at boundary value
> 15: In glm.fit(x = X, y = Y, weights = weights, start = start,  ... :
>   fitted rates numerically 0 occurred
> 
> 
> Tim Carnus wrote:
> > Dear list,
> > 
> > Just adding an example of the model I am fitting, and session info.
> > 
> > model<-glmer(count~-1+X1+X2+X3+X4+(1|plot),poisson(link='identity'),
> > REML=TRUE)
> > 
> > where I am interested in the additive effects of X1-X4 on the count per
> > plot response. The random effect is simply there to account for the
> > repeated measures taken over time on each plot.
> > 
> > R version 2.10.1 (2009-12-14) 
> > i486-pc-linux-gnu 
> > 
> > 
> > 
> > On Mon, 2010-03-29 at 17:45 +0100, Tim Carnus wrote:
> >> Dear list,
> >>
> >> I am trying to fit a number of GLMERs to count data with an additive
> >> model (in the predictors) that requires the use of the identity link
> >> function. For about half of my response variables this causes no
> >> problems. However in a number of cases the model fitting runs into
> >> problems with regards estimation of negative mean (for e.g. the error
> >> message in mer_finalize: mu[i] must be positive: mu = 1.76267e-312, i =
> >> 13075456). As far as I understand this is well known and documented, and
> >> guarding against that possibility is necessary, and built in to say the
> >> glm() function.
> >>
> >> My question then is, how can I do this with lmer? (ie how can I specify
> >> the constraints necessary to fit these types of models, if at all
> >> possible)
> >>
> >> Best regards,
> >>
> >> Tim Carnus
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
>



From j.hadfield at ed.ac.uk  Tue Apr  6 18:59:29 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 6 Apr 2010 17:59:29 +0100
Subject: [R-sig-ME] lme and prediction intervals
In-Reply-To: <t2zdcf23fb81004051948n7ad56e91tf0d987b1a6e648e2@mail.gmail.com>
References: <dcf23fb81002180925o2a82d2a4xea95799c547753c5@mail.gmail.com>
	<dcf23fb81002252132u7fd4b01ft5a3232e51fcfc73@mail.gmail.com>
	<t2ydcf23fb81004032212p656253e4v42234d8a5b90a669@mail.gmail.com>
	<v2y40e66e0b1004040538qc2cfe08ag975cbdc65a9e4326@mail.gmail.com>
	<4BB942CA.1040909@ufl.edu>
	<r2n40e66e0b1004050740wcb2f1317m6d29ed4b288d262f@mail.gmail.com>
	<t2zdcf23fb81004051948n7ad56e91tf0d987b1a6e648e2@mail.gmail.com>
Message-ID: <62EFF908-0131-4846-8A32-EB8D79C39DBB@ed.ac.uk>

Hi,

I have written a predict function for MCMCglmm, would anyone like to  
beta test it before I release it?

It computes confidence intervals (credible intervals on f(x) where x  
are the model parameters) and prediction intervals (posterior  
predictive intervals of future observations).

Residuals are always marginalised. Random terms can be marginalised or  
not. I have no issue with having a random effect in x, but that's my  
persuasion.

For some distributions the predictions can be made on the data scale,  
but I'm having trouble formulating a general solution for things like  
ZIPs and ordinal models. Any suggestions or suggested reading welcome.

I have tested it on a few data sets and it looks reasonable. However,  
I will be busy with field work soon and will not have time to test it  
thoroughly in the near future.

Cheers,

Jarrod

On 6 Apr 2010, at 03:48, D Chaws wrote:

> I knew bringing up lsmeans would get a response out of Doug :)
>
> I certainly believe that lsmeans can spit out garbage, like any other
> function (including
> R/lme/etc...), but how is the routine a "nonsensical construction"?
> It generates a list of
> values associated with a design matrix and set of model parameters.   
> That seems
> reasonable, as long as you request something reasonable.  It it also
> seems reasonable
> to want to know the SEs of such values.  Sure lsmeans has a bunch of
> crazy bells and
> whistles that may be questionable, and I realize the name "least
> squares means" doesn't
> mean much of anything I can understand, but at its base the routine
> appears to be the
> same as predict.lme.  What's so wrong with that?
>
> At the very beginning of this thread I listed exactly what I wanted  
> to calculate
> based on data in lme, a known model, set of parameters, and design
> matrix.  Others
> have been asking about this for years, with no solution.  Again,  
> take the model:
>
> fm1 <- lme(distance ~ age*Sex, random = ~ 1 + age | Subject, data =  
> Orthodont)
>
> Wouldn't it be interesting to see how the distance/age relationships  
> changes
> for Males and Females?  Ok, then:
>
> newdat <- expand.grid(age=c(8,10,12,14), Sex=c("Male","Female"))
> newdat$pred <- predict(fm1, newdat, level = 0)
> R# newdat
> age    Sex  pred
> 1   8   Male 22.62
> 2  10   Male 24.18
> 3  12   Male 25.75
> 4  14   Male 27.32
> 5   8 Female 21.21
> 6  10 Female 22.17
> 7  12 Female 23.13
> 8  14 Female 24.09
>
> As a professional statistician, what is the appropriate method to
> compute the SE of these predictions which accounts for the variance of
> the fixed and random effects?
>
> -- DC
>
> On Mon, Apr 5, 2010 at 10:40 AM, Douglas Bates <bates at stat.wisc.edu>  
> wrote:
>> On Sun, Apr 4, 2010 at 8:54 PM, Ben Bolker <bolker at ufl.edu> wrote:
>>> Douglas Bates wrote:
>>>> On Sat, Apr 3, 2010 at 11:12 PM, D Chaws  
>>>> <cat.dev.urandom at gmail.com> wrote:
>>>>> Ok, issue solved for the most straightforward random effects  
>>>>> cases.
>>>>> Not sure about nested random effects or more complex cases.
>>>>
>>>> Assuming that you can make sense of lsmeans in such a case.  You  
>>>> may
>>>> notice that lsmeans are not provided in base and recommended R
>>>> packages.  That isn't an oversight.  Try to explain what lsmeans  
>>>> are
>>>> in terms of the probability model.
>>>>
>>>> Anyway, if you are happy with it, then go for it.  I'll just give  
>>>> you
>>>> a warning from a professional statistician that they are a  
>>>> nonsensical
>>>> construction.
>>>
>>> lsmeans may not make sense in general (I don't really know, I have a
>>> somewhat weird background that mostly doesn't include SAS), but  
>>> there's
>>> nothing wrong with wanting predictions and standard errors of
>>> predictions, which be definable (?) if one can specify (a) whether a
>>> given random effect is set to zero or included at its conditional
>>> mean/mode value (or, for a simulation, chosen from a normal  
>>> distribution
>>> with the appropriate variance-covariance structure (b) whether  
>>> random
>>> effects not included in the prediction (and the residual error) are
>>> included in the SE or not.  I agree that specifying all this is  
>>> not as
>>> easy as specifying "level", but can't one in principle do this by
>>> specifying which random effects are in/out of the prediction or  
>>> the SE?
>>
>> Your first sentence is absolutely right - those whose backgrounds do
>> not include an introduction to SASspeak have difficulty in
>> understanding what lsmeans are, and that group includes me.  Once
>> again, I have phrased my objections poorly.  What I should have said
>> is that I do not understand what lsmeans are.  I have tried to read
>> the documentation on them in various SAS publications and also in  
>> some
>> books and I still can't make sense of them.
>>
>> I have a strong suspicion that, for most users, the definition of
>> lsmeans is "the numbers that I get from SAS when I use an lsmeans
>> statement".  My suggestion for obtaining such numbers is to buy a SAS
>> license and use SAS to fit your models.
>>
>> Those who have read Bill Venables unpublished paper, "Exegeses on
>> Linear Models" (just put the title into a search engine) will
>> recognize this situation.  Insightfull or whatever their name was at
>> the time had important customers (read "pharmaceutical companies")  
>> who
>> wanted them to change S-PLUS so that it created both Type I and Type
>> III sums of squares.  They consulted with statisticians who knew
>> S-PLUS well who told them "don't do that, it doesn't make sense".  Of
>> course the marketing folks won out and the company proceeded to  
>> ignore
>> this advice and implement (poorly) the Type X sums of squares where X
>> is the number that means "give me something that I will regard as a
>> marginal sum of squares for a factor in the presence of non-ignorable
>> interactions".  Apparently the fact that such a concept doesn't make
>> sense is not an adequate reason to avoid emulating SAS in producing
>> these numbers.
>>
>> I should have phrased my objection as a deficiency in my background.
>> I don't know what lsmeans are and therefore cannot advise anyone on
>> how to calculate them.  If you or anyone else can explain to me - in
>> terms of the random variables Y and B and the model parameters - what
>> you wish to calculate then I can indicate how it could be calculated.
>> I think that lsmeans are, in some sense, elements of the mean of Y  
>> but
>> I don't know if they are conditional on a value of B or not.  If they
>> are means of Y then there must be a parameter vector beta specified.
>> This is where I begin to lose it.  Many people believe that they can
>> specify an incomplete parameter vector and evaluate something that
>> represents means.  In other words, many people believe that when  
>> there
>> are multiple factors in the fixed-effects formula they can evaluate
>> the mean response for levels of factor A in some way that is marginal
>> with respect to the levels of the other factors or numerical
>> covariates.  I can't understand how that can be done.
>>
>> So I need to know what the values of the fixed-effects parameters,
>> beta, should be and whether you want to condition on a particular
>> value, B = b, or evaluate the mean of the marginal distribution of Y,
>> in the sense of integrating with respect to the distribution of B.   
>> If
>> the latter, then you need to specify the parameters that determine  
>> the
>> distribution of B.  If the former, then I imagine that you wish to
>> evaluate the mean of the distribution of Y conditional on B at the
>> BLUPs.  As you know I prefer to use the term "conditional means" or,
>> for more general models like GLMMs, "conditional modes", instead of
>> BLUPs.  The values returned by ranef for a linear mixed model are the
>> conditional means of B given the observed value Y = y evaluated at  
>> the
>> parameter estimates.  To say that you want the conditional mean of Y
>> given B = the conditional mean of B given the observed y is a bit too
>> intricate for me to understand.  I really don't know how to interpret
>> such a concept.
>>
>>> My hope is that, after building code for a reasonable number of
>>> examples, the general principles will become sufficiently clear  
>>> that a
>>> method with an appropriate interface can then be written (note use  
>>> of
>>> the passive voice).  The hardest part I discovered for doing this  
>>> with
>>> existing lme and lme4 objects is recalculating the random-effects  
>>> design
>>> matrix appropriately when a new set of data (with different
>>> random-effects factor structure) is specified ...
>>
>> You may find the sparse.model.matrix function in the Matrix package  
>> helpful.
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From itaymay at gmail.com  Tue Apr  6 20:45:12 2010
From: itaymay at gmail.com (Itay Mayrose)
Date: Tue, 6 Apr 2010 11:45:12 -0700
Subject: [R-sig-ME] lme: random effect nested within fixed effect
Message-ID: <n2wab24bf531004061145y9298cfebo424dcf837a502a2b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100406/ccf50925/attachment.pl>

From andydolman at gmail.com  Tue Apr  6 21:13:49 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Tue, 6 Apr 2010 21:13:49 +0200
Subject: [R-sig-ME] lme: random effect nested within fixed effect
In-Reply-To: <n2wab24bf531004061145y9298cfebo424dcf837a502a2b@mail.gmail.com>
References: <n2wab24bf531004061145y9298cfebo424dcf837a502a2b@mail.gmail.com>
Message-ID: <u2h951234ac1004061213x502852b6re8188bc9c6258a77@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100406/9ea4f784/attachment.pl>

From andydolman at gmail.com  Tue Apr  6 22:43:15 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Tue, 6 Apr 2010 22:43:15 +0200
Subject: [R-sig-ME] lme: random effect nested within fixed effect
In-Reply-To: <r2vab24bf531004061224ld7094c33i417fccb31f114a33@mail.gmail.com>
References: <n2wab24bf531004061145y9298cfebo424dcf837a502a2b@mail.gmail.com>
	<u2h951234ac1004061213x502852b6re8188bc9c6258a77@mail.gmail.com>
	<r2vab24bf531004061224ld7094c33i417fccb31f114a33@mail.gmail.com>
Message-ID: <h2r951234ac1004061343xea79a34dra8e677f6805f02cb@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100406/a9a16e26/attachment.pl>

From bolker at ufl.edu  Tue Apr  6 22:54:11 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 06 Apr 2010 16:54:11 -0400
Subject: [R-sig-ME] lme: random effect nested within fixed effect
In-Reply-To: <h2r951234ac1004061343xea79a34dra8e677f6805f02cb@mail.gmail.com>
References: <n2wab24bf531004061145y9298cfebo424dcf837a502a2b@mail.gmail.com>	<u2h951234ac1004061213x502852b6re8188bc9c6258a77@mail.gmail.com>	<r2vab24bf531004061224ld7094c33i417fccb31f114a33@mail.gmail.com>
	<h2r951234ac1004061343xea79a34dra8e677f6805f02cb@mail.gmail.com>
Message-ID: <4BBB9F73.2080709@ufl.edu>

  in general "nested" is used to apply to the relationship between
random effects, not to the relationship between fixed & random effects
-- the relationship between random (population) and fixed (type) would
actually be an interaction between random and fixed.

  I'm still not 100% sure of the meaning of the design, but I would
strongly consider whether simply pooling (i.e., taking means) of
individuals within populations would make sense -- there's a nice paper
by Murtaugh (2009) in Ecology or Ecological Applications that makes this
point.  Then you wouldn't have to mess with mixed models at all, you
would just have 'populations' as your sample points.

Andrew Dolman wrote:
> I wouldn't consider population to be nested within type or type to be a
> random effect. You've measured growth of individuals of three different
> types (a fixed effect) and the individuals were grouped in populations so
> perhaps should not be considered totally independent data points. The random
> structure ~ 1 | population  reflects this sampling structure.
> 
> Andy.
> 
> andydolman at gmail.com
> 
> 
> On 6 April 2010 21:24, Itay Mayrose <itaymay at gmail.com> wrote:
> 
>> thanks Andy!
>>
>> what I am a bit confused about is that I am not sure how does this account
>> for population nested within type so I thought the second option is the most
>> sensible:
>>
>>
>> z1 <- lme(growth ~ type, random = ~ 1 | type/population, data =
>> times,method="ML")
>>
>> itay
>>
>>
>>
>> On Tue, Apr 6, 2010 at 12:13 PM, Andrew Dolman <andydolman at gmail.com>wrote:
>>
>>> Hi Itay,
>>>
>>> I think what you want is the following.
>>>
>>>
>>> z0 <- lme(growth ~ 1,     random = ~ 1 | population, data =
>>> times,method="ML")
>>>
>>>
>>> z1 <- lme(growth ~ type, random = ~ 1 | population, data =
>>> times,method="ML")
>>>
>>> anova(z0,z1)
>>>
>>>
>>> This tests for differences in growth between plant types while allowing
>>> growth rates to vary randomly between populations - or to look at it a
>>> different way, it accounts for individuals within populations being more
>>> similar to each other on average than individuals from different
>>> populations.
>>>
>>>
>>> A construction like this
>>>
>>> z1 <- lme(growth ~ type, random = ~ type | population, data =
>>> times,method="ML")
>>>
>>> allows the difference in growth between plant types to vary randomly
>>> between populations. But this would only makes sense if different plant
>>> types existed in the same populations, which does not sound to be the case
>>> here, and is asking a different question.
>>>
>>>
>>>
>>> Andy.
>>>
>>>
>>>
>>>
>>>
>>>
>>> andydolman at gmail.com
>>>
>>>
>>> On 6 April 2010 20:45, Itay Mayrose <itaymay at gmail.com> wrote:
>>>
>>>> Hi all,
>>>>
>>>>  This should be a somewhat trivial question but I am new to R and I am a
>>>> bit
>>>> puzzled with the lme syntax.
>>>>
>>>>  I would like to test for growth difference between three types of
>>>> plants.
>>>> For each plant type I randomly sampled four populations and for each
>>>> population several individuals.
>>>>
>>>>  First, I used lme where type is the fixed effect and population is
>>>> random
>>>> nested within type, but I am not sure which of the three options the
>>>> correct
>>>> syntax is:
>>>>
>>>> (1)
>>>>
>>>> z1 <- lme(growth ~ type, random = ~ 1 | population, data =
>>>> times,method="ML")
>>>>
>>>>  (2)
>>>>
>>>> z1 <- lme(growth ~ type, random = ~ 1 | type/population, data =
>>>> times,method="ML")
>>>>
>>>>  (3)
>>>>
>>>> z1 <- lme(growth ~ type, random = ~ type | population, data =
>>>> times,method="ML")
>>>>
>>>>
>>>>
>>>> I am using the ML method because I would like to contrast this model
>>>> against
>>>> a NULL model where growth does not depend on plant type (assuming the
>>>> first
>>>> syntax is correct):
>>>>
>>>> z0 <- lme(growth ~ 1, random = ~ type | population, data =
>>>> times,method="ML")
>>>>
>>>> anova(z0,z1)
>>>>
>>>>
>>>>
>>>> Thanks!
>>>> Khilik
>>>>
>>>>        [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>
>> --
>> _________________________________
>> Itay Mayrose
>> http://www.zoology.ubc.ca/~mayrose/<http://www.zoology.ubc.ca/%7Emayrose/>
>> Department of Zoology,
>> University of British Columbia
>> email: itaymay at gmail.com
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From dhsu2 at uw.edu  Tue Apr  6 23:00:08 2010
From: dhsu2 at uw.edu (David Hsu)
Date: Tue, 6 Apr 2010 14:00:08 -0700
Subject: [R-sig-ME] lme and prediction intervals
Message-ID: <u2m8e8b187b1004061400w427389fu8369097a7f89440a@mail.gmail.com>

D Chaws wrote, Tue Apr 6 04:48:33 CEST 2010:

> As a professional statistician, what is the appropriate method to
> compute the SE of these predictions which accounts for the variance of
> the fixed and random effects?

I asked the same question myself about prediction last month.  I think
Doug's response to me was, in a nutshell, how can you statistically
*define* the variance contribution of the random effects?  (Doug,
please correct me if I am wrong or over-simplifying).  After thinking
about it for awhile, I indeed can *not* see what the variance of the
random effect means from a classical perspective.

Nobody seems to have conceptual difficulties with the errors from the
fixed effects, so I'll sketch out a toy example to show how I've
thought about it in terms of the theoretical statistics that I dimly
remember (again, corrections from anyone are most welcome).

Writing it out, a simple linear model is Y ~ N( A + BX, s^2).  Our
vector of parameters in the first distribution is (theta_1) = (A, B,
s).  From a classical perspective, A and B are fixed parameters, so
that when we estimate A, B, we are maximizing the likelihood L:

L ( theta_1 | X ) = P ( Y=y | theta_1 ) = 1/sqrt (2 pi sigma^2) exp -
(Y - A - BX )^2 / sigma^2

where (theta_1) is set by definite numbers, (theta_1) = (A, B, s).

Now, thinking about the random effects model, we're saying that A is a
random effect, so it's not just a set of numbers.  Therefore A is a
random variable, distributed by A ~ N(mu, sigma^2).  Our second vector
of parameters for this distribution is (theta_2) = (mu, sigma).  On
the face of it, this doesn't necessarily seem catastrophic, since we
just want the marginal probability distribution function for Y based
on the joint probability of Y, A,

P (Y=y | theta_1) = \int^\infty_infty P ( Y=y, A=a | theta_1, theta_2) da

However, this is where I get stuck in the classical perspective.  We
need to state *something* about the quantity P ( Y=y, A=a | theta_1,
theta_2) inside the integral, but it's not clear to me what we can say
about the relationship of A and Y, and presumably theta_2 is derived
from the observations of Y.  I think Doug's point is that if we have
the probability P ( Y=y, A=a | theta_1, theta_2), you can't just use
conditioning to break it down such as:

P ( Y=y, A=a | theta_1, theta_2) *not* equal to P ( Y=y | theta_1)
times P ( A=a | theta_2)

because somehow you got (or would like to get) theta_2 based on the Y
(data) as well.  So they A and Y are not independent.

In the Bayesian perspective, I guess you'd say that the posterior =
prior x likelihood, so that:

P ( theta_1, theta_2 | A, Y)  is proportional to P ( theta_1) times P
( theta_2 | A, Y, theta_1)

and then insert some belief about the the prior distribution of
theta_1, and do this iteratively for each of the parameter values
until you get convergence.

Anyway, this is how I've thought about it.  Corrections welcome.

David


--
David Hsu
PhD Candidate, Urban Planning
University of Washington
(e-mail) dhsu2 at uw.edu



From f.calboli at imperial.ac.uk  Tue Apr  6 23:01:32 2010
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Tue, 6 Apr 2010 22:01:32 +0100
Subject: [R-sig-ME] lme: random effect nested within fixed effect
In-Reply-To: <n2wab24bf531004061145y9298cfebo424dcf837a502a2b@mail.gmail.com>
References: <n2wab24bf531004061145y9298cfebo424dcf837a502a2b@mail.gmail.com>
Message-ID: <214E364F-B02B-45A5-AAF7-C5B781BC70D6@imperial.ac.uk>

On 6 Apr 2010, at 19:45, Itay Mayrose wrote:

> Hi all,
> 
> This should be a somewhat trivial question but I am new to R and I am a bit
> puzzled with the lme syntax.
> 
> I would like to test for growth difference between three types of plants.
> For each plant type I randomly sampled four populations and for each
> population several individuals.
> 
> First, I used lme where type is the fixed effect and population is random
> nested within type, but I am not sure which of the three options the correct
> syntax is:
> 
> (1)
> 
> z1 <- lme(growth ~ type, random = ~ 1 | population, data =
> times,method="ML")

depending how you coded population the above is fine. If your have, for instance, type : A, B, C, then populations coded as 1,2,3 in each type, the syntax above will NOT work.

BUT

If you have type A, B, C, then population as 1,2,3,4,5,6 (ideally as.factor(population)), or as A1, A2, A3, B1, B2...C3, the syntax above will work as if by magic, because I have tried it many times and lme --and lmer I presume, is smart enought to see that since population A1 is only found in conjunction with type A, population is nested in type. Prof Bates can possibly give the details of why it is so, I think it's due to variance components, but I suspect you might not need the fine stats details at this point.

HTH

Federico






> 
> (2)
> 
> z1 <- lme(growth ~ type, random = ~ 1 | type/population, data =
> times,method="ML")
> 
> (3)
> 
> z1 <- lme(growth ~ type, random = ~ type | population, data =
> times,method="ML")
> 
> 
> 
> I am using the ML method because I would like to contrast this model against
> a NULL model where growth does not depend on plant type (assuming the first
> syntax is correct):
> 
> z0 <- lme(growth ~ 1, random = ~ type | population, data =
> times,method="ML")
> 
> anova(z0,z1)
> 
> 
> 
> Thanks!
> Khilik
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--
Federico C. F. Calboli
Department of Epidemiology and Biostatistics
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From andydolman at gmail.com  Tue Apr  6 23:37:05 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Tue, 6 Apr 2010 23:37:05 +0200
Subject: [R-sig-ME] lme: random effect nested within fixed effect
In-Reply-To: <214E364F-B02B-45A5-AAF7-C5B781BC70D6@imperial.ac.uk>
References: <n2wab24bf531004061145y9298cfebo424dcf837a502a2b@mail.gmail.com>
	<214E364F-B02B-45A5-AAF7-C5B781BC70D6@imperial.ac.uk>
Message-ID: <n2l951234ac1004061437y92d3c517g90d9d8a7d19c20@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100406/67f3ddd6/attachment.pl>

From danielezrajohnson at gmail.com  Tue Apr  6 23:36:35 2010
From: danielezrajohnson at gmail.com (Daniel Ezra Johnson)
Date: Tue, 6 Apr 2010 17:36:35 -0400
Subject: [R-sig-ME] lme: random effect nested within fixed effect
In-Reply-To: <4BBB9F73.2080709@ufl.edu>
References: <n2wab24bf531004061145y9298cfebo424dcf837a502a2b@mail.gmail.com>
	<u2h951234ac1004061213x502852b6re8188bc9c6258a77@mail.gmail.com>
	<r2vab24bf531004061224ld7094c33i417fccb31f114a33@mail.gmail.com>
	<h2r951234ac1004061343xea79a34dra8e677f6805f02cb@mail.gmail.com>
	<4BBB9F73.2080709@ufl.edu>
Message-ID: <6E31CC48-8A72-45DC-A7AF-29BB42595A8B@gmail.com>

Take the classic example of students nested within schools. And the  
fixed effect of interest might be two different versions of a test.

Are people saying that if the effect of interest was instead school,  
and school was made a fixed effect, that you would stop saying  
students are "nested" within school?

To me it's a valuable term. A random effect can nest in, or be crossed  
with, a fixed effect.

Dan

On Apr 6, 2010, at 4:54 PM, Ben Bolker <bolker at ufl.edu> wrote:

>  in general "nested" is used to apply to the relationship between
> random effects, not to the relationship between fixed & random effects
> -- the relationship between random (population) and fixed (type) would
> actually be an interaction between random and fixed.
>
>  I'm still not 100% sure of the meaning of the design, but I would
> strongly consider whether simply pooling (i.e., taking means) of
> individuals within populations would make sense -- there's a nice  
> paper
> by Murtaugh (2009) in Ecology or Ecological Applications that makes  
> this
> point.  Then you wouldn't have to mess with mixed models at all, you
> would just have 'populations' as your sample points.
>
> Andrew Dolman wrote:
>> I wouldn't consider population to be nested within type or type to  
>> be a
>> random effect. You've measured growth of individuals of three  
>> different
>> types (a fixed effect) and the individuals were grouped in  
>> populations so
>> perhaps should not be considered totally independent data points.  
>> The random
>> structure ~ 1 | population  reflects this sampling structure.
>>
>> Andy.
>>
>> andydolman at gmail.com
>>
>>
>> On 6 April 2010 21:24, Itay Mayrose <itaymay at gmail.com> wrote:
>>
>>> thanks Andy!
>>>
>>> what I am a bit confused about is that I am not sure how does this  
>>> account
>>> for population nested within type so I thought the second option  
>>> is the most
>>> sensible:
>>>
>>>
>>> z1 <- lme(growth ~ type, random = ~ 1 | type/population, data =
>>> times,method="ML")
>>>
>>> itay
>>>
>>>
>>>
>>> On Tue, Apr 6, 2010 at 12:13 PM, Andrew Dolman  
>>> <andydolman at gmail.com>wrote:
>>>
>>>> Hi Itay,
>>>>
>>>> I think what you want is the following.
>>>>
>>>>
>>>> z0 <- lme(growth ~ 1,     random = ~ 1 | population, data =
>>>> times,method="ML")
>>>>
>>>>
>>>> z1 <- lme(growth ~ type, random = ~ 1 | population, data =
>>>> times,method="ML")
>>>>
>>>> anova(z0,z1)
>>>>
>>>>
>>>> This tests for differences in growth between plant types while  
>>>> allowing
>>>> growth rates to vary randomly between populations - or to look at  
>>>> it a
>>>> different way, it accounts for individuals within populations  
>>>> being more
>>>> similar to each other on average than individuals from different
>>>> populations.
>>>>
>>>>
>>>> A construction like this
>>>>
>>>> z1 <- lme(growth ~ type, random = ~ type | population, data =
>>>> times,method="ML")
>>>>
>>>> allows the difference in growth between plant types to vary  
>>>> randomly
>>>> between populations. But this would only makes sense if different  
>>>> plant
>>>> types existed in the same populations, which does not sound to be  
>>>> the case
>>>> here, and is asking a different question.
>>>>
>>>>
>>>>
>>>> Andy.
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> andydolman at gmail.com
>>>>
>>>>
>>>> On 6 April 2010 20:45, Itay Mayrose <itaymay at gmail.com> wrote:
>>>>
>>>>> Hi all,
>>>>>
>>>>> This should be a somewhat trivial question but I am new to R and  
>>>>> I am a
>>>>> bit
>>>>> puzzled with the lme syntax.
>>>>>
>>>>> I would like to test for growth difference between three types of
>>>>> plants.
>>>>> For each plant type I randomly sampled four populations and for  
>>>>> each
>>>>> population several individuals.
>>>>>
>>>>> First, I used lme where type is the fixed effect and population is
>>>>> random
>>>>> nested within type, but I am not sure which of the three options  
>>>>> the
>>>>> correct
>>>>> syntax is:
>>>>>
>>>>> (1)
>>>>>
>>>>> z1 <- lme(growth ~ type, random = ~ 1 | population, data =
>>>>> times,method="ML")
>>>>>
>>>>> (2)
>>>>>
>>>>> z1 <- lme(growth ~ type, random = ~ 1 | type/population, data =
>>>>> times,method="ML")
>>>>>
>>>>> (3)
>>>>>
>>>>> z1 <- lme(growth ~ type, random = ~ type | population, data =
>>>>> times,method="ML")
>>>>>
>>>>>
>>>>>
>>>>> I am using the ML method because I would like to contrast this  
>>>>> model
>>>>> against
>>>>> a NULL model where growth does not depend on plant type  
>>>>> (assuming the
>>>>> first
>>>>> syntax is correct):
>>>>>
>>>>> z0 <- lme(growth ~ 1, random = ~ type | population, data =
>>>>> times,method="ML")
>>>>>
>>>>> anova(z0,z1)
>>>>>
>>>>>
>>>>>
>>>>> Thanks!
>>>>> Khilik
>>>>>
>>>>>       [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>
>>>
>>> --
>>> _________________________________
>>> Itay Mayrose
>>> http://www.zoology.ubc.ca/~mayrose/<http://www.zoology.ubc.ca/%7Emayrose/ 
>>> >
>>> Department of Zoology,
>>> University of British Columbia
>>> email: itaymay at gmail.com
>>>
>>
>>    [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> -- 
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / people.biology.ufl.edu/bolker
> GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From djmuser at gmail.com  Tue Apr  6 23:54:11 2010
From: djmuser at gmail.com (Dennis Murphy)
Date: Tue, 6 Apr 2010 14:54:11 -0700
Subject: [R-sig-ME] lme: random effect nested within fixed effect
In-Reply-To: <n2wab24bf531004061145y9298cfebo424dcf837a502a2b@mail.gmail.com>
References: <n2wab24bf531004061145y9298cfebo424dcf837a502a2b@mail.gmail.com>
Message-ID: <s2w9a8a6c631004061454p8e78df9aze4bf760ef6d1454f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100406/8f4f192c/attachment.pl>

From andydolman at gmail.com  Tue Apr  6 23:58:47 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Tue, 6 Apr 2010 23:58:47 +0200
Subject: [R-sig-ME] lme: random effect nested within fixed effect
In-Reply-To: <6E31CC48-8A72-45DC-A7AF-29BB42595A8B@gmail.com>
References: <n2wab24bf531004061145y9298cfebo424dcf837a502a2b@mail.gmail.com>
	<u2h951234ac1004061213x502852b6re8188bc9c6258a77@mail.gmail.com>
	<r2vab24bf531004061224ld7094c33i417fccb31f114a33@mail.gmail.com>
	<h2r951234ac1004061343xea79a34dra8e677f6805f02cb@mail.gmail.com>
	<4BBB9F73.2080709@ufl.edu>
	<6E31CC48-8A72-45DC-A7AF-29BB42595A8B@gmail.com>
Message-ID: <k2h951234ac1004061458l13ad4145s621a714896c6413d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100406/028477be/attachment.pl>

From kingsfordjones at gmail.com  Wed Apr  7 00:06:34 2010
From: kingsfordjones at gmail.com (Kingsford Jones)
Date: Tue, 6 Apr 2010 16:06:34 -0600
Subject: [R-sig-ME] lme: random effect nested within fixed effect
In-Reply-To: <n2l951234ac1004061437y92d3c517g90d9d8a7d19c20@mail.gmail.com>
References: <n2wab24bf531004061145y9298cfebo424dcf837a502a2b@mail.gmail.com> 
	<214E364F-B02B-45A5-AAF7-C5B781BC70D6@imperial.ac.uk>
	<n2l951234ac1004061437y92d3c517g90d9d8a7d19c20@mail.gmail.com>
Message-ID: <g2k2ad0cc111004061506q455433d2gbca4ae66717ad725@mail.gmail.com>

On Tue, Apr 6, 2010 at 3:37 PM, Andrew Dolman <andydolman at gmail.com> wrote:
[snip]
>
> This is not entirely correct. The syntax will work because the populations
> are uniquely labeled but it does not model population as nested within type.
> It models there being 12 populations (4 for each of the three types).
>
> These two models are not the same:
>
> lme(growth ~ type, random = ~ 1 | population) - with populations uniquely
> identified (A1, A2 ... B1) is not the same as
>
> lme(growth ~ type, random = ~ 1 | type/population) - with populations
> "nested" within type
>

~1|type/population is shorthand for wanting both ~1|type and
~1|type:population.  Since the OP isn't interested in ~1|type, and the
design indicates that ~1|type:population is the same as ~1|population
when the populations are uniquely labelled, the first of the two
models above seems correct.  The tricky part, of course, will be
determining denominator df for the type effects.


Kingsford


>
>
> Andy.
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From cat.dev.urandom at gmail.com  Wed Apr  7 06:17:58 2010
From: cat.dev.urandom at gmail.com (D Chaws)
Date: Wed, 7 Apr 2010 00:17:58 -0400
Subject: [R-sig-ME] lme and prediction intervals
In-Reply-To: <u2m8e8b187b1004061400w427389fu8369097a7f89440a@mail.gmail.com>
References: <u2m8e8b187b1004061400w427389fu8369097a7f89440a@mail.gmail.com>
Message-ID: <t2vdcf23fb81004062117v1a2ba184n52e987d5148a3359@mail.gmail.com>

Very interesting.  Is it really the state of the field that there is uncertainty
about the how to integrate random and fixed effects variance components?
That seems like quite a hole.  Does that mean the best approach is probably
an empirical one then, through something like MCMC?

-- DC

On Tue, Apr 6, 2010 at 5:00 PM, David Hsu <dhsu2 at uw.edu> wrote:
> D Chaws wrote, Tue Apr 6 04:48:33 CEST 2010:
>
>> As a professional statistician, what is the appropriate method to
>> compute the SE of these predictions which accounts for the variance of
>> the fixed and random effects?
>
> I asked the same question myself about prediction last month.  I think
> Doug's response to me was, in a nutshell, how can you statistically
> *define* the variance contribution of the random effects?  (Doug,
> please correct me if I am wrong or over-simplifying).  After thinking
> about it for awhile, I indeed can *not* see what the variance of the
> random effect means from a classical perspective.
>
> Nobody seems to have conceptual difficulties with the errors from the
> fixed effects, so I'll sketch out a toy example to show how I've
> thought about it in terms of the theoretical statistics that I dimly
> remember (again, corrections from anyone are most welcome).
>
> Writing it out, a simple linear model is Y ~ N( A + BX, s^2).  Our
> vector of parameters in the first distribution is (theta_1) = (A, B,
> s).  From a classical perspective, A and B are fixed parameters, so
> that when we estimate A, B, we are maximizing the likelihood L:
>
> L ( theta_1 | X ) = P ( Y=y | theta_1 ) = 1/sqrt (2 pi sigma^2) exp -
> (Y - A - BX )^2 / sigma^2
>
> where (theta_1) is set by definite numbers, (theta_1) = (A, B, s).
>
> Now, thinking about the random effects model, we're saying that A is a
> random effect, so it's not just a set of numbers.  Therefore A is a
> random variable, distributed by A ~ N(mu, sigma^2).  Our second vector
> of parameters for this distribution is (theta_2) = (mu, sigma).  On
> the face of it, this doesn't necessarily seem catastrophic, since we
> just want the marginal probability distribution function for Y based
> on the joint probability of Y, A,
>
> P (Y=y | theta_1) = \int^\infty_infty P ( Y=y, A=a | theta_1, theta_2) da
>
> However, this is where I get stuck in the classical perspective.  We
> need to state *something* about the quantity P ( Y=y, A=a | theta_1,
> theta_2) inside the integral, but it's not clear to me what we can say
> about the relationship of A and Y, and presumably theta_2 is derived
> from the observations of Y.  I think Doug's point is that if we have
> the probability P ( Y=y, A=a | theta_1, theta_2), you can't just use
> conditioning to break it down such as:
>
> P ( Y=y, A=a | theta_1, theta_2) *not* equal to P ( Y=y | theta_1)
> times P ( A=a | theta_2)
>
> because somehow you got (or would like to get) theta_2 based on the Y
> (data) as well.  So they A and Y are not independent.
>
> In the Bayesian perspective, I guess you'd say that the posterior =
> prior x likelihood, so that:
>
> P ( theta_1, theta_2 | A, Y)  is proportional to P ( theta_1) times P
> ( theta_2 | A, Y, theta_1)
>
> and then insert some belief about the the prior distribution of
> theta_1, and do this iteratively for each of the parameter values
> until you get convergence.
>
> Anyway, this is how I've thought about it.  Corrections welcome.
>
> David
>
>
> --
> David Hsu
> PhD Candidate, Urban Planning
> University of Washington
> (e-mail) dhsu2 at uw.edu
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From john.maindonald at anu.edu.au  Wed Apr  7 07:47:35 2010
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Wed, 7 Apr 2010 15:47:35 +1000
Subject: [R-sig-ME] lme and prediction intervals
In-Reply-To: <t2vdcf23fb81004062117v1a2ba184n52e987d5148a3359@mail.gmail.com>
References: <u2m8e8b187b1004061400w427389fu8369097a7f89440a@mail.gmail.com>
	<t2vdcf23fb81004062117v1a2ba184n52e987d5148a3359@mail.gmail.com>
Message-ID: <E6293527-7E38-4AE8-A0C4-C91D32D3F7DA@anu.edu.au>

There is no uncertainty about SEs of predictions, once the
prediction problem has been properly delimited.  As often, 
the problem has to be sufficiently well defined that "integrate 
random and fixed effects variance components" (not the 
language that I would use) has, in any specific instance, 
a well-defined meaning. Specifically, note that the SEs change
depending on the population for which predictions are made.
Use of MCMC does not cause this issue to go away, though
it may provide a way to address it once the prediction has
been properly delimited.

The DAAG package has the dataset ant111b.  One may fit 
the model:

ant111b.lme <- lme(fixed=harvwt ~ 1, random = ~1 | site, 
                   data=ant111b)

One might make predictions:
1) for a new parcel at an existing site
2) for a new parcel at a new site
3) for the average of two parcels at a new site

These will all lead to different SEs.  1 < 3 < 2

In these instances it is fairly easy, if one believes
the model, to calculate the different SEs.  

More generally, it is necessary to tease the
variance-covariance structure apart, then putting
it back together in a manner that reflects the
desired generalization.  At least for various
special cases, this can be automated, based on 
conventions for describing the intended 
generalization, and there is software that does
this. 

This is an issue for the use of AIC to compare mixed 
effects models.  There is an implicit assumption that 
generalizations are for individual units at the population 
level.  This does not necessarily reflect the intended
use of the model results.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 07/04/2010, at 2:17 PM, D Chaws wrote:

> Very interesting.  Is it really the state of the field that there is uncertainty
> about the how to integrate random and fixed effects variance components?
> That seems like quite a hole.  Does that mean the best approach is probably
> an empirical one then, through something like MCMC?
> 
> -- DC
> 
> On Tue, Apr 6, 2010 at 5:00 PM, David Hsu <dhsu2 at uw.edu> wrote:
>> D Chaws wrote, Tue Apr 6 04:48:33 CEST 2010:
>> 
>>> As a professional statistician, what is the appropriate method to
>>> compute the SE of these predictions which accounts for the variance of
>>> the fixed and random effects?
>> 
>> I asked the same question myself about prediction last month.  I think
>> Doug's response to me was, in a nutshell, how can you statistically
>> *define* the variance contribution of the random effects?  (Doug,
>> please correct me if I am wrong or over-simplifying).  After thinking
>> about it for awhile, I indeed can *not* see what the variance of the
>> random effect means from a classical perspective.
>> 
>> Nobody seems to have conceptual difficulties with the errors from the
>> fixed effects, so I'll sketch out a toy example to show how I've
>> thought about it in terms of the theoretical statistics that I dimly
>> remember (again, corrections from anyone are most welcome).
>> 
>> Writing it out, a simple linear model is Y ~ N( A + BX, s^2).  Our
>> vector of parameters in the first distribution is (theta_1) = (A, B,
>> s).  From a classical perspective, A and B are fixed parameters, so
>> that when we estimate A, B, we are maximizing the likelihood L:
>> 
>> L ( theta_1 | X ) = P ( Y=y | theta_1 ) = 1/sqrt (2 pi sigma^2) exp -
>> (Y - A - BX )^2 / sigma^2
>> 
>> where (theta_1) is set by definite numbers, (theta_1) = (A, B, s).
>> 
>> Now, thinking about the random effects model, we're saying that A is a
>> random effect, so it's not just a set of numbers.  Therefore A is a
>> random variable, distributed by A ~ N(mu, sigma^2).  Our second vector
>> of parameters for this distribution is (theta_2) = (mu, sigma).  On
>> the face of it, this doesn't necessarily seem catastrophic, since we
>> just want the marginal probability distribution function for Y based
>> on the joint probability of Y, A,
>> 
>> P (Y=y | theta_1) = \int^\infty_infty P ( Y=y, A=a | theta_1, theta_2) da
>> 
>> However, this is where I get stuck in the classical perspective.  We
>> need to state *something* about the quantity P ( Y=y, A=a | theta_1,
>> theta_2) inside the integral, but it's not clear to me what we can say
>> about the relationship of A and Y, and presumably theta_2 is derived
>> from the observations of Y.  I think Doug's point is that if we have
>> the probability P ( Y=y, A=a | theta_1, theta_2), you can't just use
>> conditioning to break it down such as:
>> 
>> P ( Y=y, A=a | theta_1, theta_2) *not* equal to P ( Y=y | theta_1)
>> times P ( A=a | theta_2)
>> 
>> because somehow you got (or would like to get) theta_2 based on the Y
>> (data) as well.  So they A and Y are not independent.
>> 
>> In the Bayesian perspective, I guess you'd say that the posterior =
>> prior x likelihood, so that:
>> 
>> P ( theta_1, theta_2 | A, Y)  is proportional to P ( theta_1) times P
>> ( theta_2 | A, Y, theta_1)
>> 
>> and then insert some belief about the the prior distribution of
>> theta_1, and do this iteratively for each of the parameter values
>> until you get convergence.
>> 
>> Anyway, this is how I've thought about it.  Corrections welcome.
>> 
>> David
>> 
>> 
>> --
>> David Hsu
>> PhD Candidate, Urban Planning
>> University of Washington
>> (e-mail) dhsu2 at uw.edu
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bates at stat.wisc.edu  Wed Apr  7 15:53:56 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 7 Apr 2010 08:53:56 -0500
Subject: [R-sig-ME] lme and prediction intervals
In-Reply-To: <E6293527-7E38-4AE8-A0C4-C91D32D3F7DA@anu.edu.au>
References: <u2m8e8b187b1004061400w427389fu8369097a7f89440a@mail.gmail.com>
	<t2vdcf23fb81004062117v1a2ba184n52e987d5148a3359@mail.gmail.com>
	<E6293527-7E38-4AE8-A0C4-C91D32D3F7DA@anu.edu.au>
Message-ID: <y2x40e66e0b1004070653ube3d58d0q419f6abefc6b825d@mail.gmail.com>

Thanks for the discussion on this point.  I think I am beginning to
understand what is requested in general although I am not sure I am
quite up to John's level of detail.

I have a formula in mind, based on what John describes as "teasing the
variance-covariance structure apart, then putting it back together",
but the justification for the calculation is still somewhat vague.

The left Choelseky factor for the penalized least squares problem to
determine the conditional estimates of the fixed effects and the
conditional modes of the random effects (also the conditional means,
in the case of a linear model) is of the form

L        0
RZX'  RX'

where L, RZX and RX are a sparse Cholesky decomposition (L), a dense q
by p matrix (RZX) and an upper triangular p by p matrix (RX), all
stored in the mer object returned by lmer.  The variance-covariance
matrix of the estimators of the fixed-effects parameters, conditional
on a value of the random effects vector is (RX'RX)^{-1} =
RX^{-1}RX^{-1}'.  (This is one of the few cases when it is appropriate
to evaluate the inverse of a matrix, because RX is triangular.).
When multiplied by s^2 this is the matrix used to evaluate standard
errors and correlations of the fixed-effects estimators.

I think what we are seeking is the marginal variance-covariance matrix
of the parameter estimators (marginal with respect to the random
effects random variable, B), which would have the form of the inverse
of the crossproduct of  a (q+p) by p matrix composed of the vertical
concatenation of - L^{-1}RZX RX^{-1} and RX^{-1}.  (Note: You do *not*
want to calculate the first term by inverting L, use solve(L, RZX,
system = "L"") - don't even think about using solve(L) - don't!,
don't!, don't! - have I made myself clear? - don't do that (and we all
know that someone will do exactly that for a very large L and then
send out messages about "R is SOOOOO SLOOOOW!!!! :-) )

Anyway, that is what I think should be calculated - something like

chol2inv(chol(tcrossprod(solve(RX, cbind(t(solve(L, RZX, system =
"L")), diag(ncol(RZX)))))

and then multiply by s^2

I haven't debugged that expression so it may some fixes.
Unfortunately there are other tasks to which I must first attend.






On Wed, Apr 7, 2010 at 12:47 AM, John Maindonald
<john.maindonald at anu.edu.au> wrote:
> There is no uncertainty about SEs of predictions, once the
> prediction problem has been properly delimited. ?As often,
> the problem has to be sufficiently well defined that "integrate
> random and fixed effects variance components" (not the
> language that I would use) has, in any specific instance,
> a well-defined meaning. Specifically, note that the SEs change
> depending on the population for which predictions are made.
> Use of MCMC does not cause this issue to go away, though
> it may provide a way to address it once the prediction has
> been properly delimited.
>
> The DAAG package has the dataset ant111b. ?One may fit
> the model:
>
> ant111b.lme <- lme(fixed=harvwt ~ 1, random = ~1 | site,
> ? ? ? ? ? ? ? ? ? data=ant111b)
>
> One might make predictions:
> 1) for a new parcel at an existing site
> 2) for a new parcel at a new site
> 3) for the average of two parcels at a new site
>
> These will all lead to different SEs. ?1 < 3 < 2
>
> In these instances it is fairly easy, if one believes
> the model, to calculate the different SEs.
>
> More generally, it is necessary to tease the
> variance-covariance structure apart, then putting
> it back together in a manner that reflects the
> desired generalization. ?At least for various
> special cases, this can be automated, based on
> conventions for describing the intended
> generalization, and there is software that does
> this.
>
> This is an issue for the use of AIC to compare mixed
> effects models. ?There is an implicit assumption that
> generalizations are for individual units at the population
> level. ?This does not necessarily reflect the intended
> use of the model results.
>
> John Maindonald ? ? ? ? ? ? email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473 ? ?fax ?: +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> http://www.maths.anu.edu.au/~johnm
>
> On 07/04/2010, at 2:17 PM, D Chaws wrote:
>
>> Very interesting. ?Is it really the state of the field that there is uncertainty
>> about the how to integrate random and fixed effects variance components?
>> That seems like quite a hole. ?Does that mean the best approach is probably
>> an empirical one then, through something like MCMC?
>>
>> -- DC
>>
>> On Tue, Apr 6, 2010 at 5:00 PM, David Hsu <dhsu2 at uw.edu> wrote:
>>> D Chaws wrote, Tue Apr 6 04:48:33 CEST 2010:
>>>
>>>> As a professional statistician, what is the appropriate method to
>>>> compute the SE of these predictions which accounts for the variance of
>>>> the fixed and random effects?
>>>
>>> I asked the same question myself about prediction last month. ?I think
>>> Doug's response to me was, in a nutshell, how can you statistically
>>> *define* the variance contribution of the random effects? ?(Doug,
>>> please correct me if I am wrong or over-simplifying). ?After thinking
>>> about it for awhile, I indeed can *not* see what the variance of the
>>> random effect means from a classical perspective.
>>>
>>> Nobody seems to have conceptual difficulties with the errors from the
>>> fixed effects, so I'll sketch out a toy example to show how I've
>>> thought about it in terms of the theoretical statistics that I dimly
>>> remember (again, corrections from anyone are most welcome).
>>>
>>> Writing it out, a simple linear model is Y ~ N( A + BX, s^2). ?Our
>>> vector of parameters in the first distribution is (theta_1) = (A, B,
>>> s). ?From a classical perspective, A and B are fixed parameters, so
>>> that when we estimate A, B, we are maximizing the likelihood L:
>>>
>>> L ( theta_1 | X ) = P ( Y=y | theta_1 ) = 1/sqrt (2 pi sigma^2) exp -
>>> (Y - A - BX )^2 / sigma^2
>>>
>>> where (theta_1) is set by definite numbers, (theta_1) = (A, B, s).
>>>
>>> Now, thinking about the random effects model, we're saying that A is a
>>> random effect, so it's not just a set of numbers. ?Therefore A is a
>>> random variable, distributed by A ~ N(mu, sigma^2). ?Our second vector
>>> of parameters for this distribution is (theta_2) = (mu, sigma). ?On
>>> the face of it, this doesn't necessarily seem catastrophic, since we
>>> just want the marginal probability distribution function for Y based
>>> on the joint probability of Y, A,
>>>
>>> P (Y=y | theta_1) = \int^\infty_infty P ( Y=y, A=a | theta_1, theta_2) da
>>>
>>> However, this is where I get stuck in the classical perspective. ?We
>>> need to state *something* about the quantity P ( Y=y, A=a | theta_1,
>>> theta_2) inside the integral, but it's not clear to me what we can say
>>> about the relationship of A and Y, and presumably theta_2 is derived
>>> from the observations of Y. ?I think Doug's point is that if we have
>>> the probability P ( Y=y, A=a | theta_1, theta_2), you can't just use
>>> conditioning to break it down such as:
>>>
>>> P ( Y=y, A=a | theta_1, theta_2) *not* equal to P ( Y=y | theta_1)
>>> times P ( A=a | theta_2)
>>>
>>> because somehow you got (or would like to get) theta_2 based on the Y
>>> (data) as well. ?So they A and Y are not independent.
>>>
>>> In the Bayesian perspective, I guess you'd say that the posterior =
>>> prior x likelihood, so that:
>>>
>>> P ( theta_1, theta_2 | A, Y) ?is proportional to P ( theta_1) times P
>>> ( theta_2 | A, Y, theta_1)
>>>
>>> and then insert some belief about the the prior distribution of
>>> theta_1, and do this iteratively for each of the parameter values
>>> until you get convergence.
>>>
>>> Anyway, this is how I've thought about it. ?Corrections welcome.
>>>
>>> David
>>>
>>>
>>> --
>>> David Hsu
>>> PhD Candidate, Urban Planning
>>> University of Washington
>>> (e-mail) dhsu2 at uw.edu
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Wed Apr  7 16:15:17 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 7 Apr 2010 09:15:17 -0500
Subject: [R-sig-ME] lme and prediction intervals
In-Reply-To: <y2x40e66e0b1004070653ube3d58d0q419f6abefc6b825d@mail.gmail.com>
References: <u2m8e8b187b1004061400w427389fu8369097a7f89440a@mail.gmail.com>
	<t2vdcf23fb81004062117v1a2ba184n52e987d5148a3359@mail.gmail.com>
	<E6293527-7E38-4AE8-A0C4-C91D32D3F7DA@anu.edu.au>
	<y2x40e66e0b1004070653ube3d58d0q419f6abefc6b825d@mail.gmail.com>
Message-ID: <t2v40e66e0b1004070715j379f82b9jec760945bc20c1e3@mail.gmail.com>

On Wed, Apr 7, 2010 at 8:53 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
> Thanks for the discussion on this point. ?I think I am beginning to
> understand what is requested in general although I am not sure I am
> quite up to John's level of detail.
>
> I have a formula in mind, based on what John describes as "teasing the
> variance-covariance structure apart, then putting it back together",
> but the justification for the calculation is still somewhat vague.
>
> The left Choelseky factor for the penalized least squares problem to
> determine the conditional estimates of the fixed effects and the
> conditional modes of the random effects (also the conditional means,
> in the case of a linear model) is of the form
>
> L ? ? ? ?0
> RZX' ?RX'
>
> where L, RZX and RX are a sparse Cholesky decomposition (L), a dense q
> by p matrix (RZX) and an upper triangular p by p matrix (RX), all
> stored in the mer object returned by lmer. ?The variance-covariance
> matrix of the estimators of the fixed-effects parameters, conditional
> on a value of the random effects vector is (RX'RX)^{-1} =
> RX^{-1}RX^{-1}'. ?(This is one of the few cases when it is appropriate
> to evaluate the inverse of a matrix, because RX is triangular.).
> When multiplied by s^2 this is the matrix used to evaluate standard
> errors and correlations of the fixed-effects estimators.
>
> I think what we are seeking is the marginal variance-covariance matrix
> of the parameter estimators (marginal with respect to the random
> effects random variable, B), which would have the form of the inverse
> of the crossproduct of ?a (q+p) by p matrix composed of the vertical
> concatenation of - L^{-1}RZX RX^{-1} and RX^{-1}. ?(Note: You do *not*
> want to calculate the first term by inverting L, use solve(L, RZX,
> system = "L"") - don't even think about using solve(L) - don't!,
> don't!, don't! - have I made myself clear? - don't do that (and we all
> know that someone will do exactly that for a very large L and then
> send out messages about "R is SOOOOO SLOOOOW!!!! :-) )

I know that someone is going to be tempted to try it and then find
that it isn't that slow.  I should have been more precise.  If you
have a nested sequence of grouping factors for the random effects
(which includes the case of a single grouping factor) then the matrix
L has a special property that they pattern of non-zeros in the inverse
is the same as the pattern in L itself.  You still don't want to
invert large matrices to solve a linear system when you can do that
directly but evaluating the inverse will not explode in complexity on
you.  However, if you try it with non-nested grouping factors it will
explode in complexity.
> Anyway, that is what I think should be calculated - something like
>
> chol2inv(chol(tcrossprod(solve(RX, cbind(t(solve(L, RZX, system =
> "L")), diag(ncol(RZX)))))
>
> and then multiply by s^2
>
> I haven't debugged that expression so it may some fixes.
> Unfortunately there are other tasks to which I must first attend.
>
>
>
>
>
>
> On Wed, Apr 7, 2010 at 12:47 AM, John Maindonald
> <john.maindonald at anu.edu.au> wrote:
>> There is no uncertainty about SEs of predictions, once the
>> prediction problem has been properly delimited. ?As often,
>> the problem has to be sufficiently well defined that "integrate
>> random and fixed effects variance components" (not the
>> language that I would use) has, in any specific instance,
>> a well-defined meaning. Specifically, note that the SEs change
>> depending on the population for which predictions are made.
>> Use of MCMC does not cause this issue to go away, though
>> it may provide a way to address it once the prediction has
>> been properly delimited.
>>
>> The DAAG package has the dataset ant111b. ?One may fit
>> the model:
>>
>> ant111b.lme <- lme(fixed=harvwt ~ 1, random = ~1 | site,
>> ? ? ? ? ? ? ? ? ? data=ant111b)
>>
>> One might make predictions:
>> 1) for a new parcel at an existing site
>> 2) for a new parcel at a new site
>> 3) for the average of two parcels at a new site
>>
>> These will all lead to different SEs. ?1 < 3 < 2
>>
>> In these instances it is fairly easy, if one believes
>> the model, to calculate the different SEs.
>>
>> More generally, it is necessary to tease the
>> variance-covariance structure apart, then putting
>> it back together in a manner that reflects the
>> desired generalization. ?At least for various
>> special cases, this can be automated, based on
>> conventions for describing the intended
>> generalization, and there is software that does
>> this.
>>
>> This is an issue for the use of AIC to compare mixed
>> effects models. ?There is an implicit assumption that
>> generalizations are for individual units at the population
>> level. ?This does not necessarily reflect the intended
>> use of the model results.
>>
>> John Maindonald ? ? ? ? ? ? email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473 ? ?fax ?: +61 2(6125)5549
>> Centre for Mathematics & Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>> http://www.maths.anu.edu.au/~johnm
>>
>> On 07/04/2010, at 2:17 PM, D Chaws wrote:
>>
>>> Very interesting. ?Is it really the state of the field that there is uncertainty
>>> about the how to integrate random and fixed effects variance components?
>>> That seems like quite a hole. ?Does that mean the best approach is probably
>>> an empirical one then, through something like MCMC?
>>>
>>> -- DC
>>>
>>> On Tue, Apr 6, 2010 at 5:00 PM, David Hsu <dhsu2 at uw.edu> wrote:
>>>> D Chaws wrote, Tue Apr 6 04:48:33 CEST 2010:
>>>>
>>>>> As a professional statistician, what is the appropriate method to
>>>>> compute the SE of these predictions which accounts for the variance of
>>>>> the fixed and random effects?
>>>>
>>>> I asked the same question myself about prediction last month. ?I think
>>>> Doug's response to me was, in a nutshell, how can you statistically
>>>> *define* the variance contribution of the random effects? ?(Doug,
>>>> please correct me if I am wrong or over-simplifying). ?After thinking
>>>> about it for awhile, I indeed can *not* see what the variance of the
>>>> random effect means from a classical perspective.
>>>>
>>>> Nobody seems to have conceptual difficulties with the errors from the
>>>> fixed effects, so I'll sketch out a toy example to show how I've
>>>> thought about it in terms of the theoretical statistics that I dimly
>>>> remember (again, corrections from anyone are most welcome).
>>>>
>>>> Writing it out, a simple linear model is Y ~ N( A + BX, s^2). ?Our
>>>> vector of parameters in the first distribution is (theta_1) = (A, B,
>>>> s). ?From a classical perspective, A and B are fixed parameters, so
>>>> that when we estimate A, B, we are maximizing the likelihood L:
>>>>
>>>> L ( theta_1 | X ) = P ( Y=y | theta_1 ) = 1/sqrt (2 pi sigma^2) exp -
>>>> (Y - A - BX )^2 / sigma^2
>>>>
>>>> where (theta_1) is set by definite numbers, (theta_1) = (A, B, s).
>>>>
>>>> Now, thinking about the random effects model, we're saying that A is a
>>>> random effect, so it's not just a set of numbers. ?Therefore A is a
>>>> random variable, distributed by A ~ N(mu, sigma^2). ?Our second vector
>>>> of parameters for this distribution is (theta_2) = (mu, sigma). ?On
>>>> the face of it, this doesn't necessarily seem catastrophic, since we
>>>> just want the marginal probability distribution function for Y based
>>>> on the joint probability of Y, A,
>>>>
>>>> P (Y=y | theta_1) = \int^\infty_infty P ( Y=y, A=a | theta_1, theta_2) da
>>>>
>>>> However, this is where I get stuck in the classical perspective. ?We
>>>> need to state *something* about the quantity P ( Y=y, A=a | theta_1,
>>>> theta_2) inside the integral, but it's not clear to me what we can say
>>>> about the relationship of A and Y, and presumably theta_2 is derived
>>>> from the observations of Y. ?I think Doug's point is that if we have
>>>> the probability P ( Y=y, A=a | theta_1, theta_2), you can't just use
>>>> conditioning to break it down such as:
>>>>
>>>> P ( Y=y, A=a | theta_1, theta_2) *not* equal to P ( Y=y | theta_1)
>>>> times P ( A=a | theta_2)
>>>>
>>>> because somehow you got (or would like to get) theta_2 based on the Y
>>>> (data) as well. ?So they A and Y are not independent.
>>>>
>>>> In the Bayesian perspective, I guess you'd say that the posterior =
>>>> prior x likelihood, so that:
>>>>
>>>> P ( theta_1, theta_2 | A, Y) ?is proportional to P ( theta_1) times P
>>>> ( theta_2 | A, Y, theta_1)
>>>>
>>>> and then insert some belief about the the prior distribution of
>>>> theta_1, and do this iteratively for each of the parameter values
>>>> until you get convergence.
>>>>
>>>> Anyway, this is how I've thought about it. ?Corrections welcome.
>>>>
>>>> David
>>>>
>>>>
>>>> --
>>>> David Hsu
>>>> PhD Candidate, Urban Planning
>>>> University of Washington
>>>> (e-mail) dhsu2 at uw.edu
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>



From 2nuzzbot at gmail.com  Wed Apr  7 18:28:36 2010
From: 2nuzzbot at gmail.com (E T)
Date: Wed, 7 Apr 2010 17:28:36 +0100
Subject: [R-sig-ME] Multi-level models Odds ratio
Message-ID: <z2m706f8d1f1004070928p43a3f49ds21f3b5ac0179625d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100407/452e06ed/attachment.pl>

From danielezrajohnson at gmail.com  Wed Apr  7 18:47:11 2010
From: danielezrajohnson at gmail.com (Daniel Ezra Johnson)
Date: Wed, 7 Apr 2010 12:47:11 -0400
Subject: [R-sig-ME] Multi-level models Odds ratio
In-Reply-To: <z2m706f8d1f1004070928p43a3f49ds21f3b5ac0179625d@mail.gmail.com>
References: <z2m706f8d1f1004070928p43a3f49ds21f3b5ac0179625d@mail.gmail.com>
Message-ID: <4A3D5F61-CB31-40C9-B16E-4247523E1842@gmail.com>

something like odds.ratios = exp(coefs(model))

On Apr 7, 2010, at 12:28 PM, E T <2nuzzbot at gmail.com> wrote:

> Hi all,
>
> Apologies for the simplicity of my question.... however any advice is
> greatly appreciated. Thanks
>
> Is there a specific command available to obtain the odds ratios  
> produced
> from a multilevel logistic model?
>
> I have estimated a multi-level logistic model using the lme4  
> package. I can
> obtain results using the 'summary' command, however I would like to  
> obtain
> the computed odds ratios.
> (Similar to the output that can be produced for logistic GLM using the
> logistic.display command from the epicalc package).
>
>    [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From charpent at bacbuc.dyndns.org  Wed Apr  7 23:36:44 2010
From: charpent at bacbuc.dyndns.org (Emmanuel Charpentier)
Date: Wed, 07 Apr 2010 23:36:44 +0200
Subject: [R-sig-ME] lme and prediction intervals
In-Reply-To: <y2x40e66e0b1004070653ube3d58d0q419f6abefc6b825d@mail.gmail.com>
References: <u2m8e8b187b1004061400w427389fu8369097a7f89440a@mail.gmail.com>
	<t2vdcf23fb81004062117v1a2ba184n52e987d5148a3359@mail.gmail.com>
	<E6293527-7E38-4AE8-A0C4-C91D32D3F7DA@anu.edu.au>
	<y2x40e66e0b1004070653ube3d58d0q419f6abefc6b825d@mail.gmail.com>
Message-ID: <1270676203.19686.72.camel@PortableToshiba>

Le mercredi 07 avril 2010 ? 08:53 -0500, Douglas Bates a ?crit :

[ Snip... ]

> I think what we are seeking is the marginal variance-covariance matrix
> of the parameter estimators (marginal with respect to the random
> effects random variable, B), which would have the form of the inverse
> of the crossproduct of  a (q+p) by p matrix composed of the vertical
> concatenation of - L^{-1}RZX RX^{-1} and RX^{-1}.  (Note: You do *not*
> want to calculate the first term by inverting L, use solve(L, RZX,
> system = "L"") - don't even think about using solve(L) - don't!,
> don't!, don't! - have I made myself clear? - don't do that (and we all
> know that someone will do exactly that for a very large L and then
> send out messages about "R is SOOOOO SLOOOOW!!!! :-) )

This *HAS* to be a fortune(), next to the "brain surgery" warning...

					Emmanuel Charpentier



From alessiag at interchange.ubc.ca  Thu Apr  8 07:50:59 2010
From: alessiag at interchange.ubc.ca (Alessia Guggisberg)
Date: Wed, 07 Apr 2010 22:50:59 -0700
Subject: [R-sig-ME] variance structure in lme/lmer
Message-ID: <5484B83D4A00471FB4456A35712C1971@Guggisberg>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100407/7520afc2/attachment.pl>

From j.hadfield at ed.ac.uk  Thu Apr  8 11:22:39 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 8 Apr 2010 10:22:39 +0100
Subject: [R-sig-ME] variance structure in lme/lmer
In-Reply-To: <5484B83D4A00471FB4456A35712C1971@Guggisberg>
References: <5484B83D4A00471FB4456A35712C1971@Guggisberg>
Message-ID: <A8CFA9F9-2A41-4882-9199-803E2DB8D91B@ed.ac.uk>

Dear Alessia,

I think the problem is that  individuals from a population all belong  
to one type (native or invasive) (is this true?) If this is the case  
your 4x4 covariance matrices needs to look like

         TreatmentControl:Rangenative   *  *  0  0
     TreatmentHerbivory:Rangenative   *  *  0  0
TreatmentHerbivory:Rangeinvasive   0  0  *  *
TreatmentHerbivory:Rangeinvasive   0  0  *  *

where * indicates it could be estimated and 0 not.

To fit such a covariance matrix  try

  (at.level(Range, "native"):Treatment-1|Pop)+(at.level(Range,  
"invasive"):Treatment-1|Pop)

in lmer.  The at.level function is at the bottom of the email

If individuals with the same mother have the same treatment then the  
pop/mom matrix needs to be


         TreatmentControl:Rangenative   *  0  0  0
     TreatmentHerbivory:Rangenative   0  *  0  0
TreatmentHerbivory:Rangeinvasive   0  0  *  0
TreatmentHerbivory:Rangeinvasive   0  0  0  *

and you can use either

  (at.level(Range, "native"):at.level(Treatment, "Herbivory")-1| 
Pop:mom)+(at.level(Range, "invasive"):at.level(Treatment,  
"Herbivory")-1|Pop:mom)+(at.level(Range, "native"):at.level(Treatment,  
"Control")-1|Pop:mom)+(at.level(Range, "invasive"):at.level(Treatment,  
Control")-1|Pop:mom)

or

  (at.level(subgroup, 1)|Pop:mom)+ (at.level(subgroup, 2)|Pop:mom) +  
(at.level(subgroup, 3)|Pop:mom) + (at.level(subgroup, 4)|Pop:mom)

I'm not sure if you can use this type of syntax in lme, but without  
allowing different residual variances for the subgroups I would be  
very cautious about the results.

Cheers,

Jarrod



at.level<-function (x, level)
{
     if (is.numeric(level)) {
         M <- outer(x, levels(x)[level], "==")
     }
     else {
         M <- outer(x, level, "==")
     }
     mode(M) <- "numeric"
     M
}
<environment: namespace:MCMCglmm>



On 8 Apr 2010, at 06:50, Alessia Guggisberg wrote:

> Dear R-sig-mixed-models list members
>
> I apologise in advance, if my question seems trivial; I'm new to  
> mixed-models in R.
>
> To make things easier, I'm giving you an example, followed by the  
> questions I'm hoping to be able to address with one of you.
>
> Study: Response of different populations of plants from two  
> different ranges (Europe vs. North America) to various stresses in a  
> greenhouse experiment
> Study question: Do populations from the native range (Europe) differ  
> in terms of response from the ones of the introduced range (North  
> America)?
> Type of data: Growth and reproductive data
> Example of mixed model: above-ground biomass as a function of  
> treatment (control vs. stress), range (Europe vs. North America) and  
> a covariate (in this case, longest leaf length at t0, to account for  
> size difference prior to stress)
>
> model=lme(above~Treatment * Range * t0.LLL, random= ~1|Pop/Mom)
>
> model=lmer(above~Treatment * Range * t0.LLL + (1|Pop/Mom))
>
> Due to the introduction history (bottleneck), I expect less genetic  
> variation in the introduced than in the native range, hence less  
> variation in response in the introduced than native range. Indeed,  
> inspection of raw data and residuals indicate higher variance for  
> native than introduced range. Similarly, I observe less variation in  
> response in the stress than in the control plot. Obviously, these  
> observations suggest violation of homoscedasticity. I therefore  
> would like to test and eventually account for difference in  
> variances between the different subgroups: (i) Europe-control, (ii)  
> Europe-stress, (iii) North America-control, (iv) North America-stress.
>
> Following options are possible:
>
> - account for heteroscedasticity in the innermost residuals:
>
> model=lme(above~Treatment * Range * t0.LLL, random= ~1|Pop/Mom,  
> weights=varIdent(form=~1|Treatment*Range))
>
> Random effects:
> Formula: ~1 | Pop
>                (Intercept)
> StdDev:     0.997503
>
> Formula: ~1 | Mom %in% Pop
>                (Intercept)     Residual
> StdDev:     1.150242      3.684324
>
> Variance function:
> Structure: Different standard deviations per stratum
> Formula: ~1 | Treatment * Range
> Parameter estimates:
>    Control*native   Herbivory*native   Control*invasive     
> Herbivory*invasive
>    1.0000000        0.3343747           0.9324055           0.2389115
>
> Is it true, that weights cannot be incorporated in lmer?
>
> - stratify the variance for the random effects:
>
> subgroup=factor(Treatment:Range)
> model=lme(above~Treatment * Range * t0.LLL, random= ~subgroup-1|Pop/ 
> Mom)
> ## warning message: Fewer observations than random effects in all  
> level 2 groups
>
> model=lmer(above~Treatment * Range * t0.LLL + (0 + subgroup|Pop/Mom))
>
> Random effects:
> Groups       Name                                         
> Variance          Corr
> Mom:Pop    TreatmentControl:Rangenative      11.783704        0.000
>                   TreatmentHerbivory:Rangenative   1.714778           
> 0.419    0.000
>                   TreatmentControl:Rangeinvasive   11.213378         
> -0.003    0.311        -0.001
>                   TreatmentHerbivory:Rangeinvasive 0.819599
> Pop            TreatmentControl:Rangenative       5.578492
>                   TreatmentHerbivory:Rangenative    1.569965          
> 1.000
>                   TreatmentControl:Rangeinvasive     0.029164         
> 0.839     0.839
>                   TreatmentHerbivory:Rangeinvasive  0.315794         
> 1.000     1.000        0.839
> Residual                                                         
> 1.239337
> Number of obs: 368, groups: Mom:Pop, 184; Pop, 42
>
> Why do I get an error message, when I run the model in lme?
>
> - another option found in R forums would be to code each subgroup  
> with a dummy variable, as follows (I only know how to implement that  
> method with lmer):
>
> nativeControl=as.numeric(factor(Range=="native" &  
> Treatment=="Control"))
> invasiveControl=as.numeric(factor(Range=="invasive" &  
> Treatment=="Control"))
> nativeHerbivory=as.numeric(factor(Range=="native" &  
> Treatment=="Herbivory"))
> invasiveHerbivory=as.numeric(factor(Range=="invasive" &  
> Treatment=="Herbivory"))
> model=lmer(above~Treatment*Range*t0.LLL + (0 + nativeControl|Pop/ 
> Mom) + (0 + invasiveControl|Pop/Mom) + (0 + nativeHerbivory|Pop/Mom)  
> + (0 + invasiveHerbivory|Pop/Mom))
>
> Random effects:
> Groups       Name                   Variance
> Mom:Pop   invasiveHerbivory    0.0000e+00
> Mom:Pop   nativeHerbivory      0.0000e+00
> Mom:Pop   invasiveControl       9.7939e-01
> Mom:Pop   nativeControl         1.0516e+00
> Pop          invasiveHerbivory    0.0000e+00
> Pop          nativeHerbivory      2.4815e-10
> Pop          invasiveControl      1.7994e-09
> Pop          nativeControl         9.1133e-01
> Residual                                4.1959e+00
> Number of obs: 368, groups: Mom:Pop, 184; Pop, 42
>
> This last model entails less parameters than the previous one  
> (because it doesn't calculate any correlations), but its AIC is also  
> much higher. Other than that, what differs between the two previous  
> models?
>
> In view of my problematic, what do you suggest me to do?
>
> I thank you in advance for any help you might be able to provide and  
> look forward to receiving your recommendations.
>
> Best,
>
> Alessia
>
> *************************************************************
> Alessia Guggisberg, PhD
> Postdoctoral Fellow
> Department of Botany
> University of British Columbia
> 3529-6270 University Boulevard
> Vancouver, BC, V6T 1Z4
> Canada
>
> Email: alessiag at interchange.ubc.ca
>
> *************************************************************
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From 2nuzzbot at gmail.com  Thu Apr  8 12:27:49 2010
From: 2nuzzbot at gmail.com (E T)
Date: Thu, 8 Apr 2010 11:27:49 +0100
Subject: [R-sig-ME] Multi-level models Odds ratio
In-Reply-To: <4A3D5F61-CB31-40C9-B16E-4247523E1842@gmail.com>
References: <z2m706f8d1f1004070928p43a3f49ds21f3b5ac0179625d@mail.gmail.com>
	<4A3D5F61-CB31-40C9-B16E-4247523E1842@gmail.com>
Message-ID: <l2w706f8d1f1004080327re8708f46mc7d334f41ae19a10@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100408/bd5b5171/attachment.pl>

From Thierry.ONKELINX at inbo.be  Thu Apr  8 12:32:01 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 8 Apr 2010 12:32:01 +0200
Subject: [R-sig-ME] Multi-level models Odds ratio
In-Reply-To: <l2w706f8d1f1004080327re8708f46mc7d334f41ae19a10@mail.gmail.com>
References: <z2m706f8d1f1004070928p43a3f49ds21f3b5ac0179625d@mail.gmail.com><4A3D5F61-CB31-40C9-B16E-4247523E1842@gmail.com>
	<l2w706f8d1f1004080327re8708f46mc7d334f41ae19a10@mail.gmail.com>
Message-ID: <2E9C414912813E4EB981326983E0A104071B69A6@inboexch.inbo.be>

It should be 

exp(coef(model))

Without the "s"

HTH,

Thierry
------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens E T
> Verzonden: donderdag 8 april 2010 12:28
> Aan: Daniel Ezra Johnson
> CC: r-sig-mixed-models at r-project.org
> Onderwerp: Re: [R-sig-ME] Multi-level models Odds ratio
> 
> odds.ratios = exp(coefs(model))
> 
> Thanks, however unfortunately when I try the above command I 
> receive the following error:
> 
> Error: could not find function "coefs"
> 
> Regards
> 
> Et
> 
> 
> 
> On Wed, Apr 7, 2010 at 5:47 PM, Daniel Ezra Johnson < 
> danielezrajohnson at gmail.com> wrote:
> 
> > something like odds.ratios = exp(coefs(model))
> >
> >
> > On Apr 7, 2010, at 12:28 PM, E T <2nuzzbot at gmail.com> wrote:
> >
> >  Hi all,
> >>
> >> Apologies for the simplicity of my question.... however 
> any advice is 
> >> greatly appreciated. Thanks
> >>
> >> Is there a specific command available to obtain the odds ratios 
> >> produced from a multilevel logistic model?
> >>
> >> I have estimated a multi-level logistic model using the 
> lme4 package. 
> >> I can obtain results using the 'summary' command, however I would 
> >> like to obtain the computed odds ratios.
> >> (Similar to the output that can be produced for logistic GLM using 
> >> the logistic.display command from the epicalc package).
> >>
> >>   [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list 
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From 2nuzzbot at gmail.com  Thu Apr  8 12:35:03 2010
From: 2nuzzbot at gmail.com (E T)
Date: Thu, 8 Apr 2010 11:35:03 +0100
Subject: [R-sig-ME] Multi-level models Odds ratio
In-Reply-To: <l2w706f8d1f1004080327re8708f46mc7d334f41ae19a10@mail.gmail.com>
References: <z2m706f8d1f1004070928p43a3f49ds21f3b5ac0179625d@mail.gmail.com>
	<4A3D5F61-CB31-40C9-B16E-4247523E1842@gmail.com>
	<l2w706f8d1f1004080327re8708f46mc7d334f41ae19a10@mail.gmail.com>
Message-ID: <i2y706f8d1f1004080335q84f61b78u8c7b656b67a08a8e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100408/a051b4be/attachment.pl>

From andy.fugard at sbg.ac.at  Thu Apr  8 12:48:30 2010
From: andy.fugard at sbg.ac.at (Andy Fugard (Work))
Date: Thu, 08 Apr 2010 12:48:30 +0200
Subject: [R-sig-ME] Multi-level models Odds ratio
In-Reply-To: <i2y706f8d1f1004080335q84f61b78u8c7b656b67a08a8e@mail.gmail.com>
References: <z2m706f8d1f1004070928p43a3f49ds21f3b5ac0179625d@mail.gmail.com>	<4A3D5F61-CB31-40C9-B16E-4247523E1842@gmail.com>	<l2w706f8d1f1004080327re8708f46mc7d334f41ae19a10@mail.gmail.com>
	<i2y706f8d1f1004080335q84f61b78u8c7b656b67a08a8e@mail.gmail.com>
Message-ID: <4BBDB47E.8030305@sbg.ac.at>

Here's another example, borrowed from the help for "lmer":

> gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
              family = binomial, data = cbpp)

As you say, coef works:

> coef(gm1)
$herd
   (Intercept)    period2   period3   period4
1   -0.8085096 -0.9923347 -1.128675 -1.580374
2   -1.6974292 -0.9923347 -1.128675 -1.580374
3   -0.9922697 -0.9923347 -1.128675 -1.580374
4   -1.3592525 -0.9923347 -1.128675 -1.580374
5   -1.5885461 -0.9923347 -1.128675 -1.580374
6   -1.7987950 -0.9923347 -1.128675 -1.580374
7   -0.5091313 -0.9923347 -1.128675 -1.580374
8   -0.7991613 -0.9923347 -1.128675 -1.580374
9   -1.6361848 -0.9923347 -1.128675 -1.580374
10  -1.9394614 -0.9923347 -1.128675 -1.580374
11  -1.4831632 -0.9923347 -1.128675 -1.580374
12  -1.4633469 -0.9923347 -1.128675 -1.580374
13  -2.0884474 -0.9923347 -1.128675 -1.580374
14  -0.4278151 -0.9923347 -1.128675 -1.580374
15  -1.9290041 -0.9923347 -1.128675 -1.580374

But note the "$herd" bit.  Since this model has a varying intercept by
herd, you get a column in the resulting data frame called "herd".

So you could try, for this example:

> exp(coef(gm1)$herd)
   (Intercept)   period2   period3   period4
1    0.4455216 0.3707102 0.3234614 0.2058981
2    0.1831538 0.3707102 0.3234614 0.2058981
3    0.3707343 0.3707102 0.3234614 0.2058981
4    0.2568527 0.3707102 0.3234614 0.2058981
5    0.2042223 0.3707102 0.3234614 0.2058981
6    0.1654982 0.3707102 0.3234614 0.2058981
7    0.6010174 0.3707102 0.3234614 0.2058981
8    0.4497060 0.3707102 0.3234614 0.2058981
9    0.1947215 0.3707102 0.3234614 0.2058981
10   0.1437814 0.3707102 0.3234614 0.2058981
11   0.2269188 0.3707102 0.3234614 0.2058981
12   0.2314603 0.3707102 0.3234614 0.2058981
13   0.1238793 0.3707102 0.3234614 0.2058981
14   0.6519320 0.3707102 0.3234614 0.2058981
15   0.1452928 0.3707102 0.3234614 0.2058981

Since the slopes don't vary by herd, you might also want just the fixed
effects:

> exp(fixef(gm1))
(Intercept)     period2     period3     period4
  0.2469585   0.3707102   0.3234614   0.2058981

HTH,

Andy


E T wrote:
> If I use the command coef(model) this extracts the coefficients in the
> model, however if I try exp(coef(model)) I receive an error:
> 
> Error in exp(coef(model)) : Non-numeric argument to mathematical function
> 
> I could manually get the exp of each factor in my model..... but as I have a
> large model (and also have numerous other models to produce), I was
> wondering if there was an automated method
> 
> Regards
> 
> Et
> 
> On Thu, Apr 8, 2010 at 11:27 AM, E T <2nuzzbot at gmail.com> wrote:
> 
>> odds.ratios = exp(coefs(model))
>>
>> Thanks, however unfortunately when I try the above command I receive the
>> following error:
>>
>> Error: could not find function "coefs"
>>
>> Regards
>>
>> Et
>>
>>
>>
>>
>> On Wed, Apr 7, 2010 at 5:47 PM, Daniel Ezra Johnson <
>> danielezrajohnson at gmail.com> wrote:
>>
>>> something like odds.ratios = exp(coefs(model))
>>>
>>>
>>> On Apr 7, 2010, at 12:28 PM, E T <2nuzzbot at gmail.com> wrote:
>>>
>>>  Hi all,
>>>> Apologies for the simplicity of my question.... however any advice is
>>>> greatly appreciated. Thanks
>>>>
>>>> Is there a specific command available to obtain the odds ratios produced
>>>> from a multilevel logistic model?
>>>>
>>>> I have estimated a multi-level logistic model using the lme4 package. I
>>>> can
>>>> obtain results using the 'summary' command, however I would like to
>>>> obtain
>>>> the computed odds ratios.
>>>> (Similar to the output that can be produced for logistic GLM using the
>>>> logistic.display command from the epicalc package).
>>>>
>>>>   [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Andy Fugard, Postdoctoral researcher, ESF LogICCC project
"Modeling human inference within the framework of probability logic"
Department of Psychology, University of Salzburg, Austria
http://www.andyfugard.info



From 2nuzzbot at gmail.com  Thu Apr  8 13:13:23 2010
From: 2nuzzbot at gmail.com (E T)
Date: Thu, 8 Apr 2010 12:13:23 +0100
Subject: [R-sig-ME] Multi-level models Odds ratio
In-Reply-To: <4BBDB47E.8030305@sbg.ac.at>
References: <z2m706f8d1f1004070928p43a3f49ds21f3b5ac0179625d@mail.gmail.com>
	<4A3D5F61-CB31-40C9-B16E-4247523E1842@gmail.com>
	<l2w706f8d1f1004080327re8708f46mc7d334f41ae19a10@mail.gmail.com>
	<i2y706f8d1f1004080335q84f61b78u8c7b656b67a08a8e@mail.gmail.com>
	<4BBDB47E.8030305@sbg.ac.at>
Message-ID: <p2p706f8d1f1004080413k3014fe10q444382c927c2f90e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100408/ba742a4d/attachment.pl>

From lamprianou at yahoo.com  Thu Apr  8 15:58:15 2010
From: lamprianou at yahoo.com (Iasonas Lamprianou)
Date: Thu, 8 Apr 2010 06:58:15 -0700 (PDT)
Subject: [R-sig-ME] MCMCglmm
In-Reply-To: <mailman.269.1270725223.4213.r-sig-mixed-models@r-project.org>
Message-ID: <581653.40560.qm@web58903.mail.re1.yahoo.com>

Dear all, 
I recently experimented with MCMCglmm and I loved (really loved) the fact that it will give me confidence intervals for the variance of the random effects. It seems that MCMC is a reasonable method to do so, in contrast to REML which seems to have problems on this front. However, MCMCglmm is painfully slower than lmer which is more familiar to me. The good news is that the point estimates of lmer are near the centre of the confidence intervals by MCMCglmm. 

I reduced my sample size a bit and managed to fit those two models with lmer (the second would not fit because it needed 1.5GB or RAM). Both seem to have a reasonable fit (at least at first look).

m4 <- lmer(score ~ 1+(1|marker/day)+(1|candidate)+(1|batch), mg2006)

m5 <- lmer(score ~ 1+(1+day|marker)+(1|candidate)+(1|batch), mg2006)

I would like to run these two models above with MCMCglmm. Does anyone know how to do it?

Thank you for the help

Jason

Dr. Iasonas Lamprianou


Assistant Professor (Educational Research and Evaluation)
Department of Education Sciences
European University-Cyprus
P.O. Box 22006
1516 Nicosia
Cyprus 
Tel.: +357-22-713178
Fax: +357-22-590539


Honorary Research Fellow
Department of Education
The University of Manchester
Oxford Road, Manchester M13 9PL, UK
Tel. 0044  161 275 3485
iasonas.lamprianou at manchester.ac.uk


--- On Thu, 8/4/10, r-sig-mixed-models-request at r-project.org <r-sig-mixed-models-request at r-project.org> wrote:

> From: r-sig-mixed-models-request at r-project.org <r-sig-mixed-models-request at r-project.org>
> Subject: R-sig-mixed-models Digest, Vol 40, Issue 15
> To: r-sig-mixed-models at r-project.org
> Date: Thursday, 8 April, 2010, 12:13
> Send R-sig-mixed-models mailing list
> submissions to
> ??? r-sig-mixed-models at r-project.org
> 
> To subscribe or unsubscribe via the World Wide Web, visit
> ??? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help'
> to
> ??? r-sig-mixed-models-request at r-project.org
> 
> You can reach the person managing the list at
> ??? r-sig-mixed-models-owner at r-project.org
> 
> When replying, please edit your Subject line so it is more
> specific
> than "Re: Contents of R-sig-mixed-models digest..."
> 
> 
> Today's Topics:
> 
> ???1. Re: Multi-level models Odds ratio (E
> T)
> ???2. Re: Multi-level models Odds ratio
> (ONKELINX, Thierry)
> ???3. Re: Multi-level models Odds ratio (E
> T)
> ???4. Re: Multi-level models Odds ratio
> (Andy Fugard (Work))
> ???5. Re: Multi-level models Odds ratio (E
> T)
> 
> 
> ----------------------------------------------------------------------
> 
> Message: 1
> Date: Thu, 8 Apr 2010 11:27:49 +0100
> From: E T <2nuzzbot at gmail.com>
> To: Daniel Ezra Johnson <danielezrajohnson at gmail.com>
> Cc: "r-sig-mixed-models at r-project.org"
> ??? <r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] Multi-level models Odds ratio
> Message-ID:
> ??? <l2w706f8d1f1004080327re8708f46mc7d334f41ae19a10 at mail.gmail.com>
> Content-Type: text/plain
> 
> odds.ratios = exp(coefs(model))
> 
> Thanks, however unfortunately when I try the above command
> I receive the
> following error:
> 
> Error: could not find function "coefs"
> 
> Regards
> 
> Et
> 
> 
> 
> On Wed, Apr 7, 2010 at 5:47 PM, Daniel Ezra Johnson <
> danielezrajohnson at gmail.com>
> wrote:
> 
> > something like odds.ratios = exp(coefs(model))
> >
> >
> > On Apr 7, 2010, at 12:28 PM, E T <2nuzzbot at gmail.com>
> wrote:
> >
> >? Hi all,
> >>
> >> Apologies for the simplicity of my question....
> however any advice is
> >> greatly appreciated. Thanks
> >>
> >> Is there a specific command available to obtain
> the odds ratios produced
> >> from a multilevel logistic model?
> >>
> >> I have estimated a multi-level logistic model
> using the lme4 package. I
> >> can
> >> obtain results using the 'summary' command,
> however I would like to obtain
> >> the computed odds ratios.
> >> (Similar to the output that can be produced for
> logistic GLM using the
> >> logistic.display command from the epicalc
> package).
> >>
> >>???[[alternative HTML version
> deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org
> mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> 
> ??? [[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------
> 
> Message: 2
> Date: Thu, 8 Apr 2010 12:32:01 +0200
> From: "ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be>
> To: "E T" <2nuzzbot at gmail.com>,???
> "Daniel Ezra Johnson"
> ??? <danielezrajohnson at gmail.com>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Multi-level models Odds ratio
> Message-ID:
> ??? <2E9C414912813E4EB981326983E0A104071B69A6 at inboexch.inbo.be>
> Content-Type: text/plain;???
> charset="us-ascii"
> 
> It should be 
> 
> exp(coef(model))
> 
> Without the "s"
> 
> HTH,
> 
> Thierry
> ------------------------------------------------------------------------
> ----
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek
> team Biometrie & Kwaliteitszorg
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
> 
> Research Institute for Nature and Forest
> team Biometrics & Quality Assurance
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
> 
> tel. + 32 54/436 185
> Thierry.Onkelinx at inbo.be
> www.inbo.be
> 
> To call in the statistician after the experiment is done
> may be no more
> than asking him to perform a post-mortem examination: he
> may be able to
> say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
> 
> The plural of anecdote is not data.
> ~ Roger Brinner
> 
> The combination of some data and an aching desire for an
> answer does not
> ensure that a reasonable answer can be extracted from a
> given body of
> data.
> ~ John Tukey
> ? 
> 
> > -----Oorspronkelijk bericht-----
> > Van: r-sig-mixed-models-bounces at r-project.org
> 
> > [mailto:r-sig-mixed-models-bounces at r-project.org]
> Namens E T
> > Verzonden: donderdag 8 april 2010 12:28
> > Aan: Daniel Ezra Johnson
> > CC: r-sig-mixed-models at r-project.org
> > Onderwerp: Re: [R-sig-ME] Multi-level models Odds
> ratio
> > 
> > odds.ratios = exp(coefs(model))
> > 
> > Thanks, however unfortunately when I try the above
> command I 
> > receive the following error:
> > 
> > Error: could not find function "coefs"
> > 
> > Regards
> > 
> > Et
> > 
> > 
> > 
> > On Wed, Apr 7, 2010 at 5:47 PM, Daniel Ezra Johnson
> < 
> > danielezrajohnson at gmail.com>
> wrote:
> > 
> > > something like odds.ratios = exp(coefs(model))
> > >
> > >
> > > On Apr 7, 2010, at 12:28 PM, E T <2nuzzbot at gmail.com>
> wrote:
> > >
> > >? Hi all,
> > >>
> > >> Apologies for the simplicity of my
> question.... however 
> > any advice is 
> > >> greatly appreciated. Thanks
> > >>
> > >> Is there a specific command available to
> obtain the odds ratios 
> > >> produced from a multilevel logistic model?
> > >>
> > >> I have estimated a multi-level logistic model
> using the 
> > lme4 package. 
> > >> I can obtain results using the 'summary'
> command, however I would 
> > >> like to obtain the computed odds ratios.
> > >> (Similar to the output that can be produced
> for logistic GLM using 
> > >> the logistic.display command from the epicalc
> package).
> > >>
> > >>???[[alternative HTML version
> deleted]]
> > >>
> > >>
> _______________________________________________
> > >> R-sig-mixed-models at r-project.org
> mailing list 
> > >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >>
> > >
> > 
> > ??? [[alternative HTML version
> deleted]]
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org
> mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > 
> 
> Druk dit bericht a.u.b. niet onnodig af.
> Please do not print this message unnecessarily.
> 
> Dit bericht en eventuele bijlagen geven enkel de visie van
> de schrijver weer 
> en binden het INBO onder geen enkel beding, zolang dit
> bericht niet bevestigd is
> door een geldig ondertekend document. The views expressed
> in? this message 
> and any annex are purely those of the writer and may not be
> regarded as stating 
> an official position of INBO, as long as the message is not
> confirmed by a duly 
> signed document.
> 
> 
> 
> ------------------------------
> 
> Message: 3
> Date: Thu, 8 Apr 2010 11:35:03 +0100
> From: E T <2nuzzbot at gmail.com>
> To: Daniel Ezra Johnson <danielezrajohnson at gmail.com>
> Cc: "r-sig-mixed-models at r-project.org"
> ??? <r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] Multi-level models Odds ratio
> Message-ID:
> ??? <i2y706f8d1f1004080335q84f61b78u8c7b656b67a08a8e at mail.gmail.com>
> Content-Type: text/plain
> 
> If I use the command coef(model) this extracts the
> coefficients in the
> model, however if I try exp(coef(model)) I receive an
> error:
> 
> Error in exp(coef(model)) : Non-numeric argument to
> mathematical function
> 
> I could manually get the exp of each factor in my
> model..... but as I have a
> large model (and also have numerous other models to
> produce), I was
> wondering if there was an automated method
> 
> Regards
> 
> Et
> 
> On Thu, Apr 8, 2010 at 11:27 AM, E T <2nuzzbot at gmail.com>
> wrote:
> 
> > odds.ratios = exp(coefs(model))
> >
> > Thanks, however unfortunately when I try the above
> command I receive the
> > following error:
> >
> > Error: could not find function "coefs"
> >
> > Regards
> >
> > Et
> >
> >
> >
> >
> > On Wed, Apr 7, 2010 at 5:47 PM, Daniel Ezra Johnson
> <
> > danielezrajohnson at gmail.com>
> wrote:
> >
> >> something like odds.ratios = exp(coefs(model))
> >>
> >>
> >> On Apr 7, 2010, at 12:28 PM, E T <2nuzzbot at gmail.com>
> wrote:
> >>
> >>? Hi all,
> >>>
> >>> Apologies for the simplicity of my
> question.... however any advice is
> >>> greatly appreciated. Thanks
> >>>
> >>> Is there a specific command available to
> obtain the odds ratios produced
> >>> from a multilevel logistic model?
> >>>
> >>> I have estimated a multi-level logistic model
> using the lme4 package. I
> >>> can
> >>> obtain results using the 'summary' command,
> however I would like to
> >>> obtain
> >>> the computed odds ratios.
> >>> (Similar to the output that can be produced
> for logistic GLM using the
> >>> logistic.display command from the epicalc
> package).
> >>>
> >>>???[[alternative HTML version
> deleted]]
> >>>
> >>>
> _______________________________________________
> >>> R-sig-mixed-models at r-project.org
> mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>
> >>
> >
> 
> ??? [[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------
> 
> Message: 4
> Date: Thu, 08 Apr 2010 12:48:30 +0200
> From: "Andy Fugard (Work)" <andy.fugard at sbg.ac.at>
> To: E T <2nuzzbot at gmail.com>
> Cc: "r-sig-mixed-models at r-project.org"
> ??? <r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] Multi-level models Odds ratio
> Message-ID: <4BBDB47E.8030305 at sbg.ac.at>
> Content-Type: text/plain; charset=ISO-8859-1
> 
> Here's another example, borrowed from the help for "lmer":
> 
> > gm1 <- glmer(cbind(incidence, size - incidence) ~
> period + (1 | herd),
> ? ? ? ? ? ? ? family =
> binomial, data = cbpp)
> 
> As you say, coef works:
> 
> > coef(gm1)
> $herd
> ???(Intercept)? ?
> period2???period3???period4
> 1???-0.8085096 -0.9923347 -1.128675
> -1.580374
> 2???-1.6974292 -0.9923347 -1.128675
> -1.580374
> 3???-0.9922697 -0.9923347 -1.128675
> -1.580374
> 4???-1.3592525 -0.9923347 -1.128675
> -1.580374
> 5???-1.5885461 -0.9923347 -1.128675
> -1.580374
> 6???-1.7987950 -0.9923347 -1.128675
> -1.580374
> 7???-0.5091313 -0.9923347 -1.128675
> -1.580374
> 8???-0.7991613 -0.9923347 -1.128675
> -1.580374
> 9???-1.6361848 -0.9923347 -1.128675
> -1.580374
> 10? -1.9394614 -0.9923347 -1.128675 -1.580374
> 11? -1.4831632 -0.9923347 -1.128675 -1.580374
> 12? -1.4633469 -0.9923347 -1.128675 -1.580374
> 13? -2.0884474 -0.9923347 -1.128675 -1.580374
> 14? -0.4278151 -0.9923347 -1.128675 -1.580374
> 15? -1.9290041 -0.9923347 -1.128675 -1.580374
> 
> But note the "$herd" bit.? Since this model has a
> varying intercept by
> herd, you get a column in the resulting data frame called
> "herd".
> 
> So you could try, for this example:
> 
> > exp(coef(gm1)$herd)
> ???(Intercept)???period2???period3???period4
> 1? ? 0.4455216 0.3707102 0.3234614 0.2058981
> 2? ? 0.1831538 0.3707102 0.3234614 0.2058981
> 3? ? 0.3707343 0.3707102 0.3234614 0.2058981
> 4? ? 0.2568527 0.3707102 0.3234614 0.2058981
> 5? ? 0.2042223 0.3707102 0.3234614 0.2058981
> 6? ? 0.1654982 0.3707102 0.3234614 0.2058981
> 7? ? 0.6010174 0.3707102 0.3234614 0.2058981
> 8? ? 0.4497060 0.3707102 0.3234614 0.2058981
> 9? ? 0.1947215 0.3707102 0.3234614 0.2058981
> 10???0.1437814 0.3707102 0.3234614
> 0.2058981
> 11???0.2269188 0.3707102 0.3234614
> 0.2058981
> 12???0.2314603 0.3707102 0.3234614
> 0.2058981
> 13???0.1238793 0.3707102 0.3234614
> 0.2058981
> 14???0.6519320 0.3707102 0.3234614
> 0.2058981
> 15???0.1452928 0.3707102 0.3234614
> 0.2058981
> 
> Since the slopes don't vary by herd, you might also want
> just the fixed
> effects:
> 
> > exp(fixef(gm1))
> (Intercept)? ???period2?
> ???period3? ???period4
> ?
> 0.2469585???0.3707102???0.3234614???0.2058981
> 
> HTH,
> 
> Andy
> 
> 
> E T wrote:
> > If I use the command coef(model) this extracts the
> coefficients in the
> > model, however if I try exp(coef(model)) I receive an
> error:
> > 
> > Error in exp(coef(model)) : Non-numeric argument to
> mathematical function
> > 
> > I could manually get the exp of each factor in my
> model..... but as I have a
> > large model (and also have numerous other models to
> produce), I was
> > wondering if there was an automated method
> > 
> > Regards
> > 
> > Et
> > 
> > On Thu, Apr 8, 2010 at 11:27 AM, E T <2nuzzbot at gmail.com>
> wrote:
> > 
> >> odds.ratios = exp(coefs(model))
> >>
> >> Thanks, however unfortunately when I try the above
> command I receive the
> >> following error:
> >>
> >> Error: could not find function "coefs"
> >>
> >> Regards
> >>
> >> Et
> >>
> >>
> >>
> >>
> >> On Wed, Apr 7, 2010 at 5:47 PM, Daniel Ezra
> Johnson <
> >> danielezrajohnson at gmail.com>
> wrote:
> >>
> >>> something like odds.ratios =
> exp(coefs(model))
> >>>
> >>>
> >>> On Apr 7, 2010, at 12:28 PM, E T <2nuzzbot at gmail.com>
> wrote:
> >>>
> >>>? Hi all,
> >>>> Apologies for the simplicity of my
> question.... however any advice is
> >>>> greatly appreciated. Thanks
> >>>>
> >>>> Is there a specific command available to
> obtain the odds ratios produced
> >>>> from a multilevel logistic model?
> >>>>
> >>>> I have estimated a multi-level logistic
> model using the lme4 package. I
> >>>> can
> >>>> obtain results using the 'summary'
> command, however I would like to
> >>>> obtain
> >>>> the computed odds ratios.
> >>>> (Similar to the output that can be
> produced for logistic GLM using the
> >>>> logistic.display command from the epicalc
> package).
> >>>>
> >>>>???[[alternative HTML
> version deleted]]
> >>>>
> >>>>
> _______________________________________________
> >>>> R-sig-mixed-models at r-project.org
> mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>
> > 
> > ??? [[alternative HTML version
> deleted]]
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org
> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> -- 
> Andy Fugard, Postdoctoral researcher, ESF LogICCC project
> "Modeling human inference within the framework of
> probability logic"
> Department of Psychology, University of Salzburg, Austria
> http://www.andyfugard.info
> 
> 
> 
> ------------------------------
> 
> Message: 5
> Date: Thu, 8 Apr 2010 12:13:23 +0100
> From: E T <2nuzzbot at gmail.com>
> To: "Andy Fugard (Work)" <andy.fugard at sbg.ac.at>
> Cc: "r-sig-mixed-models at r-project.org"
> ??? <r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] Multi-level models Odds ratio
> Message-ID:
> ??? <p2p706f8d1f1004080413k3014fe10q444382c927c2f90e at mail.gmail.com>
> Content-Type: text/plain
> 
> exp(coef(model)$group)
> 
> exp(fixef(model))
> 
> Thanks.... yes this worked successfully :o)
> 
> Et
> 
> On Thu, Apr 8, 2010 at 11:48 AM, Andy Fugard (Work)
> <andy.fugard at sbg.ac.at>wrote:
> 
> > Here's another example, borrowed from the help for
> "lmer":
> >
> > > gm1 <- glmer(cbind(incidence, size -
> incidence) ~ period + (1 | herd),
> >? ? ? ? ? ? ? family
> = binomial, data = cbpp)
> >
> > As you say, coef works:
> >
> > > coef(gm1)
> > $herd
> >???(Intercept)? ?
> period2???period3???period4
> > 1???-0.8085096 -0.9923347 -1.128675
> -1.580374
> > 2???-1.6974292 -0.9923347 -1.128675
> -1.580374
> > 3???-0.9922697 -0.9923347 -1.128675
> -1.580374
> > 4???-1.3592525 -0.9923347 -1.128675
> -1.580374
> > 5???-1.5885461 -0.9923347 -1.128675
> -1.580374
> > 6???-1.7987950 -0.9923347 -1.128675
> -1.580374
> > 7???-0.5091313 -0.9923347 -1.128675
> -1.580374
> > 8???-0.7991613 -0.9923347 -1.128675
> -1.580374
> > 9???-1.6361848 -0.9923347 -1.128675
> -1.580374
> > 10? -1.9394614 -0.9923347 -1.128675 -1.580374
> > 11? -1.4831632 -0.9923347 -1.128675 -1.580374
> > 12? -1.4633469 -0.9923347 -1.128675 -1.580374
> > 13? -2.0884474 -0.9923347 -1.128675 -1.580374
> > 14? -0.4278151 -0.9923347 -1.128675 -1.580374
> > 15? -1.9290041 -0.9923347 -1.128675 -1.580374
> >
> > But note the "$herd" bit.? Since this model has a
> varying intercept by
> > herd, you get a column in the resulting data frame
> called "herd".
> >
> > So you could try, for this example:
> >
> > > exp(coef(gm1)$herd)
> >???(Intercept)???period2???period3???period4
> > 1? ? 0.4455216 0.3707102 0.3234614
> 0.2058981
> > 2? ? 0.1831538 0.3707102 0.3234614
> 0.2058981
> > 3? ? 0.3707343 0.3707102 0.3234614
> 0.2058981
> > 4? ? 0.2568527 0.3707102 0.3234614
> 0.2058981
> > 5? ? 0.2042223 0.3707102 0.3234614
> 0.2058981
> > 6? ? 0.1654982 0.3707102 0.3234614
> 0.2058981
> > 7? ? 0.6010174 0.3707102 0.3234614
> 0.2058981
> > 8? ? 0.4497060 0.3707102 0.3234614
> 0.2058981
> > 9? ? 0.1947215 0.3707102 0.3234614
> 0.2058981
> > 10???0.1437814 0.3707102 0.3234614
> 0.2058981
> > 11???0.2269188 0.3707102 0.3234614
> 0.2058981
> > 12???0.2314603 0.3707102 0.3234614
> 0.2058981
> > 13???0.1238793 0.3707102 0.3234614
> 0.2058981
> > 14???0.6519320 0.3707102 0.3234614
> 0.2058981
> > 15???0.1452928 0.3707102 0.3234614
> 0.2058981
> >
> > Since the slopes don't vary by herd, you might also
> want just the fixed
> > effects:
> >
> > > exp(fixef(gm1))
> > (Intercept)? ???period2?
> ???period3? ???period4
> >?
> 0.2469585???0.3707102???0.3234614???0.2058981
> >
> > HTH,
> >
> > Andy
> >
> >
> > E T wrote:
> > > If I use the command coef(model) this extracts
> the coefficients in the
> > > model, however if I try exp(coef(model)) I
> receive an error:
> > >
> > > Error in exp(coef(model)) : Non-numeric argument
> to mathematical function
> > >
> > > I could manually get the exp of each factor in my
> model..... but as I
> > have a
> > > large model (and also have numerous other models
> to produce), I was
> > > wondering if there was an automated method
> > >
> > > Regards
> > >
> > > Et
> > >
> > > On Thu, Apr 8, 2010 at 11:27 AM, E T <2nuzzbot at gmail.com>
> wrote:
> > >
> > >> odds.ratios = exp(coefs(model))
> > >>
> > >> Thanks, however unfortunately when I try the
> above command I receive the
> > >> following error:
> > >>
> > >> Error: could not find function "coefs"
> > >>
> > >> Regards
> > >>
> > >> Et
> > >>
> > >>
> > >>
> > >>
> > >> On Wed, Apr 7, 2010 at 5:47 PM, Daniel Ezra
> Johnson <
> > >> danielezrajohnson at gmail.com>
> wrote:
> > >>
> > >>> something like odds.ratios =
> exp(coefs(model))
> > >>>
> > >>>
> > >>> On Apr 7, 2010, at 12:28 PM, E T <2nuzzbot at gmail.com>
> wrote:
> > >>>
> > >>>? Hi all,
> > >>>> Apologies for the simplicity of my
> question.... however any advice is
> > >>>> greatly appreciated. Thanks
> > >>>>
> > >>>> Is there a specific command available
> to obtain the odds ratios
> > produced
> > >>>> from a multilevel logistic model?
> > >>>>
> > >>>> I have estimated a multi-level
> logistic model using the lme4 package.
> > I
> > >>>> can
> > >>>> obtain results using the 'summary'
> command, however I would like to
> > >>>> obtain
> > >>>> the computed odds ratios.
> > >>>> (Similar to the output that can be
> produced for logistic GLM using the
> > >>>> logistic.display command from the
> epicalc package).
> > >>>>
> > >>>>???[[alternative HTML
> version deleted]]
> > >>>>
> > >>>>
> _______________________________________________
> > >>>> R-sig-mixed-models at r-project.org
> mailing list
> > >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >>>>
> > >
> > >? ? ???[[alternative HTML
> version deleted]]
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org
> mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
> > --
> > Andy Fugard, Postdoctoral researcher, ESF LogICCC
> project
> > "Modeling human inference within the framework of
> probability logic"
> > Department of Psychology, University of Salzburg,
> Austria
> > http://www.andyfugard.info
> >
> 
> ??? [[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------
> 
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> End of R-sig-mixed-models Digest, Vol 40, Issue 15
> **************************************************
> 






From j.hadfield at ed.ac.uk  Thu Apr  8 16:10:21 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 8 Apr 2010 15:10:21 +0100
Subject: [R-sig-ME] MCMCglmm
In-Reply-To: <581653.40560.qm@web58903.mail.re1.yahoo.com>
References: <581653.40560.qm@web58903.mail.re1.yahoo.com>
Message-ID: <62320BBA-C45B-4AE3-8783-6ABC174FE88C@ed.ac.uk>

Dear Jason,

These should work:

m4.mcmc <- MCMCglmm(score ~ 1, random=~marker+marker:day+candidate 
+batch, data=mg2006)
m5 .mcmc<- MCMCglmm(score ~ 1, random=~us(1+day):marker+candidate 
+batch, data=mg2006)

You may need to code day as a factor for m4, and as numeric for m5  
depending on the model you actually want to fit.

Cheers,

Jarrod


On 8 Apr 2010, at 14:58, Iasonas Lamprianou wrote:

> Dear all,
> I recently experimented with MCMCglmm and I loved (really loved) the  
> fact that it will give me confidence intervals for the variance of  
> the random effects. It seems that MCMC is a reasonable method to do  
> so, in contrast to REML which seems to have problems on this front.  
> However, MCMCglmm is painfully slower than lmer which is more  
> familiar to me. The good news is that the point estimates of lmer  
> are near the centre of the confidence intervals by MCMCglmm.
>
> I reduced my sample size a bit and managed to fit those two models  
> with lmer (the second would not fit because it needed 1.5GB or RAM).  
> Both seem to have a reasonable fit (at least at first look).
>
> m4 <- lmer(score ~ 1+(1|marker/day)+(1|candidate)+(1|batch), mg2006)
>
> m5 <- lmer(score ~ 1+(1+day|marker)+(1|candidate)+(1|batch), mg2006)
>
> I would like to run these two models above with MCMCglmm. Does  
> anyone know how to do it?
>
> Thank you for the help
>
> Jason
>
> Dr. Iasonas Lamprianou
>
>
> Assistant Professor (Educational Research and Evaluation)
> Department of Education Sciences
> European University-Cyprus
> P.O. Box 22006
> 1516 Nicosia
> Cyprus
> Tel.: +357-22-713178
> Fax: +357-22-590539
>
>
> Honorary Research Fellow
> Department of Education
> The University of Manchester
> Oxford Road, Manchester M13 9PL, UK
> Tel. 0044  161 275 3485
> iasonas.lamprianou at manchester.ac.uk
>
>
> --- On Thu, 8/4/10, r-sig-mixed-models-request at r-project.org <r-sig-mixed-models-request at r-project.org 
> > wrote:
>
>> From: r-sig-mixed-models-request at r-project.org <r-sig-mixed-models-request at r-project.org 
>> >
>> Subject: R-sig-mixed-models Digest, Vol 40, Issue 15
>> To: r-sig-mixed-models at r-project.org
>> Date: Thursday, 8 April, 2010, 12:13
>> Send R-sig-mixed-models mailing list
>> submissions to
>>     r-sig-mixed-models at r-project.org
>>
>> To subscribe or unsubscribe via the World Wide Web, visit
>>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> or, via email, send a message with subject or body 'help'
>> to
>>     r-sig-mixed-models-request at r-project.org
>>
>> You can reach the person managing the list at
>>     r-sig-mixed-models-owner at r-project.org
>>
>> When replying, please edit your Subject line so it is more
>> specific
>> than "Re: Contents of R-sig-mixed-models digest..."
>>
>>
>> Today's Topics:
>>
>>    1. Re: Multi-level models Odds ratio (E
>> T)
>>    2. Re: Multi-level models Odds ratio
>> (ONKELINX, Thierry)
>>    3. Re: Multi-level models Odds ratio (E
>> T)
>>    4. Re: Multi-level models Odds ratio
>> (Andy Fugard (Work))
>>    5. Re: Multi-level models Odds ratio (E
>> T)
>>
>>
>> ----------------------------------------------------------------------
>>
>> Message: 1
>> Date: Thu, 8 Apr 2010 11:27:49 +0100
>> From: E T <2nuzzbot at gmail.com>
>> To: Daniel Ezra Johnson <danielezrajohnson at gmail.com>
>> Cc: "r-sig-mixed-models at r-project.org"
>>     <r-sig-mixed-models at r-project.org>
>> Subject: Re: [R-sig-ME] Multi-level models Odds ratio
>> Message-ID:
>>     <l2w706f8d1f1004080327re8708f46mc7d334f41ae19a10 at mail.gmail.com>
>> Content-Type: text/plain
>>
>> odds.ratios = exp(coefs(model))
>>
>> Thanks, however unfortunately when I try the above command
>> I receive the
>> following error:
>>
>> Error: could not find function "coefs"
>>
>> Regards
>>
>> Et
>>
>>
>>
>> On Wed, Apr 7, 2010 at 5:47 PM, Daniel Ezra Johnson <
>> danielezrajohnson at gmail.com>
>> wrote:
>>
>>> something like odds.ratios = exp(coefs(model))
>>>
>>>
>>> On Apr 7, 2010, at 12:28 PM, E T <2nuzzbot at gmail.com>
>> wrote:
>>>
>>>   Hi all,
>>>>
>>>> Apologies for the simplicity of my question....
>> however any advice is
>>>> greatly appreciated. Thanks
>>>>
>>>> Is there a specific command available to obtain
>> the odds ratios produced
>>>> from a multilevel logistic model?
>>>>
>>>> I have estimated a multi-level logistic model
>> using the lme4 package. I
>>>> can
>>>> obtain results using the 'summary' command,
>> however I would like to obtain
>>>> the computed odds ratios.
>>>> (Similar to the output that can be produced for
>> logistic GLM using the
>>>> logistic.display command from the epicalc
>> package).
>>>>
>>>>    [[alternative HTML version
>> deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org
>> mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>
>>     [[alternative HTML version deleted]]
>>
>>
>>
>> ------------------------------
>>
>> Message: 2
>> Date: Thu, 8 Apr 2010 12:32:01 +0200
>> From: "ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be>
>> To: "E T" <2nuzzbot at gmail.com>,
>> "Daniel Ezra Johnson"
>>     <danielezrajohnson at gmail.com>
>> Cc: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] Multi-level models Odds ratio
>> Message-ID:
>>     <2E9C414912813E4EB981326983E0A104071B69A6 at inboexch.inbo.be>
>> Content-Type: text/plain;
>> charset="us-ascii"
>>
>> It should be
>>
>> exp(coef(model))
>>
>> Without the "s"
>>
>> HTH,
>>
>> Thierry
>> ------------------------------------------------------------------------
>> ----
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek
>> team Biometrie & Kwaliteitszorg
>> Gaverstraat 4
>> 9500 Geraardsbergen
>> Belgium
>>
>> Research Institute for Nature and Forest
>> team Biometrics & Quality Assurance
>> Gaverstraat 4
>> 9500 Geraardsbergen
>> Belgium
>>
>> tel. + 32 54/436 185
>> Thierry.Onkelinx at inbo.be
>> www.inbo.be
>>
>> To call in the statistician after the experiment is done
>> may be no more
>> than asking him to perform a post-mortem examination: he
>> may be able to
>> say what the experiment died of.
>> ~ Sir Ronald Aylmer Fisher
>>
>> The plural of anecdote is not data.
>> ~ Roger Brinner
>>
>> The combination of some data and an aching desire for an
>> answer does not
>> ensure that a reasonable answer can be extracted from a
>> given body of
>> data.
>> ~ John Tukey
>>
>>
>>> -----Oorspronkelijk bericht-----
>>> Van: r-sig-mixed-models-bounces at r-project.org
>>
>>> [mailto:r-sig-mixed-models-bounces at r-project.org]
>> Namens E T
>>> Verzonden: donderdag 8 april 2010 12:28
>>> Aan: Daniel Ezra Johnson
>>> CC: r-sig-mixed-models at r-project.org
>>> Onderwerp: Re: [R-sig-ME] Multi-level models Odds
>> ratio
>>>
>>> odds.ratios = exp(coefs(model))
>>>
>>> Thanks, however unfortunately when I try the above
>> command I
>>> receive the following error:
>>>
>>> Error: could not find function "coefs"
>>>
>>> Regards
>>>
>>> Et
>>>
>>>
>>>
>>> On Wed, Apr 7, 2010 at 5:47 PM, Daniel Ezra Johnson
>> <
>>> danielezrajohnson at gmail.com>
>> wrote:
>>>
>>>> something like odds.ratios = exp(coefs(model))
>>>>
>>>>
>>>> On Apr 7, 2010, at 12:28 PM, E T <2nuzzbot at gmail.com>
>> wrote:
>>>>
>>>>   Hi all,
>>>>>
>>>>> Apologies for the simplicity of my
>> question.... however
>>> any advice is
>>>>> greatly appreciated. Thanks
>>>>>
>>>>> Is there a specific command available to
>> obtain the odds ratios
>>>>> produced from a multilevel logistic model?
>>>>>
>>>>> I have estimated a multi-level logistic model
>> using the
>>> lme4 package.
>>>>> I can obtain results using the 'summary'
>> command, however I would
>>>>> like to obtain the computed odds ratios.
>>>>> (Similar to the output that can be produced
>> for logistic GLM using
>>>>> the logistic.display command from the epicalc
>> package).
>>>>>
>>>>>    [[alternative HTML version
>> deleted]]
>>>>>
>>>>>
>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org
>> mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>
>>>
>>>     [[alternative HTML version
>> deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org
>> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> Druk dit bericht a.u.b. niet onnodig af.
>> Please do not print this message unnecessarily.
>>
>> Dit bericht en eventuele bijlagen geven enkel de visie van
>> de schrijver weer
>> en binden het INBO onder geen enkel beding, zolang dit
>> bericht niet bevestigd is
>> door een geldig ondertekend document. The views expressed
>> in  this message
>> and any annex are purely those of the writer and may not be
>> regarded as stating
>> an official position of INBO, as long as the message is not
>> confirmed by a duly
>> signed document.
>>
>>
>>
>> ------------------------------
>>
>> Message: 3
>> Date: Thu, 8 Apr 2010 11:35:03 +0100
>> From: E T <2nuzzbot at gmail.com>
>> To: Daniel Ezra Johnson <danielezrajohnson at gmail.com>
>> Cc: "r-sig-mixed-models at r-project.org"
>>     <r-sig-mixed-models at r-project.org>
>> Subject: Re: [R-sig-ME] Multi-level models Odds ratio
>> Message-ID:
>>     <i2y706f8d1f1004080335q84f61b78u8c7b656b67a08a8e at mail.gmail.com>
>> Content-Type: text/plain
>>
>> If I use the command coef(model) this extracts the
>> coefficients in the
>> model, however if I try exp(coef(model)) I receive an
>> error:
>>
>> Error in exp(coef(model)) : Non-numeric argument to
>> mathematical function
>>
>> I could manually get the exp of each factor in my
>> model..... but as I have a
>> large model (and also have numerous other models to
>> produce), I was
>> wondering if there was an automated method
>>
>> Regards
>>
>> Et
>>
>> On Thu, Apr 8, 2010 at 11:27 AM, E T <2nuzzbot at gmail.com>
>> wrote:
>>
>>> odds.ratios = exp(coefs(model))
>>>
>>> Thanks, however unfortunately when I try the above
>> command I receive the
>>> following error:
>>>
>>> Error: could not find function "coefs"
>>>
>>> Regards
>>>
>>> Et
>>>
>>>
>>>
>>>
>>> On Wed, Apr 7, 2010 at 5:47 PM, Daniel Ezra Johnson
>> <
>>> danielezrajohnson at gmail.com>
>> wrote:
>>>
>>>> something like odds.ratios = exp(coefs(model))
>>>>
>>>>
>>>> On Apr 7, 2010, at 12:28 PM, E T <2nuzzbot at gmail.com>
>> wrote:
>>>>
>>>>   Hi all,
>>>>>
>>>>> Apologies for the simplicity of my
>> question.... however any advice is
>>>>> greatly appreciated. Thanks
>>>>>
>>>>> Is there a specific command available to
>> obtain the odds ratios produced
>>>>> from a multilevel logistic model?
>>>>>
>>>>> I have estimated a multi-level logistic model
>> using the lme4 package. I
>>>>> can
>>>>> obtain results using the 'summary' command,
>> however I would like to
>>>>> obtain
>>>>> the computed odds ratios.
>>>>> (Similar to the output that can be produced
>> for logistic GLM using the
>>>>> logistic.display command from the epicalc
>> package).
>>>>>
>>>>>    [[alternative HTML version
>> deleted]]
>>>>>
>>>>>
>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org
>> mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>
>>>
>>
>>     [[alternative HTML version deleted]]
>>
>>
>>
>> ------------------------------
>>
>> Message: 4
>> Date: Thu, 08 Apr 2010 12:48:30 +0200
>> From: "Andy Fugard (Work)" <andy.fugard at sbg.ac.at>
>> To: E T <2nuzzbot at gmail.com>
>> Cc: "r-sig-mixed-models at r-project.org"
>>     <r-sig-mixed-models at r-project.org>
>> Subject: Re: [R-sig-ME] Multi-level models Odds ratio
>> Message-ID: <4BBDB47E.8030305 at sbg.ac.at>
>> Content-Type: text/plain; charset=ISO-8859-1
>>
>> Here's another example, borrowed from the help for "lmer":
>>
>>> gm1 <- glmer(cbind(incidence, size - incidence) ~
>> period + (1 | herd),
>>               family =
>> binomial, data = cbpp)
>>
>> As you say, coef works:
>>
>>> coef(gm1)
>> $herd
>>    (Intercept)
>> period2   period3   period4
>> 1   -0.8085096 -0.9923347 -1.128675
>> -1.580374
>> 2   -1.6974292 -0.9923347 -1.128675
>> -1.580374
>> 3   -0.9922697 -0.9923347 -1.128675
>> -1.580374
>> 4   -1.3592525 -0.9923347 -1.128675
>> -1.580374
>> 5   -1.5885461 -0.9923347 -1.128675
>> -1.580374
>> 6   -1.7987950 -0.9923347 -1.128675
>> -1.580374
>> 7   -0.5091313 -0.9923347 -1.128675
>> -1.580374
>> 8   -0.7991613 -0.9923347 -1.128675
>> -1.580374
>> 9   -1.6361848 -0.9923347 -1.128675
>> -1.580374
>> 10  -1.9394614 -0.9923347 -1.128675 -1.580374
>> 11  -1.4831632 -0.9923347 -1.128675 -1.580374
>> 12  -1.4633469 -0.9923347 -1.128675 -1.580374
>> 13  -2.0884474 -0.9923347 -1.128675 -1.580374
>> 14  -0.4278151 -0.9923347 -1.128675 -1.580374
>> 15  -1.9290041 -0.9923347 -1.128675 -1.580374
>>
>> But note the "$herd" bit.  Since this model has a
>> varying intercept by
>> herd, you get a column in the resulting data frame called
>> "herd".
>>
>> So you could try, for this example:
>>
>>> exp(coef(gm1)$herd)
>>    (Intercept)   period2   period3   period4
>> 1    0.4455216 0.3707102 0.3234614 0.2058981
>> 2    0.1831538 0.3707102 0.3234614 0.2058981
>> 3    0.3707343 0.3707102 0.3234614 0.2058981
>> 4    0.2568527 0.3707102 0.3234614 0.2058981
>> 5    0.2042223 0.3707102 0.3234614 0.2058981
>> 6    0.1654982 0.3707102 0.3234614 0.2058981
>> 7    0.6010174 0.3707102 0.3234614 0.2058981
>> 8    0.4497060 0.3707102 0.3234614 0.2058981
>> 9    0.1947215 0.3707102 0.3234614 0.2058981
>> 10   0.1437814 0.3707102 0.3234614
>> 0.2058981
>> 11   0.2269188 0.3707102 0.3234614
>> 0.2058981
>> 12   0.2314603 0.3707102 0.3234614
>> 0.2058981
>> 13   0.1238793 0.3707102 0.3234614
>> 0.2058981
>> 14   0.6519320 0.3707102 0.3234614
>> 0.2058981
>> 15   0.1452928 0.3707102 0.3234614
>> 0.2058981
>>
>> Since the slopes don't vary by herd, you might also want
>> just the fixed
>> effects:
>>
>>> exp(fixef(gm1))
>> (Intercept)     period2
>>    period3     period4
>>
>> 0.2469585   0.3707102   0.3234614   0.2058981
>>
>> HTH,
>>
>> Andy
>>
>>
>> E T wrote:
>>> If I use the command coef(model) this extracts the
>> coefficients in the
>>> model, however if I try exp(coef(model)) I receive an
>> error:
>>>
>>> Error in exp(coef(model)) : Non-numeric argument to
>> mathematical function
>>>
>>> I could manually get the exp of each factor in my
>> model..... but as I have a
>>> large model (and also have numerous other models to
>> produce), I was
>>> wondering if there was an automated method
>>>
>>> Regards
>>>
>>> Et
>>>
>>> On Thu, Apr 8, 2010 at 11:27 AM, E T <2nuzzbot at gmail.com>
>> wrote:
>>>
>>>> odds.ratios = exp(coefs(model))
>>>>
>>>> Thanks, however unfortunately when I try the above
>> command I receive the
>>>> following error:
>>>>
>>>> Error: could not find function "coefs"
>>>>
>>>> Regards
>>>>
>>>> Et
>>>>
>>>>
>>>>
>>>>
>>>> On Wed, Apr 7, 2010 at 5:47 PM, Daniel Ezra
>> Johnson <
>>>> danielezrajohnson at gmail.com>
>> wrote:
>>>>
>>>>> something like odds.ratios =
>> exp(coefs(model))
>>>>>
>>>>>
>>>>> On Apr 7, 2010, at 12:28 PM, E T <2nuzzbot at gmail.com>
>> wrote:
>>>>>
>>>>>   Hi all,
>>>>>> Apologies for the simplicity of my
>> question.... however any advice is
>>>>>> greatly appreciated. Thanks
>>>>>>
>>>>>> Is there a specific command available to
>> obtain the odds ratios produced
>>>>>> from a multilevel logistic model?
>>>>>>
>>>>>> I have estimated a multi-level logistic
>> model using the lme4 package. I
>>>>>> can
>>>>>> obtain results using the 'summary'
>> command, however I would like to
>>>>>> obtain
>>>>>> the computed odds ratios.
>>>>>> (Similar to the output that can be
>> produced for logistic GLM using the
>>>>>> logistic.display command from the epicalc
>> package).
>>>>>>
>>>>>>    [[alternative HTML
>> version deleted]]
>>>>>>
>>>>>>
>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org
>> mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>
>>>
>>>     [[alternative HTML version
>> deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org
>> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>> -- 
>> Andy Fugard, Postdoctoral researcher, ESF LogICCC project
>> "Modeling human inference within the framework of
>> probability logic"
>> Department of Psychology, University of Salzburg, Austria
>> http://www.andyfugard.info
>>
>>
>>
>> ------------------------------
>>
>> Message: 5
>> Date: Thu, 8 Apr 2010 12:13:23 +0100
>> From: E T <2nuzzbot at gmail.com>
>> To: "Andy Fugard (Work)" <andy.fugard at sbg.ac.at>
>> Cc: "r-sig-mixed-models at r-project.org"
>>     <r-sig-mixed-models at r-project.org>
>> Subject: Re: [R-sig-ME] Multi-level models Odds ratio
>> Message-ID:
>>     <p2p706f8d1f1004080413k3014fe10q444382c927c2f90e at mail.gmail.com>
>> Content-Type: text/plain
>>
>> exp(coef(model)$group)
>>
>> exp(fixef(model))
>>
>> Thanks.... yes this worked successfully :o)
>>
>> Et
>>
>> On Thu, Apr 8, 2010 at 11:48 AM, Andy Fugard (Work)
>> <andy.fugard at sbg.ac.at>wrote:
>>
>>> Here's another example, borrowed from the help for
>> "lmer":
>>>
>>>> gm1 <- glmer(cbind(incidence, size -
>> incidence) ~ period + (1 | herd),
>>>               family
>> = binomial, data = cbpp)
>>>
>>> As you say, coef works:
>>>
>>>> coef(gm1)
>>> $herd
>>>    (Intercept)
>> period2   period3   period4
>>> 1   -0.8085096 -0.9923347 -1.128675
>> -1.580374
>>> 2   -1.6974292 -0.9923347 -1.128675
>> -1.580374
>>> 3   -0.9922697 -0.9923347 -1.128675
>> -1.580374
>>> 4   -1.3592525 -0.9923347 -1.128675
>> -1.580374
>>> 5   -1.5885461 -0.9923347 -1.128675
>> -1.580374
>>> 6   -1.7987950 -0.9923347 -1.128675
>> -1.580374
>>> 7   -0.5091313 -0.9923347 -1.128675
>> -1.580374
>>> 8   -0.7991613 -0.9923347 -1.128675
>> -1.580374
>>> 9   -1.6361848 -0.9923347 -1.128675
>> -1.580374
>>> 10  -1.9394614 -0.9923347 -1.128675 -1.580374
>>> 11  -1.4831632 -0.9923347 -1.128675 -1.580374
>>> 12  -1.4633469 -0.9923347 -1.128675 -1.580374
>>> 13  -2.0884474 -0.9923347 -1.128675 -1.580374
>>> 14  -0.4278151 -0.9923347 -1.128675 -1.580374
>>> 15  -1.9290041 -0.9923347 -1.128675 -1.580374
>>>
>>> But note the "$herd" bit.  Since this model has a
>> varying intercept by
>>> herd, you get a column in the resulting data frame
>> called "herd".
>>>
>>> So you could try, for this example:
>>>
>>>> exp(coef(gm1)$herd)
>>>    (Intercept)   period2   period3   period4
>>> 1    0.4455216 0.3707102 0.3234614
>> 0.2058981
>>> 2    0.1831538 0.3707102 0.3234614
>> 0.2058981
>>> 3    0.3707343 0.3707102 0.3234614
>> 0.2058981
>>> 4    0.2568527 0.3707102 0.3234614
>> 0.2058981
>>> 5    0.2042223 0.3707102 0.3234614
>> 0.2058981
>>> 6    0.1654982 0.3707102 0.3234614
>> 0.2058981
>>> 7    0.6010174 0.3707102 0.3234614
>> 0.2058981
>>> 8    0.4497060 0.3707102 0.3234614
>> 0.2058981
>>> 9    0.1947215 0.3707102 0.3234614
>> 0.2058981
>>> 10   0.1437814 0.3707102 0.3234614
>> 0.2058981
>>> 11   0.2269188 0.3707102 0.3234614
>> 0.2058981
>>> 12   0.2314603 0.3707102 0.3234614
>> 0.2058981
>>> 13   0.1238793 0.3707102 0.3234614
>> 0.2058981
>>> 14   0.6519320 0.3707102 0.3234614
>> 0.2058981
>>> 15   0.1452928 0.3707102 0.3234614
>> 0.2058981
>>>
>>> Since the slopes don't vary by herd, you might also
>> want just the fixed
>>> effects:
>>>
>>>> exp(fixef(gm1))
>>> (Intercept)     period2
>>    period3     period4
>>>
>> 0.2469585   0.3707102   0.3234614   0.2058981
>>>
>>> HTH,
>>>
>>> Andy
>>>
>>>
>>> E T wrote:
>>>> If I use the command coef(model) this extracts
>> the coefficients in the
>>>> model, however if I try exp(coef(model)) I
>> receive an error:
>>>>
>>>> Error in exp(coef(model)) : Non-numeric argument
>> to mathematical function
>>>>
>>>> I could manually get the exp of each factor in my
>> model..... but as I
>>> have a
>>>> large model (and also have numerous other models
>> to produce), I was
>>>> wondering if there was an automated method
>>>>
>>>> Regards
>>>>
>>>> Et
>>>>
>>>> On Thu, Apr 8, 2010 at 11:27 AM, E T <2nuzzbot at gmail.com>
>> wrote:
>>>>
>>>>> odds.ratios = exp(coefs(model))
>>>>>
>>>>> Thanks, however unfortunately when I try the
>> above command I receive the
>>>>> following error:
>>>>>
>>>>> Error: could not find function "coefs"
>>>>>
>>>>> Regards
>>>>>
>>>>> Et
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> On Wed, Apr 7, 2010 at 5:47 PM, Daniel Ezra
>> Johnson <
>>>>> danielezrajohnson at gmail.com>
>> wrote:
>>>>>
>>>>>> something like odds.ratios =
>> exp(coefs(model))
>>>>>>
>>>>>>
>>>>>> On Apr 7, 2010, at 12:28 PM, E T <2nuzzbot at gmail.com>
>> wrote:
>>>>>>
>>>>>>   Hi all,
>>>>>>> Apologies for the simplicity of my
>> question.... however any advice is
>>>>>>> greatly appreciated. Thanks
>>>>>>>
>>>>>>> Is there a specific command available
>> to obtain the odds ratios
>>> produced
>>>>>>> from a multilevel logistic model?
>>>>>>>
>>>>>>> I have estimated a multi-level
>> logistic model using the lme4 package.
>>> I
>>>>>>> can
>>>>>>> obtain results using the 'summary'
>> command, however I would like to
>>>>>>> obtain
>>>>>>> the computed odds ratios.
>>>>>>> (Similar to the output that can be
>> produced for logistic GLM using the
>>>>>>> logistic.display command from the
>> epicalc package).
>>>>>>>
>>>>>>>    [[alternative HTML
>> version deleted]]
>>>>>>>
>>>>>>>
>> _______________________________________________
>>>>>>> R-sig-mixed-models at r-project.org
>> mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>
>>>>
>>>>        [[alternative HTML
>> version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org
>> mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>> --
>>> Andy Fugard, Postdoctoral researcher, ESF LogICCC
>> project
>>> "Modeling human inference within the framework of
>> probability logic"
>>> Department of Psychology, University of Salzburg,
>> Austria
>>> http://www.andyfugard.info
>>>
>>
>>     [[alternative HTML version deleted]]
>>
>>
>>
>> ------------------------------
>>
>> _______________________________________________
>> R-sig-mixed-models mailing list
>> R-sig-mixed-models at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>> End of R-sig-mixed-models Digest, Vol 40, Issue 15
>> **************************************************
>>
>
>
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From alessiag at interchange.ubc.ca  Thu Apr  8 19:08:02 2010
From: alessiag at interchange.ubc.ca (Alessia Guggisberg)
Date: Thu, 08 Apr 2010 10:08:02 -0700
Subject: [R-sig-ME] variance structure in lme/lmer
References: <5484B83D4A00471FB4456A35712C1971@Guggisberg>
	<A8CFA9F9-2A41-4882-9199-803E2DB8D91B@ed.ac.uk>
Message-ID: <121EB05A386845FB88C384B5876264D1@Guggisberg>

Hi Jarrod

Thank you so much for your reply!

Indeed, each population/mom belongs to one type of range (native or 
invasive) solely, but occurs in both treatment plots. I've just tried your 
suggestion and its seems to work fine:

model=lmer(above~Treatment * Range * Ct0.LLL + (at.level(Range, 
"native"):Treatment-1|Pop/Mom) + 
(at.level(Range,"invasive"):Treatment-1|Pop/Mom))

Random effects:
 Groups       Name 
Variance           Std.Dev.           Corr
 Mom:Pop  at.level(Range, "invasive"):TreatmentControl       1.1326e+01 
3.3654e+00
                  at.level(Range, "invasive"):TreatmentHerbivory 
9.1458e-01     9.5633e-01        0.292
 Mom:Pop  at.level(Range, "native"):TreatmentControl          1.1868e+01 
3.4451e+00
                  at.level(Range, "native"):TreatmentHerbivory 
1.7996e+00     1.3415e+00       0.396
 Pop          at.level(Range, "invasive"):TreatmentControl        1.1083e-09 
3.3291e-05
                  at.level(Range, "invasive"):TreatmentHerbivory 
2.9827e-01      5.4614e-01        0.000
 Pop          at.level(Range, "native"):TreatmentControl 
5.5788e+00      2.3619e+00
                  at.level(Range, "native"):TreatmentHerbivory 
1.5701e+00     1.2530e+00        0.839
 Residual 
1.1545e+00     1.0745e+00
Number of obs: 368, groups: Mom:Pop, 184; Pop, 42

Also, the BLUPs are now 'logical' as I get zero-values for populations/moms 
that do not occur in a given range.

The question remains though, whether I should additionnally account for 
heterogeneity in the innermost residuals (like 'weights' in lme), and if so, 
how I should implement that in lmer.

Thanks again for your precious help; thanks to you, I've just made a big 
step today....

Best,

Alessia


*************************************************************
Alessia Guggisberg, PhD
Postdoctoral Fellow
Department of Botany
University of British Columbia
3529-6270 University Boulevard
Vancouver, BC, V6T 1Z4
Canada

Email: alessiag at interchange.ubc.ca

*************************************************************
----- Original Message ----- 
From: "Jarrod Hadfield" <j.hadfield at ed.ac.uk>
To: "Alessia Guggisberg" <alessiag at interchange.ubc.ca>
Cc: <r-sig-mixed-models at r-project.org>
Sent: Thursday, April 08, 2010 2:22 AM
Subject: Re: [R-sig-ME] variance structure in lme/lmer


> Dear Alessia,
>
> I think the problem is that  individuals from a population all belong  to 
> one type (native or invasive) (is this true?) If this is the case  your 
> 4x4 covariance matrices needs to look like
>
>         TreatmentControl:Rangenative   *  *  0  0
>     TreatmentHerbivory:Rangenative   *  *  0  0
> TreatmentHerbivory:Rangeinvasive   0  0  *  *
> TreatmentHerbivory:Rangeinvasive   0  0  *  *
>
> where * indicates it could be estimated and 0 not.
>
> To fit such a covariance matrix  try
>
>  (at.level(Range, "native"):Treatment-1|Pop)+(at.level(Range, 
> "invasive"):Treatment-1|Pop)
>
> in lmer.  The at.level function is at the bottom of the email
>
> If individuals with the same mother have the same treatment then the 
> pop/mom matrix needs to be
>
>
>         TreatmentControl:Rangenative   *  0  0  0
>     TreatmentHerbivory:Rangenative   0  *  0  0
> TreatmentHerbivory:Rangeinvasive   0  0  *  0
> TreatmentHerbivory:Rangeinvasive   0  0  0  *
>
> and you can use either
>
>  (at.level(Range, "native"):at.level(Treatment, "Herbivory")-1| 
> Pop:mom)+(at.level(Range, "invasive"):at.level(Treatment, 
> "Herbivory")-1|Pop:mom)+(at.level(Range, "native"):at.level(Treatment, 
> "Control")-1|Pop:mom)+(at.level(Range, "invasive"):at.level(Treatment, 
> Control")-1|Pop:mom)
>
> or
>
>  (at.level(subgroup, 1)|Pop:mom)+ (at.level(subgroup, 2)|Pop:mom) + 
> (at.level(subgroup, 3)|Pop:mom) + (at.level(subgroup, 4)|Pop:mom)
>
> I'm not sure if you can use this type of syntax in lme, but without 
> allowing different residual variances for the subgroups I would be  very 
> cautious about the results.
>
> Cheers,
>
> Jarrod
>
>
>
> at.level<-function (x, level)
> {
>     if (is.numeric(level)) {
>         M <- outer(x, levels(x)[level], "==")
>     }
>     else {
>         M <- outer(x, level, "==")
>     }
>     mode(M) <- "numeric"
>     M
> }
> <environment: namespace:MCMCglmm>
>
>
>
> On 8 Apr 2010, at 06:50, Alessia Guggisberg wrote:
>
>> Dear R-sig-mixed-models list members
>>
>> I apologise in advance, if my question seems trivial; I'm new to 
>> mixed-models in R.
>>
>> To make things easier, I'm giving you an example, followed by the 
>> questions I'm hoping to be able to address with one of you.
>>
>> Study: Response of different populations of plants from two  different 
>> ranges (Europe vs. North America) to various stresses in a  greenhouse 
>> experiment
>> Study question: Do populations from the native range (Europe) differ  in 
>> terms of response from the ones of the introduced range (North  America)?
>> Type of data: Growth and reproductive data
>> Example of mixed model: above-ground biomass as a function of  treatment 
>> (control vs. stress), range (Europe vs. North America) and  a covariate 
>> (in this case, longest leaf length at t0, to account for  size difference 
>> prior to stress)
>>
>> model=lme(above~Treatment * Range * t0.LLL, random= ~1|Pop/Mom)
>>
>> model=lmer(above~Treatment * Range * t0.LLL + (1|Pop/Mom))
>>
>> Due to the introduction history (bottleneck), I expect less genetic 
>> variation in the introduced than in the native range, hence less 
>> variation in response in the introduced than native range. Indeed, 
>> inspection of raw data and residuals indicate higher variance for  native 
>> than introduced range. Similarly, I observe less variation in  response 
>> in the stress than in the control plot. Obviously, these  observations 
>> suggest violation of homoscedasticity. I therefore  would like to test 
>> and eventually account for difference in  variances between the different 
>> subgroups: (i) Europe-control, (ii)  Europe-stress, (iii) North 
>> America-control, (iv) North America-stress.
>>
>> Following options are possible:
>>
>> - account for heteroscedasticity in the innermost residuals:
>>
>> model=lme(above~Treatment * Range * t0.LLL, random= ~1|Pop/Mom, 
>> weights=varIdent(form=~1|Treatment*Range))
>>
>> Random effects:
>> Formula: ~1 | Pop
>>                (Intercept)
>> StdDev:     0.997503
>>
>> Formula: ~1 | Mom %in% Pop
>>                (Intercept)     Residual
>> StdDev:     1.150242      3.684324
>>
>> Variance function:
>> Structure: Different standard deviations per stratum
>> Formula: ~1 | Treatment * Range
>> Parameter estimates:
>>    Control*native   Herbivory*native   Control*invasive 
>> Herbivory*invasive
>>    1.0000000        0.3343747           0.9324055           0.2389115
>>
>> Is it true, that weights cannot be incorporated in lmer?
>>
>> - stratify the variance for the random effects:
>>
>> subgroup=factor(Treatment:Range)
>> model=lme(above~Treatment * Range * t0.LLL, random= ~subgroup-1|Pop/ Mom)
>> ## warning message: Fewer observations than random effects in all  level 
>> 2 groups
>>
>> model=lmer(above~Treatment * Range * t0.LLL + (0 + subgroup|Pop/Mom))
>>
>> Random effects:
>> Groups       Name                                         Variance 
>> Corr
>> Mom:Pop    TreatmentControl:Rangenative      11.783704        0.000
>>                   TreatmentHerbivory:Rangenative   1.714778 
>> 0.419    0.000
>>                   TreatmentControl:Rangeinvasive 
>> 378         -0.003    0.311        -0.001
>>                   TreatmentHerbivory:Rangeinvasive 0.819599
>> Pop            TreatmentControl:Rangenative       5.578492
>>                   TreatmentHerbivory:Rangenative    1.569965 
>> 1.000
>>                   TreatmentControl:Rangeinvasive     0.029164 
>> 0.839     0.839
>>                   TreatmentHerbivory:Rangeinvasive  0.315794 
>> 1.000     1.000        0.839
>> Residual                                                         1.239337
>> Number of obs: 368, groups: Mom:Pop, 184; Pop, 42
>>
>> Why do I get an error message, when I run the model in lme?
>>
>> - another option found in R forums would be to code each subgroup  with a 
>> dummy variable, as follows (I only know how to implement that  method 
>> with lmer):
>>
>> nativeControl=as.numeric(factor(Range=="native" &  Treatment=="Control"))
>> invasiveControl=as.numeric(factor(Range=="invasive" & 
>> Treatment=="Control"))
>> nativeHerbivory=as.numeric(factor(Range=="native" & 
>> Treatment=="Herbivory"))
>> invasiveHerbivory=as.numeric(factor(Range=="invasive" & 
>> Treatment=="Herbivory"))
>> model=lmer(above~Treatment*Range*t0.LLL + (0 + nativeControl|Pop/ Mom) + 
>> (0 + invasiveControl|Pop/Mom) + (0 + nativeHerbivory|Pop/Mom)  + (0 + 
>> invasiveHerbivory|Pop/Mom))
>>
>> Random effects:
>> Groups       Name                   Variance
>> Mom:Pop   invasiveHerbivory    0.0000e+00
>> Mom:Pop   nativeHerbivory      0.0000e+00
>> Mom:Pop   invasiveControl       9.7939e-01
>> Mom:Pop   nativeControl         1.0516e+00
>> Pop          invasiveHerbivory    0.0000e+00
>> Pop          nativeHerbivory      2.4815e-10
>> Pop          invasiveControl      1.7994e-09
>> Pop          nativeControl         9.1133e-01
>> Residual                                4.1959e+00
>> Number of obs: 368, groups: Mom:Pop, 184; Pop, 42
>>
>> This last model entails less parameters than the previous one  (because 
>> it doesn't calculate any correlations), but its AIC is also  much higher. 
>> Other than that, what differs between the two previous  models?
>>
>> In view of my problematic, what do you suggest me to do?
>>
>> I thank you in advance for any help you might be able to provide and 
>> look forward to receiving your recommendations.
>>
>> Best,
>>
>> Alessia
>>
>> *************************************************************
>> Alessia Guggisberg, PhD
>> Postdoctoral Fellow
>> Department of Botany
>> University of British Columbia
>> 3529-6270 University Boulevard
>> Vancouver, BC, V6T 1Z4
>> Canada
>>
>> Email: alessiag at interchange.ubc.ca
>>
>> *************************************************************
>> [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>



From cat.dev.urandom at gmail.com  Thu Apr  8 21:10:53 2010
From: cat.dev.urandom at gmail.com (D Chaws)
Date: Thu, 8 Apr 2010 15:10:53 -0400
Subject: [R-sig-ME] lme and prediction intervals
In-Reply-To: <E6293527-7E38-4AE8-A0C4-C91D32D3F7DA@anu.edu.au>
References: <u2m8e8b187b1004061400w427389fu8369097a7f89440a@mail.gmail.com>
	<t2vdcf23fb81004062117v1a2ba184n52e987d5148a3359@mail.gmail.com>
	<E6293527-7E38-4AE8-A0C4-C91D32D3F7DA@anu.edu.au>
Message-ID: <u2pdcf23fb81004081210h1ecdfda3ie330cfcf943a57f9@mail.gmail.com>

Interesting, I thought I had at least defined my problem in the most
straightforward way possible (twice in fact in this thread).

Given that concrete example and that example only, then the field is
settled on how to
compute the SEs?

On Wed, Apr 7, 2010 at 1:47 AM, John Maindonald
<john.maindonald at anu.edu.au> wrote:
> There is no uncertainty about SEs of predictions, once the
> prediction problem has been properly delimited.  As often,
> the problem has to be sufficiently well defined that "integrate
> random and fixed effects variance components" (not the
> language that I would use) has, in any specific instance,
> a well-defined meaning. Specifically, note that the SEs change
> depending on the population for which predictions are made.
> Use of MCMC does not cause this issue to go away, though
> it may provide a way to address it once the prediction has
> been properly delimited.
>
> The DAAG package has the dataset ant111b.  One may fit
> the model:
>
> ant111b.lme <- lme(fixed=harvwt ~ 1, random = ~1 | site,
>                   data=ant111b)
>
> One might make predictions:
> 1) for a new parcel at an existing site
> 2) for a new parcel at a new site
> 3) for the average of two parcels at a new site
>
> These will all lead to different SEs.  1 < 3 < 2
>
> In these instances it is fairly easy, if one believes
> the model, to calculate the different SEs.
>
> More generally, it is necessary to tease the
> variance-covariance structure apart, then putting
> it back together in a manner that reflects the
> desired generalization.  At least for various
> special cases, this can be automated, based on
> conventions for describing the intended
> generalization, and there is software that does
> this.
>
> This is an issue for the use of AIC to compare mixed
> effects models.  There is an implicit assumption that
> generalizations are for individual units at the population
> level.  This does not necessarily reflect the intended
> use of the model results.
>
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> http://www.maths.anu.edu.au/~johnm
>
> On 07/04/2010, at 2:17 PM, D Chaws wrote:
>
>> Very interesting.  Is it really the state of the field that there is uncertainty
>> about the how to integrate random and fixed effects variance components?
>> That seems like quite a hole.  Does that mean the best approach is probably
>> an empirical one then, through something like MCMC?
>>
>> -- DC
>>
>> On Tue, Apr 6, 2010 at 5:00 PM, David Hsu <dhsu2 at uw.edu> wrote:
>>> D Chaws wrote, Tue Apr 6 04:48:33 CEST 2010:
>>>
>>>> As a professional statistician, what is the appropriate method to
>>>> compute the SE of these predictions which accounts for the variance of
>>>> the fixed and random effects?
>>>
>>> I asked the same question myself about prediction last month.  I think
>>> Doug's response to me was, in a nutshell, how can you statistically
>>> *define* the variance contribution of the random effects?  (Doug,
>>> please correct me if I am wrong or over-simplifying).  After thinking
>>> about it for awhile, I indeed can *not* see what the variance of the
>>> random effect means from a classical perspective.
>>>
>>> Nobody seems to have conceptual difficulties with the errors from the
>>> fixed effects, so I'll sketch out a toy example to show how I've
>>> thought about it in terms of the theoretical statistics that I dimly
>>> remember (again, corrections from anyone are most welcome).
>>>
>>> Writing it out, a simple linear model is Y ~ N( A + BX, s^2).  Our
>>> vector of parameters in the first distribution is (theta_1) = (A, B,
>>> s).  From a classical perspective, A and B are fixed parameters, so
>>> that when we estimate A, B, we are maximizing the likelihood L:
>>>
>>> L ( theta_1 | X ) = P ( Y=y | theta_1 ) = 1/sqrt (2 pi sigma^2) exp -
>>> (Y - A - BX )^2 / sigma^2
>>>
>>> where (theta_1) is set by definite numbers, (theta_1) = (A, B, s).
>>>
>>> Now, thinking about the random effects model, we're saying that A is a
>>> random effect, so it's not just a set of numbers.  Therefore A is a
>>> random variable, distributed by A ~ N(mu, sigma^2).  Our second vector
>>> of parameters for this distribution is (theta_2) = (mu, sigma).  On
>>> the face of it, this doesn't necessarily seem catastrophic, since we
>>> just want the marginal probability distribution function for Y based
>>> on the joint probability of Y, A,
>>>
>>> P (Y=y | theta_1) = \int^\infty_infty P ( Y=y, A=a | theta_1, theta_2) da
>>>
>>> However, this is where I get stuck in the classical perspective.  We
>>> need to state *something* about the quantity P ( Y=y, A=a | theta_1,
>>> theta_2) inside the integral, but it's not clear to me what we can say
>>> about the relationship of A and Y, and presumably theta_2 is derived
>>> from the observations of Y.  I think Doug's point is that if we have
>>> the probability P ( Y=y, A=a | theta_1, theta_2), you can't just use
>>> conditioning to break it down such as:
>>>
>>> P ( Y=y, A=a | theta_1, theta_2) *not* equal to P ( Y=y | theta_1)
>>> times P ( A=a | theta_2)
>>>
>>> because somehow you got (or would like to get) theta_2 based on the Y
>>> (data) as well.  So they A and Y are not independent.
>>>
>>> In the Bayesian perspective, I guess you'd say that the posterior =
>>> prior x likelihood, so that:
>>>
>>> P ( theta_1, theta_2 | A, Y)  is proportional to P ( theta_1) times P
>>> ( theta_2 | A, Y, theta_1)
>>>
>>> and then insert some belief about the the prior distribution of
>>> theta_1, and do this iteratively for each of the parameter values
>>> until you get convergence.
>>>
>>> Anyway, this is how I've thought about it.  Corrections welcome.
>>>
>>> David
>>>
>>>
>>> --
>>> David Hsu
>>> PhD Candidate, Urban Planning
>>> University of Washington
>>> (e-mail) dhsu2 at uw.edu
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



From j.hadfield at ed.ac.uk  Fri Apr  9 11:04:34 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 9 Apr 2010 10:04:34 +0100
Subject: [R-sig-ME] variance structure in lme/lmer
In-Reply-To: <121EB05A386845FB88C384B5876264D1@Guggisberg>
References: <5484B83D4A00471FB4456A35712C1971@Guggisberg>
	<A8CFA9F9-2A41-4882-9199-803E2DB8D91B@ed.ac.uk>
	<121EB05A386845FB88C384B5876264D1@Guggisberg>
Message-ID: <E2DB66E8-678A-4760-8C1F-B24C905785F7@ed.ac.uk>

Hi,

I think

model=lme(above~Treatment * Range, random = list(~ at.level(Range,  
"native"):Treatment-1|Pop/mom, ~ at.level(Range,  
"invasive"):Treatment-1|Pop/mom), weights=varIdent(form=~1| 
Treatment*Range))

should do the job.

Cheers,

Jarrod


On 8 Apr 2010, at 18:08, Alessia Guggisberg wrote:

> Hi Jarrod
>
> Thank you so much for your reply!
>
> Indeed, each population/mom belongs to one type of range (native or  
> invasive) solely, but occurs in both treatment plots. I've just  
> tried your suggestion and its seems to work fine:
>
> model=lmer(above~Treatment * Range * Ct0.LLL + (at.level(Range,  
> "native"):Treatment-1|Pop/Mom) +  
> (at.level(Range,"invasive"):Treatment-1|Pop/Mom))
>
> Random effects:
> Groups       Name Variance           Std.Dev.           Corr
> Mom:Pop  at.level(Range, "invasive"):TreatmentControl       1.1326e 
> +01 3.3654e+00
>                 at.level(Range, "invasive"):TreatmentHerbivory  
> 9.1458e-01     9.5633e-01        0.292
> Mom:Pop  at.level(Range, "native"):TreatmentControl          1.1868e 
> +01 3.4451e+00
>                 at.level(Range, "native"):TreatmentHerbivory 1.7996e 
> +00     1.3415e+00       0.396
> Pop          at.level(Range, "invasive"):TreatmentControl         
> 1.1083e-09 3.3291e-05
>                 at.level(Range, "invasive"):TreatmentHerbivory  
> 2.9827e-01      5.4614e-01        0.000
> Pop          at.level(Range, "native"):TreatmentControl 5.5788e 
> +00      2.3619e+00
>                 at.level(Range, "native"):TreatmentHerbivory 1.5701e 
> +00     1.2530e+00        0.839
> Residual 1.1545e+00     1.0745e+00
> Number of obs: 368, groups: Mom:Pop, 184; Pop, 42
>
> Also, the BLUPs are now 'logical' as I get zero-values for  
> populations/moms that do not occur in a given range.
>
> The question remains though, whether I should additionnally account  
> for heterogeneity in the innermost residuals (like 'weights' in  
> lme), and if so, how I should implement that in lmer.
>
> Thanks again for your precious help; thanks to you, I've just made a  
> big step today....
>
> Best,
>
> Alessia
>
>
> *************************************************************
> Alessia Guggisberg, PhD
> Postdoctoral Fellow
> Department of Botany
> University of British Columbia
> 3529-6270 University Boulevard
> Vancouver, BC, V6T 1Z4
> Canada
>
> Email: alessiag at interchange.ubc.ca
>
> *************************************************************
> ----- Original Message ----- From: "Jarrod Hadfield" <j.hadfield at ed.ac.uk 
> >
> To: "Alessia Guggisberg" <alessiag at interchange.ubc.ca>
> Cc: <r-sig-mixed-models at r-project.org>
> Sent: Thursday, April 08, 2010 2:22 AM
> Subject: Re: [R-sig-ME] variance structure in lme/lmer
>
>
>> Dear Alessia,
>>
>> I think the problem is that  individuals from a population all  
>> belong  to one type (native or invasive) (is this true?) If this is  
>> the case  your 4x4 covariance matrices needs to look like
>>
>>        TreatmentControl:Rangenative   *  *  0  0
>>    TreatmentHerbivory:Rangenative   *  *  0  0
>> TreatmentHerbivory:Rangeinvasive   0  0  *  *
>> TreatmentHerbivory:Rangeinvasive   0  0  *  *
>>
>> where * indicates it could be estimated and 0 not.
>>
>> To fit such a covariance matrix  try
>>
>> (at.level(Range, "native"):Treatment-1|Pop)+(at.level(Range,  
>> "invasive"):Treatment-1|Pop)
>>
>> in lmer.  The at.level function is at the bottom of the email
>>
>> If individuals with the same mother have the same treatment then  
>> the pop/mom matrix needs to be
>>
>>
>>        TreatmentControl:Rangenative   *  0  0  0
>>    TreatmentHerbivory:Rangenative   0  *  0  0
>> TreatmentHerbivory:Rangeinvasive   0  0  *  0
>> TreatmentHerbivory:Rangeinvasive   0  0  0  *
>>
>> and you can use either
>>
>> (at.level(Range, "native"):at.level(Treatment, "Herbivory")-1|  
>> Pop:mom)+(at.level(Range, "invasive"):at.level(Treatment,  
>> "Herbivory")-1|Pop:mom)+(at.level(Range,  
>> "native"):at.level(Treatment, "Control")-1|Pop:mom)+ 
>> (at.level(Range, "invasive"):at.level(Treatment, Control")-1|Pop:mom)
>>
>> or
>>
>> (at.level(subgroup, 1)|Pop:mom)+ (at.level(subgroup, 2)|Pop:mom) +  
>> (at.level(subgroup, 3)|Pop:mom) + (at.level(subgroup, 4)|Pop:mom)
>>
>> I'm not sure if you can use this type of syntax in lme, but without  
>> allowing different residual variances for the subgroups I would be   
>> very cautious about the results.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>> at.level<-function (x, level)
>> {
>>    if (is.numeric(level)) {
>>        M <- outer(x, levels(x)[level], "==")
>>    }
>>    else {
>>        M <- outer(x, level, "==")
>>    }
>>    mode(M) <- "numeric"
>>    M
>> }
>> <environment: namespace:MCMCglmm>
>>
>>
>>
>> On 8 Apr 2010, at 06:50, Alessia Guggisberg wrote:
>>
>>> Dear R-sig-mixed-models list members
>>>
>>> I apologise in advance, if my question seems trivial; I'm new to  
>>> mixed-models in R.
>>>
>>> To make things easier, I'm giving you an example, followed by the  
>>> questions I'm hoping to be able to address with one of you.
>>>
>>> Study: Response of different populations of plants from two   
>>> different ranges (Europe vs. North America) to various stresses in  
>>> a  greenhouse experiment
>>> Study question: Do populations from the native range (Europe)  
>>> differ  in terms of response from the ones of the introduced range  
>>> (North  America)?
>>> Type of data: Growth and reproductive data
>>> Example of mixed model: above-ground biomass as a function of   
>>> treatment (control vs. stress), range (Europe vs. North America)  
>>> and  a covariate (in this case, longest leaf length at t0, to  
>>> account for  size difference prior to stress)
>>>
>>> model=lme(above~Treatment * Range * t0.LLL, random= ~1|Pop/Mom)
>>>
>>> model=lmer(above~Treatment * Range * t0.LLL + (1|Pop/Mom))
>>>
>>> Due to the introduction history (bottleneck), I expect less  
>>> genetic variation in the introduced than in the native range,  
>>> hence less variation in response in the introduced than native  
>>> range. Indeed, inspection of raw data and residuals indicate  
>>> higher variance for  native than introduced range. Similarly, I  
>>> observe less variation in  response in the stress than in the  
>>> control plot. Obviously, these  observations suggest violation of  
>>> homoscedasticity. I therefore  would like to test and eventually  
>>> account for difference in  variances between the different  
>>> subgroups: (i) Europe-control, (ii)  Europe-stress, (iii) North  
>>> America-control, (iv) North America-stress.
>>>
>>> Following options are possible:
>>>
>>> - account for heteroscedasticity in the innermost residuals:
>>>
>>> model=lme(above~Treatment * Range * t0.LLL, random= ~1|Pop/Mom,  
>>> weights=varIdent(form=~1|Treatment*Range))
>>>
>>> Random effects:
>>> Formula: ~1 | Pop
>>>               (Intercept)
>>> StdDev:     0.997503
>>>
>>> Formula: ~1 | Mom %in% Pop
>>>               (Intercept)     Residual
>>> StdDev:     1.150242      3.684324
>>>
>>> Variance function:
>>> Structure: Different standard deviations per stratum
>>> Formula: ~1 | Treatment * Range
>>> Parameter estimates:
>>>   Control*native   Herbivory*native   Control*invasive  
>>> Herbivory*invasive
>>>   1.0000000        0.3343747           0.9324055           0.2389115
>>>
>>> Is it true, that weights cannot be incorporated in lmer?
>>>
>>> - stratify the variance for the random effects:
>>>
>>> subgroup=factor(Treatment:Range)
>>> model=lme(above~Treatment * Range * t0.LLL, random= ~subgroup-1| 
>>> Pop/ Mom)
>>> ## warning message: Fewer observations than random effects in all   
>>> level 2 groups
>>>
>>> model=lmer(above~Treatment * Range * t0.LLL + (0 + subgroup|Pop/ 
>>> Mom))
>>>
>>> Random effects:
>>> Groups       Name                                         Variance  
>>> Corr
>>> Mom:Pop    TreatmentControl:Rangenative      11.783704        0.000
>>>                  TreatmentHerbivory:Rangenative   1.714778  
>>> 0.419    0.000
>>>                  TreatmentControl:Rangeinvasive 378          
>>> -0.003    0.311        -0.001
>>>                  TreatmentHerbivory:Rangeinvasive 0.819599
>>> Pop            TreatmentControl:Rangenative       5.578492
>>>                  TreatmentHerbivory:Rangenative    1.569965 1.000
>>>                  TreatmentControl:Rangeinvasive     0.029164  
>>> 0.839     0.839
>>>                  TreatmentHerbivory:Rangeinvasive  0.315794  
>>> 1.000     1.000        0.839
>>> Residual                                                          
>>> 1.239337
>>> Number of obs: 368, groups: Mom:Pop, 184; Pop, 42
>>>
>>> Why do I get an error message, when I run the model in lme?
>>>
>>> - another option found in R forums would be to code each subgroup   
>>> with a dummy variable, as follows (I only know how to implement  
>>> that  method with lmer):
>>>
>>> nativeControl=as.numeric(factor(Range=="native" &   
>>> Treatment=="Control"))
>>> invasiveControl=as.numeric(factor(Range=="invasive" &  
>>> Treatment=="Control"))
>>> nativeHerbivory=as.numeric(factor(Range=="native" &  
>>> Treatment=="Herbivory"))
>>> invasiveHerbivory=as.numeric(factor(Range=="invasive" &  
>>> Treatment=="Herbivory"))
>>> model=lmer(above~Treatment*Range*t0.LLL + (0 + nativeControl|Pop/  
>>> Mom) + (0 + invasiveControl|Pop/Mom) + (0 + nativeHerbivory|Pop/ 
>>> Mom)  + (0 + invasiveHerbivory|Pop/Mom))
>>>
>>> Random effects:
>>> Groups       Name                   Variance
>>> Mom:Pop   invasiveHerbivory    0.0000e+00
>>> Mom:Pop   nativeHerbivory      0.0000e+00
>>> Mom:Pop   invasiveControl       9.7939e-01
>>> Mom:Pop   nativeControl         1.0516e+00
>>> Pop          invasiveHerbivory    0.0000e+00
>>> Pop          nativeHerbivory      2.4815e-10
>>> Pop          invasiveControl      1.7994e-09
>>> Pop          nativeControl         9.1133e-01
>>> Residual                                4.1959e+00
>>> Number of obs: 368, groups: Mom:Pop, 184; Pop, 42
>>>
>>> This last model entails less parameters than the previous one   
>>> (because it doesn't calculate any correlations), but its AIC is  
>>> also  much higher. Other than that, what differs between the two  
>>> previous  models?
>>>
>>> In view of my problematic, what do you suggest me to do?
>>>
>>> I thank you in advance for any help you might be able to provide  
>>> and look forward to receiving your recommendations.
>>>
>>> Best,
>>>
>>> Alessia
>>>
>>> *************************************************************
>>> Alessia Guggisberg, PhD
>>> Postdoctoral Fellow
>>> Department of Botany
>>> University of British Columbia
>>> 3529-6270 University Boulevard
>>> Vancouver, BC, V6T 1Z4
>>> Canada
>>>
>>> Email: alessiag at interchange.ubc.ca
>>>
>>> *************************************************************
>>> [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>> -- 
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>
>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100409/b026dbbf/attachment.pl>

From kevin.thorpe at utoronto.ca  Fri Apr  9 13:03:34 2010
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Fri, 09 Apr 2010 07:03:34 -0400
Subject: [R-sig-ME] Another case of -1.0 correlation of random effects
Message-ID: <4BBF0986.70309@utoronto.ca>

Hello.

I know this has come up a couple times recently, but I'm still not sure 
what to do about it in my data.  Note that my sessionInfo() will be at 
the bottom.

My data come from a crossover trial and are balanced.

 > str(gluc)
'data.frame':	96 obs. of  4 variables:
  $ Subject  : int  1 2 3 5 6 7 10 11 12 13 ...
  $ Treatment: Factor w/ 2 levels "Barley","Oat": 1 1 1 1 1 1 1 1 1 1 ...
  $ Dose     : int  8 8 8 8 8 8 8 8 8 8 ...
  $ iAUC     : num  110 256 129 207 244 ...

 > xtabs(~Treatment+Dose,data=gluc)
          Dose
Treatment  0  2  4  8
    Barley 12 12 12 12
    Oat    12 12 12 12

I plot the data (attached as gluc.pdf, if it comes through).

 From the plot, I think I want to fit the model as:

lmer(iAUC~Treatment+Dose+(Treatment|Subject)+(Dose|Subject),data=gluc)

It could possibly be argued that the (Treatment|Subject) part is not 
needed.  When I fit this, I got -1.0 correlation within the Dose random 
effects.  To simplify, I will fit a simpler model, since the issue persists.

 > lmer(iAUC~Dose+(Dose|Subject),data=gluc,subset=Treatment=="Oat")
Linear mixed model fit by REML
Formula: iAUC ~ Dose + (Dose | Subject)
    Data: gluc
  Subset: Treatment == "Oat"
    AIC   BIC logLik deviance REMLdev
  562.6 573.9 -275.3    563.1   550.6
Random effects:
  Groups   Name        Variance Std.Dev. Corr
  Subject  (Intercept) 8274.324 90.9633
           Dose          16.214  4.0266  -1.000
  Residual             4862.319 69.7303
Number of obs: 48, groups: Subject, 12

Fixed effects:
             Estimate Std. Error t value
(Intercept)  309.352     30.539  10.130
Dose         -14.424      3.596  -4.012

Correlation of Fixed Effects:
      (Intr)
Dose -0.647

Now, a plot created by (and attached as lmlist.pdf):

plot(confint(lmList(iAUC~Dose|Subject,data=gluc,subset=Treatment=="Oat"),pooled=TRUE),order=1)

shows (I think) a strong negative correlation between the intercept and 
slope random effects for Dose.

So, I would appreciate some advice on how I might specify these random 
effects correctly.

One last thing I tried.  If I treat Dose as a factor (which might be 
reasonable) rather than numeric, I don't get any -1.0 correlations.

 > lmer(iAUC~dose+(dose|Subject),data=gluc,subset=Treatment=="Oat")
Linear mixed model fit by REML
Formula: iAUC ~ dose + (dose | Subject)
    Data: gluc
  Subset: Treatment == "Oat"
    AIC   BIC logLik deviance REMLdev
  545.2 573.3 -257.6      547   515.2
Random effects:
  Groups   Name        Variance Std.Dev. Corr
  Subject  (Intercept)  7509.9   86.660
           dose2       11993.0  109.513  -0.321
           dose4        6399.5   79.997   0.043  0.873
           dose8        6051.7   77.793  -0.743  0.433  0.306
  Residual              1206.4   34.733
Number of obs: 48, groups: Subject, 12

Fixed effects:
             Estimate Std. Error t value
(Intercept)  293.567     26.951  10.893
dose2          6.692     34.648   0.193
dose4        -39.975     27.099  -1.475
dose8       -105.517     26.558  -3.973

Correlation of Fixed Effects:
       (Intr) dose2  dose4
dose2 -0.380
dose4 -0.103  0.786
dose8 -0.724  0.443  0.360

Thanks in advance and here is my sessionInfo().

 > sessionInfo()
R version 2.10.1 Patched (2009-12-29 r50852)
i686-pc-linux-gnu

locale:
  [1] LC_CTYPE=en_US       LC_NUMERIC=C         LC_TIME=en_US
  [4] LC_COLLATE=C         LC_MONETARY=C        LC_MESSAGES=en_US
  [7] LC_PAPER=en_US       LC_NAME=C            LC_ADDRESS=C
[10] LC_TELEPHONE=C       LC_MEASUREMENT=en_US LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999375-32   Matrix_0.999375-33 lattice_0.17-26

loaded via a namespace (and not attached):
[1] grid_2.10.1


-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
-------------- next part --------------
A non-text attachment was scrubbed...
Name: gluc.pdf
Type: application/pdf
Size: 49449 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100409/a55f7d89/attachment.pdf>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: lmlist.pdf
Type: application/pdf
Size: 9444 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100409/a55f7d89/attachment-0001.pdf>

From lamprianou at yahoo.com  Fri Apr  9 14:03:55 2010
From: lamprianou at yahoo.com (Iasonas Lamprianou)
Date: Fri, 9 Apr 2010 05:03:55 -0700 (PDT)
Subject: [R-sig-ME] MCMCglmm
In-Reply-To: <62320BBA-C45B-4AE3-8783-6ABC174FE88C@ed.ac.uk>
Message-ID: <308306.27924.qm@web58903.mail.re1.yahoo.com>

Dear Jarrod Hadfield
I followed your advice but got this message:

 m5_06.mcmc<- MCMCglmm(score ~ 1, random=~us(0+phase):marker+candidate+batch, data=mg2006_sub)

Warning in MCMCglmm(score ~ 1, random = ~us(0 + phase):marker + candidate +  :
  some combinations in us(0 + phase):marker do not exist and 118 missing records have been generated
Error in MCMCglmm(score ~ 1, random = ~us(0 + phase):marker + candidate +  : 
  ill-conditioned G/R structure: use proper priors if you haven't or rescale data if you have



could you please help me?

Dr. Iasonas Lamprianou


Assistant Professor (Educational Research and Evaluation)
Department of Education Sciences
European University-Cyprus
P.O. Box 22006
1516 Nicosia
Cyprus 
Tel.: +357-22-713178
Fax: +357-22-590539


Honorary Research Fellow
Department of Education
The University of Manchester
Oxford Road, Manchester M13 9PL, UK
Tel. 0044  161 275 3485
iasonas.lamprianou at manchester.ac.uk


--- On Thu, 8/4/10, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:

> From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
> Subject: Re: [R-sig-ME] MCMCglmm
> To: "Iasonas Lamprianou" <lamprianou at yahoo.com>
> Cc: r-sig-mixed-models at r-project.org
> Date: Thursday, 8 April, 2010, 15:10
> Dear Jason,
> 
> These should work:
> 
> m4.mcmc <- MCMCglmm(score ~ 1,
> random=~marker+marker:day+candidate 
> +batch, data=mg2006)
> m5 .mcmc<- MCMCglmm(score ~ 1,
> random=~us(1+day):marker+candidate 
> +batch, data=mg2006)
> 
> You may need to code day as a factor for m4, and as numeric
> for m5? 
> depending on the model you actually want to fit.
> 
> Cheers,
> 
> Jarrod
> 
> 
> On 8 Apr 2010, at 14:58, Iasonas Lamprianou wrote:
> 
> > Dear all,
> > I recently experimented with MCMCglmm and I loved
> (really loved) the? 
> > fact that it will give me confidence intervals for the
> variance of? 
> > the random effects. It seems that MCMC is a reasonable
> method to do? 
> > so, in contrast to REML which seems to have problems
> on this front.? 
> > However, MCMCglmm is painfully slower than lmer which
> is more? 
> > familiar to me. The good news is that the point
> estimates of lmer? 
> > are near the centre of the confidence intervals by
> MCMCglmm.
> >
> > I reduced my sample size a bit and managed to fit
> those two models? 
> > with lmer (the second would not fit because it needed
> 1.5GB or RAM).? 
> > Both seem to have a reasonable fit (at least at first
> look).
> >
> > m4 <- lmer(score ~
> 1+(1|marker/day)+(1|candidate)+(1|batch), mg2006)
> >
> > m5 <- lmer(score ~
> 1+(1+day|marker)+(1|candidate)+(1|batch), mg2006)
> >
> > I would like to run these two models above with
> MCMCglmm. Does? 
> > anyone know how to do it?
> >
> > Thank you for the help
> >
> > Jason
> >
> > Dr. Iasonas Lamprianou
> >
> >
> > Assistant Professor (Educational Research and
> Evaluation)
> > Department of Education Sciences
> > European University-Cyprus
> > P.O. Box 22006
> > 1516 Nicosia
> > Cyprus
> > Tel.: +357-22-713178
> > Fax: +357-22-590539
> >
> >
> > Honorary Research Fellow
> > Department of Education
> > The University of Manchester
> > Oxford Road, Manchester M13 9PL, UK
> > Tel. 0044? 161 275 3485
> > iasonas.lamprianou at manchester.ac.uk
> >
> >
> > --- On Thu, 8/4/10, r-sig-mixed-models-request at r-project.org
> <r-sig-mixed-models-request at r-project.org
> 
> > > wrote:
> >
> >> From: r-sig-mixed-models-request at r-project.org
> <r-sig-mixed-models-request at r-project.org
> 
> >> >
> >> Subject: R-sig-mixed-models Digest, Vol 40, Issue
> 15
> >> To: r-sig-mixed-models at r-project.org
> >> Date: Thursday, 8 April, 2010, 12:13
> >> Send R-sig-mixed-models mailing list
> >> submissions to
> >>? ???r-sig-mixed-models at r-project.org
> >>
> >> To subscribe or unsubscribe via the World Wide
> Web, visit
> >>? ???https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> or, via email, send a message with subject or body
> 'help'
> >> to
> >>? ???r-sig-mixed-models-request at r-project.org
> >>
> >> You can reach the person managing the list at
> >>? ???r-sig-mixed-models-owner at r-project.org
> >>
> >> When replying, please edit your Subject line so it
> is more
> >> specific
> >> than "Re: Contents of R-sig-mixed-models
> digest..."
> >>
> >>
> >> Today's Topics:
> >>
> >>? ? 1. Re: Multi-level models Odds ratio
> (E
> >> T)
> >>? ? 2. Re: Multi-level models Odds ratio
> >> (ONKELINX, Thierry)
> >>? ? 3. Re: Multi-level models Odds ratio
> (E
> >> T)
> >>? ? 4. Re: Multi-level models Odds ratio
> >> (Andy Fugard (Work))
> >>? ? 5. Re: Multi-level models Odds ratio
> (E
> >> T)
> >>
> >>
> >>
> ----------------------------------------------------------------------
> >>
> >> Message: 1
> >> Date: Thu, 8 Apr 2010 11:27:49 +0100
> >> From: E T <2nuzzbot at gmail.com>
> >> To: Daniel Ezra Johnson <danielezrajohnson at gmail.com>
> >> Cc: "r-sig-mixed-models at r-project.org"
> >>? ???<r-sig-mixed-models at r-project.org>
> >> Subject: Re: [R-sig-ME] Multi-level models Odds
> ratio
> >> Message-ID:
> >>? ???<l2w706f8d1f1004080327re8708f46mc7d334f41ae19a10 at mail.gmail.com>
> >> Content-Type: text/plain
> >>
> >> odds.ratios = exp(coefs(model))
> >>
> >> Thanks, however unfortunately when I try the above
> command
> >> I receive the
> >> following error:
> >>
> >> Error: could not find function "coefs"
> >>
> >> Regards
> >>
> >> Et
> >>
> >>
> >>
> >> On Wed, Apr 7, 2010 at 5:47 PM, Daniel Ezra
> Johnson <
> >> danielezrajohnson at gmail.com>
> >> wrote:
> >>
> >>> something like odds.ratios =
> exp(coefs(model))
> >>>
> >>>
> >>> On Apr 7, 2010, at 12:28 PM, E T <2nuzzbot at gmail.com>
> >> wrote:
> >>>
> >>>???Hi all,
> >>>>
> >>>> Apologies for the simplicity of my
> question....
> >> however any advice is
> >>>> greatly appreciated. Thanks
> >>>>
> >>>> Is there a specific command available to
> obtain
> >> the odds ratios produced
> >>>> from a multilevel logistic model?
> >>>>
> >>>> I have estimated a multi-level logistic
> model
> >> using the lme4 package. I
> >>>> can
> >>>> obtain results using the 'summary'
> command,
> >> however I would like to obtain
> >>>> the computed odds ratios.
> >>>> (Similar to the output that can be
> produced for
> >> logistic GLM using the
> >>>> logistic.display command from the epicalc
> >> package).
> >>>>
> >>>>? ? [[alternative HTML version
> >> deleted]]
> >>>>
> >>>>
> _______________________________________________
> >>>> R-sig-mixed-models at r-project.org
> >> mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>
> >>>
> >>
> >>? ???[[alternative HTML version
> deleted]]
> >>
> >>
> >>
> >> ------------------------------
> >>
> >> Message: 2
> >> Date: Thu, 8 Apr 2010 12:32:01 +0200
> >> From: "ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be>
> >> To: "E T" <2nuzzbot at gmail.com>,
> >> "Daniel Ezra Johnson"
> >>? ???<danielezrajohnson at gmail.com>
> >> Cc: r-sig-mixed-models at r-project.org
> >> Subject: Re: [R-sig-ME] Multi-level models Odds
> ratio
> >> Message-ID:
> >>? ???<2E9C414912813E4EB981326983E0A104071B69A6 at inboexch.inbo.be>
> >> Content-Type: text/plain;
> >> charset="us-ascii"
> >>
> >> It should be
> >>
> >> exp(coef(model))
> >>
> >> Without the "s"
> >>
> >> HTH,
> >>
> >> Thierry
> >>
> ------------------------------------------------------------------------
> >> ----
> >> ir. Thierry Onkelinx
> >> Instituut voor natuur- en bosonderzoek
> >> team Biometrie & Kwaliteitszorg
> >> Gaverstraat 4
> >> 9500 Geraardsbergen
> >> Belgium
> >>
> >> Research Institute for Nature and Forest
> >> team Biometrics & Quality Assurance
> >> Gaverstraat 4
> >> 9500 Geraardsbergen
> >> Belgium
> >>
> >> tel. + 32 54/436 185
> >> Thierry.Onkelinx at inbo.be
> >> www.inbo.be
> >>
> >> To call in the statistician after the experiment
> is done
> >> may be no more
> >> than asking him to perform a post-mortem
> examination: he
> >> may be able to
> >> say what the experiment died of.
> >> ~ Sir Ronald Aylmer Fisher
> >>
> >> The plural of anecdote is not data.
> >> ~ Roger Brinner
> >>
> >> The combination of some data and an aching desire
> for an
> >> answer does not
> >> ensure that a reasonable answer can be extracted
> from a
> >> given body of
> >> data.
> >> ~ John Tukey
> >>
> >>
> >>> -----Oorspronkelijk bericht-----
> >>> Van: r-sig-mixed-models-bounces at r-project.org
> >>
> >>> [mailto:r-sig-mixed-models-bounces at r-project.org]
> >> Namens E T
> >>> Verzonden: donderdag 8 april 2010 12:28
> >>> Aan: Daniel Ezra Johnson
> >>> CC: r-sig-mixed-models at r-project.org
> >>> Onderwerp: Re: [R-sig-ME] Multi-level models
> Odds
> >> ratio
> >>>
> >>> odds.ratios = exp(coefs(model))
> >>>
> >>> Thanks, however unfortunately when I try the
> above
> >> command I
> >>> receive the following error:
> >>>
> >>> Error: could not find function "coefs"
> >>>
> >>> Regards
> >>>
> >>> Et
> >>>
> >>>
> >>>
> >>> On Wed, Apr 7, 2010 at 5:47 PM, Daniel Ezra
> Johnson
> >> <
> >>> danielezrajohnson at gmail.com>
> >> wrote:
> >>>
> >>>> something like odds.ratios =
> exp(coefs(model))
> >>>>
> >>>>
> >>>> On Apr 7, 2010, at 12:28 PM, E T <2nuzzbot at gmail.com>
> >> wrote:
> >>>>
> >>>>???Hi all,
> >>>>>
> >>>>> Apologies for the simplicity of my
> >> question.... however
> >>> any advice is
> >>>>> greatly appreciated. Thanks
> >>>>>
> >>>>> Is there a specific command available
> to
> >> obtain the odds ratios
> >>>>> produced from a multilevel logistic
> model?
> >>>>>
> >>>>> I have estimated a multi-level
> logistic model
> >> using the
> >>> lme4 package.
> >>>>> I can obtain results using the
> 'summary'
> >> command, however I would
> >>>>> like to obtain the computed odds
> ratios.
> >>>>> (Similar to the output that can be
> produced
> >> for logistic GLM using
> >>>>> the logistic.display command from the
> epicalc
> >> package).
> >>>>>
> >>>>>? ? [[alternative HTML
> version
> >> deleted]]
> >>>>>
> >>>>>
> >> _______________________________________________
> >>>>> R-sig-mixed-models at r-project.org
> >> mailing list
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>>
> >>>>
> >>>
> >>>? ???[[alternative HTML
> version
> >> deleted]]
> >>>
> >>>
> _______________________________________________
> >>> R-sig-mixed-models at r-project.org
> >> mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>
> >>
> >> Druk dit bericht a.u.b. niet onnodig af.
> >> Please do not print this message unnecessarily.
> >>
> >> Dit bericht en eventuele bijlagen geven enkel de
> visie van
> >> de schrijver weer
> >> en binden het INBO onder geen enkel beding, zolang
> dit
> >> bericht niet bevestigd is
> >> door een geldig ondertekend document. The views
> expressed
> >> in? this message
> >> and any annex are purely those of the writer and
> may not be
> >> regarded as stating
> >> an official position of INBO, as long as the
> message is not
> >> confirmed by a duly
> >> signed document.
> >>
> >>
> >>
> >> ------------------------------
> >>
> >> Message: 3
> >> Date: Thu, 8 Apr 2010 11:35:03 +0100
> >> From: E T <2nuzzbot at gmail.com>
> >> To: Daniel Ezra Johnson <danielezrajohnson at gmail.com>
> >> Cc: "r-sig-mixed-models at r-project.org"
> >>? ???<r-sig-mixed-models at r-project.org>
> >> Subject: Re: [R-sig-ME] Multi-level models Odds
> ratio
> >> Message-ID:
> >>? ???<i2y706f8d1f1004080335q84f61b78u8c7b656b67a08a8e at mail.gmail.com>
> >> Content-Type: text/plain
> >>
> >> If I use the command coef(model) this extracts
> the
> >> coefficients in the
> >> model, however if I try exp(coef(model)) I receive
> an
> >> error:
> >>
> >> Error in exp(coef(model)) : Non-numeric argument
> to
> >> mathematical function
> >>
> >> I could manually get the exp of each factor in my
> >> model..... but as I have a
> >> large model (and also have numerous other models
> to
> >> produce), I was
> >> wondering if there was an automated method
> >>
> >> Regards
> >>
> >> Et
> >>
> >> On Thu, Apr 8, 2010 at 11:27 AM, E T <2nuzzbot at gmail.com>
> >> wrote:
> >>
> >>> odds.ratios = exp(coefs(model))
> >>>
> >>> Thanks, however unfortunately when I try the
> above
> >> command I receive the
> >>> following error:
> >>>
> >>> Error: could not find function "coefs"
> >>>
> >>> Regards
> >>>
> >>> Et
> >>>
> >>>
> >>>
> >>>
> >>> On Wed, Apr 7, 2010 at 5:47 PM, Daniel Ezra
> Johnson
> >> <
> >>> danielezrajohnson at gmail.com>
> >> wrote:
> >>>
> >>>> something like odds.ratios =
> exp(coefs(model))
> >>>>
> >>>>
> >>>> On Apr 7, 2010, at 12:28 PM, E T <2nuzzbot at gmail.com>
> >> wrote:
> >>>>
> >>>>???Hi all,
> >>>>>
> >>>>> Apologies for the simplicity of my
> >> question.... however any advice is
> >>>>> greatly appreciated. Thanks
> >>>>>
> >>>>> Is there a specific command available
> to
> >> obtain the odds ratios produced
> >>>>> from a multilevel logistic model?
> >>>>>
> >>>>> I have estimated a multi-level
> logistic model
> >> using the lme4 package. I
> >>>>> can
> >>>>> obtain results using the 'summary'
> command,
> >> however I would like to
> >>>>> obtain
> >>>>> the computed odds ratios.
> >>>>> (Similar to the output that can be
> produced
> >> for logistic GLM using the
> >>>>> logistic.display command from the
> epicalc
> >> package).
> >>>>>
> >>>>>? ? [[alternative HTML
> version
> >> deleted]]
> >>>>>
> >>>>>
> >> _______________________________________________
> >>>>> R-sig-mixed-models at r-project.org
> >> mailing list
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>>
> >>>>
> >>>
> >>
> >>? ???[[alternative HTML version
> deleted]]
> >>
> >>
> >>
> >> ------------------------------
> >>
> >> Message: 4
> >> Date: Thu, 08 Apr 2010 12:48:30 +0200
> >> From: "Andy Fugard (Work)" <andy.fugard at sbg.ac.at>
> >> To: E T <2nuzzbot at gmail.com>
> >> Cc: "r-sig-mixed-models at r-project.org"
> >>? ???<r-sig-mixed-models at r-project.org>
> >> Subject: Re: [R-sig-ME] Multi-level models Odds
> ratio
> >> Message-ID: <4BBDB47E.8030305 at sbg.ac.at>
> >> Content-Type: text/plain; charset=ISO-8859-1
> >>
> >> Here's another example, borrowed from the help for
> "lmer":
> >>
> >>> gm1 <- glmer(cbind(incidence, size -
> incidence) ~
> >> period + (1 | herd),
> >>? ? ? ? ? ?
> ???family =
> >> binomial, data = cbpp)
> >>
> >> As you say, coef works:
> >>
> >>> coef(gm1)
> >> $herd
> >>? ? (Intercept)
> >>
> period2???period3???period4
> >> 1???-0.8085096 -0.9923347
> -1.128675
> >> -1.580374
> >> 2???-1.6974292 -0.9923347
> -1.128675
> >> -1.580374
> >> 3???-0.9922697 -0.9923347
> -1.128675
> >> -1.580374
> >> 4???-1.3592525 -0.9923347
> -1.128675
> >> -1.580374
> >> 5???-1.5885461 -0.9923347
> -1.128675
> >> -1.580374
> >> 6???-1.7987950 -0.9923347
> -1.128675
> >> -1.580374
> >> 7???-0.5091313 -0.9923347
> -1.128675
> >> -1.580374
> >> 8???-0.7991613 -0.9923347
> -1.128675
> >> -1.580374
> >> 9???-1.6361848 -0.9923347
> -1.128675
> >> -1.580374
> >> 10? -1.9394614 -0.9923347 -1.128675
> -1.580374
> >> 11? -1.4831632 -0.9923347 -1.128675
> -1.580374
> >> 12? -1.4633469 -0.9923347 -1.128675
> -1.580374
> >> 13? -2.0884474 -0.9923347 -1.128675
> -1.580374
> >> 14? -0.4278151 -0.9923347 -1.128675
> -1.580374
> >> 15? -1.9290041 -0.9923347 -1.128675
> -1.580374
> >>
> >> But note the "$herd" bit.? Since this model
> has a
> >> varying intercept by
> >> herd, you get a column in the resulting data frame
> called
> >> "herd".
> >>
> >> So you could try, for this example:
> >>
> >>> exp(coef(gm1)$herd)
> >>? ?
> (Intercept)???period2???period3???period4
> >> 1? ? 0.4455216 0.3707102 0.3234614
> 0.2058981
> >> 2? ? 0.1831538 0.3707102 0.3234614
> 0.2058981
> >> 3? ? 0.3707343 0.3707102 0.3234614
> 0.2058981
> >> 4? ? 0.2568527 0.3707102 0.3234614
> 0.2058981
> >> 5? ? 0.2042223 0.3707102 0.3234614
> 0.2058981
> >> 6? ? 0.1654982 0.3707102 0.3234614
> 0.2058981
> >> 7? ? 0.6010174 0.3707102 0.3234614
> 0.2058981
> >> 8? ? 0.4497060 0.3707102 0.3234614
> 0.2058981
> >> 9? ? 0.1947215 0.3707102 0.3234614
> 0.2058981
> >> 10???0.1437814 0.3707102 0.3234614
> >> 0.2058981
> >> 11???0.2269188 0.3707102 0.3234614
> >> 0.2058981
> >> 12???0.2314603 0.3707102 0.3234614
> >> 0.2058981
> >> 13???0.1238793 0.3707102 0.3234614
> >> 0.2058981
> >> 14???0.6519320 0.3707102 0.3234614
> >> 0.2058981
> >> 15???0.1452928 0.3707102 0.3234614
> >> 0.2058981
> >>
> >> Since the slopes don't vary by herd, you might
> also want
> >> just the fixed
> >> effects:
> >>
> >>> exp(fixef(gm1))
> >> (Intercept)? ???period2
> >>? ? period3?
> ???period4
> >>
> >>
> 0.2469585???0.3707102???0.3234614???0.2058981
> >>
> >> HTH,
> >>
> >> Andy
> >>
> >>
> >> E T wrote:
> >>> If I use the command coef(model) this extracts
> the
> >> coefficients in the
> >>> model, however if I try exp(coef(model)) I
> receive an
> >> error:
> >>>
> >>> Error in exp(coef(model)) : Non-numeric
> argument to
> >> mathematical function
> >>>
> >>> I could manually get the exp of each factor in
> my
> >> model..... but as I have a
> >>> large model (and also have numerous other
> models to
> >> produce), I was
> >>> wondering if there was an automated method
> >>>
> >>> Regards
> >>>
> >>> Et
> >>>
> >>> On Thu, Apr 8, 2010 at 11:27 AM, E T <2nuzzbot at gmail.com>
> >> wrote:
> >>>
> >>>> odds.ratios = exp(coefs(model))
> >>>>
> >>>> Thanks, however unfortunately when I try
> the above
> >> command I receive the
> >>>> following error:
> >>>>
> >>>> Error: could not find function "coefs"
> >>>>
> >>>> Regards
> >>>>
> >>>> Et
> >>>>
> >>>>
> >>>>
> >>>>
> >>>> On Wed, Apr 7, 2010 at 5:47 PM, Daniel
> Ezra
> >> Johnson <
> >>>> danielezrajohnson at gmail.com>
> >> wrote:
> >>>>
> >>>>> something like odds.ratios =
> >> exp(coefs(model))
> >>>>>
> >>>>>
> >>>>> On Apr 7, 2010, at 12:28 PM, E T
> <2nuzzbot at gmail.com>
> >> wrote:
> >>>>>
> >>>>>???Hi all,
> >>>>>> Apologies for the simplicity of
> my
> >> question.... however any advice is
> >>>>>> greatly appreciated. Thanks
> >>>>>>
> >>>>>> Is there a specific command
> available to
> >> obtain the odds ratios produced
> >>>>>> from a multilevel logistic model?
> >>>>>>
> >>>>>> I have estimated a multi-level
> logistic
> >> model using the lme4 package. I
> >>>>>> can
> >>>>>> obtain results using the
> 'summary'
> >> command, however I would like to
> >>>>>> obtain
> >>>>>> the computed odds ratios.
> >>>>>> (Similar to the output that can
> be
> >> produced for logistic GLM using the
> >>>>>> logistic.display command from the
> epicalc
> >> package).
> >>>>>>
> >>>>>>? ? [[alternative HTML
> >> version deleted]]
> >>>>>>
> >>>>>>
> >> _______________________________________________
> >>>>>> R-sig-mixed-models at r-project.org
> >> mailing list
> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>>>
> >>>
> >>>? ???[[alternative HTML
> version
> >> deleted]]
> >>>
> >>>
> _______________________________________________
> >>> R-sig-mixed-models at r-project.org
> >> mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >>
> >> -- 
> >> Andy Fugard, Postdoctoral researcher, ESF LogICCC
> project
> >> "Modeling human inference within the framework of
> >> probability logic"
> >> Department of Psychology, University of Salzburg,
> Austria
> >> http://www.andyfugard.info
> >>
> >>
> >>
> >> ------------------------------
> >>
> >> Message: 5
> >> Date: Thu, 8 Apr 2010 12:13:23 +0100
> >> From: E T <2nuzzbot at gmail.com>
> >> To: "Andy Fugard (Work)" <andy.fugard at sbg.ac.at>
> >> Cc: "r-sig-mixed-models at r-project.org"
> >>? ???<r-sig-mixed-models at r-project.org>
> >> Subject: Re: [R-sig-ME] Multi-level models Odds
> ratio
> >> Message-ID:
> >>? ???<p2p706f8d1f1004080413k3014fe10q444382c927c2f90e at mail.gmail.com>
> >> Content-Type: text/plain
> >>
> >> exp(coef(model)$group)
> >>
> >> exp(fixef(model))
> >>
> >> Thanks.... yes this worked successfully :o)
> >>
> >> Et
> >>
> >> On Thu, Apr 8, 2010 at 11:48 AM, Andy Fugard
> (Work)
> >> <andy.fugard at sbg.ac.at>wrote:
> >>
> >>> Here's another example, borrowed from the help
> for
> >> "lmer":
> >>>
> >>>> gm1 <- glmer(cbind(incidence, size -
> >> incidence) ~ period + (1 | herd),
> >>>? ? ? ? ? ?
> ???family
> >> = binomial, data = cbpp)
> >>>
> >>> As you say, coef works:
> >>>
> >>>> coef(gm1)
> >>> $herd
> >>>? ? (Intercept)
> >>
> period2???period3???period4
> >>> 1???-0.8085096 -0.9923347
> -1.128675
> >> -1.580374
> >>> 2???-1.6974292 -0.9923347
> -1.128675
> >> -1.580374
> >>> 3???-0.9922697 -0.9923347
> -1.128675
> >> -1.580374
> >>> 4???-1.3592525 -0.9923347
> -1.128675
> >> -1.580374
> >>> 5???-1.5885461 -0.9923347
> -1.128675
> >> -1.580374
> >>> 6???-1.7987950 -0.9923347
> -1.128675
> >> -1.580374
> >>> 7???-0.5091313 -0.9923347
> -1.128675
> >> -1.580374
> >>> 8???-0.7991613 -0.9923347
> -1.128675
> >> -1.580374
> >>> 9???-1.6361848 -0.9923347
> -1.128675
> >> -1.580374
> >>> 10? -1.9394614 -0.9923347 -1.128675
> -1.580374
> >>> 11? -1.4831632 -0.9923347 -1.128675
> -1.580374
> >>> 12? -1.4633469 -0.9923347 -1.128675
> -1.580374
> >>> 13? -2.0884474 -0.9923347 -1.128675
> -1.580374
> >>> 14? -0.4278151 -0.9923347 -1.128675
> -1.580374
> >>> 15? -1.9290041 -0.9923347 -1.128675
> -1.580374
> >>>
> >>> But note the "$herd" bit.? Since this
> model has a
> >> varying intercept by
> >>> herd, you get a column in the resulting data
> frame
> >> called "herd".
> >>>
> >>> So you could try, for this example:
> >>>
> >>>> exp(coef(gm1)$herd)
> >>>? ?
> (Intercept)???period2???period3???period4
> >>> 1? ? 0.4455216 0.3707102 0.3234614
> >> 0.2058981
> >>> 2? ? 0.1831538 0.3707102 0.3234614
> >> 0.2058981
> >>> 3? ? 0.3707343 0.3707102 0.3234614
> >> 0.2058981
> >>> 4? ? 0.2568527 0.3707102 0.3234614
> >> 0.2058981
> >>> 5? ? 0.2042223 0.3707102 0.3234614
> >> 0.2058981
> >>> 6? ? 0.1654982 0.3707102 0.3234614
> >> 0.2058981
> >>> 7? ? 0.6010174 0.3707102 0.3234614
> >> 0.2058981
> >>> 8? ? 0.4497060 0.3707102 0.3234614
> >> 0.2058981
> >>> 9? ? 0.1947215 0.3707102 0.3234614
> >> 0.2058981
> >>> 10???0.1437814 0.3707102
> 0.3234614
> >> 0.2058981
> >>> 11???0.2269188 0.3707102
> 0.3234614
> >> 0.2058981
> >>> 12???0.2314603 0.3707102
> 0.3234614
> >> 0.2058981
> >>> 13???0.1238793 0.3707102
> 0.3234614
> >> 0.2058981
> >>> 14???0.6519320 0.3707102
> 0.3234614
> >> 0.2058981
> >>> 15???0.1452928 0.3707102
> 0.3234614
> >> 0.2058981
> >>>
> >>> Since the slopes don't vary by herd, you might
> also
> >> want just the fixed
> >>> effects:
> >>>
> >>>> exp(fixef(gm1))
> >>> (Intercept)? ???period2
> >>? ? period3?
> ???period4
> >>>
> >>
> 0.2469585???0.3707102???0.3234614???0.2058981
> >>>
> >>> HTH,
> >>>
> >>> Andy
> >>>
> >>>
> >>> E T wrote:
> >>>> If I use the command coef(model) this
> extracts
> >> the coefficients in the
> >>>> model, however if I try exp(coef(model))
> I
> >> receive an error:
> >>>>
> >>>> Error in exp(coef(model)) : Non-numeric
> argument
> >> to mathematical function
> >>>>
> >>>> I could manually get the exp of each
> factor in my
> >> model..... but as I
> >>> have a
> >>>> large model (and also have numerous other
> models
> >> to produce), I was
> >>>> wondering if there was an automated
> method
> >>>>
> >>>> Regards
> >>>>
> >>>> Et
> >>>>
> >>>> On Thu, Apr 8, 2010 at 11:27 AM, E T
> <2nuzzbot at gmail.com>
> >> wrote:
> >>>>
> >>>>> odds.ratios = exp(coefs(model))
> >>>>>
> >>>>> Thanks, however unfortunately when I
> try the
> >> above command I receive the
> >>>>> following error:
> >>>>>
> >>>>> Error: could not find function
> "coefs"
> >>>>>
> >>>>> Regards
> >>>>>
> >>>>> Et
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>> On Wed, Apr 7, 2010 at 5:47 PM, Daniel
> Ezra
> >> Johnson <
> >>>>> danielezrajohnson at gmail.com>
> >> wrote:
> >>>>>
> >>>>>> something like odds.ratios =
> >> exp(coefs(model))
> >>>>>>
> >>>>>>
> >>>>>> On Apr 7, 2010, at 12:28 PM, E T
> <2nuzzbot at gmail.com>
> >> wrote:
> >>>>>>
> >>>>>>???Hi all,
> >>>>>>> Apologies for the simplicity
> of my
> >> question.... however any advice is
> >>>>>>> greatly appreciated. Thanks
> >>>>>>>
> >>>>>>> Is there a specific command
> available
> >> to obtain the odds ratios
> >>> produced
> >>>>>>> from a multilevel logistic
> model?
> >>>>>>>
> >>>>>>> I have estimated a
> multi-level
> >> logistic model using the lme4 package.
> >>> I
> >>>>>>> can
> >>>>>>> obtain results using the
> 'summary'
> >> command, however I would like to
> >>>>>>> obtain
> >>>>>>> the computed odds ratios.
> >>>>>>> (Similar to the output that
> can be
> >> produced for logistic GLM using the
> >>>>>>> logistic.display command from
> the
> >> epicalc package).
> >>>>>>>
> >>>>>>>? ? [[alternative
> HTML
> >> version deleted]]
> >>>>>>>
> >>>>>>>
> >> _______________________________________________
> >>>>>>> R-sig-mixed-models at r-project.org
> >> mailing list
> >>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>>>>
> >>>>
> >>>>? ? ? ? [[alternative
> HTML
> >> version deleted]]
> >>>>
> >>>>
> _______________________________________________
> >>>> R-sig-mixed-models at r-project.org
> >> mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>
> >>>
> >>> --
> >>> Andy Fugard, Postdoctoral researcher, ESF
> LogICCC
> >> project
> >>> "Modeling human inference within the framework
> of
> >> probability logic"
> >>> Department of Psychology, University of
> Salzburg,
> >> Austria
> >>> http://www.andyfugard.info
> >>>
> >>
> >>? ???[[alternative HTML version
> deleted]]
> >>
> >>
> >>
> >> ------------------------------
> >>
> >> _______________________________________________
> >> R-sig-mixed-models mailing list
> >> R-sig-mixed-models at r-project.org
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >>
> >> End of R-sig-mixed-models Digest, Vol 40, Issue
> 15
> >>
> **************************************************
> >>
> >
> >
> >
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org
> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
> 
> -- 
> The University of Edinburgh is a charitable body,
> registered in
> Scotland, with registration number SC005336.
> 
> 






From bolker at ufl.edu  Fri Apr  9 14:26:15 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Fri, 09 Apr 2010 08:26:15 -0400
Subject: [R-sig-ME] Another case of -1.0 correlation of random effects
In-Reply-To: <4BBF0986.70309@utoronto.ca>
References: <4BBF0986.70309@utoronto.ca>
Message-ID: <4BBF1CE7.7060206@ufl.edu>

Kevin E. Thorpe wrote:
> Hello.
> 
> I know this has come up a couple times recently, but I'm still not sure 
> what to do about it in my data.  Note that my sessionInfo() will be at 
> the bottom.
> 
> My data come from a crossover trial and are balanced.
> 
>  > str(gluc)
> 'data.frame':	96 obs. of  4 variables:
>   $ Subject  : int  1 2 3 5 6 7 10 11 12 13 ...
>   $ Treatment: Factor w/ 2 levels "Barley","Oat": 1 1 1 1 1 1 1 1 1 1 ...
>   $ Dose     : int  8 8 8 8 8 8 8 8 8 8 ...
>   $ iAUC     : num  110 256 129 207 244 ...
> 
>  > xtabs(~Treatment+Dose,data=gluc)
>           Dose
> Treatment  0  2  4  8
>     Barley 12 12 12 12
>     Oat    12 12 12 12
> 
> I plot the data (attached as gluc.pdf, if it comes through).
> 
>  From the plot, I think I want to fit the model as:
> 
> lmer(iAUC~Treatment+Dose+(Treatment|Subject)+(Dose|Subject),data=gluc)
> 
> It could possibly be argued that the (Treatment|Subject) part is not 
> needed.  When I fit this, I got -1.0 correlation within the Dose random 
> effects.  To simplify, I will fit a simpler model, since the issue persists.
> 
>  > lmer(iAUC~Dose+(Dose|Subject),data=gluc,subset=Treatment=="Oat")
> Linear mixed model fit by REML
> Formula: iAUC ~ Dose + (Dose | Subject)
>     Data: gluc
>   Subset: Treatment == "Oat"
>     AIC   BIC logLik deviance REMLdev
>   562.6 573.9 -275.3    563.1   550.6
> Random effects:
>   Groups   Name        Variance Std.Dev. Corr
>   Subject  (Intercept) 8274.324 90.9633
>            Dose          16.214  4.0266  -1.000
>   Residual             4862.319 69.7303
> Number of obs: 48, groups: Subject, 12
> 
> Fixed effects:
>              Estimate Std. Error t value
> (Intercept)  309.352     30.539  10.130
> Dose         -14.424      3.596  -4.012
> 
> Correlation of Fixed Effects:
>       (Intr)
> Dose -0.647
> 
> Now, a plot created by (and attached as lmlist.pdf):
> 
> plot(confint(lmList(iAUC~Dose|Subject,data=gluc,subset=Treatment=="Oat"),pooled=TRUE),order=1)
> 
> shows (I think) a strong negative correlation between the intercept and 
> slope random effects for Dose.
> 
> So, I would appreciate some advice on how I might specify these random 
> effects correctly.

  It's not entirely clear whether Subjects are unique within Treatments
(OK, maybe we should say "nested") or whether the same Subject can have
both Treatments  -- what would xtabs(~Subject+Dose+Treatment) look like?

  *If* each Subject appears in only one Treatment (i.e., 5 doses per
Subject, each Subject is either Oat or Barley, 12 Subjects per
Treatment), which is what I initially took for granted, then it makes
perfect sense to me that you can't specify Treatment|Subject, because
Treatment does not vary within Subject -- there doesn't seem to be any
way you can recover information about how the effect of Treatment varies
among Subject.

  Since your plots do look reasonably linear within Subject,

iAUC~Treatment*Dose+(Dose|Subject)

 seems best to me.
For what it's worth, this example closely parallels the Orthodont
example in the nlme package ...



-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From kevin.thorpe at utoronto.ca  Fri Apr  9 14:35:29 2010
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Fri, 09 Apr 2010 08:35:29 -0400
Subject: [R-sig-ME] Another case of -1.0 correlation of random effects
In-Reply-To: <4BBF1CE7.7060206@ufl.edu>
References: <4BBF0986.70309@utoronto.ca> <4BBF1CE7.7060206@ufl.edu>
Message-ID: <4BBF1F11.1090905@utoronto.ca>

Ben Bolker wrote:
> Kevin E. Thorpe wrote:
>> Hello.
>>
>> I know this has come up a couple times recently, but I'm still not sure 
>> what to do about it in my data.  Note that my sessionInfo() will be at 
>> the bottom.
>>
>> My data come from a crossover trial and are balanced.
>>
>>  > str(gluc)
>> 'data.frame':	96 obs. of  4 variables:
>>   $ Subject  : int  1 2 3 5 6 7 10 11 12 13 ...
>>   $ Treatment: Factor w/ 2 levels "Barley","Oat": 1 1 1 1 1 1 1 1 1 1 ...
>>   $ Dose     : int  8 8 8 8 8 8 8 8 8 8 ...
>>   $ iAUC     : num  110 256 129 207 244 ...
>>
>>  > xtabs(~Treatment+Dose,data=gluc)
>>           Dose
>> Treatment  0  2  4  8
>>     Barley 12 12 12 12
>>     Oat    12 12 12 12
>>
>> I plot the data (attached as gluc.pdf, if it comes through).
>>
>>  From the plot, I think I want to fit the model as:
>>
>> lmer(iAUC~Treatment+Dose+(Treatment|Subject)+(Dose|Subject),data=gluc)
>>
>> It could possibly be argued that the (Treatment|Subject) part is not 
>> needed.  When I fit this, I got -1.0 correlation within the Dose random 
>> effects.  To simplify, I will fit a simpler model, since the issue persists.
>>
>>  > lmer(iAUC~Dose+(Dose|Subject),data=gluc,subset=Treatment=="Oat")
>> Linear mixed model fit by REML
>> Formula: iAUC ~ Dose + (Dose | Subject)
>>     Data: gluc
>>   Subset: Treatment == "Oat"
>>     AIC   BIC logLik deviance REMLdev
>>   562.6 573.9 -275.3    563.1   550.6
>> Random effects:
>>   Groups   Name        Variance Std.Dev. Corr
>>   Subject  (Intercept) 8274.324 90.9633
>>            Dose          16.214  4.0266  -1.000
>>   Residual             4862.319 69.7303
>> Number of obs: 48, groups: Subject, 12
>>
>> Fixed effects:
>>              Estimate Std. Error t value
>> (Intercept)  309.352     30.539  10.130
>> Dose         -14.424      3.596  -4.012
>>
>> Correlation of Fixed Effects:
>>       (Intr)
>> Dose -0.647
>>
>> Now, a plot created by (and attached as lmlist.pdf):
>>
>> plot(confint(lmList(iAUC~Dose|Subject,data=gluc,subset=Treatment=="Oat"),pooled=TRUE),order=1)
>>
>> shows (I think) a strong negative correlation between the intercept and 
>> slope random effects for Dose.
>>
>> So, I would appreciate some advice on how I might specify these random 
>> effects correctly.
> 
>   It's not entirely clear whether Subjects are unique within Treatments
> (OK, maybe we should say "nested") or whether the same Subject can have
> both Treatments  -- what would xtabs(~Subject+Dose+Treatment) look like?
> 
>   *If* each Subject appears in only one Treatment (i.e., 5 doses per
> Subject, each Subject is either Oat or Barley, 12 Subjects per
> Treatment), which is what I initially took for granted, then it makes
> perfect sense to me that you can't specify Treatment|Subject, because
> Treatment does not vary within Subject -- there doesn't seem to be any
> way you can recover information about how the effect of Treatment varies
> among Subject.
> 
>   Since your plots do look reasonably linear within Subject,
> 
> iAUC~Treatment*Dose+(Dose|Subject)
> 
>  seems best to me.
> For what it's worth, this example closely parallels the Orthodont
> example in the nlme package ...

It is a true crossover.  There are 12 patients and each patient gets 
both treatments and all four doses.

I will look at the Orthodont example too.


-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016



From j.hadfield at ed.ac.uk  Fri Apr  9 14:38:35 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 9 Apr 2010 13:38:35 +0100
Subject: [R-sig-ME] MCMCglmm
In-Reply-To: <308306.27924.qm@web58903.mail.re1.yahoo.com>
References: <308306.27924.qm@web58903.mail.re1.yahoo.com>
Message-ID: <B6AB9D6D-F954-446D-A224-D859F163448B@ed.ac.uk>

Hi,

In order to update the covariance matrix it is much easier if every  
combination of phase and marker exist. MCMCglmm generates any missing  
combinations and treats the unknown responses as missing data. It is  
just a computational strategy and the warning message can be ignored  
(I may suppress it in future versions).

The error message is unrelated. I presume phase is a factor (?) with n  
levels.  At some iteration the nXn covariance matrix associated with  
us(0+phase):marker becomes singular (or close to). If n=2 the error  
message implies that a variance has hit zero, or a correlation has hit  
-1 and 1. If n>2 then this implies that one (or more) eigenvalues of  
the covariance matrix has hit zero.  Numerical problems arise when  
these conditions occur so MCMCglmm terminates.  In your analysis you  
have used the default flat priors, but if a proper prior is specified  
these conditions do not generally arise. You can choose from the  
standard inverse-Wishart prior or from the parameter expanded non- 
central F prior (see Gelman 2006 Bayesian Analysis 1 515-533, or the  
CourseNotes). The latter is particularly useful if the variances are  
close to zero because you can get dramatic improvements in mixing.

Cheers,

Jarrod

On 9 Apr 2010, at 13:03, Iasonas Lamprianou wrote:

> Dear Jarrod Hadfield
> I followed your advice but got this message:
>
> m5_06.mcmc<- MCMCglmm(score ~ 1, random=~us(0+phase):marker+candidate 
> +batch, data=mg2006_sub)
>
> Warning in MCMCglmm(score ~ 1, random = ~us(0 + phase):marker +  
> candidate +  :
>  some combinations in us(0 + phase):marker do not exist and 118  
> missing records have been generated
> Error in MCMCglmm(score ~ 1, random = ~us(0 + phase):marker +  
> candidate +  :
>  ill-conditioned G/R structure: use proper priors if you haven't or  
> rescale data if you have
>
>
>
> could you please help me?
>
> Dr. Iasonas Lamprianou
>
>
> Assistant Professor (Educational Research and Evaluation)
> Department of Education Sciences
> European University-Cyprus
> P.O. Box 22006
> 1516 Nicosia
> Cyprus
> Tel.: +357-22-713178
> Fax: +357-22-590539
>
>
> Honorary Research Fellow
> Department of Education
> The University of Manchester
> Oxford Road, Manchester M13 9PL, UK
> Tel. 0044  161 275 3485
> iasonas.lamprianou at manchester.ac.uk
>
>
> --- On Thu, 8/4/10, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>
>> From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
>> Subject: Re: [R-sig-ME] MCMCglmm
>> To: "Iasonas Lamprianou" <lamprianou at yahoo.com>
>> Cc: r-sig-mixed-models at r-project.org
>> Date: Thursday, 8 April, 2010, 15:10
>> Dear Jason,
>>
>> These should work:
>>
>> m4.mcmc <- MCMCglmm(score ~ 1,
>> random=~marker+marker:day+candidate
>> +batch, data=mg2006)
>> m5 .mcmc<- MCMCglmm(score ~ 1,
>> random=~us(1+day):marker+candidate
>> +batch, data=mg2006)
>>
>> You may need to code day as a factor for m4, and as numeric
>> for m5
>> depending on the model you actually want to fit.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>> On 8 Apr 2010, at 14:58, Iasonas Lamprianou wrote:
>>
>>> Dear all,
>>> I recently experimented with MCMCglmm and I loved
>> (really loved) the
>>> fact that it will give me confidence intervals for the
>> variance of
>>> the random effects. It seems that MCMC is a reasonable
>> method to do
>>> so, in contrast to REML which seems to have problems
>> on this front.
>>> However, MCMCglmm is painfully slower than lmer which
>> is more
>>> familiar to me. The good news is that the point
>> estimates of lmer
>>> are near the centre of the confidence intervals by
>> MCMCglmm.
>>>
>>> I reduced my sample size a bit and managed to fit
>> those two models
>>> with lmer (the second would not fit because it needed
>> 1.5GB or RAM).
>>> Both seem to have a reasonable fit (at least at first
>> look).
>>>
>>> m4 <- lmer(score ~
>> 1+(1|marker/day)+(1|candidate)+(1|batch), mg2006)
>>>
>>> m5 <- lmer(score ~
>> 1+(1+day|marker)+(1|candidate)+(1|batch), mg2006)
>>>
>>> I would like to run these two models above with
>> MCMCglmm. Does
>>> anyone know how to do it?
>>>
>>> Thank you for the help
>>>
>>> Jason
>>>
>>> Dr. Iasonas Lamprianou
>>>
>>>
>>> Assistant Professor (Educational Research and
>> Evaluation)
>>> Department of Education Sciences
>>> European University-Cyprus
>>> P.O. Box 22006
>>> 1516 Nicosia
>>> Cyprus
>>> Tel.: +357-22-713178
>>> Fax: +357-22-590539
>>>
>>>
>>> Honorary Research Fellow
>>> Department of Education
>>> The University of Manchester
>>> Oxford Road, Manchester M13 9PL, UK
>>> Tel. 0044  161 275 3485
>>> iasonas.lamprianou at manchester.ac.uk
>>>
>>>
>>> --- On Thu, 8/4/10, r-sig-mixed-models-request at r-project.org
>> <r-sig-mixed-models-request at r-project.org
>>
>>>> wrote:
>>>
>>>> From: r-sig-mixed-models-request at r-project.org
>> <r-sig-mixed-models-request at r-project.org
>>
>>>>>
>>>> Subject: R-sig-mixed-models Digest, Vol 40, Issue
>> 15
>>>> To: r-sig-mixed-models at r-project.org
>>>> Date: Thursday, 8 April, 2010, 12:13
>>>> Send R-sig-mixed-models mailing list
>>>> submissions to
>>>>      r-sig-mixed-models at r-project.org
>>>>
>>>> To subscribe or unsubscribe via the World Wide
>> Web, visit
>>>>      https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> or, via email, send a message with subject or body
>> 'help'
>>>> to
>>>>      r-sig-mixed-models-request at r-project.org
>>>>
>>>> You can reach the person managing the list at
>>>>      r-sig-mixed-models-owner at r-project.org
>>>>
>>>> When replying, please edit your Subject line so it
>> is more
>>>> specific
>>>> than "Re: Contents of R-sig-mixed-models
>> digest..."
>>>>
>>>>
>>>> Today's Topics:
>>>>
>>>>     1. Re: Multi-level models Odds ratio
>> (E
>>>> T)
>>>>     2. Re: Multi-level models Odds ratio
>>>> (ONKELINX, Thierry)
>>>>     3. Re: Multi-level models Odds ratio
>> (E
>>>> T)
>>>>     4. Re: Multi-level models Odds ratio
>>>> (Andy Fugard (Work))
>>>>     5. Re: Multi-level models Odds ratio
>> (E
>>>> T)
>>>>
>>>>
>>>>
>> ----------------------------------------------------------------------
>>>>
>>>> Message: 1
>>>> Date: Thu, 8 Apr 2010 11:27:49 +0100
>>>> From: E T <2nuzzbot at gmail.com>
>>>> To: Daniel Ezra Johnson <danielezrajohnson at gmail.com>
>>>> Cc: "r-sig-mixed-models at r-project.org"
>>>>      <r-sig-mixed-models at r-project.org>
>>>> Subject: Re: [R-sig-ME] Multi-level models Odds
>> ratio
>>>> Message-ID:
>>>>      <l2w706f8d1f1004080327re8708f46mc7d334f41ae19a10 at mail.gmail.com 
>>>> >
>>>> Content-Type: text/plain
>>>>
>>>> odds.ratios = exp(coefs(model))
>>>>
>>>> Thanks, however unfortunately when I try the above
>> command
>>>> I receive the
>>>> following error:
>>>>
>>>> Error: could not find function "coefs"
>>>>
>>>> Regards
>>>>
>>>> Et
>>>>
>>>>
>>>>
>>>> On Wed, Apr 7, 2010 at 5:47 PM, Daniel Ezra
>> Johnson <
>>>> danielezrajohnson at gmail.com>
>>>> wrote:
>>>>
>>>>> something like odds.ratios =
>> exp(coefs(model))
>>>>>
>>>>>
>>>>> On Apr 7, 2010, at 12:28 PM, E T <2nuzzbot at gmail.com>
>>>> wrote:
>>>>>
>>>>>    Hi all,
>>>>>>
>>>>>> Apologies for the simplicity of my
>> question....
>>>> however any advice is
>>>>>> greatly appreciated. Thanks
>>>>>>
>>>>>> Is there a specific command available to
>> obtain
>>>> the odds ratios produced
>>>>>> from a multilevel logistic model?
>>>>>>
>>>>>> I have estimated a multi-level logistic
>> model
>>>> using the lme4 package. I
>>>>>> can
>>>>>> obtain results using the 'summary'
>> command,
>>>> however I would like to obtain
>>>>>> the computed odds ratios.
>>>>>> (Similar to the output that can be
>> produced for
>>>> logistic GLM using the
>>>>>> logistic.display command from the epicalc
>>>> package).
>>>>>>
>>>>>>     [[alternative HTML version
>>>> deleted]]
>>>>>>
>>>>>>
>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org
>>>> mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>
>>>>>
>>>>
>>>>      [[alternative HTML version
>> deleted]]
>>>>
>>>>
>>>>
>>>> ------------------------------
>>>>
>>>> Message: 2
>>>> Date: Thu, 8 Apr 2010 12:32:01 +0200
>>>> From: "ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be>
>>>> To: "E T" <2nuzzbot at gmail.com>,
>>>> "Daniel Ezra Johnson"
>>>>      <danielezrajohnson at gmail.com>
>>>> Cc: r-sig-mixed-models at r-project.org
>>>> Subject: Re: [R-sig-ME] Multi-level models Odds
>> ratio
>>>> Message-ID:
>>>>      <2E9C414912813E4EB981326983E0A104071B69A6 at inboexch.inbo.be>
>>>> Content-Type: text/plain;
>>>> charset="us-ascii"
>>>>
>>>> It should be
>>>>
>>>> exp(coef(model))
>>>>
>>>> Without the "s"
>>>>
>>>> HTH,
>>>>
>>>> Thierry
>>>>
>> ------------------------------------------------------------------------
>>>> ----
>>>> ir. Thierry Onkelinx
>>>> Instituut voor natuur- en bosonderzoek
>>>> team Biometrie & Kwaliteitszorg
>>>> Gaverstraat 4
>>>> 9500 Geraardsbergen
>>>> Belgium
>>>>
>>>> Research Institute for Nature and Forest
>>>> team Biometrics & Quality Assurance
>>>> Gaverstraat 4
>>>> 9500 Geraardsbergen
>>>> Belgium
>>>>
>>>> tel. + 32 54/436 185
>>>> Thierry.Onkelinx at inbo.be
>>>> www.inbo.be
>>>>
>>>> To call in the statistician after the experiment
>> is done
>>>> may be no more
>>>> than asking him to perform a post-mortem
>> examination: he
>>>> may be able to
>>>> say what the experiment died of.
>>>> ~ Sir Ronald Aylmer Fisher
>>>>
>>>> The plural of anecdote is not data.
>>>> ~ Roger Brinner
>>>>
>>>> The combination of some data and an aching desire
>> for an
>>>> answer does not
>>>> ensure that a reasonable answer can be extracted
>> from a
>>>> given body of
>>>> data.
>>>> ~ John Tukey
>>>>
>>>>
>>>>> -----Oorspronkelijk bericht-----
>>>>> Van: r-sig-mixed-models-bounces at r-project.org
>>>>
>>>>> [mailto:r-sig-mixed-models-bounces at r-project.org]
>>>> Namens E T
>>>>> Verzonden: donderdag 8 april 2010 12:28
>>>>> Aan: Daniel Ezra Johnson
>>>>> CC: r-sig-mixed-models at r-project.org
>>>>> Onderwerp: Re: [R-sig-ME] Multi-level models
>> Odds
>>>> ratio
>>>>>
>>>>> odds.ratios = exp(coefs(model))
>>>>>
>>>>> Thanks, however unfortunately when I try the
>> above
>>>> command I
>>>>> receive the following error:
>>>>>
>>>>> Error: could not find function "coefs"
>>>>>
>>>>> Regards
>>>>>
>>>>> Et
>>>>>
>>>>>
>>>>>
>>>>> On Wed, Apr 7, 2010 at 5:47 PM, Daniel Ezra
>> Johnson
>>>> <
>>>>> danielezrajohnson at gmail.com>
>>>> wrote:
>>>>>
>>>>>> something like odds.ratios =
>> exp(coefs(model))
>>>>>>
>>>>>>
>>>>>> On Apr 7, 2010, at 12:28 PM, E T <2nuzzbot at gmail.com>
>>>> wrote:
>>>>>>
>>>>>>    Hi all,
>>>>>>>
>>>>>>> Apologies for the simplicity of my
>>>> question.... however
>>>>> any advice is
>>>>>>> greatly appreciated. Thanks
>>>>>>>
>>>>>>> Is there a specific command available
>> to
>>>> obtain the odds ratios
>>>>>>> produced from a multilevel logistic
>> model?
>>>>>>>
>>>>>>> I have estimated a multi-level
>> logistic model
>>>> using the
>>>>> lme4 package.
>>>>>>> I can obtain results using the
>> 'summary'
>>>> command, however I would
>>>>>>> like to obtain the computed odds
>> ratios.
>>>>>>> (Similar to the output that can be
>> produced
>>>> for logistic GLM using
>>>>>>> the logistic.display command from the
>> epicalc
>>>> package).
>>>>>>>
>>>>>>>     [[alternative HTML
>> version
>>>> deleted]]
>>>>>>>
>>>>>>>
>>>> _______________________________________________
>>>>>>> R-sig-mixed-models at r-project.org
>>>> mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>
>>>>>>
>>>>>
>>>>>      [[alternative HTML
>> version
>>>> deleted]]
>>>>>
>>>>>
>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org
>>>> mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>
>>>> Druk dit bericht a.u.b. niet onnodig af.
>>>> Please do not print this message unnecessarily.
>>>>
>>>> Dit bericht en eventuele bijlagen geven enkel de
>> visie van
>>>> de schrijver weer
>>>> en binden het INBO onder geen enkel beding, zolang
>> dit
>>>> bericht niet bevestigd is
>>>> door een geldig ondertekend document. The views
>> expressed
>>>> in  this message
>>>> and any annex are purely those of the writer and
>> may not be
>>>> regarded as stating
>>>> an official position of INBO, as long as the
>> message is not
>>>> confirmed by a duly
>>>> signed document.
>>>>
>>>>
>>>>
>>>> ------------------------------
>>>>
>>>> Message: 3
>>>> Date: Thu, 8 Apr 2010 11:35:03 +0100
>>>> From: E T <2nuzzbot at gmail.com>
>>>> To: Daniel Ezra Johnson <danielezrajohnson at gmail.com>
>>>> Cc: "r-sig-mixed-models at r-project.org"
>>>>      <r-sig-mixed-models at r-project.org>
>>>> Subject: Re: [R-sig-ME] Multi-level models Odds
>> ratio
>>>> Message-ID:
>>>>      <i2y706f8d1f1004080335q84f61b78u8c7b656b67a08a8e at mail.gmail.com 
>>>> >
>>>> Content-Type: text/plain
>>>>
>>>> If I use the command coef(model) this extracts
>> the
>>>> coefficients in the
>>>> model, however if I try exp(coef(model)) I receive
>> an
>>>> error:
>>>>
>>>> Error in exp(coef(model)) : Non-numeric argument
>> to
>>>> mathematical function
>>>>
>>>> I could manually get the exp of each factor in my
>>>> model..... but as I have a
>>>> large model (and also have numerous other models
>> to
>>>> produce), I was
>>>> wondering if there was an automated method
>>>>
>>>> Regards
>>>>
>>>> Et
>>>>
>>>> On Thu, Apr 8, 2010 at 11:27 AM, E T <2nuzzbot at gmail.com>
>>>> wrote:
>>>>
>>>>> odds.ratios = exp(coefs(model))
>>>>>
>>>>> Thanks, however unfortunately when I try the
>> above
>>>> command I receive the
>>>>> following error:
>>>>>
>>>>> Error: could not find function "coefs"
>>>>>
>>>>> Regards
>>>>>
>>>>> Et
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> On Wed, Apr 7, 2010 at 5:47 PM, Daniel Ezra
>> Johnson
>>>> <
>>>>> danielezrajohnson at gmail.com>
>>>> wrote:
>>>>>
>>>>>> something like odds.ratios =
>> exp(coefs(model))
>>>>>>
>>>>>>
>>>>>> On Apr 7, 2010, at 12:28 PM, E T <2nuzzbot at gmail.com>
>>>> wrote:
>>>>>>
>>>>>>    Hi all,
>>>>>>>
>>>>>>> Apologies for the simplicity of my
>>>> question.... however any advice is
>>>>>>> greatly appreciated. Thanks
>>>>>>>
>>>>>>> Is there a specific command available
>> to
>>>> obtain the odds ratios produced
>>>>>>> from a multilevel logistic model?
>>>>>>>
>>>>>>> I have estimated a multi-level
>> logistic model
>>>> using the lme4 package. I
>>>>>>> can
>>>>>>> obtain results using the 'summary'
>> command,
>>>> however I would like to
>>>>>>> obtain
>>>>>>> the computed odds ratios.
>>>>>>> (Similar to the output that can be
>> produced
>>>> for logistic GLM using the
>>>>>>> logistic.display command from the
>> epicalc
>>>> package).
>>>>>>>
>>>>>>>     [[alternative HTML
>> version
>>>> deleted]]
>>>>>>>
>>>>>>>
>>>> _______________________________________________
>>>>>>> R-sig-mixed-models at r-project.org
>>>> mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>
>>>>>>
>>>>>
>>>>
>>>>      [[alternative HTML version
>> deleted]]
>>>>
>>>>
>>>>
>>>> ------------------------------
>>>>
>>>> Message: 4
>>>> Date: Thu, 08 Apr 2010 12:48:30 +0200
>>>> From: "Andy Fugard (Work)" <andy.fugard at sbg.ac.at>
>>>> To: E T <2nuzzbot at gmail.com>
>>>> Cc: "r-sig-mixed-models at r-project.org"
>>>>      <r-sig-mixed-models at r-project.org>
>>>> Subject: Re: [R-sig-ME] Multi-level models Odds
>> ratio
>>>> Message-ID: <4BBDB47E.8030305 at sbg.ac.at>
>>>> Content-Type: text/plain; charset=ISO-8859-1
>>>>
>>>> Here's another example, borrowed from the help for
>> "lmer":
>>>>
>>>>> gm1 <- glmer(cbind(incidence, size -
>> incidence) ~
>>>> period + (1 | herd),
>>>>
>>    family =
>>>> binomial, data = cbpp)
>>>>
>>>> As you say, coef works:
>>>>
>>>>> coef(gm1)
>>>> $herd
>>>>     (Intercept)
>>>>
>> period2   period3   period4
>>>> 1   -0.8085096 -0.9923347
>> -1.128675
>>>> -1.580374
>>>> 2   -1.6974292 -0.9923347
>> -1.128675
>>>> -1.580374
>>>> 3   -0.9922697 -0.9923347
>> -1.128675
>>>> -1.580374
>>>> 4   -1.3592525 -0.9923347
>> -1.128675
>>>> -1.580374
>>>> 5   -1.5885461 -0.9923347
>> -1.128675
>>>> -1.580374
>>>> 6   -1.7987950 -0.9923347
>> -1.128675
>>>> -1.580374
>>>> 7   -0.5091313 -0.9923347
>> -1.128675
>>>> -1.580374
>>>> 8   -0.7991613 -0.9923347
>> -1.128675
>>>> -1.580374
>>>> 9   -1.6361848 -0.9923347
>> -1.128675
>>>> -1.580374
>>>> 10  -1.9394614 -0.9923347 -1.128675
>> -1.580374
>>>> 11  -1.4831632 -0.9923347 -1.128675
>> -1.580374
>>>> 12  -1.4633469 -0.9923347 -1.128675
>> -1.580374
>>>> 13  -2.0884474 -0.9923347 -1.128675
>> -1.580374
>>>> 14  -0.4278151 -0.9923347 -1.128675
>> -1.580374
>>>> 15  -1.9290041 -0.9923347 -1.128675
>> -1.580374
>>>>
>>>> But note the "$herd" bit.  Since this model
>> has a
>>>> varying intercept by
>>>> herd, you get a column in the resulting data frame
>> called
>>>> "herd".
>>>>
>>>> So you could try, for this example:
>>>>
>>>>> exp(coef(gm1)$herd)
>>>>
>> (Intercept)   period2   period3   period4
>>>> 1    0.4455216 0.3707102 0.3234614
>> 0.2058981
>>>> 2    0.1831538 0.3707102 0.3234614
>> 0.2058981
>>>> 3    0.3707343 0.3707102 0.3234614
>> 0.2058981
>>>> 4    0.2568527 0.3707102 0.3234614
>> 0.2058981
>>>> 5    0.2042223 0.3707102 0.3234614
>> 0.2058981
>>>> 6    0.1654982 0.3707102 0.3234614
>> 0.2058981
>>>> 7    0.6010174 0.3707102 0.3234614
>> 0.2058981
>>>> 8    0.4497060 0.3707102 0.3234614
>> 0.2058981
>>>> 9    0.1947215 0.3707102 0.3234614
>> 0.2058981
>>>> 10   0.1437814 0.3707102 0.3234614
>>>> 0.2058981
>>>> 11   0.2269188 0.3707102 0.3234614
>>>> 0.2058981
>>>> 12   0.2314603 0.3707102 0.3234614
>>>> 0.2058981
>>>> 13   0.1238793 0.3707102 0.3234614
>>>> 0.2058981
>>>> 14   0.6519320 0.3707102 0.3234614
>>>> 0.2058981
>>>> 15   0.1452928 0.3707102 0.3234614
>>>> 0.2058981
>>>>
>>>> Since the slopes don't vary by herd, you might
>> also want
>>>> just the fixed
>>>> effects:
>>>>
>>>>> exp(fixef(gm1))
>>>> (Intercept)     period2
>>>>     period3
>>    period4
>>>>
>>>>
>> 0.2469585   0.3707102   0.3234614   0.2058981
>>>>
>>>> HTH,
>>>>
>>>> Andy
>>>>
>>>>
>>>> E T wrote:
>>>>> If I use the command coef(model) this extracts
>> the
>>>> coefficients in the
>>>>> model, however if I try exp(coef(model)) I
>> receive an
>>>> error:
>>>>>
>>>>> Error in exp(coef(model)) : Non-numeric
>> argument to
>>>> mathematical function
>>>>>
>>>>> I could manually get the exp of each factor in
>> my
>>>> model..... but as I have a
>>>>> large model (and also have numerous other
>> models to
>>>> produce), I was
>>>>> wondering if there was an automated method
>>>>>
>>>>> Regards
>>>>>
>>>>> Et
>>>>>
>>>>> On Thu, Apr 8, 2010 at 11:27 AM, E T <2nuzzbot at gmail.com>
>>>> wrote:
>>>>>
>>>>>> odds.ratios = exp(coefs(model))
>>>>>>
>>>>>> Thanks, however unfortunately when I try
>> the above
>>>> command I receive the
>>>>>> following error:
>>>>>>
>>>>>> Error: could not find function "coefs"
>>>>>>
>>>>>> Regards
>>>>>>
>>>>>> Et
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> On Wed, Apr 7, 2010 at 5:47 PM, Daniel
>> Ezra
>>>> Johnson <
>>>>>> danielezrajohnson at gmail.com>
>>>> wrote:
>>>>>>
>>>>>>> something like odds.ratios =
>>>> exp(coefs(model))
>>>>>>>
>>>>>>>
>>>>>>> On Apr 7, 2010, at 12:28 PM, E T
>> <2nuzzbot at gmail.com>
>>>> wrote:
>>>>>>>
>>>>>>>    Hi all,
>>>>>>>> Apologies for the simplicity of
>> my
>>>> question.... however any advice is
>>>>>>>> greatly appreciated. Thanks
>>>>>>>>
>>>>>>>> Is there a specific command
>> available to
>>>> obtain the odds ratios produced
>>>>>>>> from a multilevel logistic model?
>>>>>>>>
>>>>>>>> I have estimated a multi-level
>> logistic
>>>> model using the lme4 package. I
>>>>>>>> can
>>>>>>>> obtain results using the
>> 'summary'
>>>> command, however I would like to
>>>>>>>> obtain
>>>>>>>> the computed odds ratios.
>>>>>>>> (Similar to the output that can
>> be
>>>> produced for logistic GLM using the
>>>>>>>> logistic.display command from the
>> epicalc
>>>> package).
>>>>>>>>
>>>>>>>>     [[alternative HTML
>>>> version deleted]]
>>>>>>>>
>>>>>>>>
>>>> _______________________________________________
>>>>>>>> R-sig-mixed-models at r-project.org
>>>> mailing list
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>>
>>>>>
>>>>>      [[alternative HTML
>> version
>>>> deleted]]
>>>>>
>>>>>
>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org
>>>> mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>>
>>>> -- 
>>>> Andy Fugard, Postdoctoral researcher, ESF LogICCC
>> project
>>>> "Modeling human inference within the framework of
>>>> probability logic"
>>>> Department of Psychology, University of Salzburg,
>> Austria
>>>> http://www.andyfugard.info
>>>>
>>>>
>>>>
>>>> ------------------------------
>>>>
>>>> Message: 5
>>>> Date: Thu, 8 Apr 2010 12:13:23 +0100
>>>> From: E T <2nuzzbot at gmail.com>
>>>> To: "Andy Fugard (Work)" <andy.fugard at sbg.ac.at>
>>>> Cc: "r-sig-mixed-models at r-project.org"
>>>>      <r-sig-mixed-models at r-project.org>
>>>> Subject: Re: [R-sig-ME] Multi-level models Odds
>> ratio
>>>> Message-ID:
>>>>      <p2p706f8d1f1004080413k3014fe10q444382c927c2f90e at mail.gmail.com 
>>>> >
>>>> Content-Type: text/plain
>>>>
>>>> exp(coef(model)$group)
>>>>
>>>> exp(fixef(model))
>>>>
>>>> Thanks.... yes this worked successfully :o)
>>>>
>>>> Et
>>>>
>>>> On Thu, Apr 8, 2010 at 11:48 AM, Andy Fugard
>> (Work)
>>>> <andy.fugard at sbg.ac.at>wrote:
>>>>
>>>>> Here's another example, borrowed from the help
>> for
>>>> "lmer":
>>>>>
>>>>>> gm1 <- glmer(cbind(incidence, size -
>>>> incidence) ~ period + (1 | herd),
>>>>>
>>    family
>>>> = binomial, data = cbpp)
>>>>>
>>>>> As you say, coef works:
>>>>>
>>>>>> coef(gm1)
>>>>> $herd
>>>>>     (Intercept)
>>>>
>> period2   period3   period4
>>>>> 1   -0.8085096 -0.9923347
>> -1.128675
>>>> -1.580374
>>>>> 2   -1.6974292 -0.9923347
>> -1.128675
>>>> -1.580374
>>>>> 3   -0.9922697 -0.9923347
>> -1.128675
>>>> -1.580374
>>>>> 4   -1.3592525 -0.9923347
>> -1.128675
>>>> -1.580374
>>>>> 5   -1.5885461 -0.9923347
>> -1.128675
>>>> -1.580374
>>>>> 6   -1.7987950 -0.9923347
>> -1.128675
>>>> -1.580374
>>>>> 7   -0.5091313 -0.9923347
>> -1.128675
>>>> -1.580374
>>>>> 8   -0.7991613 -0.9923347
>> -1.128675
>>>> -1.580374
>>>>> 9   -1.6361848 -0.9923347
>> -1.128675
>>>> -1.580374
>>>>> 10  -1.9394614 -0.9923347 -1.128675
>> -1.580374
>>>>> 11  -1.4831632 -0.9923347 -1.128675
>> -1.580374
>>>>> 12  -1.4633469 -0.9923347 -1.128675
>> -1.580374
>>>>> 13  -2.0884474 -0.9923347 -1.128675
>> -1.580374
>>>>> 14  -0.4278151 -0.9923347 -1.128675
>> -1.580374
>>>>> 15  -1.9290041 -0.9923347 -1.128675
>> -1.580374
>>>>>
>>>>> But note the "$herd" bit.  Since this
>> model has a
>>>> varying intercept by
>>>>> herd, you get a column in the resulting data
>> frame
>>>> called "herd".
>>>>>
>>>>> So you could try, for this example:
>>>>>
>>>>>> exp(coef(gm1)$herd)
>>>>>
>> (Intercept)   period2   period3   period4
>>>>> 1    0.4455216 0.3707102 0.3234614
>>>> 0.2058981
>>>>> 2    0.1831538 0.3707102 0.3234614
>>>> 0.2058981
>>>>> 3    0.3707343 0.3707102 0.3234614
>>>> 0.2058981
>>>>> 4    0.2568527 0.3707102 0.3234614
>>>> 0.2058981
>>>>> 5    0.2042223 0.3707102 0.3234614
>>>> 0.2058981
>>>>> 6    0.1654982 0.3707102 0.3234614
>>>> 0.2058981
>>>>> 7    0.6010174 0.3707102 0.3234614
>>>> 0.2058981
>>>>> 8    0.4497060 0.3707102 0.3234614
>>>> 0.2058981
>>>>> 9    0.1947215 0.3707102 0.3234614
>>>> 0.2058981
>>>>> 10   0.1437814 0.3707102
>> 0.3234614
>>>> 0.2058981
>>>>> 11   0.2269188 0.3707102
>> 0.3234614
>>>> 0.2058981
>>>>> 12   0.2314603 0.3707102
>> 0.3234614
>>>> 0.2058981
>>>>> 13   0.1238793 0.3707102
>> 0.3234614
>>>> 0.2058981
>>>>> 14   0.6519320 0.3707102
>> 0.3234614
>>>> 0.2058981
>>>>> 15   0.1452928 0.3707102
>> 0.3234614
>>>> 0.2058981
>>>>>
>>>>> Since the slopes don't vary by herd, you might
>> also
>>>> want just the fixed
>>>>> effects:
>>>>>
>>>>>> exp(fixef(gm1))
>>>>> (Intercept)     period2
>>>>     period3
>>    period4
>>>>>
>>>>
>> 0.2469585   0.3707102   0.3234614   0.2058981
>>>>>
>>>>> HTH,
>>>>>
>>>>> Andy
>>>>>
>>>>>
>>>>> E T wrote:
>>>>>> If I use the command coef(model) this
>> extracts
>>>> the coefficients in the
>>>>>> model, however if I try exp(coef(model))
>> I
>>>> receive an error:
>>>>>>
>>>>>> Error in exp(coef(model)) : Non-numeric
>> argument
>>>> to mathematical function
>>>>>>
>>>>>> I could manually get the exp of each
>> factor in my
>>>> model..... but as I
>>>>> have a
>>>>>> large model (and also have numerous other
>> models
>>>> to produce), I was
>>>>>> wondering if there was an automated
>> method
>>>>>>
>>>>>> Regards
>>>>>>
>>>>>> Et
>>>>>>
>>>>>> On Thu, Apr 8, 2010 at 11:27 AM, E T
>> <2nuzzbot at gmail.com>
>>>> wrote:
>>>>>>
>>>>>>> odds.ratios = exp(coefs(model))
>>>>>>>
>>>>>>> Thanks, however unfortunately when I
>> try the
>>>> above command I receive the
>>>>>>> following error:
>>>>>>>
>>>>>>> Error: could not find function
>> "coefs"
>>>>>>>
>>>>>>> Regards
>>>>>>>
>>>>>>> Et
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> On Wed, Apr 7, 2010 at 5:47 PM, Daniel
>> Ezra
>>>> Johnson <
>>>>>>> danielezrajohnson at gmail.com>
>>>> wrote:
>>>>>>>
>>>>>>>> something like odds.ratios =
>>>> exp(coefs(model))
>>>>>>>>
>>>>>>>>
>>>>>>>> On Apr 7, 2010, at 12:28 PM, E T
>> <2nuzzbot at gmail.com>
>>>> wrote:
>>>>>>>>
>>>>>>>>    Hi all,
>>>>>>>>> Apologies for the simplicity
>> of my
>>>> question.... however any advice is
>>>>>>>>> greatly appreciated. Thanks
>>>>>>>>>
>>>>>>>>> Is there a specific command
>> available
>>>> to obtain the odds ratios
>>>>> produced
>>>>>>>>> from a multilevel logistic
>> model?
>>>>>>>>>
>>>>>>>>> I have estimated a
>> multi-level
>>>> logistic model using the lme4 package.
>>>>> I
>>>>>>>>> can
>>>>>>>>> obtain results using the
>> 'summary'
>>>> command, however I would like to
>>>>>>>>> obtain
>>>>>>>>> the computed odds ratios.
>>>>>>>>> (Similar to the output that
>> can be
>>>> produced for logistic GLM using the
>>>>>>>>> logistic.display command from
>> the
>>>> epicalc package).
>>>>>>>>>
>>>>>>>>>     [[alternative
>> HTML
>>>> version deleted]]
>>>>>>>>>
>>>>>>>>>
>>>> _______________________________________________
>>>>>>>>> R-sig-mixed-models at r-project.org
>>>> mailing list
>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>>>
>>>>>>
>>>>>>         [[alternative
>> HTML
>>>> version deleted]]
>>>>>>
>>>>>>
>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org
>>>> mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>>
>>>>> --
>>>>> Andy Fugard, Postdoctoral researcher, ESF
>> LogICCC
>>>> project
>>>>> "Modeling human inference within the framework
>> of
>>>> probability logic"
>>>>> Department of Psychology, University of
>> Salzburg,
>>>> Austria
>>>>> http://www.andyfugard.info
>>>>>
>>>>
>>>>      [[alternative HTML version
>> deleted]]
>>>>
>>>>
>>>>
>>>> ------------------------------
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models mailing list
>>>> R-sig-mixed-models at r-project.org
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>>
>>>> End of R-sig-mixed-models Digest, Vol 40, Issue
>> 15
>>>>
>> **************************************************
>>>>
>>>
>>>
>>>
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org
>> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>> -- 
>> The University of Edinburgh is a charitable body,
>> registered in
>> Scotland, with registration number SC005336.
>>
>>
>
>
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From ken.knoblauch at inserm.fr  Fri Apr  9 14:40:13 2010
From: ken.knoblauch at inserm.fr (Ken Knoblauch)
Date: Fri, 9 Apr 2010 12:40:13 +0000 (UTC)
Subject: [R-sig-ME] Another case of -1.0 correlation of random effects
References: <4BBF0986.70309@utoronto.ca>
Message-ID: <loom.20100409T143920-273@post.gmane.org>

Kevin E. Thorpe <kevin.thorpe at ...> writes:

> My data come from a crossover trial and are balanced.
> 
>  > str(gluc)
> 'data.frame':	96 obs. of  4 variables:
>   $ Subject  : int  1 2 3 5 6 7 10 11 12 13 ...
>   $ Treatment: Factor w/ 2 levels "Barley","Oat": 1 1 1 1 1 1 1 1 1 1 ...
>   $ Dose     : int  8 8 8 8 8 8 8 8 8 8 ...
>   $ iAUC     : num  110 256 129 207 244 ...
> 

>clip>

Shouldn't you make Subject into a factor?

Ken

-- 
Ken Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html



From bolker at ufl.edu  Fri Apr  9 15:03:00 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Fri, 09 Apr 2010 09:03:00 -0400
Subject: [R-sig-ME] Another case of -1.0 correlation of random effects
In-Reply-To: <loom.20100409T143920-273@post.gmane.org>
References: <4BBF0986.70309@utoronto.ca>
	<loom.20100409T143920-273@post.gmane.org>
Message-ID: <4BBF2584.10609@ufl.edu>

Ken Knoblauch wrote:
> Kevin E. Thorpe <kevin.thorpe at ...> writes:
> 
>> My data come from a crossover trial and are balanced.
>>
>>  > str(gluc)
>> 'data.frame':	96 obs. of  4 variables:
>>   $ Subject  : int  1 2 3 5 6 7 10 11 12 13 ...
>>   $ Treatment: Factor w/ 2 levels "Barley","Oat": 1 1 1 1 1 1 1 1 1 1 ...
>>   $ Dose     : int  8 8 8 8 8 8 8 8 8 8 ...
>>   $ iAUC     : num  110 256 129 207 244 ...
>>
> 
>> clip>
> 
> Shouldn't you make Subject into a factor?
> 
> Ken
> 

  It would make the plot a little bit prettier but I don't think it
matters in this case because variable that appears as a grouping
variable (i.e. on the right of the | ) is automatically treated as a
factor?  I think?

  Since it is really a crossover trial, it would seem reasonable in
principle to have the (Treatment|Subject) random effect in there as
well. I'm not sure what to do about the -1 correlation: it seems the
choices (not necessarily in order) are (1) throw up your hands and say
there's not enough data to estimate independently; (2) try WinBUGS,
possibly with slightly informative priors; (3) try using lme4a to create
profiles of the parameters and see if you can figure out what's happening.



-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From kevin.thorpe at utoronto.ca  Fri Apr  9 15:10:04 2010
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Fri, 09 Apr 2010 09:10:04 -0400
Subject: [R-sig-ME] Another case of -1.0 correlation of random effects
In-Reply-To: <loom.20100409T143920-273@post.gmane.org>
References: <4BBF0986.70309@utoronto.ca>
	<loom.20100409T143920-273@post.gmane.org>
Message-ID: <4BBF272C.8020607@utoronto.ca>

Ken Knoblauch wrote:
> Kevin E. Thorpe <kevin.thorpe at ...> writes:
> 
>> My data come from a crossover trial and are balanced.
>>
>>  > str(gluc)
>> 'data.frame':	96 obs. of  4 variables:
>>   $ Subject  : int  1 2 3 5 6 7 10 11 12 13 ...
>>   $ Treatment: Factor w/ 2 levels "Barley","Oat": 1 1 1 1 1 1 1 1 1 1 ...
>>   $ Dose     : int  8 8 8 8 8 8 8 8 8 8 ...
>>   $ iAUC     : num  110 256 129 207 244 ...
>>
> 
>> clip>
> 
> Shouldn't you make Subject into a factor?
> 
> Ken
> 

I just tried that and it had no effect on the results.

-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016



From Wolfgang.Viechtbauer at STAT.unimaas.nl  Fri Apr  9 15:16:32 2010
From: Wolfgang.Viechtbauer at STAT.unimaas.nl (Viechtbauer Wolfgang (STAT))
Date: Fri, 9 Apr 2010 15:16:32 +0200
Subject: [R-sig-ME] Another case of -1.0 correlation of random effects
In-Reply-To: <4BBF0986.70309@utoronto.ca>
Message-ID: <077E31A57DA26E46AB0D493C9966AC7308663A8E2E@UM-MAIL4112.unimaas.nl>

Maybe I am totally off here, but wouldn't it help if you make what is currently Dose = 0 equal to Dose = -8 and then have what is currently Dose = 8 be equal to Dose = 0? This should help to decrease the correlation between the intercepts and the slopes.

Best,

--
Wolfgang Viechtbauer                        http://www.wvbauer.com/
Department of Methodology and Statistics    Tel: +31 (43) 388-2277
School for Public Health and Primary Care   Office Location:
Maastricht University, P.O. Box 616         Room B2.01 (second floor)
6200 MD Maastricht, The Netherlands         Debyeplein 1 (Randwyck)


----Original Message----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Kevin E.
Thorpe Sent: Friday, April 09, 2010 13:04 To:
r-sig-mixed-models at r-project.org Subject: [R-sig-ME] Another case of
-1.0 correlation of random effects

> Hello.
>
> I know this has come up a couple times recently, but I'm still not
> sure
> what to do about it in my data.  Note that my sessionInfo() will be at
> the bottom.
>
> My data come from a crossover trial and are balanced.
>
>  > str(gluc)
> 'data.frame': 96 obs. of  4 variables:
>   $ Subject  : int  1 2 3 5 6 7 10 11 12 13 ...
>   $ Treatment: Factor w/ 2 levels "Barley","Oat": 1 1 1 1 1 1 1 1 1 1
>   ... $ Dose     : int  8 8 8 8 8 8 8 8 8 8 ...
>   $ iAUC     : num  110 256 129 207 244 ...
>
>  > xtabs(~Treatment+Dose,data=gluc)
>           Dose
> Treatment  0  2  4  8
>     Barley 12 12 12 12
>     Oat    12 12 12 12
>
> I plot the data (attached as gluc.pdf, if it comes through).
>
>  From the plot, I think I want to fit the model as:
>
> lmer(iAUC~Treatment+Dose+(Treatment|Subject)+(Dose|Subject),data=gluc)
>
> It could possibly be argued that the (Treatment|Subject) part is not
> needed.  When I fit this, I got -1.0 correlation within the Dose
> random
> effects.  To simplify, I will fit a simpler model, since the issue
> persists.
>
>  > lmer(iAUC~Dose+(Dose|Subject),data=gluc,subset=Treatment=="Oat")
> Linear mixed model fit by REML
> Formula: iAUC ~ Dose + (Dose | Subject)
>     Data: gluc
>   Subset: Treatment == "Oat"
>     AIC   BIC logLik deviance REMLdev
>   562.6 573.9 -275.3    563.1   550.6
> Random effects:
>   Groups   Name        Variance Std.Dev. Corr
>   Subject  (Intercept) 8274.324 90.9633
>            Dose          16.214  4.0266  -1.000
>   Residual             4862.319 69.7303
> Number of obs: 48, groups: Subject, 12
>
> Fixed effects:
>              Estimate Std. Error t value
> (Intercept)  309.352     30.539  10.130
> Dose         -14.424      3.596  -4.012
>
> Correlation of Fixed Effects:
>       (Intr)
> Dose -0.647
>
> Now, a plot created by (and attached as lmlist.pdf):
>
> plot(confint(lmList(iAUC~Dose|Subject,data=gluc,subset=Treatment=="Oat"),pooled=TRUE),order=1)
>
> shows (I think) a strong negative correlation between the intercept
> and
> slope random effects for Dose.
>
> So, I would appreciate some advice on how I might specify these random
> effects correctly.
>
> One last thing I tried.  If I treat Dose as a factor (which might be
> reasonable) rather than numeric, I don't get any -1.0 correlations.
>
>  > lmer(iAUC~dose+(dose|Subject),data=gluc,subset=Treatment=="Oat")
> Linear mixed model fit by REML
> Formula: iAUC ~ dose + (dose | Subject)
>     Data: gluc
>   Subset: Treatment == "Oat"
>     AIC   BIC logLik deviance REMLdev
>   545.2 573.3 -257.6      547   515.2
> Random effects:
>   Groups   Name        Variance Std.Dev. Corr
>   Subject  (Intercept)  7509.9   86.660
>            dose2       11993.0  109.513  -0.321
>            dose4        6399.5   79.997   0.043  0.873
>            dose8        6051.7   77.793  -0.743  0.433  0.306
>   Residual              1206.4   34.733
> Number of obs: 48, groups: Subject, 12
>
> Fixed effects:
>              Estimate Std. Error t value
> (Intercept)  293.567     26.951  10.893
> dose2          6.692     34.648   0.193
> dose4        -39.975     27.099  -1.475
> dose8       -105.517     26.558  -3.973
>
> Correlation of Fixed Effects:
>        (Intr) dose2  dose4
> dose2 -0.380
> dose4 -0.103  0.786
> dose8 -0.724  0.443  0.360
>
> Thanks in advance and here is my sessionInfo().
>
>  > sessionInfo()
> R version 2.10.1 Patched (2009-12-29 r50852)
> i686-pc-linux-gnu
>
> locale:
>   [1] LC_CTYPE=en_US       LC_NUMERIC=C         LC_TIME=en_US
>   [4] LC_COLLATE=C         LC_MONETARY=C        LC_MESSAGES=en_US
>   [7] LC_PAPER=en_US       LC_NAME=C            LC_ADDRESS=C
> [10] LC_TELEPHONE=C       LC_MEASUREMENT=en_US LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] lme4_0.999375-32   Matrix_0.999375-33 lattice_0.17-26
>
> loaded via a namespace (and not attached):
> [1] grid_2.10.1
>
>
> --
> Kevin E. Thorpe
> Biostatistician/Trialist, Knowledge Translation Program Assistant
> Professor, Dalla Lana School of Public Health University of Toronto
> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016



From j.hadfield at ed.ac.uk  Fri Apr  9 15:21:16 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 9 Apr 2010 14:21:16 +0100
Subject: [R-sig-ME] Another case of -1.0 correlation of random effects
In-Reply-To: <4BBF2584.10609@ufl.edu>
References: <4BBF0986.70309@utoronto.ca>
	<loom.20100409T143920-273@post.gmane.org> <4BBF2584.10609@ufl.edu>
Message-ID: <61102BD6-CEBD-4238-8B7F-5BDB5829BD59@ed.ac.uk>

Hi,

As a solution to suggestion 2: an inverse-Wishart prior with null  
scale matrix and degree of belief parameter equal to 3 (for a 2X2  
case) is non-informative for the correlation.  As a quick stab you  
could try:

prior<-list(R=list(V=1, nu=0), G=list(G1=list(V=diag(2)*1e-6, nu=3)))

m1<-MCMCglmm(iAUC~Dose, random=~us(Dose):Subject, prior=prior,  
data=gluc)

plot(posterior.cor(m1$VCV[,1:4]))


NOTE: I do not advocate this prior as it does not imply non- 
informativeness for the (co)variances (amongst other things). It is  
just useful to know the uncertainty regarding the correlation.

Jarrod




On 9 Apr 2010, at 14:03, Ben Bolker wrote:

> Ken Knoblauch wrote:
>> Kevin E. Thorpe <kevin.thorpe at ...> writes:
>>
>>> My data come from a crossover trial and are balanced.
>>>
>>>> str(gluc)
>>> 'data.frame':	96 obs. of  4 variables:
>>>  $ Subject  : int  1 2 3 5 6 7 10 11 12 13 ...
>>>  $ Treatment: Factor w/ 2 levels "Barley","Oat": 1 1 1 1 1 1 1 1 1  
>>> 1 ...
>>>  $ Dose     : int  8 8 8 8 8 8 8 8 8 8 ...
>>>  $ iAUC     : num  110 256 129 207 244 ...
>>>
>>
>>> clip>
>>
>> Shouldn't you make Subject into a factor?
>>
>> Ken
>>
>
>  It would make the plot a little bit prettier but I don't think it
> matters in this case because variable that appears as a grouping
> variable (i.e. on the right of the | ) is automatically treated as a
> factor?  I think?
>
>  Since it is really a crossover trial, it would seem reasonable in
> principle to have the (Treatment|Subject) random effect in there as
> well. I'm not sure what to do about the -1 correlation: it seems the
> choices (not necessarily in order) are (1) throw up your hands and say
> there's not enough data to estimate independently; (2) try WinBUGS,
> possibly with slightly informative priors; (3) try using lme4a to  
> create
> profiles of the parameters and see if you can figure out what's  
> happening.
>
>
>
> -- 
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / people.biology.ufl.edu/bolker
> GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From shigesong at gmail.com  Fri Apr  9 15:28:35 2010
From: shigesong at gmail.com (Shige Song)
Date: Fri, 9 Apr 2010 09:28:35 -0400
Subject: [R-sig-ME] Bayesian counterpart to NPMLREG
Message-ID: <t2t5abc11d81004090628g74f9a3e1vc2d7fb81ffd3c29c@mail.gmail.com>

Dear All,

I am comparing two sets of results on involuntary fetal loss from
retrospective pregnancy history. Since each woman may have more than
one pregnancy, it makes sense to analyse it as a two-level logistic
regression with random intercept (at mother-level). One set of results
were obtained from random effect models that assume normal
distribution for the random component (estimated using Lme4 and
NPMLREG with random distribution set to "gh"), the second set of
results were obtained from random effect model that assume a set of
mass points for the random component (estimated using NPMLREG with
random distribution set to "np"). There are some interesting findings.
To be more specific, one interaction term I included (between birth
cohort and place residence) was estimated to be .373 (.202) in random
effect logistic regression assuming normal distribution but .433
(.202) in random effect assuming non-parametric random component. My
reading on this is that, the normal distribution assumption has
downwardly biased the point estimate of this interaction term and the
NPML estimate is more trustworthy.

I also want to do a similar comparison with Bayesian analysis. I have
been playing with MCMCglmm. The mean and the median of the posterior
distribution for that interaction term is .415 and .414, which is in
between of the the parametric and non-parametric ML estimates. Are we
still assuming some parametric distributions for the random component
here? If so, is there a way to further relax such assumption? Any
comments and suggestion are highly appreciated.

Best,
Shige



From lamprianou at yahoo.com  Fri Apr  9 15:33:18 2010
From: lamprianou at yahoo.com (Iasonas Lamprianou)
Date: Fri, 9 Apr 2010 06:33:18 -0700 (PDT)
Subject: [R-sig-ME] MCMCglmm
In-Reply-To: <B6AB9D6D-F954-446D-A224-D859F163448B@ed.ac.uk>
Message-ID: <867162.88778.qm@web58908.mail.re1.yahoo.com>

thank you

jason

Dr. Iasonas Lamprianou


Assistant Professor (Educational Research and Evaluation)
Department of Education Sciences
European University-Cyprus
P.O. Box 22006
1516 Nicosia
Cyprus 
Tel.: +357-22-713178
Fax: +357-22-590539


Honorary Research Fellow
Department of Education
The University of Manchester
Oxford Road, Manchester M13 9PL, UK
Tel. 0044  161 275 3485
iasonas.lamprianou at manchester.ac.uk


--- On Fri, 9/4/10, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:

> From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
> Subject: Re: [R-sig-ME] MCMCglmm
> To: "Iasonas Lamprianou" <lamprianou at yahoo.com>
> Cc: r-sig-mixed-models at r-project.org
> Date: Friday, 9 April, 2010, 13:38
> Hi,
> 
> In order to update the covariance matrix it is much easier
> if every? 
> combination of phase and marker exist. MCMCglmm generates
> any missing? 
> combinations and treats the unknown responses as missing
> data. It is? 
> just a computational strategy and the warning message can
> be ignored? 
> (I may suppress it in future versions).
> 
> The error message is unrelated. I presume phase is a factor
> (?) with n? 
> levels.? At some iteration the nXn covariance matrix
> associated with? 
> us(0+phase):marker becomes singular (or close to). If n=2
> the error? 
> message implies that a variance has hit zero, or a
> correlation has hit? 
> -1 and 1. If n>2 then this implies that one (or more)
> eigenvalues of? 
> the covariance matrix has hit zero.? Numerical
> problems arise when? 
> these conditions occur so MCMCglmm terminates.? In
> your analysis you? 
> have used the default flat priors, but if a proper prior is
> specified? 
> these conditions do not generally arise. You can choose
> from the? 
> standard inverse-Wishart prior or from the parameter
> expanded non- 
> central F prior (see Gelman 2006 Bayesian Analysis 1
> 515-533, or the? 
> CourseNotes). The latter is particularly useful if the
> variances are? 
> close to zero because you can get dramatic improvements in
> mixing.
> 
> Cheers,
> 
> Jarrod
> 
> On 9 Apr 2010, at 13:03, Iasonas Lamprianou wrote:
> 
> > Dear Jarrod Hadfield
> > I followed your advice but got this message:
> >
> > m5_06.mcmc<- MCMCglmm(score ~ 1,
> random=~us(0+phase):marker+candidate 
> > +batch, data=mg2006_sub)
> >
> > Warning in MCMCglmm(score ~ 1, random = ~us(0 +
> phase):marker +? 
> > candidate +? :
> >? some combinations in us(0 + phase):marker do not
> exist and 118? 
> > missing records have been generated
> > Error in MCMCglmm(score ~ 1, random = ~us(0 +
> phase):marker +? 
> > candidate +? :
> >? ill-conditioned G/R structure: use proper priors
> if you haven't or? 
> > rescale data if you have
> >
> >
> >
> > could you please help me?
> >
> > Dr. Iasonas Lamprianou
> >
> >
> > Assistant Professor (Educational Research and
> Evaluation)
> > Department of Education Sciences
> > European University-Cyprus
> > P.O. Box 22006
> > 1516 Nicosia
> > Cyprus
> > Tel.: +357-22-713178
> > Fax: +357-22-590539
> >
> >
> > Honorary Research Fellow
> > Department of Education
> > The University of Manchester
> > Oxford Road, Manchester M13 9PL, UK
> > Tel. 0044? 161 275 3485
> > iasonas.lamprianou at manchester.ac.uk
> >
> >
> > --- On Thu, 8/4/10, Jarrod Hadfield <j.hadfield at ed.ac.uk>
> wrote:
> >
> >> From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
> >> Subject: Re: [R-sig-ME] MCMCglmm
> >> To: "Iasonas Lamprianou" <lamprianou at yahoo.com>
> >> Cc: r-sig-mixed-models at r-project.org
> >> Date: Thursday, 8 April, 2010, 15:10
> >> Dear Jason,
> >>
> >> These should work:
> >>
> >> m4.mcmc <- MCMCglmm(score ~ 1,
> >> random=~marker+marker:day+candidate
> >> +batch, data=mg2006)
> >> m5 .mcmc<- MCMCglmm(score ~ 1,
> >> random=~us(1+day):marker+candidate
> >> +batch, data=mg2006)
> >>
> >> You may need to code day as a factor for m4, and
> as numeric
> >> for m5
> >> depending on the model you actually want to fit.
> >>
> >> Cheers,
> >>
> >> Jarrod
> >>
> >>
> >> On 8 Apr 2010, at 14:58, Iasonas Lamprianou
> wrote:
> >>
> >>> Dear all,
> >>> I recently experimented with MCMCglmm and I
> loved
> >> (really loved) the
> >>> fact that it will give me confidence intervals
> for the
> >> variance of
> >>> the random effects. It seems that MCMC is a
> reasonable
> >> method to do
> >>> so, in contrast to REML which seems to have
> problems
> >> on this front.
> >>> However, MCMCglmm is painfully slower than
> lmer which
> >> is more
> >>> familiar to me. The good news is that the
> point
> >> estimates of lmer
> >>> are near the centre of the confidence
> intervals by
> >> MCMCglmm.
> >>>
> >>> I reduced my sample size a bit and managed to
> fit
> >> those two models
> >>> with lmer (the second would not fit because it
> needed
> >> 1.5GB or RAM).
> >>> Both seem to have a reasonable fit (at least
> at first
> >> look).
> >>>
> >>> m4 <- lmer(score ~
> >> 1+(1|marker/day)+(1|candidate)+(1|batch), mg2006)
> >>>
> >>> m5 <- lmer(score ~
> >> 1+(1+day|marker)+(1|candidate)+(1|batch), mg2006)
> >>>
> >>> I would like to run these two models above
> with
> >> MCMCglmm. Does
> >>> anyone know how to do it?
> >>>
> >>> Thank you for the help
> >>>
> >>> Jason
> >>>
> >>> Dr. Iasonas Lamprianou
> >>>
> >>>
> >>> Assistant Professor (Educational Research and
> >> Evaluation)
> >>> Department of Education Sciences
> >>> European University-Cyprus
> >>> P.O. Box 22006
> >>> 1516 Nicosia
> >>> Cyprus
> >>> Tel.: +357-22-713178
> >>> Fax: +357-22-590539
> >>>
> >>>
> >>> Honorary Research Fellow
> >>> Department of Education
> >>> The University of Manchester
> >>> Oxford Road, Manchester M13 9PL, UK
> >>> Tel. 0044? 161 275 3485
> >>> iasonas.lamprianou at manchester.ac.uk
> >>>
> >>>
> >>> --- On Thu, 8/4/10, r-sig-mixed-models-request at r-project.org
> >> <r-sig-mixed-models-request at r-project.org
> >>
> >>>> wrote:
> >>>
> >>>> From: r-sig-mixed-models-request at r-project.org
> >> <r-sig-mixed-models-request at r-project.org
> >>
> >>>>>
> >>>> Subject: R-sig-mixed-models Digest, Vol
> 40, Issue
> >> 15
> >>>> To: r-sig-mixed-models at r-project.org
> >>>> Date: Thursday, 8 April, 2010, 12:13
> >>>> Send R-sig-mixed-models mailing list
> >>>> submissions to
> >>>>? ? ? r-sig-mixed-models at r-project.org
> >>>>
> >>>> To subscribe or unsubscribe via the World
> Wide
> >> Web, visit
> >>>>? ? ? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>> or, via email, send a message with subject
> or body
> >> 'help'
> >>>> to
> >>>>? ? ? r-sig-mixed-models-request at r-project.org
> >>>>
> >>>> You can reach the person managing the list
> at
> >>>>? ? ? r-sig-mixed-models-owner at r-project.org
> >>>>
> >>>> When replying, please edit your Subject
> line so it
> >> is more
> >>>> specific
> >>>> than "Re: Contents of R-sig-mixed-models
> >> digest..."
> >>>>
> >>>>
> >>>> Today's Topics:
> >>>>
> >>>>? ???1. Re: Multi-level
> models Odds ratio
> >> (E
> >>>> T)
> >>>>? ???2. Re: Multi-level
> models Odds ratio
> >>>> (ONKELINX, Thierry)
> >>>>? ???3. Re: Multi-level
> models Odds ratio
> >> (E
> >>>> T)
> >>>>? ???4. Re: Multi-level
> models Odds ratio
> >>>> (Andy Fugard (Work))
> >>>>? ???5. Re: Multi-level
> models Odds ratio
> >> (E
> >>>> T)
> >>>>
> >>>>
> >>>>
> >>
> ----------------------------------------------------------------------
> >>>>
> >>>> Message: 1
> >>>> Date: Thu, 8 Apr 2010 11:27:49 +0100
> >>>> From: E T <2nuzzbot at gmail.com>
> >>>> To: Daniel Ezra Johnson <danielezrajohnson at gmail.com>
> >>>> Cc: "r-sig-mixed-models at r-project.org"
> >>>>? ? ? <r-sig-mixed-models at r-project.org>
> >>>> Subject: Re: [R-sig-ME] Multi-level models
> Odds
> >> ratio
> >>>> Message-ID:
> >>>>? ? ? <l2w706f8d1f1004080327re8708f46mc7d334f41ae19a10 at mail.gmail.com
> 
> >>>> >
> >>>> Content-Type: text/plain
> >>>>
> >>>> odds.ratios = exp(coefs(model))
> >>>>
> >>>> Thanks, however unfortunately when I try
> the above
> >> command
> >>>> I receive the
> >>>> following error:
> >>>>
> >>>> Error: could not find function "coefs"
> >>>>
> >>>> Regards
> >>>>
> >>>> Et
> >>>>
> >>>>
> >>>>
> >>>> On Wed, Apr 7, 2010 at 5:47 PM, Daniel
> Ezra
> >> Johnson <
> >>>> danielezrajohnson at gmail.com>
> >>>> wrote:
> >>>>
> >>>>> something like odds.ratios =
> >> exp(coefs(model))
> >>>>>
> >>>>>

> >>>>> On Apr 7, 2010, at 12:28 PM, E T
> <2nuzzbot at gmail.com>
> >>>> wrote:
> >>>>>
> >>>>>? ? Hi all,
> >>>>>>
> >>>>>> Apologies for the simplicity of
> my
> >> question....
> >>>> however any advice is
> >>>>>> greatly appreciated. Thanks
> >>>>>>
> >>>>>> Is there a specific command
> available to
> >> obtain
> >>>> the odds ratios produced
> >>>>>> from a multilevel logistic model?
> >>>>>>
> >>>>>> I have estimated a multi-level
> logistic
> >> model
> >>>> using the lme4 package. I
> >>>>>> can
> >>>>>> obtain results using the
> 'summary'
> >> command,
> >>>> however I would like to obtain
> >>>>>> the computed odds ratios.
> >>>>>> (Similar to the output that can
> be
> >> produced for
> >>>> logistic GLM using the
> >>>>>> logistic.display command from the
> epicalc
> >>>> package).
> >>>>>>
> >>>>>>?
> ???[[alternative HTML version
> >>>> deleted]]
> >>>>>>
> >>>>>>
> >> _______________________________________________
> >>>>>> R-sig-mixed-models at r-project.org
> >>>> mailing list
> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>>>
> >>>>>
> >>>>
> >>>>? ? ? [[alternative HTML
> version
> >> deleted]]
> >>>>
> >>>>
> >>>>
> >>>> ------------------------------
> >>>>
> >>>> Message: 2
> >>>> Date: Thu, 8 Apr 2010 12:32:01 +0200
> >>>> From: "ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be>
> >>>> To: "E T" <2nuzzbot at gmail.com>,
> >>>> "Daniel Ezra Johnson"
> >>>>? ? ? <danielezrajohnson at gmail.com>
> >>>> Cc: r-sig-mixed-models at r-project.org
> >>>> Subject: Re: [R-sig-ME] Multi-level models
> Odds
> >> ratio
> >>>> Message-ID:
> >>>>? ? ? <2E9C414912813E4EB981326983E0A104071B69A6 at inboexch.inbo.be>
> >>>> Content-Type: text/plain;
> >>>> charset="us-ascii"
> >>>>
> >>>> It should be
> >>>>
> >>>> exp(coef(model))
> >>>>
> >>>> Without the "s"
> >>>>
> >>>> HTH,
> >>>>
> >>>> Thierry
> >>>>
> >>
> ------------------------------------------------------------------------
> >>>> ----
> >>>> ir. Thierry Onkelinx
> >>>> Instituut voor natuur- en bosonderzoek
> >>>> team Biometrie & Kwaliteitszorg
> >>>> Gaverstraat 4
> >>>> 9500 Geraardsbergen
> >>>> Belgium
> >>>>
> >>>> Research Institute for Nature and Forest
> >>>> team Biometrics & Quality Assurance
> >>>> Gaverstraat 4
> >>>> 9500 Geraardsbergen
> >>>> Belgium
> >>>>
> >>>> tel. + 32 54/436 185
> >>>> Thierry.Onkelinx at inbo.be
> >>>> www.inbo.be
> >>>>
> >>>> To call in the statistician after the
> experiment
> >> is done
> >>>> may be no more
> >>>> than asking him to perform a post-mortem
> >> examination: he
> >>>> may be able to
> >>>> say what the experiment died of.
> >>>> ~ Sir Ronald Aylmer Fisher
> >>>>
> >>>> The plural of anecdote is not data.
> >>>> ~ Roger Brinner
> >>>>
> >>>> The combination of some data and an aching
> desire
> >> for an
> >>>> answer does not
> >>>> ensure that a reasonable answer can be
> extracted
> >> from a
> >>>> given body of
> >>>> data.
> >>>> ~ John Tukey
> >>>>
> >>>>
> >>>>> -----Oorspronkelijk bericht-----
> >>>>> Van: r-sig-mixed-models-bounces at r-project.org
> >>>>
> >>>>> [mailto:r-sig-mixed-models-bounces at r-project.org]
> >>>> Namens E T
> >>>>> Verzonden: donderdag 8 april 2010
> 12:28
> >>>>> Aan: Daniel Ezra Johnson
> >>>>> CC: r-sig-mixed-models at r-project.org
> >>>>> Onderwerp: Re: [R-sig-ME] Multi-level
> models
> >> Odds
> >>>> ratio
> >>>>>
> >>>>> odds.ratios = exp(coefs(model))
> >>>>>
> >>>>> Thanks, however unfortunately when I
> try the
> >> above
> >>>> command I
> >>>>> receive the following error:
> >>>>>
> >>>>> Error: could not find function
> "coefs"
> >>>>>
> >>>>> Regards
> >>>>>
> >>>>> Et
> >>>>>
> >>>>>
> >>>>>
> >>>>> On Wed, Apr 7, 2010 at 5:47 PM, Daniel
> Ezra
> >> Johnson
> >>>> <
> >>>>> danielezrajohnson at gmail.com>
> >>>> wrote:
> >>>>>
> >>>>>> something like odds.ratios =
> >> exp(coefs(model))
> >>>>>>
> >>>>>>
> >>>>>> On Apr 7, 2010, at 12:28 PM, E T
> <2nuzzbot at gmail.com>
> >>>> wrote:
> >>>>>>
> >>>>>>? ? Hi all,
> >>>>>>>
> >>>>>>> Apologies for the simplicity
> of my
> >>>> question.... however
> >>>>> any advice is
> >>>>>>> greatly appreciated. Thanks
> >>>>>>>
> >>>>>>> Is there a specific command
> available
> >> to
> >>>> obtain the odds ratios
> >>>>>>> produced from a multilevel
> logistic
> >> model?
> >>>>>>>
> >>>>>>> I have estimated a
> multi-level
> >> logistic model
> >>>> using the
> >>>>> lme4 package.
> >>>>>>> I can obtain results using
> the
> >> 'summary'
> >>>> command, however I would
> >>>>>>> like to obtain the computed
> odds
> >> ratios.
> >>>>>>> (Similar to the output that
> can be
> >> produced
> >>>> for logistic GLM using
> >>>>>>> the logistic.display command
> from the
> >> epicalc
> >>>> package).
> >>>>>>>
> >>>>>>>?
> ???[[alternative HTML
> >> version
> >>>> deleted]]
> >>>>>>>
> >>>>>>>
> >>>>
> _______________________________________________
> >>>>>>> R-sig-mixed-models at r-project.org
> >>>> mailing list
> >>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>>>>
> >>>>>>
> >>>>>
> >>>>>? ? ? [[alternative
> HTML
> >> version
> >>>> deleted]]
> >>>>>
> >>>>>
> >> _______________________________________________
> >>>>> R-sig-mixed-models at r-project.org
> >>>> mailing list
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>>
> >>>>
> >>>> Druk dit bericht a.u.b. niet onnodig af.
> >>>> Please do not print this message
> unnecessarily.
> >>>>
> >>>> Dit bericht en eventuele bijlagen geven
> enkel de
> >> visie van
> >>>> de schrijver weer
> >>>> en binden het INBO onder geen enkel
> beding, zolang
> >> dit
> >>>> bericht niet bevestigd is
> >>>> door een geldig ondertekend document. The
> views
> >> expressed
> >>>> in? this message
> >>>> and any annex are purely those of the
> writer and
> >> may not be
> >>>> regarded as stating
> >>>> an official position of INBO, as long as
> the
> >> message is not
> >>>> confirmed by a duly
> >>>> signed document.
> >>>>
> >>>>
> >>>>
> >>>> ------------------------------
> >>>>
> >>>> Message: 3
> >>>> Date: Thu, 8 Apr 2010 11:35:03 +0100
> >>>> From: E T <2nuzzbot at gmail.com>
> >>>> To: Daniel Ezra Johnson <danielezrajohnson at gmail.com>
> >>>> Cc: "r-sig-mixed-models at r-project.org"
> >>>>? ? ? <r-sig-mixed-models at r-project.org>
> >>>> Subject: Re: [R-sig-ME] Multi-level models
> Odds
> >> ratio
> >>>> Message-ID:
> >>>>? ? ? <i2y706f8d1f1004080335q84f61b78u8c7b656b67a08a8e at mail.gmail.com
> 
> >>>> >
> >>>> Content-Type: text/plain
> >>>>
> >>>> If I use the command coef(model) this
> extracts
> >> the
> >>>> coefficients in the
> >>>> model, however if I try exp(coef(model)) I
> receive
> >> an
> >>>> error:
> >>>>
> >>>> Error in exp(coef(model)) : Non-numeric
> argument
> >> to
> >>>> mathematical function
> >>>>
> >>>> I could manually get the exp of each
> factor in my
> >>>> model..... but as I have a
> >>>> large model (and also have numerous other
> models
> >> to
> >>>> produce), I was
> >>>> wondering if there was an automated
> method
> >>>>
> >>>> Regards
> >>>>
> >>>> Et
> >>>>
> >>>> On Thu, Apr 8, 2010 at 11:27 AM, E T
> <2nuzzbot at gmail.com>
> >>>> wrote:
> >>>>
> >>>>> odds.ratios = exp(coefs(model))
> >>>>>
> >>>>> Thanks, however unfortunately when I
> try the
> >> above
> >>>> command I receive the
> >>>>> following error:
> >>>>>
> >>>>> Error: could not find function
> "coefs"
> >>>>>
> >>>>> Regards
> >>>>>
> >>>>> Et
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>> On Wed, Apr 7, 2010 at 5:47 PM, Daniel
> Ezra
> >> Johnson
> >>>> <
> >>>>> danielezrajohnson at gmail.com>
> >>>> wrote:
> >>>>>
> >>>>>> something like odds.ratios =
> >> exp(coefs(model))
> >>>>>>
> >>>>>>
> >>>>>> On Apr 7, 2010, at 12:28 PM, E T
> <2nuzzbot at gmail.com>
> >>>> wrote:
> >>>>>>
> >>>>>>? ? Hi all,
> >>>>>>>
> >>>>>>> Apologies for the simplicity
> of my
> >>>> question.... however any advice is
> >>>>>>> greatly appreciated. Thanks
> >>>>>>>
> >>>>>>> Is there a specific command
> available
> >> to
> >>>> obtain the odds ratios produced
> >>>>>>> from a multilevel logistic
> model?
> >>>>>>>
> >>>>>>> I have estimated a
> multi-level
> >> logistic model
> >>>> using the lme4 package. I
> >>>>>>> can
> >>>>>>> obtain results using the
> 'summary'
> >> command,
> >>>> however I would like to
> >>>>>>> obtain
> >>>>>>> the computed odds ratios.
> >>>>>>> (Similar to the output that
> can be
> >> produced
> >>>> for logistic GLM using the
> >>>>>>> logistic.display command from
> the
> >> epicalc
> >>>> package).
> >>>>>>>
> >>>>>>>?
> ???[[alternative HTML
> >> version
> >>>> deleted]]
> >>>>>>>
> >>>>>>>
> >>>>
> _______________________________________________
> >>>>>>> R-sig-mixed-models at r-project.org
> >>>> mailing list
> >>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>>>>
> >>>>>>
> >>>>>
> >>>>
> >>>>? ? ? [[alternative HTML
> version
> >> deleted]]
> >>>>
> >>>>
> >>>>
> >>>> ------------------------------
> >>>>
> >>>> Message: 4
> >>>> Date: Thu, 08 Apr 2010 12:48:30 +0200
> >>>> From: "Andy Fugard (Work)" <andy.fugard at sbg.ac.at>
> >>>> To: E T <2nuzzbot at gmail.com>
> >>>> Cc: "r-sig-mixed-models at r-project.org"
> >>>>? ? ? <r-sig-mixed-models at r-project.org>
> >>>> Subject: Re: [R-sig-ME] Multi-level models
> Odds
> >> ratio
> >>>> Message-ID: <4BBDB47E.8030305 at sbg.ac.at>
> >>>> Content-Type: text/plain;
> charset=ISO-8859-1
> >>>>
> >>>> Here's another example, borrowed from the
> help for
> >> "lmer":
> >>>>
> >>>>> gm1 <- glmer(cbind(incidence, size
> -
> >> incidence) ~
> >>>> period + (1 | herd),
> >>>>
> >>? ? family =
> >>>> binomial, data = cbpp)
> >>>>
> >>>> As you say, coef works:
> >>>>
> >>>>> coef(gm1)
> >>>> $herd
> >>>>? ???(Intercept)
> >>>>
> >>
> period2???period3???period4
> >>>> 1???-0.8085096 -0.9923347
> >> -1.128675
> >>>> -1.580374
> >>>> 2???-1.6974292 -0.9923347
> >> -1.128675
> >>>> -1.580374
> >>>> 3???-0.9922697 -0.9923347
> >> -1.128675
> >>>> -1.580374
> >>>> 4???-1.3592525 -0.9923347
> >> -1.128675
> >>>> -1.580374
> >>>> 5???-1.5885461 -0.9923347
> >> -1.128675
> >>>> -1.580374
> >>>> 6???-1.7987950 -0.9923347
> >> -1.128675
> >>>> -1.580374
> >>>> 7???-0.5091313 -0.9923347
> >> -1.128675
> >>>> -1.580374
> >>>> 8???-0.7991613 -0.9923347
> >> -1.128675
> >>>> -1.580374
> >>>> 9???-1.6361848 -0.9923347
> >> -1.128675
> >>>> -1.580374
> >>>> 10? -1.9394614 -0.9923347 -1.128675
> >> -1.580374
> >>>> 11? -1.4831632 -0.9923347 -1.128675
> >> -1.580374
> >>>> 12? -1.4633469 -0.9923347 -1.128675
> >> -1.580374
> >>>> 13? -2.0884474 -0.9923347 -1.128675
> >> -1.580374
> >>>> 14? -0.4278151 -0.9923347 -1.128675
> >> -1.580374
> >>>> 15? -1.9290041 -0.9923347 -1.128675
> >> -1.580374
> >>>>
> >>>> But note the "$herd" bit.? Since this
> model
> >> has a
> >>>> varying intercept by
> >>>> herd, you get a column in the resulting
> data frame
> >> called
> >>>> "herd".
> >>>>
> >>>> So you could try, for this example:
> >>>>
> >>>>> exp(coef(gm1)$herd)
> >>>>
> >>
> (Intercept)???period2???period3???period4
> >>>> 1? ? 0.4455216 0.3707102
> 0.3234614
> >> 0.2058981
> >>>> 2? ? 0.1831538 0.3707102
> 0.3234614
> >> 0.2058981
> >>>> 3? ? 0.3707343 0.3707102
> 0.3234614
> >> 0.2058981
> >>>> 4? ? 0.2568527 0.3707102
> 0.3234614
> >> 0.2058981
> >>>> 5? ? 0.2042223 0.3707102
> 0.3234614
> >> 0.2058981
> >>>> 6? ? 0.1654982 0.3707102
> 0.3234614
> >> 0.2058981
> >>>> 7? ? 0.6010174 0.3707102
> 0.3234614
> >> 0.2058981
> >>>> 8? ? 0.4497060 0.3707102
> 0.3234614
> >> 0.2058981
> >>>> 9? ? 0.1947215 0.3707102
> 0.3234614
> >> 0.2058981
> >>>> 10???0.1437814 0.3707102
> 0.3234614
> >>>> 0.2058981
> >>>> 11???0.2269188 0.3707102
> 0.3234614
> >>>> 0.2058981
> >>>> 12???0.2314603 0.3707102
> 0.3234614
> >>>> 0.2058981
> >>>> 13???0.1238793 0.3707102
> 0.3234614
> >>>> 0.2058981
> >>>> 14???0.6519320 0.3707102
> 0.3234614
> >>>> 0.2058981
> >>>> 15???0.1452928 0.3707102
> 0.3234614
> >>>> 0.2058981
> >>>>
> >>>> Since the slopes don't vary by herd, you
> might
> >> also want
> >>>> just the fixed
> >>>> effects:
> >>>>
> >>>>> exp(fixef(gm1))
> >>>> (Intercept)?
> ???period2
> >>>>? ???period3
> >>? ? period4
> >>>>
> >>>>
> >>
> 0.2469585???0.3707102???0.3234614???0.2058981
> >>>>
> >>>> HTH,
> >>>>
> >>>> Andy
> >>>>
> >>>>
> >>>> E T wrote:
> >>>>> If I use the command coef(model) this
> extracts
> >> the
> >>>> coefficients in the
> >>>>> model, however if I try
> exp(coef(model)) I
> >> receive an
> >>>> error:
> >>>>>
> >>>>> Error in exp(coef(model)) :
> Non-numeric
> >> argument to
> >>>> mathematical function
> >>>>>
> >>>>> I could manually get the exp of each
> factor in
> >> my
> >>>> model..... but as I have a
> >>>>> large model (and also have numerous
> other
> >> models to
> >>>> produce), I was
> >>>>> wondering if there was an automated
> method
> >>>>>
> >>>>> Regards
> >>>>>
> >>>>> Et
> >>>>>
> >>>>> On Thu, Apr 8, 2010 at 11:27 AM, E T
> <2nuzzbot at gmail.com>
> >>>> wrote:
> >>>>>
> >>>>>> odds.ratios = exp(coefs(model))
> >>>>>>
> >>>>>> Thanks, however unfortunately when
> I try
> >> the above
> >>>> command I receive the
> >>>>>> following error:
> >>>>>>
> >>>>>> Error: could not find function
> "coefs"
> >>>>>>
> >>>>>> Regards
> >>>>>>
> >>>>>> Et
> >>>>>>
> >>>>>>
> >>>>>>
> >>>>>>
> >>>>>> On Wed, Apr 7, 2010 at 5:47 PM,
> Daniel
> >> Ezra
> >>>> Johnson <
> >>>>>> danielezrajohnson at gmail.com>
> >>>> wrote:
> >>>>>>
> >>>>>>> something like odds.ratios =
> >>>> exp(coefs(model))
> >>>>>>>
> >>>>>>>
> >>>>>>> On Apr 7, 2010, at 12:28 PM, E
> T
> >> <2nuzzbot at gmail.com>
> >>>> wrote:
> >>>>>>>
> >>>>>>>? ? Hi all,
> >>>>>>>> Apologies for the
> simplicity of
> >> my
> >>>> question.... however any advice is
> >>>>>>>> greatly appreciated.
> Thanks
> >>>>>>>>
> >>>>>>>> Is there a specific
> command
> >> available to
> >>>> obtain the odds ratios produced
> >>>>>>>> from a multilevel logistic
> model?
> >>>>>>>>
> >>>>>>>> I have estimated a
> multi-level
> >> logistic
> >>>> model using the lme4 package. I
> >>>>>>>> can
> >>>>>>>> obtain results using the
> >> 'summary'
> >>>> command, however I would like to
> >>>>>>>> obtain
> >>>>>>>> the computed odds ratios.
> >>>>>>>> (Similar to the output
> that can
> >> be
> >>>> produced for logistic GLM using the
> >>>>>>>> logistic.display command
> from the
> >> epicalc
> >>>> package).
> >>>>>>>>
> >>>>>>>>?
> ???[[alternative HTML
> >>>> version deleted]]
> >>>>>>>>
> >>>>>>>>
> >>>>
> _______________________________________________
> >>>>>>>> R-sig-mixed-models at r-project.org
> >>>> mailing list
> >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>>>>>
> >>>>>
> >>>>>? ? ? [[alternative
> HTML
> >> version
> >>>> deleted]]
> >>>>>
> >>>>>
> >> _______________________________________________
> >>>>> R-sig-mixed-models at r-project.org
> >>>> mailing list
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>
> >>>>
> >>>> -- 
> >>>> Andy Fugard, Postdoctoral researcher, ESF
> LogICCC
> >> project
> >>>> "Modeling human inference within the
> framework of
> >>>> probability logic"
> >>>> Department of Psychology, University of
> Salzburg,
> >> Austria
> >>>> http://www.andyfugard.info
> >>>>
> >>>>
> >>>>
> >>>> ------------------------------
> >>>>
> >>>> Message: 5
> >>>> Date: Thu, 8 Apr 2010 12:13:23 +0100
> >>>> From: E T <2nuzzbot at gmail.com>
> >>>> To: "Andy Fugard (Work)" <andy.fugard at sbg.ac.at>
> >>>> Cc: "r-sig-mixed-models at r-project.org"
> >>>>? ? ? <r-sig-mixed-models at r-project.org>
> >>>> Subject: Re: [R-sig-ME] Multi-level models
> Odds
> >> ratio
> >>>> Message-ID:
> >>>>? ? ? <p2p706f8d1f1004080413k3014fe10q444382c927c2f90e at mail.gmail.com
> 
> >>>> >
> >>>> Content-Type: text/plain
> >>>>
> >>>> exp(coef(model)$group)
> >>>>
> >>>> exp(fixef(model))
> >>>>
> >>>> Thanks.... yes this worked successfully
> :o)
> >>>>
> >>>> Et
> >>>>
> >>>> On Thu, Apr 8, 2010 at 11:48 AM, Andy
> Fugard
> >> (Work)
> >>>> <andy.fugard at sbg.ac.at>wrote:
> >>>>
> >>>>> Here's another example, borrowed from
> the help
> >> for
> >>>> "lmer":
> >>>>>
> >>>>>> gm1 <- glmer(cbind(incidence,
> size -
> >>>> incidence) ~ period + (1 | herd),
> >>>>>
> >>? ? family
> >>>> = binomial, data = cbpp)
> >>>>>
> >>>>> As you say, coef works:
> >>>>>
> >>>>>> coef(gm1)
> >>>>> $herd
> >>>>>? ???(Intercept)
> >>>>
> >>
> period2???period3???period4
> >>>>> 1???-0.8085096
> -0.9923347
> >> -1.128675
> >>>> -1.580374
> >>>>> 2???-1.6974292
> -0.9923347
> >> -1.128675
> >>>> -1.580374
> >>>>> 3???-0.9922697
> -0.9923347
> >> -1.128675
> >>>> -1.580374
> >>>>> 4???-1.3592525
> -0.9923347
> >> -1.128675
> >>>> -1.580374
> >>>>> 5???-1.5885461
> -0.9923347
> >> -1.128675
> >>>> -1.580374
> >>>>> 6???-1.7987950
> -0.9923347
> >> -1.128675
> >>>> -1.580374
> >>>>> 7???-0.5091313
> -0.9923347
> >> -1.128675
> >>>> -1.580374
> >>>>> 8???-0.7991613
> -0.9923347
> >> -1.128675
> >>>> -1.580374
> >>>>> 9???-1.6361848
> -0.9923347
> >> -1.128675
> >>>> -1.580374
> >>>>> 10? -1.9394614 -0.9923347
> -1.128675
> >> -1.580374
> >>>>> 11? -1.4831632 -0.9923347
> -1.128675
> >> -1.580374
> >>>>> 12? -1.4633469 -0.9923347
> -1.128675
> >> -1.580374
> >>>>> 13? -2.0884474 -0.9923347
> -1.128675
> >> -1.580374
> >>>>> 14? -0.4278151 -0.9923347
> -1.128675
> >> -1.580374
> >>>>> 15? -1.9290041 -0.9923347
> -1.128675
> >> -1.580374
> >>>>>
> >>>>> But note the "$herd" bit.? Since
> this
> >> model has a
> >>>> varying intercept by
> >>>>> herd, you get a column in the
> resulting data
> >> frame
> >>>> called "herd".
> >>>>>
> >>>>> So you could try, for this example:
> >>>>>
> >>>>>> exp(coef(gm1)$herd)
> >>>>>
> >>
> (Intercept)???period2???period3???period4
> >>>>> 1? ? 0.4455216 0.3707102
> 0.3234614
> >>>> 0.2058981
> >>>>> 2? ? 0.1831538 0.3707102
> 0.3234614
> >>>> 0.2058981
> >>>>> 3? ? 0.3707343 0.3707102
> 0.3234614
> >>>> 0.2058981
> >>>>> 4? ? 0.2568527 0.3707102
> 0.3234614
> >>>> 0.2058981
> >>>>> 5? ? 0.2042223 0.3707102
> 0.3234614
> >>>> 0.2058981
> >>>>> 6? ? 0.1654982 0.3707102
> 0.3234614
> >>>> 0.2058981
> >>>>> 7? ? 0.6010174 0.3707102
> 0.3234614
> >>>> 0.2058981
> >>>>> 8? ? 0.4497060 0.3707102
> 0.3234614
> >>>> 0.2058981
> >>>>> 9? ? 0.1947215 0.3707102
> 0.3234614
> >>>> 0.2058981
> >>>>> 10???0.1437814
> 0.3707102
> >> 0.3234614
> >>>> 0.2058981
> >>>>> 11???0.2269188
> 0.3707102
> >> 0.3234614
> >>>> 0.2058981
> >>>>> 12???0.2314603
> 0.3707102
> >> 0.3234614
> >>>> 0.2058981
> >>>>> 13???0.1238793
> 0.3707102
> >> 0.3234614
> >>>> 0.2058981
> >>>>> 14???0.6519320
> 0.3707102
> >> 0.3234614
> >>>> 0.2058981
> >>>>> 15???0.1452928
> 0.3707102
> >> 0.3234614
> >>>> 0.2058981
> >>>>>
> >>>>> Since the slopes don't vary by herd,
> you might
> >> also
> >>>> want just the fixed
> >>>>> effects:
> >>>>>
> >>>>>> exp(fixef(gm1))
> >>>>> (Intercept)?
> ???period2
> >>>>? ???period3
> >>? ? period4
> >>>>>
> >>>>
> >>
> 0.2469585???0.3707102???0.3234614???0.2058981
> >>>>>
> >>>>> HTH,
> >>>>>
> >>>>> Andy
> >>>>>
> >>>>>
> >>>>> E T wrote:
> >>>>>> If I use the command coef(model)
> this
> >> extracts
> >>>> the coefficients in the
> >>>>>> model, however if I try
> exp(coef(model))
> >> I
> >>>> receive an error:
> >>>>>>
> >>>>>> Error in exp(coef(model)) :
> Non-numeric
> >> argument
> >>>> to mathematical function
> >>>>>>
> >>>>>> I could manually get the exp of
> each
> >> factor in my
> >>>> model..... but as I
> >>>>> have a
> >>>>>> large model (and also have
> numerous other
> >> models
> >>>> to produce), I was
> >>>>>> wondering if there was an
> automated
> >> method
> >>>>>>
> >>>>>> Regards
> >>>>>>
> >>>>>> Et
> >>>>>>
> >>>>>> On Thu, Apr 8, 2010 at 11:27 AM, E
> T
> >> <2nuzzbot at gmail.com>
> >>>> wrote:
> >>>>>>
> >>>>>>> odds.ratios =
> exp(coefs(model))
> >>>>>>>
> >>>>>>> Thanks, however unfortunately
> when I
> >> try the
> >>>> above command I receive the
> >>>>>>> following error:
> >>>>>>>
> >>>>>>> Error: could not find
> function
> >> "coefs"
> >>>>>>>
> >>>>>>> Regards
> >>>>>>>
> >>>>>>> Et
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>> On Wed, Apr 7, 2010 at 5:47
> PM, Daniel
> >> Ezra
> >>>> Johnson <
> >>>>>>> danielezrajohnson at gmail.com>
> >>>> wrote:
> >>>>>>>
> >>>>>>>> something like odds.ratios
> =
> >>>> exp(coefs(model))
> >>>>>>>>
> >>>>>>>>
> >>>>>>>> On Apr 7, 2010, at 12:28
> PM, E T
> >> <2nuzzbot at gmail.com>
> >>>> wrote:
> >>>>>>>>
> >>>>>>>>? ? Hi all,
> >>>>>>>>> Apologies for the
> simplicity
> >> of my
> >>>> question.... however any advice is
> >>>>>>>>> greatly appreciated.
> Thanks
> >>>>>>>>>
> >>>>>>>>> Is there a specific
> command
> >> available
> >>>> to obtain the odds ratios
> >>>>> produced
> >>>>>>>>> from a multilevel
> logistic
> >> model?
> >>>>>>>>>
> >>>>>>>>> I have estimated a
> >> multi-level
> >>>> logistic model using the lme4 package.
> >>>>> I
> >>>>>>>>> can
> >>>>>>>>> obtain results using
> the
> >> 'summary'
> >>>> command, however I would like to
> >>>>>>>>> obtain
> >>>>>>>>> the computed odds
> ratios.
> >>>>>>>>> (Similar to the output
> that
> >> can be
> >>>> produced for logistic GLM using the
> >>>>>>>>> logistic.display
> command from
> >> the
> >>>> epicalc package).
> >>>>>>>>>
> >>>>>>>>>?
> ???[[alternative
> >> HTML
> >>>> version deleted]]
> >>>>>>>>>
> >>>>>>>>>
> >>>>
> _______________________________________________
> >>>>>>>>> R-sig-mixed-models at r-project.org
> >>>> mailing list
> >>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>>>>>>
> >>>>>>
> >>>>>>? ? ?
> ???[[alternative
> >> HTML
> >>>> version deleted]]
> >>>>>>
> >>>>>>
> >> _______________________________________________
> >>>>>> R-sig-mixed-models at r-project.org
> >>>> mailing list
> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>>
> >>>>>
> >>>>> --
> >>>>> Andy Fugard, Postdoctoral researcher,
> ESF
> >> LogICCC
> >>>> project
> >>>>> "Modeling human inference within the
> framework
> >> of
> >>>> probability logic"
> >>>>> Department of Psychology, University
> of
> >> Salzburg,
> >>>> Austria
> >>>>> http://www.andyfugard.info
> >>>>>
> >>>>
> >>>>? ? ? [[alternative HTML
> version
> >> deleted]]
> >>>>
> >>>>
> >>>>
> >>>> ------------------------------
> >>>>
> >>>>
> _______________________________________________
> >>>> R-sig-mixed-models mailing list
> >>>> R-sig-mixed-models at r-project.org
> >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>
> >>>>
> >>>> End of R-sig-mixed-models Digest, Vol 40,
> Issue
> >> 15
> >>>>
> >>
> **************************************************
> >>>>
> >>>
> >>>
> >>>
> >>>
> >>>
> _______________________________________________
> >>> R-sig-mixed-models at r-project.org
> >> mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>
> >>
> >>
> >> -- 
> >> The University of Edinburgh is a charitable body,
> >> registered in
> >> Scotland, with registration number SC005336.
> >>
> >>
> >
> >
> >
> >
> 
> 
> -- 
> The University of Edinburgh is a charitable body,
> registered in
> Scotland, with registration number SC005336.
> 
> 






From j.hadfield at ed.ac.uk  Fri Apr  9 15:41:37 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 9 Apr 2010 14:41:37 +0100
Subject: [R-sig-ME] Bayesian counterpart to NPMLREG
In-Reply-To: <t2t5abc11d81004090628g74f9a3e1vc2d7fb81ffd3c29c@mail.gmail.com>
References: <t2t5abc11d81004090628g74f9a3e1vc2d7fb81ffd3c29c@mail.gmail.com>
Message-ID: <B45A625B-7833-439E-AE88-7E2CDC214875@ed.ac.uk>

Dear Shige,

I am not sure what is meant by "mass points for the random component"  
so can't really say whether it is better or worse than assuming a  
Gaussian distribution for the random effects. With regard to your  
second question - MCMCglmm assumes the random effects follow a  
Gaussian distribution on the link scale, and does not allow an other  
option. The hglm package would allow different distributions though.

Note that unless you have rescaled your terms by your choice of  
residual  variance (the response is binary, right?) then you should  
not expect MCMCglmm to give you the same answer as lme4 (and NPMLREG  
probably).

Cheers,

Jarrod


On 9 Apr 2010, at 14:28, Shige Song wrote:

> Dear All,
>
> I am comparing two sets of results on involuntary fetal loss from
> retrospective pregnancy history. Since each woman may have more than
> one pregnancy, it makes sense to analyse it as a two-level logistic
> regression with random intercept (at mother-level). One set of results
> were obtained from random effect models that assume normal
> distribution for the random component (estimated using Lme4 and
> NPMLREG with random distribution set to "gh"), the second set of
> results were obtained from random effect model that assume a set of
> mass points for the random component (estimated using NPMLREG with
> random distribution set to "np"). There are some interesting findings.
> To be more specific, one interaction term I included (between birth
> cohort and place residence) was estimated to be .373 (.202) in random
> effect logistic regression assuming normal distribution but .433
> (.202) in random effect assuming non-parametric random component. My
> reading on this is that, the normal distribution assumption has
> downwardly biased the point estimate of this interaction term and the
> NPML estimate is more trustworthy.
>
> I also want to do a similar comparison with Bayesian analysis. I have
> been playing with MCMCglmm. The mean and the median of the posterior
> distribution for that interaction term is .415 and .414, which is in
> between of the the parametric and non-parametric ML estimates. Are we
> still assuming some parametric distributions for the random component
> here? If so, is there a way to further relax such assumption? Any
> comments and suggestion are highly appreciated.
>
> Best,
> Shige
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From ken.knoblauch at inserm.fr  Fri Apr  9 16:15:13 2010
From: ken.knoblauch at inserm.fr (Ken Knoblauch)
Date: Fri, 09 Apr 2010 16:15:13 +0200
Subject: [R-sig-ME] Another case of -1.0 correlation of random effects
In-Reply-To: <4BBF2584.10609@ufl.edu>
References: <4BBF0986.70309@utoronto.ca>
	<loom.20100409T143920-273@post.gmane.org> <4BBF2584.10609@ufl.edu>
Message-ID: <20100409161513.ggvxn9h70ooswsos@imp.inserm.fr>

Yes. It was a knee-jerk reaction, recalling a trap that
I fell into before with glm.  But, lmer seems to handle
this smoothly for the grouping factor.  Thanks.

Ken


Quoting Ben Bolker <bolker at ufl.edu>:

> Ken Knoblauch wrote:
>> Kevin E. Thorpe <kevin.thorpe at ...> writes:
>>
>>> My data come from a crossover trial and are balanced.
>>>
>>>  > str(gluc)
>>> 'data.frame':	96 obs. of  4 variables:
>>>   $ Subject  : int  1 2 3 5 6 7 10 11 12 13 ...
>>>   $ Treatment: Factor w/ 2 levels "Barley","Oat": 1 1 1 1 1 1 1 1 1 1 ...
>>>   $ Dose     : int  8 8 8 8 8 8 8 8 8 8 ...
>>>   $ iAUC     : num  110 256 129 207 244 ...
>>>
>>
>>> clip>
>>
>> Shouldn't you make Subject into a factor?
>>
>> Ken
>>
>
>   It would make the plot a little bit prettier but I don't think it
> matters in this case because variable that appears as a grouping
> variable (i.e. on the right of the | ) is automatically treated as a
> factor?  I think?
>
>   Since it is really a crossover trial, it would seem reasonable in
> principle to have the (Treatment|Subject) random effect in there as
> well. I'm not sure what to do about the -1 correlation: it seems the
> choices (not necessarily in order) are (1) throw up your hands and say
> there's not enough data to estimate independently; (2) try WinBUGS,
> possibly with slightly informative priors; (3) try using lme4a to create
> profiles of the parameters and see if you can figure out what's happening.
>
>
>
> --
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / people.biology.ufl.edu/bolker
> GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc
>



-- 
Ken Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html



From shigesong at gmail.com  Fri Apr  9 16:20:47 2010
From: shigesong at gmail.com (Shige Song)
Date: Fri, 9 Apr 2010 10:20:47 -0400
Subject: [R-sig-ME] Bayesian counterpart to NPMLREG
In-Reply-To: <B45A625B-7833-439E-AE88-7E2CDC214875@ed.ac.uk>
References: <t2t5abc11d81004090628g74f9a3e1vc2d7fb81ffd3c29c@mail.gmail.com>
	<B45A625B-7833-439E-AE88-7E2CDC214875@ed.ac.uk>
Message-ID: <s2q5abc11d81004090720qe369c46ei4a465871fe1033b7@mail.gmail.com>

Dear Jarrod,

Thanks for the quick response. Software packages like NPMLREG, GLLAMM,
and GLIM4, instead of assuming the random components of multilevel
models follow normal distribution and integrating them using GH
quadrature, approximate the random components non-procedurally using a
number of mass points, sort of like using histogram to approximate a
density function. As results, the random components are not
constrained to follow any distributions and thus may be more flexible.

Thank you for the information about hglm (it is hglmm, isn't it), I
will definitely check it out.

Best,
Shige

On Fri, Apr 9, 2010 at 9:41 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
> Dear Shige,
>
> I am not sure what is meant by "mass points for the random component" so
> can't really say whether it is better or worse than assuming a Gaussian
> distribution for the random effects. With regard to your second question -
> MCMCglmm assumes the random effects follow a Gaussian distribution on the
> link scale, and does not allow an other option. The hglm package would allow
> different distributions though.
>
> Note that unless you have rescaled your terms by your choice of residual
> ?variance (the response is binary, right?) then you should not expect
> MCMCglmm to give you the same answer as lme4 (and NPMLREG probably).
>
> Cheers,
>
> Jarrod
>
>
> On 9 Apr 2010, at 14:28, Shige Song wrote:
>
>> Dear All,
>>
>> I am comparing two sets of results on involuntary fetal loss from
>> retrospective pregnancy history. Since each woman may have more than
>> one pregnancy, it makes sense to analyse it as a two-level logistic
>> regression with random intercept (at mother-level). One set of results
>> were obtained from random effect models that assume normal
>> distribution for the random component (estimated using Lme4 and
>> NPMLREG with random distribution set to "gh"), the second set of
>> results were obtained from random effect model that assume a set of
>> mass points for the random component (estimated using NPMLREG with
>> random distribution set to "np"). There are some interesting findings.
>> To be more specific, one interaction term I included (between birth
>> cohort and place residence) was estimated to be .373 (.202) in random
>> effect logistic regression assuming normal distribution but .433
>> (.202) in random effect assuming non-parametric random component. My
>> reading on this is that, the normal distribution assumption has
>> downwardly biased the point estimate of this interaction term and the
>> NPML estimate is more trustworthy.
>>
>> I also want to do a similar comparison with Bayesian analysis. I have
>> been playing with MCMCglmm. The mean and the median of the posterior
>> distribution for that interaction term is .415 and .414, which is in
>> between of the the parametric and non-parametric ML estimates. Are we
>> still assuming some parametric distributions for the random component
>> here? If so, is there a way to further relax such assumption? Any
>> comments and suggestion are highly appreciated.
>>
>> Best,
>> Shige
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>



From kevin.thorpe at utoronto.ca  Fri Apr  9 19:54:43 2010
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Fri, 09 Apr 2010 13:54:43 -0400
Subject: [R-sig-ME] Another case of -1.0 correlation of random effects
In-Reply-To: <4BBF2584.10609@ufl.edu>
References: <4BBF0986.70309@utoronto.ca>	<loom.20100409T143920-273@post.gmane.org>
	<4BBF2584.10609@ufl.edu>
Message-ID: <4BBF69E3.3050308@utoronto.ca>

Ben Bolker wrote:
> Ken Knoblauch wrote:
>> Kevin E. Thorpe <kevin.thorpe at ...> writes:
>>
>>> My data come from a crossover trial and are balanced.
>>>
>>>  > str(gluc)
>>> 'data.frame':	96 obs. of  4 variables:
>>>   $ Subject  : int  1 2 3 5 6 7 10 11 12 13 ...
>>>   $ Treatment: Factor w/ 2 levels "Barley","Oat": 1 1 1 1 1 1 1 1 1 1 ...
>>>   $ Dose     : int  8 8 8 8 8 8 8 8 8 8 ...
>>>   $ iAUC     : num  110 256 129 207 244 ...
>>>
>>> clip>
>> Shouldn't you make Subject into a factor?
>>
>> Ken
>>
> 
>   It would make the plot a little bit prettier but I don't think it
> matters in this case because variable that appears as a grouping
> variable (i.e. on the right of the | ) is automatically treated as a
> factor?  I think?
> 
>   Since it is really a crossover trial, it would seem reasonable in
> principle to have the (Treatment|Subject) random effect in there as
> well. I'm not sure what to do about the -1 correlation: it seems the
> choices (not necessarily in order) are (1) throw up your hands and say
> there's not enough data to estimate independently; (2) try WinBUGS,
> possibly with slightly informative priors; (3) try using lme4a to create
> profiles of the parameters and see if you can figure out what's happening.

Let's see.  I wish (1) was an option.  (2) would be promising if my 
knowledge of BUGS and Bayesian methods filled more than a thimble. 
Thanks to Jarrod for his suggestion in response to this.  I'll take a 
look at that too.  Option (3) is probably worth a go too.

Aside from the fact that the Dose variable are the actual doses and not 
categories, and we all know not to categorize continuous variables, what 
are your thoughts on treating Dose as a factor (since it seems to behave)?

Thanks all for taking the time to provide your suggestions.

Kevin

-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016



From dadrivr at gmail.com  Fri Apr  9 22:43:05 2010
From: dadrivr at gmail.com (Isaac Petersen)
Date: Fri, 9 Apr 2010 16:43:05 -0400
Subject: [R-sig-ME] Fixed vs. random slopes
Message-ID: <o2o2708c8bc1004091343p6812f7d5s7bc08546ad1b2214@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100409/3b514244/attachment.pl>

From alessiag at interchange.ubc.ca  Sun Apr 11 06:11:57 2010
From: alessiag at interchange.ubc.ca (Alessia Guggisberg)
Date: Sat, 10 Apr 2010 21:11:57 -0700
Subject: [R-sig-ME] variance structure in lme/lmer
References: <5484B83D4A00471FB4456A35712C1971@Guggisberg>
	<A8CFA9F9-2A41-4882-9199-803E2DB8D91B@ed.ac.uk>
	<121EB05A386845FB88C384B5876264D1@Guggisberg>
	<E2DB66E8-678A-4760-8C1F-B24C905785F7@ed.ac.uk>
Message-ID: <3DC905805F7A4E4CBC6D5FB63871C144@Guggisberg>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100410/df62e54e/attachment.pl>

From j.hadfield at ed.ac.uk  Sun Apr 11 20:43:13 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sun, 11 Apr 2010 19:43:13 +0100
Subject: [R-sig-ME] variance structure in lme/lmer
In-Reply-To: <3DC905805F7A4E4CBC6D5FB63871C144@Guggisberg>
References: <5484B83D4A00471FB4456A35712C1971@Guggisberg>
	<A8CFA9F9-2A41-4882-9199-803E2DB8D91B@ed.ac.uk>
	<121EB05A386845FB88C384B5876264D1@Guggisberg>
	<E2DB66E8-678A-4760-8C1F-B24C905785F7@ed.ac.uk>
	<3DC905805F7A4E4CBC6D5FB63871C144@Guggisberg>
Message-ID: <20100411194313.k5ozroh74844w0ow@www.staffmail.ed.ac.uk>

Dear Alessia,

I think the first model is trying to fit the model you intend, the  
problem is that it is failing to converge.

It is hard for me too see from the information I have, but I think the  
problem is that the Mom effects are confounded with the residuals. Am  
I right in thinking there is one observation per Mom in each  
treatment? If so, you cannot separate the treatment specific Mom  
variances from the treatment specific residual variances.

You have four options:

a) Drop Mom from the model and interpret the weight term as the  
combined effects of Mom and residual. Here you assume the variances  
differ between the treatments, and the Mom effects in the two  
treatments are uncorrelated

b) Have "~at.level(Range, "invasive")|Mom" (i.e without the  
interaction with Treatment) and the weight term.  Here you assume the  
variances differ between the treatments (again measured by the weights  
term), but the Mom effects have a positive covariance which is  
estimated by the Mom variance component.

c) Use ASReml to fit a model where the Mom terms in the original model  
defines a residual covariance matrix. This is the same as b) except  
the covariances are free to go negative

You can imagine these models as trying to fit a 2x2 covariance matrix  
for each range. The covariance matrix is the Mom+Residual  
(co)variances for the two treatments. If we label the estimates as a)  
weight in treatment 1, b) weight in treatment 2 and c) the Mom  
estimate then these matrices have the form

a)  =   a 0
         0 b

b)  =   a+c  c
         c   b+c

where as ASReml would directly estimate the covariance matrix.

MCMCglmm cannot estimate c) in this case because it would not allow  
the Range interaction in the residual structure as well as the  
Treatment interaction. This is an over sight on my part but do not  
have time in the next few months to remedy it.

Cheers,

Jarrod




Quoting Alessia Guggisberg <alessiag at interchange.ubc.ca>:

> Dear Jarrod
>
> I've tried many times to run your function in lme, but I always got   
> an error message, must often of the form:
>
>> model=lme(above~Treatment*Range*t0.LLL, random =   
>> list(~at.level(Range, "invasive"):Treatment-1|Pop, ~at.level(Range,  
>>  "native"):Treatment-1|Pop, ~at.level(Range,   
>> "invasive"):Treatment-1|Mom, ~at.level(Range,   
>> "native"):Treatment-1|Mom), weights=varIdent(form=~1|Treatment*Range)
>
> Erreur dans lme.formula(above ~ Treatment * Range * t0.LLL, random =  
>  list(~at.level(Range,  :
>   nlminb problem, convergence error code = 1
>   message = iteration limit reached without convergence (9)
>
> or
>
>> model=lme(above~Treatment*Range*t0.LLL, random =   
>> list(~at.level(Range, "invasive"):Treatment-1|Pop/Mom,   
>> ~at.level(Range, "native"):Treatment-1|Pop/Mom),   
>> weights=varIdent(form=~1|Treatment*Range),   
>> data=ch.above.3);summary(model)
>
> Erreur dans MEEM(object, conLin, control$niterEM) :
>   NA dans un appel ? une fonction externe (argument 2)
> De plus : Message d'avis :
> In ncols * c(rep(1, Q), 0, 0) :
>
> I'm afraid your function cannot be combined with weights in lme.
>
> Alessia
>
> *************************************************************
> Alessia Guggisberg, PhD
> Postdoctoral Fellow
> Department of Botany
> University of British Columbia
> 3529-6270 University Boulevard
> Vancouver, BC, V6T 1Z4
> Canada
>
> Email: alessiag at interchange.ubc.ca
>
> *************************************************************
>   ----- Original Message -----
>   From: Jarrod Hadfield
>   To: Alessia Guggisberg
>   Cc: r-sig-mixed-models at r-project.org
>   Sent: Friday, April 09, 2010 2:04 AM
>   Subject: Re: [R-sig-ME] variance structure in lme/lmer
>
>
>   Hi,
>
>
>   I think
>
>
>   model=lme(above~Treatment, random = list(~ at.level(Range,   
> "native"):Treatment-1|Pop/mom, ~ at.level(Range,   
> "invasive"):Treatment-1|Pop/mom), weights=varIdent(form=~1*Range))
>
>
>   should do the job.
>
>
>   Cheers,
>
>
>   Jarrod
>
>
>
>
>   On 8 Apr 2010, at 18:08, Alessia Guggisberg wrote:
>
>
>     Hi Jarrod
>
>     Thank you so much for your reply!
>
>     Indeed, each population/mom belongs to one type of range (native  
>  or invasive) solely, but occurs in both treatment plots. I've just   
> tried your suggestion and br>
>     model=lmer(above~Treatment * Range * Ct0.LLL + (at.level(Range,   
> "native"):Treatment-1|Pop/Mom) +   
> (at.level(Range,"invasive"):Treatment-1|Pop/Mom))
>
>     Random effects:
>     Groups       Name Variance           Std.Dev.           Corr
>     Mom:Pop  at.level(Range, "invasive"):TreatmentControl         
> 1.1326e+01 3.3654e+00
>                     at.level(Range, "invasive"):TreatmentHerbivory   
> 9.1458e-01     9.5633e-01        0.292
>     Mom:Pop  at.level(Range, "native"):TreatmentControl            
> 1.1868e+01 3.4451e+00
>                     at.level(Range, "native"):Trea     1.3415e+00       0.396
>     Pop          at.level(Range, "invasive"):TreatmentControl         
>  1.1083e-09 3.3291e-05
>                     at.level(Range, "invasive"):TreatmentHerbivory   
> 2.9827e-01      5.4614e-01        0.000
>     Pop          at.level(Range, "native"):TreatmentControl   
> 5.5788e+00      2.3619e+00
>                     at.level(Range, "native"):TreatmentHerbivory   
> 1.5701e+00     1.2530e+00        0.839
>     Residual 1.1545e+00     1.0745e+00
>     Number of obs: 368, groups: Mom:Pop, 184; Pop, are now 'logical'  
>  as I get zero-values for populations/moms that do not occur in a   
> given range.
>
>     The question remains though, whether I should additionnally   
> account for heterogeneity in the innermost residuals (like 'weights'  
>  in lme), and if so, how I should implement that in lmer.
>
>     Thanks again for your precious help; thanks to you, I've just   
> made a big step today....
>
>     Best,
>
>     Alessia
>
>
>     *************************************************************
>     Alessia Guggisberg, PhD
>     Postdoctoral Fellow
>     Department of Botany
>     University of British Columbia
>     3529-6270 University Boulevard
>     Vancouver, BC, V6T 1Z4
>     Canada
>
>     Email: alessiag at interchange.ubc.ca
>
>     *************************************************************
>     ----- Original Message ----- From: "Jarrod Hadfield"   
> <j.hadfield at ed.ac.uk>
>     To: "Alessia Guggisberg" <r-sig-mixed-models at r-project.org>
>     Sent: Thursday, April 08, 2010 2:22 AM
>     Subject: Re: [R-sig-ME] variance structure in lme/lmer
>
>
>
>       Dear Alessia,
>
>
>
>       I think the problem is that  individuals from a population all  
>  belong  to one type (native or invasive) (is this true?) If this is  
>  the case  your 4x4 covariance matrices needs to look like
>
>
>
>              TreatmentControl:Rangenative   *  *  0  0
>
>          TreatmentHerbivory:Rangenative   *  *  0  0
>
>       TreatmentHerbivory:Rangeinvasive   0  0  *  *
>       TreatmentHerbivory:Rangeinvasive   0  0  *  *
>
>
>
>       where * indicates it could be estimated and 0 not.
>
>
>
>       To fit such a covariance matrix  try
>
>
>
>       (at.level(Range, "native"):Treatment-1|Pop)+(at.level(Range,   
> "invasive"):Treatment-1|Pop)
>
>
>
>       in lmer.  The at.level function is at the bottom of the email
>
>
>
>       If individuals with the same mother have the same treatment   
> then the pop/mom matrix needs to be
>
>
>
>
>
>             &nb native   *  0  0  0
>
>          TreatmentHerbivory:Rangenative   0  *  0  0
>
>       TreatmentHerbivory:Rangeinvasive   0  0  *  0
>
>       TreatmentHerbivory:Rangeinvasive   0  0  0  *
>
>
>
>       and you can use either
>
>
>
>       (at.level(Range, "native"):at.level(Treatment, "Herbivory")-1|  
>  Pop:mom)+(at.level(Range, "invasive"):at.level(Treatment,   
> "Herbivory")-1|Pop:mom)+(at.level(Range,   
> "native"):at.level(Treatment, "Control")-1|Pop:mom)+(at.level(Range,  
>  "invasive"):at.level(Treatment, Control")-1|Pop:mom)
>
>
>
>       or
>
>
>       (at.level(subgroup, 1)|Pop:mom)+ (at.level(subgroup,   
> 2)|Pop:mom) + (at.level(subgroup, 3)|Pop:mom) + (at.level(subgroup,   
> 4)|Pop:mom)
>
>
>
>       I'm not sure if you can use this type of syntax in lme, but   
> without allowing different residual variances for the subgroups I   
> would be  very cautious about the results.
>
>
>
>       Cheers,
>
>
>
>       Jarrod
>
>
>
>
>
>
>
>       at.level<-function (x, level)
>
>       {
>
>          if (is.numeric(level)) {
>
>              M <- outer(x, lev /blockquote>
>            }
>
>            else {
>
>                M <- outer(x, level, "==")
>
>            }
>
>            mode(M) <- "numeric"
>
>            M
>
>         }
>
>         <environment: namespace:MCMCglmm>
>
>
>
>
>
>
>
>         On 8 Apr 2010, at 06:50, Alessia Guggisberg wrote:
>
>
>
>           Dear R-sig-mixed-models list members
>
>
>           <
>               I apologise in advance, if my question seems trivial;   
> I'm new to mixed-models in R.
>
>
>
>               To make things easier, I'm giving you an example,   
> followed by the questions I'm hoping to be able to address with one   
> of you.
>
>
>
>               Study: Response of different populations of plants   
> from two  different ranges (Europe vs. North America) to various   
> stresses in a  greenhouse experiment
>
>               Study question: Do populations from the native range   
> (Europe) differ  in terms of response from the ones of the   
> introduced range (North  America)?
>
>           Type of data: Growth and reproductive data
>
>           Example of mixed model: above-ground biomass as a function  
>  of  treatment (control vs. stress), range (Europe vs. North  
> America)  and  a covariate (in this case, longest leaf length at t0,  
> to  account for  size difference prior to stress)
>
>
>
>           model=lme(above~Treatment * Range * t0.LLL, random= ~1|Pop/Mom)
>
>
>
>           model=lmer(above~Treatment * Range * t0.LLL + (1|Pop/Mom))
>
>
>
>           Due to the introduct I expect less genetic variation in   
> the introduced than in the native range, hence less variation in   
> response in the introduced than native range. Indeed, inspection of   
> raw data and residuals indicate higher variance for  native than   
> introduced range. Similarly, I observe less variation in  response   
> in the stress than in the control plot. Obviously, these    
> observations suggest violation of homoscedasticity. I therefore    
> would like to test and eventually account for difference in    
> variances between the different subgroups: (i) Europe-control, (ii)   
>  Europe-stress, (iii) North America-control, (iv) North  
> America-stress.
>
>
>
>           Following options are possible:
>
>
>
>           - ticity in the innermost residuals:
>
>
>
>           model=lme(above~Treatment * Range * t0.LLL, random=   
> ~1|Pop/Mom, weights=varIdent(form=~1|Treatment*Range))
>
>
>
>           Random effects:
>
>           Formula: ~1 | Pop
>
>                         (Intercept)
>
>           StdDev:     0.997503
>
>
>
>                         (Intercept)     Residual
>
>           StdDev:     1.150242      3.684324
>
>
>
>           Variance function:
>
>           Structure: Different standard deviations per stratum
>
>           Formula: ~1 | Treatment * Range
>
>           Parameter estimates:
>
>             Control*native &nbs   Control*invasive Herbivory*invasive
>
>             1.0000000        0.3343747           0.9324055            
>  0.2389115
>
>
>
>           Is it true, that weights cannot be incorporated in lmer?
>
>
>
>           - stratify the variance for the random effects:
>
>
>
>           subgroup=factor(Treatment:Range)
>
>         ## warning message: Fewer observations than random effects   
> in all  level 2 groups
>
>
>
>         model=lmer(above~Treatment * Range * t0.LLL + (0 + subgroup|Pop/Mom))
>
>
>
>         Random effects:
>
>         Groups       Name                                         Va te>
>           Mom:Pop    TreatmentControl:Rangenative      11.783704        0.000
>
>                            TreatmentHerbivory:Rangenative   1.714778  
>  0.419    0.000
>
>                            TreatmentControl:Rangeinvasive 378         
>   -0.003    0.311        -0.001
>
>                            Treatm e 0.819599
>
>           Pop            TreatmentControl:Rangenative       5.578492
>
>                            TreatmentHerbivory:Rangenative    1.569965 1.000
>
>                            TreatmentControl:Rangeinvasive       
> 0.029164 0.839     0.839
>
>                            TreatmentHerbivory:Rangeinvasive    
> 0.315794 1.000  &n sp;      0.839
>
>           Residual                                                    
>        1.239337
>
>           Number of obs: 368, groups: Mom:Pop, 184; Pop, 42
>
>
>
>           Why do I get an error message, when I run the model in lme?
>
>
>
>           - another option found in e each subgroup  with a dummy   
> variable, as follows (I only know how to implement that  method with  
>  lmer):
>
>
>
>           nativeControl=as.numeric(factor(Range=="native" &    
> Treatment=="Control"))
>
>           invasiveControl=as.numeric(factor(Range=="invasive" &   
> Treatment=="Control"))
>
>           nativeHerbivory=as.numeric(factor(Range=="native" &   
> Treatment=="Herbivory"))
>
>           invasiveHerbivory=as.numeric(factor(Range=="invasive" &   
> Treatment=="Herbivory"))
>
>           model=lmer(above~Treatment*Range*t0.LLL + (0 +   
> nativeControl|Pop/ Mom) + (0 + invasiveCon veHerbivory|Pop/Mom)  +   
> (0 + invasiveHerbivory|Pop/Mom))
>
>
>
>           Random effects:
>
>           Groups       Name                   Variance
>
>           Mom:Pop   invasiveHerbivory    0.0000e+00
>
>           Mom:Pop   nativeHerbivory      0.0000e+00
>
>           Mom:Pop   invasiveControl       9.7939e-01
>
>           Pop          invasiveHerbivory    0.0000e+00
>
>           Pop          nativeHerbivory      2.4815e-10
>
>           Pop          invasiveControl      1.7994e-09
>
>           Pop          nativeControl         9.1133e-01
>
>           Residual          &nbs ;                 4.1959e+00
>
>           Number of obs: 368, groups: Mom:Pop, 184; Pop, 42
>
>
>
>           This last model entails less parameters than the previous   
> one  (because it doesn't calculate any correlations), but its AIC is  
>  also  much higher. Other than that, what differs between the two   
> previous  models?
>
>
>
>           In view of my problematic, what do you suggest me to do?
>
>
>
>           I thank yo you might be able to provide and look forward   
> to receiving your recommendations.
>
>
>
>           Best,
>
>
>
>           Alessia
>
>
>
>           *************************************************************
>
>           Alessia Guggisberg, PhD
>
>           Postdoctoral Fellow
>
>           Department of Botany
>
>           Un bia
>
>           3529-6270 University Boulevard
>
>           Vancouver, BC, V6T 1Z4
>
>           Canada
>
>
>
>           Email: alessiag at interchange.ubc.ca
>
>
>
>           *************************************************************
>
>           [[alternative HTML version deleted]]
>
>
>
>         < _____________________________________________
>
>         R-sig-mixed-models at r-project.org mailing list
>
>         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
>
>
>
>
>       --
>
>       The University of Edinburgh is a charitable body, registered in
>
>       Scotland, with registration number SC005336.
>
>
>
>
>
>
>
>
> ------------------------------------------------------------------------------
>
>
>   The University of Edinburgh is a charitable body, registered in
>   Scotland, with registration number SC005336.
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From j.hadfield at ed.ac.uk  Sun Apr 11 20:43:24 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sun, 11 Apr 2010 19:43:24 +0100
Subject: [R-sig-ME] variance structure in lme/lmer
In-Reply-To: <3DC905805F7A4E4CBC6D5FB63871C144@Guggisberg>
References: <5484B83D4A00471FB4456A35712C1971@Guggisberg>
	<A8CFA9F9-2A41-4882-9199-803E2DB8D91B@ed.ac.uk>
	<121EB05A386845FB88C384B5876264D1@Guggisberg>
	<E2DB66E8-678A-4760-8C1F-B24C905785F7@ed.ac.uk>
	<3DC905805F7A4E4CBC6D5FB63871C144@Guggisberg>
Message-ID: <20100411194324.twow5fgt2i8sc4ks@www.staffmail.ed.ac.uk>

Dear Alessia,

I think the first model is trying to fit the model you intend, the  
problem is that it is failing to converge.

It is hard for me too see from the information I have, but I think the  
problem is that the Mom effects are confounded with the residuals. Am  
I right in thinking there is one observation per Mom in each  
treatment? If so, you cannot separate the treatment specific Mom  
variances from the treatment specific residual variances.

You have four options:

a) Drop Mom from the model and interpret the weight term as the  
combined effects of Mom and residual. Here you assume the variances  
differ between the treatments, and the Mom effects in the two  
treatments are uncorrelated

b) Have "~at.level(Range, "invasive")|Mom" (i.e without the  
interaction with Treatment) and the weight term.  Here you assume the  
variances differ between the treatments (again measured by the weights  
term), but the Mom effects have a positive covariance which is  
estimated by the Mom variance component.

c) Use ASReml to fit a model where the Mom terms in the original model  
defines a residual covariance matrix. This is the same as b) except  
the covariances are free to go negative

You can imagine these models as trying to fit a 2x2 covariance matrix  
for each range. The covariance matrix is the Mom+Residual  
(co)variances for the two treatments. If we label the estimates as a)  
weight in treatment 1, b) weight in treatment 2 and c) the Mom  
estimate then these matrices have the form

a)  =   a 0
         0 b

b)  =   a+c  c
         c   b+c

where as ASReml would directly estimate the covariance matrix.

MCMCglmm cannot estimate c) in this case because it would not allow  
the Range interaction in the residual structure as well as the  
Treatment interaction. This is an over sight on my part but do not  
have time in the next few months to remedy it.

Cheers,

Jarrod




Quoting Alessia Guggisberg <alessiag at interchange.ubc.ca>:

> Dear Jarrod
>
> I've tried many times to run your function in lme, but I always got   
> an error message, must often of the form:
>
>> model=lme(above~Treatment*Range*t0.LLL, random =   
>> list(~at.level(Range, "invasive"):Treatment-1|Pop, ~at.level(Range,  
>>  "native"):Treatment-1|Pop, ~at.level(Range,   
>> "invasive"):Treatment-1|Mom, ~at.level(Range,   
>> "native"):Treatment-1|Mom), weights=varIdent(form=~1|Treatment*Range)
>
> Erreur dans lme.formula(above ~ Treatment * Range * t0.LLL, random =  
>  list(~at.level(Range,  :
>   nlminb problem, convergence error code = 1
>   message = iteration limit reached without convergence (9)
>
> or
>
>> model=lme(above~Treatment*Range*t0.LLL, random =   
>> list(~at.level(Range, "invasive"):Treatment-1|Pop/Mom,   
>> ~at.level(Range, "native"):Treatment-1|Pop/Mom),   
>> weights=varIdent(form=~1|Treatment*Range),   
>> data=ch.above.3);summary(model)
>
> Erreur dans MEEM(object, conLin, control$niterEM) :
>   NA dans un appel ? une fonction externe (argument 2)
> De plus : Message d'avis :
> In ncols * c(rep(1, Q), 0, 0) :
>
> I'm afraid your function cannot be combined with weights in lme.
>
> Alessia
>
> *************************************************************
> Alessia Guggisberg, PhD
> Postdoctoral Fellow
> Department of Botany
> University of British Columbia
> 3529-6270 University Boulevard
> Vancouver, BC, V6T 1Z4
> Canada
>
> Email: alessiag at interchange.ubc.ca
>
> *************************************************************
>   ----- Original Message -----
>   From: Jarrod Hadfield
>   To: Alessia Guggisberg
>   Cc: r-sig-mixed-models at r-project.org
>   Sent: Friday, April 09, 2010 2:04 AM
>   Subject: Re: [R-sig-ME] variance structure in lme/lmer
>
>
>   Hi,
>
>
>   I think
>
>
>   model=lme(above~Treatment, random = list(~ at.level(Range,   
> "native"):Treatment-1|Pop/mom, ~ at.level(Range,   
> "invasive"):Treatment-1|Pop/mom), weights=varIdent(form=~1*Range))
>
>
>   should do the job.
>
>
>   Cheers,
>
>
>   Jarrod
>
>
>
>
>   On 8 Apr 2010, at 18:08, Alessia Guggisberg wrote:
>
>
>     Hi Jarrod
>
>     Thank you so much for your reply!
>
>     Indeed, each population/mom belongs to one type of range (native  
>  or invasive) solely, but occurs in both treatment plots. I've just   
> tried your suggestion and br>
>     model=lmer(above~Treatment * Range * Ct0.LLL + (at.level(Range,   
> "native"):Treatment-1|Pop/Mom) +   
> (at.level(Range,"invasive"):Treatment-1|Pop/Mom))
>
>     Random effects:
>     Groups       Name Variance           Std.Dev.           Corr
>     Mom:Pop  at.level(Range, "invasive"):TreatmentControl         
> 1.1326e+01 3.3654e+00
>                     at.level(Range, "invasive"):TreatmentHerbivory   
> 9.1458e-01     9.5633e-01        0.292
>     Mom:Pop  at.level(Range, "native"):TreatmentControl            
> 1.1868e+01 3.4451e+00
>                     at.level(Range, "native"):Trea     1.3415e+00       0.396
>     Pop          at.level(Range, "invasive"):TreatmentControl         
>  1.1083e-09 3.3291e-05
>                     at.level(Range, "invasive"):TreatmentHerbivory   
> 2.9827e-01      5.4614e-01        0.000
>     Pop          at.level(Range, "native"):TreatmentControl   
> 5.5788e+00      2.3619e+00
>                     at.level(Range, "native"):TreatmentHerbivory   
> 1.5701e+00     1.2530e+00        0.839
>     Residual 1.1545e+00     1.0745e+00
>     Number of obs: 368, groups: Mom:Pop, 184; Pop, are now 'logical'  
>  as I get zero-values for populations/moms that do not occur in a   
> given range.
>
>     The question remains though, whether I should additionnally   
> account for heterogeneity in the innermost residuals (like 'weights'  
>  in lme), and if so, how I should implement that in lmer.
>
>     Thanks again for your precious help; thanks to you, I've just   
> made a big step today....
>
>     Best,
>
>     Alessia
>
>
>     *************************************************************
>     Alessia Guggisberg, PhD
>     Postdoctoral Fellow
>     Department of Botany
>     University of British Columbia
>     3529-6270 University Boulevard
>     Vancouver, BC, V6T 1Z4
>     Canada
>
>     Email: alessiag at interchange.ubc.ca
>
>     *************************************************************
>     ----- Original Message ----- From: "Jarrod Hadfield"   
> <j.hadfield at ed.ac.uk>
>     To: "Alessia Guggisberg" <r-sig-mixed-models at r-project.org>
>     Sent: Thursday, April 08, 2010 2:22 AM
>     Subject: Re: [R-sig-ME] variance structure in lme/lmer
>
>
>
>       Dear Alessia,
>
>
>
>       I think the problem is that  individuals from a population all  
>  belong  to one type (native or invasive) (is this true?) If this is  
>  the case  your 4x4 covariance matrices needs to look like
>
>
>
>              TreatmentControl:Rangenative   *  *  0  0
>
>          TreatmentHerbivory:Rangenative   *  *  0  0
>
>       TreatmentHerbivory:Rangeinvasive   0  0  *  *
>       TreatmentHerbivory:Rangeinvasive   0  0  *  *
>
>
>
>       where * indicates it could be estimated and 0 not.
>
>
>
>       To fit such a covariance matrix  try
>
>
>
>       (at.level(Range, "native"):Treatment-1|Pop)+(at.level(Range,   
> "invasive"):Treatment-1|Pop)
>
>
>
>       in lmer.  The at.level function is at the bottom of the email
>
>
>
>       If individuals with the same mother have the same treatment   
> then the pop/mom matrix needs to be
>
>
>
>
>
>             &nb native   *  0  0  0
>
>          TreatmentHerbivory:Rangenative   0  *  0  0
>
>       TreatmentHerbivory:Rangeinvasive   0  0  *  0
>
>       TreatmentHerbivory:Rangeinvasive   0  0  0  *
>
>
>
>       and you can use either
>
>
>
>       (at.level(Range, "native"):at.level(Treatment, "Herbivory")-1|  
>  Pop:mom)+(at.level(Range, "invasive"):at.level(Treatment,   
> "Herbivory")-1|Pop:mom)+(at.level(Range,   
> "native"):at.level(Treatment, "Control")-1|Pop:mom)+(at.level(Range,  
>  "invasive"):at.level(Treatment, Control")-1|Pop:mom)
>
>
>
>       or
>
>
>       (at.level(subgroup, 1)|Pop:mom)+ (at.level(subgroup,   
> 2)|Pop:mom) + (at.level(subgroup, 3)|Pop:mom) + (at.level(subgroup,   
> 4)|Pop:mom)
>
>
>
>       I'm not sure if you can use this type of syntax in lme, but   
> without allowing different residual variances for the subgroups I   
> would be  very cautious about the results.
>
>
>
>       Cheers,
>
>
>
>       Jarrod
>
>
>
>
>
>
>
>       at.level<-function (x, level)
>
>       {
>
>          if (is.numeric(level)) {
>
>              M <- outer(x, lev /blockquote>
>            }
>
>            else {
>
>                M <- outer(x, level, "==")
>
>            }
>
>            mode(M) <- "numeric"
>
>            M
>
>         }
>
>         <environment: namespace:MCMCglmm>
>
>
>
>
>
>
>
>         On 8 Apr 2010, at 06:50, Alessia Guggisberg wrote:
>
>
>
>           Dear R-sig-mixed-models list members
>
>
>           <
>               I apologise in advance, if my question seems trivial;   
> I'm new to mixed-models in R.
>
>
>
>               To make things easier, I'm giving you an example,   
> followed by the questions I'm hoping to be able to address with one   
> of you.
>
>
>
>               Study: Response of different populations of plants   
> from two  different ranges (Europe vs. North America) to various   
> stresses in a  greenhouse experiment
>
>               Study question: Do populations from the native range   
> (Europe) differ  in terms of response from the ones of the   
> introduced range (North  America)?
>
>           Type of data: Growth and reproductive data
>
>           Example of mixed model: above-ground biomass as a function  
>  of  treatment (control vs. stress), range (Europe vs. North  
> America)  and  a covariate (in this case, longest leaf length at t0,  
> to  account for  size difference prior to stress)
>
>
>
>           model=lme(above~Treatment * Range * t0.LLL, random= ~1|Pop/Mom)
>
>
>
>           model=lmer(above~Treatment * Range * t0.LLL + (1|Pop/Mom))
>
>
>
>           Due to the introduct I expect less genetic variation in   
> the introduced than in the native range, hence less variation in   
> response in the introduced than native range. Indeed, inspection of   
> raw data and residuals indicate higher variance for  native than   
> introduced range. Similarly, I observe less variation in  response   
> in the stress than in the control plot. Obviously, these    
> observations suggest violation of homoscedasticity. I therefore    
> would like to test and eventually account for difference in    
> variances between the different subgroups: (i) Europe-control, (ii)   
>  Europe-stress, (iii) North America-control, (iv) North  
> America-stress.
>
>
>
>           Following options are possible:
>
>
>
>           - ticity in the innermost residuals:
>
>
>
>           model=lme(above~Treatment * Range * t0.LLL, random=   
> ~1|Pop/Mom, weights=varIdent(form=~1|Treatment*Range))
>
>
>
>           Random effects:
>
>           Formula: ~1 | Pop
>
>                         (Intercept)
>
>           StdDev:     0.997503
>
>
>
>                         (Intercept)     Residual
>
>           StdDev:     1.150242      3.684324
>
>
>
>           Variance function:
>
>           Structure: Different standard deviations per stratum
>
>           Formula: ~1 | Treatment * Range
>
>           Parameter estimates:
>
>             Control*native &nbs   Control*invasive Herbivory*invasive
>
>             1.0000000        0.3343747           0.9324055            
>  0.2389115
>
>
>
>           Is it true, that weights cannot be incorporated in lmer?
>
>
>
>           - stratify the variance for the random effects:
>
>
>
>           subgroup=factor(Treatment:Range)
>
>         ## warning message: Fewer observations than random effects   
> in all  level 2 groups
>
>
>
>         model=lmer(above~Treatment * Range * t0.LLL + (0 + subgroup|Pop/Mom))
>
>
>
>         Random effects:
>
>         Groups       Name                                         Va te>
>           Mom:Pop    TreatmentControl:Rangenative      11.783704        0.000
>
>                            TreatmentHerbivory:Rangenative   1.714778  
>  0.419    0.000
>
>                            TreatmentControl:Rangeinvasive 378         
>   -0.003    0.311        -0.001
>
>                            Treatm e 0.819599
>
>           Pop            TreatmentControl:Rangenative       5.578492
>
>                            TreatmentHerbivory:Rangenative    1.569965 1.000
>
>                            TreatmentControl:Rangeinvasive       
> 0.029164 0.839     0.839
>
>                            TreatmentHerbivory:Rangeinvasive    
> 0.315794 1.000  &n sp;      0.839
>
>           Residual                                                    
>        1.239337
>
>           Number of obs: 368, groups: Mom:Pop, 184; Pop, 42
>
>
>
>           Why do I get an error message, when I run the model in lme?
>
>
>
>           - another option found in e each subgroup  with a dummy   
> variable, as follows (I only know how to implement that  method with  
>  lmer):
>
>
>
>           nativeControl=as.numeric(factor(Range=="native" &    
> Treatment=="Control"))
>
>           invasiveControl=as.numeric(factor(Range=="invasive" &   
> Treatment=="Control"))
>
>           nativeHerbivory=as.numeric(factor(Range=="native" &   
> Treatment=="Herbivory"))
>
>           invasiveHerbivory=as.numeric(factor(Range=="invasive" &   
> Treatment=="Herbivory"))
>
>           model=lmer(above~Treatment*Range*t0.LLL + (0 +   
> nativeControl|Pop/ Mom) + (0 + invasiveCon veHerbivory|Pop/Mom)  +   
> (0 + invasiveHerbivory|Pop/Mom))
>
>
>
>           Random effects:
>
>           Groups       Name                   Variance
>
>           Mom:Pop   invasiveHerbivory    0.0000e+00
>
>           Mom:Pop   nativeHerbivory      0.0000e+00
>
>           Mom:Pop   invasiveControl       9.7939e-01
>
>           Pop          invasiveHerbivory    0.0000e+00
>
>           Pop          nativeHerbivory      2.4815e-10
>
>           Pop          invasiveControl      1.7994e-09
>
>           Pop          nativeControl         9.1133e-01
>
>           Residual          &nbs ;                 4.1959e+00
>
>           Number of obs: 368, groups: Mom:Pop, 184; Pop, 42
>
>
>
>           This last model entails less parameters than the previous   
> one  (because it doesn't calculate any correlations), but its AIC is  
>  also  much higher. Other than that, what differs between the two   
> previous  models?
>
>
>
>           In view of my problematic, what do you suggest me to do?
>
>
>
>           I thank yo you might be able to provide and look forward   
> to receiving your recommendations.
>
>
>
>           Best,
>
>
>
>           Alessia
>
>
>
>           *************************************************************
>
>           Alessia Guggisberg, PhD
>
>           Postdoctoral Fellow
>
>           Department of Botany
>
>           Un bia
>
>           3529-6270 University Boulevard
>
>           Vancouver, BC, V6T 1Z4
>
>           Canada
>
>
>
>           Email: alessiag at interchange.ubc.ca
>
>
>
>           *************************************************************
>
>           [[alternative HTML version deleted]]
>
>
>
>         < _____________________________________________
>
>         R-sig-mixed-models at r-project.org mailing list
>
>         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
>
>
>
>
>       --
>
>       The University of Edinburgh is a charitable body, registered in
>
>       Scotland, with registration number SC005336.
>
>
>
>
>
>
>
>
> ------------------------------------------------------------------------------
>
>
>   The University of Edinburgh is a charitable body, registered in
>   Scotland, with registration number SC005336.
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From izod3 at yahoo.com  Mon Apr 12 01:20:51 2010
From: izod3 at yahoo.com (Wkoef Slknfd)
Date: Sun, 11 Apr 2010 16:20:51 -0700 (PDT)
Subject: [R-sig-ME] one question about Error in asMethod(object) : matrix is
	not symmetric [1, 2]
Message-ID: <633033.12947.qm@web113720.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100411/b5740b2a/attachment.pl>

From kevin.thorpe at utoronto.ca  Mon Apr 12 15:00:58 2010
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Mon, 12 Apr 2010 09:00:58 -0400
Subject: [R-sig-ME] Another case of -1.0 correlation of random effects
In-Reply-To: <4BBF69E3.3050308@utoronto.ca>
References: <4BBF0986.70309@utoronto.ca>	<loom.20100409T143920-273@post.gmane.org>	<4BBF2584.10609@ufl.edu>
	<4BBF69E3.3050308@utoronto.ca>
Message-ID: <4BC3198A.6070408@utoronto.ca>

Kevin E. Thorpe wrote:
> Ben Bolker wrote:
>> Ken Knoblauch wrote:
>>> Kevin E. Thorpe <kevin.thorpe at ...> writes:
>>>
>>>> My data come from a crossover trial and are balanced.
>>>>
>>>>  > str(gluc)
>>>> 'data.frame':    96 obs. of  4 variables:
>>>>   $ Subject  : int  1 2 3 5 6 7 10 11 12 13 ...
>>>>   $ Treatment: Factor w/ 2 levels "Barley","Oat": 1 1 1 1 1 1 1 1 1 
>>>> 1 ...
>>>>   $ Dose     : int  8 8 8 8 8 8 8 8 8 8 ...
>>>>   $ iAUC     : num  110 256 129 207 244 ...
>>>>
>>>> clip>
>>> Shouldn't you make Subject into a factor?
>>>
>>> Ken
>>>
>>
>>   It would make the plot a little bit prettier but I don't think it
>> matters in this case because variable that appears as a grouping
>> variable (i.e. on the right of the | ) is automatically treated as a
>> factor?  I think?
>>
>>   Since it is really a crossover trial, it would seem reasonable in
>> principle to have the (Treatment|Subject) random effect in there as
>> well. I'm not sure what to do about the -1 correlation: it seems the
>> choices (not necessarily in order) are (1) throw up your hands and say
>> there's not enough data to estimate independently; (2) try WinBUGS,
>> possibly with slightly informative priors; (3) try using lme4a to create
>> profiles of the parameters and see if you can figure out what's 
>> happening.
> 
> Let's see.  I wish (1) was an option.  (2) would be promising if my 
> knowledge of BUGS and Bayesian methods filled more than a thimble. 
> Thanks to Jarrod for his suggestion in response to this.  I'll take a 
> look at that too.  Option (3) is probably worth a go too.
> 
> Aside from the fact that the Dose variable are the actual doses and not 
> categories, and we all know not to categorize continuous variables, what 
> are your thoughts on treating Dose as a factor (since it seems to behave)?
> 
> Thanks all for taking the time to provide your suggestions.
> 
> Kevin
> 

Regarding lme4a: how do I obtain it?  I guess that comes down to, what 
is the repository to give to install.packages()?  Does it require a 
different Matrix package than the one I have, which is, 0.999375-33 and 
if so, how do I not break my current lme4/Matrix combination?

By the way, the problems with these data get stranger.  In a different 
outcome from the same trial the following results from a model fitting 
attempt.

lmer(iAUC~Treatment+Dose+(Treatment|Subject)+(Dose|Subject),data=insulin)
Linear mixed model fit by REML
Formula: iAUC ~ Treatment + Dose + (Treatment | Subject) + (Dose | Subject)
    Data: insulin
   AIC  BIC logLik deviance REMLdev
  1956 1982   -968     1983    1936
Random effects:
  Groups   Name         Variance   Std.Dev.   Corr
  Subject  (Intercept)  4.2678e-02 2.0659e-01
           TreatmentOat 1.6115e+07 4.0144e+03 0.000
  Subject  (Intercept)  3.0430e+08 1.7444e+04
           Dose         1.5173e+06 1.2318e+03 -1.000
  Residual              3.1907e+07 5.6486e+03
Number of obs: 96, groups: Subject, 12

Fixed effects:
              Estimate Std. Error t value
(Intercept)   40142.4     5146.7   7.800
TreatmentOat   1340.3     1634.7   0.820
Dose          -2675.1      405.5  -6.597

Correlation of Fixed Effects:
             (Intr) TrtmnO
TreatmentOt -0.079
Dose        -0.922  0.000

As you can see, I get a 0 correlation within one set of random effects 
and -1.0 in the other.  Also, the fact the fixed effects estimates are 
huge makes me suspicious.

Note that if I drop the treatment portions and fit the Dose model to 
only one treatment, the correlation is again -1.0 and the fixed effects 
are similar.


-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016



From bates at stat.wisc.edu  Mon Apr 12 15:17:43 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 12 Apr 2010 08:17:43 -0500
Subject: [R-sig-ME] Another case of -1.0 correlation of random effects
In-Reply-To: <4BC3198A.6070408@utoronto.ca>
References: <4BBF0986.70309@utoronto.ca>
	<loom.20100409T143920-273@post.gmane.org> <4BBF2584.10609@ufl.edu>
	<4BBF69E3.3050308@utoronto.ca> <4BC3198A.6070408@utoronto.ca>
Message-ID: <v2u40e66e0b1004120617pe772b870se58090a6d6639f7f@mail.gmail.com>

On Mon, Apr 12, 2010 at 8:00 AM, Kevin E. Thorpe
<kevin.thorpe at utoronto.ca> wrote:
> Kevin E. Thorpe wrote:
>>
>> Ben Bolker wrote:
>>>
>>> Ken Knoblauch wrote:
>>>>
>>>> Kevin E. Thorpe <kevin.thorpe at ...> writes:
>>>>
>>>>> My data come from a crossover trial and are balanced.
>>>>>
>>>>> ?> str(gluc)
>>>>> 'data.frame': ? ?96 obs. of ?4 variables:
>>>>> ?$ Subject ?: int ?1 2 3 5 6 7 10 11 12 13 ...
>>>>> ?$ Treatment: Factor w/ 2 levels "Barley","Oat": 1 1 1 1 1 1 1 1 1 1
>>>>> ...
>>>>> ?$ Dose ? ? : int ?8 8 8 8 8 8 8 8 8 8 ...
>>>>> ?$ iAUC ? ? : num ?110 256 129 207 244 ...
>>>>>
>>>>> clip>
>>>>
>>>> Shouldn't you make Subject into a factor?
>>>>
>>>> Ken
>>>>
>>>
>>> ?It would make the plot a little bit prettier but I don't think it
>>> matters in this case because variable that appears as a grouping
>>> variable (i.e. on the right of the | ) is automatically treated as a
>>> factor? ?I think?
>>>
>>> ?Since it is really a crossover trial, it would seem reasonable in
>>> principle to have the (Treatment|Subject) random effect in there as
>>> well. I'm not sure what to do about the -1 correlation: it seems the
>>> choices (not necessarily in order) are (1) throw up your hands and say
>>> there's not enough data to estimate independently; (2) try WinBUGS,
>>> possibly with slightly informative priors; (3) try using lme4a to create
>>> profiles of the parameters and see if you can figure out what's
>>> happening.
>>
>> Let's see. ?I wish (1) was an option. ?(2) would be promising if my
>> knowledge of BUGS and Bayesian methods filled more than a thimble. Thanks to
>> Jarrod for his suggestion in response to this. ?I'll take a look at that
>> too. ?Option (3) is probably worth a go too.
>>
>> Aside from the fact that the Dose variable are the actual doses and not
>> categories, and we all know not to categorize continuous variables, what are
>> your thoughts on treating Dose as a factor (since it seems to behave)?
>>
>> Thanks all for taking the time to provide your suggestions.
>>
>> Kevin
>>
>
> Regarding lme4a: how do I obtain it? ?I guess that comes down to, what is
> the repository to give to install.packages()? ?Does it require a different
> Matrix package than the one I have, which is, 0.999375-33 and if so, how do
> I not break my current lme4/Matrix combination?

The repository is http://R-forge.R-project.org but be aware that lme4a
is under active development and not guaranteed against breakage.  It
would be inadvisable to rely on functions and classes in that package
to persist.

> By the way, the problems with these data get stranger. ?In a different
> outcome from the same trial the following results from a model fitting
> attempt.
>
> lmer(iAUC~Treatment+Dose+(Treatment|Subject)+(Dose|Subject),data=insulin)
> Linear mixed model fit by REML
> Formula: iAUC ~ Treatment + Dose + (Treatment | Subject) + (Dose | Subject)
> ? Data: insulin
> ?AIC ?BIC logLik deviance REMLdev
> ?1956 1982 ? -968 ? ? 1983 ? ?1936
> Random effects:
> ?Groups ? Name ? ? ? ? Variance ? Std.Dev. ? Corr
> ?Subject ?(Intercept) ?4.2678e-02 2.0659e-01
> ? ? ? ? ?TreatmentOat 1.6115e+07 4.0144e+03 0.000
> ?Subject ?(Intercept) ?3.0430e+08 1.7444e+04
> ? ? ? ? ?Dose ? ? ? ? 1.5173e+06 1.2318e+03 -1.000

And did you notice that you have an Intercept term by Subject in there
twice?  It is not surprising that the parameter estimates are
unstable.  You will need to rethink the model.

> ?Residual ? ? ? ? ? ? ?3.1907e+07 5.6486e+03
> Number of obs: 96, groups: Subject, 12
>
> Fixed effects:
> ? ? ? ? ? ? Estimate Std. Error t value
> (Intercept) ? 40142.4 ? ? 5146.7 ? 7.800
> TreatmentOat ? 1340.3 ? ? 1634.7 ? 0.820
> Dose ? ? ? ? ?-2675.1 ? ? ?405.5 ?-6.597
>
> Correlation of Fixed Effects:
> ? ? ? ? ? ?(Intr) TrtmnO
> TreatmentOt -0.079
> Dose ? ? ? ?-0.922 ?0.000
>
> As you can see, I get a 0 correlation within one set of random effects and
> -1.0 in the other. ?Also, the fact the fixed effects estimates are huge
> makes me suspicious.
>
> Note that if I drop the treatment portions and fit the Dose model to only
> one treatment, the correlation is again -1.0 and the fixed effects are
> similar.
>
>
> --
> Kevin E. Thorpe
> Biostatistician/Trialist, Knowledge Translation Program
> Assistant Professor, Dalla Lana School of Public Health
> University of Toronto
> email: kevin.thorpe at utoronto.ca ?Tel: 416.864.5776 ?Fax: 416.864.3016
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From kevin.thorpe at utoronto.ca  Mon Apr 12 15:22:39 2010
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Mon, 12 Apr 2010 09:22:39 -0400
Subject: [R-sig-ME] Another case of -1.0 correlation of random effects
In-Reply-To: <v2u40e66e0b1004120617pe772b870se58090a6d6639f7f@mail.gmail.com>
References: <4BBF0986.70309@utoronto.ca>	
	<loom.20100409T143920-273@post.gmane.org>
	<4BBF2584.10609@ufl.edu>	 <4BBF69E3.3050308@utoronto.ca>
	<4BC3198A.6070408@utoronto.ca>
	<v2u40e66e0b1004120617pe772b870se58090a6d6639f7f@mail.gmail.com>
Message-ID: <4BC31E9F.1000604@utoronto.ca>

Douglas Bates wrote:
> On Mon, Apr 12, 2010 at 8:00 AM, Kevin E. Thorpe
> <kevin.thorpe at utoronto.ca> wrote:
>> Kevin E. Thorpe wrote:
>>> Ben Bolker wrote:
>>>> Ken Knoblauch wrote:
>>>>> Kevin E. Thorpe <kevin.thorpe at ...> writes:
>>>>>
>>>>>> My data come from a crossover trial and are balanced.
>>>>>>
>>>>>>  > str(gluc)
>>>>>> 'data.frame':    96 obs. of  4 variables:
>>>>>>  $ Subject  : int  1 2 3 5 6 7 10 11 12 13 ...
>>>>>>  $ Treatment: Factor w/ 2 levels "Barley","Oat": 1 1 1 1 1 1 1 1 1 1
>>>>>> ...
>>>>>>  $ Dose     : int  8 8 8 8 8 8 8 8 8 8 ...
>>>>>>  $ iAUC     : num  110 256 129 207 244 ...
>>>>>>
>>>>>> clip>
>>>>> Shouldn't you make Subject into a factor?
>>>>>
>>>>> Ken
>>>>>
>>>>  It would make the plot a little bit prettier but I don't think it
>>>> matters in this case because variable that appears as a grouping
>>>> variable (i.e. on the right of the | ) is automatically treated as a
>>>> factor?  I think?
>>>>
>>>>  Since it is really a crossover trial, it would seem reasonable in
>>>> principle to have the (Treatment|Subject) random effect in there as
>>>> well. I'm not sure what to do about the -1 correlation: it seems the
>>>> choices (not necessarily in order) are (1) throw up your hands and say
>>>> there's not enough data to estimate independently; (2) try WinBUGS,
>>>> possibly with slightly informative priors; (3) try using lme4a to create
>>>> profiles of the parameters and see if you can figure out what's
>>>> happening.
>>> Let's see.  I wish (1) was an option.  (2) would be promising if my
>>> knowledge of BUGS and Bayesian methods filled more than a thimble. Thanks to
>>> Jarrod for his suggestion in response to this.  I'll take a look at that
>>> too.  Option (3) is probably worth a go too.
>>>
>>> Aside from the fact that the Dose variable are the actual doses and not
>>> categories, and we all know not to categorize continuous variables, what are
>>> your thoughts on treating Dose as a factor (since it seems to behave)?
>>>
>>> Thanks all for taking the time to provide your suggestions.
>>>
>>> Kevin
>>>
>> Regarding lme4a: how do I obtain it?  I guess that comes down to, what is
>> the repository to give to install.packages()?  Does it require a different
>> Matrix package than the one I have, which is, 0.999375-33 and if so, how do
>> I not break my current lme4/Matrix combination?
> 
> The repository is http://R-forge.R-project.org but be aware that lme4a
> is under active development and not guaranteed against breakage.  It
> would be inadvisable to rely on functions and classes in that package
> to persist.
> 
>> By the way, the problems with these data get stranger.  In a different
>> outcome from the same trial the following results from a model fitting
>> attempt.
>>
>> lmer(iAUC~Treatment+Dose+(Treatment|Subject)+(Dose|Subject),data=insulin)
>> Linear mixed model fit by REML
>> Formula: iAUC ~ Treatment + Dose + (Treatment | Subject) + (Dose | Subject)
>>   Data: insulin
>>  AIC  BIC logLik deviance REMLdev
>>  1956 1982   -968     1983    1936
>> Random effects:
>>  Groups   Name         Variance   Std.Dev.   Corr
>>  Subject  (Intercept)  4.2678e-02 2.0659e-01
>>          TreatmentOat 1.6115e+07 4.0144e+03 0.000
>>  Subject  (Intercept)  3.0430e+08 1.7444e+04
>>          Dose         1.5173e+06 1.2318e+03 -1.000
> 
> And did you notice that you have an Intercept term by Subject in there
> twice?  It is not surprising that the parameter estimates are
> unstable.  You will need to rethink the model.

Thanks Doug.  Any suggestions?  Note that the instability is present 
without the random effects for treatment in the model too.

> 
>>  Residual              3.1907e+07 5.6486e+03
>> Number of obs: 96, groups: Subject, 12
>>
>> Fixed effects:
>>             Estimate Std. Error t value
>> (Intercept)   40142.4     5146.7   7.800
>> TreatmentOat   1340.3     1634.7   0.820
>> Dose          -2675.1      405.5  -6.597
>>
>> Correlation of Fixed Effects:
>>            (Intr) TrtmnO
>> TreatmentOt -0.079
>> Dose        -0.922  0.000
>>
>> As you can see, I get a 0 correlation within one set of random effects and
>> -1.0 in the other.  Also, the fact the fixed effects estimates are huge
>> makes me suspicious.
>>
>> Note that if I drop the treatment portions and fit the Dose model to only
>> one treatment, the correlation is again -1.0 and the fixed effects are
>> similar.
>>
>>


-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016



From Wolfgang.Viechtbauer at STAT.unimaas.nl  Mon Apr 12 15:51:22 2010
From: Wolfgang.Viechtbauer at STAT.unimaas.nl (Viechtbauer Wolfgang (STAT))
Date: Mon, 12 Apr 2010 15:51:22 +0200
Subject: [R-sig-ME] Another case of -1.0 correlation of random effects
In-Reply-To: <4BC31E9F.1000604@utoronto.ca>
Message-ID: <077E31A57DA26E46AB0D493C9966AC7308663A8E42@UM-MAIL4112.unimaas.nl>

Dear Kevin,

I am curious to see what happens if you fit the same model with lme and if you play around with the optimizer used. Also, try changing the definition of the intercept. In particular:

library(nlme)
res <- lme(iAUC~Treatment+Dose, random=~Dose|Subject, data=insulin)
summary(res)

res <- lme(iAUC~Treatment+Dose, random=~Dose|Subject, data=insulin,
           control=list(msVerbose=T, opt="nlm"))
summary(res)

insulin$Dose <- insulin$Dose - 8

res <- lme(iAUC~Treatment+Dose, random=~Dose|Subject, data=insulin)
summary(res)

res <- lme(iAUC~Treatment+Dose, random=~Dose|Subject, data=insulin,
           control=list(msVerbose=T, opt="nlm"))
summary(res)

Best,

--
Wolfgang Viechtbauer                        http://www.wvbauer.com/
Department of Methodology and Statistics    Tel: +31 (43) 388-2277
School for Public Health and Primary Care   Office Location:
Maastricht University, P.O. Box 616         Room B2.01 (second floor)
6200 MD Maastricht, The Netherlands         Debyeplein 1 (Randwyck)


----Original Message----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Kevin E.
Thorpe Sent: Monday, April 12, 2010 15:23 To: Douglas Bates
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Another case of -1.0 correlation of random
effects

> Douglas Bates wrote:
>> On Mon, Apr 12, 2010 at 8:00 AM, Kevin E. Thorpe
>> <kevin.thorpe at utoronto.ca> wrote:
>>> Kevin E. Thorpe wrote:
>>>> Ben Bolker wrote:
>>>>> Ken Knoblauch wrote:
>>>>>> Kevin E. Thorpe <kevin.thorpe at ...> writes:
>>>>>>
>>>>>>> My data come from a crossover trial and are balanced.
>>>>>>>
>>>>>>>  > str(gluc)
>>>>>>> 'data.frame':    96 obs. of  4 variables:
>>>>>>>  $ Subject  : int  1 2 3 5 6 7 10 11 12 13 ...
>>>>>>>  $ Treatment: Factor w/ 2 levels "Barley","Oat": 1 1 1 1 1 1 1
>>>>>>>  1 1 1 ... $ Dose     : int  8 8 8 8 8 8 8 8 8 8 ...
>>>>>>>  $ iAUC     : num  110 256 129 207 244 ...
>>>>>>>
>>>>>>> clip>
>>>>>> Shouldn't you make Subject into a factor?
>>>>>>
>>>>>> Ken
>>>>>>
>>>>>  It would make the plot a little bit prettier but I don't think it
>>>>> matters in this case because variable that appears as a grouping
>>>>> variable (i.e. on the right of the | ) is automatically treated
>>>>> as a factor?  I think?
>>>>>
>>>>>  Since it is really a crossover trial, it would seem reasonable in
>>>>> principle to have the (Treatment|Subject) random effect in there
>>>>> as well. I'm not sure what to do about the -1 correlation: it
>>>>> seems the choices (not necessarily in order) are (1) throw up
>>>>> your hands and say there's not enough data to estimate
>>>>> independently; (2) try WinBUGS, possibly with slightly
>>>>> informative priors; (3) try using lme4a to create profiles of the
>>>>> parameters and see if you can figure out what's happening.
>>>> Let's see.  I wish (1) was an option.  (2) would be promising if my
>>>> knowledge of BUGS and Bayesian methods filled more than a thimble.
>>>> Thanks to Jarrod for his suggestion in response to this.  I'll take
>>>> a look at that too.  Option (3) is probably worth a go too.
>>>>
>>>> Aside from the fact that the Dose variable are the actual doses and
>>>> not categories, and we all know not to categorize continuous
>>>> variables, what are your thoughts on treating Dose as a factor
>>>> (since it seems to behave)?
>>>>
>>>> Thanks all for taking the time to provide your suggestions.
>>>>
>>>> Kevin
>>>>
>>> Regarding lme4a: how do I obtain it?  I guess that comes down to,
>>> what is the repository to give to install.packages()?  Does it
>>> require a different Matrix package than the one I have, which is,
>>> 0.999375-33 and if so, how do I not break my current lme4/Matrix
>>> combination?
>>
>> The repository is http://R-forge.R-project.org but be aware that
>> lme4a is under active development and not guaranteed against
>> breakage.  It would be inadvisable to rely on functions and classes
>> in that package to persist.
>>
>>> By the way, the problems with these data get stranger.  In a
>>> different outcome from the same trial the following results from a
>>> model fitting attempt.
>>>
>>> lmer(iAUC~Treatment+Dose+(Treatment|Subject)+(Dose|Subject),data=insu
>>> lin)
>>> Linear mixed model fit by REML
>>> Formula: iAUC ~ Treatment + Dose + (Treatment | Subject) + (Dose |
>>>  Subject)   Data: insulin AIC  BIC logLik deviance REMLdev
>>>  1956 1982   -968     1983    1936
>>> Random effects:
>>>  Groups   Name         Variance   Std.Dev.   Corr
>>>  Subject  (Intercept)  4.2678e-02 2.0659e-01
>>>          TreatmentOat 1.6115e+07 4.0144e+03 0.000
>>>  Subject  (Intercept)  3.0430e+08 1.7444e+04
>>>          Dose         1.5173e+06 1.2318e+03 -1.000
>>
>> And did you notice that you have an Intercept term by Subject in
>> there twice?  It is not surprising that the parameter estimates are
>> unstable.  You will need to rethink the model.
>
> Thanks Doug.  Any suggestions?  Note that the instability is present
> without the random effects for treatment in the model too.
>
>>
>>>  Residual              3.1907e+07 5.6486e+03
>>> Number of obs: 96, groups: Subject, 12
>>>
>>> Fixed effects:
>>>             Estimate Std. Error t value
>>> (Intercept)   40142.4     5146.7   7.800
>>> TreatmentOat   1340.3     1634.7   0.820
>>> Dose          -2675.1      405.5  -6.597
>>>
>>> Correlation of Fixed Effects:
>>>            (Intr) TrtmnO
>>> TreatmentOt -0.079
>>> Dose        -0.922  0.000
>>>
>>> As you can see, I get a 0 correlation within one set of random
>>> effects and -1.0 in the other.  Also, the fact the fixed effects
>>> estimates are huge makes me suspicious.
>>>
>>> Note that if I drop the treatment portions and fit the Dose model to
>>> only one treatment, the correlation is again -1.0 and the fixed
>>> effects are similar.
>>>
>>>
>
>
> --
> Kevin E. Thorpe
> Biostatistician/Trialist, Knowledge Translation Program Assistant
> Professor, Dalla Lana School of Public Health University of Toronto
> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bates at stat.wisc.edu  Mon Apr 12 16:05:58 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 12 Apr 2010 09:05:58 -0500
Subject: [R-sig-ME] Another case of -1.0 correlation of random effects
In-Reply-To: <077E31A57DA26E46AB0D493C9966AC7308663A8E42@UM-MAIL4112.unimaas.nl>
References: <4BC31E9F.1000604@utoronto.ca>
	<077E31A57DA26E46AB0D493C9966AC7308663A8E42@UM-MAIL4112.unimaas.nl>
Message-ID: <q2p40e66e0b1004120705nfda05c27x7ad4ba683bcfd23e@mail.gmail.com>

lme won't return a correlation of exactly -1 but that is a deficiency
of lme, not lmer.

Mixed-effects software should be able to handle the case of a singular
variance-covariance matrix for the random effects.  Because most
numerical methods, including those in lme, iterate with respect to the
precision matrix (inverse of the variance-covariance matrix) they
usually declare convergence at a non-singular matrix.  That is not an
advantage.  If the MLEs or REML estimates are at a singular covariance
the user should learn this.

On Mon, Apr 12, 2010 at 8:51 AM, Viechtbauer Wolfgang (STAT)
<Wolfgang.Viechtbauer at stat.unimaas.nl> wrote:
> Dear Kevin,
>
> I am curious to see what happens if you fit the same model with lme and if you play around with the optimizer used. Also, try changing the definition of the intercept. In particular:
>
> library(nlme)
> res <- lme(iAUC~Treatment+Dose, random=~Dose|Subject, data=insulin)
> summary(res)
>
> res <- lme(iAUC~Treatment+Dose, random=~Dose|Subject, data=insulin,
> ? ? ? ? ? control=list(msVerbose=T, opt="nlm"))
> summary(res)
>
> insulin$Dose <- insulin$Dose - 8
>
> res <- lme(iAUC~Treatment+Dose, random=~Dose|Subject, data=insulin)
> summary(res)
>
> res <- lme(iAUC~Treatment+Dose, random=~Dose|Subject, data=insulin,
> ? ? ? ? ? control=list(msVerbose=T, opt="nlm"))
> summary(res)
>
> Best,
>
> --
> Wolfgang Viechtbauer ? ? ? ? ? ? ? ? ? ? ? ?http://www.wvbauer.com/
> Department of Methodology and Statistics ? ?Tel: +31 (43) 388-2277
> School for Public Health and Primary Care ? Office Location:
> Maastricht University, P.O. Box 616 ? ? ? ? Room B2.01 (second floor)
> 6200 MD Maastricht, The Netherlands ? ? ? ? Debyeplein 1 (Randwyck)
>
>
> ----Original Message----
> From: r-sig-mixed-models-bounces at r-project.org
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Kevin E.
> Thorpe Sent: Monday, April 12, 2010 15:23 To: Douglas Bates
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Another case of -1.0 correlation of random
> effects
>
>> Douglas Bates wrote:
>>> On Mon, Apr 12, 2010 at 8:00 AM, Kevin E. Thorpe
>>> <kevin.thorpe at utoronto.ca> wrote:
>>>> Kevin E. Thorpe wrote:
>>>>> Ben Bolker wrote:
>>>>>> Ken Knoblauch wrote:
>>>>>>> Kevin E. Thorpe <kevin.thorpe at ...> writes:
>>>>>>>
>>>>>>>> My data come from a crossover trial and are balanced.
>>>>>>>>
>>>>>>>> ?> str(gluc)
>>>>>>>> 'data.frame': ? ?96 obs. of ?4 variables:
>>>>>>>> ?$ Subject ?: int ?1 2 3 5 6 7 10 11 12 13 ...
>>>>>>>> ?$ Treatment: Factor w/ 2 levels "Barley","Oat": 1 1 1 1 1 1 1
>>>>>>>> ?1 1 1 ... $ Dose ? ? : int ?8 8 8 8 8 8 8 8 8 8 ...
>>>>>>>> ?$ iAUC ? ? : num ?110 256 129 207 244 ...
>>>>>>>>
>>>>>>>> clip>
>>>>>>> Shouldn't you make Subject into a factor?
>>>>>>>
>>>>>>> Ken
>>>>>>>
>>>>>> ?It would make the plot a little bit prettier but I don't think it
>>>>>> matters in this case because variable that appears as a grouping
>>>>>> variable (i.e. on the right of the | ) is automatically treated
>>>>>> as a factor? ?I think?
>>>>>>
>>>>>> ?Since it is really a crossover trial, it would seem reasonable in
>>>>>> principle to have the (Treatment|Subject) random effect in there
>>>>>> as well. I'm not sure what to do about the -1 correlation: it
>>>>>> seems the choices (not necessarily in order) are (1) throw up
>>>>>> your hands and say there's not enough data to estimate
>>>>>> independently; (2) try WinBUGS, possibly with slightly
>>>>>> informative priors; (3) try using lme4a to create profiles of the
>>>>>> parameters and see if you can figure out what's happening.
>>>>> Let's see. ?I wish (1) was an option. ?(2) would be promising if my
>>>>> knowledge of BUGS and Bayesian methods filled more than a thimble.
>>>>> Thanks to Jarrod for his suggestion in response to this. ?I'll take
>>>>> a look at that too. ?Option (3) is probably worth a go too.
>>>>>
>>>>> Aside from the fact that the Dose variable are the actual doses and
>>>>> not categories, and we all know not to categorize continuous
>>>>> variables, what are your thoughts on treating Dose as a factor
>>>>> (since it seems to behave)?
>>>>>
>>>>> Thanks all for taking the time to provide your suggestions.
>>>>>
>>>>> Kevin
>>>>>
>>>> Regarding lme4a: how do I obtain it? ?I guess that comes down to,
>>>> what is the repository to give to install.packages()? ?Does it
>>>> require a different Matrix package than the one I have, which is,
>>>> 0.999375-33 and if so, how do I not break my current lme4/Matrix
>>>> combination?
>>>
>>> The repository is http://R-forge.R-project.org but be aware that
>>> lme4a is under active development and not guaranteed against
>>> breakage. ?It would be inadvisable to rely on functions and classes
>>> in that package to persist.
>>>
>>>> By the way, the problems with these data get stranger. ?In a
>>>> different outcome from the same trial the following results from a
>>>> model fitting attempt.
>>>>
>>>> lmer(iAUC~Treatment+Dose+(Treatment|Subject)+(Dose|Subject),data=insu
>>>> lin)
>>>> Linear mixed model fit by REML
>>>> Formula: iAUC ~ Treatment + Dose + (Treatment | Subject) + (Dose |
>>>> ?Subject) ? Data: insulin AIC ?BIC logLik deviance REMLdev
>>>> ?1956 1982 ? -968 ? ? 1983 ? ?1936
>>>> Random effects:
>>>> ?Groups ? Name ? ? ? ? Variance ? Std.Dev. ? Corr
>>>> ?Subject ?(Intercept) ?4.2678e-02 2.0659e-01
>>>> ? ? ? ? ?TreatmentOat 1.6115e+07 4.0144e+03 0.000
>>>> ?Subject ?(Intercept) ?3.0430e+08 1.7444e+04
>>>> ? ? ? ? ?Dose ? ? ? ? 1.5173e+06 1.2318e+03 -1.000
>>>
>>> And did you notice that you have an Intercept term by Subject in
>>> there twice? ?It is not surprising that the parameter estimates are
>>> unstable. ?You will need to rethink the model.
>>
>> Thanks Doug. ?Any suggestions? ?Note that the instability is present
>> without the random effects for treatment in the model too.
>>
>>>
>>>> ?Residual ? ? ? ? ? ? ?3.1907e+07 5.6486e+03
>>>> Number of obs: 96, groups: Subject, 12
>>>>
>>>> Fixed effects:
>>>> ? ? ? ? ? ? Estimate Std. Error t value
>>>> (Intercept) ? 40142.4 ? ? 5146.7 ? 7.800
>>>> TreatmentOat ? 1340.3 ? ? 1634.7 ? 0.820
>>>> Dose ? ? ? ? ?-2675.1 ? ? ?405.5 ?-6.597
>>>>
>>>> Correlation of Fixed Effects:
>>>> ? ? ? ? ? ?(Intr) TrtmnO
>>>> TreatmentOt -0.079
>>>> Dose ? ? ? ?-0.922 ?0.000
>>>>
>>>> As you can see, I get a 0 correlation within one set of random
>>>> effects and -1.0 in the other. ?Also, the fact the fixed effects
>>>> estimates are huge makes me suspicious.
>>>>
>>>> Note that if I drop the treatment portions and fit the Dose model to
>>>> only one treatment, the correlation is again -1.0 and the fixed
>>>> effects are similar.
>>>>
>>>>
>>
>>
>> --
>> Kevin E. Thorpe
>> Biostatistician/Trialist, Knowledge Translation Program Assistant
>> Professor, Dalla Lana School of Public Health University of Toronto
>> email: kevin.thorpe at utoronto.ca ?Tel: 416.864.5776 ?Fax: 416.864.3016
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From Thierry.ONKELINX at inbo.be  Tue Apr 13 10:24:30 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 13 Apr 2010 10:24:30 +0200
Subject: [R-sig-ME] [R] glmer with non integer weights
In-Reply-To: <1271081497939-1837179.post@n4.nabble.com>
References: <1271081497939-1837179.post@n4.nabble.com>
Message-ID: <2E9C414912813E4EB981326983E0A104071B6EE3@inboexch.inbo.be>

Dear Kay,

There is a R list about mixed models. Which is a better place for your
questions.

The (quasi)binomial family is used with binary data or a ratio that
originates from binary data. In case of a ratio you need to provide the
number of trials through the weights argument.

Further I would suggest to drop stage from either the random effects or
the fixed effects. You are trying to estimate the same effect twice in a
model.

HTH,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] Namens Kay Cichini
> Verzonden: maandag 12 april 2010 16:12
> Aan: r-help at r-project.org
> Onderwerp: [R] glmer with non integer weights
> 
> 
> hello,
> 
> i'd appreciate help with my glmer.
> i have a dependent which is an index (MH.index) ranging from 
> 0-1. this index can also be considered as a propability. as i 
> have a fixed factor (stage) and a nested random factor (site) 
> i tried to model with glmer. i read that it's possible to use 
> a quasibinomial distribution, for this kind of data, which i 
> than actually did - but firstly 
> 
> (1) i'm not quite sure if that's appropiate for my data, secondly
> (2) i wondered if the model can be correct when variance of 
> then main and nested factor are zero.
> (3) also i could not yield p-values for that model.
> 
> here's data, call and output:
> 
> ##########################################################
> #call:
> ##########################################################
> 
> glmer(MH~stage+(1|stage/site),family=quasibinomial)
> 
> ##########################################################
> #output:
> ##########################################################
> #Generalized linear mixed model fit by the Laplace approximation
> #Formula: MH ~ stage + (1 | stage/site) 
> #  AIC   BIC logLik deviance
> # 66.03 86.47 -26.01    52.03
> #Random effects:
> # Groups     Name        Variance Std.Dev.
> # site:stage (Intercept) 0.000000 0.000   
> # stage      (Intercept) 0.000000 0.000   
> # Residual               0.076175 0.276   
> # Number of obs: 137, groups: site:stage, 39; stage, 4
> 
> #Fixed effects:
> #            Estimate Std. Error t value
> #(Intercept)  0.39205    0.09009   4.352
> #stageB      -0.87214    0.12498  -6.978
> #stageC      -0.36153    0.12202  -2.963
> #stageD      -0.09884    0.19811  -0.499
> 
> #Correlation of Fixed Effects:
> #       (Intr) stageB stageC
> #stageB -0.721              
> #stageC -0.738  0.532       
> #stageD -0.455  0.328  0.336
> ##########################################################
> #my data:
> ##########################################################
> similarity<-data.frame(list(structure(list(stage = 
> structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 
> 4L, 4L, 4L, 4L), .Label = c("A", "B", "C", "D"), class = 
> "factor"), site = structure(c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 3L, 
> 3L, 3L, 4L, 4L, 4L, 4L, 5L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 8L, 
> 8L, 8L, 8L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L, 11L, 11L, 
> 12L, 12L, 12L, 13L, 13L, 13L, 14L, 14L, 14L, 14L, 15L, 15L, 
> 15L, 15L, 16L, 16L, 16L, 17L, 17L, 17L, 17L, 18L, 18L, 19L, 
> 19L, 19L, 19L, 20L, 20L, 20L, 20L, 21L, 21L, 21L, 21L, 22L, 
> 22L, 22L, 22L, 23L, 23L, 23L, 24L, 24L, 24L, 24L, 25L, 25L, 
> 25L, 25L, 26L, 26L, 26L, 26L, 27L, 27L, 27L, 27L, 28L, 28L, 
> 28L, 28L, 29L, 29L, 29L, 30L, 30L, 30L, 30L, 31L, 31L, 32L, 
> 32L, 32L, 32L, 33L, 33L, 33L, 33L, 34L, 34L, 34L, 34L, 35L, 
> 35L, 35L, 35L, 36L, 36L, 36L, 36L, 37L, 37L, 38L, 38L, 38L, 
> 38L, 39L, 39L, 39L ), .Label = c("A11", "A12", "A14", "A15", 
> "A16", "A17", "A18", "A19", "A20", "A5", "A7", "A8", "B1", 
> "B12", "B13", "B14", "B15", "B17", "B18", "B2", "B4", "B7", 
> "B8", "B9", "C1", "C10", "C11", "C15", "C17", "C18", "C19", 
> "C2", "C20", "C3", "C4", "C6", "D1", "D4", "D7"), class = 
> "factor"), MH.Index = c(0.392156863, 0.602434077, 
> 0.576923077, 0.647482014, 0.989010989, 0.857142857, 1, 1, 1, 
> 0, 1, 0.378378378, 0.839087948, 0.252915554, 1, 0.22556391, 
> 0.510366826, 0.476190476, 0.555819477, 0.961538462, 
> 0.666666667, 0.089285714, 0.923076923, 0.571428571, 0, 
> 0.923076923, 0.617647059, 0.599423631, 0, 0.727272727, 
> 0.998112812, 0, 0, 0, 1, 0.565656566, 0.75, 0.923076923, 
> 0.654545455, 0.14084507, 0.617647059, 0.315789474, 
> 0.179347826, 0.583468021, 0.165525114, 0.817438692, 
> 0.455551457, 0.49548886, 0.556127703, 0.707431246, 
> 0.506757551, 0.689655172, 0.241433511, 0.379232506, 
> 0.241935484, 0, 0.30848329, 0.530973451, 0.148148148, 0, 
> 0.976744186, 0.550218341, 0.542168675, 0.769230769, 
> 0.153310105, 0, 0, 0.380569406, 0.742174733, 0.222222222,
> 0.046925432, 0, 0.068076328, 0.772727273, 0.830039526, 
> 0.503458415, 0.863910822, 0.39401263, 0.081818182, 
> 0.368421053, 0.088607595, 0, 0.575499851, 0.605657238, 
> 0.714854232, 0.855881172, 0.815689401, 0.552207228, 
> 0.81708081, 0.583228133, 0.334466349, 0.259477365, 
> 0.194711538, 0.278916707, 0.636304805, 0.593715432, 
> 0.661016949, 0.626865672, 0.420219245, 0.453535143, 
> 0.471243706, 0.462427746, 0.56980057, 0.453821155, 
> 0.052828527, 0.926829268, 0.51988266, 0.472200264, 
> 0.351219512, 0.290030211, 0.765258974, 0.564894108, 
> 0.789699571, 0.863378215, 0.525181559, 0.803061458, 
> 0.260164645, 0.477265792, 0.265889379, 0.317791411, 
> 0.107623318, 0.279181709, 0.471953363, 0.463724265, 
> 0.241966696, 0.403647213, 0.693087992, 0.494259925, 
> 0.68904453, 0.39329147, 0.498161213, 0.376225983, 
> 0.407001046, 0.825016633, 0.718991658, 0.662995912)), .Names
> = c("stage", "site", "MH.Index"), class = "data.frame", 
> row.names = c(NA,
> -136L))))
> ##########################################################
> --
> View this message in context: 
> http://n4.nabble.com/glmer-with-non-integer-weights-tp1837179p
> 1837179.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From kari.ruohonen at utu.fi  Tue Apr 13 13:11:47 2010
From: kari.ruohonen at utu.fi (Kari Ruohonen)
Date: Tue, 13 Apr 2010 14:11:47 +0300
Subject: [R-sig-ME] ordinal regression with MCMCglmm
Message-ID: <1271157107.3921.17.camel@kant>

Hi,
I am trying to figure out how to fit an ordinal regression model with
MCMCglmm. The "MCMCglmm Course notes" has a section on multinomial
models but no example of ordinal models. Suppose I have the following
data

 > data
   resp treat group
1     4     A    1
2     4     A    1
3     3     A    2
4     4     A    2
5     2     A    3
6     4     A    3
7     2     A    4
8     2     A    4
9     3     A    5
10    2     A    5
11    1     B    6
12    1     B    6
13    1     B    7
14    2     B    7
15    2     B    8
16    3     B    8
17    2     B    9
18    1     B    9
19    2     B   10
20    2     B   10

and the "resp" is an ordinal response, "treat" is a treatment and
"group" is membership to a group. Assume I would like to fit an ordinal
model between "resp" and "treat" by having "group" effects as random
effects. How would I specify such a model in MCMCglmm? And how would I
specify the prior distributions?

All help is greatly appreciated.

regards, Kari



From kevin.thorpe at utoronto.ca  Tue Apr 13 14:57:20 2010
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Tue, 13 Apr 2010 08:57:20 -0400
Subject: [R-sig-ME] Another case of -1.0 correlation of random effects
In-Reply-To: <v2u40e66e0b1004120617pe772b870se58090a6d6639f7f@mail.gmail.com>
References: <4BBF0986.70309@utoronto.ca>	
	<loom.20100409T143920-273@post.gmane.org>
	<4BBF2584.10609@ufl.edu>	 <4BBF69E3.3050308@utoronto.ca>
	<4BC3198A.6070408@utoronto.ca>
	<v2u40e66e0b1004120617pe772b870se58090a6d6639f7f@mail.gmail.com>
Message-ID: <4BC46A30.9010802@utoronto.ca>

Douglas Bates wrote:
> On Mon, Apr 12, 2010 at 8:00 AM, Kevin E. Thorpe
> <kevin.thorpe at utoronto.ca> wrote:
>> Kevin E. Thorpe wrote:
>>>
>> Regarding lme4a: how do I obtain it?  I guess that comes down to, what is
>> the repository to give to install.packages()?  Does it require a different
>> Matrix package than the one I have, which is, 0.999375-33 and if so, how do
>> I not break my current lme4/Matrix combination?
> 
> The repository is http://R-forge.R-project.org but be aware that lme4a
> is under active development and not guaranteed against breakage.  It
> would be inadvisable to rely on functions and classes in that package
> to persist.

I tried to get lme4a but am having problems.

 > install.packages("lme4a", repos="http://R-Forge.R-project.org")
Warning message:
In getDependencies(pkgs, dependencies, available, lib) :
   package 'lme4a' is not available

Also, if I try and download the package source directly from:

http://r-forge.r-project.org/src/contrib/lme4a_0.999375-48.tar.gz

which comes from the "R Packages" tab of the lme4 project pages I get 
"PAGE NOT FOUND."


-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016



From bolker at ufl.edu  Tue Apr 13 15:22:30 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 13 Apr 2010 09:22:30 -0400
Subject: [R-sig-ME] Another case of -1.0 correlation of random effects
In-Reply-To: <4BC46A30.9010802@utoronto.ca>
References: <4BBF0986.70309@utoronto.ca>		<loom.20100409T143920-273@post.gmane.org>	<4BBF2584.10609@ufl.edu>	
	<4BBF69E3.3050308@utoronto.ca>	<4BC3198A.6070408@utoronto.ca>	<v2u40e66e0b1004120617pe772b870se58090a6d6639f7f@mail.gmail.com>
	<4BC46A30.9010802@utoronto.ca>
Message-ID: <4BC47016.7090905@ufl.edu>

  Something (don't know what) is currently broken in the lme4a build
process on r-forge, which doesn't necessarily mean that the package
itself is broken (it passes tests and installs fine on my system).  You
have two choices:

 (1) follow the instructions on r-forge to download the full SVN
repository; build the package from source. (You will need SVN tools as
well as the full suite of R-building tools -- compiler etc etc.)

 (2) I can send/post a binary build of the current SVN version easily
(which will install if you have the necessary tools to build from source
-- this gets you out of needing the SVN tools above, but you still need
compiler etc). I have shipped a version off to the R-project windows
cross-building service, so I could also send/post a Windows binary if
you like. Can you send sessionInfo() output?

Kevin E. Thorpe wrote:
> Douglas Bates wrote:
>> On Mon, Apr 12, 2010 at 8:00 AM, Kevin E. Thorpe
>> <kevin.thorpe at utoronto.ca> wrote:
>>> Kevin E. Thorpe wrote:
>>> Regarding lme4a: how do I obtain it?  I guess that comes down to, what is
>>> the repository to give to install.packages()?  Does it require a different
>>> Matrix package than the one I have, which is, 0.999375-33 and if so, how do
>>> I not break my current lme4/Matrix combination?
>> The repository is http://R-forge.R-project.org but be aware that lme4a
>> is under active development and not guaranteed against breakage.  It
>> would be inadvisable to rely on functions and classes in that package
>> to persist.
> 
> I tried to get lme4a but am having problems.
> 
>  > install.packages("lme4a", repos="http://R-Forge.R-project.org")
> Warning message:
> In getDependencies(pkgs, dependencies, available, lib) :
>    package 'lme4a' is not available
> 
> Also, if I try and download the package source directly from:
> 
> http://r-forge.r-project.org/src/contrib/lme4a_0.999375-48.tar.gz
> 
> which comes from the "R Packages" tab of the lme4 project pages I get 
> "PAGE NOT FOUND."
> 
> 


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From bates at stat.wisc.edu  Tue Apr 13 15:25:55 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 13 Apr 2010 08:25:55 -0500
Subject: [R-sig-ME] Another case of -1.0 correlation of random effects
In-Reply-To: <4BC46A30.9010802@utoronto.ca>
References: <4BBF0986.70309@utoronto.ca>
	<loom.20100409T143920-273@post.gmane.org> <4BBF2584.10609@ufl.edu>
	<4BBF69E3.3050308@utoronto.ca> <4BC3198A.6070408@utoronto.ca>
	<v2u40e66e0b1004120617pe772b870se58090a6d6639f7f@mail.gmail.com>
	<4BC46A30.9010802@utoronto.ca>
Message-ID: <r2n40e66e0b1004130625xd609aee0z92a7222c6f40a187@mail.gmail.com>

On Tue, Apr 13, 2010 at 7:57 AM, Kevin E. Thorpe
<kevin.thorpe at utoronto.ca> wrote:
> Douglas Bates wrote:
>>
>> On Mon, Apr 12, 2010 at 8:00 AM, Kevin E. Thorpe
>> <kevin.thorpe at utoronto.ca> wrote:
>>>
>>> Kevin E. Thorpe wrote:
>>>>
>>> Regarding lme4a: how do I obtain it? ?I guess that comes down to, what is
>>> the repository to give to install.packages()? ?Does it require a
>>> different
>>> Matrix package than the one I have, which is, 0.999375-33 and if so, how
>>> do
>>> I not break my current lme4/Matrix combination?
>>
>> The repository is http://R-forge.R-project.org but be aware that lme4a
>> is under active development and not guaranteed against breakage. ?It
>> would be inadvisable to rely on functions and classes in that package
>> to persist.
>
> I tried to get lme4a but am having problems.
>
>> install.packages("lme4a", repos="http://R-Forge.R-project.org")
> Warning message:
> In getDependencies(pkgs, dependencies, available, lib) :
> ?package 'lme4a' is not available
>
> Also, if I try and download the package source directly from:
>
> http://r-forge.r-project.org/src/contrib/lme4a_0.999375-48.tar.gz
>
> which comes from the "R Packages" tab of the lme4 project pages I get "PAGE
> NOT FOUND."

lme4a is under active development and I will often commit things from
work then update at home, add some more code, and commit again.   My
standard for commits is that I can run

R CMD INSTALL lme4a

on an Ubuntu 64-bit system, which I run both at home and at work.  I'm
not surprised that it doesn't compile and pass checks everywhere.
Things will need to stabilize with a week because I have project
reports to read and grade starting next Tuesday and I won't have time
for further development.



From kevin.thorpe at utoronto.ca  Tue Apr 13 15:28:18 2010
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Tue, 13 Apr 2010 09:28:18 -0400
Subject: [R-sig-ME] Another case of -1.0 correlation of random effects
In-Reply-To: <4BC47016.7090905@ufl.edu>
References: <4BBF0986.70309@utoronto.ca>		<loom.20100409T143920-273@post.gmane.org>	<4BBF2584.10609@ufl.edu>	
	<4BBF69E3.3050308@utoronto.ca>	<4BC3198A.6070408@utoronto.ca>	<v2u40e66e0b1004120617pe772b870se58090a6d6639f7f@mail.gmail.com>
	<4BC46A30.9010802@utoronto.ca> <4BC47016.7090905@ufl.edu>
Message-ID: <4BC47172.8010202@utoronto.ca>

Ben Bolker wrote:
>   Something (don't know what) is currently broken in the lme4a build
> process on r-forge, which doesn't necessarily mean that the package
> itself is broken (it passes tests and installs fine on my system).  You
> have two choices:
> 
>  (1) follow the instructions on r-forge to download the full SVN
> repository; build the package from source. (You will need SVN tools as
> well as the full suite of R-building tools -- compiler etc etc.)
> 
>  (2) I can send/post a binary build of the current SVN version easily
> (which will install if you have the necessary tools to build from source
> -- this gets you out of needing the SVN tools above, but you still need
> compiler etc). I have shipped a version off to the R-project windows
> cross-building service, so I could also send/post a Windows binary if
> you like. Can you send sessionInfo() output?

I posted my sessionInfo() in my OP, but I'll give it below again.  In 
any case, I run on Linux and always build R from source, so I have the 
compiler tools.  I also have subversion.

 > sessionInfo()
R version 2.10.1 Patched (2009-12-29 r50852)
i686-pc-linux-gnu

locale:
  [1] LC_CTYPE=en_US       LC_NUMERIC=C         LC_TIME=en_US
  [4] LC_COLLATE=C         LC_MONETARY=C        LC_MESSAGES=en_US
  [7] LC_PAPER=en_US       LC_NAME=C            LC_ADDRESS=C
[10] LC_TELEPHONE=C       LC_MEASUREMENT=en_US LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999375-32   Matrix_0.999375-33 lattice_0.17-26

loaded via a namespace (and not attached):
[1] grid_2.10.1  tools_2.10.1

> 
> Kevin E. Thorpe wrote:
>> Douglas Bates wrote:
>>> On Mon, Apr 12, 2010 at 8:00 AM, Kevin E. Thorpe
>>> <kevin.thorpe at utoronto.ca> wrote:
>>>> Kevin E. Thorpe wrote:
>>>> Regarding lme4a: how do I obtain it?  I guess that comes down to, what is
>>>> the repository to give to install.packages()?  Does it require a different
>>>> Matrix package than the one I have, which is, 0.999375-33 and if so, how do
>>>> I not break my current lme4/Matrix combination?
>>> The repository is http://R-forge.R-project.org but be aware that lme4a
>>> is under active development and not guaranteed against breakage.  It
>>> would be inadvisable to rely on functions and classes in that package
>>> to persist.
>> I tried to get lme4a but am having problems.
>>
>>  > install.packages("lme4a", repos="http://R-Forge.R-project.org")
>> Warning message:
>> In getDependencies(pkgs, dependencies, available, lib) :
>>    package 'lme4a' is not available
>>
>> Also, if I try and download the package source directly from:
>>
>> http://r-forge.r-project.org/src/contrib/lme4a_0.999375-48.tar.gz
>>
>> which comes from the "R Packages" tab of the lme4 project pages I get 
>> "PAGE NOT FOUND."
>>
>>
> 
> 


-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016



From bolker at ufl.edu  Tue Apr 13 15:40:19 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 13 Apr 2010 09:40:19 -0400
Subject: [R-sig-ME] Another case of -1.0 correlation of random effects
In-Reply-To: <4BC47172.8010202@utoronto.ca>
References: <4BBF0986.70309@utoronto.ca>		<loom.20100409T143920-273@post.gmane.org>	<4BBF2584.10609@ufl.edu>	
	<4BBF69E3.3050308@utoronto.ca>	<4BC3198A.6070408@utoronto.ca>	<v2u40e66e0b1004120617pe772b870se58090a6d6639f7f@mail.gmail.com>
	<4BC46A30.9010802@utoronto.ca> <4BC47016.7090905@ufl.edu>
	<4BC47172.8010202@utoronto.ca>
Message-ID: <4BC47443.1020706@ufl.edu>

  In that case, just go to http://r-forge.r-project.org/scm/?group_id=60
and follow the instructions:

svn checkout svn://svn.r-forge.r-project.org/svnroot/lme4

then navigate to the lme4a directory and build/install it ...

Kevin E. Thorpe wrote:
> Ben Bolker wrote:
>>   Something (don't know what) is currently broken in the lme4a build
>> process on r-forge, which doesn't necessarily mean that the package
>> itself is broken (it passes tests and installs fine on my system).  You
>> have two choices:
>>
>>  (1) follow the instructions on r-forge to download the full SVN
>> repository; build the package from source. (You will need SVN tools as
>> well as the full suite of R-building tools -- compiler etc etc.)
>>
>>  (2) I can send/post a binary build of the current SVN version easily
>> (which will install if you have the necessary tools to build from source
>> -- this gets you out of needing the SVN tools above, but you still need
>> compiler etc). I have shipped a version off to the R-project windows
>> cross-building service, so I could also send/post a Windows binary if
>> you like. Can you send sessionInfo() output?
> 
> I posted my sessionInfo() in my OP, but I'll give it below again.  In 
> any case, I run on Linux and always build R from source, so I have the 
> compiler tools.  I also have subversion.
> 
>  > sessionInfo()
> R version 2.10.1 Patched (2009-12-29 r50852)
> i686-pc-linux-gnu
> 
> locale:
>   [1] LC_CTYPE=en_US       LC_NUMERIC=C         LC_TIME=en_US
>   [4] LC_COLLATE=C         LC_MONETARY=C        LC_MESSAGES=en_US
>   [7] LC_PAPER=en_US       LC_NAME=C            LC_ADDRESS=C
> [10] LC_TELEPHONE=C       LC_MEASUREMENT=en_US LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] lme4_0.999375-32   Matrix_0.999375-33 lattice_0.17-26
> 
> loaded via a namespace (and not attached):
> [1] grid_2.10.1  tools_2.10.1
> 
>> Kevin E. Thorpe wrote:
>>> Douglas Bates wrote:
>>>> On Mon, Apr 12, 2010 at 8:00 AM, Kevin E. Thorpe
>>>> <kevin.thorpe at utoronto.ca> wrote:
>>>>> Kevin E. Thorpe wrote:
>>>>> Regarding lme4a: how do I obtain it?  I guess that comes down to, what is
>>>>> the repository to give to install.packages()?  Does it require a different
>>>>> Matrix package than the one I have, which is, 0.999375-33 and if so, how do
>>>>> I not break my current lme4/Matrix combination?
>>>> The repository is http://R-forge.R-project.org but be aware that lme4a
>>>> is under active development and not guaranteed against breakage.  It
>>>> would be inadvisable to rely on functions and classes in that package
>>>> to persist.
>>> I tried to get lme4a but am having problems.
>>>
>>>  > install.packages("lme4a", repos="http://R-Forge.R-project.org")
>>> Warning message:
>>> In getDependencies(pkgs, dependencies, available, lib) :
>>>    package 'lme4a' is not available
>>>
>>> Also, if I try and download the package source directly from:
>>>
>>> http://r-forge.r-project.org/src/contrib/lme4a_0.999375-48.tar.gz
>>>
>>> which comes from the "R Packages" tab of the lme4 project pages I get 
>>> "PAGE NOT FOUND."
>>>
>>>
>>
> 
> 


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From kevin.thorpe at utoronto.ca  Tue Apr 13 17:19:40 2010
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Tue, 13 Apr 2010 11:19:40 -0400
Subject: [R-sig-ME] Another case of -1.0 correlation of random effects
In-Reply-To: <4BC47443.1020706@ufl.edu>
References: <4BBF0986.70309@utoronto.ca>		<loom.20100409T143920-273@post.gmane.org>	<4BBF2584.10609@ufl.edu>	
	<4BBF69E3.3050308@utoronto.ca>	<4BC3198A.6070408@utoronto.ca>	<v2u40e66e0b1004120617pe772b870se58090a6d6639f7f@mail.gmail.com>
	<4BC46A30.9010802@utoronto.ca> <4BC47016.7090905@ufl.edu>
	<4BC47172.8010202@utoronto.ca> <4BC47443.1020706@ufl.edu>
Message-ID: <4BC48B8C.6040701@utoronto.ca>

Ben Bolker wrote:
>   In that case, just go to http://r-forge.r-project.org/scm/?group_id=60
> and follow the instructions:
> 
> svn checkout svn://svn.r-forge.r-project.org/svnroot/lme4
> 
> then navigate to the lme4a directory and build/install it ...

It's not my day.  I go to the directory where the lme4a tree is located 
and type "R CMD build lme4a" and get an error when the process gets to:

g++ -I/usr/local/lib/R/include  -I/usr/local/include 
-I"/usr/local/lib/R/library/Matrix/include" 
-I"/usr/local/lib/R/library/Rcpp/include"   -fpic  -g -O2 -c 
glmFamily.cpp -o glmFamily.o

In file included from glmFamily.cpp:1:
glmFamily.h:5:18: error: Rcpp.h: No such file or directory
In file included from glmFamily.cpp:1:
[errors continue]

I looked at lme4a/src/glmFamily.h and find

#include <Rcpp.h>
#include <Rmath.h>

Now, I have both of these files in my installation, but not in the 
locations referenced with the -I switches.  My Rcpp.h is found in 
/usr/local/lib/R/library/Rcpp/lib (not include) and my Rmath.h is
found in /usr/local/lib/R/include which doesn't even show up in an -I 
switch.

So, I don't know how these -I switches get generated, but there is a 
problem somewhere, either with my installation or something else.

My installation was a standard build (configure; make; make install).

Yes, I fully understand what "unstable" means.  Hopefully these errors 
are helpful.

Kevin

-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016



From bates at stat.wisc.edu  Tue Apr 13 17:43:26 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 13 Apr 2010 10:43:26 -0500
Subject: [R-sig-ME] Another case of -1.0 correlation of random effects
In-Reply-To: <4BC48B8C.6040701@utoronto.ca>
References: <4BBF0986.70309@utoronto.ca> <4BBF2584.10609@ufl.edu>
	<4BBF69E3.3050308@utoronto.ca> <4BC3198A.6070408@utoronto.ca>
	<v2u40e66e0b1004120617pe772b870se58090a6d6639f7f@mail.gmail.com>
	<4BC46A30.9010802@utoronto.ca> <4BC47016.7090905@ufl.edu>
	<4BC47172.8010202@utoronto.ca> <4BC47443.1020706@ufl.edu>
	<4BC48B8C.6040701@utoronto.ca>
Message-ID: <i2y40e66e0b1004130843q7dee2e79g4dbf481606181c07@mail.gmail.com>

On Tue, Apr 13, 2010 at 10:19 AM, Kevin E. Thorpe
<kevin.thorpe at utoronto.ca> wrote:
> Ben Bolker wrote:
>>
>> ?In that case, just go to http://r-forge.r-project.org/scm/?group_id=60
>> and follow the instructions:
>>
>> svn checkout svn://svn.r-forge.r-project.org/svnroot/lme4
>>
>> then navigate to the lme4a directory and build/install it ...
>
> It's not my day. ?I go to the directory where the lme4a tree is located and
> type "R CMD build lme4a" and get an error when the process gets to:
>
> g++ -I/usr/local/lib/R/include ?-I/usr/local/include
> -I"/usr/local/lib/R/library/Matrix/include"
> -I"/usr/local/lib/R/library/Rcpp/include" ? -fpic ?-g -O2 -c glmFamily.cpp
> -o glmFamily.o
>
> In file included from glmFamily.cpp:1:
> glmFamily.h:5:18: error: Rcpp.h: No such file or directory
> In file included from glmFamily.cpp:1:
> [errors continue]
>
> I looked at lme4a/src/glmFamily.h and find
>
> #include <Rcpp.h>
> #include <Rmath.h>
>
> Now, I have both of these files in my installation, but not in the locations
> referenced with the -I switches. ?My Rcpp.h is found in
> /usr/local/lib/R/library/Rcpp/lib (not include) and my Rmath.h is
> found in /usr/local/lib/R/include which doesn't even show up in an -I
> switch.
>
> So, I don't know how these -I switches get generated, but there is a problem
> somewhere, either with my installation or something else.
>
> My installation was a standard build (configure; make; make install).
>
> Yes, I fully understand what "unstable" means. ?Hopefully these errors are
> helpful.

The DESCRIPTION file says that the lme4a package is linking to Matrix
and Rcpp so you need to have both of those packages installed before
you can compile lme4a.



From kevin.thorpe at utoronto.ca  Tue Apr 13 18:10:22 2010
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Tue, 13 Apr 2010 12:10:22 -0400
Subject: [R-sig-ME] Another case of -1.0 correlation of random effects
In-Reply-To: <i2y40e66e0b1004130843q7dee2e79g4dbf481606181c07@mail.gmail.com>
References: <4BBF0986.70309@utoronto.ca> <4BBF2584.10609@ufl.edu>	
	<4BBF69E3.3050308@utoronto.ca> <4BC3198A.6070408@utoronto.ca>	
	<v2u40e66e0b1004120617pe772b870se58090a6d6639f7f@mail.gmail.com>	
	<4BC46A30.9010802@utoronto.ca> <4BC47016.7090905@ufl.edu>	
	<4BC47172.8010202@utoronto.ca> <4BC47443.1020706@ufl.edu>	
	<4BC48B8C.6040701@utoronto.ca>
	<i2y40e66e0b1004130843q7dee2e79g4dbf481606181c07@mail.gmail.com>
Message-ID: <4BC4976E.3060409@utoronto.ca>

Douglas Bates wrote:
> On Tue, Apr 13, 2010 at 10:19 AM, Kevin E. Thorpe
> <kevin.thorpe at utoronto.ca> wrote:
>> Ben Bolker wrote:
>>>  In that case, just go to http://r-forge.r-project.org/scm/?group_id=60
>>> and follow the instructions:
>>>
>>> svn checkout svn://svn.r-forge.r-project.org/svnroot/lme4
>>>
>>> then navigate to the lme4a directory and build/install it ...
>> It's not my day.  I go to the directory where the lme4a tree is located and
>> type "R CMD build lme4a" and get an error when the process gets to:
>>
>> g++ -I/usr/local/lib/R/include  -I/usr/local/include
>> -I"/usr/local/lib/R/library/Matrix/include"
>> -I"/usr/local/lib/R/library/Rcpp/include"   -fpic  -g -O2 -c glmFamily.cpp
>> -o glmFamily.o
>>
>> In file included from glmFamily.cpp:1:
>> glmFamily.h:5:18: error: Rcpp.h: No such file or directory
>> In file included from glmFamily.cpp:1:
>> [errors continue]
>>
>> I looked at lme4a/src/glmFamily.h and find
>>
>> #include <Rcpp.h>
>> #include <Rmath.h>
>>
>> Now, I have both of these files in my installation, but not in the locations
>> referenced with the -I switches.  My Rcpp.h is found in
>> /usr/local/lib/R/library/Rcpp/lib (not include) and my Rmath.h is
>> found in /usr/local/lib/R/include which doesn't even show up in an -I
>> switch.
>>
>> So, I don't know how these -I switches get generated, but there is a problem
>> somewhere, either with my installation or something else.
>>
>> My installation was a standard build (configure; make; make install).
>>
>> Yes, I fully understand what "unstable" means.  Hopefully these errors are
>> helpful.
> 
> The DESCRIPTION file says that the lme4a package is linking to Matrix
> and Rcpp so you need to have both of those packages installed before
> you can compile lme4a.
> 

They are both installed.  From the DESCRIPTION files on my system:

Package: Rcpp
Title: Rcpp R/C++ interface package
Version: 0.7.11
Date: $Date: 2010-03-26 15:15:51 -0500 (Fri, 26 Mar 2010) $

and

Package: Matrix
Version: 0.999375-38
Date: 2010-03-31


-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016



From j.hadfield at ed.ac.uk  Tue Apr 13 18:41:12 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 13 Apr 2010 17:41:12 +0100
Subject: [R-sig-ME] ordinal regression with MCMCglmm
In-Reply-To: <1271157107.3921.17.camel@kant>
References: <1271157107.3921.17.camel@kant>
Message-ID: <20100413174112.jdti1k3yo8o8ss4o@www.staffmail.ed.ac.uk>

Hi Kari,

The simplest model is


m1<-MCMCglmm(resp~treat, random=~group, family="ordinal",  
data=your.data, prior=prior)

as with multinomial data with a single realisation, the residual  
variance cannot be estimated from the data. The best option is to fix  
it at some value. most programs fix it at zero but MCMCglmm will fail  
to mix if this is done, so I usually fix it at 1:


prior=list(R=list(V=1, fix=1), G=list(G1=list(V=1, nu=0)))

I have left the default prior for the fixed effects (not explicitly  
specified above), and the default prior random effect variance  
structure (G) which has a zero degree of belief parameter. Often this  
requires some/more thought, especially if there are few groups or  
replication within groups is low. Sections 1.2, 1.5 & 8.2 in the  
CourseNotes cover priors for variances.


Currently there is no option for specifying priors on the cut-points -  
the prior is flat and improper. The posterior in virtually all cases  
will be proper though.

Cheers,

Jarrod

Quoting Kari Ruohonen <kari.ruohonen at utu.fi>:

> Hi,
> I am trying to figure out how to fit an ordinal regression model with
> MCMCglmm. The "MCMCglmm Course notes" has a section on multinomial
> models but no example of ordinal models. Suppose I have the following
> data
>
>  > data
>    resp treat group
> 1     4     A    1
> 2     4     A    1
> 3     3     A    2
> 4     4     A    2
> 5     2     A    3
> 6     4     A    3
> 7     2     A    4
> 8     2     A    4
> 9     3     A    5
> 10    2     A    5
> 11    1     B    6
> 12    1     B    6
> 13    1     B    7
> 14    2     B    7
> 15    2     B    8
> 16    3     B    8
> 17    2     B    9
> 18    1     B    9
> 19    2     B   10
> 20    2     B   10
>
> and the "resp" is an ordinal response, "treat" is a treatment and
> "group" is membership to a group. Assume I would like to fit an ordinal
> model between "resp" and "treat" by having "group" effects as random
> effects. How would I specify such a model in MCMCglmm? And how would I
> specify the prior distributions?
>
> All help is greatly appreciated.
>
> regards, Kari
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From mayam at interchange.ubc.ca  Wed Apr 14 01:29:26 2010
From: mayam at interchange.ubc.ca (maya mayrose)
Date: Tue, 13 Apr 2010 16:29:26 -0700 (PDT)
Subject: [R-sig-ME] lme: nested and not-nested random factors
Message-ID: <27403172.35881271201366909.JavaMail.myubc2@handel.my.ubc.ca>

Dear R users,

I have a question regarding the lme function. I am not sure how to model 2 random factors, one random factor is nested with the fixed factor but the second one is not.

Specifically, I have collected RNA expression data for nine populations that are nested within three plant groups (that is, each population belongs to only one group; the populations were sampled randomly from a large pool of populations in each group). Each population was sampled once.

I then replicated the experiment 3 times, so there may be some differences between the replicates that are shared across all populations.

My aim is to look for differences in expression between the three groups, accounting for population as a random factor and for the variability between the three replicates.

 
The formula I thought of is:

z <- lme(y ~ group, random = list(population=~ 1,replicate=~1))

but this would treat both replicate as nested within population.

 
Another option would be to treat replicate as an additional fixed factor, as there were three independent replicates (but on the other hand, the plants for each replicate were randomly chosen).

I would greatly appreciate your help!

Maya



From kari.ruohonen at utu.fi  Wed Apr 14 09:07:20 2010
From: kari.ruohonen at utu.fi (Kari Ruohonen)
Date: Wed, 14 Apr 2010 10:07:20 +0300
Subject: [R-sig-ME] ordinal regression with MCMCglmm
In-Reply-To: <20100413174112.jdti1k3yo8o8ss4o@www.staffmail.ed.ac.uk>
References: <1271157107.3921.17.camel@kant>
	<20100413174112.jdti1k3yo8o8ss4o@www.staffmail.ed.ac.uk>
Message-ID: <1271228840.3921.47.camel@kant>

Hi and thanks for the answer. I tried exactly that model syntax before
posting but the output of the "fixed" part had an unexpected
parameterisation and I thought I misspecified the model somehow. The
parameters I got with the above model are
- two cutpoints
- intercept
- effect of group B

I would have expected that instead of the intercept and two cutpoints I
would have had three cutpoints as given by polr (MASS package), for
example. Can you explain me the parameterisation in MCMCglmm and how it
connects to the one in polr that uses J-1 ordered cutpoints (J=number of
score classes) without an intercept?

Also, I am uncertain do I need to convert the "resp" before MCMCglmm to
an ordered factor (with "ordered")?

Many thanks,

Kari

On Tue, 2010-04-13 at 17:41 +0100, Jarrod Hadfield wrote:
> Hi Kari,
> 
> The simplest model is
> 
> 
> m1<-MCMCglmm(resp~treat, random=~group, family="ordinal",  
> data=your.data, prior=prior)
> 
> as with multinomial data with a single realisation, the residual  
> variance cannot be estimated from the data. The best option is to fix  
> it at some value. most programs fix it at zero but MCMCglmm will fail  
> to mix if this is done, so I usually fix it at 1:
> 
> 
> prior=list(R=list(V=1, fix=1), G=list(G1=list(V=1, nu=0)))
> 
> I have left the default prior for the fixed effects (not explicitly  
> specified above), and the default prior random effect variance  
> structure (G) which has a zero degree of belief parameter. Often this  
> requires some/more thought, especially if there are few groups or  
> replication within groups is low. Sections 1.2, 1.5 & 8.2 in the  
> CourseNotes cover priors for variances.
> 
> 
> Currently there is no option for specifying priors on the cut-points -  
> the prior is flat and improper. The posterior in virtually all cases  
> will be proper though.
> 
> Cheers,
> 
> Jarrod
> 
> Quoting Kari Ruohonen <kari.ruohonen at utu.fi>:
> 
> > Hi,
> > I am trying to figure out how to fit an ordinal regression model with
> > MCMCglmm. The "MCMCglmm Course notes" has a section on multinomial
> > models but no example of ordinal models. Suppose I have the following
> > data
> >
> >  > data
> >    resp treat group
> > 1     4     A    1
> > 2     4     A    1
> > 3     3     A    2
> > 4     4     A    2
> > 5     2     A    3
> > 6     4     A    3
> > 7     2     A    4
> > 8     2     A    4
> > 9     3     A    5
> > 10    2     A    5
> > 11    1     B    6
> > 12    1     B    6
> > 13    1     B    7
> > 14    2     B    7
> > 15    2     B    8
> > 16    3     B    8
> > 17    2     B    9
> > 18    1     B    9
> > 19    2     B   10
> > 20    2     B   10
> >
> > and the "resp" is an ordinal response, "treat" is a treatment and
> > "group" is membership to a group. Assume I would like to fit an ordinal
> > model between "resp" and "treat" by having "group" effects as random
> > effects. How would I specify such a model in MCMCglmm? And how would I
> > specify the prior distributions?
> >
> > All help is greatly appreciated.
> >
> > regards, Kari
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
> 
> 
>



From j.hadfield at ed.ac.uk  Wed Apr 14 15:34:51 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 14 Apr 2010 14:34:51 +0100
Subject: [R-sig-ME] ordinal regression with MCMCglmm
In-Reply-To: <1271228840.3921.47.camel@kant>
References: <1271157107.3921.17.camel@kant>
	<20100413174112.jdti1k3yo8o8ss4o@www.staffmail.ed.ac.uk>
	<1271228840.3921.47.camel@kant>
Message-ID: <C0B7C7DF-CE43-47D7-B0DC-CBBAD72C546A@ed.ac.uk>

Hi,

Imagine a latent variable (l) that conforms to the  standard linear  
model.

l = Xb+Zu+e

The probabilities of falling into each of the four categories are:


pnorm(-l)

pnorm(cp[1]-l)-pnorm(-l)

  pnorm(cp[2]-l)-pnorm(cp[1]-l)

1-pnorm(cp[2]-l)

where cp is the vector of cut-points with 2 elements. A 3 cut-point  
model would be over-parameterised (unless the intercept is zero, which  
I presume is what polr does (?).

The factors don't need to be ordered, the order is obtained from  
levels(resp).  In the future, I may only allowed ordered factors to  
stop any accidents.

Cheers,

Jarrod





On 14 Apr 2010, at 08:07, Kari Ruohonen wrote:

> Hi and thanks for the answer. I tried exactly that model syntax before
> posting but the output of the "fixed" part had an unexpected
> parameterisation and I thought I misspecified the model somehow. The
> parameters I got with the above model are
> - two cutpoints
> - intercept
> - effect of group B
>
> I would have expected that instead of the intercept and two  
> cutpoints I
> would have had three cutpoints as given by polr (MASS package), for
> example. Can you explain me the parameterisation in MCMCglmm and how  
> it
> connects to the one in polr that uses J-1 ordered cutpoints  
> (J=number of
> score classes) without an intercept?
>
> Also, I am uncertain do I need to convert the "resp" before MCMCglmm  
> to
> an ordered factor (with "ordered")?
>
> Many thanks,
>
> Kari
>
> On Tue, 2010-04-13 at 17:41 +0100, Jarrod Hadfield wrote:
>> Hi Kari,
>>
>> The simplest model is
>>
>>
>> m1<-MCMCglmm(resp~treat, random=~group, family="ordinal",
>> data=your.data, prior=prior)
>>
>> as with multinomial data with a single realisation, the residual
>> variance cannot be estimated from the data. The best option is to fix
>> it at some value. most programs fix it at zero but MCMCglmm will fail
>> to mix if this is done, so I usually fix it at 1:
>>
>>
>> prior=list(R=list(V=1, fix=1), G=list(G1=list(V=1, nu=0)))
>>
>> I have left the default prior for the fixed effects (not explicitly
>> specified above), and the default prior random effect variance
>> structure (G) which has a zero degree of belief parameter. Often this
>> requires some/more thought, especially if there are few groups or
>> replication within groups is low. Sections 1.2, 1.5 & 8.2 in the
>> CourseNotes cover priors for variances.
>>
>>
>> Currently there is no option for specifying priors on the cut- 
>> points -
>> the prior is flat and improper. The posterior in virtually all cases
>> will be proper though.
>>
>> Cheers,
>>
>> Jarrod
>>
>> Quoting Kari Ruohonen <kari.ruohonen at utu.fi>:
>>
>>> Hi,
>>> I am trying to figure out how to fit an ordinal regression model  
>>> with
>>> MCMCglmm. The "MCMCglmm Course notes" has a section on multinomial
>>> models but no example of ordinal models. Suppose I have the  
>>> following
>>> data
>>>
>>>> data
>>>   resp treat group
>>> 1     4     A    1
>>> 2     4     A    1
>>> 3     3     A    2
>>> 4     4     A    2
>>> 5     2     A    3
>>> 6     4     A    3
>>> 7     2     A    4
>>> 8     2     A    4
>>> 9     3     A    5
>>> 10    2     A    5
>>> 11    1     B    6
>>> 12    1     B    6
>>> 13    1     B    7
>>> 14    2     B    7
>>> 15    2     B    8
>>> 16    3     B    8
>>> 17    2     B    9
>>> 18    1     B    9
>>> 19    2     B   10
>>> 20    2     B   10
>>>
>>> and the "resp" is an ordinal response, "treat" is a treatment and
>>> "group" is membership to a group. Assume I would like to fit an  
>>> ordinal
>>> model between "resp" and "treat" by having "group" effects as random
>>> effects. How would I specify such a model in MCMCglmm? And how  
>>> would I
>>> specify the prior distributions?
>>>
>>> All help is greatly appreciated.
>>>
>>> regards, Kari
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>
>>
>>
>
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From Thierry.ONKELINX at inbo.be  Wed Apr 14 16:25:12 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 14 Apr 2010 16:25:12 +0200
Subject: [R-sig-ME] ordinal regression with MCMCglmm
In-Reply-To: <C0B7C7DF-CE43-47D7-B0DC-CBBAD72C546A@ed.ac.uk>
References: <1271157107.3921.17.camel@kant><20100413174112.jdti1k3yo8o8ss4o@www.staffmail.ed.ac.uk><1271228840.3921.47.camel@kant>
	<C0B7C7DF-CE43-47D7-B0DC-CBBAD72C546A@ed.ac.uk>
Message-ID: <2E9C414912813E4EB981326983E0A104071FEA6F@inboexch.inbo.be>

Dear Jarrod,

I'm working on a similar problem. Does it makes sense to calculate that
for the fixed effects only? Something like this:
pnorm(-Xb), 
pnorm(cp[1] - Xb) - pnorm(Xb)
pnorm(cp[2] - Xb) - pnorm(cp[1] - Xb)
1 - pnorm(cp[2] - Xb)

Best regards,

Thierry
------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens 
> Jarrod Hadfield
> Verzonden: woensdag 14 april 2010 15:35
> Aan: Kari Ruohonen
> CC: Kari Ruohonen; r-sig-mixed-models at r-project.org
> Onderwerp: Re: [R-sig-ME] ordinal regression with MCMCglmm
> 
> Hi,
> 
> Imagine a latent variable (l) that conforms to the  standard 
> linear model.
> 
> l = Xb+Zu+e
> 
> The probabilities of falling into each of the four categories are:
> 
> 
> pnorm(-l)
> 
> pnorm(cp[1]-l)-pnorm(-l)
> 
>   pnorm(cp[2]-l)-pnorm(cp[1]-l)
> 
> 1-pnorm(cp[2]-l)
> 
> where cp is the vector of cut-points with 2 elements. A 3 
> cut-point model would be over-parameterised (unless the
> intercept is zero, which I presume is what polr does (?).
> 
> The factors don't need to be ordered, the order is obtained 
> from levels(resp).  In the future, I may only allowed ordered 
> factors to stop any accidents.
> 
> Cheers,
> 
> Jarrod
> 
> 
> 
> 
> 
> On 14 Apr 2010, at 08:07, Kari Ruohonen wrote:
> 
> > Hi and thanks for the answer. I tried exactly that model 
> syntax before 
> > posting but the output of the "fixed" part had an unexpected 
> > parameterisation and I thought I misspecified the model 
> somehow. The 
> > parameters I got with the above model are
> > - two cutpoints
> > - intercept
> > - effect of group B
> >
> > I would have expected that instead of the intercept and two 
> cutpoints 
> > I would have had three cutpoints as given by polr (MASS 
> package), for 
> > example. Can you explain me the parameterisation in
> MCMCglmm and how 
> > it connects to the one in polr that uses J-1 ordered cutpoints 
> > (J=number of score classes) without an intercept?
> >
> > Also, I am uncertain do I need to convert the "resp" before 
> MCMCglmm 
> > to an ordered factor (with "ordered")?
> >
> > Many thanks,
> >
> > Kari
> >
> > On Tue, 2010-04-13 at 17:41 +0100, Jarrod Hadfield wrote:
> >> Hi Kari,
> >>
> >> The simplest model is
> >>
> >>
> >> m1<-MCMCglmm(resp~treat, random=~group, family="ordinal", 
> >> data=your.data, prior=prior)
> >>
> >> as with multinomial data with a single realisation, the residual 
> >> variance cannot be estimated from the data. The best 
> option is to fix 
> >> it at some value. most programs fix it at zero but 
> MCMCglmm will fail 
> >> to mix if this is done, so I usually fix it at 1:
> >>
> >>
> >> prior=list(R=list(V=1, fix=1), G=list(G1=list(V=1, nu=0)))
> >>
> >> I have left the default prior for the fixed effects (not 
> explicitly 
> >> specified above), and the default prior random effect variance 
> >> structure (G) which has a zero degree of belief parameter. 
> Often this 
> >> requires some/more thought, especially if there are few groups or 
> >> replication within groups is low. Sections 1.2, 1.5 & 8.2 in the 
> >> CourseNotes cover priors for variances.
> >>
> >>
> >> Currently there is no option for specifying priors on the 
> cut- points 
> >> - the prior is flat and improper. The posterior in virtually all 
> >> cases will be proper though.
> >>
> >> Cheers,
> >>
> >> Jarrod
> >>
> >> Quoting Kari Ruohonen <kari.ruohonen at utu.fi>:
> >>
> >>> Hi,
> >>> I am trying to figure out how to fit an ordinal regression model 
> >>> with MCMCglmm. The "MCMCglmm Course notes" has a section on 
> >>> multinomial models but no example of ordinal models. 
> Suppose I have 
> >>> the following data
> >>>
> >>>> data
> >>>   resp treat group
> >>> 1     4     A    1
> >>> 2     4     A    1
> >>> 3     3     A    2
> >>> 4     4     A    2
> >>> 5     2     A    3
> >>> 6     4     A    3
> >>> 7     2     A    4
> >>> 8     2     A    4
> >>> 9     3     A    5
> >>> 10    2     A    5
> >>> 11    1     B    6
> >>> 12    1     B    6
> >>> 13    1     B    7
> >>> 14    2     B    7
> >>> 15    2     B    8
> >>> 16    3     B    8
> >>> 17    2     B    9
> >>> 18    1     B    9
> >>> 19    2     B   10
> >>> 20    2     B   10
> >>>
> >>> and the "resp" is an ordinal response, "treat" is a treatment and 
> >>> "group" is membership to a group. Assume I would like to fit an 
> >>> ordinal model between "resp" and "treat" by having 
> "group" effects 
> >>> as random effects. How would I specify such a model in 
> MCMCglmm? And 
> >>> how would I specify the prior distributions?
> >>>
> >>> All help is greatly appreciated.
> >>>
> >>> regards, Kari
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list 
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>
> >>>
> >>
> >>
> >>
> >
> >
> >
> 
> 
> --
> The University of Edinburgh is a charitable body, registered 
> in Scotland, with registration number SC005336.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From j.hadfield at ed.ac.uk  Wed Apr 14 16:41:45 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 14 Apr 2010 15:41:45 +0100
Subject: [R-sig-ME] ordinal regression with MCMCglmm
In-Reply-To: <2E9C414912813E4EB981326983E0A104071FEA6F@inboexch.inbo.be>
References: <1271157107.3921.17.camel@kant><20100413174112.jdti1k3yo8o8ss4o@www.staffmail.ed.ac.uk><1271228840.3921.47.camel@kant>
	<C0B7C7DF-CE43-47D7-B0DC-CBBAD72C546A@ed.ac.uk>
	<2E9C414912813E4EB981326983E0A104071FEA6F@inboexch.inbo.be>
Message-ID: <2FE797FF-C1EC-4CA2-8275-C3B0AA9243BE@ed.ac.uk>

Dear Thierry,

I think (but you had better check) that it would actually be something  
like

pnorm(-Xb, 0, sqrt(1+v)),
pnorm(cp[1] - Xb,0, sqrt(1+v)) - pnorm(Xb,0, sqrt(1+v))
pnorm(cp[2] - Xb,0, sqrt(1+v)) - pnorm(cp[1] - Xb,0, sqrt(1+v))
1- pnorm(cp[2] - Xb,0, sqrt(1+v))

where v is  the sum of the variance components for the residual and  
random effects.

Alternatively, if the residual variance is set to one and there are no  
random effects

pnorm(-Xb, 0, sqrt(2)),
pnorm(cp[1] - Xb,0, sqrt(2)) - pnorm(Xb,0, sqrt(2))
pnorm(cp[2] - Xb,0, sqrt(2)) - pnorm(cp[1] - Xb,0, sqrt(2))
1- pnorm(cp[2] - Xb,0, sqrt(2))

or if the prediction includes random effects:

pnorm(-(Xb+Zu), 0, sqrt(2)),
pnorm(cp[1] - (Xb+Zu),0, sqrt(2)) - pnorm((Xb+Zu),0, sqrt(2))
pnorm(cp[2] - (Xb+Zu),0, sqrt(2)) - pnorm(cp[1] - (Xb+Zu),0, sqrt(2))
1- pnorm(cp[2] - (Xb+Zu),0, sqrt(2))

Please, do not take this as gospel. I have not got time to check these  
results, they are a hunch.

Cheers,

Jarrod


On 14 Apr 2010, at 15:25, ONKELINX, Thierry wrote:

> Dear Jarrod,
>
> I'm working on a similar problem. Does it makes sense to calculate  
> that
> for the fixed effects only? Something like this:
> pnorm(-Xb),
> pnorm(cp[1] - Xb) - pnorm(Xb)
> pnorm(cp[2] - Xb) - pnorm(cp[1] - Xb)
> 1 - pnorm(cp[2] - Xb)
>
> Best regards,
>
> Thierry
> ------------------------------------------------------------------------
> ----
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek
> team Biometrie & Kwaliteitszorg
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
>
> Research Institute for Nature and Forest
> team Biometrics & Quality Assurance
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
>
> tel. + 32 54/436 185
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no  
> more
> than asking him to perform a post-mortem examination: he may be able  
> to
> say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does  
> not
> ensure that a reasonable answer can be extracted from a given body of
> data.
> ~ John Tukey
>
>
>> -----Oorspronkelijk bericht-----
>> Van: r-sig-mixed-models-bounces at r-project.org
>> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens
>> Jarrod Hadfield
>> Verzonden: woensdag 14 april 2010 15:35
>> Aan: Kari Ruohonen
>> CC: Kari Ruohonen; r-sig-mixed-models at r-project.org
>> Onderwerp: Re: [R-sig-ME] ordinal regression with MCMCglmm
>>
>> Hi,
>>
>> Imagine a latent variable (l) that conforms to the  standard
>> linear model.
>>
>> l = Xb+Zu+e
>>
>> The probabilities of falling into each of the four categories are:
>>
>>
>> pnorm(-l)
>>
>> pnorm(cp[1]-l)-pnorm(-l)
>>
>>  pnorm(cp[2]-l)-pnorm(cp[1]-l)
>>
>> 1-pnorm(cp[2]-l)
>>
>> where cp is the vector of cut-points with 2 elements. A 3
>> cut-point model would be over-parameterised (unless the
>> intercept is zero, which I presume is what polr does (?).
>>
>> The factors don't need to be ordered, the order is obtained
>> from levels(resp).  In the future, I may only allowed ordered
>> factors to stop any accidents.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>>
>>
>> On 14 Apr 2010, at 08:07, Kari Ruohonen wrote:
>>
>>> Hi and thanks for the answer. I tried exactly that model
>> syntax before
>>> posting but the output of the "fixed" part had an unexpected
>>> parameterisation and I thought I misspecified the model
>> somehow. The
>>> parameters I got with the above model are
>>> - two cutpoints
>>> - intercept
>>> - effect of group B
>>>
>>> I would have expected that instead of the intercept and two
>> cutpoints
>>> I would have had three cutpoints as given by polr (MASS
>> package), for
>>> example. Can you explain me the parameterisation in
>> MCMCglmm and how
>>> it connects to the one in polr that uses J-1 ordered cutpoints
>>> (J=number of score classes) without an intercept?
>>>
>>> Also, I am uncertain do I need to convert the "resp" before
>> MCMCglmm
>>> to an ordered factor (with "ordered")?
>>>
>>> Many thanks,
>>>
>>> Kari
>>>
>>> On Tue, 2010-04-13 at 17:41 +0100, Jarrod Hadfield wrote:
>>>> Hi Kari,
>>>>
>>>> The simplest model is
>>>>
>>>>
>>>> m1<-MCMCglmm(resp~treat, random=~group, family="ordinal",
>>>> data=your.data, prior=prior)
>>>>
>>>> as with multinomial data with a single realisation, the residual
>>>> variance cannot be estimated from the data. The best
>> option is to fix
>>>> it at some value. most programs fix it at zero but
>> MCMCglmm will fail
>>>> to mix if this is done, so I usually fix it at 1:
>>>>
>>>>
>>>> prior=list(R=list(V=1, fix=1), G=list(G1=list(V=1, nu=0)))
>>>>
>>>> I have left the default prior for the fixed effects (not
>> explicitly
>>>> specified above), and the default prior random effect variance
>>>> structure (G) which has a zero degree of belief parameter.
>> Often this
>>>> requires some/more thought, especially if there are few groups or
>>>> replication within groups is low. Sections 1.2, 1.5 & 8.2 in the
>>>> CourseNotes cover priors for variances.
>>>>
>>>>
>>>> Currently there is no option for specifying priors on the
>> cut- points
>>>> - the prior is flat and improper. The posterior in virtually all
>>>> cases will be proper though.
>>>>
>>>> Cheers,
>>>>
>>>> Jarrod
>>>>
>>>> Quoting Kari Ruohonen <kari.ruohonen at utu.fi>:
>>>>
>>>>> Hi,
>>>>> I am trying to figure out how to fit an ordinal regression model
>>>>> with MCMCglmm. The "MCMCglmm Course notes" has a section on
>>>>> multinomial models but no example of ordinal models.
>> Suppose I have
>>>>> the following data
>>>>>
>>>>>> data
>>>>>  resp treat group
>>>>> 1     4     A    1
>>>>> 2     4     A    1
>>>>> 3     3     A    2
>>>>> 4     4     A    2
>>>>> 5     2     A    3
>>>>> 6     4     A    3
>>>>> 7     2     A    4
>>>>> 8     2     A    4
>>>>> 9     3     A    5
>>>>> 10    2     A    5
>>>>> 11    1     B    6
>>>>> 12    1     B    6
>>>>> 13    1     B    7
>>>>> 14    2     B    7
>>>>> 15    2     B    8
>>>>> 16    3     B    8
>>>>> 17    2     B    9
>>>>> 18    1     B    9
>>>>> 19    2     B   10
>>>>> 20    2     B   10
>>>>>
>>>>> and the "resp" is an ordinal response, "treat" is a treatment and
>>>>> "group" is membership to a group. Assume I would like to fit an
>>>>> ordinal model between "resp" and "treat" by having
>> "group" effects
>>>>> as random effects. How would I specify such a model in
>> MCMCglmm? And
>>>>> how would I specify the prior distributions?
>>>>>
>>>>> All help is greatly appreciated.
>>>>>
>>>>> regards, Kari
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>>
>>>>
>>>>
>>>>
>>>
>>>
>>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered
>> in Scotland, with registration number SC005336.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> Druk dit bericht a.u.b. niet onnodig af.
> Please do not print this message unnecessarily.
>
> Dit bericht en eventuele bijlagen geven enkel de visie van de  
> schrijver weer
> en binden het INBO onder geen enkel beding, zolang dit bericht niet  
> bevestigd is
> door een geldig ondertekend document. The views expressed in  this  
> message
> and any annex are purely those of the writer and may not be regarded  
> as stating
> an official position of INBO, as long as the message is not  
> confirmed by a duly
> signed document.
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From pierrenouvellet at hotmail.com  Wed Apr 14 18:27:05 2010
From: pierrenouvellet at hotmail.com (pierre nouvellet)
Date: Wed, 14 Apr 2010 18:27:05 +0200
Subject: [R-sig-ME] profile() for lmer
Message-ID: <BAY146-w352B2A03B017B89780CC2AA0100@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100414/ed952d73/attachment.pl>

From cewright at uci.edu  Wed Apr 14 19:46:22 2010
From: cewright at uci.edu (Charles E. (Ted) Wright)
Date: Wed, 14 Apr 2010 10:46:22 -0700 (Pacific Daylight Time)
Subject: [R-sig-ME] Problem using mcmcsamp with a model fit with lmer
Message-ID: <alpine.WNT.2.00.1004141036580.2596@pcwright>

Hi -

I am new user of lme4 package so I apologize if the answer to the question 
is obvious. I have fit a model using lmer
 	fit4 = lmer(Resp ~ Stype * HidVis * SameDiff * Nfirst +
 		(HidVis|Pnum), family = binomial, data=tdat)

I would like to construct intervals on the parameters using the results of 
mcmcsamp. However, when I try to run that with the line
 	samp0 <- mcmcsamp(fit4, n=1000)

I get the error message
 	Error in .local(object, n, verbose, ...) : Update not yet written

I saw on the newsgroup awhile ago that there were problems with mcmcsamp on 
some models. Is that the problem here?

I tried updating all the packages I am using to the most recent version and 
that does not have any effect.

Thanks,

Ted Wright



From glorenz2000 at yahoo.com  Wed Apr 14 23:08:02 2010
From: glorenz2000 at yahoo.com (Guido Lorenz)
Date: Wed, 14 Apr 2010 14:08:02 -0700 (PDT)
Subject: [R-sig-ME] modeling spatial autocorrelation and heteroscedascity
	with gls / nlme
Message-ID: <2617.73329.qm@web30804.mail.mud.yahoo.com>

Dear R users,

my question is about groupwise modeling of spatial autocorrelation in mixed effect models: In a soil study, five different sites are to be compared respect to specific soil properties. A regular sampling grid with 32 points in each site was applied. Due to heteroscedascity and a supposed spatial correlation of the data, a mixed effects model was formulated, with the "site" (ID.sitio) as a fixed effect, and different variances and spatial autocorrelation, also stratified by the same factor, "site", using the gls module of nlme package: 

> lmm.dap3a <- gls(Dap.sa ~ 1 + ID.sitio, Pd2006mm, correlation=corSpher(form=~(easting.m+northing.m)|ID.sitio, nugget=TRUE, metric="euclidean"), weights=varIdent(form=~1|ID.sitio), na.action=na.omit, method="REML") 

>  summary(lmm.dap3a)
Generalized least squares fit by REML
  Model: Dap.sa ~ 1 + ID.sitio 
  Data: Pd2006mm 
        AIC       BIC   logLik
  -280.4552 -243.9341 152.2276

Correlation Structure: Spherical spatial correlation
 Formula: ~(easting.m + northing.m) | ID.sitio 
 Parameter estimate(s):
     range     nugget 
17.7285895  0.2560010 
Variance function:
 Structure: Different standard deviations per stratum
 Formula: ~1 | ID.sitio 
 Parameter estimates:
     pag1      pag2      pag3      pag4      pag5 
1.0000000 1.4464638 0.6195818 1.0094856 0.7684725 

Coefficients:
                  Value  Std.Error  t-value p-value
(Intercept)   1.3930856 0.03141931 44.33851  0.0000
ID.sitiopag2  0.0520236 0.05601737  0.92871  0.3545
ID.sitiopag3 -0.1816564 0.03708524 -4.89835  0.0000
ID.sitiopag4  0.0160424 0.04424861  0.36255  0.7174
ID.sitiopag5 -0.1334217 0.03983743 -3.34915  0.0010

 Correlation: 
             (Intr) ID.st2 ID.st3 ID.st4
ID.sitiopag2 -0.561                     
ID.sitiopag3 -0.847  0.475              
ID.sitiopag4 -0.710  0.398  0.602       
ID.sitiopag5 -0.789  0.442  0.668  0.560

Standardized residuals:
        Min          Q1         Med          Q3         Max 
-2.24247234 -0.61313647 -0.01625797  0.67134893  2.21471264 

Residual standard error: 0.1117062 
Degrees of freedom: 160 total; 155 residual



Nevertheless, the output shows that the variances were described as group-specific, but the spatial correlation is expressed as a unique semivariogram for all the sites. Supposing that spatial correlation may be also specific for each sampling unit, how can one specify the model to account for this, using the gls or or some other algorithm?

Thanks in advance for any advice,

Guido Lorenz



From davidD at qimr.edu.au  Thu Apr 15 04:53:18 2010
From: davidD at qimr.edu.au (David Duffy)
Date: Thu, 15 Apr 2010 12:53:18 +1000 (EST)
Subject: [R-sig-ME] ordinal regression with MCMCglmm
In-Reply-To: <2E9C414912813E4EB981326983E0A104071FEA6F@inboexch.inbo.be>
References: <1271157107.3921.17.camel@kant><20100413174112.jdti1k3yo8o8ss4o@www.staffmail.ed.ac.uk><1271228840.3921.47.camel@kant><C0B7C7DF-CE43-47D7-B0DC-CBBAD72C546A@ed.ac.uk>
	<2E9C414912813E4EB981326983E0A104071FEA6F@inboexch.inbo.be>
Message-ID: <Pine.LNX.4.64.1004151249470.24389@orpheus.qimr.edu.au>

On Wed, 14 Apr 2010, ONKELINX, Thierry wrote:

> Dear Jarrod,
>
> I'm working on a similar problem. Does it makes sense to calculate that
> for the fixed effects only? Something like this:
> pnorm(-Xb),
> pnorm(cp[1] - Xb) - pnorm(Xb)
> pnorm(cp[2] - Xb) - pnorm(cp[1] - Xb)
> 1 - pnorm(cp[2] - Xb)

What Jarrod says, elsethread. But it is interesting/confusing to think 
about what the random effects do to the effective spacing of the 
thresholds eg two groups, at least two thresholds, different 
variances ;)

another 2c, David.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From rune.haubo at gmail.com  Thu Apr 15 08:49:23 2010
From: rune.haubo at gmail.com (Rune Haubo)
Date: Thu, 15 Apr 2010 08:49:23 +0200
Subject: [R-sig-ME] ordinal regression with MCMCglmm
In-Reply-To: <1271157107.3921.17.camel@kant>
References: <1271157107.3921.17.camel@kant>
Message-ID: <i2j4949c7e61004142349m56711dbdn69818fa60b5bfb83@mail.gmail.com>

Hi Kari

I know you asked specifically about MCMCglmm, but as an alternative
you could consider to fit the mixed-effects model with clmm from
package ordinal by maximum likelihood:

> library(ordinal)
> fmm1 <- clmm(resp ~ treat, random = group, Hess = 1, nAGQ = 7)
> summary(fmm1)
Cumulative Link Mixed Model fitted with the adaptive Gauss-Hermite
quadrature approximation with 7 quadrature points

Call:
clmm(location = resp ~ treat, random = group, Hess = 1, nAGQ = 7)

Random effects:
           Var  Std.Dev
group 1.673846 1.293772

Location coefficients:
       Estimate Std. Error z value Pr(>|z|)
treatB -3.9275   1.8372    -2.1377 0.032539

No scale coefficients

Threshold coefficients:
    Estimate Std. Error z value
1|2 -4.5676   1.8970    -2.4078
2|3 -0.7297   0.9509    -0.7674
3|4  0.6002   0.9466     0.6340

log-likelihood: -20.43121
AIC: 50.86241
Condition number of Hessian: 32.46322

This function uses the same parameterization as polr in MASS:

> summary(polr(resp ~ treat, Hess = TRUE))
Call:
polr(formula = resp ~ treat, Hess = TRUE)

Coefficients:
           Value Std. Error   t value
treatB -3.130462   1.219036 -2.567981

Intercepts:
    Value   Std. Error t value
1|2 -3.6062  1.1872    -3.0376
2|3 -0.5510  0.6451    -0.8542
3|4  0.4758  0.6498     0.7321

Residual Deviance: 41.81359
AIC: 49.81359

Observe how the estimates of the thresholds and regression
coefficients from the marginal model (polr) are smaller ("attenuated"
is the official term) in absolute value than the estimate from the
conditional model (the mixed-effects model fitted by clmm) to comment
on David's 2c. I am not sure what the effect would be in an MCMCglmm
model.

Regards,
Rune

On 13 April 2010 13:11, Kari Ruohonen <kari.ruohonen at utu.fi> wrote:
> Hi,
> I am trying to figure out how to fit an ordinal regression model with
> MCMCglmm. The "MCMCglmm Course notes" has a section on multinomial
> models but no example of ordinal models. Suppose I have the following
> data
>
> ?> data
> ? resp treat group
> 1 ? ? 4 ? ? A ? ?1
> 2 ? ? 4 ? ? A ? ?1
> 3 ? ? 3 ? ? A ? ?2
> 4 ? ? 4 ? ? A ? ?2
> 5 ? ? 2 ? ? A ? ?3
> 6 ? ? 4 ? ? A ? ?3
> 7 ? ? 2 ? ? A ? ?4
> 8 ? ? 2 ? ? A ? ?4
> 9 ? ? 3 ? ? A ? ?5
> 10 ? ?2 ? ? A ? ?5
> 11 ? ?1 ? ? B ? ?6
> 12 ? ?1 ? ? B ? ?6
> 13 ? ?1 ? ? B ? ?7
> 14 ? ?2 ? ? B ? ?7
> 15 ? ?2 ? ? B ? ?8
> 16 ? ?3 ? ? B ? ?8
> 17 ? ?2 ? ? B ? ?9
> 18 ? ?1 ? ? B ? ?9
> 19 ? ?2 ? ? B ? 10
> 20 ? ?2 ? ? B ? 10
>
> and the "resp" is an ordinal response, "treat" is a treatment and
> "group" is membership to a group. Assume I would like to fit an ordinal
> model between "resp" and "treat" by having "group" effects as random
> effects. How would I specify such a model in MCMCglmm? And how would I
> specify the prior distributions?
>
> All help is greatly appreciated.
>
> regards, Kari
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Rune Haubo Bojesen Christensen

PhD Student, M.Sc. Eng.
Phone: (+45) 45 25 33 63
Mobile: (+45) 30 26 45 54
Mail: rhbc at imm.dtu.dk, rune.haubo at gmail.com

DTU Informatics, Section for Statistics
Technical University of Denmark, Build. 305, Room 122,
DK-2800 Kgs. Lyngby, Denmark



From p.taylor at niwa.co.nz  Thu Apr 15 12:07:30 2010
From: p.taylor at niwa.co.nz (Paul Taylor)
Date: Thu, 15 Apr 2010 22:07:30 +1200
Subject: [R-sig-ME] profile() for lmer
Message-ID: <4BC78E22020000A2000275DB@gwia.niwa.co.nz>

Hi Pierre,

I'm having the same problem. I discovered a suggestion on another mailing list (stat.ethz.ch/mailman/listinfo/r-help) that using a delta argument would work ie pr1ML<-profile(fm1ML,delta=0.2). However, I have tried that and several smaller steps, but to no avail. 

I too am using lme4a and R-2.10.1 on windows 2007 professional.

Any help from anyone would be greatly appreciated.

Paul Taylor
Pelagic Fisheries Scientist
NIWA
New Zealand.

>>> pierre nouvellet 04/15/10 4:29 AM >>> 

Hi,Hi, 

>From the draft book on lme4: 
using lme4a, and the dyestuff data, I call profile and get: 

> profile(fm1ML) 

Error in UseMethod("profile") : 

no applicable method for 'profile' applied to an object of class 
"lmer" 


any suggestions? 
using a R-2.10.1 on windows vista 

pierre 


_________________________________________________________________ 
Hotmail: Free, trusted and rich email service. 

[[alternative HTML version deleted]] 

_______________________________________________ 
R-sig-mixed-models at r-project.org mailing list 
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
NIWA is the trading name of the National Institute of Water & Atmospheric Research Ltd.



From pierrenouvellet at hotmail.com  Thu Apr 15 12:40:39 2010
From: pierrenouvellet at hotmail.com (pierre nouvellet)
Date: Thu, 15 Apr 2010 12:40:39 +0200
Subject: [R-sig-ME] profile() for lmer
In-Reply-To: <4BC78E22020000A2000275DB@gwia.niwa.co.nz>
References: <4BC78E22020000A2000275DB@gwia.niwa.co.nz>
Message-ID: <BAY146-w58E5A1470E249E05833DB7A00F0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100415/04ee6130/attachment.pl>

From Gustaf.Granath at ebc.uu.se  Thu Apr 15 13:50:57 2010
From: Gustaf.Granath at ebc.uu.se (Gustaf Granath)
Date: Thu, 15 Apr 2010 13:50:57 +0200
Subject: [R-sig-ME] MCMCglmm: meta-analysis problem
Message-ID: <4BC6FDA1.1040806@ebc.uu.se>

Hi,

In a meta-analysis, the SEs of the outcomes are known. However in some 
cases, the correlation (co-variances) among outcomes are known as well. 
For example when you have multiple outcomes from one study. I wanted to 
see if the whole error structure of measurement errors (the R-structure 
in MCMCglmm, or?) can be passed and not only the diagonal.

##test data
testdata<-data.frame(Experiment=as.factor(c(1,2,3,4,5,6,7,8)),Study=c("a","a","b","c","d","d","e","e")
,y=c(34,38,45,48,35,28,43,39),yvar=c(3,5,6,2,3,4,5,7),covar=c(1.5,1.5,NA,NA,2.5,2.5,1.25,1.25))
Rmat<-diag(8)*testdata$yvar
Rmat[1,2]<-testdata$covar[1]
Rmat[2,1]<-testdata$covar[2]
Rmat[5,6]<-testdata$covar[5]
Rmat[6,5]<-testdata$covar[6]
Rmat[7,8]<-testdata$covar[7]
Rmat[8,7]<-testdata$covar[8]

Rmat is the known covariance structure of the experimental outcomes.

library(MCMCglmm)
#"normal" meta-analysis using only the diagonal:
prior = list(R = list(V = 1, n=1,fix = 1),G = list(G1  = list ( V = 1, n 
= 1)))
model1 <- MCMCglmm(y ~ 1, random = ~idh(sqrt(yvar)):units ,data = testdata,
                      prior=prior)

#OR (should be equal right? give sligtly different results though):
model2 <- MCMCglmm(y ~ 1, random = ~Experiment ,data = testdata,
                      mev=testdata$yvar,prior=prior)

#Now I want to include the known within-study correlation.
prior = list(R = list(V = Rmat, fix = 1),G = list(G1  = list ( V = (1), 
nu = 0.002)))
model1 <- MCMCglmm(y ~ 1, random = ~idh(Experiment):units, rcov = ~ 
us(Study):Experiment ,data = testdata,
                      prior=prior)

This did not work (I tried other ways as well but all failed) and I 
guess that it is because of my R-structure prior. Is there an 
alternative specification, or? (I played around a little with the 
"animal" argument but I couldnt get to do what I wanted.)

Cheers,

Gustaf

-- 

Gustaf Granath (PhD student)

Dept of Plant Ecology
Uppsala University



From cewright at uci.edu  Wed Apr 14 19:46:22 2010
From: cewright at uci.edu (Charles E. (Ted) Wright)
Date: Wed, 14 Apr 2010 10:46:22 -0700 (Pacific Daylight Time)
Subject: [R-sig-ME] Problem using mcmcsamp with a model fit with lmer
Message-ID: <alpine.WNT.2.00.1004141036580.2596@pcwright>

Hi -

I am new user of lme4 package so I apologize if the answer to the question 
is obvious. I have fit a model using lmer
 	fit4 = lmer(Resp ~ Stype * HidVis * SameDiff * Nfirst +
 		(HidVis|Pnum), family = binomial, data=tdat)

I would like to construct intervals on the parameters using the results of 
mcmcsamp. However, when I try to run that with the line
 	samp0 <- mcmcsamp(fit4, n=1000)

I get the error message
 	Error in .local(object, n, verbose, ...) : Update not yet written

I saw on the newsgroup awhile ago that there were problems with mcmcsamp on 
some models. Is that the problem here?

I tried updating all the packages I am using to the most recent version and 
that does not have any effect.

Thanks,

Ted Wright



From kevin.thorpe at utoronto.ca  Thu Apr 15 16:24:27 2010
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Thu, 15 Apr 2010 10:24:27 -0400
Subject: [R-sig-ME] Workaround for my trouble installing lme4a
Message-ID: <4BC7219B.2050207@utoronto.ca>

Hello, since my difficulties installing lme4a are buried in another 
thread, I'm creating a new thread more relevant to the problem.  In 
working through this email, I did find a solution (at the bottom), but I 
still have a question after that.

I have fetched the entire project tree using subversion.  Here is my 
sessionInfo.

 > sessionInfo()
R version 2.10.1 Patched (2009-12-29 r50852)
i686-pc-linux-gnu

locale:
  [1] LC_CTYPE=en_US       LC_NUMERIC=C         LC_TIME=en_US
  [4] LC_COLLATE=C         LC_MONETARY=C        LC_MESSAGES=en_US
  [7] LC_PAPER=en_US       LC_NAME=C            LC_ADDRESS=C
[10] LC_TELEPHONE=C       LC_MEASUREMENT=en_US LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_2.10.1

I have installed all of the dependencies in lme4a/DESCRIPTION, including 
Rcpp and the correct version of Matrix.  The command
'R CMD INSTALL lme4a' fails when it gets to the following instruction:

g++ -I/usr/local/lib/R/include  -I/usr/local/include 
-I"/usr/local/lib/R/library/Matrix/include" 
-I"/usr/local/lib/R/library/Rcpp/include"   -fpic  -g -O2 -c 
glmFamily.cpp -o glmFamily.o

One thing I notice is that the one of the -I switches does not match how 
my system is installed (I have not done anything special in my R 
installation).

Specifically, my version of Rcpp (0.7.11) does not have an include 
directory.  The header files appear to be in 
/usr/local/lib/R/library/Rcpp/lib

I created a symbolic link for the missing include directory and 
successfully built lme4a.

My question is, how are the -I switches constructed?  Are they 
hard-coded in the package source somewhere?  Did something go wrong in 
my Rcpp install?

Kevin

-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016



From bates at stat.wisc.edu  Thu Apr 15 16:55:21 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 15 Apr 2010 09:55:21 -0500
Subject: [R-sig-ME] Workaround for my trouble installing lme4a
In-Reply-To: <4BC7219B.2050207@utoronto.ca>
References: <4BC7219B.2050207@utoronto.ca>
Message-ID: <y2o40e66e0b1004150755ga0277ad7uc2e3ffabc8f0027c@mail.gmail.com>

On Thu, Apr 15, 2010 at 9:24 AM, Kevin E. Thorpe
<kevin.thorpe at utoronto.ca> wrote:
> Hello, since my difficulties installing lme4a are buried in another thread,
> I'm creating a new thread more relevant to the problem. ?In working through
> this email, I did find a solution (at the bottom), but I still have a
> question after that.
>
> I have fetched the entire project tree using subversion. ?Here is my
> sessionInfo.
>
>> sessionInfo()
> R version 2.10.1 Patched (2009-12-29 r50852)
> i686-pc-linux-gnu
>
> locale:
> ?[1] LC_CTYPE=en_US ? ? ? LC_NUMERIC=C ? ? ? ? LC_TIME=en_US
> ?[4] LC_COLLATE=C ? ? ? ? LC_MONETARY=C ? ? ? ?LC_MESSAGES=en_US
> ?[7] LC_PAPER=en_US ? ? ? LC_NAME=C ? ? ? ? ? ?LC_ADDRESS=C
> [10] LC_TELEPHONE=C ? ? ? LC_MEASUREMENT=en_US LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
> loaded via a namespace (and not attached):
> [1] tools_2.10.1
>
> I have installed all of the dependencies in lme4a/DESCRIPTION, including
> Rcpp and the correct version of Matrix. ?The command
> 'R CMD INSTALL lme4a' fails when it gets to the following instruction:
>
> g++ -I/usr/local/lib/R/include ?-I/usr/local/include
> -I"/usr/local/lib/R/library/Matrix/include"
> -I"/usr/local/lib/R/library/Rcpp/include" ? -fpic ?-g -O2 -c glmFamily.cpp
> -o glmFamily.o
>
> One thing I notice is that the one of the -I switches does not match how my
> system is installed (I have not done anything special in my R installation).
>
> Specifically, my version of Rcpp (0.7.11) does not have an include
> directory. ?The header files appear to be in
> /usr/local/lib/R/library/Rcpp/lib
>
> I created a symbolic link for the missing include directory and successfully
> built lme4a.
>
> My question is, how are the -I switches constructed? ?Are they hard-coded in
> the package source somewhere? ?Did something go wrong in my Rcpp install?

The -I switches were constructed from code in lme4a/src/Makevars that
called Rscript and was difficult to maintain.  We (well, primarily
Dirk and Romain) made a change in where the include files for Rcpp
were stored so that the LinkingTo specification in the DESCRIPTION
file is all that is necessary for the includes.

Obviously I have been testing lme4a against the development version of
Rcpp and not against the released version.  Dirk is suggesting a 0.8.0
release of Rcpp, after which I will bump up the dependence of lme4a on
Rcpp.  Short term you could install the development version of Rcpp,
also on R-forge.



From j.hadfield at ed.ac.uk  Thu Apr 15 18:02:04 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 15 Apr 2010 17:02:04 +0100
Subject: [R-sig-ME] MCMCglmm: meta-analysis problem
In-Reply-To: <4BC6FDA1.1040806@ebc.uu.se>
References: <4BC6FDA1.1040806@ebc.uu.se>
Message-ID: <5E0F14C9-93D8-4249-8F79-7FFCDA94BCEC@ed.ac.uk>

Hi Gustaf,

It's not pretty,  but I believe it works:

Rsvd<-svd(Rmat)
Rsvd<-Rsvd$v%*%(t(Rsvd$u)*sqrt(Rsvd$d))
Z<-model.matrix(~Experiment-1, testdata)%*%Rsvd

testdata$Z<-Z

prior=list(R=list(V=1, nu=0), G=list(G1=list(V=1, fix=1)))
m1<-MCMCglmm(y~1, random=~idv(Z), data=testdata, prior=prior)


It works because Z%*%t(Z)  = Rmat, and idv fits a common variance to  
all terms in Z. Since we have fixed this variance to one then the  
random term is essentially fitting Rmat as a known covariance structure.

MCMCglmm always fits random effect meta-analysis, because a) that is  
the way I wrote it and b) I think it is an odd assumption to believe  
that with enough replication every experiment should produce exactly  
the same answer.  Hence this model is fitting i.i.d residuals after  
accounting for (correlated) measurement error.

Cheers,

Jarrod






On 15 Apr 2010, at 12:50, Gustaf Granath wrote:

> Hi,
>
> In a meta-analysis, the SEs of the outcomes are known. However in  
> some cases, the correlation (co-variances) among outcomes are known  
> as well. For example when you have multiple outcomes from one study.  
> I wanted to see if the whole error structure of measurement errors  
> (the R-structure in MCMCglmm, or?) can be passed and not only the  
> diagonal.
>
> ##test data
> testdata<- 
> data 
> .frame 
> (Experiment 
> = 
> as.factor(c(1,2,3,4,5,6,7,8)),Study=c("a","a","b","c","d","d","e","e")
> ,y 
> = 
> c 
> (34,38,45,48,35,28,43,39 
> ),yvar=c(3,5,6,2,3,4,5,7),covar=c(1.5,1.5,NA,NA,2.5,2.5,1.25,1.25))
> Rmat<-diag(8)*testdata$yvar
> Rmat[1,2]<-testdata$covar[1]
> Rmat[2,1]<-testdata$covar[2]
> Rmat[5,6]<-testdata$covar[5]
> Rmat[6,5]<-testdata$covar[6]
> Rmat[7,8]<-testdata$covar[7]
> Rmat[8,7]<-testdata$covar[8]
>
> Rmat is the known covariance structure of the experimental outcomes.
>
> library(MCMCglmm)
> #"normal" meta-analysis using only the diagonal:
> prior = list(R = list(V = 1, n=1,fix = 1),G = list(G1  = list ( V =  
> 1, n = 1)))
> model1 <- MCMCglmm(y ~ 1, random = ~idh(sqrt(yvar)):units ,data =  
> testdata,
>                     prior=prior)
>
> #OR (should be equal right? give sligtly different results though):
> model2 <- MCMCglmm(y ~ 1, random = ~Experiment ,data = testdata,
>                     mev=testdata$yvar,prior=prior)
>
> #Now I want to include the known within-study correlation.
> prior = list(R = list(V = Rmat, fix = 1),G = list(G1  = list ( V =  
> (1), nu = 0.002)))
> model1 <- MCMCglmm(y ~ 1, random = ~idh(Experiment):units, rcov = ~  
> us(Study):Experiment ,data = testdata,
>                     prior=prior)
>
> This did not work (I tried other ways as well but all failed) and I  
> guess that it is because of my R-structure prior. Is there an  
> alternative specification, or? (I played around a little with the  
> "animal" argument but I couldnt get to do what I wanted.)
>
> Cheers,
>
> Gustaf
>
> -- 
>
> Gustaf Granath (PhD student)
>
> Dept of Plant Ecology
> Uppsala University
>
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From bates at stat.wisc.edu  Thu Apr 15 20:04:53 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 15 Apr 2010 13:04:53 -0500
Subject: [R-sig-ME] profile() for lmer
In-Reply-To: <BAY146-w58E5A1470E249E05833DB7A00F0@phx.gbl>
References: <4BC78E22020000A2000275DB@gwia.niwa.co.nz>
	<BAY146-w58E5A1470E249E05833DB7A00F0@phx.gbl>
Message-ID: <l2q40e66e0b1004151104tcf945fd5oce48b0c3dafa11ba@mail.gmail.com>

On Thu, Apr 15, 2010 at 5:40 AM, pierre nouvellet
<pierrenouvellet at hotmail.com> wrote:

> Thanks again to Rob!

> the call to 'profile(fm1ML at env)' ?worked perfectly!
> it is really nice to see it working smoothly!!

Thanks to those who picked up on this.  Both Martin and I have been
doing a lot of development on lme4a in the past couple of weeks,
including fundamental changes to the internal representation.  We
didn't mean to turn the process of determining the profiles into a
treasure hunt - that just sort-of happened.

I should post a warning that the profile is likely to break again in
the near future when I move in the wonderful new and improved class
representation currently lurking around as a resurrected lmer2
function.  We will get the profiling working again after we break it
but there is a lot going on under the hood right now and some breakage
is inevitable.

As others have discovered, lme4a now depends on the Rcpp package and,
inadvertently, on an unreleased version.  That should be fixed soon.

Thanks for your patience.


> pierre
>
>> Date: Thu, 15 Apr 2010 22:07:30 +1200
>> From: p.taylor at niwa.co.nz
>> To: pierrenouvellet at hotmail.com; r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] profile() for lmer
>>
>> Hi Pierre,
>>
>> I'm having the same problem. I discovered a suggestion on another mailing list (stat.ethz.ch/mailman/listinfo/r-help) that using a delta argument would work ie pr1ML<-profile(fm1ML,delta=0.2). However, I have tried that and several smaller steps, but to no avail.
>>
>> I too am using lme4a and R-2.10.1 on windows 2007 professional.
>>
>> Any help from anyone would be greatly appreciated.
>>
>> Paul Taylor
>> Pelagic Fisheries Scientist
>> NIWA
>> New Zealand.
>>
>> >>> pierre nouvellet 04/15/10 4:29 AM >>>
>>
>> Hi,Hi,
>>
>> >From the draft book on lme4:
>> using lme4a, and the dyestuff data, I call profile and get:
>>
>> > profile(fm1ML)
>>
>> Error in UseMethod("profile") :
>>
>> no applicable method for 'profile' applied to an object of class
>> "lmer"
>>
>>
>> any suggestions?
>> using a R-2.10.1 on windows vista
>>
>> pierre
>>
>>
>> _________________________________________________________________
>> Hotmail: Free, trusted and rich email service.
>>
>> [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> NIWA is the trading name of the National Institute of Water & Atmospheric Research Ltd.
>
> _________________________________________________________________
> Hotmail: Powerful Free email with security by Microsoft.
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From kevin.thorpe at utoronto.ca  Thu Apr 15 22:43:57 2010
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Thu, 15 Apr 2010 16:43:57 -0400
Subject: [R-sig-ME] Another case of -1.0 correlation of random effects
In-Reply-To: <4BBF69E3.3050308@utoronto.ca>
References: <4BBF0986.70309@utoronto.ca>	<loom.20100409T143920-273@post.gmane.org>	<4BBF2584.10609@ufl.edu>
	<4BBF69E3.3050308@utoronto.ca>
Message-ID: <4BC77A8D.5010208@utoronto.ca>

Kevin E. Thorpe wrote:
> Ben Bolker wrote:
>> Ken Knoblauch wrote:
>>> Kevin E. Thorpe <kevin.thorpe at ...> writes:
>>>
>>>> My data come from a crossover trial and are balanced.
>>>>
>>>>  > str(gluc)
>>>> 'data.frame':    96 obs. of  4 variables:
>>>>   $ Subject  : int  1 2 3 5 6 7 10 11 12 13 ...
>>>>   $ Treatment: Factor w/ 2 levels "Barley","Oat": 1 1 1 1 1 1 1 1 1 
>>>> 1 ...
>>>>   $ Dose     : int  8 8 8 8 8 8 8 8 8 8 ...
>>>>   $ iAUC     : num  110 256 129 207 244 ...
>>>>
>>>> clip>
>>> Shouldn't you make Subject into a factor?
>>>
>>> Ken
>>>
>>
>>   It would make the plot a little bit prettier but I don't think it
>> matters in this case because variable that appears as a grouping
>> variable (i.e. on the right of the | ) is automatically treated as a
>> factor?  I think?
>>
>>   Since it is really a crossover trial, it would seem reasonable in
>> principle to have the (Treatment|Subject) random effect in there as
>> well. I'm not sure what to do about the -1 correlation: it seems the
>> choices (not necessarily in order) are (1) throw up your hands and say
>> there's not enough data to estimate independently; (2) try WinBUGS,
>> possibly with slightly informative priors; (3) try using lme4a to create
>> profiles of the parameters and see if you can figure out what's 
>> happening.
> 
> Let's see.  I wish (1) was an option.  (2) would be promising if my 
> knowledge of BUGS and Bayesian methods filled more than a thimble. 
> Thanks to Jarrod for his suggestion in response to this.  I'll take a 
> look at that too.  Option (3) is probably worth a go too.
> 
> Aside from the fact that the Dose variable are the actual doses and not 
> categories, and we all know not to categorize continuous variables, what 
> are your thoughts on treating Dose as a factor (since it seems to behave)?
> 
> Thanks all for taking the time to provide your suggestions.
> 
> Kevin
> 
Okay, I now have lme4a installed and I get an error message when I do 
(note: this is the same model from my OP):

 > gluc.lmer1a <- 
lmer(iAUC~Dose+(Dose|Subject),data=gluc,subset=Treatment=="Oat",REML=FALSE)

 > gluc.lmer1a
Linear mixed model fit by maximum likelihood  ['lmer']
Formula: iAUC ~ Dose + (Dose | Subject)
    Data: gluc
  Subset: Treatment == "Oat"
      AIC      BIC   logLik deviance
    575.1    586.3   -281.6    563.1

Random effects:
  Groups   Name        Variance Std.Dev. Corr
  Subject  (Intercept) 7492.19  86.557
           Dose          14.68   3.831   -1.000
  Residual             4727.27  68.755
Number of obs: 48, groups: Subject, 12

Fixed effects:
             Estimate Std. Error t value
(Intercept)  309.352     29.338  10.544
Dose         -14.424      3.533  -4.083

Correlation of Fixed Effects:
      (Intr)
Dose -0.647

 > pr1 <- profile(gluc.lmer1a at env)  ## using @env base on other threads
Error in x[ndat + (1L:deg) - deg] :
   only 0's may be mixed with negative subscripts

Is this because I'm trying to profile a model that profile() cannot 
handle yet, or does it indicate there really are serious problems with 
my model?

I'm at a loss as to how determine what is really going on with these data.

Kevin
-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016



From Gustaf.Granath at ebc.uu.se  Fri Apr 16 11:45:58 2010
From: Gustaf.Granath at ebc.uu.se (Gustaf Granath)
Date: Fri, 16 Apr 2010 11:45:58 +0200
Subject: [R-sig-ME] MCMCglmm: meta-analysis problem
In-Reply-To: <5E0F14C9-93D8-4249-8F79-7FFCDA94BCEC@ed.ac.uk>
References: <4BC6FDA1.1040806@ebc.uu.se>
	<5E0F14C9-93D8-4249-8F79-7FFCDA94BCEC@ed.ac.uk>
Message-ID: <4BC831D6.6000700@ebc.uu.se>

Excellent! Works and the results seem to be reasonable.

However, how would I add a hierarchical level on this?

If we have the model
y=bX + tau2 + V (V=the known co-variance matrix), your code give me b 
and tau2. But there might be another level of dependence in the data, 
for example, research groups (so studies are nested in research groups, 
call it batches). This would lead co-variances within each research 
group (i.e. batch). A common co-variance is ok (at least to start with).
So we get,
y=bX + D + V, (D=tau2*I + hierarchical group blocks with the co-variances)

I have problems to add this. I played around but nothing really worked 
out. I tried the rcov argument:
testdata$Bacth<-Batch=c("a","a","a","b","b","b","c","c")

Ideas?

Cheers,

Gustaf



On 2010-04-15 18:02, Jarrod Hadfield wrote:
> Hi Gustaf,
>
> It's not pretty,  but I believe it works:
>
> Rsvd<-svd(Rmat)
> Rsvd<-Rsvd$v%*%(t(Rsvd$u)*sqrt(Rsvd$d))
> Z<-model.matrix(~Experiment-1, testdata)%*%Rsvd
>
> testdata$Z<-Z
>
> prior=list(R=list(V=1, nu=0), G=list(G1=list(V=1, fix=1)))
> m1<-MCMCglmm(y~1, random=~idv(Z), data=testdata, prior=prior)
>
>
> It works because Z%*%t(Z)  = Rmat, and idv fits a common variance to 
> all terms in Z. Since we have fixed this variance to one then the 
> random term is essentially fitting Rmat as a known covariance structure.
>
> MCMCglmm always fits random effect meta-analysis, because a) that is 
> the way I wrote it and b) I think it is an odd assumption to believe 
> that with enough replication every experiment should produce exactly 
> the same answer.  Hence this model is fitting i.i.d residuals after 
> accounting for (correlated) measurement error.
>
> Cheers,
>
> Jarrod
>
>
>
>
>
>
> On 15 Apr 2010, at 12:50, Gustaf Granath wrote:
>
>> Hi,
>>
>> In a meta-analysis, the SEs of the outcomes are known. However in 
>> some cases, the correlation (co-variances) among outcomes are known 
>> as well. For example when you have multiple outcomes from one study. 
>> I wanted to see if the whole error structure of measurement errors 
>> (the R-structure in MCMCglmm, or?) can be passed and not only the 
>> diagonal.
>>
>> ##test data
>> testdata<-data.frame(Experiment=as.factor(c(1,2,3,4,5,6,7,8)),Study=c("a","a","b","c","d","d","e","e") 
>>
>> ,y=c(34,38,45,48,35,28,43,39),yvar=c(3,5,6,2,3,4,5,7),covar=c(1.5,1.5,NA,NA,2.5,2.5,1.25,1.25)) 
>>
>> Rmat<-diag(8)*testdata$yvar
>> Rmat[1,2]<-testdata$covar[1]
>> Rmat[2,1]<-testdata$covar[2]
>> Rmat[5,6]<-testdata$covar[5]
>> Rmat[6,5]<-testdata$covar[6]
>> Rmat[7,8]<-testdata$covar[7]
>> Rmat[8,7]<-testdata$covar[8]
>>
>> Rmat is the known covariance structure of the experimental outcomes.
>>
>> library(MCMCglmm)
>> #"normal" meta-analysis using only the diagonal:
>> prior = list(R = list(V = 1, n=1,fix = 1),G = list(G1  = list ( V = 
>> 1, n = 1)))
>> model1 <- MCMCglmm(y ~ 1, random = ~idh(sqrt(yvar)):units ,data = 
>> testdata,
>>                     prior=prior)
>>
>> #OR (should be equal right? give sligtly different results though):
>> model2 <- MCMCglmm(y ~ 1, random = ~Experiment ,data = testdata,
>>                     mev=testdata$yvar,prior=prior)
>>
>> #Now I want to include the known within-study correlation.
>> prior = list(R = list(V = Rmat, fix = 1),G = list(G1  = list ( V = 
>> (1), nu = 0.002)))
>> model1 <- MCMCglmm(y ~ 1, random = ~idh(Experiment):units, rcov = ~ 
>> us(Study):Experiment ,data = testdata,
>>                     prior=prior)
>>
>> This did not work (I tried other ways as well but all failed) and I 
>> guess that it is because of my R-structure prior. Is there an 
>> alternative specification, or? (I played around a little with the 
>> "animal" argument but I couldnt get to do what I wanted.)
>>
>> Cheers,
>>
>> Gustaf
>>
>> -- 
>>
>> Gustaf Granath (PhD student)
>>
>> Dept of Plant Ecology
>> Uppsala University
>>
>>
>>
>
>

-- 
Gustaf Granath (PhD student)

Dept of Plant Ecology
Evolutionary Biology Centre (EBC)
Uppsala University
Norbyv?gen 18D, SE - 752 36 Uppsala, Sweden

Tel: +46 (0)18-471 28 82
Email: Gustaf.Granath at ebc.uu.se
http://www.vaxtbio.uu.se/resfold/granath.htm



From andydolman at gmail.com  Fri Apr 16 12:36:50 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Fri, 16 Apr 2010 12:36:50 +0200
Subject: [R-sig-ME] Another case of -1.0 correlation of random effects
In-Reply-To: <4BC77A8D.5010208@utoronto.ca>
References: <4BBF0986.70309@utoronto.ca>
	<loom.20100409T143920-273@post.gmane.org> <4BBF2584.10609@ufl.edu>
	<4BBF69E3.3050308@utoronto.ca> <4BC77A8D.5010208@utoronto.ca>
Message-ID: <u2k951234ac1004160336x4d457317ra346ba45137594bc@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100416/95609f22/attachment.pl>

From Djibril.Dayamba at ess.slu.se  Fri Apr 16 13:59:59 2010
From: Djibril.Dayamba at ess.slu.se (Djibril Dayamba)
Date: Fri, 16 Apr 2010 13:59:59 +0200
Subject: [R-sig-ME] Negative R-squared in linear regression: What's the
	meaning
In-Reply-To: <mailman.5.1271412003.6962.r-sig-mixed-models@r-project.org>
References: <mailman.5.1271412003.6962.r-sig-mixed-models@r-project.org>
Message-ID: <C1CE865EFF7A544789C6C7C46FEF264A38C41A3702@exmbx1.ad.slu.se>

Dear all,
I am trying to run a regression with two variables (Rainfaill and Rainydays) as predictor of species Abundance (Abund). I got a negative adjusted R-squared (-1.055) which is very strange for me; indeed as far as I understand this statistics could never be negative as it is supposed to be the squared value of R.
I would really appreciate if somebody could tell me why is it so and what does this mean in practice (please see the output from R below)?

Regards,

Sidzabda Djibril Dayamba, 
Swedish University of Agricultural Sciences
Faculty of Forest Science
Southern Swedish Forest Research Centre
Tropical Silviculture and Seed Laboratory
PO Box 101
SE - 230 53 Alnarp,
Sweden
Tel: +46 76 83 515 70 (Mobile)
        +46 40 41 53 95 (Office)


> mod1<-lm(Abund~Rain+Rdays)
> summary(mod1)

Call:
lm(formula = Abund ~ Rain + Rdays)

Residuals:
      1       2       3       4 
 0.8104 -3.4108  0.8480  1.7524 

Coefficients:
             Estimate Std. Error t value Pr(>|t|)
(Intercept) 88.444166  27.319474   3.237    0.191
Rain        -0.005913   0.012995  -0.455    0.728
Rdays       -0.112197   0.605448  -0.185    0.883

Residual standard error: 4.01 on 1 degrees of freedom
Multiple R-squared: 0.315,      Adjusted R-squared: -1.055 
F-statistic:  0.23 on 2 and 1 DF,  p-value: 0.8276

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of r-sig-mixed-models-request at r-project.org
Sent: den 16 april 2010 12:00
To: r-sig-mixed-models at r-project.org
Subject: R-sig-mixed-models Digest, Vol 40, Issue 33

Send R-sig-mixed-models mailing list submissions to
	r-sig-mixed-models at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
or, via email, send a message with subject or body 'help' to
	r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
	r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

   1. Re: profile() for lmer (Douglas Bates)
   2. Re: Another case of -1.0 correlation of random effects
      (Kevin E. Thorpe)
   3. Re: MCMCglmm: meta-analysis problem (Gustaf Granath)


----------------------------------------------------------------------

Message: 1
Date: Thu, 15 Apr 2010 13:04:53 -0500
From: Douglas Bates <bates at stat.wisc.edu>
To: pierre nouvellet <pierrenouvellet at hotmail.com>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] profile() for lmer
Message-ID:
	<l2q40e66e0b1004151104tcf945fd5oce48b0c3dafa11ba at mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1

On Thu, Apr 15, 2010 at 5:40 AM, pierre nouvellet
<pierrenouvellet at hotmail.com> wrote:

> Thanks again to Rob!

> the call to 'profile(fm1ML at env)' ?worked perfectly!
> it is really nice to see it working smoothly!!

Thanks to those who picked up on this.  Both Martin and I have been
doing a lot of development on lme4a in the past couple of weeks,
including fundamental changes to the internal representation.  We
didn't mean to turn the process of determining the profiles into a
treasure hunt - that just sort-of happened.

I should post a warning that the profile is likely to break again in
the near future when I move in the wonderful new and improved class
representation currently lurking around as a resurrected lmer2
function.  We will get the profiling working again after we break it
but there is a lot going on under the hood right now and some breakage
is inevitable.

As others have discovered, lme4a now depends on the Rcpp package and,
inadvertently, on an unreleased version.  That should be fixed soon.

Thanks for your patience.


> pierre
>
>> Date: Thu, 15 Apr 2010 22:07:30 +1200
>> From: p.taylor at niwa.co.nz
>> To: pierrenouvellet at hotmail.com; r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] profile() for lmer
>>
>> Hi Pierre,
>>
>> I'm having the same problem. I discovered a suggestion on another mailing list (stat.ethz.ch/mailman/listinfo/r-help) that using a delta argument would work ie pr1ML<-profile(fm1ML,delta=0.2). However, I have tried that and several smaller steps, but to no avail.
>>
>> I too am using lme4a and R-2.10.1 on windows 2007 professional.
>>
>> Any help from anyone would be greatly appreciated.
>>
>> Paul Taylor
>> Pelagic Fisheries Scientist
>> NIWA
>> New Zealand.
>>
>> >>> pierre nouvellet 04/15/10 4:29 AM >>>
>>
>> Hi,Hi,
>>
>> >From the draft book on lme4:
>> using lme4a, and the dyestuff data, I call profile and get:
>>
>> > profile(fm1ML)
>>
>> Error in UseMethod("profile") :
>>
>> no applicable method for 'profile' applied to an object of class
>> "lmer"
>>
>>
>> any suggestions?
>> using a R-2.10.1 on windows vista
>>
>> pierre
>>
>>
>> _________________________________________________________________
>> Hotmail: Free, trusted and rich email service.
>>
>> [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> NIWA is the trading name of the National Institute of Water & Atmospheric Research Ltd.
>
> _________________________________________________________________
> Hotmail: Powerful Free email with security by Microsoft.
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



------------------------------

Message: 2
Date: Thu, 15 Apr 2010 16:43:57 -0400
From: "Kevin E. Thorpe" <kevin.thorpe at utoronto.ca>
To: "r-sig-mixed-models at r-project.org"
	<r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Another case of -1.0 correlation of random
	effects
Message-ID: <4BC77A8D.5010208 at utoronto.ca>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed

Kevin E. Thorpe wrote:
> Ben Bolker wrote:
>> Ken Knoblauch wrote:
>>> Kevin E. Thorpe <kevin.thorpe at ...> writes:
>>>
>>>> My data come from a crossover trial and are balanced.
>>>>
>>>>  > str(gluc)
>>>> 'data.frame':    96 obs. of  4 variables:
>>>>   $ Subject  : int  1 2 3 5 6 7 10 11 12 13 ...
>>>>   $ Treatment: Factor w/ 2 levels "Barley","Oat": 1 1 1 1 1 1 1 1 1 
>>>> 1 ...
>>>>   $ Dose     : int  8 8 8 8 8 8 8 8 8 8 ...
>>>>   $ iAUC     : num  110 256 129 207 244 ...
>>>>
>>>> clip>
>>> Shouldn't you make Subject into a factor?
>>>
>>> Ken
>>>
>>
>>   It would make the plot a little bit prettier but I don't think it
>> matters in this case because variable that appears as a grouping
>> variable (i.e. on the right of the | ) is automatically treated as a
>> factor?  I think?
>>
>>   Since it is really a crossover trial, it would seem reasonable in
>> principle to have the (Treatment|Subject) random effect in there as
>> well. I'm not sure what to do about the -1 correlation: it seems the
>> choices (not necessarily in order) are (1) throw up your hands and say
>> there's not enough data to estimate independently; (2) try WinBUGS,
>> possibly with slightly informative priors; (3) try using lme4a to create
>> profiles of the parameters and see if you can figure out what's 
>> happening.
> 
> Let's see.  I wish (1) was an option.  (2) would be promising if my 
> knowledge of BUGS and Bayesian methods filled more than a thimble. 
> Thanks to Jarrod for his suggestion in response to this.  I'll take a 
> look at that too.  Option (3) is probably worth a go too.
> 
> Aside from the fact that the Dose variable are the actual doses and not 
> categories, and we all know not to categorize continuous variables, what
> are your thoughts on treating Dose as a factor (since it seems to behave)?
> 
> Thanks all for taking the time to provide your suggestions.
> 
> Kevin
> 
Okay, I now have lme4a installed and I get an error message when I do 
(note: this is the same model from my OP):

 > gluc.lmer1a <- 
lmer(iAUC~Dose+(Dose|Subject),data=gluc,subset=Treatment=="Oat",REML=FALSE)

 > gluc.lmer1a
Linear mixed model fit by maximum likelihood  ['lmer']
Formula: iAUC ~ Dose + (Dose | Subject)
    Data: gluc
  Subset: Treatment == "Oat"
      AIC      BIC   logLik deviance
    575.1    586.3   -281.6    563.1

Random effects:
  Groups   Name        Variance Std.Dev. Corr
  Subject  (Intercept) 7492.19  86.557
           Dose          14.68   3.831   -1.000
  Residual             4727.27  68.755
Number of obs: 48, groups: Subject, 12

Fixed effects:
             Estimate Std. Error t value
(Intercept)  309.352     29.338  10.544
Dose         -14.424      3.533  -4.083

Correlation of Fixed Effects:
      (Intr)
Dose -0.647

 > pr1 <- profile(gluc.lmer1a at env)  ## using @env base on other threads
Error in x[ndat + (1L:deg) - deg] :
   only 0's may be mixed with negative subscripts

Is this because I'm trying to profile a model that profile() cannot 
handle yet, or does it indicate there really are serious problems with 
my model?

I'm at a loss as to how determine what is really going on with these data.

Kevin
-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016



------------------------------

Message: 3
Date: Fri, 16 Apr 2010 11:45:58 +0200
From: Gustaf Granath <Gustaf.Granath at ebc.uu.se>
To: Jarrod Hadfield <j.hadfield at ed.ac.uk>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] MCMCglmm: meta-analysis problem
Message-ID: <4BC831D6.6000700 at ebc.uu.se>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed

Excellent! Works and the results seem to be reasonable.

However, how would I add a hierarchical level on this?

If we have the model
y=bX + tau2 + V (V=the known co-variance matrix), your code give me b 
and tau2. But there might be another level of dependence in the data, 
for example, research groups (so studies are nested in research groups, 
call it batches). This would lead co-variances within each research 
group (i.e. batch). A common co-variance is ok (at least to start with).
So we get,
y=bX + D + V, (D=tau2*I + hierarchical group blocks with the co-variances)

I have problems to add this. I played around but nothing really worked 
out. I tried the rcov argument:
testdata$Bacth<-Batch=c("a","a","a","b","b","b","c","c")

Ideas?

Cheers,

Gustaf



On 2010-04-15 18:02, Jarrod Hadfield wrote:
> Hi Gustaf,
>
> It's not pretty,  but I believe it works:
>
> Rsvd<-svd(Rmat)
> Rsvd<-Rsvd$v%*%(t(Rsvd$u)*sqrt(Rsvd$d))
> Z<-model.matrix(~Experiment-1, testdata)%*%Rsvd
>
> testdata$Z<-Z
>
> prior=list(R=list(V=1, nu=0), G=list(G1=list(V=1, fix=1)))
> m1<-MCMCglmm(y~1, random=~idv(Z), data=testdata, prior=prior)
>
>
> It works because Z%*%t(Z)  = Rmat, and idv fits a common variance to 
> all terms in Z. Since we have fixed this variance to one then the 
> random term is essentially fitting Rmat as a known covariance structure.
>
> MCMCglmm always fits random effect meta-analysis, because a) that is 
> the way I wrote it and b) I think it is an odd assumption to believe 
> that with enough replication every experiment should produce exactly 
> the same answer.  Hence this model is fitting i.i.d residuals after 
> accounting for (correlated) measurement error.
>
> Cheers,
>
> Jarrod
>
>
>
>
>
>
> On 15 Apr 2010, at 12:50, Gustaf Granath wrote:
>
>> Hi,
>>
>> In a meta-analysis, the SEs of the outcomes are known. However in 
>> some cases, the correlation (co-variances) among outcomes are known 
>> as well. For example when you have multiple outcomes from one study. 
>> I wanted to see if the whole error structure of measurement errors 
>> (the R-structure in MCMCglmm, or?) can be passed and not only the 
>> diagonal.
>>
>> ##test data
>> testdata<-data.frame(Experiment=as.factor(c(1,2,3,4,5,6,7,8)),Study=c("a","a","b","c","d","d","e","e") 
>>
>> ,y=c(34,38,45,48,35,28,43,39),yvar=c(3,5,6,2,3,4,5,7),covar=c(1.5,1.5,NA,NA,2.5,2.5,1.25,1.25)) 
>>
>> Rmat<-diag(8)*testdata$yvar
>> Rmat[1,2]<-testdata$covar[1]
>> Rmat[2,1]<-testdata$covar[2]
>> Rmat[5,6]<-testdata$covar[5]
>> Rmat[6,5]<-testdata$covar[6]
>> Rmat[7,8]<-testdata$covar[7]
>> Rmat[8,7]<-testdata$covar[8]
>>
>> Rmat is the known covariance structure of the experimental outcomes.
>>
>> library(MCMCglmm)
>> #"normal" meta-analysis using only the diagonal:
>> prior = list(R = list(V = 1, n=1,fix = 1),G = list(G1  = list ( V = 
>> 1, n = 1)))
>> model1 <- MCMCglmm(y ~ 1, random = ~idh(sqrt(yvar)):units ,data = 
>> testdata,
>>                     prior=prior)
>>
>> #OR (should be equal right? give sligtly different results though):
>> model2 <- MCMCglmm(y ~ 1, random = ~Experiment ,data = testdata,
>>                     mev=testdata$yvar,prior=prior)
>>
>> #Now I want to include the known within-study correlation.
>> prior = list(R = list(V = Rmat, fix = 1),G = list(G1  = list ( V = 
>> (1), nu = 0.002)))
>> model1 <- MCMCglmm(y ~ 1, random = ~idh(Experiment):units, rcov = ~
>> us(Study):Experiment ,data = testdata,
>>                     prior=prior)
>>
>> This did not work (I tried other ways as well but all failed) and I 
>> guess that it is because of my R-structure prior. Is there an 
>> alternative specification, or? (I played around a little with the 
>> "animal" argument but I couldnt get to do what I wanted.)
>>
>> Cheers,
>>
>> Gustaf
>>
>> -- 
>>
>> Gustaf Granath (PhD student)
>>
>> Dept of Plant Ecology
>> Uppsala University
>>
>>
>>
>
>

-- 
Gustaf Granath (PhD student)

Dept of Plant Ecology
Evolutionary Biology Centre (EBC)
Uppsala University
Norbyv?gen 18D, SE - 752 36 Uppsala, Sweden

Tel: +46 (0)18-471 28 82
Email: Gustaf.Granath at ebc.uu.se
http://www.vaxtbio.uu.se/resfold/granath.htm



------------------------------

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


End of R-sig-mixed-models Digest, Vol 40, Issue 33



From kevin.thorpe at utoronto.ca  Fri Apr 16 14:22:18 2010
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Fri, 16 Apr 2010 08:22:18 -0400
Subject: [R-sig-ME] Another case of -1.0 correlation of random effects
In-Reply-To: <u2k951234ac1004160336x4d457317ra346ba45137594bc@mail.gmail.com>
References: <4BBF0986.70309@utoronto.ca>	
	<loom.20100409T143920-273@post.gmane.org>
	<4BBF2584.10609@ufl.edu>	 <4BBF69E3.3050308@utoronto.ca>
	<4BC77A8D.5010208@utoronto.ca>
	<u2k951234ac1004160336x4d457317ra346ba45137594bc@mail.gmail.com>
Message-ID: <4BC8567A.1060903@utoronto.ca>

Andrew Dolman wrote:
> Is it possible to post your data, or a dummy data set, so that we can 
> definitely rule out a structural problem? Do you get the same problem 
> with a dummy dataset?
> 
> The function dump("myData", file=stdout()) might be useful.
> 
> Andy.
> 
> 
> andydolman at gmail.com <mailto:andydolman at gmail.com>
> 
> 
> 
> 

You should be able to get it with

load(url("http://www.kevinthorpe.ca/~kevin/gluc.RData"))

The profile function did work with the Diestuff example in chapter 1 of 
the lme4 book, so I know that profile() is working.


-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016



From andydolman at gmail.com  Fri Apr 16 15:40:41 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Fri, 16 Apr 2010 15:40:41 +0200
Subject: [R-sig-ME] Another case of -1.0 correlation of random effects
In-Reply-To: <4BC8567A.1060903@utoronto.ca>
References: <4BBF0986.70309@utoronto.ca>
	<loom.20100409T143920-273@post.gmane.org> <4BBF2584.10609@ufl.edu>
	<4BBF69E3.3050308@utoronto.ca> <4BC77A8D.5010208@utoronto.ca>
	<u2k951234ac1004160336x4d457317ra346ba45137594bc@mail.gmail.com>
	<4BC8567A.1060903@utoronto.ca>
Message-ID: <u2o951234ac1004160640xefe11b11t6fac17a03586bdbb@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100416/368e8ab6/attachment.pl>

From kevin.thorpe at utoronto.ca  Fri Apr 16 15:53:37 2010
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Fri, 16 Apr 2010 09:53:37 -0400
Subject: [R-sig-ME] Another case of -1.0 correlation of random effects
In-Reply-To: <u2o951234ac1004160640xefe11b11t6fac17a03586bdbb@mail.gmail.com>
References: <4BBF0986.70309@utoronto.ca>	
	<loom.20100409T143920-273@post.gmane.org>
	<4BBF2584.10609@ufl.edu>	 <4BBF69E3.3050308@utoronto.ca>
	<4BC77A8D.5010208@utoronto.ca>	
	<u2k951234ac1004160336x4d457317ra346ba45137594bc@mail.gmail.com>	
	<4BC8567A.1060903@utoronto.ca>
	<u2o951234ac1004160640xefe11b11t6fac17a03586bdbb@mail.gmail.com>
Message-ID: <4BC86BE1.9080707@utoronto.ca>

Andrew Dolman wrote:
> Shouldn't your preferred model be coded:
> 
> (lmer1 <- lmer(iAUC~Treatment+Dose+(Treatment+Dose|Subject),data=gluc))
> 
> 
> Linear mixed model fit by REML
> Formula: iAUC ~ Treatment + Dose + (Treatment + Dose | Subject)
>    Data: gluc
>   AIC  BIC logLik deviance REMLdev
>  1107 1132 -543.3     1106    1087
> Random effects:
>  Groups   Name         Variance Std.Dev. Corr         
>  Subject  (Intercept)  8402.295 91.6640               
>           TreatmentOat 1736.103 41.6666  -0.097       
>           Dose           30.774  5.5474  -0.883 -0.335
>  Residual              4100.082 64.0319               
> Number of obs: 96, groups: Subject, 12
> 
> Fixed effects:
>              Estimate Std. Error t value
> (Intercept)   313.198     29.076  10.772
> TreatmentOat   -6.673     17.763  -0.376
> Dose          -13.617      2.729  -4.990
> 
> Correlation of Fixed Effects:
>             (Intr) TrtmnO
> TreatmentOt -0.225      
> Dose        -0.687 -0.133
> 
> 
> Which kind of works but you still have a very high correlation between 2 
> random effects.
> 
> 
> Your problems stem, i think, from the fact that there's a very high 
> correlation between the slope of Dose and the Intercept, i.e. subjects 
> with initially higher iAUC respond more strongly to increasing doses of 
> the treatment. You can help the estimation by re-coding Dose so that the 
> intercept is estimated for the highest dose rather than the smallest.
> 
> 
> (lmer1 <- 
> lmer(iAUC~Treatment+I(Dose-8)+(Treatment+I(Dose-8)|Subject),data=gluc))
> 
> Linear mixed model fit by REML
> Formula: iAUC ~ Treatment + I(Dose - 8) + (Treatment + I(Dose - 8) | 
> Subject)
>    Data: gluc
>   AIC  BIC logLik deviance REMLdev
>  1107 1132 -543.3     1106    1087
> Random effects:
>  Groups   Name         Variance Std.Dev. Corr         
>  Subject  (Intercept)  3189.270 56.4736               
>           TreatmentOat 1736.099 41.6665  -0.421       
>           I(Dose - 8)    30.773  5.5474  -0.647 -0.335
>  Residual              4100.085 64.0319               
> Number of obs: 96, groups: Subject, 12
> 
> Fixed effects:
>              Estimate Std. Error t value
> (Intercept)   204.264     21.214   9.629
> TreatmentOat   -6.673     17.763  -0.376
> I(Dose - 8)   -13.617      2.729  -4.990
> 
> Correlation of Fixed Effects:
>             (Intr) TrtmnO
> TreatmentOt -0.446      
> I(Dose - 8)  0.088 -0.133
>  
> 
> Andy.

Thank you very much Andy.  This is extremely helpful.

Thanks also to everyone else who looked at my problem and made 
suggestions.  Mixed-effects models are relatively new to me and I still 
feel not quite at home with them.

Kevin

-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016



From andydolman at gmail.com  Fri Apr 16 17:26:53 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Fri, 16 Apr 2010 17:26:53 +0200
Subject: [R-sig-ME] Another case of -1.0 correlation of random effects
In-Reply-To: <4BC87BB1.4000001@utoronto.ca>
References: <4BBF0986.70309@utoronto.ca>
	<loom.20100409T143920-273@post.gmane.org> <4BBF2584.10609@ufl.edu>
	<4BBF69E3.3050308@utoronto.ca> <4BC77A8D.5010208@utoronto.ca>
	<u2k951234ac1004160336x4d457317ra346ba45137594bc@mail.gmail.com>
	<4BC8567A.1060903@utoronto.ca>
	<u2o951234ac1004160640xefe11b11t6fac17a03586bdbb@mail.gmail.com>
	<4BC87BB1.4000001@utoronto.ca>
Message-ID: <s2h951234ac1004160826i9ac1a80fve663a65fd6150612@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100416/047d6da1/attachment.pl>

From kevin.thorpe at utoronto.ca  Fri Apr 16 17:31:55 2010
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Fri, 16 Apr 2010 11:31:55 -0400
Subject: [R-sig-ME] Another case of -1.0 correlation of random effects
In-Reply-To: <s2h951234ac1004160826i9ac1a80fve663a65fd6150612@mail.gmail.com>
References: <4BBF0986.70309@utoronto.ca>	
	<loom.20100409T143920-273@post.gmane.org>
	<4BBF2584.10609@ufl.edu>	 <4BBF69E3.3050308@utoronto.ca>
	<4BC77A8D.5010208@utoronto.ca>	
	<u2k951234ac1004160336x4d457317ra346ba45137594bc@mail.gmail.com>	
	<4BC8567A.1060903@utoronto.ca>	
	<u2o951234ac1004160640xefe11b11t6fac17a03586bdbb@mail.gmail.com>	
	<4BC87BB1.4000001@utoronto.ca>
	<s2h951234ac1004160826i9ac1a80fve663a65fd6150612@mail.gmail.com>
Message-ID: <4BC882EB.9080203@utoronto.ca>

Andrew Dolman wrote:
> No problem,
> 
> lme1 <- lme(iAUC~Treatment+I(Dose-8), 
> random=~Treatment+I(Dose-8)|Subject,data=gluc)
> summary(lme1)
> 
> works fine for me.
> 
> Your problem might have been that you had lmer and nlme loaded at the 
> same time, or it might just have been the spelling mistake (+Does)
> 
> 
> Andy.

Smacks head!

It was a spelling mistake, just not the one in my email.  I spelled lme 
as lmer.  Clearly, that won't work! :-)

Thanks again.

> 
> 
> andydolman at gmail.com <mailto:andydolman at gmail.com>
> 
> 
>     Maybe, since the data are balanced, I could use lme(), but I have no
>     clue how to specify this random effect structure there.  I tried
>     random=~Treatment+Does|Subject but lme() didn't like that.
> 
>     Thanks for listening.  I appreciate all you've done already.
> 
>     Kevin
> 


-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016



From izod3 at yahoo.com  Sat Apr 17 08:17:36 2010
From: izod3 at yahoo.com (Wkoef Slknfd)
Date: Fri, 16 Apr 2010 23:17:36 -0700 (PDT)
Subject: [R-sig-ME] cancel my email from your list!!!!!!!!
Message-ID: <837290.91020.qm@web113704.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100416/f08e9578/attachment.pl>

From julien.martin2 at usherbrooke.ca  Sun Apr 18 00:01:43 2010
From: julien.martin2 at usherbrooke.ca (Julien Martin)
Date: Sat, 17 Apr 2010 18:01:43 -0400
Subject: [R-sig-ME] confidence intervals of VPC
Message-ID: <BLU0-SMTP175D2965E3C3BA09EF94B8C20D0@phx.gbl>

Hi
when using a model mixed with both a random intercept and slope such as 
lmer( y ~ x + ( x | group) )
we could computed the variance partition coefficient (VPC) as suggested 
by Goldstein et al 2002.
VPC_x = (Vi + X*cov(I,S) + X^2 * Vs) / (Vi + X * cov(I,S) + X^2 * Vs + Vr)
I am wondering how we could obtain confidence intervals for VPC using lmer.
Thanks
Julien



From andy_liaw at merck.com  Tue Apr 20 15:02:58 2010
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 20 Apr 2010 09:02:58 -0400
Subject: [R-sig-ME] Negative R-squared in linear regression: What's
	themeaning
In-Reply-To: <C1CE865EFF7A544789C6C7C46FEF264A38C41A3702@exmbx1.ad.slu.se>
References: <mailman.5.1271412003.6962.r-sig-mixed-models@r-project.org>
	<C1CE865EFF7A544789C6C7C46FEF264A38C41A3702@exmbx1.ad.slu.se>
Message-ID: <B10BAA7D28D88B45AF82813C4A6FFA936D5E14@usctmx1157.merck.com>

I don't know if you got any reply off-list, but I didn't see any coming
through the mailing list, so...

The negative value is for the "adjusted" R-squared, and there's no
guarantee that that has to be non-negative.  In your case you only have
one degree of freedom for error, thus maximizing the chance for that
statistic to have a negative value.  R-squared is 1 - SSE/SStotal, and
indeed is equivalent to squared correlation between response and fitted
values, but adjusted R-squared is 1 - MSE/MStotal, and that need not be
positive, and does not correspond to squared correlation.

If you are fitting a model with 1 df for error, you need to learn the
danger of doing usual inference with such a model.

Andy 

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
> Of Djibril Dayamba
> Sent: Friday, April 16, 2010 8:00 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Negative R-squared in linear regression: 
> What's themeaning
> 
> Dear all,
> I am trying to run a regression with two variables (Rainfaill 
> and Rainydays) as predictor of species Abundance (Abund). I 
> got a negative adjusted R-squared (-1.055) which is very 
> strange for me; indeed as far as I understand this statistics 
> could never be negative as it is supposed to be the squared 
> value of R.
> I would really appreciate if somebody could tell me why is it 
> so and what does this mean in practice (please see the output 
> from R below)?
> 
> Regards,
> 
> Sidzabda Djibril Dayamba, 
> Swedish University of Agricultural Sciences
> Faculty of Forest Science
> Southern Swedish Forest Research Centre
> Tropical Silviculture and Seed Laboratory
> PO Box 101
> SE - 230 53 Alnarp,
> Sweden
> Tel: +46 76 83 515 70 (Mobile)
>         +46 40 41 53 95 (Office)
> 
> 
> > mod1<-lm(Abund~Rain+Rdays)
> > summary(mod1)
> 
> Call:
> lm(formula = Abund ~ Rain + Rdays)
> 
> Residuals:
>       1       2       3       4 
>  0.8104 -3.4108  0.8480  1.7524 
> 
> Coefficients:
>              Estimate Std. Error t value Pr(>|t|)
> (Intercept) 88.444166  27.319474   3.237    0.191
> Rain        -0.005913   0.012995  -0.455    0.728
> Rdays       -0.112197   0.605448  -0.185    0.883
> 
> Residual standard error: 4.01 on 1 degrees of freedom
> Multiple R-squared: 0.315,      Adjusted R-squared: -1.055 
> F-statistic:  0.23 on 2 and 1 DF,  p-value: 0.8276
> 
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
> Of r-sig-mixed-models-request at r-project.org
> Sent: den 16 april 2010 12:00
> To: r-sig-mixed-models at r-project.org
> Subject: R-sig-mixed-models Digest, Vol 40, Issue 33
> 
> Send R-sig-mixed-models mailing list submissions to
> 	r-sig-mixed-models at r-project.org
> 
> To subscribe or unsubscribe via the World Wide Web, visit
> 	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help' to
> 	r-sig-mixed-models-request at r-project.org
> 
> You can reach the person managing the list at
> 	r-sig-mixed-models-owner at r-project.org
> 
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-sig-mixed-models digest..."
> 
> 
> Today's Topics:
> 
>    1. Re: profile() for lmer (Douglas Bates)
>    2. Re: Another case of -1.0 correlation of random effects
>       (Kevin E. Thorpe)
>    3. Re: MCMCglmm: meta-analysis problem (Gustaf Granath)
> 
> 
> ----------------------------------------------------------------------
> 
> Message: 1
> Date: Thu, 15 Apr 2010 13:04:53 -0500
> From: Douglas Bates <bates at stat.wisc.edu>
> To: pierre nouvellet <pierrenouvellet at hotmail.com>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] profile() for lmer
> Message-ID:
> 	<l2q40e66e0b1004151104tcf945fd5oce48b0c3dafa11ba at mail.gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1
> 
> On Thu, Apr 15, 2010 at 5:40 AM, pierre nouvellet
> <pierrenouvellet at hotmail.com> wrote:
> 
> > Thanks again to Rob!
> 
> > the call to 'profile(fm1ML at env)' ?worked perfectly!
> > it is really nice to see it working smoothly!!
> 
> Thanks to those who picked up on this.  Both Martin and I have been
> doing a lot of development on lme4a in the past couple of weeks,
> including fundamental changes to the internal representation.  We
> didn't mean to turn the process of determining the profiles into a
> treasure hunt - that just sort-of happened.
> 
> I should post a warning that the profile is likely to break again in
> the near future when I move in the wonderful new and improved class
> representation currently lurking around as a resurrected lmer2
> function.  We will get the profiling working again after we break it
> but there is a lot going on under the hood right now and some breakage
> is inevitable.
> 
> As others have discovered, lme4a now depends on the Rcpp package and,
> inadvertently, on an unreleased version.  That should be fixed soon.
> 
> Thanks for your patience.
> 
> 
> > pierre
> >
> >> Date: Thu, 15 Apr 2010 22:07:30 +1200
> >> From: p.taylor at niwa.co.nz
> >> To: pierrenouvellet at hotmail.com; r-sig-mixed-models at r-project.org
> >> Subject: Re: [R-sig-ME] profile() for lmer
> >>
> >> Hi Pierre,
> >>
> >> I'm having the same problem. I discovered a suggestion on 
> another mailing list (stat.ethz.ch/mailman/listinfo/r-help) 
> that using a delta argument would work ie 
> pr1ML<-profile(fm1ML,delta=0.2). However, I have tried that 
> and several smaller steps, but to no avail.
> >>
> >> I too am using lme4a and R-2.10.1 on windows 2007 professional.
> >>
> >> Any help from anyone would be greatly appreciated.
> >>
> >> Paul Taylor
> >> Pelagic Fisheries Scientist
> >> NIWA
> >> New Zealand.
> >>
> >> >>> pierre nouvellet 04/15/10 4:29 AM >>>
> >>
> >> Hi,Hi,
> >>
> >> >From the draft book on lme4:
> >> using lme4a, and the dyestuff data, I call profile and get:
> >>
> >> > profile(fm1ML)
> >>
> >> Error in UseMethod("profile") :
> >>
> >> no applicable method for 'profile' applied to an object of class
> >> "lmer"
> >>
> >>
> >> any suggestions?
> >> using a R-2.10.1 on windows vista
> >>
> >> pierre
> >>
> >>
> >> _________________________________________________________________
> >> Hotmail: Free, trusted and rich email service.
> >>
> >> [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> NIWA is the trading name of the National Institute of 
> Water & Atmospheric Research Ltd.
> >
> > _________________________________________________________________
> > Hotmail: Powerful Free email with security by Microsoft.
> >
> > ? ? ? ?[[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
> 
> 
> ------------------------------
> 
> Message: 2
> Date: Thu, 15 Apr 2010 16:43:57 -0400
> From: "Kevin E. Thorpe" <kevin.thorpe at utoronto.ca>
> To: "r-sig-mixed-models at r-project.org"
> 	<r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] Another case of -1.0 correlation of random
> 	effects
> Message-ID: <4BC77A8D.5010208 at utoronto.ca>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
> 
> Kevin E. Thorpe wrote:
> > Ben Bolker wrote:
> >> Ken Knoblauch wrote:
> >>> Kevin E. Thorpe <kevin.thorpe at ...> writes:
> >>>
> >>>> My data come from a crossover trial and are balanced.
> >>>>
> >>>>  > str(gluc)
> >>>> 'data.frame':    96 obs. of  4 variables:
> >>>>   $ Subject  : int  1 2 3 5 6 7 10 11 12 13 ...
> >>>>   $ Treatment: Factor w/ 2 levels "Barley","Oat": 1 1 1 
> 1 1 1 1 1 1 
> >>>> 1 ...
> >>>>   $ Dose     : int  8 8 8 8 8 8 8 8 8 8 ...
> >>>>   $ iAUC     : num  110 256 129 207 244 ...
> >>>>
> >>>> clip>
> >>> Shouldn't you make Subject into a factor?
> >>>
> >>> Ken
> >>>
> >>
> >>   It would make the plot a little bit prettier but I don't think it
> >> matters in this case because variable that appears as a grouping
> >> variable (i.e. on the right of the | ) is automatically 
> treated as a
> >> factor?  I think?
> >>
> >>   Since it is really a crossover trial, it would seem reasonable in
> >> principle to have the (Treatment|Subject) random effect in there as
> >> well. I'm not sure what to do about the -1 correlation: it 
> seems the
> >> choices (not necessarily in order) are (1) throw up your 
> hands and say
> >> there's not enough data to estimate independently; (2) try WinBUGS,
> >> possibly with slightly informative priors; (3) try using 
> lme4a to create
> >> profiles of the parameters and see if you can figure out what's 
> >> happening.
> > 
> > Let's see.  I wish (1) was an option.  (2) would be promising if my 
> > knowledge of BUGS and Bayesian methods filled more than a thimble. 
> > Thanks to Jarrod for his suggestion in response to this.  
> I'll take a 
> > look at that too.  Option (3) is probably worth a go too.
> > 
> > Aside from the fact that the Dose variable are the actual 
> doses and not 
> > categories, and we all know not to categorize continuous 
> variables, what
> > are your thoughts on treating Dose as a factor (since it 
> seems to behave)?
> > 
> > Thanks all for taking the time to provide your suggestions.
> > 
> > Kevin
> > 
> Okay, I now have lme4a installed and I get an error message when I do 
> (note: this is the same model from my OP):
> 
>  > gluc.lmer1a <- 
> lmer(iAUC~Dose+(Dose|Subject),data=gluc,subset=Treatment=="Oat
> ",REML=FALSE)
> 
>  > gluc.lmer1a
> Linear mixed model fit by maximum likelihood  ['lmer']
> Formula: iAUC ~ Dose + (Dose | Subject)
>     Data: gluc
>   Subset: Treatment == "Oat"
>       AIC      BIC   logLik deviance
>     575.1    586.3   -281.6    563.1
> 
> Random effects:
>   Groups   Name        Variance Std.Dev. Corr
>   Subject  (Intercept) 7492.19  86.557
>            Dose          14.68   3.831   -1.000
>   Residual             4727.27  68.755
> Number of obs: 48, groups: Subject, 12
> 
> Fixed effects:
>              Estimate Std. Error t value
> (Intercept)  309.352     29.338  10.544
> Dose         -14.424      3.533  -4.083
> 
> Correlation of Fixed Effects:
>       (Intr)
> Dose -0.647
> 
>  > pr1 <- profile(gluc.lmer1a at env)  ## using @env base on 
> other threads
> Error in x[ndat + (1L:deg) - deg] :
>    only 0's may be mixed with negative subscripts
> 
> Is this because I'm trying to profile a model that profile() cannot 
> handle yet, or does it indicate there really are serious 
> problems with 
> my model?
> 
> I'm at a loss as to how determine what is really going on 
> with these data.
> 
> Kevin
> -- 
> Kevin E. Thorpe
> Biostatistician/Trialist, Knowledge Translation Program
> Assistant Professor, Dalla Lana School of Public Health
> University of Toronto
> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
> 
> 
> 
> ------------------------------
> 
> Message: 3
> Date: Fri, 16 Apr 2010 11:45:58 +0200
> From: Gustaf Granath <Gustaf.Granath at ebc.uu.se>
> To: Jarrod Hadfield <j.hadfield at ed.ac.uk>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] MCMCglmm: meta-analysis problem
> Message-ID: <4BC831D6.6000700 at ebc.uu.se>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
> 
> Excellent! Works and the results seem to be reasonable.
> 
> However, how would I add a hierarchical level on this?
> 
> If we have the model
> y=bX + tau2 + V (V=the known co-variance matrix), your code give me b 
> and tau2. But there might be another level of dependence in the data, 
> for example, research groups (so studies are nested in 
> research groups, 
> call it batches). This would lead co-variances within each research 
> group (i.e. batch). A common co-variance is ok (at least to 
> start with).
> So we get,
> y=bX + D + V, (D=tau2*I + hierarchical group blocks with the 
> co-variances)
> 
> I have problems to add this. I played around but nothing 
> really worked 
> out. I tried the rcov argument:
> testdata$Bacth<-Batch=c("a","a","a","b","b","b","c","c")
> 
> Ideas?
> 
> Cheers,
> 
> Gustaf
> 
> 
> 
> On 2010-04-15 18:02, Jarrod Hadfield wrote:
> > Hi Gustaf,
> >
> > It's not pretty,  but I believe it works:
> >
> > Rsvd<-svd(Rmat)
> > Rsvd<-Rsvd$v%*%(t(Rsvd$u)*sqrt(Rsvd$d))
> > Z<-model.matrix(~Experiment-1, testdata)%*%Rsvd
> >
> > testdata$Z<-Z
> >
> > prior=list(R=list(V=1, nu=0), G=list(G1=list(V=1, fix=1)))
> > m1<-MCMCglmm(y~1, random=~idv(Z), data=testdata, prior=prior)
> >
> >
> > It works because Z%*%t(Z)  = Rmat, and idv fits a common 
> variance to 
> > all terms in Z. Since we have fixed this variance to one then the 
> > random term is essentially fitting Rmat as a known 
> covariance structure.
> >
> > MCMCglmm always fits random effect meta-analysis, because 
> a) that is 
> > the way I wrote it and b) I think it is an odd assumption 
> to believe 
> > that with enough replication every experiment should 
> produce exactly 
> > the same answer.  Hence this model is fitting i.i.d residuals after 
> > accounting for (correlated) measurement error.
> >
> > Cheers,
> >
> > Jarrod
> >
> >
> >
> >
> >
> >
> > On 15 Apr 2010, at 12:50, Gustaf Granath wrote:
> >
> >> Hi,
> >>
> >> In a meta-analysis, the SEs of the outcomes are known. However in 
> >> some cases, the correlation (co-variances) among outcomes 
> are known 
> >> as well. For example when you have multiple outcomes from 
> one study. 
> >> I wanted to see if the whole error structure of measurement errors 
> >> (the R-structure in MCMCglmm, or?) can be passed and not only the 
> >> diagonal.
> >>
> >> ##test data
> >> 
> testdata<-data.frame(Experiment=as.factor(c(1,2,3,4,5,6,7,8)),
Study=c("a","a","b","c","d","d","e","e") 
> >>
> >> 
> ,y=c(34,38,45,48,35,28,43,39),yvar=c(3,5,6,2,3,4,5,7),covar=c(
> 1.5,1.5,NA,NA,2.5,2.5,1.25,1.25)) 
> >>
> >> Rmat<-diag(8)*testdata$yvar
> >> Rmat[1,2]<-testdata$covar[1]
> >> Rmat[2,1]<-testdata$covar[2]
> >> Rmat[5,6]<-testdata$covar[5]
> >> Rmat[6,5]<-testdata$covar[6]
> >> Rmat[7,8]<-testdata$covar[7]
> >> Rmat[8,7]<-testdata$covar[8]
> >>
> >> Rmat is the known covariance structure of the experimental 
> outcomes.
> >>
> >> library(MCMCglmm)
> >> #"normal" meta-analysis using only the diagonal:
> >> prior = list(R = list(V = 1, n=1,fix = 1),G = list(G1  = 
> list ( V = 
> >> 1, n = 1)))
> >> model1 <- MCMCglmm(y ~ 1, random = ~idh(sqrt(yvar)):units ,data = 
> >> testdata,
> >>                     prior=prior)
> >>
> >> #OR (should be equal right? give sligtly different results though):
> >> model2 <- MCMCglmm(y ~ 1, random = ~Experiment ,data = testdata,
> >>                     mev=testdata$yvar,prior=prior)
> >>
> >> #Now I want to include the known within-study correlation.
> >> prior = list(R = list(V = Rmat, fix = 1),G = list(G1  = list ( V = 
> >> (1), nu = 0.002)))
> >> model1 <- MCMCglmm(y ~ 1, random = ~idh(Experiment):units, rcov = ~
> >> us(Study):Experiment ,data = testdata,
> >>                     prior=prior)
> >>
> >> This did not work (I tried other ways as well but all 
> failed) and I 
> >> guess that it is because of my R-structure prior. Is there an 
> >> alternative specification, or? (I played around a little with the 
> >> "animal" argument but I couldnt get to do what I wanted.)
> >>
> >> Cheers,
> >>
> >> Gustaf
> >>
> >> -- 
> >>
> >> Gustaf Granath (PhD student)
> >>
> >> Dept of Plant Ecology
> >> Uppsala University
> >>
> >>
> >>
> >
> >
> 
> -- 
> Gustaf Granath (PhD student)
> 
> Dept of Plant Ecology
> Evolutionary Biology Centre (EBC)
> Uppsala University
> Norbyv?gen 18D, SE - 752 36 Uppsala, Sweden
> 
> Tel: +46 (0)18-471 28 82
> Email: Gustaf.Granath at ebc.uu.se
> http://www.vaxtbio.uu.se/resfold/granath.htm
> 
> 
> 
> ------------------------------
> 
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> End of R-sig-mixed-models Digest, Vol 40, Issue 33
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
Notice:  This e-mail message, together with any attachme...{{dropped:10}}



From Christoph.Scherber at agr.uni-goettingen.de  Tue Apr 20 16:00:43 2010
From: Christoph.Scherber at agr.uni-goettingen.de (Christoph Scherber)
Date: Tue, 20 Apr 2010 16:00:43 +0200
Subject: [R-sig-ME] compareFits() for residuals
Message-ID: <4BCDB38B.6080905@agr.uni-goettingen.de>

Dear all,

Suppose I want to compare the residuals of two lme fits using the compareFits() function. Is this possible (in principle)?

I end up with an error message here:

fm1 <- lme(distance ~ age, data = Orthodont)
fm2 <- lme(distance ~ age, data = Orthodont, weights=varPower())
compareFits(resid(fm1),resid(fm2))

Many thanks,
Christoph





 --
Dr. rer.nat. Christoph Scherber
University of Goettingen
DNPW, Agroecology
Waldweg 26
D-37073 Goettingen
Germany

phone +49 (0)551 39 8807
fax   +49 (0)551 39 8806

Homepage http://www.gwdg.de/~cscherb1



From sylvestre at lunenfeld.ca  Tue Apr 20 19:35:02 2010
From: sylvestre at lunenfeld.ca (Marie-Pierre Sylvestre)
Date: Tue, 20 Apr 2010 13:35:02 -0400
Subject: [R-sig-ME] negative log-likelihood ratio tests
Message-ID: <A249C197854D3442BDAE4C6BA4D5553C02AE3FE5@ex1.ad.mshri.on.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100420/4cc37532/attachment.pl>

From wuolong at gmail.com  Wed Apr 21 17:12:07 2010
From: wuolong at gmail.com (Michael Li)
Date: Wed, 21 Apr 2010 11:12:07 -0400
Subject: [R-sig-ME] nested random effects in nlme
Message-ID: <x2w30b434fe1004210812h471632aek8b751039c91aa775@mail.gmail.com>

I'm trying to fit a four-parameter logistic model using nlme with
nested random effects. I use something like:

fits <- nlme (y ~ SSfpl (x, A, B, xmid, scal),
                     random = A + xmid ~ 1,
                     group = ~ subject / plate,
                     fixed = A + B + xmid + scal ~ 1,
                     data = mydata,
                     start = c(A = 600, B = 5, xmid = 10, scal = 1))

However, I kept getting the error

Error in names(reSt) <- namGrp :
  'names' attribute [2] must be the same length as the vector [1]

I look into the code nlme.formula() and there is an assignment

names (reSt) <- namGrp,

which is causing the trouble when namGrp has length of 2 instead of 1.

Did I do something wrong? How do you use nested random effects in nlme?

Best, Michael



From shigesong at gmail.com  Thu Apr 22 02:17:03 2010
From: shigesong at gmail.com (Shige Song)
Date: Wed, 21 Apr 2010 20:17:03 -0400
Subject: [R-sig-ME] MCMCglmm for more than two levels
Message-ID: <x2x5abc11d81004211717ya31e19bj495986368dc3beee@mail.gmail.com>

Dear All,

I am trying to estimating a three-level multinomial logit model using
MCMCglmm (I am not aware of other options for random effect
multinomial logit models). My question is: can MCMCglmm handle more
than two levels of nesting? I have been trying to find answers from
the documents without luck, and would really appreciate for some
examples if it is feasible at all. Many thanks.

Best,
Shige



From datkins at u.washington.edu  Thu Apr 22 06:07:13 2010
From: datkins at u.washington.edu (David Atkins)
Date: Wed, 21 Apr 2010 21:07:13 -0700
Subject: [R-sig-ME] MCMCglmm for more than two levels
In-Reply-To: <x2x5abc11d81004211717ya31e19bj495986368dc3beee@mail.gmail.com>
References: <x2x5abc11d81004211717ya31e19bj495986368dc3beee@mail.gmail.com>
Message-ID: <4BCFCB71.2070204@u.washington.edu>

 >Dear All,
 >
 >I am trying to estimating a three-level multinomial logit model using 
 >MCMCglmm (I am not aware of other options for random effect
 >multinomial logit models). My question is: can MCMCglmm handle more
 >than two levels of nesting? I have been trying to find answers from
 >the documents without luck, and would really appreciate for some
 > examples if it is feasible at all. Many thanks.
 >
 >Best,
 >Shige

Yes, MCMCglmm can fit multiple levels, though outside of social 
sciences, I don't think mixed-model folks think in terms of "levels" 
(quite possibly with good reason, due to cross-classification, etc.).

I've included an example below that uses data from a marital therapy 
study (which I used in the following article):

Atkins, D. C. (2005). Using multilevel models to analyze marital and 
family treatment data: Basic and advanced issues. Journal of Family 
Psychology, 19, 98-110.

The data has 4 repeated measures, on 268 individuals, in 134 couples; 
thus, a 3-level model in Raudenbush and Bryk jargon.

The outcome is the "dyadic adjustment scale", which is reasonably 
normally distributed; however, I think the code for MCMCglmm should be 
similar, with the exception of an additional "family" argument.

Hope it helps.

cheers, Dave



df <- read.table(file = 
"http://depts.washington.edu/cshrb/newweb/stats%20documents/Atkins%202005%20data.txt",
					header = TRUE)
head(df)					
names(df) <- casefold(names(df))			

### create unique individual ID
df$ind.id <- with(df, interaction(id, sex))

### fit "3 level" model with lmer
library(lme4)		

out.lmer <- lmer(das ~ therapy*time + (1 | id) + (1 | ind.id),
					data = df, verbose = TRUE)
summary(out.lmer)					

### fit random slopes across couples
out.lmer2 <- lmer(das ~ therapy*time + (time | id) + (1 | ind.id),
					data = df, verbose = TRUE)
summary(out.lmer2)					

### fit same models using MCMCglmm
library(MCMCglmm)

out.mcmc <- MCMCglmm(das ~ therapy*time,
					random = ~ id + ind.id,
					data = df, verbose = TRUE)
summary(out.mcmc$Sol)
summary(out.mcmc$VCV)
### results similar to out.lmer
### NOTE: this is functionally random-intercepts

prior <- list(R = list(V = 1, nu = 1),
				G = list(G1 = list(V = diag(2), nu = 2),
						  G2 = list(V = 1, nu = 1)))

out.mcmc2 <- MCMCglmm(das ~ therapy*time,
					random = ~ us(1 + time):id + ind.id,
					rcov = ~ units,
					data = df, verbose = TRUE,
					prior = prior)
summary(out.mcmc2$Sol)
summary(out.mcmc2$VCV)
### NOTE: this fits random intercept and slope for couples and
### intercept only for individuals
### results largely comparable to out.lmer2;
### using iterations, burn-in, thinning "out of the box"

-- 
Dave Atkins, PhD
Research Associate Professor
Department of Psychiatry and Behavioral Science
University of Washington
datkins at u.washington.edu

Center for the Study of Health and Risk Behaviors (CSHRB)		
1100 NE 45th Street, Suite 300 	
Seattle, WA  98105 	
206-616-3879 	
http://depts.washington.edu/cshrb/
(Mon-Wed)	

Center for Healthcare Improvement, for Addictions, Mental Illness,
   Medically Vulnerable Populations (CHAMMP)
325 9th Avenue, 2HH-15
Box 359911
Seattle, WA 98104?
206-897-4210
http://www.chammp.org
(Thurs)



From hugh-jones at econ.mpg.de  Thu Apr 22 09:44:41 2010
From: hugh-jones at econ.mpg.de (David Hugh-Jones)
Date: Thu, 22 Apr 2010 09:44:41 +0200
Subject: [R-sig-ME] question re poisson "fixed effects"
Message-ID: <i2pf5d848061004220044x2d05e494zc33aed12b1e09155@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100422/588e0ab3/attachment.pl>

From annafreni at yahoo.it  Thu Apr 22 12:58:20 2010
From: annafreni at yahoo.it (anna freni sterrantino)
Date: Thu, 22 Apr 2010 10:58:20 +0000 (GMT)
Subject: [R-sig-ME] repeated measures  nested
Message-ID: <794893.7414.qm@web29010.mail.ird.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100422/36143dc5/attachment.pl>

From shigesong at gmail.com  Thu Apr 22 14:59:48 2010
From: shigesong at gmail.com (Shige Song)
Date: Thu, 22 Apr 2010 08:59:48 -0400
Subject: [R-sig-ME] MCMCglmm for more than two levels
In-Reply-To: <4BCFCB71.2070204@u.washington.edu>
References: <x2x5abc11d81004211717ya31e19bj495986368dc3beee@mail.gmail.com>
	<4BCFCB71.2070204@u.washington.edu>
Message-ID: <g2q5abc11d81004220559m2c5aa061h7f5dc2c9a0ebcefd@mail.gmail.com>

Dear Dave,

This is very helpful, thank you very much!

Best,
Shige

On Thu, Apr 22, 2010 at 12:07 AM, David Atkins <datkins at u.washington.edu> wrote:
>>Dear All,
>>
>>I am trying to estimating a three-level multinomial logit model using
>> >MCMCglmm (I am not aware of other options for random effect
>>multinomial logit models). My question is: can MCMCglmm handle more
>>than two levels of nesting? I have been trying to find answers from
>>the documents without luck, and would really appreciate for some
>> examples if it is feasible at all. Many thanks.
>>
>>Best,
>>Shige
>
> Yes, MCMCglmm can fit multiple levels, though outside of social sciences, I
> don't think mixed-model folks think in terms of "levels" (quite possibly
> with good reason, due to cross-classification, etc.).
>
> I've included an example below that uses data from a marital therapy study
> (which I used in the following article):
>
> Atkins, D. C. (2005). Using multilevel models to analyze marital and family
> treatment data: Basic and advanced issues. Journal of Family Psychology, 19,
> 98-110.
>
> The data has 4 repeated measures, on 268 individuals, in 134 couples; thus,
> a 3-level model in Raudenbush and Bryk jargon.
>
> The outcome is the "dyadic adjustment scale", which is reasonably normally
> distributed; however, I think the code for MCMCglmm should be similar, with
> the exception of an additional "family" argument.
>
> Hope it helps.
>
> cheers, Dave
>
>
>
> df <- read.table(file =
> "http://depts.washington.edu/cshrb/newweb/stats%20documents/Atkins%202005%20data.txt",
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?header = TRUE)
> head(df)
> names(df) <- casefold(names(df))
>
> ### create unique individual ID
> df$ind.id <- with(df, interaction(id, sex))
>
> ### fit "3 level" model with lmer
> library(lme4)
>
> out.lmer <- lmer(das ~ therapy*time + (1 | id) + (1 | ind.id),
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?data = df, verbose = TRUE)
> summary(out.lmer)
>
> ### fit random slopes across couples
> out.lmer2 <- lmer(das ~ therapy*time + (time | id) + (1 | ind.id),
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?data = df, verbose = TRUE)
> summary(out.lmer2)
>
> ### fit same models using MCMCglmm
> library(MCMCglmm)
>
> out.mcmc <- MCMCglmm(das ~ therapy*time,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?random = ~ id + ind.id,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?data = df, verbose = TRUE)
> summary(out.mcmc$Sol)
> summary(out.mcmc$VCV)
> ### results similar to out.lmer
> ### NOTE: this is functionally random-intercepts
>
> prior <- list(R = list(V = 1, nu = 1),
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?G = list(G1 = list(V = diag(2), nu = 2),
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?G2 = list(V = 1, nu = 1)))
>
> out.mcmc2 <- MCMCglmm(das ~ therapy*time,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?random = ~ us(1 + time):id + ind.id,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?rcov = ~ units,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?data = df, verbose = TRUE,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?prior = prior)
> summary(out.mcmc2$Sol)
> summary(out.mcmc2$VCV)
> ### NOTE: this fits random intercept and slope for couples and
> ### intercept only for individuals
> ### results largely comparable to out.lmer2;
> ### using iterations, burn-in, thinning "out of the box"
>
> --
> Dave Atkins, PhD
> Research Associate Professor
> Department of Psychiatry and Behavioral Science
> University of Washington
> datkins at u.washington.edu
>
> Center for the Study of Health and Risk Behaviors (CSHRB)
> 1100 NE 45th Street, Suite 300
> Seattle, WA ?98105
> 206-616-3879
> http://depts.washington.edu/cshrb/
> (Mon-Wed)
>
> Center for Healthcare Improvement, for Addictions, Mental Illness,
> ?Medically Vulnerable Populations (CHAMMP)
> 325 9th Avenue, 2HH-15
> Box 359911
> Seattle, WA 98104?
> 206-897-4210
> http://www.chammp.org
> (Thurs)
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From benjamin.rosenfield at gmail.com  Fri Apr 23 05:50:54 2010
From: benjamin.rosenfield at gmail.com (Ben Rosenfield)
Date: Thu, 22 Apr 2010 22:50:54 -0500
Subject: [R-sig-ME] Convergence error for longitudinal glmm with simulated
	data
Message-ID: <571D265E-5390-4447-A37C-2752218AF624@gmail.com>

Hello R-ers,

I want to do power analysis via fake data simulation. Unfortunately, glmer returns convergence errors with a significant percentage of the data sets I generate. Unless, of course, I center one of my predictors, in which case everything works great. Except, I'd prefer not.

Let's get to the data:
N simulated subjects hypothetically quit smoking at week 0, split evenly into treatment and control groups. They report at which week they relapse and this is converted into a sequence of 0's and 1's (0 for every week they abstain and 1 for every week after they relapse) of length W, the length of the experiment. So the data frame looks like this (N=2, W=3):

ID Trt Week Smoke
1    0     0          0
1    0     1          0
1    0     2          1
1    0     3          1
2    1     0          0
2    1     1          0
2    1     2          0
2    1     3          0

A reasonable approximation of "time to relapse" is given by a Weibull distribution with scale 0.7, and shape 5 for the control group and 11.5-ish for the treatment group. Just for fun, I've added a little bit of individual variation to these. Note that this model doesn't allow people to "re-quit". 
I should also note that I've checked the data with large N, and it looks how it is supposed to.

The model we'd like to test is something like

glmer(Smoke ~ (Week-W)*Trt + (Week-W)^2 + ((Week-W) | ID), family=binomial)
(So we 'centered' Week at the final week, because I'm most interested in the treatment effect at the end of the experiment)

Enough chit-chat, here's my code: 

Using R 2.10.1 for OSX

library(lme4) # version 0.999375-32
library(boot) # I use the inv.logit function

time.quit<-function(P,E=0) { 				# returns number of weeks until relapse, E is an individual variation, sampled from a normal distribution
	return(floor(rweibull(1,0.7,(inv.logit(logit(P)+E))^-1)))
}

fake.data<-function(N,W,P,Q,S){ # generates the data, P = shape parameter for control group, Q = shape parameter for treatment group, S = standard error for individual variation
	interval<-0
	smoke<-matrix(nrow = N*(W+1), ncol=1)
	for(k in 0:1){
		for(i in 1:I(N/2)){
		error<-rnorm(1,0,S)		#ind variation
		time<-min(time.quit(ifelse(k==0,P,Q),error),W)		# returns number of weeks until relapse or study ends
		smoke[(1+interval):(W+1+interval),1]<-rep(0:1,c(1+time,W-time))               # turns time into sequence of 0's and 1's
		interval<-interval+W+1
		}
	}
	Data<-data.frame(cbind(rep(1:N,each=W+1),rep(0:1,each=I(N*(W+1)/2)),rep(0:W,times=N),smoke))  # creates most of the data frame
	colnames(Data)<-c("ID","Trt","Week","Smoke")
	rownames(Data)<-c(1:I(N*(W+1)))
	cWeek<-(Data$Week-mean(Data$Week))                     # creates a centered Week column
	eWeek<-(Data$Week-W)							# creates an end-centered Week column
	Data<-cbind(Data,cWeek,eWeek)
	return(Data)
}

fake<-fake.data(60,10,0.20,0.85,0.1); # 60 and 10 are chosen as they are neither too large nor too small
glmer(Smoke~cWeek*Trt + I(cWeek^2) + (0 + cWeek | ID),family=binomial,data=fake) # this works great
glmer(Smoke~cWeek*Trt + I(cWeek^2) + (cWeek | ID),family=binomial,data=fake) # this produces "In mer_finalize(ans) : false convergence (8)" much of the time
glmer(Smoke~eWeek*Trt + I(eWeek^2) + (0 + eWeek | ID),family=binomial,data=fake) # this produces "In mer_finalize(ans) : false convergence (8)" much of the time

For different models, as long as you have eWeek as a fixed effect or the intercept as a random effect, you see similar results.

So, what's up? 
In particular:
a) Why does a random intercept cause problems?
b) Why do I need to center the model? (I'm actually rather interested in this, as I assume it has something to do with the inner workings of lmer)
c) Am I doing anything screwy? (This is primarily an educational project for me; I'm newish to stats and I'm newer to glm's (even without the extra m))

Ben


From andydolman at gmail.com  Fri Apr 23 13:02:58 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Fri, 23 Apr 2010 13:02:58 +0200
Subject: [R-sig-ME] repeated measures nested
In-Reply-To: <794893.7414.qm@web29010.mail.ird.yahoo.com>
References: <794893.7414.qm@web29010.mail.ird.yahoo.com>
Message-ID: <x2m951234ac1004230402l84b54827w9c275915dd34be02@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100423/8be8b476/attachment.pl>

From Mark.Schultz2 at va.gov  Fri Apr 23 15:38:07 2010
From: Mark.Schultz2 at va.gov (Schultz, Mark R.)
Date: Fri, 23 Apr 2010 09:38:07 -0400
Subject: [R-sig-ME] Random vs. fixed effects
Message-ID: <263B04CBBF074046AFD8E36BA524E6170687F8C6@VHAV01MSGA2.v01.med.va.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100423/5c256d07/attachment.pl>

From danielezrajohnson at gmail.com  Fri Apr 23 15:47:41 2010
From: danielezrajohnson at gmail.com (Daniel Ezra Johnson)
Date: Fri, 23 Apr 2010 09:47:41 -0400
Subject: [R-sig-ME] Random vs. fixed effects
In-Reply-To: <263B04CBBF074046AFD8E36BA524E6170687F8C6@VHAV01MSGA2.v01.med.va.gov>
References: <263B04CBBF074046AFD8E36BA524E6170687F8C6@VHAV01MSGA2.v01.med.va.gov>
Message-ID: <j2za46630751004230647pa5d26e81r6a651644f911f261@mail.gmail.com>

I'm not personally an expert, but from reading this list for some
time, the consensus is that three points is not enough to make a
reasonable estimate of a variance. Nor is a three-level effect likely
to be nested within a fixed effect, which would require it be treated
as random.

So yes, a fixed effect sounds like the way to go here, but as far as
what differences you'd get by treating it as fixed or random, in terms
of inference or prediction (from the BLUPs, if random) you might want
to investigate that. If you want to make predictions to new population
members, then of course random is your only choice.

Dan

On Fri, Apr 23, 2010 at 9:38 AM, Schultz, Mark R. <Mark.Schultz2 at va.gov> wrote:
> I just read a post by Andrew Dolman suggesting that a factor with only 3
> levels should be treated as a fixed effect. This seems to be a perennial
> question with mixed models. I'd really like to hear opinions from
> several experts as to whether there is a consensus on the topic. It
> really makes me uncomfortable that such an important modeling decision
> is made with an "ad hoc" heuristic.
>
>
>
> Thanks,
>
> Mark Schultz, Ph.D.
>
> Bedford VA Hospital
>
> Bedford, Ma.
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From andy_liaw at merck.com  Fri Apr 23 15:49:44 2010
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 23 Apr 2010 09:49:44 -0400
Subject: [R-sig-ME] Random vs. fixed effects
In-Reply-To: <263B04CBBF074046AFD8E36BA524E6170687F8C6@VHAV01MSGA2.v01.med.va.gov>
References: <263B04CBBF074046AFD8E36BA524E6170687F8C6@VHAV01MSGA2.v01.med.va.gov>
Message-ID: <B10BAA7D28D88B45AF82813C4A6FFA936D63F9@usctmx1157.merck.com>

I'm by no means expert, but it seems to me that this is more a
philosophical question than a technical one.

To me, a factor is treated a fixed effect if the interest is in the
differences from one level to another (or some contrasts).  A random
factor, on the other hand, is when the interest is in the variability
due to the factor, and the levels of the factor can be considered as a
sample from a (Gaussian) population.  The problem is, if a factor has
only three levels, can we really reliably estimate the variance of the
population from which the three levels of the factor were drawn from?
Well, if you must, you must.  However, it seems to me that if the factor
is really a blocking variable (thus basically nuisance parameters), one
can go either way.

I'd very much welcome the real experts' corrections or comments.

Andy

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
> Of Schultz, Mark R.
> Sent: Friday, April 23, 2010 9:38 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Random vs. fixed effects
> 
> I just read a post by Andrew Dolman suggesting that a factor 
> with only 3
> levels should be treated as a fixed effect. This seems to be 
> a perennial
> question with mixed models. I'd really like to hear opinions from
> several experts as to whether there is a consensus on the topic. It
> really makes me uncomfortable that such an important modeling decision
> is made with an "ad hoc" heuristic.
> 
>  
> 
> Thanks,
> 
> Mark Schultz, Ph.D.
> 
> Bedford VA Hospital
> 
> Bedford, Ma. 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
Notice:  This e-mail message, together with any attachme...{{dropped:10}}



From ral at lcfltd.com  Fri Apr 23 18:13:28 2010
From: ral at lcfltd.com (Robert A LaBudde)
Date: Fri, 23 Apr 2010 12:13:28 -0400
Subject: [R-sig-ME] Random vs. fixed effects
Message-ID: <0L1C00DE67QI5X30@vms173005.mailsrvcs.net>

The question isn't whether an effect is "random" or "fixed". Anything 
can be considered either under different conditions. The real 
question is one of inference: Are you willing to make statements only 
about "these" blocks, or do you want to make inferences about "those" 
blocks too.

Consider the simplest case: a randomized block design. Suppose you 
have 3 blocks upon which you apply the treatments you want to 
measure. The treatments are applied in replicate within blocks.

If you treat the blocks as a fixed effect, you are saying you only 
care about inferences of treatment effect on "these" blocks, but no 
others. The blocks are then just an artifact of the design used to 
reduce variance of the treatment effect.

If the treat the blocks as a random effect, you are saying you want 
your inferences on treatment effect to apply not only to "these" 
blocks, but also hypothetically all "those" other blocks of similar 
type. You would also then be interested in the standard deviation of 
the block effect of that population of blocks.

Now we get to the practical side. You can treat the blocks as random 
with only 3 blocks, but you will get a very imprecise estimate of the 
block variance. This is not doing something wrong, it's only a fact 
of estimation. You will still control for block in measuring 
treatment effect. The bad news is that the imprecision in block 
variance will lead to imprecision in treatment effect. What then do 
you want to do? Treat blocks correctly as random, but get imprecise 
estimates? Or treat blocks as fixed, but get a  precise treatment 
estimate, but with a confidence interval that's a little too liberal?

Personally, I'm a purist. If blocks are random, I want to model them 
as random, even if I've only got 3 or 4 of them. I rather have a 
correct model (low bias) than precise, biased estimates. Others have 
different opinions. Hence the 6 blocks minimum rule of thumb.

Note that any effect can be theoretically fixed or random. Consider a 
1-way ANOVA with 3 drugs tested in replicate (mice, say). Normally 
this is treated as a fixed effect model, because we only care about 
the effects of "these" three drugs. But suppose I hypothecate the 3 
drugs were chosen at random from some sampling frame of drugs, and I 
want to make inferences about variability of treatment effect within 
"that" population of drugs. Then  I might use a random effect model 
to get a standard deviation of treatment effect.

The "elephant in the room" on this question is that rarely do people 
actually have random sampling behind the choice of the random effect 
subjects/blocks/centers. That introduces considerable selection bias 
and confusion about what population is really being represented. If 
your blocks aren't being randomly selected or at least representative 
of the population of inference, that is a more important issue than 
whether you model the effect as fixed or random. So this is more 
justification for the ad hoc 6 blocks minimum rule, and creates more 
acceptability for the fixed effect model.



At 09:38 AM 4/23/2010, Schultz, Mark R. wrote:
>I just read a post by Andrew Dolman suggesting that a factor with only 3
>levels should be treated as a fixed effect. This seems to be a perennial
>question with mixed models. I'd really like to hear opinions from
>several experts as to whether there is a consensus on the topic. It
>really makes me uncomfortable that such an important modeling decision
>is made with an "ad hoc" heuristic.
>
>
>
>Thanks,
>
>Mark Schultz, Ph.D.
>
>Bedford VA Hospital
>
>Bedford, Ma.
>
>
>         [[alternative HTML version deleted]]
>
>_______________________________________________
>R-sig-mixed-models at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

================================================================
Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
824 Timberlake Drive                     Tel: 757-467-0954
Virginia Beach, VA 23464-3239            Fax: 757-467-2947

"Vere scire est per causas scire"



From ggrothendieck at gmail.com  Fri Apr 23 18:41:05 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 23 Apr 2010 12:41:05 -0400
Subject: [R-sig-ME] Random vs. fixed effects
In-Reply-To: <263B04CBBF074046AFD8E36BA524E6170687F8C6@VHAV01MSGA2.v01.med.va.gov>
References: <263B04CBBF074046AFD8E36BA524E6170687F8C6@VHAV01MSGA2.v01.med.va.gov>
Message-ID: <l2t971536df1004230941t95de95c5z25a1b8d5a616d787@mail.gmail.com>

Here is a simulation of 10k cases using 4 and 50 level factors for the
random effect.  With 4 levels there are numerical problems and the
accuracy of the random effect is terrible.  With 50 levels there are
no numerical problems and the accuracy is much better.

> library(lme4)
> set.seed(1)
> n <- 10000
> k <- 4
> f <- function(n, k) {
+ set.seed(1)
+ x <- 1:n
+ fac <- gl(k, 1, n)
+ fac.eff <- rnorm(k, 0, 4)[fac]
+ e <- rnorm(n)
+ y <- 1 + 2 * x + fac.eff + e
+ lmer(y ~ x + (1|fac))
+ }

> # simulation with 4 level random effect
> f(n, 4)
Linear mixed model fit by REML
Formula: y ~ x + (1 | fac)
   AIC   BIC logLik deviance REMLdev
 28733 28762 -14363    28702   28725
Random effects:
 Groups   Name        Variance Std.Dev.
 fac      (Intercept) 1.1162   1.0565
 Residual             1.0298   1.0148
Number of obs: 10000, groups: fac, 4

Fixed effects:
             Estimate Std. Error t value
(Intercept) 1.313e+00  5.286e-01       2
x           2.000e+00  3.515e-06  568923

Correlation of Fixed Effects:
  (Intr)
x -0.033
Warning message:
In mer_finalize(ans) : false convergence (8)

> # simulation with 50 level random effect
> f(n, 50)
Linear mixed model fit by REML
Formula: y ~ x + (1 | fac)
   AIC   BIC logLik deviance REMLdev
 29040 29069 -14516    29009   29032
Random effects:
 Groups   Name        Variance Std.Dev.
 fac      (Intercept) 11.2016  3.3469
 Residual              1.0251  1.0125
Number of obs: 10000, groups: fac, 50

Fixed effects:
             Estimate Std. Error t value
(Intercept) 1.396e+00  4.738e-01       3
x           2.000e+00  3.507e-06  570242

Correlation of Fixed Effects:
  (Intr)
x -0.037




On Fri, Apr 23, 2010 at 9:38 AM, Schultz, Mark R. <Mark.Schultz2 at va.gov> wrote:
> I just read a post by Andrew Dolman suggesting that a factor with only 3
> levels should be treated as a fixed effect. This seems to be a perennial
> question with mixed models. I'd really like to hear opinions from
> several experts as to whether there is a consensus on the topic. It
> really makes me uncomfortable that such an important modeling decision
> is made with an "ad hoc" heuristic.
>
>
>
> Thanks,
>
> Mark Schultz, Ph.D.
>
> Bedford VA Hospital
>
> Bedford, Ma.
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bolker at ufl.edu  Fri Apr 23 20:11:45 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Fri, 23 Apr 2010 14:11:45 -0400
Subject: [R-sig-ME] Random vs. fixed effects
In-Reply-To: <l2t971536df1004230941t95de95c5z25a1b8d5a616d787@mail.gmail.com>
References: <263B04CBBF074046AFD8E36BA524E6170687F8C6@VHAV01MSGA2.v01.med.va.gov>
	<l2t971536df1004230941t95de95c5z25a1b8d5a616d787@mail.gmail.com>
Message-ID: <4BD1E2E1.5030906@ufl.edu>

  Here's my question for the group:

  Given that it is a reasonable *philosophical* position to say 'treat
philosophically random effects as random no matter what, and leave them
in the model even if they don't appear to be statistically significant',
and given that with small numbers of random-effect levels this approach
is likely to lead to numerical difficulties in most (??) mixed model
packages (warnings, errors, or low estimates of the variance), what
should one do?  (Suppose one is in a situation that is too complicated
to use classical method-of-moments approaches -- crossed designs, highly
unbalanced data, GLMMs ...)

 1. philosophy, schmilosophy.  Fit these factors as a fixed effect,
anything else is too dangerous/misleading/unworkable.
 2. proceed with the 'standard' mixed model (lme4, nlme, PROC MIXED,
...) and hope it doesn't break.  Ignore warnings.
 3. use Bayesian-computational approaches (MCMCglmm, WinBUGS, AD Model
Builder with post-hoc MCMC calculation? Data cloning?)?  Possibly with
half-Cauchy priors on variance as recommended by Gelman [Bayesian
Analysis (2006) 1, Number 3, pp. 515?533]?



Gabor Grothendieck wrote:
> Here is a simulation of 10k cases using 4 and 50 level factors for the
> random effect.  With 4 levels there are numerical problems and the
> accuracy of the random effect is terrible.  With 50 levels there are
> no numerical problems and the accuracy is much better.
> 
>> library(lme4)
>> set.seed(1)
>> n <- 10000
>> k <- 4
>> f <- function(n, k) {
> + set.seed(1)
> + x <- 1:n
> + fac <- gl(k, 1, n)
> + fac.eff <- rnorm(k, 0, 4)[fac]
> + e <- rnorm(n)
> + y <- 1 + 2 * x + fac.eff + e
> + lmer(y ~ x + (1|fac))
> + }
> 
>> # simulation with 4 level random effect
>> f(n, 4)
> Linear mixed model fit by REML
> Formula: y ~ x + (1 | fac)
>    AIC   BIC logLik deviance REMLdev
>  28733 28762 -14363    28702   28725
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  fac      (Intercept) 1.1162   1.0565
>  Residual             1.0298   1.0148
> Number of obs: 10000, groups: fac, 4
> 
> Fixed effects:
>              Estimate Std. Error t value
> (Intercept) 1.313e+00  5.286e-01       2
> x           2.000e+00  3.515e-06  568923
> 
> Correlation of Fixed Effects:
>   (Intr)
> x -0.033
> Warning message:
> In mer_finalize(ans) : false convergence (8)
> 
>> # simulation with 50 level random effect
>> f(n, 50)
> Linear mixed model fit by REML
> Formula: y ~ x + (1 | fac)
>    AIC   BIC logLik deviance REMLdev
>  29040 29069 -14516    29009   29032
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  fac      (Intercept) 11.2016  3.3469
>  Residual              1.0251  1.0125
> Number of obs: 10000, groups: fac, 50
> 
> Fixed effects:
>              Estimate Std. Error t value
> (Intercept) 1.396e+00  4.738e-01       3
> x           2.000e+00  3.507e-06  570242
> 
> Correlation of Fixed Effects:
>   (Intr)
> x -0.037
> 
> 
> 
> 
> On Fri, Apr 23, 2010 at 9:38 AM, Schultz, Mark R. <Mark.Schultz2 at va.gov> wrote:
>> I just read a post by Andrew Dolman suggesting that a factor with only 3
>> levels should be treated as a fixed effect. This seems to be a perennial
>> question with mixed models. I'd really like to hear opinions from
>> several experts as to whether there is a consensus on the topic. It
>> really makes me uncomfortable that such an important modeling decision
>> is made with an "ad hoc" heuristic.
>>
>>
>>
>> Thanks,
>>
>> Mark Schultz, Ph.D.
>>
>> Bedford VA Hospital
>>
>> Bedford, Ma.
>>
>>
>>        [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From ral at lcfltd.com  Fri Apr 23 22:18:10 2010
From: ral at lcfltd.com (Robert A LaBudde)
Date: Fri, 23 Apr 2010 16:18:10 -0400
Subject: [R-sig-ME] Random vs. fixed effects
In-Reply-To: <4BD1E2E1.5030906@ufl.edu>
References: <263B04CBBF074046AFD8E36BA524E6170687F8C6@VHAV01MSGA2.v01.med.va.gov>
	<l2t971536df1004230941t95de95c5z25a1b8d5a616d787@mail.gmail.com>
	<4BD1E2E1.5030906@ufl.edu>
Message-ID: <0L1C0092QJ8A8IA0@vms173013.mailsrvcs.net>

The answer is effect-size dependent, is it not?

If you fit the random effect and the algorithm 
works without failure, why not use it?

If it doesn't work, you have a faulty tool for 
estimation. Punting to a fixed model is one way 
out of the problem. Another is matched-on-the-random-factor data analysis.

Pragmatism is certainly an issue. But what if you 
have 10 centers as a factor with known 
correlation issues. If you analyze with one set 
of predictors, missing values leaves you with 
only 5 centers, so you treat centers as a fixed 
effect with 5 levels. If you use another set of 
predictors, you have all 10 levels, so you use 
centers as a random effect with a variance. Isn't 
intellectual consistency an issue here too? How 
do you explain this in the executive summary?

One thing you can do if the mixed modeling fails 
is to use the standard deviation among levels of 
the random-treated-as-fixed factor as an estimate 
of the random effect. This would at least maintain consistency of concept.

Note that I'm not a mixed modeling expert, so my 
opinions may not be worth much.

At 02:11 PM 4/23/2010, Ben Bolker wrote:
>Here's my question for the group:   Given that 
>it is a reasonable *philosophical* position to 
>say 'treat philosophically random effects as 
>random no matter what, and leave them in the 
>model even if they don't appear to be 
>statistically significant', and given that with 
>small numbers of random-effect levels this 
>approach is likely to lead to numerical 
>difficulties in most (??) mixed model packages 
>(warnings, errors, or low estimates of the variance), what should one do?
>
>(Suppose one is in a situation that is too 
>complicated to use classical method-of-moments 
>approaches -- crossed designs, highly unbalanced data, GLMMs ...)
>
>1. philosophy, schmilosophy.  Fit these factors 
>as a fixed effect, anything else is too dangerous/misleading/unworkable.
>
>2. proceed with the 'standard' mixed model 
>(lme4, nlme, PROC MIXED, ...) and hope it doesn't break.  Ignore warnings.
>
>3. use Bayesian-computational approaches 
>(MCMCglmm, WinBUGS, AD Model Builder with 
>post-hoc MCMC calculation? Data 
>cloning?)?  Possibly with half-Cauchy priors on 
>variance as recommended by Gelman [Bayesian 
>Analysis (2006) 1, Number 3, pp. 515?533]?

================================================================
Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
824 Timberlake Drive                     Tel: 757-467-0954
Virginia Beach, VA 23464-3239            Fax: 757-467-2947

"Vere scire est per causas scire"
================================================================



From daniel.lists at zeno.co.nz  Fri Apr 23 23:25:13 2010
From: daniel.lists at zeno.co.nz (Daniel Myall)
Date: Sat, 24 Apr 2010 09:25:13 +1200
Subject: [R-sig-ME] patch for building lme4a on Mac OS X
Message-ID: <4BD21039.4020800@zeno.co.nz>

Hi,

Below is a patch for lme4a from SVN to build on Mac OS X (at least 
leopard/snow leopard and under R 2.11 but I assume for Mac OS X in general).

Note: could potentially make cleaner by checking for __sun and _AIX at 
top as well but I am not sure if there are cases where __GNUC__ are 
defined on these systems and alloca.h shouldn't be used. Hence I left 
them as they were.

Regards,
Daniel

Index: pkg/lme4a/src/lme4utils.h
===================================================================
--- pkg/lme4a/src/lme4utils.h   (revision 791)
+++ pkg/lme4a/src/lme4utils.h   (working copy)
@@ -33,7 +33,11 @@
   * is freed automatically on return from a function. When using gcc the
   * builtin version is much faster. */

-#ifdef __GNUC__
+#ifdef __APPLE__
+/* This is necessary (and sufficient) for Mac OS X leopard/snow leopard
+ * Note that __GNUC__ is also defined on Mac OS X so this needs to go 
first */
+# include <alloca.h>
+#elif defined(__GNUC__)
  # undef alloca
  # define alloca(x) __builtin_alloca((x))
  #elif defined(__sun) || defined(_AIX)



From wkmor1 at gmail.com  Sat Apr 24 05:51:17 2010
From: wkmor1 at gmail.com (William Morris)
Date: Sat, 24 Apr 2010 13:51:17 +1000
Subject: [R-sig-ME] Random vs. fixed effects
In-Reply-To: <4BD1E2E1.5030906@ufl.edu>
References: <263B04CBBF074046AFD8E36BA524E6170687F8C6@VHAV01MSGA2.v01.med.va.gov>
	<l2t971536df1004230941t95de95c5z25a1b8d5a616d787@mail.gmail.com>
	<4BD1E2E1.5030906@ufl.edu>
Message-ID: <5302B708-EE72-4184-A459-1D304555B1B0@gmail.com>

For what its worth, I would take approach 3. 

Others have pointed this out before, but I think strict adherence to the 'random' vs 'fixed effects' nomenclature can sometimes do us a disservice. For me I find it easier to think of my multilevel models as having some parameters I allow to vary and some that I don't, or, some parameters are themselves modelled, some aren't. 

Bayesianly, I think of the level above my modelled parameter as a prior. This prior can be relatively informative or uninformative, when the number of groups contributing to the modelled parameter is low then this prior is likely to be relatively uninformative. But nonetheless probably still useful. Yes, the estimated posterior mode for the variance is likely to be underestimated but this is only a problem if I ignore the rest of its distribution. The uncertainty around the estimate of the variance is likely to be very large and in fact will allow for unrealistically large values. This assumes I have specified a flat prior on the variance, but it can be ameliorated if I instead apply an appropriate half-Cauchy. 

In most cases I would treat grouping variables with more than two levels as a single parameter allowed to vary by group, either as a component of an intercept term or as an error term centred on zero. Then, if the data allowed, I might consider allowing other parameters in my model to vary by these groups and therefore take care of the interactions.

Arguably even categorical variables that some would consider inarguably philosophically 'fixed', can be incorporated as a modelled (allowed to vary by group) parameter. Gelman points out that such an approach can negate the 'classical' problem of multiple comparisons. See http://www.stat.columbia.edu/~gelman/research/unpublished/multiple2.pdf .

Will Morris 
Masters of Philosophy candidate 
Vesk Plant Ecology Lab 
The School of Botany 
The University of Melbourne 
Australia 
Phone: +61 3 8344 0120 
http://www.botany.unimelb.edu.au/vesk/ 

On 24/04/2010, at 4:11 AM, Ben Bolker wrote:

>  Here's my question for the group:
> 
>  Given that it is a reasonable *philosophical* position to say 'treat
> philosophically random effects as random no matter what, and leave them
> in the model even if they don't appear to be statistically significant',
> and given that with small numbers of random-effect levels this approach
> is likely to lead to numerical difficulties in most (??) mixed model
> packages (warnings, errors, or low estimates of the variance), what
> should one do?  (Suppose one is in a situation that is too complicated
> to use classical method-of-moments approaches -- crossed designs, highly
> unbalanced data, GLMMs ...)
> 
> 1. philosophy, schmilosophy.  Fit these factors as a fixed effect,
> anything else is too dangerous/misleading/unworkable.
> 2. proceed with the 'standard' mixed model (lme4, nlme, PROC MIXED,
> ...) and hope it doesn't break.  Ignore warnings.
> 3. use Bayesian-computational approaches (MCMCglmm, WinBUGS, AD Model
> Builder with post-hoc MCMC calculation? Data cloning?)?  Possibly with
> half-Cauchy priors on variance as recommended by Gelman [Bayesian
> Analysis (2006) 1, Number 3, pp. 515?533]?
> 
> 
> 
> Gabor Grothendieck wrote:
>> Here is a simulation of 10k cases using 4 and 50 level factors for the
>> random effect.  With 4 levels there are numerical problems and the
>> accuracy of the random effect is terrible.  With 50 levels there are
>> no numerical problems and the accuracy is much better.
>> 
>>> library(lme4)
>>> set.seed(1)
>>> n <- 10000
>>> k <- 4
>>> f <- function(n, k) {
>> + set.seed(1)
>> + x <- 1:n
>> + fac <- gl(k, 1, n)
>> + fac.eff <- rnorm(k, 0, 4)[fac]
>> + e <- rnorm(n)
>> + y <- 1 + 2 * x + fac.eff + e
>> + lmer(y ~ x + (1|fac))
>> + }
>> 
>>> # simulation with 4 level random effect
>>> f(n, 4)
>> Linear mixed model fit by REML
>> Formula: y ~ x + (1 | fac)
>>   AIC   BIC logLik deviance REMLdev
>> 28733 28762 -14363    28702   28725
>> Random effects:
>> Groups   Name        Variance Std.Dev.
>> fac      (Intercept) 1.1162   1.0565
>> Residual             1.0298   1.0148
>> Number of obs: 10000, groups: fac, 4
>> 
>> Fixed effects:
>>             Estimate Std. Error t value
>> (Intercept) 1.313e+00  5.286e-01       2
>> x           2.000e+00  3.515e-06  568923
>> 
>> Correlation of Fixed Effects:
>>  (Intr)
>> x -0.033
>> Warning message:
>> In mer_finalize(ans) : false convergence (8)
>> 
>>> # simulation with 50 level random effect
>>> f(n, 50)
>> Linear mixed model fit by REML
>> Formula: y ~ x + (1 | fac)
>>   AIC   BIC logLik deviance REMLdev
>> 29040 29069 -14516    29009   29032
>> Random effects:
>> Groups   Name        Variance Std.Dev.
>> fac      (Intercept) 11.2016  3.3469
>> Residual              1.0251  1.0125
>> Number of obs: 10000, groups: fac, 50
>> 
>> Fixed effects:
>>             Estimate Std. Error t value
>> (Intercept) 1.396e+00  4.738e-01       3
>> x           2.000e+00  3.507e-06  570242
>> 
>> Correlation of Fixed Effects:
>>  (Intr)
>> x -0.037
>> 
>> 
>> 
>> 
>> On Fri, Apr 23, 2010 at 9:38 AM, Schultz, Mark R. <Mark.Schultz2 at va.gov> wrote:
>>> I just read a post by Andrew Dolman suggesting that a factor with only 3
>>> levels should be treated as a fixed effect. This seems to be a perennial
>>> question with mixed models. I'd really like to hear opinions from
>>> several experts as to whether there is a consensus on the topic. It
>>> really makes me uncomfortable that such an important modeling decision
>>> is made with an "ad hoc" heuristic.
>>> 
>>> 
>>> 
>>> Thanks,
>>> 
>>> Mark Schultz, Ph.D.
>>> 
>>> Bedford VA Hospital
>>> 
>>> Bedford, Ma.
>>> 
>>> 
>>>       [[alternative HTML version deleted]]
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> -- 
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / people.biology.ufl.edu/bolker
> GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From djmuser at gmail.com  Sat Apr 24 07:17:05 2010
From: djmuser at gmail.com (Dennis Murphy)
Date: Fri, 23 Apr 2010 22:17:05 -0700
Subject: [R-sig-ME] Random vs. fixed effects
In-Reply-To: <g2s9a8a6c631004232215w380e5493g1f674f655353d508@mail.gmail.com>
References: <0L1C00DE67QI5X30@vms173005.mailsrvcs.net>
	<g2s9a8a6c631004232215w380e5493g1f674f655353d508@mail.gmail.com>
Message-ID: <n2l9a8a6c631004232217lc29d4b54i5d82511cd836f26b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100423/cb47dbda/attachment.pl>

From ral at lcfltd.com  Sat Apr 24 07:17:19 2010
From: ral at lcfltd.com (Robert A LaBudde)
Date: Sat, 24 Apr 2010 01:17:19 -0400
Subject: [R-sig-ME] Random vs. fixed effects
In-Reply-To: <4BD1E2E1.5030906@ufl.edu>
References: <263B04CBBF074046AFD8E36BA524E6170687F8C6@VHAV01MSGA2.v01.med.va.gov>
	<l2t971536df1004230941t95de95c5z25a1b8d5a616d787@mail.gmail.com>
	<4BD1E2E1.5030906@ufl.edu>
Message-ID: <0L1D00IDF80YWI10@vms173015.mailsrvcs.net>

As an addendum, back in the "Old Days", before there were good mixed 
model programs and all you could fit were fixed effect models, you 
had to estimate random effects by fitting the fixed effect model and 
then taking mean squares of the random effect levels as the estimate 
of the variance.

As an example, consider a simple complete randomized block design:

 > require('nlme')
 > set.seed(1)
 > nr<- 2  #reps per case
 > nB<- 4  #blocks
 > nT<- 2  #treatments
 > n<- nT*nB*nr  #total data
 > T<- rep(c(-1,1),nB*nr)
 > B<- factor(c(rep(1,nr*nT),rep(2,nr*nT),rep(3,nr*nT),rep(4,nr*nT)))
 > rB<- rnorm(nB,0,4)[B]
 > e<- rnorm(n,0,1)  #residuals
 > y<- T + rB + e
 > fit4m<- lme(y ~ T, random=~1|B)
 > summary(fit4m)
Linear mixed-effects model fit by REML
  Data: NULL
        AIC      BIC    logLik
   63.22191 65.77814 -27.61096

Random effects:
  Formula: ~1 | B
         (Intercept)  Residual
StdDev:    4.767061 0.8488003

Fixed effects: y ~ T
                 Value Std.Error DF  t-value p-value
(Intercept) 0.5351939 2.3929577 11 0.223654  0.8271
T           0.6916997 0.2122001 11 3.259658  0.0076
  Correlation:
   (Intr)
T 0

Standardized Within-Group Residuals:
         Min          Q1         Med          Q3         Max
-1.76880069 -0.62080393 -0.02900206  0.78562378  1.43929227

Number of Observations: 16
Number of Groups: 4
 > fit4f<- lm(y ~ T + B)
 > summary(fit4f)

Call:
lm(formula = y ~ T + B)

Residuals:
      Min       1Q   Median       3Q      Max
-1.46741 -0.50294 -0.03867  0.66197  1.25562

Coefficients:
             Estimate Std. Error t value Pr(>|t|)
(Intercept)  -2.3221     0.4244  -5.472 0.000194 ***
T             0.6917     0.2122   3.260 0.007604 **
B2            3.5997     0.6002   5.998 8.96e-05 ***
B3           -1.4594     0.6002  -2.432 0.033319 *
B4            9.2889     0.6002  15.477 8.20e-09 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.8488 on 11 degrees of freedom
Multiple R-squared: 0.9727,     Adjusted R-squared: 0.9628
F-statistic: 98.03 on 4 and 11 DF,  p-value: 1.587e-08

 > d<- coef(fit4f)[3:5]  #block coeffs
 > cB<- c(-0.25*d[1]-0.25*d[2]-0.25*d[3],
+   0.75*d[1]-0.25*d[2]-0.25*d[3],
+   -0.25*d[1]+0.75*d[2]-0.25*d[3],
+   -0.25*d[1]-0.25*d[2]+0.75*d[3]) #convert to mean = 0 basis
 > sd(cB)  #estimate random effect
[1] 4.785915

Note that the two approaches give essentially identical estimates.


At 02:11 PM 4/23/2010, Ben Bolker wrote:
>Here's my question for the group:   Given that it is a reasonable 
>*philosophical* position to say 'treat philosophically random 
>effects as random no matter what, and leave them in the model even 
>if they don't appear to be statistically significant', and given 
>that with small numbers of random-effect levels this approach is 
>likely to lead to numerical difficulties in most (??) mixed model 
>packages (warnings, errors, or low estimates of the variance), what 
>should one do?
><snip>


================================================================
Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
824 Timberlake Drive                     Tel: 757-467-0954
Virginia Beach, VA 23464-3239            Fax: 757-467-2947

"Vere scire est per causas scire"



From andydolman at gmail.com  Sat Apr 24 10:04:41 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Sat, 24 Apr 2010 10:04:41 +0200
Subject: [R-sig-ME] Random vs. fixed effects
In-Reply-To: <0L1D00IDF80YWI10@vms173015.mailsrvcs.net>
References: <263B04CBBF074046AFD8E36BA524E6170687F8C6@VHAV01MSGA2.v01.med.va.gov>
	<l2t971536df1004230941t95de95c5z25a1b8d5a616d787@mail.gmail.com>
	<4BD1E2E1.5030906@ufl.edu> <0L1D00IDF80YWI10@vms173015.mailsrvcs.net>
Message-ID: <h2i951234ac1004240104q372254fftb8c2aac5bce474f7@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100424/f2cd2b68/attachment.pl>

From charpent at bacbuc.dyndns.org  Fri Apr 23 23:57:21 2010
From: charpent at bacbuc.dyndns.org (Emmanuel Charpentier)
Date: Fri, 23 Apr 2010 23:57:21 +0200
Subject: [R-sig-ME] Random vs. fixed effects
In-Reply-To: <4BD1E2E1.5030906@ufl.edu>
References: <263B04CBBF074046AFD8E36BA524E6170687F8C6@VHAV01MSGA2.v01.med.va.gov>
	<l2t971536df1004230941t95de95c5z25a1b8d5a616d787@mail.gmail.com>
	<4BD1E2E1.5030906@ufl.edu>
Message-ID: <1272059840.3582.332.camel@PortableToshiba>

Two cents from an humble practitioner :

Le vendredi 23 avril 2010 ? 14:11 -0400, Ben Bolker a ?crit :
> Here's my question for the group:
> 
>   Given that it is a reasonable *philosophical* position to say 'treat
> philosophically random effects as random no matter what, and leave them
> in the model even if they don't appear to be statistically significant',
> and given that with small numbers of random-effect levels this approach
> is likely to lead to numerical difficulties in most (??) mixed model
> packages (warnings, errors, or low estimates of the variance), what
> should one do?  (Suppose one is in a situation that is too complicated
> to use classical method-of-moments approaches -- crossed designs, highly
> unbalanced data, GLMMs ...)
> 
>  1. philosophy, schmilosophy.  Fit these factors as a fixed effect,
> anything else is too dangerous/misleading/unworkable.
>  2. proceed with the 'standard' mixed model (lme4, nlme, PROC MIXED,
> ...) and hope it doesn't break.  Ignore warnings.
>  3. use Bayesian-computational approaches (MCMCglmm, WinBUGS, AD Model
> Builder with post-hoc MCMC calculation? Data cloning?)?  Possibly with
> half-Cauchy priors on variance as recommended by Gelman [Bayesian
> Analysis (2006) 1, Number 3, pp. 515?533]?

Schmilosophically speaking, option #3 has a set of interesting
features :

- It entails the creation and fitting of a full joint probability model.
Internal consistency is guranteed.

- Bayesian modeling tools (especially BUGS) offer enough flexibility to
*require* explicit *choices* for model assumption. For exmple, the
"standard" choice of a normal distribution for level II effects has to
be *explcitely writtern by the modeler, which gives him/her an
opportunity to consider and/or justify his/her choice. This is also true
of the choice of the modelization of nuisance parameters.

- There is no "formal" distinction between fixed and random effects ;
the latter are given a distribution (to be fitted), whereas the formere
are not.

However : 

- getting such a model to converge can be hard (especilly with BUGS).
Current tools need a real (maybe too much) understanding of the
numerical analysis problems to choose an *efficient* model expression,
and some "tricks" used to get convergence (such as rendering a model
deliberately unidentifible...) are difficult to justify rom a modeling
standpoint. Again, Gelman & Hill comparison of the current Bayesian
tools to early-generation regression software seems quite apt.

- The choices made about shape of distributions, relationships, etc ...
should be submitted to a sensitivity analysis, which raises again the
statistician's workload.

In short, option #3 is the *expensive* way of (maybe) getting the most
precise honest answer to your problem... if such thing exists and is
reachble with current numerical tools.

Murphy's law ensures that option #2 will "break" (and warnngs will be
ignored) especilly when warnings mean something important.

But option #1 is *also* an acceptable one : using it entails modeling
*conditionally on your experimental setup*. You won't be able to state
(directly) an estimation of the possible "population" effects of the
formerly-random effects, and the validity of your inferences about the
really-fixed effects will be formerly limited to the particular
population defined by these formerly-random effects. But that might be
okay if you have other information allowing you (and your reader) to
independently assess the possible value of an extrapolation from this
particulr subpopulation to an hypothetical population.

In short, option #1 is a cheap wy of getting a ossibly ccetable
approximate solution to your problem, whose value has to be assessed by
other means.

Of course, you won't benefit from artial pooling, and serious inter-unit
interactions will mess your inferences ...

HTH,

					Emmanuel Charpentier

> Gabor Grothendieck wrote:
> > Here is a simulation of 10k cases using 4 and 50 level factors for the
> > random effect.  With 4 levels there are numerical problems and the
> > accuracy of the random effect is terrible.  With 50 levels there are
> > no numerical problems and the accuracy is much better.
> > 
> >> library(lme4)
> >> set.seed(1)
> >> n <- 10000
> >> k <- 4
> >> f <- function(n, k) {
> > + set.seed(1)
> > + x <- 1:n
> > + fac <- gl(k, 1, n)
> > + fac.eff <- rnorm(k, 0, 4)[fac]
> > + e <- rnorm(n)
> > + y <- 1 + 2 * x + fac.eff + e
> > + lmer(y ~ x + (1|fac))
> > + }
> > 
> >> # simulation with 4 level random effect
> >> f(n, 4)
> > Linear mixed model fit by REML
> > Formula: y ~ x + (1 | fac)
> >    AIC   BIC logLik deviance REMLdev
> >  28733 28762 -14363    28702   28725
> > Random effects:
> >  Groups   Name        Variance Std.Dev.
> >  fac      (Intercept) 1.1162   1.0565
> >  Residual             1.0298   1.0148
> > Number of obs: 10000, groups: fac, 4
> > 
> > Fixed effects:
> >              Estimate Std. Error t value
> > (Intercept) 1.313e+00  5.286e-01       2
> > x           2.000e+00  3.515e-06  568923
> > 
> > Correlation of Fixed Effects:
> >   (Intr)
> > x -0.033
> > Warning message:
> > In mer_finalize(ans) : false convergence (8)
> > 
> >> # simulation with 50 level random effect
> >> f(n, 50)
> > Linear mixed model fit by REML
> > Formula: y ~ x + (1 | fac)
> >    AIC   BIC logLik deviance REMLdev
> >  29040 29069 -14516    29009   29032
> > Random effects:
> >  Groups   Name        Variance Std.Dev.
> >  fac      (Intercept) 11.2016  3.3469
> >  Residual              1.0251  1.0125
> > Number of obs: 10000, groups: fac, 50
> > 
> > Fixed effects:
> >              Estimate Std. Error t value
> > (Intercept) 1.396e+00  4.738e-01       3
> > x           2.000e+00  3.507e-06  570242
> > 
> > Correlation of Fixed Effects:
> >   (Intr)
> > x -0.037
> > 
> > 
> > 
> > 
> > On Fri, Apr 23, 2010 at 9:38 AM, Schultz, Mark R. <Mark.Schultz2 at va.gov> wrote:
> >> I just read a post by Andrew Dolman suggesting that a factor with only 3
> >> levels should be treated as a fixed effect. This seems to be a perennial
> >> question with mixed models. I'd really like to hear opinions from
> >> several experts as to whether there is a consensus on the topic. It
> >> really makes me uncomfortable that such an important modeling decision
> >> is made with an "ad hoc" heuristic.
> >>
> >>
> >>
> >> Thanks,
> >>
> >> Mark Schultz, Ph.D.
> >>
> >> Bedford VA Hospital
> >>
> >> Bedford, Ma.
> >>
> >>
> >>        [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> -- 
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / people.biology.ufl.edu/bolker
> GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From s.wood at bath.ac.uk  Sat Apr 24 12:56:39 2010
From: s.wood at bath.ac.uk (Simon Wood)
Date: Sat, 24 Apr 2010 11:56:39 +0100
Subject: [R-sig-ME] How to code proportional data with gamm binomial
	model using gamm4 package?
In-Reply-To: <B56D7C27B4408243B93FBC46ABECB5A0011A83C8F669@EXCH-MBX-F.ulaval.ca>
References: <B56D7C27B4408243B93FBC46ABECB5A0011A83C8F669@EXCH-MBX-F.ulaval.ca>
Message-ID: <201004241156.39980.s.wood@bath.ac.uk>

Julien,

Apologies for the cbind problem: I'll see what I can do about that.

The different results problem is probably because neither of your model 
specifications is quite right. For the `cbind' form of the response you 
should provide something ot the form cbind(success,failure), not 
cbind(success, success+failure). For the proportions form then you must 
supply a `weights' argument containing your `total'.

best,
Simon

On Friday 19 March 2010 19:30, Julien Beguin wrote:
> Dear user,
> ?
> I am trying to fit an additive mixed model with proportional data as
> response variable using gamm4 package. My proportional data are composed of
> 1) the number of time an individual was observed at location i (=presence),
> and 2) the number of time each location i was visited (=total). In my data
> set, I also have one random variable (=bloc) and a set of continuous
> independent variables that could explain part of the response variable
> variability. 
> Unfortunately, I have trouble to specify the response variable in the
> model. When I try to code proportional dataas "cbind(presence,total)", I
> don't have access to the "gam" object in the summary() function, while I
> can get the "mer" object which is, fortunately, similar to that from
> glmer() model... When I try to code proportional data directly as
> "proportion" ([0,1]) where proportion = presence/total, I can get all what
> I want except that model parameters and AIC values does not match the
> previous one anymore. I guess that I am doing something wrong here... 
> My question is how to code proportional response variables to get the "gam"
> object in the summary() function and that gives consistant results of AIC,
> parameter estimates, etc...? 
> My R code is below. It is a simple version where I included only one
> independent variable and no smooth term yet but in my real data set, I will
> use several independent variables, potentially with smoothers. 
> Any help would be really appreciated,
> ?
> Many thanks,
> ?
> Julien Beguin
>  Laval University
>  Ph.D. candidate
>
>
>  ----------------------------------------------- R code
> ---------------------------------------- #################
>  # simulated data#
>  #################
> ?
> set.seed(1001)
>  presence <- round(runif(50,0,15))
>  total <- round(runif(50,50,70))
>  prop <- presence/total
>  bloc <- rep(c(1,2,3,4,5), each=10)
>  x1 <- rnorm(50, 20, 5)
>  mydata <- as.data.frame(cbind(presence, total, prop, bloc, x1))
>  mydata$bloc <- as.factor(mydata$bloc)
> ?
> #############################################################
>  # gamm model with response variable as cbind(presence,total)#
>  #############################################################
>
> mod1 <- gamm4(cbind(presence,total)~ x1,
> random=~(1|bloc),family=binomial(link = "logit"), data=mydata)
> summary(mod1$gam)
>
> >Error in object$y - object$fitted.values : non-conformable arrays
>
> ?
> summary(mod1$mer)
>
> > AIC?? BIC logLik deviance
> >
>  > 150.7 156.4 -72.33??? 144.7
>  >
>  >Fixed effects:
>  >???????????? Estimate Std. Error z value Pr(>|z|)???
>  >X(Intercept) -1.54827??? 0.21700? -7.135? 9.7e-13 ***
>  >Xx1????????? -0.02927??? 0.01110? -2.637? 0.00837 **
>
> ?
> mod2 <- gamm4(prop~ x1, random=~(1|bloc),family=binomial(link = "logit"),
> data=mydata)
>
>  summary(mod2$gam)
>
> >Parametric coefficients:
>  >??????????? Estimate Std. Error z value Pr(>|z|)
>  >(Intercept) -1.35978??? 1.68946? -0.805??? 0.421
>  >x1????????? -0.03236??? 0.08600? -0.376??? 0.707
>
> ?
> summary(mod2$mer)
>
> > AIC?? BIC logLik deviance
> >
>  > 8.983 14.72 -1.492??? 2.983
> >
> >Fixed effects:
>  >???????????? Estimate Std. Error z value Pr(>|z|)
>  >X(Intercept) -1.35978??? 1.68946? -0.805??? 0.421
>  >Xx1????????? -0.03236??? 0.08600? -0.376??? 0.707
>
> ?
> mod3 <- glmer(cbind(presence,total)~ x1 + (1|bloc), family=binomial(link =
> "logit"), data=mydata, REML=FALSE) summary(mod3)
>
> > AIC?? BIC logLik deviance
> >
>  > 150.7 156.4 -72.33??? 144.7
> >
> >Fixed effects:
>  >??????????? Estimate Std. Error z value Pr(>|z|)???
>  >(Intercept) -1.54827??? 0.21700? -7.135? 9.7e-13 ***
>  >x1????????? -0.02927??? 0.01110? -2.637? 0.00837 **
>
> ?
> mod4 <- glmer(prop~ x1 + (1|bloc), family=binomial(link = "logit"),
> data=mydata, REML=FALSE) summary(mod4)
>
> > AIC?? BIC logLik deviance
> >
>  > 8.983 14.72 -1.492??? 2.983
> >
> >Fixed effects:
>  >??????????? Estimate Std. Error z value Pr(>|z|)
>  >(Intercept) -1.35978??? 1.68946? -0.805??? 0.421
>  >x1????????? -0.03236??? 0.08600? -0.376??? 0.707

-- 
> Simon Wood, Mathematical Sciences, University of Bath, Bath, BA2 7AY UK
> +44 1225 386603  www.maths.bath.ac.uk/~sw283 



From R.COE at CGIAR.ORG  Sat Apr 24 15:07:46 2010
From: R.COE at CGIAR.ORG (Coe, Richard (ICRAF-ILRI))
Date: Sat, 24 Apr 2010 16:07:46 +0300
Subject: [R-sig-ME] Random vs. fixed effects
References: <263B04CBBF074046AFD8E36BA524E6170687F8C6@VHAV01MSGA2.v01.med.va.gov><l2t971536df1004230941t95de95c5z25a1b8d5a616d787@mail.gmail.com><4BD1E2E1.5030906@ufl.edu>
	<1272059840.3582.332.camel@PortableToshiba>
Message-ID: <4658B112D15C194CAC8A76DCFE75E22B07BCAEE3@icrafmx.ICRAF.CGIARAD.ORG>

I am surprised at suggestions that the problem of random effects with very few levels can be overcome by changing modelling framework or estimation algorithms.

It seems to me that the problem is a basic one of lack of information. If you want to estimate the variance of something you really need more than 3 observations. No amount of fiddling with the model or algorithms will change that. The only thing that might change it is to use Bayesian methods with informative priors, but then you are changing the problem by taking some information from elsewhere.

I reach the same conclusion if I think about the 'scope of inference'. I cannot expect to say much about a population I have just 3 observations from.

Statistical finesse cannot compensate for a basic lack of information. 


Richard Coe
Principal Scientist ? Research Methods
World Agroforestry Centre (ICRAF), Nairobi

and

Statistical Services Centre, U Reading.


-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Emmanuel Charpentier
Sent: Saturday, April 24, 2010 12:57 AM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Random vs. fixed effects

Two cents from an humble practitioner :

Le vendredi 23 avril 2010 ? 14:11 -0400, Ben Bolker a ?crit :
> Here's my question for the group:
> 
>   Given that it is a reasonable *philosophical* position to say 'treat
> philosophically random effects as random no matter what, and leave them
> in the model even if they don't appear to be statistically significant',
> and given that with small numbers of random-effect levels this approach
> is likely to lead to numerical difficulties in most (??) mixed model
> packages (warnings, errors, or low estimates of the variance), what
> should one do?  (Suppose one is in a situation that is too complicated
> to use classical method-of-moments approaches -- crossed designs, highly
> unbalanced data, GLMMs ...)
> 
>  1. philosophy, schmilosophy.  Fit these factors as a fixed effect,
> anything else is too dangerous/misleading/unworkable.
>  2. proceed with the 'standard' mixed model (lme4, nlme, PROC MIXED,
> ...) and hope it doesn't break.  Ignore warnings.
>  3. use Bayesian-computational approaches (MCMCglmm, WinBUGS, AD Model
> Builder with post-hoc MCMC calculation? Data cloning?)?  Possibly with
> half-Cauchy priors on variance as recommended by Gelman [Bayesian
> Analysis (2006) 1, Number 3, pp. 515?533]?

Schmilosophically speaking, option #3 has a set of interesting
features :

- It entails the creation and fitting of a full joint probability model.
Internal consistency is guranteed.

- Bayesian modeling tools (especially BUGS) offer enough flexibility to
*require* explicit *choices* for model assumption. For exmple, the
"standard" choice of a normal distribution for level II effects has to
be *explcitely writtern by the modeler, which gives him/her an
opportunity to consider and/or justify his/her choice. This is also true
of the choice of the modelization of nuisance parameters.

- There is no "formal" distinction between fixed and random effects ;
the latter are given a distribution (to be fitted), whereas the formere
are not.

However : 

- getting such a model to converge can be hard (especilly with BUGS).
Current tools need a real (maybe too much) understanding of the
numerical analysis problems to choose an *efficient* model expression,
and some "tricks" used to get convergence (such as rendering a model
deliberately unidentifible...) are difficult to justify rom a modeling
standpoint. Again, Gelman & Hill comparison of the current Bayesian
tools to early-generation regression software seems quite apt.

- The choices made about shape of distributions, relationships, etc ...
should be submitted to a sensitivity analysis, which raises again the
statistician's workload.

In short, option #3 is the *expensive* way of (maybe) getting the most
precise honest answer to your problem... if such thing exists and is
reachble with current numerical tools.

Murphy's law ensures that option #2 will "break" (and warnngs will be
ignored) especilly when warnings mean something important.

But option #1 is *also* an acceptable one : using it entails modeling
*conditionally on your experimental setup*. You won't be able to state
(directly) an estimation of the possible "population" effects of the
formerly-random effects, and the validity of your inferences about the
really-fixed effects will be formerly limited to the particular
population defined by these formerly-random effects. But that might be
okay if you have other information allowing you (and your reader) to
independently assess the possible value of an extrapolation from this
particulr subpopulation to an hypothetical population.

In short, option #1 is a cheap wy of getting a ossibly ccetable
approximate solution to your problem, whose value has to be assessed by
other means.

Of course, you won't benefit from artial pooling, and serious inter-unit
interactions will mess your inferences ...

HTH,

					Emmanuel Charpentier

> Gabor Grothendieck wrote:
> > Here is a simulation of 10k cases using 4 and 50 level factors for the
> > random effect.  With 4 levels there are numerical problems and the
> > accuracy of the random effect is terrible.  With 50 levels there are
> > no numerical problems and the accuracy is much better.
> > 
> >> library(lme4)
> >> set.seed(1)
> >> n <- 10000
> >> k <- 4
> >> f <- function(n, k) {
> > + set.seed(1)
> > + x <- 1:n
> > + fac <- gl(k, 1, n)
> > + fac.eff <- rnorm(k, 0, 4)[fac]
> > + e <- rnorm(n)
> > + y <- 1 + 2 * x + fac.eff + e
> > + lmer(y ~ x + (1|fac))
> > + }
> > 
> >> # simulation with 4 level random effect
> >> f(n, 4)
> > Linear mixed model fit by REML
> > Formula: y ~ x + (1 | fac)
> >    AIC   BIC logLik deviance REMLdev
> >  28733 28762 -14363    28702   28725
> > Random effects:
> >  Groups   Name        Variance Std.Dev.
> >  fac      (Intercept) 1.1162   1.0565
> >  Residual             1.0298   1.0148
> > Number of obs: 10000, groups: fac, 4
> > 
> > Fixed effects:
> >              Estimate Std. Error t value
> > (Intercept) 1.313e+00  5.286e-01       2
> > x           2.000e+00  3.515e-06  568923
> > 
> > Correlation of Fixed Effects:
> >   (Intr)
> > x -0.033
> > Warning message:
> > In mer_finalize(ans) : false convergence (8)
> > 
> >> # simulation with 50 level random effect
> >> f(n, 50)
> > Linear mixed model fit by REML
> > Formula: y ~ x + (1 | fac)
> >    AIC   BIC logLik deviance REMLdev
> >  29040 29069 -14516    29009   29032
> > Random effects:
> >  Groups   Name        Variance Std.Dev.
> >  fac      (Intercept) 11.2016  3.3469
> >  Residual              1.0251  1.0125
> > Number of obs: 10000, groups: fac, 50
> > 
> > Fixed effects:
> >              Estimate Std. Error t value
> > (Intercept) 1.396e+00  4.738e-01       3
> > x           2.000e+00  3.507e-06  570242
> > 
> > Correlation of Fixed Effects:
> >   (Intr)
> > x -0.037
> > 
> > 
> > 
> > 
> > On Fri, Apr 23, 2010 at 9:38 AM, Schultz, Mark R. <Mark.Schultz2 at va.gov> wrote:
> >> I just read a post by Andrew Dolman suggesting that a factor with only 3
> >> levels should be treated as a fixed effect. This seems to be a perennial
> >> question with mixed models. I'd really like to hear opinions from
> >> several experts as to whether there is a consensus on the topic. It
> >> really makes me uncomfortable that such an important modeling decision
> >> is made with an "ad hoc" heuristic.
> >>
> >>
> >>
> >> Thanks,
> >>
> >> Mark Schultz, Ph.D.
> >>
> >> Bedford VA Hospital
> >>
> >> Bedford, Ma.
> >>
> >>
> >>        [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> -- 
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / people.biology.ufl.edu/bolker
> GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
 

__________ Information from ESET NOD32 Antivirus, version of virus signature database 5055 (20100424) __________

The message was checked by ESET NOD32 Antivirus.

http://www.eset.com
 
 

__________ Information from ESET NOD32 Antivirus, version of virus signature database 5055 (20100424) __________

The message was checked by ESET NOD32 Antivirus.

http://www.eset.com
 

From otter at otter-rsch.com  Sat Apr 24 08:06:24 2010
From: otter at otter-rsch.com (dave fournier)
Date: Sat, 24 Apr 2010 02:06:24 -0400
Subject: [R-sig-ME] Random vs. fixed effects
In-Reply-To: <l2t971536df1004230941t95de95c5z25a1b8d5a616d787@mail.gmail.com>
References: <l2t971536df1004230941t95de95c5z25a1b8d5a616d787@mail.gmail.com>
Message-ID: <4BD28A60.4020706@otter-rsch.com>

It appears that the real problem here is not with the data, but with the
estimation procedure.  When fitting the model by maximum likelihood both
lme and AD Model builder give an estimate of about 3.8 (true value 4)
for the std dev of the RE's.  When fitting the data by reml
AD Model builder gets an estimate of about 4.4.  I think that the
reml estimation is more numerically challenging than ml and that lmer's
algorithm is just not up to the job. You can see the ADMB code etc.
at

         http://groups.google.com/group/admb-users/t/83d371e04bbe48c9



From s.wood at bath.ac.uk  Sat Apr 24 16:51:50 2010
From: s.wood at bath.ac.uk (Simon Wood)
Date: Sat, 24 Apr 2010 15:51:50 +0100
Subject: [R-sig-ME] How to code proportional data with gamm binomial
	model using gamm4 package?
In-Reply-To: <B56D7C27B4408243B93FBC46ABECB5A0011A83C8F669@EXCH-MBX-F.ulaval.ca>
References: <B56D7C27B4408243B93FBC46ABECB5A0011A83C8F669@EXCH-MBX-F.ulaval.ca>
Message-ID: <201004241551.50909.s.wood@bath.ac.uk>

Ah, amusingly I have coded gamm4 so that you can't supply a weights vector. 
Sorry. Fixed for version 0.0-3 (out soon). best,  Simon


On Friday 19 March 2010 19:30, Julien Beguin wrote:
> Dear user,
> ?
> I am trying to fit an additive mixed model with proportional data as
> response variable using gamm4 package. My proportional data are composed of
> 1) the number of time an individual was observed at location i (=presence),
> and 2) the number of time each location i was visited (=total). In my data
> set, I also have one random variable (=bloc) and a set of continuous
> independent variables that could explain part of the response variable
> variability. 
> Unfortunately, I have trouble to specify the response variable in the
> model. When I try to code proportional dataas "cbind(presence,total)", I
> don't have access to the "gam" object in the summary() function, while I
> can get the "mer" object which is, fortunately, similar to that from
> glmer() model... When I try to code proportional data directly as
> "proportion" ([0,1]) where proportion = presence/total, I can get all what
> I want except that model parameters and AIC values does not match the
> previous one anymore. I guess that I am doing something wrong here... 
> My question is how to code proportional response variables to get the "gam"
> object in the summary() function and that gives consistant results of AIC,
> parameter estimates, etc...? 
> My R code is below. It is a simple version where I included only one
> independent variable and no smooth term yet but in my real data set, I will
> use several independent variables, potentially with smoothers. 
> Any help would be really appreciated,
> ?
> Many thanks,
> ?
> Julien Beguin
>  Laval University
>  Ph.D. candidate
>
>
>  ----------------------------------------------- R code
> ---------------------------------------- #################
>  # simulated data#
>  #################
> ?
> set.seed(1001)
>  presence <- round(runif(50,0,15))
>  total <- round(runif(50,50,70))
>  prop <- presence/total
>  bloc <- rep(c(1,2,3,4,5), each=10)
>  x1 <- rnorm(50, 20, 5)
>  mydata <- as.data.frame(cbind(presence, total, prop, bloc, x1))
>  mydata$bloc <- as.factor(mydata$bloc)
> ?
> #############################################################
>  # gamm model with response variable as cbind(presence,total)#
>  #############################################################
>
> mod1 <- gamm4(cbind(presence,total)~ x1,
> random=~(1|bloc),family=binomial(link = "logit"), data=mydata)
> summary(mod1$gam)
>
> >Error in object$y - object$fitted.values : non-conformable arrays
>
> ?
> summary(mod1$mer)
>
> > AIC?? BIC logLik deviance
> >
>  > 150.7 156.4 -72.33??? 144.7
>  >
>  >Fixed effects:
>  >???????????? Estimate Std. Error z value Pr(>|z|)???
>  >X(Intercept) -1.54827??? 0.21700? -7.135? 9.7e-13 ***
>  >Xx1????????? -0.02927??? 0.01110? -2.637? 0.00837 **
>
> ?
> mod2 <- gamm4(prop~ x1, random=~(1|bloc),family=binomial(link = "logit"),
> data=mydata)
>
>  summary(mod2$gam)
>
> >Parametric coefficients:
>  >??????????? Estimate Std. Error z value Pr(>|z|)
>  >(Intercept) -1.35978??? 1.68946? -0.805??? 0.421
>  >x1????????? -0.03236??? 0.08600? -0.376??? 0.707
>
> ?
> summary(mod2$mer)
>
> > AIC?? BIC logLik deviance
> >
>  > 8.983 14.72 -1.492??? 2.983
> >
> >Fixed effects:
>  >???????????? Estimate Std. Error z value Pr(>|z|)
>  >X(Intercept) -1.35978??? 1.68946? -0.805??? 0.421
>  >Xx1????????? -0.03236??? 0.08600? -0.376??? 0.707
>
> ?
> mod3 <- glmer(cbind(presence,total)~ x1 + (1|bloc), family=binomial(link =
> "logit"), data=mydata, REML=FALSE) summary(mod3)
>
> > AIC?? BIC logLik deviance
> >
>  > 150.7 156.4 -72.33??? 144.7
> >
> >Fixed effects:
>  >??????????? Estimate Std. Error z value Pr(>|z|)???
>  >(Intercept) -1.54827??? 0.21700? -7.135? 9.7e-13 ***
>  >x1????????? -0.02927??? 0.01110? -2.637? 0.00837 **
>
> ?
> mod4 <- glmer(prop~ x1 + (1|bloc), family=binomial(link = "logit"),
> data=mydata, REML=FALSE) summary(mod4)
>
> > AIC?? BIC logLik deviance
> >
>  > 8.983 14.72 -1.492??? 2.983
> >
> >Fixed effects:
>  >??????????? Estimate Std. Error z value Pr(>|z|)
>  >(Intercept) -1.35978??? 1.68946? -0.805??? 0.421
>  >x1????????? -0.03236??? 0.08600? -0.376??? 0.707

-- 
> Simon Wood, Mathematical Sciences, University of Bath, Bath, BA2 7AY UK
> +44 1225 386603  www.maths.bath.ac.uk/~sw283 



From ggrothendieck at gmail.com  Sat Apr 24 18:34:04 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 24 Apr 2010 12:34:04 -0400
Subject: [R-sig-ME] Random vs. fixed effects
In-Reply-To: <l2t971536df1004230941t95de95c5z25a1b8d5a616d787@mail.gmail.com>
References: <263B04CBBF074046AFD8E36BA524E6170687F8C6@VHAV01MSGA2.v01.med.va.gov>
	<l2t971536df1004230941t95de95c5z25a1b8d5a616d787@mail.gmail.com>
Message-ID: <l2i971536df1004240934x17a38a0at1a8ec351201d758c@mail.gmail.com>

Here it is redone with lme.  lme seems not to exhibit the numerical
problems for 4 levels that we saw with lmer.

> library(nlme)
> set.seed(1)
> f <- function(n, k) {
+   set.seed(1)
+   x <- 1:n
+   fac <- gl(k, 1, n)
+   fac.eff <- rnorm(k, 0, 4)[fac]
+   e <- rnorm(n)
+   y <- 1 + 2 * x + fac.eff + e
+   lme(y ~ x, random = ~ 1 | fac)
+ }
> n <- 10000
> f(n, 4) # 4 levels
Linear mixed-effects model fit by REML
  Data: NULL
  Log-restricted-likelihood: -14342.06
  Fixed: y ~ x
(Intercept)           x
   1.313495    1.999999

Random effects:
 Formula: ~1 | fac
        (Intercept) Residual
StdDev:    4.421380 1.012295

Number of Observations: 10000
Number of Groups: 4

> ######################
> f(n, 50) # 50 levels
Linear mixed-effects model fit by REML
  Data: NULL
  Log-restricted-likelihood: -14515.87
  Fixed: y ~ x
(Intercept)           x
   1.396288    2.000000

Random effects:
 Formula: ~1 | fac
        (Intercept) Residual
StdDev:    3.322084  1.01249

Number of Observations: 10000
Number of Groups: 50



On Fri, Apr 23, 2010 at 12:41 PM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
> Here is a simulation of 10k cases using 4 and 50 level factors for the
> random effect. ?With 4 levels there are numerical problems and the
> accuracy of the random effect is terrible. ?With 50 levels there are
> no numerical problems and the accuracy is much better.
>
>> library(lme4)
>> set.seed(1)
>> n <- 10000
>> k <- 4
>> f <- function(n, k) {
> + set.seed(1)
> + x <- 1:n
> + fac <- gl(k, 1, n)
> + fac.eff <- rnorm(k, 0, 4)[fac]
> + e <- rnorm(n)
> + y <- 1 + 2 * x + fac.eff + e
> + lmer(y ~ x + (1|fac))
> + }
>
>> # simulation with 4 level random effect
>> f(n, 4)
> Linear mixed model fit by REML
> Formula: y ~ x + (1 | fac)
> ? AIC ? BIC logLik deviance REMLdev
> ?28733 28762 -14363 ? ?28702 ? 28725
> Random effects:
> ?Groups ? Name ? ? ? ?Variance Std.Dev.
> ?fac ? ? ?(Intercept) 1.1162 ? 1.0565
> ?Residual ? ? ? ? ? ? 1.0298 ? 1.0148
> Number of obs: 10000, groups: fac, 4
>
> Fixed effects:
> ? ? ? ? ? ? Estimate Std. Error t value
> (Intercept) 1.313e+00 ?5.286e-01 ? ? ? 2
> x ? ? ? ? ? 2.000e+00 ?3.515e-06 ?568923
>
> Correlation of Fixed Effects:
> ?(Intr)
> x -0.033
> Warning message:
> In mer_finalize(ans) : false convergence (8)
>
>> # simulation with 50 level random effect
>> f(n, 50)
> Linear mixed model fit by REML
> Formula: y ~ x + (1 | fac)
> ? AIC ? BIC logLik deviance REMLdev
> ?29040 29069 -14516 ? ?29009 ? 29032
> Random effects:
> ?Groups ? Name ? ? ? ?Variance Std.Dev.
> ?fac ? ? ?(Intercept) 11.2016 ?3.3469
> ?Residual ? ? ? ? ? ? ?1.0251 ?1.0125
> Number of obs: 10000, groups: fac, 50
>
> Fixed effects:
> ? ? ? ? ? ? Estimate Std. Error t value
> (Intercept) 1.396e+00 ?4.738e-01 ? ? ? 3
> x ? ? ? ? ? 2.000e+00 ?3.507e-06 ?570242
>
> Correlation of Fixed Effects:
> ?(Intr)
> x -0.037
>
>
>
>
> On Fri, Apr 23, 2010 at 9:38 AM, Schultz, Mark R. <Mark.Schultz2 at va.gov> wrote:
>> I just read a post by Andrew Dolman suggesting that a factor with only 3
>> levels should be treated as a fixed effect. This seems to be a perennial
>> question with mixed models. I'd really like to hear opinions from
>> several experts as to whether there is a consensus on the topic. It
>> really makes me uncomfortable that such an important modeling decision
>> is made with an "ad hoc" heuristic.
>>
>>
>>
>> Thanks,
>>
>> Mark Schultz, Ph.D.
>>
>> Bedford VA Hospital
>>
>> Bedford, Ma.
>>
>>
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>



From otter at otter-rsch.com  Sat Apr 24 11:18:16 2010
From: otter at otter-rsch.com (dave fournier)
Date: Sat, 24 Apr 2010 05:18:16 -0400
Subject: [R-sig-ME] Random vs. fixed effects
In-Reply-To: <l2i971536df1004240934x17a38a0at1a8ec351201d758c@mail.gmail.com>
References: <l2i971536df1004240934x17a38a0at1a8ec351201d758c@mail.gmail.com>
Message-ID: <4BD2B758.6030803@otter-rsch.com>

I think the point is that lme only addresses the simplest case of a
linear mixed model and that by such specialization it is more effective
in this case. lmer attempts  to handle slightly more complex mixed
models and must use a different algorithm and this algorithm
seems to fail. AD Model Builder on the other hand uses
a much more general algorithm intended to work with arbitrary nonlinear
mixed models. To stick with the current simple example suppose that you
want to have the regression be robust such as assuming that the random
variable e has a fat-tailed student's distribution. This can easily be
done in ADMB, but not in lme, I believe.



From ggrothendieck at gmail.com  Sat Apr 24 19:34:25 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 24 Apr 2010 13:34:25 -0400
Subject: [R-sig-ME] Random vs. fixed effects
In-Reply-To: <l2t971536df1004230941t95de95c5z25a1b8d5a616d787@mail.gmail.com>
References: <263B04CBBF074046AFD8E36BA524E6170687F8C6@VHAV01MSGA2.v01.med.va.gov>
	<l2t971536df1004230941t95de95c5z25a1b8d5a616d787@mail.gmail.com>
Message-ID: <j2v971536df1004241034o890cff5ej5d3775e76a0fdcc8@mail.gmail.com>

Just one other comment so that we are not unfair to lmer.  I was using
the CRAN version of lmer.  Using the development version in package
lme4a there are no numerical problems for the 4 level case. Thus it
appears that lme, lme4a and ADMB all handle this case.

> library(lme4a)
Loading required package: Matrix
Loading required package: lattice

Attaching package: 'Matrix'


        The following object(s) are masked from package:base :

         det

> set.seed(1)
> f <- function(n, k) {
+   set.seed(1)
+   x <- 1:n
+   fac <- gl(k, 1, n)
+   fac.eff <- rnorm(k, 0, 4)[fac]
+   e <- rnorm(n)
+   y <- 1 + 2 * x + fac.eff + e
+   # lme(y ~ x, random = ~ 1 | fac)
+   lmer(y ~ x + (1 | fac))
+ }
> n <- 10000
> f(n, 4)
Linear mixed model fit by REML
Formula: y ~ x + (1 | fac)
 REML
28684

Random effects:
 Groups   Name        Variance Std.Dev.
 fac      (Intercept) 19.5486  4.4214
 Residual              1.0247  1.0123
Number of obs: 10000, groups: fac, 4

Fixed effects:
             Estimate Std. Error t value
(Intercept) 1.313e+00  2.211e+00       1
x           2.000e+00  3.507e-06  570338

Correlation of Fixed Effects:
  (Intr)
x -0.008
> packageDescription("lme4a")$Version
[1] "0.999375-45"


On Fri, Apr 23, 2010 at 12:41 PM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
> Here is a simulation of 10k cases using 4 and 50 level factors for the
> random effect. ?With 4 levels there are numerical problems and the
> accuracy of the random effect is terrible. ?With 50 levels there are
> no numerical problems and the accuracy is much better.
>
>> library(lme4)
>> set.seed(1)
>> n <- 10000
>> k <- 4
>> f <- function(n, k) {
> + set.seed(1)
> + x <- 1:n
> + fac <- gl(k, 1, n)
> + fac.eff <- rnorm(k, 0, 4)[fac]
> + e <- rnorm(n)
> + y <- 1 + 2 * x + fac.eff + e
> + lmer(y ~ x + (1|fac))
> + }
>
>> # simulation with 4 level random effect
>> f(n, 4)
> Linear mixed model fit by REML
> Formula: y ~ x + (1 | fac)
> ? AIC ? BIC logLik deviance REMLdev
> ?28733 28762 -14363 ? ?28702 ? 28725
> Random effects:
> ?Groups ? Name ? ? ? ?Variance Std.Dev.
> ?fac ? ? ?(Intercept) 1.1162 ? 1.0565
> ?Residual ? ? ? ? ? ? 1.0298 ? 1.0148
> Number of obs: 10000, groups: fac, 4
>
> Fixed effects:
> ? ? ? ? ? ? Estimate Std. Error t value
> (Intercept) 1.313e+00 ?5.286e-01 ? ? ? 2
> x ? ? ? ? ? 2.000e+00 ?3.515e-06 ?568923
>
> Correlation of Fixed Effects:
> ?(Intr)
> x -0.033
> Warning message:
> In mer_finalize(ans) : false convergence (8)
>
>> # simulation with 50 level random effect
>> f(n, 50)
> Linear mixed model fit by REML
> Formula: y ~ x + (1 | fac)
> ? AIC ? BIC logLik deviance REMLdev
> ?29040 29069 -14516 ? ?29009 ? 29032
> Random effects:
> ?Groups ? Name ? ? ? ?Variance Std.Dev.
> ?fac ? ? ?(Intercept) 11.2016 ?3.3469
> ?Residual ? ? ? ? ? ? ?1.0251 ?1.0125
> Number of obs: 10000, groups: fac, 50
>
> Fixed effects:
> ? ? ? ? ? ? Estimate Std. Error t value
> (Intercept) 1.396e+00 ?4.738e-01 ? ? ? 3
> x ? ? ? ? ? 2.000e+00 ?3.507e-06 ?570242
>
> Correlation of Fixed Effects:
> ?(Intr)
> x -0.037
>
>
>
>
> On Fri, Apr 23, 2010 at 9:38 AM, Schultz, Mark R. <Mark.Schultz2 at va.gov> wrote:
>> I just read a post by Andrew Dolman suggesting that a factor with only 3
>> levels should be treated as a fixed effect. This seems to be a perennial
>> question with mixed models. I'd really like to hear opinions from
>> several experts as to whether there is a consensus on the topic. It
>> really makes me uncomfortable that such an important modeling decision
>> is made with an "ad hoc" heuristic.
>>
>>
>>
>> Thanks,
>>
>> Mark Schultz, Ph.D.
>>
>> Bedford VA Hospital
>>
>> Bedford, Ma.
>>
>>
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>



From argchris at hotmail.com  Mon Apr 26 05:37:13 2010
From: argchris at hotmail.com (Christos Argyropoulos)
Date: Mon, 26 Apr 2010 06:37:13 +0300
Subject: [R-sig-ME] Random vs. fixed effects
Message-ID: <BLU149-W681ECDCB15FD33D85A47AD8040@phx.gbl>


Dave Fournier wrote ...

"It appears that the real problem here is not with the data, but with the
estimation procedure...."

This appears to be the case, but ADMB is not the only package that produces the "right" REML solution.
The "old" function (lme from package nlme) yields the "correct" answer and so does proc mixed (in SAS)

The results are summarized in the following table (the code and the R/SAS program output is attached at
the end of the email). 


Function ??           4 Level Factor???        50 Level Factor ? ?    Truth

lmer(lme4)??              1.0565 ? ? ? ? ? ?                3.3469 ? ? ? ? ? ?         4.0
lme(nlme)???               4.4215????????????                 3.3221 ? ? ? ? ? ?         4.0
proc mixed ?         4.4214????????????                 3.3221????????????          4.0
ADMB????????                    4.4214?????????????? NA?????????????? 4.0


If I remember correctly lme(nlme) uses a few EM steps before switching to a Newton type of algorithm 
for the optimization (what about lmer?). It is sort of funny that the SAS help file on proc mixed downplays this
approach, yet the results are the same!

SAS Help file text:
('PROC MIXED uses a 
ridge-stabilized Newton-Raphson algorithm to optimize either a full (ML) or 
residual (REML) 
likelihood function. The Newton-Raphson algorithm is preferred 
to the EM algorithm (Lindstrom and Bates 1988) ')

If I find the time I will run the same example in WinBUGS to see what comes out of it.

The discussion of how to adjust for such effects (fixed v.s. random effects) has an interesting counterpart in survival analysis i.e. whether
center effects should be adjusted for by including them a in the model design matrix or by specifying a separate baseline hazard
for each of the centers (=levels of a factor). It all boils down to what one wants to achieve by such adjustment; if the factor effects are of inferential interest them I guess they should be included as fixed effects. If they are not of primary inferential interest, then including them as random effects 
(or baseline hazards in survival analysis) is the way to go.

Christos Argyropoulos

CODE


R side (to simulate the datasets)

 set.seed(1)
 n <- 10000
 k <- 4
 f <- function(n, k) {
 set.seed(1)
 x <- 1:n
 fac <- gl(k, 1, n)
 fac.eff <- rnorm(k, 0, 4)[fac]
 e <- rnorm(n)
 y <- 1 + 2 * x + fac.eff + e
data.frame(y=y,x=x,fac_eff=fac.eff,fac=fac)
}

d4<-f(10000,4)
d50<-f(10000,50)

write.dta(d4,"d4.dta")
write.dta(d50,"d50.dta")

(save the stata files somewhere handy e.g. in C:\Temp because you will need it to import the data
in SAS)
####################################################################
FACTOR WITH 4 LEVELS in R
####################################################################

> lme(y~x,random=~1|fac,data=d4)
Linear mixed-effects model fit by REML
  Data: d4
  Log-restricted-likelihood: -14342.06
  Fixed: y ~ x
(Intercept)           x
   1.313495    1.999999

Random effects:
 Formula: ~1 | fac
        (Intercept) Residual
StdDev:    4.421380 1.012295

Number of Observations: 10000
Number of Groups: 4

> lmer(y~x+(1|fac),data=d4)
Linear mixed model fit by REML
Formula: y ~ x + (1 | fac)
   Data: d4
   AIC   BIC logLik deviance REMLdev
 28733 28762 -14363    28702   28725
Random effects:
 Groups   Name        Variance Std.Dev.
 fac      (Intercept) 1.1162   1.0565
 Residual             1.0298   1.0148
Number of obs: 10000, groups: fac, 4

Fixed effects:
             Estimate Std. Error t value
(Intercept) 1.313e+00  5.286e-01       2
x           2.000e+00  3.515e-06  568923

Correlation of Fixed Effects:
  (Intr)
x -0.033
Warning message:
In mer_finalize(ans) : false convergence (8)


####################################################################
FACTOR WITH 50 LEVELS in R
####################################################################

> lme(y~x,random=~1|fac,data=d50)
Linear mixed-effects model fit by REML
  Data: d50
  Log-restricted-likelihood: -14515.87
  Fixed: y ~ x
(Intercept)           x
   1.396288    2.000000

Random effects:
 Formula: ~1 | fac
        (Intercept) Residual
StdDev:    3.322084  1.01249

Number of Observations: 10000
Number of Groups: 50
>

> lmer(y~x+(1|fac),data=d50)
Linear mixed model fit by REML
Formula: y ~ x + (1 | fac)
   Data: d50
   AIC   BIC logLik deviance REMLdev
 29040 29069 -14516    29009   29032
Random effects:
 Groups   Name        Variance Std.Dev.
 fac      (Intercept) 11.2016  3.3469
 Residual              1.0251  1.0125
Number of obs: 10000, groups: fac, 50

Fixed effects:
             Estimate Std. Error t value
(Intercept) 1.396e+00  4.738e-01       3
x           2.000e+00  3.507e-06  570242

Correlation of Fixed Effects:
  (Intr)
x -0.037
>


******************************************
SAS side
******************************************
PROC IMPORT OUT= WORK.d4
            DATAFILE= "C:\Temp\d4.dta"
            DBMS=DTA REPLACE;
RUN;

PROC IMPORT OUT= WORK.d50
            DATAFILE= "C:\Temp\d50.dta"
            DBMS=DTA REPLACE;
RUN;
proc sort data=work.d4 out=work.d4;
        by fac;
run;
proc sort data=work.d50 out=work.d50;
        by fac;
run;


proc mixed data=work.d4 method=REML;
   class fac;
   model y = x/s;
   random fac;
run;

proc mixed data=work.d50;
   class fac;
   model y = x/s;
   random fac;
run;


####################################################################
FACTOR WITH 4 LEVELS in SAS
####################################################################


                                    Convergence criteria met.

                                          The SAS System          22:12 Sunday, April 25, 2010  25

                                       The Mixed Procedure

                                      Covariance Parameter
                                            Estimates

                                      Cov Parm     Estimate

                                      FAC           11.0363
                                      Residual       1.0251


                                         Fit Statistics

                              -2 Res Log Likelihood         29031.7
                              AIC (smaller is better)       29035.7
                              AICC (smaller is better)      29035.7
                              BIC (smaller is better)       29039.5


                                    Solution for Fixed Effects

                                          Standard
                 Effect       Estimate       Error      DF    t Value    Pr> |t|

                 Intercept      1.3963      0.4703      49       2.97      0.0046
                 X              2.0000    3.507E-6    9949     570221      <.0001


                                  Type 3 Tests of Fixed Effects

                                        Num     Den
                          Effect         DF      DF    F Value    Pr> F

                          X               1    9949    3.25E11    <.0001


####################################################################
FACTOR WITH 50 LEVELS in SAS
####################################################################


                                          The SAS System          22:12 Sunday, April 25, 2010  25

                                       The Mixed Procedure

                                      Covariance Parameter
                                            Estimates

                                      Cov Parm     Estimate

                                      FAC           11.0363
                                      Residual       1.0251


                                         Fit Statistics

                              -2 Res Log Likelihood         29031.7
                              AIC (smaller is better)       29035.7
                              AICC (smaller is better)      29035.7
                              BIC (smaller is better)       29039.5


                                    Solution for Fixed Effects

                                          Standard
                 Effect       Estimate       Error      DF    t Value    Pr> |t|

                 Intercept      1.3963      0.4703      49       2.97      0.0046
                 X              2.0000    3.507E-6    9949     570221      <.0001


                                  Type 3 Tests of Fixed Effects

                                        Num     Den
                          Effect         DF      DF    F Value    Pr> F

                          X               1    9949    3.25E11    <.0001

 		 	   		  
_________________________________________________________________
Hotmail: Trusted email with Microsoft?s powerful SPAM protection.



From studdsc at gmail.com  Mon Apr 26 16:22:24 2010
From: studdsc at gmail.com (Colin Studds)
Date: Mon, 26 Apr 2010 10:22:24 -0400
Subject: [R-sig-ME] lme4 missing?
Message-ID: <5833B36A-C174-48D4-94AE-4E52B1CD14A9@gmail.com>

Hi all,
I just installed R on a new machine and can't link to the binaries for lme4 at any of the mirrors. Are others seeing the same? The r-cran site also seems to be down presently.  
Colin


From bolker at ufl.edu  Mon Apr 26 16:31:54 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Mon, 26 Apr 2010 10:31:54 -0400
Subject: [R-sig-ME] lme4 missing?
In-Reply-To: <5833B36A-C174-48D4-94AE-4E52B1CD14A9@gmail.com>
References: <5833B36A-C174-48D4-94AE-4E52B1CD14A9@gmail.com>
Message-ID: <4BD5A3DA.50106@ufl.edu>

Colin Studds wrote:
> Hi all, I just installed R on a new machine and can't link to the
> binaries for lme4 at any of the mirrors. Are others seeing the same?
> The r-cran site also seems to be down presently. Colin 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

  Due to r-project outage [http://wu.ac.at/], many of the mirrors in the
.r-project.org domain are down or inaccessible. The US mirror is still
up (for example) -- so are lots of the 'independent' mirrors.

http://cran.us.r-project.org/bin/windows/contrib/2.11/lme4_0.999375-33.zip


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From 2nuzzbot at gmail.com  Mon Apr 26 16:38:23 2010
From: 2nuzzbot at gmail.com (Etn)
Date: Mon, 26 Apr 2010 15:38:23 +0100
Subject: [R-sig-ME] GLMM -Error Message
Message-ID: <l2o706f8d1f1004260738zb8a76a5eve5bff381522182f0@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100426/d17af0ca/attachment.pl>

From S.Ellison at lgc.co.uk  Mon Apr 26 17:35:06 2010
From: S.Ellison at lgc.co.uk (S Ellison)
Date: Mon, 26 Apr 2010 16:35:06 +0100
Subject: [R-sig-ME] Random vs. fixed effects
Message-ID: <sbd5c0c7.093@tedmail.lgc.co.uk>



>>> Ben Bolker <bolker at ufl.edu> 23/04/2010 19:11:45 >>>
>  Given that it is a reasonable *philosophical* position to say
'treat
>philosophically random effects as random no matter what, and leave
them
>in the model even if they don't appear to be statistically
significant',
>and given that with small numbers of random-effect levels this
approach
>is likely to lead to numerical difficulties in most (??) mixed model
>packages (warnings, errors, or low estimates of the variance), what
>should one do?  

A bigger experiment.

Steve E

*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}



From gentz at ensat.fr  Mon Apr 26 17:40:35 2010
From: gentz at ensat.fr (Laurent Gentzbittel)
Date: Mon, 26 Apr 2010 17:40:35 +0200
Subject: [R-sig-ME] 'fixed' covariates in nlmer
Message-ID: <4BD5B3F3.1050803@ensat.fr>

Dear all,


I need to fit a logistic curve to disease index for plants subjected to
a pathogen. I have longitudinal data (the disease is monitored on
different plants as a function of time) and I would like to use lme4 and
nlmer function.

fit1 <- nlmer( score ~ SSlogis(dpi, Asym, xmid, scal) ~ (Asym + xmid |
plant),
          start=c(Asym=3.9 ,xmid= 12 ,scal= 1.4)
          data=mydata)

do the job by fitting random 'plant' effects for the Asym and xmid
parameters and also estimate population values (fixed effects) for Asym,
xmid and scal

However, not all the plants have the same genotype and I see on the
curves that some genotypes have different Asym and xmid values. Thus I
need to include a fixed 'genotype' effect for those parameters. I was
not able to find any line of code or example, nor in the lme4
documentation, that could help me to specify a 'genotype' fixed effect
for some of the parameters

I tried :
fit2 <- nlmer( score ~ SSlogis(dpi, Asym, xmid, scal) ~  (Asym|genotype)
+ (Asym + xmid | plant))

that fit a RANDOM genotype effect for Asym BUT not a FIXED effect as I
expected.

I also tried (mimicking the lmer syntax) :

fit3 <- nlmer( score ~ SSlogis(dpi, Asym, xmid, scal) ~  genotype +
(Asym + xmid | plant))

yet that syntax does not add a fixed 'genotype' effect for each three
parameters


How do I must specify these fixed effects ?

ps : I posted a similar mail one year ago, did not get answers and
survived using the lme package instead of the lme4 one. However, I
really would like to change.

Thanks for your help.
Laurent

-- 
Prof. L. GENTZBITTEL            Phone: +33 (0)5 62 19 35 96
INP - Agro Toulouse             Fax  : +33 (0)5 62 19 35 89
Symb. & Path. Plantes   - IFR40
18, Chemin de Borde Rouge - Auzeville Tolosane
31326 CASTANET TOLOSAN - FRANCE
E-mail:                         gentz at ensat.fr
Plant genomes synteny  :       
http://bioinfo.genopole-toulouse.prd.fr/iccare/
Linux user #301231



From adik at ilovebacon.org  Mon Apr 26 20:22:39 2010
From: adik at ilovebacon.org (Adam D. I. Kramer)
Date: Mon, 26 Apr 2010 11:22:39 -0700 (PDT)
Subject: [R-sig-ME] Start values for glmer: Bug?
Message-ID: <Pine.LNX.4.64.1004261049180.23911@ilovebacon.org>

Hello,

 	I'm fitting a model something like this:

s1d2.s <- glmer(chosen ~ rating + option + option2 + rating:option +
rating:option2 + (distNum|studyID), data=cc2, family=binomial)

...pretty straightforward. Of course, it doesn't converge...boo. So I turn
on verbose, and see that it's starting with some really improbable values. 
So I plug in some start values from other similar matrices that fit and some
good guesses, and it chugs along and finishes, but gives me a warning I do
not understand.

These are my start values:

> arg
[[1]]
             (Intercept) distNum
(Intercept)         1.9     0.0
distNum            -0.1     0.5

> fe
    (Intercept)         rating         option        option2  rating:option
        -7.5000         1.1000        -0.3000         0.0090         0.0500 
rating:option2        distNum     condition1     condition2
        -0.0025         0.2000         0.1000         0.1000

...this is my call:
s1d2.s <- glmer(chosen ~ rating + option + option2 + rating:option +
rating:option2 + (distNum|studyID), data=cc2, family=binomial, verbose=TRUE,
start=list(ST=arg,fixef=fe[1:6]))

...and this is the eventual completion, with the warning message I do not
understand:

  65:     1633.7847:  2.71240 0.719770 -0.228343 -8.32184  1.56395 -0.0683526
0.00144433 0.0226594 -0.000315729
Warning message:
In sort(names(start)) == sort(names(FL)) :
   longer object length is not a multiple of shorter object length

...the first-round verbose output does indeed use my provided start values,
in the right order. The summary table, eventually, also uses names(fe)
instead of the actual variable names passed to glmer...which I would argue
is inappropriate behavior. But it's the problem with the length of the names
of `start` that has me confused.

The help page says that I should be passing a list with items ST and fixef,
and I'm doing that, and it's working...

Advice?

--
Adam D. I. Kramer
Ph.D. Candidate, Psychology
adik at uoregon.edu



From bolker at ufl.edu  Mon Apr 26 22:46:56 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Mon, 26 Apr 2010 16:46:56 -0400
Subject: [R-sig-ME] Start values for glmer: Bug?
In-Reply-To: <Pine.LNX.4.64.1004261049180.23911@ilovebacon.org>
References: <Pine.LNX.4.64.1004261049180.23911@ilovebacon.org>
Message-ID: <4BD5FBC0.2000605@ufl.edu>

Adam D. I. Kramer wrote:
> Hello,
> 
>  	I'm fitting a model something like this:
> 
> s1d2.s <- glmer(chosen ~ rating + option + option2 + rating:option +
> rating:option2 + (distNum|studyID), data=cc2, family=binomial)
> 
> ...pretty straightforward. Of course, it doesn't converge...boo. So I turn
> on verbose, and see that it's starting with some really improbable values. 
> So I plug in some start values from other similar matrices that fit and some
> good guesses, and it chugs along and finishes, but gives me a warning I do
> not understand.
> 
> These are my start values:
> 
>> arg
> [[1]]
>              (Intercept) distNum
> (Intercept)         1.9     0.0
> distNum            -0.1     0.5
> 
>> fe
>     (Intercept)         rating         option        option2  rating:option
>         -7.5000         1.1000        -0.3000         0.0090         0.0500 
> rating:option2        distNum     condition1     condition2
>         -0.0025         0.2000         0.1000         0.1000
> 
> ...this is my call:
> s1d2.s <- glmer(chosen ~ rating + option + option2 + rating:option +
> rating:option2 + (distNum|studyID), data=cc2, family=binomial, verbose=TRUE,
> start=list(ST=arg,fixef=fe[1:6]))
> 
> ...and this is the eventual completion, with the warning message I do not
> understand:
> 
>   65:     1633.7847:  2.71240 0.719770 -0.228343 -8.32184  1.56395 -0.0683526
> 0.00144433 0.0226594 -0.000315729
> Warning message:
> In sort(names(start)) == sort(names(FL)) :
>    longer object length is not a multiple of shorter object length
> 
> ...the first-round verbose output does indeed use my provided start values,
> in the right order. The summary table, eventually, also uses names(fe)
> instead of the actual variable names passed to glmer...which I would argue
> is inappropriate behavior. But it's the problem with the length of the names
> of `start` that has me confused.
> 
> The help page says that I should be passing a list with items ST and fixef,
> and I'm doing that, and it's working...
> 
> Advice?

  Provide a reproducible example?
  (Not really meant to be snarky.  lme4 is still fairly bleeding-edge,
and it's quite possible that you have exposed a bug of some sort, but
without digging into it it's hard to tell.)

  or

debug(lme4:::glmer_finalize)

  and see what's going on (the test causing the warning is in the first
line of this function).

  In fact, digging around further suggests that this is indeed a bug I'm
not sure I've correctly reconstructed the logic of the test, which is
currently

  if (is.list(start) && all(sort(names(start)) == sort(names(FL))))
        start <- list(ST = start)

 FL comes from a call to lmerFactorList, which returns a list with
elements "trms" (terms), "fl" (factor list), and "dims" (dimensions &
auxiliary information).  Based on the logic of the help page, it seems
that perhaps the test should be

if (is.list(start) && length(start)==length(FL$fl) &&
all(sort(names(start)) == sort(names(FL$fl))))
        start <- list(ST = start)

  ?

  cheers
    Ben Bolker



From adik at ilovebacon.org  Mon Apr 26 23:48:02 2010
From: adik at ilovebacon.org (Adam D. I. Kramer)
Date: Mon, 26 Apr 2010 14:48:02 -0700 (PDT)
Subject: [R-sig-ME] Start values for glmer: Bug?
In-Reply-To: <4BD5FBC0.2000605@ufl.edu>
References: <Pine.LNX.4.64.1004261049180.23911@ilovebacon.org>
	<4BD5FBC0.2000605@ufl.edu>
Message-ID: <Pine.LNX.4.64.1004261403320.23911@ilovebacon.org>

Hi Ben,

 	I'd rather not publish my dissertation data online before it's
analyzed, but I will email you a copy of the data.frame personally if you
like. Others interested in this debugging process should email me
personally; should I use this address?

 	But yes, the FL object is not exactly what this test thinks it is.
The proposed solution also doesn't seem to work: FL$fl is a list of grouping
factors (just one, in my case: studyID). What is the goal of this check? It
seems to me that we are trying to check that the items in "start" are either
of form 1 or form 2, but FL does not seem to me to be the key.

--Adam

On Mon, 26 Apr 2010, Ben Bolker wrote:

> Adam D. I. Kramer wrote:
>> Hello,
>>
>>  	I'm fitting a model something like this:
>>
>> s1d2.s <- glmer(chosen ~ rating + option + option2 + rating:option +
>> rating:option2 + (distNum|studyID), data=cc2, family=binomial)
>>
>> ...pretty straightforward. Of course, it doesn't converge...boo. So I turn
>> on verbose, and see that it's starting with some really improbable values.
>> So I plug in some start values from other similar matrices that fit and some
>> good guesses, and it chugs along and finishes, but gives me a warning I do
>> not understand.
>>
>> These are my start values:
>>
>>> arg
>> [[1]]
>>              (Intercept) distNum
>> (Intercept)         1.9     0.0
>> distNum            -0.1     0.5
>>
>>> fe
>>     (Intercept)         rating         option        option2  rating:option
>>         -7.5000         1.1000        -0.3000         0.0090         0.0500
>> rating:option2        distNum     condition1     condition2
>>         -0.0025         0.2000         0.1000         0.1000
>>
>> ...this is my call:
>> s1d2.s <- glmer(chosen ~ rating + option + option2 + rating:option +
>> rating:option2 + (distNum|studyID), data=cc2, family=binomial, verbose=TRUE,
>> start=list(ST=arg,fixef=fe[1:6]))
>>
>> ...and this is the eventual completion, with the warning message I do not
>> understand:
>>
>>   65:     1633.7847:  2.71240 0.719770 -0.228343 -8.32184  1.56395 -0.0683526
>> 0.00144433 0.0226594 -0.000315729
>> Warning message:
>> In sort(names(start)) == sort(names(FL)) :
>>    longer object length is not a multiple of shorter object length
>>
>> ...the first-round verbose output does indeed use my provided start values,
>> in the right order. The summary table, eventually, also uses names(fe)
>> instead of the actual variable names passed to glmer...which I would argue
>> is inappropriate behavior. But it's the problem with the length of the names
>> of `start` that has me confused.
>>
>> The help page says that I should be passing a list with items ST and fixef,
>> and I'm doing that, and it's working...
>>
>> Advice?
>
>  Provide a reproducible example?
>  (Not really meant to be snarky.  lme4 is still fairly bleeding-edge,
> and it's quite possible that you have exposed a bug of some sort, but
> without digging into it it's hard to tell.)
>
>  or
>
> debug(lme4:::glmer_finalize)
>
>  and see what's going on (the test causing the warning is in the first
> line of this function).
>
>  In fact, digging around further suggests that this is indeed a bug I'm
> not sure I've correctly reconstructed the logic of the test, which is
> currently
>
>  if (is.list(start) && all(sort(names(start)) == sort(names(FL))))
>        start <- list(ST = start)
>
> FL comes from a call to lmerFactorList, which returns a list with
> elements "trms" (terms), "fl" (factor list), and "dims" (dimensions &
> auxiliary information).  Based on the logic of the help page, it seems
> that perhaps the test should be
>
> if (is.list(start) && length(start)==length(FL$fl) &&
> all(sort(names(start)) == sort(names(FL$fl))))
>        start <- list(ST = start)
>
>  ?
>
>  cheers
>    Ben Bolker
>
>



From bolker at ufl.edu  Tue Apr 27 02:00:16 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Mon, 26 Apr 2010 20:00:16 -0400
Subject: [R-sig-ME] Start values for glmer: Bug?
In-Reply-To: <Pine.LNX.4.64.1004261403320.23911@ilovebacon.org>
References: <Pine.LNX.4.64.1004261049180.23911@ilovebacon.org>
	<4BD5FBC0.2000605@ufl.edu>
	<Pine.LNX.4.64.1004261403320.23911@ilovebacon.org>
Message-ID: <4BD62910.1070601@ufl.edu>

Adam D. I. Kramer wrote:
> Hi Ben,
> 
>  	I'd rather not publish my dissertation data online before it's
> analyzed, but I will email you a copy of the data.frame personally if you
> like. Others interested in this debugging process should email me
> personally; should I use this address?

  I don't think we really need your data, because it's easy to come up
with a reproducible example:

library(lme4)
gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
             family = binomial, data = cbpp, verbose=TRUE)

gm2 <- update(gm1,start=list(ST=gm1 at ST,fixef=fixef(gm1)),verbose=TRUE)

## I think what would be intended for setting only the
## ST parameters would be:

gm3 <- update(gm1,start=list(herd=gm1 at ST),verbose=TRUE)

## but doesn't work?

  I haven't quite worked my way through the glmer_finalize logic of
"STpars" vs "ST" list element.

>  	But yes, the FL object is not exactly what this test thinks it is.
> The proposed solution also doesn't seem to work: FL$fl is a list of grouping
> factors (just one, in my case: studyID). What is the goal of this check? It
> seems to me that we are trying to check that the items in "start" are either
> of form 1 or form 2, but FL does not seem to me to be the key.

 The help says:

   If the list is of the same form as the ?ST? slot, it
          is becomes the starting values of the ?ST? slot.

FL$fl seems to contain a list of random effects:

Browse[2]> names(FL)
[1] "trms" "fl"   "dims"
Browse[2]> names(FL$fl)
[1] "herd"

  so checking that 'start' was a list whose names matched those of FL$fl
would seem to be sensible.

> 
> --Adam
> 
> On Mon, 26 Apr 2010, Ben Bolker wrote:
> 
>> Adam D. I. Kramer wrote:
>>> Hello,
>>>
>>>  	I'm fitting a model something like this:
>>>
>>> s1d2.s <- glmer(chosen ~ rating + option + option2 + rating:option +
>>> rating:option2 + (distNum|studyID), data=cc2, family=binomial)
>>>
>>> ...pretty straightforward. Of course, it doesn't converge...boo. So I turn
>>> on verbose, and see that it's starting with some really improbable values.
>>> So I plug in some start values from other similar matrices that fit and some
>>> good guesses, and it chugs along and finishes, but gives me a warning I do
>>> not understand.
>>>
>>> These are my start values:
>>>
>>>> arg
>>> [[1]]
>>>              (Intercept) distNum
>>> (Intercept)         1.9     0.0
>>> distNum            -0.1     0.5
>>>
>>>> fe
>>>     (Intercept)         rating         option        option2  rating:option
>>>         -7.5000         1.1000        -0.3000         0.0090         0.0500
>>> rating:option2        distNum     condition1     condition2
>>>         -0.0025         0.2000         0.1000         0.1000
>>>
>>> ...this is my call:
>>> s1d2.s <- glmer(chosen ~ rating + option + option2 + rating:option +
>>> rating:option2 + (distNum|studyID), data=cc2, family=binomial, verbose=TRUE,
>>> start=list(ST=arg,fixef=fe[1:6]))
>>>
>>> ...and this is the eventual completion, with the warning message I do not
>>> understand:
>>>
>>>   65:     1633.7847:  2.71240 0.719770 -0.228343 -8.32184  1.56395 -0.0683526
>>> 0.00144433 0.0226594 -0.000315729
>>> Warning message:
>>> In sort(names(start)) == sort(names(FL)) :
>>>    longer object length is not a multiple of shorter object length
>>>
>>> ...the first-round verbose output does indeed use my provided start values,
>>> in the right order. The summary table, eventually, also uses names(fe)
>>> instead of the actual variable names passed to glmer...which I would argue
>>> is inappropriate behavior. But it's the problem with the length of the names
>>> of `start` that has me confused.
>>>
>>> The help page says that I should be passing a list with items ST and fixef,
>>> and I'm doing that, and it's working...
>>>
>>> Advice?
>>  Provide a reproducible example?
>>  (Not really meant to be snarky.  lme4 is still fairly bleeding-edge,
>> and it's quite possible that you have exposed a bug of some sort, but
>> without digging into it it's hard to tell.)
>>
>>  or
>>
>> debug(lme4:::glmer_finalize)
>>
>>  and see what's going on (the test causing the warning is in the first
>> line of this function).
>>
>>  In fact, digging around further suggests that this is indeed a bug I'm
>> not sure I've correctly reconstructed the logic of the test, which is
>> currently
>>
>>  if (is.list(start) && all(sort(names(start)) == sort(names(FL))))
>>        start <- list(ST = start)
>>
>> FL comes from a call to lmerFactorList, which returns a list with
>> elements "trms" (terms), "fl" (factor list), and "dims" (dimensions &
>> auxiliary information).  Based on the logic of the help page, it seems
>> that perhaps the test should be
>>
>> if (is.list(start) && length(start)==length(FL$fl) &&
>> all(sort(names(start)) == sort(names(FL$fl))))
>>        start <- list(ST = start)
>>
>>  ?
>>
>>  cheers
>>    Ben Bolker
>>
>>


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From adik at ilovebacon.org  Tue Apr 27 02:32:11 2010
From: adik at ilovebacon.org (Adam D. I. Kramer)
Date: Mon, 26 Apr 2010 17:32:11 -0700 (PDT)
Subject: [R-sig-ME] Start values for glmer: Bug?
In-Reply-To: <4BD62910.1070601@ufl.edu>
References: <Pine.LNX.4.64.1004261049180.23911@ilovebacon.org>
	<4BD5FBC0.2000605@ufl.edu>
	<Pine.LNX.4.64.1004261403320.23911@ilovebacon.org>
	<4BD62910.1070601@ufl.edu>
Message-ID: <Pine.LNX.4.64.1004261725300.23911@ilovebacon.org>


On Mon, 26 Apr 2010, Ben Bolker wrote:

>  I don't think we really need your data, because it's easy to come up with
> a reproducible example:
>
> library(lme4)
> gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
>             family = binomial, data = cbpp, verbose=TRUE)
>
> gm2 <- update(gm1,start=list(ST=gm1 at ST,fixef=fixef(gm1)),verbose=TRUE)
>
> ## I think what would be intended for setting only the
> ## ST parameters would be:
>
> gm3 <- update(gm1,start=list(herd=gm1 at ST),verbose=TRUE)

...gm3 appears to work, while gm2 throws the error.

This also works:

gm2 <- update(gm1,start=list(ST=gm1 at ST),verbose=TRUE)

...which suggests to me that the error is in the fixef specification, not
the ranef specification.

> ## but doesn't work?
>
>  I haven't quite worked my way through the glmer_finalize logic of
> "STpars" vs "ST" list element.
>
>>  	But yes, the FL object is not exactly what this test thinks it is.
>> The proposed solution also doesn't seem to work: FL$fl is a list of grouping
>> factors (just one, in my case: studyID). What is the goal of this check? It
>> seems to me that we are trying to check that the items in "start" are either
>> of form 1 or form 2, but FL does not seem to me to be the key.
>
> The help says:
>
>   If the list is of the same form as the ??ST?? slot, it
>          is becomes the starting values of the ??ST?? slot.
>
> FL$fl seems to contain a list of random effects:
>
> Browse[2]> names(FL)
> [1] "trms" "fl"   "dims"
> Browse[2]> names(FL$fl)
> [1] "herd"
>
>  so checking that 'start' was a list whose names matched those of FL$fl
> would seem to be sensible.

And indeed it is--the problem is present only when one also provides fixed
effects starting values.

--Adam


>
>>
>> --Adam
>>
>> On Mon, 26 Apr 2010, Ben Bolker wrote:
>>
>>> Adam D. I. Kramer wrote:
>>>> Hello,
>>>>
>>>>  	I'm fitting a model something like this:
>>>>
>>>> s1d2.s <- glmer(chosen ~ rating + option + option2 + rating:option +
>>>> rating:option2 + (distNum|studyID), data=cc2, family=binomial)
>>>>
>>>> ...pretty straightforward. Of course, it doesn't converge...boo. So I turn
>>>> on verbose, and see that it's starting with some really improbable values.
>>>> So I plug in some start values from other similar matrices that fit and some
>>>> good guesses, and it chugs along and finishes, but gives me a warning I do
>>>> not understand.
>>>>
>>>> These are my start values:
>>>>
>>>>> arg
>>>> [[1]]
>>>>              (Intercept) distNum
>>>> (Intercept)         1.9     0.0
>>>> distNum            -0.1     0.5
>>>>
>>>>> fe
>>>>     (Intercept)         rating         option        option2  rating:option
>>>>         -7.5000         1.1000        -0.3000         0.0090         0.0500
>>>> rating:option2        distNum     condition1     condition2
>>>>         -0.0025         0.2000         0.1000         0.1000
>>>>
>>>> ...this is my call:
>>>> s1d2.s <- glmer(chosen ~ rating + option + option2 + rating:option +
>>>> rating:option2 + (distNum|studyID), data=cc2, family=binomial, verbose=TRUE,
>>>> start=list(ST=arg,fixef=fe[1:6]))
>>>>
>>>> ...and this is the eventual completion, with the warning message I do not
>>>> understand:
>>>>
>>>>   65:     1633.7847:  2.71240 0.719770 -0.228343 -8.32184  1.56395 -0.0683526
>>>> 0.00144433 0.0226594 -0.000315729
>>>> Warning message:
>>>> In sort(names(start)) == sort(names(FL)) :
>>>>    longer object length is not a multiple of shorter object length
>>>>
>>>> ...the first-round verbose output does indeed use my provided start values,
>>>> in the right order. The summary table, eventually, also uses names(fe)
>>>> instead of the actual variable names passed to glmer...which I would argue
>>>> is inappropriate behavior. But it's the problem with the length of the names
>>>> of `start` that has me confused.
>>>>
>>>> The help page says that I should be passing a list with items ST and fixef,
>>>> and I'm doing that, and it's working...
>>>>
>>>> Advice?
>>>  Provide a reproducible example?
>>>  (Not really meant to be snarky.  lme4 is still fairly bleeding-edge,
>>> and it's quite possible that you have exposed a bug of some sort, but
>>> without digging into it it's hard to tell.)
>>>
>>>  or
>>>
>>> debug(lme4:::glmer_finalize)
>>>
>>>  and see what's going on (the test causing the warning is in the first
>>> line of this function).
>>>
>>>  In fact, digging around further suggests that this is indeed a bug I'm
>>> not sure I've correctly reconstructed the logic of the test, which is
>>> currently
>>>
>>>  if (is.list(start) && all(sort(names(start)) == sort(names(FL))))
>>>        start <- list(ST = start)
>>>
>>> FL comes from a call to lmerFactorList, which returns a list with
>>> elements "trms" (terms), "fl" (factor list), and "dims" (dimensions &
>>> auxiliary information).  Based on the logic of the help page, it seems
>>> that perhaps the test should be
>>>
>>> if (is.list(start) && length(start)==length(FL$fl) &&
>>> all(sort(names(start)) == sort(names(FL$fl))))
>>>        start <- list(ST = start)
>>>
>>>  ?
>>>
>>>  cheers
>>>    Ben Bolker
>>>
>>>
>
>
> -- 
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / people.biology.ufl.edu/bolker
> GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc
>

From bolker at ufl.edu  Tue Apr 27 04:58:32 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Mon, 26 Apr 2010 22:58:32 -0400
Subject: [R-sig-ME] Start values for glmer: Bug?
In-Reply-To: <Pine.LNX.4.64.1004261725300.23911@ilovebacon.org>
References: <Pine.LNX.4.64.1004261049180.23911@ilovebacon.org>
	<4BD5FBC0.2000605@ufl.edu>
	<Pine.LNX.4.64.1004261403320.23911@ilovebacon.org>
	<4BD62910.1070601@ufl.edu>
	<Pine.LNX.4.64.1004261725300.23911@ilovebacon.org>
Message-ID: <4BD652D8.8050804@ufl.edu>

Adam D. I. Kramer wrote:
> On Mon, 26 Apr 2010, Ben Bolker wrote:
> 
>>  I don't think we really need your data, because it's easy to come up with
>> a reproducible example:
>>
>> library(lme4)
>> gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
>>             family = binomial, data = cbpp, verbose=TRUE)
>>
>> gm2 <- update(gm1,start=list(ST=gm1 at ST,fixef=fixef(gm1)),verbose=TRUE)
>>
>> ## I think what would be intended for setting only the
>> ## ST parameters would be:
>>
>> gm3 <- update(gm1,start=list(herd=gm1 at ST),verbose=TRUE)
> 
> ...gm3 appears to work, while gm2 throws the error.
> 
> This also works:
> 
> gm2 <- update(gm1,start=list(ST=gm1 at ST),verbose=TRUE)
> 
> ...which suggests to me that the error is in the fixef specification, not
> the ranef specification.

  I think we need to look more closely.  "Causes a warning" and "works"
are not the same (although "causes a warning even when there isn't
really a problem" is still a bug).

  In the verbose output, e.g

 17:     100.09586: 0.642260 -1.39854 -0.992335 -1.12868 -1.58031
(the last line of the initial fit), the first element (before the colon)
is deviance, the rest of the elements are (var-cov, fixed effects).

 start=list(ST=gm1 at ST,fixef=fixef(gm1))

starts in the right place:

    0:     100.09586: 0.642260 -1.39854 -0.992335 -1.12868 -1.58037

start=list(herd=gm1 at ST[[1]])
  doesn't give an error, but doesn't start in the right place either
(it should set starting var-cov to 0.642260):

  0:     101.94202: 0.845154 -1.26902 -1.17076 -1.30141 -1.78228

  I could dig in and fix this according to my understanding, but I'd
rather wait for Martin Maechler or Doug Bates to chime in ...



From adik at ilovebacon.org  Tue Apr 27 09:40:15 2010
From: adik at ilovebacon.org (Adam D. I. Kramer)
Date: Tue, 27 Apr 2010 00:40:15 -0700 (PDT)
Subject: [R-sig-ME] Start values for glmer: Bug?
In-Reply-To: <4BD652D8.8050804@ufl.edu>
References: <Pine.LNX.4.64.1004261049180.23911@ilovebacon.org>
	<4BD5FBC0.2000605@ufl.edu>
	<Pine.LNX.4.64.1004261403320.23911@ilovebacon.org>
	<4BD62910.1070601@ufl.edu>
	<Pine.LNX.4.64.1004261725300.23911@ilovebacon.org>
	<4BD652D8.8050804@ufl.edu>
Message-ID: <Pine.LNX.4.64.1004262306210.23911@ilovebacon.org>


On Mon, 26 Apr 2010, Ben Bolker wrote:

> Adam D. I. Kramer wrote:
>> On Mon, 26 Apr 2010, Ben Bolker wrote:
>>
>>>  I don't think we really need your data, because it's easy to come up with
>>> a reproducible example:
>>>
>>> library(lme4)
>>> gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
>>>             family = binomial, data = cbpp, verbose=TRUE)
>>>
>>> gm2 <- update(gm1,start=list(ST=gm1 at ST,fixef=fixef(gm1)),verbose=TRUE)
>>>
>>> ## I think what would be intended for setting only the
>>> ## ST parameters would be:
>>>
>>> gm3 <- update(gm1,start=list(herd=gm1 at ST),verbose=TRUE)
>>
>> ...gm3 appears to work, while gm2 throws the error.
>>
>> This also works:
>>
>> gm2 <- update(gm1,start=list(ST=gm1 at ST),verbose=TRUE)
>>
>> ...which suggests to me that the error is in the fixef specification, not
>> the ranef specification.
>
>  I think we need to look more closely.  "Causes a warning" and "works" are
> not the same (although "causes a warning even when there isn't really a
> problem" is still a bug).

Apologies for my imprecise wording. When I said "error" I meant "bug."

>  In the verbose output, e.g
>
> 17:     100.09586: 0.642260 -1.39854 -0.992335 -1.12868 -1.58031
> (the last line of the initial fit), the first element (before the colon)
> is deviance, the rest of the elements are (var-cov, fixed effects).
>
> start=list(ST=gm1 at ST,fixef=fixef(gm1))
>
> starts in the right place:
>
>    0:     100.09586: 0.642260 -1.39854 -0.992335 -1.12868 -1.58037

...should we worry about the last fixed effect being off by 6e-5 ? I would
expect them to be precisely the same.

Perhaps the output at 0 is the output of the estimated effects AFTER the 0th
iteration? That would explain the below as well.

Also, this run actually takes 6 iterations and comes up with a slightly
different solution:

6:     100.09586: 0.642261 -1.39853 -0.992333 -1.12867 -1.58032

...granted, the deviance is the same, but it seems odd to me that this would
take more than 1 iteration.

> start=list(herd=gm1 at ST[[1]])
>  doesn't give an error, but doesn't start in the right place either
> (it should set starting var-cov to 0.642260):
>
>  0:     101.94202: 0.845154 -1.26902 -1.17076 -1.30141 -1.78228

I agree that that should give an error. My reading of the syntax suggested
by ?glmer suggests that the syntax above is incorrect, and that these ones
are correct:

gm2 <- update(gm1,start=list(ST=gm1 at ST),verbose=TRUE)
   0:     100.74403: 0.642260 -1.26902 -1.17076 -1.30141 -1.78228

...there, I specified ST=, rather than herd=.

Specifying just c() also works as expected, so long as the c() contains only
the ST matrix:
gm2 <- update(gm1,start=c(gm1 at ST[[1]]),verbose=TRUE)
   0:     100.74403: 0.642260 -1.26902 -1.17076 -1.30141 -1.78228

...but specifying the fixef inside the c() (which seems like a reasonable
thing to do, given that the verbose output appears to be a vector...so we
might want a warning here too) also fails:

gm2 <- update(gm1,start=c(gm1 at ST[[1]],fixef(gm1)),verbose=TRUE)
   0:     101.94202: 0.845154 -1.26902 -1.17076 -1.30141 -1.78228

...I think this is illustrated a bit better if we complicate the random
effects structure:

cbpp$grp <- rep(1:2,each=28)
gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (period | herd) +
(period | grp), family = binomial, data = cbpp, verbose=TRUE)

...then gm1 at ST is:

gm1 at ST
[[1]]
             (Intercept)    period2       period3      period4
(Intercept)   0.9068296  0.0000000  0.000000e+00 0.000000e+00
period2      -1.3084100  0.6256717  0.000000e+00 0.000000e+00
period3      -1.3421617  2.5756482  2.928284e-05 0.000000e+00
period4      -0.9121509 -0.8045486 -4.480320e-01 7.996506e-06

[[2]]
             (Intercept)       period2   period3      period4
(Intercept)   0.3956145  0.000000e+00 0.0000000 0.000000e+00
period2      -1.1822589  5.288660e-06 0.0000000 0.000000e+00
period3       0.3188161 -1.906580e-02 0.0000000 0.000000e+00
period4      -0.4143081 -3.631300e-02 0.0331796 3.338474e-07

...with [[1]] being the herd effect and [[2]] being the grp effect. Then
fitting gives us:

...
160:     78.533021: 0.906830 0.625672 2.92828e-05 7.99651e-06 -1.30841
-1.34216 -0.912151  2.57565 -0.804549 -0.448032 0.395614 5.28866e-06
0.00000 3.33847e-07 -1.18226 0.318816 -0.414308 -0.0190658 -0.0363130
0.0331796 -1.55707 -1.10585 -1.86776 -1.62993

...which looks to me to be:
  c( diag(gm1 at ST[[1]]),
     gm1 at ST[[1]][lower.tri(gm1 at ST[[1]])],
     diag(gm1 at ST[[2]]),
     gm1 at ST[[2]][lower.tri(gm1 at ST[[2]])],
     fixef(gm1)
   )

...in this case, I can't figure out a syntax that gets the first iteration
of gm2 to match the above. The failures are all the same, which is to say,
they use the same starting values glmer() creates without input.

This one, I would expect to succeed:
gm2 <- update(gm1, start=list(ST=gm1 at ST,fixef=fixef(gm1)))
...but it fails:
   0:     105.57844: 0.845154  1.69031  1.69031  1.75412  0.00000  0.00000
0.00000  0.00000  0.00000  0.00000 0.308607 0.617213 0.617213 0.640513
0.00000  0.00000  0.00000  0.00000  0.00000  0.00000 -1.26902 -1.17076
-1.30141 -1.78228

This one also:
gm2 <- update(gm1, start=gm1 at ST)
...also fails:
   0:     105.57844: 0.845154  1.69031  1.69031  1.75412  0.00000  0.00000
0.00000  0.00000  0.00000  0.00000 0.308607 0.617213 0.617213 0.640513
0.00000  0.00000  0.00000  0.00000  0.00000  0.00000 -1.26902 -1.17076
-1.30141 -1.78228

...the closest I can get is:

gm2 <- update(gm1, start= c( diag(gm1 at ST[[1]]),
     gm1 at ST[[1]][lower.tri(gm1 at ST[[1]])],
     diag(gm1 at ST[[2]]),
     gm1 at ST[[2]][lower.tri(gm1 at ST[[2]])] ) )

...but that only sets the random-effect start values correctly, not the
fixed effects. Adding fixef(gm1) to the end or passing the above as the ST
component of a list throws errors.

>  I could dig in and fix this according to my understanding, but I'd
> rather wait for Martin Maechler or Doug Bates to chime in ...

Agreed, though if our understanding is off by much, I would quite like to
know why.

--Adam



From 2nuzzbot at gmail.com  Tue Apr 27 09:47:26 2010
From: 2nuzzbot at gmail.com (Etn)
Date: Tue, 27 Apr 2010 08:47:26 +0100
Subject: [R-sig-ME] GLMM -Error Message
In-Reply-To: <AD8B7F6F-5AF7-4CAE-96DA-9EF3CEBCD5D0@gmail.com>
References: <AD8B7F6F-5AF7-4CAE-96DA-9EF3CEBCD5D0@gmail.com>
Message-ID: <u2w706f8d1f1004270047sd679e94cp18a8784fa8a4a84e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100427/d0274aaf/attachment.pl>

From j.ayanz.loro at gmail.com  Tue Apr 27 13:36:30 2010
From: j.ayanz.loro at gmail.com (Jesus Ayanz)
Date: Tue, 27 Apr 2010 13:36:30 +0200
Subject: [R-sig-ME] non-changing variables in a repeated measures analysis
	with lmer
Message-ID: <y2w23c76c4e1004270436q23f14277g686184b84536c6ba@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100427/93ce99c0/attachment.pl>

From hapdlloyd at googlemail.com  Tue Apr 27 15:26:30 2010
From: hapdlloyd at googlemail.com (Hywel Lloyd)
Date: Tue, 27 Apr 2010 14:26:30 +0100
Subject: [R-sig-ME] Help with some nearly-binomial data
Message-ID: <u2oc59a5cf61004270626rf0c01ebcu74860aaaa8ece0eb@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100427/163ffd71/attachment.pl>

From paolo.innocenti at ebc.uu.se  Tue Apr 27 15:29:07 2010
From: paolo.innocenti at ebc.uu.se (Paolo Innocenti)
Date: Tue, 27 Apr 2010 15:29:07 +0200
Subject: [R-sig-ME] Model representation for mixed models
Message-ID: <4BD6E6A3.4070903@ebc.uu.se>

Hi,

I am fitting a mixed model with lme4, specifically:

model <- lmer(Y ~ female.type*male.type+(1|female.pop)+(1|male.pop))

with female.pop nested in female.type and
male.pop nested in male.type:

 > model.frame(model)
               Y female.type male.type female.pop male.pop
M1M1-1 3.851804        Mono      Mono      Mono1    Mono1
M1M1-2 3.628088        Mono      Mono      Mono1    Mono1
M1P1-1 3.619024        Mono      Prom      Mono1    Prom1
M1P1-2 3.676578        Mono      Prom      Mono1    Prom1
M2M2-1 3.561432        Mono      Mono      Mono2    Mono2
M2M2-2 3.982403        Mono      Mono      Mono2    Mono2
M2P2-1 3.728523        Mono      Prom      Mono2    Prom2
M2P2-2 3.754911        Mono      Prom      Mono2    Prom2
M3M3-1 3.868304        Mono      Mono      Mono3    Mono3
M3M3-2 3.875949        Mono      Mono      Mono3    Mono3
M3P3-1 3.873787        Mono      Prom      Mono3    Prom3
M3P3-2 3.573503        Mono      Prom      Mono3    Prom3
M4M4-1 3.691399        Mono      Mono      Mono4    Mono4
M4M4-2 3.774606        Mono      Mono      Mono4    Mono4
M4P4-1 3.901790        Mono      Prom      Mono4    Prom4
M4P4-2 3.882356        Mono      Prom      Mono4    Prom4
P1M1-1 3.710269        Prom      Mono      Prom1    Mono1
P1M1-2 3.690842        Prom      Mono      Prom1    Mono1
P1P1-1 3.735968        Prom      Prom      Prom1    Prom1
P1P1-2 3.575529        Prom      Prom      Prom1    Prom1
P2M2-1 3.521016        Prom      Mono      Prom2    Mono2
P2M2-2 3.888614        Prom      Mono      Prom2    Mono2
P2P2-1 3.566240        Prom      Prom      Prom2    Prom2
P2P2-2 3.799283        Prom      Prom      Prom2    Prom2
P3M3-1 3.947283        Prom      Mono      Prom3    Mono3
P3M3-2 3.508592        Prom      Mono      Prom3    Mono3
P3P3-1 3.670293        Prom      Prom      Prom3    Prom3
P3P3-2 3.817314        Prom      Prom      Prom3    Prom3
P4M4-1 3.624735        Prom      Mono      Prom4    Mono4
P4M4-2 3.892305        Prom      Mono      Prom4    Mono4
P4P4-1 3.864690        Prom      Prom      Prom4    Prom4
P4P4-2 3.604446        Prom      Prom      Prom4    Prom4

and "contr.sum" as contrasts.

I need to write this model in a rigorous statistical way, but my 
knowledge of stats/math/algebra is really poor, so I find it quite 
difficult. I can guess it is something like:

y_(ijkhw) = u + F_i + M_j + I_(ij) + a_(ik) + b_(jh) + e_(ijkhw)

i = 1,2
j = 1,2
k = 1,...,4
h = 1,...,4
w = 1,...,32

a (female.pop) ~ N(0, (s^2)_1)
b (male.pop) ~ N(0, (s^2)_2)
e (error) ~ N(0, s^2)

I read in ch. 2.1 of the Pinheiro and Bates about the "Laird and Ware 
(1982)" formulation based on two matrices, one for the fixed and the 
random effects, something like:

y_i = X_i Beta + Z_i b_i + e_i

but I cannot really figure out how to apply it to my dataset (which 
should have partially crossed random factors).

My questions:

1 - which formulation is most appropriate/clear?

2 - where can I learn how to write the models properly (and which 
information I have to give to explain my model fully)?

3 - the "model" object contains all the information necessary to produce 
the formal structure of the model in a "pretty" (LaTeX maybe?) format. 
Is there a function that takes the model object and spit out the formal 
representation of the model? I think it would be extremely helpful (and 
pedagogic) for non-statistician users of R.

Best,
paolo

 > model.matrix(model)
       [,1] [,2] [,3] [,4]
  [1,]    1   -1   -1    1
  [2,]    1   -1   -1    1
  [3,]    1   -1    1   -1
  [4,]    1   -1    1   -1
  [5,]    1   -1   -1    1
  [6,]    1   -1   -1    1
  [7,]    1   -1    1   -1
  [8,]    1   -1    1   -1
  [9,]    1   -1   -1    1
[10,]    1   -1   -1    1
[11,]    1   -1    1   -1
[12,]    1   -1    1   -1
[13,]    1   -1   -1    1
[14,]    1   -1   -1    1
[15,]    1   -1    1   -1
[16,]    1   -1    1   -1
[17,]    1    1   -1   -1
[18,]    1    1   -1   -1
[19,]    1    1    1    1
[20,]    1    1    1    1
[21,]    1    1   -1   -1
[22,]    1    1   -1   -1
[23,]    1    1    1    1
[24,]    1    1    1    1
[25,]    1    1   -1   -1
[26,]    1    1   -1   -1
[27,]    1    1    1    1
[28,]    1    1    1    1
[29,]    1    1   -1   -1
[30,]    1    1   -1   -1
[31,]    1    1    1    1
[32,]    1    1    1    1
attr(,"assign")
[1] 0 1 2 3
attr(,"contrasts")
attr(,"contrasts")$female.type
[1] "contr.sum"

attr(,"contrasts")$male.type
[1] "contr.sum"




-- 
Paolo Innocenti
Department of Animal Ecology, EBC
Uppsala University
Norbyv?gen 18D
75236 Uppsala, Sweden



From andydolman at gmail.com  Tue Apr 27 15:56:48 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Tue, 27 Apr 2010 15:56:48 +0200
Subject: [R-sig-ME] Help with some nearly-binomial data
In-Reply-To: <u2oc59a5cf61004270626rf0c01ebcu74860aaaa8ece0eb@mail.gmail.com>
References: <u2oc59a5cf61004270626rf0c01ebcu74860aaaa8ece0eb@mail.gmail.com>
Message-ID: <t2j951234ac1004270656v159c9f32v621f71d019caa968@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100427/cd172b7b/attachment.pl>

From Mike.Lawrence at dal.ca  Tue Apr 27 17:06:40 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Tue, 27 Apr 2010 12:06:40 -0300
Subject: [R-sig-ME] Help with some nearly-binomial data
In-Reply-To: <u2oc59a5cf61004270626rf0c01ebcu74860aaaa8ece0eb@mail.gmail.com>
References: <u2oc59a5cf61004270626rf0c01ebcu74860aaaa8ece0eb@mail.gmail.com>
Message-ID: <q2i37fda5351004270806ibd96e137ued2bd6ddd9d9ca2a@mail.gmail.com>

If the purpose of the control condition is to to look at the relative
effects, why not simply run a binomial model on all the data, test and
control, add group as a variable and look for group*generation
interactions?

On Tuesday, April 27, 2010, Hywel Lloyd <hapdlloyd at googlemail.com> wrote:
> Hi, I've got stuck trying to model some data. Sorry for the trouble, but if
> anyone's got any help or suggestions I'd be really grateful.
>
> I'm trying to use mixed models to look at the rate that the hatching success
> of butterflies recovers after inbreeding over a number of generations. The
> data I have is the proportion of eggs that hatch for test and control
> populations so I would use a binomial distribution.
>
> But the main value I am interested in is the inbreeding depression, *s*,
> calculated as 1 - (test hatch rate/control mean hatch rate). This has two
> important roles - to give the relative decline in fitness and, by using the
> contemporaneous outbred hatching in each generation, it helps to control for
> other (lab) influences that may affect hatching from one generation to the
> next. The problem is though that occasionally the inbreds outperform the
> control, giving negative values for *s* which can't then be compared to the
> binomial distribution. Originally I simply used the test line mean hatch
> rates and assumed a normal distribution under the central limit theorem but
> this cut my number of data points from ~450 to 15 which seemed a bit
> wasteful.
>
> Does anyone have any suggestions for how I can proceed?
> I had considered simply changing the equation for *s* to 2 - (test/control),
> but I'm not sure if I could then convert my estimates for the fixed effect
> back into terms of the original inbreeding depression?
>
> Thanks for any help you can give me.
> Hywel
>
>  ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org?mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

-- 
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~



From tahirajamil at yahoo.com  Wed Apr 28 10:19:18 2010
From: tahirajamil at yahoo.com (Tahira Jamil)
Date: Wed, 28 Apr 2010 01:19:18 -0700 (PDT)
Subject: [R-sig-ME] significance of random effects and prediction
Message-ID: <806272.14409.qm@web113513.mail.gq1.yahoo.com>

Hi
I am fitting model in nlme/lme4) and interested testing the variance component and how the significance of variance component play a role in improving the prediction. First I fitted a model in nlme like this 

 v0 <- 0 * train.data$y + 1;

 fm.train<- lme(groupedData(y0 ~ X|v0), 
           random =list( v0=pdBlocked(list(pdIdent(~sp-1),pdIdent(~site-1),
                       pdIdent(~ X:Z0-1 ))),sp=pdIdent(~X-1)))  
  

and then only that variance component model which variance copmnent I wanted to test 

  fm.train1<- lme(groupedData(y0 ~ X|v0), 
         random =list( v0=pdIdent(~ X:Z0-1 )))


both the model fits well and  when I compare the above two models with exactRLRT test,
 exactRLRT( fm.train1, mA = fm.train$nlme)
 the variance component turn out to be siginifcant. 

then I fitted a reduce model 
 fm.train0<- lme(groupedData(y0 ~ X|v0), 
          random =list( v0=pdBlocked(list(pdIdent(~sp-1),pdIdent(~site-1)))
                       ,sp=pdIdent(~X-1))) 

But I do some cross validation and look for increse in R2 value for the left out data for both the models fm.train and fm.train0 give the approximately same value. 
So my question is if the variance component of a model is significant, does it improve or have some role for the prediction or how we can interpret this situation.
Hope for some good remarks 
Cheers

Tahira
Ph.D Student Biometris
Wageningen University



From Emma.Stone at bristol.ac.uk  Fri Apr 30 13:08:12 2010
From: Emma.Stone at bristol.ac.uk (Emma Stone)
Date: Fri, 30 Apr 2010 12:08:12 +0100
Subject: [R-sig-ME] post hoc tests for aov with mulitple error terms?
Message-ID: <5D5A343626E0445E2CC80780@bio-mammal012.bio.bris.ac.uk>

Dear All,

I am conducting an anova with multiple error terms:

model<-aov(time~treat+Error(site/treat))

and would like to be able to do post hoc tests (eg Tukeys) but the aov 
function only allows Tukeys test with aov.objects and the aov with multiple 
error terms creates and aov.list.

Can anyone suggest a solution to this?

previous posts on the forum have stated that I can use the following code 
with the glht function, but this also only works on aov. objects.

summary(glht(model, linfct=mcp(V="Tukey")))

Any ideas would be very much appreciated!!

Emma

----------------------
Emma Stone
Postgraduate Researcher
Bat Ecology and Bioacoustics Lab
& Mammal Research Unit
School of Biological Sciences,
University of Bristol, Woodland Road,
Bristol, BS8 1UG
Email: emma.stone at bristol.ac.uk



From matthewgiovanni at gmail.com  Sun May  2 04:04:58 2010
From: matthewgiovanni at gmail.com (Matthew Giovanni)
Date: Sat, 1 May 2010 21:04:58 -0500
Subject: [R-sig-ME] [R] Problem specifying Gamma distribution in
	lme4/glmer
In-Reply-To: <4BA6B8F1.40800@ufl.edu>
References: <3da23281003201554x2df00a9cw6e2dac28d6d8636a@mail.gmail.com> 
	<loom.20100321T155551-701@post.gmane.org>
	<1269187217065-1676746.post@n4.nabble.com> 
	<loom.20100321T221531-295@post.gmane.org>
	<7740B3D1-F709-414C-90F3-5885E11E2F37@comcast.net> 
	<4BA6B8F1.40800@ufl.edu>
Message-ID: <g2k3da23281005011904le5c2467bu1e4e920ebfa25e53@mail.gmail.com>

Hey, everyone.  Thanks so much for your input.  I apologize for not
attaching an example data file before.  I'm attaching an example csv file,
used with the following R script:

veg=read.csv("Litter.csv",header=TRUE)
veg$YPM=factor(veg$YPM)
veg$YEAR=factor(veg$YEAR)
hist(veg$LITTER)
qqnorm(veg$LITTER)
qqline(veg$LITTER)
litter=glmer(LITTER~YPM+MNG+(1|PROV/SITE)+(1|YEAR),data=veg,family=Gamma(link=log))
summary(litter)

I also noticed that Stephani posted an inquiry describing the same problem (
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2008q4/001684.html), where
the Gamma specification works with glm, and the lognormal specification
works with glmer, but the Gamma with glmer produces the same error for the
both of us:

Error in asMethod(object) : matrix is not symmetric [1,2]

Stephani, have you had any luck understanding this error?  I have not been
able to figure it out.  Thanks again for your input, everyone.  Best
regards,

Matt
___________________________________
Matt Giovanni, Ph.D.
NSERC Visiting Research Fellow
Canadian Wildlife Service
2365 Albert St., Room 300
Regina, SK S4P 4K1
306-780-6121 work
402-617-3764 mobile
http://sites.google.com/site/matthewgiovanni/


On Sun, Mar 21, 2010 at 7:25 PM, Ben Bolker <bolker at ufl.edu> wrote:

>  [Moving this to r-sig-mixed-models ]
>
> David Winsemius wrote:
> > On Mar 21, 2010, at 5:16 PM, Ben Bolker wrote:
> >
> >> Dieter Menne <dieter.menne <at> menne-biomed.de> writes:
> >>
> >>> Ben Bolker wrote:
> >>>> 3. zero-inflated data may not be particularly well-represented
> >>>> by a Gamma distribution: if you actually have a significant number
> >>>> of exactly-zero values, you may want to analyze your data in two
> >>>> stages, first as a presence-absence problem and then as a
> >>>> conditional
> >>>> density (i.e., what is the distribution of the non-zero values)?
> >>> [...] Do you know of a example where this was done (independent
> >>> of lmer)?  [...]
> >>  Nothing springs to mind, but it seems sensible.
> >
> > I thought this was what hurdle and ZIF models were supposed to handle
> > gracefully?
>
>  hurdle/zero-inflated/zero-altered models are typically developed in
> the context of discrete (count) data, where the base model has some
> non-zero probability of recording a zero and has to be altered to
> account for the presence of extra (or missing) zeros.  In this case
> (continuous data) the gamma distribution has an infinitesimal
> probability of producing an exact zero, so it's actually easier to deal
> with the data as a mixture of zeros (with probability p) and
> Gamma-distributed values (with shape and scale or rate parameters
> specified).  If it's OK to model the mixture process and the conditional
> density separately this is actually easier than a hurdle or ZIF model.
>
>  Another possibility, which I've heard of but not ever looked at
> carefully, would be to use Tweedie distributions with 1<p<2:
>
> http://en.wikipedia.org/wiki/Tweedie_distributions
> http://cran.r-project.org/web/packages/tweedie/index.html
>
>  Incorporating random effects could be tricky, though: a mean-variance
> relationship is given for Tweedie distributions (V = phi*mu^p), so
> conceivably the fitting could be done as a two-dimensional search over
> the GLMM fits obtained for fixed values of (phi,p).  (Yikes.)
>
>  Ben
>
>
>
> --
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / people.biology.ufl.edu/bolker
> GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc
>

From j.ayanz.loro at gmail.com  Mon May  3 10:44:51 2010
From: j.ayanz.loro at gmail.com (Jesus Ayanz)
Date: Mon, 3 May 2010 10:44:51 +0200
Subject: [R-sig-ME] Non-changing variables in a repeated measures analysis
	with lmer
Message-ID: <s2x23c76c4e1005030144q9d167ddeo5bb32f3b5aa0f25a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100503/0e6aa592/attachment.pl>

From Mike.Lawrence at dal.ca  Wed May  5 02:22:27 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Tue, 4 May 2010 21:22:27 -0300
Subject: [R-sig-ME] Predictor variable with quantifiable measurement error
Message-ID: <s2l37fda5351005041722q86e42356p61a514645dc976ec@mail.gmail.com>

Hi folks,

I'm wondering if there's a way to specify an lme model in a way that
lets it take into account quantifiable measurement error in a
predictor variable. The context is that I am interested in how fast
people categorize faces (as male vs female) as a function of the
attractiveness of the faces. I've measured the decision time to each
face multiple across multiple repetitions, eg:

categorization_data = expand.grid(
	subject = factor(1:40)
	, face = factor(1:20)
	, trial = 1:10
)
categorization_data$time = rnorm(nrow(a))

In a separate task, I've also elicited each subject's rating of each
face's attractiveness multiple times, eg:

rating_data = expand.grid(
	subject = factor(1:40)
	, face = factor(1:20)
	, trial = 1:2
)
rating_data$rating = sample(1:10,nrow(rating_data),replace=T)

Now, I could of course get the mean rating per face and use that mean
rating to predict categorization time (something along the lines of
"lmer( time ~ mean_rating  + ( 1 | face ) + ( 1 | subject ) )" ), but
I suspect that it might be important to let the lme know that there's
quantifiable measurement error in the rating data. I'm simply not sure
how to combine the data then formulate the model to achieve this.
Suggestions?

Mike

-- 
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~



From davidD at qimr.edu.au  Wed May  5 08:26:57 2010
From: davidD at qimr.edu.au (David Duffy)
Date: Wed, 5 May 2010 16:26:57 +1000 (EST)
Subject: [R-sig-ME] Predictor variable with quantifiable measurement
	error
In-Reply-To: <s2l37fda5351005041722q86e42356p61a514645dc976ec@mail.gmail.com>
References: <s2l37fda5351005041722q86e42356p61a514645dc976ec@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1005051616530.13241@orpheus.qimr.edu.au>

On Tue, 4 May 2010, Mike Lawrence wrote:

> Hi folks,
>
> I'm wondering if there's a way to specify an lme model in a way that
> lets it take into account quantifiable measurement error in a
> predictor variable. The context is that I am interested in how fast
> people categorize faces (as male vs female) as a function of the
> attractiveness of the faces. I've measured the decision time to each
> face multiple across multiple repetitions, eg:
>
> In a separate task, I've also elicited each subject's rating of each
> face's attractiveness multiple times, eg:

> ...I'm simply not sure how to combine the data then formulate the model 
> to achieve this.

That's the kind of thing more easily handled in a multi-group SEM 
framework, I would have thought.  To do it nicely, you might carry out a 
bivariate (normal, binomial) analysis of decision time and rating type in 
MCMCglmm or BUGS.  But if you have 10 trials in the main experiment, 
surely you have some variation in the ratings there too?

Cheers, David Duffy.
-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From christina.bogner at uni-bayreuth.de  Wed May  5 15:58:21 2010
From: christina.bogner at uni-bayreuth.de (Christina Bogner)
Date: Wed, 05 May 2010 15:58:21 +0200
Subject: [R-sig-ME] F test for two mixed-effects models
Message-ID: <4BE1797D.2020800@uni-bayreuth.de>

Dear list,

I am stuck with an F test in a mixed-effects model. Some time ago Dr. 
Bates explained that if we had factors for fixed-effects, the model 
always spaned an intercept, even if we excluded it in the model formula. 
Now, I fit two models:

model1 = lme(response ~ factor1 + factor2 + x, random= ~1|plot, data=mydata)

model2 = lme(response ~ 0  + factor1 + factor2 + x, random= ~1|plot, 
data=mydata)

response and x are continuous, factor1, factor2 and plot are factors.
And I would like to test the hypothesis, that all model coefficients 
except the intercept are zero. For model2, instead of the intercept, I 
use the reference level (the same as the estimate of the intercept in 
model1, of course). For the test, I use the function wald.test in the 
package aod. To my surprise, the F value in the test is not the same for 
model1 and model2.
I certainly miss something important, but I can?t figure out what it is. 
Of course, the fixed-effects estimates of the factors are different 
(except for the reference level) and the var-cov-matrices differ as 
well. But, I thought, that the two models were equivalent and that I was 
testing the same hypothesis.

Any help would be greatly appreciated.

Christina



From Paul.Prew at ecolab.com  Thu May  6 08:12:35 2010
From: Paul.Prew at ecolab.com (Prew, Paul)
Date: Thu, 6 May 2010 01:12:35 -0500
Subject: [R-sig-ME] starting values in nlme
Message-ID: <6B810AFB14C606439FD57E5985E0379104759411@useagan1500p.GLOBAL.ECOLAB.CORP>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100506/c9cff368/attachment.pl>

From Jesus.Frias at dit.ie  Thu May  6 15:14:11 2010
From: Jesus.Frias at dit.ie (Jesus Frias)
Date: Thu, 6 May 2010 14:14:11 +0100
Subject: [R-sig-ME] starting values in nlme
In-Reply-To: <6B810AFB14C606439FD57E5985E0379104759411@useagan1500p.GLOBAL.ECOLAB.CORP>
References: <6B810AFB14C606439FD57E5985E0379104759411@useagan1500p.GLOBAL.ECOLAB.CORP>
Message-ID: <005e01caed1e$04596650$0d0c32f0$@Frias@dit.ie>

Hi Paul,

I think that in your "fixed=" statement you are declaring linear
relationships between your parameters (Peak and Rate) and the variables
Vents and Time.
 
fixed = Peak + Rate ~ Vents * Time

you are saying that the Peak pressure and the rate of decrease  depends on
the no of Vents and changes linearly with time. 

If I understand well what you are doing you probably want 

fixed= Peak + Rate ~ 1

That will work with the starting values that you have (and if you are lucky
it will converge). 

After you have obtained that model you can start building more complicated
relationships (specially introducing Vents, to check for differences between
using 1 Vent or 2 Vents). I am not sure about the time relationship in that
mass transfer.

Regards,

Jesus


Jes?s Mar?a Fr?as Celayeta
Head of Department of Food Science
School of Food Science and Environmental Health
Dublin Institute of Technology
t +353 1 402 4459
f +353 1 4024495
w http://fseh.dit.ie/o4/StaffListing/JesusFrias.html





-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Prew, Paul
Sent: Thursday, May 06, 2010 7:13 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] starting values in nlme

Hello,  I am making my first attempt to work with a non-linear model in R,
and am hoping someone can spot the error I've made.  The scenario is to
model the rate of gas escaping from a container with 1 vs. 2 vents.   10
container samples were pumped up to 2 psi (relative pressure), then allowed
to vent for 15 minutes.  Pressure readings were taken every minute.  The
research question is the significance of the Vent factor (1 vs. 2),  with
Samples as the random factor and Pressure decaying exponentially.  Readings
at time zero were removed, as they were 2 psi.  Any direction you can
provide is appreciated, regards, Paul
 
> str(Press.dat)
'data.frame':   125 obs. of  4 variables:
 $ Time     : num  1 2 3 4 5 6 7 8 9 10 ...
 $ Pressure : num  1.8 1.6 1.5 1.4 1.3 1.2 1.1 1 0.9 0.8 ...
 $ Vents    : num  1 1 1 1 1 1 1 1 1 1 ...
 $ Sample   : num  1 1 1 1 1 1 1 1 1 1 ...
 

 
> Press.fit1 <-
+ nlme(model = Pressure ~ Peak * (1 - exp(-Rate*Time)),
+ fixed = Peak + Rate ~ Vents * Time, random = Peak + Rate ~ 1 | Sample,
+ data = Press.dat,
+ start = c(Peak=2, Rate=1.3))
Error in nlme.formula(model = Pressure ~ Peak * (1 - exp(-Rate * Time)),  : 
  starting values for the fixed component are not the correct length
 

CONFIDENTIALITY NOTICE: \ This e-mail communication an.....{{dropped:9}}



From bates at stat.wisc.edu  Thu May  6 17:44:56 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 6 May 2010 10:44:56 -0500
Subject: [R-sig-ME] lmer() on linux
In-Reply-To: <h2x76fe59071005060834m343dd24aw39fd7fd7e7012709@mail.gmail.com>
References: <h2x76fe59071005060834m343dd24aw39fd7fd7e7012709@mail.gmail.com>
Message-ID: <l2v40e66e0b1005060844p37e039a1ufbe9495da65889d6@mail.gmail.com>

On Thu, May 6, 2010 at 10:34 AM, Julia Liu <liujulia7 at gmail.com> wrote:
> Dear Prof. Bates,
>
> I have been using lmer() for sometime in windows version of R. Recently, I
> decided to install R on a linux machine in order get bigger memory limit.
> Everything went fine, including testing most of my existing R codes.
> However, I have ran into one problem with function lmer() on Linux R. For
> some of my data and codes, the lmer() gave the following warning:
> "Warning message:
> In mer_finalize(ans) : iteration limit reached without convergence (9)"
>
> And the exact same code and data ran fine in Windows R (without any
> warnings).? What's is the reason? Does Linux version have a lower iteration
> limit than the windows version?

Even on the same hardware there are subtle differences in the
numerical properties of some of the optimization and linear algebra
methods between Windows and Linux.  This warning comes from the
optimization method.

Could you provide a reproducible example, including the data?  If the
data are proprietary you could remove any identifying characteristics
and anonymize the identifiers.  I would just need to have the
numerical values of the covariates and response plus the formula
defining the model.

It is generally better to send questions like this to the
R-SIG-Mixed-Models at R-project.org mailing list, which I have taken the
liberty of cc:ing on this reply.  I am deep in the throes of writing
and debugging a new version of the code and don't always have the
opportunity to respond quickly to inquiries.



From Paul.Prew at ecolab.com  Thu May  6 22:54:31 2010
From: Paul.Prew at ecolab.com (Prew, Paul)
Date: Thu, 6 May 2010 15:54:31 -0500
Subject: [R-sig-ME] starting values in nlme
In-Reply-To: <005e01caed1e$04596650$0d0c32f0$@Frias@dit.ie>
References: <6B810AFB14C606439FD57E5985E0379104759411@useagan1500p.GLOBAL.ECOLAB.CORP>
	<005e01caed1e$04596650$0d0c32f0$@Frias@dit.ie>
Message-ID: <6B810AFB14C606439FD57E5985E03791050E1C51@useagan1500p.GLOBAL.ECOLAB.CORP>

Dear Jesus,

Thank you for your reply.  Your suggested changes did work, but the model failed to converge as you ventured might happen.  In reading through various sources and  help lists, could be that the model is over-parameterized, and random effects for the repeated measures are over-kill.

Also, your reply was helpful in identifying the complex interpretation of my model terms.  I am interested in modeling the Rate as a function of # Vents.   Probably not the Asymptote/Peak vs. # Vents, after thinking about it more.  The other 'flexibility' in the parameters --- the Time interaction --- was me not understanding the concepts of nonlinear mixed models.   Thank you for your insight.

Regards,
Paul


Paul Prew  |  Statistician
651-795-5942?? |?? fax 651-204-7504 
Ecolab Research Center  | Mail Stop ESC-F4412-A 
655 Lone Oak Drive  |  Eagan, MN 55121-1560 

 

-----Original Message-----
From: Jesus Frias [mailto:Jesus.Frias at dit.ie] 
Sent: Thursday, May 06, 2010 8:14 AM
To: Prew, Paul
Cc: r-sig-mixed-models at r-project.org
Subject: RE: [R-sig-ME] starting values in nlme

Hi Paul,

I think that in your "fixed=" statement you are declaring 
linear relationships between your parameters (Peak and Rate) 
and the variables Vents and Time.
 
fixed = Peak + Rate ~ Vents * Time

you are saying that the Peak pressure and the rate of decrease  
depends on the no of Vents and changes linearly with time. 

If I understand well what you are doing you probably want 

fixed= Peak + Rate ~ 1

That will work with the starting values that you have (and if 
you are lucky it will converge). 

After you have obtained that model you can start building more 
complicated relationships (specially introducing Vents, to 
check for differences between using 1 Vent or 2 Vents). I am 
not sure about the time relationship in that mass transfer.

Regards,

Jesus


Jes?s Mar?a Fr?as Celayeta
Head of Department of Food Science
School of Food Science and Environmental Health Dublin 
Institute of Technology t +353 1 402 4459 f +353 1 4024495 w 
http://fseh.dit.ie/o4/StaffListing/JesusFrias.html





-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of 
Prew, Paul
Sent: Thursday, May 06, 2010 7:13 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] starting values in nlme

Hello,  I am making my first attempt to work with a non-linear 
model in R, and am hoping someone can spot the error I've made. 
 The scenario is to
model the rate of gas escaping from a container with 1 vs. 2 vents.   10
container samples were pumped up to 2 psi (relative pressure), 
then allowed to vent for 15 minutes.  Pressure readings were 
taken every minute.  The research question is the significance 
of the Vent factor (1 vs. 2),  with Samples as the random 
factor and Pressure decaying exponentially.  Readings at time 
zero were removed, as they were 2 psi.  Any direction you can 
provide is appreciated, regards, Paul
 
> str(Press.dat)
'data.frame':   125 obs. of  4 variables:
 $ Time     : num  1 2 3 4 5 6 7 8 9 10 ...
 $ Pressure : num  1.8 1.6 1.5 1.4 1.3 1.2 1.1 1 0.9 0.8 ...
 $ Vents    : num  1 1 1 1 1 1 1 1 1 1 ...
 $ Sample   : num  1 1 1 1 1 1 1 1 1 1 ...
 

 
> Press.fit1 <-
+ nlme(model = Pressure ~ Peak * (1 - exp(-Rate*Time)), fixed = Peak + 
+ Rate ~ Vents * Time, random = Peak + Rate ~ 1 | Sample, data = 
+ Press.dat, start = c(Peak=2, Rate=1.3))
Error in nlme.formula(model = Pressure ~ Peak * (1 - exp(-Rate 
* Time)),  : 
  starting values for the fixed component are not the correct length
 

CONFIDENTIALITY NOTICE: \ This e-mail communication an.....{{dropped:22}}



From alex.safari at flinders.edu.au  Fri May  7 13:46:05 2010
From: alex.safari at flinders.edu.au (Alex Safari)
Date: Fri, 7 May 2010 21:16:05 +0930
Subject: [R-sig-ME] reshape
Message-ID: <000001caedda$e134ae60$a39e0b20$@safari@flinders.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100507/4f9d3920/attachment.pl>

From Jesus.Frias at dit.ie  Fri May  7 13:47:08 2010
From: Jesus.Frias at dit.ie (Jesus Frias)
Date: Fri, 7 May 2010 12:47:08 +0100
Subject: [R-sig-ME] starting values in nlme
In-Reply-To: <6B810AFB14C606439FD57E5985E03791050E1C51@useagan1500p.GLOBAL.ECOLAB.CORP>
References: <6B810AFB14C606439FD57E5985E0379104759411@useagan1500p.GLOBAL.ECOLAB.CORP>
	<005e01caed1e$04596650$0d0c32f0$%Frias@dit.ie>
	<6B810AFB14C606439FD57E5985E03791050E1C51@useagan1500p.GLOBAL.ECOLAB.CORP>
Message-ID: <010b01caeddb$05cea550$116beff0$@Frias@dit.ie>

Hi Paul,

If the model failed to converge without the Vents effect you may want to
try:

Press.fit1 <-nlme(model = Pressure ~ Peak * (1 - exp(-Rate*Time)), fixed =
list(Peak~1, Rate ~ Vents), random = Peak + Rate ~ 1 | Sample, data =
Press.dat, start = c(2,1.3,2.6))

The 1.3 is the difference in rate between the first level of your factor
Vents and the second (analytical contrasts). Use a better estimation of that
value instead of the 1.3 (double the rate for using 2 vents, if 1 Vent is
the first level in your Vents variable).

Regards,

Jesus


-----Original Message-----
From: Prew, Paul [mailto:Paul.Prew at ecolab.com] 
Sent: Thursday, May 06, 2010 9:55 PM
To: Jesus Frias
Cc: r-sig-mixed-models at r-project.org
Subject: RE: [R-sig-ME] starting values in nlme

Dear Jesus,

Thank you for your reply.  Your suggested changes did work, but the model
failed to converge as you ventured might happen.  In reading through various
sources and  help lists, could be that the model is over-parameterized, and
random effects for the repeated measures are over-kill.

Also, your reply was helpful in identifying the complex interpretation of my
model terms.  I am interested in modeling the Rate as a function of # Vents.
Probably not the Asymptote/Peak vs. # Vents, after thinking about it more.
The other 'flexibility' in the parameters --- the Time interaction --- was
me not understanding the concepts of nonlinear mixed models.   Thank you for
your insight.

Regards,
Paul


Paul Prew  |  Statistician
651-795-5942?? |?? fax 651-204-7504 
Ecolab Research Center  | Mail Stop ESC-F4412-A 
655 Lone Oak Drive  |  Eagan, MN 55121-1560 

 

-----Original Message-----
From: Jesus Frias [mailto:Jesus.Frias at dit.ie] 
Sent: Thursday, May 06, 2010 8:14 AM
To: Prew, Paul
Cc: r-sig-mixed-models at r-project.org
Subject: RE: [R-sig-ME] starting values in nlme

Hi Paul,

I think that in your "fixed=" statement you are declaring 
linear relationships between your parameters (Peak and Rate) 
and the variables Vents and Time.
 
fixed = Peak + Rate ~ Vents * Time

you are saying that the Peak pressure and the rate of decrease  
depends on the no of Vents and changes linearly with time. 

If I understand well what you are doing you probably want 

fixed= Peak + Rate ~ 1

That will work with the starting values that you have (and if 
you are lucky it will converge). 

After you have obtained that model you can start building more 
complicated relationships (specially introducing Vents, to 
check for differences between using 1 Vent or 2 Vents). I am 
not sure about the time relationship in that mass transfer.

Regards,

Jesus


Jes?s Mar?a Fr?as Celayeta
Head of Department of Food Science
School of Food Science and Environmental Health Dublin 
Institute of Technology t +353 1 402 4459 f +353 1 4024495 w 
http://fseh.dit.ie/o4/StaffListing/JesusFrias.html





-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of 
Prew, Paul
Sent: Thursday, May 06, 2010 7:13 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] starting values in nlme

Hello,  I am making my first attempt to work with a non-linear 
model in R, and am hoping someone can spot the error I've made. 
 The scenario is to
model the rate of gas escaping from a container with 1 vs. 2 vents.   10
container samples were pumped up to 2 psi (relative pressure), 
then allowed to vent for 15 minutes.  Pressure readings were 
taken every minute.  The research question is the significance 
of the Vent factor (1 vs. 2),  with Samples as the random 
factor and Pressure decaying exponentially.  Readings at time 
zero were removed, as they were 2 psi.  Any direction you can 
provide is appreciated, regards, Paul
 
> str(Press.dat)
'data.frame':   125 obs. of  4 variables:
 $ Time     : num  1 2 3 4 5 6 7 8 9 10 ...
 $ Pressure : num  1.8 1.6 1.5 1.4 1.3 1.2 1.1 1 0.9 0.8 ...
 $ Vents    : num  1 1 1 1 1 1 1 1 1 1 ...
 $ Sample   : num  1 1 1 1 1 1 1 1 1 1 ...
 

 
> Press.fit1 <-
+ nlme(model = Pressure ~ Peak * (1 - exp(-Rate*Time)), fixed = Peak + 
+ Rate ~ Vents * Time, random = Peak + Rate ~ 1 | Sample, data = 
+ Press.dat, start = c(Peak=2, Rate=1.3))
Error in nlme.formula(model = Pressure ~ Peak * (1 - exp(-Rate 
* Time)),  : 
  starting values for the fixed component are not the correct length
 

CONFIDENTIALITY NOTICE: \ This e-mail communication an.....{{dropped:26}}



From Emma.Stone at bristol.ac.uk  Fri May  7 14:28:30 2010
From: Emma.Stone at bristol.ac.uk (Emma Stone)
Date: Fri, 07 May 2010 13:28:30 +0100
Subject: [R-sig-ME] Conducting an anova with multiple error terms
Message-ID: <729DBBFFDE8D8DDCC4DB6B61@bio-mammal012.bio.bris.ac.uk>


Dear All,

I am conducting an anova with multiple error terms:

model<-aov(time~treat+Error(site/treat))

and would like to be able to do post hoc tests (eg Tukeys) but the aov
function only allows Tukeys test with aov.objects and the aov with multiple
error terms creates and aov.list.

Can anyone suggest a solution to this?

previous posts on the forum have stated that I can use the following code
with the glht function, but this also only works on aov. objects.

summary(glht(model, linfct=mcp(V="Tukey")))

Any ideas would be very much appreciated!!
----------------------
Emma Stone
Postgraduate Researcher
Bat Ecology and Bioacoustics Lab
& Mammal Research Unit
School of Biological Sciences,
University of Bristol, Woodland Road,
Bristol, BS8 1UG
Email: emma.stone at bristol.ac.uk



From cmc76 at drexel.edu  Sat May  8 23:07:52 2010
From: cmc76 at drexel.edu (Claire M. Sheridan)
Date: Sat, 8 May 2010 17:07:52 -0400
Subject: [R-sig-ME] Binominal GLMM in Lmer
Message-ID: <000001caeef2$88738990$995a9cb0$@edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100508/6c0da0b9/attachment.pl>

From bolker at ufl.edu  Mon May 10 04:26:30 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Sun, 09 May 2010 22:26:30 -0400
Subject: [R-sig-ME] Binominal GLMM in Lmer
In-Reply-To: <000001caeef2$88738990$995a9cb0$@edu>
References: <000001caeef2$88738990$995a9cb0$@edu>
Message-ID: <4BE76ED6.50200@ufl.edu>

Claire M. Sheridan wrote:
>   
> I am new to the use of R and to GLMM's. I am not sure how to interpret my
> results. I first modeled my most complex model with all of my hypothesized
> fixed effects(print out below). From my Pr(>|z|) values I feel that I should
> be able to say that none of the fixed effects significantly affects
> presence. I also ran models in which I took out one fixed effect at a time
> and compare using ANOVA. 

  Do you mean anova()? (This runs a likelihood ratio test, confusingly
enough.)

I also started with more basic models (1 fixed
> effect) 

  with no random effect?  or do you mean 1 fixed effect + random effects?

and compared it to a model with only random effects (with the #1 in
> place of where the fixed effect would be). Using ANOVA I also compared those
> models. What is confusing to me is that I sometimes get lower AIC values and
> significant p-values for the ANOVA with the model with a single fixed effect
> vs. a model with no fixed effect. I was expecting based on the Pr(>|z|)
> values that I would get lower AIC values for the no fixed effects model. For
> any variation that I run on the model (1-7 fixed effects), the Pr(>|z|)
> values are always >0.05. Can someone help explain this to me? I'm really
> sorry if this something that has already been addressed, but I couldn't find
> anything on the message boards similar to my question. 

  Which other variables are included matters in GLMMs (it matters in any
  modeling framework where the effects are not perfectly orthogonal,
which includes most regression models, any nonlinear model, and GLMMs).
 It is not shocking that you find some cases where adding some variables
to the simplest/null model improves prediction, but adding the same
variables to a model with the other 6 variables present does not.  In
addition, AIC and Likelihood ratio test p-values are completely
different frameworks, my fairly strong advice is to pick one or the
other & not to use them in the same analysis.

  These issues are fairly generic to modeling/model selection problems
as soon as one leaves the balanced/orthogonal/designed experiment case.
Zuur et al (mixed models book), Harrell (applied regression modeling)
are both recommended.  Others may have other recommendations.

> print(m1<-lmer(Presence ~FixedEffect1 + FixedEffect2 + FixedEffect3 +
> FixedEffect4 + FixedEffect5 + FixedEffect6 + FixedEffect7 + (1|Site) +
> (1|Year), family=binomial, REML=FALSE))
> 
> Generalized linear mixed model fit by the Laplace approximation 
> 
> Formula: Presence ~FixedEffect1 + FixedEffect2 + FixedEffect3 + FixedEffect4
> + FixedEffect5 + FixedEffect6 + FixedEffect7  + (1 | Site) + (1 | Year) 
> 
>   AIC   BIC logLik deviance
> 
>  88.9 110.8 -34.45     68.9
> 
> Random effects:
> 
>  Groups Name        Variance Std.Dev.
>  Site   (Intercept)  0        0      
>  Year   (Intercept)  0        0      
> 
> Number of obs: 66, groups: Site, 4; Year, 2

   The zero variances here suggest fairly strongly that you're
overfitting.  It's hard to fit a random-effects term with only 4 sites,
and even harder with only 2 years (e.g. search for "Are there enough
levels" in <http://glmm.wikidot.com/faq>)

> Fixed effects:
> 
>                   Estimate Std. Error z value Pr(>|z|)  
> 
> (Intercept)     -17.793834   9.299257  -1.914   0.0557 . 
> FixedEffect1        0.164940   0.175818   0.938   0.3482  
> FixedEffect2         0.068806   0.057713   1.192   0.2332  
> FixedEffect3      -0.004817   0.004070  -1.183   0.2367  
> FixedEffect4          0.375625   0.399966   0.939   0.3477  
> FixedEffect5          -0.112683   0.658858  -0.171   0.8642  
> FixedEffect6  2.672537   2.158679   1.238   0.2157  
> FixedEffect7       -0.175103   0.132223  -1.324   0.1854  
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
*** NEW E-MAIL ADDRESSES:
***   bbolker at gmail.com , bolker at math.mcmaster.ca
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From j.Perez-Barberia at macaulay.ac.uk  Mon May 10 12:56:28 2010
From: j.Perez-Barberia at macaulay.ac.uk (Javier Perez-Barberia)
Date: Mon, 10 May 2010 11:56:28 +0100
Subject: [R-sig-ME] How to deal with time correlated fixed effects in lmer?
Message-ID: <4BE7F46D020000690004F6A5@macaulay.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100510/846f2e71/attachment.pl>

From 2nuzzbot at gmail.com  Tue May 11 17:11:13 2010
From: 2nuzzbot at gmail.com (Etn)
Date: Tue, 11 May 2010 16:11:13 +0100
Subject: [R-sig-ME] OR random effects - multilevel model
Message-ID: <AANLkTilHLW1Rsum20nTAcQe8zZhlAsA5X_ioZofIXNBZ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100511/92f6e1a4/attachment.pl>

From ccleland at optonline.net  Tue May 11 19:14:16 2010
From: ccleland at optonline.net (Chuck Cleland)
Date: Tue, 11 May 2010 13:14:16 -0400
Subject: [R-sig-ME] OR random effects - multilevel model
In-Reply-To: <AANLkTilHLW1Rsum20nTAcQe8zZhlAsA5X_ioZofIXNBZ@mail.gmail.com>
References: <AANLkTilHLW1Rsum20nTAcQe8zZhlAsA5X_ioZofIXNBZ@mail.gmail.com>
Message-ID: <4BE99068.8090509@optonline.net>

On 5/11/2010 11:11 AM, Etn wrote:
> Hi All,
> 
> I would really appreciate any advice on extracting Odds Ratios for random
> effects from my multilevel model. I want to find the OR for the random
> effects School and School:Student_ID......
> I have tried several approaches with no success.....

  Perhaps you are looking for the median odds ratio described by Larsen
and Merlo (2005)?

http://aje.oxfordjournals.org/cgi/content/short/161/1/81

  If not, you may want to further explain what you mean.

hope this helps,

Chuck Cleland

> Model<- lmer(Res~Gender+(1|School)+(1|School:Student_ID),
> family=binomial,data=Data)
> 
> 
> I can extract the ORs for the fixed effects using:
> 
> OR_fixed=exp(fixef(Model))
> OR_fixed
> 
> However, I cannot seem to extract for Random effects...
> 
> The methods I have tried are:
> 
> 1): This gives the OR for School..... but I'm unsure how to get
> School:Student_ID
> 
> Random1 = coef(Model)$School
> OR_Random<-exp(Random1)
> 
> 
> 2) This extracts the random effects, but I cannot exp to get OR
> 
> 
> ranef(Model)
> exp(ranef(Model))
> 
> Error in exp(ranef(Model)) :
>   Non-numeric argument to mathematical function
> 
> 2a)
> 
> exp(ranef(Model)$School:Student_ID)
> Error in ranef(Model)$School:Student_ID: NA/NaN argument
> In addition: Warning message:
> In ranef(Model)$School:Student_ID:
>   numerical expression has 43159 elements: only the first used
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Chuck Cleland, Ph.D.
NDRI, Inc. (www.ndri.org)
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894



From dzajanc at harveyecology.com  Wed May 12 01:49:38 2010
From: dzajanc at harveyecology.com (David Zajanc)
Date: Tue, 11 May 2010 16:49:38 -0700
Subject: [R-sig-ME] Negative binomial mixed effects modeling
Message-ID: <16DD87487289A44088D4991B7D9EA8B501EBC800@exchange.harvey.corp>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100511/b5c640f1/attachment.pl>

From davidD at qimr.edu.au  Wed May 12 05:33:12 2010
From: davidD at qimr.edu.au (David Duffy)
Date: Wed, 12 May 2010 13:33:12 +1000 (EST)
Subject: [R-sig-ME] Negative binomial mixed effects modeling
In-Reply-To: <16DD87487289A44088D4991B7D9EA8B501EBC800@exchange.harvey.corp>
References: <16DD87487289A44088D4991B7D9EA8B501EBC800@exchange.harvey.corp>
Message-ID: <Pine.LNX.4.64.1005121315140.9609@orpheus.qimr.edu.au>

On Tue, 11 May 2010, David Zajanc wrote:

> Hi,
>
> I am looking into ways to fit a negative binomial mixed effects model to
> our data, but have not found any obvious methods in searching through
> the archives of this list.  I noticed suggestions for using the
> quasipoisson distribution, but our dataset appears better suited for the
> negative binomial model, based on past analyses using GLM.  It appears
> that "glmer" of package "lme4" is not currently capable of fitting a
> negative binomial model, though please correct me if I'm wrong about
> this.  Any feedback or suggestions would be welcomed.

If you have only a "single level" of random effects eg simple clusters, 
then gamm() [mgcv] or spm() [SemiPar].  If a negative binomial GLM fits, 
then an "ordinary" poisson 
GLMM may be appopriate (the REs have to come from a gamma to give a 
negative binomial IIRC, in which case maybe one could use the survival 
package with gamma frailty???).  You could also go to 
(other) semiparametric mixed models (see refs in Diao and Lin Am J Hum 
Genet 2005l 77:97-111).

In one of my analyses of total body mole count, diagnostics showed the 
negative binomial and cube-root-transforms were equally nice for mixed 
model, FWIW.


-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From bolker at ufl.edu  Wed May 12 05:36:32 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 11 May 2010 23:36:32 -0400
Subject: [R-sig-ME] Negative binomial mixed effects modeling
In-Reply-To: <16DD87487289A44088D4991B7D9EA8B501EBC800@exchange.harvey.corp>
References: <16DD87487289A44088D4991B7D9EA8B501EBC800@exchange.harvey.corp>
Message-ID: <4BEA2240.8030305@ufl.edu>

David Zajanc wrote:
> Hi,
> 
>  
> 
> I am looking into ways to fit a negative binomial mixed effects model to
> our data, but have not found any obvious methods in searching through
> the archives of this list.  I noticed suggestions for using the
> quasipoisson distribution, but our dataset appears better suited for the
> negative binomial model, based on past analyses using GLM.  It appears
> that "glmer" of package "lme4" is not currently capable of fitting a
> negative binomial model, though please correct me if I'm wrong about
> this.  Any feedback or suggestions would be welcomed.

  At the moment you need glmmADMB, or glmmBUGS, or R2WinBUGS, or AD
Model Builder, or ... see <http://glmm.wikidot.com/faq> for (not much)
more information.



From s.blomberg1 at uq.edu.au  Wed May 12 05:59:01 2010
From: s.blomberg1 at uq.edu.au (Simon Blomberg)
Date: Wed, 12 May 2010 13:59:01 +1000
Subject: [R-sig-ME] Negative binomial mixed effects modeling
In-Reply-To: <4BEA2240.8030305@ufl.edu>
References: <16DD87487289A44088D4991B7D9EA8B501EBC800@exchange.harvey.corp>
	<4BEA2240.8030305@ufl.edu>
Message-ID: <1273636741.7726.31.camel@sib-sblomberg1n>

Jim Lindsey's repeated package has function gnlmm which will fit neg-bin
mixed effects models with one level of nesting. See:

http://www.commanster.eu/rcode.html

Jim's packages are non-CRAN. There are source packages and Windows
binaries. There is also a binary package in the Debian repository, but
it currently doesn't work for R > 2.10.0.

Simon.


On Tue, 2010-05-11 at 23:36 -0400, Ben Bolker wrote:
> David Zajanc wrote:
> > Hi,
> > 
> >  
> > 
> > I am looking into ways to fit a negative binomial mixed effects model to
> > our data, but have not found any obvious methods in searching through
> > the archives of this list.  I noticed suggestions for using the
> > quasipoisson distribution, but our dataset appears better suited for the
> > negative binomial model, based on past analyses using GLM.  It appears
> > that "glmer" of package "lme4" is not currently capable of fitting a
> > negative binomial model, though please correct me if I'm wrong about
> > this.  Any feedback or suggestions would be welcomed.
> 
>   At the moment you need glmmADMB, or glmmBUGS, or R2WinBUGS, or AD
> Model Builder, or ... see <http://glmm.wikidot.com/faq> for (not much)
> more information.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bolker at ufl.edu  Wed May 12 06:11:58 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Wed, 12 May 2010 00:11:58 -0400
Subject: [R-sig-ME] Negative binomial mixed effects modeling
In-Reply-To: <Pine.LNX.4.64.1005121315140.9609@orpheus.qimr.edu.au>
References: <16DD87487289A44088D4991B7D9EA8B501EBC800@exchange.harvey.corp>
	<Pine.LNX.4.64.1005121315140.9609@orpheus.qimr.edu.au>
Message-ID: <4BEA2A8E.3070508@ufl.edu>

David Duffy wrote:
> On Tue, 11 May 2010, David Zajanc wrote:
> 
>> Hi,
>>
>> I am looking into ways to fit a negative binomial mixed effects model to
>> our data, but have not found any obvious methods in searching through
>> the archives of this list.  I noticed suggestions for using the
>> quasipoisson distribution, but our dataset appears better suited for the
>> negative binomial model, based on past analyses using GLM.  It appears
>> that "glmer" of package "lme4" is not currently capable of fitting a
>> negative binomial model, though please correct me if I'm wrong about
>> this.  Any feedback or suggestions would be welcomed.
> 
> If you have only a "single level" of random effects eg simple clusters, 
> then gamm() [mgcv] or spm() [SemiPar].  

  ??
  I don't see how this works -- gamm() will do the family options from
glm (including negative.binomial() from MASS with a *fixed*
overdispersion/theta/k parameter, but not? estimating the overdispersion
as part of the fitting process?), spm() doesn't seem to have a NB option?

  I would love to be wrong on this and corrected on it.

  Anyone should feel free to update <http://glmm.wikidot.com/faq> if
they have a better way, or a worked example ...



From davidD at qimr.edu.au  Wed May 12 09:58:37 2010
From: davidD at qimr.edu.au (David Duffy)
Date: Wed, 12 May 2010 17:58:37 +1000 (EST)
Subject: [R-sig-ME] Negative binomial mixed effects modeling
In-Reply-To: <4BEA2A8E.3070508@ufl.edu>
References: <16DD87487289A44088D4991B7D9EA8B501EBC800@exchange.harvey.corp>
	<Pine.LNX.4.64.1005121315140.9609@orpheus.qimr.edu.au>
	<4BEA2A8E.3070508@ufl.edu>
Message-ID: <Pine.LNX.4.64.1005121734060.18846@orpheus.qimr.edu.au>

On Wed, 12 May 2010, Ben Bolker wrote:

> David Duffy wrote:
>> On Tue, 11 May 2010, David Zajanc wrote:
>> If you have only a "single level" of random effects eg simple clusters,
>> then gamm() [mgcv] or spm() [SemiPar].
>
>  I don't see how this works -- gamm() will do the family options from
> glm (including negative.binomial() from MASS with a *fixed*
> overdispersion/theta/k parameter, but not? estimating the overdispersion
> as part of the fitting process?), spm() doesn't seem to have a NB option?
>
>  I would love to be wrong on this and corrected on it.

No you are right.  I don't regard having to iterate mgcv's gamm() "by 
hand" over theta to be a showstopper, though.  My memory was just wrong 
about spm().


Cheers, David.


-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From Kay.Cichini at uibk.ac.at  Wed May 12 11:14:11 2010
From: Kay.Cichini at uibk.ac.at (Kay Cecil Cichini)
Date: Wed, 12 May 2010 11:14:11 +0200
Subject: [R-sig-ME] post hocs for lmer / lme
Message-ID: <4BEA7163.7090709@uibk.ac.at>

hello,

i searched for a reference how to do post hocs for lmms or glmms but 
without success!

i have a model with 2 nominal explanatory variables (2 levels and 4 
levels) and 2 nested random variables. from my final model i want to 
examine certain combinations of the fixed factors.
how is this best achived in LMMs / GLMMs?
is it valid to re-order the levels of the factors and assess the 
t-statistics of the paramteres?

any advise or pointers on useful references would be greatly appreciated!

best,
kay



From Mike.Lawrence at dal.ca  Wed May 12 14:16:43 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Wed, 12 May 2010 09:16:43 -0300
Subject: [R-sig-ME] post hocs for lmer / lme
In-Reply-To: <4BEA7163.7090709@uibk.ac.at>
References: <4BEA7163.7090709@uibk.ac.at>
Message-ID: <AANLkTinglmwXdpPUyMIhRuYMyziuxFLZfnE4mVaW3crD@mail.gmail.com>

One approach I've been playing with lately is using bootstrapping &
LME to generate distributions of predicted values for each cell in the
design (using the full model on each iteration of the loop). These
distributions (or, more properly, the distributions of difference
scores for focal comparisons) can then be used for post hocs. I
haven't thought about application to nested designs though, so you may
have to be careful with how you bootstrap there.

On Wed, May 12, 2010 at 6:14 AM, Kay Cecil Cichini
<Kay.Cichini at uibk.ac.at> wrote:
> hello,
>
> i searched for a reference how to do post hocs for lmms or glmms but without
> success!
>
> i have a model with 2 nominal explanatory variables (2 levels and 4 levels)
> and 2 nested random variables. from my final model i want to examine certain
> combinations of the fixed factors.
> how is this best achived in LMMs / GLMMs?
> is it valid to re-order the levels of the factors and assess the
> t-statistics of the paramteres?
>
> any advise or pointers on useful references would be greatly appreciated!
>
> best,
> kay
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~



From dmsilv at gmail.com  Wed May 12 16:36:57 2010
From: dmsilv at gmail.com (Daniel)
Date: Wed, 12 May 2010 11:36:57 -0300
Subject: [R-sig-ME] Centering dummies
Message-ID: <AANLkTik9W7BM_-bBNZ0j-zXzgvBi34NJWzxsqegAtOB_@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100512/f5a46e99/attachment.pl>

From datkins at u.washington.edu  Wed May 12 17:36:14 2010
From: datkins at u.washington.edu (David Atkins)
Date: Wed, 12 May 2010 08:36:14 -0700
Subject: [R-sig-ME] Negative binomial mixed effects modeling
In-Reply-To: <4BEA2240.8030305@ufl.edu>
References: <4BEA2240.8030305@ufl.edu>
Message-ID: <4BEACAEE.1020305@u.washington.edu>


My preference would be to use MCMCglmm, which will fit an over-dispersed 
Poisson GLMM (ie, an extra observation-level random-effect is included 
to capture the over-dispersion).

If you specifically need to fit a negative-binomial mixed-effects 
model... then I don't have anything to add over the other's points.

cheers, Dave


David Zajanc wrote:
 > Hi,
 >
 >
 >
 > I am looking into ways to fit a negative binomial mixed effects model to
 > our data, but have not found any obvious methods in searching through
 > the archives of this list.  I noticed suggestions for using the
 > quasipoisson distribution, but our dataset appears better suited for the
 > negative binomial model, based on past analyses using GLM.  It appears
 > that "glmer" of package "lme4" is not currently capable of fitting a
 > negative binomial model, though please correct me if I'm wrong about
 > this.  Any feedback or suggestions would be welcomed.


-- 
Dave Atkins, PhD
Research Associate Professor
Department of Psychiatry and Behavioral Science
University of Washington
datkins at u.washington.edu

Center for the Study of Health and Risk Behaviors (CSHRB)		
1100 NE 45th Street, Suite 300 	
Seattle, WA  98105 	
206-616-3879 	
http://depts.washington.edu/cshrb/
(Mon-Wed)	

Center for Healthcare Improvement, for Addictions, Mental Illness,
   Medically Vulnerable Populations (CHAMMP)
325 9th Avenue, 2HH-15
Box 359911
Seattle, WA 98104?
206-897-4210
http://www.chammp.org
(Thurs)



From dzajanc at harveyecology.com  Thu May 13 19:57:54 2010
From: dzajanc at harveyecology.com (David Zajanc)
Date: Thu, 13 May 2010 10:57:54 -0700
Subject: [R-sig-ME] Negative binomial mixed effects modeling
In-Reply-To: <4BEA2240.8030305@ufl.edu>
Message-ID: <16DD87487289A44088D4991B7D9EA8B501EBCAA0@exchange.harvey.corp>

Thanks for the input to all who have replied.  Will mull these options
over with my colleagues before proceeding.

David

-----Original Message-----
From: Ben Bolker [mailto:bolker at ufl.edu] 
Sent: Tuesday, May 11, 2010 8:37 PM
To: David Zajanc
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Negative binomial mixed effects modeling

David Zajanc wrote:
> Hi,
> 
>  
> 
> I am looking into ways to fit a negative binomial mixed effects model
to
> our data, but have not found any obvious methods in searching through
> the archives of this list.  I noticed suggestions for using the
> quasipoisson distribution, but our dataset appears better suited for
the
> negative binomial model, based on past analyses using GLM.  It appears
> that "glmer" of package "lme4" is not currently capable of fitting a
> negative binomial model, though please correct me if I'm wrong about
> this.  Any feedback or suggestions would be welcomed.

  At the moment you need glmmADMB, or glmmBUGS, or R2WinBUGS, or AD
Model Builder, or ... see <http://glmm.wikidot.com/faq> for (not much)
more information.



From ken.knoblauch at inserm.fr  Fri May 14 17:58:13 2010
From: ken.knoblauch at inserm.fr (Ken Knoblauch)
Date: Fri, 14 May 2010 17:58:13 +0200
Subject: [R-sig-ME] Proportional odds model w/ random effects
Message-ID: <20100514175813.ytw47eh1344so88c@imp.inserm.fr>

Hi,

I've been looking at some data in which observers rated
pairs of images as being of siblings or not.  There
were 32 observers and 30 pairs of images, half of
which were of siblings.  Treating the ratings as ordinal responses,
I'm interested in fitting the data with a proportional odds model.
I would like to treat both Observer and Image pair as random effects.
I followed the recent discussion on the list on
proportional odds models with mixed-effects.
The clmm function from the ordinal package in the
current version only accepts 1 random effect, as far
as I can tell.  I have played with MCMCglmm a bit
but don't feel comfortable with my understanding (yet)
about how best to choose priors.  I put (hacked) together
a wrapper (see below) for glmer (or glm if there are no random effect
terms) that builds a model matrix for the fixed effects
part of the model which is combined with the random
effect terms before handing it over to glmer (or glm
if no random effects).  It has a lot of imperfections
but it seems to give results for the cutpoints,
predictors and standard errors that are systematically
close to those from polr from MASS (when there are no fixed
effects in the model) or clmm with one random effect and
reasonably otherwise.  I say  systematically close,
because they always  differ in the 2nd decimal place or so.
This may turn out to be an unimportant difference but I worry
because in the past, I've found glm and direct optimization
approaches to be more similar when things are set up right.
The deviances are quite different (usually by about a factor
of 2), but there may be more benign reasons for that (inclusion
of constants, etc.).
I would like to know if this is a reasonable approach or not,
I have played with convergence criteria and number of iterations
and have not found these to explain the differences.
I pasted in my code below for anyone interested and would be happy to
learn of its deficiencies (a few of which I'm already aware).

Thank you.

Ken

polmer <- function(formula, data, lnk = "logit",
	cor = FALSE, ...){
# Get fixed and random terms
	lTerms <- labels(terms(formula))
	rTerms <- sapply(lTerms, function(x){
		rT <- grep("|", x, fixed = TRUE)
		length(rT) > 0
		})
	ranTerms <- lTerms[rTerms]
	fixTerms <- lTerms[!rTerms]
	ranNames <- as.vector(sapply(ranTerms, function(x)
		strsplit(x, "\\| ")[[1]][2]
		))
	NoRanEff <- !(length(ranTerms) > 0)

# Make fixed-effect model matrix
	Resp <- ordered(data[[as.character(formula[[2]])]])
	Cuts <- seq(0, length(levels(Resp)) - 2)
	cumRat <- as.vector(sapply(Cuts,
		function(x) Resp <= x))
	fRat <- gl(length(Cuts), nrow(data),
		nrow(data) * length(Cuts))
	X <- model.matrix(~ fRat - 1)
	labs <- sapply(Cuts, function(x)
		paste(x, "|", x+1, sep = "")
		)
	colnames(X) <- labs
	fxForm <- if(!NoRanEff){
		tmp <- formula
		tmp[[2]] <- NULL
		while( any(xx <- sapply(tmp[[2]],
			inherits, what = "(" ))){
				RE <- which(xx)
				for(ix in RE) tmp[[2]][[ix]] <- NULL
				tmp[[2]] <- tmp[[2]][[2]]
		}
		tmp } else formula

	fX <- -model.matrix(fxForm, data)[, -1]
	fX <- kronecker(matrix(rep(1, length(Cuts)), nc = 1),
		 fX)
	X <- cbind(X, fX)
	colnames(X)[-seq(length(Cuts))] <- fixTerms
	p.df <- data.frame(cumRat = cumRat, X = X)
	names(p.df) <- c("cumRat", colnames(X))

# Make random-effect model vectors
	frm <- if(!NoRanEff){
		tmp <- sapply(seq_len(length(ranNames)),
			function(x)
				rep(data[[ranNames[x]]], 10))

		for(ix in seq_len(ncol(tmp)))
			assign(ranNames[ix], tmp[, ix])
		rxForm <- paste(paste("(", ranTerms, ")",
			sep = "", collapse = " + "), " - 1")
	as.formula(paste("cumRat ~ .  + ", rxForm))
	} else as.formula("cumRat ~ . - 1")

	res <- if (NoRanEff)
	  glm(frm, data = p.df,
	  	family =  binomial(lnk), ...) else
	  glmer(frm, data = p.df,
	  	family =  binomial(lnk), ...)
	if (inherits(res, "mer")) print(res, cor = cor) else
		print(res)
	invisible(res)
}


-- 
Ken Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html



From tahirajamil at yahoo.com  Mon May 17 12:38:21 2010
From: tahirajamil at yahoo.com (Tahira Jamil)
Date: Mon, 17 May 2010 03:38:21 -0700 (PDT)
Subject: [R-sig-ME] how to extract the BIC value
Message-ID: <755356.74318.qm@web113511.mail.gq1.yahoo.com>


Hi
I can extract the AIC value of a model like this

AIC(logLik(fm0)

How can I extract the BIC value if I need!

Cheers
Tahira 
Biometris 
Wageningen University



From andy.fugard at sbg.ac.at  Mon May 17 12:54:16 2010
From: andy.fugard at sbg.ac.at (Andy Fugard (Work))
Date: Mon, 17 May 2010 12:54:16 +0200
Subject: [R-sig-ME] how to extract the BIC value
In-Reply-To: <755356.74318.qm@web113511.mail.gq1.yahoo.com>
References: <755356.74318.qm@web113511.mail.gq1.yahoo.com>
Message-ID: <4BF12058.1020108@sbg.ac.at>

Greetings,

Assuming you're using lmer, here's an example which does what you need:

> (fm1    <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
Linear mixed model fit by REML
Formula: Reaction ~ Days + (Days | Subject)
   Data: sleepstudy
  AIC  BIC logLik deviance REMLdev
 1756 1775 -871.8     1752    1744
Random effects:
 Groups   Name        Variance Std.Dev. Corr
 Subject  (Intercept) 612.092  24.7405
          Days         35.072   5.9221  0.066
 Residual             654.941  25.5918
Number of obs: 180, groups: Subject, 18

Fixed effects:
            Estimate Std. Error t value
(Intercept)  251.405      6.825   36.84
Days          10.467      1.546    6.77

Correlation of Fixed Effects:
     (Intr)
Days -0.138

> (fm1fit <- summary(fm1)@AICtab)
      AIC      BIC    logLik deviance  REMLdev
 1755.628 1774.786 -871.8141 1751.986 1743.628

> fm1fit$BIC
[1] 1774.786

Cheers,

Andy


Tahira Jamil wrote:
> Hi
> I can extract the AIC value of a model like this
> 
> AIC(logLik(fm0)
> 
> How can I extract the BIC value if I need!
> 
> Cheers
> Tahira 
> Biometris 
> Wageningen University
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Andy Fugard, Postdoctoral researcher, ESF LogICCC project
"Modeling human inference within the framework of probability logic"
Department of Psychology, University of Salzburg, Austria
http://www.andyfugard.info



From bates at stat.wisc.edu  Mon May 17 15:29:07 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 17 May 2010 08:29:07 -0500
Subject: [R-sig-ME] how to extract the BIC value
In-Reply-To: <4BF12058.1020108@sbg.ac.at>
References: <755356.74318.qm@web113511.mail.gq1.yahoo.com>
	<4BF12058.1020108@sbg.ac.at>
Message-ID: <AANLkTikIEd8hiz01rMDahqycM5poFIYr7ZSYFyZrlWa0@mail.gmail.com>

On Mon, May 17, 2010 at 5:54 AM, Andy Fugard (Work)
<andy.fugard at sbg.ac.at> wrote:
> Greetings,
>
> Assuming you're using lmer, here's an example which does what you need:
>
>> (fm1 ? ?<- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
> Linear mixed model fit by REML
> Formula: Reaction ~ Days + (Days | Subject)
> ? Data: sleepstudy
> ?AIC ?BIC logLik deviance REMLdev
> ?1756 1775 -871.8 ? ? 1752 ? ?1744
> Random effects:
> ?Groups ? Name ? ? ? ?Variance Std.Dev. Corr
> ?Subject ?(Intercept) 612.092 ?24.7405
> ? ? ? ? ?Days ? ? ? ? 35.072 ? 5.9221 ?0.066
> ?Residual ? ? ? ? ? ? 654.941 ?25.5918
> Number of obs: 180, groups: Subject, 18
>
> Fixed effects:
> ? ? ? ? ? ?Estimate Std. Error t value
> (Intercept) ?251.405 ? ? ?6.825 ? 36.84
> Days ? ? ? ? ?10.467 ? ? ?1.546 ? ?6.77
>
> Correlation of Fixed Effects:
> ? ? (Intr)
> Days -0.138
>
>> (fm1fit <- summary(fm1)@AICtab)
> ? ? ?AIC ? ? ?BIC ? ?logLik deviance ?REMLdev
> ?1755.628 1774.786 -871.8141 1751.986 1743.628
>
>> fm1fit$BIC
> [1] 1774.786

That's one way of doing it but it relies on a particular
representation of the object returned by summary, and that is subject
to change.

I had thought that it would work to use

BIC(logLik(fm1))

but that doesn't because the BIC function is imported from the nlme
package but not later exported.  The situation is rather tricky - at
one point I defined a generic for BIC in the lme4 package but that led
to conflicts when multiple packages defined different versions.  The
order in which the packages were loaded became important in
determining which version was used.

We agreed to use the generic from the nlme package, which is what is
now done.  However, I don't want to make the entire nlme package
visible when you have loaded lme4 because of resulting conflicts.

I can get the result as

> (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
Linear mixed model fit by REML
Formula: Reaction ~ Days + (Days | Subject)
   Data: sleepstudy
  AIC  BIC logLik deviance REMLdev
 1756 1775 -871.8     1752    1744
Random effects:
 Groups   Name        Variance Std.Dev. Corr
 Subject  (Intercept) 612.090  24.7405
          Days         35.072   5.9221  0.066
 Residual             654.941  25.5918
Number of obs: 180, groups: Subject, 18

Fixed effects:
            Estimate Std. Error t value
(Intercept)  251.405      6.825   36.84
Days          10.467      1.546    6.77

Correlation of Fixed Effects:
     (Intr)
Days -0.138
> nlme:::BIC(logLik(fm1))
    REML
1774.786

but that is unintuitive.  I am not sure what the best approach is.
Perhaps Martin (or anyone else who knows namespace intricacies) can
suggest something.


> Tahira Jamil wrote:
>> Hi
>> I can extract the AIC value of a model like this
>>
>> AIC(logLik(fm0)
>>
>> How can I extract the BIC value if I need!
>>
>> Cheers
>> Tahira
>> Biometris
>> Wageningen University
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> --
> Andy Fugard, Postdoctoral researcher, ESF LogICCC project
> "Modeling human inference within the framework of probability logic"
> Department of Psychology, University of Salzburg, Austria
> http://www.andyfugard.info
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From ggrothendieck at gmail.com  Mon May 17 15:45:00 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 17 May 2010 09:45:00 -0400
Subject: [R-sig-ME] how to extract the BIC value
In-Reply-To: <AANLkTikIEd8hiz01rMDahqycM5poFIYr7ZSYFyZrlWa0@mail.gmail.com>
References: <755356.74318.qm@web113511.mail.gq1.yahoo.com> 
	<4BF12058.1020108@sbg.ac.at>
	<AANLkTikIEd8hiz01rMDahqycM5poFIYr7ZSYFyZrlWa0@mail.gmail.com>
Message-ID: <AANLkTiluh9FUnMWdfArmI7yGSUDRGmv_rngc_qztvmL5@mail.gmail.com>

BIC seems like something that would logically go into stats in the
core of R, as AIC is already, and then various packages could define
methods for it.

On Mon, May 17, 2010 at 9:29 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
> On Mon, May 17, 2010 at 5:54 AM, Andy Fugard (Work)
> <andy.fugard at sbg.ac.at> wrote:
>> Greetings,
>>
>> Assuming you're using lmer, here's an example which does what you need:
>>
>>> (fm1 ? ?<- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
>> Linear mixed model fit by REML
>> Formula: Reaction ~ Days + (Days | Subject)
>> ? Data: sleepstudy
>> ?AIC ?BIC logLik deviance REMLdev
>> ?1756 1775 -871.8 ? ? 1752 ? ?1744
>> Random effects:
>> ?Groups ? Name ? ? ? ?Variance Std.Dev. Corr
>> ?Subject ?(Intercept) 612.092 ?24.7405
>> ? ? ? ? ?Days ? ? ? ? 35.072 ? 5.9221 ?0.066
>> ?Residual ? ? ? ? ? ? 654.941 ?25.5918
>> Number of obs: 180, groups: Subject, 18
>>
>> Fixed effects:
>> ? ? ? ? ? ?Estimate Std. Error t value
>> (Intercept) ?251.405 ? ? ?6.825 ? 36.84
>> Days ? ? ? ? ?10.467 ? ? ?1.546 ? ?6.77
>>
>> Correlation of Fixed Effects:
>> ? ? (Intr)
>> Days -0.138
>>
>>> (fm1fit <- summary(fm1)@AICtab)
>> ? ? ?AIC ? ? ?BIC ? ?logLik deviance ?REMLdev
>> ?1755.628 1774.786 -871.8141 1751.986 1743.628
>>
>>> fm1fit$BIC
>> [1] 1774.786
>
> That's one way of doing it but it relies on a particular
> representation of the object returned by summary, and that is subject
> to change.
>
> I had thought that it would work to use
>
> BIC(logLik(fm1))
>
> but that doesn't because the BIC function is imported from the nlme
> package but not later exported. ?The situation is rather tricky - at
> one point I defined a generic for BIC in the lme4 package but that led
> to conflicts when multiple packages defined different versions. ?The
> order in which the packages were loaded became important in
> determining which version was used.
>
> We agreed to use the generic from the nlme package, which is what is
> now done. ?However, I don't want to make the entire nlme package
> visible when you have loaded lme4 because of resulting conflicts.
>
> I can get the result as
>
>> (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
> Linear mixed model fit by REML
> Formula: Reaction ~ Days + (Days | Subject)
> ? Data: sleepstudy
> ?AIC ?BIC logLik deviance REMLdev
> ?1756 1775 -871.8 ? ? 1752 ? ?1744
> Random effects:
> ?Groups ? Name ? ? ? ?Variance Std.Dev. Corr
> ?Subject ?(Intercept) 612.090 ?24.7405
> ? ? ? ? ?Days ? ? ? ? 35.072 ? 5.9221 ?0.066
> ?Residual ? ? ? ? ? ? 654.941 ?25.5918
> Number of obs: 180, groups: Subject, 18
>
> Fixed effects:
> ? ? ? ? ? ?Estimate Std. Error t value
> (Intercept) ?251.405 ? ? ?6.825 ? 36.84
> Days ? ? ? ? ?10.467 ? ? ?1.546 ? ?6.77
>
> Correlation of Fixed Effects:
> ? ? (Intr)
> Days -0.138
>> nlme:::BIC(logLik(fm1))
> ? ?REML
> 1774.786
>
> but that is unintuitive. ?I am not sure what the best approach is.
> Perhaps Martin (or anyone else who knows namespace intricacies) can
> suggest something.
>
>
>> Tahira Jamil wrote:
>>> Hi
>>> I can extract the AIC value of a model like this
>>>
>>> AIC(logLik(fm0)
>>>
>>> How can I extract the BIC value if I need!
>>>
>>> Cheers
>>> Tahira
>>> Biometris
>>> Wageningen University
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>> --
>> Andy Fugard, Postdoctoral researcher, ESF LogICCC project
>> "Modeling human inference within the framework of probability logic"
>> Department of Psychology, University of Salzburg, Austria
>> http://www.andyfugard.info
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From J.A.Etzel at med.umcg.nl  Mon May 17 15:50:40 2010
From: J.A.Etzel at med.umcg.nl (J.A. Etzel)
Date: Mon, 17 May 2010 15:50:40 +0200
Subject: [R-sig-ME] strategy for interpreting significant interactions
Message-ID: <4BF149B0.4070708@med.umcg.nl>

Good afternoon,

I think of myself as knowing enough about mixed models ?to be 
dangerous?, but certainly not an expert. In a recent manuscript I used 
mixed models, and a reviewer?s comment has me confused; I hope that 
someone on this list may be able to point me in the right direction. My 
understanding is that it is not proper to interpret main effects that 
are present in a significant interaction, but rather that elements of 
the interaction should be held constant so the others can be examined in 
a sensible manner:


my text:
As expected, many significant interactions are present in the data. The 
five-way interaction was not significant, nor were any of the four-way 
interactions. All five factors (tc, d, ds, p, s) are involved in at 
least one three-way interaction: tc interacts with d and ds, p, and s; s 
and d also interact with ds. In these [linear mixed] models it is not 
possible to interpret main effects or lower-order interactions when 
higher-order interactions are present, so no attempt will be made to do 
so here. Instead, additional models with certain factors held constant 
were constructed to characterize the interactions and allow 
interpretation of the effects.

reviewer?s comment:
The authors argue that "interpretation of main effects is not possible 
in the presence of significant interactions". This statement is only 
one-third true. Indeed, main effects must not be interpreted in the 
presence of disordinal interactions. However, in the case of 
semi-disordinal interactions one main effect can be interpreted and in 
the case of ordinal interactions even both main effects can be 
interpreted. Thus, for every interaction the authors have to qualify the 
type of interaction in order to decide whether or not the main effects 
can be interpreted.


Is my text/the strategy I followed correct? If so, do you have any 
suggestions for references to use in the response to reviewers on this 
point? I have had a surprising (to me!) amount of difficulty finding 
references detailing what should be done in the face of significant 
interactions.

Thanks for your help!
Jo Etzel



From julien.beguin.1 at ulaval.ca  Mon May 17 17:44:14 2010
From: julien.beguin.1 at ulaval.ca (Julien Beguin)
Date: Mon, 17 May 2010 11:44:14 -0400
Subject: [R-sig-ME] RE : strategy for interpreting significant interactions
In-Reply-To: <4BF149B0.4070708@med.umcg.nl>
References: <4BF149B0.4070708@med.umcg.nl>
Message-ID: <B56D7C27B4408243B93FBC46ABECB5A0011A85A9D290@EXCH-MBX-F.ulaval.ca>

I think that the reviewer's comment saying that you need to "qualify the
type of interaction in order to decide whether or not the main effects
can be interpreted" means that you need to establish that you have interval or ratio data because 
an apparent interaction could be an artifact of ordinal scale measurement. 

Have a look at this link:
http://www.markwebtest.netfirms.com/Appendix/WebAppOrdinalInteraction/WebAppOrdinalInteractions.htm

Julien Beguin 
________________________________________
De : r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] de la part de J.A. Etzel [J.A.Etzel at med.umcg.nl]
Date d'envoi : 17 mai 2010 09:50
? : r-sig-mixed-models at r-project.org
Objet : [R-sig-ME] strategy for interpreting significant interactions

Good afternoon,

I think of myself as knowing enough about mixed models ?to be
dangerous?, but certainly not an expert. In a recent manuscript I used
mixed models, and a reviewer?s comment has me confused; I hope that
someone on this list may be able to point me in the right direction. My
understanding is that it is not proper to interpret main effects that
are present in a significant interaction, but rather that elements of
the interaction should be held constant so the others can be examined in
a sensible manner:


my text:
As expected, many significant interactions are present in the data. The
five-way interaction was not significant, nor were any of the four-way
interactions. All five factors (tc, d, ds, p, s) are involved in at
least one three-way interaction: tc interacts with d and ds, p, and s; s
and d also interact with ds. In these [linear mixed] models it is not
possible to interpret main effects or lower-order interactions when
higher-order interactions are present, so no attempt will be made to do
so here. Instead, additional models with certain factors held constant
were constructed to characterize the interactions and allow
interpretation of the effects.

reviewer?s comment:
The authors argue that "interpretation of main effects is not possible
in the presence of significant interactions". This statement is only
one-third true. Indeed, main effects must not be interpreted in the
presence of disordinal interactions. However, in the case of
semi-disordinal interactions one main effect can be interpreted and in
the case of ordinal interactions even both main effects can be
interpreted. Thus, for every interaction the authors have to qualify the
type of interaction in order to decide whether or not the main effects
can be interpreted.


Is my text/the strategy I followed correct? If so, do you have any
suggestions for references to use in the response to reviewers on this
point? I have had a surprising (to me!) amount of difficulty finding
references detailing what should be done in the face of significant
interactions.

Thanks for your help!
Jo Etzel

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From Thierry.ONKELINX at inbo.be  Tue May 18 10:54:26 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 18 May 2010 10:54:26 +0200
Subject: [R-sig-ME] strategy for interpreting significant interactions
In-Reply-To: <4BF149B0.4070708@med.umcg.nl>
References: <4BF149B0.4070708@med.umcg.nl>
Message-ID: <2E9C414912813E4EB981326983E0A104072D05EE@inboexch.inbo.be>

Dear Jo,

In case that at most one variable in an interaction is continuous, you
can give *some* interpretation on the main effects and lower order
interactions. But you have to be very carefull on the interpretation.
Suppose you have two factors: Var1 with levels A, B and C. Var2 with
levels x, y and z. Then below you have the interpretation of the
parameters from the model Var1*Var2

Intercept = level Ax
Var1:B = level Bx
Var1:C = level Cx
Var2:y = level Ay
Var2:z = level Az
Var1:Var2:B:y = level By
Var1:Var2:C:y = level Cy
...

Note that the 'main effects' does not yield the marginal effect of a
level, but the effect conditional on the reference level of the other
variables.

HTH,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens J.A. Etzel
> Verzonden: maandag 17 mei 2010 15:51
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] strategy for interpreting significant
> interactions
> 
> Good afternoon,
> 
> I think of myself as knowing enough about mixed models "to be 
> dangerous", but certainly not an expert. In a recent
> manuscript I used mixed models, and a reviewer's comment has 
> me confused; I hope that someone on this list may be able to 
> point me in the right direction. My understanding is that it 
> is not proper to interpret main effects that are present in a 
> significant interaction, but rather that elements of the 
> interaction should be held constant so the others can be 
> examined in a sensible manner:
> 
> 
> my text:
> As expected, many significant interactions are present in the 
> data. The five-way interaction was not significant, nor were 
> any of the four-way interactions. All five factors (tc, d, 
> ds, p, s) are involved in at least one three-way interaction: 
> tc interacts with d and ds, p, and s; s and d also interact 
> with ds. In these [linear mixed] models it is not possible to 
> interpret main effects or lower-order interactions when
> higher-order interactions are present, so no attempt will be 
> made to do so here. Instead, additional models with certain 
> factors held constant were constructed to characterize the 
> interactions and allow interpretation of the effects.
> 
> reviewer's comment:
> The authors argue that "interpretation of main effects is not 
> possible in the presence of significant interactions". This 
> statement is only one-third true. Indeed, main effects must 
> not be interpreted in the presence of disordinal 
> interactions. However, in the case of semi-disordinal 
> interactions one main effect can be interpreted and in the 
> case of ordinal interactions even both main effects can be 
> interpreted. Thus, for every interaction the authors have to 
> qualify the type of interaction in order to decide whether or 
> not the main effects can be interpreted.
> 
> 
> Is my text/the strategy I followed correct? If so, do you 
> have any suggestions for references to use in the response to 
> reviewers on this point? I have had a surprising (to me!) 
> amount of difficulty finding references detailing what should 
> be done in the face of significant interactions.
> 
> Thanks for your help!
> Jo Etzel
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From S.L.Frank at uva.nl  Tue May 18 12:20:00 2010
From: S.L.Frank at uva.nl (Stefan Frank)
Date: Tue, 18 May 2010 12:20:00 +0200
Subject: [R-sig-ME] Error "mu[i] must be positive" with Gamma family
Message-ID: <4BF269D0.5010709@uva.nl>

Hi,

I'm trying to fit a LMER to Gamma distributed data using the identity 
link function, but keep running into the problem that a negative mean is 
estimated:

 > lmer(y~x+(1|s), data, family=Gamma(link="identity"), verbose=TRUE)
   0:     303489.72: 0.0118042  5.95694 -0.0360192
   1:     206240.18: 0.990220  6.16357 -0.0381219
Error in mer_finalize(ans) :
   mu[i] must be positive: mu = 2.63294e-309, i = 1788870688


Fitting a GLM works fine. I tried taking its coefficients as start 
values for the LMER, but that made no difference:

 > m <- glm(y~x, data, family=Gamma(link="identity"))
 > lmer(y~x+(1|s), data, family=Gamma(link="identity"), 
start=coefficients(m), verbose=TRUE)
   0:     303489.72: 0.0118042  5.95694 -0.0360192
   1:     206240.18: 0.990220  6.16357 -0.0381219
Error in mer_finalize(ans) :
   mu[i] must be positive: mu = 2.63293e-309, i = 1778647072


What could be going on, and what can I do about it?

R version 2.9.2 (2009-08-24) on Windows
lme4 version 0.999375-32


Best,

Stefan Frank
Institute for Logic, Language and Computation
University of Amsterdam
URL: staff.science.uva.nl/~sfrank
Tel: +31 20 5256054

Visiting address:                    Postal address:
Science Park 904, Room C3.123        P.O. Box 94242
Amsterdam                            1090 GE Amsterdam
The Netherlands                      The Netherlands



From maechler at stat.math.ethz.ch  Tue May 18 12:37:21 2010
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 18 May 2010 12:37:21 +0200
Subject: [R-sig-ME] how to extract the BIC value
In-Reply-To: <AANLkTiluh9FUnMWdfArmI7yGSUDRGmv_rngc_qztvmL5@mail.gmail.com>
References: <755356.74318.qm@web113511.mail.gq1.yahoo.com>
	<4BF12058.1020108@sbg.ac.at>
	<AANLkTikIEd8hiz01rMDahqycM5poFIYr7ZSYFyZrlWa0@mail.gmail.com>
	<AANLkTiluh9FUnMWdfArmI7yGSUDRGmv_rngc_qztvmL5@mail.gmail.com>
Message-ID: <19442.28129.658401.419154@lynne.math.ethz.ch>

>>>>> "GaGr" == Gabor Grothendieck <ggrothendieck at gmail.com>
>>>>>     on Mon, 17 May 2010 09:45:00 -0400 writes:

    GaGr> BIC seems like something that would logically go into stats in the
    GaGr> core of R, as AIC is already, and then various packages could define
    GaGr> methods for it.

Well, if you look at help(AIC):

 > Usage:

 >     AIC(object, ..., k = 2)

 > Arguments:

 >   object: a fitted model object, for which there exists a ?logLik?
 >           method to extract the corresponding log-likelihood, or an
 >           object inheriting from class ?logLik?.

 >      ...: optionally more fitted model objects.

 >        k: numeric, the _penalty_ per parameter to be used; the default
 >           ?k = 2? is the classical AIC.

you may note that the original authors of AIC where always
allowing the AIC() function (and its methods) to compute the BIC,
simply by using 'k = log(n)' where of course n  must be correct.

I do like the concept that BIC is just a variation of AIC and
AFAIK, AIC was really first (historically).

Typically (and with lme4), the 'n' needed is already part of the logLik()
attributes :

> AIC((ll <- logLik(fm1)), k = log(attr(ll,"nobs")))
    REML 
1774.786 

indeed gives the BIC (where the "REML" name may or may not be a
bit overkill)

A stats-package based  BIC function could then simply be defined as

BIC <- function (object, ...) UseMethod("BIC")
BIC.default <- function (object, ...) 
     BIC(logLik(object), ...)
BIC.logLik <- function (object, ...) 
     AIC(object, ..., k = log(attr(object,"nobs")))


--
Martin Maechler, ETH Zurich

    GaGr> On Mon, May 17, 2010 at 9:29 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
    >> On Mon, May 17, 2010 at 5:54 AM, Andy Fugard (Work)
    >> <andy.fugard at sbg.ac.at> wrote:
    >>> Greetings,
    >>> 
    >>> Assuming you're using lmer, here's an example which does what you need:
    >>> 
    >>>> (fm1 ? ?<- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
    >>> Linear mixed model fit by REML
    >>> Formula: Reaction ~ Days + (Days | Subject)
    >>> ? Data: sleepstudy
    >>> ?AIC ?BIC logLik deviance REMLdev
    >>> ?1756 1775 -871.8 ? ? 1752 ? ?1744
    >>> Random effects:
    >>> ?Groups ? Name ? ? ? ?Variance Std.Dev. Corr
    >>> ?Subject ?(Intercept) 612.092 ?24.7405
    >>> ? ? ? ? ?Days ? ? ? ? 35.072 ? 5.9221 ?0.066
    >>> ?Residual ? ? ? ? ? ? 654.941 ?25.5918
    >>> Number of obs: 180, groups: Subject, 18
    >>> 
    >>> Fixed effects:
    >>> ? ? ? ? ? ?Estimate Std. Error t value
    >>> (Intercept) ?251.405 ? ? ?6.825 ? 36.84
    >>> Days ? ? ? ? ?10.467 ? ? ?1.546 ? ?6.77
    >>> 
    >>> Correlation of Fixed Effects:
    >>> ? ? (Intr)
    >>> Days -0.138
    >>> 
    >>>> (fm1fit <- summary(fm1)@AICtab)
    >>> ? ? ?AIC ? ? ?BIC ? ?logLik deviance ?REMLdev
    >>> ?1755.628 1774.786 -871.8141 1751.986 1743.628
    >>> 
    >>>> fm1fit$BIC
    >>> [1] 1774.786
    >> 
    >> That's one way of doing it but it relies on a particular
    >> representation of the object returned by summary, and that is subject
    >> to change.
    >> 
    >> I had thought that it would work to use
    >> 
    >> BIC(logLik(fm1))
    >> 
    >> but that doesn't because the BIC function is imported from the nlme
    >> package but not later exported. ?The situation is rather tricky - at
    >> one point I defined a generic for BIC in the lme4 package but that led
    >> to conflicts when multiple packages defined different versions. ?The
    >> order in which the packages were loaded became important in
    >> determining which version was used.
    >> 
    >> We agreed to use the generic from the nlme package, which is what is
    >> now done. ?However, I don't want to make the entire nlme package
    >> visible when you have loaded lme4 because of resulting conflicts.
    >> 
    >> I can get the result as
    >> 
    >>> (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
    >> Linear mixed model fit by REML
    >> Formula: Reaction ~ Days + (Days | Subject)
    >> ? Data: sleepstudy
    >> ?AIC ?BIC logLik deviance REMLdev
    >> ?1756 1775 -871.8 ? ? 1752 ? ?1744
    >> Random effects:
    >> ?Groups ? Name ? ? ? ?Variance Std.Dev. Corr
    >> ?Subject ?(Intercept) 612.090 ?24.7405
    >> ? ? ? ? ?Days ? ? ? ? 35.072 ? 5.9221 ?0.066
    >> ?Residual ? ? ? ? ? ? 654.941 ?25.5918
    >> Number of obs: 180, groups: Subject, 18
    >> 
    >> Fixed effects:
    >> ? ? ? ? ? ?Estimate Std. Error t value
    >> (Intercept) ?251.405 ? ? ?6.825 ? 36.84
    >> Days ? ? ? ? ?10.467 ? ? ?1.546 ? ?6.77
    >> 
    >> Correlation of Fixed Effects:
    >> ? ? (Intr)
    >> Days -0.138
    >>> nlme:::BIC(logLik(fm1))
    >> ? ?REML
    >> 1774.786
    >> 
    >> but that is unintuitive. ?I am not sure what the best approach is.
    >> Perhaps Martin (or anyone else who knows namespace intricacies) can
    >> suggest something.
    >> 
    >> 
    >>> Tahira Jamil wrote:
    >>>> Hi
    >>>> I can extract the AIC value of a model like this
    >>>> 
    >>>> AIC(logLik(fm0)
    >>>> 
    >>>> How can I extract the BIC value if I need!
    >>>> 
    >>>> Cheers
    >>>> Tahira
    >>>> Biometris
    >>>> Wageningen University
    >>>> 
    >>>> _______________________________________________
    >>>> R-sig-mixed-models at r-project.org mailing list
    >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    >>> 
    >>> 
    >>> --
    >>> Andy Fugard, Postdoctoral researcher, ESF LogICCC project
    >>> "Modeling human inference within the framework of probability logic"
    >>> Department of Psychology, University of Salzburg, Austria
    >>> http://www.andyfugard.info
    >>> 
    >>> _______________________________________________
    >>> R-sig-mixed-models at r-project.org mailing list
    >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    >>> 
    >> 
    >> _______________________________________________
    >> R-sig-mixed-models at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    >> 

    GaGr> _______________________________________________
    GaGr> R-sig-mixed-models at r-project.org mailing list
    GaGr> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From maechler at stat.math.ethz.ch  Tue May 18 13:05:27 2010
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 18 May 2010 13:05:27 +0200
Subject: [R-sig-ME] BIC() in "stats"  {was  how to extract the BIC value}
In-Reply-To: <19442.28129.658401.419154@lynne.math.ethz.ch>
References: <755356.74318.qm@web113511.mail.gq1.yahoo.com>
	<4BF12058.1020108@sbg.ac.at>
	<AANLkTikIEd8hiz01rMDahqycM5poFIYr7ZSYFyZrlWa0@mail.gmail.com>
	<AANLkTiluh9FUnMWdfArmI7yGSUDRGmv_rngc_qztvmL5@mail.gmail.com>
	<19442.28129.658401.419154@lynne.math.ethz.ch>
Message-ID: <19442.29815.854237.706135@lynne.math.ethz.ch>

>>>>> "MM" == Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Tue, 18 May 2010 12:37:21 +0200 writes:

>>>>> "GaGr" == Gabor Grothendieck <ggrothendieck at gmail.com>
>>>>>     on Mon, 17 May 2010 09:45:00 -0400 writes:

    GaGr> BIC seems like something that would logically go into stats in the
    GaGr> core of R, as AIC is already, and then various packages could define
    GaGr> methods for it.

    MM> Well, if you look at help(AIC):

    >> Usage:

    >> AIC(object, ..., k = 2)

    >> Arguments:

    >> object: a fitted model object, for which there exists a ?logLik?
    >> method to extract the corresponding log-likelihood, or an
    >> object inheriting from class ?logLik?.

    >> ...: optionally more fitted model objects.

    >> k: numeric, the _penalty_ per parameter to be used; the default
    >> ?k = 2? is the classical AIC.

    MM> you may note that the original authors of AIC where always
    MM> allowing the AIC() function (and its methods) to compute the BIC,
    MM> simply by using 'k = log(n)' where of course n  must be correct.

    MM> I do like the concept that BIC is just a variation of AIC and
    MM> AFAIK, AIC was really first (historically).

    MM> Typically (and with lme4), the 'n' needed is already part of the logLik()
    MM> attributes :

    >> AIC((ll <- logLik(fm1)), k = log(attr(ll,"nobs")))
    MM> REML 
    MM> 1774.786 

    MM> indeed gives the BIC (where the "REML" name may or may not be a
    MM> bit overkill)


    MM> A stats-package based  BIC function could then simply be defined as

    > BIC <- function (object, ...) UseMethod("BIC")

    > BIC.default <- function (object, ...) BIC(logLik(object), ...)

    > BIC.logLik <- function (object, ...) 
    >    AIC(object, ..., k = log(attr(object,"nobs")))

 {well, modulo the fact that "..." should really allow to do
  this for *several* models simultaneously}

In addition to that (and more replying to Doug Bates):

Given nlme's tradition of explicitly providing BIC(), and in
analogue to the S3 semantics of the AIC() methods,

- I think lme4 (and "lme4a" on R-forge) should end up having
  working  AIC() and BIC() directly for fitted models, instead of
  having to use
	 AIC(logLik(.))   and    BIC(logLik(.))

  The reason that even the first of this currently does *not*
  work is that lme4 imports AIC from "stats" but should do so
  from "stats4".
  --> I'm about to change that for 'lme4' (and 'lme4a').
    
  However, for the BIC case, ... see below


- I tend to agree with Gabor (for once! :-)  that
  basic BIC methods (S3, alas) should move from  nlme to stats.
  
  For this reason, I'm breaking the rule of "do not cross-post"
  for once, and am hereby diverting this thread to R-devel

Martin


    MM> --
    MM> Martin Maechler, ETH Zurich

    GaGr> On Mon, May 17, 2010 at 9:29 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
    >>> On Mon, May 17, 2010 at 5:54 AM, Andy Fugard (Work)
    >>> <andy.fugard at sbg.ac.at> wrote:
    >>>> Greetings,
    >>>> 
    >>>> Assuming you're using lmer, here's an example which does what you need:
    >>>> 
    >>>>> (fm1 ? ?<- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
    >>>> Linear mixed model fit by REML
    >>>> Formula: Reaction ~ Days + (Days | Subject)
    >>>> ? Data: sleepstudy
    >>>> ?AIC ?BIC logLik deviance REMLdev
    >>>> ?1756 1775 -871.8 ? ? 1752 ? ?1744
    >>>> Random effects:
    >>>> ?Groups ? Name ? ? ? ?Variance Std.Dev. Corr
    >>>> ?Subject ?(Intercept) 612.092 ?24.7405
    >>>> ? ? ? ? ?Days ? ? ? ? 35.072 ? 5.9221 ?0.066
    >>>> ?Residual ? ? ? ? ? ? 654.941 ?25.5918
    >>>> Number of obs: 180, groups: Subject, 18
    >>>> 
    >>>> Fixed effects:
    >>>> ? ? ? ? ? ?Estimate Std. Error t value
    >>>> (Intercept) ?251.405 ? ? ?6.825 ? 36.84
    >>>> Days ? ? ? ? ?10.467 ? ? ?1.546 ? ?6.77
    >>>> 
    >>>> Correlation of Fixed Effects:
    >>>> ? ? (Intr)
    >>>> Days -0.138
    >>>> 
    >>>>> (fm1fit <- summary(fm1)@AICtab)
    >>>> ? ? ?AIC ? ? ?BIC ? ?logLik deviance ?REMLdev
    >>>> ?1755.628 1774.786 -871.8141 1751.986 1743.628
    >>>> 
    >>>>> fm1fit$BIC
    >>>> [1] 1774.786
    >>> 
    >>> That's one way of doing it but it relies on a particular
    >>> representation of the object returned by summary, and that is subject
    >>> to change.
    >>> 
    >>> I had thought that it would work to use
    >>> 
    >>> BIC(logLik(fm1))
    >>> 
    >>> but that doesn't because the BIC function is imported from the nlme
    >>> package but not later exported. ?The situation is rather tricky - at
    >>> one point I defined a generic for BIC in the lme4 package but that led
    >>> to conflicts when multiple packages defined different versions. ?The
    >>> order in which the packages were loaded became important in
    >>> determining which version was used.
    >>> 
    >>> We agreed to use the generic from the nlme package, which is what is
    >>> now done. ?However, I don't want to make the entire nlme package
    >>> visible when you have loaded lme4 because of resulting conflicts.
    >>> 
    >>> I can get the result as
    >>> 
    >>>> (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
    >>> Linear mixed model fit by REML
    >>> Formula: Reaction ~ Days + (Days | Subject)
    >>> ? Data: sleepstudy
    >>> ?AIC ?BIC logLik deviance REMLdev
    >>> ?1756 1775 -871.8 ? ? 1752 ? ?1744
    >>> Random effects:
    >>> ?Groups ? Name ? ? ? ?Variance Std.Dev. Corr
    >>> ?Subject ?(Intercept) 612.090 ?24.7405
    >>> ? ? ? ? ?Days ? ? ? ? 35.072 ? 5.9221 ?0.066
    >>> ?Residual ? ? ? ? ? ? 654.941 ?25.5918
    >>> Number of obs: 180, groups: Subject, 18
    >>> 
    >>> Fixed effects:
    >>> ? ? ? ? ? ?Estimate Std. Error t value
    >>> (Intercept) ?251.405 ? ? ?6.825 ? 36.84
    >>> Days ? ? ? ? ?10.467 ? ? ?1.546 ? ?6.77
    >>> 
    >>> Correlation of Fixed Effects:
    >>> ? ? (Intr)
    >>> Days -0.138
    >>>> nlme:::BIC(logLik(fm1))
    >>> ? ?REML
    >>> 1774.786
    >>> 
    >>> but that is unintuitive. ?I am not sure what the best approach is.
    >>> Perhaps Martin (or anyone else who knows namespace intricacies) can
    >>> suggest something.
    >>> 
    >>> 
    >>>> Tahira Jamil wrote:
    >>>>> Hi
    >>>>> I can extract the AIC value of a model like this
    >>>>> 
    >>>>> AIC(logLik(fm0)
    >>>>> 
    >>>>> How can I extract the BIC value if I need!
    >>>>> 
    >>>>> Cheers
    >>>>> Tahira
    >>>>> Biometris
    >>>>> Wageningen University
    >>>>> 
    >>>>> _______________________________________________
    >>>>> R-sig-mixed-models at r-project.org mailing list
    >>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    >>>> 
    >>>> 
    >>>> --
    >>>> Andy Fugard, Postdoctoral researcher, ESF LogICCC project
    >>>> "Modeling human inference within the framework of probability logic"
    >>>> Department of Psychology, University of Salzburg, Austria
    >>>> http://www.andyfugard.info
    >>>>



From ggrothendieck at gmail.com  Tue May 18 14:12:55 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 18 May 2010 08:12:55 -0400
Subject: [R-sig-ME] how to extract the BIC value
In-Reply-To: <AANLkTiluh9FUnMWdfArmI7yGSUDRGmv_rngc_qztvmL5@mail.gmail.com>
References: <755356.74318.qm@web113511.mail.gq1.yahoo.com> 
	<4BF12058.1020108@sbg.ac.at>
	<AANLkTikIEd8hiz01rMDahqycM5poFIYr7ZSYFyZrlWa0@mail.gmail.com> 
	<AANLkTiluh9FUnMWdfArmI7yGSUDRGmv_rngc_qztvmL5@mail.gmail.com>
Message-ID: <AANLkTilj2bAUrXslbN3EjkXnXLc97BbBxjiGv0r5Y9Bv@mail.gmail.com>

Another possibility would be for AIC methods to define AIC(,.., k =
"BIC") or AIC(..., method = "BIC").

This would not require any change to stats but to encourage
standardization it would be best if stats did define this for existing
AIC methods in stats.

On Mon, May 17, 2010 at 9:45 AM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
> BIC seems like something that would logically go into stats in the
> core of R, as AIC is already, and then various packages could define
> methods for it.
>
> On Mon, May 17, 2010 at 9:29 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
>> On Mon, May 17, 2010 at 5:54 AM, Andy Fugard (Work)
>> <andy.fugard at sbg.ac.at> wrote:
>>> Greetings,
>>>
>>> Assuming you're using lmer, here's an example which does what you need:
>>>
>>>> (fm1 ? ?<- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
>>> Linear mixed model fit by REML
>>> Formula: Reaction ~ Days + (Days | Subject)
>>> ? Data: sleepstudy
>>> ?AIC ?BIC logLik deviance REMLdev
>>> ?1756 1775 -871.8 ? ? 1752 ? ?1744
>>> Random effects:
>>> ?Groups ? Name ? ? ? ?Variance Std.Dev. Corr
>>> ?Subject ?(Intercept) 612.092 ?24.7405
>>> ? ? ? ? ?Days ? ? ? ? 35.072 ? 5.9221 ?0.066
>>> ?Residual ? ? ? ? ? ? 654.941 ?25.5918
>>> Number of obs: 180, groups: Subject, 18
>>>
>>> Fixed effects:
>>> ? ? ? ? ? ?Estimate Std. Error t value
>>> (Intercept) ?251.405 ? ? ?6.825 ? 36.84
>>> Days ? ? ? ? ?10.467 ? ? ?1.546 ? ?6.77
>>>
>>> Correlation of Fixed Effects:
>>> ? ? (Intr)
>>> Days -0.138
>>>
>>>> (fm1fit <- summary(fm1)@AICtab)
>>> ? ? ?AIC ? ? ?BIC ? ?logLik deviance ?REMLdev
>>> ?1755.628 1774.786 -871.8141 1751.986 1743.628
>>>
>>>> fm1fit$BIC
>>> [1] 1774.786
>>
>> That's one way of doing it but it relies on a particular
>> representation of the object returned by summary, and that is subject
>> to change.
>>
>> I had thought that it would work to use
>>
>> BIC(logLik(fm1))
>>
>> but that doesn't because the BIC function is imported from the nlme
>> package but not later exported. ?The situation is rather tricky - at
>> one point I defined a generic for BIC in the lme4 package but that led
>> to conflicts when multiple packages defined different versions. ?The
>> order in which the packages were loaded became important in
>> determining which version was used.
>>
>> We agreed to use the generic from the nlme package, which is what is
>> now done. ?However, I don't want to make the entire nlme package
>> visible when you have loaded lme4 because of resulting conflicts.
>>
>> I can get the result as
>>
>>> (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
>> Linear mixed model fit by REML
>> Formula: Reaction ~ Days + (Days | Subject)
>> ? Data: sleepstudy
>> ?AIC ?BIC logLik deviance REMLdev
>> ?1756 1775 -871.8 ? ? 1752 ? ?1744
>> Random effects:
>> ?Groups ? Name ? ? ? ?Variance Std.Dev. Corr
>> ?Subject ?(Intercept) 612.090 ?24.7405
>> ? ? ? ? ?Days ? ? ? ? 35.072 ? 5.9221 ?0.066
>> ?Residual ? ? ? ? ? ? 654.941 ?25.5918
>> Number of obs: 180, groups: Subject, 18
>>
>> Fixed effects:
>> ? ? ? ? ? ?Estimate Std. Error t value
>> (Intercept) ?251.405 ? ? ?6.825 ? 36.84
>> Days ? ? ? ? ?10.467 ? ? ?1.546 ? ?6.77
>>
>> Correlation of Fixed Effects:
>> ? ? (Intr)
>> Days -0.138
>>> nlme:::BIC(logLik(fm1))
>> ? ?REML
>> 1774.786
>>
>> but that is unintuitive. ?I am not sure what the best approach is.
>> Perhaps Martin (or anyone else who knows namespace intricacies) can
>> suggest something.
>>
>>
>>> Tahira Jamil wrote:
>>>> Hi
>>>> I can extract the AIC value of a model like this
>>>>
>>>> AIC(logLik(fm0)
>>>>
>>>> How can I extract the BIC value if I need!
>>>>
>>>> Cheers
>>>> Tahira
>>>> Biometris
>>>> Wageningen University
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>> --
>>> Andy Fugard, Postdoctoral researcher, ESF LogICCC project
>>> "Modeling human inference within the framework of probability logic"
>>> Department of Psychology, University of Salzburg, Austria
>>> http://www.andyfugard.info
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>



From J.A.Etzel at med.umcg.nl  Tue May 18 09:46:11 2010
From: J.A.Etzel at med.umcg.nl (J.A. Etzel)
Date: Tue, 18 May 2010 09:46:11 +0200
Subject: [R-sig-ME] strategy for interpreting significant interactions
In-Reply-To: <B56D7C27B4408243B93FBC46ABECB5A0011A85A9D290@EXCH-MBX-F.ulaval.ca>
References: <4BF149B0.4070708@med.umcg.nl>
	<B56D7C27B4408243B93FBC46ABECB5A0011A85A9D290@EXCH-MBX-F.ulaval.ca>
Message-ID: <4BF245C3.2010402@med.umcg.nl>

I received another reply, which I copy here since it wasn't sent to the 
list:
-----
I also just know enough to be dangerous, but here's a first 
approximation of the ultimate truth.

I think he is just arguing (rightly or wrongly) that some kinds of main 
effects in the presence of an interaction can indeed be safely 
interpreted. One example comes to mind: if the interaction only 
moderates the strength of a main effect and does not flip over its 
direction. If the variables are setup in some sensible way then the main 
effects will give a kind of average.

A more general approach would be somehow to make sense of the meaning of 
the interactions. Can they be given a theoretical interpretation, 
perhaps with the help of some graphing? This is where the theory comes 
in handy: to limit the space of statistical models you have to explain!

Andy Fugard
-----


Thanks for the replies!

In this case, the data is on a ratio scale and floor/ceiling effects 
aren't a problem. This should have been obvious from the paper, but 
maybe wasn't. Thanks for the link; I wasn't familiar with this artifact.

Perhaps I should add plots of the interactions, demonstrating that they 
do cross ("disordinal interactions"). The approach I followed in the 
paper was to construct sensible (given the data) sub-analyses to 
describe the interactions, such as looking at the effect of p within 
each combination of d and tc (since p did not interact with ds or s).

thanks again,
Jo Etzel




Julien Beguin wrote:
> I think that the reviewer's comment saying that you need to "qualify the
> type of interaction in order to decide whether or not the main effects
> can be interpreted" means that you need to establish that you have interval or ratio data because 
> an apparent interaction could be an artifact of ordinal scale measurement. 
>
> Have a look at this link:
> http://www.markwebtest.netfirms.com/Appendix/WebAppOrdinalInteraction/WebAppOrdinalInteractions.htm
>
> Julien Beguin 
> ________________________________________
> De : r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] de la part de J.A. Etzel [J.A.Etzel at med.umcg.nl]
> Date d'envoi : 17 mai 2010 09:50
> ? : r-sig-mixed-models at r-project.org
> Objet : [R-sig-ME] strategy for interpreting significant interactions
>
> Good afternoon,
>
> I think of myself as knowing enough about mixed models ?to be
> dangerous?, but certainly not an expert. In a recent manuscript I used
> mixed models, and a reviewer?s comment has me confused; I hope that
> someone on this list may be able to point me in the right direction. My
> understanding is that it is not proper to interpret main effects that
> are present in a significant interaction, but rather that elements of
> the interaction should be held constant so the others can be examined in
> a sensible manner:
>
>
> my text:
> As expected, many significant interactions are present in the data. The
> five-way interaction was not significant, nor were any of the four-way
> interactions. All five factors (tc, d, ds, p, s) are involved in at
> least one three-way interaction: tc interacts with d and ds, p, and s; s
> and d also interact with ds. In these [linear mixed] models it is not
> possible to interpret main effects or lower-order interactions when
> higher-order interactions are present, so no attempt will be made to do
> so here. Instead, additional models with certain factors held constant
> were constructed to characterize the interactions and allow
> interpretation of the effects.
>
> reviewer?s comment:
> The authors argue that "interpretation of main effects is not possible
> in the presence of significant interactions". This statement is only
> one-third true. Indeed, main effects must not be interpreted in the
> presence of disordinal interactions. However, in the case of
> semi-disordinal interactions one main effect can be interpreted and in
> the case of ordinal interactions even both main effects can be
> interpreted. Thus, for every interaction the authors have to qualify the
> type of interaction in order to decide whether or not the main effects
> can be interpreted.
>
>
> Is my text/the strategy I followed correct? If so, do you have any
> suggestions for references to use in the response to reviewers on this
> point? I have had a surprising (to me!) amount of difficulty finding
> references detailing what should be done in the face of significant
> interactions.
>
> Thanks for your help!
> Jo Etzel
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From Kay.Cichini at uibk.ac.at  Wed May 19 09:38:11 2010
From: Kay.Cichini at uibk.ac.at (Kay Cecil Cichini)
Date: Wed, 19 May 2010 09:38:11 +0200
Subject: [R-sig-ME] post hocs for LMMs / GLMMs
Message-ID: <4BF39563.9040004@uibk.ac.at>

hello,

i have several LMMs and GLMMs with 2 nominal fixed factors, f1: A,B,C,D 
and f2: 1,2. now i need inference on the differences of level 1 vs. 2 of 
f2 within each level of f1, or vice versa differences of A/B, A/C, A/D, 
B/C, etc. within each level of f2.

before i try with glht(): isn't it justified to examining the model's 
t-tests with re-ordered levels of the nominal variables, by
which each of this comparisons can be yielded by the different
parameterizations - this seems to be the most convenient way and till 
now i found no one to explain to me why this may or may not be valid.

best regards,
kay



From Kay.Cichini at uibk.ac.at  Wed May 19 09:52:05 2010
From: Kay.Cichini at uibk.ac.at (Kay Cecil Cichini)
Date: Wed, 19 May 2010 09:52:05 +0200
Subject: [R-sig-ME] post hocs for LMMs / GLMMs
In-Reply-To: <4BF39563.9040004@uibk.ac.at>
References: <4BF39563.9040004@uibk.ac.at>
Message-ID: <4BF398A5.5070404@uibk.ac.at>

p.s.:
..."different parameterizations" may be the wrong term, as the 
parameters actually stay the same and i only change the intercept-level.

Kay Cecil Cichini schrieb:
> hello,
> 
> i have several LMMs and GLMMs with 2 nominal fixed factors, f1: A,B,C,D 
> and f2: 1,2. now i need inference on the differences of level 1 vs. 2 of 
> f2 within each level of f1, or vice versa differences of A/B, A/C, A/D, 
> B/C, etc. within each level of f2.
> 
> before i try with glht(): isn't it justified to examining the model's 
> t-tests with re-ordered levels of the nominal variables, by
> which each of this comparisons can be yielded by the different
> parameterizations - this seems to be the most convenient way and till 
> now i found no one to explain to me why this may or may not be valid.
> 
> best regards,
> kay
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From adik at ilovebacon.org  Wed May 19 10:47:55 2010
From: adik at ilovebacon.org (Adam D. I. Kramer)
Date: Wed, 19 May 2010 01:47:55 -0700 (PDT)
Subject: [R-sig-ME] post hocs for LMMs / GLMMs
In-Reply-To: <4BF398A5.5070404@uibk.ac.at>
References: <4BF39563.9040004@uibk.ac.at> <4BF398A5.5070404@uibk.ac.at>
Message-ID: <Pine.LNX.4.64.1005190136460.20620@ilovebacon.org>

Hi Kay,

The general way to do what you want is to pre-define comparisons of
interest. For example, if you thought A would be higher than B C and D, then
you would attach a contrast to your data.frame for the factor f1 that would
compare A to B C and D. If there is a contrasts() attribute on f1, then when
you fit your model (say, using lmer from the lm4 package), R will
automatically parse out and test that contrast specifically.

If you don't do this, most functions will create contrasts that compare
levels of a factor to the first level (A vs B, A vs C, A vs D in the above
case).

...but if you don't have any idea or any theory of how A B C and D differ,
I would recommend that you treat your analysis as exploratory, and then just
look at the differences without testing them and see what's there, try to
come up with a theory, and then go collect more data.  When you're just
"comparing levels" or looking at effects, there's a lot more going on than
you'd at first think--in this case, the comparisons to be made are A vs B, A
vs.  B and C, A vs.  B and D, A vs.  C and D, A vs.  B C and D, and A vs
0--8 comparisons.  The same are available for B C and D, resulting in 32
comparisons.  That's a lot!  With an interpretation alpha of .05, you may
get a couple false positives.  That is why the "reparamaterization" approach
is ill advised--it greatly inflates your likelihood of finding something by
chance alone.

So really, the best thing to do here is to encode the things you hope to
find, and test them--and if you see anything else, call it a theoretically
useful fluke. The effect is positive/negative, but you can't say it's
significant...and at that point you have to replicate it anyway so a precise
p-value isn't super useful.

--Adam

On Wed, 19 May 2010, Kay Cecil Cichini wrote:

> p.s.:
> ..."different parameterizations" may be the wrong term, as the parameters 
> actually stay the same and i only change the intercept-level.
>
> Kay Cecil Cichini schrieb:
>> hello,
>> 
>> i have several LMMs and GLMMs with 2 nominal fixed factors, f1: A,B,C,D and 
>> f2: 1,2. now i need inference on the differences of level 1 vs. 2 of f2 
>> within each level of f1, or vice versa differences of A/B, A/C, A/D, B/C, 
>> etc. within each level of f2.
>> 
>> before i try with glht(): isn't it justified to examining the model's 
>> t-tests with re-ordered levels of the nominal variables, by
>> which each of this comparisons can be yielded by the different
>> parameterizations - this seems to be the most convenient way and till now i 
>> found no one to explain to me why this may or may not be valid.
>> 
>> best regards,
>> kay
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From Kay.Cichini at uibk.ac.at  Wed May 19 11:23:36 2010
From: Kay.Cichini at uibk.ac.at (Kay Cecil Cichini)
Date: Wed, 19 May 2010 11:23:36 +0200
Subject: [R-sig-ME] post hocs for LMMs / GLMMs
In-Reply-To: <4BF398A5.5070404@uibk.ac.at>
References: <4BF39563.9040004@uibk.ac.at> <4BF398A5.5070404@uibk.ac.at>
Message-ID: <4BF3AE18.2050603@uibk.ac.at>

hello adam,

thanks for your explanations.

say i had a full model with f1+f2+f1*f2+random and was interested only 
in the differences of level 1 vs. 2 of f2 within each level of f1, that 
is f2.1 vs. f2.2 within f1.A, in f1.B, etc. - would then tests on 
specified contrasts not yield about the same results as the 
corresponding t-tests on f2.1 vs f2.1 with each f1.A, f1.B, etc. at the 
intercept?


like:
testing the effect of f1 within A

Fixed	effects:			
			Estimate	z	Pr(>|z|)	
(Intercept= A, 1)	0.5687	4.283	< 0.001	***
B			1.1225	6.875	< 0.001	***
C			1.3807	8.622	< 0.001	***
D			1.7949	8.301	< 0.001	***
2			0.0482	0.309	0.75724		<- A, 1 vs. A, 2	
B:2			-0.495	-2.656	0.0079	**
C:2			-0.5767	-3.191	0.00142	**
D:2			-0.4922	-2.235	0.02542	*

yours,
kay


Hi Kay,

The general way to do what you want is to pre-define comparisons of
interest. For example, if you thought A would be higher than B C and D, then
you would attach a contrast to your data.frame for the factor f1 that would
compare A to B C and D. If there is a contrasts() attribute on f1, then when
you fit your model (say, using lmer from the lm4 package), R will
automatically parse out and test that contrast specifically.

If you don't do this, most functions will create contrasts that compare
levels of a factor to the first level (A vs B, A vs C, A vs D in the above
case).

...but if you don't have any idea or any theory of how A B C and D differ,
I would recommend that you treat your analysis as exploratory, and then just
look at the differences without testing them and see what's there, try to
come up with a theory, and then go collect more data.  When you're just
"comparing levels" or looking at effects, there's a lot more going on than
you'd at first think--in this case, the comparisons to be made are A vs B, A
vs.  B and C, A vs.  B and D, A vs.  C and D, A vs.  B C and D, and A vs
0--8 comparisons.  The same are available for B C and D, resulting in 32
comparisons.  That's a lot!  With an interpretation alpha of .05, you may
get a couple false positives.  That is why the "reparamaterization" approach
is ill advised--it greatly inflates your likelihood of finding something by
chance alone.

So really, the best thing to do here is to encode the things you hope to
find, and test them--and if you see anything else, call it a theoretically
useful fluke. The effect is positive/negative, but you can't say it's
significant...and at that point you have to replicate it anyway so a precise
p-value isn't super useful.

--Adam

On Wed, 19 May 2010, Kay Cecil Cichini wrote:

> p.s.:
> ..."different parameterizations" may be the wrong term, as the parameters 
> actually stay the same and i only change the intercept-level.
>
> Kay Cecil Cichini schrieb:
>> hello,
>> 
>> i have several LMMs and GLMMs with 2 nominal fixed factors, f1: A,B,C,D and 
>> f2: 1,2. now i need inference on the differences of level 1 vs. 2 of f2 
>> within each level of f1, or vice versa differences of A/B, A/C, A/D, B/C, 
>> etc. within each level of f2.
>> 
>> before i try with glht(): isn't it justified to examining the model's 
>> t-tests with re-ordered levels of the nominal variables, by
>> which each of this comparisons can be yielded by the different
>> parameterizations - this seems to be the most convenient way and till now i 
>> found no one to explain to me why this may or may not be valid.
>> 
>> best regards,
>> kay
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From walmeszeviani at yahoo.com.br  Wed May 19 19:55:14 2010
From: walmeszeviani at yahoo.com.br (walmes zeviani)
Date: Wed, 19 May 2010 10:55:14 -0700 (PDT)
Subject: [R-sig-ME] Overdispersion parameter estimation in glmer
Message-ID: <998166.92479.qm@web111703.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100519/4b1c3abf/attachment.pl>

From geir.bolstad at bio.ntnu.no  Thu May 20 11:01:21 2010
From: geir.bolstad at bio.ntnu.no (Geir H Bolstad)
Date: Thu, 20 May 2010 11:01:21 +0200
Subject: [R-sig-ME] Variance of random effects in binomial lmer
Message-ID: <1274346081.2295.44.camel@g>

Dear all,

Why is the estimated variance of a random effect different from the
variance of the predicted random effects in a lmer with logit link and
binomially distributed errors?

> mod <- lmer(y~(1|x), family=binomial)

Random effects:
 Groups Name        Variance Std.Dev.
 x      (Intercept) 7.1227   2.6688  
Number of obs: 10000, groups: x, 500

> var(ranef(mod)$x)
            (Intercept)
(Intercept)    5.126217

These two (variance of random effects and var(ranef(mod)$x)) are the
same in a lmer with normally distributed errors and identity link. So
what is the difference?

Syntax to generate data:
n1 <- 500
n2 <- 20
sd1 <- 3
sd2 <- 1
AA <- rnorm(n1, 0, sd1)
BB <- list()
for(i in 1:length(AA)) BB[[i]] <- AA[i]+rnorm(n2, 0, sd2)
BB2 <- unlist(BB)
y1 <- exp(BB2)/(1+exp(BB2))
y <- rbinom(length(y1), 1, y1)
x <- factor(rep(1:n1, each=n2))

Thanks for your help
Geir H. Bolstad
PhD candidate, Biology
Norwegian University of Science and Technology



From j.hox at uu.nl  Thu May 20 12:24:32 2010
From: j.hox at uu.nl (Hox, J. (Joop))
Date: Thu, 20 May 2010 12:24:32 +0200
Subject: [R-sig-ME] multilevel conference 2011
Message-ID: <2AE8AE55CF1AD141BEC92603ED873A4F237FD2@uu01msg-exb01.soliscom.uu.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100520/3559f2c9/attachment.pl>

From romain.piault at gmail.com  Thu May 20 17:45:53 2010
From: romain.piault at gmail.com (Romain.Piault)
Date: Thu, 20 May 2010 17:45:53 +0200
Subject: [R-sig-ME] sigmoid residual distribution for a random effect
Message-ID: <1274370353.15947.31.camel@Analyse>

Hi everybody!

Using a linear mixed-effects model (library nlme), I have found a
sigmo?d pattern in the distribution of residuals for my random factor,
and I wonder whether some of you know potential causes of this
phenomenon.  

The model is as follow: 
model<-lme(MeanBand~Body_Condition+Brood_Size,random=~1|Nid)

where * MeanBand is a measure of the width of the sub-terminal black
band on the tail feathers of young kestrels
      * Body_Condition is a continuous measure of the amount of
resources nestlings received during their development
      * Brood_Size is a factor (with 2 levels) indicating whether the
brood where a nestling was raised was reduced or increased by one
nestling at hatching
      * Nid is the nest where a nestling was raised. Because there are 2
or more nestlings in one nest, Nest enters in the model as a random
factor.

Using qqnorm(model,~ranef(.,level=1)), I find that residuals do not
follow a line but describe a sigmo?d, revealing that the distribution of
the residuals for my random factor is not normal.

My question is therefore: do you know potential causes for such
distribution of residuals for a random effect?

Here is the output of the model:

 
Linear mixed-effects model fit by REML
 Data: NULL 
       AIC      BIC    logLik
  322.0317 332.9037 -156.0159

Random effects:
 Formula: ~1 | Nid
        (Intercept) Residual
StdDev:    1.523250 2.059382

Fixed effects: MeanBand ~ condition + Brood 
                Value Std.Error DF   t-value p-value
(Intercept) 19.050443 0.6243577 48 30.512066  0.0000
condition    0.093862 0.0263644 48  3.560170  0.0008
BroodRed     1.730359 0.8764315 17  1.974323  0.0648
 Correlation: 
          (Intr) condtn
condition  0.080       
BroodRed  -0.717 -0.109

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max 
-1.81195733 -0.68685432 -0.02572958  0.65085007  1.77797726 

Number of Observations: 68
Number of Groups: 19 

Furthermore, I wonder whether the high correlation shown in the
"Correlation" argument is indicative of any particular problem.

Thanking you in advance for your answers!

Best regards,

Romain



From deriso at gmail.com  Thu May 20 20:13:35 2010
From: deriso at gmail.com (Dave Deriso)
Date: Thu, 20 May 2010 11:13:35 -0700
Subject: [R-sig-ME] Interpreting Mixed Effects Model on Fully
	Within-Subjects Design
Message-ID: <AANLkTimj4gxCXbsSRMChOKL_rTy57fOqxxgRm9fFFA_J@mail.gmail.com>

Dear Mixed Models Experts,

I am trying to find the p_value for the overall interaction of
condition*difficulty, but the lme() seems to output everything but
this. Can offer some suggestions on how to make sense of this output,
and where my interaction and main effects are? I read the 'mixed
effects' section in the R Book (Crawley, 2007) and still can't figure
it out. Any advice will be very much appreciated.

lme(value~condition*diff,random=~1|subject/rep)

Fixed effects: value ~ condition * diff
                      Value Std.Error  DF   t-value p-value
(Intercept)       300109.95  9506.690 688 31.568289  0.0000
condition2         27717.65  9071.048 688  3.055617  0.0023
condition3        -23718.72  9071.048 688 -2.614772  0.0091
diff50             56767.55  9071.048 688  6.258103  0.0000
diff75            120031.80  9071.048 688 13.232408  0.0000
condition2:diff50 -45481.21 12828.399 688 -3.545354  0.0004
condition3:diff50   7333.37 12828.399 688  0.571651  0.5677
condition2:diff75 -38765.77 12828.399 688 -3.021871  0.0026
condition3:diff75  12919.59 12828.399 688  1.007109  0.3142


Here is a synopsis:

There are 5 independent variables (subject, condition, difficulty,
repetition) and 1 dependent measure (value). Condition and difficulty
are fixed effects and have 3 levels each (1,2,3 and 25,50,75
respectively), while subject and repetition are random effects. Three
repeated measurements (rep = 1,2,3) were taken for each condition x
difficulty pair for each subject, making this an entirely
within-subject design.

Here is the code:

#get the data
study.data =read.csv("http://files.davidderiso.com/example_data.csv", header=T)
attach(study.data)
subject = factor(subject)
condition = factor(condition)
diff = factor(diff)
rep = factor(rep)

#visualize whats happening
interaction.plot(diff, condition, value, ylim=c(240000,
450000),ylab="value", xlab="difficulty", trace.label="condition")

#compute the significance
library(nlme)
study.lme = lme(value~condition*diff,random=~1|subject/rep)
summary(study.lme)

Best,
Dave Deriso
UCSD Psychology



From cewright at uci.edu  Thu May 20 20:36:54 2010
From: cewright at uci.edu (Charles E. (Ted) Wright)
Date: Thu, 20 May 2010 11:36:54 -0700 (Pacific Daylight Time)
Subject: [R-sig-ME] Interpreting Mixed Effects Model on Fully
 Within-Subjects Design
In-Reply-To: <AANLkTimj4gxCXbsSRMChOKL_rTy57fOqxxgRm9fFFA_J@mail.gmail.com>
References: <AANLkTimj4gxCXbsSRMChOKL_rTy57fOqxxgRm9fFFA_J@mail.gmail.com>
Message-ID: <alpine.WNT.2.00.1005201135490.5168@pcwright>

If I understand your question, the command
 	anova(study.lme)
should give you what you are looking for.

Ted Wright

On Thu, 20 May 2010, Dave Deriso wrote:

> Dear Mixed Models Experts,
>
> I am trying to find the p_value for the overall interaction of
> condition*difficulty, but the lme() seems to output everything but
> this. Can offer some suggestions on how to make sense of this output,
> and where my interaction and main effects are? I read the 'mixed
> effects' section in the R Book (Crawley, 2007) and still can't figure
> it out. Any advice will be very much appreciated.
>
> lme(value~condition*diff,random=~1|subject/rep)
>
> Fixed effects: value ~ condition * diff
>                      Value Std.Error  DF   t-value p-value
> (Intercept)       300109.95  9506.690 688 31.568289  0.0000
> condition2         27717.65  9071.048 688  3.055617  0.0023
> condition3        -23718.72  9071.048 688 -2.614772  0.0091
> diff50             56767.55  9071.048 688  6.258103  0.0000
> diff75            120031.80  9071.048 688 13.232408  0.0000
> condition2:diff50 -45481.21 12828.399 688 -3.545354  0.0004
> condition3:diff50   7333.37 12828.399 688  0.571651  0.5677
> condition2:diff75 -38765.77 12828.399 688 -3.021871  0.0026
> condition3:diff75  12919.59 12828.399 688  1.007109  0.3142
>
>
> Here is a synopsis:
>
> There are 5 independent variables (subject, condition, difficulty,
> repetition) and 1 dependent measure (value). Condition and difficulty
> are fixed effects and have 3 levels each (1,2,3 and 25,50,75
> respectively), while subject and repetition are random effects. Three
> repeated measurements (rep = 1,2,3) were taken for each condition x
> difficulty pair for each subject, making this an entirely
> within-subject design.
>
> Here is the code:
>
> #get the data
> study.data =read.csv("http://files.davidderiso.com/example_data.csv", header=T)
> attach(study.data)
> subject = factor(subject)
> condition = factor(condition)
> diff = factor(diff)
> rep = factor(rep)
>
> #visualize whats happening
> interaction.plot(diff, condition, value, ylim=c(240000,
> 450000),ylab="value", xlab="difficulty", trace.label="condition")
>
> #compute the significance
> library(nlme)
> study.lme = lme(value~condition*diff,random=~1|subject/rep)
> summary(study.lme)
>
> Best,
> Dave Deriso
> UCSD Psychology
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



From deriso at gmail.com  Thu May 20 20:56:56 2010
From: deriso at gmail.com (Dave Deriso)
Date: Thu, 20 May 2010 11:56:56 -0700
Subject: [R-sig-ME] Interpreting Mixed Effects Model on Fully
	Within-Subjects Design
In-Reply-To: <AANLkTimU6568904lp0RcnX5F1jSn8iGla7dItZhWzTGE@mail.gmail.com>
References: <AANLkTimj4gxCXbsSRMChOKL_rTy57fOqxxgRm9fFFA_J@mail.gmail.com> 
	<AANLkTil2EH6m1NCGHfU5wE6tfTCbdJHn2xENfqJK7N9i@mail.gmail.com> 
	<AANLkTikp3o1rSziWGoRwVM-PBfaxIHcktxXgGCwUt24_@mail.gmail.com> 
	<AANLkTimU6568904lp0RcnX5F1jSn8iGla7dItZhWzTGE@mail.gmail.com>
Message-ID: <AANLkTinfAIIIxIlr-fFpwfuVrUYGlFOmP1nZIVW4wVEe@mail.gmail.com>

Hi Daniel,

Thank you so much for taking the time to explain this.

I guess I am having trouble believing the results.

condition x diff p=.001
condition p=.001
diff p=.001

When I run the ANOVA, I get more conservative results:

summary(aov(value~condition*diff*rep + Error(subject/(condition*diff*rep))))
condition x diff  p=2.311e-05 ***

summary(aov(value~(condition*rep+diff*rep)+Error(subject/(condition*rep+diff*rep))))
condition p=0.02116 *
diff p=2.2e-16 ***

How do I stay conservative here?

Best,
Dave

On Thu, May 20, 2010 at 11:38 AM, Daniel Ezra Johnson
<danielezrajohnson at gmail.com> wrote:
>>> m0 = lme(value~condition+diff,random=~1|subject/rep)
>>> m1 = lme(value~condition*diff,random=~1|subject/rep)
>>> anova(m0,m1)
>
> This will give you the p-value for the interaction since that's the
> only thing different between the two models.
>
> if you similarly compared
>
> lme(value~condition+diff...) to
> lme(value~condition...)
>
> that would be a test of "diff", whereas comparing
>
> lme(value~condition+diff...) to
> lme(value~diff...)
>
> that would be a test of "condition".
>
> there's more than one way to test these, but using anova() like this,
> i think is reasonable.
> of course, if you follow the mixed-model literature you'll see that
> people have shown these tests (likelihood-ratio tests) to be
> anti-conservative (p-values too high) when applied to mixed models..
>
> Dan
>



From deriso at gmail.com  Thu May 20 20:58:35 2010
From: deriso at gmail.com (Dave Deriso)
Date: Thu, 20 May 2010 11:58:35 -0700
Subject: [R-sig-ME] Interpreting Mixed Effects Model on Fully
	Within-Subjects Design
In-Reply-To: <alpine.WNT.2.00.1005201135490.5168@pcwright>
References: <AANLkTimj4gxCXbsSRMChOKL_rTy57fOqxxgRm9fFFA_J@mail.gmail.com> 
	<alpine.WNT.2.00.1005201135490.5168@pcwright>
Message-ID: <AANLkTilIn1wbPoxEYFNbpzScq6DwP3r71aQWkJxrWM5w@mail.gmail.com>

Hi Ted,

Thank you for offering this suggestion! However, simply running an
anova on the lme is difficult to interpret. Daniel has suggested doing
this only when comparing models. Can you explain how yours works?

Best,
Dave

On Thu, May 20, 2010 at 11:36 AM, Charles E. (Ted) Wright
<cewright at uci.edu> wrote:
> If I understand your question, the command
> ? ? ? ?anova(study.lme)
> should give you what you are looking for.
>
> Ted Wright
>
> On Thu, 20 May 2010, Dave Deriso wrote:
>
>> Dear Mixed Models Experts,
>>
>> I am trying to find the p_value for the overall interaction of
>> condition*difficulty, but the lme() seems to output everything but
>> this. Can offer some suggestions on how to make sense of this output,
>> and where my interaction and main effects are? I read the 'mixed
>> effects' section in the R Book (Crawley, 2007) and still can't figure
>> it out. Any advice will be very much appreciated.
>>
>> lme(value~condition*diff,random=~1|subject/rep)
>>
>> Fixed effects: value ~ condition * diff
>> ? ? ? ? ? ? ? ? ? ? Value Std.Error ?DF ? t-value p-value
>> (Intercept) ? ? ? 300109.95 ?9506.690 688 31.568289 ?0.0000
>> condition2 ? ? ? ? 27717.65 ?9071.048 688 ?3.055617 ?0.0023
>> condition3 ? ? ? ?-23718.72 ?9071.048 688 -2.614772 ?0.0091
>> diff50 ? ? ? ? ? ? 56767.55 ?9071.048 688 ?6.258103 ?0.0000
>> diff75 ? ? ? ? ? ?120031.80 ?9071.048 688 13.232408 ?0.0000
>> condition2:diff50 -45481.21 12828.399 688 -3.545354 ?0.0004
>> condition3:diff50 ? 7333.37 12828.399 688 ?0.571651 ?0.5677
>> condition2:diff75 -38765.77 12828.399 688 -3.021871 ?0.0026
>> condition3:diff75 ?12919.59 12828.399 688 ?1.007109 ?0.3142
>>
>>
>> Here is a synopsis:
>>
>> There are 5 independent variables (subject, condition, difficulty,
>> repetition) and 1 dependent measure (value). Condition and difficulty
>> are fixed effects and have 3 levels each (1,2,3 and 25,50,75
>> respectively), while subject and repetition are random effects. Three
>> repeated measurements (rep = 1,2,3) were taken for each condition x
>> difficulty pair for each subject, making this an entirely
>> within-subject design.
>>
>> Here is the code:
>>
>> #get the data
>> study.data =read.csv("http://files.davidderiso.com/example_data.csv",
>> header=T)
>> attach(study.data)
>> subject = factor(subject)
>> condition = factor(condition)
>> diff = factor(diff)
>> rep = factor(rep)
>>
>> #visualize whats happening
>> interaction.plot(diff, condition, value, ylim=c(240000,
>> 450000),ylab="value", xlab="difficulty", trace.label="condition")
>>
>> #compute the significance
>> library(nlme)
>> study.lme = lme(value~condition*diff,random=~1|subject/rep)
>> summary(study.lme)
>>
>> Best,
>> Dave Deriso
>> UCSD Psychology
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>



From s90225007 at yahoo.com.tw  Sat May 22 20:28:04 2010
From: s90225007 at yahoo.com.tw (Nai-Wei Chen)
Date: Sun, 23 May 2010 02:28:04 +0800 (CST)
Subject: [R-sig-ME] Questions about using glmmPQL and glmer
Message-ID: <969847.30889.qm@web73404.mail.tp2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100523/eb3b2a59/attachment.pl>

From bolker at ufl.edu  Sun May 23 00:08:38 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Sat, 22 May 2010 18:08:38 -0400
Subject: [R-sig-ME] Questions about using glmmPQL and glmer
In-Reply-To: <969847.30889.qm@web73404.mail.tp2.yahoo.com>
References: <969847.30889.qm@web73404.mail.tp2.yahoo.com>
Message-ID: <4BF855E6.20009@ufl.edu>

Nai-Wei Chen wrote:
> Dear all R users,
> 
> I  have problems when I use glmmPQL to analyze binary data with
> random effects. When I use "summary(glmmPQL())$residuals", I just see
> the five summary statistics of standardized residuals. How can I
> retrive the fitted probability and reiduals from the summary?

  m1 <- glmmPQL(...)
  residuals(m1)
  fitted(m1)
> 
> When I retrive the fitted values of fixed effects, what do the values
> corresponding to increasing levels of grouping mean?

  See any discussion of contrasts in R: differences between level x and
the baseline (first) level.  (In order to use glmmPQL you should be
familiar with both glm() and lme() ...)
> 
> When I use the "glmer" procedure, how can I retrive the AIC value,
> the coefficients of random effects to the groups and residuals?

  m2 <- glmer()
  AIC(m2) ## or maybe AIC(logLik(m2))
  ranef(m2)
  residuals(m2)

  I would be careful using glmmPQL on binary data, this is a type of
data where penalized quasi-likelihood is known to be a bit dicey ...
Breslow, N. E. 2004. Whither PQL? Pages 1?22 in D. Y. Lin and P. J.
Heagerty, editors. Proceedings of the second Seattle symposium in
biostatistics: Analysis of correlated data. Springer.
<www.bepress.com/uwbiostat/paper192/>



From mcmahons at si.edu  Tue May 25 01:00:19 2010
From: mcmahons at si.edu (McMahon, Sean)
Date: Mon, 24 May 2010 19:00:19 -0400
Subject: [R-sig-ME] Failure to load lme4 on Mac
Message-ID: <C8207D43.4236%mcmahons@si.edu>

Hey,
I've been able to work around the lack of a binary for mac snow leopard's (and lme4's) latest updates.  On a  Mac Pro, I was able to download the source package and install.  On my Mac Book, I cannot install lme4 on the latest R 2.11.0 at all.

My status now is that I have no access to lme4 on my laptop for some reason, but cannot figure out what the problem is.

Any help would be welcome,

Sean

This is from the mac GUI install through the source.  Obviously there is no binary at the CRAN site.

* installing *source* package 'lme4' ...
** libs
** arch - i386
sh: make: command not found
ERROR: compilation failed for package 'lme4'
* removing '/Library/Frameworks/R.framework/Versions/2.11/Resources/library/lme4'
* restoring previous '/Library/Frameworks/R.framework/Versions/2.11/Resources/library/lme4'

The downloaded packages are in
    '/private/var/folders/Aa/AafdcUsp2RW66U+8ZMzUBU+++TI/-Tmp-/Rtmpds1XEs/downloaded_packages'



From daniel.lists at zeno.co.nz  Tue May 25 01:25:20 2010
From: daniel.lists at zeno.co.nz (Daniel Myall)
Date: Tue, 25 May 2010 11:25:20 +1200
Subject: [R-sig-ME] Failure to load lme4 on Mac
In-Reply-To: <C8207D43.4236%mcmahons@si.edu>
References: <C8207D43.4236%mcmahons@si.edu>
Message-ID: <4BFB0AE0.3090803@zeno.co.nz>

Hi Sean,

On your Macbook do you have xcode installed? The error "sh: make: 
command not found" indicates that this is not the case.

The best place to get the latest xcode is http://connect.apple.com/ (The 
main Apple site sends you back and forward between two pages for the 
xcode download).

Here is the log when I build lme4 (R 2.11.0, Snow Leopard 10.6.3, xcode 
3.2.2):

* installing *source* package ?lme4? ...
** libs
** arch - i386
gcc -arch i386 -std=gnu99 
-I/Library/Frameworks/R.framework/Resources/include 
-I/Library/Frameworks/R.framework/Resources/include/i386 
-I/usr/local/include 
-I"/Library/Frameworks/R.framework/Versions/2.11/Resources/library/Matrix/include" 
-I"/Library/Frameworks/R.framework/Resources/library/stats/include" 
-fPIC -g -O2 -c init.c -o init.o
gcc -arch i386 -std=gnu99 
-I/Library/Frameworks/R.framework/Resources/include 
-I/Library/Frameworks/R.framework/Resources/include/i386 
-I/usr/local/include 
-I"/Library/Frameworks/R.framework/Versions/2.11/Resources/library/Matrix/include" 
-I"/Library/Frameworks/R.framework/Resources/library/stats/include" 
-fPIC -g -O2 -c lmer.c -o lmer.o
gcc -arch i386 -std=gnu99 
-I/Library/Frameworks/R.framework/Resources/include 
-I/Library/Frameworks/R.framework/Resources/include/i386 
-I/usr/local/include 
-I"/Library/Frameworks/R.framework/Versions/2.11/Resources/library/Matrix/include" 
-I"/Library/Frameworks/R.framework/Resources/library/stats/include" 
-fPIC -g -O2 -c local_stubs.c -o local_stubs.o
gcc -arch i386 -std=gnu99 -dynamiclib -Wl,-headerpad_max_install_names 
-undefined dynamic_lookup -single_module -multiply_defined suppress 
-L/usr/local/lib -o lme4.so init.o lmer.o local_stubs.o 
-L/Library/Frameworks/R.framework/Resources/lib/i386 -lRlapack 
-L/Library/Frameworks/R.framework/Resources/lib/i386 -lRblas -lgfortran 
-F/Library/Frameworks/R.framework/.. -framework R -Wl,-framework 
-Wl,CoreFoundation
installing to 
/Library/Frameworks/R.framework/Versions/2.11/Resources/library/lme4/libs/i386
** arch - x86_64
gcc -arch x86_64 -std=gnu99 
-I/Library/Frameworks/R.framework/Resources/include 
-I/Library/Frameworks/R.framework/Resources/include/x86_64 
-I/usr/local/include 
-I"/Library/Frameworks/R.framework/Versions/2.11/Resources/library/Matrix/include" 
-I"/Library/Frameworks/R.framework/Resources/library/stats/include" 
-fPIC -g -O2 -c init.c -o init.o
gcc -arch x86_64 -std=gnu99 
-I/Library/Frameworks/R.framework/Resources/include 
-I/Library/Frameworks/R.framework/Resources/include/x86_64 
-I/usr/local/include 
-I"/Library/Frameworks/R.framework/Versions/2.11/Resources/library/Matrix/include" 
-I"/Library/Frameworks/R.framework/Resources/library/stats/include" 
-fPIC -g -O2 -c lmer.c -o lmer.o
gcc -arch x86_64 -std=gnu99 
-I/Library/Frameworks/R.framework/Resources/include 
-I/Library/Frameworks/R.framework/Resources/include/x86_64 
-I/usr/local/include 
-I"/Library/Frameworks/R.framework/Versions/2.11/Resources/library/Matrix/include" 
-I"/Library/Frameworks/R.framework/Resources/library/stats/include" 
-fPIC -g -O2 -c local_stubs.c -o local_stubs.o
gcc -arch x86_64 -std=gnu99 -dynamiclib -Wl,-headerpad_max_install_names 
-undefined dynamic_lookup -single_module -multiply_defined suppress 
-L/usr/local/lib -o lme4.so init.o lmer.o local_stubs.o 
-L/Library/Frameworks/R.framework/Resources/lib/x86_64 -lRlapack 
-L/Library/Frameworks/R.framework/Resources/lib/x86_64 -lRblas 
-lgfortran -F/Library/Frameworks/R.framework/.. -framework R 
-Wl,-framework -Wl,CoreFoundation
installing to 
/Library/Frameworks/R.framework/Versions/2.11/Resources/library/lme4/libs/x86_64
** R
** data
** moving datasets to lazyload DB
** inst
** preparing package for lazy loading
Loading required package: lattice

Attaching package: 'Matrix'

The following object(s) are masked from 'package:base':

det

Creating a new generic function for "coef" in "lme4"
Creating a new generic function for "confint" in "lme4"
Creating a new generic function for "plot" in "lme4"
Creating a new generic function for "formula" in "lme4"
Creating a new generic function for "fixef" in "lme4"
Creating a new generic function for "ranef" in "lme4"
Creating a new generic function for "anova" in "lme4"
Creating a new generic function for "deviance" in "lme4"
Creating a new generic function for "fitted" in "lme4"
Creating a new generic function for "logLik" in "lme4"
Creating a new generic function for "predict" in "lme4"
Creating a new generic function for "residuals" in "lme4"
Creating a new generic function for "resid" in "lme4"
Creating a new generic function for "simulate" in "lme4"
Creating a new generic function for "model.frame" in "lme4"
Creating a new generic function for "model.matrix" in "lme4"
Creating a new generic function for "terms" in "lme4"
Creating a new generic function for "vcov" in "lme4"
Restoring the implicit generic function for ?with? from package ?base?
into package ?lme4?; the generic differs from the default conversion 
(Signatures differ: (data, expr), (data))
Creating a new generic function for "with" in "lme4"
Creating a new generic function for "as.data.frame" in "lme4"
Creating a new generic function for "xyplot" in "lme4"
Creating a new generic function for "densityplot" in "lme4"
Creating a new generic function for "qqmath" in "lme4"
** help
*** installing help indices
** building package indices ...
** testing if installed package can be loaded

* DONE (lme4)


On 25/05/10 11:00 AM, McMahon, Sean wrote:
> Hey,
> I've been able to work around the lack of a binary for mac snow leopard's (and lme4's) latest updates.  On a  Mac Pro, I was able to download the source package and install.  On my Mac Book, I cannot install lme4 on the latest R 2.11.0 at all.
>
> My status now is that I have no access to lme4 on my laptop for some reason, but cannot figure out what the problem is.
>
> Any help would be welcome,
>
> Sean
>
> This is from the mac GUI install through the source.  Obviously there is no binary at the CRAN site.
>
> * installing *source* package 'lme4' ...
> ** libs
> ** arch - i386
> sh: make: command not found
> ERROR: compilation failed for package 'lme4'
> * removing '/Library/Frameworks/R.framework/Versions/2.11/Resources/library/lme4'
> * restoring previous '/Library/Frameworks/R.framework/Versions/2.11/Resources/library/lme4'
>
> The downloaded packages are in
>      '/private/var/folders/Aa/AafdcUsp2RW66U+8ZMzUBU+++TI/-Tmp-/Rtmpds1XEs/downloaded_packages'
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From rjeffries at ucla.edu  Tue May 25 01:46:22 2010
From: rjeffries at ucla.edu (Robin Jeffries)
Date: Mon, 24 May 2010 16:46:22 -0700
Subject: [R-sig-ME] Improving computation time for a binary outcome in lme4
Message-ID: <AANLkTikTJz6nbCs-_WJ8RApzIshqAM7697wuPJo3jYbl@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100524/09a13d50/attachment.pl>

From bates at stat.wisc.edu  Tue May 25 01:48:10 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 24 May 2010 19:48:10 -0400
Subject: [R-sig-ME] [R] sparse matrices in lme4
In-Reply-To: <AANLkTikBn9gSCOaRHV43ukJ5THqJUpGIMzhOtamoX4qO@mail.gmail.com>
References: <AANLkTikBn9gSCOaRHV43ukJ5THqJUpGIMzhOtamoX4qO@mail.gmail.com>
Message-ID: <AANLkTinQ9cJoK85PNIJjKi9k-Lh-u8AMOrtieorVduCg@mail.gmail.com>

On Mon, May 24, 2010 at 6:24 PM, Robin Jeffries <rjeffries at ucla.edu> wrote:
> I read somewhere (help list, documentation) that the random effects in lme4
> uses sparse matrix "technology".

Yes.  That is why there is such a close link between the Matrix and
lme4 packages.  The sparse matrix methods in the Matrix package are
crucial to the lme4 package.

> I'd like to confirm with others that I can't use a sparse matrix as a fixed
> effect? I'm getting an "Invalid type (S4) " error.

The development version of the lme4 package, called lme4a and only
available from R-forge, has an optional argument sparseX that allows
for this.

In fact, that option is one of the reasons that the development
version has been in development for so long (the programming becomes
much more intricate when you must allow for such an option).

Some day, and I hope not too far in the future, the lme4a package will
be released as lme4.

By the way, questions such as this are probably more suitable for the
R-SIG-Mixed-Models at R-project.org mailing list, which I am cc:ing on
this reply.



From claire_brittain at hotmail.com  Tue May 25 02:00:28 2010
From: claire_brittain at hotmail.com (Claire Brittain)
Date: Tue, 25 May 2010 00:00:28 +0000
Subject: [R-sig-ME] glmmPQL - producing an overall interaction term
In-Reply-To: <SNT139-w314CED0AD3590D69DE53189FE70@phx.gbl>
References: <SNT139-w314CED0AD3590D69DE53189FE70@phx.gbl>
Message-ID: <SNT139-w7EBDCAC1D2089BEFBAA0A9FE80@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100525/a55062c3/attachment.pl>

From walmeszeviani at yahoo.com.br  Tue May 25 02:19:27 2010
From: walmeszeviani at yahoo.com.br (walmes zeviani)
Date: Mon, 24 May 2010 17:19:27 -0700 (PDT)
Subject: [R-sig-ME] Res:  glmmPQL - producing an overall interaction term
In-Reply-To: <SNT139-w7EBDCAC1D2089BEFBAA0A9FE80@phx.gbl>
References: <SNT139-w314CED0AD3590D69DE53189FE70@phx.gbl>
	<SNT139-w7EBDCAC1D2089BEFBAA0A9FE80@phx.gbl>
Message-ID: <639561.25579.qm@web111726.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100524/d57564f6/attachment.pl>

From walmeszeviani at yahoo.com.br  Tue May 25 02:44:39 2010
From: walmeszeviani at yahoo.com.br (walmes zeviani)
Date: Mon, 24 May 2010 17:44:39 -0700 (PDT)
Subject: [R-sig-ME] Res:  glmmPQL - producing an overall interaction term
In-Reply-To: <SNT139-w7EBDCAC1D2089BEFBAA0A9FE80@phx.gbl>
References: <SNT139-w314CED0AD3590D69DE53189FE70@phx.gbl>
	<SNT139-w7EBDCAC1D2089BEFBAA0A9FE80@phx.gbl>
Message-ID: <860338.81419.qm@web111712.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100524/460e2ccd/attachment.pl>

From bates at stat.wisc.edu  Tue May 25 03:09:02 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 24 May 2010 21:09:02 -0400
Subject: [R-sig-ME] Improving computation time for a binary outcome in
	lme4
In-Reply-To: <AANLkTikTJz6nbCs-_WJ8RApzIshqAM7697wuPJo3jYbl@mail.gmail.com>
References: <AANLkTikTJz6nbCs-_WJ8RApzIshqAM7697wuPJo3jYbl@mail.gmail.com>
Message-ID: <AANLkTikxJcMD2JTZDehu3TmefX4VQ6NnGiQBv-FHn_fV@mail.gmail.com>

On Mon, May 24, 2010 at 7:46 PM, Robin Jeffries <rjeffries at ucla.edu> wrote:
> I am running a mixed effects model with two random effects that have ~500
> and ~1400 factor levels respectively.

> For a continuous outcome, the computation time using lme4 is workable.
> However for a binary outcome the computation time increases 4-80 fold
> compared to a similar model for a continuous outcome. I tend to stop
> computations if they've been running more than 8 hours, so I don't have a
> max time estimate)

There are at least two characteristics of the generalized linear mixed
model that are causing the increase in computational time.  The first
is the fact that the algorithm is based on iteratively reweighted
least squares (IRLS) and not ordinary least squares (OLS).  It is
inevitable that an iterative algorithm is slower than a direct
calculation.

The second cause is the fact that one can "profile out" the
fixed-effects parameters in a linear mixed-effects model but not in a
generalized linear mixed-effects model.  You can fake it to some
extent but the currently released version of the lme4 package doesn't.
 Thus, the greater the number of fixed-effects parameters, the greater
the complexity of the problem.

If you use the verbose option to lmer and to glmer on similar problems
you will see that lmer if optimizing over fewer parameters than is
glmer.

> At least one of the fixed effects is also a 6-level factor. I attempted to
> treat this as a sparse matrix, but lmer() doesn't seem to allow for this
> type of matrix in the model.

As I mentioned in my reply on R-help, the development version of the
lme4 package does have a sparseX option.  For a factor with 6 levels
it is unlikely that it will help.  The sparsity index of the X matrix
will be greater than 1/6 and that is close to the breakpoint where
dense methods, which do more numerical computation but less structural
analysis, are actually faster than sparse methods.

> Are there any suggestions on what I can do (other than simplify the model)
> to improve the computation time for a binary outcome?

There are the usual suspects of getting access to a fast computer with
lots of memory and a 64-bit operating system.  You could see whether
an accelerated BLAS will help.  For example, Revolution R has the MKL
BLAS built-in.  Regrettably, that isn't always a speed boost.  We have
seen situations where multi-threaded BLAS actually slow down sparse
matrix operations because the communications overhead is greater than
the time savings of being able to perform more flops per second.

> Also, could people comment on the speed of MCMCglmm vs lme4? Perhaps I could
> go this route if it will prove to be substantially quicker for a binary
> outcome.

> Thank you to Douglas Bates for suggesting I post here. I think i'll be able
> to find more help using lme4 here than on the normal R-help.
>
> ~~~~~~~~~~~~~~~~~~~
> -Robin Jeffries
> Dr.P.H. Candidate in Biostatistics
> UCLA School of Public Health
> rjeffries at ucla.edu
> 530-624-0428
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From adik at ilovebacon.org  Tue May 25 03:25:55 2010
From: adik at ilovebacon.org (Adam D. I. Kramer)
Date: Mon, 24 May 2010 18:25:55 -0700 (PDT)
Subject: [R-sig-ME] Improving computation time for a binary outcome in
 lme4
In-Reply-To: <AANLkTikxJcMD2JTZDehu3TmefX4VQ6NnGiQBv-FHn_fV@mail.gmail.com>
References: <AANLkTikTJz6nbCs-_WJ8RApzIshqAM7697wuPJo3jYbl@mail.gmail.com>
	<AANLkTikxJcMD2JTZDehu3TmefX4VQ6NnGiQBv-FHn_fV@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1005241822490.18863@ilovebacon.org>


On Mon, 24 May 2010, Douglas Bates wrote:

> If you use the verbose option to lmer and to glmer on similar problems you
> will see that lmer if optimizing over fewer parameters than is glmer.

Just one potentially useful observation: Turning on "verbose" makes the
waiting period much MUCH more tolerable. It's kinda like a progress bar--you
know glmer is doing something and that makes it easier to wait.

For some huge models with bigger-than-I-needed data sets (back in the
netflix prize days), I just let R run overnight and got what I wanted--but I
had never let it go more than an hour before I worried that it was looping.

>> Are there any suggestions on what I can do (other than simplify the model)
>> to improve the computation time for a binary outcome?
>
> There are the usual suspects of getting access to a fast computer with
> lots of memory and a 64-bit operating system.  You could see whether an
> accelerated BLAS will help.  For example, Revolution R has the MKL BLAS
> built-in.  Regrettably, that isn't always a speed boost.  We have seen
> situations where multi-threaded BLAS actually slow down sparse matrix
> operations because the communications overhead is greater than the time
> savings of being able to perform more flops per second.

My kingdom for multi-threaded nlm()...

--Adam



From Wolfgang.Viechtbauer at STAT.unimaas.nl  Tue May 25 11:19:31 2010
From: Wolfgang.Viechtbauer at STAT.unimaas.nl (Viechtbauer Wolfgang (STAT))
Date: Tue, 25 May 2010 11:19:31 +0200
Subject: [R-sig-ME] Interesting software comparison paper
Message-ID: <077E31A57DA26E46AB0D493C9966AC7308689F8CE4@UM-MAIL4112.unimaas.nl>

Hello All,

I just stumbled across this article and I figured this may be of interest to some of you:

Austin, P. C. (2010). Estimating Multilevel Logistic Regression Models When the Number of Clusters is Low: A Comparison of Different Statistical Software Procedures. The International Journal of Biostatistics, 6(1).

http://www.bepress.com/ijb/vol6/iss1/16/

At least, the issue of what to do when the number of clusters is low has come up several times before on this list.

The comparison includes glmmPQL and glmer (although I suspect the version of glmer used was quite old; the author does not mention the version number of the lme4 package used, but does mention using R 2.8.0 -- which is a bit dated). Nice to see that glmer compares very well with other software.

Best,

--
Wolfgang Viechtbauer                        http://www.wvbauer.com/
Department of Methodology and Statistics    Tel: +31 (43) 388-2277
School for Public Health and Primary Care   Office Location:
Maastricht University, P.O. Box 616         Room B2.01 (second floor)
6200 MD Maastricht, The Netherlands         Debyeplein 1 (Randwyck)



From m.ramon.fernandez at gmail.com  Tue May 25 17:30:45 2010
From: m.ramon.fernandez at gmail.com (Manuel Ramon)
Date: Tue, 25 May 2010 17:30:45 +0200
Subject: [R-sig-ME] Mixed-effects model with nested factors
Message-ID: <AANLkTikyepW9Aq7Tyw6ZZ43RgH4pEa40J5Av2UYyKsY8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100525/71fe2510/attachment.pl>

From mmalten at gmail.com  Tue May 25 21:23:18 2010
From: mmalten at gmail.com (Mitchell Maltenfort)
Date: Tue, 25 May 2010 15:23:18 -0400
Subject: [R-sig-ME] Attempts at diagnostics with logistic regression and two
	random effects
Message-ID: <AANLkTikn-QV5p8nRt1haA2n2moo3-6fWsyLJwZ4MZWHb@mail.gmail.com>

I am currently playing with a logistic regression (family=binomial),
two random effects (state and hospital within state), and a handful of
fixed effects.

I'm implementing the two random effects as 1|hospital + 1|state,
following Dr. Bates' draft chapter 2 for the lme4 book.

So far, I've found that plotting prediction vs. residual gives me two
curved lines,  both concave facing the right (like the reciprocal
curve for x > 0), and that doing qqnorm on the residual gives me an
approximate straight line that then shoots upward.

Not quite sure how to interpret what they are telling me, never mind
addressing the inherent problem.

Can anyone point me in the right direction?

Thanks!



From rjeffries at ucla.edu  Wed May 26 03:03:34 2010
From: rjeffries at ucla.edu (Robin Jeffries)
Date: Tue, 25 May 2010 18:03:34 -0700
Subject: [R-sig-ME] MCMCglmm - random effects specification
Message-ID: <AANLkTilrsJEbRDp47KSV5rRzyUGe0Ph9YnkMxWnwd6Ck@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100525/0a2b7a1e/attachment.pl>

From Thierry.ONKELINX at inbo.be  Wed May 26 11:03:12 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 26 May 2010 11:03:12 +0200
Subject: [R-sig-ME] Mixed-effects model with nested factors
In-Reply-To: <AANLkTikyepW9Aq7Tyw6ZZ43RgH4pEa40J5Av2UYyKsY8@mail.gmail.com>
References: <AANLkTikyepW9Aq7Tyw6ZZ43RgH4pEa40J5Av2UYyKsY8@mail.gmail.com>
Message-ID: <2E9C414912813E4EB981326983E0A104072D0F67@inboexch.inbo.be>

Dear Manuel,

The fixed effect of sp IS estimated. You don't get a p-value because it has no df. You have no df because you used the factor in both the fixed effects as in the random effects. So remove sp from the random effect.

Furthermore, random effect with only a few levels is not a very good idea. You get unreliable estimates of the variance. Have a look at the plot below. It plots the confidence interval for the ratio of the sample variance and the population variance. Note that the interval is very wide with a small number of levels. 6 levels is a minimum minimorum. Ideally you should aim for 30 levels or more.

n <- 2:100
plot(n, qchisq(0.975, n - 1) / (n - 1), type = "l", ylim = c(0, 5.5))
lines(n, qchisq(0.025, n - 1) / (n - 1))
abline(h = 1, lty = 2, col = "red")
abline(v = c(2, 6, 10, 30), lty = 3, col = "blue")

HTH,

Thierry

----------------------------------------------------------------------------
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Manuel Ramon
> Verzonden: dinsdag 25 mei 2010 17:31
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] Mixed-effects model with nested factors
> 
> Hello,
> I having problems on the definition of a mixed model with 
> nested factors. My data base is as follows:
>      y:      performance measure
>      sp:    species factor with two levels
>      ani:   individual with 6 levels but three of one belong 
> to the fist
> species
>              and the other three to the other. That is, sp 
> and ani are NESTED
>      v1:    treatment with two levels
> 
> The aim of my work is to study if there are significant 
> differences between both species (sp), and both treatments 
> (v1). I want to consider the ani effect as random effect.  My 
> attemp is the next:
> 
>      lme( y ~ sp + v1, data=mydata, random=~1|sp/ani )
> 
> My first question is if the fm1 model is well desing. When I 
> run this analysis, the factor sp is not estimated, but I do 
> not know why?
> 
> A simulated example could be:
> 
> ##    Simul data
>      set.seed(1234)
> 
>      N <- 24
>      error <- rnorm(N)   # error term
>      ani <- rep(1:(N/4),each=4)   # individual effect (random)
>      b1 <- c(0,2,4,1,2,5)
>      sp <- rep(1:2, each=N/2)   # species (fixed)
>      b2 <- c(1,5)
>      v1 <- rep(1:2,each=2,length=N)   # treatment (fixed)
>      b3 <- c(2,7)
> 
>      y <- b1[ani] + b2[sp] + b3[v1] + error
> 
>      dat <- data.frame(y,ani,sp,v1)
>           dat$ani <- as.factor(dat$ani)
>           dat$sp <- as.factor(dat$sp)
>           dat$v1 <- as.factor(dat$v1)
> 
>      library(nlme)
>      fm1 <- lme(y ~ sp + v1, data=dat, random=~1|sp/ani)
>      summary(fm1)
> 
> 
> ## Output
> Linear mixed-effects model fit by REML
> Data: dat
>       AIC      BIC   logLik
>   94.0726 100.3397 -41.0363
> 
> Random effects:
>  Formula: ~1 | sp
>         (Intercept)
> StdDev:   0.8539529
> 
>  Formula: ~1 | ani %in% sp
>         (Intercept) Residual
> StdDev:    2.226151 1.109317
> 
> Fixed effects: y ~ sp + v1
>                 Value         Std.Error     DF   t-value       p-value
> (Intercept)  5.124082   1.5921603   17    3.218320   0.005
> sp2           4.220951   2.2287665     0    1.893851     NaN
> v12            5.160433   0.4528769   17  11.394781   0.000
>  Correlation:
>     (Intr) sp2
> sp2 -0.700
> v12 -0.142  0.000
> 
> Standardized Within-Group Residuals:
>         Min          Q1         Med          Q3         Max
> -1.39622076 -0.59150658  0.06285846  0.41361144  1.75700646
> 
> Number of Observations: 24
> Number of Groups:
>          sp ani %in% sp
>           2           6
> Mensajes de aviso perdidos
> In pt(q, df, lower.tail, log.p) : Se han producido NaNs
> 
> Why the sp effect has not DF? It could be due to its presence 
> in the random term.
> Is my model rigth? I think that I'm missing something.
> 
> Thanks in advance
> 
> 
> --
> --
> Manuel Ram?n
> m.ramon.fernandez at gmail.com
> 
> 	[[alternative HTML version deleted]]
> 
> 

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From b.pelzer at maw.ru.nl  Wed May 26 21:26:53 2010
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Wed, 26 May 2010 21:26:53 +0200
Subject: [R-sig-ME] weights-option in lmer
Message-ID: <4BFD75FD.1000705@maw.ru.nl>

Dear all,

I have to related questions concerning the weights-option in lmer.

1) Imagine a two level design, like respondents in a number of 
countries. From each country one has a sample and the percentages of 
males and females in each country differ from the population percentages 
for that country. Can one use the weights-option in lmer to obtain a 
weighted sample for which the (weighted) male/female sample-percentages 
are equal to the population percentages, to achieve more representative 
results?

2) If one has aggregated data-records, each record containing the values 
of the dependent and independent variables and also the number of 
lower-level cases in a variable named 'nofcases', can the ' 
weight=nofcases'  option in lmer then be used to 'disaggregate' the 
data? And are the resulting standard errors then correct, i.e. related 
to the total number of lower-level (disaggregated) cases?

If the answer to these question is 'yes', which I hope, does that also 
hold for the nonlinear, especially the binomial family models?  

Thanks for any help!!

Ben.



From walmeszeviani at yahoo.com.br  Sun May 30 00:23:28 2010
From: walmeszeviani at yahoo.com.br (walmes zeviani)
Date: Sat, 29 May 2010 15:23:28 -0700 (PDT)
Subject: [R-sig-ME] How obtain the estimated scale parameter as in older
	lmer function version
Message-ID: <139593.21145.qm@web111719.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100529/662e5b8f/attachment.pl>

From bates at stat.wisc.edu  Mon May 31 00:03:21 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 30 May 2010 17:03:21 -0500
Subject: [R-sig-ME] How obtain the estimated scale parameter as in older
	lmer function version
In-Reply-To: <139593.21145.qm@web111719.mail.gq1.yahoo.com>
References: <139593.21145.qm@web111719.mail.gq1.yahoo.com>
Message-ID: <AANLkTinrCyVv6fITf7YXBX-V6cxb9LNqmEBHABenMOkX@mail.gmail.com>

On Sat, May 29, 2010 at 5:23 PM, walmes zeviani
<walmeszeviani at yahoo.com.br> wrote:
> Hello,
>
> I read the article based on lme4
>
> Doran H, Bates D, Bliese P, Dowling M (2007). ?Estimating the Multilevel Rasch Model: With
> the lme4 Package.? Journal of Statistical Software, 20(2). URL http://www.jstatsoft.
> org/v20/i02/.
>
> and I saw that the print of 'mer' class showed a estimated scale parameter. Nowadays, the print doesn't show this. I tried calculate by myself employing Pearson residuals and deviance() function but this didn't match the same result. In the article there was this output:
>
> R> data("lq2002", package = "multilevel")
> R> wrk <- lq2002
> R> for (i in 3:16) wrk[[i]] <- ordered(wrk[[i]])
> R> for (i in 17:21) wrk[[i]] <- ordered(5 - wrk[[i]])
> R> lql <- reshape(wrk, varying = list(names(lq2002)[3:21]),
> + ? ? v.names = "fivelev", idvar = "subj", timevar = "item",
> + ? ? drop = names(lq2002)[c(2, 22:27)], direction = "long")
> R> lql$itype <- with(lql, factor(ifelse(item < 12, "Leadership",
> + ? ? ifelse(item < 15, "Task Sig.", "Hostility"))))
> R> for (i in c(1, 2, 4, 5)) lql[[i]] <- factor(lql[[i]])
> R> lql$dichot <- factor(ifelse(lql$fivelev < 4, 0, 1))
>
> R> (fm1 <- lmer(dichot ~ 0 + itype + (1 | subj) + (1 | COMPID) +
> + ? ? (1 | item), lql, binomial))
> Generalized linear mixed model fit using Laplace
> Formula: dichot ~ 0 + itype + (1 | subj) + (1 | COMPID) + (1 | item)
> ? Data: lql
> ?Family: binomial(logit link)
> ? AIC ? BIC logLik deviance
> ?40722 40773 -20355 ? ?40710
> Random effects:
> ?Groups Name ? ? ? ?Variance Std.Dev.
> ?subj ? (Intercept) 2.30528 1.51831
> ?COMPID (Intercept) 0.25449 0.50447
> ?item ? (Intercept) 0.37700 0.61400
> number of obs: 38798, groups: subj, 2042; COMPID, 49; item, 19
>
> Estimated scale (compare to ?1 ) ?0.9386558 ?#<---------------------------- this!

That quantity is the square root of the penalized residual sum of
squares divided by n, the number of observations, evaluated as

> sqrt(sum(c(fm1 at resid, fm1 at u)^2)/length(fm1 at resid))
[1] 0.9386649

> Fixed effects:
> ? ? ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
> itypeHostility ? ?1.6721 ? ? 0.2883 ? 5.801 6.6e-09
> itypeLeadership ?-0.4921 ? ? 0.2036 -2.417 ? ?0.0157
> itypeTask Sig. ? -0.1308 ? ? 0.3654 -0.358 ? ?0.7203
> Correlation of Fixed Effects:
> ? ? ? ? ? ?itypHs itypLd
> itypeLdrshp 0.117
> itypeTskSg. 0.066 0.093
>
> My actual output is:
>
>> fm1
> Generalized linear mixed model fit by the Laplace approximation
> Formula: dichot ~ 0 + itype + (1 | subj) + (1 | COMPID) + (1 | item)
> ? Data: lql
> ? AIC ? BIC logLik deviance
> ?40722 40773 -20355 ? ?40710
> Random effects:
> ?Groups Name ? ? ? ?Variance Std.Dev.
> ?subj ? (Intercept) 2.30573 ?1.51846
> ?COMPID (Intercept) 0.25416 ?0.50415
> ?item ? (Intercept) 0.37488 ?0.61227
> Number of obs: 38798, groups: subj, 2042; COMPID, 49; item, 19
>
> Fixed effects:
> ? ? ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
> itypeHostility ? ?1.6774 ? ? 0.2875 ? 5.834 ?5.4e-09 ***
> itypeLeadership ?-0.4928 ? ? 0.2031 ?-2.426 ? 0.0153 *
> itypeTask Sig. ? -0.1362 ? ? 0.3644 ?-0.374 ? 0.7086
> ---
> Signif. codes: ?0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
> ? ? ? ? ? ?itypHs itypLd
> itypeLdrshp 0.118
> itypeTskSg. 0.066 ?0.093
>> sum(residuals(fm1, type="pearson")^2)/(nrow(lql)-3-3)
> [1] 0.8399116
>> deviance(fm1)/(nrow(lql)-3-3)
> ? ? ?ML
> 1.049437
>>
>
> As you can see, I can't figure out the estimated scale parameter. How can I get it? Why was this information removed from the output in newer versions of the function?
>
> Thanks in advance.
>
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



From mmalten at gmail.com  Mon May 31 00:24:00 2010
From: mmalten at gmail.com (Mitchell Maltenfort)
Date: Sun, 30 May 2010 18:24:00 -0400
Subject: [R-sig-ME] sanity-checking plans for glmer
Message-ID: <AANLkTinMj2_AO64QgMcRU9WqgF1YxEjxkp0PklPc_PM1@mail.gmail.com>

Having briefly fallen for the notion that the negative.binomial family
in MASS could be used in glmer, I want to use these lists for a sanity
check on my final (?) plans.

I want to use glmer for logistic regression and for poisson regression
on a data set of 10,000 items.  There will be two crossed random
effects.

For the logistic regression, I want odds ratios with confidence
intervals.For the poisson regression, I'd want multiplying factors,
again with confidence intervals. Either way, my co-authors will want
p-values.  I'd also like to examine whether the two random effects
have comparable variation, and whether any of them are provide odds
ratios or multipliers that are are statistically distinct from 1.0 .

Can I use the s.e's and p-values (from z-statistics) provided by
glmer?  Or should I use the pvals.fnc function from the language R
package?

Are there any holes in my plans I'm not seeing?

Thanks in advance.



From albart at dairyconsult.nl  Mon May 31 15:49:19 2010
From: albart at dairyconsult.nl (Albart Coster)
Date: Mon, 31 May 2010 15:49:19 +0200
Subject: [R-sig-ME] Random effect with two contributions for each record
Message-ID: <4C03BE5F.8070009@dairyconsult.nl>

Dear list,

I am working with genetic data and puzzling with the following problem. 
An individual inherits one allele from each of his parents and both 
alleles contribute an unknown quantity to its phenotype. If we want to 
model his phenotype, we can write it as P = a0 + a1. Now, imagine that 
we have 3 alleles, numbered 1, 2, and 3. Then, we can have the following 
individuals:

i1: 11
i2: 12
i3: 13
i4: 22
i5: 23
i6: 33

if the order of the alleles does not matter. Now, I would like to fit 
this in a model where the effect of the alleles is random and with a 
single variance term for all the alleles. The problem is that each 
individual can have 0, 1, or 2 copies of each allele while in the normal 
(Z) matrix of a mixed model we can only have 0's and 1's. Fitting it as 
follows in lme4 will not give the correct solutions:

lmer(P~1 + (1|a0) + (1|a1),data = df)

if I have a data.frame with three columns, P is the phenotype, a1 is the 
first allele and a2 is the second allele.

Thanks in advance for considering this,

Albart Coster



From sven.demaeyer at ua.ac.be  Mon May 31 15:47:29 2010
From: sven.demaeyer at ua.ac.be (Sven De Maeyer)
Date: Mon, 31 May 2010 15:47:29 +0200
Subject: [R-sig-ME] complex residual variance
Message-ID: <FF7B1337-4CE2-4A1D-A19E-84203147BBA8@ua.ac.be>

Hi all,

I'm not a frequent user of Lme4 and I have the habit to use mlwin for  
multilevel analyses. Nevertheless I'm willing to master lme4 further.

In my research I'm often faced with the situation where level 1  
variance (or residual variance in the mixed effects framework) isn't  
constant. E.g. I have longitudinal data on children, with multiple  
measurements (observations) of these children at a certain moment. As  
children get older these measurements seem to vary more and more. So  
the residual variance itself is a function of time. As a consequence  
there is heteroscedasticity.  Is there a possibility to explicitly  
model this in lme4? I know how to do it in mlwin, but is it possible  
in lmer?

With kind regards

Sven De Maeyer



From bates at stat.wisc.edu  Mon May 31 16:12:50 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 31 May 2010 09:12:50 -0500
Subject: [R-sig-ME] complex residual variance
In-Reply-To: <FF7B1337-4CE2-4A1D-A19E-84203147BBA8@ua.ac.be>
References: <FF7B1337-4CE2-4A1D-A19E-84203147BBA8@ua.ac.be>
Message-ID: <AANLkTimEswD8D4hFzlHfAZWgyeMui65vaPLOcSoU774y@mail.gmail.com>

On Mon, May 31, 2010 at 8:47 AM, Sven De Maeyer <sven.demaeyer at ua.ac.be> wrote:
> Hi all,
>
> I'm not a frequent user of Lme4 and I have the habit to use mlwin for
> multilevel analyses. Nevertheless I'm willing to master lme4 further.
>
> In my research I'm often faced with the situation where level 1 variance (or
> residual variance in the mixed effects framework) isn't constant. E.g. I
> have longitudinal data on children, with multiple measurements
> (observations) of these children at a certain moment. As children get older
> these measurements seem to vary more and more. So the residual variance
> itself is a function of time. As a consequence there is heteroscedasticity.
> ?Is there a possibility to explicitly model this in lme4? I know how to do
> it in mlwin, but is it possible in lmer?

Not at present.



From Thierry.ONKELINX at inbo.be  Mon May 31 16:37:39 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 31 May 2010 16:37:39 +0200
Subject: [R-sig-ME] complex residual variance
In-Reply-To: <FF7B1337-4CE2-4A1D-A19E-84203147BBA8@ua.ac.be>
References: <FF7B1337-4CE2-4A1D-A19E-84203147BBA8@ua.ac.be>
Message-ID: <2E9C414912813E4EB981326983E0A1040730C77E@inboexch.inbo.be>

Not in lmer(). But you can do it with lme() from the nlme package.

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Sven 
> De Maeyer
> Verzonden: maandag 31 mei 2010 15:47
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] complex residual variance
> 
> Hi all,
> 
> I'm not a frequent user of Lme4 and I have the habit to use 
> mlwin for multilevel analyses. Nevertheless I'm willing to 
> master lme4 further.
> 
> In my research I'm often faced with the situation where level 
> 1 variance (or residual variance in the mixed effects
> framework) isn't constant. E.g. I have longitudinal data on 
> children, with multiple measurements (observations) of these 
> children at a certain moment. As children get older these 
> measurements seem to vary more and more. So the residual 
> variance itself is a function of time. As a consequence there 
> is heteroscedasticity.  Is there a possibility to explicitly 
> model this in lme4? I know how to do it in mlwin, but is it 
> possible in lmer?
> 
> With kind regards
> 
> Sven De Maeyer
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From djmuser at gmail.com  Mon May 31 18:14:09 2010
From: djmuser at gmail.com (Dennis Murphy)
Date: Mon, 31 May 2010 09:14:09 -0700
Subject: [R-sig-ME] [R] Post-hoc tests for repeated measures in balanced
	experimental design
In-Reply-To: <9EE20044-D02F-4461-AB45-D2D183572F8E@augenklinik.uni-wuerzburg.de>
References: <CFDB29C5-8809-4207-9813-3223C37C3290@augenklinik.uni-wuerzburg.de>
	<AANLkTimPQ2I2bRcqTaW4SEQd1aFgEoppPWOBXYJ-6UMQ@mail.gmail.com>
	<9EE20044-D02F-4461-AB45-D2D183572F8E@augenklinik.uni-wuerzburg.de>
Message-ID: <AANLkTilOgeTu2yY_JExxhcET2VIpMBZrjqFWFqLBqBwR@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100531/dbd6893a/attachment.pl>

From davidD at qimr.edu.au  Tue Jun  1 00:55:32 2010
From: davidD at qimr.edu.au (David Duffy)
Date: Tue, 1 Jun 2010 08:55:32 +1000 (EST)
Subject: [R-sig-ME] Random effect with two contributions for each record
In-Reply-To: <4C03BE5F.8070009@dairyconsult.nl>
References: <4C03BE5F.8070009@dairyconsult.nl>
Message-ID: <Pine.LNX.4.64.1006010837310.9895@orpheus.qimr.edu.au>

On Mon, 31 May 2010, Albart Coster wrote:

> I am working with genetic data and puzzling with the following problem. An 
> individual inherits one allele from each of his parents and both alleles 
> contribute an unknown quantity to its phenotype. If we want to model his 
> phenotype, we can write it as P = a0 + a1. Now, imagine that we have 3 
> alleles, numbered 1, 2, and 3. Then, we can have the following individuals:
>
> if the order of the alleles does not matter. Now, I would like to fit this in 
> a model where the effect of the alleles is random and with a single variance 
> term for all the alleles. The problem is that each individual can have 0, 1, 
> or 2 copies of each allele while in the normal (Z) matrix of a mixed model we 
> can only have 0's and 1's.

No, they can take any value, and this would be one approach to your 
setup.

> Fitting it as follows in lme4 will not give the 
> correct solutions:
>
> lmer(P~1 + (1|a0) + (1|a1),data = df)

If you were fitting a genotypic model, you would have P ~ (1|g), where g 
is a factor with six levels or six binary indicator variables.  If there 
were parent of origin effects, then your model as stated would be 
appropriate.  For the model under exchangability, you need three indicator 
variables representing the count of each allele type for each individual 
(just the same as in the fixed effects type model).

Cheers, David Duffy.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From bolker at ufl.edu  Tue Jun  1 02:01:51 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Mon, 31 May 2010 20:01:51 -0400
Subject: [R-sig-ME] sanity-checking plans for glmer
In-Reply-To: <AANLkTinMj2_AO64QgMcRU9WqgF1YxEjxkp0PklPc_PM1@mail.gmail.com>
References: <AANLkTinMj2_AO64QgMcRU9WqgF1YxEjxkp0PklPc_PM1@mail.gmail.com>
Message-ID: <4C044DEF.2040002@ufl.edu>

Mitchell Maltenfort wrote:
> Having briefly fallen for the notion that the negative.binomial family
> in MASS could be used in glmer, I want to use these lists for a sanity
> check on my final (?) plans.
> 
> I want to use glmer for logistic regression and for poisson regression
> on a data set of 10,000 items.  There will be two crossed random
> effects.
> 
> For the logistic regression, I want odds ratios with confidence
> intervals.For the poisson regression, I'd want multiplying factors,
> again with confidence intervals. Either way, my co-authors will want
> p-values.  I'd also like to examine whether the two random effects
> have comparable variation, and whether any of them are provide odds
> ratios or multipliers that are are statistically distinct from 1.0 .
> 
> Can I use the s.e's and p-values (from z-statistics) provided by
> glmer?  Or should I use the pvals.fnc function from the language R
> package?
> 
> Are there any holes in my plans I'm not seeing?
> 

  [cross-posting to multiple R lists is discouraged.]

  How difficult this is, practically, depends on how many random-effects
levels you have (in the random effect with the minimum number of
random-effect levels).  If this number is large (>50?  Angrist and
Pischke give "42" as the rule of thumb in their Douglas-Adams-themed
econometrics book ...), then you can get away with Wald-Z or likelihood
ratio inferences without worrying about adjusting for finite-sample
effects (i.e., use anova() or the s.e.'s and p-values provided by
glmer).  For the random effects, use anova() [or possibly the RLRsim
package, although I don't know if it will work in this case].
Confidence intervals on the random effects are harder; see the "standard
 errors of variance estimates" section in <http://glmm.wikidot.com/faq>.
 (It says there that you can use lme4a, the bleeding-edge R-forge
version of lme4, for profiles, but as of a couple of days ago profiles
weren't available for GLMMs ...)

   pvals.fnc from the languageR function hasn't worked for a while, as
far as I know, because it uses the mcmcsamp() function which has been
disabled for some months (due to difficulty getting the sampling
algorithm to mix reliably).

  MCMCglmm would be a reasonable alternative -- I don't know how slow it
would be with 10,000 items, I have used it successfully for a problem
with 1600, so it should definitely work given that you're willing to be
patient.

  good luck,
    Ben Bolker



From Ulrich.Halekoh at agrsci.dk  Tue Jun  1 15:16:10 2010
From: Ulrich.Halekoh at agrsci.dk (Ulrich Halekoh)
Date: Tue, 1 Jun 2010 15:16:10 +0200
Subject: [R-sig-ME] update-function: frame problem with lmer-fit
Message-ID: <9F0721FDD4F12D4B95AD894274F388EC01D27F2C7572@DJFEXMBX01.djf.agrsci.dk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100601/b7e3dc23/attachment.pl>

From Mike.Lawrence at dal.ca  Tue Jun  1 18:28:53 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Tue, 1 Jun 2010 13:28:53 -0300
Subject: [R-sig-ME] Likelihood ratios
Message-ID: <AANLkTilHsOd0nigMWyM1_dTpdAHm5Ayvt6wvxNopkTPg@mail.gmail.com>

Hi folks,

I have 2 lmer fits, one (fit1) nested in the other (fit2), and I'd
like to compute the likelihood ratio comparing the models so I can say
something like "there is X times more evidence for fit1 than for fit2"
(as in Glover & Dixon, 2004, www.ncbi.nlm.nih.gov/pubmed/15732688).

I know I can use anova(fit1,fit2) to obtain a null-hypothesis
significance test of the fits, and I suspect the output also contains
the information I need to make my evidentiary statement, but I'm not
confident of what I'm doing here. Is it correct that the reported
value of chi-square from anova() is simply the D of the likelihood
ratio test (http://en.wikipedia.org/wiki/Likelihood_ratio_test)? If
so, does it sound right that I can simply derive the
complexity-corrected likelihood ratio as:

LR = exp( -2 * anova( fit1 , fit2 )$Chisq[2] )

?


Mike

-- 
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~



From Mike.Lawrence at dal.ca  Tue Jun  1 18:50:43 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Tue, 1 Jun 2010 13:50:43 -0300
Subject: [R-sig-ME] Likelihood ratios
In-Reply-To: <AANLkTilHsOd0nigMWyM1_dTpdAHm5Ayvt6wvxNopkTPg@mail.gmail.com>
References: <AANLkTilHsOd0nigMWyM1_dTpdAHm5Ayvt6wvxNopkTPg@mail.gmail.com>
Message-ID: <AANLkTimTIBZc6Uar4xmLK3tisr-cpj-AmBqgABIYg4ND@mail.gmail.com>

oops, I guess that should be:

LR = exp( anova( fit1 , fit2 )$Chisq[2] / -2 )


On Tue, Jun 1, 2010 at 1:28 PM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
> Hi folks,
>
> I have 2 lmer fits, one (fit1) nested in the other (fit2), and I'd
> like to compute the likelihood ratio comparing the models so I can say
> something like "there is X times more evidence for fit1 than for fit2"
> (as in Glover & Dixon, 2004, www.ncbi.nlm.nih.gov/pubmed/15732688).
>
> I know I can use anova(fit1,fit2) to obtain a null-hypothesis
> significance test of the fits, and I suspect the output also contains
> the information I need to make my evidentiary statement, but I'm not
> confident of what I'm doing here. Is it correct that the reported
> value of chi-square from anova() is simply the D of the likelihood
> ratio test (http://en.wikipedia.org/wiki/Likelihood_ratio_test)? If
> so, does it sound right that I can simply derive the
> complexity-corrected likelihood ratio as:
>
> LR = exp( -2 * anova( fit1 , fit2 )$Chisq[2] )
>
> ?
>
>
> Mike
>
> --
> Mike Lawrence
> Graduate Student
> Department of Psychology
> Dalhousie University
>
> Looking to arrange a meeting? Check my public calendar:
> http://tr.im/mikes_public_calendar
>
> ~ Certainty is folly... I think. ~
>



-- 
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~



From fengsj at mail.utexas.edu  Tue Jun  1 19:13:12 2010
From: fengsj at mail.utexas.edu (fengsj at mail.utexas.edu)
Date: Tue, 01 Jun 2010 12:13:12 -0500
Subject: [R-sig-ME] RLRsim example
In-Reply-To: <9F0721FDD4F12D4B95AD894274F388EC01D27F2C7572@DJFEXMBX01.djf.agrsci.dk>
References: <9F0721FDD4F12D4B95AD894274F388EC01D27F2C7572@DJFEXMBX01.djf.agrsci.dk>
Message-ID: <20100601121312.7dsw2b7i7408wk8g@webmail.utexas.edu>

Hi all,
I want to compare different glmer fits.  I read examples about  
comparing models by anova() for lmer fits and this method may not be  
accurate.  I have been checking the Package ?RLRsim? to do the test. I  
am very confused  by  the example from the package reference:

library(lme4)
data(sleepstudy)
mA <- lmer(Reaction ~ I(Days-4.5) + (1|Subject) + (0 +  
I(Days-4.5)|Subject), sleepstudy)
m0 <- update(mA, . ~ . - (0 + I(Days-4.5)|Subject))
m.slope <- update(mA, . ~ . - (1|Subject))
#test for subject specific slopes:
## Not run: exactRLRT(m.slope, mA, m0)

First of all, what does it mean ?not run? there? (when I did run  
exactRLRT(m.slope, mA, m0), I got error messages) . Then , what should  
be run?

Suppose I want to test if there is siginficant random slope based on I  
already have the random intercept, what should I do with exactRLRT?

Thanks so much!



From Mike.Lawrence at dal.ca  Tue Jun  1 20:08:44 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Tue, 1 Jun 2010 15:08:44 -0300
Subject: [R-sig-ME] Likelihood ratios
In-Reply-To: <AANLkTimTIBZc6Uar4xmLK3tisr-cpj-AmBqgABIYg4ND@mail.gmail.com>
References: <AANLkTilHsOd0nigMWyM1_dTpdAHm5Ayvt6wvxNopkTPg@mail.gmail.com> 
	<AANLkTimTIBZc6Uar4xmLK3tisr-cpj-AmBqgABIYg4ND@mail.gmail.com>
Message-ID: <AANLkTim3Wd2n-EGtQH1o_aylHQRCjMJv63QvBkRCWvDM@mail.gmail.com>

After posting this, I thought to contact Pete Dixon himself and indeed
it seems he already coded the functions to obtain a likelihood ratio
comparing two lmer models:

AIC_lmer = function(x){
	require(lme4)
	print(formula(attr(x,"call")))
	summary(x)@AICtab
}

LR_lmer = function(m0,m1){
	exp((AIC_lmer(m0)[[1]]-AIC_lmer(m1)[[1]])/2)
}

#example usage:
LR_lmer( my_fit1 , my_fit2 )



On Tue, Jun 1, 2010 at 1:50 PM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
> oops, I guess that should be:
>
> LR = exp( anova( fit1 , fit2 )$Chisq[2] / -2 )
>
>
> On Tue, Jun 1, 2010 at 1:28 PM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
>> Hi folks,
>>
>> I have 2 lmer fits, one (fit1) nested in the other (fit2), and I'd
>> like to compute the likelihood ratio comparing the models so I can say
>> something like "there is X times more evidence for fit1 than for fit2"
>> (as in Glover & Dixon, 2004, www.ncbi.nlm.nih.gov/pubmed/15732688).
>>
>> I know I can use anova(fit1,fit2) to obtain a null-hypothesis
>> significance test of the fits, and I suspect the output also contains
>> the information I need to make my evidentiary statement, but I'm not
>> confident of what I'm doing here. Is it correct that the reported
>> value of chi-square from anova() is simply the D of the likelihood
>> ratio test (http://en.wikipedia.org/wiki/Likelihood_ratio_test)? If
>> so, does it sound right that I can simply derive the
>> complexity-corrected likelihood ratio as:
>>
>> LR = exp( -2 * anova( fit1 , fit2 )$Chisq[2] )
>>
>> ?
>>
>>
>> Mike
>>
>> --
>> Mike Lawrence
>> Graduate Student
>> Department of Psychology
>> Dalhousie University
>>
>> Looking to arrange a meeting? Check my public calendar:
>> http://tr.im/mikes_public_calendar
>>
>> ~ Certainty is folly... I think. ~
>>
>
>
>
> --
> Mike Lawrence
> Graduate Student
> Department of Psychology
> Dalhousie University
>
> Looking to arrange a meeting? Check my public calendar:
> http://tr.im/mikes_public_calendar
>
> ~ Certainty is folly... I think. ~
>



-- 
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~



From Mike.Lawrence at dal.ca  Tue Jun  1 20:12:15 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Tue, 1 Jun 2010 15:12:15 -0300
Subject: [R-sig-ME] Likelihood ratios
In-Reply-To: <AANLkTim3Wd2n-EGtQH1o_aylHQRCjMJv63QvBkRCWvDM@mail.gmail.com>
References: <AANLkTilHsOd0nigMWyM1_dTpdAHm5Ayvt6wvxNopkTPg@mail.gmail.com> 
	<AANLkTimTIBZc6Uar4xmLK3tisr-cpj-AmBqgABIYg4ND@mail.gmail.com> 
	<AANLkTim3Wd2n-EGtQH1o_aylHQRCjMJv63QvBkRCWvDM@mail.gmail.com>
Message-ID: <AANLkTilapE5vjmR-O_NylPR5_VPbDIr0cEiPaczsnxsd@mail.gmail.com>

(sorry to spam!)

Pete Dixon also mentioned: "I think maybe you also have to do "REML=F"
in the lmer fits as well."

On Tue, Jun 1, 2010 at 3:08 PM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
> After posting this, I thought to contact Pete Dixon himself and indeed
> it seems he already coded the functions to obtain a likelihood ratio
> comparing two lmer models:
>
> AIC_lmer = function(x){
> ? ? ? ?require(lme4)
> ? ? ? ?print(formula(attr(x,"call")))
> ? ? ? ?summary(x)@AICtab
> }
>
> LR_lmer = function(m0,m1){
> ? ? ? ?exp((AIC_lmer(m0)[[1]]-AIC_lmer(m1)[[1]])/2)
> }
>
> #example usage:
> LR_lmer( my_fit1 , my_fit2 )
>
>
>
> On Tue, Jun 1, 2010 at 1:50 PM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
>> oops, I guess that should be:
>>
>> LR = exp( anova( fit1 , fit2 )$Chisq[2] / -2 )
>>
>>
>> On Tue, Jun 1, 2010 at 1:28 PM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
>>> Hi folks,
>>>
>>> I have 2 lmer fits, one (fit1) nested in the other (fit2), and I'd
>>> like to compute the likelihood ratio comparing the models so I can say
>>> something like "there is X times more evidence for fit1 than for fit2"
>>> (as in Glover & Dixon, 2004, www.ncbi.nlm.nih.gov/pubmed/15732688).
>>>
>>> I know I can use anova(fit1,fit2) to obtain a null-hypothesis
>>> significance test of the fits, and I suspect the output also contains
>>> the information I need to make my evidentiary statement, but I'm not
>>> confident of what I'm doing here. Is it correct that the reported
>>> value of chi-square from anova() is simply the D of the likelihood
>>> ratio test (http://en.wikipedia.org/wiki/Likelihood_ratio_test)? If
>>> so, does it sound right that I can simply derive the
>>> complexity-corrected likelihood ratio as:
>>>
>>> LR = exp( -2 * anova( fit1 , fit2 )$Chisq[2] )
>>>
>>> ?
>>>
>>>
>>> Mike
>>>
>>> --
>>> Mike Lawrence
>>> Graduate Student
>>> Department of Psychology
>>> Dalhousie University
>>>
>>> Looking to arrange a meeting? Check my public calendar:
>>> http://tr.im/mikes_public_calendar
>>>
>>> ~ Certainty is folly... I think. ~
>>>
>>
>>
>>
>> --
>> Mike Lawrence
>> Graduate Student
>> Department of Psychology
>> Dalhousie University
>>
>> Looking to arrange a meeting? Check my public calendar:
>> http://tr.im/mikes_public_calendar
>>
>> ~ Certainty is folly... I think. ~
>>
>
>
>
> --
> Mike Lawrence
> Graduate Student
> Department of Psychology
> Dalhousie University
>
> Looking to arrange a meeting? Check my public calendar:
> http://tr.im/mikes_public_calendar
>
> ~ Certainty is folly... I think. ~
>



-- 
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~



From fengsj at mail.utexas.edu  Tue Jun  1 20:19:16 2010
From: fengsj at mail.utexas.edu (fengsj at mail.utexas.edu)
Date: Tue, 01 Jun 2010 13:19:16 -0500
Subject: [R-sig-ME] RLRsim example
In-Reply-To: <AANLkTinFl8GDhoIUC-3SRcJkNIh0ybxn4-HU-Ki2M1Oh@mail.gmail.com>
References: <9F0721FDD4F12D4B95AD894274F388EC01D27F2C7572@DJFEXMBX01.djf.agrsci.dk>
	<20100601121312.7dsw2b7i7408wk8g@webmail.utexas.edu>
	<AANLkTinFl8GDhoIUC-3SRcJkNIh0ybxn4-HU-Ki2M1Oh@mail.gmail.com>
Message-ID: <20100601131916.cedqeax3k848ocos@webmail.utexas.edu>

I got :
> exactRLRT(m.slope, mA, m0)
Error in if (diff(anova(mA, m0)$df) > 1) { : argument is of length zero

Thanks!


Quoting Andy Fugard <andyfugard at gmail.com>:

> On Tue, Jun 1, 2010 at 7:13 PM,  <fengsj at mail.utexas.edu> wrote:
>> Hi all,
>> I want to compare different glmer fits. ?I read examples about comparing
>> models by anova() for lmer fits and this method may not be accurate. ?I have
>> been checking the Package 'RLRsim' to do the test. I am very confused ?by
>> ?the example from the package reference:
>>
>> library(lme4)
>> data(sleepstudy)
>> mA <- lmer(Reaction ~ I(Days-4.5) + (1|Subject) + (0 + I(Days-4.5)|Subject),
>> sleepstudy)
>> m0 <- update(mA, . ~ . - (0 + I(Days-4.5)|Subject))
>> m.slope <- update(mA, . ~ . - (1|Subject))
>> #test for subject specific slopes:
>> ## Not run: exactRLRT(m.slope, mA, m0)
>>
>> First of all, what does it mean "not run" there? (when I did run
>> exactRLRT(m.slope, mA, m0), I got error messages) . Then , what should be
>> run?
>
> What error messages did you get?  It would be helpful to see the
> complete output.
>
> Cheers,
>
> Andy
>
> --
> http://www.andyfugard.info
>



From fengsj at mail.utexas.edu  Tue Jun  1 20:24:42 2010
From: fengsj at mail.utexas.edu (fengsj at mail.utexas.edu)
Date: Tue, 01 Jun 2010 13:24:42 -0500
Subject: [R-sig-ME] Likelihood ratios
In-Reply-To: <AANLkTim3Wd2n-EGtQH1o_aylHQRCjMJv63QvBkRCWvDM@mail.gmail.com>
References: <AANLkTilHsOd0nigMWyM1_dTpdAHm5Ayvt6wvxNopkTPg@mail.gmail.com>
	<AANLkTimTIBZc6Uar4xmLK3tisr-cpj-AmBqgABIYg4ND@mail.gmail.com>
	<AANLkTim3Wd2n-EGtQH1o_aylHQRCjMJv63QvBkRCWvDM@mail.gmail.com>
Message-ID: <20100601132442.0z7p4rkgkgkogs44@webmail.utexas.edu>

Is there someting similar for glmer models?
Thanks!


Quoting Mike Lawrence <Mike.Lawrence at dal.ca>:

> After posting this, I thought to contact Pete Dixon himself and indeed
> it seems he already coded the functions to obtain a likelihood ratio
> comparing two lmer models:
>
> AIC_lmer = function(x){
> 	require(lme4)
> 	print(formula(attr(x,"call")))
> 	summary(x)@AICtab
> }
>
> LR_lmer = function(m0,m1){
> 	exp((AIC_lmer(m0)[[1]]-AIC_lmer(m1)[[1]])/2)
> }
>
> #example usage:
> LR_lmer( my_fit1 , my_fit2 )
>
>
>
> On Tue, Jun 1, 2010 at 1:50 PM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
>> oops, I guess that should be:
>>
>> LR = exp( anova( fit1 , fit2 )$Chisq[2] / -2 )
>>
>>
>> On Tue, Jun 1, 2010 at 1:28 PM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
>>> Hi folks,
>>>
>>> I have 2 lmer fits, one (fit1) nested in the other (fit2), and I'd
>>> like to compute the likelihood ratio comparing the models so I can say
>>> something like "there is X times more evidence for fit1 than for fit2"
>>> (as in Glover & Dixon, 2004, www.ncbi.nlm.nih.gov/pubmed/15732688).
>>>
>>> I know I can use anova(fit1,fit2) to obtain a null-hypothesis
>>> significance test of the fits, and I suspect the output also contains
>>> the information I need to make my evidentiary statement, but I'm not
>>> confident of what I'm doing here. Is it correct that the reported
>>> value of chi-square from anova() is simply the D of the likelihood
>>> ratio test (http://en.wikipedia.org/wiki/Likelihood_ratio_test)? If
>>> so, does it sound right that I can simply derive the
>>> complexity-corrected likelihood ratio as:
>>>
>>> LR = exp( -2 * anova( fit1 , fit2 )$Chisq[2] )
>>>
>>> ?
>>>
>>>
>>> Mike
>>>
>>> --
>>> Mike Lawrence
>>> Graduate Student
>>> Department of Psychology
>>> Dalhousie University
>>>
>>> Looking to arrange a meeting? Check my public calendar:
>>> http://tr.im/mikes_public_calendar
>>>
>>> ~ Certainty is folly... I think. ~
>>>
>>
>>
>>
>> --
>> Mike Lawrence
>> Graduate Student
>> Department of Psychology
>> Dalhousie University
>>
>> Looking to arrange a meeting? Check my public calendar:
>> http://tr.im/mikes_public_calendar
>>
>> ~ Certainty is folly... I think. ~
>>
>
>
>
> --
> Mike Lawrence
> Graduate Student
> Department of Psychology
> Dalhousie University
>
> Looking to arrange a meeting? Check my public calendar:
> http://tr.im/mikes_public_calendar
>
> ~ Certainty is folly... I think. ~
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bolker at ufl.edu  Wed Jun  2 01:25:56 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 01 Jun 2010 19:25:56 -0400
Subject: [R-sig-ME] Likelihood ratios
In-Reply-To: <20100601132442.0z7p4rkgkgkogs44@webmail.utexas.edu>
References: <AANLkTilHsOd0nigMWyM1_dTpdAHm5Ayvt6wvxNopkTPg@mail.gmail.com>	<AANLkTimTIBZc6Uar4xmLK3tisr-cpj-AmBqgABIYg4ND@mail.gmail.com>	<AANLkTim3Wd2n-EGtQH1o_aylHQRCjMJv63QvBkRCWvDM@mail.gmail.com>
	<20100601132442.0z7p4rkgkgkogs44@webmail.utexas.edu>
Message-ID: <4C059704.9080103@ufl.edu>

  Yes, or

exp(logLik(fit2,REML=FALSE)-logLik(fit1,REML=FALSE))


   What is a "complexity-corrected" likelihood ratio?
   I'm very nervous about mixing in the AIC penalty terms with the rest
of the likelihood ratio -- and, as I think has been pointed out, you
have to be careful to set REML=FALSE ...

fengsj at mail.utexas.edu wrote:
> Is there someting similar for glmer models?
> Thanks!
> 
> 
> Quoting Mike Lawrence <Mike.Lawrence at dal.ca>:
> 
>> After posting this, I thought to contact Pete Dixon himself and indeed
>> it seems he already coded the functions to obtain a likelihood ratio
>> comparing two lmer models:
>>
>> AIC_lmer = function(x){
>> 	require(lme4)
>> 	print(formula(attr(x,"call")))
>> 	summary(x)@AICtab
>> }
>>
>> LR_lmer = function(m0,m1){
>> 	exp((AIC_lmer(m0)[[1]]-AIC_lmer(m1)[[1]])/2)
>> }
>>
>> #example usage:
>> LR_lmer( my_fit1 , my_fit2 )
>>
>>
>>
>> On Tue, Jun 1, 2010 at 1:50 PM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
>>> oops, I guess that should be:
>>>
>>> LR = exp( anova( fit1 , fit2 )$Chisq[2] / -2 )
>>>
>>>
>>> On Tue, Jun 1, 2010 at 1:28 PM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
>>>> Hi folks,
>>>>
>>>> I have 2 lmer fits, one (fit1) nested in the other (fit2), and I'd
>>>> like to compute the likelihood ratio comparing the models so I can say
>>>> something like "there is X times more evidence for fit1 than for fit2"
>>>> (as in Glover & Dixon, 2004, www.ncbi.nlm.nih.gov/pubmed/15732688).
>>>>
>>>> I know I can use anova(fit1,fit2) to obtain a null-hypothesis
>>>> significance test of the fits, and I suspect the output also contains
>>>> the information I need to make my evidentiary statement, but I'm not
>>>> confident of what I'm doing here. Is it correct that the reported
>>>> value of chi-square from anova() is simply the D of the likelihood
>>>> ratio test (http://en.wikipedia.org/wiki/Likelihood_ratio_test)? If
>>>> so, does it sound right that I can simply derive the
>>>> complexity-corrected likelihood ratio as:
>>>>
>>>> LR = exp( -2 * anova( fit1 , fit2 )$Chisq[2] )
>>>>
>>>> ?
>>>>
>>>>
>>>> Mike
>>>>
>>>> --
>>>> Mike Lawrence
>>>> Graduate Student
>>>> Department of Psychology
>>>> Dalhousie University
>>>>
>>>> Looking to arrange a meeting? Check my public calendar:
>>>> http://tr.im/mikes_public_calendar
>>>>
>>>> ~ Certainty is folly... I think. ~
>>>>
>>>
>>>
>>> --
>>> Mike Lawrence
>>> Graduate Student
>>> Department of Psychology
>>> Dalhousie University
>>>
>>> Looking to arrange a meeting? Check my public calendar:
>>> http://tr.im/mikes_public_calendar
>>>
>>> ~ Certainty is folly... I think. ~
>>>
>>
>>
>> --
>> Mike Lawrence
>> Graduate Student
>> Department of Psychology
>> Dalhousie University
>>
>> Looking to arrange a meeting? Check my public calendar:
>> http://tr.im/mikes_public_calendar
>>
>> ~ Certainty is folly... I think. ~
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
*** NEW E-MAIL ADDRESSES:
***   bbolker at gmail.com , bolker at math.mcmaster.ca
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From Maarten.deGroot at nib.si  Wed Jun  2 10:58:04 2010
From: Maarten.deGroot at nib.si (Maarten de Groot)
Date: Wed, 02 Jun 2010 10:58:04 +0200
Subject: [R-sig-ME] gamm
Message-ID: <4C061D1C.1080608@nib.si>

Dear list,

I would like to relate probability of responding animals to a signal 
variable. because the relationship is not linear, I used gam with 
binomial distribution. Till here there was no problem. However, the 
animals were used repeatedly for different values of the signal 
variable, I included the animal as a random factor (N = 26). Furthermore 
I have missing values, because some animals died during the process. 
When running the following model: M1<-gamm(call~s(signal variable), 
random=list(fanimal=~1), data=mydata,family=binomial), I encountered the 
following message:

Error in plot.window(...) : need finite 'xlim' values
In addition: Warning messages:
1: In min(x) : no non-missing arguments to min; returning Inf
2: In max(x) : no non-missing arguments to max; returning -Inf
3: In min(x) : no non-missing arguments to min; returning Inf
4: In max(x) : no non-missing arguments to max; returning -Inf

Can someone help what went wrong and give some advise on letting the 
model run correctly.

Kind regards,

Maarten de Groot



From bates at stat.wisc.edu  Wed Jun  2 16:26:11 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 2 Jun 2010 09:26:11 -0500
Subject: [R-sig-ME] update-function: frame problem with lmer-fit
In-Reply-To: <9F0721FDD4F12D4B95AD894274F388EC01D27F2C7572@DJFEXMBX01.djf.agrsci.dk>
References: <9F0721FDD4F12D4B95AD894274F388EC01D27F2C7572@DJFEXMBX01.djf.agrsci.dk>
Message-ID: <AANLkTikogMerWgctxtv32vaXzjPZVu96eGYYaYEF94VP@mail.gmail.com>

I don't think it would be a good idea to use the model frame from the
previous fit because you may end up modifying the data in some way
during the update.  Also, a model frame is slightly different from a
data frame.

I agree that your initial attempt should work.  It is a matter of
determining in exactly which environment the revised call should be
evaluated and that is always tricky.

Because I am in the midst of a lot of development on glmer, nlmer,
etc.  and you were good enough to discover several workarounds, I
think I will leave this problem on the "To Do" list.

On Tue, Jun 1, 2010 at 8:16 AM, Ulrich Halekoh <Ulrich.Halekoh at agrsci.dk> wrote:
> #Dear
> # I got a framing problem with the update function
> # on a lmer-fit
> # if -data-generation,
> # ? ?-lmer-fit,
> # ? ?-call to update,
> # are called from within the same function.
>
> # Example:
> # Using update ?on a lmer-fit 'gfit'
> # an the data 'ukkel' defined within
> # the function ?fam1:
> # I get the error message
>
> # Error in inherits(x, "data.frame") : object 'ukkel' not found
>
> # I found several work around(s), but I wonder whether 'update' should not
> # ?find the data.frame of the fitted object as it does for lm-objects.
>
>
> #Ulrich
>
>
> library(lme4)
> fam1<-function(){
> #data generation:
> ?set.seed(89)
> ?ukkel<- data.frame(y=rnorm(100),id=rep(c(1,2,3,4),25))
> #lmer fit:
> ?gfit<- lmer(y ~ ?1 + (1|id), data=ukkel)
> #update:
> ?update(gfit)
> }
>
> try(fam1())
>
> #providing the data frame explicitely in 'update' works:
> fam2<-function(){
> set.seed(89)
> #data generation:
> ukkel<- data.frame(y=rnorm(100),id=rep(c(1,2,3,4),25))
> #lmer fit:
> ?gfit<- lmer(y ~ ?1 + (1|id), data=ukkel)
> #update:
> ?update(gfit,data=gfit at frame)
> }
>
> try(fam2())
>
>
>
> #providing the data frame before calling the function works
>
> fam3<-function(){
> ?g<- lmer(y ~ ?1 +(1|id), data=ukkel)
> ?update(g)
> }
>
> set.seed(89)
> ukkel<- data.frame(y=rnorm(100),id=rep(c(1,2,3,4),25))
> fam3()
>
>
>
>
>
> ## The same like fam1 but with 'lm' instead of 'lmer' ?works
> rm(ukkel)
> ham1<-function(){
> ?ukkel<- data.frame(y=rnorm(100),id=rep(c(1,2,3,4),25))
> ?set.seed(89)
> ?g<- lm(y ~ ?1, data=ukkel)
> ?update(g)
> }
>
> ham1()
>
>
>
> Package lme4 version 0.999375-33
> R-version:
> platform ? ? ? i386-pc-mingw32
> arch ? ? ? ? ? i386
> os ? ? ? ? ? ? mingw32
> system ? ? ? ? i386, mingw32
> status
> major ? ? ? ? ?2
> minor ? ? ? ? ?11.0
> year ? ? ? ? ? 2010
> month ? ? ? ? ?04
> day ? ? ? ? ? ?22
> svn rev ? ? ? ?51801
> language ? ? ? R
> version.string R version 2.11.0 (2010-04-22)
>
> Kind regards
> Ulrich Halekoh
> Dept. of Genetics and Biotechnology
> Faculty of Agricultural Sciences
> Aarhus University
> Email: Ulrich.Halekoh at agrsci.dk<mailto:Ulrich.Halekoh at agrsci.dk>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From Mike.Lawrence at dal.ca  Wed Jun  2 17:01:23 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Wed, 2 Jun 2010 12:01:23 -0300
Subject: [R-sig-ME] Likelihood ratios
In-Reply-To: <4C059704.9080103@ufl.edu>
References: <AANLkTilHsOd0nigMWyM1_dTpdAHm5Ayvt6wvxNopkTPg@mail.gmail.com> 
	<AANLkTimTIBZc6Uar4xmLK3tisr-cpj-AmBqgABIYg4ND@mail.gmail.com> 
	<AANLkTim3Wd2n-EGtQH1o_aylHQRCjMJv63QvBkRCWvDM@mail.gmail.com> 
	<20100601132442.0z7p4rkgkgkogs44@webmail.utexas.edu>
	<4C059704.9080103@ufl.edu>
Message-ID: <AANLkTild2e8s9cOWDS2OVwBFnSG8MsOcHKBXnPl1c5Cz@mail.gmail.com>

By "complexity-corrected", I simply meant a likelihood ratio that
takes into account potential differences in the number of parameters
between models, penalizing the more complex model. In the Glover &
Dixon paper I cited in my original post, they compute a likelihood
ratio based on ANOVA sums of squares, then apply a complexity
correction factor (they show formulae for both AIC and BIC) to yield a
final ratio that I've been calling a "complexity-corrected likelihood
ratio". Sorry for causing confusion by using my idiosyncratic
nomenclature!

On Tue, Jun 1, 2010 at 8:25 PM, Ben Bolker <bolker at ufl.edu> wrote:
> ?Yes, or
>
> exp(logLik(fit2,REML=FALSE)-logLik(fit1,REML=FALSE))
>
>
> ? What is a "complexity-corrected" likelihood ratio?
> ? I'm very nervous about mixing in the AIC penalty terms with the rest
> of the likelihood ratio -- and, as I think has been pointed out, you
> have to be careful to set REML=FALSE ...
>
> fengsj at mail.utexas.edu wrote:
>> Is there someting similar for glmer models?
>> Thanks!
>>
>>
>> Quoting Mike Lawrence <Mike.Lawrence at dal.ca>:
>>
>>> After posting this, I thought to contact Pete Dixon himself and indeed
>>> it seems he already coded the functions to obtain a likelihood ratio
>>> comparing two lmer models:
>>>
>>> AIC_lmer = function(x){
>>> ? ? ?require(lme4)
>>> ? ? ?print(formula(attr(x,"call")))
>>> ? ? ?summary(x)@AICtab
>>> }
>>>
>>> LR_lmer = function(m0,m1){
>>> ? ? ?exp((AIC_lmer(m0)[[1]]-AIC_lmer(m1)[[1]])/2)
>>> }
>>>
>>> #example usage:
>>> LR_lmer( my_fit1 , my_fit2 )
>>>
>>>
>>>
>>> On Tue, Jun 1, 2010 at 1:50 PM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
>>>> oops, I guess that should be:
>>>>
>>>> LR = exp( anova( fit1 , fit2 )$Chisq[2] / -2 )
>>>>
>>>>
>>>> On Tue, Jun 1, 2010 at 1:28 PM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
>>>>> Hi folks,
>>>>>
>>>>> I have 2 lmer fits, one (fit1) nested in the other (fit2), and I'd
>>>>> like to compute the likelihood ratio comparing the models so I can say
>>>>> something like "there is X times more evidence for fit1 than for fit2"
>>>>> (as in Glover & Dixon, 2004, www.ncbi.nlm.nih.gov/pubmed/15732688).
>>>>>
>>>>> I know I can use anova(fit1,fit2) to obtain a null-hypothesis
>>>>> significance test of the fits, and I suspect the output also contains
>>>>> the information I need to make my evidentiary statement, but I'm not
>>>>> confident of what I'm doing here. Is it correct that the reported
>>>>> value of chi-square from anova() is simply the D of the likelihood
>>>>> ratio test (http://en.wikipedia.org/wiki/Likelihood_ratio_test)? If
>>>>> so, does it sound right that I can simply derive the
>>>>> complexity-corrected likelihood ratio as:
>>>>>
>>>>> LR = exp( -2 * anova( fit1 , fit2 )$Chisq[2] )
>>>>>
>>>>> ?
>>>>>
>>>>>
>>>>> Mike
>>>>>
>>>>> --
>>>>> Mike Lawrence
>>>>> Graduate Student
>>>>> Department of Psychology
>>>>> Dalhousie University
>>>>>
>>>>> Looking to arrange a meeting? Check my public calendar:
>>>>> http://tr.im/mikes_public_calendar
>>>>>
>>>>> ~ Certainty is folly... I think. ~
>>>>>
>>>>
>>>>
>>>> --
>>>> Mike Lawrence
>>>> Graduate Student
>>>> Department of Psychology
>>>> Dalhousie University
>>>>
>>>> Looking to arrange a meeting? Check my public calendar:
>>>> http://tr.im/mikes_public_calendar
>>>>
>>>> ~ Certainty is folly... I think. ~
>>>>
>>>
>>>
>>> --
>>> Mike Lawrence
>>> Graduate Student
>>> Department of Psychology
>>> Dalhousie University
>>>
>>> Looking to arrange a meeting? Check my public calendar:
>>> http://tr.im/mikes_public_calendar
>>>
>>> ~ Certainty is folly... I think. ~
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> --
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> *** NEW E-MAIL ADDRESSES:
> *** ? bbolker at gmail.com , bolker at math.mcmaster.ca
> bolker at ufl.edu / people.biology.ufl.edu/bolker
> GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~



From nikko at hailmail.net  Wed Jun  2 20:25:54 2010
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Wed, 02 Jun 2010 11:25:54 -0700
Subject: [R-sig-ME] (no subject)
In-Reply-To: <mailman.5.1275472802.10832.r-sig-mixed-models@r-project.org>
References: <mailman.5.1275472802.10832.r-sig-mixed-models@r-project.org>
Message-ID: <1275503154.1526.1378146561@webmail.messagingengine.com>

Hi Maarten,
I don't know how you are getting a plotting error from fitting a model?
But I suspect what you left out is that you did something like:
> M1<-gamm(call~s(signal variable), random=list(fanimal=~1), data=mydata,family=binomial)
> plot(M1)

and what you wanted is
> plot(M1$gam)

But with out more info that is the best I can do.

Nicholas



> ------------------------------
> 
> Message: 4
> Date: Wed, 02 Jun 2010 10:58:04 +0200
> From: Maarten de Groot <Maarten.deGroot at nib.si>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] gamm
> Message-ID: <4C061D1C.1080608 at nib.si>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
> 
> Dear list,
> 
> I would like to relate probability of responding animals to a signal 
> variable. because the relationship is not linear, I used gam with 
> binomial distribution. Till here there was no problem. However, the 
> animals were used repeatedly for different values of the signal 
> variable, I included the animal as a random factor (N = 26). Furthermore 
> I have missing values, because some animals died during the process. 
> When running the following model: M1<-gamm(call~s(signal variable), 
> random=list(fanimal=~1), data=mydata,family=binomial), I encountered the 
> following message:
> 
> Error in plot.window(...) : need finite 'xlim' values
> In addition: Warning messages:
> 1: In min(x) : no non-missing arguments to min; returning Inf
> 2: In max(x) : no non-missing arguments to max; returning -Inf
> 3: In min(x) : no non-missing arguments to min; returning Inf
> 4: In max(x) : no non-missing arguments to max; returning -Inf
> 
> Can someone help what went wrong and give some advise on letting the 
> model run correctly.
> 
> Kind regards,
> 
> Maarten de Groot
> 
> 
> 
> ------------------------------
> 
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> End of R-sig-mixed-models Digest, Vol 42, Issue 3
> *************************************************
>



From fengsj at mail.utexas.edu  Wed Jun  2 23:03:44 2010
From: fengsj at mail.utexas.edu (fengsj at mail.utexas.edu)
Date: Wed, 02 Jun 2010 16:03:44 -0500
Subject: [R-sig-ME] GLMM linearity checking
Message-ID: <20100602160344.i0m0lhcpw0w4sscc@webmail.utexas.edu>

I am sorry for asking this question here. It is more related to  
logistic regression.

I need to use GLMM (binomial(link = "logit")) )to fit my data. The  
dependent variable is 0 or 1 and  I'd like to do some roughly  
graphical checkings for my data to see if the responses of  
transformaed data are linear with respect to continuous predictors in  
general. How should I do this?

Thanks,



From fengsj at mail.utexas.edu  Thu Jun  3 18:22:57 2010
From: fengsj at mail.utexas.edu (Shujuan Feng)
Date: Thu, 3 Jun 2010 11:22:57 -0500
Subject: [R-sig-ME] fit fixed-effect GLMs within each level of the random
	factors
References: <AANLkTilHsOd0nigMWyM1_dTpdAHm5Ayvt6wvxNopkTPg@mail.gmail.com>	<AANLkTimTIBZc6Uar4xmLK3tisr-cpj-AmBqgABIYg4ND@mail.gmail.com>	<AANLkTim3Wd2n-EGtQH1o_aylHQRCjMJv63QvBkRCWvDM@mail.gmail.com>
	<20100601132442.0z7p4rkgkgkogs44@webmail.utexas.edu>
	<4C059704.9080103@ufl.edu>
Message-ID: <004101cb0339$60a47180$650aa8c0@utshujuanfeng>

Hi all,



Is there a function similar to"lmList" for GLM?  I'd like to fit 
fixed-effect GLMs within each level of the random factors to take a look at 
the distribution of estimated parameters.



Thanks



From bolker at ufl.edu  Thu Jun  3 18:25:43 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 03 Jun 2010 12:25:43 -0400
Subject: [R-sig-ME] GLMM linearity checking
In-Reply-To: <20100602160344.i0m0lhcpw0w4sscc@webmail.utexas.edu>
References: <20100602160344.i0m0lhcpw0w4sscc@webmail.utexas.edu>
Message-ID: <4C07D787.50003@ufl.edu>

fengsj at mail.utexas.edu wrote:
> I am sorry for asking this question here. It is more related to  
> logistic regression.
> 
> I need to use GLMM (binomial(link = "logit")) )to fit my data. The  
> dependent variable is 0 or 1 and  I'd like to do some roughly  
> graphical checkings for my data to see if the responses of  
> transformaed data are linear with respect to continuous predictors in  
> general. How should I do this?
> 
> Thanks,
> 

   how about

 m <- glmer(...,data=d)
 d$resid <- residuals(m)

 xyplot(resid~continuous_predictor_1,type=c("p","smooth"),data=d)

 ...

  Non-linearity on the transformed scale will appear as a (non-flat)
pattern of the (smoothed line fitted to the) residuals as a function of
the continuous predictors ...

  Ben Bolker



From bolker at ufl.edu  Thu Jun  3 18:33:55 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 03 Jun 2010 12:33:55 -0400
Subject: [R-sig-ME] fit fixed-effect GLMs within each level of the
 random factors
In-Reply-To: <004101cb0339$60a47180$650aa8c0@utshujuanfeng>
References: <AANLkTilHsOd0nigMWyM1_dTpdAHm5Ayvt6wvxNopkTPg@mail.gmail.com>	<AANLkTimTIBZc6Uar4xmLK3tisr-cpj-AmBqgABIYg4ND@mail.gmail.com>	<AANLkTim3Wd2n-EGtQH1o_aylHQRCjMJv63QvBkRCWvDM@mail.gmail.com>	<20100601132442.0z7p4rkgkgkogs44@webmail.utexas.edu>	<4C059704.9080103@ufl.edu>
	<004101cb0339$60a47180$650aa8c0@utshujuanfeng>
Message-ID: <4C07D973.2020702@ufl.edu>

  Not quite as convenient as lmList, but something like

  L <- lapply(split(yourdata,yourdata$random_factor),glm,
              family=...)
  sapply(L,coef)

  should work fine.

Shujuan Feng wrote:
> Hi all,
> 
> 
> 
> Is there a function similar to"lmList" for GLM?  I'd like to fit 
> fixed-effect GLMs within each level of the random factors to take a look at 
> the distribution of estimated parameters.
> 
> 
> 
> Thanks
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
*** NEW E-MAIL ADDRESSES:
***   bbolker at gmail.com , bolker at math.mcmaster.ca
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From fengsj at mail.utexas.edu  Thu Jun  3 19:10:59 2010
From: fengsj at mail.utexas.edu (Shujuan Feng)
Date: Thu, 3 Jun 2010 12:10:59 -0500
Subject: [R-sig-ME] GLMM linearity checking
References: <20100602160344.i0m0lhcpw0w4sscc@webmail.utexas.edu>
	<4C07D787.50003@ufl.edu>
Message-ID: <005301cb033f$bd28ecf0$650aa8c0@utshujuanfeng>

Thanks so much!

I read about Graphical checking for GLMM (transformed by the link Function) 
before fitting the model from a paper. I have difficulty in imaging how the 
0s and 1s are transformed by the ink. .....

I tried your suggestions and this way should give me more valuable checkings 
for the model. But because I have a lot of missing data, I could not put the 
residuals into the data. I got errors:

Error in `$<-.data.frame`(`*tmp*`, "resid", value = c(-0.776415  : 
replacement has 13580 rows, data has 68158

Is there any way to match residuals and the predictor?

I tried just plot(model), but it doesn't work for GLMM.



Thanks!!







----- Original Message ----- 
From: "Ben Bolker" <bolker at ufl.edu>
To: <fengsj at mail.utexas.edu>
Cc: <r-sig-mixed-models at r-project.org>
Sent: Thursday, June 03, 2010 11:25 AM
Subject: Re: [R-sig-ME] GLMM linearity checking


> fengsj at mail.utexas.edu wrote:
>> I am sorry for asking this question here. It is more related to
>> logistic regression.
>>
>> I need to use GLMM (binomial(link = "logit")) )to fit my data. The
>> dependent variable is 0 or 1 and  I'd like to do some roughly
>> graphical checkings for my data to see if the responses of
>> transformaed data are linear with respect to continuous predictors in
>> general. How should I do this?
>>
>> Thanks,
>>
>
>   how about
>
> m <- glmer(...,data=d)
> d$resid <- residuals(m)
>
> xyplot(resid~continuous_predictor_1,type=c("p","smooth"),data=d)
>
> ...
>
>  Non-linearity on the transformed scale will appear as a (non-flat)
> pattern of the (smoothed line fitted to the) residuals as a function of
> the continuous predictors ...
>
>  Ben Bolker



From bolker at ufl.edu  Thu Jun  3 20:37:58 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 03 Jun 2010 14:37:58 -0400
Subject: [R-sig-ME] GLMM linearity checking
In-Reply-To: <001501cb034a$5e1bbb10$650aa8c0@utshujuanfeng>
References: <20100602160344.i0m0lhcpw0w4sscc@webmail.utexas.edu><4C07D787.50003@ufl.edu>
	<005301cb033f$bd28ecf0$650aa8c0@utshujuanfeng>
	<001501cb034a$5e1bbb10$650aa8c0@utshujuanfeng>
Message-ID: <4C07F686.1040804@ufl.edu>

  [cc'ing back to r-sig-mixed]

  That was going to be my suggestion.
  Try omitting rows of the data set with NA predictors or responses
(na.omit() will work if your data frame does not have *other* columns
with NAs in them beyond those used in the model) before you start.


Shujuan Feng wrote:
> or maybe I can just delete the missing rows.
> 
> 
> ----- Original Message ----- 
> From: "Shujuan Feng" <fengsj at mail.utexas.edu>
> To: "Ben Bolker" <bolker at ufl.edu>
> Cc: <r-sig-mixed-models at r-project.org>
> Sent: Thursday, June 03, 2010 12:10 PM
> Subject: Re: [R-sig-ME] GLMM linearity checking
> 
> 
>> Thanks so much!
>>
>> I read about Graphical checking for GLMM (transformed by the link 
>> Function) before fitting the model from a paper. I have difficulty in 
>> imaging how the 0s and 1s are transformed by the ink. .....
>>
>> I tried your suggestions and this way should give me more valuable 
>> checkings for the model. But because I have a lot of missing data, I could 
>> not put the residuals into the data. I got errors:
>>
>> Error in `$<-.data.frame`(`*tmp*`, "resid", value = c(-0.776415  : 
>> replacement has 13580 rows, data has 68158
>>
>> Is there any way to match residuals and the predictor?
>>
>> I tried just plot(model), but it doesn't work for GLMM.
>>
>>
>>
>> Thanks!!
>>
>>
>>
>>
>>
>>
>>
>> ----- Original Message ----- 
>> From: "Ben Bolker" <bolker at ufl.edu>
>> To: <fengsj at mail.utexas.edu>
>> Cc: <r-sig-mixed-models at r-project.org>
>> Sent: Thursday, June 03, 2010 11:25 AM
>> Subject: Re: [R-sig-ME] GLMM linearity checking
>>
>>
>>> fengsj at mail.utexas.edu wrote:
>>>> I am sorry for asking this question here. It is more related to
>>>> logistic regression.
>>>>
>>>> I need to use GLMM (binomial(link = "logit")) )to fit my data. The
>>>> dependent variable is 0 or 1 and  I'd like to do some roughly
>>>> graphical checkings for my data to see if the responses of
>>>> transformaed data are linear with respect to continuous predictors in
>>>> general. How should I do this?
>>>>
>>>> Thanks,
>>>>
>>>   how about
>>>
>>> m <- glmer(...,data=d)
>>> d$resid <- residuals(m)
>>>
>>> xyplot(resid~continuous_predictor_1,type=c("p","smooth"),data=d)
>>>
>>> ...
>>>
>>>  Non-linearity on the transformed scale will appear as a (non-flat)
>>> pattern of the (smoothed line fitted to the) residuals as a function of
>>> the continuous predictors ...
>>>
>>>  Ben Bolker
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models 
> 


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
*** NEW E-MAIL ADDRESSES:
***   bbolker at gmail.com , bolker at math.mcmaster.ca
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From kyler at mail.smu.edu  Thu Jun  3 21:15:16 2010
From: kyler at mail.smu.edu (Roberts, Kyle)
Date: Thu, 3 Jun 2010 14:15:16 -0500
Subject: [R-sig-ME] Cross-classified multiple membership models
In-Reply-To: <4C07F686.1040804@ufl.edu>
Message-ID: <C82D6974.8B24%kyler@smu.edu>

Dear All,

Is it possible to perform a cross-classified multiple membership model with lmer? Here's the data scenario. I have mathematics data for 2500 kids across four measurement occasions. At each occasion, they are in a separate teacher's classroom (cross-classified, not truly nested). However, there are times that the kids are taking more than one math course during that semester (multiple membership; for example, in a remedial math course AND in another math course with their cohort). Here's an example:

id      time        teacher     score
1       1           1005        118
1       2           1021        125
1       2           1024        125
1       3           1151        139
1       4           1148        164

See how at time==2, person 1 is in two separate math courses, but receives the same score for both "rows" of data since the administration of the instrument occurred only once at that time point.

When I looked through the archive, I found one reference from Doug a year ago that said that he didn't think this was possible yet. However, I thought that maybe someone worked a solution since then.

http://finzi.psych.upenn.edu/R-sig-mixed-models/2009q1/002080.html

Thanks,
Kyle



From fengsj at mail.utexas.edu  Thu Jun  3 21:40:27 2010
From: fengsj at mail.utexas.edu (Shujuan Feng)
Date: Thu, 3 Jun 2010 14:40:27 -0500
Subject: [R-sig-ME] GLMM linearity checking
References: <20100602160344.i0m0lhcpw0w4sscc@webmail.utexas.edu><4C07D787.50003@ufl.edu>
	<005301cb033f$bd28ecf0$650aa8c0@utshujuanfeng>
	<001501cb034a$5e1bbb10$650aa8c0@utshujuanfeng>
	<4C07F686.1040804@ufl.edu>
Message-ID: <002901cb0354$9ec6b570$650aa8c0@utshujuanfeng>

Thanks Ben, it works.

Then I feel there may be problems with the model by looking at the residul 
plots.

When I just plot the residuals, I get two big group values (the plots of 
residual~predicotr are also like this). See the attach file: residaul.jpeg.

I have difficulty in imaging the residuals in GLM with the original 
dependent are 0s or 1s. Residuals should be the difference between the 
observed and the predicted.  I can understand the predicted in terms of 
transformed scale(logit), but I don't know how the observed 0s and 1s are 
transformed. Are the two group residual values from the 0s and 1s 
respectively?  Have anyone see such residuals?

Thanks!



PS: In my model, I have three continuous predictors, the dependent are 0s or 
1s and I use binomial(link = "logit"). I tried GLMM and also just GLM, I got 
similar residual plots.









----- Original Message ----- 
From: "Ben Bolker" <bolker at ufl.edu>
To: "Shujuan Feng" <fengsj at mail.utexas.edu>
Cc: "R Mixed Models" <r-sig-mixed-models at r-project.org>
Sent: Thursday, June 03, 2010 1:37 PM
Subject: Re: [R-sig-ME] GLMM linearity checking


>  [cc'ing back to r-sig-mixed]
>
>  That was going to be my suggestion.
>  Try omitting rows of the data set with NA predictors or responses
> (na.omit() will work if your data frame does not have *other* columns
> with NAs in them beyond those used in the model) before you start.
>
>
> Shujuan Feng wrote:
>> or maybe I can just delete the missing rows.
>>
>>
>> ----- Original Message ----- 
>> From: "Shujuan Feng" <fengsj at mail.utexas.edu>
>> To: "Ben Bolker" <bolker at ufl.edu>
>> Cc: <r-sig-mixed-models at r-project.org>
>> Sent: Thursday, June 03, 2010 12:10 PM
>> Subject: Re: [R-sig-ME] GLMM linearity checking
>>
>>
>>> Thanks so much!
>>>
>>> I read about Graphical checking for GLMM (transformed by the link
>>> Function) before fitting the model from a paper. I have difficulty in
>>> imaging how the 0s and 1s are transformed by the ink. .....
>>>
>>> I tried your suggestions and this way should give me more valuable
>>> checkings for the model. But because I have a lot of missing data, I 
>>> could
>>> not put the residuals into the data. I got errors:
>>>
>>> Error in `$<-.data.frame`(`*tmp*`, "resid", value = c(-0.776415  :
>>> replacement has 13580 rows, data has 68158
>>>
>>> Is there any way to match residuals and the predictor?
>>>
>>> I tried just plot(model), but it doesn't work for GLMM.
>>>
>>>
>>>
>>> Thanks!!
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> ----- Original Message ----- 
>>> From: "Ben Bolker" <bolker at ufl.edu>
>>> To: <fengsj at mail.utexas.edu>
>>> Cc: <r-sig-mixed-models at r-project.org>
>>> Sent: Thursday, June 03, 2010 11:25 AM
>>> Subject: Re: [R-sig-ME] GLMM linearity checking
>>>
>>>
>>>> fengsj at mail.utexas.edu wrote:
>>>>> I am sorry for asking this question here. It is more related to
>>>>> logistic regression.
>>>>>
>>>>> I need to use GLMM (binomial(link = "logit")) )to fit my data. The
>>>>> dependent variable is 0 or 1 and  I'd like to do some roughly
>>>>> graphical checkings for my data to see if the responses of
>>>>> transformaed data are linear with respect to continuous predictors in
>>>>> general. How should I do this?
>>>>>
>>>>> Thanks,
>>>>>
>>>>   how about
>>>>
>>>> m <- glmer(...,data=d)
>>>> d$resid <- residuals(m)
>>>>
>>>> xyplot(resid~continuous_predictor_1,type=c("p","smooth"),data=d)
>>>>
>>>> ...
>>>>
>>>>  Non-linearity on the transformed scale will appear as a (non-flat)
>>>> pattern of the (smoothed line fitted to the) residuals as a function of
>>>> the continuous predictors ...
>>>>
>>>>  Ben Bolker
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
> -- 
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> *** NEW E-MAIL ADDRESSES:
> ***   bbolker at gmail.com , bolker at math.mcmaster.ca
> bolker at ufl.edu / people.biology.ufl.edu/bolker
> GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc 

From fengsj at mail.utexas.edu  Thu Jun  3 22:07:22 2010
From: fengsj at mail.utexas.edu (Shujuan Feng)
Date: Thu, 3 Jun 2010 15:07:22 -0500
Subject: [R-sig-ME] GLMM linearity checking
References: <20100602160344.i0m0lhcpw0w4sscc@webmail.utexas.edu><4C07D787.50003@ufl.edu><005301cb033f$bd28ecf0$650aa8c0@utshujuanfeng><001501cb034a$5e1bbb10$650aa8c0@utshujuanfeng><4C07F686.1040804@ufl.edu>
	<002901cb0354$9ec6b570$650aa8c0@utshujuanfeng>
Message-ID: <00a001cb0358$61801360$650aa8c0@utshujuanfeng>

The attach plot may not be visible.

The plot is like this : One big group residuals cluster around 1.2( from 1 
to 1.5), another big group residuals cluster around -0.8( from -0.6 to -1). 
There are no any values between -0.6 and 1.

 Thanks!







----- Original Message ----- 
From: "Shujuan Feng" <fengsj at mail.utexas.edu>
To: "R Mixed Models" <r-sig-mixed-models at r-project.org>
Sent: Thursday, June 03, 2010 2:40 PM
Subject: Re: [R-sig-ME] GLMM linearity checking


> Thanks Ben, it works.
>
> Then I feel there may be problems with the model by looking at the residul
> plots.
>
> When I just plot the residuals, I get two big group values (the plots of
> residual~predicotr are also like this). See the attach file: 
> residaul.jpeg.
>
> I have difficulty in imaging the residuals in GLM with the original
> dependent are 0s or 1s. Residuals should be the difference between the
> observed and the predicted.  I can understand the predicted in terms of
> transformed scale(logit), but I don't know how the observed 0s and 1s are
> transformed. Are the two group residual values from the 0s and 1s
> respectively?  Have anyone see such residuals?
>
> Thanks!
>
>
>
> PS: In my model, I have three continuous predictors, the dependent are 0s 
> or
> 1s and I use binomial(link = "logit"). I tried GLMM and also just GLM, I 
> got
> similar residual plots.
>
>
>
>
>
>
>
>
>
> ----- Original Message ----- 
> From: "Ben Bolker" <bolker at ufl.edu>
> To: "Shujuan Feng" <fengsj at mail.utexas.edu>
> Cc: "R Mixed Models" <r-sig-mixed-models at r-project.org>
> Sent: Thursday, June 03, 2010 1:37 PM
> Subject: Re: [R-sig-ME] GLMM linearity checking
>
>
>>  [cc'ing back to r-sig-mixed]
>>
>>  That was going to be my suggestion.
>>  Try omitting rows of the data set with NA predictors or responses
>> (na.omit() will work if your data frame does not have *other* columns
>> with NAs in them beyond those used in the model) before you start.
>>
>>
>> Shujuan Feng wrote:
>>> or maybe I can just delete the missing rows.
>>>
>>>
>>> ----- Original Message ----- 
>>> From: "Shujuan Feng" <fengsj at mail.utexas.edu>
>>> To: "Ben Bolker" <bolker at ufl.edu>
>>> Cc: <r-sig-mixed-models at r-project.org>
>>> Sent: Thursday, June 03, 2010 12:10 PM
>>> Subject: Re: [R-sig-ME] GLMM linearity checking
>>>
>>>
>>>> Thanks so much!
>>>>
>>>> I read about Graphical checking for GLMM (transformed by the link
>>>> Function) before fitting the model from a paper. I have difficulty in
>>>> imaging how the 0s and 1s are transformed by the ink. .....
>>>>
>>>> I tried your suggestions and this way should give me more valuable
>>>> checkings for the model. But because I have a lot of missing data, I
>>>> could
>>>> not put the residuals into the data. I got errors:
>>>>
>>>> Error in `$<-.data.frame`(`*tmp*`, "resid", value = c(-0.776415  :
>>>> replacement has 13580 rows, data has 68158
>>>>
>>>> Is there any way to match residuals and the predictor?
>>>>
>>>> I tried just plot(model), but it doesn't work for GLMM.
>>>>
>>>>
>>>>
>>>> Thanks!!
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> ----- Original Message ----- 
>>>> From: "Ben Bolker" <bolker at ufl.edu>
>>>> To: <fengsj at mail.utexas.edu>
>>>> Cc: <r-sig-mixed-models at r-project.org>
>>>> Sent: Thursday, June 03, 2010 11:25 AM
>>>> Subject: Re: [R-sig-ME] GLMM linearity checking
>>>>
>>>>
>>>>> fengsj at mail.utexas.edu wrote:
>>>>>> I am sorry for asking this question here. It is more related to
>>>>>> logistic regression.
>>>>>>
>>>>>> I need to use GLMM (binomial(link = "logit")) )to fit my data. The
>>>>>> dependent variable is 0 or 1 and  I'd like to do some roughly
>>>>>> graphical checkings for my data to see if the responses of
>>>>>> transformaed data are linear with respect to continuous predictors in
>>>>>> general. How should I do this?
>>>>>>
>>>>>> Thanks,
>>>>>>
>>>>>   how about
>>>>>
>>>>> m <- glmer(...,data=d)
>>>>> d$resid <- residuals(m)
>>>>>
>>>>> xyplot(resid~continuous_predictor_1,type=c("p","smooth"),data=d)
>>>>>
>>>>> ...
>>>>>
>>>>>  Non-linearity on the transformed scale will appear as a (non-flat)
>>>>> pattern of the (smoothed line fitted to the) residuals as a function 
>>>>> of
>>>>> the continuous predictors ...
>>>>>
>>>>>  Ben Bolker
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>> -- 
>> Ben Bolker
>> Associate professor, Biology Dep't, Univ. of Florida
>> *** NEW E-MAIL ADDRESSES:
>> ***   bbolker at gmail.com , bolker at math.mcmaster.ca
>> bolker at ufl.edu / people.biology.ufl.edu/bolker
>> GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc
>


--------------------------------------------------------------------------------


> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From datkins at u.washington.edu  Thu Jun  3 23:43:44 2010
From: datkins at u.washington.edu (David Atkins)
Date: Thu, 03 Jun 2010 14:43:44 -0700
Subject: [R-sig-ME] fit fixed-effect GLMs within each level of the
 random factors
In-Reply-To: <4C07D973.2020702@ufl.edu>
References: <4C07D973.2020702@ufl.edu>
Message-ID: <4C082210.2050902@u.washington.edu>


Ben et al.--

Methinks lmList() in lme4 package takes a family argument:

Arguments

formula 	a linear formula object of the form y ~ x1+...+xn | g. In the 
formula object, y represents the response, x1,...,xn the covariates, and 
g the grouping factor specifying the partitioning of the data according 
to which different lm fits should be performed.

data 	a data frame in which to interpret the variables named in object.

family 	an optional family specification for a generalized linear model.

[snip]

So, I don't think a workaround is needed.

cheers, Dave

-- 
Dave Atkins, PhD
Research Associate Professor
Department of Psychiatry and Behavioral Science
University of Washington
datkins at u.washington.edu

Center for the Study of Health and Risk Behaviors (CSHRB)		
1100 NE 45th Street, Suite 300 	
Seattle, WA  98105 	
206-616-3879 	
http://depts.washington.edu/cshrb/
(Mon-Wed)	

Center for Healthcare Improvement, for Addictions, Mental Illness,
   Medically Vulnerable Populations (CHAMMP)
325 9th Avenue, 2HH-15
Box 359911
Seattle, WA 98104?
206-897-4210
http://www.chammp.org
(Thurs)



From fengsj at mail.utexas.edu  Fri Jun  4 21:28:19 2010
From: fengsj at mail.utexas.edu (fengsj at mail.utexas.edu)
Date: Fri, 04 Jun 2010 14:28:19 -0500
Subject: [R-sig-ME] NAs from lmList(fit GLM) :fit fixed-effect
	GLMs	within each level of the random factors
In-Reply-To: <4C082210.2050902@u.washington.edu>
References: <4C07D973.2020702@ufl.edu> <4C082210.2050902@u.washington.edu>
Message-ID: <20100604142819.dh8v5n5k0k0kcsoo@webmail.utexas.edu>

I use lmList to fit GLM (logit, with 3 contious predictors) within  
each leavel of my random factor. I can get results but with some  
warnings. I think the reason for the warnings is because GLM(logit)  
can not be used or estimated within some levels. (The dependents are  
all 0 within some levels. There are some NA for some estimated  
coefficients in the results).
Is there a way to remove those lm objects with NA values from the  
lmList results? I cannot use plot(),intervals() for the lmList  
results(I guess it is because of those NAs )
Thanks!




Quoting David Atkins <datkins at u.washington.edu>:

>
> Ben et al.--
>
> Methinks lmList() in lme4 package takes a family argument:
>
> Arguments
>
> formula 	a linear formula object of the form y ~ x1+...+xn | g. In the
> formula object, y represents the response, x1,...,xn the covariates,
> and g the grouping factor specifying the partitioning of the data
> according to which different lm fits should be performed.
>
> data 	a data frame in which to interpret the variables named in object.
>
> family 	an optional family specification for a generalized linear model.
>
> [snip]
>
> So, I don't think a workaround is needed.
>
> cheers, Dave
>
> -- 
> Dave Atkins, PhD
> Research Associate Professor
> Department of Psychiatry and Behavioral Science
> University of Washington
> datkins at u.washington.edu
>
> Center for the Study of Health and Risk Behaviors (CSHRB)
> 1100 NE 45th Street, Suite 300
> Seattle, WA  98105
> 206-616-3879
> http://depts.washington.edu/cshrb/
> (Mon-Wed)
>
> Center for Healthcare Improvement, for Addictions, Mental Illness,
>   Medically Vulnerable Populations (CHAMMP)
> 325 9th Avenue, 2HH-15
> Box 359911
> Seattle, WA 98104?
> 206-897-4210
> http://www.chammp.org
> (Thurs)
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From fengsj at mail.utexas.edu  Fri Jun  4 23:09:04 2010
From: fengsj at mail.utexas.edu (fengsj at mail.utexas.edu)
Date: Fri, 04 Jun 2010 16:09:04 -0500
Subject: [R-sig-ME] NAs from lmList(fit GLM) :fit fixed-effect
	GLMs	within each level of the random factors
In-Reply-To: <20100604142819.dh8v5n5k0k0kcsoo@webmail.utexas.edu>
References: <4C07D973.2020702@ufl.edu> <4C082210.2050902@u.washington.edu>
	<20100604142819.dh8v5n5k0k0kcsoo@webmail.utexas.edu>
Message-ID: <20100604160904.tjkfn5u9s00k4woo@webmail.utexas.edu>

I just read about:? No definition of residuals is completely  
satisfactory for binary data (in GLM)?.  Does anyone know how to check  
linearity for GLM(M) with the binary data?
Thanks


Quoting fengsj at mail.utexas.edu:

> I use lmList to fit GLM (logit, with 3 contious predictors) within each
> leavel of my random factor. I can get results but with some warnings. I
> think the reason for the warnings is because GLM(logit) can not be used
> or estimated within some levels. (The dependents are all 0 within some
> levels. There are some NA for some estimated coefficients in the
> results).
> Is there a way to remove those lm objects with NA values from the
> lmList results? I cannot use plot(),intervals() for the lmList
> results(I guess it is because of those NAs )
> Thanks!
>
>
>
>
> Quoting David Atkins <datkins at u.washington.edu>:
>
>>
>> Ben et al.--
>>
>> Methinks lmList() in lme4 package takes a family argument:
>>
>> Arguments
>>
>> formula 	a linear formula object of the form y ~ x1+...+xn | g. In the
>> formula object, y represents the response, x1,...,xn the covariates,
>> and g the grouping factor specifying the partitioning of the data
>> according to which different lm fits should be performed.
>>
>> data 	a data frame in which to interpret the variables named in object.
>>
>> family 	an optional family specification for a generalized linear model.
>>
>> [snip]
>>
>> So, I don't think a workaround is needed.
>>
>> cheers, Dave
>>
>> -- 
>> Dave Atkins, PhD
>> Research Associate Professor
>> Department of Psychiatry and Behavioral Science
>> University of Washington
>> datkins at u.washington.edu
>>
>> Center for the Study of Health and Risk Behaviors (CSHRB)
>> 1100 NE 45th Street, Suite 300
>> Seattle, WA  98105
>> 206-616-3879
>> http://depts.washington.edu/cshrb/
>> (Mon-Wed)
>>
>> Center for Healthcare Improvement, for Addictions, Mental Illness,
>>  Medically Vulnerable Populations (CHAMMP)
>> 325 9th Avenue, 2HH-15
>> Box 359911
>> Seattle, WA 98104?
>> 206-897-4210
>> http://www.chammp.org
>> (Thurs)
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From arrayprofile at yahoo.com  Fri Jun  4 21:46:46 2010
From: arrayprofile at yahoo.com (array chip)
Date: Fri, 4 Jun 2010 12:46:46 -0700 (PDT)
Subject: [R-sig-ME] lmer() with no intercept
Message-ID: <39760.49561.qm@web56301.mail.re3.yahoo.com>

Hi, I am wondering how I can specify no intercept in a mixed model using lmer(). 


Here is an example dataset attached ("test.txt"). There are 3 workers, in 5 days, measured a response variable "y" on independent variable "x". I want to use a quadratic term (x2 in the dataset) to model the relationship between y and x.

test<-read.table("test.txt",sep='\t',header=T)

If I just simply use lm() and ignore worker and day, so that I can try both a linear regression with and without an intercept, here is what I get:

lm(y~x+x2, data=test)
Coefficients:
(Intercept)            x           x2  
-1.7749104    0.1099160   -0.0006152

lm(y~x+x2-1, data=test)
Coefficients:
         x          x2  
0.0490097  -0.0001962

Now, I want to try mixed model considering worker and day as random effect. 

With an intercept:

lmer(y~x+x2+(1|worker)+(1|day), data=test)
Fixed effects:
              Estimate Std. Error t value
(Intercept) -1.324e+00  4.490e-01  -2.948
x            1.117e-01  8.563e-03  13.041
x2          -6.357e-04  7.822e-05  -8.127

Without an intercept:

lmer(y~x+x2+(1|worker)+(1|day)-1, data=test)
Fixed effects:
     Estimate Std. Error t value
x   1.107e-01  8.528e-03  12.981
x2 -6.304e-04  7.805e-05  -8.077

It seems working fine. But if you look at the fixed effect coefficients of both mixed models, the coefficients for x and x2 are not much different, regardless of whether an intercept is included or not. This is not the case for simple linear regression using lm() on the top.

If I plot all 4 models in the following plot:

xyplot(y~x,groups=worker,test, col.line = "grey", lwd = 2,
, panel = function(x,y) { 
    panel.xyplot(x,y, type='p')
    x<-sort(x)
    panel.lines(x,-1.324+0.1117*x-0.0006357*x*x) 
    panel.lines(x,0.1107*x-0.0006304*x*x,col='red') 
    panel.lines(x,0.04901*x-0.0001962*x*x,col='blue') 
    panel.lines(x,-1.7749+0.10992*x-0.0006152*x*x,col='green') 


  }) 

As you can see, the mixed model without intercept (red line) does not fit the data very well (it's at the top edge of the data, instead of in the middle of the data), so I guess I did something wrong here.

Can anyone make any suggestions?

Thanks

John


      
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: test.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100604/9d1aa4bc/attachment.txt>

From c.ryan.king at gmail.com  Fri Jun  4 23:16:37 2010
From: c.ryan.king at gmail.com (Ryan King)
Date: Fri, 4 Jun 2010 16:16:37 -0500
Subject: [R-sig-ME] Representation of CHMfactor objects in Matrix package
Message-ID: <AANLkTimCE94WR86yiOLXDU7qhILXls_5qIh2A1j5K3wB@mail.gmail.com>

Hi,
I'm working a a mixed model problem which is slightly nonstandard, so
I have to do a bit of optimization by hand.

The general problem is that I have to repeatedly cholesky factor matrices like

Identity + C L t(L) C

where L is the cholesky root of a matrix which does not change each
iteration, and C is a diagonal matrix which does depend on parameters.
 C is not uniform, so I can not factor it out for a constant multiple
of identity.

I would like to use the fast update() method for CHMfactor objects
produced by Cholesky() to take care of the Identity part, and the
solve() method for the next stage after I decompose this matrix.
Since C is diagonal, it should be very easy to scale the rows of L and
still be a cholesky root.  The problem that I've run into is that I am
not sure about the internal representation of CHMfactor objects.

I understand the @x, @i, @p slots which code for some sparse matrix,
but I don't know which matrix that is.

How the @perms translate into the P matrix is also not clear to me.
Many of the remaining slots do not appear in the manual.

Sorry if this is just me being clumsy at S4.  Right now I just chol()
the above matrix at each step, which is unnecessarily slow.

Thanks,
Ryan King
University of Chicago, Department of Health Studies



From bates at stat.wisc.edu  Sat Jun  5 14:36:08 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 5 Jun 2010 07:36:08 -0500
Subject: [R-sig-ME] Representation of CHMfactor objects in Matrix package
In-Reply-To: <AANLkTimCE94WR86yiOLXDU7qhILXls_5qIh2A1j5K3wB@mail.gmail.com>
References: <AANLkTimCE94WR86yiOLXDU7qhILXls_5qIh2A1j5K3wB@mail.gmail.com>
Message-ID: <AANLkTikVnlQsK3hp1hDEvAHbyx_BswdKqujqTiv5lVHu@mail.gmail.com>

On Fri, Jun 4, 2010 at 4:16 PM, Ryan King <c.ryan.king at gmail.com> wrote:
> Hi,
> I'm working a a mixed model problem which is slightly nonstandard, so
> I have to do a bit of optimization by hand.
>
> The general problem is that I have to repeatedly cholesky factor matrices like
>
> Identity + C L t(L) C
>
> where L is the cholesky root of a matrix which does not change each
> iteration, and C is a diagonal matrix which does depend on parameters.
> ?C is not uniform, so I can not factor it out for a constant multiple
> of identity.
>
> I would like to use the fast update() method for CHMfactor objects
> produced by Cholesky() to take care of the Identity part, and the
> solve() method for the next stage after I decompose this matrix.
> Since C is diagonal, it should be very easy to scale the rows of L and
> still be a cholesky root. ?The problem that I've run into is that I am
> not sure about the internal representation of CHMfactor objects.
>
> I understand the @x, @i, @p slots which code for some sparse matrix,
> but I don't know which matrix that is.
>
> How the @perms translate into the P matrix is also not clear to me.
> Many of the remaining slots do not appear in the manual.
>
> Sorry if this is just me being clumsy at S4. ?Right now I just chol()
> the above matrix at each step, which is unnecessarily slow.

The representation of the Cholesky factor is based on the C struct
defined in the CHOLMOD package of C functions, which are included in
the sources for the Matrix package.  You could go through the
definition (in Matrix/src/CHOLMOD/Include/cholmod_core.h) and decide
how to update the structure but I think there is a simpler approach,
which is to update the sparse, positive definite matrix being factored
then update the factor.

It may seem that this is equivalent to using chol each time as you are
doing now but if you use the update method for a CHMfactor it bypasses
much of the effort in chol().  Most sparse matrix methods are
performed in two phase: a symbolic phase in which the number of
non-zeros in the result and their locations are calculated and a
numeric phase in which the actual values at these locations are
determined.  The update method only needs to perform the numeric
phase. Also, the update method allows you to add a multiple of the
identity matrix virtually during the decomposition process without
actually adding it to the matrix being decomposed.

If you are willing to use compiled code it is even faster because
there is a special scale operator that scales a symmetric matrix
symmetrically, i.e. your C %*% L %*% t(L) %*% C operation and a
special method for updating the decomposition with the virtual
multiple of the identity.



From elizabeth.crone at cfc.umt.edu  Sat Jun  5 18:34:53 2010
From: elizabeth.crone at cfc.umt.edu (Elizabeth Crone)
Date: Sat, 5 Jun 2010 10:34:53 -0600
Subject: [R-sig-ME] lmer() with no intercept (array chip)
Message-ID: <FDE3381E3E2B9945BDA9105DBBE2D608030533563976@pangaea.cfc.umt.edu>

> Hi, I am wondering how I can specify no intercept in a mixed model using lmer().

The intercept IS the term that varies randomly in both your models, i.e., (1|worker) and (1|day).  If you look at the terms you get, e.g., from coef() and ranef(), you should find that you are getting the same "intercept" terms for each group in the "no intercept" and "intercept" models, they are just parameterized differently.

If you want to play around with random effects, no intercept models, you need to make something other than the intercept vary among groups, e.g.,
y~x+x2+(x+x2|worker)+(x+x2|day) vs. y~-1 + x+x2+(-1+x+x2|worker)+(-1+x+x2|day)

Good luck!


From Mike.Lawrence at dal.ca  Sun Jun  6 03:22:55 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Sat, 5 Jun 2010 22:22:55 -0300
Subject: [R-sig-ME] A strange design; impossible to model using mixed models?
Message-ID: <AANLkTinG5KVCGGl0GT_C3adTZ2_9Em-ua-ByUZgbEUuI@mail.gmail.com>

Hi folks,

This is likely a case of an experimentalist (not me!) failing to
consult a statistician before applying an experimental design. I have
data where I'm interested in 3 theoretical variables derived from 2
manipulated variables, all measured within-Ss:

#set up the design
a = expand.grid(
	s = 1:100 #subjects
	, x = 1:4 #one predictor variable
	, y = 1:3 #second predictor variable
)
a$z = rnorm(nrow(a)) #fake data

#recode predictor variables
a$v1 = ifelse(a$x==1,-.5,ifelse(a$x==2,.5,NA)) #based on x
a$v2 = ifelse(a$x==3,-.5,ifelse(a$x==4,.5,NA)) #based on x
a$v3 = ifelse(a$y==1,-.5,ifelse(a$y==2,.5,NA)) #based on y


Now, obviously with such formulation, it's impossible to compute an
interaction between v1 and v2 because they're non-orthogonal, but it
is possible to compute the interactions between v1 & v3, and between
v2 and v3:

fit1 = lmer(
	z ~ v1 * v3 + ( 1 | s )
	, data = a
)

fit2 = lmer(
	z ~ v2 * v3 + ( 1 | s )
	, data = a
)

But I feel like it should be possible to do both above models
simultaneously (gaining accuracy in the estimation of the main effect
of v3), as:

fit = lmer(
	z ~
		v1 +
		v2 +
		v3 +
		v1:v3 +
		v2:v3 +
		( 1 | s )
	, data = a
)

However, I get the error:
Error in function (fr, FL, start, REML, verbose)  :
  Number of levels of a grouping factor for the random effects
must be less than the number of observations

Is it simply impossible to model the three variables simultaneously?

Mike

-- 
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~



From bates at stat.wisc.edu  Sun Jun  6 15:01:13 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 6 Jun 2010 08:01:13 -0500
Subject: [R-sig-ME] Cross-classified multiple membership models
In-Reply-To: <C82D6974.8B24%kyler@smu.edu>
References: <4C07F686.1040804@ufl.edu>
	<C82D6974.8B24%kyler@smu.edu>
Message-ID: <AANLkTinAgo6XpwcK23iPa-8yjp3S5kJgJPk9MaTrewqO@mail.gmail.com>

On Thu, Jun 3, 2010 at 2:15 PM, Roberts, Kyle <kyler at mail.smu.edu> wrote:
> Dear All,
>
> Is it possible to perform a cross-classified multiple membership model with lmer? Here's the data scenario. I have mathematics data for 2500 kids across four measurement occasions. At each occasion, they are in a separate teacher's classroom (cross-classified, not truly nested). However, there are times that the kids are taking more than one math course during that semester (multiple membership; for example, in a remedial math course AND in another math course with their cohort). Here's an example:
>
> id ? ? ?time ? ? ? ?teacher ? ? score
> 1 ? ? ? 1 ? ? ? ? ? 1005 ? ? ? ?118
> 1 ? ? ? 2 ? ? ? ? ? 1021 ? ? ? ?125
> 1 ? ? ? 2 ? ? ? ? ? 1024 ? ? ? ?125
> 1 ? ? ? 3 ? ? ? ? ? 1151 ? ? ? ?139
> 1 ? ? ? 4 ? ? ? ? ? 1148 ? ? ? ?164
>
> See how at time==2, person 1 is in two separate math courses, but receives the same score for both "rows" of data since the administration of the instrument occurred only once at that time point.

> When I looked through the archive, I found one reference from Doug a year ago that said that he didn't think this was possible yet. However, I thought that maybe someone worked a solution since then.

> http://finzi.psych.upenn.edu/R-sig-mixed-models/2009q1/002080.html

You can fit such a model but not easily in that you would need to
manually intervene between the stages of specifying the model and
fitting the model.

When you specify a model using the formula language the random-effects
terms are specified with respect to grouping factors (student,
instructor, etc.) and the assumption is that each observation is
associated with a unique level of each grouping factor.  That is not
the case here.

The matrix representation of the model does not require that it be
based on such random-effects terms.  It simply requires that the model
matrices can be specified.  This is why in the lme4a package (only on
R-forge) there is a distinction between the S4 class reModule
(random-effects module) and reTrms (random-effects module based on
formula terms).

What would need to be done in this case is to specify the model with
the usual formula for a unique teacher at each exam score then add the
extra teachers to the Z model matrix before fitting the model.

I can provide code to do this if you can give me some sample data.

  The computational methods for estimating the parameters in a
mixed-effects model are more general than the specification of models
using the formula language.



From bates at stat.wisc.edu  Sun Jun  6 15:16:01 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 6 Jun 2010 08:16:01 -0500
Subject: [R-sig-ME] A strange design;
	impossible to model using mixed 	models?
In-Reply-To: <AANLkTinG5KVCGGl0GT_C3adTZ2_9Em-ua-ByUZgbEUuI@mail.gmail.com>
References: <AANLkTinG5KVCGGl0GT_C3adTZ2_9Em-ua-ByUZgbEUuI@mail.gmail.com>
Message-ID: <AANLkTiksfjbylWNH9k_AA_rjaSDcJuN9CcZnq-VdctmM@mail.gmail.com>

On Sat, Jun 5, 2010 at 8:22 PM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
> Hi folks,
>
> This is likely a case of an experimentalist (not me!) failing to
> consult a statistician before applying an experimental design. I have
> data where I'm interested in 3 theoretical variables derived from 2
> manipulated variables, all measured within-Ss:
>
> #set up the design
> a = expand.grid(
> ? ? ? ?s = 1:100 #subjects
> ? ? ? ?, x = 1:4 #one predictor variable
> ? ? ? ?, y = 1:3 #second predictor variable
> )
> a$z = rnorm(nrow(a)) #fake data
>
> #recode predictor variables
> a$v1 = ifelse(a$x==1,-.5,ifelse(a$x==2,.5,NA)) #based on x
> a$v2 = ifelse(a$x==3,-.5,ifelse(a$x==4,.5,NA)) #based on x
> a$v3 = ifelse(a$y==1,-.5,ifelse(a$y==2,.5,NA)) #based on y
>
>
> Now, obviously with such formulation, it's impossible to compute an
> interaction between v1 and v2 because they're non-orthogonal, but it
> is possible to compute the interactions between v1 & v3, and between
> v2 and v3:
>
> fit1 = lmer(
> ? ? ? ?z ~ v1 * v3 + ( 1 | s )
> ? ? ? ?, data = a
> )
>
> fit2 = lmer(
> ? ? ? ?z ~ v2 * v3 + ( 1 | s )
> ? ? ? ?, data = a
> )
>
> But I feel like it should be possible to do both above models
> simultaneously (gaining accuracy in the estimation of the main effect
> of v3), as:
>
> fit = lmer(
> ? ? ? ?z ~
> ? ? ? ? ? ? ? ?v1 +
> ? ? ? ? ? ? ? ?v2 +
> ? ? ? ? ? ? ? ?v3 +
> ? ? ? ? ? ? ? ?v1:v3 +
> ? ? ? ? ? ? ? ?v2:v3 +
> ? ? ? ? ? ? ? ?( 1 | s )
> ? ? ? ?, data = a
> )
>
> However, I get the error:
> Error in function (fr, FL, start, REML, verbose) ?:
> ?Number of levels of a grouping factor for the random effects
> must be less than the number of observations
>
> Is it simply impossible to model the three variables simultaneously?

The way you have specified those variables, yes.
> str(a)
'data.frame':	1200 obs. of  7 variables:
 $ s : int  1 2 3 4 5 6 7 8 9 10 ...
 $ x : int  1 1 1 1 1 1 1 1 1 1 ...
 $ y : int  1 1 1 1 1 1 1 1 1 1 ...
 $ z : num  1.629 1.684 0.115 0.723 -0.415 ...
 $ v1: num  -0.5 -0.5 -0.5 -0.5 -0.5 -0.5 -0.5 -0.5 -0.5 -0.5 ...
 $ v2: num  NA NA NA NA NA NA NA NA NA NA ...
 $ v3: num  -0.5 -0.5 -0.5 -0.5 -0.5 -0.5 -0.5 -0.5 -0.5 -0.5 ...
 - attr(*, "out.attrs")=List of 2
  ..$ dim     : Named int  100 4 3
  .. ..- attr(*, "names")= chr  "s" "x" "y"
  ..$ dimnames:List of 3
  .. ..$ s: chr  "s=  1" "s=  2" "s=  3" "s=  4" ...
  .. ..$ x: chr  "x=1" "x=2" "x=3" "x=4"
  .. ..$ y: chr  "y=1" "y=2" "y=3"

> str(model.matrix(~ v1 + v2, a))
 num[0 , 1:3]
 - attr(*, "dimnames")=List of 2
  ..$ : NULL
  ..$ : chr [1:3] "(Intercept)" "v1" "v2"
 - attr(*, "assign")= int [1:3] 0 1 2

If you include both v1 and v2 in the model there are 0 observations
without missing data in one of the covariates.



From bertrand.servin at toulouse.inra.fr  Mon Jun  7 17:41:14 2010
From: bertrand.servin at toulouse.inra.fr (Bertrand Servin)
Date: Mon, 07 Jun 2010 17:41:14 +0200
Subject: [R-sig-ME] "Animal Model" plus logistic regression
Message-ID: <4C0D131A.2070706@toulouse.inra.fr>

Dear list,

I tried searching in the archive, but cannot seem to find a relevant
thread on my problem. I would like to fit a generalized linear
model (logit link) where the random effects are individuals and
I estimated (from genetic data) the expected correlation between
these random effects. This is sometimes called "Animal model" because
it is quite used in livestock genetics.

This could be a simple dataset:

library(lme4)

y=c(1,1,0,0)
ID=as.factor(1:4)
V=matrix(c(1,0.1,0.2,0.3,0.1,1,0,0,0.2,0,1,0,0.3,0,0,1),nrow=4,byrow=T)

The model is just logit(y) ~ mu + e

with Var(e)=V.sigma^2_a+I.sigma^2_e

So V is not to be estimated within the model fit, I just want to
get an estimate of sigma^2_a, and the model residuals.

I was thinking among these lines:

glmer(y~1|ID,family=binomial,doFit=FALSE)

and then modify something within this model.
Related question, how do I actually fit the model once
I made the modifications needed ?

Is this the right way to go ?

thanks for your help
-- 
Bertrand Servin



From corey.sparks at utsa.edu  Tue Jun  8 02:45:37 2010
From: corey.sparks at utsa.edu (Corey Sparks)
Date: Mon, 7 Jun 2010 19:45:37 -0500
Subject: [R-sig-ME] Help with glmmPQL using Scottish Lip Cancer data
References: <C832A896.2D16%corey.sparks@utsa.edu>
Message-ID: <8AE2B530-D97C-45B6-B887-3C0EFD161009@utsa.edu>

Dear list,
Please forgive the double posting ( i sent this to the geo sig as well)
>
> Dear List,
> I'm trying to replicate results from several sources that analyze the
> Clayton and Kaldor (1987) Scottish Lip Cancer data using a Poisson  
> GLMM with
> spatial correlation structure using a simple exponential variogram  
> model.
> The only way (I think) that my data are different from the published  
> data
> are that i'm using the Lat/Long instead of the OSGB projection.
>
> Here is what I've tried:
> scot<-read.csv("scotland.csv")
> names(scot)
> scot$aff<-scot$AFF/10
> scot$x<-scot$Longitude
> scot$y<-scot$Latitude
> scot$smr<-scot$Observed/scot$Expected
> scot$logsmr<-log(scot$smr+1)
> coordinates(scot)=~x+y
>
> library(MASS)
> library(nlme)
>
> #This is the first try, using the corEXP() directly in glmmPQL
>
> fit<-glmmPQL(Observed~offset(log(Expected))+aff,family=poisson,  
> data=scot,
> random=~1|District, correlation=corExp(form=~x+y), niter=200)
>
> #it fails with:
> iteration 1
> Error in corFactor.corSpatial(object) :
>  NA/NaN/Inf in foreign function call (arg 1)
> In addition: Warning messages:
> 1: In min(unlist(attr(object, "covariate"))) :
>  no non-missing arguments to min; returning Inf
> 2: In min(unlist(attr(object, "covariate"))) :
>  no non-missing arguments to min; returning Inf
>
>
> #Then I try to initialize the spatial correlation as in ASDAR
> sp2<-corSpatial( form=~x+y, type="exponential")
> spcor<-Initialize(sp2, as(scot, "data.frame")[,c("x","y")])
>
> glmmPQL(Observed~offset(log(Expected))+aff,family=poisson, data=scot,
> random=~1|District, correlation=spcor, niter=200, na.action="na.omit")
>
> #This fails with:
> iteration 1
> iteration 2
> iteration 3
> iteration 4
> iteration 5
> Error in lme.formula(fixed = zz ~ offset(log(Expected)) + aff,  
> random = ~1 |
> :
>  nlminb problem, convergence error code = 1
>  message = function evaluation limit reached without convergence (9)
>
> Basically, i'm wondering if  anyone can get this to work, because  
> i'm at my
> wits end.
>
>
> My system info is:
> sessionInfo()
> R version 2.11.1 (2010-05-31)
> x86_64-apple-darwin9.8.0
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] nlme_3.1-96  MASS_7.3-6   gstat_0.9-69 sp_0.9-64
>
> loaded via a namespace (and not attached):
> [1] grid_2.11.1    lattice_0.18-8 tools_2.11.1
>
>
> Best,
> Corey
>
> I'm pasting in the data, in case anyone wants to have a look:
>
> District,Observed,Expected,AFF,Latitude,Longitude
> 1,9,1.4,16,57.29,5.5
> 2,39,8.7,16,57.56,2.36
> 3,11,3,10,58.44,3.9
> 4,9,2.5,24,55.76,2.4
> 5,15,4.3,10,57.71,5.09
> 6,8,2.4,24,59.13,3.25
> 7,26,8.1,10,57.47,3.3
> 8,7,2.3,7,60.24,1.43
> 9,6,2,7,56.9,5.42
> 10,20,6.6,16,57.24,2.6
> 11,13,4.4,7,58.12,6.8
> 12,5,1.8,16,58.06,4.64
> 13,3,1.1,10,57.47,3.98
> 14,8,3.3,24,54.94,5
> 15,17,7.8,7,56.3,3.1
> 16,9,4.6,16,57,3
> 17,2,1.1,10,57.06,4.09
> 18,7,4.2,7,55.65,2.88
> 19,9,5.5,7,57.24,4.73
> 20,7,4.4,10,55.35,2.9
> 21,16,10.5,7,56.75,2.98
> 22,31,22.7,16,57.12,2.2
> 23,11,8.8,10,56.4,5.27
> 24,7,5.6,7,55.63,3.96
> 25,19,15.5,1,56.2,3.3
> 26,15,12.5,1,56.1,3.6
> 27,7,6,7,55.24,4.09
> 28,10,9,7,55.95,2.8
> 29,16,14.4,10,56.6,4.09
> 30,11,10.2,10,55.9,3.8
> 31,5,4.8,7,55.47,4.55
> 32,3,2.9,24,55,4.36
> 33,7,7,10,55.83,3.2
> 34,8,8.5,7,56.3,4.73
> 35,11,12.3,7,55.29,4.98
> 36,9,10.1,0,55.94,4.95
> 37,11,12.7,10,55.76,5.02
> 38,8,9.4,1,55.91,4.18
> 39,6,7.2,16,56.15,4.99
> 40,4,5.3,0,56.05,4.91
> 41,10,18.8,1,55.88,4.82
> 42,8,15.8,16,56.03,4
> 43,2,4.3,16,56.15,3.96
> 44,6,14.6,0,55.82,4.09
> 45,19,50.7,1,55.93,3.4
> 46,3,8.2,7,55.65,4.75
> 47,2,5.6,1,55.71,4.45
> 48,3,9.3,1,55.79,4.27
> 49,28,88.7,0,55.9,4.55
> 50,6,19.6,1,56.45,3.2
> 51,1,3.4,1,56,4.27
> 52,1,3.6,0,56.15,4.64
> 53,1,5.7,1,55.79,4.7
> 54,1,7,1,55.99,4.45
> 55,0,4.2,16,55.68,3.38
> 56,0,1.8,10,55.18,3.4
>
>
> -- 
> Corey Sparks
> Assistant Professor
> Department of Demography and Organization Studies
> University of Texas at San Antonio
> 501 West Durango Blvd
> Monterey Building 2.270C
> San Antonio, TX 78207
> 210-458-3166
> corey.sparks 'at' utsa.edu
> https://rowdyspace.utsa.edu/users/ozd504/www/index.htm
>



From Mike.Lawrence at dal.ca  Tue Jun  8 18:30:39 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Tue, 8 Jun 2010 13:30:39 -0300
Subject: [R-sig-ME] Random vs Fixed effect correlations
Message-ID: <AANLkTimdIau73tLXokH-j5n_JSevC0y-QmImY-sC6e36@mail.gmail.com>

Hi Folks,

I'm in the process of learning mixed modelling, and I'm having trouble
getting my head around the meaning of the correlations produced for
fixed effects when you do something like print( my_lmer_model , corr=T
). To possibly help you help me, I'll try to explain what I think I
*do* understand.

I understand that when you fit a model like "A ~ B + (1|C)", you're
letting each level of C have it's own intercept, but specify that
levels of C should be fit to a common slope for the effect of B.
Furthermore, I understand that when you fit a model like "A ~ B +
(1+B|C)", you're letting each level of C have it's own intercept *and*
it's own slope for the effect of B. I understand that this differs
from simply fitting individual models to each level of C in that in
mixed effects modelling, the variance observed in the data at each
level of C affects your confidence in that level's estimate of the
slope of B, and thus estimates with low confidence are shrunk towards
the mean estimate of B across levels of C. Finally, I understand that
when you have multiple random effects like "A ~ B + D + (1+B+D|C)",
you can compute a correlation between the per-Ss estimates of B and D
that take into account the shrinkage applied to the estimates.

What I don't understand is the fixed effects correlations obtained
when you fit a model like "A ~ B + D + (1|C)". In that model, I
thought that Ss are fit to common estimates of the slope for B and D,
so I don't understand over what these estimates are being correlated.

Could it be that the fixed-effects correlation between B & D is the
correlation across trials, ignoring levels of C? If so, would it then
be accurate to describe this correlation as a measure of the degree to
which measurement error in B & D are correlated? Furthermore, if there
are true correlations at the random effects level between B & D (for
example: such that levels of C with high B's also have high D), would
a model like "A ~ B + D + (1+B+D|C)" take this random effects
correlation into account when reporting the fixed effects correlation
between B & D? If not, I can imagine that in presence of correlations
at the random effects level would confound investigation of
correlations at the fixed effects level.

Would anyone care to attempt to ameliorate my confusions?

Mike

-- 
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~



From fengsj at mail.utexas.edu  Tue Jun  8 19:25:20 2010
From: fengsj at mail.utexas.edu (Shujuan Feng)
Date: Tue, 8 Jun 2010 12:25:20 -0500
Subject: [R-sig-ME] Random vs Fixed effect correlations
References: <AANLkTimdIau73tLXokH-j5n_JSevC0y-QmImY-sC6e36@mail.gmail.com>
Message-ID: <004d01cb072f$924a6ec0$650aa8c0@utshujuanfeng>

I was confused about the correlation between fixed coefficients. I am still 
not very sure about it.....

One thing is that the correlations between fixed coefficients also exist in 
the model without random effects. It is more like: how one coefficient 
estimate influence the other coefficient estimate. (We get point fixed 
estimate, but a fixed coefficient have a distribution and can vary (CIs).) 
Strong correlations between fixed coefficients may show there is 
collinearity between the predictors.

I may be totally off. I am in the process of learning, too.





----- Original Message ----- 
From: "Mike Lawrence" <Mike.Lawrence at dal.ca>
To: <r-sig-mixed-models at r-project.org>
Sent: Tuesday, June 08, 2010 11:30 AM
Subject: [R-sig-ME] Random vs Fixed effect correlations


> Hi Folks,
>
> I'm in the process of learning mixed modelling, and I'm having trouble
> getting my head around the meaning of the correlations produced for
> fixed effects when you do something like print( my_lmer_model , corr=T
> ). To possibly help you help me, I'll try to explain what I think I
> *do* understand.
>
> I understand that when you fit a model like "A ~ B + (1|C)", you're
> letting each level of C have it's own intercept, but specify that
> levels of C should be fit to a common slope for the effect of B.
> Furthermore, I understand that when you fit a model like "A ~ B +
> (1+B|C)", you're letting each level of C have it's own intercept *and*
> it's own slope for the effect of B. I understand that this differs
> from simply fitting individual models to each level of C in that in
> mixed effects modelling, the variance observed in the data at each
> level of C affects your confidence in that level's estimate of the
> slope of B, and thus estimates with low confidence are shrunk towards
> the mean estimate of B across levels of C. Finally, I understand that
> when you have multiple random effects like "A ~ B + D + (1+B+D|C)",
> you can compute a correlation between the per-Ss estimates of B and D
> that take into account the shrinkage applied to the estimates.
>
> What I don't understand is the fixed effects correlations obtained
> when you fit a model like "A ~ B + D + (1|C)". In that model, I
> thought that Ss are fit to common estimates of the slope for B and D,
> so I don't understand over what these estimates are being correlated.
>
> Could it be that the fixed-effects correlation between B & D is the
> correlation across trials, ignoring levels of C? If so, would it then
> be accurate to describe this correlation as a measure of the degree to
> which measurement error in B & D are correlated? Furthermore, if there
> are true correlations at the random effects level between B & D (for
> example: such that levels of C with high B's also have high D), would
> a model like "A ~ B + D + (1+B+D|C)" take this random effects
> correlation into account when reporting the fixed effects correlation
> between B & D? If not, I can imagine that in presence of correlations
> at the random effects level would confound investigation of
> correlations at the fixed effects level.
>
> Would anyone care to attempt to ameliorate my confusions?
>
> Mike
>
> -- 
> Mike Lawrence
> Graduate Student
> Department of Psychology
> Dalhousie University
>
> Looking to arrange a meeting? Check my public calendar:
> http://tr.im/mikes_public_calendar
>
> ~ Certainty is folly... I think. ~
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From Mike.Lawrence at dal.ca  Tue Jun  8 20:09:13 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Tue, 8 Jun 2010 15:09:13 -0300
Subject: [R-sig-ME] Random vs Fixed effect correlations
In-Reply-To: <004d01cb072f$924a6ec0$650aa8c0@utshujuanfeng>
References: <AANLkTimdIau73tLXokH-j5n_JSevC0y-QmImY-sC6e36@mail.gmail.com> 
	<004d01cb072f$924a6ec0$650aa8c0@utshujuanfeng>
Message-ID: <AANLkTinwUCN7oAe2btxhtCwIHa18jSmK2gezhYeD_gdT@mail.gmail.com>

Possibly a clue:

After playing with a few data sets, It seems that the fixed effects
correlation between B & D obtained from "A ~ B + D + (B + D | C)" is
consistently quite close to the value computed using the more
rudimentary "compute the score independently for each level of C"
approach. So maybe the fixed effects correlations report what you'd
likely see from the independent score method while the random-effects
correlations are what you get when you let the model shrink the
estimates?

On the other hand, it also seems that correlations involving the
intercept seem to differ dramatically between the fixed effects
correlations and the independent scores correlations.


On Tue, Jun 8, 2010 at 2:25 PM, Shujuan Feng <fengsj at mail.utexas.edu> wrote:
> I was confused about the correlation between fixed coefficients. I am still
> not very sure about it.....
>
> One thing is that the correlations between fixed coefficients also exist in
> the model without random effects. It is more like: how one coefficient
> estimate influence the other coefficient estimate. (We get point fixed
> estimate, but a fixed coefficient have a distribution and can vary (CIs).)
> Strong correlations between fixed coefficients may show there is
> collinearity between the predictors.
>
> I may be totally off. I am in the process of learning, too.
>
>
>
>
>
> ----- Original Message ----- From: "Mike Lawrence" <Mike.Lawrence at dal.ca>
> To: <r-sig-mixed-models at r-project.org>
> Sent: Tuesday, June 08, 2010 11:30 AM
> Subject: [R-sig-ME] Random vs Fixed effect correlations
>
>
>> Hi Folks,
>>
>> I'm in the process of learning mixed modelling, and I'm having trouble
>> getting my head around the meaning of the correlations produced for
>> fixed effects when you do something like print( my_lmer_model , corr=T
>> ). To possibly help you help me, I'll try to explain what I think I
>> *do* understand.
>>
>> I understand that when you fit a model like "A ~ B + (1|C)", you're
>> letting each level of C have it's own intercept, but specify that
>> levels of C should be fit to a common slope for the effect of B.
>> Furthermore, I understand that when you fit a model like "A ~ B +
>> (1+B|C)", you're letting each level of C have it's own intercept *and*
>> it's own slope for the effect of B. I understand that this differs
>> from simply fitting individual models to each level of C in that in
>> mixed effects modelling, the variance observed in the data at each
>> level of C affects your confidence in that level's estimate of the
>> slope of B, and thus estimates with low confidence are shrunk towards
>> the mean estimate of B across levels of C. Finally, I understand that
>> when you have multiple random effects like "A ~ B + D + (1+B+D|C)",
>> you can compute a correlation between the per-Ss estimates of B and D
>> that take into account the shrinkage applied to the estimates.
>>
>> What I don't understand is the fixed effects correlations obtained
>> when you fit a model like "A ~ B + D + (1|C)". In that model, I
>> thought that Ss are fit to common estimates of the slope for B and D,
>> so I don't understand over what these estimates are being correlated.
>>
>> Could it be that the fixed-effects correlation between B & D is the
>> correlation across trials, ignoring levels of C? If so, would it then
>> be accurate to describe this correlation as a measure of the degree to
>> which measurement error in B & D are correlated? Furthermore, if there
>> are true correlations at the random effects level between B & D (for
>> example: such that levels of C with high B's also have high D), would
>> a model like "A ~ B + D + (1+B+D|C)" take this random effects
>> correlation into account when reporting the fixed effects correlation
>> between B & D? If not, I can imagine that in presence of correlations
>> at the random effects level would confound investigation of
>> correlations at the fixed effects level.
>>
>> Would anyone care to attempt to ameliorate my confusions?
>>
>> Mike
>>
>> --
>> Mike Lawrence
>> Graduate Student
>> Department of Psychology
>> Dalhousie University
>>
>> Looking to arrange a meeting? Check my public calendar:
>> http://tr.im/mikes_public_calendar
>>
>> ~ Certainty is folly... I think. ~
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~



From jjclark at email.unc.edu  Tue Jun  8 21:21:54 2010
From: jjclark at email.unc.edu (jjclark)
Date: Tue, 08 Jun 2010 15:21:54 -0400
Subject: [R-sig-ME] corGaus specification
Message-ID: <aedf453e67219600b8f849ddfa2ec5a4@email.unc.edu>


I'm trying to run a linear mixed model with a spatial gaussian correlation
using the lme function.  I have a y, a linear term, x, and 5 additional
variables (z1,z2,z3,z4,z5) for each observation and am trying to build a
model with a random effect for each observation with the z variables used
in the gaussian correlation.  In SAS the following code builds this model:
proc mixed data=dat; 
class obs; 	
model y=x / ddfm=bw;	
random obs/type=sp(gau)(z1 z2 z3 z4 z5); 
run;

I am still fairly new to using R and have tried using the following code to
build this same model with no success:

cobs=factor(obs)
lme(y ~ x, dat, random = ~ 1|cobs, correlation = corGaus(form = ~
z1+z2+z3+z4+z5|cobs))

The code runs when I take out the correlation specification, but with it I
get the following error:
Error in corFactor.corSpatial(object) : NA/NaN/Inf in foreign function call
(arg 1)
In addition: Warning messages:
1: no non-missing arguments to min; returning Inf in:
min(unlist(attr(object, "covariate"))) 
2: no non-missing arguments to min; returning Inf in:
min(unlist(attr(object, "covariate")))

All the z?s are between 0 and 1 and are non-missing.  Can anyone give me
some pointers as to how to specify the Gaussian spatial correlation for
mixed models either here or perhaps in another R function?  Thank You!

Jennifer



From adik at ilovebacon.org  Wed Jun  9 00:54:18 2010
From: adik at ilovebacon.org (Adam D. I. Kramer)
Date: Tue, 8 Jun 2010 15:54:18 -0700 (PDT)
Subject: [R-sig-ME] Deviance tests and contrasts
Message-ID: <alpine.DEB.2.00.1006081542220.9543@parser.ilovebacon.org>

Dear colleagues,

 	Consider this data set:

d <- data.frame(subject=rep(1:40,each=5), sex=factor(rep(0:1,each=5,20)),
   condition=factor(rep(1:5,40)), score=rnorm(200), cov=rnorm(200) )

...and this model:

l <- lmer(score ~ sex * condition + cov + (1 + condition + cov | subject), data=d)

...I am aware of the problem with estimating p-values for t-values when we
don't know the degrees of freedom for t and how we have no good way to
estimate them. So, my usual go-to method for getting precise p-values in
this case is to do a deviance test, for example to test the covariate's
significance:

anova(l, update(l, . ~ . - cov))

...however, I know of no way to do this for a single R-generated contrast.
Could someone recommend a method of conducting a deviance test for the
effect coded by one of the contrasts for the condition factor?

Or in the simpler case,

l2 <- lmer(score ~ sex * condition + (1 + condition | subject), data=d)

...the main effect for sex, which has only one contrast?

Many thanks!
Adam



From davidD at qimr.edu.au  Wed Jun  9 05:51:59 2010
From: davidD at qimr.edu.au (David Duffy)
Date: Wed, 9 Jun 2010 13:51:59 +1000 (EST)
Subject: [R-sig-ME] Help with glmmPQL using Scottish Lip Cancer data
In-Reply-To: <8AE2B530-D97C-45B6-B887-3C0EFD161009@utsa.edu>
References: <C832A896.2D16%corey.sparks@utsa.edu>
	<8AE2B530-D97C-45B6-B887-3C0EFD161009@utsa.edu>
Message-ID: <Pine.LNX.4.64.1006091349530.23964@orpheus.qimr.edu.au>

On Mon, 7 Jun 2010, Corey Sparks wrote:

> glmmPQL(Observed~offset(log(Expected))+aff,family=poisson, data=scot,
> random=~1|District, correlation=spcor, niter=200, na.action="na.omit")

> nlminb problem, convergence error code = 1
> message = function evaluation limit reached without convergence (9)

When I added  control=lmeControl(opt="optim") to the above, it does 
converge.

FWIW, David Duffy.


-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From davidD at qimr.edu.au  Wed Jun  9 12:30:28 2010
From: davidD at qimr.edu.au (David Duffy)
Date: Wed, 9 Jun 2010 20:30:28 +1000 (EST)
Subject: [R-sig-ME] Deviance tests and contrasts
In-Reply-To: <alpine.DEB.2.00.1006081542220.9543@parser.ilovebacon.org>
References: <alpine.DEB.2.00.1006081542220.9543@parser.ilovebacon.org>
Message-ID: <Pine.LNX.4.64.1006092023370.6281@orpheus.qimr.edu.au>

On Tue, 8 Jun 2010, Adam D. I. Kramer wrote:

>
> l2 <- lmer(score ~ sex * condition + (1 + condition | subject), data=d)
>
> ...the main effect for sex, which has only one contrast?

Being very simple minded, I would have run something like:
l2 <- lmer(score ~ sex * condition + (1 + condition | subject), data=d)
l1 <- lmer(score ~ sex + condition + (1 + condition | subject), data=d)
l0 <- lmer(score ~ condition + (1 + condition | subject), data=d,
            subset=complete.cases(sex))
anova(l2, l1, l0)



-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From Thierry.ONKELINX at inbo.be  Wed Jun  9 14:09:44 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 9 Jun 2010 14:09:44 +0200
Subject: [R-sig-ME] corGaus specification
In-Reply-To: <aedf453e67219600b8f849ddfa2ec5a4@email.unc.edu>
References: <aedf453e67219600b8f849ddfa2ec5a4@email.unc.edu>
Message-ID: <2E9C414912813E4EB981326983E0A1040735B7E5@inboexch.inbo.be>

Dear Jennifer,

Have you tried to specify some staring values for the correlation. I
noticed that lme uses a fraction of the smallest distance between two
points as starting value for the range. Changing that value to a more
sensible one based a variogram yielded more realistic parameters for
range and nugget.

HTH,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens jjclark
> Verzonden: dinsdag 8 juni 2010 21:22
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] corGaus specification
> 
> 
> I'm trying to run a linear mixed model with a spatial 
> gaussian correlation using the lme function.  I have a y, a 
> linear term, x, and 5 additional variables (z1,z2,z3,z4,z5) 
> for each observation and am trying to build a model with a 
> random effect for each observation with the z variables used 
> in the gaussian correlation.  In SAS the following code 
> builds this model:
> proc mixed data=dat; 
> class obs; 	
> model y=x / ddfm=bw;	
> random obs/type=sp(gau)(z1 z2 z3 z4 z5); run;
> 
> I am still fairly new to using R and have tried using the 
> following code to build this same model with no success:
> 
> cobs=factor(obs)
> lme(y ~ x, dat, random = ~ 1|cobs, correlation = corGaus(form = ~
> z1+z2+z3+z4+z5|cobs))
> 
> The code runs when I take out the correlation specification, 
> but with it I get the following error:
> Error in corFactor.corSpatial(object) : NA/NaN/Inf in foreign 
> function call (arg 1) In addition: Warning messages:
> 1: no non-missing arguments to min; returning Inf in:
> min(unlist(attr(object, "covariate")))
> 2: no non-missing arguments to min; returning Inf in:
> min(unlist(attr(object, "covariate")))
> 
> All the z's are between 0 and 1 and are non-missing.  Can 
> anyone give me some pointers as to how to specify the 
> Gaussian spatial correlation for mixed models either here or 
> perhaps in another R function?  Thank You!
> 
> Jennifer
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From yvonnick.noel at free.fr  Thu Jun 10 17:29:08 2010
From: yvonnick.noel at free.fr (Yvonnick NOEL)
Date: Thu, 10 Jun 2010 17:29:08 +0200
Subject: [R-sig-ME] How to get family/link information from a fitted glmer
	model?
Message-ID: <1276183748.5009.4.camel@yvonnick-laptop>

Hello,

Everything's in the subject :-)

How could I get information about distribution family and link function
programmatically?

I tried:

family(my.glmer.model)

or

my.glmer.model at family

but this slot doesn't exist. Is there any other mean than parsing the
'call' string?

Thank you very much for this wonderful software.

Yvonnick Noel, PhD.
European University of Brittany
Dpt. of Psychology
France



From desja004 at umn.edu  Thu Jun 10 17:49:32 2010
From: desja004 at umn.edu (Christopher David Desjardins)
Date: Thu, 10 Jun 2010 10:49:32 -0500
Subject: [R-sig-ME] Predictive growth curve for a ZIP model in MCMCglmm
Message-ID: <4C11098C.9010505@umn.edu>

Hi,
I have the following model:

q2.schint<- MCMCglmm(sus~trait-1 + at.level(trait,1):grade + 
at.level(trait,1):I(grade^2) + at.level(trait,1):male.f + 
at.level(trait,1):ethnic.f + at.level(trait,1):sped.f 
+at.level(trait,1):risk.f + at.level(trait,1):male.f*grade + 
at.level(trait,1):ethnic.f*grade + at.level(trait,1):sped.f*grade 
+at.level(trait,1):risk.f*grade + at.level(trait,1):male.f*I(grade^2) + 
at.level(trait,1):ethnic.f*I(grade^2) + 
at.level(trait,1):sped.f*I(grade^2) 
+at.level(trait,1):risk.f*I(grade^2), random=~us(at.level(trait,1)):id.f 
+ us(at.level(trait,1)):schn.f + us(at.level(trait,1)):schn.f:id.f, 
data=suslm, rcov=~idh(trait):units, family="zipoisson", 
prior=prior,nitt=30000, thin=50, burnin=10000)

I would like to generate group level growth curves by "risk.f". risk.f 
is a categorical variable with 4 levels. I curious how I might do this? 
Additionally, how can I find out the proportion of zeros predicted by 
the Poisson component and the proportion of zeros predicted by the 
Poisson+ZIP component?

Jarrod Hadfield has provided the following code in the past but I am not 
sure how to generalize to my example.

Thanks!
Chris


beta<-colMeans(m3$Sol)
c2<-16*sqrt(3)/(15*pi)             # see Diggle 2004
zi<-inv.logit(beta[2]/sqrt(1+c2))  # scale zero-inflation as if residual 
variance was set to zero
pred<-exp(beta[1]+beta[3]*I(1:12)+beta[4]*I((1:12)^2)+0.5*mean(rowSums(m3$VCV[,1:2]))) 
# poisson predictions
pz<-ppois(0, pred)  # proportion of zeros predicted from the poisson
tz<-zi+(1-zi)*pz  # total proportion of zeros predicted
Ezip0<-function(mu){mu/(1-exp(-mu))} # the expected value of a zero 
truncated Poisson with mu = mean prior to trunaction.

# plot for non-zero data points
plot(suslm$sus[which(suslm$sus>0)]~as.factor(suslm$grade)[which(suslm$sus>0)],xlab="Grade",ylab="Number 
of Suspensions")
points(tapply(suslm$sus[which(suslm$sus>0)], 
as.factor(suslm$grade)[which(suslm$sus>0)], mean)~I(1:12), pch=16)  # 
overlay observed means
lines(Ezip0(pred)~I(1:12)) # predictions goodish - see below



From juliet.hannah at gmail.com  Thu Jun 10 23:57:07 2010
From: juliet.hannah at gmail.com (Juliet Hannah)
Date: Thu, 10 Jun 2010 17:57:07 -0400
Subject: [R-sig-ME] "Animal Model" plus logistic regression
In-Reply-To: <4C0D131A.2070706@toulouse.inra.fr>
References: <4C0D131A.2070706@toulouse.inra.fr>
Message-ID: <AANLkTimOA9jF_B0CeFN6a1qLVwoVhrlRAwUi3jlKLSvy@mail.gmail.com>

For a continuous trait, the animal model can be fit using the kinship
package. I don't think it works with discrete traits yet. My
understanding is that you need to be able to specify a custom
correlation matrix. Can glmer do that?

On Mon, Jun 7, 2010 at 11:41 AM, Bertrand Servin
<bertrand.servin at toulouse.inra.fr> wrote:
> Dear list,
>
> I tried searching in the archive, but cannot seem to find a relevant
> thread on my problem. I would like to fit a generalized linear
> model (logit link) where the random effects are individuals and
> I estimated (from genetic data) the expected correlation between
> these random effects. This is sometimes called "Animal model" because
> it is quite used in livestock genetics.
>
> This could be a simple dataset:
>
> library(lme4)
>
> y=c(1,1,0,0)
> ID=as.factor(1:4)
> V=matrix(c(1,0.1,0.2,0.3,0.1,1,0,0,0.2,0,1,0,0.3,0,0,1),nrow=4,byrow=T)
>
> The model is just logit(y) ~ mu + e
>
> with Var(e)=V.sigma^2_a+I.sigma^2_e
>
> So V is not to be estimated within the model fit, I just want to
> get an estimate of sigma^2_a, and the model residuals.
>
> I was thinking among these lines:
>
> glmer(y~1|ID,family=binomial,doFit=FALSE)
>
> and then modify something within this model.
> Related question, how do I actually fit the model once
> I made the modifications needed ?
>
> Is this the right way to go ?
>
> thanks for your help
> --
> Bertrand Servin
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From davidD at qimr.edu.au  Fri Jun 11 00:53:46 2010
From: davidD at qimr.edu.au (David Duffy)
Date: Fri, 11 Jun 2010 08:53:46 +1000 (EST)
Subject: [R-sig-ME] "Animal Model" plus logistic regression
In-Reply-To: <AANLkTimOA9jF_B0CeFN6a1qLVwoVhrlRAwUi3jlKLSvy@mail.gmail.com>
References: <4C0D131A.2070706@toulouse.inra.fr>
	<AANLkTimOA9jF_B0CeFN6a1qLVwoVhrlRAwUi3jlKLSvy@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1006110852590.10879@orpheus.qimr.edu.au>

On Thu, 10 Jun 2010, Juliet Hannah wrote:

> For a continuous trait, the animal model can be fit using the kinship
> package. I don't think it works with discrete traits yet. My
> understanding is that you need to be able to specify a custom
> correlation matrix. Can glmer do that?
>

See the pedigreemm package.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From fengsj at mail.utexas.edu  Fri Jun 11 02:48:36 2010
From: fengsj at mail.utexas.edu (fengsj at mail.utexas.edu)
Date: Thu, 10 Jun 2010 19:48:36 -0500
Subject: [R-sig-ME] Random slope
In-Reply-To: <Pine.LNX.4.64.1006110852590.10879@orpheus.qimr.edu.au>
References: <4C0D131A.2070706@toulouse.inra.fr>
	<AANLkTimOA9jF_B0CeFN6a1qLVwoVhrlRAwUi3jlKLSvy@mail.gmail.com>
	<Pine.LNX.4.64.1006110852590.10879@orpheus.qimr.edu.au>
Message-ID: <20100610194836.h7com532jcccggo0@webmail.utexas.edu>

I am in the process of selection models. If the random slope for A is  
decided in the model, but the fixed effect of A is not significant. Is  
that ok if I remove fixed A? I don?t feel very comfortable with it.   
Is the random slope like the interaction between the fixed and random  
factor?  If the interaction term is in the model, we better also keep  
all the main effects even if they are not significant. Does it also  
apply in this situation?
Thanks
Shujuan



From Kay.Cichini at uibk.ac.at  Fri Jun 11 11:01:45 2010
From: Kay.Cichini at uibk.ac.at (Kay Cecil Cichini)
Date: Fri, 11 Jun 2010 11:01:45 +0200
Subject: [R-sig-ME] Deviance tests and contrasts
In-Reply-To: <Pine.LNX.4.64.1006092023370.6281@orpheus.qimr.edu.au>
References: <alpine.DEB.2.00.1006081542220.9543@parser.ilovebacon.org>
	<Pine.LNX.4.64.1006092023370.6281@orpheus.qimr.edu.au>
Message-ID: <4C11FB79.1050801@uibk.ac.at>

hello adam, david and others,

i recently was trying to figure out the same problem. i think that 
anova(l2,l0) is not appropiate because the models ar not nested.

i ended up testing anova(l2,l1) for the interaction and anova(l1,l0) for 
the main effect of sex. any thoughts on this?

yours,
kay


David Duffy schrieb:
> On Tue, 8 Jun 2010, Adam D. I. Kramer wrote:
> 
>>
>> l2 <- lmer(score ~ sex * condition + (1 + condition | subject), data=d)
>>
>> ...the main effect for sex, which has only one contrast?
> 
> Being very simple minded, I would have run something like:
> l2 <- lmer(score ~ sex * condition + (1 + condition | subject), data=d)
> l1 <- lmer(score ~ sex + condition + (1 + condition | subject), data=d)
> l0 <- lmer(score ~ condition + (1 + condition | subject), data=d,
>            subset=complete.cases(sex))
> anova(l2, l1, l0)
> 
> 
>



From bolker at ufl.edu  Fri Jun 11 14:09:00 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Fri, 11 Jun 2010 08:09:00 -0400
Subject: [R-sig-ME] Random slope
In-Reply-To: <20100610194836.h7com532jcccggo0@webmail.utexas.edu>
References: <4C0D131A.2070706@toulouse.inra.fr>	<AANLkTimOA9jF_B0CeFN6a1qLVwoVhrlRAwUi3jlKLSvy@mail.gmail.com>	<Pine.LNX.4.64.1006110852590.10879@orpheus.qimr.edu.au>
	<20100610194836.h7com532jcccggo0@webmail.utexas.edu>
Message-ID: <4C12275C.3030706@ufl.edu>

fengsj at mail.utexas.edu wrote:
> I am in the process of selection models. If the random slope for A is  
> decided in the model, but the fixed effect of A is not significant. Is  
> that ok if I remove fixed A? I don?t feel very comfortable with it.   
> Is the random slope like the interaction between the fixed and random  
> factor?  If the interaction term is in the model, we better also keep  
> all the main effects even if they are not significant. Does it also  
> apply in this situation?
> Thanks
> Shujuan
> 

  Your analogy is good.
  Keeping a random slope while discarding the fixed effect of A is
equivalent to assuming that the population mean slope is *exactly* zero
while the variance is non-zero: it's possible that it could make sense
for some special cases, but in general it doesn't.

  [Insert usual caveats about model selection algorithms here]

  Ben Bolker



From bertrand.servin at toulouse.inra.fr  Fri Jun 11 08:41:55 2010
From: bertrand.servin at toulouse.inra.fr (Bertrand Servin)
Date: Fri, 11 Jun 2010 08:41:55 +0200
Subject: [R-sig-ME] "Animal Model" plus logistic regression
In-Reply-To: <Pine.LNX.4.64.1006110852590.10879@orpheus.qimr.edu.au>
References: <4C0D131A.2070706@toulouse.inra.fr>	<AANLkTimOA9jF_B0CeFN6a1qLVwoVhrlRAwUi3jlKLSvy@mail.gmail.com>
	<Pine.LNX.4.64.1006110852590.10879@orpheus.qimr.edu.au>
Message-ID: <4C11DAB3.4050903@toulouse.inra.fr>

Hi,

thanks for all your replies, it seems I will need to use other packages
(possibly related to lme4) for this purpose.

To summarize the possibilities (in R):

1. kinship
2. genabel (rgenetics now ?)
3. asreml-R (not free)
4. pedigreemm

thanks again
-- 
Bertrand

David Duffy wrote:
> On Thu, 10 Jun 2010, Juliet Hannah wrote:
> 
>> For a continuous trait, the animal model can be fit using the kinship
>> package. I don't think it works with discrete traits yet. My
>> understanding is that you need to be able to specify a custom
>> correlation matrix. Can glmer do that?
>>
> 
> See the pedigreemm package.
>



From chris.kleier at gmail.com  Fri Jun 11 14:43:55 2010
From: chris.kleier at gmail.com (Chris Kleier)
Date: Fri, 11 Jun 2010 14:43:55 +0200
Subject: [R-sig-ME] Why post-hoc Tukey more significant than lme P-values?
Message-ID: <AANLkTilJbbJ14UFvJSHk9U7WrITZgW7DJiMTqrXNGWoV@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100611/6e066709/attachment.pl>

From danielezrajohnson at gmail.com  Fri Jun 11 18:34:51 2010
From: danielezrajohnson at gmail.com (Daniel Ezra Johnson)
Date: Fri, 11 Jun 2010 12:34:51 -0400
Subject: [R-sig-ME] Random slope
In-Reply-To: <4C12275C.3030706@ufl.edu>
References: <4C0D131A.2070706@toulouse.inra.fr>
	<AANLkTimOA9jF_B0CeFN6a1qLVwoVhrlRAwUi3jlKLSvy@mail.gmail.com>
	<Pine.LNX.4.64.1006110852590.10879@orpheus.qimr.edu.au>
	<20100610194836.h7com532jcccggo0@webmail.utexas.edu>
	<4C12275C.3030706@ufl.edu>
Message-ID: <AANLkTinN_EMvWrJ0VCHUwEqsP_Cq4NKDmUlKQTKe8Pp0@mail.gmail.com>

In practice, though, wouldn't glmer() estimate the variance of the
slope accurately, even though the random effects would not be centered
around zero anymore?

I don't see why you would drop the fixed-effect term, but when you say
doing so would be assuming this parameter is exactly zero, that's not
quite in the same sense as if you, for example, dropped the intercept
in a simple linear regression, is it?

Won't the random effects "pick up the slack" - they're not actually
constrained to be centered around zero, except in theory...

Dan

On Fri, Jun 11, 2010 at 8:09 AM, Ben Bolker <bolker at ufl.edu> wrote:
> fengsj at mail.utexas.edu wrote:
>> I am in the process of selection models. If the random slope for A is
>> decided in the model, but the fixed effect of A is not significant. Is
>> that ok if I remove fixed A? I don?t feel very comfortable with it.
>> Is the random slope like the interaction between the fixed and random
>> factor? ?If the interaction term is in the model, we better also keep
>> all the main effects even if they are not significant. Does it also
>> apply in this situation?
>> Thanks
>> Shujuan
>>
>
> ?Your analogy is good.
> ?Keeping a random slope while discarding the fixed effect of A is
> equivalent to assuming that the population mean slope is *exactly* zero
> while the variance is non-zero: it's possible that it could make sense
> for some special cases, but in general it doesn't.
>
> ?[Insert usual caveats about model selection algorithms here]
>
> ?Ben Bolker
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From crm53 at cam.ac.uk  Fri Jun 11 19:08:18 2010
From: crm53 at cam.ac.uk (Rafael Mares)
Date: Fri, 11 Jun 2010 18:08:18 +0100
Subject: [R-sig-ME] problem using lmer with family = Gamma
Message-ID: <AANLkTimDmp4XjTvfdivGwIFmXkNqmWIhtvXHRGqJ97_H@mail.gmail.com>

Dear all

I'm trying to run a GLMM with Gamma errors (as seems most appropriate
for my data) using the lme4 package (version 0.999375-33) in R version
2.10.1 on Windows.

I measured the time an individual sniffed a sample (continous response
variable, no 0s and all positive), in an experiment with a control and
1 treatment, while also controlling for sex and dominance class and
the age of the donor of the sample. I have 2 random effects:
individual (n = 31) and group to which the individual belongs (n = 8).
There are no missing values.


The formula is:

fullmod<-lmer(sniff ~ treatment + sex + domstatus + donor.age +
(1|group/id), family = Gamma, REML = FALSE, data = pres)

and this is the output:

Error in mer_finalize(ans) : mu[i] must be positive: mu = -44.2351, i = 1


Does anyone have any idea on what might be going on?  Someone posted a
similar question about a month ago, but it doesn't seem like anyone
replied.  I'll happily send some of my data if someone is able to look
into this.
Thanks in advance for your help and my apologies if this is not the
right place to post this question.


Raff



-- 
Rafael Mares
Large Animal Research Group (LARG)
Department of Zoology
University of Cambridge
Downing Street
Cambridge
CB2 3EJ



From huiyan.zhao at monsanto.com  Fri Jun 11 20:54:21 2010
From: huiyan.zhao at monsanto.com (ZHAO, HUIYAN [AG/1005])
Date: Fri, 11 Jun 2010 13:54:21 -0500
Subject: [R-sig-ME] How to code mixed model with nested factors in lmer
In-Reply-To: <153E410F1C1B4A43A36B1454A7B13994984B3A@NA1000EXM03.na.ds.monsanto.com>
References: <153E410F1C1B4A43A36B1454A7B13994984B3A@NA1000EXM03.na.ds.monsanto.com>
Message-ID: <153E410F1C1B4A43A36B1454A7B13994984B4C@NA1000EXM03.na.ds.monsanto.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100611/72f7092c/attachment.pl>

From edeline at biologie.ens.fr  Fri Jun 11 22:23:59 2010
From: edeline at biologie.ens.fr (Eric Edeline)
Date: Fri, 11 Jun 2010 22:23:59 +0200
Subject: [R-sig-ME] Skewed residuals from random effects
Message-ID: <4C129B5F.1090901@biologie.ens.fr>

Dear list,

what to do when a normally-distributed random effect is justified by the 
data structure, drops model AIC but badly skews the residuals? And 
actually how can this happen? I am modeling body length of 50 fish 
species as a function of various environmental variables (see below). 
Any feed back would be greatly appreciated.

Thanks!


My model:
m046<-lme(log(Length) ~ 
log(Slope)+log(Width)+log(D)+log(Compint2)+log(Pred2)*log(Temp)+Year, 
data=Data, na.action=na.omit,
random=list(Strategy=pdDiag(form=~1), Method=pdDiag(form=~1), 
Species=pdDiag(form=~1)))    #normal random effects but skewed residuals
                                                                         
                                                                         
                        #residuals from a lm are nicely distributed


-- 
Eric Edeline
Assistant Professor
UMR 7618 BIOEMCO
Ecole Normale Sup?rieure
46 rue d'Ulm
75230 Paris cedex 05
France

Tel: +33 (0)1 44 32 38 84
Fax: +33 (0)1 44 32 38 85

http://www.biologie.ens.fr/bioemco/biodiversite/edeline.html



From f.calboli at imperial.ac.uk  Fri Jun 11 22:50:10 2010
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Fri, 11 Jun 2010 21:50:10 +0100
Subject: [R-sig-ME] How to code mixed model with nested factors in lmer
In-Reply-To: <153E410F1C1B4A43A36B1454A7B13994984B4C@NA1000EXM03.na.ds.monsanto.com>
References: <153E410F1C1B4A43A36B1454A7B13994984B3A@NA1000EXM03.na.ds.monsanto.com>
	<153E410F1C1B4A43A36B1454A7B13994984B4C@NA1000EXM03.na.ds.monsanto.com>
Message-ID: <970C0B54-EF01-4034-BA9F-B87922921884@imperial.ac.uk>

On 11 Jun 2010, at 19:54, ZHAO, HUIYAN [AG/1005] wrote:
> I have coding question on mixed model in R. I am using R2.11.0 in
> windows. I have an experiment with 2 fixed effect factors - A and B. The
> levels of B are within the levels of A factor. The model is very similar
> to a split plot design except the nesting relationship between the 2
> fixed effect factors. For example: there are 2 levels for A - GM and ZM.
> There are 7 levels of B in total (G1-G4 and Z1 - Z3) - but G1, G2, G3,
> G4 only appear in GM while Z1, Z2 and Z3 only appear in ZM. The SAS code
> is like the following:

> I tried to code this model in R using lmer(). It turned out that R has
> some issues with nesting levels with fixed effect. I changed and tried a
> few models just for diagnostic purpose. And I found whenever I included
> the nesting fixed effects, I got the following error message: "Problem
> in .C("mixed_EM",: Singularity in backsolve, while calling subroutine
> mixed_EM". I am wondering whether someone can help me set up this mixed
> model in R. 


no idea of the error you're getting, but assuming that:

1) B is a *random* factor
2) the levels of B are uniquely coded G1:G4 and Z1:Z3, i.e. GX is only found in level 1 of A and ZX is only found in level 2 of A

my hunch is the formula should be

lmer(y ~ A + (1|B), data)

I am pretty sure the formula for lme (library nlme)

is 

lme(y ~ A, random  = ~1|B, data)

You have not provided us with the code you're running, so I find it difficult to figure out why you get that error. BTW, if B is a *fixed* factor, why not using 

aov(y ~ A + B%in%A, data)

??

F
 
--
Federico C. F. Calboli
Department of Epidemiology and Biostatistics
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From davidD at qimr.edu.au  Sat Jun 12 01:55:41 2010
From: davidD at qimr.edu.au (David Duffy)
Date: Sat, 12 Jun 2010 09:55:41 +1000 (EST)
Subject: [R-sig-ME] problem using lmer with family = Gamma
In-Reply-To: <AANLkTimDmp4XjTvfdivGwIFmXkNqmWIhtvXHRGqJ97_H@mail.gmail.com>
References: <AANLkTimDmp4XjTvfdivGwIFmXkNqmWIhtvXHRGqJ97_H@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1006120952240.10088@orpheus.qimr.edu.au>

On Fri, 11 Jun 2010, Rafael Mares wrote:

> Dear all
>
> I'm trying to run a GLMM with Gamma errors (as seems most appropriate
> for my data) using the lme4 package (version 0.999375-33)
>
> fullmod<-lmer(sniff ~ treatment + sex + domstatus + donor.age +
> (1|group/id), family = Gamma, REML = FALSE, data = pres)
>
> Error in mer_finalize(ans) : mu[i] must be positive: mu = -44.2351, i = 1

May I ask if you have fitted an ordinary GLM using the fixed effects? 
Have you perhaps tried a Box-Cox approach, or a LMM with log(sniff)?

Cheers, David Duffy.
-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From fog0 at gmx.com  Sun Jun 13 05:55:53 2010
From: fog0 at gmx.com (Doug Adams)
Date: Sat, 12 Jun 2010 21:55:53 -0600
Subject: [R-sig-ME] Nutrition questionnaire data
In-Reply-To: <AANLkTinppM3mp9BU0uxnq_AByQs1FUh5SrkuGw5gEt9g@mail.gmail.com>
References: <AANLkTinppM3mp9BU0uxnq_AByQs1FUh5SrkuGw5gEt9g@mail.gmail.com>
Message-ID: <AANLkTinhv1iaDj_ros-9J7tNIy8cVnTkS9K3vYBzp38d@mail.gmail.com>

Hello,

It's been a while since I've posted, although I've been using R
sig-mixed-models as a reference a lot lately.

I've got some data from a questionnaire that I'd like to analyze, and
I want to make sure my syntax is right. ?There were multiple groups of
subjects (residents, medical students...) being surveyed, and the
questions were also grouped into subscales. ?So basically, I have the
"response" for each question & for each subject, and questions &
subjects are crossed. ?Further, questions are nested within subscales,
while subjects are nested within groups -- and groups & subscales are
crossed.

So here's kind of what it looks like:

? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?subscale 1
subscale 2 ? ? ? ? ? ? ? ? ? ? ?subscale 3
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?q1 ? ? ?q2 ? ? ?q3 ? ? ?q4 ? ? ?q5
q6 ? ? ?q7 ? ? ?q8 ? ? ?q9 ? ? ?q10 ? ? q11 ? ? q12
Attending ? ? ? ? s1 ? ? ?# ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? #
 ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? #
? ? ? ? ? ? ? ? ? ? ? ?s2 ? ? ?# ? ? ? # ? ? ? # ? ? ? # ? ? ? #
# ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? #
? ? ? ? ? ? ? ? ? ? ? ?s3 ? ? ?# ? ? ? # ? ? ? # ? ? ? # ? ? ? #
# ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? #
Student ?    ? ? ? s4 ? ? ?# ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? #
? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? #
? ? ? ? ? ? ? ? ? ? ? ?s5 ? ? ?# ? ? ? # ? ? ? # ? ? ? # ? ? ? #
# ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? #
? ? ? ? ? ? ? ? ? ? ? ?s6 ? ? ?# ? ? ? # ? ? ? # ? ? ? # ? ? ? #
# ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? #
Resident ? ? ? ? ?s7 ? ? ?# ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? #
 ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? #
? ? ? ? ? ? ? ? ? ? ? ?s8 ? ? ?# ? ? ? # ? ? ? # ? ? ? # ? ? ? #
# ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? #
? ? ? ? ? ? ? ? ? ? ? ?s9 ? ? ?# ? ? ? # ? ? ? # ? ? ? # ? ? ? #
# ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? #


I hope that comes out right ASCII-wise in this post! ? : ) ? Anyway,
there are more subjects and questions and such than in this little
visual of course. ?Is this correct?

lmer(response ~ group + (1|subject) + (1|question), data=NL, REML=TRUE)

Thanks so much,
Doug Adams


P.S. - If there's a reference for the modeling syntax used in R -- or
in lme4 specifically if need be -- and how each operator works, please
let me know. ?For example, if there were a help document that says
things like " A\B means A is nested within B ," or " the | symbol
denotes the the following factor is at a higher level in the model, "
etc., that would be so helpful. ?I've learned a lot from context, from
Pinheiro & Bates (though that's for nlme), and from this forum, but I
haven't been able to find something like a formula syntax reference
like that.



From adik at ilovebacon.org  Mon Jun 14 00:18:28 2010
From: adik at ilovebacon.org (Adam D. I. Kramer)
Date: Sun, 13 Jun 2010 15:18:28 -0700 (PDT)
Subject: [R-sig-ME] lmer, p-values and all that
Message-ID: <alpine.DEB.2.00.1006131515540.8163@parser.ilovebacon.org>

Dear Colleagues,

 	Regarding Douglas Bates' cogent explanation of why lmer doesn't
return p-values, available at
http://finzi.psych.upenn.edu/R/Rhelp02a/archive/76742.html ...could anybody
cite for me a published version of this explanation, or a paper in which
this explanation is put forth formally? I would like to mention this briefly
and cite something in a paper I am currently writing, but am wary about
citing a mailing list post in a paper.

Thanks in advance,
Adam



From adik at ilovebacon.org  Mon Jun 14 00:21:10 2010
From: adik at ilovebacon.org (Adam D. I. Kramer)
Date: Sun, 13 Jun 2010 15:21:10 -0700 (PDT)
Subject: [R-sig-ME] Deviance tests and contrasts
In-Reply-To: <4C11FB79.1050801@uibk.ac.at>
References: <alpine.DEB.2.00.1006081542220.9543@parser.ilovebacon.org>
	<Pine.LNX.4.64.1006092023370.6281@orpheus.qimr.edu.au>
	<4C11FB79.1050801@uibk.ac.at>
Message-ID: <alpine.DEB.2.00.1006131519370.8163@parser.ilovebacon.org>

Dear Kay and David,

 	These models are indeed nested, but they do not test what I am
trying to test. What I am interested in testing is the main effect of sex
when the interaction is in the model. Or, a type-III sum of squares
approach. David's solution below will give me the main effect of sex, but
will not tell me whether the sex effect is significant when the interaction
is in the model.

Thanks,
Adam

On Fri, 11 Jun 2010, Kay Cecil Cichini wrote:

> hello adam, david and others,
>
> i recently was trying to figure out the same problem. i think that 
> anova(l2,l0) is not appropiate because the models ar not nested.
>
> i ended up testing anova(l2,l1) for the interaction and anova(l1,l0) for the 
> main effect of sex. any thoughts on this?
>
> yours,
> kay
>
>
> David Duffy schrieb:
>> On Tue, 8 Jun 2010, Adam D. I. Kramer wrote:
>> 
>>> 
>>> l2 <- lmer(score ~ sex * condition + (1 + condition | subject), data=d)
>>> 
>>> ...the main effect for sex, which has only one contrast?
>> 
>> Being very simple minded, I would have run something like:
>> l2 <- lmer(score ~ sex * condition + (1 + condition | subject), data=d)
>> l1 <- lmer(score ~ sex + condition + (1 + condition | subject), data=d)
>> l0 <- lmer(score ~ condition + (1 + condition | subject), data=d,
>>            subset=complete.cases(sex))
>> anova(l2, l1, l0)
>> 
>> 
>> 
>
>



From andyfugard at gmail.com  Mon Jun 14 00:25:07 2010
From: andyfugard at gmail.com (Andy Fugard)
Date: Mon, 14 Jun 2010 00:25:07 +0200
Subject: [R-sig-ME] lmer, p-values and all that
In-Reply-To: <alpine.DEB.2.00.1006131515540.8163@parser.ilovebacon.org>
References: <alpine.DEB.2.00.1006131515540.8163@parser.ilovebacon.org>
Message-ID: <AANLkTilpfg1rdBndOrUsUrUJeeSPG0J-prdGswprAOvt@mail.gmail.com>

Adam,

See

Baayen, R.H., Davidson, D.J. and Bates, D.M. (2008). Mixed-effects
modeling with crossed random effects for subjects and items. Journal
of Memory and Language 59, 390--412.

beginning p. 396.

Cheers,

Andy


On Mon, Jun 14, 2010 at 00:18, Adam D. I. Kramer <adik at ilovebacon.org> wrote:
> Dear Colleagues,
>
> ? ? ? ?Regarding Douglas Bates' cogent explanation of why lmer doesn't
> return p-values, available at
> http://finzi.psych.upenn.edu/R/Rhelp02a/archive/76742.html ...could anybody
> cite for me a published version of this explanation, or a paper in which
> this explanation is put forth formally? I would like to mention this briefly
> and cite something in a paper I am currently writing, but am wary about
> citing a mailing list post in a paper.
>
> Thanks in advance,
> Adam
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
http://www.andyfugard.info



From adik at ilovebacon.org  Mon Jun 14 00:56:06 2010
From: adik at ilovebacon.org (Adam D. I. Kramer)
Date: Sun, 13 Jun 2010 15:56:06 -0700 (PDT)
Subject: [R-sig-ME] lmer, p-values and all that
In-Reply-To: <AANLkTilpfg1rdBndOrUsUrUJeeSPG0J-prdGswprAOvt@mail.gmail.com>
References: <alpine.DEB.2.00.1006131515540.8163@parser.ilovebacon.org>
	<AANLkTilpfg1rdBndOrUsUrUJeeSPG0J-prdGswprAOvt@mail.gmail.com>
Message-ID: <alpine.DEB.2.00.1006131555440.8163@parser.ilovebacon.org>

Fantastic! Many thanks. Looks like a pretty informative article in general.

--Adam


On Mon, 14 Jun 2010, Andy Fugard wrote:

> Adam,
>
> See
>
> Baayen, R.H., Davidson, D.J. and Bates, D.M. (2008). Mixed-effects
> modeling with crossed random effects for subjects and items. Journal
> of Memory and Language 59, 390--412.
>
> beginning p. 396.
>
> Cheers,
>
> Andy
>
>
> On Mon, Jun 14, 2010 at 00:18, Adam D. I. Kramer <adik at ilovebacon.org> wrote:
>> Dear Colleagues,
>>
>>        Regarding Douglas Bates' cogent explanation of why lmer doesn't
>> return p-values, available at
>> http://finzi.psych.upenn.edu/R/Rhelp02a/archive/76742.html ...could anybody
>> cite for me a published version of this explanation, or a paper in which
>> this explanation is put forth formally? I would like to mention this briefly
>> and cite something in a paper I am currently writing, but am wary about
>> citing a mailing list post in a paper.
>>
>> Thanks in advance,
>> Adam
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> -- 
> http://www.andyfugard.info
>



From davidD at qimr.edu.au  Mon Jun 14 02:19:20 2010
From: davidD at qimr.edu.au (David Duffy)
Date: Mon, 14 Jun 2010 10:19:20 +1000 (EST)
Subject: [R-sig-ME] Deviance tests and contrasts
In-Reply-To: <alpine.DEB.2.00.1006131519370.8163@parser.ilovebacon.org>
References: <alpine.DEB.2.00.1006081542220.9543@parser.ilovebacon.org>
	<Pine.LNX.4.64.1006092023370.6281@orpheus.qimr.edu.au>
	<4C11FB79.1050801@uibk.ac.at>
	<alpine.DEB.2.00.1006131519370.8163@parser.ilovebacon.org>
Message-ID: <Pine.LNX.4.64.1006141010500.21171@orpheus.qimr.edu.au>

>
> David's solution below will give me the main effect of sex, but
> will not tell me whether the sex effect is significant when the interaction
> is in the model.

Perhaps this is teaching one's grandmother how to suck eggs (not that I've 
actually ever sucked eggs ;)), but I was always told that it is pretty 
hard to interpret _significance_ of a main effect in the presence of an 
interaction.  I would think this doubly so in the presence of your random 
effects.

Cheers, David.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From adik at ilovebacon.org  Mon Jun 14 03:04:54 2010
From: adik at ilovebacon.org (Adam D. I. Kramer)
Date: Sun, 13 Jun 2010 18:04:54 -0700 (PDT)
Subject: [R-sig-ME] Deviance tests and contrasts
In-Reply-To: <Pine.LNX.4.64.1006141010500.21171@orpheus.qimr.edu.au>
References: <alpine.DEB.2.00.1006081542220.9543@parser.ilovebacon.org>
	<Pine.LNX.4.64.1006092023370.6281@orpheus.qimr.edu.au>
	<4C11FB79.1050801@uibk.ac.at>
	<alpine.DEB.2.00.1006131519370.8163@parser.ilovebacon.org>
	<Pine.LNX.4.64.1006141010500.21171@orpheus.qimr.edu.au>
Message-ID: <alpine.DEB.2.00.1006131749200.8163@parser.ilovebacon.org>

Yes, this is true...but it is a failure of my choice of example, rather than
a real solution to the question.  =) I only really brought up the "main
effect in the presence of the interaction" example as an instance of the
broader problem, which is testing the significance of an effect that I can't
remove in order to use anova()...for example, single-df contrasts on a
multi-level variable:

d <- data.frame(favcol=factor(rep(c("red","blue","yellow","purple"),each=50)),
subj=factor(rep(1:20,each=10)), dv=rnorm(200))

lmer(dv ~ favcol + (1|subj), data=d)

...in this example, with default (dummy-coded) contrasts, the "favcolpurple"
effect tests whether purple differs from red, but I can't (easily) subtract
the "favcolpurple" effect and recompute.

The test I want to conduct is, functionally, this one:

d <- cbind(d,t(sapply(d$favcol, function(x) { contrasts(d$favcol)[x,] } )))
l <- lmer(dv ~ purple + red + yellow + (1|subj), data=d)
l0 <- update(l, . ~ . - purple)
anova(l0,l)

...but what I want is a more elegant way to do this for lmer models, as it
seems to me that the "contrasts" system exists for exactly this reason.

Any thoughts on this?

Thanks,
Adam

On Mon, 14 Jun 2010, David Duffy wrote:

>> 
>> David's solution below will give me the main effect of sex, but
>> will not tell me whether the sex effect is significant when the interaction
>> is in the model.
>
> Perhaps this is teaching one's grandmother how to suck eggs (not that I've 
> actually ever sucked eggs ;)), but I was always told that it is pretty hard 
> to interpret _significance_ of a main effect in the presence of an 
> interaction.  I would think this doubly so in the presence of your random 
> effects.
>
> Cheers, David.
>
> -- 
> | David Duffy (MBBS PhD)                                         ,-_|\
> | email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
> | Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
> | 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v
>



From crm53 at cam.ac.uk  Mon Jun 14 11:54:48 2010
From: crm53 at cam.ac.uk (Rafael Mares)
Date: Mon, 14 Jun 2010 10:54:48 +0100
Subject: [R-sig-ME] problem using lmer with family = Gamma
In-Reply-To: <Pine.LNX.4.64.1006120952240.10088@orpheus.qimr.edu.au>
References: <AANLkTimDmp4XjTvfdivGwIFmXkNqmWIhtvXHRGqJ97_H@mail.gmail.com>
	<Pine.LNX.4.64.1006120952240.10088@orpheus.qimr.edu.au>
Message-ID: <AANLkTildDBr94fUnnBRRJLQokTJBjbsZ5EJXz_cPuaLl@mail.gmail.com>

Hi David

Thank you very much for your reply.  I have tried the options you
suggest, and it seems to me that the Box-Cox transformation does a
good job of normalizing the data, but I would rather not transform the
response variable, based on Zuur et al's data exploration protocol
(2010) - which seems to suggest that in my case, differences in time
spent sniffing between the control and treatment may be made smaller
after transformation.

Do you think a transformation would be preferable over using Gamma
errors in my case?  Possibly a difficult question to answer not having
seen the raw data, but maybe there is something about mixed models in
lmer with Gamma errors that I am completely missing.

Thanks again for your help.
All the best,


Raff



On 12 June 2010 00:55, David Duffy <davidD at qimr.edu.au> wrote:
> On Fri, 11 Jun 2010, Rafael Mares wrote:
>
>> Dear all
>>
>> I'm trying to run a GLMM with Gamma errors (as seems most appropriate
>> for my data) using the lme4 package (version 0.999375-33)
>>
>> fullmod<-lmer(sniff ~ treatment + sex + domstatus + donor.age +
>> (1|group/id), family = Gamma, REML = FALSE, data = pres)
>>
>> Error in mer_finalize(ans) : mu[i] must be positive: mu = -44.2351, i = 1
>
> May I ask if you have fitted an ordinary GLM using the fixed effects? Have
> you perhaps tried a Box-Cox approach, or a LMM with log(sniff)?
>
> Cheers, David Duffy.
> --
> | David Duffy (MBBS PhD) ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ,-_|\
> | email: davidD at qimr.edu.au ?ph: INT+61+7+3362-0217 fax: -0101 ?/ ? ? *
> | Epidemiology Unit, Queensland Institute of Medical Research ? \_,-._/
> | 300 Herston Rd, Brisbane, Queensland 4029, Australia ?GPG 4D0B994A v
>



-- 
Rafael Mares
Large Animal Research Group (LARG)
Department of Zoology
University of Cambridge
Downing Street
Cambridge
CB2 3EJ



From chris.kleier at gmail.com  Mon Jun 14 16:04:38 2010
From: chris.kleier at gmail.com (Chris Kleier)
Date: Mon, 14 Jun 2010 16:04:38 +0200
Subject: [R-sig-ME] Why post-hoc Tukey more significant than lme
	P-values?
In-Reply-To: <11C9E7AF7CBD1B4DA9BEFBDC7D0E86940221B38747@bru-emb107.na.pg.com>
References: <AANLkTilJbbJ14UFvJSHk9U7WrITZgW7DJiMTqrXNGWoV@mail.gmail.com>
	<11C9E7AF7CBD1B4DA9BEFBDC7D0E86940221B38747@bru-emb107.na.pg.com>
Message-ID: <AANLkTilU-BMjrMMf8YbmADIHx5E1dAKGCi9dZLiZfI3s@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100614/8aa22ed1/attachment.pl>

From fog0 at gmx.com  Tue Jun 15 02:12:56 2010
From: fog0 at gmx.com (Doug Adams)
Date: Mon, 14 Jun 2010 18:12:56 -0600
Subject: [R-sig-ME] Nutrition questionnaire data
In-Reply-To: <AANLkTikIWB_rDmxgF8ncO4K0TnGGcUGGr2-YuGz5VQwY@mail.gmail.com>
References: <AANLkTinppM3mp9BU0uxnq_AByQs1FUh5SrkuGw5gEt9g@mail.gmail.com>
	<AANLkTinhv1iaDj_ros-9J7tNIy8cVnTkS9K3vYBzp38d@mail.gmail.com>
	<AANLkTikIWB_rDmxgF8ncO4K0TnGGcUGGr2-YuGz5VQwY@mail.gmail.com>
Message-ID: <AANLkTilVBGeajjmq1TVsCixrseEyIl4GtHiyisuT8jZs@mail.gmail.com>

Thanks very much Dennis.  You're right: it does use a Likert scale,
although one subscale is binary (which is another mini-problem on its
own, though one aspect less complex than the rest of the data of
course).

Maybe I will try a MANOVA approach to see how it works out.  I'll also
check out the lavaan package.  I'm still struggling to wrap my head
around everything you've said, but that's not your fault!  I've just
got lots of learning to do still...   : )

Doug


On Sat, Jun 12, 2010 at 11:53 PM, Dennis Murphy <djmuser at gmail.com> wrote:
> Hi:
>
> On Sat, Jun 12, 2010 at 8:55 PM, Doug Adams <fog0 at gmx.com> wrote:
>>
>> Hello,
>>
>> It's been a while since I've posted, although I've been using R
>> sig-mixed-models as a reference a lot lately.
>>
>> I've got some data from a questionnaire that I'd like to analyze, and
>> I want to make sure my syntax is right. ?There were multiple groups of
>> subjects (residents, medical students...) being surveyed, and the
>> questions were also grouped into subscales. ?So basically, I have the
>> "response" for each question & for each subject, and questions &
>> subjects are crossed. ?Further, questions are nested within subscales,
>> while subjects are nested within groups -- and groups & subscales are
>> crossed.
>>
> But:
> ? - the subscales are properties of the questionnaire (response)
> ? - the groups are properties of the subjects
>
> I would tend to view this problem more as one with a multivariate response
> where you could use 'MANOVA-like' concepts - for example, one contrast
> matrix for the subjects, another for the responses (subscales) and a test
> statistic that uses one or both using matrix multiplication. The problem, I
> suspect, is that your questionnaire is on a Likert scale, so multivariate
> normal
> assumptions would be specious.
>
> In a sense, you're caught between modeling paradigms: on one hand, it's
> reminiscent of the multivariate response approach to repeated measures
> applied to an entire questionnaire scale, where the subjects would be
> considered fixed blocks in a MANOVA (associated with different types of
> health providers, an intrinsic factor); on the other hand, the subjects are
> random and you'd prefer to use a mixed model approach. The problem with the
> latter is that AFAIK no one has extended linear or generalized mixed models
> to the case of multivariate responses, and I'm rather sure that neither nlme
> or
> lme4 is designed for that type of problem at present. I wonder if some type
> of latent variable or structural equation model might be better suited for
> this
> task - the question is whether such models can handle ordinal responses,
> as would normally be the case with Likert scales. (Of course, if the
> questions yield plausibly normal distributions, that's a different
> matter...) The
> recently released lavaan package might be useful if the latent variable
> route
> looks promising.
>
> Something for you to cogitate over :)
>
> HTH,
> Dennis
>
>
>
>>
>> So here's kind of what it looks like:
>>
>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?subscale 1
>> subscale 2 ? ? ? ? ? ? ? ? ? ? ?subscale 3
>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?q1 ? ? ?q2 ? ? ?q3 ? ? ?q4 ? ? ?q5
>> q6 ? ? ?q7 ? ? ?q8 ? ? ?q9 ? ? ?q10 ? ? q11 ? ? q12
>> Attending ? ? ? ? s1 ? ? ?# ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? #
>> ?? # ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? #
>> ? ? ? ? ? ? ? ? ? ? ? ?s2 ? ? ?# ? ? ? # ? ? ? # ? ? ? # ? ? ? #
>> # ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? #
>> ? ? ? ? ? ? ? ? ? ? ? ?s3 ? ? ?# ? ? ? # ? ? ? # ? ? ? # ? ? ? #
>> # ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? #
>> Student ? ? ?? ? ? s4 ? ? ?# ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? #
>> ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? #
>> ? ? ? ? ? ? ? ? ? ? ? ?s5 ? ? ?# ? ? ? # ? ? ? # ? ? ? # ? ? ? #
>> # ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? #
>> ? ? ? ? ? ? ? ? ? ? ? ?s6 ? ? ?# ? ? ? # ? ? ? # ? ? ? # ? ? ? #
>> # ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? #
>> Resident ? ? ? ? ?s7 ? ? ?# ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? #
>> ?? # ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? #
>> ? ? ? ? ? ? ? ? ? ? ? ?s8 ? ? ?# ? ? ? # ? ? ? # ? ? ? # ? ? ? #
>> # ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? #
>> ? ? ? ? ? ? ? ? ? ? ? ?s9 ? ? ?# ? ? ? # ? ? ? # ? ? ? # ? ? ? #
>> # ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? #
>>
>>
>> I hope that comes out right ASCII-wise in this post! ? : ) ? Anyway,
>> there are more subjects and questions and such than in this little
>> visual of course. ?Is this correct?
>>
>> lmer(response ~ group + (1|subject) + (1|question), data=NL, REML=TRUE)
>>
>> Thanks so much,
>> Doug Adams
>>
>>
>> P.S. - If there's a reference for the modeling syntax used in R -- or
>> in lme4 specifically if need be -- and how each operator works, please
>> let me know. ?For example, if there were a help document that says
>> things like " A\B means A is nested within B ," or " the | symbol
>> denotes the the following factor is at a higher level in the model, "
>> etc., that would be so helpful. ?I've learned a lot from context, from
>> Pinheiro & Bates (though that's for nlme), and from this forum, but I
>> haven't been able to find something like a formula syntax reference
>> like that.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



From martykardos at gmail.com  Tue Jun 15 22:27:59 2010
From: martykardos at gmail.com (Marty Kardos)
Date: Tue, 15 Jun 2010 14:27:59 -0600
Subject: [R-sig-ME] likelihood ratio tests vs. bootstrapping in
	quasi-poisson models
Message-ID: <AANLkTinec67BJhIIqc7-SPdou1FaDLh_CCukI__-NTUD@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100615/81f3f680/attachment.pl>

From davidD at qimr.edu.au  Wed Jun 16 00:16:31 2010
From: davidD at qimr.edu.au (David Duffy)
Date: Wed, 16 Jun 2010 08:16:31 +1000 (EST)
Subject: [R-sig-ME] Deviance tests and contrasts
In-Reply-To: <alpine.DEB.2.00.1006131749200.8163@parser.ilovebacon.org>
References: <alpine.DEB.2.00.1006081542220.9543@parser.ilovebacon.org>
	<Pine.LNX.4.64.1006092023370.6281@orpheus.qimr.edu.au>
	<4C11FB79.1050801@uibk.ac.at>
	<alpine.DEB.2.00.1006131519370.8163@parser.ilovebacon.org>
	<Pine.LNX.4.64.1006141010500.21171@orpheus.qimr.edu.au>
	<alpine.DEB.2.00.1006131749200.8163@parser.ilovebacon.org>
Message-ID: <Pine.LNX.4.64.1006160814050.14975@orpheus.qimr.edu.au>

On Sun, 13 Jun 2010, Adam D. I. Kramer wrote:

> d <- 
> data.frame(favcol=factor(rep(c("red","blue","yellow","purple"),each=50)),
> subj=factor(rep(1:20,each=10)), dv=rnorm(200))
>
> lmer(dv ~ favcol + (1|subj), data=d)
>
> ...in this example, with default (dummy-coded) contrasts, the "favcolpurple"
> effect tests whether purple differs from red, but I can't (easily) subtract
> the "favcolpurple" effect and recompute.
>
> ...but what I want is a more elegant way to do this for lmer models, as it
> seems to me that the "contrasts" system exists for exactly this reason.
>

Not elegant ;)

levels(d$favcol)[4] <- 'red'



From Thierry.ONKELINX at inbo.be  Wed Jun 16 11:17:01 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 16 Jun 2010 11:17:01 +0200
Subject: [R-sig-ME] likelihood ratio tests vs. bootstrapping
	inquasi-poisson models
In-Reply-To: <AANLkTinec67BJhIIqc7-SPdou1FaDLh_CCukI__-NTUD@mail.gmail.com>
References: <AANLkTinec67BJhIIqc7-SPdou1FaDLh_CCukI__-NTUD@mail.gmail.com>
Message-ID: <2E9C414912813E4EB981326983E0A1040735C211@inboexch.inbo.be>

Dear marty,

Why don't you derive p-values from your bootstrap data? Just find the
largest confidence level at which zero is still excluded from the
confidence interval.

Furthermore I'm interested in how you simulate data from a quasipoisson
distribution. Can you share your code?

Best regards,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Marty Kardos
> Verzonden: dinsdag 15 juni 2010 22:28
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] likelihood ratio tests vs. 
> bootstrapping inquasi-poisson models
> 
> Hello mixed-model folks;
> 
> I am assessing the significance of regression coefficients in 
> quasi-poisson mixed models using lmer.  Based on previous 
> discussion in the mixed models archives, it appears that 
> p-values from likelihood ratio tests on this kind of model 
> may often be unreliable.
> 
> I have been debating with myself over the merits of two 
> alternative approaches to assess the significance of coefficients...
> 
> I have done likelihood ratio tests (comparing nested models), 
> and I have written a program in R to build 'bias-corrected 
> and accelerated' bootstrap confidence intervals for 
> coefficient estimates.  In most cases the inferences based on 
> the bootstrap intervals and likelihood ratio tests 
> qualitatively agree (i.e. when the bootstrap confidence
> interval does not contain zero the likelihood ratio test is 
> significant for the particular coefficient estimate). However 
> in a few important cases, the inferences based on bootstrap 
> intervals and likelihood ratio tests are different (i.e.
> a few coefficients would be determined to be siginficant 
> based on the bootstrap intervals and either marginally
> significant or insignificant based on the likelihood ratio 
> test).  I am attracted to the bootstrapping confidence 
> intervals approach because it appears that it is likely to be 
> more reliable.  I am attracted to the likelihood ratio tests 
> because they provide p-values (which editors and readers of 
> scientific journals seem to enjoy having).
> 
> Here is an example of the models I am working with:
> nongene<-
> lmer(data$offspring~data$age+data$weight+data$agesq+data$Het+(
> 1|data$ID)+(1|factor(data$year)),family=quasipoisson,REML=FALS
> E,na.action=na.omit)
> 
> Do any of you have an opinion on which of these approaches 
> may be best, or ideas for better a better approach?
> 
> Thanks for any thoughts you might have!
> --
> Marty Kardos
> Ph.D. Candidate
> Montana Conservation Genetics Lab
> Organismal Biology & Ecology
> MEID IGERT Program
> University of Montana
> 
> --
> Marty Kardos
> Ph.D. Candidate
> Montana Conservation Genetics Lab
> Organismal Biology & Ecology
> MEID IGERT Program
> University of Montana
> 406-599-1358
> http://dbs.umt.edu/people/gradStudents.php
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From fog0 at gmx.com  Wed Jun 16 17:42:00 2010
From: fog0 at gmx.com (Doug Adams)
Date: Wed, 16 Jun 2010 09:42:00 -0600
Subject: [R-sig-ME] Nutrition questionnaire data
In-Reply-To: <1276610507.20972.46.camel@tim-laptop>
References: <AANLkTinppM3mp9BU0uxnq_AByQs1FUh5SrkuGw5gEt9g@mail.gmail.com>
	<AANLkTinhv1iaDj_ros-9J7tNIy8cVnTkS9K3vYBzp38d@mail.gmail.com>
	<AANLkTikIWB_rDmxgF8ncO4K0TnGGcUGGr2-YuGz5VQwY@mail.gmail.com>
	<AANLkTilVBGeajjmq1TVsCixrseEyIl4GtHiyisuT8jZs@mail.gmail.com>
	<1276610507.20972.46.camel@tim-laptop>
Message-ID: <AANLkTimykIUjnRNF7L2GDCCX3pHbf95Ux0Gv6NzEoJsN@mail.gmail.com>

Thank you Tim! -- those are definitely helpful too.



On Tue, Jun 15, 2010 at 8:01 AM, Tim Carnus <Tim.Carnus at ucd.ie> wrote:
> Hi Dennis,
>
> Not sure if you are aware of the following paper:
>
> Doran H, Bates D, Bliese P, Dowling M (2007). ?Estimating the Multilevel
> Rasch Model: With
> the lme4 Package.? Journal of Statistical Software, 20(2). URL
> http://www.jstatsoft.
> org/v20/i02/.
>
> It seems that the Rasch model is a similar model to what you are hoping
> to fit to your data. They reduce the 1:5 responses to a binary response
> in a first step and mention then how to fit the model to the ordinal
> response.
>
> Another option for you would be MCMCglmm which I think is capable of
> fitting mixed models to ordinal data but also allows for different
> distribution in the response variable.
>
> Best regards,
>
> Tim Carnus
>
>
> On Mon, 2010-06-14 at 18:12 -0600, Doug Adams wrote:
>> Thanks very much Dennis. ?You're right: it does use a Likert scale,
>> although one subscale is binary (which is another mini-problem on its
>> own, though one aspect less complex than the rest of the data of
>> course).
>>
>> Maybe I will try a MANOVA approach to see how it works out. ?I'll also
>> check out the lavaan package. ?I'm still struggling to wrap my head
>> around everything you've said, but that's not your fault! ?I've just
>> got lots of learning to do still... ? : )
>>
>> Doug
>>
>>
>> On Sat, Jun 12, 2010 at 11:53 PM, Dennis Murphy <djmuser at gmail.com> wrote:
>> > Hi:
>> >
>> > On Sat, Jun 12, 2010 at 8:55 PM, Doug Adams <fog0 at gmx.com> wrote:
>> >>
>> >> Hello,
>> >>
>> >> It's been a while since I've posted, although I've been using R
>> >> sig-mixed-models as a reference a lot lately.
>> >>
>> >> I've got some data from a questionnaire that I'd like to analyze, and
>> >> I want to make sure my syntax is right. ?There were multiple groups of
>> >> subjects (residents, medical students...) being surveyed, and the
>> >> questions were also grouped into subscales. ?So basically, I have the
>> >> "response" for each question & for each subject, and questions &
>> >> subjects are crossed. ?Further, questions are nested within subscales,
>> >> while subjects are nested within groups -- and groups & subscales are
>> >> crossed.
>> >>
>> > But:
>> > ? - the subscales are properties of the questionnaire (response)
>> > ? - the groups are properties of the subjects
>> >
>> > I would tend to view this problem more as one with a multivariate response
>> > where you could use 'MANOVA-like' concepts - for example, one contrast
>> > matrix for the subjects, another for the responses (subscales) and a test
>> > statistic that uses one or both using matrix multiplication. The problem, I
>> > suspect, is that your questionnaire is on a Likert scale, so multivariate
>> > normal
>> > assumptions would be specious.
>> >
>> > In a sense, you're caught between modeling paradigms: on one hand, it's
>> > reminiscent of the multivariate response approach to repeated measures
>> > applied to an entire questionnaire scale, where the subjects would be
>> > considered fixed blocks in a MANOVA (associated with different types of
>> > health providers, an intrinsic factor); on the other hand, the subjects are
>> > random and you'd prefer to use a mixed model approach. The problem with the
>> > latter is that AFAIK no one has extended linear or generalized mixed models
>> > to the case of multivariate responses, and I'm rather sure that neither nlme
>> > or
>> > lme4 is designed for that type of problem at present. I wonder if some type
>> > of latent variable or structural equation model might be better suited for
>> > this
>> > task - the question is whether such models can handle ordinal responses,
>> > as would normally be the case with Likert scales. (Of course, if the
>> > questions yield plausibly normal distributions, that's a different
>> > matter...) The
>> > recently released lavaan package might be useful if the latent variable
>> > route
>> > looks promising.
>> >
>> > Something for you to cogitate over :)
>> >
>> > HTH,
>> > Dennis
>> >
>> >
>> >
>> >>
>> >> So here's kind of what it looks like:
>> >>
>> >> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?subscale 1
>> >> subscale 2 ? ? ? ? ? ? ? ? ? ? ?subscale 3
>> >> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?q1 ? ? ?q2 ? ? ?q3 ? ? ?q4 ? ? ?q5
>> >> q6 ? ? ?q7 ? ? ?q8 ? ? ?q9 ? ? ?q10 ? ? q11 ? ? q12
>> >> Attending ? ? ? ? s1 ? ? ?# ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? #
>> >> ? ?# ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? #
>> >> ? ? ? ? ? ? ? ? ? ? ? ?s2 ? ? ?# ? ? ? # ? ? ? # ? ? ? # ? ? ? #
>> >> # ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? #
>> >> ? ? ? ? ? ? ? ? ? ? ? ?s3 ? ? ?# ? ? ? # ? ? ? # ? ? ? # ? ? ? #
>> >> # ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? #
>> >> Student ? ? ? ? ? ?s4 ? ? ?# ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? #
>> >> ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? #
>> >> ? ? ? ? ? ? ? ? ? ? ? ?s5 ? ? ?# ? ? ? # ? ? ? # ? ? ? # ? ? ? #
>> >> # ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? #
>> >> ? ? ? ? ? ? ? ? ? ? ? ?s6 ? ? ?# ? ? ? # ? ? ? # ? ? ? # ? ? ? #
>> >> # ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? #
>> >> Resident ? ? ? ? ?s7 ? ? ?# ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? #
>> >> ? ?# ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? #
>> >> ? ? ? ? ? ? ? ? ? ? ? ?s8 ? ? ?# ? ? ? # ? ? ? # ? ? ? # ? ? ? #
>> >> # ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? #
>> >> ? ? ? ? ? ? ? ? ? ? ? ?s9 ? ? ?# ? ? ? # ? ? ? # ? ? ? # ? ? ? #
>> >> # ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? # ? ? ? #
>> >>
>> >>
>> >> I hope that comes out right ASCII-wise in this post! ? : ) ? Anyway,
>> >> there are more subjects and questions and such than in this little
>> >> visual of course. ?Is this correct?
>> >>
>> >> lmer(response ~ group + (1|subject) + (1|question), data=NL, REML=TRUE)
>> >>
>> >> Thanks so much,
>> >> Doug Adams
>> >>
>> >>
>> >> P.S. - If there's a reference for the modeling syntax used in R -- or
>> >> in lme4 specifically if need be -- and how each operator works, please
>> >> let me know. ?For example, if there were a help document that says
>> >> things like " A\B means A is nested within B ," or " the | symbol
>> >> denotes the the following factor is at a higher level in the model, "
>> >> etc., that would be so helpful. ?I've learned a lot from context, from
>> >> Pinheiro & Bates (though that's for nlme), and from this forum, but I
>> >> haven't been able to find something like a formula syntax reference
>> >> like that.
>> >>
>> >> _______________________________________________
>> >> R-sig-mixed-models at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>> >
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>



From Mike.Lawrence at dal.ca  Thu Jun 17 14:43:38 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Thu, 17 Jun 2010 09:43:38 -0300
Subject: [R-sig-ME] MCMCglmm troubles
Message-ID: <AANLkTilkcHW2S5L_GJkC2HxzaTYRRysMrt_gRxYxd2tC@mail.gmail.com>

Hi folks,

I'm trying to do a mixed multinomial model with 3 response variables,
but I'm getting the error "please use idh() or us() error structure".
I believe that idh() and us() are used to specify the nature of the
interaction between multiple random variables, but I don't have
multiple random variables, so I'm not sure why I'm getting that error.
Some example data are below, but note that in my real data, the dv's
are indeed non-independent (they are in fact the number of trials
classified into each of three categories).

a = expand.grid(
	sid = 1:20
	, condition = factor(1:2)
)
a$group = factor(a$sid%%2)
a$sid = factor(a$sid)
a$dv1 = rnorm(nrow(a))
a$dv2 = rnorm(nrow(a))
a$dv3 = rnorm(nrow(a))

MCMCglmm(
	cbind(dv1,dv2,dv3)~condition*group
	, random = ~ sid
	, family = 'multinomial3'
	, data = a
)



-- 
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~



From chris.kleier at gmail.com  Thu Jun 17 14:51:21 2010
From: chris.kleier at gmail.com (Chris Kleier)
Date: Thu, 17 Jun 2010 14:51:21 +0200
Subject: [R-sig-ME] lme posthoc constrasts for interaction effects group*time
Message-ID: <AANLkTilMkK9HJZqXDZimDzKCswXElxw__dUVQpSnW8FQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100617/a020c4c0/attachment.pl>

From bates at stat.wisc.edu  Fri Jun 18 16:46:46 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 18 Jun 2010 09:46:46 -0500
Subject: [R-sig-ME] lmer
In-Reply-To: <COL103-W509A822C6E3DE30C3914328EC00@phx.gbl>
References: <COL103-W6338D36014234866CB91958EDF0@phx.gbl>
	<AANLkTiksuUpVFePB5BIJI-PSxZhjTNR71m5ZqRszoira@mail.gmail.com>
	<COL103-W509A822C6E3DE30C3914328EC00@phx.gbl>
Message-ID: <AANLkTinjM_CzS0ZEu6A6ehZE5AoCt4mz6bCfhhmS7-Kn@mail.gmail.com>

On Fri, Jun 18, 2010 at 8:42 AM, Ricardo Alvarado
<hipotesis_delta at hotmail.com> wrote:
> Thank you very much for your response.
>
> I really need to use this package and make it work, maybe you can help me to
> define the right model I need to input.
>
> I have 3 blocks with 5 treatments within each block.? We gathered
> information from response variables at 5 different times on the same units -
> so I have a longitudinal study.
>
> If I call:
>
> B: blocks??????? - a,b,c? (factor)
> T: treatments? - A,B,C,D,E? (factor)
> t: time??????????? -? 15, 30, 45, 60, 75 days (continuous)
>
> How do I write the model and how do I determine the degrees of freedom?

Please send such messages to the R-SIG-Mixed-Models at R-project.org
mailing list, which I am cc:ing on this reply.

>
> I wrote this:
>
> ?????????? lmer(y~t*T+(t|B))
>
> but I am not sure if it is taking into accout the random nature of the
> blocks where the treatements are included.
>
> I would really appreciate if you could give me some insight on this.
>
> Best regards,
>
> Ricardo
> ----------------------
>
> On Thu, Jun 17, 2010 at 3:56 AM, Ricardo Alvarado
> <hipotesis_delta at hotmail.com> wrote:
>> Hello:
>> I am using package lme4. When I run a model with lmer I don't get the
>> p-values.
>
> That's intentional.  See R FAQ (Frequently Asked Questions) 7.35
>
> 7.35 Why are p-values not displayed when using lmer()?
>
> Doug Bates has kindly provided an extensive response in a post to the
> r-help list, which can be reviewed at
>
> https://stat.ethz.ch/pipermail/r-help/2006-May/094765.html.
>
>> Is there any way to get them directly without have to compute from
>> the F values?
>
> Before you can evaluate a p-value from an F distribution you will need
> to decide on the degrees of freedom in the denominator and that is the
> source of controversy.
>
> ________________________________
> Hotmail es m?s seguro. Con el Filtro Anti Spam tu cuenta est? mucho m?s
> protegida. Ver m?s



From nikko at hailmail.net  Fri Jun 18 18:27:17 2010
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Fri, 18 Jun 2010 09:27:17 -0700
Subject: [R-sig-ME] lme posthoc constrasts for interaction effects group*time
In-Reply-To: <mailman.7.1276855203.25637.r-sig-mixed-models@r-project.org>
References: <mailman.7.1276855203.25637.r-sig-mixed-models@r-project.org>
Message-ID: <1276878437.5914.1380778075@webmail.messagingengine.com>

Hi,
Try 
library(multcomp)
test<-glht(model,lin=mcp(group="Tukey"))
confint(test)

However, that just tests the marginal effect of group. 
With interactions you want to test over time, probably a simultaneous
interval.
This will get you close:
library(contrast)
ctt<-contrast(model, a=list( day=c(0,3,7,21,49), group=c(Small Stroke",
"Large Stroke")),
              b=list(day=c(0,3,7,21,49), group=c("Control", "Control")))
## Extract the contrast matrix
cmtrx <- ctt$X

## Fit the contrasts using glht
ttgl<-glht(model,lin=cmtrx)

confint(ttgl)

hope this helps.
And do read the vignette in multcomp  :)

Nicholas


> Message: 2
> Date: Thu, 17 Jun 2010 14:51:21 +0200
> From: Chris Kleier <chris.kleier at gmail.com>
> To: R sig-mixed-models <r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] lme posthoc constrasts for interaction effects
> 	group*time
> Message-ID:
> 	<AANLkTilMkK9HJZqXDZimDzKCswXElxw__dUVQpSnW8FQ at mail.gmail.com>
> Content-Type: text/plain
> 
> Hi all,
> 
> Our dataset is a repeated measures design including 3 groups (a)
> Controls,
> (b) Small stroke and (c) Large stroke. We want to know if the group
> behave
> different over time.
> 
> We first fitted a lme with fixed = group * time (see below).
> Their was a significant interaction effect (see below as well; p < 0.05)
> 
> In the next step we want to know which groups have significant
> interactions
> (Control - Stroke large, Control - Stroke small, Stroke small - Stroke
> large), and their p-values + CIs.
> 
> A posthoc Tukey, I think is fine. However, I do not know how to setup the
> constrast matrix.
> 
> These are the contrast names ( names( coef( model ) ) ):
> "(Intercept)", "groupStroke large", "groupStroke small", "time",
> "groupStroke large:time" "groupStroke small:time"
> 
> I guess, the model has to be refitted to get a contrast for
> "groupControl:time" as well, but I do not know how.
> 
> Any solution known? (Probabily something in the direction of: model.2 <-
> update( model, fixed = 0 + group * time ) )
> 
> Thanks!
> 
> Chris
> 
> 
> 
> 
> 
> This is a print of the dataset:
> 
>     subject        group       value day
> 1       N03 Stroke small  0.47545500   0
> 2       N04 Stroke small  0.38866500   0
> 3       N19 Stroke small  0.64749800   0
> 4       N20 Stroke small  0.50468600   0
> 5       N22 Stroke small  0.55872300   0
> 6       N03 Stroke small  0.01979970   3
> 7       N04 Stroke small  0.05607250   3
> 8       N19 Stroke small -0.04506370   3
> 9       N20 Stroke small -0.33935400   3
> 10      N22 Stroke small  0.22052700   3
> 11      N03 Stroke small  0.29805300   7
> 12      N04 Stroke small -0.24908100   7
> 13      N19 Stroke small -0.02657290   7
> 14      N20 Stroke small -0.19483200   7
> 15      N22 Stroke small  0.50948000   7
> 16      N03 Stroke small  0.13056600  21
> 17      N04 Stroke small  0.33759500  21
> 18      N19 Stroke small  0.14929200  21
> 19      N20 Stroke small  0.25033100  21
> 20      N22 Stroke small  0.71456800  21
> 21      N03 Stroke small  0.39007100  49
> 22      N04 Stroke small  0.33254400  49
> 23      N19 Stroke small  0.27767600  49
> 24      N20 Stroke small  0.33467500  49
> 25      N22 Stroke small  0.52203500  49
> 26      N03 Stroke small  0.29851100  70
> 27      N04 Stroke small  0.50900200  70
> 28      N19 Stroke small  0.51781700  70
> 29      N20 Stroke small  0.69543700  70
> 30      N22 Stroke small  0.49337000  70
> 31      N01 Stroke large          NA   0
> 32      N07 Stroke large  0.54930600   0
> 33      N09 Stroke large  0.59703600   0
> 34      N10 Stroke large  0.72751400   0
> 35      N17 Stroke large  0.63878400   0
> 36      N23 Stroke large  0.65749100   0
> 37      N24 Stroke large  0.60945900   0
> 38      N28 Stroke large          NA   0
> 39      N01 Stroke large -0.31610900   3
> 40      N07 Stroke large -0.33615700   3
> 41      N09 Stroke large -0.24906400   3
> 42      N10 Stroke large  0.33868700   3
> 43      N17 Stroke large -0.31357300   3
> 44      N23 Stroke large -0.13162800   3
> 45      N24 Stroke large -0.45343700   3
> 46      N28 Stroke large -0.18206700   3
> 47      N01 Stroke large -0.05309070   7
> 48      N07 Stroke large -0.83318300   7
> 49      N09 Stroke large -0.49667100   7
> 50      N10 Stroke large -0.48083200   7
> 51      N17 Stroke large -0.28447000   7
> 52      N23 Stroke large  0.01842660   7
> 53      N24 Stroke large -0.50464400   7
> 54      N28 Stroke large  0.16456100   7
> 55      N01 Stroke large  0.24652600  21
> 56      N07 Stroke large -0.31566500  21
> 57      N09 Stroke large  0.39618900  21
> 58      N10 Stroke large -0.30702200  21
> 59      N17 Stroke large -0.28860100  21
> 60      N23 Stroke large -0.23851000  21
> 61      N24 Stroke large -0.00913697  21
> 62      N28 Stroke large  0.43462600  21
> 63      N01 Stroke large -0.20660100  49
> 64      N07 Stroke large -0.13044900  49
> 65      N09 Stroke large  0.24625000  49
> 66      N10 Stroke large -0.28206200  49
> 67      N17 Stroke large  0.29186400  49
> 68      N23 Stroke large -0.14246600  49
> 69      N24 Stroke large -0.11297700  49
> 70      N28 Stroke large  0.32027300  49
> 71      N01 Stroke large -0.00106427  70
> 72      N07 Stroke large -0.17264000  70
> 73      N09 Stroke large  0.26417500  70
> 74      N10 Stroke large -0.11202200  70
> 75      N17 Stroke large  0.16687700  70
> 76      N23 Stroke large -0.24308300  70
> 77      N24 Stroke large  0.00322026  70
> 78      N28 Stroke large  0.34928100  70
> 79      C01      Control          NA   0
> 80      C02      Control          NA   0
> 81      C03      Control          NA   0
> 82      C04      Control          NA   0
> 83      C05      Control          NA   0
> 84      C06      Control          NA   0
> 85      C07      Control          NA   0
> 86      C09      Control          NA   0
> 87      C10      Control          NA   0
> 88      C32      Control          NA   0
> 89      C01      Control  0.32387500   3
> 90      C02      Control  0.48334200   3
> 91      C03      Control  0.70698800   3
> 92      C04      Control  0.00572262   3
> 93      C05      Control  0.40416000   3
> 94      C06      Control  0.36343800   3
> 95      C07      Control  0.05064140   3
> 96      C09      Control  0.84621500   3
> 97      C10      Control  0.80675300   3
> 98      C32      Control          NA   3
> 99      C01      Control  0.23174400   7
> 100     C02      Control  0.36959100   7
> 101     C03      Control  0.43762800   7
> 102     C04      Control  0.34187100   7
> 103     C05      Control  0.74288400   7
> 104     C06      Control  0.17692600   7
> 105     C07      Control  0.60067600   7
> 106     C09      Control  0.80314900   7
> 107     C10      Control  0.81695500   7
> 108     C32      Control  0.19029400   7
> 109     C01      Control  0.45062600  21
> 110     C02      Control  0.62884500  21
> 111     C03      Control  0.33693200  21
> 112     C04      Control  0.76098800  21
> 113     C05      Control  0.59837500  21
> 114     C06      Control  0.39328800  21
> 115     C07      Control  0.55099400  21
> 116     C09      Control  0.75411500  21
> 117     C10      Control  0.72495100  21
> 118     C32      Control  0.66503400  21
> 119     C01      Control  0.63903900  49
> 120     C02      Control          NA  49
> 121     C03      Control  0.59655200  49
> 122     C04      Control  0.42958700  49
> 123     C05      Control  0.68408700  49
> 124     C06      Control  0.45482700  49
> 125     C07      Control  0.37217700  49
> 126     C09      Control  0.75770400  49
> 127     C10      Control  0.62059200  49
> 128     C32      Control  0.68320900  49
> 129     C01      Control  0.66179300  70
> 130     C02      Control  0.34183000  70
> 131     C03      Control  0.58543900  70
> 132     C04      Control  0.62621700  70
> 133     C05      Control  0.40610400  70
> 134     C06      Control  0.32596100  70
> 135     C07      Control  0.14847100  70
> 136     C09      Control  0.79177000  70
> 137     C10      Control  0.71970900  70
> 138     C32      Control  0.56702700  70
> 
> This is our model:
> 
> model <- lme( na.action = na.omit, data = data, fixed = value ~ group *
> time, random = ~1 | subject, correlation = corCAR1( form = ~time |
> subject )
> )
> 
> 
> 
> anova( model )
> 
>             numDF denDF  F-value p-value
> (Intercept)     1    87 59.08836  <.0001
> group           2    20 34.50706  <.0001
> time            1    87 19.45032  <.0001
> group:time      2    87  4.53603  0.0134
> 
> 
> 
> intervals( model )
> 
> Approximate 95% confidence intervals
> 
>  Fixed effects:
>                                lower          est.        upper
> (Intercept)             0.3677066515  0.4905816494  0.613456647
> groupStroke large      -0.9027833601 -0.7106686760 -0.518553992
> groupStroke small      -0.6705657199 -0.4490365094 -0.227507299
> time                   -0.0013629996  0.0009963115  0.003355623
> groupStroke large:time -0.0003754957  0.0031296769  0.006634850
> groupStroke small:time  0.0019261801  0.0059657552  0.010005330
> attr(,"label")
> [1] "Fixed effects:"
> 
>  Random Effects:
>   Level: subject
>                      lower      est.     upper
> sd((Intercept)) 0.07377088 0.1227132 0.2041257
> 
>  Correlation structure:
>         lower      est.     upper
> Phi 0.2035765 0.5971507 0.8957905
> attr(,"label")
> [1] "Correlation structure:"
> 
>  Within-group standard error:
>     lower      est.     upper
> 0.1779472 0.2071400 0.2411220
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------
> 
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> End of R-sig-mixed-models Digest, Vol 42, Issue 22
> **************************************************
>



From DOgle at northland.edu  Fri Jun 18 21:39:02 2010
From: DOgle at northland.edu (Derek Ogle)
Date: Fri, 18 Jun 2010 14:39:02 -0500
Subject: [R-sig-ME] Model Setup Help
Message-ID: <42367154246C08458DDA1F9A7AD4834680CCB5FA@nc-mail.northland.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100618/001bc610/attachment.pl>

From fog0 at gmx.com  Fri Jun 18 22:06:13 2010
From: fog0 at gmx.com (Doug Adams)
Date: Fri, 18 Jun 2010 14:06:13 -0600
Subject: [R-sig-ME] Nutrition questionnaire data
In-Reply-To: <AANLkTikIWB_rDmxgF8ncO4K0TnGGcUGGr2-YuGz5VQwY@mail.gmail.com>
References: <AANLkTinppM3mp9BU0uxnq_AByQs1FUh5SrkuGw5gEt9g@mail.gmail.com>
	<AANLkTinhv1iaDj_ros-9J7tNIy8cVnTkS9K3vYBzp38d@mail.gmail.com>
	<AANLkTikIWB_rDmxgF8ncO4K0TnGGcUGGr2-YuGz5VQwY@mail.gmail.com>
Message-ID: <AANLkTinbbGMc4OsjpIOWjXuDUSLUBZKBGO0tR2Wtcm1o@mail.gmail.com>

> P.S. - If there's a reference for the modeling syntax used in R -- or
> in lme4 specifically if need be -- and how each operator works, please
> let me know. ?For example, if there were a help document that says
> things like " A\B means A is nested within B ," or " the | symbol
> denotes the the following factor is at a higher level in the model, "
> etc., that would be so helpful. ?I've learned a lot from context, from
> Pinheiro & Bates (though that's for nlme), and from this forum, but I
> haven't been able to find something like a formula syntax reference
> like that.

To answer my own question, I found that Douglas Bates already did
indeed an excellent job of explaining those very things:

http://cran.r-project.org/doc/Rnews/Rnews_2005-1.pdf

I hope that helps if anyone had the same types of questions   : )

Doug Adams



From DOgle at northland.edu  Fri Jun 18 22:41:14 2010
From: DOgle at northland.edu (Derek Ogle)
Date: Fri, 18 Jun 2010 15:41:14 -0500
Subject: [R-sig-ME] Model Setup Help
In-Reply-To: <42367154246C08458DDA1F9A7AD4834680CCB5FA@nc-mail.northland.edu>
References: <42367154246C08458DDA1F9A7AD4834680CCB5FA@nc-mail.northland.edu>
Message-ID: <42367154246C08458DDA1F9A7AD4834680CCB616@nc-mail.northland.edu>

Off-list it was suggested that I should supply some data.  A text file of the data I am working with is at

http://www.ncfaculty.net/dogle/me_ex.txt

The YEAR and SITE variables should be factor()ed after reading the data file.

Thanks.

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-
> models-bounces at r-project.org] On Behalf Of Derek Ogle
> Sent: Friday, June 18, 2010 2:39 PM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Model Setup Help
> 
> I am working on a project to convert some SAS code to R code as an on-
> line addendum to a published book
> (http://www.montana.edu/mtcfru/Guy/AIFFD.html).  For the most part this
> has been fairly straightforward.  However, I do not have much
> experience, and I am currently struggling to learn, with mixed-effects
> models.  As a hope to create a conversion from SAS to R that I can
> learn from, I have been attempting to work with the following
> situation.
> 
> Numbers of fish in two size categories were captured on one lake, over
> a nine year period (variable YEAR), at 12 fixed sites (variable SITE)
> each year.  A management regulation was implemented during the nine-
> year sampling period such that the years have been categorized as
> either "APRE" (before the regulation) or "BPOST" (after the regulation)
> (variable PERIOD).  The total number of fish in both size categories
> have been summed (variable TOTAL) and the log ratio of the number of
> fish in each size category has been created (variable LOGIT).  PERIOD,
> YEAR, and SITE are factor variables, LOGIT is a continuous quantitative
> variable, and TOTAL is a discrete quantitative variable.  The ultimate
> goal is to determine if mean LOGIT differed between periods (i.e., does
> the "ratio" of the two size categories differ from before to after the
> implementation of the regulation).
> 
> I would consider PERIOD to be a fixed effect, YEAR to be random, and
> there to be a lack of independence from year-to-year of LOGIT and TOTAL
> at each SITE.
> 
> The SAS PROC MIXED code that I am trying to convert is
> 
> PROC MIXED;
> CLASS PERIOD YEAR SITE;
> MODEL LOGIT=PERIOD;
> WEIGHT TOTAL;
> RANDOM YEAR(PERIOD);
> REPEATED YEAR/SUBJECT=SITE TYPE=AR(1);
> RUN;
> 
> I have tried various "things" in lme() from the nlme package but to no
> real success (defined as either re-creating something close to the SAS
> output or convincing myself that I knew what I was doing).
> 
> If someone has the time and inclination to help me set up lme() code (I
> assume that that is the most appropriate function) for this situation I
> would be very thankful.  Thank you in advance for any help you can
> offer.
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From roberto.patuelli at usi.ch  Sat Jun 19 15:29:32 2010
From: roberto.patuelli at usi.ch (Roberto Patuelli)
Date: Sat, 19 Jun 2010 15:29:32 +0200
Subject: [R-sig-ME] Zero-inflated negative binomial mixed model?
Message-ID: <4A61C498BBAF488D9CA941447C3F18A3@Ciretto>

Dear Listers,

I was wondering if there is any implementation available in R of a GLMM 
based on a zero-inflated negative binomial (basically a zero-inflated 
negative binomial mixed effects model).
I see at least one paper online (KKW Yau, K Wang, AH Lee - Biometrical 
Journal, 2003) where something like this has been developed (but right now I 
can't read the paper because Wiley Interscience is down for maintenance).

Thanks and best regards,
Roberto Patuelli

********************
Roberto Patuelli, Ph.D.
Istituto Ricerche Economiche (IRE) (Institute for Economic Research)
Universit? della Svizzera Italiana (University of Lugano)
via Maderno 24, CP 4361
CH-6904 Lugano
Switzerland
Phone: +41-(0)58-666-4166
Fax: +39-02-700419665
Email: roberto.patuelli at usi.ch
Homepage: http://www.people.lu.unisi.ch/patuellr



From datkins at u.washington.edu  Sat Jun 19 17:26:48 2010
From: datkins at u.washington.edu (David Atkins)
Date: Sat, 19 Jun 2010 08:26:48 -0700
Subject: [R-sig-ME] Zero-inflated negative binomial mixed model?
In-Reply-To: <4A61C498BBAF488D9CA941447C3F18A3@Ciretto>
References: <4A61C498BBAF488D9CA941447C3F18A3@Ciretto>
Message-ID: <4C1CE1B8.2040409@u.washington.edu>


Roberto--

Yau et al. wrote some functions in Splus to fit their models.  At one 
point, I had gotten them (I think from Andy Lee, if memory serves), 
though they are not terribly user-friendly, and I think the last time I 
tried to use them in R (a couple years back), I was unable to do so.

However, I would definitely recommend the MCMCglmm package, which can 
fit an over-dispersed Poisson mixed model.  It includes a 
per-observation random-effect to handle the over-dispersion.

Hope that helps.

cheers, Dave

Roberto wrote:

Dear Listers,

I was wondering if there is any implementation available in R of a GLMM
based on a zero-inflated negative binomial (basically a zero-inflated
negative binomial mixed effects model).
I see at least one paper online (KKW Yau, K Wang, AH Lee - Biometrical
Journal, 2003) where something like this has been developed (but right 
now I
can't read the paper because Wiley Interscience is down for maintenance).

Thanks and best regards,
Roberto Patuelli

********************
Roberto Patuelli, Ph.D.
Istituto Ricerche Economiche (IRE) (Institute for Economic Research)
Universit? della Svizzera Italiana (University of Lugano)
via Maderno 24, CP 4361
CH-6904 Lugano
Switzerland
Phone: +41-(0)58-666-4166
Fax: +39-02-700419665
Email: roberto.patuelli at usi.ch
Homepage: http://www.people.lu.unisi.ch/patuellr


-- 
Dave Atkins, PhD
Research Associate Professor
Department of Psychiatry and Behavioral Science
University of Washington
datkins at u.washington.edu

Center for the Study of Health and Risk Behaviors (CSHRB)		
1100 NE 45th Street, Suite 300 	
Seattle, WA  98105 	
206-616-3879 	
http://depts.washington.edu/cshrb/
(Mon-Wed)	

Center for Healthcare Improvement, for Addictions, Mental Illness,
   Medically Vulnerable Populations (CHAMMP)
325 9th Avenue, 2HH-15
Box 359911
Seattle, WA 98104?
206-897-4210
http://www.chammp.org
(Thurs)



From datkins at u.washington.edu  Sat Jun 19 17:42:57 2010
From: datkins at u.washington.edu (David Atkins)
Date: Sat, 19 Jun 2010 08:42:57 -0700
Subject: [R-sig-ME] Computational speed - MCMCglmm/lmer
Message-ID: <4C1CE581.9030205@u.washington.edu>


Hi all--

I use (g)lmer and MCMCglmm on a weekly basis, and I am wondering about 
options for speeding up their computations.  This is primarily an issue 
with MCMCglmm, given the many necessary MCMC iterations to get to 
convergence on some problems.  But, even with glmer(), I have runs that 
get into 20-30 minutes.

First, let me be very clear that this is in no way a criticism of Doug's 
and Jarrod's work (package developers for lme4 and MCMCglmm, 
respectively).  Their code has probably brought models/data into range 
that would not have been possible.

Second, I have included link to data and script below, along with some 
timings on my computer: Mac Book Pro, 2.5GHz, with 4GB RAM.  Here's 
sessionInfo from my runs:

 > sessionInfo()
R version 2.11.1 (2010-05-31)
i386-apple-darwin9.8.0

locale:
[1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] MCMCglmm_2.05      corpcor_1.5.6      ape_2.5-3
[4] coda_0.13-5        tensorA_0.35       lme4_0.999375-34
[7] Matrix_0.999375-41 lattice_0.19-7

loaded via a namespace (and not attached):
[1] gee_4.13-14   grid_2.11.1   nlme_3.1-96   stats4_2.11.1 tools_2.11.1

Specific questions:

1. Would be curious to know timings on other people's set-ups.  Jarrod 
and I had an exchange one time where he was gracious enough to run a 
zero-inflated model where I was concerned about convergence.  He ran a 
model with 1.3M iterations, which I think would take a number of days, 
if not a week on my computer.  This was part of what got me thinking 
about this.  Thus, my first interest is whether there is an "optimal" 
hardware/OS configuration, or does it matter?

Some things I see in R-help archives:

2. 32 vs. 64-bit: Seems like this is mostly an issue of data/model size 
and whether you need to access more than 4GB of RAM.  AFAICS, 64-bit 
processors are not necessarily faster.

3. "Optimized" BLAS: There's a bit of discussion about optimized BLAS 
(basis linear algebra... something).  However, these discussions note 
that there is no generally superior BLAS.  Not sure whether specific 
BLAS might be optimized for GLMM computations.

4. Parallel computing: With multi-core computers, looks like there are 
some avenues for splitting intensive computations across processors.

Finally, I'm asking here b/c I run into these issues with GLMM (and 
zero-inflated mixed models), though most of the discussion I've seen 
thus far about computation speed has been on R-help.

The data below are self-reported drinks (alcohol) from college students 
for up to the last 90 days.  Distribution of counts is zero-inflated.  I 
run a Poisson GLMM with glmer, over-dispersed Poisson GLMM with 
MCMCglmm, and then zero-inflated OD Poisson with MCMCglmm and provide 
timings for my set-up.

Okay, any and all thoughts welcomed.

thanks, Dave


### thinking through computational speed with lmer and MCMCglmm
#
### read drinking data
drink.df <- read.table(file = 
"http://depts.washington.edu/cshrb/newweb/stats%20documents/tlfb.txt",
						header = TRUE, sep = "\t")
str(drink.df) # 57K rows

### id is id variable (shocking)
### gender and weekday are 0/1 indicator variables
### drinks has number of drinks consumed

### distribution of outcome
table(drink.df$drinks)
plot(table(drink.df$drinks), lwd=2) # zero-inflated

### how many people?
length(unique(drink.df$id)) # 990
sort(table(drink.df$id))

### NOTE: most people have max of 90, which they should
###			two folks with 180 and 435 (prob data errors)
###			long negative tail down from 90
#
### NOTE: for this purpose, not worrying about the 180/435

### speed tests
#
### fit random intercept and random slope for weekday
### fixed effects for gender and weekday and interaction
#
### Poisson GLMM with glmer()
library(lme4)

system.time(
drk.glmer <- glmer(drinks ~ weekday*gender + (weekday | id),
					data = drink.df, family = poisson,
					verbose = TRUE)
)
summary(drk.glmer)

### timing
#
###    user  system elapsed
###  36.326   9.013  45.316
					
### over-dispersed Poisson GLMM with MCMCglmm()
library(MCMCglmm)

prior <- list(R = list(V = 1, n = 1),
				G = list(G1 = list(V = diag(2), n = 2)))
system.time(
drk.mcmc <- MCMCglmm(drinks ~ weekday*gender,
					random = ~ us(1 + weekday):id,
					data = drink.df, family = "poisson",
					prior = prior)
)
summary(drk.mcmc) # NOTE: using summary.MCMCglmm in v 2.05 of package

### timing
#
###        user   system  elapsed
### 	1034.317  165.128 1203.536

### zero-inflated, over-dispersed Poisson GLMM with MCMCglmm()
#
### NOTE: haven't run the following yet, other than a quick "toy run" to
###			sure that it is set up correctly.
### NOTE: this only has random intercept in each portion of the model

prior2 <- list(R = list(V = diag(2), n = 1, fix = 2),
				G = list(G1 = list(V = 1, n = 1),
						  G2 = list(V = 1, n = 1)))
system.time(
drk.zimcmc <- MCMCglmm(drinks ~ -1 + trait*weekday*gender,
					random = ~ idh(at.level(trait, 1)):id + idh(at.level(trait, 2)):id,
					rcov = ~ idh(trait):units,
					data = drink.df, family = "zipoisson",
					prior = prior2)
)
summary(drk.zimcmc)

### timing
#
###    	 user   system  elapsed
###    2105.366  544.881 2640.030

-- 
Dave Atkins, PhD
Research Associate Professor
Department of Psychiatry and Behavioral Science
University of Washington
datkins at u.washington.edu

Center for the Study of Health and Risk Behaviors (CSHRB)		
1100 NE 45th Street, Suite 300 	
Seattle, WA  98105 	
206-616-3879 	
http://depts.washington.edu/cshrb/
(Mon-Wed)	

Center for Healthcare Improvement, for Addictions, Mental Illness,
   Medically Vulnerable Populations (CHAMMP)
325 9th Avenue, 2HH-15
Box 359911
Seattle, WA 98104?
206-897-4210
http://www.chammp.org
(Thurs)



From bates at stat.wisc.edu  Sat Jun 19 18:50:24 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 19 Jun 2010 11:50:24 -0500
Subject: [R-sig-ME] Computational speed - MCMCglmm/lmer
In-Reply-To: <4C1CE581.9030205@u.washington.edu>
References: <4C1CE581.9030205@u.washington.edu>
Message-ID: <AANLkTimAq9cmn87M7BcQepEOo5TaAdiR3xSMgaR2-waf@mail.gmail.com>

Thanks for making the data available, Dave.  I will be very interested
in seeing if I can make glmer more effective in fitting this model.

Right now I have a quick question, what are genders 0, 1, 2?  I
checked that if gender is consistent within subjects, which it is, so
you have 549 subjects of gender 0, 439 of gender 1 and 2 of gender 2.
If I wanted to label them as "M", "F" and "?" which labels should I
apply to genders 0 and 1 and what does gender 2 mean?

> drink.df <- within(read.delim("http://depts.washington.edu/cshrb/newweb/stats%20documents/tlfb.txt"),
+                    {
+                        id      <- factor(id)
+                        gender  <- factor(gender)
+                        weekday <- factor(weekday, labels = c("N","Y"))
+                    })
> str(drink.df) # 57K rows
'data.frame':	57318 obs. of  4 variables:
 $ id     : Factor w/ 990 levels "1014503","1017782",..: 1 1 1 2 2 2 2 2 2 2 ...
 $ gender : Factor w/ 3 levels "0","1","2": 1 1 1 2 2 2 2 2 2 2 ...
 $ weekday: Factor w/ 2 levels "N","Y": 2 1 1 2 1 1 2 2 2 2 ...
 $ drinks : int  0 0 5 8 5 10 0 0 0 0 ...
> summary(drink.df)
       id        gender    weekday       drinks
 8396125:  435   0:32445   N:16633   Min.   : 0.0000
 6551092:  180   1:24780   Y:40685   1st Qu.: 0.0000
 1028078:   90   2:   93             Median : 0.0000
 1325095:   90                       Mean   : 0.9983
 1365806:   90                       3rd Qu.: 0.0000
 1411092:   90                       Max.   :45.0000
 (Other):56343
> str(subj <- unique(subset(drink.df, select = c(id, gender))))
'data.frame':	990 obs. of  2 variables:
 $ id    : Factor w/ 990 levels "1014503","1017782",..: 1 2 3 4 5 6 7 8 9 10 ...
 $ gender: Factor w/ 3 levels "0","1","2": 1 2 1 1 2 2 1 1 1 2 ...
> summary(subj)
       id      gender
 1014503:  1   0:549
 1017782:  1   1:439
 1018311:  1   2:  2
 1026066:  1
 1028078:  1
 1036230:  1
 (Other):984


On Sat, Jun 19, 2010 at 10:42 AM, David Atkins <datkins at u.washington.edu> wrote:
>
> Hi all--
>
> I use (g)lmer and MCMCglmm on a weekly basis, and I am wondering about
> options for speeding up their computations. ?This is primarily an issue with
> MCMCglmm, given the many necessary MCMC iterations to get to convergence on
> some problems. ?But, even with glmer(), I have runs that get into 20-30
> minutes.
>
> First, let me be very clear that this is in no way a criticism of Doug's and
> Jarrod's work (package developers for lme4 and MCMCglmm, respectively).
> ?Their code has probably brought models/data into range that would not have
> been possible.
>
> Second, I have included link to data and script below, along with some
> timings on my computer: Mac Book Pro, 2.5GHz, with 4GB RAM. ?Here's
> sessionInfo from my runs:
>
>> sessionInfo()
> R version 2.11.1 (2010-05-31)
> i386-apple-darwin9.8.0
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
> other attached packages:
> [1] MCMCglmm_2.05 ? ? ?corpcor_1.5.6 ? ? ?ape_2.5-3
> [4] coda_0.13-5 ? ? ? ?tensorA_0.35 ? ? ? lme4_0.999375-34
> [7] Matrix_0.999375-41 lattice_0.19-7
>
> loaded via a namespace (and not attached):
> [1] gee_4.13-14 ? grid_2.11.1 ? nlme_3.1-96 ? stats4_2.11.1 tools_2.11.1
>
> Specific questions:
>
> 1. Would be curious to know timings on other people's set-ups. ?Jarrod and I
> had an exchange one time where he was gracious enough to run a zero-inflated
> model where I was concerned about convergence. ?He ran a model with 1.3M
> iterations, which I think would take a number of days, if not a week on my
> computer. ?This was part of what got me thinking about this. ?Thus, my first
> interest is whether there is an "optimal" hardware/OS configuration, or does
> it matter?
>
> Some things I see in R-help archives:
>
> 2. 32 vs. 64-bit: Seems like this is mostly an issue of data/model size and
> whether you need to access more than 4GB of RAM. ?AFAICS, 64-bit processors
> are not necessarily faster.
>
> 3. "Optimized" BLAS: There's a bit of discussion about optimized BLAS (basis
> linear algebra... something). ?However, these discussions note that there is
> no generally superior BLAS. ?Not sure whether specific BLAS might be
> optimized for GLMM computations.
>
> 4. Parallel computing: With multi-core computers, looks like there are some
> avenues for splitting intensive computations across processors.
>
> Finally, I'm asking here b/c I run into these issues with GLMM (and
> zero-inflated mixed models), though most of the discussion I've seen thus
> far about computation speed has been on R-help.
>
> The data below are self-reported drinks (alcohol) from college students for
> up to the last 90 days. ?Distribution of counts is zero-inflated. ?I run a
> Poisson GLMM with glmer, over-dispersed Poisson GLMM with MCMCglmm, and then
> zero-inflated OD Poisson with MCMCglmm and provide timings for my set-up.
>
> Okay, any and all thoughts welcomed.
>
> thanks, Dave
>
>
> ### thinking through computational speed with lmer and MCMCglmm
> #
> ### read drinking data
> drink.df <- read.table(file =
> "http://depts.washington.edu/cshrb/newweb/stats%20documents/tlfb.txt",
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?header = TRUE, sep = "\t")
> str(drink.df) # 57K rows
>
> ### id is id variable (shocking)
> ### gender and weekday are 0/1 indicator variables
> ### drinks has number of drinks consumed
>
> ### distribution of outcome
> table(drink.df$drinks)
> plot(table(drink.df$drinks), lwd=2) # zero-inflated
>
> ### how many people?
> length(unique(drink.df$id)) # 990
> sort(table(drink.df$id))
>
> ### NOTE: most people have max of 90, which they should
> ### ? ? ? ? ? ? ? ? ? ? two folks with 180 and 435 (prob data errors)
> ### ? ? ? ? ? ? ? ? ? ? long negative tail down from 90
> #
> ### NOTE: for this purpose, not worrying about the 180/435
>
> ### speed tests
> #
> ### fit random intercept and random slope for weekday
> ### fixed effects for gender and weekday and interaction
> #
> ### Poisson GLMM with glmer()
> library(lme4)
>
> system.time(
> drk.glmer <- glmer(drinks ~ weekday*gender + (weekday | id),
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?data = drink.df, family = poisson,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?verbose = TRUE)
> )
> summary(drk.glmer)
>
> ### timing
> #
> ### ? ?user ?system elapsed
> ### ?36.326 ? 9.013 ?45.316
>
> ### over-dispersed Poisson GLMM with MCMCglmm()
> library(MCMCglmm)
>
> prior <- list(R = list(V = 1, n = 1),
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?G = list(G1 = list(V = diag(2), n = 2)))
> system.time(
> drk.mcmc <- MCMCglmm(drinks ~ weekday*gender,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?random = ~ us(1 + weekday):id,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?data = drink.df, family = "poisson",
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?prior = prior)
> )
> summary(drk.mcmc) # NOTE: using summary.MCMCglmm in v 2.05 of package
>
> ### timing
> #
> ### ? ? ? ?user ? system ?elapsed
> ### ? ? 1034.317 ?165.128 1203.536
>
> ### zero-inflated, over-dispersed Poisson GLMM with MCMCglmm()
> #
> ### NOTE: haven't run the following yet, other than a quick "toy run" to
> ### ? ? ? ? ? ? ? ? ? ? sure that it is set up correctly.
> ### NOTE: this only has random intercept in each portion of the model
>
> prior2 <- list(R = list(V = diag(2), n = 1, fix = 2),
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?G = list(G1 = list(V = 1, n = 1),
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?G2 = list(V = 1, n = 1)))
> system.time(
> drk.zimcmc <- MCMCglmm(drinks ~ -1 + trait*weekday*gender,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?random = ~ idh(at.level(trait, 1)):id
> + idh(at.level(trait, 2)):id,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?rcov = ~ idh(trait):units,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?data = drink.df, family =
> "zipoisson",
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?prior = prior2)
> )
> summary(drk.zimcmc)
>
> ### timing
> #
> ### ? ? ?user ? system ?elapsed
> ### ? ?2105.366 ?544.881 2640.030
>
> --
> Dave Atkins, PhD
> Research Associate Professor
> Department of Psychiatry and Behavioral Science
> University of Washington
> datkins at u.washington.edu
>
> Center for the Study of Health and Risk Behaviors (CSHRB)
> 1100 NE 45th Street, Suite 300
> Seattle, WA ?98105
> 206-616-3879
> http://depts.washington.edu/cshrb/
> (Mon-Wed)
>
> Center for Healthcare Improvement, for Addictions, Mental Illness,
> ?Medically Vulnerable Populations (CHAMMP)
> 325 9th Avenue, 2HH-15
> Box 359911
> Seattle, WA 98104?
> 206-897-4210
> http://www.chammp.org
> (Thurs)
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From datkins at u.washington.edu  Sun Jun 20 02:00:11 2010
From: datkins at u.washington.edu (David Atkins)
Date: Sat, 19 Jun 2010 17:00:11 -0700
Subject: [R-sig-ME] Computational speed - MCMCglmm/lmer
In-Reply-To: <AANLkTimAq9cmn87M7BcQepEOo5TaAdiR3xSMgaR2-waf@mail.gmail.com>
References: <4C1CE581.9030205@u.washington.edu>
	<AANLkTimAq9cmn87M7BcQepEOo5TaAdiR3xSMgaR2-waf@mail.gmail.com>
Message-ID: <4C1D5A0B.60606@u.washington.edu>


Douglas Bates wrote:
> Thanks for making the data available, Dave.  I will be very interested
> in seeing if I can make glmer more effective in fitting this model.
> 
> Right now I have a quick question, what are genders 0, 1, 2?  I
> checked that if gender is consistent within subjects, which it is, so
> you have 549 subjects of gender 0, 439 of gender 1 and 2 of gender 2.
> If I wanted to label them as "M", "F" and "?" which labels should I
> apply to genders 0 and 1 and what does gender 2 mean?

Whoops, thought this data was a bit cleaner that apparently it is.

For gender, 0 = Female, 1 = Male

(Men drink more, so pretty easy to confirm...)

I would need to double-check on the 2s, though I do believe there is a 
category for transgendered on the demographics.

I'll try to get a cleaner dataset up soon.

D

> 
>> drink.df <- within(read.delim("http://depts.washington.edu/cshrb/newweb/stats%20documents/tlfb.txt"),
> +                    {
> +                        id      <- factor(id)
> +                        gender  <- factor(gender)
> +                        weekday <- factor(weekday, labels = c("N","Y"))
> +                    })
>> str(drink.df) # 57K rows
> 'data.frame':	57318 obs. of  4 variables:
>  $ id     : Factor w/ 990 levels "1014503","1017782",..: 1 1 1 2 2 2 2 2 2 2 ...
>  $ gender : Factor w/ 3 levels "0","1","2": 1 1 1 2 2 2 2 2 2 2 ...
>  $ weekday: Factor w/ 2 levels "N","Y": 2 1 1 2 1 1 2 2 2 2 ...
>  $ drinks : int  0 0 5 8 5 10 0 0 0 0 ...
>> summary(drink.df)
>        id        gender    weekday       drinks
>  8396125:  435   0:32445   N:16633   Min.   : 0.0000
>  6551092:  180   1:24780   Y:40685   1st Qu.: 0.0000
>  1028078:   90   2:   93             Median : 0.0000
>  1325095:   90                       Mean   : 0.9983
>  1365806:   90                       3rd Qu.: 0.0000
>  1411092:   90                       Max.   :45.0000
>  (Other):56343
>> str(subj <- unique(subset(drink.df, select = c(id, gender))))
> 'data.frame':	990 obs. of  2 variables:
>  $ id    : Factor w/ 990 levels "1014503","1017782",..: 1 2 3 4 5 6 7 8 9 10 ...
>  $ gender: Factor w/ 3 levels "0","1","2": 1 2 1 1 2 2 1 1 1 2 ...
>> summary(subj)
>        id      gender
>  1014503:  1   0:549
>  1017782:  1   1:439
>  1018311:  1   2:  2
>  1026066:  1
>  1028078:  1
>  1036230:  1
>  (Other):984
> 
> 
> On Sat, Jun 19, 2010 at 10:42 AM, David Atkins <datkins at u.washington.edu> wrote:
>> Hi all--
>>
>> I use (g)lmer and MCMCglmm on a weekly basis, and I am wondering about
>> options for speeding up their computations.  This is primarily an issue with
>> MCMCglmm, given the many necessary MCMC iterations to get to convergence on
>> some problems.  But, even with glmer(), I have runs that get into 20-30
>> minutes.
>>
>> First, let me be very clear that this is in no way a criticism of Doug's and
>> Jarrod's work (package developers for lme4 and MCMCglmm, respectively).
>>  Their code has probably brought models/data into range that would not have
>> been possible.
>>
>> Second, I have included link to data and script below, along with some
>> timings on my computer: Mac Book Pro, 2.5GHz, with 4GB RAM.  Here's
>> sessionInfo from my runs:
>>
>>> sessionInfo()
>> R version 2.11.1 (2010-05-31)
>> i386-apple-darwin9.8.0
>>
>> locale:
>> [1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] MCMCglmm_2.05      corpcor_1.5.6      ape_2.5-3
>> [4] coda_0.13-5        tensorA_0.35       lme4_0.999375-34
>> [7] Matrix_0.999375-41 lattice_0.19-7
>>
>> loaded via a namespace (and not attached):
>> [1] gee_4.13-14   grid_2.11.1   nlme_3.1-96   stats4_2.11.1 tools_2.11.1
>>
>> Specific questions:
>>
>> 1. Would be curious to know timings on other people's set-ups.  Jarrod and I
>> had an exchange one time where he was gracious enough to run a zero-inflated
>> model where I was concerned about convergence.  He ran a model with 1.3M
>> iterations, which I think would take a number of days, if not a week on my
>> computer.  This was part of what got me thinking about this.  Thus, my first
>> interest is whether there is an "optimal" hardware/OS configuration, or does
>> it matter?
>>
>> Some things I see in R-help archives:
>>
>> 2. 32 vs. 64-bit: Seems like this is mostly an issue of data/model size and
>> whether you need to access more than 4GB of RAM.  AFAICS, 64-bit processors
>> are not necessarily faster.
>>
>> 3. "Optimized" BLAS: There's a bit of discussion about optimized BLAS (basis
>> linear algebra... something).  However, these discussions note that there is
>> no generally superior BLAS.  Not sure whether specific BLAS might be
>> optimized for GLMM computations.
>>
>> 4. Parallel computing: With multi-core computers, looks like there are some
>> avenues for splitting intensive computations across processors.
>>
>> Finally, I'm asking here b/c I run into these issues with GLMM (and
>> zero-inflated mixed models), though most of the discussion I've seen thus
>> far about computation speed has been on R-help.
>>
>> The data below are self-reported drinks (alcohol) from college students for
>> up to the last 90 days.  Distribution of counts is zero-inflated.  I run a
>> Poisson GLMM with glmer, over-dispersed Poisson GLMM with MCMCglmm, and then
>> zero-inflated OD Poisson with MCMCglmm and provide timings for my set-up.
>>
>> Okay, any and all thoughts welcomed.
>>
>> thanks, Dave
>>
>>
>> ### thinking through computational speed with lmer and MCMCglmm
>> #
>> ### read drinking data
>> drink.df <- read.table(file =
>> "http://depts.washington.edu/cshrb/newweb/stats%20documents/tlfb.txt",
>>                                                header = TRUE, sep = "\t")
>> str(drink.df) # 57K rows
>>
>> ### id is id variable (shocking)
>> ### gender and weekday are 0/1 indicator variables
>> ### drinks has number of drinks consumed
>>
>> ### distribution of outcome
>> table(drink.df$drinks)
>> plot(table(drink.df$drinks), lwd=2) # zero-inflated
>>
>> ### how many people?
>> length(unique(drink.df$id)) # 990
>> sort(table(drink.df$id))
>>
>> ### NOTE: most people have max of 90, which they should
>> ###                     two folks with 180 and 435 (prob data errors)
>> ###                     long negative tail down from 90
>> #
>> ### NOTE: for this purpose, not worrying about the 180/435
>>
>> ### speed tests
>> #
>> ### fit random intercept and random slope for weekday
>> ### fixed effects for gender and weekday and interaction
>> #
>> ### Poisson GLMM with glmer()
>> library(lme4)
>>
>> system.time(
>> drk.glmer <- glmer(drinks ~ weekday*gender + (weekday | id),
>>                                        data = drink.df, family = poisson,
>>                                        verbose = TRUE)
>> )
>> summary(drk.glmer)
>>
>> ### timing
>> #
>> ###    user  system elapsed
>> ###  36.326   9.013  45.316
>>
>> ### over-dispersed Poisson GLMM with MCMCglmm()
>> library(MCMCglmm)
>>
>> prior <- list(R = list(V = 1, n = 1),
>>                                G = list(G1 = list(V = diag(2), n = 2)))
>> system.time(
>> drk.mcmc <- MCMCglmm(drinks ~ weekday*gender,
>>                                        random = ~ us(1 + weekday):id,
>>                                        data = drink.df, family = "poisson",
>>                                        prior = prior)
>> )
>> summary(drk.mcmc) # NOTE: using summary.MCMCglmm in v 2.05 of package
>>
>> ### timing
>> #
>> ###        user   system  elapsed
>> ###     1034.317  165.128 1203.536
>>
>> ### zero-inflated, over-dispersed Poisson GLMM with MCMCglmm()
>> #
>> ### NOTE: haven't run the following yet, other than a quick "toy run" to
>> ###                     sure that it is set up correctly.
>> ### NOTE: this only has random intercept in each portion of the model
>>
>> prior2 <- list(R = list(V = diag(2), n = 1, fix = 2),
>>                                G = list(G1 = list(V = 1, n = 1),
>>                                                  G2 = list(V = 1, n = 1)))
>> system.time(
>> drk.zimcmc <- MCMCglmm(drinks ~ -1 + trait*weekday*gender,
>>                                        random = ~ idh(at.level(trait, 1)):id
>> + idh(at.level(trait, 2)):id,
>>                                        rcov = ~ idh(trait):units,
>>                                        data = drink.df, family =
>> "zipoisson",
>>                                        prior = prior2)
>> )
>> summary(drk.zimcmc)
>>
>> ### timing
>> #
>> ###      user   system  elapsed
>> ###    2105.366  544.881 2640.030
>>
>> --
>> Dave Atkins, PhD
>> Research Associate Professor
>> Department of Psychiatry and Behavioral Science
>> University of Washington
>> datkins at u.washington.edu
>>
>> Center for the Study of Health and Risk Behaviors (CSHRB)
>> 1100 NE 45th Street, Suite 300
>> Seattle, WA  98105
>> 206-616-3879
>> http://depts.washington.edu/cshrb/
>> (Mon-Wed)
>>
>> Center for Healthcare Improvement, for Addictions, Mental Illness,
>>  Medically Vulnerable Populations (CHAMMP)
>> 325 9th Avenue, 2HH-15
>> Box 359911
>> Seattle, WA 98104?
>> 206-897-4210
>> http://www.chammp.org
>> (Thurs)
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>



From shigesong at gmail.com  Sun Jun 20 14:17:36 2010
From: shigesong at gmail.com (Shige Song)
Date: Sun, 20 Jun 2010 20:17:36 +0800
Subject: [R-sig-ME] Making glmmBUGS work with JAGS
Message-ID: <AANLkTinosf8kmXF6ivjK8NfhGI5YS5pGqe5Xtt9zq4Ad@mail.gmail.com>

Dear All,

I wonder if anybody has tried to make glmmBUGS work with JAGS. My
attempt was not successful.

Here is the simple example I copied from the glmmBUGS Vignettes:

------------------------
library(MASS)
data(bacteria)

bacterianew <- bacteria
bacterianew$yInt = as.integer(bacterianew$y == "y")

levels(bacterianew$trt) <- c("placebo", "drug", "drugplus")

library(glmmBUGS)

bacrag <- glmmBUGS(formula = yInt ~ trt + week, data=bacterianew,
effects = "ID",
                   modelFile="model.bug", family="bernoulli")

names(bacrag$ragged)

source("getInits.R")

startingValues = bacrag$startingValues
------------------------

With WinBUGS, it runs well:

------------------------
library(R2WinBUGS)

bacResult1 = bugs(bacrag$ragged, getInits, model.file="model.bug", n.chain=3,
  n.iter=2000, n.burnin=100, parameters=names(getInits()), n.thin=10)
------------------------

But with JAGS, I got error message "Error in FUN(50L[[1L]], ...) :
invalid first argument"

------------------------
library(R2jags)

jags.parms=names(getInits())

bacResult = jags(data=bacrag$ragged, n.chain=3, n.iter=2000,
model.file=model.bug)
------------------------

I hope somebody can help me figuring out how to make this work. Many thanks.

Best,
Shige



From Jeffrey.Evans at dartmouth.edu  Mon Jun 21 22:39:04 2010
From: Jeffrey.Evans at dartmouth.edu (Jeffrey Evans)
Date: Mon, 21 Jun 2010 16:39:04 -0400
Subject: [R-sig-ME] lme4 feature request: standardizing data and false
	convergence
Message-ID: <710D3D7F9086474B9062D51BCAE15D7F@Animal>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100621/7a07cdd2/attachment.pl>

From adik at ilovebacon.org  Mon Jun 21 23:24:55 2010
From: adik at ilovebacon.org (Adam D. I. Kramer)
Date: Mon, 21 Jun 2010 14:24:55 -0700 (PDT)
Subject: [R-sig-ME] lme4 feature request: standardizing data and false
 convergence
In-Reply-To: <710D3D7F9086474B9062D51BCAE15D7F@Animal>
References: <710D3D7F9086474B9062D51BCAE15D7F@Animal>
Message-ID: <alpine.DEB.2.00.1006211416170.8163@parser.ilovebacon.org>

Hi Jeffrey,

 	You can also avoid convergence errors in glmer by making sure your
expected coefficients are in the realm of 1e0 or 1e1. Standardizing works
because it mean-centers your data, so coefficients will probably be around
the mean...but you can fix things just as easily by dividing a variable with
a tiny coefficient by 100 or 1000.

 	...but...there's also a bit of an issue of HOW to standardized
in a multi-level model. For example, do you standardize a variable relative
to its grand mean?  Relative to the level-1 mean?  Or the highest level?  Or
relative to each mean in turn?  Etc.

 	Given that SAS has done this by default, as you suggest, which mean
do they standardize relative to?

--Adam


On Mon, 21 Jun 2010, Jeffrey Evans wrote:

> When using glmer in lme4 I frequently get false convergence errors. Many
> have posted to this list about this topic. The solution seems to be to
> standardize the X matrix first, which is effective at resolving the issue.
>
> Is there, (or could there be in future versions) a simple way to request
> that glmer optionally standardize the data internally and return
> back-transformed parameter estimates (on the original scale)?
>
> It seems that SAS does this by default in PROC GLIMMIX (version 9.2) and
> rarely had issues with regression conversion. It would be a huge help.
>
> Jeff Evans
> Dartmouth College
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From hipotesis_delta at hotmail.com  Mon Jun 21 06:36:44 2010
From: hipotesis_delta at hotmail.com (Ricardo Alvarado)
Date: Sun, 20 Jun 2010 22:36:44 -0600
Subject: [R-sig-ME] longitudinal model with blocks
Message-ID: <COL103-W260A7335CCAA7E3FCCEB98EC30@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100620/6884f667/attachment.pl>

From ailene at U.WASHINGTON.EDU  Mon Jun 21 23:18:59 2010
From: ailene at U.WASHINGTON.EDU (Ailene Kane)
Date: Mon, 21 Jun 2010 14:18:59 -0700
Subject: [R-sig-ME] correlated random effects in lmer and false convergence
Message-ID: <D2B731CF-9ECD-4500-920F-9AE5517C4BD4@u.washington.edu>

Dear Dr. Bates and/or other expert lmer users:

We are having problems fitting a linear mixed effects model using the lmer() function in the lme4 package, and are hoping that you will be able (and willing!) to answer some of our questions.  We have read several chapters in your book on lmer, and other online resources which have helped resolve many of our questions, but our data set is pretty complex and we wanted to make very sure that we are interpreting the output (and some error messages that we get) correctly. Thank you so much for your time!

As background, we are exploring the influence of climative factors (e.g. snow, temperature, etc) on annual tree growth (?rwi?= ring width index, a detrended index for tree growth that ranges from ~-1 to +2).  We are evaluating the fit of 29 different models, including various climate variables and combinations of climate variables as fixed effects (e.g. in the model below, GST=Growing season Temperature, and GPT=growing season precipitation).  Note: the climate variables have been standardized by substracting the mean and dividing by the standard deviation. There are 2 random effects: ?ind? (the individual tree; 20 trees were cored at each location and they differ in sensitivity to climate) and ?yr? (the year of tree growth - this is sort of like a block effect, because you could have years with similar temperature values). A subset of our dataset is attached as a .csv, and some sample code and output is listed below (and in the attached file).

We have the following questions:

1) We originally thought that test13 and test13b were the same thing:

test13<-lmer(rwi~GST*GPT+(0+GST*GPT|ind)+(1|yrs),control=list(maxIter=5000))
test13b<-lmer(rwi~GST*GPT+(0+GST|ind)+(0+GPT|ind)+(0+GST:GPT|ind)+(1|yrs),control=list(maxIter=5000))

However, we recently noticed that they result in differences in the correlations between random effects, and different AIC values (output is below and can be generated by the code below, if you are interested).  In test13, the random effects on ind for GST,GPT, and their interaction are perfectly correlated (1.00).  In test13b the random effects are NOT PERFECTLY correlated (r= 0.6349112). Does this mean that test13 ASSUMES correlated random effects (because of the way that it is coded)? We definitely don't want this and wanted to make sure that we understood correctly how to code the model appropriately. We are comparing the 29 potential models to a null model and using the delta AIC (in part) to evaluate the best-fit model.  The null model is coded as follows:

test0<-lmer(rwi~1+(0+1|ind)+(1|yrs),control=list(maxIter=5000)

2) We have been getting warning message for some models (for example, test13): ?Warning message: In mer_finalize(ans) : singular convergence (7).?  We have explored our data and get this error message only for complex models (e.g. 2 climate variables with an interaction), and mainly at locations where tree growth (of individual trees) is not correlated to any of our climate variables.  Do you think this interpretation makes sense, in which case we can conclude that the model fits poorly, indicating that other factors besides climate influence growth? Or, is there something else that you think we should do to avoid singular convergence? Again, the output generated by the code (test13b) is below and attached, in case you are interested.

Thank you so much for your help!

Best wishes,

Ailene


R OUTPUT FROM ATTACHED CODE:
> summary(test13)
Linear mixed model fit by REML 
Formula: rwi ~ GST * GPT + (0 + GST * GPT | ind) + (1 | yrs) 
    AIC  BIC logLik deviance REMLdev
 -528.4 -463  276.2     -577  -552.4
Random effects:
 Groups   Name        Variance   Std.Dev. Corr        
 yrs      (Intercept) 0.02764111 0.166256             
 ind      GST         0.00033501 0.018303             
          GPT         0.00029068 0.017049 1.000       
          GST:GPT     0.00023243 0.015246 1.000 1.000 
 Residual             0.03587474 0.189406             
Number of obs: 1727, groups: yrs, 94; ind, 20

Fixed effects:
             Estimate Std. Error t value
(Intercept)  0.999112   0.018777   53.21
GST          0.071152   0.019373    3.67
GPT          0.036372   0.019266    1.89
GST:GPT     -0.004302   0.019494   -0.22

Correlation of Fixed Effects:
        (Intr) GST    GPT   
GST      0.033              
GPT     -0.024  0.340       
GST:GPT  0.320  0.140 -0.032
> summary(test13b)
Linear mixed model fit by REML 
Formula: rwi ~ GST * GPT + (0 + GST | ind) + (0 + GPT | ind) + (0 + GST:GPT |      ind) + (1 | yrs) 
    AIC    BIC logLik deviance REMLdev
 -522.7 -473.6  270.4   -565.3  -540.7
Random effects:
 Groups   Name        Variance   Std.Dev. 
 yrs      (Intercept) 2.7626e-02 0.1662108
 ind      GST:GPT     8.7606e-05 0.0093598
 ind      GPT         3.2627e-05 0.0057120
 ind      GST         2.3199e-05 0.0048165
 Residual             3.6397e-02 0.1907813
Number of obs: 1727, groups: yrs, 94; ind, 20

Fixed effects:
             Estimate Std. Error t value
(Intercept)  0.999101   0.018778   53.21
GST          0.071329   0.018967    3.76
GPT          0.036529   0.018928    1.93
GST:GPT     -0.004107   0.019310   -0.21

Correlation of Fixed Effects:
        (Intr) GST    GPT   
GST      0.034              
GPT     -0.024  0.310       
GST:GPT  0.323  0.106 -0.069
Ailene Kane Ettinger
PhD Candidate
Biology Department
University of Washington
Box 351800
Seattle, Washington  98195-1800

ailene at u.washington.edu





From bates at stat.wisc.edu  Tue Jun 22 00:04:08 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 21 Jun 2010 17:04:08 -0500
Subject: [R-sig-ME] correlated random effects in lmer and false
	convergence
In-Reply-To: <D2B731CF-9ECD-4500-920F-9AE5517C4BD4@u.washington.edu>
References: <D2B731CF-9ECD-4500-920F-9AE5517C4BD4@u.washington.edu>
Message-ID: <AANLkTim2HZa-OzSQa4llI_Ar78nuqbUkmP_o3yDywZz_@mail.gmail.com>

A quick response as I must catch a bus soon.

On Mon, Jun 21, 2010 at 4:18 PM, Ailene Kane <ailene at u.washington.edu> wrote:
> Dear Dr. Bates and/or other expert lmer users:
>
> We are having problems fitting a linear mixed effects model using the lmer()
> function in the lme4 package, and are hoping that you will be able (and
> willing!) to answer some of our questions. ?We have read several chapters in
> your book on lmer, and other online resources which have helped resolve many
> of our questions, but our data set is pretty complex and we wanted to make
> very sure that we are interpreting the output (and some error messages that
> we get) correctly. Thank you so much for your time!
>
> As background, we are exploring the influence of climative factors (e.g.
> snow, temperature, etc) on annual tree growth (?rwi?= ring width index, a
> detrended index for tree growth that ranges from ~-1 to +2). ?We are
> evaluating the fit of 29 different models, including various climate
> variables and combinations of climate variables as fixed effects (e.g. in
> the model below, GST=Growing season Temperature, and GPT=growing season
> precipitation). ?Note: the climate variables have been standardized by
> substracting the mean and dividing by the standard deviation. There are 2
> random effects: ?ind? (the individual tree; 20 trees were cored at each
> location and they differ in sensitivity to climate) and ?yr? (the year of
> tree growth - this is sort of like a block effect, because you could have
> years with similar temperature values). A subset of our dataset is attached
> as a .csv, and some sample code and output is listed below (and in the
> attached file).
>
> We have the following questions:
>
> 1)?We originally thought that test13 and test13b were the same thing:
>
> test13<-lmer(rwi~GST*GPT+(0+GST*GPT|ind)+(1|yrs),control=list(maxIter=5000))
> test13b<-lmer(rwi~GST*GPT+(0+GST|ind)+(0+GPT|ind)+(0+GST:GPT|ind)+(1|yrs),control=list(maxIter=5000))

No, they are not the same as you have seen in your later
investigation.  The first model generates a vector-valued random
effect for each level of ind with possible correlation in the
variance-covariance matrix.  In the second model the components of the
random effects are independent.

It seems to me that there is very little variation associated with the
levels of ind.  I enclose a transcript of fitting a series of models
ending up with one that doesn't have any random effects for ind and it
seems to compare well to the others.

I must go to the bus.  I'll explain about the model-building strategy later.
> However, we recently noticed that they result in differences in the
> correlations between random effects, and different AIC values (output is
> below and can be generated by the code below, if you are interested). ?In
> test13, the random effects on ind for GST,GPT, and their interaction are
> perfectly correlated (1.00). ?In test13b the random effects are NOT
> PERFECTLY correlated (r= 0.6349112). Does this mean that test13 ASSUMES
> correlated random effects (because of the way that it is coded)? We
> definitely don't want this and wanted to make sure that we understood
> correctly how to code the model appropriately. We are comparing the 29
> potential models to a null model and using the delta AIC (in part) to
> evaluate the best-fit model. ?The null model is coded as follows:
>
> test0<-lmer(rwi~1+(0+1|ind)+(1|yrs),control=list(maxIter=5000)
>
> 2) We have been getting warning message for some models (for example,
> test13): ?Warning message: In mer_finalize(ans) : singular convergence (7).?
> ?We have explored our data and get this error message only for complex
> models?(e.g. 2 climate variables with an interaction), and mainly at
> locations where tree growth (of individual trees) is not correlated to any
> of our climate variables. ?Do you think this interpretation makes sense, in
> which case we can conclude that the model fits poorly, indicating that other
> factors besides climate influence growth? Or, is there something else that
> you think we should do to avoid singular convergence? Again, the output
> generated by the code (test13b) is below
>
> ?and attached, in case you are interested.
> Thank you so much for your help!
>
> Best wishes,
>
> Ailene
>
> R OUTPUT FROM ATTACHED CODE:
>> summary(test13)
> Linear mixed model fit by REML
> Formula: rwi ~ GST * GPT + (0 + GST * GPT | ind) + (1 | yrs)
> ?? ?AIC ?BIC logLik deviance REMLdev
> ?-528.4 -463 ?276.2 ? ? -577 ?-552.4
> Random effects:
> ?Groups ? Name ? ? ? ?Variance ? Std.Dev. Corr
> ?yrs ? ? ?(Intercept) 0.02764111 0.166256
> ?ind ? ? ?GST ? ? ? ? 0.00033501 0.018303
> ?? ? ? ? ?GPT ? ? ? ? 0.00029068 0.017049 1.000
> ?? ? ? ? ?GST:GPT ? ? 0.00023243 0.015246 1.000 1.000
> ?Residual ? ? ? ? ? ? 0.03587474 0.189406
> Number of obs: 1727, groups: yrs, 94; ind, 20
> Fixed effects:
> ?? ? ? ? ? ? Estimate Std. Error t value
> (Intercept) ?0.999112 ? 0.018777 ? 53.21
> GST ? ? ? ? ?0.071152 ? 0.019373 ? ?3.67
> GPT ? ? ? ? ?0.036372 ? 0.019266 ? ?1.89
> GST:GPT ? ? -0.004302 ? 0.019494 ? -0.22
> Correlation of Fixed Effects:
> ?? ? ? ?(Intr) GST ? ?GPT
> GST ? ? ?0.033
> GPT ? ? -0.024 ?0.340
> GST:GPT ?0.320 ?0.140 -0.032
>> summary(test13b)
> Linear mixed model fit by REML
> Formula: rwi ~ GST * GPT + (0 + GST | ind) + (0 + GPT | ind) + (0 + GST:GPT
> | ? ? ?ind) + (1 | yrs)
> ?? ?AIC ? ?BIC logLik deviance REMLdev
> ?-522.7 -473.6 ?270.4 ? -565.3 ?-540.7
> Random effects:
> ?Groups ? Name ? ? ? ?Variance ? Std.Dev.
> ?yrs ? ? ?(Intercept) 2.7626e-02 0.1662108
> ?ind ? ? ?GST:GPT ? ? 8.7606e-05 0.0093598
> ?ind ? ? ?GPT ? ? ? ? 3.2627e-05 0.0057120
> ?ind ? ? ?GST ? ? ? ? 2.3199e-05 0.0048165
> ?Residual ? ? ? ? ? ? 3.6397e-02 0.1907813
> Number of obs: 1727, groups: yrs, 94; ind, 20
> Fixed effects:
> ?? ? ? ? ? ? Estimate Std. Error t value
> (Intercept) ?0.999101 ? 0.018778 ? 53.21
> GST ? ? ? ? ?0.071329 ? 0.018967 ? ?3.76
> GPT ? ? ? ? ?0.036529 ? 0.018928 ? ?1.93
> GST:GPT ? ? -0.004107 ? 0.019310 ? -0.21
> Correlation of Fixed Effects:
> ?? ? ? ?(Intr) GST ? ?GPT
> GST ? ? ?0.034
> GPT ? ? -0.024 ?0.310
> GST:GPT ?0.323 ?0.106 -0.069
> Ailene Kane Ettinger
> PhD Candidate
> Biology Department
> University of Washington
> Box 351800
> Seattle, Washington??98195-1800
> ailene at u.washington.edu
>
>
>
>
-------------- next part --------------

R version 2.11.1 (2010-05-31)
Copyright (C) 2010 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> library(lme4a)
Loading required package: Matrix
Loading required package: lattice

Attaching package: 'Matrix'

The following object(s) are masked from 'package:base':

    det

Loading required package: minqa
Loading required package: Rcpp

Attaching package: 'lme4a'

The following object(s) are masked from 'package:stats':

    AIC

> hdat <- within(read.csv("~/tests/abamparadat.csv", header=TRUE),
+            {
+                ind <- factor(inds)
+                yrs <- factor(yrs)
+            })
> xyplot(rwi ~ SWE | inds, hdat, pch=16, type =c("p","r"),
+        main=paste("Abam-snow"), lwd=2, ylim=c(0.5,1.5))
> 
> (test13b <- lmer(rwi ~ GST*GPT+(1|inds)+(0+GST|inds)+(0+GPT|inds)+(0+GST:GPT|inds)+(1|yrs),
+                  hdat, REML=FALSE))
Linear mixed model fit by maximum likelihood ['merMod']
Formula: rwi ~ GST * GPT + (1 | inds) + (0 + GST | inds) + (0 + GPT |      inds) + (0 + GST:GPT | inds) + (1 | yrs) 
   Data: hdat 
      AIC       BIC    logLik  deviance 
-545.3849 -490.8435  282.6925 -565.3849 

Random effects:
 Groups   Name        Variance  Std.Dev.
 yrs      (Intercept) 2.637e-02 0.162397
 inds     GST:GPT     8.551e-05 0.009247
 inds     GPT         3.040e-05 0.005514
 inds     GST         2.080e-05 0.004560
 inds     (Intercept) 0.000e+00 0.000000
 Residual             3.640e-02 0.190796
Number of obs: 1727, groups: yrs, 94; inds, 20

Fixed effects:
             Estimate Std. Error t value
(Intercept)  0.999094   0.018377   54.37
GST          0.071329   0.018559    3.84
GPT          0.036532   0.018522    1.97
GST:GPT     -0.004108   0.018898   -0.22

Correlation of Fixed Effects:
        (Intr) GST    GPT   
GST      0.034              
GPT     -0.025  0.310       
GST:GPT  0.323  0.106 -0.069
> (test13c <- lmer(rwi ~ GST*GPT+(0+GST|inds)+(0+GPT|inds)+(0+GST:GPT|inds)+(1|yrs),
+                  hdat, REML=FALSE))
Linear mixed model fit by maximum likelihood ['merMod']
Formula: rwi ~ GST * GPT + (0 + GST | inds) + (0 + GPT | inds) + (0 +      GST:GPT | inds) + (1 | yrs) 
   Data: hdat 
      AIC       BIC    logLik  deviance 
-547.3849 -498.2977  282.6925 -565.3849 

Random effects:
 Groups   Name        Variance  Std.Dev.
 yrs      (Intercept) 2.637e-02 0.162397
 inds     GST:GPT     8.551e-05 0.009247
 inds     GPT         3.040e-05 0.005514
 inds     GST         2.080e-05 0.004560
 Residual             3.640e-02 0.190796
Number of obs: 1727, groups: yrs, 94; inds, 20

Fixed effects:
             Estimate Std. Error t value
(Intercept)  0.999094   0.018377   54.37
GST          0.071329   0.018559    3.84
GPT          0.036532   0.018522    1.97
GST:GPT     -0.004108   0.018898   -0.22

Correlation of Fixed Effects:
        (Intr) GST    GPT   
GST      0.034              
GPT     -0.025  0.310       
GST:GPT  0.323  0.106 -0.069
> (test13d <- lmer(rwi ~ GST*GPT+(0+GST|inds)+(0+GPT|inds)+(1|yrs),
+                  hdat, REML=FALSE))
Linear mixed model fit by maximum likelihood ['merMod']
Formula: rwi ~ GST * GPT + (0 + GST | inds) + (0 + GPT | inds) + (1 |      yrs) 
   Data: hdat 
      AIC       BIC    logLik  deviance 
-549.0160 -505.3829  282.5080 -565.0160 

Random effects:
 Groups   Name        Variance  Std.Dev.
 yrs      (Intercept) 2.637e-02 0.162376
 inds     GPT         3.646e-05 0.006038
 inds     GST         1.146e-05 0.003385
 Residual             3.649e-02 0.191035
Number of obs: 1727, groups: yrs, 94; inds, 20

Fixed effects:
             Estimate Std. Error t value
(Intercept)  0.999095   0.018377   54.37
GST          0.071351   0.018545    3.85
GPT          0.036539   0.018530    1.97
GST:GPT     -0.004121   0.018782   -0.22

Correlation of Fixed Effects:
        (Intr) GST    GPT   
GST      0.034              
GPT     -0.025  0.310       
GST:GPT  0.325  0.107 -0.069
> (test13e <- lmer(rwi ~ GST + GPT+(0+GST|inds)+(0+GPT|inds)+(1|yrs),
+                  hdat, REML=FALSE))
Linear mixed model fit by maximum likelihood ['merMod']
Formula: rwi ~ GST + GPT + (0 + GST | inds) + (0 + GPT | inds) + (1 |      yrs) 
   Data: hdat 
      AIC       BIC    logLik  deviance 
-550.9679 -512.7889  282.4840 -564.9679 

Random effects:
 Groups   Name        Variance  Std.Dev.
 yrs      (Intercept) 2.638e-02 0.162421
 inds     GPT         3.656e-05 0.006046
 inds     GST         1.150e-05 0.003391
 Residual             3.649e-02 0.191035
Number of obs: 1727, groups: yrs, 94; inds, 20

Fixed effects:
            Estimate Std. Error t value
(Intercept)  1.00041    0.01738   57.56
GST          0.07179    0.01844    3.89
GPT          0.03626    0.01849    1.96

Correlation of Fixed Effects:
    (Intr) GST   
GST -0.001       
GPT -0.002  0.320
> (test13f <- lmer(rwi ~ GST + GPT +(1|yrs), hdat, REML=FALSE))
Linear mixed model fit by maximum likelihood ['merMod']
Formula: rwi ~ GST + GPT + (1 | yrs) 
   Data: hdat 
      AIC       BIC    logLik  deviance 
-554.8997 -527.6289  282.4498 -564.8997 

Random effects:
 Groups   Name        Variance Std.Dev.
 yrs      (Intercept) 0.02637  0.1624  
 Residual             0.03654  0.1912  
Number of obs: 1727, groups: yrs, 94

Fixed effects:
            Estimate Std. Error t value
(Intercept)  1.00040    0.01738   57.56
GST          0.07180    0.01843    3.90
GPT          0.03631    0.01844    1.97

Correlation of Fixed Effects:
    (Intr) GST   
GST -0.001       
GPT -0.002  0.321
> 
> anova(test13f, test13e, test13d, test13c, test13b)
Data: hdat
Models:
test13f: rwi ~ GST + GPT + (1 | yrs)
test13e: rwi ~ GST + GPT + (0 + GST | inds) + (0 + GPT | inds) + (1 | 
test13e:     yrs)
test13d: rwi ~ GST * GPT + (0 + GST | inds) + (0 + GPT | inds) + (1 | 
test13d:     yrs)
test13c: rwi ~ GST * GPT + (0 + GST | inds) + (0 + GPT | inds) + (0 + 
test13c:     GST:GPT | inds) + (1 | yrs)
test13b: rwi ~ GST * GPT + (1 | inds) + (0 + GST | inds) + (0 + GPT | 
test13b:     inds) + (0 + GST:GPT | inds) + (1 | yrs)
        Df     AIC     BIC logLik  Chisq Chi Df Pr(>Chisq)
test13f  5 -554.90 -527.63 282.45                         
test13e  7 -550.97 -512.79 282.48 0.0683      2     0.9664
test13d  8 -549.02 -505.38 282.51 0.0481      1     0.8263
test13c  9 -547.38 -498.30 282.69 0.3689      1     0.5436
test13b 10 -545.38 -490.84 282.69 0.0000      1     1.0000
> qqmath(ranef(test13f, postVar = TRUE))
$yrs

> 
> proc.time()
   user  system elapsed 
 10.980   0.210  11.414 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplots.pdf
Type: application/pdf
Size: 142396 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100621/3a106705/attachment.pdf>

From danielezrajohnson at gmail.com  Tue Jun 22 00:21:58 2010
From: danielezrajohnson at gmail.com (Daniel Ezra Johnson)
Date: Mon, 21 Jun 2010 18:21:58 -0400
Subject: [R-sig-ME] Mac OS X binary for lme4
In-Reply-To: <D2B731CF-9ECD-4500-920F-9AE5517C4BD4@u.washington.edu>
References: <D2B731CF-9ECD-4500-920F-9AE5517C4BD4@u.washington.edu>
Message-ID: <1C4A6C44-9DAC-49DA-B479-3E2D50E6E95F@gmail.com>

For some weeks the Mac OS X binary of the lme4 package has not been  
available, as it has failed some check. Could anyone comment on how  
long this situation is likely to last?

Thanks,
Daniel



From bates at stat.wisc.edu  Tue Jun 22 03:28:26 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 21 Jun 2010 20:28:26 -0500
Subject: [R-sig-ME] Mac OS X binary for lme4
In-Reply-To: <1C4A6C44-9DAC-49DA-B479-3E2D50E6E95F@gmail.com>
References: <D2B731CF-9ECD-4500-920F-9AE5517C4BD4@u.washington.edu>
	<1C4A6C44-9DAC-49DA-B479-3E2D50E6E95F@gmail.com>
Message-ID: <AANLkTikd5HirxgUz-Rovz8axp-Sdr-H3OC2CMI8PQwPp@mail.gmail.com>

On Mon, Jun 21, 2010 at 5:21 PM, Daniel Ezra Johnson
<danielezrajohnson at gmail.com> wrote:
> For some weeks the Mac OS X binary of the lme4 package has not been
> available, as it has failed some check. Could anyone comment on how long
> this situation is likely to last?

Neither Martin nor I have access to a Max OS X system with the
development tools installed that we could use to debug the problem.
We can't duplicate the failure of the test on other, similar systems
like Linux.

My advice to Mac OS X users has been to install the source package.



From bates at stat.wisc.edu  Tue Jun 22 04:42:45 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 21 Jun 2010 21:42:45 -0500
Subject: [R-sig-ME] correlated random effects in lmer and false
	convergence
In-Reply-To: <AANLkTim2HZa-OzSQa4llI_Ar78nuqbUkmP_o3yDywZz_@mail.gmail.com>
References: <D2B731CF-9ECD-4500-920F-9AE5517C4BD4@u.washington.edu>
	<AANLkTim2HZa-OzSQa4llI_Ar78nuqbUkmP_o3yDywZz_@mail.gmail.com>
Message-ID: <AANLkTinT76hDhPJOtKWQBkXgdovkjrIEGf5rD5YNR6Ks@mail.gmail.com>

On Mon, Jun 21, 2010 at 5:04 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
> A quick response as I must catch a bus soon.
>
> On Mon, Jun 21, 2010 at 4:18 PM, Ailene Kane <ailene at u.washington.edu> wrote:
>> Dear Dr. Bates and/or other expert lmer users:
>>
>> We are having problems fitting a linear mixed effects model using the lmer()
>> function in the lme4 package, and are hoping that you will be able (and
>> willing!) to answer some of our questions. ?We have read several chapters in
>> your book on lmer, and other online resources which have helped resolve many
>> of our questions, but our data set is pretty complex and we wanted to make
>> very sure that we are interpreting the output (and some error messages that
>> we get) correctly. Thank you so much for your time!
>>
>> As background, we are exploring the influence of climative factors (e.g.
>> snow, temperature, etc) on annual tree growth (?rwi?= ring width index, a
>> detrended index for tree growth that ranges from ~-1 to +2). ?We are
>> evaluating the fit of 29 different models, including various climate
>> variables and combinations of climate variables as fixed effects (e.g. in
>> the model below, GST=Growing season Temperature, and GPT=growing season
>> precipitation). ?Note: the climate variables have been standardized by
>> substracting the mean and dividing by the standard deviation. There are 2
>> random effects: ?ind? (the individual tree; 20 trees were cored at each
>> location and they differ in sensitivity to climate) and ?yr? (the year of
>> tree growth - this is sort of like a block effect, because you could have
>> years with similar temperature values). A subset of our dataset is attached
>> as a .csv, and some sample code and output is listed below (and in the
>> attached file).
>>
>> We have the following questions:
>>
>> 1)?We originally thought that test13 and test13b were the same thing:
>>
>> test13<-lmer(rwi~GST*GPT+(0+GST*GPT|ind)+(1|yrs),control=list(maxIter=5000))
>> test13b<-lmer(rwi~GST*GPT+(0+GST|ind)+(0+GPT|ind)+(0+GST:GPT|ind)+(1|yrs),control=list(maxIter=5000))
>
> No, they are not the same as you have seen in your later
> investigation. ?The first model generates a vector-valued random
> effect for each level of ind with possible correlation in the
> variance-covariance matrix. ?In the second model the components of the
> random effects are independent.
>
> It seems to me that there is very little variation associated with the
> levels of ind. ?I enclose a transcript of fitting a series of models
> ending up with one that doesn't have any random effects for ind and it
> seems to compare well to the others.
>
> I must go to the bus. ?I'll explain about the model-building strategy later.
>> However, we recently noticed that they result in differences in the
>> correlations between random effects, and different AIC values (output is
>> below and can be generated by the code below, if you are interested). ?In
>> test13, the random effects on ind for GST,GPT, and their interaction are
>> perfectly correlated (1.00). ?In test13b the random effects are NOT
>> PERFECTLY correlated (r= 0.6349112). Does this mean that test13 ASSUMES
>> correlated random effects (because of the way that it is coded)? We
>> definitely don't want this and wanted to make sure that we understood
>> correctly how to code the model appropriately. We are comparing the 29
>> potential models to a null model and using the delta AIC (in part) to
>> evaluate the best-fit model. ?The null model is coded as follows:

When describing the distribution of the random effects you must be
careful to distinguish the unconditional distribution and the
conditional distribution, given the data and the values of the model
parameters.  The model is described in terms of the unconditional
distribution whereas the values provided by the ranef extractor are
from the conditional distribution.

The unconditional distribution is a multivariate Gaussian (or
"normal") distribution with mean zero and a parameterized
variance-covariance matrix.  That matrix is generated from the
random-effects terms in the model formula.  Each such term is of the
form (expr|grp) where expr is a linear model expression and grp is the
"grouping factor".  This is usually the name of a factor like ind or
yr but could also be an expression, as long as it evaluates to a
factor.

The variance-covariance matrix of the unconditional distribution is
block diagonal with one block for each term.  Thus the random effects
for different terms are independent in this distribution, even when
their grouping factors are the same.  When there is more than one
random effect per level of the factor, as in the term (0 + GST * GPT |
ind), which generates 3 random effects for each individual, these
random effects can be correlated in the unconditional distribution.
Thus that term requires 6 variance-covariance parameters (3 variances
and 3 covariances) to be estimated while the other expression, (0 +
GST|ind) + (0+GPT|ind) + (0 + GST:GPT|ind) requires on 3 variance
parameters to be estimated.

The maximum likelihood or REML estimates seek a balance between
complexity of the model and fidelity to the data.  The way that the
complexity of the model is measured a model with a singular
variance-covariance matrix is considered ideal.  If the random effects
don't have much explanatory power, as in this model, the variance
parameters will be driven to zero or the correlations to +1 or -1.
Here the random effects with respect to ind don't contribute that much
to the model fit and you are better off without them,

There is always a question of how to go about building a statistical
model for your data.  Sometimes we take a forward selection approach,
starting with a simple model and adding terms as indicated and testing
whether they have sufficient explanatory power to warrant retaining
them.  Sometimes we start with a complex model and eliminate terms
that seem redundant.  I have noticed a tendency for those trained in
areas like ecology, forestry and agriculture to start with the complex
model and eliminate terms that are not contributing.  This works fine
in some situations like well-balanced agricultural field trials.  You
can fit very complex models to balanced designs because the
contributions of various terms lie in orthogonal subspaces of the
response space, resulting in independent estimators for their
coefficients.   Observational data from fields like ecology is often
highly imbalanced making it difficult to fit the complex model.  In
those cases it is probably better to start simple and build up the
model rather than trying to fit all possible terms and see which ones
make the cut.  Of course, you may not be able to convince the referees
on your paper that this approach makes sense.

>> test0<-lmer(rwi~1+(0+1|ind)+(1|yrs),control=list(maxIter=5000)
>>
>> 2) We have been getting warning message for some models (for example,
>> test13): ?Warning message: In mer_finalize(ans) : singular convergence (7).?
>> ?We have explored our data and get this error message only for complex
>> models?(e.g. 2 climate variables with an interaction), and mainly at
>> locations where tree growth (of individual trees) is not correlated to any
>> of our climate variables. ?Do you think this interpretation makes sense, in
>> which case we can conclude that the model fits poorly, indicating that other
>> factors besides climate influence growth? Or, is there something else that
>> you think we should do to avoid singular convergence? Again, the output
>> generated by the code (test13b) is below

That message about singular convergence comes from the nlminb
optimizer that is used in the released versions of lme4.  In the
development version, called lme4a and available only through R-forge
in source form, I have switched to another optimizer called bobyqa in
lme4a because it seems to provide better results and is generally
faster than nlminb.  As you indicate, the convergence problems are
characteristic of complex models and often indicate a model that is
more complex than is warranted by the data.


>> ?and attached, in case you are interested.
>> Thank you so much for your help!
>>
>> Best wishes,
>>
>> Ailene
>>
>> R OUTPUT FROM ATTACHED CODE:
>>> summary(test13)
>> Linear mixed model fit by REML
>> Formula: rwi ~ GST * GPT + (0 + GST * GPT | ind) + (1 | yrs)
>> ?? ?AIC ?BIC logLik deviance REMLdev
>> ?-528.4 -463 ?276.2 ? ? -577 ?-552.4
>> Random effects:
>> ?Groups ? Name ? ? ? ?Variance ? Std.Dev. Corr
>> ?yrs ? ? ?(Intercept) 0.02764111 0.166256
>> ?ind ? ? ?GST ? ? ? ? 0.00033501 0.018303
>> ?? ? ? ? ?GPT ? ? ? ? 0.00029068 0.017049 1.000
>> ?? ? ? ? ?GST:GPT ? ? 0.00023243 0.015246 1.000 1.000
>> ?Residual ? ? ? ? ? ? 0.03587474 0.189406
>> Number of obs: 1727, groups: yrs, 94; ind, 20
>> Fixed effects:
>> ?? ? ? ? ? ? Estimate Std. Error t value
>> (Intercept) ?0.999112 ? 0.018777 ? 53.21
>> GST ? ? ? ? ?0.071152 ? 0.019373 ? ?3.67
>> GPT ? ? ? ? ?0.036372 ? 0.019266 ? ?1.89
>> GST:GPT ? ? -0.004302 ? 0.019494 ? -0.22
>> Correlation of Fixed Effects:
>> ?? ? ? ?(Intr) GST ? ?GPT
>> GST ? ? ?0.033
>> GPT ? ? -0.024 ?0.340
>> GST:GPT ?0.320 ?0.140 -0.032
>>> summary(test13b)
>> Linear mixed model fit by REML
>> Formula: rwi ~ GST * GPT + (0 + GST | ind) + (0 + GPT | ind) + (0 + GST:GPT
>> | ? ? ?ind) + (1 | yrs)
>> ?? ?AIC ? ?BIC logLik deviance REMLdev
>> ?-522.7 -473.6 ?270.4 ? -565.3 ?-540.7
>> Random effects:
>> ?Groups ? Name ? ? ? ?Variance ? Std.Dev.
>> ?yrs ? ? ?(Intercept) 2.7626e-02 0.1662108
>> ?ind ? ? ?GST:GPT ? ? 8.7606e-05 0.0093598
>> ?ind ? ? ?GPT ? ? ? ? 3.2627e-05 0.0057120
>> ?ind ? ? ?GST ? ? ? ? 2.3199e-05 0.0048165
>> ?Residual ? ? ? ? ? ? 3.6397e-02 0.1907813
>> Number of obs: 1727, groups: yrs, 94; ind, 20
>> Fixed effects:
>> ?? ? ? ? ? ? Estimate Std. Error t value
>> (Intercept) ?0.999101 ? 0.018778 ? 53.21
>> GST ? ? ? ? ?0.071329 ? 0.018967 ? ?3.76
>> GPT ? ? ? ? ?0.036529 ? 0.018928 ? ?1.93
>> GST:GPT ? ? -0.004107 ? 0.019310 ? -0.21
>> Correlation of Fixed Effects:
>> ?? ? ? ?(Intr) GST ? ?GPT
>> GST ? ? ?0.034
>> GPT ? ? -0.024 ?0.310
>> GST:GPT ?0.323 ?0.106 -0.069
>> Ailene Kane Ettinger
>> PhD Candidate
>> Biology Department
>> University of Washington
>> Box 351800
>> Seattle, Washington??98195-1800
>> ailene at u.washington.edu
>>
>>
>>
>>
>



From laomeng.3 at gmail.com  Tue Jun 22 06:51:54 2010
From: laomeng.3 at gmail.com (Lao Meng)
Date: Tue, 22 Jun 2010 12:51:54 +0800
Subject: [R-sig-ME] hi
Message-ID: <AANLkTil40d7gPt-oVyCLUWVvcqv_a9Sue40lz3XmTK7R@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100622/00a5ad82/attachment.pl>

From roberto.patuelli at usi.ch  Tue Jun 22 10:42:49 2010
From: roberto.patuelli at usi.ch (Roberto Patuelli)
Date: Tue, 22 Jun 2010 10:42:49 +0200
Subject: [R-sig-ME] Standard errors or t values from glmm.admb
References: <mailman.3.1274349602.23867.r-sig-mixed-models@r-project.org>
Message-ID: <E1EAD31D792D446BA52639D52BE2CA71@Ciretto>

Dear All,

I have experimented with estimating a negative binomial mixed model through 
the glmmADMB package (that is, using the glmm.admb function).
After an entire night of computing :) I have results (though with a warning 
message saying that proper convergence could not be reached). But when I use 
summary.glmm.admb, I can only see, with regard to the fixed effects, the 
betas estimates, but no standard errors or other measures regarding the 
precision of the regression coefficients. See below:

***********************************************************
Fixed effects:
  Log-likelihood: -12729.3
  Formula: trade ~ factor(YEAR) + factor(contig) + factor(comlang_off) + 
factor(colony) + factor(comcol) + factor(col45) + factor(smctry) + 
log(dist) + log(I(iPopulation * iGDPpcPPP)) + log(I(jPopulation * 
jGDPpcPPP)) + factor(FTA) + log(iPiracy) + log(jPiracy) +      e8 + e14 + 
e15 + e45 + e53 + e57
                    (Intercept)                factor(YEAR)1997 
factor(YEAR)1998                factor(YEAR)1999 
factor(YEAR)2000
                     -5.5350000                       0.0139690 
0.0368520                       0.1594000                       0.2116200
               factor(YEAR)2001                factor(YEAR)2002 
factor(YEAR)2003                factor(YEAR)2004 
factor(YEAR)2005
                      0.2161600                       0.3880400 
0.4666700                       0.5722600                       0.5980400
               factor(YEAR)2006                 factor(contig)1 
factor(comlang_off)1                 factor(colony)1 
factor(comcol)1
                      0.5235100                       0.4576100 
0.6817900                       0.1317700                      -0.0158100
                 factor(col45)1                 factor(smctry)1 
log(dist) log(I(iPopulation * iGDPpcPPP)) log(I(jPopulation * jGDPpcPPP))
                     -0.5674800                      -1.2061000              
         -0.4347800                       0.3970300 
0.3670800
                   factor(FTA)1                    log(iPiracy) 
log(jPiracy)                              e8                             e14
                      0.3087500                      -0.1044300              
         -0.1283700                      -0.1780900                      -0.3323800
                            e15                             e45 
e53                             e57
                     -0.0052419                      -0.2903100              
         -0.1977900                      -0.0892520
***********************************************************

Is anyone more expert than me with this package and can help me getting the 
additional information? Or is it just not given? The help files for the 
package don't seem to help...

Thanks
Roberto Patuelli

********************
Roberto Patuelli, Ph.D.
Istituto Ricerche Economiche (IRE) (Institute for Economic Research)
Universit? della Svizzera Italiana (University of Lugano)
via Maderno 24, CP 4361
CH-6904 Lugano
Switzerland
Phone: +41-(0)58-666-4166
Fax: +39-02-700419665
Email: roberto.patuelli at usi.ch
Homepage: http://www.people.lu.unisi.ch/patuellr



From chris.kleier at gmail.com  Tue Jun 22 16:57:43 2010
From: chris.kleier at gmail.com (Chris Kleier)
Date: Tue, 22 Jun 2010 16:57:43 +0200
Subject: [R-sig-ME] lme posthoc constrasts for interaction effects
	group*time
In-Reply-To: <1276878437.5914.1380778075@webmail.messagingengine.com>
References: <mailman.7.1276855203.25637.r-sig-mixed-models@r-project.org>
	<1276878437.5914.1380778075@webmail.messagingengine.com>
Message-ID: <AANLkTin1e2AbFBSokMeO_BuTFX5iGg0qA8UczwVRIOPs@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100622/982a0d2c/attachment.pl>

From cm744 at st-andrews.ac.uk  Tue Jun 22 17:14:43 2010
From: cm744 at st-andrews.ac.uk (Chris Mcowen)
Date: Tue, 22 Jun 2010 16:14:43 +0100
Subject: [R-sig-ME] In mer_finalize(ans) : gr cannot be computed at initial
	par (65)
Message-ID: <E5BC2538-9356-4593-BA51-66A54B1975E3@st-andrews.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100622/205351dc/attachment.pl>

From nikko at hailmail.net  Tue Jun 22 17:18:53 2010
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Tue, 22 Jun 2010 08:18:53 -0700
Subject: [R-sig-ME] lme posthoc constrasts for interaction effects
 group*time
In-Reply-To: <AANLkTin1e2AbFBSokMeO_BuTFX5iGg0qA8UczwVRIOPs@mail.gmail.com>
References: <mailman.7.1276855203.25637.r-sig-mixed-models@r-project.org><1276878437.5914.1380778075@webmail.messagingengine.com>
	<AANLkTin1e2AbFBSokMeO_BuTFX5iGg0qA8UczwVRIOPs@mail.gmail.com>
Message-ID: <1277219933.10568.1381346789@webmail.messagingengine.com>


Hi Chris,
If you look at the code I sent, the second part uses the contrast
package to get
the contrast matrix for testing within the interaction. mcp does not
handle interactions (I think) but you can specifiy them more easily 
using the contrast package and then peel off the contrast matrix for use
in multcomp.


Nicholas 
On Tue, 22 Jun 2010 16:57 +0200, "Chris Kleier"
<chris.kleier at gmail.com> wrote:

  Hi Nicholas,
  Thanks for your help.
  I have been looking at the contrast library, however, we are
  interested in differences between interactions only and not
  between group and interactions together.
  In fact I would like:
  test <- glht( model, lin = mcp( "group:time"  = 'Tukey' ) )
  This quesion is in fact similar to the question posted before:
  [1]http://www.mail-archive.com/r-help at r-project.org/msg65720.h
  tml
  The mcp function is probably not able to manage interactions.
  Chris

On Fri, Jun 18, 2010 at 6:27 PM, Nicholas Lewin-Koh
<[2]nikko at hailmail.net> wrote:

  Hi,
  Try
  library(multcomp)
  test<-glht(model,lin=mcp(group="Tukey"))
  confint(test)
  However, that just tests the marginal effect of group.
  With interactions you want to test over time, probably a
  simultaneous
  interval.
  This will get you close:
  library(contrast)
  ctt<-contrast(model, a=list( day=c(0,3,7,21,49), group=c(Small
  Stroke",
  "Large Stroke")),
               b=list(day=c(0,3,7,21,49), group=c("Control",
  "Control")))
  ## Extract the contrast matrix
  cmtrx <- ctt$X
  ## Fit the contrasts using glht
  ttgl<-glht(model,lin=cmtrx)
  confint(ttgl)
  hope this helps.
  And do read the vignette in multcomp  :)
  Nicholas
  > Message: 2
  > Date: Thu, 17 Jun 2010 14:51:21 +0200
  > From: Chris Kleier <[3]chris.kleier at gmail.com>
  > To: R sig-mixed-models <[4]r-sig-mixed-models at r-project.org>
  > Subject: [R-sig-ME] lme posthoc constrasts for interaction
  effects
  >       group*time
  > Message-ID:
  >
  <[5]AANLkTilMkK9HJZqXDZimDzKCswXElxw__dUVQpSnW8FQ at mail.gmail.c
  om>
  > Content-Type: text/plain
  >
  > Hi all,
  >
  > Our dataset is a repeated measures design including 3 groups
  (a)
  > Controls,
  > (b) Small stroke and (c) Large stroke. We want to know if
  the group
  > behave
  > different over time.
  >
  > We first fitted a lme with fixed = group * time (see below).
  > Their was a significant interaction effect (see below as
  well; p < 0.05)
  >
  > In the next step we want to know which groups have
  significant
  > interactions
  > (Control - Stroke large, Control - Stroke small, Stroke
  small - Stroke
  > large), and their p-values + CIs.
  >
  > A posthoc Tukey, I think is fine. However, I do not know how
  to setup the
  > constrast matrix.
  >
  > These are the contrast names ( names( coef( model ) ) ):
  > "(Intercept)", "groupStroke large", "groupStroke small",
  "time",
  > "groupStroke large:time" "groupStroke small:time"
  >
  > I guess, the model has to be refitted to get a contrast for
  > "groupControl:time" as well, but I do not know how.
  >
  > Any solution known? (Probabily something in the direction
  of: model.2 <-
  > update( model, fixed = 0 + group * time ) )
  >
  > Thanks!
  >
  > Chris
  >
  >
  >
  >
  >
  > This is a print of the dataset:
  >
  >     subject        group       value day
  > 1       N03 Stroke small  0.47545500   0
  > 2       N04 Stroke small  0.38866500   0
  > 3       N19 Stroke small  0.64749800   0
  > 4       N20 Stroke small  0.50468600   0
  > 5       N22 Stroke small  0.55872300   0
  > 6       N03 Stroke small  0.01979970   3
  > 7       N04 Stroke small  0.05607250   3
  > 8       N19 Stroke small -0.04506370   3
  > 9       N20 Stroke small -0.33935400   3
  > 10      N22 Stroke small  0.22052700   3
  > 11      N03 Stroke small  0.29805300   7
  > 12      N04 Stroke small -0.24908100   7
  > 13      N19 Stroke small -0.02657290   7
  > 14      N20 Stroke small -0.19483200   7
  > 15      N22 Stroke small  0.50948000   7
  > 16      N03 Stroke small  0.13056600  21
  > 17      N04 Stroke small  0.33759500  21
  > 18      N19 Stroke small  0.14929200  21
  > 19      N20 Stroke small  0.25033100  21
  > 20      N22 Stroke small  0.71456800  21
  > 21      N03 Stroke small  0.39007100  49
  > 22      N04 Stroke small  0.33254400  49
  > 23      N19 Stroke small  0.27767600  49
  > 24      N20 Stroke small  0.33467500  49
  > 25      N22 Stroke small  0.52203500  49
  > 26      N03 Stroke small  0.29851100  70
  > 27      N04 Stroke small  0.50900200  70
  > 28      N19 Stroke small  0.51781700  70
  > 29      N20 Stroke small  0.69543700  70
  > 30      N22 Stroke small  0.49337000  70
  > 31      N01 Stroke large          NA   0
  > 32      N07 Stroke large  0.54930600   0
  > 33      N09 Stroke large  0.59703600   0
  > 34      N10 Stroke large  0.72751400   0
  > 35      N17 Stroke large  0.63878400   0
  > 36      N23 Stroke large  0.65749100   0
  > 37      N24 Stroke large  0.60945900   0
  > 38      N28 Stroke large          NA   0
  > 39      N01 Stroke large -0.31610900   3
  > 40      N07 Stroke large -0.33615700   3
  > 41      N09 Stroke large -0.24906400   3
  > 42      N10 Stroke large  0.33868700   3
  > 43      N17 Stroke large -0.31357300   3
  > 44      N23 Stroke large -0.13162800   3
  > 45      N24 Stroke large -0.45343700   3
  > 46      N28 Stroke large -0.18206700   3
  > 47      N01 Stroke large -0.05309070   7
  > 48      N07 Stroke large -0.83318300   7
  > 49      N09 Stroke large -0.49667100   7
  > 50      N10 Stroke large -0.48083200   7
  > 51      N17 Stroke large -0.28447000   7
  > 52      N23 Stroke large  0.01842660   7
  > 53      N24 Stroke large -0.50464400   7
  > 54      N28 Stroke large  0.16456100   7
  > 55      N01 Stroke large  0.24652600  21
  > 56      N07 Stroke large -0.31566500  21
  > 57      N09 Stroke large  0.39618900  21
  > 58      N10 Stroke large -0.30702200  21
  > 59      N17 Stroke large -0.28860100  21
  > 60      N23 Stroke large -0.23851000  21
  > 61      N24 Stroke large -0.00913697  21
  > 62      N28 Stroke large  0.43462600  21
  > 63      N01 Stroke large -0.20660100  49
  > 64      N07 Stroke large -0.13044900  49
  > 65      N09 Stroke large  0.24625000  49
  > 66      N10 Stroke large -0.28206200  49
  > 67      N17 Stroke large  0.29186400  49
  > 68      N23 Stroke large -0.14246600  49
  > 69      N24 Stroke large -0.11297700  49
  > 70      N28 Stroke large  0.32027300  49
  > 71      N01 Stroke large -0.00106427  70
  > 72      N07 Stroke large -0.17264000  70
  > 73      N09 Stroke large  0.26417500  70
  > 74      N10 Stroke large -0.11202200  70
  > 75      N17 Stroke large  0.16687700  70
  > 76      N23 Stroke large -0.24308300  70
  > 77      N24 Stroke large  0.00322026  70
  > 78      N28 Stroke large  0.34928100  70
  > 79      C01      Control          NA   0
  > 80      C02      Control          NA   0
  > 81      C03      Control          NA   0
  > 82      C04      Control          NA   0
  > 83      C05      Control          NA   0
  > 84      C06      Control          NA   0
  > 85      C07      Control          NA   0
  > 86      C09      Control          NA   0
  > 87      C10      Control          NA   0
  > 88      C32      Control          NA   0
  > 89      C01      Control  0.32387500   3
  > 90      C02      Control  0.48334200   3
  > 91      C03      Control  0.70698800   3
  > 92      C04      Control  0.00572262   3
  > 93      C05      Control  0.40416000   3
  > 94      C06      Control  0.36343800   3
  > 95      C07      Control  0.05064140   3
  > 96      C09      Control  0.84621500   3
  > 97      C10      Control  0.80675300   3
  > 98      C32      Control          NA   3
  > 99      C01      Control  0.23174400   7
  > 100     C02      Control  0.36959100   7
  > 101     C03      Control  0.43762800   7
  > 102     C04      Control  0.34187100   7
  > 103     C05      Control  0.74288400   7
  > 104     C06      Control  0.17692600   7
  > 105     C07      Control  0.60067600   7
  > 106     C09      Control  0.80314900   7
  > 107     C10      Control  0.81695500   7
  > 108     C32      Control  0.19029400   7
  > 109     C01      Control  0.45062600  21
  > 110     C02      Control  0.62884500  21
  > 111     C03      Control  0.33693200  21
  > 112     C04      Control  0.76098800  21
  > 113     C05      Control  0.59837500  21
  > 114     C06      Control  0.39328800  21
  > 115     C07      Control  0.55099400  21
  > 116     C09      Control  0.75411500  21
  > 117     C10      Control  0.72495100  21
  > 118     C32      Control  0.66503400  21
  > 119     C01      Control  0.63903900  49
  > 120     C02      Control          NA  49
  > 121     C03      Control  0.59655200  49
  > 122     C04      Control  0.42958700  49
  > 123     C05      Control  0.68408700  49
  > 124     C06      Control  0.45482700  49
  > 125     C07      Control  0.37217700  49
  > 126     C09      Control  0.75770400  49
  > 127     C10      Control  0.62059200  49
  > 128     C32      Control  0.68320900  49
  > 129     C01      Control  0.66179300  70
  > 130     C02      Control  0.34183000  70
  > 131     C03      Control  0.58543900  70
  > 132     C04      Control  0.62621700  70
  > 133     C05      Control  0.40610400  70
  > 134     C06      Control  0.32596100  70
  > 135     C07      Control  0.14847100  70
  > 136     C09      Control  0.79177000  70
  > 137     C10      Control  0.71970900  70
  > 138     C32      Control  0.56702700  70
  >
  > This is our model:
  >
  > model <- lme( na.action = na.omit, data = data, fixed =
  value ~ group *
  > time, random = ~1 | subject, correlation = corCAR1( form =
  ~time |
  > subject )
  > )
  >
  >
  >
  > anova( model )
  >
  >             numDF denDF  F-value p-value
  > (Intercept)     1    87 59.08836  <.0001
  > group           2    20 34.50706  <.0001
  > time            1    87 19.45032  <.0001
  > group:time      2    87  4.53603  0.0134
  >
  >
  >
  > intervals( model )
  >
  > Approximate 95% confidence intervals
  >
  >  Fixed effects:
  >                                lower          est.
  upper
  > (Intercept)             0.3677066515  0.4905816494
  0.613456647
  > groupStroke large      -0.9027833601 -0.7106686760
  -0.518553992
  > groupStroke small      -0.6705657199 -0.4490365094
  -0.227507299
  > time                   -0.0013629996  0.0009963115
  0.003355623
  > groupStroke large:time -0.0003754957  0.0031296769
  0.006634850
  > groupStroke small:time  0.0019261801  0.0059657552
  0.010005330
  > attr(,"label")
  > [1] "Fixed effects:"
  >
  >  Random Effects:
  >   Level: subject
  >                      lower      est.     upper
  > sd((Intercept)) 0.07377088 0.1227132 0.2041257
  >
  >  Correlation structure:
  >         lower      est.     upper
  > Phi 0.2035765 0.5971507 0.8957905
  > attr(,"label")
  > [1] "Correlation structure:"
  >
  >  Within-group standard error:
  >     lower      est.     upper
  > 0.1779472 0.2071400 0.2411220
  >
  >       [[alternative HTML version deleted]]
  >
  >
  >
  > ------------------------------
  >
  > _______________________________________________
  > R-sig-mixed-models mailing list
  > [6]R-sig-mixed-models at r-project.org
  > [7]https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
  >
  >
  > End of R-sig-mixed-models Digest, Vol 42, Issue 22
  > **************************************************
  >

References

1. http://www.mail-archive.com/r-help at r-project.org/msg65720.html
2. mailto:nikko at hailmail.net
3. mailto:chris.kleier at gmail.com
4. mailto:r-sig-mixed-models at r-project.org
5. mailto:AANLkTilMkK9HJZqXDZimDzKCswXElxw__dUVQpSnW8FQ at mail.gmail.com
6. mailto:R-sig-mixed-models at r-project.org
7. https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bates at stat.wisc.edu  Tue Jun 22 17:34:10 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 22 Jun 2010 10:34:10 -0500
Subject: [R-sig-ME] In mer_finalize(ans) : gr cannot be computed at
	initial par (65)
In-Reply-To: <E5BC2538-9356-4593-BA51-66A54B1975E3@st-andrews.ac.uk>
References: <E5BC2538-9356-4593-BA51-66A54B1975E3@st-andrews.ac.uk>
Message-ID: <AANLkTilG5bHHFf4tK-kPN0fycgUAx_rNrDWO9YRx0umM@mail.gmail.com>

Would it be possible to make the data available so we could check on
the models being fit?

On Tue, Jun 22, 2010 at 10:14 AM, Chris Mcowen <cm744 at st-andrews.ac.uk> wrote:
> Dear R List -
>
> I am trying to do a relatively simple GLMM but am having a problem.
>
> My data is categorical but converted to numeric form in excel ( i.e a=1, b=2 etc) my response is binary and i have two random terms - FAMILY and ORDER.
>
> I have been running the model fine calling this -
>
> model2 <- lmer(THREAT~1+(1|ORDER/FAMILY) + BREEDING_SYSTEM*LIFE_FORM + WOODY_NONWOODY, family=binomial)
>
> Fixed effects:
> ? ? ? ? ? ? ? ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
> (Intercept) ? ? ? ? ? ? ? ?2.62364 ? ?1.41554 ? 1.853 ?0.06382 .
> BREEDING_SYSTEM ? ? ? ? ? -1.24256 ? ?0.47227 ?-2.631 ?0.00851 **
> LIFE_FORM ? ? ? ? ? ? ? ? -0.64368 ? ?0.29026 ?-2.218 ?0.02659 *
> WOODY_NONWOODY ? ? ? ? ? ? 0.51817 ? ?0.19548 ? 2.651 ?0.00803 **
> BREEDING_SYSTEM:LIFE_FORM ?0.22289 ? ?0.09842 ? 2.265 ?0.02353 *

How many different levels of BREEDING_SYSTEM and LIFE_FORM do you
have?  I assume that WOODY_NONWOODY is a binary variable.  If the
others have more than two possible levels, and your saying that Excel
stored them in numeric form (a = 1, b = 2, etc.)  leads me to believe
that there may be more than two, then you are not fitting an
appropriate model.

> However i want to know what type of life form, breeding system etc is significant so i called -
>
> woodynonwoody <- as.factor(WOODY_NONWOODY)
> habit <- as.factor(HABIT)
> breedingsystem <- as.factor(BREEDING_SYSTEM)
>
> model3 <- lmer(THREAT~1+(1|ORDER/FAMILY) + breedingsystem + woodynonwoody*habit, family=binomial)
> Warning message:
> In mer_finalize(ans) : gr cannot be computed at initial par (65)
>
> model3
> Error in asMethod(object) : matrix is not symmetric [1,2]
>
> Interestingly when i try the above call without the interaction term it works

Yes.  Generalized linear models and generalized linear mixed models
can't support a large number of possibly redundant coefficients.  You
need to be careful of your model-building strategy.  Starting from the
most complex model possible and using backward elimination doesn't
always work.

>
> Any help would be greatly appreciated
>
> Chris
>
>
>> sessionInfo()
> R version 2.11.1 (2010-05-31)
> i386-apple-darwin9.8.0
>
> locale:
> [1] en_GB.UTF-8/en_GB.UTF-8/C/C/en_GB.UTF-8/en_GB.UTF-8
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
> other attached packages:
> [1] perturb_2.03 ? ? ? lme4_0.999375-34 ? Matrix_0.999375-40 lattice_0.18-8
>
> loaded via a namespace (and not attached):
> [1] grid_2.11.1 ? nlme_3.1-96 ? stats4_2.11.1 tools_2.11.1
>
>
> Chris Mcowen
> PhD Student
>
> Room 15
> Sir Harold Mitchell Building
> University of St Andrews
> St Andrews
> Fife
> KY16 9TH
> UK
> Phone 01334 463381
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From cm744 at st-andrews.ac.uk  Tue Jun 22 17:40:15 2010
From: cm744 at st-andrews.ac.uk (Chris Mcowen)
Date: Tue, 22 Jun 2010 16:40:15 +0100
Subject: [R-sig-ME] In mer_finalize(ans) : gr cannot be computed at initial
	par (65)
In-Reply-To: <AANLkTilG5bHHFf4tK-kPN0fycgUAx_rNrDWO9YRx0umM@mail.gmail.com>
References: <E5BC2538-9356-4593-BA51-66A54B1975E3@st-andrews.ac.uk>
	<AANLkTilG5bHHFf4tK-kPN0fycgUAx_rNrDWO9YRx0umM@mail.gmail.com>
Message-ID: <7E6CD52E-E54E-4081-AEF6-237633E25AE2@st-andrews.ac.uk>

Hi Douglas and list,

Yeah sure - sorry i should have done that originally, 

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: traits.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100622/5051099b/attachment.txt>
-------------- next part --------------

On 22 Jun 2010, at 16:34, Douglas Bates wrote:

Would it be possible to make the data available so we could check on
the models being fit?

On Tue, Jun 22, 2010 at 10:14 AM, Chris Mcowen <cm744 at st-andrews.ac.uk> wrote:
> Dear R List -
> 
> I am trying to do a relatively simple GLMM but am having a problem.
> 
> My data is categorical but converted to numeric form in excel ( i.e a=1, b=2 etc) my response is binary and i have two random terms - FAMILY and ORDER.
> 
> I have been running the model fine calling this -
> 
> model2 <- lmer(THREAT~1+(1|ORDER/FAMILY) + BREEDING_SYSTEM*LIFE_FORM + WOODY_NONWOODY, family=binomial)
> 
> Fixed effects:
>                          Estimate Std. Error z value Pr(>|z|)
> (Intercept)                2.62364    1.41554   1.853  0.06382 .
> BREEDING_SYSTEM           -1.24256    0.47227  -2.631  0.00851 **
> LIFE_FORM                 -0.64368    0.29026  -2.218  0.02659 *
> WOODY_NONWOODY             0.51817    0.19548   2.651  0.00803 **
> BREEDING_SYSTEM:LIFE_FORM  0.22289    0.09842   2.265  0.02353 *

How many different levels of BREEDING_SYSTEM and LIFE_FORM do you
have?  I assume that WOODY_NONWOODY is a binary variable.  If the
others have more than two possible levels, and your saying that Excel
stored them in numeric form (a = 1, b = 2, etc.)  leads me to believe
that there may be more than two, then you are not fitting an
appropriate model.

> However i want to know what type of life form, breeding system etc is significant so i called -
> 
> woodynonwoody <- as.factor(WOODY_NONWOODY)
> habit <- as.factor(HABIT)
> breedingsystem <- as.factor(BREEDING_SYSTEM)
> 
> model3 <- lmer(THREAT~1+(1|ORDER/FAMILY) + breedingsystem + woodynonwoody*habit, family=binomial)
> Warning message:
> In mer_finalize(ans) : gr cannot be computed at initial par (65)
> 
> model3
> Error in asMethod(object) : matrix is not symmetric [1,2]
> 
> Interestingly when i try the above call without the interaction term it works

Yes.  Generalized linear models and generalized linear mixed models
can't support a large number of possibly redundant coefficients.  You
need to be careful of your model-building strategy.  Starting from the
most complex model possible and using backward elimination doesn't
always work.

> 
> Any help would be greatly appreciated
> 
> Chris
> 
> 
>> sessionInfo()
> R version 2.11.1 (2010-05-31)
> i386-apple-darwin9.8.0
> 
> locale:
> [1] en_GB.UTF-8/en_GB.UTF-8/C/C/en_GB.UTF-8/en_GB.UTF-8
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] perturb_2.03       lme4_0.999375-34   Matrix_0.999375-40 lattice_0.18-8
> 
> loaded via a namespace (and not attached):
> [1] grid_2.11.1   nlme_3.1-96   stats4_2.11.1 tools_2.11.1
> 
> 
> Chris Mcowen
> PhD Student
> 
> Room 15
> Sir Harold Mitchell Building
> University of St Andrews
> St Andrews
> Fife
> KY16 9TH
> UK
> Phone 01334 463381
> 
> 
>        [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 


From bates at stat.wisc.edu  Tue Jun 22 18:44:30 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 22 Jun 2010 11:44:30 -0500
Subject: [R-sig-ME] In mer_finalize(ans) : gr cannot be computed at
	initial par (65)
In-Reply-To: <7E6CD52E-E54E-4081-AEF6-237633E25AE2@st-andrews.ac.uk>
References: <E5BC2538-9356-4593-BA51-66A54B1975E3@st-andrews.ac.uk>
	<AANLkTilG5bHHFf4tK-kPN0fycgUAx_rNrDWO9YRx0umM@mail.gmail.com>
	<7E6CD52E-E54E-4081-AEF6-237633E25AE2@st-andrews.ac.uk>
Message-ID: <AANLkTinaxmjMRqjtnwrSPi3i_1bW_AYBppj0xxTyobCb@mail.gmail.com>

On Tue, Jun 22, 2010 at 10:40 AM, Chris Mcowen <cm744 at st-andrews.ac.uk> wrote:
> Hi Douglas and list,
>
> Yeah sure - sorry i should have done that originally,

Thanks for making the data available.  As I suspected there was a
problem with factor variables not being encoded as factors but there
was also an interesting twist.  When you include the interaction term
there are missing cells in the WOODY_NONWOODY HABIT combinations. (Is
this a consequence of the definition of the habitat levels?)  These
missing cells result in a rank-deficient model matrix for the fixed
effects.

The numerical methods used in glm pick this up but those in glmer
don't.  See the enclosed output.

This point is often overlooked in discussions of how to speed up
computations in R.  Many people feel that using accelerated BLAS
(Basic Linear Algebra Subroutines) will be a panacea but it is exactly
problems like this that necessitate using more careful methods.

>
>
> On 22 Jun 2010, at 16:34, Douglas Bates wrote:
>
> Would it be possible to make the data available so we could check on
> the models being fit?
>
> On Tue, Jun 22, 2010 at 10:14 AM, Chris Mcowen <cm744 at st-andrews.ac.uk> wrote:
>> Dear R List -
>>
>> I am trying to do a relatively simple GLMM but am having a problem.
>>
>> My data is categorical but converted to numeric form in excel ( i.e a=1, b=2 etc) my response is binary and i have two random terms - FAMILY and ORDER.
>>
>> I have been running the model fine calling this -
>>
>> model2 <- lmer(THREAT~1+(1|ORDER/FAMILY) + BREEDING_SYSTEM*LIFE_FORM + WOODY_NONWOODY, family=binomial)
>>
>> Fixed effects:
>> ? ? ? ? ? ? ? ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
>> (Intercept) ? ? ? ? ? ? ? ?2.62364 ? ?1.41554 ? 1.853 ?0.06382 .
>> BREEDING_SYSTEM ? ? ? ? ? -1.24256 ? ?0.47227 ?-2.631 ?0.00851 **
>> LIFE_FORM ? ? ? ? ? ? ? ? -0.64368 ? ?0.29026 ?-2.218 ?0.02659 *
>> WOODY_NONWOODY ? ? ? ? ? ? 0.51817 ? ?0.19548 ? 2.651 ?0.00803 **
>> BREEDING_SYSTEM:LIFE_FORM ?0.22289 ? ?0.09842 ? 2.265 ?0.02353 *
>
> How many different levels of BREEDING_SYSTEM and LIFE_FORM do you
> have? ?I assume that WOODY_NONWOODY is a binary variable. ?If the
> others have more than two possible levels, and your saying that Excel
> stored them in numeric form (a = 1, b = 2, etc.) ?leads me to believe
> that there may be more than two, then you are not fitting an
> appropriate model.
>
>> However i want to know what type of life form, breeding system etc is significant so i called -
>>
>> woodynonwoody <- as.factor(WOODY_NONWOODY)
>> habit <- as.factor(HABIT)
>> breedingsystem <- as.factor(BREEDING_SYSTEM)
>>
>> model3 <- lmer(THREAT~1+(1|ORDER/FAMILY) + breedingsystem + woodynonwoody*habit, family=binomial)
>> Warning message:
>> In mer_finalize(ans) : gr cannot be computed at initial par (65)
>>
>> model3
>> Error in asMethod(object) : matrix is not symmetric [1,2]
>>
>> Interestingly when i try the above call without the interaction term it works
>
> Yes. ?Generalized linear models and generalized linear mixed models
> can't support a large number of possibly redundant coefficients. ?You
> need to be careful of your model-building strategy. ?Starting from the
> most complex model possible and using backward elimination doesn't
> always work.
>
>>
>> Any help would be greatly appreciated
>>
>> Chris
>>
>>
>>> sessionInfo()
>> R version 2.11.1 (2010-05-31)
>> i386-apple-darwin9.8.0
>>
>> locale:
>> [1] en_GB.UTF-8/en_GB.UTF-8/C/C/en_GB.UTF-8/en_GB.UTF-8
>>
>> attached base packages:
>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>
>> other attached packages:
>> [1] perturb_2.03 ? ? ? lme4_0.999375-34 ? Matrix_0.999375-40 lattice_0.18-8
>>
>> loaded via a namespace (and not attached):
>> [1] grid_2.11.1 ? nlme_3.1-96 ? stats4_2.11.1 tools_2.11.1
>>
>>
>> Chris Mcowen
>> PhD Student
>>
>> Room 15
>> Sir Harold Mitchell Building
>> University of St Andrews
>> St Andrews
>> Fife
>> KY16 9TH
>> UK
>> Phone 01334 463381
>>
>>
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
-------------- next part --------------

R version 2.11.1 (2010-05-31)
Copyright (C) 2010 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> library(lme4a)
Loading required package: Matrix
Loading required package: lattice

Attaching package: 'Matrix'

The following object(s) are masked from 'package:base':

    det

Loading required package: minqa
Loading required package: Rcpp

Attaching package: 'lme4a'

The following object(s) are masked from 'package:stats':

    AIC

> dat <- within(read.delim("~/tests/traits.txt"),
+           {
+               FLORAL_SYMMETRY <- factor(FLORAL_SYMMETRY, labels = c("Y", "N"))
+               THREAT <- factor(THREAT, labels = c("Y", "N"))
+               STORAGE_ORGAN <- factor(STORAGE_ORGAN, labels = c("Y", "N"))
+               WOODY <- factor(WOODY_NONWOODY, labels = c("Y", "N"))
+               HABIT <- factor(HABIT)
+               BREEDING_SYSTEM <- factor(BREEDING_SYSTEM)
+           })
> str(dat)
'data.frame':	1344 obs. of  20 variables:
 $ ORDER           : Factor w/ 9 levels "Alismatales",..: 3 3 3 3 3 3 3 3 3 3 ...
 $ FAMILY          : Factor w/ 43 levels "Agavaceae","Alliaceae",..: 1 1 1 2 2 2 2 2 2 2 ...
 $ GENUS           : Factor w/ 501 levels "Acanthochlamys",..: 10 10 10 19 19 19 19 19 19 19 ...
 $ SPECIES         : Factor w/ 1258 levels "abdulrahmanii",..: 456 591 804 237 103 411 123 172 199 372 ...
 $ LIFE_FORM       : int  5 5 5 5 5 5 5 5 5 5 ...
 $ YES             : int  10 10 10 10 10 10 10 10 10 10 ...
 $ STORAGE_ORGAN   : Factor w/ 2 levels "Y","N": 1 1 1 1 1 1 1 1 1 1 ...
 $ BREEDING_SYSTEM : Factor w/ 3 levels "1","2","3": 3 3 3 3 3 3 3 3 3 3 ...
 $ POLLEN_DISPERSAL: int  2 2 2 2 2 2 2 2 2 2 ...
 $ FRUIT           : int  2 2 2 1 1 1 1 1 1 1 ...
 $ ENDOSPERM       : int  2 2 2 2 2 2 2 2 2 2 ...
 $ HABIT           : Factor w/ 5 levels "1","2","3","4",..: 3 3 3 3 3 3 3 3 3 3 ...
 $ WOODY_NONWOODY  : int  2 2 2 2 2 2 2 2 2 2 ...
 $ L2_REGIONS      : int  2 1 1 2 1 2 1 1 1 1 ...
 $ SEASONALITY     : int  2 2 2 2 2 2 2 2 2 2 ...
 $ ALTITUDE        : int  1 2 5 6 6 6 5 5 5 5 ...
 $ SEED_FRUIT      : int  2 2 2 5 5 5 5 5 5 5 ...
 $ FLORAL_SYMMETRY : Factor w/ 2 levels "Y","N": 1 1 1 1 1 1 1 1 1 1 ...
 $ THREAT          : Factor w/ 2 levels "Y","N": 2 2 1 1 2 2 1 1 1 2 ...
 $ WOODY           : Factor w/ 2 levels "Y","N": 2 2 2 2 2 2 2 2 2 2 ...
> summary(dat)
          ORDER              FAMILY             GENUS           SPECIES    
 Asparagales :615   Orchidaceae :532   Carex       :  48   pallida  :   4  
 Poales      :490   Poaceae     :246   Bulbophyllum:  38   bracteata:   3  
 Arecales    : 62   Cyperaceae  :118   Tillandsia  :  23   debilis  :   3  
 Alismatales : 61   Bromeliaceae: 81   Dendrobium  :  22   elatum   :   3  
 Zingiberales: 48   Arecaceae   : 62   Lepanthes   :  22   gracile  :   3  
 Dioscoreales: 22   Araceae     : 60   Habenaria   :  19   javanica :   3  
 (Other)     : 46   (Other)     :245   (Other)     :1172   (Other)  :1325  
   LIFE_FORM           YES        STORAGE_ORGAN BREEDING_SYSTEM
 Min.   : 1.000   Min.   : 1.00   Y:1103        1: 170         
 1st Qu.: 1.000   1st Qu.:10.00   N: 241        2:  83         
 Median : 5.000   Median :10.00                 3:1091         
 Mean   : 3.704   Mean   : 9.91                                
 3rd Qu.: 5.000   3rd Qu.:10.00                                
 Max.   :10.000   Max.   :10.00                                
                                                               
 POLLEN_DISPERSAL     FRUIT         ENDOSPERM     HABIT    WOODY_NONWOODY 
 Min.   :1.000    Min.   :1.000   Min.   :1.000   1:  60   Min.   :1.000  
 1st Qu.:1.000    1st Qu.:1.000   1st Qu.:1.000   2:   6   1st Qu.:2.000  
 Median :2.000    Median :1.000   Median :2.000   3:1230   Median :2.000  
 Mean   :1.674    Mean   :1.136   Mean   :1.563   4:  38   Mean   :1.906  
 3rd Qu.:2.000    3rd Qu.:1.000   3rd Qu.:2.000   5:  10   3rd Qu.:2.000  
 Max.   :2.000    Max.   :2.000   Max.   :2.000            Max.   :2.000  
                                                                          
   L2_REGIONS     SEASONALITY       ALTITUDE       SEED_FRUIT   
 Min.   : 1.00   Min.   :1.000   Min.   :1.000   Min.   :1.000  
 1st Qu.: 1.00   1st Qu.:2.000   1st Qu.:1.000   1st Qu.:2.000  
 Median : 1.00   Median :2.000   Median :3.000   Median :2.000  
 Mean   : 1.79   Mean   :1.963   Mean   :3.001   Mean   :3.004  
 3rd Qu.: 2.00   3rd Qu.:2.000   3rd Qu.:5.000   3rd Qu.:4.000  
 Max.   :49.00   Max.   :3.000   Max.   :6.000   Max.   :5.000  
                                                                
 FLORAL_SYMMETRY THREAT  WOODY   
 Y:762           Y:659   Y: 126  
 N:582           N:685   N:1218  
                                 
                                 
                                 
                                 
                                 
> summary(glm1 <- glm(THREAT ~ BREEDING_SYSTEM + WOODY * HABIT, family = binomial, data = dat))

Call:
glm(formula = THREAT ~ BREEDING_SYSTEM + WOODY * HABIT, family = binomial, 
    data = dat)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-1.5866  -1.1930   0.9706   1.1619   2.0349  

Coefficients: (2 not defined because of singularities)
                  Estimate Std. Error z value Pr(>|z|)   
(Intercept)       -0.06820    0.40392  -0.169  0.86592   
BREEDING_SYSTEM2  -0.29553    0.33997  -0.869  0.38470   
BREEDING_SYSTEM3  -0.47137    0.17330  -2.720  0.00653 **
WOODYN            -1.57186    0.81875  -1.920  0.05488 . 
HABIT2             2.56450    1.16005   2.211  0.02706 * 
HABIT3             0.41879    0.50302   0.833  0.40510   
HABIT4             0.01707    0.50597   0.034  0.97308   
HABIT5            -0.84673    0.87861  -0.964  0.33519   
WOODYN:HABIT2           NA         NA      NA       NA   
WOODYN:HABIT3      1.72928    0.88892   1.945  0.05173 . 
WOODYN:HABIT4    -10.47171  324.74491  -0.032  0.97428   
WOODYN:HABIT5           NA         NA      NA       NA   
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 1862.7  on 1343  degrees of freedom
Residual deviance: 1834.6  on 1334  degrees of freedom
AIC: 1854.6

Number of Fisher Scoring iterations: 11

> summary(glm2 <- glm(THREAT ~ BREEDING_SYSTEM + WOODY + HABIT, family = binomial, data = dat))

Call:
glm(formula = THREAT ~ BREEDING_SYSTEM + WOODY + HABIT, family = binomial, 
    data = dat)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-1.6042  -1.1888   0.9707   1.1660   1.7941  

Coefficients:
                 Estimate Std. Error z value Pr(>|z|)   
(Intercept)       -0.2804     0.3948  -0.710  0.47762   
BREEDING_SYSTEM2  -0.3680     0.3383  -1.088  0.27677   
BREEDING_SYSTEM3  -0.4810     0.1734  -2.774  0.00554 **
WOODYN            -0.2088     0.3018  -0.692  0.48902   
HABIT2             1.4527     0.9438   1.539  0.12374   
HABIT3             0.9969     0.4271   2.334  0.01959 * 
HABIT4             0.2000     0.4953   0.404  0.68636   
HABIT5            -0.6250     0.8743  -0.715  0.47470   
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 1862.7  on 1343  degrees of freedom
Residual deviance: 1839.9  on 1336  degrees of freedom
AIC: 1855.9

Number of Fisher Scoring iterations: 4

> anova(glm2, glm1)
Analysis of Deviance Table

Model 1: THREAT ~ BREEDING_SYSTEM + WOODY + HABIT
Model 2: THREAT ~ BREEDING_SYSTEM + WOODY * HABIT
  Resid. Df Resid. Dev Df Deviance
1      1336     1839.9            
2      1334     1834.6  2   5.3305
> pchisq(5.3305, 2, lower = FALSE)
[1] 0.06958196
> print(glmm1 <- glmer(THREAT ~ BREEDING_SYSTEM + WOODY + HABIT + (1|ORDER/FAMILY),
+                      dat, binomial, verbose = 1), corr=FALSE)
npt = 5 , n =  2 
rhobeg =  0.2 , rhoend =  2e-07 
   0.020:   8:      1839.93; 0.00000  0.00000 
  0.0020:  12:      1839.93; 0.00000  0.00000 
 0.00020:  14:      1839.93; 0.00000  0.00000 
 2.0e-05:  16:      1839.93; 0.00000  0.00000 
 2.0e-06:  18:      1839.93; 0.00000  0.00000 
 2.0e-07:  21:      1839.93; 0.00000  0.00000 
At return
 26:     1839.9318:  0.00000 1.00000e-07
npt = 16 , n =  10 
rhobeg =  0.2905476 , rhoend =  2.905476e-07 
   0.029:  17:      1839.93; 0.00000  0.00000 -0.280354 -0.367978 -0.480966 -0.208796  1.45274 0.996945 0.200016 -0.624974 
  0.0029:  33:      1839.93; 0.00000  0.00000 -0.280354 -0.367978 -0.480966 -0.208796  1.45274 0.996945 0.200016 -0.624974 
 0.00029:  46:      1839.93; 0.00000  0.00000 -0.280354 -0.367978 -0.480966 -0.208796  1.45274 0.996945 0.200016 -0.624974 
 2.9e-05:  57:      1839.93; 0.00000  0.00000 -0.280354 -0.367978 -0.480966 -0.208796  1.45274 0.996945 0.200016 -0.624974 
 2.9e-06:  68:      1839.93; 0.00000  0.00000 -0.280354 -0.367978 -0.480966 -0.208796  1.45274 0.996945 0.200016 -0.624974 
 2.9e-07:  81:      1839.93; 0.00000  0.00000 -0.280354 -0.367978 -0.480966 -0.208796  1.45274 0.996945 0.200016 -0.624974 
At return
100:     1839.9318:  0.00000  0.00000 -0.280354 -0.367978 -0.480966 -0.208797  1.45274 0.996946 0.200016 -0.624974
Generalized linear mixed model fit by maximum likelihood ['merMod']
 Family: binomial 
Formula: THREAT ~ BREEDING_SYSTEM + WOODY + HABIT + (1 | ORDER/FAMILY) 
   Data: dat 
      AIC       BIC    logLik  deviance 
1859.9318 1911.9659 -919.9659 1839.9318 

Random effects:
 Groups       Name        Variance Std.Dev.
 FAMILY:ORDER (Intercept) 0        0       
 ORDER        (Intercept) 0        0       
Number of obs: 1344, groups: FAMILY:ORDER, 43; ORDER, 9

Fixed effects:
                 Estimate Std. Error z value
(Intercept)       -0.2804     0.3948  -0.710
BREEDING_SYSTEM2  -0.3680     0.3383  -1.088
BREEDING_SYSTEM3  -0.4810     0.1734  -2.774
WOODYN            -0.2088     0.3018  -0.692
HABIT2             1.4527     0.9438   1.539
HABIT3             0.9969     0.4271   2.334
HABIT4             0.2000     0.4953   0.404
HABIT5            -0.6250     0.8743  -0.715
> 
> proc.time()
   user  system elapsed 
  6.800   0.110   6.888 

From chris.kleier at gmail.com  Tue Jun 22 20:44:16 2010
From: chris.kleier at gmail.com (Chris Kleier)
Date: Tue, 22 Jun 2010 20:44:16 +0200
Subject: [R-sig-ME] lme posthoc constrasts for interaction effects
	group*time
In-Reply-To: <1277219933.10568.1381346789@webmail.messagingengine.com>
References: <mailman.7.1276855203.25637.r-sig-mixed-models@r-project.org>
	<1276878437.5914.1380778075@webmail.messagingengine.com>
	<AANLkTin1e2AbFBSokMeO_BuTFX5iGg0qA8UczwVRIOPs@mail.gmail.com>
	<1277219933.10568.1381346789@webmail.messagingengine.com>
Message-ID: <AANLkTiludePJdZi783zL1gPZJmbrXV7M1OvUK0yGpQ17@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100622/f00a70cb/attachment.pl>

From nikko at hailmail.net  Tue Jun 22 21:36:35 2010
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Tue, 22 Jun 2010 12:36:35 -0700
Subject: [R-sig-ME] lme posthoc constrasts for interaction effects
 group*time
In-Reply-To: <AANLkTiludePJdZi783zL1gPZJmbrXV7M1OvUK0yGpQ17@mail.gmail.com>
References: <mailman.7.1276855203.25637.r-sig-mixed-models@r-project.org><1276878437.5914.1380778075@webmail.messagingengine.com><AANLkTin1e2AbFBSokMeO_BuTFX5iGg0qA8UczwVRIOPs@mail.gmail.com><1277219933.10568.1381346789@webmail.messagingengine.com>
	<AANLkTiludePJdZi783zL1gPZJmbrXV7M1OvUK0yGpQ17@mail.gmail.com>
Message-ID: <1277235395.3889.1381389339@webmail.messagingengine.com>

Hi Chris,
No, you want to leave the main effects in.
Nicholas

On Tue, 22 Jun 2010 20:44 +0200, "Chris Kleier"
<chris.kleier at gmail.com> wrote:

  Hi Nicolas,
  You're right, I'll should go for the manual contrast matrix,
  and correct for multiple comparisons manually.
  This is the matrix created using the contrast package for
  'group' (taking into account the interaction effects as well).
                              (Intercept) groupStroke large
  groupStroke small    time groupStroke large:time groupStroke
  small:time
  Stroke large - Control                0
  1                 0    0
  1                      0
  Stroke small - Control               0
  0                 1    0
  0                      1
  Stroke small - Stroke large        0
  -1                 1    0
  -1                      1
  Just to be sure: to get the interaction effect contrasts ONLY,
  should I change the contrast to: ?
                              (Intercept) groupStroke large
  groupStroke small    time groupStroke large:time groupStroke
  small:time
  Stroke large - Control                0                 0
              0    0                      1
  0
  Stroke small - Control               0
  0                 0    0
  0                      1
  Stroke small - Stroke large        0                 0
           0    0                     -1                      1
  Thanks!
  Chris

On Tue, Jun 22, 2010 at 5:18 PM, Nicholas Lewin-Koh
<[1]nikko at hailmail.net> wrote:

  Hi Chris,
  If you look at the code I sent, the second part uses the
  contrast
  package to get
  the contrast matrix for testing within the interaction. mcp
  does not
  handle interactions (I think) but you can specifiy them more
  easily
  using the contrast package and then peel off the contrast
  matrix for use
  in multcomp.
  Nicholas

On Tue, 22 Jun 2010 16:57 +0200, "Chris Kleier"
<[2]chris.kleier at gmail.com> wrote:
 Hi Nicholas,
 Thanks for your help.
 I have been looking at the contrast library, however, we are
 interested in differences between interactions only and not
 between group and interactions together.
 In fact I would like:
 test <- glht( model, lin = mcp( "group:time"  = 'Tukey' ) )
 This quesion is in fact similar to the question posted before:

   [1][3]http://www.mail-archive.com/r-help at r-project.org/msg657
  20.h

 tml
 The mcp function is probably not able to manage interactions.
 Chris
On Fri, Jun 18, 2010 at 6:27 PM, Nicholas Lewin-Koh


<[2][4]nikko at hailmail.net> wrote:
 Hi,
 Try
 library(multcomp)
 test<-glht(model,lin=mcp(group="Tukey"))
 confint(test)
 However, that just tests the marginal effect of group.
 With interactions you want to test over time, probably a
 simultaneous
 interval.
 This will get you close:
 library(contrast)
 ctt<-contrast(model, a=list( day=c(0,3,7,21,49), group=c(Small
 Stroke",
 "Large Stroke")),
              b=list(day=c(0,3,7,21,49), group=c("Control",
 "Control")))
 ## Extract the contrast matrix
 cmtrx <- ctt$X
 ## Fit the contrasts using glht
 ttgl<-glht(model,lin=cmtrx)
 confint(ttgl)
 hope this helps.
 And do read the vignette in multcomp  :)
 Nicholas
 > Message: 2
 > Date: Thu, 17 Jun 2010 14:51:21 +0200

   > From: Chris Kleier <[3][5]chris.kleier at gmail.com>
   > To: R sig-mixed-models
  <[4][6]r-sig-mixed-models at r-project.org>

 > Subject: [R-sig-ME] lme posthoc constrasts for interaction
 effects
 >       group*time
 > Message-ID:
 >

   <[5]AANLkTilMkK9HJZqXDZimDzKCswXElxw__dUVQpSnW8FQ at mail.gmail.
  c


 om>
 > Content-Type: text/plain
 >
 > Hi all,
 >
 > Our dataset is a repeated measures design including 3 groups
 (a)
 > Controls,
 > (b) Small stroke and (c) Large stroke. We want to know if
 the group
 > behave
 > different over time.
 >
 > We first fitted a lme with fixed = group * time (see below).
 > Their was a significant interaction effect (see below as
 well; p < 0.05)
 >
 > In the next step we want to know which groups have
 significant
 > interactions
 > (Control - Stroke large, Control - Stroke small, Stroke
 small - Stroke
 > large), and their p-values + CIs.
 >
 > A posthoc Tukey, I think is fine. However, I do not know how
 to setup the
 > constrast matrix.
 >
 > These are the contrast names ( names( coef( model ) ) ):
 > "(Intercept)", "groupStroke large", "groupStroke small",
 "time",
 > "groupStroke large:time" "groupStroke small:time"
 >
 > I guess, the model has to be refitted to get a contrast for
 > "groupControl:time" as well, but I do not know how.
 >
 > Any solution known? (Probabily something in the direction
 of: model.2 <-
 > update( model, fixed = 0 + group * time ) )
 >
 > Thanks!
 >
 > Chris
 >
 >
 >
 >
 >
 > This is a print of the dataset:
 >
 >     subject        group       value day
 > 1       N03 Stroke small  0.47545500   0
 > 2       N04 Stroke small  0.38866500   0
 > 3       N19 Stroke small  0.64749800   0
 > 4       N20 Stroke small  0.50468600   0
 > 5       N22 Stroke small  0.55872300   0
 > 6       N03 Stroke small  0.01979970   3
 > 7       N04 Stroke small  0.05607250   3
 > 8       N19 Stroke small -0.04506370   3
 > 9       N20 Stroke small -0.33935400   3
 > 10      N22 Stroke small  0.22052700   3
 > 11      N03 Stroke small  0.29805300   7
 > 12      N04 Stroke small -0.24908100   7
 > 13      N19 Stroke small -0.02657290   7
 > 14      N20 Stroke small -0.19483200   7
 > 15      N22 Stroke small  0.50948000   7
 > 16      N03 Stroke small  0.13056600  21
 > 17      N04 Stroke small  0.33759500  21
 > 18      N19 Stroke small  0.14929200  21
 > 19      N20 Stroke small  0.25033100  21
 > 20      N22 Stroke small  0.71456800  21
 > 21      N03 Stroke small  0.39007100  49
 > 22      N04 Stroke small  0.33254400  49
 > 23      N19 Stroke small  0.27767600  49
 > 24      N20 Stroke small  0.33467500  49
 > 25      N22 Stroke small  0.52203500  49
 > 26      N03 Stroke small  0.29851100  70
 > 27      N04 Stroke small  0.50900200  70
 > 28      N19 Stroke small  0.51781700  70
 > 29      N20 Stroke small  0.69543700  70
 > 30      N22 Stroke small  0.49337000  70
 > 31      N01 Stroke large          NA   0
 > 32      N07 Stroke large  0.54930600   0
 > 33      N09 Stroke large  0.59703600   0
 > 34      N10 Stroke large  0.72751400   0
 > 35      N17 Stroke large  0.63878400   0
 > 36      N23 Stroke large  0.65749100   0
 > 37      N24 Stroke large  0.60945900   0
 > 38      N28 Stroke large          NA   0
 > 39      N01 Stroke large -0.31610900   3
 > 40      N07 Stroke large -0.33615700   3
 > 41      N09 Stroke large -0.24906400   3
 > 42      N10 Stroke large  0.33868700   3
 > 43      N17 Stroke large -0.31357300   3
 > 44      N23 Stroke large -0.13162800   3
 > 45      N24 Stroke large -0.45343700   3
 > 46      N28 Stroke large -0.18206700   3
 > 47      N01 Stroke large -0.05309070   7
 > 48      N07 Stroke large -0.83318300   7
 > 49      N09 Stroke large -0.49667100   7
 > 50      N10 Stroke large -0.48083200   7
 > 51      N17 Stroke large -0.28447000   7
 > 52      N23 Stroke large  0.01842660   7
 > 53      N24 Stroke large -0.50464400   7
 > 54      N28 Stroke large  0.16456100   7
 > 55      N01 Stroke large  0.24652600  21
 > 56      N07 Stroke large -0.31566500  21
 > 57      N09 Stroke large  0.39618900  21
 > 58      N10 Stroke large -0.30702200  21
 > 59      N17 Stroke large -0.28860100  21
 > 60      N23 Stroke large -0.23851000  21
 > 61      N24 Stroke large -0.00913697  21
 > 62      N28 Stroke large  0.43462600  21
 > 63      N01 Stroke large -0.20660100  49
 > 64      N07 Stroke large -0.13044900  49
 > 65      N09 Stroke large  0.24625000  49
 > 66      N10 Stroke large -0.28206200  49
 > 67      N17 Stroke large  0.29186400  49
 > 68      N23 Stroke large -0.14246600  49
 > 69      N24 Stroke large -0.11297700  49
 > 70      N28 Stroke large  0.32027300  49
 > 71      N01 Stroke large -0.00106427  70
 > 72      N07 Stroke large -0.17264000  70
 > 73      N09 Stroke large  0.26417500  70
 > 74      N10 Stroke large -0.11202200  70
 > 75      N17 Stroke large  0.16687700  70
 > 76      N23 Stroke large -0.24308300  70
 > 77      N24 Stroke large  0.00322026  70
 > 78      N28 Stroke large  0.34928100  70
 > 79      C01      Control          NA   0
 > 80      C02      Control          NA   0
 > 81      C03      Control          NA   0
 > 82      C04      Control          NA   0
 > 83      C05      Control          NA   0
 > 84      C06      Control          NA   0
 > 85      C07      Control          NA   0
 > 86      C09      Control          NA   0
 > 87      C10      Control          NA   0
 > 88      C32      Control          NA   0
 > 89      C01      Control  0.32387500   3
 > 90      C02      Control  0.48334200   3
 > 91      C03      Control  0.70698800   3
 > 92      C04      Control  0.00572262   3
 > 93      C05      Control  0.40416000   3
 > 94      C06      Control  0.36343800   3
 > 95      C07      Control  0.05064140   3
 > 96      C09      Control  0.84621500   3
 > 97      C10      Control  0.80675300   3
 > 98      C32      Control          NA   3
 > 99      C01      Control  0.23174400   7
 > 100     C02      Control  0.36959100   7
 > 101     C03      Control  0.43762800   7
 > 102     C04      Control  0.34187100   7
 > 103     C05      Control  0.74288400   7
 > 104     C06      Control  0.17692600   7
 > 105     C07      Control  0.60067600   7
 > 106     C09      Control  0.80314900   7
 > 107     C10      Control  0.81695500   7
 > 108     C32      Control  0.19029400   7
 > 109     C01      Control  0.45062600  21
 > 110     C02      Control  0.62884500  21
 > 111     C03      Control  0.33693200  21
 > 112     C04      Control  0.76098800  21
 > 113     C05      Control  0.59837500  21
 > 114     C06      Control  0.39328800  21
 > 115     C07      Control  0.55099400  21
 > 116     C09      Control  0.75411500  21
 > 117     C10      Control  0.72495100  21
 > 118     C32      Control  0.66503400  21
 > 119     C01      Control  0.63903900  49
 > 120     C02      Control          NA  49
 > 121     C03      Control  0.59655200  49
 > 122     C04      Control  0.42958700  49
 > 123     C05      Control  0.68408700  49
 > 124     C06      Control  0.45482700  49
 > 125     C07      Control  0.37217700  49
 > 126     C09      Control  0.75770400  49
 > 127     C10      Control  0.62059200  49
 > 128     C32      Control  0.68320900  49
 > 129     C01      Control  0.66179300  70
 > 130     C02      Control  0.34183000  70
 > 131     C03      Control  0.58543900  70
 > 132     C04      Control  0.62621700  70
 > 133     C05      Control  0.40610400  70
 > 134     C06      Control  0.32596100  70
 > 135     C07      Control  0.14847100  70
 > 136     C09      Control  0.79177000  70
 > 137     C10      Control  0.71970900  70
 > 138     C32      Control  0.56702700  70
 >
 > This is our model:
 >
 > model <- lme( na.action = na.omit, data = data, fixed =
 value ~ group *
 > time, random = ~1 | subject, correlation = corCAR1( form =
 ~time |
 > subject )
 > )
 >
 >
 >
 > anova( model )
 >
 >             numDF denDF  F-value p-value
 > (Intercept)     1    87 59.08836  <.0001
 > group           2    20 34.50706  <.0001
 > time            1    87 19.45032  <.0001
 > group:time      2    87  4.53603  0.0134
 >
 >
 >
 > intervals( model )
 >
 > Approximate 95% confidence intervals
 >
 >  Fixed effects:
 >                                lower          est.
 upper
 > (Intercept)             0.3677066515  0.4905816494
 0.613456647
 > groupStroke large      -0.9027833601 -0.7106686760
 -0.518553992
 > groupStroke small      -0.6705657199 -0.4490365094
 -0.227507299
 > time                   -0.0013629996  0.0009963115
 0.003355623
 > groupStroke large:time -0.0003754957  0.0031296769
 0.006634850
 > groupStroke small:time  0.0019261801  0.0059657552
 0.010005330
 > attr(,"label")
 > [1] "Fixed effects:"
 >
 >  Random Effects:
 >   Level: subject
 >                      lower      est.     upper
 > sd((Intercept)) 0.07377088 0.1227132 0.2041257
 >
 >  Correlation structure:
 >         lower      est.     upper
 > Phi 0.2035765 0.5971507 0.8957905
 > attr(,"label")
 > [1] "Correlation structure:"
 >
 >  Within-group standard error:
 >     lower      est.     upper
 > 0.1779472 0.2071400 0.2411220
 >
 >       [[alternative HTML version deleted]]
 >
 >
 >
 > ------------------------------
 >
 > _______________________________________________
 > R-sig-mixed-models mailing list

   > [6][7]R-sig-mixed-models at r-project.org
   >
  [7][8]https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

 >
 >
 > End of R-sig-mixed-models Digest, Vol 42, Issue 22
 > **************************************************
 >

  References
  1.
  [9]http://www.mail-archive.com/r-help at r-project.org/msg65720.h
  tml
  2. mailto:[10]nikko at hailmail.net
  3. mailto:[11]chris.kleier at gmail.com
  4. mailto:[12]r-sig-mixed-models at r-project.org
  5.
  mailto:[13]AANLkTilMkK9HJZqXDZimDzKCswXElxw__dUVQpSnW8FQ at mail.
  gmail.com
  6. mailto:[14]R-sig-mixed-models at r-project.org
  7.
  [15]https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

References

1. mailto:nikko at hailmail.net
2. mailto:chris.kleier at gmail.com
3. http://www.mail-archive.com/r-help at r-project.org/msg65720.h
4. mailto:nikko at hailmail.net
5. mailto:chris.kleier at gmail.com
6. mailto:r-sig-mixed-models at r-project.org
7. mailto:R-sig-mixed-models at r-project.org
8. https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
9. http://www.mail-archive.com/r-help at r-project.org/msg65720.html
  10. mailto:nikko at hailmail.net
  11. mailto:chris.kleier at gmail.com
  12. mailto:r-sig-mixed-models at r-project.org
  13.
  mailto:AANLkTilMkK9HJZqXDZimDzKCswXElxw__dUVQpSnW8FQ at mail.gmail.com
  14. mailto:R-sig-mixed-models at r-project.org
  15. https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From pauljohn32 at gmail.com  Tue Jun 22 22:06:37 2010
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Tue, 22 Jun 2010 15:06:37 -0500
Subject: [R-sig-ME] Computational speed - MCMCglmm/lmer
In-Reply-To: <4C1CE581.9030205@u.washington.edu>
References: <4C1CE581.9030205@u.washington.edu>
Message-ID: <AANLkTimm7BPOARDPXgW_mTHNngu_sbKjPPgVlS6FSqQf@mail.gmail.com>

On Sat, Jun 19, 2010 at 10:42 AM, David Atkins <datkins at u.washington.edu> wrote:
>
> Hi all--
>
> I use (g)lmer and MCMCglmm on a weekly basis, and I am wondering about
> options for speeding up their computations. ?This is primarily an issue with
> MCMCglmm, given the many necessary MCMC iterations to get to convergence on
> some problems. ?But, even with glmer(), I have runs that get into 20-30
> minutes.
>
> 3. "Optimized" BLAS: There's a bit of discussion about optimized BLAS (basis
> linear algebra... something). ?However, these discussions note that there is
> no generally superior BLAS. ?Not sure whether specific BLAS might be
> optimized for GLMM computations.
>
> 4. Parallel computing: With multi-core computers, looks like there are some
> avenues for splitting intensive computations across processors.

Hi, Dave:

I've wondered this same thing. I replaced the base R BLAS with
GOTOBLAS2 and ATLAS and both are much faster than R's base BLAS.  In
Gotoblas2, computation is about 10 x faster on linear algebra
problems, especially on the kinds of problems where it can  thread
computations across all cores.  The BLAS library from Atlas does not
seem to thread, so it is not quite so fast.

In either case, I've tested your example on this Lenovo T61 laptop
with dual core Pentium that maxes out at 2.4GHz,

To calculate your model with the base R BLAS:

drk.glmer

 user  system elapsed
 29.920   0.120  30.245


The time elapsed with the optimized BLAS is not so much faster as I
had expected. With Atlas it is:

   user  system elapsed
 25.660   0.100  25.784

Gotoblas2 is almost identical, I'm quite surprised.  On other tests
I've done, it supplies a more noticeable speedup because it can go
multi core when needed.  I was monitoring the CPU and the calculations
all stay on one core.

   user  system elapsed
 25.670   0.050  25.725

Well, if you use Atlas or GOTOBLAS2, you can expect a speedup of about 1/6th.

I made the mistake of running that example with MCMCglmm in your code.
 The system is locked in mortal combat with that.  I didn't notice
your time was 1208. before I started that one.  :(

pj

-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas



From steven.brady at yale.edu  Tue Jun 22 23:11:03 2010
From: steven.brady at yale.edu (Steven Brady)
Date: Tue, 22 Jun 2010 17:11:03 -0400
Subject: [R-sig-ME] Contrast interaction effects in lmer object for
	reciprocal transplant experiment
Message-ID: <F4C20990-E4AA-444A-9339-10D663C8BF60@yale.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100622/c9994337/attachment.pl>

From reinhold.kliegl at gmail.com  Tue Jun 22 23:56:36 2010
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Tue, 22 Jun 2010 23:56:36 +0200
Subject: [R-sig-ME] Contrast interaction effects in lmer object for
	reciprocal transplant experiment
In-Reply-To: <F4C20990-E4AA-444A-9339-10D663C8BF60@yale.edu>
References: <F4C20990-E4AA-444A-9339-10D663C8BF60@yale.edu>
Message-ID: <AANLkTimK7Vq2AuarP2g4_sqmInvF8ewmsG_jkMBT3JQ0@mail.gmail.com>

#You could specify a main effect of environment and two nested
contrasts of origin
# within levels of environment for a single factor with four levels,
constructed with paste()

exp=data.frame(pond=pond, env=env, origin=origin, iv = paste(env,
origin, sep="_"), survival=survival)

# nested contrasts
cmat <- matrix(c( -1/2, -1/2, +1/2, +1/2, ? ? ? ? ? ?   # Main effect of env
? ? ? ? ? ?                 ?-1/2, +1/2, ? ? 0, ? ?  0,
# Nested effect of origin | env==r
? ? ? ? ? ? ? ?                   0, ? ? 0, -1/2, +1/2), ?4, ?3, ? ?#
Nested effect of origin | env==w
? ? ? ? ? ? ? ?              dimnames=list(c("r_r", "r_w", "w_r", "w_w"),
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?c(".Ew-Er", ".w-r|Er", ".w-r|Ew")))

(contrasts(exp$iv) <- cmat)

(g<-lmer(survival ~ iv + (1|pond), data = exp))

Reinhold Kliegl

On Tue, Jun 22, 2010 at 11:11 PM, Steven Brady <steven.brady at yale.edu> wrote:
> Dear All:
>
> I am using lmer() to analyze results from a reciprocal transplant
> experiment where the response variable is modeled as a function of two
> fixed effects and their interaction.
>
> Example data follow:
>
> #library(lme4)
> #library(gmodels)
>
> env=c("r","r","w","w","r","r","w","w","r","r",
> "w","w","r","r","w","w")
> #type of environment to where populations
> #were transplanted (fixed effect)
>
> origin=c("r","r","r","r","r","r","r",
> "r","w","w","w","w","w","w","w","w")
> #type of environment from where populations
> #originated (fixed effect)
>
> survival=c(rnorm(16,0.75, sd = 0.1))
> #percent survival (response variable)
>
> population=c("a","a","a","a","b","b","b","b",
> "c","c","c","c","d","d","d","d")
> #local population (random effect)
>
> exp=data.frame(pond=pond, env=env,
> origin=origin,survival=survival)
> #make data frame
>
> g<-lmer(survival~origin*env + (1|population),
> data = exp)
> # mixed model
>
> pvals.fnc(g)
> #evaluate fixed effects
>
>
> My question is this:
>
> How do I perform contrasts on the interaction of the fixed effects
> using, say estimable() in the library {gmodels}? ?I have seen how to
> do this for levels within a factor, however, I am unsure how to apply
> these to levels among factors (i.e. the interaction terms).
>
> Biologically speaking, I am interested in evaluating the difference in
> survival between the two origin types in each of two types of
> environments. ?In other words:
>
> 1. does origin r differ from origin w within env w? ?and,
> 2. does origin r differ from origin w within env r?
>
> Part of my misunderstanding concerns the reporting of the fixed
> effects of the model, which are named as the fixed term concatenated
> with a level (e.g. originw). ?Does the way lmer names the fixed
> effects influence the contrast matrix I should specify?
>
> Many thanks in advance,
>
> Steve Brady
>
> __________________________________________
> Steven P. Brady, Ph.D. Candidate
> School of Forestry & Environmental Studies
> Yale University
> 370 Prospect Street
> New Haven, CT 06511
>
> Email: steven.brady at yale.edu
> Phone: 203-432-5321 Fax: 203-432-3929
> Web: http://www.cbc.yale.edu/people/skelly/steveb.html
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From as146608 at umconnect.umt.edu  Wed Jun 23 01:16:28 2010
From: as146608 at umconnect.umt.edu (Alan Swanson)
Date: Tue, 22 Jun 2010 17:16:28 -0600
Subject: [R-sig-ME] inconsistent gamm likelihoods
Message-ID: <4C21444C.70900@umconnect.umt.edu>

I have some soil measurements along transects and I'd like to test for
a treatment effect.  GAMM models with a random intercept fit the data
well, although there is some residual autocorrelation.  My approach is 
to use a likelihood ratio test to compare GAMMs with no treatment effect 
to GAMMs that allows for a separate fit by treatment.

My problem is that I'm getting very different results when I use 
penalized cubic regression splines versus cr splines with fixed degrees 
of freedom.  For some response variables, the results are as I would 
expect:  likelihood values are about the same when effective degrees of 
freedom are similar.  For other response variables, penalized cr splines 
  give inferior likelihoods when the treatment effect is included, so 
likelihood ratio test statistic is much smaller (4 vs 30), even though 
the fits look very similar.

Does anybody know why penalized cr splines would give a significantly 
different likelihood than a very similar fit with fixed df?  Sample code 
(same syntax but I am unable to reproduce the inconsistency) and session 
info are pasted below.

Many thanks in advance,
Alan Swanson

#simulate data#
d_vec <- -25:25; n <- length(d_vec)
simdata <- 
data.frame(treatment=factor(rep(1:3,rep(n*3,3))),dist=rep(d_vec,9),rep=factor(rep(1:9,n)))
t1_mean <- .002*d_vec^2+.00005*d_vec^3
t2_mean <- .002*d_vec^2+.00007*d_vec^3+1
t3_mean <- .002*d_vec^2+.00009*d_vec^3+2
plot(t3_mean~d_vec,type="l");lines(t2_mean~d_vec,lty=2);lines(t1_mean~d_vec,lty=3)
simdata$response <- 
c(rep(t1_mean,3),rep(t2_mean,3),rep(t3_mean,3))+rep(rnorm(9,0,10),rep(n,9))+rnorm(nrow(simdata),0,20)

#fit gamm models with fixed df#
require(mgcv)
m0_fixed<-gamm(response~s(dist, fx = T, k = 4, bs = 
"cr"),random=list(rep=~1),data=simdata)
m1_fixed<-gamm(response~treatment + s(dist,by=treatment,fx = T, k = 4, 
bs = "cr"),random=list(rep=~1),data=simdata)

#fit gamm models with penalized cubic regression splines.
m0_pen<-gamm(response~s(dist, fx = F, k = -1, bs = 
"cr"),random=list(rep=~1),data=simdata)
m1_pen<-gamm(response~treatment + s(dist,by=treatment,fx = F, k = -1, bs 
= "cr"),random=list(rep=~1),data=simdata)

#likelihood ratio tests
print(anova(m0_fixed$lme,m1_fixed$lme))
print(anova(m0_pen$lme,m1_pen$lme))



 > sessionInfo()
R version 2.11.1 (2010-05-31)
i386-pc-mingw32

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices datasets  utils     methods   base

other attached packages:
[1] mgcv_1.6-2    nlme_3.1-96   RWinEdt_1.8-2

loaded via a namespace (and not attached):
[1] grid_2.11.1        lattice_0.18-8     Matrix_0.999375-40



From roberto.patuelli at usi.ch  Wed Jun 23 12:44:47 2010
From: roberto.patuelli at usi.ch (Roberto Patuelli)
Date: Wed, 23 Jun 2010 12:44:47 +0200
Subject: [R-sig-ME] Standard errors or t values from glmm.admb
References: <mailman.3.1274349602.23867.r-sig-mixed-models@r-project.org><E1EAD31D792D446BA52639D52BE2CA71@Ciretto>
	<AANLkTimVglKCTxevXXDOTG_P5ghEhBKxLRvotsbqBclX@mail.gmail.com>
Message-ID: <F93DBE61C0774B3CA6A3DB91F122E71D@Ciretto>

Dear Paul,

Thanks a lot for the "dedication" in investigating the function. Indeed, I 
should have looked more carefully at the attributes of the regression 
object. This is also confirmed to me off-list by Dave Fournier, who works 
for ADMB. So at least standard errors are not a problem, as well as probably 
t-values. P-values are a different story of course...

I'll run the model again (it takes 12 hours) and see if everything hidden 
looks fine.

Cheers
Roberto


----- Original Message ----- 
From: "Paul Johnson" <pauljohn32 at gmail.com>
To: "Patuelli Roberto" <roberto.patuelli at usi.ch>; 
"R-SIG-Mixed-Models at r-project.org" <r-sig-mixed-models at r-project.org>
Sent: Tuesday, June 22, 2010 9:24 PM
Subject: Re: [R-sig-ME] Standard errors or t values from glmm.admb


On Tue, Jun 22, 2010 at 3:42 AM, Roberto Patuelli
<roberto.patuelli at usi.ch> wrote:
> Dear All,
>
> I have experimented with estimating a negative binomial mixed model 
> through
> the glmmADMB package (that is, using the glmm.admb function).
> After an entire night of computing :) I have results (though with a 
> warning
> message saying that proper convergence could not be reached). But when I 
> use
> summary.glmm.admb, I can only see, with regard to the fixed effects, the
> betas estimates, but no standard errors or other measures regarding the
> precision of the regression coefficients. See below:

I've not tried glmmADMB before, but I went and found it at
http://otter-rsch.com/admbre/examples/glmmadmb/glmmADMB.html.

I agree, this is lacking some creature comforts, summary is not
exhaustive, vcov() is not implemented.  Appears no way to get the
Hessian out of it.  So, well, I agree this would be a frustrating user
experience.

Here's where being old helps. :)  I went old school on it!

Suppose your output object is ad1, run

attributes(ad1),

I see:

> attributes(ad1)
$names
 [1] "n"             "q"             "fixed"         "call"
 [5] "group"         "family"        "corStruct"     "impSamp"
 [9] "easyFlag"      "zeroInflation" "b"             "stdbeta"
[13] "alpha"         "sd_alpha"      "S"             "sd_S"
[17] "random"        "U"             "sd_U"          "fitted"
[21] "residuals"     "npar"          "loglik"        "gradloglik"

$class
[1] "glmm.admb"

I wondered if ad1$stdbeta might give me what you want.  From the name,
it appears promising.

You'd need to run some model in some program that we trust, like
"lmer", and see if the values match up.  Without documentation from
the ADMB folks, its hard to guess.

## Create your own t values for the fixed effects.
> ad1$b/ad1$stdbeta
      (Intercept)              Base      trtprogabide               Age
        -1.129856          6.759541         -2.328344          1.374022
            Visit Base:trtprogabide
        -1.619971          1.665581

Now, I wonder if that is the correct number. You can read the code if
you do this (this used to work for almost all R commands, still works
for many). Read down a ways to find "stdbeta"


> glmm.admb
function (fixed, random, group, data, family = "poisson", link,
    corStruct = "diag", impSamp = 0, easyFlag = TRUE, zeroInflation = FALSE,
    imaxfn = 10, save.dir = NULL, offset)
{
    olddir <- getwd()
    dirname <- ifelse(is.null(save.dir), "_glmm_ADMB_temp_dir_",
        save.dir)
    dir.create(dirname)
    setwd(dirname)
    if (is.null(save.dir))
        on.exit(unlink(dirname, recursive = TRUE))
    call <- match.call()
    if (!(corStruct == "diag" | corStruct == "full"))
        stop("Argument \"corStruct\" must be either \"diag\" or \"full\"")
    if (!(family == "poisson" | family == "nbinom" | family ==
        "binomial"))
        stop("Argument \"family\" must be either \"poisson\",
\"binomial\"  or \"nbinom\"")
    if (missing(random) & ((!missing(impSamp)) | (!missing(corStruct))))
        stop("When \"random\" is missing neither of \"impSamp\" or
\"corStruct\" make sense")
    if (missing(group) || (!(is.character(group) & (length(group) ==
        1))) || !member(group, names(data)))
        stop("Argument \"group\" must be a character string spesifying
the name of the grouping variable (also when \"random\" is missing)")
    if (missing(link) & family == "binomial")
        stop("Argument \"link\" must be provided for the \"binomial\" 
family)")
    if ((!missing(offset)) && ((!is.character(offset)) || (length(offset) !=
        1) || !member(offset, names(data))))
        stop("An error occured in relatation to the argument
\"offset\". It must be a character string spesifying of the variable
holding the offset")
    if (!missing(offset))
        Offset = data[[offset]]
    else Offset = rep(0, nrow(data))
    tmpu <- table(data[[group]])
    tmpu[] <- 1:length(tmpu)
    tmpI <- tmpu[as.character(data[[group]])]
    data <- data[order(tmpI), ]
    n <- nrow(data)
    y <- data[[as.character(fixed[2])]]
    X <- model.matrix(fixed, data)
    p <- ncol(X)
    II <- as.numeric(tmpu[as.character(data[[group]])])
    group_d <- c(1, (2:n)[diff(II) == 1], n + 1)
    if (missing(random))
        Z <- model.matrix(~1, data)
    else Z <- model.matrix(random, data)
    m <- ncol(Z)
    q <- length(unique(II))
    cmdoptions = paste("-maxfn 500", ifelse(impSamp == 0, "",
        paste("-is", impSamp)))
    dat_list = list(n = n, y = y, p = p, X = X, q = q, m = m,
        Z = Z, group_d = group_d, II = II, cor_flag = ifelse(corStruct ==
            "full", 1, 0), like_type_flag = as.numeric(family ==
            "poisson" || ((family == "binomial") && (link ==
            "logit"))), no_rand_flag = as.numeric(missing(random)),
        easy_flag = as.numeric(easyFlag), zi_flag = 
as.numeric(zeroInflation),
        intermediate_maxfn = 10, offset = Offset)
    pin_list = list(pz = ifelse(zeroInflation, 0.02, 1e-04),
        b = numeric(p), tmpL = 0.25 + numeric(m), tmpL1 = 1e-04 +
            numeric(m * (m - 1)/2), logalpha = 2, kkludge = 0,
        u = matrix(numeric(q * m), q, m))
    if (family == "binomial") {
        if (!all(member(y, 0:1)))
            stop("Only Bernoulli responce (0 or 1) allowed currently")
        file_name = "bvprobit"
        dat_list = dat_list[c("n", "y", "p", "X", "q", "m", "Z",
            "group_d", "cor_flag", "like_type_flag", "no_rand_flag")]
        pin_list = pin_list[c("b", "tmpL", "tmpL1", "kkludge",
            "u")]
    }
    else {
        file_name = "nbmm"
        dat_list = dat_list[c("n", "y", "p", "X", "q", "m", "Z",
            "II", "cor_flag", "easy_flag", "zi_flag", "like_type_flag",
            "no_rand_flag", "intermediate_maxfn", "offset")]
        pin_list = pin_list[c("pz", "b", "tmpL", "tmpL1", "logalpha",
            "kkludge", "u")]
        if (!missing(link))
            warning("Argument \"link\" ignored for other familes than
\"binomial\" (exponential link used)")
    }
    dat_write(file_name, dat_list)
    pin_write(file_name, pin_list)
    std_file = paste(file_name, ".std", sep = "")
    file.remove(std_file)
    if (.Platform$OS.type == "windows") {
        shell(paste(.path.package("glmmADMB"), "/admb/", file_name,
            ".exe", " ", cmdoptions, sep = ""), invisible = TRUE)
    }
    else {
        system(paste("cp ", .path.package("glmmADMB"), "/admb/",
            file_name, " .", sep = ""))
        system(paste("./", file_name, " ", cmdoptions, sep = ""))
        unlink(file_name)
    }
    if (!file.exists(std_file))
        stop("The function maximizer failed")
    tmp <- read.table(paste(file_name, ".std", sep = ""), skip = 1)
    tmpindex <- as.character(tmp[, 2])
    out <- list(n = n, q = q, fixed = fixed, call = call, group = group,
        family = family, corStruct = corStruct, impSamp = impSamp,
        easyFlag = easyFlag, zeroInflation = zeroInflation)
    if (zeroInflation)
        out$pz = as.numeric(tmp[tmpindex == "pz", 3])
    out$b = as.numeric(tmp[tmpindex == "real_b", 3])
    names(out$b) = colnames(X)
    out$stdbeta = as.numeric(tmp[tmpindex == "real_b", 4])
    names(out$stdbeta) = colnames(X)
    if (family == "nbinom") {
        out$alpha <- as.numeric(tmp[tmpindex == "alpha", 3])
        out$sd_alpha <- as.numeric(tmp[tmpindex == "alpha", 3])
    }
    if (!missing(random)) {
        out$S = matrix(as.numeric(tmp[tmpindex == "S", 3]), nrow = m,
            dimnames = list(colnames(Z), colnames(Z)))
        out$sd_S = matrix(as.numeric(tmp[tmpindex == "S", 4]),
            nrow = m, dimnames = list(colnames(Z), colnames(Z)))
        if (corStruct == "diag") {
            out$S[below(m, TRUE) | t(below(m, TRUE))] = 0
            out$sd_S[below(m, TRUE) | t(below(m, TRUE))] = 0
        }
        out$random = random
    }
    if (!missing(link))
        out$link = link
    if (!missing(random)) {
        U = matrix(as.numeric(tmp[tmpindex == "u", 3]), ncol = m,
            byrow = TRUE, dimnames = list(data[, group][group_d[-1] -
                1], colnames(Z)))
        out$U = U
        out$sd_U = matrix(as.numeric(tmp[tmpindex == "u", 4]),
            ncol = m, byrow = TRUE, dimnames = list(data[, 
group][group_d[-1] -
                1], colnames(Z)))
    }
    else U = matrix(rep(0, q), ncol = 1, byrow = TRUE)
    mu <- as.numeric(X %*% out$b)
    lambda <- 0
    for (i in 1:n) lambda[i] <- exp(mu[i] + sum(Z[i, ] * U[II[i],
        ]))
    if (family == "binomial")
        out$fitted <- lambda/(1 + lambda)
    else out$fitted <- lambda
    tmpsd <- switch(family, poisson = sqrt(lambda), nbinom = sqrt(lambda *
        (1 + lambda/out$alpha)), binomial = sqrt(out$fitted *
        (1 - out$fitted)))
    out$residuals <- as.numeric(y - lambda)/tmpsd
    tmp = par_read(file_name)
    out$npar <- as.numeric(scan(paste(file_name, ".par", sep = ""),
        what = "", quiet = TRUE)[6])
    out$loglik = tmp$loglik
    out$gradloglik = tmp$gradient
    if (abs(out$gradloglik) >= 0.001)
        warning("Proper convergence could not be reached")
    setwd(olddir)
    class(out) <- "glmm.admb"
    return(out)
}

It doesn't tell us exactly what stdbeta represents, but it is still 
interesting.

I'm able to see that this routine does not actually do calculations,
rather it calls a separate program that ADMB installed in your R lib
folder, "admb.exe" or "admb" depending on your OS.  This writes
commands to a file, runs that external program, writes the output into
a temp file.  I suppose I would not go further to deconstruct the ADMB
software to see what they mean, since they have claimed it is secret
in the past.

Well, that's all I can do.  But it does remind me of the dangers of
using packages that don't exist in CRAN and aren't exactly "open
source". You probably need to directly contact the owners....

-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas



From teplitsky at mnhn.fr  Wed Jun 23 17:07:29 2010
From: teplitsky at mnhn.fr (Celine Teplitsky)
Date: Wed, 23 Jun 2010 15:07:29 -0000
Subject: [R-sig-ME] random regression with MCMCglmm
Message-ID: <4A40EF96.7070900@mnhn.fr>

Dear all,

I would like to fit a random regression using MCMCglmm. The problem is I 
don't manage to include heterogeneous residual variance (when I use just 
one residual variance the model is running). I have created a factor 
(Cat) grouping the environments into 4 food qualities from good to bad, 
so the model looks like:
priorA<-list(G=list(G1=list(V=diag(2), n=2)),R=list(V=diag(4), n= 2))

MCMCglmm(LD ~ Age+stFood , random=~us(1+st2Food):ID, rcov = 
~us(Cat):units, data=Data,prior=priorA, family = 
c("gaussian"),nitt=120000, burnin=20000, thin=100)

but I get this error message, and I really don't know how to fix the 
problem:

Error in `[.data.frame`(data, , components[[1]]) :
   undefined columns selected

Many thanks in advance for any help

Celine

-- 

Celine Teplitsky
D?partement Ecologie et Gestion de la Biodiversit? UMR 7204
Unit? Conservation des Esp?ces, Restauration et Suivi des Populations
Case Postale 51
55 rue Buffon 75005 Paris

Webpage : http://www2.mnhn.fr/cersp/spip.php?rubrique96
Fax : (33-1)-4079-3835
Phone: (33-1)-4079-3443



From bates at stat.wisc.edu  Wed Jun 23 17:36:38 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 23 Jun 2010 10:36:38 -0500
Subject: [R-sig-ME] Computational speed - MCMCglmm/lmer
In-Reply-To: <AANLkTimm7BPOARDPXgW_mTHNngu_sbKjPPgVlS6FSqQf@mail.gmail.com>
References: <4C1CE581.9030205@u.washington.edu>
	<AANLkTimm7BPOARDPXgW_mTHNngu_sbKjPPgVlS6FSqQf@mail.gmail.com>
Message-ID: <AANLkTim89W3S3AN2qSc2wK1PzGvUxmgLZIZ-gFfaJK8i@mail.gmail.com>

On Tue, Jun 22, 2010 at 3:06 PM, Paul Johnson <pauljohn32 at gmail.com> wrote:
> On Sat, Jun 19, 2010 at 10:42 AM, David Atkins <datkins at u.washington.edu> wrote:
>>
>> Hi all--
>>
>> I use (g)lmer and MCMCglmm on a weekly basis, and I am wondering about
>> options for speeding up their computations. ?This is primarily an issue with
>> MCMCglmm, given the many necessary MCMC iterations to get to convergence on
>> some problems. ?But, even with glmer(), I have runs that get into 20-30
>> minutes.
>>
>> 3. "Optimized" BLAS: There's a bit of discussion about optimized BLAS (basis
>> linear algebra... something). ?However, these discussions note that there is
>> no generally superior BLAS. ?Not sure whether specific BLAS might be
>> optimized for GLMM computations.
>>
>> 4. Parallel computing: With multi-core computers, looks like there are some
>> avenues for splitting intensive computations across processors.
>
> Hi, Dave:
>
> I've wondered this same thing. I replaced the base R BLAS with
> GOTOBLAS2 and ATLAS and both are much faster than R's base BLAS. ?In
> Gotoblas2, computation is about 10 x faster on linear algebra
> problems, especially on the kinds of problems where it can ?thread
> computations across all cores. ?The BLAS library from Atlas does not
> seem to thread, so it is not quite so fast.
>
> In either case, I've tested your example on this Lenovo T61 laptop
> with dual core Pentium that maxes out at 2.4GHz,
>
> To calculate your model with the base R BLAS:
>
> drk.glmer
>
> ?user ?system elapsed
> ?29.920 ? 0.120 ?30.245
>
>
> The time elapsed with the optimized BLAS is not so much faster as I
> had expected. With Atlas it is:
>
> ? user ?system elapsed
> ?25.660 ? 0.100 ?25.784
>
> Gotoblas2 is almost identical, I'm quite surprised. ?On other tests
> I've done, it supplies a more noticeable speedup because it can go
> multi core when needed. ?I was monitoring the CPU and the calculations
> all stay on one core.
>
> ? user ?system elapsed
> ?25.670 ? 0.050 ?25.725
>
> Well, if you use Atlas or GOTOBLAS2, you can expect a speedup of about 1/6th.

On this particular model/data set combination.  Accelarated BLAS
change the speed of low-level numerical linear algebra operations, the
so-called basic linear algebra subroutines.  If those are the
bottleneck in your calculation you will see a performance boost.  If
it is not, you won't.

Accelerated BLAS are not a panacea.  Neither is parallel computation.
When your computation if essentially single-threaded, as an
optimization like this is, it doesn't matter if you have one core or
twelve.

The basic rule of optimizing performance of programs is to profile
*before* you make changes.  Making great efforts to optimize an
operation that takes only 5% of the execution time will provide you
with at most a 5% gain in performance.

> I made the mistake of running that example with MCMCglmm in your code.
> ?The system is locked in mortal combat with that. ?I didn't notice
> your time was 1208. before I started that one. ?:(

Forgive me for sounding grouchy but I find this whole discussion
misguided.  Worrying about the speed of fitting a model and niceties
of the model formulation before doing elementary checks on the data is
putting the cart before the horse.  Why is gender coded as 0, 1 and 2?
 Why, when there was a maximum of 90 days of monitoring, is there one
id with 435 observations and another with 180 observations.  Did
someone really have 45 drinks in one day and, if so, are they still
alive?  Accelerated BLAS and parallel algorithms are way, way down the
list of issues that should be addressed.



From hadley at rice.edu  Wed Jun 23 18:47:11 2010
From: hadley at rice.edu (Hadley Wickham)
Date: Wed, 23 Jun 2010 11:47:11 -0500
Subject: [R-sig-ME] Computational speed - MCMCglmm/lmer
In-Reply-To: <AANLkTim89W3S3AN2qSc2wK1PzGvUxmgLZIZ-gFfaJK8i@mail.gmail.com>
References: <4C1CE581.9030205@u.washington.edu>
	<AANLkTimm7BPOARDPXgW_mTHNngu_sbKjPPgVlS6FSqQf@mail.gmail.com> 
	<AANLkTim89W3S3AN2qSc2wK1PzGvUxmgLZIZ-gFfaJK8i@mail.gmail.com>
Message-ID: <AANLkTimZMBFRXKD9g1k_bxiEewv4Cuik9gNBFZrUr7ns@mail.gmail.com>

> Forgive me for sounding grouchy but I find this whole discussion
> misguided. ?Worrying about the speed of fitting a model and niceties
> of the model formulation before doing elementary checks on the data is
> putting the cart before the horse. ?Why is gender coded as 0, 1 and 2?
> ?Why, when there was a maximum of 90 days of monitoring, is there one
> id with 435 observations and another with 180 observations.

Especially when you look at (e.g.) subset(drink.df, id == 8396125) and
notice that drinks appear to be repeated in blocks of five.  Looks
like a data processing error - but has it also happened for other
subject?

I also wonder why the date has been removed from the data. It seems
like this would be an important covariate (St Patrick's day, match
days, birthdays, ...).  And I hope weekday isn't Monday-Friday...

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/



From otter at otter-rsch.com  Wed Jun 23 11:15:20 2010
From: otter at otter-rsch.com (dave fournier)
Date: Wed, 23 Jun 2010 05:15:20 -0400
Subject: [R-sig-ME] Standard errors or t values from glmm.admb
In-Reply-To: <F93DBE61C0774B3CA6A3DB91F122E71D@Ciretto>
References: <F93DBE61C0774B3CA6A3DB91F122E71D@Ciretto>
Message-ID: <4C21D0A8.70602@otter-rsch.com>


  Actually AD Model Builder has been freely available and
  open source for some time.

      http://admb-project.org

  But the easiest way to see everything
  is to run glmmADMB with the option of keeping the temporary files
  and then using the ADMB documentation to interpret these files.
  There are a lot of interesting options that are not available
  using the R interface. However first running the model in R is
  useful to create the model matrix etc in a way familiar to r
  users.



From bates at stat.wisc.edu  Thu Jun 24 00:13:25 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 23 Jun 2010 17:13:25 -0500
Subject: [R-sig-ME] Data Redux -- Re: Computational speed - MCMCglmm/lmer
In-Reply-To: <AANLkTimGL8N1nsaSJd8nbga5iqGeVtorcebX4vTSb_eb@mail.gmail.com>
References: <4C1CE581.9030205@u.washington.edu>
	<AANLkTimm7BPOARDPXgW_mTHNngu_sbKjPPgVlS6FSqQf@mail.gmail.com>
	<AANLkTim89W3S3AN2qSc2wK1PzGvUxmgLZIZ-gFfaJK8i@mail.gmail.com>
	<AANLkTimZMBFRXKD9g1k_bxiEewv4Cuik9gNBFZrUr7ns@mail.gmail.com>
	<4C225535.30505@u.washington.edu>
	<AANLkTimGL8N1nsaSJd8nbga5iqGeVtorcebX4vTSb_eb@mail.gmail.com>
Message-ID: <AANLkTinnELwi2CVvniEpwbXVXoR9I2jb22Qiiein6NcD@mail.gmail.com>

Thanks for sending the cleaned up version of the data, Dave.

First, it seems to me that the model should include the fratsor
variable and perhaps an interaction with gender. ?This will make it
difficult to fit (because it has even more fixed-effects parameters)
and I would suggest replacing weekday by a factor with three levels
"Sun-Wed", "Thu" and "Fri-Sat". ?See the enclosed plot for why I would
suggest that. ?Alternatively you could consider a binary variable of
Sun-Wed and Thu-Sat.
There definitely does seem to be a peak at Friday, especially in the
Frat/Sor group and a drop-off to Saturday. ?Interestingly Thursday
seems to have heavier consumption by the Frat/Sor group than Saturday
(I was wondering why attendance seems a little thin for my 8:00 a.m.
Intro Engineering Statistics class on Fridays).

Second, there is a good news/bad news situation regarding the
development version of glmer. ?I have introduced a coarser method of
getting estimates selected with the optional argument nAGQ = 0. ?It is
more complicated to explain than I would like to embark on here but
suffice to say it is much faster and gets good estimates but not
the best. ?At this point the output will look suspicious because I needed to
turn off the system.time in the batch run, probably because of a
memory protection issue that I will need to resolve.

Timing this fit works interactively for me but not in a batch run

> system.time(
+ drk0.glmer <- glmer(drinks ~ weekday*gender + (1 | id),
+ ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?data = drink.df, family = poisson,
+ ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?verbose = TRUE, nAGQ=0L)
+ )
npt = 3 , n = ?1
rhobeg = ?0.2 , rhoend = ?2e-07
? 0.020: ? 3: ? ? ?146545.; 1.00000
?0.0020: ? 3: ? ? ?146545.; 1.00000
?0.00020: ?10: ? ? ?146543.;0.960752
?2.0e-05: ?12: ? ? ?146543.;0.960984
?2.0e-06: ?15: ? ? ?146543.;0.960974
?2.0e-07: ?15: ? ? ?146543.;0.960974
At return
?17: ? ? 146542.78: 0.960974
? user ?system elapsed
?16.870 ? 0.080 ?17.029

So 17 seconds elapsed time is pretty good. ?The full Laplacian fit
took about 300 seconds and gave only a slightly better deviance.
Regrettably I have seen situations where the full Laplacian fit is
considerably better so I can't recommend avoiding the full Laplacian
fit entirely. ?I do think that the fit with nAGQ = 0 is okay for coarse model
building where you need rough comparisons of several different models.


On Wed, Jun 23, 2010 at 1:40 PM, David Atkins <datkins at u.washington.edu> wrote:
>
> First, my apologies for not providing clean data in my initial posting,
> which was clearly an oversight on my part. ?I have an email in to the PI but
> haven't gotten a response yet.
>
> I have attached an updated dataset, that pulls out the 2 suspect
> participants as well as those with gender coded 2. ?In addition, it includes
> two more variables:
>
> weekday - 7 level factor for day of week (new variable weekend now has the
> binary version)
> fratsor - a binary factor indicating whether individual is part of a
> fraternity or sorority (or not)
>
> I have an updated script below that shows (descriptively) how drinking
> varies over these factors. ?Moreover, including weekday as either fixed or
> random, really ratchets up the time for glmer. ?Again, my original purpose
> is definitely *not* to criticize lme4 (or Doug), but simply to get some
> feedback about computational speed, and whether or not it's possible to
> speed up runs via hardware, OS, or software.
>
> Finally, in providing some data, I was trying to provide a brief subset of
> data that has certain realistic qualities (and it is real data) but is not a
> "full" data set. ?In trying to be simple and straightforward, I may have
> raised more questions.
>
> So, in response to a few questions raised:
>
> The data come from a study of problematic drinking focused on high-risk
> events, and this particular data focused on 21st birthdays (here in the US,
> that is the legal drinking age). ?The present data are from a survey (ie,
> non-intervention), which then informed a later intervention study. ?Thus,
> the (up to) 90 days of retrospective drinking, will cover the individual's
> 21st birthday.
>
> Doug asks about someone reporting 45 drinks. ?Because we are capturing 21st
> birthdays, we are definitely getting some extreme drinking, but we also are
> relying on self-report. ?Clearly, there will be some errors and possible
> bravado about feats of drinking. ?Moreover, the study has a protocol for
> addressing potentially dangerous levels of drinking with participants (when
> blood-alcohol content passes a certain cutoff).
>
> Hadley asks about the repeated data. ?Part of the study involves friends of
> the main participant (as one intervention condition includes friends input
> as part of the intervention). ?Some of the friend's data were included in a
> larger version of this dataset, which then led to replicates of the
> participant's data. ?Thus, we knew individuals with friend's data had
> replicates, but this version was supposed to have that cleaned up.
>
> Finally, this particular data was collected on a rolling basis, and thus the
> 90 day recounting of drinking covers a large swath of the calendar year. ?We
> are currently working on a paper that examines student drinking on typical
> weekdays vs. weekends vs. 21st birthday vs. holidays (including St.
> Patrick's Day, though July 4th and New Year's Eve are much heavier drinking
> days...).
>
> Hopefully this clarifies certain aspects of the data, and I definitely
> appreciate folks input on the computational aspects -- I'm certainly
> learning.
>
> [BTW, I'm currently fitting a second model to the one reported below, with a
> random effect for weekday -- currently at 30 minutes and counting.]
-------------- next part --------------

R version 2.11.1 (2010-05-31)
Copyright (C) 2010 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #
> ### read in *updated* drinking data
> drink.df <- within(read.delim("~/tests/drinksUPDATED.txt"), id <- factor(id))
> str(drink.df) # 57K rows
'data.frame':	56199 obs. of  6 variables:
 $ id     : Factor w/ 980 levels "1014503","1017782",..: 1 1 1 2 2 2 2 2 2 2 ...
 $ gender : Factor w/ 2 levels "F","M": 1 1 1 2 2 2 2 2 2 2 ...
 $ fratsor: Factor w/ 2 levels "Frat/Sor","Not Frat/Sor": 2 2 2 2 2 2 2 2 2 2 ...
 $ weekday: Factor w/ 7 levels "Friday   ","Monday   ",..: 4 3 1 4 3 1 5 7 6 2 ...
 $ weekend: Factor w/ 2 levels "Weekday","Weekend": 1 2 2 1 2 2 1 1 1 1 ...
 $ drinks : int  0 0 5 8 5 10 0 0 0 0 ...
> 
> ### NOTE: slight variable changes since last iteration
> ### id is id variable (shocking)
> ### gender is binary factor
> ### fratsor is binary factor (in fraternity or sorority vs. not)
> ### weekday now has day of week
> ### weekend is now weekday (Sun - Thurs) vs. weekend (Fri - Sat)
> ### drinks has number of drinks consumed
> 
> ### trim trailing white spaces
> levels(drink.df$weekday) <- sub('[[:space:]]+$', '', levels(drink.df$weekday))
> ### re-order factor
> drink.df <- within(drink.df,
+                    weekday <- factor(weekday, levels = levels(weekday)[c(4,2,6,7,5,1,3)]))
> summary(drink.df)
       id        gender            fratsor           weekday    
 1028078:   90   F:31599   Frat/Sor    :11639   Sunday   :8112  
 1325095:   90   M:24600   Not Frat/Sor:44560   Monday   :7999  
 1365806:   90                                  Tuesday  :7949  
 1411092:   90                                  Wednesday:7903  
 1472245:   90                                  Thursday :7928  
 1518480:   90                                  Friday   :8091  
 (Other):55659                                  Saturday :8217  
    weekend          drinks      
 Weekday:39891   Min.   : 0.000  
 Weekend:16308   1st Qu.: 0.000  
                 Median : 0.000  
                 Mean   : 1.001  
                 3rd Qu.: 0.000  
                 Max.   :45.000  
                                 
> 
> ### distribution of outcome
> table(drink.df$drinks)

    0     1     2     3     4     5     6     7     8     9    10    11    12 
44818  1787  1831  1482  1337  1261   864   495   673   189   634    44   248 
   13    14    15    16    17    18    19    20    21    22    23    24    25 
   46    61   183    44    19    45     4    39    28    15     8    13    13 
   26    27    28    30    32    34    45 
    3     2     3     7     1     1     1 
> plot(table(drink.df$drinks), lwd=2) # zero-inflated
> 
> ### how many people?
> length(unique(drink.df$id)) # 980
[1] 980
> sort(table(drink.df$id)) # max of 90 drinks

1319941 4212130 8015105 8603120 9835536 2875902 5283938 6538318 1014503 1275277 
      1       1       1       1       1       2       2       2       3       3 
2973838 3817648 3852450 5023034 6086263 6659737 7921706 9844380 1236528 1399161 
      3       3       3       3       3       3       3       3       4       4 
1407847 1420474 1958097 2041854 2077901 2085569 2263898 2278280 2324119 2361365 
      4       4       4       4       4       4       4       4       4       4 
2491080 2643739 2781746 2845433 2971385 3015995 3496488 3559269 3728091 4393986 
      4       4       4       4       4       4       4       4       4       4 
4591080 4837581 5014416 5049844 5590582 5961753 6333650 6463057 6488182 6539097 
      4       4       4       4       4       4       4       4       4       4 
6659123 6890432 6962360 6993756 7980552 8096007 8613583 8812345 8891232 9416540 
      4       4       4       4       4       4       4       4       4       4 
9434405 9525137 9876487 9877492 9921013 1189810 1388664 1527755 1839258 2113919 
      4       4       4       4       4       5       5       5       5       5 
2319518 2369091 2525656 2544519 2619796 3103486 3231339 3391214 3825014 3854175 
      5       5       5       5       5       5       5       5       5       5 
3896152 3914774 4030284 4050701 4316326 4460349 4830580 5098079 5204524 5372808 
      5       5       5       5       5       5       5       5       5       5 
5548610 5731826 6254008 6255413 6536013 6611692 6863222 7201642 7590309 8155947 
      5       5       5       5       5       5       5       5       5       5 
8843022 9343822 1344463 1616364 2101965 2737711 3132946 3649336 4170641 4212525 
      5       5       6       6       6       6       6       6       6       6 
4326702 4532354 4591237 5303660 5827251 6216133 6480774 6575532 6711978 6833640 
      6       6       6       6       6       6       6       6       6       6 
7157691 7281220 8214282 8540069 9041756 9430688 9965510 1263864 1736059 2189596 
      6       6       6       6       6       6       6       7       7       7 
3773611 3838167 3949720 4393579 4865975 5530455 5534759 5777541 6352488 6952025 
      7       7       7       7       7       7       7       7       7       7 
7754746 7992618 8201208 8268278 8761577 1124709 1200968 1559244 1935294 2228747 
      7       7       7       7       7       8       8       8       8       8 
4737932 5095385 5622687 7172505 7458973 7631251 7887629 8075124 9516066 9939608 
      8       8       8       8       8       8       8       8       8       8 
1400561 2760380 4140447 5944406 6483868 6558815 7528954 8045277 8583302 9023183 
      9       9       9       9       9       9       9       9       9       9 
9179082 2334460 2681159 2881046 3013308 3503828 3559980 6144342 6603388 7380815 
      9      10      10      10      10      10      10      10      10      10 
7529009 7966676 8082059 8556613 8596599 8700467 1194733 1202025 1548596 1936396 
     10      10      10      10      10      10      11      11      11      11 
3371613 3523351 4722623 6658047 6847647 7663735 8430686 8944029 9971653 3001944 
     11      11      11      11      11      11      11      11      11      12 
3370505 3587272 5340980 7731005 8843600 9021560 9546257 1149205 4055666 5119167 
     12      12      12      12      12      12      12      13      13      13 
5251847 5878758 8226137 2738000 3240450 8933334 2035575 7284638 8515671 2318278 
     14      14      14      15      15      15      16      16      16      17 
3551696 5233134 7258209 4123960 6471323 8883864 1612271 2285751 2922474 3076020 
     17      17      17      18      18      18      19      19      19      19 
4234749 2624602 4977586 1283972 3026303 5024081 5270748 1432309 1726095 3499615 
     19      20      21      22      22      22      22      23      23      23 
3716970 4351947 4766409 6317417 7522203 7951118 1111222 3055242 1542736 3972120 
     23      23      23      23      23      23      24      24      25      25 
4245213 5695022 5330042 1017782 2904857 7572151 1565477 1824717 4411256 6400138 
     25      25      26      27      27      27      28      28      28      29 
8373776 2132369 4269915 7478885 9179169 6686464 8254827 8370884 8962932 9544612 
     29      30      30      30      30      31      31      31      31      31 
9816970 1049490 4668787 7494674 8037577 9587610 1740479 5538680 8354486 4931091 
     31      32      32      32      32      32      33      33      33      34 
7968119 9130847 4034626 5056981 5852393 8226859 2586445 2953918 6568163 6773971 
     34      34      35      35      35      35      36      36      36      36 
7391718 8039498 1084348 1334031 9529321 1119763 3607705 3767381 8228497 3063500 
     36      36      37      37      37      38      38      38      38      39 
6197215 7817663 8812679 1670770 2036242 3927226 9450062 9797059 2262819 2606374 
     39      39      39      40      40      40      40      40      41      41 
6810115 9522634 6761002 8335986 9218397 1701786 6012467 7285261 7390966 9700659 
     41      41      42      42      42      43      43      43      43      43 
1752166 5756629 7821357 8499519 9084692 9902893 7534646 7841156 8871670 3173554 
     44      44      44      44      44      44      45      45      45      46 
3618145 4903956 6812321 6814520 8973400 9565738 3012589 3790128 7234962 7978339 
     46      46      46      46      46      46      47      47      47      47 
8546289 1090548 2797750 4789463 6030867 6577914 6754613 8312313 6577580 2343179 
     47      48      48      48      48      48      48      48      49      50 
3791562 1153586 4898306 6724498 7420735 7716703 7732578 8418926 5261553 7593175 
     50      51      51      51      51      51      51      51      52      52 
7798623 1831240 2190753 3318244 4433082 6527360 1026066 4184204 4274077 2351479 
     52      53      53      53      53      53      54      54      54      55 
4588702 5685719 4941227 5591227 6006241 2392265 5869946 6243698 8961338 9642276 
     55      55      56      56      56      57      57      57      57      57 
2050263 2069149 5083578 6853929 8454287 8890689 8953595 2050221 2158552 3458758 
     58      58      58      58      58      58      58      59      59      59 
3522382 5641747 5997701 9128379 1182230 2413733 2535813 3331699 4339133 4450695 
     59      59      59      59      60      60      60      60      60      60 
6810803 7630900 7943059 8873348 9700900 2105448 3012259 3827576 7189737 8416507 
     60      60      60      60      60      61      61      61      61      61 
1317485 1505208 2350411 4620203 4736431 4963162 6055972 6264065 8842582 9207550 
     62      62      62      62      62      62      62      62      62      62 
9578508 9656757 9799794 2607767 4739249 5599093 1147135 1554725 2235706 2750601 
     62      62      62      63      63      63      64      64      64      64 
3128066 3294040 4641961 7142254 7840065 9200728 3371565 4107771 5887960 6314102 
     64      64      64      64      64      64      65      65      65      65 
7146040 9922543 2646375 2930620 4418596 4528211 4617143 6343663 7446665 1272677 
     65      65      66      66      66      66      66      66      66      67 
2399193 3553766 3629994 4010491 5711642 7452512 7650803 8553285 1117617 1301598 
     67      67      67      67      67      67      67      67      68      68 
1505319 2570427 2929328 3408926 4873580 5350307 5968724 7334474 7789100 9527960 
     68      68      68      68      68      68      68      68      68      68 
3387469 4024391 4595134 4609073 4945815 5356055 7299896 7737387 8961776 1766542 
     69      69      69      69      69      69      69      69      69      70 
1906887 5175402 5314655 6837568 6976189 7182350 8532893 3293350 7416680 8423955 
     70      70      70      70      70      70      70      71      71      71 
1384884 4514791 7229999 7270645 7456963 7742042 2678061 3647332 3733652 4747381 
     72      72      72      72      72      72      73      73      73      73 
4795840 5087112 5446166 6577484 6878267 8381261 8916650 9616935 1384034 1388948 
     73      73      73      73      73      73      73      73      74      74 
1399735 2340467 3023513 4921437 5553430 6350154 7718953 7741538 7918428 8039756 
     74      74      74      74      74      74      74      74      74      74 
8369132 8913920 2419425 2605267 2967863 3374000 3850222 4804293 5431687 6154621 
     74      74      75      75      75      75      75      75      75      75 
9772394 1996278 2152434 2397856 2841562 3129354 5241710 5692737 6032653 9587463 
     75      76      76      76      76      76      76      76      76      76 
2333659 2384771 3574470 4609920 5825759 6107071 6146448 7755304 9103794 9565154 
     77      77      77      77      77      77      77      77      77      77 
1861175 2690918 2854882 3106424 3416432 6336288 6507821 8357406 8519282 8702886 
     78      78      78      78      78      78      78      78      78      78 
9045606 9424169 9741259 1369777 1604781 2702553 3433746 3949484 4298020 4429340 
     78      78      78      79      79      79      79      79      79      79 
4661052 5377253 5476874 6223586 6605590 9784649 9991046 1041305 2768589 4199368 
     79      79      79      79      79      79      79      80      80      80 
4800597 5978910 6744147 8090873 8148478 8202008 9398903 9989437 1438856 2587909 
     80      80      80      80      80      80      80      80      81      81 
2777473 3045211 3283541 3413108 4049379 4184536 4633747 4704308 5106933 5136888 
     81      81      81      81      81      81      81      81      81      81 
6318117 7500044 8016393 8192947 9238014 9513072 9895677 1094090 2212851 3895865 
     81      81      81      81      81      81      81      82      82      82 
4620085 5709481 6081672 6183521 6307233 6427909 7275518 7768940 8117150 8292490 
     82      82      82      82      82      82      82      82      82      82 
8475230 8554640 8883466 9581589 1678506 2587475 3353997 3515965 4893926 4996850 
     82      82      82      82      83      83      83      83      83      83 
5250988 6544739 9373978 1382196 1890481 2669757 2864117 3178560 4389909 4578617 
     83      83      83      84      84      84      84      84      84      84 
4594967 4735247 4943866 5884100 6100969 7945975 8328398 8498254 8932468 9260484 
     84      84      84      84      84      84      84      84      84      84 
9326824 9413535 9465826 9668847 9728227 9735231 9753192 1036230 1051413 1260586 
     84      84      84      84      84      84      84      85      85      85 
1305494 1414681 1767157 2120749 2482707 2485802 3018266 3101640 3160683 3286662 
     85      85      85      85      85      85      85      85      85      85 
3353992 3548288 3926161 3935922 3986444 4687346 4784436 4806947 4890780 5210585 
     85      85      85      85      85      85      85      85      85      85 
5698410 5869573 5880239 6388293 6389512 6415510 6746544 6926473 6933118 7359086 
     85      85      85      85      85      85      85      85      85      85 
8275585 8716706 8968760 9240111 9710092 1231849 1621401 1923000 2200655 2421711 
     85      85      85      85      85      86      86      86      86      86 
2587227 2853104 2991236 3256411 3344508 3428038 3866174 3884389 4209867 4271676 
     86      86      86      86      86      86      86      86      86      86 
4425827 4774968 5042867 5239893 5591873 5724112 5857791 6015473 6158972 6176690 
     86      86      86      86      86      86      86      86      86      86 
6458602 6805254 7323564 7432112 7494869 7540968 7883047 8169294 8215045 8278127 
     86      86      86      86      86      86      86      86      86      86 
8600629 8877853 9033780 9266671 9312950 9438722 9510451 9619923 9810771 1055518 
     86      86      86      86      86      86      86      86      86      87 
1137483 1365297 1561984 1564925 1575328 1808816 1816247 2007755 2509906 2576361 
     87      87      87      87      87      87      87      87      87      87 
3261394 3325217 3343960 3381532 3443817 3783180 3787936 4284261 4345533 4488394 
     87      87      87      87      87      87      87      87      87      87 
4617546 4726620 4765320 4992047 5224005 5466615 5595838 6024689 6085143 6571288 
     87      87      87      87      87      87      87      87      87      87 
6587909 6684602 6708037 6877474 7206889 7243481 7288167 7459578 7468356 7659363 
     87      87      87      87      87      87      87      87      87      87 
7915938 8508927 8672882 8695411 8780163 8920438 9037135 9115186 9120269 9208791 
     87      87      87      87      87      87      87      87      87      87 
9220180 9354798 9366076 9437047 9542564 9657810 9981229 1097170 1457609 1692855 
     87      87      87      87      87      87      87      88      88      88 
1810902 2250326 2618792 2897495 3093021 3480548 3534464 3704884 3920567 3955444 
     88      88      88      88      88      88      88      88      88      88 
4059039 4433206 4611007 4839703 5041333 5068838 5084692 5134654 5201522 5222523 
     88      88      88      88      88      88      88      88      88      88 
5233868 5489568 5776328 5792758 5992977 6043463 6208455 6806650 6813814 6823221 
     88      88      88      88      88      88      88      88      88      88 
6936798 6981594 6985816 7039783 7547535 8123200 8145763 8312450 8316822 8701514 
     88      88      88      88      88      88      88      88      88      88 
9019769 9190078 9324488 9422387 9570269 9604624 1018311 1090450 1429568 1496511 
     88      88      88      88      88      88      89      89      89      89 
1528467 1678666 2145671 2363344 2405236 2442143 2960794 2963673 3088601 3121625 
     89      89      89      89      89      89      89      89      89      89 
3242908 3316233 3331169 3399691 3521621 3561331 3781407 3789272 3812146 3970715 
     89      89      89      89      89      89      89      89      89      89 
4243453 4536638 4665414 4847893 4902781 5145482 5296793 5969776 6781377 6835229 
     89      89      89      89      89      89      89      89      89      89 
6934677 6984514 7057236 7095917 7588390 7665148 7741332 7857601 7870097 8013659 
     89      89      89      89      89      89      89      89      89      89 
8040899 8578096 8690859 8743762 9002871 9011395 9076490 9135181 9187303 9737625 
     89      89      89      89      89      89      89      89      89      89 
1028078 1325095 1365806 1411092 1472245 1518480 1612755 1623484 1709091 1712310 
     90      90      90      90      90      90      90      90      90      90 
1717093 2006062 2197700 2274268 2312415 2317039 2340830 2371406 2373969 2562107 
     90      90      90      90      90      90      90      90      90      90 
2740118 2776673 2928270 2929024 3001617 3121973 3337422 3425845 3520950 3637606 
     90      90      90      90      90      90      90      90      90      90 
3690177 3740782 4180489 4253149 4518861 4571593 4864922 4914398 5051738 5060642 
     90      90      90      90      90      90      90      90      90      90 
5276247 5558779 5575437 5878137 6074463 6178916 6293584 6352030 6384195 6625594 
     90      90      90      90      90      90      90      90      90      90 
6978483 7046422 7231071 7231469 7396509 7435632 7515183 7746665 7875916 7879710 
     90      90      90      90      90      90      90      90      90      90 
7905511 7923832 8268380 8310625 8419023 8539279 8654166 8704823 9073782 9182202 
     90      90      90      90      90      90      90      90      90      90 
9214537 9237022 9281036 9319098 9335478 9590420 9614550 9782207 9799571 9809027 
     90      90      90      90      90      90      90      90      90      90 
> 
> ### how do drinks vary across days of week and also gender and fratsor?
> #
> with(drink.df, tapply(drinks, list(gender, fratsor), mean))
   Frat/Sor Not Frat/Sor
F 0.9248277    0.6265573
M 2.3757664    1.0561690
> ### not surprising, but men in fraternities drink notably more
> 
> with(drink.df, tapply(drinks, list(gender, weekday, fratsor), mean))
, , Frat/Sor

     Sunday    Monday   Tuesday Wednesday Thursday   Friday Saturday
F 0.4729136 0.5565476 0.6992593 0.6315007 1.300872 1.583691 1.191702
M 1.0111336 1.6358025 1.7236705 1.7907950 3.285861 4.103518 3.017928

, , Not Frat/Sor

     Sunday    Monday   Tuesday Wednesday  Thursday   Friday Saturday
F 0.3888029 0.3678161 0.3602419 0.3539073 0.5484897 1.189956 1.159294
M 0.4557505 0.5734072 0.4944268 0.5014006 0.9024096 2.311668 2.106416

> ### general peak on friday and/or saturday, but differences in rest
> ### of week for fraternity/sorority crowd...
> 
> ### speed tests
> #
> ### fit random intercept and random slope for weekday
> ### fixed effects for gender and weekday and interaction
> #
> ### Poisson GLMM with glmer()
> library(lme4a)
Loading required package: Matrix
Loading required package: lattice

Attaching package: 'Matrix'

The following object(s) are masked from 'package:base':

    det

Loading required package: minqa
Loading required package: Rcpp

Attaching package: 'lme4a'

The following object(s) are masked from 'package:stats':

    AIC

> xyplot(drinks ~ as.integer(weekday)|fratsor, drink.df, groups = gender,
+        type = c("g","a"), ylim=c(-0.1, 5),
+        auto.key = list(columns = 2, points = FALSE, lines = TRUE))
> ### NOTE: weekday is different from last set of code; last time it was
> ###                     binary, this time it is 7 level factor
> #
> ### random intercept
> #system.time(
> drk0.glmer <- glmer(drinks ~ weekday*gender + (1 | id),
+                                        data = drink.df, family = poisson,
+                                        verbose = TRUE, nAGQ=0L)
npt = 3 , n =  1 
rhobeg =  0.2 , rhoend =  2e-07 
   0.020:   3:      146545.; 1.00000 
  0.0020:   3:      146545.; 1.00000 
 0.00020:  10:      146543.;0.960752 
 2.0e-05:  12:      146543.;0.960984 
 2.0e-06:  15:      146543.;0.960974 
 2.0e-07:  15:      146543.;0.960974 
At return
 17:     146542.78: 0.960974
> #)
> print(drk0.glmer, corr = FALSE)
Generalized linear mixed model fit by maximum likelihood ['merMod']
 Family: poisson 
Formula: drinks ~ weekday * gender + (1 | id) 
   Data: drink.df 
      AIC       BIC    logLik  deviance 
146572.78 146706.83 -73271.39 146542.78 

Random effects:
 Groups Name        Variance Std.Dev.
 id     (Intercept) 0.9235   0.961   
Number of obs: 56199, groups: id, 980

Fixed effects:
                         Estimate Std. Error z value
(Intercept)              -1.20139    0.04862  -24.71
weekdayMonday            -0.01034    0.03329   -0.31
weekdayTuesday            0.02582    0.03302    0.78
weekdayWednesday         -0.01160    0.03340   -0.35
weekdayThursday           0.50043    0.02975   16.82
weekdayFriday             1.12674    0.02690   41.89
weekdaySaturday           1.05958    0.02708   39.13
genderM                   0.29031    0.07098    4.09
weekdayMonday:genderM     0.36965    0.04358    8.48
weekdayTuesday:genderM    0.29549    0.04356    6.78
weekdayWednesday:genderM  0.36294    0.04376    8.29
weekdayThursday:genderM   0.45316    0.03912   11.58
weekdayFriday:genderM     0.40287    0.03586   11.24
weekdaySaturday:genderM   0.29769    0.03623    8.22
> 
> system.time(
+ drk.glmer <- glmer(drinks ~ weekday*gender + (1 | id),
+                    data = drink.df, family = poisson,
+                    verbose = TRUE)
+ )
npt = 3 , n =  1 
rhobeg =  0.2 , rhoend =  2e-07 
   0.020:   3:      146545.; 1.00000 
  0.0020:   3:      146545.; 1.00000 
 0.00020:  10:      146543.;0.960752 
 2.0e-05:  12:      146543.;0.960984 
 2.0e-06:  15:      146543.;0.960974 
 2.0e-07:  15:      146543.;0.960974 
At return
 17:     146542.78: 0.960974
npt = 21 , n =  15 
rhobeg =  0.2402773 , rhoend =  2.402773e-07 
   0.024:  22:      146543.;0.960974 -1.20139 -0.0103437 0.0258154 -0.0116047 0.500429  1.12674  1.05958 0.290308 0.369654 0.295491 0.362936 0.453156 0.402868 0.297695 
  0.0024:  25:      146543.;0.960974 -1.20139 -0.0103437 0.0258154 -0.0116047 0.500429  1.12674  1.05958 0.290308 0.369654 0.295491 0.362936 0.453156 0.402868 0.297695 
 0.00024:  55:      146542.;0.963295 -1.20556 -0.0147872 0.0209361 -0.0160586 0.496082  1.12355  1.05572 0.291643 0.369540 0.297302 0.363591 0.453500 0.400996 0.296965 
 2.4e-05:  77:      146542.;0.963244 -1.20602 -0.0145060 0.0217739 -0.0169666 0.496343  1.12370  1.05553 0.291640 0.369878 0.297602 0.363590 0.453817 0.401563 0.297064 
 2.4e-06:  97:      146542.;0.963253 -1.20604 -0.0145030 0.0217623 -0.0169737 0.496334  1.12371  1.05551 0.291631 0.369875 0.297614 0.363567 0.453827 0.401556 0.297047 
 2.4e-07: 116:      146542.;0.963253 -1.20604 -0.0145012 0.0217604 -0.0169719 0.496334  1.12370  1.05551 0.291631 0.369876 0.297614 0.363567 0.453827 0.401554 0.297047 
At return
137:     146542.06: 0.963254 -1.20604 -0.0145012 0.0217604 -0.0169719 0.496334  1.12370  1.05551 0.291631 0.369876 0.297614 0.363567 0.453827 0.401554 0.297047
   user  system elapsed 
360.240   0.710 368.761 
> print(drk.glmer, corr = FALSE)
Generalized linear mixed model fit by maximum likelihood ['merMod']
 Family: poisson 
Formula: drinks ~ weekday * gender + (1 | id) 
   Data: drink.df 
      AIC       BIC    logLik  deviance 
146572.06 146706.11 -73271.03 146542.06 

Random effects:
 Groups Name        Variance Std.Dev.
 id     (Intercept) 0.9279   0.9633  
Number of obs: 56199, groups: id, 980

Fixed effects:
                         Estimate Std. Error z value
(Intercept)              -1.20604    0.04870  -24.77
weekdayMonday            -0.01450    0.03328   -0.44
weekdayTuesday            0.02176    0.03301    0.66
weekdayWednesday         -0.01697    0.03340   -0.51
weekdayThursday           0.49633    0.02973   16.69
weekdayFriday             1.12370    0.02688   41.81
weekdaySaturday           1.05551    0.02706   39.01
genderM                   0.29163    0.07110    4.10
weekdayMonday:genderM     0.36988    0.04356    8.49
weekdayTuesday:genderM    0.29761    0.04354    6.84
weekdayWednesday:genderM  0.36357    0.04376    8.31
weekdayThursday:genderM   0.45383    0.03910   11.61
weekdayFriday:genderM     0.40155    0.03582   11.21
weekdaySaturday:genderM   0.29705    0.03620    8.21
> 
> ### timing
> #
> ###    user  system elapsed
> ### 257.268  39.115 295.754
> 
> proc.time()
   user  system elapsed 
388.650   1.230 399.061 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplots.pdf
Type: application/pdf
Size: 11088 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100623/9619f98d/attachment.pdf>

From Jeffrey.Evans at dartmouth.edu  Thu Jun 24 01:17:45 2010
From: Jeffrey.Evans at dartmouth.edu (Jeffrey Evans)
Date: Wed, 23 Jun 2010 19:17:45 -0400
Subject: [R-sig-ME] lme4a, glmer and all that
Message-ID: <317D66FF74C3488183DF70F66A23BC21@Animal>

Can anyone provide a status update on Doug Bates' comment from March about
doubting parameter estimates from glmer in lme4? 

A) Which version is suspect - version 32, it seems?
B) Des version 33 resolve this issue?

Many thanks,

Jeff Evans
Dartmouth College

In March Doug Bates wrote:
"Two further comments. It is only the results from fitting generalized
linear mixed models with the current lme4 that I have cause to doubt. The
results from linear mixed models do check out. "



From j.hadfield at ed.ac.uk  Thu Jun 24 10:24:43 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 24 Jun 2010 09:24:43 +0100
Subject: [R-sig-ME] random regression with MCMCglmm
In-Reply-To: <4A40EF96.7070900@mnhn.fr>
References: <4A40EF96.7070900@mnhn.fr>
Message-ID: <CCB337DB-69A5-48B9-817F-528B84E7B8F4@ed.ac.uk>

Hi Celine,

The most likely reason is that Cat or st2Food are not present in your  
data frame.  If this is not the case, then let me know and I'll take a  
more detailed look.

Cheers,

Jarrod


On 23 Jun 2009, at 16:07, Celine Teplitsky wrote:

> Dear all,
>
> I would like to fit a random regression using MCMCglmm. The problem  
> is I don't manage to include heterogeneous residual variance (when I  
> use just one residual variance the model is running). I have created  
> a factor (Cat) grouping the environments into 4 food qualities from  
> good to bad, so the model looks like:
> priorA<-list(G=list(G1=list(V=diag(2), n=2)),R=list(V=diag(4), n= 2))
>
> MCMCglmm(LD ~ Age+stFood , random=~us(1+st2Food):ID, rcov =  
> ~us(Cat):units, data=Data,prior=priorA, family =  
> c("gaussian"),nitt=120000, burnin=20000, thin=100)
>
> but I get this error message, and I really don't know how to fix the  
> problem:
>
> Error in `[.data.frame`(data, , components[[1]]) :
>  undefined columns selected
>
> Many thanks in advance for any help
>
> Celine
>
> -- 
>
> Celine Teplitsky
> D?partement Ecologie et Gestion de la Biodiversit? UMR 7204
> Unit? Conservation des Esp?ces, Restauration et Suivi des Populations
> Case Postale 51
> 55 rue Buffon 75005 Paris
>
> Webpage : http://www2.mnhn.fr/cersp/spip.php?rubrique96
> Fax : (33-1)-4079-3835
> Phone: (33-1)-4079-3443
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From j.hadfield at ed.ac.uk  Thu Jun 24 10:33:33 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 24 Jun 2010 09:33:33 +0100
Subject: [R-sig-ME] Computational speed - MCMCglmm/lmer
In-Reply-To: <4C1CE581.9030205@u.washington.edu>
References: <4C1CE581.9030205@u.washington.edu>
Message-ID: <C33AFF89-6B19-4956-9CF6-FC4C0F3A10A4@ed.ac.uk>

Hi Dave,

Sorry for the late response on this  - I've been doing field work.   I  
think there is little option for speeding up the time per iteration in  
MCMCglmm without considerable extra work. Most cpu are spent either  
solving the mixed model equations or generating random (normal)  
deviates.  It may be possible to multi-thread the latter but how easy  
this would be and how much of an increase in speed you would get I'm  
not sure.  For ZIP models at least, the long computing time is a  
result of poor mixing. The next version (as you know) will allow  
hurdle models to be fitted.  These have much better mixing properties  
and in terms of model fit are very similar to ZIP models.

Cheers,

Jarrod
On 19 Jun 2010, at 16:42, David Atkins wrote:

>
> Hi all--
>
> I use (g)lmer and MCMCglmm on a weekly basis, and I am wondering  
> about options for speeding up their computations.  This is primarily  
> an issue with MCMCglmm, given the many necessary MCMC iterations to  
> get to convergence on some problems.  But, even with glmer(), I have  
> runs that get into 20-30 minutes.
>
> First, let me be very clear that this is in no way a criticism of  
> Doug's and Jarrod's work (package developers for lme4 and MCMCglmm,  
> respectively).  Their code has probably brought models/data into  
> range that would not have been possible.
>
> Second, I have included link to data and script below, along with  
> some timings on my computer: Mac Book Pro, 2.5GHz, with 4GB RAM.   
> Here's sessionInfo from my runs:
>
> > sessionInfo()
> R version 2.11.1 (2010-05-31)
> i386-apple-darwin9.8.0
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] MCMCglmm_2.05      corpcor_1.5.6      ape_2.5-3
> [4] coda_0.13-5        tensorA_0.35       lme4_0.999375-34
> [7] Matrix_0.999375-41 lattice_0.19-7
>
> loaded via a namespace (and not attached):
> [1] gee_4.13-14   grid_2.11.1   nlme_3.1-96   stats4_2.11.1  
> tools_2.11.1
>
> Specific questions:
>
> 1. Would be curious to know timings on other people's set-ups.   
> Jarrod and I had an exchange one time where he was gracious enough  
> to run a zero-inflated model where I was concerned about  
> convergence.  He ran a model with 1.3M iterations, which I think  
> would take a number of days, if not a week on my computer.  This was  
> part of what got me thinking about this.  Thus, my first interest is  
> whether there is an "optimal" hardware/OS configuration, or does it  
> matter?
>
> Some things I see in R-help archives:
>
> 2. 32 vs. 64-bit: Seems like this is mostly an issue of data/model  
> size and whether you need to access more than 4GB of RAM.  AFAICS,  
> 64-bit processors are not necessarily faster.
>
> 3. "Optimized" BLAS: There's a bit of discussion about optimized  
> BLAS (basis linear algebra... something).  However, these  
> discussions note that there is no generally superior BLAS.  Not sure  
> whether specific BLAS might be optimized for GLMM computations.
>
> 4. Parallel computing: With multi-core computers, looks like there  
> are some avenues for splitting intensive computations across  
> processors.
>
> Finally, I'm asking here b/c I run into these issues with GLMM (and  
> zero-inflated mixed models), though most of the discussion I've seen  
> thus far about computation speed has been on R-help.
>
> The data below are self-reported drinks (alcohol) from college  
> students for up to the last 90 days.  Distribution of counts is zero- 
> inflated.  I run a Poisson GLMM with glmer, over-dispersed Poisson  
> GLMM with MCMCglmm, and then zero-inflated OD Poisson with MCMCglmm  
> and provide timings for my set-up.
>
> Okay, any and all thoughts welcomed.
>
> thanks, Dave
>
>
> ### thinking through computational speed with lmer and MCMCglmm
> #
> ### read drinking data
> drink.df <- read.table(file = "http://depts.washington.edu/cshrb/newweb/stats%20documents/tlfb.txt 
> ",
> 						header = TRUE, sep = "\t")
> str(drink.df) # 57K rows
>
> ### id is id variable (shocking)
> ### gender and weekday are 0/1 indicator variables
> ### drinks has number of drinks consumed
>
> ### distribution of outcome
> table(drink.df$drinks)
> plot(table(drink.df$drinks), lwd=2) # zero-inflated
>
> ### how many people?
> length(unique(drink.df$id)) # 990
> sort(table(drink.df$id))
>
> ### NOTE: most people have max of 90, which they should
> ###			two folks with 180 and 435 (prob data errors)
> ###			long negative tail down from 90
> #
> ### NOTE: for this purpose, not worrying about the 180/435
>
> ### speed tests
> #
> ### fit random intercept and random slope for weekday
> ### fixed effects for gender and weekday and interaction
> #
> ### Poisson GLMM with glmer()
> library(lme4)
>
> system.time(
> drk.glmer <- glmer(drinks ~ weekday*gender + (weekday | id),
> 					data = drink.df, family = poisson,
> 					verbose = TRUE)
> )
> summary(drk.glmer)
>
> ### timing
> #
> ###    user  system elapsed
> ###  36.326   9.013  45.316
> 					
> ### over-dispersed Poisson GLMM with MCMCglmm()
> library(MCMCglmm)
>
> prior <- list(R = list(V = 1, n = 1),
> 				G = list(G1 = list(V = diag(2), n = 2)))
> system.time(
> drk.mcmc <- MCMCglmm(drinks ~ weekday*gender,
> 					random = ~ us(1 + weekday):id,
> 					data = drink.df, family = "poisson",
> 					prior = prior)
> )
> summary(drk.mcmc) # NOTE: using summary.MCMCglmm in v 2.05 of package
>
> ### timing
> #
> ###        user   system  elapsed
> ### 	1034.317  165.128 1203.536
>
> ### zero-inflated, over-dispersed Poisson GLMM with MCMCglmm()
> #
> ### NOTE: haven't run the following yet, other than a quick "toy  
> run" to
> ###			sure that it is set up correctly.
> ### NOTE: this only has random intercept in each portion of the model
>
> prior2 <- list(R = list(V = diag(2), n = 1, fix = 2),
> 				G = list(G1 = list(V = 1, n = 1),
> 						  G2 = list(V = 1, n = 1)))
> system.time(
> drk.zimcmc <- MCMCglmm(drinks ~ -1 + trait*weekday*gender,
> 					random = ~ idh(at.level(trait, 1)):id + idh(at.level(trait,  
> 2)):id,
> 					rcov = ~ idh(trait):units,
> 					data = drink.df, family = "zipoisson",
> 					prior = prior2)
> )
> summary(drk.zimcmc)
>
> ### timing
> #
> ###    	 user   system  elapsed
> ###    2105.366  544.881 2640.030
>
> -- 
> Dave Atkins, PhD
> Research Associate Professor
> Department of Psychiatry and Behavioral Science
> University of Washington
> datkins at u.washington.edu
>
> Center for the Study of Health and Risk Behaviors (CSHRB)		
> 1100 NE 45th Street, Suite 300 	
> Seattle, WA  98105 	
> 206-616-3879 	
> http://depts.washington.edu/cshrb/
> (Mon-Wed)	
>
> Center for Healthcare Improvement, for Addictions, Mental Illness,
>  Medically Vulnerable Populations (CHAMMP)
> 325 9th Avenue, 2HH-15
> Box 359911
> Seattle, WA 98104?
> 206-897-4210
> http://www.chammp.org
> (Thurs)
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From j.hadfield at ed.ac.uk  Thu Jun 24 10:46:59 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 24 Jun 2010 09:46:59 +0100
Subject: [R-sig-ME] MCMCglmm troubles
In-Reply-To: <AANLkTilkcHW2S5L_GJkC2HxzaTYRRysMrt_gRxYxd2tC@mail.gmail.com>
References: <AANLkTilkcHW2S5L_GJkC2HxzaTYRRysMrt_gRxYxd2tC@mail.gmail.com>
Message-ID: <B182B1D1-DB98-44C1-AA5E-394B0AFA2AF4@ed.ac.uk>

Hi Mike,

Sorry for the delay on this.  I'm not sure you want "multinomial3" as  
your family given that the three response variables are normally  
distributed. Specifying family=rep("gaussian", 3) would be more  
appropriate.  You will still get an error message because the default   
residual term is ~units which specifies a residual for each row of the  
response. For univariate models this is equivalent to IID residuals.  
For multi-response models it is more usual to allow different residual  
variances for each response, and often residual covariances between  
responses. rcov=~idh(trait):units fits different variances across  
responses (trait)  but sets the covariances to zero. rcov=  
~us(trait):units  estimates the covariances too. There are other less  
general possibilities too (see CourseNotes) which may be usefull. For  
example  rcov=~trait:units fits a common variance across responses and  
fixes the covariances to zero.

Having random=~sid also assumes that each sid effect is identical  
across responses so you may want to relax this assumption as above.

Cheers,

Jarrod


On 17 Jun 2010, at 13:43, Mike Lawrence wrote:

> Hi folks,
>
> I'm trying to do a mixed multinomial model with 3 response variables,
> but I'm getting the error "please use idh() or us() error structure".
> I believe that idh() and us() are used to specify the nature of the
> interaction between multiple random variables, but I don't have
> multiple random variables, so I'm not sure why I'm getting that error.
> Some example data are below, but note that in my real data, the dv's
> are indeed non-independent (they are in fact the number of trials
> classified into each of three categories).
>
> a = expand.grid(
> 	sid = 1:20
> 	, condition = factor(1:2)
> )
> a$group = factor(a$sid%%2)
> a$sid = factor(a$sid)
> a$dv1 = rnorm(nrow(a))
> a$dv2 = rnorm(nrow(a))
> a$dv3 = rnorm(nrow(a))
>
> MCMCglmm(
> 	cbind(dv1,dv2,dv3)~condition*group
> 	, random = ~ sid
> 	, family = 'multinomial3'
> 	, data = a
> )
>
>
>
> -- 
> Mike Lawrence
> Graduate Student
> Department of Psychology
> Dalhousie University
>
> Looking to arrange a meeting? Check my public calendar:
> http://tr.im/mikes_public_calendar
>
> ~ Certainty is folly... I think. ~
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From teplitsky at mnhn.fr  Thu Jun 24 12:32:06 2010
From: teplitsky at mnhn.fr (Celine Teplitsky)
Date: Thu, 24 Jun 2010 12:32:06 +0200
Subject: [R-sig-ME] random regression with MCMCglmm
In-Reply-To: <CCB337DB-69A5-48B9-817F-528B84E7B8F4@ed.ac.uk>
References: <4A40EF96.7070900@mnhn.fr>
	<CCB337DB-69A5-48B9-817F-528B84E7B8F4@ed.ac.uk>
Message-ID: <4C233426.3010904@mnhn.fr>

Hi Jarrod,

actually they both are. Here is a list of the columns in the data frame

  [1] "ID"                "Mate"              "Hf"
  [4] "Hm"                "AgeFemale"         "AgeMale"
  [7] "Year"              "DayRecovered"      "StatusBreeding"
[10] "Bonding"           "LD"                "Af"
[13] "Am"                "Afc"               "Amc"
[16] "Food.availability" "mFood"             "stFood"
[19] "st2Food"           "Quant"             "Q2"
[22] "animal"            "Cat"


Cat is 1 to 4 but as a factor. I tried a simpler version with Q2: only 2 
environments and coded as A/B but I get the same error message. The 
model runs very well when I try without error structure, but problems 
arise when I specify rcov.

Thanks a lot for your help!

Cheers

Celine

> Hi Celine,
>
> The most likely reason is that Cat or st2Food are not present in your 
> data frame.  If this is not the case, then let me know and I'll take a 
> more detailed look.
>
> Cheers,
>
> Jarrod
>
>
> On 23 Jun 2009, at 16:07, Celine Teplitsky wrote:
>
>> Dear all,
>>
>> I would like to fit a random regression using MCMCglmm. The problem 
>> is I don't manage to include heterogeneous residual variance (when I 
>> use just one residual variance the model is running). I have created 
>> a factor (Cat) grouping the environments into 4 food qualities from 
>> good to bad, so the model looks like:
>> priorA<-list(G=list(G1=list(V=diag(2), n=2)),R=list(V=diag(4), n= 2))
>>
>> MCMCglmm(LD ~ Age+stFood , random=~us(1+st2Food):ID, rcov = 
>> ~us(Cat):units, data=Data,prior=priorA, family = 
>> c("gaussian"),nitt=120000, burnin=20000, thin=100)
>>
>> but I get this error message, and I really don't know how to fix the 
>> problem:
>>
>> Error in `[.data.frame`(data, , components[[1]]) :
>>  undefined columns selected
>>
>> Many thanks in advance for any help
>>
>> Celine
>>
>> -- 
>>
>> Celine Teplitsky
>> D?partement Ecologie et Gestion de la Biodiversit? UMR 7204
>> Unit? Conservation des Esp?ces, Restauration et Suivi des Populations
>> Case Postale 51
>> 55 rue Buffon 75005 Paris
>>
>> Webpage : http://www2.mnhn.fr/cersp/spip.php?rubrique96
>> Fax : (33-1)-4079-3835
>> Phone: (33-1)-4079-3443
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>


-- 

Celine Teplitsky
D?partement Ecologie et Gestion de la Biodiversit? UMR 7204
Unit? Conservation des Esp?ces, Restauration et Suivi des Populations
Case Postale 51
55 rue Buffon 75005 Paris

Webpage : http://www2.mnhn.fr/cersp/spip.php?rubrique96
Fax : (33-1)-4079-3835
Phone: (33-1)-4079-3443



From Mike.Lawrence at dal.ca  Thu Jun 24 13:21:29 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Thu, 24 Jun 2010 08:21:29 -0300
Subject: [R-sig-ME] MCMCglmm troubles
In-Reply-To: <B182B1D1-DB98-44C1-AA5E-394B0AFA2AF4@ed.ac.uk>
References: <AANLkTilkcHW2S5L_GJkC2HxzaTYRRysMrt_gRxYxd2tC@mail.gmail.com> 
	<B182B1D1-DB98-44C1-AA5E-394B0AFA2AF4@ed.ac.uk>
Message-ID: <AANLkTil-SvKxdVFbg9EdHDoo1SO06fyjBsAamDkv9zTB@mail.gmail.com>

Ah, that makes sense now. Oh, and I think it is indeed the
"multinomial3" family that I need to model; I used rnorm() as a
shortcut to generate data to show the error I encountered, but the
real data are counts.

On Thu, Jun 24, 2010 at 5:46 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
> Hi Mike,
>
> Sorry for the delay on this. ?I'm not sure you want "multinomial3" as your
> family given that the three response variables are normally distributed.
> Specifying family=rep("gaussian", 3) would be more appropriate. ?You will
> still get an error message because the default ?residual term is ~units
> which specifies a residual for each row of the response. For univariate
> models this is equivalent to IID residuals. For multi-response models it is
> more usual to allow different residual variances for each response, and
> often residual covariances between responses. rcov=~idh(trait):units fits
> different variances across responses (trait) ?but sets the covariances to
> zero. rcov= ~us(trait):units ?estimates the covariances too. There are other
> less general possibilities too (see CourseNotes) which may be usefull. For
> example ?rcov=~trait:units fits a common variance across responses and fixes
> the covariances to zero.
>
> Having random=~sid also assumes that each sid effect is identical across
> responses so you may want to relax this assumption as above.
>
> Cheers,
>
> Jarrod
>
>
> On 17 Jun 2010, at 13:43, Mike Lawrence wrote:
>
>> Hi folks,
>>
>> I'm trying to do a mixed multinomial model with 3 response variables,
>> but I'm getting the error "please use idh() or us() error structure".
>> I believe that idh() and us() are used to specify the nature of the
>> interaction between multiple random variables, but I don't have
>> multiple random variables, so I'm not sure why I'm getting that error.
>> Some example data are below, but note that in my real data, the dv's
>> are indeed non-independent (they are in fact the number of trials
>> classified into each of three categories).
>>
>> a = expand.grid(
>> ? ? ? ?sid = 1:20
>> ? ? ? ?, condition = factor(1:2)
>> )
>> a$group = factor(a$sid%%2)
>> a$sid = factor(a$sid)
>> a$dv1 = rnorm(nrow(a))
>> a$dv2 = rnorm(nrow(a))
>> a$dv3 = rnorm(nrow(a))
>>
>> MCMCglmm(
>> ? ? ? ?cbind(dv1,dv2,dv3)~condition*group
>> ? ? ? ?, random = ~ sid
>> ? ? ? ?, family = 'multinomial3'
>> ? ? ? ?, data = a
>> )
>>
>>
>>
>> --
>> Mike Lawrence
>> Graduate Student
>> Department of Psychology
>> Dalhousie University
>>
>> Looking to arrange a meeting? Check my public calendar:
>> http://tr.im/mikes_public_calendar
>>
>> ~ Certainty is folly... I think. ~
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~



From datkins at u.washington.edu  Wed Jun 23 20:40:53 2010
From: datkins at u.washington.edu (David Atkins)
Date: Wed, 23 Jun 2010 11:40:53 -0700
Subject: [R-sig-ME] Data Redux -- Re:  Computational speed - MCMCglmm/lmer
In-Reply-To: <AANLkTimZMBFRXKD9g1k_bxiEewv4Cuik9gNBFZrUr7ns@mail.gmail.com>
References: <4C1CE581.9030205@u.washington.edu>
	<AANLkTimm7BPOARDPXgW_mTHNngu_sbKjPPgVlS6FSqQf@mail.gmail.com>
	<AANLkTim89W3S3AN2qSc2wK1PzGvUxmgLZIZ-gFfaJK8i@mail.gmail.com>
	<AANLkTimZMBFRXKD9g1k_bxiEewv4Cuik9gNBFZrUr7ns@mail.gmail.com>
Message-ID: <4C225535.30505@u.washington.edu>


First, my apologies for not providing clean data in my initial posting, 
which was clearly an oversight on my part.  I have an email in to the PI 
but haven't gotten a response yet.

I have attached an updated dataset, that pulls out the 2 suspect 
participants as well as those with gender coded 2.  In addition, it 
includes two more variables:

weekday - 7 level factor for day of week (new variable weekend now has 
the binary version)
fratsor - a binary factor indicating whether individual is part of a 
fraternity or sorority (or not)

I have an updated script below that shows (descriptively) how drinking 
varies over these factors.  Moreover, including weekday as either fixed 
or random, really ratchets up the time for glmer.  Again, my original 
purpose is definitely *not* to criticize lme4 (or Doug), but simply to 
get some feedback about computational speed, and whether or not it's 
possible to speed up runs via hardware, OS, or software.

Finally, in providing some data, I was trying to provide a brief subset 
of data that has certain realistic qualities (and it is real data) but 
is not a "full" data set.  In trying to be simple and straightforward, I 
may have raised more questions.

So, in response to a few questions raised:

The data come from a study of problematic drinking focused on high-risk 
events, and this particular data focused on 21st birthdays (here in the 
US, that is the legal drinking age).  The present data are from a survey 
(ie, non-intervention), which then informed a later intervention study. 
  Thus, the (up to) 90 days of retrospective drinking, will cover the 
individual's 21st birthday.

Doug asks about someone reporting 45 drinks.  Because we are capturing 
21st birthdays, we are definitely getting some extreme drinking, but we 
also are relying on self-report.  Clearly, there will be some errors and 
possible bravado about feats of drinking.  Moreover, the study has a 
protocol for addressing potentially dangerous levels of drinking with 
participants (when blood-alcohol content passes a certain cutoff).

Hadley asks about the repeated data.  Part of the study involves friends 
of the main participant (as one intervention condition includes friends 
input as part of the intervention).  Some of the friend's data were 
included in a larger version of this dataset, which then led to 
replicates of the participant's data.  Thus, we knew individuals with 
friend's data had replicates, but this version was supposed to have that 
cleaned up.

Finally, this particular data was collected on a rolling basis, and thus 
the 90 day recounting of drinking covers a large swath of the calendar 
year.  We are currently working on a paper that examines student 
drinking on typical weekdays vs. weekends vs. 21st birthday vs. holidays 
(including St. Patrick's Day, though July 4th and New Year's Eve are 
much heavier drinking days...).

Hopefully this clarifies certain aspects of the data, and I definitely 
appreciate folks input on the computational aspects -- I'm certainly 
learning.

[BTW, I'm currently fitting a second model to the one reported below, 
with a random effect for weekday -- currently at 30 minutes and counting.]

cheers, Dave



### updated 6.23.10 -- thinking through computational speed with lmer 
and MCMCglmm
#
### read in *updated* drinking data
drink.df <- read.table("drinksUPDATED.txt",
						header = TRUE, sep = "\t")
str(drink.df) # 57K rows

### NOTE: slight variable changes since last iteration
### id is id variable (shocking)
### gender is binary factor
### fratsor is binary factor (in fraternity or sorority vs. not)
### weekday now has day of week
### weekend is now weekday (Sun - Thurs) vs. weekend (Fri - Sat)
### drinks has number of drinks consumed

### trim trailing white spaces
levels(drink.df$weekday) <- sub('[[:space:]]+$', '', 
levels(drink.df$weekday))

### re-order factor
library(gdata)
drink.df$weekday <- reorder.factor(drink.df$weekday, new.order = 
c(4,2,6,7,5,1,3))
levels(drink.df$weekday)

### distribution of outcome
table(drink.df$drinks)
plot(table(drink.df$drinks), lwd=2) # zero-inflated

### how many people?
length(unique(drink.df$id)) # 980
sort(table(drink.df$id)) # max of 90 drinks

### how do drinks vary across days of week and also gender and fratsor?
#
with(drink.df, tapply(drinks, list(gender, fratsor), mean))
### not surprising, but men in fraternities drink notably more

with(drink.df, tapply(drinks, list(gender, weekday, fratsor), mean))
### general peak on friday and/or saturday, but differences in rest
### of week for fraternity/sorority crowd...

### speed tests
#
### fit random intercept and random slope for weekday
### fixed effects for gender and weekday and interaction
#
### Poisson GLMM with glmer()
library(lme4)

### NOTE: weekday is different from last set of code; last time it was
###			binary, this time it is 7 level factor
#
### random intercept
system.time(
drk.glmer <- glmer(drinks ~ weekday*gender + (1 | id),
					data = drink.df, family = poisson,
					verbose = TRUE)
)
summary(drk.glmer)

### timing
#
###    user  system elapsed
### 257.268  39.115 295.754


Hadley Wickham wrote:
>> Forgive me for sounding grouchy but I find this whole discussion
>> misguided.  Worrying about the speed of fitting a model and niceties
>> of the model formulation before doing elementary checks on the data is
>> putting the cart before the horse.  Why is gender coded as 0, 1 and 2?
>>  Why, when there was a maximum of 90 days of monitoring, is there one
>> id with 435 observations and another with 180 observations.
> 
> Especially when you look at (e.g.) subset(drink.df, id == 8396125) and
> notice that drinks appear to be repeated in blocks of five.  Looks
> like a data processing error - but has it also happened for other
> subject?
> 
> I also wonder why the date has been removed from the data. It seems
> like this would be an important covariate (St Patrick's day, match
> days, birthdays, ...).  And I hope weekday isn't Monday-Friday...
> 
> Hadley
> 
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: drinksUPDATED.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100623/f0ef694b/attachment.txt>

From mmalten at gmail.com  Thu Jun 24 15:38:24 2010
From: mmalten at gmail.com (Mitchell Maltenfort)
Date: Thu, 24 Jun 2010 09:38:24 -0400
Subject: [R-sig-ME] lme4a, glmer and all that
In-Reply-To: <317D66FF74C3488183DF70F66A23BC21@Animal>
References: <AcsTKkmitWxsVID7TEmL3XlilseyQA==>
	<317D66FF74C3488183DF70F66A23BC21@Animal>
Message-ID: <AANLkTilR3ZgdFQSXZcMwAWWeEDiBxKwgUbCBQZTIsNqs@mail.gmail.com>

Haven't seen anything new since his March 4 post indicating that a
check vs Stata agreed with lme4, not lme4a.





On Wed, Jun 23, 2010 at 7:17 PM, Jeffrey Evans
<Jeffrey.Evans at dartmouth.edu> wrote:
> Can anyone provide a status update on Doug Bates' comment from March about
> doubting parameter estimates from glmer in lme4?
>
> A) Which version is suspect - version 32, it seems?
> B) Des version 33 resolve this issue?
>
> Many thanks,
>
> Jeff Evans
> Dartmouth College
>
> In March Doug Bates wrote:
> "Two further comments. It is only the results from fitting generalized
> linear mixed models with the current lme4 that I have cause to doubt. The
> results from linear mixed models do check out. "
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Thu Jun 24 17:29:44 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 24 Jun 2010 10:29:44 -0500
Subject: [R-sig-ME] lme4a, glmer and all that
In-Reply-To: <AANLkTilR3ZgdFQSXZcMwAWWeEDiBxKwgUbCBQZTIsNqs@mail.gmail.com>
References: <317D66FF74C3488183DF70F66A23BC21@Animal>
	<AANLkTilR3ZgdFQSXZcMwAWWeEDiBxKwgUbCBQZTIsNqs@mail.gmail.com>
Message-ID: <AANLkTik4h6DZD2ps68CByTE7PW3uRRwJ1W34NeBvPVj7@mail.gmail.com>

On Thu, Jun 24, 2010 at 8:38 AM, Mitchell Maltenfort <mmalten at gmail.com> wrote:
> Haven't seen anything new since his March 4 post indicating that a
> check vs Stata agreed with lme4, not lme4a.

Sorry, I should have followed up more publicly on that posting.  There
was a difference in the results between lme4 and lme4a and I was
concerned that the problem was in lme4.  It turns out that the problem
was in lme4a and has now been resolved.

Having said that, I have now encountered examples where lme4a
converges to a different and better optimum than does lme4.

All of the maximum likelihood estimation methods for mixed models end
up doing some kind of numerical optimization procedure.  One of the
changes in lme4a is the use of the bobyqa optimizer from the minqa
package, as opposed to the nlminb optimizer in the stats package.  I
feel that the bobyqa optimizer is more effective and often faster than
nlminb (although not always).

One of the big differences between linear mixed models and generalized
linear mixed models is the number of parameters in the general
optimizer problem.  In linear mixed models one can "profile out" the
fixed-effects parameters and produce a much easier optimization
problem.  For generalized linear mixed models profiling out the
fixed-effects produces only an approximate minimum.  In the example
from Dave Atkins fitting a Poisson GLMM that has been discussed on
this list recently the differences were minimal and solving the
reduced problem was much faster (17 seconds versus 300 seconds) than
the full optimization problem.  However, in the examples from the 2007
JSS paper by Doran, Bates, Bliese and Dowling
(http://http://www.jstatsoft.org/v20/i02) I have seen a substantially
better minimum deviance using the full optimization than using the
reduced optimization.

Bottom line is that the results from lme4 should be ok but lme4a, when
I get it all sorted out, can do better.

> On Wed, Jun 23, 2010 at 7:17 PM, Jeffrey Evans
> <Jeffrey.Evans at dartmouth.edu> wrote:
>> Can anyone provide a status update on Doug Bates' comment from March about
>> doubting parameter estimates from glmer in lme4?
>>
>> A) Which version is suspect - version 32, it seems?
>> B) Des version 33 resolve this issue?
>>
>> Many thanks,
>>
>> Jeff Evans
>> Dartmouth College
>>
>> In March Doug Bates wrote:
>> "Two further comments. It is only the results from fitting generalized
>> linear mixed models with the current lme4 that I have cause to doubt. The
>> results from linear mixed models do check out. "
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From Jeffrey.Evans at dartmouth.edu  Thu Jun 24 18:37:12 2010
From: Jeffrey.Evans at dartmouth.edu (Jeffrey Evans)
Date: Thu, 24 Jun 2010 12:37:12 -0400
Subject: [R-sig-ME] lme4a, glmer and all that
In-Reply-To: <AANLkTik4h6DZD2ps68CByTE7PW3uRRwJ1W34NeBvPVj7@mail.gmail.com>
References: <317D66FF74C3488183DF70F66A23BC21@Animal>
	<AANLkTilR3ZgdFQSXZcMwAWWeEDiBxKwgUbCBQZTIsNqs@mail.gmail.com>
	<AANLkTik4h6DZD2ps68CByTE7PW3uRRwJ1W34NeBvPVj7@mail.gmail.com>
Message-ID: <4CEBB3CE8E894C24B38F8515DB46EA21@Animal>

Thanks Doug,

I guess I'll forge ahead with lme4 for now.

I have another question for you about overdispersion, but I'll put that in a
separate thread.

Thanks,
Jeff

-----Original Message-----
From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas
Bates
Sent: Thursday, June 24, 2010 11:30 AM
To: Mitchell Maltenfort
Cc: Jeffrey Evans; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] lme4a, glmer and all that

On Thu, Jun 24, 2010 at 8:38 AM, Mitchell Maltenfort <mmalten at gmail.com>
wrote:
> Haven't seen anything new since his March 4 post indicating that a 
> check vs Stata agreed with lme4, not lme4a.

Sorry, I should have followed up more publicly on that posting.  There was a
difference in the results between lme4 and lme4a and I was concerned that
the problem was in lme4.  It turns out that the problem was in lme4a and has
now been resolved.

Having said that, I have now encountered examples where lme4a converges to a
different and better optimum than does lme4.

All of the maximum likelihood estimation methods for mixed models end up
doing some kind of numerical optimization procedure.  One of the changes in
lme4a is the use of the bobyqa optimizer from the minqa package, as opposed
to the nlminb optimizer in the stats package.  I feel that the bobyqa
optimizer is more effective and often faster than nlminb (although not
always).

One of the big differences between linear mixed models and generalized
linear mixed models is the number of parameters in the general optimizer
problem.  In linear mixed models one can "profile out" the fixed-effects
parameters and produce a much easier optimization problem.  For generalized
linear mixed models profiling out the fixed-effects produces only an
approximate minimum.  In the example from Dave Atkins fitting a Poisson GLMM
that has been discussed on this list recently the differences were minimal
and solving the reduced problem was much faster (17 seconds versus 300
seconds) than the full optimization problem.  However, in the examples from
the 2007 JSS paper by Doran, Bates, Bliese and Dowling
(http://http://www.jstatsoft.org/v20/i02) I have seen a substantially better
minimum deviance using the full optimization than using the reduced
optimization.

Bottom line is that the results from lme4 should be ok but lme4a, when I get
it all sorted out, can do better.

> On Wed, Jun 23, 2010 at 7:17 PM, Jeffrey Evans 
> <Jeffrey.Evans at dartmouth.edu> wrote:
>> Can anyone provide a status update on Doug Bates' comment from March 
>> about doubting parameter estimates from glmer in lme4?
>>
>> A) Which version is suspect - version 32, it seems?
>> B) Des version 33 resolve this issue?
>>
>> Many thanks,
>>
>> Jeff Evans
>> Dartmouth College
>>
>> In March Doug Bates wrote:
>> "Two further comments. It is only the results from fitting 
>> generalized linear mixed models with the current lme4 that I have 
>> cause to doubt. The results from linear mixed models do check out. "
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From Jeffrey.Evans at dartmouth.edu  Thu Jun 24 18:54:23 2010
From: Jeffrey.Evans at dartmouth.edu (Jeffrey Evans)
Date: Thu, 24 Jun 2010 12:54:23 -0400
Subject: [R-sig-ME] lme4, lme4a, and overdispersed distributions (again)
Message-ID: <6FB4614396E94759B89A6C78CE421807@Animal>

Like others, I have experienced trouble with estimation of the scale
parameter using the quasi-distributions in lme4, which is necessary to
calculate QAICc and rank overdispersed generalized linear mixed models. 

I had several exchanges with Ben Bolker about this early last year after his
TREE paper came out
(http://www.cell.com/trends/ecology-evolution/abstract/S0169-5347%2809%29000
19-6), and I know it's been discussed on on this list. Has there been or is
there any potential resolution to this forthcoming in future releases of
lme4 or lme4a? I run into overdispersed binomial distributions frequently
and have had to use SAS to deal with them. SAS appears to work, but it won't
estimate the overdispersion parameter using laplace estimation (only PQL),
As I understand it, these pseudo-Iikelihoods can't be used for model
ranking. I don't know why SAS can't/won't, but lme4 will run these
quasi-binomial and quasi-poisson distributions with Laplace estimation.

Is there a workable way to use lme4 for modeling overdispersed binomial
data?

Thanks again,

Jeff Evans
Dartmouth College



From bates at stat.wisc.edu  Thu Jun 24 19:25:01 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 24 Jun 2010 12:25:01 -0500
Subject: [R-sig-ME] lme4, lme4a, and overdispersed distributions (again)
In-Reply-To: <6FB4614396E94759B89A6C78CE421807@Animal>
References: <6FB4614396E94759B89A6C78CE421807@Animal>
Message-ID: <AANLkTinNtxnv2JvYNbF05lUTt6-tajtFXttzImcT7ALs@mail.gmail.com>

On Thu, Jun 24, 2010 at 11:54 AM, Jeffrey Evans
<Jeffrey.Evans at dartmouth.edu> wrote:
> Like others, I have experienced trouble with estimation of the scale
> parameter using the quasi-distributions in lme4, which is necessary to
> calculate QAICc and rank overdispersed generalized linear mixed models.

> I had several exchanges with Ben Bolker about this early last year after his
> TREE paper came out
> (http://www.cell.com/trends/ecology-evolution/abstract/S0169-5347%2809%29000
> 19-6), and I know it's been discussed on on this list. Has there been or is
> there any potential resolution to this forthcoming in future releases of
> lme4 or lme4a? I run into overdispersed binomial distributions frequently
> and have had to use SAS to deal with them. SAS appears to work, but it won't
> estimate the overdispersion parameter using laplace estimation (only PQL),
> As I understand it, these pseudo-Iikelihoods can't be used for model
> ranking. I don't know why SAS can't/won't, but lme4 will run these
> quasi-binomial and quasi-poisson distributions with Laplace estimation.

> Is there a workable way to use lme4 for modeling overdispersed binomial
> data?

I have trouble discussing this because I come from a background as a
mathematician and am used to tracing derivations back to the original
definitions.  So when I think of a likelihood (or, equivalently, a
deviance) to be optimized it only makes sense to me if there is a
probability distribution associated with the model.  And for the
quasi-binomial and quasi-Poisson families, there isn't a probability
distribution.  To me that means that discussing maximum likelihood
estimators for such models is nonsense.  The models simply do not
exist.  One can play tricks in the case of a generalized linear model
to estimate a "quasi-parameter" that isn't part of the probability
distribution but it is foolhardy to expect that the tricks will
automatically carry over to a generalized linear mixed model.

I am not denying that data that are over-dispersed with respect to the
binomial or Poisson distributions can and do occur.  But having data
like this and a desire to model it doesn't make the quasi families
real.  In his signature Thierry Onkelinx quotes

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

I could and do plan to incorporate the negative binomial family but,
without a definition that I can understand of a quasi-binomial or
quasi-Poisson distribution and its associated probability function,
I'm stuck. To me it's a "build bricks without straw" situation - you
can't find maximum likelihood estimates for parameters that aren't
part of the likelihood.



From Jeffrey.Evans at dartmouth.edu  Thu Jun 24 19:59:58 2010
From: Jeffrey.Evans at dartmouth.edu (Jeffrey Evans)
Date: Thu, 24 Jun 2010 13:59:58 -0400
Subject: [R-sig-ME] lme4, lme4a, and overdispersed distributions (again)
In-Reply-To: <AANLkTinNtxnv2JvYNbF05lUTt6-tajtFXttzImcT7ALs@mail.gmail.com>
References: <6FB4614396E94759B89A6C78CE421807@Animal>
	<AANLkTinNtxnv2JvYNbF05lUTt6-tajtFXttzImcT7ALs@mail.gmail.com>
Message-ID: <45A2DEF7CF6C4DC29A488964A9A7333D@Animal>

Since I am definitely *not* a mathematician, I am straying in over my head
here. 

I understand what you are saying - that there isn't a likelihood function
for the quasi-binomial "distribution". And therefore, there is no-such
distribution.

What do you think of the suggestion that a beta-binomial mixture
distribution could be used to model overdispersed binomial data? 

Would this be a techinically correct and logistically feasibile solution?

-jeff

-----Original Message-----
From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas
Bates
Sent: Thursday, June 24, 2010 1:25 PM
To: Jeffrey Evans
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] lme4, lme4a, and overdispersed distributions (again)

On Thu, Jun 24, 2010 at 11:54 AM, Jeffrey Evans
<Jeffrey.Evans at dartmouth.edu> wrote:
> Like others, I have experienced trouble with estimation of the scale 
> parameter using the quasi-distributions in lme4, which is necessary to 
> calculate QAICc and rank overdispersed generalized linear mixed models.

> I had several exchanges with Ben Bolker about this early last year 
> after his TREE paper came out 
> (http://www.cell.com/trends/ecology-evolution/abstract/S0169-5347%2809
> %29000 19-6), and I know it's been discussed on on this list. Has 
> there been or is there any potential resolution to this forthcoming in 
> future releases of
> lme4 or lme4a? I run into overdispersed binomial distributions 
> frequently and have had to use SAS to deal with them. SAS appears to 
> work, but it won't estimate the overdispersion parameter using laplace 
> estimation (only PQL), As I understand it, these pseudo-Iikelihoods 
> can't be used for model ranking. I don't know why SAS can't/won't, but 
> lme4 will run these quasi-binomial and quasi-poisson distributions with
Laplace estimation.

> Is there a workable way to use lme4 for modeling overdispersed 
> binomial data?

I have trouble discussing this because I come from a background as a
mathematician and am used to tracing derivations back to the original
definitions.  So when I think of a likelihood (or, equivalently, a
deviance) to be optimized it only makes sense to me if there is a
probability distribution associated with the model.  And for the
quasi-binomial and quasi-Poisson families, there isn't a probability
distribution.  To me that means that discussing maximum likelihood
estimators for such models is nonsense.  The models simply do not exist.
One can play tricks in the case of a generalized linear model to estimate a
"quasi-parameter" that isn't part of the probability distribution but it is
foolhardy to expect that the tricks will automatically carry over to a
generalized linear mixed model.

I am not denying that data that are over-dispersed with respect to the
binomial or Poisson distributions can and do occur.  But having data like
this and a desire to model it doesn't make the quasi families real.  In his
signature Thierry Onkelinx quotes

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

I could and do plan to incorporate the negative binomial family but, without
a definition that I can understand of a quasi-binomial or quasi-Poisson
distribution and its associated probability function, I'm stuck. To me it's
a "build bricks without straw" situation - you can't find maximum likelihood
estimates for parameters that aren't part of the likelihood.



From bates at stat.wisc.edu  Thu Jun 24 23:17:25 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 24 Jun 2010 16:17:25 -0500
Subject: [R-sig-ME] lme4, lme4a, and overdispersed distributions (again)
In-Reply-To: <45A2DEF7CF6C4DC29A488964A9A7333D@Animal>
References: <6FB4614396E94759B89A6C78CE421807@Animal>
	<AANLkTinNtxnv2JvYNbF05lUTt6-tajtFXttzImcT7ALs@mail.gmail.com>
	<45A2DEF7CF6C4DC29A488964A9A7333D@Animal>
Message-ID: <AANLkTikveHhv-cLLlPD7hxmcaEM5kG53kS1uzfeaH4PV@mail.gmail.com>

On Thu, Jun 24, 2010 at 12:59 PM, Jeffrey Evans
<Jeffrey.Evans at dartmouth.edu> wrote:
> Since I am definitely *not* a mathematician, I am straying in over my head
> here.
>
> I understand what you are saying - that there isn't a likelihood function
> for the quasi-binomial "distribution". And therefore, there is no-such
> distribution.
>
> What do you think of the suggestion that a beta-binomial mixture
> distribution could be used to model overdispersed binomial data?
>
> Would this be a techinically correct and logistically feasibile solution?

Technically correct, I imagine.  The feasibility would depend on
whether there is an IRLS type of algorithm for determining the
estimates of the coefficients in the linear predictor.

I see several packages mention the beta-binomial distribution and
fitting such models.  Without actually examining the code though I
wouldn't be able to guess how easily they could be adapted.  You have
to realize that it may be necessary to fit and re-fit the penalized,
generalized linear model many many times, perhaps into the thousands
of times, during the fit of one GLMM. You can't be casual about the
inner loop of fitting the GLM.  Most of the descriptions in packages
that I have seen eventually call optim.  The implementation of GLMs
within glmer is very different from calling an optimizer.

> -----Original Message-----
> From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas
> Bates
> Sent: Thursday, June 24, 2010 1:25 PM
> To: Jeffrey Evans
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] lme4, lme4a, and overdispersed distributions (again)
>
> On Thu, Jun 24, 2010 at 11:54 AM, Jeffrey Evans
> <Jeffrey.Evans at dartmouth.edu> wrote:
>> Like others, I have experienced trouble with estimation of the scale
>> parameter using the quasi-distributions in lme4, which is necessary to
>> calculate QAICc and rank overdispersed generalized linear mixed models.
>
>> I had several exchanges with Ben Bolker about this early last year
>> after his TREE paper came out
>> (http://www.cell.com/trends/ecology-evolution/abstract/S0169-5347%2809
>> %29000 19-6), and I know it's been discussed on on this list. Has
>> there been or is there any potential resolution to this forthcoming in
>> future releases of
>> lme4 or lme4a? I run into overdispersed binomial distributions
>> frequently and have had to use SAS to deal with them. SAS appears to
>> work, but it won't estimate the overdispersion parameter using laplace
>> estimation (only PQL), As I understand it, these pseudo-Iikelihoods
>> can't be used for model ranking. I don't know why SAS can't/won't, but
>> lme4 will run these quasi-binomial and quasi-poisson distributions with
> Laplace estimation.
>
>> Is there a workable way to use lme4 for modeling overdispersed
>> binomial data?
>
> I have trouble discussing this because I come from a background as a
> mathematician and am used to tracing derivations back to the original
> definitions. ?So when I think of a likelihood (or, equivalently, a
> deviance) to be optimized it only makes sense to me if there is a
> probability distribution associated with the model. ?And for the
> quasi-binomial and quasi-Poisson families, there isn't a probability
> distribution. ?To me that means that discussing maximum likelihood
> estimators for such models is nonsense. ?The models simply do not exist.
> One can play tricks in the case of a generalized linear model to estimate a
> "quasi-parameter" that isn't part of the probability distribution but it is
> foolhardy to expect that the tricks will automatically carry over to a
> generalized linear mixed model.
>
> I am not denying that data that are over-dispersed with respect to the
> binomial or Poisson distributions can and do occur. ?But having data like
> this and a desire to model it doesn't make the quasi families real. ?In his
> signature Thierry Onkelinx quotes
>
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> I could and do plan to incorporate the negative binomial family but, without
> a definition that I can understand of a quasi-binomial or quasi-Poisson
> distribution and its associated probability function, I'm stuck. To me it's
> a "build bricks without straw" situation - you can't find maximum likelihood
> estimates for parameters that aren't part of the likelihood.
>
>



From davidD at qimr.edu.au  Thu Jun 24 23:31:59 2010
From: davidD at qimr.edu.au (David Duffy)
Date: Fri, 25 Jun 2010 07:31:59 +1000 (EST)
Subject: [R-sig-ME] lme4, lme4a, and overdispersed distributions (again)
In-Reply-To: <45A2DEF7CF6C4DC29A488964A9A7333D@Animal>
References: <6FB4614396E94759B89A6C78CE421807@Animal><AANLkTinNtxnv2JvYNbF05lUTt6-tajtFXttzImcT7ALs@mail.gmail.com>
	<45A2DEF7CF6C4DC29A488964A9A7333D@Animal>
Message-ID: <Pine.LNX.4.64.1006250724350.14896@orpheus.qimr.edu.au>

On Thu, 24 Jun 2010, Jeffrey Evans wrote:

> What do you think of the suggestion that a beta-binomial mixture
> distribution could be used to model overdispersed binomial data?
>
> Would this be a techinically correct and logistically feasible solution?

If you have a relatively simple setup for the random effects, then the 
nonparametric ML models can be used for overdispersed data: these allow an 
arbitrary distribution for the random effects (as a mixture of 
distributions).  See the npmlreg package.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From john.maindonald at anu.edu.au  Fri Jun 25 01:11:56 2010
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Fri, 25 Jun 2010 09:11:56 +1000
Subject: [R-sig-ME] Fwd:  lme4, lme4a,
	and overdispersed distributions (again)
References: <05CAFA60-CB75-43EF-94FD-85E09FF2FE34@anu.edu.au>
Message-ID: <9972FE5C-7E13-41E5-A3A3-46238B81266A@anu.edu.au>

I think it more accurate to say that, in general, there may be 
a class of distributions, and therefore a possible multiplicity 
of likelihoods, not necessarily for distributions of exponential 
form.  This is a PhD thesis asking to be done, or maybe 
someone has already done it.

Over-dispersed distributions, where it is entirely clear what the
distribution is, can be generated as GLM model +  one random
effect per observation.  We have discussed this before.  This
seems to me the preferred way to go, if such a model seems to
fit the data.  I've not checked the current state of play re fitting
such models in lme4 of lme4a; in the past some versions have
allowed such a model.

I like the simplicity of the one random effect per observation 
approach, as against what can seem the convoluted theoretical 
framework in which beta binomials live.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

> 
> On 25/06/2010, at 3:59 AM, Jeffrey Evans wrote:
> 
>> Since I am definitely *not* a mathematician, I am straying in over my head
>> here. 
>> 
>> I understand what you are saying - that there isn't a likelihood function
>> for the quasi-binomial "distribution". And therefore, there is no-such
>> distribution.
>> 
>> What do you think of the suggestion that a beta-binomial mixture
>> distribution could be used to model overdispersed binomial data? 
>> 
>> Would this be a techinically correct and logistically feasibile solution?
>> 
>> -jeff
>> 
>> -----Original Message-----
>> From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas
>> Bates
>> Sent: Thursday, June 24, 2010 1:25 PM
>> To: Jeffrey Evans
>> Cc: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] lme4, lme4a, and overdispersed distributions (again)
>> 
>> On Thu, Jun 24, 2010 at 11:54 AM, Jeffrey Evans
>> <Jeffrey.Evans at dartmouth.edu> wrote:
>>> Like others, I have experienced trouble with estimation of the scale 
>>> parameter using the quasi-distributions in lme4, which is necessary to 
>>> calculate QAICc and rank overdispersed generalized linear mixed models.
>> 
>>> I had several exchanges with Ben Bolker about this early last year 
>>> after his TREE paper came out 
>>> (http://www.cell.com/trends/ecology-evolution/abstract/S0169-5347%2809
>>> %29000 19-6), and I know it's been discussed on on this list. Has 
>>> there been or is there any potential resolution to this forthcoming in 
>>> future releases of
>>> lme4 or lme4a? I run into overdispersed binomial distributions 
>>> frequently and have had to use SAS to deal with them. SAS appears to 
>>> work, but it won't estimate the overdispersion parameter using laplace 
>>> estimation (only PQL), As I understand it, these pseudo-Iikelihoods 
>>> can't be used for model ranking. I don't know why SAS can't/won't, but 
>>> lme4 will run these quasi-binomial and quasi-poisson distributions with
>> Laplace estimation.
>> 
>>> Is there a workable way to use lme4 for modeling overdispersed 
>>> binomial data?
>> 
>> I have trouble discussing this because I come from a background as a
>> mathematician and am used to tracing derivations back to the original
>> definitions.  So when I think of a likelihood (or, equivalently, a
>> deviance) to be optimized it only makes sense to me if there is a
>> probability distribution associated with the model.  And for the
>> quasi-binomial and quasi-Poisson families, there isn't a probability
>> distribution.  To me that means that discussing maximum likelihood
>> estimators for such models is nonsense.  The models simply do not exist.
>> One can play tricks in the case of a generalized linear model to estimate a
>> "quasi-parameter" that isn't part of the probability distribution but it is
>> foolhardy to expect that the tricks will automatically carry over to a
>> generalized linear mixed model.
>> 
>> I am not denying that data that are over-dispersed with respect to the
>> binomial or Poisson distributions can and do occur.  But having data like
>> this and a desire to model it doesn't make the quasi families real.  In his
>> signature Thierry Onkelinx quotes
>> 
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>> 
>> I could and do plan to incorporate the negative binomial family but, without
>> a definition that I can understand of a quasi-binomial or quasi-Poisson
>> distribution and its associated probability function, I'm stuck. To me it's
>> a "build bricks without straw" situation - you can't find maximum likelihood
>> estimates for parameters that aren't part of the likelihood.
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm



From datkins at u.washington.edu  Fri Jun 25 18:24:45 2010
From: datkins at u.washington.edu (David Atkins)
Date: Fri, 25 Jun 2010 09:24:45 -0700
Subject: [R-sig-ME] Data Redux -- Re: Computational speed - MCMCglmm/lmer
In-Reply-To: <AANLkTinnELwi2CVvniEpwbXVXoR9I2jb22Qiiein6NcD@mail.gmail.com>
References: <4C1CE581.9030205@u.washington.edu>	<AANLkTimm7BPOARDPXgW_mTHNngu_sbKjPPgVlS6FSqQf@mail.gmail.com>	<AANLkTim89W3S3AN2qSc2wK1PzGvUxmgLZIZ-gFfaJK8i@mail.gmail.com>	<AANLkTimZMBFRXKD9g1k_bxiEewv4Cuik9gNBFZrUr7ns@mail.gmail.com>	<4C225535.30505@u.washington.edu>	<AANLkTimGL8N1nsaSJd8nbga5iqGeVtorcebX4vTSb_eb@mail.gmail.com>
	<AANLkTinnELwi2CVvniEpwbXVXoR9I2jb22Qiiein6NcD@mail.gmail.com>
Message-ID: <4C24D84D.2000307@u.washington.edu>


Douglas Bates wrote:
> Thanks for sending the cleaned up version of the data, Dave.
> 
> First, it seems to me that the model should include the fratsor
> variable and perhaps an interaction with gender.  This will make it
> difficult to fit (because it has even more fixed-effects parameters)
> and I would suggest replacing weekday by a factor with three levels
> "Sun-Wed", "Thu" and "Fri-Sat".  See the enclosed plot for why I would
> suggest that.  Alternatively you could consider a binary variable of
> Sun-Wed and Thu-Sat.
> There definitely does seem to be a peak at Friday, especially in the
> Frat/Sor group and a drop-off to Saturday.  Interestingly Thursday
> seems to have heavier consumption by the Frat/Sor group than Saturday
> (I was wondering why attendance seems a little thin for my 8:00 a.m.
> Intro Engineering Statistics class on Fridays).

Agreed; one of the tricky things we regularly wrestle with (with such 
data) is how best to model the week effects.  A colleague and I have 
taken a look at possibly using cyclical terms (inspired, in part, by 
models in P&B).  There clearly is a *cycle* over weeks, it just ain't 
terribly smooth in its rising and falling.

[If anybody has any additional, creative thoughts on this one... I'm all 
ears.  There are a lot of daily alcohol studies, and this is a perennial 
thorn in the side during the analyses...]

The most common thing to find in the alcohol literature is either a 
dummy-code for weekend/weekday (where Thurs "switch hits" depending on 
the paper), or what you suggest: Sun-Wed, Thurs, Fri-Sat.  Letting day 
of week be a fully dummy-coded factor often leads to better fit based on 
model criteria (though, not universally with BIC for obvious reasons), 
but the tricky part is that we almost always want interactions with 
these changes, and interactions with 6 dummy-codes for day of week just 
"blossoms" the model incredibly.

Thanks for the substantive as well as computational thoughts; a few more 
comments from me below.

> Second, there is a good news/bad news situation regarding the
> development version of glmer.  I have introduced a coarser method of
> getting estimates selected with the optional argument nAGQ = 0.  It is
> more complicated to explain than I would like to embark on here but
> suffice to say it is much faster and gets good estimates but not
> the best.  At this point the output will look suspicious because I needed to
> turn off the system.time in the batch run, probably because of a
> memory protection issue that I will need to resolve.

This would actually be pretty attractive to me, as I don't mind 
"cooking" a final model for quite a while either using (g)lmer or 
MCMCglmm, but long running models can be trying when you're doing 
initial runs working toward a final model.

Per usual, many thanks for your expertise, code, and willingness to 
contribute.

cheers, Dave

> 
> Timing this fit works interactively for me but not in a batch run
> 
>> system.time(
> + drk0.glmer <- glmer(drinks ~ weekday*gender + (1 | id),
> +                                        data = drink.df, family = poisson,
> +                                        verbose = TRUE, nAGQ=0L)
> + )
> npt = 3 , n =  1
> rhobeg =  0.2 , rhoend =  2e-07
>   0.020:   3:      146545.; 1.00000
>  0.0020:   3:      146545.; 1.00000
>  0.00020:  10:      146543.;0.960752
>  2.0e-05:  12:      146543.;0.960984
>  2.0e-06:  15:      146543.;0.960974
>  2.0e-07:  15:      146543.;0.960974
> At return
>  17:     146542.78: 0.960974
>   user  system elapsed
>  16.870   0.080  17.029
> 
> So 17 seconds elapsed time is pretty good.  The full Laplacian fit
> took about 300 seconds and gave only a slightly better deviance.
> Regrettably I have seen situations where the full Laplacian fit is
> considerably better so I can't recommend avoiding the full Laplacian
> fit entirely.  I do think that the fit with nAGQ = 0 is okay for coarse model
> building where you need rough comparisons of several different models.
> 
> 
> On Wed, Jun 23, 2010 at 1:40 PM, David Atkins <datkins at u.washington.edu> wrote:
>> First, my apologies for not providing clean data in my initial posting,
>> which was clearly an oversight on my part.  I have an email in to the PI but
>> haven't gotten a response yet.
>>
>> I have attached an updated dataset, that pulls out the 2 suspect
>> participants as well as those with gender coded 2.  In addition, it includes
>> two more variables:
>>
>> weekday - 7 level factor for day of week (new variable weekend now has the
>> binary version)
>> fratsor - a binary factor indicating whether individual is part of a
>> fraternity or sorority (or not)
>>
>> I have an updated script below that shows (descriptively) how drinking
>> varies over these factors.  Moreover, including weekday as either fixed or
>> random, really ratchets up the time for glmer.  Again, my original purpose
>> is definitely *not* to criticize lme4 (or Doug), but simply to get some
>> feedback about computational speed, and whether or not it's possible to
>> speed up runs via hardware, OS, or software.
>>
>> Finally, in providing some data, I was trying to provide a brief subset of
>> data that has certain realistic qualities (and it is real data) but is not a
>> "full" data set.  In trying to be simple and straightforward, I may have
>> raised more questions.
>>
>> So, in response to a few questions raised:
>>
>> The data come from a study of problematic drinking focused on high-risk
>> events, and this particular data focused on 21st birthdays (here in the US,
>> that is the legal drinking age).  The present data are from a survey (ie,
>> non-intervention), which then informed a later intervention study.  Thus,
>> the (up to) 90 days of retrospective drinking, will cover the individual's
>> 21st birthday.
>>
>> Doug asks about someone reporting 45 drinks.  Because we are capturing 21st
>> birthdays, we are definitely getting some extreme drinking, but we also are
>> relying on self-report.  Clearly, there will be some errors and possible
>> bravado about feats of drinking.  Moreover, the study has a protocol for
>> addressing potentially dangerous levels of drinking with participants (when
>> blood-alcohol content passes a certain cutoff).
>>
>> Hadley asks about the repeated data.  Part of the study involves friends of
>> the main participant (as one intervention condition includes friends input
>> as part of the intervention).  Some of the friend's data were included in a
>> larger version of this dataset, which then led to replicates of the
>> participant's data.  Thus, we knew individuals with friend's data had
>> replicates, but this version was supposed to have that cleaned up.
>>
>> Finally, this particular data was collected on a rolling basis, and thus the
>> 90 day recounting of drinking covers a large swath of the calendar year.  We
>> are currently working on a paper that examines student drinking on typical
>> weekdays vs. weekends vs. 21st birthday vs. holidays (including St.
>> Patrick's Day, though July 4th and New Year's Eve are much heavier drinking
>> days...).
>>
>> Hopefully this clarifies certain aspects of the data, and I definitely
>> appreciate folks input on the computational aspects -- I'm certainly
>> learning.
>>
>> [BTW, I'm currently fitting a second model to the one reported below, with a
>> random effect for weekday -- currently at 30 minutes and counting.]



From datkins at u.washington.edu  Fri Jun 25 18:31:02 2010
From: datkins at u.washington.edu (David Atkins)
Date: Fri, 25 Jun 2010 09:31:02 -0700
Subject: [R-sig-ME] Summary -- Re:  Computational speed - MCMCglmm/lmer
In-Reply-To: <C33AFF89-6B19-4956-9CF6-FC4C0F3A10A4@ed.ac.uk>
References: <4C1CE581.9030205@u.washington.edu>
	<C33AFF89-6B19-4956-9CF6-FC4C0F3A10A4@ed.ac.uk>
Message-ID: <4C24D9C6.1010300@u.washington.edu>


First, thanks to Doug, Jarrod, Paul, and others who chimed in on this. 
I will take a stab at a summary:

For the most part, it sounds like there are no simple solutions for 
computational time.  Specifically, beyond obvious differences in 
hardware, there may be some minor gains from an optimized BLAS, but as 
Doug notes, this is not a panacea.

Doug and Jarrod both commented on the fact that at its heart, there is a 
single optimization process going on, so it's not clear how this could 
be threaded or parallelized (and it would certainly not be trivial to try).

Finally, Doug has an option in the development version of (g)lmer that 
allows "coarse" but faster fits.  This might be quite useful for initial 
model exploration.

Again, thanks all.

cheers, Dave



Dave Atkins, PhD
Research Associate Professor
Department of Psychiatry and Behavioral Science
University of Washington
datkins at u.washington.edu

Center for the Study of Health and Risk Behaviors (CSHRB)		
1100 NE 45th Street, Suite 300 	
Seattle, WA  98105 	
206-616-3879 	
http://depts.washington.edu/cshrb/
(Mon-Wed)	

Center for Healthcare Improvement, for Addictions, Mental Illness,
   Medically Vulnerable Populations (CHAMMP)
325 9th Avenue, 2HH-15
Box 359911
Seattle, WA 98104
http://www.chammp.org
(Thurs)


Jarrod Hadfield wrote:
> Hi Dave,
> 
> Sorry for the late response on this  - I've been doing field work.   I 
> think there is little option for speeding up the time per iteration in 
> MCMCglmm without considerable extra work. Most cpu are spent either 
> solving the mixed model equations or generating random (normal) 
> deviates.  It may be possible to multi-thread the latter but how easy 
> this would be and how much of an increase in speed you would get I'm not 
> sure.  For ZIP models at least, the long computing time is a result of 
> poor mixing. The next version (as you know) will allow hurdle models to 
> be fitted.  These have much better mixing properties and in terms of 
> model fit are very similar to ZIP models.
> 
> Cheers,
> 
> Jarrod
> On 19 Jun 2010, at 16:42, David Atkins wrote:
> 
>>
>> Hi all--
>>
>> I use (g)lmer and MCMCglmm on a weekly basis, and I am wondering about 
>> options for speeding up their computations.  This is primarily an 
>> issue with MCMCglmm, given the many necessary MCMC iterations to get 
>> to convergence on some problems.  But, even with glmer(), I have runs 
>> that get into 20-30 minutes.
>>
>> First, let me be very clear that this is in no way a criticism of 
>> Doug's and Jarrod's work (package developers for lme4 and MCMCglmm, 
>> respectively).  Their code has probably brought models/data into range 
>> that would not have been possible.
>>
>> Second, I have included link to data and script below, along with some 
>> timings on my computer: Mac Book Pro, 2.5GHz, with 4GB RAM.  Here's 
>> sessionInfo from my runs:
>>
>> > sessionInfo()
>> R version 2.11.1 (2010-05-31)
>> i386-apple-darwin9.8.0
>>
>> locale:
>> [1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] MCMCglmm_2.05      corpcor_1.5.6      ape_2.5-3
>> [4] coda_0.13-5        tensorA_0.35       lme4_0.999375-34
>> [7] Matrix_0.999375-41 lattice_0.19-7
>>
>> loaded via a namespace (and not attached):
>> [1] gee_4.13-14   grid_2.11.1   nlme_3.1-96   stats4_2.11.1 tools_2.11.1
>>
>> Specific questions:
>>
>> 1. Would be curious to know timings on other people's set-ups.  Jarrod 
>> and I had an exchange one time where he was gracious enough to run a 
>> zero-inflated model where I was concerned about convergence.  He ran a 
>> model with 1.3M iterations, which I think would take a number of days, 
>> if not a week on my computer.  This was part of what got me thinking 
>> about this.  Thus, my first interest is whether there is an "optimal" 
>> hardware/OS configuration, or does it matter?
>>
>> Some things I see in R-help archives:
>>
>> 2. 32 vs. 64-bit: Seems like this is mostly an issue of data/model 
>> size and whether you need to access more than 4GB of RAM.  AFAICS, 
>> 64-bit processors are not necessarily faster.
>>
>> 3. "Optimized" BLAS: There's a bit of discussion about optimized BLAS 
>> (basis linear algebra... something).  However, these discussions note 
>> that there is no generally superior BLAS.  Not sure whether specific 
>> BLAS might be optimized for GLMM computations.
>>
>> 4. Parallel computing: With multi-core computers, looks like there are 
>> some avenues for splitting intensive computations across processors.
>>
>> Finally, I'm asking here b/c I run into these issues with GLMM (and 
>> zero-inflated mixed models), though most of the discussion I've seen 
>> thus far about computation speed has been on R-help.
>>
>> The data below are self-reported drinks (alcohol) from college 
>> students for up to the last 90 days.  Distribution of counts is 
>> zero-inflated.  I run a Poisson GLMM with glmer, over-dispersed 
>> Poisson GLMM with MCMCglmm, and then zero-inflated OD Poisson with 
>> MCMCglmm and provide timings for my set-up.
>>
>> Okay, any and all thoughts welcomed.
>>
>> thanks, Dave
>>
>>
>> ### thinking through computational speed with lmer and MCMCglmm
>> #
>> ### read drinking data
>> drink.df <- read.table(file = 
>> "http://depts.washington.edu/cshrb/newweb/stats%20documents/tlfb.txt",
>>                         header = TRUE, sep = "\t")
>> str(drink.df) # 57K rows
>>
>> ### id is id variable (shocking)
>> ### gender and weekday are 0/1 indicator variables
>> ### drinks has number of drinks consumed
>>
>> ### distribution of outcome
>> table(drink.df$drinks)
>> plot(table(drink.df$drinks), lwd=2) # zero-inflated
>>
>> ### how many people?
>> length(unique(drink.df$id)) # 990
>> sort(table(drink.df$id))
>>
>> ### NOTE: most people have max of 90, which they should
>> ###            two folks with 180 and 435 (prob data errors)
>> ###            long negative tail down from 90
>> #
>> ### NOTE: for this purpose, not worrying about the 180/435
>>
>> ### speed tests
>> #
>> ### fit random intercept and random slope for weekday
>> ### fixed effects for gender and weekday and interaction
>> #
>> ### Poisson GLMM with glmer()
>> library(lme4)
>>
>> system.time(
>> drk.glmer <- glmer(drinks ~ weekday*gender + (weekday | id),
>>                     data = drink.df, family = poisson,
>>                     verbose = TRUE)
>> )
>> summary(drk.glmer)
>>
>> ### timing
>> #
>> ###    user  system elapsed
>> ###  36.326   9.013  45.316
>>                    
>> ### over-dispersed Poisson GLMM with MCMCglmm()
>> library(MCMCglmm)
>>
>> prior <- list(R = list(V = 1, n = 1),
>>                 G = list(G1 = list(V = diag(2), n = 2)))
>> system.time(
>> drk.mcmc <- MCMCglmm(drinks ~ weekday*gender,
>>                     random = ~ us(1 + weekday):id,
>>                     data = drink.df, family = "poisson",
>>                     prior = prior)
>> )
>> summary(drk.mcmc) # NOTE: using summary.MCMCglmm in v 2.05 of package
>>
>> ### timing
>> #
>> ###        user   system  elapsed
>> ###     1034.317  165.128 1203.536
>>
>> ### zero-inflated, over-dispersed Poisson GLMM with MCMCglmm()
>> #
>> ### NOTE: haven't run the following yet, other than a quick "toy run" to
>> ###            sure that it is set up correctly.
>> ### NOTE: this only has random intercept in each portion of the model
>>
>> prior2 <- list(R = list(V = diag(2), n = 1, fix = 2),
>>                 G = list(G1 = list(V = 1, n = 1),
>>                           G2 = list(V = 1, n = 1)))
>> system.time(
>> drk.zimcmc <- MCMCglmm(drinks ~ -1 + trait*weekday*gender,
>>                     random = ~ idh(at.level(trait, 1)):id + 
>> idh(at.level(trait, 2)):id,
>>                     rcov = ~ idh(trait):units,
>>                     data = drink.df, family = "zipoisson",
>>                     prior = prior2)
>> )
>> summary(drk.zimcmc)
>>
>> ### timing
>> #
>> ###         user   system  elapsed
>> ###    2105.366  544.881 2640.030
>>
>> -- 
>> Dave Atkins, PhD
>> Research Associate Professor
>> Department of Psychiatry and Behavioral Science
>> University of Washington
>> datkins at u.washington.edu
>>
>> Center for the Study of Health and Risk Behaviors (CSHRB)       
>> 1100 NE 45th Street, Suite 300    
>> Seattle, WA  98105    
>> 206-616-3879    
>> http://depts.washington.edu/cshrb/
>> (Mon-Wed)   
>>
>> Center for Healthcare Improvement, for Addictions, Mental Illness,
>>  Medically Vulnerable Populations (CHAMMP)
>> 325 9th Avenue, 2HH-15
>> Box 359911
>> Seattle, WA 98104?
>> 206-897-4210
>> http://www.chammp.org
>> (Thurs)
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
>



From datkins at u.washington.edu  Fri Jun 25 19:15:40 2010
From: datkins at u.washington.edu (David Atkins)
Date: Fri, 25 Jun 2010 10:15:40 -0700
Subject: [R-sig-ME] Fwd:  lme4, lme4a,
 and overdispersed distributions (again)
In-Reply-To: <9972FE5C-7E13-41E5-A3A3-46238B81266A@anu.edu.au>
References: <9972FE5C-7E13-41E5-A3A3-46238B81266A@anu.edu.au>
Message-ID: <4C24E43C.9050207@u.washington.edu>


John et al.--

Actually, looks like the current version of glmer *does* allow 
observation level random-effects, though it throws you a little warning 
(which seems entirely appropriate). (Thank you Doug!)

Using the data that we were recently discussing (and attached to one of 
my previous posts "Data Redux"):

 > drink.df$over <- 1:nrow(drink.df)
 > drk.glmer <- glmer(drinks ~ weekday*gender + (1 | id) + (1 | over),
+ 					data = drink.df, family = poisson,
+ 					verbose = TRUE)
Number of levels of a grouping factor for the random effects
is *equal* to n, the number of observations
   0:     96443.694:  1.63299 0.215642 -0.912787 -0.0135537 0.0244628 
-0.0137854 0.504067  1.13637  1.06483 0.418800 0.366592 0.288067 
0.354827 0.443268 0.392234 0.287877

[snip]

  76:     73629.541:  4.35359 0.187209 -5.44079 -0.101647 -0.0249078 
-0.0721097 0.513271  1.65032  1.51045 0.132999 0.435110 0.356431 
0.382994 0.600458  1.26700 0.797529

 > summary(drk.glmer)
Generalized linear mixed model fit by the Laplace approximation
Formula: drinks ~ weekday * gender + (1 | id) + (1 | over)
    Data: drink.df
    AIC   BIC logLik deviance
  73662 73805 -36815    73630
Random effects:
  Groups Name        Variance  Std.Dev.
  over   (Intercept) 18.953746 4.35359
  id     (Intercept)  0.035047 0.18721
Number of obs: 56199, groups: over, 56199; id, 980

Fixed effects:
                          Estimate Std. Error z value Pr(>|z|)
(Intercept)              -5.44079    0.15315  -35.53  < 2e-16 ***
weekdayMonday            -0.10165    0.22164   -0.46  0.64651
weekdayTuesday           -0.02491    0.21837   -0.11  0.90919
weekdayWednesday         -0.07211    0.22089   -0.33  0.74408
weekdayThursday           0.51327    0.19953    2.57  0.01010 *
weekdayFriday             1.65032    0.17918    9.21  < 2e-16 ***
weekdaySaturday           1.51045    0.18023    8.38  < 2e-16 ***
genderM                   0.13300    0.22493    0.59  0.55432
weekdayMonday:genderM     0.43511    0.31295    1.39  0.16442
weekdayTuesday:genderM    0.35643    0.31078    1.15  0.25142
weekdayWednesday:genderM  0.38299    0.31327    1.22  0.22150
weekdayThursday:genderM   0.60046    0.28439    2.11  0.03474 *
weekdayFriday:genderM     1.26700    0.25845    4.90 9.48e-07 ***
weekdaySaturday:genderM   0.79712    0.26107    3.05  0.00226 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

As an aside, it is interesting to see for this particular data how the 
variance swings pretty wildly between the model without over-dispersion 
to the current one:

 > summary(drk.glmer)
Generalized linear mixed model fit by the Laplace approximation
Formula: drinks ~ weekday * gender + (1 | id)
    Data: drink.df
     AIC    BIC logLik deviance
  146572 146706 -73271   146542
Random effects:
  Groups Name        Variance Std.Dev.
  id     (Intercept) 0.92314  0.9608
Number of obs: 56199, groups: id, 980

Fixed effects:
                          Estimate Std. Error z value Pr(>|z|)
(Intercept)              -1.23639    0.04863  -25.42  < 2e-16 ***
weekdayMonday            -0.01035    0.03331   -0.31    0.756
weekdayTuesday            0.02583    0.03304    0.78    0.434
weekdayWednesday         -0.01161    0.03341   -0.35    0.728
weekdayThursday           0.50049    0.02976   16.82  < 2e-16 ***
weekdayFriday             1.12677    0.02691   41.87  < 2e-16 ***
weekdaySaturday           1.05954    0.02709   39.11  < 2e-16 ***
genderM                   0.30064    0.07099    4.24 2.28e-05 ***
weekdayMonday:genderM     0.36970    0.04359    8.48  < 2e-16 ***
weekdayTuesday:genderM    0.29552    0.04358    6.78 1.19e-11 ***
weekdayWednesday:genderM  0.36295    0.04378    8.29  < 2e-16 ***
weekdayThursday:genderM   0.45315    0.03913   11.58  < 2e-16 ***
weekdayFriday:genderM     0.40290    0.03587   11.23  < 2e-16 ***
weekdaySaturday:genderM   0.29764    0.03624    8.21  < 2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

These data in all likelihood are probably best modeled by a two-part 
model, with zero vs. non-zero and count model for non-zeroes.  The 
current version of MCMCglmm allows for zero-inflated models (where 
zeroes are a mixture of a point mass and count distribution), and the 
development version has hurdle formulations (with zero vs. non-zero, and 
then truncated count distribution for non-zeroes).

cheers, Dave

John Maindonald wrote:

I think it more accurate to say that, in general, there may be
a class of distributions, and therefore a possible multiplicity
of likelihoods, not necessarily for distributions of exponential
form.  This is a PhD thesis asking to be done, or maybe
someone has already done it.

Over-dispersed distributions, where it is entirely clear what the
distribution is, can be generated as GLM model +  one random
effect per observation.  We have discussed this before.  This
seems to me the preferred way to go, if such a model seems to
fit the data.  I've not checked the current state of play re fitting
such models in lme4 of lme4a; in the past some versions have
allowed such a model.

I like the simplicity of the one random effect per observation
approach, as against what can seem the convoluted theoretical
framework in which beta binomials live.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

 >
 > On 25/06/2010, at 3:59 AM, Jeffrey Evans wrote:
 >
 >> Since I am definitely *not* a mathematician, I am straying in over 
my head
 >> here.
 >>
 >> I understand what you are saying - that there isn't a likelihood 
function
 >> for the quasi-binomial "distribution". And therefore, there is no-such
 >> distribution.
 >>
 >> What do you think of the suggestion that a beta-binomial mixture
 >> distribution could be used to model overdispersed binomial data?
 >>
 >> Would this be a techinically correct and logistically feasibile 
solution?
 >>
 >> -jeff
 >>
 >> -----Original Message-----
 >> From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf 
Of Douglas
 >> Bates
 >> Sent: Thursday, June 24, 2010 1:25 PM
 >> To: Jeffrey Evans
 >> Cc: r-sig-mixed-models at r-project.org
 >> Subject: Re: [R-sig-ME] lme4, lme4a, and overdispersed distributions 
(again)
 >>
 >> On Thu, Jun 24, 2010 at 11:54 AM, Jeffrey Evans
 >> <Jeffrey.Evans at dartmouth.edu> wrote:
 >>> Like others, I have experienced trouble with estimation of the scale
 >>> parameter using the quasi-distributions in lme4, which is necessary to
 >>> calculate QAICc and rank overdispersed generalized linear mixed models.
 >>
 >>> I had several exchanges with Ben Bolker about this early last year
 >>> after his TREE paper came out
 >>> (http://www.cell.com/trends/ecology-evolution/abstract/S0169-5347%2809
 >>> %29000 19-6), and I know it's been discussed on on this list. Has
 >>> there been or is there any potential resolution to this forthcoming in
 >>> future releases of
 >>> lme4 or lme4a? I run into overdispersed binomial distributions
 >>> frequently and have had to use SAS to deal with them. SAS appears to
 >>> work, but it won't estimate the overdispersion parameter using laplace
 >>> estimation (only PQL), As I understand it, these pseudo-Iikelihoods
 >>> can't be used for model ranking. I don't know why SAS can't/won't, but
 >>> lme4 will run these quasi-binomial and quasi-poisson distributions with
 >> Laplace estimation.
 >>
 >>> Is there a workable way to use lme4 for modeling overdispersed
 >>> binomial data?
 >>
 >> I have trouble discussing this because I come from a background as a
 >> mathematician and am used to tracing derivations back to the original
 >> definitions.  So when I think of a likelihood (or, equivalently, a
 >> deviance) to be optimized it only makes sense to me if there is a
 >> probability distribution associated with the model.  And for the
 >> quasi-binomial and quasi-Poisson families, there isn't a probability
 >> distribution.  To me that means that discussing maximum likelihood
 >> estimators for such models is nonsense.  The models simply do not exist.
 >> One can play tricks in the case of a generalized linear model to 
estimate a
 >> "quasi-parameter" that isn't part of the probability distribution 
but it is
 >> foolhardy to expect that the tricks will automatically carry over to a
 >> generalized linear mixed model.
 >>
 >> I am not denying that data that are over-dispersed with respect to the
 >> binomial or Poisson distributions can and do occur.  But having data 
like
 >> this and a desire to model it doesn't make the quasi families real. 
  In his
 >> signature Thierry Onkelinx quotes
 >>
 >> The combination of some data and an aching desire for an answer does not
 >> ensure that a reasonable answer can be extracted from a given body 
of data.
 >> ~ John Tukey
 >>
 >> I could and do plan to incorporate the negative binomial family but, 
without
 >> a definition that I can understand of a quasi-binomial or quasi-Poisson
 >> distribution and its associated probability function, I'm stuck. To 
me it's
 >> a "build bricks without straw" situation - you can't find maximum 
likelihood
 >> estimates for parameters that aren't part of the likelihood.
 >>
 >> _______________________________________________
 >> R-sig-mixed-models at r-project.org mailing list
 >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
 >

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm


-- 
Dave Atkins, PhD
Research Associate Professor
Department of Psychiatry and Behavioral Science
University of Washington
datkins at u.washington.edu

Center for the Study of Health and Risk Behaviors (CSHRB)		
1100 NE 45th Street, Suite 300 	
Seattle, WA  98105 	
206-616-3879 	
http://depts.washington.edu/cshrb/
(Mon-Wed)	

Center for Healthcare Improvement, for Addictions, Mental Illness,
   Medically Vulnerable Populations (CHAMMP)
325 9th Avenue, 2HH-15
Box 359911
Seattle, WA 98104
http://www.chammp.org
(Thurs)



From bates at stat.wisc.edu  Fri Jun 25 22:39:22 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 25 Jun 2010 15:39:22 -0500
Subject: [R-sig-ME] Status of the development package lme4a
Message-ID: <AANLkTilR_5pEYT_SbzjNv9AgUbAYsmcsAhUKi4DL4Zia@mail.gmail.com>

I have often referred to the development version of the lme4 package,
called lme4a.  At the risk of annoying people who don't want to hear
more about a package that they can't yet use, I provide this update.

The sources for lme4a are available from the SVN archive on R-forge
but binary packages are not.  I hope that will change in the near
future.

I have switched to using the marvelous Rcpp package created by Dirk
Eddelbuettel and Romain Fran?ois, which I heartily recommend to those
writing C++/C code to be loaded into R.  Recently Romain has been on a
"code rant" creating "syntactic sugar" that makes it much easier to
write expressions using R vectors in C++ and it has just been too
tempting for me to use these capabilities.  That is why binary
packages are not available. Some of the code in the lme4a package
depends on the "Rcpp du jour", more or less, and doesn't build on
systems like win-builder or R-forge because of that dependency.  When
Dirk and Romain are ready to release Rcpp_0.8.3 to CRAN we'll be able
to pursue making binary packages available.

Another change from lme4 to lme4a is the use of the bobyqa optimizer
from the minqa package, instead of the nlminb optimizer.  Generally I
have been pleased with the results from bobyqa but I am always on the
lookout for good optimizers that will handle nonlinear objective
functions subject to box constraints on the parameters.  The lme4a
code is constructed so that the user can create a function to evaluate
the deviance without doing the actual optimization to get the
parameter estimates.  This allows for experimentation with other
optimizers.  At this summer's useR! conference Stefan Theussl, Kurt
Hornik and David Meyer will talk about their R Optimization
Infrastructure package and I look forward to perhaps writing a generic
interface to several different optimizers through that.  (Note to
Stefan et al: and I would also like to write the interface glue for
the optimizers in the minqa package for ROI, once you document what
must be written.)

Generally I am pleased with both the quality of the results and the
speed of the package.  For glmer and nlmer there are two optimizations
- the first involving only the variance-component parameters and the
second involving the variance component parameters and the fixed
effects.  A value of 0 for the optional argument nAGQ suppresses the
second optimization, which can take much longer than the first.  In
many cases the second optimization doesn't improve the result much but
I have seen cases where the result from the second optimization is
considerably better than that from the first.  (It should always be at
least as good as the first because the converged values from the first
optimization are used as the starting values for the second.)  I
enclose an example where there is a big difference. This is a slight
modification of the R code in Doran, Bates, Bliese and Dowling
(http://www.jstatsoft.org/v20/i02).  The good news is that the results
from these model fits are better than the results quoted in that paper
(the bad news is that we should now post a correction).

As I mentioned in a thread started by Dave Atkins, the optional
argument nAGQ to glmer and nlmer can be given the value 0, in which
case a faster algorithm that iterates over the variance-component
parameters only is used.
-------------- next part --------------

R version 2.11.1 (2010-05-31)
Copyright (C) 2010 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ###################################################
> ### chunk number 1: preliminaries
> ###################################################
> library("lme4a")
Loading required package: Matrix
Loading required package: lattice

Attaching package: 'Matrix'

The following object(s) are masked from 'package:base':

    det

Loading required package: minqa
Loading required package: Rcpp

Attaching package: 'lme4a'

The following object(s) are masked from 'package:stats':

    AIC

> 
> 
> ###################################################
> ### chunk number 2: conversion
> ###################################################
> data("lq2002", package = "multilevel")
> wrk <- lq2002
> for (i in 3:16) wrk[[i]] <- ordered(wrk[[i]])
> for (i in 17:21) wrk[[i]] <- ordered(5 - wrk[[i]])
> lql <- within(reshape(wrk, varying = list(names(lq2002)[3:21]), v.names = "fivelev",
+                       idvar = "subj", timevar = "item", drop = names(lq2002)[c(2,22:27)],
+                       direction = "long"),
+           {
+               itype <- factor(ifelse(item < 12, "Leadership",
+                                      ifelse(item < 15, "Task Sig.", "Hostility")))
+               COMPID <- factor(COMPID)
+               item <- factor(item)
+               dichot <- factor(ifelse(fivelev < 4, 0, 1))
+               subj <- factor(subj)
+           })
> 
> 
> ###################################################
> ### chunk number 3: conv2
> ###################################################
> attr(lql,"reshapeLong") <- NULL
> lnkinv <- binomial()$linkinv
> 
> 
> ###################################################
> ### chunk number 4: lqlstr
> ###################################################
> str(lql)
'data.frame':	38798 obs. of  6 variables:
 $ COMPID : Factor w/ 49 levels "2","3","4","5",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ item   : Factor w/ 19 levels "1","2","3","4",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ fivelev: Ord.factor w/ 5 levels "1"<"2"<"3"<"4"<..: 2 4 4 1 1 2 3 3 3 4 ...
 $ subj   : Factor w/ 2042 levels "1","2","3","4",..: 1 2 3 4 5 6 7 8 9 10 ...
 $ dichot : Factor w/ 2 levels "0","1": 1 2 2 1 1 1 1 1 1 2 ...
 $ itype  : Factor w/ 3 levels "Hostility","Leadership",..: 2 2 2 2 2 2 2 2 2 2 ...
> summary(lql)
     COMPID           item       fivelev        subj       dichot   
 13     : 1881   1      : 2042   1: 5208   1      :   19   0:19444  
 18     : 1786   2      : 2042   2: 5357   2      :   19   1:19354  
 46     : 1710   3      : 2042   3: 8879   3      :   19            
 15     : 1691   4      : 2042   4:11353   4      :   19            
 29     : 1615   5      : 2042   5: 8001   5      :   19            
 34     : 1482   6      : 2042             6      :   19            
 (Other):28633   (Other):26546             (Other):38684            
        itype      
 Hostility :10210  
 Leadership:22462  
 Task Sig. : 6126  
                   
                   
                   
                   
> 
> 
> ###################################################
> ### chunk number 5: fm1
> ###################################################
> (fm1 <- glmer(dichot ~ 0+itype+(1|subj)+(1|COMPID)+(1|item), lql, binomial, verbose = 1L))
npt = 7 , n =  3 
rhobeg =  0.2 , rhoend =  2e-07 
   0.020:  11:      40741.2; 1.35123 0.495665 0.564184 
  0.0020:  33:      40710.8; 1.50829 0.494469 0.531752 
 0.00020:  61:      40709.9; 1.51809 0.504002 0.615309 
 2.0e-05:  68:      40709.9; 1.51838 0.504114 0.613816 
 2.0e-06:  73:      40709.9; 1.51838 0.504112 0.613836 
 2.0e-07:  79:      40709.9; 1.51838 0.504114 0.613840 
At return
 86:     40709.884:  1.51838 0.504114 0.613840
npt = 12 , n =  6 
rhobeg =  0.3190403 , rhoend =  3.190403e-07 
   0.032:  13:      40709.9; 1.51838 0.504114 0.613840  1.59520 -0.473858 -0.131846 
  0.0032:  22:      40692.4; 1.57441 0.523403 0.634852  1.63328 -0.490345 -0.144524 
 0.00032:  39:      40689.2; 1.60306 0.534949 0.643919  1.67542 -0.495931 -0.141326 
 3.2e-05:  46:      40689.2; 1.60328 0.535336 0.644220  1.67589 -0.496257 -0.140769 
 3.2e-06:  55:      40689.2; 1.60332 0.535302 0.644204  1.67591 -0.496281 -0.140763 
 3.2e-07:  63:      40689.2; 1.60332 0.535303 0.644200  1.67591 -0.496282 -0.140763 
At return
 77:     40689.248:  1.60332 0.535302 0.644201  1.67591 -0.496282 -0.140764
Generalized linear mixed model fit by maximum likelihood ['merMod']
 Family: binomial 
Formula: dichot ~ 0 + itype + (1 | subj) + (1 | COMPID) + (1 | item) 
   Data: lql 
      AIC       BIC    logLik  deviance 
 40701.25  40752.64 -20344.62  40689.25 

Random effects:
 Groups Name        Variance Std.Dev.
 subj   (Intercept) 2.5706   1.6033  
 COMPID (Intercept) 0.2865   0.5353  
 item   (Intercept) 0.4150   0.6442  
Number of obs: 38798, groups: subj, 2042; COMPID, 49; item, 19

Fixed effects:
                Estimate Std. Error z value
itypeHostility    1.6759     0.3026   5.538
itypeLeadership  -0.4963     0.2139  -2.320
itypeTask Sig.   -0.1408     0.3835  -0.367

Correlation of Fixed Effects:
            itypHs itypLd
itypeLdrshp 0.120        
itypeTskSg. 0.067  0.095 
> 
> 
> ###################################################
> ### chunk number 6: fm1ranef
> ###################################################
> rr <- ranef(fm1, postVar = TRUE)
> str(rr$COMPID)
'data.frame':	49 obs. of  1 variable:
 $ (Intercept): num  0.0332 -0.0456 -0.2194 0.0255 0.1012 ...
 - attr(*, "postVar")= num [1, 1, 1:49] 0.0893 0.0649 0.0567 0.047 0.1325 ...
> head(rr$COMPID)
  (Intercept)
2  0.03322195
3 -0.04559110
4 -0.21944834
5  0.02549450
6  0.10115283
7  0.36494211
> 
> 
> ###################################################
> ### chunk number 7: fm1subj
> ###################################################
> qq <- qqmath(rr)
> print(qq$subj)
> 
> 
> ###################################################
> ### chunk number 8: fm1comp
> ###################################################
> print(qq$COMPID)
> 
> 
> ###################################################
> ### chunk number 9: fm1item
> ###################################################
> print(qq$item)
> 
> 
> ###################################################
> ### chunk number 10: fm2
> ###################################################
> (fm2 <- glmer(dichot ~ 0 + itype + (1|subj) + (0+itype|COMPID) + (1|item), lql, binomial, verbose = 1L))
npt = 14 , n =  8 
rhobeg =  0.2 , rhoend =  2e-07 
   0.020:  20:      40350.7; 1.39862 0.542358 0.180288 0.147768 0.420898 0.0125334 0.506361 0.739096 
  0.0020:  60:      40312.0; 1.53517 0.639396 0.410296 0.397523 0.464948 -0.224284 0.487233 0.646907 
 0.00020:  92:      40311.8; 1.54308 0.632955 0.399188 0.418186 0.458937 -0.207663 0.488347 0.620140 
 2.0e-05: 170:      40311.8; 1.54448 0.626989 0.393000 0.413212 0.460822 -0.204481 0.492391 0.627449 
 2.0e-06: 245:      40311.8; 1.54449 0.626270 0.393088 0.410954 0.460661 -0.205147 0.491765 0.626785 
 2.0e-07: 296:      40311.8; 1.54447 0.626253 0.393063 0.410957 0.460655 -0.205147 0.491738 0.626749 
At return
309:     40311.791:  1.54447 0.626253 0.393063 0.410957 0.460655 -0.205147 0.491738 0.626749
npt = 17 , n =  11 
rhobeg =  0.3305596 , rhoend =  3.305596e-07 
   0.033:  18:      40311.8; 1.54447 0.626253 0.393063 0.410957 0.460655 -0.205147 0.491738 0.626749  1.65280 -0.484036 -0.144485 
  0.0033:  36:      40294.2; 1.60488 0.631657 0.423541 0.458069 0.488782 -0.215207 0.516055 0.648040  1.68190 -0.502535 -0.112069 
 0.00033:  80:      40287.9; 1.63652 0.667969 0.420028 0.438087 0.489400 -0.208066 0.519277 0.657647  1.74174 -0.507172 -0.148206 
 3.3e-05: 111:      40287.9; 1.63602 0.664944 0.421462 0.441305 0.489187 -0.207635 0.518033 0.658308  1.74150 -0.507175 -0.148653 
 3.3e-06: 250:      40287.8; 1.63673 0.666256 0.421678 0.443048 0.489561 -0.209605 0.516668 0.657986  1.74346 -0.506651 -0.148784 
 3.3e-07: 809:      40287.8; 1.63706 0.666668 0.421492 0.442301 0.489018 -0.210597 0.516027 0.658385  1.74491 -0.507136 -0.150170 
At return
1233:     40287.829:  1.63713 0.666671 0.421527 0.442126 0.489014 -0.210660 0.516197 0.658422  1.74498 -0.507134 -0.150225
Generalized linear mixed model fit by maximum likelihood ['merMod']
 Family: binomial 
Formula: dichot ~ 0 + itype + (1 | subj) + (0 + itype | COMPID) + (1 |      item) 
   Data: lql 
      AIC       BIC    logLik  deviance 
 40309.83  40404.06 -20143.91  40287.83 

Random effects:
 Groups Name            Variance Std.Dev. Corr       
 subj   (Intercept)     2.6802   1.6371              
 COMPID itypeHostility  0.4445   0.6667              
        itypeLeadership 0.4168   0.6456   0.653      
        itypeTask Sig.  0.5063   0.7116   0.621 0.181
 item   (Intercept)     0.4335   0.6584              
Number of obs: 38798, groups: subj, 2042; COMPID, 49; item, 19

Fixed effects:
                Estimate Std. Error z value
itypeHostility    1.7450     0.3146   5.546
itypeLeadership  -0.5071     0.2242  -2.262
itypeTask Sig.   -0.1502     0.3976  -0.378

Correlation of Fixed Effects:
            itypHs itypLd
itypeLdrshp 0.108        
itypeTskSg. 0.064  0.040 
> 
> 
> ###################################################
> ### chunk number 11: fm2out
> ###################################################
> #print(fm2)
> 
> 
> ###################################################
> ### chunk number 12: fm3
> ###################################################
> (fm3 <- glmer(dichot ~ 0 + itype + (1|subj) + (1|COMPID:itype) + (1|item), lql, binomial, verbose = 1L))
npt = 7 , n =  3 
rhobeg =  0.2 , rhoend =  2e-07 
   0.020:  11:      40394.1; 1.35996 0.442839 0.896775 
  0.0020:  25:      40347.5; 1.51216 0.554390 0.975959 
 0.00020:  47:      40340.2; 1.54972 0.574367 0.624496 
 2.0e-05:  61:      40340.2; 1.54987 0.573398 0.626334 
 2.0e-06:  76:      40340.2; 1.54997 0.573608 0.626665 
 2.0e-07:  84:      40340.2; 1.54997 0.573613 0.626656 
At return
 91:     40340.235:  1.54997 0.573613 0.626656
npt = 12 , n =  6 
rhobeg =  0.3264886 , rhoend =  3.264886e-07 
   0.033:  13:      40340.2; 1.54997 0.573613 0.626656  1.63244 -0.516605 -0.182560 
  0.0033:  22:      40319.6; 1.60634 0.593426 0.650953  1.69948 -0.534045 -0.191250 
 0.00033:  49:      40316.4; 1.64318 0.613330 0.656907  1.71556 -0.540384 -0.184701 
 3.3e-05:  98:      40316.2; 1.64560 0.610322 0.656665  1.72500 -0.543570 -0.186336 
 3.3e-06: 124:      40316.2; 1.64651 0.610800 0.657226  1.72450 -0.543193 -0.187133 
 3.3e-07: 137:      40316.2; 1.64650 0.610804 0.657227  1.72450 -0.543193 -0.187144 
At return
161:     40316.198:  1.64649 0.610802 0.657233  1.72450 -0.543192 -0.187146
Generalized linear mixed model fit by maximum likelihood ['merMod']
 Family: binomial 
Formula: dichot ~ 0 + itype + (1 | subj) + (1 | COMPID:itype) + (1 | item) 
   Data: lql 
      AIC       BIC    logLik  deviance 
 40328.20  40379.59 -20158.10  40316.20 

Random effects:
 Groups       Name        Variance Std.Dev.
 subj         (Intercept) 2.7109   1.6465  
 COMPID:itype (Intercept) 0.3731   0.6108  
 item         (Intercept) 0.4320   0.6572  
Number of obs: 38798, groups: subj, 2042; COMPID:itype, 147; item, 19

Fixed effects:
                Estimate Std. Error z value
itypeHostility    1.7245     0.3116   5.534
itypeLeadership  -0.5432     0.2216  -2.451
itypeTask Sig.   -0.1871     0.3934  -0.476

Correlation of Fixed Effects:
            itypHs itypLd
itypeLdrshp 0.024        
itypeTskSg. 0.014  0.020 
> (fm3a <- glmer(dichot ~ 0 + itype + (1|subj) + (1|COMPID:itype) + (1|COMPID) + (1|item), lql, binomial, verbose = 1L))
npt = 9 , n =  4 
rhobeg =  0.2 , rhoend =  2e-07 
   0.020:  14:      40364.4; 1.37711 0.501643 0.628101 0.816288 
  0.0020:  36:      40328.0; 1.50852 0.454115 0.437267 0.716678 
 0.00020:  78:      40326.0; 1.54465 0.472324 0.438092 0.629258 
 2.0e-05:  95:      40326.0; 1.54406 0.471497 0.433136 0.627481 
 2.0e-06: 111:      40326.0; 1.54409 0.471502 0.433098 0.627292 
 2.0e-07: 124:      40326.0; 1.54408 0.471497 0.433097 0.627273 
At return
134:     40325.999:  1.54408 0.471497 0.433097 0.627273
npt = 13 , n =  7 
rhobeg =  0.331217 , rhoend =  3.31217e-07 
   0.033:  14:      40326.0; 1.54408 0.471497 0.433097 0.627273  1.65608 -0.490604 -0.151649 
  0.0033:  17:      40326.0; 1.54408 0.471497 0.433097 0.627273  1.65608 -0.490604 -0.151649 
 0.00033:  46:      40302.0; 1.63538 0.496953 0.465459 0.659065  1.74911 -0.513849 -0.157569 
 3.3e-05:  63:      40302.0; 1.63667 0.497528 0.464641 0.659300  1.74920 -0.514326 -0.158874 
 3.3e-06:  72:      40302.0; 1.63669 0.497531 0.464599 0.659319  1.74923 -0.514321 -0.158871 
 3.3e-07:  86:      40302.0; 1.63669 0.497531 0.464597 0.659320  1.74923 -0.514329 -0.158881 
At return
 98:     40302.000:  1.63669 0.497531 0.464598 0.659319  1.74923 -0.514329 -0.158881
Generalized linear mixed model fit by maximum likelihood ['merMod']
 Family: binomial 
Formula: dichot ~ 0 + itype + (1 | subj) + (1 | COMPID:itype) + (1 | COMPID) +      (1 | item) 
   Data: lql 
      AIC       BIC    logLik  deviance 
 40316.00  40375.96 -20151.00  40302.00 

Random effects:
 Groups       Name        Variance Std.Dev.
 subj         (Intercept) 2.6788   1.6367  
 COMPID:itype (Intercept) 0.2475   0.4975  
 COMPID       (Intercept) 0.2159   0.4646  
 item         (Intercept) 0.4347   0.6593  
Number of obs: 38798, groups: subj, 2042; COMPID:itype, 147; COMPID, 49; item, 19

Fixed effects:
                Estimate Std. Error z value
itypeHostility    1.7492     0.3157   5.541
itypeLeadership  -0.5143     0.2266  -2.270
itypeTask Sig.   -0.1589     0.3971  -0.400

Correlation of Fixed Effects:
            itypHs itypLd
itypeLdrshp 0.088        
itypeTskSg. 0.050  0.070 
> 
> 
> ###################################################
> ### chunk number 13: fm23comp
> ###################################################
> anova(fm3,fm3a,fm2)
Data: lql
Models:
fm3: dichot ~ 0 + itype + (1 | subj) + (1 | COMPID:itype) + (1 | item)
fm3a: dichot ~ 0 + itype + (1 | subj) + (1 | COMPID:itype) + (1 | COMPID) + 
fm3a:     (1 | item)
fm2: dichot ~ 0 + itype + (1 | subj) + (0 + itype | COMPID) + (1 | 
fm2:     item)
     Df   AIC   BIC logLik  Chisq Chi Df Pr(>Chisq)    
fm3   6 40328 40380 -20158                             
fm3a  7 40316 40376 -20151 14.198      1  0.0001645 ***
fm2  11 40310 40404 -20144 14.171      4  0.0067686 ** 
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 
> 
> 
> ###################################################
> ### chunk number 14: splom
> ###################################################
> rr2 <- ranef(fm2, postVar = TRUE)
> print(splom(rr2$COMPID))
> 
> 
> ###################################################
> ### chunk number 15: cat2
> ###################################################
> qq2 <- qqmath(rr2)
> print(qq2$COMPID)
> 
> 
> ###################################################
> ### chunk number 16: iParams
> ###################################################
> str(imap <- unique(lql[, c("itype", "item")]))
'data.frame':	19 obs. of  2 variables:
 $ itype: Factor w/ 3 levels "Hostility","Leadership",..: 2 2 2 2 2 2 2 2 2 2 ...
 $ item : Factor w/ 19 levels "1","2","3","4",..: 1 2 3 4 5 6 7 8 9 10 ...
> (easiness <- ranef(fm2)$item[[1]] + fixef(fm2)[imap$itype])
itypeLeadership itypeLeadership itypeLeadership itypeLeadership itypeLeadership 
    -0.41119010      0.37121913     -1.43984345     -0.69252265     -1.10502062 
itypeLeadership itypeLeadership itypeLeadership itypeLeadership itypeLeadership 
     0.20917647     -0.85582304      0.37127642     -1.22834689     -0.01874933 
itypeLeadership  itypeTask Sig.  itypeTask Sig.  itypeTask Sig.  itypeHostility 
    -0.75757333     -0.73730287      0.11498491      0.18156054      0.61385233 
 itypeHostility  itypeHostility  itypeHostility  itypeHostility 
     2.47447112      1.41594039      1.73665401      2.49778523 
> 
> 
> ###################################################
> ### chunk number 17: compParams
> ###################################################
> compPar <- t(fixef(fm2) + t(ranef(fm2)$COMPID))
> head(compPar)
  itypeHostility itypeLeadership itypeTask Sig.
2       1.481509     -0.72862096     0.62270773
3       2.137032     -0.75702385     0.16635924
4       1.494098     -1.06671635     0.55629019
5       2.061113     -0.99900157     1.17293550
6       1.948834      0.09073122    -1.00704904
7       2.283477     -0.02442879    -0.06122837
> 
> 
> ###################################################
> ### chunk number 18: compprob
> ###################################################
> head(binomial()$linkinv(compPar))
  itypeHostility itypeLeadership itypeTask Sig.
2      0.8148005       0.3254974      0.6508341
3      0.8944507       0.3192928      0.5414942
4      0.8166925       0.2560280      0.6355937
5      0.8870657       0.2691378      0.7636752
6      0.8753194       0.5226673      0.2675578
7      0.9074993       0.4938931      0.4846977
> 
> proc.time()
    user   system  elapsed 
1073.250   43.970 1205.453 

From adik at ilovebacon.org  Sat Jun 26 01:54:57 2010
From: adik at ilovebacon.org (Adam D. I. Kramer)
Date: Fri, 25 Jun 2010 16:54:57 -0700 (PDT)
Subject: [R-sig-ME] Status of the development package lme4a
In-Reply-To: <AANLkTilR_5pEYT_SbzjNv9AgUbAYsmcsAhUKi4DL4Zia@mail.gmail.com>
References: <AANLkTilR_5pEYT_SbzjNv9AgUbAYsmcsAhUKi4DL4Zia@mail.gmail.com>
Message-ID: <alpine.DEB.2.00.1006251651500.8163@parser.ilovebacon.org>

At risk of annoying people who don't want to hear about a package they can't
use in order to help some other people be ABLE to use the package, for those
who may be new to R-Forge and have trouble getting ahold of lme4a, here is
the method:

svn checkout svn://svn.r-forge.r-project.org/svnroot/lme4

...lme4a is part of the r-forge lme4 package, so if you try the standard
means of installing r-forge packages (e.g.,
install.packages("lme4a",repos="http://r-forge.r-project.org") or the above
but using lme4a instead of lme4, or clicking on the "download lme4a source"
link from the lme4 r-forge group), you will fail.

Hope this helps others suffer less.

--Adam

On Fri, 25 Jun 2010, Douglas Bates wrote:

> I have often referred to the development version of the lme4 package,
> called lme4a.  At the risk of annoying people who don't want to hear
> more about a package that they can't yet use, I provide this update.
>
> The sources for lme4a are available from the SVN archive on R-forge
> but binary packages are not.  I hope that will change in the near
> future.
>
> I have switched to using the marvelous Rcpp package created by Dirk
> Eddelbuettel and Romain Fran?ois, which I heartily recommend to those
> writing C++/C code to be loaded into R.  Recently Romain has been on a
> "code rant" creating "syntactic sugar" that makes it much easier to
> write expressions using R vectors in C++ and it has just been too
> tempting for me to use these capabilities.  That is why binary
> packages are not available. Some of the code in the lme4a package
> depends on the "Rcpp du jour", more or less, and doesn't build on
> systems like win-builder or R-forge because of that dependency.  When
> Dirk and Romain are ready to release Rcpp_0.8.3 to CRAN we'll be able
> to pursue making binary packages available.
>
> Another change from lme4 to lme4a is the use of the bobyqa optimizer
> from the minqa package, instead of the nlminb optimizer.  Generally I
> have been pleased with the results from bobyqa but I am always on the
> lookout for good optimizers that will handle nonlinear objective
> functions subject to box constraints on the parameters.  The lme4a
> code is constructed so that the user can create a function to evaluate
> the deviance without doing the actual optimization to get the
> parameter estimates.  This allows for experimentation with other
> optimizers.  At this summer's useR! conference Stefan Theussl, Kurt
> Hornik and David Meyer will talk about their R Optimization
> Infrastructure package and I look forward to perhaps writing a generic
> interface to several different optimizers through that.  (Note to
> Stefan et al: and I would also like to write the interface glue for
> the optimizers in the minqa package for ROI, once you document what
> must be written.)
>
> Generally I am pleased with both the quality of the results and the
> speed of the package.  For glmer and nlmer there are two optimizations
> - the first involving only the variance-component parameters and the
> second involving the variance component parameters and the fixed
> effects.  A value of 0 for the optional argument nAGQ suppresses the
> second optimization, which can take much longer than the first.  In
> many cases the second optimization doesn't improve the result much but
> I have seen cases where the result from the second optimization is
> considerably better than that from the first.  (It should always be at
> least as good as the first because the converged values from the first
> optimization are used as the starting values for the second.)  I
> enclose an example where there is a big difference. This is a slight
> modification of the R code in Doran, Bates, Bliese and Dowling
> (http://www.jstatsoft.org/v20/i02).  The good news is that the results
> from these model fits are better than the results quoted in that paper
> (the bad news is that we should now post a correction).
>
> As I mentioned in a thread started by Dave Atkins, the optional
> argument nAGQ to glmer and nlmer can be given the value 0, in which
> case a faster algorithm that iterates over the variance-component
> parameters only is used.
>



From lborger at uoguelph.ca  Sat Jun 26 08:15:22 2010
From: lborger at uoguelph.ca (Luca Borger)
Date: Sat, 26 Jun 2010 02:15:22 -0400
Subject: [R-sig-ME] overdispersion and the one random effect per observation
	approach
Message-ID: <DC988A78AE74432B9C8610A9EF646639@lborger>

Dear All,

it has been recently discussed on this list (e.g. see below, as well as 
http://glmm.wikidot.com/faq) that overdispersed distributions can be 
modelled by using an observation-level random effect (i.e. one random effect 
per observation). I am wondering if anyone knows a good reference for this 
approach. John Maindonald kindly pointed me to an example in the new edition 
of his book:

> There is an example in Section 10.5 of the 3rd edition of Data Analysis & 
> Graphics Using R, which is just now out.

Does anyone know other refs? Thanks in advance for your help!


Cheers,

Luca


-------------------
Luca B?rger, PhD
Postdoctoral Research Fellow
Department of Integrative Biology
University of Guelph
Guelph, Ontario, Canada N1G 2W1

office +1 519 824 4120 ext. 52975
lab     +1 519 824 4120 ext. 53594
fax:     +1 519 767 1656

email: lborger at uoguelph.ca
www.researcherid.com/rid/C-6003-2008
http://uoguelph.academia.edu/LucaBorger
--------------------------------------------------------------------




> ----- Original Message ----- From: "John Maindonald" 
> <john.maindonald at anu.edu.au>
> To: <r-sig-mixed-models at r-project.org>
> Sent: Thursday, June 24, 2010 7:11 PM
> Subject: [R-sig-ME] Fwd: lme4, lme4a,and overdispersed distributions 
> (again)
>
>
>> I think it more accurate to say that, in general, there may be
>> a class of distributions, and therefore a possible multiplicity
>> of likelihoods, not necessarily for distributions of exponential
>> form.  This is a PhD thesis asking to be done, or maybe
>> someone has already done it.
>>
>> Over-dispersed distributions, where it is entirely clear what the
>> distribution is, can be generated as GLM model +  one random
>> effect per observation.  We have discussed this before.  This
>> seems to me the preferred way to go, if such a model seems to
>> fit the data.  I've not checked the current state of play re fitting
>> such models in lme4 of lme4a; in the past some versions have
>> allowed such a model.
>>
>> I like the simplicity of the one random effect per observation
>> approach, as against what can seem the convoluted theoretical
>> framework in which beta binomials live.
>>
>> John Maindonald             email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Mathematics & Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>> http://www.maths.anu.edu.au/~johnm
>>
>>>
>>> On 25/06/2010, at 3:59 AM, Jeffrey Evans wrote:
>>>
>>>> Since I am definitely *not* a mathematician, I am straying in over my 
>>>> head
>>>> here.
>>>>
>>>> I understand what you are saying - that there isn't a likelihood 
>>>> function
>>>> for the quasi-binomial "distribution". And therefore, there is no-such
>>>> distribution.
>>>>
>>>> What do you think of the suggestion that a beta-binomial mixture
>>>> distribution could be used to model overdispersed binomial data?
>>>>
>>>> Would this be a techinically correct and logistically feasibile 
>>>> solution?
>>>>
>>>> -jeff
>>>>
>>>> -----Original Message-----
>>>> From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas
>>>> Bates
>>>> Sent: Thursday, June 24, 2010 1:25 PM
>>>> To: Jeffrey Evans
>>>> Cc: r-sig-mixed-models at r-project.org
>>>> Subject: Re: [R-sig-ME] lme4, lme4a, and overdispersed distributions 
>>>> (again)
>>>>
>>>> On Thu, Jun 24, 2010 at 11:54 AM, Jeffrey Evans
>>>> <Jeffrey.Evans at dartmouth.edu> wrote:
>>>>> Like others, I have experienced trouble with estimation of the scale
>>>>> parameter using the quasi-distributions in lme4, which is necessary to
>>>>> calculate QAICc and rank overdispersed generalized linear mixed 
>>>>> models.
>>>>
>>>>> I had several exchanges with Ben Bolker about this early last year
>>>>> after his TREE paper came out
>>>>> (http://www.cell.com/trends/ecology-evolution/abstract/S0169-5347%2809
>>>>> %29000 19-6), and I know it's been discussed on on this list. Has
>>>>> there been or is there any potential resolution to this forthcoming in
>>>>> future releases of
>>>>> lme4 or lme4a? I run into overdispersed binomial distributions
>>>>> frequently and have had to use SAS to deal with them. SAS appears to
>>>>> work, but it won't estimate the overdispersion parameter using laplace
>>>>> estimation (only PQL), As I understand it, these pseudo-Iikelihoods
>>>>> can't be used for model ranking. I don't know why SAS can't/won't, but
>>>>> lme4 will run these quasi-binomial and quasi-poisson distributions 
>>>>> with
>>>> Laplace estimation.
>>>>
>>>>> Is there a workable way to use lme4 for modeling overdispersed
>>>>> binomial data?
>>>>
>>>> I have trouble discussing this because I come from a background as a
>>>> mathematician and am used to tracing derivations back to the original
>>>> definitions.  So when I think of a likelihood (or, equivalently, a
>>>> deviance) to be optimized it only makes sense to me if there is a
>>>> probability distribution associated with the model.  And for the
>>>> quasi-binomial and quasi-Poisson families, there isn't a probability
>>>> distribution.  To me that means that discussing maximum likelihood
>>>> estimators for such models is nonsense.  The models simply do not 
>>>> exist.
>>>> One can play tricks in the case of a generalized linear model to 
>>>> estimate a
>>>> "quasi-parameter" that isn't part of the probability distribution but 
>>>> it is
>>>> foolhardy to expect that the tricks will automatically carry over to a
>>>> generalized linear mixed model.
>>>>
>>>> I am not denying that data that are over-dispersed with respect to the
>>>> binomial or Poisson distributions can and do occur.  But having data 
>>>> like
>>>> this and a desire to model it doesn't make the quasi families real.  In 
>>>> his
>>>> signature Thierry Onkelinx quotes
>>>>
>>>> The combination of some data and an aching desire for an answer does 
>>>> not
>>>> ensure that a reasonable answer can be extracted from a given body of 
>>>> data.
>>>> ~ John Tukey
>>>>
>>>> I could and do plan to incorporate the negative binomial family but, 
>>>> without
>>>> a definition that I can understand of a quasi-binomial or quasi-Poisson
>>>> distribution and its associated probability function, I'm stuck. To me 
>>>> it's
>>>> a "build bricks without straw" situation - you can't find maximum 
>>>> likelihood
>>>> estimates for parameters that aren't part of the likelihood.
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> John Maindonald             email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Mathematics & Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>> http://www.maths.anu.edu.au/~johnm
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From dmsilv at gmail.com  Sat Jun 26 13:28:28 2010
From: dmsilv at gmail.com (Daniel)
Date: Sat, 26 Jun 2010 08:28:28 -0300
Subject: [R-sig-ME] Doubt in print mle results
Message-ID: <AANLkTinxVVGNnrbEsBHtGIpfBJC5uopPdPJYcvkZyA98@mail.gmail.com>

Hello All,
My problem is basically, I think, but I have no answer yet.
I did 4 models, which of that 3 is from lm() and 1 lme().
I can print a nice table of 3 models using estout(), but i did not
apply estout for lme object.
How can produce an output table with lm and lme objects?

-- 
Daniel



From bates at stat.wisc.edu  Sat Jun 26 18:34:41 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 26 Jun 2010 11:34:41 -0500
Subject: [R-sig-ME] Is anyone using the lmList() function in the lme4
	package?
Message-ID: <AANLkTimjkME7qha1Ip80CD4mCzbiOQoy63B9KLM-2UeS@mail.gmail.com>

When we wrote the nlme package we tried to be very careful about
starting estimates and created the lmList function to allow evaluation
of coefficients from within-group linear fits.  It turns out that it
is most useful for longitudinal data where there are enough
observations on each subject to do within-subject fits; that is, for
data like the sleepstudy data.  Subsequent developments have made it
easy enough to fit the mixed model reliably without needing a lot of
preliminary work to get starting estimates.  (Similarly, the
groupedData class was a good idea at the time but no longer
necessary.)

Would anyone miss the lmList function if it was removed from future
versions of lme4?



From reinhold.kliegl at gmail.com  Sat Jun 26 18:44:40 2010
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Sat, 26 Jun 2010 18:44:40 +0200
Subject: [R-sig-ME] Is anyone using the lmList() function in the lme4
	package?
In-Reply-To: <AANLkTimjkME7qha1Ip80CD4mCzbiOQoy63B9KLM-2UeS@mail.gmail.com>
References: <AANLkTimjkME7qha1Ip80CD4mCzbiOQoy63B9KLM-2UeS@mail.gmail.com>
Message-ID: <38DADD28-4335-416F-8D02-12BD87782BA7@gmail.com>

We are using lmList() in the context of NLMM.  How easy will it be to  
get good starting values for nlmer?

Reinhold Kliegl

On 26.06.2010, at 18:34, Douglas Bates wrote:

> When we wrote the nlme package we tried to be very careful about
> starting estimates and created the lmList function to allow evaluation
> of coefficients from within-group linear fits.  It turns out that it
> is most useful for longitudinal data where there are enough
> observations on each subject to do within-subject fits; that is, for
> data like the sleepstudy data.  Subsequent developments have made it
> easy enough to fit the mixed model reliably without needing a lot of
> preliminary work to get starting estimates.  (Similarly, the
> groupedData class was a good idea at the time but no longer
> necessary.)
>
> Would anyone miss the lmList function if it was removed from future
> versions of lme4?
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bolker at ufl.edu  Sat Jun 26 18:50:08 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Sat, 26 Jun 2010 12:50:08 -0400
Subject: [R-sig-ME] overdispersion and the one random effect per
 observation approach
In-Reply-To: <DC988A78AE74432B9C8610A9EF646639@lborger>
References: <DC988A78AE74432B9C8610A9EF646639@lborger>
Message-ID: <4C262FC0.3000002@ufl.edu>

  @article{elston_analysis_2001,
        title = {Analysis of aggregation, a worked example: numbers of
ticks on red grouse chicks},
        volume = {122},
        number = {5},
        journal = {Parasitology},
        author = {D. A. Elston and R. Moss and T. Boulinier and C.
Arrowsmith and X. Lambin},
        year = {2001},
        pages = {563--569}
}


 ... although having looked at this particular example more carefully I
think I might *not* recommend the particular approach they took (i.e.,
using PQL with per-individual random effects, which is explicitly
disrecommended in the Genstat/AS-REML documentation ...)

  Try searching for "Poisson-lognormal distribution" too ...

Luca Borger wrote:
> Dear All,
> 
> it has been recently discussed on this list (e.g. see below, as well as 
> http://glmm.wikidot.com/faq) that overdispersed distributions can be 
> modelled by using an observation-level random effect (i.e. one random effect 
> per observation). I am wondering if anyone knows a good reference for this 
> approach. John Maindonald kindly pointed me to an example in the new edition 
> of his book:
> 
>> There is an example in Section 10.5 of the 3rd edition of Data Analysis & 
>> Graphics Using R, which is just now out.
> 
> Does anyone know other refs? Thanks in advance for your help!
> 
> 
> Cheers,
> 
> Luca
> 
> 
> -------------------
> Luca B?rger, PhD
> Postdoctoral Research Fellow
> Department of Integrative Biology
> University of Guelph
> Guelph, Ontario, Canada N1G 2W1
> 
> office +1 519 824 4120 ext. 52975
> lab     +1 519 824 4120 ext. 53594
> fax:     +1 519 767 1656
> 
> email: lborger at uoguelph.ca
> www.researcherid.com/rid/C-6003-2008
> http://uoguelph.academia.edu/LucaBorger
> --------------------------------------------------------------------
> 
> 
> 
> 
>> ----- Original Message ----- From: "John Maindonald" 
>> <john.maindonald at anu.edu.au>
>> To: <r-sig-mixed-models at r-project.org>
>> Sent: Thursday, June 24, 2010 7:11 PM
>> Subject: [R-sig-ME] Fwd: lme4, lme4a,and overdispersed distributions 
>> (again)
>>
>>
>>> I think it more accurate to say that, in general, there may be
>>> a class of distributions, and therefore a possible multiplicity
>>> of likelihoods, not necessarily for distributions of exponential
>>> form.  This is a PhD thesis asking to be done, or maybe
>>> someone has already done it.
>>>
>>> Over-dispersed distributions, where it is entirely clear what the
>>> distribution is, can be generated as GLM model +  one random
>>> effect per observation.  We have discussed this before.  This
>>> seems to me the preferred way to go, if such a model seems to
>>> fit the data.  I've not checked the current state of play re fitting
>>> such models in lme4 of lme4a; in the past some versions have
>>> allowed such a model.
>>>
>>> I like the simplicity of the one random effect per observation
>>> approach, as against what can seem the convoluted theoretical
>>> framework in which beta binomials live.
>>>
>>> John Maindonald             email: john.maindonald at anu.edu.au
>>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>>> Centre for Mathematics & Its Applications, Room 1194,
>>> John Dedman Mathematical Sciences Building (Building 27)
>>> Australian National University, Canberra ACT 0200.
>>> http://www.maths.anu.edu.au/~johnm
>>>
>>>> On 25/06/2010, at 3:59 AM, Jeffrey Evans wrote:
>>>>
>>>>> Since I am definitely *not* a mathematician, I am straying in over my 
>>>>> head
>>>>> here.
>>>>>
>>>>> I understand what you are saying - that there isn't a likelihood 
>>>>> function
>>>>> for the quasi-binomial "distribution". And therefore, there is no-such
>>>>> distribution.
>>>>>
>>>>> What do you think of the suggestion that a beta-binomial mixture
>>>>> distribution could be used to model overdispersed binomial data?
>>>>>
>>>>> Would this be a techinically correct and logistically feasibile 
>>>>> solution?
>>>>>
>>>>> -jeff
>>>>>
>>>>> -----Original Message-----
>>>>> From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas
>>>>> Bates
>>>>> Sent: Thursday, June 24, 2010 1:25 PM
>>>>> To: Jeffrey Evans
>>>>> Cc: r-sig-mixed-models at r-project.org
>>>>> Subject: Re: [R-sig-ME] lme4, lme4a, and overdispersed distributions 
>>>>> (again)
>>>>>
>>>>> On Thu, Jun 24, 2010 at 11:54 AM, Jeffrey Evans
>>>>> <Jeffrey.Evans at dartmouth.edu> wrote:
>>>>>> Like others, I have experienced trouble with estimation of the scale
>>>>>> parameter using the quasi-distributions in lme4, which is necessary to
>>>>>> calculate QAICc and rank overdispersed generalized linear mixed 
>>>>>> models.
>>>>>> I had several exchanges with Ben Bolker about this early last year
>>>>>> after his TREE paper came out
>>>>>> (http://www.cell.com/trends/ecology-evolution/abstract/S0169-5347%2809
>>>>>> %29000 19-6), and I know it's been discussed on on this list. Has
>>>>>> there been or is there any potential resolution to this forthcoming in
>>>>>> future releases of
>>>>>> lme4 or lme4a? I run into overdispersed binomial distributions
>>>>>> frequently and have had to use SAS to deal with them. SAS appears to
>>>>>> work, but it won't estimate the overdispersion parameter using laplace
>>>>>> estimation (only PQL), As I understand it, these pseudo-Iikelihoods
>>>>>> can't be used for model ranking. I don't know why SAS can't/won't, but
>>>>>> lme4 will run these quasi-binomial and quasi-poisson distributions 
>>>>>> with
>>>>> Laplace estimation.
>>>>>
>>>>>> Is there a workable way to use lme4 for modeling overdispersed
>>>>>> binomial data?
>>>>> I have trouble discussing this because I come from a background as a
>>>>> mathematician and am used to tracing derivations back to the original
>>>>> definitions.  So when I think of a likelihood (or, equivalently, a
>>>>> deviance) to be optimized it only makes sense to me if there is a
>>>>> probability distribution associated with the model.  And for the
>>>>> quasi-binomial and quasi-Poisson families, there isn't a probability
>>>>> distribution.  To me that means that discussing maximum likelihood
>>>>> estimators for such models is nonsense.  The models simply do not 
>>>>> exist.
>>>>> One can play tricks in the case of a generalized linear model to 
>>>>> estimate a
>>>>> "quasi-parameter" that isn't part of the probability distribution but 
>>>>> it is
>>>>> foolhardy to expect that the tricks will automatically carry over to a
>>>>> generalized linear mixed model.
>>>>>
>>>>> I am not denying that data that are over-dispersed with respect to the
>>>>> binomial or Poisson distributions can and do occur.  But having data 
>>>>> like
>>>>> this and a desire to model it doesn't make the quasi families real.  In 
>>>>> his
>>>>> signature Thierry Onkelinx quotes
>>>>>
>>>>> The combination of some data and an aching desire for an answer does 
>>>>> not
>>>>> ensure that a reasonable answer can be extracted from a given body of 
>>>>> data.
>>>>> ~ John Tukey
>>>>>
>>>>> I could and do plan to incorporate the negative binomial family but, 
>>>>> without
>>>>> a definition that I can understand of a quasi-binomial or quasi-Poisson
>>>>> distribution and its associated probability function, I'm stuck. To me 
>>>>> it's
>>>>> a "build bricks without straw" situation - you can't find maximum 
>>>>> likelihood
>>>>> estimates for parameters that aren't part of the likelihood.
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> John Maindonald             email: john.maindonald at anu.edu.au
>>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>>> Centre for Mathematics & Its Applications, Room 1194,
>>> John Dedman Mathematical Sciences Building (Building 27)
>>> Australian National University, Canberra ACT 0200.
>>> http://www.maths.anu.edu.au/~johnm
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
*** NEW E-MAIL ADDRESSES:
***   bbolker at gmail.com , bolker at math.mcmaster.ca
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From baron at psych.upenn.edu  Sat Jun 26 19:25:47 2010
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Sat, 26 Jun 2010 13:25:47 -0400
Subject: [R-sig-ME] Is anyone using the lmList() function in the lme4
	package?
In-Reply-To: <38DADD28-4335-416F-8D02-12BD87782BA7@gmail.com>
	<AANLkTimjkME7qha1Ip80CD4mCzbiOQoy63B9KLM-2UeS@mail.gmail.com>
References: <AANLkTimjkME7qha1Ip80CD4mCzbiOQoy63B9KLM-2UeS@mail.gmail.com>
	<38DADD28-4335-416F-8D02-12BD87782BA7@gmail.com>
	<AANLkTimjkME7qha1Ip80CD4mCzbiOQoy63B9KLM-2UeS@mail.gmail.com>
Message-ID: <20100626172547.GA31013@psych.upenn.edu>

I use lmList() a fair bit because it is sort of a standard approach to
data analysis in psychology when you can fit the model to each subject
and then test the coefficients across subjects, or look at the
correlations of the coefficients with something else.

HOWEVER, for years before lme4 existed I was doing exactly the same
thing with a loop.  Thus, lmList() is merely a convenience for people
like me.  So the answer is that I WOULD BE HAPPY TO LIVE WITHOUT IT.

Jon

P.S.  I hope that, eventually, lme4a works with languageR's
pvals.fnc().  Right now it doesn't, and this is probably not your
problem but theirs.
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron



From renaud.lancelot at cirad.fr  Sat Jun 26 21:00:01 2010
From: renaud.lancelot at cirad.fr (lancelot)
Date: Sat, 26 Jun 2010 21:00:01 +0200
Subject: [R-sig-ME] Is anyone using the lmList() function in the lme4
 package?
In-Reply-To: <AANLkTimjkME7qha1Ip80CD4mCzbiOQoy63B9KLM-2UeS@mail.gmail.com>
References: <AANLkTimjkME7qha1Ip80CD4mCzbiOQoy63B9KLM-2UeS@mail.gmail.com>
Message-ID: <4C264E31.7060508@cirad.fr>

I use it - more for exploratory analysis than to get starting estimates, 
to decide what might be a good starting point for the random structure 
of (g)lmm's. It is also very convenient to explain the concepts of mixed 
models, e.g. with MSc students with a biological background. Indeed, I 
would miss the lmList function if it was removed from future versions of 
lme4.

All the best,

Renaud

Douglas Bates a ?crit :
> When we wrote the nlme package we tried to be very careful about
> starting estimates and created the lmList function to allow evaluation
> of coefficients from within-group linear fits.  It turns out that it
> is most useful for longitudinal data where there are enough
> observations on each subject to do within-subject fits; that is, for
> data like the sleepstudy data.  Subsequent developments have made it
> easy enough to fit the mixed model reliably without needing a lot of
> preliminary work to get starting estimates.  (Similarly, the
> groupedData class was a good idea at the time but no longer
> necessary.)
> 
> Would anyone miss the lmList function if it was removed from future
> versions of lme4?
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
Renaud Lancelot
EDEN Project, coordinator
http://www.eden-fp6project.net/

UMR CIRAD-INRA "Contr?le des maladies animales exotiques et ?mergentes"
Joint research unit "Control of emerging and exotic animal diseases"

CIRAD, Campus International de Baillarguet TA A-DIR / B
F34398 Montpellier
http://umr-cmaee.cirad.fr/

Tel.  +33 4 67 59 37 17  -  Fax  +33 4 67 59 37 95
Secr. +33 4 67 59 37 37  - Cell. +33 6 77 52 08 69



From kevin.thorpe at utoronto.ca  Sat Jun 26 21:07:47 2010
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Sat, 26 Jun 2010 15:07:47 -0400
Subject: [R-sig-ME] Is anyone using the lmList() function in the lme4
 package?
In-Reply-To: <AANLkTimjkME7qha1Ip80CD4mCzbiOQoy63B9KLM-2UeS@mail.gmail.com>
References: <AANLkTimjkME7qha1Ip80CD4mCzbiOQoy63B9KLM-2UeS@mail.gmail.com>
Message-ID: <4C265003.50501@utoronto.ca>

Douglas Bates wrote:
> When we wrote the nlme package we tried to be very careful about
> starting estimates and created the lmList function to allow evaluation
> of coefficients from within-group linear fits.  It turns out that it
> is most useful for longitudinal data where there are enough
> observations on each subject to do within-subject fits; that is, for
> data like the sleepstudy data.  Subsequent developments have made it
> easy enough to fit the mixed model reliably without needing a lot of
> preliminary work to get starting estimates.  (Similarly, the
> groupedData class was a good idea at the time but no longer
> necessary.)
> 
> Would anyone miss the lmList function if it was removed from future
> versions of lme4?

Speaking as one is relatively new to mixed models and not altogether
comfortable with them at times, I have found it useful to understand
my data.  With some data I was having trouble with (estimated
correlations of 1) it was very handy for producing caterpiller plots
to see how slope and intercept were related.

Of course, if I'm the only one who feels this way, my amount of usage
is not nearly sufficient to demand you keep lmList. :-)


-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016



From ken.knoblauch at inserm.fr  Sat Jun 26 21:57:07 2010
From: ken.knoblauch at inserm.fr (Ken Knoblauch)
Date: Sat, 26 Jun 2010 19:57:07 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?Is_anyone_using_the_lmList=28=29_function_in?=
	=?utf-8?q?_the_lme4=09package=3F?=
References: <AANLkTimjkME7qha1Ip80CD4mCzbiOQoy63B9KLM-2UeS@mail.gmail.com>
Message-ID: <loom.20100626T215050-368@post.gmane.org>

Douglas Bates <bates at ...> writes:
> When we wrote the nlme package we tried to be very careful about
> starting estimates and created the lmList function to allow evaluation
> of coefficients from within-group linear fits.  It turns out that it
> is most useful for longitudinal data where there are enough
> observations on each subject to do within-subject fits; that is, for
> data like the sleepstudy data.  Subsequent developments have made it
> easy enough to fit the mixed model reliably without needing a lot of
> preliminary work to get starting estimates.  (Similarly, the
> groupedData class was a good idea at the time but no longer
> necessary.)
> 
> Would anyone miss the lmList function if it was removed from future
> versions of lme4?

I would vote for keeping it, too.  Anything that facilitates exploring the
data is generally useful.  I always found the didactic use of lmList to motivate
the selection of variables that might be treated as random effects, in the
Pinheiro & Bates book very helpful.  I'm using the lme4 version in a chapter that
I'm writing currently, so have a vested interest in knowing whether it will
be deprecated, as well.  

Ken

-- 
Ken Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html



From jmblanco at ub.edu  Sat Jun 26 22:43:16 2010
From: jmblanco at ub.edu (=?ISO-8859-1?Q?Jos=E9_Manuel_Blanco_Moreno?=)
Date: Sat, 26 Jun 2010 22:43:16 +0200
Subject: [R-sig-ME] Is anyone using the lmList() function in the lme4
 package?
In-Reply-To: <AANLkTimjkME7qha1Ip80CD4mCzbiOQoy63B9KLM-2UeS@mail.gmail.com>
References: <AANLkTimjkME7qha1Ip80CD4mCzbiOQoy63B9KLM-2UeS@mail.gmail.com>
Message-ID: <4C266664.1030009@ub.edu>

Not that I have used it too much, but I would prefer keeping it (for 
teaching, practical reasons...)


El 26/06/2010 18:34, Douglas Bates escribi?:
> When we wrote the nlme package we tried to be very careful about
> starting estimates and created the lmList function to allow evaluation
> of coefficients from within-group linear fits.  It turns out that it
> is most useful for longitudinal data where there are enough
> observations on each subject to do within-subject fits; that is, for
> data like the sleepstudy data.  Subsequent developments have made it
> easy enough to fit the mixed model reliably without needing a lot of
> preliminary work to get starting estimates.  (Similarly, the
> groupedData class was a good idea at the time but no longer
> necessary.)
>
> Would anyone miss the lmList function if it was removed from future
> versions of lme4?
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>    


-- 
---------------------------------------
Jos? M. Blanco Moreno

Dept. de Biologia Vegetal (Bot?nica)
Universitat de Barcelona
Av. Diagonal 645
08028 Barcelona SPAIN
---------------------------------------

phone: (+34) 934 039 863
fax: (+34) 934 112 842
e-mail: jmblanco at ub.edu



From steven.brady at yale.edu  Sat Jun 26 23:45:49 2010
From: steven.brady at yale.edu (Steven Brady)
Date: Sat, 26 Jun 2010 17:45:49 -0400
Subject: [R-sig-ME] Evaluate fixed effects with aovlmer.fnc
Message-ID: <20100626174549.9r3b48l30gskc440@www.mail.yale.edu>


Hi All:

I am evaluating the outcome of a reciprocal transplant experiment that
involves two fixed factors (and their interaction) and one random
factor.  Example code is below.

One goal of this analysis is to report an mcmc based p-value (and
estimates, HDP Intervals, etc...) for each of the two fixed factors and
their interaction.  Using aovlmer.fnc() I can generate an anova table to
that effect (with F based p values), but only one mcmc p value is
reported.  I suspect this may have something to do with the Warning
message (see below).

Can anyone suggest how to extract the mcmc p values for each factor
along with HDP intervals?

Also: When I attempt to evaluate the significance of the fixed factors
using pvals.fnc() instead of aovlmer.fnc(), I noticed that the p values
depend on the name (alphabetical?) of the level within the factor.  Can
anyone clarify this distinction in outputs?  Said another way, what do
the different p values refer to in the output of

pvals.fnc(g)

versus

aovlmer.fnc(g, mcmc$mcmc, c("originw", "envw",
+ "originw:envw"))

Many thanks for any input.

Best,

Steve


#Example
population=c("a","a","a","a","b","b","b",
"b","c","c","c","c","d","d","d","d")
env=c("r","r","w","w","r","r","w","w",
"r","r","w","w","r","r","w","w")
origin=c("r","r","r","r","r","r","r",
"r","w","w","w","w","w","w","w","w")
survival=c(rnorm(16,0.75, sd = 0.1))
exp=data.frame(population=population, env=env,
origin=origin,survival=survival)

g<-lmer(survival~origin*env +
(1|population), data = exp)

mcmc = pvals.fnc(g, nsim=10000, withMCMC=TRUE)
aovlmer.fnc(g, mcmc$mcmc, c("originw", "envw",
"originw:envw"))

$MCMC
$MCMC$p
[1] 0.0802

$MCMC$which
[1] "originw"      "envw"         "originw:envw"


$Ftests
Analysis of Variance Table
           Df   Sum Sq  Mean Sq F value      F Df2       p
origin      1 0.000570 0.000570  0.1267 0.1267  12 0.72808
env         1 0.036297 0.036297  8.0659 8.0659  12 0.01490
origin:env  1 0.004855 0.004855  1.0789 1.0789  12 0.31942

Warning message:
In if (class(anov) != "try-error") { :
  the condition has length > 1 and only the first element will be used

__________________________________________
Steven P. Brady, Ph.D. Candidate
School of Forestry & Environmental Studies
Yale University
370 Prospect Street
New Haven, CT 06511

Email: steven.brady at yale.edu
Phone: 203-432-5321 Fax: 203-432-3929
Web: http://www.cbc.yale.edu/people/skelly/steveb.html



From hadley at rice.edu  Sat Jun 26 23:52:58 2010
From: hadley at rice.edu (Hadley Wickham)
Date: Sat, 26 Jun 2010 16:52:58 -0500
Subject: [R-sig-ME] Is anyone using the lmList() function in the lme4
	package?
In-Reply-To: <AANLkTimjkME7qha1Ip80CD4mCzbiOQoy63B9KLM-2UeS@mail.gmail.com>
References: <AANLkTimjkME7qha1Ip80CD4mCzbiOQoy63B9KLM-2UeS@mail.gmail.com>
Message-ID: <AANLkTimxwLO4B4QqrmzQ_M3snQHdqXoxxUjk6cgPjU_z@mail.gmail.com>

I would argue that it should be removed because it's pretty trivial to
replace with a combination of split and lapply, or if you prefer,
dlply from plyr.

Hadley

On Saturday, June 26, 2010, Douglas Bates <bates at stat.wisc.edu> wrote:
> When we wrote the nlme package we tried to be very careful about
> starting estimates and created the lmList function to allow evaluation
> of coefficients from within-group linear fits. ?It turns out that it
> is most useful for longitudinal data where there are enough
> observations on each subject to do within-subject fits; that is, for
> data like the sleepstudy data. ?Subsequent developments have made it
> easy enough to fit the mixed model reliably without needing a lot of
> preliminary work to get starting estimates. ?(Similarly, the
> groupedData class was a good idea at the time but no longer
> necessary.)
>
> Would anyone miss the lmList function if it was removed from future
> versions of lme4?
>
> _______________________________________________
> R-sig-mixed-models at r-project.org?mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/



From ggrothendieck at gmail.com  Sun Jun 27 00:02:34 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 26 Jun 2010 18:02:34 -0400
Subject: [R-sig-ME] Is anyone using the lmList() function in the lme4
	package?
In-Reply-To: <AANLkTimxwLO4B4QqrmzQ_M3snQHdqXoxxUjk6cgPjU_z@mail.gmail.com>
References: <AANLkTimjkME7qha1Ip80CD4mCzbiOQoy63B9KLM-2UeS@mail.gmail.com> 
	<AANLkTimxwLO4B4QqrmzQ_M3snQHdqXoxxUjk6cgPjU_z@mail.gmail.com>
Message-ID: <AANLkTim4kkaEsoL-VoC6EESv8KkdgNnxeQNEOtF12Fan@mail.gmail.com>

On Sat, Jun 26, 2010 at 5:52 PM, Hadley Wickham <hadley at rice.edu> wrote:
> I would argue that it should be removed because it's pretty trivial to
> replace with a combination of split and lapply, or if you prefer,
> dlply from plyr.

Note that it supports a pool= argument.



From datkins at u.washington.edu  Sun Jun 27 00:03:45 2010
From: datkins at u.washington.edu (David Atkins)
Date: Sat, 26 Jun 2010 15:03:45 -0700
Subject: [R-sig-ME] overdispersion and the one random effect per
 observation approach
In-Reply-To: <4C262FC0.3000002@ufl.edu>
References: <4C262FC0.3000002@ufl.edu>
Message-ID: <4C267941.1020006@u.washington.edu>


Another place where it is discussed is in Sophia Rabe-Heseth and Anders 
Skrondal's book on multilevel modeling:

http://www.stata-press.com/books/mlmus.html

cheers, Dave

-- 
Dave Atkins, PhD
Research Associate Professor
Department of Psychiatry and Behavioral Science
University of Washington
datkins at u.washington.edu

Center for the Study of Health and Risk Behaviors (CSHRB)		
1100 NE 45th Street, Suite 300 	
Seattle, WA  98105 	
206-616-3879 	
http://depts.washington.edu/cshrb/
(Mon-Wed)	

Center for Healthcare Improvement, for Addictions, Mental Illness,
   Medically Vulnerable Populations (CHAMMP)
325 9th Avenue, 2HH-15
Box 359911
Seattle, WA 98104
http://www.chammp.org
(Thurs)



From idworkin at msu.edu  Sun Jun 27 17:06:49 2010
From: idworkin at msu.edu (Ian Dworkin)
Date: Sun, 27 Jun 2010 11:06:49 -0400
Subject: [R-sig-ME] Is anyone using the lmList() function in the lme4
	package?
In-Reply-To: <AANLkTim4kkaEsoL-VoC6EESv8KkdgNnxeQNEOtF12Fan@mail.gmail.com>
References: <AANLkTimjkME7qha1Ip80CD4mCzbiOQoy63B9KLM-2UeS@mail.gmail.com>
	<AANLkTimxwLO4B4QqrmzQ_M3snQHdqXoxxUjk6cgPjU_z@mail.gmail.com>
	<AANLkTim4kkaEsoL-VoC6EESv8KkdgNnxeQNEOtF12Fan@mail.gmail.com>
Message-ID: <AANLkTil2mEQp8CYAw51_fN2IukS9hyQEwSDX4AQ1BZwq@mail.gmail.com>

Hi All

  While it is very easy to write a function to perform the tasks of
lmList(), from the point of view of teaching students who are still
learning to write their own functions, it sometimes helps to have a
function that already does it well. I use lmList() as I teach, for
similar reasons as were mentioned earlier in this thread. So I "vote"
to keep it.

Cheers

Ian

On 26 June 2010 18:02, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> On Sat, Jun 26, 2010 at 5:52 PM, Hadley Wickham <hadley at rice.edu> wrote:
>> I would argue that it should be removed because it's pretty trivial to
>> replace with a combination of split and lapply, or if you prefer,
>> dlply from plyr.
>
> Note that it supports a pool= argument.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Ian Dworkin
Assistant Professor
Department of Zoology
Program in Ecology, Evolutionary Biology & Behaviour
Program in Genetics
Michigan State University
office (517) 432-6733
lab (517) 432-6730
idworkin at msu.edu
https://www.msu.edu/~idworkin/



From bates at stat.wisc.edu  Sun Jun 27 17:36:12 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 27 Jun 2010 10:36:12 -0500
Subject: [R-sig-ME] Is anyone using the lmList() function in the lme4
	package?
In-Reply-To: <AANLkTil2mEQp8CYAw51_fN2IukS9hyQEwSDX4AQ1BZwq@mail.gmail.com>
References: <AANLkTimjkME7qha1Ip80CD4mCzbiOQoy63B9KLM-2UeS@mail.gmail.com>
	<AANLkTimxwLO4B4QqrmzQ_M3snQHdqXoxxUjk6cgPjU_z@mail.gmail.com>
	<AANLkTim4kkaEsoL-VoC6EESv8KkdgNnxeQNEOtF12Fan@mail.gmail.com>
	<AANLkTil2mEQp8CYAw51_fN2IukS9hyQEwSDX4AQ1BZwq@mail.gmail.com>
Message-ID: <AANLkTinkQdijntFRXTuyHxS0-5_KxQVauljJHDyESYhU@mail.gmail.com>

Thanks for all the responses, which do answer my question of whether
lmList is used and should be retained.  I will do so.

On Sun, Jun 27, 2010 at 10:06 AM, Ian Dworkin <idworkin at msu.edu> wrote:
> Hi All
>
> ?While it is very easy to write a function to perform the tasks of
> lmList(), from the point of view of teaching students who are still
> learning to write their own functions, it sometimes helps to have a
> function that already does it well. I use lmList() as I teach, for
> similar reasons as were mentioned earlier in this thread. So I "vote"
> to keep it.
>
> Cheers
>
> Ian
>
> On 26 June 2010 18:02, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
>> On Sat, Jun 26, 2010 at 5:52 PM, Hadley Wickham <hadley at rice.edu> wrote:
>>> I would argue that it should be removed because it's pretty trivial to
>>> replace with a combination of split and lapply, or if you prefer,
>>> dlply from plyr.
>>
>> Note that it supports a pool= argument.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
> Ian Dworkin
> Assistant Professor
> Department of Zoology
> Program in Ecology, Evolutionary Biology & Behaviour
> Program in Genetics
> Michigan State University
> office (517) 432-6733
> lab (517) 432-6730
> idworkin at msu.edu
> https://www.msu.edu/~idworkin/
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Mon Jun 28 16:36:53 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 28 Jun 2010 09:36:53 -0500
Subject: [R-sig-ME] Status of the development package lme4a
In-Reply-To: <19495.55735.436657.371332@ron.nulle.part>
References: <AANLkTilR_5pEYT_SbzjNv9AgUbAYsmcsAhUKi4DL4Zia@mail.gmail.com>
	<19495.55735.436657.371332@ron.nulle.part>
Message-ID: <AANLkTilSOcr9ZlEccAxmy5WiBIPNlqENyefETKGHM9N2@mail.gmail.com>

Dirk says that Rcpp 0.8.3 has been uploaded to CRAN.


---------- Forwarded message ----------
From: Dirk Eddelbuettel <edd at debian.org>
Date: Sun, Jun 27, 2010 at 6:07 PM
Subject: Re: Status of the development package lme4a
To: Douglas Bates <bates at stat.wisc.edu>
Cc: R-mixed models mailing list <r-sig-mixed-models at r-project.org>,
RomainAndDirk <RomainAndDirk at r-enthusiasts.com>, Stefan Theussl
<stefan.theussl at wu-wien.ac.at>, Kurt Hornik
<Kurt.Hornik at wu-wien.ac.at>, David Meyer <David.Meyer at wu-wien.ac.at>,
"Doran, Harold" <HDoran at air.org>, "Bliese, Paul D LTC USAMH"
<paul.bliese at us.army.mil>, Maritza Dowling <nmdowlin at biostat.wisc.edu>



On 25 June 2010 at 15:39, Douglas Bates wrote:
| I have switched to using the marvelous Rcpp package created by Dirk
| Eddelbuettel and Romain Fran?ois, which I heartily recommend to those
| writing C++/C code to be loaded into R. ?Recently Romain has been on a
| "code rant" creating "syntactic sugar" that makes it much easier to
| write expressions using R vectors in C++ and it has just been too
| tempting for me to use these capabilities. ?That is why binary
| packages are not available. Some of the code in the lme4a package
| depends on the "Rcpp du jour", more or less, and doesn't build on
| systems like win-builder or R-forge because of that dependency. ?When
| Dirk and Romain are ready to release Rcpp_0.8.3 to CRAN we'll be able
| to pursue making binary packages available.

Thank you for the very kind words about Rcpp, and the ongoing encouragement.

Version 0.8.3 of Rcpp is now in the incoming/ directory of CRAN, and should
find its way onto the mirrors in the next few days (unless Kurt et al find
fault with it).

Rcpp-related question will be welcomed at the rcpp-devel list. ?(Which is
subscriber-only, as I suppose r-sig-mixed-model is so if someone could
forward my post there I'd appreciate it).

--
?Regards, Dirk



From Jeffrey.Evans at dartmouth.edu  Mon Jun 28 22:44:41 2010
From: Jeffrey.Evans at dartmouth.edu (Jeffrey Evans)
Date: Mon, 28 Jun 2010 16:44:41 -0400
Subject: [R-sig-ME] Fwd: lme4, lme4a, and overdispersed distributions (again)
Message-ID: <C50176A7901048F8AF8819E50EB5B36F@Animal>

Hi Dave, I see that Ben Bolker et al's wiki page also references it.

I'm not able to get glmer to do this. I do something similar with my dataset
(dat$over = 1:nrow(dat)) and I get an error, not a warning.

> Xfit$over = 1:nrow(Xfit)
> m800 = glmer(cbind(gmdat$SdlFinal, gmdat$SdlMax-gmdat$SdlFinal)
~soilpc3+(1|gmdat$ID)+(1|over),data=Xfit, family="binomial")

Error in function (fr, FL, glmFit, start, nAGQ, verbose)  : 
  Number of levels of a grouping factor for the random effects
must be less than the number of observations

What version are you using? I'm running version 33.

Cheers,
Jeff



John et al.--

Actually, looks like the current version of glmer *does* allow 
observation level random-effects, though it throws you a little warning 
(which seems entirely appropriate). (Thank you Doug!)

Using the data that we were recently discussing (and attached to one of 
my previous posts "Data Redux"):

 > drink.df$over <- 1:nrow(drink.df)
 > drk.glmer <- glmer(drinks ~ weekday*gender + (1 | id) + (1 | over),
+ 					data = drink.df, family = poisson,
+ 					verbose = TRUE)
Number of levels of a grouping factor for the random effects
is *equal* to n, the number of observations
   0:     96443.694:  1.63299 0.215642 -0.912787 -0.0135537 0.0244628 
-0.0137854 0.504067  1.13637  1.06483 0.418800 0.366592 0.288067 
0.354827 0.443268 0.392234 0.287877

[snip]

  76:     73629.541:  4.35359 0.187209 -5.44079 -0.101647 -0.0249078 
-0.0721097 0.513271  1.65032  1.51045 0.132999 0.435110 0.356431 
0.382994 0.600458  1.26700 0.797529

 > summary(drk.glmer)
Generalized linear mixed model fit by the Laplace approximation
Formula: drinks ~ weekday * gender + (1 | id) + (1 | over)
    Data: drink.df
    AIC   BIC logLik deviance
  73662 73805 -36815    73630
Random effects:
  Groups Name        Variance  Std.Dev.
  over   (Intercept) 18.953746 4.35359
  id     (Intercept)  0.035047 0.18721
Number of obs: 56199, groups: over, 56199; id, 980

Fixed effects:
                          Estimate Std. Error z value Pr(>|z|)
(Intercept)              -5.44079    0.15315  -35.53  < 2e-16 ***
weekdayMonday            -0.10165    0.22164   -0.46  0.64651
weekdayTuesday           -0.02491    0.21837   -0.11  0.90919
weekdayWednesday         -0.07211    0.22089   -0.33  0.74408
weekdayThursday           0.51327    0.19953    2.57  0.01010 *
weekdayFriday             1.65032    0.17918    9.21  < 2e-16 ***
weekdaySaturday           1.51045    0.18023    8.38  < 2e-16 ***
genderM                   0.13300    0.22493    0.59  0.55432
weekdayMonday:genderM     0.43511    0.31295    1.39  0.16442
weekdayTuesday:genderM    0.35643    0.31078    1.15  0.25142
weekdayWednesday:genderM  0.38299    0.31327    1.22  0.22150
weekdayThursday:genderM   0.60046    0.28439    2.11  0.03474 *
weekdayFriday:genderM     1.26700    0.25845    4.90 9.48e-07 ***
weekdaySaturday:genderM   0.79712    0.26107    3.05  0.00226 **
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

As an aside, it is interesting to see for this particular data how the 
variance swings pretty wildly between the model without over-dispersion 
to the current one:

 > summary(drk.glmer)
Generalized linear mixed model fit by the Laplace approximation
Formula: drinks ~ weekday * gender + (1 | id)
    Data: drink.df
     AIC    BIC logLik deviance
  146572 146706 -73271   146542
Random effects:
  Groups Name        Variance Std.Dev.
  id     (Intercept) 0.92314  0.9608
Number of obs: 56199, groups: id, 980

Fixed effects:
                          Estimate Std. Error z value Pr(>|z|)
(Intercept)              -1.23639    0.04863  -25.42  < 2e-16 ***
weekdayMonday            -0.01035    0.03331   -0.31    0.756
weekdayTuesday            0.02583    0.03304    0.78    0.434
weekdayWednesday         -0.01161    0.03341   -0.35    0.728
weekdayThursday           0.50049    0.02976   16.82  < 2e-16 ***
weekdayFriday             1.12677    0.02691   41.87  < 2e-16 ***
weekdaySaturday           1.05954    0.02709   39.11  < 2e-16 ***
genderM                   0.30064    0.07099    4.24 2.28e-05 ***
weekdayMonday:genderM     0.36970    0.04359    8.48  < 2e-16 ***
weekdayTuesday:genderM    0.29552    0.04358    6.78 1.19e-11 ***
weekdayWednesday:genderM  0.36295    0.04378    8.29  < 2e-16 ***
weekdayThursday:genderM   0.45315    0.03913   11.58  < 2e-16 ***
weekdayFriday:genderM     0.40290    0.03587   11.23  < 2e-16 ***
weekdaySaturday:genderM   0.29764    0.03624    8.21  < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

These data in all likelihood are probably best modeled by a two-part 
model, with zero vs. non-zero and count model for non-zeroes.  The 
current version of MCMCglmm allows for zero-inflated models (where 
zeroes are a mixture of a point mass and count distribution), and the 
development version has hurdle formulations (with zero vs. non-zero, and 
then truncated count distribution for non-zeroes).

cheers, Dave

John Maindonald wrote:

I think it more accurate to say that, in general, there may be
a class of distributions, and therefore a possible multiplicity
of likelihoods, not necessarily for distributions of exponential
form.  This is a PhD thesis asking to be done, or maybe
someone has already done it.

Over-dispersed distributions, where it is entirely clear what the
distribution is, can be generated as GLM model +  one random
effect per observation.  We have discussed this before.  This
seems to me the preferred way to go, if such a model seems to
fit the data.  I've not checked the current state of play re fitting
such models in lme4 of lme4a; in the past some versions have
allowed such a model.

I like the simplicity of the one random effect per observation
approach, as against what can seem the convoluted theoretical
framework in which beta binomials live.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

 >
 > On 25/06/2010, at 3:59 AM, Jeffrey Evans wrote:
 >
 >> Since I am definitely *not* a mathematician, I am straying in over 
my head
 >> here.
 >>
 >> I understand what you are saying - that there isn't a likelihood 
function
 >> for the quasi-binomial "distribution". And therefore, there is no-such
 >> distribution.
 >>
 >> What do you think of the suggestion that a beta-binomial mixture
 >> distribution could be used to model overdispersed binomial data?
 >>
 >> Would this be a techinically correct and logistically feasibile 
solution?
 >>
 >> -jeff
 >>
 >> -----Original Message-----
 >> From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf 
Of Douglas
 >> Bates
 >> Sent: Thursday, June 24, 2010 1:25 PM
 >> To: Jeffrey Evans
 >> Cc: r-sig-mixed-models at r-project.org
 >> Subject: Re: [R-sig-ME] lme4, lme4a, and overdispersed distributions 
(again)
 >>
 >> On Thu, Jun 24, 2010 at 11:54 AM, Jeffrey Evans
 >> <Jeffrey.Evans at dartmouth.edu> wrote:
 >>> Like others, I have experienced trouble with estimation of the scale
 >>> parameter using the quasi-distributions in lme4, which is necessary to
 >>> calculate QAICc and rank overdispersed generalized linear mixed models.
 >>
 >>> I had several exchanges with Ben Bolker about this early last year
 >>> after his TREE paper came out
 >>> (http://www.cell.com/trends/ecology-evolution/abstract/S0169-5347%2809
 >>> %29000 19-6), and I know it's been discussed on on this list. Has
 >>> there been or is there any potential resolution to this forthcoming in
 >>> future releases of
 >>> lme4 or lme4a? I run into overdispersed binomial distributions
 >>> frequently and have had to use SAS to deal with them. SAS appears to
 >>> work, but it won't estimate the overdispersion parameter using laplace
 >>> estimation (only PQL), As I understand it, these pseudo-Iikelihoods
 >>> can't be used for model ranking. I don't know why SAS can't/won't, but
 >>> lme4 will run these quasi-binomial and quasi-poisson distributions with
 >> Laplace estimation.
 >>
 >>> Is there a workable way to use lme4 for modeling overdispersed
 >>> binomial data?
 >>
 >> I have trouble discussing this because I come from a background as a
 >> mathematician and am used to tracing derivations back to the original
 >> definitions.  So when I think of a likelihood (or, equivalently, a
 >> deviance) to be optimized it only makes sense to me if there is a
 >> probability distribution associated with the model.  And for the
 >> quasi-binomial and quasi-Poisson families, there isn't a probability
 >> distribution.  To me that means that discussing maximum likelihood
 >> estimators for such models is nonsense.  The models simply do not exist.
 >> One can play tricks in the case of a generalized linear model to 
estimate a
 >> "quasi-parameter" that isn't part of the probability distribution 
but it is
 >> foolhardy to expect that the tricks will automatically carry over to a
 >> generalized linear mixed model.
 >>
 >> I am not denying that data that are over-dispersed with respect to the
 >> binomial or Poisson distributions can and do occur.  But having data 
like
 >> this and a desire to model it doesn't make the quasi families real. 
  In his
 >> signature Thierry Onkelinx quotes
 >>
 >> The combination of some data and an aching desire for an answer does not
 >> ensure that a reasonable answer can be extracted from a given body 
of data.
 >> ~ John Tukey
 >>
 >> I could and do plan to incorporate the negative binomial family but, 
without
 >> a definition that I can understand of a quasi-binomial or quasi-Poisson
 >> distribution and its associated probability function, I'm stuck. To 
me it's
 >> a "build bricks without straw" situation - you can't find maximum 
likelihood
 >> estimates for parameters that aren't part of the likelihood.
 >>
 >> _______________________________________________
 >> R-sig-mixed-models at r-project.org mailing list
 >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
 >

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

-- 
Dave Atkins, PhD
Research Associate Professor
Department of Psychiatry and Behavioral Science
University of Washington
datkins <at> u.washington.edu

Center for the Study of Health and Risk Behaviors (CSHRB)		
1100 NE 45th Street, Suite 300 	
Seattle, WA  98105 	
206-616-3879 	
http://depts.washington.edu/cshrb/
(Mon-Wed)	

Center for Healthcare Improvement, for Addictions, Mental Illness,
   Medically Vulnerable Populations (CHAMMP)
325 9th Avenue, 2HH-15
Box 359911
Seattle, WA 98104
http://www.chammp.org <http://www.chammp.org/> 
(Thurs)



From robert.espesser at lpl-aix.fr  Mon Jun 28 23:03:57 2010
From: robert.espesser at lpl-aix.fr (robert.espesser at lpl-aix.fr)
Date: Mon, 28 Jun 2010 23:03:57 +0200
Subject: [R-sig-ME] Fwd: lme4, lme4a,
 and overdispersed distributions (again)
In-Reply-To: <C50176A7901048F8AF8819E50EB5B36F@Animal>
References: <C50176A7901048F8AF8819E50EB5B36F@Animal>
Message-ID: <4C290E3D.2090508@lpl-aix.fr>

I remember that D. Bates recommended ( 6 or 12 months ago  ?)  to use 
the binary format (ie NOT the matrix success-fail counts format)  for 
binomial data; one reason was that  glmer was not as smart as glm to get 
the correct number of response.
Robert


Le 28/06/2010 22:44, Jeffrey Evans a ?crit :
> Hi Dave, I see that Ben Bolker et al's wiki page also references it.
>
> I'm not able to get glmer to do this. I do something similar with my dataset
> (dat$over = 1:nrow(dat)) and I get an error, not a warning.
>
>> Xfit$over = 1:nrow(Xfit)
>> m800 = glmer(cbind(gmdat$SdlFinal, gmdat$SdlMax-gmdat$SdlFinal)
> ~soilpc3+(1|gmdat$ID)+(1|over),data=Xfit, family="binomial")
>
> Error in function (fr, FL, glmFit, start, nAGQ, verbose)  :
>    Number of levels of a grouping factor for the random effects
> must be less than the number of observations
>
> What version are you using? I'm running version 33.
>
> Cheers,
> Jeff
>
>
>
> John et al.--
>
> Actually, looks like the current version of glmer *does* allow
> observation level random-effects, though it throws you a little warning
> (which seems entirely appropriate). (Thank you Doug!)
>
> Using the data that we were recently discussing (and attached to one of
> my previous posts "Data Redux"):
>
>   >  drink.df$over<- 1:nrow(drink.df)
>   >  drk.glmer<- glmer(drinks ~ weekday*gender + (1 | id) + (1 | over),
> + 					data = drink.df, family = poisson,
> + 					verbose = TRUE)
> Number of levels of a grouping factor for the random effects
> is *equal* to n, the number of observations
>     0:     96443.694:  1.63299 0.215642 -0.912787 -0.0135537 0.0244628
> -0.0137854 0.504067  1.13637  1.06483 0.418800 0.366592 0.288067
> 0.354827 0.443268 0.392234 0.287877
>
> [snip]
>
>    76:     73629.541:  4.35359 0.187209 -5.44079 -0.101647 -0.0249078
> -0.0721097 0.513271  1.65032  1.51045 0.132999 0.435110 0.356431
> 0.382994 0.600458  1.26700 0.797529
>
>   >  summary(drk.glmer)
> Generalized linear mixed model fit by the Laplace approximation
> Formula: drinks ~ weekday * gender + (1 | id) + (1 | over)
>      Data: drink.df
>      AIC   BIC logLik deviance
>    73662 73805 -36815    73630
> Random effects:
>    Groups Name        Variance  Std.Dev.
>    over   (Intercept) 18.953746 4.35359
>    id     (Intercept)  0.035047 0.18721
> Number of obs: 56199, groups: over, 56199; id, 980
>
> Fixed effects:
>                            Estimate Std. Error z value Pr(>|z|)
> (Intercept)              -5.44079    0.15315  -35.53<  2e-16 ***
> weekdayMonday            -0.10165    0.22164   -0.46  0.64651
> weekdayTuesday           -0.02491    0.21837   -0.11  0.90919
> weekdayWednesday         -0.07211    0.22089   -0.33  0.74408
> weekdayThursday           0.51327    0.19953    2.57  0.01010 *
> weekdayFriday             1.65032    0.17918    9.21<  2e-16 ***
> weekdaySaturday           1.51045    0.18023    8.38<  2e-16 ***
> genderM                   0.13300    0.22493    0.59  0.55432
> weekdayMonday:genderM     0.43511    0.31295    1.39  0.16442
> weekdayTuesday:genderM    0.35643    0.31078    1.15  0.25142
> weekdayWednesday:genderM  0.38299    0.31327    1.22  0.22150
> weekdayThursday:genderM   0.60046    0.28439    2.11  0.03474 *
> weekdayFriday:genderM     1.26700    0.25845    4.90 9.48e-07 ***
> weekdaySaturday:genderM   0.79712    0.26107    3.05  0.00226 **
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
> As an aside, it is interesting to see for this particular data how the
> variance swings pretty wildly between the model without over-dispersion
> to the current one:
>
>   >  summary(drk.glmer)
> Generalized linear mixed model fit by the Laplace approximation
> Formula: drinks ~ weekday * gender + (1 | id)
>      Data: drink.df
>       AIC    BIC logLik deviance
>    146572 146706 -73271   146542
> Random effects:
>    Groups Name        Variance Std.Dev.
>    id     (Intercept) 0.92314  0.9608
> Number of obs: 56199, groups: id, 980
>
> Fixed effects:
>                            Estimate Std. Error z value Pr(>|z|)
> (Intercept)              -1.23639    0.04863  -25.42<  2e-16 ***
> weekdayMonday            -0.01035    0.03331   -0.31    0.756
> weekdayTuesday            0.02583    0.03304    0.78    0.434
> weekdayWednesday         -0.01161    0.03341   -0.35    0.728
> weekdayThursday           0.50049    0.02976   16.82<  2e-16 ***
> weekdayFriday             1.12677    0.02691   41.87<  2e-16 ***
> weekdaySaturday           1.05954    0.02709   39.11<  2e-16 ***
> genderM                   0.30064    0.07099    4.24 2.28e-05 ***
> weekdayMonday:genderM     0.36970    0.04359    8.48<  2e-16 ***
> weekdayTuesday:genderM    0.29552    0.04358    6.78 1.19e-11 ***
> weekdayWednesday:genderM  0.36295    0.04378    8.29<  2e-16 ***
> weekdayThursday:genderM   0.45315    0.03913   11.58<  2e-16 ***
> weekdayFriday:genderM     0.40290    0.03587   11.23<  2e-16 ***
> weekdaySaturday:genderM   0.29764    0.03624    8.21<  2e-16 ***
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
> These data in all likelihood are probably best modeled by a two-part
> model, with zero vs. non-zero and count model for non-zeroes.  The
> current version of MCMCglmm allows for zero-inflated models (where
> zeroes are a mixture of a point mass and count distribution), and the
> development version has hurdle formulations (with zero vs. non-zero, and
> then truncated count distribution for non-zeroes).
>
> cheers, Dave
>
> John Maindonald wrote:
>
> I think it more accurate to say that, in general, there may be
> a class of distributions, and therefore a possible multiplicity
> of likelihoods, not necessarily for distributions of exponential
> form.  This is a PhD thesis asking to be done, or maybe
> someone has already done it.
>
> Over-dispersed distributions, where it is entirely clear what the
> distribution is, can be generated as GLM model +  one random
> effect per observation.  We have discussed this before.  This
> seems to me the preferred way to go, if such a model seems to
> fit the data.  I've not checked the current state of play re fitting
> such models in lme4 of lme4a; in the past some versions have
> allowed such a model.
>
> I like the simplicity of the one random effect per observation
> approach, as against what can seem the convoluted theoretical
> framework in which beta binomials live.
>
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics&  Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> http://www.maths.anu.edu.au/~johnm
>
>   >
>   >  On 25/06/2010, at 3:59 AM, Jeffrey Evans wrote:
>   >
>   >>  Since I am definitely *not* a mathematician, I am straying in over
> my head
>   >>  here.
>   >>
>   >>  I understand what you are saying - that there isn't a likelihood
> function
>   >>  for the quasi-binomial "distribution". And therefore, there is no-such
>   >>  distribution.
>   >>
>   >>  What do you think of the suggestion that a beta-binomial mixture
>   >>  distribution could be used to model overdispersed binomial data?
>   >>
>   >>  Would this be a techinically correct and logistically feasibile
> solution?
>   >>
>   >>  -jeff
>   >>
>   >>  -----Original Message-----
>   >>  From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf
> Of Douglas
>   >>  Bates
>   >>  Sent: Thursday, June 24, 2010 1:25 PM
>   >>  To: Jeffrey Evans
>   >>  Cc: r-sig-mixed-models at r-project.org
>   >>  Subject: Re: [R-sig-ME] lme4, lme4a, and overdispersed distributions
> (again)
>   >>
>   >>  On Thu, Jun 24, 2010 at 11:54 AM, Jeffrey Evans
>   >>  <Jeffrey.Evans at dartmouth.edu>  wrote:
>   >>>  Like others, I have experienced trouble with estimation of the scale
>   >>>  parameter using the quasi-distributions in lme4, which is necessary to
>   >>>  calculate QAICc and rank overdispersed generalized linear mixed models.
>   >>
>   >>>  I had several exchanges with Ben Bolker about this early last year
>   >>>  after his TREE paper came out
>   >>>  (http://www.cell.com/trends/ecology-evolution/abstract/S0169-5347%2809
>   >>>  %29000 19-6), and I know it's been discussed on on this list. Has
>   >>>  there been or is there any potential resolution to this forthcoming in
>   >>>  future releases of
>   >>>  lme4 or lme4a? I run into overdispersed binomial distributions
>   >>>  frequently and have had to use SAS to deal with them. SAS appears to
>   >>>  work, but it won't estimate the overdispersion parameter using laplace
>   >>>  estimation (only PQL), As I understand it, these pseudo-Iikelihoods
>   >>>  can't be used for model ranking. I don't know why SAS can't/won't, but
>   >>>  lme4 will run these quasi-binomial and quasi-poisson distributions with
>   >>  Laplace estimation.
>   >>
>   >>>  Is there a workable way to use lme4 for modeling overdispersed
>   >>>  binomial data?
>   >>
>   >>  I have trouble discussing this because I come from a background as a
>   >>  mathematician and am used to tracing derivations back to the original
>   >>  definitions.  So when I think of a likelihood (or, equivalently, a
>   >>  deviance) to be optimized it only makes sense to me if there is a
>   >>  probability distribution associated with the model.  And for the
>   >>  quasi-binomial and quasi-Poisson families, there isn't a probability
>   >>  distribution.  To me that means that discussing maximum likelihood
>   >>  estimators for such models is nonsense.  The models simply do not exist.
>   >>  One can play tricks in the case of a generalized linear model to
> estimate a
>   >>  "quasi-parameter" that isn't part of the probability distribution
> but it is
>   >>  foolhardy to expect that the tricks will automatically carry over to a
>   >>  generalized linear mixed model.
>   >>
>   >>  I am not denying that data that are over-dispersed with respect to the
>   >>  binomial or Poisson distributions can and do occur.  But having data
> like
>   >>  this and a desire to model it doesn't make the quasi families real.
>    In his
>   >>  signature Thierry Onkelinx quotes
>   >>
>   >>  The combination of some data and an aching desire for an answer does not
>   >>  ensure that a reasonable answer can be extracted from a given body
> of data.
>   >>  ~ John Tukey
>   >>
>   >>  I could and do plan to incorporate the negative binomial family but,
> without
>   >>  a definition that I can understand of a quasi-binomial or quasi-Poisson
>   >>  distribution and its associated probability function, I'm stuck. To
> me it's
>   >>  a "build bricks without straw" situation - you can't find maximum
> likelihood
>   >>  estimates for parameters that aren't part of the likelihood.
>   >>
>   >>  _______________________________________________
>   >>  R-sig-mixed-models at r-project.org mailing list
>   >>  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>   >
>
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics&  Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> http://www.maths.anu.edu.au/~johnm
>



From datkins at u.washington.edu  Mon Jun 28 23:04:09 2010
From: datkins at u.washington.edu (David Atkins)
Date: Mon, 28 Jun 2010 14:04:09 -0700
Subject: [R-sig-ME] Fwd: lme4, lme4a,
	and overdispersed distributions (again)
In-Reply-To: <C50176A7901048F8AF8819E50EB5B36F@Animal>
References: <C50176A7901048F8AF8819E50EB5B36F@Animal>
Message-ID: <4C290E49.1090406@u.washington.edu>



Jeffrey Evans wrote:
> Hi Dave, I see that Ben Bolker et al's wiki page also references it.
> 
> I'm not able to get glmer to do this. I do something similar with my dataset
> (dat$over = 1:nrow(dat)) and I get an error, not a warning.
> 
>> Xfit$over = 1:nrow(Xfit)
>> m800 = glmer(cbind(gmdat$SdlFinal, gmdat$SdlMax-gmdat$SdlFinal)
> ~soilpc3+(1|gmdat$ID)+(1|over),data=Xfit, family="binomial")
> 
> Error in function (fr, FL, glmFit, start, nAGQ, verbose)  : 
>   Number of levels of a grouping factor for the random effects
> must be less than the number of observations
> 
> What version are you using? I'm running version 33.

Sorry, I should have included sessionInfo() in my earlier email:

Looks like I'm running v 34 with Matrix v 41 (on R 2.11.1)

[And I did just re-confirm that it works with a different dataset...]

cheers, dave

 > sessionInfo()
R version 2.11.1 (2010-05-31)
i386-apple-darwin9.8.0

locale:
[1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] splines   stats     graphics  grDevices utils     datasets  methods
[8] base

other attached packages:
[1] lme4_0.999375-34   Matrix_0.999375-41 lattice_0.19-7
[4] car_2.0-0          survival_2.35-9    leaps_2.9
[7] nnet_7.3-1         MASS_7.3-6

loaded via a namespace (and not attached):
[1] grid_2.11.1    MCMCglmm_2.05  memisc_0.95-30 nlme_3.1-96
[5] stats4_2.11.1

> 
> Cheers,
> Jeff
> 
> 
> 
> John et al.--
> 
> Actually, looks like the current version of glmer *does* allow 
> observation level random-effects, though it throws you a little warning 
> (which seems entirely appropriate). (Thank you Doug!)
> 
> Using the data that we were recently discussing (and attached to one of 
> my previous posts "Data Redux"):
> 
>  > drink.df$over <- 1:nrow(drink.df)
>  > drk.glmer <- glmer(drinks ~ weekday*gender + (1 | id) + (1 | over),
> + 					data = drink.df, family = poisson,
> + 					verbose = TRUE)
> Number of levels of a grouping factor for the random effects
> is *equal* to n, the number of observations
>    0:     96443.694:  1.63299 0.215642 -0.912787 -0.0135537 0.0244628 
> -0.0137854 0.504067  1.13637  1.06483 0.418800 0.366592 0.288067 
> 0.354827 0.443268 0.392234 0.287877
> 
> [snip]
> 
>   76:     73629.541:  4.35359 0.187209 -5.44079 -0.101647 -0.0249078 
> -0.0721097 0.513271  1.65032  1.51045 0.132999 0.435110 0.356431 
> 0.382994 0.600458  1.26700 0.797529
> 
>  > summary(drk.glmer)
> Generalized linear mixed model fit by the Laplace approximation
> Formula: drinks ~ weekday * gender + (1 | id) + (1 | over)
>     Data: drink.df
>     AIC   BIC logLik deviance
>   73662 73805 -36815    73630
> Random effects:
>   Groups Name        Variance  Std.Dev.
>   over   (Intercept) 18.953746 4.35359
>   id     (Intercept)  0.035047 0.18721
> Number of obs: 56199, groups: over, 56199; id, 980
> 
> Fixed effects:
>                           Estimate Std. Error z value Pr(>|z|)
> (Intercept)              -5.44079    0.15315  -35.53  < 2e-16 ***
> weekdayMonday            -0.10165    0.22164   -0.46  0.64651
> weekdayTuesday           -0.02491    0.21837   -0.11  0.90919
> weekdayWednesday         -0.07211    0.22089   -0.33  0.74408
> weekdayThursday           0.51327    0.19953    2.57  0.01010 *
> weekdayFriday             1.65032    0.17918    9.21  < 2e-16 ***
> weekdaySaturday           1.51045    0.18023    8.38  < 2e-16 ***
> genderM                   0.13300    0.22493    0.59  0.55432
> weekdayMonday:genderM     0.43511    0.31295    1.39  0.16442
> weekdayTuesday:genderM    0.35643    0.31078    1.15  0.25142
> weekdayWednesday:genderM  0.38299    0.31327    1.22  0.22150
> weekdayThursday:genderM   0.60046    0.28439    2.11  0.03474 *
> weekdayFriday:genderM     1.26700    0.25845    4.90 9.48e-07 ***
> weekdaySaturday:genderM   0.79712    0.26107    3.05  0.00226 **
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> 
> As an aside, it is interesting to see for this particular data how the 
> variance swings pretty wildly between the model without over-dispersion 
> to the current one:
> 
>  > summary(drk.glmer)
> Generalized linear mixed model fit by the Laplace approximation
> Formula: drinks ~ weekday * gender + (1 | id)
>     Data: drink.df
>      AIC    BIC logLik deviance
>   146572 146706 -73271   146542
> Random effects:
>   Groups Name        Variance Std.Dev.
>   id     (Intercept) 0.92314  0.9608
> Number of obs: 56199, groups: id, 980
> 
> Fixed effects:
>                           Estimate Std. Error z value Pr(>|z|)
> (Intercept)              -1.23639    0.04863  -25.42  < 2e-16 ***
> weekdayMonday            -0.01035    0.03331   -0.31    0.756
> weekdayTuesday            0.02583    0.03304    0.78    0.434
> weekdayWednesday         -0.01161    0.03341   -0.35    0.728
> weekdayThursday           0.50049    0.02976   16.82  < 2e-16 ***
> weekdayFriday             1.12677    0.02691   41.87  < 2e-16 ***
> weekdaySaturday           1.05954    0.02709   39.11  < 2e-16 ***
> genderM                   0.30064    0.07099    4.24 2.28e-05 ***
> weekdayMonday:genderM     0.36970    0.04359    8.48  < 2e-16 ***
> weekdayTuesday:genderM    0.29552    0.04358    6.78 1.19e-11 ***
> weekdayWednesday:genderM  0.36295    0.04378    8.29  < 2e-16 ***
> weekdayThursday:genderM   0.45315    0.03913   11.58  < 2e-16 ***
> weekdayFriday:genderM     0.40290    0.03587   11.23  < 2e-16 ***
> weekdaySaturday:genderM   0.29764    0.03624    8.21  < 2e-16 ***
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> 
> These data in all likelihood are probably best modeled by a two-part 
> model, with zero vs. non-zero and count model for non-zeroes.  The 
> current version of MCMCglmm allows for zero-inflated models (where 
> zeroes are a mixture of a point mass and count distribution), and the 
> development version has hurdle formulations (with zero vs. non-zero, and 
> then truncated count distribution for non-zeroes).
> 
> cheers, Dave
> 
> John Maindonald wrote:
> 
> I think it more accurate to say that, in general, there may be
> a class of distributions, and therefore a possible multiplicity
> of likelihoods, not necessarily for distributions of exponential
> form.  This is a PhD thesis asking to be done, or maybe
> someone has already done it.
> 
> Over-dispersed distributions, where it is entirely clear what the
> distribution is, can be generated as GLM model +  one random
> effect per observation.  We have discussed this before.  This
> seems to me the preferred way to go, if such a model seems to
> fit the data.  I've not checked the current state of play re fitting
> such models in lme4 of lme4a; in the past some versions have
> allowed such a model.
> 
> I like the simplicity of the one random effect per observation
> approach, as against what can seem the convoluted theoretical
> framework in which beta binomials live.
> 
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> http://www.maths.anu.edu.au/~johnm
> 
>  >
>  > On 25/06/2010, at 3:59 AM, Jeffrey Evans wrote:
>  >
>  >> Since I am definitely *not* a mathematician, I am straying in over 
> my head
>  >> here.
>  >>
>  >> I understand what you are saying - that there isn't a likelihood 
> function
>  >> for the quasi-binomial "distribution". And therefore, there is no-such
>  >> distribution.
>  >>
>  >> What do you think of the suggestion that a beta-binomial mixture
>  >> distribution could be used to model overdispersed binomial data?
>  >>
>  >> Would this be a techinically correct and logistically feasibile 
> solution?
>  >>
>  >> -jeff
>  >>
>  >> -----Original Message-----
>  >> From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf 
> Of Douglas
>  >> Bates
>  >> Sent: Thursday, June 24, 2010 1:25 PM
>  >> To: Jeffrey Evans
>  >> Cc: r-sig-mixed-models at r-project.org
>  >> Subject: Re: [R-sig-ME] lme4, lme4a, and overdispersed distributions 
> (again)
>  >>
>  >> On Thu, Jun 24, 2010 at 11:54 AM, Jeffrey Evans
>  >> <Jeffrey.Evans at dartmouth.edu> wrote:
>  >>> Like others, I have experienced trouble with estimation of the scale
>  >>> parameter using the quasi-distributions in lme4, which is necessary to
>  >>> calculate QAICc and rank overdispersed generalized linear mixed models.
>  >>
>  >>> I had several exchanges with Ben Bolker about this early last year
>  >>> after his TREE paper came out
>  >>> (http://www.cell.com/trends/ecology-evolution/abstract/S0169-5347%2809
>  >>> %29000 19-6), and I know it's been discussed on on this list. Has
>  >>> there been or is there any potential resolution to this forthcoming in
>  >>> future releases of
>  >>> lme4 or lme4a? I run into overdispersed binomial distributions
>  >>> frequently and have had to use SAS to deal with them. SAS appears to
>  >>> work, but it won't estimate the overdispersion parameter using laplace
>  >>> estimation (only PQL), As I understand it, these pseudo-Iikelihoods
>  >>> can't be used for model ranking. I don't know why SAS can't/won't, but
>  >>> lme4 will run these quasi-binomial and quasi-poisson distributions with
>  >> Laplace estimation.
>  >>
>  >>> Is there a workable way to use lme4 for modeling overdispersed
>  >>> binomial data?
>  >>
>  >> I have trouble discussing this because I come from a background as a
>  >> mathematician and am used to tracing derivations back to the original
>  >> definitions.  So when I think of a likelihood (or, equivalently, a
>  >> deviance) to be optimized it only makes sense to me if there is a
>  >> probability distribution associated with the model.  And for the
>  >> quasi-binomial and quasi-Poisson families, there isn't a probability
>  >> distribution.  To me that means that discussing maximum likelihood
>  >> estimators for such models is nonsense.  The models simply do not exist.
>  >> One can play tricks in the case of a generalized linear model to 
> estimate a
>  >> "quasi-parameter" that isn't part of the probability distribution 
> but it is
>  >> foolhardy to expect that the tricks will automatically carry over to a
>  >> generalized linear mixed model.
>  >>
>  >> I am not denying that data that are over-dispersed with respect to the
>  >> binomial or Poisson distributions can and do occur.  But having data 
> like
>  >> this and a desire to model it doesn't make the quasi families real. 
>   In his
>  >> signature Thierry Onkelinx quotes
>  >>
>  >> The combination of some data and an aching desire for an answer does not
>  >> ensure that a reasonable answer can be extracted from a given body 
> of data.
>  >> ~ John Tukey
>  >>
>  >> I could and do plan to incorporate the negative binomial family but, 
> without
>  >> a definition that I can understand of a quasi-binomial or quasi-Poisson
>  >> distribution and its associated probability function, I'm stuck. To 
> me it's
>  >> a "build bricks without straw" situation - you can't find maximum 
> likelihood
>  >> estimates for parameters that aren't part of the likelihood.
>  >>
>  >> _______________________________________________
>  >> R-sig-mixed-models at r-project.org mailing list
>  >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>  >
> 
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> http://www.maths.anu.edu.au/~johnm
>



From john.maindonald at anu.edu.au  Tue Jun 29 00:46:27 2010
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Tue, 29 Jun 2010 08:46:27 +1000
Subject: [R-sig-ME] Fwd: lme4, lme4a,
	and overdispersed distributions (again)
In-Reply-To: <4C290E49.1090406@u.washington.edu>
References: <C50176A7901048F8AF8819E50EB5B36F@Animal>
	<4C290E49.1090406@u.washington.edu>
Message-ID: <8F072F50-D215-4DD8-8E1C-E79BD73EC376@anu.edu.au>

Verson lme4_0.999375-34   that David is using seems not to be on CRAN yet.
But, as Steven indicated, one can get it from R-forge using the command.

install.packages("lme4", repos="http://R-Forge.R-project.org")

This is available for MacOS X as well as (I presume) for Windows.  The immediately
previous (-33) release fails compilation for MacOS X.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 29/06/2010, at 7:04 AM, David Atkins wrote:

> 
> Jeffrey Evans wrote:
>> Hi Dave, I see that Ben Bolker et al's wiki page also references it.
>> I'm not able to get glmer to do this. I do something similar with my dataset
>> (dat$over = 1:nrow(dat)) and I get an error, not a warning.
>>> Xfit$over = 1:nrow(Xfit)
>>> m800 = glmer(cbind(gmdat$SdlFinal, gmdat$SdlMax-gmdat$SdlFinal)
>> ~soilpc3+(1|gmdat$ID)+(1|over),data=Xfit, family="binomial")
>> Error in function (fr, FL, glmFit, start, nAGQ, verbose)  :   Number of levels of a grouping factor for the random effects
>> must be less than the number of observations
>> What version are you using? I'm running version 33.
> 
> Sorry, I should have included sessionInfo() in my earlier email:
> 
> Looks like I'm running v 34 with Matrix v 41 (on R 2.11.1)
> 
> [And I did just re-confirm that it works with a different dataset...]
> 
> cheers, dave
> 
>> sessionInfo()
> R version 2.11.1 (2010-05-31)
> i386-apple-darwin9.8.0
> 
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
> 
> attached base packages:
> [1] splines   stats     graphics  grDevices utils     datasets  methods
> [8] base
> 
> other attached packages:
> [1] lme4_0.999375-34   Matrix_0.999375-41 lattice_0.19-7
> [4] car_2.0-0          survival_2.35-9    leaps_2.9
> [7] nnet_7.3-1         MASS_7.3-6
> 
> loaded via a namespace (and not attached):
> [1] grid_2.11.1    MCMCglmm_2.05  memisc_0.95-30 nlme_3.1-96
> [5] stats4_2.11.1
> 
>> Cheers,
>> Jeff
>> John et al.--
>> Actually, looks like the current version of glmer *does* allow observation level random-effects, though it throws you a little warning (which seems entirely appropriate). (Thank you Doug!)
>> Using the data that we were recently discussing (and attached to one of my previous posts "Data Redux"):
>>> drink.df$over <- 1:nrow(drink.df)
>>> drk.glmer <- glmer(drinks ~ weekday*gender + (1 | id) + (1 | over),
>> + 					data = drink.df, family = poisson,
>> + 					verbose = TRUE)
>> Number of levels of a grouping factor for the random effects
>> is *equal* to n, the number of observations
>>  0:     96443.694:  1.63299 0.215642 -0.912787 -0.0135537 0.0244628 -0.0137854 0.504067  1.13637  1.06483 0.418800 0.366592 0.288067 0.354827 0.443268 0.392234 0.287877
>> [snip]
>> 76:     73629.541:  4.35359 0.187209 -5.44079 -0.101647 -0.0249078 -0.0721097 0.513271  1.65032  1.51045 0.132999 0.435110 0.356431 0.382994 0.600458  1.26700 0.797529
>>> summary(drk.glmer)
>> Generalized linear mixed model fit by the Laplace approximation
>> Formula: drinks ~ weekday * gender + (1 | id) + (1 | over)
>>   Data: drink.df
>>   AIC   BIC logLik deviance
>> 73662 73805 -36815    73630
>> Random effects:
>> Groups Name        Variance  Std.Dev.
>> over   (Intercept) 18.953746 4.35359
>> id     (Intercept)  0.035047 0.18721
>> Number of obs: 56199, groups: over, 56199; id, 980
>> Fixed effects:
>>                         Estimate Std. Error z value Pr(>|z|)
>> (Intercept)              -5.44079    0.15315  -35.53  < 2e-16 ***
>> weekdayMonday            -0.10165    0.22164   -0.46  0.64651
>> weekdayTuesday           -0.02491    0.21837   -0.11  0.90919
>> weekdayWednesday         -0.07211    0.22089   -0.33  0.74408
>> weekdayThursday           0.51327    0.19953    2.57  0.01010 *
>> weekdayFriday             1.65032    0.17918    9.21  < 2e-16 ***
>> weekdaySaturday           1.51045    0.18023    8.38  < 2e-16 ***
>> genderM                   0.13300    0.22493    0.59  0.55432
>> weekdayMonday:genderM     0.43511    0.31295    1.39  0.16442
>> weekdayTuesday:genderM    0.35643    0.31078    1.15  0.25142
>> weekdayWednesday:genderM  0.38299    0.31327    1.22  0.22150
>> weekdayThursday:genderM   0.60046    0.28439    2.11  0.03474 *
>> weekdayFriday:genderM     1.26700    0.25845    4.90 9.48e-07 ***
>> weekdaySaturday:genderM   0.79712    0.26107    3.05  0.00226 **
>> ---
>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>> As an aside, it is interesting to see for this particular data how the variance swings pretty wildly between the model without over-dispersion to the current one:
>>> summary(drk.glmer)
>> Generalized linear mixed model fit by the Laplace approximation
>> Formula: drinks ~ weekday * gender + (1 | id)
>>   Data: drink.df
>>    AIC    BIC logLik deviance
>> 146572 146706 -73271   146542
>> Random effects:
>> Groups Name        Variance Std.Dev.
>> id     (Intercept) 0.92314  0.9608
>> Number of obs: 56199, groups: id, 980
>> Fixed effects:
>>                         Estimate Std. Error z value Pr(>|z|)
>> (Intercept)              -1.23639    0.04863  -25.42  < 2e-16 ***
>> weekdayMonday            -0.01035    0.03331   -0.31    0.756
>> weekdayTuesday            0.02583    0.03304    0.78    0.434
>> weekdayWednesday         -0.01161    0.03341   -0.35    0.728
>> weekdayThursday           0.50049    0.02976   16.82  < 2e-16 ***
>> weekdayFriday             1.12677    0.02691   41.87  < 2e-16 ***
>> weekdaySaturday           1.05954    0.02709   39.11  < 2e-16 ***
>> genderM                   0.30064    0.07099    4.24 2.28e-05 ***
>> weekdayMonday:genderM     0.36970    0.04359    8.48  < 2e-16 ***
>> weekdayTuesday:genderM    0.29552    0.04358    6.78 1.19e-11 ***
>> weekdayWednesday:genderM  0.36295    0.04378    8.29  < 2e-16 ***
>> weekdayThursday:genderM   0.45315    0.03913   11.58  < 2e-16 ***
>> weekdayFriday:genderM     0.40290    0.03587   11.23  < 2e-16 ***
>> weekdaySaturday:genderM   0.29764    0.03624    8.21  < 2e-16 ***
>> ---
>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>> These data in all likelihood are probably best modeled by a two-part model, with zero vs. non-zero and count model for non-zeroes.  The current version of MCMCglmm allows for zero-inflated models (where zeroes are a mixture of a point mass and count distribution), and the development version has hurdle formulations (with zero vs. non-zero, and then truncated count distribution for non-zeroes).
>> cheers, Dave
>> John Maindonald wrote:
>> I think it more accurate to say that, in general, there may be
>> a class of distributions, and therefore a possible multiplicity
>> of likelihoods, not necessarily for distributions of exponential
>> form.  This is a PhD thesis asking to be done, or maybe
>> someone has already done it.
>> Over-dispersed distributions, where it is entirely clear what the
>> distribution is, can be generated as GLM model +  one random
>> effect per observation.  We have discussed this before.  This
>> seems to me the preferred way to go, if such a model seems to
>> fit the data.  I've not checked the current state of play re fitting
>> such models in lme4 of lme4a; in the past some versions have
>> allowed such a model.
>> I like the simplicity of the one random effect per observation
>> approach, as against what can seem the convoluted theoretical
>> framework in which beta binomials live.
>> John Maindonald             email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Mathematics & Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>> http://www.maths.anu.edu.au/~johnm
>>> 
>>> On 25/06/2010, at 3:59 AM, Jeffrey Evans wrote:
>>> 
>>>> Since I am definitely *not* a mathematician, I am straying in over my head
>>>> here.
>>>> 
>>>> I understand what you are saying - that there isn't a likelihood function
>>>> for the quasi-binomial "distribution". And therefore, there is no-such
>>>> distribution.
>>>> 
>>>> What do you think of the suggestion that a beta-binomial mixture
>>>> distribution could be used to model overdispersed binomial data?
>>>> 
>>>> Would this be a techinically correct and logistically feasibile solution?
>>>> 
>>>> -jeff
>>>> 
>>>> -----Original Message-----
>>>> From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas
>>>> Bates
>>>> Sent: Thursday, June 24, 2010 1:25 PM
>>>> To: Jeffrey Evans
>>>> Cc: r-sig-mixed-models at r-project.org
>>>> Subject: Re: [R-sig-ME] lme4, lme4a, and overdispersed distributions (again)
>>>> 
>>>> On Thu, Jun 24, 2010 at 11:54 AM, Jeffrey Evans
>>>> <Jeffrey.Evans at dartmouth.edu> wrote:
>>>>> Like others, I have experienced trouble with estimation of the scale
>>>>> parameter using the quasi-distributions in lme4, which is necessary to
>>>>> calculate QAICc and rank overdispersed generalized linear mixed models.
>>>> 
>>>>> I had several exchanges with Ben Bolker about this early last year
>>>>> after his TREE paper came out
>>>>> (http://www.cell.com/trends/ecology-evolution/abstract/S0169-5347%2809
>>>>> %29000 19-6), and I know it's been discussed on on this list. Has
>>>>> there been or is there any potential resolution to this forthcoming in
>>>>> future releases of
>>>>> lme4 or lme4a? I run into overdispersed binomial distributions
>>>>> frequently and have had to use SAS to deal with them. SAS appears to
>>>>> work, but it won't estimate the overdispersion parameter using laplace
>>>>> estimation (only PQL), As I understand it, these pseudo-Iikelihoods
>>>>> can't be used for model ranking. I don't know why SAS can't/won't, but
>>>>> lme4 will run these quasi-binomial and quasi-poisson distributions with
>>>> Laplace estimation.
>>>> 
>>>>> Is there a workable way to use lme4 for modeling overdispersed
>>>>> binomial data?
>>>> 
>>>> I have trouble discussing this because I come from a background as a
>>>> mathematician and am used to tracing derivations back to the original
>>>> definitions.  So when I think of a likelihood (or, equivalently, a
>>>> deviance) to be optimized it only makes sense to me if there is a
>>>> probability distribution associated with the model.  And for the
>>>> quasi-binomial and quasi-Poisson families, there isn't a probability
>>>> distribution.  To me that means that discussing maximum likelihood
>>>> estimators for such models is nonsense.  The models simply do not exist.
>>>> One can play tricks in the case of a generalized linear model to estimate a
>>>> "quasi-parameter" that isn't part of the probability distribution but it is
>>>> foolhardy to expect that the tricks will automatically carry over to a
>>>> generalized linear mixed model.
>>>> 
>>>> I am not denying that data that are over-dispersed with respect to the
>>>> binomial or Poisson distributions can and do occur.  But having data like
>>>> this and a desire to model it doesn't make the quasi families real.   In his
>>>> signature Thierry Onkelinx quotes
>>>> 
>>>> The combination of some data and an aching desire for an answer does not
>>>> ensure that a reasonable answer can be extracted from a given body of data.
>>>> ~ John Tukey
>>>> 
>>>> I could and do plan to incorporate the negative binomial family but, without
>>>> a definition that I can understand of a quasi-binomial or quasi-Poisson
>>>> distribution and its associated probability function, I'm stuck. To me it's
>>>> a "build bricks without straw" situation - you can't find maximum likelihood
>>>> estimates for parameters that aren't part of the likelihood.
>>>> 
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>> John Maindonald             email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Mathematics & Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>> http://www.maths.anu.edu.au/~johnm
>> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From davidD at qimr.edu.au  Tue Jun 29 09:11:41 2010
From: davidD at qimr.edu.au (David Duffy)
Date: Tue, 29 Jun 2010 17:11:41 +1000 (EST)
Subject: [R-sig-ME] nplmreg and overdispersed distributions
In-Reply-To: <4C24E43C.9050207@u.washington.edu>
References: <9972FE5C-7E13-41E5-A3A3-46238B81266A@anu.edu.au>
	<4C24E43C.9050207@u.washington.edu>
Message-ID: <Pine.LNX.4.64.1006291704540.11425@orpheus.qimr.edu.au>

On Fri, 25 Jun 2010, David Atkins wrote:

>
>> summary(drk.glmer)
> Generalized linear mixed model fit by the Laplace approximation
> Formula: drinks ~ weekday * gender + (1 | id) + (1 | over)
>   Data: drink.df
>   AIC   BIC logLik deviance
> 73662 73805 -36815    73630
> Random effects:
> Groups Name        Variance  Std.Dev.
> over   (Intercept) 18.953746 4.35359
> id     (Intercept)  0.035047 0.18721
> Number of obs: 56199, groups: over, 56199; id, 980
>
> Fixed effects:
>                         Estimate Std. Error z value Pr(>|z|)
> (Intercept)              -5.44079    0.15315  -35.53  < 2e-16 ***
> weekdayMonday            -0.10165    0.22164   -0.46  0.64651
> weekdayTuesday           -0.02491    0.21837   -0.11  0.90919
> weekdayWednesday         -0.07211    0.22089   -0.33  0.74408
> weekdayThursday           0.51327    0.19953    2.57  0.01010 *
> weekdayFriday             1.65032    0.17918    9.21  < 2e-16 ***
> weekdaySaturday           1.51045    0.18023    8.38  < 2e-16 ***
> genderM                   0.13300    0.22493    0.59  0.55432
> weekdayMonday:genderM     0.43511    0.31295    1.39  0.16442
> weekdayTuesday:genderM    0.35643    0.31078    1.15  0.25142
> weekdayWednesday:genderM  0.38299    0.31327    1.22  0.22150
> weekdayThursday:genderM   0.60046    0.28439    2.11  0.03474 *
> weekdayFriday:genderM     1.26700    0.25845    4.90 9.48e-07 ***
> weekdaySaturday:genderM   0.79712    0.26107    3.05  0.00226 **
> ---
>

I played around using the nplmreg package for these data:

x <- read.table("atkinsdrinking.dat",h=T)
x$id <- factor(x$id)
x$weekday <- factor(x$weekday)
library(npmlreg)
w1 <- allvc(drinks ~ weekday * gender, random=~1|id,
             data=x, k=3, family=poisson())
w2 <- allvc(drinks ~ weekday * gender, random=~1|id,
             data=x, k=4, family=poisson())
w3 <- allvc(drinks ~ weekday * gender, random=~1|id,
           data=x, k=5, family=poisson())


summary(w3)

Call:  allvc(formula = drinks ~ weekday * gender, random = ~1 | id, 
family = poisson(), data = x, k = 5)

Coefficients:
                     Estimate Std. Error     t value
weekday2         -0.01078244 0.03327762  -0.3240146
weekday3          0.02648464 0.03300293   0.8024937
weekday4         -0.01053878 0.03337888  -0.3157319
weekday5          0.50105222 0.02972589  16.8557542
weekday6          1.12753214 0.02687809  41.9498558
weekday7          1.06078775 0.02706839  39.1891739
genderM           0.37350999 0.03174335  11.7665577
weekday2:genderM  0.36926108 0.04355992   8.4770837
weekday3:genderM  0.29559643 0.04353879   6.7892661
weekday4:genderM  0.36289380 0.04373133   8.2982575
weekday5:genderM  0.45263084 0.03909019  11.5791429
weekday6:genderM  0.40175135 0.03582774  11.2134145
weekday7:genderM  0.29630811 0.03621084   8.1828555
MASS1            -2.65406245 0.03205365 -82.8006201
MASS2            -1.58730489 0.02522484 -62.9262717
MASS3            -0.83696785 0.02427729 -34.4753395
MASS4            -0.20183478 0.02463629  -8.1925804
MASS5             0.42940967 0.02434547  17.6381755

Mixture proportions:
      MASS1       MASS2       MASS3       MASS4       MASS5
0.19720118  0.31780163  0.27323454  0.12845641  0.08330624

Random effect distribution - standard deviation:	   0.9206557

-2 log L:	    184333.2     Convergence at iteration  76


This is not too slow, though worsening as the number of components 
increasing (looking at the likelihoods, I might still need a few more 
components).

another 2c,

David Duffy.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From cm744 at st-andrews.ac.uk  Tue Jun 29 13:57:28 2010
From: cm744 at st-andrews.ac.uk (Chris Mcowen)
Date: Tue, 29 Jun 2010 12:57:28 +0100
Subject: [R-sig-ME] Multi level response variables
Message-ID: <367C965A-F573-4971-9412-311F5DEF1FF2@st-andrews.ac.uk>

Dear List,

I am a little unsure how to structure my model and was after some advice. I am a little unsure if this question is appropriate for this list, if it is not please just delete and accept my apologise.

I have 10 factors that are categorical variables and 5 levels of response variables -

WOODYNONWOODY		L2_REGIONS	SEASONALITY	FLORALSYMMETRY	- Factors		IUCN - RESPONSE 
2						2						2						2				NE
2						4						2						2				LC
2						1						2						2				CR
2						1						2						1				NE
2						3						2						2				NE
2						1						1						2				NE
2						1						2						3				NT
1						1						3						2				NE
2						2						2						2				LC
2						1						5						2				LC

The response variables relate to how threatened the species is  - from not threatened to extinct (1-5)

My first approach was to divide the 5 response levels into 2 - threatened ( levels 1+2) or non threatened (levels 3,4+5) and call

model1 <- lmer(THREAT~1+(1|ORDER/FAMILY) + STORAGE_ORGAN + BREEDING_SYSTEM + POLLEN_DISPERSAL + LIFE_FORM + FRUIT + ENDOSPERM + HABIT + WOODY_NONWOODY + L2_REGIONS + SEASONALITY + ALTITUDE + SEED_FRUIT + FLORAL_SYMMETRY, family=binomial) 

Which worked well, now i want to see how the factors influence the individual response variables i.e do species with LC for instance, posses certain factors, and it is this i am unsure how to build into a lmer model.

My overall goal would be to use the model as a predictive model and ask -  "if a species has factors a ,b,c for instance , can i predict what the response level (0-5) would be". 

Thanks, and once again i apologise if this is not the right place to ask this type of question.

Chris


Chris Mcowen
PhD Student

Room 15
Sir Harold Mitchell Building
University of St Andrews
St Andrews
Fife
KY16 9TH
UK
Phone 01334 463381 



From Jeffrey.Evans at Dartmouth.edu  Tue Jun 29 14:40:15 2010
From: Jeffrey.Evans at Dartmouth.edu (Jeffrey Evans)
Date: 29 Jun 2010 08:40:15 -0400
Subject: [R-sig-ME] Fwd: lme4, lme4a,
	and overdispersed distributions (again)
Message-ID: <138811101@comet.Dartmouth.EDU>

Thanks John,
You answered my question before it got past my lips.

Following on this, if I run two non-nested models with overdispersion accouted for using a random observation effect, what would be the proper way to rank them? Would you just use AICc in the standard way? Or if you were to use QAICc, what do you use as the scale parameter? I'm not exactly sure how to interpret the result.

Cheers,
Jeff

--- John Maindonald wrote:
Verson lme4_0.999375-34   that David is using seems not to be on CRAN yet.
But, as Steven indicated, one can get it from R-forge using the command.

install.packages("lme4", repos="http://R-Forge.R-project.org")

This is available for MacOS X as well as (I presume) for Windows.  The immediately
previous (-33) release fails compilation for MacOS X.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 29/06/2010, at 7:04 AM, David Atkins wrote:

> 
> Jeffrey Evans wrote:
>> Hi Dave, I see that Ben Bolker et al's wiki page also references it.
>> I'm not able to get glmer to do this. I do something similar with my dataset
>> (dat$over = 1:nrow(dat)) and I get an error, not a warning.
>>> Xfit$over = 1:nrow(Xfit)
>>> m800 = glmer(cbind(gmdat$SdlFinal, gmdat$SdlMax-gmdat$SdlFinal)
>> ~soilpc3+(1|gmdat$ID)+(1|over),data=Xfit, family="binomial")
>> Error in function (fr, FL, glmFit, start, nAGQ, verbose)  :   Number of levels of a grouping factor for the random effects
>> must be less than the number of observations
>> What version are you using? I'm running version 33.
> 
> Sorry, I should have included sessionInfo() in my earlier email:
> 
> Looks like I'm running v 34 with Matrix v 41 (on R 2.11.1)
> 
> [And I did just re-confirm that it works with a different dataset...]
> 
> cheers, dave
> 
>> sessionInfo()
> R version 2.11.1 (2010-05-31)
> i386-apple-darwin9.8.0
> 
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
> 
> attached base packages:
> [1] splines   stats     graphics  grDevices utils     datasets  methods
> [8] base
> 
> other attached packages:
> [1] lme4_0.999375-34   Matrix_0.999375-41 lattice_0.19-7
> [4] car_2.0-0          survival_2.35-9    leaps_2.9
> [7] nnet_7.3-1         MASS_7.3-6
> 
> loaded via a namespace (and not attached):
> [1] grid_2.11.1    MCMCglmm_2.05  memisc_0.95-30 nlme_3.1-96
> [5] stats4_2.11.1
> 
>> Cheers,
>> Jeff
>> John et al.--
>> Actually, looks like the current version of glmer *does* allow observation level random-effects, though it throws you a little warning (which seems entirely appropriate). (Thank you Doug!)
>> Using the data that we were recently discussing (and attached to one of my previous posts "Data Redux"):
>>> drink.df$over <- 1:nrow(drink.df)
>>> drk.glmer <- glmer(drinks ~ weekday*gender + (1 | id) + (1 | over),
>> + 					data = drink.df, family = poisson,
>> + 					verbose = TRUE)
>> Number of levels of a grouping factor for the random effects
>> is *equal* to n, the number of observations
>>  0:     96443.694:  1.63299 0.215642 -0.912787 -0.0135537 0.0244628 -0.0137854 0.504067  1.13637  1.06483 0.418800 0.366592 0.288067 0.354827 0.443268 0.392234 0.287877
>> [snip]
>> 76:     73629.541:  4.35359 0.187209 -5.44079 -0.101647 -0.0249078 -0.0721097 0.513271  1.65032  1.51045 0.132999 0.435110 0.356431 0.382994 0.600458  1.26700 0.797529
>>> summary(drk.glmer)
>> Generalized linear mixed model fit by the Laplace approximation
>> Formula: drinks ~ weekday * gender + (1 | id) + (1 | over)
>>   Data: drink.df
>>   AIC   BIC logLik deviance
>> 73662 73805 -36815    73630
>> Random effects:
>> Groups Name        Variance  Std.Dev.
>> over   (Intercept) 18.953746 4.35359
>> id     (Intercept)  0.035047 0.18721
>> Number of obs: 56199, groups: over, 56199; id, 980
>> Fixed effects:
>>                         Estimate Std. Error z value Pr(>|z|)
>> (Intercept)              -5.44079    0.15315  -35.53  < 2e-16 ***
>> weekdayMonday            -0.10165    0.22164   -0.46  0.64651
>> weekdayTuesday           -0.02491    0.21837   -0.11  0.90919
>> weekdayWednesday         -0.07211    0.22089   -0.33  0.74408
>> weekdayThursday           0.51327    0.19953    2.57  0.01010 *
>> weekdayFriday             1.65032    0.17918    9.21  < 2e-16 ***
>> weekdaySaturday           1.51045    0.18023    8.38  < 2e-16 ***
>> genderM                   0.13300    0.22493    0.59  0.55432
>> weekdayMonday:genderM     0.43511    0.31295    1.39  0.16442
>> weekdayTuesday:genderM    0.35643    0.31078    1.15  0.25142
>> weekdayWednesday:genderM  0.38299    0.31327    1.22  0.22150
>> weekdayThursday:genderM   0.60046    0.28439    2.11  0.03474 *
>> weekdayFriday:genderM     1.26700    0.25845    4.90 9.48e-07 ***
>> weekdaySaturday:genderM   0.79712    0.26107    3.05  0.00226 **
>> ---
>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>> As an aside, it is interesting to see for this particular data how the variance swings pretty wildly between the model without over-dispersion to the current one:
>>> summary(drk.glmer)
>> Generalized linear mixed model fit by the Laplace approximation
>> Formula: drinks ~ weekday * gender + (1 | id)
>>   Data: drink.df
>>    AIC    BIC logLik deviance
>> 146572 146706 -73271   146542
>> Random effects:
>> Groups Name        Variance Std.Dev.
>> id     (Intercept) 0.92314  0.9608
>> Number of obs: 56199, groups: id, 980
>> Fixed effects:
>>                         Estimate Std. Error z value Pr(>|z|)
>> (Intercept)              -1.23639    0.04863  -25.42  < 2e-16 ***
>> weekdayMonday            -0.01035    0.03331   -0.31    0.756
>> weekdayTuesday            0.02583    0.03304    0.78    0.434
>> weekdayWednesday         -0.01161    0.03341   -0.35    0.728
>> weekdayThursday           0.50049    0.02976   16.82  < 2e-16 ***
>> weekdayFriday             1.12677    0.02691   41.87  < 2e-16 ***
>> weekdaySaturday           1.05954    0.02709   39.11  < 2e-16 ***
>> genderM                   0.30064    0.07099    4.24 2.28e-05 ***
>> weekdayMonday:genderM     0.36970    0.04359    8.48  < 2e-16 ***
>> weekdayTuesday:genderM    0.29552    0.04358    6.78 1.19e-11 ***
>> weekdayWednesday:genderM  0.36295    0.04378    8.29  < 2e-16 ***
>> weekdayThursday:genderM   0.45315    0.03913   11.58  < 2e-16 ***
>> weekdayFriday:genderM     0.40290    0.03587   11.23  < 2e-16 ***
>> weekdaySaturday:genderM   0.29764    0.03624    8.21  < 2e-16 ***
>> ---
>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>> These data in all likelihood are probably best modeled by a two-part model, with zero vs. non-zero and count model for non-zeroes.  The current version of MCMCglmm allows for zero-inflated models (where zeroes are a mixture of a point mass and count distribution), and the development version has hurdle formulations (with zero vs. non-zero, and then truncated count distribution for non-zeroes).
>> cheers, Dave
>> John Maindonald wrote:
>> I think it more accurate to say that, in general, there may be
>> a class of distributions, and therefore a possible multiplicity
>> of likelihoods, not necessarily for distributions of exponential
>> form.  This is a PhD thesis asking to be done, or maybe
>> someone has already done it.
>> Over-dispersed distributions, where it is entirely clear what the
>> distribution is, can be generated as GLM model +  one random
>> effect per observation.  We have discussed this before.  This
>> seems to me the preferred way to go, if such a model seems to
>> fit the data.  I've not checked the current state of play re fitting
>> such models in lme4 of lme4a; in the past some versions have
>> allowed such a model.
>> I like the simplicity of the one random effect per observation
>> approach, as against what can seem the convoluted theoretical
>> framework in which beta binomials live.
>> John Maindonald             email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Mathematics & Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>> http://www.maths.anu.edu.au/~johnm
>>> 
>>> On 25/06/2010, at 3:59 AM, Jeffrey Evans wrote:
>>> 
>>>> Since I am definitely *not* a mathematician, I am straying in over my head
>>>> here.
>>>> 
>>>> I understand what you are saying - that there isn't a likelihood function
>>>> for the quasi-binomial "distribution". And therefore, there is no-such
>>>> distribution.
>>>> 
>>>> What do you think of the suggestion that a beta-binomial mixture
>>>> distribution could be used to model overdispersed binomial data?
>>>> 
>>>> Would this be a techinically correct and logistically feasibile solution?
>>>> 
>>>> -jeff
>>>> 
>>>> -----Original Message-----
>>>> From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas
>>>> Bates
>>>> Sent: Thursday, June 24, 2010 1:25 PM
>>>> To: Jeffrey Evans
>>>> Cc: r-sig-mixed-models at r-project.org
>>>> Subject: Re: [R-sig-ME] lme4, lme4a, and overdispersed distributions (again)
>>>> 
>>>> On Thu, Jun 24, 2010 at 11:54 AM, Jeffrey Evans
>>>> <Jeffrey.Evans at dartmouth.edu> wrote:
>>>>> Like others, I have experienced trouble with estimation of the scale
>>>>> parameter using the quasi-distributions in lme4, which is necessary to
>>>>> calculate QAICc and rank overdispersed generalized linear mixed models.
>>>> 
>>>>> I had several exchanges with Ben Bolker about this early last year
>>>>> after his TREE paper came out
>>>>> (http://www.cell.com/trends/ecology-evolution/abstract/S0169-5347%2809
>>>>> %29000 19-6), and I know it's been discussed on on this list. Has
>>>>> there been or is there any potential resolution to this forthcoming in
>>>>> future releases of
>>>>> lme4 or lme4a? I run into overdispersed binomial distributions
>>>>> frequently and have had to use SAS to deal with them. SAS appears to
>>>>> work, but it won't estimate the overdispersion parameter using laplace
>>>>> estimation (only PQL), As I understand it, these pseudo-Iikelihoods
>>>>> can't be used for model ranking. I don't know why SAS can't/won't, but
>>>>> lme4 will run these quasi-binomial and quasi-poisson distributions with
>>>> Laplace estimation.
>>>> 
>>>>> Is there a workable way to use lme4 for modeling overdispersed
>>>>> binomial data?
>>>> 
>>>> I have trouble discussing this because I come from a background as a
>>>> mathematician and am used to tracing derivations back to the original
>>>> definitions.  So when I think of a likelihood (or, equivalently, a
>>>> deviance) to be optimized it only makes sense to me if there is a
>>>> probability distribution associated with the model.  And for the
>>>> quasi-binomial and quasi-Poisson families, there isn't a probability
>>>> distribution.  To me that means that discussing maximum likelihood
>>>> estimators for such models is nonsense.  The models simply do not exist.
>>>> One can play tricks in the case of a generalized linear model to estimate a
>>>> "quasi-parameter" that isn't part of the probability distribution but it is
>>>> foolhardy to expect that the tricks will automatically carry over to a
>>>> generalized linear mixed model.
>>>> 
>>>> I am not denying that data that are over-dispersed with respect to the
>>>> binomial or Poisson distributions can and do occur.  But having data like
>>>> this and a desire to model it doesn't make the quasi families real.   In his
>>>> signature Thierry Onkelinx quotes
>>>> 
>>>> The combination of some data and an aching desire for an answer does not
>>>> ensure that a reasonable answer can be extracted from a given body of data.
>>>> ~ John Tukey
>>>> 
>>>> I could and do plan to incorporate the negative binomial family but, without
>>>> a definition that I can understand of a quasi-binomial or quasi-Poisson
>>>> distribution and its associated probability function, I'm stuck. To me it's
>>>> a "build bricks without straw" situation - you can't find maximum likelihood
>>>> estimates for parameters that aren't part of the likelihood.
>>>> 
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>> John Maindonald             email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Mathematics & Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>> http://www.maths.anu.edu.au/~johnm
>> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
--- end of quote ---



From Mike.Lawrence at dal.ca  Tue Jun 29 15:40:30 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Tue, 29 Jun 2010 10:40:30 -0300
Subject: [R-sig-ME] Multi level response variables
In-Reply-To: <367C965A-F573-4971-9412-311F5DEF1FF2@st-andrews.ac.uk>
References: <367C965A-F573-4971-9412-311F5DEF1FF2@st-andrews.ac.uk>
Message-ID: <AANLkTiktsFOFay8NRjoT_CIZKzHQqljKkA-2iAjzX3Ev@mail.gmail.com>

I'm no expert, but I think you want family='ordinal' from the MCMCglmm
package. The package page on cran has a bunch of documentation
materials (tutorial, etc):
http://cran.r-project.org/web/packages/MCMCglmm/index.html

On Tue, Jun 29, 2010 at 8:57 AM, Chris Mcowen <cm744 at st-andrews.ac.uk> wrote:
> Dear List,
>
> I am a little unsure how to structure my model and was after some advice. I am a little unsure if this question is appropriate for this list, if it is not please just delete and accept my apologise.
>
> I have 10 factors that are categorical variables and 5 levels of response variables -
>
> WOODYNONWOODY ? ? ? ? ? L2_REGIONS ? ? ?SEASONALITY ? ? FLORALSYMMETRY ?- Factors ? ? ? ? ? ? ? IUCN - RESPONSE
> 2 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 2 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 2 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 2 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? NE
> 2 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 4 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 2 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 2 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? LC
> 2 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 1 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 2 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 2 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? CR
> 2 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 1 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 2 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 1 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? NE
> 2 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 3 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 2 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 2 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? NE
> 2 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 1 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 1 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 2 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? NE
> 2 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 1 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 2 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 3 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? NT
> 1 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 1 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 3 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 2 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? NE
> 2 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 2 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 2 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 2 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? LC
> 2 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 1 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 5 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 2 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? LC
>
> The response variables relate to how threatened the species is ?- from not threatened to extinct (1-5)
>
> My first approach was to divide the 5 response levels into 2 - threatened ( levels 1+2) or non threatened (levels 3,4+5) and call
>
> model1 <- lmer(THREAT~1+(1|ORDER/FAMILY) + STORAGE_ORGAN + BREEDING_SYSTEM + POLLEN_DISPERSAL + LIFE_FORM + FRUIT + ENDOSPERM + HABIT + WOODY_NONWOODY + L2_REGIONS + SEASONALITY + ALTITUDE + SEED_FRUIT + FLORAL_SYMMETRY, family=binomial)
>
> Which worked well, now i want to see how the factors influence the individual response variables i.e do species with LC for instance, posses certain factors, and it is this i am unsure how to build into a lmer model.
>
> My overall goal would be to use the model as a predictive model and ask - ?"if a species has factors a ,b,c for instance , can i predict what the response level (0-5) would be".
>
> Thanks, and once again i apologise if this is not the right place to ask this type of question.
>
> Chris
>
>
> Chris Mcowen
> PhD Student
>
> Room 15
> Sir Harold Mitchell Building
> University of St Andrews
> St Andrews
> Fife
> KY16 9TH
> UK
> Phone 01334 463381
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~

From bates at stat.wisc.edu  Tue Jun 29 17:00:43 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 29 Jun 2010 10:00:43 -0500
Subject: [R-sig-ME] Fwd: lme4, lme4a,
	and overdispersed distributions 	(again)
In-Reply-To: <8F072F50-D215-4DD8-8E1C-E79BD73EC376@anu.edu.au>
References: <C50176A7901048F8AF8819E50EB5B36F@Animal>
	<4C290E49.1090406@u.washington.edu>
	<8F072F50-D215-4DD8-8E1C-E79BD73EC376@anu.edu.au>
Message-ID: <AANLkTik1OwMGGP5-OIpb6jERLugrKbWzId02pesXvAMt@mail.gmail.com>

Oops.  It should have been uploaded to CRAN a long time ago.  I have
now done so.

On Mon, Jun 28, 2010 at 5:46 PM, John Maindonald
<john.maindonald at anu.edu.au> wrote:
> Verson lme4_0.999375-34 ? that David is using seems not to be on CRAN yet.
> But, as Steven indicated, one can get it from R-forge using the command.
>
> install.packages("lme4", repos="http://R-Forge.R-project.org")
>
> This is available for MacOS X as well as (I presume) for Windows. ?The immediately
> previous (-33) release fails compilation for MacOS X.
>
> John Maindonald ? ? ? ? ? ? email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473 ? ?fax ?: +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> http://www.maths.anu.edu.au/~johnm
>
> On 29/06/2010, at 7:04 AM, David Atkins wrote:
>
>>
>> Jeffrey Evans wrote:
>>> Hi Dave, I see that Ben Bolker et al's wiki page also references it.
>>> I'm not able to get glmer to do this. I do something similar with my dataset
>>> (dat$over = 1:nrow(dat)) and I get an error, not a warning.
>>>> Xfit$over = 1:nrow(Xfit)
>>>> m800 = glmer(cbind(gmdat$SdlFinal, gmdat$SdlMax-gmdat$SdlFinal)
>>> ~soilpc3+(1|gmdat$ID)+(1|over),data=Xfit, family="binomial")
>>> Error in function (fr, FL, glmFit, start, nAGQ, verbose) ?: ? Number of levels of a grouping factor for the random effects
>>> must be less than the number of observations
>>> What version are you using? I'm running version 33.
>>
>> Sorry, I should have included sessionInfo() in my earlier email:
>>
>> Looks like I'm running v 34 with Matrix v 41 (on R 2.11.1)
>>
>> [And I did just re-confirm that it works with a different dataset...]
>>
>> cheers, dave
>>
>>> sessionInfo()
>> R version 2.11.1 (2010-05-31)
>> i386-apple-darwin9.8.0
>>
>> locale:
>> [1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
>>
>> attached base packages:
>> [1] splines ? stats ? ? graphics ?grDevices utils ? ? datasets ?methods
>> [8] base
>>
>> other attached packages:
>> [1] lme4_0.999375-34 ? Matrix_0.999375-41 lattice_0.19-7
>> [4] car_2.0-0 ? ? ? ? ?survival_2.35-9 ? ?leaps_2.9
>> [7] nnet_7.3-1 ? ? ? ? MASS_7.3-6
>>
>> loaded via a namespace (and not attached):
>> [1] grid_2.11.1 ? ?MCMCglmm_2.05 ?memisc_0.95-30 nlme_3.1-96
>> [5] stats4_2.11.1
>>
>>> Cheers,
>>> Jeff
>>> John et al.--
>>> Actually, looks like the current version of glmer *does* allow observation level random-effects, though it throws you a little warning (which seems entirely appropriate). (Thank you Doug!)
>>> Using the data that we were recently discussing (and attached to one of my previous posts "Data Redux"):
>>>> drink.df$over <- 1:nrow(drink.df)
>>>> drk.glmer <- glmer(drinks ~ weekday*gender + (1 | id) + (1 | over),
>>> + ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?data = drink.df, family = poisson,
>>> + ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?verbose = TRUE)
>>> Number of levels of a grouping factor for the random effects
>>> is *equal* to n, the number of observations
>>> ?0: ? ? 96443.694: ?1.63299 0.215642 -0.912787 -0.0135537 0.0244628 -0.0137854 0.504067 ?1.13637 ?1.06483 0.418800 0.366592 0.288067 0.354827 0.443268 0.392234 0.287877
>>> [snip]
>>> 76: ? ? 73629.541: ?4.35359 0.187209 -5.44079 -0.101647 -0.0249078 -0.0721097 0.513271 ?1.65032 ?1.51045 0.132999 0.435110 0.356431 0.382994 0.600458 ?1.26700 0.797529
>>>> summary(drk.glmer)
>>> Generalized linear mixed model fit by the Laplace approximation
>>> Formula: drinks ~ weekday * gender + (1 | id) + (1 | over)
>>> ? Data: drink.df
>>> ? AIC ? BIC logLik deviance
>>> 73662 73805 -36815 ? ?73630
>>> Random effects:
>>> Groups Name ? ? ? ?Variance ?Std.Dev.
>>> over ? (Intercept) 18.953746 4.35359
>>> id ? ? (Intercept) ?0.035047 0.18721
>>> Number of obs: 56199, groups: over, 56199; id, 980
>>> Fixed effects:
>>> ? ? ? ? ? ? ? ? ? ? ? ? Estimate Std. Error z value Pr(>|z|)
>>> (Intercept) ? ? ? ? ? ? ?-5.44079 ? ?0.15315 ?-35.53 ?< 2e-16 ***
>>> weekdayMonday ? ? ? ? ? ?-0.10165 ? ?0.22164 ? -0.46 ?0.64651
>>> weekdayTuesday ? ? ? ? ? -0.02491 ? ?0.21837 ? -0.11 ?0.90919
>>> weekdayWednesday ? ? ? ? -0.07211 ? ?0.22089 ? -0.33 ?0.74408
>>> weekdayThursday ? ? ? ? ? 0.51327 ? ?0.19953 ? ?2.57 ?0.01010 *
>>> weekdayFriday ? ? ? ? ? ? 1.65032 ? ?0.17918 ? ?9.21 ?< 2e-16 ***
>>> weekdaySaturday ? ? ? ? ? 1.51045 ? ?0.18023 ? ?8.38 ?< 2e-16 ***
>>> genderM ? ? ? ? ? ? ? ? ? 0.13300 ? ?0.22493 ? ?0.59 ?0.55432
>>> weekdayMonday:genderM ? ? 0.43511 ? ?0.31295 ? ?1.39 ?0.16442
>>> weekdayTuesday:genderM ? ?0.35643 ? ?0.31078 ? ?1.15 ?0.25142
>>> weekdayWednesday:genderM ?0.38299 ? ?0.31327 ? ?1.22 ?0.22150
>>> weekdayThursday:genderM ? 0.60046 ? ?0.28439 ? ?2.11 ?0.03474 *
>>> weekdayFriday:genderM ? ? 1.26700 ? ?0.25845 ? ?4.90 9.48e-07 ***
>>> weekdaySaturday:genderM ? 0.79712 ? ?0.26107 ? ?3.05 ?0.00226 **
>>> ---
>>> Signif. codes: ?0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>> As an aside, it is interesting to see for this particular data how the variance swings pretty wildly between the model without over-dispersion to the current one:
>>>> summary(drk.glmer)
>>> Generalized linear mixed model fit by the Laplace approximation
>>> Formula: drinks ~ weekday * gender + (1 | id)
>>> ? Data: drink.df
>>> ? ?AIC ? ?BIC logLik deviance
>>> 146572 146706 -73271 ? 146542
>>> Random effects:
>>> Groups Name ? ? ? ?Variance Std.Dev.
>>> id ? ? (Intercept) 0.92314 ?0.9608
>>> Number of obs: 56199, groups: id, 980
>>> Fixed effects:
>>> ? ? ? ? ? ? ? ? ? ? ? ? Estimate Std. Error z value Pr(>|z|)
>>> (Intercept) ? ? ? ? ? ? ?-1.23639 ? ?0.04863 ?-25.42 ?< 2e-16 ***
>>> weekdayMonday ? ? ? ? ? ?-0.01035 ? ?0.03331 ? -0.31 ? ?0.756
>>> weekdayTuesday ? ? ? ? ? ?0.02583 ? ?0.03304 ? ?0.78 ? ?0.434
>>> weekdayWednesday ? ? ? ? -0.01161 ? ?0.03341 ? -0.35 ? ?0.728
>>> weekdayThursday ? ? ? ? ? 0.50049 ? ?0.02976 ? 16.82 ?< 2e-16 ***
>>> weekdayFriday ? ? ? ? ? ? 1.12677 ? ?0.02691 ? 41.87 ?< 2e-16 ***
>>> weekdaySaturday ? ? ? ? ? 1.05954 ? ?0.02709 ? 39.11 ?< 2e-16 ***
>>> genderM ? ? ? ? ? ? ? ? ? 0.30064 ? ?0.07099 ? ?4.24 2.28e-05 ***
>>> weekdayMonday:genderM ? ? 0.36970 ? ?0.04359 ? ?8.48 ?< 2e-16 ***
>>> weekdayTuesday:genderM ? ?0.29552 ? ?0.04358 ? ?6.78 1.19e-11 ***
>>> weekdayWednesday:genderM ?0.36295 ? ?0.04378 ? ?8.29 ?< 2e-16 ***
>>> weekdayThursday:genderM ? 0.45315 ? ?0.03913 ? 11.58 ?< 2e-16 ***
>>> weekdayFriday:genderM ? ? 0.40290 ? ?0.03587 ? 11.23 ?< 2e-16 ***
>>> weekdaySaturday:genderM ? 0.29764 ? ?0.03624 ? ?8.21 ?< 2e-16 ***
>>> ---
>>> Signif. codes: ?0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>> These data in all likelihood are probably best modeled by a two-part model, with zero vs. non-zero and count model for non-zeroes. ?The current version of MCMCglmm allows for zero-inflated models (where zeroes are a mixture of a point mass and count distribution), and the development version has hurdle formulations (with zero vs. non-zero, and then truncated count distribution for non-zeroes).
>>> cheers, Dave
>>> John Maindonald wrote:
>>> I think it more accurate to say that, in general, there may be
>>> a class of distributions, and therefore a possible multiplicity
>>> of likelihoods, not necessarily for distributions of exponential
>>> form. ?This is a PhD thesis asking to be done, or maybe
>>> someone has already done it.
>>> Over-dispersed distributions, where it is entirely clear what the
>>> distribution is, can be generated as GLM model + ?one random
>>> effect per observation. ?We have discussed this before. ?This
>>> seems to me the preferred way to go, if such a model seems to
>>> fit the data. ?I've not checked the current state of play re fitting
>>> such models in lme4 of lme4a; in the past some versions have
>>> allowed such a model.
>>> I like the simplicity of the one random effect per observation
>>> approach, as against what can seem the convoluted theoretical
>>> framework in which beta binomials live.
>>> John Maindonald ? ? ? ? ? ? email: john.maindonald at anu.edu.au
>>> phone : +61 2 (6125)3473 ? ?fax ?: +61 2(6125)5549
>>> Centre for Mathematics & Its Applications, Room 1194,
>>> John Dedman Mathematical Sciences Building (Building 27)
>>> Australian National University, Canberra ACT 0200.
>>> http://www.maths.anu.edu.au/~johnm
>>>>
>>>> On 25/06/2010, at 3:59 AM, Jeffrey Evans wrote:
>>>>
>>>>> Since I am definitely *not* a mathematician, I am straying in over my head
>>>>> here.
>>>>>
>>>>> I understand what you are saying - that there isn't a likelihood function
>>>>> for the quasi-binomial "distribution". And therefore, there is no-such
>>>>> distribution.
>>>>>
>>>>> What do you think of the suggestion that a beta-binomial mixture
>>>>> distribution could be used to model overdispersed binomial data?
>>>>>
>>>>> Would this be a techinically correct and logistically feasibile solution?
>>>>>
>>>>> -jeff
>>>>>
>>>>> -----Original Message-----
>>>>> From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas
>>>>> Bates
>>>>> Sent: Thursday, June 24, 2010 1:25 PM
>>>>> To: Jeffrey Evans
>>>>> Cc: r-sig-mixed-models at r-project.org
>>>>> Subject: Re: [R-sig-ME] lme4, lme4a, and overdispersed distributions (again)
>>>>>
>>>>> On Thu, Jun 24, 2010 at 11:54 AM, Jeffrey Evans
>>>>> <Jeffrey.Evans at dartmouth.edu> wrote:
>>>>>> Like others, I have experienced trouble with estimation of the scale
>>>>>> parameter using the quasi-distributions in lme4, which is necessary to
>>>>>> calculate QAICc and rank overdispersed generalized linear mixed models.
>>>>>
>>>>>> I had several exchanges with Ben Bolker about this early last year
>>>>>> after his TREE paper came out
>>>>>> (http://www.cell.com/trends/ecology-evolution/abstract/S0169-5347%2809
>>>>>> %29000 19-6), and I know it's been discussed on on this list. Has
>>>>>> there been or is there any potential resolution to this forthcoming in
>>>>>> future releases of
>>>>>> lme4 or lme4a? I run into overdispersed binomial distributions
>>>>>> frequently and have had to use SAS to deal with them. SAS appears to
>>>>>> work, but it won't estimate the overdispersion parameter using laplace
>>>>>> estimation (only PQL), As I understand it, these pseudo-Iikelihoods
>>>>>> can't be used for model ranking. I don't know why SAS can't/won't, but
>>>>>> lme4 will run these quasi-binomial and quasi-poisson distributions with
>>>>> Laplace estimation.
>>>>>
>>>>>> Is there a workable way to use lme4 for modeling overdispersed
>>>>>> binomial data?
>>>>>
>>>>> I have trouble discussing this because I come from a background as a
>>>>> mathematician and am used to tracing derivations back to the original
>>>>> definitions. ?So when I think of a likelihood (or, equivalently, a
>>>>> deviance) to be optimized it only makes sense to me if there is a
>>>>> probability distribution associated with the model. ?And for the
>>>>> quasi-binomial and quasi-Poisson families, there isn't a probability
>>>>> distribution. ?To me that means that discussing maximum likelihood
>>>>> estimators for such models is nonsense. ?The models simply do not exist.
>>>>> One can play tricks in the case of a generalized linear model to estimate a
>>>>> "quasi-parameter" that isn't part of the probability distribution but it is
>>>>> foolhardy to expect that the tricks will automatically carry over to a
>>>>> generalized linear mixed model.
>>>>>
>>>>> I am not denying that data that are over-dispersed with respect to the
>>>>> binomial or Poisson distributions can and do occur. ?But having data like
>>>>> this and a desire to model it doesn't make the quasi families real. ? In his
>>>>> signature Thierry Onkelinx quotes
>>>>>
>>>>> The combination of some data and an aching desire for an answer does not
>>>>> ensure that a reasonable answer can be extracted from a given body of data.
>>>>> ~ John Tukey
>>>>>
>>>>> I could and do plan to incorporate the negative binomial family but, without
>>>>> a definition that I can understand of a quasi-binomial or quasi-Poisson
>>>>> distribution and its associated probability function, I'm stuck. To me it's
>>>>> a "build bricks without straw" situation - you can't find maximum likelihood
>>>>> estimates for parameters that aren't part of the likelihood.
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>> John Maindonald ? ? ? ? ? ? email: john.maindonald at anu.edu.au
>>> phone : +61 2 (6125)3473 ? ?fax ?: +61 2(6125)5549
>>> Centre for Mathematics & Its Applications, Room 1194,
>>> John Dedman Mathematical Sciences Building (Building 27)
>>> Australian National University, Canberra ACT 0200.
>>> http://www.maths.anu.edu.au/~johnm
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From ral at lcfltd.com  Tue Jun 29 18:44:14 2010
From: ral at lcfltd.com (Robert A. LaBudde)
Date: Tue, 29 Jun 2010 12:44:14 -0400
Subject: [R-sig-ME] How to get estimates of time (Age) as well as Lots in a
	mixed model
Message-ID: <0L4S0000NBTVRXA0@vms173001.mailsrvcs.net>

I have a small dataset that represents measurements across Lots of a 
processed food, where each lot has a particular Age since manufacturer.

The object of the study is twofold: 1) Determine the Lot-Lot random 
effect size, and 2) determine the degradation slope with Age.

Unfortunately, there is only one unique Lot for each particular 
unique Age. (A Lot is all manufacture from a particular date.) So the 
Lot effect is confounded to some extent with the Age effect.

My question is: What is the best way to get estimate of the two 
effects from this dataset? Should I use the Lot effect from a random 
effects model with no Age variable (so the Lot effect will include 
the Age degradation effect), or should I fit a mixed model anyway, 
and let the software sort them out (which it apparently does by 
dropping a level of Lots)?

I happen to be using the "nlme" package, so here is the example (I 
get a little larger Lot standard deviation when I include Age in the model):

 > blots<- read.table('pseudolots.txt', header=TRUE)
 > blots$ID<- factor(blots$ID)
 > blots$Unit<- factor(blots$Unit)
 > blots
    ID Lot Unit Age Conc
1   1   A    1   3 1.44
2   2   A    2   3 1.56
3   3   B    3  41 1.03
4   4   B    4  41 1.57
5   5   C    5 229 1.49
6   6   C    6 229 1.66
7   7   D    7 238 0.88
8   8   D    8 238 0.93
9   9   E    9 349 1.43
10 10   E   10 349 1.22
11 11   F   11 391 1.42
12 12   F   12 391 1.46
 > #Modeling
 > require('nlme')
Loading required package: nlme
 > fit1<- lme(Conc ~ Age, data=blots, random=~1|Lot)
 > summary(fit1)
Linear mixed-effects model fit by REML
  Data: blots
        AIC      BIC    logLik
   22.74858 23.95893 -7.374292

Random effects:
  Formula: ~1 | Lot
         (Intercept)  Residual
StdDev:   0.2320592 0.1786757

Fixed effects: Conc ~ Age
                  Value  Std.Error DF   t-value p-value
(Intercept)  1.3710359 0.18970706  6  7.227121  0.0004
Age         -0.0001449 0.00074846  4 -0.193538  0.8560
  Correlation:
     (Intr)
Age -0.823

Standardized Within-Group Residuals:
         Min          Q1         Med          Q3         Max
-1.59441923 -0.45471612 -0.06071212  0.52440223  1.42781630

Number of Observations: 12
Number of Groups: 6
 > anova(fit1)
             numDF denDF   F-value p-value
(Intercept)     1     6 154.51072  <.0001
Age             1     4   0.03746   0.856
 >
 > fit2<- lme(Conc ~ 1, data=blots, random=~1|Lot)
 > summary(fit2)
Linear mixed-effects model fit by REML
  Data: blots
        AIC     BIC    logLik
   8.122374 9.31606 -1.061187

Random effects:
  Formula: ~1 | Lot
         (Intercept)  Residual
StdDev:   0.2010265 0.1786757

Fixed effects: Conc ~ 1
                Value  Std.Error DF  t-value p-value
(Intercept) 1.340833 0.09693139  6 13.83281       0

Standardized Within-Group Residuals:
         Min          Q1         Med          Q3         Max
-1.57582754 -0.56625710 -0.01917496  0.56893404  1.44640790

Number of Observations: 12
Number of Groups: 6
 > anova(fit2)
             numDF denDF  F-value p-value
(Intercept)     1     6 191.3466  <.0001
================================================================
Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
824 Timberlake Drive                     Tel: 757-467-0954
Virginia Beach, VA 23464-3239            Fax: 757-467-2947

"Vere scire est per causas scire"



From Jesus.Frias at dit.ie  Tue Jun 29 20:26:33 2010
From: Jesus.Frias at dit.ie (Jesus Frias)
Date: Tue, 29 Jun 2010 19:26:33 +0100 (BST)
Subject: [R-sig-ME] How to get estimates of time (Age) as well as Lots
	in a mixed model
Message-ID: <2298009.1277835993156.JavaMail.Jesus.Frias@dit.ie>

Dear Robert,

I think that your situation is similar to many other mixed effect 
problems (e.g. a clinical trial in phase II where there are a lot of 
subjects but there is very few information on each individual patient). 

In my personal opinion (and I have used R for something very similar to 
what you are trying to do) the nlme library is well able to solve your 
problem. However you probably will need a lot more data than the 
example you have there to have an estimate of the lot random with  some 
confidence.

In my opinion

fit1<- lme(Conc ~ Age, data=blots, random=~1|Lot)

will do what you want. You have at least two replicates from each lot 
with the same Age. 

Be mindful however that the lot-to-lot random effect  you are 
estimating is only at the intercept. All your lots are behaving with 
the same time slope. If you want to study if the lot is affecting how 
fast the food product degrades you might need a model like:

fit1<- lme(Conc ~ Age, data=blots, random=~Age|Lot)

And that is where your confounding might give you trouble.

Is nice to see that other people in the area of food tech are using 
this fantastic tool!

regards,

Jesus

Robert A. LaBudde wrote:


>I have a small dataset that represents measurements across Lots of a 
>processed food, where each lot has a particular Age since manufacturer.
>
>The object of the study is twofold: 1) Determine the Lot-Lot random 
>effect size, and 2) determine the degradation slope with Age.
>
>Unfortunately, there is only one unique Lot for each particular 
>unique Age. (A Lot is all manufacture from a particular date.) So the 
>Lot effect is confounded to some extent with the Age effect.
>
>My question is: What is the best way to get estimate of the two 
>effects from this dataset? Should I use the Lot effect from a random 
>effects model with no Age variable (so the Lot effect will include 
>the Age degradation effect), or should I fit a mixed model anyway, 
>and let the software sort them out (which it apparently does by 
>dropping a level of Lots)?
>
>I happen to be using the "nlme" package, so here is the example (I 
>get a little larger Lot standard deviation when I include Age in the 
model):
>
> > blots<- read.table('pseudolots.txt', header=TRUE)
> > blots$ID<- factor(blots$ID)
> > blots$Unit<- factor(blots$Unit)
> > blots
>    ID Lot Unit Age Conc
>1   1   A    1   3 1.44
>2   2   A    2   3 1.56
>3   3   B    3  41 1.03
>4   4   B    4  41 1.57
>5   5   C    5 229 1.49
>6   6   C    6 229 1.66
>7   7   D    7 238 0.88
>8   8   D    8 238 0.93
>9   9   E    9 349 1.43
>10 10   E   10 349 1.22
>11 11   F   11 391 1.42
>12 12   F   12 391 1.46
> > #Modeling
> > require('nlme')
>Loading required package: nlme
> > fit1<- lme(Conc ~ Age, data=blots, random=~1|Lot)
> > summary(fit1)
>Linear mixed-effects model fit by REML
>  Data: blots
>        AIC      BIC    logLik
>   22.74858 23.95893 -7.374292
>
>Random effects:
>  Formula: ~1 | Lot
>         (Intercept)  Residual
>StdDev:   0.2320592 0.1786757
>
>Fixed effects: Conc ~ Age
>                  Value  Std.Error DF   t-value p-value
>(Intercept)  1.3710359 0.18970706  6  7.227121  0.0004
>Age         -0.0001449 0.00074846  4 -0.193538  0.8560
>  Correlation:
>     (Intr)
>Age -0.823
>
>Standardized Within-Group Residuals:
>         Min          Q1         Med          Q3         Max
>-1.59441923 -0.45471612 -0.06071212  0.52440223  1.42781630
>
>Number of Observations: 12
>Number of Groups: 6
> > anova(fit1)
>             numDF denDF   F-value p-value
>(Intercept)     1     6 154.51072  <.0001
>Age             1     4   0.03746   0.856
> >
> > fit2<- lme(Conc ~ 1, data=blots, random=~1|Lot)
> > summary(fit2)
>Linear mixed-effects model fit by REML
>  Data: blots
>        AIC     BIC    logLik
>   8.122374 9.31606 -1.061187
>
>Random effects:
>  Formula: ~1 | Lot
>         (Intercept)  Residual
>StdDev:   0.2010265 0.1786757
>
>Fixed effects: Conc ~ 1
>                Value  Std.Error DF  t-value p-value
>(Intercept) 1.340833 0.09693139  6 13.83281       0
>
>Standardized Within-Group Residuals:
>         Min          Q1         Med          Q3         Max
>-1.57582754 -0.56625710 -0.01917496  0.56893404  1.44640790
>
>Number of Observations: 12
>Number of Groups: 6
> > anova(fit2)
>             numDF denDF  F-value p-value
>(Intercept)     1     6 191.3466  <.0001
>================================================================
>Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
>Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
>824 Timberlake Drive                     Tel: 757-467-0954
>Virginia Beach, VA 23464-3239            Fax: 757-467-2947
>
>"Vere scire est per causas scire"
>
>_______________________________________________
>R-sig-mixed-models at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

--------------------------------------------------
Jes??s Mar??a Fr??as Celayeta
Head of the Dept of Food Science 
School of Food Sci. and Env. Health 
DIT 
t + 353 1 402 4459 
f + 353 1 402 4495
http://fseh.dit.ie/o4/StaffListing/JesusFrias.html

This message has been scanned for content and viruses by the DIT Information Services E-Mail Scanning Service, and is believed to be clean. http://www.dit.ie



From byjung at gmail.com  Tue Jun 29 23:57:38 2010
From: byjung at gmail.com (Byju Govindan)
Date: Tue, 29 Jun 2010 17:57:38 -0400
Subject: [R-sig-ME] mcmcsamp, HatTrace and lmer
Message-ID: <AANLkTinhWYVJz5B1VawoWGiOmNo6SCI_xniKfrGvpIqw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100629/dddf8e1e/attachment.pl>

From k.lamb at sphsu.mrc.ac.uk  Wed Jun 30 13:12:59 2010
From: k.lamb at sphsu.mrc.ac.uk (Karen Lamb)
Date: Wed, 30 Jun 2010 12:12:59 +0100
Subject: [R-sig-ME] MCMCglmm help- information about 'units' term
Message-ID: <01DF6CEB00684620BE0A2602BB967A5A@ibmroompc>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100630/73a5bfea/attachment.pl>

