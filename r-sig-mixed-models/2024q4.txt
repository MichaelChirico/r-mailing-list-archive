From @|m@h@rme| @end|ng |rom gm@||@com  Tue Oct  8 04:19:09 2024
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Mon, 7 Oct 2024 21:19:09 -0500
Subject: [R-sig-ME] Starting point for modeling a within-subject design
Message-ID: <CACgv6yXpdk6MSa+v=4SbcxGabU9aZxccvs8+e499NMaywrJa_Q@mail.gmail.com>

Dear Mixed-Effects Experts,

Suppose a causal mechanism where a normally distributed outcome is impacted
by condition (a binary factor variable), and a mediator (a
continuous variable) that sits between the condition and outcome.

Here, all subjects get to taste both conditions by counterbalancing. That
is, based on chance, some will first get one condition at one point, and
later, they will get another condition.

In a sense, this is a within-subject design with a data structure like:
subject condition   outcome  mediator
 1          complex       25.1        6
 1          simple          11.0        4
 2          complex       24.3        7
 2          simple          12.2        3
QUESTIONS:
1) Can we think of this model as a multivariate model where the outcome and
mediator are indeed 2 correlated DVs that are impacted by condition?

2) Given that the same participants get both levels of condition, should
levels of condition in each subject be correlated at the latent level as in
(condition | subject) and/or possibly at the residual level as in nlme::
corClasses?

3) Is there any frequentist software to analyze such data, and if not, does
the following bayesian model sound like a good "starting point"?

library(brms)
mediator_formula <- bf(mediator ~ condition + (condition | subject))

outcome_formula <- bf(outcome ~  condition +  mediator + (condition |
subject))

model <- brm(mediator_formula + outcome_formula,
               data = DATA,
               seed = 123,
               chains = 4,
               iter = 10000)

Thank you all for your expertise,
Simon

	[[alternative HTML version deleted]]


From ||@hun@n@y@ng @end|ng |rom m@||@nwpu@edu@cn  Wed Oct 16 14:36:18 2024
From: ||@hun@n@y@ng @end|ng |rom m@||@nwpu@edu@cn (=?utf-8?B?5p2o5p2O6IiS55S3?=)
Date: Wed, 16 Oct 2024 20:36:18 +0800
Subject: [R-sig-ME] Seeking Advice on Structural Equation Modeling with GLMMs
Message-ID: <C54FB63D-DD76-4845-BD9B-B4933A45E8D2@mail.nwpu.edu.cn>

Dear interest group,
As a newcomer?to R and statistics, I now have an unsolvable problem.
I are investigating how neighborhood and topography affect the intensity of seed predation with two treatments. Using GLMMs for neighborhood and topography, I observed complete separation in the models, indicated by coefficients greater than 10. Following Ben Bolker's guidance, I employed the bglmer function from the blme package. These are the two models we constructed:
treatment * elev_lg_sd + slope_lg_sd + (1|obs1) + (1|plot)
shannon_lg_sd * treatment + A.het_lg_sd + (1|obs1) + (1|plot)
Assuming I used the bglmer function correctly, we then attempted to?establish a cause-and-effect relationship using the psem function from?the piecewiseSEM package. Unfortunately, it seems that psem function?does not?support models of class bglmerMod.
I now understand the interrelationships between topography,?neighborhood, and seed predation, but I'm unable to use structural?equation modeling to determine the cause-and-effect relationship between?them.?
I have attached my code and partial data.
Could you please advise me on?how to proceed??
Thank you for your time and assistance.?
Best regards,?
Lishunan Yang

From We|||@ng@Q|u @end|ng |rom @@no||@com  Wed Oct 16 16:42:24 2024
From: We|||@ng@Q|u @end|ng |rom @@no||@com (Qiu, Weiliang /US)
Date: Wed, 16 Oct 2024 14:42:24 +0000
Subject: [R-sig-ME] how to get satterthwaite/Kenward-Roger degrees of
 freedom for heterogeneous-variance one-way ANOVA from an object of
 nlme::gls
Message-ID: <MN2PR05MB6944B9CA807BA584983C0D80FC462@MN2PR05MB6944.namprd05.prod.outlook.com>

Greetings. I am using nlme::gls() to perform heterogeneous-variance one-way ANOVA and would like to get type III anova table. It looks like nlme:::anova.gls() does not provide Satterthwaite or Kenward-Roger degree of freedom. Please see below an example.


library(nlme)

res.gls <- nlme::gls(extra ~ group, data = sleep, weights = varIdent(form = ~1|group))

nlme:::anova.gls(res.gls, type = "marginal")


Could you suggest how to get type III anova table with Satterthwaite/Kenward-Roger degree of freedom from an object of nlme::gls()? Thanks!

Best regards,

Weiliang

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Wed Oct 16 18:05:36 2024
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 16 Oct 2024 12:05:36 -0400
Subject: [R-sig-ME] how to get satterthwaite/Kenward-Roger degrees of
 freedom for heterogeneous-variance one-way ANOVA from an object of
 nlme::gls
In-Reply-To: <MN2PR05MB6944B9CA807BA584983C0D80FC462@MN2PR05MB6944.namprd05.prod.outlook.com>
References: <MN2PR05MB6944B9CA807BA584983C0D80FC462@MN2PR05MB6944.namprd05.prod.outlook.com>
Message-ID: <41cdd60e-ac04-48e4-a955-ceb1746f46ae@gmail.com>



   emmeans() has some capability for computing Satterthwaite df for gls 
model; it will work for your example, although it wouldn't extend (or I 
don't see how to use it) to testing factors with more than two levels.

https://cran.r-project.org/web/packages/emmeans/vignettes/models.html#K
help("emmc-functions")

library(emmeans)
contrast(emmeans(res.gls, ~ group), "trt.vs.ctrl")

  contrast        estimate    SE   df t.ratio p.value
  group2 - group1     1.58 0.849 17.8   1.861  0.0794

Degrees-of-freedom method: satterthwaite

   I don't see a way to get emmeans to estimate df matching the value 
that nlme::anova() gets (i.e. df = 18)

anova(res.gls, type = "marginal")
## df = Inf
contrast(emmeans(res.gls, ~ group, mode = "asymptotic"), "trt.vs.ctrl")
## df = 17
contrast(emmeans(res.gls, ~ group, mode = "df.error"), "trt.vs.ctrl")

   Not sure how this will extend to more complex models (i.e. type-3, 
where you want to test main effects in the presence of interactions).

There is a pull request adding some of this functionality to the 
pbkrtest package (but only does model comparisons, so again may be hard 
to get type-3 Anova out of it), but it looks like it was never merged/is 
now slightly out of sync.

   If you can get the Satterthwaite (or Kenward-Roger) df computed, you 
could hack the output of some other method to recompute p-values with 
the new df ...




On 10/16/24 10:42, Qiu, Weiliang /US via R-sig-mixed-models wrote:
> Greetings. I am using nlme::gls() to perform heterogeneous-variance one-way ANOVA and would like to get type III anova table. It looks like nlme:::anova.gls() does not provide Satterthwaite or Kenward-Roger degree of freedom. Please see below an example.
> 
> 
> library(nlme)
> 
> res.gls <- nlme::gls(extra ~ group, data = sleep, weights = varIdent(form = ~1|group))
> 
> nlme:::anova.gls(res.gls, type = "marginal")
> 
> 
> Could you suggest how to get type III anova table with Satterthwaite/Kenward-Roger degree of freedom from an object of nlme::gls()? Thanks!
> 
> Best regards,
> 
> Weiliang
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
* E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From bbo|ker @end|ng |rom gm@||@com  Wed Oct 16 20:56:27 2024
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 16 Oct 2024 14:56:27 -0400
Subject: [R-sig-ME] Starting point for modeling a within-subject design
In-Reply-To: <CACgv6yXpdk6MSa+v=4SbcxGabU9aZxccvs8+e499NMaywrJa_Q@mail.gmail.com>
References: <CACgv6yXpdk6MSa+v=4SbcxGabU9aZxccvs8+e499NMaywrJa_Q@mail.gmail.com>
Message-ID: <f97743f5-dd57-415e-a36b-e11dd71a797c@gmail.com>



On 10/7/24 22:19, Simon Harmel wrote:
> Dear Mixed-Effects Experts,
> 
> Suppose a causal mechanism where a normally distributed outcome is impacted
> by condition (a binary factor variable), and a mediator (a
> continuous variable) that sits between the condition and outcome.
> 
> Here, all subjects get to taste both conditions by counterbalancing. That
> is, based on chance, some will first get one condition at one point, and
> later, they will get another condition.
> 
> In a sense, this is a within-subject design with a data structure like:
> subject condition   outcome  mediator
>   1          complex       25.1        6
>   1          simple          11.0        4
>   2          complex       24.3        7
>   2          simple          12.2        3
> QUESTIONS:
> 1) Can we think of this model as a multivariate model where the outcome and
> mediator are indeed 2 correlated DVs that are impacted by condition?

   I don't know.  Some questions to consider: (1) is the mediator 
considered to be measured/observed with or without error? (2) are you 
interested in making inferences about the true value of the mediator? My 
guess would be that at least in the linear/Gaussian case, the estimates 
of the direct and combined effects wouldn't be biased by treating the 
observed value of the mediator as the true value (although I guess the 
uncertainty would be underestimated).

> 
> 2) Given that the same participants get both levels of condition, should
> levels of condition in each subject be correlated at the latent level as in
> (condition | subject) and/or possibly at the residual level as in nlme::
> corClasses?
> 

    The levels of condition are categorical (complex/simple), right? And 
they're not random variables ... Or do you mean the **effects** of the 
level of each condition?

   You could in principle fit (condition|subject), but you'll have an 
identifiability problem if you only have two observations per subject 
[as in the 'starling' example here: 
https://bbolker.github.io/morelia_2018/notes/mixedlab.html]

   If variability varied by condition, you could estimate that ...


> 3) Is there any frequentist software to analyze such data, and if not, does
> the following bayesian model sound like a good "starting point"?
> 
> library(brms)
> mediator_formula <- bf(mediator ~ condition + (condition | subject))
> 
> outcome_formula <- bf(outcome ~  condition +  mediator + (condition |
> subject))
> 
> model <- brm(mediator_formula + outcome_formula,
>                 data = DATA,
>                 seed = 123,
>                 chains = 4,
>                 iter = 10000)
> 
> Thank you all for your expertise,
> Simon
> 

   identifiability is in principle less of an issue with Bayesian 
methods (since _in theory_ the sampler should be able to integrate over 
all possible combinations of the confounded/unidentifiable variables), 
but in practice this will also cause problems unless your priors are 
relatively informative.


From We|||@ng@Q|u @end|ng |rom @@no||@com  Wed Oct 16 21:42:25 2024
From: We|||@ng@Q|u @end|ng |rom @@no||@com (Qiu, Weiliang /US)
Date: Wed, 16 Oct 2024 19:42:25 +0000
Subject: [R-sig-ME] how to get satterthwaite/Kenward-Roger degrees of
 freedom for heterogeneous-variance one-way ANOVA from an object of
 nlme::gls
In-Reply-To: <41cdd60e-ac04-48e4-a955-ceb1746f46ae@gmail.com>
References: <MN2PR05MB6944B9CA807BA584983C0D80FC462@MN2PR05MB6944.namprd05.prod.outlook.com>
 <41cdd60e-ac04-48e4-a955-ceb1746f46ae@gmail.com>
Message-ID: <MN2PR05MB6944FA81A40335BE5FB07672FC462@MN2PR05MB6944.namprd05.prod.outlook.com>

Many thanks for the info!

From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Ben Bolker
Sent: Wednesday, October 16, 2024 12:06 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] how to get satterthwaite/Kenward-Roger degrees of freedom for heterogeneous-variance one-way ANOVA from an object of nlme::gls



emmeans() has some capability for computing Satterthwaite df for gls
model; it will work for your example, although it wouldn't extend (or I
don't see how to use it) to testing factors with more than two levels.

https://cran.r-project.org/web/packages/emmeans/vignettes/models.html#K<https://cran.r-project.org/web/packages/emmeans/vignettes/models.html#K>
help("emmc-functions")

library(emmeans)
contrast(emmeans(res.gls, ~ group), "trt.vs.ctrl")

contrast estimate SE df t.ratio p.value
group2 - group1 1.58 0.849 17.8 1.861 0.0794

Degrees-of-freedom method: satterthwaite

I don't see a way to get emmeans to estimate df matching the value
that nlme::anova() gets (i.e. df = 18)

anova(res.gls, type = "marginal")
## df = Inf
contrast(emmeans(res.gls, ~ group, mode = "asymptotic"), "trt.vs.ctrl")
## df = 17
contrast(emmeans(res.gls, ~ group, mode = "df.error"), "trt.vs.ctrl")

Not sure how this will extend to more complex models (i.e. type-3,
where you want to test main effects in the presence of interactions).

There is a pull request adding some of this functionality to the
pbkrtest package (but only does model comparisons, so again may be hard
to get type-3 Anova out of it), but it looks like it was never merged/is
now slightly out of sync.

If you can get the Satterthwaite (or Kenward-Roger) df computed, you
could hack the output of some other method to recompute p-values with
the new df ...




On 10/16/24 10:42, Qiu, Weiliang /US via R-sig-mixed-models wrote:
> Greetings. I am using nlme::gls() to perform heterogeneous-variance one-way ANOVA and would like to get type III anova table. It looks like nlme:::anova.gls() does not provide Satterthwaite or Kenward-Roger degree of freedom. Please see below an example.
>
>
> library(nlme)
>
> res.gls <- nlme::gls(extra ~ group, data = sleep, weights = varIdent(form = ~1|group))
>
> nlme:::anova.gls(res.gls, type = "marginal")
>
>
> Could you suggest how to get type III anova table with Satterthwaite/Kenward-Roger degree of freedom from an object of nlme::gls()? Thanks!
>
> Best regards,
>
> Weiliang
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>

--
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
* E-mail is sent at my convenience; I don't expect replies outside of
working hours.

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>

	[[alternative HTML version deleted]]


From jungm@@rten @end|ng |rom gm@||@com  Thu Oct 17 09:17:33 2024
From: jungm@@rten @end|ng |rom gm@||@com (Maarten Jung)
Date: Thu, 17 Oct 2024 09:17:33 +0200
Subject: [R-sig-ME] how to get satterthwaite/Kenward-Roger degrees of
 freedom for heterogeneous-variance one-way ANOVA from an object of
 nlme::gls
In-Reply-To: <MN2PR05MB6944FA81A40335BE5FB07672FC462@MN2PR05MB6944.namprd05.prod.outlook.com>
References: <MN2PR05MB6944B9CA807BA584983C0D80FC462@MN2PR05MB6944.namprd05.prod.outlook.com>
 <41cdd60e-ac04-48e4-a955-ceb1746f46ae@gmail.com>
 <MN2PR05MB6944FA81A40335BE5FB07672FC462@MN2PR05MB6944.namprd05.prod.outlook.com>
Message-ID: <8579173f-fa46-4351-8770-cb2319b44ed4@gmail.com>

The emmeans::joint_tests function can give you type III style tests.

library(nlme)
library(emmeans)

d <- ToothGrowth
d$dose <- as.factor(d$dose)

res.gls <- gls(len ~ supp * dose, data = d, weights = varIdent(form = ~ 
1 | supp * dose))

anova(res.gls, type = "marginal")

joint_tests(res.gls, mode = "satterthwaite")
joint_tests(res.gls, mode = "df.error")
joint_tests(res.gls, mode = "asymptotic")

Best,
Maarten

On 16.10.2024 21:42, Qiu, Weiliang /US via R-sig-mixed-models wrote:
> Many thanks for the info!
>
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Ben Bolker
> Sent: Wednesday, October 16, 2024 12:06 PM
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] how to get satterthwaite/Kenward-Roger degrees of freedom for heterogeneous-variance one-way ANOVA from an object of nlme::gls
>
>
>
> emmeans() has some capability for computing Satterthwaite df for gls
> model; it will work for your example, although it wouldn't extend (or I
> don't see how to use it) to testing factors with more than two levels.
>
> https://cran.r-project.org/web/packages/emmeans/vignettes/models.html#K<https://cran.r-project.org/web/packages/emmeans/vignettes/models.html#K>
> help("emmc-functions")
>
> library(emmeans)
> contrast(emmeans(res.gls, ~ group), "trt.vs.ctrl")
>
> contrast estimate SE df t.ratio p.value
> group2 - group1 1.58 0.849 17.8 1.861 0.0794
>
> Degrees-of-freedom method: satterthwaite
>
> I don't see a way to get emmeans to estimate df matching the value
> that nlme::anova() gets (i.e. df = 18)
>
> anova(res.gls, type = "marginal")
> ## df = Inf
> contrast(emmeans(res.gls, ~ group, mode = "asymptotic"), "trt.vs.ctrl")
> ## df = 17
> contrast(emmeans(res.gls, ~ group, mode = "df.error"), "trt.vs.ctrl")
>
> Not sure how this will extend to more complex models (i.e. type-3,
> where you want to test main effects in the presence of interactions).
>
> There is a pull request adding some of this functionality to the
> pbkrtest package (but only does model comparisons, so again may be hard
> to get type-3 Anova out of it), but it looks like it was never merged/is
> now slightly out of sync.
>
> If you can get the Satterthwaite (or Kenward-Roger) df computed, you
> could hack the output of some other method to recompute p-values with
> the new df ...
>
>
>
>
> On 10/16/24 10:42, Qiu, Weiliang /US via R-sig-mixed-models wrote:
>> Greetings. I am using nlme::gls() to perform heterogeneous-variance one-way ANOVA and would like to get type III anova table. It looks like nlme:::anova.gls() does not provide Satterthwaite or Kenward-Roger degree of freedom. Please see below an example.
>>
>>
>> library(nlme)
>>
>> res.gls <- nlme::gls(extra ~ group, data = sleep, weights = varIdent(form = ~1|group))
>>
>> nlme:::anova.gls(res.gls, type = "marginal")
>>
>>
>> Could you suggest how to get type III anova table with Satterthwaite/Kenward-Roger degree of freedom from an object of nlme::gls()? Thanks!
>>
>> Best regards,
>>
>> Weiliang
>>
>> [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> --
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> * E-mail is sent at my convenience; I don't expect replies outside of
> working hours.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From We|||@ng@Q|u @end|ng |rom @@no||@com  Thu Oct 17 14:30:17 2024
From: We|||@ng@Q|u @end|ng |rom @@no||@com (Qiu, Weiliang /US)
Date: Thu, 17 Oct 2024 12:30:17 +0000
Subject: [R-sig-ME] how to get satterthwaite/Kenward-Roger degrees of
 freedom for heterogeneous-variance one-way ANOVA from an object of
 nlme::gls
In-Reply-To: <8579173f-fa46-4351-8770-cb2319b44ed4@gmail.com>
References: <MN2PR05MB6944B9CA807BA584983C0D80FC462@MN2PR05MB6944.namprd05.prod.outlook.com>
 <41cdd60e-ac04-48e4-a955-ceb1746f46ae@gmail.com>
 <MN2PR05MB6944FA81A40335BE5FB07672FC462@MN2PR05MB6944.namprd05.prod.outlook.com>
 <8579173f-fa46-4351-8770-cb2319b44ed4@gmail.com>
Message-ID: <MN2PR05MB6944027575D06E062685703FFC472@MN2PR05MB6944.namprd05.prod.outlook.com>

Hi Maarten,

Great to know this solution! Many thanks for your help!

Best regards,

Weiliang

From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Maarten Jung
Sent: Thursday, October 17, 2024 3:18 AM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] how to get satterthwaite/Kenward-Roger degrees of freedom for heterogeneous-variance one-way ANOVA from an object of nlme::gls

The emmeans::joint_tests function can give you type III style tests.

library(nlme)
library(emmeans)

d <- ToothGrowth
d$dose <- as.factor(d$dose)

res.gls <- gls(len ~ supp * dose, data = d, weights = varIdent(form = ~
1 | supp * dose))

anova(res.gls, type = "marginal")

joint_tests(res.gls, mode = "satterthwaite")
joint_tests(res.gls, mode = "df.error")
joint_tests(res.gls, mode = "asymptotic")

Best,
Maarten

On 16.10.2024 21:42, Qiu, Weiliang /US via R-sig-mixed-models wrote:
> Many thanks for the info!
>
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>> On Behalf Of Ben Bolker
> Sent: Wednesday, October 16, 2024 12:06 PM
> To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] how to get satterthwaite/Kenward-Roger degrees of freedom for heterogeneous-variance one-way ANOVA from an object of nlme::gls
>
>
>
> emmeans() has some capability for computing Satterthwaite df for gls
> model; it will work for your example, although it wouldn't extend (or I
> don't see how to use it) to testing factors with more than two levels.
>
> https://cran.r-project.org/web/packages/emmeans/vignettes/models.html#K<https://cran.r-project.org/web/packages/emmeans/vignettes/models.html#K><https://cran.r-project.org/web/packages/emmeans/vignettes/models.html#K<https://cran.r-project.org/web/packages/emmeans/vignettes/models.html#K>>
> help("emmc-functions")
>
> library(emmeans)
> contrast(emmeans(res.gls, ~ group), "trt.vs.ctrl")
>
> contrast estimate SE df t.ratio p.value
> group2 - group1 1.58 0.849 17.8 1.861 0.0794
>
> Degrees-of-freedom method: satterthwaite
>
> I don't see a way to get emmeans to estimate df matching the value
> that nlme::anova() gets (i.e. df = 18)
>
> anova(res.gls, type = "marginal")
> ## df = Inf
> contrast(emmeans(res.gls, ~ group, mode = "asymptotic"), "trt.vs.ctrl")
> ## df = 17
> contrast(emmeans(res.gls, ~ group, mode = "df.error"), "trt.vs.ctrl")
>
> Not sure how this will extend to more complex models (i.e. type-3,
> where you want to test main effects in the presence of interactions).
>
> There is a pull request adding some of this functionality to the
> pbkrtest package (but only does model comparisons, so again may be hard
> to get type-3 Anova out of it), but it looks like it was never merged/is
> now slightly out of sync.
>
> If you can get the Satterthwaite (or Kenward-Roger) df computed, you
> could hack the output of some other method to recompute p-values with
> the new df ...
>
>
>
>
> On 10/16/24 10:42, Qiu, Weiliang /US via R-sig-mixed-models wrote:
>> Greetings. I am using nlme::gls() to perform heterogeneous-variance one-way ANOVA and would like to get type III anova table. It looks like nlme:::anova.gls() does not provide Satterthwaite or Kenward-Roger degree of freedom. Please see below an example.
>>
>>
>> library(nlme)
>>
>> res.gls <- nlme::gls(extra ~ group, data = sleep, weights = varIdent(form = ~1|group))
>>
>> nlme:::anova.gls(res.gls, type = "marginal")
>>
>>
>> Could you suggest how to get type III anova table with Satterthwaite/Kenward-Roger degree of freedom from an object of nlme::gls()? Thanks!
>>
>> Best regards,
>>
>> Weiliang
>>
>> [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org%3cmailto:R-sig-mixed-models at r-project.org>> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models><https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> --
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> * E-mail is sent at my convenience; I don't expect replies outside of
> working hours.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org%3cmailto:R-sig-mixed-models at r-project.org>> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models><https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>

	[[alternative HTML version deleted]]


From @|m@h@rme| @end|ng |rom gm@||@com  Thu Oct 17 21:06:44 2024
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Thu, 17 Oct 2024 14:06:44 -0500
Subject: [R-sig-ME] Starting point for modeling a within-subject design
In-Reply-To: <f97743f5-dd57-415e-a36b-e11dd71a797c@gmail.com>
References: <CACgv6yXpdk6MSa+v=4SbcxGabU9aZxccvs8+e499NMaywrJa_Q@mail.gmail.com>
 <f97743f5-dd57-415e-a36b-e11dd71a797c@gmail.com>
Message-ID: <CACgv6yX5Lt3mo0B8HcjqwVAGCLznWU2WD45rJ8GGncyhF0=Ugw@mail.gmail.com>

Dear Ben,

Such an amazing answer! Please see my follow ups indicated by >>.

(1) is the mediator considered to be measured/observed with or without
error?

>> Likely measured with error, both due to an imprecise tool and how it was
collected! But none of these variables are included in the model.

(2) are you interested in making inferences about the true value of the
mediator?

>> True values of the mediator are not of interest. Only its estimated
effect on outcome is of interest.

[Regarding the correlation between the condition's binary levels], they're
not random variables ... Or do you mean the **effects** of the level of
each condition?

>> No, they're not random variables! We have a finite set of levels for
condition (complex/simple) ... Yes, I mean the effects of each level is
correlated with that of the other level, due to the same participants being
in both simple and complex conditions.

identifiability is in principle less of an issue with Bayesian
methods (since _in theory_ the sampler should be able to integrate over
all possible combinations of the confounded/unidentifiable variables),
but in practice this will also cause problems unless your priors are
relatively informative.

>> I wonder what would be a frequentist alternative to the Baysian model I
sketched? Relatedly, are any random effects even for 'subject' warranted
(given two observations per subject), if not then it seems nlme:gls() with
"correlation=corSymm(form= ~1|subject)" and "weights=varIdent (form=
~1|condition)" may better account for the correlation between effects of
condition than "(condition|subject)" does .

But I'm not sure how gls() could eventually estimate the fixed effect of
mediator on outcome?


On Wed, Oct 16, 2024 at 1:56?PM Ben Bolker <bbolker at gmail.com> wrote:

>
>
> On 10/7/24 22:19, Simon Harmel wrote:
> > Dear Mixed-Effects Experts,
> >
> > Suppose a causal mechanism where a normally distributed outcome is
> impacted
> > by condition (a binary factor variable), and a mediator (a
> > continuous variable) that sits between the condition and outcome.
> >
> > Here, all subjects get to taste both conditions by counterbalancing. That
> > is, based on chance, some will first get one condition at one point, and
> > later, they will get another condition.
> >
> > In a sense, this is a within-subject design with a data structure like:
> > subject condition   outcome  mediator
> >   1          complex       25.1        6
> >   1          simple          11.0        4
> >   2          complex       24.3        7
> >   2          simple          12.2        3
> > QUESTIONS:
> > 1) Can we think of this model as a multivariate model where the outcome
> and
> > mediator are indeed 2 correlated DVs that are impacted by condition?
>
>    I don't know.  Some questions to consider: (1) is the mediator
> considered to be measured/observed with or without error? (2) are you
> interested in making inferences about the true value of the mediator? My
> guess would be that at least in the linear/Gaussian case, the estimates
> of the direct and combined effects wouldn't be biased by treating the
> observed value of the mediator as the true value (although I guess the
> uncertainty would be underestimated).
>
> >
> > 2) Given that the same participants get both levels of condition, should
> > levels of condition in each subject be correlated at the latent level as
> in
> > (condition | subject) and/or possibly at the residual level as in nlme::
> > corClasses?
> >
>
>     The levels of condition are categorical (complex/simple), right? And
> they're not random variables ... Or do you mean the **effects** of the
> level of each condition?
>
>    You could in principle fit (condition|subject), but you'll have an
> identifiability problem if you only have two observations per subject
> [as in the 'starling' example here:
> https://bbolker.github.io/morelia_2018/notes/mixedlab.html]
>
>    If variability varied by condition, you could estimate that ...
>
>
> > 3) Is there any frequentist software to analyze such data, and if not,
> does
> > the following bayesian model sound like a good "starting point"?
> >
> > library(brms)
> > mediator_formula <- bf(mediator ~ condition + (condition | subject))
> >
> > outcome_formula <- bf(outcome ~  condition +  mediator + (condition |
> > subject))
> >
> > model <- brm(mediator_formula + outcome_formula,
> >                 data = DATA,
> >                 seed = 123,
> >                 chains = 4,
> >                 iter = 10000)
> >
> > Thank you all for your expertise,
> > Simon
> >
>
>    identifiability is in principle less of an issue with Bayesian
> methods (since _in theory_ the sampler should be able to integrate over
> all possible combinations of the confounded/unidentifiable variables),
> but in practice this will also cause problems unless your priors are
> relatively informative.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From ru@@e||-|enth @end|ng |rom u|ow@@edu  Fri Oct 18 03:06:08 2024
From: ru@@e||-|enth @end|ng |rom u|ow@@edu (Lenth, Russell V)
Date: Fri, 18 Oct 2024 01:06:08 +0000
Subject: [R-sig-ME] how to get satterthwaite/Kenward-Roger degrees of
 freedom for heterogeneous-variance one-way ANOVA from an object of
 nlme::gls
In-Reply-To: <mailman.20373.3.1729159201.1233.r-sig-mixed-models@r-project.org>
References: <mailman.20373.3.1729159201.1233.r-sig-mixed-models@r-project.org>
Message-ID: <DM6PR04MB4474F84BBED1625087E1CF95F1402@DM6PR04MB4474.namprd04.prod.outlook.com>

A couple of clarifications on what emmeans does and does not do. The main thing to know is it is only capable of obtaining Satterthwaite degrees of freedom for _one linear function at a time_. For the denominator d.f. of joint.tests() (labeled df2 in tables), we obtain the d.f. for each contrast involved, and what is shown as df2 is the minimum of these. This is usually conservative, but I can't say it always is. I'm realizing I need to document this.

emmeans supports Satterthwaite d.f. for gls objects, but not lme. That is because we cannot access the needed internal functions. I put in a request to the nlme maintainers for more support years ago, but it met with deaf ears. 

For a given variance estimate V, the Satterthwaite d.f. is equal to 2V^2/var(V), so we need to be able to get var(V) as a function of the fixed-effect parameters. For lme models, I do provide an "appx-Satterthwaite" method that involves perturbing the response values slightly, then estimating var(V) empirically. It works surprisingly well, especially given that only a few perturbations are used. 

As I understand it, K-R d.f. are done in the same manner except that they are based on a bias-adjusted covariance matrix that I don't think is available in the nlme package.

--
Russell V. Lenth? -? Professor Emeritus
Department of Statistics and Actuarial Science? 
The University of Iowa? -? Iowa City, IA 52242? USA??????? ?
Dept office (319)335-0712? -? FAX (319)335-3017
russell-lenth at uiowa.edu? -? http://www.stat.uiowa.edu/~rlenth/


-----Original Message-----
Date: Thu, 17 Oct 2024 09:17:33 +0200
From: Maarten Jung <jungmaarten at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] how to get satterthwaite/Kenward-Roger degrees
	of freedom for heterogeneous-variance one-way ANOVA from an object of
	nlme::gls
Message-ID: <8579173f-fa46-4351-8770-cb2319b44ed4 at gmail.com>
Content-Type: text/plain; charset="utf-8"; Format="flowed"

The emmeans::joint_tests function can give you type III style tests.

library(nlme)
library(emmeans)

d <- ToothGrowth
d$dose <- as.factor(d$dose)

res.gls <- gls(len ~ supp * dose, data = d, weights = varIdent(form = ~
1 | supp * dose))

anova(res.gls, type = "marginal")

joint_tests(res.gls, mode = "satterthwaite") joint_tests(res.gls, mode = "df.error") joint_tests(res.gls, mode = "asymptotic")

Best,
Maarten


From ro||turner @end|ng |rom po@teo@net  Fri Oct 18 03:53:26 2024
From: ro||turner @end|ng |rom po@teo@net (Rolf Turner)
Date: Fri, 18 Oct 2024 01:53:26 +0000
Subject: [R-sig-ME] how to get satterthwaite/Kenward-Roger degrees of
 freedom for heterogeneous-variance one-way ANOVA from an object of
 nlme::gls
In-Reply-To: <MN2PR05MB6944B9CA807BA584983C0D80FC462@MN2PR05MB6944.namprd05.prod.outlook.com>
References: <MN2PR05MB6944B9CA807BA584983C0D80FC462@MN2PR05MB6944.namprd05.prod.outlook.com>
Message-ID: <20241018145326.7217405a@elderly-dell>


On Wed, 16 Oct 2024 14:42:24 +0000
"Qiu, Weiliang /US via R-sig-mixed-models"
<r-sig-mixed-models at r-project.org> wrote:

> Greetings. I am using nlme::gls() to perform heterogeneous-variance
> one-way ANOVA and would like to get type III anova table.

<SNIP>

One should always think very carefully about what hypotheses are
actually being tested in a "type III analysis".  Such an analysis may
well be "meaningful" but the hypotheses being tested may not be of any
real interest. They involve taking averages of cell means over the
levels of factors and these averages may not describe anything
pertinent.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Stats. Dep't. (secretaries) phone:
         +64-9-373-7599 ext. 89622
Home phone: +64-9-480-4619


From We|||@ng@Q|u @end|ng |rom @@no||@com  Fri Oct 18 13:58:53 2024
From: We|||@ng@Q|u @end|ng |rom @@no||@com (Qiu, Weiliang /US)
Date: Fri, 18 Oct 2024 11:58:53 +0000
Subject: [R-sig-ME] how to get satterthwaite/Kenward-Roger degrees of
 freedom for heterogeneous-variance one-way ANOVA from an object of
 nlme::gls
In-Reply-To: <DM6PR04MB4474F84BBED1625087E1CF95F1402@DM6PR04MB4474.namprd04.prod.outlook.com>
References: <mailman.20373.3.1729159201.1233.r-sig-mixed-models@r-project.org>
 <DM6PR04MB4474F84BBED1625087E1CF95F1402@DM6PR04MB4474.namprd04.prod.outlook.com>
Message-ID: <MN2PR05MB6944C801397D2E4C351D36D2FC402@MN2PR05MB6944.namprd05.prod.outlook.com>

Dear Prof. Lenth,

Thank you for the clarifications, which is very helpful!

Best regards,

Weiliang


From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Lenth, Russell V via R-sig-mixed-models
Sent: Thursday, October 17, 2024 9:06 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] how to get satterthwaite/Kenward-Roger degrees of freedom for heterogeneous-variance one-way ANOVA from an object of nlme::gls

A couple of clarifications on what emmeans does and does not do. The main thing to know is it is only capable of obtaining Satterthwaite degrees of freedom for _one linear function at a time_. For the denominator d.f. of joint.tests() (labeled df2 in tables), we obtain the d.f. for each contrast involved, and what is shown as df2 is the minimum of these. This is usually conservative, but I can't say it always is. I'm realizing I need to document this.

emmeans supports Satterthwaite d.f. for gls objects, but not lme. That is because we cannot access the needed internal functions. I put in a request to the nlme maintainers for more support years ago, but it met with deaf ears.

For a given variance estimate V, the Satterthwaite d.f. is equal to 2V^2/var(V), so we need to be able to get var(V) as a function of the fixed-effect parameters. For lme models, I do provide an "appx-Satterthwaite" method that involves perturbing the response values slightly, then estimating var(V) empirically. It works surprisingly well, especially given that only a few perturbations are used.

As I understand it, K-R d.f. are done in the same manner except that they are based on a bias-adjusted covariance matrix that I don't think is available in the nlme package.

--
Russell V. Lenth  -  Professor Emeritus
Department of Statistics and Actuarial Science
The University of Iowa  -  Iowa City, IA 52242  USA
Dept office (319)335-0712  -  FAX (319)335-3017
russell-lenth at uiowa.edu<mailto:russell-lenth at uiowa.edu>  -  http://www.stat.uiowa.edu/~rlenth/<http://www.stat.uiowa.edu/~rlenth>


-----Original Message-----
Date: Thu, 17 Oct 2024 09:17:33 +0200
From: Maarten Jung <jungmaarten at gmail.com<mailto:jungmaarten at gmail.com>>
To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] how to get satterthwaite/Kenward-Roger degrees
of freedom for heterogeneous-variance one-way ANOVA from an object of
nlme::gls
Message-ID: <8579173f-fa46-4351-8770-cb2319b44ed4 at gmail.com<mailto:8579173f-fa46-4351-8770-cb2319b44ed4 at gmail.com>>
Content-Type: text/plain; charset="utf-8"; Format="flowed"

The emmeans::joint_tests function can give you type III style tests.

library(nlme)
library(emmeans)

d <- ToothGrowth
d$dose <- as.factor(d$dose)

res.gls <- gls(len ~ supp * dose, data = d, weights = varIdent(form = ~
1 | supp * dose))

anova(res.gls, type = "marginal")

joint_tests(res.gls, mode = "satterthwaite") joint_tests(res.gls, mode = "df.error") joint_tests(res.gls, mode = "asymptotic")

Best,
Maarten

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>

	[[alternative HTML version deleted]]


From We|||@ng@Q|u @end|ng |rom @@no||@com  Fri Oct 18 14:01:21 2024
From: We|||@ng@Q|u @end|ng |rom @@no||@com (Qiu, Weiliang /US)
Date: Fri, 18 Oct 2024 12:01:21 +0000
Subject: [R-sig-ME] how to get satterthwaite/Kenward-Roger degrees of
 freedom for heterogeneous-variance one-way ANOVA from an object of
 nlme::gls
In-Reply-To: <20241018145326.7217405a@elderly-dell>
References: <MN2PR05MB6944B9CA807BA584983C0D80FC462@MN2PR05MB6944.namprd05.prod.outlook.com>
 <20241018145326.7217405a@elderly-dell>
Message-ID: <MN2PR05MB6944D9B1B8483AF4242E59F3FC402@MN2PR05MB6944.namprd05.prod.outlook.com>

Dear Dr. Turner,

Thanks for the information!

Best regards,

Weiliang

-----Original Message-----
From: Rolf Turner <rolfturner at posteo.net> 
Sent: Thursday, October 17, 2024 9:53 PM
To: Qiu, Weiliang /US via R-sig-mixed-models <r-sig-mixed-models at r-project.org>
Cc: Qiu, Weiliang /US <Weiliang.Qiu at sanofi.com>
Subject: Re: [R-sig-ME] how to get satterthwaite/Kenward-Roger degrees of freedom for heterogeneous-variance one-way ANOVA from an object of nlme::gls


On Wed, 16 Oct 2024 14:42:24 +0000
"Qiu, Weiliang /US via R-sig-mixed-models"
<r-sig-mixed-models at r-project.org> wrote:

> Greetings. I am using nlme::gls() to perform heterogeneous-variance 
> one-way ANOVA and would like to get type III anova table.

<SNIP>

One should always think very carefully about what hypotheses are actually being tested in a "type III analysis".  Such an analysis may well be "meaningful" but the hypotheses being tested may not be of any real interest. They involve taking averages of cell means over the levels of factors and these averages may not describe anything pertinent.

cheers,

Rolf Turner

--
Honorary Research Fellow
Department of Statistics
University of Auckland
Stats. Dep't. (secretaries) phone:
         +64-9-373-7599 ext. 89622
Home phone: +64-9-480-4619


From ru@@e||-|enth @end|ng |rom u|ow@@edu  Fri Oct 18 19:44:21 2024
From: ru@@e||-|enth @end|ng |rom u|ow@@edu (Lenth, Russell V)
Date: Fri, 18 Oct 2024 17:44:21 +0000
Subject: [R-sig-ME] how to get satterthwaite/Kenward-Roger degrees of
 freedom for heterogeneous-variance one-way ANOVA from an object of
 nlme::gls
In-Reply-To: <mailman.20377.5.1729245602.45222.r-sig-mixed-models@r-project.org>
References: <mailman.20377.5.1729245602.45222.r-sig-mixed-models@r-project.org>
Message-ID: <DM6PR04MB44740C72BA14660A2720798EF1402@DM6PR04MB4474.namprd04.prod.outlook.com>

What Rolf says is true, but I'm going to push back a little bit on this. The joint_tests() function in emmeans does not implement SAS's type III F tests, though they are often the same. Joint_tests() results are ALWAYS formulated in terms of estimated marginal means. If the associated EMMs are appropriate, so are the joint tests. 

SAS does the wrong thing with covariates in its type III estimable functions: it sets them to zero instead of to their mean. Consequently, its type III tests are based on comparing intercepts instead of adjusted means. That is an unfortunate mistake that has endured and has generally been misunderstood for about 50 years.

--
Russell V. Lenth? -? Professor Emeritus
Department of Statistics and Actuarial Science? 
The University of Iowa? -? Iowa City, IA 52242? USA??????? ?
Dept office (319)335-0712? -? FAX (319)335-3017
russell-lenth at uiowa.edu? -? http://www.stat.uiowa.edu/~rlenth/


-----Original Message-----
Date: Fri, 18 Oct 2024 01:53:26 +0000
From: Rolf Turner <rolfturner at posteo.net>
To: "Qiu, Weiliang /US via R-sig-mixed-models"
	<r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] how to get satterthwaite/Kenward-Roger degrees
	of freedom for heterogeneous-variance one-way ANOVA from an object of
	nlme::gls
Message-ID: <20241018145326.7217405a at elderly-dell>
Content-Type: text/plain; charset="us-ascii"


On Wed, 16 Oct 2024 14:42:24 +0000
"Qiu, Weiliang /US via R-sig-mixed-models"
<r-sig-mixed-models at r-project.org> wrote:

> Greetings. I am using nlme::gls() to perform heterogeneous-variance 
> one-way ANOVA and would like to get type III anova table.

<SNIP>

One should always think very carefully about what hypotheses are actually being tested in a "type III analysis".  Such an analysis may well be "meaningful" but the hypotheses being tested may not be of any real interest. They involve taking averages of cell means over the levels of factors and these averages may not describe anything pertinent.

cheers,

Rolf Turner

--
Honorary Research Fellow
Department of Statistics
University of Auckland
Stats. Dep't. (secretaries) phone:
         +64-9-373-7599 ext. 89622
Home phone: +64-9-480-4619


From We|||@ng@Q|u @end|ng |rom @@no||@com  Fri Oct 18 21:57:52 2024
From: We|||@ng@Q|u @end|ng |rom @@no||@com (Qiu, Weiliang /US)
Date: Fri, 18 Oct 2024 19:57:52 +0000
Subject: [R-sig-ME] how to get satterthwaite/Kenward-Roger degrees of
 freedom for heterogeneous-variance one-way ANOVA from an object of
 nlme::gls
In-Reply-To: <DM6PR04MB44740C72BA14660A2720798EF1402@DM6PR04MB4474.namprd04.prod.outlook.com>
References: <mailman.20377.5.1729245602.45222.r-sig-mixed-models@r-project.org>
 <DM6PR04MB44740C72BA14660A2720798EF1402@DM6PR04MB4474.namprd04.prod.outlook.com>
Message-ID: <MN2PR05MB6944A54B4CF24ED9332A66B7FC402@MN2PR05MB6944.namprd05.prod.outlook.com>

Dear Prof. Lenth,

Thanks for the clarification!

Best regards,

Weiliang


From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Lenth, Russell V via R-sig-mixed-models
Sent: Friday, October 18, 2024 1:44 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] how to get satterthwaite/Kenward-Roger degrees of freedom for heterogeneous-variance one-way ANOVA from an object of nlme::gls

What Rolf says is true, but I'm going to push back a little bit on this. The joint_tests() function in emmeans does not implement SAS's type III F tests, though they are often the same. Joint_tests() results are ALWAYS formulated in terms of estimated marginal means. If the associated EMMs are appropriate, so are the joint tests.

SAS does the wrong thing with covariates in its type III estimable functions: it sets them to zero instead of to their mean. Consequently, its type III tests are based on comparing intercepts instead of adjusted means. That is an unfortunate mistake that has endured and has generally been misunderstood for about 50 years.

--
Russell V. Lenth  -  Professor Emeritus
Department of Statistics and Actuarial Science
The University of Iowa  -  Iowa City, IA 52242  USA
Dept office (319)335-0712  -  FAX (319)335-3017
russell-lenth at uiowa.edu<mailto:russell-lenth at uiowa.edu>  -  http://www.stat.uiowa.edu/~rlenth/<http://www.stat.uiowa.edu/~rlenth>


-----Original Message-----
Date: Fri, 18 Oct 2024 01:53:26 +0000
From: Rolf Turner <rolfturner at posteo.net<mailto:rolfturner at posteo.net>>
To: "Qiu, Weiliang /US via R-sig-mixed-models"
<r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: Re: [R-sig-ME] how to get satterthwaite/Kenward-Roger degrees
of freedom for heterogeneous-variance one-way ANOVA from an object of
nlme::gls
Message-ID: <20241018145326.7217405a at elderly-dell<mailto:20241018145326.7217405a at elderly-dell>>
Content-Type: text/plain; charset="us-ascii"


On Wed, 16 Oct 2024 14:42:24 +0000
"Qiu, Weiliang /US via R-sig-mixed-models"
<r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>> wrote:

> Greetings. I am using nlme::gls() to perform heterogeneous-variance
> one-way ANOVA and would like to get type III anova table.

<SNIP>

One should always think very carefully about what hypotheses are actually being tested in a "type III analysis". Such an analysis may well be "meaningful" but the hypotheses being tested may not be of any real interest. They involve taking averages of cell means over the levels of factors and these averages may not describe anything pertinent.

cheers,

Rolf Turner

--
Honorary Research Fellow
Department of Statistics
University of Auckland
Stats. Dep't. (secretaries) phone:
+64-9-373-7599 ext. 89622
Home phone: +64-9-480-4619

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>

	[[alternative HTML version deleted]]


From g@ngchen @end|ng |rom m@||@n|h@gov  Fri Oct 18 23:33:12 2024
From: g@ngchen @end|ng |rom m@||@n|h@gov (Chen, Gang (NIH/NIMH) [E])
Date: Fri, 18 Oct 2024 21:33:12 +0000
Subject: [R-sig-ME] Coding comparisons and interactions with the R package
 emmeans
In-Reply-To: <DM6PR04MB44740C72BA14660A2720798EF1402@DM6PR04MB4474.namprd04.prod.outlook.com>
References: <mailman.20377.5.1729245602.45222.r-sig-mixed-models@r-project.org>
 <DM6PR04MB44740C72BA14660A2720798EF1402@DM6PR04MB4474.namprd04.prod.outlook.com>
Message-ID: <MW4PR09MB932930A6587D2152FA120573ED402@MW4PR09MB9329.namprd09.prod.outlook.com>

I am starting to learn how to use the R package emmeans and would appreciate help with some specific applications.
For illustration, let me use a dataset from the afex package. The variable phase is a factor with three levels: "fup", "post", and "pre". The variable age is continuous. Below is a model fit using lme4:
library(afex); library(lme4); library(phia)
data(obk.long, package = "afex")
options(contrasts = c("contr.sum", "contr.poly"))
fm <- lmer(value ~ phase * age + (1|id), data = obk.long)

I would like to replicate the following seven comparisons and interactions using emmeans:

  1.  Contrast between the first two levels ("fup" vs. "post") of the factor phase
In phia, this is done with:
testInteractions(fm, custom = list(phase = c(-1, 1, 0)), adjustment = "none")

  1.  Contrast between the first two levels of phase, with age fixed at 5.5
In phia:
testInteractions(fm, custom = list(phase = c(-1, 1, 0)), covariates = c(age = 5.5), adjustment = "none")

  1.  Slope of age (averaged across all levels of phase)
In phia:
testInteractions(fm, pairwise = NULL, slope = "age", adjustment = "none")

  1.  Slope difference in age between the first two levels ("fup" vs. "post") of phase
In phia:
testInteractions(fm, custom = list(phase = c(-1, 1, 0)), slope = "age", adjustment = "none")

  1.  Composite contrast among the three levels of phase (e.g., "fup" - "pre" and "post" - "pre"). By "composite contrasts," I mean a null hypothesis that involves multiple effects simultaneously. In this case, the null hypothesis for the three factor levels is ?0: fup - pre = 0 and post - pre = 0.
In phia:
testFactors(fm, levels = testFactors(fm, levels = list(phase = rbind(diag(2), c(-1,-1)))))

  1.  Composite slope comparisons among the three levels of phase (e.g., slope differences for "fup" vs. "pre" and "post" vs. "pre")
In phia:
testFactors(fm, levels = testFactors(fm, levels = list(phase = rbind(diag(2), c(-1,-1)))), slope = "age")

  1.  Composite contrasts among the three levels of phase at a fixed age (e.g., "fup" - "pre" and "post" - "pre" at age = 5.5)
In phia:
testFactors(fm, levels = testFactors(fm, levels = list(phase = rbind(diag(2), c(-1,-1)))), covariates = c(age = 5.5))
My question is: how can I code these seven effects/interactions using the emmeans package?

Thanks,
Gang Chen

	[[alternative HTML version deleted]]


From |ongrob604 @end|ng |rom gm@||@com  Mon Oct 21 17:40:49 2024
From: |ongrob604 @end|ng |rom gm@||@com (Robert Long)
Date: Mon, 21 Oct 2024 16:40:49 +0100
Subject: [R-sig-ME] Convergence issues with nlme:lme
Message-ID: <CA+3TTkPfiKayg4vWGG7UVSK4qw7OkCeSXR5bT2LV5OVFo5R5Yw@mail.gmail.com>

Dear list

Having tried to fit a mixed effects model with nlme:lme, and found
convergence problems, how do we inspect the fitted model object to find out
what is the problem?

Reproducible example:

> set.seed(3)
> data <- data.frame(y = rnorm(100), x = rnorm(100), group = rep(1:10, each
= 10))
>
> model <- lme(y ~ x, random = ~ 1 + x | group, data = data)
Error in lme.formula(y ~ x, random = ~1 + x | group, data = data) :
  nlminb problem, convergence error code = 1
  message = iteration limit reached without convergence (10)

Now that we have the model object, how do we interrogate it to find out
what went wrong? I need to do this in code, so I won't have access to the
Error message raised when the model was first fitted (unless there is a
magical way to get at the error (which I haven't yet found)

Thanks !

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Mon Oct 21 17:50:57 2024
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 21 Oct 2024 11:50:57 -0400
Subject: [R-sig-ME] Convergence issues with nlme:lme
In-Reply-To: <CA+3TTkPfiKayg4vWGG7UVSK4qw7OkCeSXR5bT2LV5OVFo5R5Yw@mail.gmail.com>
References: <CA+3TTkPfiKayg4vWGG7UVSK4qw7OkCeSXR5bT2LV5OVFo5R5Yw@mail.gmail.com>
Message-ID: <0806121d-fbbf-45a0-9b02-84e8fadc36b3@gmail.com>

    You don't have the model object, since R threw an error.


   If you run

model <- lme(y ~ x, random = ~ 1 + x | group, data = data, control = 
lmeControl(returnObject = TRUE))

   you will get an object returned. However, I don't see anything in the 
returned object that stores warning information.

   In these cases you need to set up some machinery to capture and store 
errors and warnings, et.c. from
https://github.com/lme4/lme4/blob/master/R/error_factory.R

mylme <- lme4:::factory(lme)
model2 <- mylme(y ~ x, random = ~ 1 + x | group, data = data, control = 
lmeControl(returnObject = TRUE))


attr(model2, "factory-warning")
## [1] "nlminb problem, convergence error code = 1\n  message = 
iteration limit reached without convergence (10)"

And now without setting returnObject = TRUE ...

model3 <- mylme(y ~ x, random = ~ 1 + x | group, data = data)

model3
[1] "An error occurred in the factory function"
attr(,"factory-error")
[1] "nlminb problem, convergence error code = 1\n  message = iteration 
limit reached without convergence (10)"


On 10/21/24 11:40, Robert Long wrote:
> Dear list
> 
> Having tried to fit a mixed effects model with nlme:lme, and found
> convergence problems, how do we inspect the fitted model object to find out
> what is the problem?
> 
> Reproducible example:
> 
>> set.seed(3)
>> data <- data.frame(y = rnorm(100), x = rnorm(100), group = rep(1:10, each
> = 10))
>>
>> model <- lme(y ~ x, random = ~ 1 + x | group, data = data)
> Error in lme.formula(y ~ x, random = ~1 + x | group, data = data) :
>    nlminb problem, convergence error code = 1
>    message = iteration limit reached without convergence (10)
> 
> Now that we have the model object, how do we interrogate it to find out
> what went wrong? I need to do this in code, so I won't have access to the
> Error message raised when the model was first fitted (unless there is a
> magical way to get at the error (which I haven't yet found)
> 
> Thanks !
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
* E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From @|m@h@rme| @end|ng |rom gm@||@com  Mon Oct 21 20:34:56 2024
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Mon, 21 Oct 2024 13:34:56 -0500
Subject: [R-sig-ME] Fixing non-symetrix sigma matrix
Message-ID: <CACgv6yUixJQYs8Wz=Vzm+NAS42A-W_X0g_UHbqGGtH-WCHjxdA@mail.gmail.com>

Hello Mixed-Models experts,

I'm trying to fit the following reproducible mediation model called
final. But I get an error saying: ...sigma must be a symmetric
matrix...

Could you please advise how I can possibly fix this error?

Many thanks,
Simon

Reproducible R code:
df <- read.csv("https://raw.githubusercontent.com/fpqq/w/refs/heads/main/t.csv")

library(glmmTMB)
library(mediation)

mediator <- glmmTMB(pic_percent ~ con +
                      (0+con | ID) +
                      (0+con | TRIAL_INDEX),
                    data=df,
        family = beta_family(),
        ziformula = ~1)

outcome <- glmmTMB(acc ~ con + pic_percent +
                      (0+con+pic_percent | Q),
                     data = df,
                   family = binomial())

final <- mediate(mediator, outcome, sims=50,
                    treat="con", mediator="pic_percent")


From ro||turner @end|ng |rom po@teo@net  Tue Oct 22 00:57:46 2024
From: ro||turner @end|ng |rom po@teo@net (Rolf Turner)
Date: Mon, 21 Oct 2024 22:57:46 +0000
Subject: [R-sig-ME] Fixing non-symetrix sigma matrix
In-Reply-To: <CACgv6yUixJQYs8Wz=Vzm+NAS42A-W_X0g_UHbqGGtH-WCHjxdA@mail.gmail.com>
References: <CACgv6yUixJQYs8Wz=Vzm+NAS42A-W_X0g_UHbqGGtH-WCHjxdA@mail.gmail.com>
Message-ID: <20241022115746.4dffe9b6@elderly-dell>


On Mon, 21 Oct 2024 13:34:56 -0500
Simon Harmel <sim.harmel at gmail.com> wrote:

> Hello Mixed-Models experts,
> 
> I'm trying to fit the following reproducible mediation model called
> final. But I get an error saying: ...sigma must be a symmetric
> matrix...
> 
> Could you please advise how I can possibly fix this error?
> 
> Many thanks,
> Simon
> 
> Reproducible R code:
> df <-
> read.csv("https://raw.githubusercontent.com/fpqq/w/refs/heads/main/t.csv")
> 
> library(glmmTMB)
> library(mediation)
> 
> mediator <- glmmTMB(pic_percent ~ con +
>                       (0+con | ID) +
>                       (0+con | TRIAL_INDEX),
>                     data=df,
>         family = beta_family(),
>         ziformula = ~1)
> 
> outcome <- glmmTMB(acc ~ con + pic_percent +
>                       (0+con+pic_percent | Q),
>                      data = df,
>                    family = binomial())
> 
> final <- mediate(mediator, outcome, sims=50,
>                     treat="con", mediator="pic_percent")
> 

Thank you for the clearly structured reproducible example.

I must preface my remarks by saying that this is definitely a case of
the blind leading the partially-sighted; I am no "mixed model expert",
and I really haven't a clue about "mediation".

Having said that, there seems to me (in my ignorance) to be several
things wrong in the code of mediate().  If we do

    sink("mediate.R")
    mediate
    sink()

we find at line 469 of mediate.R the code:

    MModel <- rmvnorm(sims, mean = MModel.coef, sigma = MModel.var.cov)

This seems to be incorrect.  MModel.var.coef should be a 2 x 2 matrix,
but it is a list.  The first entry of this list seems to be the
required covariance matrix.  Similarly MModel.coef is a list; the
second two entries seem to be empty lists.  The first entry is a list of
length 2, each entry being a matrix.  It is not at all clear to me what
role these matrices play.  If one modifies the call to rmvnorm() to,
e.g.

    MModel <- rmvnorm(sims, mean = MModel.coef[[1]][[1]],
                      sigma = MModel.var.cov[[1]])

then the code runs a bit further, but rmvnorm() hangs up at the end
with an error.  The call to sweep()

    retval <- sweep(retval, 2, mean, "+")

complains about a dimension miss-match, but then throws an error
"non-numeric argument to binary operator" which mystifies me completely.

At this point I give up, and hope that someone who knows what they are
doing will take over.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Stats. Dep't. (secretaries) phone:
         +64-9-373-7599 ext. 89622
Home phone: +64-9-480-4619


From bbo|ker @end|ng |rom gm@||@com  Tue Oct 22 04:28:04 2024
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 21 Oct 2024 22:28:04 -0400
Subject: [R-sig-ME] Fixing non-symetrix sigma matrix
In-Reply-To: <20241022115746.4dffe9b6@elderly-dell>
References: <CACgv6yUixJQYs8Wz=Vzm+NAS42A-W_X0g_UHbqGGtH-WCHjxdA@mail.gmail.com>
 <20241022115746.4dffe9b6@elderly-dell>
Message-ID: <750149ac-de0e-4d10-b3e4-5cb04ac85d1c@gmail.com>


   The mediate() function simply isn't set up to work with glmmTMB 
objects.  Rolf's fix takes care of the fact that vcov() applied to a 
glmmTMB object returns a list of covariance matrices (for the fixed 
effect parameters of the conditional distribution, zero-inflation model, 
dispersion model) rather than a single matrix.

   Beyond that, though, if you look at the code for mediate() you'll see 
a whole bunch of logic that checks whether each of the two models 
inherits from classes `glm`, `gam`, `survreg`, `merMod`, etc. ... by 
structuring their code this way (rather than using S3 methods), the 
authors have made it hard to adapt their code to new model types without 
digging all the way into the code and writing new components for the new 
model type ...

   You could ask the package maintainers to add these capabilities, or 
try to find someone else who can do it for you ... (it might not be too 
hard, but the mediate() function is 1400+ lines long ... the way to go 
at it would be to look for everywhere that `isMer.m` or `isMer.y` (main 
or mediation model is from lme4) and write parallel code that works with 
glmmTMB objects instead ...)

   Ben Bolker



On 10/21/24 18:57, Rolf Turner wrote:
> 
> On Mon, 21 Oct 2024 13:34:56 -0500
> Simon Harmel <sim.harmel at gmail.com> wrote:
> 
>> Hello Mixed-Models experts,
>>
>> I'm trying to fit the following reproducible mediation model called
>> final. But I get an error saying: ...sigma must be a symmetric
>> matrix...
>>
>> Could you please advise how I can possibly fix this error?
>>
>> Many thanks,
>> Simon
>>
>> Reproducible R code:
>> df <-
>> read.csv("https://raw.githubusercontent.com/fpqq/w/refs/heads/main/t.csv")
>>
>> library(glmmTMB)
>> library(mediation)
>>
>> mediator <- glmmTMB(pic_percent ~ con +
>>                        (0+con | ID) +
>>                        (0+con | TRIAL_INDEX),
>>                      data=df,
>>          family = beta_family(),
>>          ziformula = ~1)
>>
>> outcome <- glmmTMB(acc ~ con + pic_percent +
>>                        (0+con+pic_percent | Q),
>>                       data = df,
>>                     family = binomial())
>>
>> final <- mediate(mediator, outcome, sims=50,
>>                      treat="con", mediator="pic_percent")
>>
> 
> Thank you for the clearly structured reproducible example.
> 
> I must preface my remarks by saying that this is definitely a case of
> the blind leading the partially-sighted; I am no "mixed model expert",
> and I really haven't a clue about "mediation".
> 
> Having said that, there seems to me (in my ignorance) to be several
> things wrong in the code of mediate().  If we do
> 
>      sink("mediate.R")
>      mediate
>      sink()
> 
> we find at line 469 of mediate.R the code:
> 
>      MModel <- rmvnorm(sims, mean = MModel.coef, sigma = MModel.var.cov)
> 
> This seems to be incorrect.  MModel.var.coef should be a 2 x 2 matrix,
> but it is a list.  The first entry of this list seems to be the
> required covariance matrix.  Similarly MModel.coef is a list; the
> second two entries seem to be empty lists.  The first entry is a list of
> length 2, each entry being a matrix.  It is not at all clear to me what
> role these matrices play.  If one modifies the call to rmvnorm() to,
> e.g.
> 
>      MModel <- rmvnorm(sims, mean = MModel.coef[[1]][[1]],
>                        sigma = MModel.var.cov[[1]])
> 
> then the code runs a bit further, but rmvnorm() hangs up at the end
> with an error.  The call to sweep()
> 
>      retval <- sweep(retval, 2, mean, "+")
> 
> complains about a dimension miss-match, but then throws an error
> "non-numeric argument to binary operator" which mystifies me completely.
> 
> At this point I give up, and hope that someone who knows what they are
> doing will take over.
> 
> cheers,
> 
> Rolf Turner
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
* E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From @|m@h@rme| @end|ng |rom gm@||@com  Tue Oct 22 14:53:17 2024
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Tue, 22 Oct 2024 07:53:17 -0500
Subject: [R-sig-ME] Fixing non-symetrix sigma matrix
In-Reply-To: <750149ac-de0e-4d10-b3e4-5cb04ac85d1c@gmail.com>
References: <CACgv6yUixJQYs8Wz=Vzm+NAS42A-W_X0g_UHbqGGtH-WCHjxdA@mail.gmail.com>
 <20241022115746.4dffe9b6@elderly-dell>
 <750149ac-de0e-4d10-b3e4-5cb04ac85d1c@gmail.com>
Message-ID: <CACgv6yVkrmM1oe2A5uW0G=mL9cd28PU+0j67g8h1i3O0gFiSuQ@mail.gmail.com>

Thank you so much all for your responses.
Ben, I wonder what would be the equivalent of my mediator model in brms?

mediator <- glmmTMB(pic_percent ~ con +
                      (0+con | ID) +
                      (0+con | TRIAL_INDEX),
                    data=df,
        family = beta_family(),
        ziformula = ~1)

On Mon, Oct 21, 2024, 9:28?PM Ben Bolker <bbolker at gmail.com> wrote:

>
>    The mediate() function simply isn't set up to work with glmmTMB
> objects.  Rolf's fix takes care of the fact that vcov() applied to a
> glmmTMB object returns a list of covariance matrices (for the fixed
> effect parameters of the conditional distribution, zero-inflation model,
> dispersion model) rather than a single matrix.
>
>    Beyond that, though, if you look at the code for mediate() you'll see
> a whole bunch of logic that checks whether each of the two models
> inherits from classes `glm`, `gam`, `survreg`, `merMod`, etc. ... by
> structuring their code this way (rather than using S3 methods), the
> authors have made it hard to adapt their code to new model types without
> digging all the way into the code and writing new components for the new
> model type ...
>
>    You could ask the package maintainers to add these capabilities, or
> try to find someone else who can do it for you ... (it might not be too
> hard, but the mediate() function is 1400+ lines long ... the way to go
> at it would be to look for everywhere that `isMer.m` or `isMer.y` (main
> or mediation model is from lme4) and write parallel code that works with
> glmmTMB objects instead ...)
>
>    Ben Bolker
>
>
>
> On 10/21/24 18:57, Rolf Turner wrote:
> >
> > On Mon, 21 Oct 2024 13:34:56 -0500
> > Simon Harmel <sim.harmel at gmail.com> wrote:
> >
> >> Hello Mixed-Models experts,
> >>
> >> I'm trying to fit the following reproducible mediation model called
> >> final. But I get an error saying: ...sigma must be a symmetric
> >> matrix...
> >>
> >> Could you please advise how I can possibly fix this error?
> >>
> >> Many thanks,
> >> Simon
> >>
> >> Reproducible R code:
> >> df <-
> >> read.csv("
> https://raw.githubusercontent.com/fpqq/w/refs/heads/main/t.csv")
> >>
> >> library(glmmTMB)
> >> library(mediation)
> >>
> >> mediator <- glmmTMB(pic_percent ~ con +
> >>                        (0+con | ID) +
> >>                        (0+con | TRIAL_INDEX),
> >>                      data=df,
> >>          family = beta_family(),
> >>          ziformula = ~1)
> >>
> >> outcome <- glmmTMB(acc ~ con + pic_percent +
> >>                        (0+con+pic_percent | Q),
> >>                       data = df,
> >>                     family = binomial())
> >>
> >> final <- mediate(mediator, outcome, sims=50,
> >>                      treat="con", mediator="pic_percent")
> >>
> >
> > Thank you for the clearly structured reproducible example.
> >
> > I must preface my remarks by saying that this is definitely a case of
> > the blind leading the partially-sighted; I am no "mixed model expert",
> > and I really haven't a clue about "mediation".
> >
> > Having said that, there seems to me (in my ignorance) to be several
> > things wrong in the code of mediate().  If we do
> >
> >      sink("mediate.R")
> >      mediate
> >      sink()
> >
> > we find at line 469 of mediate.R the code:
> >
> >      MModel <- rmvnorm(sims, mean = MModel.coef, sigma = MModel.var.cov)
> >
> > This seems to be incorrect.  MModel.var.coef should be a 2 x 2 matrix,
> > but it is a list.  The first entry of this list seems to be the
> > required covariance matrix.  Similarly MModel.coef is a list; the
> > second two entries seem to be empty lists.  The first entry is a list of
> > length 2, each entry being a matrix.  It is not at all clear to me what
> > role these matrices play.  If one modifies the call to rmvnorm() to,
> > e.g.
> >
> >      MModel <- rmvnorm(sims, mean = MModel.coef[[1]][[1]],
> >                        sigma = MModel.var.cov[[1]])
> >
> > then the code runs a bit further, but rmvnorm() hangs up at the end
> > with an error.  The call to sweep()
> >
> >      retval <- sweep(retval, 2, mean, "+")
> >
> > complains about a dimension miss-match, but then throws an error
> > "non-numeric argument to binary operator" which mystifies me completely.
> >
> > At this point I give up, and hope that someone who knows what they are
> > doing will take over.
> >
> > cheers,
> >
> > Rolf Turner
> >
>
> --
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> * E-mail is sent at my convenience; I don't expect replies outside of
> working hours.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From @|m@h@rme| @end|ng |rom gm@||@com  Thu Oct 24 01:13:14 2024
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Wed, 23 Oct 2024 18:13:14 -0500
Subject: [R-sig-ME] glmmTMB syntax to brm() syntax
Message-ID: <CACgv6yVSpSufc8+H78T5qbnRwv3n-0ShErQkuo-MvqMKZjy59g@mail.gmail.com>

Hello all,

I was wondering what is the closest equivalent of my glmmTMB syntax below
in brms::brm() syntax?

glmmTMBglmmTMB(pic_percent ~ con +
                      (0+con | ID) +
                      (0+con | TRIAL_INDEX),
                    data=DATA,
        family = beta_family(),
        ziformula = ~1)


Thank you,

Simon

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Thu Oct 24 18:10:56 2024
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 24 Oct 2024 12:10:56 -0400
Subject: [R-sig-ME] glmmTMB syntax to brm() syntax
In-Reply-To: <CACgv6yVSpSufc8+H78T5qbnRwv3n-0ShErQkuo-MvqMKZjy59g@mail.gmail.com>
References: <CACgv6yVSpSufc8+H78T5qbnRwv3n-0ShErQkuo-MvqMKZjy59g@mail.gmail.com>
Message-ID: <ddce0a67-33ba-4743-8c60-2a8883bde549@gmail.com>

   See below.  The two models (glmmTMB and brms) give sufficiently 
similar estimates that I'm confident that the specifications match.

set.seed(101)
library(glmmTMB)
library(brms)
library(broom.mixed)
library(tidyverse)

dd <- data.frame(ID = rep(1:100, each = 10),
                  TRIAL_INDEX = rep(1:10, 100),
                  con = rnorm(1000))
dd$pic_percent <- simulate_new(
     ~ con + (0+con | ID) +
         (0+con | TRIAL_INDEX),
     ziformula = ~1,
     family = beta_family(),
     newdata = dd,
     newparams = list(beta = c(0, 0.5), theta = rep(-1,2),
                      betadisp = 1, betazi = -2))[[1]]


m1 <- glmmTMB(pic_percent ~ con + (0+con | ID) +
     (0+con | TRIAL_INDEX),
         data=dd,
         family = beta_family(),
         ziformula = ~1)

## 
https://mvuorre.github.io/posts/2019-02-18-analyze-analog-scale-ratings-with-zero-one-inflated-beta-models/
m2 <- brm(
     bf(pic_percent ~ con + (0+con | ID) +
            (0+con | TRIAL_INDEX),
     zi = ~ 1),
     data=dd,
     family = zero_inflated_beta()
)


(purrr::map_dfr(list(glmmTMB = m1, brms = m2), tidy, .id = "model")
     |> select(model, effect, component, group, term, estimate)
     |> pivot_wider(names_from = model, values_from = estimate)
)



On 10/23/24 19:13, Simon Harmel wrote:
> Hello all,
> 
> I was wondering what is the closest equivalent of my glmmTMB syntax below
> in brms::brm() syntax?
> 
> glmmTMBglmmTMB(pic_percent ~ con +
>                        (0+con | ID) +
>                        (0+con | TRIAL_INDEX),
>                      data=DATA,
>          family = beta_family(),
>          ziformula = ~1)
> 
> 
> Thank you,
> 
> Simon
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
* E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From @|m@h@rme| @end|ng |rom gm@||@com  Fri Oct 25 03:44:56 2024
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Thu, 24 Oct 2024 20:44:56 -0500
Subject: [R-sig-ME] glmmTMB syntax to brm() syntax
In-Reply-To: <ddce0a67-33ba-4743-8c60-2a8883bde549@gmail.com>
References: <CACgv6yVSpSufc8+H78T5qbnRwv3n-0ShErQkuo-MvqMKZjy59g@mail.gmail.com>
 <ddce0a67-33ba-4743-8c60-2a8883bde549@gmail.com>
Message-ID: <CACgv6yVYh7AhGgsfceRFgMaF8kA0Rvvb40btfC4pZ7ZxOiz0TQ@mail.gmail.com>

Thank you so very much, Ben! And wow, the brm() version is extremely slow.

Simon

On Thu, Oct 24, 2024 at 11:11?AM Ben Bolker <bbolker at gmail.com> wrote:
>
>    See below.  The two models (glmmTMB and brms) give sufficiently
> similar estimates that I'm confident that the specifications match.
>
> set.seed(101)
> library(glmmTMB)
> library(brms)
> library(broom.mixed)
> library(tidyverse)
>
> dd <- data.frame(ID = rep(1:100, each = 10),
>                   TRIAL_INDEX = rep(1:10, 100),
>                   con = rnorm(1000))
> dd$pic_percent <- simulate_new(
>      ~ con + (0+con | ID) +
>          (0+con | TRIAL_INDEX),
>      ziformula = ~1,
>      family = beta_family(),
>      newdata = dd,
>      newparams = list(beta = c(0, 0.5), theta = rep(-1,2),
>                       betadisp = 1, betazi = -2))[[1]]
>
>
> m1 <- glmmTMB(pic_percent ~ con + (0+con | ID) +
>      (0+con | TRIAL_INDEX),
>          data=dd,
>          family = beta_family(),
>          ziformula = ~1)
>
> ##
> https://mvuorre.github.io/posts/2019-02-18-analyze-analog-scale-ratings-with-zero-one-inflated-beta-models/
> m2 <- brm(
>      bf(pic_percent ~ con + (0+con | ID) +
>             (0+con | TRIAL_INDEX),
>      zi = ~ 1),
>      data=dd,
>      family = zero_inflated_beta()
> )
>
>
> (purrr::map_dfr(list(glmmTMB = m1, brms = m2), tidy, .id = "model")
>      |> select(model, effect, component, group, term, estimate)
>      |> pivot_wider(names_from = model, values_from = estimate)
> )
>
>
>
> On 10/23/24 19:13, Simon Harmel wrote:
> > Hello all,
> >
> > I was wondering what is the closest equivalent of my glmmTMB syntax below
> > in brms::brm() syntax?
> >
> > glmmTMBglmmTMB(pic_percent ~ con +
> >                        (0+con | ID) +
> >                        (0+con | TRIAL_INDEX),
> >                      data=DATA,
> >          family = beta_family(),
> >          ziformula = ~1)
> >
> >
> > Thank you,
> >
> > Simon
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> * E-mail is sent at my convenience; I don't expect replies outside of
> working hours.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbo|ker @end|ng |rom gm@||@com  Fri Oct 25 04:11:26 2024
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 24 Oct 2024 22:11:26 -0400
Subject: [R-sig-ME] glmmTMB syntax to brm() syntax
In-Reply-To: <CACgv6yVYh7AhGgsfceRFgMaF8kA0Rvvb40btfC4pZ7ZxOiz0TQ@mail.gmail.com>
References: <CACgv6yVSpSufc8+H78T5qbnRwv3n-0ShErQkuo-MvqMKZjy59g@mail.gmail.com>
 <ddce0a67-33ba-4743-8c60-2a8883bde549@gmail.com>
 <CACgv6yVYh7AhGgsfceRFgMaF8kA0Rvvb40btfC4pZ7ZxOiz0TQ@mail.gmail.com>
Message-ID: <d2436da3-830d-4b3a-8f7f-a047bb57e99b@gmail.com>

   Most of the time taken by the brms version is in compilation. It may 
be possible (I don't remember how) to cache the compiled model and 
re-use it for subsequent models, if you are going to be (for example) 
fitting the same model to many different data sets ...

On 10/24/24 21:44, Simon Harmel wrote:
> Thank you so very much, Ben! And wow, the brm() version is extremely slow.
> 
> Simon
> 
> On Thu, Oct 24, 2024 at 11:11?AM Ben Bolker <bbolker at gmail.com> wrote:
>>
>>     See below.  The two models (glmmTMB and brms) give sufficiently
>> similar estimates that I'm confident that the specifications match.
>>
>> set.seed(101)
>> library(glmmTMB)
>> library(brms)
>> library(broom.mixed)
>> library(tidyverse)
>>
>> dd <- data.frame(ID = rep(1:100, each = 10),
>>                    TRIAL_INDEX = rep(1:10, 100),
>>                    con = rnorm(1000))
>> dd$pic_percent <- simulate_new(
>>       ~ con + (0+con | ID) +
>>           (0+con | TRIAL_INDEX),
>>       ziformula = ~1,
>>       family = beta_family(),
>>       newdata = dd,
>>       newparams = list(beta = c(0, 0.5), theta = rep(-1,2),
>>                        betadisp = 1, betazi = -2))[[1]]
>>
>>
>> m1 <- glmmTMB(pic_percent ~ con + (0+con | ID) +
>>       (0+con | TRIAL_INDEX),
>>           data=dd,
>>           family = beta_family(),
>>           ziformula = ~1)
>>
>> ##
>> https://mvuorre.github.io/posts/2019-02-18-analyze-analog-scale-ratings-with-zero-one-inflated-beta-models/
>> m2 <- brm(
>>       bf(pic_percent ~ con + (0+con | ID) +
>>              (0+con | TRIAL_INDEX),
>>       zi = ~ 1),
>>       data=dd,
>>       family = zero_inflated_beta()
>> )
>>
>>
>> (purrr::map_dfr(list(glmmTMB = m1, brms = m2), tidy, .id = "model")
>>       |> select(model, effect, component, group, term, estimate)
>>       |> pivot_wider(names_from = model, values_from = estimate)
>> )
>>
>>
>>
>> On 10/23/24 19:13, Simon Harmel wrote:
>>> Hello all,
>>>
>>> I was wondering what is the closest equivalent of my glmmTMB syntax below
>>> in brms::brm() syntax?
>>>
>>> glmmTMBglmmTMB(pic_percent ~ con +
>>>                         (0+con | ID) +
>>>                         (0+con | TRIAL_INDEX),
>>>                       data=DATA,
>>>           family = beta_family(),
>>>           ziformula = ~1)
>>>
>>>
>>> Thank you,
>>>
>>> Simon
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> --
>> Dr. Benjamin Bolker
>> Professor, Mathematics & Statistics and Biology, McMaster University
>> Director, School of Computational Science and Engineering
>> * E-mail is sent at my convenience; I don't expect replies outside of
>> working hours.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
* E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From @|m@h@rme| @end|ng |rom gm@||@com  Sun Oct 27 02:51:39 2024
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Sat, 26 Oct 2024 20:51:39 -0500
Subject: [R-sig-ME] glmmTMB syntax to brm() syntax
In-Reply-To: <d2436da3-830d-4b3a-8f7f-a047bb57e99b@gmail.com>
References: <CACgv6yVSpSufc8+H78T5qbnRwv3n-0ShErQkuo-MvqMKZjy59g@mail.gmail.com>
 <ddce0a67-33ba-4743-8c60-2a8883bde549@gmail.com>
 <CACgv6yVYh7AhGgsfceRFgMaF8kA0Rvvb40btfC4pZ7ZxOiz0TQ@mail.gmail.com>
 <d2436da3-830d-4b3a-8f7f-a047bb57e99b@gmail.com>
Message-ID: <CACgv6yU+3ss86qqsaY0YQeqhY3JDTKQvOs0yd=kg9-chM68+iw@mail.gmail.com>

Ben, can I ask a similar question? Is there also a function similar to
glmmTMB::new_simulate() to easily simulate the following model?

nlme::lme(Y ~ condition + Cognitive_Rate, random= ~1 | subject, data = DATA,
weights = varIdent(form=~1|condition),
 correlation = corSymm(form = ~1| subject))

Thank you!
Simon

On Thu, Oct 24, 2024 at 9:11?PM Ben Bolker <bbolker at gmail.com> wrote:
>
>    Most of the time taken by the brms version is in compilation. It may
> be possible (I don't remember how) to cache the compiled model and
> re-use it for subsequent models, if you are going to be (for example)
> fitting the same model to many different data sets ...
>
> On 10/24/24 21:44, Simon Harmel wrote:
> > Thank you so very much, Ben! And wow, the brm() version is extremely slow.
> >
> > Simon
> >
> > On Thu, Oct 24, 2024 at 11:11?AM Ben Bolker <bbolker at gmail.com> wrote:
> >>
> >>     See below.  The two models (glmmTMB and brms) give sufficiently
> >> similar estimates that I'm confident that the specifications match.
> >>
> >> set.seed(101)
> >> library(glmmTMB)
> >> library(brms)
> >> library(broom.mixed)
> >> library(tidyverse)
> >>
> >> dd <- data.frame(ID = rep(1:100, each = 10),
> >>                    TRIAL_INDEX = rep(1:10, 100),
> >>                    con = rnorm(1000))
> >> dd$pic_percent <- simulate_new(
> >>       ~ con + (0+con | ID) +
> >>           (0+con | TRIAL_INDEX),
> >>       ziformula = ~1,
> >>       family = beta_family(),
> >>       newdata = dd,
> >>       newparams = list(beta = c(0, 0.5), theta = rep(-1,2),
> >>                        betadisp = 1, betazi = -2))[[1]]
> >>
> >>
> >> m1 <- glmmTMB(pic_percent ~ con + (0+con | ID) +
> >>       (0+con | TRIAL_INDEX),
> >>           data=dd,
> >>           family = beta_family(),
> >>           ziformula = ~1)
> >>
> >> ##
> >> https://mvuorre.github.io/posts/2019-02-18-analyze-analog-scale-ratings-with-zero-one-inflated-beta-models/
> >> m2 <- brm(
> >>       bf(pic_percent ~ con + (0+con | ID) +
> >>              (0+con | TRIAL_INDEX),
> >>       zi = ~ 1),
> >>       data=dd,
> >>       family = zero_inflated_beta()
> >> )
> >>
> >>
> >> (purrr::map_dfr(list(glmmTMB = m1, brms = m2), tidy, .id = "model")
> >>       |> select(model, effect, component, group, term, estimate)
> >>       |> pivot_wider(names_from = model, values_from = estimate)
> >> )
> >>
> >>
> >>
> >> On 10/23/24 19:13, Simon Harmel wrote:
> >>> Hello all,
> >>>
> >>> I was wondering what is the closest equivalent of my glmmTMB syntax below
> >>> in brms::brm() syntax?
> >>>
> >>> glmmTMBglmmTMB(pic_percent ~ con +
> >>>                         (0+con | ID) +
> >>>                         (0+con | TRIAL_INDEX),
> >>>                       data=DATA,
> >>>           family = beta_family(),
> >>>           ziformula = ~1)
> >>>
> >>>
> >>> Thank you,
> >>>
> >>> Simon
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >> --
> >> Dr. Benjamin Bolker
> >> Professor, Mathematics & Statistics and Biology, McMaster University
> >> Director, School of Computational Science and Engineering
> >> * E-mail is sent at my convenience; I don't expect replies outside of
> >> working hours.
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> * E-mail is sent at my convenience; I don't expect replies outside of
> working hours.
>


From bbo|ker @end|ng |rom gm@||@com  Sun Oct 27 21:31:40 2024
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sun, 27 Oct 2024 16:31:40 -0400
Subject: [R-sig-ME] glmmTMB syntax to brm() syntax
In-Reply-To: <CACgv6yU+3ss86qqsaY0YQeqhY3JDTKQvOs0yd=kg9-chM68+iw@mail.gmail.com>
References: <CACgv6yVSpSufc8+H78T5qbnRwv3n-0ShErQkuo-MvqMKZjy59g@mail.gmail.com>
 <ddce0a67-33ba-4743-8c60-2a8883bde549@gmail.com>
 <CACgv6yVYh7AhGgsfceRFgMaF8kA0Rvvb40btfC4pZ7ZxOiz0TQ@mail.gmail.com>
 <d2436da3-830d-4b3a-8f7f-a047bb57e99b@gmail.com>
 <CACgv6yU+3ss86qqsaY0YQeqhY3JDTKQvOs0yd=kg9-chM68+iw@mail.gmail.com>
Message-ID: <5a6f2ef3-e5e4-441d-afdc-c019c64b949c@gmail.com>

   the way you would do this in glmmTMB (with simulate_new [sic], you 
wouldn't need a different function:

  * conditional model: ~condition + Cognitive_Rate ... (not surprisingly)
  * random effect model :  ... + (1|subject) (also not surprising
  * varIdent:  dispformula = ~  (1|condition)


The tricky part is the corSymm part.  To do this you'd probably need to 
add an 'observation number within subject' variable (say it's called 
`obs`) and use  ... + (0 + obs | subject).

   I don't know if that would correspond exactly. You could try some 
experiments.

   If not, you might have to implement the simulation code yourself ...

   Ben Bolker

On 10/26/24 21:51, Simon Harmel wrote:
> Ben, can I ask a similar question? Is there also a function similar to
> glmmTMB::new_simulate() to easily simulate the following model?
> 
> nlme::lme(Y ~ condition + Cognitive_Rate, random= ~1 | subject, data = DATA,
> weights = varIdent(form=~1|condition),
>   correlation = corSymm(form = ~1| subject))
> 
> Thank you!
> Simon
> 
> On Thu, Oct 24, 2024 at 9:11?PM Ben Bolker <bbolker at gmail.com> wrote:
>>
>>     Most of the time taken by the brms version is in compilation. It may
>> be possible (I don't remember how) to cache the compiled model and
>> re-use it for subsequent models, if you are going to be (for example)
>> fitting the same model to many different data sets ...
>>
>> On 10/24/24 21:44, Simon Harmel wrote:
>>> Thank you so very much, Ben! And wow, the brm() version is extremely slow.
>>>
>>> Simon
>>>
>>> On Thu, Oct 24, 2024 at 11:11?AM Ben Bolker <bbolker at gmail.com> wrote:
>>>>
>>>>      See below.  The two models (glmmTMB and brms) give sufficiently
>>>> similar estimates that I'm confident that the specifications match.
>>>>
>>>> set.seed(101)
>>>> library(glmmTMB)
>>>> library(brms)
>>>> library(broom.mixed)
>>>> library(tidyverse)
>>>>
>>>> dd <- data.frame(ID = rep(1:100, each = 10),
>>>>                     TRIAL_INDEX = rep(1:10, 100),
>>>>                     con = rnorm(1000))
>>>> dd$pic_percent <- simulate_new(
>>>>        ~ con + (0+con | ID) +
>>>>            (0+con | TRIAL_INDEX),
>>>>        ziformula = ~1,
>>>>        family = beta_family(),
>>>>        newdata = dd,
>>>>        newparams = list(beta = c(0, 0.5), theta = rep(-1,2),
>>>>                         betadisp = 1, betazi = -2))[[1]]
>>>>
>>>>
>>>> m1 <- glmmTMB(pic_percent ~ con + (0+con | ID) +
>>>>        (0+con | TRIAL_INDEX),
>>>>            data=dd,
>>>>            family = beta_family(),
>>>>            ziformula = ~1)
>>>>
>>>> ##
>>>> https://mvuorre.github.io/posts/2019-02-18-analyze-analog-scale-ratings-with-zero-one-inflated-beta-models/
>>>> m2 <- brm(
>>>>        bf(pic_percent ~ con + (0+con | ID) +
>>>>               (0+con | TRIAL_INDEX),
>>>>        zi = ~ 1),
>>>>        data=dd,
>>>>        family = zero_inflated_beta()
>>>> )
>>>>
>>>>
>>>> (purrr::map_dfr(list(glmmTMB = m1, brms = m2), tidy, .id = "model")
>>>>        |> select(model, effect, component, group, term, estimate)
>>>>        |> pivot_wider(names_from = model, values_from = estimate)
>>>> )
>>>>
>>>>
>>>>
>>>> On 10/23/24 19:13, Simon Harmel wrote:
>>>>> Hello all,
>>>>>
>>>>> I was wondering what is the closest equivalent of my glmmTMB syntax below
>>>>> in brms::brm() syntax?
>>>>>
>>>>> glmmTMBglmmTMB(pic_percent ~ con +
>>>>>                          (0+con | ID) +
>>>>>                          (0+con | TRIAL_INDEX),
>>>>>                        data=DATA,
>>>>>            family = beta_family(),
>>>>>            ziformula = ~1)
>>>>>
>>>>>
>>>>> Thank you,
>>>>>
>>>>> Simon
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>> --
>>>> Dr. Benjamin Bolker
>>>> Professor, Mathematics & Statistics and Biology, McMaster University
>>>> Director, School of Computational Science and Engineering
>>>> * E-mail is sent at my convenience; I don't expect replies outside of
>>>> working hours.
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> --
>> Dr. Benjamin Bolker
>> Professor, Mathematics & Statistics and Biology, McMaster University
>> Director, School of Computational Science and Engineering
>> * E-mail is sent at my convenience; I don't expect replies outside of
>> working hours.
>>

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
* E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From @|m@h@rme| @end|ng |rom gm@||@com  Sun Oct 27 21:43:29 2024
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Sun, 27 Oct 2024 15:43:29 -0500
Subject: [R-sig-ME] glmmTMB syntax to brm() syntax
In-Reply-To: <5a6f2ef3-e5e4-441d-afdc-c019c64b949c@gmail.com>
References: <CACgv6yVSpSufc8+H78T5qbnRwv3n-0ShErQkuo-MvqMKZjy59g@mail.gmail.com>
 <ddce0a67-33ba-4743-8c60-2a8883bde549@gmail.com>
 <CACgv6yVYh7AhGgsfceRFgMaF8kA0Rvvb40btfC4pZ7ZxOiz0TQ@mail.gmail.com>
 <d2436da3-830d-4b3a-8f7f-a047bb57e99b@gmail.com>
 <CACgv6yU+3ss86qqsaY0YQeqhY3JDTKQvOs0yd=kg9-chM68+iw@mail.gmail.com>
 <5a6f2ef3-e5e4-441d-afdc-c019c64b949c@gmail.com>
Message-ID: <CACgv6yWdFjESRiHG0PSLWCVjU8iEMxFDkzk7kVEifxxnObvibA@mail.gmail.com>

Super interesting! Thank you very much!

On Sun, Oct 27, 2024 at 3:31?PM Ben Bolker <bbolker at gmail.com> wrote:
>
>    the way you would do this in glmmTMB (with simulate_new [sic], you
> wouldn't need a different function:
>
>   * conditional model: ~condition + Cognitive_Rate ... (not surprisingly)
>   * random effect model :  ... + (1|subject) (also not surprising
>   * varIdent:  dispformula = ~  (1|condition)
>
>
> The tricky part is the corSymm part.  To do this you'd probably need to
> add an 'observation number within subject' variable (say it's called
> `obs`) and use  ... + (0 + obs | subject).
>
>    I don't know if that would correspond exactly. You could try some
> experiments.
>
>    If not, you might have to implement the simulation code yourself ...
>
>    Ben Bolker
>
> On 10/26/24 21:51, Simon Harmel wrote:
> > Ben, can I ask a similar question? Is there also a function similar to
> > glmmTMB::new_simulate() to easily simulate the following model?
> >
> > nlme::lme(Y ~ condition + Cognitive_Rate, random= ~1 | subject, data = DATA,
> > weights = varIdent(form=~1|condition),
> >   correlation = corSymm(form = ~1| subject))
> >
> > Thank you!
> > Simon
> >
> > On Thu, Oct 24, 2024 at 9:11?PM Ben Bolker <bbolker at gmail.com> wrote:
> >>
> >>     Most of the time taken by the brms version is in compilation. It may
> >> be possible (I don't remember how) to cache the compiled model and
> >> re-use it for subsequent models, if you are going to be (for example)
> >> fitting the same model to many different data sets ...
> >>
> >> On 10/24/24 21:44, Simon Harmel wrote:
> >>> Thank you so very much, Ben! And wow, the brm() version is extremely slow.
> >>>
> >>> Simon
> >>>
> >>> On Thu, Oct 24, 2024 at 11:11?AM Ben Bolker <bbolker at gmail.com> wrote:
> >>>>
> >>>>      See below.  The two models (glmmTMB and brms) give sufficiently
> >>>> similar estimates that I'm confident that the specifications match.
> >>>>
> >>>> set.seed(101)
> >>>> library(glmmTMB)
> >>>> library(brms)
> >>>> library(broom.mixed)
> >>>> library(tidyverse)
> >>>>
> >>>> dd <- data.frame(ID = rep(1:100, each = 10),
> >>>>                     TRIAL_INDEX = rep(1:10, 100),
> >>>>                     con = rnorm(1000))
> >>>> dd$pic_percent <- simulate_new(
> >>>>        ~ con + (0+con | ID) +
> >>>>            (0+con | TRIAL_INDEX),
> >>>>        ziformula = ~1,
> >>>>        family = beta_family(),
> >>>>        newdata = dd,
> >>>>        newparams = list(beta = c(0, 0.5), theta = rep(-1,2),
> >>>>                         betadisp = 1, betazi = -2))[[1]]
> >>>>
> >>>>
> >>>> m1 <- glmmTMB(pic_percent ~ con + (0+con | ID) +
> >>>>        (0+con | TRIAL_INDEX),
> >>>>            data=dd,
> >>>>            family = beta_family(),
> >>>>            ziformula = ~1)
> >>>>
> >>>> ##
> >>>> https://mvuorre.github.io/posts/2019-02-18-analyze-analog-scale-ratings-with-zero-one-inflated-beta-models/
> >>>> m2 <- brm(
> >>>>        bf(pic_percent ~ con + (0+con | ID) +
> >>>>               (0+con | TRIAL_INDEX),
> >>>>        zi = ~ 1),
> >>>>        data=dd,
> >>>>        family = zero_inflated_beta()
> >>>> )
> >>>>
> >>>>
> >>>> (purrr::map_dfr(list(glmmTMB = m1, brms = m2), tidy, .id = "model")
> >>>>        |> select(model, effect, component, group, term, estimate)
> >>>>        |> pivot_wider(names_from = model, values_from = estimate)
> >>>> )
> >>>>
> >>>>
> >>>>
> >>>> On 10/23/24 19:13, Simon Harmel wrote:
> >>>>> Hello all,
> >>>>>
> >>>>> I was wondering what is the closest equivalent of my glmmTMB syntax below
> >>>>> in brms::brm() syntax?
> >>>>>
> >>>>> glmmTMBglmmTMB(pic_percent ~ con +
> >>>>>                          (0+con | ID) +
> >>>>>                          (0+con | TRIAL_INDEX),
> >>>>>                        data=DATA,
> >>>>>            family = beta_family(),
> >>>>>            ziformula = ~1)
> >>>>>
> >>>>>
> >>>>> Thank you,
> >>>>>
> >>>>> Simon
> >>>>>
> >>>>>         [[alternative HTML version deleted]]
> >>>>>
> >>>>> _______________________________________________
> >>>>> R-sig-mixed-models at r-project.org mailing list
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>
> >>>> --
> >>>> Dr. Benjamin Bolker
> >>>> Professor, Mathematics & Statistics and Biology, McMaster University
> >>>> Director, School of Computational Science and Engineering
> >>>> * E-mail is sent at my convenience; I don't expect replies outside of
> >>>> working hours.
> >>>>
> >>>> _______________________________________________
> >>>> R-sig-mixed-models at r-project.org mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >> --
> >> Dr. Benjamin Bolker
> >> Professor, Mathematics & Statistics and Biology, McMaster University
> >> Director, School of Computational Science and Engineering
> >> * E-mail is sent at my convenience; I don't expect replies outside of
> >> working hours.
> >>
>
> --
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> * E-mail is sent at my convenience; I don't expect replies outside of
> working hours.
>


From L|eke@Moeree|@ @end|ng |rom UGent@be  Mon Oct 28 09:33:27 2024
From: L|eke@Moeree|@ @end|ng |rom UGent@be (Lieke Moereels)
Date: Mon, 28 Oct 2024 08:33:27 +0000
Subject: [R-sig-ME] GLMM post-hoc analysis with bootstrapping
Message-ID: <AS8PR09MB49502C593A9450DEA792D304F44A2@AS8PR09MB4950.eurprd09.prod.outlook.com>

Hello all
I hope you are all doing well!
I was also hoping someone could perhaps help me out with the following:
For an ecological study, we?re interested in comparing the diversity of different organism groups between one land use type (let?s call it ?type 1?) and three other land use types.
Our model is: Diversity ~ landuse + (1|location)
Currently, I am using the emmeans-package to conduct the post-hoc analysis and thereby obtain

  1.  Estimated marginal means of the diversity per land use type and their 95% confidence intervals, transformed to the response scale (with a bias adjustment for the random effects)
  2.  Contrasts between the emmeans (more specifically ratios, in the response scale) and the 95%CI thereof, with a Dunnett-like adjustment for multiple comparisons
  3.  P-values for the pairwise comparisons between the estimated mean of land use type 1 and the three other land use types, tests performed on the log-scale, with a Dunnet-like adjustment for multiple comparisons

However, as in the emmeans package Wald-intervals and -tests are used, I was hoping I could shift to an approach that uses bootstrap intervals which would be a bit more reliable for my small sample sizes.
Since I don?t manage to figure out how to code this to obtain the same output as above (a-c), I was hoping someone could help me with this.
Below is a minimal reproducible example for how I currently approach the post-hoc analysis.
It is not the best example given the singularity and really low random effect variance, but I hope this doesn?t bother for this question. Otherwise I could provide another dataset.
Thank you very much in advance for any help!
Lieke

# example data (D1 stands for the Shannon diversity)
example_df <- data.frame(
  code = c(1:88),
  landuse = c(rep("type1", 28), rep("type2", 24),
              rep("type3", 24), rep("type4", 12)),
  location = c(rep(letters[c(1,2,2:13)], each = 2),
               rep(letters[c(1,3:13)], each = 2),
               rep(letters[c(1:6,8:13)], each = 2),
               rep(letters[c(5,6,7,9,10,12)], each = 2)),
  D1 = c(2.59, 2.23, 1, 1, 1, 2.46, 2.94, 1, 2.94, 1.71,
          3.92, 2.94, 0, 3.78, 1, 2, 1.3, 1, 0, 0, 0, 3.75,
          0, 1, 0, 2, 2.38, 2, 1.51, 2.38, 1.89, 0, 2.97,
          1.18, 3.26, 5.86, 3.59, 1, 4.63, 2.94, 0, 0, 2.7,
          3.26, 2, 3.79, 0, 1, 4, 0, 2.8, 2, 0, 0, 1.7, 1,
          2, 0, 1, 0, 0, 0, 0, 0, 0, 2, 1, 0.98, 0, 0, 0, 1, 0,
          0, 1.38, 2, 0, 0, 0, 1.05, 0, 0, 1, 1, 1.16, 0, 2, 1)
)

# tweedie model
model <- glmmTMB(D1 ~ landuse + (1|location),
                 family = tweedie,
                 data = example_df)

# get "sigma"/extra dispersion necessary for bias adjustment (for random effects) when transforming estimates and intervals from log to response scale
extra_disp <- sqrt(sum(insight::get_variance(model)[["var.intercept"]]))
### singularity --> can't compute random effect variances reliably, but hope this is OK for the example
# a) get estimated marginal means and their 95%CI (Wald here) at the response scale
(model.emm <- emmeans(model, ~ landuse, type = "response",
                       bias.adjust = TRUE, sigma = extra_disp))
# b) get contrasts and their 95%CI at the response scale, with a Dunnet-like adjustment for multiple comparisons
(model.ratios <- confint(contrast(emmeans(model, ~ landuse),
                                     type = "response",
                                     bias.adjust = TRUE, sigma = extra_disp,
                                     "trt.vs.ctrl", ref = 1, reverse = TRUE)))

# c) get p-values for contrasts (tests performed on the log scale)
contrast(emmeans(model, ~ landuse), "trt.vs.ctrl", ref = 1, reverse = TRUE)


	[[alternative HTML version deleted]]


From @|m@h@rme| @end|ng |rom gm@||@com  Mon Oct 28 18:05:12 2024
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Mon, 28 Oct 2024 12:05:12 -0500
Subject: [R-sig-ME] glmmTMB syntax to brm() syntax
In-Reply-To: <ddce0a67-33ba-4743-8c60-2a8883bde549@gmail.com>
References: <CACgv6yVSpSufc8+H78T5qbnRwv3n-0ShErQkuo-MvqMKZjy59g@mail.gmail.com>
 <ddce0a67-33ba-4743-8c60-2a8883bde549@gmail.com>
Message-ID: <CACgv6yXXC96zcJUeVs7wCmjmnANga1Hk572Jxkmt_LLwfmxL=A@mail.gmail.com>

Ben, when I run your code below, I get the following error message: y
values must be 0 <= y < 1. My glmmTMB version is: ?1.1.7?.

Also, is there any good documentation explaining all possible names
used in argument `newparams=` in glmmTMB::new_simulate()?

Thank you!
Simon

On Thu, Oct 24, 2024 at 11:11?AM Ben Bolker <bbolker at gmail.com> wrote:
>
>    See below.  The two models (glmmTMB and brms) give sufficiently
> similar estimates that I'm confident that the specifications match.
>
> set.seed(101)
> library(glmmTMB)
> library(brms)
> library(broom.mixed)
> library(tidyverse)
>
> dd <- data.frame(ID = rep(1:100, each = 10),
>                   TRIAL_INDEX = rep(1:10, 100),
>                   con = rnorm(1000))
> dd$pic_percent <- simulate_new(
>      ~ con + (0+con | ID) +
>          (0+con | TRIAL_INDEX),
>      ziformula = ~1,
>      family = beta_family(),
>      newdata = dd,
>      newparams = list(beta = c(0, 0.5), theta = rep(-1,2),
>                       betadisp = 1, betazi = -2))[[1]]
>
>
> m1 <- glmmTMB(pic_percent ~ con + (0+con | ID) +
>      (0+con | TRIAL_INDEX),
>          data=dd,
>          family = beta_family(),
>          ziformula = ~1)
>
> ##
> https://mvuorre.github.io/posts/2019-02-18-analyze-analog-scale-ratings-with-zero-one-inflated-beta-models/
> m2 <- brm(
>      bf(pic_percent ~ con + (0+con | ID) +
>             (0+con | TRIAL_INDEX),
>      zi = ~ 1),
>      data=dd,
>      family = zero_inflated_beta()
> )
>
>
> (purrr::map_dfr(list(glmmTMB = m1, brms = m2), tidy, .id = "model")
>      |> select(model, effect, component, group, term, estimate)
>      |> pivot_wider(names_from = model, values_from = estimate)
> )
>
>
>
> On 10/23/24 19:13, Simon Harmel wrote:
> > Hello all,
> >
> > I was wondering what is the closest equivalent of my glmmTMB syntax below
> > in brms::brm() syntax?
> >
> > glmmTMBglmmTMB(pic_percent ~ con +
> >                        (0+con | ID) +
> >                        (0+con | TRIAL_INDEX),
> >                      data=DATA,
> >          family = beta_family(),
> >          ziformula = ~1)
> >
> >
> > Thank you,
> >
> > Simon
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> * E-mail is sent at my convenience; I don't expect replies outside of
> working hours.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbo|ker @end|ng |rom gm@||@com  Mon Oct 28 18:10:22 2024
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 28 Oct 2024 13:10:22 -0400
Subject: [R-sig-ME] glmmTMB syntax to brm() syntax
In-Reply-To: <CACgv6yXXC96zcJUeVs7wCmjmnANga1Hk572Jxkmt_LLwfmxL=A@mail.gmail.com>
References: <CACgv6yVSpSufc8+H78T5qbnRwv3n-0ShErQkuo-MvqMKZjy59g@mail.gmail.com>
 <ddce0a67-33ba-4743-8c60-2a8883bde549@gmail.com>
 <CACgv6yXXC96zcJUeVs7wCmjmnANga1Hk572Jxkmt_LLwfmxL=A@mail.gmail.com>
Message-ID: <1616e114-f867-46c8-b96f-21ec35315d9b@gmail.com>

    That's quite old, by R standards (1.1.8 came out a year ago, latest 
version is 1.1.10 -- there's a note in the NEWS for 1.1.10 
<https://cran.r-project.org/web/packages/glmmTMB/news.html> about fixing 
a simulate bug for the beta family

   (It's simulate_new(), not new_simulate())

   The docs say "(?beta?, ?betazi?, ?betadisp?, ?theta?, etc.)"; in this 
case "etc." includes thetazi (random-effects parameters for ZI terms, if 
any) and thetadisp (ditto, dispersion terms).

  The 'covstruct' vignette is the best place to read about 
parameterization of random-effects components.

On 2024-10-28 1:05 p.m., Simon Harmel wrote:
> Ben, when I run your code below, I get the following error message: y
> values must be 0 <= y < 1. My glmmTMB version is: ?1.1.7?.
> 
> Also, is there any good documentation explaining all possible names
> used in argument `newparams=` in glmmTMB::new_simulate()?
> 
> Thank you!
> Simon
> 
> On Thu, Oct 24, 2024 at 11:11?AM Ben Bolker <bbolker at gmail.com> wrote:
>>
>>     See below.  The two models (glmmTMB and brms) give sufficiently
>> similar estimates that I'm confident that the specifications match.
>>
>> set.seed(101)
>> library(glmmTMB)
>> library(brms)
>> library(broom.mixed)
>> library(tidyverse)
>>
>> dd <- data.frame(ID = rep(1:100, each = 10),
>>                    TRIAL_INDEX = rep(1:10, 100),
>>                    con = rnorm(1000))
>> dd$pic_percent <- simulate_new(
>>       ~ con + (0+con | ID) +
>>           (0+con | TRIAL_INDEX),
>>       ziformula = ~1,
>>       family = beta_family(),
>>       newdata = dd,
>>       newparams = list(beta = c(0, 0.5), theta = rep(-1,2),
>>                        betadisp = 1, betazi = -2))[[1]]
>>
>>
>> m1 <- glmmTMB(pic_percent ~ con + (0+con | ID) +
>>       (0+con | TRIAL_INDEX),
>>           data=dd,
>>           family = beta_family(),
>>           ziformula = ~1)
>>
>> ##
>> https://mvuorre.github.io/posts/2019-02-18-analyze-analog-scale-ratings-with-zero-one-inflated-beta-models/
>> m2 <- brm(
>>       bf(pic_percent ~ con + (0+con | ID) +
>>              (0+con | TRIAL_INDEX),
>>       zi = ~ 1),
>>       data=dd,
>>       family = zero_inflated_beta()
>> )
>>
>>
>> (purrr::map_dfr(list(glmmTMB = m1, brms = m2), tidy, .id = "model")
>>       |> select(model, effect, component, group, term, estimate)
>>       |> pivot_wider(names_from = model, values_from = estimate)
>> )
>>
>>
>>
>> On 10/23/24 19:13, Simon Harmel wrote:
>>> Hello all,
>>>
>>> I was wondering what is the closest equivalent of my glmmTMB syntax below
>>> in brms::brm() syntax?
>>>
>>> glmmTMBglmmTMB(pic_percent ~ con +
>>>                         (0+con | ID) +
>>>                         (0+con | TRIAL_INDEX),
>>>                       data=DATA,
>>>           family = beta_family(),
>>>           ziformula = ~1)
>>>
>>>
>>> Thank you,
>>>
>>> Simon
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> --
>> Dr. Benjamin Bolker
>> Professor, Mathematics & Statistics and Biology, McMaster University
>> Director, School of Computational Science and Engineering
>> * E-mail is sent at my convenience; I don't expect replies outside of
>> working hours.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
 > E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From @|m@h@rme| @end|ng |rom gm@||@com  Mon Oct 28 18:39:03 2024
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Mon, 28 Oct 2024 12:39:03 -0500
Subject: [R-sig-ME] glmmTMB syntax to brm() syntax
In-Reply-To: <1616e114-f867-46c8-b96f-21ec35315d9b@gmail.com>
References: <CACgv6yVSpSufc8+H78T5qbnRwv3n-0ShErQkuo-MvqMKZjy59g@mail.gmail.com>
 <ddce0a67-33ba-4743-8c60-2a8883bde549@gmail.com>
 <CACgv6yXXC96zcJUeVs7wCmjmnANga1Hk572Jxkmt_LLwfmxL=A@mail.gmail.com>
 <1616e114-f867-46c8-b96f-21ec35315d9b@gmail.com>
Message-ID: <CACgv6yWWgAPSYrFO-2hDYobJ5ai-NscnEz4QzwD5Zm6ksCJJuw@mail.gmail.com>

Thank you, Ben. I deleted and installed glmmTMB from CRAN and it is
still version 1.1.9 on my machine with that same error showing up.

I love the 'covstruct' vignette. But I, for example, don't know what
to use in my simulate_new() call below to define the dispersion,
would that be 'sigmadisp'?

dd <- data.frame(ID = rep(1:100, each = 2),
                 con = rep(c("simple","complex"), 100)) %>%
  group_by(ID) %>% mutate(obs=row_number())

dd$VOCD <- simulate_new(
  ~ 0+con + (1|ID),
  dispformula = ~ con,
  newdata = dd,
  newparams = list(beta = c(0, 0.5), theta = rep(-1,2),
                   disp = 1))[[1]]

On Mon, Oct 28, 2024 at 12:10?PM Ben Bolker <bbolker at gmail.com> wrote:
>
>     That's quite old, by R standards (1.1.8 came out a year ago, latest
> version is 1.1.10 -- there's a note in the NEWS for 1.1.10
> <https://cran.r-project.org/web/packages/glmmTMB/news.html> about fixing
> a simulate bug for the beta family
>
>    (It's simulate_new(), not new_simulate())
>
>    The docs say "(?beta?, ?betazi?, ?betadisp?, ?theta?, etc.)"; in this
> case "etc." includes thetazi (random-effects parameters for ZI terms, if
> any) and thetadisp (ditto, dispersion terms).
>
>   The 'covstruct' vignette is the best place to read about
> parameterization of random-effects components.
>
> On 2024-10-28 1:05 p.m., Simon Harmel wrote:
> > Ben, when I run your code below, I get the following error message: y
> > values must be 0 <= y < 1. My glmmTMB version is: ?1.1.7?.
> >
> > Also, is there any good documentation explaining all possible names
> > used in argument `newparams=` in glmmTMB::new_simulate()?
> >
> > Thank you!
> > Simon
> >
> > On Thu, Oct 24, 2024 at 11:11?AM Ben Bolker <bbolker at gmail.com> wrote:
> >>
> >>     See below.  The two models (glmmTMB and brms) give sufficiently
> >> similar estimates that I'm confident that the specifications match.
> >>
> >> set.seed(101)
> >> library(glmmTMB)
> >> library(brms)
> >> library(broom.mixed)
> >> library(tidyverse)
> >>
> >> dd <- data.frame(ID = rep(1:100, each = 10),
> >>                    TRIAL_INDEX = rep(1:10, 100),
> >>                    con = rnorm(1000))
> >> dd$pic_percent <- simulate_new(
> >>       ~ con + (0+con | ID) +
> >>           (0+con | TRIAL_INDEX),
> >>       ziformula = ~1,
> >>       family = beta_family(),
> >>       newdata = dd,
> >>       newparams = list(beta = c(0, 0.5), theta = rep(-1,2),
> >>                        betadisp = 1, betazi = -2))[[1]]
> >>
> >>
> >> m1 <- glmmTMB(pic_percent ~ con + (0+con | ID) +
> >>       (0+con | TRIAL_INDEX),
> >>           data=dd,
> >>           family = beta_family(),
> >>           ziformula = ~1)
> >>
> >> ##
> >> https://mvuorre.github.io/posts/2019-02-18-analyze-analog-scale-ratings-with-zero-one-inflated-beta-models/
> >> m2 <- brm(
> >>       bf(pic_percent ~ con + (0+con | ID) +
> >>              (0+con | TRIAL_INDEX),
> >>       zi = ~ 1),
> >>       data=dd,
> >>       family = zero_inflated_beta()
> >> )
> >>
> >>
> >> (purrr::map_dfr(list(glmmTMB = m1, brms = m2), tidy, .id = "model")
> >>       |> select(model, effect, component, group, term, estimate)
> >>       |> pivot_wider(names_from = model, values_from = estimate)
> >> )
> >>
> >>
> >>
> >> On 10/23/24 19:13, Simon Harmel wrote:
> >>> Hello all,
> >>>
> >>> I was wondering what is the closest equivalent of my glmmTMB syntax below
> >>> in brms::brm() syntax?
> >>>
> >>> glmmTMBglmmTMB(pic_percent ~ con +
> >>>                         (0+con | ID) +
> >>>                         (0+con | TRIAL_INDEX),
> >>>                       data=DATA,
> >>>           family = beta_family(),
> >>>           ziformula = ~1)
> >>>
> >>>
> >>> Thank you,
> >>>
> >>> Simon
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >> --
> >> Dr. Benjamin Bolker
> >> Professor, Mathematics & Statistics and Biology, McMaster University
> >> Director, School of Computational Science and Engineering
> >> * E-mail is sent at my convenience; I don't expect replies outside of
> >> working hours.
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
>  > E-mail is sent at my convenience; I don't expect replies outside of
> working hours.
>


From bbo|ker @end|ng |rom gm@||@com  Mon Oct 28 19:33:37 2024
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 28 Oct 2024 14:33:37 -0400
Subject: [R-sig-ME] glmmTMB syntax to brm() syntax
In-Reply-To: <CACgv6yWWgAPSYrFO-2hDYobJ5ai-NscnEz4QzwD5Zm6ksCJJuw@mail.gmail.com>
References: <CACgv6yVSpSufc8+H78T5qbnRwv3n-0ShErQkuo-MvqMKZjy59g@mail.gmail.com>
 <ddce0a67-33ba-4743-8c60-2a8883bde549@gmail.com>
 <CACgv6yXXC96zcJUeVs7wCmjmnANga1Hk572Jxkmt_LLwfmxL=A@mail.gmail.com>
 <1616e114-f867-46c8-b96f-21ec35315d9b@gmail.com>
 <CACgv6yWWgAPSYrFO-2hDYobJ5ai-NscnEz4QzwD5Zm6ksCJJuw@mail.gmail.com>
Message-ID: <bb8ad692-8ce2-462b-88f4-355057deb482@gmail.com>

   You should be getting version 1.1.10 from CRAN, unless you're using 
an outdated mirror, see 
https://cran.r-project.org/web/packages/glmmTMB/index.html ... you will 
need version 1.1.10 to avoid the error.

    If you want a dispersion parameter of 1.0 then you probably want 
betadisp = 0 (since the dispersion model uses a log link).

   You also need to provide only a vector of length 1 for theta, since 
you only have a single (scalar) random effect term.  And you need to 
provide two values for betadisp (since you are specifying ~con, and con 
is a two-level factor), i.e.

  dd$VOCD <- simulate_new(
    ~ 0+con + (1|ID),
    dispformula = ~ con,
    newdata = dd,
    newparams = list(beta = c(0, 0.5), theta = -1,
                     betadisp = rep(0,2)))[[1]]



On 2024-10-28 1:39 p.m., Simon Harmel wrote:
> Thank you, Ben. I deleted and installed glmmTMB from CRAN and it is
> still version 1.1.9 on my machine with that same error showing up.
> 
> I love the 'covstruct' vignette. But I, for example, don't know what
> to use in my simulate_new() call below to define the dispersion,
> would that be 'sigmadisp'?
> 
> dd <- data.frame(ID = rep(1:100, each = 2),
>                   con = rep(c("simple","complex"), 100)) %>%
>    group_by(ID) %>% mutate(obs=row_number())
> 
> dd$VOCD <- simulate_new(
>    ~ 0+con + (1|ID),
>    dispformula = ~ con,
>    newdata = dd,
>    newparams = list(beta = c(0, 0.5), theta = rep(-1,2),
>                     disp = 1))[[1]]
> 
> On Mon, Oct 28, 2024 at 12:10?PM Ben Bolker <bbolker at gmail.com> wrote:
>>
>>      That's quite old, by R standards (1.1.8 came out a year ago, latest
>> version is 1.1.10 -- there's a note in the NEWS for 1.1.10
>> <https://cran.r-project.org/web/packages/glmmTMB/news.html> about fixing
>> a simulate bug for the beta family
>>
>>     (It's simulate_new(), not new_simulate())
>>
>>     The docs say "(?beta?, ?betazi?, ?betadisp?, ?theta?, etc.)"; in this
>> case "etc." includes thetazi (random-effects parameters for ZI terms, if
>> any) and thetadisp (ditto, dispersion terms).
>>
>>    The 'covstruct' vignette is the best place to read about
>> parameterization of random-effects components.
>>
>> On 2024-10-28 1:05 p.m., Simon Harmel wrote:
>>> Ben, when I run your code below, I get the following error message: y
>>> values must be 0 <= y < 1. My glmmTMB version is: ?1.1.7?.
>>>
>>> Also, is there any good documentation explaining all possible names
>>> used in argument `newparams=` in glmmTMB::new_simulate()?
>>>
>>> Thank you!
>>> Simon
>>>
>>> On Thu, Oct 24, 2024 at 11:11?AM Ben Bolker <bbolker at gmail.com> wrote:
>>>>
>>>>      See below.  The two models (glmmTMB and brms) give sufficiently
>>>> similar estimates that I'm confident that the specifications match.
>>>>
>>>> set.seed(101)
>>>> library(glmmTMB)
>>>> library(brms)
>>>> library(broom.mixed)
>>>> library(tidyverse)
>>>>
>>>> dd <- data.frame(ID = rep(1:100, each = 10),
>>>>                     TRIAL_INDEX = rep(1:10, 100),
>>>>                     con = rnorm(1000))
>>>> dd$pic_percent <- simulate_new(
>>>>        ~ con + (0+con | ID) +
>>>>            (0+con | TRIAL_INDEX),
>>>>        ziformula = ~1,
>>>>        family = beta_family(),
>>>>        newdata = dd,
>>>>        newparams = list(beta = c(0, 0.5), theta = rep(-1,2),
>>>>                         betadisp = 1, betazi = -2))[[1]]
>>>>
>>>>
>>>> m1 <- glmmTMB(pic_percent ~ con + (0+con | ID) +
>>>>        (0+con | TRIAL_INDEX),
>>>>            data=dd,
>>>>            family = beta_family(),
>>>>            ziformula = ~1)
>>>>
>>>> ##
>>>> https://mvuorre.github.io/posts/2019-02-18-analyze-analog-scale-ratings-with-zero-one-inflated-beta-models/
>>>> m2 <- brm(
>>>>        bf(pic_percent ~ con + (0+con | ID) +
>>>>               (0+con | TRIAL_INDEX),
>>>>        zi = ~ 1),
>>>>        data=dd,
>>>>        family = zero_inflated_beta()
>>>> )
>>>>
>>>>
>>>> (purrr::map_dfr(list(glmmTMB = m1, brms = m2), tidy, .id = "model")
>>>>        |> select(model, effect, component, group, term, estimate)
>>>>        |> pivot_wider(names_from = model, values_from = estimate)
>>>> )
>>>>
>>>>
>>>>
>>>> On 10/23/24 19:13, Simon Harmel wrote:
>>>>> Hello all,
>>>>>
>>>>> I was wondering what is the closest equivalent of my glmmTMB syntax below
>>>>> in brms::brm() syntax?
>>>>>
>>>>> glmmTMBglmmTMB(pic_percent ~ con +
>>>>>                          (0+con | ID) +
>>>>>                          (0+con | TRIAL_INDEX),
>>>>>                        data=DATA,
>>>>>            family = beta_family(),
>>>>>            ziformula = ~1)
>>>>>
>>>>>
>>>>> Thank you,
>>>>>
>>>>> Simon
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>> --
>>>> Dr. Benjamin Bolker
>>>> Professor, Mathematics & Statistics and Biology, McMaster University
>>>> Director, School of Computational Science and Engineering
>>>> * E-mail is sent at my convenience; I don't expect replies outside of
>>>> working hours.
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> --
>> Dr. Benjamin Bolker
>> Professor, Mathematics & Statistics and Biology, McMaster University
>> Director, School of Computational Science and Engineering
>>   > E-mail is sent at my convenience; I don't expect replies outside of
>> working hours.
>>

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
 > E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From @|m@h@rme| @end|ng |rom gm@||@com  Tue Oct 29 00:43:12 2024
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Mon, 28 Oct 2024 18:43:12 -0500
Subject: [R-sig-ME] glmmTMB syntax to brm() syntax
In-Reply-To: <bb8ad692-8ce2-462b-88f4-355057deb482@gmail.com>
References: <CACgv6yVSpSufc8+H78T5qbnRwv3n-0ShErQkuo-MvqMKZjy59g@mail.gmail.com>
 <ddce0a67-33ba-4743-8c60-2a8883bde549@gmail.com>
 <CACgv6yXXC96zcJUeVs7wCmjmnANga1Hk572Jxkmt_LLwfmxL=A@mail.gmail.com>
 <1616e114-f867-46c8-b96f-21ec35315d9b@gmail.com>
 <CACgv6yWWgAPSYrFO-2hDYobJ5ai-NscnEz4QzwD5Zm6ksCJJuw@mail.gmail.com>
 <bb8ad692-8ce2-462b-88f4-355057deb482@gmail.com>
Message-ID: <CACgv6yVX_0-_PbOsFN78bFrN2XuBYdwxMoFG-dgYKfHJ7pUYcQ@mail.gmail.com>

All good now, I managed to get the 1.1.10 version installed. So, with
large enough data (ex. below), I should be able to recover the
parameters, right?

I ask because I can recover all parameters, but wonder how to
determine if my model is recovering theta=-1?


set.seed(101)
dd <- data.frame(ID = rep(1:10000, each=2),
                 con = rep(c("simple","complex"), 10000))

dd$VOCD <- simulate_new(
  ~ 0+con + (1|ID),
  dispformula = ~ 0+con,
  newdata = dd,
  newparams = list(beta = c(0, .5), theta = -1,
                   betadisp = c(2,1.6)))[[1]]


glmmTMB(VOCD ~ 0+con + (1|ID),
        dispformula = ~ 0+con, data = dd)

On Mon, Oct 28, 2024 at 1:33?PM Ben Bolker <bbolker at gmail.com> wrote:
>
>    You should be getting version 1.1.10 from CRAN, unless you're using
> an outdated mirror, see
> https://cran.r-project.org/web/packages/glmmTMB/index.html ... you will
> need version 1.1.10 to avoid the error.
>
>     If you want a dispersion parameter of 1.0 then you probably want
> betadisp = 0 (since the dispersion model uses a log link).
>
>    You also need to provide only a vector of length 1 for theta, since
> you only have a single (scalar) random effect term.  And you need to
> provide two values for betadisp (since you are specifying ~con, and con
> is a two-level factor), i.e.
>
>   dd$VOCD <- simulate_new(
>     ~ 0+con + (1|ID),
>     dispformula = ~ con,
>     newdata = dd,
>     newparams = list(beta = c(0, 0.5), theta = -1,
>                      betadisp = rep(0,2)))[[1]]
>
>
>
> On 2024-10-28 1:39 p.m., Simon Harmel wrote:
> > Thank you, Ben. I deleted and installed glmmTMB from CRAN and it is
> > still version 1.1.9 on my machine with that same error showing up.
> >
> > I love the 'covstruct' vignette. But I, for example, don't know what
> > to use in my simulate_new() call below to define the dispersion,
> > would that be 'sigmadisp'?
> >
> > dd <- data.frame(ID = rep(1:100, each = 2),
> >                   con = rep(c("simple","complex"), 100)) %>%
> >    group_by(ID) %>% mutate(obs=row_number())
> >
> > dd$VOCD <- simulate_new(
> >    ~ 0+con + (1|ID),
> >    dispformula = ~ con,
> >    newdata = dd,
> >    newparams = list(beta = c(0, 0.5), theta = rep(-1,2),
> >                     disp = 1))[[1]]
> >
> > On Mon, Oct 28, 2024 at 12:10?PM Ben Bolker <bbolker at gmail.com> wrote:
> >>
> >>      That's quite old, by R standards (1.1.8 came out a year ago, latest
> >> version is 1.1.10 -- there's a note in the NEWS for 1.1.10
> >> <https://cran.r-project.org/web/packages/glmmTMB/news.html> about fixing
> >> a simulate bug for the beta family
> >>
> >>     (It's simulate_new(), not new_simulate())
> >>
> >>     The docs say "(?beta?, ?betazi?, ?betadisp?, ?theta?, etc.)"; in this
> >> case "etc." includes thetazi (random-effects parameters for ZI terms, if
> >> any) and thetadisp (ditto, dispersion terms).
> >>
> >>    The 'covstruct' vignette is the best place to read about
> >> parameterization of random-effects components.
> >>
> >> On 2024-10-28 1:05 p.m., Simon Harmel wrote:
> >>> Ben, when I run your code below, I get the following error message: y
> >>> values must be 0 <= y < 1. My glmmTMB version is: ?1.1.7?.
> >>>
> >>> Also, is there any good documentation explaining all possible names
> >>> used in argument `newparams=` in glmmTMB::new_simulate()?
> >>>
> >>> Thank you!
> >>> Simon
> >>>
> >>> On Thu, Oct 24, 2024 at 11:11?AM Ben Bolker <bbolker at gmail.com> wrote:
> >>>>
> >>>>      See below.  The two models (glmmTMB and brms) give sufficiently
> >>>> similar estimates that I'm confident that the specifications match.
> >>>>
> >>>> set.seed(101)
> >>>> library(glmmTMB)
> >>>> library(brms)
> >>>> library(broom.mixed)
> >>>> library(tidyverse)
> >>>>
> >>>> dd <- data.frame(ID = rep(1:100, each = 10),
> >>>>                     TRIAL_INDEX = rep(1:10, 100),
> >>>>                     con = rnorm(1000))
> >>>> dd$pic_percent <- simulate_new(
> >>>>        ~ con + (0+con | ID) +
> >>>>            (0+con | TRIAL_INDEX),
> >>>>        ziformula = ~1,
> >>>>        family = beta_family(),
> >>>>        newdata = dd,
> >>>>        newparams = list(beta = c(0, 0.5), theta = rep(-1,2),
> >>>>                         betadisp = 1, betazi = -2))[[1]]
> >>>>
> >>>>
> >>>> m1 <- glmmTMB(pic_percent ~ con + (0+con | ID) +
> >>>>        (0+con | TRIAL_INDEX),
> >>>>            data=dd,
> >>>>            family = beta_family(),
> >>>>            ziformula = ~1)
> >>>>
> >>>> ##
> >>>> https://mvuorre.github.io/posts/2019-02-18-analyze-analog-scale-ratings-with-zero-one-inflated-beta-models/
> >>>> m2 <- brm(
> >>>>        bf(pic_percent ~ con + (0+con | ID) +
> >>>>               (0+con | TRIAL_INDEX),
> >>>>        zi = ~ 1),
> >>>>        data=dd,
> >>>>        family = zero_inflated_beta()
> >>>> )
> >>>>
> >>>>
> >>>> (purrr::map_dfr(list(glmmTMB = m1, brms = m2), tidy, .id = "model")
> >>>>        |> select(model, effect, component, group, term, estimate)
> >>>>        |> pivot_wider(names_from = model, values_from = estimate)
> >>>> )
> >>>>
> >>>>
> >>>>
> >>>> On 10/23/24 19:13, Simon Harmel wrote:
> >>>>> Hello all,
> >>>>>
> >>>>> I was wondering what is the closest equivalent of my glmmTMB syntax below
> >>>>> in brms::brm() syntax?
> >>>>>
> >>>>> glmmTMBglmmTMB(pic_percent ~ con +
> >>>>>                          (0+con | ID) +
> >>>>>                          (0+con | TRIAL_INDEX),
> >>>>>                        data=DATA,
> >>>>>            family = beta_family(),
> >>>>>            ziformula = ~1)
> >>>>>
> >>>>>
> >>>>> Thank you,
> >>>>>
> >>>>> Simon
> >>>>>
> >>>>>         [[alternative HTML version deleted]]
> >>>>>
> >>>>> _______________________________________________
> >>>>> R-sig-mixed-models at r-project.org mailing list
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>
> >>>> --
> >>>> Dr. Benjamin Bolker
> >>>> Professor, Mathematics & Statistics and Biology, McMaster University
> >>>> Director, School of Computational Science and Engineering
> >>>> * E-mail is sent at my convenience; I don't expect replies outside of
> >>>> working hours.
> >>>>
> >>>> _______________________________________________
> >>>> R-sig-mixed-models at r-project.org mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >> --
> >> Dr. Benjamin Bolker
> >> Professor, Mathematics & Statistics and Biology, McMaster University
> >> Director, School of Computational Science and Engineering
> >>   > E-mail is sent at my convenience; I don't expect replies outside of
> >> working hours.
> >>
>
> --
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
>  > E-mail is sent at my convenience; I don't expect replies outside of
> working hours.
>


From bbo|ker @end|ng |rom gm@||@com  Tue Oct 29 00:52:02 2024
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 28 Oct 2024 19:52:02 -0400
Subject: [R-sig-ME] glmmTMB syntax to brm() syntax
In-Reply-To: <CACgv6yVX_0-_PbOsFN78bFrN2XuBYdwxMoFG-dgYKfHJ7pUYcQ@mail.gmail.com>
References: <CACgv6yVSpSufc8+H78T5qbnRwv3n-0ShErQkuo-MvqMKZjy59g@mail.gmail.com>
 <ddce0a67-33ba-4743-8c60-2a8883bde549@gmail.com>
 <CACgv6yXXC96zcJUeVs7wCmjmnANga1Hk572Jxkmt_LLwfmxL=A@mail.gmail.com>
 <1616e114-f867-46c8-b96f-21ec35315d9b@gmail.com>
 <CACgv6yWWgAPSYrFO-2hDYobJ5ai-NscnEz4QzwD5Zm6ksCJJuw@mail.gmail.com>
 <bb8ad692-8ce2-462b-88f4-355057deb482@gmail.com>
 <CACgv6yVX_0-_PbOsFN78bFrN2XuBYdwxMoFG-dgYKfHJ7pUYcQ@mail.gmail.com>
Message-ID: <9ce09c8e-155d-4035-8d1f-0f4a7503cee3@gmail.com>



On 2024-10-28 7:43 p.m., Simon Harmel wrote:
> All good now, I managed to get the 1.1.10 version installed. So, with
> large enough data (ex. below), I should be able to recover the
> parameters, right?
> 
> I ask because I can recover all parameters, but wonder how to
> determine if my model is recovering theta=-1?
> 
> 
> set.seed(101)
> dd <- data.frame(ID = rep(1:10000, each=2),
>                   con = rep(c("simple","complex"), 10000))
> 
> dd$VOCD <- simulate_new(
>    ~ 0+con + (1|ID),
>    dispformula = ~ 0+con,
>    newdata = dd,
>    newparams = list(beta = c(0, .5), theta = -1,
>                     betadisp = c(2,1.6)))[[1]]
> 
> 
> glmmTMB(VOCD ~ 0+con + (1|ID),
>          dispformula = ~ 0+con, data = dd)

  Saving that last model as g1,

log(sqrt(c(VarCorr(g1)$cond[[1]])))

or if you like tidyverse

library(tidyverse)

broom.mixed::tidy(g1, effects = "ran_pars")
    |> filter(term == "sd__(Intercept)")
    |> pull(estimate)
    |> log()

  These both give -1.155614, which seems reasonably close.

> 
> On Mon, Oct 28, 2024 at 1:33?PM Ben Bolker <bbolker at gmail.com> wrote:
>>
>>     You should be getting version 1.1.10 from CRAN, unless you're using
>> an outdated mirror, see
>> https://cran.r-project.org/web/packages/glmmTMB/index.html ... you will
>> need version 1.1.10 to avoid the error.
>>
>>      If you want a dispersion parameter of 1.0 then you probably want
>> betadisp = 0 (since the dispersion model uses a log link).
>>
>>     You also need to provide only a vector of length 1 for theta, since
>> you only have a single (scalar) random effect term.  And you need to
>> provide two values for betadisp (since you are specifying ~con, and con
>> is a two-level factor), i.e.
>>
>>    dd$VOCD <- simulate_new(
>>      ~ 0+con + (1|ID),
>>      dispformula = ~ con,
>>      newdata = dd,
>>      newparams = list(beta = c(0, 0.5), theta = -1,
>>                       betadisp = rep(0,2)))[[1]]
>>
>>
>>
>> On 2024-10-28 1:39 p.m., Simon Harmel wrote:
>>> Thank you, Ben. I deleted and installed glmmTMB from CRAN and it is
>>> still version 1.1.9 on my machine with that same error showing up.
>>>
>>> I love the 'covstruct' vignette. But I, for example, don't know what
>>> to use in my simulate_new() call below to define the dispersion,
>>> would that be 'sigmadisp'?
>>>
>>> dd <- data.frame(ID = rep(1:100, each = 2),
>>>                    con = rep(c("simple","complex"), 100)) %>%
>>>     group_by(ID) %>% mutate(obs=row_number())
>>>
>>> dd$VOCD <- simulate_new(
>>>     ~ 0+con + (1|ID),
>>>     dispformula = ~ con,
>>>     newdata = dd,
>>>     newparams = list(beta = c(0, 0.5), theta = rep(-1,2),
>>>                      disp = 1))[[1]]
>>>
>>> On Mon, Oct 28, 2024 at 12:10?PM Ben Bolker <bbolker at gmail.com> wrote:
>>>>
>>>>       That's quite old, by R standards (1.1.8 came out a year ago, latest
>>>> version is 1.1.10 -- there's a note in the NEWS for 1.1.10
>>>> <https://cran.r-project.org/web/packages/glmmTMB/news.html> about fixing
>>>> a simulate bug for the beta family
>>>>
>>>>      (It's simulate_new(), not new_simulate())
>>>>
>>>>      The docs say "(?beta?, ?betazi?, ?betadisp?, ?theta?, etc.)"; in this
>>>> case "etc." includes thetazi (random-effects parameters for ZI terms, if
>>>> any) and thetadisp (ditto, dispersion terms).
>>>>
>>>>     The 'covstruct' vignette is the best place to read about
>>>> parameterization of random-effects components.
>>>>
>>>> On 2024-10-28 1:05 p.m., Simon Harmel wrote:
>>>>> Ben, when I run your code below, I get the following error message: y
>>>>> values must be 0 <= y < 1. My glmmTMB version is: ?1.1.7?.
>>>>>
>>>>> Also, is there any good documentation explaining all possible names
>>>>> used in argument `newparams=` in glmmTMB::new_simulate()?
>>>>>
>>>>> Thank you!
>>>>> Simon
>>>>>
>>>>> On Thu, Oct 24, 2024 at 11:11?AM Ben Bolker <bbolker at gmail.com> wrote:
>>>>>>
>>>>>>       See below.  The two models (glmmTMB and brms) give sufficiently
>>>>>> similar estimates that I'm confident that the specifications match.
>>>>>>
>>>>>> set.seed(101)
>>>>>> library(glmmTMB)
>>>>>> library(brms)
>>>>>> library(broom.mixed)
>>>>>> library(tidyverse)
>>>>>>
>>>>>> dd <- data.frame(ID = rep(1:100, each = 10),
>>>>>>                      TRIAL_INDEX = rep(1:10, 100),
>>>>>>                      con = rnorm(1000))
>>>>>> dd$pic_percent <- simulate_new(
>>>>>>         ~ con + (0+con | ID) +
>>>>>>             (0+con | TRIAL_INDEX),
>>>>>>         ziformula = ~1,
>>>>>>         family = beta_family(),
>>>>>>         newdata = dd,
>>>>>>         newparams = list(beta = c(0, 0.5), theta = rep(-1,2),
>>>>>>                          betadisp = 1, betazi = -2))[[1]]
>>>>>>
>>>>>>
>>>>>> m1 <- glmmTMB(pic_percent ~ con + (0+con | ID) +
>>>>>>         (0+con | TRIAL_INDEX),
>>>>>>             data=dd,
>>>>>>             family = beta_family(),
>>>>>>             ziformula = ~1)
>>>>>>
>>>>>> ##
>>>>>> https://mvuorre.github.io/posts/2019-02-18-analyze-analog-scale-ratings-with-zero-one-inflated-beta-models/
>>>>>> m2 <- brm(
>>>>>>         bf(pic_percent ~ con + (0+con | ID) +
>>>>>>                (0+con | TRIAL_INDEX),
>>>>>>         zi = ~ 1),
>>>>>>         data=dd,
>>>>>>         family = zero_inflated_beta()
>>>>>> )
>>>>>>
>>>>>>
>>>>>> (purrr::map_dfr(list(glmmTMB = m1, brms = m2), tidy, .id = "model")
>>>>>>         |> select(model, effect, component, group, term, estimate)
>>>>>>         |> pivot_wider(names_from = model, values_from = estimate)
>>>>>> )
>>>>>>
>>>>>>
>>>>>>
>>>>>> On 10/23/24 19:13, Simon Harmel wrote:
>>>>>>> Hello all,
>>>>>>>
>>>>>>> I was wondering what is the closest equivalent of my glmmTMB syntax below
>>>>>>> in brms::brm() syntax?
>>>>>>>
>>>>>>> glmmTMBglmmTMB(pic_percent ~ con +
>>>>>>>                           (0+con | ID) +
>>>>>>>                           (0+con | TRIAL_INDEX),
>>>>>>>                         data=DATA,
>>>>>>>             family = beta_family(),
>>>>>>>             ziformula = ~1)
>>>>>>>
>>>>>>>
>>>>>>> Thank you,
>>>>>>>
>>>>>>> Simon
>>>>>>>
>>>>>>>          [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> _______________________________________________
>>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>
>>>>>> --
>>>>>> Dr. Benjamin Bolker
>>>>>> Professor, Mathematics & Statistics and Biology, McMaster University
>>>>>> Director, School of Computational Science and Engineering
>>>>>> * E-mail is sent at my convenience; I don't expect replies outside of
>>>>>> working hours.
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>> --
>>>> Dr. Benjamin Bolker
>>>> Professor, Mathematics & Statistics and Biology, McMaster University
>>>> Director, School of Computational Science and Engineering
>>>>    > E-mail is sent at my convenience; I don't expect replies outside of
>>>> working hours.
>>>>
>>
>> --
>> Dr. Benjamin Bolker
>> Professor, Mathematics & Statistics and Biology, McMaster University
>> Director, School of Computational Science and Engineering
>>   > E-mail is sent at my convenience; I don't expect replies outside of
>> working hours.
>>

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
 > E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From @|ngm@nn @end|ng |rom gm@||@com  Tue Oct 29 11:48:19 2024
From: @|ngm@nn @end|ng |rom gm@||@com (Henrik Singmann)
Date: Tue, 29 Oct 2024 10:48:19 +0000
Subject: [R-sig-ME] glmmTMB output for t-family
Message-ID: <CA+rDMKJm-T8RL+nHAeJdGA4P-xuZByH-GjysH=tzJVrPHoeKRg@mail.gmail.com>

Hi all,

It seems to me as if the estimate for the df of the t-family in glmmTMB are
somewhat hidden from the user. In particular, the only way I have found to
get to it is via exp(model$fit$par["psi"])

So my question is just if I am missing something obvious here.

To give some background, I am trying to fit some data that looks pretty
leptokurtic so t-distribution  seems appropriate which is luckily available
in glmmTMB. To get going with it, I first wanted to see whether I can
actually recover the df, which seems to work reasonably well for large N,
see code below.

Best,
Henrik

#### Simulation code (somewhat long) follows ###
library("mvtnorm")
library("extraDistr")
library("glmmTMB")

# Sample size
nsubjects <- 100
replicates_cell <- 20

# Fixed effects
ifixed <- 0.5 # intercept
sfixed1 <- 0.5 # slope

# Subject random effects
is <- 0.5 # sd intercept
ss <- 0.5 # sd slope

# Correlations
rs.is <- 0.5 # intercept and slope

# Residual
sigma <- 1.5
phi <- 3.4

set.seed(56771234)
cov.is <- rs.is*is*ss
cov.subjects <- matrix(c(is^2, cov.is, cov.is, ss^2),
                       nrow=2, byrow=TRUE)
# Random sample from bivariate normal, for each subject
re.subjects <- data.frame(cbind(1:nsubjects,
                                rmvnorm(nsubjects, mean=c(rep(0, 2)),
                                        sigma=cov.subjects)))
colnames(re.subjects) <- c("Subject", "IntSubject", "SlopeSubject")
# Observations
df <- expand.grid(unique(re.subjects$Subject), seq(replicates_cell),
                  c("A", "B"))
colnames(df) <- c("Subject", "Item", "Condition")
# Numerical coding (treatment contrasts)
df$Condition.num <- ifelse(df$Condition=="A", 0, 1)
# Fixed effects and sigma
df$Intercept <- ifixed
df$Slope <- sfixed1
df$Error <- rlst(nrow(df), phi, 0, sigma)
# Merge random effects
df <- merge(df, re.subjects)
# Response variable
df$Y <- with(df, (Intercept + IntSubject) + (Slope + SlopeSubject) *
Condition.num + Error)

m1 <- glmmTMB(Y ~ Condition.num + (1+Condition.num|Subject), df,
              family = t_family())
summary(m1)
sigma(m1) ## 1.558537
exp(m1$fit$par["psi"]) ## 3.633625

#### Simulation code end ###

-- 
Dr. Henrik Singmann
Associate Professor, Experimental Psychology
University College London (UCL), UK
http://singmann.org

	[[alternative HTML version deleted]]


From mo|||eebrook@ @end|ng |rom gm@||@com  Tue Oct 29 14:13:12 2024
From: mo|||eebrook@ @end|ng |rom gm@||@com (Mollie Brooks)
Date: Tue, 29 Oct 2024 14:13:12 +0100
Subject: [R-sig-ME] glmmTMB output for t-family
In-Reply-To: <CA+rDMKJm-T8RL+nHAeJdGA4P-xuZByH-GjysH=tzJVrPHoeKRg@mail.gmail.com>
References: <CA+rDMKJm-T8RL+nHAeJdGA4P-xuZByH-GjysH=tzJVrPHoeKRg@mail.gmail.com>
Message-ID: <B775C88B-A89A-492F-8CF6-CB5732104CBF@gmail.com>

Hi Henrik,

Thanks for the reproducible example and clear question. The function family_params(m1) will give you

> family_params(m1)
Student-t df 
    3.633625 

cheers,
Mollie

> On 29 Oct 2024, at 11.48, Henrik Singmann <singmann at gmail.com> wrote:
> 
> Hi all,
> 
> It seems to me as if the estimate for the df of the t-family in glmmTMB are
> somewhat hidden from the user. In particular, the only way I have found to
> get to it is via exp(model$fit$par["psi"])
> 
> So my question is just if I am missing something obvious here.
> 
> To give some background, I am trying to fit some data that looks pretty
> leptokurtic so t-distribution  seems appropriate which is luckily available
> in glmmTMB. To get going with it, I first wanted to see whether I can
> actually recover the df, which seems to work reasonably well for large N,
> see code below.
> 
> Best,
> Henrik
> 
> #### Simulation code (somewhat long) follows ###
> library("mvtnorm")
> library("extraDistr")
> library("glmmTMB")
> 
> # Sample size
> nsubjects <- 100
> replicates_cell <- 20
> 
> # Fixed effects
> ifixed <- 0.5 # intercept
> sfixed1 <- 0.5 # slope
> 
> # Subject random effects
> is <- 0.5 # sd intercept
> ss <- 0.5 # sd slope
> 
> # Correlations
> rs.is <- 0.5 # intercept and slope
> 
> # Residual
> sigma <- 1.5
> phi <- 3.4
> 
> set.seed(56771234)
> cov.is <- rs.is*is*ss
> cov.subjects <- matrix(c(is^2, cov.is, cov.is, ss^2),
>                       nrow=2, byrow=TRUE)
> # Random sample from bivariate normal, for each subject
> re.subjects <- data.frame(cbind(1:nsubjects,
>                                rmvnorm(nsubjects, mean=c(rep(0, 2)),
>                                        sigma=cov.subjects)))
> colnames(re.subjects) <- c("Subject", "IntSubject", "SlopeSubject")
> # Observations
> df <- expand.grid(unique(re.subjects$Subject), seq(replicates_cell),
>                  c("A", "B"))
> colnames(df) <- c("Subject", "Item", "Condition")
> # Numerical coding (treatment contrasts)
> df$Condition.num <- ifelse(df$Condition=="A", 0, 1)
> # Fixed effects and sigma
> df$Intercept <- ifixed
> df$Slope <- sfixed1
> df$Error <- rlst(nrow(df), phi, 0, sigma)
> # Merge random effects
> df <- merge(df, re.subjects)
> # Response variable
> df$Y <- with(df, (Intercept + IntSubject) + (Slope + SlopeSubject) *
> Condition.num + Error)
> 
> m1 <- glmmTMB(Y ~ Condition.num + (1+Condition.num|Subject), df,
>              family = t_family())
> summary(m1)
> sigma(m1) ## 1.558537
> exp(m1$fit$par["psi"]) ## 3.633625
> 
> #### Simulation code end ###
> 
> -- 
> Dr. Henrik Singmann
> Associate Professor, Experimental Psychology
> University College London (UCL), UK
> http://singmann.org
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From @|ngm@nn @end|ng |rom gm@||@com  Tue Oct 29 15:18:14 2024
From: @|ngm@nn @end|ng |rom gm@||@com (Henrik Singmann)
Date: Tue, 29 Oct 2024 14:18:14 +0000
Subject: [R-sig-ME] glmmTMB output for t-family
In-Reply-To: <B775C88B-A89A-492F-8CF6-CB5732104CBF@gmail.com>
References: <CA+rDMKJm-T8RL+nHAeJdGA4P-xuZByH-GjysH=tzJVrPHoeKRg@mail.gmail.com>
 <B775C88B-A89A-492F-8CF6-CB5732104CBF@gmail.com>
Message-ID: <CA+rDMKLfOAoz0wAyb01CsxcADVc6_LfuJt=rOw3f6pasiNvAHg@mail.gmail.com>

Thanks Mollie, exactly what I was looking for!

Am Di., 29. Okt. 2024 um 13:13 Uhr schrieb Mollie Brooks <
mollieebrooks at gmail.com>:

> Hi Henrik,
>
> Thanks for the reproducible example and clear question. The function
> family_params(m1) will give you
>
> > family_params(m1)
> Student-t df
>     3.633625
>
> cheers,
> Mollie
>
> > On 29 Oct 2024, at 11.48, Henrik Singmann <singmann at gmail.com> wrote:
> >
> > Hi all,
> >
> > It seems to me as if the estimate for the df of the t-family in glmmTMB
> are
> > somewhat hidden from the user. In particular, the only way I have found
> to
> > get to it is via exp(model$fit$par["psi"])
> >
> > So my question is just if I am missing something obvious here.
> >
> > To give some background, I am trying to fit some data that looks pretty
> > leptokurtic so t-distribution  seems appropriate which is luckily
> available
> > in glmmTMB. To get going with it, I first wanted to see whether I can
> > actually recover the df, which seems to work reasonably well for large N,
> > see code below.
> >
> > Best,
> > Henrik
> >
> > #### Simulation code (somewhat long) follows ###
> > library("mvtnorm")
> > library("extraDistr")
> > library("glmmTMB")
> >
> > # Sample size
> > nsubjects <- 100
> > replicates_cell <- 20
> >
> > # Fixed effects
> > ifixed <- 0.5 # intercept
> > sfixed1 <- 0.5 # slope
> >
> > # Subject random effects
> > is <- 0.5 # sd intercept
> > ss <- 0.5 # sd slope
> >
> > # Correlations
> > rs.is <- 0.5 # intercept and slope
> >
> > # Residual
> > sigma <- 1.5
> > phi <- 3.4
> >
> > set.seed(56771234)
> > cov.is <- rs.is*is*ss
> > cov.subjects <- matrix(c(is^2, cov.is, cov.is, ss^2),
> >                       nrow=2, byrow=TRUE)
> > # Random sample from bivariate normal, for each subject
> > re.subjects <- data.frame(cbind(1:nsubjects,
> >                                rmvnorm(nsubjects, mean=c(rep(0, 2)),
> >                                        sigma=cov.subjects)))
> > colnames(re.subjects) <- c("Subject", "IntSubject", "SlopeSubject")
> > # Observations
> > df <- expand.grid(unique(re.subjects$Subject), seq(replicates_cell),
> >                  c("A", "B"))
> > colnames(df) <- c("Subject", "Item", "Condition")
> > # Numerical coding (treatment contrasts)
> > df$Condition.num <- ifelse(df$Condition=="A", 0, 1)
> > # Fixed effects and sigma
> > df$Intercept <- ifixed
> > df$Slope <- sfixed1
> > df$Error <- rlst(nrow(df), phi, 0, sigma)
> > # Merge random effects
> > df <- merge(df, re.subjects)
> > # Response variable
> > df$Y <- with(df, (Intercept + IntSubject) + (Slope + SlopeSubject) *
> > Condition.num + Error)
> >
> > m1 <- glmmTMB(Y ~ Condition.num + (1+Condition.num|Subject), df,
> >              family = t_family())
> > summary(m1)
> > sigma(m1) ## 1.558537
> > exp(m1$fit$par["psi"]) ## 3.633625
> >
> > #### Simulation code end ###
> >
> > --
> > Dr. Henrik Singmann
> > Associate Professor, Experimental Psychology
> > University College London (UCL), UK
> > http://singmann.org
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

-- 
Dr. Henrik Singmann
Associate Professor, Experimental Psychology
University College London (UCL), UK
http://singmann.org

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Tue Oct 29 15:29:33 2024
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 29 Oct 2024 10:29:33 -0400
Subject: [R-sig-ME] glmmTMB output for t-family
In-Reply-To: <CA+rDMKLfOAoz0wAyb01CsxcADVc6_LfuJt=rOw3f6pasiNvAHg@mail.gmail.com>
References: <CA+rDMKJm-T8RL+nHAeJdGA4P-xuZByH-GjysH=tzJVrPHoeKRg@mail.gmail.com>
 <B775C88B-A89A-492F-8CF6-CB5732104CBF@gmail.com>
 <CA+rDMKLfOAoz0wAyb01CsxcADVc6_LfuJt=rOw3f6pasiNvAHg@mail.gmail.com>
Message-ID: <43266d3f-93f9-4a53-a0d5-73be54f8f9c4@gmail.com>

   I agree that this ought to be more visible: I note that it's included 
in the print method [print(m1)] but should be included in the summary 
output as well.

   As far as making family_params() more visible, maybe we could link to 
it from ?glmmTMB and ?sigma.glmmTMB ...


On 10/29/24 10:18, Henrik Singmann wrote:
> Thanks Mollie, exactly what I was looking for!
> 
> Am Di., 29. Okt. 2024 um 13:13 Uhr schrieb Mollie Brooks <
> mollieebrooks at gmail.com>:
> 
>> Hi Henrik,
>>
>> Thanks for the reproducible example and clear question. The function
>> family_params(m1) will give you
>>
>>> family_params(m1)
>> Student-t df
>>      3.633625
>>
>> cheers,
>> Mollie
>>
>>> On 29 Oct 2024, at 11.48, Henrik Singmann <singmann at gmail.com> wrote:
>>>
>>> Hi all,
>>>
>>> It seems to me as if the estimate for the df of the t-family in glmmTMB
>> are
>>> somewhat hidden from the user. In particular, the only way I have found
>> to
>>> get to it is via exp(model$fit$par["psi"])
>>>
>>> So my question is just if I am missing something obvious here.
>>>
>>> To give some background, I am trying to fit some data that looks pretty
>>> leptokurtic so t-distribution  seems appropriate which is luckily
>> available
>>> in glmmTMB. To get going with it, I first wanted to see whether I can
>>> actually recover the df, which seems to work reasonably well for large N,
>>> see code below.
>>>
>>> Best,
>>> Henrik
>>>
>>> #### Simulation code (somewhat long) follows ###
>>> library("mvtnorm")
>>> library("extraDistr")
>>> library("glmmTMB")
>>>
>>> # Sample size
>>> nsubjects <- 100
>>> replicates_cell <- 20
>>>
>>> # Fixed effects
>>> ifixed <- 0.5 # intercept
>>> sfixed1 <- 0.5 # slope
>>>
>>> # Subject random effects
>>> is <- 0.5 # sd intercept
>>> ss <- 0.5 # sd slope
>>>
>>> # Correlations
>>> rs.is <- 0.5 # intercept and slope
>>>
>>> # Residual
>>> sigma <- 1.5
>>> phi <- 3.4
>>>
>>> set.seed(56771234)
>>> cov.is <- rs.is*is*ss
>>> cov.subjects <- matrix(c(is^2, cov.is, cov.is, ss^2),
>>>                        nrow=2, byrow=TRUE)
>>> # Random sample from bivariate normal, for each subject
>>> re.subjects <- data.frame(cbind(1:nsubjects,
>>>                                 rmvnorm(nsubjects, mean=c(rep(0, 2)),
>>>                                         sigma=cov.subjects)))
>>> colnames(re.subjects) <- c("Subject", "IntSubject", "SlopeSubject")
>>> # Observations
>>> df <- expand.grid(unique(re.subjects$Subject), seq(replicates_cell),
>>>                   c("A", "B"))
>>> colnames(df) <- c("Subject", "Item", "Condition")
>>> # Numerical coding (treatment contrasts)
>>> df$Condition.num <- ifelse(df$Condition=="A", 0, 1)
>>> # Fixed effects and sigma
>>> df$Intercept <- ifixed
>>> df$Slope <- sfixed1
>>> df$Error <- rlst(nrow(df), phi, 0, sigma)
>>> # Merge random effects
>>> df <- merge(df, re.subjects)
>>> # Response variable
>>> df$Y <- with(df, (Intercept + IntSubject) + (Slope + SlopeSubject) *
>>> Condition.num + Error)
>>>
>>> m1 <- glmmTMB(Y ~ Condition.num + (1+Condition.num|Subject), df,
>>>               family = t_family())
>>> summary(m1)
>>> sigma(m1) ## 1.558537
>>> exp(m1$fit$par["psi"]) ## 3.633625
>>>
>>> #### Simulation code end ###
>>>
>>> --
>>> Dr. Henrik Singmann
>>> Associate Professor, Experimental Psychology
>>> University College London (UCL), UK
>>> http://singmann.org
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
* E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From L|eke@Moeree|@ @end|ng |rom UGent@be  Wed Nov 13 13:58:13 2024
From: L|eke@Moeree|@ @end|ng |rom UGent@be (Lieke Moereels)
Date: Wed, 13 Nov 2024 12:58:13 +0000
Subject: [R-sig-ME] bootstrap confidence interval and p-value for treatment
 vs control comparisons
Message-ID: <AS8PR09MB4950512B63460A1DF4E5D425F45A2@AS8PR09MB4950.eurprd09.prod.outlook.com>

Dear all
I hope you?re doing well. I posted a similar question earlier but didn?t get a reply and because I?m under a bit of pressure to advance on this matter, I hope it?s fine I ask this modified, shorter question on the same topic.
If I have a simple GLMM specified as: diversity ~ land use type + (1|location) where land use type has 4 levels (let?s say 1 control and 3 treatments) and location at least 8.
How could I obtain parametric bootstrap confidence intervals and associated p-values for the difference in mean diversity between each of the treatments and the control, that are corrected for these multiple comparisons by a Dunnett correction?
(So I'm basically looking for a parametric bootstrapping alternative to emmeans' "confint(contrast(emmeans(fitted_model, ~ landuse), "trt.vs.ctrl", ref = 1))")

Any help would be greatly appreciated!

Have a very nice day!
Lieke

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Wed Nov 13 16:21:29 2024
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 13 Nov 2024 10:21:29 -0500
Subject: [R-sig-ME] 
 bootstrap confidence interval and p-value for treatment
 vs control comparisons
In-Reply-To: <AS8PR09MB4950512B63460A1DF4E5D425F45A2@AS8PR09MB4950.eurprd09.prod.outlook.com>
References: <AS8PR09MB4950512B63460A1DF4E5D425F45A2@AS8PR09MB4950.eurprd09.prod.outlook.com>
Message-ID: <64736a29-1ae5-4aa2-aeed-fbe03906ec3e@gmail.com>

   I think the "trt.vs.ctrl" part will be relatively easy, because this 
is what you get from the default treatment contrasts in R anyway (that 
is, if `landuse` is a factor, then the beta (fixed-effect) parameters 
corresponding to `landuse` will be equal to the contrasts between each 
level of landuse and the reference level.

   So

bb <- bootMer(fitted_model,
    FUN = function(x) {
       ff <- fixef(f)
       ff[startsWith(names(ff), "landuse")]
    },
    nsim = 1000  ## or whatever
}

and confint(bb) will give you the confidence intervals.
bb$t will give you the ensemble of bootstrap values

You could get the two-tailed p-values something like this:

boot_pval <- function(x) { 2*min(mean(x<0), mean(x>0)) }
apply(bb$t, 2, boot_pval)

   However, I think a Dunnett adjustment will be harder.  Based on this 
<https://stats.stackexchange.com/questions/631129/multicomp-package-and-emmeans-package-produce-different-adjust-pvalues-for-dunne>, 
the Dunnett adjustment relies the t distribution (or multivariate t). In 
particular, if you look at 
<https://en.wikipedia.org/wiki/Dunnett%27s_test>, you can see that step 
5 includes knowing the residual degrees of freedom, which are hard to 
define for (G)LMMs ...

   You could choose one of the other methods implemented in base R's 
p.adjust() ...

   If you do want to apply Dunnett's correction on bootstrap replicates, 
you might need to ask on Cross Validated 
(https://stats.stackexchange.com), although I don't know if you'll get a 
satisfactory answer there either ...

   good luck,
    Ben Bolker


On 11/13/24 07:58, Lieke Moereels via R-sig-mixed-models wrote:
> Dear all
> I hope you?re doing well. I posted a similar question earlier but didn?t get a reply and because I?m under a bit of pressure to advance on this matter, I hope it?s fine I ask this modified, shorter question on the same topic.
> If I have a simple GLMM specified as: diversity ~ land use type + (1|location) where land use type has 4 levels (let?s say 1 control and 3 treatments) and location at least 8.
> How could I obtain parametric bootstrap confidence intervals and associated p-values for the difference in mean diversity between each of the treatments and the control, that are corrected for these multiple comparisons by a Dunnett correction?
> (So I'm basically looking for a parametric bootstrapping alternative to emmeans' "confint(contrast(emmeans(fitted_model, ~ landuse), "trt.vs.ctrl", ref = 1))")
> 
> Any help would be greatly appreciated!
> 
> Have a very nice day!
> Lieke
> 
> 	[[alternative HTML version deleted]]
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
* E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From L|eke@Moeree|@ @end|ng |rom UGent@be  Thu Nov 14 22:28:46 2024
From: L|eke@Moeree|@ @end|ng |rom UGent@be (Lieke Moereels)
Date: Thu, 14 Nov 2024 21:28:46 +0000
Subject: [R-sig-ME] 
 bootstrap confidence interval and p-value for treatment
 vs control comparisons
In-Reply-To: <64736a29-1ae5-4aa2-aeed-fbe03906ec3e@gmail.com>
References: <AS8PR09MB4950512B63460A1DF4E5D425F45A2@AS8PR09MB4950.eurprd09.prod.outlook.com>
 <64736a29-1ae5-4aa2-aeed-fbe03906ec3e@gmail.com>
Message-ID: <AS8PR09MB495067328CC5EB17D6C3A29FF45B2@AS8PR09MB4950.eurprd09.prod.outlook.com>

Dear Ben, all

Something went wrong when I replied to Ben's answer, so I am hereby reposting our two last mails that weren't sent to the entire mailing list along with (below) my new reply.
My apologies for this messy approach, I don't know how else to remedy this. Sorry!


My newest reply:
Dear Ben

Alright, thank you very much for sharing your opinion!
I agree that 88 observations is an unfortunate low number...
We have exactly 4 land use types.

Thank you again!

All the best
Lieke

Ben wrote:
> I would probably choose option 1.  With only 88 observations, I
> would take *any* conclusions with a big grain of salt (how many land use
> types do you have?); according to Frank Harrell's rules of thumb, you
> can't even do a reasonable job estimating parameters if you have more
> than about 4 land use types (which would be few enough that I wouldn't
> bother with multiple comparisons corrections anyway).
>
>    Or I might just show everything unadjusted and take the whole thing
> with a slightly bigger grain of salt ...
>
>   While I wouldn't disagree with someone who figured out how to do both
> MC-adjusted p-values and CIs (using some defensible approach), it also
> wouldn't bother me very much if unadjusted results were presented.
>
>   How many land use types *do* you have?
>
>   cheers
>    Ben Bolker


On 11/14/24 12:54, Lieke Moereels wrote:
> Dear Ben
>
> Thank you very much for your quick reply and your help!
> I really appreciate it a lot.
>
> I see, I didn't think of this issue with the Dunnett adjustment's use
> of the residual degrees of freedom. Thank you for pointing that out!
>
> I thought I'd best adjust the confidence intervals for the multiple
> comparisons as well, and not just the p-values (in this case
> afterwards), but perhaps you wouldn't think so?
> It seems like there is still some discussion on these multiplicity
> adjusted CIs, but it does seem a bit odd to report adjusted p-values but
> unadjusted CIs?
>
> This idea was among others discussed here: Benjamini, Y., and D.
> Yekutieli. ?False Discovery Rate-Adjusted Multiple Confidence Intervals
> for Selected Parameters <https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.tandfonline.com%2Fdoi%2F&data=05%7C02%7CLieke.Moereels%40UGent.be%7Cb29f47a11366421b25a708dd04e2c8eb%7Cd7811cdeecef496c8f91a1786241b99c%7C1%7C0%7C638672094274001449%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&sdata=0Lly7dHi0RV%2FLZzbPA7gV8y4R3yA%2B2pxVHWrv%2F2m%2BUI%3D&reserved=0
> pdf/10.1198/016214504000001907>.? /Journal of the American Statistical
> Association/ 100, no. 469 (2005): 71?81.
> However, if using their approach to control the False Coverage Rate, I
> would in practice not perform any adjustment I believe, since I am in
> fact reporting the CIs of all 4 parameter estimates (intercept and 3
> beta-parameters), not just selecting some of them.
>
> Unfortunately, there seem to not be many options to adjust constructed
> CIs for multiplicity, besides using Bonferroni or Sidak adjustments that
> will probably be considered too conservative or the Dunnett adjustment
> that wouldn't be an option here because of what you pointed out. (I
> would of course use the same adjustment method for the p-values and the
> confidence intervals.)
>
> I'm sorry if this is bothersome, but if I could just ask this, I would
> be really happy to hear what (if hopefully any) you yourself  would
> consider the most appropriate approach out of the following options (in
> my case of a sample size of at least 88 observations and the model Y ~
> landuse + (1|location)):
>
>  1.
>     report Holm-adjusted p-values obtained from parametric bootstrap CIs
>     together with these unadjusted bootstrap CIs
>  2.
>     report Sidak- or Bonferroni-adjusted p-values obtained from
>     parametric bootstrap CIs together with the corresponding Sidak- or
>     Bonferroni-adjusted bootstrap CIs
>  3.
>     report Dunnett-like-adjusted p-values obtained from Wald tests
>     together with the corresponding multiplicity corrected Wald tests
>     (emmeans-approach; Wald-intervals not much more narrow than
>     bootstrap intervals in most cases)
>
> Thank you again a lot, apologies for all the questions and have a great
> autumn day
> Lieke

________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Ben Bolker <bbolker at gmail.com>
Sent: Wednesday, November 13, 2024 4:21 PM
To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] bootstrap confidence interval and p-value for treatment vs control comparisons

   I think the "trt.vs.ctrl" part will be relatively easy, because this
is what you get from the default treatment contrasts in R anyway (that
is, if `landuse` is a factor, then the beta (fixed-effect) parameters
corresponding to `landuse` will be equal to the contrasts between each
level of landuse and the reference level.

   So

bb <- bootMer(fitted_model,
    FUN = function(x) {
       ff <- fixef(f)
       ff[startsWith(names(ff), "landuse")]
    },
    nsim = 1000  ## or whatever
}

and confint(bb) will give you the confidence intervals.
bb$t will give you the ensemble of bootstrap values

You could get the two-tailed p-values something like this:

boot_pval <- function(x) { 2*min(mean(x<0), mean(x>0)) }
apply(bb$t, 2, boot_pval)

   However, I think a Dunnett adjustment will be harder.  Based on this
<https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstats.stackexchange.com%2Fquestions%2F631129%2Fmulticomp-package-and-emmeans-package-produce-different-adjust-pvalues-for-dunne&data=05%7C02%7CLieke.Moereels%40UGent.be%7Ca41701cf99c54430abf308dd03f6e5f0%7Cd7811cdeecef496c8f91a1786241b99c%7C1%7C0%7C638671081155038608%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&sdata=ydOeNey4swzgaO0feSYadgXZD4S6oMRtVAIC1jHXlNw%3D&reserved=0<https://stats.stackexchange.com/questions/631129/multicomp-package-and-emmeans-package-produce-different-adjust-pvalues-for-dunne>>,
the Dunnett adjustment relies the t distribution (or multivariate t). In
particular, if you look at
<https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FDunnett%2527s_test&data=05%7C02%7CLieke.Moereels%40UGent.be%7Ca41701cf99c54430abf308dd03f6e5f0%7Cd7811cdeecef496c8f91a1786241b99c%7C1%7C0%7C638671081155061334%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&sdata=dlNvVEJ5rakYyhjZ0IhN9ZoCZwfeal52eF%2FtWv8%2BsRU%3D&reserved=0<https://en.wikipedia.org/wiki/Dunnett%27s_test>>, you can see that step
5 includes knowing the residual degrees of freedom, which are hard to
define for (G)LMMs ...

   You could choose one of the other methods implemented in base R's
p.adjust() ...

   If you do want to apply Dunnett's correction on bootstrap replicates,
you might need to ask on Cross Validated
(https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstats.stackexchange.com%2F&data=05%7C02%7CLieke.Moereels%40UGent.be%7Ca41701cf99c54430abf308dd03f6e5f0%7Cd7811cdeecef496c8f91a1786241b99c%7C1%7C0%7C638671081155076909%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&sdata=Id6%2BDKtfLna1iUqjZkf5roWZ8uFTc%2FQKO9u%2F4sd62wo%3D&reserved=0<https://stats.stackexchange.com/>), although I don't know if you'll get a
satisfactory answer there either ...

   good luck,
    Ben Bolker


On 11/13/24 07:58, Lieke Moereels via R-sig-mixed-models wrote:
> Dear all
> I hope you?re doing well. I posted a similar question earlier but didn?t get a reply and because I?m under a bit of pressure to advance on this matter, I hope it?s fine I ask this modified, shorter question on the same topic.
> If I have a simple GLMM specified as: diversity ~ land use type + (1|location) where land use type has 4 levels (let?s say 1 control and 3 treatments) and location at least 8.
> How could I obtain parametric bootstrap confidence intervals and associated p-values for the difference in mean diversity between each of the treatments and the control, that are corrected for these multiple comparisons by a Dunnett correction?
> (So I'm basically looking for a parametric bootstrapping alternative to emmeans' "confint(contrast(emmeans(fitted_model, ~ landuse), "trt.vs.ctrl", ref = 1))")
>
> Any help would be greatly appreciated!
>
> Have a very nice day!
> Lieke
>
>        [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&data=05%7C02%7CLieke.Moereels%40UGent.be%7Ca41701cf99c54430abf308dd03f6e5f0%7Cd7811cdeecef496c8f91a1786241b99c%7C1%7C0%7C638671081155092051%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&sdata=9a5Zr2kHSV8wFr6ZHUSat52HOKm%2FyoRvQP48d3BIwMk%3D&reserved=0<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>

--
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
* E-mail is sent at my convenience; I don't expect replies outside of
working hours.

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&data=05%7C02%7CLieke.Moereels%40UGent.be%7Ca41701cf99c54430abf308dd03f6e5f0%7Cd7811cdeecef496c8f91a1786241b99c%7C1%7C0%7C638671081155107178%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&sdata=ys9GuIEtxEM6RYJVrqsfaXw7y%2FE%2FfUq7iqGWBa%2BVQg4%3D&reserved=0<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>

	[[alternative HTML version deleted]]


From h|gh@t@t @end|ng |rom h|gh@t@t@com  Mon Nov 18 11:32:45 2024
From: h|gh@t@t @end|ng |rom h|gh@t@t@com (Alain Zuur)
Date: Mon, 18 Nov 2024 10:32:45 +0000
Subject: [R-sig-ME] Introduction to GLLVM and multivariate GLMM
Message-ID: <943661fa-ebb9-4867-8365-886b8a5ee945@highstat.com>

We would like to announce the following online statistics course:

Online course: Introduction to GLLVM and multivariate GLMM
When: *2 - 5 December, 09.00-16.00 UK*?time OR *9 - 12 December, 
15.00-21.00 UK time (10.00-16.00 EST) *
Website: https://www.highstat.com/


The central theme of this course is the analysis of multiple correlated 
response (or dependent) variables using GLMs and GLMMs. Rather
than applying multiple univariate GLMs or GLMMs, we will focus on 
multivariate GLMMs, particularly generalised linear latent variable
models (GLLVMs), for the simultaneous analysis of all variables.

During the course, we cover a large number of exercises with examples 
such as trait variables from turtle hatchlings from multiple clutches,
biomass data from fish species sampled at multiple sites, count data 
from 250 freshwater benthic species sampled at 200 sites, abundances
of multiple parasite species on fish, counts of 60 different debris 
types in water samples, abundances of multiple spider species in traps, 
multiple
morphometric variables sampled from honeybees, and absence/presence of 
diet variables from faecal samples of brown bears.

In all these examples, we can analyse each variable with a univariate 
GLM(M). Although these analyses are relatively simple, there are also
some problems:

  * Extra Work: Individual analyses are computationally less efficient
    and require separate validation, interpretation, and reporting.
  * Lack of Multivariate Relationships: Analysing the variables
    individually neglects the interconnected relationships and
    interactions between them.
  * No Shared Variation: Univariate models might overlook consistent
    residual patterns across species, while multivariate models can
    capture shared variations due to common environmental factors.
  * Multiple Testing: Conducting separate analyses increases the risk of
    Type I errors, especially when the response variables are highly
    correlated.
  * Loss of Community-Level Insights: Analysing species separately
    misses out on a comprehensive, community-level viewpoint and can
    lead to inconsistent conclusions.


Kind regards,

Alain

	[[alternative HTML version deleted]]


From d@v|d@@|r|@uk @end|ng |rom gm@||@com  Thu Nov 21 22:12:09 2024
From: d@v|d@@|r|@uk @end|ng |rom gm@||@com (David Sirl)
Date: Thu, 21 Nov 2024 21:12:09 +0000
Subject: [R-sig-ME] Nonlinear mixed models with nlme::nlme() and
 lme4::nlmer()
In-Reply-To: <AS4PR06MB85657C047306A352F7B4EB26C3222@AS4PR06MB8565.eurprd06.prod.outlook.com>
References: <AS4PR06MB85657C047306A352F7B4EB26C3222@AS4PR06MB8565.eurprd06.prod.outlook.com>
Message-ID: <aafcb4fc-653e-4d0d-8851-1841ebd36b5b@gmail.com>

Hi R-sig-mixed-models-ers,

I'm fairly new to working with mixed models (and only have a couple of 
years of working with R behind me) and have reason to want to fit some 
nonlinear mixed models, so I'm working through the analysis of the 
Soybean data that's in Sec 6.3 of Pinheiro & Bates' book "Mixed-Effects 
Models in S and S-plus" (2000, Springer series on Statistics & Computing).

To help learn about these models I've been reproducing this analysis 
using both nlme::nlme() (as P&B use, though in S rather than R) and 
lme4::nlmer() (which I understand to have broadly similar functionality 
but with better numerics in some places) and the results from the two 
different packages agreed fairly well for the first analyses I did. But 
now I have tried to fit a particular model (to the same data) using 
these two methods and I get results that (i) suggest I really am fitting 
the same model to the same data, (ii) in some respects agree closely, 
but (iii) in other respects differ wildly.

A couple of colleagues have checked my code and don't see any issues, so 
I wonder if anyone here might be able to suggest what's going wrong with 
either one of these functions (which I presume is not very likely) or my 
use of these functions (presumably much more likely!) please?

I've set out what I've done below; and I'd be very grateful for any 
suggestions that anyone can offer re what has gone wrong and where.

Best wishes,
Dave


*A first sanity check*

First I'll just write out the key parts of the calls I make to these 
functions, in case I've been really daft and not noticed that my calls 
should not be expected to fit the same model:

nlme::nlme(weight ~ SSlogis(Time, Asym, xmid, scal),
 ?????????? data = ...,
 ?????????? fixed = Asym+xmid+scal~1,
 ?????????? random = Asym~1,
 ?????????? groups = ~Plot,
 ?????????? start = ...)

lme4::nlmer(weight ~ SSlogis(Time, Asym, xmid, scal) ~ (Asym + xmid + 
scal) + (Asym|Plot),
 ??????????? data = ...,
 ??????????? start = ...)


*Some more detail*

Assuming/hoping that the code above suggests that I am fitting the same 
model with both methods, here's a bit more detail of the context, what 
I'm trying to do and what's happening that suggests to me something is 
going wrong.

The dataset is Soybean (has "weight" recorded at 8-10 values of "Time" 
for each of 48 values of the grouping factor "Plot") and the model I'm 
trying to fit is of logistic growth using SSlogis(Time, Asym, xmid, 
scal) with a random effect for Asym only (and fixed effects for all 
three parameters).

The starting parameter values I use are the (marginal) medians of the 
parameter estimates for group-wise OLS fits of a logistic function to 
the data for each Plot (fitted using nlme::olsList()) - I've omitted 
this and entered the values explicitly here:

startParams = c(Asym=19.813031, xmid=56.243394, scal=8.718537)

fm3Soy.nlme =
nlme::nlme(weight ~ SSlogis(Time, Asym, xmid, scal),
 ???????????? data = nlme::Soybean
 ???????????? fixed = Asym+xmid+scal~1,
 ???????????? random = Asym~1,
 ???????????? groups = ~Plot,
 ???????????? start = startParams)


fm3Soy.nlmer =
lme4::nlmer(weight ~ SSlogis(Time, Asym, xmid, scal) ~ (Asym + xmid + 
scal) + (Asym|Plot),
 ????????????? data = nlme::Soybean
 ????????????? start = startParams)

 From the summary() of each fit I get what appear to be exactly the same 
parameters being estimated / reported on, and they're very much in 
agreement regarding likelihood/AIC/BIC values, variances of random 
effects, point estimates of fixed effects. But they are qualitatively 
very different in terms of standard errors and correlations for fixed 
effects. The standard errors differ by a factor of ~100 and the 
correlations are in the range 0.3 - 0.7 vs -0.3 - 0.0 and, based on what 
I know of the data (and the output in P&B's book!)? I'm fairly confident 
that the results from lme4::nlmer() which are incorrect.

A further suggestion of things going wrong arises if I try to find CIs 
for model parameters [using intervals(fm3Soy.nlme) and 
confint(fm3Soy.nlmer)]. The latter gives an error message "Error in 
eval(expr, envir, enclos): step factor reduced below 0.001 without 
reducing pwrss" which I don't understand and for which my Google-ing 
doesn't yield any help - I only see help for when this error arises in 
fitting the model.

Another possibly relevant point is that this is not a model that's 
actually fitted in P&B (the first thing they do is deal with the 
non-constant error variance). But even if some of the model assumptions 
are violated I am still fitting the same model to the same data, so I 
feel quite un-nerved by the big discrepancy in the results from the two 
methods.

The fits both seem reasonably good in the sense that the augmented 
predictions [e.g. with nlme::augPred(fm3Soy.nlme, level=0:1) |> plot()] 
for both methods agree with each other and, visually, agree fairly well 
to the data. (It's only standard errors and correlations of fixed 
effects that differ.)

(I have also fitted the model in a Bayesian way using brms::brm() and 
get results that are in keeping with those from nlme::nlme() above.)

Thanks very much if you've read this far. I hope I've included all 
relevant information to help track down what might be happening, but if 
someone is interested in helping and would like some more information 
then please do let me know.

	[[alternative HTML version deleted]]


From gonc@|o@m@ro@@ @end|ng |rom gm@||@com  Thu Nov 28 18:28:01 2024
From: gonc@|o@m@ro@@ @end|ng |rom gm@||@com (=?UTF-8?Q?Gon=C3=A7alo_M=2E_Rosa?=)
Date: Thu, 28 Nov 2024 17:28:01 +0000
Subject: [R-sig-ME] contrasts and factors with 2 or more levels
Message-ID: <CABY6znSZNmXqp9ZZqoNT=Y4qybrWTxRdjRoJ8Z8ZLVrMqT+Ynw@mail.gmail.com>

Hi team,

I hope you?re doing well. I?ve been struggling with fitting a model for my
experiment over the past few weeks, and I was hoping to get your advice.

We?re testing the effect of NE over time using a complex experimental
design with several treatment combinations. Here?s a summary of the setup:

   1. *Phase 1*: Each subject was randomly submitted to one of three
   initial treatments involving exposure to NE: NH, NE+, or NE-.
   2. *Phase 2*: After the initial treatment, subjects were randomly
   re-assigned to one of the 3 treatments. So we ended up with the following
   six possible treatment sequences:
      - NE- > NE-
      - NE- > NE+
      - NE- > NH
      - NE+ > NE+
      - NE+ > NE-
      - NE+ > NH

As response variables, we measure:

- body.index (once per phase)
- feeding.rate (3 times each phase)
- cover.use (7 times each phase)

Here a few summaries:

   1. > sapply(DF_Am[c("id", "treatment", "phase", "day", "body.index",
   "cover.use", "feeding.rate")], class)
   2.           id    treatment        phase          day   body.index
   cover.use feeding.rate
   3.     "factor"     "factor"     "factor"    "numeric"    "numeric"
   "numeric"    "numeric"
   4.
   5.
   6. > table(DF_Am$treatment, DF_Am$phase)
   7.
   8.                 phase1     phase2
   9.   NE- > NH         195        195
   10.   NE+ > NH         182        182
   11.   NE- > NE-        195        195
   12.   NE- > NE+        195        195
   13.   NE+ > NE-        195        195
   14.   NE+ > NE+        195        195
   15.
   16.
   17. > sapply(lapply(DF_Am, unique), length)
   18.                    id             treatment
   phase                  day
   19.                   105                     6
   2                   14
   20.           body.weight                   svl
   body.index             cover.use
   21.                   108                    12
   155                     3
   22.               feeding          feeding.rate
   23.                     7                     7

(all variables have at least 2 levels).

I wanted to model the effect of treatment and phase (i.e., treatment *
phase) on feeding.rate (proportion between 0 and 1) and cover.use (binary:
0 or 1), while considering the effect of the body.index as well. So, I?ve
started with the following model:

   1. model1 <- glmmTMB(cover.use ~ treatment * phase + body.index +
   2.                              (1 | id) + (1 | phase/day),
   3.                            family = binomial(link = "logit"),
   4.                            data = DF_Am)

The model runs smoothly and overall not showing any major issues (no
collinearity, no issues of dispersion, residuals, etc). The only red flag
is the binned_residuals(model1), where it says "Only about 79% of the
residuals are inside the error bounds".

I then tried to replicate the same structure for the feeding rate:

   1. model2 <- glmmTMB(feeding.rate ~ treatment * phase + body.index +
   2.                     (1 | id) + (1 | phase/day),
   3.                   family = binomial(link = "logit"),
   4.                   data = DF_Am)

But I always get the same error:

   1. Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
   2.   contrasts can be applied only to factors with 2 or more levels

I tried using counts instead of a rate, so changing the model to a Poisson
family, but made no difference.

I tried simplifying the random factors or even having the body.index as a
random factor... but that error is always there. The only way I found to
run the model is without the inclusion of body.index at all. I would
discharge it, but it seems too important of a variable given that we expect
a higher body.index to influence the feeding rate positively.


I thought that the fact that we only have one body.index data point per
subject (id) per phase would be the driver of this error, but why is that
not an issue in the first model? What am I missing here?


I?d really appreciate any guidance you can offer on how to address this
issue :) I've spent two weeks running in circles and I'm out of options...

Thank you so much for your time and help!

Gon?alo M. Rosa
IMIB Biodiversity Research Institute (CSIC, UO, PA), Spain
Institute of Zoology, Zoological Society of London, UK
Centre for Ecology, Evolution and Environmental Changes (CE3C), Faculdade
de Ci?ncias UL, Portugal
IUCN SSC Amphibian Specialist Group
?

	[[alternative HTML version deleted]]


From @|m@h@rme| @end|ng |rom gm@||@com  Tue Dec 10 03:47:21 2024
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Mon, 9 Dec 2024 20:47:21 -0600
Subject: [R-sig-ME] Simulating beta-distributed outcome in glmmTMB
Message-ID: <CACgv6yX9i5MijGFZYGAZ1=ceQoXgt8VjCrJGt-3kiDPnK3tdhw@mail.gmail.com>

Hello all,

I'm trying to simulate about 50 datasets each with a beta-distributed
outcome (Y) according to the R code below.

For each dataset, I would like to randomly determine the parameter
values for "beta=" and/or "theta=" arguments in my
glmmTMB::simulate_new() call such that I avoid getting Y values that
are close to 0 or 1.

I was wondering how you all suggest I can achieve this?

Thanks, Simon

## R code for 1 dataset:
library(tidyverse)
library(glmmTMB)

n_participant=100
n_time=3
groups = c("A","B", "Control")

set.seed(123)

dd <- data.frame(ID = ID <- rep(1:n_participant, each = n_time),
                 time = factor(rep(0:(n_time-1), n_participant),
levels=0:(n_time-1)),
                 group = factor(sample(groups, n_participant, replace=TRUE)[ID],
                                   levels = groups))
dd$Y <- simulate_new(
  ~ group*time + (time | ID),
  family = beta_family(),
  newdata = dd,
  newparams = list(beta = c(.2, .2, .3, .5, .1, 1.7, .9, .3, .1),
                   theta = c(-1.1, -1.25, -1.4, -1.2, -1.4, -1.3)))[[1]]


model <- glmmTMB(Y ~ group*time + (time | ID),
       family = beta_family(),
        data = dd)

VarCorr(model)


From @@nto@h@b@@r|n|v@@ @end|ng |rom out|ook@com  Mon Dec 16 16:07:47 2024
From: @@nto@h@b@@r|n|v@@ @end|ng |rom out|ook@com (Santosh Srinivas)
Date: Mon, 16 Dec 2024 15:07:47 +0000
Subject: [R-sig-ME] very low conditiona;
 l/marginal r-squared for a mixed model
Message-ID: <CH2PR20MB3189BF9D0EDD811EE77B2BC0C93B2@CH2PR20MB3189.namprd20.prod.outlook.com>

Dear List,

In a paper taking a hypothesis testing approach, we are reporting the results based on the following mixed model:

m = glmmTMB::glmmTMB(
      agentic_language ~ time + event + time_since_event + speaker_gender + (time|speaker_id), data = df_regress)

We reported the r-squared using the performance::r2(m) function.

A reviewer has critiqued that conditional and marginal r-squared values being so low (<  0.04) it is a very poor model.

We are not sure if the reviewer is making a valid critique based on r-squared value for a mixed model. Do you too think the mode has no merits?

Thanks for taking the time.

Kind regards
Santosh

	[[alternative HTML version deleted]]


From M@nue|@V@zquezS@nchez @end|ng |rom nyu|@ngone@org  Mon Dec 16 18:25:00 2024
From: M@nue|@V@zquezS@nchez @end|ng |rom nyu|@ngone@org (Vazquez Sanchez, Manuel)
Date: Mon, 16 Dec 2024 17:25:00 +0000
Subject: [R-sig-ME] lme4 (V.1.1-35.5) Convergence Warnings & Model
 Reliability
Message-ID: <MN2PR18MB36887F79DC1F386795023BF8823B2@MN2PR18MB3688.namprd18.prod.outlook.com>

Dear R-SIG-Mixed-Models Maling List Recipients,


I hope this email finds you well. My name is Manny, and I am a biostatistics analyst at NYU Langone Health in New York, NY. I am reaching out with a question regarding the functionality of the lme4 (Version 1.1-35.5) package, specifically its handling of model convergence in longitudinal data analyses.

One of the projects I am collaborating on involves analyzing longitudinal data from the Women's Interagency HIV Study (WIHS). Our goal is to explore the "syndemic" effects of individual-level exposures?such as depression, physical and sexual abuse, and drug use?on health outcomes like sleep quality and hypertension. The study cohort included 2,345 participants with each participant having 1-36  visits. We are using longitudinal, mixed-effects models to determine how the risk of hypertension status (binary outcome) varies with different combinations of these exposures while accounting for the repeated measurement over time as random effect.



For this analysis, we are using the glmer() function from the lme4 package. Example model:


glmer(HTN ~ AGEATBL + RACE + EDUCATION + MARRIED + INCOME + YearsFromBaseline + DRUGUSE + (1|ID), family = binomial(link = ?logit?))



AGEATBL, RACE, EDUCATION, MARRIED, INCOME, and YearsFromBaseline  are confounders, and DRUGUSE is one of the syndemic factors. The random effects specified (1|ID) are to account for differences between individual participants.

In our analyses, we encounter a consistent issue: almost all of the models return convergence warnings of the form:


Warning message:



In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :



  Model failed to converge with max|grad| = 0.794027 (tol = 0.002, component 1)

To address this, we have tried the following strategies:

  *   Changing the optimizer and increasing the number of iterations, including using the built-in lme4 functions to identify the best optimizer.
  *   Reducing the dataset by limiting the number of participants to decrease the levels of random effects.
  *   Excluding participants with either too few or too many visits to regularize the time in study for the included participants.
  *
Employing confounder variable selection procedures for dimensionality reduction.


Despite these efforts, the warnings persist. While the models do not produce errors, the warnings raise concerns about the reliability of our results.  We also checked the documentation on lme4 regarding performance tips. Setting  `control=glmerControl(calc.derivs=FALSE)` eliminates the warnings, but we need to report CI's and standard deviations of fixed effects parameters for our paper.


I have two primary questions:

  1.  How reliable are the results when convergence warnings are present?
     *   Are the parameter estimates and standard errors likely to be biased or misleading?
  2.  If the results are not reliable, are there additional strategies you recommend to improve model convergence or performance?
     *
For instance, would penalized likelihood approaches or modifications to the random effects structure be viable options?



I appreciate the robust functionality of the lme4 package and its critical role in facilitating complex modeling. Any guidance you can provide on addressing these convergence issues would be immensely helpful for our work. Thank you for your time and invaluable contribution to the research community. I look forward to any and all insights.



Best regards,

Manny


Manuel R. Vazquez-Sanchez, MS
Asst Research Scientist
Department of Population Health
Division of Biostatistics
NYU Grossman School of Medicine
Manuel.VazquezSanchez at nyulangone.org
(917) 581 2034

NYU Langone Health
180 Madison Avenue, 2nd Floor #2-32A
New York, NY 10016

	[[alternative HTML version deleted]]


From o||verhooker @end|ng |rom pr@t@t|@t|c@@com  Thu Dec 19 17:23:31 2024
From: o||verhooker @end|ng |rom pr@t@t|@t|c@@com (Oliver Hooker)
Date: Thu, 19 Dec 2024 16:23:31 +0000
Subject: [R-sig-ME] =?utf-8?q?ONLINE_COURSE_=E2=80=93_Introduction_To_Mix?=
	=?utf-8?q?ed_Models_Using_R_And_Rstudio_=28IMMR09=29?=
Message-ID: <CAEsSYzzC74d5adjA2_uQa5JxOkcaGKtCJ1mPMccWsDbWRt-7WA@mail.gmail.com>

ONLINE COURSE ? Introduction To Mixed Models Using R And Rstudio (IMMR09)

https://www.prstats.org/course/introduction-to-mixed-models-using-r-and-rstudio-immr09/

11th - 13th march 2025

Instructor - Dr. Rafael De Andrade Moral

COURSE OVERVIEW: This course provides a comprehensive practical and
theoretical introduction to multilevel models, also known as hierarchical
or mixed effects models. We will focus primarily on multilevel linear
models, but also cover multilevel generalized linear models. Likewise, we
will also describe Bayesian approaches to multilevel modelling. We will
begin by focusing on *random effects* multilevel models. These models make
it clear how multilevel models are in fact models of models. In addition,
random effects models serve as a solid basis for understanding mixed
effects, i.e. fixed and random effects, models. In this coverage of random
effects, we will also cover the important concepts of statistical shrinkage
in the estimation of effects, as well as intraclass correlation. We then
proceed to cover linear mixed effects models, particularly focusing on
varying intercept and/or varying slopes regression models. We will then
cover further aspects of linear mixed effects models, including multilevel
models for nested and crossed data data, and group level predictor
variables. Towards the end of the course we also cover generalized linear
mixed models (GLMMs), how to accommodate overdispersion through
individual-level random effects, as well as Bayesian approaches to
multilevel levels using the brms R package.

Please email oliverhooker at prstatistics.com with any questions.


-- 
Oliver Hooker PhD.
PR stats

	[[alternative HTML version deleted]]


From jepu@to @end|ng |rom gm@||@com  Fri Dec 20 20:39:16 2024
From: jepu@to @end|ng |rom gm@||@com (James Pustejovsky)
Date: Fri, 20 Dec 2024 13:39:16 -0600
Subject: [R-sig-ME] reference category in varIdent function (once again)
Message-ID: <CAFUVuJzHc9MUkf0fyAjMcA9eyUuhrv=yx7Mn3Jt=sa7ZwjeEmw@mail.gmail.com>

Greetings,

I'm trying to fit a linear mixed effect model using nlme::lme() that
includes heteroskedastic variances by group, where the variance for one
group is fixed to a specific value. I *think* I can do this using
varIdent() and setting lmeControl(sigma = x) for a specified value x.
However, I've run into what is evidently an old problem: that there doesn't
appear to be any way to control the reference level of varIdent().

As was noted in a very old post to R-SIG-mixed-models (
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q3/020582.html), the
reference level of varIdent() within an lme() call is set to the most
common level of the grouping factor. For reasons that are too involved to
get into, I need to set the reference level to something else (in fact, the
least frequently occurring level), so it seems I'm stuck.

Curiously, the behavior of varIdent() within a gls() call is a bit
different. As documented in this StackOverflow (
https://stackoverflow.com/questions/75929847/reference-category-in-varident-function-nlme-package-depends-on-data-order),
the reference level used within gls() depends on the sort order of the
data. I've included below a minimal working example that demonstrates the
difference in behavior.

Does anyone know of any work-around for setting the reference level of
varIdent() within an lme() call? I'd be grateful for any leads/suggestions
on what I could do (up to and including to just use a different package
already).

Thanks,
James


----------------------------------------------------------------------------
library(nlme)

# Make reversed factor
table(Orthodont$Sex)
Orthodont$Sex_rev <- Orthodont$Sex
levels(Orthodont$Sex_rev) <- rev(levels(Orthodont$Sex))
table(Orthodont$Sex_rev)

Ortho_male_first <- Orthodont[order(Orthodont$Sex),]
Ortho_female_first <- Orthodont[order(Orthodont$Sex, decreasing = TRUE),]

# Fit gls models with heteroskedastic variance
gls1 <- gls(
  distance ~ age + Sex,
  weights = varIdent(form = ~ 1 | Sex),
  data = Ortho_male_first
)
gls2 <- update(gls1, data = Ortho_female_first)
gls3 <- update(gls1, weights = varIdent(form = ~ 1 |Sex_rev))
gls4 <- update(gls3, data = Ortho_female_first)

# Parameterization depends on sort order
coef(gls1$modelStruct$varStruct)
coef(gls2$modelStruct$varStruct)
# But not on factor level order
coef(gls3$modelStruct$varStruct)
coef(gls4$modelStruct$varStruct)

# Fit lme models with heteroskedastic level-1 variance

lme1 <- lme(
  distance ~ age + Sex,
  random = ~ 1,
  weights = varIdent(form = ~ 1 | Sex),
  data = Ortho_male_first
)
lme2 <- update(lme1, data = Ortho_female_first)
lme3 <- update(lme1, weights = varIdent(form = ~ 1 |Sex_rev))
lme4 <- update(lme3, data = Ortho_female_first)

# Parameterization depends neither on sort order nor on factor level order
coef(lme1$modelStruct$varStruct)
coef(lme2$modelStruct$varStruct)
coef(lme3$modelStruct$varStruct)
coef(lme4$modelStruct$varStruct)

	[[alternative HTML version deleted]]


From p@u|john32 @end|ng |rom gm@||@com  Fri Dec 20 23:48:44 2024
From: p@u|john32 @end|ng |rom gm@||@com (Paul Johnson)
Date: Fri, 20 Dec 2024 16:48:44 -0600
Subject: [R-sig-ME] lme4 (V.1.1-35.5) Convergence Warnings & Model
 Reliability
In-Reply-To: <MN2PR18MB36887F79DC1F386795023BF8823B2@MN2PR18MB3688.namprd18.prod.outlook.com>
References: <MN2PR18MB36887F79DC1F386795023BF8823B2@MN2PR18MB3688.namprd18.prod.outlook.com>
Message-ID: <CAErODj8PeE=YrH2b__mvq3aUM4RX+uOAwH3f5cEYk3NtkoDRjA@mail.gmail.com>

Hi, Manny:

Can you give some details to help us understand this?  I'm guessing there
is collinearity in the estimation process, but you need to help us with
some details. If you are allowed to share the full input, let us see.
Almost for sure, there's something unexpected in your data structure.

1 It would help to know how big the sample is and how many individual
observations there are for each person.

I've seen the error you describe when the numbers of observations are very
small in some groups and the presence of cases in these small groups also
coincide with the other predictors in the model.

2 You refer to several variables as confounders, which is a new usage of
that term for me.  Lets get some diagnostics. Please fit this with an
ordinary regression and then diagnose the multicollinearity among the
predictors.

3. How about fitting the model with just the one random effect term and
then review the magnitude of the differences in the predictions for the
groups of observations.

I think its also possible that the assumption that the effects are normally
distributed is violated and the calculation process cannot find a way to
tell you that.

PJ

On Tue, Dec 17, 2024 at 3:36?PM Vazquez Sanchez, Manuel via
R-sig-mixed-models <r-sig-mixed-models at r-project.org> wrote:

> Dear R-SIG-Mixed-Models Maling List Recipients,
>
>
> I hope this email finds you well. My name is Manny, and I am a
> biostatistics analyst at NYU Langone Health in New York, NY. I am reaching
> out with a question regarding the functionality of the lme4 (Version
> 1.1-35.5) package, specifically its handling of model convergence in
> longitudinal data analyses.
>
> One of the projects I am collaborating on involves analyzing longitudinal
> data from the Women's Interagency HIV Study (WIHS). Our goal is to explore
> the "syndemic" effects of individual-level exposures?such as depression,
> physical and sexual abuse, and drug use?on health outcomes like sleep
> quality and hypertension. The study cohort included 2,345 participants with
> each participant having 1-36  visits. We are using longitudinal,
> mixed-effects models to determine how the risk of hypertension status
> (binary outcome) varies with different combinations of these exposures
> while accounting for the repeated measurement over time as random effect.
>
>
>
> For this analysis, we are using the glmer() function from the lme4
> package. Example model:
>
>
> glmer(HTN ~ AGEATBL + RACE + EDUCATION + MARRIED + INCOME +
> YearsFromBaseline + DRUGUSE + (1|ID), family = binomial(link = ?logit?))
>
>
>
> AGEATBL, RACE, EDUCATION, MARRIED, INCOME, and YearsFromBaseline  are
> confounders, and DRUGUSE is one of the syndemic factors. The random effects
> specified (1|ID) are to account for differences between individual
> participants.
>
> In our analyses, we encounter a consistent issue: almost all of the models
> return convergence warnings of the form:
>
>
> Warning message:
>
>
>
> In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>
>
>
>   Model failed to converge with max|grad| = 0.794027 (tol = 0.002,
> component 1)
>
> To address this, we have tried the following strategies:
>
>   *   Changing the optimizer and increasing the number of iterations,
> including using the built-in lme4 functions to identify the best optimizer.
>   *   Reducing the dataset by limiting the number of participants to
> decrease the levels of random effects.
>   *   Excluding participants with either too few or too many visits to
> regularize the time in study for the included participants.
>   *
> Employing confounder variable selection procedures for dimensionality
> reduction.
>
>
> Despite these efforts, the warnings persist. While the models do not
> produce errors, the warnings raise concerns about the reliability of our
> results.  We also checked the documentation on lme4 regarding performance
> tips. Setting  `control=glmerControl(calc.derivs=FALSE)` eliminates the
> warnings, but we need to report CI's and standard deviations of fixed
> effects parameters for our paper.
>
>
> I have two primary questions:
>
>   1.  How reliable are the results when convergence warnings are present?
>      *   Are the parameter estimates and standard errors likely to be
> biased or misleading?
>   2.  If the results are not reliable, are there additional strategies you
> recommend to improve model convergence or performance?
>      *
> For instance, would penalized likelihood approaches or modifications to
> the random effects structure be viable options?
>
>
>
> I appreciate the robust functionality of the lme4 package and its critical
> role in facilitating complex modeling. Any guidance you can provide on
> addressing these convergence issues would be immensely helpful for our
> work. Thank you for your time and invaluable contribution to the research
> community. I look forward to any and all insights.
>
>
>
> Best regards,
>
> Manny
>
>
> Manuel R. Vazquez-Sanchez, MS
> Asst Research Scientist
> Department of Population Health
> Division of Biostatistics
> NYU Grossman School of Medicine
> Manuel.VazquezSanchez at nyulangone.org
> (917) 581 2034
>
> NYU Langone Health
> 180 Madison Avenue, 2nd Floor #2-32A
> New York, NY 10016
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
Paul E. Johnson   http://pj.freefaculty.org
Director, Center for Research Methods and Data Analysis http://crmda.ku.edu

To write to me directly, please address me at pauljohn at ku.edu.

	[[alternative HTML version deleted]]


From @eb@meyer @end|ng |rom |@u@de  Mon Dec 23 17:40:13 2024
From: @eb@meyer @end|ng |rom |@u@de (Sebastian Meyer)
Date: Mon, 23 Dec 2024 17:40:13 +0100
Subject: [R-sig-ME] reference category in varIdent function (once again)
In-Reply-To: <CAFUVuJzHc9MUkf0fyAjMcA9eyUuhrv=yx7Mn3Jt=sa7ZwjeEmw@mail.gmail.com>
References: <CAFUVuJzHc9MUkf0fyAjMcA9eyUuhrv=yx7Mn3Jt=sa7ZwjeEmw@mail.gmail.com>
Message-ID: <380ececa-f338-4389-90d0-48dce309d2ee@fau.de>

I think it is unfortunate that varIdent() selects the reference category 
based on how the data is sorted (using the first level that occurs). 
There is also a corresponding bug report 
<https://bugs.r-project.org/show_bug.cgi?id=18505>.

Your example illustrates an additional issue with this behaviour, 
because lme() internally reorders the data by the grouping factor(s) 
before initialization, so the order of that factor ('Subject' in your 
example, with first level "M16", so male) will indirectly determine the 
reference level of varIdent(), regardless of how your data or strata 
levels are ordered originally.

It seems that only if there are more than two strata, the reference 
level for varIdent() can be chosen via a named initial parameter 
'value', leaving out the desired reference level, but I haven't tested 
if this works as intended with both gls() and lme(). It would then make 
sense to support such a choice also in the case of only two strata, so 
for a single parameter.

Best wishes,

	Sebastian Meyer


Am 20.12.24 um 20:39 schrieb James Pustejovsky:
> Greetings,
> 
> I'm trying to fit a linear mixed effect model using nlme::lme() that
> includes heteroskedastic variances by group, where the variance for one
> group is fixed to a specific value. I *think* I can do this using
> varIdent() and setting lmeControl(sigma = x) for a specified value x.
> However, I've run into what is evidently an old problem: that there doesn't
> appear to be any way to control the reference level of varIdent().
> 
> As was noted in a very old post to R-SIG-mixed-models (
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q3/020582.html), the
> reference level of varIdent() within an lme() call is set to the most
> common level of the grouping factor. For reasons that are too involved to
> get into, I need to set the reference level to something else (in fact, the
> least frequently occurring level), so it seems I'm stuck.
> 
> Curiously, the behavior of varIdent() within a gls() call is a bit
> different. As documented in this StackOverflow (
> https://stackoverflow.com/questions/75929847/reference-category-in-varident-function-nlme-package-depends-on-data-order),
> the reference level used within gls() depends on the sort order of the
> data. I've included below a minimal working example that demonstrates the
> difference in behavior.
> 
> Does anyone know of any work-around for setting the reference level of
> varIdent() within an lme() call? I'd be grateful for any leads/suggestions
> on what I could do (up to and including to just use a different package
> already).
> 
> Thanks,
> James
> 
> 
> ----------------------------------------------------------------------------
> library(nlme)
> 
> # Make reversed factor
> table(Orthodont$Sex)
> Orthodont$Sex_rev <- Orthodont$Sex
> levels(Orthodont$Sex_rev) <- rev(levels(Orthodont$Sex))
> table(Orthodont$Sex_rev)
> 
> Ortho_male_first <- Orthodont[order(Orthodont$Sex),]
> Ortho_female_first <- Orthodont[order(Orthodont$Sex, decreasing = TRUE),]
> 
> # Fit gls models with heteroskedastic variance
> gls1 <- gls(
>    distance ~ age + Sex,
>    weights = varIdent(form = ~ 1 | Sex),
>    data = Ortho_male_first
> )
> gls2 <- update(gls1, data = Ortho_female_first)
> gls3 <- update(gls1, weights = varIdent(form = ~ 1 |Sex_rev))
> gls4 <- update(gls3, data = Ortho_female_first)
> 
> # Parameterization depends on sort order
> coef(gls1$modelStruct$varStruct)
> coef(gls2$modelStruct$varStruct)
> # But not on factor level order
> coef(gls3$modelStruct$varStruct)
> coef(gls4$modelStruct$varStruct)
> 
> # Fit lme models with heteroskedastic level-1 variance
> 
> lme1 <- lme(
>    distance ~ age + Sex,
>    random = ~ 1,
>    weights = varIdent(form = ~ 1 | Sex),
>    data = Ortho_male_first
> )
> lme2 <- update(lme1, data = Ortho_female_first)
> lme3 <- update(lme1, weights = varIdent(form = ~ 1 |Sex_rev))
> lme4 <- update(lme3, data = Ortho_female_first)
> 
> # Parameterization depends neither on sort order nor on factor level order
> coef(lme1$modelStruct$varStruct)
> coef(lme2$modelStruct$varStruct)
> coef(lme3$modelStruct$varStruct)
> coef(lme4$modelStruct$varStruct)
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From jepu@to @end|ng |rom gm@||@com  Sun Dec 29 22:40:05 2024
From: jepu@to @end|ng |rom gm@||@com (James Pustejovsky)
Date: Sun, 29 Dec 2024 15:40:05 -0600
Subject: [R-sig-ME] reference category in varIdent function (once again)
In-Reply-To: <380ececa-f338-4389-90d0-48dce309d2ee@fau.de>
References: <CAFUVuJzHc9MUkf0fyAjMcA9eyUuhrv=yx7Mn3Jt=sa7ZwjeEmw@mail.gmail.com>
 <380ececa-f338-4389-90d0-48dce309d2ee@fau.de>
Message-ID: <CAFUVuJzHFJSbsE66bjDxW4YyMCNh_GS9_pfix4jREc1YOA3ZAw@mail.gmail.com>

Hi Sebastian,

Thanks for your reply. This helped me figure out how to control the
reference level for the particular model I'm working on. I wrote up what
I've learned (in an excessive degree of detail) here:
https://jepusto.com/posts/varIdent-function-in-nlme/

James

On Mon, Dec 23, 2024 at 10:40?AM Sebastian Meyer <seb.meyer at fau.de> wrote:

> I think it is unfortunate that varIdent() selects the reference category
> based on how the data is sorted (using the first level that occurs).
> There is also a corresponding bug report
> <https://bugs.r-project.org/show_bug.cgi?id=18505>.
>
> Your example illustrates an additional issue with this behaviour,
> because lme() internally reorders the data by the grouping factor(s)
> before initialization, so the order of that factor ('Subject' in your
> example, with first level "M16", so male) will indirectly determine the
> reference level of varIdent(), regardless of how your data or strata
> levels are ordered originally.
>
> It seems that only if there are more than two strata, the reference
> level for varIdent() can be chosen via a named initial parameter
> 'value', leaving out the desired reference level, but I haven't tested
> if this works as intended with both gls() and lme(). It would then make
> sense to support such a choice also in the case of only two strata, so
> for a single parameter.
>
> Best wishes,
>
>         Sebastian Meyer
>
>
> Am 20.12.24 um 20:39 schrieb James Pustejovsky:
> > Greetings,
> >
> > I'm trying to fit a linear mixed effect model using nlme::lme() that
> > includes heteroskedastic variances by group, where the variance for one
> > group is fixed to a specific value. I *think* I can do this using
> > varIdent() and setting lmeControl(sigma = x) for a specified value x.
> > However, I've run into what is evidently an old problem: that there
> doesn't
> > appear to be any way to control the reference level of varIdent().
> >
> > As was noted in a very old post to R-SIG-mixed-models (
> > https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q3/020582.html),
> the
> > reference level of varIdent() within an lme() call is set to the most
> > common level of the grouping factor. For reasons that are too involved to
> > get into, I need to set the reference level to something else (in fact,
> the
> > least frequently occurring level), so it seems I'm stuck.
> >
> > Curiously, the behavior of varIdent() within a gls() call is a bit
> > different. As documented in this StackOverflow (
> >
> https://stackoverflow.com/questions/75929847/reference-category-in-varident-function-nlme-package-depends-on-data-order
> ),
> > the reference level used within gls() depends on the sort order of the
> > data. I've included below a minimal working example that demonstrates the
> > difference in behavior.
> >
> > Does anyone know of any work-around for setting the reference level of
> > varIdent() within an lme() call? I'd be grateful for any
> leads/suggestions
> > on what I could do (up to and including to just use a different package
> > already).
> >
> > Thanks,
> > James
> >
> >
> >
> ----------------------------------------------------------------------------
> > library(nlme)
> >
> > # Make reversed factor
> > table(Orthodont$Sex)
> > Orthodont$Sex_rev <- Orthodont$Sex
> > levels(Orthodont$Sex_rev) <- rev(levels(Orthodont$Sex))
> > table(Orthodont$Sex_rev)
> >
> > Ortho_male_first <- Orthodont[order(Orthodont$Sex),]
> > Ortho_female_first <- Orthodont[order(Orthodont$Sex, decreasing = TRUE),]
> >
> > # Fit gls models with heteroskedastic variance
> > gls1 <- gls(
> >    distance ~ age + Sex,
> >    weights = varIdent(form = ~ 1 | Sex),
> >    data = Ortho_male_first
> > )
> > gls2 <- update(gls1, data = Ortho_female_first)
> > gls3 <- update(gls1, weights = varIdent(form = ~ 1 |Sex_rev))
> > gls4 <- update(gls3, data = Ortho_female_first)
> >
> > # Parameterization depends on sort order
> > coef(gls1$modelStruct$varStruct)
> > coef(gls2$modelStruct$varStruct)
> > # But not on factor level order
> > coef(gls3$modelStruct$varStruct)
> > coef(gls4$modelStruct$varStruct)
> >
> > # Fit lme models with heteroskedastic level-1 variance
> >
> > lme1 <- lme(
> >    distance ~ age + Sex,
> >    random = ~ 1,
> >    weights = varIdent(form = ~ 1 | Sex),
> >    data = Ortho_male_first
> > )
> > lme2 <- update(lme1, data = Ortho_female_first)
> > lme3 <- update(lme1, weights = varIdent(form = ~ 1 |Sex_rev))
> > lme4 <- update(lme3, data = Ortho_female_first)
> >
> > # Parameterization depends neither on sort order nor on factor level
> order
> > coef(lme1$modelStruct$varStruct)
> > coef(lme2$modelStruct$varStruct)
> > coef(lme3$modelStruct$varStruct)
> > coef(lme4$modelStruct$varStruct)
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

	[[alternative HTML version deleted]]


From @eb@meyer @end|ng |rom |@u@de  Mon Dec 30 00:23:29 2024
From: @eb@meyer @end|ng |rom |@u@de (Sebastian Meyer)
Date: Mon, 30 Dec 2024 00:23:29 +0100
Subject: [R-sig-ME] reference category in varIdent function (once again)
In-Reply-To: <CAFUVuJzHFJSbsE66bjDxW4YyMCNh_GS9_pfix4jREc1YOA3ZAw@mail.gmail.com>
References: <CAFUVuJzHc9MUkf0fyAjMcA9eyUuhrv=yx7Mn3Jt=sa7ZwjeEmw@mail.gmail.com>
 <380ececa-f338-4389-90d0-48dce309d2ee@fau.de>
 <CAFUVuJzHFJSbsE66bjDxW4YyMCNh_GS9_pfix4jREc1YOA3ZAw@mail.gmail.com>
Message-ID: <6bf9475b-02bc-4bfe-b70c-9b5495d29d99@fau.de>

Glad to hear that helped. Your exemplification of current varIdent 
behaviour is also helpful, thanks. I'll revisit the bug with a closer 
look next year.

In principle, it would be better for the reference level to be based on 
the factor levels, but as you say, nlme's code base is very old, which 
means many publications (implicitly) rely on the current behaviour, so 
semantics or defaults won't be changed easily. Still, bugs should be 
fixed -- and it should be possible to choose the reference level.

Best regards,

	Sebastian Meyer

PS: The getVarCov() bug that is linked in your report (to another post) 
was fixed a while ago in 2020 (nlme version 3.1-150), i.e., the 
`all.equal(V_raw, V_sorted)` tests now give TRUE. It might be worth 
noting this somewhere.


Am 29.12.24 um 22:40 schrieb James Pustejovsky:
> Hi Sebastian,
> 
> Thanks for your reply. This helped me figure out how to control the 
> reference level for the particular model I'm working on. I wrote up what 
> I've learned (in an excessive degree of detail) here:
> https://jepusto.com/posts/varIdent-function-in-nlme/ 
> <https://jepusto.com/posts/varIdent-function-in-nlme/>
> 
> James
> 
> On Mon, Dec 23, 2024 at 10:40?AM Sebastian Meyer <seb.meyer at fau.de 
> <mailto:seb.meyer at fau.de>> wrote:
> 
>     I think it is unfortunate that varIdent() selects the reference
>     category
>     based on how the data is sorted (using the first level that occurs).
>     There is also a corresponding bug report
>     <https://bugs.r-project.org/show_bug.cgi?id=18505
>     <https://bugs.r-project.org/show_bug.cgi?id=18505>>.
> 
>     Your example illustrates an additional issue with this behaviour,
>     because lme() internally reorders the data by the grouping factor(s)
>     before initialization, so the order of that factor ('Subject' in your
>     example, with first level "M16", so male) will indirectly determine the
>     reference level of varIdent(), regardless of how your data or strata
>     levels are ordered originally.
> 
>     It seems that only if there are more than two strata, the reference
>     level for varIdent() can be chosen via a named initial parameter
>     'value', leaving out the desired reference level, but I haven't tested
>     if this works as intended with both gls() and lme(). It would then make
>     sense to support such a choice also in the case of only two strata, so
>     for a single parameter.
> 
>     Best wishes,
> 
>      ? ? ? ? Sebastian Meyer
> 
> 
>     Am 20.12.24 um 20:39 schrieb James Pustejovsky:
>      > Greetings,
>      >
>      > I'm trying to fit a linear mixed effect model using nlme::lme() that
>      > includes heteroskedastic variances by group, where the variance
>     for one
>      > group is fixed to a specific value. I *think* I can do this using
>      > varIdent() and setting lmeControl(sigma = x) for a specified value x.
>      > However, I've run into what is evidently an old problem: that
>     there doesn't
>      > appear to be any way to control the reference level of varIdent().
>      >
>      > As was noted in a very old post to R-SIG-mixed-models (
>      >
>     https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q3/020582.html
>     <https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q3/020582.html>), the
>      > reference level of varIdent() within an lme() call is set to the most
>      > common level of the grouping factor. For reasons that are too
>     involved to
>      > get into, I need to set the reference level to something else (in
>     fact, the
>      > least frequently occurring level), so it seems I'm stuck.
>      >
>      > Curiously, the behavior of varIdent() within a gls() call is a bit
>      > different. As documented in this StackOverflow (
>      >
>     https://stackoverflow.com/questions/75929847/reference-category-in-varident-function-nlme-package-depends-on-data-order <https://stackoverflow.com/questions/75929847/reference-category-in-varident-function-nlme-package-depends-on-data-order>),
>      > the reference level used within gls() depends on the sort order
>     of the
>      > data. I've included below a minimal working example that
>     demonstrates the
>      > difference in behavior.
>      >
>      > Does anyone know of any work-around for setting the reference
>     level of
>      > varIdent() within an lme() call? I'd be grateful for any
>     leads/suggestions
>      > on what I could do (up to and including to just use a different
>     package
>      > already).
>      >
>      > Thanks,
>      > James
>      >
>      >
>      >
>     ----------------------------------------------------------------------------
>      > library(nlme)
>      >
>      > # Make reversed factor
>      > table(Orthodont$Sex)
>      > Orthodont$Sex_rev <- Orthodont$Sex
>      > levels(Orthodont$Sex_rev) <- rev(levels(Orthodont$Sex))
>      > table(Orthodont$Sex_rev)
>      >
>      > Ortho_male_first <- Orthodont[order(Orthodont$Sex),]
>      > Ortho_female_first <- Orthodont[order(Orthodont$Sex, decreasing =
>     TRUE),]
>      >
>      > # Fit gls models with heteroskedastic variance
>      > gls1 <- gls(
>      >? ? distance ~ age + Sex,
>      >? ? weights = varIdent(form = ~ 1 | Sex),
>      >? ? data = Ortho_male_first
>      > )
>      > gls2 <- update(gls1, data = Ortho_female_first)
>      > gls3 <- update(gls1, weights = varIdent(form = ~ 1 |Sex_rev))
>      > gls4 <- update(gls3, data = Ortho_female_first)
>      >
>      > # Parameterization depends on sort order
>      > coef(gls1$modelStruct$varStruct)
>      > coef(gls2$modelStruct$varStruct)
>      > # But not on factor level order
>      > coef(gls3$modelStruct$varStruct)
>      > coef(gls4$modelStruct$varStruct)
>      >
>      > # Fit lme models with heteroskedastic level-1 variance
>      >
>      > lme1 <- lme(
>      >? ? distance ~ age + Sex,
>      >? ? random = ~ 1,
>      >? ? weights = varIdent(form = ~ 1 | Sex),
>      >? ? data = Ortho_male_first
>      > )
>      > lme2 <- update(lme1, data = Ortho_female_first)
>      > lme3 <- update(lme1, weights = varIdent(form = ~ 1 |Sex_rev))
>      > lme4 <- update(lme3, data = Ortho_female_first)
>      >
>      > # Parameterization depends neither on sort order nor on factor
>     level order
>      > coef(lme1$modelStruct$varStruct)
>      > coef(lme2$modelStruct$varStruct)
>      > coef(lme3$modelStruct$varStruct)
>      > coef(lme4$modelStruct$varStruct)
>      >
>      >? ? ? ?[[alternative HTML version deleted]]
>      >
>      > _______________________________________________
>      > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>


From jepu@to @end|ng |rom gm@||@com  Mon Dec 30 15:50:01 2024
From: jepu@to @end|ng |rom gm@||@com (James Pustejovsky)
Date: Mon, 30 Dec 2024 08:50:01 -0600
Subject: [R-sig-ME] reference category in varIdent function (once again)
In-Reply-To: <6bf9475b-02bc-4bfe-b70c-9b5495d29d99@fau.de>
References: <CAFUVuJzHc9MUkf0fyAjMcA9eyUuhrv=yx7Mn3Jt=sa7ZwjeEmw@mail.gmail.com>
 <380ececa-f338-4389-90d0-48dce309d2ee@fau.de>
 <CAFUVuJzHFJSbsE66bjDxW4YyMCNh_GS9_pfix4jREc1YOA3ZAw@mail.gmail.com>
 <6bf9475b-02bc-4bfe-b70c-9b5495d29d99@fau.de>
Message-ID: <CAFUVuJykwjVt9tPaNP64ejkxsWCBa4CTepXKHRS6R69XL9mk3A@mail.gmail.com>

Regarding your P.S., I've added a callout to the post noting that the bug
has been squashed.
https://jepusto.com/posts/bug-in-nlme-getVarCov/

Kind Regards,
James

On Sun, Dec 29, 2024 at 5:23?PM Sebastian Meyer <seb.meyer at fau.de> wrote:

> Glad to hear that helped. Your exemplification of current varIdent
> behaviour is also helpful, thanks. I'll revisit the bug with a closer
> look next year.
>
> In principle, it would be better for the reference level to be based on
> the factor levels, but as you say, nlme's code base is very old, which
> means many publications (implicitly) rely on the current behaviour, so
> semantics or defaults won't be changed easily. Still, bugs should be
> fixed -- and it should be possible to choose the reference level.
>
> Best regards,
>
>         Sebastian Meyer
>
> PS: The getVarCov() bug that is linked in your report (to another post)
> was fixed a while ago in 2020 (nlme version 3.1-150), i.e., the
> `all.equal(V_raw, V_sorted)` tests now give TRUE. It might be worth
> noting this somewhere.
>
>
> Am 29.12.24 um 22:40 schrieb James Pustejovsky:
> > Hi Sebastian,
> >
> > Thanks for your reply. This helped me figure out how to control the
> > reference level for the particular model I'm working on. I wrote up what
> > I've learned (in an excessive degree of detail) here:
> > https://jepusto.com/posts/varIdent-function-in-nlme/
> > <https://jepusto.com/posts/varIdent-function-in-nlme/>
> >
> > James
> >
> > On Mon, Dec 23, 2024 at 10:40?AM Sebastian Meyer <seb.meyer at fau.de
> > <mailto:seb.meyer at fau.de>> wrote:
> >
> >     I think it is unfortunate that varIdent() selects the reference
> >     category
> >     based on how the data is sorted (using the first level that occurs).
> >     There is also a corresponding bug report
> >     <https://bugs.r-project.org/show_bug.cgi?id=18505
> >     <https://bugs.r-project.org/show_bug.cgi?id=18505>>.
> >
> >     Your example illustrates an additional issue with this behaviour,
> >     because lme() internally reorders the data by the grouping factor(s)
> >     before initialization, so the order of that factor ('Subject' in your
> >     example, with first level "M16", so male) will indirectly determine
> the
> >     reference level of varIdent(), regardless of how your data or strata
> >     levels are ordered originally.
> >
> >     It seems that only if there are more than two strata, the reference
> >     level for varIdent() can be chosen via a named initial parameter
> >     'value', leaving out the desired reference level, but I haven't
> tested
> >     if this works as intended with both gls() and lme(). It would then
> make
> >     sense to support such a choice also in the case of only two strata,
> so
> >     for a single parameter.
> >
> >     Best wishes,
> >
> >              Sebastian Meyer
> >
> >
> >     Am 20.12.24 um 20:39 schrieb James Pustejovsky:
> >      > Greetings,
> >      >
> >      > I'm trying to fit a linear mixed effect model using nlme::lme()
> that
> >      > includes heteroskedastic variances by group, where the variance
> >     for one
> >      > group is fixed to a specific value. I *think* I can do this using
> >      > varIdent() and setting lmeControl(sigma = x) for a specified
> value x.
> >      > However, I've run into what is evidently an old problem: that
> >     there doesn't
> >      > appear to be any way to control the reference level of varIdent().
> >      >
> >      > As was noted in a very old post to R-SIG-mixed-models (
> >      >
> >     https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q3/020582.html
> >     <
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q3/020582.html>),
> the
> >      > reference level of varIdent() within an lme() call is set to the
> most
> >      > common level of the grouping factor. For reasons that are too
> >     involved to
> >      > get into, I need to set the reference level to something else (in
> >     fact, the
> >      > least frequently occurring level), so it seems I'm stuck.
> >      >
> >      > Curiously, the behavior of varIdent() within a gls() call is a bit
> >      > different. As documented in this StackOverflow (
> >      >
> >
> https://stackoverflow.com/questions/75929847/reference-category-in-varident-function-nlme-package-depends-on-data-order
> <
> https://stackoverflow.com/questions/75929847/reference-category-in-varident-function-nlme-package-depends-on-data-order
> >),
> >      > the reference level used within gls() depends on the sort order
> >     of the
> >      > data. I've included below a minimal working example that
> >     demonstrates the
> >      > difference in behavior.
> >      >
> >      > Does anyone know of any work-around for setting the reference
> >     level of
> >      > varIdent() within an lme() call? I'd be grateful for any
> >     leads/suggestions
> >      > on what I could do (up to and including to just use a different
> >     package
> >      > already).
> >      >
> >      > Thanks,
> >      > James
> >      >
> >      >
> >      >
> >
>  ----------------------------------------------------------------------------
> >      > library(nlme)
> >      >
> >      > # Make reversed factor
> >      > table(Orthodont$Sex)
> >      > Orthodont$Sex_rev <- Orthodont$Sex
> >      > levels(Orthodont$Sex_rev) <- rev(levels(Orthodont$Sex))
> >      > table(Orthodont$Sex_rev)
> >      >
> >      > Ortho_male_first <- Orthodont[order(Orthodont$Sex),]
> >      > Ortho_female_first <- Orthodont[order(Orthodont$Sex, decreasing =
> >     TRUE),]
> >      >
> >      > # Fit gls models with heteroskedastic variance
> >      > gls1 <- gls(
> >      >    distance ~ age + Sex,
> >      >    weights = varIdent(form = ~ 1 | Sex),
> >      >    data = Ortho_male_first
> >      > )
> >      > gls2 <- update(gls1, data = Ortho_female_first)
> >      > gls3 <- update(gls1, weights = varIdent(form = ~ 1 |Sex_rev))
> >      > gls4 <- update(gls3, data = Ortho_female_first)
> >      >
> >      > # Parameterization depends on sort order
> >      > coef(gls1$modelStruct$varStruct)
> >      > coef(gls2$modelStruct$varStruct)
> >      > # But not on factor level order
> >      > coef(gls3$modelStruct$varStruct)
> >      > coef(gls4$modelStruct$varStruct)
> >      >
> >      > # Fit lme models with heteroskedastic level-1 variance
> >      >
> >      > lme1 <- lme(
> >      >    distance ~ age + Sex,
> >      >    random = ~ 1,
> >      >    weights = varIdent(form = ~ 1 | Sex),
> >      >    data = Ortho_male_first
> >      > )
> >      > lme2 <- update(lme1, data = Ortho_female_first)
> >      > lme3 <- update(lme1, weights = varIdent(form = ~ 1 |Sex_rev))
> >      > lme4 <- update(lme3, data = Ortho_female_first)
> >      >
> >      > # Parameterization depends neither on sort order nor on factor
> >     level order
> >      > coef(lme1$modelStruct$varStruct)
> >      > coef(lme2$modelStruct$varStruct)
> >      > coef(lme3$modelStruct$varStruct)
> >      > coef(lme4$modelStruct$varStruct)
> >      >
> >      >       [[alternative HTML version deleted]]
> >      >
> >      > _______________________________________________
> >      > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >
>

	[[alternative HTML version deleted]]


