From trea26 at gmail.com  Tue Jan  5 19:09:50 2010
From: trea26 at gmail.com (Antoine Tremblay)
Date: Tue, 5 Jan 2010 13:09:50 -0500
Subject: [R-sig-ME] main effects in a model with interactions
Message-ID: <581a8bcf1001051009r3fa0d08aqe409135b38cc0770@mail.gmail.com>

Dear list member,
I would like to thank you for your past help with the questions I had;
it was well appreciated.

I now have a question regarding main effects in a model with interactions.

We have a model with variables Frequency (High vs. Low), Diagnosis (N
and LI), and Time (continuous from 1 to 1600). The dependent variable
is Reaction Time (logged). Note that the design is unbalanced: there
are more LI than N data points and more High than Low data points.
Roughly put, the model is RT ~ Time*Diagnosis*Frequency + ranefs

The fixed effects portion of the summary would look something like this:

Fixed effects:
                                Estimate    Std. Error  t value
(Intercept)                 6.344e+00  4.598e-02  137.97
Time                       -1.619e-04   1.868e-05   -8.67
DiagN                      -1.103e-01   4.840e-02   -2.28
FreqLow                    3.316e-02   4.005e-02    0.83
Time:DiagN               1.956e-05   2.489e-05    0.79
Time:FreqLow           1.564e-05   1.241e-05    1.26
DiagN:FreqLow         -2.449e-03   4.745e-03   -0.52
Time:DiagN:FreqLow  2.104e-05  1.027e-05     2.05

What we would like to get estimates, standard errors and t values for
the main effects of:
  Time,
  Diagnosis (Diag) and
  Frequency (Freq) and
  a Time slope for N across frequencies,
  a Time slope for LI across frequencies,
  a Time slope for High across groups, and
  a Time slope for Low across groups.

As far as I know, these are not provided in the table (please correct
me if I'm wrong): The (Intercept) row refers to the intercept for the
reference level (here LI-High), the DiagN row refers to the difference
in intercept between N-High and LI-High, the FreqLow row is the
difference in intercept between LI-Low and LI-High, and so forth.

The question is can I do the following to compute the main effect of
Frequency for example:
(1) Get the estimated intercepts for LI-High and N-High (by releveling
and refitting the model), and average them, then get the estimated
intercepts for LI-Low and N-Low and average them?

Note that the design is unbalanced and I think this might affect the
averaging unless this was already taken care of by the LMER modeling
process (please correct me if I'm wrong).

(2) Compute the difference between the mean estimate for High and the
mean estimate for Low and divided it by the pooled (or averaged?)
standard error of the intercepts for LI-High, N-High, LI-Low, and
N-Low.

Would this be an acceptable way to approach the problem?

Your help is always greatly appreciated,
Sincerely,
--
Antoine Tremblay
Department of Neuroscience
Georgetown University
Washington DC



From desja004 at umn.edu  Fri Jan  8 19:18:38 2010
From: desja004 at umn.edu (Christopher David Desjardins)
Date: Fri, 08 Jan 2010 12:18:38 -0600
Subject: [R-sig-ME] R-structure in ZIP models
Message-ID: <1262974718.20299.4.camel@debian>

I recall that Jarrod recommended that I fix the variance in the
R-structure when I set priors for ZIP models. However, I don't recall
why. Was the reason that it expedites MCMC convergence?
Thanks,
Chris



From j.hadfield at ed.ac.uk  Sat Jan  9 12:20:44 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 09 Jan 2010 11:20:44 +0000
Subject: [R-sig-ME] R-structure in ZIP models
In-Reply-To: <1262974718.20299.4.camel@debian>
References: <1262974718.20299.4.camel@debian>
Message-ID: <20100109112044.kryi3thtcsk80ow8@www.staffmail.ed.ac.uk>

Hi Chris,

The zero-inflation part of the model is like modelling a binary  
variable. Between observation heterogeneity in the probability of  
success cannot be observed (even if it exists) and so the residual  
variance is unestimable. For this reason I recommend fixing the  
residual variance of the zero-inflation process at something (usually  
one). By not fixing it, the posterior and prior for the residual  
variance will be identical. It turns out that the higher you fix the  
residual variance the better it mixes, but if it is too high you will  
get numerical problems trying to take the inverse logit of the latent  
variables.

Different values of the residual variance will give different  
estimates or the fixed effects and other variance components. Diggle  
et al in their book on longitudinal analysis give a very accurate  
method for rescaling the effects back to what would be observed if the  
residual variance was zero (the assumption of most other programs).  
I'm not on my computer at the moment but the result can be found in  
the CourseNotes vignette. From memory, you divide the fixed effects by  
sqrt(1-c^2*R) where R is the estimated residual variance and  
c=(16*sqrt(3))/(15*pi). For the variance components divide by (1-c^2R).

Cheers,

Jarrod


Quoting Christopher David Desjardins <desja004 at umn.edu>:

> I recall that Jarrod recommended that I fix the variance in the
> R-structure when I set priors for ZIP models. However, I don't recall
> why. Was the reason that it expedites MCMC convergence?
> Thanks,
> Chris
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From nikko at hailmail.net  Sun Jan 10 00:52:27 2010
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Sat, 09 Jan 2010 15:52:27 -0800
Subject: [R-sig-ME] R-structure in ZIP models
In-Reply-To: <mailman.5.1263034801.788.r-sig-mixed-models@r-project.org>
References: <mailman.5.1263034801.788.r-sig-mixed-models@r-project.org>
Message-ID: <1263081147.7088.1353816689@webmail.messagingengine.com>

Hi Chris,
If you mean the covariance between the poission parameter and zero
inflation, its because the 
model is not identified. In general though fixing a variance should
expedite MCMC convergence
as 2nd moments require much more information to estimate. But fixing a
parameter tends to
be a pretty strong prior ;)

Nicholas
> 
> ----------------------------------------------------------------------
> 
> Message: 1
> Date: Fri, 08 Jan 2010 12:18:38 -0600
> From: Christopher David Desjardins <desja004 at umn.edu>
> Subject: [R-sig-ME] R-structure in ZIP models
> To: r-sig-mixed-models at r-project.org
> Message-ID: <1262974718.20299.4.camel at debian>
> Content-Type: text/plain; charset="UTF-8"
> 
> I recall that Jarrod recommended that I fix the variance in the
> R-structure when I set priors for ZIP models. However, I don't recall
> why. Was the reason that it expedites MCMC convergence?
> Thanks,
> Chris
> 
> 
> 
> ------------------------------
> 
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> End of R-sig-mixed-models Digest, Vol 37, Issue 2
> *************************************************



From trina.schneider at huskymail.uconn.edu  Mon Jan 11 18:51:22 2010
From: trina.schneider at huskymail.uconn.edu (Trina Schneider Bayard)
Date: Mon, 11 Jan 2010 12:51:22 -0500 (EST)
Subject: [R-sig-ME] package for zero-inflated poisson models with temporal
	correlation?
Message-ID: <9629282c41e7ba4b08d880cfa7a71939.squirrel@huskymailweb.uconn.edu>

Dear all,

After looking through the archives I'm pretty certain I'm on the right
list but please let me know if this question is best posted elsewhere:

Does anyone know of an R package that is able to perform zero-inflated
Poisson/negative binomial models that incorporate temporal correlation?

My data consist of weekly counts (12) of various bird behaviors taken at
29 points, along with various explanatory variables related to local
reproductive activity and environmental conditions.

So far, I have been able to
1) model the counts of bird behaviors as a function of the explanatory
variables while incorporating the temporal correlation associated with my
data collection methods using the ?geepack? library (thus ignoring
zero-inflation)
2) model the zero-inflated counts of bird behaviors as a function of the
explanatory variables using the ?pscl? library (thus ignoring temporal
correlation)
....but have not been able to find a function that incorporates both
conditions.

I?d rather not take the average of the counts across all 12 weeks as I am
interested in how specific bird behaviors change according to both local
reproductive activities and the progression of the breeding season.

Thanks in advance for your help,

Trina

-- 
Trina Schneider Bayard
PhD Candidate

Department of Ecology and Evolutionary Biology
University of Connecticut
75 North Eagleville Road, U3043
Storrs, CT  06269

office:860.486.3005



From datkins at u.washington.edu  Tue Jan 12 00:08:55 2010
From: datkins at u.washington.edu (David Atkins)
Date: Mon, 11 Jan 2010 15:08:55 -0800
Subject: [R-sig-ME] package for zero-inflated poisson models with
 temporal correlation?
In-Reply-To: <9629282c41e7ba4b08d880cfa7a71939.squirrel@huskymailweb.uconn.edu>
References: <9629282c41e7ba4b08d880cfa7a71939.squirrel@huskymailweb.uconn.edu>
Message-ID: <4B4BAF87.8020704@u.washington.edu>


Hi Trina--

In short: no, I'm not aware of a package that can do zero-inflated 
(mixed/GEE) models with autocorrelated errors.

However, the MCMCglmm package can fit mixed-effects zero-inflated 
models, and a random-effect for time implies some autocorrelation. 
Thus, one option would be to use MCMCglmm and explore whether there 
appears to be residual autocorrelation, and compare this to your results 
using GEE and zeroinfl() in pscl.

Finally, Zuur et al. show BUGS code for mixed-effects Poisson with 
autocorrelated error in their book, Mixed Effects Models and Extensions 
in Ecology with R.

For what it's worth.

cheers, Dave

-- 
Dave Atkins, PhD
Research Associate Professor
Department of Psychiatry and Behavioral Science
University of Washington
datkins at u.washington.edu

Center for the Study of Health and Risk Behaviors (CSHRB)		
1100 NE 45th Street, Suite 300 	
Seattle, WA  98105 	
206-616-3879 	
http://depts.washington.edu/cshrb/
(Mon-Wed)	

Center for Healthcare Improvement, for Addictions, Mental Illness,
   Medically Vulnerable Populations (CHAMMP)
325 9th Avenue, 2HH-15
Box 359911
Seattle, WA 98104?
206-897-4210
http://www.chammp.org
(Thurs)


Dear all,

After looking through the archives I'm pretty certain I'm on the right
list but please let me know if this question is best posted elsewhere:

Does anyone know of an R package that is able to perform zero-inflated
Poisson/negative binomial models that incorporate temporal correlation?

My data consist of weekly counts (12) of various bird behaviors taken at
29 points, along with various explanatory variables related to local
reproductive activity and environmental conditions.

So far, I have been able to
1) model the counts of bird behaviors as a function of the explanatory
variables while incorporating the temporal correlation associated with my
data collection methods using the ?geepack? library (thus ignoring
zero-inflation)
2) model the zero-inflated counts of bird behaviors as a function of the
explanatory variables using the ?pscl? library (thus ignoring temporal
correlation)
....but have not been able to find a function that incorporates both
conditions.

I?d rather not take the average of the counts across all 12 weeks as I am
interested in how specific bird behaviors change according to both local
reproductive activities and the progression of the breeding season.

Thanks in advance for your help,

Trina

-- 
Trina Schneider Bayard
PhD Candidate

Department of Ecology and Evolutionary Biology
University of Connecticut
75 North Eagleville Road, U3043
Storrs, CT  06269

office:860.486.3005



From desja004 at umn.edu  Tue Jan 12 17:43:27 2010
From: desja004 at umn.edu (Christopher David Desjardins)
Date: Tue, 12 Jan 2010 10:43:27 -0600
Subject: [R-sig-ME] Prior on G-structure and model formulation for ZIP model
 in MCMCglmm
Message-ID: <1263314607.2682.13.camel@debian.hsd1.mn.comcast.net.>

Hi,
I am trying to estimate a model in MCMCglmm where my outcome variable is
number of suspensions, a count variable. Presently, I am trying to
predict the number of suspensions with the following MCMCglmm ZIP model
(lots of students have no suspension).

m0 <-MCMCglmm(sus~trait-1 + at.level(trait,1):grade +
at.level(trait,1):I(grade^2), random=~us(at.level(trait,1)):id.f,
data=suslm, rcov=~idh(trait):units, family="zipoisson", prior=prior,
nitt=60000, thin=50, burnin=10000)

Which has allowed me to answer the first part of my analysis. However,
I'd like to account for correlations between students within a school as
well as throwing in some covariates and am curious if the following
model would be correct:

m1 <- MCMCglmm(sus~trait-1 + at.level(trait,1):grade +
at.level(trait,1):I(grade^2) + at.level(trait,1):gender +
at.level(trait,1):ethnicity + at.level(trait,1):specialeducation +
at.level(trait,1):ethnicity*grade +
at.level(trait,1):ethnicity*I(grade^2),
random=~us(at.level(trait,1)):id.f + us(at.level(trait,1)):schn.f +
us(at.level(trait,1)):id.f + us(at.level(trait,1)):schn.f:id.f,
data=suslm, rcov=~idh(trait):units, family="zipoisson", prior=prior,
nitt=60000, thin=50, burnin=10000)

Gender is a dummy variable: 0 - Female; 1 - Male

Ethnicity is a dummy variable: 0 - non-Hispanic White, 1 - African
American, 2 - Asian American, 3 - Hispanic, 4 - American Indian

specialeducation is a dummy variable: 0 - Not in special ed, 1 - in
special ed.

id.f is the student's id

schn.f is the school variable as a factor

Students are able to, and often do, move between schools. 

My second question is what would the G-structure for this look like and
what form might a prior take?

For model m0, I have been specifying the following prior:

G=list(G1=list(V=1, nu=1, alpha.mu=0, alpha.V=25^2))

But now my G matrix is obviously more than 1 element. I believe it
becomes a 4 x 4 matrix but I'm not even sure about that. 

Thanks for your patience with my questions. I've been working through
Diggle et al. 2002 to try and get a better feel of these models.

Chris



From Kevin.Kardynal at EC.gc.ca  Tue Jan 12 17:58:48 2010
From: Kevin.Kardynal at EC.gc.ca (Kardynal,Kevin [Yel])
Date: Tue, 12 Jan 2010 09:58:48 -0700
Subject: [R-sig-ME] Back-transformation of Poisson model
Message-ID: <09359F11B0FD38458672F47AE757EEEF01531ABB@sr-yel-exch2.prairie.int.ec.gc.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100112/f1479346/attachment.pl>

From j.hadfield at ed.ac.uk  Tue Jan 12 19:41:21 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 12 Jan 2010 18:41:21 +0000
Subject: [R-sig-ME] Prior on G-structure and model formulation for
	ZIP	model in MCMCglmm
Message-ID: <20100112184121.9y5fr3gpxss80gcs@www.staffmail.ed.ac.uk>



----- Forwarded message from j.hadfield at ed.ac.uk -----
     Date: Tue, 12 Jan 2010 18:12:21 +0000
     From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
Reply-To: Jarrod Hadfield <j.hadfield at ed.ac.uk>
  Subject: Re: [R-sig-ME] Prior on G-structure and model formulation  
for ZIP model in MCMCglmm
       To: Christopher David Desjardins <desja004 at umn.edu>

Hi Chris,

You can drop the third (or first term) random term from your model
because they are identical, which leaves you with the three 1X1
covariance matrices to estimate (or if you like, 3 variances!).

Using the same prior that you used in the simpler model for all three
variances, the prior for G would look like

G=list(G1=list(V=1, nu=1, alpha.mu=0, alpha.V=25^2),
         G2=list(V=1, nu=1, alpha.mu=0, alpha.V=25^2),
         G3=list(V=1, nu=1, alpha.mu=0, alpha.V=25^2))

Whether this is an appropriate prior, is your responsibility.

Cheers,

Jarrod
Quoting Christopher David Desjardins <desja004 at umn.edu>:

> Hi,
> I am trying to estimate a model in MCMCglmm where my outcome variable is
> number of suspensions, a count variable. Presently, I am trying to
> predict the number of suspensions with the following MCMCglmm ZIP model
> (lots of students have no suspension).
>
> m0 <-MCMCglmm(sus~trait-1 + at.level(trait,1):grade +
> at.level(trait,1):I(grade^2), random=~us(at.level(trait,1)):id.f,
> data=suslm, rcov=~idh(trait):units, family="zipoisson", prior=prior,
> nitt=60000, thin=50, burnin=10000)
>
> Which has allowed me to answer the first part of my analysis. However,
> I'd like to account for correlations between students within a school as
> well as throwing in some covariates and am curious if the following
> model would be correct:
>
> m1 <- MCMCglmm(sus~trait-1 + at.level(trait,1):grade +
> at.level(trait,1):I(grade^2) + at.level(trait,1):gender +
> at.level(trait,1):ethnicity + at.level(trait,1):specialeducation +
> at.level(trait,1):ethnicity*grade +
> at.level(trait,1):ethnicity*I(grade^2),
> random=~us(at.level(trait,1)):id.f + us(at.level(trait,1)):schn.f +
> us(at.level(trait,1)):id.f + us(at.level(trait,1)):schn.f:id.f,
> data=suslm, rcov=~idh(trait):units, family="zipoisson", prior=prior,
> nitt=60000, thin=50, burnin=10000)
>
> Gender is a dummy variable: 0 - Female; 1 - Male
>
> Ethnicity is a dummy variable: 0 - non-Hispanic White, 1 - African
> American, 2 - Asian American, 3 - Hispanic, 4 - American Indian
>
> specialeducation is a dummy variable: 0 - Not in special ed, 1 - in
> special ed.
>
> id.f is the student's id
>
> schn.f is the school variable as a factor
>
> Students are able to, and often do, move between schools.
>
> My second question is what would the G-structure for this look like and
> what form might a prior take?
>
> For model m0, I have been specifying the following prior:
>
> G=list(G1=list(V=1, nu=1, alpha.mu=0, alpha.V=25^2))
>
> But now my G matrix is obviously more than 1 element. I believe it
> becomes a 4 x 4 matrix but I'm not even sure about that.
>
> Thanks for your patience with my questions. I've been working through
> Diggle et al. 2002 to try and get a better feel of these models.
>
> Chris
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



----- End forwarded message -----


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From j.hadfield at ed.ac.uk  Tue Jan 12 19:41:52 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 12 Jan 2010 18:41:52 +0000
Subject: [R-sig-ME] Back-transformation of Poisson model
Message-ID: <20100112184152.uv4f906s0cgsk800@www.staffmail.ed.ac.uk>



----- Forwarded message from j.hadfield at ed.ac.uk -----
     Date: Tue, 12 Jan 2010 18:38:06 +0000
     From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
Reply-To: Jarrod Hadfield <j.hadfield at ed.ac.uk>
  Subject: Re: [R-sig-ME] Back-transformation of Poisson model
       To: "Kardynal,Kevin [Yel]" <Kevin.Kardynal at EC.gc.ca>

Dear Kevin,

You will have to exponentiate the output from predict.

It is worth noting there are three types of prediction (on the
data-scale) you could make:

a) exp(Xb)
b) exp(Xb+Zu)
c) int exp(Xb)du assuming the u's are iid.

X - fixed effect design matrix  b - fixed effects
Z - random effect design matrix  u - fixed effects

You have done the first, but this can be very different from c, which
is what I expect you want: the predictions averaged over possible
realisations of the random effects.

To obtain c use exp(Xb+0.5*v)

where v is the sum of the variance components. If you use additive
over-dispersed models you want to include the "residual" variance in
v, also.

Cheers,

Jarrod

Quoting "Kardynal,Kevin [Yel]" <Kevin.Kardynal at EC.gc.ca>:

> Hello,
>
> I'd like to know if predicted values from  a Poisson mixed model require
> back-transformation to get the 'real' predicted values or if this is
> done automatically? I assume that the predicted values are already
> back-transformed since my results are similar to the annual means.
>
> My model for estimating bird trends in lme4 is as such:
>
> lme3<-lmer(Abundance ~ Year +  (1|Observer) + (1|Site/Station),
> data=SWTH, family = poisson(link=log))
>
> I then took the coefficients from the mixed model and used them in a GLM
> to derive the predicted values.
> dd <-fixef(lme3) # gives coefficients
>
> lme_glmDEY <- glm(Abundance ~ Year, data=SWTH, family = poisson(link =
> log)) # for poisson distribution
> lme_glmDEY$coefficients <- dd
>
> # create a data set of predicted values
> pred <- as.data.frame(predict(lme_glmDEY, SWTH , "response", se.fit=T))
> pred_val <- as.data.frame(cbind(SWTH,pred))
>
> So, do I have to perform a back-transformation on the predicted values
> (ie., using exp())?
>
> Thanks,
>
> Kevin
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



----- End forwarded message -----


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From patili_buergi at hotmail.com  Tue Jan 12 23:15:34 2010
From: patili_buergi at hotmail.com (=?iso-8859-1?B?TGluZGEgQvxyZ2k=?=)
Date: Tue, 12 Jan 2010 14:15:34 -0800
Subject: [R-sig-ME] STRANGE! lmer: "false convergence" warning only for
 certain multiples of x!?!
Message-ID: <SNT107-W6851659847D2E3558EAA5976C0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100112/945f91cf/attachment.pl>

From cahn88 at gmail.com  Thu Jan 14 04:13:52 2010
From: cahn88 at gmail.com (Chaehyung Ahn)
Date: Wed, 13 Jan 2010 22:13:52 -0500
Subject: [R-sig-ME] an error in gee()
Message-ID: <800cb8d51001131913m6f3af548x641a74f8b94fa9b5@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100113/8646e949/attachment.pl>

From Thierry.ONKELINX at inbo.be  Thu Jan 14 10:11:49 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 14 Jan 2010 10:11:49 +0100
Subject: [R-sig-ME] an error in gee()
In-Reply-To: <800cb8d51001131913m6f3af548x641a74f8b94fa9b5@mail.gmail.com>
References: <800cb8d51001131913m6f3af548x641a74f8b94fa9b5@mail.gmail.com>
Message-ID: <2E9C414912813E4EB981326983E0A10406ED8DBB@inboexch.inbo.be>

Dear Cahn,

I tend to use the geepack package instead of the gee package. Just
change the name of the package and it works like a charm.

library(geepack)
data(Rail,package="nlme")
geese(travel~1, id=Rail, data=Rail, corstr="exchangeable") 

HTH,

Thierry


------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] Namens Chaehyung Ahn
Verzonden: donderdag 14 januari 2010 4:14
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] an error in gee()

Hi everyone,

I've been trying to fit a simple dataset Rail in nlme package with
gee().

This is what I tried. Rail has 3 repetitions for each id.
----------------------------------------
library(gee)
data(Rail,package="nlme")
gee(travel~1, id=Rail, data=Rail, corstr="exchangeable")
 ----------------------------------------

However, I got the following error;
 ----------------------------------------
Working Correlation[1:4,1:4]
Error in print(x$working.correlation[1:4, 1:4], digits = digits) :
  subscript out of bounds
 ----------------------------------------

I make the Rail have 4 repetitions per each id, then it works.
-----------------------------------------------
Rail1<-rbind(Rail,c(1,53),c(2,30),c(3,87),c(4,95),c(5,48),c(6,84))
aa<-order(Rail1$Rail)
Rail1<-Rail1[aa,]
gee(travel~1, id=Rail, data=Rail1, corstr="exchangeable")
---------------------------------------------------

So, it works with 4 repetitions but with 3 repetitions. Did I do
something wrong or is it a known bug?

Many thanks in advance.

cahn


--
Chaehyung Ahn
4033 Remington Oaks Circle
Cary, NC 27519
http://cahn88.blogspot.com/

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From juliet.hannah at gmail.com  Thu Jan 14 20:48:41 2010
From: juliet.hannah at gmail.com (Juliet Hannah)
Date: Thu, 14 Jan 2010 14:48:41 -0500
Subject: [R-sig-ME] r examples of mixed models from scratch
Message-ID: <93d6f2a81001141148r52212a3ci59af26b4f43b53aa@mail.gmail.com>

Hi List,

I'm trying to learn more about mixed models in detail. Does anyone know of
any examples where code is provided showing simple examples of doing
this from scratch. For example, setting up a likelihood, using optim, and things
like that.

Thanks,

Juliet



From bolker at ufl.edu  Thu Jan 14 21:13:34 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 14 Jan 2010 15:13:34 -0500
Subject: [R-sig-ME] r examples of mixed models from scratch
In-Reply-To: <93d6f2a81001141148r52212a3ci59af26b4f43b53aa@mail.gmail.com>
References: <93d6f2a81001141148r52212a3ci59af26b4f43b53aa@mail.gmail.com>
Message-ID: <4B4F7AEE.3090300@ufl.edu>

Juliet Hannah wrote:
> Hi List,
> 
> I'm trying to learn more about mixed models in detail. Does anyone know of
> any examples where code is provided showing simple examples of doing
> this from scratch. For example, setting up a likelihood, using optim, and things
> like that.
> 
> Thanks,
> 
> Juliet
> 

  If I understand what you want to do correctly, this is probably not
something you want to mess with -- the computational details of
implementing mixed model fitting are tricky. If you do need a "custom"
mixed model, implementing them in AD Model Builder or WinBUGS will
probably be your best bet (there are R interfaces to both of these
programs).

  Ben Bolker

-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From cahn88 at gmail.com  Thu Jan 14 21:16:49 2010
From: cahn88 at gmail.com (Chaehyung Ahn)
Date: Thu, 14 Jan 2010 15:16:49 -0500
Subject: [R-sig-ME] r examples of mixed models from scratch
In-Reply-To: <93d6f2a81001141148r52212a3ci59af26b4f43b53aa@mail.gmail.com>
References: <93d6f2a81001141148r52212a3ci59af26b4f43b53aa@mail.gmail.com>
Message-ID: <800cb8d51001141216i7c4aff11le2235168322b9100@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100114/1238940a/attachment.pl>

From cahn88 at gmail.com  Thu Jan 14 21:22:45 2010
From: cahn88 at gmail.com (Chaehyung Ahn)
Date: Thu, 14 Jan 2010 15:22:45 -0500
Subject: [R-sig-ME] r examples of mixed models from scratch
In-Reply-To: <93d6f2a81001141148r52212a3ci59af26b4f43b53aa@mail.gmail.com>
References: <93d6f2a81001141148r52212a3ci59af26b4f43b53aa@mail.gmail.com>
Message-ID: <800cb8d51001141222g471de58cm604e21c63140432a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100114/aba65554/attachment.pl>

From juliet.hannah at gmail.com  Thu Jan 14 21:37:30 2010
From: juliet.hannah at gmail.com (Juliet Hannah)
Date: Thu, 14 Jan 2010 15:37:30 -0500
Subject: [R-sig-ME] r examples of mixed models from scratch
In-Reply-To: <4B4F7AEE.3090300@ufl.edu>
References: <93d6f2a81001141148r52212a3ci59af26b4f43b53aa@mail.gmail.com>
	<4B4F7AEE.3090300@ufl.edu>
Message-ID: <93d6f2a81001141237g2c2eac66j53bd3c543d44b487@mail.gmail.com>

Thanks for the suggestions. By no means is this for an application. It
is just for my education. I thought I should be able to find some
simple examples, like the one posted in this thread. Perhaps I cannot
find many examples online because of the complexities arising for even
simple cases.

On Thu, Jan 14, 2010 at 3:13 PM, Ben Bolker <bolker at ufl.edu> wrote:
> Juliet Hannah wrote:
>> Hi List,
>>
>> I'm trying to learn more about mixed models in detail. Does anyone know of
>> any examples where code is provided showing simple examples of doing
>> this from scratch. For example, setting up a likelihood, using optim, and things
>> like that.
>>
>> Thanks,
>>
>> Juliet
>>
>
> ?If I understand what you want to do correctly, this is probably not
> something you want to mess with -- the computational details of
> implementing mixed model fitting are tricky. If you do need a "custom"
> mixed model, implementing them in AD Model Builder or WinBUGS will
> probably be your best bet (there are R interfaces to both of these
> programs).
>
> ?Ben Bolker
>
> --
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / people.biology.ufl.edu/bolker
> GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc
>



From ggrothendieck at gmail.com  Fri Jan 15 00:59:00 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 14 Jan 2010 18:59:00 -0500
Subject: [R-sig-ME] r examples of mixed models from scratch
In-Reply-To: <93d6f2a81001141148r52212a3ci59af26b4f43b53aa@mail.gmail.com>
References: <93d6f2a81001141148r52212a3ci59af26b4f43b53aa@mail.gmail.com>
Message-ID: <971536df1001141559j2ea408fewd7cd99fce06bd23d@mail.gmail.com>

Chapter 6 of Simon Wood's book, Generalized Additive Models, has short
R code that maximizes the log likelihood of a mixed model using optim.

On Thu, Jan 14, 2010 at 2:48 PM, Juliet Hannah <juliet.hannah at gmail.com> wrote:
> Hi List,
>
> I'm trying to learn more about mixed models in detail. Does anyone know of
> any examples where code is provided showing simple examples of doing
> this from scratch. For example, setting up a likelihood, using optim, and things
> like that.
>
> Thanks,
>
> Juliet
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From sven.wirthner at wsl.ch  Fri Jan 15 11:44:28 2010
From: sven.wirthner at wsl.ch (Sven Wirthner)
Date: Fri, 15 Jan 2010 11:44:28 +0100
Subject: [R-sig-ME] paired and repeated measurements
Message-ID: <20100115114428.11644sy3sol48f8k@webmail.wsl.ch>

Dear all

I have the following problem:

I measured co2 on 6 paired sites (one grubbed and one non-grubbed
fence per site -> grubbing = treatment). These measurements I repeated
15 times over 2 years (see attached table). So, now my problem is how  
to analyze these
data. I tried the following model:

mod1_CO2<-lme(co2~treatment+time,random=~1|site,data=CO2_t1_t15)

I think with the random effect I included the paired sample design of
my study, but obviously the model does not check for the "repeated
measurements" structure of my data. Or in other words, the model
assumpt that different sampling dates are independent of each other,
but they aren't (since I measured the CO2 15 times on exactly the same
spot).

So, that's why my question is how can I combine the paired (or nested)
design with the repeated measurements in one model???

Thank you for any help

Sven


--
Sven Wirthner
Eidg. Forschungsanstalt f?r Wald, Schnee und Landschaft WSL
Tier?kologie
Z?rcherstrasse 111
CH-8903 Birmensdorf

Tel. +41 44 7392 371
Fax  +41 44 7392 215
sven.wirthner at wsl.ch
http://www.wsl.ch

-----------------------------------------------------------------------------------
This message was sent using IMP (http://horde.org/imp/) at WSL  
(http://www.wsl.ch).

From alexandre.villers at cebc.cnrs.fr  Sat Jan 16 15:38:18 2010
From: alexandre.villers at cebc.cnrs.fr (alexandre villers)
Date: Sat, 16 Jan 2010 15:38:18 +0100
Subject: [R-sig-ME] Boosting computation time of glmmPQL when specifying
	spatial correlation structure
Message-ID: <1263652698.82a3b1calexandre.villers@cebc.cnrs.fr>

Good afternoon,

I know how to speed up GAMM when specifying a spatial correlation structure by splitting up the dataset to compute the spatial correlation coefficients of corSpher.
such (if dataG is my dataset)
cutx<-cut(dataG$x,breaks=(4))                          cuty <- cut(dataG$y, breaks=(4))
cutxy <- paste(cutx, cuty)

and then 
gamm(Response~(var1)+s(var2),family=binomial, data=dataG,correlation=corSpher(form=~(x+y)|cutxy)).

the cutxy doesn't seem to work with glmmPQL and with 1500 points, it takes ages... 
Does anyone know if there is a way to apply the same "trick" ?

By the way (take a breath...), does the plotting of a spatial correlogram with residuals(model, type="pearson") from a glmmPQL model (where correlation structure was specified) makes sense to you ? I'm not sure if residuals of such model account for the stucture (and I can hear some of you, why don't you check this by yourself... yes , I will try !)

Best regards and thanks for any hint

Alex

Alexandre Villers
PhD. Candidate
Team Agripop
CEBC CNRS UPR 1934
79360 Beauvoir sur Niort

Phone: +33 (0)549 099 613 


__________ Information from ESET Mail Security, version of virus signature database 4777 (20100116) __________

The message was checked by ESET Mail Security.
http://www.eset.com



From highstat at highstat.com  Sun Jan 17 14:52:18 2010
From: highstat at highstat.com (Highstat Statistics Ltd)
Date: Sun, 17 Jan 2010 13:52:18 +0000
Subject: [R-sig-ME] Boosting computation time of glmmPQL when
 specifying	spatial, correlation structure
In-Reply-To: <mailman.5.1263726002.17541.r-sig-mixed-models@r-project.org>
References: <mailman.5.1263726002.17541.r-sig-mixed-models@r-project.org>
Message-ID: <4B531612.4050809@highstat.com>

On 17/01/2010 11:00, r-sig-mixed-models-request at r-project.org wrote:
> Send R-sig-mixed-models mailing list submissions to
> 	r-sig-mixed-models at r-project.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
> 	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help' to
> 	r-sig-mixed-models-request at r-project.org
>
>
>
> I know how to speed up GAMM when specifying a spatial correlation structure by splitting up the dataset to compute the

You are not splitting up the data set. Instead you are imposing the 
correlation on a sub-block of data.

> spatial correlation coefficients of corSpher.
> such (if dataG is my dataset)
> cutx<-cut(dataG$x,breaks=(4))                          cuty<- cut(dataG$y, breaks=(4))
> cutxy<- paste(cutx, cuty)
>
> and then
> gamm(Response~(var1)+s(var2),family=binomial, data=dataG,correlation=corSpher(form=~(x+y)|cutxy)).
>
> the cutxy doesn't seem to work with glmmPQL and with 1500 points, it takes ages...
> Does anyone know if there is a way to apply the same "trick" ?
>    

The first thing to do is to use decent starting values for the range 
(and nugget???). See
?corSpher

Alain


> By the way (take a breath...), does the plotting of a spatial correlogram with residuals(model, type="pearson") from a glmmPQL model (where correlation structure was specified) makes sense to you ? I'm not sure if residuals of such model account for the stucture (and I can hear some of you, why don't you check this by yourself... yes , I will try !)
>
> Best regards and thanks for any hint
>
> Alex
>
> Alexandre Villers
> PhD. Candidate
> Team Agripop
> CEBC CNRS UPR 1934
> 79360 Beauvoir sur Niort
>
> Phone: +33 (0)549 099 613
>
>
> __________ Information from ESET Mail Security, version of virus signature database 4777 (20100116) __________
>
> The message was checked by ESET Mail Security.
> http://www.eset.com
>
>
>
> ------------------------------
>
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> End of R-sig-mixed-models Digest, Vol 37, Issue 9
> *************************************************
>
>    


-- 


Dr. Alain F. Zuur
First author of:

1. Analysing Ecological Data (2007).
Zuur, AF, Ieno, EN and Smith, GM. Springer. 680 p.
URL: www.springer.com/0-387-45967-7


2. Mixed effects models and extensions in ecology with R. (2009).
Zuur, AF, Ieno, EN, Walker, N, Saveliev, AA, and Smith, GM. Springer.
http://www.springer.com/life+sci/ecology/book/978-0-387-87457-9


3. A Beginner's Guide to R (2009).
Zuur, AF, Ieno, EN, Meesters, EHWG. Springer
http://www.springer.com/statistics/computational/book/978-0-387-93836-3


Other books: http://www.highstat.com/books.htm


Statistical consultancy, courses, data analysis and software
Highland Statistics Ltd.
6 Laverock road
UK - AB41 6FN Newburgh
Tel: 0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com
URL: www.brodgar.com



From Thierry.ONKELINX at inbo.be  Mon Jan 18 10:33:58 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 18 Jan 2010 10:33:58 +0100
Subject: [R-sig-ME] paired and repeated measurements
In-Reply-To: <20100115114428.11644sy3sol48f8k@webmail.wsl.ch>
References: <20100115114428.11644sy3sol48f8k@webmail.wsl.ch>
Message-ID: <2E9C414912813E4EB981326983E0A10406F2B105@inboexch.inbo.be>

Dear Sven,

If you expect serial autocorrelation along time, then you could add a correlation structure like e.g. corAR1() or corExp(). You can find more details in Pinheiro & Bates (2000) or Zuur et al. (2009)

lme(co2~treatment+time, random=~1|site, correlation = corAR1(form = ~time), data=CO2_t1_t15)

@BOOK{
  title = {Mixed-Effects Models in {S} and {S-Plus}},
  publisher = {Springer},
  year = {2000},
  author = {Pinheiro, Jose C. and Bates, Douglas M.},
  note = {{ISBN 0-387-98957-0}},
  abstract = {A comprehensive guide to the use of the `nlme' package for linear
	and nonlinear mixed-effects models.},
  publisherurl = {http://www.springeronline.com/sgw/cda/frontpage/0,11855,4-10129-22-2102822-0,00.html?changeHeader=true}
}

@BOOK{
  title = {Mixed Effects Models and Extensions in Ecology with R},
  publisher = {Springer New York},
  year = {2009},
  author = {Zuur, Alain F. and Ieno, Elena N. and Walker, Neil J. and Saveliev,
	Anatoly A. and Smith, Graham M.},
  doi = {10.1007/978-0-387-87458-6}
}

HTH,

Thierry

----------------------------------------------------------------------------
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Sven Wirthner
Verzonden: vrijdag 15 januari 2010 11:44
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] paired and repeated measurements

Dear all

I have the following problem:

I measured co2 on 6 paired sites (one grubbed and one non-grubbed fence per site -> grubbing = treatment). These measurements I repeated
15 times over 2 years (see attached table). So, now my problem is how to analyze these data. I tried the following model:

mod1_CO2<-lme(co2~treatment+time,random=~1|site,data=CO2_t1_t15)

I think with the random effect I included the paired sample design of my study, but obviously the model does not check for the "repeated measurements" structure of my data. Or in other words, the model assumpt that different sampling dates are independent of each other, but they aren't (since I measured the CO2 15 times on exactly the same spot).

So, that's why my question is how can I combine the paired (or nested) design with the repeated measurements in one model???

Thank you for any help

Sven


--
Sven Wirthner
Eidg. Forschungsanstalt f?r Wald, Schnee und Landschaft WSL Tier?kologie Z?rcherstrasse 111
CH-8903 Birmensdorf

Tel. +41 44 7392 371
Fax  +41 44 7392 215
sven.wirthner at wsl.ch
http://www.wsl.ch

-----------------------------------------------------------------------------------
This message was sent using IMP (http://horde.org/imp/) at WSL (http://www.wsl.ch).

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From gmgarland at ucdavis.edu  Sun Jan 17 22:51:20 2010
From: gmgarland at ucdavis.edu (Gina Garland)
Date: Sun, 17 Jan 2010 13:51:20 -0800
Subject: [R-sig-ME] using R for linear mixed effects models
Message-ID: <1a2e445a1001171351k13d169a4gea0909c335ff9e98@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100117/3a60fa5c/attachment.pl>

From catarina.miranda at gmail.com  Mon Jan 18 15:58:38 2010
From: catarina.miranda at gmail.com (Catarina Miranda)
Date: Mon, 18 Jan 2010 15:58:38 +0100
Subject: [R-sig-ME] using R for linear mixed effects models
In-Reply-To: <1a2e445a1001171351k13d169a4gea0909c335ff9e98@mail.gmail.com>
References: <1a2e445a1001171351k13d169a4gea0909c335ff9e98@mail.gmail.com>
Message-ID: <be7c0f81001180658i23bb7ae7xa683d4cce1595e30@mail.gmail.com>

These slides from Douglas Bates could be helpful:

http://lme4.r-forge.r-project.org/slides/2009-07-21-Seewiesen/

2010/1/17 Gina Garland <gmgarland at ucdavis.edu>:
> Hello,
>
> ? I'm a Masters student at UC Davis and I'm trying to use R to produce a
> linear mixed effect model for my data on N2O emissions in agricultural
> ecosystems. I'm looking at the effects of management practices (such as
> fertilization and irrigation) as well as crop type, soil type, and other
> environmental factors on N2O emissions in California cropping systems.
> However, I'm having trouble finding specific examples on how to do it. I've
> never used a computer program like this before and I'm struggling on where
> to begin. Do you have any advice or specific examples that could point me in
> the right direction?
>
> Thanks,
> Gina
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From guiga82 at msn.com  Tue Jan 19 15:09:47 2010
From: guiga82 at msn.com (Guilherme Mazzochini)
Date: Tue, 19 Jan 2010 14:09:47 +0000
Subject: [R-sig-ME] Help with LME in R
Message-ID: <COL102-W158A228D9E98CBC9D33BC4B2650@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100119/250ca31f/attachment.pl>

From sylvain.willart at gmail.com  Wed Jan 20 15:23:57 2010
From: sylvain.willart at gmail.com (sylvain willart)
Date: Wed, 20 Jan 2010 15:23:57 +0100
Subject: [R-sig-ME] different VarCov structures for different levels of
	grouping with lme
Message-ID: <79473eea1001200623r60e64bdh593cb6bba57450ca@mail.gmail.com>

Hello all,

I am struggling for a while with a problem of model specification,
I don't know if it is possible, but I would like to fit a nested model
where subjects are autocorrelated with respect to time (AR1), and
goups are correlated with respect to their spatial position...

with (i) the subjects, observed through time (t), and grouped with
respect to (g) : Y(git)

because of the AR1 structure, I am using nlme library, I tried the
multiple random instruction:

random = list(Group = ~ 1 , Subject = ~ 1 )

but I don't know how to specify that each of the random term have its
own covariance structure:
corAR1 for time within subject
corGauss for subject within group

If it helps, this is to apply a marketing model of stores sales
(subject are stores) observed over several weeks (time), and stores
are correlated when they are geographically close to each other
(variogram on averaged sales over time shows gaussian correlation , I
used spdep to construct a neighbourhood matrix)

Thanks in advance,

Sylvain



From Sebastiaan.DeSmedt at ua.ac.be  Wed Jan 20 17:32:30 2010
From: Sebastiaan.DeSmedt at ua.ac.be (De Smedt Sebastiaan)
Date: Wed, 20 Jan 2010 17:32:30 +0100
Subject: [R-sig-ME] Random & fixed effects on same level
Message-ID: <930B1A45F446404FA4D99A46F09209C401540E0A@xmail05.ad.ua.ac.be>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100120/bd7186c5/attachment.pl>

From m.fairbrother at bristol.ac.uk  Thu Jan 21 12:16:23 2010
From: m.fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Thu, 21 Jan 2010 11:16:23 +0000
Subject: [R-sig-ME] Random & fixed effects on same level
In-Reply-To: <mailman.7.1264071602.26832.r-sig-mixed-models@r-project.org>
References: <mailman.7.1264071602.26832.r-sig-mixed-models@r-project.org>
Message-ID: <C304C0D0-CC7A-44A9-B5DA-FB9A317A256D@bristol.ac.uk>

Dear Sebastiaan,

What you're proposing to do is entirely reasonable. In essence, as you say, you're using covariates to explain the variation across groups (or alternatively the clustering within groups) at different levels. Any introduction to multilevel modelling should cover this issue (e.g., http://www.cmm.bristol.ac.uk/learning-training/multilevel-models/index.shtml).

Cheers,
Malcolm


Dr Malcolm Fairbrother
Lecturer in Global Policy and Politics
School of Geographical Sciences
University of Bristol


> Message: 2
> Date: Wed, 20 Jan 2010 17:32:30 +0100
> From: "De Smedt Sebastiaan" <Sebastiaan.DeSmedt at ua.ac.be>
> To: <r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] Random & fixed effects on same level
> Message-ID:
> 	<930B1A45F446404FA4D99A46F09209C401540E0A at xmail05.ad.ua.ac.be>
> Content-Type: text/plain
> 
> Dear mailing list,
> 
> 
> 
> 
> 
> I have a model where I use leaf characteristics as response variables,
> and populations and trees (nested in populations) as random effects.
> After quantifying the variation associated with the different grouping
> levels (error/within trees/within populations), I've added fixed
> effects. I have information on population level (annual precipitation,
> soil characteristics ...). By adding explanatory variables on population
> level, can I still include 'population' as a random effect (without
> breaking any statistical rule)? My idea was that, by including a fixed
> effect, the fixed effect partially explains the variation added by a
> grouping variable, but now I'm hesitating a bit... Does anybody have
> some references on this topic?
> 
> 
> 
> 
> 
> Thanks in advance,
> 
> Sebastiaan   



From guiga82 at msn.com  Thu Jan 21 22:50:02 2010
From: guiga82 at msn.com (Guilherme Mazzochini)
Date: Thu, 21 Jan 2010 21:50:02 +0000
Subject: [R-sig-ME] How to do an split-plot design with glmer??
Message-ID: <COL102-W361EA955F6110F2317807EB2630@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100121/6b832017/attachment.pl>

From juliet.hannah at gmail.com  Fri Jan 22 04:01:04 2010
From: juliet.hannah at gmail.com (Juliet Hannah)
Date: Thu, 21 Jan 2010 22:01:04 -0500
Subject: [R-sig-ME] using R for linear mixed effects models
In-Reply-To: <1a2e445a1001171351k13d169a4gea0909c335ff9e98@mail.gmail.com>
References: <1a2e445a1001171351k13d169a4gea0909c335ff9e98@mail.gmail.com>
Message-ID: <93d6f2a81001211901u4ecdafeauda4a2abe5eafe7f3@mail.gmail.com>

It takes time to learn how to do these analyses. I think a good place to
start is working through the examples of an Intro graduate-level methods course.

I used Statistical Research methods in the life sciences by rao.

It gave nice simple examples related to the description you gave. There
are many books at this level. Once you
understand some simple models, the R code and output will seem
less mysterious. Then work your way through some examples with
a little more complexity, for example: Mixed-effects models in S and S-PLUS.

Also, if you are going to be involved in analysis, try and recruit a
statistician to
your committee.

Good luck.


On Sun, Jan 17, 2010 at 4:51 PM, Gina Garland <gmgarland at ucdavis.edu> wrote:
> Hello,
>
> ? I'm a Masters student at UC Davis and I'm trying to use R to produce a
> linear mixed effect model for my data on N2O emissions in agricultural
> ecosystems. I'm looking at the effects of management practices (such as
> fertilization and irrigation) as well as crop type, soil type, and other
> environmental factors on N2O emissions in California cropping systems.
> However, I'm having trouble finding specific examples on how to do it. I've
> never used a computer program like this before and I'm struggling on where
> to begin. Do you have any advice or specific examples that could point me in
> the right direction?
>
> Thanks,
> Gina
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From H.Quene at uu.nl  Fri Jan 22 10:28:34 2010
From: H.Quene at uu.nl (=?UTF-8?B?SHVnbyBRdWVuwo7DqQ==?=)
Date: Fri, 22 Jan 2010 10:28:34 +0100
Subject: [R-sig-ME] r examples of mixed models from scratch
Message-ID: <4B596FC2.1040903@uu.nl>

Dear Juliet, and list,
Perhaps some annotated examples of mine are helpful:
www.hugoquene.nl/mixedeffects
Best wishes, Hugo

> I'm trying to learn more about mixed models in detail. Does anyone know of
> any examples where code is provided showing simple examples of doing
> this from scratch. For example, setting up a likelihood, using optim, and things
> like that.

-- 
Dr Hugo Quen? | assoc prof Phonetics | Departement Moderne Talen | 
Utrecht inst of Linguistics OTS | Utrecht University | Trans 10 | room 
1.17 | 3512 JK Utrecht | The Netherlands | T +31 30 253 6070 | F +31 30 
253 6000 | H.Quene at uu.nl | www.hugoquene.nl | www.hum.uu.nl



From giacomo.santini at unifi.it  Fri Jan 22 10:55:43 2010
From: giacomo.santini at unifi.it (Giacomo Santini)
Date: Fri, 22 Jan 2010 10:55:43 +0100
Subject: [R-sig-ME] advice with lmer syntax
Message-ID: <4B59761F.50003@unifi.it>

Dear all,

here is my problem, a very  simple one indeed. I am new to mixed models 
and before go on with the analysis I wish to be sure I am rigth in  
model formulation.

My data set consists of  observations on the behaviour (say time active, 
Activity) of marine animals. I have 120 individually marked animals in 
three different randomly chosen sites (40 animals per site). I was 
interested in assessing if the behaviour changed during A) different 
seasons and  B) different tidal conditions.
For each animal in each site the behaviour was observed during three 
different randomly chosen days within each combination of Season (A) and 
Tide (B). Obviously each individual is specific to one of the three 
sites. In summary:

Season, fixed factor, 2 levels (Summer,    Winter)
Tide, fixed, 2 levels (Neap and Spring)
Site, random factor, 3 levels
Animal, random factor, 120 levels, nested within Site

I wish to analyse this data set using lme4. I guess the starting model 
to answer to questions A, B and C is

Mod1<- lmer(Activity~Season*Tide + (1|Site)+ (1|Site/Animal) , 
data=obsTot, REML=TRUE)

Now if I wish to check if the effect of Season and Tide differs in the 
different sites (altough I am not interested in these tree sites in 
particular) would it be correct to add to Mod1 terms like 
(1|Season:Site) and or, (1|Tide:Site)? Something like:

Mod2<- lmer(Activity~Season*Tide + (1|Site)+ (1|Site/Animal) + 
(1|Season:Site)+ (1|Tide:Site), data=obsTot, REML=TRUE)

Any suggetion is welcome

Cheers
Giacomo

-- 
-------------------------------------------------------
Giacomo Santini PhD
Dipartimento di Biologia Evoluzionistica "Leo Pardi"
Universita' degli Studi di Firenze
Via Romana 17
I-50125 Firenze
Italy

Tel: +39 055 2288288 (DBE) - +39 0574 447727 (CESPRO)
Fax: +39 055 2288289
www.dbe.unifi.it/santini



From Thierry.ONKELINX at inbo.be  Fri Jan 22 11:16:11 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Fri, 22 Jan 2010 11:16:11 +0100
Subject: [R-sig-ME] advice with lmer syntax
In-Reply-To: <4B59761F.50003@unifi.it>
References: <4B59761F.50003@unifi.it>
Message-ID: <2E9C414912813E4EB981326983E0A10406F2BC5B@inboexch.inbo.be>

Dear Giacomo,

You want a different random intercept for Season or Tide per site. Use
(Season|Site) instead of (1|Season:Site)

In your case I would not use site as a random site since you have only 3
sites. That won't give you a good estimate of the variance. Therefore I
would use Site as a fixed effect. It only requires one d.f. extra so
that should not be a big problem.

Mod1<- lmer(Activity~Season*Tide + Site+ (1|Site:Animal) , data=obsTot,
REML=TRUE)

The (1|Site:Animal) indicates a random effect per animal, assuming that
you reuse the animal Ids among sites. If all animals have a unique ID
you can use (1|Animal).

If you want to test the difference in Season effect among sites then you
just have to add the interaction between Season and Site.

HTH,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] Namens Giacomo Santini
Verzonden: vrijdag 22 januari 2010 10:56
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] advice with lmer syntax

Dear all,

here is my problem, a very  simple one indeed. I am new to mixed models
and before go on with the analysis I wish to be sure I am rigth in model
formulation.

My data set consists of  observations on the behaviour (say time active,
Activity) of marine animals. I have 120 individually marked animals in
three different randomly chosen sites (40 animals per site). I was
interested in assessing if the behaviour changed during A) different
seasons and  B) different tidal conditions.
For each animal in each site the behaviour was observed during three
different randomly chosen days within each combination of Season (A) and
Tide (B). Obviously each individual is specific to one of the three
sites. In summary:

Season, fixed factor, 2 levels (Summer,    Winter)
Tide, fixed, 2 levels (Neap and Spring)
Site, random factor, 3 levels
Animal, random factor, 120 levels, nested within Site

I wish to analyse this data set using lme4. I guess the starting model
to answer to questions A, B and C is

Mod1<- lmer(Activity~Season*Tide + (1|Site)+ (1|Site/Animal) ,
data=obsTot, REML=TRUE)

Now if I wish to check if the effect of Season and Tide differs in the
different sites (altough I am not interested in these tree sites in
particular) would it be correct to add to Mod1 terms like
(1|Season:Site) and or, (1|Tide:Site)? Something like:

Mod2<- lmer(Activity~Season*Tide + (1|Site)+ (1|Site/Animal) +
(1|Season:Site)+ (1|Tide:Site), data=obsTot, REML=TRUE)

Any suggetion is welcome

Cheers
Giacomo

--
-------------------------------------------------------
Giacomo Santini PhD
Dipartimento di Biologia Evoluzionistica "Leo Pardi"
Universita' degli Studi di Firenze
Via Romana 17
I-50125 Firenze
Italy

Tel: +39 055 2288288 (DBE) - +39 0574 447727 (CESPRO)
Fax: +39 055 2288289
www.dbe.unifi.it/santini

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From ritz at life.ku.dk  Fri Jan 22 11:55:41 2010
From: ritz at life.ku.dk (Christian Ritz)
Date: Fri, 22 Jan 2010 11:55:41 +0100
Subject: [R-sig-ME] advice with lmer syntax
In-Reply-To: <4B59761F.50003@unifi.it>
References: <4B59761F.50003@unifi.it>
Message-ID: <4B59842D.7040307@life.ku.dk>

Dear Giacomo,

I would prefer to include whichever random effects that could be relevant in the initial
model. Instead of checking afterwards by adding more terms and possibly even carry out a
significance tests!

For each random effects term I would ask a question such as:

Is it reasonable to assume that there could be random variation at this level? For
instance it seems sensible to me that there could be some random variation between season
in sites as (I guess) this would reflect variation between different time periods. So the
term (1|Season:Site) makes sense to me.

As you only have 3 sites there won't be that much variation to pick up be the random
effects you include (variation across 3 sites). However, I would still prefer to keep site
as a random effect in model as it is actually randomly chosen sites, and thus the model
reflects the design of the experiment.


Christian



From jpntsang at yahoo.com  Fri Jan 22 22:05:58 2010
From: jpntsang at yahoo.com (Juliet Ndukum)
Date: Fri, 22 Jan 2010 13:05:58 -0800 (PST)
Subject: [R-sig-ME] Meaning of parameters in nlme output
Message-ID: <275296.78818.qm@web53201.mail.re2.yahoo.com>



The data set Soybean.csv is the modified Soybean data set in the R nlme library. I wish to test the effect of the fixed effect Svariety which is a factor with three levels allen, fowler and glenn. In other words, I wish to investigate the effect of Svariety on the individual parameters i.e. beta, theta and lambda.

The file project.R contains the R code, whereby the self-starting three parameter logistic model SSlogis is used.

First concern, what is the meaning of the intercept term?
What is the meaning of the parameter estimates?

How do I compare variety allen with variety glenn for example? Since there are three levels, how many comparisons can I possibly have?

Thank you in advance for your help.


      

From jpntsang at yahoo.com  Sun Jan 24 20:51:37 2010
From: jpntsang at yahoo.com (Juliet Ndukum)
Date: Sun, 24 Jan 2010 11:51:37 -0800 (PST)
Subject: [R-sig-ME] Fw: Meaning of parameters in nlme output
Message-ID: <666410.66704.qm@web53205.mail.re2.yahoo.com>





----- Forwarded Message ----
From: Juliet Ndukum <jpntsang at yahoo.com>
To: R-SIG-Mixed-Models at R-project.org
Sent: Fri, January 22, 2010 4:05:58 PM
Subject: Meaning of parameters in nlme output




The data set Soybean.csv is the modified Soybean data set in the R nlme library. I wish to test the effect of the fixed effect Svariety which is a factor with three levels allen, fowler and glenn. In other words, I wish to investigate the effect of Svariety on the individual parameters i.e. beta, theta and lambda.

The file project.R contains the R code, whereby the self-starting three parameter logistic model SSlogis is used.

First concern, what is the meaning of the intercept term?
What is the meaning of the parameter estimates?

How do I compare variety allen with variety glenn for example? Since there are three levels, how many comparisons can I possibly have?

Thank you in advance for your help.


      

From jpntsang at yahoo.com  Mon Jan 25 01:41:19 2010
From: jpntsang at yahoo.com (Juliet Ndukum)
Date: Sun, 24 Jan 2010 16:41:19 -0800 (PST)
Subject: [R-sig-ME] Meaning of parameter estimates in nlme output
Message-ID: <221256.54759.qm@web53201.mail.re2.yahoo.com>

The data set Soybean.csv is the modified Soybean data set in the R nlme library. I wish to test the effect of the fixed effect Svariety which is a factor with three levels allen, fowler and glenn. In other words, I wish to investigate the effect of Svariety on the individual parameters i.e. beta, theta and lambda.

The file project.R contains the R code, whereby the self-starting three parameter logistic model SSlogis is used.

First concern, what is the meaning of the intercept term?
What is the meaning of the parameter estimates?

How do I compare variety allen with variety glenn for example? Since there are three levels, how many comparisons can I possibly have?

Thank you in advance for your help.

I believe email has been sent out more than once, I am so sorry for the mix-up. 


      

From marcelolaia at gmail.com  Mon Jan 25 03:55:06 2010
From: marcelolaia at gmail.com (Marcelo Laia)
Date: Mon, 25 Jan 2010 00:55:06 -0200
Subject: [R-sig-ME] Categorical data repeated on time analysis
Message-ID: <a35fc1811001241855n2f1a281ape278d7782a1aac27@mail.gmail.com>

I have posted a message on R-help (http://tinyurl.com/ybdgref) about
an experiment with categorical data along the time.

I do not explain very well my plot (nor my split).

I work with nematode and I put about 400 specimens on a Petri dishes
and divided it in three parts. Each part is analyzed on a time point.
This is the reason that I need to consider the living nematode, too.

I follow the Dennis suggestions  and have looked at lme4 functions,
lmer() and glmer(). Also, I looked at the archives of
r-sig-mixed-models, too. But, I dont't found any similar issue. I am a
biologist that know a litlle about statistics and a little more about
R.

I try to work with percentage, too, but I am not secure because the
data have a lot of zero (on the control, all nematode remain living).

What you suggest for me?

Have you a example for share? Or a paper? Or tutorial?

Thank you very much!

-- 
Marcelo Luiz de Laia
Lages - SC - Brazil
Linux user number 487797



From teplitsky at mnhn.fr  Mon Jan 25 15:03:23 2010
From: teplitsky at mnhn.fr (Celine Teplitsky)
Date: Mon, 25 Jan 2010 15:03:23 +0100
Subject: [R-sig-ME] estimates of between sex correlations
Message-ID: <4B5DA4AB.3010001@mnhn.fr>

Dear all,

I would like to fit a model to estimate between sex genetic correlations 
for 3 traits (3 same traits expressed both in males and females) using 
MCMCglmm. My problem is I don't understand how I can manage to fix the 
covariances between male and female traits to 0 for residual variance 
and permanent environment. Could anyone help me with this?

Many thanks in advance

All the best

Celine

-- 

Celine Teplitsky
D?partement Ecologie et Gestion de la Biodiversit? UMR 7204
Unit? Conservation des Esp?ces, Restauration et Suivi des Populations
Case Postale 51
55 rue Buffon 75005 Paris

Webpage :http://www2.mnhn.fr/cersp/spip.php?rubrique96
Fax : (33-1)-4079-3835
Phone: (33-1)-4079-3443



From dougadams53 at gmail.com  Mon Jan 25 21:29:24 2010
From: dougadams53 at gmail.com (Doug Adams)
Date: Mon, 25 Jan 2010 13:29:24 -0700
Subject: [R-sig-ME] Science Fair data
Message-ID: <74cfd9161001251229t73902338g1dbb2c02d9b2dcbf@mail.gmail.com>

Hi everyone,

I had posted a question on the R Help forum previously about my syntax
of what I was trying to do with this dataset...  But now I'd like to
get an opinion if I'm thinking about it correctly after all.  I've got
data for a science fair, and here's what I have for each student:

School District
School
Teacher
Division (Elementary, Junior, High)
Student, and several scores for each student project

My committee & I decided there aren't enough teachers within each
school to warrant using Teacher as a level in a hierarchical model, so
we decided to go with just 'School' and 'Average Student Project' as
the two levels in the model.  The problem is that sometimes there is
only 1 student from a given school, although it doesn't happen too
often.  Is HLM theory robust enough that that will still give pretty
reliable results?

Does this all sound correct so far?   :-)   And another question: if I
were to include District as a third level, would this look right?

lmer(score ~ division + (1|school|district), data=Age6m)

Thanks for reading my novel  :)

Doug Adams



From dougadams53 at gmail.com  Mon Jan 25 21:31:16 2010
From: dougadams53 at gmail.com (Doug Adams)
Date: Mon, 25 Jan 2010 13:31:16 -0700
Subject: [R-sig-ME] Science Fair data
In-Reply-To: <74cfd9161001251229t73902338g1dbb2c02d9b2dcbf@mail.gmail.com>
References: <74cfd9161001251229t73902338g1dbb2c02d9b2dcbf@mail.gmail.com>
Message-ID: <74cfd9161001251231x254bdb8ame60f028b9b9320c4@mail.gmail.com>

Whoops, I should say also that we're trying to test and see if
'Division' (representing student age) has a significant effect, (or
can be used to roughly predict) student score.


On Mon, Jan 25, 2010 at 1:29 PM, Doug Adams <dougadams53 at gmail.com> wrote:
> Hi everyone,
>
> I had posted a question on the R Help forum previously about my syntax
> of what I was trying to do with this dataset... ?But now I'd like to
> get an opinion if I'm thinking about it correctly after all. ?I've got
> data for a science fair, and here's what I have for each student:
>
> School District
> School
> Teacher
> Division (Elementary, Junior, High)
> Student, and several scores for each student project
>
> My committee & I decided there aren't enough teachers within each
> school to warrant using Teacher as a level in a hierarchical model, so
> we decided to go with just 'School' and 'Average Student Project' as
> the two levels in the model. ?The problem is that sometimes there is
> only 1 student from a given school, although it doesn't happen too
> often. ?Is HLM theory robust enough that that will still give pretty
> reliable results?
>
> Does this all sound correct so far? ? :-) ? And another question: if I
> were to include District as a third level, would this look right?
>
> lmer(score ~ division + (1|school|district), data=Age6m)
>
> Thanks for reading my novel ?:)
>
> Doug Adams
>



From desja004 at umn.edu  Mon Jan 25 21:46:23 2010
From: desja004 at umn.edu (Christopher David Desjardins)
Date: Mon, 25 Jan 2010 14:46:23 -0600
Subject: [R-sig-ME] Science Fair data
In-Reply-To: <74cfd9161001251229t73902338g1dbb2c02d9b2dcbf@mail.gmail.com>
References: <74cfd9161001251229t73902338g1dbb2c02d9b2dcbf@mail.gmail.com>
Message-ID: <4B5E031F.6070009@umn.edu>

I think ....

On 01/25/2010 02:29 PM, Doug Adams wrote:
> Hi everyone,
>
> I had posted a question on the R Help forum previously about my syntax
> of what I was trying to do with this dataset...  But now I'd like to
> get an opinion if I'm thinking about it correctly after all.  I've got
> data for a science fair, and here's what I have for each student:
>
> School District
> School
> Teacher
> Division (Elementary, Junior, High)
> Student, and several scores for each student project
>
> My committee&  I decided there aren't enough teachers within each
> school to warrant using Teacher as a level in a hierarchical model, so
> we decided to go with just 'School' and 'Average Student Project' as
> the two levels in the model.  The problem is that sometimes there is
> only 1 student from a given school, although it doesn't happen too
> often.  Is HLM theory robust enough that that will still give pretty
> reliable results?
>
> Does this all sound correct so far?   :-)   And another question: if I
> were to include District as a third level, would this look right?
>
> lmer(score ~ division + (1|school|district), data=Age6m)
>    
you want ...

lmer(score ~ division + (1|district/school), data=Age6m)

and not

lmer(score ~ division + (1|school|district), data=Age6m)


You want school nested within district correct? The first line specifies 
that. Or maybe you really wanted ...

lmer(score ~ division + (1|school + district), data=Age6m)


HTH,
Chris


> Thanks for reading my novel  :)
>
> Doug Adams
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From dougadams53 at gmail.com  Tue Jan 26 04:41:24 2010
From: dougadams53 at gmail.com (Doug Adams)
Date: Mon, 25 Jan 2010 20:41:24 -0700
Subject: [R-sig-ME] Science Fair data
In-Reply-To: <74cfd9161001251403i2b9cccbfx11b77bcaf0a9f778@mail.gmail.com>
References: <74cfd9161001251229t73902338g1dbb2c02d9b2dcbf@mail.gmail.com>
	<1264456076.24134.2.camel@musuko.spc.uchicago.edu>
	<74cfd9161001251403i2b9cccbfx11b77bcaf0a9f778@mail.gmail.com>
Message-ID: <74cfd9161001251941k26ec341r890285b4a55692b@mail.gmail.com>

> you want ...
>
> lmer(score ~ division + (1|district/school), data=Age6m)
>
> and not
>
> lmer(score ~ division + (1|school|district), data=Age6m)
>
>
> You want school nested within district correct? The first line specifies
> that. Or maybe you really wanted ...
>
> lmer(score ~ division + (1|school + district), data=Age6m)

Thanks; I think that makes sense.  What's the difference between
listing your factors as:

lmer(score ~ division + (1|district/school), data=Age6m)
and
lmer(score ~ division + (1|school) + district, data=Age6m)

since district is another level?  Sorry if that question is quite
'newbie.'   : )

Doug



From bates at stat.wisc.edu  Tue Jan 26 16:41:41 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 26 Jan 2010 09:41:41 -0600
Subject: [R-sig-ME] Science Fair data
In-Reply-To: <74cfd9161001251941k26ec341r890285b4a55692b@mail.gmail.com>
References: <74cfd9161001251229t73902338g1dbb2c02d9b2dcbf@mail.gmail.com>
	<1264456076.24134.2.camel@musuko.spc.uchicago.edu>
	<74cfd9161001251403i2b9cccbfx11b77bcaf0a9f778@mail.gmail.com>
	<74cfd9161001251941k26ec341r890285b4a55692b@mail.gmail.com>
Message-ID: <40e66e0b1001260741j287ac82bg88314db5cf7eab25@mail.gmail.com>

On Mon, Jan 25, 2010 at 9:41 PM, Doug Adams <dougadams53 at gmail.com> wrote:
>> you want ...
>>
>> lmer(score ~ division + (1|district/school), data=Age6m)
>>
>> and not
>>
>> lmer(score ~ division + (1|school|district), data=Age6m)
>>
>>
>> You want school nested within district correct? The first line specifies
>> that. Or maybe you really wanted ...
>>
>> lmer(score ~ division + (1|school + district), data=Age6m)
>
> Thanks; I think that makes sense.

Well, actually it doesn't.  If you tried that it would fail because
there is no addition operator for factors.

> What's the difference between
> listing your factors as:

> lmer(score ~ division + (1|district/school), data=Age6m)

In this model the effects of the district and the school are modeled
with random effects.  The model specification is equivalent to

 lmer(score ~ division + (1|district) + (1|school:district), Age6m)

and, if the levels of school are distinct (i.e. you don't have a
school 1 in both district 1 and district 2 or something like that),
then the specification is equivalent to

lmer(score ~ division + (1|district) + (1|school), Age6m)

> and
> lmer(score ~ division + (1|school) + district, data=Age6m)

In this model the effect of the school is modeled by random effects
but the effect of the district is modeled by fixed-effects parameters.

The choice of fixed effects or random effects depends on the structure
of the data and the type of inferences you wish to make.  If you have
data from only some of the school districts and you wish to form
conclusions about a generic district then random effects are
preferred.  If you have data from all districts and you want to reach
conclusions only about those specific districts then fixed effects are
preferred.  If you want to consider how the variability in the
responses splits into student-to-student variability and
school-to-school variability and district-to-district variability then
random effects are preferred.

>
> since district is another level? ?Sorry if that question is quite
> 'newbie.' ? : )
>
> Doug
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From desja004 at umn.edu  Tue Jan 26 17:28:01 2010
From: desja004 at umn.edu (Christopher David Desjardins)
Date: Tue, 26 Jan 2010 10:28:01 -0600
Subject: [R-sig-ME] Science Fair data
In-Reply-To: <40e66e0b1001260741j287ac82bg88314db5cf7eab25@mail.gmail.com>
References: <74cfd9161001251229t73902338g1dbb2c02d9b2dcbf@mail.gmail.com>	<1264456076.24134.2.camel@musuko.spc.uchicago.edu>	<74cfd9161001251403i2b9cccbfx11b77bcaf0a9f778@mail.gmail.com>	<74cfd9161001251941k26ec341r890285b4a55692b@mail.gmail.com>
	<40e66e0b1001260741j287ac82bg88314db5cf7eab25@mail.gmail.com>
Message-ID: <4B5F1811.7030901@umn.edu>



Douglas Bates wrote:
> On Mon, Jan 25, 2010 at 9:41 PM, Doug Adams <dougadams53 at gmail.com> wrote:
>   
>>> you want ...
>>>
>>> lmer(score ~ division + (1|district/school), data=Age6m)
>>>
>>> and not
>>>
>>> lmer(score ~ division + (1|school|district), data=Age6m)
>>>
>>>
>>> You want school nested within district correct? The first line specifies
>>> that. Or maybe you really wanted ...
>>>
>>> lmer(score ~ division + (1|school + district), data=Age6m)
>>>       
>> Thanks; I think that makes sense.
>>     
>
> Well, actually it doesn't.  If you tried that it would fail because
> there is no addition operator for factors.
>
>   
>> What's the difference between
>> listing your factors as:
>>     
>
>   
>> lmer(score ~ division + (1|district/school), data=Age6m)
>>     
>
> In this model the effects of the district and the school are modeled
> with random effects.  The model specification is equivalent to
>
>  lmer(score ~ division + (1|district) + (1|school:district), Age6m)
>
> and, if the levels of school are distinct (i.e. you don't have a
> school 1 in both district 1 and district 2 or something like that),
> then the specification is equivalent to
>
> lmer(score ~ division + (1|district) + (1|school), Age6m)
>   

Sorry I thought that

lmer(score ~ division + (1|district) + (1|school), Age6m)


Was equivalent to:

lmer(score ~ division + (1|school + district), Age6m)


>   
>> and
>> lmer(score ~ division + (1|school) + district, data=Age6m)
>>     
>
> In this model the effect of the school is modeled by random effects
> but the effect of the district is modeled by fixed-effects parameters.
>
> The choice of fixed effects or random effects depends on the structure
> of the data and the type of inferences you wish to make.  If you have
> data from only some of the school districts and you wish to form
> conclusions about a generic district then random effects are
> preferred.  If you have data from all districts and you want to reach
> conclusions only about those specific districts then fixed effects are
> preferred.  If you want to consider how the variability in the
> responses splits into student-to-student variability and
> school-to-school variability and district-to-district variability then
> random effects are preferred.
>
>   
>> since district is another level?  Sorry if that question is quite
>> 'newbie.'   : )
>>
>> Doug
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>     
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From fog0 at gmx.com  Wed Jan 27 05:10:07 2010
From: fog0 at gmx.com (Doug Adams)
Date: Tue, 26 Jan 2010 21:10:07 -0700
Subject: [R-sig-ME] Science Fair data
In-Reply-To: <4B5F1811.7030901@umn.edu>
References: <74cfd9161001251229t73902338g1dbb2c02d9b2dcbf@mail.gmail.com>
	<1264456076.24134.2.camel@musuko.spc.uchicago.edu>
	<74cfd9161001251403i2b9cccbfx11b77bcaf0a9f778@mail.gmail.com>
	<74cfd9161001251941k26ec341r890285b4a55692b@mail.gmail.com>
	<40e66e0b1001260741j287ac82bg88314db5cf7eab25@mail.gmail.com>
	<4B5F1811.7030901@umn.edu>
Message-ID: <74cfd9161001262010w66257672mfc766bfa3609f3a4@mail.gmail.com>

I appreciate that, both of you (& that's ok for the mistake Christopher)   :)

So fixed factors as simply listed by themselves (no 1| notation) and
random effects are listed with appropriate nesting...  I do want to
consider schools as random effects; that will give me the information
I'd like to have about the variability (and reliability too?) of the
schools as they fit into the big picture.

When I use fixef & ranef to extract estimates for division and schools
(& maybe districts eventually too now), am I right in thinking that
the 3 numbers given for each level of division (fixef) are the
intercepts for each level -- as if there were individual OLS
regressions performed for each?  And are the random effects for the
schools (ranef) are the slopes associated with those regression lines?

Thanks again everyone   :)

Doug




>>>
>>> What's the difference between
>>> listing your factors as:
>>>
>>>
>>> lmer(score ~ division + (1|district/school), data=Age6m)
>>>
>>
>> In this model the effects of the district and the school are modeled
>> with random effects. ?The model specification is equivalent to
>>
>> ?lmer(score ~ division + (1|district) + (1|school:district), Age6m)
>>
>> and, if the levels of school are distinct (i.e. you don't have a
>> school 1 in both district 1 and district 2 or something like that),
>> then the specification is equivalent to
>>
>> lmer(score ~ division + (1|district) + (1|school), Age6m)
>>
>>>
>>> and
>>> lmer(score ~ division + (1|school) + district, data=Age6m)
>>>
>>
>> In this model the effect of the school is modeled by random effects
>> but the effect of the district is modeled by fixed-effects parameters.
>>
>> The choice of fixed effects or random effects depends on the structure
>> of the data and the type of inferences you wish to make. ?If you have
>> data from only some of the school districts and you wish to form
>> conclusions about a generic district then random effects are
>> preferred. ?If you have data from all districts and you want to reach
>> conclusions only about those specific districts then fixed effects are
>> preferred. ?If you want to consider how the variability in the
>> responses splits into student-to-student variability and
>> school-to-school variability and district-to-district variability then
>> random effects are preferred.
>>



From dougadams53 at gmail.com  Tue Jan 26 04:46:42 2010
From: dougadams53 at gmail.com (Doug Adams)
Date: Mon, 25 Jan 2010 20:46:42 -0700
Subject: [R-sig-ME] using R for linear mixed effects models
Message-ID: <74cfd9161001251946g16df70f4ta762f04b02e85887@mail.gmail.com>

Hi Gina,

This website has been so helpful to me in my masters project (which
I'm still doing too, hah)...

http://statmethods.net/

It's helped me import & organize my data, get descriptives and perform
most of the analyses I've needed.
I hope that helps!

Doug Adams



From austen.thomas at gmail.com  Wed Jan 27 08:46:00 2010
From: austen.thomas at gmail.com (Austen Thomas)
Date: Tue, 26 Jan 2010 23:46:00 -0800
Subject: [R-sig-ME] Time series LME with nested fixed effects
Message-ID: <9d4eee51001262346u4abd4313s3e0abef7652f6bd0@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100126/ce82c87a/attachment.pl>

From bates at stat.wisc.edu  Wed Jan 27 16:07:59 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 27 Jan 2010 09:07:59 -0600
Subject: [R-sig-ME] Science Fair data
In-Reply-To: <74cfd9161001262010w66257672mfc766bfa3609f3a4@mail.gmail.com>
References: <74cfd9161001251229t73902338g1dbb2c02d9b2dcbf@mail.gmail.com>
	<1264456076.24134.2.camel@musuko.spc.uchicago.edu>
	<74cfd9161001251403i2b9cccbfx11b77bcaf0a9f778@mail.gmail.com>
	<74cfd9161001251941k26ec341r890285b4a55692b@mail.gmail.com>
	<40e66e0b1001260741j287ac82bg88314db5cf7eab25@mail.gmail.com>
	<4B5F1811.7030901@umn.edu>
	<74cfd9161001262010w66257672mfc766bfa3609f3a4@mail.gmail.com>
Message-ID: <40e66e0b1001270707vf94b18coc96c9720ed3683f0@mail.gmail.com>

On Tue, Jan 26, 2010 at 10:10 PM, Doug Adams <fog0 at gmx.com> wrote:
> I appreciate that, both of you (& that's ok for the mistake Christopher) ? :)

> So fixed factors as simply listed by themselves (no 1| notation) and
> random effects are listed with appropriate nesting... ?I do want to
> consider schools as random effects; that will give me the information
> I'd like to have about the variability (and reliability too?) of the
> schools as they fit into the big picture.

> When I use fixef & ranef to extract estimates for division and schools
> (& maybe districts eventually too now), am I right in thinking that
> the 3 numbers given for each level of division (fixef) are the
> intercepts for each level -- as if there were individual OLS
> regressions performed for each?

Not quite.  They should be labeled "(Intercept)" and something like
division2 and division 3.  (By the way, it helps if you quote the
output when you want to discussion what particular values mean.)  The
(Intercept) coefficient represents the prediction at the first level
of the division factor.  The next two coefficients are the change from
the first to the second level and from the first to the third level.

> And are the random effects for the
> schools (ranef) are the slopes associated with those regression lines?
>
> Thanks again everyone ? :)
>
> Doug
>
>
>
>
>>>>
>>>> What's the difference between
>>>> listing your factors as:
>>>>
>>>>
>>>> lmer(score ~ division + (1|district/school), data=Age6m)
>>>>
>>>
>>> In this model the effects of the district and the school are modeled
>>> with random effects. ?The model specification is equivalent to
>>>
>>> ?lmer(score ~ division + (1|district) + (1|school:district), Age6m)
>>>
>>> and, if the levels of school are distinct (i.e. you don't have a
>>> school 1 in both district 1 and district 2 or something like that),
>>> then the specification is equivalent to
>>>
>>> lmer(score ~ division + (1|district) + (1|school), Age6m)
>>>
>>>>
>>>> and
>>>> lmer(score ~ division + (1|school) + district, data=Age6m)
>>>>
>>>
>>> In this model the effect of the school is modeled by random effects
>>> but the effect of the district is modeled by fixed-effects parameters.
>>>
>>> The choice of fixed effects or random effects depends on the structure
>>> of the data and the type of inferences you wish to make. ?If you have
>>> data from only some of the school districts and you wish to form
>>> conclusions about a generic district then random effects are
>>> preferred. ?If you have data from all districts and you want to reach
>>> conclusions only about those specific districts then fixed effects are
>>> preferred. ?If you want to consider how the variability in the
>>> responses splits into student-to-student variability and
>>> school-to-school variability and district-to-district variability then
>>> random effects are preferred.
>>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From fog0 at gmx.com  Wed Jan 27 21:53:58 2010
From: fog0 at gmx.com (Doug Adams)
Date: Wed, 27 Jan 2010 13:53:58 -0700
Subject: [R-sig-ME] Science Fair data
In-Reply-To: <40e66e0b1001270707vf94b18coc96c9720ed3683f0@mail.gmail.com>
References: <74cfd9161001251229t73902338g1dbb2c02d9b2dcbf@mail.gmail.com>
	<1264456076.24134.2.camel@musuko.spc.uchicago.edu>
	<74cfd9161001251403i2b9cccbfx11b77bcaf0a9f778@mail.gmail.com>
	<74cfd9161001251941k26ec341r890285b4a55692b@mail.gmail.com>
	<40e66e0b1001260741j287ac82bg88314db5cf7eab25@mail.gmail.com>
	<4B5F1811.7030901@umn.edu>
	<74cfd9161001262010w66257672mfc766bfa3609f3a4@mail.gmail.com>
	<40e66e0b1001270707vf94b18coc96c9720ed3683f0@mail.gmail.com>
Message-ID: <74cfd9161001271253i41114833j9bf2c19a117a6bb8@mail.gmail.com>

Hi, and thanks again.  That makes sense with the 3 levels of division:

(Intercept) divisionJunior divisionSenior
     80.306526      -3.252372      -2.694055

...so that the Junior and Senior levels are both slightly lower than
the Elementary level.

I'd love to really understand the summary of lmer and what ranef,
fixef, coef and fitted are extracting - so that probably means I don't
understand the basics and nomenclature of HLMing as I thought I might
have.  I took a 1-week class on HLM, and I have the book you (Douglas
Bates) wrote...  Maybe I just need to study up on things a little
better!

Anyway, I appreciate your help very much   : )

Doug



On Wed, Jan 27, 2010 at 8:07 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
> On Tue, Jan 26, 2010 at 10:10 PM, Doug Adams <fog0 at gmx.com> wrote:
>> I appreciate that, both of you (& that's ok for the mistake Christopher) ? :)
>
>> So fixed factors as simply listed by themselves (no 1| notation) and
>> random effects are listed with appropriate nesting... ?I do want to
>> consider schools as random effects; that will give me the information
>> I'd like to have about the variability (and reliability too?) of the
>> schools as they fit into the big picture.
>
>> When I use fixef & ranef to extract estimates for division and schools
>> (& maybe districts eventually too now), am I right in thinking that
>> the 3 numbers given for each level of division (fixef) are the
>> intercepts for each level -- as if there were individual OLS
>> regressions performed for each?
>
> Not quite. ?They should be labeled "(Intercept)" and something like
> division2 and division 3. ?(By the way, it helps if you quote the
> output when you want to discussion what particular values mean.) ?The
> (Intercept) coefficient represents the prediction at the first level
> of the division factor. ?The next two coefficients are the change from
> the first to the second level and from the first to the third level.
>
>> And are the random effects for the
>> schools (ranef) are the slopes associated with those regression lines?



From andydolman at gmail.com  Wed Jan 27 22:23:47 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Wed, 27 Jan 2010 22:23:47 +0100
Subject: [R-sig-ME] Time series LME with nested fixed effects
In-Reply-To: <9d4eee51001262346u4abd4313s3e0abef7652f6bd0@mail.gmail.com>
References: <9d4eee51001262346u4abd4313s3e0abef7652f6bd0@mail.gmail.com>
Message-ID: <951234ac1001271323r7ca32abbxda3c0d9f59564bec@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100127/f658dde9/attachment.pl>

From ritz at life.ku.dk  Thu Jan 28 08:29:01 2010
From: ritz at life.ku.dk (Christian Ritz)
Date: Thu, 28 Jan 2010 08:29:01 +0100
Subject: [R-sig-ME] Time series LME with nested fixed effects
Message-ID: <4B613CBD.9090705@life.ku.dk>

Hi Austen,

apart from the residual error I could imagine that there are two additional layers of
variation in the experimental setup you've:

(1|seal) - variation between seals

(1|seal:season) - season-specific seal variation

(1|seal:season:period) - season- and period-specific seal variation


Far from sure that all sources will show up for an experiment only involving 5 seals. For
clarity, I would prefer using these three terms to using "(1|seal/season/period)", even
though I think the end result is this same as the latter is equivalent to:

(1|seal) + (1|seal:season) + (1|seal:season:period)


If there are no replicates (you didn't tell us about replicates...) the last term will be
redundant as it corresponds to the residual error term, which is anyway part of the model.
So in short your original model specification looks ok to me.


Christian



From Thierry.ONKELINX at inbo.be  Thu Jan 28 11:12:44 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 28 Jan 2010 11:12:44 +0100
Subject: [R-sig-ME] Trend in total number of animals
Message-ID: <2E9C414912813E4EB981326983E0A10406F91914@inboexch.inbo.be>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100128/8e07b841/attachment.pl>

From j.hadfield at ed.ac.uk  Thu Jan 28 13:57:04 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 28 Jan 2010 12:57:04 +0000
Subject: [R-sig-ME] Trend in total number of animals
In-Reply-To: <2E9C414912813E4EB981326983E0A10406F91914@inboexch.inbo.be>
References: <2E9C414912813E4EB981326983E0A10406F91914@inboexch.inbo.be>
Message-ID: <20100128125704.hn6nx4hrks4osw48@www.staffmail.ed.ac.uk>

Dear Thierry,

I THINK the fixed effect slope should be what you're after if you want  
to predict the change in log numbers, but simply exponentiating the  
prediction will not give you a true measure of the arithmetic increase.

The arithmetic prediction for years 1:10 (for example) when the slope  
variance for the year|room term is zero would be:

exp(b_year*1:10+0.5*(v1+v2))

where b_year is your slope estimate, and v1 is the year intercept  
variance and v2 is the room intercept variance.

When slope variance exists this becomes more difficult, because it  
implies the variance v2 changes as a function of year. In this case:

v2=diag(Z%*%V2%*%t(Z))

where

Z<-cbind(rep(1,10), 1:10)

and V2 is the covariance matrix of the room intercept-slopes.

Or if you like

v2 = V2[1,1]+(1:10)*V2[1,2]*2+(1:10^2)*V2[2,2]

Another difficulty is the possibility that your missing data are not  
"completely missing at random". By default lmer just seems to omit  
missing data rather than dealing with it properly, but perhaps there  
is an argument that can be passed to na.omit which suppresses this? If  
so, then the less strict assumption of "missing at random" can be  
made. In this latter case the missing data only have to be random  
conditional on the observed data - for example, if there were no bats  
in room A in year 1 which made the field workers less inclined to  
visit room A in year 2 based on their knowledge of the 1'st year's  
count.

Cheers,

Jarrod

Quoting "ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be>:

> Dear all,
>
> We are modelling the total numbers of hibarnating bats in a fortress. We
> have data of the number of bats per room spanning ten years. The main
> problem is that not all rooms were visited each year. The fieldworkers
> did not known or find all rooms and some rooms were not allways
> accessible.
>
> Some of the rooms were not counted in the early years and they contain a
> rather high number of bats in the more recent years. So a glm on the
> total observed number would be very biased. Therefore we would use a
> mixed model on the numbers of bats per room. The model looks like:
> glmer(Number ~ Year + (1|Year) + (Year|Room), family = poisson). Year is
> the long-term trend. (1|Year) allows for year-to-year variability (due
> to weatherconditions) and (Year|Room) allows for a random intercept and
> slope per room.
>
> Our main question about this model is the interpretation of the
> long-term trend (fixed effect of Year). Given the model specification it
> is the trend in an 'average' room from the population of rooms. Can we
> assume that this trend equals the trend in the total number of bats in
> the fortress. That would be the trend in to total observed numbers if we
> could have investigated every room in every year.
> Or is it better to use the model to simulate the total number of bats
> and then model this simulated totals using a simple glm? Repeating the
> simulations a large number of times would yield an average and
> confidence intervals for the trend.
>
> Best regards,
>
> Thierry
>
> ------------------------------------------------------------------------
> ----
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek
> team Biometrie & Kwaliteitszorg
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
>
> Research Institute for Nature and Forest
> team Biometrics & Quality Assurance
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
>
> tel. + 32 54/436 185
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to
> say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of
> data.
> ~ John Tukey
>
>
>
>
> Druk dit bericht a.u.b. niet onnodig af.
> Please do not print this message unnecessarily.
>
> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer
> en binden het INBO onder geen enkel beding, zolang dit bericht niet   
> bevestigd is
> door een geldig ondertekend document. The views expressed in  this message
> and any annex are purely those of the writer and may not be regarded  
>  as stating
> an official position of INBO, as long as the message is not   
> confirmed by a duly
> signed document.
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From austen.thomas at gmail.com  Thu Jan 28 02:27:37 2010
From: austen.thomas at gmail.com (Austen Thomas)
Date: Wed, 27 Jan 2010 17:27:37 -0800
Subject: [R-sig-ME] Time series LME with nested fixed effects
In-Reply-To: <951234ac1001271323r7ca32abbxda3c0d9f59564bec@mail.gmail.com>
References: <9d4eee51001262346u4abd4313s3e0abef7652f6bd0@mail.gmail.com>
	<951234ac1001271323r7ca32abbxda3c0d9f59564bec@mail.gmail.com>
Message-ID: <9d4eee51001271727i4edcc565l1a5d7999ade2fc2b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100127/96b300bc/attachment.pl>

From bates at stat.wisc.edu  Thu Jan 28 16:35:02 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 28 Jan 2010 09:35:02 -0600
Subject: [R-sig-ME] Science Fair data
In-Reply-To: <74cfd9161001271253i41114833j9bf2c19a117a6bb8@mail.gmail.com>
References: <74cfd9161001251229t73902338g1dbb2c02d9b2dcbf@mail.gmail.com>
	<1264456076.24134.2.camel@musuko.spc.uchicago.edu>
	<74cfd9161001251403i2b9cccbfx11b77bcaf0a9f778@mail.gmail.com>
	<74cfd9161001251941k26ec341r890285b4a55692b@mail.gmail.com>
	<40e66e0b1001260741j287ac82bg88314db5cf7eab25@mail.gmail.com>
	<4B5F1811.7030901@umn.edu>
	<74cfd9161001262010w66257672mfc766bfa3609f3a4@mail.gmail.com>
	<40e66e0b1001270707vf94b18coc96c9720ed3683f0@mail.gmail.com>
	<74cfd9161001271253i41114833j9bf2c19a117a6bb8@mail.gmail.com>
Message-ID: <40e66e0b1001280735r5c90ad8arf2c73a101aadc8b2@mail.gmail.com>

I'm writing a book about lme4 and lmer.  When it gets to the point
where others can read it without too much frowning and scratching of
heads, I will make chapter drafts available.

For the time being you may find the slides from a short course given
last summer informative.  They are at
http://lme4.R-forge.R-project.org/slides/2009-07-21-Seewiesen/

On Wed, Jan 27, 2010 at 2:53 PM, Doug Adams <fog0 at gmx.com> wrote:
> Hi, and thanks again. ?That makes sense with the 3 levels of division:
>
> (Intercept) divisionJunior divisionSenior
> ? ? 80.306526 ? ? ?-3.252372 ? ? ?-2.694055
>
> ...so that the Junior and Senior levels are both slightly lower than
> the Elementary level.
>
> I'd love to really understand the summary of lmer and what ranef,
> fixef, coef and fitted are extracting - so that probably means I don't
> understand the basics and nomenclature of HLMing as I thought I might
> have. ?I took a 1-week class on HLM, and I have the book you (Douglas
> Bates) wrote... ?Maybe I just need to study up on things a little
> better!
>
> Anyway, I appreciate your help very much ? : )
>
> Doug
>
>
>
> On Wed, Jan 27, 2010 at 8:07 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
>> On Tue, Jan 26, 2010 at 10:10 PM, Doug Adams <fog0 at gmx.com> wrote:
>>> I appreciate that, both of you (& that's ok for the mistake Christopher) ? :)
>>
>>> So fixed factors as simply listed by themselves (no 1| notation) and
>>> random effects are listed with appropriate nesting... ?I do want to
>>> consider schools as random effects; that will give me the information
>>> I'd like to have about the variability (and reliability too?) of the
>>> schools as they fit into the big picture.
>>
>>> When I use fixef & ranef to extract estimates for division and schools
>>> (& maybe districts eventually too now), am I right in thinking that
>>> the 3 numbers given for each level of division (fixef) are the
>>> intercepts for each level -- as if there were individual OLS
>>> regressions performed for each?
>>
>> Not quite. ?They should be labeled "(Intercept)" and something like
>> division2 and division 3. ?(By the way, it helps if you quote the
>> output when you want to discussion what particular values mean.) ?The
>> (Intercept) coefficient represents the prediction at the first level
>> of the division factor. ?The next two coefficients are the change from
>> the first to the second level and from the first to the third level.
>>
>>> And are the random effects for the
>>> schools (ranef) are the slopes associated with those regression lines?
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From fog0 at gmx.com  Thu Jan 28 17:48:06 2010
From: fog0 at gmx.com (Doug Adams)
Date: Thu, 28 Jan 2010 09:48:06 -0700
Subject: [R-sig-ME] Science Fair data
In-Reply-To: <40e66e0b1001280735r5c90ad8arf2c73a101aadc8b2@mail.gmail.com>
References: <74cfd9161001251229t73902338g1dbb2c02d9b2dcbf@mail.gmail.com>
	<1264456076.24134.2.camel@musuko.spc.uchicago.edu>
	<74cfd9161001251403i2b9cccbfx11b77bcaf0a9f778@mail.gmail.com>
	<74cfd9161001251941k26ec341r890285b4a55692b@mail.gmail.com>
	<40e66e0b1001260741j287ac82bg88314db5cf7eab25@mail.gmail.com>
	<4B5F1811.7030901@umn.edu>
	<74cfd9161001262010w66257672mfc766bfa3609f3a4@mail.gmail.com>
	<40e66e0b1001270707vf94b18coc96c9720ed3683f0@mail.gmail.com>
	<74cfd9161001271253i41114833j9bf2c19a117a6bb8@mail.gmail.com>
	<40e66e0b1001280735r5c90ad8arf2c73a101aadc8b2@mail.gmail.com>
Message-ID: <74cfd9161001280848u7192230ey1cc450405cf3c579@mail.gmail.com>

That's great!  Thanks!



On Thu, Jan 28, 2010 at 8:35 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
> I'm writing a book about lme4 and lmer. ?When it gets to the point
> where others can read it without too much frowning and scratching of
> heads, I will make chapter drafts available.
>
> For the time being you may find the slides from a short course given
> last summer informative. ?They are at
> http://lme4.R-forge.R-project.org/slides/2009-07-21-Seewiesen/
>
> On Wed, Jan 27, 2010 at 2:53 PM, Doug Adams <fog0 at gmx.com> wrote:
>> Hi, and thanks again. ?That makes sense with the 3 levels of division:
>>
>> (Intercept) divisionJunior divisionSenior
>> ? ? 80.306526 ? ? ?-3.252372 ? ? ?-2.694055
>>
>> ...so that the Junior and Senior levels are both slightly lower than
>> the Elementary level.
>>
>> I'd love to really understand the summary of lmer and what ranef,
>> fixef, coef and fitted are extracting - so that probably means I don't
>> understand the basics and nomenclature of HLMing as I thought I might
>> have. ?I took a 1-week class on HLM, and I have the book you (Douglas
>> Bates) wrote... ?Maybe I just need to study up on things a little
>> better!
>>
>> Anyway, I appreciate your help very much ? : )
>>
>> Doug



From j.hadfield at ed.ac.uk  Thu Jan 28 18:23:44 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 28 Jan 2010 17:23:44 +0000
Subject: [R-sig-ME] estimates of between sex correlations
In-Reply-To: <4B5DA4AB.3010001@mnhn.fr>
References: <4B5DA4AB.3010001@mnhn.fr>
Message-ID: <20100128172344.1nykjdyvwg0sg4wg@www.staffmail.ed.ac.uk>

Hi Celine,

Unfortunately I don't think the model you want to fit can be fitted in  
MCMCglmm. Currently only (conditional) diagonal and (conditional)  
block residual covariance matrices are implemented, and what you want  
is block diagonal. ASReml is probably you best way forward at the  
moment. If you are prepared to assume that the residual covariances  
for the 3 traits are equivalent in the two sexes then you can use  
rcov=~us(trait):sex:units.

  With respect to the permanent environment effects you can fit a  
block diagonal using

us(at.level(sex,1):trait):id+us(at.level(sex,2):trait):id

where id are the individual identifiers.

I may allow this type of syntax in the residual structure in the near future.

Cheers,

Jarrod


Quoting Celine Teplitsky <teplitsky at mnhn.fr>:

> Dear all,
>
> I would like to fit a model to estimate between sex genetic
> correlations for 3 traits (3 same traits expressed both in males and
> females) using MCMCglmm. My problem is I don't understand how I can
> manage to fix the covariances between male and female traits to 0 for
> residual variance and permanent environment. Could anyone help me with
> this?
>
> Many thanks in advance
>
> All the best
>
> Celine
>
> -- 
>
> Celine Teplitsky
> D?partement Ecologie et Gestion de la Biodiversit? UMR 7204
> Unit? Conservation des Esp?ces, Restauration et Suivi des Populations
> Case Postale 51
> 55 rue Buffon 75005 Paris
>
> Webpage :http://www2.mnhn.fr/cersp/spip.php?rubrique96
> Fax : (33-1)-4079-3835
> Phone: (33-1)-4079-3443
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From David.Duffy at qimr.edu.au  Thu Jan 28 22:25:27 2010
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Fri, 29 Jan 2010 07:25:27 +1000 (EST)
Subject: [R-sig-ME] Trend in total number of animals
In-Reply-To: <2E9C414912813E4EB981326983E0A10406F91914@inboexch.inbo.be>
References: <2E9C414912813E4EB981326983E0A10406F91914@inboexch.inbo.be>
Message-ID: <Pine.LNX.4.64.1001290717440.16167@orpheus.qimr.edu.au>

On Thu, 28 Jan 2010, ONKELINX, Thierry wrote:

> We are modelling the total numbers of hibernating bats in a fortress. We
> have data of the number of bats per room spanning ten years. The main
> problem is that not all rooms were visited each year. The fieldworkers
> did not known or find all rooms and some rooms were not allways
> accessible.
>
> Some of the rooms were not counted in the early years and they contain a
> rather high number of bats in the more recent years.

I would try (fixed-effects) log-linear models for incomplete tables as 
well, to deal with the sampling (I have written an R package "gllm", that 
may be suitable).  Then you could compare the estimates of total counts to 
the GLMM results.  If you are going to simulate, you might might as well 
go to BUGS.

Cheers, David.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From bates at stat.wisc.edu  Thu Jan 28 23:29:58 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 28 Jan 2010 16:29:58 -0600
Subject: [R-sig-ME] Trend in total number of animals
In-Reply-To: <20100128125704.hn6nx4hrks4osw48@www.staffmail.ed.ac.uk>
References: <2E9C414912813E4EB981326983E0A10406F91914@inboexch.inbo.be>
	<20100128125704.hn6nx4hrks4osw48@www.staffmail.ed.ac.uk>
Message-ID: <40e66e0b1001281429g4381d7c7tc492bb328ce50259@mail.gmail.com>

On Thu, Jan 28, 2010 at 6:57 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
> Dear Thierry,
>
> I THINK the fixed effect slope should be what you're after if you want to
> predict the change in log numbers, but simply exponentiating the prediction
> will not give you a true measure of the arithmetic increase.

I too think that the fixed-effect slope should be an estimate of the
population slope on the log(count) scale, except for the usual
problems with counts of zero and, in this case, the (1|Year) random
effects term.  I can appreciate that you may want to incorporate year
to year variability due to weather conditions in the model but I'm not
sure what the effect of that on the fixed effect for Year would be.  I
could imagine an argument for them not interfering with each other
(the fixed effect is measuring the trend and the random effect
measures year-to-year variability around the trend line) but I am not
confident of that argument.

> The arithmetic prediction for years 1:10 (for example) when the slope.
> variance for the year|room term is zero would be:
>
> exp(b_year*1:10+0.5*(v1+v2))
>
> where b_year is your slope estimate, and v1 is the year intercept variance
> and v2 is the room intercept variance.
>
> When slope variance exists this becomes more difficult, because it implies
> the variance v2 changes as a function of year. In this case:
>
> v2=diag(Z%*%V2%*%t(Z))
>
> where
>
> Z<-cbind(rep(1,10), 1:10)
>
> and V2 is the covariance matrix of the room intercept-slopes.
>
> Or if you like
>
> v2 = V2[1,1]+(1:10)*V2[1,2]*2+(1:10^2)*V2[2,2]
>
> Another difficulty is the possibility that your missing data are not
> "completely missing at random". By default lmer just seems to omit missing
> data rather than dealing with it properly, but perhaps there is an argument
> that can be passed to na.omit which suppresses this?

I'm not sure what you mean by "dealing with it properly".  Are you
considering some form of imputation?

My general approach is that, because the methods in lmer allow for
unbalanced data, there would not be a purpose in imputing counts that
were not observed.  I presume that when Number is observed the Year
and Room are also recorded (otherwise you should get rid of some of
the members of your field crew).  The only benefit that I could
imagine for imputing cases that were not observed would be if the
computational methods required balanced data.

Perhaps I am misunderstanding what you are getting at here, Jarrod.
>  If so, then the less
> strict assumption of "missing at random" can be made. In this latter case
> the missing data only have to be random conditional on the observed data -
> for example, if there were no bats in room A in year 1 which made the field
> workers less inclined to visit room A in year 2 based on their knowledge of
> the 1'st year's count.
>
> Cheers,
>
> Jarrod
>
> Quoting "ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be>:
>
>> Dear all,
>>
>> We are modelling the total numbers of hibarnating bats in a fortress. We
>> have data of the number of bats per room spanning ten years. The main
>> problem is that not all rooms were visited each year. The fieldworkers
>> did not known or find all rooms and some rooms were not allways
>> accessible.
>>
>> Some of the rooms were not counted in the early years and they contain a
>> rather high number of bats in the more recent years. So a glm on the
>> total observed number would be very biased. Therefore we would use a
>> mixed model on the numbers of bats per room. The model looks like:
>> glmer(Number ~ Year + (1|Year) + (Year|Room), family = poisson). Year is
>> the long-term trend. (1|Year) allows for year-to-year variability (due
>> to weatherconditions) and (Year|Room) allows for a random intercept and
>> slope per room.
>>
>> Our main question about this model is the interpretation of the
>> long-term trend (fixed effect of Year). Given the model specification it
>> is the trend in an 'average' room from the population of rooms. Can we
>> assume that this trend equals the trend in the total number of bats in
>> the fortress. That would be the trend in to total observed numbers if we
>> could have investigated every room in every year.
>> Or is it better to use the model to simulate the total number of bats
>> and then model this simulated totals using a simple glm? Repeating the
>> simulations a large number of times would yield an average and
>> confidence intervals for the trend.
>>
>> Best regards,
>>
>> Thierry
>>
>> ------------------------------------------------------------------------
>> ----
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek
>> team Biometrie & Kwaliteitszorg
>> Gaverstraat 4
>> 9500 Geraardsbergen
>> Belgium
>>
>> Research Institute for Nature and Forest
>> team Biometrics & Quality Assurance
>> Gaverstraat 4
>> 9500 Geraardsbergen
>> Belgium
>>
>> tel. + 32 54/436 185
>> Thierry.Onkelinx at inbo.be
>> www.inbo.be
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to
>> say what the experiment died of.
>> ~ Sir Ronald Aylmer Fisher
>>
>> The plural of anecdote is not data.
>> ~ Roger Brinner
>>
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of
>> data.
>> ~ John Tukey
>>
>>
>>
>>
>> Druk dit bericht a.u.b. niet onnodig af.
>> Please do not print this message unnecessarily.
>>
>> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver
>> weer
>> en binden het INBO onder geen enkel beding, zolang dit bericht niet
>> ?bevestigd is
>> door een geldig ondertekend document. The views expressed in ?this message
>> and any annex are purely those of the writer and may not be regarded ?as
>> stating
>> an official position of INBO, as long as the message is not ?confirmed by
>> a duly
>> signed document.
>>
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From nikko at hailmail.net  Fri Jan 29 00:48:40 2010
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Thu, 28 Jan 2010 15:48:40 -0800
Subject: [R-sig-ME] (no subject)
In-Reply-To: <mailman.317.1264673655.18074.r-sig-mixed-models@r-project.org>
References: <mailman.317.1264673655.18074.r-sig-mixed-models@r-project.org>
Message-ID: <1264722520.13870.1357141535@webmail.messagingengine.com>

Hi Thierry,
The other responses you've gotten all address your question. I was
wondering
if you had considered coverage estimators? These are used to address
problems
of census undercount, which seems to be the issue here. Anne Chao has
written
a great deal on this, and there is a vast literature on estimating the
number
of species in a community which uses similar models. Just a thought.

Nicholas

> Date: Thu, 28 Jan 2010 11:12:44 +0100
> From: "ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be>
> To: <r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] Trend in total number of animals
> Message-ID:
> 	<2E9C414912813E4EB981326983E0A10406F91914 at inboexch.inbo.be>
> Content-Type: text/plain
> 
> Dear all,
>  
> We are modelling the total numbers of hibarnating bats in a fortress. We
> have data of the number of bats per room spanning ten years. The main
> problem is that not all rooms were visited each year. The fieldworkers
> did not known or find all rooms and some rooms were not allways
> accessible.
>  
> Some of the rooms were not counted in the early years and they contain a
> rather high number of bats in the more recent years. So a glm on the
> total observed number would be very biased. Therefore we would use a
> mixed model on the numbers of bats per room. The model looks like:
> glmer(Number ~ Year + (1|Year) + (Year|Room), family = poisson). Year is
> the long-term trend. (1|Year) allows for year-to-year variability (due
> to weatherconditions) and (Year|Room) allows for a random intercept and
> slope per room.
>  
> Our main question about this model is the interpretation of the
> long-term trend (fixed effect of Year). Given the model specification it
> is the trend in an 'average' room from the population of rooms. Can we
> assume that this trend equals the trend in the total number of bats in
> the fortress. That would be the trend in to total observed numbers if we
> could have investigated every room in every year.
> Or is it better to use the model to simulate the total number of bats
> and then model this simulated totals using a simple glm? Repeating the
> simulations a large number of times would yield an average and
> confidence intervals for the trend.
>  
> Best regards,
>  
> Thierry
> 
> ------------------------------------------------------------------------
> ----
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek
> team Biometrie & Kwaliteitszorg
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
> 
> Research Institute for Nature and Forest
> team Biometrics & Quality Assurance
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
> 
> tel. + 32 54/436 185
> Thierry.Onkelinx at inbo.be
> www.inbo.be
> 
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to
> say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
> 
> The plural of anecdote is not data.
> ~ Roger Brinner
> 
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of
> data.
> ~ John Tukey
>   
> 
> 
> 
> Druk dit bericht a.u.b. niet onnodig af.
> Please do not print this message unnecessarily.
> 
> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver
> weer 
> en binden het INBO onder geen enkel beding, zolang dit bericht niet
> bevestigd is
> door een geldig ondertekend document. The views expressed in  this
> message
> and any annex are purely those of the writer and may not be regarded as
> stating 
> an official position of INBO, as long as the message is not confirmed by
> a duly 
> signed document.
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------
> 
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> End of R-sig-mixed-models Digest, Vol 37, Issue 19
> **************************************************



From Antonio.Gasparrini at lshtm.ac.uk  Fri Jan 29 03:02:45 2010
From: Antonio.Gasparrini at lshtm.ac.uk (Antonio.Gasparrini at lshtm.ac.uk)
Date: Fri, 29 Jan 2010 02:02:45 +0000
Subject: [R-sig-ME] Poisson mixed models with glmer and glmmPQL
Message-ID: <4B6241C5.5572.00B2.1@lshtm.ac.uk>

Dear R user,
 
I'm running an analysis on the trend of rates of acute myocardial infarction in 20 regions.
I want to specify both the national and the region-specific trends with a polynomial function. The latter are included as random effects in a model with region as grouping factor.
I tried to use both 'glmmPQL' (package MASS) and 'glmer' (package lme4), the former being more flexible in the choice of var-covar structure, the second known as more robust.
 
Here you can find the code (stdpop in the standardized population size, seasonality is modelled with harmonic functions of month):
 
pql.model <- glmmPQL(outcome ~ offset(log(stdpop)) + poly(time,3) + 
 harmonic(month,3,12), random=list(region=pdSymm(~poly(time,3))), family=poisson, data)
 
glmer.model <- glmer(outcome ~ offset(log(stdpop)) + poly(time,3) + 
 harmonic(mm,3,12) + (poly(time,3)|region), family=poisson, data)
 
I have 2 questions:
 
1) If a specify the pql.model with pdSymm as above, or with a simple argument 'random=~poly(time,3)|region', I got different results. Very small changes, but not exactly the same anyway. I also realized the latter simpler formula included here use a log-Cholesky parametrization, while the former does not. I had some convergence problem with the simpler formula, not with the pdSymm specification. Can someone give me some explanation/suggestion?
 
2) More importantly, the pql.model returns a value of sigma (pql.model$sigma) higher than 1. I interpreted it as a within-group error parameter which can explain some overdispersion in the data. Conversely, the glmer.model gives sigma=1 ( attributes(summary(glmerpoly3))$sigma ), although the estimates being practically identical to pql.model. Do you think the glmer.model included a within-group parameter as well, or not?
 
Thanks for your help

Antonio Gasparrini
Public and Environmental Health Research Unit (PEHRU)
London School of Hygiene & Tropical Medicine
Keppel Street, London WC1E 7HT, UK
Office: 0044 (0)20 79272406 - Mobile: 0044 (0)79 64925523
Skype contact: a.gasparrini
http://www.lshtm.ac.uk/people/gasparrini.antonio ( http://www.lshtm.ac.uk/pehru/ )



From j.hadfield at ed.ac.uk  Fri Jan 29 03:11:24 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 29 Jan 2010 02:11:24 +0000
Subject: [R-sig-ME] Trend in total number of animals
In-Reply-To: <40e66e0b1001281429g4381d7c7tc492bb328ce50259@mail.gmail.com>
References: <2E9C414912813E4EB981326983E0A10406F91914@inboexch.inbo.be>
	<20100128125704.hn6nx4hrks4osw48@www.staffmail.ed.ac.uk>
	<40e66e0b1001281429g4381d7c7tc492bb328ce50259@mail.gmail.com>
Message-ID: <20100129021124.9ifwbexassookg4s@www.staffmail.ed.ac.uk>

Dear Doug,

Perhaps I misunderstand Rubin's missing data theory, and/or perhaps  
its not relevant to Thierry's problem.

I was under the impression that if the probability of missingness  
depends on the value observed for some other data (MAR), then by  
including this data and structuring the likelihood correctly then  
correct inferences (i.e. in the absence of missingness) could be made.  
Given that the default na.action of lmer seems to deletes other data  
(complete case analysis), it is hard to see how the other data can be  
used to 'correct' for missingness. MCMCglmm uses augmentation for  
missing data. Internally, this is often used just to simplify/speed up  
the matrix operations using dummy data.  However, I had presumed that  
if users really did have MAR data then the augmentation would take  
care of this. I know ASReml has an na.includeY argument so presumably  
there is something to be gained by not reducing the problem to a  
complete-case analysis, but perhaps this function is there just to  
allow users to make predictions for missing data points. I know the  
asreml team read this list, so perhaps they could comment?

Cheers,

Jarrod




Quoting Douglas Bates <bates at stat.wisc.edu>:

> On Thu, Jan 28, 2010 at 6:57 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>> Dear Thierry,
>>
>> I THINK the fixed effect slope should be what you're after if you want to
>> predict the change in log numbers, but simply exponentiating the prediction
>> will not give you a true measure of the arithmetic increase.
>
> I too think that the fixed-effect slope should be an estimate of the
> population slope on the log(count) scale, except for the usual
> problems with counts of zero and, in this case, the (1|Year) random
> effects term.  I can appreciate that you may want to incorporate year
> to year variability due to weather conditions in the model but I'm not
> sure what the effect of that on the fixed effect for Year would be.  I
> could imagine an argument for them not interfering with each other
> (the fixed effect is measuring the trend and the random effect
> measures year-to-year variability around the trend line) but I am not
> confident of that argument.
>
>> The arithmetic prediction for years 1:10 (for example) when the slope.
>> variance for the year|room term is zero would be:
>>
>> exp(b_year*1:10+0.5*(v1+v2))
>>
>> where b_year is your slope estimate, and v1 is the year intercept variance
>> and v2 is the room intercept variance.
>>
>> When slope variance exists this becomes more difficult, because it implies
>> the variance v2 changes as a function of year. In this case:
>>
>> v2=diag(Z%*%V2%*%t(Z))
>>
>> where
>>
>> Z<-cbind(rep(1,10), 1:10)
>>
>> and V2 is the covariance matrix of the room intercept-slopes.
>>
>> Or if you like
>>
>> v2 = V2[1,1]+(1:10)*V2[1,2]*2+(1:10^2)*V2[2,2]
>>
>> Another difficulty is the possibility that your missing data are not
>> "completely missing at random". By default lmer just seems to omit missing
>> data rather than dealing with it properly, but perhaps there is an argument
>> that can be passed to na.omit which suppresses this?
>
> I'm not sure what you mean by "dealing with it properly".  Are you
> considering some form of imputation?
>
> My general approach is that, because the methods in lmer allow for
> unbalanced data, there would not be a purpose in imputing counts that
> were not observed.  I presume that when Number is observed the Year
> and Room are also recorded (otherwise you should get rid of some of
> the members of your field crew).  The only benefit that I could
> imagine for imputing cases that were not observed would be if the
> computational methods required balanced data.
>
> Perhaps I am misunderstanding what you are getting at here, Jarrod.
>>  If so, then the less
>> strict assumption of "missing at random" can be made. In this latter case
>> the missing data only have to be random conditional on the observed data -
>> for example, if there were no bats in room A in year 1 which made the field
>> workers less inclined to visit room A in year 2 based on their knowledge of
>> the 1'st year's count.
>>
>> Cheers,
>>
>> Jarrod
>>
>> Quoting "ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be>:
>>
>>> Dear all,
>>>
>>> We are modelling the total numbers of hibarnating bats in a fortress. We
>>> have data of the number of bats per room spanning ten years. The main
>>> problem is that not all rooms were visited each year. The fieldworkers
>>> did not known or find all rooms and some rooms were not allways
>>> accessible.
>>>
>>> Some of the rooms were not counted in the early years and they contain a
>>> rather high number of bats in the more recent years. So a glm on the
>>> total observed number would be very biased. Therefore we would use a
>>> mixed model on the numbers of bats per room. The model looks like:
>>> glmer(Number ~ Year + (1|Year) + (Year|Room), family = poisson). Year is
>>> the long-term trend. (1|Year) allows for year-to-year variability (due
>>> to weatherconditions) and (Year|Room) allows for a random intercept and
>>> slope per room.
>>>
>>> Our main question about this model is the interpretation of the
>>> long-term trend (fixed effect of Year). Given the model specification it
>>> is the trend in an 'average' room from the population of rooms. Can we
>>> assume that this trend equals the trend in the total number of bats in
>>> the fortress. That would be the trend in to total observed numbers if we
>>> could have investigated every room in every year.
>>> Or is it better to use the model to simulate the total number of bats
>>> and then model this simulated totals using a simple glm? Repeating the
>>> simulations a large number of times would yield an average and
>>> confidence intervals for the trend.
>>>
>>> Best regards,
>>>
>>> Thierry
>>>
>>> ------------------------------------------------------------------------
>>> ----
>>> ir. Thierry Onkelinx
>>> Instituut voor natuur- en bosonderzoek
>>> team Biometrie & Kwaliteitszorg
>>> Gaverstraat 4
>>> 9500 Geraardsbergen
>>> Belgium
>>>
>>> Research Institute for Nature and Forest
>>> team Biometrics & Quality Assurance
>>> Gaverstraat 4
>>> 9500 Geraardsbergen
>>> Belgium
>>>
>>> tel. + 32 54/436 185
>>> Thierry.Onkelinx at inbo.be
>>> www.inbo.be
>>>
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to
>>> say what the experiment died of.
>>> ~ Sir Ronald Aylmer Fisher
>>>
>>> The plural of anecdote is not data.
>>> ~ Roger Brinner
>>>
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of
>>> data.
>>> ~ John Tukey
>>>
>>>
>>>
>>>
>>> Druk dit bericht a.u.b. niet onnodig af.
>>> Please do not print this message unnecessarily.
>>>
>>> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver
>>> weer
>>> en binden het INBO onder geen enkel beding, zolang dit bericht niet
>>> ?bevestigd is
>>> door een geldig ondertekend document. The views expressed in ?this message
>>> and any annex are purely those of the writer and may not be regarded ?as
>>> stating
>>> an official position of INBO, as long as the message is not ?confirmed by
>>> a duly
>>> signed document.
>>>
>>> ? ? ? ?[[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From damian.collins at industry.nsw.gov.au  Fri Jan 29 06:51:02 2010
From: damian.collins at industry.nsw.gov.au (damian.collins at industry.nsw.gov.au)
Date: Fri, 29 Jan 2010 16:51:02 +1100
Subject: [R-sig-ME] Fw: re: Trend in total number of animals
Message-ID: <OFAE28BDF2.EED9F92E-ONCA2576BA.00202359-CA2576BA.00202385@dpi.nsw.gov.au>


Dear Jarrod,

You asked about ASReml's na.include=Y option.

No, this does not do any fancy imputation or augmentation like MCMCglmm
does either.

As you can read on p113 of the user guide (p139 of the pdf)
http://www.vsni.co.uk/downloads/asreml/release3/UserGuide.pdf
!mvinclude just imputes zeros. This obviously assumes centred covariates.
For factors, another factor level is created.

Damian

Damian Collins, Biometrician, I&I NSW
damian.collins at industry.nsw.gov.au

>Dear Doug,

>Perhaps I misunderstand Rubin's missing data theory, and/or perhaps
>its not relevant to Thierry's problem.


>I was under the impression that if the probability of missingness
>depends on the value observed for some other data (MAR), then by
>including this data and structuring the likelihood correctly then
>correct inferences (i.e. in the absence of missingness) could be made.
>Given that the default na.action of lmer seems to deletes other data
>(complete case analysis), it is hard to see how the other data can be
>used to 'correct' for missingness. MCMCglmm uses augmentation for
>missing data. Internally, this is often used just to simplify/speed up
>the matrix operations using dummy data. ?However, I had presumed that
>if users really did have MAR data then the augmentation would take
>care of this. I know ASReml has an na.includeY argument so presumably
>there is something to be gained by not reducing the problem to a
>complete-case analysis, but perhaps this function is there just to
>allow users to make predictions for missing data points. I know the
>asreml team read this list, so perhaps they could comment?

>Cheers,
>Jarrod,


This message is intended for the addressee named and may contain confidential information. If you are not the intended recipient, please delete it and notify the sender. Views expressed in this message are those of the individual sender, and are not necessarily the views of their organisation.




From lamprianou at yahoo.com  Fri Jan 29 07:09:12 2010
From: lamprianou at yahoo.com (Iasonas Lamprianou)
Date: Thu, 28 Jan 2010 22:09:12 -0800 (PST)
Subject: [R-sig-ME] raters
In-Reply-To: <mailman.422.1264713966.18074.r-sig-mixed-models@r-project.org>
Message-ID: <643461.79630.qm@web58904.mail.re1.yahoo.com>

Good morning colleagues,
I have a dataset where 100 raters (teachers who mark student responses to examination questions) participated to a number of examinations. Not everybofy participated to each examination. For example, one rater may have participated to only 2 examinations, and another rater may have participated to 12 examinations. The examinations do not happen at regular intervals i.e. sometimes a month may pass between two examinations, sometimes the distance between two examinations may be nine months. So, we have a situation where diffrent people participated to a different number of examinations and the distance between the examinations is not constant. Every time a rater participates to one examination, he is awarded some statistical indications of his/her rating profile: accuracy, consistency, restriction of range (he only uses part of the rating scale) etc. 
I need to investigate (a) if the are raters who follow specific patterns e.g. the more the exminations they participate, the more consistent they become, or the more accurate they become. (b)I want to check if there is statistically significant variability between the raters' statistics. In every case, I want to use the time that elaplses between exams as a covariate. 

How can I do the above two points using lme?  


Dr. Iasonas Lamprianou


Assistant Professor (Educational Research and Evaluation)
Department of Education Sciences
European University-Cyprus
P.O. Box 22006
1516 Nicosia
Cyprus 
Tel.: +357-22-713178
Fax: +357-22-590539


Honorary Research Fellow
Department of Education
The University of Manchester
Oxford Road, Manchester M13 9PL, UK
Tel. 0044  161 275 3485
iasonas.lamprianou at manchester.ac.uk


--- On Thu, 28/1/10, r-sig-mixed-models-request at r-project.org <r-sig-mixed-models-request at r-project.org> wrote:

> From: r-sig-mixed-models-request at r-project.org <r-sig-mixed-models-request at r-project.org>
> Subject: R-sig-mixed-models Digest, Vol 37, Issue 20
> To: r-sig-mixed-models at r-project.org
> Date: Thursday, 28 January, 2010, 21:26
> Send R-sig-mixed-models mailing list
> submissions to
> ??? r-sig-mixed-models at r-project.org
> 
> To subscribe or unsubscribe via the World Wide Web, visit
> ??? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help'
> to
> ??? r-sig-mixed-models-request at r-project.org
> 
> You can reach the person managing the list at
> ??? r-sig-mixed-models-owner at r-project.org
> 
> When replying, please edit your Subject line so it is more
> specific
> than "Re: Contents of R-sig-mixed-models digest..."
> 
> 
> Today's Topics:
> 
> ???1. Re: Trend in total number of animals
> (Jarrod Hadfield)
> ???2. Re: Time series LME with nested fixed
> effects (Austen Thomas)
> ???3. Re: Science Fair data (Douglas Bates)
> ???4. Re: Science Fair data (Doug Adams)
> ???5. Re: estimates of between sex
> correlations (Jarrod Hadfield)
> ???6. Re: Trend in total number of animals
> (David Duffy)
> 
> 
> ----------------------------------------------------------------------
> 
> Message: 1
> Date: Thu, 28 Jan 2010 12:57:04 +0000
> From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
> To: "ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Trend in total number of animals
> Message-ID: <20100128125704.hn6nx4hrks4osw48 at www.staffmail.ed.ac.uk>
> Content-Type: text/plain;???
> charset=ISO-8859-1;??? DelSp="Yes";
> ??? format="flowed"
> 
> Dear Thierry,
> 
> I THINK the fixed effect slope should be what you're after
> if you want? 
> to predict the change in log numbers, but simply
> exponentiating the? 
> prediction will not give you a true measure of the
> arithmetic increase.
> 
> The arithmetic prediction for years 1:10 (for example) when
> the slope? 
> variance for the year|room term is zero would be:
> 
> exp(b_year*1:10+0.5*(v1+v2))
> 
> where b_year is your slope estimate, and v1 is the year
> intercept? 
> variance and v2 is the room intercept variance.
> 
> When slope variance exists this becomes more difficult,
> because it? 
> implies the variance v2 changes as a function of year. In
> this case:
> 
> v2=diag(Z%*%V2%*%t(Z))
> 
> where
> 
> Z<-cbind(rep(1,10), 1:10)
> 
> and V2 is the covariance matrix of the room
> intercept-slopes.
> 
> Or if you like
> 
> v2 = V2[1,1]+(1:10)*V2[1,2]*2+(1:10^2)*V2[2,2]
> 
> Another difficulty is the possibility that your missing
> data are not? 
> "completely missing at random". By default lmer just seems
> to omit? 
> missing data rather than dealing with it properly, but
> perhaps there? 
> is an argument that can be passed to na.omit which
> suppresses this? If? 
> so, then the less strict assumption of "missing at random"
> can be? 
> made. In this latter case the missing data only have to be
> random? 
> conditional on the observed data - for example, if there
> were no bats? 
> in room A in year 1 which made the field workers less
> inclined to? 
> visit room A in year 2 based on their knowledge of the 1'st
> year's? 
> count.
> 
> Cheers,
> 
> Jarrod
> 
> Quoting "ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be>:
> 
> > Dear all,
> >
> > We are modelling the total numbers of hibarnating bats
> in a fortress. We
> > have data of the number of bats per room spanning ten
> years. The main
> > problem is that not all rooms were visited each year.
> The fieldworkers
> > did not known or find all rooms and some rooms were
> not allways
> > accessible.
> >
> > Some of the rooms were not counted in the early years
> and they contain a
> > rather high number of bats in the more recent years.
> So a glm on the
> > total observed number would be very biased. Therefore
> we would use a
> > mixed model on the numbers of bats per room. The model
> looks like:
> > glmer(Number ~ Year + (1|Year) + (Year|Room), family =
> poisson). Year is
> > the long-term trend. (1|Year) allows for year-to-year
> variability (due
> > to weatherconditions) and (Year|Room) allows for a
> random intercept and
> > slope per room.
> >
> > Our main question about this model is the
> interpretation of the
> > long-term trend (fixed effect of Year). Given the
> model specification it
> > is the trend in an 'average' room from the population
> of rooms. Can we
> > assume that this trend equals the trend in the total
> number of bats in
> > the fortress. That would be the trend in to total
> observed numbers if we
> > could have investigated every room in every year.
> > Or is it better to use the model to simulate the total
> number of bats
> > and then model this simulated totals using a simple
> glm? Repeating the
> > simulations a large number of times would yield an
> average and
> > confidence intervals for the trend.
> >
> > Best regards,
> >
> > Thierry
> >
> >
> ------------------------------------------------------------------------
> > ----
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek
> > team Biometrie & Kwaliteitszorg
> > Gaverstraat 4
> > 9500 Geraardsbergen
> > Belgium
> >
> > Research Institute for Nature and Forest
> > team Biometrics & Quality Assurance
> > Gaverstraat 4
> > 9500 Geraardsbergen
> > Belgium
> >
> > tel. + 32 54/436 185
> > Thierry.Onkelinx at inbo.be
> > www.inbo.be
> >
> > To call in the statistician after the experiment is
> done may be no more
> > than asking him to perform a post-mortem examination:
> he may be able to
> > say what the experiment died of.
> > ~ Sir Ronald Aylmer Fisher
> >
> > The plural of anecdote is not data.
> > ~ Roger Brinner
> >
> > The combination of some data and an aching desire for
> an answer does not
> > ensure that a reasonable answer can be extracted from
> a given body of
> > data.
> > ~ John Tukey
> >
> >
> >
> >
> > Druk dit bericht a.u.b. niet onnodig af.
> > Please do not print this message unnecessarily.
> >
> > Dit bericht en eventuele bijlagen geven enkel de visie
> van de schrijver weer
> > en binden het INBO onder geen enkel beding, zolang dit
> bericht niet???
> > bevestigd is
> > door een geldig ondertekend document. The views
> expressed in? this message
> > and any annex are purely those of the writer and may
> not be regarded? 
> >? as stating
> > an official position of INBO, as long as the message
> is not???
> > confirmed by a duly
> > signed document.
> >
> > ??? [[alternative HTML version
> deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org
> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
> 
> 
> 
> -- 
> The University of Edinburgh is a charitable body,
> registered in
> Scotland, with registration number SC005336.
> 
> 
> 
> ------------------------------
> 
> Message: 2
> Date: Wed, 27 Jan 2010 17:27:37 -0800
> From: Austen Thomas <austen.thomas at gmail.com>
> To: Andrew Dolman <andydolman at gmail.com>
> Cc: R-SIG-Mixed-Models at r-project.org
> Subject: Re: [R-sig-ME] Time series LME with nested fixed
> effects
> Message-ID:
> ??? <9d4eee51001271727i4edcc565l1a5d7999ade2fc2b at mail.gmail.com>
> Content-Type: text/plain
> 
> Hi Andrew,
> 
> Thank you so much for taking the time to look this over for
> us.? Your
> assistance has been exceedingly helpful.
> 
> -Austen
> 
> On Wed, Jan 27, 2010 at 1:23 PM, Andrew Dolman <andydolman at gmail.com>
> wrote:
> 
> > Hello Austin,
> >
> > I stand to be corrected but as no-one else has offered
> anything yet I'll
> > make a suggestion or two.
> >
> >
> > 1.
> > I don't think you want your random effects nested; you
> want them crossed.
> > This you can only do with lmer, not nlme.
> >
> > So something like:
> >
> > lmer(MDB~Season*Period+(1|Seal)
> +(1|Season)+(1|Period), data=d,
> > REML=F)->fit10
> >
> > This is because the seasons and periods have meaning
> independently. i.e.
> > saying "spawn" means the same thing for each seal, and
> each period. Or in
> > other words, you might expect "spawn" data points to
> share similarities with
> > each other that they do not share with non-spawn,
> regardless of which time
> > period or seal.
> >
> > 2. But!
> >
> > You only have 2 categories for season. This is not
> enough to treat it as
> > random. 4 periods is not really enough either. 5 seals
> is possibly just
> > enough. So I would just have seal as the only random
> effect. Just treat
> > season and period as fixed.
> >
> > lmer(MDB~Season*Period+(1|Seal), data=d,
> REML=F)->fit10
> >
> >
> >
> > andydolman at gmail.com
> >
> >
> > 2010/1/27 Austen Thomas <austen.thomas at gmail.com>
> >
> >>? We are using transmitting time/depth
> recorders to measure the diving
> >> behavior of 5 harbor seals in Puget Sound.?
> For each seal, we have two
> >> seasons, while herring are spawning and after they
> spawn.? Nested in each
> >> season, we have four times of day (labeled
> period).? We are interested in
> >> whether there is an effect of ?season? (spawn
> / non-spawn), ?period?
> >> (morning, day, evening, night) on the ?Modal
> Depth Bin? of harbor seals,
> >> or
> >> an interaction between these two factors.
> >>
> >> Below is the code that we think is correct.?
> Does anyone think the model
> >> is
> >> specified incorrectly, and if so what do they
> recommend (and why)?
> >> Thanks very much for your time.
> >>
> >> -Austen Thomas
> >>
> >> Biology Department
> >> Western Washington University
> >> Biology Building BI 315
> >> Mail Stop 9160
> >> Bellingham, WA 98225-9160
> >>
> >>
> >>
> >> For lme4 package
> >> summary(d)
> >> lmer(MDB~Season*Period+(1|Seal/Season/Period),
> data=d, REML=F)->fit10
> >> summary(fit10)
> >> lmer(MDB~Season+Period+(1|Seal/Season/Period),
> data=d, REML=F)->fit11
> >> lmer(MDB~Season+(1|Seal/Season/Period), data=d,
> REML=F)->fit12
> >> lmer(MDB~1+(1|Seal/Season/Period), data=d,
> REML=F)->fit13
> >> anova(fit10, fit11, fit12, fit13)
> >>
> >> for the nlme package
> >> lme(MDB~Season*Period,
> random=~1|Seal/Season/Period, method="ML",
> >> data=d)->fit20
> >> summary(fit20)
> >> lme(MDB~Season+Period,
> random=~1|Seal/Season/Period, method="ML",
> >> data=d)->fit21
> >> lme(MDB~Season, random=~1|Seal/Season/Period,
> method="ML", data=d)->fit22
> >> lme(MDB~1, random=~1|Seal/Season/Period,
> method="ML", data=d)->fit23
> >> anova(fit20, fit21, fit22, fit23)
> >>
> >>? ? ? ? [[alternative HTML
> version deleted]]
> >>
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org
> mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >>
> >
> 
> 
> -- 
> Biology Department
> Western Washington University
> Biology Building BI 315
> Mail Stop 9160
> Bellingham, WA 98225-9160
> 
> ??? [[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------
> 
> Message: 3
> Date: Thu, 28 Jan 2010 09:35:02 -0600
> From: Douglas Bates <bates at stat.wisc.edu>
> To: Doug Adams <fog0 at gmx.com>
> Cc: R sig-mixed-models <r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] Science Fair data
> Message-ID:
> ??? <40e66e0b1001280735r5c90ad8arf2c73a101aadc8b2 at mail.gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1
> 
> I'm writing a book about lme4 and lmer.? When it gets
> to the point
> where others can read it without too much frowning and
> scratching of
> heads, I will make chapter drafts available.
> 
> For the time being you may find the slides from a short
> course given
> last summer informative.? They are at
> http://lme4.R-forge.R-project.org/slides/2009-07-21-Seewiesen/
> 
> On Wed, Jan 27, 2010 at 2:53 PM, Doug Adams <fog0 at gmx.com>
> wrote:
> > Hi, and thanks again. ?That makes sense with the 3
> levels of division:
> >
> > (Intercept) divisionJunior divisionSenior
> > ? ? 80.306526 ? ? ?-3.252372 ? ? ?-2.694055
> >
> > ...so that the Junior and Senior levels are both
> slightly lower than
> > the Elementary level.
> >
> > I'd love to really understand the summary of lmer and
> what ranef,
> > fixef, coef and fitted are extracting - so that
> probably means I don't
> > understand the basics and nomenclature of HLMing as I
> thought I might
> > have. ?I took a 1-week class on HLM, and I have the
> book you (Douglas
> > Bates) wrote... ?Maybe I just need to study up on
> things a little
> > better!
> >
> > Anyway, I appreciate your help very much ? : )
> >
> > Doug
> >
> >
> >
> > On Wed, Jan 27, 2010 at 8:07 AM, Douglas Bates <bates at stat.wisc.edu>
> wrote:
> >> On Tue, Jan 26, 2010 at 10:10 PM, Doug Adams
> <fog0 at gmx.com>
> wrote:
> >>> I appreciate that, both of you (& that's
> ok for the mistake Christopher) ? :)
> >>
> >>> So fixed factors as simply listed by
> themselves (no 1| notation) and
> >>> random effects are listed with appropriate
> nesting... ?I do want to
> >>> consider schools as random effects; that will
> give me the information
> >>> I'd like to have about the variability (and
> reliability too?) of the
> >>> schools as they fit into the big picture.
> >>
> >>> When I use fixef & ranef to extract
> estimates for division and schools
> >>> (& maybe districts eventually too now), am
> I right in thinking that
> >>> the 3 numbers given for each level of division
> (fixef) are the
> >>> intercepts for each level -- as if there were
> individual OLS
> >>> regressions performed for each?
> >>
> >> Not quite. ?They should be labeled "(Intercept)"
> and something like
> >> division2 and division 3. ?(By the way, it helps
> if you quote the
> >> output when you want to discussion what particular
> values mean.) ?The
> >> (Intercept) coefficient represents the prediction
> at the first level
> >> of the division factor. ?The next two coefficients
> are the change from
> >> the first to the second level and from the first
> to the third level.
> >>
> >>> And are the random effects for the
> >>> schools (ranef) are the slopes associated with
> those regression lines?
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org
> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
> 
> 
> ------------------------------
> 
> Message: 4
> Date: Thu, 28 Jan 2010 09:48:06 -0700
> From: Doug Adams <fog0 at gmx.com>
> To: Douglas Bates <bates at stat.wisc.edu>,???
> R sig-mixed-models
> ??? <r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] Science Fair data
> Message-ID:
> ??? <74cfd9161001280848u7192230ey1cc450405cf3c579 at mail.gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1
> 
> That's great!? Thanks!
> 
> 
> 
> On Thu, Jan 28, 2010 at 8:35 AM, Douglas Bates <bates at stat.wisc.edu>
> wrote:
> > I'm writing a book about lme4 and lmer. ?When it gets
> to the point
> > where others can read it without too much frowning and
> scratching of
> > heads, I will make chapter drafts available.
> >
> > For the time being you may find the slides from a
> short course given
> > last summer informative. ?They are at
> > http://lme4.R-forge.R-project.org/slides/2009-07-21-Seewiesen/
> >
> > On Wed, Jan 27, 2010 at 2:53 PM, Doug Adams <fog0 at gmx.com>
> wrote:
> >> Hi, and thanks again. ?That makes sense with the 3
> levels of division:
> >>
> >> (Intercept) divisionJunior divisionSenior
> >> ? ? 80.306526 ? ? ?-3.252372 ? ? ?-2.694055
> >>
> >> ...so that the Junior and Senior levels are both
> slightly lower than
> >> the Elementary level.
> >>
> >> I'd love to really understand the summary of lmer
> and what ranef,
> >> fixef, coef and fitted are extracting - so that
> probably means I don't
> >> understand the basics and nomenclature of HLMing
> as I thought I might
> >> have. ?I took a 1-week class on HLM, and I have
> the book you (Douglas
> >> Bates) wrote... ?Maybe I just need to study up on
> things a little
> >> better!
> >>
> >> Anyway, I appreciate your help very much ? : )
> >>
> >> Doug
> 
> 
> 
> ------------------------------
> 
> Message: 5
> Date: Thu, 28 Jan 2010 17:23:44 +0000
> From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] estimates of between sex
> correlations
> Message-ID: <20100128172344.1nykjdyvwg0sg4wg at www.staffmail.ed.ac.uk>
> Content-Type: text/plain;???
> charset=ISO-8859-1;??? DelSp="Yes";
> ??? format="flowed"
> 
> Hi Celine,
> 
> Unfortunately I don't think the model you want to fit can
> be fitted in? 
> MCMCglmm. Currently only (conditional) diagonal and
> (conditional)? 
> block residual covariance matrices are implemented, and
> what you want? 
> is block diagonal. ASReml is probably you best way forward
> at the? 
> moment. If you are prepared to assume that the residual
> covariances? 
> for the 3 traits are equivalent in the two sexes then you
> can use? 
> rcov=~us(trait):sex:units.
> 
> ? With respect to the permanent environment effects
> you can fit a? 
> block diagonal using
> 
> us(at.level(sex,1):trait):id+us(at.level(sex,2):trait):id
> 
> where id are the individual identifiers.
> 
> I may allow this type of syntax in the residual structure
> in the near future.
> 
> Cheers,
> 
> Jarrod
> 
> 
> Quoting Celine Teplitsky <teplitsky at mnhn.fr>:
> 
> > Dear all,
> >
> > I would like to fit a model to estimate between sex
> genetic
> > correlations for 3 traits (3 same traits expressed
> both in males and
> > females) using MCMCglmm. My problem is I don't
> understand how I can
> > manage to fix the covariances between male and female
> traits to 0 for
> > residual variance and permanent environment. Could
> anyone help me with
> > this?
> >
> > Many thanks in advance
> >
> > All the best
> >
> > Celine
> >
> > -- 
> >
> > Celine Teplitsky
> > D?partement Ecologie et Gestion de la Biodiversit? UMR
> 7204
> > Unit? Conservation des Esp?ces, Restauration et Suivi
> des Populations
> > Case Postale 51
> > 55 rue Buffon 75005 Paris
> >
> > Webpage :http://www2.mnhn.fr/cersp/spip.php?rubrique96
> > Fax : (33-1)-4079-3835
> > Phone: (33-1)-4079-3443
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org
> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 
> -- 
> The University of Edinburgh is a charitable body,
> registered in
> Scotland, with registration number SC005336.
> 
> 
> 
> ------------------------------
> 
> Message: 6
> Date: Fri, 29 Jan 2010 07:25:27 +1000 (EST)
> From: David Duffy <David.Duffy at qimr.edu.au>
> To: "ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Trend in total number of animals
> Message-ID: <Pine.LNX.4.64.1001290717440.16167 at orpheus.qimr.edu.au>
> Content-Type: TEXT/PLAIN; charset=US-ASCII; format=flowed
> 
> On Thu, 28 Jan 2010, ONKELINX, Thierry wrote:
> 
> > We are modelling the total numbers of hibernating bats
> in a fortress. We
> > have data of the number of bats per room spanning ten
> years. The main
> > problem is that not all rooms were visited each year.
> The fieldworkers
> > did not known or find all rooms and some rooms were
> not allways
> > accessible.
> >
> > Some of the rooms were not counted in the early years
> and they contain a
> > rather high number of bats in the more recent years.
> 
> I would try (fixed-effects) log-linear models for
> incomplete tables as 
> well, to deal with the sampling (I have written an R
> package "gllm", that 
> may be suitable).? Then you could compare the
> estimates of total counts to 
> the GLMM results.? If you are going to simulate, you
> might might as well 
> go to BUGS.
> 
> Cheers, David.
> 
> -- 
> | David Duffy (MBBS PhD)? ? ? ? ?
> ? ? ? ? ? ? ? ?
> ? ? ? ? ? ?
> ???,-_|\
> | email: davidD at qimr.edu.au?
> ph: INT+61+7+3362-0217 fax: -0101? /?
> ???*
> | Epidemiology Unit, Queensland Institute of Medical
> Research???\_,-._/
> | 300 Herston Rd, Brisbane, Queensland 4029,
> Australia? GPG 4D0B994A v
> 
> 
> 
> ------------------------------
> 
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> End of R-sig-mixed-models Digest, Vol 37, Issue 20
> **************************************************
> 


     


From austen.thomas at gmail.com  Fri Jan 29 10:05:19 2010
From: austen.thomas at gmail.com (Austen Thomas)
Date: Fri, 29 Jan 2010 01:05:19 -0800
Subject: [R-sig-ME] Time series LME with nested fixed effects
In-Reply-To: <4B613CBD.9090705@life.ku.dk>
References: <4B613CBD.9090705@life.ku.dk>
Message-ID: <9d4eee51001290105x6c02a538nfa0d582b87225f95@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100129/3cf3a450/attachment.pl>

From Thierry.ONKELINX at inbo.be  Mon Feb  1 11:07:41 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 1 Feb 2010 11:07:41 +0100
Subject: [R-sig-ME] Trend in total number of animals
In-Reply-To: <40e66e0b1001281429g4381d7c7tc492bb328ce50259@mail.gmail.com>
References: <2E9C414912813E4EB981326983E0A10406F91914@inboexch.inbo.be>
	<20100128125704.hn6nx4hrks4osw48@www.staffmail.ed.ac.uk>
	<40e66e0b1001281429g4381d7c7tc492bb328ce50259@mail.gmail.com>
Message-ID: <2E9C414912813E4EB981326983E0A10406F91E18@inboexch.inbo.be>

Dear all,

Thanky you for your comments.

Adding (1|Year) seems to effect both the estimate and the standard error
of Year. The standard error increases a factor 1.68. That seems logical
to me since (1|Year) and Year compete for information on the data. The
estimate of the trend (fixed effect) changes 37%. And that worries me
more. Therefore I will drop the (1|Year) term and look for some relevant
weather data. We know that there is some correlation with the
temperature at the moment of observation.

The actual dataset is much longer than ten years, but we use only the
years were we have unambiguous information on the room in which an
individual was recorded. Our dataset contains a row with the number of
individuals, the room and year for all observed rooms, thus including
rooms without bats but excluding rooms that were not visited in a given
year. Hence the dataset contains no NA values for the number of
individuals. MAR seems a reasonal assumumption on the missingness.

Since the bats are known to change their location within the fortress,
several bats moving from one room to another is not that relevant. Hence
a trend in the total numbers is more important than a trend in the
number in an average room. Therefore I used the model on the data per
room to get an estimating of the number in the entire fortress (= all
rooms with at least one observation).

To upscale the predictions , I calculated the fitted values using both
the fixed and the random effects manually. So it would be something
equivalent as predict.lme(model, newdata = entire.fortress, level = 1).
This yields for each room and each year a prediction on the log-scale.
The number of bats is simulated by rpois with lambda = exp(prediction).
Summing the simulated counts per year over all rooms gives a possible
realisation of total number of bats in a given year. Next I fit a simple
glm(total ~ year) and saved the trend. Repeating that for 1000
simulations gives a interval for the trend on the total number. 

The model using only the the observed totals (discarding information on
the visited rooms), indicate an increase of 30% every five years. The
mixed model, using the information on the rooms, gave an increase of 61%
every five years. Using the mixed model to interpolate the counts to the
non visited rooms and running a large number of simulation yields an
increase of 4% per five years. That last number corresponds with my gut
feeling since some rooms with high numbers were not visited in the early
years. In the recent years most of the rooms are visited and the total
number seems to be more or less stable.

Best regards,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From lucybrowning at gmail.com  Tue Feb  2 16:23:33 2010
From: lucybrowning at gmail.com (Lucy Browning)
Date: Tue, 2 Feb 2010 15:23:33 +0000
Subject: [R-sig-ME] standard errors of estimaters in glmer
Message-ID: <dac603dc1002020723m48fe30eetda94df5fd44c7275@mail.gmail.com>

Hi,

I am trying to calculate standard errors of the means (rather than the
differences between means) of parameter estimates for a model similar
to this one from the lme4 library:

gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 |
herd),family=binomial,data= cbpp)

I am aware that the non-intercept estimates are given as differences
from the intercept and non-intercept standard errors are given as
standard error of the difference between means:

fixef(gm1)
#(Intercept)     period2     period3     period4
 #   -1.3985     -0.9923     -1.1287     -1.5804

se.fixef(gm1)
#(Intercept)     period2     period3     period4
 #    0.2279      0.3054      0.3260      0.4288


Moreover, they are given on the logit scale and so must be
backtransformed.  I have assumed that the standard error of the
difference between the means of two treatment levels (with different
sample sizes) would be the following:

se.diff <- sqrt(variance1/n1 + variance2/n2)

hence, the standard errors of the parameter estimates should be
calculable from the output as follows:

se.estimate <- sqrt( se.diff^2 - se.intercept^2)

where se.intercept is the standard error of the intercept taken from
the output, and se.diff is any one of the standard errors given for
the fixed effects.

So the standard error of the estimate for period2 should be

sqrt(0.3054^2-0.2279^2) ## 0.2033.

To backtransform this, we have to (respectively) add this value to,
and subtract it from, the fixed-effect estimate to obtain upper and
lower standard errors, and then apply an inverse logit tranformation
(in the arm library).

invlogit(-1.3985-0.9923+0.2033) ##  0.1009
invlogit(-1.3985-0.9923-0.2033) ## 0.06952

I am worried that this may not be the correct way of doing it, because
when we simulate the distribution that comes from the model output, we
get something different:

test1<-rnorm(100000,-1.3985,0.2279)
test2<-rnorm(100000,-0.9923,0.3054)
test3<-test1+test2
sd(test3) ##  0.3809

invlogit(-1.3985-0.9923+0.3809)  ## 0.1182
invlogit(-1.3985-0.9923-0.3809)  ## 0.05887

for the model I am using, these differences are larger than this.  Can
anyone advise on the right way to calculate the standard errors of the
means for backtransformed estimates from a binomial glmer?

Many thanks in advance,

Lucy Browning

--



From bolker at ufl.edu  Tue Feb  2 18:01:37 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 02 Feb 2010 12:01:37 -0500
Subject: [R-sig-ME] standard errors of estimaters in glmer
In-Reply-To: <dac603dc1002020723m48fe30eetda94df5fd44c7275@mail.gmail.com>
References: <dac603dc1002020723m48fe30eetda94df5fd44c7275@mail.gmail.com>
Message-ID: <4B685A71.3040304@ufl.edu>

  Some overkill:

==============================
\documentclass{article}

\newcommand{\code}[1]{{\tt #1}}
\begin{document}

\begin{quote}
Hi,

I am trying to calculate standard errors of the means (rather than the
differences between means) of parameter estimates for a model similar
to this one from the lme4 library:
\end{quote}

\SweaveOpts{keep.source=TRUE}
<<echo=FALSE>>=
options(continue=" ")
@
<<>>=
library(lme4)
gm1 <- glmer(cbind(incidence, size - incidence) ~ period +
             (1 | herd),family=binomial,data= cbpp)
## perhaps easier if we fit without an intercept,
##   so estimates are actual estimates by period
##   rather than period 1 vs. later period differences
gm1B <- glmer(cbind(incidence, size - incidence) ~ period -1 +
             (1 | herd),family=binomial,data= cbpp)
@

\begin{quote}
I am aware that the non-intercept estimates are given as differences
from the intercept and non-intercept standard errors are given as
standard error of the difference between means:
\end{quote}

<<>>=
(coefs <- fixef(gm1))
library(arm)
(se.vals <- se.fixef(gm1))
@

\emph{note to \code{arm} maintainers: in \code{se.fixef()}, wouldn't
\code{sqrt(diag(as.matrix(vcov(object))))} be more general?}

To calculate
the standard error of the estimate for period2, we need
to use both the variances and the covariance between
the intercept and the period2-difference estimate:
if we want to evaluate a linear combination of parameters
$a_1 p_1 + a_2 p_2 + \ldots$ (in this case $a_1=1$,
$a_2=1$, $a_i=0$ for $i>2$), let's say $\mathbf{a}$,
then the variance is $\mathbf{a} \mathbf{V} \mathbf{a}^T$:

<<>>=
eff <- c(1,1)
se.period2 <- sqrt(eff %*% as.matrix(vcov(gm1)[1:2,1:2]) %*% eff)
@
Or, we can retrieve the answer
directly from the no-intercept fit:
<<>>=
se.period2 - se.fixef(gm1B)["period2"]
@
These are close, but not identical
(plausibly consistent with round-off error).

To backtransform this, we have to (respectively) add this value to,
and subtract it from, the fixed-effect estimate to obtain upper and
lower standard errors, and then apply an inverse logit tranformation
(in the arm library).


\emph{note to \code{arm} maintainers:
  I don't see why arm defines \code{invlogit} when \code{plogis()} exists
  in base R already \ldots}
<<>>=
plogis((coefs["(Intercept)"]+coefs["period2"])+c(-2,2)*se.period2)
@

To simulate:
(1) from normal distribution

<<>>=
parsims <- MASS:::mvrnorm(1000,mu=coefs,Sigma=as.matrix(vcov(gm1)))
p2 <- parsims[,"(Intercept)"]+parsims[,"period2"]
plogis(quantile(p2,c(0.025,0.975)))
@

(2) using \code{sim} from \code{arm}:
<<>>=
parsims2 <- sim(gm1,n.sims=1000)$fixef
p2B <- parsims2[,"(Intercept)"]+parsims2[,"period2"]
plogis(quantile(p2B,c(0.025,0.975)))
@

As far as I can tell from looking at Gelman and Hill's
book (one can also look through the code
using \code{getMethod("sim","mer")}, but it's too big
and complicated for me to face right now), these two
approaches are essentially the same.

\end{document}


Lucy Browning wrote:
> Hi,
> 
> I am trying to calculate standard errors of the means (rather than the
> differences between means) of parameter estimates for a model similar
> to this one from the lme4 library:
> 
> gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 |
> herd),family=binomial,data= cbpp)
> 
> I am aware that the non-intercept estimates are given as differences
> from the intercept and non-intercept standard errors are given as
> standard error of the difference between means:
> 
> fixef(gm1)
> #(Intercept)     period2     period3     period4
>  #   -1.3985     -0.9923     -1.1287     -1.5804
> 
> se.fixef(gm1)
> #(Intercept)     period2     period3     period4
>  #    0.2279      0.3054      0.3260      0.4288
> 
> 
> Moreover, they are given on the logit scale and so must be
> backtransformed.  I have assumed that the standard error of the
> difference between the means of two treatment levels (with different
> sample sizes) would be the following:
> 
> se.diff <- sqrt(variance1/n1 + variance2/n2)
> 
> hence, the standard errors of the parameter estimates should be
> calculable from the output as follows:
> 
> se.estimate <- sqrt( se.diff^2 - se.intercept^2)
> 
> where se.intercept is the standard error of the intercept taken from
> the output, and se.diff is any one of the standard errors given for
> the fixed effects.
> 
> So the standard error of the estimate for period2 should be
> 
> sqrt(0.3054^2-0.2279^2) ## 0.2033.
> 
> To backtransform this, we have to (respectively) add this value to,
> and subtract it from, the fixed-effect estimate to obtain upper and
> lower standard errors, and then apply an inverse logit tranformation
> (in the arm library).
> 
> invlogit(-1.3985-0.9923+0.2033) ##  0.1009
> invlogit(-1.3985-0.9923-0.2033) ## 0.06952
> 
> I am worried that this may not be the correct way of doing it, because
> when we simulate the distribution that comes from the model output, we
> get something different:
> 
> test1<-rnorm(100000,-1.3985,0.2279)
> test2<-rnorm(100000,-0.9923,0.3054)
> test3<-test1+test2
> sd(test3) ##  0.3809
> 
> invlogit(-1.3985-0.9923+0.3809)  ## 0.1182
> invlogit(-1.3985-0.9923-0.3809)  ## 0.05887
> 
> for the model I am using, these differences are larger than this.  Can
> anyone advise on the right way to calculate the standard errors of the
> means for backtransformed estimates from a binomial glmer?
> 
> Many thanks in advance,
> 
> Lucy Browning
> 
> --
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From Oliver.Duerr at genedata.com  Wed Feb  3 15:32:10 2010
From: Oliver.Duerr at genedata.com (Oliver Duerr)
Date: Wed, 3 Feb 2010 15:32:10 +0100
Subject: [R-sig-ME] Bug / problems in optimizer of lmer.
Message-ID: <A1D6833D0813C941A81D86EE81070A500ADE977FDB@shasta.Genedata.win>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100203/558b72a5/attachment.pl>

From donal.bisanzio at gmail.com  Wed Feb  3 10:05:38 2010
From: donal.bisanzio at gmail.com (Donal Bisanzio)
Date: Wed, 3 Feb 2010 10:05:38 +0100
Subject: [R-sig-ME] glmm.admb p value
Message-ID: <ba95c4b81002030105j2d21a6c1n31310eea99aaf492@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100203/ee267b5b/attachment.pl>

From bates at stat.wisc.edu  Wed Feb  3 16:29:02 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 3 Feb 2010 09:29:02 -0600
Subject: [R-sig-ME] Bug / problems in optimizer of lmer.
In-Reply-To: <A1D6833D0813C941A81D86EE81070A500ADE977FDB@shasta.Genedata.win>
References: <A1D6833D0813C941A81D86EE81070A500ADE977FDB@shasta.Genedata.win>
Message-ID: <40e66e0b1002030729h40f540f5wf53f41c8f2858573@mail.gmail.com>

On Wed, Feb 3, 2010 at 8:32 AM, Oliver Duerr <Oliver.Duerr at genedata.com> wrote:
> Hello all,
>
> First of all I don't know if I am in the right news group to report bug / suspicious behavior in lme4. If not I do apologize.
>
> I am currently developing a linear mixed model implementation. For testing I used the model
>
> y ~ dose * day + (1 | comp)
>
> and compared my implementation with lmer from lme4_0.999375-32 for about 30'000 different values of y.
> Generally the comparison is quite good but for certain y values (approx 100) I found small differences. Looking closer at some of those cases ?I observe that the optimization reaches 0 but then it ?cannot "escape" from anymore.
>
> One example, reproducible with the data provided below:
>>fit <- lmer(y ~ dose * day + (1 | comp), verbose=TRUE)
> ?0: ? ?-21.202738: 0.245256
> ?1: ? ?-21.863496: ?0.00000
> ?2: ? ?-21.863496: 4.14318e-06
>
> Plotting the one dimensional reduced deviance reveals a minimum at ~ 0.0862 (this minimum can also be found by providing a different start value).
>
>> fit <- lmer(y ~ dose * day + (1 | comp), verbose=TRUE, start = c(0.05))
> ?0: ? ?-21.917896: 0.0500000
> ?1: ? ?-21.950001: 0.0784911
> ?2: ? ?-21.951063: 0.0913211
> ?3: ? ?-21.951911: 0.0860209
> ?4: ? ?-21.951913: 0.0862628
> ?5: ? ?-21.951913: 0.0862698
>
> In my implementation I had similar problems when I had to evaluate the likelihood at very small numbers it began to fluctuated and the optimizer had been trapped in a local minimum due to these numeric instabilities.
>
> Is this behavior known or do I maybe use lmer in a wrong way?

It is known in the sense that numerical optimization is not guaranteed
to produce a global optimum.  At best it can produce a local optimum.
On my system the REML fit does converge to the optimum you indicate
but, of course, 0 is well within any reasonable confidence interval on
the standard deviation of the random effects.  The ML fit converges to
an estimate of zero.

> print(fit <- lmer(y ~ dose * day + (1 | comp), verbose=TRUE), corr = FALSE)
  0:    -16.846009:  1.00000
  1:    -21.863496:  0.00000
  2:    -21.863496: 3.34671e-05
  3:    -21.864249: 0.00511679
  4:    -21.910197: 0.0451168
  5:    -21.951246: 0.0817081
  6:    -21.951470: 0.0899260
  7:    -21.951913: 0.0861839
  8:    -21.951913: 0.0862678
  9:    -21.951913: 0.0862697
Linear mixed model fit by REML
Formula: y ~ dose * day + (1 | comp)
  REML
-21.95

Random effects:
 Groups   Name        Variance   Std.Dev.
 comp     (Intercept) 0.00025129 0.015852
 Residual             0.03376472 0.183752
Number of obs: 133, groups: comp, 3

Fixed effects:
              Estimate Std. Error t value
(Intercept)  0.9553992  0.0183807   51.98
dose1       -0.0057256  0.0194846   -0.29
dose2        0.0189734  0.0112938    1.68
day1         0.0420788  0.0193691    2.17
day2         0.0032043  0.0113592    0.28
dose1:day1  -0.0057732  0.0237223   -0.24
dose2:day1  -0.0177054  0.0136961   -1.29
dose1:day2  -0.0148491  0.0138588   -1.07
dose2:day2   0.0007798  0.0080636    0.10
> print(fitML <- lmer(y ~ dose * day + (1 | comp), verbose=TRUE, REML = 0), corr = FALSE)
  0:    -73.180235:  1.00000
  1:    -81.824446:  0.00000
  2:    -81.824446:  0.00000
Linear mixed model fit by maximum likelihood
Formula: y ~ dose * day + (1 | comp)
    AIC    BIC logLik deviance
 -59.82 -28.03  40.91   -81.82

Random effects:
 Groups   Name        Variance Std.Dev.
 comp     (Intercept) 0.000000 0.00000
 Residual             0.031647 0.17790
Number of obs: 133, groups: comp, 3

Fixed effects:
              Estimate Std. Error t value
(Intercept)  0.9554630  0.0154320   61.91
dose1       -0.0057222  0.0188633   -0.30
dose2        0.0190337  0.0109334    1.74
day1         0.0420788  0.0187520    2.24
day2         0.0032680  0.0109970    0.30
dose1:day1  -0.0057732  0.0229664   -0.25
dose2:day1  -0.0177054  0.0132597   -1.34
dose1:day2  -0.0148456  0.0134166   -1.11
dose2:day2   0.0008401  0.0078059    0.11

Note that there are only three distinct levels of comp.  It is
difficult to estimate a variance component with only three distinct
levels of the grouping factor.

If you check the prediction intervals on the random effects from this
model (plot enclosed) you will see that, even for the REML fit, zero
is comfortably within the 95% confidence intervals on all the random
effects for the comp factor.

Having said all this, there is a better way of performing the
optimization when there is only one parameter in the profiled deviance
or profiled REML criterion.  The development version of the lme4
package, called lme4a on the R-forge site, allows for the model
structure to be returned without optimization.  It is packaged in such
a way that the parameter estimates can be determined by optimizers
other than nlminb, which is the default.

The optimize function is usually more effective for one-dimensional
problems than are more general optimizers such as nlminb or bobyqa.
If we use optimize on this problem

> fit <- lmer(y ~ dose * day + (1 | comp), doFit = FALSE)
> optimize(fit at setPars, interval = c(0,4))
$minimum
[1] 0.08624942

$objective
[1] -21.95191

> fit <- lmer(y ~ dose * day + (1 | comp), REML = 0, doFit = FALSE)
> optimize(fit at setPars, interval = c(0,4))
$minimum
[1] 6.96079e-05

$objective
[1] -81.82445

we do get convergence to non-zero parameter values, although the
differences in the objective (either the profiled REML criterion or
the profiled deviance) at these values compared to those at zero are
negligible.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplots.pdf
Type: application/pdf
Size: 2744 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100203/fa5bd0d6/attachment.pdf>

From isabella at ghement.ca  Wed Feb  3 18:12:58 2010
From: isabella at ghement.ca (Isabella Ghement)
Date: Wed, 3 Feb 2010 09:12:58 -0800
Subject: [R-sig-ME] Baseline + Follow-Up
Message-ID: <CEEDLPBNOCMDHIGPLIJLKEACCHAA.isabella@ghement.ca>

Hi everyone,

I am using the lme() function in the nlme library to fit a linear mixed
effects model
such as the one below, where an individual-level follow-up measurement is
modeled as a linear
function of an individual-level baseline measurement plus a fixed treatment
effect
plus a random cluster effect plus random error:

lme(FollowUp ~ Baseline + Treatment, random=~1|Cluster, method="REML",
data=Data)

The summary of the lme model fit reports a point estimate and confidence
interval
for the treatment effect (i.e., difference in adjusted treatment means), but
I am also
interested in getting estimates and confidence intervals for the adjusted
treatment means.
In my case, Treatment is a factor having two levels (say, A and B).
Is there a way to force lme() to report these quantities?

Many thanks!

Isabella

Isabella R. Ghement, Ph.D.
Ghement Statistical Consulting Company
301-7031 Blundell Road, Richmond, B.C., Canada, V6Y 1J5
Tel: 604-767-1250
Fax: 604-270-3922
E-mail: isabella at ghement.ca
Web: www.ghement.ca



From bates at stat.wisc.edu  Wed Feb  3 18:39:42 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 3 Feb 2010 11:39:42 -0600
Subject: [R-sig-ME] Baseline + Follow-Up
In-Reply-To: <CEEDLPBNOCMDHIGPLIJLKEACCHAA.isabella@ghement.ca>
References: <CEEDLPBNOCMDHIGPLIJLKEACCHAA.isabella@ghement.ca>
Message-ID: <40e66e0b1002030939n7fa62aces787a9b5addd1669f@mail.gmail.com>

On Wed, Feb 3, 2010 at 11:12 AM, Isabella Ghement <isabella at ghement.ca> wrote:
> Hi everyone,
>
> I am using the lme() function in the nlme library to fit a linear mixed
> effects model
> such as the one below, where an individual-level follow-up measurement is
> modeled as a linear
> function of an individual-level baseline measurement plus a fixed treatment
> effect
> plus a random cluster effect plus random error:
>
> lme(FollowUp ~ Baseline + Treatment, random=~1|Cluster, method="REML",
> data=Data)
>
> The summary of the lme model fit reports a point estimate and confidence
> interval
> for the treatment effect (i.e., difference in adjusted treatment means), but
> I am also
> interested in getting estimates and confidence intervals for the adjusted
> treatment means.
> In my case, Treatment is a factor having two levels (say, A and B).
> Is there a way to force lme() to report these quantities?

If I understand what you are asking, you can get these standard errors
by modifying the formula to

FollowUp ~ 0 + Treatment + Baseline



From Oliver.Duerr at genedata.com  Wed Feb  3 18:43:44 2010
From: Oliver.Duerr at genedata.com (Oliver Duerr)
Date: Wed, 3 Feb 2010 18:43:44 +0100
Subject: [R-sig-ME] Bug / problems in optimizer of lmer.
In-Reply-To: <40e66e0b1002030729h40f540f5wf53f41c8f2858573@mail.gmail.com>
References: <A1D6833D0813C941A81D86EE81070A500ADE977FDB@shasta.Genedata.win>
	<40e66e0b1002030729h40f540f5wf53f41c8f2858573@mail.gmail.com>
Message-ID: <A1D6833D0813C941A81D86EE81070A500ADE97800F@shasta.Genedata.win>

Dear Douglas Bates,

Thanks for the extremely fast and detailed answer.

Of course, as you said, 0 is well within any reasonable confidence interval on the standard deviation of the random effects and therefore this is not a real problem for that model and data set. It might be a bit of a pathologic data set, but I still ask myself why the optimizer is trapped around zero. I do not believe this is a real local minimum but rather a numeric artifact looking like a local minimum or a problem with the optimizer. I tried to evaluate and plot the deviance without fitting but I could not download the lme4a package.
I am kind of a newbie to R, after a google search I tried

	install.packages("lme4a", repos="http://R-Forge.R-project.org")

but that did not work out (package 'lme4a' is not available).

Finally, I guess if this kind sticking to zero only happens for data with their minimum close to zero anyway, than this should not be a problem at all.

Thanks again for your help and all the best,

Oliver 





-----Original Message-----
From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas Bates
Sent: Wednesday, February 03, 2010 4:29 PM
To: Oliver Duerr
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Bug / problems in optimizer of lmer.

On Wed, Feb 3, 2010 at 8:32 AM, Oliver Duerr <Oliver.Duerr at genedata.com> wrote:
> Hello all,
>
> First of all I don't know if I am in the right news group to report bug / suspicious behavior in lme4. If not I do apologize.
>
> I am currently developing a linear mixed model implementation. For 
> testing I used the model
>
> y ~ dose * day + (1 | comp)
>
> and compared my implementation with lmer from lme4_0.999375-32 for about 30'000 different values of y.
> Generally the comparison is quite good but for certain y values (approx 100) I found small differences. Looking closer at some of those cases ?I observe that the optimization reaches 0 but then it ?cannot "escape" from anymore.
>
> One example, reproducible with the data provided below:
>>fit <- lmer(y ~ dose * day + (1 | comp), verbose=TRUE)
> ?0: ? ?-21.202738: 0.245256
> ?1: ? ?-21.863496: ?0.00000
> ?2: ? ?-21.863496: 4.14318e-06
>
> Plotting the one dimensional reduced deviance reveals a minimum at ~ 0.0862 (this minimum can also be found by providing a different start value).
>
>> fit <- lmer(y ~ dose * day + (1 | comp), verbose=TRUE, start = 
>> c(0.05))
> ?0: ? ?-21.917896: 0.0500000
> ?1: ? ?-21.950001: 0.0784911
> ?2: ? ?-21.951063: 0.0913211
> ?3: ? ?-21.951911: 0.0860209
> ?4: ? ?-21.951913: 0.0862628
> ?5: ? ?-21.951913: 0.0862698
>
> In my implementation I had similar problems when I had to evaluate the likelihood at very small numbers it began to fluctuated and the optimizer had been trapped in a local minimum due to these numeric instabilities.
>
> Is this behavior known or do I maybe use lmer in a wrong way?

It is known in the sense that numerical optimization is not guaranteed to produce a global optimum.  At best it can produce a local optimum.
On my system the REML fit does converge to the optimum you indicate but, of course, 0 is well within any reasonable confidence interval on the standard deviation of the random effects.  The ML fit converges to an estimate of zero.

> print(fit <- lmer(y ~ dose * day + (1 | comp), verbose=TRUE), corr = 
> FALSE)
  0:    -16.846009:  1.00000
  1:    -21.863496:  0.00000
  2:    -21.863496: 3.34671e-05
  3:    -21.864249: 0.00511679
  4:    -21.910197: 0.0451168
  5:    -21.951246: 0.0817081
  6:    -21.951470: 0.0899260
  7:    -21.951913: 0.0861839
  8:    -21.951913: 0.0862678
  9:    -21.951913: 0.0862697
Linear mixed model fit by REML
Formula: y ~ dose * day + (1 | comp)
  REML
-21.95

Random effects:
 Groups   Name        Variance   Std.Dev.
 comp     (Intercept) 0.00025129 0.015852
 Residual             0.03376472 0.183752
Number of obs: 133, groups: comp, 3

Fixed effects:
              Estimate Std. Error t value
(Intercept)  0.9553992  0.0183807   51.98
dose1       -0.0057256  0.0194846   -0.29
dose2        0.0189734  0.0112938    1.68
day1         0.0420788  0.0193691    2.17
day2         0.0032043  0.0113592    0.28
dose1:day1  -0.0057732  0.0237223   -0.24
dose2:day1  -0.0177054  0.0136961   -1.29
dose1:day2  -0.0148491  0.0138588   -1.07
dose2:day2   0.0007798  0.0080636    0.10
> print(fitML <- lmer(y ~ dose * day + (1 | comp), verbose=TRUE, REML = 
> 0), corr = FALSE)
  0:    -73.180235:  1.00000
  1:    -81.824446:  0.00000
  2:    -81.824446:  0.00000
Linear mixed model fit by maximum likelihood
Formula: y ~ dose * day + (1 | comp)
    AIC    BIC logLik deviance
 -59.82 -28.03  40.91   -81.82

Random effects:
 Groups   Name        Variance Std.Dev.
 comp     (Intercept) 0.000000 0.00000
 Residual             0.031647 0.17790
Number of obs: 133, groups: comp, 3

Fixed effects:
              Estimate Std. Error t value
(Intercept)  0.9554630  0.0154320   61.91
dose1       -0.0057222  0.0188633   -0.30
dose2        0.0190337  0.0109334    1.74
day1         0.0420788  0.0187520    2.24
day2         0.0032680  0.0109970    0.30
dose1:day1  -0.0057732  0.0229664   -0.25
dose2:day1  -0.0177054  0.0132597   -1.34
dose1:day2  -0.0148456  0.0134166   -1.11
dose2:day2   0.0008401  0.0078059    0.11

Note that there are only three distinct levels of comp.  It is difficult to estimate a variance component with only three distinct levels of the grouping factor.

If you check the prediction intervals on the random effects from this model (plot enclosed) you will see that, even for the REML fit, zero is comfortably within the 95% confidence intervals on all the random effects for the comp factor.

Having said all this, there is a better way of performing the optimization when there is only one parameter in the profiled deviance or profiled REML criterion.  The development version of the lme4 package, called lme4a on the R-forge site, allows for the model structure to be returned without optimization.  It is packaged in such a way that the parameter estimates can be determined by optimizers other than nlminb, which is the default.

The optimize function is usually more effective for one-dimensional problems than are more general optimizers such as nlminb or bobyqa.
If we use optimize on this problem

> fit <- lmer(y ~ dose * day + (1 | comp), doFit = FALSE) 
> optimize(fit at setPars, interval = c(0,4))
$minimum
[1] 0.08624942

$objective
[1] -21.95191

> fit <- lmer(y ~ dose * day + (1 | comp), REML = 0, doFit = FALSE) 
> optimize(fit at setPars, interval = c(0,4))
$minimum
[1] 6.96079e-05

$objective
[1] -81.82445

we do get convergence to non-zero parameter values, although the differences in the objective (either the profiled REML criterion or the profiled deviance) at these values compared to those at zero are negligible.



From isabella at ghement.ca  Wed Feb  3 18:46:08 2010
From: isabella at ghement.ca (Isabella Ghement)
Date: Wed, 3 Feb 2010 09:46:08 -0800
Subject: [R-sig-ME] Baseline + Follow-Up
In-Reply-To: <40e66e0b1002030939n7fa62aces787a9b5addd1669f@mail.gmail.com>
Message-ID: <CEEDLPBNOCMDHIGPLIJLCEADCHAA.isabella@ghement.ca>

Thank you so much, Douglas!  I am not familiar with the "0" trick - can you
provide me with
some intuition for why this might work?

Isabella


-----Original Message-----
From: dmbates at gmail.com [mailto:dmbates at gmail.com]On Behalf Of Douglas
Bates
Sent: February 3, 2010 9:40 AM
To: Isabella Ghement
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Baseline + Follow-Up


On Wed, Feb 3, 2010 at 11:12 AM, Isabella Ghement <isabella at ghement.ca>
wrote:
> Hi everyone,
>
> I am using the lme() function in the nlme library to fit a linear mixed
> effects model
> such as the one below, where an individual-level follow-up measurement is
> modeled as a linear
> function of an individual-level baseline measurement plus a fixed
treatment
> effect
> plus a random cluster effect plus random error:
>
> lme(FollowUp ~ Baseline + Treatment, random=~1|Cluster, method="REML",
> data=Data)
>
> The summary of the lme model fit reports a point estimate and confidence
> interval
> for the treatment effect (i.e., difference in adjusted treatment means),
but
> I am also
> interested in getting estimates and confidence intervals for the adjusted
> treatment means.
> In my case, Treatment is a factor having two levels (say, A and B).
> Is there a way to force lme() to report these quantities?

If I understand what you are asking, you can get these standard errors
by modifying the formula to

FollowUp ~ 0 + Treatment + Baseline



From bates at stat.wisc.edu  Wed Feb  3 19:07:17 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 3 Feb 2010 12:07:17 -0600
Subject: [R-sig-ME] Baseline + Follow-Up
In-Reply-To: <CEEDLPBNOCMDHIGPLIJLCEADCHAA.isabella@ghement.ca>
References: <40e66e0b1002030939n7fa62aces787a9b5addd1669f@mail.gmail.com>
	<CEEDLPBNOCMDHIGPLIJLCEADCHAA.isabella@ghement.ca>
Message-ID: <40e66e0b1002031007t584e86fft9b9b9614fc6a7ab8@mail.gmail.com>

On Wed, Feb 3, 2010 at 11:46 AM, Isabella Ghement <isabella at ghement.ca> wrote:
> Thank you so much, Douglas! ?I am not familiar with the "0" trick - can you
> provide me with
> some intuition for why this might work?

The (Intercept) term is implicit in a linear model formula.  Thus the formula

FollowUp ~ Treatment + Baseline

is equivalent to

FollowUp ~ 1 + Treatment + Baseline

The symbolic analysis of the formula and data detects that there is an
intercept term and expresses Treatment as one contrast, which happens
to be the difference between treatment B and treatment A.  The 0 + in
the formula

FollowUp ~ 0 + Treatment + Baseline

suppresses the intercept term.  The first factor in the formula is
then expressed as a set of indicator columns, producing separate
estimates for treatment A and treatment B.

>
> Isabella
>
>
> -----Original Message-----
> From: dmbates at gmail.com [mailto:dmbates at gmail.com]On Behalf Of Douglas
> Bates
> Sent: February 3, 2010 9:40 AM
> To: Isabella Ghement
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Baseline + Follow-Up
>
>
> On Wed, Feb 3, 2010 at 11:12 AM, Isabella Ghement <isabella at ghement.ca>
> wrote:
>> Hi everyone,
>>
>> I am using the lme() function in the nlme library to fit a linear mixed
>> effects model
>> such as the one below, where an individual-level follow-up measurement is
>> modeled as a linear
>> function of an individual-level baseline measurement plus a fixed
> treatment
>> effect
>> plus a random cluster effect plus random error:
>>
>> lme(FollowUp ~ Baseline + Treatment, random=~1|Cluster, method="REML",
>> data=Data)
>>
>> The summary of the lme model fit reports a point estimate and confidence
>> interval
>> for the treatment effect (i.e., difference in adjusted treatment means),
> but
>> I am also
>> interested in getting estimates and confidence intervals for the adjusted
>> treatment means.
>> In my case, Treatment is a factor having two levels (say, A and B).
>> Is there a way to force lme() to report these quantities?
>
> If I understand what you are asking, you can get these standard errors
> by modifying the formula to
>
> FollowUp ~ 0 + Treatment + Baseline
>
>



From bates at stat.wisc.edu  Wed Feb  3 19:18:44 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 3 Feb 2010 12:18:44 -0600
Subject: [R-sig-ME] Bug / problems in optimizer of lmer.
In-Reply-To: <A1D6833D0813C941A81D86EE81070A500ADE97800F@shasta.Genedata.win>
References: <A1D6833D0813C941A81D86EE81070A500ADE977FDB@shasta.Genedata.win>
	<40e66e0b1002030729h40f540f5wf53f41c8f2858573@mail.gmail.com>
	<A1D6833D0813C941A81D86EE81070A500ADE97800F@shasta.Genedata.win>
Message-ID: <40e66e0b1002031018n4cf140e4u8b6d32c02417820b@mail.gmail.com>

On Wed, Feb 3, 2010 at 11:43 AM, Oliver Duerr <Oliver.Duerr at genedata.com> wrote:
> Dear Douglas Bates,
>
> Thanks for the extremely fast and detailed answer.
>
> Of course, as you said, 0 is well within any reasonable confidence interval on the standard deviation of the random effects and therefore this is not a real problem for that model and data set. It might be a bit of a pathologic data set, but I still ask myself why the optimizer is trapped around zero. I do not believe this is a real local minimum but rather a numeric artifact looking like a local minimum or a problem with the optimizer. I tried to evaluate and plot the deviance without fitting but I could not download the lme4a package.
> I am kind of a newbie to R, after a google search I tried
>
> ? ? ? ?install.packages("lme4a", repos="http://R-Forge.R-project.org")
>
> but that did not work out (package 'lme4a' is not available).

Thanks for the "heads up".  I frequently don't know what packages have
been prepared successfully on R-forge because I install these packages
from the sources - several times on some days.  It looks as the
Windows and Mac OS X packages are encountering conflicting definition
in C++ and C headers.  The Linux packages are not being built because
the available version of Matrix is out of date.  All these issues
could be addressed given sufficient time, which, regrettably, I don't
have right now.

I'll see if Uwe's win-builder service can create binary Windows
packages, although I may need to wait until Matrix_0.999375-35 gets on
the archives.

> Finally, I guess if this kind sticking to zero only happens for data with their minimum close to zero anyway, than this should not be a problem at all.
>
> Thanks again for your help and all the best,
>
> Oliver
>
>
>
>
>
> -----Original Message-----
> From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas Bates
> Sent: Wednesday, February 03, 2010 4:29 PM
> To: Oliver Duerr
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Bug / problems in optimizer of lmer.
>
> On Wed, Feb 3, 2010 at 8:32 AM, Oliver Duerr <Oliver.Duerr at genedata.com> wrote:
>> Hello all,
>>
>> First of all I don't know if I am in the right news group to report bug / suspicious behavior in lme4. If not I do apologize.
>>
>> I am currently developing a linear mixed model implementation. For
>> testing I used the model
>>
>> y ~ dose * day + (1 | comp)
>>
>> and compared my implementation with lmer from lme4_0.999375-32 for about 30'000 different values of y.
>> Generally the comparison is quite good but for certain y values (approx 100) I found small differences. Looking closer at some of those cases ?I observe that the optimization reaches 0 but then it ?cannot "escape" from anymore.
>>
>> One example, reproducible with the data provided below:
>>>fit <- lmer(y ~ dose * day + (1 | comp), verbose=TRUE)
>> ?0: ? ?-21.202738: 0.245256
>> ?1: ? ?-21.863496: ?0.00000
>> ?2: ? ?-21.863496: 4.14318e-06
>>
>> Plotting the one dimensional reduced deviance reveals a minimum at ~ 0.0862 (this minimum can also be found by providing a different start value).
>>
>>> fit <- lmer(y ~ dose * day + (1 | comp), verbose=TRUE, start =
>>> c(0.05))
>> ?0: ? ?-21.917896: 0.0500000
>> ?1: ? ?-21.950001: 0.0784911
>> ?2: ? ?-21.951063: 0.0913211
>> ?3: ? ?-21.951911: 0.0860209
>> ?4: ? ?-21.951913: 0.0862628
>> ?5: ? ?-21.951913: 0.0862698
>>
>> In my implementation I had similar problems when I had to evaluate the likelihood at very small numbers it began to fluctuated and the optimizer had been trapped in a local minimum due to these numeric instabilities.
>>
>> Is this behavior known or do I maybe use lmer in a wrong way?
>
> It is known in the sense that numerical optimization is not guaranteed to produce a global optimum. ?At best it can produce a local optimum.
> On my system the REML fit does converge to the optimum you indicate but, of course, 0 is well within any reasonable confidence interval on the standard deviation of the random effects. ?The ML fit converges to an estimate of zero.
>
>> print(fit <- lmer(y ~ dose * day + (1 | comp), verbose=TRUE), corr =
>> FALSE)
> ?0: ? ?-16.846009: ?1.00000
> ?1: ? ?-21.863496: ?0.00000
> ?2: ? ?-21.863496: 3.34671e-05
> ?3: ? ?-21.864249: 0.00511679
> ?4: ? ?-21.910197: 0.0451168
> ?5: ? ?-21.951246: 0.0817081
> ?6: ? ?-21.951470: 0.0899260
> ?7: ? ?-21.951913: 0.0861839
> ?8: ? ?-21.951913: 0.0862678
> ?9: ? ?-21.951913: 0.0862697
> Linear mixed model fit by REML
> Formula: y ~ dose * day + (1 | comp)
> ?REML
> -21.95
>
> Random effects:
> ?Groups ? Name ? ? ? ?Variance ? Std.Dev.
> ?comp ? ? (Intercept) 0.00025129 0.015852
> ?Residual ? ? ? ? ? ? 0.03376472 0.183752
> Number of obs: 133, groups: comp, 3
>
> Fixed effects:
> ? ? ? ? ? ? ?Estimate Std. Error t value
> (Intercept) ?0.9553992 ?0.0183807 ? 51.98
> dose1 ? ? ? -0.0057256 ?0.0194846 ? -0.29
> dose2 ? ? ? ?0.0189734 ?0.0112938 ? ?1.68
> day1 ? ? ? ? 0.0420788 ?0.0193691 ? ?2.17
> day2 ? ? ? ? 0.0032043 ?0.0113592 ? ?0.28
> dose1:day1 ?-0.0057732 ?0.0237223 ? -0.24
> dose2:day1 ?-0.0177054 ?0.0136961 ? -1.29
> dose1:day2 ?-0.0148491 ?0.0138588 ? -1.07
> dose2:day2 ? 0.0007798 ?0.0080636 ? ?0.10
>> print(fitML <- lmer(y ~ dose * day + (1 | comp), verbose=TRUE, REML =
>> 0), corr = FALSE)
> ?0: ? ?-73.180235: ?1.00000
> ?1: ? ?-81.824446: ?0.00000
> ?2: ? ?-81.824446: ?0.00000
> Linear mixed model fit by maximum likelihood
> Formula: y ~ dose * day + (1 | comp)
> ? ?AIC ? ?BIC logLik deviance
> ?-59.82 -28.03 ?40.91 ? -81.82
>
> Random effects:
> ?Groups ? Name ? ? ? ?Variance Std.Dev.
> ?comp ? ? (Intercept) 0.000000 0.00000
> ?Residual ? ? ? ? ? ? 0.031647 0.17790
> Number of obs: 133, groups: comp, 3
>
> Fixed effects:
> ? ? ? ? ? ? ?Estimate Std. Error t value
> (Intercept) ?0.9554630 ?0.0154320 ? 61.91
> dose1 ? ? ? -0.0057222 ?0.0188633 ? -0.30
> dose2 ? ? ? ?0.0190337 ?0.0109334 ? ?1.74
> day1 ? ? ? ? 0.0420788 ?0.0187520 ? ?2.24
> day2 ? ? ? ? 0.0032680 ?0.0109970 ? ?0.30
> dose1:day1 ?-0.0057732 ?0.0229664 ? -0.25
> dose2:day1 ?-0.0177054 ?0.0132597 ? -1.34
> dose1:day2 ?-0.0148456 ?0.0134166 ? -1.11
> dose2:day2 ? 0.0008401 ?0.0078059 ? ?0.11
>
> Note that there are only three distinct levels of comp. ?It is difficult to estimate a variance component with only three distinct levels of the grouping factor.
>
> If you check the prediction intervals on the random effects from this model (plot enclosed) you will see that, even for the REML fit, zero is comfortably within the 95% confidence intervals on all the random effects for the comp factor.
>
> Having said all this, there is a better way of performing the optimization when there is only one parameter in the profiled deviance or profiled REML criterion. ?The development version of the lme4 package, called lme4a on the R-forge site, allows for the model structure to be returned without optimization. ?It is packaged in such a way that the parameter estimates can be determined by optimizers other than nlminb, which is the default.
>
> The optimize function is usually more effective for one-dimensional problems than are more general optimizers such as nlminb or bobyqa.
> If we use optimize on this problem
>
>> fit <- lmer(y ~ dose * day + (1 | comp), doFit = FALSE)
>> optimize(fit at setPars, interval = c(0,4))
> $minimum
> [1] 0.08624942
>
> $objective
> [1] -21.95191
>
>> fit <- lmer(y ~ dose * day + (1 | comp), REML = 0, doFit = FALSE)
>> optimize(fit at setPars, interval = c(0,4))
> $minimum
> [1] 6.96079e-05
>
> $objective
> [1] -81.82445
>
> we do get convergence to non-zero parameter values, although the differences in the objective (either the profiled REML criterion or the profiled deviance) at these values compared to those at zero are negligible.
>



From bates at stat.wisc.edu  Wed Feb  3 19:46:47 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 3 Feb 2010 12:46:47 -0600
Subject: [R-sig-ME] Bug / problems in optimizer of lmer.
In-Reply-To: <40e66e0b1002031018n4cf140e4u8b6d32c02417820b@mail.gmail.com>
References: <A1D6833D0813C941A81D86EE81070A500ADE977FDB@shasta.Genedata.win>
	<40e66e0b1002030729h40f540f5wf53f41c8f2858573@mail.gmail.com>
	<A1D6833D0813C941A81D86EE81070A500ADE97800F@shasta.Genedata.win>
	<40e66e0b1002031018n4cf140e4u8b6d32c02417820b@mail.gmail.com>
Message-ID: <40e66e0b1002031046u265d3976nef79fe7f0411f19c@mail.gmail.com>

On Wed, Feb 3, 2010 at 12:18 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
> On Wed, Feb 3, 2010 at 11:43 AM, Oliver Duerr <Oliver.Duerr at genedata.com> wrote:
>> Dear Douglas Bates,
>>
>> Thanks for the extremely fast and detailed answer.
>>
>> Of course, as you said, 0 is well within any reasonable confidence interval on the standard deviation of the random effects and therefore this is not a real problem for that model and data set. It might be a bit of a pathologic data set, but I still ask myself why the optimizer is trapped around zero. I do not believe this is a real local minimum but rather a numeric artifact looking like a local minimum or a problem with the optimizer. I tried to evaluate and plot the deviance without fitting but I could not download the lme4a package.
>> I am kind of a newbie to R, after a google search I tried
>>
>> ? ? ? ?install.packages("lme4a", repos="http://R-Forge.R-project.org")
>>
>> but that did not work out (package 'lme4a' is not available).
>
> Thanks for the "heads up". ?I frequently don't know what packages have
> been prepared successfully on R-forge because I install these packages
> from the sources - several times on some days. ?It looks as the
> Windows and Mac OS X packages are encountering conflicting definition
> in C++ and C headers. ?The Linux packages are not being built because
> the available version of Matrix is out of date. ?All these issues
> could be addressed given sufficient time, which, regrettably, I don't
> have right now.
>
> I'll see if Uwe's win-builder service can create binary Windows
> packages, although I may need to wait until Matrix_0.999375-35 gets on
> the archives.

To follow up on this, the win-builder succeeds in building a Windows
package but only for R-devel running on 64-bit Windows.  I'll see what
happens for R-patched and 32-bit R-devel once Matrix_0.999375-35 is
installed.  I think there will still be problems with respect to
R-patched because of the C++/C header files conflict.

>> Finally, I guess if this kind sticking to zero only happens for data with their minimum close to zero anyway, than this should not be a problem at all.
>>
>> Thanks again for your help and all the best,
>>
>> Oliver
>>
>>
>>
>>
>>
>> -----Original Message-----
>> From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas Bates
>> Sent: Wednesday, February 03, 2010 4:29 PM
>> To: Oliver Duerr
>> Cc: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] Bug / problems in optimizer of lmer.
>>
>> On Wed, Feb 3, 2010 at 8:32 AM, Oliver Duerr <Oliver.Duerr at genedata.com> wrote:
>>> Hello all,
>>>
>>> First of all I don't know if I am in the right news group to report bug / suspicious behavior in lme4. If not I do apologize.
>>>
>>> I am currently developing a linear mixed model implementation. For
>>> testing I used the model
>>>
>>> y ~ dose * day + (1 | comp)
>>>
>>> and compared my implementation with lmer from lme4_0.999375-32 for about 30'000 different values of y.
>>> Generally the comparison is quite good but for certain y values (approx 100) I found small differences. Looking closer at some of those cases ?I observe that the optimization reaches 0 but then it ?cannot "escape" from anymore.
>>>
>>> One example, reproducible with the data provided below:
>>>>fit <- lmer(y ~ dose * day + (1 | comp), verbose=TRUE)
>>> ?0: ? ?-21.202738: 0.245256
>>> ?1: ? ?-21.863496: ?0.00000
>>> ?2: ? ?-21.863496: 4.14318e-06
>>>
>>> Plotting the one dimensional reduced deviance reveals a minimum at ~ 0.0862 (this minimum can also be found by providing a different start value).
>>>
>>>> fit <- lmer(y ~ dose * day + (1 | comp), verbose=TRUE, start =
>>>> c(0.05))
>>> ?0: ? ?-21.917896: 0.0500000
>>> ?1: ? ?-21.950001: 0.0784911
>>> ?2: ? ?-21.951063: 0.0913211
>>> ?3: ? ?-21.951911: 0.0860209
>>> ?4: ? ?-21.951913: 0.0862628
>>> ?5: ? ?-21.951913: 0.0862698
>>>
>>> In my implementation I had similar problems when I had to evaluate the likelihood at very small numbers it began to fluctuated and the optimizer had been trapped in a local minimum due to these numeric instabilities.
>>>
>>> Is this behavior known or do I maybe use lmer in a wrong way?
>>
>> It is known in the sense that numerical optimization is not guaranteed to produce a global optimum. ?At best it can produce a local optimum.
>> On my system the REML fit does converge to the optimum you indicate but, of course, 0 is well within any reasonable confidence interval on the standard deviation of the random effects. ?The ML fit converges to an estimate of zero.
>>
>>> print(fit <- lmer(y ~ dose * day + (1 | comp), verbose=TRUE), corr =
>>> FALSE)
>> ?0: ? ?-16.846009: ?1.00000
>> ?1: ? ?-21.863496: ?0.00000
>> ?2: ? ?-21.863496: 3.34671e-05
>> ?3: ? ?-21.864249: 0.00511679
>> ?4: ? ?-21.910197: 0.0451168
>> ?5: ? ?-21.951246: 0.0817081
>> ?6: ? ?-21.951470: 0.0899260
>> ?7: ? ?-21.951913: 0.0861839
>> ?8: ? ?-21.951913: 0.0862678
>> ?9: ? ?-21.951913: 0.0862697
>> Linear mixed model fit by REML
>> Formula: y ~ dose * day + (1 | comp)
>> ?REML
>> -21.95
>>
>> Random effects:
>> ?Groups ? Name ? ? ? ?Variance ? Std.Dev.
>> ?comp ? ? (Intercept) 0.00025129 0.015852
>> ?Residual ? ? ? ? ? ? 0.03376472 0.183752
>> Number of obs: 133, groups: comp, 3
>>
>> Fixed effects:
>> ? ? ? ? ? ? ?Estimate Std. Error t value
>> (Intercept) ?0.9553992 ?0.0183807 ? 51.98
>> dose1 ? ? ? -0.0057256 ?0.0194846 ? -0.29
>> dose2 ? ? ? ?0.0189734 ?0.0112938 ? ?1.68
>> day1 ? ? ? ? 0.0420788 ?0.0193691 ? ?2.17
>> day2 ? ? ? ? 0.0032043 ?0.0113592 ? ?0.28
>> dose1:day1 ?-0.0057732 ?0.0237223 ? -0.24
>> dose2:day1 ?-0.0177054 ?0.0136961 ? -1.29
>> dose1:day2 ?-0.0148491 ?0.0138588 ? -1.07
>> dose2:day2 ? 0.0007798 ?0.0080636 ? ?0.10
>>> print(fitML <- lmer(y ~ dose * day + (1 | comp), verbose=TRUE, REML =
>>> 0), corr = FALSE)
>> ?0: ? ?-73.180235: ?1.00000
>> ?1: ? ?-81.824446: ?0.00000
>> ?2: ? ?-81.824446: ?0.00000
>> Linear mixed model fit by maximum likelihood
>> Formula: y ~ dose * day + (1 | comp)
>> ? ?AIC ? ?BIC logLik deviance
>> ?-59.82 -28.03 ?40.91 ? -81.82
>>
>> Random effects:
>> ?Groups ? Name ? ? ? ?Variance Std.Dev.
>> ?comp ? ? (Intercept) 0.000000 0.00000
>> ?Residual ? ? ? ? ? ? 0.031647 0.17790
>> Number of obs: 133, groups: comp, 3
>>
>> Fixed effects:
>> ? ? ? ? ? ? ?Estimate Std. Error t value
>> (Intercept) ?0.9554630 ?0.0154320 ? 61.91
>> dose1 ? ? ? -0.0057222 ?0.0188633 ? -0.30
>> dose2 ? ? ? ?0.0190337 ?0.0109334 ? ?1.74
>> day1 ? ? ? ? 0.0420788 ?0.0187520 ? ?2.24
>> day2 ? ? ? ? 0.0032680 ?0.0109970 ? ?0.30
>> dose1:day1 ?-0.0057732 ?0.0229664 ? -0.25
>> dose2:day1 ?-0.0177054 ?0.0132597 ? -1.34
>> dose1:day2 ?-0.0148456 ?0.0134166 ? -1.11
>> dose2:day2 ? 0.0008401 ?0.0078059 ? ?0.11
>>
>> Note that there are only three distinct levels of comp. ?It is difficult to estimate a variance component with only three distinct levels of the grouping factor.
>>
>> If you check the prediction intervals on the random effects from this model (plot enclosed) you will see that, even for the REML fit, zero is comfortably within the 95% confidence intervals on all the random effects for the comp factor.
>>
>> Having said all this, there is a better way of performing the optimization when there is only one parameter in the profiled deviance or profiled REML criterion. ?The development version of the lme4 package, called lme4a on the R-forge site, allows for the model structure to be returned without optimization. ?It is packaged in such a way that the parameter estimates can be determined by optimizers other than nlminb, which is the default.
>>
>> The optimize function is usually more effective for one-dimensional problems than are more general optimizers such as nlminb or bobyqa.
>> If we use optimize on this problem
>>
>>> fit <- lmer(y ~ dose * day + (1 | comp), doFit = FALSE)
>>> optimize(fit at setPars, interval = c(0,4))
>> $minimum
>> [1] 0.08624942
>>
>> $objective
>> [1] -21.95191
>>
>>> fit <- lmer(y ~ dose * day + (1 | comp), REML = 0, doFit = FALSE)
>>> optimize(fit at setPars, interval = c(0,4))
>> $minimum
>> [1] 6.96079e-05
>>
>> $objective
>> [1] -81.82445
>>
>> we do get convergence to non-zero parameter values, although the differences in the objective (either the profiled REML criterion or the profiled deviance) at these values compared to those at zero are negligible.
>>
>



From h.lingsma at erasmusmc.nl  Thu Feb  4 12:32:25 2010
From: h.lingsma at erasmusmc.nl (Hester Lingsma)
Date: Thu, 04 Feb 2010 12:32:25 +0100
Subject: [R-sig-ME] postVar in ranef function
Message-ID: <4B6AB049.6080001@erasmusmc.nl>

Dear R users,
For some strange reason the postVar=T statement in the extraction of the 
random effects (with ranef) is not working anymore. I use ranef (model1, 
postVar=T) but I just get the posterior estimates, not the variance. In 
the past it worked fine. Does anyone have an idea what is happening here?
Best wishes,
Hester

-- 
_________________________________________________
Hester F. Lingsma, MSc
Dept of Public Health
Room AE-141
Erasmus MC
P.O. Box 2040
3000 CA Rotterdam
The Netherlands
Phone: (+31) (0)10 7038458/7038460
Mobile: (+31) (0)6 26467338



From bates at stat.wisc.edu  Thu Feb  4 16:13:22 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 4 Feb 2010 09:13:22 -0600
Subject: [R-sig-ME] postVar in ranef function
In-Reply-To: <4B6AB049.6080001@erasmusmc.nl>
References: <4B6AB049.6080001@erasmusmc.nl>
Message-ID: <40e66e0b1002040713s3e38b84am54696abca6bbb3d1@mail.gmail.com>

Could you provide a reproducible example, please?  In the example
below I don't see a changed behavior.

Note that the printed output from ranef doesn't change with postVar =
TRUE.  The conditional variance-covariance matrices are attached as an
attribute.

> (fm1 <- lmer(Reaction ~ 1 + Days + (1 + Days|Subject), sleepstudy))
Linear mixed model fit by REML
Formula: Reaction ~ 1 + Days + (1 + Days | Subject)
   Data: sleepstudy
  AIC  BIC logLik deviance REMLdev
 1756 1775 -871.8     1752    1744
Random effects:
 Groups   Name        Variance Std.Dev. Corr
 Subject  (Intercept) 612.090  24.7405
          Days         35.072   5.9221  0.066
 Residual             654.941  25.5918
Number of obs: 180, groups: Subject, 18

Fixed effects:
            Estimate Std. Error t value
(Intercept)  251.405      6.825   36.84
Days          10.467      1.546    6.77

Correlation of Fixed Effects:
     (Intr)
Days -0.138
> str(ranef(fm1))
List of 1
 $ Subject:'data.frame':	18 obs. of  2 variables:
  ..$ (Intercept): num [1:18] 2.26 -40.4 -38.96 23.69 22.26 ...
  ..$ Days       : num [1:18] 9.2 -8.62 -5.45 -4.81 -3.07 ...
 - attr(*, "class")= chr "ranef.mer"
> str(ranef(fm1, postVar = TRUE))
List of 1
 $ Subject:'data.frame':	18 obs. of  2 variables:
  ..$ (Intercept): num [1:18] 2.26 -40.4 -38.96 23.69 22.26 ...
  ..$ Days       : num [1:18] 9.2 -8.62 -5.45 -4.81 -3.07 ...
  ..- attr(*, "postVar")= num [1:2, 1:2, 1:18] 145.71 -21.44 -21.44
5.31 145.71 ...
 - attr(*, "class")= chr "ranef.mer"
> sessionInfo()
R version 2.10.1 (2009-12-14)
x86_64-pc-linux-gnu

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999375-32   Matrix_0.999375-33 lattice_0.18-3

loaded via a namespace (and not attached):
[1] grid_2.10.1  tools_2.10.1


ranef(myModel, postVar = TRUE)




On Thu, Feb 4, 2010 at 5:32 AM, Hester Lingsma <h.lingsma at erasmusmc.nl> wrote:
> Dear R users,
> For some strange reason the postVar=T statement in the extraction of the
> random effects (with ranef) is not working anymore. I use ranef (model1,
> postVar=T) but I just get the posterior estimates, not the variance. In the
> past it worked fine. Does anyone have an idea what is happening here?
> Best wishes,
> Hester
>
> --
> _________________________________________________
> Hester F. Lingsma, MSc
> Dept of Public Health
> Room AE-141
> Erasmus MC
> P.O. Box 2040
> 3000 CA Rotterdam
> The Netherlands
> Phone: (+31) (0)10 7038458/7038460
> Mobile: (+31) (0)6 26467338
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From s90225007 at yahoo.com.tw  Thu Feb  4 16:15:55 2010
From: s90225007 at yahoo.com.tw (Nai-Wei Chen)
Date: Thu, 4 Feb 2010 23:15:55 +0800 (CST)
Subject: [R-sig-ME] How to retrieve estimates from glmer()
Message-ID: <132279.51150.qm@web72906.mail.tp2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100204/8327a71f/attachment.pl>

From cahn88 at gmail.com  Thu Feb  4 18:36:11 2010
From: cahn88 at gmail.com (Chaehyung Ahn)
Date: Thu, 4 Feb 2010 12:36:11 -0500
Subject: [R-sig-ME] nonlinear models with warnOnly
Message-ID: <800cb8d51002040936tb662068jd4cfa5c6c38c0cfa@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100204/44d734bc/attachment.pl>

From smckinney at bccrc.ca  Thu Feb  4 21:29:25 2010
From: smckinney at bccrc.ca (Steven McKinney)
Date: Thu, 4 Feb 2010 12:29:25 -0800
Subject: [R-sig-ME] nonlinear models with warnOnly
In-Reply-To: <19837_1265305186_1265305186_800cb8d51002040936tb662068jd4cfa5c6c38c0cfa@mail.gmail.com>
References: <19837_1265305186_1265305186_800cb8d51002040936tb662068jd4cfa5c6c38c0cfa@mail.gmail.com>
Message-ID: <DCE81E14EB74504B971DAD4D2DB0356B032C6259C7@crcmail4.BCCRC.CA>


> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-
> models-bounces at r-project.org] On Behalf Of Chaehyung Ahn
> Sent: Thursday, February 04, 2010 9:36 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] nonlinear models with warnOnly
> 
> Dear list,
> 
> I need to make nls() or gnls() function to return something like "NA"
> when
> it fails to fit. I found I can use "warnOnly", but I cannot make it
> work.
> 
> In the following program. I intentionally make it fail by making very
> wrong
> initial values, but the "out" is empty. What is wrong with my approach?
> 
> Many thanks in advance!
> 
> library(nlme)
> out<- gnls(conc~SSbiexp(time,A,lalpha,B,lbeta),
>           start=list(A=-1,lalpha=2,B=20,lbeta=4),
>           weights=varPower(fixed=1),control=list(warnOnly=TRUE),
>           data=Indometh,subset=Subject==1)

Have you explored using the "try()" or "tryCatch()"
strategies?


 out <- try(gnls(conc~SSbiexp(time,A,lalpha,B,lbeta),
           start=list(A=-1,lalpha=2,B=20,lbeta=4),
           weights=varPower(fixed=1),
           data=Indometh,subset=Subject==1))

Then if the fit fails, variable "out" will have class "try-error"
so you can check the class of out and decide what to do etc.


(I tried your example in R 2.10.1 on a Mac and R 2.9.2 on a PC and
get an error that I haven't been able to track down yet.
> require("nlme")
Loading required package: nlme
> out<- gnls(conc~SSbiexp(time,A,lalpha,B,lbeta),
+            start=list(A=-1,lalpha=2,B=20,lbeta=4),
+            weights=varPower(fixed=1),control=list(warnOnly=TRUE),
+            data=Indometh,subset=Subject==1)
Error: object 'convIter' not found
> 
> 
>  out<- try(gnls(conc~SSbiexp(time,A,lalpha,B,lbeta),
+            start=list(A=-1,lalpha=2,B=20,lbeta=4),
+            weights=varPower(fixed=1),
+            data=Indometh,subset=Subject==1))
Error : object 'convIter' not found
>
)

Best

Steve McKinney


> 
> 
> 
> 
> --
> Chaehyung Ahn, Ph.D.
> 4033 Remington Oaks Circle
> Cary, NC 27519
> Daum Cafe: http://cafe.daum.net/biometrika
> Blog: http://cahn88.blogspot.com/
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models




Steven McKinney, Ph.D.

Statistician
Molecular Oncology and Breast Cancer Program
British Columbia Cancer Research Centre

email: smckinney -at-  bccrc +dot+ ca
tel: 604-675-8000 x7561

BCCRC
Molecular Oncology
675 West 10th Ave, Floor 4
Vancouver B.C.
V5Z 1L3

Canada



From cahn88 at gmail.com  Thu Feb  4 21:47:44 2010
From: cahn88 at gmail.com (Chaehyung Ahn)
Date: Thu, 4 Feb 2010 15:47:44 -0500
Subject: [R-sig-ME] nonlinear models with warnOnly
In-Reply-To: <DCE81E14EB74504B971DAD4D2DB0356B032C6259C7@crcmail4.BCCRC.CA>
References: <19837_1265305186_1265305186_800cb8d51002040936tb662068jd4cfa5c6c38c0cfa@mail.gmail.com>
	<DCE81E14EB74504B971DAD4D2DB0356B032C6259C7@crcmail4.BCCRC.CA>
Message-ID: <800cb8d51002041247l49394971s14fb0da9ed117bf2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100204/68ab1480/attachment.pl>

From dhsu2 at uw.edu  Thu Feb  4 22:01:01 2010
From: dhsu2 at uw.edu (David Hsu)
Date: Thu, 4 Feb 2010 13:01:01 -0800
Subject: [R-sig-ME] Convergence check in lmer()
Message-ID: <8e8b187b1002041301r180cfcf3n11b81e6a81e27d73@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100204/27eb710d/attachment.pl>

From smckinney at bccrc.ca  Thu Feb  4 22:13:26 2010
From: smckinney at bccrc.ca (Steven McKinney)
Date: Thu, 4 Feb 2010 13:13:26 -0800
Subject: [R-sig-ME] nonlinear models with warnOnly
In-Reply-To: <800cb8d51002041247l49394971s14fb0da9ed117bf2@mail.gmail.com>
References: <19837_1265305186_1265305186_800cb8d51002040936tb662068jd4cfa5c6c38c0cfa@mail.gmail.com>
	<DCE81E14EB74504B971DAD4D2DB0356B032C6259C7@crcmail4.BCCRC.CA>,
	<800cb8d51002041247l49394971s14fb0da9ed117bf2@mail.gmail.com>
Message-ID: <DCE81E14EB74504B971DAD4D2DB0356B032C7C5B6B@crcmail4.BCCRC.CA>

Hi Cahn

Have you tried the "verbose" argument to gnls?
That will make gnls() print out information on each iteration before it
throws the error.

Steve McKinney
________________________________________
From: Chaehyung Ahn [cahn88 at gmail.com]
Sent: February 4, 2010 12:47 PM
To: Steven McKinney
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] nonlinear models with warnOnly

Hi Steven,

Thank you for your reply.

But I need to this to prevent the error from stopping the iteration. I need to count how many time the model fits without error.

cahn



On Thu, Feb 4, 2010 at 3:29 PM, Steven McKinney <smckinney at bccrc.ca<mailto:smckinney at bccrc.ca>> wrote:

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org> [mailto:r-sig-mixed-<mailto:r-sig-mixed->
> models-bounces at r-project.org<mailto:models-bounces at r-project.org>] On Behalf Of Chaehyung Ahn
> Sent: Thursday, February 04, 2010 9:36 AM
> To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] nonlinear models with warnOnly
>
> Dear list,
>
> I need to make nls() or gnls() function to return something like "NA"
> when
> it fails to fit. I found I can use "warnOnly", but I cannot make it
> work.
>
> In the following program. I intentionally make it fail by making very
> wrong
> initial values, but the "out" is empty. What is wrong with my approach?
>
> Many thanks in advance!
>
> library(nlme)
> out<- gnls(conc~SSbiexp(time,A,lalpha,B,lbeta),
>           start=list(A=-1,lalpha=2,B=20,lbeta=4),
>           weights=varPower(fixed=1),control=list(warnOnly=TRUE),
>           data=Indometh,subset=Subject==1)

Have you explored using the "try()" or "tryCatch()"
strategies?


 out <- try(gnls(conc~SSbiexp(time,A,lalpha,B,lbeta),
          start=list(A=-1,lalpha=2,B=20,lbeta=4),
          weights=varPower(fixed=1),
          data=Indometh,subset=Subject==1))

Then if the fit fails, variable "out" will have class "try-error"
so you can check the class of out and decide what to do etc.


(I tried your example in R 2.10.1 on a Mac and R 2.9.2 on a PC and
get an error that I haven't been able to track down yet.
> require("nlme")
Loading required package: nlme
> out<- gnls(conc~SSbiexp(time,A,lalpha,B,lbeta),
+            start=list(A=-1,lalpha=2,B=20,lbeta=4),
+            weights=varPower(fixed=1),control=list(warnOnly=TRUE),
+            data=Indometh,subset=Subject==1)
Error: object 'convIter' not found
>
>
>  out<- try(gnls(conc~SSbiexp(time,A,lalpha,B,lbeta),
+            start=list(A=-1,lalpha=2,B=20,lbeta=4),
+            weights=varPower(fixed=1),
+            data=Indometh,subset=Subject==1))
Error : object 'convIter' not found
>
)

Best

Steve McKinney


>
>
>
>
> --
> Chaehyung Ahn, Ph.D.
> 4033 Remington Oaks Circle
> Cary, NC 27519
> Daum Cafe: http://cafe.daum.net/biometrika
> Blog: http://cahn88.blogspot.com/
>
>       [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models




Steven McKinney, Ph.D.

Statistician
Molecular Oncology and Breast Cancer Program
British Columbia Cancer Research Centre

email: smckinney -at-  bccrc +dot+ ca
tel: 604-675-8000 x7561

BCCRC
Molecular Oncology
675 West 10th Ave, Floor 4
Vancouver B.C.
V5Z 1L3

Canada




--
Chaehyung Ahn, Ph.D.
4033 Remington Oaks Circle
Cary, NC 27519
Daum Cafe: http://cafe.daum.net/biometrika
Blog: http://cahn88.blogspot.com/



From smckinney at bccrc.ca  Thu Feb  4 22:27:20 2010
From: smckinney at bccrc.ca (Steven McKinney)
Date: Thu, 4 Feb 2010 13:27:20 -0800
Subject: [R-sig-ME] nonlinear models with warnOnly
In-Reply-To: <800cb8d51002041247l49394971s14fb0da9ed117bf2@mail.gmail.com>
References: <19837_1265305186_1265305186_800cb8d51002040936tb662068jd4cfa5c6c38c0cfa@mail.gmail.com>
	<DCE81E14EB74504B971DAD4D2DB0356B032C6259C7@crcmail4.BCCRC.CA>,
	<800cb8d51002041247l49394971s14fb0da9ed117bf2@mail.gmail.com>
Message-ID: <DCE81E14EB74504B971DAD4D2DB0356B032C7C5B6C@crcmail4.BCCRC.CA>

Hi Cahn,

I'm not seeing a "warnOnly" argument to gnlsControl.
I do see a returnObject argument

returnObject	 a logical value indicating whether the fitted object should be returned when the maximum number of iterations is reached without convergence of the algorithm. Default is FALSE.

With returnObject=TRUE you will get output even if the fitting fails (the error appears to be downgraded to a warning). 

> fm <- gnls(weight ~ SSlogis(Time, Asym, xmid, scal), Soybean,
+            weights = varPower(), start = list(Asym = 2000, xmid = 1, scal = 100),
+            verbose = TRUE, control=list(returnObject = TRUE))

**Iteration 1
GLS step: Objective: NULLvarStruct  parameters:
    power 
0.9431074 
Warning message:
In gnls(weight ~ SSlogis(Time, Asym, xmid, scal), Soybean, weights = varPower(),  :
  Step halving factor reduced below minimum in NLS step
> fm
Generalized nonlinear least squares fit
  Model: weight ~ SSlogis(Time, Asym, xmid, scal) 
  Data: Soybean 
  Log-likelihood: -1381.013

Coefficients:
Asym xmid scal 
2000    1  100 

Variance function:
 Structure: Power of variance covariate
 Formula: ~fitted(.) 
 Parameter estimates:
    power 
0.9431074 
Degrees of freedom: 412 total; 409 residual
Residual standard error: 0.008625526 
> fm$numIter
[1] 1
> 

Steve McKinney
________________________________________
From: Chaehyung Ahn [cahn88 at gmail.com]
Sent: February 4, 2010 12:47 PM
To: Steven McKinney
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] nonlinear models with warnOnly

Hi Steven,

Thank you for your reply.

But I need to this to prevent the error from stopping the iteration. I need to count how many time the model fits without error.

cahn



On Thu, Feb 4, 2010 at 3:29 PM, Steven McKinney <smckinney at bccrc.ca<mailto:smckinney at bccrc.ca>> wrote:

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org> [mailto:r-sig-mixed-<mailto:r-sig-mixed->
> models-bounces at r-project.org<mailto:models-bounces at r-project.org>] On Behalf Of Chaehyung Ahn
> Sent: Thursday, February 04, 2010 9:36 AM
> To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] nonlinear models with warnOnly
>
> Dear list,
>
> I need to make nls() or gnls() function to return something like "NA"
> when
> it fails to fit. I found I can use "warnOnly", but I cannot make it
> work.
>
> In the following program. I intentionally make it fail by making very
> wrong
> initial values, but the "out" is empty. What is wrong with my approach?
>
> Many thanks in advance!
>
> library(nlme)
> out<- gnls(conc~SSbiexp(time,A,lalpha,B,lbeta),
>           start=list(A=-1,lalpha=2,B=20,lbeta=4),
>           weights=varPower(fixed=1),control=list(warnOnly=TRUE),
>           data=Indometh,subset=Subject==1)

Have you explored using the "try()" or "tryCatch()"
strategies?


 out <- try(gnls(conc~SSbiexp(time,A,lalpha,B,lbeta),
          start=list(A=-1,lalpha=2,B=20,lbeta=4),
          weights=varPower(fixed=1),
          data=Indometh,subset=Subject==1))

Then if the fit fails, variable "out" will have class "try-error"
so you can check the class of out and decide what to do etc.


(I tried your example in R 2.10.1 on a Mac and R 2.9.2 on a PC and
get an error that I haven't been able to track down yet.
> require("nlme")
Loading required package: nlme
> out<- gnls(conc~SSbiexp(time,A,lalpha,B,lbeta),
+            start=list(A=-1,lalpha=2,B=20,lbeta=4),
+            weights=varPower(fixed=1),control=list(warnOnly=TRUE),
+            data=Indometh,subset=Subject==1)
Error: object 'convIter' not found
>
>
>  out<- try(gnls(conc~SSbiexp(time,A,lalpha,B,lbeta),
+            start=list(A=-1,lalpha=2,B=20,lbeta=4),
+            weights=varPower(fixed=1),
+            data=Indometh,subset=Subject==1))
Error : object 'convIter' not found
>
)

Best

Steve McKinney


>
>
>
>
> --
> Chaehyung Ahn, Ph.D.
> 4033 Remington Oaks Circle
> Cary, NC 27519
> Daum Cafe: http://cafe.daum.net/biometrika
> Blog: http://cahn88.blogspot.com/
>
>       [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models




Steven McKinney, Ph.D.

Statistician
Molecular Oncology and Breast Cancer Program
British Columbia Cancer Research Centre

email: smckinney -at-  bccrc +dot+ ca
tel: 604-675-8000 x7561

BCCRC
Molecular Oncology
675 West 10th Ave, Floor 4
Vancouver B.C.
V5Z 1L3

Canada




--
Chaehyung Ahn, Ph.D.
4033 Remington Oaks Circle
Cary, NC 27519
Daum Cafe: http://cafe.daum.net/biometrika
Blog: http://cahn88.blogspot.com/



From dhsu2 at uw.edu  Fri Feb  5 07:46:33 2010
From: dhsu2 at uw.edu (David Hsu)
Date: Thu, 4 Feb 2010 22:46:33 -0800
Subject: [R-sig-ME] Convergence check in lmer()
Message-ID: <8e8b187b1002042246k27be00d4k9ed73d9e5653cba4@mail.gmail.com>

Dear all,

(Sorry for the double posting, but the message was apparently scrubbed before).

I've been running a series of large models on a remote computer, and store
the model results as .rda files after every run to free up memory.  However,
I'm worried that some of the models did not in fact reach convergence.  How
can I check whether the models reached convergence from the resulting model
objects?

My example code, where M1 is the model object that I am storing:

M1 <- lmer( y ~ avgprcp + avgtemp + (1 + mp + dv |acct), data = dat,
verbose=TRUE)
# you can see the message that it did not reach convergence after the
iterations
save(M1, file="M1.rda")
rm(list=ls())
load("M1.rda")
summary(M1)

Sincerely,

David Hsu


--
David Hsu
PhD Candidate, Urban Planning
University of Washington
(e-mail) dhsu2 at uw.edu



From h.lingsma at erasmusmc.nl  Fri Feb  5 11:16:36 2010
From: h.lingsma at erasmusmc.nl (Hester Lingsma)
Date: Fri, 05 Feb 2010 11:16:36 +0100
Subject: [R-sig-ME] postVar in ranef function
In-Reply-To: <40e66e0b1002040713s3e38b84am54696abca6bbb3d1@mail.gmail.com>
References: <4B6AB049.6080001@erasmusmc.nl>
	<40e66e0b1002040713s3e38b84am54696abca6bbb3d1@mail.gmail.com>
Message-ID: <4B6BF004.9090606@erasmusmc.nl>

Dear Prof Bates,
Thank you very much for the reply. You already solved my problem, I 
indeed did not notice that the printed output from ranef doesn't change 
with postVar =TRUE. Very stupid. Thanks again!
Hester Lingsma 
 
on 04-02-2010 16:13 Douglas Bates said the following:
> Could you provide a reproducible example, please?  In the example
> below I don't see a changed behavior.
>
> Note that the printed output from ranef doesn't change with postVar =
> TRUE.  The conditional variance-covariance matrices are attached as an
> attribute.
>
>   
>> (fm1 <- lmer(Reaction ~ 1 + Days + (1 + Days|Subject), sleepstudy))
>>     
> Linear mixed model fit by REML
> Formula: Reaction ~ 1 + Days + (1 + Days | Subject)
>    Data: sleepstudy
>   AIC  BIC logLik deviance REMLdev
>  1756 1775 -871.8     1752    1744
> Random effects:
>  Groups   Name        Variance Std.Dev. Corr
>  Subject  (Intercept) 612.090  24.7405
>           Days         35.072   5.9221  0.066
>  Residual             654.941  25.5918
> Number of obs: 180, groups: Subject, 18
>
> Fixed effects:
>             Estimate Std. Error t value
> (Intercept)  251.405      6.825   36.84
> Days          10.467      1.546    6.77
>
> Correlation of Fixed Effects:
>      (Intr)
> Days -0.138
>   
>> str(ranef(fm1))
>>     
> List of 1
>  $ Subject:'data.frame':	18 obs. of  2 variables:
>   ..$ (Intercept): num [1:18] 2.26 -40.4 -38.96 23.69 22.26 ...
>   ..$ Days       : num [1:18] 9.2 -8.62 -5.45 -4.81 -3.07 ...
>  - attr(*, "class")= chr "ranef.mer"
>   
>> str(ranef(fm1, postVar = TRUE))
>>     
> List of 1
>  $ Subject:'data.frame':	18 obs. of  2 variables:
>   ..$ (Intercept): num [1:18] 2.26 -40.4 -38.96 23.69 22.26 ...
>   ..$ Days       : num [1:18] 9.2 -8.62 -5.45 -4.81 -3.07 ...
>   ..- attr(*, "postVar")= num [1:2, 1:2, 1:18] 145.71 -21.44 -21.44
> 5.31 145.71 ...
>  - attr(*, "class")= chr "ranef.mer"
>   
>> sessionInfo()
>>     
> R version 2.10.1 (2009-12-14)
> x86_64-pc-linux-gnu
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] lme4_0.999375-32   Matrix_0.999375-33 lattice_0.18-3
>
> loaded via a namespace (and not attached):
> [1] grid_2.10.1  tools_2.10.1
>
>
> ranef(myModel, postVar = TRUE)
>
>
>
>
> On Thu, Feb 4, 2010 at 5:32 AM, Hester Lingsma <h.lingsma at erasmusmc.nl> wrote:
>   
>> Dear R users,
>> For some strange reason the postVar=T statement in the extraction of the
>> random effects (with ranef) is not working anymore. I use ranef (model1,
>> postVar=T) but I just get the posterior estimates, not the variance. In the
>> past it worked fine. Does anyone have an idea what is happening here?
>> Best wishes,
>> Hester
>>
>> --
>> _________________________________________________
>> Hester F. Lingsma, MSc
>> Dept of Public Health
>> Room AE-141
>> Erasmus MC
>> P.O. Box 2040
>> 3000 CA Rotterdam
>> The Netherlands
>> Phone: (+31) (0)10 7038458/7038460
>> Mobile: (+31) (0)6 26467338
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>     

-- 
_________________________________________________
Hester F. Lingsma, MSc
Dept of Public Health
Room AE-141
Erasmus MC
P.O. Box 2040
3000 CA Rotterdam
The Netherlands
Phone: (+31) (0)10 7038458/7038460
Mobile: (+31) (0)6 26467338



From trea26 at gmail.com  Fri Feb  5 15:53:52 2010
From: trea26 at gmail.com (Antoine Tremblay)
Date: Fri, 5 Feb 2010 09:53:52 -0500
Subject: [R-sig-ME] Convergence check in lmer()
Message-ID: <581a8bcf1002050653p537f46f5n22e7f27da8c3ad97@mail.gmail.com>

Dear David,

You could do something like create a log file where you would redirect
the warnings and error messages and then check the logs to see if a
particular model converged or not. For instance:

options(warn=1)
wngs=file("temp.txt",open="w+",blocking=TRUE)
sink(wngs,type="message")

Then to link up a specific model to the warning message (to know which
model did not converge) you could insert the following line before
running each model:

message("M1")

where "M1" is the name of the model object.

Then run your model

M1 <- lmer( y ~ avgprcp + avgtemp + (1 + mp + dv |acct), data = dat,
verbose=TRUE)
# you can see the message that it did not reach convergence after the iterations
save(M1, file="M1.rda")
rm(list=ls())
load("M1.rda")
summary(M1)

and repeat the same thing for your other models.

This would create a file named temp.txt that would contain first the
name of the model object then any warnings (if there were any) and
then the name of the next model object, and so forth.

--
Antoine Tremblay
Department of Neuroscience
Georgetown University
Washington DC

> Message: 7
> Date: Thu, 4 Feb 2010 13:01:01 -0800
> From: David Hsu <dhsu2 at uw.edu>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Convergence check in lmer()
> Message-ID:
>        <8e8b187b1002041301r180cfcf3n11b81e6a81e27d73 at mail.gmail.com>
> Content-Type: text/plain
>
> Dear all,
>
> I've been running a series of large models on a remote computer, and store
> the model results as .rda files after every run to free up memory.  However,
> I'm worried that some of the models did not in fact reach convergence.  How
> can I check whether the models reached convergence from the resulting model
> objects?
>
> My example code, where M1 is the model object that I am storing:
>
> M1 <- lmer( y ~ avgprcp + avgtemp + (1 + mp + dv |acct), data = dat,
> verbose=TRUE)
> # you can see the message that it did not reach convergence after the
> iterations
> save(M1, file="M1.rda")
> rm(list=ls())
> load("M1.rda")
> summary(M1)
>
> Sincerely,
>
> David Hsu
>
>
> --
> David Hsu
> PhD Candidate, Urban Planning
> University of Washington
> (e-mail) dhsu2 at uw.edu
>
>        [[alternative HTML version deleted]]
>
>
>
> ------------------------------
>
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> End of R-sig-mixed-models Digest, Vol 38, Issue 6
> *************************************************
>



From j.hadfield at ed.ac.uk  Sat Feb  6 01:47:08 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 06 Feb 2010 00:47:08 +0000
Subject: [R-sig-ME] MCMCglmm update
In-Reply-To: <581a8bcf1002050653p537f46f5n22e7f27da8c3ad97@mail.gmail.com>
References: <581a8bcf1002050653p537f46f5n22e7f27da8c3ad97@mail.gmail.com>
Message-ID: <20100206004708.41blb60a8scs04k4@www.staffmail.ed.ac.uk>

Hi,

I've update MCMCglmm (2.02) and it should appear on CRAN soon. The  
main changes are:

1) After many questions regarding multivariate binary and multivariate  
ordinal models I've now implemented a sampler for correlation  
matrices. Simply  use "cor" instead of "us".

2) I found a bug regarding a cholesky update. Potentially it can  
affect analyses that use parameter expansion and analyses that have  
conditionally independent blocks of missing data. The effects are  
likely to be subtle; I only noticed it during an analysis of 2 data  
points both of which were missing, and even then the discrepancy  
between the sampled posterior and that expected (the prior) was small.

3) The companion paper to MCMCglmm has now been published in The  
journal of Statistical Software. If you use MCMCglmm I would be  
grateful if you could cite this paper.

If anyone could provide feedback on the behaviour of the correlation  
sampler I'd be grateful.

Thanks,

Jarrod


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From fog0 at gmx.com  Tue Feb  9 08:21:52 2010
From: fog0 at gmx.com (Doug Adams)
Date: Tue, 9 Feb 2010 00:21:52 -0700
Subject: [R-sig-ME] anova on lmer object
Message-ID: <74cfd9161002082321v44c8c0a2sc6cde9a46a43dd2d@mail.gmail.com>

Maybe this has been asked many times before, but I couldn't find it
exactly:  When you use anova() on an lmer object -- like "
anova(lmer(...)) " -- what is being calculated?  I assume it's a test
for the significance of fixed effects, but just wanted to know how
it's being done.   :)

Thanks,



From h.lingsma at erasmusmc.nl  Tue Feb  9 09:50:10 2010
From: h.lingsma at erasmusmc.nl (Hester Lingsma)
Date: Tue, 09 Feb 2010 09:50:10 +0100
Subject: [R-sig-ME] var-covar matrix in ranef
In-Reply-To: <Pine.LNX.4.64.0912151821280.15161@orpheus.qimr.edu.au>
References: <4B2745DD.5020308@erasmusmc.nl>
	<Pine.LNX.4.64.0912151821280.15161@orpheus.qimr.edu.au>
Message-ID: <4B7121C2.9040305@erasmusmc.nl>

Dear R users,
If I fit a model with a random slope and a random intercept, the 
var-covar matrix derived from PostVar from the function ranef is a 2 by 
2 matrix for each upper level subject. I want to use the posterior 
estimates (from ranef) and their standard error from both the slope and 
the intercepct for each upper level subject. Which elemants of the 2 by 
2 matrixes to use for the se of the posterior estimate?
Thanks,
Hester

_________________________________________________
Hester F. Lingsma, MSc
Dept of Public Health
Room AE-141
Erasmus MC
P.O. Box 2040
3000 CA Rotterdam
The Netherlands
Phone: (+31) (0)10 7038458/7038460
Mobile: (+31) (0)6 26467338



From marianne.promberger at kcl.ac.uk  Tue Feb  9 12:16:55 2010
From: marianne.promberger at kcl.ac.uk (Marianne Promberger)
Date: Tue, 9 Feb 2010 11:16:55 +0000
Subject: [R-sig-ME] anova on lmer object
In-Reply-To: <74cfd9161002082321v44c8c0a2sc6cde9a46a43dd2d@mail.gmail.com>
References: <74cfd9161002082321v44c8c0a2sc6cde9a46a43dd2d@mail.gmail.com>
Message-ID: <20100209111655.GA23546@lauren>

Doug Adams <fog0 at gmx.com> 09-Feb-10 07:21:
> When you use anova() on an lmer object -- like " anova(lmer(...)) "
> -- what is being calculated?  I assume it's a test for the
> significance of fixed effects, but just wanted to know how it's
> being done.  :)

It is a likelihood ratio test. 

I'm also just getting my head around mixed models and lmer() and found
this paper very helpful:

Baayen, R. H., Davidson, D. J., and Bates, D. M. (2008). Mixed-effects
modeling with crossed random effects for subjects and items. Journal
of Memory and Language, 59(4):390-412.

http://dx.doi.org/10.1016/j.jml.2007.12.005

See p 395 for comparing two models with anova()

Marianne

-- 
Marianne Promberger PhD, King's College London
http://promberger.info
R version 2.10.1 (2009-12-14)
Ubuntu 9.04



From h.lingsma at erasmusmc.nl  Tue Feb  9 12:19:46 2010
From: h.lingsma at erasmusmc.nl (Hester Lingsma)
Date: Tue, 09 Feb 2010 12:19:46 +0100
Subject: [R-sig-ME] Variance of the random effects
In-Reply-To: <Pine.LNX.4.64.0912151821280.15161@orpheus.qimr.edu.au>
References: <4B2745DD.5020308@erasmusmc.nl>
	<Pine.LNX.4.64.0912151821280.15161@orpheus.qimr.edu.au>
Message-ID: <4B7144D2.9020409@erasmusmc.nl>

Dear R users,
In a model with a random intercept for center, I use the variance of the 
random effect to express the differenrences between centers in a 95% 
range of odds ratios. I use:
exp(1.96*(sqrt(as.numeric(VarCorr(random1)[[1]]))))
exp(1.96*(-(sqrt(as.numeric(VarCorr(random1)[[1]])))))
If I look at the posterior estimates of the individual centers, I find 
out that (much) more than 5% is actually out of the range I calculated. 
Am I making a mistake?
Thanks,
Hester

-- 
_________________________________________________
Hester F. Lingsma, MSc
Dept of Public Health
Room AE-141
Erasmus MC
P.O. Box 2040
3000 CA Rotterdam
The Netherlands
Phone: (+31) (0)10 7038458/7038460
Mobile: (+31) (0)6 26467338



From walmeszeviani at yahoo.com.br  Tue Feb  9 13:23:57 2010
From: walmeszeviani at yahoo.com.br (walmes zeviani)
Date: Tue, 9 Feb 2010 04:23:57 -0800 (PST)
Subject: [R-sig-ME] Res:  anova on lmer object
In-Reply-To: <74cfd9161002082321v44c8c0a2sc6cde9a46a43dd2d@mail.gmail.com>
References: <74cfd9161002082321v44c8c0a2sc6cde9a46a43dd2d@mail.gmail.com>
Message-ID: <686095.82588.qm@web32106.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100209/cdf7fe49/attachment.pl>

From bates at stat.wisc.edu  Tue Feb  9 16:13:07 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 9 Feb 2010 09:13:07 -0600
Subject: [R-sig-ME] var-covar matrix in ranef
In-Reply-To: <4B7121C2.9040305@erasmusmc.nl>
References: <4B2745DD.5020308@erasmusmc.nl>
	<Pine.LNX.4.64.0912151821280.15161@orpheus.qimr.edu.au>
	<4B7121C2.9040305@erasmusmc.nl>
Message-ID: <40e66e0b1002090713s7a575e26j9404b99fceb94171@mail.gmail.com>

On Tue, Feb 9, 2010 at 2:50 AM, Hester Lingsma <h.lingsma at erasmusmc.nl> wrote:
> Dear R users,
> If I fit a model with a random slope and a random intercept, the var-covar
> matrix derived from PostVar from the function ranef is a 2 by 2 matrix for
> each upper level subject. I want to use the posterior estimates (from ranef)
> and their standard error from both the slope and the intercepct for each
> upper level subject. Which elemants of the 2 by 2 matrixes to use for the se
> of the posterior estimate?

I'm not sure what "the posterior estimates" means but that term is
probably my fault because the argument name is "postVar" for
"posterior variance".  (Actually I think it is Harold Doran's fault
because he is the one who suggested the term "posterior variance",
which I not realize is a misnomer.)  Even though the argument name is
"postVar", and I would prefer not to change it at this point, I now
refer to the values returned by ranef as the conditional means (for
linear mixed models, in more general models they are the conditional
modes) of the random effects given the observed data and evaluated at
the parameter estimates.  The conditional standard deviations of the
random effects will be the square roots of the diagonal elements of
the 2 by 2 matrices returned in the postVar attribute.



From h.lingsma at erasmusmc.nl  Tue Feb  9 16:21:18 2010
From: h.lingsma at erasmusmc.nl (Hester Lingsma)
Date: Tue, 09 Feb 2010 16:21:18 +0100
Subject: [R-sig-ME] var-covar matrix in ranef
In-Reply-To: <40e66e0b1002090713s7a575e26j9404b99fceb94171@mail.gmail.com>
References: <4B2745DD.5020308@erasmusmc.nl>	
	<Pine.LNX.4.64.0912151821280.15161@orpheus.qimr.edu.au>	
	<4B7121C2.9040305@erasmusmc.nl>
	<40e66e0b1002090713s7a575e26j9404b99fceb94171@mail.gmail.com>
Message-ID: <4B717D6E.9020409@erasmusmc.nl>

Dear Prof Bates,
Thank you very much for this answer. I mean by the posterior estimates 
what you here refer to as the conditional means. So I was looking for 
the sd of the conditional means of the intecepts and the slopes. I 
already thought this was the square roots of the diagonal of the 2 by 2 
matrices, which is now confirmed. So thanks again!
Hester Lingsma

on 09-02-2010 16:13 Douglas Bates said the following:
> On Tue, Feb 9, 2010 at 2:50 AM, Hester Lingsma <h.lingsma at erasmusmc.nl> wrote:
>   
>> Dear R users,
>> If I fit a model with a random slope and a random intercept, the var-covar
>> matrix derived from PostVar from the function ranef is a 2 by 2 matrix for
>> each upper level subject. I want to use the posterior estimates (from ranef)
>> and their standard error from both the slope and the intercepct for each
>> upper level subject. Which elemants of the 2 by 2 matrixes to use for the se
>> of the posterior estimate?
>>     
>
> I'm not sure what "the posterior estimates" means but that term is
> probably my fault because the argument name is "postVar" for
> "posterior variance".  (Actually I think it is Harold Doran's fault
> because he is the one who suggested the term "posterior variance",
> which I not realize is a misnomer.)  Even though the argument name is
> "postVar", and I would prefer not to change it at this point, I now
> refer to the values returned by ranef as the conditional means (for
> linear mixed models, in more general models they are the conditional
> modes) of the random effects given the observed data and evaluated at
> the parameter estimates.  The conditional standard deviations of the
> random effects will be the square roots of the diagonal elements of
> the 2 by 2 matrices returned in the postVar attribute.
>   

-- 
_________________________________________________
Hester F. Lingsma, MSc
Dept of Public Health
Room AE-141
Erasmus MC
P.O. Box 2040
3000 CA Rotterdam
The Netherlands
Phone: (+31) (0)10 7038458/7038460
Mobile: (+31) (0)6 26467338



From donal.bisanzio at gmail.com  Tue Feb  9 17:10:42 2010
From: donal.bisanzio at gmail.com (Donal Bisanzio)
Date: Tue, 9 Feb 2010 17:10:42 +0100
Subject: [R-sig-ME] Compare glmmQPL
Message-ID: <ba95c4b81002090810l284dfe92idf09fefa9f87a4c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100209/853005b0/attachment.pl>

From bolker at ufl.edu  Tue Feb  9 17:59:17 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 09 Feb 2010 11:59:17 -0500
Subject: [R-sig-ME] Compare glmmQPL
In-Reply-To: <ba95c4b81002090810l284dfe92idf09fefa9f87a4c@mail.gmail.com>
References: <ba95c4b81002090810l284dfe92idf09fefa9f87a4c@mail.gmail.com>
Message-ID: <4B719465.5040306@ufl.edu>

Donal Bisanzio wrote:
> Good morning,
> 
> I made two different model with glmmQPL function. I need to compare them,
> but anova() does not work. I also changed class from "glmmQPL" "lme" to
> "lme", but this trick does not work.
> 
> Is there a way to compare these type of model??
> 
> Thanks for your help
> 
> Donal
> 

  It's tricky.
  What is the relationship between your models?  What kind of comparison
do you want to make? If they are nested, you can look at the Wald t-test
(or F-test, if you need to set multiple parameters to zero
simultaneously) of the parameters that differ.  If they are not nested,
then you can in principle compute a quasi-AIC value to compare them, but
 it's a bit tricky to extract that information ...

  Ben Bolker

-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From fog0 at gmx.com  Wed Feb 10 06:06:27 2010
From: fog0 at gmx.com (Doug Adams)
Date: Tue, 9 Feb 2010 22:06:27 -0700
Subject: [R-sig-ME] anova on lmer object
In-Reply-To: <74cfd9161002091532hfc0c4e6u96eae4fcb4e4aa48@mail.gmail.com>
References: <74cfd9161002082321v44c8c0a2sc6cde9a46a43dd2d@mail.gmail.com>
	<707098.21563.qm@web32104.mail.mud.yahoo.com>
	<74cfd9161002091532hfc0c4e6u96eae4fcb4e4aa48@mail.gmail.com>
Message-ID: <74cfd9161002092106x6204608bx11e64dc46304b53f@mail.gmail.com>

On Tue, Feb 9, 2010 at 4:32 PM, Doug Adams <fog0 at gmx.com> wrote:
> Thanks to both of you!
>

If I only pass one model into the anova function, does it assume the
nested model being tested against is the one without fixed effects?

And are the denominator degrees of freedom the ones listed in the output table:
         Df Sum Sq Mean Sq F value
division  2 103.59  51.793  1.0155

If it's 2, am I correct in thinking that it's because my fixed effect
has 3 states, the first of which would be considered the baseline
against which the others are offset -- so it would exist in the model
without fixed effects?  (So the baseline, and then the other 2
additional states for fixed effects...)

One more question:  If I want to explicitly spell out the simpler
model that doesn't have fixed effects so I can test for them, would
this be correct:
Complete Model:        lmer(outcome ~ FixedEffect + (1|RandomGrouping), data...)
Simplified Model:        lmer(outcome ~ 1 + (1|RandomGrouping))

so that "1" is like a placeholder for the first level?

Goodness, thanks everyone for your patience with my endless questions.



From walmeszeviani at yahoo.com.br  Wed Feb 10 12:11:07 2010
From: walmeszeviani at yahoo.com.br (walmes zeviani)
Date: Wed, 10 Feb 2010 03:11:07 -0800 (PST)
Subject: [R-sig-ME] Res:  anova on lmer object
In-Reply-To: <74cfd9161002092106x6204608bx11e64dc46304b53f@mail.gmail.com>
References: <74cfd9161002082321v44c8c0a2sc6cde9a46a43dd2d@mail.gmail.com>
	<707098.21563.qm@web32104.mail.mud.yahoo.com>
	<74cfd9161002091532hfc0c4e6u96eae4fcb4e4aa48@mail.gmail.com>
	<74cfd9161002092106x6204608bx11e64dc46304b53f@mail.gmail.com>
Message-ID: <979210.24176.qm@web32107.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100210/705cc2e8/attachment.pl>

From Marcus.Rowcliffe at ioz.ac.uk  Wed Feb 10 17:52:56 2010
From: Marcus.Rowcliffe at ioz.ac.uk (Marcus Rowcliffe)
Date: Wed, 10 Feb 2010 16:52:56 -0000
Subject: [R-sig-ME]  lme4 and calculating QAICc
Message-ID: <B1436FB2EE57AB40A56AA806EEB273010237ADCA@ZSL26.zsl.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100210/ad02837f/attachment.pl>

From arendahl at stat.umn.edu  Wed Feb 10 17:47:20 2010
From: arendahl at stat.umn.edu (Aaron Rendahl)
Date: Wed, 10 Feb 2010 10:47:20 -0600
Subject: [R-sig-ME] pedigreemm with one observation per individual
Message-ID: <3f7256361002100847rc987980xc2884dbcda536e69@mail.gmail.com>

I'm trying to fit a mixed model using pedigreemm, but unlike any of
the examples, I only have one observation per individual.
I'm getting the following error:

   Error in function (fr, FL, start, REML, verbose)  :
     Number of levels of a grouping factor for the random effects must
be less than the number of observations

which makes sense when the random effects are uncorrelated; as Spencer
Graves wrote when reporting this issue, "there are zero degrees of
freedom to distinguish 'group' from Residual."

However, with correlated random effects with a known correlation
pattern, as with pedigree data, it seems this is a reasonable thing to
do.  Is there a way to tell lme4 to allow this in this case?  Or is
this still not a reasonable thing to do?  Thanks for any comments or
suggestions you may have.

I'm running R 2.10.1, pedigreemm 0.2-4, and lme4 0.999375-32.

I've recreated the error using data from the milk dataset from
pedigreemm, as below.

> library(pedigreemm)
>
> # to simplify, just get one herd and remove unneeded columns
> milk <- within(milk, sdMilk <- milk / sd(milk))
> m<-subset(milk, herd==89)
> m<-m[,c("id","lact","dim","sdMilk")]
>
> # the data now has three measurements per cow
> head(m)
    id lact dim   sdMilk
1 6489    1 286 4.118756
2 6489    2 305 4.828023
3 6489    3 203 3.540520
4 6490    1 281 4.624768
5 6490    2 277 4.483228
6 6490    3 289 4.894880
>
> # and fitting a model works fine
> fm <- pedigreemm(sdMilk ~ lact + log(dim) + (1|id),
+   data = m, pedigree = list(id = pedCowsR))
>
> # but if I use only one measurement for each cow, as follows
> m1<-subset(m, lact==1)
> head(m1)
     id lact dim   sdMilk
1  6489    1 286 4.118756
4  6490    1 281 4.624768
7  6491    1 305 5.287302
8  6492    1 281 4.421290
12 6493    1 305 4.374557
16 6494    1 305 3.783129
>
> # it then fails
> fm1 <- pedigreemm(sdMilk ~ log(dim) + (1|id),
+   data = m1, pedigree = list(id = pedCowsR))
Error in function (fr, FL, start, REML, verbose)  :
  Number of levels of a grouping factor for the random effects
must be less than the number of observations

-- 
Aaron Rendahl, Ph.D.
Statistical Consulting Manager
School of Statistics, University of Minnesota

NEW OFFICE (as of June 2009):
48C McNeal Hall, St. Paul Campus
612-625-1062
www.stat.umn.edu/consulting



From fog0 at gmx.com  Wed Feb 10 19:52:18 2010
From: fog0 at gmx.com (Doug Adams)
Date: Wed, 10 Feb 2010 11:52:18 -0700
Subject: [R-sig-ME] anova on lmer object
In-Reply-To: <979210.24176.qm@web32107.mail.mud.yahoo.com>
References: <74cfd9161002082321v44c8c0a2sc6cde9a46a43dd2d@mail.gmail.com>
	<707098.21563.qm@web32104.mail.mud.yahoo.com>
	<74cfd9161002091532hfc0c4e6u96eae4fcb4e4aa48@mail.gmail.com>
	<74cfd9161002092106x6204608bx11e64dc46304b53f@mail.gmail.com>
	<979210.24176.qm@web32107.mail.mud.yahoo.com>
Message-ID: <74cfd9161002101052n18a93004h88b77893fa79f834@mail.gmail.com>

Thank you Walmes,

That makes sense; I read somewhere that REML removes the effects of
fixed effects, essentially, and calculates parameters based on
residuals.  I'll use full Maximum Likelihood on both models then.
When I'm testing for random effects, does the choice between REML and
full ML matter when using a LR test?

Best wishes,


On Wed, Feb 10, 2010 at 4:11 AM, walmes zeviani
<walmeszeviani at yahoo.com.br> wrote:
> Doug,
>
> Test fixed effects by single term in anova() and test by likelihood ratio
> test are different. In anova you are assuming that random effects estimates
> are the parametric values, in other words, this test is conditional to the
> random effects.
>
> When you want to test fixed effects by double term in anova (anova(m1, m0))
> you must use maximum likelihood (lmer(y~x1+x2+(1|x3), REML=FALSE)). It's
> because REML is based in function of the fixed effects and ML not.
>
> Using "1" in your simple model means adjust to the general mean.
>
> At your disposal.
> Walmes Zeviani, Lavras, MG - Brasil.
>
> ________________________________
> De: Doug Adams <fog0 at gmx.com>
> Para: walmes zeviani <walmeszeviani at yahoo.com.br>;
> marianne.promberger at kcl.ac.uk; R sig-mixed-models
> <r-sig-mixed-models at r-project.org>
> Enviadas: Quarta-feira, 10 de Fevereiro de 2010 3:06:27
> Assunto: Re: [R-sig-ME] anova on lmer object
>
> On Tue, Feb 9, 2010 at 4:32 PM, Doug Adams <fog0 at gmx.com> wrote:
>> Thanks to both of you!
>>
>
> If I only pass one model into the anova function, does it assume the
> nested model being tested against is the one without fixed effects?
>
> And are the denominator degrees of freedom the ones listed in the output
> table:
> ? ? ? ? Df Sum Sq Mean Sq F value
> division? 2 103.59? 51.793? 1.0155
>
> If it's 2, am I correct in thinking that it's because my fixed effect
> has 3 states, the first of which would be considered the baseline
> against which the others are offset -- so it would exist in the model
> without fixed effects?? (So the baseline, and then the other 2
> additional states for fixed effects...)
>
> One more question:? If I want to explicitly spell out the simpler
> model that doesn't have fixed effects so I can test for them, would
> this be correct:
> Complete Model:? ? ? ? lmer(outcome ~ FixedEffect + (1|RandomGrouping),
> data...)
> Simplified Model:? ? ? ? lmer(outcome ~ 1 + (1|RandomGrouping))
>
> so that "1" is like a placeholder for the first level?
>
> Goodness, thanks everyone for your patience with my endless questions.
>
> ________________________________
> Veja quais s?o os assuntos do momento no Yahoo! + Buscados: Top 10 -
> Celebridades - M?sica - Esportes



From fog0 at gmx.com  Wed Feb 10 20:11:13 2010
From: fog0 at gmx.com (Doug Adams)
Date: Wed, 10 Feb 2010 12:11:13 -0700
Subject: [R-sig-ME] anova on lmer object
In-Reply-To: <74cfd9161002101052n18a93004h88b77893fa79f834@mail.gmail.com>
References: <74cfd9161002082321v44c8c0a2sc6cde9a46a43dd2d@mail.gmail.com>
	<707098.21563.qm@web32104.mail.mud.yahoo.com>
	<74cfd9161002091532hfc0c4e6u96eae4fcb4e4aa48@mail.gmail.com>
	<74cfd9161002092106x6204608bx11e64dc46304b53f@mail.gmail.com>
	<979210.24176.qm@web32107.mail.mud.yahoo.com>
	<74cfd9161002101052n18a93004h88b77893fa79f834@mail.gmail.com>
Message-ID: <74cfd9161002101111qe27ea6hc2f55c36cd4c2790@mail.gmail.com>

Oh wait: when I fit the model without random effects I'm using glm,
and it doesn't give the option between REML and ML...  I'm guessing
the "iteratively reweighted least squares" method used to find
parameters for a glm doesn't have to do with ML techniques.  (?)   I
hope it's ok then, that I'm testing random effects using a LR test
where one model is fitted using lmer and the other using glm.

Thanks   :)


On Wed, Feb 10, 2010 at 11:52 AM, Doug Adams <fog0 at gmx.com> wrote:
> Thank you Walmes,
>
> That makes sense; I read somewhere that REML removes the effects of
> fixed effects, essentially, and calculates parameters based on
> residuals. ?I'll use full Maximum Likelihood on both models then.
> When I'm testing for random effects, does the choice between REML and
> full ML matter when using a LR test?
>
> Best wishes,
>
>
> On Wed, Feb 10, 2010 at 4:11 AM, walmes zeviani
> <walmeszeviani at yahoo.com.br> wrote:
>> Doug,
>>
>> Test fixed effects by single term in anova() and test by likelihood ratio
>> test are different. In anova you are assuming that random effects estimates
>> are the parametric values, in other words, this test is conditional to the
>> random effects.
>>
>> When you want to test fixed effects by double term in anova (anova(m1, m0))
>> you must use maximum likelihood (lmer(y~x1+x2+(1|x3), REML=FALSE)). It's
>> because REML is based in function of the fixed effects and ML not.
>>
>> Using "1" in your simple model means adjust to the general mean.
>>
>> At your disposal.
>> Walmes Zeviani, Lavras, MG - Brasil.
>>
>> ________________________________
>> De: Doug Adams <fog0 at gmx.com>
>> Para: walmes zeviani <walmeszeviani at yahoo.com.br>;
>> marianne.promberger at kcl.ac.uk; R sig-mixed-models
>> <r-sig-mixed-models at r-project.org>
>> Enviadas: Quarta-feira, 10 de Fevereiro de 2010 3:06:27
>> Assunto: Re: [R-sig-ME] anova on lmer object
>>
>> On Tue, Feb 9, 2010 at 4:32 PM, Doug Adams <fog0 at gmx.com> wrote:
>>> Thanks to both of you!
>>>
>>
>> If I only pass one model into the anova function, does it assume the
>> nested model being tested against is the one without fixed effects?
>>
>> And are the denominator degrees of freedom the ones listed in the output
>> table:
>> ? ? ? ? Df Sum Sq Mean Sq F value
>> division? 2 103.59? 51.793? 1.0155
>>
>> If it's 2, am I correct in thinking that it's because my fixed effect
>> has 3 states, the first of which would be considered the baseline
>> against which the others are offset -- so it would exist in the model
>> without fixed effects?? (So the baseline, and then the other 2
>> additional states for fixed effects...)
>>
>> One more question:? If I want to explicitly spell out the simpler
>> model that doesn't have fixed effects so I can test for them, would
>> this be correct:
>> Complete Model:? ? ? ? lmer(outcome ~ FixedEffect + (1|RandomGrouping),
>> data...)
>> Simplified Model:? ? ? ? lmer(outcome ~ 1 + (1|RandomGrouping))
>>
>> so that "1" is like a placeholder for the first level?
>>
>> Goodness, thanks everyone for your patience with my endless questions.
>>
>> ________________________________
>> Veja quais s?o os assuntos do momento no Yahoo! + Buscados: Top 10 -
>> Celebridades - M?sica - Esportes
>



From lborger at uoguelph.ca  Wed Feb 10 20:23:54 2010
From: lborger at uoguelph.ca (Luca Borger)
Date: Wed, 10 Feb 2010 14:23:54 -0500
Subject: [R-sig-ME] anova on lmer object
References: <74cfd9161002082321v44c8c0a2sc6cde9a46a43dd2d@mail.gmail.com><707098.21563.qm@web32104.mail.mud.yahoo.com><74cfd9161002091532hfc0c4e6u96eae4fcb4e4aa48@mail.gmail.com><74cfd9161002092106x6204608bx11e64dc46304b53f@mail.gmail.com><979210.24176.qm@web32107.mail.mud.yahoo.com><74cfd9161002101052n18a93004h88b77893fa79f834@mail.gmail.com>
	<74cfd9161002101111qe27ea6hc2f55c36cd4c2790@mail.gmail.com>
Message-ID: <29944B6FE591410D9EC638616B2E86E9@lborger>

Hello,

>hope it's ok then, that I'm testing random effects using a LR test
>where one model is fitted using lmer and the other using glm.

no, if I remember well. Please check the mail list archive, this issue has 
been discussed in the past, also recently(-ish).


Cheers,

Luca


----- Original Message ----- 
From: "Doug Adams" <fog0 at gmx.com>
To: "walmes zeviani" <walmeszeviani at yahoo.com.br>; "R sig-mixed-models" 
<r-sig-mixed-models at r-project.org>
Sent: Wednesday, February 10, 2010 2:11 PM
Subject: Re: [R-sig-ME] anova on lmer object


Oh wait: when I fit the model without random effects I'm using glm,
and it doesn't give the option between REML and ML...  I'm guessing
the "iteratively reweighted least squares" method used to find
parameters for a glm doesn't have to do with ML techniques.  (?)   I
hope it's ok then, that I'm testing random effects using a LR test
where one model is fitted using lmer and the other using glm.

Thanks   :)


On Wed, Feb 10, 2010 at 11:52 AM, Doug Adams <fog0 at gmx.com> wrote:
> Thank you Walmes,
>
> That makes sense; I read somewhere that REML removes the effects of
> fixed effects, essentially, and calculates parameters based on
> residuals. I'll use full Maximum Likelihood on both models then.
> When I'm testing for random effects, does the choice between REML and
> full ML matter when using a LR test?
>
> Best wishes,
>
>
> On Wed, Feb 10, 2010 at 4:11 AM, walmes zeviani
> <walmeszeviani at yahoo.com.br> wrote:
>> Doug,
>>
>> Test fixed effects by single term in anova() and test by likelihood ratio
>> test are different. In anova you are assuming that random effects 
>> estimates
>> are the parametric values, in other words, this test is conditional to 
>> the
>> random effects.
>>
>> When you want to test fixed effects by double term in anova (anova(m1, 
>> m0))
>> you must use maximum likelihood (lmer(y~x1+x2+(1|x3), REML=FALSE)). It's
>> because REML is based in function of the fixed effects and ML not.
>>
>> Using "1" in your simple model means adjust to the general mean.
>>
>> At your disposal.
>> Walmes Zeviani, Lavras, MG - Brasil.
>>
>> ________________________________
>> De: Doug Adams <fog0 at gmx.com>
>> Para: walmes zeviani <walmeszeviani at yahoo.com.br>;
>> marianne.promberger at kcl.ac.uk; R sig-mixed-models
>> <r-sig-mixed-models at r-project.org>
>> Enviadas: Quarta-feira, 10 de Fevereiro de 2010 3:06:27
>> Assunto: Re: [R-sig-ME] anova on lmer object
>>
>> On Tue, Feb 9, 2010 at 4:32 PM, Doug Adams <fog0 at gmx.com> wrote:
>>> Thanks to both of you!
>>>
>>
>> If I only pass one model into the anova function, does it assume the
>> nested model being tested against is the one without fixed effects?
>>
>> And are the denominator degrees of freedom the ones listed in the output
>> table:
>> Df Sum Sq Mean Sq F value
>> division 2 103.59 51.793 1.0155
>>
>> If it's 2, am I correct in thinking that it's because my fixed effect
>> has 3 states, the first of which would be considered the baseline
>> against which the others are offset -- so it would exist in the model
>> without fixed effects? (So the baseline, and then the other 2
>> additional states for fixed effects...)
>>
>> One more question: If I want to explicitly spell out the simpler
>> model that doesn't have fixed effects so I can test for them, would
>> this be correct:
>> Complete Model: lmer(outcome ~ FixedEffect + (1|RandomGrouping),
>> data...)
>> Simplified Model: lmer(outcome ~ 1 + (1|RandomGrouping))
>>
>> so that "1" is like a placeholder for the first level?
>>
>> Goodness, thanks everyone for your patience with my endless questions.
>>
>> ________________________________
>> Veja quais s?o os assuntos do momento no Yahoo! + Buscados: Top 10 -
>> Celebridades - M?sica - Esportes
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From walmeszeviani at yahoo.com.br  Wed Feb 10 20:54:40 2010
From: walmeszeviani at yahoo.com.br (walmes zeviani)
Date: Wed, 10 Feb 2010 11:54:40 -0800 (PST)
Subject: [R-sig-ME] Res:  anova on lmer object
In-Reply-To: <29944B6FE591410D9EC638616B2E86E9@lborger>
References: <74cfd9161002082321v44c8c0a2sc6cde9a46a43dd2d@mail.gmail.com><707098.21563.qm@web32104.mail.mud.yahoo.com><74cfd9161002091532hfc0c4e6u96eae4fcb4e4aa48@mail.gmail.com><74cfd9161002092106x6204608bx11e64dc46304b53f@mail.gmail.com><979210.24176.qm@web32107.mail.mud.yahoo.com><74cfd9161002101052n18a93004h88b77893fa79f834@mail.gmail.com>
	<74cfd9161002101111qe27ea6hc2f55c36cd4c2790@mail.gmail.com>
	<29944B6FE591410D9EC638616B2E86E9@lborger>
Message-ID: <108271.72790.qm@web32107.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100210/05b42fee/attachment.pl>

From bolker at ufl.edu  Wed Feb 10 22:33:41 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Wed, 10 Feb 2010 16:33:41 -0500
Subject: [R-sig-ME] lme4 and calculating QAICc
In-Reply-To: <B1436FB2EE57AB40A56AA806EEB273010237ADCA@ZSL26.zsl.org>
References: <B1436FB2EE57AB40A56AA806EEB273010237ADCA@ZSL26.zsl.org>
Message-ID: <4B732635.2020209@ufl.edu>

Marcus Rowcliffe wrote:
> Dear all
> I found the following useful exchange in the archive, but there are a
> couple of crucial things confusing me:
> 1.	In the Bolker et al supplement, it appears that his QAICc
> function (essentially the same as that outlined below) is run on quasi
> models, so the log-likelihood used is from quasi models, not straight
> poisson, as recommended below. In fact, looking at simple model fits,
> log-likelihoods for poisson and quasipoisson appear to be the same
> anyway, so why is it necessary to fit both types of model as suggested
> by Bolker below?

     Some confusion (on my part) between different kinds of models: for
more traditional generalized quasilikelihood models (e.g. fitted by
glm() or glmmPQL()), R refuses (perhaps rightly) to return a
log-likelihood, hence one has to fit the non-quasi- version to get the
equivalent likelihood value.  Not really necessary for glmer, although I
can imagine this will change in the future ... ?

  **NB** someone (alas I can no longer remember who nor quickly find the
e-mail) pointed out that the "scale" estimate for QAICc should be
lme4:::sigma(model)^2 [i.e. SQUARED].  I've been meaning to send in a
correction to Elsevier but haven't gotten around to it yet.

> 2.	Comparing poisson and quasipoisson models, I note that the
> former has no residual random variance, and hence one fewer degrees of
> freedom than the quasipoisson. Why is this? It obviously has important
> implications for the QAIC calculation.

  I find this a bit difficult myself.  Technically, it's another
'estimated parameter', but it's a nuisance parameter that does *not*
affect the predictions at all (it is simply calculated from the
residuals of the model), so I'm not really sure whether it should affect
the estimate of expected Kullback-Leibler distance or not ... however, I
would quibble a little bit with "important implications for the QAIC
calculation" -- it's just 1 degree of freedom!  To quote _Numerical
Recipes in C_ 2d ed. p. 611 (Press et al): "We might also comment that
if the difference between N and N-1 ever matters to you, then you are
probably up to no good anyway -- e.g., trying to substantiate a
questionable hypothesis with marginal data.")

> Apologies if the latter should be obvious and I've missed it somewhere.
> Marcus
> 
> 
> 
>>> Dear all,
>>>
>>> I am trying to calculate QAICc using to compare two Poisson models.
>>> Unfortunately all I seem to get as printed values is NaN.
>>>
>>> Is there something I'm missing? Even though I am able to generate
> model
>>> output, I do receive "convergence errors". Would these warning
> message
>>> have anything to do with this?
>>>
>>> Incidentally, I'm using the methodology extracted from Bolker et al
> (2009)
>>> Here is the code I have used.
>>>
>>> ######
>>> library(lme4)
>>> ######
>>>
> mp1=lmer(abundance~year+controlA+(year|groupC:sitecode),family="poisson"
> ,data=testData)
>>> ######
>>>
> mq1=lmer(abundance~year+controlA+(year|groupC:sitecode),family="quasipoi
> sson",data=testData)
> 
>   OR
> 
>   mq1 = update(mp1,family="quasipoisson")
> 
> (as in Bolker et al supplement)
> 

QAICc <- function(mod, scale, QAICc = TRUE) {
   LL <- logLik(mod)
   ll <- as.numeric(LL)
   df <- attr(LL, "df")
   n <- length(mod at y)
   if (QAICc)      qaic = as.numeric(-2 * ll/scale + 2 * df + 2 * df *
(df +1)/(n - df - 1))
  else qaic = as.numeric(-2 * ll/scale + 2 * df)
   qaic
 }

QAICc(mq1,scale=phi)
> 
>    In order to use QAICc you have to do the following:
> 
> phi = lme4:::sigma(mq1)
> QAICc(mp1,scale=phi)
> 
>   (see p. 8 of the Bolker et al supplement)
> 
> The basic problem is that quasi- models don't return likelihoods,
> and non-quasi- models don't return estimates of scale parameters,
> so you have fit both and combine the information.
> 
>   good luck,
>     Ben Bolker
> 
> 
> The Zoological Society of London is incorporated by Royal Charter
> Principal Office England. Company Number RC000749
> Registered address: 
> Regent's Park, London, England NW1 4RY
> Registered Charity in England and Wales no. 208728 
> 
> _________________________________________________________________________
> This e-mail has been sent in confidence to the named a...{{dropped:13}}



From David.Duffy at qimr.edu.au  Wed Feb 10 23:06:14 2010
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Thu, 11 Feb 2010 08:06:14 +1000 (EST)
Subject: [R-sig-ME] pedigreemm with one observation per individual
In-Reply-To: <3f7256361002100847rc987980xc2884dbcda536e69@mail.gmail.com>
References: <3f7256361002100847rc987980xc2884dbcda536e69@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1002110741010.20189@orpheus.qimr.edu.au>

On Wed, 10 Feb 2010, Aaron Rendahl wrote:

> I'm trying to fit a mixed model using pedigreemm, but unlike any of
> the examples, I only have one observation per individual.
> I'm getting the following error:
>
>   Error in function (fr, FL, start, REML, verbose)  :
>     Number of levels of a grouping factor for the random effects must
> be less than the number of observations
>
> However, with correlated random effects with a known correlation
> pattern, as with pedigree data, it seems this is a reasonable thing to
> do.  Is there a way to tell lme4 to allow this in this case?  Or is
> this still not a reasonable thing to do?
>

It is reasonable, especially when one wants to estimate breeding values 
(so could be many more REs than observations).

Continuing the example (FWIW)...

library(kinship)
p1 <- data.frame(id=pedCowsR at label, fa=pedCowsR at sire, mo=pedCowsR at dam)
kmat <- kinship(p1$id, p1$fa, p1$mo)
lmekin(sdMilk ~ 1, data=m1, random = ~1|id, varlist=list(kmat))

Linear mixed-effects kinship model fit by maximum likelihood
   Data: m1
   Log-likelihood = -57.32775
   n= 47

Fixed effects: sdMilk ~ 1
             Estimate Std. Error t value     Pr(>|t|)
(Intercept) 4.311032  0.1208144 35.6831 3.558233e-35

Random effects: ~1 | id
  Variance list: list(kmat)
                         id     resid
Standard Dev: 0.0025911150 0.8193825
% Variance:   0.0000099999 0.9999900

(Not a great example, as in herd 89, the half-sib correlation for this
variable, the sole source of information, is -0.04)

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From bolker at ufl.edu  Thu Feb 11 18:32:33 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 11 Feb 2010 12:32:33 -0500
Subject: [R-sig-ME] lme4 and calculating QAICc
In-Reply-To: <B1436FB2EE57AB40A56AA806EEB273010237ADD6@ZSL26.zsl.org>
References: <B1436FB2EE57AB40A56AA806EEB273010237ADCA@ZSL26.zsl.org>
	<4B732635.2020209@ufl.edu>
	<B1436FB2EE57AB40A56AA806EEB273010237ADD6@ZSL26.zsl.org>
Message-ID: <4B743F31.7010901@ufl.edu>

 [cc'ing back to r-sig-mixed-models so it gets archived somewhere]

Marcus Rowcliffe wrote:
> Many thanks Ben
> 
> The squaring of the scale parameter is a bit of a surprise! It seems to
> give sensible results (see below *), but I can't immediately see why
> it's necessary - is there an obvious explanation?

  Because c-hat is supposed to be on the same scale as the deviance --
the deviance is essentially on a variance, or sum-of-squares scale, not
a standard deviation/root-mean-square scale.  @sigma is defined as a
standard deviation, not a variance.

  For what it's worth, Doug Bates has said in the past that he's not
*sure* that sigma really corresponds to the same quantity that we would
want to use as sqrt(c-hat) -- it seems reasonable, but no-one to my
knowledge has either sat down and worked through it carefully *or*
tested with simulations.

> I've also noted in Burnham and Anderson that when using QAIC to compare
> a set of models, they recommend that the scale estimate of the full
> model should be used to correct all models, rather than each model's own
> estimate. Again, this does seem to give sensible results, whereas
> applying scale estimates model-by-model can give very different and less
> apparently sensible results (including complete reversals of what's
> deemed the best model), so it seems crucial to get this right. Do you
> have a view on this? 

  I believe B&A are right.

I'd value you your opinion on whether you think the
> following is a sensible QAIC function for comparing multiple lmer models
> with different fixed effects:
> 
> qaic <- function(...)
> {	mods <- list(...)
> 	LL <- lapply(mods,logLik)
> 	df <- as.numeric(lapply(LL,attr,"df"))
> 	nfixef <- as.numeric(lapply(mods,function(mm)
> length(fixef(mm))))
> 	scale <- summary(mods[[which(nfixef==max(nfixef))]])@sigma^2
> 		#assumes only one model with max(nfixef) - needs error
> catching
> 	2*df - 2*as.numeric(LL)/scale
> }

  Seems reasonable.

> 
> * By sensible I mean that I've tested QAIC comparisons for simple lmer
> models varying in fixed structure, and using the squared scale estimate
> from the full model, the outcome seems to reflect what I would expect
> from eyballing coeficients and SEs
> 
> Best
> Marcus
> 
>



From Antonio.Gasparrini at lshtm.ac.uk  Fri Feb 12 02:48:16 2010
From: Antonio.Gasparrini at lshtm.ac.uk (Antonio.Gasparrini at lshtm.ac.uk)
Date: Fri, 12 Feb 2010 01:48:16 +0000
Subject: [R-sig-ME] lme4, glmmPQL and calculating QAICc
Message-ID: <4B74B363.5572.00B2.1@lshtm.ac.uk>

Dear R users,
 
following the recent discussion on calculating QAICc in lme4, I report the weird results I got comparing glmer and glmmPQL.
 
I ran these models: 
 
pql.model <- glmmPQL(outcome ~ offset(log(pop)) + time + 
 harmonic(month,3,12), random=list(region=pdSymm(~time)), family=poisson, data)
 
glmer.model <- glmer(outcome ~ offset(log(pop)) + time + 
 harmonic(mm,3,12) + (time|region), family=poisson, data)
The first model with glmmPQL estimates a sigma (within-group error) anyway, both with poisson or quasipoisson family.
Its value is 1.40
The value of sigma^2 is equal to the overdispersion parameter of simpler glm-gam models (~1.96), which makes sense.
 
The second model with glmer doesn't estimate a sigma (correctly), but when the family is set to quasipoisson the estimated sigma [lme4:::sigma(glmer.model)] is 15.8, which is simply unbelievable. The standard errors are therefore incredibly huge.
 
I couldn't find a reason for that.
Any comment/suggestion is more than welcome.
Thanks

Antonio Gasparrini
Public and Environmental Health Research Unit (PEHRU)
London School of Hygiene & Tropical Medicine
Keppel Street, London WC1E 7HT, UK
Office: 0044 (0)20 79272406 - Mobile: 0044 (0)79 64925523



From bolker at ufl.edu  Fri Feb 12 04:59:06 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 11 Feb 2010 22:59:06 -0500
Subject: [R-sig-ME] lme4, glmmPQL and calculating QAICc
In-Reply-To: <4B74B363.5572.00B2.1@lshtm.ac.uk>
References: <4B74B363.5572.00B2.1@lshtm.ac.uk>
Message-ID: <4B74D20A.2030603@ufl.edu>

Antonio.Gasparrini at lshtm.ac.uk wrote:
> Dear R users,
>  
> following the recent discussion on calculating QAICc in lme4, I report the weird results I got comparing glmer and glmmPQL.
>  
> I ran these models: 
>  
> pql.model <- glmmPQL(outcome ~ offset(log(pop)) + time + 
>  harmonic(month,3,12), random=list(region=pdSymm(~time)), family=poisson, data)
>  
> glmer.model <- glmer(outcome ~ offset(log(pop)) + time + 
>  harmonic(mm,3,12) + (time|region), family=poisson, data)
> The first model with glmmPQL estimates a sigma (within-group error) anyway, both with poisson or quasipoisson family.
> Its value is 1.40
> The value of sigma^2 is equal to the overdispersion parameter of simpler glm-gam models (~1.96), which makes sense.
>  
> The second model with glmer doesn't estimate a sigma (correctly), but when the family is set to quasipoisson the estimated sigma [lme4:::sigma(glmer.model)] is 15.8, which is simply unbelievable. The standard errors are therefore incredibly huge.
>  
> I couldn't find a reason for that.
> Any comment/suggestion is more than welcome.
> Thanks

  This is interesting.  Can you provide a reproducible example?  Is
random=list(region=pdSymm(~time)) really equivalent to (time|region)?



From Antonio.Gasparrini at lshtm.ac.uk  Fri Feb 12 15:32:54 2010
From: Antonio.Gasparrini at lshtm.ac.uk (Antonio.Gasparrini at lshtm.ac.uk)
Date: Fri, 12 Feb 2010 14:32:54 +0000
Subject: [R-sig-ME] lme4, glmmPQL and calculating QAICc
In-Reply-To: <4B74D20A.2030603@ufl.edu>
References: <4B74B363.5572.00B2.1@lshtm.ac.uk> <4B74D20A.2030603@ufl.edu>
Message-ID: <4B756690.5572.00B2.0@lshtm.ac.uk>

Dear Ben and R users,
 
I put the pdSymm constructor in glmmPQL just because I tried also different correlation structures.
If I change it to the simpler 'random=~time|region' I got slightly different results and the notification of 'General positive-definite, Log-Cholesky parametrization' instead of the simple 'General positive-definite'.
 
Anyway, nothing affecting the results substantially.
I can't include the original data, so I simulated them (trends of Poisson-distributed counts with overdispersion for 20 regions) with parameters similar to the estimates I found. Here is the code:
 
##################################################################

set.seed(13041975)
library(MASS);library(lattice)

# BUILD THE DESIGN MATRIX FOR FIXED AND RANDOM EFFECTS
region <- rep(1:20,each=60)
time <- rep(1:60,20)
X <- cbind(rep(1,20*60), time)
Z <- diag(rep(1,20)) %x% cbind(rep(1,60),1:60)

# SET FIXED AND RANDOM EFFECTS (FROM MV-NORMAL)
fixef <- c(-6.5,0.001)
ranef <- mvrnorm(20,c(0,0),matrix(c(0.14^2,0,0,0.003^2),2,2))

# POPULATION (DIFFERENT SIZE)
pop <- rep(runif(20,10^4,10^6),each=60)

# PREDICTED
pred <- exp(X%*%fixef + Z%*%as.vector(t(ranef))) * pop

# OBSERVED (FROM NEGATIVE BINOMIAL WITH OVERDISPERSION PHI)
phi <- 1.4^2
obs <- rnbinom(length(pop), mu=pred, size=pred/(phi-1))

# PLOT (RATES)
xyplot(obs/pop*10^5+pred/pop*10^5~time|region,type=c("p","l"),
 distribute.type=T)

# MODELS

library(nlme)
pql <- glmmPQL(obs ~ offset(log(pop)) + time, random=~time|region,
 family=poisson)
pql$sigma
# THIS IS OK

library(lme4)
glmer <- glmer(obs ~ offset(log(pop)) + time + (time|region),
 family=quasipoisson)
glmer
lme4:::sigma(glmer)
# STRANGE RESULTS

##################################################################

After this results, I think there's something odd with glmer and quasipoisson family.
I'm currently running an analysis on real data, I hope someone can give me some hints.

Thanks

Antonio Gasparrini
Public and Environmental Health Research Unit (PEHRU)
London School of Hygiene & Tropical Medicine
Keppel Street, London WC1E 7HT, UK
Office: 0044 (0)20 79272406 - Mobile: 0044 (0)79 64925523

>>> Ben Bolker <bolker at ufl.edu> 12/02/2010 03:59 >>>
Antonio.Gasparrini at lshtm.ac.uk wrote:
> Dear R users,
>  
> following the recent discussion on calculating QAICc in lme4, I report the weird results I got comparing glmer and glmmPQL.
>  
> I ran these models: 
>  
> pql.model <- glmmPQL(outcome ~ offset(log(pop)) + time + 
>  harmonic(month,3,12), random=list(region=pdSymm(~time)), family=poisson, data)
>  
> glmer.model <- glmer(outcome ~ offset(log(pop)) + time + 
>  harmonic(mm,3,12) + (time|region), family=poisson, data)
> The first model with glmmPQL estimates a sigma (within-group error) anyway, both with poisson or quasipoisson family.
> Its value is 1.40
> The value of sigma^2 is equal to the overdispersion parameter of simpler glm-gam models (~1.96), which makes sense.
>  
> The second model with glmer doesn't estimate a sigma (correctly), but when the family is set to quasipoisson the estimated sigma [lme4:::sigma(glmer.model)] is 15.8, which is simply unbelievable. The standard errors are therefore incredibly huge.
>  
> I couldn't find a reason for that.
> Any comment/suggestion is more than welcome.
> Thanks

  This is interesting.  Can you provide a reproducible example?  Is
random=list(region=pdSymm(~time)) really equivalent to (time|region)?



From Thierry.ONKELINX at inbo.be  Fri Feb 12 15:42:23 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Fri, 12 Feb 2010 15:42:23 +0100
Subject: [R-sig-ME] offset() not working in nlme?
Message-ID: <2E9C414912813E4EB981326983E0A1040701FF1E@inboexch.inbo.be>

Dear all,
 
I tried to use an offset in liner mixed model with nlme but it seems
like lme() ignores the offset. Models with or without the offset yield
exactly the same estimates. See the example below.

Is this intended behaviour or am I doing something wrong?

Best regards,

Thierry

> library(nlme)
> nSubject <- 100
> MeasurementError <- 10
> dataset <- expand.grid(Subject = seq_len(nSubject), Measurement =
seq_len(5))
> dataset$Truth <- rnorm(nSubject, mean = 100, sd = 20)[dataset$Subject]
> dataset$Precise <- round(dataset$Truth, 0)
> dataset$Unprecise <- round(rnorm(nrow(dataset), mean = dataset$Truth,
sd = MeasurementError), 0)
> dataset$Bias <- dataset$Unprecise - dataset$Precise

#With offset

> lme(Unprecise ~ offset(Precise), random =  ~ 1|Subject, data =
dataset)
Linear mixed-effects model fit by REML
  Data: dataset 
  Log-restricted-likelihood: -2014.358
  Fixed: Unprecise ~ offset(Precise) 
(Intercept) 
     97.844 

Random effects:
 Formula: ~1 | Subject
        (Intercept) Residual
StdDev:    20.10238 10.07502

Number of Observations: 500
Number of Groups: 100 

#without offset
> lme(Unprecise ~ 1, random =  ~ 1|Subject, data = dataset)
Linear mixed-effects model fit by REML
  Data: dataset 
  Log-restricted-likelihood: -2014.358
  Fixed: Unprecise ~ 1 
(Intercept) 
     97.844 

Random effects:
 Formula: ~1 | Subject
        (Intercept) Residual
StdDev:    20.10238 10.07502

Number of Observations: 500
Number of Groups: 100 

#calculating the offset a priori.
> lme(Bias ~ 1, random =  ~ 1|Subject, data = dataset)
Linear mixed-effects model fit by REML
  Data: dataset 
  Log-restricted-likelihood: -1868.963
  Fixed: Bias ~ 1 
(Intercept) 
     -0.066 

Random effects:
 Formula: ~1 | Subject
        (Intercept) Residual
StdDev:    1.482101 10.07502

Number of Observations: 500
Number of Groups: 100 


> sessionInfo()
R version 2.10.1 (2009-12-14) 
i386-pc-mingw32 

locale:
[1] LC_COLLATE=Dutch_Belgium.1252  LC_CTYPE=Dutch_Belgium.1252   
[3] LC_MONETARY=Dutch_Belgium.1252 LC_NUMERIC=C                  
[5] LC_TIME=Dutch_Belgium.1252    

attached base packages:
[1] stats     graphics  grDevices datasets  utils     methods   base


other attached packages:
[1] nlme_3.1-96

loaded via a namespace (and not attached):
[1] grid_2.10.1    lattice_0.18-3
 

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey
  


Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From j.Perez-Barberia at macaulay.ac.uk  Fri Feb 12 17:14:19 2010
From: j.Perez-Barberia at macaulay.ac.uk (Javier Perez-Barberia)
Date: Fri, 12 Feb 2010 16:14:19 +0000
Subject: [R-sig-ME] Use of poly( ) in LMER: bug?
Message-ID: <4B757E5B020000690004A11F@macaulay.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100212/211403aa/attachment.pl>

From reinhold.kliegl at gmail.com  Fri Feb 12 17:29:13 2010
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Fri, 12 Feb 2010 17:29:13 +0100
Subject: [R-sig-ME] Use of poly( ) in LMER: bug?
In-Reply-To: <4B757E5B020000690004A11F@macaulay.ac.uk>
References: <4B757E5B020000690004A11F@macaulay.ac.uk>
Message-ID: <aefe4d0a1002120829i3ef4196ara5b40fd804c4b703@mail.gmail.com>

Try:
library(lme4)
(fm1 <- lmer(Reaction ~ Days + (1|Subject), sleepstudy))
(fm2 <- lmer(Reaction ~ poly(Days, 1, raw=TRUE) + (1|Subject), sleepstudy))

Then:
?poly

Reinhold Kliegl

On Fri, Feb 12, 2010 at 5:14 PM, Javier Perez-Barberia
<j.Perez-Barberia at macaulay.ac.uk> wrote:
> Dear users,
>
> After more than a day figuring out why my predicted values were so high we found out that fitting a term as poly(my_term,1)
> was creating havoc in the fixed effects of LMER for this term.
>
> I thought that poly(my_term,1) was the same that fitting "my_term", it seems that I was wrong.
>
> Although it doesn't make sense fitting a linear term as poly(my_term,1) rather than the more economical "my_term", I wonder what it is behind
> the poly( ) function that produces such a different result (see below).
>
> Many thanks
>
> Javier
>
> Model 1
> fm1<-lmer(niche_breadth~cos_days+sin_days+poly(easting,2)+poly(northing,2)+
> ? ? ? ? ?poly(mean_temp,1)+lgdensity+lgdensity*poly(easting,2)+lgdensity*poly(northing,2)+
> ? ? ? ? ?(lgdensity|block)+(1|year),data=data)
>
>
> fixef(fm1)[8]
> poly(mean_temp, 1)
> ? ? ? ? 0.1789691
> Model 2 (as Model 1 but "mean_temp" rather than "poly(mean_temp,1)")
>
> fixef(fm1)[8] ##all other fixed effects were as in Model 1.
> ? mean_temp
> 2.590413e-05
>
>
> Dr. Javier Perez-Barberia
> Population and evolutionary ecologist
> The Macaulay Institute
> Craigiebuckler
> Aberdeen
> AB15 8QH
> Scotland, UK
>
> Tel: +44(0)1224 395221
> e-mail: j.perez-barberia at macaulay.ac.uk
> http://www.macaulay.ac.uk
> http://www.macaulay.ac.uk/upland
>
> --
> Please note that the views expressed in this e-mail are those of the
> sender and do not necessarily represent the views of the Macaulay
> Institute. This email and any attachments are confidential and are
> intended solely for the use of the recipient(s) to whom they are
> addressed. If you are not the intended recipient, you should not read,
> copy, disclose or rely on any information contained in this e-mail, and
> we would ask you to contact the sender immediately and delete the email
> from your system. Thank you.
> The Macaulay Land Use Research Institute is a company limited by guarantee,
> registered in Scotland under company number 16190 and a registered Scottish
> charity, number SC011922. Registered office
> Macaulay Drive, Craigiebuckler, Aberdeen, AB15 8QH.
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Sat Feb 13 00:28:28 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 12 Feb 2010 17:28:28 -0600
Subject: [R-sig-ME] Chapter drafts of my book are now on the R-forge web
	site for lme4
Message-ID: <40e66e0b1002121528x3a5415c5oc3af82404e95e42d@mail.gmail.com>

I have finally gotten the chapter drafts of the book, "lme4:
Mixed-effects Modeling with R", that I am writing to the point where I
think they can be helpful to others.  I believe I have properly
committed them to the R-forge site but they will not appear for an
hour or so.  They should be available under
http://lme4.R-forge.R-project.org/book/

Chapters 1, 2, 4 and 5 are currently available as are the .R files for
those chapters.  Chapters 4 and 5 will have material added to them.  I
don't expect to change chapters 1 and 2 until I get reviewers reports.

When pointing out errors, inconsistencies, bad writing, obtuse
explanations, etc., please be gentle.



From desja004 at umn.edu  Sun Feb 14 02:57:34 2010
From: desja004 at umn.edu (desja004 at umn.edu)
Date: 13 Feb 2010 19:57:34 -0600
Subject: [R-sig-ME] Question about usuge of DIC
In-Reply-To: <40e66e0b1002121528x3a5415c5oc3af82404e95e42d@mail.gmail.com>
References: <40e66e0b1002121528x3a5415c5oc3af82404e95e42d@mail.gmail.com>
Message-ID: <Gophermail.2.0.1002131957340.23778@vs-a.tc.umn.edu>

Hi,
I have a general question about the use of the DIC and other fit indices. I 
have fit a Poisson and a zero-inflated Poisson model in MCMCglmm and I am 
curious if I can use the DIC as evidence in support of one distributional 
model over another (with the same fixed and random effects)? Currently I 
plan on including graphs with predicted values from the two models to show 
that the ZIP model fits better than the Poisson but I was curious if I 
could use the DIC or another statistic to support my decision in choosing 
one distribution over another.
Chris



From mspinola10 at gmail.com  Sun Feb 14 17:54:09 2010
From: mspinola10 at gmail.com (=?ISO-8859-1?Q?Manuel_Sp=EDnola?=)
Date: Sun, 14 Feb 2010 10:54:09 -0600
Subject: [R-sig-ME] Repeated measures design in R
Message-ID: <4B782AB1.5060701@gmail.com>

Dear list members,

Sorry for cross-posting.

I am analyzing a repeated measure design with the nlme package to assess 
the disease rate in 48 counties (localidad).  The disease rate was 
measured in 4 consecutive years.  The first 20 observations of my data 
set looks like:

 > ipa
             localidad tiempo    ipa
1             15.MILLAS      1 123.40
2             23.MILLAS      1 185.40
3             24.MILLAS      1  21.31
4             25.MILLAS      1   0.00
5             26.MILLAS      1  59.11
6             28.MILLAS      1  10.28
7              4.MILLAS      1 118.69
8              7.MILLAS      1  17.09
9              AGRODISA      1  59.49
10              ASELICA      1  50.98
11            BALTIMORE      1  25.10
12             BANANITA      1  19.30
13              BANASOL      1   0.00
14             BARBILLA      1  27.33
15                BATAN      1  48.58
16               B.LINE      1  57.97
17               BOSTON      1 101.32
18              BRISTOL      1  47.62
19  COLONIA.PURISCALE?A      1  22.22
20               CORINA      1  22.22


I tried these models:


# Pooled data

modelo1 = glm(ipa ~ tiempo, family=gaussian(link=identity), data=ipa)
summary(modelo1)

# Parallel slopes

modelo2 = glm(ipa ~ tiempo + localidad, family=gaussian(link=identity), 
data=ipa)
summary(modelo2)

# Random intercept (el intercepto cambia para cada localidad)

modelo3 = lme(ipa ~ tiempo, random = ~ 1 | localidad, data=ipa)
summary(modelo3)

# Random intercept and slope

modelo4 = lme(ipa ~ tiempo, random =  ~ tiempo | localidad, data=ipa)
summary(modelo4)

# Autocorrelation

modelo6 = lme(ipa ~ tiempo, random =  ~ 1 | localidad, correlation = 
corCAR1(form = ~ tiempo | localidad), data=ipa)
summary(modelo6)


The model for Random intercept and slope gave me this error:

 > modelo4 = lme(ipa ~ tiempo, random =  ~ tiempo | localidad, data=ipa)
Error en lme.formula(ipa ~ tiempo, random = ~tiempo | localidad, data = 
ipa) :
 nlminb problem, convergence error code = 1
 message = iteration limit reached without convergence (9)

Do you know why the model (modelo4) has problems?

Also, is this the way to analyze a repeated measure design in R?

The counties (localidad) are all the county that I am interested, is 
that still random factor?

Thank you very much in advance.

Best,

Manuel Sp?nola

-- 
Manuel Sp?nola, Ph.D.
Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
Universidad Nacional
Apartado 1350-3000
Heredia
COSTA RICA
mspinola at una.ac.cr
mspinola10 at gmail.com
Tel?fono: (506) 2277-3598
Fax: (506) 2237-7036



From bolker at ufl.edu  Sun Feb 14 20:58:32 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Sun, 14 Feb 2010 14:58:32 -0500
Subject: [R-sig-ME] Repeated measures design in R
In-Reply-To: <4B782AB1.5060701@gmail.com>
References: <4B782AB1.5060701@gmail.com>
Message-ID: <4B7855E8.2070408@ufl.edu>


  Your design looks reasonable.  Convergence failures usually have
something to do with weak identifiability -- not quite enough
information in the data to fit the model.  It's hard to tell from
just the time-1 data you've presented here.  It does look like the
data are a bit non-normal, although not terribly extremely.  I don't
know if you really need a continuous-time correlation model (corCAR1);
are your data irregularly sampled in time?  corAR1 might be better ...
You might also try assuming independence between the time and intercept
random effects (see Pinheiro and Bates 2000) to squeeze out a tiny bit
more model-fitting capability.  The other extreme is to go to a Bayesian
approach which uses a mildly informative prior to stabilize the fitting ...

Manuel Sp?nola wrote:
> Dear list members,
> 
> Sorry for cross-posting.
> 
> I am analyzing a repeated measure design with the nlme package to assess 
> the disease rate in 48 counties (localidad).  The disease rate was 
> measured in 4 consecutive years.  The first 20 observations of my data 
> set looks like:
> 
>  > ipa
>              localidad tiempo    ipa
> 1             15.MILLAS      1 123.40
> 2             23.MILLAS      1 185.40
> 3             24.MILLAS      1  21.31
> 4             25.MILLAS      1   0.00
> 5             26.MILLAS      1  59.11
> 6             28.MILLAS      1  10.28
> 7              4.MILLAS      1 118.69
> 8              7.MILLAS      1  17.09
> 9              AGRODISA      1  59.49
> 10              ASELICA      1  50.98
> 11            BALTIMORE      1  25.10
> 12             BANANITA      1  19.30
> 13              BANASOL      1   0.00
> 14             BARBILLA      1  27.33
> 15                BATAN      1  48.58
> 16               B.LINE      1  57.97
> 17               BOSTON      1 101.32
> 18              BRISTOL      1  47.62
> 19  COLONIA.PURISCALE?A      1  22.22
> 20               CORINA      1  22.22
> 
> 
> I tried these models:
> 
> 
> # Pooled data
> 
> modelo1 = glm(ipa ~ tiempo, family=gaussian(link=identity), data=ipa)
> summary(modelo1)
> 
> # Parallel slopes
> 
> modelo2 = glm(ipa ~ tiempo + localidad, family=gaussian(link=identity), 
> data=ipa)
> summary(modelo2)
> 
> # Random intercept (el intercepto cambia para cada localidad)
> 
> modelo3 = lme(ipa ~ tiempo, random = ~ 1 | localidad, data=ipa)
> summary(modelo3)
> 
> # Random intercept and slope
> 
> modelo4 = lme(ipa ~ tiempo, random =  ~ tiempo | localidad, data=ipa)
> summary(modelo4)
> 
> # Autocorrelation
> 
> modelo6 = lme(ipa ~ tiempo, random =  ~ 1 | localidad, correlation = 
> corCAR1(form = ~ tiempo | localidad), data=ipa)
> summary(modelo6)
> 
> 
> The model for Random intercept and slope gave me this error:
> 
>  > modelo4 = lme(ipa ~ tiempo, random =  ~ tiempo | localidad, data=ipa)
> Error en lme.formula(ipa ~ tiempo, random = ~tiempo | localidad, data = 
> ipa) :
>  nlminb problem, convergence error code = 1
>  message = iteration limit reached without convergence (9)
> 
> Do you know why the model (modelo4) has problems?
> 
> Also, is this the way to analyze a repeated measure design in R?
> 
> The counties (localidad) are all the county that I am interested, is 
> that still random factor?
> 
> Thank you very much in advance.
> 
> Best,
> 
> Manuel Sp?nola
> 


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From robjgoedman at me.com  Mon Feb 15 01:15:54 2010
From: robjgoedman at me.com (Rob Goedman)
Date: Sun, 14 Feb 2010 16:15:54 -0800
Subject: [R-sig-ME] Chapter drafts of my book are now on the R-forge
	web	site for lme4
In-Reply-To: <40e66e0b1002121528x3a5415c5oc3af82404e95e42d@mail.gmail.com>
References: <40e66e0b1002121528x3a5415c5oc3af82404e95e42d@mail.gmail.com>
Message-ID: <326890CE-7F7D-4FA4-BED3-90A4859CD327@me.com>

Hi,

Working through chapter 1, I got stuck on the profiled deviance section (1.4.2/1.5) which need lme4a (I guess).

Has anyone been able to install lme4a on SnowLeopard? 

An older R.2.10.1/Leopard/ppc machine or R.2.10.1 and R-devel (SnowLeopard, both 32 or 64 bit) all produce the error shown below.

Thanks,
Rob


------------------------------------

Robs-Intel:~ rob$ cd Projects/R/R_projects/Bates/lme_package/lme4a/
Robs-Intel:lme4a rob$ R_ARCH=/x86_64 R CMD BUILD .
* checking for file './DESCRIPTION' ... OK
* preparing '.':
* checking DESCRIPTION meta-information ... OK
* cleaning src
make: Nothing to be done for `clean'.
* installing the package to re-build vignettes
* installing *source* package ?lme4a? ...
** libs
** arch - x86_64
g++-4.2 -arch x86_64 -I/Library/Frameworks/R.framework/Resources/include -I/Library/Frameworks/R.framework/Resources/include/x86_64  -I/usr/local/include -I"/Library/Frameworks/R.framework/Resources/library/Matrix/include"   -fPIC  -mtune=core2 -g -O2 -c GLfamily.cpp -o GLfamily.o
In file included from /usr/include/stdlib.h:67,
                 from /usr/include/c++/4.2.1/cstdlib:72,
                 from /usr/include/c++/4.2.1/bits/stl_algobase.h:68,
                 from /usr/include/c++/4.2.1/bits/char_traits.h:46,
                 from /usr/include/c++/4.2.1/string:47,
                 from GLfamily.hpp:5,
                 from GLfamily.cpp:1:
/usr/include/alloca.h:36: error: declaration of ?void* __builtin_alloca?
/usr/include/alloca.h:36: error: conflicts with built-in declaration ?void* __builtin_alloca(long unsigned int)?
/usr/include/alloca.h:36: error: declaration of ?void* __builtin_alloca?
<built-in>:0: error: conflicts with previous declaration ?void* __builtin_alloca(long unsigned int)?
/usr/include/alloca.h:36: error: expected primary-expression before ?)? token
make: *** [GLfamily.o] Error 1
ERROR: compilation failed for package ?lme4a?
* removing ?/private/var/folders/RC/RC96PNSWFMORQM4VyHEgik+++TI/-Tmp-/Rinst7538767924/lme4a?
 ERROR
Installation failed.
Removing '/var/folders/RC/RC96PNSWFMORQM4VyHEgik+++TI/-Tmp-//Rinst7538767924'
Robs-Intel:lme4a rob$ 



On Feb 12, 2010, at 3:28 PM, Douglas Bates wrote:

> I have finally gotten the chapter drafts of the book, "lme4:
> Mixed-effects Modeling with R", that I am writing to the point where I
> think they can be helpful to others.  I believe I have properly
> committed them to the R-forge site but they will not appear for an
> hour or so.  They should be available under
> http://lme4.R-forge.R-project.org/book/
> 
> Chapters 1, 2, 4 and 5 are currently available as are the .R files for
> those chapters.  Chapters 4 and 5 will have material added to them.  I
> don't expect to change chapters 1 and 2 until I get reviewers reports.
> 
> When pointing out errors, inconsistencies, bad writing, obtuse
> explanations, etc., please be gentle.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From Sam.Weber at exeter.ac.uk  Sun Feb 14 18:54:03 2010
From: Sam.Weber at exeter.ac.uk (Weber, Sam)
Date: Sun, 14 Feb 2010 17:54:03 +0000
Subject: [R-sig-ME] [R] Missing interaction effect in binomial GLMM with
	lmer
In-Reply-To: <001201caa9b5$151bab30$bed41f0a@gne.windows.gene.com>
References: <5BB78285B60F9B4DB2C6A4DA8F3E788C2B99E17D1D@EXCHMBS04.isad.isadroot.ex.ac.uk>
	<f55e7cf51002090919w40dcbe11g1da362e090d61676@mail.gmail.com>,
	<001201caa9b5$151bab30$bed41f0a@gne.windows.gene.com>
Message-ID: <5BB78285B60F9B4DB2C6A4DA8F3E788C2EB3DBA01F@EXCHMBS04.isad.isadroot.ex.ac.uk>

Dear all, 

I posted the following query to the general R-help list last week, but following the recommendation below I thought it might be worth posting to the mixed-models list as well to see if anyone could give me any pointers. The original post and data are included below. Would be very grateful for any suggestions,

Best regards

Sam Weber

________________________________________
From: Bert Gunter [gunter.berton at gene.com]
Sent: 09 February 2010 18:24
To: 'Ista Zahn'; Weber, Sam
Cc: 'r-help at R-project.org'
Subject: RE: [R] Missing interaction effect in binomial GLMM with lmer

You might do better posting this on the R-sig-mixed-models list.

Bert Gunter
Genentech Nonclinical Statistics





-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Ista Zahn
Sent: Tuesday, February 09, 2010 9:19 AM
To: Weber, Sam
Cc: r-help at R-project.org
Subject: Re: [R] Missing interaction effect in binomial GLMM with lmer

Hi Sam,
Good question. I originally guessed that the "simple effect" (I know
some people on this list don't seem to care for that term, but it's
always made sense to me) coefficients were in the same direction, such
that the effect if Origin at Treat=hot was significantly different
from zero, but not from the effect of Origin at Treat = cold. But a
quick look indicated that is not the case:

contrasts(hatch.frame$Treat) <- contr.treatment(2, base=1)
model1<-lmer(success~Origin*Treat+(1|Female),family=binomial,REML=TRUE,data=
hatch.frame)
summary(model1)

Generalized linear mixed model fit by the Laplace approximation
Formula: success ~ Origin * Treat + (1 | Female)
  Data: hatch.frame
  AIC   BIC logLik deviance
 95.34 109.3 -42.67    85.34
Random effects:
 Groups Name        Variance Std.Dev.
 Female (Intercept) 0.54993  0.74157
Number of obs: 120, groups: Female, 20

Fixed effects:
               Estimate Std. Error z value Pr(>|z|)
(Intercept)     3.609227   1.146844   3.147  0.00165 **
Origin2        -0.004192   1.606214  -0.003  0.99792
Treat2         -5.401703   1.238911  -4.360  1.3e-05 ***
Origin2:Treat2  1.948242   1.697945   1.147  0.25121
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
           (Intr) Orign2 Treat2
Origin2     -0.714
Treat2      -0.889  0.635
Orign2:Trt2  0.649 -0.907 -0.730

contrasts(hatch.frame$Treat) <- contr.treatment(2, base=2)
model2<-lmer(success~Origin*Treat+(1|Female),family=binomial,REML=TRUE,data=
hatch.frame)
summary(model2)

Generalized linear mixed model fit by the Laplace approximation
Formula: success ~ Origin * Treat + (1 | Female)
  Data: hatch.frame
  AIC   BIC logLik deviance
 95.34 109.3 -42.67    85.34
Random effects:
 Groups Name        Variance Std.Dev.
 Female (Intercept) 0.54993  0.74157
Number of obs: 120, groups: Female, 20

Fixed effects:
              Estimate Std. Error z value Pr(>|z|)
(Intercept)     -1.7925     0.5683  -3.154  0.00161 **
Origin2          1.9441     0.7190   2.704  0.00686 **
Treat1           5.4017     1.2389   4.360  1.3e-05 ***
Origin2:Treat1  -1.9484     1.6979  -1.148  0.25116
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
           (Intr) Orign2 Treat1
Origin2     -0.790
Treat1      -0.385  0.305
Orign2:Trt1  0.281 -0.336 -0.730


So I'm as stumped as you are. How can the effect of Origin at
treat=hot be significantly different from zero, but not significantly
different from -0.004? Clearly there is something here I'm not
understanding. I'm very curious to know the answer.

Best,
Ista






On Tue, Feb 9, 2010 at 12:22 PM, Weber, Sam <Sam.Weber at exeter.ac.uk> wrote:
> Dear all,
>
> I was wondering if anyone could help solve a problem of a missing
interaction effect!!
>
> I carried out a 2 x 2 factorial experiment to see if eggs from 2 different
locations (Origin =  1 or 2) had different hatching success under 2
different incubation schedules (Treat = 1 or 2). Six eggs were taken from 10
females (random = Female) at each location and split between the treatments,
giving 30 eggs from each location in each treatment.
>
> Overall proportions hatching were as follows:
>
> Treat
>                        1                     2
> Origin
> 1                   29/30                 5/30
> 2                   29/30               16/30
>
>
> I made a binomial response in which hatching was a success and
not-hatching was a failure, and analysed as a binomial GLMM. I'm
particularly interested in the interaction between the two factors. An
expression reproducing the raw data is attached at the end of the post in
case it is helpful.
>
> hatch.frame$success<-cbind(hatch.frame$Hatched,hatch.frame$Nothatched)
>
model<-lmer(success~Origin*Treat+(1|Female),family=binomial,method="ML",data
=hatch.frame)
> model2<-update(model,~.-Origin:Treat)
> anova(model,model2)
>
> Data:
> Models:
> model2: success ~ Origin + Treat + (1 | Female)
> model: success ~ Origin * Treat + (1 | Female)
>            Df     AIC     BIC       logLik  Chisq  Chi Df   Pr(>Chisq)
> model2  4  94.707 105.857 -43.353
> model   5  95.350 109.287 -42.675 1.3572      1      0.244
>
> model3<-update(model2,~.-Origin)
> anova(model2,model3)
>
> Data:
> Models:
> model3: success ~ Treat + (1 | Female)
> model2: success ~ Origin + Treat + (1 | Female)
>       Df     AIC     BIC  logLik  Chisq Chi Df Pr(>Chisq)
> model3  3  98.863 107.225 -46.431
> model2  4  94.707 105.857 -43.353 6.1558      1    0.01310 *
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
> model4<-update(model2,~.-Treat)
> anova(model2,model4)
>
> Data:
> Models:
> model4: success ~ Origin + (1 | Female)
> model2: success ~ Origin + Treat + (1 | Female)
>       Df     AIC     BIC  logLik  Chisq Chi Df Pr(>Chisq)
> model4  3 155.592 163.954 -74.796
> model2  4  94.707 105.857 -43.353 62.885      1  2.191e-15 ***
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> So the model implies that there is a very significant effect of treatment
(reduced hatching at treatment 2) with a small effect of origin (improved
hatching from origin 2). However the lack of interaction effect implies
hatching was better for Origin 2 at both treatments, which looking at the
raw values above does not seem to be the case. Identical numbers of eggs
hatched from both Origins in Treatment 1, but much more from Origin 2
hatched at Treatment 2.
>
> If you divide the analysis by treatments, Origin only has a significant
effect on hatching under Treatment 2 and not with Treatment 1
>
> Hot<-data.frame(hatch.frame[hatch.frame$Treat==2,])
> Cold<-data.frame(hatch.frame[hatch.frame$Treat==1,])
>
> #2
model<-lmer(success~Origin+(1|Female),family=binomial,method="ML",data=Hot)
> model2<-update(model,~.-Origin)
> anova(model,model2)
> Data: Hot
> Models:
> model2: incubate ~ (1 | Code)
> model: incubate ~ Origin + (1 | Code)
>       Df     AIC     BIC  logLik  Chisq Chi Df Pr(>Chisq)
> model2  2  78.633  82.821 -37.316
> model   3  73.697  79.980 -33.848 6.9357      1   0.008449 **
>
> #1
model<-lmer(success~Origin+(1|Female),family=binomial,method="ML",data=Cold)
> model2<-update(model,~.-Origin)
> anova(model,model2)
>
> Data: Cold
> Models:
> model2: incubate ~ (1 | Code)
> model: incubate ~ Origin + (1 | Code)
>       Df     AIC     BIC  logLik  Chisq Chi Df Pr(>Chisq)
> model2  2 21.5086 25.6973 -8.7543
> model   3 23.3472 29.6302 -8.6736 0.1615      1     0.6878
>
> So I can't understand where the interaction effect has gone in the full
model?! I get the same result in a binomial GLM, without the random effect
of Female i.e. a small effect of origin but no interaction with treatment.
I'm sure I must be missing something here so I would be very grateful to
anyone who can point out my mistakes. I've read previous R Help posts that
suggest binomial GLM(M) can create problems when estimated probabilities are
close to 0 or 1. In Treatment 1 hatching probability was 0.97 for both
Origins, so could this be the source of the problem?
>
> Thanks for your help
>
> Sam Weber
>
----------------------------------------------------------------------------
> University of Exeter
> Centre for Ecology and Conservation
> Tremough Campus
> Penryn
> Cornwall TR10 9EZ
> UK
>
>
>
> hatch.frame <-
> structure(list(Female = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 2L,
> 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L,
> 4L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 6L, 7L, 7L, 7L,
> 7L, 7L, 7L, 8L, 8L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 9L, 9L, 10L,
> 10L, 10L, 10L, 10L, 10L, 11L, 11L, 11L, 11L, 11L, 11L, 12L, 12L,
> 12L, 12L, 12L, 12L, 13L, 13L, 13L, 13L, 13L, 13L, 14L, 14L, 14L,
> 14L, 14L, 14L, 15L, 15L, 15L, 15L, 15L, 15L, 16L, 16L, 16L, 16L,
> 16L, 16L, 17L, 17L, 17L, 17L, 17L, 17L, 18L, 18L, 18L, 18L, 18L,
> 18L, 19L, 19L, 19L, 19L, 19L, 19L, 20L, 20L, 20L, 20L, 20L, 20L
> ), .Label = c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10",
> "11", "12", "13", "14", "15", "16", "17", "18", "19", "20"), class =
"factor"),
>    Origin = structure(c(2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L,
>    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
>    2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
>    2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
>    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
>    2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
>    1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L,
>    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
>    2L, 2L, 2L, 2L, 2L, 2L), .Label = c("1", "2"), class = "factor"),
>    Treat = structure(c(1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
>    1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>    2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
>    1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>    2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
>    1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>    2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
>    1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>    2L, 1L, 2L, 1L, 2L), .Label = c("1", "2"), class = "factor"),
>    Hatched = c(1L, 1L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L,
>    1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
>    1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L,
>    1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L,
>    0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L,
>    1L, 0L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L,
>    0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L,
>    1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 1L,
>    0L, 1L, 1L), Nothatched = c(0, 0, 1, 0, 0, 1, 0, 1, 0, 1,
>    0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
>    0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,
>    0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0,
>    0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,
>    0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,
>    1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0)), .Names = c("Female",
> "Origin", "Treat", "Hatched", "Nothatched"), row.names = c(NA,
> -120L), class = "data.frame")


From bolker at ufl.edu  Mon Feb 15 04:15:47 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Sun, 14 Feb 2010 22:15:47 -0500
Subject: [R-sig-ME] [R] Missing interaction effect in binomial GLMM with
 lmer
In-Reply-To: <5BB78285B60F9B4DB2C6A4DA8F3E788C2EB3DBA01F@EXCHMBS04.isad.isadroot.ex.ac.uk>
References: <5BB78285B60F9B4DB2C6A4DA8F3E788C2B99E17D1D@EXCHMBS04.isad.isadroot.ex.ac.uk>	<f55e7cf51002090919w40dcbe11g1da362e090d61676@mail.gmail.com>,
	<001201caa9b5$151bab30$bed41f0a@gne.windows.gene.com>
	<5BB78285B60F9B4DB2C6A4DA8F3E788C2EB3DBA01F@EXCHMBS04.isad.isadroot.ex.ac.uk>
Message-ID: <4B78BC63.6060904@ufl.edu>


  I don't think this is necessarily a mixed model question (as you
pointed out, one gets about the same effect in the plain non-mixed GLM).
I also don't think it's the Hauck-Donner effect (i.e., a problem with
estimated probabilities being too close to 0 or 1 so that Wald tests are
unreliable) -- in any case, this issue applies only to Wald tests (e.g.
Z- and t-statistics reported by summary()), not to likelihood ratio
tests (e.g. results of anova()).  Is it not just a reasonable conclusion
that there is not a significant difference between (the difference
between 29/30 and 16/30) and (the difference between 29/30 and 5/30)?

  The likelihood ratio test is known to be a little unreliable for small
sample sizes (I can't work out the approximate "denominator df" for this
case without thinking too hard), but a quick parametric bootstrap
suggests that the p-value of 0.24 is not too far off ...





Weber, Sam wrote:
> Dear all,
> 
> I posted the following query to the general R-help list last week,
> but following the recommendation below I thought it might be worth
> posting to the mixed-models list as well to see if anyone could give
> me any pointers. The original post and data are included below. Would
> be very grateful for any suggestions,
> 
> Best regards
> 
> Sam Weber
> 
> ________________________________________ From: Bert Gunter
> [gunter.berton at gene.com] Sent: 09 February 2010 18:24 To: 'Ista
> Zahn'; Weber, Sam Cc: 'r-help at R-project.org' Subject: RE: [R] Missing
> interaction effect in binomial GLMM with lmer
> 
> You might do better posting this on the R-sig-mixed-models list.
> 
> Bert Gunter Genentech Nonclinical Statistics
> 
> 
> 
> 
> 
> -----Original Message----- From: r-help-bounces at r-project.org
> [mailto:r-help-bounces at r-project.org] On Behalf Of Ista Zahn Sent:
> Tuesday, February 09, 2010 9:19 AM To: Weber, Sam Cc:
> r-help at R-project.org Subject: Re: [R] Missing interaction effect in
> binomial GLMM with lmer
> 
> Hi Sam, Good question. I originally guessed that the "simple effect"
> (I know some people on this list don't seem to care for that term,
> but it's always made sense to me) coefficients were in the same
> direction, such that the effect if Origin at Treat=hot was
> significantly different from zero, but not from the effect of Origin
> at Treat = cold. But a quick look indicated that is not the case:
> 
> contrasts(hatch.frame$Treat) <- contr.treatment(2, base=1) 
> model1<-lmer(success~Origin*Treat+(1|Female),family=binomial,REML=TRUE,data=
>  hatch.frame) summary(model1)
> 
> Generalized linear mixed model fit by the Laplace approximation 
> Formula: success ~ Origin * Treat + (1 | Female) Data: hatch.frame 
> AIC   BIC logLik deviance 95.34 109.3 -42.67    85.34 Random effects:
>  Groups Name        Variance Std.Dev. Female (Intercept) 0.54993
> 0.74157 Number of obs: 120, groups: Female, 20
> 
> Fixed effects: Estimate Std. Error z value Pr(>|z|) (Intercept)
> 3.609227   1.146844   3.147  0.00165 ** Origin2        -0.004192
> 1.606214  -0.003  0.99792 Treat2         -5.401703   1.238911  -4.360
> 1.3e-05 *** Origin2:Treat2  1.948242   1.697945   1.147  0.25121 --- 
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Correlation of Fixed Effects: (Intr) Orign2 Treat2 Origin2     -0.714
>  Treat2      -0.889  0.635 Orign2:Trt2  0.649 -0.907 -0.730
> 
> contrasts(hatch.frame$Treat) <- contr.treatment(2, base=2) 
> model2<-lmer(success~Origin*Treat+(1|Female),family=binomial,REML=TRUE,data=
>  hatch.frame) summary(model2)
> 
> Generalized linear mixed model fit by the Laplace approximation 
> Formula: success ~ Origin * Treat + (1 | Female) Data: hatch.frame 
> AIC   BIC logLik deviance 95.34 109.3 -42.67    85.34 Random effects:
>  Groups Name        Variance Std.Dev. Female (Intercept) 0.54993
> 0.74157 Number of obs: 120, groups: Female, 20
> 
> Fixed effects: Estimate Std. Error z value Pr(>|z|) (Intercept)
> -1.7925     0.5683  -3.154  0.00161 ** Origin2          1.9441
> 0.7190   2.704  0.00686 ** Treat1           5.4017     1.2389   4.360
> 1.3e-05 *** Origin2:Treat1  -1.9484     1.6979  -1.148  0.25116 --- 
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Correlation of Fixed Effects: (Intr) Orign2 Treat1 Origin2     -0.790
>  Treat1      -0.385  0.305 Orign2:Trt1  0.281 -0.336 -0.730
> 
> 
> So I'm as stumped as you are. How can the effect of Origin at 
> treat=hot be significantly different from zero, but not significantly
>  different from -0.004? Clearly there is something here I'm not 
> understanding. I'm very curious to know the answer.
> 
> Best, Ista
> 
> 
> 
> 
> 
> 
> On Tue, Feb 9, 2010 at 12:22 PM, Weber, Sam <Sam.Weber at exeter.ac.uk>
> wrote:
>> Dear all,
>> 
>> I was wondering if anyone could help solve a problem of a missing
> interaction effect!!
>> I carried out a 2 x 2 factorial experiment to see if eggs from 2
>> different
> locations (Origin =  1 or 2) had different hatching success under 2 
> different incubation schedules (Treat = 1 or 2). Six eggs were taken
> from 10 females (random = Female) at each location and split between
> the treatments, giving 30 eggs from each location in each treatment.
>> Overall proportions hatching were as follows:
>> 
>> Treat 1                     2 Origin 1                   29/30
>> 5/30 2                   29/30               16/30
>> 
>> 
>> I made a binomial response in which hatching was a success and
> not-hatching was a failure, and analysed as a binomial GLMM. I'm 
> particularly interested in the interaction between the two factors.
> An expression reproducing the raw data is attached at the end of the
> post in case it is helpful.
>> hatch.frame$success<-cbind(hatch.frame$Hatched,hatch.frame$Nothatched)
>> 
>> 
> model<-lmer(success~Origin*Treat+(1|Female),family=binomial,method="ML",data
>  =hatch.frame)
>> model2<-update(model,~.-Origin:Treat) anova(model,model2)
>> 
>> Data: Models: model2: success ~ Origin + Treat + (1 | Female) 
>> model: success ~ Origin * Treat + (1 | Female) Df     AIC     BIC
>> logLik  Chisq  Chi Df   Pr(>Chisq) model2  4  94.707 105.857
>> -43.353 model   5  95.350 109.287 -42.675 1.3572      1      0.244
>> 
>> model3<-update(model2,~.-Origin) anova(model2,model3)
>> 
>> Data: Models: model3: success ~ Treat + (1 | Female) model2:
>> success ~ Origin + Treat + (1 | Female) Df     AIC     BIC  logLik
>> Chisq Chi Df Pr(>Chisq) model3  3  98.863 107.225 -46.431 model2  4
>> 94.707 105.857 -43.353 6.1558      1    0.01310 * --- Signif.
>> codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>> 
>> model4<-update(model2,~.-Treat) anova(model2,model4)
>> 
>> Data: Models: model4: success ~ Origin + (1 | Female) model2:
>> success ~ Origin + Treat + (1 | Female) Df     AIC     BIC  logLik
>> Chisq Chi Df Pr(>Chisq) model4  3 155.592 163.954 -74.796 model2  4
>> 94.707 105.857 -43.353 62.885      1  2.191e-15 *** --- Signif.
>> codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 So the model
>> implies that there is a very significant effect of treatment
> (reduced hatching at treatment 2) with a small effect of origin
> (improved hatching from origin 2). However the lack of interaction
> effect implies hatching was better for Origin 2 at both treatments,
> which looking at the raw values above does not seem to be the case.
> Identical numbers of eggs hatched from both Origins in Treatment 1,
> but much more from Origin 2 hatched at Treatment 2.
>> If you divide the analysis by treatments, Origin only has a
>> significant
> effect on hatching under Treatment 2 and not with Treatment 1
>> Hot<-data.frame(hatch.frame[hatch.frame$Treat==2,]) 
>> Cold<-data.frame(hatch.frame[hatch.frame$Treat==1,])
>> 
>> #2
> model<-lmer(success~Origin+(1|Female),family=binomial,method="ML",data=Hot)
> 
>> model2<-update(model,~.-Origin) anova(model,model2) Data: Hot 
>> Models: model2: incubate ~ (1 | Code) model: incubate ~ Origin + (1
>> | Code) Df     AIC     BIC  logLik  Chisq Chi Df Pr(>Chisq) model2
>> 2  78.633  82.821 -37.316 model   3  73.697  79.980 -33.848 6.9357
>> 1   0.008449 **
>> 
>> #1
> model<-lmer(success~Origin+(1|Female),family=binomial,method="ML",data=Cold)
> 
>> model2<-update(model,~.-Origin) anova(model,model2)
>> 
>> Data: Cold Models: model2: incubate ~ (1 | Code) model: incubate ~
>> Origin + (1 | Code) Df     AIC     BIC  logLik  Chisq Chi Df
>> Pr(>Chisq) model2  2 21.5086 25.6973 -8.7543 model   3 23.3472
>> 29.6302 -8.6736 0.1615      1     0.6878
>> 
>> So I can't understand where the interaction effect has gone in the
>> full
> model?! I get the same result in a binomial GLM, without the random
> effect of Female i.e. a small effect of origin but no interaction
> with treatment. I'm sure I must be missing something here so I would
> be very grateful to anyone who can point out my mistakes. I've read
> previous R Help posts that suggest binomial GLM(M) can create
> problems when estimated probabilities are close to 0 or 1. In
> Treatment 1 hatching probability was 0.97 for both Origins, so could
> this be the source of the problem?
>> Thanks for your help
>> 
>> Sam Weber
>> 
> ----------------------------------------------------------------------------
> 
>> University of Exeter Centre for Ecology and Conservation Tremough
>> Campus Penryn Cornwall TR10 9EZ UK
>> 
>> 
>> 
>> hatch.frame <- structure(list(Female = structure(c(1L, 1L, 1L, 1L,
>> 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L,
>> 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 6L, 7L, 7L,
>> 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 9L, 9L,
>> 10L, 10L, 10L, 10L, 10L, 10L, 11L, 11L, 11L, 11L, 11L, 11L, 12L,
>> 12L, 12L, 12L, 12L, 12L, 13L, 13L, 13L, 13L, 13L, 13L, 14L, 14L,
>> 14L, 14L, 14L, 14L, 15L, 15L, 15L, 15L, 15L, 15L, 16L, 16L, 16L,
>> 16L, 16L, 16L, 17L, 17L, 17L, 17L, 17L, 17L, 18L, 18L, 18L, 18L,
>> 18L, 18L, 19L, 19L, 19L, 19L, 19L, 19L, 20L, 20L, 20L, 20L, 20L,
>> 20L ), .Label = c("1", "2", "3", "4", "5", "6", "7", "8", "9",
>> "10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20"),
>> class =
> "factor"),
>> Origin = structure(c(2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("1", "2"), class =
>> "factor"), Treat = structure(c(1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>> 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
>> 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>> 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
>> 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>> 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
>> 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>> 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L), .Label = c("1", "2"), class =
>> "factor"), Hatched = c(1L, 1L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 0L, 1L,
>> 0L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L,
>> 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 1L,
>> 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 1L,
>> 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L,
>> 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L,
>> 1L, 1L, 0L, 1L, 0L, 1L, 1L), Nothatched = c(0, 0, 1, 0, 0, 1, 0, 1,
>> 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
>> 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,
>> 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,
>> 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,
>> 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1,
>> 0, 0)), .Names = c("Female", "Origin", "Treat", "Hatched",
>> "Nothatched"), row.names = c(NA, -120L), class = "data.frame")
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From David.Duffy at qimr.edu.au  Mon Feb 15 05:35:23 2010
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Mon, 15 Feb 2010 14:35:23 +1000 (EST)
Subject: [R-sig-ME] [R] Missing interaction effect in binomial GLMM with
 lmer
In-Reply-To: <4B78BC63.6060904@ufl.edu>
References: <5BB78285B60F9B4DB2C6A4DA8F3E788C2B99E17D1D@EXCHMBS04.isad.isadroot.ex.ac.uk>
	<f55e7cf51002090919w40dcbe11g1da362e090d61676@mail.gmail.com>,
	<001201caa9b5$151bab30$bed41f0a@gne.windows.gene.com><5BB78285B60F9B4DB2C6A4DA8F3E788C2EB3DBA01F@EXCHMBS04.isad.isadroot.ex.ac.uk>
	<4B78BC63.6060904@ufl.edu>
Message-ID: <Pine.LNX.4.64.1002151354430.10542@orpheus.qimr.edu.au>

On Sun, 14 Feb 2010, Ben Bolker wrote:

>
>  I don't think this is necessarily a mixed model question (as you
> ...  Is it not just a reasonable conclusion
> that there is not a significant difference between (the difference
> between 29/30 and 16/30) and (the difference between 29/30 and 5/30)?
>

What he said ;)

Perhaps the OP is confused by the fact that the subgroup analysis gives a 
"signficant" association in one subgroup and not the other, but the 
difference in association strength between the two groups is not 
significant -- this is quite common.

It seems that the maternal random effect variance can be set to zero, eg

library(glmmML)
m1 <- glmmML(Hatched ~ Origin + Treat, cluster=Female, data=hatch.frame)

Scale parameter in mixing distribution:  0.6484 gaussian
Std. Error:                              0.5779

m2 <- glm(Hatched ~ Origin + Treat, family=binomial,  data=hatch.frame)
LRTS <- m1$deviance-m2$deviance

so the results of the fixed effects GLM are a reasonable thing to look at,
and as Ben Bolker pointed out reduce to testing equality of odds ratios in 
two 2x2 tables.

  t1 <- with(hatch.frame,as.data.frame(table(Origin,Treat,Hatched)))
  library(exactLoglinTest)
  mcexact(Freq ~ Origin+Treat+Hatched+Treat:Hatched+Origin:Hatched,
          data=t1)

is one approach to an exact test of the significance of the interaction 
term, I think.  When I dug up my copy of Donald and Gart's IC2x2 program, 
their exact test for interaction P=0.52.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From j.o.villar at bio.uio.no  Tue Feb 16 14:56:15 2010
From: j.o.villar at bio.uio.no (Jaime Otero Villar)
Date: Tue, 16 Feb 2010 14:56:15 +0100
Subject: [R-sig-ME] Temporal and spatial correlation at the same time?
Message-ID: <FFA50FF5-2B5B-425E-9A96-BAA91F18084E@ulrik.uio.no>

Dear all,

I'm working with a set of data that comprise long time series of  
abundance of fish in different rivers. I'm modelling this abundance  
using covariates, random intercept and slope and serial correlation at  
the river level as follows:


model.lme1<-lme(abundance~temp+runoff,
+ 							random=~temp|River,
+ 							correlation=corAR1(form=~1|River),
+ 							data=myData)


This model assumes that there is no correlation of residuals for  
different time series, and I wonder if it would be possible to handle  
temporal and spatial correlation at the same time in nlme. Or, could  
anybody give some hint on how to take into account variability among  
rivers as a function of distance between them?


Thanks in advance for helping.


Jaime.



From m03acj at math.ku.dk  Tue Feb 16 16:57:15 2010
From: m03acj at math.ku.dk (Anders Christian Jensen)
Date: Tue, 16 Feb 2010 16:57:15 +0100
Subject: [R-sig-ME] Random effects, autocorrelation and nesting in lme
Message-ID: <ec5eb98743520547f3f62cf42bf012b4.squirrel@mail.math.ku.dk>

Dear R - users

I have a problem with lme when trying to specify both "random" and
"correlation" arguments to my model.

The problem seems to be related to the nesting structure of my data:

For each person (p) I have multiple replicates (r) of a time series of
observations. Observations within a time series is indexed by t. That is,
my outcome (y) is uniquely determined by indices y_{prt}.

I would like to specify a model that includes
1)  a random slope and intercept for each person, and
2)  some sort of correlation on the time series, within each
(person,replicate); possibly an AR(1) process.

In other words, I would like to specify the following model (disregarding
the fixed effects part of the model):

y_{prt} = a_p + b_p * t + e_{prt},

where a_p and b_p are the (Gaussian) random slope and intercept on person
level, and e_{prt} should be such that

cor(e_{prt},e_{p'r't'}) = f(|t-t'|), for some function f

when p=p' and r=r', and 0 otherwise.

When I try to fit the model with lme I get an error message:

"Incompatible formulas for groups in "random" and "correlation""

A very small toy data set (without any autocorrelation) illustrates my
problem:

> Data <- data.frame(Person           = factor(rep(1:3,each=12)),
+                    Person_replicate = factor(rep(1:12,each=3)),
+                    Time             = rep(1:4,9),
+                    response         = round(5+rnorm(36),2))
> str(Data)
'data.frame':   36 obs. of  4 variables:
 $ Person          : Factor w/ 3 levels "1","2","3": 1 1 1 1 1 1 1 1 1 1 ...
 $ Person_replicate: Factor w/ 12 levels "1","2","3","4",..: 1 1 1 2 2 2 3
3 3 4 ...
 $ Time            : int  1 2 3 4 1 2 3 4 1 2 ...
 $ response        : num  5.21 4.95 3.32 4.86 6.18 5.68 5.14 3.81 6.17
5.08 ...
> head(Data)
  Person Person_replicate Time response
1      1                1    1     5.21
2      1                1    2     4.95
3      1                1    3     3.32
4      1                2    4     4.86
5      1                2    1     6.18
6      1                2    2     5.68

I then try to fit the model, and get an error:
> library(splines)
> library(nlme)
> lme(response ~ Time,
+     random = list(~Time|Person),
+     correlation=corGaus(form=~1|Person_replicate),
+     data = Data)
Error in lme.formula(response ~ Time, random = list(~Time | Person),
correlation = corGaus(form = ~1 |  :
  Incompatible formulas for groups in "random" and "correlation"

Basically I would like the "random"-argument for lme to work on person
level, but the "correlation"-argument should work on (person,replicate)
level. I found old posts on the mailing list with similar problems but
none of them include an answer.
Any help would be much appreciated! Thanks



From walmeszeviani at yahoo.com.br  Tue Feb 16 20:04:42 2010
From: walmeszeviani at yahoo.com.br (walmes zeviani)
Date: Tue, 16 Feb 2010 11:04:42 -0800 (PST)
Subject: [R-sig-ME] Res:  Random effects, autocorrelation and nesting in lme
In-Reply-To: <ec5eb98743520547f3f62cf42bf012b4.squirrel@mail.math.ku.dk>
References: <ec5eb98743520547f3f62cf42bf012b4.squirrel@mail.math.ku.dk>
Message-ID: <293066.22516.qm@web32105.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100216/1d3844ac/attachment.pl>

From bates at stat.wisc.edu  Tue Feb 16 20:47:28 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 16 Feb 2010 13:47:28 -0600
Subject: [R-sig-ME] [R] False convergence of a glmer model
In-Reply-To: <5abc11d81002160738x552f08ebo1249bf2a2c2e9445@mail.gmail.com>
References: <5abc11d81002160705n219979f3q988dffbc37a2cafd@mail.gmail.com>
	<40e66e0b1002160729nb624b5bs724bd5bd1e6b8456@mail.gmail.com>
	<5abc11d81002160738x552f08ebo1249bf2a2c2e9445@mail.gmail.com>
Message-ID: <40e66e0b1002161147i75c835b0i182a699f60a4686b@mail.gmail.com>

On Tue, Feb 16, 2010 at 9:38 AM, Shige Song <shigesong at gmail.com> wrote:
> Hi Doug,
>
> Thanks. Next time I will post it to the R-SIG0-mixed-models mailing
> list, as you suggested.

I have added R-SIG-mixed-models to the cc: list.  I suggest we drop
the cc: to R-help after this message.

> With respect to your question, the answer is no, these parameters do
> not make sense. Here is the Stata output from "exactly" the same
> model:

> . xi:xtlogit inftmort i.cohort, i(code)
> i.cohort ? ? ? ? ?_Icohort_1-3 ? ? ? ?(naturally coded; _Icohort_1 omitted)
>
> Fitting comparison model:
>
> Iteration 0: ? log likelihood = -1754.4476
> Iteration 1: ? log likelihood = -1749.3366
> Iteration 2: ? log likelihood = -1749.2491
> Iteration 3: ? log likelihood = -1749.2491
>
> Fitting full model:
>
> tau = ?0.0 ? ? log likelihood = -1749.2491
> tau = ?0.1 ? ? log likelihood = -1743.8418
> tau = ?0.2 ? ? log likelihood = -1739.0769
> tau = ?0.3 ? ? log likelihood = -1736.4914
> tau = ?0.4 ? ? log likelihood = -1739.5415
>
> Iteration 0: ? log likelihood = -1736.4914
> Iteration 1: ? log likelihood = -1722.6629
> Iteration 2: ? log likelihood = -1694.9114
> Iteration 3: ? log likelihood = -1694.6509
> Iteration 4: ? log likelihood = ?-1694.649
> Iteration 5: ? log likelihood = ?-1694.649
>
> Random-effects logistic regression ? ? ? ? ? ? ?Number of obs ? ? ?= ? ? 21694
> Group variable: code ? ? ? ? ? ? ? ? ? ? ? ? ? ?Number of groups ? = ? ? 10789
>
> Random effects u_i ~ Gaussian ? ? ? ? ? ? ? ? ? Obs per group: min = ? ? ? ? 1
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? avg = ? ? ? 2.0
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? max = ? ? ? ? 9
>
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Wald chi2(2) ? ? ? = ? ? ?8.05
> Log likelihood ?= ?-1694.649 ? ? ? ? ? ? ? ? ? ?Prob > chi2 ? ? ? ?= ? ?0.0178

Well, the quantities being displayed in the iteration output from
glmer are the deviance and the parameter values.  This stata
log-likelihood corresponds to a deviance of 3389.3.  It is possible
that glmer and stata don't measure the log-likelihood on the same
scale but, if not, then the estimates where glmer gets stalled are
producing a lower deviance of 2837.49.

The reason that glmer is getting stalled is because of the coefficient
of -7.45883 for the intercept.  This corresponds to a mean success
probability of 0.0005 for cohort 1.  The stata coefficient estimate of
-5.214642 corresponds to a mean success probability of  0.0055 for
cohort 1, which is still very, very small.  The success probabilities
for the other cohorts are going to be even smaller.  What is the
overall proportion of zeros in the response?

The optimization to determine the maximum likelihood estimates of the
coefficients is being done on the scale of the linear predictor.  When
the values of the linear predictor become very small or very large,
the fitted values become insensitive to the coefficients.  The fact
the one program converges and another one doesn't may have more to do
with the convergence criterion than with the quality of the fit.


> ------------------------------------------------------------------------------
> ? ?inftmort | ? ? ?Coef. ? Std. Err. ? ? ?z ? ?P>|z| ? ? [95% Conf. Interval]
> -------------+----------------------------------------------------------------
> ?_Icohort_2 | ?-.5246846 ? .1850328 ? ?-2.84 ? 0.005 ? ?-.8873422 ? -.1620269
> ?_Icohort_3 | ?-.1424331 ? ?.140369 ? ?-1.01 ? 0.310 ? ?-.4175513 ? ? .132685
> ? ? ? _cons | ?-5.214642 ? .1839703 ? -28.35 ? 0.000 ? ?-5.575217 ? -4.854067
> -------------+----------------------------------------------------------------
> ? ?/lnsig2u | ? .9232684 ? .1416214 ? ? ? ? ? ? ? ? ? ? ?.6456956 ? ?1.200841
> -------------+----------------------------------------------------------------
> ? ? sigma_u | ? 1.586665 ? .1123528 ? ? ? ? ? ? ? ? ? ? ?1.381055 ? ?1.822885
> ? ? ? ? rho | ? .4335015 ? .0347791 ? ? ? ? ? ? ? ? ? ? ?.3669899 ? ?.5024984
> ------------------------------------------------------------------------------
> Likelihood-ratio test of rho=0: chibar2(01) = ? 109.20 Prob >= chibar2 = 0.000
>
> The difference is quite huge, and Stata did not have any difficulties
> estimating this model, which makes feel that I might get some very
> basic specification wrong in my R model...
>
> Best,
> Shige
>
> On Tue, Feb 16, 2010 at 10:29 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
>> On Tue, Feb 16, 2010 at 9:05 AM, Shige Song <shigesong at gmail.com> wrote:
>>> Dear All,
>>
>>> I am trying to fit a 2-level random intercept logistic regression on a
>>> data set of 20,000 cases. ?The model is specified as the following:
>>
>>> ?m1 <- glmer(inftmort ~ as.factor(cohort) + (1|code), family=binomial, data=d)
>>
>>> I got "Warning message: In mer_finalize(ans) : false convergence (8)"
>>
>> That message means that the optimizer function, nlminb, got stalled.
>> It has converged but the point at which is has converged is not
>> clearly the optimum. ?In many cases this just indicates that the
>> optimizer is being overly cautious. ?However, it can also mean that
>> the problem is ill-defined.
>>
>> The fact the the second parameter is -7.46 is likely the problem. ?A
>> difference in the probability of infant mortality between levels of
>> cohort on the order of -7.5 on the logit scale is huge. ? Do the
>> estimated probabilities at this value of the parameters make sense?
>>
>> P.S. Questions of this sort may be more readily answered in the
>> R-SIG-mixed-models mailing list.
>>
>>> With the "verbose=TRUE" option, I was able to get the following
>>> iteration history:
>>>
>>> ?0: ? ? 3456.4146: ?1.15161 -3.99068 -0.498790 -0.122116
>>> ?1: ? ? 3361.3370: ?1.04044 -4.38172 -0.561756 -0.289991
>>> ?2: ? ? 3303.7986: ?1.48296 -4.40741 -0.566208 -0.259730
>>> ?3: ? ? 3147.5537: ?1.93037 -5.14388 -0.682530 -0.443006
>>> ?4: ? ? 3123.6900: ?2.10192 -5.18784 -0.685558 -0.428320
>>> ?5: ? ? 2988.6287: ?2.94890 -6.31023 -0.825286 -0.586282
>>> ?6: ? ? 2958.3364: ?3.25396 -6.88256 -0.316988 0.572428
>>> ?7: ? ? 2853.7703: ?4.22731 -7.44955 -0.279492 -0.294353
>>> ?8: ? ? 2844.8476: ?4.36583 -7.43902 -0.293111 -0.267308
>>> ?9: ? ? 2843.2879: ?4.39182 -7.44895 -0.298791 -0.265899
>>> ?10: ? ? 2840.2676: ?4.44288 -7.47103 -0.310477 -0.263945
>>> ?11: ? ? 2839.0890: ?4.46259 -7.48131 -0.315320 -0.263753
>>> ?12: ? ? 2838.8550: ?4.46649 -7.48344 -0.316292 -0.263745
>>> ?13: ? ? 2838.3889: ?4.47428 -7.48771 -0.318236 -0.263737
>>> ?14: ? ? 2838.3703: ?4.47459 -7.48788 -0.318314 -0.263738
>>> ?15: ? ? 2838.2216: ?4.47708 -7.48927 -0.318936 -0.263742
>>> ?16: ? ? 2838.2157: ?4.47718 -7.48932 -0.318961 -0.263742
>>> ?17: ? ? 2838.2145: ?4.47720 -7.48934 -0.318966 -0.263742
>>> ?18: ? ? 2838.2121: ?4.47724 -7.48936 -0.318976 -0.263742
>>> ?19: ? ? 2838.2120: ?4.47724 -7.48936 -0.318976 -0.263742
>>> ?20: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>> ?21: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>> ?22: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>> ?23: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>> ?24: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>> ?25: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>> ?26: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>> ?27: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>> ?28: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>> ?29: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>> ?30: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>> ?31: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>> ?32: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>> ?33: ? ? 2837.8154: ?4.46385 -7.47464 -0.495684 -0.263985
>>> ?34: ? ? 2837.7613: ?4.46641 -7.47053 -0.498335 -0.264014
>>> ?35: ? ? 2837.6418: ?4.47259 -7.46200 -0.501644 -0.264141
>>> ?36: ? ? 2837.5982: ?4.47485 -7.45928 -0.502598 -0.264214
>>> ?37: ? ? 2837.5850: ?4.47537 -7.45882 -0.502848 -0.264237
>>> ?38: ? ? 2837.5307: ?4.47674 -7.45848 -0.503216 -0.264313
>>> ?39: ? ? 2837.5014: ?4.47725 -7.45875 -0.503273 -0.264344
>>> ?40: ? ? 2837.4955: ?4.47735 -7.45881 -0.503284 -0.264350
>>> ?41: ? ? 2837.4944: ?4.47738 -7.45882 -0.503286 -0.264351
>>> ?42: ? ? 2837.4941: ?4.47738 -7.45882 -0.503287 -0.264351
>>> ?43: ? ? 2837.4936: ?4.47739 -7.45883 -0.503288 -0.264352
>>> ?44: ? ? 2837.4935: ?4.47739 -7.45883 -0.503288 -0.264352
>>> ?45: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>> ?46: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>> ?47: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>> ?48: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>> ?49: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>> ?50: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>> ?51: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>> ?52: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>> ?53: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>> ?54: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>> ?55: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>> ?56: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>> ?57: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>> ?58: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>> ?59: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>> ?60: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>> ?61: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>> ?62: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>> ?63: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>
>>> By the way, the same model can be fitted using Stata using xtlogit and
>>> xtmelogit; a simpler model without the random component can be
>>> estimated using R as:
>>>
>>> m <- glm(inftmort ~ as.factor(cohort), family=binomial, data=d)
>>>
>>> I was also able to get highly consistent results via MCMC simulation
>>> using MCMCglmm.
>>>
>>> It will be greatly appreciated if someone can give me some hints where
>>> to look further. Thanks.
>>>
>>> Best,
>>> Shige
>>>
>>> BTW, sorry about the earlier post, which was caused by a mistake.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>



From shigesong at gmail.com  Tue Feb 16 21:23:08 2010
From: shigesong at gmail.com (Shige Song)
Date: Tue, 16 Feb 2010 15:23:08 -0500
Subject: [R-sig-ME] [R] False convergence of a glmer model
In-Reply-To: <40e66e0b1002161147i75c835b0i182a699f60a4686b@mail.gmail.com>
References: <5abc11d81002160705n219979f3q988dffbc37a2cafd@mail.gmail.com>
	<40e66e0b1002160729nb624b5bs724bd5bd1e6b8456@mail.gmail.com>
	<5abc11d81002160738x552f08ebo1249bf2a2c2e9445@mail.gmail.com>
	<40e66e0b1002161147i75c835b0i182a699f60a4686b@mail.gmail.com>
Message-ID: <5abc11d81002161223r2b9e2303y81248b1d7112ca5d@mail.gmail.com>

Dear Doug,

Your argument makes a lot sense: after all, infant mortality is a rare
event! I have two questions:

1) Is there a way to change the convergence criterion in a glmer model
(to make it more tolerant)?
2) Do you see a better approach than mixed logistic regression model
in estimating infant morality, given the fact that infant mortality is
a rare event?

Many thanks.

Best,
Shige

On Tue, Feb 16, 2010 at 2:47 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
> On Tue, Feb 16, 2010 at 9:38 AM, Shige Song <shigesong at gmail.com> wrote:
>> Hi Doug,
>>
>> Thanks. Next time I will post it to the R-SIG0-mixed-models mailing
>> list, as you suggested.
>
> I have added R-SIG-mixed-models to the cc: list. ?I suggest we drop
> the cc: to R-help after this message.
>
>> With respect to your question, the answer is no, these parameters do
>> not make sense. Here is the Stata output from "exactly" the same
>> model:
>
>> . xi:xtlogit inftmort i.cohort, i(code)
>> i.cohort ? ? ? ? ?_Icohort_1-3 ? ? ? ?(naturally coded; _Icohort_1 omitted)
>>
>> Fitting comparison model:
>>
>> Iteration 0: ? log likelihood = -1754.4476
>> Iteration 1: ? log likelihood = -1749.3366
>> Iteration 2: ? log likelihood = -1749.2491
>> Iteration 3: ? log likelihood = -1749.2491
>>
>> Fitting full model:
>>
>> tau = ?0.0 ? ? log likelihood = -1749.2491
>> tau = ?0.1 ? ? log likelihood = -1743.8418
>> tau = ?0.2 ? ? log likelihood = -1739.0769
>> tau = ?0.3 ? ? log likelihood = -1736.4914
>> tau = ?0.4 ? ? log likelihood = -1739.5415
>>
>> Iteration 0: ? log likelihood = -1736.4914
>> Iteration 1: ? log likelihood = -1722.6629
>> Iteration 2: ? log likelihood = -1694.9114
>> Iteration 3: ? log likelihood = -1694.6509
>> Iteration 4: ? log likelihood = ?-1694.649
>> Iteration 5: ? log likelihood = ?-1694.649
>>
>> Random-effects logistic regression ? ? ? ? ? ? ?Number of obs ? ? ?= ? ? 21694
>> Group variable: code ? ? ? ? ? ? ? ? ? ? ? ? ? ?Number of groups ? = ? ? 10789
>>
>> Random effects u_i ~ Gaussian ? ? ? ? ? ? ? ? ? Obs per group: min = ? ? ? ? 1
>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? avg = ? ? ? 2.0
>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? max = ? ? ? ? 9
>>
>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Wald chi2(2) ? ? ? = ? ? ?8.05
>> Log likelihood ?= ?-1694.649 ? ? ? ? ? ? ? ? ? ?Prob > chi2 ? ? ? ?= ? ?0.0178
>
> Well, the quantities being displayed in the iteration output from
> glmer are the deviance and the parameter values. ?This stata
> log-likelihood corresponds to a deviance of 3389.3. ?It is possible
> that glmer and stata don't measure the log-likelihood on the same
> scale but, if not, then the estimates where glmer gets stalled are
> producing a lower deviance of 2837.49.
>
> The reason that glmer is getting stalled is because of the coefficient
> of -7.45883 for the intercept. ?This corresponds to a mean success
> probability of 0.0005 for cohort 1. ?The stata coefficient estimate of
> -5.214642 corresponds to a mean success probability of ?0.0055 for
> cohort 1, which is still very, very small. ?The success probabilities
> for the other cohorts are going to be even smaller. ?What is the
> overall proportion of zeros in the response?
>
> The optimization to determine the maximum likelihood estimates of the
> coefficients is being done on the scale of the linear predictor. ?When
> the values of the linear predictor become very small or very large,
> the fitted values become insensitive to the coefficients. ?The fact
> the one program converges and another one doesn't may have more to do
> with the convergence criterion than with the quality of the fit.
>
>
>> ------------------------------------------------------------------------------
>> ? ?inftmort | ? ? ?Coef. ? Std. Err. ? ? ?z ? ?P>|z| ? ? [95% Conf. Interval]
>> -------------+----------------------------------------------------------------
>> ?_Icohort_2 | ?-.5246846 ? .1850328 ? ?-2.84 ? 0.005 ? ?-.8873422 ? -.1620269
>> ?_Icohort_3 | ?-.1424331 ? ?.140369 ? ?-1.01 ? 0.310 ? ?-.4175513 ? ? .132685
>> ? ? ? _cons | ?-5.214642 ? .1839703 ? -28.35 ? 0.000 ? ?-5.575217 ? -4.854067
>> -------------+----------------------------------------------------------------
>> ? ?/lnsig2u | ? .9232684 ? .1416214 ? ? ? ? ? ? ? ? ? ? ?.6456956 ? ?1.200841
>> -------------+----------------------------------------------------------------
>> ? ? sigma_u | ? 1.586665 ? .1123528 ? ? ? ? ? ? ? ? ? ? ?1.381055 ? ?1.822885
>> ? ? ? ? rho | ? .4335015 ? .0347791 ? ? ? ? ? ? ? ? ? ? ?.3669899 ? ?.5024984
>> ------------------------------------------------------------------------------
>> Likelihood-ratio test of rho=0: chibar2(01) = ? 109.20 Prob >= chibar2 = 0.000
>>
>> The difference is quite huge, and Stata did not have any difficulties
>> estimating this model, which makes feel that I might get some very
>> basic specification wrong in my R model...
>>
>> Best,
>> Shige
>>
>> On Tue, Feb 16, 2010 at 10:29 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
>>> On Tue, Feb 16, 2010 at 9:05 AM, Shige Song <shigesong at gmail.com> wrote:
>>>> Dear All,
>>>
>>>> I am trying to fit a 2-level random intercept logistic regression on a
>>>> data set of 20,000 cases. ?The model is specified as the following:
>>>
>>>> ?m1 <- glmer(inftmort ~ as.factor(cohort) + (1|code), family=binomial, data=d)
>>>
>>>> I got "Warning message: In mer_finalize(ans) : false convergence (8)"
>>>
>>> That message means that the optimizer function, nlminb, got stalled.
>>> It has converged but the point at which is has converged is not
>>> clearly the optimum. ?In many cases this just indicates that the
>>> optimizer is being overly cautious. ?However, it can also mean that
>>> the problem is ill-defined.
>>>
>>> The fact the the second parameter is -7.46 is likely the problem. ?A
>>> difference in the probability of infant mortality between levels of
>>> cohort on the order of -7.5 on the logit scale is huge. ? Do the
>>> estimated probabilities at this value of the parameters make sense?
>>>
>>> P.S. Questions of this sort may be more readily answered in the
>>> R-SIG-mixed-models mailing list.
>>>
>>>> With the "verbose=TRUE" option, I was able to get the following
>>>> iteration history:
>>>>
>>>> ?0: ? ? 3456.4146: ?1.15161 -3.99068 -0.498790 -0.122116
>>>> ?1: ? ? 3361.3370: ?1.04044 -4.38172 -0.561756 -0.289991
>>>> ?2: ? ? 3303.7986: ?1.48296 -4.40741 -0.566208 -0.259730
>>>> ?3: ? ? 3147.5537: ?1.93037 -5.14388 -0.682530 -0.443006
>>>> ?4: ? ? 3123.6900: ?2.10192 -5.18784 -0.685558 -0.428320
>>>> ?5: ? ? 2988.6287: ?2.94890 -6.31023 -0.825286 -0.586282
>>>> ?6: ? ? 2958.3364: ?3.25396 -6.88256 -0.316988 0.572428
>>>> ?7: ? ? 2853.7703: ?4.22731 -7.44955 -0.279492 -0.294353
>>>> ?8: ? ? 2844.8476: ?4.36583 -7.43902 -0.293111 -0.267308
>>>> ?9: ? ? 2843.2879: ?4.39182 -7.44895 -0.298791 -0.265899
>>>> ?10: ? ? 2840.2676: ?4.44288 -7.47103 -0.310477 -0.263945
>>>> ?11: ? ? 2839.0890: ?4.46259 -7.48131 -0.315320 -0.263753
>>>> ?12: ? ? 2838.8550: ?4.46649 -7.48344 -0.316292 -0.263745
>>>> ?13: ? ? 2838.3889: ?4.47428 -7.48771 -0.318236 -0.263737
>>>> ?14: ? ? 2838.3703: ?4.47459 -7.48788 -0.318314 -0.263738
>>>> ?15: ? ? 2838.2216: ?4.47708 -7.48927 -0.318936 -0.263742
>>>> ?16: ? ? 2838.2157: ?4.47718 -7.48932 -0.318961 -0.263742
>>>> ?17: ? ? 2838.2145: ?4.47720 -7.48934 -0.318966 -0.263742
>>>> ?18: ? ? 2838.2121: ?4.47724 -7.48936 -0.318976 -0.263742
>>>> ?19: ? ? 2838.2120: ?4.47724 -7.48936 -0.318976 -0.263742
>>>> ?20: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>> ?21: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>> ?22: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>> ?23: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>> ?24: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>> ?25: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>> ?26: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>> ?27: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>> ?28: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>> ?29: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>> ?30: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>> ?31: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>> ?32: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>> ?33: ? ? 2837.8154: ?4.46385 -7.47464 -0.495684 -0.263985
>>>> ?34: ? ? 2837.7613: ?4.46641 -7.47053 -0.498335 -0.264014
>>>> ?35: ? ? 2837.6418: ?4.47259 -7.46200 -0.501644 -0.264141
>>>> ?36: ? ? 2837.5982: ?4.47485 -7.45928 -0.502598 -0.264214
>>>> ?37: ? ? 2837.5850: ?4.47537 -7.45882 -0.502848 -0.264237
>>>> ?38: ? ? 2837.5307: ?4.47674 -7.45848 -0.503216 -0.264313
>>>> ?39: ? ? 2837.5014: ?4.47725 -7.45875 -0.503273 -0.264344
>>>> ?40: ? ? 2837.4955: ?4.47735 -7.45881 -0.503284 -0.264350
>>>> ?41: ? ? 2837.4944: ?4.47738 -7.45882 -0.503286 -0.264351
>>>> ?42: ? ? 2837.4941: ?4.47738 -7.45882 -0.503287 -0.264351
>>>> ?43: ? ? 2837.4936: ?4.47739 -7.45883 -0.503288 -0.264352
>>>> ?44: ? ? 2837.4935: ?4.47739 -7.45883 -0.503288 -0.264352
>>>> ?45: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>> ?46: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>> ?47: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>> ?48: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>> ?49: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>> ?50: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>> ?51: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>> ?52: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>> ?53: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>> ?54: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>> ?55: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>> ?56: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>> ?57: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>> ?58: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>> ?59: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>> ?60: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>> ?61: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>> ?62: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>> ?63: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>
>>>> By the way, the same model can be fitted using Stata using xtlogit and
>>>> xtmelogit; a simpler model without the random component can be
>>>> estimated using R as:
>>>>
>>>> m <- glm(inftmort ~ as.factor(cohort), family=binomial, data=d)
>>>>
>>>> I was also able to get highly consistent results via MCMC simulation
>>>> using MCMCglmm.
>>>>
>>>> It will be greatly appreciated if someone can give me some hints where
>>>> to look further. Thanks.
>>>>
>>>> Best,
>>>> Shige
>>>>
>>>> BTW, sorry about the earlier post, which was caused by a mistake.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>
>



From bates at stat.wisc.edu  Tue Feb 16 21:32:04 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 16 Feb 2010 14:32:04 -0600
Subject: [R-sig-ME] [R] False convergence of a glmer model
In-Reply-To: <5abc11d81002161223r2b9e2303y81248b1d7112ca5d@mail.gmail.com>
References: <5abc11d81002160705n219979f3q988dffbc37a2cafd@mail.gmail.com>
	<40e66e0b1002160729nb624b5bs724bd5bd1e6b8456@mail.gmail.com>
	<5abc11d81002160738x552f08ebo1249bf2a2c2e9445@mail.gmail.com>
	<40e66e0b1002161147i75c835b0i182a699f60a4686b@mail.gmail.com>
	<5abc11d81002161223r2b9e2303y81248b1d7112ca5d@mail.gmail.com>
Message-ID: <40e66e0b1002161232k542cf242yc13da515a64a82e6@mail.gmail.com>

On Tue, Feb 16, 2010 at 2:23 PM, Shige Song <shigesong at gmail.com> wrote:
> Dear Doug,
>
> Your argument makes a lot sense: after all, infant mortality is a rare
> event! I have two questions:
>
> 1) Is there a way to change the convergence criterion in a glmer model
> (to make it more tolerant)?

I'm not sure that is a good idea.  If the linear predictor produces
probabilities that are so small that the deviance is insensitive to
the parameter values, what would it mean to quote estimates of those
parameters?

> 2) Do you see a better approach than mixed logistic regression model
> in estimating infant morality, given the fact that infant mortality is
> a rare event?

I don't know of other approaches myself.  Others on the list (Ben?)
may have suggestions.

> On Tue, Feb 16, 2010 at 2:47 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
>> On Tue, Feb 16, 2010 at 9:38 AM, Shige Song <shigesong at gmail.com> wrote:
>>> Hi Doug,
>>>
>>> Thanks. Next time I will post it to the R-SIG0-mixed-models mailing
>>> list, as you suggested.
>>
>> I have added R-SIG-mixed-models to the cc: list. ?I suggest we drop
>> the cc: to R-help after this message.
>>
>>> With respect to your question, the answer is no, these parameters do
>>> not make sense. Here is the Stata output from "exactly" the same
>>> model:
>>
>>> . xi:xtlogit inftmort i.cohort, i(code)
>>> i.cohort ? ? ? ? ?_Icohort_1-3 ? ? ? ?(naturally coded; _Icohort_1 omitted)
>>>
>>> Fitting comparison model:
>>>
>>> Iteration 0: ? log likelihood = -1754.4476
>>> Iteration 1: ? log likelihood = -1749.3366
>>> Iteration 2: ? log likelihood = -1749.2491
>>> Iteration 3: ? log likelihood = -1749.2491
>>>
>>> Fitting full model:
>>>
>>> tau = ?0.0 ? ? log likelihood = -1749.2491
>>> tau = ?0.1 ? ? log likelihood = -1743.8418
>>> tau = ?0.2 ? ? log likelihood = -1739.0769
>>> tau = ?0.3 ? ? log likelihood = -1736.4914
>>> tau = ?0.4 ? ? log likelihood = -1739.5415
>>>
>>> Iteration 0: ? log likelihood = -1736.4914
>>> Iteration 1: ? log likelihood = -1722.6629
>>> Iteration 2: ? log likelihood = -1694.9114
>>> Iteration 3: ? log likelihood = -1694.6509
>>> Iteration 4: ? log likelihood = ?-1694.649
>>> Iteration 5: ? log likelihood = ?-1694.649
>>>
>>> Random-effects logistic regression ? ? ? ? ? ? ?Number of obs ? ? ?= ? ? 21694
>>> Group variable: code ? ? ? ? ? ? ? ? ? ? ? ? ? ?Number of groups ? = ? ? 10789
>>>
>>> Random effects u_i ~ Gaussian ? ? ? ? ? ? ? ? ? Obs per group: min = ? ? ? ? 1
>>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? avg = ? ? ? 2.0
>>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? max = ? ? ? ? 9
>>>
>>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Wald chi2(2) ? ? ? = ? ? ?8.05
>>> Log likelihood ?= ?-1694.649 ? ? ? ? ? ? ? ? ? ?Prob > chi2 ? ? ? ?= ? ?0.0178
>>
>> Well, the quantities being displayed in the iteration output from
>> glmer are the deviance and the parameter values. ?This stata
>> log-likelihood corresponds to a deviance of 3389.3. ?It is possible
>> that glmer and stata don't measure the log-likelihood on the same
>> scale but, if not, then the estimates where glmer gets stalled are
>> producing a lower deviance of 2837.49.
>>
>> The reason that glmer is getting stalled is because of the coefficient
>> of -7.45883 for the intercept. ?This corresponds to a mean success
>> probability of 0.0005 for cohort 1. ?The stata coefficient estimate of
>> -5.214642 corresponds to a mean success probability of ?0.0055 for
>> cohort 1, which is still very, very small. ?The success probabilities
>> for the other cohorts are going to be even smaller. ?What is the
>> overall proportion of zeros in the response?
>>
>> The optimization to determine the maximum likelihood estimates of the
>> coefficients is being done on the scale of the linear predictor. ?When
>> the values of the linear predictor become very small or very large,
>> the fitted values become insensitive to the coefficients. ?The fact
>> the one program converges and another one doesn't may have more to do
>> with the convergence criterion than with the quality of the fit.
>>
>>
>>> ------------------------------------------------------------------------------
>>> ? ?inftmort | ? ? ?Coef. ? Std. Err. ? ? ?z ? ?P>|z| ? ? [95% Conf. Interval]
>>> -------------+----------------------------------------------------------------
>>> ?_Icohort_2 | ?-.5246846 ? .1850328 ? ?-2.84 ? 0.005 ? ?-.8873422 ? -.1620269
>>> ?_Icohort_3 | ?-.1424331 ? ?.140369 ? ?-1.01 ? 0.310 ? ?-.4175513 ? ? .132685
>>> ? ? ? _cons | ?-5.214642 ? .1839703 ? -28.35 ? 0.000 ? ?-5.575217 ? -4.854067
>>> -------------+----------------------------------------------------------------
>>> ? ?/lnsig2u | ? .9232684 ? .1416214 ? ? ? ? ? ? ? ? ? ? ?.6456956 ? ?1.200841
>>> -------------+----------------------------------------------------------------
>>> ? ? sigma_u | ? 1.586665 ? .1123528 ? ? ? ? ? ? ? ? ? ? ?1.381055 ? ?1.822885
>>> ? ? ? ? rho | ? .4335015 ? .0347791 ? ? ? ? ? ? ? ? ? ? ?.3669899 ? ?.5024984
>>> ------------------------------------------------------------------------------
>>> Likelihood-ratio test of rho=0: chibar2(01) = ? 109.20 Prob >= chibar2 = 0.000
>>>
>>> The difference is quite huge, and Stata did not have any difficulties
>>> estimating this model, which makes feel that I might get some very
>>> basic specification wrong in my R model...
>>>
>>> Best,
>>> Shige
>>>
>>> On Tue, Feb 16, 2010 at 10:29 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
>>>> On Tue, Feb 16, 2010 at 9:05 AM, Shige Song <shigesong at gmail.com> wrote:
>>>>> Dear All,
>>>>
>>>>> I am trying to fit a 2-level random intercept logistic regression on a
>>>>> data set of 20,000 cases. ?The model is specified as the following:
>>>>
>>>>> ?m1 <- glmer(inftmort ~ as.factor(cohort) + (1|code), family=binomial, data=d)
>>>>
>>>>> I got "Warning message: In mer_finalize(ans) : false convergence (8)"
>>>>
>>>> That message means that the optimizer function, nlminb, got stalled.
>>>> It has converged but the point at which is has converged is not
>>>> clearly the optimum. ?In many cases this just indicates that the
>>>> optimizer is being overly cautious. ?However, it can also mean that
>>>> the problem is ill-defined.
>>>>
>>>> The fact the the second parameter is -7.46 is likely the problem. ?A
>>>> difference in the probability of infant mortality between levels of
>>>> cohort on the order of -7.5 on the logit scale is huge. ? Do the
>>>> estimated probabilities at this value of the parameters make sense?
>>>>
>>>> P.S. Questions of this sort may be more readily answered in the
>>>> R-SIG-mixed-models mailing list.
>>>>
>>>>> With the "verbose=TRUE" option, I was able to get the following
>>>>> iteration history:
>>>>>
>>>>> ?0: ? ? 3456.4146: ?1.15161 -3.99068 -0.498790 -0.122116
>>>>> ?1: ? ? 3361.3370: ?1.04044 -4.38172 -0.561756 -0.289991
>>>>> ?2: ? ? 3303.7986: ?1.48296 -4.40741 -0.566208 -0.259730
>>>>> ?3: ? ? 3147.5537: ?1.93037 -5.14388 -0.682530 -0.443006
>>>>> ?4: ? ? 3123.6900: ?2.10192 -5.18784 -0.685558 -0.428320
>>>>> ?5: ? ? 2988.6287: ?2.94890 -6.31023 -0.825286 -0.586282
>>>>> ?6: ? ? 2958.3364: ?3.25396 -6.88256 -0.316988 0.572428
>>>>> ?7: ? ? 2853.7703: ?4.22731 -7.44955 -0.279492 -0.294353
>>>>> ?8: ? ? 2844.8476: ?4.36583 -7.43902 -0.293111 -0.267308
>>>>> ?9: ? ? 2843.2879: ?4.39182 -7.44895 -0.298791 -0.265899
>>>>> ?10: ? ? 2840.2676: ?4.44288 -7.47103 -0.310477 -0.263945
>>>>> ?11: ? ? 2839.0890: ?4.46259 -7.48131 -0.315320 -0.263753
>>>>> ?12: ? ? 2838.8550: ?4.46649 -7.48344 -0.316292 -0.263745
>>>>> ?13: ? ? 2838.3889: ?4.47428 -7.48771 -0.318236 -0.263737
>>>>> ?14: ? ? 2838.3703: ?4.47459 -7.48788 -0.318314 -0.263738
>>>>> ?15: ? ? 2838.2216: ?4.47708 -7.48927 -0.318936 -0.263742
>>>>> ?16: ? ? 2838.2157: ?4.47718 -7.48932 -0.318961 -0.263742
>>>>> ?17: ? ? 2838.2145: ?4.47720 -7.48934 -0.318966 -0.263742
>>>>> ?18: ? ? 2838.2121: ?4.47724 -7.48936 -0.318976 -0.263742
>>>>> ?19: ? ? 2838.2120: ?4.47724 -7.48936 -0.318976 -0.263742
>>>>> ?20: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>>> ?21: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>>> ?22: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>>> ?23: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>>> ?24: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>>> ?25: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>>> ?26: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>>> ?27: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>>> ?28: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>>> ?29: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>>> ?30: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>>> ?31: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>>> ?32: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>>> ?33: ? ? 2837.8154: ?4.46385 -7.47464 -0.495684 -0.263985
>>>>> ?34: ? ? 2837.7613: ?4.46641 -7.47053 -0.498335 -0.264014
>>>>> ?35: ? ? 2837.6418: ?4.47259 -7.46200 -0.501644 -0.264141
>>>>> ?36: ? ? 2837.5982: ?4.47485 -7.45928 -0.502598 -0.264214
>>>>> ?37: ? ? 2837.5850: ?4.47537 -7.45882 -0.502848 -0.264237
>>>>> ?38: ? ? 2837.5307: ?4.47674 -7.45848 -0.503216 -0.264313
>>>>> ?39: ? ? 2837.5014: ?4.47725 -7.45875 -0.503273 -0.264344
>>>>> ?40: ? ? 2837.4955: ?4.47735 -7.45881 -0.503284 -0.264350
>>>>> ?41: ? ? 2837.4944: ?4.47738 -7.45882 -0.503286 -0.264351
>>>>> ?42: ? ? 2837.4941: ?4.47738 -7.45882 -0.503287 -0.264351
>>>>> ?43: ? ? 2837.4936: ?4.47739 -7.45883 -0.503288 -0.264352
>>>>> ?44: ? ? 2837.4935: ?4.47739 -7.45883 -0.503288 -0.264352
>>>>> ?45: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>> ?46: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>> ?47: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>> ?48: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>> ?49: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>> ?50: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>> ?51: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>> ?52: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>> ?53: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>> ?54: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>> ?55: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>> ?56: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>> ?57: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>> ?58: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>> ?59: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>> ?60: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>> ?61: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>> ?62: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>> ?63: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>>
>>>>> By the way, the same model can be fitted using Stata using xtlogit and
>>>>> xtmelogit; a simpler model without the random component can be
>>>>> estimated using R as:
>>>>>
>>>>> m <- glm(inftmort ~ as.factor(cohort), family=binomial, data=d)
>>>>>
>>>>> I was also able to get highly consistent results via MCMC simulation
>>>>> using MCMCglmm.
>>>>>
>>>>> It will be greatly appreciated if someone can give me some hints where
>>>>> to look further. Thanks.
>>>>>
>>>>> Best,
>>>>> Shige
>>>>>
>>>>> BTW, sorry about the earlier post, which was caused by a mistake.
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>
>>
>



From lborger at uoguelph.ca  Tue Feb 16 22:32:41 2010
From: lborger at uoguelph.ca (Luca Borger)
Date: Tue, 16 Feb 2010 16:32:41 -0500 (EST)
Subject: [R-sig-ME] [R] False convergence of a glmer model
In-Reply-To: <1434683562.395581266355846191.JavaMail.root@huron.cs.uoguelph.ca>
Message-ID: <490376807.396931266355961138.JavaMail.root@huron.cs.uoguelph.ca>

Hello,

> 2) Do you see a better approach than mixed logistic regression model
> in estimating infant morality, given the fact that infant mortality is
> a rare event?

For count data with lots of zeroes in a glm setting hurdle models, which are two-component models with a truncated count component for positive counts and a hurdle component that models the zero counts, seem to be a good solution. Specifically, a binomial logit can be used to model the occurrence of positive counts and a negative binomial or truncated Poisson for the positive counts, where the latter is only employed if the hurdle for modeling the occurence of zeros is exceeded. Hurdle models are implemented in the plsc package by Achim Zeileis:

http://rss.acs.unt.edu/Rdoc/library/pscl/html/hurdle.html
http://epub.wu.ac.at/dyn/virlib/wp/showentry?ID=epub-wu-01_bca


Could a similar approach be extended to a glmm setting and employed for data as the infant mortality data? Apologies if this is just a dumb idea or based on some major misunderstanding from my part.



Cheers,

Luca







----- Original Message -----
From: "Douglas Bates" <bates at stat.wisc.edu>
To: "Shige Song" <shigesong at gmail.com>
Cc: "R-mixed models mailing list" <r-sig-mixed-models at r-project.org>
Sent: Tuesday, 16 February, 2010 15:32:04 GMT -05:00 US/Canada Eastern
Subject: Re: [R-sig-ME] [R] False convergence of a glmer model

On Tue, Feb 16, 2010 at 2:23 PM, Shige Song <shigesong at gmail.com> wrote:
> Dear Doug,
>
> Your argument makes a lot sense: after all, infant mortality is a rare
> event! I have two questions:
>
> 1) Is there a way to change the convergence criterion in a glmer model
> (to make it more tolerant)?

I'm not sure that is a good idea.  If the linear predictor produces
probabilities that are so small that the deviance is insensitive to
the parameter values, what would it mean to quote estimates of those
parameters?

> 2) Do you see a better approach than mixed logistic regression model
> in estimating infant morality, given the fact that infant mortality is
> a rare event?

I don't know of other approaches myself.  Others on the list (Ben?)
may have suggestions.

> On Tue, Feb 16, 2010 at 2:47 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
>> On Tue, Feb 16, 2010 at 9:38 AM, Shige Song <shigesong at gmail.com> wrote:
>>> Hi Doug,
>>>
>>> Thanks. Next time I will post it to the R-SIG0-mixed-models mailing
>>> list, as you suggested.
>>
>> I have added R-SIG-mixed-models to the cc: list. ?I suggest we drop
>> the cc: to R-help after this message.
>>
>>> With respect to your question, the answer is no, these parameters do
>>> not make sense. Here is the Stata output from "exactly" the same
>>> model:
>>
>>> . xi:xtlogit inftmort i.cohort, i(code)
>>> i.cohort ? ? ? ? ?_Icohort_1-3 ? ? ? ?(naturally coded; _Icohort_1 omitted)
>>>
>>> Fitting comparison model:
>>>
>>> Iteration 0: ? log likelihood = -1754.4476
>>> Iteration 1: ? log likelihood = -1749.3366
>>> Iteration 2: ? log likelihood = -1749.2491
>>> Iteration 3: ? log likelihood = -1749.2491
>>>
>>> Fitting full model:
>>>
>>> tau = ?0.0 ? ? log likelihood = -1749.2491
>>> tau = ?0.1 ? ? log likelihood = -1743.8418
>>> tau = ?0.2 ? ? log likelihood = -1739.0769
>>> tau = ?0.3 ? ? log likelihood = -1736.4914
>>> tau = ?0.4 ? ? log likelihood = -1739.5415
>>>
>>> Iteration 0: ? log likelihood = -1736.4914
>>> Iteration 1: ? log likelihood = -1722.6629
>>> Iteration 2: ? log likelihood = -1694.9114
>>> Iteration 3: ? log likelihood = -1694.6509
>>> Iteration 4: ? log likelihood = ?-1694.649
>>> Iteration 5: ? log likelihood = ?-1694.649
>>>
>>> Random-effects logistic regression ? ? ? ? ? ? ?Number of obs ? ? ?= ? ? 21694
>>> Group variable: code ? ? ? ? ? ? ? ? ? ? ? ? ? ?Number of groups ? = ? ? 10789
>>>
>>> Random effects u_i ~ Gaussian ? ? ? ? ? ? ? ? ? Obs per group: min = ? ? ? ? 1
>>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? avg = ? ? ? 2.0
>>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? max = ? ? ? ? 9
>>>
>>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Wald chi2(2) ? ? ? = ? ? ?8.05
>>> Log likelihood ?= ?-1694.649 ? ? ? ? ? ? ? ? ? ?Prob > chi2 ? ? ? ?= ? ?0.0178
>>
>> Well, the quantities being displayed in the iteration output from
>> glmer are the deviance and the parameter values. ?This stata
>> log-likelihood corresponds to a deviance of 3389.3. ?It is possible
>> that glmer and stata don't measure the log-likelihood on the same
>> scale but, if not, then the estimates where glmer gets stalled are
>> producing a lower deviance of 2837.49.
>>
>> The reason that glmer is getting stalled is because of the coefficient
>> of -7.45883 for the intercept. ?This corresponds to a mean success
>> probability of 0.0005 for cohort 1. ?The stata coefficient estimate of
>> -5.214642 corresponds to a mean success probability of ?0.0055 for
>> cohort 1, which is still very, very small. ?The success probabilities
>> for the other cohorts are going to be even smaller. ?What is the
>> overall proportion of zeros in the response?
>>
>> The optimization to determine the maximum likelihood estimates of the
>> coefficients is being done on the scale of the linear predictor. ?When
>> the values of the linear predictor become very small or very large,
>> the fitted values become insensitive to the coefficients. ?The fact
>> the one program converges and another one doesn't may have more to do
>> with the convergence criterion than with the quality of the fit.
>>
>>
>>> ------------------------------------------------------------------------------
>>> ? ?inftmort | ? ? ?Coef. ? Std. Err. ? ? ?z ? ?P>|z| ? ? [95% Conf. Interval]
>>> -------------+----------------------------------------------------------------
>>> ?_Icohort_2 | ?-.5246846 ? .1850328 ? ?-2.84 ? 0.005 ? ?-.8873422 ? -.1620269
>>> ?_Icohort_3 | ?-.1424331 ? ?.140369 ? ?-1.01 ? 0.310 ? ?-.4175513 ? ? .132685
>>> ? ? ? _cons | ?-5.214642 ? .1839703 ? -28.35 ? 0.000 ? ?-5.575217 ? -4.854067
>>> -------------+----------------------------------------------------------------
>>> ? ?/lnsig2u | ? .9232684 ? .1416214 ? ? ? ? ? ? ? ? ? ? ?.6456956 ? ?1.200841
>>> -------------+----------------------------------------------------------------
>>> ? ? sigma_u | ? 1.586665 ? .1123528 ? ? ? ? ? ? ? ? ? ? ?1.381055 ? ?1.822885
>>> ? ? ? ? rho | ? .4335015 ? .0347791 ? ? ? ? ? ? ? ? ? ? ?.3669899 ? ?.5024984
>>> ------------------------------------------------------------------------------
>>> Likelihood-ratio test of rho=0: chibar2(01) = ? 109.20 Prob >= chibar2 = 0.000
>>>
>>> The difference is quite huge, and Stata did not have any difficulties
>>> estimating this model, which makes feel that I might get some very
>>> basic specification wrong in my R model...
>>>
>>> Best,
>>> Shige
>>>
>>> On Tue, Feb 16, 2010 at 10:29 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
>>>> On Tue, Feb 16, 2010 at 9:05 AM, Shige Song <shigesong at gmail.com> wrote:
>>>>> Dear All,
>>>>
>>>>> I am trying to fit a 2-level random intercept logistic regression on a
>>>>> data set of 20,000 cases. ?The model is specified as the following:
>>>>
>>>>> ?m1 <- glmer(inftmort ~ as.factor(cohort) + (1|code), family=binomial, data=d)
>>>>
>>>>> I got "Warning message: In mer_finalize(ans) : false convergence (8)"
>>>>
>>>> That message means that the optimizer function, nlminb, got stalled.
>>>> It has converged but the point at which is has converged is not
>>>> clearly the optimum. ?In many cases this just indicates that the
>>>> optimizer is being overly cautious. ?However, it can also mean that
>>>> the problem is ill-defined.
>>>>
>>>> The fact the the second parameter is -7.46 is likely the problem. ?A
>>>> difference in the probability of infant mortality between levels of
>>>> cohort on the order of -7.5 on the logit scale is huge. ? Do the
>>>> estimated probabilities at this value of the parameters make sense?
>>>>
>>>> P.S. Questions of this sort may be more readily answered in the
>>>> R-SIG-mixed-models mailing list.
>>>>
>>>>> With the "verbose=TRUE" option, I was able to get the following
>>>>> iteration history:
>>>>>
>>>>> ?0: ? ? 3456.4146: ?1.15161 -3.99068 -0.498790 -0.122116
>>>>> ?1: ? ? 3361.3370: ?1.04044 -4.38172 -0.561756 -0.289991
>>>>> ?2: ? ? 3303.7986: ?1.48296 -4.40741 -0.566208 -0.259730
>>>>> ?3: ? ? 3147.5537: ?1.93037 -5.14388 -0.682530 -0.443006
>>>>> ?4: ? ? 3123.6900: ?2.10192 -5.18784 -0.685558 -0.428320
>>>>> ?5: ? ? 2988.6287: ?2.94890 -6.31023 -0.825286 -0.586282
>>>>> ?6: ? ? 2958.3364: ?3.25396 -6.88256 -0.316988 0.572428
>>>>> ?7: ? ? 2853.7703: ?4.22731 -7.44955 -0.279492 -0.294353
>>>>> ?8: ? ? 2844.8476: ?4.36583 -7.43902 -0.293111 -0.267308
>>>>> ?9: ? ? 2843.2879: ?4.39182 -7.44895 -0.298791 -0.265899
>>>>> ?10: ? ? 2840.2676: ?4.44288 -7.47103 -0.310477 -0.263945
>>>>> ?11: ? ? 2839.0890: ?4.46259 -7.48131 -0.315320 -0.263753
>>>>> ?12: ? ? 2838.8550: ?4.46649 -7.48344 -0.316292 -0.263745
>>>>> ?13: ? ? 2838.3889: ?4.47428 -7.48771 -0.318236 -0.263737
>>>>> ?14: ? ? 2838.3703: ?4.47459 -7.48788 -0.318314 -0.263738
>>>>> ?15: ? ? 2838.2216: ?4.47708 -7.48927 -0.318936 -0.263742
>>>>> ?16: ? ? 2838.2157: ?4.47718 -7.48932 -0.318961 -0.263742
>>>>> ?17: ? ? 2838.2145: ?4.47720 -7.48934 -0.318966 -0.263742
>>>>> ?18: ? ? 2838.2121: ?4.47724 -7.48936 -0.318976 -0.263742
>>>>> ?19: ? ? 2838.2120: ?4.47724 -7.48936 -0.318976 -0.263742
>>>>> ?20: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>>> ?21: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>>> ?22: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>>> ?23: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>>> ?24: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>>> ?25: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>>> ?26: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>>> ?27: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>>> ?28: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>>> ?29: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>>> ?30: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>>> ?31: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>>> ?32: ? ? 2838.2118: ?4.47724 -7.48936 -0.318977 -0.263742
>>>>> ?33: ? ? 2837.8154: ?4.46385 -7.47464 -0.495684 -0.263985
>>>>> ?34: ? ? 2837.7613: ?4.46641 -7.47053 -0.498335 -0.264014
>>>>> ?35: ? ? 2837.6418: ?4.47259 -7.46200 -0.501644 -0.264141
>>>>> ?36: ? ? 2837.5982: ?4.47485 -7.45928 -0.502598 -0.264214
>>>>> ?37: ? ? 2837.5850: ?4.47537 -7.45882 -0.502848 -0.264237
>>>>> ?38: ? ? 2837.5307: ?4.47674 -7.45848 -0.503216 -0.264313
>>>>> ?39: ? ? 2837.5014: ?4.47725 -7.45875 -0.503273 -0.264344
>>>>> ?40: ? ? 2837.4955: ?4.47735 -7.45881 -0.503284 -0.264350
>>>>> ?41: ? ? 2837.4944: ?4.47738 -7.45882 -0.503286 -0.264351
>>>>> ?42: ? ? 2837.4941: ?4.47738 -7.45882 -0.503287 -0.264351
>>>>> ?43: ? ? 2837.4936: ?4.47739 -7.45883 -0.503288 -0.264352
>>>>> ?44: ? ? 2837.4935: ?4.47739 -7.45883 -0.503288 -0.264352
>>>>> ?45: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>> ?46: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>> ?47: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>> ?48: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>> ?49: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>> ?50: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>> ?51: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>> ?52: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>> ?53: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>> ?54: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>> ?55: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>> ?56: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>> ?57: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>> ?58: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>> ?59: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>> ?60: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>> ?61: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>> ?62: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>> ?63: ? ? 2837.4931: ?4.47740 -7.45883 -0.503289 -0.264352
>>>>>
>>>>> By the way, the same model can be fitted using Stata using xtlogit and
>>>>> xtmelogit; a simpler model without the random component can be
>>>>> estimated using R as:
>>>>>
>>>>> m <- glm(inftmort ~ as.factor(cohort), family=binomial, data=d)
>>>>>
>>>>> I was also able to get highly consistent results via MCMC simulation
>>>>> using MCMCglmm.
>>>>>
>>>>> It will be greatly appreciated if someone can give me some hints where
>>>>> to look further. Thanks.
>>>>>
>>>>> Best,
>>>>> Shige
>>>>>
>>>>> BTW, sorry about the earlier post, which was caused by a mistake.
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>
>>
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bolker at ufl.edu  Wed Feb 17 01:00:05 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 16 Feb 2010 19:00:05 -0500
Subject: [R-sig-ME] [R] False convergence of a glmer model
In-Reply-To: <40e66e0b1002161232k542cf242yc13da515a64a82e6@mail.gmail.com>
References: <5abc11d81002160705n219979f3q988dffbc37a2cafd@mail.gmail.com>	<40e66e0b1002160729nb624b5bs724bd5bd1e6b8456@mail.gmail.com>	<5abc11d81002160738x552f08ebo1249bf2a2c2e9445@mail.gmail.com>	<40e66e0b1002161147i75c835b0i182a699f60a4686b@mail.gmail.com>	<5abc11d81002161223r2b9e2303y81248b1d7112ca5d@mail.gmail.com>
	<40e66e0b1002161232k542cf242yc13da515a64a82e6@mail.gmail.com>
Message-ID: <4B7B3185.2070505@ufl.edu>

Douglas Bates wrote:
> On Tue, Feb 16, 2010 at 2:23 PM, Shige Song <shigesong at gmail.com> wrote:
>> Dear Doug,
>>
>> Your argument makes a lot sense: after all, infant mortality is a rare
>> event! I have two questions:
>>
>> 1) Is there a way to change the convergence criterion in a glmer model
>> (to make it more tolerant)?
> 
> I'm not sure that is a good idea.  If the linear predictor produces
> probabilities that are so small that the deviance is insensitive to
> the parameter values, what would it mean to quote estimates of those
> parameters?
> 
>> 2) Do you see a better approach than mixed logistic regression model
>> in estimating infant morality, given the fact that infant mortality is
>> a rare event?
> 
> I don't know of other approaches myself.  Others on the list (Ben?)
> may have suggestions.

  I would think that a Bayesian approach would help here (by ruling out
probabilities of exactly zero): however, generally harder to implement
-- don't know if MCMCglmm offers possibilities for priors on fixed
effect parameters -- WinBUGS (possibly via glmmBUGS), ADMB may be
solutions.  (Also maybe harder to convince reviewers of.)



From shigesong at gmail.com  Wed Feb 17 01:41:23 2010
From: shigesong at gmail.com (Shige Song)
Date: Tue, 16 Feb 2010 19:41:23 -0500
Subject: [R-sig-ME] [R] False convergence of a glmer model
In-Reply-To: <4B7B3185.2070505@ufl.edu>
References: <5abc11d81002160705n219979f3q988dffbc37a2cafd@mail.gmail.com>
	<40e66e0b1002160729nb624b5bs724bd5bd1e6b8456@mail.gmail.com>
	<5abc11d81002160738x552f08ebo1249bf2a2c2e9445@mail.gmail.com>
	<40e66e0b1002161147i75c835b0i182a699f60a4686b@mail.gmail.com>
	<5abc11d81002161223r2b9e2303y81248b1d7112ca5d@mail.gmail.com>
	<40e66e0b1002161232k542cf242yc13da515a64a82e6@mail.gmail.com>
	<4B7B3185.2070505@ufl.edu>
Message-ID: <5abc11d81002161641k2a35dd93jf49b26f5ca3043e9@mail.gmail.com>

Hi Ben,

As I stated earlier, Stata's xtlogit and xtmelogit did reach
convergence and gave reasonable results, so did MCMCglmm; so this
seems to be a unique problem with R's ML optimizer.

Shige

On Tue, Feb 16, 2010 at 7:00 PM, Ben Bolker <bolker at ufl.edu> wrote:
> Douglas Bates wrote:
>> On Tue, Feb 16, 2010 at 2:23 PM, Shige Song <shigesong at gmail.com> wrote:
>>> Dear Doug,
>>>
>>> Your argument makes a lot sense: after all, infant mortality is a rare
>>> event! I have two questions:
>>>
>>> 1) Is there a way to change the convergence criterion in a glmer model
>>> (to make it more tolerant)?
>>
>> I'm not sure that is a good idea. ?If the linear predictor produces
>> probabilities that are so small that the deviance is insensitive to
>> the parameter values, what would it mean to quote estimates of those
>> parameters?
>>
>>> 2) Do you see a better approach than mixed logistic regression model
>>> in estimating infant morality, given the fact that infant mortality is
>>> a rare event?
>>
>> I don't know of other approaches myself. ?Others on the list (Ben?)
>> may have suggestions.
>
> ?I would think that a Bayesian approach would help here (by ruling out
> probabilities of exactly zero): however, generally harder to implement
> -- don't know if MCMCglmm offers possibilities for priors on fixed
> effect parameters -- WinBUGS (possibly via glmmBUGS), ADMB may be
> solutions. ?(Also maybe harder to convince reviewers of.)
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From lgcarvalheiro at gmail.com  Wed Feb 17 12:00:07 2010
From: lgcarvalheiro at gmail.com (Luisa Carvalheiro)
Date: Wed, 17 Feb 2010 13:00:07 +0200
Subject: [R-sig-ME] R2 measure in mixed models?
Message-ID: <221597f21002170300lcd22247sc202c3bb11bf6469@mail.gmail.com>

Dear mixed modelers,

Is there any package for calculating R2 measures for mixed models in R
(e.g. using the measure proposed by Mittlbock; Waldhor 2000)?

Luisa



From m03acj at math.ku.dk  Wed Feb 17 14:20:53 2010
From: m03acj at math.ku.dk (Anders Christian Jensen)
Date: Wed, 17 Feb 2010 14:20:53 +0100
Subject: [R-sig-ME] Res:  Random effects,
 autocorrelation and nesting in lme
In-Reply-To: <293066.22516.qm@web32105.mail.mud.yahoo.com>
References: <ec5eb98743520547f3f62cf42bf012b4.squirrel@mail.math.ku.dk>
	<293066.22516.qm@web32105.mail.mud.yahoo.com>
Message-ID: <8e620c5f5f213869bd2bc1ca70dcd1d0.squirrel@mail.math.ku.dk>

Walmes,

Thank you for your fast reply!

If I had only one time series per person (no r index) then I would use the
model you suggest, but I dont think this is the solution to my problem:

If I understand correctly, your model would imply that for all r and r',

e_{prt} and e_{pr't'}

would have the same correlation as

e_{prt} and e_{prt'}.

That is, for a given person you would have a correlation between
measurements from different time series. But this is not what Im trying to
model. I want measurements from different replications to be correlated
only through the random person effect.

Thanks!

Anders

> Anders,
>
> I think that the correct sintax or model specification is different. I
> think you should use form=~1|Person instead of form=~1|Person_replicate at
> correlation argument, this because repeated measures on the same person
> along time induces correlation. More about it in Pinheiro & Bates (2000).
> The code is the following:
>
>> Data <- data.frame(Person=factor(rep(1:3,each=12)),
> +                    Person_replicate=factor(rep(1:12,each=3)),
> +                    Time=rep(1:4,9),
> +                    response=round(5+rnorm(36),2))
>>
>> lme(response~Time, random=list(~Time|Person),
> +     correlation=corGaus(form=~1|Person), data=Data)
> Linear mixed-effects model fit by REML
>   Data: Data
>   Log-restricted-likelihood: -41.12866
>   Fixed: response ~ Time
> (Intercept)        Time
>   5.3595834  -0.2110061
>
> Random effects:
>  Formula: ~Time | Person
>  Structure: General positive-definite, Log-Cholesky parametrization
>             StdDev       Corr
> (Intercept) 2.270560e-05 (Intr)
> Time        1.236894e-08 0
> Residual    7.507016e-01
>
> Correlation Structure: Gaussian spatial correlation
>  Formula: ~1 | Person
>  Parameter estimate(s):
>     range
> 0.8230017
> Number of Observations: 36
> Number of Groups: 3
>>
>
> Walmes Zeviani. Brasil.
>
>
>
>
> ________________________________
> De: Anders Christian Jensen <m03acj at math.ku.dk>
> Para: r-sig-mixed-models at r-project.org
> Enviadas: Ter?a-feira, 16 de Fevereiro de 2010 13:57:15
> Assunto: [R-sig-ME] Random effects, autocorrelation and nesting in lme
>
> Dear R - users
>
> I have a problem with lme when trying to specify both "random" and
> "correlation" arguments to my model.
>
> The problem seems to be related to the nesting structure of my data:
>
> For each person (p) I have multiple replicates (r) of a time series of
> observations. Observations within a time series is indexed by t. That is,
> my outcome (y) is uniquely determined by indices y_{prt}.
>
> I would like to specify a model that includes
> 1)  a random slope and intercept for each person, and
> 2)  some sort of correlation on the time series, within each
> (person,replicate); possibly an AR(1) process.
>
> In other words, I would like to specify the following model (disregarding
> the fixed effects part of the model):
>
> y_{prt} = a_p + b_p * t + e_{prt},
>
> where a_p and b_p are the (Gaussian) random slope and intercept on person
> level, and e_{prt} should be such that
>
> cor(e_{prt},e_{p'r't'}) = f(|t-t'|), for some function f
>
> when p=p' and r=r', and 0 otherwise.
>
> When I try to fit the model with lme I get an error message:
>
> "Incompatible formulas for groups in "random" and "correlation""
>
> A very small toy data set (without any autocorrelation) illustrates my
> problem:
>
>> Data <- data.frame(Person           = factor(rep(1:3,each=12)),
> +                    Person_replicate = factor(rep(1:12,each=3)),
> +                    Time             = rep(1:4,9),
> +                    response         = round(5+rnorm(36),2))
>> str(Data)
> 'data.frame':   36 obs. of  4 variables:
> $ Person          : Factor w/ 3 levels "1","2","3": 1 1 1 1 1 1 1 1 1 1
> ...
> $ Person_replicate: Factor w/ 12 levels "1","2","3","4",..: 1 1 1 2 2 2 3
> 3 3 4 ...
> $ Time            : int  1 2 3 4 1 2 3 4 1 2 ...
> $ response        : num  5.21 4.95 3.32 4.86 6.18 5.68 5.14 3.81 6.17
> 5.08 ...
>> head(Data)
>   Person Person_replicate Time response
> 1      1                1    1     5.21
> 2      1                1    2     4.95
> 3      1                1    3     3.32
> 4      1                2    4     4.86
> 5      1                2    1     6.18
> 6      1                2    2     5.68
>
> I then try to fit the model, and get an error:
>> library(splines)
>> library(nlme)
>> lme(response ~ Time,
> +     random = list(~Time|Person),
> +     correlation=corGaus(form=~1|Person_replicate),
> +     data = Data)
> Error in lme.formula(response ~ Time, random = list(~Time | Person),
> correlation = corGaus(form = ~1 |  :
>   Incompatible formulas for groups in "random" and "correlation"
>
> Basically I would like the "random"-argument for lme to work on person
> level, but the "correlation"-argument should work on (person,replicate)
> level. I found old posts on the mailing list with similar problems but
> none of them include an answer.
> Any help would be much appreciated! Thanks
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
>       ____________________________________________________________________________________
> Veja quais s?o os assuntos do momento no Yahoo! +Buscados
> http://br.maisbuscados.yahoo.com



From bates at stat.wisc.edu  Wed Feb 17 15:09:23 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 17 Feb 2010 08:09:23 -0600
Subject: [R-sig-ME] [R] False convergence of a glmer model
In-Reply-To: <5abc11d81002161641k2a35dd93jf49b26f5ca3043e9@mail.gmail.com>
References: <5abc11d81002160705n219979f3q988dffbc37a2cafd@mail.gmail.com>
	<40e66e0b1002160729nb624b5bs724bd5bd1e6b8456@mail.gmail.com>
	<5abc11d81002160738x552f08ebo1249bf2a2c2e9445@mail.gmail.com>
	<40e66e0b1002161147i75c835b0i182a699f60a4686b@mail.gmail.com>
	<5abc11d81002161223r2b9e2303y81248b1d7112ca5d@mail.gmail.com>
	<40e66e0b1002161232k542cf242yc13da515a64a82e6@mail.gmail.com>
	<4B7B3185.2070505@ufl.edu>
	<5abc11d81002161641k2a35dd93jf49b26f5ca3043e9@mail.gmail.com>
Message-ID: <40e66e0b1002170609p6057cceep7c2c084ed872dcee@mail.gmail.com>

On Tue, Feb 16, 2010 at 6:41 PM, Shige Song <shigesong at gmail.com> wrote:
> Hi Ben,
>
> As I stated earlier, Stata's xtlogit and xtmelogit did reach
> convergence and gave reasonable results, so did MCMCglmm; so this
> seems to be a unique problem with R's ML optimizer.

Bear in mind that declaring convergence and converging are different
things.  One way to check on the estimates from the Stata procedures
is to use them as starting estimates in glmer and see whether glmer
proceeds to reduce the deviance from those estimates.

For generalized linear mixed models and even more for nonlinear mixed
models I have for several years been advocating that rather than
comparing parameter estimates from different procedures on which
method provided convergence, etc., we should agree on a method for
evaluating the log-likelihood or deviance from a model/data
set/parameter value combination.  The method could be quite
computationally intensive and unsuitable for use in optimizing the
parameter estimates but suitable as a "gold standard" deviance
evaluation.  Then when software developers want to play the "my
estimates are better than your estimates" game, the standard for
comparing the estimates from different software systems could be to
evaluate the log-likelihood or deviance at those estimates and see
which set provides a lower value of the deviance.

It is quite possible that there are reasonable parameter estimates
corresponding to very low predicted probabilities but that the maximum
likelihood estimates don't exist because they would correspond to
negative infinity for some of the parameters.

> Shige
>
> On Tue, Feb 16, 2010 at 7:00 PM, Ben Bolker <bolker at ufl.edu> wrote:
>> Douglas Bates wrote:
>>> On Tue, Feb 16, 2010 at 2:23 PM, Shige Song <shigesong at gmail.com> wrote:
>>>> Dear Doug,
>>>>
>>>> Your argument makes a lot sense: after all, infant mortality is a rare
>>>> event! I have two questions:
>>>>
>>>> 1) Is there a way to change the convergence criterion in a glmer model
>>>> (to make it more tolerant)?
>>>
>>> I'm not sure that is a good idea. ?If the linear predictor produces
>>> probabilities that are so small that the deviance is insensitive to
>>> the parameter values, what would it mean to quote estimates of those
>>> parameters?
>>>
>>>> 2) Do you see a better approach than mixed logistic regression model
>>>> in estimating infant morality, given the fact that infant mortality is
>>>> a rare event?
>>>
>>> I don't know of other approaches myself. ?Others on the list (Ben?)
>>> may have suggestions.
>>
>> ?I would think that a Bayesian approach would help here (by ruling out
>> probabilities of exactly zero): however, generally harder to implement
>> -- don't know if MCMCglmm offers possibilities for priors on fixed
>> effect parameters -- WinBUGS (possibly via glmmBUGS), ADMB may be
>> solutions. ?(Also maybe harder to convince reviewers of.)
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From HDoran at air.org  Wed Feb 17 16:09:34 2010
From: HDoran at air.org (Doran, Harold)
Date: Wed, 17 Feb 2010 10:09:34 -0500
Subject: [R-sig-ME] [R] False convergence of a glmer model
In-Reply-To: <40e66e0b1002170609p6057cceep7c2c084ed872dcee@mail.gmail.com>
References: <5abc11d81002160705n219979f3q988dffbc37a2cafd@mail.gmail.com>
	<40e66e0b1002160729nb624b5bs724bd5bd1e6b8456@mail.gmail.com>
	<5abc11d81002160738x552f08ebo1249bf2a2c2e9445@mail.gmail.com>
	<40e66e0b1002161147i75c835b0i182a699f60a4686b@mail.gmail.com>
	<5abc11d81002161223r2b9e2303y81248b1d7112ca5d@mail.gmail.com>
	<40e66e0b1002161232k542cf242yc13da515a64a82e6@mail.gmail.com>
	<4B7B3185.2070505@ufl.edu>
	<5abc11d81002161641k2a35dd93jf49b26f5ca3043e9@mail.gmail.com>
	<40e66e0b1002170609p6057cceep7c2c084ed872dcee@mail.gmail.com>
Message-ID: <C0772C7568B5374481D2F8A880E9BBDF0454E4260A@DC1EX07CMS.air.org>

I agree with Doug. But, agreeing with Doug is like agreeing that the Pope is Catholic. Quick small thing. I don't like using the term "convergence" with MCMC methods. I don't think MCMC converges in the same sense as ML methods do; they reach a stationary distribution.

Also, I only partly recall the OP on this, but from what I recall the differences in the log-likelihood and parameter estimates in the final iterations were nominal at best. I think many software programs would declare convergence given that differences in the log-likelihood are no longer larger than some predetermined criterion (e.g., 1e-3). So, reaching a stopping point w.r.t. an algorithm is (or may be) different than reaching the MLE of an objective function.

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Douglas Bates
Sent: Wednesday, February 17, 2010 9:09 AM
To: Shige Song
Cc: R Mixed Models
Subject: Re: [R-sig-ME] [R] False convergence of a glmer model

On Tue, Feb 16, 2010 at 6:41 PM, Shige Song <shigesong at gmail.com> wrote:
> Hi Ben,
>
> As I stated earlier, Stata's xtlogit and xtmelogit did reach
> convergence and gave reasonable results, so did MCMCglmm; so this
> seems to be a unique problem with R's ML optimizer.

Bear in mind that declaring convergence and converging are different
things.  One way to check on the estimates from the Stata procedures
is to use them as starting estimates in glmer and see whether glmer
proceeds to reduce the deviance from those estimates.

For generalized linear mixed models and even more for nonlinear mixed
models I have for several years been advocating that rather than
comparing parameter estimates from different procedures on which
method provided convergence, etc., we should agree on a method for
evaluating the log-likelihood or deviance from a model/data
set/parameter value combination.  The method could be quite
computationally intensive and unsuitable for use in optimizing the
parameter estimates but suitable as a "gold standard" deviance
evaluation.  Then when software developers want to play the "my
estimates are better than your estimates" game, the standard for
comparing the estimates from different software systems could be to
evaluate the log-likelihood or deviance at those estimates and see
which set provides a lower value of the deviance.

It is quite possible that there are reasonable parameter estimates
corresponding to very low predicted probabilities but that the maximum
likelihood estimates don't exist because they would correspond to
negative infinity for some of the parameters.

> Shige
>
> On Tue, Feb 16, 2010 at 7:00 PM, Ben Bolker <bolker at ufl.edu> wrote:
>> Douglas Bates wrote:
>>> On Tue, Feb 16, 2010 at 2:23 PM, Shige Song <shigesong at gmail.com> wrote:
>>>> Dear Doug,
>>>>
>>>> Your argument makes a lot sense: after all, infant mortality is a rare
>>>> event! I have two questions:
>>>>
>>>> 1) Is there a way to change the convergence criterion in a glmer model
>>>> (to make it more tolerant)?
>>>
>>> I'm not sure that is a good idea. ?If the linear predictor produces
>>> probabilities that are so small that the deviance is insensitive to
>>> the parameter values, what would it mean to quote estimates of those
>>> parameters?
>>>
>>>> 2) Do you see a better approach than mixed logistic regression model
>>>> in estimating infant morality, given the fact that infant mortality is
>>>> a rare event?
>>>
>>> I don't know of other approaches myself. ?Others on the list (Ben?)
>>> may have suggestions.
>>
>> ?I would think that a Bayesian approach would help here (by ruling out
>> probabilities of exactly zero): however, generally harder to implement
>> -- don't know if MCMCglmm offers possibilities for priors on fixed
>> effect parameters -- WinBUGS (possibly via glmmBUGS), ADMB may be
>> solutions. ?(Also maybe harder to convince reviewers of.)
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bb.patrick at hotmail.com  Wed Feb 17 20:53:14 2010
From: bb.patrick at hotmail.com (Bob Patrick)
Date: Wed, 17 Feb 2010 14:53:14 -0500
Subject: [R-sig-ME] Convergence failure in lmer
Message-ID: <BAY142-W27557BA5340E1D49ED9D4597480@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100217/1cc13d95/attachment.pl>

From cat.dev.urandom at gmail.com  Wed Feb 17 22:34:07 2010
From: cat.dev.urandom at gmail.com (D Chaws)
Date: Wed, 17 Feb 2010 16:34:07 -0500
Subject: [R-sig-ME] prediction intervals from a mixed-effects models?
Message-ID: <dcf23fb81002171334y77888079p9aedd87dbe6e3c0b@mail.gmail.com>

This is an old post from April, 2008.  Spencer, you indicated you were
off to find a solution.  Did you ever solve the problem
of getting prediction intervals from lme?  I think the community would
benefit greatly if you did and would like to share it.  I
know I have been trying to find this for quite some time.

-D Chaws

--------------------------------------------------------------------------------------
     How can I get prediction intervals from a mixed-effects model?
Consider the following example:

library(nlme)
fm3 <- lme(distance ~ age*Sex, data = Orthodont, random = ~ 1)
df3.1 <- with(Orthodont, data.frame(age=seq(5, 20, 5),
                    Subject=rep(Subject[1], 4),
                    Sex=rep(Sex[1], 4)))
predict(fm3, df3.1, interval='prediction')
#      M01      M01      M01      M01
# 22.69012 26.61199 30.53387 34.45574

# NOTE:  The 'interval' argument to the 'predict' function was ignored.
# It works works for an 'lm' object, but not an 'lme' object.

      One way to do this might be via mcmcsamp of the corresponding
'lmer' model:

library(lme4)
set.seed(3)
samp3r <- mcmcsamp(fm3r, n=10000)
samp3r[1:2,]

      Then use library(coda) to check convergence and write a function
to simulate a single observation from each set of simulated parameters
and compute quantile(..., c(.025, .975)) for each prediction level
desired.

      However, before I coded that, I thought I would ask if some easier
method might be available.

      Thanks,
      Spencer
p.s.  RSiteSearch("lme prediction intervals") produced 3 hits including
2 from James A Rogers over 3 years ago.  In one, he said, "I am not
aware of any published R function that gives you prediction intervals or
tolerance intervals for lme models."
(http://finzi.psych.upenn.edu/R/Rhelp02a/archive/42781.html)   In the
other, he provided sample code for prediction or tolerance intervals of
lme variance components.
(http://finzi.psych.upenn.edu/R/Rhelp02a/archive/44675.html)



From pierces1 at msu.edu  Thu Feb 18 00:46:50 2010
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Wed, 17 Feb 2010 18:46:50 -0500
Subject: [R-sig-ME] R2 measure in mixed models?
In-Reply-To: <221597f21002170300lcd22247sc202c3bb11bf6469@mail.gmail.com>
References: <221597f21002170300lcd22247sc202c3bb11bf6469@mail.gmail.com>
Message-ID: <11E3FEA23855407391779E0D7CE701AB@TheVoid>

Luisa,

I'm not aware of any packages for that, but I'd like the full citation for
the paper you mentioned. In exchange, here are some citations for other
papers about R-square measures in multilevel models that I've found.

Edwards, L. J., Muller, K. E., Wolfinger, R. D., Qaqish, B. F., &
Schabenberger, O. (2008). An R2 statistic for fixed effects in the linear
mixed model. Statistics in Medicine, 27(29), 6137-6157. doi:
10.1002/sim.3429

Gelman, A., & Pardoe, I. (2006). Bayesian measures of explained variance and
pooling in multilevel (hierarchical) models. Technometrics, 48(2), 241-251.
doi: 10.1198/004017005000000517

Kramer, M. (2005). R2 statistics for mixed models. Proceedings of the
Conference on Applied Statistics in Agriculture, 17, 148-160. Retrieved from
http://www.ars.usda.gov/sp2UserFiles/ad_hoc/12000000SpatialWorkshop/19Kramer
SupplRsq.pdf

Merlo, J., Yang, M., Chaix, B., Lynch, J., & R?stam, L. (2005). A brief
conceptual tutorial on multilevel analysis in social epidemiology:
investigating contextual phenomena in different groups of people. Journal of
Epidemiology and Community Health, 59(9), 729-736. doi:
10.1136/jech.2004.023929

Orelien, J. G., & Edwards, L. J. (2008). Fixed-effect variable selection in
linear mixed models using R2 statistics. Computational Statistics & Data
Analysis, 52(4), 1896-1907. doi: 10.1016/j.csda.2007.06.006

Roberts, J. K., & Monaco, J. P. (2006, April). Effect size measures for the
two-level linear multilevel model.  Paper presented at the annual meeting of
the American Educational Research Association, San Francisco, CA. Retrieved
from http://www.hlm-online.com/papers/HLM_effect_size.pdf

Snijders, T. A. B., & Bosker, R. J. (1994). Modeled variance in two-level
models. Sociological Methods & Research, 22(3), 342-363. doi:
10.1177/0049124194022003004

Snijders, T. A. B., & Bosker, R. J. (1999). Multilevel analysis. London, UK:
Sage.
Xu, R. (2003). Measuring explained variation in linear mixed effects models.
Statistics in Medicine, 22(22), 3527-3541. doi: 10.1002/sim.1572



Steven J. Pierce
Associate Director
Center for Statistical Training & Consulting (CSTAT)
Michigan State University
178 Giltner Hall
East Lansing, MI 48824
Web: http://www.cstat.msu.edu


-----Original Message-----
From: Luisa Carvalheiro [mailto:lgcarvalheiro at gmail.com] 
Sent: Wednesday, February 17, 2010 6:00 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] R2 measure in mixed models?

Dear mixed modelers,

Is there any package for calculating R2 measures for mixed models in R (e.g.
using the measure proposed by Mittlbock; Waldhor 2000)?

Luisa



From lgcarvalheiro at gmail.com  Thu Feb 18 07:55:17 2010
From: lgcarvalheiro at gmail.com (Luisa Carvalheiro)
Date: Thu, 18 Feb 2010 08:55:17 +0200
Subject: [R-sig-ME] R2 measure in mixed models?
In-Reply-To: <11E3FEA23855407391779E0D7CE701AB@TheVoid>
References: <221597f21002170300lcd22247sc202c3bb11bf6469@mail.gmail.com>
	<11E3FEA23855407391779E0D7CE701AB@TheVoid>
Message-ID: <221597f21002172255h7004365di8d7155a77809ade1@mail.gmail.com>

Hi Steve,

Thanlks for reply and literature list. Here are 3 papers on  R2
calculations for Mixed Models:

M. Mittlbock, T. Waldhor. Adjustments for R2-measures for Poisson
regression models. Computational Statistics & Data Analysis 34 (2000)
461-472

M. Mittlbock Calculating adjusted R2 measures for Poisson regression
Models. Computer Methods and Programs in Biomedicine 68 (2002) 205?214

H. Liu,Y. Zheng and J. Shen. Goodness-of-fit measures of R2 for
repeated measures mixed effect models Journal of Applied Statistics.
35, 2008, 1081?1092


On Thu, Feb 18, 2010 at 1:46 AM, Steven J. Pierce <pierces1 at msu.edu> wrote:
> Luisa,
>
> I'm not aware of any packages for that, but I'd like the full citation for
> the paper you mentioned. In exchange, here are some citations for other
> papers about R-square measures in multilevel models that I've found.
>
> Edwards, L. J., Muller, K. E., Wolfinger, R. D., Qaqish, B. F., &
> Schabenberger, O. (2008). An R2 statistic for fixed effects in the linear
> mixed model. Statistics in Medicine, 27(29), 6137-6157. doi:
> 10.1002/sim.3429
>
> Gelman, A., & Pardoe, I. (2006). Bayesian measures of explained variance and
> pooling in multilevel (hierarchical) models. Technometrics, 48(2), 241-251.
> doi: 10.1198/004017005000000517
>
> Kramer, M. (2005). R2 statistics for mixed models. Proceedings of the
> Conference on Applied Statistics in Agriculture, 17, 148-160. Retrieved from
> http://www.ars.usda.gov/sp2UserFiles/ad_hoc/12000000SpatialWorkshop/19Kramer
> SupplRsq.pdf
>
> Merlo, J., Yang, M., Chaix, B., Lynch, J., & R?stam, L. (2005). A brief
> conceptual tutorial on multilevel analysis in social epidemiology:
> investigating contextual phenomena in different groups of people. Journal of
> Epidemiology and Community Health, 59(9), 729-736. doi:
> 10.1136/jech.2004.023929
>
> Orelien, J. G., & Edwards, L. J. (2008). Fixed-effect variable selection in
> linear mixed models using R2 statistics. Computational Statistics & Data
> Analysis, 52(4), 1896-1907. doi: 10.1016/j.csda.2007.06.006
>
> Roberts, J. K., & Monaco, J. P. (2006, April). Effect size measures for the
> two-level linear multilevel model. ?Paper presented at the annual meeting of
> the American Educational Research Association, San Francisco, CA. Retrieved
> from http://www.hlm-online.com/papers/HLM_effect_size.pdf
>
> Snijders, T. A. B., & Bosker, R. J. (1994). Modeled variance in two-level
> models. Sociological Methods & Research, 22(3), 342-363. doi:
> 10.1177/0049124194022003004
>
> Snijders, T. A. B., & Bosker, R. J. (1999). Multilevel analysis. London, UK:
> Sage.
> Xu, R. (2003). Measuring explained variation in linear mixed effects models.
> Statistics in Medicine, 22(22), 3527-3541. doi: 10.1002/sim.1572
>
>
>
> Steven J. Pierce
> Associate Director
> Center for Statistical Training & Consulting (CSTAT)
> Michigan State University
> 178 Giltner Hall
> East Lansing, MI 48824
> Web: http://www.cstat.msu.edu
>
>
> -----Original Message-----
> From: Luisa Carvalheiro [mailto:lgcarvalheiro at gmail.com]
> Sent: Wednesday, February 17, 2010 6:00 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] R2 measure in mixed models?
>
> Dear mixed modelers,
>
> Is there any package for calculating R2 measures for mixed models in R (e.g.
> using the measure proposed by Mittlb ock; ?Waldh or 2000)?
>
> Luisa
>
>
>
>



-- 
Luisa Carvalheiro, PhD
Southern African Biodiversity Institute, Kirstenbosch Research Center, Claremont
& University of Pretoria
Postal address - SAWC Pbag X3015 Hoedspruit 1380, South Africa
telephone - +27 (0) 790250944
Carvalheiro at sanbi.org
lgcarvalheiro at gmail.com



From Maarten.deGroot at nib.si  Thu Feb 18 10:35:06 2010
From: Maarten.deGroot at nib.si (Maarten de Groot)
Date: Thu, 18 Feb 2010 10:35:06 +0100
Subject: [R-sig-ME] offset in glmmPQL
Message-ID: <4B7D09CA.9020301@nib.si>

Dear all,

I have a small question about including an offset value into a glmmPQL 
with a poisson distribution. I want to compare the number of songs of an 
animal between treatments. Because the experiment time is not always the 
same I want to include this as an offset in my formula 
("mod<-glmmPQL(nosongs~offset(experiment.time)+treatment,random=~1|block/malenr,family=poisson,data=mcrs)"). 


However R seems not to recognize the command"offset" when using a glmmPQL.

Hopefully some one can help me.

Kind regards,

Maarten



From bates at stat.wisc.edu  Thu Feb 18 16:10:06 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 18 Feb 2010 09:10:06 -0600
Subject: [R-sig-ME] lmer book draft
In-Reply-To: <201002181432.o1IEWL0G029626@defang9.it.ohio-state.edu>
References: <201002181432.o1IEWL0G029626@defang9.it.ohio-state.edu>
Message-ID: <40e66e0b1002180710s37bfd1bbred8259c22556c821@mail.gmail.com>

On Thu, Feb 18, 2010 at 7:29 AM, Philip A. Viton <viton.1 at osu.edu> wrote:

> Dear Douglas Bates:

> It was very kind of you to post a draft of the lmer book on the r-forge
> site, but I was wondering: was the omission of (the very short) chapter 3 an
> oversight, or is it really not available?

Chapter 3 is still in outline form, which is why it is apparently so
short.  I am adding to it but, as these things tend to go, slowly.  I
will also add more topics to chapter 4 and extend chapter 5.  If you
make it all the way to the end of chapter 5 you will find that it
kind-of drops off a cliff at the end.  There will probably be 5 or 6
more chapters after that plus a couple of appendices.

I made these chapters available so that I don't need to explain the
use of profiling when others begin using the development version of
lme4.

I have taken the liberty of copying this reply to the
R-SIG-Mixed-Models mailing list in case others are wondering about the
organization.

By the way, I have been able to build the lme4a package for Windows on
Uwe's win-builder.r-project.org.  I checked the R-forge site for
packages this morning but they haven't been re-built since last week.
The latest SVN check-in that was built is revision 637 and the current
revision is 650.



From cat.dev.urandom at gmail.com  Thu Feb 18 18:25:32 2010
From: cat.dev.urandom at gmail.com (D Chaws)
Date: Thu, 18 Feb 2010 12:25:32 -0500
Subject: [R-sig-ME] lme and prediction intervals
Message-ID: <dcf23fb81002180925o2a82d2a4xea95799c547753c5@mail.gmail.com>

Dear lme(r) users,

I have seen this issue come up many times over the years, but haven't
come across an answer as of yet.
Take for example the growth model:

fm1 <- lme(distance ~ age*Sex, random = ~ 1 + age | Subject, data = Orthodont)

Distance increases with age, but more so in Males.

I want to obtain the model predicted values of distance at each age
(c(8,10,12,14)) for males and female separately to explore this
interaction.

So,

newdat <- expand.grid(age=c(8,10,12,14), Sex=c("Male","Female"))
newdat$pred <- predict(fm1, newdat, level = 0)

R# newdat
  age    Sex  pred
1   8   Male 22.62
2  10   Male 24.18
3  12   Male 25.75
4  14   Male 27.32
5   8 Female 21.21
6  10 Female 22.17
7  12 Female 23.13
8  14 Female 24.09

Yup, males have a steeper increase with age than females.

The question is, how to go about getting prediction intervals around
these predictions.  It seems reasonable to need to know
the precision of these predictions, and of course most journals
require the reporting of error bars etc...  However, predict.lme
doesn't
have a se.fit or intervals argument.

The only answer I have found at the moment is to use the design matrix
and $varFix from the model.

So,

Designmat <- model.matrix(eval(eval(fm1$call$fixed)[-2]), newdat[-3])
R# Designmat
  (Intercept) age SexFemale age:SexFemale
1           1   8         0             0
2           1  10         0             0
3           1  12         0             0
4           1  14         0             0
5           1   8         1             8
6           1  10         1            10
7           1  12         1            12
8           1  14         1            14

newdat$SE <- sqrt(diag(Designmat %*% fm1$varFix %*% t(Designmat)))
R# newdat
  age    Sex  pred     SE
1   8   Male 22.62 0.5265
2  10   Male 24.18 0.4848
3  12   Male 25.75 0.5021
4  14   Male 27.32 0.5730
5   8 Female 21.21 0.6350
6  10 Female 22.17 0.5847
7  12 Female 23.13 0.6056
8  14 Female 24.09 0.6910

Are these true pointwise prediction intervals?

Any help would be greatly appreciated.  I refuse to use SAS for this!

-- D. Chaws



From isabella at ghement.ca  Thu Feb 18 19:14:09 2010
From: isabella at ghement.ca (Isabella Ghement)
Date: Thu, 18 Feb 2010 10:14:09 -0800
Subject: [R-sig-ME] Baseline + Follow-Up
In-Reply-To: <552567.41366.qm@web55408.mail.re4.yahoo.com>
Message-ID: <CEEDLPBNOCMDHIGPLIJLCEDGCHAA.isabella@ghement.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100218/a200c643/attachment.pl>

From andydolman at gmail.com  Thu Feb 18 21:19:16 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Thu, 18 Feb 2010 21:19:16 +0100
Subject: [R-sig-ME] lmer book draft
In-Reply-To: <40e66e0b1002180710s37bfd1bbred8259c22556c821@mail.gmail.com>
References: <201002181432.o1IEWL0G029626@defang9.it.ohio-state.edu>
	<40e66e0b1002180710s37bfd1bbred8259c22556c821@mail.gmail.com>
Message-ID: <951234ac1002181219q386cfaacq44c9fa5a312bcb93@mail.gmail.com>

Any chance of getting the compiled windows lme4a package? Or should I
expect to see it on r-forge very soon?

Cheers,


andydolman at gmail.com




>
> By the way, I have been able to build the lme4a package for Windows on
> Uwe's win-builder.r-project.org. ?I checked the R-forge site for
> packages this morning but they haven't been re-built since last week.
> The latest SVN check-in that was built is revision 637 and the current
> revision is 650.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Thu Feb 18 21:38:32 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 18 Feb 2010 14:38:32 -0600
Subject: [R-sig-ME] lmer book draft
In-Reply-To: <951234ac1002181219q386cfaacq44c9fa5a312bcb93@mail.gmail.com>
References: <201002181432.o1IEWL0G029626@defang9.it.ohio-state.edu>
	<40e66e0b1002180710s37bfd1bbred8259c22556c821@mail.gmail.com>
	<951234ac1002181219q386cfaacq44c9fa5a312bcb93@mail.gmail.com>
Message-ID: <40e66e0b1002181238l427789e1j75a15fe4daa8eb6c@mail.gmail.com>

On Thu, Feb 18, 2010 at 2:19 PM, Andrew Dolman <andydolman at gmail.com> wrote:
> Any chance of getting the compiled windows lme4a package? Or should I
> expect to see it on r-forge very soon?

I hope it will appear overnight on R-forge.  If not, I will follow up
with the R-forge maintainers and, if necessary, make a compiled
Windows binary from  win-builder available.

I can see on the SVN archive that the lme4a sources are at revision
652.  (Windows compilations need revision 649 or later to succeed.) It
looks like the last attempt to build a Windows version was around
midnight CET yesterday, which is about 17:00 my time (CST).  I may
have committed my fixes for Windows after that.  Right now the archive
shows revision 649 as having been committed 23 hours ago.

>>
>> By the way, I have been able to build the lme4a package for Windows on
>> Uwe's win-builder.r-project.org. ?I checked the R-forge site for
>> packages this morning but they haven't been re-built since last week.
>> The latest SVN check-in that was built is revision 637 and the current
>> revision is 650.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Thu Feb 18 21:47:57 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 18 Feb 2010 14:47:57 -0600
Subject: [R-sig-ME] lmer book draft
In-Reply-To: <40e66e0b1002181238l427789e1j75a15fe4daa8eb6c@mail.gmail.com>
References: <201002181432.o1IEWL0G029626@defang9.it.ohio-state.edu>
	<40e66e0b1002180710s37bfd1bbred8259c22556c821@mail.gmail.com>
	<951234ac1002181219q386cfaacq44c9fa5a312bcb93@mail.gmail.com>
	<40e66e0b1002181238l427789e1j75a15fe4daa8eb6c@mail.gmail.com>
Message-ID: <40e66e0b1002181247m70c86f74oa90b878ff2cc1211@mail.gmail.com>

By the way, the Mac OSX version is failing to build for a different
reason.  It's another "twisty maze of include files" problem.

On Thu, Feb 18, 2010 at 2:38 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
> On Thu, Feb 18, 2010 at 2:19 PM, Andrew Dolman <andydolman at gmail.com> wrote:
>> Any chance of getting the compiled windows lme4a package? Or should I
>> expect to see it on r-forge very soon?
>
> I hope it will appear overnight on R-forge. ?If not, I will follow up
> with the R-forge maintainers and, if necessary, make a compiled
> Windows binary from ?win-builder available.
>
> I can see on the SVN archive that the lme4a sources are at revision
> 652. ?(Windows compilations need revision 649 or later to succeed.) It
> looks like the last attempt to build a Windows version was around
> midnight CET yesterday, which is about 17:00 my time (CST). ?I may
> have committed my fixes for Windows after that. ?Right now the archive
> shows revision 649 as having been committed 23 hours ago.
>
>>>
>>> By the way, I have been able to build the lme4a package for Windows on
>>> Uwe's win-builder.r-project.org. ?I checked the R-forge site for
>>> packages this morning but they haven't been re-built since last week.
>>> The latest SVN check-in that was built is revision 637 and the current
>>> revision is 650.
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>



From walmeszeviani at yahoo.com.br  Thu Feb 18 22:03:21 2010
From: walmeszeviani at yahoo.com.br (walmes zeviani)
Date: Thu, 18 Feb 2010 13:03:21 -0800 (PST)
Subject: [R-sig-ME] Res:  lme and prediction intervals
In-Reply-To: <dcf23fb81002180925o2a82d2a4xea95799c547753c5@mail.gmail.com>
References: <dcf23fb81002180925o2a82d2a4xea95799c547753c5@mail.gmail.com>
Message-ID: <316625.80950.qm@web32102.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100218/ad39e71c/attachment.pl>

From robjgoedman at me.com  Thu Feb 18 22:30:10 2010
From: robjgoedman at me.com (Rob Goedman)
Date: Thu, 18 Feb 2010 13:30:10 -0800
Subject: [R-sig-ME] lmer book draft
In-Reply-To: <40e66e0b1002181247m70c86f74oa90b878ff2cc1211@mail.gmail.com>
References: <201002181432.o1IEWL0G029626@defang9.it.ohio-state.edu>
	<40e66e0b1002180710s37bfd1bbred8259c22556c821@mail.gmail.com>
	<951234ac1002181219q386cfaacq44c9fa5a312bcb93@mail.gmail.com>
	<40e66e0b1002181238l427789e1j75a15fe4daa8eb6c@mail.gmail.com>
	<40e66e0b1002181247m70c86f74oa90b878ff2cc1211@mail.gmail.com>
Message-ID: <EDC81757-2A43-45D6-B534-841E94F8D63F@me.com>

Douglas,

After my previous message I figured out how to work around the compile issue and 
have been able to get all 4 test scripts (for chapters 1, 2, 4 and 5) to work on MacOS
SnowLeopard using 64 bit R.2.11 (but I think the same fix might also work on R.2.10,
on Leopard and for 32 bit). It also required a later version of the Matrix package
(available on R-forge).

If someone needs help, they can just send me an email. It requires a temporary (just
to install lme4a) change to a system file (alloca.h). I'm sure its not the final solution, but
it seems to work for now.

Regards,
Rob


On Feb 18, 2010, at 12:47 PM, Douglas Bates wrote:

> By the way, the Mac OSX version is failing to build for a different
> reason.  It's another "twisty maze of include files" problem.
> 
> On Thu, Feb 18, 2010 at 2:38 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
>> On Thu, Feb 18, 2010 at 2:19 PM, Andrew Dolman <andydolman at gmail.com> wrote:
>>> Any chance of getting the compiled windows lme4a package? Or should I
>>> expect to see it on r-forge very soon?
>> 
>> I hope it will appear overnight on R-forge.  If not, I will follow up
>> with the R-forge maintainers and, if necessary, make a compiled
>> Windows binary from  win-builder available.
>> 
>> I can see on the SVN archive that the lme4a sources are at revision
>> 652.  (Windows compilations need revision 649 or later to succeed.) It
>> looks like the last attempt to build a Windows version was around
>> midnight CET yesterday, which is about 17:00 my time (CST).  I may
>> have committed my fixes for Windows after that.  Right now the archive
>> shows revision 649 as having been committed 23 hours ago.
>> 
>>>> 
>>>> By the way, I have been able to build the lme4a package for Windows on
>>>> Uwe's win-builder.r-project.org.  I checked the R-forge site for
>>>> packages this morning but they haven't been re-built since last week.
>>>> The latest SVN check-in that was built is revision 637 and the current
>>>> revision is 650.
>>>> 
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> 
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From isabella at ghement.ca  Thu Feb 18 22:53:31 2010
From: isabella at ghement.ca (Isabella Ghement)
Date: Thu, 18 Feb 2010 13:53:31 -0800
Subject: [R-sig-ME] Baseline + Follow-Up
In-Reply-To: <CEEDLPBNOCMDHIGPLIJLCEDGCHAA.isabella@ghement.ca>
Message-ID: <CEEDLPBNOCMDHIGPLIJLCEDHCHAA.isabella@ghement.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100218/ddaf68db/attachment.pl>

From bates at stat.wisc.edu  Fri Feb 19 00:20:08 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 18 Feb 2010 17:20:08 -0600
Subject: [R-sig-ME] lmer book draft
In-Reply-To: <EDC81757-2A43-45D6-B534-841E94F8D63F@me.com>
References: <201002181432.o1IEWL0G029626@defang9.it.ohio-state.edu>
	<40e66e0b1002180710s37bfd1bbred8259c22556c821@mail.gmail.com>
	<951234ac1002181219q386cfaacq44c9fa5a312bcb93@mail.gmail.com>
	<40e66e0b1002181238l427789e1j75a15fe4daa8eb6c@mail.gmail.com>
	<40e66e0b1002181247m70c86f74oa90b878ff2cc1211@mail.gmail.com>
	<EDC81757-2A43-45D6-B534-841E94F8D63F@me.com>
Message-ID: <40e66e0b1002181520i35a1478axab870eaaa370c34a@mail.gmail.com>

On Thu, Feb 18, 2010 at 3:30 PM, Rob Goedman <robjgoedman at me.com> wrote:
> Douglas,
>
> After my previous message I figured out how to work around the compile issue and
> have been able to get all 4 test scripts (for chapters 1, 2, 4 and 5) to work on MacOS
> SnowLeopard using 64 bit R.2.11 (but I think the same fix might also work on R.2.10,
> on Leopard and for 32 bit). It also required a later version of the Matrix package
> (available on R-forge).
>
> If someone needs help, they can just send me an email. It requires a temporary (just
> to install lme4a) change to a system file (alloca.h). I'm sure its not the final solution, but
> it seems to work for now.

Thanks Rob.  Indeed it is the problem with alloca.h that is hanging up
the compilation on Mac OSX.  The conflict is between a definition in
lme4utils.h, which does not have a prototype, and a definition in
header files downstream from the string header file, which does have a
prototype.

If you know an identifier for the compiler under Mac OSX that I can
use in an ifdef clause I will change that.  Not to worry if you don't,
I can check with Simon, or even grep through the R sources until I
find it.

An alternative, of course, it to remove that definition from a header
file that is included by C++ code.
> On Feb 18, 2010, at 12:47 PM, Douglas Bates wrote:
>
>> By the way, the Mac OSX version is failing to build for a different
>> reason. ?It's another "twisty maze of include files" problem.
>>
>> On Thu, Feb 18, 2010 at 2:38 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
>>> On Thu, Feb 18, 2010 at 2:19 PM, Andrew Dolman <andydolman at gmail.com> wrote:
>>>> Any chance of getting the compiled windows lme4a package? Or should I
>>>> expect to see it on r-forge very soon?
>>>
>>> I hope it will appear overnight on R-forge. ?If not, I will follow up
>>> with the R-forge maintainers and, if necessary, make a compiled
>>> Windows binary from ?win-builder available.
>>>
>>> I can see on the SVN archive that the lme4a sources are at revision
>>> 652. ?(Windows compilations need revision 649 or later to succeed.) It
>>> looks like the last attempt to build a Windows version was around
>>> midnight CET yesterday, which is about 17:00 my time (CST). ?I may
>>> have committed my fixes for Windows after that. ?Right now the archive
>>> shows revision 649 as having been committed 23 hours ago.
>>>
>>>>>
>>>>> By the way, I have been able to build the lme4a package for Windows on
>>>>> Uwe's win-builder.r-project.org. ?I checked the R-forge site for
>>>>> packages this morning but they haven't been re-built since last week.
>>>>> The latest SVN check-in that was built is revision 637 and the current
>>>>> revision is 650.
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



From bolker at ufl.edu  Fri Feb 19 16:47:20 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Fri, 19 Feb 2010 10:47:20 -0500
Subject: [R-sig-ME] offset in glmmPQL
In-Reply-To: <4B7D09CA.9020301@nib.si>
References: <4B7D09CA.9020301@nib.si>
Message-ID: <4B7EB288.9010900@ufl.edu>


  It's surprising that your example doesn't work, because this example
(which is a hidden example in the ?glmmPQL help page - it doesn't appear
when you type ?glmmPQL, but it gets run when you say example(glmmPQL))
does ...
	
library(MASS)
library(nlme)
 summary(glmmPQL(y ~ trt + week + offset(week), random = ~ 1 | ID,
                 family = binomial, data = bacteria))

  Can you provide a reproducible example of what doesn't work?

Maarten de Groot wrote:
> Dear all,
> 
> I have a small question about including an offset value into a glmmPQL 
> with a poisson distribution. I want to compare the number of songs of an 
> animal between treatments. Because the experiment time is not always the 
> same I want to include this as an offset in my formula 
> ("mod<-glmmPQL(nosongs~offset(experiment.time)+treatment,random=~1|block/malenr,family=poisson,data=mcrs)"). 
> 
> 
> However R seems not to recognize the command"offset" when using a glmmPQL.
> 
> Hopefully some one can help me.
> 
> Kind regards,
> 
> Maarten
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From to166 at columbia.edu  Fri Feb 19 17:23:10 2010
From: to166 at columbia.edu (Todd Ogden)
Date: Fri, 19 Feb 2010 11:23:10 -0500
Subject: [R-sig-ME] lme - incorporating measurement error with estimated V-C
	matrix
Message-ID: <B14203EC-5ACE-4873-907E-EE447D039ED6@columbia.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100219/f2cd1ab7/attachment.pl>

From bates at stat.wisc.edu  Fri Feb 19 17:34:37 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 19 Feb 2010 10:34:37 -0600
Subject: [R-sig-ME] Windows binary for the lme4a package?
Message-ID: <40e66e0b1002190834j7e71ebffwb34068fc5b084d4b@mail.gmail.com>

It looks to me as if the build of the Windows binary of the lme4a
package on R-forge succeeded last night.  Can anyone confirm that the
package can now be installed on Windows using the R-forge archive?



From andydolman at gmail.com  Fri Feb 19 17:41:51 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Fri, 19 Feb 2010 17:41:51 +0100
Subject: [R-sig-ME] Windows binary for the lme4a package?
In-Reply-To: <40e66e0b1002190834j7e71ebffwb34068fc5b084d4b@mail.gmail.com>
References: <40e66e0b1002190834j7e71ebffwb34068fc5b084d4b@mail.gmail.com>
Message-ID: <951234ac1002190841y62f0141fje8f23c30ef39e2eb@mail.gmail.com>

Yes it's working thank you.


andydolman at gmail.com



On 19 February 2010 17:34, Douglas Bates <bates at stat.wisc.edu> wrote:
> It looks to me as if the build of the Windows binary of the lme4a
> package on R-forge succeeded last night. ?Can anyone confirm that the
> package can now be installed on Windows using the R-forge archive?
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From gsaxer at rice.edu  Sat Feb 20 16:26:31 2010
From: gsaxer at rice.edu (Gerda Saxer)
Date: Sat, 20 Feb 2010 09:26:31 -0600
Subject: [R-sig-ME] (no subject)
Message-ID: <46AE1D9D-A25F-4C9E-86DB-D960BED05196@rice.edu>



Gerda



From cat.dev.urandom at gmail.com  Sat Feb 20 18:01:26 2010
From: cat.dev.urandom at gmail.com (D Chaws)
Date: Sat, 20 Feb 2010 12:01:26 -0500
Subject: [R-sig-ME] lme and prediction intervals
In-Reply-To: <dcf23fb81002180925o2a82d2a4xea95799c547753c5@mail.gmail.com>
References: <dcf23fb81002180925o2a82d2a4xea95799c547753c5@mail.gmail.com>
Message-ID: <dcf23fb81002200901ubda1508q4d3c5ff611cb3b5d@mail.gmail.com>

Dr. Bates, would you be able to weigh in on this?

On Thu, Feb 18, 2010 at 12:25 PM, D Chaws <cat.dev.urandom at gmail.com> wrote:
> Dear lme(r) users,
>
> I have seen this issue come up many times over the years, but haven't
> come across an answer as of yet.
> Take for example the growth model:
>
> fm1 <- lme(distance ~ age*Sex, random = ~ 1 + age | Subject, data = Orthodont)
>
> Distance increases with age, but more so in Males.
>
> I want to obtain the model predicted values of distance at each age
> (c(8,10,12,14)) for males and female separately to explore this
> interaction.
>
> So,
>
> newdat <- expand.grid(age=c(8,10,12,14), Sex=c("Male","Female"))
> newdat$pred <- predict(fm1, newdat, level = 0)
>
> R# newdat
>  age    Sex  pred
> 1   8   Male 22.62
> 2  10   Male 24.18
> 3  12   Male 25.75
> 4  14   Male 27.32
> 5   8 Female 21.21
> 6  10 Female 22.17
> 7  12 Female 23.13
> 8  14 Female 24.09
>
> Yup, males have a steeper increase with age than females.
>
> The question is, how to go about getting prediction intervals around
> these predictions.  It seems reasonable to need to know
> the precision of these predictions, and of course most journals
> require the reporting of error bars etc...  However, predict.lme
> doesn't
> have a se.fit or intervals argument.
>
> The only answer I have found at the moment is to use the design matrix
> and $varFix from the model.
>
> So,
>
> Designmat <- model.matrix(eval(eval(fm1$call$fixed)[-2]), newdat[-3])
> R# Designmat
>  (Intercept) age SexFemale age:SexFemale
> 1           1   8         0             0
> 2           1  10         0             0
> 3           1  12         0             0
> 4           1  14         0             0
> 5           1   8         1             8
> 6           1  10         1            10
> 7           1  12         1            12
> 8           1  14         1            14
>
> newdat$SE <- sqrt(diag(Designmat %*% fm1$varFix %*% t(Designmat)))
> R# newdat
>  age    Sex  pred     SE
> 1   8   Male 22.62 0.5265
> 2  10   Male 24.18 0.4848
> 3  12   Male 25.75 0.5021
> 4  14   Male 27.32 0.5730
> 5   8 Female 21.21 0.6350
> 6  10 Female 22.17 0.5847
> 7  12 Female 23.13 0.6056
> 8  14 Female 24.09 0.6910
>
> Are these true pointwise prediction intervals?
>
> Any help would be greatly appreciated.  I refuse to use SAS for this!
>
> -- D. Chaws
>



From bolker at ufl.edu  Sat Feb 20 22:08:37 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Sat, 20 Feb 2010 16:08:37 -0500
Subject: [R-sig-ME] [R-sig-eco] questio
In-Reply-To: <c3ffc6e11002200455v668bbe59ic6086fa43dc8af83@mail.gmail.com>
References: <c3ffc6e11002200455v668bbe59ic6086fa43dc8af83@mail.gmail.com>
Message-ID: <4B804F55.2040903@ufl.edu>

  [taking the liberty of forwarding my answer to r-sig-mixed-models]

Mariela Sued wrote:
>  I am a mathematician  trying to interact
> with biologists.
> 
> I am working with a generalized mixed model, for  counting response
ors > corresponding to a number of visits that
> certain birds make to their nests, in a period of time (giving rise to an
> offset).
> One  random effect, since I have several observations coming from the same
> nests.
> 
> I am trying to present a multimodel approach (Burnham and Anderson). After
> reading the following phrase, I decide to ask for some help.
> 
> "First, AIC can be generalized to random-effects models, ultimately probably
> in way better than given here."
> 
> What would you suggest to use as AIC in this case?
> AIC? QAIC? QAIC_c?

  Well, QAIC is really for handling overdispersion in the residuals;
'corrected' (_c) versions of AIC are for handling finite-sample-size
corrections (AIC makes various asymptotic assumptions).  So the answers
depend on whether your data are (a) overdispersed, once you have
incorporated known grouping factors & covariates; (b) 'small' (while B&A
recommend always using corrected variants of AIC, they do also give a
rule of thumb of it being especially useful when (# obs)/(# parameters)
< 40.

  The biggest difficulty with using AIC for random-effects models is
parameter counting -- how many effective parameters/degrees of freedom
does a random effect represent?  Vaida and Blanchard (2005) offer a
useful perspective.  The bottom line: (A) *if* you are (1) not trying to
model-average over models with and without a particular random effect
and (2) not using a 'corrected' variant of AIC (where "# of residual
degrees of freedom" is incorporated in the penalty term), then the issue
doesn't come up.  (B) if you are interested in expected predictive
ability *at the level of the population* then random effects can be
counted as the number of variance parameters.  (C) if you are interested
in predictive ability at the level of random-effects units, see Vaida
and Blanchard 2005.  See also Bolker et al (2009) Trends in Ecology and
Evolution ...

> 
> On the other hand, using lmer or glmmMl I obtain different results  for the
> AIC.

  That is most likely because different additive constants are included
in each case.  If the log-likelihoods are different, that's more
interesting (but hard to diagnose without more details).

> Any suggestion?
> thanks for your attention
> Mariela
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-ecology mailing list
> R-sig-ecology at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-ecology


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From bolker at ufl.edu  Sat Feb 20 22:27:39 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Sat, 20 Feb 2010 16:27:39 -0500
Subject: [R-sig-ME] lme and prediction intervals
In-Reply-To: <dcf23fb81002200901ubda1508q4d3c5ff611cb3b5d@mail.gmail.com>
References: <dcf23fb81002180925o2a82d2a4xea95799c547753c5@mail.gmail.com>
	<dcf23fb81002200901ubda1508q4d3c5ff611cb3b5d@mail.gmail.com>
Message-ID: <4B8053CB.3000908@ufl.edu>

  As I believe someone else commented, these seem to be confidence
intervals (conditional on random effects estimates) and not prediction
intervals.  To get prediction intervals (I think) you would need to
incorporate the residual variance: see below.

library(nlme)
fm1 <- lme(distance ~ age*Sex, random = ~ 1 + age | Subject,
           data = Orthodont)
plot(Orthodont)

newdat <- expand.grid(age=c(8,10,12,14), Sex=c("Male","Female"))
newdat$pred <- predict(fm1, newdat, level = 0)

Designmat <- model.matrix(eval(eval(fm1$call$fixed)[-2]), newdat[-3])
predvar <- diag(Designmat %*% fm1$varFix %*% t(Designmat))
newdat$SE <- sqrt(predvar)
newdat$SE2 <- sqrt(predvar+fm1$sigma^2)

library(ggplot2)
pd <- position_dodge(width=0.4)
ggplot(newdat,aes(x=age,y=pred,colour=Sex))+
  geom_point(position=pd)+
  geom_linerange(aes(ymin=pred-2*SE,ymax=pred+2*SE),
                 position=pd)

## prediction intervals
ggplot(newdat,aes(x=age,y=pred,colour=Sex))+
  geom_point(position=pd)+
  geom_linerange(aes(ymin=pred-2*SE2,ymax=pred+2*SE2),
                 position=pd)


D Chaws wrote:
> Dr. Bates, would you be able to weigh in on this?
> 
> On Thu, Feb 18, 2010 at 12:25 PM, D Chaws <cat.dev.urandom at gmail.com> wrote:
>> Dear lme(r) users,
>>
>> I have seen this issue come up many times over the years, but haven't
>> come across an answer as of yet.
>> Take for example the growth model:
>>
>> fm1 <- lme(distance ~ age*Sex, random = ~ 1 + age | Subject, data = Orthodont)
>>
>> Distance increases with age, but more so in Males.
>>
>> I want to obtain the model predicted values of distance at each age
>> (c(8,10,12,14)) for males and female separately to explore this
>> interaction.
>>
>> So,
>>
>> newdat <- expand.grid(age=c(8,10,12,14), Sex=c("Male","Female"))
>> newdat$pred <- predict(fm1, newdat, level = 0)
>>
>> R# newdat
>>  age    Sex  pred
>> 1   8   Male 22.62
>> 2  10   Male 24.18
>> 3  12   Male 25.75
>> 4  14   Male 27.32
>> 5   8 Female 21.21
>> 6  10 Female 22.17
>> 7  12 Female 23.13
>> 8  14 Female 24.09
>>
>> Yup, males have a steeper increase with age than females.
>>
>> The question is, how to go about getting prediction intervals around
>> these predictions.  It seems reasonable to need to know
>> the precision of these predictions, and of course most journals
>> require the reporting of error bars etc...  However, predict.lme
>> doesn't
>> have a se.fit or intervals argument.
>>
>> The only answer I have found at the moment is to use the design matrix
>> and $varFix from the model.
>>
>> So,
>>
>> Designmat <- model.matrix(eval(eval(fm1$call$fixed)[-2]), newdat[-3])
>> R# Designmat
>>  (Intercept) age SexFemale age:SexFemale
>> 1           1   8         0             0
>> 2           1  10         0             0
>> 3           1  12         0             0
>> 4           1  14         0             0
>> 5           1   8         1             8
>> 6           1  10         1            10
>> 7           1  12         1            12
>> 8           1  14         1            14
>>
>> newdat$SE <- sqrt(diag(Designmat %*% fm1$varFix %*% t(Designmat)))
>> R# newdat
>>  age    Sex  pred     SE
>> 1   8   Male 22.62 0.5265
>> 2  10   Male 24.18 0.4848
>> 3  12   Male 25.75 0.5021
>> 4  14   Male 27.32 0.5730
>> 5   8 Female 21.21 0.6350
>> 6  10 Female 22.17 0.5847
>> 7  12 Female 23.13 0.6056
>> 8  14 Female 24.09 0.6910
>>
>> Are these true pointwise prediction intervals?
>>
>> Any help would be greatly appreciated.  I refuse to use SAS for this!
>>
>> -- D. Chaws
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From renaud.lancelot at cirad.fr  Sun Feb 21 11:44:21 2010
From: renaud.lancelot at cirad.fr (lancelot)
Date: Sun, 21 Feb 2010 11:44:21 +0100
Subject: [R-sig-ME] Windows binary for the lme4a package?
In-Reply-To: <40e66e0b1002190834j7e71ebffwb34068fc5b084d4b@mail.gmail.com>
References: <40e66e0b1002190834j7e71ebffwb34068fc5b084d4b@mail.gmail.com>
Message-ID: <4B810E85.2010606@cirad.fr>

I was able to download and install 
http://R-Forge.R-project.org/bin/windows/contrib/2.10/lme4a_0.999375-45.zip

Douglas Bates a ?crit :
> It looks to me as if the build of the Windows binary of the lme4a
> package on R-forge succeeded last night.  Can anyone confirm that the
> package can now be installed on Windows using the R-forge archive?
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
Renaud Lancelot
EDEN Project, coordinator
http://www.eden-fp6project.net/
<< EDEN International Conference, Montpellier,  10-12 May 2010 >>
<<   http://international-conference2010.eden-fp6project.net/  >>

UMR CIRAD-INRA "Contr?le des maladies animales exotiques et ?mergentes"
Joint research unit "Control of emerging and exotic animal diseases"

CIRAD, Campus International de Baillarguet TA A-DIR / B
F34398 Montpellier
http://umr-cmaee.cirad.fr/

Tel.  +33 4 67 59 37 17  -  Fax  +33 4 67 59 37 95
Secr. +33 4 67 59 37 37  - Cell. +33 6 77 52 08 69



From b.pelzer at maw.ru.nl  Mon Feb 22 16:25:40 2010
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Mon, 22 Feb 2010 16:25:40 +0100
Subject: [R-sig-ME] laplace deviance crossed factors glm
Message-ID: <4B82A1F4.5060703@maw.ru.nl>

Dear all,

Recently I ran into a counterintuitive result related to the Laplace 
deviance value produced by lmer for a logistic regression model.

For logistic regression models, one of the methods lmer can use to 
derive an (approximate) deviance value, is
called 'Laplace approximation'. As explained in the lmer package's pdf, 
this Laplace deviance is equal to the deviance that one would obtain 
when using the 'adaptive Gaus-Hermite quadrature' (AGQ) with only 1 
sample point. However, with AGQ one can use more sample points to 
increase the precision of the approximation to the true deviance. Hence, 
the Laplace deviance is 'worse' than the AGQ deviance that uses, say, 
five sample points. So far so good.

My question now is, in how far it is safe to use the Laplace deviance to 
compare the fit of two nested glm models. Realizing that the Laplace
deviance can be pretty rough, the Laplace deviance difference between 
two nested models may not be as nicely chisquare distributed as we would 
like it to be. Is there literature on this subject?

This question was inspired by running a  model, in which two random 
factors A and B are crossed, having 214 and 40 levels, respectively. For 
each (A,B)  combination there is exactly 1 observation in my data, so 
random interaction of A and B cannot be modeled. In total there 214 * 40 
minus 1 = 8559 observations, the "minus 1" caused by the fact that  for 
1 particular (A,B) combination the dependent Y is missing.

The nice thing about the Laplace approximation method is that it can be 
applied to such cross-factorial glm models, while AGQ (with more than 1 
quadr. point) cannot. However, comparing the deviances of two nested 
cross-factorial models, I discovered that the more restricted model has 
a smaller (closer to zero) deviance, than the full model! This doesn't 
make sense, of course. There appear to be no convergence problems, the 
models being relatively simple.

The restricted and full model differ as follows. There are two 
(independent) groups of observations in the data, the indicator 
variables (0/1) gr1 and gr2 indicating the group to which an 
observations belongs. In the full model, the random effect variances of 
A and B are allowed to vary across the two groups, so in total there are 
4 variances to be estimated,  var(A) for group 1, var(A) for group 2, 
var(B) for group 1 and var(B) group 2.  In the restricted model, both 
groups have the same random effect variance for A, but each group has a 
different variance for B, so there are three variances to be estimated 
now, var(A), var(B) for group 1 and var(B) for group 2. In R syntax:

# full model; deviance = 7095.
M1 <- lmer (Y ~  1  +  (gr1+0|A)  +  (gr2+0|A)  +  (gr1+0|B)  +  
(gr2+0|B)  +  gr1,
                    family=binomial(link="logit"), reml=FALSE)

# restricted model; deviance = 7076.
M2 <- lmer (Y ~ 1  +  (gr1+0|A)  +  (gr2+0|A)  +  (1|B)  +  gr1,
                     family=binomial(link="logit"), reml=FALSE)

Now I'm wondering where the unexpected reduction of the deviance may 
come from. Could this be related to the fact that, for comparing nested 
models,  the Laplace deviance should not be used? Or am I simply 
overlooking something which has nothing to do with the Laplace deviance 
at all? Any tip would be greatly appreciated. Kind regards,

Ben



From bates at stat.wisc.edu  Mon Feb 22 17:07:17 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 22 Feb 2010 10:07:17 -0600
Subject: [R-sig-ME] laplace deviance crossed factors glm
In-Reply-To: <4B82A1F4.5060703@maw.ru.nl>
References: <4B82A1F4.5060703@maw.ru.nl>
Message-ID: <40e66e0b1002220807l38aed234xf1d198b33835a8fa@mail.gmail.com>

On Mon, Feb 22, 2010 at 9:25 AM, Ben Pelzer <b.pelzer at maw.ru.nl> wrote:
> Dear all,
>
> Recently I ran into a counterintuitive result related to the Laplace
> deviance value produced by lmer for a logistic regression model.
>
> For logistic regression models, one of the methods lmer can use to derive an
> (approximate) deviance value, is
> called 'Laplace approximation'. As explained in the lmer package's pdf, this
> Laplace deviance is equal to the deviance that one would obtain when using
> the 'adaptive Gaus-Hermite quadrature' (AGQ) with only 1 sample point.
> However, with AGQ one can use more sample points to increase the precision
> of the approximation to the true deviance. Hence, the Laplace deviance is
> 'worse' than the AGQ deviance that uses, say, five sample points. So far so
> good.
>
> My question now is, in how far it is safe to use the Laplace deviance to
> compare the fit of two nested glm models. Realizing that the Laplace
> deviance can be pretty rough, the Laplace deviance difference between two
> nested models may not be as nicely chisquare distributed as we would like it
> to be. Is there literature on this subject?
>
> This question was inspired by running a ?model, in which two random factors
> A and B are crossed, having 214 and 40 levels, respectively. For each (A,B)
> ?combination there is exactly 1 observation in my data, so random
> interaction of A and B cannot be modeled. In total there 214 * 40 minus 1 =
> 8559 observations, the "minus 1" caused by the fact that ?for 1 particular
> (A,B) combination the dependent Y is missing.
>
> The nice thing about the Laplace approximation method is that it can be
> applied to such cross-factorial glm models, while AGQ (with more than 1
> quadr. point) cannot. However, comparing the deviances of two nested
> cross-factorial models, I discovered that the more restricted model has a
> smaller (closer to zero) deviance, than the full model! This doesn't make
> sense, of course. There appear to be no convergence problems, the models
> being relatively simple.
>
> The restricted and full model differ as follows. There are two (independent)
> groups of observations in the data, the indicator variables (0/1) gr1 and
> gr2 indicating the group to which an observations belongs. In the full
> model, the random effect variances of A and B are allowed to vary across the
> two groups, so in total there are 4 variances to be estimated, ?var(A) for
> group 1, var(A) for group 2, var(B) for group 1 and var(B) group 2. ?In the
> restricted model, both groups have the same random effect variance for A,
> but each group has a different variance for B, so there are three variances
> to be estimated now, var(A), var(B) for group 1 and var(B) for group 2. In R
> syntax:
>
> # full model; deviance = 7095.
> M1 <- lmer (Y ~ ?1 ?+ ?(gr1+0|A) ?+ ?(gr2+0|A) ?+ ?(gr1+0|B) ?+ ?(gr2+0|B)
> ?+ ?gr1,
> ? ? ? ? ? ? ? ? ? family=binomial(link="logit"), reml=FALSE)
>
> # restricted model; deviance = 7076.
> M2 <- lmer (Y ~ 1 ?+ ?(gr1+0|A) ?+ ?(gr2+0|A) ?+ ?(1|B) ?+ ?gr1,
> ? ? ? ? ? ? ? ? ? ?family=binomial(link="logit"), reml=FALSE)

Those models don't appear to be nested.  The second model has a
random-effects term (1|B) and I don't see such a term in the first
model.

(By the way, the argument name is "REML", not "reml" and it is
unnecessary to provide it to a generalized linear mixed model.)
> Now I'm wondering where the unexpected reduction of the deviance may come
> from. Could this be related to the fact that, for comparing nested models,
> ?the Laplace deviance should not be used? Or am I simply overlooking
> something which has nothing to do with the Laplace deviance at all? Any tip
> would be greatly appreciated. Kind regards,
>
> Ben
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From arendahl at stat.umn.edu  Mon Feb 22 18:29:22 2010
From: arendahl at stat.umn.edu (Aaron Rendahl)
Date: Mon, 22 Feb 2010 11:29:22 -0600
Subject: [R-sig-ME] pedigreemm with one observation per individual
In-Reply-To: <Pine.LNX.4.64.1002120718250.19700@orpheus.qimr.edu.au>
References: <3f7256361002100847rc987980xc2884dbcda536e69@mail.gmail.com>
	<Pine.LNX.4.64.1002110741010.20189@orpheus.qimr.edu.au>
	<3f7256361002111202w5e99a2b0g7a0dcf507fa8bedc@mail.gmail.com>
	<Pine.LNX.4.64.1002120718250.19700@orpheus.qimr.edu.au>
Message-ID: <3f7256361002220929h26ade3e7w16386cf05ca0d171@mail.gmail.com>

When trying to fit a mixed model using pedigreemm (which uses lme4)
with only one observation per individual, lme4 gives an error that the
"Number of levels of a grouping factor for the random effects must be
less than the number of observations"; which is not necessarily true
when modeling relationships between the individuals.

David Duffy suggested the kinship package, but in an off-list email,
commented on the need to get pedigreemm working, as kinship is much
slower because it uses nlme instead of lme4.

Here is a somewhat crude fix; it adds an additional parameter
(checklevels) to the lmer_finalize and glmer_finalize functions in
lme4 that turns off the unwanted sanity check.  The default is
checklevels=TRUE, which maintains the previous behavior.  The
pedigreemm function is then changed to set checklevels=FALSE before
calling the appropriate finalizing function.  I'm running these
changes locally and they seem to work fine.

Comments or suggestions are welcome, as is consideration of this
change or some variant on it for inclusion in the pedigreemm and lme4
packages.


----- in lmer.R in the lme4 package -----
lmer_finalize <- function(fr, FL, start, REML, verbose, checklevels=TRUE)
{
...
### This checks that the number of levels in a grouping factor < n
### Only need to check the first factor because it is the one with
### the most levels.
    if (checklevels & !(length(levels(dm$flist[[1]])) < length(Y)))
...

glmer_finalize <- function(fr, FL, glmFit, start, nAGQ, verbose,
checklevels=TRUE)
{
...
### This checks that the number of levels in a grouping factor < n
### Only need to check the first factor because it is the one with
### the most levels.
    if (checklevels & !(length(levels(dm$flist[[1]])) < ncol(dm$Zt)))
...

----- in pedigree.R in the pedigreemm package -----
pedigreemm <-
    function(formula, data, family = NULL, REML = TRUE, pedigree = list(),
...
    lmf$checklevels <- FALSE;
    ans <- do.call(if (!is.null(lmf$glmFit)) lme4:::glmer_finalize
else lme4:::lmer_finalize, lmf)
...



-- 
Aaron Rendahl, Ph.D.
Statistical Consulting Manager
School of Statistics, University of Minnesota

NEW OFFICE (as of June 2009):
48C McNeal Hall, St. Paul Campus
612-625-1062
www.stat.umn.edu/consulting



From bolker at ufl.edu  Mon Feb 22 23:05:35 2010
From: bolker at ufl.edu (Bolker,Benjamin Michael)
Date: Mon, 22 Feb 2010 17:05:35 -0500
Subject: [R-sig-ME] pedigreemm with one observation per individual
In-Reply-To: <3f7256361002220929h26ade3e7w16386cf05ca0d171@mail.gmail.com>
References: <3f7256361002100847rc987980xc2884dbcda536e69@mail.gmail.com>
	<Pine.LNX.4.64.1002110741010.20189@orpheus.qimr.edu.au>
	<3f7256361002111202w5e99a2b0g7a0dcf507fa8bedc@mail.gmail.com>
	<Pine.LNX.4.64.1002120718250.19700@orpheus.qimr.edu.au>,
	<3f7256361002220929h26ade3e7w16386cf05ca0d171@mail.gmail.com>
Message-ID: <AC6F23A2BA13C347A59BDCBCFF41E27B614C9A4CD0@UFEXCH-MBXCL03.ad.ufl.edu>


  It would be nice if this could go into the main lme4 (or lme4a?) branch -- even nicer if it could be passed through from [g]lmer -- as mentioned before, there are legitimate cases for this (modeling overdispersion at the individual level ...) ... 
________________________________________
From: r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] On Behalf Of Aaron Rendahl [arendahl at stat.umn.edu]
Sent: Monday, February 22, 2010 12:29 PM
To: David Duffy
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] pedigreemm with one observation per individual

When trying to fit a mixed model using pedigreemm (which uses lme4)
with only one observation per individual, lme4 gives an error that the
"Number of levels of a grouping factor for the random effects must be
less than the number of observations"; which is not necessarily true
when modeling relationships between the individuals.

David Duffy suggested the kinship package, but in an off-list email,
commented on the need to get pedigreemm working, as kinship is much
slower because it uses nlme instead of lme4.

Here is a somewhat crude fix; it adds an additional parameter
(checklevels) to the lmer_finalize and glmer_finalize functions in
lme4 that turns off the unwanted sanity check.  The default is
checklevels=TRUE, which maintains the previous behavior.  The
pedigreemm function is then changed to set checklevels=FALSE before
calling the appropriate finalizing function.  I'm running these
changes locally and they seem to work fine.

Comments or suggestions are welcome, as is consideration of this
change or some variant on it for inclusion in the pedigreemm and lme4
packages.


----- in lmer.R in the lme4 package -----
lmer_finalize <- function(fr, FL, start, REML, verbose, checklevels=TRUE)
{
...
### This checks that the number of levels in a grouping factor < n
### Only need to check the first factor because it is the one with
### the most levels.
    if (checklevels & !(length(levels(dm$flist[[1]])) < length(Y)))
...

glmer_finalize <- function(fr, FL, glmFit, start, nAGQ, verbose,
checklevels=TRUE)
{
...
### This checks that the number of levels in a grouping factor < n
### Only need to check the first factor because it is the one with
### the most levels.
    if (checklevels & !(length(levels(dm$flist[[1]])) < ncol(dm$Zt)))
...

----- in pedigree.R in the pedigreemm package -----
pedigreemm <-
    function(formula, data, family = NULL, REML = TRUE, pedigree = list(),
...
    lmf$checklevels <- FALSE;
    ans <- do.call(if (!is.null(lmf$glmFit)) lme4:::glmer_finalize
else lme4:::lmer_finalize, lmf)
...



--
Aaron Rendahl, Ph.D.
Statistical Consulting Manager
School of Statistics, University of Minnesota

NEW OFFICE (as of June 2009):
48C McNeal Hall, St. Paul Campus
612-625-1062
www.stat.umn.edu/consulting

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From C.Millar at MARLAB.AC.UK  Mon Feb 22 23:29:40 2010
From: C.Millar at MARLAB.AC.UK (Colin Millar)
Date: Mon, 22 Feb 2010 22:29:40 -0000
Subject: [R-sig-ME] pedigreemm with one observation per individual
References: <3f7256361002100847rc987980xc2884dbcda536e69@mail.gmail.com><Pine.LNX.4.64.1002110741010.20189@orpheus.qimr.edu.au><3f7256361002111202w5e99a2b0g7a0dcf507fa8bedc@mail.gmail.com><Pine.LNX.4.64.1002120718250.19700@orpheus.qimr.edu.au>,
	<3f7256361002220929h26ade3e7w16386cf05ca0d171@mail.gmail.com>
	<AC6F23A2BA13C347A59BDCBCFF41E27B614C9A4CD0@UFEXCH-MBXCL03.ad.ufl.edu>
Message-ID: <A0F8DAFB525DED4ABAF6841BB11C5812018F80C0@mail4.marlab.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100222/4738f205/attachment.pl>

From David.Duffy at qimr.edu.au  Tue Feb 23 01:00:37 2010
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Tue, 23 Feb 2010 10:00:37 +1000 (EST)
Subject: [R-sig-ME] pedigreemm with one observation per individual
In-Reply-To: <A0F8DAFB525DED4ABAF6841BB11C5812018F80C0@mail4.marlab.ac.uk>
References: <3f7256361002100847rc987980xc2884dbcda536e69@mail.gmail.com><Pine.LNX.4.64.1002110741010.20189@orpheus.qimr.edu.au><3f7256361002111202w5e99a2b0g7a0dcf507fa8bedc@mail.gmail.com><Pine.LNX.4.64.1002120718250.19700@orpheus.qimr.edu.au>,
	<3f7256361002220929h26ade3e7w16386cf05ca0d171@mail.gmail.com>
	<AC6F23A2BA13C347A59BDCBCFF41E27B614C9A4CD0@UFEXCH-MBXCL03.ad.ufl.edu>
	<A0F8DAFB525DED4ABAF6841BB11C5812018F80C0@mail4.marlab.ac.uk>
Message-ID: <Pine.LNX.4.64.1002230935430.23348@orpheus.qimr.edu.au>

On Mon, 22 Feb 2010, Colin Millar wrote:

> My two pence worth: I would agree.  We have used a similar trick when 
> modelling overdispersed poisson counts.  We tried using the quasipoisson 
> family but it didn't give sensible results - it seems to return the mean 
> as the residual variance component.  On that note it would be useful if 
> the use of quasipoisson was not allowed or a warning was given for the 
> unsuspecting user.

Model identifiability is a hard problem ;) It is hard in the SEM context, 
where one has summary covariance matrices so you can count observed 
statistics and compare this to the number of model parameters, but it's 
harder still for "raw" model fitting.  But, yes, lmer() should have a 
"no checking" mode for the fool^H^H^H^Hexperienced user.

Maybe lmer needs an automatic random restart option, though such things 
often require so much specification of constraints on the permitted 
starting values that it is easier just to restart by hand.

> Aaron Rendahl wrote:
> Here is a somewhat crude fix; it adds an additional parameter
> (checklevels) to the lmer_finalize and glmer_finalize functions in
> lme4 that turns off the unwanted sanity check.  The default is
> checklevels=TRUE, which maintains the previous behavior.  The
> pedigreemm function is then changed to set checklevels=FALSE before
> calling the appropriate finalizing function.  I'm running these
> changes locally and they seem to work fine.

Another 2c, David Duffy.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From b.pelzer at maw.ru.nl  Tue Feb 23 10:46:23 2010
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Tue, 23 Feb 2010 10:46:23 +0100
Subject: [R-sig-ME] laplace deviance crossed factors glm
In-Reply-To: <40e66e0b1002220807l38aed234xf1d198b33835a8fa@mail.gmail.com>
References: <4B82A1F4.5060703@maw.ru.nl>
	<40e66e0b1002220807l38aed234xf1d198b33835a8fa@mail.gmail.com>
Message-ID: <4B83A3EF.3030102@maw.ru.nl>

Dear Douglas,

Thanks for your prompt reply, no nesting indeed! I now realize that a 
single variance term for both groups can lead to a better fit (smaller 
deviance) than two different variances, one for each group. At first 
thought this seemed counterintuitive to me. Regards,

Ben.



Op 22-2-2010 17:07, Douglas Bates schreef:
> On Mon, Feb 22, 2010 at 9:25 AM, Ben Pelzer<b.pelzer at maw.ru.nl>  wrote:
>> Dear all,
>>
>> Recently I ran into a counterintuitive result related to the Laplace
>> deviance value produced by lmer for a logistic regression model.
>>
>> For logistic regression models, one of the methods lmer can use to derive an
>> (approximate) deviance value, is
>> called 'Laplace approximation'. As explained in the lmer package's pdf, this
>> Laplace deviance is equal to the deviance that one would obtain when using
>> the 'adaptive Gaus-Hermite quadrature' (AGQ) with only 1 sample point.
>> However, with AGQ one can use more sample points to increase the precision
>> of the approximation to the true deviance. Hence, the Laplace deviance is
>> 'worse' than the AGQ deviance that uses, say, five sample points. So far so
>> good.
>>
>> My question now is, in how far it is safe to use the Laplace deviance to
>> compare the fit of two nested glm models. Realizing that the Laplace
>> deviance can be pretty rough, the Laplace deviance difference between two
>> nested models may not be as nicely chisquare distributed as we would like it
>> to be. Is there literature on this subject?
>>
>> This question was inspired by running a  model, in which two random factors
>> A and B are crossed, having 214 and 40 levels, respectively. For each (A,B)
>>   combination there is exactly 1 observation in my data, so random
>> interaction of A and B cannot be modeled. In total there 214 * 40 minus 1 =
>> 8559 observations, the "minus 1" caused by the fact that  for 1 particular
>> (A,B) combination the dependent Y is missing.
>>
>> The nice thing about the Laplace approximation method is that it can be
>> applied to such cross-factorial glm models, while AGQ (with more than 1
>> quadr. point) cannot. However, comparing the deviances of two nested
>> cross-factorial models, I discovered that the more restricted model has a
>> smaller (closer to zero) deviance, than the full model! This doesn't make
>> sense, of course. There appear to be no convergence problems, the models
>> being relatively simple.
>>
>> The restricted and full model differ as follows. There are two (independent)
>> groups of observations in the data, the indicator variables (0/1) gr1 and
>> gr2 indicating the group to which an observations belongs. In the full
>> model, the random effect variances of A and B are allowed to vary across the
>> two groups, so in total there are 4 variances to be estimated,  var(A) for
>> group 1, var(A) for group 2, var(B) for group 1 and var(B) group 2.  In the
>> restricted model, both groups have the same random effect variance for A,
>> but each group has a different variance for B, so there are three variances
>> to be estimated now, var(A), var(B) for group 1 and var(B) for group 2. In R
>> syntax:
>>
>> # full model; deviance = 7095.
>> M1<- lmer (Y ~  1  +  (gr1+0|A)  +  (gr2+0|A)  +  (gr1+0|B)  +  (gr2+0|B)
>>   +  gr1,
>>                    family=binomial(link="logit"), reml=FALSE)
>>
>> # restricted model; deviance = 7076.
>> M2<- lmer (Y ~ 1  +  (gr1+0|A)  +  (gr2+0|A)  +  (1|B)  +  gr1,
>>                     family=binomial(link="logit"), reml=FALSE)
>
> Those models don't appear to be nested.  The second model has a
> random-effects term (1|B) and I don't see such a term in the first
> model.
>
> (By the way, the argument name is "REML", not "reml" and it is
> unnecessary to provide it to a generalized linear mixed model.)
>> Now I'm wondering where the unexpected reduction of the deviance may come
>> from. Could this be related to the fact that, for comparing nested models,
>>   the Laplace deviance should not be used? Or am I simply overlooking
>> something which has nothing to do with the Laplace deviance at all? Any tip
>> would be greatly appreciated. Kind regards,
>>
>> Ben
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>



From frederic.gosselin at cemagref.fr  Tue Feb 23 16:08:05 2010
From: frederic.gosselin at cemagref.fr (Gosselin Frederic)
Date: Tue, 23 Feb 2010 16:08:05 +0100
Subject: [R-sig-ME] lme4 and calculating QAICc
Message-ID: <D74CFE08A4F86B45870D14844A636E900138A68A@murier.nogent.cemagref.fr>


Dear R-helpers,

some -late- reactions on the dicussion between Marcus Rowcliffe & Ben Bolker:

Marcus Rowcliffe wrote:
> Many thanks Ben
> 
> The squaring of the scale parameter is a bit of a surprise! It seems 
> to give sensible results (see below *), but I can't immediately see 
> why it's necessary - is there an obvious explanation?

Ben Bolker answered:
>  Because c-hat is supposed to be on the same scale as the deviance -- the deviance is essentially on a variance, or 
> sum-of-squares scale, not a standard deviation/root-mean-square scale.  @sigma is defined as a standard deviation, not
> a variance.

>  For what it's worth, Doug Bates has said in the past that he's not
> *sure* that sigma really corresponds to the same quantity that we would want to use as sqrt(c-hat) -- it seems 
> reasonable, but no-one to my knowledge has either sat down and worked through it carefully *or* tested with
>simulations.
> Any comment/insight appreciated.

I actually sent an e-mail directly to Ben Bolker on these issue earlier this year, reaching the same conclusion that the scale parameter should be squared. Here was my rationale:


> I however went to question this choice: indeed, sigma is a standard 
> deviation, whereas if I understand Burnham & Anderson books correctly 
> (pp.68-69), c-hat should rather be a variance (seen both through its 
> effect on the variance estimators and on the way c-hat is calculated 
> from the chi square statistic). Then: shouldn't we use the square of 
> the sigma, and not sigma itsel: i.e.:
> 
> phi = (lme4:::sigma(mq1))^2
> 
> ? This should correspond to the variance parameter of the "Residual"
> line in the summary of the lmer function.


I however agree with Ben Bolker's remark that this should be studied more closely.

Marcus Rowcliffe wrote:
> 2.	Comparing poisson and quasipoisson models, I note that the
> former has no residual random variance, and hence one fewer degrees of 
> freedom than the quasipoisson. Why is this? It obviously has important 
> implications for the QAIC calculation.

Ben Bolker replied:
>  I find this a bit difficult myself.  Technically, it's another 'estimated parameter', but it's a nuisance parameter 
> that does *not* affect the predictions at all (it is simply calculated from the residuals of the model), so I'm not 
> really sure whether it should affect the estimate of expected Kullback-Leibler distance or not ... however, I would 
> quibble a little bit with "important implications for the QAIC calculation" -- it's just 1 degree of freedom!  To 
> quote _Numerical Recipes in C_ 2d ed. p. 611 (Press et al): "We might also comment that if the difference between N 
> and N-1 ever matters to you, then you are probably up to no good anyway -- e.g., trying to substantiate a questionable 
> hypothesis with marginal data.")

I also suggested this in my former message to Ben Bolker. Burnham & Anderson (2002, p.69) specify that we should include the dispersion parameter in the number of parameters used in the QAIC/AIC formula. Surely the quotation from Numerical Recipes in C has a part of truth. However, a Bayesian might have a different perspective on the link between the estimation of the nuisance parameter and the precision of the predictions. I would therefore rather add an extra parameter when changing from Poisson to quasi-Poisson...

I join at the end of the message a proposal of program for the calculus of QAIC for different kinds of mixed models, under different versions of R and probably also for S-Plus: any remark is welcome. This refers to another AIC.lme program that I can also share. I also have ones for QAICc and QAICu.


Two final remarks on quasi-likelihoods:
	(i) take care of the version of R on which you use it: http://markmail.org/message/s4abxhhdacqjkunm

	(ii) the case of under-dispersed data relative to the Poisson distribution is not clear:  Burnham & Anderson (2002, p.69) say that in such cases we should take c-hat=1 (or dispersion parameter), with no reason why. I personnally keep the calculated sigma in the calculus of the QAIC below. Here too some more work is needed.

All the best,
 
Fr?d?ric Gosselin
Engineer & Researcher (PhD) in Forest Ecology
Cemagref
Domaine des Barres
F-45290 Nogent sur Vernisson
France




***********************************************************************************************************************************************************************************************************************************************

"QAIC.lme"<-
function(x, c = NULL,mod.df = 0,mod.N=0)
{
	
	#number of parameters should include the estimated dispersion (Bunrham & Anderson 2002, p.69)
	# (c being fixed for a class of models to be compared; cf. Venables & Ripley)
	#mod.df and mod.N are for "manual" modifications of the numbers of degrees of freedom or numbers of observations
	if(!is.element(class(x), c("glmer","lmer","mer", "nlme", "gls", "gnls"))) stop(
			"Object x not lmer, nlme, gls or gnls")
if (is.null(c))
{
if ((is.null(c))& (!is.null(attributes(x)$dev["sigmaML"])))
{
c<-attributes(x)$dev["sigmaML"]^2
}
else
{
if ((is.null(c))& (!is.null(attributes(summary(x))$devComp["scale"])))
{
c<-attributes(summary(x))$devComp["scale"]^2
}
else
{
if ((is.null(c))& (!is.null(attributes(summary(x))$sigma)))
{
c<-attributes(summary(x))$sigma^2
}

else
{

}
}
}
}

if (!is.element(class(x), c("glmer","lmer","mer"))){K <- attributes(logLik(x))$df + mod.df} else {K <- attributes(logLik(x))$df + mod.df}

if (is.R())
{#adding 1 in this case because in these old versions the estimation of the dispersion parameter/innermost variance is not included in the count; unclear how it works for R2.6...
if (as.double(R.Version()$minor)<7.0&c!=1&is.element(class(x), c("glmer","lmer","mer"))){K<-K+1}}


#n<-attributes(logLik(x))$nall
if(!is.element(class(x), c("glmer","lmer","mer"))){n <- x$dims$N+mod.N
if(x$method == "REML") {
print("Object x fitted with REML; take care that models have similar fixed effects and contrasts before comparing them with AIC"
)}} else {n <- attributes(logLik(x))$nall+mod.N}




#here, we will only divide the logLik by the "dispersion parameter" (a variance) if this is a quasi binomial or Poisson (and not a general gaussian like quasi)
correct.logLik<-F
if (is.R())
{
family.ref<-attributes(summary(x))$family
if (is.null(family.ref)){family.ref<-paste(as.character(attributes(summary(x))$call),sep=" ")}
if (!is.null(family.ref)){
if (max(c(max(sapply(family.ref,function(x){if(is.character(x)){regexpr("quasi",x)>0}else{F}})),
max(sapply(family.ref,function(x){if(is.character(x)){regexpr("Quasi",x)>0}else{F}}))))==T & max(c(max(sapply(family.ref,function(x){if(is.character(x)){regexpr("logit",x)>0}else{F}})),
max(sapply(family.ref,function(x){if(is.character(x)){regexpr("Logit",x)>0}else{F}})),
max(sapply(family.ref,function(x){if(is.character(x)){regexpr("log",x)>0}else{F}})),
max(sapply(family.ref,function(x){if(is.character(x)){regexpr("Log",x)>0}else{F}})),
max(sapply(family.ref,function(x){if(is.character(x)){regexpr("poisson",x)>0}else{F}})),
max(sapply(family.ref,function(x){if(is.character(x)){regexpr("Poisson",x)>0}else{F}})),
max(sapply(family.ref,function(x){if(is.character(x)){regexpr("binomial",x)>0}else{F}})),
max(sapply(family.ref,function(x){if(is.character(x)){regexpr("Binomial",x)>0}else{F}}))))==T)

correct.logLik<-T}


#we also allow corrected AICc=> QAICc in case of models fitted with binomial or Poisson:
if (!is.null(family.ref)){
if (max(c(max(sapply(family.ref,function(x){if(is.character(x)){regexpr("poisson",x)>0}else{F}})),
max(sapply(family.ref,function(x){if(is.character(x)){regexpr("Poisson",x)>0}else{F}})),
max(sapply(family.ref,function(x){if(is.character(x)){regexpr("binomial",x)>0}else{F}})),
max(sapply(family.ref,function(x){if(is.character(x)){regexpr("Binomial",x)>0}else{F}}))))==T)

correct.logLik<-T}


if (is.element(class(x), c("glmer","lmer","mer")) & correct.logLik & (as.double(R.Version()$minor)>=7.0&R.Version()$major=="2"))
{print("lmer does not work well with quasi family for this R version")
stop("cf. http://markmail.org/message/s4abxhhdacqjkunm")} 

}



	if (!is.null(c) & correct.logLik==T)
		{

#condition removed for working with lmer & co: attributes(x)[["modelStruct
	QAIC <- (-2 * logLik(x)[[1]] )/c + 2 * K

		
	}
	else
	{QAIC <- AIC.lme(x,mod.df,mod.N)
		
	}
	
	QAIC
}



From dieter.menne at menne-biomed.de  Tue Feb 23 15:11:32 2010
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Tue, 23 Feb 2010 14:11:32 +0000 (UTC)
Subject: [R-sig-ME] lmer book draft
References: <201002181432.o1IEWL0G029626@defang9.it.ohio-state.edu>
	<40e66e0b1002180710s37bfd1bbred8259c22556c821@mail.gmail.com>
	<951234ac1002181219q386cfaacq44c9fa5a312bcb93@mail.gmail.com>
	<40e66e0b1002181238l427789e1j75a15fe4daa8eb6c@mail.gmail.com>
	<40e66e0b1002181247m70c86f74oa90b878ff2cc1211@mail.gmail.com>
	<EDC81757-2A43-45D6-B534-841E94F8D63F@me.com>
	<40e66e0b1002181520i35a1478axab870eaaa370c34a@mail.gmail.com>
Message-ID: <loom.20100223T150956-6@post.gmane.org>

With lme4a, profile and friends works for me, but mcmc seems to be broken (works
for lme4)

R version 2.10.1 (2009-12-14) 
i386-pc-mingw32 
...
other attached packages:
[1] lme4a_0.999375-45  Matrix_0.999375-37 lattice_0.18-3    


library(lme4a)
sessionInfo()
(fm1 <- lmer(Reaction ~ Days + (1|Subject) + (0+Days|Subject), sleepstudy))
set.seed(101)
samp0 <- mcmcsamp(fm1, n = 1000)

#Error in function (classes, fdef, mtable)  :
#  unable to find an inherited method for function "mcmcsamp", for signature
"lmerenv"



From Thierry.ONKELINX at inbo.be  Tue Feb 23 16:14:29 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 23 Feb 2010 16:14:29 +0100
Subject: [R-sig-ME] offset in glmmPQL
In-Reply-To: <4B7EB288.9010900@ufl.edu>
References: <4B7D09CA.9020301@nib.si> <4B7EB288.9010900@ufl.edu>
Message-ID: <2E9C414912813E4EB981326983E0A1040705F945@inboexch.inbo.be>

Dear Ben,

I think the problem might be rather with lme() than with glmmPQL(). I
posted a reproducible example two weeks ago: 
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q1/003290.html

Any ideas?

Best regards,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Ben Bolker
> Verzonden: vrijdag 19 februari 2010 16:47
> Aan: Maarten de Groot
> CC: r-sig-mixed-models at r-project.org
> Onderwerp: Re: [R-sig-ME] offset in glmmPQL
> 
> 
>   It's surprising that your example doesn't work, because 
> this example (which is a hidden example in the ?glmmPQL help 
> page - it doesn't appear when you type ?glmmPQL, but it gets 
> run when you say example(glmmPQL)) does ...
> 	
> library(MASS)
> library(nlme)
>  summary(glmmPQL(y ~ trt + week + offset(week), random = ~ 1 | ID,
>                  family = binomial, data = bacteria))
> 
>   Can you provide a reproducible example of what doesn't work?
> 
> Maarten de Groot wrote:
> > Dear all,
> > 
> > I have a small question about including an offset value 
> into a glmmPQL 
> > with a poisson distribution. I want to compare the number 
> of songs of 
> > an animal between treatments. Because the experiment time is not 
> > always the same I want to include this as an offset in my formula 
> > 
> ("mod<-glmmPQL(nosongs~offset(experiment.time)+treatment,rando
> m=~1|block/malenr,family=poisson,data=mcrs)").
> > 
> > 
> > However R seems not to recognize the command"offset" when 
> using a glmmPQL.
> > 
> > Hopefully some one can help me.
> > 
> > Kind regards,
> > 
> > Maarten
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> --
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida 
> bolker at ufl.edu / people.biology.ufl.edu/bolker GPG key: 
> people.biology.ufl.edu/bolker/benbolker-publickey.asc
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From frederic.gosselin at cemagref.fr  Tue Feb 23 16:17:27 2010
From: frederic.gosselin at cemagref.fr (Gosselin Frederic)
Date: Tue, 23 Feb 2010 16:17:27 +0100
Subject: [R-sig-ME] lme4, glmmPQL and calculating QAICc
Message-ID: <D74CFE08A4F86B45870D14844A636E900138A68B@murier.nogent.cemagref.fr>


Dear colleagues,

the problem you mention is close to the one I posted here: http://markmail.org/message/s4abxhhdacqjkunm. In other words, quasi-likelihood within glmer might be problematic for the lattest versions of R and not in older versions... This is my provisional conclusion.

Sincerely,

Fr?d?ric Gosselin 
Engineer & Researcher (PhD) in Forest Ecology 
Cemagref 
Domaine des Barres 
F-45290 Nogent sur Vernisson 
France 

http://www.cemagref.fr/les-contacts/les-pages-personnelles-professionnelles/gosselin-frederic/english-short-scientific-cv






 



From bates at stat.wisc.edu  Tue Feb 23 16:43:59 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 23 Feb 2010 09:43:59 -0600
Subject: [R-sig-ME] lmer book draft
In-Reply-To: <loom.20100223T150956-6@post.gmane.org>
References: <201002181432.o1IEWL0G029626@defang9.it.ohio-state.edu>
	<40e66e0b1002180710s37bfd1bbred8259c22556c821@mail.gmail.com>
	<951234ac1002181219q386cfaacq44c9fa5a312bcb93@mail.gmail.com>
	<40e66e0b1002181238l427789e1j75a15fe4daa8eb6c@mail.gmail.com>
	<40e66e0b1002181247m70c86f74oa90b878ff2cc1211@mail.gmail.com>
	<EDC81757-2A43-45D6-B534-841E94F8D63F@me.com>
	<40e66e0b1002181520i35a1478axab870eaaa370c34a@mail.gmail.com>
	<loom.20100223T150956-6@post.gmane.org>
Message-ID: <40e66e0b1002230743y7f2a5c0axebaaa26e9f8f57c@mail.gmail.com>

I should have warned users about that.  The mcmcsamp function has not
been written for the new formulation.  Part of it is the old problem
of how you sample from the distribution of the variance-component
parameters appropriately accounting for the possibility that variance
components often have a non-negligible probability of being zero.
Part of it is just finding the time to write the code.  For the time
being I would suggest using Jarrod Hatfield's MCMCglmm package.  As a
interim fix we may be able to collaborate on an interface between
lme4a and MCMCglmm to take a fitted lmer model and use it to define
the MCMCglmm model and plausible starting parameter values for the
chains.

On Tue, Feb 23, 2010 at 8:11 AM, Dieter Menne
<dieter.menne at menne-biomed.de> wrote:
> With lme4a, profile and friends works for me, but mcmc seems to be broken (works
> for lme4)
>
> R version 2.10.1 (2009-12-14)
> i386-pc-mingw32
> ...
> other attached packages:
> [1] lme4a_0.999375-45 ?Matrix_0.999375-37 lattice_0.18-3
>
>
> library(lme4a)
> sessionInfo()
> (fm1 <- lmer(Reaction ~ Days + (1|Subject) + (0+Days|Subject), sleepstudy))
> set.seed(101)
> samp0 <- mcmcsamp(fm1, n = 1000)
>
> #Error in function (classes, fdef, mtable) ?:
> # ?unable to find an inherited method for function "mcmcsamp", for signature
> "lmerenv"
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From shigesong at gmail.com  Tue Feb 23 16:52:15 2010
From: shigesong at gmail.com (Shige Song)
Date: Tue, 23 Feb 2010 10:52:15 -0500
Subject: [R-sig-ME] lmer book draft
In-Reply-To: <40e66e0b1002230743y7f2a5c0axebaaa26e9f8f57c@mail.gmail.com>
References: <201002181432.o1IEWL0G029626@defang9.it.ohio-state.edu>
	<40e66e0b1002180710s37bfd1bbred8259c22556c821@mail.gmail.com>
	<951234ac1002181219q386cfaacq44c9fa5a312bcb93@mail.gmail.com>
	<40e66e0b1002181238l427789e1j75a15fe4daa8eb6c@mail.gmail.com>
	<40e66e0b1002181247m70c86f74oa90b878ff2cc1211@mail.gmail.com>
	<EDC81757-2A43-45D6-B534-841E94F8D63F@me.com>
	<40e66e0b1002181520i35a1478axab870eaaa370c34a@mail.gmail.com>
	<loom.20100223T150956-6@post.gmane.org>
	<40e66e0b1002230743y7f2a5c0axebaaa26e9f8f57c@mail.gmail.com>
Message-ID: <5abc11d81002230752w6243dbdduefb54b547cb73fcf@mail.gmail.com>

Creating an interface between Lme4 and MCMCglmm sounds like a really
great idea.

Shige

On Tue, Feb 23, 2010 at 10:43 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
> I should have warned users about that. ?The mcmcsamp function has not
> been written for the new formulation. ?Part of it is the old problem
> of how you sample from the distribution of the variance-component
> parameters appropriately accounting for the possibility that variance
> components often have a non-negligible probability of being zero.
> Part of it is just finding the time to write the code. ?For the time
> being I would suggest using Jarrod Hatfield's MCMCglmm package. ?As a
> interim fix we may be able to collaborate on an interface between
> lme4a and MCMCglmm to take a fitted lmer model and use it to define
> the MCMCglmm model and plausible starting parameter values for the
> chains.
>
> On Tue, Feb 23, 2010 at 8:11 AM, Dieter Menne
> <dieter.menne at menne-biomed.de> wrote:
>> With lme4a, profile and friends works for me, but mcmc seems to be broken (works
>> for lme4)
>>
>> R version 2.10.1 (2009-12-14)
>> i386-pc-mingw32
>> ...
>> other attached packages:
>> [1] lme4a_0.999375-45 ?Matrix_0.999375-37 lattice_0.18-3
>>
>>
>> library(lme4a)
>> sessionInfo()
>> (fm1 <- lmer(Reaction ~ Days + (1|Subject) + (0+Days|Subject), sleepstudy))
>> set.seed(101)
>> samp0 <- mcmcsamp(fm1, n = 1000)
>>
>> #Error in function (classes, fdef, mtable) ?:
>> # ?unable to find an inherited method for function "mcmcsamp", for signature
>> "lmerenv"
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From f.calboli at imperial.ac.uk  Tue Feb 23 18:32:05 2010
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Tue, 23 Feb 2010 17:32:05 +0000
Subject: [R-sig-ME] Conditional logistic regression vs lmer
Message-ID: <3D3B95AE-7C91-4C29-94A9-244B73BA8980@imperial.ac.uk>

Hi,

I am doing a conditional logistic regression with clogit() of library survival, but I have a number of random factors I'd like to add to my model and I was thinking of lmer...

clg.tigeR = clogit(c.c ~ tIgE.Resp + strata(match), data.ready)

and all is good. I also have two more variables, both random which I'd like to use, but I am not 100% sure what's the way to go with lmer. I suspect I would need to specify a different intercept for each strata, but seems to baffle me at the moment. The code below might do what I want, but I have no idea if that's correct (i.e. does it match the clogit one + two more random effects?):

lmer.tigeR = lmer(c.c ~ tIgE.Resp + (tIgE.Resp|match) + (1|Run) + (1|Box), family = binomial, data.ready)

lmer.tigeR is computed without problems btw.

Any illumination would be gratefully accepted.

Best

Federico


--
Federico C. F. Calboli
Department of Epidemiology and Biostatistics
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From mcmahons at si.edu  Tue Feb 23 18:48:38 2010
From: mcmahons at si.edu (McMahon, Sean)
Date: Tue, 23 Feb 2010 12:48:38 -0500
Subject: [R-sig-ME] Nesting notation for lmer
Message-ID: <C7A97F26.2524%mcmahons@si.edu>

I have seen online a few different approaches to creating formulas with nested random effects in lmer(), as well as indication that the program automatically interprets nesting based on indicator variables.  What is the final word on how to construct a three-level model that is nested?

I'm not including real variables in the hope that this is straightforward enough to propose a simple template.

For a simple random intercept model where an individual is nested within a group variable level1 which is in turn nested within a community variable level2 , would a simple, nested model be:

lmer(y ~ 1 + (1 | level1) + (1 | level2) )  # this would assume that the program can intuit nestedness

lmer(y ~ 1 + (1 |level2 : level1) + (1 | level2) )  # I've seen examples of this, but cannot get it to run with my data

lmer(y ~ 1 + (1 | level1) + (level1 | level2) )  #  this runs, but with slightly different results from the first example, but I don't feel confident that it is correct.

Thanks for help on this,

Sean



From bates at stat.wisc.edu  Tue Feb 23 19:45:41 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 23 Feb 2010 12:45:41 -0600
Subject: [R-sig-ME] Nesting notation for lmer
In-Reply-To: <C7A97F26.2524%mcmahons@si.edu>
References: <C7A97F26.2524%mcmahons@si.edu>
Message-ID: <40e66e0b1002231045n6dfeabc4x111e7fcf1a62ae56@mail.gmail.com>

On Tue, Feb 23, 2010 at 11:48 AM, McMahon, Sean <mcmahons at si.edu> wrote:
> I have seen online a few different approaches to creating formulas with nested random effects in lmer(), as well as indication that the program automatically interprets nesting based on indicator variables. ?What is the final word on how to construct a three-level model that is nested?

> I'm not including real variables in the hope that this is straightforward enough to propose a simple template.

> For a simple random intercept model where an individual is nested within a group variable level1 which is in turn nested within a community variable level2 , would a simple, nested model be:

> lmer(y ~ 1 + (1 | level1) + (1 | level2) ) ?# this would assume that the program can intuit nestedness

> lmer(y ~ 1 + (1 |level2 : level1) + (1 | level2) ) ?# I've seen examples of this, but cannot get it to run with my data

Telling us that you cannot get it to run is not very informative.
What did you type and what was the response?  I'll give you a hint.
First you should check the structure of your data with the str()
function to determine if the variables level1 and level2 are stored as
factors.  If they are not stored as factors then convert them.

The distinction between the first and the second model specifications
only occurs when a factor is implicitly nested within another.  There
is an example of what this means in the Ch2.pdf file at
http://lme4.R-forge.R-project.org/book/  If the factors have been
constructed so that each distinct group has a distinct label then
either form will work.


> lmer(y ~ 1 + (1 | level1) + (level1 | level2) ) ?# ?this runs, but with slightly different results from the first example, but I don't feel confident that it is correct.

And with good reason.  That model specification is peculiar and almost
certainly not what you want.



From f.calboli at imperial.ac.uk  Wed Feb 24 08:40:41 2010
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Wed, 24 Feb 2010 07:40:41 +0000
Subject: [R-sig-ME] Conditional logistic regression vs lmer
In-Reply-To: <3D3B95AE-7C91-4C29-94A9-244B73BA8980@imperial.ac.uk>
References: <3D3B95AE-7C91-4C29-94A9-244B73BA8980@imperial.ac.uk>
Message-ID: <4186AF8E-82D4-493A-A3B4-F28255C806E5@imperial.ac.uk>

On 23 Feb 2010, at 17:32, Federico Calboli wrote:

> Hi,
> 
> I am doing a conditional logistic regression with clogit() of library survival, but I have a number of random factors I'd like to add to my model and I was thinking of lmer...
> 
> clg.tigeR = clogit(c.c ~ tIgE.Resp + strata(match), data.ready)
> 
> and all is good. I also have two more variables, both random which I'd like to use, but I am not 100% sure what's the way to go with lmer. I suspect I would need to specify a different intercept for each strata, but seems to baffle me at the moment. The code below might do what I want, but I have no idea if that's correct (i.e. does it match the clogit one + two more random effects?):
> 
> lmer.tigeR = lmer(c.c ~ tIgE.Resp + (tIgE.Resp|match) + (1|Run) + (1|Box), family = binomial, data.ready)
> 
> lmer.tigeR is computed without problems btw.


I forgot to mention that tIgE.Resp is a continuous variable, so I have serious douts my lmer code is equivalent to the clogit one.

Best,

Federico


--
Federico C. F. Calboli
Department of Epidemiology and Biostatistics
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From walmeszeviani at yahoo.com.br  Thu Feb 25 21:26:18 2010
From: walmeszeviani at yahoo.com.br (walmes zeviani)
Date: Thu, 25 Feb 2010 12:26:18 -0800 (PST)
Subject: [R-sig-ME] How is the lmer model specification to strip-plot design?
Message-ID: <164450.96959.qm@web111709.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100225/95411a5e/attachment.pl>

From C.Millar at MARLAB.AC.UK  Thu Feb 25 21:52:37 2010
From: C.Millar at MARLAB.AC.UK (Colin Millar)
Date: Thu, 25 Feb 2010 20:52:37 -0000
Subject: [R-sig-ME] Quasipoisson: alternative implementation
References: <D74CFE08A4F86B45870D14844A636E900138A68B@murier.nogent.cemagref.fr>
Message-ID: <A0F8DAFB525DED4ABAF6841BB11C5812018F80C4@mail4.marlab.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100225/94e91d43/attachment.pl>

From kw.stat at gmail.com  Thu Feb 25 22:10:50 2010
From: kw.stat at gmail.com (Kevin Wright)
Date: Thu, 25 Feb 2010 15:10:50 -0600
Subject: [R-sig-ME] How is the lmer model specification to strip-plot
	design?
In-Reply-To: <164450.96959.qm@web111709.mail.gq1.yahoo.com>
References: <164450.96959.qm@web111709.mail.gq1.yahoo.com>
Message-ID: <5c62e0071002251310u467e4230tab08e7d4c9cda270@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100225/7114c9af/attachment.pl>

From jeroen.minderman at stir.ac.uk  Fri Feb 26 00:22:10 2010
From: jeroen.minderman at stir.ac.uk (Jeroen Minderman)
Date: Thu, 25 Feb 2010 23:22:10 +0000
Subject: [R-sig-ME] problem with lme4 fit and update() function?
Message-ID: <60CFD5A6-D475-45E7-927A-9855C4FC8C30@stir.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100225/6e1b645e/attachment.pl>

From lborger at uoguelph.ca  Fri Feb 26 03:36:54 2010
From: lborger at uoguelph.ca (Luca Borger)
Date: Thu, 25 Feb 2010 21:36:54 -0500
Subject: [R-sig-ME] problem with lme4 fit and update() function?
References: <60CFD5A6-D475-45E7-927A-9855C4FC8C30@stir.ac.uk>
Message-ID: <F51AECB1048145A6BEC7953352BF3378@lborger>

Hi Jeroen,

seems to work fine on my system, without any warnings, too:

> library(lme4)
Loading required package: Matrix
Loading required package: lattice

> summary(all_test)
     fledge           mass           nmass            NEST
 Min.   :1.000   Min.   :58.38   Min.   :2.000   Min.   :14.00
 1st Qu.:2.000   1st Qu.:61.50   1st Qu.:2.250   1st Qu.:15.00
 Median :2.000   Median :62.50   Median :3.500   Median :17.00
 Mean   :2.367   Mean   :61.81   Mean   :3.367   Mean   :18.23
 3rd Qu.:3.000   3rd Qu.:63.50   3rd Qu.:4.000   3rd Qu.:20.00
 Max.   :5.000   Max.   :64.00   Max.   :5.000   Max.   :23.00

> str(all_test)
'data.frame':   30 obs. of  4 variables:
 $ fledge: int  2 2 2 2 2 2 2 2 2 2 ...
 $ mass  : num  61.5 61.5 61.5 61.5 61.5 61.5 61.5 62.5 62.5 62.5 ...
 $ nmass : int  3 3 3 3 3 3 3 2 2 2 ...
 $ NEST  : int  17 17 17 17 17 17 17 20 20 20 ...


> mod1 <- lmer(fledge ~ mass + nmass + (1|NEST), family="poisson", 
> data=all_test)

> summary(mod1)
Generalized linear mixed model fit by the Laplace approximation
Formula: fledge ~ mass + nmass + (1 | NEST)
   Data: all_test
   AIC   BIC  logLik deviance
 8.574 14.18 -0.2869   0.5737
Random effects:
 Groups Name        Variance  Std.Dev.
 NEST   (Intercept) 7.718e-17 8.7852e-09
Number of obs: 30, groups: NEST, 5

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)
(Intercept) -14.26458    4.86333  -2.933  0.00336 **
mass          0.23377    0.07977   2.931  0.00338 **
nmass         0.16731    0.11564   1.447  0.14793
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Correlation of Fixed Effects:
      (Intr) mass
mass  -0.996
nmass  0.271 -0.349




> mod2<- update(mod1, . ~ . - nmass)

> summary(mod2)
Generalized linear mixed model fit by the Laplace approximation
Formula: fledge ~ mass + (1 | NEST)
   Data: all_test
   AIC   BIC logLik deviance
 8.708 12.91 -1.354    2.708
Random effects:
 Groups Name        Variance Std.Dev.
 NEST   (Intercept)  0        0
Number of obs: 30, groups: NEST, 5

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)
(Intercept) -16.34354    5.15302  -3.172 0.001516 **
mass          0.27646    0.08231   3.359 0.000783 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Correlation of Fixed Effects:
     (Intr)
mass -1.000



> anova(mod1,mod2)
Data: all_test
Models:
mod2: fledge ~ mass + (1 | NEST)
mod1: fledge ~ mass + nmass + (1 | NEST)
     Df    AIC    BIC   logLik  Chisq Chi Df Pr(>Chisq)
mod2  3 8.7075 12.911 -1.35376
mod1  4 8.5737 14.178 -0.28686 2.1338      1     0.1441


> sessionInfo()
R version 2.10.1 (2009-12-14)
i386-pc-mingw32

locale:
[1] LC_COLLATE=English_United Kingdom.1252
[2] LC_CTYPE=English_United Kingdom.1252
[3] LC_MONETARY=English_United Kingdom.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United Kingdom.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999375-32   Matrix_0.999375-37 lattice_0.18-3

loaded via a namespace (and not attached):
[1] grid_2.10.1
>


HTH


Cheers,

Luca



----- Original Message ----- 
From: "Jeroen Minderman" <jeroen.minderman at stir.ac.uk>
To: <r-sig-mixed-models at r-project.org>
Sent: Thursday, February 25, 2010 6:22 PM
Subject: [R-sig-ME] problem with lme4 fit and update() function?


Hi all,

I may be doing something very silly - but I'm stuck on something that has 
always worked fine for me!

Is there a problem with the 0.9993725-32 version of lme4 and the update() 
function?

I've been trying to use update() to drop a single fixed factor from a 
previous model fit, and then compare the two fits with anova(). I've done 
this successfully previously, but I can't seem to get this to work now and 
am at a loss why.

Anova() returns "Error in anova(mod1, mod2) : all models must be fit to the 
same data object", suggesting that the two models have been fit on different 
datasets which is presumably not the case, although if I re-fit the model 
manually, it does work?

See code and output to follow - any ideas?

######################################################
> library(lme4)
### The following dataset is a snippet of the full set for convenience
###  (the full dataset produces the same issue:)

> all_test
   fledge   mass nmass NEST
1       2 61.500     3   17
2       2 61.500     3   17
3       2 61.500     3   17
4       2 61.500     3   17
5       2 61.500     3   17
6       2 61.500     3   17
7       2 61.500     3   17
8       2 62.500     2   20
9       2 62.500     2   20
10      2 62.500     2   20
11      3 63.500     4   14
12      5 64.000     5   15
13      5 64.000     5   15
14      2 62.500     2   20
15      3 63.500     4   14
16      3 63.500     4   14
17      3 63.500     4   14
18      2 62.500     2   20
19      5 64.000     5   15
20      2 62.500     2   20
21      2 62.500     2   20
22      2 62.500     2   20
23      3 63.500     4   14
24      5 64.000     5   15
25      1 58.375     4   23
26      1 58.375     4   23
27      1 58.375     4   23
28      1 58.375     4   23
29      1 58.375     4   23
30      1 58.375     4   23

> mod1 <- lmer(fledge ~ mass + nmass + (1|NEST), family="poisson", 
> data=all_test)
> summary(mod1)
Generalized linear mixed model fit by the Laplace approximation
Formula: fledge ~ mass + nmass + (1 | NEST)
   Data: all_test
   AIC   BIC  logLik deviance
 8.574 14.18 -0.2869   0.5737
Random effects:
 Groups Name        Variance Std.Dev.
 NEST   (Intercept)  0        0
Number of obs: 30, groups: NEST, 5

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)
(Intercept) -14.26458    4.86333  -2.933  0.00336 **
mass          0.23377    0.07977   2.931  0.00338 **
nmass         0.16731    0.11564   1.447  0.14793
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Correlation of Fixed Effects:
      (Intr) mass
mass  -0.996
nmass  0.271 -0.349

### .... attempting to drop 'nmass' using update() ###################
### .. Note that this only seems to work if specifying 'data=all_test'
### ..  again, I don't remember having to do this before!
### .. Also, something weird seems to be going on in the 'Data:..'
### ..  bit in the model summary?

> mod2 <- update(mod1, .~. -nmass, data=all_test)
> summary(mod2)
Generalized linear mixed model fit by the Laplace approximation
Formula: fledge ~ mass + (1 | NEST)
   Data: ..2
   AIC   BIC logLik deviance
 8.708 12.91 -1.354    2.708
Random effects:
 Groups Name        Variance   Std.Dev.
 NEST   (Intercept) 3.1459e-21 5.6088e-11
Number of obs: 30, groups: NEST, 5

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)
(Intercept) -16.34354    5.15302  -3.172 0.001516 **
mass          0.27646    0.08231   3.359 0.000783 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Correlation of Fixed Effects:
     (Intr)
mass -1.000

### Now, attempting to compare these two fits using anova(): #############

> anova(mod1, mod2)
Error in anova(mod1, mod2) :
  all models must be fit to the same data object

### However, if I 'refit' mod2 manually...:

> mod2 <- lmer(fledge ~ mass + (1|NEST), family="poisson", data=all_test)

### ... the two models compare fine using anova(), except for a couple of 
#####
###  warning messages that I find puzzling and alarming.

> anova(mod1, mod2)
Data: all_test
Models:
mod2: fledge ~ mass + (1 | NEST)
mod1: fledge ~ mass + nmass + (1 | NEST)
     Df    AIC    BIC   logLik  Chisq Chi Df Pr(>Chisq)
mod2  3 8.7075 12.911 -1.35376
mod1  4 8.5737 14.178 -0.28686 2.1338      1     0.1441
Warning messages:
1: In deparse(expr) :
  it is not known that wchar_t is Unicode on this platform
2: In deparse(expr) :
  it is not known that wchar_t is Unicode on this platform

############################################################

Any suggestions would be very helpful, this has had me mystified for the 
past few days??

I'm using R version 2.10.1 (2009-12-14), on Mac OSX 10.6.2 (Snow Leopard), 
x86_64-apple-darwin9.8.0.

Thanks and best wishes,

Jeroen Minderman


-- 
The Sunday Times Scottish University of the Year 2009/2010
The University of Stirling is a charity registered in Scotland,
 number SC 011159.


[[alternative HTML version deleted]]




--------------------------------------------------------------------------------


> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From cat.dev.urandom at gmail.com  Fri Feb 26 06:32:14 2010
From: cat.dev.urandom at gmail.com (D Chaws)
Date: Fri, 26 Feb 2010 00:32:14 -0500
Subject: [R-sig-ME] lme and prediction intervals
In-Reply-To: <dcf23fb81002180925o2a82d2a4xea95799c547753c5@mail.gmail.com>
References: <dcf23fb81002180925o2a82d2a4xea95799c547753c5@mail.gmail.com>
Message-ID: <dcf23fb81002252132u7fd4b01ft5a3232e51fcfc73@mail.gmail.com>

And the saga continues...

I checked on the SAS website to see how they compute standard errors
for predictions in LSMEANS, just for giggles.  According to
http://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/statug_mixed_sect014.htm

SE = L(X'V-1X)-L'

or in R terms

SE = Designmat %*% solve(formXtViX(extract.lme.cov2(fm1, Orthodont),
extract.lmeDesign(fm1)$X), t(Designmat))

which is, yes...you guessed it, the exact same thing as Designmat %*%
fm1$varFix %*% t(Designmat).

And of course, the SE's don't match those in LSMEANS.  Any thoughts?
I can't believe a solution to this has never come up.  I don't care
about replicating LSMEANS, I just want to be confident that the SE's I
present are accurate and meaningful.  Since they currently leave out
random-effects variance, I suspect something important is missing.

-- DC

On Thu, Feb 18, 2010 at 12:25 PM, D Chaws <cat.dev.urandom at gmail.com> wrote:
> Dear lme(r) users,
>
> I have seen this issue come up many times over the years, but haven't
> come across an answer as of yet.
> Take for example the growth model:
>
> fm1 <- lme(distance ~ age*Sex, random = ~ 1 + age | Subject, data = Orthodont)
>
> Distance increases with age, but more so in Males.
>
> I want to obtain the model predicted values of distance at each age
> (c(8,10,12,14)) for males and female separately to explore this
> interaction.
>
> So,
>
> newdat <- expand.grid(age=c(8,10,12,14), Sex=c("Male","Female"))
> newdat$pred <- predict(fm1, newdat, level = 0)
>
> R# newdat
>  age    Sex  pred
> 1   8   Male 22.62
> 2  10   Male 24.18
> 3  12   Male 25.75
> 4  14   Male 27.32
> 5   8 Female 21.21
> 6  10 Female 22.17
> 7  12 Female 23.13
> 8  14 Female 24.09
>
> Yup, males have a steeper increase with age than females.
>
> The question is, how to go about getting prediction intervals around
> these predictions.  It seems reasonable to need to know
> the precision of these predictions, and of course most journals
> require the reporting of error bars etc...  However, predict.lme
> doesn't
> have a se.fit or intervals argument.
>
> The only answer I have found at the moment is to use the design matrix
> and $varFix from the model.
>
> So,
>
> Designmat <- model.matrix(eval(eval(fm1$call$fixed)[-2]), newdat[-3])
> R# Designmat
>  (Intercept) age SexFemale age:SexFemale
> 1           1   8         0             0
> 2           1  10         0             0
> 3           1  12         0             0
> 4           1  14         0             0
> 5           1   8         1             8
> 6           1  10         1            10
> 7           1  12         1            12
> 8           1  14         1            14
>
> newdat$SE <- sqrt(diag(Designmat %*% fm1$varFix %*% t(Designmat)))
> R# newdat
>  age    Sex  pred     SE
> 1   8   Male 22.62 0.5265
> 2  10   Male 24.18 0.4848
> 3  12   Male 25.75 0.5021
> 4  14   Male 27.32 0.5730
> 5   8 Female 21.21 0.6350
> 6  10 Female 22.17 0.5847
> 7  12 Female 23.13 0.6056
> 8  14 Female 24.09 0.6910
>
> Are these true pointwise prediction intervals?
>
> Any help would be greatly appreciated.  I refuse to use SAS for this!
>
> -- D. Chaws
>



From frederic.gosselin at cemagref.fr  Fri Feb 26 08:49:25 2010
From: frederic.gosselin at cemagref.fr (Gosselin Frederic)
Date: Fri, 26 Feb 2010 08:49:25 +0100
Subject: [R-sig-ME] Quasipoisson: alternative implementation
Message-ID: <D74CFE08A4F86B45870D14844A636E900138A6EF@murier.nogent.cemagref.fr>

Dear Colleague,

it seems that quasi-poisson interests more and more R members...

To your question 1:
> 1) Is it common knowledge that the quasipoisson family incorrectly weights things somewhere in glmer?  The example 
>below gives a demonstration.

I answer again (cf. https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q1/003348.html and https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q4/003059.html) that quasi-poisson implemented in glmer/lmer - as well as quasibinomial - has a very strange behaviour as the one you report in latter versions of R but not in older ones (let's say before version 2.5.1). I reproduced your test under R2.2.1: here is the result, much better - note the slight difference in the syntax:


>  lmer(x2 ~ 1+(1|z), family = "quasipoisson")
Generalized linear mixed model fit using PQL 
Formula: x2 ~ 1 + (1 | z) 
 Family: quasipoisson(log link)
      AIC      BIC    logLik deviance
 188.8215 194.0318 -92.41075 184.8215
Random effects:
 Groups   Name        Variance   Std.Dev.  
 z        (Intercept) 9.1691e-10 3.0280e-05
 Residual             1.8338e+00 1.3542e+00
number of obs: 100, groups: z, 2

Fixed effects:
            Estimate Std. Error t value
(Intercept) 4.621536   0.013432  344.08




Regarding your second suggestion, - including a innerlevel random effect - this is a different model, which is based on a "real" liklelihood, that might be worth considering, along e.g. negative binomial models in other R functions. Then, why not simply using:
	ind <- factor(1:100)
	glmer(x2 ~ (1|ind), family = poisson)

As you mention, you then cannot treat underdispersion, which might be a problem in some settings.

Sincerely,

Fr?d?ric Gosselin 
Engineer & Researcher (PhD) in Forest Ecology 
Cemagref 
Domaine des Barres 
F-45290 Nogent sur Vernisson 
France 

http://www.cemagref.fr/les-contacts/les-pages-personnelles-professionnelles/gosselin-frederic/english-short-scientific-cv

 
 



From njbisaac at googlemail.com  Fri Feb 26 14:37:47 2010
From: njbisaac at googlemail.com (Nick Isaac)
Date: Fri, 26 Feb 2010 13:37:47 +0000
Subject: [R-sig-ME] R2 measure in mixed models?
In-Reply-To: <221597f21002172255h7004365di8d7155a77809ade1@mail.gmail.com>
References: <221597f21002170300lcd22247sc202c3bb11bf6469@mail.gmail.com>
	<11E3FEA23855407391779E0D7CE701AB@TheVoid>
	<221597f21002172255h7004365di8d7155a77809ade1@mail.gmail.com>
Message-ID: <a072ed701002260537m453c697v290c1a15cbec4b37@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100226/9a5bfa59/attachment.pl>

From bates at stat.wisc.edu  Fri Feb 26 15:30:41 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 26 Feb 2010 08:30:41 -0600
Subject: [R-sig-ME] R2 measure in mixed models?
In-Reply-To: <a072ed701002260537m453c697v290c1a15cbec4b37@mail.gmail.com>
References: <221597f21002170300lcd22247sc202c3bb11bf6469@mail.gmail.com>
	<11E3FEA23855407391779E0D7CE701AB@TheVoid>
	<221597f21002172255h7004365di8d7155a77809ade1@mail.gmail.com>
	<a072ed701002260537m453c697v290c1a15cbec4b37@mail.gmail.com>
Message-ID: <40e66e0b1002260630j43f1e508lea82fcfd4ee3b427@mail.gmail.com>

On Fri, Feb 26, 2010 at 7:37 AM, Nick Isaac <njbisaac at googlemail.com> wrote:
> Sorry to be joining this late.

> I have written some code to implement Gelman & Pardoe's Rsq for an lmer
> object. It gives some believable results, but it's difficult to be confident
> because of the translation from Bayesian into frequentist paradigms.

> If anyone is interested then I'd be really happy to discuss this off-list
> and share/develop the code.

Assuming that one wants to define an R^2 measure, I think an argument
could be made for treating the penalized residual sum of squares from
a linear mixed model in the same way that we consider the residual sum
of squares from a linear model.  Or one could use just the residual
sum of squares without the penalty or the minimum residual sum of
squares obtainable from a given set of terms, which corresponds to an
infinite precision matrix.  I don't know, really.  It depends on what
you are trying to characterize.

In other words, what's the purpose?  What aspect of the R^2 for a
linear model are you trying to generalize?

I'm sorry if I sound argumentative but discussions like this sometimes
frustrate me.  A linear mixed model does not behave exactly like a
linear model without random effects so a measure that may be
appropriate for the linear model does not necessarily generalize.  I'm
not saying that this is the case but if the request is "I don't care
what the number means or if indeed it means anything at all, just give
me a number I can report", that's not the style of statistics I
practice.

I regard Bill Venables' wonderful unpublished paper "Exegeses on
Linear Models" (just put the name in a search engine to find a copy -
there is only one paper with "Exegeses" and "Linear Models" in the
title) as required reading for statisticians.  As Bill emphasizes in
that paper, statistics is not just a collection of formulas (many of
which are based on approximations).  It's about models and comparing
how well different models fit the observed data.  If we start with a
formula and only ask ourselves "How do we generalize this formula?"
we're missing the point.  We should start at the model.

In a linear model the R^2 statistic is a dimensionless comparison of
the quality of the current model fit, as measured by the residual sum
of squares, to the fit one would obtain from a trivial model.  When
the current model can be shown to contain a model with an intercept
term only (and whose coefficient will be estimated by the mean
response) then that model fit is the trivial model.  Otherwise the
trivial model is a prediction of zero for each response.  We know that
the trivial model will produce a greater residual sum of squares than
the current model fit because the models are nested.  The R^2 is the
proportion of variability not accounted for by the trivial model but
accounted for by the current model (my apologies to my grammar
teachers for having juxtaposed prepositions).

The interesting point there is that when you think of the
relationships between models you can determine how you handle the case
of a model that does not have an intercept term.  If you start from
the formula instead you can end up calculating a negative R^2 because
you compare models that are not nested.  Such nonsensical results are
often reported.  (I think it was the Mathematica documentation that
gave a careful explanation of why you get a negative R^2 instead of
recognizing that the formula they were using did not apply in certain
cases.)

It may be that there is a sensible measure of the quality of fit from
a linear mixed model that generalizes the R^2 from a linear model.  I
don't see an obvious candidate but I will freely admit that I haven't
thought much about the problem.  I would ask others who are thinking
about this to consider both the "what" and the "why".  George
Mallory's justification of "because it's there" for attempting to
climb Everest is perhaps a good justification for such endeavors
(Mallory may have questioned his rationale as he lay freezing to death
on the mountain).  I don't think it is a good justification for
manipulating formulas.


>
> Best wishes, Nick
>
>
> On 18 February 2010 06:55, Luisa Carvalheiro <lgcarvalheiro at gmail.com>wrote:
>
>> Hi Steve,
>>
>> Thanlks for reply and literature list. Here are 3 papers on ?R2
>> calculations for Mixed Models:
>>
>> M. Mittlbock, T. Waldhor. Adjustments for R2-measures for Poisson
>> regression models. Computational Statistics & Data Analysis 34 (2000)
>> 461-472
>>
>> M. Mittlbock Calculating adjusted R2 measures for Poisson regression
>> Models. Computer Methods and Programs in Biomedicine 68 (2002) 205?214
>>
>> H. Liu,Y. Zheng and J. Shen. Goodness-of-fit measures of R2 for
>> repeated measures mixed effect models Journal of Applied Statistics.
>> 35, 2008, 1081?1092
>>
>>
>> On Thu, Feb 18, 2010 at 1:46 AM, Steven J. Pierce <pierces1 at msu.edu>
>> wrote:
>> > Luisa,
>> >
>> > I'm not aware of any packages for that, but I'd like the full citation
>> for
>> > the paper you mentioned. In exchange, here are some citations for other
>> > papers about R-square measures in multilevel models that I've found.
>> >
>> > Edwards, L. J., Muller, K. E., Wolfinger, R. D., Qaqish, B. F., &
>> > Schabenberger, O. (2008). An R2 statistic for fixed effects in the linear
>> > mixed model. Statistics in Medicine, 27(29), 6137-6157. doi:
>> > 10.1002/sim.3429
>> >
>> > Gelman, A., & Pardoe, I. (2006). Bayesian measures of explained variance
>> and
>> > pooling in multilevel (hierarchical) models. Technometrics, 48(2),
>> 241-251.
>> > doi: 10.1198/004017005000000517
>> >
>> > Kramer, M. (2005). R2 statistics for mixed models. Proceedings of the
>> > Conference on Applied Statistics in Agriculture, 17, 148-160. Retrieved
>> from
>> >
>> http://www.ars.usda.gov/sp2UserFiles/ad_hoc/12000000SpatialWorkshop/19Kramer
>> > SupplRsq.pdf
>> >
>> > Merlo, J., Yang, M., Chaix, B., Lynch, J., & R?stam, L. (2005). A brief
>> > conceptual tutorial on multilevel analysis in social epidemiology:
>> > investigating contextual phenomena in different groups of people. Journal
>> of
>> > Epidemiology and Community Health, 59(9), 729-736. doi:
>> > 10.1136/jech.2004.023929
>> >
>> > Orelien, J. G., & Edwards, L. J. (2008). Fixed-effect variable selection
>> in
>> > linear mixed models using R2 statistics. Computational Statistics & Data
>> > Analysis, 52(4), 1896-1907. doi: 10.1016/j.csda.2007.06.006
>> >
>> > Roberts, J. K., & Monaco, J. P. (2006, April). Effect size measures for
>> the
>> > two-level linear multilevel model. ?Paper presented at the annual meeting
>> of
>> > the American Educational Research Association, San Francisco, CA.
>> Retrieved
>> > from http://www.hlm-online.com/papers/HLM_effect_size.pdf
>> >
>> > Snijders, T. A. B., & Bosker, R. J. (1994). Modeled variance in two-level
>> > models. Sociological Methods & Research, 22(3), 342-363. doi:
>> > 10.1177/0049124194022003004
>> >
>> > Snijders, T. A. B., & Bosker, R. J. (1999). Multilevel analysis. London,
>> UK:
>> > Sage.
>> > Xu, R. (2003). Measuring explained variation in linear mixed effects
>> models.
>> > Statistics in Medicine, 22(22), 3527-3541. doi: 10.1002/sim.1572
>> >
>> >
>> >
>> > Steven J. Pierce
>> > Associate Director
>> > Center for Statistical Training & Consulting (CSTAT)
>> > Michigan State University
>> > 178 Giltner Hall
>> > East Lansing, MI 48824
>> > Web: http://www.cstat.msu.edu
>> >
>> >
>> > -----Original Message-----
>> > From: Luisa Carvalheiro [mailto:lgcarvalheiro at gmail.com]
>> > Sent: Wednesday, February 17, 2010 6:00 AM
>> > To: r-sig-mixed-models at r-project.org
>> > Subject: [R-sig-ME] R2 measure in mixed models?
>> >
>> > Dear mixed modelers,
>> >
>> > Is there any package for calculating R2 measures for mixed models in R
>> (e.g.
>> > using the measure proposed by Mittlb ock; ?Waldh or 2000)?
>> >
>> > Luisa
>> >
>> >
>> >
>> >
>>
>>
>>
>> --
>> Luisa Carvalheiro, PhD
>> Southern African Biodiversity Institute, Kirstenbosch Research Center,
>> Claremont
>> & University of Pretoria
>> Postal address - SAWC Pbag X3015 Hoedspruit 1380, South Africa
>> telephone - +27 (0) 790250944
>> Carvalheiro at sanbi.org
>> lgcarvalheiro at gmail.com
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



From njbisaac at googlemail.com  Fri Feb 26 16:27:49 2010
From: njbisaac at googlemail.com (Nick Isaac)
Date: Fri, 26 Feb 2010 15:27:49 +0000
Subject: [R-sig-ME] R2 measure in mixed models?
In-Reply-To: <40e66e0b1002260630j43f1e508lea82fcfd4ee3b427@mail.gmail.com>
References: <221597f21002170300lcd22247sc202c3bb11bf6469@mail.gmail.com>
	<11E3FEA23855407391779E0D7CE701AB@TheVoid>
	<221597f21002172255h7004365di8d7155a77809ade1@mail.gmail.com>
	<a072ed701002260537m453c697v290c1a15cbec4b37@mail.gmail.com>
	<40e66e0b1002260630j43f1e508lea82fcfd4ee3b427@mail.gmail.com>
Message-ID: <a072ed701002260727k7dd64473m68d56aaf2919dab8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100226/872f09d0/attachment.pl>

From jungck at gmail.com  Fri Feb 26 20:58:30 2010
From: jungck at gmail.com (jungck)
Date: Fri, 26 Feb 2010 14:58:30 -0500
Subject: [R-sig-ME] glmer ordered response models
Message-ID: <6a32069d1002261158k5f2dd10dhcc151de8bab9766f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100226/a4c0d63a/attachment.pl>

From HDoran at air.org  Fri Feb 26 21:06:18 2010
From: HDoran at air.org (Doran, Harold)
Date: Fri, 26 Feb 2010 15:06:18 -0500
Subject: [R-sig-ME] glmer ordered response models
In-Reply-To: <6a32069d1002261158k5f2dd10dhcc151de8bab9766f@mail.gmail.com>
References: <6a32069d1002261158k5f2dd10dhcc151de8bab9766f@mail.gmail.com>
Message-ID: <C0772C7568B5374481D2F8A880E9BBDF0454F51E10@DC1EX07CMS.air.org>

See ?family for available link functions. 

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of jungck
Sent: Friday, February 26, 2010 2:59 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] glmer ordered response models

Hi, all.

I am a new comer to lmer package in R.
When I run a ordered response model, I couldn't
figure out what is the option name for "family=" option.
R keep saying error warnings when I use family="categorical", which
seem to be used in MCMCglmm package. I don't know how to do bayesian
model. so I want to know how to do glmer function with ordered dependent
variable.

Thanks for your help!

-CK

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From j.hadfield at ed.ac.uk  Fri Feb 26 21:43:12 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 26 Feb 2010 20:43:12 +0000
Subject: [R-sig-ME] glmer ordered response models
In-Reply-To: <C0772C7568B5374481D2F8A880E9BBDF0454F51E10@DC1EX07CMS.air.org>
References: <6a32069d1002261158k5f2dd10dhcc151de8bab9766f@mail.gmail.com>
	<C0772C7568B5374481D2F8A880E9BBDF0454F51E10@DC1EX07CMS.air.org>
Message-ID: <20100226204312.sakl1irzggwwkgk0@www.staffmail.ed.ac.uk>

Hi,

Just to avoid confusion - "ordinal" is the family argument for ordered  
response models in MCMCglmm not "categorical".  If your response has  
two levels then it makes no difference (except "categorical" uses the  
logit link and "ordinal" uses the probit link). You can fit this in  
glmer using  family = "binomial(link="logit") or family =  
"binomial(link="probit"). If there are more than two levels I think it  
is not possible to fit the model in glmer, but could be wrong.

Cheers,

Jarrod






Quoting "Doran, Harold" <HDoran at air.org>:

> See ?family for available link functions.
>
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org   
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of jungck
> Sent: Friday, February 26, 2010 2:59 PM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] glmer ordered response models
>
> Hi, all.
>
> I am a new comer to lmer package in R.
> When I run a ordered response model, I couldn't
> figure out what is the option name for "family=" option.
> R keep saying error warnings when I use family="categorical", which
> seem to be used in MCMCglmm package. I don't know how to do bayesian
> model. so I want to know how to do glmer function with ordered dependent
> variable.
>
> Thanks for your help!
>
> -CK
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From j.hadfield at ed.ac.uk  Fri Feb 26 21:43:41 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 26 Feb 2010 20:43:41 +0000
Subject: [R-sig-ME] glmer ordered response models
In-Reply-To: <C0772C7568B5374481D2F8A880E9BBDF0454F51E10@DC1EX07CMS.air.org>
References: <6a32069d1002261158k5f2dd10dhcc151de8bab9766f@mail.gmail.com>
	<C0772C7568B5374481D2F8A880E9BBDF0454F51E10@DC1EX07CMS.air.org>
Message-ID: <20100226204341.a6lfrzby8w0084cc@www.staffmail.ed.ac.uk>

Hi,

Just to avoid confusion - "ordinal" is the family argument for ordered  
response models in MCMCglmm not "categorical".  If your response has  
two levels then it makes no difference (except "categorical" uses the  
logit link and "ordinal" uses the probit link). You can fit this in  
glmer using  family = binomial(link="logit") or family =  
binomial(link="probit"). If there are more than two levels I think it  
is not possible to fit the model in glmer, but could be wrong.

Cheers,

Jarrod






Quoting "Doran, Harold" <HDoran at air.org>:

> See ?family for available link functions.
>
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org   
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of jungck
> Sent: Friday, February 26, 2010 2:59 PM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] glmer ordered response models
>
> Hi, all.
>
> I am a new comer to lmer package in R.
> When I run a ordered response model, I couldn't
> figure out what is the option name for "family=" option.
> R keep saying error warnings when I use family="categorical", which
> seem to be used in MCMCglmm package. I don't know how to do bayesian
> model. so I want to know how to do glmer function with ordered dependent
> variable.
>
> Thanks for your help!
>
> -CK
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From j.hadfield at ed.ac.uk  Fri Feb 26 21:43:39 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 26 Feb 2010 20:43:39 +0000
Subject: [R-sig-ME] glmer ordered response models
In-Reply-To: <C0772C7568B5374481D2F8A880E9BBDF0454F51E10@DC1EX07CMS.air.org>
References: <6a32069d1002261158k5f2dd10dhcc151de8bab9766f@mail.gmail.com>
	<C0772C7568B5374481D2F8A880E9BBDF0454F51E10@DC1EX07CMS.air.org>
Message-ID: <20100226204339.n92qcw0m1w84w8o0@www.staffmail.ed.ac.uk>

Hi,

Just to avoid confusion - "ordinal" is the family argument for ordered  
response models in MCMCglmm not "categorical".  If your response has  
two levels then it makes no difference (except "categorical" uses the  
logit link and "ordinal" uses the probit link). You can fit this in  
glmer using  family = binomial(link="logit") or family =  
binomial(link="probit"). If there are more than two levels I think it  
is not possible to fit the model in glmer, but could be wrong.

Cheers,

Jarrod






Quoting "Doran, Harold" <HDoran at air.org>:

> See ?family for available link functions.
>
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org   
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of jungck
> Sent: Friday, February 26, 2010 2:59 PM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] glmer ordered response models
>
> Hi, all.
>
> I am a new comer to lmer package in R.
> When I run a ordered response model, I couldn't
> figure out what is the option name for "family=" option.
> R keep saying error warnings when I use family="categorical", which
> seem to be used in MCMCglmm package. I don't know how to do bayesian
> model. so I want to know how to do glmer function with ordered dependent
> variable.
>
> Thanks for your help!
>
> -CK
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From HDoran at air.org  Fri Feb 26 21:46:36 2010
From: HDoran at air.org (Doran, Harold)
Date: Fri, 26 Feb 2010 15:46:36 -0500
Subject: [R-sig-ME] glmer ordered response models
In-Reply-To: <20100226204312.sakl1irzggwwkgk0@www.staffmail.ed.ac.uk>
References: <6a32069d1002261158k5f2dd10dhcc151de8bab9766f@mail.gmail.com>
	<C0772C7568B5374481D2F8A880E9BBDF0454F51E10@DC1EX07CMS.air.org>
	<20100226204312.sakl1irzggwwkgk0@www.staffmail.ed.ac.uk>
Message-ID: <C0772C7568B5374481D2F8A880E9BBDF0454F51E22@DC1EX07CMS.air.org>

I don't believe you are wrong, Jarrod. glmer, AFAIK, does not have links for ordered logit/probit or multinomial links

-----Original Message-----
From: Jarrod Hadfield [mailto:j.hadfield at ed.ac.uk] 
Sent: Friday, February 26, 2010 3:43 PM
To: Doran, Harold
Cc: jungck; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] glmer ordered response models

Hi,

Just to avoid confusion - "ordinal" is the family argument for ordered  
response models in MCMCglmm not "categorical".  If your response has  
two levels then it makes no difference (except "categorical" uses the  
logit link and "ordinal" uses the probit link). You can fit this in  
glmer using  family = "binomial(link="logit") or family =  
"binomial(link="probit"). If there are more than two levels I think it  
is not possible to fit the model in glmer, but could be wrong.

Cheers,

Jarrod






Quoting "Doran, Harold" <HDoran at air.org>:

> See ?family for available link functions.
>
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org   
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of jungck
> Sent: Friday, February 26, 2010 2:59 PM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] glmer ordered response models
>
> Hi, all.
>
> I am a new comer to lmer package in R.
> When I run a ordered response model, I couldn't
> figure out what is the option name for "family=" option.
> R keep saying error warnings when I use family="categorical", which
> seem to be used in MCMCglmm package. I don't know how to do bayesian
> model. so I want to know how to do glmer function with ordered dependent
> variable.
>
> Thanks for your help!
>
> -CK
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From jungck at gmail.com  Sun Feb 28 18:40:06 2010
From: jungck at gmail.com (jungck)
Date: Sun, 28 Feb 2010 12:40:06 -0500
Subject: [R-sig-ME] glmer ordered response models
In-Reply-To: <C0772C7568B5374481D2F8A880E9BBDF0454F51E22@DC1EX07CMS.air.org>
References: <6a32069d1002261158k5f2dd10dhcc151de8bab9766f@mail.gmail.com>
	<C0772C7568B5374481D2F8A880E9BBDF0454F51E10@DC1EX07CMS.air.org>
	<20100226204312.sakl1irzggwwkgk0@www.staffmail.ed.ac.uk>
	<C0772C7568B5374481D2F8A880E9BBDF0454F51E22@DC1EX07CMS.air.org>
Message-ID: <6a32069d1002280940w769f19ddrd7b24aa79df0b745@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100228/f4420888/attachment.pl>

From julien.martin2 at usherbrooke.ca  Mon Mar  1 20:26:35 2010
From: julien.martin2 at usherbrooke.ca (Julien Martin)
Date: Mon, 01 Mar 2010 14:26:35 -0500
Subject: [R-sig-ME] Approximate standard error for variance component with
	lmer
In-Reply-To: <mailman.2.1267441201.4650.r-sig-mixed-models@r-project.org>
References: <mailman.2.1267441201.4650.r-sig-mixed-models@r-project.org>
Message-ID: <1267471595.5957.9.camel@julien-uni>

Hi
I am wondering if it is possible to compute approximate standard error
for variance component as proposed by Fischer et al 2004 using lmer. 

Thanks

Julien

Fischer, TM., Gilmour, AR. and Werf, JHVD. (2004). Computing approximate
standard errors for genetic parameters derived from random regression
models fitted by average information REML. Genetics Selection Evolution
36, 363-369.

-- 
-------------
Julien Martin
Candidat au Doctorat
D?partement de Biologie
Universit? de Sherbrooke
Sherbrooke, Qc, Canada



From bates at stat.wisc.edu  Mon Mar  1 20:56:43 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 1 Mar 2010 13:56:43 -0600
Subject: [R-sig-ME] Approximate standard error for variance component
	with lmer
In-Reply-To: <1267471595.5957.9.camel@julien-uni>
References: <mailman.2.1267441201.4650.r-sig-mixed-models@r-project.org>
	<1267471595.5957.9.camel@julien-uni>
Message-ID: <40e66e0b1003011156l3e966371mfc13b34588a4dfd8@mail.gmail.com>

2010/3/1 Julien Martin <julien.martin2 at usherbrooke.ca>:
> Hi
> I am wondering if it is possible to compute approximate standard error
> for variance component as proposed by Fischer et al 2004 using lmer.
>
> Thanks
>
> Julien
>
> Fischer, TM., Gilmour, AR. and Werf, JHVD. (2004). Computing approximate
> standard errors for genetic parameters derived from random regression
> models fitted by average information REML. Genetics Selection Evolution
> 36, 363-369.

Part of the point of the profiling of the parameters in mixed-effects
models that I describe in chapters 1 and 2 of the book I am writing
(chapter drafts are available at
http://lme4.R-forge.R-project.org/book/) is to show that the estimates
of variance components are not symmetrically distributed - in fact
they are quite asymmetric.  In such cases there isn't much point in
computing a standard error.  You could do so from the profiles but I
don't see the point.



From james.croft at aut.ac.nz  Mon Mar  1 23:47:38 2010
From: james.croft at aut.ac.nz (James Croft)
Date: Tue, 2 Mar 2010 11:47:38 +1300
Subject: [R-sig-ME] specifying model with multiple interactions
Message-ID: <8F74B98E-CA55-4ADE-BF54-6D43A2412B26@aut.ac.nz>

I am having trouble specifying a mixed effects model and would  
appreciate some guidance.

Background
We are interested in how cricket batsmen respond to balls delivered  
from bowling machines. We filmed batsmen facing deliveries at  
different speeds from a bower and machine. The data is very expensive  
because each video has to be digitized by hand to identify various  
parameters of interest. Hence we only have data on 13 subjects (and it  
has missing values).

One objective is to predict the timing of bat lift (BatUp) by delivery  
speed (Speed) for a given condition (Delivery) and to assess the  
variability across subjects (Subject).

Delivery  : Factor w/ 2 levels "Bowler","Machine"
Subject   : Factor w/ 13 levels
Speed     : num
BatUp     : num

So I believe I want to predict a fixed effect for speed and random  
slope and intercept for each level of a factor created by  
Subject:Delivery

I'm getting a bit confused with the combinations of random effect.
I have read through a few of the chapters  of Doug Bates. (2010).  
lme4: Mixed-effects modeling with R.

This is as far as I have got...

BatUp ~ Speed + (1|Delivery) + (1|Subject) + (1|Subject:Delivery) +  
(0+Speed|Subject:Delivery)

Thanks in advance for any help.

Regards,
James









Regards,
James


________________________________________
James Croft, PhD
Research Fellow
Sport Performance Research Institute New Zealand
School of Sport and Recreation
AUT University
Private Bag 92006
Auckland 1142
New Zealand

Phone 64-9-921 9999 ext 7685
Fax 64-9 921 9960
Email james.croft at aut.ac.nz
http://www.isrrnz.ac.nz/



From juliet.hannah at gmail.com  Mon Mar  1 23:55:59 2010
From: juliet.hannah at gmail.com (Juliet Hannah)
Date: Mon, 1 Mar 2010 17:55:59 -0500
Subject: [R-sig-ME] R2 measure in mixed models?
In-Reply-To: <a072ed701002260727k7dd64473m68d56aaf2919dab8@mail.gmail.com>
References: <221597f21002170300lcd22247sc202c3bb11bf6469@mail.gmail.com>
	<11E3FEA23855407391779E0D7CE701AB@TheVoid>
	<221597f21002172255h7004365di8d7155a77809ade1@mail.gmail.com>
	<a072ed701002260537m453c697v290c1a15cbec4b37@mail.gmail.com>
	<40e66e0b1002260630j43f1e508lea82fcfd4ee3b427@mail.gmail.com>
	<a072ed701002260727k7dd64473m68d56aaf2919dab8@mail.gmail.com>
Message-ID: <93d6f2a81003011455g40fac57fy1dee8a00b55e2788@mail.gmail.com>

How does one try and summarize the "strength" of a fixed effect in the
mixed model setting?

It is this question that had led me to try and understand the various
pseudo R-squares.

I'm curious how others do this (for any definition of strength).



On Fri, Feb 26, 2010 at 10:27 AM, Nick Isaac <njbisaac at googlemail.com> wrote:
> Thanks for these pertinent comments.
>
> I can't comment on the motivation for the original post. I have always felt
> that a single dimensionless Rsq was fairly meaningless in the context of
> mixed models.
>
> Gelman & Pardoe's formula summarizes the fit at each level in the model
> separately. This has more intuitive appeal, especially since I tend to fit
> models containing fixed effects at the group level. The motivation then
> would be to write a sentence along the lines of 'gender explains 5% of the
> among-subject variance in orthodontic growth curves; age explains 80% of the
> within-subject variation'.
>
> Incidentally, G&P also state that negative Rsqs might be expected (for their
> index): essentially it means that adding a fixed effect causes the variance
> of a random effect to increase..
>
> Best wishes, Nick
>
>
> On 26 February 2010 14:30, Douglas Bates <bates at stat.wisc.edu> wrote:
>
>> On Fri, Feb 26, 2010 at 7:37 AM, Nick Isaac <njbisaac at googlemail.com>
>> wrote:
>> > Sorry to be joining this late.
>>
>> > I have written some code to implement Gelman & Pardoe's Rsq for an lmer
>> > object. It gives some believable results, but it's difficult to be
>> confident
>> > because of the translation from Bayesian into frequentist paradigms.
>>
>> > If anyone is interested then I'd be really happy to discuss this off-list
>> > and share/develop the code.
>>
>> Assuming that one wants to define an R^2 measure, I think an argument
>> could be made for treating the penalized residual sum of squares from
>> a linear mixed model in the same way that we consider the residual sum
>> of squares from a linear model. ?Or one could use just the residual
>> sum of squares without the penalty or the minimum residual sum of
>> squares obtainable from a given set of terms, which corresponds to an
>> infinite precision matrix. ?I don't know, really. ?It depends on what
>> you are trying to characterize.
>>
>> In other words, what's the purpose? ?What aspect of the R^2 for a
>> linear model are you trying to generalize?
>>
>> I'm sorry if I sound argumentative but discussions like this sometimes
>> frustrate me. ?A linear mixed model does not behave exactly like a
>> linear model without random effects so a measure that may be
>> appropriate for the linear model does not necessarily generalize. ?I'm
>> not saying that this is the case but if the request is "I don't care
>> what the number means or if indeed it means anything at all, just give
>> me a number I can report", that's not the style of statistics I
>> practice.
>>
>> I regard Bill Venables' wonderful unpublished paper "Exegeses on
>> Linear Models" (just put the name in a search engine to find a copy -
>> there is only one paper with "Exegeses" and "Linear Models" in the
>> title) as required reading for statisticians. ?As Bill emphasizes in
>> that paper, statistics is not just a collection of formulas (many of
>> which are based on approximations). ?It's about models and comparing
>> how well different models fit the observed data. ?If we start with a
>> formula and only ask ourselves "How do we generalize this formula?"
>> we're missing the point. ?We should start at the model.
>>
>> In a linear model the R^2 statistic is a dimensionless comparison of
>> the quality of the current model fit, as measured by the residual sum
>> of squares, to the fit one would obtain from a trivial model. ?When
>> the current model can be shown to contain a model with an intercept
>> term only (and whose coefficient will be estimated by the mean
>> response) then that model fit is the trivial model. ?Otherwise the
>> trivial model is a prediction of zero for each response. ?We know that
>> the trivial model will produce a greater residual sum of squares than
>> the current model fit because the models are nested. ?The R^2 is the
>> proportion of variability not accounted for by the trivial model but
>> accounted for by the current model (my apologies to my grammar
>> teachers for having juxtaposed prepositions).
>>
>> The interesting point there is that when you think of the
>> relationships between models you can determine how you handle the case
>> of a model that does not have an intercept term. ?If you start from
>> the formula instead you can end up calculating a negative R^2 because
>> you compare models that are not nested. ?Such nonsensical results are
>> often reported. ?(I think it was the Mathematica documentation that
>> gave a careful explanation of why you get a negative R^2 instead of
>> recognizing that the formula they were using did not apply in certain
>> cases.)
>>
>> It may be that there is a sensible measure of the quality of fit from
>> a linear mixed model that generalizes the R^2 from a linear model. ?I
>> don't see an obvious candidate but I will freely admit that I haven't
>> thought much about the problem. ?I would ask others who are thinking
>> about this to consider both the "what" and the "why". ?George
>> Mallory's justification of "because it's there" for attempting to
>> climb Everest is perhaps a good justification for such endeavors
>> (Mallory may have questioned his rationale as he lay freezing to death
>> on the mountain). ?I don't think it is a good justification for
>> manipulating formulas.
>>
>>
>> >
>> > Best wishes, Nick
>> >
>> >
>> > On 18 February 2010 06:55, Luisa Carvalheiro <lgcarvalheiro at gmail.com
>> >wrote:
>> >
>> >> Hi Steve,
>> >>
>> >> Thanlks for reply and literature list. Here are 3 papers on ?R2
>> >> calculations for Mixed Models:
>> >>
>> >> M. Mittlbock, T. Waldhor. Adjustments for R2-measures for Poisson
>> >> regression models. Computational Statistics & Data Analysis 34 (2000)
>> >> 461-472
>> >>
>> >> M. Mittlbock Calculating adjusted R2 measures for Poisson regression
>> >> Models. Computer Methods and Programs in Biomedicine 68 (2002) 205?214
>> >>
>> >> H. Liu,Y. Zheng and J. Shen. Goodness-of-fit measures of R2 for
>> >> repeated measures mixed effect models Journal of Applied Statistics.
>> >> 35, 2008, 1081?1092
>> >>
>> >>
>> >> On Thu, Feb 18, 2010 at 1:46 AM, Steven J. Pierce <pierces1 at msu.edu>
>> >> wrote:
>> >> > Luisa,
>> >> >
>> >> > I'm not aware of any packages for that, but I'd like the full citation
>> >> for
>> >> > the paper you mentioned. In exchange, here are some citations for
>> other
>> >> > papers about R-square measures in multilevel models that I've found.
>> >> >
>> >> > Edwards, L. J., Muller, K. E., Wolfinger, R. D., Qaqish, B. F., &
>> >> > Schabenberger, O. (2008). An R2 statistic for fixed effects in the
>> linear
>> >> > mixed model. Statistics in Medicine, 27(29), 6137-6157. doi:
>> >> > 10.1002/sim.3429
>> >> >
>> >> > Gelman, A., & Pardoe, I. (2006). Bayesian measures of explained
>> variance
>> >> and
>> >> > pooling in multilevel (hierarchical) models. Technometrics, 48(2),
>> >> 241-251.
>> >> > doi: 10.1198/004017005000000517
>> >> >
>> >> > Kramer, M. (2005). R2 statistics for mixed models. Proceedings of the
>> >> > Conference on Applied Statistics in Agriculture, 17, 148-160.
>> Retrieved
>> >> from
>> >> >
>> >>
>> http://www.ars.usda.gov/sp2UserFiles/ad_hoc/12000000SpatialWorkshop/19Kramer
>> >> > SupplRsq.pdf
>> >> >
>> >> > Merlo, J., Yang, M., Chaix, B., Lynch, J., & R?stam, L. (2005). A
>> brief
>> >> > conceptual tutorial on multilevel analysis in social epidemiology:
>> >> > investigating contextual phenomena in different groups of people.
>> Journal
>> >> of
>> >> > Epidemiology and Community Health, 59(9), 729-736. doi:
>> >> > 10.1136/jech.2004.023929
>> >> >
>> >> > Orelien, J. G., & Edwards, L. J. (2008). Fixed-effect variable
>> selection
>> >> in
>> >> > linear mixed models using R2 statistics. Computational Statistics &
>> Data
>> >> > Analysis, 52(4), 1896-1907. doi: 10.1016/j.csda.2007.06.006
>> >> >
>> >> > Roberts, J. K., & Monaco, J. P. (2006, April). Effect size measures
>> for
>> >> the
>> >> > two-level linear multilevel model. ?Paper presented at the annual
>> meeting
>> >> of
>> >> > the American Educational Research Association, San Francisco, CA.
>> >> Retrieved
>> >> > from http://www.hlm-online.com/papers/HLM_effect_size.pdf
>> >> >
>> >> > Snijders, T. A. B., & Bosker, R. J. (1994). Modeled variance in
>> two-level
>> >> > models. Sociological Methods & Research, 22(3), 342-363. doi:
>> >> > 10.1177/0049124194022003004
>> >> >
>> >> > Snijders, T. A. B., & Bosker, R. J. (1999). Multilevel analysis.
>> London,
>> >> UK:
>> >> > Sage.
>> >> > Xu, R. (2003). Measuring explained variation in linear mixed effects
>> >> models.
>> >> > Statistics in Medicine, 22(22), 3527-3541. doi: 10.1002/sim.1572
>> >> >
>> >> >
>> >> >
>> >> > Steven J. Pierce
>> >> > Associate Director
>> >> > Center for Statistical Training & Consulting (CSTAT)
>> >> > Michigan State University
>> >> > 178 Giltner Hall
>> >> > East Lansing, MI 48824
>> >> > Web: http://www.cstat.msu.edu
>> >> >
>> >> >
>> >> > -----Original Message-----
>> >> > From: Luisa Carvalheiro [mailto:lgcarvalheiro at gmail.com]
>> >> > Sent: Wednesday, February 17, 2010 6:00 AM
>> >> > To: r-sig-mixed-models at r-project.org
>> >> > Subject: [R-sig-ME] R2 measure in mixed models?
>> >> >
>> >> > Dear mixed modelers,
>> >> >
>> >> > Is there any package for calculating R2 measures for mixed models in R
>> >> (e.g.
>> >> > using the measure proposed by Mittlb ock; ?Waldh or 2000)?
>> >> >
>> >> > Luisa
>> >> >
>> >> >
>> >> >
>> >> >
>> >>
>> >>
>> >>
>> >> --
>> >> Luisa Carvalheiro, PhD
>> >> Southern African Biodiversity Institute, Kirstenbosch Research Center,
>> >> Claremont
>> >> & University of Pretoria
>> >> Postal address - SAWC Pbag X3015 Hoedspruit 1380, South Africa
>> >> telephone - +27 (0) 790250944
>> >> Carvalheiro at sanbi.org
>> >> lgcarvalheiro at gmail.com
>> >>
>> >> _______________________________________________
>> >> R-sig-mixed-models at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>
>> >
>> > ? ? ? ?[[alternative HTML version deleted]]
>> >
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>> >
>>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



From David.Duffy at qimr.edu.au  Tue Mar  2 00:39:30 2010
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Tue, 2 Mar 2010 09:39:30 +1000 (EST)
Subject: [R-sig-ME] R2 measure in mixed models?
In-Reply-To: <93d6f2a81003011455g40fac57fy1dee8a00b55e2788@mail.gmail.com>
References: <221597f21002170300lcd22247sc202c3bb11bf6469@mail.gmail.com><11E3FEA23855407391779E0D7CE701AB@TheVoid><221597f21002172255h7004365di8d7155a77809ade1@mail.gmail.com><a072ed701002260537m453c697v290c1a15cbec4b37@mail.gmail.com><40e66e0b1002260630j43f1e508lea82fcfd4ee3b427@mail.gmail.com><a072ed701002260727k7dd64473m68d56aaf2919dab8@mail.gmail.com>
	<93d6f2a81003011455g40fac57fy1dee8a00b55e2788@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1003020928490.5906@orpheus.qimr.edu.au>

On Mon, 1 Mar 2010, Juliet Hannah wrote:

> How does one try and summarize the "strength" of a fixed effect in the
> mixed model setting?
>
> It is this question that had led me to try and understand the various
> pseudo R-squares.
>
> I'm curious how others do this (for any definition of strength).
>
> On Fri, Feb 26, 2010 at 10:27 AM, Nick Isaac <njbisaac at googlemail.com> wrote:
>> Thanks for these pertinent comments.
>>
>> I can't comment on the motivation for the original post. I have always felt
>> that a single dimensionless Rsq was fairly meaningless in the context of
>> mixed models.
>>
>> Gelman & Pardoe's formula summarizes the fit at each level in the model
>> separately. This has more intuitive appeal, especially since I tend to fit
>> models containing fixed effects at the group level.
>>>
>>> In other words, what's the purpose? ?What aspect of the R^2 for a
>>> linear model are you trying to generalize?
>>>
>>> I'm sorry if I sound argumentative but discussions like this sometimes
>>> frustrate me. ?A linear mixed model does not behave exactly like a
>>> linear model without random effects so a measure that may be
>>> appropriate for the linear model does not necessarily generalize.
>>>
>>> In a linear model the R^2 statistic is a dimensionless comparison of
>>> the quality of the current model fit, as measured by the residual sum

I have been following this discussion with great interest, and don't pretend
to have any answers.  But, isn't all this only a problem for a MIXED model?
That is, if you made all your variables random effects, then proportion of
variation due to X (in the given population at the given time, yada yada) 
again becomes meaningful?

In the genetics context, where we are usually interested in the random
effects, the "R2" for a given random effect often does strange things
depending on which fixed effects one conditions on.

Another 2c.  David Duffy

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v

From istazahn at gmail.com  Tue Mar  2 00:54:26 2010
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 1 Mar 2010 18:54:26 -0500
Subject: [R-sig-ME] specifying model with multiple interactions
In-Reply-To: <8F74B98E-CA55-4ADE-BF54-6D43A2412B26@aut.ac.nz>
References: <8F74B98E-CA55-4ADE-BF54-6D43A2412B26@aut.ac.nz>
Message-ID: <f55e7cf51003011554u774b8b0ayf1a33940d048aa82@mail.gmail.com>

Hi James,
I think you probably want something along the lines of

 BatUp ~ Speed + Delivery + (1|Subject) + (0+Speed|Subject) +
(0+Delivery|Subject)

assuming that Subject is a unique identifier for each participant. I
highly doubt that you want the (1|Delivery) term in there, as it
surely makes more sense to think of this as a fixed factor.

I'm sure someone will correct me if I'm wrong...
-Ista

On Mon, Mar 1, 2010 at 5:47 PM, James Croft <james.croft at aut.ac.nz> wrote:
> I am having trouble specifying a mixed effects model and would appreciate
> some guidance.
>
> Background
> We are interested in how cricket batsmen respond to balls delivered from
> bowling machines. We filmed batsmen facing deliveries at different speeds
> from a bower and machine. The data is very expensive because each video has
> to be digitized by hand to identify various parameters of interest. Hence we
> only have data on 13 subjects (and it has missing values).
>
> One objective is to predict the timing of bat lift (BatUp) by delivery speed
> (Speed) for a given condition (Delivery) and to assess the variability
> across subjects (Subject).
>
> Delivery ?: Factor w/ 2 levels "Bowler","Machine"
> Subject ? : Factor w/ 13 levels
> Speed ? ? : num
> BatUp ? ? : num
>
> So I believe I want to predict a fixed effect for speed and random slope and
> intercept for each level of a factor created by Subject:Delivery
>
> I'm getting a bit confused with the combinations of random effect.
> I have read through a few of the chapters ?of Doug Bates. (2010). lme4:
> Mixed-effects modeling with R.
>
> This is as far as I have got...
>
> BatUp ~ Speed + (1|Delivery) + (1|Subject) + (1|Subject:Delivery) +
> (0+Speed|Subject:Delivery)
>
> Thanks in advance for any help.
>
> Regards,
> James
>
>
>
>
>
>
>
>
>
> Regards,
> James
>
>
> ________________________________________
> James Croft, PhD
> Research Fellow
> Sport Performance Research Institute New Zealand
> School of Sport and Recreation
> AUT University
> Private Bag 92006
> Auckland 1142
> New Zealand
>
> Phone 64-9-921 9999 ext 7685
> Fax 64-9 921 9960
> Email james.croft at aut.ac.nz
> http://www.isrrnz.ac.nz/
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Ista Zahn
Graduate student
University of Rochester
Department of Clinical and Social Psychology
http://yourpsyche.org



From juliet.hannah at gmail.com  Tue Mar  2 00:59:46 2010
From: juliet.hannah at gmail.com (Juliet Hannah)
Date: Mon, 1 Mar 2010 18:59:46 -0500
Subject: [R-sig-ME] R2 measure in mixed models?
In-Reply-To: <Pine.LNX.4.64.1003020928490.5906@orpheus.qimr.edu.au>
References: <221597f21002170300lcd22247sc202c3bb11bf6469@mail.gmail.com>
	<11E3FEA23855407391779E0D7CE701AB@TheVoid>
	<221597f21002172255h7004365di8d7155a77809ade1@mail.gmail.com>
	<a072ed701002260537m453c697v290c1a15cbec4b37@mail.gmail.com>
	<40e66e0b1002260630j43f1e508lea82fcfd4ee3b427@mail.gmail.com>
	<a072ed701002260727k7dd64473m68d56aaf2919dab8@mail.gmail.com>
	<93d6f2a81003011455g40fac57fy1dee8a00b55e2788@mail.gmail.com>
	<Pine.LNX.4.64.1003020928490.5906@orpheus.qimr.edu.au>
Message-ID: <93d6f2a81003011559v21ec081avd2a6586bd2bc8517@mail.gmail.com>

Hi David,

How would you go about summarizing the how much variation a SNP (fixed effect)
explains (in the mixed model setting)/ or the "strength" of the SNP.

Thanks,

Juliet

On Mon, Mar 1, 2010 at 6:39 PM, David Duffy <David.Duffy at qimr.edu.au> wrote:
> On Mon, 1 Mar 2010, Juliet Hannah wrote:
>
>> How does one try and summarize the "strength" of a fixed effect in the
>> mixed model setting?
>>
>> It is this question that had led me to try and understand the various
>> pseudo R-squares.
>>
>> I'm curious how others do this (for any definition of strength).
>>
>> On Fri, Feb 26, 2010 at 10:27 AM, Nick Isaac <njbisaac at googlemail.com>
>> wrote:
>>>
>>> Thanks for these pertinent comments.
>>>
>>> I can't comment on the motivation for the original post. I have always
>>> felt
>>> that a single dimensionless Rsq was fairly meaningless in the context of
>>> mixed models.
>>>
>>> Gelman & Pardoe's formula summarizes the fit at each level in the model
>>> separately. This has more intuitive appeal, especially since I tend to
>>> fit
>>> models containing fixed effects at the group level.
>>>>
>>>> In other words, what's the purpose? ?What aspect of the R^2 for a
>>>> linear model are you trying to generalize?
>>>>
>>>> I'm sorry if I sound argumentative but discussions like this sometimes
>>>> frustrate me. ?A linear mixed model does not behave exactly like a
>>>> linear model without random effects so a measure that may be
>>>> appropriate for the linear model does not necessarily generalize.
>>>>
>>>> In a linear model the R^2 statistic is a dimensionless comparison of
>>>> the quality of the current model fit, as measured by the residual sum
>
> I have been following this discussion with great interest, and don't pretend
> to have any answers. ?But, isn't all this only a problem for a MIXED model?
> That is, if you made all your variables random effects, then proportion of
> variation due to X (in the given population at the given time, yada yada)
> again becomes meaningful?
>
> In the genetics context, where we are usually interested in the random
> effects, the "R2" for a given random effect often does strange things
> depending on which fixed effects one conditions on.
>
> Another 2c. ?David Duffy
>
> --
> | David Duffy (MBBS PhD) ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ,-_|\
> | email: davidD at qimr.edu.au ?ph: INT+61+7+3362-0217 fax: -0101 ?/ ? ? *
> | Epidemiology Unit, Queensland Institute of Medical Research ? \_,-._/
> | 300 Herston Rd, Brisbane, Queensland 4029, Australia ?GPG 4D0B994A v
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



From David.Duffy at qimr.edu.au  Tue Mar  2 02:30:11 2010
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Tue, 2 Mar 2010 11:30:11 +1000 (EST)
Subject: [R-sig-ME] R2 measure in mixed models?
In-Reply-To: <93d6f2a81003011559v21ec081avd2a6586bd2bc8517@mail.gmail.com>
References: <221597f21002170300lcd22247sc202c3bb11bf6469@mail.gmail.com>
	<11E3FEA23855407391779E0D7CE701AB@TheVoid>
	<221597f21002172255h7004365di8d7155a77809ade1@mail.gmail.com>
	<a072ed701002260537m453c697v290c1a15cbec4b37@mail.gmail.com>
	<40e66e0b1002260630j43f1e508lea82fcfd4ee3b427@mail.gmail.com>
	<a072ed701002260727k7dd64473m68d56aaf2919dab8@mail.gmail.com>
	<93d6f2a81003011455g40fac57fy1dee8a00b55e2788@mail.gmail.com>
	<Pine.LNX.4.64.1003020928490.5906@orpheus.qimr.edu.au>
	<93d6f2a81003011559v21ec081avd2a6586bd2bc8517@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1003021115580.10054@orpheus.qimr.edu.au>

On Mon, 1 Mar 2010, Juliet Hannah wrote:

> How would you go about summarizing the how much variation a SNP (fixed effect)
> explains (in the mixed model setting)/ or the "strength" of the SNP.

In a way, that is an easy one, as we can plug in our estimates for the 
minor allele frequency and genotypic means into the population genetic 
model for the trait, where our estimates of the total genetic and 
environmenal variances will usually come from other (pedigree based) 
studies.  The contribution of the fixed effect is expressed as a 
proportion of the genetic covariation between related individuals in the 
population (including with themselves).  It seems to me that if one wanted 
to do this all in a single model, the SNP would be included as a random 
effect.  The usual measured genotypes model fitted to pedigree data ends 
up estimating the genotypic means and the residual genetic variance, which 
I don't find completely satisfactory.

It becomes more interesting for categorical traits/GLMMs, where 
some assumptions about gene by gene interaction and the appropriate link 
function have to be made.

Cheers, David.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From Steve.Candy at aad.gov.au  Tue Mar  2 05:23:57 2010
From: Steve.Candy at aad.gov.au (Steve Candy)
Date: Tue, 2 Mar 2010 15:23:57 +1100
Subject: [R-sig-ME] R2 measure in mixed models? (Steve Candy)
	[Sec=Unclassified]
Message-ID: <42C7503E0B99F248B06BC65E7D2B4E020156D848E276@EX2K7-CCR.AAD.GOV.AU>

A further complication is that there could be information about a fixed effect at more than one sampling level in a LMM.
So how does one combine %variance explained across multiple levels to give an overall "strength" of a fixed effect?

The classic example is the incomplete block design analysis with recovery of inter-block information. There is information on treatment means and comparisons in both the plots within-blocks and in the block totals.


On Mon, 1 Mar, 2010 at 17:55:59 PM, Juliet Hannah <juliet.hannah at gmail.com> wrote:

>How does one try and summarize the "strength" of a fixed effect in the mixed model setting?
>It is this question that had led me to try and understand the various pseudo R-squares.
>I'm curious how others do this (for any definition of strength).


>>On Fri, Feb 26, 2010 at 10:27 AM, Nick Isaac <njbisaac at googlemail.com> wrote:
>> Thanks for these pertinent comments.
>>
>> I can't comment on the motivation for the original post. I have always
>> felt that a single dimensionless Rsq was fairly meaningless in the
>> context of mixed models.
>>
>> Gelman & Pardoe's formula summarizes the fit at each level in the
>> model separately. This has more intuitive appeal, especially since I
>> tend to fit models containing fixed effects at the group level. The
>> motivation then would be to write a sentence along the lines of
>> 'gender explains 5% of the among-subject variance in orthodontic
>> growth curves; age explains 80% of the within-subject variation'.
>>
>> Incidentally, G&P also state that negative Rsqs might be expected (for
>> their
>> index): essentially it means that adding a fixed effect causes the variance
>> of a random effect to increase..
>>
>> Best wishes, Nick

Regards Steve

-------------------------------------------------------------
Steven G Candy
Senior Applied Statistician
Southern Ocean Ecosystems
Australian Antarctic Division
Kingston, Tasmania 7050
Australia
ph +61 (0)3 6232 3135
___________________________________________________________________________

    Australian Antarctic Division - Commonwealth of Australia
IMPORTANT: This transmission is intended for the addressee only. If you are not the
intended recipient, you are notified that use or dissemination of this communication is
strictly prohibited by Commonwealth law. If you have received this transmission in error,
please notify the sender immediately by e-mail or by telephoning +61 3 6232 3209 and
DELETE the message.
        Visit our web site at http://www.antarctica.gov.au/
___________________________________________________________________________



From chris.knight at manchester.ac.uk  Tue Mar  2 18:01:47 2010
From: chris.knight at manchester.ac.uk (Chris Knight)
Date: Tue, 02 Mar 2010 17:01:47 +0000
Subject: [R-sig-ME] discrete random effect query
Message-ID: <4B8D447B.8060109@manchester.ac.uk>

Dear all,

I have a piece of equipment which produces several time series of data 
simultaneously, for the sake of an example, two lines with the same 
slope but (randomly) different intercepts

    set.seed(17)
    time<-seq(0,24,length.out=241)
    dat1<-time + 5 + rnorm(length(time), sd=0.4)
    dat2<-time + 6 + rnorm(length(time), sd=0.4)

However, for some physical reason that I don't care about and can't seem 
to cure, a substantial (and variable between experiments) minority of 
readings at particular time points (again, which is variable between 
experiments), in all time series are displaced to vary around a slightly 
different line (say 2 away) apparently at random:

    affected<-sample(c(0,1),replace=TRUE, size=length(time), 
prob=c(0.8,0.2))
    dat1<-affected*2+dat1
    dat2<-affected*2+dat2

This seems to be a random effect of reading number and I'd like to model 
it as such. My issue is that this is a discrete effect, clearly not 
drawn from a normal distribution and I don't know if it's possible to 
fit such a random effect, let alone how to do it (particularly when 
there's also the random effect of the different time series to worry about).

What I'm currently doing amounts to fitting a model ignoring the effect, 
eye-balling and putting a line through the residuals to invent a new 
fixed effect (probablyAffected) and then including that in the model:

    
datA<-data.frame(rep(time,2),c(dat1,dat2),factor(c(rep("dat1",241),rep("dat2",241))))
    names(datA)<-c("time","dat","series")
    library(nlme)  
    lme1<-lme(fixed= dat~time, random= ~1 | series, data=datA)
    plot(resid(lme1)[1:241],resid(lme1)[242:482])
    abline(1.4,-1)
    probablyAffected<-rep((resid(lme1)[1:241]+resid(lme1)[242:482])>1.4, 2)
    lme2<-lme(fixed= dat~time+probablyAffected, random= ~1 | series, 
data=datA)

This more or less works, though in reality, there are more time series 
and more complex curves than this example, so where to draw the line 
becomes more like guesswork (and/or a clustering problem) and the 
influence of this effect may be more complex than simply adding a value 
to the intercept, which also makes things less clear.

I feel I may be missing something obvious, but does anyone have 
suggestions for a better way to go about this?

Any suggestions much appreciated,

Chris

-- 
------------------------------------------------------------------------
Dr Christopher Knight                             Michael Smith Building
Wellcome Trust RCD Fellow                       Faculty of Life Sciences
Tel:  +44 (0)161 2755378                    The University of Manchester
room B.2012                                                  Oxford Road
tinyurl.com/knightLab/                                Manchester M13 9PT
? . ,,><(((?>                                                         UK



From Emma.Stone at bristol.ac.uk  Wed Mar  3 13:19:29 2010
From: Emma.Stone at bristol.ac.uk (Emma Stone)
Date: Wed, 03 Mar 2010 12:19:29 +0000
Subject: [R-sig-ME] Running repeated measures in lme4
Message-ID: <98AAA74084A2FD8851D9065D@bio-mammal012.ads.bris.ac.uk>

Dear all,

I wander if you can help.

I am running a repeated measures model with lmer.I have 8 sites, at each I 
conducted an experiment with treatments which have 4 levels. Each treatment 
was conducted only once per site, but each site has one of each of the 
treatment levels so it is balanced. Obviously the treatments within sites 
are the repeated measures component, and I want to look at differences 
between treatments within sites, I am not really interested in the site 
group effect but need to incorporate it. So I have set up my model as 
follows:

model1<-lmer~(minutes~treatment+(treatment|site), data = data)


But when I run the model, it gives no variance for the group level effect 
as shown below.

Random effects:
 Groups   Name        Variance Std.Dev. Corr
 site     (Intercept) 0.00000  0.00000
          treatment   0.00000  0.00000    NaN
 Residual             0.07707  0.27762
Number of obs: 32, groups: site, 8

Is this because I only have one replicate of each treatment level at each 
site? Can anyone help?

Thanks

Emma
University of Bristol



From bolker at ufl.edu  Wed Mar  3 13:28:06 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Wed, 03 Mar 2010 07:28:06 -0500
Subject: [R-sig-ME] Running repeated measures in lme4
In-Reply-To: <98AAA74084A2FD8851D9065D@bio-mammal012.ads.bris.ac.uk>
References: <98AAA74084A2FD8851D9065D@bio-mammal012.ads.bris.ac.uk>
Message-ID: <4B8E55D6.90902@ufl.edu>

Emma Stone wrote:
> Dear all,
> 
> I wander if you can help.
> 
> I am running a repeated measures model with lmer.I have 8 sites, at each I 
> conducted an experiment with treatments which have 4 levels. Each treatment 
> was conducted only once per site, but each site has one of each of the 
> treatment levels so it is balanced. Obviously the treatments within sites 
> are the repeated measures component, and I want to look at differences 
> between treatments within sites, I am not really interested in the site 
> group effect but need to incorporate it. So I have set up my model as 
> follows:
> 
> model1<-lmer~(minutes~treatment+(treatment|site), data = data)

  This model fits a site by treatment interaction, which you don't
have enough information for since you don't have replication.  I believe
you want

model1<-lmer~(minutes~treatment+(1|site), data = data)


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From Emma.Stone at bristol.ac.uk  Wed Mar  3 13:45:59 2010
From: Emma.Stone at bristol.ac.uk (Emma Stone)
Date: Wed, 03 Mar 2010 12:45:59 +0000
Subject: [R-sig-ME] Running repeated measures in lme4
In-Reply-To: <4B8E55D6.90902@ufl.edu>
References: <98AAA74084A2FD8851D9065D@bio-mammal012.ads.bris.ac.uk>
	<4B8E55D6.90902@ufl.edu>
Message-ID: <F4D567D20A97979D5A43BC95@bio-mammal012.ads.bris.ac.uk>

Hi Ben,

Thanks for your reply, however I have re ran this and I still get zero 
group variance. Also, forgive my ignorance but doesn't this code remove the 
repeated measures element of the design? Also for note, I ran my code with 
a poisson distribution and I did get variance outputs for the Random Group 
level.

Emma

--On 03 March 2010 07:28 -0500 Ben Bolker <bolker at ufl.edu> wrote:

> Emma Stone wrote:
>> Dear all,
>>
>> I wander if you can help.
>>
>> I am running a repeated measures model with lmer.I have 8 sites, at each
>> I  conducted an experiment with treatments which have 4 levels. Each
>> treatment  was conducted only once per site, but each site has one of
>> each of the  treatment levels so it is balanced. Obviously the
>> treatments within sites  are the repeated measures component, and I want
>> to look at differences  between treatments within sites, I am not really
>> interested in the site  group effect but need to incorporate it. So I
>> have set up my model as  follows:
>>
>> model1<-lmer~(minutes~treatment+(treatment|site), data = data)
>
>   This model fits a site by treatment interaction, which you don't
> have enough information for since you don't have replication.  I believe
> you want
>
> model1<-lmer~(minutes~treatment+(1|site), data = data)
>
>
> --
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / people.biology.ufl.edu/bolker
> GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



----------------------
Emma Stone
Postgraduate Researcher
Bat Ecology and Bioacoustics Lab
& Mammal Research Unit
School of Biological Sciences,
University of Bristol, Woodland Road,
Bristol, BS8 1UG
Email: emma.stone at bristol.ac.uk



From andydolman at gmail.com  Wed Mar  3 14:15:11 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Wed, 3 Mar 2010 14:15:11 +0100
Subject: [R-sig-ME] Running repeated measures in lme4
In-Reply-To: <F4D567D20A97979D5A43BC95@bio-mammal012.ads.bris.ac.uk>
References: <98AAA74084A2FD8851D9065D@bio-mammal012.ads.bris.ac.uk>
	<4B8E55D6.90902@ufl.edu>
	<F4D567D20A97979D5A43BC95@bio-mammal012.ads.bris.ac.uk>
Message-ID: <951234ac1003030515v73101a0n65cd17f4dc65e406@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100303/0460cc78/attachment.pl>

From andydolman at gmail.com  Wed Mar  3 14:25:57 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Wed, 3 Mar 2010 14:25:57 +0100
Subject: [R-sig-ME] Running repeated measures in lme4
In-Reply-To: <F4D567D20A97979D5A43BC95@bio-mammal012.ads.bris.ac.uk>
References: <98AAA74084A2FD8851D9065D@bio-mammal012.ads.bris.ac.uk>
	<4B8E55D6.90902@ufl.edu>
	<F4D567D20A97979D5A43BC95@bio-mammal012.ads.bris.ac.uk>
Message-ID: <951234ac1003030525s1446e5cj898f71fb25b081be@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100303/b0047c37/attachment.pl>

From Emma.Stone at bristol.ac.uk  Wed Mar  3 15:01:15 2010
From: Emma.Stone at bristol.ac.uk (Emma Stone)
Date: Wed, 03 Mar 2010 14:01:15 +0000
Subject: [R-sig-ME] Running repeated measures in lme4
In-Reply-To: <4B8E630B.4050609@sbg.ac.at>
References: <98AAA74084A2FD8851D9065D@bio-mammal012.ads.bris.ac.uk>
	<4B8E55D6.90902@ufl.edu>
	<F4D567D20A97979D5A43BC95@bio-mammal012.ads.bris.ac.uk>
	<4B8E630B.4050609@sbg.ac.at>
Message-ID: <D997FE0627E6F04E1B534912@bio-mammal012.ads.bris.ac.uk>

Hi Everyone,

Thanks for your replies in response:

Yes my data are

site	treatment		minutes
1	1			15
1	2			16
1	3			60
1	4			35
2	1			
2	2
2	3
2	1

etc

Regards the repeated measures element: although I only have one replicate 
of each treatment level, the subject is site and at each site I repeatedly 
measured the response across treatments, treatments 1-4 were sequentially 
measured on each subject.

Regards using the model1<-lmer~(minutes~treatment+(1|site), data = data)

"The intercept value for the response is allowed to vary randomly between 
sites - the unit that has been measured repeatedly. ". Forgive me for 
sounding stupid, but I am not sure that I really understand this, if this 
is the site level variation in the intercept of the response, isnt this my 
group level effect regardless of treatment? If so how can it be accounting 
for the repeated measures, as the repeated measures are treatments within 
sites.

I am not interested in the between sites differences in intercepts - 
overall site level effects in themselves, i.e. I don't care if there is a 
difference between sites in terms of intercept, as I would expect there to 
be as they are a random selection of sites, which all start with different 
actual values.

I am interested in how the response changes between treatments within site 
- and whether this pattern (slope) is the same across sites. So I 
understand that I am after the within subject effects of treatment across 
sites, therefore - whether the effect of treatment is the same across sites 
(the slope), if it significantly different between sites, there is no 
overall effect of treatment.

I then would want to conduct post hocs to test which treatment levels are 
significantly different from each other.

I have run this model (from the same design) with a different data set in 
SPSS and it runs fine, there are enough degrees of freedom as I have 4 
treatments and 8 sites.

I tried using a poisson model because I used the unlogged data.

Thanks


Emma


--On 03 March 2010 14:24 +0100 "Andy Fugard (Work)" <andy.fugard at sbg.ac.at> 
wrote:

> Emma Stone wrote:
>> Hi Ben,
>>
>> Thanks for your reply, however I have re ran this and I still get zero
>> group variance. Also, forgive my ignorance but doesn't this code remove
>> the repeated measures element of the design? Also for note, I ran my
>> code with a poisson distribution and I did get variance outputs for the
>> Random Group level.
>
> Would be helpful to know more about the dataset, maybe use "head" to get
> the first few rows.  Does it look like this?
>
>   site   treatment    minutes
>   1      1
>   1      2
>   1      3
>   1      4
>   2      1
>   2      2
>   2      3
>   2      4
>   ...
>   8
>   8
>   8
>   8
>
> Also what was the whole summary output.
>
> Have you tried this?
>
>   xyplot(minutes ~ treatment|site)
>
> Is it possible that there is no variation between sites?
>
> /A
>
>
>
>
>
>>
>> Emma
>>
>> --On 03 March 2010 07:28 -0500 Ben Bolker <bolker at ufl.edu> wrote:
>>
>>> Emma Stone wrote:
>>>> Dear all,
>>>>
>>>> I wander if you can help.
>>>>
>>>> I am running a repeated measures model with lmer.I have 8 sites, at
>>>> each I  conducted an experiment with treatments which have 4 levels.
>>>> Each treatment  was conducted only once per site, but each site has
>>>> one of each of the  treatment levels so it is balanced. Obviously the
>>>> treatments within sites  are the repeated measures component, and I
>>>> want to look at differences  between treatments within sites, I am not
>>>> really interested in the site  group effect but need to incorporate
>>>> it. So I have set up my model as  follows:
>>>>
>>>> model1<-lmer~(minutes~treatment+(treatment|site), data = data)
>>>
>>>   This model fits a site by treatment interaction, which you don't
>>> have enough information for since you don't have replication.  I believe
>>> you want
>>>
>>> model1<-lmer~(minutes~treatment+(1|site), data = data)
>>>
>>>
>>> --
>>> Ben Bolker
>>> Associate professor, Biology Dep't, Univ. of Florida
>>> bolker at ufl.edu / people.biology.ufl.edu/bolker
>>> GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc
>>
>>
>>
>> ----------------------
>> Emma Stone
>> Postgraduate Researcher
>> Bat Ecology and Bioacoustics Lab
>> & Mammal Research Unit
>> School of Biological Sciences,
>> University of Bristol, Woodland Road,
>> Bristol, BS8 1UG
>> Email: emma.stone at bristol.ac.uk
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> --
> Andy Fugard, Postdoctoral researcher, ESF LogICCC project
> "Modeling human inference within the framework of probability logic"
> Department of Psychology, University of Salzburg, Austria
> http://www.andyfugard.info



----------------------
Emma Stone
Postgraduate Researcher
Bat Ecology and Bioacoustics Lab
& Mammal Research Unit
School of Biological Sciences,
University of Bristol, Woodland Road,
Bristol, BS8 1UG
Email: emma.stone at bristol.ac.uk



From andydolman at gmail.com  Wed Mar  3 15:31:26 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Wed, 3 Mar 2010 15:31:26 +0100
Subject: [R-sig-ME] Running repeated measures in lme4
In-Reply-To: <D997FE0627E6F04E1B534912@bio-mammal012.ads.bris.ac.uk>
References: <98AAA74084A2FD8851D9065D@bio-mammal012.ads.bris.ac.uk>
	<4B8E55D6.90902@ufl.edu>
	<F4D567D20A97979D5A43BC95@bio-mammal012.ads.bris.ac.uk>
	<4B8E630B.4050609@sbg.ac.at>
	<D997FE0627E6F04E1B534912@bio-mammal012.ads.bris.ac.uk>
Message-ID: <951234ac1003030631i3f589cbaib231537f2e60a7f0@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100303/f5f96ee9/attachment.pl>

From f.calboli at imperial.ac.uk  Wed Mar  3 16:32:52 2010
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Wed, 3 Mar 2010 15:32:52 +0000
Subject: [R-sig-ME] Conditional logistic regression vs lmer
In-Reply-To: <3D3B95AE-7C91-4C29-94A9-244B73BA8980@imperial.ac.uk>
References: <3D3B95AE-7C91-4C29-94A9-244B73BA8980@imperial.ac.uk>
Message-ID: <B9F402C0-CBD0-4939-87CB-8D3B4CF2478F@imperial.ac.uk>

Sorry to dig up an unexciting topic, but the number of random effects in my analysis is increasing so I would like to figure things out. I was trying to compare conditional logistic regression with logistic regression with random terms:

> I am doing a conditional logistic regression with clogit() of library survival, but I have a number of random factors I'd like to add to my model and I was thinking of lmer...
> 
> clg.tigeR = clogit(c.c ~ tIgE.Resp + strata(match), data.ready)
> 
> and all is good. I also have two more variables, both random which I'd like to use, but I am not 100% sure what's the way to go with lmer. I suspect I would need to specify a different intercept for each strata, but seems to baffle me at the moment. The code below might do what I want, but I have no idea if that's correct (i.e. does it match the clogit one + two more random effects?):
> 
> lmer.tigeR = lmer(c.c ~ tIgE.Resp + (tIgE.Resp|match) + (1|Run) + (1|Box), family = binomial, data.ready)
> 
> lmer.tigeR is computed without problems btw.

Most importantly, I utterly fail to see the conceptual difference between *nesting* in a logistic regression with random terms and *strata* in a conditional logistic regression, but that's probably just me.

Best,

F



--
Federico C. F. Calboli
Department of Epidemiology and Biostatistics
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From joyce at mcs.st-and.ac.uk  Wed Mar  3 18:57:07 2010
From: joyce at mcs.st-and.ac.uk (Yuan Yuan)
Date: Wed,  3 Mar 2010 17:57:07 +0000
Subject: [R-sig-ME] var estimates of the random effects variance in lme4
Message-ID: <1267639027.4b8ea2f3c6686@webmail.st-andrews.ac.uk>

Hi, all
For an estimate of the parameter, we have a variance estimate associated with
the parameter estimate.
Say, let beta denote the fixed effect in linear regresssion, we have an estimate
given the data,\hat{beta} and its variance estimate \hat{var}[\hat{beta}].
My question is, for the random effects, denoted by b, sd(b) is our parameter of
interest, but I can not find the estimated sd[sd(b)]. There is \hat{sd(b)} in
the summary list, but not \hat{sd}{\hat{sd(b)}}.

I was told that you can find estimted var[var(random effect)] in SAS
Is there anyone can tell me whether or not I can find var[var(random effect)] in
the output given by glmer in package lme4?
Thank you very much.

Cheers,
Joyce
-- 
Yuan(Joyce) Yuan
PhD student in Statistics

CREEM - Centre for Research into Ecological and Environmental Modelling
University of St Andrews
The Observatory
Buchanan Gardens
St Andrews
Fife
KY16 9LZ
Scotland

Tel: +44 (0)1334 461826
Fax: +44 (0)1334 461800


------------------------------------------------------------------
University of St Andrews Webmail: https://webmail.st-andrews.ac.uk



From bates at stat.wisc.edu  Wed Mar  3 19:21:28 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 3 Mar 2010 12:21:28 -0600
Subject: [R-sig-ME] var estimates of the random effects variance in lme4
In-Reply-To: <1267639027.4b8ea2f3c6686@webmail.st-andrews.ac.uk>
References: <1267639027.4b8ea2f3c6686@webmail.st-andrews.ac.uk>
Message-ID: <40e66e0b1003031021o3b6b795fp99e31afa399fe46d@mail.gmail.com>

On Wed, Mar 3, 2010 at 11:57 AM, Yuan Yuan <joyce at mcs.st-and.ac.uk> wrote:
> Hi, all
> For an estimate of the parameter, we have a variance estimate associated with
> the parameter estimate.

Usually called the standard error of a parameter estimate.

> Say, let beta denote the fixed effect in linear regresssion, we have an estimate
> given the data,\hat{beta} and its variance estimate \hat{var}[\hat{beta}].
> My question is, for the random effects, denoted by b, sd(b) is our parameter of
> interest, but I can not find the estimated sd[sd(b)]. There is \hat{sd(b)} in
> the summary list, but not \hat{sd}{\hat{sd(b)}}.

> I was told that you can find estimted var[var(random effect)] in SAS
> Is there anyone can tell me whether or not I can find var[var(random effect)] in
> the output given by glmer in package lme4?

It is true that SAS does provide a standard error of a variance
estimate from SAS PROC MIXED.  If you check the book by West, Welch
and Galecki (ISBN 1-58488-480-0) you will see that all of the software
systems they use to fit mixed-effects models provide such standard
errors, except for the nlme package in R and the lme4 package for R.
This is intentional.  Standard errors of variance estimates are
nonsensical because the estimators are highly skewed.  This is
discussed and illustrated in chapters 1 and 2 of the book I am writing
for which the chapter drafts are available at
http://lme4.R-forge.R-project.org/book/

> Thank you very much.
>
> Cheers,
> Joyce
> --
> Yuan(Joyce) Yuan
> PhD student in Statistics
>
> CREEM - Centre for Research into Ecological and Environmental Modelling
> University of St Andrews
> The Observatory
> Buchanan Gardens
> St Andrews
> Fife
> KY16 9LZ
> Scotland
>
> Tel: +44 (0)1334 461826
> Fax: +44 (0)1334 461800
>
>
> ------------------------------------------------------------------
> University of St Andrews Webmail: https://webmail.st-andrews.ac.uk
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From David.Duffy at qimr.edu.au  Wed Mar  3 23:23:13 2010
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Thu, 4 Mar 2010 08:23:13 +1000 (EST)
Subject: [R-sig-ME] Conditional logistic regression vs lmer
In-Reply-To: <B9F402C0-CBD0-4939-87CB-8D3B4CF2478F@imperial.ac.uk>
References: <3D3B95AE-7C91-4C29-94A9-244B73BA8980@imperial.ac.uk>
	<B9F402C0-CBD0-4939-87CB-8D3B4CF2478F@imperial.ac.uk>
Message-ID: <Pine.LNX.4.64.1003040741520.2584@orpheus.qimr.edu.au>

On Wed, 3 Mar 2010, Federico Calboli wrote:

> I was trying to compare conditional logistic regression with logistic 
> regression with random terms:
>
>> I am doing a conditional logistic regression with clogit() of library 
>> survival, but I have a number of random factors I'd like to add to my 
>> model and I was thinking of lmer...
>>
>> clg.tigeR = clogit(c.c ~ tIgE.Resp + strata(match), data.ready)
>>
>> and all is good. I also have two more variables, both random which I'd 
>> like to use, but I am not 100% sure what's the way to go with lmer. I 
>> suspect I would need to specify a different intercept for each strata, 
>> but seems to baffle me at the moment. The code below might do what I 
>> want, but I have no idea if that's correct (i.e. does it match the 
>> clogit one + two more random effects?):
>>
>> lmer.tigeR = lmer(c.c ~ tIgE.Resp + (tIgE.Resp|match) + (1|Run) + 
>> (1|Box), family = binomial, data.ready)
>>
>> lmer.tigeR is computed without problems btw.

Was the study a matched case-control design, or is "match" the family or 
some natural clustering variable? How many cases and controls for each 
level of match?  (maybe this was in your earlier email.) If the strata are 
small (eg 1:1), then I would be nervous about (tIgE.Resp|match) giving a 
meaningful estimate, cf c.c ~ tIgE.Resp + (1|match)+ (1|Run) + (1|Box).

> Most importantly, I utterly fail to see the conceptual difference 
> between *nesting* in a logistic regression with random terms and 
> *strata* in a conditional logistic regression, but that's probably just 
> me.

You might read over the intro to the paper by Liang, Qaqish and Zeger on 
the GEE for binary data in JRSSB (?1990 or so), where they contrast the 
different approaches to clustered data.  Basically, the (usual) GLMM fits
a parametric model for the intercepts for each stratum, while the 
CLR discards this information, and for a categorical covariate is "just" 
a permutation test.

FWIW, David Duffy.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From sp8ial at gmail.com  Thu Mar  4 00:25:42 2010
From: sp8ial at gmail.com (glee)
Date: Thu, 4 Mar 2010 10:25:42 +1100
Subject: [R-sig-ME] lme4a?
Message-ID: <54c8adaa1003031525m4d6ba297vddd1191552e94a9c@mail.gmail.com>

I am attempting to following along with Douglas Bates book draft.

R Forge claims that the following works automatically:

install.packages("lme4a", repos="http://R-Forge.R-project.org")

but I get

? package ?lme4a? is not available.

Attempting to obtain the source manually from the lme4 project page
(which points to):

http://r-forge.r-project.org/src/contrib/lme4a_0.999375-46.tar.gz

produces page not found.

I presume this means something is broken? Or is the expectation that
we fetch from SVN?

Regards,
Greg

> sessionInfo()

R version 2.10.1 (2009-12-14)
x86_64-pc-linux-gnu

locale:
?[1] LC_CTYPE=en_AU.UTF-8 ? ? ? LC_NUMERIC=C
?[3] LC_TIME=en_AU.UTF-8 ? ? ? ?LC_COLLATE=en_AU.UTF-8
?[5] LC_MONETARY=C ? ? ? ? ? ? ?LC_MESSAGES=en_AU.UTF-8
?[7] LC_PAPER=en_AU.UTF-8 ? ? ? LC_NAME=C
?[9] LC_ADDRESS=C ? ? ? ? ? ? ? LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_AU.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base



From bolker at ufl.edu  Thu Mar  4 01:31:25 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Wed, 03 Mar 2010 19:31:25 -0500
Subject: [R-sig-ME] lme4a?
In-Reply-To: <54c8adaa1003031525m4d6ba297vddd1191552e94a9c@mail.gmail.com>
References: <54c8adaa1003031525m4d6ba297vddd1191552e94a9c@mail.gmail.com>
Message-ID: <4B8EFF5D.7080201@ufl.edu>

  I'm not sure, but I got it via SVN.  I don't see lme4a exposed
anywhere on r-forge.

  As the web page suggests

svn checkout svn://svn.r-forge.r-project.org/svnroot/lme4
[move to appropriate directory]
cd pkg
R CMD INSTALL lme4a

[you'll need to have all the appropriate build tools installed]

 HOWEVER: lme4a is under EXTREMELY rapid (=unstable) development, and
the current version is broken on my system -- I think (???) that there's
a "mer.h" file that's supposed to have been added but didn't get in.

  The current version on SVN is r685; I had to back up to r679 to get a
working version.

  r680 log says "Removing definitions no longer used" -- perhaps
something extra got removed?

 (I have mucked around with things a bit, so there's an outside chance
that this is my fault -- can anyone else confirm?)

glee wrote:
> I am attempting to following along with Douglas Bates book draft.
> 
> R Forge claims that the following works automatically:
> 
> install.packages("lme4a", repos="http://R-Forge.R-project.org")
> 
> but I get
> 
> ? package ?lme4a? is not available.
> 
> Attempting to obtain the source manually from the lme4 project page
> (which points to):
> 
> http://r-forge.r-project.org/src/contrib/lme4a_0.999375-46.tar.gz
> 
> produces page not found.
> 
> I presume this means something is broken? Or is the expectation that
> we fetch from SVN?
> 
> Regards,
> Greg
> 
>> sessionInfo()
> 
> R version 2.10.1 (2009-12-14)
> x86_64-pc-linux-gnu
> 
> locale:
>  [1] LC_CTYPE=en_AU.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_AU.UTF-8        LC_COLLATE=en_AU.UTF-8
>  [5] LC_MONETARY=C              LC_MESSAGES=en_AU.UTF-8
>  [7] LC_PAPER=en_AU.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_AU.UTF-8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From ggrothendieck at gmail.com  Thu Mar  4 01:41:03 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 3 Mar 2010 19:41:03 -0500
Subject: [R-sig-ME] lme4a?
In-Reply-To: <4B8EFF5D.7080201@ufl.edu>
References: <54c8adaa1003031525m4d6ba297vddd1191552e94a9c@mail.gmail.com> 
	<4B8EFF5D.7080201@ufl.edu>
Message-ID: <971536df1003031641o2e5f8cdfle20752b5fee8a3ab@mail.gmail.com>

I was able to use install.packages to install version 652 (the current
version at the time) of lme4a on my Vista system.

On Wed, Mar 3, 2010 at 7:31 PM, Ben Bolker <bolker at ufl.edu> wrote:
> ?I'm not sure, but I got it via SVN. ?I don't see lme4a exposed
> anywhere on r-forge.
>
> ?As the web page suggests
>
> svn checkout svn://svn.r-forge.r-project.org/svnroot/lme4
> [move to appropriate directory]
> cd pkg
> R CMD INSTALL lme4a
>
> [you'll need to have all the appropriate build tools installed]
>
> ?HOWEVER: lme4a is under EXTREMELY rapid (=unstable) development, and
> the current version is broken on my system -- I think (???) that there's
> a "mer.h" file that's supposed to have been added but didn't get in.
>
> ?The current version on SVN is r685; I had to back up to r679 to get a
> working version.
>
> ?r680 log says "Removing definitions no longer used" -- perhaps
> something extra got removed?
>
> ?(I have mucked around with things a bit, so there's an outside chance
> that this is my fault -- can anyone else confirm?)
>
> glee wrote:
>> I am attempting to following along with Douglas Bates book draft.
>>
>> R Forge claims that the following works automatically:
>>
>> install.packages("lme4a", repos="http://R-Forge.R-project.org")
>>
>> but I get
>>
>> ? package ?lme4a? is not available.
>>
>> Attempting to obtain the source manually from the lme4 project page
>> (which points to):
>>
>> http://r-forge.r-project.org/src/contrib/lme4a_0.999375-46.tar.gz
>>
>> produces page not found.
>>
>> I presume this means something is broken? Or is the expectation that
>> we fetch from SVN?
>>
>> Regards,
>> Greg
>>
>>> sessionInfo()
>>
>> R version 2.10.1 (2009-12-14)
>> x86_64-pc-linux-gnu
>>
>> locale:
>> ?[1] LC_CTYPE=en_AU.UTF-8 ? ? ? LC_NUMERIC=C
>> ?[3] LC_TIME=en_AU.UTF-8 ? ? ? ?LC_COLLATE=en_AU.UTF-8
>> ?[5] LC_MONETARY=C ? ? ? ? ? ? ?LC_MESSAGES=en_AU.UTF-8
>> ?[7] LC_PAPER=en_AU.UTF-8 ? ? ? LC_NAME=C
>> ?[9] LC_ADDRESS=C ? ? ? ? ? ? ? LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_AU.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> --
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / people.biology.ufl.edu/bolker
> GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bolker at ufl.edu  Thu Mar  4 01:43:44 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Wed, 03 Mar 2010 19:43:44 -0500
Subject: [R-sig-ME] lme4a?
In-Reply-To: <4B8EFF5D.7080201@ufl.edu>
References: <54c8adaa1003031525m4d6ba297vddd1191552e94a9c@mail.gmail.com>
	<4B8EFF5D.7080201@ufl.edu>
Message-ID: <4B8F0240.6040000@ufl.edu>

  My apologies.  It was my fault (doh!)
  however, "under rapid development" is still true -- glmer appears to
be working now, but that's recent.



Ben Bolker wrote:
>   I'm not sure, but I got it via SVN.  I don't see lme4a exposed
> anywhere on r-forge.
> 
>   As the web page suggests
> 
> svn checkout svn://svn.r-forge.r-project.org/svnroot/lme4
> [move to appropriate directory]
> cd pkg
> R CMD INSTALL lme4a
> 
> [you'll need to have all the appropriate build tools installed]
> 
>  HOWEVER: lme4a is under EXTREMELY rapid (=unstable) development, and
> the current version is broken on my system -- I think (???) that there's
> a "mer.h" file that's supposed to have been added but didn't get in.
> 
>   The current version on SVN is r685; I had to back up to r679 to get a
> working version.
> 
>   r680 log says "Removing definitions no longer used" -- perhaps
> something extra got removed?
> 
>  (I have mucked around with things a bit, so there's an outside chance
> that this is my fault -- can anyone else confirm?)
> 
> glee wrote:
>> I am attempting to following along with Douglas Bates book draft.
>>
>> R Forge claims that the following works automatically:
>>
>> install.packages("lme4a", repos="http://R-Forge.R-project.org")
>>
>> but I get
>>
>> ? package ?lme4a? is not available.
>>
>> Attempting to obtain the source manually from the lme4 project page
>> (which points to):
>>
>> http://r-forge.r-project.org/src/contrib/lme4a_0.999375-46.tar.gz
>>
>> produces page not found.
>>
>> I presume this means something is broken? Or is the expectation that
>> we fetch from SVN?
>>
>> Regards,
>> Greg
>>
>>> sessionInfo()
>> R version 2.10.1 (2009-12-14)
>> x86_64-pc-linux-gnu
>>
>> locale:
>>  [1] LC_CTYPE=en_AU.UTF-8       LC_NUMERIC=C
>>  [3] LC_TIME=en_AU.UTF-8        LC_COLLATE=en_AU.UTF-8
>>  [5] LC_MONETARY=C              LC_MESSAGES=en_AU.UTF-8
>>  [7] LC_PAPER=en_AU.UTF-8       LC_NAME=C
>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_AU.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From sp8ial at gmail.com  Thu Mar  4 02:46:58 2010
From: sp8ial at gmail.com (glee)
Date: Thu, 4 Mar 2010 12:46:58 +1100
Subject: [R-sig-ME] lme4a?
In-Reply-To: <4B8F0240.6040000@ufl.edu>
References: <54c8adaa1003031525m4d6ba297vddd1191552e94a9c@mail.gmail.com>
	<4B8EFF5D.7080201@ufl.edu> <4B8F0240.6040000@ufl.edu>
Message-ID: <54c8adaa1003031746k2a6be8a0wa4c2dea738c46713@mail.gmail.com>

> svn checkout svn://svn.r-forge.r-project.org/svnroot/lme4

I am behind a university firewall which (apparently) has port 3690
(svn:// default) blocked.

The nightly snapshot (linked from
http://r-forge.r-project.org/scm/?group_id=60) downloads ok, and
appears to build, but fails with

Error : package 'Matrix' 0.999375-37 was found, but >= 0.999375.38 is
required by 'lme4a'
ERROR: lazy loading failed for package ?lme4a?

As far as I can see 0.999375-37 is the latest version available on CRAN.

Thanks for the suggestions. At least this path appears that it could
work, if I am able to satisfy dependencies. I will keep trying.


On 4 March 2010 11:43, Ben Bolker <bolker at ufl.edu> wrote:
> ?My apologies. ?It was my fault (doh!)
> ?however, "under rapid development" is still true -- glmer appears to
> be working now, but that's recent.
>
>
>
> Ben Bolker wrote:
>> ? I'm not sure, but I got it via SVN. ?I don't see lme4a exposed
>> anywhere on r-forge.
>>
>> ? As the web page suggests
>>
>> svn checkout svn://svn.r-forge.r-project.org/svnroot/lme4
>> [move to appropriate directory]
>> cd pkg
>> R CMD INSTALL lme4a
>>
>> [you'll need to have all the appropriate build tools installed]
>>
>> ?HOWEVER: lme4a is under EXTREMELY rapid (=unstable) development, and
>> the current version is broken on my system -- I think (???) that there's
>> a "mer.h" file that's supposed to have been added but didn't get in.
>>
>> ? The current version on SVN is r685; I had to back up to r679 to get a
>> working version.
>>
>> ? r680 log says "Removing definitions no longer used" -- perhaps
>> something extra got removed?
>>
>> ?(I have mucked around with things a bit, so there's an outside chance
>> that this is my fault -- can anyone else confirm?)
>>
>> glee wrote:
>>> I am attempting to following along with Douglas Bates book draft.
>>>
>>> R Forge claims that the following works automatically:
>>>
>>> install.packages("lme4a", repos="http://R-Forge.R-project.org")
>>>
>>> but I get
>>>
>>> ? package ?lme4a? is not available.
>>>
>>> Attempting to obtain the source manually from the lme4 project page
>>> (which points to):
>>>
>>> http://r-forge.r-project.org/src/contrib/lme4a_0.999375-46.tar.gz
>>>
>>> produces page not found.
>>>
>>> I presume this means something is broken? Or is the expectation that
>>> we fetch from SVN?
>>>
>>> Regards,
>>> Greg
>>>
>>>> sessionInfo()
>>> R version 2.10.1 (2009-12-14)
>>> x86_64-pc-linux-gnu
>>>
>>> locale:
>>> ?[1] LC_CTYPE=en_AU.UTF-8 ? ? ? LC_NUMERIC=C
>>> ?[3] LC_TIME=en_AU.UTF-8 ? ? ? ?LC_COLLATE=en_AU.UTF-8
>>> ?[5] LC_MONETARY=C ? ? ? ? ? ? ?LC_MESSAGES=en_AU.UTF-8
>>> ?[7] LC_PAPER=en_AU.UTF-8 ? ? ? LC_NAME=C
>>> ?[9] LC_ADDRESS=C ? ? ? ? ? ? ? LC_TELEPHONE=C
>>> [11] LC_MEASUREMENT=en_AU.UTF-8 LC_IDENTIFICATION=C
>>>
>>> attached base packages:
>>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
>
> --
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / people.biology.ufl.edu/bolker
> GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc
>



From bolker at ufl.edu  Thu Mar  4 02:49:27 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Wed, 03 Mar 2010 20:49:27 -0500
Subject: [R-sig-ME] lme4a?
In-Reply-To: <54c8adaa1003031746k2a6be8a0wa4c2dea738c46713@mail.gmail.com>
References: <54c8adaa1003031525m4d6ba297vddd1191552e94a9c@mail.gmail.com>	
	<4B8EFF5D.7080201@ufl.edu> <4B8F0240.6040000@ufl.edu>
	<54c8adaa1003031746k2a6be8a0wa4c2dea738c46713@mail.gmail.com>
Message-ID: <4B8F11A7.9010108@ufl.edu>

  how about

  install.packages("Matrix",repos="http://r-forge.r-project.org")

?
(not sure, but worth a try)

  Ben

glee wrote:
>> svn checkout svn://svn.r-forge.r-project.org/svnroot/lme4
> 
> I am behind a university firewall which (apparently) has port 3690
> (svn:// default) blocked.
> 
> The nightly snapshot (linked from
> http://r-forge.r-project.org/scm/?group_id=60) downloads ok, and
> appears to build, but fails with
> 
> Error : package 'Matrix' 0.999375-37 was found, but >= 0.999375.38 is
> required by 'lme4a'
> ERROR: lazy loading failed for package ?lme4a?
> 
> As far as I can see 0.999375-37 is the latest version available on CRAN.
> 
> Thanks for the suggestions. At least this path appears that it could
> work, if I am able to satisfy dependencies. I will keep trying.
> 
> 
> On 4 March 2010 11:43, Ben Bolker <bolker at ufl.edu> wrote:
>>  My apologies.  It was my fault (doh!)
>>  however, "under rapid development" is still true -- glmer appears to
>> be working now, but that's recent.
>>
>>
>>
>> Ben Bolker wrote:
>>>   I'm not sure, but I got it via SVN.  I don't see lme4a exposed
>>> anywhere on r-forge.
>>>
>>>   As the web page suggests
>>>
>>> svn checkout svn://svn.r-forge.r-project.org/svnroot/lme4
>>> [move to appropriate directory]
>>> cd pkg
>>> R CMD INSTALL lme4a
>>>
>>> [you'll need to have all the appropriate build tools installed]
>>>
>>>  HOWEVER: lme4a is under EXTREMELY rapid (=unstable) development, and
>>> the current version is broken on my system -- I think (???) that there's
>>> a "mer.h" file that's supposed to have been added but didn't get in.
>>>
>>>   The current version on SVN is r685; I had to back up to r679 to get a
>>> working version.
>>>
>>>   r680 log says "Removing definitions no longer used" -- perhaps
>>> something extra got removed?
>>>
>>>  (I have mucked around with things a bit, so there's an outside chance
>>> that this is my fault -- can anyone else confirm?)
>>>
>>> glee wrote:
>>>> I am attempting to following along with Douglas Bates book draft.
>>>>
>>>> R Forge claims that the following works automatically:
>>>>
>>>> install.packages("lme4a", repos="http://R-Forge.R-project.org")
>>>>
>>>> but I get
>>>>
>>>> ? package ?lme4a? is not available.
>>>>
>>>> Attempting to obtain the source manually from the lme4 project page
>>>> (which points to):
>>>>
>>>> http://r-forge.r-project.org/src/contrib/lme4a_0.999375-46.tar.gz
>>>>
>>>> produces page not found.
>>>>
>>>> I presume this means something is broken? Or is the expectation that
>>>> we fetch from SVN?
>>>>
>>>> Regards,
>>>> Greg
>>>>
>>>>> sessionInfo()
>>>> R version 2.10.1 (2009-12-14)
>>>> x86_64-pc-linux-gnu
>>>>
>>>> locale:
>>>>  [1] LC_CTYPE=en_AU.UTF-8       LC_NUMERIC=C
>>>>  [3] LC_TIME=en_AU.UTF-8        LC_COLLATE=en_AU.UTF-8
>>>>  [5] LC_MONETARY=C              LC_MESSAGES=en_AU.UTF-8
>>>>  [7] LC_PAPER=en_AU.UTF-8       LC_NAME=C
>>>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>>> [11] LC_MEASUREMENT=en_AU.UTF-8 LC_IDENTIFICATION=C
>>>>
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> --
>> Ben Bolker
>> Associate professor, Biology Dep't, Univ. of Florida
>> bolker at ufl.edu / people.biology.ufl.edu/bolker
>> GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc
>>


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From sp8ial at gmail.com  Thu Mar  4 02:54:17 2010
From: sp8ial at gmail.com (glee)
Date: Thu, 4 Mar 2010 12:54:17 +1100
Subject: [R-sig-ME] lme4a?
In-Reply-To: <4B8F11A7.9010108@ufl.edu>
References: <54c8adaa1003031525m4d6ba297vddd1191552e94a9c@mail.gmail.com>
	<4B8EFF5D.7080201@ufl.edu> <4B8F0240.6040000@ufl.edu>
	<54c8adaa1003031746k2a6be8a0wa4c2dea738c46713@mail.gmail.com>
	<4B8F11A7.9010108@ufl.edu>
Message-ID: <54c8adaa1003031754g54a5ac1bnced8b678f8cdbb2f@mail.gmail.com>

Yes, that works. thanks!


On 4 March 2010 12:49, Ben Bolker <bolker at ufl.edu> wrote:
> ?how about
>
> ?install.packages("Matrix",repos="http://r-forge.r-project.org")
>
> ?
> (not sure, but worth a try)
>
> ?Ben
>
> glee wrote:
>>> svn checkout svn://svn.r-forge.r-project.org/svnroot/lme4
>>
>> I am behind a university firewall which (apparently) has port 3690
>> (svn:// default) blocked.
>>
>> The nightly snapshot (linked from
>> http://r-forge.r-project.org/scm/?group_id=60) downloads ok, and
>> appears to build, but fails with
>>
>> Error : package 'Matrix' 0.999375-37 was found, but >= 0.999375.38 is
>> required by 'lme4a'
>> ERROR: lazy loading failed for package ?lme4a?
>>
>> As far as I can see 0.999375-37 is the latest version available on CRAN.
>>
>> Thanks for the suggestions. At least this path appears that it could
>> work, if I am able to satisfy dependencies. I will keep trying.
>>
>>
>> On 4 March 2010 11:43, Ben Bolker <bolker at ufl.edu> wrote:
>>> ?My apologies. ?It was my fault (doh!)
>>> ?however, "under rapid development" is still true -- glmer appears to
>>> be working now, but that's recent.
>>>
>>>
>>>
>>> Ben Bolker wrote:
>>>> ? I'm not sure, but I got it via SVN. ?I don't see lme4a exposed
>>>> anywhere on r-forge.
>>>>
>>>> ? As the web page suggests
>>>>
>>>> svn checkout svn://svn.r-forge.r-project.org/svnroot/lme4
>>>> [move to appropriate directory]
>>>> cd pkg
>>>> R CMD INSTALL lme4a
>>>>
>>>> [you'll need to have all the appropriate build tools installed]
>>>>
>>>> ?HOWEVER: lme4a is under EXTREMELY rapid (=unstable) development, and
>>>> the current version is broken on my system -- I think (???) that there's
>>>> a "mer.h" file that's supposed to have been added but didn't get in.
>>>>
>>>> ? The current version on SVN is r685; I had to back up to r679 to get a
>>>> working version.
>>>>
>>>> ? r680 log says "Removing definitions no longer used" -- perhaps
>>>> something extra got removed?
>>>>
>>>> ?(I have mucked around with things a bit, so there's an outside chance
>>>> that this is my fault -- can anyone else confirm?)
>>>>
>>>> glee wrote:
>>>>> I am attempting to following along with Douglas Bates book draft.
>>>>>
>>>>> R Forge claims that the following works automatically:
>>>>>
>>>>> install.packages("lme4a", repos="http://R-Forge.R-project.org")
>>>>>
>>>>> but I get
>>>>>
>>>>> ? package ?lme4a? is not available.
>>>>>
>>>>> Attempting to obtain the source manually from the lme4 project page
>>>>> (which points to):
>>>>>
>>>>> http://r-forge.r-project.org/src/contrib/lme4a_0.999375-46.tar.gz
>>>>>
>>>>> produces page not found.
>>>>>
>>>>> I presume this means something is broken? Or is the expectation that
>>>>> we fetch from SVN?
>>>>>
>>>>> Regards,
>>>>> Greg
>>>>>
>>>>>> sessionInfo()
>>>>> R version 2.10.1 (2009-12-14)
>>>>> x86_64-pc-linux-gnu
>>>>>
>>>>> locale:
>>>>> ?[1] LC_CTYPE=en_AU.UTF-8 ? ? ? LC_NUMERIC=C
>>>>> ?[3] LC_TIME=en_AU.UTF-8 ? ? ? ?LC_COLLATE=en_AU.UTF-8
>>>>> ?[5] LC_MONETARY=C ? ? ? ? ? ? ?LC_MESSAGES=en_AU.UTF-8
>>>>> ?[7] LC_PAPER=en_AU.UTF-8 ? ? ? LC_NAME=C
>>>>> ?[9] LC_ADDRESS=C ? ? ? ? ? ? ? LC_TELEPHONE=C
>>>>> [11] LC_MEASUREMENT=en_AU.UTF-8 LC_IDENTIFICATION=C
>>>>>
>>>>> attached base packages:
>>>>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>> --
>>> Ben Bolker
>>> Associate professor, Biology Dep't, Univ. of Florida
>>> bolker at ufl.edu / people.biology.ufl.edu/bolker
>>> GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc
>>>
>
>
> --
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / people.biology.ufl.edu/bolker
> GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc
>



From joyce at mcs.st-and.ac.uk  Thu Mar  4 10:34:40 2010
From: joyce at mcs.st-and.ac.uk (Yuan Yuan)
Date: Thu, 04 Mar 2010 09:34:40 +0000
Subject: [R-sig-ME] var estimates of the random effects variance in lme4
In-Reply-To: <A0F8DAFB525DED4ABAF6841BB11C581204AE35F6@mail4.marlab.ac.uk>
References: <1267639027.4b8ea2f3c6686@webmail.st-andrews.ac.uk>
	<40e66e0b1003031021o3b6b795fp99e31afa399fe46d@mail.gmail.com>
	<A0F8DAFB525DED4ABAF6841BB11C581204AE35F6@mail4.marlab.ac.uk>
Message-ID: <4B8F7EB0.5050700@mcs.st-and.ac.uk>

Hi, Colin
Thank you for the reply.
What I want is to simulate  sd of random effects from their estimated 
asymptotic distribution in bootstrapping.
I will have a look at the link.

Joyce
Colin Millar wrote:
> Hi Joyce,
>  
> If you want to simulate from the model parameters, including 
> simulating from the variance component distribution you can get pretty 
> exact distributions (all beit Bayesian ...) using Havad Rue's INLA 
> package which can be found in http://www.r-inla.org/.  You had to use 
> your wits to simulate from the posterior distributions last time i 
> looked (abt 4 months ago), but he is always working on it so it may be 
> more user freindly now. 
>  
> Its strength is structured random effects, however it will also do iid 
> random effects so is a Bayesian alternative in R to lme4.  Its 
> definately worth a reccy.
>  
> Hope this helps,
> Colin
>
> ------------------------------------------------------------------------
> *From:* r-sig-mixed-models-bounces at r-project.org on behalf of Douglas 
> Bates
> *Sent:* Wed 03/03/2010 18:21
> *To:* Yuan Yuan
> *Cc:* r-sig-mixed-models at r-project.org
> *Subject:* Re: [R-sig-ME] var estimates of the random effects variance 
> in lme4
>
> On Wed, Mar 3, 2010 at 11:57 AM, Yuan Yuan <joyce at mcs.st-and.ac.uk> wrote:
> > Hi, all
> > For an estimate of the parameter, we have a variance estimate 
> associated with
> > the parameter estimate.
>
> Usually called the standard error of a parameter estimate.
>
> > Say, let beta denote the fixed effect in linear regresssion, we have 
> an estimate
> > given the data,\hat{beta} and its variance estimate 
> \hat{var}[\hat{beta}].
> > My question is, for the random effects, denoted by b, sd(b) is our 
> parameter of
> > interest, but I can not find the estimated sd[sd(b)]. There is 
> \hat{sd(b)} in
> > the summary list, but not \hat{sd}{\hat{sd(b)}}.
>
> > I was told that you can find estimted var[var(random effect)] in SAS
> > Is there anyone can tell me whether or not I can find var[var(random 
> effect)] in
> > the output given by glmer in package lme4?
>
> It is true that SAS does provide a standard error of a variance
> estimate from SAS PROC MIXED.  If you check the book by West, Welch
> and Galecki (ISBN 1-58488-480-0) you will see that all of the software
> systems they use to fit mixed-effects models provide such standard
> errors, except for the nlme package in R and the lme4 package for R.
> This is intentional.  Standard errors of variance estimates are
> nonsensical because the estimators are highly skewed.  This is
> discussed and illustrated in chapters 1 and 2 of the book I am writing
> for which the chapter drafts are available at
> http://lme4.R-forge.R-project.org/book/ 
> <http://lme4.r-forge.r-project.org/book/>
>
> > Thank you very much.
> >
> > Cheers,
> > Joyce
> > --
> > Yuan(Joyce) Yuan
> > PhD student in Statistics
> >
> > CREEM - Centre for Research into Ecological and Environmental Modelling
> > University of St Andrews
> > The Observatory
> > Buchanan Gardens
> > St Andrews
> > Fife
> > KY16 9LZ
> > Scotland
> >
> > Tel: +44 (0)1334 461826
> > Fax: +44 (0)1334 461800
> >
> >
> > ------------------------------------------------------------------
> > University of St Andrews Webmail: https://webmail.st-andrews.ac.uk 
> <https://webmail.st-andrews.ac.uk/>
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> ______________________________________________________________________
> This email has been scanned by the MessageLabs Email Security System.
> For more information please visit http://www.messagelabs.com/email
> ______________________________________________________________________
>


-- 
Yuan(Joyce) Yuan
PhD student 

CREEM - Centre for Research into Ecological and Environmental Modelling
University of St Andrews
The Observatory
Buchanan Gardens
St Andrews
Fife
KY16 9LZ
Scotland

Tel: +44 (0)1334 461826
Fax: +44 (0)1334 461800

The University of St Andrews is a charity registered in Scotland: No SC013532



From f.calboli at imperial.ac.uk  Thu Mar  4 10:36:19 2010
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Thu, 4 Mar 2010 09:36:19 +0000
Subject: [R-sig-ME] Conditional logistic regression vs lmer
In-Reply-To: <Pine.LNX.4.64.1003040741520.2584@orpheus.qimr.edu.au>
References: <3D3B95AE-7C91-4C29-94A9-244B73BA8980@imperial.ac.uk>
	<B9F402C0-CBD0-4939-87CB-8D3B4CF2478F@imperial.ac.uk>
	<Pine.LNX.4.64.1003040741520.2584@orpheus.qimr.edu.au>
Message-ID: <03E3CE2A-9D0A-4563-852D-9E6D328D240D@imperial.ac.uk>

On 3 Mar 2010, at 22:23, David Duffy wrote:
> Was the study a matched case-control design, or is "match" the family or 
> some natural clustering variable? How many cases and controls for each 
> level of match?  (maybe this was in your earlier email.) If the strata are 
> small (eg 1:1), then I would be nervous about (tIgE.Resp|match) giving a 
> meaningful estimate, cf c.c ~ tIgE.Resp + (1|match)+ (1|Run) + (1|Box).

The study is a matched case/control, with matched 3 controls for each case. On top of that I have 4 independent cohorts, which I would see as random terms --though my example above does not include cohort because I had data for only one at that point.

> You might read over the intro to the paper by Liang, Qaqish and Zeger on 
> the GEE for binary data in JRSSB (?1990 or so), where they contrast the 
> different approaches to clustered data.  Basically, the (usual) GLMM fits
> a parametric model for the intercepts for each stratum, while the 
> CLR discards this information, and for a categorical covariate is "just" 
> a permutation test.


I'll look into it. Thanks!

F

--
Federico C. F. Calboli
Department of Epidemiology and Biostatistics
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From bates at stat.wisc.edu  Thu Mar  4 16:22:14 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 4 Mar 2010 09:22:14 -0600
Subject: [R-sig-ME] lme4a, glmer and all that
Message-ID: <40e66e0b1003040722m5b595e3eje2039ce3c659ea55@mail.gmail.com>

This is a good news - bad news announcement.  As Ben Bolker indicated
in a recent thread, the lme4a version of the lme4 package is
undergoing rapid development and the capability of fitting generalized
linear mixed models with glmer has recently been added.

These capabilities are changing rapidly and some aspects of the model
fits are yet incomplete.  For example, the standard errors of the
fixed-effects parameters are not yet updated for the final parameter
estimates so don't pay too much attention to those standard errors.
Also, you do need to call glmer (i.e. don't try calling lmer) to fit a
GLMM.  In the past the structures for lmer and for glmer were the same
with some flags indicating which type of model was active.  Now they
are different.

So the good news is that the brave and foolhardy can try installing
that version, once we settle the issue of a dependency on an
unreleased version of the Matrix package (Martin, can we back that out
for the time being?).

The bad news is that I can't reproduce the results from a GLMM fit
using the currently released lme4 package and I am suspicious that the
results from the current version of lme4 are the inaccurate ones.
Although I'm still trying to verify this (and I would appreciate help
- see below), I would recommend that you do not quote results from a
GLMM fit with version 0.999375-32 of the lme4 package.

Having others trust the results from this software and then find out
that these are wrong is about the worst thing that I can imagine
happening in my work.  If this is the case I sincerely apologize.

I would ask two things.  If this is an error in the lme4 software,
please do not phrase it as "an error in R" and try to correct others
if they claim this.  There is often confusion between the R system and
environment and the results from individual packages.  If there is an
error then it is an error in the package.  In particular it would be
an error in the derivation that I did and the code that I wrote and I
take full responsibility for it.  However, I do not want this misstep
to be phrased as "the results from R can't be trusted".

The second thing I would ask is if others (in particular, those who
don't mind installing a package that is undergoing rapid development)
can cross-check results from the two versions against other software
to which you may have access, such as Stata or SAS.  You can either
post to the list or send results to me privately.

Thanks for your understanding.  We will try to clear this up as soon
as possible.



From f.calboli at imperial.ac.uk  Thu Mar  4 16:34:24 2010
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Thu, 4 Mar 2010 15:34:24 +0000
Subject: [R-sig-ME] lme4a, glmer and all that
In-Reply-To: <40e66e0b1003040722m5b595e3eje2039ce3c659ea55@mail.gmail.com>
References: <40e66e0b1003040722m5b595e3eje2039ce3c659ea55@mail.gmail.com>
Message-ID: <20DB9A11-843E-40B3-976D-4FD9974692EC@imperial.ac.uk>

Dear Doug,

> This is a good news - bad news announcement.  As Ben Bolker indicated
> in a recent thread, the lme4a version of the lme4 package is
> undergoing rapid development and the capability of fitting generalized
> linear mixed models with glmer has recently been added.

I did not pay tons of attention to what was going so I take to opportunity to ask: is lme4a somethink akin a transition that will automagically replace lme4 once you're happy with it or will I have to install it side by side?

> The bad news is that I can't reproduce the results from a GLMM fit
> using the currently released lme4 package and I am suspicious that the
> results from the current version of lme4 are the inaccurate ones.
> Although I'm still trying to verify this (and I would appreciate help
> - see below), I would recommend that you do not quote results from a
> GLMM fit with version 0.999375-32 of the lme4 package.
> 
> Having others trust the results from this software and then find out
> that these are wrong is about the worst thing that I can imagine
> happening in my work.  If this is the case I sincerely apologize.

Ok, no problem! In a way that kind of resolves my attempt of replacing clogit() with lmer, and I'm grateful for your warning. I could try build lme4a --should I do it, would it be of any help if I sent you the results? I do not have any other software to compare with, just other R packages.

Best,

Federico





--
Federico C. F. Calboli
Department of Epidemiology and Biostatistics
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From bates at stat.wisc.edu  Thu Mar  4 16:53:56 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 4 Mar 2010 09:53:56 -0600
Subject: [R-sig-ME] lme4a, glmer and all that
In-Reply-To: <20DB9A11-843E-40B3-976D-4FD9974692EC@imperial.ac.uk>
References: <40e66e0b1003040722m5b595e3eje2039ce3c659ea55@mail.gmail.com>
	<20DB9A11-843E-40B3-976D-4FD9974692EC@imperial.ac.uk>
Message-ID: <40e66e0b1003040753l5a3af452h77bdf0928ace9d6f@mail.gmail.com>

On Thu, Mar 4, 2010 at 9:34 AM, Federico Calboli
<f.calboli at imperial.ac.uk> wrote:
> Dear Doug,
>
>> This is a good news - bad news announcement. ?As Ben Bolker indicated
>> in a recent thread, the lme4a version of the lme4 package is
>> undergoing rapid development and the capability of fitting generalized
>> linear mixed models with glmer has recently been added.
>
> I did not pay tons of attention to what was going so I take to opportunity to ask: is lme4a somethink akin a transition that will automagically replace lme4 once you're happy with it or will I have to install it side by side?

The former.  It is such a departure from the earlier formulation that
I needed to develop it in a separate area until I could get all the
pieces working.

>> The bad news is that I can't reproduce the results from a GLMM fit
>> using the currently released lme4 package and I am suspicious that the
>> results from the current version of lme4 are the inaccurate ones.
>> Although I'm still trying to verify this (and I would appreciate help
>> - see below), I would recommend that you do not quote results from a
>> GLMM fit with version 0.999375-32 of the lme4 package.
>>
>> Having others trust the results from this software and then find out
>> that these are wrong is about the worst thing that I can imagine
>> happening in my work. ?If this is the case I sincerely apologize.
>
> Ok, no problem! In a way that kind of resolves my attempt of replacing clogit() with lmer, and I'm grateful for your warning. I could try build lme4a --should I do it, would it be of any help if I sent you the results? I do not have any other software to compare with, just other R packages.
>
> Best,
>
> Federico
>
>
>
>
>
> --
> Federico C. F. Calboli
> Department of Epidemiology and Biostatistics
> Imperial College, St. Mary's Campus
> Norfolk Place, London W2 1PG
>
> Tel +44 (0)20 75941602 ? Fax +44 (0)20 75943193
>
> f.calboli [.a.t] imperial.ac.uk
> f.calboli [.a.t] gmail.com
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Thu Mar  4 17:11:40 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 4 Mar 2010 10:11:40 -0600
Subject: [R-sig-ME] lme4a, glmer and all that
In-Reply-To: <40e66e0b1003040722m5b595e3eje2039ce3c659ea55@mail.gmail.com>
References: <40e66e0b1003040722m5b595e3eje2039ce3c659ea55@mail.gmail.com>
Message-ID: <40e66e0b1003040811v53d677fey50e414b17cea951@mail.gmail.com>

Two further comments.  It is only the results from fitting generalized
linear mixed models with the current lme4 that I have cause to doubt.
The results from linear mixed models do check out.

Here is an example of the inconsistency.  In lme4a a model fit to the
cbpp data set provides

> (m1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
+              family = binomial, data = cbpp))
Generalized Linear mixed model fit by maximum likelihood
   AIC   BIC logLik deviance
 115.2 127.4 -51.62    103.2

Random effects:
 Groups   Name        Variance Std.Dev.
 herd     (Intercept) 0.76381  0.87396
Number of obs: 56, groups: herd, 15

Fixed effects:
            Estimate Std. Error t value
(Intercept)  -1.4277     0.1449  -9.852
period2      -0.9693     0.2915  -3.326
period3      -1.1064     0.3129  -3.536
period4      -1.5573     0.4131  -3.770

Correlation of Fixed Effects:
        (Intr) perid2 perid3
period2 -0.497
period3 -0.463  0.230
period4 -0.351  0.174  0.163

(As I mentioned previously, those standard errors are not
appropriately updated to the parameter estimates and should be
ignored.)

The corresponding results from the current lme4 are

(m1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
+              family = binomial, data = cbpp))
Generalized linear mixed model fit by the Laplace approximation
Formula: cbind(incidence, size - incidence) ~ period + (1 | herd)
   Data: cbpp
   AIC   BIC logLik deviance
 110.1 120.2 -50.05    100.1
Random effects:
 Groups Name        Variance Std.Dev.
 herd   (Intercept) 0.4125   0.64226
Number of obs: 56, groups: herd, 15

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)  -1.3985     0.2279  -6.137 8.42e-10 ***
period2      -0.9923     0.3054  -3.249 0.001156 **
period3      -1.1287     0.3260  -3.462 0.000537 ***
period4      -1.5804     0.4288  -3.686 0.000228 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
        (Intr) perid2 perid3
period2 -0.351
period3 -0.329  0.267
period4 -0.249  0.202  0.186

Fitting this model in Stata provided

. xtmelogit incidence i.period || herd: , binomial(size) intpoints(1)

Refining starting values:

Iteration 0:   log likelihood = -93.798792
Iteration 1:   log likelihood = -92.108205
Iteration 2:   log likelihood = -92.078723

Performing gradient-based optimization:

Iteration 0:   log likelihood = -92.078723
Iteration 1:   log likelihood = -92.026831
Iteration 2:   log likelihood = -92.026282
Iteration 3:   log likelihood = -92.026282

Mixed-effects logistic regression               Number of obs      =        56
Binomial variable: size
Group variable: herd                            Number of groups   =        15

                                                Obs per group: min =         1
                                                               avg =       3.7
                                                               max =         4

Integration points =   1                        Wald chi2(3)       =     24.95
Log likelihood = -92.026282                     Prob > chi2        =    0.0000

------------------------------------------------------------------------------
   incidence |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
      period |
          2  |  -.9923328   .3066425    -3.24   0.001    -1.593341   -.3913245
          3  |  -1.128672   .3266379    -3.46   0.001    -1.768871   -.4884737
          4  |  -1.580314   .4274366    -3.70   0.000    -2.418074   -.7425537
             |
       _cons |  -1.398532    .232472    -6.02   0.000    -1.854169   -.9428953
------------------------------------------------------------------------------

------------------------------------------------------------------------------
  Random-effects Parameters  |   Estimate   Std. Err.     [95% Conf. Interval]
-----------------------------+------------------------------------------------
herd: Identity               |
                   sd(_cons) |   .6422615   .1785622      .3724431    1.107551
------------------------------------------------------------------------------
LR test vs. logistic regression: chibar2(01) =    14.01 Prob>=chibar2 = 0.0001

Note: log-likelihood calculations are based on the Laplacian approximation.

.
.
end of do-file

which, now I see are more consistent with the results from lme4, not
lme4a.  I misunderstood the message I received regarding the Stata
results.

OK, this might have all been a red herring.  I'll look into it some more.

At one time on Saturday Night Live Gilda Radner would play a citizen
commentator on weekend news update who was confused about the issue
and, after a long harangue, would end up realizing she got it wrong.
She ended by saying "Never mind".  That might be the case here too.



From f.calboli at imperial.ac.uk  Thu Mar  4 18:32:38 2010
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Thu, 4 Mar 2010 17:32:38 +0000
Subject: [R-sig-ME] lme4a, glmer and all that
In-Reply-To: <40e66e0b1003040811v53d677fey50e414b17cea951@mail.gmail.com>
References: <40e66e0b1003040722m5b595e3eje2039ce3c659ea55@mail.gmail.com>
	<40e66e0b1003040811v53d677fey50e414b17cea951@mail.gmail.com>
Message-ID: <D5A85515-8EF7-44E8-B064-3A35573F2384@imperial.ac.uk>

On 4 Mar 2010, at 16:11, Douglas Bates wrote:
<cut>
> 
> which, now I see are more consistent with the results from lme4, not
> lme4a.  I misunderstood the message I received regarding the Stata
> results.
> 
> OK, this might have all been a red herring.  I'll look into it some more.
> 
> At one time on Saturday Night Live Gilda Radner would play a citizen
> commentator on weekend news update who was confused about the issue
> and, after a long harangue, would end up realizing she got it wrong.
> She ended by saying "Never mind".  That might be the case here too.


Just out of curiosity, how do we know stata and lme4 are correct and lme4a is not? why is stata the benchmark? Please note I am only being facetious.

F



--
Federico C. F. Calboli
Department of Epidemiology and Biostatistics
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From bates at stat.wisc.edu  Thu Mar  4 19:06:02 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 4 Mar 2010 12:06:02 -0600
Subject: [R-sig-ME] lme4a, glmer and all that
In-Reply-To: <D5A85515-8EF7-44E8-B064-3A35573F2384@imperial.ac.uk>
References: <40e66e0b1003040722m5b595e3eje2039ce3c659ea55@mail.gmail.com>
	<40e66e0b1003040811v53d677fey50e414b17cea951@mail.gmail.com>
	<D5A85515-8EF7-44E8-B064-3A35573F2384@imperial.ac.uk>
Message-ID: <40e66e0b1003041006l849ec17m2e5e4454806d3a9a@mail.gmail.com>

On Thu, Mar 4, 2010 at 11:32 AM, Federico Calboli
<f.calboli at imperial.ac.uk> wrote:
> On 4 Mar 2010, at 16:11, Douglas Bates wrote:
> <cut>
>>
>> which, now I see are more consistent with the results from lme4, not
>> lme4a. ?I misunderstood the message I received regarding the Stata
>> results.
>>
>> OK, this might have all been a red herring. ?I'll look into it some more.
>>
>> At one time on Saturday Night Live Gilda Radner would play a citizen
>> commentator on weekend news update who was confused about the issue
>> and, after a long harangue, would end up realizing she got it wrong.
>> She ended by saying "Never mind". ?That might be the case here too.
>
>
> Just out of curiosity, how do we know stata and lme4 are correct and lme4a is not? why is stata the benchmark? Please note I am only being facetious.

In cases like this we usually go with majority rule.  I'm still
verifying and validating.

> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From mhighfield106 at googlemail.com  Fri Mar  5 14:51:02 2010
From: mhighfield106 at googlemail.com (martin highfield)
Date: Fri, 5 Mar 2010 13:51:02 +0000
Subject: [R-sig-ME] confounded random and fixed effects
Message-ID: <c9b63d771003050551r41bfe4e6s51eed8da78ce1be7@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100305/8afebee4/attachment.pl>

From bates at stat.wisc.edu  Fri Mar  5 15:05:43 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 5 Mar 2010 08:05:43 -0600
Subject: [R-sig-ME] Sorry for the false alarm - results from glmer in the
	released lme4 are consistent with other software
Message-ID: <40e66e0b1003050605ib8ab868k1f2b74d746648974@mail.gmail.com>

In an earlier thread with the subject "lme4a, glmer and all that" I
stated that the results of fitting generalized linear mixed models in
the lme4 and lme4a packages were different and I was beginning to
doubt the results from the released version 0.999375-32 of lme4.  I
did discover a programming mistake in the development version, lme4a,
and am working on correcting it.  The results from the released
version, lme4, are consistent with those reported by other software.

In an unrelated development we have discovered one of the reasons that
the lme4 package takes a very long time to load, relative to other
packages.  It has always seemed peculiar that the Matrix package with
dozens of S4 classes and hundreds of methods takes a couple of seconds
to load whereas the much simpler lme4 package (in terms of classes and
methods) takes 5 to 10 times as long.  We have isolated why this
occurs and John Chambers is testing a modification in the methods
package that can avoid this.



From ggrothendieck at gmail.com  Fri Mar  5 15:28:32 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 5 Mar 2010 09:28:32 -0500
Subject: [R-sig-ME] Sorry for the false alarm - results from glmer in
	the released lme4 are consistent with other software
In-Reply-To: <40e66e0b1003050605ib8ab868k1f2b74d746648974@mail.gmail.com>
References: <40e66e0b1003050605ib8ab868k1f2b74d746648974@mail.gmail.com>
Message-ID: <971536df1003050628q254b5b36i3a7f23e7d27d2c7a@mail.gmail.com>

In general S4 seems slow to load relative to S3.  You can generally
tell whether a package is S3 or S4 just by the time it takes to load.
However, if there is some special situation that makes S4 take even
longer than usual it would be useful to know what it is.so others can
avoid the problem in situations related or unrelated to lme4a.

On Fri, Mar 5, 2010 at 9:05 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
> In an earlier thread with the subject "lme4a, glmer and all that" I
> stated that the results of fitting generalized linear mixed models in
> the lme4 and lme4a packages were different and I was beginning to
> doubt the results from the released version 0.999375-32 of lme4. ?I
> did discover a programming mistake in the development version, lme4a,
> and am working on correcting it. ?The results from the released
> version, lme4, are consistent with those reported by other software.
>
> In an unrelated development we have discovered one of the reasons that
> the lme4 package takes a very long time to load, relative to other
> packages. ?It has always seemed peculiar that the Matrix package with
> dozens of S4 classes and hundreds of methods takes a couple of seconds
> to load whereas the much simpler lme4 package (in terms of classes and
> methods) takes 5 to 10 times as long. ?We have isolated why this
> occurs and John Chambers is testing a modification in the methods
> package that can avoid this.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Fri Mar  5 16:33:41 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 5 Mar 2010 09:33:41 -0600
Subject: [R-sig-ME] Sorry for the false alarm - results from glmer in
	the released lme4 are consistent with other software
In-Reply-To: <971536df1003050628q254b5b36i3a7f23e7d27d2c7a@mail.gmail.com>
References: <40e66e0b1003050605ib8ab868k1f2b74d746648974@mail.gmail.com>
	<971536df1003050628q254b5b36i3a7f23e7d27d2c7a@mail.gmail.com>
Message-ID: <40e66e0b1003050733h67270efbn43b46efa1ebb558e@mail.gmail.com>

On Fri, Mar 5, 2010 at 8:28 AM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
> In general S4 seems slow to load relative to S3. ?You can generally
> tell whether a package is S3 or S4 just by the time it takes to load.
> However, if there is some special situation that makes S4 take even
> longer than usual it would be useful to know what it is.so others can
> avoid the problem in situations related or unrelated to lme4a.

There is a lot more involved in loading a package with S4 classes and
methods than in loading a package that uses S3 methods only.  S3
methods are lightweight - they only involve determining names of
functions, which is going to be done anyway.  S3 classes are even more
lightweight since they don't exist, in a formal sense.  Of course, the
downside of having everything in the S3 world so lightweight is that
S3 is limited (an S3 version of the Matrix package would be very
limited because there is no concept of multiple dispatch) and provides
no consistency checks.

>From the point of view of loading a package, S3 exists only in the
namespace.  S4 requires that tables of classes and methods be updated
and checked for consistency, which obviously takes longer.  I consider
it to be analogous to the difference between calling lm and calling
lm.fit directly.  Of course lm.fit is much faster but it requires the
user to construct the model frame and the model matrix themselves and
allows them the opportunity to make any number of subtle mistakes when
doing so.

The thing we found out was that a large portion of the time in loading
the lme4 package was being spent in the insertMethod function and
being driven by the fact that lme4 imported the entire Matrix
namespace.  The long-term fix will be to modify or perhaps even
eliminate insertMethod.  It is, for the most part, vestigial.  The
short term fix is to import only the classes and methods from Matrix
that are needed in lme4.  I'm not sure of the details but I think that
the problem originated in checking all the method tables imported from
Matrix and not modified in lme4.


> On Fri, Mar 5, 2010 at 9:05 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
>> In an earlier thread with the subject "lme4a, glmer and all that" I
>> stated that the results of fitting generalized linear mixed models in
>> the lme4 and lme4a packages were different and I was beginning to
>> doubt the results from the released version 0.999375-32 of lme4. ?I
>> did discover a programming mistake in the development version, lme4a,
>> and am working on correcting it. ?The results from the released
>> version, lme4, are consistent with those reported by other software.
>>
>> In an unrelated development we have discovered one of the reasons that
>> the lme4 package takes a very long time to load, relative to other
>> packages. ?It has always seemed peculiar that the Matrix package with
>> dozens of S4 classes and hundreds of methods takes a couple of seconds
>> to load whereas the much simpler lme4 package (in terms of classes and
>> methods) takes 5 to 10 times as long. ?We have isolated why this
>> occurs and John Chambers is testing a modification in the methods
>> package that can avoid this.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>



From bates at stat.wisc.edu  Sat Mar  6 16:57:06 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 6 Mar 2010 09:57:06 -0600
Subject: [R-sig-ME] Examples of GLMM fits?
Message-ID: <40e66e0b1003060757pa6e772fvfe29960a167e9b76@mail.gmail.com>

I have added the Gamma family for glmer in the lme4a package and will
backport to the lme4 package.   (Actually Ben Bolker sent me a patch
for lme4 several weeks ago and I haven't gotten around to installing
it yet but will do so.)

However, before I release it I would like to have an example data set
and model on which to test it.  I don't have any.  Could someone
provide me with a reference to data and a fitted model that I could
use as an example?  I would also appreciate an example of a Poisson
GLMM and other families too.



From lucianolasala at yahoo.com.ar  Sun Mar  7 01:49:29 2010
From: lucianolasala at yahoo.com.ar (Luciano La Sala)
Date: Sat, 6 Mar 2010 21:49:29 -0300
Subject: [R-sig-ME] Testing signif. of random effects by bootstrapping
Message-ID: <A3C95F6B66F5488C8EF2D1A91ECA975B@Negro1>

Dear list members, 

I am using lmer function (lme4 version 32) to fit some quite simple mixed
models. Dependent variable is chick's weight, fixed effects are HatchOrder
(3 levels), ClutchSize (3 levels), Year (2 levels) and significant two-way
interaction terms. I model Nest as a random intercept (chicks nested in
nest!). After fitting the full model I need to test the significance of the
random effect. In doing so, I've found to approaches based on Faraway's book
(Extending the linear model with R, 2006), namely likelihood ratio test and
parametric bootstrap approach. The later, I understand, would be used to
obtain a more accurate p value.  

Before presenting the outputs, here go my main questions. First off: 

1. I have fitted models where the RE should be removed according to a LRT (p
= 0.4284092), while after bootstrapping (1000 repetitions) the same model I
obtain p = 0 indicating a significant improvement of model fit by the RE.
Two opposite results. Is this normal?  

2. The bootstrap method yields p-values that are either 0 or 1 (no decimal
places), which seems a little odd to me. How can I ask R to provide, say, 4
significant digits for the bootstrapping p-value?

Following is a summary of the outputs from the model in question, with and
without the random effect, and bootstrapping right after them: 

FULL MODEL

> FULL <-
lmer(Weight~HatchOrder+ClutchSize+Year+HatchOrder*Year+ClutchSize*Year+SibCo
mp+(1|NestID))

Linear mixed model fit by REML 

   AIC   BIC logLik deviance REMLdev
 562.2 598.3 -268.1    551.1   536.2

Random effects:
 Groups   Name        Variance Std.Dev.
 NestID   (Intercept) 4.1513   2.0375  
 Residual             3.4385   1.8543  
Number of obs: 118, groups: NestID, 87

Fixed effects:
                          Estimate Std. Error t value
(Intercept)               40.44583    0.79525   50.86
HatchOrderSecond          -0.05734    1.08618   -0.05
HatchOrderThird           -4.57739    2.01458   -2.27
ClutchSizeTwo             -0.68492    1.12169   -0.61
ClutchSizeThree           -0.79372    1.08271   -0.73
Year2007                  -0.35917    1.12465   -0.32
SibCompPresente           -1.67799    0.94786   -1.77
HatchOrderSecond:Year2007 -0.71230    1.00113   -0.71
HatchOrderThird:Year2007  -1.59001    1.87684   -0.85
ClutchSizeTwo:Year2007    -0.25690    1.66292   -0.15
ClutchSizeThree:Year2007  -2.14999    1.46019   -1.47


MODEL WITHOUT RANDOM INTERCEPT TERM: 

> REDUCED
<-lm(Weight~HatchOrder+ClutchSize+Year+HatchOrder*Year+ClutchSize*Year+SibCo
mp) 

Residuals:
    Min      1Q  Median      3Q     Max 
-6.5723 -1.6628  0.3156  1.5917  6.4361 

Coefficients:
                          Estimate Std. Error t value Pr(>|t|)    
(Intercept)               40.44583    0.80129  50.476   <2e-16 ***
HatchOrderSecond           0.04877    1.22858   0.040   0.9684    
HatchOrderThird           -4.17110    2.05523  -2.030   0.0449 *  
ClutchSizeTwo             -0.82366    1.11288  -0.740   0.4608    
ClutchSizeThree           -0.91305    1.07716  -0.848   0.3985    
Year2007                  -0.35917    1.13319  -0.317   0.7519    
SibCompPresente           -1.94834    1.06655  -1.827   0.0705 .  
HatchOrderSecond:Year2007 -0.52951    1.28902  -0.411   0.6821    
HatchOrderThird:Year2007  -1.49689    2.16455  -0.692   0.4907    
ClutchSizeTwo:Year2007    -0.24930    1.64309  -0.152   0.8797    
ClutchSizeThree:Year2007  -2.12061    1.45500  -1.457   0.1479    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Residual standard error: 2.776 on 107 degrees of freedom
  (149 observations deleted due to missingness)
Multiple R-squared: 0.512,      Adjusted R-squared: 0.4664 
F-statistic: 11.23 on 10 and 107 DF,  p-value: 6.46e-13

LIKELIHOOD RATIO TEST 
as.numeric(2*(logLik(FULL)-logLik(REDUCED)))
[1] 28.0247

pchisq(28.0247,1,lower=FALSE) 
[1] 1.197768e-07

NOW THE BOOTSTRAPPING APPROACH

y <- simulate(REDUCED)
lrstat <- numeric(1000)
for(i in 1:1000){
y <- unlist(simulate(REDUCED))
REDUCED <-
lm(TMT10~HatchOrder+ClutchSize+Year+HatchOrder*Year+ClutchSize*Year+SibComp)
FULL <-
lmer(TMT10~HatchOrder+ClutchSize+Year+HatchOrder*Year+ClutchSize*Year+SibCom
p+(1|NestID))
lrstat[i] <- as.numeric(2*(logLik(FULL)-logLik(REDUCED)))}

mean(lrstat>28.0247)
[1] 0

3. Final question. Although LRT and bootstrap p-values seem to indicate the
same thing here, I would like to be able to get a p-value with some more
digits!   

Thank you very much in advance List! 

Luciano



From David.Duffy at qimr.edu.au  Sun Mar  7 02:21:25 2010
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Sun, 7 Mar 2010 11:21:25 +1000 (EST)
Subject: [R-sig-ME] Testing signif. of random effects by bootstrapping
In-Reply-To: <A3C95F6B66F5488C8EF2D1A91ECA975B@Negro1>
References: <A3C95F6B66F5488C8EF2D1A91ECA975B@Negro1>
Message-ID: <Pine.LNX.4.64.1003071113360.23158@orpheus.qimr.edu.au>

On Sat, 6 Mar 2010, Luciano La Sala wrote:

> 2. The bootstrap method yields p-values that are either 0 or 1 (no decimal
> places), which seems a little odd to me. How can I ask R to provide, say, 4
> significant digits for the bootstrapping p-value?
>
> NOW THE BOOTSTRAPPING APPROACH
>
> y <- simulate(REDUCED)
> lrstat <- numeric(1000)
> for(i in 1:1000){
>    y <- unlist(simulate(REDUCED))
>    REDUCED <- lm(TMT10~HatchOrder+ClutchSize+Year+
>                  HatchOrder*Year+ClutchSize*Year+SibComp)
>   FULL <- lmer(TMT10~HatchOrder+ClutchSize+Year+HatchOrder*Year+>
        ClutchSize*Year+SibComp+(1|NestID))
>  lrstat[i] <- as.numeric(2*(logLik(FULL)-logLik(REDUCED)))
> }

y never gets used in your loop, so lrstat[1:1000] is all 28.0247. But this 
isn't a bootstrap anyway.  You should look at the RLRsim package and 
associated paper.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From Antonio.Gasparrini at lshtm.ac.uk  Sun Mar  7 21:23:11 2010
From: Antonio.Gasparrini at lshtm.ac.uk (Antonio.Gasparrini at lshtm.ac.uk)
Date: Sun, 07 Mar 2010 20:23:11 +0000
Subject: [R-sig-ME] Examples of GLMM fits?
In-Reply-To: <mailman.7.1267959602.19611.r-sig-mixed-models@r-project.org>
References: <mailman.7.1267959602.19611.r-sig-mixed-models@r-project.org>
Message-ID: <4B940B30.5572.00B2.1@lshtm.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100307/d9fb8ae4/attachment.pl>

From bates at stat.wisc.edu  Mon Mar  8 15:50:59 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 8 Mar 2010 08:50:59 -0600
Subject: [R-sig-ME] Examples of GLMM fits?
In-Reply-To: <4B940B30.5572.00B2.1@lshtm.ac.uk>
References: <mailman.7.1267959602.19611.r-sig-mixed-models@r-project.org>
	<4B940B30.5572.00B2.1@lshtm.ac.uk>
Message-ID: <40e66e0b1003080650x22542383vef1da7fbb48e230c@mail.gmail.com>

On Sun, Mar 7, 2010 at 2:23 PM,  <Antonio.Gasparrini at lshtm.ac.uk> wrote:
> Dear Douglas Bates and R users,

> some time ago I sent an simulated example with a overdispersed Poisson GLMM where I compare glmmPQL and glmer.
> See https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q1/003289.html

> I found some problems in the results on glmer with quasipoisson family.
> I hope someone could explain this

I will leave it to others more skilled than I to decide how to
formulate parameter estimates for fictitious distributions.  I have
enough trouble working in the non-fiction end of statistical theory.

> ----------------------------------------------------------------------
>
> Message: 1
> Date: Sat, 6 Mar 2010 09:57:06 -0600
> From: Douglas Bates <bates at stat.wisc.edu>
> To: R-mixed models mailing list <r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] Examples of GLMM fits?
> Message-ID:
> <40e66e0b1003060757pa6e772fvfe29960a167e9b76 at mail.gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1
>
> I have added the Gamma family for glmer in the lme4a package and will
> backport to the lme4 package. ? (Actually Ben Bolker sent me a patch
> for lme4 several weeks ago and I haven't gotten around to installing
> it yet but will do so.)
>
> However, before I release it I would like to have an example data set
> and model on which to test it. ?I don't have any. ?Could someone
> provide me with a reference to data and a fitted model that I could
> use as an example? ?I would also appreciate an example of a Poisson
> GLMM and other families too.
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From pogola at princeton.edu  Mon Mar  8 17:33:28 2010
From: pogola at princeton.edu (Patrick Onyango)
Date: Mon, 8 Mar 2010 11:33:28 -0500
Subject: [R-sig-ME] Effect Size in lme
Message-ID: <0B1FFCC3-9F31-44A1-BDD5-4669A7B1B4A6@princeton.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100308/4dd679f3/attachment.pl>

From maj at waikato.ac.nz  Mon Mar  8 21:30:33 2010
From: maj at waikato.ac.nz (Murray Jorgensen)
Date: Tue, 09 Mar 2010 09:30:33 +1300
Subject: [R-sig-ME] Quasilikelihood considered harmful? was: Examples of
	GLMM fits?
In-Reply-To: <40e66e0b1003080650x22542383vef1da7fbb48e230c@mail.gmail.com>
References: <mailman.7.1267959602.19611.r-sig-mixed-models@r-project.org>	<4B940B30.5572.00B2.1@lshtm.ac.uk>
	<40e66e0b1003080650x22542383vef1da7fbb48e230c@mail.gmail.com>
Message-ID: <4B955E69.9030407@waikato.ac.nz>

Doug's response indicates a certain scepticism about quasilikelihood and 
it's use in modelling. I am quite interested in this question and may 
even get around to attempting some theoretical work about it. What I 
would like to know about literature and discussions critical of QL and 
its role in modelling. I think I am generally aware of pro-QL literature.

Cheers,  Murray Jorgensen

On 9/03/2010 3:50 a.m., Douglas Bates wrote:
[...]
> I will leave it to others more skilled than I to decide how to
> formulate parameter estimates for fictitious distributions.  I have
> enough trouble working in the non-fiction end of statistical theory.
>
[...]
-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    Home +64 7 825 0441   Mobile 021 0200 8350



From bates at stat.wisc.edu  Mon Mar  8 22:12:33 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 8 Mar 2010 15:12:33 -0600
Subject: [R-sig-ME] Quasilikelihood considered harmful? was: Examples of
	GLMM fits?
In-Reply-To: <4B955E69.9030407@waikato.ac.nz>
References: <mailman.7.1267959602.19611.r-sig-mixed-models@r-project.org>
	<4B940B30.5572.00B2.1@lshtm.ac.uk>
	<40e66e0b1003080650x22542383vef1da7fbb48e230c@mail.gmail.com>
	<4B955E69.9030407@waikato.ac.nz>
Message-ID: <40e66e0b1003081312i42d1c53ck7652157696c0d59@mail.gmail.com>

On Mon, Mar 8, 2010 at 2:30 PM, Murray Jorgensen <maj at waikato.ac.nz> wrote:
> Doug's response indicates a certain scepticism about quasilikelihood and
> it's use in modelling. I am quite interested in this question and may even
> get around to attempting some theoretical work about it. What I would like
> to know about literature and discussions critical of QL and its role in
> modelling. I think I am generally aware of pro-QL literature.

I should have been more specific and less cheeky.  What I am trying to
communicate is that the way that I have been able to finally work out
in my mind how to estimate parameters in generalized linear mixed
models is to go right back to the probability model and derive things
from there, step by step.  I can't do that for quasi-poisson or
quasi-binomial models because there is no probability model.

I don't know what is involved in fitting parameters using
quasilikelihood and whether or not the approach can be generalized to
mixed models.  I find it hard enough to work out what all the bits and
pieces are when working with a probability distribution.  Working with
something that sort of looks like a probability distribution but isn't
really is beyond what I want to try at this point.


> Cheers, ?Murray Jorgensen
>
> On 9/03/2010 3:50 a.m., Douglas Bates wrote:
> [...]
>>
>> I will leave it to others more skilled than I to decide how to
>> formulate parameter estimates for fictitious distributions. ?I have
>> enough trouble working in the non-fiction end of statistical theory.
>>
> [...]
> --
> Dr Murray Jorgensen ? ? ?http://www.stats.waikato.ac.nz/Staff/maj.html
> Department of Statistics, University of Waikato, Hamilton, New Zealand
> Email: maj at waikato.ac.nz ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Fax 7 838 4155
> Phone ?+64 7 838 4773 wk ? ?Home +64 7 825 0441 ? Mobile 021 0200 8350
>



From bolker at ufl.edu  Mon Mar  8 22:22:02 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Mon, 08 Mar 2010 16:22:02 -0500
Subject: [R-sig-ME] Quasilikelihood considered harmful? was: Examples
 of	GLMM fits?
In-Reply-To: <4B955E69.9030407@waikato.ac.nz>
References: <mailman.7.1267959602.19611.r-sig-mixed-models@r-project.org>	<4B940B30.5572.00B2.1@lshtm.ac.uk>	<40e66e0b1003080650x22542383vef1da7fbb48e230c@mail.gmail.com>
	<4B955E69.9030407@waikato.ac.nz>
Message-ID: <4B956A7A.2040801@ufl.edu>

Murray Jorgensen wrote:
> Doug's response indicates a certain scepticism about quasilikelihood and 
> it's use in modelling. I am quite interested in this question and may 
> even get around to attempting some theoretical work about it. What I 
> would like to know about literature and discussions critical of QL and 
> its role in modelling. I think I am generally aware of pro-QL literature.
> 
> Cheers,  Murray Jorgensen
> 
> On 9/03/2010 3:50 a.m., Douglas Bates wrote:
> [...]
>> I will leave it to others more skilled than I to decide how to
>> formulate parameter estimates for fictitious distributions.  I have
>> enough trouble working in the non-fiction end of statistical theory.

  I am interested too.

  I suspect most of the criticism of QL has to do with its extension
beyond the GLM framework to other areas, such as quasi-AIC, or
application of QL ideas in frameworks such as GLMMs where the
fundamental theory hasn't really been worked out (that I know of).
These methods are used a lot by people in applied fields, *without*
worrying about those missing foundations ... for example, most of the
citations for QAIC in the ecological literature go back to Lebreton et
al 1992, who say:

(p. 85): In priniciple [sic], the LRTs should be modified, as should the
AIC criterion. These matters, which need further work, show up in our
last example (Greater Flamingo) ... (p. 107) Similarly, the AIC should
be modified as DEV/c-hat+2*n*p. ***We caution that these ideas are
exploratory and not yet confirmed by fundamental statistical theory, but
the ideas are consistent with quasi-likelihood theory*** [emphasis mine]

  Others (such as Shane Richards 2008) have tested these ideas *by
simulation*, and they seem to work out OK, but I would be curious to
know about work that establishes the theoretical foundations for these
approaches.

  A wild guess would be that generalized estimating equations are the
more respectable (theoretically grounded?) approach to this kind of
problem ... on the other hand, it would be nice to have a version of GEE
where one had something better than Wald tests to rely on for smaller
data sets ...

  One final remark (which may get me in trouble): ecologists (and
others) have to deal with overdispersion in small, discrete (i.e.
plausibly exponential family) data sets with blocking factors (i.e.
random effects) all the time.  The approaches that I know of for
statistical analysis in this case are
1. GEE (only Wald tests -- see above),
2. using an alternative distribution such as the negative binomial (not
currently possible in glmer -- arguably could be hacked similarly to the
way that MASS::glm.nb() extends glm(), if there were a slot in the data
structure that allowed the internal code to make use of an additional
parameter for the variance function)
3. allowing random effects at the individual level (equivalent to
assuming a marginal lognormal-Poisson distribution) -- not currently
possible in lme4 because of tests comparing the number of random effects
to the number of observations [but can be hacked by expeRts]
4. quasi-likelihood approaches

#1 is presumably possible in gee(), geepack()
#2 is possible in ADMB, glmmADMB
#3 is possible in MCMCglmm, R2WinBUGS ...
#4 is possible in glmmPQL (but PQL has its own problems)

  So it's understandable (to me) why people are still asking about
quasi- in lme4 , given that people take it as the standard for mixed
modeling in R and that it has broad applicability ...

  Disclaimer: I think I'm not talking nonsense, but I would be happy to
be corrected.

  Ben Bolker

============================
Lebreton, J. D., K. P. Burnham, J. Clobert, and D. R. Anderson. 1992.
Modeling Survival and Testing Biological Hypotheses Using Marked
Animals: A Uni?ed Approach with Case Studies. Ecological Monographs
62:67-118. .

Richards, S. A. 2008. Dealing with overdispersed count data in applied
ecology. Journal of Applied Ecology 45:218-227. doi:
10.1111/j.1365-2664.2007.01377.x.



-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From bolker at ufl.edu  Mon Mar  8 22:39:31 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Mon, 08 Mar 2010 16:39:31 -0500
Subject: [R-sig-ME] Effect Size in lme
In-Reply-To: <0B1FFCC3-9F31-44A1-BDD5-4669A7B1B4A6@princeton.edu>
References: <0B1FFCC3-9F31-44A1-BDD5-4669A7B1B4A6@princeton.edu>
Message-ID: <4B956E93.4010506@ufl.edu>

Patrick Onyango wrote:
> All,
> I have been asked to provide effect sizes for results I obtained from  
> lme. Does anyone know how to handle this?
> 
> Many thanks already.
> Patrick

  There are a lot of definitions of "effect size".  If the request is
simply to indicate the practical relevance of the effects (i.e.
'biological' significance), I would just quote the parameter estimates
(with standard errors), and the standard deviations of the random
effects ...

-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From pogola at Princeton.EDU  Mon Mar  8 23:51:49 2010
From: pogola at Princeton.EDU (Patrick Onyango)
Date: Mon, 8 Mar 2010 17:51:49 -0500
Subject: [R-sig-ME] Effect Size in lme
In-Reply-To: <4B956E93.4010506@ufl.edu>
References: <0B1FFCC3-9F31-44A1-BDD5-4669A7B1B4A6@princeton.edu>
	<4B956E93.4010506@ufl.edu>
Message-ID: <E1F7F45C-03D2-48B1-A2A8-77A43E3467F6@Princeton.EDU>

Dear Ben,
Many thanks.

Thanks for clarifying: yes, I am interested in effect size with  
respect to biological significance of my findings.  In addition to  
the suggestions you have provided, which I hope to talk to you some,  
would you recommend using the following formula, from Nakagawa &  
Cuthill (2007) Biol. Rev. 82, 591-605: partial correlation  
coefficient, r = the t value divided by the square of the sum of the  
t value squared and its corresponding degrees of freedom?

Here is the equation:


I am not quite sure how to interpret, with respect to the kind of  
effect I am looking for, the parameter estimates and the other values  
that you suggested. Are there resources you can recommend. In the  
meantime, I will check in P & B 2000 as well as in West et al. 2007.

Thanks,
Patrick

On Mar 8, 2010, at 4:39 PM, Ben Bolker wrote:

> Patrick Onyango wrote:
>> All,
>> I have been asked to provide effect sizes for results I obtained from
>> lme. Does anyone know how to handle this?
>>
>> Many thanks already.
>> Patrick
>
>   There are a lot of definitions of "effect size".  If the request is
> simply to indicate the practical relevance of the effects (i.e.
> 'biological' significance), I would just quote the parameter estimates
> (with standard errors), and the standard deviations of the random
> effects ...
>
> -- 
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / people.biology.ufl.edu/bolker
> GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From moraisjr at gmail.com  Tue Mar  9 00:12:54 2010
From: moraisjr at gmail.com (Marcio M. de Morais Jr.)
Date: Mon, 8 Mar 2010 20:12:54 -0300
Subject: [R-sig-ME] Effect Size in lme
In-Reply-To: <E1F7F45C-03D2-48B1-A2A8-77A43E3467F6@Princeton.EDU>
References: <0B1FFCC3-9F31-44A1-BDD5-4669A7B1B4A6@princeton.edu>
	<4B956E93.4010506@ufl.edu>
	<E1F7F45C-03D2-48B1-A2A8-77A43E3467F6@Princeton.EDU>
Message-ID: <2a4cf8f41003081512n1aed06d9rf07034376c3b3400@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100308/f8380aec/attachment.pl>

From slu at ccsr.uchicago.edu  Tue Mar  9 01:20:51 2010
From: slu at ccsr.uchicago.edu (Stuart Luppescu)
Date: Mon, 08 Mar 2010 18:20:51 -0600
Subject: [R-sig-ME] Size/metric of variance components in lme and lmer
Message-ID: <1268094051.24443.20.camel@musume.snl.home>

Hello, I have run two analyses, each with the same data set and
predictors. One is a nested model run with lme; the other is a
cross-classified model with lmer. The only difference between the two
models is the added random effect. For example, the nested model
statement looks like this:

nested.lm3 <- lme(final.points ~ -1 + gr10 + gr11 + gr12 + per1 + per2 +
per4 + per5 + per6 + per7 + per8 + per9 + per10 + per11 + per12 +
                  cblackd + casiand + clatinod + cmale + cssoc + cscon +
cold4gr  + cmlatent8 + computer +
                    ...
               jourlsm,
                  data=all.subj, random = ~ 1|sid, na.action=na.omit)

The cross-classified model looks like this:

lm4c <- lmer(final.points ~ -1 + gr10 + gr11 + gr12 + per1 + per2 + per4
+ per5 + per6 + per7 + per8 + per9 + per10 + per11 + per12 +
                  cblackd + casiand + clatinod + cmale + cssoc + cscon +
cold4gr  + cmlatent8 + computer +
                  ...
                  jourlsm +
            ( 1 | sid) + (1 | tid), data=all.subj,  REML=F, verbose=T)

The variance components for the nested model are:
Random effects:
 Formula: ~1 | sid
        (Intercept)  Residual
StdDev:   0.8826577 0.9259174

for the cross-classified model:

 Groups   Name        Variance Std.Dev.
 sid      (Intercept) 0.75426  0.86848 
 tid      (Intercept) 0.39601  0.62929 
 Residual             0.68535  0.82786 

If we square and sum the variance components for the nested model, the
total variance is about 1.64. For the cross-classified model, the total
variance is about 1.84. Where did the additional variance come from?

Should I just interpret the size of the variance components on a
relative scale, are the units different, or what?

-- 
Stuart Luppescu -*-*- slu <at> ccsr <dot> uchicago <dot> edu
CCSR in UEI at U of C



From john.maindonald at anu.edu.au  Tue Mar  9 03:22:07 2010
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Tue, 9 Mar 2010 13:22:07 +1100
Subject: [R-sig-ME] Quasilikelihood considered harmful? was: Examples of
	GLMM fits?
In-Reply-To: <40e66e0b1003081312i42d1c53ck7652157696c0d59@mail.gmail.com>
References: <mailman.7.1267959602.19611.r-sig-mixed-models@r-project.org>
	<4B940B30.5572.00B2.1@lshtm.ac.uk>
	<40e66e0b1003080650x22542383vef1da7fbb48e230c@mail.gmail.com>
	<4B955E69.9030407@waikato.ac.nz>
	<40e66e0b1003081312i42d1c53ck7652157696c0d59@mail.gmail.com>
Message-ID: <557282F9-9398-4C3B-AE13-ACC02D2B276D@anu.edu.au>

It was at one time possible to associate one random effect with each
observation.  This is an entirely respectable model.

It was allowed in lme4a last time that I used it.  It is not however 
allowed in the version of lme4 that is currently on my computer.  

The one random effect per observation model is a different model 
from any model that might be postulated to generate the quasipoisson 
variance.  On the scale of the linear predictor, a normal variance 
component is added.  The quasipoisson error increases the variance, 
on the scale of the response, by a constant multiplier.  As the source 
of the extra variance is specified precisely, the glmer one random 
effect per observation model is nicer.  Whether it gives a better account
of the data is a separate issue!

It seems to me that it would be very messy to try to incorporate a 
quasipoisson variance into the context of a GLMM model.  One would 
need, I surmise, an explicit form of model for the extra variance.

The lme4a calculation went like this:

[lme4a_0.999375-44]
[Dependencies create problems for loading DAAG into R-devel.
So I saved the image under R-2.10.0 into moths.RData, and then
loaded that image.]
library(lme4a)
moths$transect <- 1:41  # Each row is from a different transect 
moths$habitat <- relevel(moths$habitat, ref="Lowerside") 
(A.glmer <-  glmer(A~habitat+log(meters)+(1|transect),  
+                    family=poisson, data=subset(moths,subset=habitat!="Bank"))) 
Generalized linear mixed model fit by the Laplace approximation 
Formula: A ~ habitat + log(meters) + (1 | transect) 
 Data: subset(moths, subset = habitat != "Bank") 
AIC BIC logLik deviance
208 223    -95      190
Random effects:
Groups   Name        Variance Std.Dev.
transect (Intercept) 0.229    0.478   
Number of obs: 40, groups: transect, 40

Fixed effects:
               Estimate Std. Error z value Pr(>|z|)
(Intercept)        1.0876     0.3963    2.74  0.00607
habitatDisturbed  -1.2326     0.4699   -2.62  0.00872
habitatNEsoak     -0.8210     0.4402   -1.87  0.06216
habitatNWsoak      1.5166     0.3915    3.87  0.00011
habitatSEsoak      0.0515     0.3505    0.15  0.88321
habitatSWsoak      0.2435     0.4543    0.54  0.59188
habitatUpperside  -0.1669     0.5366   -0.31  0.75570
log(meters)        0.1506     0.1374    1.10  0.27293
. . . .

The variance that is due to the Poisson error is increased, on 
the scale of the linear predictor, by 0.234.  Relative to the
quasipoisson model (below), more extreme estimates of 
treatment differences (but not for Bank) are pulled in towards 
the overall mean. The habitat Disturbed now appears clearly 
different from the reference, which is Lowerside. The reason 
is that nn the scale of the linear predictor, the Poisson variance 
is largest when the linear predictor is smallest, that is when the 
expected count is, as for Disturbed, close to zero. Addition of an 
amount that is constant across the range has, by comparison
with the quasipoisson model that uses a constant multiplier
(the "dispersion"), a relatively smaller effect when the contribution 
from the Poisson variance is, on this scale, largest.

Here is the glm model that uses a quasipoisson error:

> summary(A.glm <- glm(A ~ habitat + log(meters), data=moths))

Call:
glm(formula = A ~ habitat + log(meters), data = moths)

Deviance Residuals: 
       Min          1Q      Median          3Q         Max  
-1.477e+01  -1.893e+00   6.661e-15   1.141e+00   1.518e+01  

Coefficients:
                 Estimate Std. Error t value Pr(>|t|)
(Intercept)        3.2806     2.6352   1.245    0.222
habitatBank       -4.9768     5.0488  -0.986    0.332
habitatDisturbed  -3.0081     2.4825  -1.212    0.234
habitatNEsoak     -2.9095     2.7464  -1.059    0.297
habitatNWsoak     18.6999     3.2349   5.781 2.05e-06
habitatSEsoak      0.3414     2.4756   0.138    0.891
habitatSWsoak      1.4312     3.3565   0.426    0.673
habitatUpperside  -0.5915     3.7839  -0.156    0.877
log(meters)        0.5571     0.9212   0.605    0.550

(Dispersion parameter for gaussian family taken to be 22.50446)

    Null deviance: 1953.22  on 40  degrees of freedom
Residual deviance:  720.14  on 32  degrees of freedom
AIC: 253.85

Number of Fisher Scoring iterations: 2


I noted also that the same (?) analysis is possible under glmmPQL from MASS.  
(This relies on iterated calls to lme(), from nlme.) The estimates are 
very similar, but the SEs are noticeably different:

> A.glmmPQL <-  glmmPQL(A~habitat+log(meters), random=~1|transect,  
+                    family=poisson, data=subset(moths,subset=habitat!="Bank"))
Random effects:
Formula: ~1 | transect
      (Intercept) Residual
StdDev:       0.448     1.04

Variance function:
Structure: fixed weights
Formula: ~invwt 
Fixed effects: A ~ habitat + log(meters) 
                Value Std.Error DF t-value p-value
(Intercept)       1.110     0.437 32    2.54  0.0162
habitatDisturbed -1.240     0.528 32   -2.35  0.0253
habitatNEsoak    -0.821     0.488 32   -1.68  0.1027
habitatNWsoak     1.514     0.422 32    3.58  0.0011
habitatSEsoak     0.053     0.385 32    0.14  0.8917
habitatSWsoak     0.240     0.497 32    0.48  0.6326
habitatUpperside -0.166     0.590 32   -0.28  0.7795
log(meters)       0.147     0.151 32    0.97  0.3399


John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 09/03/2010, at 8:12 AM, Douglas Bates wrote:

> On Mon, Mar 8, 2010 at 2:30 PM, Murray Jorgensen <maj at waikato.ac.nz> wrote:
>> Doug's response indicates a certain scepticism about quasilikelihood and
>> it's use in modelling. I am quite interested in this question and may even
>> get around to attempting some theoretical work about it. What I would like
>> to know about literature and discussions critical of QL and its role in
>> modelling. I think I am generally aware of pro-QL literature.
> 
> I should have been more specific and less cheeky.  What I am trying to
> communicate is that the way that I have been able to finally work out
> in my mind how to estimate parameters in generalized linear mixed
> models is to go right back to the probability model and derive things
> from there, step by step.  I can't do that for quasi-poisson or
> quasi-binomial models because there is no probability model.
> 
> I don't know what is involved in fitting parameters using
> quasilikelihood and whether or not the approach can be generalized to
> mixed models.  I find it hard enough to work out what all the bits and
> pieces are when working with a probability distribution.  Working with
> something that sort of looks like a probability distribution but isn't
> really is beyond what I want to try at this point.
> 
> 
>> Cheers,  Murray Jorgensen
>> 
>> On 9/03/2010 3:50 a.m., Douglas Bates wrote:
>> [...]
>>> 
>>> I will leave it to others more skilled than I to decide how to
>>> formulate parameter estimates for fictitious distributions.  I have
>>> enough trouble working in the non-fiction end of statistical theory.
>>> 
>> [...]
>> --
>> Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
>> Department of Statistics, University of Waikato, Hamilton, New Zealand
>> Email: maj at waikato.ac.nz                                Fax 7 838 4155
>> Phone  +64 7 838 4773 wk    Home +64 7 825 0441   Mobile 021 0200 8350
>> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From Thierry.ONKELINX at inbo.be  Tue Mar  9 10:16:45 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 9 Mar 2010 10:16:45 +0100
Subject: [R-sig-ME] Size/metric of variance components in lme and lmer
In-Reply-To: <1268094051.24443.20.camel@musume.snl.home>
References: <1268094051.24443.20.camel@musume.snl.home>
Message-ID: <2E9C414912813E4EB981326983E0A104070E519C@inboexch.inbo.be>

Dear Stuart,

I think that the "extra" variance is substracted from the fixed effects.
Which indicates that some of the information in your fixed effects was
due to the levels of tid.

But to make a fair comparison you should run both models with lmer. And
then compare both the random effects variances and the fixed effect
estimates.

HTH,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens 
> Stuart Luppescu
> Verzonden: dinsdag 9 maart 2010 1:21
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] Size/metric of variance components in 
> lme and lmer
> 
> Hello, I have run two analyses, each with the same data set 
> and predictors. One is a nested model run with lme; the other 
> is a cross-classified model with lmer. The only difference 
> between the two models is the added random effect. For 
> example, the nested model statement looks like this:
> 
> nested.lm3 <- lme(final.points ~ -1 + gr10 + gr11 + gr12 + 
> per1 + per2 +
> per4 + per5 + per6 + per7 + per8 + per9 + per10 + per11 + per12 +
>                   cblackd + casiand + clatinod + cmale + 
> cssoc + cscon + cold4gr  + cmlatent8 + computer +
>                     ...
>                jourlsm,
>                   data=all.subj, random = ~ 1|sid, na.action=na.omit)
> 
> The cross-classified model looks like this:
> 
> lm4c <- lmer(final.points ~ -1 + gr10 + gr11 + gr12 + per1 + 
> per2 + per4
> + per5 + per6 + per7 + per8 + per9 + per10 + per11 + per12 +
>                   cblackd + casiand + clatinod + cmale + 
> cssoc + cscon + cold4gr  + cmlatent8 + computer +
>                   ...
>                   jourlsm +
>             ( 1 | sid) + (1 | tid), data=all.subj,  REML=F, verbose=T)
> 
> The variance components for the nested model are:
> Random effects:
>  Formula: ~1 | sid
>         (Intercept)  Residual
> StdDev:   0.8826577 0.9259174
> 
> for the cross-classified model:
> 
>  Groups   Name        Variance Std.Dev.
>  sid      (Intercept) 0.75426  0.86848 
>  tid      (Intercept) 0.39601  0.62929 
>  Residual             0.68535  0.82786 
> 
> If we square and sum the variance components for the nested 
> model, the total variance is about 1.64. For the 
> cross-classified model, the total variance is about 1.84. 
> Where did the additional variance come from?
> 
> Should I just interpret the size of the variance components 
> on a relative scale, are the units different, or what?
> 
> --
> Stuart Luppescu -*-*- slu <at> ccsr <dot> uchicago <dot> edu 
> CCSR in UEI at U of C
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From HDoran at air.org  Tue Mar  9 16:49:44 2010
From: HDoran at air.org (Doran, Harold)
Date: Tue, 9 Mar 2010 10:49:44 -0500
Subject: [R-sig-ME] Effect Size in lme
In-Reply-To: <E1F7F45C-03D2-48B1-A2A8-77A43E3467F6@Princeton.EDU>
References: <0B1FFCC3-9F31-44A1-BDD5-4669A7B1B4A6@princeton.edu>
	<4B956E93.4010506@ufl.edu>
	<E1F7F45C-03D2-48B1-A2A8-77A43E3467F6@Princeton.EDU>
Message-ID: <C0772C7568B5374481D2F8A880E9BBDF045685FC8A@DC1EX07CMS.air.org>

IMHO, this is a worthless endeavor. The statistic you note below is typical in meta-analysis where you want to find a linear relationship between two continuous variables. There was a big push in my field (education) to always publish some form of a standardized effect size alongside all results.

I always thought this was just plain silly since the linear model itself gives a more natural measure of an effect. That is, isn't that what the effect of some covariate is anyway? I never found it reasonable to then convert this to some standardized coefficient (no longer on the metric used for the analysis) to aid in the interpretation. I think it does exactly the opposite. You now have some number that is not on the same metric as the original variable that is supposed to help you think more about the original variable? 

When I want to think about variability of some variable, I prefer the standard deviation and not the variance since the sd is on the same scale as the metric of interest and it is therefore directly interpretable.

With that said, with mixed effects models, I think this issue is a bit more complex. I don't mean to open a can of worms, (but I'm sure I will) what is the right DF for the mixed effects model anyhow? The fixed effects do not follow a known distribution, although many treat them as though they follow an F distribution for convenience.  

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Patrick Onyango
Sent: Monday, March 08, 2010 5:52 PM
To: Ben Bolker
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Effect Size in lme

Dear Ben,
Many thanks.

Thanks for clarifying: yes, I am interested in effect size with  
respect to biological significance of my findings.  In addition to  
the suggestions you have provided, which I hope to talk to you some,  
would you recommend using the following formula, from Nakagawa &  
Cuthill (2007) Biol. Rev. 82, 591-605: partial correlation  
coefficient, r = the t value divided by the square of the sum of the  
t value squared and its corresponding degrees of freedom?

Here is the equation:


I am not quite sure how to interpret, with respect to the kind of  
effect I am looking for, the parameter estimates and the other values  
that you suggested. Are there resources you can recommend. In the  
meantime, I will check in P & B 2000 as well as in West et al. 2007.

Thanks,
Patrick

On Mar 8, 2010, at 4:39 PM, Ben Bolker wrote:

> Patrick Onyango wrote:
>> All,
>> I have been asked to provide effect sizes for results I obtained from
>> lme. Does anyone know how to handle this?
>>
>> Many thanks already.
>> Patrick
>
>   There are a lot of definitions of "effect size".  If the request is
> simply to indicate the practical relevance of the effects (i.e.
> 'biological' significance), I would just quote the parameter estimates
> (with standard errors), and the standard deviations of the random
> effects ...
>
> -- 
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / people.biology.ufl.edu/bolker
> GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From slu at ccsr.uchicago.edu  Tue Mar  9 21:08:46 2010
From: slu at ccsr.uchicago.edu (Stuart Luppescu)
Date: Tue, 09 Mar 2010 14:08:46 -0600
Subject: [R-sig-ME] Size/metric of variance components in lme and lmer
In-Reply-To: <2E9C414912813E4EB981326983E0A104070E519C@inboexch.inbo.be>
References: <1268094051.24443.20.camel@musume.snl.home>
	<2E9C414912813E4EB981326983E0A104070E519C@inboexch.inbo.be>
Message-ID: <1268165326.23765.16.camel@musuko.spc.uchicago.edu>

On Tue, 2010-03-09 at 10:16 +0100, ONKELINX, Thierry wrote:
> Dear Stuart,
> 
> I think that the "extra" variance is substracted from the fixed
> effects. Which indicates that some of the information in your fixed
> effects was due to the levels of tid.
> 
> But to make a fair comparison you should run both models with lmer.
> And then compare both the random effects variances and the fixed
> effect estimates.

OK. I copied function call from the cross-classified model with lmer and
removed the second random effect and reran it. Here are the random
effects tables:

Nested model:
   Data: all.subj 
     AIC     BIC   logLik deviance REMLdev
 3448318 3449229 -1724083  3448166 3448707
Random effects:
 Groups   Name        Variance Std.Dev.
 sid      (Intercept) 0.77403  0.87979 
 Residual             0.85746  0.92599 
Number of obs: 1185094, groups: sid, 122897

Total variance:  1.63
--------------------------------------------------

Cross-classified model:
   Data: all.subj 
     AIC     BIC   logLik deviance REMLdev
 3236856 3237779 -1618351  3236702 3237217
Random effects:
 Groups   Name        Variance Std.Dev.
 sid      (Intercept) 0.75066  0.86641 
 tid      (Intercept) 0.39171  0.62587 
 Residual             0.68583  0.82815 
Number of obs: 1185094, groups: sid, 122897; tid, 8939

Total variance: 1.83

Could some of the difference be due to covariance between the random
effects?


-- 
Stuart Luppescu <slu at ccsr.uchicago.edu>
University of Chicago



From HDoran at air.org  Tue Mar  9 22:07:13 2010
From: HDoran at air.org (Doran, Harold)
Date: Tue, 9 Mar 2010 16:07:13 -0500
Subject: [R-sig-ME] Size/metric of variance components in lme and lmer
In-Reply-To: <1268165326.23765.16.camel@musuko.spc.uchicago.edu>
References: <1268094051.24443.20.camel@musume.snl.home>
	<2E9C414912813E4EB981326983E0A104070E519C@inboexch.inbo.be>
	<1268165326.23765.16.camel@musuko.spc.uchicago.edu>
Message-ID: <C0772C7568B5374481D2F8A880E9BBDF045685FD27@DC1EX07CMS.air.org>

Stuart:

Not sure I know the answers, but a few thoughts. What covariance? In your non-nested model I don't think the random effects are assumed correlated are they? Doug Bates will certainly not be happy with what I do next, but it's one way to think about this.

An algebraic (not computational) expression for the variance of a mixed-effects model is var(y) = V = ZDZ' + sigma^2I

Where Z is the model matrix for the random effects, D is the variance/covariance of the random effects, sigma^2 is the residual variance and I is the identity matrix.

In your nested model, Z has a rather simple structure and D is a scalar. In you non-nested model, Z has a more complex structure denoting the linkage of students to multiple teachers and D is diagonal with I think D = [D_1, D_2] where D_1 = diag(0.75066, ..., 0.75066) and D_2 = diag(0.39171, ..., 0.39171).

In the first nested case, V will be block diagonal denoting no covariance between students in other teacher's classrooms. There will only be covariances between students in the same classroom. The portion ZDZ' will be pretty simple with the block diagonal elements all equal to the scalar variance.

In the non-nested case, Z will have no simple structure. It will be a horizontal concatenation of Z= [Z_1, Z_2] where Z_1 is the model matrix of the random effects for the students and Z_2 is the model matrix of the random effects for the teachers. I think in Z_1, there will be covariances between students who shared the same teacher, but it will not be bllock-diagonal. Let me think just about Z_1 and the corresponding part of D_1 for just a moment. The diagonal elements of the matrix V formed from Z_1 and D_1 will be larger in some places reflecting the multiple students that shared that teacher. 

I *think* in some hand calcs I am looking at on my notes here, that would increase the var(y) to some extent and maybe why you see the larger variance in the non-nested case.

In any event, I am recommending that you maybe do these same hand calcs on your own and break this down to see why the variances would be different. I have done this many, many times and while tedious, it has always led to an answer in regards to this exact question.



-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Stuart Luppescu
Sent: Tuesday, March 09, 2010 3:09 PM
To: ONKELINX, Thierry
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Size/metric of variance components in lme and lmer

On Tue, 2010-03-09 at 10:16 +0100, ONKELINX, Thierry wrote:
> Dear Stuart,
> 
> I think that the "extra" variance is substracted from the fixed
> effects. Which indicates that some of the information in your fixed
> effects was due to the levels of tid.
> 
> But to make a fair comparison you should run both models with lmer.
> And then compare both the random effects variances and the fixed
> effect estimates.

OK. I copied function call from the cross-classified model with lmer and
removed the second random effect and reran it. Here are the random
effects tables:

Nested model:
   Data: all.subj 
     AIC     BIC   logLik deviance REMLdev
 3448318 3449229 -1724083  3448166 3448707
Random effects:
 Groups   Name        Variance Std.Dev.
 sid      (Intercept) 0.77403  0.87979 
 Residual             0.85746  0.92599 
Number of obs: 1185094, groups: sid, 122897

Total variance:  1.63
--------------------------------------------------

Cross-classified model:
   Data: all.subj 
     AIC     BIC   logLik deviance REMLdev
 3236856 3237779 -1618351  3236702 3237217
Random effects:
 Groups   Name        Variance Std.Dev.
 sid      (Intercept) 0.75066  0.86641 
 tid      (Intercept) 0.39171  0.62587 
 Residual             0.68583  0.82815 
Number of obs: 1185094, groups: sid, 122897; tid, 8939

Total variance: 1.83

Could some of the difference be due to covariance between the random
effects?


-- 
Stuart Luppescu <slu at ccsr.uchicago.edu>
University of Chicago

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bates at stat.wisc.edu  Tue Mar  9 23:05:06 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 9 Mar 2010 16:05:06 -0600
Subject: [R-sig-ME] number of levels of grouping factor == number of
	observations
Message-ID: <40e66e0b1003091405v7561f54dx243f2b7449aa0ea2@mail.gmail.com>

For what families in a generalized linear mixed model should a
grouping factor be allowed to have as many levels as there are
observations?  Just the binomial and the poisson or everything except
the gaussian family or ...?



From guiga82 at msn.com  Tue Mar  9 23:32:31 2010
From: guiga82 at msn.com (Guilherme Mazzochini)
Date: Tue, 9 Mar 2010 22:32:31 +0000
Subject: [R-sig-ME] ANCOVA with lme4
Message-ID: <COL102-W31CBFF1C5A6ADC4EEACE3BB2340@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100309/392e3ff0/attachment.pl>

From David.Duffy at qimr.edu.au  Tue Mar  9 23:51:29 2010
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Wed, 10 Mar 2010 08:51:29 +1000 (EST)
Subject: [R-sig-ME] number of levels of grouping factor == number
 ofobservations
In-Reply-To: <40e66e0b1003091405v7561f54dx243f2b7449aa0ea2@mail.gmail.com>
References: <40e66e0b1003091405v7561f54dx243f2b7449aa0ea2@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1003100829020.18948@orpheus.qimr.edu.au>

On Tue, 9 Mar 2010, Douglas Bates wrote:

> For what families in a generalized linear mixed model should a
> grouping factor be allowed to have as many levels as there are
> observations?  Just the binomial and the poisson or everything except
> the gaussian family or ...?

It has to be all families.  As someone pointed out earlier, pedigreemm 
won't fit a simple univariate animal LMM unless this is allowed, and if 
one wishes to also estimate biometrical dominance, epistatic terms, 
assortment etc, then one has identified models with 2,3... random effects 
per individual, providing the data is adequate (that is the appropriate 
types of relationships are observed in the pedigrees).  For example, if 
one has pairs of identical twins, and ordinary siblings pairs in the data, 
there are two intraclass correlations which can be used for the 
decomposition into additive and dominance genetic variances rMZ=a+d, 
rSS=0.5*a+0.25*d (obviously the range of allowable r's is bounded).

Cheers, David DUffy.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From bolker at ufl.edu  Wed Mar 10 01:17:23 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 09 Mar 2010 19:17:23 -0500
Subject: [R-sig-ME] Random intercept and slope model with lmer
In-Reply-To: <4B96C032.5070008@gmail.com>
References: <4B963616.7060207@gmail.com> <4B9660EB.50300@ufl.edu>
	<4B96C032.5070008@gmail.com>
Message-ID: <4B96E513.5070803@ufl.edu>

  [I am taking the liberty of forwarding back to r-sig-mixed-models ...
you may feel this is 'too basic', but (as I always tell my classes)
there are probably quite a few people lurking on the list who wouldn't
mind knowing the answers -- or at least knowing my answers (which may
not be "the" answers.]

  The standard deviations of the random effects are interpretable on the
same scale as the corresponding fixed effects, and hence directly
comparable.  For example, your intercept is approx. 43 (in whatever
units); the standard deviation of the variation in intercepts among
localities (?) is 47; and the standard deviation of the residual
variation among observations is 21.  Hence, while the average value at
time=0 is strongly different from zero (t-score approx. 7), this
difference from zero is quite a bit smaller than the variation among
individual observations (think about +/- 2 std. dev.), which is in turn
smaller than the variation among localities.  The other random effect
(time|localidad) describes the variation in slope among localities (a
similar comparison to that above applies to the strongly negative
average slope with great variation in slopes among localities).

  However, there is also something a bit funny with your model, because
the correlation between the random effects is listed as being -1: the
random variation in slopes and intercepts is perfectly (negatively)
correlated.  Possibly your experimental/observational design is
insufficient (you only have an average of about 4 observations per
group); it might also help to center your time variable at the midpoint
time.

  I also think that looking at Ch. 4 of Bates's book draft
<http://lme4.r-forge.r-project.org/book/Ch4.pdf>, or at the equivalent
examples (Orthodont etc.) in PB2000, would be helpful.

 cheers
   Ben


Manuel Sp?nola wrote:
> Dear Ben,
> 
> Sorry to bother you with this again, but what do you look for at the 
> output of a mixed model in R?  I know what to do with the fixed effect, 
> but what about the random effects?:
> 
>  > modelo7 = lmer(ipa ~ time + (time | localidad), data=ipa)
>  > summary(modelo7)
> Linear mixed model fit by REML
> Formula: ipa ~ time + (time | localidad)
>    Data: ipa
>   AIC  BIC logLik deviance REMLdev
>  1917 1937 -952.4     1913    1905
> Random effects:
>  Groups    Name        Variance Std.Dev. Corr  
>  localidad (Intercept) 2232.31  47.247         
>            time         545.97  23.366   -1.000
>  Residual               450.92  21.235         
> Number of obs: 196, groups: localidad, 49
> 
> Fixed effects:
>             Estimate Std. Error t value
> (Intercept)   42.852      6.918   6.194
> time         -19.746      3.603  -5.480
> 
> Correlation of Fixed Effects:
>      (Intr)
> time -0.904
> 
> Thank you very much in advance.
> Best,
> 
> Manuel
> 
> 
> Ben Bolker wrote:
>> Manuel Sp?nola wrote:
>>   
>>> Dear Ben,
>>>
>>> I am trying to fit a random intercept and slope model with lme4 using 
>>> function lmer.
>>> Is my formulation correct?
>>>
>>>  > names(ipa)
>>> [1] "localidad" "time"    "ipa"
>>>
>>>  > modelo7 = lmer(ipa ~ time + (time | localidad), data=ipa)
>>>
>>> Thank you very much in advance.
>>> Best,
>>>
>>> Manuel
>>>
>>>     
>>   That looks reasonable.
>>   See
>>
>> http://lme4.r-forge.r-project.org/book/
>>
>>  especially chapter 4.
>>
>> (Why not send these questions to r-sig-mixed-models at r-project.org ?)
>>
>>   
> 
> 


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From float at lefant.net  Wed Mar 10 13:45:56 2010
From: float at lefant.net (Florian Klinglmueller)
Date: Wed, 10 Mar 2010 13:45:56 +0100
Subject: [R-sig-ME] problem with estimation of individual and interaction
 term with small residual variance
Message-ID: <4B979484.5060404@lefant.net>

dear list,

i have a problem with estimating the variance components of the 
following model:

i have 10 animals, from each of which 4 different tissue preparations 
are measured in replicates of 5. i'm interested in testing if there are 
any differences between the 4 preparations.
so i have a fixed effect for the preparation, then a random effect for 
the individual and i'd like to include a random interaction term since 
there might be slight differences in how the preparations are done from 
each animal. this leads me to the model:

y(ijk) = 1 + x(i) + z(j) + z(ij) + e(ijk)

where y(ijk) is the measurement from each of the samples, x(i) is the 
fixed effect for the 4 preparations, z(j) is the individual random 
effect, z(ij) is the interaction random effect of animal and preparation 
and finally e(ijk) the residual.

i want to estimate the variances of z(j), z(ij) and e(ijk).

i did a little simulation study (see code below) over several scenarios 
for the different variance components. if i set the residual standard 
error to a very small value (~0.01) keeping individual and interaction 
variance at one, i observe is that the individual effect is 
underestimated as being close to zero (mean sd for z(ij) estimate over 
1000 simulations: .01), although it should be 1. for se=0 i get false 
convergence, however not for small values. consequently the estimates 
are negatively biased, with the amount of bias dependent on the amount 
of residual standard deviation. This also doesn't get better if i 
increase the sample sizes.

so my question is: is this a numerical problem or do i have misspecified 
something?

thanks and regards
florian
 
--- Simulation Code -----

sim = function(rsd){
    sb = 1 # sd of individual random effect
    sg = 1 # sd of interaction random effect
    se = rsd  # residual standard deviation
    a = 1:4 # preparation fixed effecs
    ia = factor(rep(1:4,each=10*5)) # dummy variable for preparation
    ib = factor(rep(1:10,each=5,4))  # dummy variable for individual
    y = a[ia]+rnorm(10,0,sb)[ib] +rnorm(4*10,0,sg)[ia:ib]+rnorm(4*10*5,0,se)

    lmer(y~1+ia+(1|ib)+(1|ia:ib))
}

## 1000 runs of the simulation
foo <- replicate(1000,attr(VarCorr(sim(2))[[2]],'stddev'))



From walmeszeviani at yahoo.com.br  Wed Mar 10 14:52:16 2010
From: walmeszeviani at yahoo.com.br (walmes zeviani)
Date: Wed, 10 Mar 2010 05:52:16 -0800 (PST)
Subject: [R-sig-ME] Res: problem with estimation of individual and
	interaction term with small residual variance
In-Reply-To: <4B979484.5060404@lefant.net>
References: <4B979484.5060404@lefant.net>
Message-ID: <162825.90000.qm@web111702.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100310/f2a88b73/attachment.pl>

From Eli.Kvingedal at nina.no  Wed Mar 10 15:07:58 2010
From: Eli.Kvingedal at nina.no (Kvingedal, Eli)
Date: Wed, 10 Mar 2010 14:07:58 +0000
Subject: [R-sig-ME] mixed effects models and pseudo replication
Message-ID: <B9DC40CECBB1E4439A25B59A2D6A6B030439A6@NINSRV05.nina.no>

Hi, 

I am analysing effects of local population density on fish performance (e.g. weight). My dataset is based on fish sampled from different sites (17 stations) and in addition to measures on individual performance, I have information on age (0 and 1). On site level, I have information on fish densities for both age groups. I am interesting in estimating the effects of fish density on performance and particularly interested in determining possible differences between age groups in the density response. 

Traditionally, these kind of data are analysed based on mean values (ancovas). However, based on mixed effects model, the among individual variance will be included in the analysis and not just averaged out. I started by using lmer (lme4 package), but realizing that the variance is increasing with density, I switched to lme (nlme package) and applied variance structures. 

My starting model is thus: 

m1 <- lme(weight ~ age*density0 + age*density1, random = ~1|station, weights=....) 

with station and age as factors.  

Now, my issue is pseudo-replication. The summary table shows that the factors age and age*density have very high degrees of freedom (~700) and accordingly low p-values. It seems to me like age and the interactions between age and density are analysed as if the samples were independent, and if so, it means pseudo-replication, doesn't it? 

If I set up an alternative random structure allowing for random variance between age classes within station: 
m2 <- lme(weight ~ age*density0 + age*density1, random = ~1|station/age, weights=....) 

the summary table is more like I think it should be: 14 df for all fixed effects parameters and interactions, and the p-values seem more realistic.  

When comparing m1 and m2 (REML estimation), however, m2 do not provide better fit, and based on literature (e.g. Zuur et al. 2009), then I should use m1. 

Testing the significance of the interaction terms by model comparisons (which is what I do to find the optimal model), the significance levels of the likelihood ratio test for specific interaction terms are equivalent whether I use station or station/age as random factors. Which is sort of comforting. 

So, my question is, do I really control for pseudo-replication in the estimation of all fixed effects and interactions when using m1? If so, why these high dfs in the summary table?? 

I would really appreciate if someone could enlighten me! 

Regards, 

Eli 


________________________________________________________________

Eli Kvingedal
PhD Student

Norwegian Institute for Nature Research - NINA
Postal address: NO-7485 Trondheim, NORWAY
Delivery/Visiting address: Tungasletta 2, NO-7047 Trondheim, NORWAY
Phone: +47 73 80 14 00 * Fax: +47 73 80 14 01 * www.nina.no



From dhsu2 at uw.edu  Wed Mar 10 20:17:58 2010
From: dhsu2 at uw.edu (David Hsu)
Date: Wed, 10 Mar 2010 11:17:58 -0800
Subject: [R-sig-ME] Options for prediction from lmer
Message-ID: <8e8b187b1003101117n27a82211w11ca67e1fd4ccf2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100310/118cf16b/attachment.pl>

From Thierry.ONKELINX at inbo.be  Thu Mar 11 11:04:01 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 11 Mar 2010 11:04:01 +0100
Subject: [R-sig-ME] mixed effects models and pseudo replication
In-Reply-To: <B9DC40CECBB1E4439A25B59A2D6A6B030439A6@NINSRV05.nina.no>
References: <B9DC40CECBB1E4439A25B59A2D6A6B030439A6@NINSRV05.nina.no>
Message-ID: <2E9C414912813E4EB981326983E0A104070E5706@inboexch.inbo.be>

Dear Eli,

I find it strange that the summary tables of the models yield different
df for the fixed effects. Can you provide us with those summaries?

HTH,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens 
> Kvingedal, Eli
> Verzonden: woensdag 10 maart 2010 15:08
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] mixed effects models and pseudo replication
> 
> Hi, 
> 
> I am analysing effects of local population density on fish 
> performance (e.g. weight). My dataset is based on fish 
> sampled from different sites (17 stations) and in addition to 
> measures on individual performance, I have information on age 
> (0 and 1). On site level, I have information on fish 
> densities for both age groups. I am interesting in estimating 
> the effects of fish density on performance and particularly 
> interested in determining possible differences between age 
> groups in the density response. 
> 
> Traditionally, these kind of data are analysed based on mean 
> values (ancovas). However, based on mixed effects model, the 
> among individual variance will be included in the analysis 
> and not just averaged out. I started by using lmer (lme4 
> package), but realizing that the variance is increasing with 
> density, I switched to lme (nlme package) and applied
> variance structures. 
> 
> My starting model is thus: 
> 
> m1 <- lme(weight ~ age*density0 + age*density1, random = 
> ~1|station, weights=....) 
> 
> with station and age as factors.  
> 
> Now, my issue is pseudo-replication. The summary table shows 
> that the factors age and age*density have very high degrees 
> of freedom (~700) and accordingly low p-values. It seems to 
> me like age and the interactions between age and density are 
> analysed as if the samples were independent, and if so, it 
> means pseudo-replication, doesn't it? 
> 
> If I set up an alternative random structure allowing for 
> random variance between age classes within station: 
> m2 <- lme(weight ~ age*density0 + age*density1, random = 
> ~1|station/age, weights=....) 
> 
> the summary table is more like I think it should be: 14 df 
> for all fixed effects parameters and interactions, and the 
> p-values seem more realistic.  
> 
> When comparing m1 and m2 (REML estimation), however, m2 do 
> not provide better fit, and based on literature (e.g. Zuur et 
> al. 2009), then I should use m1. 
> 
> Testing the significance of the interaction terms by model 
> comparisons (which is what I do to find the optimal model), 
> the significance levels of the likelihood ratio test for 
> specific interaction terms are equivalent whether I use
> station or station/age as random factors. Which is sort of 
> comforting. 
> 
> So, my question is, do I really control for 
> pseudo-replication in the estimation of all fixed effects and 
> interactions when using m1? If so, why these high dfs in the 
> summary table?? 
> 
> I would really appreciate if someone could enlighten me! 
> 
> Regards, 
> 
> Eli 
> 
> 
> ________________________________________________________________
> 
> Eli Kvingedal
> PhD Student
> 
> Norwegian Institute for Nature Research - NINA Postal
> address: NO-7485 Trondheim, NORWAY Delivery/Visiting address: 
> Tungasletta 2, NO-7047 Trondheim, NORWAY
> Phone: +47 73 80 14 00 * Fax: +47 73 80 14 01 * www.nina.no
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From Eli.Kvingedal at nina.no  Thu Mar 11 12:15:41 2010
From: Eli.Kvingedal at nina.no (Kvingedal, Eli)
Date: Thu, 11 Mar 2010 11:15:41 +0000
Subject: [R-sig-ME] mixed effects models and pseudo replication
In-Reply-To: <2E9C414912813E4EB981326983E0A104070E5706@inboexch.inbo.be>
References: <B9DC40CECBB1E4439A25B59A2D6A6B030439A6@NINSRV05.nina.no>
	<2E9C414912813E4EB981326983E0A104070E5706@inboexch.inbo.be>
Message-ID: <B9DC40CECBB1E4439A25B59A2D6A6B03060221@NINSRV05.nina.no>

Dear Thierry, 

Here are the summary tables for the alternative models: 

> M1 <- lme(weight ~ age*density0 + age*density1, random=~1|station, weights=varComb(varIdent(form=~1|age), varPower(form=~density0|age)), method="ML")

> summary(M1)
Linear mixed-effects model fit by maximum likelihood
 Data: NULL 
       AIC      BIC    logLik
  3061.287 3111.566 -1519.643

Random effects:
 Formula: ~1 | station
        (Intercept)  Residual
StdDev:   0.2394472 0.3304975

Combination of variance functions: 
 Structure: Different standard deviations per stratum
 Formula: ~1 | age 
 Parameter estimates:
       0        1 
 1.00000 18.32243 
 Structure: Power of variance covariate, different strata
 Formula: ~density0 | age 
 Parameter estimates:
          0           1 
 0.12277823 -0.01863642 
Fixed effects: weight ~ age * density0 + age * density1 
                  Value Std.Error  DF   t-value p-value
(Intercept)    2.548689 0.1280585 694 19.902539  0.0000
age1          12.094327 0.5960983 694 20.289150  0.0000
density0      -0.002892 0.0007015  14 -4.122892  0.0010
density1       0.002138 0.0058263  14  0.366970  0.7191
age1:density0 -0.009194 0.0029657 694 -3.100081  0.0020
age1:density1  0.053147 0.0252106 694  2.108131  0.0354
 Correlation: 
              (Intr) age1   dnsty0 dnsty1 ag1:d0
age1          -0.054                            
density0       0.065 -0.006                     
density1      -0.697  0.042 -0.639              
age1:density0 -0.005  0.212 -0.056  0.035       
age1:density1  0.044 -0.743  0.035 -0.060 -0.722

Standardized Within-Group Residuals:
       Min         Q1        Med         Q3        Max 
-2.4011664 -0.6931402 -0.1359044  0.6256529  3.6626548 

Number of Observations: 714
Number of Groups: 17


> summary(M2)
Linear mixed-effects model fit by maximum likelihood
 Data: NULL 
       AIC      BIC    logLik
  3063.287 3118.137 -1519.643

Random effects:
 Formula: ~1 | station
        (Intercept)
StdDev:   0.2394471

 Formula: ~1 | age %in% station
         (Intercept)  Residual
StdDev: 9.335646e-05 0.3304975

Combination of variance functions: 
 Structure: Different standard deviations per stratum
 Formula: ~1 | age 
 Parameter estimates:
       0        1 
 1.00000 18.32243 
 Structure: Power of variance covariate, different strata
 Formula: ~density.trout0 | age 
 Parameter estimates:
          0           1 
 0.12277827 -0.01863644 
Fixed effects: weight ~ age * density0 + age * density1 
                  Value Std.Error  DF   t-value p-value
(Intercept)    2.548689 0.1280584 680 19.902548  0.0000
age1          12.094327 0.5960982  14 20.289153  0.0000
density0      -0.002892 0.0007015  14 -4.122894  0.0010
density1       0.002138 0.0058263  14  0.366970  0.7191
age1:density0 -0.009194 0.0029657  14 -3.100082  0.0078
age1:density1  0.053147 0.0252106  14  2.108131  0.0535
 Correlation: 
              (Intr) age1   dnsty0 dnsty1 ag1:d0
age1          -0.054                            
density0       0.065 -0.006                     
density1      -0.697  0.042 -0.639              
age1:density0 -0.005  0.212 -0.056  0.035       
age1:density1  0.044 -0.743  0.035 -0.060 -0.722

Standardized Within-Group Residuals:
       Min         Q1        Med         Q3        Max 
-2.4011661 -0.6931402 -0.1359044  0.6256530  3.6626539 

Number of Observations: 714
Number of Groups: 
         station age %in% station 
              17               34




Thank you for considering my case!

Eli


-----Original Message-----
From: ONKELINX, Thierry [mailto:Thierry.ONKELINX at inbo.be] 
Sent: 11. mars 2010 11:04
To: Kvingedal, Eli; r-sig-mixed-models at r-project.org
Subject: RE: [R-sig-ME] mixed effects models and pseudo replication

Dear Eli,

I find it strange that the summary tables of the models yield different
df for the fixed effects. Can you provide us with those summaries?

HTH,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens 
> Kvingedal, Eli
> Verzonden: woensdag 10 maart 2010 15:08
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] mixed effects models and pseudo replication
> 
> Hi, 
> 
> I am analysing effects of local population density on fish 
> performance (e.g. weight). My dataset is based on fish 
> sampled from different sites (17 stations) and in addition to 
> measures on individual performance, I have information on age 
> (0 and 1). On site level, I have information on fish 
> densities for both age groups. I am interesting in estimating 
> the effects of fish density on performance and particularly 
> interested in determining possible differences between age 
> groups in the density response. 
> 
> Traditionally, these kind of data are analysed based on mean 
> values (ancovas). However, based on mixed effects model, the 
> among individual variance will be included in the analysis 
> and not just averaged out. I started by using lmer (lme4 
> package), but realizing that the variance is increasing with 
> density, I switched to lme (nlme package) and applied 
> variance structures. 
> 
> My starting model is thus: 
> 
> m1 <- lme(weight ~ age*density0 + age*density1, random = 
> ~1|station, weights=....) 
> 
> with station and age as factors.  
> 
> Now, my issue is pseudo-replication. The summary table shows 
> that the factors age and age*density have very high degrees 
> of freedom (~700) and accordingly low p-values. It seems to 
> me like age and the interactions between age and density are 
> analysed as if the samples were independent, and if so, it 
> means pseudo-replication, doesn't it? 
> 
> If I set up an alternative random structure allowing for 
> random variance between age classes within station: 
> m2 <- lme(weight ~ age*density0 + age*density1, random = 
> ~1|station/age, weights=....) 
> 
> the summary table is more like I think it should be: 14 df 
> for all fixed effects parameters and interactions, and the 
> p-values seem more realistic.  
> 
> When comparing m1 and m2 (REML estimation), however, m2 do 
> not provide better fit, and based on literature (e.g. Zuur et 
> al. 2009), then I should use m1. 
> 
> Testing the significance of the interaction terms by model 
> comparisons (which is what I do to find the optimal model), 
> the significance levels of the likelihood ratio test for 
> specific interaction terms are equivalent whether I use 
> station or station/age as random factors. Which is sort of 
> comforting. 
> 
> So, my question is, do I really control for 
> pseudo-replication in the estimation of all fixed effects and 
> interactions when using m1? If so, why these high dfs in the 
> summary table?? 
> 
> I would really appreciate if someone could enlighten me! 
> 
> Regards, 
> 
> Eli 
> 
> 
> ________________________________________________________________
> 
> Eli Kvingedal
> PhD Student
> 
> Norwegian Institute for Nature Research - NINA Postal 
> address: NO-7485 Trondheim, NORWAY Delivery/Visiting address: 
> Tungasletta 2, NO-7047 Trondheim, NORWAY
> Phone: +47 73 80 14 00 * Fax: +47 73 80 14 01 * www.nina.no
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From lucianolasala at yahoo.com.ar  Thu Mar 11 14:32:17 2010
From: lucianolasala at yahoo.com.ar (Luciano La Sala)
Date: Thu, 11 Mar 2010 10:32:17 -0300
Subject: [R-sig-ME] Test of random effect in lme4
Message-ID: <5AFF89011FC0438A8483157147645850@Negro1>

Dear R-list members, 

I am running mixed models using lme4 package. In model selection, terms were
eliminated from a maximum model (with random intercept) to achieve a simpler
model that retained only the significant main effects and interactions,
using the Akaike information criterion. My final model includes three fixed
factors plus random intercept. Then I perform a likelihood ratio test to
test the significance of the random term. However, because when testing on
the boundary the p-value from the table is incorrect, I followed Zuur et al
(2009) to get the corrected p-value by dividing the p value obtained by 2.
Briefly, my best fit model consists of three main effects: Year (2006,
2007), Hatching Order (1st, 2nd, 3rd) and Sibling Competence
(Present/Absent) plus NestID as random intercept. The modelled outcome is
level of plasma proteins (continuous). 

I test the random effect (Nest ID), which has variance 2.1795e-16 and Std.
Dev. 1.4763e-08 (see output). LRT yields a p-value of 0.00031 (0.00015 after
dividing it by 2 as suggested). This would mean that adding a random effect
Nest ID to the model is a significant improvement. However, random effect
variance is near zero, which would indicate otherwise. 
In support of the non-significant random effect I think, coefficients and
standard error are exactly the same for models with and without the RE, as
seen in the outputs. 

Q 1. In your opinion, should I trust this LRT with a small p-value and leave
the random effect in my model, or follow the parsimony principle and
eliminated it? 

Q 2. Is it possible, under certain conditions, to have a random effect with
such low variance and still obtain a LTR p-value indicating that model fit
is improved by it?    

Outputs for both models, with and without random effect, followed by LRT
output: 

MIXED MODEL 

> full.1 <- lmer(TP10Diff~HatchOrder+Year+SibComp+(1|NestID))

Linear mixed model fit by REML 

   AIC   BIC logLik deviance REMLdev
 739.4 758.5 -362.7    738.5   725.4

Random effects:
 Groups   Name        Variance   Std.Dev.  
 NestID   (Intercept) 2.1795e-16 1.4763e-08
 Residual             4.4754e+01 6.6898e+00

Number of obs: 112, groups: NestID, 81

Fixed effects:
                 Estimate Std. Error t value
(Intercept)         6.959      1.078   6.453
HatchOrderSecond   -1.130      2.472  -0.457
HatchOrderThird   -12.483      3.514  -3.552
Year2007            7.157      1.299   5.509
SibCompPresente    -2.120      2.641  -0.803

Correlation of Fixed Effects:
            (Intr) HtchOS HtchOT Yr2007
HtchOrdrScn -0.219                     
HtchOrdrThr -0.154  0.677              
Year2007    -0.676  0.016  0.020       
SibCmpPrsnt  0.019 -0.816 -0.738 -0.079


MODEL WITHOUT RANDOM EFFECT 

> null.1 <- lm(TP10Diff~HatchOrder+Year+SibComp)

Residuals:
     Min       1Q   Median       3Q      Max 
-16.4597  -3.8812  -0.2394   4.1472  17.4203 

Coefficients:
                 Estimate Std. Error t value Pr(>|t|)    
(Intercept)         6.959      1.078   6.453 3.28e-09 ***
HatchOrderSecond   -1.130      2.472  -0.457 0.648649    
HatchOrderThird   -12.483      3.514  -3.552 0.000569 ***
Year2007            7.157      1.299   5.509 2.51e-07 ***
SibCompPresente    -2.120      2.641  -0.803 0.424037    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Residual standard error: 6.69 on 107 degrees of freedom
  (155 observations deleted due to missingness)
Multiple R-squared: 0.3771,     Adjusted R-squared: 0.3539 
F-statistic:  16.2 on 4 and 107 DF,  p-value: 2.117e-10 


TEST OF SIGNIFICANCE FOR RANDOM TERM

> as.numeric(2*(logLik(full.1)-logLik(null.1)))
[1] 13.01191

> 0.5*(1-pchisq(13.01191, 1))
[1] 0.0001547580


Thank you very much for previous assistance!
Luciano



From bolker at ufl.edu  Thu Mar 11 15:50:08 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 11 Mar 2010 09:50:08 -0500
Subject: [R-sig-ME] Test of random effect in lme4
In-Reply-To: <5AFF89011FC0438A8483157147645850@Negro1>
References: <5AFF89011FC0438A8483157147645850@Negro1>
Message-ID: <4B990320.8030507@ufl.edu>

Luciano La Sala wrote:
> Dear R-list members, 
> 
> I am running mixed models using lme4 package. In model selection, terms were
> eliminated from a maximum model (with random intercept) to achieve a simpler
> model that retained only the significant main effects and interactions,
> using the Akaike information criterion. My final model includes three fixed
> factors plus random intercept. Then I perform a likelihood ratio test to
> test the significance of the random term. 

  In general testing significance of components in a model *after* model
selection is dubious ...  I agree with most of what Zuur et al say, but
I am only comfortable with stepwise procedures as a relatively necessary
evil for eliminating non-significant interaction terms to simplify
interpretation of the remaining model.


> However, because when testing on
> the boundary the p-value from the table is incorrect, I followed Zuur et al
> (2009) to get the corrected p-value by dividing the p value obtained by 2.
> Briefly, my best fit model consists of three main effects: Year (2006,
> 2007), Hatching Order (1st, 2nd, 3rd) and Sibling Competence
> (Present/Absent) plus NestID as random intercept. The modelled outcome is
> level of plasma proteins (continuous). 
> 
> I test the random effect (Nest ID), which has variance 2.1795e-16 and Std.
> Dev. 1.4763e-08 (see output). LRT yields a p-value of 0.00031 (0.00015 after
> dividing it by 2 as suggested). This would mean that adding a random effect
> Nest ID to the model is a significant improvement. However, random effect
> variance is near zero, which would indicate otherwise. 
> In support of the non-significant random effect I think, coefficients and
> standard error are exactly the same for models with and without the RE, as
> seen in the outputs. 

  Your main problem is that the log-likelihoods returned by lm and lmer
are **NOT COMPARABLE**.  Sooner or later there should probably be a
warning to that effect somewhere in the documentation ...

  You may be able to use the RLRsim package to solve your problem.

> 
> Q 1. In your opinion, should I trust this LRT with a small p-value and leave
> the random effect in my model, or follow the parsimony principle and
> eliminated it? 

   I would leave it in whether or not it is significant (and it's
probably not).  Note that as expected all the fixed effect parameters
are estimated identically under lmer and lm ... the reason to drop it
would be to have the convenience of not dealing with mixed effects at all.

> 
> Q 2. Is it possible, under certain conditions, to have a random effect with
> such low variance and still obtain a LTR p-value indicating that model fit
> is improved by it?    

  Unlikely at best, unless your response variable has a very small
magnitude (e.g., you are comparing differences hummingbird weights
across different diet treatments, and measuring them in units of petagrams)

> 
> Outputs for both models, with and without random effect, followed by LRT
> output: 
> 
> MIXED MODEL 
> 
>> full.1 <- lmer(TP10Diff~HatchOrder+Year+SibComp+(1|NestID))
> 
> Linear mixed model fit by REML 
> 
>    AIC   BIC logLik deviance REMLdev
>  739.4 758.5 -362.7    738.5   725.4
> 
> Random effects:
>  Groups   Name        Variance   Std.Dev.  
>  NestID   (Intercept) 2.1795e-16 1.4763e-08
>  Residual             4.4754e+01 6.6898e+00
> 
> Number of obs: 112, groups: NestID, 81
> 
> Fixed effects:
>                  Estimate Std. Error t value
> (Intercept)         6.959      1.078   6.453
> HatchOrderSecond   -1.130      2.472  -0.457
> HatchOrderThird   -12.483      3.514  -3.552
> Year2007            7.157      1.299   5.509
> SibCompPresente    -2.120      2.641  -0.803
> 
> Correlation of Fixed Effects:
>             (Intr) HtchOS HtchOT Yr2007
> HtchOrdrScn -0.219                     
> HtchOrdrThr -0.154  0.677              
> Year2007    -0.676  0.016  0.020       
> SibCmpPrsnt  0.019 -0.816 -0.738 -0.079
> 
> 
> MODEL WITHOUT RANDOM EFFECT 
> 
>> null.1 <- lm(TP10Diff~HatchOrder+Year+SibComp)
> 
> Residuals:
>      Min       1Q   Median       3Q      Max 
> -16.4597  -3.8812  -0.2394   4.1472  17.4203 
> 
> Coefficients:
>                  Estimate Std. Error t value Pr(>|t|)    
> (Intercept)         6.959      1.078   6.453 3.28e-09 ***
> HatchOrderSecond   -1.130      2.472  -0.457 0.648649    
> HatchOrderThird   -12.483      3.514  -3.552 0.000569 ***
> Year2007            7.157      1.299   5.509 2.51e-07 ***
> SibCompPresente    -2.120      2.641  -0.803 0.424037    
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
> 
> Residual standard error: 6.69 on 107 degrees of freedom
>   (155 observations deleted due to missingness)
> Multiple R-squared: 0.3771,     Adjusted R-squared: 0.3539 
> F-statistic:  16.2 on 4 and 107 DF,  p-value: 2.117e-10 
> 
> 
> TEST OF SIGNIFICANCE FOR RANDOM TERM
> 
>> as.numeric(2*(logLik(full.1)-logLik(null.1)))
> [1] 13.01191
> 
>> 0.5*(1-pchisq(13.01191, 1))
> [1] 0.0001547580
> 
> 
> Thank you very much for previous assistance!
> Luciano
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From anna.renwick at bto.org  Thu Mar 11 16:30:31 2010
From: anna.renwick at bto.org (Anna Renwick)
Date: Thu, 11 Mar 2010 15:30:31 -0000
Subject: [R-sig-ME] Test of random effect in lme4
In-Reply-To: <4B990320.8030507@ufl.edu>
References: <5AFF89011FC0438A8483157147645850@Negro1>
	<4B990320.8030507@ufl.edu>
Message-ID: <234EBAC6A6054AC1941C23CE6CF1CE64@btodomain.bto.org>

There has been a lot of discussion previously whether we should remove
random effects based on LRT. The reason is that you added the random effect
based on your study design and whether it is significant or not it should
remain in there. I am not sure there is any definite rule and maybe it
depends on your study and personal view point.

Dr Anna R. Renwick
Research Ecologist
British Trust for Ornithology, 
The Nunnery, 
Thetford, 
Norfolk, 
IP24 2PU, 
UK
Tel: +44 (0)1842 750050; Fax: +44 (0)1842 750030 

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ben Bolker
Sent: 11 March 2010 14:50
To: Luciano La Sala
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Test of random effect in lme4

Luciano La Sala wrote:
> Dear R-list members, 
> 
> I am running mixed models using lme4 package. In model selection, terms
were
> eliminated from a maximum model (with random intercept) to achieve a
simpler
> model that retained only the significant main effects and interactions,
> using the Akaike information criterion. My final model includes three
fixed
> factors plus random intercept. Then I perform a likelihood ratio test to
> test the significance of the random term. 

  In general testing significance of components in a model *after* model
selection is dubious ...  I agree with most of what Zuur et al say, but
I am only comfortable with stepwise procedures as a relatively necessary
evil for eliminating non-significant interaction terms to simplify
interpretation of the remaining model.


> However, because when testing on
> the boundary the p-value from the table is incorrect, I followed Zuur et
al
> (2009) to get the corrected p-value by dividing the p value obtained by 2.
> Briefly, my best fit model consists of three main effects: Year (2006,
> 2007), Hatching Order (1st, 2nd, 3rd) and Sibling Competence
> (Present/Absent) plus NestID as random intercept. The modelled outcome is
> level of plasma proteins (continuous). 
> 
> I test the random effect (Nest ID), which has variance 2.1795e-16 and Std.
> Dev. 1.4763e-08 (see output). LRT yields a p-value of 0.00031 (0.00015
after
> dividing it by 2 as suggested). This would mean that adding a random
effect
> Nest ID to the model is a significant improvement. However, random effect
> variance is near zero, which would indicate otherwise. 
> In support of the non-significant random effect I think, coefficients and
> standard error are exactly the same for models with and without the RE, as
> seen in the outputs. 

  Your main problem is that the log-likelihoods returned by lm and lmer
are **NOT COMPARABLE**.  Sooner or later there should probably be a
warning to that effect somewhere in the documentation ...

  You may be able to use the RLRsim package to solve your problem.

> 
> Q 1. In your opinion, should I trust this LRT with a small p-value and
leave
> the random effect in my model, or follow the parsimony principle and
> eliminated it? 

   I would leave it in whether or not it is significant (and it's
probably not).  Note that as expected all the fixed effect parameters
are estimated identically under lmer and lm ... the reason to drop it
would be to have the convenience of not dealing with mixed effects at all.

> 
> Q 2. Is it possible, under certain conditions, to have a random effect
with
> such low variance and still obtain a LTR p-value indicating that model fit
> is improved by it?    

  Unlikely at best, unless your response variable has a very small
magnitude (e.g., you are comparing differences hummingbird weights
across different diet treatments, and measuring them in units of petagrams)

> 
> Outputs for both models, with and without random effect, followed by LRT
> output: 
> 
> MIXED MODEL 
> 
>> full.1 <- lmer(TP10Diff~HatchOrder+Year+SibComp+(1|NestID))
> 
> Linear mixed model fit by REML 
> 
>    AIC   BIC logLik deviance REMLdev
>  739.4 758.5 -362.7    738.5   725.4
> 
> Random effects:
>  Groups   Name        Variance   Std.Dev.  
>  NestID   (Intercept) 2.1795e-16 1.4763e-08
>  Residual             4.4754e+01 6.6898e+00
> 
> Number of obs: 112, groups: NestID, 81
> 
> Fixed effects:
>                  Estimate Std. Error t value
> (Intercept)         6.959      1.078   6.453
> HatchOrderSecond   -1.130      2.472  -0.457
> HatchOrderThird   -12.483      3.514  -3.552
> Year2007            7.157      1.299   5.509
> SibCompPresente    -2.120      2.641  -0.803
> 
> Correlation of Fixed Effects:
>             (Intr) HtchOS HtchOT Yr2007
> HtchOrdrScn -0.219                     
> HtchOrdrThr -0.154  0.677              
> Year2007    -0.676  0.016  0.020       
> SibCmpPrsnt  0.019 -0.816 -0.738 -0.079
> 
> 
> MODEL WITHOUT RANDOM EFFECT 
> 
>> null.1 <- lm(TP10Diff~HatchOrder+Year+SibComp)
> 
> Residuals:
>      Min       1Q   Median       3Q      Max 
> -16.4597  -3.8812  -0.2394   4.1472  17.4203 
> 
> Coefficients:
>                  Estimate Std. Error t value Pr(>|t|)    
> (Intercept)         6.959      1.078   6.453 3.28e-09 ***
> HatchOrderSecond   -1.130      2.472  -0.457 0.648649    
> HatchOrderThird   -12.483      3.514  -3.552 0.000569 ***
> Year2007            7.157      1.299   5.509 2.51e-07 ***
> SibCompPresente    -2.120      2.641  -0.803 0.424037    
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
> 
> Residual standard error: 6.69 on 107 degrees of freedom
>   (155 observations deleted due to missingness)
> Multiple R-squared: 0.3771,     Adjusted R-squared: 0.3539 
> F-statistic:  16.2 on 4 and 107 DF,  p-value: 2.117e-10 
> 
> 
> TEST OF SIGNIFICANCE FOR RANDOM TERM
> 
>> as.numeric(2*(logLik(full.1)-logLik(null.1)))
> [1] 13.01191
> 
>> 0.5*(1-pchisq(13.01191, 1))
> [1] 0.0001547580
> 
> 
> Thank you very much for previous assistance!
> Luciano
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From par.ingvarsson at emg.umu.se  Thu Mar 11 16:55:09 2010
From: par.ingvarsson at emg.umu.se (Pelle Ingvarsson)
Date: Thu, 11 Mar 2010 16:55:09 +0100
Subject: [R-sig-ME] incorporating a kinship matrix
Message-ID: <4B99125D.30608@emg.umu.se>

Hi,

I'm trying to replicate the behavior of the lmekin function from the 
kinship package with lmer. So far I have arrived at the pedigreemm 
function, but I'm still not at the point where I want to go.

My basic problem is as follows:

With lmekin I can incorporate an arbitrary kinship matrix into the 
calculations (ie. not based on a known pedigree, but estimates using 
genetic markers) , which is useful if you're working with species where 
you don't have pedigree information (which I happen to do).

The "problem" right now is that I have multiple observations from the 
same (cloned) genotype that I would like to include into my modeling 
effort. I have previously handled this by calculating BLUPs for each 
genotype and have used these BLUPs in the lmekin analyses. However, 
treating the BLUPs observed variables seems a little like cheating since 
  a potentially substantial source of variation (variation among 
replicate measures of each clone) just gets "eliminated" in the process 
of calculating the BLUPs.

However, including multiple observations of the same genotype is not 
possible in lmekin, where only a single observation is allowed per entry 
in the kinship matrix. Running a model with multiple observations per 
genotype results in:

lmekin(budset~year+site+pos,data=bs,random=~1|clone,varlist=list(2*K),rescale=TRUE)
Error in lmekin(budset ~ year + site + pos, data = bs, random = ~1 | 
clone,  :  The random effect must be 1 per subject

(note: where K is the nxn kinship matrix, where n in the number of 
observed genotypes):

I have tried to fit such a model using lmer/pedigreemm, which I hoped 
would be able to do that, but I have not succeeded yet. It appears that 
including a kinship matrix directly is not an option in pedigreemm, have 
I understood that correctly? I know I can fit a model like this using 
ASREML, but I would prefer to stick to open source software (and R) if 
possible.

Any ideas or helpful pointers would be very much appreciated.

Sincerely,

-Pelle



From anna.renwick at bto.org  Thu Mar 11 17:25:57 2010
From: anna.renwick at bto.org (Anna Renwick)
Date: Thu, 11 Mar 2010 16:25:57 -0000
Subject: [R-sig-ME] Test of random effect in lme4
In-Reply-To: <4B991424.6030605@unipr.it>
References: <5AFF89011FC0438A8483157147645850@Negro1>	<4B990320.8030507@ufl.edu>
	<234EBAC6A6054AC1941C23CE6CF1CE64@btodomain.bto.org>
	<4B991424.6030605@unipr.it>
Message-ID: <C8BE1F714A114F518D97CF7A0AA54197@btodomain.bto.org>

There is quite a bit on the message board. For example this string:
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2008q2/000743.html

Dr Anna R. Renwick
Research Ecologist
British Trust for Ornithology, 
The Nunnery, 
Thetford, 
Norfolk, 
IP24 2PU, 
UK
Tel: +44 (0)1842 750050; Fax: +44 (0)1842 750030 

-----Original Message-----
From: Stefano Leonardi [mailto:stefano.leonardi at unipr.it] 
Sent: 11 March 2010 16:03
To: Anna Renwick
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Test of random effect in lme4

On 11/03/2010 16:30, Anna Renwick wrote:
> There has been a lot of discussion previously whether we should remove
> random effects based on LRT. The reason is that you added the random
effect
> based on your study design and whether it is significant or not it should
> remain in there. I am not sure there is any definite rule and maybe it
> depends on your study and personal view point.
>
> Dr Anna R. Renwick
> Research Ecologist
> British Trust for Ornithology,
> The Nunnery,
> Thetford,
> Norfolk,
> IP24 2PU,
> UK

Can someone please give some literature references about this 
discussion. I am very interested.

According to my experience in Ecology it often happens  that someone 
needs to understand if a variable or factor is 
important/relevant/significant in determining some other variable.

I would like to understand up to which point the arbitrariness of the
experimenter is considered tolerable.

Thanks
Stefano

-- 
======================================================================
  Stefano Leonardi
  Dipartimento di Scienze Ambientali
  Universita` di Parma               E-mail:stefano.leonardi(at)unipr.it
  Viale Usberti 11a                             Phone : +39-0521-905659
  43100 PARMA  (Italy)                          Fax   : +39-0521-905402



From dhsu2 at uw.edu  Thu Mar 11 20:17:46 2010
From: dhsu2 at uw.edu (David Hsu)
Date: Thu, 11 Mar 2010 11:17:46 -0800
Subject: [R-sig-ME] Options for prediction from lmer
In-Reply-To: <8e8b187b1003101117n27a82211w11ca67e1fd4ccf2@mail.gmail.com>
References: <8e8b187b1003101117n27a82211w11ca67e1fd4ccf2@mail.gmail.com>
Message-ID: <8e8b187b1003111117p2c8d0082i2395d9dd19cffe84@mail.gmail.com>

Dear list (and especially the keepers of nlme / lme4),

To sharpen my previous post on this topic, I'd like to get predictions
and estimated errors of the predictions out of a model with correlated
random coefficients. In lmer() language, the model is written as:

y ~ x1 + x2 + (1 + x3 + x4 | group)

Q1: ?Can I get predictions and associated errors with lme()? ?If I use
lme(), I can get the predictions using predict(), but how do I get
errors on the predictions?

Q2: ?Can I?get predictions and associated errors?with lmer()? ?If I
use lmer(), I thought I could get the predictions and errors by
simulation (this is empirical Bayes, I think) by using mcmcsamp(). ?It
works for a single random coefficient, but it doesn't seem to work for
a model with multiple correlated random coefficients, giving me the
following error:

Error in .local(object, n, verbose, ...) :
??Code for non-trivial theta_T not yet written

As far as I know, this seems to be because mcmcsamp() doesn't yet
update the covariance parameter.

Any corrections, suggestions or comments would be much appreciated.

David


On Wed, Mar 10, 2010 at 11:17 AM, David Hsu <dhsu2 at uw.edu> wrote:
>
> Dear all,
> I know that the subject of a predict() function for lme4 / lmer -- or lack thereof -- has been kicked around before (I googled "lmer predict"). ?After reading all of the previous e-mails, I'd like to get feedback on the various ways that I've thought up to actually do prediction from lmer(). ?Most of the ideas are briefly sketched out below; any feedback or comments would be appreciated.
> David
>
> Problem Statement:
> After estimating my model from a given specification, I'd like to get both (a) predictions from the model and the original covariates, and (b) predictions from the same model applied to new covariates. ?In pseudocode:
> Step 1: ?Original covariates "origdat", columns "x1" ... "x4", groups indicated by "group"
> Step 2: ?Estimate model, get object "M1". ?My models are relatively simple, something like: ?M1 <- lmer(y ~ x1 + x2 + (x3 + x4 | group), data=origdat)
> Step 3: ?New covariates "newdat", with same column names as "dat", but different data (changed covariates represent a counterfactual scenario).
>
> After thinking about it, it seems like my options are:
> [Option #1] ?Write out the BLUPs and do simulations manually. ?From the M1 object I could extract the fixed effects, random effects, variance-covariance matrix, and residual sds, and so could just simulate by hand. ?In other words, write something like this:
> orig.pred <- rnorm(fixef(M1) %*% origdat + mvnorm(ranef(M1) %*% origdat[group], VarCorr(M1)), residsd).
> Then apply the same parameters to the new data:
> new.pred <- rnorm(fixef(M1) %*% newdat + mvnorm(ranef(M1) %*% newdat[group], VarCorr(M1)), residsd).
> Pros: ?Probably fast.
> Cons: ?Really messy since I'm doing a number of different models, unless I write a really clean function, and perhaps beyond my programming skills.
>
> [Option #2]??Think of some creative use of refit() and simulate() -- or other functions -- for lmer. ?The documentation for refit in lme4.pdf is pretty tempting, since it writes that "it is common to use the same model specification and covariate data on many simulated responses. ?That is, the only thing that changes between model fits is the response vector." ?However, in this case I want to keep the model specification, but change both the covariate data and get the response vector. ?I'm not sure if this is possible using lmer().
> Cons: obviously, I don't know how quite to do this yet.
>
> [Option #3] ?Just?use nlme().
> Pros: nlme() will estimate this relatively simple model, and then I can simply use the predict() function to get the predictions using the fit to the original data, and then predict(M1, newdat) to get predictions with the new data.
> Cons: nlme() is slower than lmer(), and my model already takes about 2 hours to run.
>
>
>
>
>
> --
> David Hsu
> PhD Candidate, Urban Planning
> University of Washington
> (e-mail) dhsu2 at uw.edu
>



--
David Hsu
PhD Candidate, Urban Planning
University of Washington
(e-mail) dhsu2 at uw.edu



From David.Duffy at qimr.edu.au  Thu Mar 11 22:59:08 2010
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Fri, 12 Mar 2010 07:59:08 +1000 (EST)
Subject: [R-sig-ME] incorporating a kinship matrix
In-Reply-To: <4B99125D.30608@emg.umu.se>
References: <4B99125D.30608@emg.umu.se>
Message-ID: <Pine.LNX.4.64.1003120746250.17968@orpheus.qimr.edu.au>

On Thu, 11 Mar 2010, Pelle Ingvarsson wrote:

> However, including multiple observations of the same genotype is not possible 
> in lmekin, where only a single observation is allowed per entry in the 
> kinship matrix. Running a model with multiple observations per genotype 
> results in:
>
> lmekin(budset~year+site+pos,data=bs,random=~1|clone,varlist=list(2*K),rescale=TRUE)
> Error in lmekin(budset ~ year + site + pos, data = bs, random = ~1 | clone, 
> :  The random effect must be 1 per subject
>
> (note: where K is the nxn kinship matrix, where n in the number of observed 
> genotypes):
>

One way is to include an additional "genotype" (I presume genotype 
corresponds to individual) for each of the multiple observations, and make 
the kinship unity between the repeated records.  You will then usually 
encounter an error message from lmekin, complaining that it cannot invert 
the matrix.  If this is the case, we add a ridge constant of sufficient 
size to the kinship matrix to make it invertible.  I would also run the 
analysis in WOMBAT, which is freely available (though not FLOSS) at

  http://agbu.une.edu.au/kmeyer/wombat.html

It allows arbitrary covariance matrices, repeated records, and is very fast and accurate.

Cheers, David.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From bates at stat.wisc.edu  Thu Mar 11 23:52:34 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 11 Mar 2010 16:52:34 -0600
Subject: [R-sig-ME] Options for prediction from lmer
In-Reply-To: <8e8b187b1003111117p2c8d0082i2395d9dd19cffe84@mail.gmail.com>
References: <8e8b187b1003101117n27a82211w11ca67e1fd4ccf2@mail.gmail.com>
	<8e8b187b1003111117p2c8d0082i2395d9dd19cffe84@mail.gmail.com>
Message-ID: <40e66e0b1003111452y7520f8ffye43049052098c5c@mail.gmail.com>

On Thu, Mar 11, 2010 at 1:17 PM, David Hsu <dhsu2 at uw.edu> wrote:
> Dear list (and especially the keepers of nlme / lme4),

> To sharpen my previous post on this topic, I'd like to get predictions
> and estimated errors of the predictions out of a model with correlated
> random coefficients. In lmer() language, the model is written as:

> y ~ x1 + x2 + (1 + x3 + x4 | group)

> Q1: ?Can I get predictions and associated errors with lme()? ?If I use
> lme(), I can get the predictions using predict(), but how do I get
> errors on the predictions?

First, you define them.  You are combining parameters and random
variables in your predictions and I'm not sure what it would mean to
assess the variability of those predictions.  A Bayesian may be able
to make sense of it but I can't get my head around it.

> Q2: ?Can I?get predictions and associated errors?with lmer()? ?If I
> use lmer(), I thought I could get the predictions and errors by
> simulation (this is empirical Bayes, I think) by using mcmcsamp(). ?It
> works for a single random coefficient, but it doesn't seem to work for
> a model with multiple correlated random coefficients, giving me the
> following error:

> Error in .local(object, n, verbose, ...) :
> ??Code for non-trivial theta_T not yet written

As it says, the code has not yet been written.  You may want to
consider Jarrod's MCMCglmm package instead.

> As far as I know, this seems to be because mcmcsamp() doesn't yet
> update the covariance parameter.
>
> Any corrections, suggestions or comments would be much appreciated.
>
> David
>
>
> On Wed, Mar 10, 2010 at 11:17 AM, David Hsu <dhsu2 at uw.edu> wrote:
>>
>> Dear all,
>> I know that the subject of a predict() function for lme4 / lmer -- or lack thereof -- has been kicked around before (I googled "lmer predict"). ?After reading all of the previous e-mails, I'd like to get feedback on the various ways that I've thought up to actually do prediction from lmer(). ?Most of the ideas are briefly sketched out below; any feedback or comments would be appreciated.
>> David
>>
>> Problem Statement:
>> After estimating my model from a given specification, I'd like to get both (a) predictions from the model and the original covariates, and (b) predictions from the same model applied to new covariates. ?In pseudocode:
>> Step 1: ?Original covariates "origdat", columns "x1" ... "x4", groups indicated by "group"
>> Step 2: ?Estimate model, get object "M1". ?My models are relatively simple, something like: ?M1 <- lmer(y ~ x1 + x2 + (x3 + x4 | group), data=origdat)
>> Step 3: ?New covariates "newdat", with same column names as "dat", but different data (changed covariates represent a counterfactual scenario).
>>
>> After thinking about it, it seems like my options are:
>> [Option #1] ?Write out the BLUPs and do simulations manually. ?From the M1 object I could extract the fixed effects, random effects, variance-covariance matrix, and residual sds, and so could just simulate by hand. ?In other words, write something like this:
>> orig.pred <- rnorm(fixef(M1) %*% origdat + mvnorm(ranef(M1) %*% origdat[group], VarCorr(M1)), residsd).
>> Then apply the same parameters to the new data:
>> new.pred <- rnorm(fixef(M1) %*% newdat + mvnorm(ranef(M1) %*% newdat[group], VarCorr(M1)), residsd).
>> Pros: ?Probably fast.
>> Cons: ?Really messy since I'm doing a number of different models, unless I write a really clean function, and perhaps beyond my programming skills.
>>
>> [Option #2]??Think of some creative use of refit() and simulate() -- or other functions -- for lmer. ?The documentation for refit in lme4.pdf is pretty tempting, since it writes that "it is common to use the same model specification and covariate data on many simulated responses. ?That is, the only thing that changes between model fits is the response vector." ?However, in this case I want to keep the model specification, but change both the covariate data and get the response vector. ?I'm not sure if this is possible using lmer().
>> Cons: obviously, I don't know how quite to do this yet.
>>
>> [Option #3] ?Just?use nlme().
>> Pros: nlme() will estimate this relatively simple model, and then I can simply use the predict() function to get the predictions using the fit to the original data, and then predict(M1, newdat) to get predictions with the new data.
>> Cons: nlme() is slower than lmer(), and my model already takes about 2 hours to run.
>>
>>
>>
>>
>>
>> --
>> David Hsu
>> PhD Candidate, Urban Planning
>> University of Washington
>> (e-mail) dhsu2 at uw.edu
>>
>
>
>
> --
> David Hsu
> PhD Candidate, Urban Planning
> University of Washington
> (e-mail) dhsu2 at uw.edu
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From brjmoreira2 at gmail.com  Fri Mar 12 11:50:02 2010
From: brjmoreira2 at gmail.com (Bruno Moreira)
Date: Fri, 12 Mar 2010 11:50:02 +0100
Subject: [R-sig-ME] Nested fixed variable in glmer
Message-ID: <51bb883a1003120250q773c071ct5e7c83048469edab@mail.gmail.com>

Dear all,

I have data with the following structure (data is not real, just an example)

SUCESS <- c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30)
FAIL <- c(30,29,28,27,26,25,24,23,22,21,20,19,18,17,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1)
sf <- cbind(s= SUCESS, f= FAIL)
sp <- c("A","A","A","A","A","A","A","A","A","A","A","A","A","A","A","B","B","B","B","B","B","B","B","B","B","B","B","B","B","B")
ind <- c("1","1","1","1","1","2","2","2","2","2","3","3","3","3","3","4","4","4","4","4","5","5","5","5","5","6","6","6","6","6")
treat <- c("A","A","A","B","B","A","A","A","B","B","A","A","A","B","B","A","A","A","B","B","A","A","A","B","B","A","A","A","B","B")
tlevel <- c("AA","AB","AC","BA","BB","AA","AB","AC","BA","BB","AA","AB","AC","BA","BB","AA","AB","AC","BA","BB","AA","AB","AC","BA","BB","AA","AB","AC","BA","BB")


Individual (ind) is random
The response variable is sf and the explanatory variables are
species(sp) and treatment(treat). treatments (A and B) have different
levels (tlevel)

I want to nest tlevels in treat, but i do not know if this is the
right way as it gives an error message:

library(lme4)
r0 <- glmer(sf ~ 1 + (1|ind), family="binomial")
r1 <- glmer(sf ~ sp + treat/tlevel + tlevel/treat*sp + (1|ind),
family="binomial")

anova(r0,r1)

And it gives me this error message:
In mer_finalize(ans) : gr cannot be computed at initial par (65)

I am new with this and i would  appreciate any help.

thanks

bruno



From nina.bhola at gmail.com  Fri Mar 12 13:49:49 2010
From: nina.bhola at gmail.com (Nina Bhola)
Date: Fri, 12 Mar 2010 13:49:49 +0100
Subject: [R-sig-ME] two random statements with a correlation structures
Message-ID: <6766ef4f1003120449j4da6a97by7d242ca3a064dc88@mail.gmail.com>

Dear list,

I am modelling trends in counts of trees across years and plots in
different height classes across a savanna ecosystem.
I am using a generalized linear mixed model with a negative binomial
distribution
(many zeros).
My fixed effects are height class + year + plot

I have two random statements which are not about random height class,
plot or year. These variables are inducing correlations between all
observations made on the same  plot in a given year (first statement)
and correlations between observations for a given age in a given, plot
and year (second random statement).

Therefore, I would like model these random effects in R like we could
do in SAS using a random term with a correlation structure.

Random year /sub=plot*rep type=sp(pow)(year2);
Random year /sub=plot*rep*age;



Is there any way of doing this? I prefer to use R so i am trying very
hard to code this in R.


Thanks in advance



From cotter.rs at gmail.com  Fri Mar 12 15:14:15 2010
From: cotter.rs at gmail.com (R.S. Cotter)
Date: Fri, 12 Mar 2010 15:14:15 +0100
Subject: [R-sig-ME] lme and how to get the standard error of the prediction?
Message-ID: <742479271003120614g325aaff1g6ba471aeae8fc820@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100312/513bd8c9/attachment.pl>

From Vincent.Kint at ees.kuleuven.be  Fri Mar 12 15:46:23 2010
From: Vincent.Kint at ees.kuleuven.be (Vincent Kint)
Date: Fri, 12 Mar 2010 15:46:23 +0100
Subject: [R-sig-ME] significance test of random and fixed effects in (quasi)
 poisson GLMM
Message-ID: <562EA47F252E594B826D3B440E0B34A21288E5803C@ICTS-S-EXC2-CA.luna.kuleuven.be>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100312/4cb57833/attachment.pl>

From Antonio.Gasparrini at lshtm.ac.uk  Sat Mar 13 14:09:52 2010
From: Antonio.Gasparrini at lshtm.ac.uk (Antonio.Gasparrini at lshtm.ac.uk)
Date: Sat, 13 Mar 2010 13:09:52 +0000
Subject: [R-sig-ME] significance test of random and fixed effects in
	(quasi)	 poisson GLMM
In-Reply-To: <mailman.5.1268478002.991.r-sig-mixed-models@r-project.org>
References: <mailman.5.1268478002.991.r-sig-mixed-models@r-project.org>
Message-ID: <4B9B8EA1.5572.00B2.0@lshtm.ac.uk>

Dear Vincent,
 
some time ago I posted a question on Poisson GLMM for overdispersed
data, including a simple simulation in order to compare the reliability
of glmmPQL and glmer.
See
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q1/003289.html

 
While glmmPQL returns the correct estimates, glmer largely
overestimated the sigma (corresponding to the overdispersion), producing
an inflated within-group residual variance.
This odd behaviour seems to be confirmed by your analysis.
 
As pointed out in the response I had to my question, the quasi-Poisson
is not a distribution and the results are not grounded on an appropriate
statistical theory. Anyway, as in your case, the quasipoisson family is
currently used and I would expect the command to return (approximate)
correct results.
 
My suggestion is to repeat the analysis with glmmPQL, even if this
doesn't solve your problem to run a test. To my knowledge, the
approximation used by the penalized quasi-likelihood method is
reasonable for Poisson data and a moderate number of counts (McCulloch &
Searle say with mean count of 7 or higher). Interestingly, the command
always estimates the sigma (not fixed to 1 as in Poisson) even with the
simple poisson family.

I hope this helps

Antonio Gasparrini
Public and Environmental Health Research Unit (PEHRU)
London School of Hygiene & Tropical Medicine
Keppel Street, London WC1E 7HT, UK
Office: 0044 (0)20 79272406 - Mobile: 0044 (0)79 64925523

------------------------------

Message: 3
Date: Fri, 12 Mar 2010 15:46:23 +0100
From: Vincent Kint <Vincent.Kint at ees.kuleuven.be>
To: "r-sig-mixed-models at r-project.org"
<r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] significance test of random and fixed effects in
(quasi) poisson GLMM
Message-ID:
<562EA47F252E594B826D3B440E0B34A21288E5803C at ICTS-S-EXC2-CA.luna.kuleuven.be>

Content-Type: text/plain

Dear list members,

I am new to this list, and new to generalised mixed modelling.

My aim is to develop a model for tree branchiness (number of branches
per tree, with trees measured in different plots) with both tree and
plot-level predictors. My choice was for a generalised model using the
poisson family, since I have count data. And for a mixed approach since
I have a nested design.

I built a first model using the lme4 package (see below). My question
is: is there an approximate test for the significance of the random
effect? From previous posts on this list, I understand that such a test
is not always reliable, and good alternatives are not implemented yet.
But from my perspective of an applied modeller, even an approximate test
(or even a rule of thumb) would be helpful in making a decision. Indeed,
if the random effect turns out to be likely not significant, I could do
with a more simple GLM.

In a second step I tried to correct for overdispersion by running the
same model as a quasi GLMM. The output is also given below. Here I have
the same question as before, but now also concerning the fixed effects.
Additionally, I wonder whether I may have made a mistake in implementing
this model, since I get a result where nearly all the variation is
attributed to the error term, and (at a first glance) the random effect
and all the fixed predictors seem to be irrelevant.

I attach the output of both models below.
Thanks for all suggestions on how to proceed.
Vincent


#1. The GLMM model
> form1<-formula(response ~ TreeHeight + DBH + TreeAge + Vplot + mF +
mL + (1 | plots))
> M.glmm<-lmer(form1, data=data, family=poisson)
> summary(M.glmm)
Generalized linear mixed model fit by the Laplace approximation
Formula: form1
   Data: data
AIC  BIC logLik deviance
976 1008   -480      960
Random effects:
Groups Name        Variance Std.Dev.
plots  (Intercept) 0.044913 0.21193
Number of obs: 399, groups: plots, 30

Fixed effects:
              Estimate Std. Error z value Pr(>|z|)
(Intercept)  6.0090427  1.4143768   4.249 2.15e-05 ***
TreeHeight  -0.0398146  0.0125816  -3.165 0.001553 **
DBH          0.0032600  0.0006599   4.940 7.80e-07 ***
TreeAge     -0.1193541  0.0242996  -4.912 9.03e-07 ***
Vplot       -0.0060713  0.0016115  -3.768 0.000165 ***
mF          -0.4838699  0.1672462  -2.893 0.003814 **
mL           0.4878563  0.1731139   2.818 0.004831 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.?
0.1 ? ? 1



#2. The same GLMM model with overdispersion
> M.glmm.q<-lmer(form1, data=data, family=quasipoisson)
> summary(M.glmm.q)
Generalized linear mixed model fit by the Laplace approximation
Formula: form1
   Data: data
AIC  BIC logLik deviance
978 1014   -480      960
Random effects:
Groups   Name        Variance Std.Dev.
plots    (Intercept)  1.6478  1.2837
Residual             36.6894  6.0572
Number of obs: 399, groups: plots, 30

Fixed effects:
             Estimate Std. Error t value
(Intercept)  6.009043   8.567129   0.701
TreeHeight  -0.039815   0.076209  -0.522
DBH          0.003260   0.003997   0.816
TreeAge     -0.119354   0.147187  -0.811
Vplot       -0.006071   0.009761  -0.622
mF          -0.483870   1.013039  -0.478
mL           0.487856   1.048581   0.465

_____________________________________
dr. ir. V. KINT
Forest Ecology and Management
Division Forest, Nature and Landscape
K.U.Leuven
Celestijnenlaan 200E - B-3001 Leuven
Tel.: +32 16 32 97 69
Fax:  +32 16 32 97 60
vincent.kint at ees.kuleuven.be 

www.kuleuven.be/forecoman<http://www.kuleuven.be/forecoman>

[[alternative HTML version deleted]]



From lucianolasala at yahoo.com.ar  Sat Mar 13 23:07:56 2010
From: lucianolasala at yahoo.com.ar (Luciano La Sala)
Date: Sat, 13 Mar 2010 14:07:56 -0800 (PST)
Subject: [R-sig-ME] Model building problem?
Message-ID: <241458.81889.qm@web59914.mail.ac4.yahoo.com>

Hello everyone, 

I am building a model using the ?lmer? function. I have IgG (continuous) as my outcome of interest, and the following variables as fixed effects: Egg Breadth (continuous), Egg Length (continuous), EggVolume (continuous), Clutch Size (three levels), and Hatching Order (three levels), plus random intercepts for NestID.  

In model selection, terms were eliminated from a maximum model (with random intercept) to achieve a simpler model that retained only the significant main effects and interactions, using the Akaike information criterion. 

At each step of model reduction, I look at the p-values of coefficients and decide which variable to eliminate next, re-fit the model and then I compare AIC values to decide whether the new model is a better fit for my data or not.  

To my dismay, the best model is the one containing only the random intercept. 

Stepwise variable elimination reduces AIC (see output) despite low p-values for the coefficients of the variables dropped! I would think that at least some of my variables (not just the random effect) should improve the model fit. It strikes me as very odd that the model with only random intercepts offers the best fit, being that random effect variances is close to zero (see output). 

Q1. Should I stop simplifying my model at Step 2 or 3, where all main effects have p < 0.05? 

Q2. However, AIC keeps dropping thereafter -regardless of significant p values of main effects- until no single main effect is left in the model. This baffles me! 

Q3. Last but not least? where am I going so wrong here?

Thank you very much for whatever help you may give me!     


Here goes a summary of the outputs:

FULL MODEL

Linear mixed model fit by REML 

Formula: ELISA2~EggBreadth+EggLength+ClutchSize+HatchOrder+ EggVolume+(1|NestID) 

    AIC    BIC logLik deviance REMLdev
 -544.1 -511.6  282.1   -632.2  -564.1

Random effects:
 Groups   Name        Variance   Std.Dev.
 NestID   (Intercept) 0.00016440 0.012822
 Residual             0.00207281 0.045528

Number of obs: 191, groups: NestID, 111

Fixed effects:
                      Estimate Std. Error t value  Pr(>|t|)
(Intercept)           3.545249   2.268083   1.563  0.1198
EggBreadth           -0.066974   0.046930  -1.427  0.1553
EggLength            -0.017986   0.016281  -1.105  0.2707
ClutchSizeTwo-eggs    0.009885   0.011652   0.848  0.3974
ClutchSizeThree-eggs -0.014039   0.011518  -1.219  0.2245
HatchOrderSecond      0.015605   0.008245   1.893  0.0600
HatchOrderThird       0.032599   0.011763   2.771  0.0062
EggVolume             0.019498   0.014616   1.334  0.1839
     





BACKWARD 1. Drop Clutch Size

Linear mixed model fit by REML 
Formula: ELISA2~EggBreadth+EggLength+HatchOrder+EggVolume+(1|NestID) 

    AIC    BIC logLik deviance REMLdev
 -556.4 -530.4  286.2   -625.6  -572.4

Random effects:
 Groups   Name        Variance   Std.Dev.
 NestID   (Intercept) 0.00017555 0.013250
 Residual             0.00211661 0.046007
Number of obs: 191, groups: NestID, 111

Fixed effects:
                  Estimate Std. Error t value   Pr(>|t|)
(Intercept)       3.089050   2.281486   1.354   0.1774
EggBreadth       -0.057337   0.047197  -1.215   0.2260
EggLength        -0.013941   0.016351  -0.853   0.3950
HatchOrderSecond  0.014215   0.007875   1.805   0.0727
HatchOrderThird   0.021879   0.010740   2.037   0.0431
EggVolume         0.015693   0.014661   1.070   0.2858


BACKWARD 2. Drop EggLength

Linear mixed model fit by REML 

Formula: ELISA2 ~ EggBreadth + HatchOrder + EggVolume + (1 | NestID) 

Formula: ELISA2 ~ EggBreadth + HatchOrder + EggVolume + (1 | NestID) 
    AIC    BIC logLik deviance REMLdev
 -564.1 -541.3  289.1   -624.8  -578.1

Random effects:
 Groups   Name        Variance   Std.Dev.
 NestID   (Intercept) 0.00015766 0.012556
 Residual             0.00212966 0.046148

Number of obs: 191, groups: NestID, 111

Fixed effects:
                  Estimate Std. Error t value   Pr(>|t|)
(Intercept)       1.148186   0.148751   7.719   0.0000
EggBreadth       -0.017284   0.004517  -3.826   0.0002
HatchOrderSecond  0.014918   0.007848   1.901   0.0588
HatchOrderThird   0.022059   0.010734   2.055   0.0413
EggVolume         0.003230   0.001148   2.813   0.0054


BACKWARD 3. Drop EggBreadth

Linear mixed model fit by REML 

Formula: ELISA2 ~ EggLength + HatchOrder + EggVolume + (1 | NestID) 

    AIC    BIC logLik deviance REMLdev
 -561.2 -538.5  287.6   -624.1  -575.2

Random effects:
 Groups   Name        Variance   Std.Dev.
 NestID   (Intercept) 0.00015423 0.012419
 Residual             0.00214197 0.046281
Number of obs: 191, groups: NestID, 111

Fixed effects:
                   Estimate Std. Error t value   Pr(>|t|)
(Intercept)       0.3196987  0.0912062   3.505   0.0006
EggLength         0.0058330  0.0015671   3.722   0.0003
HatchOrderSecond  0.0149907  0.0078835   1.902   0.0588
HatchOrderThird   0.0219364  0.0107628   2.038   0.0429
EggVolume        -0.0020977  0.0007405  -2.833   0.0051


BACKWARD 4. Drop HatchOrder

Formula: ELISA2 ~ EggBreadth + EggVolume + (1 | NestID) 

Linear mixed model fit by REML 
    AIC    BIC logLik deviance REMLdev
 -577.4 -561.1  293.7   -618.9  -587.4

Random effects:
 Groups   Name        Variance   Std.Dev.
 NestID   (Intercept) 0.00010214 0.010106
 Residual             0.00222943 0.047217

Number of obs: 191, groups: NestID, 111

Fixed effects:
             Estimate Std. Error t value   Pr(>|t|)
(Intercept)  1.084503   0.146243   7.416   0.0000
EggBreadth  -0.014484   0.004371  -3.314   0.0011
EggVolume    0.002409   0.001099   2.193   0.0295


BACKWARD 5. Drop EggVolume

Formula: ELISA2 ~ EggBreadth + (1 | NestID) 

Linear mixed model fit by REML 
    AIC    BIC logLik deviance REMLdev
 -586.5 -573.5  297.2   -614.1  -594.5
Random effects:
 Groups   Name        Variance   Std.Dev.
 NestID   (Intercept) 0.00017172 0.013104
 Residual             0.00221031 0.047014
Number of obs: 191, groups: NestID, 111

Fixed effects:
             Estimate Std. Error t value   Pr(>|t|)   
(Intercept)  0.884482   0.115833   7.636   0.0000
EggBreadth  -0.006443   0.002401  -2.683   0.0079


BACKWARD 6. Drop Egg Breadth

Formula: ELISA2 ~ 1 + (1|NestID) 

Linear mixed model fit by REML 
    AIC    BIC logLik deviance REMLdev
 -591.6 -581.8  298.8     -607  -597.6
Random effects:
 Groups   Name        Variance  Std.Dev.
 NestID   (Intercept) 0.0001917 0.013846
 Residual             0.0022692 0.047636

Number of obs: 191, groups: NestID, 111

Fixed effects:
            Estimate Std. Error t value   Pr(>|t|)
(Intercept) 0.573809   0.003727   153.9   0






      Yahoo! Cocina

Encontra las mejores recetas con Yahoo! Cocina.


http://ar.mujer.yahoo.com/cocina/



From andydolman at gmail.com  Sat Mar 13 23:58:13 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Sat, 13 Mar 2010 23:58:13 +0100
Subject: [R-sig-ME] Model building problem?
In-Reply-To: <241458.81889.qm@web59914.mail.ac4.yahoo.com>
References: <241458.81889.qm@web59914.mail.ac4.yahoo.com>
Message-ID: <951234ac1003131458p10e568b3ud733ad8c688465e0@mail.gmail.com>

Dear Luciano,

If you're going to judge when to stop dropping terms using AIC then
you should probably use AIC to decide which terms to drop rather than
their p-values. This means you have to fit a lot of models but have
you looked at the function step()? Not that this will necessarily get
you a nice answer but it does automate the process.

Having said this, model selection is a mighty can of worms and
stepwise model building has some particularly juicy ones. If you have
time, have a read of Burnham and Anderson, Model Selection and
Multi-Model Inference.

Better than stepwise elimination is to choose a set of sensible
candidate models and fit them at the same time (including the most
basic "null" model, which here looks like the intercept only model).
Compare their AIC values, specifically the difference between the
lowest AIC and all the others, these are delta-AIC values. If several
models all have low and similar d-AIC values (less than say 2) then
you can't really choose between them. Maybe multi-model inference can
help then.


Another further thought. How much collinearity do you have between
your predictors? If they are correlated with each other then stepwise
model selection is always going to struggle.


Andy.




andydolman at gmail.com



On 13 March 2010 23:07, Luciano La Sala <lucianolasala at yahoo.com.ar> wrote:
> Hello everyone,
>
> I am building a model using the ?lmer? function. I have IgG (continuous) as my outcome of interest, and the following variables as fixed effects: Egg Breadth (continuous), Egg Length (continuous), EggVolume (continuous), Clutch Size (three levels), and Hatching Order (three levels), plus random intercepts for NestID.
>
> In model selection, terms were eliminated from a maximum model (with random intercept) to achieve a simpler model that retained only the significant main effects and interactions, using the Akaike information criterion.
>
> At each step of model reduction, I look at the p-values of coefficients and decide which variable to eliminate next, re-fit the model and then I compare AIC values to decide whether the new model is a better fit for my data or not.
>
> To my dismay, the best model is the one containing only the random intercept.
>
> Stepwise variable elimination reduces AIC (see output) despite low p-values for the coefficients of the variables dropped! I would think that at least some of my variables (not just the random effect) should improve the model fit. It strikes me as very odd that the model with only random intercepts offers the best fit, being that random effect variances is close to zero (see output).
>
> Q1. Should I stop simplifying my model at Step 2 or 3, where all main effects have p < 0.05?
>
> Q2. However, AIC keeps dropping thereafter -regardless of significant p values of main effects- until no single main effect is left in the model. This baffles me!
>
> Q3. Last but not least? where am I going so wrong here?
>
> Thank you very much for whatever help you may give me!
>
>
> Here goes a summary of the outputs:
>
> FULL MODEL
>
> Linear mixed model fit by REML
>
> Formula: ELISA2~EggBreadth+EggLength+ClutchSize+HatchOrder+ EggVolume+(1|NestID)
>
> ? ?AIC ? ?BIC logLik deviance REMLdev
> ?-544.1 -511.6 ?282.1 ? -632.2 ?-564.1
>
> Random effects:
> ?Groups ? Name ? ? ? ?Variance ? Std.Dev.
> ?NestID ? (Intercept) 0.00016440 0.012822
> ?Residual ? ? ? ? ? ? 0.00207281 0.045528
>
> Number of obs: 191, groups: NestID, 111
>
> Fixed effects:
> ? ? ? ? ? ? ? ? ? ? ?Estimate Std. Error t value ?Pr(>|t|)
> (Intercept) ? ? ? ? ? 3.545249 ? 2.268083 ? 1.563 ?0.1198
> EggBreadth ? ? ? ? ? -0.066974 ? 0.046930 ?-1.427 ?0.1553
> EggLength ? ? ? ? ? ?-0.017986 ? 0.016281 ?-1.105 ?0.2707
> ClutchSizeTwo-eggs ? ?0.009885 ? 0.011652 ? 0.848 ?0.3974
> ClutchSizeThree-eggs -0.014039 ? 0.011518 ?-1.219 ?0.2245
> HatchOrderSecond ? ? ?0.015605 ? 0.008245 ? 1.893 ?0.0600
> HatchOrderThird ? ? ? 0.032599 ? 0.011763 ? 2.771 ?0.0062
> EggVolume ? ? ? ? ? ? 0.019498 ? 0.014616 ? 1.334 ?0.1839
>
>
>
>
>
>
> BACKWARD 1. Drop Clutch Size
>
> Linear mixed model fit by REML
> Formula: ELISA2~EggBreadth+EggLength+HatchOrder+EggVolume+(1|NestID)
>
> ? ?AIC ? ?BIC logLik deviance REMLdev
> ?-556.4 -530.4 ?286.2 ? -625.6 ?-572.4
>
> Random effects:
> ?Groups ? Name ? ? ? ?Variance ? Std.Dev.
> ?NestID ? (Intercept) 0.00017555 0.013250
> ?Residual ? ? ? ? ? ? 0.00211661 0.046007
> Number of obs: 191, groups: NestID, 111
>
> Fixed effects:
> ? ? ? ? ? ? ? ? ?Estimate Std. Error t value ? Pr(>|t|)
> (Intercept) ? ? ? 3.089050 ? 2.281486 ? 1.354 ? 0.1774
> EggBreadth ? ? ? -0.057337 ? 0.047197 ?-1.215 ? 0.2260
> EggLength ? ? ? ?-0.013941 ? 0.016351 ?-0.853 ? 0.3950
> HatchOrderSecond ?0.014215 ? 0.007875 ? 1.805 ? 0.0727
> HatchOrderThird ? 0.021879 ? 0.010740 ? 2.037 ? 0.0431
> EggVolume ? ? ? ? 0.015693 ? 0.014661 ? 1.070 ? 0.2858
>
>
> BACKWARD 2. Drop EggLength
>
> Linear mixed model fit by REML
>
> Formula: ELISA2 ~ EggBreadth + HatchOrder + EggVolume + (1 | NestID)
>
> Formula: ELISA2 ~ EggBreadth + HatchOrder + EggVolume + (1 | NestID)
> ? ?AIC ? ?BIC logLik deviance REMLdev
> ?-564.1 -541.3 ?289.1 ? -624.8 ?-578.1
>
> Random effects:
> ?Groups ? Name ? ? ? ?Variance ? Std.Dev.
> ?NestID ? (Intercept) 0.00015766 0.012556
> ?Residual ? ? ? ? ? ? 0.00212966 0.046148
>
> Number of obs: 191, groups: NestID, 111
>
> Fixed effects:
> ? ? ? ? ? ? ? ? ?Estimate Std. Error t value ? Pr(>|t|)
> (Intercept) ? ? ? 1.148186 ? 0.148751 ? 7.719 ? 0.0000
> EggBreadth ? ? ? -0.017284 ? 0.004517 ?-3.826 ? 0.0002
> HatchOrderSecond ?0.014918 ? 0.007848 ? 1.901 ? 0.0588
> HatchOrderThird ? 0.022059 ? 0.010734 ? 2.055 ? 0.0413
> EggVolume ? ? ? ? 0.003230 ? 0.001148 ? 2.813 ? 0.0054
>
>
> BACKWARD 3. Drop EggBreadth
>
> Linear mixed model fit by REML
>
> Formula: ELISA2 ~ EggLength + HatchOrder + EggVolume + (1 | NestID)
>
> ? ?AIC ? ?BIC logLik deviance REMLdev
> ?-561.2 -538.5 ?287.6 ? -624.1 ?-575.2
>
> Random effects:
> ?Groups ? Name ? ? ? ?Variance ? Std.Dev.
> ?NestID ? (Intercept) 0.00015423 0.012419
> ?Residual ? ? ? ? ? ? 0.00214197 0.046281
> Number of obs: 191, groups: NestID, 111
>
> Fixed effects:
> ? ? ? ? ? ? ? ? ? Estimate Std. Error t value ? Pr(>|t|)
> (Intercept) ? ? ? 0.3196987 ?0.0912062 ? 3.505 ? 0.0006
> EggLength ? ? ? ? 0.0058330 ?0.0015671 ? 3.722 ? 0.0003
> HatchOrderSecond ?0.0149907 ?0.0078835 ? 1.902 ? 0.0588
> HatchOrderThird ? 0.0219364 ?0.0107628 ? 2.038 ? 0.0429
> EggVolume ? ? ? ?-0.0020977 ?0.0007405 ?-2.833 ? 0.0051
>
>
> BACKWARD 4. Drop HatchOrder
>
> Formula: ELISA2 ~ EggBreadth + EggVolume + (1 | NestID)
>
> Linear mixed model fit by REML
> ? ?AIC ? ?BIC logLik deviance REMLdev
> ?-577.4 -561.1 ?293.7 ? -618.9 ?-587.4
>
> Random effects:
> ?Groups ? Name ? ? ? ?Variance ? Std.Dev.
> ?NestID ? (Intercept) 0.00010214 0.010106
> ?Residual ? ? ? ? ? ? 0.00222943 0.047217
>
> Number of obs: 191, groups: NestID, 111
>
> Fixed effects:
> ? ? ? ? ? ? Estimate Std. Error t value ? Pr(>|t|)
> (Intercept) ?1.084503 ? 0.146243 ? 7.416 ? 0.0000
> EggBreadth ?-0.014484 ? 0.004371 ?-3.314 ? 0.0011
> EggVolume ? ?0.002409 ? 0.001099 ? 2.193 ? 0.0295
>
>
> BACKWARD 5. Drop EggVolume
>
> Formula: ELISA2 ~ EggBreadth + (1 | NestID)
>
> Linear mixed model fit by REML
> ? ?AIC ? ?BIC logLik deviance REMLdev
> ?-586.5 -573.5 ?297.2 ? -614.1 ?-594.5
> Random effects:
> ?Groups ? Name ? ? ? ?Variance ? Std.Dev.
> ?NestID ? (Intercept) 0.00017172 0.013104
> ?Residual ? ? ? ? ? ? 0.00221031 0.047014
> Number of obs: 191, groups: NestID, 111
>
> Fixed effects:
> ? ? ? ? ? ? Estimate Std. Error t value ? Pr(>|t|)
> (Intercept) ?0.884482 ? 0.115833 ? 7.636 ? 0.0000
> EggBreadth ?-0.006443 ? 0.002401 ?-2.683 ? 0.0079
>
>
> BACKWARD 6. Drop Egg Breadth
>
> Formula: ELISA2 ~ 1 + (1|NestID)
>
> Linear mixed model fit by REML
> ? ?AIC ? ?BIC logLik deviance REMLdev
> ?-591.6 -581.8 ?298.8 ? ? -607 ?-597.6
> Random effects:
> ?Groups ? Name ? ? ? ?Variance ?Std.Dev.
> ?NestID ? (Intercept) 0.0001917 0.013846
> ?Residual ? ? ? ? ? ? 0.0022692 0.047636
>
> Number of obs: 191, groups: NestID, 111
>
> Fixed effects:
> ? ? ? ? ? ?Estimate Std. Error t value ? Pr(>|t|)
> (Intercept) 0.573809 ? 0.003727 ? 153.9 ? 0
>
>
>
>
>
>
> ? ? ?Yahoo! Cocina
>
> Encontra las mejores recetas con Yahoo! Cocina.
>
>
> http://ar.mujer.yahoo.com/cocina/
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From David.Duffy at qimr.edu.au  Sun Mar 14 07:03:03 2010
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Sun, 14 Mar 2010 16:03:03 +1000 (EST)
Subject: [R-sig-ME] Model building problem?
In-Reply-To: <241458.81889.qm@web59914.mail.ac4.yahoo.com>
References: <241458.81889.qm@web59914.mail.ac4.yahoo.com>
Message-ID: <Pine.LNX.4.64.1003141553530.17091@orpheus.qimr.edu.au>

On Sat, 13 Mar 2010, Luciano La Sala wrote:

> Hello everyone, 
> I am building a model using the lmer function. I have IgG 
> (continuous) as my outcome of interest, 
> and the following variables as fixed effects: Egg Breadth (continuous), i
> Egg Length (continuous), EggVolume (continuous), 
> Clutch Size (three levels), and Hatching Order (three levels), plus random intercepts for NestID.

logLik Model
282.1  ELISA2~EggBreadth+EggLength+ClutchSize+HatchOrder+ EggVolume+(1|NestID) 
286.2  ELISA2~EggBreadth+EggLength+HatchOrder+EggVolume+(1|NestID) 
289.1  ELISA2 ~ EggBreadth + HatchOrder + EggVolume + (1 | NestID) 
287.6  ELISA2 ~ EggLength + HatchOrder + EggVolume + (1 | NestID) 
293.7  ELISA2 ~ EggBreadth + EggVolume + (1 | NestID) 
297.2  ELISA2 ~ EggBreadth + (1 | NestID) 
298.8  ELISA2 ~ 1 + (1|NestID)

I am feeling pretty dull today, but I don't expect the model likelihood to
increase as the model is simplified (I always get confused when the sign 
on the log likelihood is positive). IgG is usually log-normal, has it been
transformed appropriately?

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From mspinola10 at gmail.com  Sun Mar 14 12:29:11 2010
From: mspinola10 at gmail.com (=?ISO-8859-1?Q?Manuel_Sp=EDnola?=)
Date: Sun, 14 Mar 2010 05:29:11 -0600
Subject: [R-sig-ME] Problems with function ranef in lme4
Message-ID: <4B9CC887.8010005@gmail.com>

Dear list members,

I am trying the function ranef from package lme4 and I got the following 
error warning:

 > data(sleepstudy)
 > fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
 > ranef(fm1)
Error en UseMethod("ranef") :
  no applicable method for 'ranef' applied to an object of class "mer"

What could be the problem?
Best,

Manuel

-- 
Manuel Sp?nola, Ph.D.
Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
Universidad Nacional
Apartado 1350-3000
Heredia
COSTA RICA
mspinola at una.ac.cr
mspinola10 at gmail.com
Tel?fono: (506) 2277-3598
Fax: (506) 2237-7036



From bolker at ufl.edu  Sun Mar 14 15:02:33 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Sun, 14 Mar 2010 10:02:33 -0400
Subject: [R-sig-ME] Problems with function ranef in lme4
In-Reply-To: <4B9CC887.8010005@gmail.com>
References: <4B9CC887.8010005@gmail.com>
Message-ID: <4B9CEC79.2000007@ufl.edu>

Manuel Sp?nola wrote:
> Dear list members,
> 
> I am trying the function ranef from package lme4 and I got the following 
> error warning:
> 
>  > data(sleepstudy)
>  > fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
>  > ranef(fm1)
> Error en UseMethod("ranef") :
>   no applicable method for 'ranef' applied to an object of class "mer"
> 
> What could be the problem?
> Best,
> 
> Manuel
> 

  My guess is that you have nlme loaded at the same time.

  search()
  detach("package:nlme")

  If that doesn't work, post the results of sessionInfo().


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From mspinola10 at gmail.com  Sun Mar 14 17:32:14 2010
From: mspinola10 at gmail.com (=?ISO-8859-1?Q?Manuel_Sp=EDnola?=)
Date: Sun, 14 Mar 2010 10:32:14 -0600
Subject: [R-sig-ME] Problems with function ranef in lme4
In-Reply-To: <4B9CEC79.2000007@ufl.edu>
References: <4B9CC887.8010005@gmail.com> <4B9CEC79.2000007@ufl.edu>
Message-ID: <4B9D0F8E.5000903@gmail.com>

Thank you very much Ben.  That was the problem.

Manuel

Ben Bolker wrote:
> Manuel Sp?nola wrote:
>   
>> Dear list members,
>>
>> I am trying the function ranef from package lme4 and I got the following 
>> error warning:
>>
>>  > data(sleepstudy)
>>  > fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
>>  > ranef(fm1)
>> Error en UseMethod("ranef") :
>>   no applicable method for 'ranef' applied to an object of class "mer"
>>
>> What could be the problem?
>> Best,
>>
>> Manuel
>>
>>     
>
>   My guess is that you have nlme loaded at the same time.
>
>   search()
>   detach("package:nlme")
>
>   If that doesn't work, post the results of sessionInfo().
>
>
>   


-- 
Manuel Sp?nola, Ph.D.
Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
Universidad Nacional
Apartado 1350-3000
Heredia
COSTA RICA
mspinola at una.ac.cr
mspinola10 at gmail.com
Tel?fono: (506) 2277-3598
Fax: (506) 2237-7036



From alex.safari at flinders.edu.au  Mon Mar 15 04:28:29 2010
From: alex.safari at flinders.edu.au (Alex Safari)
Date: Mon, 15 Mar 2010 13:58:29 +1030
Subject: [R-sig-ME] MCMCglmm
Message-ID: <002301cac3ef$95254c10$bf6fe430$@safari@flinders.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100315/994e2653/attachment.pl>

From David.Duffy at qimr.edu.au  Mon Mar 15 05:35:05 2010
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Mon, 15 Mar 2010 14:35:05 +1000 (EST)
Subject: [R-sig-ME] MCMCglmm
In-Reply-To: <002301cac3ef$95254c10$bf6fe430$@safari@flinders.edu.au>
References: <002301cac3ef$95254c10$bf6fe430$@safari@flinders.edu.au>
Message-ID: <Pine.LNX.4.64.1003151431360.14802@orpheus.qimr.edu.au>

On Mon, 15 Mar 2010, Alex Safari wrote:

> Dear all,
>
> Running a simple animal model with MCMCglmm  the following error occurred.
> Error in inverse (pedigree, nodes = nodes, scale = scale) :
> individuals appearing as dams but not in pedigree
> I run this data with ASReml and it is working ok.

I believe ASReml might automatically add in the missing pedigree members 
(who appear as a parent but do not have their own record in your 
pedigree).  MCMCglmm's Ainverse() requires the pedigree to be 
complete.

Cheers, David Duffy.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From regetz at nceas.ucsb.edu  Mon Mar 15 08:39:46 2010
From: regetz at nceas.ucsb.edu (Jim Regetz)
Date: Mon, 15 Mar 2010 00:39:46 -0700
Subject: [R-sig-ME] Model building problem?
In-Reply-To: <241458.81889.qm@web59914.mail.ac4.yahoo.com>
References: <241458.81889.qm@web59914.mail.ac4.yahoo.com>
Message-ID: <hnko83$8ho$1@dough.gmane.org>

Hi Luciano,

I'm not a big fan of the stepwise selection procedure you've adopted. 
Nevertheless, regarding your counterintuitive results, you seem to be 
comparing models based on REML fits (the lmer default), and moreover by 
manually comparing the AICs shown in the printed summary of each result. 
Values of the REML criterion, reported on the deviance scale as REMLdev 
in the printed output, are not comparable across models with different 
fixed effects specifications. Nor are the reported logLik values, which 
are simply -1/2 * REMLdev. Nor are AIC and BIC, which are calculated 
directly from logLik.

You may see something more sensible if you fit the models with 
REML=FALSE. Alternatively, I believe you could compare your REML-fit 
models with the multi-argument form of anova(), which produces AICs 
based on a value of the profiled ML (not REML) deviance that should be 
close to its optimum. Glancing quickly at the deviance values in your 
reported outputs, it appears that the reduction in deviance will more 
than overcome the penalty for adding at least some of your fixed effect 
terms.

See the list archives for more thorough (and probably terminologically 
precise) discussion from more authoritative contributors.

Cheers,
Jim

On 3/13/10 2:07 PM, Luciano La Sala wrote:
> Hello everyone,
>
> I am building a model using the ?lmer? function. I have IgG (continuous) as my outcome of interest, and the following variables as fixed effects: Egg Breadth (continuous), Egg Length (continuous), EggVolume (continuous), Clutch Size (three levels), and Hatching Order (three levels), plus random intercepts for NestID.
>
> In model selection, terms were eliminated from a maximum model (with random intercept) to achieve a simpler model that retained only the significant main effects and interactions, using the Akaike information criterion.
>
> At each step of model reduction, I look at the p-values of coefficients and decide which variable to eliminate next, re-fit the model and then I compare AIC values to decide whether the new model is a better fit for my data or not.
>
> To my dismay, the best model is the one containing only the random intercept.
>
> Stepwise variable elimination reduces AIC (see output) despite low p-values for the coefficients of the variables dropped! I would think that at least some of my variables (not just the random effect) should improve the model fit. It strikes me as very odd that the model with only random intercepts offers the best fit, being that random effect variances is close to zero (see output).
>
> Q1. Should I stop simplifying my model at Step 2 or 3, where all main effects have p<  0.05?
>
> Q2. However, AIC keeps dropping thereafter -regardless of significant p values of main effects- until no single main effect is left in the model. This baffles me!
>
> Q3. Last but not least? where am I going so wrong here?
>
> Thank you very much for whatever help you may give me!
>
>
> Here goes a summary of the outputs:
>
> FULL MODEL
>
> Linear mixed model fit by REML
>
> Formula: ELISA2~EggBreadth+EggLength+ClutchSize+HatchOrder+ EggVolume+(1|NestID)
>
>      AIC    BIC logLik deviance REMLdev
>   -544.1 -511.6  282.1   -632.2  -564.1
>
> Random effects:
>   Groups   Name        Variance   Std.Dev.
>   NestID   (Intercept) 0.00016440 0.012822
>   Residual             0.00207281 0.045528
>
> Number of obs: 191, groups: NestID, 111
>
> Fixed effects:
>                        Estimate Std. Error t value  Pr(>|t|)
> (Intercept)           3.545249   2.268083   1.563  0.1198
> EggBreadth           -0.066974   0.046930  -1.427  0.1553
> EggLength            -0.017986   0.016281  -1.105  0.2707
> ClutchSizeTwo-eggs    0.009885   0.011652   0.848  0.3974
> ClutchSizeThree-eggs -0.014039   0.011518  -1.219  0.2245
> HatchOrderSecond      0.015605   0.008245   1.893  0.0600
> HatchOrderThird       0.032599   0.011763   2.771  0.0062
> EggVolume             0.019498   0.014616   1.334  0.1839
>
>
>
>
>
>
> BACKWARD 1. Drop Clutch Size
>
> Linear mixed model fit by REML
> Formula: ELISA2~EggBreadth+EggLength+HatchOrder+EggVolume+(1|NestID)
>
>      AIC    BIC logLik deviance REMLdev
>   -556.4 -530.4  286.2   -625.6  -572.4
>
> Random effects:
>   Groups   Name        Variance   Std.Dev.
>   NestID   (Intercept) 0.00017555 0.013250
>   Residual             0.00211661 0.046007
> Number of obs: 191, groups: NestID, 111
>
> Fixed effects:
>                    Estimate Std. Error t value   Pr(>|t|)
> (Intercept)       3.089050   2.281486   1.354   0.1774
> EggBreadth       -0.057337   0.047197  -1.215   0.2260
> EggLength        -0.013941   0.016351  -0.853   0.3950
> HatchOrderSecond  0.014215   0.007875   1.805   0.0727
> HatchOrderThird   0.021879   0.010740   2.037   0.0431
> EggVolume         0.015693   0.014661   1.070   0.2858
>
>
> BACKWARD 2. Drop EggLength
>
> Linear mixed model fit by REML
>
> Formula: ELISA2 ~ EggBreadth + HatchOrder + EggVolume + (1 | NestID)
>
> Formula: ELISA2 ~ EggBreadth + HatchOrder + EggVolume + (1 | NestID)
>      AIC    BIC logLik deviance REMLdev
>   -564.1 -541.3  289.1   -624.8  -578.1
>
> Random effects:
>   Groups   Name        Variance   Std.Dev.
>   NestID   (Intercept) 0.00015766 0.012556
>   Residual             0.00212966 0.046148
>
> Number of obs: 191, groups: NestID, 111
>
> Fixed effects:
>                    Estimate Std. Error t value   Pr(>|t|)
> (Intercept)       1.148186   0.148751   7.719   0.0000
> EggBreadth       -0.017284   0.004517  -3.826   0.0002
> HatchOrderSecond  0.014918   0.007848   1.901   0.0588
> HatchOrderThird   0.022059   0.010734   2.055   0.0413
> EggVolume         0.003230   0.001148   2.813   0.0054
>
>
> BACKWARD 3. Drop EggBreadth
>
> Linear mixed model fit by REML
>
> Formula: ELISA2 ~ EggLength + HatchOrder + EggVolume + (1 | NestID)
>
>      AIC    BIC logLik deviance REMLdev
>   -561.2 -538.5  287.6   -624.1  -575.2
>
> Random effects:
>   Groups   Name        Variance   Std.Dev.
>   NestID   (Intercept) 0.00015423 0.012419
>   Residual             0.00214197 0.046281
> Number of obs: 191, groups: NestID, 111
>
> Fixed effects:
>                     Estimate Std. Error t value   Pr(>|t|)
> (Intercept)       0.3196987  0.0912062   3.505   0.0006
> EggLength         0.0058330  0.0015671   3.722   0.0003
> HatchOrderSecond  0.0149907  0.0078835   1.902   0.0588
> HatchOrderThird   0.0219364  0.0107628   2.038   0.0429
> EggVolume        -0.0020977  0.0007405  -2.833   0.0051
>
>
> BACKWARD 4. Drop HatchOrder
>
> Formula: ELISA2 ~ EggBreadth + EggVolume + (1 | NestID)
>
> Linear mixed model fit by REML
>      AIC    BIC logLik deviance REMLdev
>   -577.4 -561.1  293.7   -618.9  -587.4
>
> Random effects:
>   Groups   Name        Variance   Std.Dev.
>   NestID   (Intercept) 0.00010214 0.010106
>   Residual             0.00222943 0.047217
>
> Number of obs: 191, groups: NestID, 111
>
> Fixed effects:
>               Estimate Std. Error t value   Pr(>|t|)
> (Intercept)  1.084503   0.146243   7.416   0.0000
> EggBreadth  -0.014484   0.004371  -3.314   0.0011
> EggVolume    0.002409   0.001099   2.193   0.0295
>
>
> BACKWARD 5. Drop EggVolume
>
> Formula: ELISA2 ~ EggBreadth + (1 | NestID)
>
> Linear mixed model fit by REML
>      AIC    BIC logLik deviance REMLdev
>   -586.5 -573.5  297.2   -614.1  -594.5
> Random effects:
>   Groups   Name        Variance   Std.Dev.
>   NestID   (Intercept) 0.00017172 0.013104
>   Residual             0.00221031 0.047014
> Number of obs: 191, groups: NestID, 111
>
> Fixed effects:
>               Estimate Std. Error t value   Pr(>|t|)
> (Intercept)  0.884482   0.115833   7.636   0.0000
> EggBreadth  -0.006443   0.002401  -2.683   0.0079
>
>
> BACKWARD 6. Drop Egg Breadth
>
> Formula: ELISA2 ~ 1 + (1|NestID)
>
> Linear mixed model fit by REML
>      AIC    BIC logLik deviance REMLdev
>   -591.6 -581.8  298.8     -607  -597.6
> Random effects:
>   Groups   Name        Variance  Std.Dev.
>   NestID   (Intercept) 0.0001917 0.013846
>   Residual             0.0022692 0.047636
>
> Number of obs: 191, groups: NestID, 111
>
> Fixed effects:
>              Estimate Std. Error t value   Pr(>|t|)
> (Intercept) 0.573809   0.003727   153.9   0
>
>
>
>
>
>
>        Yahoo! Cocina
>
> Encontra las mejores recetas con Yahoo! Cocina.
>
>
> http://ar.mujer.yahoo.com/cocina/
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From j.hadfield at ed.ac.uk  Mon Mar 15 10:10:38 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 15 Mar 2010 09:10:38 +0000
Subject: [R-sig-ME] MCMCglmm
In-Reply-To: <Pine.LNX.4.64.1003151431360.14802@orpheus.qimr.edu.au>
References: <002301cac3ef$95254c10$bf6fe430$@safari@flinders.edu.au>
	<Pine.LNX.4.64.1003151431360.14802@orpheus.qimr.edu.au>
Message-ID: <BC4FA7B4-0FBF-4CE4-B306-A9DBC59E5960@ed.ac.uk>

Hi Alex/David,

The insertPed function from MasterBayes can be used to insert the  
missing records, and then it should run fine. prunePed is also useful  
for removing pedigree members which don't contribute any information  
to the analysis.

Cheers,

Jarrod





On 15 Mar 2010, at 04:35, David Duffy wrote:

> On Mon, 15 Mar 2010, Alex Safari wrote:
>
>> Dear all,
>>
>> Running a simple animal model with MCMCglmm  the following error  
>> occurred.
>> Error in inverse (pedigree, nodes = nodes, scale = scale) :
>> individuals appearing as dams but not in pedigree
>> I run this data with ASReml and it is working ok.
>
> I believe ASReml might automatically add in the missing pedigree  
> members (who appear as a parent but do not have their own record in  
> your pedigree).  MCMCglmm's Ainverse() requires the pedigree to be  
> complete.
>
> Cheers, David Duffy.
>
> -- 
> | David Duffy (MBBS PhD)                                         ,-_|\
> | email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax:  
> -0101  /     *
> | Epidemiology Unit, Queensland Institute of Medical Research    
> \_,-._/
> | 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From Vincent.Kint at ees.kuleuven.be  Mon Mar 15 10:44:24 2010
From: Vincent.Kint at ees.kuleuven.be (Vincent Kint)
Date: Mon, 15 Mar 2010 10:44:24 +0100
Subject: [R-sig-ME] significance test of random and fixed effects in
	(quasi)	 poisson GLMM
In-Reply-To: <4B9B8EA1.5572.00B2.0@lshtm.ac.uk>
References: <mailman.5.1268478002.991.r-sig-mixed-models@r-project.org>,
	<4B9B8EA1.5572.00B2.0@lshtm.ac.uk>
Message-ID: <562EA47F252E594B826D3B440E0B34A21288E58045@ICTS-S-EXC2-CA.luna.kuleuven.be>

Dear Antonio and list members,

Thanks for the reply. The problem with quasi GLMM in lme4 seems to have been reported several times. As you suggested, I tried with glmmPQL, but I don't find how to retreive the overdispersion factor (it is not in the summary). Also, I don't see any difference using poisson or quasipoisson. Does that mean that this method is correcting for overdispersion in both cases?

Further suggestions on how to test fixed and radom factors in GLMMs are still welcome.

Regards,
Vincent

________________________________________
From: Antonio.Gasparrini at lshtm.ac.uk [Antonio.Gasparrini at lshtm.ac.uk]
Sent: 13 March 2010 14:09
To: r-sig-mixed-models at r-project.org
Cc: Vincent Kint
Subject: Re: significance test of random and fixed effects in (quasi)    poisson GLMM

Dear Vincent,

some time ago I posted a question on Poisson GLMM for overdispersed
data, including a simple simulation in order to compare the reliability
of glmmPQL and glmer.
See
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q1/003289.html


While glmmPQL returns the correct estimates, glmer largely
overestimated the sigma (corresponding to the overdispersion), producing
an inflated within-group residual variance.
This odd behaviour seems to be confirmed by your analysis.

As pointed out in the response I had to my question, the quasi-Poisson
is not a distribution and the results are not grounded on an appropriate
statistical theory. Anyway, as in your case, the quasipoisson family is
currently used and I would expect the command to return (approximate)
correct results.

My suggestion is to repeat the analysis with glmmPQL, even if this
doesn't solve your problem to run a test. To my knowledge, the
approximation used by the penalized quasi-likelihood method is
reasonable for Poisson data and a moderate number of counts (McCulloch &
Searle say with mean count of 7 or higher). Interestingly, the command
always estimates the sigma (not fixed to 1 as in Poisson) even with the
simple poisson family.

I hope this helps

Antonio Gasparrini
Public and Environmental Health Research Unit (PEHRU)
London School of Hygiene & Tropical Medicine
Keppel Street, London WC1E 7HT, UK
Office: 0044 (0)20 79272406 - Mobile: 0044 (0)79 64925523

------------------------------

Message: 3
Date: Fri, 12 Mar 2010 15:46:23 +0100
From: Vincent Kint <Vincent.Kint at ees.kuleuven.be>
To: "r-sig-mixed-models at r-project.org"
<r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] significance test of random and fixed effects in
(quasi) poisson GLMM
Message-ID:
<562EA47F252E594B826D3B440E0B34A21288E5803C at ICTS-S-EXC2-CA.luna.kuleuven.be>

Content-Type: text/plain

Dear list members,

I am new to this list, and new to generalised mixed modelling.

My aim is to develop a model for tree branchiness (number of branches
per tree, with trees measured in different plots) with both tree and
plot-level predictors. My choice was for a generalised model using the
poisson family, since I have count data. And for a mixed approach since
I have a nested design.

I built a first model using the lme4 package (see below). My question
is: is there an approximate test for the significance of the random
effect? From previous posts on this list, I understand that such a test
is not always reliable, and good alternatives are not implemented yet.
But from my perspective of an applied modeller, even an approximate test
(or even a rule of thumb) would be helpful in making a decision. Indeed,
if the random effect turns out to be likely not significant, I could do
with a more simple GLM.

In a second step I tried to correct for overdispersion by running the
same model as a quasi GLMM. The output is also given below. Here I have
the same question as before, but now also concerning the fixed effects.
Additionally, I wonder whether I may have made a mistake in implementing
this model, since I get a result where nearly all the variation is
attributed to the error term, and (at a first glance) the random effect
and all the fixed predictors seem to be irrelevant.

I attach the output of both models below.
Thanks for all suggestions on how to proceed.
Vincent


#1. The GLMM model
> form1<-formula(response ~ TreeHeight + DBH + TreeAge + Vplot + mF +
mL + (1 | plots))
> M.glmm<-lmer(form1, data=data, family=poisson)
> summary(M.glmm)
Generalized linear mixed model fit by the Laplace approximation
Formula: form1
   Data: data
AIC  BIC logLik deviance
976 1008   -480      960
Random effects:
Groups Name        Variance Std.Dev.
plots  (Intercept) 0.044913 0.21193
Number of obs: 399, groups: plots, 30

Fixed effects:
              Estimate Std. Error z value Pr(>|z|)
(Intercept)  6.0090427  1.4143768   4.249 2.15e-05 ***
TreeHeight  -0.0398146  0.0125816  -3.165 0.001553 **
DBH          0.0032600  0.0006599   4.940 7.80e-07 ***
TreeAge     -0.1193541  0.0242996  -4.912 9.03e-07 ***
Vplot       -0.0060713  0.0016115  -3.768 0.000165 ***
mF          -0.4838699  0.1672462  -2.893 0.003814 **
mL           0.4878563  0.1731139   2.818 0.004831 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.?
0.1 ? ? 1



#2. The same GLMM model with overdispersion
> M.glmm.q<-lmer(form1, data=data, family=quasipoisson)
> summary(M.glmm.q)
Generalized linear mixed model fit by the Laplace approximation
Formula: form1
   Data: data
AIC  BIC logLik deviance
978 1014   -480      960
Random effects:
Groups   Name        Variance Std.Dev.
plots    (Intercept)  1.6478  1.2837
Residual             36.6894  6.0572
Number of obs: 399, groups: plots, 30

Fixed effects:
             Estimate Std. Error t value
(Intercept)  6.009043   8.567129   0.701
TreeHeight  -0.039815   0.076209  -0.522
DBH          0.003260   0.003997   0.816
TreeAge     -0.119354   0.147187  -0.811
Vplot       -0.006071   0.009761  -0.622
mF          -0.483870   1.013039  -0.478
mL           0.487856   1.048581   0.465

_____________________________________
dr. ir. V. KINT
Forest Ecology and Management
Division Forest, Nature and Landscape
K.U.Leuven
Celestijnenlaan 200E - B-3001 Leuven
Tel.: +32 16 32 97 69
Fax:  +32 16 32 97 60
vincent.kint at ees.kuleuven.be

www.kuleuven.be/forecoman<http://www.kuleuven.be/forecoman>

[[alternative HTML version deleted]]


From Antonio.Gasparrini at lshtm.ac.uk  Mon Mar 15 13:40:32 2010
From: Antonio.Gasparrini at lshtm.ac.uk (Antonio.Gasparrini at lshtm.ac.uk)
Date: Mon, 15 Mar 2010 12:40:32 +0000
Subject: [R-sig-ME] significance test of random and fixed effects in
	(quasi)	 poisson GLMM
In-Reply-To: <mailman.3.1268650801.6727.r-sig-mixed-models@r-project.org>
References: <mailman.3.1268650801.6727.r-sig-mixed-models@r-project.org>
Message-ID: <4B9E2AC5.5572.00B2.1@lshtm.ac.uk>

I guess the overdispersion parameter is equivalent to the sigma (within-group residual variance), which can be retrieved simply typing 'model$sigma' where 'model' is a glmmPQL object. I ran some analysis with alternatives models based on GAM and the estimate is coherent with the overdispersion parameter returned by them. Just remember that the phi (overdispersion parameter) is equal to sigma^2.
The estimates from glmmPQL seem coherent both in my analysis on real data and from simulations.
 
As already reported, glmmPQL always estimates a sigma (overdispersion) both with family 'poisson' or 'quasipoisson'. I think this is a problem related to the iterative calls to 'lme' for simple linear mixed models, where the sigma is not a fixed parameter as in Poisson models.
 
Regards,

Antonio Gasparrini
Public and Environmental Health Research Unit (PEHRU)
London School of Hygiene & Tropical Medicine
Keppel Street, London WC1E 7HT, UK
Office: 0044 (0)20 79272406 - Mobile: 0044 (0)79 64925523


>>> r-sig-mixed-models-request at r-project.org> 15/03/2010 11:00 >> ( mailto:r-sig-mixed-models-request at r-project.org> )

Message: 1
Date: Mon, 15 Mar 2010 10:44:24 +0100
From: Vincent Kint <Vincent.Kint at ees.kuleuven.be>
To: "r-sig-mixed-models at r-project.org"
<r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] significance test of random and fixed effects
in(quasi) poisson GLMM
Message-ID:
<562EA47F252E594B826D3B440E0B34A21288E58045 at ICTS-S-EXC2-CA.luna.kuleuven.be>

Content-Type: text/plain; charset="Windows-1252"

Dear Antonio and list members,

Thanks for the reply. The problem with quasi GLMM in lme4 seems to have been reported several times. As you suggested, I tried with glmmPQL, but I don't find how to retreive the overdispersion factor (it is not in the summary). Also, I don't see any difference using poisson or quasipoisson. Does that mean that this method is correcting for overdispersion in both cases?

Further suggestions on how to test fixed and radom factors in GLMMs are still welcome.

Regards,
Vincent

________________________________________
From: Antonio.Gasparrini at lshtm.ac.uk [Antonio.Gasparrini at lshtm.ac.uk] 
Sent: 13 March 2010 14:09
To: r-sig-mixed-models at r-project.org 
Cc: Vincent Kint
Subject: Re: significance test of random and fixed effects in (quasi)    poisson GLMM

Dear Vincent,

some time ago I posted a question on Poisson GLMM for overdispersed
data, including a simple simulation in order to compare the reliability
of glmmPQL and glmer.
See
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q1/003289.html 


While glmmPQL returns the correct estimates, glmer largely
overestimated the sigma (corresponding to the overdispersion), producing
an inflated within-group residual variance.
This odd behaviour seems to be confirmed by your analysis.

As pointed out in the response I had to my question, the quasi-Poisson
is not a distribution and the results are not grounded on an appropriate
statistical theory. Anyway, as in your case, the quasipoisson family is
currently used and I would expect the command to return (approximate)
correct results.

My suggestion is to repeat the analysis with glmmPQL, even if this
doesn't solve your problem to run a test. To my knowledge, the
approximation used by the penalized quasi-likelihood method is
reasonable for Poisson data and a moderate number of counts (McCulloch &
Searle say with mean count of 7 or higher). Interestingly, the command
always estimates the sigma (not fixed to 1 as in Poisson) even with the
simple poisson family.

I hope this helps

Antonio Gasparrini
Public and Environmental Health Research Unit (PEHRU)
London School of Hygiene & Tropical Medicine
Keppel Street, London WC1E 7HT, UK
Office: 0044 (0)20 79272406 - Mobile: 0044 (0)79 64925523

------------------------------

Message: 3
Date: Fri, 12 Mar 2010 15:46:23 +0100
From: Vincent Kint <Vincent.Kint at ees.kuleuven.be>
To: "r-sig-mixed-models at r-project.org"
<r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] significance test of random and fixed effects in
(quasi) poisson GLMM
Message-ID:
<562EA47F252E594B826D3B440E0B34A21288E5803C at ICTS-S-EXC2-CA.luna.kuleuven.be>

Content-Type: text/plain

Dear list members,

I am new to this list, and new to generalised mixed modelling.

My aim is to develop a model for tree branchiness (number of branches
per tree, with trees measured in different plots) with both tree and
plot-level predictors. My choice was for a generalised model using the
poisson family, since I have count data. And for a mixed approach since
I have a nested design.

I built a first model using the lme4 package (see below). My question
is: is there an approximate test for the significance of the random
effect? From previous posts on this list, I understand that such a test
is not always reliable, and good alternatives are not implemented yet.
But from my perspective of an applied modeller, even an approximate test
(or even a rule of thumb) would be helpful in making a decision. Indeed,
if the random effect turns out to be likely not significant, I could do
with a more simple GLM.

In a second step I tried to correct for overdispersion by running the
same model as a quasi GLMM. The output is also given below. Here I have
the same question as before, but now also concerning the fixed effects.
Additionally, I wonder whether I may have made a mistake in implementing
this model, since I get a result where nearly all the variation is
attributed to the error term, and (at a first glance) the random effect
and all the fixed predictors seem to be irrelevant.

I attach the output of both models below.
Thanks for all suggestions on how to proceed.
Vincent


#1. The GLMM model
> form1<-formula(response ~ TreeHeight + DBH + TreeAge + Vplot + mF +
mL + (1 | plots))
> M.glmm<-lmer(form1, data=data, family=poisson)
> summary(M.glmm)
Generalized linear mixed model fit by the Laplace approximation
Formula: form1
   Data: data
AIC  BIC logLik deviance
976 1008   -480      960
Random effects:
Groups Name        Variance Std.Dev.
plots  (Intercept) 0.044913 0.21193
Number of obs: 399, groups: plots, 30

Fixed effects:
              Estimate Std. Error z value Pr(>|z|)
(Intercept)  6.0090427  1.4143768   4.249 2.15e-05 ***
TreeHeight  -0.0398146  0.0125816  -3.165 0.001553 **
DBH          0.0032600  0.0006599   4.940 7.80e-07 ***
TreeAge     -0.1193541  0.0242996  -4.912 9.03e-07 ***
Vplot       -0.0060713  0.0016115  -3.768 0.000165 ***
mF          -0.4838699  0.1672462  -2.893 0.003814 **
mL           0.4878563  0.1731139   2.818 0.004831 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.?
0.1 ? ? 1



#2. The same GLMM model with overdispersion
> M.glmm.q<-lmer(form1, data=data, family=quasipoisson)
> summary(M.glmm.q)
Generalized linear mixed model fit by the Laplace approximation
Formula: form1
   Data: data
AIC  BIC logLik deviance
978 1014   -480      960
Random effects:
Groups   Name        Variance Std.Dev.
plots    (Intercept)  1.6478  1.2837
Residual             36.6894  6.0572
Number of obs: 399, groups: plots, 30

Fixed effects:
             Estimate Std. Error t value
(Intercept)  6.009043   8.567129   0.701
TreeHeight  -0.039815   0.076209  -0.522
DBH          0.003260   0.003997   0.816
TreeAge     -0.119354   0.147187  -0.811
Vplot       -0.006071   0.009761  -0.622
mF          -0.483870   1.013039  -0.478
mL           0.487856   1.048581   0.465

_____________________________________
dr. ir. V. KINT
Forest Ecology and Management
Division Forest, Nature and Landscape
K.U.Leuven
Celestijnenlaan 200E - B-3001 Leuven
Tel.: +32 16 32 97 69
Fax:  +32 16 32 97 60
vincent.kint at ees.kuleuven.be 

www.kuleuven.be/forecoman<http://www.kuleuven.be/forecoman>

[[alternative HTML version deleted]]


------------------------------

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org 
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models 


End of R-sig-mixed-models Digest, Vol 39, Issue 23



From mhighfield106 at googlemail.com  Mon Mar 15 16:15:19 2010
From: mhighfield106 at googlemail.com (martin highfield)
Date: Mon, 15 Mar 2010 15:15:19 +0000
Subject: [R-sig-ME] residuals from glmm using lmer
Message-ID: <c9b63d771003150815t36e04b20s4ce02ce8bf82ed0b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100315/631da34d/attachment.pl>

From bolker at ufl.edu  Tue Mar 16 01:59:31 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 16 Mar 2010 00:59:31 +0000 (UTC)
Subject: [R-sig-ME] residuals from glmm using lmer
References: <c9b63d771003150815t36e04b20s4ce02ce8bf82ed0b@mail.gmail.com>
Message-ID: <loom.20100316T015211-661@post.gmane.org>

martin highfield <mhighfield106 at ...> writes:

> 
> Dear all
> 
> I am trying to validate a GLMM using plots of residuals versus fitted values
> and other explanatory variables. However, I am unsure what type of residuals
> (or fitted values) are returned when using the residuals function on a lmer
> object. My data and model are similar to the example given below  where I
> have a binary response variable (y) , a continous explanatory (day) ,a two
> level nominal explanatory variable (treat) and a random effect of group ( 5
> groups).
> 
> set.seed(100)
> y <- rbinom(n=100, size=1, prob=0.5)
> day <- sample(1:10, 100, replace=T)
> group <- rep(paste("group", 1:5, sep=""), times=20)
> treat <- sample(c("T1", "T2"), 100, replace=T)
> 
> dataf <- data.frame(y,day,treat, group)
> library(lme4)
> mod.lmer <- lmer(y~day+treat+(1|group), family=binomial, data=dataf)
> summary(mod.lmer)
> 
> I can extract the residuals and fitted values using the residuals and fitted
> extractor functions and plot them.
> 
> res <- residuals(mod.lmer)
> fit <- fitted(mod.lmer)
> 
> plot(fit,res)
> abline(h=0)
> plot(res~dataf$treat)
> plot(res~dataf$day)
> 
> However, what do these residuals represent? Are they simply the observed
> minus the fitted values, Pearsons residuals (y_i - mu_i /sqrt(mu_i)),
> deviance residuals etc? 

  You can convince yourself that they're the Pearson residuals
(which are NOT what you've quoted here -- you've quoted the Pearson
residuals for the Poisson case [and I think you're missing parentheses?])

head(res)
head(y-fit)  ## not the same as res
est.sd <- sqrt(fit*(1-fit))
head((y-fit)/est.sd)   ## the same as res


> Also, I would like to extract both the residuals
> conditional on the random effect and also the residuals based on both the
> fixed and random effects but am unsure how to do this. Any
> advice/clarification would be gratefully appreciated.

  fitted() gives you the unconditional (fixed+random) estimates.
  
  Don't have time to work it out now, but you can construct your
own fixed- and random-effect predictions by constructing the appropriate
model matrices and multiplying by the random effects (ranef())
and fixed effect parameter (fixef()) vectors ...

  By the way, since you didn't add any group-level variation
to your example above, all the random effects are zero ...



From gregor.gorjanc at bfro.uni-lj.si  Tue Mar 16 23:07:58 2010
From: gregor.gorjanc at bfro.uni-lj.si (Gregor GORJANC)
Date: Tue, 16 Mar 2010 23:07:58 +0100
Subject: [R-sig-ME] Fwd: [R-pkgs] New package: ordinal
In-Reply-To: <4949c7e61003160345q19bc9ec7y732200fa09dac208@mail.gmail.com>
References: <4949c7e61003160345q19bc9ec7y732200fa09dac208@mail.gmail.com>
Message-ID: <b20ae6291003161507ua4f3a51r61e64c1baa3e858f@mail.gmail.com>

Hi,

This should be of interest to many on this list.

Regards, gg

---------- Forwarded message ----------
From: Rune Haubo <rhbc at imm.dtu.dk>
Date: 16 March 2010 11:45
Subject: [R-pkgs] New package: ordinal
To: r-packages at r-project.org


This is to announce the new R-package ?ordinal? that implements
cumulative link (mixed) models for ordinal (ordered categorical) data
(http://www.cran.r-project.org/package=ordinal/).

The main features are:
- ? ? ? scale (multiplicative) as well as location (additive) effects
- ? ? ? nominal effects for a subset of the predictors (denoted partial
proportional odds when the link is the logistic)
- ? ? ? structured thresholds, e.g. assuming symmetry or equidistant thresholds
- ? ? ? random effects via the Laplace approximation and adaptive
Gauss-Hermite quadrature in the location-part of the model.
- ? ? ? a range of standard link functions
- ? ? ? flexible link functions where an extra link function-parameter
bridges the log-log, probit and c-loglog links (log-gamma), and
cloglog and logistic links (Aranda-Ordaz)
- ? ? ? a suite of optimizers including an efficient Newton scheme.
- ? ? ? works for binomial observations (a special case of ordinal data).
- ? ? ? a suite of methods including anova, addterm, dropterm, profile,
confint, plot.profile, predict, in addition to the standard print and
summary methods.
- ? ? ? an important special case is the proportional odds model (with
random effects).
- ? ? ? a range of examples illustrates how to use the functions.

Future additions will include:
- ? ? ? more general random effect structures: multiple (crossed and nested)
and vector-valued random effects.
- ? ? ? profile methods for variance parameters in mixed effect models.
- ? ? ? helpful package vignettes.
- ? ? ? implementation of core functions in C.

Comments, critique, suggestions, wishes and contributions are always
highly appreciated.

Kind regards
Rune

--
Rune Haubo Bojesen Christensen

PhD student, M.Sc. Eng.
Phone: (+45) 45 25 33 63
Mail: rhbc at imm.dtu.dk

DTU Informatics, Section for Statistics
Technical University of Denmark, Build. 305, Room 122,
DK-2800 Kgs. Lyngby, Denmark

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages



-- 
-- 
Lep pozdrav / With regards,
    Gregor Gorjanc
----------------------------------------------------------------------
University of Ljubljana
Biotechnical Faculty        www: http://sites.google.com/site/gregorgorjanc
Zootechnical Department     blog: http://ggorjan.blogspot.com
Groblje 3                   mail: gregor.gorjanc <at> bf.uni-lj.si
SI-1230 Domzale             fax: +386 (0)1 72 17 888
Slovenia, Europe            tel: +386 (0)1 72 17 861



From David.Duffy at qimr.edu.au  Wed Mar 17 02:43:51 2010
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Wed, 17 Mar 2010 11:43:51 +1000 (EST)
Subject: [R-sig-ME] Fwd: [R-pkgs] New package: ordinal
In-Reply-To: <b20ae6291003161507ua4f3a51r61e64c1baa3e858f@mail.gmail.com>
References: <4949c7e61003160345q19bc9ec7y732200fa09dac208@mail.gmail.com>
	<b20ae6291003161507ua4f3a51r61e64c1baa3e858f@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1003171138470.8790@orpheus.qimr.edu.au>

On Tue, 16 Mar 2010, Gregor GORJANC wrote:

> Hi,
> This should be of interest to many on this list.

It does look yummy ;)  I might add, for people who are not aware of it, 
that you can fit ordinal mixed models with crossed effects in R using the
OpenMx package (http://openmx.psyc.virginia.edu/).  It doesn't seem
to be on CRAN (it is Apache licensed, so maybe that is the reason).

Cheers, David Duffy.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From kingsfordjones at gmail.com  Wed Mar 17 03:56:00 2010
From: kingsfordjones at gmail.com (Kingsford Jones)
Date: Tue, 16 Mar 2010 20:56:00 -0600
Subject: [R-sig-ME] Mixed/Hierarchical/Multilevel Modeling packages in R
Message-ID: <2ad0cc111003161956u1b4523bfgb0dfdf73b843a6ac@mail.gmail.com>

Today's post about the ordinal package inspired a search of the CRAN
packages page for the words 'mixed', 'multilevel', and 'hierarchical',
turning up an impressive list of packages (pasted below).  I'm sure
there are others on and off CRAN (e.g. the ordinal and MASS packages
didn't show up via this search, and of course neither did off-CRAN
packages OpenMx and glmmADMB).  Has anyone put together or seen a more
comprehensive summary, or have additions to the list?  Seems a Task
View would be useful, but unfortunately I can't volunteer at the
moment...

best,
Kingsford Jones

###
Mixed modeling packages found 2010-03-16 on
http://cran.r-project.org/web/packages/
###

amer -- Additive mixed models with lme4

arm -- Data Analysis Using Regression and Multilevel/Hierarchical Models

coxme -- Mixed Effects Cox Models

gamm4 -- Generalized additive mixed models using mgcv and lme4

GLMMarp -- Generalized Linear Multilevel Model with AR(p) Errors Package

glmmAK -- Generalized Linear Mixed Models

glmmBUGS -- Generalised Linear Mixed Models and Spatial Models with BUGS

heavy -- Estimation in the linear mixed model using heavy-tailed distributions

hglm -- hglm is used to fit hierarchical generalized linear models

HGLMMM -- Hierarchical Generalized Linear Models

influence.ME -- Tools for detecting influential data in mixed effects models

kinship -- mixed-effects Cox models, sparse matrices, and modeling
data from large pedigrees

lme4 -- Linear mixed-effects models using S4 classes

lmeSplines -- lmeSplines

lmec -- Linear Mixed-Effects Models with Censored Responses

lmm -- Linear mixed models

longRPart -- Recursive partitioning of longitudinal data using
mixed-effects models

MASS -- Main Package of Venables and Ripley's MASS (see function glmmPQL)

MCMCglmm -- MCMC Generalised Linear Mixed Models

MEMSS -- Data sets from Mixed-effects Models in S

mlmRev -- Examples from Multilevel Modelling Software Review

multilevel -- Multilevel Functions

nlme -- Linear and Nonlinear Mixed Effects Models

nlmeODE -- Non-linear mixed-effects modelling in nlme using
differential equations

npde -- Normalised prediction distribution errors for nonlinear
mixed-effect models

ordinal -- Regression Models for Ordinal Data

PSM -- Non-Linear Mixed-Effects modelling using Stochastic
Differential Equations

pamm -- Power analysis for random effects in mixed models

pedigreemm -- Pedigree-based mixed-effects models

phmm -- Proportional Hazards Mixed-effects Model (PHMM)

RLRsim -- Exact (Restricted) Likelihood Ratio tests for mixed and
additive models

SASmixed -- Data sets from "SAS System for Mixed Models"


###
Off-CRAN mixed modeling packages:
###

glmmADMB -- Mixed models for discrete data in R

OpenMx -- Advanced Structural Equation Modeling



From mhighfield106 at googlemail.com  Wed Mar 17 12:49:34 2010
From: mhighfield106 at googlemail.com (martin highfield)
Date: Wed, 17 Mar 2010 11:49:34 +0000
Subject: [R-sig-ME] residuals from glmm using lmer
In-Reply-To: <loom.20100316T015211-661@post.gmane.org>
References: <c9b63d771003150815t36e04b20s4ce02ce8bf82ed0b@mail.gmail.com>
	<loom.20100316T015211-661@post.gmane.org>
Message-ID: <c9b63d771003170449t5cf5a7ch72444688bc45b518@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100317/4470194b/attachment.pl>

From Eli.Kvingedal at nina.no  Wed Mar 17 16:12:25 2010
From: Eli.Kvingedal at nina.no (Kvingedal, Eli)
Date: Wed, 17 Mar 2010 15:12:25 +0000
Subject: [R-sig-ME] mixed effects models and pseudo replication
In-Reply-To: <9a8a6c631003100701n228bd329r843a91d1d9031fe2@mail.gmail.com>
References: <B9DC40CECBB1E4439A25B59A2D6A6B030439A6@NINSRV05.nina.no>
	<9a8a6c631003100701n228bd329r843a91d1d9031fe2@mail.gmail.com>
Message-ID: <B9DC40CECBB1E4439A25B59A2D6A6B0307DB47@NINSRV05.nina.no>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100317/6ba108a7/attachment.pl>

From pauljohn32 at gmail.com  Wed Mar 17 19:15:35 2010
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Wed, 17 Mar 2010 13:15:35 -0500
Subject: [R-sig-ME] Fwd: [R-pkgs] New package: ordinal
In-Reply-To: <Pine.LNX.4.64.1003171138470.8790@orpheus.qimr.edu.au>
References: <4949c7e61003160345q19bc9ec7y732200fa09dac208@mail.gmail.com>
	<b20ae6291003161507ua4f3a51r61e64c1baa3e858f@mail.gmail.com>
	<Pine.LNX.4.64.1003171138470.8790@orpheus.qimr.edu.au>
Message-ID: <13e802631003171115p67456a7l4d7851a1b7fce55d@mail.gmail.com>

On Tue, Mar 16, 2010 at 8:43 PM, David Duffy <David.Duffy at qimr.edu.au> wrote:
> On Tue, 16 Mar 2010, Gregor GORJANC wrote:
>
>> Hi,
>> This should be of interest to many on this list.
>
> It does look yummy ;) ?I might add, for people who are not aware of it, that
> you can fit ordinal mixed models with crossed effects in R using the
> OpenMx package (http://openmx.psyc.virginia.edu/). ?It doesn't seem
> to be on CRAN (it is Apache licensed, so maybe that is the reason).
>

I've been monitoring OpenMx too.  That project has very high-reaching
aspirations.  If it all comes together, it will offer the only truly
comprehensive R package to replace commercial SEM software like Mplus.

I don't think OpenMx can be distributed on CRAN, though.  OpenMx
relies on a proprietary library npsol that they distribute as a
compiled library (no source).  As far as I can tell, this means it can
never be distributed over CRAN.  If you need to see what I mean, grab
the tar.gz for OpenMx and look

./inst/npsol
./inst/npsol/windows/x86/rtools2.10/libnpsol.dll
./inst/npsol/windows/x86/rtools2.9/libnpsol.dll
./inst/npsol/osx/libnpsol.a
./inst/npsol/linux/x86/gcc3.9/libnpsol.a
./inst/npsol/linux/x86/gcc4.4/libnpsol.a
./inst/npsol/linux/x86/gcc4.3/libnpsol.a
./inst/npsol/linux/x86/gcc4.1/libnpsol.a
./inst/npsol/linux/x86/gcc3.4/libnpsol.a
./inst/npsol/linux/x86_64/gcc4.2/libnpsol.a
./inst/npsol/linux/x86_64/gcc3.9/libnpsol.a
./inst/npsol/linux/x86_64/gcc4.4/libnpsol.a
./inst/npsol/linux/x86_64/gcc4.3/libnpsol.a
./inst/npsol/linux/x86_64/gcc4.1/libnpsol.a
./inst/npsol/linux/x86_64/gcc3.4/libnpsol.a

If they have not built a version of libnpsol.a for your system, then
OpenMx cannot be built on your system.  Unless you buy npsol,  you
can't compile OpenMx.   I don't know what benefits npsol has over
other R system solvers.

I'd be interested to hear back from other people who've tested out
OpenMx.  I suppose r-sig-mixed is as good as any other venue for that
discussion.

:)

-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas



From ken.knoblauch at inserm.fr  Thu Mar 18 15:41:43 2010
From: ken.knoblauch at inserm.fr (Ken Knoblauch)
Date: Thu, 18 Mar 2010 15:41:43 +0100
Subject: [R-sig-ME] anova in lmer modifies REML to ML
Message-ID: <20100318154143.50pfjdpcg8s8wccs@imp.inserm.fr>

Hi,

I noticed that the AIC, BIC, etc. returned in printing
an object obtained by fitting with lmer with the default
REML method differ from those returned by  comparing two "mer"
objects with anova.  It looks as if the anova method
automatically uses the ML rather than the REML estimates.
In addition, in Ch. 2 of the online draft of
"lme4: Mixed-effects Modeling with R" on R-Forge,
all of the models that are compared using anova are fit
with the argument "REML = 0", even though only the random
effects vary across models.  I understand from reading
Pinheiro & Bates that fits using the REML criterion with
different fixed effects  structure cannot be compared because
of the  lack of invariance across one-to-one transformations,
but that REML fits can be compared if the fixed effects
structure does not change (p. 83 of P&B).  If I haven't
gotten anything wrong above, my question is whether
the behavior of anova, transforming to ML, is on purpose,
for example, to safeguard against those of us who might
try to compare REML fits with different fixed effects,
or perhaps the comparisons of the ML fits are preferred
even when only the random effects have been modified?
I didn't see (haven't quite finished it yet) any mention
of this behavior in the book draft and didn't find this
described on the help pages (but I may have missed something,
too), which is why I'm wondering if this is the intended
behavior.  Thank you.

A short example demonstrating this follows, using an online
data set that I have been working.

library(lme4)

###get the data and put it into long format
site <- "http://vision.arc.nasa.gov/modelfest/data/modelfestbaselinedata.csv"
  ModelFest <- read.csv(site, header = FALSE)
  Obs <- ModelFest$V1
  ModelFest.df <- data.frame(LContSens = c(t(ModelFest[, -1])),
	Obs = rep(Obs, each = ncol(ModelFest) - 1),
	Stim = rep(paste("Stim", 1:43, sep = ""), each = 4)
	)
ModelFest.df$Stim <- with(ModelFest.df, factor(Stim,
		levels = unique(Stim)))

mf1.lmer <- lmer(LContSens ~ Stim + (1 | Obs),
	ModelFest.df)
mf2.lmer <- update(mf1.lmer, . ~ . + (1 | Obs:Stim))

summary(mf1.lmer)@AICtab
summary(mf2.lmer)@AICtab
anova(mf1.lmer, mf2.lmer)
summary(update(mf1.lmer, REML = 0))@AICtab
summary(update(mf2.lmer, REML = 0))@AICtab


Ken


sessionInfo()
R version 2.10.1 Patched (2010-03-10 r51250)
i386-apple-darwin9.8.0

locale:
[1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods
[7] base

other attached packages:
[1] lme4_0.999375-32   Matrix_0.999375-38 lattice_0.18-3

loaded via a namespace (and not attached):
[1] grid_2.10.1  tools_2.10.1




-- 
Ken Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html



From bates at stat.wisc.edu  Thu Mar 18 19:01:07 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 18 Mar 2010 13:01:07 -0500
Subject: [R-sig-ME] Query lme4
In-Reply-To: <4BA24D19.40804@qub.ac.uk>
References: <4BA24D19.40804@qub.ac.uk>
Message-ID: <40e66e0b1003181101o580b9915t5803bb857f3a0af6@mail.gmail.com>

On Thu, Mar 18, 2010 at 10:56 AM, Lisa McCrink <lmccrink01 at qub.ac.uk> wrote:
> Dear Douglas Bates,

> I am a research student at Queen's University, Belfast and I am currently
> researching methods to analyse longitudinal data through the use of mixed
> models. I am interested in using the R package lme4. The syntax I am using
> to fit my model is the following,

> model.1<-lmer(eGFR_IDMS~AGEACTUAL+(AGEACTUAL|Individual),data=sample,REML=FALSE)

> I was wondering would you be able to tell me what covariance structure this
> package uses when it models the random effects using the above syntax and if
> it is possible to use a compound symmetry and autoregressive covariance
> structure to model the random effects through this package. Any help you
> could give me would be much appreciated.

The phrase "covariance structure" can mean different things in the
context of mixed models.  The covariance structure of the random
effects for such a model is a block-diagonal matrix of size 2N x 2N
where N is the number of individuals.  There are N diagonal blocks,
each of which is a copy of the 2 x 2 matrix that is returned by
VarCorr(model.1).

Since you mention an autoregressive structure I assume you are
considering the marginal covariance structure of the response vector.
To evaluate that you need to know the model matrix for the random
effects.  The within individual covariance structure is of the form

Z_i %*% D %*% Z_i' + sigma^2 I

where Z_i is the two-column model matrix for the i'th individual and D
is the 2 x 2 variance-covariance matrix returned by VarCorr(model.1),
sigma is the residual standard error and I is the n_i x n_i identity
matrix.

The marginal variance-covariance matrix for the model with random
effects specification (1|individual) has a compound symmetry
structure.

The lme4 package does not have capabilities of modeling an
autoregressive structure.  In most cases of longitudinal data it would
be very difficult to distinguish between an autoregressive structure
and a model with random effects specification (AGEACTUAL|Individual).

I have taken the liberty of copying the
R-SIG-mixed-models at R-project.org mailing list on this reply.  It is
usually more effective to send such queries to that list rather than
to me personally as sometimes I take a while to respond.


> Kind Regards,
>
> Lisa McCrink
>



From moskante at gmail.com  Fri Mar 19 10:19:13 2010
From: moskante at gmail.com (Alessandro Moscatelli)
Date: Fri, 19 Mar 2010 10:19:13 +0100
Subject: [R-sig-ME] cloglog link
Message-ID: <9446f1c91003190219y3f3e7e5ai2b28c0099541a7fd@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100319/2c367436/attachment.pl>

From bolker at ufl.edu  Fri Mar 19 19:03:41 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Fri, 19 Mar 2010 14:03:41 -0400
Subject: [R-sig-ME] cloglog and lmer
In-Reply-To: <e6820af21003191041l1ff5dacbtf109846d4eee4ea5@mail.gmail.com>
References: <4AC51F46.70101@ufl.edu>	
	<e6820af20910011446o1e18dcfckd812236c91ef3f88@mail.gmail.com>	
	<e6820af20911031548l5d6836b5n7054fb98bf329a37@mail.gmail.com>
	<e6820af21003191041l1ff5dacbtf109846d4eee4ea5@mail.gmail.com>
Message-ID: <4BA3BC7D.4080504@ufl.edu>

   Hmmm.  Can you remind me what didn't work?
  Examples below give at least vaguely plausible answers ...

  cheers
    Ben Bolker

set.seed(1001)

N <- 20
n <- 100
x <- runif(N*n)
f <- factor(rep(LETTERS[1:N],each=n))
dat <- data.frame(x,f)

beta <- c(1,3)
alpha <- rnorm(N,sd=0.5)

mm <- cbind(model.matrix(~x,data=dat),
            model.matrix(~f-1,data=dat))

eta <- mm %*% c(beta,alpha)
y <- rbinom(N*n,prob=1-exp(-exp(eta)),size=1)
dat <- data.frame(dat,y)

library(lme4)
(g1 <- glmer(y~x+(1|f),data=dat,
      family=binomial(link="cloglog")))

fixef(g1)  ## matches (1,3) reasonably well
VarCorr(g1) ## matches sd=0.5 reasonably well

## now try crossed random effects
set.seed(1001)  ## reset
N1 <- 10
N2 <- 10
n <-  20
ntot <- n*N1*N2
dat <- expand.grid(f1=LETTERS[1:N1],f2=letters[1:N2],rep=1:n)
dat <- data.frame(dat,x=runif(ntot))
alpha1 <- rnorm(N1,sd=0.5)
alpha2 <- rnorm(N2,sd=1)

mm <- cbind(model.matrix(~x,data=dat),
            model.matrix(~f1-1,data=dat),
            model.matrix(~f2-1,data=dat))

eta <- mm %*% c(beta,alpha1,alpha2)
y <- rbinom(ntot,prob=1-exp(-exp(eta)),size=1)

(g2 <- glmer(y~x+(1|f1)+(1|f2),data=dat,
      family=binomial(link="cloglog")))

## warning about false convergence
fixef(g2) ## still OK.
VarCorr(g2)  ## reasonable but ??



Sasha Goodman wrote:
> Bump. So what was your solution to the cloglog issue? Has it been fixed
> in lme4?
> 
> Other people keep asking me about this issue.
> 
> On Tue, Nov 3, 2009 at 4:48 PM, Sasha Goodman <sashag at stanford.edu
> <mailto:sashag at stanford.edu>> wrote:
> 
>     So, I want to use the cloglog link. Is your solution working now?
>     Does it worked with crossed random effects?
> 
> 
>     On Thu, Oct 1, 2009 at 1:46 PM, Sasha Goodman <sashag at stanford.edu
>     <mailto:sashag at stanford.edu>> wrote:
> 
>         Very interested! Never came up with a solution. Even retried
>         with a recent version of lme4 recently.
> 
> 
>         On Thu, Oct 1, 2009 at 2:29 PM, Ben Bolker <bolker at ufl.edu
>         <mailto:bolker at ufl.edu>> wrote:
> 
> 
>              I came across your post to the r-sig-mixed list from May.
>              Did you ever resolve your problem?  I may have a solution
>             (of sorts)
>             if you're still interested.
> 
>              Ben Bolker
> 
>             --
>             Ben Bolker
>             Associate professor, Biology Dep't, Univ. of Florida
>             bolker at ufl.edu <mailto:bolker at ufl.edu> /
>             www.zoology.ufl.edu/bolker <http://www.zoology.ufl.edu/bolker>
>             GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>             <http://www.zoology.ufl.edu/bolker/benbolker-publickey.asc>
> 
> 
> 
> 
>         -- 
>         Sasha Goodman
>         Doctoral Candidate, Organizational Behavior
> 
> 
> 
> 
>     -- 
>     Sasha Goodman
>     Doctoral Candidate, Organizational Behavior
> 
> 
> 
> 
> -- 
> Sasha Goodman
> Doctoral Candidate, Organizational Behavior


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From bolker at ufl.edu  Fri Mar 19 20:25:44 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Fri, 19 Mar 2010 15:25:44 -0400
Subject: [R-sig-ME] cloglog and lmer
In-Reply-To: <e6820af21003191150w15a73483vf7168ad2a4a06fc3@mail.gmail.com>
References: <4AC51F46.70101@ufl.edu>	
	<e6820af20910011446o1e18dcfckd812236c91ef3f88@mail.gmail.com>	
	<e6820af20911031548l5d6836b5n7054fb98bf329a37@mail.gmail.com>	
	<e6820af21003191041l1ff5dacbtf109846d4eee4ea5@mail.gmail.com>	
	<4BA3BC7D.4080504@ufl.edu>	
	<e6820af21003191146la44a373x1432c842e4389d43@mail.gmail.com>
	<e6820af21003191150w15a73483vf7168ad2a4a06fc3@mail.gmail.com>
Message-ID: <4BA3CFB8.5050406@ufl.edu>

  What are the results of sessionInfo() ?

  I am using a slightly hacked version of lme4, but I don't *think* that
any of my hacks should affect the functioning of cloglog.

  You ran exactly the toy code example that I provided, right?

  It's possible that this problem is right on the edge of numerical
tractability and thus that there are some tiny platform-dependent
differences that lead to a probability estimate that is very small on
one platform and exactly 0 (due to underflow) on another platform,
triggering the error.

  In fact the error message you got

... mu = 9.35952e-313, i = 1068030290 ...

  suggests this may be the case -- although I don't see how mu =
9.3592e-313 is triggering a (mui<=0 || mui>1) flag ...

  It also suggests there may be another bug in the reporting because I
doubt there are really 1068030290 cases in the data.

  However, there were some old bugs of this type that do not appear in
the current (at least in the development) version of lme4, so I strongly
recommend that you at least check to see if you have the latest released
version, and perhaps switch to the development version
(install.packages("lme4",repos="http://r-forge.r-project.org")).

  It might also be nice if (but this is definitely a can of worms with
reasonable arguments in either direction) lme4 could be tolerant of mu
values on the borders of the allowed region or (???) slightly beyond it,
so that optimizations could proceed to a final answer that might not be
at those boundaries.

  cheers
    Ben Bolker


>


> sessionInfo()
R version 2.10.1 (2009-12-14)
i486-pc-linux-gnu

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999375-32-2 Matrix_0.999375-38 lattice_0.18-3

loaded via a namespace (and not attached):
[1] grid_2.10.1



Sasha Goodman wrote:
> I just tried your toy code with crossed random effects, and got the
> following error when using glmer
> 
> "Error in mer_finalize(ans) :
>   mu[i] must be in the range (0,1): mu = 9.35952e-313, i = 1068030290"
> 
> No model was ever fit, so the following happened:
> 
> fixef(g2)
> Error: object 'g2' not found
> 
> This is exactly the problem I was having before.
> 
> 
> 
> On Fri, Mar 19, 2010 at 11:46 AM, Sasha Goodman <sashag at stanford.edu
> <mailto:sashag at stanford.edu>> wrote:
> 
>     Ben, thanks for getting back to me. 
>     The problem was with crossed random effects and cloglog. 
> 
> 
>     There was a strange error:
>     "mu[i] must be in the range (0,1)"
> 
>     Here is the original post:
> 
> 
> 
>     ..........
>     We have been using lme4 with a logit link and crossed random effects.
>     It works very nicely. However, because our outcome is very rare, we
>     are trying the cloglog link with lmer. The model simply does not run,
> 
> 
>     however. The errors is  "mu[i] must be in the range (0,1)". A google
>     search reveals no one else has ever posted this particular problem.
> 
>     I'm sending the following details in case it helps the developers.
> 
> 
>     Advice is also welcomed.
> 
>     Descriptives for the two variables:
>     Y: [0,1], ? R, E=0.007238727, SE=0.08477285, the binary response
>     X : [0.4318617,0.998886], ? R, E=0.9886799, SE=0.03572924, continuous
>     in the range  [0.4318617,0.998886]
> 
> 
> 
>     ## Crossed with cloglog fails
>     h = lmer(Y ~ X + (1 | i) + (1 | j) + (1|t), D2 ,family =
>     binomial(link="cloglog"),control = list(msVerbose = 1))
>       0:     5328.8713: 0.100868 0.0552843 0.00896829 -35.7191  31.0045
> 
> 
>     Error in mer_finalize(ans) :
>       mu[i] must be in the range (0,1): mu = 0, i = 253517704
> 
>     ## Crossed with logit works
>     h = lmer(Y ~ X + (1 | i) + (1 | j) + (1|t), D2 ,family =
>     binomial(link="logit"),control = list(msVerbose = 1))
> 
> 
>     summary(h)
>     Generalized linear mixed model fit by the Laplace approximation
>     Formula: Y ~ X + (1 | i) + (1 | j) + (1 | t)
>        Data: D2
>       AIC  BIC logLik deviance
>      1797 1843 -893.5     1787
>     Random effects:
> 
> 
>      Groups Name        Variance Std.Dev.
>      j      (Intercept)  17.9346  4.2349
>      i      (Intercept) 126.9971 11.2693
>      t      (Intercept)   2.6644  1.6323
>     Number of obs: 66310, groups: j, 253; i, 76; t, 2
> 
>     Fixed effects:
> 
> 
>                 Estimate Std. Error z value Pr(>|z|)
>     (Intercept)   -81.38      19.29  -4.219 2.46e-05 ***
>     X                  60.91      19.26   3.162  0.00157 **
>     ---
>     Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> 
> 
> 
> 
>     ## Simple GLM with the same data runs perfectly
>     h = glm(Y ~ X , D2 ,family = binomial(link="cloglog"))
> 
>     glm(formula = Y ~ X, family = binomial(link = "cloglog"),
>         data = D2)
> 
> 
> 
>     Deviance Residuals:
>         Min       1Q   Median       3Q      Max
>     -0.1316  -0.1271  -0.1270  -0.1212   3.9149
> 
>     Coefficients:
>                 Estimate Std. Error z value Pr(>|z|)
>     (Intercept)  -35.719      6.833  -5.228 1.72e-07 ***
> 
> 
>     X               31.004      6.869   4.514 6.37e-06 ***
>     ---
>     Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
>     (Dispersion parameter for binomial family taken to be 1)
> 
>         Null deviance: 5687.7  on 66309  degrees of freedom
> 
> 
>     Residual deviance: 5643.9  on 66308  degrees of freedom
>     AIC: 5647.9
> 
>     Number of Fisher Scoring iterations: 10
> 
> 
> 
>     On Fri, Mar 19, 2010 at 11:03 AM, Ben Bolker <bolker at ufl.edu
>     <mailto:bolker at ufl.edu>> wrote:
> 
>           Hmmm.  Can you remind me what didn't work?
>          Examples below give at least vaguely plausible answers ...
> 
>          cheers
>            Ben Bolker
> 
>         set.seed(1001)
> 
>         N <- 20
>         n <- 100
>         x <- runif(N*n)
>         f <- factor(rep(LETTERS[1:N],each=n))
>         dat <- data.frame(x,f)
> 
>         beta <- c(1,3)
>         alpha <- rnorm(N,sd=0.5)
> 
>         mm <- cbind(model.matrix(~x,data=dat),
>                    model.matrix(~f-1,data=dat))
> 
>         eta <- mm %*% c(beta,alpha)
>         y <- rbinom(N*n,prob=1-exp(-exp(eta)),size=1)
>         dat <- data.frame(dat,y)
> 
>         library(lme4)
>         (g1 <- glmer(y~x+(1|f),data=dat,
>              family=binomial(link="cloglog")))
> 
>         fixef(g1)  ## matches (1,3) reasonably well
>         VarCorr(g1) ## matches sd=0.5 reasonably well
> 
>         ## now try crossed random effects
>         set.seed(1001)  ## reset
>         N1 <- 10
>         N2 <- 10
>         n <-  20
>         ntot <- n*N1*N2
>         dat <- expand.grid(f1=LETTERS[1:N1],f2=letters[1:N2],rep=1:n)
>         dat <- data.frame(dat,x=runif(ntot))
>         alpha1 <- rnorm(N1,sd=0.5)
>         alpha2 <- rnorm(N2,sd=1)
> 
>         mm <- cbind(model.matrix(~x,data=dat),
>                    model.matrix(~f1-1,data=dat),
>                    model.matrix(~f2-1,data=dat))
> 
>         eta <- mm %*% c(beta,alpha1,alpha2)
>         y <- rbinom(ntot,prob=1-exp(-exp(eta)),size=1)
> 
>         (g2 <- glmer(y~x+(1|f1)+(1|f2),data=dat,
>              family=binomial(link="cloglog")))
> 
>         ## warning about false convergence
>         fixef(g2) ## still OK.
>         VarCorr(g2)  ## reasonable but ??
> 
> 
> 
>         Sasha Goodman wrote:
>         > Bump. So what was your solution to the cloglog issue? Has it
>         been fixed
>         > in lme4?
>         >
>         > Other people keep asking me about this issue.
>         >
>         > On Tue, Nov 3, 2009 at 4:48 PM, Sasha Goodman
>         <sashag at stanford.edu <mailto:sashag at stanford.edu>
>         > <mailto:sashag at stanford.edu <mailto:sashag at stanford.edu>>> wrote:
>         >
>         >     So, I want to use the cloglog link. Is your solution
>         working now?
>         >     Does it worked with crossed random effects?
>         >
>         >
>         >     On Thu, Oct 1, 2009 at 1:46 PM, Sasha Goodman
>         <sashag at stanford.edu <mailto:sashag at stanford.edu>
>         >     <mailto:sashag at stanford.edu <mailto:sashag at stanford.edu>>>
>         wrote:
>         >
>         >         Very interested! Never came up with a solution. Even
>         retried
>         >         with a recent version of lme4 recently.
>         >
>         >
>         >         On Thu, Oct 1, 2009 at 2:29 PM, Ben Bolker
>         <bolker at ufl.edu <mailto:bolker at ufl.edu>
>         >         <mailto:bolker at ufl.edu <mailto:bolker at ufl.edu>>> wrote:
>         >
>         >
>         >              I came across your post to the r-sig-mixed list
>         from May.
>         >              Did you ever resolve your problem?  I may have a
>         solution
>         >             (of sorts)
>         >             if you're still interested.
>         >
>         >              Ben Bolker
>         >
>         >             --
>         >             Ben Bolker
>         >             Associate professor, Biology Dep't, Univ. of Florida
>         >             bolker at ufl.edu <mailto:bolker at ufl.edu>
>         <mailto:bolker at ufl.edu <mailto:bolker at ufl.edu>> /
>         >             www.zoology.ufl.edu/bolker
>         <http://www.zoology.ufl.edu/bolker>
>         <http://www.zoology.ufl.edu/bolker>
>         >             GPG key:
>         www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>         <http://www.zoology.ufl.edu/bolker/benbolker-publickey.asc>
>         >            
>         <http://www.zoology.ufl.edu/bolker/benbolker-publickey.asc>
>         >
>         >
>         >
>         >
>         >         --
>         >         Sasha Goodman
>         >         Doctoral Candidate, Organizational Behavior
>         >
>         >
>         >
>         >
>         >     --
>         >     Sasha Goodman
>         >     Doctoral Candidate, Organizational Behavior
>         >
>         >
>         >
>         >
>         > --
>         > Sasha Goodman
>         > Doctoral Candidate, Organizational Behavior
> 
> 
>         --
>         Ben Bolker
>         Associate professor, Biology Dep't, Univ. of Florida
>         bolker at ufl.edu <mailto:bolker at ufl.edu> /
>         people.biology.ufl.edu/bolker <http://people.biology.ufl.edu/bolker>
>         GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc
>         <http://people.biology.ufl.edu/bolker/benbolker-publickey.asc>
> 
> 
> 
> 
>     -- 
>     Sasha Goodman
>     Doctoral Candidate, Organizational Behavior
> 
> 
> 
> 
> -- 
> Sasha Goodman
> Doctoral Candidate, Organizational Behavior


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From lborger at uoguelph.ca  Fri Mar 19 20:46:32 2010
From: lborger at uoguelph.ca (Luca Borger)
Date: Fri, 19 Mar 2010 15:46:32 -0400
Subject: [R-sig-ME] cloglog and lmer
References: <4AC51F46.70101@ufl.edu>	<e6820af20910011446o1e18dcfckd812236c91ef3f88@mail.gmail.com>	<e6820af20911031548l5d6836b5n7054fb98bf329a37@mail.gmail.com>	<e6820af21003191041l1ff5dacbtf109846d4eee4ea5@mail.gmail.com>	<4BA3BC7D.4080504@ufl.edu>	<e6820af21003191146la44a373x1432c842e4389d43@mail.gmail.com><e6820af21003191150w15a73483vf7168ad2a4a06fc3@mail.gmail.com>
	<4BA3CFB8.5050406@ufl.edu>
Message-ID: <ECA18FBCFAAF41CBBD1DDB6E352F3B2B@lborger>

Hello,

in case this is useful, I tried it out (exact same code, only added 
"verbose=TRUE") and got the same error message as Sasha (using the latest 
released lme4 version on CRAN, I believe):

####################################################################
> library(lme4)
> (g1 <- glmer(y~x+(1|f),data=dat,
+       family=binomial(link="cloglog"),verbose=TRUE))
  0:     267.35545: 0.163299 0.728061  2.49517
Error in mer_finalize(ans) :
  mu[i] must be in the range (0,1): mu = 5.70618e-316, i = 115478304
>


> (g2 <- glmer(y~x+(1|f1)+(1|f2),data=dat,
+       family=binomial(link="cloglog"),verbose=TRUE))
  0:     693.88107: 0.115470 0.115470 0.364870  1.73946
Error in mer_finalize(ans) :
  mu[i] must be in the range (0,1): mu = 9.34227e-313, i = 115155608
>

> sessionInfo()
R version 2.10.1 (2009-12-14)
i386-pc-mingw32

locale:
[1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United 
Kingdom.1252    LC_MONETARY=English_United Kingdom.1252
[4] LC_NUMERIC=C                            LC_TIME=English_United 
Kingdom.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999375-32   Matrix_0.999375-37 lattice_0.18-3

loaded via a namespace (and not attached):
[1] grid_2.10.1
>
####################################################################


Cheers,

Luca


---------------------------
Luca B?rger, PhD
Postdoctoral Research Fellow
Department of Integrative Biology
University of Guelph
Guelph, Ontario, Canada N1G 2W1



----- Original Message ----- 
From: "Ben Bolker" <bolker at ufl.edu>
To: "Sasha Goodman" <sashag at stanford.edu>; "R Mixed Models" 
<r-sig-mixed-models at r-project.org>
Sent: Friday, March 19, 2010 3:25 PM
Subject: Re: [R-sig-ME] cloglog and lmer


>  What are the results of sessionInfo() ?
>
>  I am using a slightly hacked version of lme4, but I don't *think* that
> any of my hacks should affect the functioning of cloglog.
>
>  You ran exactly the toy code example that I provided, right?
>
>  It's possible that this problem is right on the edge of numerical
> tractability and thus that there are some tiny platform-dependent
> differences that lead to a probability estimate that is very small on
> one platform and exactly 0 (due to underflow) on another platform,
> triggering the error.
>
>  In fact the error message you got
>
> ... mu = 9.35952e-313, i = 1068030290 ...
>
>  suggests this may be the case -- although I don't see how mu =
> 9.3592e-313 is triggering a (mui<=0 || mui>1) flag ...
>
>  It also suggests there may be another bug in the reporting because I
> doubt there are really 1068030290 cases in the data.
>
>  However, there were some old bugs of this type that do not appear in
> the current (at least in the development) version of lme4, so I strongly
> recommend that you at least check to see if you have the latest released
> version, and perhaps switch to the development version
> (install.packages("lme4",repos="http://r-forge.r-project.org")).
>
>  It might also be nice if (but this is definitely a can of worms with
> reasonable arguments in either direction) lme4 could be tolerant of mu
> values on the borders of the allowed region or (???) slightly beyond it,
> so that optimizations could proceed to a final answer that might not be
> at those boundaries.
>
>  cheers
>    Ben Bolker
>
>
>>
>
>
>> sessionInfo()
> R version 2.10.1 (2009-12-14)
> i486-pc-linux-gnu
>
> locale:
> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
> [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8
> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
> [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] lme4_0.999375-32-2 Matrix_0.999375-38 lattice_0.18-3
>
> loaded via a namespace (and not attached):
> [1] grid_2.10.1
>
>
>
> Sasha Goodman wrote:
>> I just tried your toy code with crossed random effects, and got the
>> following error when using glmer
>>
>> "Error in mer_finalize(ans) :
>>   mu[i] must be in the range (0,1): mu = 9.35952e-313, i = 1068030290"
>>
>> No model was ever fit, so the following happened:
>>
>> fixef(g2)
>> Error: object 'g2' not found
>>
>> This is exactly the problem I was having before.
>>
>>
>>
>> On Fri, Mar 19, 2010 at 11:46 AM, Sasha Goodman <sashag at stanford.edu
>> <mailto:sashag at stanford.edu>> wrote:
>>
>>     Ben, thanks for getting back to me.
>>     The problem was with crossed random effects and cloglog.
>>
>>
>>     There was a strange error:
>>     "mu[i] must be in the range (0,1)"
>>
>>     Here is the original post:
>>
>>
>>
>>     ..........
>>     We have been using lme4 with a logit link and crossed random effects.
>>     It works very nicely. However, because our outcome is very rare, we
>>     are trying the cloglog link with lmer. The model simply does not run,
>>
>>
>>     however. The errors is  "mu[i] must be in the range (0,1)". A google
>>     search reveals no one else has ever posted this particular problem.
>>
>>     I'm sending the following details in case it helps the developers.
>>
>>
>>     Advice is also welcomed.
>>
>>     Descriptives for the two variables:
>>     Y: [0,1], ? R, E=0.007238727, SE=0.08477285, the binary response
>>     X : [0.4318617,0.998886], ? R, E=0.9886799, SE=0.03572924, continuous
>>     in the range  [0.4318617,0.998886]
>>
>>
>>
>>     ## Crossed with cloglog fails
>>     h = lmer(Y ~ X + (1 | i) + (1 | j) + (1|t), D2 ,family =
>>     binomial(link="cloglog"),control = list(msVerbose = 1))
>>       0:     5328.8713: 0.100868 0.0552843 0.00896829 -35.7191  31.0045
>>
>>
>>     Error in mer_finalize(ans) :
>>       mu[i] must be in the range (0,1): mu = 0, i = 253517704
>>
>>     ## Crossed with logit works
>>     h = lmer(Y ~ X + (1 | i) + (1 | j) + (1|t), D2 ,family =
>>     binomial(link="logit"),control = list(msVerbose = 1))
>>
>>
>>     summary(h)
>>     Generalized linear mixed model fit by the Laplace approximation
>>     Formula: Y ~ X + (1 | i) + (1 | j) + (1 | t)
>>        Data: D2
>>       AIC  BIC logLik deviance
>>      1797 1843 -893.5     1787
>>     Random effects:
>>
>>
>>      Groups Name        Variance Std.Dev.
>>      j      (Intercept)  17.9346  4.2349
>>      i      (Intercept) 126.9971 11.2693
>>      t      (Intercept)   2.6644  1.6323
>>     Number of obs: 66310, groups: j, 253; i, 76; t, 2
>>
>>     Fixed effects:
>>
>>
>>                 Estimate Std. Error z value Pr(>|z|)
>>     (Intercept)   -81.38      19.29  -4.219 2.46e-05 ***
>>     X                  60.91      19.26   3.162  0.00157 **
>>     ---
>>     Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>>
>>
>>
>>
>>     ## Simple GLM with the same data runs perfectly
>>     h = glm(Y ~ X , D2 ,family = binomial(link="cloglog"))
>>
>>     glm(formula = Y ~ X, family = binomial(link = "cloglog"),
>>         data = D2)
>>
>>
>>
>>     Deviance Residuals:
>>         Min       1Q   Median       3Q      Max
>>     -0.1316  -0.1271  -0.1270  -0.1212   3.9149
>>
>>     Coefficients:
>>                 Estimate Std. Error z value Pr(>|z|)
>>     (Intercept)  -35.719      6.833  -5.228 1.72e-07 ***
>>
>>
>>     X               31.004      6.869   4.514 6.37e-06 ***
>>     ---
>>     Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>>     (Dispersion parameter for binomial family taken to be 1)
>>
>>         Null deviance: 5687.7  on 66309  degrees of freedom
>>
>>
>>     Residual deviance: 5643.9  on 66308  degrees of freedom
>>     AIC: 5647.9
>>
>>     Number of Fisher Scoring iterations: 10
>>
>>
>>
>>     On Fri, Mar 19, 2010 at 11:03 AM, Ben Bolker <bolker at ufl.edu
>>     <mailto:bolker at ufl.edu>> wrote:
>>
>>           Hmmm.  Can you remind me what didn't work?
>>          Examples below give at least vaguely plausible answers ...
>>
>>          cheers
>>            Ben Bolker
>>
>>         set.seed(1001)
>>
>>         N <- 20
>>         n <- 100
>>         x <- runif(N*n)
>>         f <- factor(rep(LETTERS[1:N],each=n))
>>         dat <- data.frame(x,f)
>>
>>         beta <- c(1,3)
>>         alpha <- rnorm(N,sd=0.5)
>>
>>         mm <- cbind(model.matrix(~x,data=dat),
>>                    model.matrix(~f-1,data=dat))
>>
>>         eta <- mm %*% c(beta,alpha)
>>         y <- rbinom(N*n,prob=1-exp(-exp(eta)),size=1)
>>         dat <- data.frame(dat,y)
>>
>>         library(lme4)
>>         (g1 <- glmer(y~x+(1|f),data=dat,
>>              family=binomial(link="cloglog")))
>>
>>         fixef(g1)  ## matches (1,3) reasonably well
>>         VarCorr(g1) ## matches sd=0.5 reasonably well
>>
>>         ## now try crossed random effects
>>         set.seed(1001)  ## reset
>>         N1 <- 10
>>         N2 <- 10
>>         n <-  20
>>         ntot <- n*N1*N2
>>         dat <- expand.grid(f1=LETTERS[1:N1],f2=letters[1:N2],rep=1:n)
>>         dat <- data.frame(dat,x=runif(ntot))
>>         alpha1 <- rnorm(N1,sd=0.5)
>>         alpha2 <- rnorm(N2,sd=1)
>>
>>         mm <- cbind(model.matrix(~x,data=dat),
>>                    model.matrix(~f1-1,data=dat),
>>                    model.matrix(~f2-1,data=dat))
>>
>>         eta <- mm %*% c(beta,alpha1,alpha2)
>>         y <- rbinom(ntot,prob=1-exp(-exp(eta)),size=1)
>>
>>         (g2 <- glmer(y~x+(1|f1)+(1|f2),data=dat,
>>              family=binomial(link="cloglog")))
>>
>>         ## warning about false convergence
>>         fixef(g2) ## still OK.
>>         VarCorr(g2)  ## reasonable but ??
>>
>>
>>
>>         Sasha Goodman wrote:
>>         > Bump. So what was your solution to the cloglog issue? Has it
>>         been fixed
>>         > in lme4?
>>         >
>>         > Other people keep asking me about this issue.
>>         >
>>         > On Tue, Nov 3, 2009 at 4:48 PM, Sasha Goodman
>>         <sashag at stanford.edu <mailto:sashag at stanford.edu>
>>         > <mailto:sashag at stanford.edu <mailto:sashag at stanford.edu>>> 
>> wrote:
>>         >
>>         >     So, I want to use the cloglog link. Is your solution
>>         working now?
>>         >     Does it worked with crossed random effects?
>>         >
>>         >
>>         >     On Thu, Oct 1, 2009 at 1:46 PM, Sasha Goodman
>>         <sashag at stanford.edu <mailto:sashag at stanford.edu>
>>         >     <mailto:sashag at stanford.edu <mailto:sashag at stanford.edu>>>
>>         wrote:
>>         >
>>         >         Very interested! Never came up with a solution. Even
>>         retried
>>         >         with a recent version of lme4 recently.
>>         >
>>         >
>>         >         On Thu, Oct 1, 2009 at 2:29 PM, Ben Bolker
>>         <bolker at ufl.edu <mailto:bolker at ufl.edu>
>>         >         <mailto:bolker at ufl.edu <mailto:bolker at ufl.edu>>> wrote:
>>         >
>>         >
>>         >              I came across your post to the r-sig-mixed list
>>         from May.
>>         >              Did you ever resolve your problem?  I may have a
>>         solution
>>         >             (of sorts)
>>         >             if you're still interested.
>>         >
>>         >              Ben Bolker
>>         >
>>         >             --
>>         >             Ben Bolker
>>         >             Associate professor, Biology Dep't, Univ. of 
>> Florida
>>         >             bolker at ufl.edu <mailto:bolker at ufl.edu>
>>         <mailto:bolker at ufl.edu <mailto:bolker at ufl.edu>> /
>>         >             www.zoology.ufl.edu/bolker
>>         <http://www.zoology.ufl.edu/bolker>
>>         <http://www.zoology.ufl.edu/bolker>
>>         >             GPG key:
>>         www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>>         <http://www.zoology.ufl.edu/bolker/benbolker-publickey.asc>
>>         >
>>         <http://www.zoology.ufl.edu/bolker/benbolker-publickey.asc>
>>         >
>>         >
>>         >
>>         >
>>         >         --
>>         >         Sasha Goodman
>>         >         Doctoral Candidate, Organizational Behavior
>>         >
>>         >
>>         >
>>         >
>>         >     --
>>         >     Sasha Goodman
>>         >     Doctoral Candidate, Organizational Behavior
>>         >
>>         >
>>         >
>>         >
>>         > --
>>         > Sasha Goodman
>>         > Doctoral Candidate, Organizational Behavior
>>
>>
>>         --
>>         Ben Bolker
>>         Associate professor, Biology Dep't, Univ. of Florida
>>         bolker at ufl.edu <mailto:bolker at ufl.edu> /
>>         people.biology.ufl.edu/bolker 
>> <http://people.biology.ufl.edu/bolker>
>>         GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc
>>         <http://people.biology.ufl.edu/bolker/benbolker-publickey.asc>
>>
>>
>>
>>
>>     -- 
>>     Sasha Goodman
>>     Doctoral Candidate, Organizational Behavior
>>
>>
>>
>>
>> -- 
>> Sasha Goodman
>> Doctoral Candidate, Organizational Behavior
>
>
> -- 
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / people.biology.ufl.edu/bolker
> GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bolker at ufl.edu  Fri Mar 19 20:50:01 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Fri, 19 Mar 2010 15:50:01 -0400
Subject: [R-sig-ME] worked example & FAQ
Message-ID: <4BA3D569.7040001@ufl.edu>


  I've posted a new worked example to
<http://glmm.wikidot.com/examples>, which analyzes some data on owlet
begging behavior (from Roulin and Bersier 2007 by way of Zuur et al
2009) -- it shows among other things how to compute predicted values and
standard errors for glmer fits.

  Perhaps against my better judgment, I also started a draft of a FAQ
list -- see

http://glmm.wikidot.com/faq

  Feel free to make suggestions about what to include (OK), how to
improve what's there (better), or (best) sign in and edit it yourself ...

  happy friday.

-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From elizabeth.crone at cfc.umt.edu  Fri Mar 19 23:13:41 2010
From: elizabeth.crone at cfc.umt.edu (Elizabeth Crone)
Date: Fri, 19 Mar 2010 16:13:41 -0600
Subject: [R-sig-ME] Query lme4
In-Reply-To: <mailman.3.1268996402.31489.r-sig-mixed-models@r-project.org>
References: <mailman.3.1268996402.31489.r-sig-mixed-models@r-project.org>
Message-ID: <FDE3381E3E2B9945BDA9105DBBE2D60803052E3B7D7E@pangaea.cfc.umt.edu>

> In most cases of longitudinal data it would
> be very difficult to distinguish between an autoregressive structure
> and a model with random effects specification (AGEACTUAL|Individual).

I think this is true if observations are POSTIVELY autocorrelated, but the random individual effects should be separable from NEGATIVE autocorrelations, right? [This posting caught my eye because I have been wishing I could use something like lme4 to fit mixed models to data with strong negative autocorrelations, specifically, probability of flowering for plants that flower approximately in alternate years.]



From bolker at ufl.edu  Sat Mar 20 23:02:04 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Sat, 20 Mar 2010 18:02:04 -0400
Subject: [R-sig-ME] Query lme4
In-Reply-To: <FDE3381E3E2B9945BDA9105DBBE2D60803052E3B7D7E@pangaea.cfc.umt.edu>
References: <mailman.3.1268996402.31489.r-sig-mixed-models@r-project.org>
	<FDE3381E3E2B9945BDA9105DBBE2D60803052E3B7D7E@pangaea.cfc.umt.edu>
Message-ID: <4BA545DC.8060904@ufl.edu>

Elizabeth Crone wrote:
>> In most cases of longitudinal data it would be very difficult to
>> distinguish between an autoregressive structure and a model with
>> random effects specification (AGEACTUAL|Individual).

  Hmm.  Is this true if there are sufficient data?  That is, shouldn't
autocorrelated variation within an individual be detectable even if
there is a linear trend within individuals?  (Isn't this what the
corARxx structures in nlme are for?)

> 
> I think this is true if observations are POSTIVELY autocorrelated,
> but the random individual effects should be separable from NEGATIVE
> autocorrelations, right? [This posting caught my eye because I have
> been wishing I could use something like lme4 to fit mixed models to
> data with strong negative autocorrelations, specifically, probability
> of flowering for plants that flower approximately in alternate
> years.]

  You probably have to do this in WinBUGS etc. for the foreseeable
future.  The good news is that it's reasonably easy to write down a
structure that should produce this, i.e. something like

   X[indiv,time] ~ Binomial(p_indiv(t))
   logit(p_indiv(t)) ~ Normal(a+b*p_indiv(t-1)+...,tau)

  where ... could include covariates, random (but persistent)
among-individual variation, etc..  If -1<b<0 then you get population
dynamics with negative autocorrelation.


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From bolker at ufl.edu  Sun Mar 21 17:35:17 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Sun, 21 Mar 2010 12:35:17 -0400
Subject: [R-sig-ME] [R-sig-eco] general lineal mixed model with
	unbalanced data
In-Reply-To: <SNT141-w42D908D34C1CA95A5FFC1DAC280@phx.gbl>
References: <mailman.1.1267959601.19611.r-sig-ecology@r-project.org>
	<SNT141-w42D908D34C1CA95A5FFC1DAC280@phx.gbl>
Message-ID: <4BA64AC5.6000205@ufl.edu>


David Douterlungne wrote:
> 
> 
> Hi al, 
> 
> 
> I am trying
> to fit a general lineal mixed modal to a small unbalanced dataset of countdata
> (poisson errors). My model would be: 
> 
> 
> glmer(indep~dep1+dep2+dep3+dep4+dep5+(1|random1)+(1|random2),family=
> 
> poisson,data)
> 
>  
> 
> Error en
> asMethod(object) : matrix is not symmetric [1,2]
> 
> Adem?s: Mensajes de aviso perdidos
> 
> 1: In mer_finalize(ans) :
> 
>   Cholmod warning 'not positive definite' at
> file:../Cholesky/t_cholmod_rowfac.c, line 432
> 
> 2: In
> mer_finalize(ans) :
> 
>   Cholmod warning 'not positive definite' at
> file:../Cholesky/t_cholmod_rowfac.c, line 432
> 
> 3: In
> mer_finalize(ans) : false convergence (8)
> 
>  
> 
> That
> isn?t a surprising R-answer, as lmer doesn?t work with several crossed (not
> nested) random factors if errors are not Gaussian. 

   What makes you say this?  I posted an example in the last couple of
days (search for "cloglog") that works.  Perhaps you are thinking of the
fact that glmer doesn't work with adaptive Gauss-Hermite quadrature
('nAGQ'>1) with multiple random factors?

> I read about a mysterious" hacked version of glmer to allow
> per-observation random effects" in Zuur et al, 2009?
> 
> Any one
> knows if there is (already) a function that does the job? 
> Are
> there any best alternatives?

  Can you post a reproducible example?

  You say you have a 'small' data set -- I strongly suspect you are
overfitting (you are trying to fit 5 fixed factors -- even if these are
all continuous, or treatments with only two levels, you should have at
least 50 data points to have a reasonable hope of fitting the model, and
that's not counting random effects).

  If one of your random effects is per-observation you should get an
error stating that you have >= as many as random-effect levels as
observations, but you shouldn't get an obscure error (such as "matrix is
not symmetric") as long as your model is well-defined, even if it's too
much to fit from your data.  Doug Bates has hinted that he's thinking
about relaxing the (observations > random-effect levels) restriction for
glmer ... but you probably need to worry first about whether you can
plausibly fit this model to your data set.

  The easiest thing to do at present for individual-level random effects
is to use MCMCglmm instead -- it adds an individual-level random effect
level by default.



From bolker at ufl.edu  Mon Mar 22 01:25:21 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Sun, 21 Mar 2010 20:25:21 -0400
Subject: [R-sig-ME] [R] Problem specifying Gamma distribution in
	lme4/glmer
In-Reply-To: <7740B3D1-F709-414C-90F3-5885E11E2F37@comcast.net>
References: <3da23281003201554x2df00a9cw6e2dac28d6d8636a@mail.gmail.com>
	<loom.20100321T155551-701@post.gmane.org>
	<1269187217065-1676746.post@n4.nabble.com>
	<loom.20100321T221531-295@post.gmane.org>
	<7740B3D1-F709-414C-90F3-5885E11E2F37@comcast.net>
Message-ID: <4BA6B8F1.40800@ufl.edu>

  [Moving this to r-sig-mixed-models ]

David Winsemius wrote:
> On Mar 21, 2010, at 5:16 PM, Ben Bolker wrote:
> 
>> Dieter Menne <dieter.menne <at> menne-biomed.de> writes:
>>
>>> Ben Bolker wrote:
>>>> 3. zero-inflated data may not be particularly well-represented
>>>> by a Gamma distribution: if you actually have a significant number
>>>> of exactly-zero values, you may want to analyze your data in two
>>>> stages, first as a presence-absence problem and then as a  
>>>> conditional
>>>> density (i.e., what is the distribution of the non-zero values)?
>>> [...] Do you know of a example where this was done (independent
>>> of lmer)?  [...]
>>  Nothing springs to mind, but it seems sensible.
> 
> I thought this was what hurdle and ZIF models were supposed to handle  
> gracefully?

  hurdle/zero-inflated/zero-altered models are typically developed in
the context of discrete (count) data, where the base model has some
non-zero probability of recording a zero and has to be altered to
account for the presence of extra (or missing) zeros.  In this case
(continuous data) the gamma distribution has an infinitesimal
probability of producing an exact zero, so it's actually easier to deal
with the data as a mixture of zeros (with probability p) and
Gamma-distributed values (with shape and scale or rate parameters
specified).  If it's OK to model the mixture process and the conditional
density separately this is actually easier than a hurdle or ZIF model.

  Another possibility, which I've heard of but not ever looked at
carefully, would be to use Tweedie distributions with 1<p<2:

http://en.wikipedia.org/wiki/Tweedie_distributions
http://cran.r-project.org/web/packages/tweedie/index.html

  Incorporating random effects could be tricky, though: a mean-variance
relationship is given for Tweedie distributions (V = phi*mu^p), so
conceivably the fitting could be done as a two-dimensional search over
the GLMM fits obtained for fixed values of (phi,p).  (Yikes.)

  Ben



-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From pdalgd at gmail.com  Mon Mar 22 11:50:39 2010
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 22 Mar 2010 11:50:39 +0100
Subject: [R-sig-ME] Query lme4
In-Reply-To: <4BA545DC.8060904@ufl.edu>
References: <mailman.3.1268996402.31489.r-sig-mixed-models@r-project.org>
	<FDE3381E3E2B9945BDA9105DBBE2D60803052E3B7D7E@pangaea.cfc.umt.edu>
	<4BA545DC.8060904@ufl.edu>
Message-ID: <D2D3D4D9-276D-4704-B409-85A8EAD4AE5F@gmail.com>


On Mar 20, 2010, at 11:02 PM, Ben Bolker wrote:

> Elizabeth Crone wrote:
(well, citing Doug, actually...)
>>> In most cases of longitudinal data it would be very difficult to
>>> distinguish between an autoregressive structure and a model with
>>> random effects specification (AGEACTUAL|Individual).
> 
>  Hmm.  Is this true if there are sufficient data?  That is, shouldn't
> autocorrelated variation within an individual be detectable even if
> there is a linear trend within individuals?  (Isn't this what the
> corARxx structures in nlme are for?)

Yes. I was also a bit surprised about that remark. I'm fairly sure I have seen examples where the tell-tale decline of intra-individual correlations with distance in time was quite visible in data. I don't think you can do that with a random-slope model.

> 
>> 
>> I think this is true if observations are POSTIVELY autocorrelated,
>> but the random individual effects should be separable from NEGATIVE
>> autocorrelations, right? [This posting caught my eye because I have
>> been wishing I could use something like lme4 to fit mixed models to
>> data with strong negative autocorrelations, specifically, probability
>> of flowering for plants that flower approximately in alternate
>> years.]
> 
>  You probably have to do this in WinBUGS etc. for the foreseeable
> future.  The good news is that it's reasonably easy to write down a
> structure that should produce this, i.e. something like
> 
>   X[indiv,time] ~ Binomial(p_indiv(t))
>   logit(p_indiv(t)) ~ Normal(a+b*p_indiv(t-1)+...,tau)
> 
>  where ... could include covariates, random (but persistent)
> among-individual variation, etc..  If -1<b<0 then you get population
> dynamics with negative autocorrelation.
> 
> 
> -- 
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / people.biology.ufl.edu/bolker
> GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From f.calboli at imperial.ac.uk  Mon Mar 22 15:06:50 2010
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Mon, 22 Mar 2010 14:06:50 +0000
Subject: [R-sig-ME] lmer and splines
Message-ID: <8112A1A5-7643-419A-835C-50EE70F3FE4B@imperial.ac.uk>

Hi everyone,

I'd be interested in fitting some cubic splines on a binary lmer model. I looked in the archives and the most I found was a discussion about lme4 and lmeSplines dated 2006. Is there anything more recent I can look up? 

Best,

Federico Calboli

--
Federico C. F. Calboli
Department of Epidemiology and Biostatistics
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From kingsfordjones at gmail.com  Mon Mar 22 17:44:02 2010
From: kingsfordjones at gmail.com (Kingsford Jones)
Date: Mon, 22 Mar 2010 10:44:02 -0600
Subject: [R-sig-ME] lmer and splines
In-Reply-To: <8112A1A5-7643-419A-835C-50EE70F3FE4B@imperial.ac.uk>
References: <8112A1A5-7643-419A-835C-50EE70F3FE4B@imperial.ac.uk>
Message-ID: <2ad0cc111003220944s64be6d69rbca90115d938b24d@mail.gmail.com>

Hi Federico,

The amer and gamm4 packages will fit GAMMs using lme4.

hth,
Kingsford

On Mon, Mar 22, 2010 at 8:06 AM, Federico Calboli
<f.calboli at imperial.ac.uk> wrote:
> Hi everyone,
>
> I'd be interested in fitting some cubic splines on a binary lmer model. I looked in the archives and the most I found was a discussion about lme4 and lmeSplines dated 2006. Is there anything more recent I can look up?
>
> Best,
>
> Federico Calboli
>
> --
> Federico C. F. Calboli
> Department of Epidemiology and Biostatistics
> Imperial College, St. Mary's Campus
> Norfolk Place, London W2 1PG
>
> Tel +44 (0)20 75941602 ? Fax +44 (0)20 75943193
>
> f.calboli [.a.t] imperial.ac.uk
> f.calboli [.a.t] gmail.com
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From james.croft at aut.ac.nz  Mon Mar 22 19:28:29 2010
From: james.croft at aut.ac.nz (James Croft)
Date: Tue, 23 Mar 2010 07:28:29 +1300
Subject: [R-sig-ME] Is it possible to specify a model with correlated random
	effects and different residual variance for 2 conditions?
Message-ID: <E4D727C1-A708-4B0F-8C55-FB677811C13A@aut.ac.nz>

Hello,

I'm still a little stuck with specifying the model I want.

Participants were tested under 2 Delivery conditions (B and M) at a  
variety of Speeds.
I'm interested in how dv varies with speed and delivery type and in  
individual differences.
I expect greater change in dv with speed for the B condition and   
greater subject to subject variability in the B condition than the M  
condition.

I have tried some simple models but don't understand how to specify  
what I want: A model that has correlated random effects AND different  
residual variance for each level of delivery (or is that implicit in  
model 1)?

model 1: correlated random effects
fm1 = lmer(dv ~ Speed*Delivery + (Speed | Participant))

model 2: uncorrelated random effects
fm2 = lmer(dv ~ Speed*Delivery + (1 | Participant) + (0 + Speed |  
Participant))

model 3: same as model 2 but with different residual variance for each  
level of delivery (where Bind and Mind are indices of B and M -  
similar to https://stat.ethz.ch/pipermail/r-sig-mixed-models/2007q3/000248.html)
fm3 = lmer(dv ~ Speed*Delivery + (0 + Bind | Participant) + (0 + Mind  
| Participant) + (0 + Speed | Participant))


Thank you so much,
James



From charpent at bacbuc.dyndns.org  Fri Mar  5 02:47:41 2010
From: charpent at bacbuc.dyndns.org (Emmanuel Charpentier)
Date: Fri, 05 Mar 2010 01:47:41 -0000
Subject: [R-sig-ME] lme4a, glmer and all that
In-Reply-To: <40e66e0b1003041006l849ec17m2e5e4454806d3a9a@mail.gmail.com>
References: <40e66e0b1003040722m5b595e3eje2039ce3c659ea55@mail.gmail.com>
	<40e66e0b1003040811v53d677fey50e414b17cea951@mail.gmail.com>
	<D5A85515-8EF7-44E8-B064-3A35573F2384@imperial.ac.uk>
	<40e66e0b1003041006l849ec17m2e5e4454806d3a9a@mail.gmail.com>
Message-ID: <1267733059.3187.214.camel@PortableToshiba>

[ Note to Martyn Plummer : this arises from a thread on the lme4
development list : I tried to use JAGS to solve a mixed-model related
problem, and the (non-)results seems fishy... I the took the liberty to
Cc you on this subject ]
 
Le jeudi 04 mars 2010 ? 12:06 -0600, Douglas Bates a ?crit :
> On Thu, Mar 4, 2010 at 11:32 AM, Federico Calboli
> <f.calboli at imperial.ac.uk> wrote:
> > On 4 Mar 2010, at 16:11, Douglas Bates wrote:
> > <cut>
> >>
> >> which, now I see are more consistent with the results from lme4, not
> >> lme4a.  I misunderstood the message I received regarding the Stata
> >> results.
> >>
> >> OK, this might have all been a red herring.  I'll look into it some more.
> >>
> >> At one time on Saturday Night Live Gilda Radner would play a citizen
> >> commentator on weekend news update who was confused about the issue
> >> and, after a long harangue, would end up realizing she got it wrong.
> >> She ended by saying "Never mind".  That might be the case here too.
> >
> >
> > Just out of curiosity, how do we know stata and lme4 are correct and lme4a is not? why is stata the benchmark? Please note I am only being facetious.
> 
> In cases like this we usually go with majority rule.  I'm still
> verifying and validating.

I'm  currently trying to fit this in BUGS (JAGS, actually), and run in
strange difficulties : OpenBUGS (3.0.7) starts an endless loop while
adapting (first update after initialization), WinBUGS (1.4.3 with patch
in Wine) stops immediately with an unhelpful "Rejection 1" message. JAGS
(1.0.3) standalone seems to load model, load data, initializing well.
However, it stops at the adaptation step, stating "Error in node
alpha[<variable...>]. Current value is inconsistent with data". JAGS
called from R (through Martyn Plummer's rjags package) *crashes R*
(almost never seen that before...). I get this in ESS :

terminate called after throwing an instance of 'std::out_of_range'
  what():  Range: upper < lower bound in constructor

Process R abandon at Thu Mar  4 20:37:46 2010

The model, in which I find no "obvious" fault, is as follows :

model
{
    for (k in 1:nobs) {
        incidence[k] ~ dbin(p[k], size[k])
        logit(p[k]) <- alpha[herd[k]] + beta[period[k]] + gamma
    }
    gamma ~ dnorm(0.00000E+00, tau.gamma)
    tau.gamma <- pow(sigma.gamma, -2)
    sigma.gamma ~ dunif(0.00000E+00, 100)
    for (i in 1:nherd) {
        alpha[i] ~ dnorm(0.00000E+00, tau.alpha)
    }
    tau.alpha <- pow(sigma.alpha, -2)
    sigma.alpha ~ dunif(0.00000E+00, 100)
    for (j in 1:nperiod) {
        beta[j] ~ dnorm(0.00000E+00, 1.00000E-06)
    }
}

I tried to pass "reasonable" initial values through model.jags (rjags) :
                          inits=function() {
                            list(mu.alpha=rnorm(nlevels(cbpp$herd),0,1),
                                 mu.beta=rnorm(nlevels(cbpp
$period),0,1),
                                 gamma=rnorm(0,1))
... to no avail ! I even took the usual "unusual step" of looking at the
raw data and graphing them, with nothing suspicious jumping out of the
graphs...

I'm Cc'ing Martyn Plummer on this one, and am curious of his thoughts on
the subject...

HTH,

					Emmanuel Charpentier



From Ulrich.Halekoh at agrsci.dk  Mon Mar  1 13:41:33 2010
From: Ulrich.Halekoh at agrsci.dk (Ulrich Halekoh)
Date: Mon, 01 Mar 2010 12:41:33 -0000
Subject: [R-sig-ME] lmer: Change the Zt matrix and refit
Message-ID: <9F0721FDD4F12D4B95AD894274F388EC01C981B4D71E@DJFEXMBX01.djf.agrsci.dk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100301/b931cb9b/attachment.pl>

From wangqiu at msu.edu  Wed Mar  3 16:45:13 2010
From: wangqiu at msu.edu (Qiu Wang)
Date: Wed, 03 Mar 2010 15:45:13 -0000
Subject: [R-sig-ME] three level var-cov matrix
Message-ID: <38d5586f1003030744l289a7064j5c39424be2683bc9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100303/43d61774/attachment.pl>

From C.Millar at MARLAB.AC.UK  Wed Mar  3 23:11:02 2010
From: C.Millar at MARLAB.AC.UK (Colin Millar)
Date: Wed, 03 Mar 2010 22:11:02 -0000
Subject: [R-sig-ME] var estimates of the random effects variance in lme4
References: <1267639027.4b8ea2f3c6686@webmail.st-andrews.ac.uk>
	<40e66e0b1003031021o3b6b795fp99e31afa399fe46d@mail.gmail.com>
Message-ID: <A0F8DAFB525DED4ABAF6841BB11C581204AE35F6@mail4.marlab.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100303/5277fd96/attachment.pl>

From charpent at bacbuc.dyndns.org  Fri Mar  5 23:13:37 2010
From: charpent at bacbuc.dyndns.org (Emmanuel Charpentier)
Date: Fri, 05 Mar 2010 22:13:37 -0000
Subject: [R-sig-ME] Apologies + a couple of data points (Re: lme4a,
	glmer and all that)
In-Reply-To: <40e66e0b1003041006l849ec17m2e5e4454806d3a9a@mail.gmail.com>
References: <40e66e0b1003040722m5b595e3eje2039ce3c659ea55@mail.gmail.com>
	<40e66e0b1003040811v53d677fey50e414b17cea951@mail.gmail.com>
	<D5A85515-8EF7-44E8-B064-3A35573F2384@imperial.ac.uk>
	<40e66e0b1003041006l849ec17m2e5e4454806d3a9a@mail.gmail.com>
Message-ID: <1267827198.4085.105.camel@PortableToshiba>

Dear list,

First and foremost, an apology for my yesterday's post : re-reading
myself, I found *quite obvious* faults with my initial proposal.
I *swear* I wasn't drunk ! But this learns me never, ever, to post
anything on lme4.devel over 39?C (102?F)...

I succeeded in fitting a couple of models in JAGS reproducing analyses
similar to those created in lme4/lme4a and discussed by Bates and
Caboli. They might be useful before deciding to "go with the majority
rule", which strikes me as a curious way to solve a scientific
problem...

The fits did not exhibit any convergence problems (plot + Gelman
diagnostics + autocorrelation plots) ; adaptation and run length were
chosen to be able to "reasonably believe" the second figure after the
decimal mark in the estimators (see the "Time-series SE" in summaries).

The first model goes to some length to reproduce lmer/Stata
parametrization :

model {
    for(k in 1:nobs) {
      incidence[k]~dbin(p[k], size[k])
      logit(p[k])<-alpha[herd[k]]+Period[period[k]]+Intercept
    }
    Intercept~dnorm(0,tau.Intercept)
    tau.Intercept<-pow(sigma.Intercept,-2)
    sigma.Intercept~dunif(0,100)
    for(i in 1:nherd) {
      alpha[i]~dnorm(0,tau.alpha)
    }
    tau.alpha<-pow(sigma.alpha,-2)
    sigma.alpha~dunif(0,100)
    Period[1]<-0
    for(j in 2:nperiod) {
      Period[j]~dnorm(0,1.0E-6)
    }
  }
This gives the following results :

> summary(Mod[[2]])

Iterations = 2001:12000
Thinning interval = 1 
Number of chains = 3 
Sample size per chain = 10000 

1. Empirical mean and standard deviation for each variable,
   plus standard error of the mean:

                Mean     SD Naive SE Time-series SE
Intercept    -1.4073 0.2684 0.001550       0.006564
Period[1]     0.0000 0.0000 0.000000       0.000000
Period[2]    -0.9954 0.3113 0.001797       0.003520
Period[3]    -1.1444 0.3321 0.001917       0.003328
Period[4]    -1.6243 0.4405 0.002543       0.004272
deviance    170.4377 6.0311 0.034821       0.060296
sigma.alpha   0.7746 0.2383 0.001376       0.004547
tau.alpha     2.2092 1.6582 0.009573       0.028883

[ ... Confidence intervals : Snip ... ]

The fixed effect estimates correlations r as follows :

 cor(as.matrix(Mod[[2]][,c(1,3:5)]))
           Intercept  Period[2]  Period[3]  Period[4]
Intercept  1.0000000 -0.3196581 -0.2910961 -0.2264680
Period[2] -0.3196581  1.0000000  0.2787671  0.2046347
Period[3] -0.2910961  0.2787671  1.0000000  0.1810498
Period[4] -0.2264680  0.2046347  0.1810498  1.0000000


The second tries to be "symmetric" in handling the fixed effects : the
beta parameters are direct estimations of the (logit of the) incidence
*rate* during a given period, while the dbeta parameters are an estimate
of the corresponding effects parametrized "? la lmer/Stata" :

model {
    for(k in 1:nobs) {
      incidence[k]~dbin(p[k], size[k])
      logit(p[k])<-alpha[herd[k]]+beta[period[k]]
    }
    moy~dnorm(0,1.0E-6)
    #tau.moy<-pow(sigma.moy,-2)
    #sigma.moy~dunif(0,100)
    for(i in 1:nherd) {
      alpha[i]~dnorm(0,tau.alpha)
    }
    tau.alpha<-pow(sigma.alpha,-2)
    sigma.alpha~dunif(0,100)
    for(j in 1:nperiod) {
      beta[j]~dnorm(moy,tau.beta)
      dbeta[j]<-beta[j]-beta[1]
    }
    tau.beta<-pow(sigma.beta,-2)
    sigma.beta~dunif(0,100)
  }

Results :

> summary(Mod2[[2]])

Iterations = 2001:12000
Thinning interval = 1 
Number of chains = 3 
Sample size per chain = 10000 

1. Empirical mean and standard deviation for each variable,
   plus standard error of the mean:

                Mean     SD Naive SE Time-series SE
beta[1]      -1.4591 0.2641 0.001525       0.005610
beta[2]      -2.4047 0.3243 0.001872       0.005246
beta[3]      -2.5295 0.3448 0.001991       0.005736
beta[4]      -2.9033 0.4301 0.002483       0.006491
dbeta[1]      0.0000 0.0000 0.000000       0.000000
dbeta[2]     -0.9456 0.3073 0.001774       0.002710
dbeta[3]     -1.0704 0.3274 0.001890       0.002899
dbeta[4]     -1.4443 0.4229 0.002442       0.004340
deviance    170.2087 5.9780 0.034514       0.058695
moy          -2.3220 0.9743 0.005625       0.007056
sigma.alpha   0.7736 0.2275 0.001314       0.003476
tau.alpha     2.1946 1.7145 0.009899       0.028458

[ ... re-Snip ... ]

> cor(as.matrix(Mod2[[2]][,c(10,6:8)]))
                moy   dbeta[2]   dbeta[3]   dbeta[4]
moy      1.00000000 0.04219075 0.04847081 0.06753645
dbeta[2] 0.04219075 1.00000000 0.33301136 0.30281680
dbeta[3] 0.04847081 0.33301136 1.00000000 0.28874007
dbeta[4] 0.06753645 0.30281680 0.28874007 1.00000000

> cor(as.matrix(Mod2[[2]][,c(10,1:4)]))
              moy   beta[1]   beta[2]   beta[3]   beta[4]
moy     1.0000000 0.1812401 0.1875507 0.1848307 0.1776862
beta[1] 0.1812401 1.0000000 0.4698507 0.4471592 0.3340112
beta[2] 0.1875507 0.4698507 1.0000000 0.3999593 0.3426471
beta[3] 0.1848307 0.4471592 0.3999593 1.0000000 0.3297085
beta[4] 0.1776i862 0.3340112 0.3426471 0.3297085 1.0000000

There exists no obvious, deviance-based reasons to prefer one of these
models over the other :

> DIC(Mod[[2]])
 Deviance        pD       DIC 
170.43770  18.18215 188.61985 
> DIC(Mod2[[2]])
Deviance       pD      DIC 
170.2087  17.8677 188.0764 

(The homebrew DIC function implements the algorithms described in the
vignette for the R2WinBUGS package, which is inspired by Gelman & al
(2004)).

Both models give "reasonable" estimators of the fixed effects, but with
a slightly different partitioning of the variance. They might be useful
as a "raincheck" for lme4/lme4a/Stata arbitration.

Of course, another class of models might offer another, quite different
class of solutions : model p as extracted from  beta(a,b) distribution
and model a and b as functions of herd and period. The resulting
estimates would probably have no easy correspondence with logistic
regression estimates, but might be more useful for prediction.

HTH,

					Emmanuel Charpentier
					recovering...

      Le jeudi 04 mars 2010 ? 12:06 -0600, Douglas Bates a ?crit :
> On Thu, Mar 4, 2010 at 11:32 AM, Federico Calboli
> <f.calboli at imperial.ac.uk> wrote:
> > On 4 Mar 2010, at 16:11, Douglas Bates wrote:
> > <cut>
> >>
> >> which, now I see are more consistent with the results from lme4, not
> >> lme4a.  I misunderstood the message I received regarding the Stata
> >> results.
> >>
> >> OK, this might have all been a red herring.  I'll look into it some more.
> >>
> >> At one time on Saturday Night Live Gilda Radner would play a citizen
> >> commentator on weekend news update who was confused about the issue
> >> and, after a long harangue, would end up realizing she got it wrong.
> >> She ended by saying "Never mind".  That might be the case here too.
> >
> >
> > Just out of curiosity, how do we know stata and lme4 are correct and lme4a is not? why is stata the benchmark? Please note I am only being facetious.
> 
> In cases like this we usually go with majority rule.  I'm still
> verifying and validating.
> 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 



From chequered at gmail.com  Mon Mar  8 19:13:56 2010
From: chequered at gmail.com (Xiaoyue Cheng)
Date: Mon, 8 Mar 2010 12:13:56 -0600
Subject: [R-sig-ME] How to change the distribution of the random effect?
Message-ID: <1852f0c11003081013k9294accmb6defb5648525aaa@mail.gmail.com>

Is it possible to build a nonlinear mixed-effects model in R with the
random effect following a distribution other than Gaussian? For
example, a t distribution or a mixed-Gaussian distribution.

Thanks,
Cheng



From stefano.leonardi at unipr.it  Thu Mar 11 17:02:44 2010
From: stefano.leonardi at unipr.it (Stefano Leonardi)
Date: Thu, 11 Mar 2010 17:02:44 +0100
Subject: [R-sig-ME] Test of random effect in lme4
In-Reply-To: <234EBAC6A6054AC1941C23CE6CF1CE64@btodomain.bto.org>
References: <5AFF89011FC0438A8483157147645850@Negro1>	<4B990320.8030507@ufl.edu>
	<234EBAC6A6054AC1941C23CE6CF1CE64@btodomain.bto.org>
Message-ID: <4B991424.6030605@unipr.it>

On 11/03/2010 16:30, Anna Renwick wrote:
> There has been a lot of discussion previously whether we should remove
> random effects based on LRT. The reason is that you added the random effect
> based on your study design and whether it is significant or not it should
> remain in there. I am not sure there is any definite rule and maybe it
> depends on your study and personal view point.
>
> Dr Anna R. Renwick
> Research Ecologist
> British Trust for Ornithology,
> The Nunnery,
> Thetford,
> Norfolk,
> IP24 2PU,
> UK

Can someone please give some literature references about this 
discussion. I am very interested.

According to my experience in Ecology it often happens  that someone 
needs to understand if a variable or factor is 
important/relevant/significant in determining some other variable.

I would like to understand up to which point the arbitrariness of the
experimenter is considered tolerable.

Thanks
Stefano

-- 
======================================================================
  Stefano Leonardi
  Dipartimento di Scienze Ambientali
  Universita` di Parma               E-mail:stefano.leonardi(at)unipr.it
  Viale Usberti 11a                             Phone : +39-0521-905659
  43100 PARMA  (Italy)                          Fax   : +39-0521-905402



From hank.stevens01 at gmail.com  Fri Mar 12 11:46:26 2010
From: hank.stevens01 at gmail.com (Hank Stevens)
Date: Fri, 12 Mar 2010 05:46:26 -0500
Subject: [R-sig-ME] Random intercept and slope model with lmer
In-Reply-To: <4B96E513.5070803@ufl.edu>
References: <4B963616.7060207@gmail.com> <4B9660EB.50300@ufl.edu>
	<4B96C032.5070008@gmail.com> <4B96E513.5070803@ufl.edu>
Message-ID: <bfd10a121003120246u36cae90foaff9ec014edfc7cc@mail.gmail.com>

Hi Ben et al.,
I am one of those lurkers ....

I have an almost off-topic comment/question about the meaning of
"smaller." First, however, I vote to keep these "too basic" replies
coming. Thanks Ben! I like being reminded of the meaning of a standard
deviation.

On Tue, Mar 9, 2010 at 7:17 PM, Ben Bolker <bolker at ufl.edu> wrote:
> ?[I am taking the liberty of forwarding back to r-sig-mixed-models ...
> you may feel this is 'too basic', but (as I always tell my classes)
> there are probably quite a few people lurking on the list who wouldn't
> mind knowing the answers -- or at least knowing my answers (which may
> not be "the" answers.]
>
> ?The standard deviations of the random effects are interpretable on the
> same scale as the corresponding fixed effects, and hence directly
> comparable. ?For example, your intercept is approx. 43 (in whatever
> units); the standard deviation of the variation in intercepts among
> localities (?) is 47; and the standard deviation of the residual
> variation among observations is 21. ?Hence, while the average value at
> time=0 is strongly different from zero (t-score approx. 7), this
> difference from zero is quite a bit smaller than the variation among
> individual observations (think about +/- 2 std. dev.),
Yeah, but aren't most deviations +/- 1 std. dev.? I can't think of too
many ecological data sets in which there is NOT substantial noise. I
once raised Ben's point (i.e., that the signal is small relative to
the noise) with a medical person with whom I was working, and their
response was "it may be a small effect, but multiply that effect times
the number of patients, and the cost of NOT addressing the small
effect..."

Hank

which is in turn
> smaller than the variation among localities. ?The other random effect
> (time|localidad) describes the variation in slope among localities (a
> similar comparison to that above applies to the strongly negative
> average slope with great variation in slopes among localities).
>
> ?However, there is also something a bit funny with your model, because
> the correlation between the random effects is listed as being -1: the
> random variation in slopes and intercepts is perfectly (negatively)
> correlated. ?Possibly your experimental/observational design is
> insufficient (you only have an average of about 4 observations per
> group); it might also help to center your time variable at the midpoint
> time.
>
> ?I also think that looking at Ch. 4 of Bates's book draft
> <http://lme4.r-forge.r-project.org/book/Ch4.pdf>, or at the equivalent
> examples (Orthodont etc.) in PB2000, would be helpful.
>
> ?cheers
> ? Ben
>
>
> Manuel Sp?nola wrote:
>> Dear Ben,
>>
>> Sorry to bother you with this again, but what do you look for at the
>> output of a mixed model in R? ?I know what to do with the fixed effect,
>> but what about the random effects?:
>>
>> ?> modelo7 = lmer(ipa ~ time + (time | localidad), data=ipa)
>> ?> summary(modelo7)
>> Linear mixed model fit by REML
>> Formula: ipa ~ time + (time | localidad)
>> ? ?Data: ipa
>> ? AIC ?BIC logLik deviance REMLdev
>> ?1917 1937 -952.4 ? ? 1913 ? ?1905
>> Random effects:
>> ?Groups ? ?Name ? ? ? ?Variance Std.Dev. Corr
>> ?localidad (Intercept) 2232.31 ?47.247
>> ? ? ? ? ? ?time ? ? ? ? 545.97 ?23.366 ? -1.000
>> ?Residual ? ? ? ? ? ? ? 450.92 ?21.235
>> Number of obs: 196, groups: localidad, 49
>>
>> Fixed effects:
>> ? ? ? ? ? ? Estimate Std. Error t value
>> (Intercept) ? 42.852 ? ? ?6.918 ? 6.194
>> time ? ? ? ? -19.746 ? ? ?3.603 ?-5.480
>>
>> Correlation of Fixed Effects:
>> ? ? ?(Intr)
>> time -0.904
>>
>> Thank you very much in advance.
>> Best,
>>
>> Manuel
>>
>>
>> Ben Bolker wrote:
>>> Manuel Sp?nola wrote:
>>>
>>>> Dear Ben,
>>>>
>>>> I am trying to fit a random intercept and slope model with lme4 using
>>>> function lmer.
>>>> Is my formulation correct?
>>>>
>>>> ?> names(ipa)
>>>> [1] "localidad" "time" ? ?"ipa"
>>>>
>>>> ?> modelo7 = lmer(ipa ~ time + (time | localidad), data=ipa)
>>>>
>>>> Thank you very much in advance.
>>>> Best,
>>>>
>>>> Manuel
>>>>
>>>>
>>> ? That looks reasonable.
>>> ? See
>>>
>>> http://lme4.r-forge.r-project.org/book/
>>>
>>> ?especially chapter 4.
>>>
>>> (Why not send these questions to r-sig-mixed-models at r-project.org ?)
>>>
>>>
>>
>>
>
>
> --
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / people.biology.ufl.edu/bolker
> GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From C.Millar at MARLAB.AC.UK  Mon Mar 15 00:16:51 2010
From: C.Millar at MARLAB.AC.UK (Colin Millar)
Date: Sun, 14 Mar 2010 23:16:51 -0000
Subject: [R-sig-ME] number of levels of grouping factor == number
	ofobservations
References: <40e66e0b1003091405v7561f54dx243f2b7449aa0ea2@mail.gmail.com>
Message-ID: <A0F8DAFB525DED4ABAF6841BB11C581204AE35FD@mail4.marlab.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100314/787a170a/attachment.pl>

From C.Millar at MARLAB.AC.UK  Mon Mar 15 13:42:02 2010
From: C.Millar at MARLAB.AC.UK (Colin Millar)
Date: Mon, 15 Mar 2010 12:42:02 -0000
Subject: [R-sig-ME] significance test of random and fixed effects
	in(quasi)	 poisson GLMM
In-Reply-To: <562EA47F252E594B826D3B440E0B34A21288E58045@ICTS-S-EXC2-CA.luna.kuleuven.be>
References: <mailman.5.1268478002.991.r-sig-mixed-models@r-project.org>,
	<4B9B8EA1.5572.00B2.0@lshtm.ac.uk>
	<562EA47F252E594B826D3B440E0B34A21288E58045@ICTS-S-EXC2-CA.luna.kuleuven.be>
Message-ID: <A0F8DAFB525DED4ABAF6841BB11C581201BB13E6@mail4.marlab.ac.uk>

Hi Vincent,

>From past experience we could not get glmmPQL to fit without fitting a
dispersion parameter.  Prior to finding out about lme4 we tended to use
genstat to fit generalised linear mixed models as this gave finer
control.  If there is a way to fit standard binomial and poisson in
glmmPQL I would be very glad to find out how to do it.

Thanks,
Colin.

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Vincent
Kint
Sent: 15 March 2010 10:44
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] significance test of random and fixed effects
in(quasi) poisson GLMM

Dear Antonio and list members,

Thanks for the reply. The problem with quasi GLMM in lme4 seems to have
been reported several times. As you suggested, I tried with glmmPQL, but
I don't find how to retreive the overdispersion factor (it is not in the
summary). Also, I don't see any difference using poisson or
quasipoisson. Does that mean that this method is correcting for
overdispersion in both cases?

Further suggestions on how to test fixed and radom factors in GLMMs are
still welcome.

Regards,
Vincent

________________________________________
From: Antonio.Gasparrini at lshtm.ac.uk [Antonio.Gasparrini at lshtm.ac.uk]
Sent: 13 March 2010 14:09
To: r-sig-mixed-models at r-project.org
Cc: Vincent Kint
Subject: Re: significance test of random and fixed effects in (quasi)
poisson GLMM

Dear Vincent,

some time ago I posted a question on Poisson GLMM for overdispersed
data, including a simple simulation in order to compare the reliability
of glmmPQL and glmer.
See
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q1/003289.html


While glmmPQL returns the correct estimates, glmer largely
overestimated the sigma (corresponding to the overdispersion), producing
an inflated within-group residual variance.
This odd behaviour seems to be confirmed by your analysis.

As pointed out in the response I had to my question, the quasi-Poisson
is not a distribution and the results are not grounded on an appropriate
statistical theory. Anyway, as in your case, the quasipoisson family is
currently used and I would expect the command to return (approximate)
correct results.

My suggestion is to repeat the analysis with glmmPQL, even if this
doesn't solve your problem to run a test. To my knowledge, the
approximation used by the penalized quasi-likelihood method is
reasonable for Poisson data and a moderate number of counts (McCulloch &
Searle say with mean count of 7 or higher). Interestingly, the command
always estimates the sigma (not fixed to 1 as in Poisson) even with the
simple poisson family.

I hope this helps

Antonio Gasparrini
Public and Environmental Health Research Unit (PEHRU)
London School of Hygiene & Tropical Medicine
Keppel Street, London WC1E 7HT, UK
Office: 0044 (0)20 79272406 - Mobile: 0044 (0)79 64925523

------------------------------

Message: 3
Date: Fri, 12 Mar 2010 15:46:23 +0100
From: Vincent Kint <Vincent.Kint at ees.kuleuven.be>
To: "r-sig-mixed-models at r-project.org"
<r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] significance test of random and fixed effects in
(quasi) poisson GLMM
Message-ID:
<562EA47F252E594B826D3B440E0B34A21288E5803C at ICTS-S-EXC2-CA.luna.kuleuven
.be>

Content-Type: text/plain

Dear list members,

I am new to this list, and new to generalised mixed modelling.

My aim is to develop a model for tree branchiness (number of branches
per tree, with trees measured in different plots) with both tree and
plot-level predictors. My choice was for a generalised model using the
poisson family, since I have count data. And for a mixed approach since
I have a nested design.

I built a first model using the lme4 package (see below). My question
is: is there an approximate test for the significance of the random
effect? From previous posts on this list, I understand that such a test
is not always reliable, and good alternatives are not implemented yet.
But from my perspective of an applied modeller, even an approximate test
(or even a rule of thumb) would be helpful in making a decision. Indeed,
if the random effect turns out to be likely not significant, I could do
with a more simple GLM.

In a second step I tried to correct for overdispersion by running the
same model as a quasi GLMM. The output is also given below. Here I have
the same question as before, but now also concerning the fixed effects.
Additionally, I wonder whether I may have made a mistake in implementing
this model, since I get a result where nearly all the variation is
attributed to the error term, and (at a first glance) the random effect
and all the fixed predictors seem to be irrelevant.

I attach the output of both models below.
Thanks for all suggestions on how to proceed.
Vincent


#1. The GLMM model
> form1<-formula(response ~ TreeHeight + DBH + TreeAge + Vplot + mF +
mL + (1 | plots))
> M.glmm<-lmer(form1, data=data, family=poisson)
> summary(M.glmm)
Generalized linear mixed model fit by the Laplace approximation
Formula: form1
   Data: data
AIC  BIC logLik deviance
976 1008   -480      960
Random effects:
Groups Name        Variance Std.Dev.
plots  (Intercept) 0.044913 0.21193
Number of obs: 399, groups: plots, 30

Fixed effects:
              Estimate Std. Error z value Pr(>|z|)
(Intercept)  6.0090427  1.4143768   4.249 2.15e-05 ***
TreeHeight  -0.0398146  0.0125816  -3.165 0.001553 **
DBH          0.0032600  0.0006599   4.940 7.80e-07 ***
TreeAge     -0.1193541  0.0242996  -4.912 9.03e-07 ***
Vplot       -0.0060713  0.0016115  -3.768 0.000165 ***
mF          -0.4838699  0.1672462  -2.893 0.003814 **
mL           0.4878563  0.1731139   2.818 0.004831 **
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.'
0.1 ' ' 1



#2. The same GLMM model with overdispersion
> M.glmm.q<-lmer(form1, data=data, family=quasipoisson)
> summary(M.glmm.q)
Generalized linear mixed model fit by the Laplace approximation
Formula: form1
   Data: data
AIC  BIC logLik deviance
978 1014   -480      960
Random effects:
Groups   Name        Variance Std.Dev.
plots    (Intercept)  1.6478  1.2837
Residual             36.6894  6.0572
Number of obs: 399, groups: plots, 30

Fixed effects:
             Estimate Std. Error t value
(Intercept)  6.009043   8.567129   0.701
TreeHeight  -0.039815   0.076209  -0.522
DBH          0.003260   0.003997   0.816
TreeAge     -0.119354   0.147187  -0.811
Vplot       -0.006071   0.009761  -0.622
mF          -0.483870   1.013039  -0.478
mL           0.487856   1.048581   0.465

_____________________________________
dr. ir. V. KINT
Forest Ecology and Management
Division Forest, Nature and Landscape
K.U.Leuven
Celestijnenlaan 200E - B-3001 Leuven
Tel.: +32 16 32 97 69
Fax:  +32 16 32 97 60
vincent.kint at ees.kuleuven.be

www.kuleuven.be/forecoman<http://www.kuleuven.be/forecoman>

[[alternative HTML version deleted]]
_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

______________________________________________________________________
This email has been scanned by the MessageLabs Email Security System.
For more information please visit http://www.messagelabs.com/email 



From james.croft at aut.ac.nz  Mon Mar 22 02:51:19 2010
From: james.croft at aut.ac.nz (James Croft)
Date: Mon, 22 Mar 2010 14:51:19 +1300
Subject: [R-sig-ME] Is it possible to specify a model with correlated random
	effects and different residual variance for 2 conditions?
Message-ID: <39F1D5BB-9D0D-4B19-9F16-2ED37E4B3949@aut.ac.nz>

Hello,

I'm still a little stuck with specifying the model I want.

Participants were tested under 2 Delivery conditions (B and M) at a  
variety of Speeds.
I'm interested in how dv varies with speed and delivery type and in  
individual differences.
I expect greater change in dv with speed for the B condition and   
greater subject to subject variability in the B condition than the M  
condition.

I have tried some simple models but don't understand how to specify  
what I want: A model that has correlated random effects AND different  
residual variance for each level of delivery (or is that implicit in  
model 1)?

model 1: correlated random effects
fm1 = lmer(dv ~ Speed*Delivery + (Speed | Participant))

model 2: uncorrelated random effects
fm2 = lmer(dv ~ Speed*Delivery + (1 | Participant) + (0 + Speed |  
Participant))

model 3: same as model 2 but with different residual variance for each  
level of delivery (where Bind and Mind are indices of B and M -  
similar to https://stat.ethz.ch/pipermail/r-sig-mixed-models/2007q3/000248.html)
fm3 = lmer(dv ~ Speed*Delivery + (0 + Bind | Participant) + (0 + Mind  
| Participant) + (0 + Speed | Participant))


Thank you so much,
James



From daviddouter at hotmail.com  Mon Mar 22 20:28:56 2010
From: daviddouter at hotmail.com (David Douterlungne)
Date: Mon, 22 Mar 2010 20:28:56 +0100
Subject: [R-sig-ME] [R-sig-eco] general lineal mixed model with
	unbalanced data
In-Reply-To: <4BA64AC5.6000205@ufl.edu>
References: <mailman.1.1267959601.19611.r-sig-ecology@r-project.org>
	<SNT141-w42D908D34C1CA95A5FFC1DAC280@phx.gbl>,
	<4BA64AC5.6000205@ufl.edu>
Message-ID: <SNT141-w21827D3FC3C49E5180E0CAC270@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100322/958319ab/attachment.pl>

From elizabeth.crone at cfc.umt.edu  Mon Mar 22 21:21:33 2010
From: elizabeth.crone at cfc.umt.edu (Elizabeth Crone)
Date: Mon, 22 Mar 2010 14:21:33 -0600
Subject: [R-sig-ME]  How to change the distribution of the random
In-Reply-To: <mailman.678.1269287030.4248.r-sig-mixed-models@r-project.org>
References: <mailman.678.1269287030.4248.r-sig-mixed-models@r-project.org>
Message-ID: <FDE3381E3E2B9945BDA9105DBBE2D60803052E3B8005@pangaea.cfc.umt.edu>


> Is it possible to build a nonlinear mixed-effects model in R with the
> random effect following a distribution other than Gaussian? For
> example, a t distribution or a mixed-Gaussian distribution.

To my knowledge, there is no way to directly specify an alternative probability distribution (but maybe others know of something).  

However, in lme4 the LINK FUNCTION parameters are Gaussian, not the parameters themselves.  For example, the random effects in a binomial(logit) model are logit-normally distributed, which looks a lot like a beta distribution when you back-transform them.  

This makes me wonder if there is a clever way to get, e.g., a mixture of two Gaussian distributions by playing around with the structure of mixed and random effects... 



From andydolman at gmail.com  Tue Mar 23 11:57:49 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Tue, 23 Mar 2010 10:57:49 +0000
Subject: [R-sig-ME] [R-sig-eco] general lineal mixed model with
	unbalanced data
In-Reply-To: <SNT141-w21827D3FC3C49E5180E0CAC270@phx.gbl>
References: <mailman.1.1267959601.19611.r-sig-ecology@r-project.org>
	<SNT141-w42D908D34C1CA95A5FFC1DAC280@phx.gbl>
	<4BA64AC5.6000205@ufl.edu>
	<SNT141-w21827D3FC3C49E5180E0CAC270@phx.gbl>
Message-ID: <951234ac1003230357k6555d72fqfdd953a1582cc642@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100323/be41eabe/attachment.pl>

From alex.safari at flinders.edu.au  Wed Mar 24 04:17:50 2010
From: alex.safari at flinders.edu.au (Alex Safari)
Date: Wed, 24 Mar 2010 13:47:50 +1030
Subject: [R-sig-ME] (no subject)
Message-ID: <003601cacb00$959c08b0$c0d41a10$@safari@flinders.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100324/49111ca7/attachment.pl>

From jana.buerger at uni-rostock.de  Wed Mar 24 13:52:22 2010
From: jana.buerger at uni-rostock.de (=?ISO-8859-15?Q?Jana_B=FCrger?=)
Date: Wed, 24 Mar 2010 13:52:22 +0100
Subject: [R-sig-ME] unbalanced data in nested lmer model
Message-ID: <4BAA0B06.1030806@uni-rostock.de>

Dear List,

I have two questions regarding unbalanced data and lmer and could not 
find any hints in archives nor in my textbooks.

1) Is there a limit to the unbalance of case numbers in cells? Or would 
it be no problem if cell sizes vary between 0 and 53?

2) I have data of individual fields from a number of farms which are 
located in a number of regions. For 2 of 8 regions there is only 1 farm, 
the other regions have 2 farms. Which consequences does this fact have 
on the random effects part of the model summary if I choose the model
lm1<-lmer(y~x1+x2+...+(1|region)+(1|region:farm))?
All y and x variables are field specific.

An anova(lm1, lm2) comparing with lm2<-lmer(y+x1+x2+...+(1|farm)) said 
models did not differ significantly and AIC was about the same. So I 
know there is no additional explanatory power including the region term.

Yet, I would like to keep the region effect in the model to separate and 
compare the effect size of region vs. farm. Is it valid to do so even if 
  some of the regions are only represented by one farm?

I would appreciate any thoughts on this very much.

Jana B?rger

Universit?t Rostock
Agrar-  und Umweltwissenschaftliche Fakult?t
FG Phytomedizin
Satower Stra?e 48
18059 Rostock

Tel. 0381-498 31 71
Fax.0381-498 31 62



From dutangc at gmail.com  Wed Mar 24 12:09:59 2010
From: dutangc at gmail.com (christophe dutang)
Date: Wed, 24 Mar 2010 12:09:59 +0100
Subject: [R-sig-ME] missing data + explanatory variables
Message-ID: <c8e8cd3d1003240409r27cfb4c0w897cae92d391942f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100324/2e3a9574/attachment.pl>

From edeline at biologie.ens.fr  Wed Mar 24 14:10:03 2010
From: edeline at biologie.ens.fr (Eric Edeline)
Date: Wed, 24 Mar 2010 14:10:03 +0100
Subject: [R-sig-ME] Could not get a lmer or glmer summary
Message-ID: <4BAA0F2B.8050404@biologie.ens.fr>

Dear all,

I am having troubles with getting a summary for lmer and glmer models 
that otherwise (apparently) converged properly (i can for instance 
extract ranefs). Could anyone point to me the mistake?

Thanks!

Eric


 >m11<-lmer(Logl ~ 1|Species, data=Data)
 >m11
Error in chol2inv(object at RX, size = object at dims["p"]) :
  could not find symbol "size" in environment of the generic function

 > sessionInfo()
R version 2.10.1 (2009-12-14)
i486-pc-linux-gnu

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C             
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8   
 [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8  
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                
 [9] LC_ADDRESS=C               LC_TELEPHONE=C           
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C      

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base    

other attached packages:
[1] lme4_0.999375-32   Matrix_0.999375-37 lattice_0.18-3   

loaded via a namespace (and not attached):
[1] grid_2.10.1

 > str(Data)
'data.frame':    90900 obs. of  39 variables:
 $ OPCOD     : num  1.01e+10 1.01e+10 1.01e+10 1.01e+10 1.01e+10 ...
 $ Species   : Factor w/ 50 levels "ABH","ABL","ANG",..: 20 18 32 29 48 
3 21 2 31 24 ...
 $ Length    : num  41.4 77.3 124.6 95.8 245.7 ...
 $ Var       : num  10 484.4 1110.3 300.7 74909.1 ...
 $ Count     : num  3 236 38 20 9 1 16 3 2 80 ...
 $ Linf      : int  110 180 200 210 1400 1330 90 250 1520 200 ...
 $ Pisc      : num  0 1 0 0 1 1 0 0 1 0 ...
 $ Nb.species: int  7 7 7 7 7 7 7 10 10 10 ...
 $ Ntot      : int  788 788 788 788 788 788 788 31521 31521 31521 ...
 $ Fcl       : num  11475 11475 11475 11475 11475 ...
 $ Name      : Factor w/ 50 levels "Able_de_Heckel",..: 20 18 29 33 48 3 
21 2 34 25 ...
 $ Mass      : num  0.697 5.665 3.292 6.808 53.077 ...
 $ Fam       : Factor w/ 12 levels "Ang","Cob","Cot",..: 6 3 7 2 11 1 6 
4 8 4 ...
 $ Compint   : num  1.282 0.641 0.237 5.994 0.254 ...
 $ Pred      : num  0.29759 0.03813 0.02509 0.0407 0.00625 ...
 $ Mu        : num  40.9 70.1 125.7 72.2 173.1 ...
 $ Nb.sp0    : int  4 4 4 4 4 4 4 5 5 5 ...
 $ Nb.sp.5   : int  0 0 0 0 0 0 0 0 0 0 ...
 $ Nb.sp1    : int  3 3 3 3 3 3 3 5 5 5 ...
 $ Month     : int  5 5 5 5 5 5 5 6 6 6 ...
 $ Year      : int  1990 1990 1990 1990 1990 1990 1990 1995 1995 1995 ...
 $ Width     : num  2.5 2.5 2.5 2.5 2.5 2.5 2.5 5 5 5 ...
 $ Depth     : num  0.38 0.38 0.38 0.38 0.38 0.38 0.38 0.53 0.53 0.53 ...
 $ Method    : Factor w/ 3 levels "Bat","Mix","Pied": 3 3 3 3 3 3 3 3 3 
3 ...
 $ Strategy  : Factor w/ 5 levels "compl","partamb",..: 1 1 1 1 1 1 1 2 
2 2 ...
 $ Surf      : num  250 250 250 250 250 250 250 650 650 650 ...
 $ Slope     : num  6.63 6.63 6.63 6.63 6.63 6.63 6.63 0.65 0.65 0.65 ...
 $ Tjan      : num  3.9 3.9 3.9 3.9 3.9 3.9 3.9 4 4 4 ...
 $ Tmin      : num  0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.3 0.3 0.3 ...
 $ Tjul      : num  18.9 18.9 18.9 18.9 18.9 18.9 18.9 19.5 19.5 19.5 ...
 $ Tmax      : num  22.5 22.5 22.5 22.5 22.5 22.5 22.5 23.3 23.3 23.3 ...
 $ CLAS_ONEMA: Factor w/ 8 levels "","Ag","Ag. Intens",..: 5 5 5 5 5 5 5 
7 7 7 ...
 $ Region    : Factor w/ 9 levels "Bassin_Garonne",..: 5 5 5 5 5 5 5 5 5 
5 ...
 $ Temp      : num  11.5 11.5 11.5 11.5 11.5 ...
 $ D         : num  0.012 0.944 0.152 0.08 0.036 ...
 $ Compint2  : num  0.4284 0.00372 0.00723 0.30072 0.02925 ...
 $ Pred2     : num  0.099207 0.000172 0.00067 0.002045 0.000704 ...
 $ CV        : num  0.0765 0.2849 0.2673 0.1811 1.114 ...
 $ Logl      : num  3.72 4.35 4.83 4.56 5.5 ...


-- 
Eric Edeline
Assistant Professor
UMR 7618 BIOEMCO
Ecole Normale Sup?rieure
46 rue d'Ulm
75230 Paris cedex 05
France

Tel: +33 (0)1 44 32 38 84
Fax: +33 (0)1 44 32 38 85

http://www.biologie.ens.fr/bioemco/biodiversite/edeline.html



From hamish.wilman at yale.edu  Wed Mar 24 16:01:47 2010
From: hamish.wilman at yale.edu (hamish.wilman at yale.edu)
Date: Wed, 24 Mar 2010 11:01:47 -0400
Subject: [R-sig-ME] Mixed effects model selection
Message-ID: <20100324110147.qzbnbc1ao88cs8sc@www.mail.yale.edu>

Hello all, I'll get right into it:

I am trying to perform model selection starting from an overly parameterized
model of the form:

mdl1<- lmer(Y ~ Sa + Sb + c + d + e + f + (c + d + e + f|SpeciesID), REML = F)

where Sa and Sb are species-level predictors and the others are population level
predictors, so can potentially vary within species (hence their inclusion as
slopes in the random effects term).

In Zuur et al 2009 it is suggested that one starts with a full model like this
and first perform selection on the random effects, then move on to do selection
on the fixed effects.

The procedure I have been using is to remove one item at a time from the random
effects, in effect plotting four new models, each missing one of the slope
parameters in the random effects, then using likelihood ratio tests (LRT) to
compare them to the full model. I throw out the variable with the lowest
non-significant LRT test statistic (realizing that the p-values are
conservative). I then repeat this procedure until all variables are
"indispensable" as defined by the LRT.

I do this with the fixed effects after selecting for the random effects. The
justification in Zuur for doing the selection on the random effects first, with
all possible fixed effects in there, is that any variation potentially explained
by the fixed effects should stay there and the random effects then give you what
doesn't show up in the fixed effects.

First of all, does this model selection procedure sound reasonable?

Now, when I complete this procedure on my model, the resulting best model looks
like this:

mdl.final<- lmer(Y ~ Sa + Sb + c + d + (e + f|SpeciesID), REML = F)

My question is whether you can have variables in the slope portion of the random
effects that are not in the fixed effects, and if so what is the interpretation
of their "influence"?

My understanding was that the slopes in the random effects are deviations from
the fixed effects parameter estimates, which seems to only make sense if the
variable also shows up as a fixed effect.

Any assistance would be hugely appreciated, even if it is just telling me I'm a
big dummy. I have looked through a lot of other literature, including Pinheiro
and Bates 2000 and haven't found anywhere that explicitly deals with selection
for models with this many variables and how it should be approached (except
Zuur, whose method gives me the above result).

Thanks so much!

Regards,

Ham



From David.Duffy at qimr.edu.au  Wed Mar 24 22:40:27 2010
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Thu, 25 Mar 2010 07:40:27 +1000 (EST)
Subject: [R-sig-ME] Could not get a lmer or glmer summary
In-Reply-To: <4BAA0F2B.8050404@biologie.ens.fr>
References: <4BAA0F2B.8050404@biologie.ens.fr>
Message-ID: <Pine.LNX.4.64.1003250738380.15751@orpheus.qimr.edu.au>

On Wed, 24 Mar 2010, Eric Edeline wrote:

> I am having troubles with getting a summary for lmer and glmer models that 
> otherwise (apparently) converged properly (i can for instance extract 
> ranefs). Could anyone point to me the mistake?

Could you show us str(m11) ?

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From edeline at biologie.ens.fr  Thu Mar 25 07:59:29 2010
From: edeline at biologie.ens.fr (Eric Edeline)
Date: Thu, 25 Mar 2010 07:59:29 +0100
Subject: [R-sig-ME] Could not get a lmer or glmer summary
In-Reply-To: <Pine.LNX.4.64.1003250738380.15751@orpheus.qimr.edu.au>
References: <4BAA0F2B.8050404@biologie.ens.fr>
	<Pine.LNX.4.64.1003250738380.15751@orpheus.qimr.edu.au>
Message-ID: <4BAB09D1.3000806@biologie.ens.fr>

Dear David,

here is the Str(m11):

 > m11<-lmer(Logl ~ 1|Species, data=Data)
 > str(m11)
Formal class 'mer' [package "lme4"] with 34 slots
  ..@ env     :<environment: 0xc077a5c>
  ..@ nlmodel : language I(x)
  ..@ frame   :'data.frame':    92093 obs. of  2 variables:
  .. ..$ Logl   : num [1:92093] 3.72 4.35 4.83 4.56 5.5 ...
  .. ..$ Species: Factor w/ 50 levels "ABH","ABL","ANG",..: 20 18 32 29 
48 3 21 2 31 24 ...
  .. ..- attr(*, "terms")=Classes 'terms', 'formula' length 3 Logl ~ 1
  .. .. .. ..- attr(*, "variables")= language list(Logl)
  .. .. .. ..- attr(*, "factors")= int(0)
  .. .. .. ..- attr(*, "term.labels")= chr(0)
  .. .. .. ..- attr(*, "order")= int(0)
  .. .. .. ..- attr(*, "intercept")= int 1
  .. .. .. ..- attr(*, "response")= int 1
  .. .. .. ..- attr(*, ".Environment")=<environment: R_GlobalEnv>
  .. .. .. ..- attr(*, "predvars")= language list(Logl)
  .. .. .. ..- attr(*, "dataClasses")= Named chr "numeric"
  .. .. .. .. ..- attr(*, "names")= chr "Logl"
  ..@ call    : language lmer(formula = Logl ~ 1 | Species, data = Data)
  ..@ flist   :'data.frame':    92093 obs. of  1 variable:
  .. ..$ Species: Factor w/ 50 levels "ABH","ABL","ANG",..: 20 18 32 29 
48 3 21 2 31 24 ...
  .. ..- attr(*, "assign")= int 1
  ..@ X       : num [1:92093, 1] 1 1 1 1 1 1 1 1 1 1 ...
  .. ..- attr(*, "assign")= int 0
  ..@ Xst     :Formal class 'dgCMatrix' [package "Matrix"] with 6 slots
  .. .. ..@ i       : int(0)
  .. .. ..@ p       : int 0
  .. .. ..@ Dim     : int [1:2] 0 0
  .. .. ..@ Dimnames:List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. .. ..@ x       : num(0)
  .. .. ..@ factors : list()
  ..@ Zt      :Formal class 'dgCMatrix' [package "Matrix"] with 6 slots
  .. .. ..@ i       : int [1:92093] 19 17 31 28 47 2 20 1 30 23 ...
  .. .. ..@ p       : int [1:92094] 0 1 2 3 4 5 6 7 8 9 ...
  .. .. ..@ Dim     : int [1:2] 50 92093
  .. .. ..@ Dimnames:List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. .. ..@ x       : num [1:92093] 1 1 1 1 1 1 1 1 1 1 ...
  .. .. ..@ factors : list()
  ..@ pWt     : num(0)
  ..@ offset  : num(0)
  ..@ y       : num [1:92093] 3.72 4.35 4.83 4.56 5.5 ...
  ..@ Gp      : int [1:2] 0 50
  ..@ dims    : Named int [1:18] 1 92093 1 50 1 1 0 1 2 5 ...
  .. ..- attr(*, "names")= chr [1:18] "nt" "n" "p" "q" ...
  ..@ ST      :List of 1
  .. ..$ : num [1, 1] 1.41
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : chr "(Intercept)"
  .. .. .. ..$ : chr "(Intercept)"
  ..@ V       : num[0 , 0 ]
  ..@ A       :Formal class 'dgCMatrix' [package "Matrix"] with 6 slots
  .. .. ..@ i       : int [1:92093] 19 17 31 28 47 2 20 1 30 23 ...
  .. .. ..@ p       : int [1:92094] 0 1 2 3 4 5 6 7 8 9 ...
  .. .. ..@ Dim     : int [1:2] 50 92093
  .. .. ..@ Dimnames:List of 2
  .. .. .. ..$ : chr [1:50] "ABH" "ABL" "ANG" "APR" ...
  .. .. .. ..$ : NULL
  .. .. ..@ x       : num [1:92093] 1.41 1.41 1.41 1.41 1.41 ...
  .. .. ..@ factors : list()
  ..@ Cm      :Formal class 'dgCMatrix' [package "Matrix"] with 6 slots
  .. .. ..@ i       : int(0)
  .. .. ..@ p       : int 0
  .. .. ..@ Dim     : int [1:2] 0 0
  .. .. ..@ Dimnames:List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. .. ..@ x       : num(0)
  .. .. ..@ factors : list()
  ..@ Cx      : num(0)
  ..@ L       :Formal class 'dCHMsimpl' [package "Matrix"] with 10 slots
  .. .. ..@ x       : num [1:50] 19.48 84.97 95.87 4.35 10.7 ...
  .. .. ..@ p       : int [1:51] 0 1 2 3 4 5 6 7 8 9 ...
  .. .. ..@ i       : int [1:50] 0 1 2 3 4 5 6 7 8 9 ...
  .. .. ..@ nz      : int [1:50] 1 1 1 1 1 1 1 1 1 1 ...
  .. .. ..@ nxt     : int [1:52] 1 2 3 4 5 6 7 8 9 10 ...
  .. .. ..@ prv     : int [1:52] 51 0 1 2 3 4 5 6 7 8 ...
  .. .. ..@ colcount: int [1:50] 1 1 1 1 1 1 1 1 1 1 ...
  .. .. ..@ perm    : int [1:50] 0 1 2 3 4 5 6 7 8 9 ...
  .. .. ..@ type    : int [1:4] 2 1 0 1
  .. .. ..@ Dim     : int [1:2] 50 50
  ..@ deviance: Named num [1:13] 9.97e+04 9.97e+04 3.61e+02 3.22 
4.15e-01 ...
  .. ..- attr(*, "names")= chr [1:13] "ML" "REML" "ldL2" "ldRX2" ...
  ..@ fixef   : Named num 4.79
  .. ..- attr(*, "names")= chr "(Intercept)"
  ..@ ranef   : num [1:50] -0.9126 -0.4434 1.3085 -0.0774 0.2951 ...
  ..@ u       : num [1:50] -0.6463 -0.3141 0.9267 -0.0548 0.209 ...
  ..@ eta     : num [1:92093] 3.68 4.22 4.82 4.26 5.1 ...
  ..@ mu      : num [1:92093] 3.68 4.22 4.82 4.26 5.1 ...
  ..@ muEta   : num(0)
  ..@ var     : num(0)
  ..@ resid   : num [1:92093] 0.03999 0.12217 0.00859 0.30464 0.40331 ...
  ..@ sqrtXWt : num[0 , 1]
  ..@ sqrtrWt : num(0)
  ..@ RZX     : num [1:50, 1] 13.77 60.2 67.92 2.92 7.52 ...
  ..@ RX      : num [1, 1] 5
  ..@ ghx     : num(0)
  ..@ ghw     : num(0)


David Duffy wrote:
> On Wed, 24 Mar 2010, Eric Edeline wrote:
>
>> I am having troubles with getting a summary for lmer and glmer models 
>> that otherwise (apparently) converged properly (i can for instance 
>> extract ranefs). Could anyone point to me the mistake?
>
> Could you show us str(m11) ?
>

-- 
Eric Edeline
Assistant Professor
UMR 7618 BIOEMCO
Ecole Normale Sup?rieure
46 rue d'Ulm
75230 Paris cedex 05
France

Tel: +33 (0)1 44 32 38 84
Fax: +33 (0)1 44 32 38 85

http://www.biologie.ens.fr/bioemco/biodiversite/edeline.html



From edeline at biologie.ens.fr  Thu Mar 25 07:59:46 2010
From: edeline at biologie.ens.fr (Eric Edeline)
Date: Thu, 25 Mar 2010 07:59:46 +0100
Subject: [R-sig-ME] Could not get a lmer or glmer summary
In-Reply-To: <Pine.LNX.4.64.1003250738380.15751@orpheus.qimr.edu.au>
References: <4BAA0F2B.8050404@biologie.ens.fr>
	<Pine.LNX.4.64.1003250738380.15751@orpheus.qimr.edu.au>
Message-ID: <4BAB09E2.9030806@biologie.ens.fr>

Dear David,

here is the Str(m11):

 > m11<-lmer(Logl ~ 1|Species, data=Data)
 > str(m11)
Formal class 'mer' [package "lme4"] with 34 slots
  ..@ env     :<environment: 0xc077a5c>
  ..@ nlmodel : language I(x)
  ..@ frame   :'data.frame':    92093 obs. of  2 variables:
  .. ..$ Logl   : num [1:92093] 3.72 4.35 4.83 4.56 5.5 ...
  .. ..$ Species: Factor w/ 50 levels "ABH","ABL","ANG",..: 20 18 32 29 
48 3 21 2 31 24 ...
  .. ..- attr(*, "terms")=Classes 'terms', 'formula' length 3 Logl ~ 1
  .. .. .. ..- attr(*, "variables")= language list(Logl)
  .. .. .. ..- attr(*, "factors")= int(0)
  .. .. .. ..- attr(*, "term.labels")= chr(0)
  .. .. .. ..- attr(*, "order")= int(0)
  .. .. .. ..- attr(*, "intercept")= int 1
  .. .. .. ..- attr(*, "response")= int 1
  .. .. .. ..- attr(*, ".Environment")=<environment: R_GlobalEnv>
  .. .. .. ..- attr(*, "predvars")= language list(Logl)
  .. .. .. ..- attr(*, "dataClasses")= Named chr "numeric"
  .. .. .. .. ..- attr(*, "names")= chr "Logl"
  ..@ call    : language lmer(formula = Logl ~ 1 | Species, data = Data)
  ..@ flist   :'data.frame':    92093 obs. of  1 variable:
  .. ..$ Species: Factor w/ 50 levels "ABH","ABL","ANG",..: 20 18 32 29 
48 3 21 2 31 24 ...
  .. ..- attr(*, "assign")= int 1
  ..@ X       : num [1:92093, 1] 1 1 1 1 1 1 1 1 1 1 ...
  .. ..- attr(*, "assign")= int 0
  ..@ Xst     :Formal class 'dgCMatrix' [package "Matrix"] with 6 slots
  .. .. ..@ i       : int(0)
  .. .. ..@ p       : int 0
  .. .. ..@ Dim     : int [1:2] 0 0
  .. .. ..@ Dimnames:List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. .. ..@ x       : num(0)
  .. .. ..@ factors : list()
  ..@ Zt      :Formal class 'dgCMatrix' [package "Matrix"] with 6 slots
  .. .. ..@ i       : int [1:92093] 19 17 31 28 47 2 20 1 30 23 ...
  .. .. ..@ p       : int [1:92094] 0 1 2 3 4 5 6 7 8 9 ...
  .. .. ..@ Dim     : int [1:2] 50 92093
  .. .. ..@ Dimnames:List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. .. ..@ x       : num [1:92093] 1 1 1 1 1 1 1 1 1 1 ...
  .. .. ..@ factors : list()
  ..@ pWt     : num(0)
  ..@ offset  : num(0)
  ..@ y       : num [1:92093] 3.72 4.35 4.83 4.56 5.5 ...
  ..@ Gp      : int [1:2] 0 50
  ..@ dims    : Named int [1:18] 1 92093 1 50 1 1 0 1 2 5 ...
  .. ..- attr(*, "names")= chr [1:18] "nt" "n" "p" "q" ...
  ..@ ST      :List of 1
  .. ..$ : num [1, 1] 1.41
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : chr "(Intercept)"
  .. .. .. ..$ : chr "(Intercept)"
  ..@ V       : num[0 , 0 ]
  ..@ A       :Formal class 'dgCMatrix' [package "Matrix"] with 6 slots
  .. .. ..@ i       : int [1:92093] 19 17 31 28 47 2 20 1 30 23 ...
  .. .. ..@ p       : int [1:92094] 0 1 2 3 4 5 6 7 8 9 ...
  .. .. ..@ Dim     : int [1:2] 50 92093
  .. .. ..@ Dimnames:List of 2
  .. .. .. ..$ : chr [1:50] "ABH" "ABL" "ANG" "APR" ...
  .. .. .. ..$ : NULL
  .. .. ..@ x       : num [1:92093] 1.41 1.41 1.41 1.41 1.41 ...
  .. .. ..@ factors : list()
  ..@ Cm      :Formal class 'dgCMatrix' [package "Matrix"] with 6 slots
  .. .. ..@ i       : int(0)
  .. .. ..@ p       : int 0
  .. .. ..@ Dim     : int [1:2] 0 0
  .. .. ..@ Dimnames:List of 2
  .. .. .. ..$ : NULL
  .. .. .. ..$ : NULL
  .. .. ..@ x       : num(0)
  .. .. ..@ factors : list()
  ..@ Cx      : num(0)
  ..@ L       :Formal class 'dCHMsimpl' [package "Matrix"] with 10 slots
  .. .. ..@ x       : num [1:50] 19.48 84.97 95.87 4.35 10.7 ...
  .. .. ..@ p       : int [1:51] 0 1 2 3 4 5 6 7 8 9 ...
  .. .. ..@ i       : int [1:50] 0 1 2 3 4 5 6 7 8 9 ...
  .. .. ..@ nz      : int [1:50] 1 1 1 1 1 1 1 1 1 1 ...
  .. .. ..@ nxt     : int [1:52] 1 2 3 4 5 6 7 8 9 10 ...
  .. .. ..@ prv     : int [1:52] 51 0 1 2 3 4 5 6 7 8 ...
  .. .. ..@ colcount: int [1:50] 1 1 1 1 1 1 1 1 1 1 ...
  .. .. ..@ perm    : int [1:50] 0 1 2 3 4 5 6 7 8 9 ...
  .. .. ..@ type    : int [1:4] 2 1 0 1
  .. .. ..@ Dim     : int [1:2] 50 50
  ..@ deviance: Named num [1:13] 9.97e+04 9.97e+04 3.61e+02 3.22 
4.15e-01 ...
  .. ..- attr(*, "names")= chr [1:13] "ML" "REML" "ldL2" "ldRX2" ...
  ..@ fixef   : Named num 4.79
  .. ..- attr(*, "names")= chr "(Intercept)"
  ..@ ranef   : num [1:50] -0.9126 -0.4434 1.3085 -0.0774 0.2951 ...
  ..@ u       : num [1:50] -0.6463 -0.3141 0.9267 -0.0548 0.209 ...
  ..@ eta     : num [1:92093] 3.68 4.22 4.82 4.26 5.1 ...
  ..@ mu      : num [1:92093] 3.68 4.22 4.82 4.26 5.1 ...
  ..@ muEta   : num(0)
  ..@ var     : num(0)
  ..@ resid   : num [1:92093] 0.03999 0.12217 0.00859 0.30464 0.40331 ...
  ..@ sqrtXWt : num[0 , 1]
  ..@ sqrtrWt : num(0)
  ..@ RZX     : num [1:50, 1] 13.77 60.2 67.92 2.92 7.52 ...
  ..@ RX      : num [1, 1] 5
  ..@ ghx     : num(0)
  ..@ ghw     : num(0)


David Duffy wrote:
> On Wed, 24 Mar 2010, Eric Edeline wrote:
>
>> I am having troubles with getting a summary for lmer and glmer models 
>> that otherwise (apparently) converged properly (i can for instance 
>> extract ranefs). Could anyone point to me the mistake?
>
> Could you show us str(m11) ?
>

-- 
Eric Edeline
Assistant Professor
UMR 7618 BIOEMCO
Ecole Normale Sup?rieure
46 rue d'Ulm
75230 Paris cedex 05
France

Tel: +33 (0)1 44 32 38 84
Fax: +33 (0)1 44 32 38 85

http://www.biologie.ens.fr/bioemco/biodiversite/edeline.html



From charpent at bacbuc.dyndns.org  Thu Mar 25 00:58:44 2010
From: charpent at bacbuc.dyndns.org (Emmanuel Charpentier)
Date: Thu, 25 Mar 2010 00:58:44 +0100
Subject: [R-sig-ME] missing data + explanatory variables
In-Reply-To: <c8e8cd3d1003240409r27cfb4c0w897cae92d391942f@mail.gmail.com>
References: <c8e8cd3d1003240409r27cfb4c0w897cae92d391942f@mail.gmail.com>
Message-ID: <1269475123.3194.343.camel@PortableToshiba>

I have been fighting (part of) these questions, too. Below some partial
an temporary answers.

Le mercredi 24 mars 2010 ? 12:09 +0100, christophe dutang a ?crit :
> Dear list,
> 
> I have two problems when I try to use mixed models. First as far as I know,
> there are two main implementations of mixed models: lme4 and MCMCglmm.
> 
> I try to model a binary response variable over a small period of time. The
> problem is that for some lines, the response is missing. In this mailing
> list archive, I do not find response to this question.
> 
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q4/002940.htmlproposes
> the MCMCglmm but I check the package and missing data are not
> handled
> 
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q3/002579.html, no
> solution
> 
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q1/001794.htmlproposes
> the EM algorithm to solve the problem
> 
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2008q3/001188.html says
> missing data in covariates can be handled directly by R or SAS.
> 
> As I'm a beginner in the use of mixed models, I spent a lot of times reading
> on this topic. And in the book of Edward Frees 'longitudinal and panel
> data', estimation seems to be available for missing data? And there is an
> article promoting the use of mixed model for that feature:
> 'A Comparison of the General Linear Mixed Model and Repeated Measures ANOVA
> Using a Dataset with Multiple Missing Data Points'

I'd be interested in references for this paper. Google led me to :

@article{krueger_tian_2004, title={A Comparison of the General Linear
Mixed Model and Repeated Measures ANOVA Using a Dataset with Multiple
Missing Data Points}, volume={6}, DOI={10.1177/1099800404267682},
number={2}, journal={Biol Res Nurs}, author={Krueger, Charlene and Tian,
Lili}, year={2004}, month={Oct}, pages={151-157}} ,

and it does not seem to be available in any of my country's (France)
academic libraries : the closest sources I can get are in Germany or
UK...

I'm a bit surprised by the abstract note (edited out above). Any model
can (theoretically) be used to impute missing data ; theoretical work of
Rubin and followers have shown that a) this was desirable, since
discarding incomplete observations ("complete-cases analysis") would
lead in many cases to biased estimates, b) such imputation could be done
"semi-automatically" in two special cases ("missing completely at
random" and "missing at random" data (in other cases, one must *also*
model the missing data mechanism), by specifying a distribution for
variables with missing data, c) that such imputation should be done at
least  few times in order to estimate the excess variability that this
estimation procedure adds to estimators, and d) that such multiple
imputations should be combined by incorporation of this excess
variability.

Mixed models explicitly model part of the inter-individual variation, by
splitting it between between-groups and within-group variabilities.
Therefore, imputation might be more precise. But they do not, *by
themselves*, allow for imputation.

Bayesian estimation of mixed model parameters, which is becoming popular
thanks to the BUGS language and recent textbooks, such as Gelman & Hill
(2007) (recommended reading, even if you are no bound to adhere to all
conclusions...), sort-of facilitates this imputation process, but only
in the sense that it is (relatively) easy to specify (at least in BUGS)
a (reasonable) a priori distribution for any variable (but it is not
always easy to obtain and assess numerical convergence...).

Other solutions have been proposed. At least three package aim at
proposing a "reasonable" imputation model for missing data : AmeliaII
(which I did not fully explore, since it is a bit "closed"), mice (which
is quite "open", but whose current version (2.3) has some problems in
specifying specialized imputation functions) and mi (Gelman & his gang,
close to the ideas of the textbook mentioned above), which I did not yet
explore fully, seems interesting but a bit awkward if you need to use
specialized imputation functions.

Various packages allow for estimation from a multiply-imputed dataset :
mice and mi, of course, , but also mitools and (reportedly) Zelig. The
only one that tries to implement hypothesis testing (e. g. test for the
"significance" of a whole factor) is mice. But I'm less and less
convinced of the necessity of such a procedure, notwithstanding journal
editor's wishes, whims and tantrums (see below).

Bayesian estimation "automatically" incorporate missing data's added
uncertainty, since it uses a full probability model for imputing them
(it can also incorportate relevant prior information if available, which
could be extremely valuable but might invalidate your imputations from a
"strict frequentist" point of view). But it can do so only if it is
build for using and modeling all data. Some specialized software, such
as MCMCpack, are built on the assumption of a complete dataset and
assumptions of a predefined shape of a priori distributions of the
variables (quite often a so-called 'uninformative' distribution). If you
have indeed missing covariates, it won't model it and exclude the
relevant observations, thus leading to the same problems that plague
"complete-cases analysis".

Similarly, lmer, as far as I can tell, does assume some shape of the
group-level coefficients and fo the distribution of the dependant
variable given its predictors, but won't impute missing data. Ditto, as
far as I can tell, for MCMCglmm.


> So I do not understand why we can't have missing data?

Because there is no probability model for imputation (nor an estimation
combining procedure) in (g)lmer nor in MCMCglmm.

> Secondly, the presentation of D. Bates done at Max Planck Institute in 2009
> states that p-values are not available for mixed models because the
> distribution of parameter estimators are not known.
> 
> My question is how can we know that an explanatory variable is significant?
> is the only tool to fit another model without the variable and to use the
> anova function?

Because 1) you did not specify *what* is a "significant variable" :-),
and 2) the exact distribution of the possible "test statistics" (Wald ?
Score ? Likelihood ratios ? Ad-hoc relevant statistic ?)  are not known
at least in the general case. The simplified models that were proposed
about 50 years ago for the (very) special case of *balanced* datasets
resulting from *designed* experiments (implemented in the aov()
function) do not hold for the ((much) more) general case (g)lmer aims to
implement.

Look in the R-help archives for a long discussion of the problem of such
hypothesis testing. Douglas Bates stated (rightly, IMNSHO) that
reproducing "what SAS does" was *not*, to his eyes, a good enough reason
to implement it, and explained (some of) his misgivings. See also his
book (Pinhero & bates (2000)) which gives good examples of the problem
(met with nlme, predecessor to lme4).

The proposed solution is to use MCMC sampling from the distributions
proposed as a solution by (g)lmer, and use this as a basis for taking
such decisions (that is what hypothesis testing aims to do).

The fly in the ointment is that, as far as I can tell, the relevant
functions are currently *broken* in current "stable" and "development"
versions of lme4 (and not yet written for some non-Gaussian cases). This
has been discussed on this list.

But the crux of the matter is that the second, technical point might be
not as important as the first : barrels of ink were spent discussing the
*epistemological* status of "significance" in hypothesis testing, which
became "standard operating procedure" probably for reasons having little
relevance to sound epistemology. Nowadays, we use electrons, but the
pendulum seems to be starting in the other direction : confidence
interval estimation is now often regarded as a better indication of the
importance of your findings than a "p-value".

A lot more could  be written about the use and misuse of hypothesis
testing, and even much more bout the (possible) relevance of Bayesian
analysis of multilevel models and its interpretation, but "this is
another story" an I've probably been already too long... A look at the
relevant literature should keep you amused, sometimes bored, but anyway
busy for quite a bit of time:-).

HTH,

					Emmanuel Charpentier, DDS, MSc

> Thanks in advance
> 
> Christophe
> 



From charpent at bacbuc.dyndns.org  Thu Mar 25 21:55:14 2010
From: charpent at bacbuc.dyndns.org (Emmanuel Charpentier)
Date: Thu, 25 Mar 2010 21:55:14 +0100
Subject: [R-sig-ME] missing data + explanatory variables : important
	complement.
In-Reply-To: <c8e8cd3d1003240409r27cfb4c0w897cae92d391942f@mail.gmail.com>
References: <c8e8cd3d1003240409r27cfb4c0w897cae92d391942f@mail.gmail.com>
Message-ID: <1269550513.3194.435.camel@PortableToshiba>

Some additions to what I wrote yesterday : I misunderstood the aim of
the paper as explained in its abstract, and started too far ...

Le mercredi 24 mars 2010 ? 12:09 +0100, christophe dutang a ?crit :
> Dear list,
> 
> I have two problems when I try to use mixed models. First as far as I know,
> there are two main implementations of mixed models: lme4 and MCMCglmm.
> 
> I try to model a binary response variable over a small period of time. The
> problem is that for some lines, the response is missing. In this mailing
> list archive, I do not find response to this question.
> 
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q4/002940.htmlproposes
> the MCMCglmm but I check the package and missing data are not
> handled
> 
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q3/002579.html, no
> solution
> 
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q1/001794.htmlproposes
> the EM algorithm to solve the problem
> 
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2008q3/001188.html says
> missing data in covariates can be handled directly by R or SAS.
> 
> As I'm a beginner in the use of mixed models, I spent a lot of times reading
> on this topic. And in the book of Edward Frees 'longitudinal and panel
> data', estimation seems to be available for missing data? And there is an
> article promoting the use of mixed model for that feature:
> 'A Comparison of the General Linear Mixed Model and Repeated Measures ANOVA
> Using a Dataset with Multiple Missing Data Points'
> 
> So I do not understand why we can't have missing data?

Okay. I have been able to lay my eyes on this article. The point it
makes is that the "mixed model" approach to analysing repeated
measurements on the same subject allows you to use observations made on
this subject having complete data, discarding only the *observations*
with missing data, whereas the old "repeated measures ANOVA" would lead
you to ignore *all* observations made on a *subject* having *one*
observation with missing data.

This is due to the fact that what the article calls the "repeated
measures ANOVA" algorithms were (geometrically very smart) *manually*
computable simplifications of a more general procedure involving, in the
general case, manually intractable computation (multiple matrix
inversions of not-so-small dimensions) ; these simplifications (and the
resulting algorithms) were valid only for at least partially *balanced*
datasets.

(g)lmer() (and its predecessor lme()) of course allow for this use of
data on incompletely documented *subjects*. This is so obvious to users
of "modern" software (i. e. using something else than transcriptions of
manual computation algorithms) that it is no longer mentioned as an
issue. The situation is similar to 2-way fixed-effects ANOVA, where the
"manual" algorithm I was taught ... too long a time ago *demanded* a
balanced datasets, which is a requirement that ended even with BMDP (end
of 70's, IIRC). Similarly, nowhere I'm aware of the authors of lm()
mention that multiway-models do not have to be balanced : that's
granted...

However, what the authors of that papers of yours do *not* mention is
that analyzing this incomplete dataset by using all the complete
*observations*, while better that using only complete *subjects*, might
still lead to biased estimates, and that debiasing them should involve
multiple imputations of missing data in incomplete *observations*. That
subject was well explored by Rubin (since the 80's IIRC), and involves
the specialized packages I mentioned yesterday ... or turning to
Bayesian estimation, which is a horse of an entirely different color.
Look up the 2nd edition of Rubin's book (ca 1998 IIRC) on the subject
for (much) better explanations.

To summarize :

Repeated-measures ANOVA : manually tractable, needs balanced datasets,
therefore forces you to ignore incomplete *subjects*. Obsolete (but
smart an historically important).

Mixed-model ANOVA : manually intractable, accepts unbalanced datasets
but does not allow for partial observations, therefore forces you to
ignore incomplete *observations*. Modern solution, but does not accounts
for possible bias due to missing data.

===== Your paper stops here (and I started here yesterday) =====

Multiple imputations + Mixed-model ANOVA : allows you to use all
available information, estimates the loss of information incurred by
missing data and attempts to make up for it. Best frequentist
(classical) solution, needs specialized software, and might require
special modeling efforts of the missing-data mechanism if "missing at
random" is not "obviously" reasonable.

Bayesian modeling : requires serious efforts to model both the
phenomenon of interest, its covariates and possibly the missing-data
mechanism and a priori information, needs some awareness of the
computational difficulties (not always solvable), current tools not yet
perfected, but is (theoretically) the best possible solution since it
attempts to model the joint distribution of all data, including their
missingness. The answers it leads to (distributions, credible intervals,
Bayes factors, probabilities) have intuitive meanings, quite different
of "frequentist" confidence intervals and p-values, and might not (yet)
be accepted in some circles insisting, for example, on hypothesis
testing.

HTH,

						Emmanuel Charpentier

PS : since "manual" algorithms are out of practical use since the end of
the 70s and the inception of what was then called "personal computers",
I'm a bit surprised that a paper published in 2004 still invokes that
issue... Is your domain special (or especially conservative) ?



From dutangc at gmail.com  Thu Mar 25 23:13:21 2010
From: dutangc at gmail.com (Christophe Dutang)
Date: Thu, 25 Mar 2010 23:13:21 +0100
Subject: [R-sig-ME] missing data + explanatory variables
In-Reply-To: <Pine.LNX.4.64.1003250727070.15751@orpheus.qimr.edu.au>
References: <c8e8cd3d1003240409r27cfb4c0w897cae92d391942f@mail.gmail.com>
	<Pine.LNX.4.64.1003250727070.15751@orpheus.qimr.edu.au>
Message-ID: <6A2368B1-6ED7-48EF-AECC-712AA6865D26@gmail.com>

Thanks David for your answer,

Le 24 mars 2010 ? 22:37, David Duffy a ?crit :

> On Wed, 24 Mar 2010, christophe dutang wrote:
> 
>> Dear list,
>> 
>> I have two problems when I try to use mixed models. First as far as I know,
>> there are two main implementations of mixed models: lme4 and MCMCglmm.
>> 
>> I try to model a binary response variable over a small period of time. The
>> problem is that for some lines, the response is missing. In this mailing
>> list archive, I do not find response to this question.
>> 
> 
> It doesn't matter if the response variable is missing -- that merely makes the design unbalanced.  If a covariate is missing, then it is more difficult.
I don't understand how to do it with the lmer function. The following R code remove the line with missing response:

library(lme4)

fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
sleepstudy2 <- sleepstudy
sleepstudy2[180, "Reaction"] <- NA
fm2 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy2)

What am I doing wrong?

> 
>> My question is how can we know that an explanatory variable is significant?
>> is the only tool to fit another model without the variable and to use the
>> anova function?
> 
> The likelihood ratio test from anova() is the "gold standard", with the proviso that the distribution of the test statistic may not be a simple chi-squared distribution, which is what we usually assume.
That was what I had understood.

> RLRSim is a package for getting a more accurate P-value if you are testing for presence or absence of a random effect.
I hope I can used it with the lme4 functions.

> 
> If you are talking about a fixed explanatory effect, you can always construct a Wald test if you are willing to accept certain assumptions about your data.
Do I have to code something or is there any package implementing the Wald test?

Christophe

> 
> HTH, David Duffy.
> 
> -- 
> | David Duffy (MBBS PhD)                                         ,-_|\
> | email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
> | Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
> | 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v

--
Christophe Dutang
Ph.D. student at ISFA, Lyon, France
website: http://dutangc.free.fr



From bolker at ufl.edu  Fri Mar 26 04:12:48 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Fri, 26 Mar 2010 03:12:48 +0000 (UTC)
Subject: [R-sig-ME] Could not get a lmer or glmer summary
References: <4BAA0F2B.8050404@biologie.ens.fr>
	<Pine.LNX.4.64.1003250738380.15751@orpheus.qimr.edu.au>
	<4BAB09E2.9030806@biologie.ens.fr>
Message-ID: <loom.20100326T040207-830@post.gmane.org>

Eric Edeline <edeline at ...> writes:

> 
> Dear David,
> 
> here is the Str(m11):
> 
>  > m11<-lmer(Logl ~ 1|Species, data=Data)
>  > str(m11)
> Formal class 'mer' [package "lme4"] with 34 slots
>   ..@ env     :<environment: 0xc077a5c>
>   ..@ nlmodel : language I(x)
>   ..@ frame   :'data.frame':    92093 obs. of  2 variables:
>   .. ..$ Logl   : num [1:92093] 3.72 4.35 4.83 4.56 5.5 ...
>   .. ..$ Species: Factor w/ 50 levels "ABH","ABL","ANG",..: 20 18 32 29 
> 48 3 21 2 31 24 ...

  [snip snip snip]

  Nothing really obvious pops out.
  I know your data set is really large, but can you either post
it somewhere, or see if a subset of your data set gives you the
same problem?  If it doesn't (i.e. if you only get problems with
the full data set) maybe that will provide a hint.
 
  I made up data that looked a little bit like yours 
and didn't have a problem:

> set.seed(1001)
> Logl <- rnorm(92093)
> Species <- factor(rep(1:50,200))[1:92093]
> Data <- data.frame(Logl,Species)
> m11 <- lmer(Logl~1|Species,data=Data)
> m11
Linear mixed model fit by REML 
Formula: Logl ~ 1 | Species 
   Data: Data 
   AIC   BIC logLik deviance REMLdev
 28375 28396 -14184    28361   28369
Random effects:
 Groups   Name        Variance   Std.Dev.
 Species  (Intercept) 0.00089705 0.029951
 Residual             0.99753902 0.998769
Number of obs: 10000, groups: Species, 50

Fixed effects:
              Estimate Std. Error t value
(Intercept) -0.0003448  0.0108462  -0.032
> nrow(Data)
[1] 92093

  ... although there is one weird thing, that
"number of obs." is reported as 10000 (???)

> sessionInfo()
R version 2.10.1 (2009-12-14) 
i486-pc-linux-gnu 

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] lme4_0.999375-32   Matrix_0.999375-38 lattice_0.18-3    

loaded via a namespace (and not attached):
[1] grid_2.10.1



From bolker at ufl.edu  Fri Mar 26 04:34:40 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Fri, 26 Mar 2010 03:34:40 +0000 (UTC)
Subject: [R-sig-ME] Mixed effects model selection
References: <20100324110147.qzbnbc1ao88cs8sc@www.mail.yale.edu>
Message-ID: <loom.20100326T042802-393@post.gmane.org>

 <hamish.wilman at ...> writes:

> I am trying to perform model selection starting from an overly parameterized
> model of the form:
> 
> mdl1<- lmer(Y ~ Sa + Sb + c + d + e + f + (c + d + e + f|SpeciesID), 
> REML = F)
> 
> where Sa and Sb are species-level 
> predictors and the others are population level
> predictors, so can potentially vary within species (hence their inclusion as
> slopes in the random effects term).
> 
> In Zuur et al 2009 it is suggested that one starts with a full 
> model like this
> and first perform selection on the random effects, 
> then move on to do selection
> on the fixed effects.
> 
> The procedure I have been using is to remove one item at a 
> time from the random
> effects, in effect plotting four new models, each missing one of the slope
> parameters in the random effects, then using likelihood ratio tests (LRT) to
> compare them to the full model. I throw out the variable with the lowest
> non-significant LRT test statistic (realizing that the p-values are
> conservative). I then repeat this procedure until all variables are
> "indispensable" as defined by the LRT.
> 
> I do this with the fixed effects after selecting for the random effects. The
> justification in Zuur for doing the selection on the random effects first, 
> with all possible fixed effects in there, is that any variation 
> potentially explained
> by the fixed effects should stay there and the 
> random effects then give you what
> doesn't show up in the fixed effects.
> 
> First of all, does this model selection procedure sound reasonable?

  While I generally like Zuur et al's approach, the one place where
I differ fairly strongly is in model selection.  There is now a *lot*
of literature out there that explains the dangers of stepwise approaches;
Harrell's 2001 book is probably the most coherent and comprehensive.
My compromise is that I am willing to discard terms (a) to allow the
model to fit (i.e., to deal with convergence and other numeric problems)
and (b) to simplify interpretation (i.e., getting rid of higher-order
interaction can make interpretation of everything else much easier).

  If your full model appears to fit adequately (i.e. it doesn't
break the fitting software), and if you want to test hypotheses
about the effects of the individual effects, then I would say you
should not do any model reduction (others may disagree).

> 
> Now, when I complete this procedure on my model, 
> the resulting best model looks
> like this:
> 
> mdl.final<- lmer(Y ~ Sa + Sb + c + d + (e + f|SpeciesID), REML = F)
> 
> My question is whether you can have variables in 
> the slope portion of the random
> effects that are not in the fixed effects,
> and if so what is the interpretation
> of their "influence"?

   It only makes sense in the situation where the hypothesis
that the species-level average of e and f across populations
is *exactly* zero, which seems somewhat dubious.  This is somewhat
analogous to dropping an intercept term from a regression while
retaining the slope: it's not impossible to find situations where
a regression that goes exactly through the origin is a reasonable
hypothesis, but it's unusual.



From jana.buerger at uni-rostock.de  Fri Mar 26 14:35:52 2010
From: jana.buerger at uni-rostock.de (=?ISO-8859-15?Q?Jana_B=FCrger?=)
Date: Fri, 26 Mar 2010 14:35:52 +0100
Subject: [R-sig-ME] unbalanced data in nested lmer model
In-Reply-To: <4BAA3810.4010701@life.ku.dk>
References: <4BAA0B06.1030806@uni-rostock.de> <4BAA3810.4010701@life.ku.dk>
Message-ID: <4BACB838.7000608@uni-rostock.de>

Dear Christian,

thank you for your answer, it was helpful and does reflect my own ways 
of thought.
Now you point out that the random effects are somewhat irrelevant 
becuase the fixed effects are the thing of interest.
In fact, the region and the farm are not just features of my study 
design but have practical relevance for the response variable. Just I 
don't want to know the exact parameters for the different regions and farms.

Am I wrong thinking that the random effects part of the model makes it 
possible to compare magnitude of influence of the region and the farm, 
and also of the sum of my fixed predictor variables (as given in Residuals)?

In this context, what are the consequences of the sructure of my data, 
with a couple of regions with only one farm?

Any more helpful thoughts are appreciated.

Christian Ritz schrieb:
> Dear Jana,
> 
> let me try to answer your questions:
> 
> 1) No there are no restrictions on how much imbalance there can be. In fact, it's one of
> the advantages of the mixed model approach!
> 
> However, cells with 0 cases will not be used in the model fit. The mixed model will
> "automatically" take the varying number of cases into account in estimates and standard
> errors.
> 
> 2) The imbalance in several random factors will indirectly influence the standard errors
> of the fixed effects estimates (as the fixed effects estimates are obtained through a
> weighted least squares approach with weights reflecting the random effects structure in
> the model).
> 
> As the structure of your data is hierarchical with fields, farms, and regions it makes
> sense to me to have random effects
> 
> (1|region) and (1|region:farm)
> 
> 
> in the model. Actually I don't see the point in testing a feature of the data that was
> imposed by the design of the study or experiment. Just leave both terms in the models and
> proceed to evaluate the fixed effects.
> 
> Random effects reflect structure in the data that is imposed by how the data were
> collected or the underlying experiment designed and therefore it's rarely relevant to test
> this part of the model (it's simply the framework within which we examine some interesting
> explanatory variable). I guess, however, that other statisticians might a different
> opinion about this issue.
> 
> I hope this explanation is useful?!
> 
> Christian
> 

-- 
Jana B?rger

Universit?t Rostock
Agrar-  und Umweltwissenschaftliche Fakult?t
FG Phytomedizin
Satower Stra?e 48
18059 Rostock

Tel. 0381-498 31 71
Fax.0381-498 31 62



From andydolman at gmail.com  Fri Mar 26 15:45:56 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Fri, 26 Mar 2010 14:45:56 +0000
Subject: [R-sig-ME] unbalanced data in nested lmer model
In-Reply-To: <4BACB838.7000608@uni-rostock.de>
References: <4BAA0B06.1030806@uni-rostock.de> <4BAA3810.4010701@life.ku.dk>
	<4BACB838.7000608@uni-rostock.de>
Message-ID: <951234ac1003260745k6590c26cj887dc17aae83a9c4@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100326/23ab0a86/attachment.pl>

From Eric.Castet at incm.cnrs-mrs.fr  Fri Mar 26 19:18:03 2010
From: Eric.Castet at incm.cnrs-mrs.fr (Eric Castet)
Date: Fri, 26 Mar 2010 19:18:03 +0100
Subject: [R-sig-ME] Correlation of -1: is it a problem?
Message-ID: <4BACFA5B.5050707@incm.cnrs-mrs.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100326/fcde75d5/attachment.pl>

From dutangc at gmail.com  Fri Mar 26 18:15:31 2010
From: dutangc at gmail.com (christophe dutang)
Date: Fri, 26 Mar 2010 18:15:31 +0100
Subject: [R-sig-ME] missing data + explanatory variables
In-Reply-To: <Pine.LNX.4.64.1003261003520.22301@orpheus.qimr.edu.au>
References: <c8e8cd3d1003240409r27cfb4c0w897cae92d391942f@mail.gmail.com>
	<Pine.LNX.4.64.1003250727070.15751@orpheus.qimr.edu.au>
	<6A2368B1-6ED7-48EF-AECC-712AA6865D26@gmail.com>
	<Pine.LNX.4.64.1003261003520.22301@orpheus.qimr.edu.au>
Message-ID: <w2uc8e8cd3d1003261015j3e52c20dmde89ec65ac2c1c4c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100326/5355d326/attachment.pl>

From bates at stat.wisc.edu  Fri Mar 26 20:06:52 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 26 Mar 2010 14:06:52 -0500
Subject: [R-sig-ME] Correlation of -1: is it a problem?
In-Reply-To: <4BACFA5B.5050707@incm.cnrs-mrs.fr>
References: <4BACFA5B.5050707@incm.cnrs-mrs.fr>
Message-ID: <40e66e0b1003261206u2ce669c9rc0d978e67701f73c@mail.gmail.com>

On Fri, Mar 26, 2010 at 1:18 PM, Eric Castet
<Eric.Castet at incm.cnrs-mrs.fr> wrote:
> Dear all,
>
> I would be grateful if you could help me with the following question
> using lmer()
> I want to test the effect of a categorical factor with two levels
> (called 'couleurs')
> The only random factor is 'nom'.
>
> I first start with all random effects (I only report the lines for the
> random effects):
> Linear mixed model fit by maximum likelihood
> Formula: lRT ~ couleurs + (1 + couleurs | nom)
> Random effects:
> ?Groups ? ? ? ? ?Name ? ? ? ? ? ?Variance ?Std.Dev. Corr
> ?nom ? ? ? ? ? ? ?(Intercept) ? ? 0.1376693 0.371038
> ? ? ? ? ? ? ? ? ? ? ?couleurs1 ? ? ? 0.0030358 0.055098 *-1.000 *
> ?Residual ? ? ? ? ? ? ? ? ? ? ? ? ? ? 0.5118424 0.715432
> Number of obs: 7927, groups: nom, 10
>
>
> Then, I remove the random effect of 'couleurs' ?with the following result:
>
> Linear mixed model fit by maximum likelihood
> Formula: lRT ~ couleurs + (1 | nom)
> ? Data: jb
>
> Random effects:
> ?Groups ? ? ? Name ? ? ? ? ? ?Variance Std.Dev.
> ?nom ? ? ? ? ?(Intercept) ? ? 0.11768 ?0.34304
> ?Residual ? ? ? ? ? ? ? ? ? ? ? ? 0.51263 ?0.71598
> Number of obs: 7927, groups: nom, 10
>
> I then compare the two models and see that I should go with the first
> model Df=6:
> ?> anova (jb.lmer1, jb.lmer2)
> Data: jb
> Models:
> jb.lmer2: lRT ~ couleurs + (1 | nom)
> jb.lmer1: lRT ~ couleurs + (1 + couleurs | nom)
> ? ? ? ? Df ? AIC ? BIC ?logLik ?Chisq Chi Df Pr(>Chisq)
> jb.lmer2 ?4 17259 17287 -8625.4
> jb.lmer1 ?6 17251 17293 -8619.4 12.078 ? ? ?2 ? 0.002384 **

> My questions are the following:

> a/ is it really a statistical (or numerical) problem to have a -1
> correlation in the model that I should keep?

Yes, it is.  The fitted model is has a singular variance-covariance
matrix for the random effects and that is not good.  In fact, it is no
longer a linear mixed model.

> b/ is it possible to remove the correlation between Intercept and
> Couleurs, as I would do if Couleurs were not a categorical factor?

I would fit another model of

IRT ~ couleurs + (1|nom:couleurs) + (1|nom)

and see how that works.  This model is, in some sense, intermediate to
the models that you have fit above.

>
> Thanks in advance,
>
> Eric Castet
>
>
>
>
> --
>
> Eric Castet
>
> Institut de Neurosciences Cognitives de la M?diterran?e -- INCM CNRS
>
> 31 chemin Joseph Aiguier
>
> 13402 Marseille cedex 20 (France)
>
> tel : (+33)(0)4-91-16-43-34
>
> fax : (+33) (0)4-91-16-44-98
>
> UMR 6193 du CNRS
>
> Universit? Aix-Marseille II
>
> http://www.incm.cnrs-mrs.fr/equipedyva.php
>
> http://www.incm.cnrs-mrs.fr/pperso/ecastet.php
>
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



From lborger at uoguelph.ca  Fri Mar 26 20:06:32 2010
From: lborger at uoguelph.ca (Luca Borger)
Date: Fri, 26 Mar 2010 15:06:32 -0400
Subject: [R-sig-ME] missing data + explanatory variables
References: <c8e8cd3d1003240409r27cfb4c0w897cae92d391942f@mail.gmail.com><Pine.LNX.4.64.1003250727070.15751@orpheus.qimr.edu.au><6A2368B1-6ED7-48EF-AECC-712AA6865D26@gmail.com><Pine.LNX.4.64.1003261003520.22301@orpheus.qimr.edu.au>
	<w2uc8e8cd3d1003261015j3e52c20dmde89ec65ac2c1c4c@mail.gmail.com>
Message-ID: <AF1F2446D9EF402AA3D10A0559F9D22A@lborger>

Hello,

> I don't receive anything from E. Charpentier?!

see:
http://markmail.org/search/?q=missing%20data%20%2B%20explanatory%20variables%20:%20important%20complement#query:missing%20data%20%2B%20explanatory%20variables%20%3A%20important%20complement+page:1+mid:oykvzrctut3dtpbj+state:results

> The problem is that my response is always of this pattern:
> 0 0 0 1
> 0 0 0 0
> 0 1 NA NA
> That's wher I had missing data, after the default, I don't have any data 
> for
> that individual. And the variable is necessary a sequence of 0 with a
> possible 1 at the end.
>
> I'm trying to use something better than the logistic GLM at each time
> period.

How about survival analysis with censoring?


HTH


Cheers,

Luca




----- Original Message ----- 
From: "christophe dutang" <dutangc at gmail.com>
To: "David Duffy" <David.Duffy at qimr.edu.au>
Cc: <r-sig-mixed-models at r-project.org>
Sent: Friday, March 26, 2010 1:15 PM
Subject: Re: [R-sig-ME] missing data + explanatory variables


> Hello,
>
> 2010/3/26 David Duffy <David.Duffy at qimr.edu.au>
>
>> On Thu, 25 Mar 2010, Christophe Dutang wrote:
>>
>>  I try to model a binary response variable over a small period of time. 
>> The
>>>>> problem is that for some lines, the response is missing. In this 
>>>>> mailing
>>>>> list archive, I do not find response to this question.
>>>>>
>>>>>  fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
>>> sleepstudy2 <- sleepstudy
>>> sleepstudy2[180, "Reaction"] <- NA
>>> fm2 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy2)
>>>
>>> What am I doing wrong?
>>>
>>
>> This worked perfectly, did it not?
>
> the observation number is reduced by 1.
>
>
>>  As Emmanuel Charpentier summarized, you can't use information from the
>> "lines" where the response is missing (expect for prediction, the BLUP)
>> unless you move to some type of multivariate model that explicitly models
>> the interrelationships of the covariates, like the multiple imputation
>> models or SEM.
>
> I don't receive anything from E. Charpentier?!
>
>
>> But in that case, all that happens is you gain a little bit of 
>> information
>> about the distributions of the covariates, which may or may not influence
>> your model for the response variable.
>>
>
> By "some lines are missing", I mean I don't have both the response and the
> covariate. Let me explain what I'm doing. I work on default of individual.
> Every 6 month for each indvidual the response variable equals to 1 if he
> defaults on the period, 0 otherwise. For each time period I also observe
> explanatory variables (age, job, marital status,...).
>
> The problem is that my response is always of this pattern:
> 0 0 0 1
> 0 0 0 0
> 0 1 NA NA
> That's wher I had missing data, after the default, I don't have any data 
> for
> that individual. And the variable is necessary a sequence of 0 with a
> possible 1 at the end.
>
> I'm trying to use something better than the logistic GLM at each time
> period.
>
> Thanks in advance for any advice
>
> Christophe
>
>
>>
>> PS what are the "lines" you refer to?  What is the actual problem you are
>> working on?
>>
>>
>> --
>> | David Duffy (MBBS PhD)                                         ,-_|\
>> | email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
>> | Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
>> | 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v
>>
>
>
>
> -- 
> Christophe DUTANG
> Ph. D. student at ISFA
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From edeline at biologie.ens.fr  Fri Mar 26 21:26:00 2010
From: edeline at biologie.ens.fr (Eric Edeline)
Date: Fri, 26 Mar 2010 21:26:00 +0100
Subject: [R-sig-ME] Could not get a lmer or glmer summary
In-Reply-To: <loom.20100326T040207-830@post.gmane.org>
References: <4BAA0F2B.8050404@biologie.ens.fr>	<Pine.LNX.4.64.1003250738380.15751@orpheus.qimr.edu.au>	<4BAB09E2.9030806@biologie.ens.fr>
	<loom.20100326T040207-830@post.gmane.org>
Message-ID: <4BAD1858.5020401@biologie.ens.fr>

Dear Ben,

thank you for your feed-back. I have now tested lmer on several datasets 
and I always get the same error message when asking for model summary. 
So the problem is with lme4, not with the data. Then, I ran the exact 
same models and data on another machine and it works fine! So the lme4 
problem is specific to my machine. Then, I tried brute force: 
uninstalling and re-installing R on my machine, but the lme4 problem 
remains. Any suggestion would be greatly appreciated.

Thanks!

Eric


Ben Bolker wrote:
> Eric Edeline <edeline at ...> writes:
>
>   
>> Dear David,
>>
>> here is the Str(m11):
>>
>>  > m11<-lmer(Logl ~ 1|Species, data=Data)
>>  > str(m11)
>> Formal class 'mer' [package "lme4"] with 34 slots
>>   ..@ env     :<environment: 0xc077a5c>
>>   ..@ nlmodel : language I(x)
>>   ..@ frame   :'data.frame':    92093 obs. of  2 variables:
>>   .. ..$ Logl   : num [1:92093] 3.72 4.35 4.83 4.56 5.5 ...
>>   .. ..$ Species: Factor w/ 50 levels "ABH","ABL","ANG",..: 20 18 32 29 
>> 48 3 21 2 31 24 ...
>>     
>
>   [snip snip snip]
>
>   Nothing really obvious pops out.
>   I know your data set is really large, but can you either post
> it somewhere, or see if a subset of your data set gives you the
> same problem?  If it doesn't (i.e. if you only get problems with
> the full data set) maybe that will provide a hint.
>  
>   I made up data that looked a little bit like yours 
> and didn't have a problem:
>
>   
>> set.seed(1001)
>> Logl <- rnorm(92093)
>> Species <- factor(rep(1:50,200))[1:92093]
>> Data <- data.frame(Logl,Species)
>> m11 <- lmer(Logl~1|Species,data=Data)
>> m11
>>     
> Linear mixed model fit by REML 
> Formula: Logl ~ 1 | Species 
>    Data: Data 
>    AIC   BIC logLik deviance REMLdev
>  28375 28396 -14184    28361   28369
> Random effects:
>  Groups   Name        Variance   Std.Dev.
>  Species  (Intercept) 0.00089705 0.029951
>  Residual             0.99753902 0.998769
> Number of obs: 10000, groups: Species, 50
>
> Fixed effects:
>               Estimate Std. Error t value
> (Intercept) -0.0003448  0.0108462  -0.032
>   
>> nrow(Data)
>>     
> [1] 92093
>
>   ... although there is one weird thing, that
> "number of obs." is reported as 10000 (???)
>
>   
>> sessionInfo()
>>     
> R version 2.10.1 (2009-12-14) 
> i486-pc-linux-gnu 
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
>  [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8   
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C            
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base     
>
> other attached packages:
> [1] lme4_0.999375-32   Matrix_0.999375-38 lattice_0.18-3    
>
> loaded via a namespace (and not attached):
> [1] grid_2.10.1
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>   

-- 
Eric Edeline
Assistant Professor
UMR 7618 BIOEMCO
Ecole Normale Sup?rieure
46 rue d'Ulm
75230 Paris cedex 05
France

Tel: +33 (0)1 44 32 38 84
Fax: +33 (0)1 44 32 38 85

http://www.biologie.ens.fr/bioemco/biodiversite/edeline.html



From David.Duffy at qimr.edu.au  Fri Mar 26 23:30:35 2010
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Sat, 27 Mar 2010 08:30:35 +1000 (EST)
Subject: [R-sig-ME] Could not get a lmer or glmer summary
In-Reply-To: <4BAD1858.5020401@biologie.ens.fr>
References: <4BAA0F2B.8050404@biologie.ens.fr>
	<Pine.LNX.4.64.1003250738380.15751@orpheus.qimr.edu.au>
	<4BAB09E2.9030806@biologie.ens.fr><loom.20100326T040207-830@post.gmane.org>
	<4BAD1858.5020401@biologie.ens.fr>
Message-ID: <Pine.LNX.4.64.1003270816130.18180@orpheus.qimr.edu.au>

On Fri, 26 Mar 2010, Eric Edeline wrote:

> Dear Ben,
>
> thank you for your feed-back. I have now tested lmer on several datasets and 
> I always get the same error message when asking for model summary. So the 
> problem is with lme4, not with the data. Then, I ran the exact same models 
> and data on another machine and it works fine! So the lme4 problem is 
> specific to my machine. Then, I tried brute force: uninstalling and 
> re-installing R on my machine, but the lme4 problem remains.

Therefore, you either need to "just" extract the results you want from m11
directly (doing any necessary calculations yourself), or step through using a
debugger, or send all the files to Douglas Bates ;)

Cheers, David Duffy.
-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From adik at ilovebacon.org  Sat Mar 27 00:51:48 2010
From: adik at ilovebacon.org (Adam D. I. Kramer)
Date: Fri, 26 Mar 2010 16:51:48 -0700 (PDT)
Subject: [R-sig-ME] Significance and lmer
Message-ID: <Pine.LNX.4.64.1003261645480.17783@ilovebacon.org>

Dear colleagues,

Please consider this series of commands:

a <- lmer(log(stddiff+.1539) ~ pred + m*v + option + (option|studyID),
data=r1, subset=option>1, REML=FALSE)

b <- update(a, . ~ . - pred)

anova(a,b)

...am I mistaken in thinking that the latter command will produce a test of
whether "pred" is a significant predictor of log(stddiff+.1539)? I am
concerned because of the results:

> coef(a)
                  Estimate   Std. Error    t value
(Intercept) -0.6608993664 0.1591862808 -4.1517357
pred         0.0879255592 0.1715599954  0.5125062
ml           0.0656916428 0.1173308419  0.5598838
vl          -0.0980204413 0.1276648229 -0.7677952
option       0.0003197903 0.0008134259  0.3931400
ml:vl       -0.1890574941 0.1710443092 -1.1053130

...note a t-value of 0.51 for this item...very small! ...but anova(a,b) produces this:

Models:
b: log(stddiff + 0.1539) ~ m + v + option + (option | studyID) +
b:     m:v
a: log(stddiff + 0.1539) ~ pred + m * v + option + (option | studyID)
   Df    AIC    BIC  logLik  Chisq Chi Df Pr(>Chisq)
b  9 3969.2 4019.1 -1975.6
a 10 3955.9 4011.2 -1967.9 15.345      1  8.954e-05 ***
---

...a significant result completely unrelated to the t-value. My
interpretation of this would be that we have no good evidence that the
estimate for 'pred' is nonzero, but including pred in the model improves
prediction.

I think I must be missing something here--I would appreciate anyone's input
on what that "something" is.

Cordially,
--
Adam D. I. Kramer
Ph.D. Candidate, Social Psychology
University of Oregon
adik-rhelp at ilovebacon.org



From edeline at biologie.ens.fr  Sat Mar 27 14:59:48 2010
From: edeline at biologie.ens.fr (Eric Edeline)
Date: Sat, 27 Mar 2010 14:59:48 +0100
Subject: [R-sig-ME] Could not get a lmer or glmer summary
In-Reply-To: <Pine.LNX.4.64.1003270816130.18180@orpheus.qimr.edu.au>
References: <4BAA0F2B.8050404@biologie.ens.fr>
	<Pine.LNX.4.64.1003250738380.15751@orpheus.qimr.edu.au>
	<4BAB09E2.9030806@biologie.ens.fr><loom.20100326T040207-830@post.gmane.org>
	<4BAD1858.5020401@biologie.ens.fr>
	<Pine.LNX.4.64.1003270816130.18180@orpheus.qimr.edu.au>
Message-ID: <4BAE0F54.3000809@biologie.ens.fr>

I have solved my problem, which was apparently due to a conflict between 
lme4 and another library (one of these: tree, VGAM, sn, Matrix, 
mclust...) about an "rcon" object if I remember well.  Removing all the 
libraries including lme4 from /usr/local/lib/R/site-library and 
re-installing lme4 in /usr/lib/R/site-library made the trick. Sorry for 
not providing more detailed information, I just do not remember more!

Cheers,

eric



David Duffy wrote:
> On Fri, 26 Mar 2010, Eric Edeline wrote:
>
>> Dear Ben,
>>
>> thank you for your feed-back. I have now tested lmer on several 
>> datasets and I always get the same error message when asking for 
>> model summary. So the problem is with lme4, not with the data. Then, 
>> I ran the exact same models and data on another machine and it works 
>> fine! So the lme4 problem is specific to my machine. Then, I tried 
>> brute force: uninstalling and re-installing R on my machine, but the 
>> lme4 problem remains.
>
> Therefore, you either need to "just" extract the results you want from 
> m11
> directly (doing any necessary calculations yourself), or step through 
> using a
> debugger, or send all the files to Douglas Bates ;)
>
> Cheers, David Duffy.

-- 
Eric Edeline
Assistant Professor
UMR 7618 BIOEMCO
Ecole Normale Sup?rieure
46 rue d'Ulm
75230 Paris cedex 05
France

Tel: +33 (0)1 44 32 38 84
Fax: +33 (0)1 44 32 38 85

http://www.biologie.ens.fr/bioemco/biodiversite/edeline.html



From bolker at ufl.edu  Sat Mar 27 16:04:42 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Sat, 27 Mar 2010 15:04:42 +0000 (UTC)
Subject: [R-sig-ME] Significance and lmer
References: <Pine.LNX.4.64.1003261645480.17783@ilovebacon.org>
Message-ID: <loom.20100327T160050-336@post.gmane.org>

Adam D. I. Kramer <adik at ...> writes:

> 
> Dear colleagues,
> 
> Please consider this series of commands:
> 
> a <- lmer(log(stddiff+.1539) ~ pred + m*v + option + (option|studyID),
> data=r1, subset=option>1, REML=FALSE)
> 
> b <- update(a, . ~ . - pred)
> 
> anova(a,b)
> 
> ...am I mistaken in thinking that the latter command will produce a test of
> whether "pred" is a significant predictor of log(stddiff+.1539)? I am
> concerned because of the results:
> 

  [snip]

> ...a significant result completely unrelated to the t-value. My
> interpretation of this would be that we have no good evidence that the
> estimate for 'pred' is nonzero, but including pred in the model improves
> prediction.

  It is possible for Wald tests (as provided by summary()) to 
disagree radically with likelihood ratio tests (look up "Hauck-Donner
effects", but my guess is that's not what's going
on here (it definitely can apply in binomial models, don't think
it should apply to LMMs but ?).

  I have seen some wonky stuff happen with update() [sorry, can't
provide any reproducible details], I would definitely try fitting
b by spelling out the full model rather than using update() and
see if that makes a difference.

  Other than that, nothing springs to mind.

  (Where does the log(x+0.1539) transformation come from???)



From adik at ilovebacon.org  Sat Mar 27 18:09:41 2010
From: adik at ilovebacon.org (Adam D. I. Kramer)
Date: Sat, 27 Mar 2010 10:09:41 -0700 (PDT)
Subject: [R-sig-ME] Significance and lmer
In-Reply-To: <loom.20100327T160050-336@post.gmane.org>
References: <Pine.LNX.4.64.1003261645480.17783@ilovebacon.org>
	<loom.20100327T160050-336@post.gmane.org>
Message-ID: <Pine.LNX.4.64.1003270955500.17783@ilovebacon.org>


On Sat, 27 Mar 2010, Ben Bolker wrote:

>> ...a significant result completely unrelated to the t-value. My
>> interpretation of this would be that we have no good evidence that the
>> estimate for 'pred' is nonzero, but including pred in the model improves
>> prediction.
>
>  It is possible for Wald tests (as provided by summary()) to disagree
> radically with likelihood ratio tests (look up "Hauck-Donner effects", but
> my guess is that's not what's going on here (it definitely can apply in
> binomial models, don't think it should apply to LMMs but ?).

There are no Wald tests produced by the summary()...my understanding from
reading this list is that the t-values are provided because they are t-like
(effect / se), but that it is difficult (and perhaps foolish) to estimate
degrees of freedom for t. So my concern is based on the fact that t is very
small.

>  I have seen some wonky stuff happen with update() [sorry, can't provide
> any reproducible details], I would definitely try fitting b by spelling
> out the full model rather than using update() and see if that makes a
> difference.

This produces no difference in b's estimates or the anova() statistics.
(That said, I originally was fitting [implicitly] with REML=TRUE, which did
make a difference, but not a big one).

>  Other than that, nothing springs to mind.

Well, thanks for the reply. Are you, then, of the opinion that the above
interpretation is reasonable?

>  (Where does the log(x+0.1539) transformation come from???)

x is power-law distributed with a bunch of zeroes (but not ordinal, or I'd
use family=poisson), and .1539 is the 25th percentile. This normalizes is
pretty well. Good question, though! And thanks ofr the response!

--Adam



From David.Duffy at qimr.edu.au  Sat Mar 27 23:04:03 2010
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Sun, 28 Mar 2010 08:04:03 +1000 (EST)
Subject: [R-sig-ME] Significance and lmer
In-Reply-To: <Pine.LNX.4.64.1003270955500.17783@ilovebacon.org>
References: <Pine.LNX.4.64.1003261645480.17783@ilovebacon.org><loom.20100327T160050-336@post.gmane.org>
	<Pine.LNX.4.64.1003270955500.17783@ilovebacon.org>
Message-ID: <Pine.LNX.4.64.1003280753090.29716@orpheus.qimr.edu.au>

On Sat, 27 Mar 2010, Adam D. I. Kramer wrote:
> On Sat, 27 Mar 2010, Ben Bolker wrote:
>
>>> ...a significant result completely unrelated to the t-value. My
>>> interpretation of this would be that we have no good evidence that the
>>> estimate for 'pred' is nonzero, but including pred in the model improves
>>> prediction.
>> 
>
>>  I have seen some wonky stuff happen with update() [sorry, can't provide
>> any reproducible details], I would definitely try fitting b by spelling
>> out the full model rather than using update() and see if that makes a
>> difference.
>
> This produces no difference in b's estimates or the anova() statistics.
> (That said, I originally was fitting [implicitly] with REML=TRUE, which did
> make a difference, but not a big one).

The two models both have the same number of observations, one hopes?  How 
many observations per studyID and how many studyIDs?

> Well, thanks for the reply. Are you, then, of the opinion that the above
> interpretation is reasonable?

I would be a bit nervous.  My interpretation would be that the model is 
inappropriate for the data (as the Wald and LR tests should roughly agree 
for a LMM, as Ben pointed out), and would look at diagnostic plots of 
residuals etc.  The bunch of zeroes you mention may still be stuffing 
things up ;)  Is a left-censored model plausible?

Just my 2c, David Duffy.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From adik at ilovebacon.org  Sun Mar 28 00:17:53 2010
From: adik at ilovebacon.org (Adam D. I. Kramer)
Date: Sat, 27 Mar 2010 16:17:53 -0700 (PDT)
Subject: [R-sig-ME] Significance and lmer
In-Reply-To: <Pine.LNX.4.64.1003280753090.29716@orpheus.qimr.edu.au>
References: <Pine.LNX.4.64.1003261645480.17783@ilovebacon.org><loom.20100327T160050-336@post.gmane.org>
	<Pine.LNX.4.64.1003270955500.17783@ilovebacon.org>
	<Pine.LNX.4.64.1003280753090.29716@orpheus.qimr.edu.au>
Message-ID: <Pine.LNX.4.64.1003271609530.17783@ilovebacon.org>

The problem turned out to be, indeed, differing numbers of observations.
This is likely due to me relying too much on update() to work as I
expected...it did not drop the observations previously dropped. The help
page for update makes it very clear that it just re-evaluates an altered
call, so this is my fault. Ben's comment about update() being wonky should
have given me a hint.

Preselecting cases using complete.cases() for both models brought the t
values and chi-square values much closer together--when t=.51 for the
coefficient, the chisq of a likelihood test for removing the variable from
the model was chisq=.25, leading to a reasonable p=.62.

Thanks very much to you and Ben Bolker!

--Adam

On Sun, 28 Mar 2010, David Duffy wrote:

> On Sat, 27 Mar 2010, Adam D. I. Kramer wrote:
>> On Sat, 27 Mar 2010, Ben Bolker wrote:
>> 
>>>> ...a significant result completely unrelated to the t-value. My
>>>> interpretation of this would be that we have no good evidence that the
>>>> estimate for 'pred' is nonzero, but including pred in the model improves
>>>> prediction.
>>> 
>>
>>>  I have seen some wonky stuff happen with update() [sorry, can't provide
>>> any reproducible details], I would definitely try fitting b by spelling
>>> out the full model rather than using update() and see if that makes a
>>> difference.
>> 
>> This produces no difference in b's estimates or the anova() statistics.
>> (That said, I originally was fitting [implicitly] with REML=TRUE, which did
>> make a difference, but not a big one).
>
> The two models both have the same number of observations, one hopes?  How 
> many observations per studyID and how many studyIDs?
>
>> Well, thanks for the reply. Are you, then, of the opinion that the above
>> interpretation is reasonable?
>
> I would be a bit nervous.  My interpretation would be that the model is 
> inappropriate for the data (as the Wald and LR tests should roughly agree for 
> a LMM, as Ben pointed out), and would look at diagnostic plots of residuals 
> etc.  The bunch of zeroes you mention may still be stuffing things up ;)  Is 
> a left-censored model plausible?
>
> Just my 2c, David Duffy.
>
> -- 
> | David Duffy (MBBS PhD)                                         ,-_|\
> | email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
> | Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
> | 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v
>



From wuyong88 at gmail.com  Sun Mar 28 06:25:21 2010
From: wuyong88 at gmail.com (Yong Wu)
Date: Sat, 27 Mar 2010 23:25:21 -0500
Subject: [R-sig-ME] Very weird lmer results, compared to SAS proc mix
Message-ID: <cfa5b89e1003272125r1677f3ddl8004de6f726683cd@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100327/380abdf7/attachment.pl>

From h.wickham at gmail.com  Sun Mar 28 06:55:54 2010
From: h.wickham at gmail.com (hadley wickham)
Date: Sat, 27 Mar 2010 23:55:54 -0500
Subject: [R-sig-ME] Very weird lmer results, compared to SAS proc mix
In-Reply-To: <cfa5b89e1003272125r1677f3ddl8004de6f726683cd@mail.gmail.com>
References: <cfa5b89e1003272125r1677f3ddl8004de6f726683cd@mail.gmail.com>
Message-ID: <f8e6ff051003272155l4501611dnebf8d57c8cfe9f5e@mail.gmail.com>

On Sat, Mar 27, 2010 at 11:25 PM, Yong Wu <wuyong88 at gmail.com> wrote:
> Sorry to bother you. I am struggling in this issue for long time. Wish
> somebody can help me.
>
> I first used lmer to do the following analysis.
> fullmodel=lmer(BMI~1+exposure+(age|ID),data, REML=FALSE)
> ? ? ? ? ?reducemodel=lmer(BMI~1+(age|ID),data, REML=FALSE)
> ? ? ? ? ?anova(full,red)
> The "fullmodel" has AIC of 6874 and "reducemodel" has AIC of 7106, which
> cause "anova" analysis giving the p-value< 2.2e-16 . This result is
> definitely wrong

How do you know?  It would be helpful if you provided the evidence you
used to judge SAS correct and R incorrect.

Hadley


-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/



From mspinola10 at gmail.com  Sun Mar 28 15:28:55 2010
From: mspinola10 at gmail.com (=?ISO-8859-1?Q?Manuel_Sp=EDnola?=)
Date: Sun, 28 Mar 2010 07:28:55 -0600
Subject: [R-sig-ME] Correlation of -1.00 in a mixed model
Message-ID: <4BAF5997.70602@gmail.com>

Dear list members,

A few days ago somebody posted a problem like the want that I have now, 
I got a correlation value of - 1.00.  I would like to have some help in 
the context of my model fitting.
My model is a random intercept random slope model (repeated measure 
design).  Variable "time" has been centered.
What will be an alternative model?

 > modelo7 = lmer(ipa ~ time + (time | localidad), data=ipa)
 > summary(modelo7)
Linear mixed model fit by REML
Formula: ipa ~ time + (time | localidad)
   Data: ipa
  AIC  BIC logLik deviance REMLdev
 1917 1937 -952.4     1913    1905
Random effects:
 Groups      Name           Variance     Std.Dev.    Corr  
 localidad  (Intercept)        2232.31    47.247
                   time                545.97     23.366   -1.000
 Residual                           450.92     21.235
Number of obs: 196, groups: localidad, 49

Fixed effects:
            Estimate Std. Error t value
(Intercept)   42.852      6.918   6.194
time         -19.746      3.603  -5.480

Correlation of Fixed Effects:
     (Intr)
time -0.904

Thank you very much in advance.
Best,

Manuel

-- 
Manuel Sp?nola, Ph.D.
Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
Universidad Nacional
Apartado 1350-3000
Heredia
COSTA RICA
mspinola at una.ac.cr
mspinola10 at gmail.com
Tel?fono: (506) 2277-3598
Fax: (506) 2237-7036



From bates at stat.wisc.edu  Sun Mar 28 15:39:38 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 28 Mar 2010 08:39:38 -0500
Subject: [R-sig-ME] Very weird lmer results, compared to SAS proc mix
In-Reply-To: <cfa5b89e1003272125r1677f3ddl8004de6f726683cd@mail.gmail.com>
References: <cfa5b89e1003272125r1677f3ddl8004de6f726683cd@mail.gmail.com>
Message-ID: <40e66e0b1003280639n64e83aapd7197467bad161b8@mail.gmail.com>

On Sat, Mar 27, 2010 at 11:25 PM, Yong Wu <wuyong88 at gmail.com> wrote:
> Sorry to bother you. I am struggling in this issue for long time. Wish
> somebody can help me.
>
> I first used lmer to do the following analysis.
> fullmodel=lmer(BMI~1+exposure+(age|ID),data, REML=FALSE)
> ? ? ? ? ?reducemodel=lmer(BMI~1+(age|ID),data, REML=FALSE)
> ? ? ? ? ?anova(full,red)

Both models are an unusual specification.  You have a random effect
with respect to age but no fixed effect for age.  This means that the
mean slope with respect to age across all ID's is constrained to be
zero, which for BMI is unlikely.  I think your model should be

BMI ~ 1 + exposure + age + (1 + age|ID)

I might even start with

BMI ~ 1 + exposure*age + (1 + age|ID)

unless exposure is at age zero.
> The "fullmodel" has AIC of 6874 and "reducemodel" has AIC of 7106, which
> cause "anova" analysis giving the p-value< 2.2e-16 . This result is
> definitely wrong
>
> I then did the similar study by SAS.
> The fullmodel is:
> proc mixed;
> class exposure;
> model BMI=exposure;
> random age /sub=id;
> run;
> The AIC is 7099.7, and type 3 test of fixed effect, exposure, got
> p-value=0.74.
>
> The reducemodel is:
> proc mixed;
> ?class exposure;
> ?model BMI=;
> ?random age /sub=id;
> ?run;
> ?The AIC is 7101.2.
>
> The SAS result is correct.
>
> Could somebody help me to explain why lmer is wrong?
>
> I do not even dare to use lmer now, since I can not trust its result. Thanks
> in advance for any of your answer.
>
> Best,
> Yong
> ,
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bolker at ufl.edu  Sun Mar 28 16:25:33 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Sun, 28 Mar 2010 10:25:33 -0400
Subject: [R-sig-ME] Very weird lmer results, compared to SAS proc mix
In-Reply-To: <cfa5b89e1003272125r1677f3ddl8004de6f726683cd@mail.gmail.com>
References: <cfa5b89e1003272125r1677f3ddl8004de6f726683cd@mail.gmail.com>
Message-ID: <4BAF66DD.2@ufl.edu>


  Can you post the summaries of these models, so we can see if there
might be something else odd going on?  (Making the data, or an otherwise
reproducible example, available would be even better ...)
   It might also be useful to post the parameter estimates from PROC
MIXED.  Maybe (it's a long shot) PROC MIXED automatically includes the
fixed effect of age (which would be highly correlated with exposure,
which might explain the non-significance of exposure)?

Yong Wu wrote:
> Sorry to bother you. I am struggling in this issue for long time. Wish
> somebody can help me.
> 
> I first used lmer to do the following analysis.
> fullmodel=lmer(BMI~1+exposure+(age|ID),data, REML=FALSE)
>           reducemodel=lmer(BMI~1+(age|ID),data, REML=FALSE)
>           anova(full,red)
> The "fullmodel" has AIC of 6874 and "reducemodel" has AIC of 7106, which
> cause "anova" analysis giving the p-value< 2.2e-16 . This result is
> definitely wrong
> 
> I then did the similar study by SAS.
> The fullmodel is:
> proc mixed;
> class exposure;
> model BMI=exposure;
> random age /sub=id;
> run;
> The AIC is 7099.7, and type 3 test of fixed effect, exposure, got
> p-value=0.74.
> 
> The reducemodel is:
> proc mixed;
>  class exposure;
>  model BMI=;
>  random age /sub=id;
>  run;
>  The AIC is 7101.2.
> 
> The SAS result is correct.
> 
> Could somebody help me to explain why lmer is wrong?
> 
> I do not even dare to use lmer now, since I can not trust its result. Thanks
> in advance for any of your answer.
> 
> Best,
> Yong
> ,
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From bolker at ufl.edu  Sun Mar 28 18:09:06 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Sun, 28 Mar 2010 16:09:06 +0000 (UTC)
Subject: [R-sig-ME] Mixed/Hierarchical/Multilevel Modeling packages in R
References: <2ad0cc111003161956u1b4523bfgb0dfdf73b843a6ac@mail.gmail.com>
Message-ID: <loom.20100328T180722-371@post.gmane.org>

Kingsford Jones <kingsfordjones at ...> writes:

> 
> Today's post about the ordinal package inspired a search of the CRAN
> packages page for the words 'mixed', 'multilevel', and 'hierarchical',
> turning up an impressive list of packages (pasted below). 

  [snip]

> 
> best,
> Kingsford Jones

  I took this information, reformatted and rearranged it slightly,
and added it to http://glmm.wikidot.com/faq (scroll down to the bottom).



From lamprianou at yahoo.com  Sun Mar 28 22:21:21 2010
From: lamprianou at yahoo.com (Iasonas Lamprianou)
Date: Sun, 28 Mar 2010 13:21:21 -0700 (PDT)
Subject: [R-sig-ME] fixed vs random
In-Reply-To: <mailman.3.1269770402.29390.r-sig-mixed-models@r-project.org>
Message-ID: <109722.72582.qm@web58905.mail.re1.yahoo.com>


Dear colleagues,
I am not sure what the difference between those models is:

m0<- lmer(score ~ 1+gender+(1|candidate), mg2006_sub)
m1<- lmer(score ~ 1+(1+gender|candidate), mg2006_sub)
m2 <- lmer(score ~ 1+gender+(1+gender|candidate), mg2006_sub)

the first model is modelling the candidate as a random effect in an examination, where two markers mark each response of a candidate (a repeated measure). I assume that the gender of the candidate is a good predictor of performance on the test, so I can use any of the three models. But I do not understand what the difference is. Why would I get different results between m0 and m1? In effect, I am just adding the gender as a fixed effect.And is m2 a valid model?

thank you

jason



Dr. Iasonas Lamprianou


Assistant Professor (Educational Research and Evaluation)
Department of Education Sciences
European University-Cyprus
P.O. Box 22006
1516 Nicosia
Cyprus 
Tel.: +357-22-713178
Fax: +357-22-590539


Honorary Research Fellow
Department of Education
The University of Manchester
Oxford Road, Manchester M13 9PL, UK
Tel. 0044  161 275 3485
iasonas.lamprianou at manchester.ac.uk


--- On Sun, 28/3/10, r-sig-mixed-models-request at r-project.org <r-sig-mixed-models-request at r-project.org> wrote:

> From: r-sig-mixed-models-request at r-project.org <r-sig-mixed-models-request at r-project.org>
> Subject: R-sig-mixed-models Digest, Vol 39, Issue 42
> To: r-sig-mixed-models at r-project.org
> Date: Sunday, 28 March, 2010, 11:00
> Send R-sig-mixed-models mailing list
> submissions to
> ??? r-sig-mixed-models at r-project.org
> 
> To subscribe or unsubscribe via the World Wide Web, visit
> ??? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help'
> to
> ??? r-sig-mixed-models-request at r-project.org
> 
> You can reach the person managing the list at
> ??? r-sig-mixed-models-owner at r-project.org
> 
> When replying, please edit your Subject line so it is more
> specific
> than "Re: Contents of R-sig-mixed-models digest..."
> 
> 
> Today's Topics:
> 
> ???1. Re: Could not get a lmer or glmer
> summary (Eric Edeline)
> ???2. Re: Significance and lmer (Ben
> Bolker)
> ???3. Re: Significance and lmer (Adam D. I.
> Kramer)
> ???4. Re: Significance and lmer (David
> Duffy)
> ???5. Re: Significance and lmer (Adam D. I.
> Kramer)
> ???6. Very weird lmer results, compared to
> SAS proc mix (Yong Wu)
> ???7. Re: Very weird lmer results, compared
> to SAS proc mix
> ? ? ? (hadley wickham)
> 
> 
> ----------------------------------------------------------------------
> 
> Message: 1
> Date: Sat, 27 Mar 2010 14:59:48 +0100
> From: Eric Edeline <edeline at biologie.ens.fr>
> To: David Duffy <David.Duffy at qimr.edu.au>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Could not get a lmer or glmer
> summary
> Message-ID: <4BAE0F54.3000809 at biologie.ens.fr>
> Content-Type: text/plain; charset=ISO-8859-1;
> format=flowed
> 
> I have solved my problem, which was apparently due to a
> conflict between 
> lme4 and another library (one of these: tree, VGAM, sn,
> Matrix, 
> mclust...) about an "rcon" object if I remember well.?
> Removing all the 
> libraries including lme4 from /usr/local/lib/R/site-library
> and 
> re-installing lme4 in /usr/lib/R/site-library made the
> trick. Sorry for 
> not providing more detailed information, I just do not
> remember more!
> 
> Cheers,
> 
> eric
> 
> 
> 
> David Duffy wrote:
> > On Fri, 26 Mar 2010, Eric Edeline wrote:
> >
> >> Dear Ben,
> >>
> >> thank you for your feed-back. I have now tested
> lmer on several 
> >> datasets and I always get the same error message
> when asking for 
> >> model summary. So the problem is with lme4, not
> with the data. Then, 
> >> I ran the exact same models and data on another
> machine and it works 
> >> fine! So the lme4 problem is specific to my
> machine. Then, I tried 
> >> brute force: uninstalling and re-installing R on
> my machine, but the 
> >> lme4 problem remains.
> >
> > Therefore, you either need to "just" extract the
> results you want from 
> > m11
> > directly (doing any necessary calculations yourself),
> or step through 
> > using a
> > debugger, or send all the files to Douglas Bates ;)
> >
> > Cheers, David Duffy.
> 
> -- 
> Eric Edeline
> Assistant Professor
> UMR 7618 BIOEMCO
> Ecole Normale Sup?rieure
> 46 rue d'Ulm
> 75230 Paris cedex 05
> France
> 
> Tel: +33 (0)1 44 32 38 84
> Fax: +33 (0)1 44 32 38 85
> 
> http://www.biologie.ens.fr/bioemco/biodiversite/edeline.html
> 
> 
> 
> ------------------------------
> 
> Message: 2
> Date: Sat, 27 Mar 2010 15:04:42 +0000 (UTC)
> From: Ben Bolker <bolker at ufl.edu>
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Significance and lmer
> Message-ID: <loom.20100327T160050-336 at post.gmane.org>
> Content-Type: text/plain; charset=us-ascii
> 
> Adam D. I. Kramer <adik at ...> writes:
> 
> > 
> > Dear colleagues,
> > 
> > Please consider this series of commands:
> > 
> > a <- lmer(log(stddiff+.1539) ~ pred + m*v + option
> + (option|studyID),
> > data=r1, subset=option>1, REML=FALSE)
> > 
> > b <- update(a, . ~ . - pred)
> > 
> > anova(a,b)
> > 
> > ...am I mistaken in thinking that the latter command
> will produce a test of
> > whether "pred" is a significant predictor of
> log(stddiff+.1539)? I am
> > concerned because of the results:
> > 
> 
> ? [snip]
> 
> > ...a significant result completely unrelated to the
> t-value. My
> > interpretation of this would be that we have no good
> evidence that the
> > estimate for 'pred' is nonzero, but including pred in
> the model improves
> > prediction.
> 
> ? It is possible for Wald tests (as provided by
> summary()) to 
> disagree radically with likelihood ratio tests (look up
> "Hauck-Donner
> effects", but my guess is that's not what's going
> on here (it definitely can apply in binomial models, don't
> think
> it should apply to LMMs but ?).
> 
> ? I have seen some wonky stuff happen with update()
> [sorry, can't
> provide any reproducible details], I would definitely try
> fitting
> b by spelling out the full model rather than using update()
> and
> see if that makes a difference.
> 
> ? Other than that, nothing springs to mind.
> 
> ? (Where does the log(x+0.1539) transformation come
> from???)
> 
> 
> 
> ------------------------------
> 
> Message: 3
> Date: Sat, 27 Mar 2010 10:09:41 -0700 (PDT)
> From: "Adam D. I. Kramer" <adik at ilovebacon.org>
> To: Ben Bolker <bolker at ufl.edu>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Significance and lmer
> Message-ID: <Pine.LNX.4.64.1003270955500.17783 at ilovebacon.org>
> Content-Type: TEXT/PLAIN; charset=US-ASCII; format=flowed
> 
> 
> On Sat, 27 Mar 2010, Ben Bolker wrote:
> 
> >> ...a significant result completely unrelated to
> the t-value. My
> >> interpretation of this would be that we have no
> good evidence that the
> >> estimate for 'pred' is nonzero, but including pred
> in the model improves
> >> prediction.
> >
> >? It is possible for Wald tests (as provided by
> summary()) to disagree
> > radically with likelihood ratio tests (look up
> "Hauck-Donner effects", but
> > my guess is that's not what's going on here (it
> definitely can apply in
> > binomial models, don't think it should apply to LMMs
> but ?).
> 
> There are no Wald tests produced by the summary()...my
> understanding from
> reading this list is that the t-values are provided because
> they are t-like
> (effect / se), but that it is difficult (and perhaps
> foolish) to estimate
> degrees of freedom for t. So my concern is based on the
> fact that t is very
> small.
> 
> >? I have seen some wonky stuff happen with
> update() [sorry, can't provide
> > any reproducible details], I would definitely try
> fitting b by spelling
> > out the full model rather than using update() and see
> if that makes a
> > difference.
> 
> This produces no difference in b's estimates or the anova()
> statistics.
> (That said, I originally was fitting [implicitly] with
> REML=TRUE, which did
> make a difference, but not a big one).
> 
> >? Other than that, nothing springs to mind.
> 
> Well, thanks for the reply. Are you, then, of the opinion
> that the above
> interpretation is reasonable?
> 
> >? (Where does the log(x+0.1539) transformation
> come from???)
> 
> x is power-law distributed with a bunch of zeroes (but not
> ordinal, or I'd
> use family=poisson), and .1539 is the 25th percentile. This
> normalizes is
> pretty well. Good question, though! And thanks ofr the
> response!
> 
> --Adam
> 
> 
> 
> ------------------------------
> 
> Message: 4
> Date: Sun, 28 Mar 2010 08:04:03 +1000 (EST)
> From: David Duffy <David.Duffy at qimr.edu.au>
> To: "Adam D. I. Kramer" <adik at ilovebacon.org>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Significance and lmer
> Message-ID: <Pine.LNX.4.64.1003280753090.29716 at orpheus.qimr.edu.au>
> Content-Type: TEXT/PLAIN; charset=US-ASCII; format=flowed
> 
> On Sat, 27 Mar 2010, Adam D. I. Kramer wrote:
> > On Sat, 27 Mar 2010, Ben Bolker wrote:
> >
> >>> ...a significant result completely unrelated
> to the t-value. My
> >>> interpretation of this would be that we have
> no good evidence that the
> >>> estimate for 'pred' is nonzero, but including
> pred in the model improves
> >>> prediction.
> >> 
> >
> >>? I have seen some wonky stuff happen with
> update() [sorry, can't provide
> >> any reproducible details], I would definitely try
> fitting b by spelling
> >> out the full model rather than using update() and
> see if that makes a
> >> difference.
> >
> > This produces no difference in b's estimates or the
> anova() statistics.
> > (That said, I originally was fitting [implicitly] with
> REML=TRUE, which did
> > make a difference, but not a big one).
> 
> The two models both have the same number of observations,
> one hopes?? How 
> many observations per studyID and how many studyIDs?
> 
> > Well, thanks for the reply. Are you, then, of the
> opinion that the above
> > interpretation is reasonable?
> 
> I would be a bit nervous.? My interpretation would be
> that the model is 
> inappropriate for the data (as the Wald and LR tests should
> roughly agree 
> for a LMM, as Ben pointed out), and would look at
> diagnostic plots of 
> residuals etc.? The bunch of zeroes you mention may
> still be stuffing 
> things up ;)? Is a left-censored model plausible?
> 
> Just my 2c, David Duffy.
> 
> -- 
> | David Duffy (MBBS PhD)? ? ? ? ?
> ? ? ? ? ? ? ? ?
> ? ? ? ? ? ?
> ???,-_|\
> | email: davidD at qimr.edu.au?
> ph: INT+61+7+3362-0217 fax: -0101? /?
> ???*
> | Epidemiology Unit, Queensland Institute of Medical
> Research???\_,-._/
> | 300 Herston Rd, Brisbane, Queensland 4029,
> Australia? GPG 4D0B994A v
> 
> 
> 
> ------------------------------
> 
> Message: 5
> Date: Sat, 27 Mar 2010 16:17:53 -0700 (PDT)
> From: "Adam D. I. Kramer" <adik at ilovebacon.org>
> To: David Duffy <David.Duffy at qimr.edu.au>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Significance and lmer
> Message-ID: <Pine.LNX.4.64.1003271609530.17783 at ilovebacon.org>
> Content-Type: TEXT/PLAIN; charset=US-ASCII; format=flowed
> 
> The problem turned out to be, indeed, differing numbers of
> observations.
> This is likely due to me relying too much on update() to
> work as I
> expected...it did not drop the observations previously
> dropped. The help
> page for update makes it very clear that it just
> re-evaluates an altered
> call, so this is my fault. Ben's comment about update()
> being wonky should
> have given me a hint.
> 
> Preselecting cases using complete.cases() for both models
> brought the t
> values and chi-square values much closer together--when
> t=.51 for the
> coefficient, the chisq of a likelihood test for removing
> the variable from
> the model was chisq=.25, leading to a reasonable p=.62.
> 
> Thanks very much to you and Ben Bolker!
> 
> --Adam
> 
> On Sun, 28 Mar 2010, David Duffy wrote:
> 
> > On Sat, 27 Mar 2010, Adam D. I. Kramer wrote:
> >> On Sat, 27 Mar 2010, Ben Bolker wrote:
> >> 
> >>>> ...a significant result completely
> unrelated to the t-value. My
> >>>> interpretation of this would be that we
> have no good evidence that the
> >>>> estimate for 'pred' is nonzero, but
> including pred in the model improves
> >>>> prediction.
> >>> 
> >>
> >>>? I have seen some wonky stuff happen with
> update() [sorry, can't provide
> >>> any reproducible details], I would definitely
> try fitting b by spelling
> >>> out the full model rather than using update()
> and see if that makes a
> >>> difference.
> >> 
> >> This produces no difference in b's estimates or
> the anova() statistics.
> >> (That said, I originally was fitting [implicitly]
> with REML=TRUE, which did
> >> make a difference, but not a big one).
> >
> > The two models both have the same number of
> observations, one hopes?? How 
> > many observations per studyID and how many studyIDs?
> >
> >> Well, thanks for the reply. Are you, then, of the
> opinion that the above
> >> interpretation is reasonable?
> >
> > I would be a bit nervous.? My interpretation
> would be that the model is 
> > inappropriate for the data (as the Wald and LR tests
> should roughly agree for 
> > a LMM, as Ben pointed out), and would look at
> diagnostic plots of residuals 
> > etc.? The bunch of zeroes you mention may still
> be stuffing things up ;)? Is 
> > a left-censored model plausible?
> >
> > Just my 2c, David Duffy.
> >
> > -- 
> > | David Duffy (MBBS PhD)? ? ? ?
> ? ? ? ? ? ? ? ?
> ? ? ? ? ? ? ?
> ???,-_|\
> > | email: davidD at qimr.edu.au?
> ph: INT+61+7+3362-0217 fax: -0101? /?
> ???*
> > | Epidemiology Unit, Queensland Institute of Medical
> Research???\_,-._/
> > | 300 Herston Rd, Brisbane, Queensland 4029,
> Australia? GPG 4D0B994A v
> >
> 
> 
> 
> ------------------------------
> 
> Message: 6
> Date: Sat, 27 Mar 2010 23:25:21 -0500
> From: Yong Wu <wuyong88 at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Very weird lmer results, compared to
> SAS proc mix
> Message-ID:
> ??? <cfa5b89e1003272125r1677f3ddl8004de6f726683cd at mail.gmail.com>
> Content-Type: text/plain
> 
> Sorry to bother you. I am struggling in this issue for long
> time. Wish
> somebody can help me.
> 
> I first used lmer to do the following analysis.
> fullmodel=lmer(BMI~1+exposure+(age|ID),data, REML=FALSE)
> ? ? ? ? ?
> reducemodel=lmer(BMI~1+(age|ID),data, REML=FALSE)
> ? ? ? ? ? anova(full,red)
> The "fullmodel" has AIC of 6874 and "reducemodel" has AIC
> of 7106, which
> cause "anova" analysis giving the p-value< 2.2e-16 .
> This result is
> definitely wrong
> 
> I then did the similar study by SAS.
> The fullmodel is:
> proc mixed;
> class exposure;
> model BMI=exposure;
> random age /sub=id;
> run;
> The AIC is 7099.7, and type 3 test of fixed effect,
> exposure, got
> p-value=0.74.
> 
> The reducemodel is:
> proc mixed;
>  class exposure;
>  model BMI=;
>  random age /sub=id;
>  run;
>  The AIC is 7101.2.
> 
> The SAS result is correct.
> 
> Could somebody help me to explain why lmer is wrong?
> 
> I do not even dare to use lmer now, since I can not trust
> its result. Thanks
> in advance for any of your answer.
> 
> Best,
> Yong
> ,
> 
> ??? [[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------
> 
> Message: 7
> Date: Sat, 27 Mar 2010 23:55:54 -0500
> From: hadley wickham <h.wickham at gmail.com>
> To: Yong Wu <wuyong88 at gmail.com>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Very weird lmer results, compared
> to SAS proc
> ??? mix
> Message-ID:
> ??? <f8e6ff051003272155l4501611dnebf8d57c8cfe9f5e at mail.gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1
> 
> On Sat, Mar 27, 2010 at 11:25 PM, Yong Wu <wuyong88 at gmail.com>
> wrote:
> > Sorry to bother you. I am struggling in this issue for
> long time. Wish
> > somebody can help me.
> >
> > I first used lmer to do the following analysis.
> > fullmodel=lmer(BMI~1+exposure+(age|ID),data,
> REML=FALSE)
> > ? ? ? ? ?reducemodel=lmer(BMI~1+(age|ID),data,
> REML=FALSE)
> > ? ? ? ? ?anova(full,red)
> > The "fullmodel" has AIC of 6874 and "reducemodel" has
> AIC of 7106, which
> > cause "anova" analysis giving the p-value< 2.2e-16
> . This result is
> > definitely wrong
> 
> How do you know?? It would be helpful if you provided
> the evidence you
> used to judge SAS correct and R incorrect.
> 
> Hadley
> 
> 
> -- 
> Assistant Professor / Dobelman Family Junior Chair
> Department of Statistics / Rice University
> http://had.co.nz/
> 
> 
> 
> ------------------------------
> 
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> End of R-sig-mixed-models Digest, Vol 39, Issue 42
> **************************************************
> 






From danielezrajohnson at gmail.com  Sun Mar 28 23:12:21 2010
From: danielezrajohnson at gmail.com (Daniel Ezra Johnson)
Date: Sun, 28 Mar 2010 17:12:21 -0400
Subject: [R-sig-ME] fixed vs random
In-Reply-To: <109722.72582.qm@web58905.mail.re1.yahoo.com>
References: <mailman.3.1269770402.29390.r-sig-mixed-models@r-project.org>
	<109722.72582.qm@web58905.mail.re1.yahoo.com>
Message-ID: <a46630751003281412i35893cd3u153264b3b9f29a8e@mail.gmail.com>

Terms such as (gender|candidate) estimate a gender effect that can
vary across candidates. It is presumably meaningless to discuss the
gender effect of any individual candidate, so this term should not be
used.

The form of m2 is preferred to m1 in most cases when you have a
legitimate random slope variable, for example if you had a factor
"difficulty" referring to the difficulty of the questions, it would be
meaningful to estimate the effect of question difficulty separately
for each candidate, so a model like

m3 <- lmer(score ~ 1 + gender + difficulty + (difficulty|candidate), mg2006_sub)

might be sensible, but not one with gender as a random slope over candidate.

Dan

On Sun, Mar 28, 2010 at 4:21 PM, Iasonas Lamprianou
<lamprianou at yahoo.com> wrote:
>
> Dear colleagues,
> I am not sure what the difference between those models is:
>
> m0<- lmer(score ~ 1+gender+(1|candidate), mg2006_sub)
> m1<- lmer(score ~ 1+(1+gender|candidate), mg2006_sub)
> m2 <- lmer(score ~ 1+gender+(1+gender|candidate), mg2006_sub)
>
> the first model is modelling the candidate as a random effect in an examination, where two markers mark each response of a candidate (a repeated measure). I assume that the gender of the candidate is a good predictor of performance on the test, so I can use any of the three models. But I do not understand what the difference is. Why would I get different results between m0 and m1? In effect, I am just adding the gender as a fixed effect.And is m2 a valid model?
>
> thank you
>
> jason
>
>
>
> Dr. Iasonas Lamprianou
>
>
> Assistant Professor (Educational Research and Evaluation)
> Department of Education Sciences
> European University-Cyprus
> P.O. Box 22006
> 1516 Nicosia
> Cyprus
> Tel.: +357-22-713178
> Fax: +357-22-590539
>
>
> Honorary Research Fellow
> Department of Education
> The University of Manchester
> Oxford Road, Manchester M13 9PL, UK
> Tel. 0044 ?161 275 3485
> iasonas.lamprianou at manchester.ac.uk
>
>
> --- On Sun, 28/3/10, r-sig-mixed-models-request at r-project.org <r-sig-mixed-models-request at r-project.org> wrote:
>
>> From: r-sig-mixed-models-request at r-project.org <r-sig-mixed-models-request at r-project.org>
>> Subject: R-sig-mixed-models Digest, Vol 39, Issue 42
>> To: r-sig-mixed-models at r-project.org
>> Date: Sunday, 28 March, 2010, 11:00
>> Send R-sig-mixed-models mailing list
>> submissions to
>> ??? r-sig-mixed-models at r-project.org
>>
>> To subscribe or unsubscribe via the World Wide Web, visit
>> ??? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> or, via email, send a message with subject or body 'help'
>> to
>> ??? r-sig-mixed-models-request at r-project.org
>>
>> You can reach the person managing the list at
>> ??? r-sig-mixed-models-owner at r-project.org
>>
>> When replying, please edit your Subject line so it is more
>> specific
>> than "Re: Contents of R-sig-mixed-models digest..."
>>
>>
>> Today's Topics:
>>
>> ???1. Re: Could not get a lmer or glmer
>> summary (Eric Edeline)
>> ???2. Re: Significance and lmer (Ben
>> Bolker)
>> ???3. Re: Significance and lmer (Adam D. I.
>> Kramer)
>> ???4. Re: Significance and lmer (David
>> Duffy)
>> ???5. Re: Significance and lmer (Adam D. I.
>> Kramer)
>> ???6. Very weird lmer results, compared to
>> SAS proc mix (Yong Wu)
>> ???7. Re: Very weird lmer results, compared
>> to SAS proc mix
>> ? ? ? (hadley wickham)
>>
>>
>> ----------------------------------------------------------------------
>>
>> Message: 1
>> Date: Sat, 27 Mar 2010 14:59:48 +0100
>> From: Eric Edeline <edeline at biologie.ens.fr>
>> To: David Duffy <David.Duffy at qimr.edu.au>
>> Cc: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] Could not get a lmer or glmer
>> summary
>> Message-ID: <4BAE0F54.3000809 at biologie.ens.fr>
>> Content-Type: text/plain; charset=ISO-8859-1;
>> format=flowed
>>
>> I have solved my problem, which was apparently due to a
>> conflict between
>> lme4 and another library (one of these: tree, VGAM, sn,
>> Matrix,
>> mclust...) about an "rcon" object if I remember well.
>> Removing all the
>> libraries including lme4 from /usr/local/lib/R/site-library
>> and
>> re-installing lme4 in /usr/lib/R/site-library made the
>> trick. Sorry for
>> not providing more detailed information, I just do not
>> remember more!
>>
>> Cheers,
>>
>> eric
>>
>>
>>
>> David Duffy wrote:
>> > On Fri, 26 Mar 2010, Eric Edeline wrote:
>> >
>> >> Dear Ben,
>> >>
>> >> thank you for your feed-back. I have now tested
>> lmer on several
>> >> datasets and I always get the same error message
>> when asking for
>> >> model summary. So the problem is with lme4, not
>> with the data. Then,
>> >> I ran the exact same models and data on another
>> machine and it works
>> >> fine! So the lme4 problem is specific to my
>> machine. Then, I tried
>> >> brute force: uninstalling and re-installing R on
>> my machine, but the
>> >> lme4 problem remains.
>> >
>> > Therefore, you either need to "just" extract the
>> results you want from
>> > m11
>> > directly (doing any necessary calculations yourself),
>> or step through
>> > using a
>> > debugger, or send all the files to Douglas Bates ;)
>> >
>> > Cheers, David Duffy.
>>
>> --
>> Eric Edeline
>> Assistant Professor
>> UMR 7618 BIOEMCO
>> Ecole Normale Sup?rieure
>> 46 rue d'Ulm
>> 75230 Paris cedex 05
>> France
>>
>> Tel: +33 (0)1 44 32 38 84
>> Fax: +33 (0)1 44 32 38 85
>>
>> http://www.biologie.ens.fr/bioemco/biodiversite/edeline.html
>>
>>
>>
>> ------------------------------
>>
>> Message: 2
>> Date: Sat, 27 Mar 2010 15:04:42 +0000 (UTC)
>> From: Ben Bolker <bolker at ufl.edu>
>> To: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] Significance and lmer
>> Message-ID: <loom.20100327T160050-336 at post.gmane.org>
>> Content-Type: text/plain; charset=us-ascii
>>
>> Adam D. I. Kramer <adik at ...> writes:
>>
>> >
>> > Dear colleagues,
>> >
>> > Please consider this series of commands:
>> >
>> > a <- lmer(log(stddiff+.1539) ~ pred + m*v + option
>> + (option|studyID),
>> > data=r1, subset=option>1, REML=FALSE)
>> >
>> > b <- update(a, . ~ . - pred)
>> >
>> > anova(a,b)
>> >
>> > ...am I mistaken in thinking that the latter command
>> will produce a test of
>> > whether "pred" is a significant predictor of
>> log(stddiff+.1539)? I am
>> > concerned because of the results:
>> >
>>
>> ? [snip]
>>
>> > ...a significant result completely unrelated to the
>> t-value. My
>> > interpretation of this would be that we have no good
>> evidence that the
>> > estimate for 'pred' is nonzero, but including pred in
>> the model improves
>> > prediction.
>>
>> ? It is possible for Wald tests (as provided by
>> summary()) to
>> disagree radically with likelihood ratio tests (look up
>> "Hauck-Donner
>> effects", but my guess is that's not what's going
>> on here (it definitely can apply in binomial models, don't
>> think
>> it should apply to LMMs but ?).
>>
>> ? I have seen some wonky stuff happen with update()
>> [sorry, can't
>> provide any reproducible details], I would definitely try
>> fitting
>> b by spelling out the full model rather than using update()
>> and
>> see if that makes a difference.
>>
>> ? Other than that, nothing springs to mind.
>>
>> ? (Where does the log(x+0.1539) transformation come
>> from???)
>>
>>
>>
>> ------------------------------
>>
>> Message: 3
>> Date: Sat, 27 Mar 2010 10:09:41 -0700 (PDT)
>> From: "Adam D. I. Kramer" <adik at ilovebacon.org>
>> To: Ben Bolker <bolker at ufl.edu>
>> Cc: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] Significance and lmer
>> Message-ID: <Pine.LNX.4.64.1003270955500.17783 at ilovebacon.org>
>> Content-Type: TEXT/PLAIN; charset=US-ASCII; format=flowed
>>
>>
>> On Sat, 27 Mar 2010, Ben Bolker wrote:
>>
>> >> ...a significant result completely unrelated to
>> the t-value. My
>> >> interpretation of this would be that we have no
>> good evidence that the
>> >> estimate for 'pred' is nonzero, but including pred
>> in the model improves
>> >> prediction.
>> >
>> >? It is possible for Wald tests (as provided by
>> summary()) to disagree
>> > radically with likelihood ratio tests (look up
>> "Hauck-Donner effects", but
>> > my guess is that's not what's going on here (it
>> definitely can apply in
>> > binomial models, don't think it should apply to LMMs
>> but ?).
>>
>> There are no Wald tests produced by the summary()...my
>> understanding from
>> reading this list is that the t-values are provided because
>> they are t-like
>> (effect / se), but that it is difficult (and perhaps
>> foolish) to estimate
>> degrees of freedom for t. So my concern is based on the
>> fact that t is very
>> small.
>>
>> >? I have seen some wonky stuff happen with
>> update() [sorry, can't provide
>> > any reproducible details], I would definitely try
>> fitting b by spelling
>> > out the full model rather than using update() and see
>> if that makes a
>> > difference.
>>
>> This produces no difference in b's estimates or the anova()
>> statistics.
>> (That said, I originally was fitting [implicitly] with
>> REML=TRUE, which did
>> make a difference, but not a big one).
>>
>> >? Other than that, nothing springs to mind.
>>
>> Well, thanks for the reply. Are you, then, of the opinion
>> that the above
>> interpretation is reasonable?
>>
>> >? (Where does the log(x+0.1539) transformation
>> come from???)
>>
>> x is power-law distributed with a bunch of zeroes (but not
>> ordinal, or I'd
>> use family=poisson), and .1539 is the 25th percentile. This
>> normalizes is
>> pretty well. Good question, though! And thanks ofr the
>> response!
>>
>> --Adam
>>
>>
>>
>> ------------------------------
>>
>> Message: 4
>> Date: Sun, 28 Mar 2010 08:04:03 +1000 (EST)
>> From: David Duffy <David.Duffy at qimr.edu.au>
>> To: "Adam D. I. Kramer" <adik at ilovebacon.org>
>> Cc: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] Significance and lmer
>> Message-ID: <Pine.LNX.4.64.1003280753090.29716 at orpheus.qimr.edu.au>
>> Content-Type: TEXT/PLAIN; charset=US-ASCII; format=flowed
>>
>> On Sat, 27 Mar 2010, Adam D. I. Kramer wrote:
>> > On Sat, 27 Mar 2010, Ben Bolker wrote:
>> >
>> >>> ...a significant result completely unrelated
>> to the t-value. My
>> >>> interpretation of this would be that we have
>> no good evidence that the
>> >>> estimate for 'pred' is nonzero, but including
>> pred in the model improves
>> >>> prediction.
>> >>
>> >
>> >>? I have seen some wonky stuff happen with
>> update() [sorry, can't provide
>> >> any reproducible details], I would definitely try
>> fitting b by spelling
>> >> out the full model rather than using update() and
>> see if that makes a
>> >> difference.
>> >
>> > This produces no difference in b's estimates or the
>> anova() statistics.
>> > (That said, I originally was fitting [implicitly] with
>> REML=TRUE, which did
>> > make a difference, but not a big one).
>>
>> The two models both have the same number of observations,
>> one hopes?? How
>> many observations per studyID and how many studyIDs?
>>
>> > Well, thanks for the reply. Are you, then, of the
>> opinion that the above
>> > interpretation is reasonable?
>>
>> I would be a bit nervous.? My interpretation would be
>> that the model is
>> inappropriate for the data (as the Wald and LR tests should
>> roughly agree
>> for a LMM, as Ben pointed out), and would look at
>> diagnostic plots of
>> residuals etc.? The bunch of zeroes you mention may
>> still be stuffing
>> things up ;)? Is a left-censored model plausible?
>>
>> Just my 2c, David Duffy.
>>
>> --
>> | David Duffy (MBBS PhD)
>>
>>
>> ???,-_|\
>> | email: davidD at qimr.edu.au
>> ph: INT+61+7+3362-0217 fax: -0101? /
>> ???*
>> | Epidemiology Unit, Queensland Institute of Medical
>> Research???\_,-._/
>> | 300 Herston Rd, Brisbane, Queensland 4029,
>> Australia? GPG 4D0B994A v
>>
>>
>>
>> ------------------------------
>>
>> Message: 5
>> Date: Sat, 27 Mar 2010 16:17:53 -0700 (PDT)
>> From: "Adam D. I. Kramer" <adik at ilovebacon.org>
>> To: David Duffy <David.Duffy at qimr.edu.au>
>> Cc: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] Significance and lmer
>> Message-ID: <Pine.LNX.4.64.1003271609530.17783 at ilovebacon.org>
>> Content-Type: TEXT/PLAIN; charset=US-ASCII; format=flowed
>>
>> The problem turned out to be, indeed, differing numbers of
>> observations.
>> This is likely due to me relying too much on update() to
>> work as I
>> expected...it did not drop the observations previously
>> dropped. The help
>> page for update makes it very clear that it just
>> re-evaluates an altered
>> call, so this is my fault. Ben's comment about update()
>> being wonky should
>> have given me a hint.
>>
>> Preselecting cases using complete.cases() for both models
>> brought the t
>> values and chi-square values much closer together--when
>> t=.51 for the
>> coefficient, the chisq of a likelihood test for removing
>> the variable from
>> the model was chisq=.25, leading to a reasonable p=.62.
>>
>> Thanks very much to you and Ben Bolker!
>>
>> --Adam
>>
>> On Sun, 28 Mar 2010, David Duffy wrote:
>>
>> > On Sat, 27 Mar 2010, Adam D. I. Kramer wrote:
>> >> On Sat, 27 Mar 2010, Ben Bolker wrote:
>> >>
>> >>>> ...a significant result completely
>> unrelated to the t-value. My
>> >>>> interpretation of this would be that we
>> have no good evidence that the
>> >>>> estimate for 'pred' is nonzero, but
>> including pred in the model improves
>> >>>> prediction.
>> >>>
>> >>
>> >>>? I have seen some wonky stuff happen with
>> update() [sorry, can't provide
>> >>> any reproducible details], I would definitely
>> try fitting b by spelling
>> >>> out the full model rather than using update()
>> and see if that makes a
>> >>> difference.
>> >>
>> >> This produces no difference in b's estimates or
>> the anova() statistics.
>> >> (That said, I originally was fitting [implicitly]
>> with REML=TRUE, which did
>> >> make a difference, but not a big one).
>> >
>> > The two models both have the same number of
>> observations, one hopes?? How
>> > many observations per studyID and how many studyIDs?
>> >
>> >> Well, thanks for the reply. Are you, then, of the
>> opinion that the above
>> >> interpretation is reasonable?
>> >
>> > I would be a bit nervous.? My interpretation
>> would be that the model is
>> > inappropriate for the data (as the Wald and LR tests
>> should roughly agree for
>> > a LMM, as Ben pointed out), and would look at
>> diagnostic plots of residuals
>> > etc.? The bunch of zeroes you mention may still
>> be stuffing things up ;)? Is
>> > a left-censored model plausible?
>> >
>> > Just my 2c, David Duffy.
>> >
>> > --
>> > | David Duffy (MBBS PhD)
>>
>>
>> ???,-_|\
>> > | email: davidD at qimr.edu.au
>> ph: INT+61+7+3362-0217 fax: -0101? /
>> ???*
>> > | Epidemiology Unit, Queensland Institute of Medical
>> Research???\_,-._/
>> > | 300 Herston Rd, Brisbane, Queensland 4029,
>> Australia? GPG 4D0B994A v
>> >
>>
>>
>>
>> ------------------------------
>>
>> Message: 6
>> Date: Sat, 27 Mar 2010 23:25:21 -0500
>> From: Yong Wu <wuyong88 at gmail.com>
>> To: r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] Very weird lmer results, compared to
>> SAS proc mix
>> Message-ID:
>> ??? <cfa5b89e1003272125r1677f3ddl8004de6f726683cd at mail.gmail.com>
>> Content-Type: text/plain
>>
>> Sorry to bother you. I am struggling in this issue for long
>> time. Wish
>> somebody can help me.
>>
>> I first used lmer to do the following analysis.
>> fullmodel=lmer(BMI~1+exposure+(age|ID),data, REML=FALSE)
>>
>> reducemodel=lmer(BMI~1+(age|ID),data, REML=FALSE)
>> ? ? ? ? ? anova(full,red)
>> The "fullmodel" has AIC of 6874 and "reducemodel" has AIC
>> of 7106, which
>> cause "anova" analysis giving the p-value< 2.2e-16 .
>> This result is
>> definitely wrong
>>
>> I then did the similar study by SAS.
>> The fullmodel is:
>> proc mixed;
>> class exposure;
>> model BMI=exposure;
>> random age /sub=id;
>> run;
>> The AIC is 7099.7, and type 3 test of fixed effect,
>> exposure, got
>> p-value=0.74.
>>
>> The reducemodel is:
>> proc mixed;
>> ?class exposure;
>> ?model BMI=;
>> ?random age /sub=id;
>> ?run;
>> ?The AIC is 7101.2.
>>
>> The SAS result is correct.
>>
>> Could somebody help me to explain why lmer is wrong?
>>
>> I do not even dare to use lmer now, since I can not trust
>> its result. Thanks
>> in advance for any of your answer.
>>
>> Best,
>> Yong
>> ,
>>
>> ??? [[alternative HTML version deleted]]
>>
>>
>>
>> ------------------------------
>>
>> Message: 7
>> Date: Sat, 27 Mar 2010 23:55:54 -0500
>> From: hadley wickham <h.wickham at gmail.com>
>> To: Yong Wu <wuyong88 at gmail.com>
>> Cc: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] Very weird lmer results, compared
>> to SAS proc
>> ??? mix
>> Message-ID:
>> ??? <f8e6ff051003272155l4501611dnebf8d57c8cfe9f5e at mail.gmail.com>
>> Content-Type: text/plain; charset=ISO-8859-1
>>
>> On Sat, Mar 27, 2010 at 11:25 PM, Yong Wu <wuyong88 at gmail.com>
>> wrote:
>> > Sorry to bother you. I am struggling in this issue for
>> long time. Wish
>> > somebody can help me.
>> >
>> > I first used lmer to do the following analysis.
>> > fullmodel=lmer(BMI~1+exposure+(age|ID),data,
>> REML=FALSE)
>> > ? ? ? ? ?reducemodel=lmer(BMI~1+(age|ID),data,
>> REML=FALSE)
>> > ? ? ? ? ?anova(full,red)
>> > The "fullmodel" has AIC of 6874 and "reducemodel" has
>> AIC of 7106, which
>> > cause "anova" analysis giving the p-value< 2.2e-16
>> . This result is
>> > definitely wrong
>>
>> How do you know?? It would be helpful if you provided
>> the evidence you
>> used to judge SAS correct and R incorrect.
>>
>> Hadley
>>
>>
>> --
>> Assistant Professor / Dobelman Family Junior Chair
>> Department of Statistics / Rice University
>> http://had.co.nz/
>>
>>
>>
>> ------------------------------
>>
>> _______________________________________________
>> R-sig-mixed-models mailing list
>> R-sig-mixed-models at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>> End of R-sig-mixed-models Digest, Vol 39, Issue 42
>> **************************************************
>>
>
>
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From jungck at gmail.com  Mon Mar 29 03:36:00 2010
From: jungck at gmail.com (jungck)
Date: Sun, 28 Mar 2010 21:36:00 -0400
Subject: [R-sig-ME] Interaction Terms controlling Influence case in lmer
Message-ID: <6a32069d1003281836m2d8e3799pb435e621115fd011@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100328/7392784e/attachment.pl>

From lamprianou at yahoo.com  Mon Mar 29 07:49:16 2010
From: lamprianou at yahoo.com (Iasonas Lamprianou)
Date: Sun, 28 Mar 2010 22:49:16 -0700 (PDT)
Subject: [R-sig-ME] fixed vs random
In-Reply-To: <a46630751003281412i35893cd3u153264b3b9f29a8e@mail.gmail.com>
Message-ID: <836648.56317.qm@web58908.mail.re1.yahoo.com>

Thank you, very kind of you to respond

Dr. Iasonas Lamprianou


Assistant Professor (Educational Research and Evaluation)
Department of Education Sciences
European University-Cyprus
P.O. Box 22006
1516 Nicosia
Cyprus 
Tel.: +357-22-713178
Fax: +357-22-590539


Honorary Research Fellow
Department of Education
The University of Manchester
Oxford Road, Manchester M13 9PL, UK
Tel. 0044  161 275 3485
iasonas.lamprianou at manchester.ac.uk


--- On Sun, 28/3/10, Daniel Ezra Johnson <danielezrajohnson at gmail.com> wrote:

> From: Daniel Ezra Johnson <danielezrajohnson at gmail.com>
> Subject: Re: [R-sig-ME] fixed vs random
> To: "Iasonas Lamprianou" <lamprianou at yahoo.com>
> Cc: r-sig-mixed-models at r-project.org
> Date: Sunday, 28 March, 2010, 22:12
> Terms such as (gender|candidate)
> estimate a gender effect that can
> vary across candidates. It is presumably meaningless to
> discuss the
> gender effect of any individual candidate, so this term
> should not be
> used.
> 
> The form of m2 is preferred to m1 in most cases when you
> have a
> legitimate random slope variable, for example if you had a
> factor
> "difficulty" referring to the difficulty of the questions,
> it would be
> meaningful to estimate the effect of question difficulty
> separately
> for each candidate, so a model like
> 
> m3 <- lmer(score ~ 1 + gender + difficulty +
> (difficulty|candidate), mg2006_sub)
> 
> might be sensible, but not one with gender as a random
> slope over candidate.
> 
> Dan
> 
> On Sun, Mar 28, 2010 at 4:21 PM, Iasonas Lamprianou
> <lamprianou at yahoo.com>
> wrote:
> >
> > Dear colleagues,
> > I am not sure what the difference between those models
> is:
> >
> > m0<- lmer(score ~ 1+gender+(1|candidate),
> mg2006_sub)
> > m1<- lmer(score ~ 1+(1+gender|candidate),
> mg2006_sub)
> > m2 <- lmer(score ~ 1+gender+(1+gender|candidate),
> mg2006_sub)
> >
> > the first model is modelling the candidate as a random
> effect in an examination, where two markers mark each
> response of a candidate (a repeated measure). I assume that
> the gender of the candidate is a good predictor of
> performance on the test, so I can use any of the three
> models. But I do not understand what the difference is. Why
> would I get different results between m0 and m1? In effect,
> I am just adding the gender as a fixed effect.And is m2 a
> valid model?
> >
> > thank you
> >
> > jason
> >
> >
> >
> > Dr. Iasonas Lamprianou
> >
> >
> > Assistant Professor (Educational Research and
> Evaluation)
> > Department of Education Sciences
> > European University-Cyprus
> > P.O. Box 22006
> > 1516 Nicosia
> > Cyprus
> > Tel.: +357-22-713178
> > Fax: +357-22-590539
> >
> >
> > Honorary Research Fellow
> > Department of Education
> > The University of Manchester
> > Oxford Road, Manchester M13 9PL, UK
> > Tel. 0044 ?161 275 3485
> > iasonas.lamprianou at manchester.ac.uk
> >
> >
> > --- On Sun, 28/3/10, r-sig-mixed-models-request at r-project.org
> <r-sig-mixed-models-request at r-project.org>
> wrote:
> >
> >> From: r-sig-mixed-models-request at r-project.org
> <r-sig-mixed-models-request at r-project.org>
> >> Subject: R-sig-mixed-models Digest, Vol 39, Issue
> 42
> >> To: r-sig-mixed-models at r-project.org
> >> Date: Sunday, 28 March, 2010, 11:00
> >> Send R-sig-mixed-models mailing list
> >> submissions to
> >> ??? r-sig-mixed-models at r-project.org
> >>
> >> To subscribe or unsubscribe via the World Wide
> Web, visit
> >> ??? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> or, via email, send a message with subject or body
> 'help'
> >> to
> >> ??? r-sig-mixed-models-request at r-project.org
> >>
> >> You can reach the person managing the list at
> >> ??? r-sig-mixed-models-owner at r-project.org
> >>
> >> When replying, please edit your Subject line so it
> is more
> >> specific
> >> than "Re: Contents of R-sig-mixed-models
> digest..."
> >>
> >>
> >> Today's Topics:
> >>
> >> ???1. Re: Could not get a lmer or glmer
> >> summary (Eric Edeline)
> >> ???2. Re: Significance and lmer (Ben
> >> Bolker)
> >> ???3. Re: Significance and lmer (Adam D. I.
> >> Kramer)
> >> ???4. Re: Significance and lmer (David
> >> Duffy)
> >> ???5. Re: Significance and lmer (Adam D. I.
> >> Kramer)
> >> ???6. Very weird lmer results, compared to
> >> SAS proc mix (Yong Wu)
> >> ???7. Re: Very weird lmer results, compared
> >> to SAS proc mix
> >> ? ? ? (hadley wickham)
> >>
> >>
> >>
> ----------------------------------------------------------------------
> >>
> >> Message: 1
> >> Date: Sat, 27 Mar 2010 14:59:48 +0100
> >> From: Eric Edeline <edeline at biologie.ens.fr>
> >> To: David Duffy <David.Duffy at qimr.edu.au>
> >> Cc: r-sig-mixed-models at r-project.org
> >> Subject: Re: [R-sig-ME] Could not get a lmer or
> glmer
> >> summary
> >> Message-ID: <4BAE0F54.3000809 at biologie.ens.fr>
> >> Content-Type: text/plain; charset=ISO-8859-1;
> >> format=flowed
> >>
> >> I have solved my problem, which was apparently due
> to a
> >> conflict between
> >> lme4 and another library (one of these: tree,
> VGAM, sn,
> >> Matrix,
> >> mclust...) about an "rcon" object if I remember
> well.
> >> Removing all the
> >> libraries including lme4 from
> /usr/local/lib/R/site-library
> >> and
> >> re-installing lme4 in /usr/lib/R/site-library made
> the
> >> trick. Sorry for
> >> not providing more detailed information, I just do
> not
> >> remember more!
> >>
> >> Cheers,
> >>
> >> eric
> >>
> >>
> >>
> >> David Duffy wrote:
> >> > On Fri, 26 Mar 2010, Eric Edeline wrote:
> >> >
> >> >> Dear Ben,
> >> >>
> >> >> thank you for your feed-back. I have now
> tested
> >> lmer on several
> >> >> datasets and I always get the same error
> message
> >> when asking for
> >> >> model summary. So the problem is with
> lme4, not
> >> with the data. Then,
> >> >> I ran the exact same models and data on
> another
> >> machine and it works
> >> >> fine! So the lme4 problem is specific to
> my
> >> machine. Then, I tried
> >> >> brute force: uninstalling and
> re-installing R on
> >> my machine, but the
> >> >> lme4 problem remains.
> >> >
> >> > Therefore, you either need to "just" extract
> the
> >> results you want from
> >> > m11
> >> > directly (doing any necessary calculations
> yourself),
> >> or step through
> >> > using a
> >> > debugger, or send all the files to Douglas
> Bates ;)
> >> >
> >> > Cheers, David Duffy.
> >>
> >> --
> >> Eric Edeline
> >> Assistant Professor
> >> UMR 7618 BIOEMCO
> >> Ecole Normale Sup?rieure
> >> 46 rue d'Ulm
> >> 75230 Paris cedex 05
> >> France
> >>
> >> Tel: +33 (0)1 44 32 38 84
> >> Fax: +33 (0)1 44 32 38 85
> >>
> >> http://www.biologie.ens.fr/bioemco/biodiversite/edeline.html
> >>
> >>
> >>
> >> ------------------------------
> >>
> >> Message: 2
> >> Date: Sat, 27 Mar 2010 15:04:42 +0000 (UTC)
> >> From: Ben Bolker <bolker at ufl.edu>
> >> To: r-sig-mixed-models at r-project.org
> >> Subject: Re: [R-sig-ME] Significance and lmer
> >> Message-ID: <loom.20100327T160050-336 at post.gmane.org>
> >> Content-Type: text/plain; charset=us-ascii
> >>
> >> Adam D. I. Kramer <adik at ...> writes:
> >>
> >> >
> >> > Dear colleagues,
> >> >
> >> > Please consider this series of commands:
> >> >
> >> > a <- lmer(log(stddiff+.1539) ~ pred + m*v
> + option
> >> + (option|studyID),
> >> > data=r1, subset=option>1, REML=FALSE)
> >> >
> >> > b <- update(a, . ~ . - pred)
> >> >
> >> > anova(a,b)
> >> >
> >> > ...am I mistaken in thinking that the latter
> command
> >> will produce a test of
> >> > whether "pred" is a significant predictor of
> >> log(stddiff+.1539)? I am
> >> > concerned because of the results:
> >> >
> >>
> >> ? [snip]
> >>
> >> > ...a significant result completely unrelated
> to the
> >> t-value. My
> >> > interpretation of this would be that we have
> no good
> >> evidence that the
> >> > estimate for 'pred' is nonzero, but including
> pred in
> >> the model improves
> >> > prediction.
> >>
> >> ? It is possible for Wald tests (as provided by
> >> summary()) to
> >> disagree radically with likelihood ratio tests
> (look up
> >> "Hauck-Donner
> >> effects", but my guess is that's not what's going
> >> on here (it definitely can apply in binomial
> models, don't
> >> think
> >> it should apply to LMMs but ?).
> >>
> >> ? I have seen some wonky stuff happen with
> update()
> >> [sorry, can't
> >> provide any reproducible details], I would
> definitely try
> >> fitting
> >> b by spelling out the full model rather than using
> update()
> >> and
> >> see if that makes a difference.
> >>
> >> ? Other than that, nothing springs to mind.
> >>
> >> ? (Where does the log(x+0.1539) transformation
> come
> >> from???)
> >>
> >>
> >>
> >> ------------------------------
> >>
> >> Message: 3
> >> Date: Sat, 27 Mar 2010 10:09:41 -0700 (PDT)
> >> From: "Adam D. I. Kramer" <adik at ilovebacon.org>
> >> To: Ben Bolker <bolker at ufl.edu>
> >> Cc: r-sig-mixed-models at r-project.org
> >> Subject: Re: [R-sig-ME] Significance and lmer
> >> Message-ID: <Pine.LNX.4.64.1003270955500.17783 at ilovebacon.org>
> >> Content-Type: TEXT/PLAIN; charset=US-ASCII;
> format=flowed
> >>
> >>
> >> On Sat, 27 Mar 2010, Ben Bolker wrote:
> >>
> >> >> ...a significant result completely
> unrelated to
> >> the t-value. My
> >> >> interpretation of this would be that we
> have no
> >> good evidence that the
> >> >> estimate for 'pred' is nonzero, but
> including pred
> >> in the model improves
> >> >> prediction.
> >> >
> >> >? It is possible for Wald tests (as provided
> by
> >> summary()) to disagree
> >> > radically with likelihood ratio tests (look
> up
> >> "Hauck-Donner effects", but
> >> > my guess is that's not what's going on here
> (it
> >> definitely can apply in
> >> > binomial models, don't think it should apply
> to LMMs
> >> but ?).
> >>
> >> There are no Wald tests produced by the
> summary()...my
> >> understanding from
> >> reading this list is that the t-values are
> provided because
> >> they are t-like
> >> (effect / se), but that it is difficult (and
> perhaps
> >> foolish) to estimate
> >> degrees of freedom for t. So my concern is based
> on the
> >> fact that t is very
> >> small.
> >>
> >> >? I have seen some wonky stuff happen with
> >> update() [sorry, can't provide
> >> > any reproducible details], I would definitely
> try
> >> fitting b by spelling
> >> > out the full model rather than using update()
> and see
> >> if that makes a
> >> > difference.
> >>
> >> This produces no difference in b's estimates or
> the anova()
> >> statistics.
> >> (That said, I originally was fitting [implicitly]
> with
> >> REML=TRUE, which did
> >> make a difference, but not a big one).
> >>
> >> >? Other than that, nothing springs to mind.
> >>
> >> Well, thanks for the reply. Are you, then, of the
> opinion
> >> that the above
> >> interpretation is reasonable?
> >>
> >> >? (Where does the log(x+0.1539)
> transformation
> >> come from???)
> >>
> >> x is power-law distributed with a bunch of zeroes
> (but not
> >> ordinal, or I'd
> >> use family=poisson), and .1539 is the 25th
> percentile. This
> >> normalizes is
> >> pretty well. Good question, though! And thanks ofr
> the
> >> response!
> >>
> >> --Adam
> >>
> >>
> >>
> >> ------------------------------
> >>
> >> Message: 4
> >> Date: Sun, 28 Mar 2010 08:04:03 +1000 (EST)
> >> From: David Duffy <David.Duffy at qimr.edu.au>
> >> To: "Adam D. I. Kramer" <adik at ilovebacon.org>
> >> Cc: r-sig-mixed-models at r-project.org
> >> Subject: Re: [R-sig-ME] Significance and lmer
> >> Message-ID: <Pine.LNX.4.64.1003280753090.29716 at orpheus.qimr.edu.au>
> >> Content-Type: TEXT/PLAIN; charset=US-ASCII;
> format=flowed
> >>
> >> On Sat, 27 Mar 2010, Adam D. I. Kramer wrote:
> >> > On Sat, 27 Mar 2010, Ben Bolker wrote:
> >> >
> >> >>> ...a significant result completely
> unrelated
> >> to the t-value. My
> >> >>> interpretation of this would be that
> we have
> >> no good evidence that the
> >> >>> estimate for 'pred' is nonzero, but
> including
> >> pred in the model improves
> >> >>> prediction.
> >> >>
> >> >
> >> >>? I have seen some wonky stuff happen
> with
> >> update() [sorry, can't provide
> >> >> any reproducible details], I would
> definitely try
> >> fitting b by spelling
> >> >> out the full model rather than using
> update() and
> >> see if that makes a
> >> >> difference.
> >> >
> >> > This produces no difference in b's estimates
> or the
> >> anova() statistics.
> >> > (That said, I originally was fitting
> [implicitly] with
> >> REML=TRUE, which did
> >> > make a difference, but not a big one).
> >>
> >> The two models both have the same number of
> observations,
> >> one hopes?? How
> >> many observations per studyID and how many
> studyIDs?
> >>
> >> > Well, thanks for the reply. Are you, then, of
> the
> >> opinion that the above
> >> > interpretation is reasonable?
> >>
> >> I would be a bit nervous.? My interpretation
> would be
> >> that the model is
> >> inappropriate for the data (as the Wald and LR
> tests should
> >> roughly agree
> >> for a LMM, as Ben pointed out), and would look at
> >> diagnostic plots of
> >> residuals etc.? The bunch of zeroes you mention
> may
> >> still be stuffing
> >> things up ;)? Is a left-censored model
> plausible?
> >>
> >> Just my 2c, David Duffy.
> >>
> >> --
> >> | David Duffy (MBBS PhD)
> >>
> >>
> >> ???,-_|\
> >> | email: davidD at qimr.edu.au
> >> ph: INT+61+7+3362-0217 fax: -0101? /
> >> ???*
> >> | Epidemiology Unit, Queensland Institute of
> Medical
> >> Research???\_,-._/
> >> | 300 Herston Rd, Brisbane, Queensland 4029,
> >> Australia? GPG 4D0B994A v
> >>
> >>
> >>
> >> ------------------------------
> >>
> >> Message: 5
> >> Date: Sat, 27 Mar 2010 16:17:53 -0700 (PDT)
> >> From: "Adam D. I. Kramer" <adik at ilovebacon.org>
> >> To: David Duffy <David.Duffy at qimr.edu.au>
> >> Cc: r-sig-mixed-models at r-project.org
> >> Subject: Re: [R-sig-ME] Significance and lmer
> >> Message-ID: <Pine.LNX.4.64.1003271609530.17783 at ilovebacon.org>
> >> Content-Type: TEXT/PLAIN; charset=US-ASCII;
> format=flowed
> >>
> >> The problem turned out to be, indeed, differing
> numbers of
> >> observations.
> >> This is likely due to me relying too much on
> update() to
> >> work as I
> >> expected...it did not drop the observations
> previously
> >> dropped. The help
> >> page for update makes it very clear that it just
> >> re-evaluates an altered
> >> call, so this is my fault. Ben's comment about
> update()
> >> being wonky should
> >> have given me a hint.
> >>
> >> Preselecting cases using complete.cases() for both
> models
> >> brought the t
> >> values and chi-square values much closer
> together--when
> >> t=.51 for the
> >> coefficient, the chisq of a likelihood test for
> removing
> >> the variable from
> >> the model was chisq=.25, leading to a reasonable
> p=.62.
> >>
> >> Thanks very much to you and Ben Bolker!
> >>
> >> --Adam
> >>
> >> On Sun, 28 Mar 2010, David Duffy wrote:
> >>
> >> > On Sat, 27 Mar 2010, Adam D. I. Kramer
> wrote:
> >> >> On Sat, 27 Mar 2010, Ben Bolker wrote:
> >> >>
> >> >>>> ...a significant result
> completely
> >> unrelated to the t-value. My
> >> >>>> interpretation of this would be
> that we
> >> have no good evidence that the
> >> >>>> estimate for 'pred' is nonzero,
> but
> >> including pred in the model improves
> >> >>>> prediction.
> >> >>>
> >> >>
> >> >>>? I have seen some wonky stuff happen
> with
> >> update() [sorry, can't provide
> >> >>> any reproducible details], I would
> definitely
> >> try fitting b by spelling
> >> >>> out the full model rather than using
> update()
> >> and see if that makes a
> >> >>> difference.
> >> >>
> >> >> This produces no difference in b's
> estimates or
> >> the anova() statistics.
> >> >> (That said, I originally was fitting
> [implicitly]
> >> with REML=TRUE, which did
> >> >> make a difference, but not a big one).
> >> >
> >> > The two models both have the same number of
> >> observations, one hopes?? How
> >> > many observations per studyID and how many
> studyIDs?
> >> >
> >> >> Well, thanks for the reply. Are you,
> then, of the
> >> opinion that the above
> >> >> interpretation is reasonable?
> >> >
> >> > I would be a bit nervous.? My
> interpretation
> >> would be that the model is
> >> > inappropriate for the data (as the Wald and
> LR tests
> >> should roughly agree for
> >> > a LMM, as Ben pointed out), and would look
> at
> >> diagnostic plots of residuals
> >> > etc.? The bunch of zeroes you mention may
> still
> >> be stuffing things up ;)? Is
> >> > a left-censored model plausible?
> >> >
> >> > Just my 2c, David Duffy.
> >> >
> >> > --
> >> > | David Duffy (MBBS PhD)
> >>
> >>
> >> ???,-_|\
> >> > | email: davidD at qimr.edu.au
> >> ph: INT+61+7+3362-0217 fax: -0101? /
> >> ???*
> >> > | Epidemiology Unit, Queensland Institute of
> Medical
> >> Research???\_,-._/
> >> > | 300 Herston Rd, Brisbane, Queensland 4029,
> >> Australia? GPG 4D0B994A v
> >> >
> >>
> >>
> >>
> >> ------------------------------
> >>
> >> Message: 6
> >> Date: Sat, 27 Mar 2010 23:25:21 -0500
> >> From: Yong Wu <wuyong88 at gmail.com>
> >> To: r-sig-mixed-models at r-project.org
> >> Subject: [R-sig-ME] Very weird lmer results,
> compared to
> >> SAS proc mix
> >> Message-ID:
> >> ??? <cfa5b89e1003272125r1677f3ddl8004de6f726683cd at mail.gmail.com>
> >> Content-Type: text/plain
> >>
> >> Sorry to bother you. I am struggling in this issue
> for long
> >> time. Wish
> >> somebody can help me.
> >>
> >> I first used lmer to do the following analysis.
> >> fullmodel=lmer(BMI~1+exposure+(age|ID),data,
> REML=FALSE)
> >>
> >> reducemodel=lmer(BMI~1+(age|ID),data, REML=FALSE)
> >> ? ? ? ? ? anova(full,red)
> >> The "fullmodel" has AIC of 6874 and "reducemodel"
> has AIC
> >> of 7106, which
> >> cause "anova" analysis giving the p-value<
> 2.2e-16 .
> >> This result is
> >> definitely wrong
> >>
> >> I then did the similar study by SAS.
> >> The fullmodel is:
> >> proc mixed;
> >> class exposure;
> >> model BMI=exposure;
> >> random age /sub=id;
> >> run;
> >> The AIC is 7099.7, and type 3 test of fixed
> effect,
> >> exposure, got
> >> p-value=0.74.
> >>
> >> The reducemodel is:
> >> proc mixed;
> >> ?class exposure;
> >> ?model BMI=;
> >> ?random age /sub=id;
> >> ?run;
> >> ?The AIC is 7101.2.
> >>
> >> The SAS result is correct.
> >>
> >> Could somebody help me to explain why lmer is
> wrong?
> >>
> >> I do not even dare to use lmer now, since I can
> not trust
> >> its result. Thanks
> >> in advance for any of your answer.
> >>
> >> Best,
> >> Yong
> >> ,
> >>
> >> ??? [[alternative HTML version deleted]]
> >>
> >>
> >>
> >> ------------------------------
> >>
> >> Message: 7
> >> Date: Sat, 27 Mar 2010 23:55:54 -0500
> >> From: hadley wickham <h.wickham at gmail.com>
> >> To: Yong Wu <wuyong88 at gmail.com>
> >> Cc: r-sig-mixed-models at r-project.org
> >> Subject: Re: [R-sig-ME] Very weird lmer results,
> compared
> >> to SAS proc
> >> ??? mix
> >> Message-ID:
> >> ??? <f8e6ff051003272155l4501611dnebf8d57c8cfe9f5e at mail.gmail.com>
> >> Content-Type: text/plain; charset=ISO-8859-1
> >>
> >> On Sat, Mar 27, 2010 at 11:25 PM, Yong Wu <wuyong88 at gmail.com>
> >> wrote:
> >> > Sorry to bother you. I am struggling in this
> issue for
> >> long time. Wish
> >> > somebody can help me.
> >> >
> >> > I first used lmer to do the following
> analysis.
> >> > fullmodel=lmer(BMI~1+exposure+(age|ID),data,
> >> REML=FALSE)
> >> > ? ? ? ?
> ?reducemodel=lmer(BMI~1+(age|ID),data,
> >> REML=FALSE)
> >> > ? ? ? ? ?anova(full,red)
> >> > The "fullmodel" has AIC of 6874 and
> "reducemodel" has
> >> AIC of 7106, which
> >> > cause "anova" analysis giving the p-value<
> 2.2e-16
> >> . This result is
> >> > definitely wrong
> >>
> >> How do you know?? It would be helpful if you
> provided
> >> the evidence you
> >> used to judge SAS correct and R incorrect.
> >>
> >> Hadley
> >>
> >>
> >> --
> >> Assistant Professor / Dobelman Family Junior
> Chair
> >> Department of Statistics / Rice University
> >> http://had.co.nz/
> >>
> >>
> >>
> >> ------------------------------
> >>
> >> _______________________________________________
> >> R-sig-mixed-models mailing list
> >> R-sig-mixed-models at r-project.org
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >>
> >> End of R-sig-mixed-models Digest, Vol 39, Issue
> 42
> >>
> **************************************************
> >>
> >
> >
> >
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org
> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 






From Martin.Stjernman at zooekol.lu.se  Mon Mar 29 10:18:49 2010
From: Martin.Stjernman at zooekol.lu.se (Martin Stjernman)
Date: Mon, 29 Mar 2010 10:18:49 +0200
Subject: [R-sig-ME] The issue of increasing maximum number of iterations
Message-ID: <320F456772133941B68BF26CC486EBE9B8F4A1CDC7@UWEXMBX01.uw.lu.se>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100329/ff7e5d63/attachment.pl>

From jungck at gmail.com  Mon Mar 29 14:00:56 2010
From: jungck at gmail.com (jungck)
Date: Mon, 29 Mar 2010 08:00:56 -0400
Subject: [R-sig-ME] Interactive Term Plot in LMER
Message-ID: <6a32069d1003290500obcd322i471842845ceb1617@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100329/675b1e54/attachment.pl>

From pierces1 at msu.edu  Mon Mar 29 15:01:22 2010
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Mon, 29 Mar 2010 09:01:22 -0400
Subject: [R-sig-ME] Interaction Terms controlling Influence case in lmer
In-Reply-To: <6a32069d1003281836m2d8e3799pb435e621115fd011@mail.gmail.com>
References: <6a32069d1003281836m2d8e3799pb435e621115fd011@mail.gmail.com>
Message-ID: <D20CB208F3184F44BAA97EE10D5BB473@TheVoid>

Since your DV is a proportion, it may not really be normally distributed in
it's original form. Perhaps you should transform the dependent variable
before running the analysis. Using an arcsine square root transformation may
help (you should be able to find details via Google). 


Steven J. Pierce
Associate Director
Center for Statistical Training & Consulting (CSTAT)
Michigan State University
178 Giltner Hall
East Lansing, MI 48824
Web: http://www.cstat.msu.edu


-----Original Message-----
From: jungck [mailto:jungck at gmail.com] 
Sent: Sunday, March 28, 2010 9:36 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Interaction Terms controlling Influence case in lmer

Dear all,

I am working on interaction terms between two levels.
But when I plot them with the package languageR and following function, I
could have "impossible" predicted values, which is going beyond my dependent
variable.
My DV ranges 0 to 1 in continuous variable. But lines appear above 1.

lmerPlotInt.fnc(model.after.control.influence, "x", "y", "y:x",
which="matplot", ylabel="DV", ylim=c(0,1.1))

The issue here seems only to appear when I control influence country by
using the package influence.ME. (Actually there is another issue involved
this package like I couldn't plot after using "exclude.influence" function.
In R, it only makes coordinates without any lines)

When I include influence case(s), I can see those lines within the range of
DV.
Can anyone familiar with lmerPlotInt.fnc let me know what's going on?

And, I wonder if there is another alternative package/function for plotting
interaction terms in mixed effect model using LMER or others.
Thanks much in advance.

-Chang

	[[alternative HTML version deleted]]



From jungck at gmail.com  Mon Mar 29 15:09:13 2010
From: jungck at gmail.com (jungck)
Date: Mon, 29 Mar 2010 09:09:13 -0400
Subject: [R-sig-ME] Interactive Term Plot in LMER
In-Reply-To: <4BB0995F.30409@sbg.ac.at>
References: <6a32069d1003290500obcd322i471842845ceb1617@mail.gmail.com>
	<4BB0995F.30409@sbg.ac.at>
Message-ID: <6a32069d1003290609m5aee270g377d63c8de71b459@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100329/02262c0f/attachment.pl>

From slu at ccsr.uchicago.edu  Mon Mar 29 16:10:07 2010
From: slu at ccsr.uchicago.edu (Stuart Luppescu)
Date: Mon, 29 Mar 2010 09:10:07 -0500
Subject: [R-sig-ME] fixed vs random
In-Reply-To: <109722.72582.qm@web58905.mail.re1.yahoo.com>
References: <109722.72582.qm@web58905.mail.re1.yahoo.com>
Message-ID: <1269871807.26467.3.camel@musuko.spc.uchicago.edu>

On Sun, 2010-03-28 at 13:21 -0700, Iasonas Lamprianou wrote:
> m1<- lmer(score ~ 1+(1+gender|candidate), mg2006_sub)

And the other unusual thing about this model, as was pointed out by 
Doug Bates recently in another thread, is that without a fixed effect of
gender, you're stipulating that the overall effect of gender is 0,
leaving only the random effect. In this case, it might not be terrible
(assuming gender is coded {0, 1}) but it might not be what you want,
either.
-- 
Stuart Luppescu <slu at ccsr.uchicago.edu>
University of Chicago



From lamprianou at yahoo.com  Mon Mar 29 16:15:38 2010
From: lamprianou at yahoo.com (Iasonas Lamprianou)
Date: Mon, 29 Mar 2010 07:15:38 -0700 (PDT)
Subject: [R-sig-ME] fixed vs random
In-Reply-To: <1269871807.26467.3.camel@musuko.spc.uchicago.edu>
Message-ID: <854911.97692.qm@web58901.mail.re1.yahoo.com>

thank you
good observation
Dr. Iasonas Lamprianou


Assistant Professor (Educational Research and Evaluation)
Department of Education Sciences
European University-Cyprus
P.O. Box 22006
1516 Nicosia
Cyprus 
Tel.: +357-22-713178
Fax: +357-22-590539


Honorary Research Fellow
Department of Education
The University of Manchester
Oxford Road, Manchester M13 9PL, UK
Tel. 0044  161 275 3485
iasonas.lamprianou at manchester.ac.uk


--- On Mon, 29/3/10, Stuart Luppescu <slu at ccsr.uchicago.edu> wrote:

> From: Stuart Luppescu <slu at ccsr.uchicago.edu>
> Subject: Re: [R-sig-ME] fixed vs random
> To: "Iasonas Lamprianou" <lamprianou at yahoo.com>
> Cc: r-sig-mixed-models at r-project.org
> Date: Monday, 29 March, 2010, 15:10
> On Sun, 2010-03-28 at 13:21 -0700,
> Iasonas Lamprianou wrote:
> > m1<- lmer(score ~ 1+(1+gender|candidate),
> mg2006_sub)
> 
> And the other unusual thing about this model, as was
> pointed out by 
> Doug Bates recently in another thread, is that without a
> fixed effect of
> gender, you're stipulating that the overall effect of
> gender is 0,
> leaving only the random effect. In this case, it might not
> be terrible
> (assuming gender is coded {0, 1}) but it might not be what
> you want,
> either.
> -- 
> Stuart Luppescu <slu at ccsr.uchicago.edu>
> University of Chicago
> 
> 






From jungck at gmail.com  Mon Mar 29 16:38:21 2010
From: jungck at gmail.com (jungck)
Date: Mon, 29 Mar 2010 10:38:21 -0400
Subject: [R-sig-ME] Interaction Terms controlling Influence case in lmer
In-Reply-To: <D20CB208F3184F44BAA97EE10D5BB473@TheVoid>
References: <6a32069d1003281836m2d8e3799pb435e621115fd011@mail.gmail.com>
	<D20CB208F3184F44BAA97EE10D5BB473@TheVoid>
Message-ID: <6a32069d1003290738t1e6d8774o10be3f6c2a8fb2b7@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100329/13f4422f/attachment.pl>

From andydolman at gmail.com  Mon Mar 29 17:08:51 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Mon, 29 Mar 2010 17:08:51 +0200
Subject: [R-sig-ME] unbalanced data in nested lmer model
In-Reply-To: <4BB0B685.70506@uni-rostock.de>
References: <4BAA0B06.1030806@uni-rostock.de> <4BAA3810.4010701@life.ku.dk>
	<4BACB838.7000608@uni-rostock.de>
	<951234ac1003260745k6590c26cj887dc17aae83a9c4@mail.gmail.com>
	<4BB0B685.70506@uni-rostock.de>
Message-ID: <951234ac1003290808g5dec0610rc7cdd3f6d89f8167@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100329/f8fd154a/attachment.pl>

From bolker at ufl.edu  Mon Mar 29 17:50:30 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Mon, 29 Mar 2010 15:50:30 +0000 (UTC)
Subject: [R-sig-ME] The issue of increasing maximum number of iterations
References: <320F456772133941B68BF26CC486EBE9B8F4A1CDC7@UWEXMBX01.uw.lu.se>
Message-ID: <loom.20100329T171254-536@post.gmane.org>

Martin Stjernman <Martin.Stjernman at ...> writes:

> 
> Dear listmembers!
> 
> I have also had trouble with the maxIter specification in (g)lmer. 
> I've tried to increase the number of
> iterations (to 1000) via the control statement in lmer 
> but it still stops at 300 (the default).
> We are now a number of users having problem with this but 
> I haven't seen any solution to the problem on this
> list and I would really appreciate any hint on what I am doing wrong.
> I am running on a Vista 64-bit machine and my model specification and
>  session info follows below. Please let
> me know if any other information needs to be attached.

  Looking at the source code in lmer.R, this seems like
a moderately obvious hole: on or about line 714 (I may be
off by a couple of lines) we have

    if (missing(verbose)) verbose <- cv$msVerbose
### FIXME: issue a warning if the model argument is FALSE.  It is ignored. 

 adding the lines

    FL$dims["mxit"] <- cv$maxIter
    FL$dims["mxfn"] <- cv$maxFN

  appears to work: running

 (gm1 <- glmer(cbind(incidence, size - incidence) ~ period + 
   (1 | herd), family=binomial, data=cbpp, control=list(maxIter=1000)))

produces a model with the correct iteration number listed in its
guts.

  The next question is whether you or someone at your institution
is capable of modifying lmer.R appropriately and rebuilding the
package ...



From Tim.Carnus at ucd.ie  Mon Mar 29 18:45:08 2010
From: Tim.Carnus at ucd.ie (Tim Carnus)
Date: Mon, 29 Mar 2010 17:45:08 +0100
Subject: [R-sig-ME] poisson GLMER with identity link
Message-ID: <1269881108.3596.24.camel@tim-laptop>

Dear list,

I am trying to fit a number of GLMERs to count data with an additive
model (in the predictors) that requires the use of the identity link
function. For about half of my response variables this causes no
problems. However in a number of cases the model fitting runs into
problems with regards estimation of negative mean (for e.g. the error
message in mer_finalize: mu[i] must be positive: mu = 1.76267e-312, i =
13075456). As far as I understand this is well known and documented, and
guarding against that possibility is necessary, and built in to say the
glm() function.

My question then is, how can I do this with lmer? (ie how can I specify
the constraints necessary to fit these types of models, if at all
possible)

Best regards,

Tim Carnus



From jana.buerger at uni-rostock.de  Mon Mar 29 16:17:41 2010
From: jana.buerger at uni-rostock.de (=?UTF-8?B?SmFuYSBCw7xyZ2Vy?=)
Date: Mon, 29 Mar 2010 16:17:41 +0200
Subject: [R-sig-ME] unbalanced data in nested lmer model
In-Reply-To: <951234ac1003260745k6590c26cj887dc17aae83a9c4@mail.gmail.com>
References: <4BAA0B06.1030806@uni-rostock.de> <4BAA3810.4010701@life.ku.dk>	
	<4BACB838.7000608@uni-rostock.de>
	<951234ac1003260745k6590c26cj887dc17aae83a9c4@mail.gmail.com>
Message-ID: <4BB0B685.70506@uni-rostock.de>

Dear Andrew and other list members,
As I described in an earlier 
post(https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q1/003503.html)
my data is actually hierarchical down to the level of fields within farms.

There is more than 500 cases on 8 farms in 6 regions.
Would you not think that gives enough power to distinguish within region 
variability vs. between regions?

Moreover I don't understand your argument that fitting random efects 
with less than 5 levels was dodgy, as often examples in the books have 3 
samples from one beach, or 3 laboratory workers within one laboratory. 
These are less than 5 levels, are they not?

Regards, Jana

Andrew Dolman schrieb:
> Dear Jana,
> 
>  >An anova(lm1, lm2)  lm1<-lmer(y~x1+x2+...+(1|region)+(1|region:farm)); 
> lm2<-lmer(y+x1+x2+...+(1|farm)) said models did not differ significantly 
> and AIC was about the same. So I know there is no additional explanatory 
> power including the region term.
> 
>  >Yet, I would like to keep the region effect in the model to separate 
> and compare the effect size of region vs. farm. Is it valid to do so 
> even if  some of the regions are only represented by one farm?
> 
> I don't think you have the data to ask questions about differences 
> between regions as distinct from differences between farms. Look at it 
> this way. If you were just doing a normal comparison between regions and 
> you only looked at 1 or 2 farms per region, would you have the 
> statistical power to say that differences were due to region rather than 
> farm? Answer = No.
> 
> Similarly, are the differences between the farms because they are in 
> different regions or just normal variation between farms? Well you only 
> have 2 farms per region so it's hard to tell. Maybe you just have enough 
> data if pairs of farms within regions are always very similar and 
> differences between regions large.
> 
> Also. Fitting random effects with fewer than 5 levels is dodgy, and you 
> only have 2 levels of farm per region, sometimes 1.
> 
> Perhaps you could look at it this way.
> 
> compare
> 
> m1 <- lmer (y~(1|region))
> m2 <- lmer (y~(1|farm))
> 
> If m2 is better then there is variation between farms within regions, if 
> there's no difference then region accounts for most of the variation. 
> BUT you've not got much power to detect farm effects within regions, so 
> a null result is not strong evidence for the absence of farm variation 
> within regions.
> 
> 
> Andy.
>  
> 
> 
> andydolman at gmail.com <mailto:andydolman at gmail.com>
> 
> 
> 

-- 
Jana B?rger

Universit?t Rostock
Agrar-  und Umweltwissenschaftliche Fakult?t
FG Phytomedizin
Satower Stra?e 48
18059 Rostock

Tel. 0381-498 31 71
Fax.0381-498 31 62



From Eric.Castet at incm.cnrs-mrs.fr  Mon Mar 29 19:45:15 2010
From: Eric.Castet at incm.cnrs-mrs.fr (Eric Castet)
Date: Mon, 29 Mar 2010 19:45:15 +0200
Subject: [R-sig-ME] Correlation of -1: is it a problem?
In-Reply-To: <40e66e0b1003261206u2ce669c9rc0d978e67701f73c@mail.gmail.com>
References: <4BACFA5B.5050707@incm.cnrs-mrs.fr>
	<40e66e0b1003261206u2ce669c9rc0d978e67701f73c@mail.gmail.com>
Message-ID: <4BB0E72B.2070404@incm.cnrs-mrs.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100329/53e9f909/attachment.pl>

From lborger at uoguelph.ca  Mon Mar 29 19:55:01 2010
From: lborger at uoguelph.ca (Luca Borger)
Date: Mon, 29 Mar 2010 13:55:01 -0400
Subject: [R-sig-ME] unbalanced data in nested lmer model
References: <4BAA0B06.1030806@uni-rostock.de>
	<4BAA3810.4010701@life.ku.dk>	<4BACB838.7000608@uni-rostock.de><951234ac1003260745k6590c26cj887dc17aae83a9c4@mail.gmail.com>
	<4BB0B685.70506@uni-rostock.de>
Message-ID: <D63BEA7FF21244B88504AA33F4E7C14D@lborger>

Hello,

as Andrew and others already explained:

> There is more than 500 cases

Fine, this might give you reasonable estimates about how your y is affected 
by your fixed effects covariates (x1,x2,...)

> (...) on 8 farms in 6 regions.
#and, from your previos post
>For 2 of 8 regions there is only 1 farm, the other regions have 2 farms.

thus no way to estimate a difference between region or farm effects for 2 
regions, and very, very limited power for the other 6 (just 2 farms per 
region). To make things worse your data are also quite unbalanced:

>unbalance of case numbers in cells? Or would it be no problem if cell sizes 
>vary between 0 and 53?

which I think means for some farms you got only one record? Anyway, to 
recap, probably OK data for understanding y~x1+x2 etc., insufficient data 
otherwise (should invest in getting data for more farms within regions, not 
more data for the farms you have already sampled).

> Moreover I don't understand your argument that fitting random efects with 
> less than 5 levels was dodgy, as often examples in the books have 3 
> samples from one beach, or 3 laboratory workers within one laboratory. 
> These are less than 5 levels, are they not?

These are usually toy datasets to exemplify how the approach works, I do not 
think they make a claim that the resulting variance estimates are very 
reliable (think in the Zuur etal. mixed effects book you can find more 
realistic examples, if I remember well). Plus, "level" refers to the number 
of beaches or the number of labs etc. and the resulting variance estimates - 
if less than say 5 it appears that you might be better off fitting it as a 
fixed effect and not trying to decompose the variance into between labs and 
within labs etc. Anyway, just my 2 cents and hope I explained this 
correctly...


See also the wiki page set up by Ben Bolker:
http://glmm.wikidot.com/faq

e.g. you might be interested in this entry therein:

Zero or very small random effects variance estimates;
(...)
Very small variance estimates, or very large correlation estimates, often 
indicates unidentifiability/lack of data (either due to exact 
identifiability [e.g. designs that are not replicated at an important level] 
or weak identifiable (designs that would be workable with more data of the 
same type)


HTH


Cheers,

Luca






----- Original Message ----- 
From: "Jana B?rger" <jana.buerger at uni-rostock.de>
To: "Andrew Dolman" <andydolman at gmail.com>
Cc: <r-sig-mixed-models at r-project.org>
Sent: Monday, March 29, 2010 10:17 AM
Subject: Re: [R-sig-ME] unbalanced data in nested lmer model


> Dear Andrew and other list members,
> As I described in an earlier 
> post(https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q1/003503.html)
> my data is actually hierarchical down to the level of fields within farms.
>
> There is more than 500 cases on 8 farms in 6 regions.
> Would you not think that gives enough power to distinguish within region 
> variability vs. between regions?
>
> Moreover I don't understand your argument that fitting random efects with 
> less than 5 levels was dodgy, as often examples in the books have 3 
> samples from one beach, or 3 laboratory workers within one laboratory. 
> These are less than 5 levels, are they not?
>
> Regards, Jana
>
> Andrew Dolman schrieb:
>> Dear Jana,
>>
>>  >An anova(lm1, lm2)  lm1<-lmer(y~x1+x2+...+(1|region)+(1|region:farm)); 
>> lm2<-lmer(y+x1+x2+...+(1|farm)) said models did not differ significantly 
>> and AIC was about the same. So I know there is no additional explanatory 
>> power including the region term.
>>
>>  >Yet, I would like to keep the region effect in the model to separate 
>> and compare the effect size of region vs. farm. Is it valid to do so even 
>> if  some of the regions are only represented by one farm?
>>
>> I don't think you have the data to ask questions about differences 
>> between regions as distinct from differences between farms. Look at it 
>> this way. If you were just doing a normal comparison between regions and 
>> you only looked at 1 or 2 farms per region, would you have the 
>> statistical power to say that differences were due to region rather than 
>> farm? Answer = No.
>>
>> Similarly, are the differences between the farms because they are in 
>> different regions or just normal variation between farms? Well you only 
>> have 2 farms per region so it's hard to tell. Maybe you just have enough 
>> data if pairs of farms within regions are always very similar and 
>> differences between regions large.
>>
>> Also. Fitting random effects with fewer than 5 levels is dodgy, and you 
>> only have 2 levels of farm per region, sometimes 1.
>>
>> Perhaps you could look at it this way.
>>
>> compare
>>
>> m1 <- lmer (y~(1|region))
>> m2 <- lmer (y~(1|farm))
>>
>> If m2 is better then there is variation between farms within regions, if 
>> there's no difference then region accounts for most of the variation. BUT 
>> you've not got much power to detect farm effects within regions, so a 
>> null result is not strong evidence for the absence of farm variation 
>> within regions.
>>
>>
>> Andy.
>>  andydolman at gmail.com <mailto:andydolman at gmail.com>
>>
>>
>>
>
> -- 
> Jana B?rger
>
> Universit?t Rostock
> Agrar-  und Umweltwissenschaftliche Fakult?t
> FG Phytomedizin
> Satower Stra?e 48
> 18059 Rostock
>
> Tel. 0381-498 31 71
> Fax.0381-498 31 62
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bolker at ufl.edu  Mon Mar 29 22:25:12 2010
From: bolker at ufl.edu (Ben Bolker)
Date: Mon, 29 Mar 2010 16:25:12 -0400
Subject: [R-sig-ME] unbalanced data in nested lmer model
In-Reply-To: <D63BEA7FF21244B88504AA33F4E7C14D@lborger>
References: <4BAA0B06.1030806@uni-rostock.de>	<4BAA3810.4010701@life.ku.dk>	<4BACB838.7000608@uni-rostock.de><951234ac1003260745k6590c26cj887dc17aae83a9c4@mail.gmail.com>	<4BB0B685.70506@uni-rostock.de>
	<D63BEA7FF21244B88504AA33F4E7C14D@lborger>
Message-ID: <4BB10CA8.6030803@ufl.edu>

Luca Borger wrote:

[Jana B?rger:]
>> Moreover I don't understand your argument that fitting random efects with 
>> less than 5 levels was dodgy, as often examples in the books have 3 
>> samples from one beach, or 3 laboratory workers within one laboratory. 
>> These are less than 5 levels, are they not?
> 
> These are usually toy datasets to exemplify how the approach works, I do not 
> think they make a claim that the resulting variance estimates are very 
> reliable (think in the Zuur etal. mixed effects book you can find more 
> realistic examples, if I remember well). Plus, "level" refers to the number 
> of beaches or the number of labs etc. and the resulting variance estimates - 
> if less than say 5 it appears that you might be better off fitting it as a 
> fixed effect and not trying to decompose the variance into between labs and 
> within labs etc. Anyway, just my 2 cents and hope I explained this 
> correctly... 
> 
> See also the wiki page set up by Ben Bolker:
> http://glmm.wikidot.com/faq
> 
> e.g. you might be interested in this entry therein:
> 
> Zero or very small random effects variance estimates;
> (...)
> Very small variance estimates, or very large correlation estimates, often 
> indicates unidentifiability/lack of data (either due to exact 
> identifiability [e.g. designs that are not replicated at an important level] 
> or weak identifiable (designs that would be workable with more data of the 
> same type)

  I just added this to the FAQ:

Should I treat factor xxx as fixed or random?

This is in general a far more difficult question than it seems on the
surface. There are many competing philosophies and definitions (see
Gelman 2xxx). One point of particular relevance to 'modern' mixed model
estimation (rather than 'classical' method-of-moments estimation) is
that, for practical purposes, there must be a reasonable number of
random-effects levels (e.g. blocks) ? more than 5 or 6 at a minimum.

    e.g., from Crawley (2002) p. 670: "Are there enough levels of the
factor in the data on which to base an estimate of the variance of the
population of effects? No, means [you should probably treat the variable
as] fixed effects."

Some researchers (who treat fixed vs random as a philosophical rather
than a pragmatic decision) object to this approach.

Treating factors with small numbers of levels as random will in the best
case lead to very small estimates of random effects; in the worst case
it will lead to various numerical difficulties such as lack of
convergence, zero variance estimates, etc.. In the classical
method-of-moments approach these problems do not arise (because the sums
of squares are always well defined as long as there are at least two
units), but the underlying problems of lack of power are there nevertheless.

   (Contributions welcome!)

-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / people.biology.ufl.edu/bolker
GPG key: people.biology.ufl.edu/bolker/benbolker-publickey.asc



From lamprianou at yahoo.com  Mon Mar 29 23:54:09 2010
From: lamprianou at yahoo.com (Iasonas Lamprianou)
Date: Mon, 29 Mar 2010 14:54:09 -0700 (PDT)
Subject: [R-sig-ME] interactions
In-Reply-To: <mailman.2195.1269894328.4248.r-sig-mixed-models@r-project.org>
Message-ID: <646445.12479.qm@web58902.mail.re1.yahoo.com>


Dear colleagues,
apologies for the long question, but I really need some help. It is not a case of academic laziness, I have done my homework but now I need some advice.

I have 10000 students nested in 50 schools, each student taking a test. The tests are randomly grouped in batches of 20 scripts (around 500 batches). Then, two random markers (out of a pool of 57 markers) mark each batch blindly. Each marker marks around 17 random batches of 20 scripts. If the two random markers disagree by more than 10% on the total score for a specific student, then the test of the student is being given to another marker randomly for a third blind marking. So, I have students nested within schools which are nested in areas. Then, scripts (the tests of the students) nested into batches. Then, batches crossed with markers. However, the actual marking lasted around 15 days. One batch may be marked by the first marker on day 1 and then marked by the second marker on the next day (or the day after etc). So the batches are also crossed by days. 

My Research question is: are there markers who are differentially severe or lenient on different days? 

I use this model:

lmer(score ~ 1+day+gender+school+(1+day|marker)+(1|candidate)+(1|batch), mg2007_sub)

I assume that this model is appropriate, because it models candidates as random effects (each candidate has an ability estimate based on the scores he/she received from the two or the three markers if his/her script was remarked by a third marker). Also, every batch is modelled as a random effect. Every marker is modelled as a random effect but I allow his/her estimate to vary by day, so I assume that this would allow me to see if a marker behaves in a different way on different days. So this should answer my research question.

Question 1: does this model make sense statistically (as i formulate it in lme4?)

So far so good, but lme4 will run for 48 hours and then fail because it reached maximum iterations. I assume that even if I allow for more iterations, it will go on for ever.

Question 2: Why is it so slow? Why it does not converge?

Then, I decided to simplify the problem. Instead of modelling day as a factor, I use 'd' which is the cardinal number of day e.g. 1, 2, 3, days that passed since we started marking. I assume that this is an interval scale. If a marker becomes (linearly) more lenient, he/she would 'like' this model. So I run

lmer(score ~ 1+day+gender+dvhool+(1+d|marker)+(1|candidate)+(1|batch), mg2007_sub)

please notice that (1+day|marker) where day is a factor with 15 levels, becomes (1+d|marker) which is numeric variable

and this gives

Error terms:
 Groups    Name        Std.Dev. Corr  
 candidate (Intercept) 16.85          
 batch     (Intercept)  3.49          
 marker    (Intercept)  4.68          
           d            0.38    -0.77 
 Residual               4.83          
---
number of obs: 18001, groups: candidate, 9402; batch, 470; marker, 59
AIC = 138232, DIC = 138388.9
deviance = 138230.4 


Question 3: How do I know that the variance of 'd' is statistically significant? MlWin gives some error estimates.

Question 4: The correlation of -0.77 is a problem?

I hope somebody can help me, this has taken me three days up to now...

Thank you 

jason



Dr. Iasonas Lamprianou


Assistant Professor (Educational Research and Evaluation)
Department of Education Sciences
European University-Cyprus
P.O. Box 22006
1516 Nicosia
Cyprus 
Tel.: +357-22-713178
Fax: +357-22-590539


Honorary Research Fellow
Department of Education
The University of Manchester
Oxford Road, Manchester M13 9PL, UK
Tel. 0044  161 275 3485
iasonas.lamprianou at manchester.ac.uk


--- On Mon, 29/3/10, r-sig-mixed-models-request at r-project.org <r-sig-mixed-models-request at r-project.org> wrote:

> From: r-sig-mixed-models-request at r-project.org <r-sig-mixed-models-request at r-project.org>
> Subject: R-sig-mixed-models Digest, Vol 39, Issue 47
> To: r-sig-mixed-models at r-project.org
> Date: Monday, 29 March, 2010, 21:25
> Send R-sig-mixed-models mailing list
> submissions to
> ??? r-sig-mixed-models at r-project.org
> 
> To subscribe or unsubscribe via the World Wide Web, visit
> ??? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help'
> to
> ??? r-sig-mixed-models-request at r-project.org
> 
> You can reach the person managing the list at
> ??? r-sig-mixed-models-owner at r-project.org
> 
> When replying, please edit your Subject line so it is more
> specific
> than "Re: Contents of R-sig-mixed-models digest..."
> 
> 
> Today's Topics:
> 
> ???1. Re: The issue of increasing maximum
> number of iterations
> ? ? ? (Ben Bolker)
> ???2. poisson GLMER with identity link (Tim
> Carnus)
> ???3. Re: unbalanced data in nested lmer
> model (Jana B?rger)
> ???4. Re: Correlation of -1: is it a
> problem? (Eric Castet)
> ???5. Re: unbalanced data in nested lmer
> model (Luca Borger)
> ???6. Re: unbalanced data in nested lmer
> model (Ben Bolker)
> 
> 
> ----------------------------------------------------------------------
> 
> Message: 1
> Date: Mon, 29 Mar 2010 15:50:30 +0000 (UTC)
> From: Ben Bolker <bolker at ufl.edu>
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] The issue of increasing maximum
> number of
> ??? iterations
> Message-ID: <loom.20100329T171254-536 at post.gmane.org>
> Content-Type: text/plain; charset=us-ascii
> 
> Martin Stjernman <Martin.Stjernman at ...> writes:
> 
> > 
> > Dear listmembers!
> > 
> > I have also had trouble with the maxIter specification
> in (g)lmer. 
> > I've tried to increase the number of
> > iterations (to 1000) via the control statement in lmer
> 
> > but it still stops at 300 (the default).
> > We are now a number of users having problem with this
> but 
> > I haven't seen any solution to the problem on this
> > list and I would really appreciate any hint on what I
> am doing wrong.
> > I am running on a Vista 64-bit machine and my model
> specification and
> >? session info follows below. Please let
> > me know if any other information needs to be
> attached.
> 
> ? Looking at the source code in lmer.R, this seems
> like
> a moderately obvious hole: on or about line 714 (I may be
> off by a couple of lines) we have
> 
> ? ? if (missing(verbose)) verbose <-
> cv$msVerbose
> ### FIXME: issue a warning if the model argument is
> FALSE.? It is ignored. 
> 
>  adding the lines
> 
> ? ? FL$dims["mxit"] <- cv$maxIter
> ? ? FL$dims["mxfn"] <- cv$maxFN
> 
> ? appears to work: running
> 
>  (gm1 <- glmer(cbind(incidence, size - incidence) ~
> period + 
> ???(1 | herd), family=binomial, data=cbpp,
> control=list(maxIter=1000)))
> 
> produces a model with the correct iteration number listed
> in its
> guts.
> 
> ? The next question is whether you or someone at your
> institution
> is capable of modifying lmer.R appropriately and rebuilding
> the
> package ...
> 
> 
> 
> ------------------------------
> 
> Message: 2
> Date: Mon, 29 Mar 2010 17:45:08 +0100
> From: Tim Carnus <Tim.Carnus at ucd.ie>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] poisson GLMER with identity link
> Message-ID: <1269881108.3596.24.camel at tim-laptop>
> Content-Type: text/plain; charset=UTF-8
> 
> Dear list,
> 
> I am trying to fit a number of GLMERs to count data with an
> additive
> model (in the predictors) that requires the use of the
> identity link
> function. For about half of my response variables this
> causes no
> problems. However in a number of cases the model fitting
> runs into
> problems with regards estimation of negative mean (for e.g.
> the error
> message in mer_finalize: mu[i] must be positive: mu =
> 1.76267e-312, i =
> 13075456). As far as I understand this is well known and
> documented, and
> guarding against that possibility is necessary, and built
> in to say the
> glm() function.
> 
> My question then is, how can I do this with lmer? (ie how
> can I specify
> the constraints necessary to fit these types of models, if
> at all
> possible)
> 
> Best regards,
> 
> Tim Carnus
> 
> 
> 
> ------------------------------
> 
> Message: 3
> Date: Mon, 29 Mar 2010 16:17:41 +0200
> From: Jana B?rger <jana.buerger at uni-rostock.de>
> To: Andrew Dolman <andydolman at gmail.com>
> Cc: "r-sig-mixed-models at r-project.org"
> ??? <r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] unbalanced data in nested lmer
> model
> Message-ID: <4BB0B685.70506 at uni-rostock.de>
> Content-Type: text/plain; charset="UTF-8"; format=flowed
> 
> Dear Andrew and other list members,
> As I described in an earlier 
> post(https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q1/003503.html)
> my data is actually hierarchical down to the level of
> fields within farms.
> 
> There is more than 500 cases on 8 farms in 6 regions.
> Would you not think that gives enough power to distinguish
> within region 
> variability vs. between regions?
> 
> Moreover I don't understand your argument that fitting
> random efects 
> with less than 5 levels was dodgy, as often examples in the
> books have 3 
> samples from one beach, or 3 laboratory workers within one
> laboratory. 
> These are less than 5 levels, are they not?
> 
> Regards, Jana
> 
> Andrew Dolman schrieb:
> > Dear Jana,
> > 
> >? >An anova(lm1, lm2)?
> lm1<-lmer(y~x1+x2+...+(1|region)+(1|region:farm)); 
> > lm2<-lmer(y+x1+x2+...+(1|farm)) said models did not
> differ significantly 
> > and AIC was about the same. So I know there is no
> additional explanatory 
> > power including the region term.
> > 
> >? >Yet, I would like to keep the region effect
> in the model to separate 
> > and compare the effect size of region vs. farm. Is it
> valid to do so 
> > even if? some of the regions are only represented
> by one farm?
> > 
> > I don't think you have the data to ask questions about
> differences 
> > between regions as distinct from differences between
> farms. Look at it 
> > this way. If you were just doing a normal comparison
> between regions and 
> > you only looked at 1 or 2 farms per region, would you
> have the 
> > statistical power to say that differences were due to
> region rather than 
> > farm? Answer = No.
> > 
> > Similarly, are the differences between the farms
> because they are in 
> > different regions or just normal variation between
> farms? Well you only 
> > have 2 farms per region so it's hard to tell. Maybe
> you just have enough 
> > data if pairs of farms within regions are always very
> similar and 
> > differences between regions large.
> > 
> > Also. Fitting random effects with fewer than 5 levels
> is dodgy, and you 
> > only have 2 levels of farm per region, sometimes 1.
> > 
> > Perhaps you could look at it this way.
> > 
> > compare
> > 
> > m1 <- lmer (y~(1|region))
> > m2 <- lmer (y~(1|farm))
> > 
> > If m2 is better then there is variation between farms
> within regions, if 
> > there's no difference then region accounts for most of
> the variation. 
> > BUT you've not got much power to detect farm effects
> within regions, so 
> > a null result is not strong evidence for the absence
> of farm variation 
> > within regions.
> > 
> > 
> > Andy.
> >? 
> > 
> > 
> > andydolman at gmail.com
> <mailto:andydolman at gmail.com>
> > 
> > 
> > 
> 
> -- 
> Jana B?rger
> 
> Universit?t Rostock
> Agrar-? und Umweltwissenschaftliche Fakult?t
> FG Phytomedizin
> Satower Stra?e 48
> 18059 Rostock
> 
> Tel. 0381-498 31 71
> Fax.0381-498 31 62
> 
> 
> 
> ------------------------------
> 
> Message: 4
> Date: Mon, 29 Mar 2010 19:45:15 +0200
> From: Eric Castet <Eric.Castet at incm.cnrs-mrs.fr>
> To: Douglas Bates <bates at stat.wisc.edu>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Correlation of -1: is it a
> problem?
> Message-ID: <4BB0E72B.2070404 at incm.cnrs-mrs.fr>
> Content-Type: text/plain
> 
> Dear Doug,
> 
> Thanks for your reply.
> 
> I've done as you suggested (your point b/), i.e. I've fit
> another model 
> that considers 'couleurs' within 'nom'
> However, after running anova() (likelihood ratio test), I
> find that I 
> should keep the initial model that contains the -1
> correlation:
> 
>  > anova (jb.lmer1, jb.lmer2)
> Data: jb
> Models:
> jb.lmer2: lRT ~ couleurs + (1 | nom) + (1 | nom:couleurs)
> jb.lmer1: lRT ~ couleurs + (1 + couleurs | nom)
> ? ? ? ? ?
> Df???AIC???BIC?
> logLik? Chisq Chi Df Pr(>Chisq)
> jb.lmer2? 5 17260 17295 -8625.2
> jb.lmer1? 6 17251 17293 -8619.4 11.584? ?
> ? 1? 0.0006654 ***
> 
> So, the question is now:
> 
> a/ How can I justify to refuse the initial model that
> contains the -1 
> correlation?
> 
> b/ And a parallel question is: what is wrong with the -1
> correlation? Is 
> it because it is exactly -1 ? Would it still be a problem
> if it were -0.99 ?
> 
> c/ Ultimately, how can I report what appears to me as an
> important 
> result: namely the high correlation between the intercept
> and the 
> 'couleurs' effect for each subject?
> 
> 
> Thanks,
> Eric
> 
> 
> 
> 
> 
> >> a/ is it really a statistical (or numerical)
> problem to have a -1
> >> correlation in the model that I should keep?
> >>? ? ? 
> >
> > Yes, it is.? The fitted model is has a singular
> variance-covariance
> > matrix for the random effects and that is not
> good.? In fact, it is no
> > longer a linear mixed model.
> >
> >? ? 
> >> b/ is it possible to remove the correlation
> between Intercept and
> >> Couleurs, as I would do if Couleurs were not a
> categorical factor?
> >>? ? ? 
> >
> > I would fit another model of
> >
> > IRT ~ couleurs + (1|nom:couleurs) + (1|nom)
> >
> > and see how that works.? This model is, in some
> sense, intermediate to
> > the models that you have fit above.
> >
> >? ? 
> >> Thanks in advance,
> >>
> >> Eric Castet
> >>
> >>
> >>
> >>
> >> --
> >>
> >> Eric Castet
> >>
> >> Institut de Neurosciences Cognitives de la
> M?diterran?e -- INCM CNRS
> >>
> >> 31 chemin Joseph Aiguier
> >>
> >> 13402 Marseille cedex 20 (France)
> >>
> >> tel : (+33)(0)4-91-16-43-34
> >>
> >> fax : (+33) (0)4-91-16-44-98
> >>
> >> UMR 6193 du CNRS
> >>
> >> Universit? Aix-Marseille II
> >>
> >> http://www.incm.cnrs-mrs.fr/equipedyva.php
> >>
> >> http://www.incm.cnrs-mrs.fr/pperso/ecastet.php
> >>
> >>
> >>
> >>
> >>? ? ?
> ???[[alternative HTML version deleted]]
> >>
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org?
> mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >>
> >>? ? ? 
> >
> >? ? 
> 
> -- 
> 
> Eric Castet
> 
> Institut de Neurosciences Cognitives de la M?diterran?e
> -- INCM CNRS
> 
> 31 chemin Joseph Aiguier
> 
> 13402 Marseille cedex 20 (France)
> 
> tel : (+33)(0)4-91-16-43-34
> 
> fax : (+33) (0)4-91-16-44-98
> 
> UMR 6193 du CNRS
> 
> Universit? Aix-Marseille II
> 
> http://www.incm.cnrs-mrs.fr/equipedyva.php
> 
> http://www.incm.cnrs-mrs.fr/pperso/ecastet.php
> 
> 
> ??? [[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------
> 
> Message: 5
> Date: Mon, 29 Mar 2010 13:55:01 -0400
> From: "Luca Borger" <lborger at uoguelph.ca>
> To: Jana B?rger <jana.buerger at uni-rostock.de>,???
> "Andrew Dolman"
> ??? <andydolman at gmail.com>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] unbalanced data in nested lmer
> model
> Message-ID:
> <D63BEA7FF21244B88504AA33F4E7C14D at lborger>
> Content-Type: text/plain; format=flowed; charset="utf-8";
> ??? reply-type=response
> 
> Hello,
> 
> as Andrew and others already explained:
> 
> > There is more than 500 cases
> 
> Fine, this might give you reasonable estimates about how
> your y is affected 
> by your fixed effects covariates (x1,x2,...)
> 
> > (...) on 8 farms in 6 regions.
> #and, from your previos post
> >For 2 of 8 regions there is only 1 farm, the other
> regions have 2 farms.
> 
> thus no way to estimate a difference between region or farm
> effects for 2 
> regions, and very, very limited power for the other 6 (just
> 2 farms per 
> region). To make things worse your data are also quite
> unbalanced:
> 
> >unbalance of case numbers in cells? Or would it be no
> problem if cell sizes 
> >vary between 0 and 53?
> 
> which I think means for some farms you got only one record?
> Anyway, to 
> recap, probably OK data for understanding y~x1+x2 etc.,
> insufficient data 
> otherwise (should invest in getting data for more farms
> within regions, not 
> more data for the farms you have already sampled).
> 
> > Moreover I don't understand your argument that fitting
> random efects with 
> > less than 5 levels was dodgy, as often examples in the
> books have 3 
> > samples from one beach, or 3 laboratory workers within
> one laboratory. 
> > These are less than 5 levels, are they not?
> 
> These are usually toy datasets to exemplify how the
> approach works, I do not 
> think they make a claim that the resulting variance
> estimates are very 
> reliable (think in the Zuur etal. mixed effects book you
> can find more 
> realistic examples, if I remember well). Plus, "level"
> refers to the number 
> of beaches or the number of labs etc. and the resulting
> variance estimates - 
> if less than say 5 it appears that you might be better off
> fitting it as a 
> fixed effect and not trying to decompose the variance into
> between labs and 
> within labs etc. Anyway, just my 2 cents and hope I
> explained this 
> correctly...
> 
> 
> See also the wiki page set up by Ben Bolker:
> http://glmm.wikidot.com/faq
> 
> e.g. you might be interested in this entry therein:
> 
> Zero or very small random effects variance estimates;
> (...)
> Very small variance estimates, or very large correlation
> estimates, often 
> indicates unidentifiability/lack of data (either due to
> exact 
> identifiability [e.g. designs that are not replicated at an
> important level] 
> or weak identifiable (designs that would be workable with
> more data of the 
> same type)
> 
> 
> HTH
> 
> 
> Cheers,
> 
> Luca
> 
> 
> 
> 
> 
> 
> ----- Original Message ----- 
> From: "Jana B?rger" <jana.buerger at uni-rostock.de>
> To: "Andrew Dolman" <andydolman at gmail.com>
> Cc: <r-sig-mixed-models at r-project.org>
> Sent: Monday, March 29, 2010 10:17 AM
> Subject: Re: [R-sig-ME] unbalanced data in nested lmer
> model
> 
> 
> > Dear Andrew and other list members,
> > As I described in an earlier 
> > post(https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q1/003503.html)
> > my data is actually hierarchical down to the level of
> fields within farms.
> >
> > There is more than 500 cases on 8 farms in 6 regions.
> > Would you not think that gives enough power to
> distinguish within region 
> > variability vs. between regions?
> >
> > Moreover I don't understand your argument that fitting
> random efects with 
> > less than 5 levels was dodgy, as often examples in the
> books have 3 
> > samples from one beach, or 3 laboratory workers within
> one laboratory. 
> > These are less than 5 levels, are they not?
> >
> > Regards, Jana
> >
> > Andrew Dolman schrieb:
> >> Dear Jana,
> >>
> >>? >An anova(lm1, lm2)?
> lm1<-lmer(y~x1+x2+...+(1|region)+(1|region:farm)); 
> >> lm2<-lmer(y+x1+x2+...+(1|farm)) said models did
> not differ significantly 
> >> and AIC was about the same. So I know there is no
> additional explanatory 
> >> power including the region term.
> >>
> >>? >Yet, I would like to keep the region
> effect in the model to separate 
> >> and compare the effect size of region vs. farm. Is
> it valid to do so even 
> >> if? some of the regions are only represented
> by one farm?
> >>
> >> I don't think you have the data to ask questions
> about differences 
> >> between regions as distinct from differences
> between farms. Look at it 
> >> this way. If you were just doing a normal
> comparison between regions and 
> >> you only looked at 1 or 2 farms per region, would
> you have the 
> >> statistical power to say that differences were due
> to region rather than 
> >> farm? Answer = No.
> >>
> >> Similarly, are the differences between the farms
> because they are in 
> >> different regions or just normal variation between
> farms? Well you only 
> >> have 2 farms per region so it's hard to tell.
> Maybe you just have enough 
> >> data if pairs of farms within regions are always
> very similar and 
> >> differences between regions large.
> >>
> >> Also. Fitting random effects with fewer than 5
> levels is dodgy, and you 
> >> only have 2 levels of farm per region, sometimes
> 1.
> >>
> >> Perhaps you could look at it this way.
> >>
> >> compare
> >>
> >> m1 <- lmer (y~(1|region))
> >> m2 <- lmer (y~(1|farm))
> >>
> >> If m2 is better then there is variation between
> farms within regions, if 
> >> there's no difference then region accounts for
> most of the variation. BUT 
> >> you've not got much power to detect farm effects
> within regions, so a 
> >> null result is not strong evidence for the absence
> of farm variation 
> >> within regions.
> >>
> >>
> >> Andy.
> >>? andydolman at gmail.com
> <mailto:andydolman at gmail.com>
> >>
> >>
> >>
> >
> > -- 
> > Jana B?rger
> >
> > Universit?t Rostock
> > Agrar-? und Umweltwissenschaftliche Fakult?t
> > FG Phytomedizin
> > Satower Stra?e 48
> > 18059 Rostock
> >
> > Tel. 0381-498 31 71
> > Fax.0381-498 31 62
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org
> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
> 
> 
> ------------------------------
> 
> Message: 6
> Date: Mon, 29 Mar 2010 16:25:12 -0400
> From: Ben Bolker <bolker at ufl.edu>
> To: Luca Borger <lborger at uoguelph.ca>
> Cc: Andrew Dolman <andydolman at gmail.com>,
> ??? "r-sig-mixed-models at r-project.org"
> <r-sig-mixed-models at r-project.org>,
> ??? Jana B?rger <jana.buerger at uni-rostock.de>
> Subject: Re: [R-sig-ME] unbalanced data in nested lmer
> model
> Message-ID: <4BB10CA8.6030803 at ufl.edu>
> Content-Type: text/plain; charset=UTF-8
> 
> Luca Borger wrote:
> 
> [Jana B?rger:]
> >> Moreover I don't understand your argument that
> fitting random efects with 
> >> less than 5 levels was dodgy, as often examples in
> the books have 3 
> >> samples from one beach, or 3 laboratory workers
> within one laboratory. 
> >> These are less than 5 levels, are they not?
> > 
> > These are usually toy datasets to exemplify how the
> approach works, I do not 
> > think they make a claim that the resulting variance
> estimates are very 
> > reliable (think in the Zuur etal. mixed effects book
> you can find more 
> > realistic examples, if I remember well). Plus, "level"
> refers to the number 
> > of beaches or the number of labs etc. and the
> resulting variance estimates - 
> > if less than say 5 it appears that you might be better
> off fitting it as a 
> > fixed effect and not trying to decompose the variance
> into between labs and 
> > within labs etc. Anyway, just my 2 cents and hope I
> explained this 
> > correctly... 
> > 
> > See also the wiki page set up by Ben Bolker:
> > http://glmm.wikidot.com/faq
> > 
> > e.g. you might be interested in this entry therein:
> > 
> > Zero or very small random effects variance estimates;
> > (...)
> > Very small variance estimates, or very large
> correlation estimates, often 
> > indicates unidentifiability/lack of data (either due
> to exact 
> > identifiability [e.g. designs that are not replicated
> at an important level] 
> > or weak identifiable (designs that would be workable
> with more data of the 
> > same type)
> 
> ? I just added this to the FAQ:
> 
> Should I treat factor xxx as fixed or random?
> 
> This is in general a far more difficult question than it
> seems on the
> surface. There are many competing philosophies and
> definitions (see
> Gelman 2xxx). One point of particular relevance to 'modern'
> mixed model
> estimation (rather than 'classical' method-of-moments
> estimation) is
> that, for practical purposes, there must be a reasonable
> number of
> random-effects levels (e.g. blocks) ? more than 5 or 6 at a
> minimum.
> 
> ? ? e.g., from Crawley (2002) p. 670: "Are there
> enough levels of the
> factor in the data on which to base an estimate of the
> variance of the
> population of effects? No, means [you should probably treat
> the variable
> as] fixed effects."
> 
> Some researchers (who treat fixed vs random as a
> philosophical rather
> than a pragmatic decision) object to this approach.
> 
> Treating factors with small numbers of levels as random
> will in the best
> case lead to very small estimates of random effects; in the
> worst case
> it will lead to various numerical difficulties such as lack
> of
> convergence, zero variance estimates, etc.. In the
> classical
> method-of-moments approach these problems do not arise
> (because the sums
> of squares are always well defined as long as there are at
> least two
> units), but the underlying problems of lack of power are
> there nevertheless.
> 
> ???(Contributions welcome!)
> 
> -- 
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu /
> people.biology.ufl.edu/bolker
> GPG key:
> people.biology.ufl.edu/bolker/benbolker-publickey.asc
> 
> 
> 
> ------------------------------
> 
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> End of R-sig-mixed-models Digest, Vol 39, Issue 47
> **************************************************
> 


    


From rroa at azti.es  Tue Mar 30 08:42:40 2010
From: rroa at azti.es (=?iso-8859-1?Q?Rub=E9n_Roa?=)
Date: Tue, 30 Mar 2010 08:42:40 +0200
Subject: [R-sig-ME] Correlation of -1: is it a problem?
References: <4BACFA5B.5050707@incm.cnrs-mrs.fr><40e66e0b1003261206u2ce669c9rc0d978e67701f73c@mail.gmail.com>
	<4BB0E72B.2070404@incm.cnrs-mrs.fr>
Message-ID: <5CD78996B8F8844D963C875D3159B94A01262E8E@DSRCORREO.azti.local>

-----Mensaje original-----
De: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] En nombre de Eric Castet
Enviado el: lunes, 29 de marzo de 2010 19:45
Para: Douglas Bates
CC: r-sig-mixed-models at r-project.org
Asunto: Re: [R-sig-ME] Correlation of -1: is it a problem?

Dear Doug,

Thanks for your reply.

I've done as you suggested (your point b/), i.e. I've fit another model that considers 'couleurs' within 'nom'
However, after running anova() (likelihood ratio test), I find that I should keep the initial model that contains the -1 correlation:

 > anova (jb.lmer1, jb.lmer2)
Data: jb
Models:
jb.lmer2: lRT ~ couleurs + (1 | nom) + (1 | nom:couleurs)
jb.lmer1: lRT ~ couleurs + (1 + couleurs | nom)
          Df   AIC   BIC  logLik  Chisq Chi Df Pr(>Chisq)
jb.lmer2  5 17260 17295 -8625.2
jb.lmer1  6 17251 17293 -8619.4 11.584      1  0.0006654 ***

So, the question is now:

a/ How can I justify to refuse the initial model that contains the -1 correlation?

b/ And a parallel question is: what is wrong with the -1 correlation? Is it because it is exactly -1 ? Would it still be a problem if it were -0.99 ?

c/ Ultimately, how can I report what appears to me as an important
result: namely the high correlation between the intercept and the 'couleurs' effect for each subject?

--------

When I see a correlation very close to 1 or -1 between parameter estimates (mostly in nonlinear models, because that is my main area) I start to think of ways to re-parameterize the model, i.e. some change in the algebraic structure that introduces different parameters, because a nearly-perfect correlation is telling me that one of the highly correlated parameter estimates is redundant: the sample does not have any more information about one parameter than it has about the other.
Probably the perfect correlation is telling you that you don't need a statistical test to tell what you want to tell.

HTH

Rub?n


____________________________________________________________________________________ 

Dr. Rub?n Roa-Ureta
AZTI - Tecnalia / Marine Research Unit
Txatxarramendi Ugartea z/g
48395 Sukarrieta (Bizkaia)
SPAIN



From Thierry.ONKELINX at inbo.be  Tue Mar 30 10:08:58 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 30 Mar 2010 10:08:58 +0200
Subject: [R-sig-ME] interactions
In-Reply-To: <646445.12479.qm@web58902.mail.re1.yahoo.com>
References: <mailman.2195.1269894328.4248.r-sig-mixed-models@r-project.org>
	<646445.12479.qm@web58902.mail.re1.yahoo.com>
Message-ID: <2E9C414912813E4EB981326983E0A1040717005C@inboexch.inbo.be>

Dear Jason,

Are you interested in the variability of the random intercept for each day along marker? If you just want to allow a different random intercept per day and per marker, you could consider (1|marker/day) instead of (day|marker). If day has 15 levels then (day|marker) has to estimate 15 variances and 105 covariances! This is probably the reason why the model doesn't converge. (1|marker/day) requires only 2 variances to be estimated.

HTH,

Thierry


----------------------------------------------------------------------------
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens 
> Iasonas Lamprianou
> Verzonden: maandag 29 maart 2010 23:54
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: Re: [R-sig-ME] interactions
> 
> 
> Dear colleagues,
> apologies for the long question, but I really need some help. 
> It is not a case of academic laziness, I have done my 
> homework but now I need some advice.
> 
> I have 10000 students nested in 50 schools, each student 
> taking a test. The tests are randomly grouped in batches of 
> 20 scripts (around 500 batches). Then, two random markers 
> (out of a pool of 57 markers) mark each batch blindly. Each 
> marker marks around 17 random batches of 20 scripts. If the 
> two random markers disagree by more than 10% on the total 
> score for a specific student, then the test of the student is 
> being given to another marker randomly for a third blind 
> marking. So, I have students nested within schools which are 
> nested in areas. Then, scripts (the tests of the students) 
> nested into batches. Then, batches crossed with markers. 
> However, the actual marking lasted around 15 days. One batch 
> may be marked by the first marker on day 1 and then marked by 
> the second marker on the next day (or the day after etc). So 
> the batches are also crossed by days. 
> 
> My Research question is: are there markers who are 
> differentially severe or lenient on different days? 
> 
> I use this model:
> 
> lmer(score ~ 
> 1+day+gender+school+(1+day|marker)+(1|candidate)+(1|batch), 
> mg2007_sub)
> 
> I assume that this model is appropriate, because it models 
> candidates as random effects (each candidate has an ability 
> estimate based on the scores he/she received from the two or 
> the three markers if his/her script was remarked by a third 
> marker). Also, every batch is modelled as a random effect. 
> Every marker is modelled as a random effect but I allow 
> his/her estimate to vary by day, so I assume that this would 
> allow me to see if a marker behaves in a different way on 
> different days. So this should answer my research question.
> 
> Question 1: does this model make sense statistically (as i 
> formulate it in lme4?)
> 
> So far so good, but lme4 will run for 48 hours and then fail 
> because it reached maximum iterations. I assume that even if 
> I allow for more iterations, it will go on for ever.
> 
> Question 2: Why is it so slow? Why it does not converge?
> 
> Then, I decided to simplify the problem. Instead of modelling 
> day as a factor, I use 'd' which is the cardinal number of 
> day e.g. 1, 2, 3, days that passed since we started marking. 
> I assume that this is an interval scale. If a marker becomes 
> (linearly) more lenient, he/she would 'like' this model. So I run
> 
> lmer(score ~ 
> 1+day+gender+dvhool+(1+d|marker)+(1|candidate)+(1|batch), mg2007_sub)
> 
> please notice that (1+day|marker) where day is a factor with 
> 15 levels, becomes (1+d|marker) which is numeric variable
> 
> and this gives
> 
> Error terms:
>  Groups    Name        Std.Dev. Corr 
>  candidate (Intercept) 16.85          
>  batch     (Intercept)  3.49          
>  marker    (Intercept)  4.68         
>            d            0.38    -0.77 
>  Residual               4.83          
> ---
> number of obs: 18001, groups: candidate, 9402; batch, 470; 
> marker, 59 AIC = 138232, DIC = 138388.9 deviance = 138230.4 
> 
> 
> Question 3: How do I know that the variance of 'd' is 
> statistically significant? MlWin gives some error estimates.
> 
> Question 4: The correlation of -0.77 is a problem?
> 
> I hope somebody can help me, this has taken me three days up to now...
> 
> Thank you 
> 
> jason
> 
> 
> 
> Dr. Iasonas Lamprianou
> 
> 
> Assistant Professor (Educational Research and Evaluation)
> Department of Education Sciences European University-Cyprus
> P.O. Box 22006
> 1516 Nicosia
> Cyprus
> Tel.: +357-22-713178
> Fax: +357-22-590539
> 
> 
> Honorary Research Fellow
> Department of Education
> The University of Manchester
> Oxford Road, Manchester M13 9PL, UK
> Tel. 0044  161 275 3485
> iasonas.lamprianou at manchester.ac.uk
> 
> 
> --- On Mon, 29/3/10, r-sig-mixed-models-request at r-project.org
> <r-sig-mixed-models-request at r-project.org> wrote:
> 
> > From: r-sig-mixed-models-request at r-project.org 
> <r-sig-mixed-models-request at r-project.org>
> > Subject: R-sig-mixed-models Digest, Vol 39, Issue 47
> > To: r-sig-mixed-models at r-project.org
> > Date: Monday, 29 March, 2010, 21:25
> > Send R-sig-mixed-models mailing list
> > submissions to
> > ??? r-sig-mixed-models at r-project.org
> > 
> > To subscribe or unsubscribe via the World Wide Web, visit
> > ??? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > or, via email, send a message with subject or body 'help'
> > to
> > ??? r-sig-mixed-models-request at r-project.org
> > 
> > You can reach the person managing the list at
> > ??? r-sig-mixed-models-owner at r-project.org
> > 
> > When replying, please edit your Subject line so it is more
> > specific
> > than "Re: Contents of R-sig-mixed-models digest..."
> > 
> > 
> > Today's Topics:
> > 
> > ???1. Re: The issue of increasing maximum
> > number of iterations
> > ? ? ? (Ben Bolker)
> > ???2. poisson GLMER with identity link (Tim
> > Carnus)
> > ???3. Re: unbalanced data in nested lmer
> > model (Jana B?rger)
> > ???4. Re: Correlation of -1: is it a
> > problem? (Eric Castet)
> > ???5. Re: unbalanced data in nested lmer
> > model (Luca Borger)
> > ???6. Re: unbalanced data in nested lmer
> > model (Ben Bolker)
> > 
> > 
> > 
> ----------------------------------------------------------------------
> > 
> > Message: 1
> > Date: Mon, 29 Mar 2010 15:50:30 +0000 (UTC)
> > From: Ben Bolker <bolker at ufl.edu>
> > To: r-sig-mixed-models at r-project.org
> > Subject: Re: [R-sig-ME] The issue of increasing maximum
> > number of
> > ??? iterations
> > Message-ID: <loom.20100329T171254-536 at post.gmane.org>
> > Content-Type: text/plain; charset=us-ascii
> > 
> > Martin Stjernman <Martin.Stjernman at ...> writes:
> > 
> > > 
> > > Dear listmembers!
> > > 
> > > I have also had trouble with the maxIter specification
> > in (g)lmer. 
> > > I've tried to increase the number of
> > > iterations (to 1000) via the control statement in lmer
> > 
> > > but it still stops at 300 (the default).
> > > We are now a number of users having problem with this
> > but 
> > > I haven't seen any solution to the problem on this
> > > list and I would really appreciate any hint on what I
> > am doing wrong.
> > > I am running on a Vista 64-bit machine and my model
> > specification and
> > >? session info follows below. Please let
> > > me know if any other information needs to be
> > attached.
> > 
> > ? Looking at the source code in lmer.R, this seems
> > like
> > a moderately obvious hole: on or about line 714 (I may be
> > off by a couple of lines) we have
> > 
> > ? ? if (missing(verbose)) verbose <-
> > cv$msVerbose
> > ### FIXME: issue a warning if the model argument is
> > FALSE.? It is ignored. 
> > 
> >  adding the lines
> > 
> > ? ? FL$dims["mxit"] <- cv$maxIter
> > ? ? FL$dims["mxfn"] <- cv$maxFN
> > 
> > ? appears to work: running
> > 
> >  (gm1 <- glmer(cbind(incidence, size - incidence) ~
> > period + 
> > ???(1 | herd), family=binomial, data=cbpp,
> > control=list(maxIter=1000)))
> > 
> > produces a model with the correct iteration number listed
> > in its
> > guts.
> > 
> > ? The next question is whether you or someone at your
> > institution
> > is capable of modifying lmer.R appropriately and rebuilding
> > the
> > package ...
> > 
> > 
> > 
> > ------------------------------
> > 
> > Message: 2
> > Date: Mon, 29 Mar 2010 17:45:08 +0100
> > From: Tim Carnus <Tim.Carnus at ucd.ie>
> > To: r-sig-mixed-models at r-project.org
> > Subject: [R-sig-ME] poisson GLMER with identity link
> > Message-ID: <1269881108.3596.24.camel at tim-laptop>
> > Content-Type: text/plain; charset=UTF-8
> > 
> > Dear list,
> > 
> > I am trying to fit a number of GLMERs to count data with an
> > additive
> > model (in the predictors) that requires the use of the
> > identity link
> > function. For about half of my response variables this
> > causes no
> > problems. However in a number of cases the model fitting
> > runs into
> > problems with regards estimation of negative mean (for e.g.
> > the error
> > message in mer_finalize: mu[i] must be positive: mu =
> > 1.76267e-312, i =
> > 13075456). As far as I understand this is well known and
> > documented, and
> > guarding against that possibility is necessary, and built
> > in to say the
> > glm() function.
> > 
> > My question then is, how can I do this with lmer? (ie how
> > can I specify
> > the constraints necessary to fit these types of models, if
> > at all
> > possible)
> > 
> > Best regards,
> > 
> > Tim Carnus
> > 
> > 
> > 
> > ------------------------------
> > 
> > Message: 3
> > Date: Mon, 29 Mar 2010 16:17:41 +0200
> > From: Jana B?rger <jana.buerger at uni-rostock.de>
> > To: Andrew Dolman <andydolman at gmail.com>
> > Cc: "r-sig-mixed-models at r-project.org"
> > ??? <r-sig-mixed-models at r-project.org>
> > Subject: Re: [R-sig-ME] unbalanced data in nested lmer
> > model
> > Message-ID: <4BB0B685.70506 at uni-rostock.de>
> > Content-Type: text/plain; charset="UTF-8"; format=flowed
> > 
> > Dear Andrew and other list members,
> > As I described in an earlier 
> > 
> post(https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q1/
> 003503.html)
> > my data is actually hierarchical down to the level of
> > fields within farms.
> > 
> > There is more than 500 cases on 8 farms in 6 regions.
> > Would you not think that gives enough power to distinguish
> > within region 
> > variability vs. between regions?
> > 
> > Moreover I don't understand your argument that fitting
> > random efects 
> > with less than 5 levels was dodgy, as often examples in the
> > books have 3 
> > samples from one beach, or 3 laboratory workers within one
> > laboratory. 
> > These are less than 5 levels, are they not?
> > 
> > Regards, Jana
> > 
> > Andrew Dolman schrieb:
> > > Dear Jana,
> > > 
> > >? >An anova(lm1, lm2)?
> > lm1<-lmer(y~x1+x2+...+(1|region)+(1|region:farm)); 
> > > lm2<-lmer(y+x1+x2+...+(1|farm)) said models did not
> > differ significantly 
> > > and AIC was about the same. So I know there is no
> > additional explanatory 
> > > power including the region term.
> > > 
> > >? >Yet, I would like to keep the region effect
> > in the model to separate 
> > > and compare the effect size of region vs. farm. Is it
> > valid to do so 
> > > even if? some of the regions are only represented
> > by one farm?
> > > 
> > > I don't think you have the data to ask questions about
> > differences 
> > > between regions as distinct from differences between
> > farms. Look at it 
> > > this way. If you were just doing a normal comparison
> > between regions and 
> > > you only looked at 1 or 2 farms per region, would you
> > have the 
> > > statistical power to say that differences were due to
> > region rather than 
> > > farm? Answer = No.
> > > 
> > > Similarly, are the differences between the farms
> > because they are in 
> > > different regions or just normal variation between
> > farms? Well you only 
> > > have 2 farms per region so it's hard to tell. Maybe
> > you just have enough 
> > > data if pairs of farms within regions are always very
> > similar and 
> > > differences between regions large.
> > > 
> > > Also. Fitting random effects with fewer than 5 levels
> > is dodgy, and you 
> > > only have 2 levels of farm per region, sometimes 1.
> > > 
> > > Perhaps you could look at it this way.
> > > 
> > > compare
> > > 
> > > m1 <- lmer (y~(1|region))
> > > m2 <- lmer (y~(1|farm))
> > > 
> > > If m2 is better then there is variation between farms
> > within regions, if 
> > > there's no difference then region accounts for most of
> > the variation. 
> > > BUT you've not got much power to detect farm effects
> > within regions, so 
> > > a null result is not strong evidence for the absence
> > of farm variation 
> > > within regions.
> > > 
> > > 
> > > Andy.
> > >? 
> > > 
> > > 
> > > andydolman at gmail.com
> > <mailto:andydolman at gmail.com>
> > > 
> > > 
> > > 
> > 
> > -- 
> > Jana B?rger
> > 
> > Universit?t Rostock
> > Agrar-? und Umweltwissenschaftliche Fakult?t
> > FG Phytomedizin
> > Satower Stra?e 48
> > 18059 Rostock
> > 
> > Tel. 0381-498 31 71
> > Fax.0381-498 31 62
> > 
> > 
> > 
> > ------------------------------
> > 
> > Message: 4
> > Date: Mon, 29 Mar 2010 19:45:15 +0200
> > From: Eric Castet <Eric.Castet at incm.cnrs-mrs.fr>
> > To: Douglas Bates <bates at stat.wisc.edu>
> > Cc: r-sig-mixed-models at r-project.org
> > Subject: Re: [R-sig-ME] Correlation of -1: is it a
> > problem?
> > Message-ID: <4BB0E72B.2070404 at incm.cnrs-mrs.fr>
> > Content-Type: text/plain
> > 
> > Dear Doug,
> > 
> > Thanks for your reply.
> > 
> > I've done as you suggested (your point b/), i.e. I've fit
> > another model 
> > that considers 'couleurs' within 'nom'
> > However, after running anova() (likelihood ratio test), I
> > find that I 
> > should keep the initial model that contains the -1
> > correlation:
> > 
> >  > anova (jb.lmer1, jb.lmer2)
> > Data: jb
> > Models:
> > jb.lmer2: lRT ~ couleurs + (1 | nom) + (1 | nom:couleurs)
> > jb.lmer1: lRT ~ couleurs + (1 + couleurs | nom)
> > ? ? ? ? ?
> > Df???AIC???BIC?
> > logLik? Chisq Chi Df Pr(>Chisq)
> > jb.lmer2? 5 17260 17295 -8625.2
> > jb.lmer1? 6 17251 17293 -8619.4 11.584? ?
> > ? 1? 0.0006654 ***
> > 
> > So, the question is now:
> > 
> > a/ How can I justify to refuse the initial model that
> > contains the -1 
> > correlation?
> > 
> > b/ And a parallel question is: what is wrong with the -1
> > correlation? Is 
> > it because it is exactly -1 ? Would it still be a problem
> > if it were -0.99 ?
> > 
> > c/ Ultimately, how can I report what appears to me as an
> > important 
> > result: namely the high correlation between the intercept
> > and the 
> > 'couleurs' effect for each subject?
> > 
> > 
> > Thanks,
> > Eric
> > 
> > 
> > 
> > 
> > 
> > >> a/ is it really a statistical (or numerical)
> > problem to have a -1
> > >> correlation in the model that I should keep?
> > >>? ? ? 
> > >
> > > Yes, it is.? The fitted model is has a singular
> > variance-covariance
> > > matrix for the random effects and that is not
> > good.? In fact, it is no
> > > longer a linear mixed model.
> > >
> > >? ? 
> > >> b/ is it possible to remove the correlation
> > between Intercept and
> > >> Couleurs, as I would do if Couleurs were not a
> > categorical factor?
> > >>? ? ? 
> > >
> > > I would fit another model of
> > >
> > > IRT ~ couleurs + (1|nom:couleurs) + (1|nom)
> > >
> > > and see how that works.? This model is, in some
> > sense, intermediate to
> > > the models that you have fit above.
> > >
> > >? ? 
> > >> Thanks in advance,
> > >>
> > >> Eric Castet
> > >>
> > >>
> > >>
> > >>
> > >> --
> > >>
> > >> Eric Castet
> > >>
> > >> Institut de Neurosciences Cognitives de la
> > M?diterran?e -- INCM CNRS
> > >>
> > >> 31 chemin Joseph Aiguier
> > >>
> > >> 13402 Marseille cedex 20 (France)
> > >>
> > >> tel : (+33)(0)4-91-16-43-34
> > >>
> > >> fax : (+33) (0)4-91-16-44-98
> > >>
> > >> UMR 6193 du CNRS
> > >>
> > >> Universit? Aix-Marseille II
> > >>
> > >> http://www.incm.cnrs-mrs.fr/equipedyva.php
> > >>
> > >> http://www.incm.cnrs-mrs.fr/pperso/ecastet.php
> > >>
> > >>
> > >>
> > >>
> > >>? ? ?
> > ???[[alternative HTML version deleted]]
> > >>
> > >>
> > >> _______________________________________________
> > >> R-sig-mixed-models at r-project.org?
> > mailing list
> > >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >>
> > >>
> > >>? ? ? 
> > >
> > >? ? 
> > 
> > -- 
> > 
> > Eric Castet
> > 
> > Institut de Neurosciences Cognitives de la M?diterran?e
> > -- INCM CNRS
> > 
> > 31 chemin Joseph Aiguier
> > 
> > 13402 Marseille cedex 20 (France)
> > 
> > tel : (+33)(0)4-91-16-43-34
> > 
> > fax : (+33) (0)4-91-16-44-98
> > 
> > UMR 6193 du CNRS
> > 
> > Universit? Aix-Marseille II
> > 
> > http://www.incm.cnrs-mrs.fr/equipedyva.php
> > 
> > http://www.incm.cnrs-mrs.fr/pperso/ecastet.php
> > 
> > 
> > ??? [[alternative HTML version deleted]]
> > 
> > 
> > 
> > ------------------------------
> > 
> > Message: 5
> > Date: Mon, 29 Mar 2010 13:55:01 -0400
> > From: "Luca Borger" <lborger at uoguelph.ca>
> > To: Jana B?rger <jana.buerger at uni-rostock.de>,???
> > "Andrew Dolman"
> > ??? <andydolman at gmail.com>
> > Cc: r-sig-mixed-models at r-project.org
> > Subject: Re: [R-sig-ME] unbalanced data in nested lmer
> > model
> > Message-ID:
> > <D63BEA7FF21244B88504AA33F4E7C14D at lborger>
> > Content-Type: text/plain; format=flowed; charset="utf-8";
> > ??? reply-type=response
> > 
> > Hello,
> > 
> > as Andrew and others already explained:
> > 
> > > There is more than 500 cases
> > 
> > Fine, this might give you reasonable estimates about how
> > your y is affected 
> > by your fixed effects covariates (x1,x2,...)
> > 
> > > (...) on 8 farms in 6 regions.
> > #and, from your previos post
> > >For 2 of 8 regions there is only 1 farm, the other
> > regions have 2 farms.
> > 
> > thus no way to estimate a difference between region or farm
> > effects for 2 
> > regions, and very, very limited power for the other 6 (just
> > 2 farms per 
> > region). To make things worse your data are also quite
> > unbalanced:
> > 
> > >unbalance of case numbers in cells? Or would it be no
> > problem if cell sizes 
> > >vary between 0 and 53?
> > 
> > which I think means for some farms you got only one record?
> > Anyway, to 
> > recap, probably OK data for understanding y~x1+x2 etc.,
> > insufficient data 
> > otherwise (should invest in getting data for more farms
> > within regions, not 
> > more data for the farms you have already sampled).
> > 
> > > Moreover I don't understand your argument that fitting
> > random efects with 
> > > less than 5 levels was dodgy, as often examples in the
> > books have 3 
> > > samples from one beach, or 3 laboratory workers within
> > one laboratory. 
> > > These are less than 5 levels, are they not?
> > 
> > These are usually toy datasets to exemplify how the
> > approach works, I do not 
> > think they make a claim that the resulting variance
> > estimates are very 
> > reliable (think in the Zuur etal. mixed effects book you
> > can find more 
> > realistic examples, if I remember well). Plus, "level"
> > refers to the number 
> > of beaches or the number of labs etc. and the resulting
> > variance estimates - 
> > if less than say 5 it appears that you might be better off
> > fitting it as a 
> > fixed effect and not trying to decompose the variance into
> > between labs and 
> > within labs etc. Anyway, just my 2 cents and hope I
> > explained this 
> > correctly...
> > 
> > 
> > See also the wiki page set up by Ben Bolker:
> > http://glmm.wikidot.com/faq
> > 
> > e.g. you might be interested in this entry therein:
> > 
> > Zero or very small random effects variance estimates;
> > (...)
> > Very small variance estimates, or very large correlation
> > estimates, often 
> > indicates unidentifiability/lack of data (either due to
> > exact 
> > identifiability [e.g. designs that are not replicated at an
> > important level] 
> > or weak identifiable (designs that would be workable with
> > more data of the 
> > same type)
> > 
> > 
> > HTH
> > 
> > 
> > Cheers,
> > 
> > Luca
> > 
> > 
> > 
> > 
> > 
> > 
> > ----- Original Message ----- 
> > From: "Jana B?rger" <jana.buerger at uni-rostock.de>
> > To: "Andrew Dolman" <andydolman at gmail.com>
> > Cc: <r-sig-mixed-models at r-project.org>
> > Sent: Monday, March 29, 2010 10:17 AM
> > Subject: Re: [R-sig-ME] unbalanced data in nested lmer
> > model
> > 
> > 
> > > Dear Andrew and other list members,
> > > As I described in an earlier 
> > > 
> post(https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q1/
> 003503.html)
> > > my data is actually hierarchical down to the level of
> > fields within farms.
> > >
> > > There is more than 500 cases on 8 farms in 6 regions.
> > > Would you not think that gives enough power to
> > distinguish within region 
> > > variability vs. between regions?
> > >
> > > Moreover I don't understand your argument that fitting
> > random efects with 
> > > less than 5 levels was dodgy, as often examples in the
> > books have 3 
> > > samples from one beach, or 3 laboratory workers within
> > one laboratory. 
> > > These are less than 5 levels, are they not?
> > >
> > > Regards, Jana
> > >
> > > Andrew Dolman schrieb:
> > >> Dear Jana,
> > >>
> > >>? >An anova(lm1, lm2)?
> > lm1<-lmer(y~x1+x2+...+(1|region)+(1|region:farm)); 
> > >> lm2<-lmer(y+x1+x2+...+(1|farm)) said models did
> > not differ significantly 
> > >> and AIC was about the same. So I know there is no
> > additional explanatory 
> > >> power including the region term.
> > >>
> > >>? >Yet, I would like to keep the region
> > effect in the model to separate 
> > >> and compare the effect size of region vs. farm. Is
> > it valid to do so even 
> > >> if? some of the regions are only represented
> > by one farm?
> > >>
> > >> I don't think you have the data to ask questions
> > about differences 
> > >> between regions as distinct from differences
> > between farms. Look at it 
> > >> this way. If you were just doing a normal
> > comparison between regions and 
> > >> you only looked at 1 or 2 farms per region, would
> > you have the 
> > >> statistical power to say that differences were due
> > to region rather than 
> > >> farm? Answer = No.
> > >>
> > >> Similarly, are the differences between the farms
> > because they are in 
> > >> different regions or just normal variation between
> > farms? Well you only 
> > >> have 2 farms per region so it's hard to tell.
> > Maybe you just have enough 
> > >> data if pairs of farms within regions are always
> > very similar and 
> > >> differences between regions large.
> > >>
> > >> Also. Fitting random effects with fewer than 5
> > levels is dodgy, and you 
> > >> only have 2 levels of farm per region, sometimes
> > 1.
> > >>
> > >> Perhaps you could look at it this way.
> > >>
> > >> compare
> > >>
> > >> m1 <- lmer (y~(1|region))
> > >> m2 <- lmer (y~(1|farm))
> > >>
> > >> If m2 is better then there is variation between
> > farms within regions, if 
> > >> there's no difference then region accounts for
> > most of the variation. BUT 
> > >> you've not got much power to detect farm effects
> > within regions, so a 
> > >> null result is not strong evidence for the absence
> > of farm variation 
> > >> within regions.
> > >>
> > >>
> > >> Andy.
> > >>? andydolman at gmail.com
> > <mailto:andydolman at gmail.com>
> > >>
> > >>
> > >>
> > >
> > > -- 
> > > Jana B?rger
> > >
> > > Universit?t Rostock
> > > Agrar-? und Umweltwissenschaftliche Fakult?t
> > > FG Phytomedizin
> > > Satower Stra?e 48
> > > 18059 Rostock
> > >
> > > Tel. 0381-498 31 71
> > > Fax.0381-498 31 62
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org
> > mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >
> > 
> > 
> > 
> > ------------------------------
> > 
> > Message: 6
> > Date: Mon, 29 Mar 2010 16:25:12 -0400
> > From: Ben Bolker <bolker at ufl.edu>
> > To: Luca Borger <lborger at uoguelph.ca>
> > Cc: Andrew Dolman <andydolman at gmail.com>,
> > ??? "r-sig-mixed-models at r-project.org"
> > <r-sig-mixed-models at r-project.org>,
> > ??? Jana B?rger <jana.buerger at uni-rostock.de>
> > Subject: Re: [R-sig-ME] unbalanced data in nested lmer
> > model
> > Message-ID: <4BB10CA8.6030803 at ufl.edu>
> > Content-Type: text/plain; charset=UTF-8
> > 
> > Luca Borger wrote:
> > 
> > [Jana B?rger:]
> > >> Moreover I don't understand your argument that
> > fitting random efects with 
> > >> less than 5 levels was dodgy, as often examples in
> > the books have 3 
> > >> samples from one beach, or 3 laboratory workers
> > within one laboratory. 
> > >> These are less than 5 levels, are they not?
> > > 
> > > These are usually toy datasets to exemplify how the
> > approach works, I do not 
> > > think they make a claim that the resulting variance
> > estimates are very 
> > > reliable (think in the Zuur etal. mixed effects book
> > you can find more 
> > > realistic examples, if I remember well). Plus, "level"
> > refers to the number 
> > > of beaches or the number of labs etc. and the
> > resulting variance estimates - 
> > > if less than say 5 it appears that you might be better
> > off fitting it as a 
> > > fixed effect and not trying to decompose the variance
> > into between labs and 
> > > within labs etc. Anyway, just my 2 cents and hope I
> > explained this 
> > > correctly... 
> > > 
> > > See also the wiki page set up by Ben Bolker:
> > > http://glmm.wikidot.com/faq
> > > 
> > > e.g. you might be interested in this entry therein:
> > > 
> > > Zero or very small random effects variance estimates;
> > > (...)
> > > Very small variance estimates, or very large
> > correlation estimates, often 
> > > indicates unidentifiability/lack of data (either due
> > to exact 
> > > identifiability [e.g. designs that are not replicated
> > at an important level] 
> > > or weak identifiable (designs that would be workable
> > with more data of the 
> > > same type)
> > 
> > ? I just added this to the FAQ:
> > 
> > Should I treat factor xxx as fixed or random?
> > 
> > This is in general a far more difficult question than it
> > seems on the
> > surface. There are many competing philosophies and
> > definitions (see
> > Gelman 2xxx). One point of particular relevance to 'modern'
> > mixed model
> > estimation (rather than 'classical' method-of-moments
> > estimation) is
> > that, for practical purposes, there must be a reasonable
> > number of
> > random-effects levels (e.g. blocks) ? more than 5 or 6 at a
> > minimum.
> > 
> > ? ? e.g., from Crawley (2002) p. 670: "Are there
> > enough levels of the
> > factor in the data on which to base an estimate of the
> > variance of the
> > population of effects? No, means [you should probably treat
> > the variable
> > as] fixed effects."
> > 
> > Some researchers (who treat fixed vs random as a
> > philosophical rather
> > than a pragmatic decision) object to this approach.
> > 
> > Treating factors with small numbers of levels as random
> > will in the best
> > case lead to very small estimates of random effects; in the
> > worst case
> > it will lead to various numerical difficulties such as lack
> > of
> > convergence, zero variance estimates, etc.. In the
> > classical
> > method-of-moments approach these problems do not arise
> > (because the sums
> > of squares are always well defined as long as there are at
> > least two
> > units), but the underlying problems of lack of power are
> > there nevertheless.
> > 
> > ???(Contributions welcome!)
> > 
> > -- 
> > Ben Bolker
> > Associate professor, Biology Dep't, Univ. of Florida
> > bolker at ufl.edu /
> > people.biology.ufl.edu/bolker
> > GPG key:
> > people.biology.ufl.edu/bolker/benbolker-publickey.asc
> > 
> > 
> > 
> > ------------------------------
> > 
> > _______________________________________________
> > R-sig-mixed-models mailing list
> > R-sig-mixed-models at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > 
> > 
> > End of R-sig-mixed-models Digest, Vol 39, Issue 47
> > **************************************************
> > 
> 
> 
>     
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From lamprianou at yahoo.com  Tue Mar 30 10:29:04 2010
From: lamprianou at yahoo.com (Iasonas Lamprianou)
Date: Tue, 30 Mar 2010 01:29:04 -0700 (PDT)
Subject: [R-sig-ME] interactions
In-Reply-To: <2E9C414912813E4EB981326983E0A1040717005C@inboexch.inbo.be>
Message-ID: <437501.48950.qm@web58905.mail.re1.yahoo.com>

Thank you for the email. 
I want to see whether a marker is differentially severe or lenient in different days. Therefore, I need to get an overall severity for each marker (probably a fixed effect?), but also an additional estimate for every marker on each day (random effect?). 
I am not sure if I need a varying intercept per marker per day or if the correct term for this is 'slope' as you call it. (Since 'day' is categorical, should we use the term 'intercept' or 'slope'?)
In any case, now that I explained to you what I want to do, do you still think that (1|marker/day) is an option? I am not sure how different this is compared to (day|marker). 

I know that we all have limited time, but any help is welcome

thanks

jason



Dr. Iasonas Lamprianou


Assistant Professor (Educational Research and Evaluation)
Department of Education Sciences
European University-Cyprus
P.O. Box 22006
1516 Nicosia
Cyprus 
Tel.: +357-22-713178
Fax: +357-22-590539


Honorary Research Fellow
Department of Education
The University of Manchester
Oxford Road, Manchester M13 9PL, UK
Tel. 0044  161 275 3485
iasonas.lamprianou at manchester.ac.uk


--- On Tue, 30/3/10, ONKELINX, Thierry <Thierry.ONKELINX at inbo.be> wrote:

> From: ONKELINX, Thierry <Thierry.ONKELINX at inbo.be>
> Subject: RE: [R-sig-ME] interactions
> To: "Iasonas Lamprianou" <lamprianou at yahoo.com>, r-sig-mixed-models at r-project.org
> Date: Tuesday, 30 March, 2010, 9:08
> Dear Jason,
> 
> Are you interested in the variability of the random
> intercept for each day along marker? If you just want to
> allow a different random intercept per day and per marker,
> you could consider (1|marker/day) instead of (day|marker).
> If day has 15 levels then (day|marker) has to estimate 15
> variances and 105 covariances! This is probably the reason
> why the model doesn't converge. (1|marker/day) requires only
> 2 variances to be estimated.
> 
> HTH,
> 
> Thierry
> 
> 
> ----------------------------------------------------------------------------
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek
> team Biometrie & Kwaliteitszorg
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
> 
> Research Institute for Nature and Forest
> team Biometrics & Quality Assurance
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
> 
> tel. + 32 54/436 185
> Thierry.Onkelinx at inbo.be
> www.inbo.be
> 
> To call in the statistician after the experiment is done
> may be no more than asking him to perform a post-mortem
> examination: he may be able to say what the experiment died
> of.
> ~ Sir Ronald Aylmer Fisher
> 
> The plural of anecdote is not data.
> ~ Roger Brinner
> 
> The combination of some data and an aching desire for an
> answer does not ensure that a reasonable answer can be
> extracted from a given body of data.
> ~ John Tukey
> ? 
> 
> > -----Oorspronkelijk bericht-----
> > Van: r-sig-mixed-models-bounces at r-project.org
> 
> > [mailto:r-sig-mixed-models-bounces at r-project.org]
> Namens 
> > Iasonas Lamprianou
> > Verzonden: maandag 29 maart 2010 23:54
> > Aan: r-sig-mixed-models at r-project.org
> > Onderwerp: Re: [R-sig-ME] interactions
> > 
> > 
> > Dear colleagues,
> > apologies for the long question, but I really need
> some help. 
> > It is not a case of academic laziness, I have done my
> 
> > homework but now I need some advice.
> > 
> > I have 10000 students nested in 50 schools, each
> student 
> > taking a test. The tests are randomly grouped in
> batches of 
> > 20 scripts (around 500 batches). Then, two random
> markers 
> > (out of a pool of 57 markers) mark each batch blindly.
> Each 
> > marker marks around 17 random batches of 20 scripts.
> If the 
> > two random markers disagree by more than 10% on the
> total 
> > score for a specific student, then the test of the
> student is 
> > being given to another marker randomly for a third
> blind 
> > marking. So, I have students nested within schools
> which are 
> > nested in areas. Then, scripts (the tests of the
> students) 
> > nested into batches. Then, batches crossed with
> markers. 
> > However, the actual marking lasted around 15 days. One
> batch 
> > may be marked by the first marker on day 1 and then
> marked by 
> > the second marker on the next day (or the day after
> etc). So 
> > the batches are also crossed by days. 
> > 
> > My Research question is: are there markers who are 
> > differentially severe or lenient on different days? 
> > 
> > I use this model:
> > 
> > lmer(score ~ 
> >
> 1+day+gender+school+(1+day|marker)+(1|candidate)+(1|batch),
> 
> > mg2007_sub)
> > 
> > I assume that this model is appropriate, because it
> models 
> > candidates as random effects (each candidate has an
> ability 
> > estimate based on the scores he/she received from the
> two or 
> > the three markers if his/her script was remarked by a
> third 
> > marker). Also, every batch is modelled as a random
> effect. 
> > Every marker is modelled as a random effect but I
> allow 
> > his/her estimate to vary by day, so I assume that this
> would 
> > allow me to see if a marker behaves in a different way
> on 
> > different days. So this should answer my research
> question.
> > 
> > Question 1: does this model make sense statistically
> (as i 
> > formulate it in lme4?)
> > 
> > So far so good, but lme4 will run for 48 hours and
> then fail 
> > because it reached maximum iterations. I assume that
> even if 
> > I allow for more iterations, it will go on for ever.
> > 
> > Question 2: Why is it so slow? Why it does not
> converge?
> > 
> > Then, I decided to simplify the problem. Instead of
> modelling 
> > day as a factor, I use 'd' which is the cardinal
> number of 
> > day e.g. 1, 2, 3, days that passed since we started
> marking. 
> > I assume that this is an interval scale. If a marker
> becomes 
> > (linearly) more lenient, he/she would 'like' this
> model. So I run
> > 
> > lmer(score ~ 
> >
> 1+day+gender+dvhool+(1+d|marker)+(1|candidate)+(1|batch),
> mg2007_sub)
> > 
> > please notice that (1+day|marker) where day is a
> factor with 
> > 15 levels, becomes (1+d|marker) which is numeric
> variable
> > 
> > and this gives
> > 
> > Error terms:
> >? Groups? ? Name? ? ?
> ? Std.Dev. Corr? 
> >? candidate (Intercept) 16.85? ? ?
> ? ? 
> >? batch? ???(Intercept)?
> 3.49? ? ? ? ? 
> >? marker? ? (Intercept)? 4.68?
> ? ? ? ? 
> >? ? ? ? ? ? d?
> ? ? ? ? ? 0.38? ? -0.77 
> >? Residual? ? ? ? ?
> ? ???4.83? ? ? ?
> ? 
> > ---
> > number of obs: 18001, groups: candidate, 9402; batch,
> 470; 
> > marker, 59 AIC = 138232, DIC = 138388.9 deviance =
> 138230.4 
> > 
> > 
> > Question 3: How do I know that the variance of 'd' is
> 
> > statistically significant? MlWin gives some error
> estimates.
> > 
> > Question 4: The correlation of -0.77 is a problem?
> > 
> > I hope somebody can help me, this has taken me three
> days up to now...
> > 
> > Thank you 
> > 
> > jason
> > 
> > 
> > 
> > Dr. Iasonas Lamprianou
> > 
> > 
> > Assistant Professor (Educational Research and
> Evaluation) 
> > Department of Education Sciences European
> University-Cyprus 
> > P.O. Box 22006
> > 1516 Nicosia
> > Cyprus
> > Tel.: +357-22-713178
> > Fax: +357-22-590539
> > 
> > 
> > Honorary Research Fellow
> > Department of Education
> > The University of Manchester
> > Oxford Road, Manchester M13 9PL, UK
> > Tel. 0044? 161 275 3485
> > iasonas.lamprianou at manchester.ac.uk
> > 
> > 
> > --- On Mon, 29/3/10, r-sig-mixed-models-request at r-project.org
> 
> > <r-sig-mixed-models-request at r-project.org>
> wrote:
> > 
> > > From: r-sig-mixed-models-request at r-project.org
> 
> > <r-sig-mixed-models-request at r-project.org>
> > > Subject: R-sig-mixed-models Digest, Vol 39, Issue
> 47
> > > To: r-sig-mixed-models at r-project.org
> > > Date: Monday, 29 March, 2010, 21:25
> > > Send R-sig-mixed-models mailing list
> > > submissions to
> > > ??? r-sig-mixed-models at r-project.org
> > > 
> > > To subscribe or unsubscribe via the World Wide
> Web, visit
> > > ??? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > > or, via email, send a message with subject or
> body 'help'
> > > to
> > > ??? r-sig-mixed-models-request at r-project.org
> > > 
> > > You can reach the person managing the list at
> > > ??? r-sig-mixed-models-owner at r-project.org
> > > 
> > > When replying, please edit your Subject line so
> it is more
> > > specific
> > > than "Re: Contents of R-sig-mixed-models
> digest..."
> > > 
> > > 
> > > Today's Topics:
> > > 
> > > ???1. Re: The issue of increasing maximum
> > > number of iterations
> > > ? ? ? (Ben Bolker)
> > > ???2. poisson GLMER with identity link (Tim
> > > Carnus)
> > > ???3. Re: unbalanced data in nested lmer
> > > model (Jana B?rger)
> > > ???4. Re: Correlation of -1: is it a
> > > problem? (Eric Castet)
> > > ???5. Re: unbalanced data in nested lmer
> > > model (Luca Borger)
> > > ???6. Re: unbalanced data in nested lmer
> > > model (Ben Bolker)
> > > 
> > > 
> > > 
> >
> ----------------------------------------------------------------------
> > > 
> > > Message: 1
> > > Date: Mon, 29 Mar 2010 15:50:30 +0000 (UTC)
> > > From: Ben Bolker <bolker at ufl.edu>
> > > To: r-sig-mixed-models at r-project.org
> > > Subject: Re: [R-sig-ME] The issue of increasing
> maximum
> > > number of
> > > ??? iterations
> > > Message-ID: <loom.20100329T171254-536 at post.gmane.org>
> > > Content-Type: text/plain; charset=us-ascii
> > > 
> > > Martin Stjernman <Martin.Stjernman at ...>
> writes:
> > > 
> > > > 
> > > > Dear listmembers!
> > > > 
> > > > I have also had trouble with the maxIter
> specification
> > > in (g)lmer. 
> > > > I've tried to increase the number of
> > > > iterations (to 1000) via the control
> statement in lmer
> > > 
> > > > but it still stops at 300 (the default).
> > > > We are now a number of users having problem
> with this
> > > but 
> > > > I haven't seen any solution to the problem
> on this
> > > > list and I would really appreciate any hint
> on what I
> > > am doing wrong.
> > > > I am running on a Vista 64-bit machine and
> my model
> > > specification and
> > > >? session info follows below. Please let
> > > > me know if any other information needs to
> be
> > > attached.
> > > 
> > > ? Looking at the source code in lmer.R, this
> seems
> > > like
> > > a moderately obvious hole: on or about line 714
> (I may be
> > > off by a couple of lines) we have
> > > 
> > > ? ? if (missing(verbose)) verbose <-
> > > cv$msVerbose
> > > ### FIXME: issue a warning if the model argument
> is
> > > FALSE.? It is ignored. 
> > > 
> > >? adding the lines
> > > 
> > > ? ? FL$dims["mxit"] <- cv$maxIter
> > > ? ? FL$dims["mxfn"] <- cv$maxFN
> > > 
> > > ? appears to work: running
> > > 
> > >? (gm1 <- glmer(cbind(incidence, size -
> incidence) ~
> > > period + 
> > > ???(1 | herd), family=binomial, data=cbpp,
> > > control=list(maxIter=1000)))
> > > 
> > > produces a model with the correct iteration
> number listed
> > > in its
> > > guts.
> > > 
> > > ? The next question is whether you or someone at
> your
> > > institution
> > > is capable of modifying lmer.R appropriately and
> rebuilding
> > > the
> > > package ...
> > > 
> > > 
> > > 
> > > ------------------------------
> > > 
> > > Message: 2
> > > Date: Mon, 29 Mar 2010 17:45:08 +0100
> > > From: Tim Carnus <Tim.Carnus at ucd.ie>
> > > To: r-sig-mixed-models at r-project.org
> > > Subject: [R-sig-ME] poisson GLMER with identity
> link
> > > Message-ID:
> <1269881108.3596.24.camel at tim-laptop>
> > > Content-Type: text/plain; charset=UTF-8
> > > 
> > > Dear list,
> > > 
> > > I am trying to fit a number of GLMERs to count
> data with an
> > > additive
> > > model (in the predictors) that requires the use
> of the
> > > identity link
> > > function. For about half of my response variables
> this
> > > causes no
> > > problems. However in a number of cases the model
> fitting
> > > runs into
> > > problems with regards estimation of negative mean
> (for e.g.
> > > the error
> > > message in mer_finalize: mu[i] must be positive:
> mu =
> > > 1.76267e-312, i =
> > > 13075456). As far as I understand this is well
> known and
> > > documented, and
> > > guarding against that possibility is necessary,
> and built
> > > in to say the
> > > glm() function.
> > > 
> > > My question then is, how can I do this with lmer?
> (ie how
> > > can I specify
> > > the constraints necessary to fit these types of
> models, if
> > > at all
> > > possible)
> > > 
> > > Best regards,
> > > 
> > > Tim Carnus
> > > 
> > > 
> > > 
> > > ------------------------------
> > > 
> > > Message: 3
> > > Date: Mon, 29 Mar 2010 16:17:41 +0200
> > > From: Jana B?rger <jana.buerger at uni-rostock.de>
> > > To: Andrew Dolman <andydolman at gmail.com>
> > > Cc: "r-sig-mixed-models at r-project.org"
> > > ??? <r-sig-mixed-models at r-project.org>
> > > Subject: Re: [R-sig-ME] unbalanced data in nested
> lmer
> > > model
> > > Message-ID: <4BB0B685.70506 at uni-rostock.de>
> > > Content-Type: text/plain; charset="UTF-8";
> format=flowed
> > > 
> > > Dear Andrew and other list members,
> > > As I described in an earlier 
> > > 
> > post(https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q1/
> > 003503.html)
> > > my data is actually hierarchical down to the
> level of
> > > fields within farms.
> > > 
> > > There is more than 500 cases on 8 farms in 6
> regions.
> > > Would you not think that gives enough power to
> distinguish
> > > within region 
> > > variability vs. between regions?
> > > 
> > > Moreover I don't understand your argument that
> fitting
> > > random efects 
> > > with less than 5 levels was dodgy, as often
> examples in the
> > > books have 3 
> > > samples from one beach, or 3 laboratory workers
> within one
> > > laboratory. 
> > > These are less than 5 levels, are they not?
> > > 
> > > Regards, Jana
> > > 
> > > Andrew Dolman schrieb:
> > > > Dear Jana,
> > > > 
> > > >? >An anova(lm1, lm2)?
> > >
> lm1<-lmer(y~x1+x2+...+(1|region)+(1|region:farm)); 
> > > > lm2<-lmer(y+x1+x2+...+(1|farm)) said
> models did not
> > > differ significantly 
> > > > and AIC was about the same. So I know there
> is no
> > > additional explanatory 
> > > > power including the region term.
> > > > 
> > > >? >Yet, I would like to keep the region
> effect
> > > in the model to separate 
> > > > and compare the effect size of region vs.
> farm. Is it
> > > valid to do so 
> > > > even if? some of the regions are only
> represented
> > > by one farm?
> > > > 
> > > > I don't think you have the data to ask
> questions about
> > > differences 
> > > > between regions as distinct from differences
> between
> > > farms. Look at it 
> > > > this way. If you were just doing a normal
> comparison
> > > between regions and 
> > > > you only looked at 1 or 2 farms per region,
> would you
> > > have the 
> > > > statistical power to say that differences
> were due to
> > > region rather than 
> > > > farm? Answer = No.
> > > > 
> > > > Similarly, are the differences between the
> farms
> > > because they are in 
> > > > different regions or just normal variation
> between
> > > farms? Well you only 
> > > > have 2 farms per region so it's hard to
> tell. Maybe
> > > you just have enough 
> > > > data if pairs of farms within regions are
> always very
> > > similar and 
> > > > differences between regions large.
> > > > 
> > > > Also. Fitting random effects with fewer than
> 5 levels
> > > is dodgy, and you 
> > > > only have 2 levels of farm per region,
> sometimes 1.
> > > > 
> > > > Perhaps you could look at it this way.
> > > > 
> > > > compare
> > > > 
> > > > m1 <- lmer (y~(1|region))
> > > > m2 <- lmer (y~(1|farm))
> > > > 
> > > > If m2 is better then there is variation
> between farms
> > > within regions, if 
> > > > there's no difference then region accounts
> for most of
> > > the variation. 
> > > > BUT you've not got much power to detect farm
> effects
> > > within regions, so 
> > > > a null result is not strong evidence for the
> absence
> > > of farm variation 
> > > > within regions.
> > > > 
> > > > 
> > > > Andy.
> > > >? 
> > > > 
> > > > 
> > > > andydolman at gmail.com
> > > <mailto:andydolman at gmail.com>
> > > > 
> > > > 
> > > > 
> > > 
> > > -- 
> > > Jana B?rger
> > > 
> > > Universit?t Rostock
> > > Agrar-? und Umweltwissenschaftliche Fakult?t
> > > FG Phytomedizin
> > > Satower Stra?e 48
> > > 18059 Rostock
> > > 
> > > Tel. 0381-498 31 71
> > > Fax.0381-498 31 62
> > > 
> > > 
> > > 
> > > ------------------------------
> > > 
> > > Message: 4
> > > Date: Mon, 29 Mar 2010 19:45:15 +0200
> > > From: Eric Castet <Eric.Castet at incm.cnrs-mrs.fr>
> > > To: Douglas Bates <bates at stat.wisc.edu>
> > > Cc: r-sig-mixed-models at r-project.org
> > > Subject: Re: [R-sig-ME] Correlation of -1: is it
> a
> > > problem?
> > > Message-ID: <4BB0E72B.2070404 at incm.cnrs-mrs.fr>
> > > Content-Type: text/plain
> > > 
> > > Dear Doug,
> > > 
> > > Thanks for your reply.
> > > 
> > > I've done as you suggested (your point b/), i.e.
> I've fit
> > > another model 
> > > that considers 'couleurs' within 'nom'
> > > However, after running anova() (likelihood ratio
> test), I
> > > find that I 
> > > should keep the initial model that contains the
> -1
> > > correlation:
> > > 

> > >? > anova (jb.lmer1, jb.lmer2)
> > > Data: jb
> > > Models:
> > > jb.lmer2: lRT ~ couleurs + (1 | nom) + (1 |
> nom:couleurs)
> > > jb.lmer1: lRT ~ couleurs + (1 + couleurs | nom)
> > > ? ? ? ? ?
> > > Df???AIC???BIC?
> > > logLik? Chisq Chi Df Pr(>Chisq)
> > > jb.lmer2? 5 17260 17295 -8625.2
> > > jb.lmer1? 6 17251 17293 -8619.4 11.584? ?
> > > ? 1? 0.0006654 ***
> > > 
> > > So, the question is now:
> > > 
> > > a/ How can I justify to refuse the initial model
> that
> > > contains the -1 
> > > correlation?
> > > 
> > > b/ And a parallel question is: what is wrong with
> the -1
> > > correlation? Is 
> > > it because it is exactly -1 ? Would it still be a
> problem
> > > if it were -0.99 ?
> > > 
> > > c/ Ultimately, how can I report what appears to
> me as an
> > > important 
> > > result: namely the high correlation between the
> intercept
> > > and the 
> > > 'couleurs' effect for each subject?
> > > 
> > > 
> > > Thanks,
> > > Eric
> > > 
> > > 
> > > 
> > > 
> > > 
> > > >> a/ is it really a statistical (or
> numerical)
> > > problem to have a -1
> > > >> correlation in the model that I should
> keep?
> > > >>? ? ? 
> > > >
> > > > Yes, it is.? The fitted model is has a
> singular
> > > variance-covariance
> > > > matrix for the random effects and that is
> not
> > > good.? In fact, it is no
> > > > longer a linear mixed model.
> > > >
> > > >? ? 
> > > >> b/ is it possible to remove the
> correlation
> > > between Intercept and
> > > >> Couleurs, as I would do if Couleurs were
> not a
> > > categorical factor?
> > > >>? ? ? 
> > > >
> > > > I would fit another model of
> > > >
> > > > IRT ~ couleurs + (1|nom:couleurs) + (1|nom)
> > > >
> > > > and see how that works.? This model is, in
> some
> > > sense, intermediate to
> > > > the models that you have fit above.
> > > >
> > > >? ? 
> > > >> Thanks in advance,
> > > >>
> > > >> Eric Castet
> > > >>
> > > >>
> > > >>
> > > >>
> > > >> --
> > > >>
> > > >> Eric Castet
> > > >>
> > > >> Institut de Neurosciences Cognitives de
> la
> > > M?diterran?e -- INCM CNRS
> > > >>
> > > >> 31 chemin Joseph Aiguier
> > > >>
> > > >> 13402 Marseille cedex 20 (France)
> > > >>
> > > >> tel : (+33)(0)4-91-16-43-34
> > > >>
> > > >> fax : (+33) (0)4-91-16-44-98
> > > >>
> > > >> UMR 6193 du CNRS
> > > >>
> > > >> Universit? Aix-Marseille II
> > > >>
> > > >> http://www.incm.cnrs-mrs.fr/equipedyva.php
> > > >>
> > > >> http://www.incm.cnrs-mrs.fr/pperso/ecastet.php
> > > >>
> > > >>
> > > >>
> > > >>
> > > >>? ? ?
> > > ???[[alternative HTML version deleted]]
> > > >>
> > > >>
> > > >>
> _______________________________________________
> > > >> R-sig-mixed-models at r-project.org?
> > > mailing list
> > > >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > > >>
> > > >>
> > > >>? ? ? 
> > > >
> > > >? ? 
> > > 
> > > -- 
> > > 
> > > Eric Castet
> > > 
> > > Institut de Neurosciences Cognitives de la
> M?diterran?e
> > > -- INCM CNRS
> > > 
> > > 31 chemin Joseph Aiguier
> > > 
> > > 13402 Marseille cedex 20 (France)
> > > 
> > > tel : (+33)(0)4-91-16-43-34
> > > 
> > > fax : (+33) (0)4-91-16-44-98
> > > 
> > > UMR 6193 du CNRS
> > > 
> > > Universit? Aix-Marseille II
> > > 
> > > http://www.incm.cnrs-mrs.fr/equipedyva.php
> > > 
> > > http://www.incm.cnrs-mrs.fr/pperso/ecastet.php
> > > 
> > > 
> > > ??? [[alternative HTML version deleted]]
> > > 
> > > 
> > > 
> > > ------------------------------
> > > 
> > > Message: 5
> > > Date: Mon, 29 Mar 2010 13:55:01 -0400
> > > From: "Luca Borger" <lborger at uoguelph.ca>
> > > To: Jana B?rger <jana.buerger at uni-rostock.de>,???
> > > "Andrew Dolman"
> > > ??? <andydolman at gmail.com>
> > > Cc: r-sig-mixed-models at r-project.org
> > > Subject: Re: [R-sig-ME] unbalanced data in nested
> lmer
> > > model
> > > Message-ID:
> > > <D63BEA7FF21244B88504AA33F4E7C14D at lborger>
> > > Content-Type: text/plain; format=flowed;
> charset="utf-8";
> > > ??? reply-type=response
> > > 
> > > Hello,
> > > 
> > > as Andrew and others already explained:
> > > 
> > > > There is more than 500 cases
> > > 
> > > Fine, this might give you reasonable estimates
> about how
> > > your y is affected 
> > > by your fixed effects covariates (x1,x2,...)
> > > 
> > > > (...) on 8 farms in 6 regions.
> > > #and, from your previos post
> > > >For 2 of 8 regions there is only 1 farm, the
> other
> > > regions have 2 farms.
> > > 
> > > thus no way to estimate a difference between
> region or farm
> > > effects for 2 
> > > regions, and very, very limited power for the
> other 6 (just
> > > 2 farms per 
> > > region). To make things worse your data are also
> quite
> > > unbalanced:
> > > 
> > > >unbalance of case numbers in cells? Or would
> it be no
> > > problem if cell sizes 
> > > >vary between 0 and 53?
> > > 
> > > which I think means for some farms you got only
> one record?
> > > Anyway, to 
> > > recap, probably OK data for understanding y~x1+x2
> etc.,
> > > insufficient data 
> > > otherwise (should invest in getting data for more
> farms
> > > within regions, not 
> > > more data for the farms you have already
> sampled).
> > > 
> > > > Moreover I don't understand your argument
> that fitting
> > > random efects with 
> > > > less than 5 levels was dodgy, as often
> examples in the
> > > books have 3 
> > > > samples from one beach, or 3 laboratory
> workers within
> > > one laboratory. 
> > > > These are less than 5 levels, are they not?
> > > 
> > > These are usually toy datasets to exemplify how
> the
> > > approach works, I do not 
> > > think they make a claim that the resulting
> variance
> > > estimates are very 
> > > reliable (think in the Zuur etal. mixed effects
> book you
> > > can find more 
> > > realistic examples, if I remember well). Plus,
> "level"
> > > refers to the number 
> > > of beaches or the number of labs etc. and the
> resulting
> > > variance estimates - 
> > > if less than say 5 it appears that you might be
> better off
> > > fitting it as a 
> > > fixed effect and not trying to decompose the
> variance into
> > > between labs and 
> > > within labs etc. Anyway, just my 2 cents and hope
> I
> > > explained this 
> > > correctly...
> > > 
> > > 
> > > See also the wiki page set up by Ben Bolker:
> > > http://glmm.wikidot.com/faq
> > > 
> > > e.g. you might be interested in this entry
> therein:
> > > 
> > > Zero or very small random effects variance
> estimates;
> > > (...)
> > > Very small variance estimates, or very large
> correlation
> > > estimates, often 
> > > indicates unidentifiability/lack of data (either
> due to
> > > exact 
> > > identifiability [e.g. designs that are not
> replicated at an
> > > important level] 
> > > or weak identifiable (designs that would be
> workable with
> > > more data of the 
> > > same type)
> > > 
> > > 
> > > HTH
> > > 
> > > 
> > > Cheers,
> > > 
> > > Luca
> > > 
> > > 
> > > 
> > > 
> > > 
> > > 
> > > ----- Original Message ----- 
> > > From: "Jana B?rger" <jana.buerger at uni-rostock.de>
> > > To: "Andrew Dolman" <andydolman at gmail.com>
> > > Cc: <r-sig-mixed-models at r-project.org>
> > > Sent: Monday, March 29, 2010 10:17 AM
> > > Subject: Re: [R-sig-ME] unbalanced data in nested
> lmer
> > > model
> > > 
> > > 
> > > > Dear Andrew and other list members,
> > > > As I described in an earlier 
> > > > 
> > post(https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q1/
> > 003503.html)
> > > > my data is actually hierarchical down to the
> level of
> > > fields within farms.
> > > >
> > > > There is more than 500 cases on 8 farms in 6
> regions.
> > > > Would you not think that gives enough power
> to
> > > distinguish within region 
> > > > variability vs. between regions?
> > > >
> > > > Moreover I don't understand your argument
> that fitting
> > > random efects with 
> > > > less than 5 levels was dodgy, as often
> examples in the
> > > books have 3 
> > > > samples from one beach, or 3 laboratory
> workers within
> > > one laboratory. 
> > > > These are less than 5 levels, are they not?
> > > >
> > > > Regards, Jana
> > > >
> > > > Andrew Dolman schrieb:
> > > >> Dear Jana,
> > > >>
> > > >>? >An anova(lm1, lm2)?
> > >
> lm1<-lmer(y~x1+x2+...+(1|region)+(1|region:farm)); 
> > > >> lm2<-lmer(y+x1+x2+...+(1|farm)) said
> models did
> > > not differ significantly 
> > > >> and AIC was about the same. So I know
> there is no
> > > additional explanatory 
> > > >> power including the region term.
> > > >>
> > > >>? >Yet, I would like to keep the
> region
> > > effect in the model to separate 
> > > >> and compare the effect size of region
> vs. farm. Is
> > > it valid to do so even 
> > > >> if? some of the regions are only
> represented
> > > by one farm?
> > > >>
> > > >> I don't think you have the data to ask
> questions
> > > about differences 
> > > >> between regions as distinct from
> differences
> > > between farms. Look at it 
> > > >> this way. If you were just doing a
> normal
> > > comparison between regions and 
> > > >> you only looked at 1 or 2 farms per
> region, would
> > > you have the 
> > > >> statistical power to say that
> differences were due
> > > to region rather than 
> > > >> farm? Answer = No.
> > > >>
> > > >> Similarly, are the differences between
> the farms
> > > because they are in 
> > > >> different regions or just normal
> variation between
> > > farms? Well you only 
> > > >> have 2 farms per region so it's hard to
> tell.
> > > Maybe you just have enough 
> > > >> data if pairs of farms within regions
> are always
> > > very similar and 
> > > >> differences between regions large.
> > > >>
> > > >> Also. Fitting random effects with fewer
> than 5
> > > levels is dodgy, and you 
> > > >> only have 2 levels of farm per region,
> sometimes
> > > 1.
> > > >>
> > > >> Perhaps you could look at it this way.
> > > >>
> > > >> compare
> > > >>
> > > >> m1 <- lmer (y~(1|region))
> > > >> m2 <- lmer (y~(1|farm))
> > > >>
> > > >> If m2 is better then there is variation
> between
> > > farms within regions, if 
> > > >> there's no difference then region
> accounts for
> > > most of the variation. BUT 
> > > >> you've not got much power to detect farm
> effects
> > > within regions, so a 
> > > >> null result is not strong evidence for
> the absence
> > > of farm variation 
> > > >> within regions.
> > > >>
> > > >>
> > > >> Andy.
> > > >>? andydolman at gmail.com
> > > <mailto:andydolman at gmail.com>
> > > >>
> > > >>
> > > >>
> > > >
> > > > -- 
> > > > Jana B?rger
> > > >
> > > > Universit?t Rostock
> > > > Agrar-? und Umweltwissenschaftliche
> Fakult?t
> > > > FG Phytomedizin
> > > > Satower Stra?e 48
> > > > 18059 Rostock
> > > >
> > > > Tel. 0381-498 31 71
> > > > Fax.0381-498 31 62
> > > >
> > > >
> _______________________________________________
> > > > R-sig-mixed-models at r-project.org
> > > mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > > >
> > > 
> > > 
> > > 
> > > ------------------------------
> > > 
> > > Message: 6
> > > Date: Mon, 29 Mar 2010 16:25:12 -0400
> > > From: Ben Bolker <bolker at ufl.edu>
> > > To: Luca Borger <lborger at uoguelph.ca>
> > > Cc: Andrew Dolman <andydolman at gmail.com>,
> > > ??? "r-sig-mixed-models at r-project.org"
> > > <r-sig-mixed-models at r-project.org>,
> > > ??? Jana B?rger <jana.buerger at uni-rostock.de>
> > > Subject: Re: [R-sig-ME] unbalanced data in nested
> lmer
> > > model
> > > Message-ID: <4BB10CA8.6030803 at ufl.edu>
> > > Content-Type: text/plain; charset=UTF-8
> > > 
> > > Luca Borger wrote:
> > > 
> > > [Jana B?rger:]
> > > >> Moreover I don't understand your
> argument that
> > > fitting random efects with 
> > > >> less than 5 levels was dodgy, as often
> examples in
> > > the books have 3 
> > > >> samples from one beach, or 3 laboratory
> workers
> > > within one laboratory. 
> > > >> These are less than 5 levels, are they
> not?
> > > > 
> > > > These are usually toy datasets to exemplify
> how the
> > > approach works, I do not 
> > > > think they make a claim that the resulting
> variance
> > > estimates are very 
> > > > reliable (think in the Zuur etal. mixed
> effects book
> > > you can find more 
> > > > realistic examples, if I remember well).
> Plus, "level"
> > > refers to the number 
> > > > of beaches or the number of labs etc. and
> the
> > > resulting variance estimates - 
> > > > if less than say 5 it appears that you might
> be better
> > > off fitting it as a 
> > > > fixed effect and not trying to decompose the
> variance
> > > into between labs and 
> > > > within labs etc. Anyway, just my 2 cents and
> hope I
> > > explained this 
> > > > correctly... 
> > > > 
> > > > See also the wiki page set up by Ben
> Bolker:
> > > > http://glmm.wikidot.com/faq
> > > > 
> > > > e.g. you might be interested in this entry
> therein:
> > > > 
> > > > Zero or very small random effects variance
> estimates;
> > > > (...)
> > > > Very small variance estimates, or very
> large
> > > correlation estimates, often 
> > > > indicates unidentifiability/lack of data
> (either due
> > > to exact 
> > > > identifiability [e.g. designs that are not
> replicated
> > > at an important level] 
> > > > or weak identifiable (designs that would be
> workable
> > > with more data of the 
> > > > same type)
> > > 
> > > ? I just added this to the FAQ:
> > > 
> > > Should I treat factor xxx as fixed or random?
> > > 
> > > This is in general a far more difficult question
> than it
> > > seems on the
> > > surface. There are many competing philosophies
> and
> > > definitions (see
> > > Gelman 2xxx). One point of particular relevance
> to 'modern'
> > > mixed model
> > > estimation (rather than 'classical'
> method-of-moments
> > > estimation) is
> > > that, for practical purposes, there must be a
> reasonable
> > > number of
> > > random-effects levels (e.g. blocks) ? more than 5
> or 6 at a
> > > minimum.
> > > 
> > > ? ? e.g., from Crawley (2002) p. 670: "Are
> there
> > > enough levels of the
> > > factor in the data on which to base an estimate
> of the
> > > variance of the
> > > population of effects? No, means [you should
> probably treat
> > > the variable
> > > as] fixed effects."
> > > 
> > > Some researchers (who treat fixed vs random as a
> > > philosophical rather
> > > than a pragmatic decision) object to this
> approach.
> > > 
> > > Treating factors with small numbers of levels as
> random
> > > will in the best
> > > case lead to very small estimates of random
> effects; in the
> > > worst case
> > > it will lead to various numerical difficulties
> such as lack
> > > of
> > > convergence, zero variance estimates, etc.. In
> the
> > > classical
> > > method-of-moments approach these problems do not
> arise
> > > (because the sums
> > > of squares are always well defined as long as
> there are at
> > > least two
> > > units), but the underlying problems of lack of
> power are
> > > there nevertheless.
> > > 
> > > ???(Contributions welcome!)
> > > 
> > > -- 
> > > Ben Bolker
> > > Associate professor, Biology Dep't, Univ. of
> Florida
> > > bolker at ufl.edu /
> > > people.biology.ufl.edu/bolker
> > > GPG key:
> > >
> people.biology.ufl.edu/bolker/benbolker-publickey.asc
> > > 
> > > 
> > > 
> > > ------------------------------
> > > 
> > > _______________________________________________
> > > R-sig-mixed-models mailing list
> > > R-sig-mixed-models at r-project.org
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > > 
> > > 
> > > End of R-sig-mixed-models Digest, Vol 39, Issue
> 47
> > >
> **************************************************
> > > 
> > 
> > 
> >? ???
> > _______________________________________________
> > R-sig-mixed-models at r-project.org
> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > 
> 
> Druk dit bericht a.u.b. niet onnodig af.
> Please do not print this message unnecessarily.
> 
> Dit bericht en eventuele bijlagen geven enkel de visie van
> de schrijver weer 
> en binden het INBO onder geen enkel beding, zolang dit
> bericht niet bevestigd is
> door een geldig ondertekend document. The views expressed
> in? this message 
> and any annex are purely those of the writer and may not be
> regarded as stating 
> an official position of INBO, as long as the message is not
> confirmed by a duly 
> signed document.
> 






From andydolman at gmail.com  Tue Mar 30 11:20:11 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Tue, 30 Mar 2010 11:20:11 +0200
Subject: [R-sig-ME] interactions
In-Reply-To: <437501.48950.qm@web58905.mail.re1.yahoo.com>
References: <2E9C414912813E4EB981326983E0A1040717005C@inboexch.inbo.be>
	<437501.48950.qm@web58905.mail.re1.yahoo.com>
Message-ID: <951234ac1003300220v44344f67p91ed99e999e38471@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100330/c89e90d9/attachment.pl>

From henrik.parn at bio.ntnu.no  Tue Mar 30 12:44:09 2010
From: henrik.parn at bio.ntnu.no (Henrik Parn)
Date: Tue, 30 Mar 2010 12:44:09 +0200
Subject: [R-sig-ME] multilevel circular regression
Message-ID: <4BB1D5F9.9030704@bio.ntnu.no>

Dear all,

I wish to analyse the dispersal direction (angle 0-360) in juvenile 
birds in relation to e.g. their sex. However, the movement may be 
non-independent among individuals. For example juveniles from the same 
nest may have non-independent dispersal behaviour due to genetic or 
environmental effects, or individuals from nests in the same colony may 
have a similar dispersal directions. Therefore, I wish to analyse 
individual dispersal direction in a nested model. Something like:

direction ~ sex + (1|colony.id) + (1|nest.id:colony.id)
...using lmer-ish notation.

I have seen similar questions on the forum before
http://finzi.psych.upenn.edu/Rhelp10/2009-May/198498.html
http://finzi.psych.upenn.edu/R/Rhelp02/archive/53700.html
...but could not find any answers

I am aware of the packages circular and CircStats, and in particular the 
function lm.circular.cl for a non-nested regression.

Has anyone tried mixed model circular regression using R? Any hints of 
relevant packages or functions are welcome!

Thanks a lot in advance!

Henrik


-- 
Henrik P?rn
Centre for Conservation Biology
Department of Biology
Norwegian University of Science and Technology
NO-7491 Trondheim
Norway

Office: +47 73596285
Fax: +47 73596100
Mobile: +47 90989255

E-mail: henrik.parn at bio.ntnu.no



From bates at stat.wisc.edu  Tue Mar 30 15:51:14 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 30 Mar 2010 08:51:14 -0500
Subject: [R-sig-ME] nlme
In-Reply-To: <D99AF594DA993D4DA110EBAC373E83C50262E3E5060F@MAIL-2.UNINE.CH>
References: <D99AF594DA993D4DA110EBAC373E83C50262E3E5060F@MAIL-2.UNINE.CH>
Message-ID: <40e66e0b1003300651o7c25dc68scd1eaa2126d399af@mail.gmail.com>

May I suggest sending inquiries like this to the
R-SIG-Mixed-Models at R-project.org mailing list.  I have taken the
liberty of cc:'ing the list on this reply.


On Tue, Mar 30, 2010 at 3:21 AM, TOPPET Val?rie <valerie.toppet at unine.ch> wrote:
> Dear ?Mr Bates,
>
>
> I'm working with the Mixed-Effects Models, and i have some questions about the code in the package ?NLME:
>
> I have to test the effect of a food additive(XTract) on the production of dairy cow(AvgYield)
> I have several races(breed4) , i coded the race as a categorical variable.
> I want to isolate the effect of the treatment on every level of the categorical variable?
>
>
> 1)Is the following code correct ?Would you give me more information about this codification?
>
>
> model1 <- lme(AvgYield~XTract+NPrevLac+WIM0cat+Tot2007+breed4+Age0+ XTract:(NPrevLac+WIM0cat+Tot2007+breed4+Age0)+I(Time-12)+ ?I(Time-12):(XTract+NPrevLac+WIM0cat+Tot2007+breed4+Age0)+
> ?I(Time-12):XTract:(NPrevLac+WIM0cat+Tot2007+breed4+Age0),
> ?data=nomiss,random=~I(Time-12)|Cow,method="ML", control=list(msMaxIter=100,opt= "optim"))
>
>
> ?model10 <- update(model1,
> ?AvgYield~XTract+WIM0cat+Tot2007+Age0+ I(XTract==1 & breed4=="Holstein")+ I(XTract==1 & breed4=="Jersey")+
> ?I(Time-12)+ I(Time-12):(XTract+NPrevLac+WIM0cat+Tot2007+Age0)+ I(I(Time-12)&breed4=="Holstein")+ I(I(Time-12)&breed4=="Jersey")+ I(I(Time-12)&breed4=="OTHER"))
>
> 2)Why ?the model10's deviance is smaller than the model1's deviance in spite of the fact that the model 1 is the most complex model? Normally it should be the opposite?
> The model with more parameters is supposed to fit better the data?
>
>
>
>
> ? ? ? ? ? ? ? ? ? ? ? ?Model ? ? ? df ? ? ?AIC ? ? ? ? ? ? ? ? ? ? BIC ? ? ? ? ? ? ? ? ? logLik ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Test ?L.Ratio ? ? ?p-value
> model1 ? ? ? ? ? ? 1 ? ? ? ? ? ? ?44 ? ? 49290.05 ? ? ? ? ? 49619.54 ? ? ? ? ?-24601.03
> model10 ? ? ? ? ? 2 ? ? ? ? ? ? ?24 ? ? 48785.30 ? ? ? ? ? 48965.02 ? ? ? ? ?-24368.65 1 ? ? ? vs 2 ? ? ? 464.7512 ? ? ? ? ? ?<.0001
>
>
>
>
> Thanks for the information.
>
> Val?rie Toppet
>
>
>
>
>
>
>
>
>
>



From davidwevans at hotmail.com  Tue Mar 30 18:22:54 2010
From: davidwevans at hotmail.com (David Evans)
Date: Tue, 30 Mar 2010 18:22:54 +0200
Subject: [R-sig-ME] Need for help with random-effect coding in Poisson model
Message-ID: <BLU0-SMTP13B897CA00EACECD23A1E1A91F0@phx.gbl>

Hello all,

Thanks in advance to anyone who can help answer my (simple) questions  
about some mixed modelling issues.

I want to model the rate of a disease event using Poisson-family glmer  
and an offset for follow-up time.  In the data, patients (approx.  
2000) are clustered within treating centres (approx. 100) (no patient  
has more than one centre) and patients can have multiple events.   I  
want to include both centre and patient as random effects and a  
patient-level exposure as a fixed effect, to calculate an incidence  
rate ratio for this exposure.

My first question is about coding.  I am hesitating between
mod1 <- glmer(event ~ exposure + offset(log(follow-up_time)) + (1 |  
idcentre/idpatient), family=poisson, data=data)
and
mod2 <- glmer(event ~ exposure + offset (log(follow-up_time)) + (1 |  
idcentre) + (1 | idpatient), family=poisson, data=data)

I think mod1 represents the nested data structure correctly.  Is this  
correct?  Could anyone help explain the differences between the two?   
It seems to make no difference to the results, which I find surprising.

My second question is about the unbalanced data.  Some centres have  
only two patients, some have over 20.  Further, some patients have no  
events, some only one, many two, and then the number decreases  
smoothly down to one patient who had 12.  I suspect this could make  
estimating the random effects for patient and centre difficult but  
would be grateful if someone could let me know how much of a problem  
this is....  For example, are there estimation methods other than REML  
with glmer that I could try?

Again, thanks for any responses.

David Evans.



From dutangc at gmail.com  Tue Mar 30 10:57:31 2010
From: dutangc at gmail.com (christophe dutang)
Date: Tue, 30 Mar 2010 10:57:31 +0200
Subject: [R-sig-ME] missing data + explanatory variables
In-Reply-To: <2FAAA29A-DA86-4F5E-86A4-5F87729ED63C@gmail.com>
References: <c8e8cd3d1003240409r27cfb4c0w897cae92d391942f@mail.gmail.com>
	<Pine.LNX.4.64.1003250727070.15751@orpheus.qimr.edu.au>
	<6A2368B1-6ED7-48EF-AECC-712AA6865D26@gmail.com>
	<Pine.LNX.4.64.1003261003520.22301@orpheus.qimr.edu.au>
	<w2uc8e8cd3d1003261015j3e52c20dmde89ec65ac2c1c4c@mail.gmail.com>
	<AF1F2446D9EF402AA3D10A0559F9D22A@lborger>
	<2FAAA29A-DA86-4F5E-86A4-5F87729ED63C@gmail.com>
Message-ID: <t2rc8e8cd3d1003300157zeac12383u39afc1b1c5013366@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100330/2756dc4e/attachment.pl>

From jana.buerger at uni-rostock.de  Tue Mar 30 11:40:11 2010
From: jana.buerger at uni-rostock.de (=?UTF-8?B?SmFuYSBCw7xyZ2Vy?=)
Date: Tue, 30 Mar 2010 11:40:11 +0200
Subject: [R-sig-ME] unbalanced data in nested lmer model
In-Reply-To: <4BB10CA8.6030803@ufl.edu>
References: <4BAA0B06.1030806@uni-rostock.de>	<4BAA3810.4010701@life.ku.dk>	<4BACB838.7000608@uni-rostock.de><951234ac1003260745k6590c26cj887dc17aae83a9c4@mail.gmail.com>	<4BB0B685.70506@uni-rostock.de>
	<D63BEA7FF21244B88504AA33F4E7C14D@lborger>
	<4BB10CA8.6030803@ufl.edu>
Message-ID: <4BB1C6FB.8000308@uni-rostock.de>

Dear all,
thank you for the very helpful comments.
I understand now that I have data that don't give the power to separate 
regional and farm effects. It would be possible to leave both random 
effects in the model as they are features of the study's data structure, 
but then concentrate on the fixed effects for interpretation.

Regards,
Jana

Ben Bolker schrieb:
> Luca Borger wrote:
> 
> [Jana B?rger:]
>>> Moreover I don't understand your argument that fitting random efects with 
>>> less than 5 levels was dodgy, as often examples in the books have 3 
>>> samples from one beach, or 3 laboratory workers within one laboratory. 
>>> These are less than 5 levels, are they not?
>> These are usually toy datasets to exemplify how the approach works, I do not 
>> think they make a claim that the resulting variance estimates are very 
>> reliable (think in the Zuur etal. mixed effects book you can find more 
>> realistic examples, if I remember well). Plus, "level" refers to the number 
>> of beaches or the number of labs etc. and the resulting variance estimates - 
>> if less than say 5 it appears that you might be better off fitting it as a 
>> fixed effect and not trying to decompose the variance into between labs and 
>> within labs etc. Anyway, just my 2 cents and hope I explained this 
>> correctly... 
>>
>> See also the wiki page set up by Ben Bolker:
>> http://glmm.wikidot.com/faq
>>
>> e.g. you might be interested in this entry therein:
>>
>> Zero or very small random effects variance estimates;
>> (...)
>> Very small variance estimates, or very large correlation estimates, often 
>> indicates unidentifiability/lack of data (either due to exact 
>> identifiability [e.g. designs that are not replicated at an important level] 
>> or weak identifiable (designs that would be workable with more data of the 
>> same type)
> 
>   I just added this to the FAQ:
> 
> Should I treat factor xxx as fixed or random?
> 
> This is in general a far more difficult question than it seems on the
> surface. There are many competing philosophies and definitions (see
> Gelman 2xxx). One point of particular relevance to 'modern' mixed model
> estimation (rather than 'classical' method-of-moments estimation) is
> that, for practical purposes, there must be a reasonable number of
> random-effects levels (e.g. blocks) ? more than 5 or 6 at a minimum.
> 
>     e.g., from Crawley (2002) p. 670: "Are there enough levels of the
> factor in the data on which to base an estimate of the variance of the
> population of effects? No, means [you should probably treat the variable
> as] fixed effects."
> 
> Some researchers (who treat fixed vs random as a philosophical rather
> than a pragmatic decision) object to this approach.
> 
> Treating factors with small numbers of levels as random will in the best
> case lead to very small estimates of random effects; in the worst case
> it will lead to various numerical difficulties such as lack of
> convergence, zero variance estimates, etc.. In the classical
> method-of-moments approach these problems do not arise (because the sums
> of squares are always well defined as long as there are at least two
> units), but the underlying problems of lack of power are there nevertheless.
> 
>    (Contributions welcome!)
> 

-- 
Jana B?rger

Universit?t Rostock
Agrar-  und Umweltwissenschaftliche Fakult?t
FG Phytomedizin
Satower Stra?e 48
18059 Rostock

Tel. 0381-498 31 71
Fax.0381-498 31 62



From N.J.Robinson at bristol.ac.uk  Wed Mar 31 16:02:37 2010
From: N.J.Robinson at bristol.ac.uk (NJ Robinson)
Date: Wed, 31 Mar 2010 15:02:37 +0100 (BST)
Subject: [R-sig-ME] clogit error message
Message-ID: <3508.77.102.246.2.1270044157.squirrel@webmail.bris.ac.uk>

Dear all,

I am trying to perform conditional logistic regression using 'clogit'.
However when I run the model I get the following error message:

Warning message:
In fitter(X, Y, strats, offset, init, control, weights = weights,  :
  Ran out of iterations and did not converge

Could someone shed some light on what this message means?

The sample size of my data is 30 (comprising 15 pairs grouped by "site").
My sample data is composed of a binary response ("response") and 3
predictor variables all of which are factors ("x1","x2","x3").

The following command was used to construct the model;

>clogit(response~x1+x2+x3+strata(site))

based on the example of my data structure seen below,

site  response            x1              x2              x3
1        0                GroupA        GroupA        GroupA
1        1                GroupB        GroupB        GroupE
2        0                GroupA        GroupA        GroupB
2        1                GroupA        GroupA        GroupC
3        0                GroupB        GroupB        GroupD
3        1                GroupA        GroupA        GroupA

Have i used the correct syntax in order to run the model correctly for my
data structure?

Any help would be greatly appreciated.

Thanks

Nathan



--



From f.calboli at imperial.ac.uk  Wed Mar 31 16:39:51 2010
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Wed, 31 Mar 2010 15:39:51 +0100
Subject: [R-sig-ME] clogit error message
In-Reply-To: <3508.77.102.246.2.1270044157.squirrel@webmail.bris.ac.uk>
References: <3508.77.102.246.2.1270044157.squirrel@webmail.bris.ac.uk>
Message-ID: <9F11107A-6D4E-4E5E-8851-5FEA34BFC8B5@imperial.ac.uk>

On 31 Mar 2010, at 15:02, NJ Robinson wrote:

> The sample size of my data is 30 (comprising 15 pairs grouped by "site").
> My sample data is composed of a binary response ("response") and 3
> predictor variables all of which are factors ("x1","x2","x3").
> 
> The following command was used to construct the model;
> 
>> clogit(response~x1+x2+x3+strata(site))
> 
> based on the example of my data structure seen below,
> 
> Have i used the correct syntax in order to run the model correctly for my
> data structure?
> 

can you check with str(data) that x1, x2, x3 and site are factors? By eye I'd say your syntax is correct.

Best,

Federico

--
Federico C. F. Calboli
Department of Epidemiology and Biostatistics
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From bates at stat.wisc.edu  Wed Mar 31 20:16:52 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 31 Mar 2010 12:16:52 -0600
Subject: [R-sig-ME] lmer question
In-Reply-To: <r2n5c3e8b1b1003311109hac096bd1x3a7bf55e9c215df2@mail.gmail.com>
References: <r2n5c3e8b1b1003311109hac096bd1x3a7bf55e9c215df2@mail.gmail.com>
Message-ID: <o2o40e66e0b1003311116m5f6f2000i271a8a6fadbfca45@mail.gmail.com>

I would recommend sending inquiries like this to the
R-SIG-Mixed-Models at R-project.org mailing list, which I have taken the
liberty of cc:'ing on this reply.  I am not always able to give a
rapid response to questions about mixed models in R.

On Wed, Mar 31, 2010 at 12:09 PM, Vivek Ayer <vivek.ayer at gmail.com> wrote:
> Hi Doug,
>
> I'm quite interested in your lmer function in the lme4 package and had
> a question on how it worked vs. lm().
>
> This is the command I run in R to get the desired mixed effect result:
>
> fitlmmixed <- lmer(MeasuredPathLoss ~ (1 | SiteLabel) + LogDist + Diffraction)
>
> Here's what I'd run to get the purley fixed effect result:
>
> fitlmfixed <- lm(MeasuredPathLoss ~ -1 + factor(SiteLabel) + LogDist +
> Diffraction)
>
> lm and lmer have interesting applications in the field of radio
> propagation and I just wanted to know how the parameters are treated.
>
> When I run summary on the former, it says the degrees of freedom are
> just LogDist, Diffraction, (1 | SiteLabel), the group intercept and
> sigma = 5. When I run summary on the latter, it says the degrees of
> freedom are LogDist, Diffraction, Sigma, and one deg of freedom for
> each factor. So clearly, in all cases, a pure fixed effects model will
> have more degrees of freedom than a mixed effects model and thus a
> better a logLik, but now by much. However, the advantage of fixed
> effects goes away when your group has many factors.
>
> So with those parameters I have above, the mixed model will always
> have 5 degs of freedom, while the fixed model can have no limit.
>
> Of course, this means the fixed effects model will allocate much more
> memory to the point where a machine may run out of memory, but this
> doesn't occur in lmer(). Why is that? Also, lmer is run fairly
> quickly, while producing very close results to lm's fixed effect. In
> lmer, is there really deg of freedom for each random effect, but all
> those degrees are bunched up into one effect, greatly reducing the
> number of parameters?
>
> Thanks,
> Vivek Ayer
>



