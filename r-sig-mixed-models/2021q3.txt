From k@|m@n@toth @end|ng |rom protonm@||@com  Sat Jul  3 16:59:52 2021
From: k@|m@n@toth @end|ng |rom protonm@||@com (kalman.toth)
Date: Sat, 03 Jul 2021 14:59:52 +0000
Subject: [R-sig-ME] Estimation of variance components in random- and
 mixed-effects models
In-Reply-To: <ca93574d-ed1f-8934-85f8-ed1e233c590f@gmail.com>
References: <CAK2ikok__C0M9JduqEuqsmjOXETDewpX1pGDNTsXJvzpjYEC3g@mail.gmail.com>
 <327afce2-3e10-d179-b4ee-348e8232d74c@gmail.com>
 <CAJuCY5yRWNvvfBJk9Hk3oq8cUCS4L4iAu2nCu--Ams_6vLbDfw@mail.gmail.com>
 <c70f7035-df66-7a96-8656-87a7b0c75b2a@gmail.com>
 <CAK2ikom9AASV49ib1_ytD0KAZwSUMw+KY43RMniY8SAc4v5i1Q@mail.gmail.com>
 <ca93574d-ed1f-8934-85f8-ed1e233c590f@gmail.com>
Message-ID: <boE5pTz1kRk1UEaDwrCx4OwQFHa_SshZzBoqKjWRLraYlQ6BIoIdQHf5Bnm-C1Z7Ivy-sGeIj1rP4RD59ONVIvXSVkGRz-T9xoiVgqpSXmE=@protonmail.com>

Sorry for butting into this conversation but there is something I cannot get my head around. I often encounter situation where B grouping variable is nested into A grouping variable. B has around 10-20 levels and A only has around 3-5. Conceptually, everything is a random effect. If my understanding is correct in this case I should use the following lmer model due to the limited number of levels of B:
R ~ A+(1|B)
Even though, scientifically R ~ (1|A/B) would make more sense.
Variance of B of the first term is not equal to variance of A:B in the second.

I am most interested in a reasonable estimation on the variance of B while we know that it is nested in A.

In general, we use the classical ANOVA to do that: aov(R~A/B). This gives the same variance estimate for A:B interaction as lmer(R ~ (1|A/B)) if it the design is relatively well balanced. In a way I am not surprised because the Cross Validated post suggested by Ben Bolker also mentions that in this case mixed effect model behaves similarly to classical ones. But does it mean that this  ANOVA variance estimate is also biased/unreliable? Would the variance estimation of B from the first lmer model really be a better estimation?

Best Regards,
Kalman Toth

Sent with ProtonMail Secure Email.

??????? Original Message ???????

On Tuesday, June 29th, 2021 at 2:12 AM, Ben Bolker <bbolker at gmail.com> wrote:

> A couple of quick responses.
>
> -   I don't recommend dropping non-significant predictors, this is a
>
>     good way to overfit models.
> -   Are the temperatures for your three cohorts in a strictly linear
>
>     sequence? i.e., temperature (cohort 1) = T1, temp (2) = T1 + delta, temp
>
>     (3) = T1 + 2*delta ? In that case, the two effects are indeed
>
>     identical/confounded. In principle, your original model (using cohort
>
>     as a random effect and temperature as fixed) is the right way to handle
>
>     this, but for the size of data set you can't really identify
>
>     among-cohort variation beyond the effect of temperature.
>
>     A nice way to handle this is to treat cohort as an ordered
>
>     categorical fixed effect (see ?ordered), and leave out temperature (this
>
>     is assuming that the temperatures are as suggested above). If you do
>
>     this (i.e. convert cohort to 'ordered' type), R will fit two parameters,
>
>     one labeled .L and the other labeled .Q, which together explain all of
>
>     the among-cohort variation; if you like (although it is quite a big
>
>     assumption, and you must be explicit about it), you can ascribe the
>
>     linear (".L") variation to temperature and the other (".Q" or quadratic)
>
>     to non-temperature effects. However, given your experimental design,
>
>     the following two explanations would be equally well supported:
> -   none of the between-cohort variation is due to temperature;
> -   temperature has a quadratic effect, so all of the between-cohort
>
>     variation is due to temperature.
>
>     cheers
>
>     Ben Bolker
>
>     On 6/28/21 3:20 PM, Amy Huang wrote:
>
> > Thank you very much for your responses and references. Sorry that I missed
> >
> > mentioning a lot of information.
> >
> > I am using lme4, and the fixed predictors are all numeric. Only having 3
> >
> > levels of cohorts is indeed the major issue. After removing insignificant
> >
> > predictors in the 2nd model, the only factor left is temperature: offspring
> >
> > trait ~ temperature + (1 | cohort/female/clutch), which gives the
> >
> > convergence warning.
> >
> > Now I treat cohort as a fixed effect, but when I include both cohort and
> >
> > temperature as fixed effects (in the 2nd model), a warning appears:
> >
> > "fixed-effect model matrix is rank deficient so dropping 1 column /
> >
> > coefficient". When I remove cohort (2nd model), the two models become very
> >
> > similar and give similar results.
> >
> > offspring trait ~ cohort + (1 | female/clutch)
> >
> > offspring trait ~ temperature + (1 | female/clutch)
> >
> > But am I not introducing pseudoreplicates if I do not include cohort as a
> >
> > factor?
> >
> > PS. The section "How do I compute a coefficient of determination (R2), or
> >
> > an analogue, for (G)LMMs?" in the GLMM FAQ also gives me some insight.
> >
> > However, the links provided there seem to be not working.
> >
> > Best regards,
> >
> > Amy Huang
> >
> > Am Mo., 28. Juni 2021 um 19:32 Uhr schrieb Ben Bolker bbolker at gmail.com:
> >
> > >     See also:
> > >
> > >
> > > https://stats.stackexchange.com/questions/37647/what-is-the-minimum-recommended-number-of-groups-for-a-random-effects-factor
> > >
> > > https://www.biorxiv.org/content/10.1101/2021.05.03.442487v2
> > >
> > > (I should these links, and the blog post link, to the GLMM FAQ ...)
> > >
> > > On 6/28/21 1:17 PM, Thierry Onkelinx wrote:
> > >
> > > > Another issue is that you have too few levels to fit "cohort" as a
> > > >
> > > > random effect. I wrote a blogpost on this a few years ago:
> > > >
> > > > https://www.muscardinus.be/2018/09/number-random-effect-levels/
> > > >
> > > > https://www.muscardinus.be/2018/09/number-random-effect-levels/
> > > >
> > > > Best regards,
> > > >
> > > > ir. Thierry Onkelinx
> > > >
> > > > Statisticus / Statistician
> > > >
> > > > Vlaamse Overheid / Government of Flanders
> > > >
> > > > INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> > > >
> > > > AND FOREST
> > > >
> > > > Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> > > >
> > > > thierry.onkelinx at inbo.be mailto:thierry.onkelinx at inbo.be
> > > >
> > > > Havenlaan 88 bus 73, 1000 Brussel
> > > >
> > > > www.inbo.be http://www.inbo.be
> > >
> > > ///////////////////////////////////////////////////////////////////////////////////////////
> > >
> > > > To call in the statistician after the experiment is done may be no more
> > > >
> > > > than asking him to perform a post-mortem examination: he may be able to
> > > >
> > > > say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > > >
> > > > The plural of anecdote is not data. ~ Roger Brinner
> > > >
> > > > The combination of some data and an aching desire for an answer does not
> > > >
> > > > ensure that a reasonable answer can be extracted from a given body of
> > > >
> > > > data. ~ John Tukey
> > >
> > > ///////////////////////////////////////////////////////////////////////////////////////////
> > >
> > > > https://www.inbo.be
> > > >
> > > > Op ma 28 jun. 2021 om 16:31 schreef Ben Bolker <bbolker at gmail.com
> > > >
> > > > mailto:bbolker at gmail.com>:
> > > >
> > > >          Are you using lme4? (I'm 99% sure you are, but it's good to be
> > > >      explicit.)
> > > >
> > > >          Are all of your fixed predictors numeric (rather than
> > > >      factor/categorical) ?
> > > >
> > > >          Note that a convergence warning is a *warning*, not an error:
> > > >
> > >
> > > have
> > >
> > > >      you checked the troubleshooting steps in ?lme4::convergence (in
> > > >      particular, scaling and centering your predictor variables might
> > > >      help ...)
> > > >
> > > >          cheers
> > > >           Ben Bolker
> > > >
> > > >
> > > >      On 6/28/21 10:17 AM, Amy Huang wrote:
> > > >       > Dear all,
> > > >       >
> > > >       > I am examining maternal effects, and my data have three hierarchy
> > > >      levels:
> > > >       > clutches of the same female, females, and cohorts. My explanatory
> > > >      variables
> > > >       > are at the female level (female length, age) and at the cohort
> > > >
> > >
> > > level
> > >
> > > >       > (temperature).
> > > >       >
> > > >       > I would like to estimate the variance components of each
> > > >      hierarchy level
> > > >       > (i.e. relative amount of variance at each level) and then to find
> > > >      out which
> > > >       > factors (female length, age, temperature) explain most of the
> > > >      variance. For
> > > >       > these, I have two models:
> > > >       >      offspring trait ~ 1 + (1 | cohort/female/clutch)
> > > >       >      offspring trait ~ temperature + female length + age + (1 |
> > > >       > cohort/female/clutch)
> > > >       >
> > > >       > The major problem is that I only have 3 cohorts (and so 3
> > > >      temperatures).
> > > >       >  From the first model I am able to get the information, but from
> > > >      the second
> > > >       > one there is an error message: "Model failed to converge with 1
> > > >      negative
> > > >       > eigenvalue: -2.0e+01". The error pops up probably because I have
> > > >
> > >
> > > both
> > >
> > > >       > temperature (fixed) and cohort (random) included. Is my approach
> > > >      correct?
> > > >       > And is there a way to fix this error?
> > > >       >
> > > >       > Thank you so much for your time.
> > > >       >
> > > >       > Best regards,
> > > >       > Amy Huang
> > > >       >
> > > >       >       [[alternative HTML version deleted]]
> > > >       >
> > > >       > _______________________________________________
> > > >       > R-sig-mixed-models at r-project.org
> > > >      <mailto:R-sig-mixed-models at r-project.org> mailing list
> > > >       > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > > >      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> > > >       >
> > > >
> > > >      _______________________________________________
> > > >      R-sig-mixed-models at r-project.org
> > > >      <mailto:R-sig-mixed-models at r-project.org> mailing list
> > > >      https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > > >      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> > > >
> > >
> > > R-sig-mixed-models at r-project.org mailing list
> > >
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> > [[alternative HTML version deleted]]
> >
> > R-sig-mixed-models at r-project.org mailing list
> >
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> R-sig-mixed-models at r-project.org mailing list
>
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From @myrb@@ @end|ng |rom gm@||@com  Sun Jul  4 00:39:24 2021
From: @myrb@@ @end|ng |rom gm@||@com (Amy Huang)
Date: Sun, 4 Jul 2021 00:39:24 +0200
Subject: [R-sig-ME] Estimation of variance components in random- and
 mixed-effects models
In-Reply-To: <boE5pTz1kRk1UEaDwrCx4OwQFHa_SshZzBoqKjWRLraYlQ6BIoIdQHf5Bnm-C1Z7Ivy-sGeIj1rP4RD59ONVIvXSVkGRz-T9xoiVgqpSXmE=@protonmail.com>
References: <CAK2ikok__C0M9JduqEuqsmjOXETDewpX1pGDNTsXJvzpjYEC3g@mail.gmail.com>
 <327afce2-3e10-d179-b4ee-348e8232d74c@gmail.com>
 <CAJuCY5yRWNvvfBJk9Hk3oq8cUCS4L4iAu2nCu--Ams_6vLbDfw@mail.gmail.com>
 <c70f7035-df66-7a96-8656-87a7b0c75b2a@gmail.com>
 <CAK2ikom9AASV49ib1_ytD0KAZwSUMw+KY43RMniY8SAc4v5i1Q@mail.gmail.com>
 <ca93574d-ed1f-8934-85f8-ed1e233c590f@gmail.com>
 <boE5pTz1kRk1UEaDwrCx4OwQFHa_SshZzBoqKjWRLraYlQ6BIoIdQHf5Bnm-C1Z7Ivy-sGeIj1rP4RD59ONVIvXSVkGRz-T9xoiVgqpSXmE=@protonmail.com>
Message-ID: <CAK2iko=NKQM_zu7J0wYYPkj+gYhxfrskQBcyZXt5VvZcd036Vg@mail.gmail.com>

 Thank you very much for your valuable insights and suggestions, Thierry
and Dr. Bolker! They have brought me to relearning and expanding my
statistical knowledge.

Treating the predictor "cohort" as an ordered factor is actually most
suitable for my original experimental design. I study cohort effects with
the levels "early, middle and late". The in-situ temperatures (T) I
measured by each level were in a nearly linear sequence "by chance": T2 =
T1 + delta, T3 = T1 + 1.7 * delta.

Because of this, linking cohort effect to temperature would probably be
more difficult. With the new model
    offspring trait ~ cohort +female length + (1 | female/clutch),
the only significant fixed predictor is cohort.L.

It suggests the levels "early, middle and late" are best interpreted as
having nearly equal-spaced intervals (similar to the temperatures). But it
does not support directly that the variance among cohorts is due to
temperature. So the best I could do is to show the correlation between
cohorts and temperatures and propose the link (?)

(Thank you again for the warning about model selection, I am carefully
revising and relearning the process.)

(I tried to use a subset of the data to compare the variance estimates by
classical ANOVA and mixed-effects model, but it is unfortunately too much
for my brain right now..)

Best regards,
Amy Huang

Am Sa., 3. Juli 2021 um 17:00 Uhr schrieb kalman.toth via
R-sig-mixed-models <r-sig-mixed-models at r-project.org>:

> Sorry for butting into this conversation but there is something I cannot
> get my head around. I often encounter situation where B grouping variable
> is nested into A grouping variable. B has around 10-20 levels and A only
> has around 3-5. Conceptually, everything is a random effect. If my
> understanding is correct in this case I should use the following lmer model
> due to the limited number of levels of B:
> R ~ A+(1|B)
> Even though, scientifically R ~ (1|A/B) would make more sense.
> Variance of B of the first term is not equal to variance of A:B in the
> second.
>
> I am most interested in a reasonable estimation on the variance of B while
> we know that it is nested in A.
>
> In general, we use the classical ANOVA to do that: aov(R~A/B). This gives
> the same variance estimate for A:B interaction as lmer(R ~ (1|A/B)) if it
> the design is relatively well balanced. In a way I am not surprised because
> the Cross Validated post suggested by Ben Bolker also mentions that in this
> case mixed effect model behaves similarly to classical ones. But does it
> mean that this  ANOVA variance estimate is also biased/unreliable? Would
> the variance estimation of B from the first lmer model really be a better
> estimation?
>
> Best Regards,
> Kalman Toth
>
> Sent with ProtonMail Secure Email.
>
> ??????? Original Message ???????
>
> On Tuesday, June 29th, 2021 at 2:12 AM, Ben Bolker <bbolker at gmail.com>
> wrote:
>
> > A couple of quick responses.
> >
> > -   I don't recommend dropping non-significant predictors, this is a
> >
> >     good way to overfit models.
> > -   Are the temperatures for your three cohorts in a strictly linear
> >
> >     sequence? i.e., temperature (cohort 1) = T1, temp (2) = T1 + delta,
> temp
> >
> >     (3) = T1 + 2*delta ? In that case, the two effects are indeed
> >
> >     identical/confounded. In principle, your original model (using cohort
> >
> >     as a random effect and temperature as fixed) is the right way to
> handle
> >
> >     this, but for the size of data set you can't really identify
> >
> >     among-cohort variation beyond the effect of temperature.
> >
> >     A nice way to handle this is to treat cohort as an ordered
> >
> >     categorical fixed effect (see ?ordered), and leave out temperature
> (this
> >
> >     is assuming that the temperatures are as suggested above). If you do
> >
> >     this (i.e. convert cohort to 'ordered' type), R will fit two
> parameters,
> >
> >     one labeled .L and the other labeled .Q, which together explain all
> of
> >
> >     the among-cohort variation; if you like (although it is quite a big
> >
> >     assumption, and you must be explicit about it), you can ascribe the
> >
> >     linear (".L") variation to temperature and the other (".Q" or
> quadratic)
> >
> >     to non-temperature effects. However, given your experimental design,
> >
> >     the following two explanations would be equally well supported:
> > -   none of the between-cohort variation is due to temperature;
> > -   temperature has a quadratic effect, so all of the between-cohort
> >
> >     variation is due to temperature.
> >
> >     cheers
> >
> >     Ben Bolker
> >
> >     On 6/28/21 3:20 PM, Amy Huang wrote:
> >
> > > Thank you very much for your responses and references. Sorry that I
> missed
> > >
> > > mentioning a lot of information.
> > >
> > > I am using lme4, and the fixed predictors are all numeric. Only having
> 3
> > >
> > > levels of cohorts is indeed the major issue. After removing
> insignificant
> > >
> > > predictors in the 2nd model, the only factor left is temperature:
> offspring
> > >
> > > trait ~ temperature + (1 | cohort/female/clutch), which gives the
> > >
> > > convergence warning.
> > >
> > > Now I treat cohort as a fixed effect, but when I include both cohort
> and
> > >
> > > temperature as fixed effects (in the 2nd model), a warning appears:
> > >
> > > "fixed-effect model matrix is rank deficient so dropping 1 column /
> > >
> > > coefficient". When I remove cohort (2nd model), the two models become
> very
> > >
> > > similar and give similar results.
> > >
> > > offspring trait ~ cohort + (1 | female/clutch)
> > >
> > > offspring trait ~ temperature + (1 | female/clutch)
> > >
> > > But am I not introducing pseudoreplicates if I do not include cohort
> as a
> > >
> > > factor?
> > >
> > > PS. The section "How do I compute a coefficient of determination (R2),
> or
> > >
> > > an analogue, for (G)LMMs?" in the GLMM FAQ also gives me some insight.
> > >
> > > However, the links provided there seem to be not working.
> > >
> > > Best regards,
> > >
> > > Amy Huang
> > >
> > > Am Mo., 28. Juni 2021 um 19:32 Uhr schrieb Ben Bolker
> bbolker at gmail.com:
> > >
> > > >     See also:
> > > >
> > > >
> > > >
> https://stats.stackexchange.com/questions/37647/what-is-the-minimum-recommended-number-of-groups-for-a-random-effects-factor
> > > >
> > > > https://www.biorxiv.org/content/10.1101/2021.05.03.442487v2
> > > >
> > > > (I should these links, and the blog post link, to the GLMM FAQ ...)
> > > >
> > > > On 6/28/21 1:17 PM, Thierry Onkelinx wrote:
> > > >
> > > > > Another issue is that you have too few levels to fit "cohort" as a
> > > > >
> > > > > random effect. I wrote a blogpost on this a few years ago:
> > > > >
> > > > > https://www.muscardinus.be/2018/09/number-random-effect-levels/
> > > > >
> > > > > https://www.muscardinus.be/2018/09/number-random-effect-levels/
> > > > >
> > > > > Best regards,
> > > > >
> > > > > ir. Thierry Onkelinx
> > > > >
> > > > > Statisticus / Statistician
> > > > >
> > > > > Vlaamse Overheid / Government of Flanders
> > > > >
> > > > > INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR
> NATURE
> > > > >
> > > > > AND FOREST
> > > > >
> > > > > Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality
> Assurance
> > > > >
> > > > > thierry.onkelinx at inbo.be mailto:thierry.onkelinx at inbo.be
> > > > >
> > > > > Havenlaan 88 bus 73, 1000 Brussel
> > > > >
> > > > > www.inbo.be http://www.inbo.be
> > > >
> > > >
> ///////////////////////////////////////////////////////////////////////////////////////////
> > > >
> > > > > To call in the statistician after the experiment is done may be no
> more
> > > > >
> > > > > than asking him to perform a post-mortem examination: he may be
> able to
> > > > >
> > > > > say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > > > >
> > > > > The plural of anecdote is not data. ~ Roger Brinner
> > > > >
> > > > > The combination of some data and an aching desire for an answer
> does not
> > > > >
> > > > > ensure that a reasonable answer can be extracted from a given body
> of
> > > > >
> > > > > data. ~ John Tukey
> > > >
> > > >
> ///////////////////////////////////////////////////////////////////////////////////////////
> > > >
> > > > > https://www.inbo.be
> > > > >
> > > > > Op ma 28 jun. 2021 om 16:31 schreef Ben Bolker <bbolker at gmail.com
> > > > >
> > > > > mailto:bbolker at gmail.com>:
> > > > >
> > > > >          Are you using lme4? (I'm 99% sure you are, but it's good
> to be
> > > > >      explicit.)
> > > > >
> > > > >          Are all of your fixed predictors numeric (rather than
> > > > >      factor/categorical) ?
> > > > >
> > > > >          Note that a convergence warning is a *warning*, not an
> error:
> > > > >
> > > >
> > > > have
> > > >
> > > > >      you checked the troubleshooting steps in ?lme4::convergence
> (in
> > > > >      particular, scaling and centering your predictor variables
> might
> > > > >      help ...)
> > > > >
> > > > >          cheers
> > > > >           Ben Bolker
> > > > >
> > > > >
> > > > >      On 6/28/21 10:17 AM, Amy Huang wrote:
> > > > >       > Dear all,
> > > > >       >
> > > > >       > I am examining maternal effects, and my data have three
> hierarchy
> > > > >      levels:
> > > > >       > clutches of the same female, females, and cohorts. My
> explanatory
> > > > >      variables
> > > > >       > are at the female level (female length, age) and at the
> cohort
> > > > >
> > > >
> > > > level
> > > >
> > > > >       > (temperature).
> > > > >       >
> > > > >       > I would like to estimate the variance components of each
> > > > >      hierarchy level
> > > > >       > (i.e. relative amount of variance at each level) and then
> to find
> > > > >      out which
> > > > >       > factors (female length, age, temperature) explain most of
> the
> > > > >      variance. For
> > > > >       > these, I have two models:
> > > > >       >      offspring trait ~ 1 + (1 | cohort/female/clutch)
> > > > >       >      offspring trait ~ temperature + female length + age +
> (1 |
> > > > >       > cohort/female/clutch)
> > > > >       >
> > > > >       > The major problem is that I only have 3 cohorts (and so 3
> > > > >      temperatures).
> > > > >       >  From the first model I am able to get the information,
> but from
> > > > >      the second
> > > > >       > one there is an error message: "Model failed to converge
> with 1
> > > > >      negative
> > > > >       > eigenvalue: -2.0e+01". The error pops up probably because
> I have
> > > > >
> > > >
> > > > both
> > > >
> > > > >       > temperature (fixed) and cohort (random) included. Is my
> approach
> > > > >      correct?
> > > > >       > And is there a way to fix this error?
> > > > >       >
> > > > >       > Thank you so much for your time.
> > > > >       >
> > > > >       > Best regards,
> > > > >       > Amy Huang
> > > > >       >
> > > > >       >       [[alternative HTML version deleted]]
> > > > >       >
> > > > >       > _______________________________________________
> > > > >       > R-sig-mixed-models at r-project.org
> > > > >      <mailto:R-sig-mixed-models at r-project.org> mailing list
> > > > >       > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > > > >      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> > > > >       >
> > > > >
> > > > >      _______________________________________________
> > > > >      R-sig-mixed-models at r-project.org
> > > > >      <mailto:R-sig-mixed-models at r-project.org> mailing list
> > > > >      https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > > > >      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> > > > >
> > > >
> > > > R-sig-mixed-models at r-project.org mailing list
> > > >
> > > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >
> > > [[alternative HTML version deleted]]
> > >
> > > R-sig-mixed-models at r-project.org mailing list
> > >
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> > R-sig-mixed-models at r-project.org mailing list
> >
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Sun Jul  4 02:49:56 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sat, 3 Jul 2021 20:49:56 -0400
Subject: [R-sig-ME] Estimation of variance components in random- and
 mixed-effects models
In-Reply-To: <boE5pTz1kRk1UEaDwrCx4OwQFHa_SshZzBoqKjWRLraYlQ6BIoIdQHf5Bnm-C1Z7Ivy-sGeIj1rP4RD59ONVIvXSVkGRz-T9xoiVgqpSXmE=@protonmail.com>
References: <CAK2ikok__C0M9JduqEuqsmjOXETDewpX1pGDNTsXJvzpjYEC3g@mail.gmail.com>
 <327afce2-3e10-d179-b4ee-348e8232d74c@gmail.com>
 <CAJuCY5yRWNvvfBJk9Hk3oq8cUCS4L4iAu2nCu--Ams_6vLbDfw@mail.gmail.com>
 <c70f7035-df66-7a96-8656-87a7b0c75b2a@gmail.com>
 <CAK2ikom9AASV49ib1_ytD0KAZwSUMw+KY43RMniY8SAc4v5i1Q@mail.gmail.com>
 <ca93574d-ed1f-8934-85f8-ed1e233c590f@gmail.com>
 <boE5pTz1kRk1UEaDwrCx4OwQFHa_SshZzBoqKjWRLraYlQ6BIoIdQHf5Bnm-C1Z7Ivy-sGeIj1rP4RD59ONVIvXSVkGRz-T9xoiVgqpSXmE=@protonmail.com>
Message-ID: <26f04be8-8d12-9279-3806-2ecf2b48e8dd@gmail.com>

    Very briefly (and tentatively: someone should feel free to correct 
me if I got something wrong).

   Analysis of variance doesn't usually try to *estimate* the difference 
variance components, it just computes the mean sums of squares 
associated with different factors/levels, e.g.

 > summary(aov(angle ~ recipe/temperature/replicate, data = cake))
                               Df Sum Sq Mean Sq
recipe                         2    135   67.54
recipe:temperature            15   2306  153.75
recipe:temperature:replicate 252  15702   62.31

   These provide a framework for *testing the significance* of different 
components.  By avoiding explicit estimation, this avoids a lot of the 
problems of instability of estimates.  You will still generally have low 
power for a significance test against the null hypothesis that a 
particular variance component is zero ...

   In the variance decomposition/partitioning literature, *negative* 
variance components are the analog of the "what to do about singular 
fits?" conversation from mixed models. There is a big literature on neg

https://scholar.google.com/scholar?q="negative+variance+components"




On 7/3/21 10:59 AM, kalman.toth wrote:
> Sorry for butting into this conversation but there is something I cannot get my head around. I often encounter situation where B grouping variable is nested into A grouping variable. B has around 10-20 levels and A only has around 3-5. Conceptually, everything is a random effect. If my understanding is correct in this case I should use the following lmer model due to the limited number of levels of B:
> R ~ A+(1|B)
> Even though, scientifically R ~ (1|A/B) would make more sense.
> Variance of B of the first term is not equal to variance of A:B in the second.
> 
> I am most interested in a reasonable estimation on the variance of B while we know that it is nested in A.
> 
> In general, we use the classical ANOVA to do that: aov(R~A/B). This gives the same variance estimate for A:B interaction as lmer(R ~ (1|A/B)) if it the design is relatively well balanced. In a way I am not surprised because the Cross Validated post suggested by Ben Bolker also mentions that in this case mixed effect model behaves similarly to classical ones. But does it mean that this  ANOVA variance estimate is also biased/unreliable? Would the variance estimation of B from the first lmer model really be a better estimation?
> 
> Best Regards,
> Kalman Toth
> 
> Sent with ProtonMail Secure Email.
> 
> ??????? Original Message ???????
> 
> On Tuesday, June 29th, 2021 at 2:12 AM, Ben Bolker <bbolker at gmail.com> wrote:
> 
>> A couple of quick responses.
>>
>> -   I don't recommend dropping non-significant predictors, this is a
>>
>>      good way to overfit models.
>> -   Are the temperatures for your three cohorts in a strictly linear
>>
>>      sequence? i.e., temperature (cohort 1) = T1, temp (2) = T1 + delta, temp
>>
>>      (3) = T1 + 2*delta ? In that case, the two effects are indeed
>>
>>      identical/confounded. In principle, your original model (using cohort
>>
>>      as a random effect and temperature as fixed) is the right way to handle
>>
>>      this, but for the size of data set you can't really identify
>>
>>      among-cohort variation beyond the effect of temperature.
>>
>>      A nice way to handle this is to treat cohort as an ordered
>>
>>      categorical fixed effect (see ?ordered), and leave out temperature (this
>>
>>      is assuming that the temperatures are as suggested above). If you do
>>
>>      this (i.e. convert cohort to 'ordered' type), R will fit two parameters,
>>
>>      one labeled .L and the other labeled .Q, which together explain all of
>>
>>      the among-cohort variation; if you like (although it is quite a big
>>
>>      assumption, and you must be explicit about it), you can ascribe the
>>
>>      linear (".L") variation to temperature and the other (".Q" or quadratic)
>>
>>      to non-temperature effects. However, given your experimental design,
>>
>>      the following two explanations would be equally well supported:
>> -   none of the between-cohort variation is due to temperature;
>> -   temperature has a quadratic effect, so all of the between-cohort
>>
>>      variation is due to temperature.
>>
>>      cheers
>>
>>      Ben Bolker
>>
>>      On 6/28/21 3:20 PM, Amy Huang wrote:
>>
>>> Thank you very much for your responses and references. Sorry that I missed
>>>
>>> mentioning a lot of information.
>>>
>>> I am using lme4, and the fixed predictors are all numeric. Only having 3
>>>
>>> levels of cohorts is indeed the major issue. After removing insignificant
>>>
>>> predictors in the 2nd model, the only factor left is temperature: offspring
>>>
>>> trait ~ temperature + (1 | cohort/female/clutch), which gives the
>>>
>>> convergence warning.
>>>
>>> Now I treat cohort as a fixed effect, but when I include both cohort and
>>>
>>> temperature as fixed effects (in the 2nd model), a warning appears:
>>>
>>> "fixed-effect model matrix is rank deficient so dropping 1 column /
>>>
>>> coefficient". When I remove cohort (2nd model), the two models become very
>>>
>>> similar and give similar results.
>>>
>>> offspring trait ~ cohort + (1 | female/clutch)
>>>
>>> offspring trait ~ temperature + (1 | female/clutch)
>>>
>>> But am I not introducing pseudoreplicates if I do not include cohort as a
>>>
>>> factor?
>>>
>>> PS. The section "How do I compute a coefficient of determination (R2), or
>>>
>>> an analogue, for (G)LMMs?" in the GLMM FAQ also gives me some insight.
>>>
>>> However, the links provided there seem to be not working.
>>>
>>> Best regards,
>>>
>>> Amy Huang
>>>
>>> Am Mo., 28. Juni 2021 um 19:32 Uhr schrieb Ben Bolker bbolker at gmail.com:
>>>
>>>>      See also:
>>>>
>>>>
>>>> https://stats.stackexchange.com/questions/37647/what-is-the-minimum-recommended-number-of-groups-for-a-random-effects-factor
>>>>
>>>> https://www.biorxiv.org/content/10.1101/2021.05.03.442487v2
>>>>
>>>> (I should these links, and the blog post link, to the GLMM FAQ ...)
>>>>
>>>> On 6/28/21 1:17 PM, Thierry Onkelinx wrote:
>>>>
>>>>> Another issue is that you have too few levels to fit "cohort" as a
>>>>>
>>>>> random effect. I wrote a blogpost on this a few years ago:
>>>>>
>>>>> https://www.muscardinus.be/2018/09/number-random-effect-levels/
>>>>>
>>>>> https://www.muscardinus.be/2018/09/number-random-effect-levels/
>>>>>
>>>>> Best regards,
>>>>>
>>>>> ir. Thierry Onkelinx
>>>>>
>>>>> Statisticus / Statistician
>>>>>
>>>>> Vlaamse Overheid / Government of Flanders
>>>>>
>>>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>>>>>
>>>>> AND FOREST
>>>>>
>>>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>>>>
>>>>> thierry.onkelinx at inbo.be mailto:thierry.onkelinx at inbo.be
>>>>>
>>>>> Havenlaan 88 bus 73, 1000 Brussel
>>>>>
>>>>> www.inbo.be http://www.inbo.be
>>>>
>>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>>
>>>>> To call in the statistician after the experiment is done may be no more
>>>>>
>>>>> than asking him to perform a post-mortem examination: he may be able to
>>>>>
>>>>> say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>>>
>>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>>>
>>>>> The combination of some data and an aching desire for an answer does not
>>>>>
>>>>> ensure that a reasonable answer can be extracted from a given body of
>>>>>
>>>>> data. ~ John Tukey
>>>>
>>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>>
>>>>> https://www.inbo.be
>>>>>
>>>>> Op ma 28 jun. 2021 om 16:31 schreef Ben Bolker <bbolker at gmail.com
>>>>>
>>>>> mailto:bbolker at gmail.com>:
>>>>>
>>>>>           Are you using lme4? (I'm 99% sure you are, but it's good to be
>>>>>       explicit.)
>>>>>
>>>>>           Are all of your fixed predictors numeric (rather than
>>>>>       factor/categorical) ?
>>>>>
>>>>>           Note that a convergence warning is a *warning*, not an error:
>>>>>
>>>>
>>>> have
>>>>
>>>>>       you checked the troubleshooting steps in ?lme4::convergence (in
>>>>>       particular, scaling and centering your predictor variables might
>>>>>       help ...)
>>>>>
>>>>>           cheers
>>>>>            Ben Bolker
>>>>>
>>>>>
>>>>>       On 6/28/21 10:17 AM, Amy Huang wrote:
>>>>>        > Dear all,
>>>>>        >
>>>>>        > I am examining maternal effects, and my data have three hierarchy
>>>>>       levels:
>>>>>        > clutches of the same female, females, and cohorts. My explanatory
>>>>>       variables
>>>>>        > are at the female level (female length, age) and at the cohort
>>>>>
>>>>
>>>> level
>>>>
>>>>>        > (temperature).
>>>>>        >
>>>>>        > I would like to estimate the variance components of each
>>>>>       hierarchy level
>>>>>        > (i.e. relative amount of variance at each level) and then to find
>>>>>       out which
>>>>>        > factors (female length, age, temperature) explain most of the
>>>>>       variance. For
>>>>>        > these, I have two models:
>>>>>        >      offspring trait ~ 1 + (1 | cohort/female/clutch)
>>>>>        >      offspring trait ~ temperature + female length + age + (1 |
>>>>>        > cohort/female/clutch)
>>>>>        >
>>>>>        > The major problem is that I only have 3 cohorts (and so 3
>>>>>       temperatures).
>>>>>        >  From the first model I am able to get the information, but from
>>>>>       the second
>>>>>        > one there is an error message: "Model failed to converge with 1
>>>>>       negative
>>>>>        > eigenvalue: -2.0e+01". The error pops up probably because I have
>>>>>
>>>>
>>>> both
>>>>
>>>>>        > temperature (fixed) and cohort (random) included. Is my approach
>>>>>       correct?
>>>>>        > And is there a way to fix this error?
>>>>>        >
>>>>>        > Thank you so much for your time.
>>>>>        >
>>>>>        > Best regards,
>>>>>        > Amy Huang
>>>>>        >
>>>>>        >       [[alternative HTML version deleted]]
>>>>>        >
>>>>>        > _______________________________________________
>>>>>        > R-sig-mixed-models at r-project.org
>>>>>       <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>>>        > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>        >
>>>>>
>>>>>       _______________________________________________
>>>>>       R-sig-mixed-models at r-project.org
>>>>>       <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>>>       https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>
>>>>
>>>> R-sig-mixed-models at r-project.org mailing list
>>>>
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>> [[alternative HTML version deleted]]
>>>
>>> R-sig-mixed-models at r-project.org mailing list
>>>
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> R-sig-mixed-models at r-project.org mailing list
>>
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics


From |@brun@ @end|ng |rom udc@e@  Sun Jul  4 18:19:37 2021
From: |@brun@ @end|ng |rom udc@e@ (Fernando Pedro Bruna Quintas)
Date: Sun, 4 Jul 2021 16:19:37 +0000
Subject: [R-sig-ME] Methodological and practical issues about survey weights
 using lme4
Message-ID: <PR1PR02MB4889A9F703D90E4C097C6DC4921D9@PR1PR02MB4889.eurprd02.prod.outlook.com>



Dear list members,

I have two questions about the use of survey weights in multilevel models.

I have estimated a multilevel model about the effects of individual and cultural variables in well-being, using the European Social Survey. By ?culture? I mean national aggregates of my level-1 indicators. Think of Yij as an indicator of wellbeing, Xij as an indicator of being individualistic (for instance) and Xj as the sample country mean of individualism, representing the degree of individualism in a national culture (contextual effect).

I have estimated the following simplified model:
lmer( Yij  ~ (Xij-Xj) + Xj + (1 | country) ) , data=databank)

A referee makes me the following comment: ?Post stratication weights at individual level and at the higher-level national variables is a relevant issue. This issue of importance on MLM context as Stata instructions note https://www.stata.com/features/overview/multilevel-models-with-survey-data/. The authors seem to be using R but I would assume it includes similar options to include weights to all levels of the analysis. The literature on MLM includes recommendations for Fitting multilevel models in complex survey data with design weights and this needs to be referred and selection of weights justified.?

The information about weights in the survey I am using is in the following link:
https://www.europeansocialsurvey.org/methodology/ess_methodology/data_processing_archiving/weighting.html

My questions are the following:

  1.  A first questions is about general methodology, though applied to the analysis of the effects of level-two variables. I would appreciate references or links about when is appropriate to use survey weights, depending on the research question. I have data on 23 countries. My goal is to measure the effects of level-two (cultural variables). Therefore, I am not so much interested on concluding about big countries (Russia has 145 million of people!). I need variance to differentiate cultural effects in Belgium, Netherlands... However, If I do not use weights my conclusions are only about the particular sample published by the European Social Survey. Any thought?
  2.  Apart from that, and more generally for any other study, I would appreciate comments and references about using survey weights in lme4. I understand that I would have to change the calculation of all may level-one variables, which are defined as deviations to the national means. Additionally, I must consider reweighting national means of those variables, as well as other level-two variables. The estimation procedure has to be weighted... I would appreciate any practical comment about weighted estimation using survey data and lme4.

Thank you very much,

Fernando Bruna
Department of Economics
University of A Corunha (Coru?a), Spain


	[[alternative HTML version deleted]]


From jepu@to @end|ng |rom gm@||@com  Mon Jul  5 01:02:32 2021
From: jepu@to @end|ng |rom gm@||@com (James Pustejovsky)
Date: Sun, 4 Jul 2021 18:02:32 -0500
Subject: [R-sig-ME] 
 Methodological and practical issues about survey weights using lme4
In-Reply-To: <PR1PR02MB4889A9F703D90E4C097C6DC4921D9@PR1PR02MB4889.eurprd02.prod.outlook.com>
References: <PR1PR02MB4889A9F703D90E4C097C6DC4921D9@PR1PR02MB4889.eurprd02.prod.outlook.com>
Message-ID: <036E18B5-EBE3-4471-9FCA-BF6D22930468@gmail.com>

My understanding is that lme4 does not accommodate survey weights. But check out the WeMix package for an alternative: https://cran.r-project.org/package=WeMix

I learned about WeMix when I posted a query on Twitter very similar to your question (https://twitter.com/jepusto/status/1408084119884599299?s=21).

Kind Regards,
James

> On Jul 4, 2021, at 11:20 AM, Fernando Pedro Bruna Quintas <f.bruna at udc.es> wrote:
> 
> ?
> 
> Dear list members,
> 
> I have two questions about the use of survey weights in multilevel models.
> 
> I have estimated a multilevel model about the effects of individual and cultural variables in well-being, using the European Social Survey. By ?culture? I mean national aggregates of my level-1 indicators. Think of Yij as an indicator of wellbeing, Xij as an indicator of being individualistic (for instance) and Xj as the sample country mean of individualism, representing the degree of individualism in a national culture (contextual effect).
> 
> I have estimated the following simplified model:
> lmer( Yij  ~ (Xij-Xj) + Xj + (1 | country) ) , data=databank)
> 
> A referee makes me the following comment: ?Post stratication weights at individual level and at the higher-level national variables is a relevant issue. This issue of importance on MLM context as Stata instructions note https://www.stata.com/features/overview/multilevel-models-with-survey-data/. The authors seem to be using R but I would assume it includes similar options to include weights to all levels of the analysis. The literature on MLM includes recommendations for Fitting multilevel models in complex survey data with design weights and this needs to be referred and selection of weights justified.?
> 
> The information about weights in the survey I am using is in the following link:
> https://www.europeansocialsurvey.org/methodology/ess_methodology/data_processing_archiving/weighting.html
> 
> My questions are the following:
> 
>  1.  A first questions is about general methodology, though applied to the analysis of the effects of level-two variables. I would appreciate references or links about when is appropriate to use survey weights, depending on the research question. I have data on 23 countries. My goal is to measure the effects of level-two (cultural variables). Therefore, I am not so much interested on concluding about big countries (Russia has 145 million of people!). I need variance to differentiate cultural effects in Belgium, Netherlands... However, If I do not use weights my conclusions are only about the particular sample published by the European Social Survey. Any thought?
>  2.  Apart from that, and more generally for any other study, I would appreciate comments and references about using survey weights in lme4. I understand that I would have to change the calculation of all may level-one variables, which are defined as deviations to the national means. Additionally, I must consider reweighting national means of those variables, as well as other level-two variables. The estimation procedure has to be weighted... I would appreciate any practical comment about weighted estimation using survey data and lme4.
> 
> Thank you very much,
> 
> Fernando Bruna
> Department of Economics
> University of A Corunha (Coru?a), Spain
> 
> 
>    [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From |@brun@ @end|ng |rom udc@e@  Mon Jul  5 11:42:19 2021
From: |@brun@ @end|ng |rom udc@e@ (Fernando Pedro Bruna Quintas)
Date: Mon, 5 Jul 2021 09:42:19 +0000
Subject: [R-sig-ME] 
 Methodological and practical issues about survey weights using lme4
In-Reply-To: <036E18B5-EBE3-4471-9FCA-BF6D22930468@gmail.com>
References: <PR1PR02MB4889A9F703D90E4C097C6DC4921D9@PR1PR02MB4889.eurprd02.prod.outlook.com>,
 <036E18B5-EBE3-4471-9FCA-BF6D22930468@gmail.com>
Message-ID: <PR1PR02MB4889C670A69ABE63567A1BC5921C9@PR1PR02MB4889.eurprd02.prod.outlook.com>

Dear James and list members,

Thank you very much for pointing me out to WeMix. That is a very interesting package. As an aside, I still do not understand why we might need clustered standard errors in multilevel models, as in WeMix or Stata (I would appreciate any thought). However, let me go back to my original question.

I am realizing that I do not need level-two weights. My level two are European countries. That is not a sample, but all the available countries. Therefore, I do not need level-two weights, as in the case of a random sample of schools. I may use the argument weights in lmer() to consider level-one weights. However, I would appreciate a confirmation of that, given that there has been some discussion in internet about this option in lme4 package. I am considering using the survey weights and transform them to sum to 1 in my sample after ignoring missing data. Is this right?

My other question was more general. I am studying contextual effect. I understand that if I use weights I will give more importance to big countries. However, the analysis of contextual (cultural) effect might require ignoring weights, in order to give more importance to small countries. Any thought?

I know that the discussion about weights is deep and there are dozens of internet links about that. Therefore, I apologize to ask again about this confusing topic. I would be grateful for some advice.


Thanks again,

Fernando


________________________________
De: James Pustejovsky <jepusto at gmail.com>
Enviado: lunes, 5 de julio de 2021 1:02
Para: Fernando Pedro Bruna Quintas <f.bruna at udc.es>
Cc: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Asunto: Re: [R-sig-ME] Methodological and practical issues about survey weights using lme4

My understanding is that lme4 does not accommodate survey weights. But check out the WeMix package for an alternative: https://cran.r-project.org/package=WeMix

I learned about WeMix when I posted a query on Twitter very similar to your question (https://twitter.com/jepusto/status/1408084119884599299?s=21).

Kind Regards,
James

On Jul 4, 2021, at 11:20 AM, Fernando Pedro Bruna Quintas <f.bruna at udc.es> wrote:

?

Dear list members,

I have two questions about the use of survey weights in multilevel models.

I have estimated a multilevel model about the effects of individual and cultural variables in well-being, using the European Social Survey. By ?culture? I mean national aggregates of my level-1 indicators. Think of Yij as an indicator of wellbeing, Xij as an indicator of being individualistic (for instance) and Xj as the sample country mean of individualism, representing the degree of individualism in a national culture (contextual effect).

I have estimated the following simplified model:
lmer( Yij  ~ (Xij-Xj) + Xj + (1 | country) ) , data=databank)

A referee makes me the following comment: ?Post stratication weights at individual level and at the higher-level national variables is a relevant issue. This issue of importance on MLM context as Stata instructions note https://www.stata.com/features/overview/multilevel-models-with-survey-data/. The authors seem to be using R but I would assume it includes similar options to include weights to all levels of the analysis. The literature on MLM includes recommendations for Fitting multilevel models in complex survey data with design weights and this needs to be referred and selection of weights justified.?

The information about weights in the survey I am using is in the following link:
https://www.europeansocialsurvey.org/methodology/ess_methodology/data_processing_archiving/weighting.html

My questions are the following:

 1.  A first questions is about general methodology, though applied to the analysis of the effects of level-two variables. I would appreciate references or links about when is appropriate to use survey weights, depending on the research question. I have data on 23 countries. My goal is to measure the effects of level-two (cultural variables). Therefore, I am not so much interested on concluding about big countries (Russia has 145 million of people!). I need variance to differentiate cultural effects in Belgium, Netherlands... However, If I do not use weights my conclusions are only about the particular sample published by the European Social Survey. Any thought?
 2.  Apart from that, and more generally for any other study, I would appreciate comments and references about using survey weights in lme4. I understand that I would have to change the calculation of all may level-one variables, which are defined as deviations to the national means. Additionally, I must consider reweighting national means of those variables, as well as other level-two variables. The estimation procedure has to be weighted... I would appreciate any practical comment about weighted estimation using survey data and lme4.

Thank you very much,

Fernando Bruna
Department of Economics
University of A Corunha (Coru?a), Spain


   [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From jepu@to @end|ng |rom gm@||@com  Mon Jul  5 19:19:46 2021
From: jepu@to @end|ng |rom gm@||@com (James Pustejovsky)
Date: Mon, 5 Jul 2021 12:19:46 -0500
Subject: [R-sig-ME] 
 Methodological and practical issues about survey weights using lme4
In-Reply-To: <PR1PR02MB4889C670A69ABE63567A1BC5921C9@PR1PR02MB4889.eurprd02.prod.outlook.com>
References: <PR1PR02MB4889C670A69ABE63567A1BC5921C9@PR1PR02MB4889.eurprd02.prod.outlook.com>
Message-ID: <98D0DC2D-1224-488F-B3EB-97CB3B30EB13@gmail.com>

Fernando,

Again, I think lmer does not handle survey weights, even at level 1. The weights argument is for precision weights (not sampling weights). From ?lmer: "The diagonal of the residual covariance matrix is the squared residual standard deviation parameter sigma times the vector of inverse weights."

If your analysis is about relating country-level features to country-level predictors, and you are unsure about an appropriate weighting strategy, then perhaps you could simplify things by aggregating to the country level. You could use the (level-1) survey weights to generate estimates of the population mean outcome in each country, along with a sampling variance for each country?s estimate. Then estimate the country level regression, or use meta-regression to account for the different sampling variances of the estimates from each country.

James

> On Jul 5, 2021, at 4:42 AM, Fernando Pedro Bruna Quintas <f.bruna at udc.es> wrote:
> 
> ?
> Dear James and list members, 
>  
> Thank you very much for pointing me out to WeMix. That is a very interesting package. As an aside, I still do not understand why we might need clustered standard errors in multilevel models, as in WeMix or Stata (I would appreciate any thought). However, let me go back to my original question. 
>  
> I am realizing that I do not need level-two weights. My level two are European countries. That is not a sample, but all the available countries. Therefore, I do not need level-two weights, as in the case of a random sample of schools. I may use the argument weights in lmer() to consider level-one weights. However, I would appreciate a confirmation of that, given that there has been some discussion in internet about this option in lme4 package. I am considering using the survey weights and transform them to sum to 1 in my sample after ignoring missing data. Is this right? 
>  
> My other question was more general. I am studying contextual effect. I understand that if I use weights I will give more importance to big countries. However, the analysis of contextual (cultural) effect might require ignoring weights, in order to give more importance to small countries. Any thought? 
>  
> I know that the discussion about weights is deep and there are dozens of internet links about that. Therefore, I apologize to ask again about this confusing topic. I would be grateful for some advice. 
>  
>  
> Thanks again, 
>  
> Fernando 
> 
> 
> De: James Pustejovsky <jepusto at gmail.com>
> Enviado: lunes, 5 de julio de 2021 1:02
> Para: Fernando Pedro Bruna Quintas <f.bruna at udc.es>
> Cc: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
> Asunto: Re: [R-sig-ME] Methodological and practical issues about survey weights using lme4
>  
> My understanding is that lme4 does not accommodate survey weights. But check out the WeMix package for an alternative: https://cran.r-project.org/package=WeMix
> 
> I learned about WeMix when I posted a query on Twitter very similar to your question (https://twitter.com/jepusto/status/1408084119884599299?s=21).
> 
> Kind Regards,
> James
> 
>>> On Jul 4, 2021, at 11:20 AM, Fernando Pedro Bruna Quintas <f.bruna at udc.es> wrote:
>>> 
>> ?
>> 
>> Dear list members,
>> 
>> I have two questions about the use of survey weights in multilevel models.
>> 
>> I have estimated a multilevel model about the effects of individual and cultural variables in well-being, using the European Social Survey. By ?culture? I mean national aggregates of my level-1 indicators. Think of Yij as an indicator of wellbeing, Xij as an indicator of being individualistic (for instance) and Xj as the sample country mean of individualism, representing the degree of individualism in a national culture (contextual effect).
>> 
>> I have estimated the following simplified model:
>> lmer( Yij  ~ (Xij-Xj) + Xj + (1 | country) ) , data=databank)
>> 
>> A referee makes me the following comment: ?Post stratication weights at individual level and at the higher-level national variables is a relevant issue. This issue of importance on MLM context as Stata instructions note https://www.stata.com/features/overview/multilevel-models-with-survey-data/. The authors seem to be using R but I would assume it includes similar options to include weights to all levels of the analysis. The literature on MLM includes recommendations for Fitting multilevel models in complex survey data with design weights and this needs to be referred and selection of weights justified.?
>> 
>> The information about weights in the survey I am using is in the following link:
>> https://www.europeansocialsurvey.org/methodology/ess_methodology/data_processing_archiving/weighting.html
>> 
>> My questions are the following:
>> 
>>  1.  A first questions is about general methodology, though applied to the analysis of the effects of level-two variables. I would appreciate references or links about when is appropriate to use survey weights, depending on the research question. I have data on 23 countries. My goal is to measure the effects of level-two (cultural variables). Therefore, I am not so much interested on concluding about big countries (Russia has 145 million of people!). I need variance to differentiate cultural effects in Belgium, Netherlands... However, If I do not use weights my conclusions are only about the particular sample published by the European Social Survey. Any thought?
>>  2.  Apart from that, and more generally for any other study, I would appreciate comments and references about using survey weights in lme4. I understand that I would have to change the calculation of all may level-one variables, which are defined as deviations to the national means. Additionally, I must consider reweighting national means of those variables, as well as other level-two variables. The estimation procedure has to be weighted... I would appreciate any practical comment about weighted estimation using survey data and lme4.
>> 
>> Thank you very much,
>> 
>> Fernando Bruna
>> Department of Economics
>> University of A Corunha (Coru?a), Spain
>> 
>> 
>>    [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From |@brun@ @end|ng |rom udc@e@  Tue Jul  6 10:23:43 2021
From: |@brun@ @end|ng |rom udc@e@ (Fernando Pedro Bruna Quintas)
Date: Tue, 6 Jul 2021 08:23:43 +0000
Subject: [R-sig-ME] 
 Methodological and practical issues about survey weights using lme4
In-Reply-To: <98D0DC2D-1224-488F-B3EB-97CB3B30EB13@gmail.com>
References: <PR1PR02MB4889C670A69ABE63567A1BC5921C9@PR1PR02MB4889.eurprd02.prod.outlook.com>,
 <98D0DC2D-1224-488F-B3EB-97CB3B30EB13@gmail.com>
Message-ID: <DB7PR02MB488883782FD0BB975278234B921B9@DB7PR02MB4888.eurprd02.prod.outlook.com>


Thank you very much James.

Indeed that argument in lmer() is confusing, considering that in many other funtions in R a weights argument is used with a different meaning.

I do not want to aggregate my data at the country level (ecological regression). As I mentioned, I am interested on contextual effects for individual data. Think of Yij as an indicator of wellbeing, Xij as an indicator of being individualistic (for instance) and Xj as the sample country mean of individualism, representing the degree of individualism in a national culture (contextual effect). I have estimated the following simplified model:
lmer( Yij  ~ (Xij-Xj) + Xj + (1 | country) ) , data=databank)

Therere, I am going to try WeMix, setting the level 1 weights to the survey weights and the level 2 weights to 1, given that my level 2 data is for the total population of countries in Europe.

Thanks again,

Fernando

________________________________
De: James Pustejovsky <jepusto at gmail.com>
Enviado: lunes, 5 de julio de 2021 19:19
Para: Fernando Pedro Bruna Quintas <f.bruna at udc.es>
Cc: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Asunto: Re: [R-sig-ME] Methodological and practical issues about survey weights using lme4

Fernando,

Again, I think lmer does not handle survey weights, even at level 1. The weights argument is for precision weights (not sampling weights). From ?lmer: "The diagonal of the residual covariance matrix is the squared residual standard deviation parameter sigma times the vector of inverse weights."

If your analysis is about relating country-level features to country-level predictors, and you are unsure about an appropriate weighting strategy, then perhaps you could simplify things by aggregating to the country level. You could use the (level-1) survey weights to generate estimates of the population mean outcome in each country, along with a sampling variance for each country?s estimate. Then estimate the country level regression, or use meta-regression to account for the different sampling variances of the estimates from each country.

James

On Jul 5, 2021, at 4:42 AM, Fernando Pedro Bruna Quintas <f.bruna at udc.es> wrote:

?

Dear James and list members,



Thank you very much for pointing me out to WeMix. That is a very interesting package. As an aside, I still do not understand why we might need clustered standard errors in multilevel models, as in WeMix or Stata (I would appreciate any thought). However, let me go back to my original question.



I am realizing that I do not need level-two weights. My level two are European countries. That is not a sample, but all the available countries. Therefore, I do not need level-two weights, as in the case of a random sample of schools. I may use the argument weights in lmer() to consider level-one weights. However, I would appreciate a confirmation of that, given that there has been some discussion in internet about this option in lme4 package. I am considering using the survey weights and transform them to sum to 1 in my sample after ignoring missing data. Is this right?



My other question was more general. I am studying contextual effect. I understand that if I use weights I will give more importance to big countries. However, the analysis of contextual (cultural) effect might require ignoring weights, in order to give more importance to small countries. Any thought?



I know that the discussion about weights is deep and there are dozens of internet links about that. Therefore, I apologize to ask again about this confusing topic. I would be grateful for some advice.





Thanks again,



Fernando


________________________________
De: James Pustejovsky <jepusto at gmail.com>
Enviado: lunes, 5 de julio de 2021 1:02
Para: Fernando Pedro Bruna Quintas <f.bruna at udc.es>
Cc: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Asunto: Re: [R-sig-ME] Methodological and practical issues about survey weights using lme4

My understanding is that lme4 does not accommodate survey weights. But check out the WeMix package for an alternative: https://cran.r-project.org/package=WeMix

I learned about WeMix when I posted a query on Twitter very similar to your question (https://twitter.com/jepusto/status/1408084119884599299?s=21).

Kind Regards,
James

On Jul 4, 2021, at 11:20 AM, Fernando Pedro Bruna Quintas <f.bruna at udc.es> wrote:

?

Dear list members,

I have two questions about the use of survey weights in multilevel models.

I have estimated a multilevel model about the effects of individual and cultural variables in well-being, using the European Social Survey. By ?culture? I mean national aggregates of my level-1 indicators. Think of Yij as an indicator of wellbeing, Xij as an indicator of being individualistic (for instance) and Xj as the sample country mean of individualism, representing the degree of individualism in a national culture (contextual effect).

I have estimated the following simplified model:
lmer( Yij  ~ (Xij-Xj) + Xj + (1 | country) ) , data=databank)

A referee makes me the following comment: ?Post stratication weights at individual level and at the higher-level national variables is a relevant issue. This issue of importance on MLM context as Stata instructions note https://www.stata.com/features/overview/multilevel-models-with-survey-data/. The authors seem to be using R but I would assume it includes similar options to include weights to all levels of the analysis. The literature on MLM includes recommendations for Fitting multilevel models in complex survey data with design weights and this needs to be referred and selection of weights justified.?

The information about weights in the survey I am using is in the following link:
https://www.europeansocialsurvey.org/methodology/ess_methodology/data_processing_archiving/weighting.html

My questions are the following:

 1.  A first questions is about general methodology, though applied to the analysis of the effects of level-two variables. I would appreciate references or links about when is appropriate to use survey weights, depending on the research question. I have data on 23 countries. My goal is to measure the effects of level-two (cultural variables). Therefore, I am not so much interested on concluding about big countries (Russia has 145 million of people!). I need variance to differentiate cultural effects in Belgium, Netherlands... However, If I do not use weights my conclusions are only about the particular sample published by the European Social Survey. Any thought?
 2.  Apart from that, and more generally for any other study, I would appreciate comments and references about using survey weights in lme4. I understand that I would have to change the calculation of all may level-one variables, which are defined as deviations to the national means. Additionally, I must consider reweighting national means of those variables, as well as other level-two variables. The estimation procedure has to be weighted... I would appreciate any practical comment about weighted estimation using survey data and lme4.

Thank you very much,

Fernando Bruna
Department of Economics
University of A Corunha (Coru?a), Spain


   [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From @r|vo@r@ @end|ng |rom gm@||@com  Wed Jul  7 09:02:14 2021
From: @r|vo@r@ @end|ng |rom gm@||@com (Arivoara Rabarijaona)
Date: Wed, 7 Jul 2021 09:02:14 +0200
Subject: [R-sig-ME] Error in MEEM(object, conLin,
 control$niterEM) : Singularity in backsolve at level 0, block 1 in LME model
Message-ID: <CAGowLttckx6wzrLLsPyty8=ruywQsAGCD1zjyzDj3EGrJZEsgQ@mail.gmail.com>

Hi,
I hope someone can help me. I'm using nlme to fit models.

My dataframe (1785 obs) :
$ id: Factor w/595 levels
$ treatment: Factor w/3 levels
$ provenance: Factor w/16 levels
$ repetition: Factor w/4 levels
$ bloc: Factor w/66 levels # nested to repetition
$ response: num ... (1777 obs and 8 NA) # 3 repeated measures by id
$ status: Factor w/3 levels, "dominant","codominant","suppressed" # there
are 6 provenances without suppressed trees

I want to run a modele like this :

modele <- lme(response  ~ provenance + treatment + provenance:treatment +
status + status:treatment + statuts:provenance,
                   random = ~ 1|repetition/bloc,
                   correlation = corAR1(form = ~ 1|repetition/bloc/id),
                   data, method= "ML", na.action =na.omit)

I get the message :
Error in MEEM(object, conLin, control$niterEM) :   Singularity in backsolve
at level 0, block 1 in LME model

If I run the modele without the interaction statuts:provenance, it works.

Can anyone tell me how to resolve this error ?

Thanks,
Arivoara Rabarijaona

	[[alternative HTML version deleted]]


From romunov @end|ng |rom gm@||@com  Wed Jul  7 09:51:57 2021
From: romunov @end|ng |rom gm@||@com (romunov)
Date: Wed, 7 Jul 2021 09:51:57 +0200
Subject: [R-sig-ME] Error in MEEM(object, conLin,
 control$niterEM) : Singularity in backsolve at level 0, block 1 in LME model
In-Reply-To: <CAGowLttckx6wzrLLsPyty8=ruywQsAGCD1zjyzDj3EGrJZEsgQ@mail.gmail.com>
References: <CAGowLttckx6wzrLLsPyty8=ruywQsAGCD1zjyzDj3EGrJZEsgQ@mail.gmail.com>
Message-ID: <CAHT1vpjuBE5rCb44VYHdcqHt9ubp-Qv1NDk5zed2yDoTYrF=7g@mail.gmail.com>

Have you tried plotting this? My guess is that you will find something
unexpected in the provenance:treatment level combination.

Cheers,
Roman

On Wed, Jul 7, 2021 at 9:03 AM Arivoara Rabarijaona <arivoara at gmail.com>
wrote:

> Hi,
> I hope someone can help me. I'm using nlme to fit models.
>
> My dataframe (1785 obs) :
> $ id: Factor w/595 levels
> $ treatment: Factor w/3 levels
> $ provenance: Factor w/16 levels
> $ repetition: Factor w/4 levels
> $ bloc: Factor w/66 levels # nested to repetition
> $ response: num ... (1777 obs and 8 NA) # 3 repeated measures by id
> $ status: Factor w/3 levels, "dominant","codominant","suppressed" # there
> are 6 provenances without suppressed trees
>
> I want to run a modele like this :
>
> modele <- lme(response  ~ provenance + treatment + provenance:treatment +
> status + status:treatment + statuts:provenance,
>                    random = ~ 1|repetition/bloc,
>                    correlation = corAR1(form = ~ 1|repetition/bloc/id),
>                    data, method= "ML", na.action =na.omit)
>
> I get the message :
> Error in MEEM(object, conLin, control$niterEM) :   Singularity in backsolve
> at level 0, block 1 in LME model
>
> If I run the modele without the interaction statuts:provenance, it works.
>
> Can anyone tell me how to resolve this error ?
>
> Thanks,
> Arivoara Rabarijaona
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
In God we trust, all others bring data.

	[[alternative HTML version deleted]]


From @r|vo@r@ @end|ng |rom gm@||@com  Wed Jul  7 10:01:39 2021
From: @r|vo@r@ @end|ng |rom gm@||@com (Arivoara Rabarijaona)
Date: Wed, 7 Jul 2021 10:01:39 +0200
Subject: [R-sig-ME] Error in MEEM(object, conLin,
 control$niterEM) : Singularity in backsolve at level 0, block 1 in LME model
In-Reply-To: <CAHT1vpjuBE5rCb44VYHdcqHt9ubp-Qv1NDk5zed2yDoTYrF=7g@mail.gmail.com>
References: <CAGowLttckx6wzrLLsPyty8=ruywQsAGCD1zjyzDj3EGrJZEsgQ@mail.gmail.com>
 <CAHT1vpjuBE5rCb44VYHdcqHt9ubp-Qv1NDk5zed2yDoTYrF=7g@mail.gmail.com>
Message-ID: <CAGowLtvLhhBN3Y7F0A2N_XDkNaLiuFHO-nMD7skCcVL8UGfUpA@mail.gmail.com>

Thank you,
provenance:treatment is normal, nothing is unexpected
I think the problem is with provenance:status, but I don't know how to
resolve it.
Using lmer, I get the message: fixed-effect model matrix is rank deficient
so dropping 18 columns / coefficients

Ari

Le mer. 7 juil. 2021 ? 09:52, romunov <romunov at gmail.com> a ?crit :

> Have you tried plotting this? My guess is that you will find something
> unexpected in the provenance:treatment level combination.
>
> Cheers,
> Roman
>
> On Wed, Jul 7, 2021 at 9:03 AM Arivoara Rabarijaona <arivoara at gmail.com>
> wrote:
>
>> Hi,
>> I hope someone can help me. I'm using nlme to fit models.
>>
>> My dataframe (1785 obs) :
>> $ id: Factor w/595 levels
>> $ treatment: Factor w/3 levels
>> $ provenance: Factor w/16 levels
>> $ repetition: Factor w/4 levels
>> $ bloc: Factor w/66 levels # nested to repetition
>> $ response: num ... (1777 obs and 8 NA) # 3 repeated measures by id
>> $ status: Factor w/3 levels, "dominant","codominant","suppressed" # there
>> are 6 provenances without suppressed trees
>>
>> I want to run a modele like this :
>>
>> modele <- lme(response  ~ provenance + treatment + provenance:treatment +
>> status + status:treatment + statuts:provenance,
>>                    random = ~ 1|repetition/bloc,
>>                    correlation = corAR1(form = ~ 1|repetition/bloc/id),
>>                    data, method= "ML", na.action =na.omit)
>>
>> I get the message :
>> Error in MEEM(object, conLin, control$niterEM) :   Singularity in
>> backsolve
>> at level 0, block 1 in LME model
>>
>> If I run the modele without the interaction statuts:provenance, it works.
>>
>> Can anyone tell me how to resolve this error ?
>>
>> Thanks,
>> Arivoara Rabarijaona
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
> --
> In God we trust, all others bring data.
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Wed Jul  7 16:25:50 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 7 Jul 2021 10:25:50 -0400
Subject: [R-sig-ME] Error in MEEM(object, conLin,
 control$niterEM) : Singularity in backsolve at level 0, block 1 in LME model
In-Reply-To: <CAGowLtvLhhBN3Y7F0A2N_XDkNaLiuFHO-nMD7skCcVL8UGfUpA@mail.gmail.com>
References: <CAGowLttckx6wzrLLsPyty8=ruywQsAGCD1zjyzDj3EGrJZEsgQ@mail.gmail.com>
 <CAHT1vpjuBE5rCb44VYHdcqHt9ubp-Qv1NDk5zed2yDoTYrF=7g@mail.gmail.com>
 <CAGowLtvLhhBN3Y7F0A2N_XDkNaLiuFHO-nMD7skCcVL8UGfUpA@mail.gmail.com>
Message-ID: <fb64f28b-9287-3c4f-275c-b715caf1f391@gmail.com>

   You have constructed a model with multicollinear predictors (another 
way to put this is that your model matrix is rank-deficient).  R's 
formula interface usually takes care of discarding redundant columns, 
but when interactions are spelled out explicitly with it can't always 
manage. You might do better expressing the fixed effects component of 
the model as

(provenance + treatment + status)^2
'
As is often stated in this forum, you may have trouble fitting a random 
effect with only four levels (repetition).

   Ben Bolker

On 7/7/21 4:01 AM, Arivoara Rabarijaona wrote:
> Thank you,
> provenance:treatment is normal, nothing is unexpected
> I think the problem is with provenance:status, but I don't know how to
> resolve it.
> Using lmer, I get the message: fixed-effect model matrix is rank deficient
> so dropping 18 columns / coefficients
> 
> Ari
> 
> Le mer. 7 juil. 2021 ? 09:52, romunov <romunov at gmail.com> a ?crit :
> 
>> Have you tried plotting this? My guess is that you will find something
>> unexpected in the provenance:treatment level combination.
>>
>> Cheers,
>> Roman
>>
>> On Wed, Jul 7, 2021 at 9:03 AM Arivoara Rabarijaona <arivoara at gmail.com>
>> wrote:
>>
>>> Hi,
>>> I hope someone can help me. I'm using nlme to fit models.
>>>
>>> My dataframe (1785 obs) :
>>> $ id: Factor w/595 levels
>>> $ treatment: Factor w/3 levels
>>> $ provenance: Factor w/16 levels
>>> $ repetition: Factor w/4 levels
>>> $ bloc: Factor w/66 levels # nested to repetition
>>> $ response: num ... (1777 obs and 8 NA) # 3 repeated measures by id
>>> $ status: Factor w/3 levels, "dominant","codominant","suppressed" # there
>>> are 6 provenances without suppressed trees
>>>
>>> I want to run a modele like this :
>>>
>>> modele <- lme(response  ~ provenance + treatment + provenance:treatment +
>>> status + status:treatment + statuts:provenance,
>>>                     random = ~ 1|repetition/bloc,
>>>                     correlation = corAR1(form = ~ 1|repetition/bloc/id),
>>>                     data, method= "ML", na.action =na.omit)
>>>
>>> I get the message :
>>> Error in MEEM(object, conLin, control$niterEM) :   Singularity in
>>> backsolve
>>> at level 0, block 1 in LME model
>>>
>>> If I run the modele without the interaction statuts:provenance, it works.
>>>
>>> Can anyone tell me how to resolve this error ?
>>>
>>> Thanks,
>>> Arivoara Rabarijaona
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>> --
>> In God we trust, all others bring data.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From @r|vo@r@ @end|ng |rom gm@||@com  Wed Jul  7 17:20:31 2021
From: @r|vo@r@ @end|ng |rom gm@||@com (Arivoara Rabarijaona)
Date: Wed, 7 Jul 2021 17:20:31 +0200
Subject: [R-sig-ME] Error in MEEM(object, conLin,
 control$niterEM) : Singularity in backsolve at level 0, block 1 in LME model
In-Reply-To: <fb64f28b-9287-3c4f-275c-b715caf1f391@gmail.com>
References: <CAGowLttckx6wzrLLsPyty8=ruywQsAGCD1zjyzDj3EGrJZEsgQ@mail.gmail.com>
 <CAHT1vpjuBE5rCb44VYHdcqHt9ubp-Qv1NDk5zed2yDoTYrF=7g@mail.gmail.com>
 <CAGowLtvLhhBN3Y7F0A2N_XDkNaLiuFHO-nMD7skCcVL8UGfUpA@mail.gmail.com>
 <fb64f28b-9287-3c4f-275c-b715caf1f391@gmail.com>
Message-ID: <CAGowLttuGx-WQiGhrd6=VDWo8OLN2F0GE1M1qJmzEgJrrU=YJA@mail.gmail.com>

Thank you for your explanation. I really appreciate it.
However, there is no change using nlme (Error in MEEM(object, conLin,
control$niterEM) : Singularity in backsolve at level 0, block 1 in LME
model) and lmer (fixed-effect model matrix is rank deficient so dropping 6
columns / coefficients). My problem is not resolved.
There is a problem with repetition only when I use lmer model.

Arivoara Rabarijaona

Le mer. 7 juil. 2021 ? 16:26, Ben Bolker <bbolker at gmail.com> a ?crit :

>    You have constructed a model with multicollinear predictors (another
> way to put this is that your model matrix is rank-deficient).  R's
> formula interface usually takes care of discarding redundant columns,
> but when interactions are spelled out explicitly with it can't always
> manage. You might do better expressing the fixed effects component of
> the model as
>
> (provenance + treatment + status)^2
> '
> As is often stated in this forum, you may have trouble fitting a random
> effect with only four levels (repetition).
>
>    Ben Bolker
>
> On 7/7/21 4:01 AM, Arivoara Rabarijaona wrote:
> > Thank you,
> > provenance:treatment is normal, nothing is unexpected
> > I think the problem is with provenance:status, but I don't know how to
> > resolve it.
> > Using lmer, I get the message: fixed-effect model matrix is rank
> deficient
> > so dropping 18 columns / coefficients
> >
> > Ari
> >
> > Le mer. 7 juil. 2021 ? 09:52, romunov <romunov at gmail.com> a ?crit :
> >
> >> Have you tried plotting this? My guess is that you will find something
> >> unexpected in the provenance:treatment level combination.
> >>
> >> Cheers,
> >> Roman
> >>
> >> On Wed, Jul 7, 2021 at 9:03 AM Arivoara Rabarijaona <arivoara at gmail.com
> >
> >> wrote:
> >>
> >>> Hi,
> >>> I hope someone can help me. I'm using nlme to fit models.
> >>>
> >>> My dataframe (1785 obs) :
> >>> $ id: Factor w/595 levels
> >>> $ treatment: Factor w/3 levels
> >>> $ provenance: Factor w/16 levels
> >>> $ repetition: Factor w/4 levels
> >>> $ bloc: Factor w/66 levels # nested to repetition
> >>> $ response: num ... (1777 obs and 8 NA) # 3 repeated measures by id
> >>> $ status: Factor w/3 levels, "dominant","codominant","suppressed" #
> there
> >>> are 6 provenances without suppressed trees
> >>>
> >>> I want to run a modele like this :
> >>>
> >>> modele <- lme(response  ~ provenance + treatment +
> provenance:treatment +
> >>> status + status:treatment + statuts:provenance,
> >>>                     random = ~ 1|repetition/bloc,
> >>>                     correlation = corAR1(form = ~
> 1|repetition/bloc/id),
> >>>                     data, method= "ML", na.action =na.omit)
> >>>
> >>> I get the message :
> >>> Error in MEEM(object, conLin, control$niterEM) :   Singularity in
> >>> backsolve
> >>> at level 0, block 1 in LME model
> >>>
> >>> If I run the modele without the interaction statuts:provenance, it
> works.
> >>>
> >>> Can anyone tell me how to resolve this error ?
> >>>
> >>> Thanks,
> >>> Arivoara Rabarijaona
> >>>
> >>>          [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>
> >>
> >>
> >> --
> >> In God we trust, all others bring data.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From @r|vo@r@ @end|ng |rom gm@||@com  Wed Jul  7 17:37:13 2021
From: @r|vo@r@ @end|ng |rom gm@||@com (Arivoara Rabarijaona)
Date: Wed, 7 Jul 2021 17:37:13 +0200
Subject: [R-sig-ME] Error in MEEM(object, conLin,
 control$niterEM) : Singularity in backsolve at level 0, block 1 in LME model
In-Reply-To: <CAGowLttuGx-WQiGhrd6=VDWo8OLN2F0GE1M1qJmzEgJrrU=YJA@mail.gmail.com>
References: <CAGowLttckx6wzrLLsPyty8=ruywQsAGCD1zjyzDj3EGrJZEsgQ@mail.gmail.com>
 <CAHT1vpjuBE5rCb44VYHdcqHt9ubp-Qv1NDk5zed2yDoTYrF=7g@mail.gmail.com>
 <CAGowLtvLhhBN3Y7F0A2N_XDkNaLiuFHO-nMD7skCcVL8UGfUpA@mail.gmail.com>
 <fb64f28b-9287-3c4f-275c-b715caf1f391@gmail.com>
 <CAGowLttuGx-WQiGhrd6=VDWo8OLN2F0GE1M1qJmzEgJrrU=YJA@mail.gmail.com>
Message-ID: <CAGowLtsxtQxKaLzOwChvjsvg7pOnN4VK_jXcTxJjcNCwsPeR1Q@mail.gmail.com>

I can see my data in the attached file.

Arivoara Rabarijaona

Le mer. 7 juil. 2021 ? 17:20, Arivoara Rabarijaona <arivoara at gmail.com> a
?crit :

> Thank you for your explanation. I really appreciate it.
> However, there is no change using nlme (Error in MEEM(object, conLin,
> control$niterEM) : Singularity in backsolve at level 0, block 1 in LME
> model) and lmer (fixed-effect model matrix is rank deficient so dropping 6
> columns / coefficients). My problem is not resolved.
> There is a problem with repetition only when I use lmer model.
>
> Arivoara Rabarijaona
>
> Le mer. 7 juil. 2021 ? 16:26, Ben Bolker <bbolker at gmail.com> a ?crit :
>
>>    You have constructed a model with multicollinear predictors (another
>> way to put this is that your model matrix is rank-deficient).  R's
>> formula interface usually takes care of discarding redundant columns,
>> but when interactions are spelled out explicitly with it can't always
>> manage. You might do better expressing the fixed effects component of
>> the model as
>>
>> (provenance + treatment + status)^2
>> '
>> As is often stated in this forum, you may have trouble fitting a random
>> effect with only four levels (repetition).
>>
>>    Ben Bolker
>>
>> On 7/7/21 4:01 AM, Arivoara Rabarijaona wrote:
>> > Thank you,
>> > provenance:treatment is normal, nothing is unexpected
>> > I think the problem is with provenance:status, but I don't know how to
>> > resolve it.
>> > Using lmer, I get the message: fixed-effect model matrix is rank
>> deficient
>> > so dropping 18 columns / coefficients
>> >
>> > Ari
>> >
>> > Le mer. 7 juil. 2021 ? 09:52, romunov <romunov at gmail.com> a ?crit :
>> >
>> >> Have you tried plotting this? My guess is that you will find something
>> >> unexpected in the provenance:treatment level combination.
>> >>
>> >> Cheers,
>> >> Roman
>> >>
>> >> On Wed, Jul 7, 2021 at 9:03 AM Arivoara Rabarijaona <
>> arivoara at gmail.com>
>> >> wrote:
>> >>
>> >>> Hi,
>> >>> I hope someone can help me. I'm using nlme to fit models.
>> >>>
>> >>> My dataframe (1785 obs) :
>> >>> $ id: Factor w/595 levels
>> >>> $ treatment: Factor w/3 levels
>> >>> $ provenance: Factor w/16 levels
>> >>> $ repetition: Factor w/4 levels
>> >>> $ bloc: Factor w/66 levels # nested to repetition
>> >>> $ response: num ... (1777 obs and 8 NA) # 3 repeated measures by id
>> >>> $ status: Factor w/3 levels, "dominant","codominant","suppressed" #
>> there
>> >>> are 6 provenances without suppressed trees
>> >>>
>> >>> I want to run a modele like this :
>> >>>
>> >>> modele <- lme(response  ~ provenance + treatment +
>> provenance:treatment +
>> >>> status + status:treatment + statuts:provenance,
>> >>>                     random = ~ 1|repetition/bloc,
>> >>>                     correlation = corAR1(form = ~
>> 1|repetition/bloc/id),
>> >>>                     data, method= "ML", na.action =na.omit)
>> >>>
>> >>> I get the message :
>> >>> Error in MEEM(object, conLin, control$niterEM) :   Singularity in
>> >>> backsolve
>> >>> at level 0, block 1 in LME model
>> >>>
>> >>> If I run the modele without the interaction statuts:provenance, it
>> works.
>> >>>
>> >>> Can anyone tell me how to resolve this error ?
>> >>>
>> >>> Thanks,
>> >>> Arivoara Rabarijaona
>> >>>
>> >>>          [[alternative HTML version deleted]]
>> >>>
>> >>> _______________________________________________
>> >>> R-sig-mixed-models at r-project.org mailing list
>> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>>
>> >>
>> >>
>> >> --
>> >> In God we trust, all others bring data.
>> >>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

From Amirhossei@@Amirhossei@T@iebi m@iii@g oii r@dboudumc@@i  Wed Jul  7 17:41:15 2021
From: Amirhossei@@Amirhossei@T@iebi m@iii@g oii r@dboudumc@@i (Amirhossei@@Amirhossei@T@iebi m@iii@g oii r@dboudumc@@i)
Date: Wed, 7 Jul 2021 15:41:15 +0000
Subject: [R-sig-ME] FW: Time-Dependent Negative Binomial Regression
In-Reply-To: <ac4a53c402484b42b92e6869bf82c6d6@Umcexchp05.umcn.nl>
References: <996386d014b34f79bbf8840caf2dfd5c@Umcexchp05.umcn.nl>
 <1625215915432.68365@radboudumc.nl>
 <b5e7a334debb47d1a9c872f020ab3924@Umcexchp05.umcn.nl>
 <b8da9034f9ed440cbdf85c27e2311ab8@Umcexchp05.umcn.nl>
 <e247aa398d234aef9b516b50401bf12c@Umcexchp05.umcn.nl>
 <ac4a53c402484b42b92e6869bf82c6d6@Umcexchp05.umcn.nl>
Message-ID: <5a91e01b2b72412baf9fde5bfc3ef2dd@Umcexchp05.umcn.nl>

Dear responders,

I am a medical doctor and currently working on leveraging big data in healthcare as part of my PhD project in Radboudumc.

Recently, I have processed and cleaned a data for the aim of application of a negative binomial regression. First, I tried to use the function [glm.nb] of package ?MASS? in R and I had a problem with ensuring that the model will realize the data are for one unique participant (possible correlations in a group of observations). Then, I realized that I can use [glmmPQL] of package ?MASS? or [glmer] of package ?lme4? and use the family negative binomial in it?s family link. The question is I wanted to check whether I am on a right path using these functions, in addition I would like to know in which part of the model I can embed the offset (logarithm of the number of days of treatment) also how should I insert the time-constant observations for an id (such as gender and baseline age in the attached excel file)?

My latest try is:

[(glmmPQL (event ~ treatment + offset (log(person.time)) , random= list (id=~1, gender=~1, baseline.age=~1), family= negative.binomial (theta=1.75), data=df ))]

Kind regards and thank you for your time and consideration,

Amir

De informatie in dit bericht is uitsluitend bestemd voor de geadresseerde. Aan dit bericht en de bijlagen kunnen geen rechten worden ontleend. Heeft u deze e-mail onbedoeld ontvangen? Dan verzoeken wij u het te vernietigen en de afzender te informeren. Openbaar maken, kopi?ren en verspreiden van deze e-mail of informatie uit deze e-mail is alleen toegestaan met voorafgaande schriftelijke toestemming van de afzender. Het Radboudumc staat geregistreerd bij de Kamer van Koophandel in het handelsregister onder nummer 80262783.

The content of this message is intended solely for the addressee. No rights can be derived from this message or its attachments. If you are not the intended recipient, we kindly request you to delete the message and inform the sender. It is strictly prohibited to disclose, copy or distribute this email or the information inside it, without a written consent from the sender. Radboud university medical center is registered with the Dutch Chamber of Commerce trade register with number 80262783.

From bbo|ker @end|ng |rom gm@||@com  Thu Jul  8 01:46:57 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 7 Jul 2021 19:46:57 -0400
Subject: [R-sig-ME] Error in MEEM(object, conLin,
 control$niterEM) : Singularity in backsolve at level 0, block 1 in LME model
In-Reply-To: <CAGowLtsxtQxKaLzOwChvjsvg7pOnN4VK_jXcTxJjcNCwsPeR1Q@mail.gmail.com>
References: <CAGowLttckx6wzrLLsPyty8=ruywQsAGCD1zjyzDj3EGrJZEsgQ@mail.gmail.com>
 <CAHT1vpjuBE5rCb44VYHdcqHt9ubp-Qv1NDk5zed2yDoTYrF=7g@mail.gmail.com>
 <CAGowLtvLhhBN3Y7F0A2N_XDkNaLiuFHO-nMD7skCcVL8UGfUpA@mail.gmail.com>
 <fb64f28b-9287-3c4f-275c-b715caf1f391@gmail.com>
 <CAGowLttuGx-WQiGhrd6=VDWo8OLN2F0GE1M1qJmzEgJrrU=YJA@mail.gmail.com>
 <CAGowLtsxtQxKaLzOwChvjsvg7pOnN4VK_jXcTxJjcNCwsPeR1Q@mail.gmail.com>
Message-ID: <98bdbadd-7763-8094-6cb2-2b8a98330ad7@gmail.com>

    If expressing the model in the R-friendliest form doesn't resolve 
the problem, then you almost certainly have a *real* multicollinearity 
problem, which in turn is almost certainly driven by combinations of 
factors that are missing from your data set (e.g. if you have provenance 
A, B, C and treatment a, b, c and the combination {provenance = A, 
treatment = a} doesn't occur in your data set, then your model matrix is 
multicollinear/unidentifiable.

   Some options:

  * fit in lme4 or another package that automatically handles 
multicollinear terms.  Looking at the mixed model comparison table 
<https://docs.google.com/spreadsheets/d/19itelYaVW0U0gtNtRfqh76ZGt1awlamNcJwT71u_5Uk/edit#gid=0>, 
if you want an AR1 model *and* automatic rank deficiency, you might need 
the INLA package (off-CRAN) ...

* You can construct the model matrix manually and drop collinear terms 
yourself: at least one example is given here: 
https://github.com/glmmTMB/glmmTMB/issues/522

* you can expand the two-way interaction manually and build a one-way model.

   I don't know how to interpret "There is a problem with repetition 
only when I use lmer model".

   cheers
    Ben Bolker



On 7/7/21 11:37 AM, Arivoara Rabarijaona wrote:
> I can see my data in the attached file.
> 
> Arivoara Rabarijaona
> 
> Le?mer. 7 juil. 2021 ??17:20, Arivoara Rabarijaona <arivoara at gmail.com 
> <mailto:arivoara at gmail.com>> a ?crit?:
> 
>     Thank you for your explanation. I really appreciate it.
>     However, there is no change using nlme (Error in MEEM(object,
>     conLin, control$niterEM) : Singularity in backsolve at level 0,
>     block 1 in LME model) and lmer (fixed-effect model matrix is rank
>     deficient so dropping 6 columns / coefficients). My problem is not
>     resolved.
>     There is a problem with repetition only when I use lmer model.
> 
>     Arivoara Rabarijaona
> 
>     Le?mer. 7 juil. 2021 ??16:26, Ben Bolker <bbolker at gmail.com
>     <mailto:bbolker at gmail.com>> a ?crit?:
> 
>          ? ?You have constructed a model with multicollinear predictors
>         (another
>         way to put this is that your model matrix is rank-deficient).? R's
>         formula interface usually takes care of discarding redundant
>         columns,
>         but when interactions are spelled out explicitly with it can't
>         always
>         manage. You might do better expressing the fixed effects
>         component of
>         the model as
> 
>         (provenance + treatment + status)^2
>         '
>         As is often stated in this forum, you may have trouble fitting a
>         random
>         effect with only four levels (repetition).
> 
>          ? ?Ben Bolker
> 
>         On 7/7/21 4:01 AM, Arivoara Rabarijaona wrote:
>          > Thank you,
>          > provenance:treatment is normal, nothing is unexpected
>          > I think the problem is with provenance:status, but I don't
>         know how to
>          > resolve it.
>          > Using lmer, I get the message: fixed-effect model matrix is
>         rank deficient
>          > so dropping 18 columns / coefficients
>          >
>          > Ari
>          >
>          > Le mer. 7 juil. 2021 ? 09:52, romunov <romunov at gmail.com
>         <mailto:romunov at gmail.com>> a ?crit :
>          >
>          >> Have you tried plotting this? My guess is that you will find
>         something
>          >> unexpected in the provenance:treatment level combination.
>          >>
>          >> Cheers,
>          >> Roman
>          >>
>          >> On Wed, Jul 7, 2021 at 9:03 AM Arivoara Rabarijaona
>         <arivoara at gmail.com <mailto:arivoara at gmail.com>>
>          >> wrote:
>          >>
>          >>> Hi,
>          >>> I hope someone can help me. I'm using nlme to fit models.
>          >>>
>          >>> My dataframe (1785 obs) :
>          >>> $ id: Factor w/595 levels
>          >>> $ treatment: Factor w/3 levels
>          >>> $ provenance: Factor w/16 levels
>          >>> $ repetition: Factor w/4 levels
>          >>> $ bloc: Factor w/66 levels # nested to repetition
>          >>> $ response: num ... (1777 obs and 8 NA) # 3 repeated
>         measures by id
>          >>> $ status: Factor w/3 levels,
>         "dominant","codominant","suppressed" # there
>          >>> are 6 provenances without suppressed trees
>          >>>
>          >>> I want to run a modele like this :
>          >>>
>          >>> modele <- lme(response? ~ provenance + treatment +
>         provenance:treatment +
>          >>> status + status:treatment + statuts:provenance,
>          >>>? ? ? ? ? ? ? ? ? ? ?random = ~ 1|repetition/bloc,
>          >>>? ? ? ? ? ? ? ? ? ? ?correlation = corAR1(form = ~
>         1|repetition/bloc/id),
>          >>>? ? ? ? ? ? ? ? ? ? ?data, method= "ML", na.action =na.omit)
>          >>>
>          >>> I get the message :
>          >>> Error in MEEM(object, conLin, control$niterEM) : 
>          ?Singularity in
>          >>> backsolve
>          >>> at level 0, block 1 in LME model
>          >>>
>          >>> If I run the modele without the interaction
>         statuts:provenance, it works.
>          >>>
>          >>> Can anyone tell me how to resolve this error ?
>          >>>
>          >>> Thanks,
>          >>> Arivoara Rabarijaona
>          >>>
>          >>>? ? ? ? ? [[alternative HTML version deleted]]
>          >>>
>          >>> _______________________________________________
>          >>> R-sig-mixed-models at r-project.org
>         <mailto:R-sig-mixed-models at r-project.org> mailing list
>          >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>         <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>          >>>
>          >>
>          >>
>          >> --
>          >> In God we trust, all others bring data.
>          >>
>          >
>          >? ? ? ?[[alternative HTML version deleted]]
>          >
>          > _______________________________________________
>          > R-sig-mixed-models at r-project.org
>         <mailto:R-sig-mixed-models at r-project.org> mailing list
>          > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>         <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>          >
> 
>         _______________________________________________
>         R-sig-mixed-models at r-project.org
>         <mailto:R-sig-mixed-models at r-project.org> mailing list
>         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>         <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics


From Amirhossei@@Amirhossei@T@iebi m@iii@g oii r@dboudumc@@i  Thu Jul  8 08:59:16 2021
From: Amirhossei@@Amirhossei@T@iebi m@iii@g oii r@dboudumc@@i (Amirhossei@@Amirhossei@T@iebi m@iii@g oii r@dboudumc@@i)
Date: Thu, 8 Jul 2021 06:59:16 +0000
Subject: [R-sig-ME] Time-dependent Negative binomial regression
Message-ID: <1625727556626.79583@radboudumc.nl>

Dear responders,


Recently I have processed and cleaned a data for the aim of application of a negative binomial regression.

First, I tried to use the function glm.nb of package MASS in R and I had a problem with ensuring that the model will realize the data are for one unique participant (possible correlations in a group of observations).

Then, I realized that I can use glmmPQL of package MASS or glmer of package lme4 and use the family negative binomial in it's family link.

The question is I would like to know in which part of the model I can embed the offset (logarithm of the number of days of treatment) also how should I insert the time-constant observations for an id (such as gender and baseline age in the df)?

My latest attempt was:

(glmmPQL (event ~ treatment + offset (log(person.time)) ,
random= list (id=~1, gender=~1, baseline.age=~1),
family= negative.binomial (theta=1.75), data=df ))


which faced with a memory-related error (probably because of the wrong code). data example:

df<-data.frame(id=rep(1:3,each=4),treatment=sample(c(0,1),12,replace = T),
event=sample(c(0,1),12,replace = T),
person.time=sample(c(15,31,30),12,replace = T),
age=rep(c(65,58,74),each=4),gender=rep(c("m","f","m"),each=4))


Thank you for your time and considerations,

Amir

De informatie in dit bericht is uitsluitend bestemd voor de geadresseerde. Aan dit bericht en de bijlagen kunnen geen rechten worden ontleend. Heeft u deze e-mail onbedoeld ontvangen? Dan verzoeken wij u het te vernietigen en de afzender te informeren. Openbaar maken, kopi?ren en verspreiden van deze e-mail of informatie uit deze e-mail is alleen toegestaan met voorafgaande schriftelijke toestemming van de afzender. Het Radboudumc staat geregistreerd bij de Kamer van Koophandel in het handelsregister onder nummer 80262783.

The content of this message is intended solely for the addressee. No rights can be derived from this message or its attachments. If you are not the intended recipient, we kindly request you to delete the message and inform the sender. It is strictly prohibited to disclose, copy or distribute this email or the information inside it, without a written consent from the sender. Radboud university medical center is registered with the Dutch Chamber of Commerce trade register with number 80262783.

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Thu Jul  8 11:06:12 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Thu, 8 Jul 2021 11:06:12 +0200
Subject: [R-sig-ME] Time-dependent Negative binomial regression
In-Reply-To: <1625727556626.79583@radboudumc.nl>
References: <1625727556626.79583@radboudumc.nl>
Message-ID: <CAJuCY5wF9f1mFg2NYDioCpqdgi8keP9R_7EKwvJdeoaNSNhkHA@mail.gmail.com>

Dear Amir,

Have a look at the lme4, glmmTMB or INLA packages. Note that if you need on
the fly transformations in the model you need to code them as
I(log(person.time)) instead of log(person.time). Personally, I prefer to
create a new variable in the data.frame and use that new variable in the
model.

Another thing is that you shouldn't use gender and baseline.age as random
effects. Either don't use them (as their effect is handled by the id random
effect) or add them as fixed effects.

library(lme4)
glmer.nb(event ~ offset(log_time) + treatment + gender + baseline.age +
(1|id), data = df)

Best regards,


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op do 8 jul. 2021 om 08:59 schreef <
Amirhossein.AmirhosseinTalebi at radboudumc.nl>:

> Dear responders,
>
>
> Recently I have processed and cleaned a data for the aim of application of
> a negative binomial regression.
>
> First, I tried to use the function glm.nb of package MASS in R and I had a
> problem with ensuring that the model will realize the data are for one
> unique participant (possible correlations in a group of observations).
>
> Then, I realized that I can use glmmPQL of package MASS or glmer of
> package lme4 and use the family negative binomial in it's family link.
>
> The question is I would like to know in which part of the model I can
> embed the offset (logarithm of the number of days of treatment) also how
> should I insert the time-constant observations for an id (such as gender
> and baseline age in the df)?
>
> My latest attempt was:
>
> (glmmPQL (event ~ treatment + offset (log(person.time)) ,
> random= list (id=~1, gender=~1, baseline.age=~1),
> family= negative.binomial (theta=1.75), data=df ))
>
>
> which faced with a memory-related error (probably because of the wrong
> code). data example:
>
> df<-data.frame(id=rep(1:3,each=4),treatment=sample(c(0,1),12,replace = T),
> event=sample(c(0,1),12,replace = T),
> person.time=sample(c(15,31,30),12,replace = T),
> age=rep(c(65,58,74),each=4),gender=rep(c("m","f","m"),each=4))
>
>
> Thank you for your time and considerations,
>
> Amir
>
> De informatie in dit bericht is uitsluitend bestemd voor de geadresseerde.
> Aan dit bericht en de bijlagen kunnen geen rechten worden ontleend. Heeft u
> deze e-mail onbedoeld ontvangen? Dan verzoeken wij u het te vernietigen en
> de afzender te informeren. Openbaar maken, kopi?ren en verspreiden van deze
> e-mail of informatie uit deze e-mail is alleen toegestaan met voorafgaande
> schriftelijke toestemming van de afzender. Het Radboudumc staat
> geregistreerd bij de Kamer van Koophandel in het handelsregister onder
> nummer 80262783.
>
> The content of this message is intended solely for the addressee. No
> rights can be derived from this message or its attachments. If you are not
> the intended recipient, we kindly request you to delete the message and
> inform the sender. It is strictly prohibited to disclose, copy or
> distribute this email or the information inside it, without a written
> consent from the sender. Radboud university medical center is registered
> with the Dutch Chamber of Commerce trade register with number 80262783.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Thu Jul  8 16:38:09 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 8 Jul 2021 10:38:09 -0400
Subject: [R-sig-ME] Time-dependent Negative binomial regression
In-Reply-To: <CAJuCY5wF9f1mFg2NYDioCpqdgi8keP9R_7EKwvJdeoaNSNhkHA@mail.gmail.com>
References: <1625727556626.79583@radboudumc.nl>
 <CAJuCY5wF9f1mFg2NYDioCpqdgi8keP9R_7EKwvJdeoaNSNhkHA@mail.gmail.com>
Message-ID: <ececbe0d-bec2-ea9f-51b6-23c327c58bb2@gmail.com>

   I think log(person.time) will actually work fine, although I() 
doesn't hurt (it's only transformations that involve operators that are 
also used by R's formula syntax (*, +, :, /, ^) that need to be 
protected by I().



On 7/8/21 5:06 AM, Thierry Onkelinx via R-sig-mixed-models wrote:
> Dear Amir,
> 
> Have a look at the lme4, glmmTMB or INLA packages. Note that if you need on
> the fly transformations in the model you need to code them as
> I(log(person.time)) instead of log(person.time). Personally, I prefer to
> create a new variable in the data.frame and use that new variable in the
> model.
> 
> Another thing is that you shouldn't use gender and baseline.age as random
> effects. Either don't use them (as their effect is handled by the id random
> effect) or add them as fixed effects.
> 
> library(lme4)
> glmer.nb(event ~ offset(log_time) + treatment + gender + baseline.age +
> (1|id), data = df)
> 
> Best regards,
> 
> 
> ir. Thierry Onkelinx
> Statisticus / Statistician
> 
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
> 
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
> 
> <https://www.inbo.be>
> 
> 
> Op do 8 jul. 2021 om 08:59 schreef <
> Amirhossein.AmirhosseinTalebi at radboudumc.nl>:
> 
>> Dear responders,
>>
>>
>> Recently I have processed and cleaned a data for the aim of application of
>> a negative binomial regression.
>>
>> First, I tried to use the function glm.nb of package MASS in R and I had a
>> problem with ensuring that the model will realize the data are for one
>> unique participant (possible correlations in a group of observations).
>>
>> Then, I realized that I can use glmmPQL of package MASS or glmer of
>> package lme4 and use the family negative binomial in it's family link.
>>
>> The question is I would like to know in which part of the model I can
>> embed the offset (logarithm of the number of days of treatment) also how
>> should I insert the time-constant observations for an id (such as gender
>> and baseline age in the df)?
>>
>> My latest attempt was:
>>
>> (glmmPQL (event ~ treatment + offset (log(person.time)) ,
>> random= list (id=~1, gender=~1, baseline.age=~1),
>> family= negative.binomial (theta=1.75), data=df ))
>>
>>
>> which faced with a memory-related error (probably because of the wrong
>> code). data example:
>>
>> df<-data.frame(id=rep(1:3,each=4),treatment=sample(c(0,1),12,replace = T),
>> event=sample(c(0,1),12,replace = T),
>> person.time=sample(c(15,31,30),12,replace = T),
>> age=rep(c(65,58,74),each=4),gender=rep(c("m","f","m"),each=4))
>>
>>
>> Thank you for your time and considerations,
>>
>> Amir
>>
>> De informatie in dit bericht is uitsluitend bestemd voor de geadresseerde.
>> Aan dit bericht en de bijlagen kunnen geen rechten worden ontleend. Heeft u
>> deze e-mail onbedoeld ontvangen? Dan verzoeken wij u het te vernietigen en
>> de afzender te informeren. Openbaar maken, kopi?ren en verspreiden van deze
>> e-mail of informatie uit deze e-mail is alleen toegestaan met voorafgaande
>> schriftelijke toestemming van de afzender. Het Radboudumc staat
>> geregistreerd bij de Kamer van Koophandel in het handelsregister onder
>> nummer 80262783.
>>
>> The content of this message is intended solely for the addressee. No
>> rights can be derived from this message or its attachments. If you are not
>> the intended recipient, we kindly request you to delete the message and
>> inform the sender. It is strictly prohibited to disclose, copy or
>> distribute this email or the information inside it, without a written
>> consent from the sender. Radboud university medical center is registered
>> with the Dutch Chamber of Commerce trade register with number 80262783.
>>
>>          [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics


From kj@j@o|omon @end|ng |rom gm@||@com  Sat Jul 10 22:55:19 2021
From: kj@j@o|omon @end|ng |rom gm@||@com (Jack Solomon)
Date: Sat, 10 Jul 2021 15:55:19 -0500
Subject: [R-sig-ME] Is crossed random-effect the only choice?
Message-ID: <CA+sL+8VM5R5pxhY12E8VerpmyoOquTxEAKQcg=YQqeiqu0meaQ@mail.gmail.com>

Hello Allo,

In my two-level data structure, I have a cluster-level variable (called
"X"; one that doesn't vary in any cluster). If I intend to generalize
beyond X's current possible levels, then, I should take X as a random
effect.

However, because "X" doesn't vary in any cluster, therefore, such a random
effect necessarily must be a crossed random effect (e.g., "~ 1 | X"),
correct?

If yes, then what is "X" crossed with?

Thank you,
Jack

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Sun Jul 11 03:29:44 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sat, 10 Jul 2021 21:29:44 -0400
Subject: [R-sig-ME] Is crossed random-effect the only choice?
In-Reply-To: <CA+sL+8VM5R5pxhY12E8VerpmyoOquTxEAKQcg=YQqeiqu0meaQ@mail.gmail.com>
References: <CA+sL+8VM5R5pxhY12E8VerpmyoOquTxEAKQcg=YQqeiqu0meaQ@mail.gmail.com>
Message-ID: <ccb81c51-ec18-21f3-a9b1-7d354e5e6187@gmail.com>

   The "crossed vs random" terminology is only relevant in models with 
more than one grouping variable.  I would call (1|X) " a random effect 
of X" or more precisely "a random-intercept model with grouping variable X"

   However, your question is a little unclear to me.  Is X a grouping 
variable or a predictor variable (numeric or categorical) that varies 
across groups?

   I can think of four possibilities.

  1. X is the grouping variable (e.g. "hospital"). Then ~ (1|X) is a 
model that describes variation in the model intercept / baseline value, 
across hospitals.

  2. X is a continuous covariate (e.g. annual hospital budget).  Then if 
H is the factor designating hospitals, we want  ~ X + (1|H) (plus any 
other fixed effects of interest. (It doesn't make sense / isn't 
identifiable to fit a random-slopes model ~ (H | X) because budgets 
don't vary within hospitals.

3. X is a categorical / factor predictor (e.g. hospital size class 
{small, medium, large} with multiple hospitals measured in each size 
class:  ~ X + (1|H) (the same as #2).

4. X is a categorical predictor with unique values for each hospital 
(e.g. postal code).  Then X is redundant with H, you shouldn't try to 
include them both in the same model.

On 7/10/21 4:55 PM, Jack Solomon wrote:
> Hello Allo,
> 
> In my two-level data structure, I have a cluster-level variable (called
> "X"; one that doesn't vary in any cluster). If I intend to generalize
> beyond X's current possible levels, then, I should take X as a random
> effect.
> 
> However, because "X" doesn't vary in any cluster, therefore, such a random
> effect necessarily must be a crossed random effect (e.g., "~ 1 | X"),
> correct?
> 
> If yes, then what is "X" crossed with?
> 
> Thank you,
> Jack
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics


From kj@j@o|omon @end|ng |rom gm@||@com  Sun Jul 11 05:36:20 2021
From: kj@j@o|omon @end|ng |rom gm@||@com (Jack Solomon)
Date: Sat, 10 Jul 2021 22:36:20 -0500
Subject: [R-sig-ME] Is crossed random-effect the only choice?
In-Reply-To: <ccb81c51-ec18-21f3-a9b1-7d354e5e6187@gmail.com>
References: <CA+sL+8VM5R5pxhY12E8VerpmyoOquTxEAKQcg=YQqeiqu0meaQ@mail.gmail.com>
 <ccb81c51-ec18-21f3-a9b1-7d354e5e6187@gmail.com>
Message-ID: <CA+sL+8WoDgEKfttJrOs-1hxO6hg34pGKtz+XJ2Fn2zp=ngf=8A@mail.gmail.com>

Dear Ben,

Thank you for your informative response. I think # 4 is what matches my
situation.

Thanks again, Jack

On Sat, Jul 10, 2021 at 8:30 PM Ben Bolker <bbolker at gmail.com> wrote:

>    The "crossed vs random" terminology is only relevant in models with
> more than one grouping variable.  I would call (1|X) " a random effect
> of X" or more precisely "a random-intercept model with grouping variable X"
>
>    However, your question is a little unclear to me.  Is X a grouping
> variable or a predictor variable (numeric or categorical) that varies
> across groups?
>
>    I can think of four possibilities.
>
>   1. X is the grouping variable (e.g. "hospital"). Then ~ (1|X) is a
> model that describes variation in the model intercept / baseline value,
> across hospitals.
>
>   2. X is a continuous covariate (e.g. annual hospital budget).  Then if
> H is the factor designating hospitals, we want  ~ X + (1|H) (plus any
> other fixed effects of interest. (It doesn't make sense / isn't
> identifiable to fit a random-slopes model ~ (H | X) because budgets
> don't vary within hospitals.
>
> 3. X is a categorical / factor predictor (e.g. hospital size class
> {small, medium, large} with multiple hospitals measured in each size
> class:  ~ X + (1|H) (the same as #2).
>
> 4. X is a categorical predictor with unique values for each hospital
> (e.g. postal code).  Then X is redundant with H, you shouldn't try to
> include them both in the same model.
>
> On 7/10/21 4:55 PM, Jack Solomon wrote:
> > Hello Allo,
> >
> > In my two-level data structure, I have a cluster-level variable (called
> > "X"; one that doesn't vary in any cluster). If I intend to generalize
> > beyond X's current possible levels, then, I should take X as a random
> > effect.
> >
> > However, because "X" doesn't vary in any cluster, therefore, such a
> random
> > effect necessarily must be a crossed random effect (e.g., "~ 1 | X"),
> > correct?
> >
> > If yes, then what is "X" crossed with?
> >
> > Thank you,
> > Jack
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> --
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> Graduate chair, Mathematics & Statistics
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From |@brun@ @end|ng |rom udc@e@  Sun Jul 11 10:36:10 2021
From: |@brun@ @end|ng |rom udc@e@ (Fernando Pedro Bruna Quintas)
Date: Sun, 11 Jul 2021 08:36:10 +0000
Subject: [R-sig-ME] Comparing weighted and unweighted estimation RE:
 Methodological and practical issues about survey weights using lme4
In-Reply-To: <036E18B5-EBE3-4471-9FCA-BF6D22930468@gmail.com>
References: <PR1PR02MB4889A9F703D90E4C097C6DC4921D9@PR1PR02MB4889.eurprd02.prod.outlook.com>,
 <036E18B5-EBE3-4471-9FCA-BF6D22930468@gmail.com>
Message-ID: <PR1PR02MB48891E8C051949948626C5AE92169@PR1PR02MB4889.eurprd02.prod.outlook.com>



Dear list members

I am still trying to understand weighed estimation of mixed models. In previous messages I was very kindly told that the weights argument in lmer() is for precision weights (not sampling weights). However, I am still not convinced about that and I would appreciat more thoughts about weighting.

The vignette of WeMix packaged says: ?The packagelme4 fits mixed models when there are no weights or weights only for first-level units (Bates, Maechler,Bolker, & Walker, 2015) and is recommended when both of two conditions hold: no weights are above the first level,and cluster-robust standard errors are not required.WeMixcan fit models with weights at every level of the modeland also calculates cluster-robust standard errors that account for covariance between units in the same groups?. See https://cran.r-project.org/web/packages/WeMix/
Additionally, in the help page of the mix() function of WeMix explains: "When all weights above the individual level are 1, this is similar to a lmer and you should use lme4 because it is much faster. "

I have seen explanations of that use, such as in the following link: https://www.r-bloggers.com/2017/06/sampling-weights-and-multilevel-modeling-in-r/

That use is different from the use in meta-analysis, weighting by inverse variance or sample size: https://www.metafor-project.org/doku.php/tips:rma_vs_lm_lme_lmer

There are also links of debates in internet commenting that lmer() cannot be used for survey weights. Some of them are old so I do not summarize them here.

The 'weights' argument in lmer() function of lme4 is explained in the following way: "weights an optional vector of ?prior weights? to be used in the fitting process. Should be NULL or a numeric vector. Prior weights are not normalized or standardized in any way. In particular, the diagonal of the residual covariance matrix is the squared residual standard deviation parameter sigma times the vector of inverse weights. Therefore, if the weights have relatively large magnitudes, then in order to compensate, the sigma parameter will also need to have a relatively large magnitude"

I apologise for my ignorance but I do not understand the difference between precisoon weights or survey weights in this last function. The expression "prior weights" doest not help me with that.

Using the European Social Survey, I have used the ?analysis weights? () normalized to sum to the sample size after deletion of missing data.
https://www.europeansocialsurvey.org/methodology/ess_methodology/data_processing_archiving/weighting.html
Using lmer() with weights and WeMix with those weights for level-1 and unitary weights for level-2 produce very similar estimates of level-1-and-2 variables. I use unitary weights for level-2 because they are European countries, therefore it is not a sample such a sample of schools in a country. Example of results for my main variables:

  *   Using lmer() without weights
                                           Estimate             Std. Error          t value
level-2 variable1                0.20795196        0.06229626      3.338113
level-2 variable2                -0.26445932       0.06232801     -4.243025
level-2 variable2                0.46072085         0.05212811      8.838241

  *   Using lmer() and weights
                                           Estimate             Std. Error           t value
level-2 variable1                0.194559163       0.06695520      2.9058113
level-2 variable2                -0.258452710     0.06771138     -3.8169759
level-2 variable2                0.466058046       0.05746252      8.1106439

  *   Using WeMix
                                           Estimate              Std. Error        t value
level-2 variable1                0.1954945           0.0512900       3.8116
level-2 variable2                -0.2593960          0.0585994        -4.4266
level-2 variable2                0.4667014           0.0548841       8.5034

I am surprised by the similarity of results between weighted and unweighted lmer(). The four most populated countries are 22% of the observations in my sample but 60% of the sum of the normalized weights. Therefore, I was expecting more impact of weighting. In any case, comparing weighted lmer() and WeMix?s function, we find similar results.

Apart from the sofware issues, my more general question was methodological. Solon et al (2015) do not suggest using weights for causal analysis. Indeed, their paper starts with a paragraph that is worthy to repeat here: ?At the beginning of their textbook?s section on weighted estimation of regression models, Angrist and Pischke (2009, p. 91) acknowledge, ?Few things are as confusing to applied researchers as the role of sample weights. Even now, 20 years post- Ph.D., we read the section of the Stata manual on weighting with some dismay.? After years of discussing weighting issues with fellow economic researchers, we know that Angrist and Pischke are in excellent company. In published research, top- notch empirical scholars make conflicting choices about whether and how to weight and often provide little or no rationale for their choices. And in private discussions, we have found that accomplished researchers sometimes own up to confusion or declare demonstrably faulty reasons for their weighting choices.?
http://jhr.uwpress.org/content/50/2/301

Therefore, some of the available discussions in internet are probably wrong. I would appreciate further comments about these issues: 1) convenience of using weights for causal analysis; 2) using survey weights in lme4 pacakge; 3) comparison of weighted and unweighted results in spite of such a difference of the importance of the level-2 units (countries here).

Thank you very much. All the best,

Fernando Bruna



________________________________
De: James Pustejovsky <jepusto at gmail.com>
Enviado: lunes, 5 de julio de 2021 1:02
Para: Fernando Pedro Bruna Quintas <f.bruna at udc.es>
Cc: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Asunto: Re: [R-sig-ME] Methodological and practical issues about survey weights using lme4

My understanding is that lme4 does not accommodate survey weights. But check out the WeMix package for an alternative: https://cran.r-project.org/package=WeMix

I learned about WeMix when I posted a query on Twitter very similar to your question (https://twitter.com/jepusto/status/1408084119884599299?s=21).

Kind Regards,
James

On Jul 4, 2021, at 11:20 AM, Fernando Pedro Bruna Quintas <f.bruna at udc.es> wrote:

?

Dear list members,

I have two questions about the use of survey weights in multilevel models.

I have estimated a multilevel model about the effects of individual and cultural variables in well-being, using the European Social Survey. By ?culture? I mean national aggregates of my level-1 indicators. Think of Yij as an indicator of wellbeing, Xij as an indicator of being individualistic (for instance) and Xj as the sample country mean of individualism, representing the degree of individualism in a national culture (contextual effect).

I have estimated the following simplified model:
lmer( Yij  ~ (Xij-Xj) + Xj + (1 | country) ) , data=databank)

A referee makes me the following comment: ?Post stratication weights at individual level and at the higher-level national variables is a relevant issue. This issue of importance on MLM context as Stata instructions note https://www.stata.com/features/overview/multilevel-models-with-survey-data/. The authors seem to be using R but I would assume it includes similar options to include weights to all levels of the analysis. The literature on MLM includes recommendations for Fitting multilevel models in complex survey data with design weights and this needs to be referred and selection of weights justified.?

The information about weights in the survey I am using is in the following link:
https://www.europeansocialsurvey.org/methodology/ess_methodology/data_processing_archiving/weighting.html

My questions are the following:

 1.  A first questions is about general methodology, though applied to the analysis of the effects of level-two variables. I would appreciate references or links about when is appropriate to use survey weights, depending on the research question. I have data on 23 countries. My goal is to measure the effects of level-two (cultural variables). Therefore, I am not so much interested on concluding about big countries (Russia has 145 million of people!). I need variance to differentiate cultural effects in Belgium, Netherlands... However, If I do not use weights my conclusions are only about the particular sample published by the European Social Survey. Any thought?
 2.  Apart from that, and more generally for any other study, I would appreciate comments and references about using survey weights in lme4. I understand that I would have to change the calculation of all may level-one variables, which are defined as deviations to the national means. Additionally, I must consider reweighting national means of those variables, as well as other level-two variables. The estimation procedure has to be weighted... I would appreciate any practical comment about weighted estimation using survey data and lme4.

Thank you very much,

Fernando Bruna
Department of Economics
University of A Corunha (Coru?a), Spain


   [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From mrm|500 @end|ng |rom york@@c@uk  Tue Jul 13 12:30:10 2021
From: mrm|500 @end|ng |rom york@@c@uk (Michael Lawson)
Date: Tue, 13 Jul 2021 11:30:10 +0100
Subject: [R-sig-ME] Modelling with uncertain (but not missing) categorical
 random effect values
Message-ID: <CACtWw1HWv6ph0vwt4TLpUxiojZ_3993Kop0bvfXe=3yt2Lu9JA@mail.gmail.com>

I have a dataset where I have offspring paternity of females with
males of different species. However, many of the offspring have
ambiguous paternity - where I know the offspring must be from
particular fathers, but not from others. The data currently looks a
bit like this (but with many more rows per mum_id):

mum_id  mum_sp  dad_sp dad_id                    con

Af1          A              A           Am1 / Am2             1
Af1          A              A           Am2                       1
Bf1          B             A           Am1 / Am2 / Am4   0
Bf2          B              B          Bm1 / Bm3              1

Which I have so far run as a binomial GLMM with con (conspecific mating) as
a binary response, mum_sp and dad_sp (species) as fixed factors and
mum_id as a random factor - and have just not included dad_id as
a random factor. The ambiguously assigned fathers in dad_id is also
non-random, i.e.
certain individuals are more likely to be ambiguously assigned than
others, so just leaving these cases as NA is problematic.

For some of the ambiguous assignments, I can also extract
probabilities that a possible male is the father of the offspring,
e.g. for the first row, father Am1 is 60% likely to be the father and
Am2 40% likely.

Are there any approaches where I can include the ambiguous dad_id in
a GLMM framework? - where the uncertainty of the assignment contributes to the
overall uncertainty in the tested relationship.

Thank you for any suggestions,
Mike


From th|erry@onke||nx @end|ng |rom |nbo@be  Tue Jul 13 13:09:34 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Tue, 13 Jul 2021 13:09:34 +0200
Subject: [R-sig-ME] 
 Modelling with uncertain (but not missing) categorical
 random effect values
In-Reply-To: <CACtWw1HWv6ph0vwt4TLpUxiojZ_3993Kop0bvfXe=3yt2Lu9JA@mail.gmail.com>
References: <CACtWw1HWv6ph0vwt4TLpUxiojZ_3993Kop0bvfXe=3yt2Lu9JA@mail.gmail.com>
Message-ID: <CAJuCY5xD_4QNNhbKMOjsJ2uQETWyHzaBznkUxg65_+QV-5Vw9A@mail.gmail.com>

Dear Michael,

Maybe something like (0 + w_1 | dad_1) + (0 + w_2 | dad_2) + (0 + w_3 |
dad_3). Where w_1 is the probability of dad_1.

Make sure that dad_1, dad_2 and dad_3 are factors with the same levels.
Then INLA allows you to add this as f(dad_1, w_1, model = "iid") + f(dad_2,
w_2, copy = "dad_"1) + f(dad_3, w_3, copy = "dad_1"). So you end up with a
single random intercept for every dad (dad_2 and dad_3 share their
estimates with dad_1).

mum_id  mum_sp  dad_sp dad_id                    con    dad_1   w_1 dad_2
w_ 2 dad_3 w_3

Af1          A              A           Am1 / Am2             1      Am1
0.6   Am2 0.4  NA 0
Af1          A              A           Am2                       1
Am2    1     NA     0     NA 0
Bf1          B             A           Am1 / Am2 / Am4   0      Am1    0.4
 Am2 0.3   Am4 0.3
Bf2          B              B          Bm1 / Bm3              1      Bm1
0.5   Bm2  0.5  NA 0

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op di 13 jul. 2021 om 12:30 schreef Michael Lawson via R-sig-mixed-models <
r-sig-mixed-models at r-project.org>:

> I have a dataset where I have offspring paternity of females with
> males of different species. However, many of the offspring have
> ambiguous paternity - where I know the offspring must be from
> particular fathers, but not from others. The data currently looks a
> bit like this (but with many more rows per mum_id):
>
> mum_id  mum_sp  dad_sp dad_id                    con
>
> Af1          A              A           Am1 / Am2             1
> Af1          A              A           Am2                       1
> Bf1          B             A           Am1 / Am2 / Am4   0
> Bf2          B              B          Bm1 / Bm3              1
>
> Which I have so far run as a binomial GLMM with con (conspecific mating) as
> a binary response, mum_sp and dad_sp (species) as fixed factors and
> mum_id as a random factor - and have just not included dad_id as
> a random factor. The ambiguously assigned fathers in dad_id is also
> non-random, i.e.
> certain individuals are more likely to be ambiguously assigned than
> others, so just leaving these cases as NA is problematic.
>
> For some of the ambiguous assignments, I can also extract
> probabilities that a possible male is the father of the offspring,
> e.g. for the first row, father Am1 is 60% likely to be the father and
> Am2 40% likely.
>
> Are there any approaches where I can include the ambiguous dad_id in
> a GLMM framework? - where the uncertainty of the assignment contributes to
> the
> overall uncertainty in the tested relationship.
>
> Thank you for any suggestions,
> Mike
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From cm|o500 @end|ng |rom york@@c@uk  Wed Jul 14 01:18:05 2021
From: cm|o500 @end|ng |rom york@@c@uk (=?UTF-8?Q?C=C3=A1tia_Ferreira_De_Oliveira?=)
Date: Wed, 14 Jul 2021 00:18:05 +0100
Subject: [R-sig-ME] How to fix a gamma model with poor fit?
Message-ID: <CACw+Tff-B8WeHcTnZjT5MA--zZz59JFhZcCkm2KzXSajAUpuVQ@mail.gmail.com>

Dear all,

I am sorry for reposting here after posting on cross validated here
<https://stats.stackexchange.com/questions/534098/glmer-gamma-model-good-fit>
but I am still not sure what would be the best way of going about fixing
this model. It seems to have poor fit if you look at the plots as they have
extremes on both sides, which would not fit well with a gamma distribution.
Despite this, the results are consistent across packages (lme4, nlme...).

I have 209062 rows of data and this is response time data.
I want to determine whether there are differences between groups (Groups -
2 levels) on the learning of a task (Probability - 2 levels) across time
(within sessions - Block - 4 levels / across sessions - Session - 2
levels). It doesn't have zero response times, but some close to zero.

Do you have any suggestions for how one can improve a model like this or
whether I should just use another distribution that fits the data a bit
better?

Thank you!

Catia


Model:

    glmer(RT ~ Prob * Bl * Session * Gr + (1  | Participant), data=
Data.trimmed, family = Gamma(link =
"log"), control=glmerControl(optimizer="bobyqa"))
Model summary:

    Generalized linear mixed model fit by maximum likelihood (Adaptive
Gauss-Hermite Quadrature, nAGQ = 0) ['glmerMod']
     Family: Gamma  ( log )
    Formula: RT ~ Probability * Block * Session * Group + (1 | Participant)
       Data: Data.trimmed
    Control: glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun =
1e+06))

         AIC      BIC   logLik deviance df.resid
     2456107  2456538 -1228012  2456023   209020

    Scaled residuals:
       Min     1Q Median     3Q    Max
    -4.297 -0.625 -0.158  0.440 35.691

    Random effects:
     Groups      Name        Variance Std.Dev.
     Participant (Intercept) 0.002203 0.04694
     Residual                0.053481 0.23126
    Number of obs: 209062, groups:  Participant, 130

    Fixed effects:
                                            Estimate Std. Error  t value
Pr(>|z|)
    (Intercept)                            6.024e+00  4.182e-03 1440.439  <
2e-16 ***
    Probability1                          -2.835e-02  7.041e-04  -40.265  <
2e-16 ***
    Block2-1                              -2.925e-02  2.077e-03  -14.084  <
2e-16 ***
    Block3-2                              -3.676e-03  2.131e-03   -1.725
0.084500 .
    Block4-3                               4.085e-03  2.307e-03    1.771
0.076577 .
    Block5-4                              -1.220e-02  2.380e-03   -5.125
2.98e-07 ***
    Session1                               4.795e-02  7.323e-04   65.478  <
2e-16 ***
    Group1                                -4.616e-02  4.182e-03  -11.037  <
2e-16 ***
    Probability1:Block2-1                 -7.228e-03  2.077e-03   -3.480
0.000501 ***
    Probability1:Block3-2                 -5.332e-03  2.131e-03   -2.503
0.012331 *
    Probability1:Block4-3                 -2.076e-02  2.307e-03   -8.999  <
2e-16 ***
    Probability1:Block5-4                  6.044e-03  2.380e-03    2.539
0.011104 *
    Probability1:Session1                  1.656e-03  7.046e-04    2.351
0.018743 *
    Block2-1:Session1                     -1.972e-02  2.077e-03   -9.494  <
2e-16 ***
    Block3-2:Session1                     -8.521e-03  2.131e-03   -3.999
6.35e-05 ***
    Block4-3:Session1                      4.380e-05  2.308e-03    0.019
0.984856
    Block5-4:Session1                     -3.768e-03  2.380e-03   -1.583
0.113389
    Probability1:Group1                    1.515e-03  7.041e-04    2.151
0.031478 *
    Block2-1:Group1                       -6.161e-03  2.077e-03   -2.966
0.003015 **
    Block3-2:Group1                       -1.129e-02  2.131e-03   -5.301
1.15e-07 ***
    Block4-3:Group1                        7.095e-03  2.307e-03    3.076
0.002101 **
    Block5-4:Group1                       -4.055e-03  2.380e-03   -1.704
0.088414 .
    Session1:Group1                        3.782e-03  7.323e-04    5.164
2.41e-07 ***
    Probability1:Block2-1:Session1         5.729e-05  2.077e-03    0.028
0.977997
    Probability1:Block3-2:Session1         3.543e-03  2.131e-03    1.663
0.096363 .
    Probability1:Block4-3:Session1        -6.877e-03  2.308e-03   -2.980
0.002886 **
    Probability1:Block5-4:Session1         4.329e-03  2.380e-03    1.819
0.068952 .
    Probability1:Block2-1:Group1          -1.238e-03  2.077e-03   -0.596
0.550980
    Probability1:Block3-2:Group1           1.022e-02  2.131e-03    4.795
1.63e-06 ***
    Probability1:Block4-3:Group1          -6.532e-03  2.307e-03   -2.831
0.004634 **
    Probability1:Block5-4:Group1           2.351e-03  2.380e-03    0.988
0.323373
    Probability1:Session1:Group1          -1.805e-03  7.046e-04   -2.562
0.010412 *
    Block2-1:Session1:Group1              -2.060e-04  2.077e-03   -0.099
0.920984
    Block3-2:Session1:Group1              -4.211e-03  2.131e-03   -1.977
0.048094 *
    Block4-3:Session1:Group1               3.339e-03  2.308e-03    1.447
0.147888
    Block5-4:Session1:Group1              -3.956e-03  2.380e-03   -1.662
0.096539 .
    Probability1:Block2-1:Session1:Group1 -1.270e-03  2.077e-03   -0.611
0.540933
    Probability1:Block3-2:Session1:Group1  1.678e-03  2.131e-03    0.788
0.430929
    Probability1:Block4-3:Session1:Group1 -4.640e-03  2.308e-03   -2.010
0.044392 *
    Probability1:Block5-4:Session1:Group1  4.714e-03  2.380e-03    1.980
0.047649 *
    ---
    Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

    Correlation matrix not shown by default, as p = 40 > 12.
    Use print(x, correlation=TRUE)  or
        vcov(x)        if you need it

Plots:

  [1]: https://i.stack.imgur.com/XPdtl.png
  [2]: https://i.stack.imgur.com/zUNRX.png
  [3]: https://i.stack.imgur.com/6slYG.png
  [4]: https://i.stack.imgur.com/LlRwT.png
  [5]: https://i.stack.imgur.com/TNYCP.png
  [6]: https://i.stack.imgur.com/45l0P.png

	[[alternative HTML version deleted]]


From pb@||ey @end|ng |rom @|r@org  Wed Jul 14 01:23:48 2021
From: pb@||ey @end|ng |rom @|r@org (Bailey, Paul)
Date: Tue, 13 Jul 2021 23:23:48 +0000
Subject: [R-sig-ME] Comparing weighted and unweighted estimation RE:
 Methodological and practical issues about survey weights using lme4
Message-ID: <DS7PR05MB7239A220B701DD1AE401DE5EBE149@DS7PR05MB7239.namprd05.prod.outlook.com>

I just wanted to confirm that WeMix is designed for survey sample weights and, consistent with good survey variance estimation practices, produces clustered standard errors. Those interested in the package can see the package's page here https://american-institutes-for-research.github.io/WeMix/index.html.

How to use the weights is an area of active research in the literature, and I'm not going to comment on that.

Best,
Paul Bailey, Ph.D.


	[[alternative HTML version deleted]]


From me @end|ng |rom ph||||p@|d@y@com  Wed Jul 14 03:11:35 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Tue, 13 Jul 2021 20:11:35 -0500
Subject: [R-sig-ME] How to fix a gamma model with poor fit?
In-Reply-To: <CACw+Tff-B8WeHcTnZjT5MA--zZz59JFhZcCkm2KzXSajAUpuVQ@mail.gmail.com>
References: <CACw+Tff-B8WeHcTnZjT5MA--zZz59JFhZcCkm2KzXSajAUpuVQ@mail.gmail.com>
Message-ID: <4ce632bc-040e-9a00-c36c-8d399818a884@phillipalday.com>

A few quick comments:

1. The QQ-plot diagnostic needs to be against the appropriate
distribution. For a gamma model, the theoretical quantiles comes from
the gamma distribution, not the normal distribution.
2. You have a log link but your reaction-time data looks to be in
seconds, not milliseconds. Note that log10(0.1) = -1 and log10(1) = 0,
but log10(100) = 2 and log10(1000) = 3, so you'll get very different
answers for seconds vs. milliseconds. The reason why log transforms are
so nice for reaction times is not "just" the skew, but rather that there
is an underlying power law driving the effects *on the milliseconds* scale.

Are you using a gamma model because of the Lo and Andrews paper? I've
indicated my skepticism about that work previously, but these are my
critical points:

- there's still a transformation going on, it's just in the link function
- having a nonlinear link complicates interpretation of the coefficients
- gamma models are much harder to fit numerically (and I believe that
codepath is less well tested in lme4; it's a known problem in
MixedModels.jl)
- the usual tests on residuals, etc. now have to be done against a gamma
distribution, not a normal, but a lot of diagnostics use the normal by
default
- I don't understand the obsession with "satisfying normality
assumptions" (from their abstract) in a GLMM -- half the point of the
*generalized* bit is that you can swap in a different distributional
assumption (the other half is the use of a link function)


When thinking about using a model from a particular family/distribution,
note that the distributional assumption is *on the residuals* so the
skew in your raw data may or may not be present in the residuals. So
maybe you don't need a Gamma model at all.

Looking at your model output, it looks like you're using sum contrasts
-- great! But checkout contr.Sum from the car package for nicer looking
labels. :)

Phillip




On 13/7/21 6:18 pm, C?tia Ferreira De Oliveira via R-sig-mixed-models wrote:
> Dear all,
> 
> I am sorry for reposting here after posting on cross validated here
> <https://stats.stackexchange.com/questions/534098/glmer-gamma-model-good-fit>
> but I am still not sure what would be the best way of going about fixing
> this model. It seems to have poor fit if you look at the plots as they have
> extremes on both sides, which would not fit well with a gamma distribution.
> Despite this, the results are consistent across packages (lme4, nlme...).
> 
> I have 209062 rows of data and this is response time data.
> I want to determine whether there are differences between groups (Groups -
> 2 levels) on the learning of a task (Probability - 2 levels) across time
> (within sessions - Block - 4 levels / across sessions - Session - 2
> levels). It doesn't have zero response times, but some close to zero.
> 
> Do you have any suggestions for how one can improve a model like this or
> whether I should just use another distribution that fits the data a bit
> better?
> 
> Thank you!
> 
> Catia
> 
> 
> Model:
> 
>     glmer(RT ~ Prob * Bl * Session * Gr + (1  | Participant), data=
> Data.trimmed, family = Gamma(link =
> "log"), control=glmerControl(optimizer="bobyqa"))
> Model summary:
> 
>     Generalized linear mixed model fit by maximum likelihood (Adaptive
> Gauss-Hermite Quadrature, nAGQ = 0) ['glmerMod']
>      Family: Gamma  ( log )
>     Formula: RT ~ Probability * Block * Session * Group + (1 | Participant)
>        Data: Data.trimmed
>     Control: glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun =
> 1e+06))
> 
>          AIC      BIC   logLik deviance df.resid
>      2456107  2456538 -1228012  2456023   209020
> 
>     Scaled residuals:
>        Min     1Q Median     3Q    Max
>     -4.297 -0.625 -0.158  0.440 35.691
> 
>     Random effects:
>      Groups      Name        Variance Std.Dev.
>      Participant (Intercept) 0.002203 0.04694
>      Residual                0.053481 0.23126
>     Number of obs: 209062, groups:  Participant, 130
> 
>     Fixed effects:
>                                             Estimate Std. Error  t value
> Pr(>|z|)
>     (Intercept)                            6.024e+00  4.182e-03 1440.439  <
> 2e-16 ***
>     Probability1                          -2.835e-02  7.041e-04  -40.265  <
> 2e-16 ***
>     Block2-1                              -2.925e-02  2.077e-03  -14.084  <
> 2e-16 ***
>     Block3-2                              -3.676e-03  2.131e-03   -1.725
> 0.084500 .
>     Block4-3                               4.085e-03  2.307e-03    1.771
> 0.076577 .
>     Block5-4                              -1.220e-02  2.380e-03   -5.125
> 2.98e-07 ***
>     Session1                               4.795e-02  7.323e-04   65.478  <
> 2e-16 ***
>     Group1                                -4.616e-02  4.182e-03  -11.037  <
> 2e-16 ***
>     Probability1:Block2-1                 -7.228e-03  2.077e-03   -3.480
> 0.000501 ***
>     Probability1:Block3-2                 -5.332e-03  2.131e-03   -2.503
> 0.012331 *
>     Probability1:Block4-3                 -2.076e-02  2.307e-03   -8.999  <
> 2e-16 ***
>     Probability1:Block5-4                  6.044e-03  2.380e-03    2.539
> 0.011104 *
>     Probability1:Session1                  1.656e-03  7.046e-04    2.351
> 0.018743 *
>     Block2-1:Session1                     -1.972e-02  2.077e-03   -9.494  <
> 2e-16 ***
>     Block3-2:Session1                     -8.521e-03  2.131e-03   -3.999
> 6.35e-05 ***
>     Block4-3:Session1                      4.380e-05  2.308e-03    0.019
> 0.984856
>     Block5-4:Session1                     -3.768e-03  2.380e-03   -1.583
> 0.113389
>     Probability1:Group1                    1.515e-03  7.041e-04    2.151
> 0.031478 *
>     Block2-1:Group1                       -6.161e-03  2.077e-03   -2.966
> 0.003015 **
>     Block3-2:Group1                       -1.129e-02  2.131e-03   -5.301
> 1.15e-07 ***
>     Block4-3:Group1                        7.095e-03  2.307e-03    3.076
> 0.002101 **
>     Block5-4:Group1                       -4.055e-03  2.380e-03   -1.704
> 0.088414 .
>     Session1:Group1                        3.782e-03  7.323e-04    5.164
> 2.41e-07 ***
>     Probability1:Block2-1:Session1         5.729e-05  2.077e-03    0.028
> 0.977997
>     Probability1:Block3-2:Session1         3.543e-03  2.131e-03    1.663
> 0.096363 .
>     Probability1:Block4-3:Session1        -6.877e-03  2.308e-03   -2.980
> 0.002886 **
>     Probability1:Block5-4:Session1         4.329e-03  2.380e-03    1.819
> 0.068952 .
>     Probability1:Block2-1:Group1          -1.238e-03  2.077e-03   -0.596
> 0.550980
>     Probability1:Block3-2:Group1           1.022e-02  2.131e-03    4.795
> 1.63e-06 ***
>     Probability1:Block4-3:Group1          -6.532e-03  2.307e-03   -2.831
> 0.004634 **
>     Probability1:Block5-4:Group1           2.351e-03  2.380e-03    0.988
> 0.323373
>     Probability1:Session1:Group1          -1.805e-03  7.046e-04   -2.562
> 0.010412 *
>     Block2-1:Session1:Group1              -2.060e-04  2.077e-03   -0.099
> 0.920984
>     Block3-2:Session1:Group1              -4.211e-03  2.131e-03   -1.977
> 0.048094 *
>     Block4-3:Session1:Group1               3.339e-03  2.308e-03    1.447
> 0.147888
>     Block5-4:Session1:Group1              -3.956e-03  2.380e-03   -1.662
> 0.096539 .
>     Probability1:Block2-1:Session1:Group1 -1.270e-03  2.077e-03   -0.611
> 0.540933
>     Probability1:Block3-2:Session1:Group1  1.678e-03  2.131e-03    0.788
> 0.430929
>     Probability1:Block4-3:Session1:Group1 -4.640e-03  2.308e-03   -2.010
> 0.044392 *
>     Probability1:Block5-4:Session1:Group1  4.714e-03  2.380e-03    1.980
> 0.047649 *
>     ---
>     Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
>     Correlation matrix not shown by default, as p = 40 > 12.
>     Use print(x, correlation=TRUE)  or
>         vcov(x)        if you need it
> 
> Plots:
> 
>   [1]: https://i.stack.imgur.com/XPdtl.png
>   [2]: https://i.stack.imgur.com/zUNRX.png
>   [3]: https://i.stack.imgur.com/6slYG.png
>   [4]: https://i.stack.imgur.com/LlRwT.png
>   [5]: https://i.stack.imgur.com/TNYCP.png
>   [6]: https://i.stack.imgur.com/45l0P.png
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From cm|o500 @end|ng |rom york@@c@uk  Wed Jul 14 06:18:37 2021
From: cm|o500 @end|ng |rom york@@c@uk (=?UTF-8?Q?C=C3=A1tia_Ferreira_De_Oliveira?=)
Date: Wed, 14 Jul 2021 05:18:37 +0100
Subject: [R-sig-ME] How to fix a gamma model with poor fit?
In-Reply-To: <4ce632bc-040e-9a00-c36c-8d399818a884@phillipalday.com>
References: <CACw+Tff-B8WeHcTnZjT5MA--zZz59JFhZcCkm2KzXSajAUpuVQ@mail.gmail.com>
 <4ce632bc-040e-9a00-c36c-8d399818a884@phillipalday.com>
Message-ID: <CACw+TfdTaRRdyiQF7rCvfg1bVBSq3QTYo2JxrsfbDjYkmNMOxw@mail.gmail.com>

Dear Philip,

Thank you for your comments! I decided to add the information about the
lmer model with logRT as the dependent variable. I decided against using
the lmer with logRT because it also seemed to show a poor fit, so the next
option seemed to be using the glmer + Gamma. In all plots I am plotting the
residuals of the model and not the raw dependent variable as I am aware the
assumption of normality is imposed on the residuals.
The variable RT is in milliseconds, there are just some very small response
times, though still accurate. I am a bit reluctant to remove them because
a) I did not pre-registered any criteria, b) based on the design one of the
groups was overall faster than the other and that may attenuate the group
differences, though maybe winsorization would be an option.

Here are the images for the lmer logRT model.

  [7]: https://i.stack.imgur.com/l53YH.png
  [8]: https://i.stack.imgur.com/9We75.png
  [9]: https://i.stack.imgur.com/PNIqt.png
  [10]: https://i.stack.imgur.com/crz9j.png

And the post on crossvalidated with everything:
https://stats.stackexchange.com/questions/534098/glmer-gamma-model-good-fit

Thank you again!

Best wishes,

Catia

On Wed, 14 Jul 2021 at 02:11, Phillip Alday <me at phillipalday.com> wrote:

> A few quick comments:
>
> 1. The QQ-plot diagnostic needs to be against the appropriate
> distribution. For a gamma model, the theoretical quantiles comes from
> the gamma distribution, not the normal distribution.
> 2. You have a log link but your reaction-time data looks to be in
> seconds, not milliseconds. Note that log10(0.1) = -1 and log10(1) = 0,
> but log10(100) = 2 and log10(1000) = 3, so you'll get very different
> answers for seconds vs. milliseconds. The reason why log transforms are
> so nice for reaction times is not "just" the skew, but rather that there
> is an underlying power law driving the effects *on the milliseconds* scale.
>
> Are you using a gamma model because of the Lo and Andrews paper? I've
> indicated my skepticism about that work previously, but these are my
> critical points:
>
> - there's still a transformation going on, it's just in the link function
> - having a nonlinear link complicates interpretation of the coefficients
> - gamma models are much harder to fit numerically (and I believe that
> codepath is less well tested in lme4; it's a known problem in
> MixedModels.jl)
> - the usual tests on residuals, etc. now have to be done against a gamma
> distribution, not a normal, but a lot of diagnostics use the normal by
> default
> - I don't understand the obsession with "satisfying normality
> assumptions" (from their abstract) in a GLMM -- half the point of the
> *generalized* bit is that you can swap in a different distributional
> assumption (the other half is the use of a link function)
>
>
> When thinking about using a model from a particular family/distribution,
> note that the distributional assumption is *on the residuals* so the
> skew in your raw data may or may not be present in the residuals. So
> maybe you don't need a Gamma model at all.
>
> Looking at your model output, it looks like you're using sum contrasts
> -- great! But checkout contr.Sum from the car package for nicer looking
> labels. :)
>
> Phillip
>
>
>
>
> On 13/7/21 6:18 pm, C?tia Ferreira De Oliveira via R-sig-mixed-models
> wrote:
> > Dear all,
> >
> > I am sorry for reposting here after posting on cross validated here
> > <
> https://stats.stackexchange.com/questions/534098/glmer-gamma-model-good-fit
> >
> > but I am still not sure what would be the best way of going about fixing
> > this model. It seems to have poor fit if you look at the plots as they
> have
> > extremes on both sides, which would not fit well with a gamma
> distribution.
> > Despite this, the results are consistent across packages (lme4, nlme...).
> >
> > I have 209062 rows of data and this is response time data.
> > I want to determine whether there are differences between groups (Groups
> -
> > 2 levels) on the learning of a task (Probability - 2 levels) across time
> > (within sessions - Block - 4 levels / across sessions - Session - 2
> > levels). It doesn't have zero response times, but some close to zero.
> >
> > Do you have any suggestions for how one can improve a model like this or
> > whether I should just use another distribution that fits the data a bit
> > better?
> >
> > Thank you!
> >
> > Catia
> >
> >
> > Model:
> >
> >     glmer(RT ~ Prob * Bl * Session * Gr + (1  | Participant), data=
> > Data.trimmed, family = Gamma(link =
> > "log"), control=glmerControl(optimizer="bobyqa"))
> > Model summary:
> >
> >     Generalized linear mixed model fit by maximum likelihood (Adaptive
> > Gauss-Hermite Quadrature, nAGQ = 0) ['glmerMod']
> >      Family: Gamma  ( log )
> >     Formula: RT ~ Probability * Block * Session * Group + (1 |
> Participant)
> >        Data: Data.trimmed
> >     Control: glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun =
> > 1e+06))
> >
> >          AIC      BIC   logLik deviance df.resid
> >      2456107  2456538 -1228012  2456023   209020
> >
> >     Scaled residuals:
> >        Min     1Q Median     3Q    Max
> >     -4.297 -0.625 -0.158  0.440 35.691
> >
> >     Random effects:
> >      Groups      Name        Variance Std.Dev.
> >      Participant (Intercept) 0.002203 0.04694
> >      Residual                0.053481 0.23126
> >     Number of obs: 209062, groups:  Participant, 130
> >
> >     Fixed effects:
> >                                             Estimate Std. Error  t value
> > Pr(>|z|)
> >     (Intercept)                            6.024e+00  4.182e-03
> 1440.439  <
> > 2e-16 ***
> >     Probability1                          -2.835e-02  7.041e-04
> -40.265  <
> > 2e-16 ***
> >     Block2-1                              -2.925e-02  2.077e-03
> -14.084  <
> > 2e-16 ***
> >     Block3-2                              -3.676e-03  2.131e-03   -1.725
> > 0.084500 .
> >     Block4-3                               4.085e-03  2.307e-03    1.771
> > 0.076577 .
> >     Block5-4                              -1.220e-02  2.380e-03   -5.125
> > 2.98e-07 ***
> >     Session1                               4.795e-02  7.323e-04
>  65.478  <
> > 2e-16 ***
> >     Group1                                -4.616e-02  4.182e-03
> -11.037  <
> > 2e-16 ***
> >     Probability1:Block2-1                 -7.228e-03  2.077e-03   -3.480
> > 0.000501 ***
> >     Probability1:Block3-2                 -5.332e-03  2.131e-03   -2.503
> > 0.012331 *
> >     Probability1:Block4-3                 -2.076e-02  2.307e-03
>  -8.999  <
> > 2e-16 ***
> >     Probability1:Block5-4                  6.044e-03  2.380e-03    2.539
> > 0.011104 *
> >     Probability1:Session1                  1.656e-03  7.046e-04    2.351
> > 0.018743 *
> >     Block2-1:Session1                     -1.972e-02  2.077e-03
>  -9.494  <
> > 2e-16 ***
> >     Block3-2:Session1                     -8.521e-03  2.131e-03   -3.999
> > 6.35e-05 ***
> >     Block4-3:Session1                      4.380e-05  2.308e-03    0.019
> > 0.984856
> >     Block5-4:Session1                     -3.768e-03  2.380e-03   -1.583
> > 0.113389
> >     Probability1:Group1                    1.515e-03  7.041e-04    2.151
> > 0.031478 *
> >     Block2-1:Group1                       -6.161e-03  2.077e-03   -2.966
> > 0.003015 **
> >     Block3-2:Group1                       -1.129e-02  2.131e-03   -5.301
> > 1.15e-07 ***
> >     Block4-3:Group1                        7.095e-03  2.307e-03    3.076
> > 0.002101 **
> >     Block5-4:Group1                       -4.055e-03  2.380e-03   -1.704
> > 0.088414 .
> >     Session1:Group1                        3.782e-03  7.323e-04    5.164
> > 2.41e-07 ***
> >     Probability1:Block2-1:Session1         5.729e-05  2.077e-03    0.028
> > 0.977997
> >     Probability1:Block3-2:Session1         3.543e-03  2.131e-03    1.663
> > 0.096363 .
> >     Probability1:Block4-3:Session1        -6.877e-03  2.308e-03   -2.980
> > 0.002886 **
> >     Probability1:Block5-4:Session1         4.329e-03  2.380e-03    1.819
> > 0.068952 .
> >     Probability1:Block2-1:Group1          -1.238e-03  2.077e-03   -0.596
> > 0.550980
> >     Probability1:Block3-2:Group1           1.022e-02  2.131e-03    4.795
> > 1.63e-06 ***
> >     Probability1:Block4-3:Group1          -6.532e-03  2.307e-03   -2.831
> > 0.004634 **
> >     Probability1:Block5-4:Group1           2.351e-03  2.380e-03    0.988
> > 0.323373
> >     Probability1:Session1:Group1          -1.805e-03  7.046e-04   -2.562
> > 0.010412 *
> >     Block2-1:Session1:Group1              -2.060e-04  2.077e-03   -0.099
> > 0.920984
> >     Block3-2:Session1:Group1              -4.211e-03  2.131e-03   -1.977
> > 0.048094 *
> >     Block4-3:Session1:Group1               3.339e-03  2.308e-03    1.447
> > 0.147888
> >     Block5-4:Session1:Group1              -3.956e-03  2.380e-03   -1.662
> > 0.096539 .
> >     Probability1:Block2-1:Session1:Group1 -1.270e-03  2.077e-03   -0.611
> > 0.540933
> >     Probability1:Block3-2:Session1:Group1  1.678e-03  2.131e-03    0.788
> > 0.430929
> >     Probability1:Block4-3:Session1:Group1 -4.640e-03  2.308e-03   -2.010
> > 0.044392 *
> >     Probability1:Block5-4:Session1:Group1  4.714e-03  2.380e-03    1.980
> > 0.047649 *
> >     ---
> >     Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> >     Correlation matrix not shown by default, as p = 40 > 12.
> >     Use print(x, correlation=TRUE)  or
> >         vcov(x)        if you need it
> >
> > Plots:
> >
> >   [1]: https://i.stack.imgur.com/XPdtl.png
> >   [2]: https://i.stack.imgur.com/zUNRX.png
> >   [3]: https://i.stack.imgur.com/6slYG.png
> >   [4]: https://i.stack.imgur.com/LlRwT.png
> >   [5]: https://i.stack.imgur.com/TNYCP.png
> >   [6]: https://i.stack.imgur.com/45l0P.png
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>


-- 
C?tia Margarida Ferreira de Oliveira
Psychology PhD Student
Department of Psychology, Room B214
University of York, YO10 5DD
pronouns: she, her

	[[alternative HTML version deleted]]


From me @end|ng |rom ph||||p@|d@y@com  Wed Jul 14 09:41:32 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Wed, 14 Jul 2021 02:41:32 -0500
Subject: [R-sig-ME] How to fix a gamma model with poor fit?
In-Reply-To: <CACw+TfdTaRRdyiQF7rCvfg1bVBSq3QTYo2JxrsfbDjYkmNMOxw@mail.gmail.com>
References: <CACw+Tff-B8WeHcTnZjT5MA--zZz59JFhZcCkm2KzXSajAUpuVQ@mail.gmail.com>
 <4ce632bc-040e-9a00-c36c-8d399818a884@phillipalday.com>
 <CACw+TfdTaRRdyiQF7rCvfg1bVBSq3QTYo2JxrsfbDjYkmNMOxw@mail.gmail.com>
Message-ID: <5199fa71-60be-13c1-9bd5-bb30a3e9d79f@phillipalday.com>

I don't have time to examine things in depth, but the log-RT seems to do
pretty well for a big chunk of the data. There's a pretty hefty left
tail on the residuals that's not great, but it's not the worst I've ever
seen. I would start thinking about why your model is breaking down more
on that side than on the right side.

I suspect you're hitting ceiling effects in your participants - in other
words, that you've run into an asymptote around a certain minimum
reaction time. I think that's an interesting statement in its own right:
the dominant factor isn't (just) your experimental manipulation but
rather biological limits. The ceiling would also be why your model
struggles with the left tail -- the line keeps going in one direction,
but the observed values don't. The one last "easy" transformation to try
would be looking at 1/RT (the inverse transform) instead of log RT.
Beyond that and you have to get into richer models with fancier
distributions or nonlinear components, see e.g.
https://lindeloev.github.io/shiny-rt/ for an overview.

Phillip



On 13/7/21 11:18 pm, C?tia Ferreira De Oliveira wrote:
> Dear Philip,
> 
> Thank you for your comments! I decided to add the information about the
> lmer model with logRT as the dependent variable. I decided against?using
> the lmer with logRT because it also seemed to show a poor fit, so the
> next option seemed to be using the glmer?+ Gamma. In all plots I am
> plotting the residuals of the model and not the raw dependent variable
> as I am aware the assumption of normality is imposed on the residuals.
> The variable RT is in milliseconds, there are just some very small
> response times, though still accurate. I am a bit reluctant?to remove
> them because a) I did not pre-registered any criteria, b) based on the
> design one of the groups was overall faster than the other and that may
> attenuate the group differences, though maybe winsorization would be an
> option.
> 
> Here are the images for the lmer logRT model.
> 
> ? [7]: https://i.stack.imgur.com/l53YH.png
> ? [8]: https://i.stack.imgur.com/9We75.png
> ? [9]: https://i.stack.imgur.com/PNIqt.png
> ? [10]: https://i.stack.imgur.com/crz9j.png
> 
> And the post on crossvalidated?with
> everything:?https://stats.stackexchange.com/questions/534098/glmer-gamma-model-good-fit
> 
> Thank you again!
> 
> Best wishes,
> 
> Catia
> 
> On Wed, 14 Jul 2021 at 02:11, Phillip Alday <me at phillipalday.com
> <mailto:me at phillipalday.com>> wrote:
> 
>     A few quick comments:
> 
>     1. The QQ-plot diagnostic needs to be against the appropriate
>     distribution. For a gamma model, the theoretical quantiles comes from
>     the gamma distribution, not the normal distribution.
>     2. You have a log link but your reaction-time data looks to be in
>     seconds, not milliseconds. Note that log10(0.1) = -1 and log10(1) = 0,
>     but log10(100) = 2 and log10(1000) = 3, so you'll get very different
>     answers for seconds vs. milliseconds. The reason why log transforms are
>     so nice for reaction times is not "just" the skew, but rather that there
>     is an underlying power law driving the effects *on the milliseconds*
>     scale.
> 
>     Are you using a gamma model because of the Lo and Andrews paper? I've
>     indicated my skepticism about that work previously, but these are my
>     critical points:
> 
>     - there's still a transformation going on, it's just in the link
>     function
>     - having a nonlinear link complicates interpretation of the coefficients
>     - gamma models are much harder to fit numerically (and I believe that
>     codepath is less well tested in lme4; it's a known problem in
>     MixedModels.jl)
>     - the usual tests on residuals, etc. now have to be done against a gamma
>     distribution, not a normal, but a lot of diagnostics use the normal by
>     default
>     - I don't understand the obsession with "satisfying normality
>     assumptions" (from their abstract) in a GLMM -- half the point of the
>     *generalized* bit is that you can swap in a different distributional
>     assumption (the other half is the use of a link function)
> 
> 
>     When thinking about using a model from a particular family/distribution,
>     note that the distributional assumption is *on the residuals* so the
>     skew in your raw data may or may not be present in the residuals. So
>     maybe you don't need a Gamma model at all.
> 
>     Looking at your model output, it looks like you're using sum contrasts
>     -- great! But checkout contr.Sum from the car package for nicer looking
>     labels. :)
> 
>     Phillip
> 
> 
> 
> 
>     On 13/7/21 6:18 pm, C?tia Ferreira De Oliveira via
>     R-sig-mixed-models wrote:
>     > Dear all,
>     >
>     > I am sorry for reposting here after posting on cross validated here
>     >
>     <https://stats.stackexchange.com/questions/534098/glmer-gamma-model-good-fit>
>     > but I am still not sure what would be the best way of going about
>     fixing
>     > this model. It seems to have poor fit if you look at the plots as
>     they have
>     > extremes on both sides, which would not fit well with a gamma
>     distribution.
>     > Despite this, the results are consistent across packages (lme4,
>     nlme...).
>     >
>     > I have 209062 rows of data and this is response time data.
>     > I want to determine whether there are differences between groups
>     (Groups -
>     > 2 levels) on the learning of a task (Probability - 2 levels)
>     across time
>     > (within sessions - Block - 4 levels / across sessions - Session - 2
>     > levels). It doesn't have zero response times, but some close to zero.
>     >
>     > Do you have any suggestions for how one can improve a model like
>     this or
>     > whether I should just use another distribution that fits the data
>     a bit
>     > better?
>     >
>     > Thank you!
>     >
>     > Catia
>     >
>     >
>     > Model:
>     >
>     >? ? ?glmer(RT ~ Prob * Bl * Session * Gr + (1? | Participant), data=
>     > Data.trimmed, family = Gamma(link =
>     > "log"), control=glmerControl(optimizer="bobyqa"))
>     > Model summary:
>     >
>     >? ? ?Generalized linear mixed model fit by maximum likelihood (Adaptive
>     > Gauss-Hermite Quadrature, nAGQ = 0) ['glmerMod']
>     >? ? ? Family: Gamma? ( log )
>     >? ? ?Formula: RT ~ Probability * Block * Session * Group + (1 |
>     Participant)
>     >? ? ? ? Data: Data.trimmed
>     >? ? ?Control: glmerControl(optimizer = "bobyqa", optCtrl =
>     list(maxfun =
>     > 1e+06))
>     >
>     >? ? ? ? ? AIC? ? ? BIC? ?logLik deviance df.resid
>     >? ? ? 2456107? 2456538 -1228012? 2456023? ?209020
>     >
>     >? ? ?Scaled residuals:
>     >? ? ? ? Min? ? ?1Q Median? ? ?3Q? ? Max
>     >? ? ?-4.297 -0.625 -0.158? 0.440 35.691
>     >
>     >? ? ?Random effects:
>     >? ? ? Groups? ? ? Name? ? ? ? Variance Std.Dev.
>     >? ? ? Participant (Intercept) 0.002203 0.04694
>     >? ? ? Residual? ? ? ? ? ? ? ? 0.053481 0.23126
>     >? ? ?Number of obs: 209062, groups:? Participant, 130
>     >
>     >? ? ?Fixed effects:
>     >? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Estimate Std. Error? t
>     value
>     > Pr(>|z|)
>     >? ? ?(Intercept)? ? ? ? ? ? ? ? ? ? ? ? ? ? 6.024e+00? 4.182e-03
>     1440.439? <
>     > 2e-16 ***
>     >? ? ?Probability1? ? ? ? ? ? ? ? ? ? ? ? ? -2.835e-02? 7.041e-04?
>     -40.265? <
>     > 2e-16 ***
>     >? ? ?Block2-1? ? ? ? ? ? ? ? ? ? ? ? ? ? ? -2.925e-02? 2.077e-03?
>     -14.084? <
>     > 2e-16 ***
>     >? ? ?Block3-2? ? ? ? ? ? ? ? ? ? ? ? ? ? ? -3.676e-03? 2.131e-03?
>     ?-1.725
>     > 0.084500 .
>     >? ? ?Block4-3? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?4.085e-03? 2.307e-03? ?
>     1.771
>     > 0.076577 .
>     >? ? ?Block5-4? ? ? ? ? ? ? ? ? ? ? ? ? ? ? -1.220e-02? 2.380e-03?
>     ?-5.125
>     > 2.98e-07 ***
>     >? ? ?Session1? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?4.795e-02? 7.323e-04?
>     ?65.478? <
>     > 2e-16 ***
>     >? ? ?Group1? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? -4.616e-02? 4.182e-03?
>     -11.037? <
>     > 2e-16 ***
>     >? ? ?Probability1:Block2-1? ? ? ? ? ? ? ? ?-7.228e-03? 2.077e-03?
>     ?-3.480
>     > 0.000501 ***
>     >? ? ?Probability1:Block3-2? ? ? ? ? ? ? ? ?-5.332e-03? 2.131e-03?
>     ?-2.503
>     > 0.012331 *
>     >? ? ?Probability1:Block4-3? ? ? ? ? ? ? ? ?-2.076e-02? 2.307e-03?
>     ?-8.999? <
>     > 2e-16 ***
>     >? ? ?Probability1:Block5-4? ? ? ? ? ? ? ? ? 6.044e-03? 2.380e-03? ?
>     2.539
>     > 0.011104 *
>     >? ? ?Probability1:Session1? ? ? ? ? ? ? ? ? 1.656e-03? 7.046e-04? ?
>     2.351
>     > 0.018743 *
>     >? ? ?Block2-1:Session1? ? ? ? ? ? ? ? ? ? ?-1.972e-02? 2.077e-03?
>     ?-9.494? <
>     > 2e-16 ***
>     >? ? ?Block3-2:Session1? ? ? ? ? ? ? ? ? ? ?-8.521e-03? 2.131e-03?
>     ?-3.999
>     > 6.35e-05 ***
>     >? ? ?Block4-3:Session1? ? ? ? ? ? ? ? ? ? ? 4.380e-05? 2.308e-03? ?
>     0.019
>     > 0.984856
>     >? ? ?Block5-4:Session1? ? ? ? ? ? ? ? ? ? ?-3.768e-03? 2.380e-03?
>     ?-1.583
>     > 0.113389
>     >? ? ?Probability1:Group1? ? ? ? ? ? ? ? ? ? 1.515e-03? 7.041e-04? ?
>     2.151
>     > 0.031478 *
>     >? ? ?Block2-1:Group1? ? ? ? ? ? ? ? ? ? ? ?-6.161e-03? 2.077e-03?
>     ?-2.966
>     > 0.003015 **
>     >? ? ?Block3-2:Group1? ? ? ? ? ? ? ? ? ? ? ?-1.129e-02? 2.131e-03?
>     ?-5.301
>     > 1.15e-07 ***
>     >? ? ?Block4-3:Group1? ? ? ? ? ? ? ? ? ? ? ? 7.095e-03? 2.307e-03? ?
>     3.076
>     > 0.002101 **
>     >? ? ?Block5-4:Group1? ? ? ? ? ? ? ? ? ? ? ?-4.055e-03? 2.380e-03?
>     ?-1.704
>     > 0.088414 .
>     >? ? ?Session1:Group1? ? ? ? ? ? ? ? ? ? ? ? 3.782e-03? 7.323e-04? ?
>     5.164
>     > 2.41e-07 ***
>     >? ? ?Probability1:Block2-1:Session1? ? ? ? ?5.729e-05? 2.077e-03? ?
>     0.028
>     > 0.977997
>     >? ? ?Probability1:Block3-2:Session1? ? ? ? ?3.543e-03? 2.131e-03? ?
>     1.663
>     > 0.096363 .
>     >? ? ?Probability1:Block4-3:Session1? ? ? ? -6.877e-03? 2.308e-03?
>     ?-2.980
>     > 0.002886 **
>     >? ? ?Probability1:Block5-4:Session1? ? ? ? ?4.329e-03? 2.380e-03? ?
>     1.819
>     > 0.068952 .
>     >? ? ?Probability1:Block2-1:Group1? ? ? ? ? -1.238e-03? 2.077e-03?
>     ?-0.596
>     > 0.550980
>     >? ? ?Probability1:Block3-2:Group1? ? ? ? ? ?1.022e-02? 2.131e-03? ?
>     4.795
>     > 1.63e-06 ***
>     >? ? ?Probability1:Block4-3:Group1? ? ? ? ? -6.532e-03? 2.307e-03?
>     ?-2.831
>     > 0.004634 **
>     >? ? ?Probability1:Block5-4:Group1? ? ? ? ? ?2.351e-03? 2.380e-03? ?
>     0.988
>     > 0.323373
>     >? ? ?Probability1:Session1:Group1? ? ? ? ? -1.805e-03? 7.046e-04?
>     ?-2.562
>     > 0.010412 *
>     >? ? ?Block2-1:Session1:Group1? ? ? ? ? ? ? -2.060e-04? 2.077e-03?
>     ?-0.099
>     > 0.920984
>     >? ? ?Block3-2:Session1:Group1? ? ? ? ? ? ? -4.211e-03? 2.131e-03?
>     ?-1.977
>     > 0.048094 *
>     >? ? ?Block4-3:Session1:Group1? ? ? ? ? ? ? ?3.339e-03? 2.308e-03? ?
>     1.447
>     > 0.147888
>     >? ? ?Block5-4:Session1:Group1? ? ? ? ? ? ? -3.956e-03? 2.380e-03?
>     ?-1.662
>     > 0.096539 .
>     >? ? ?Probability1:Block2-1:Session1:Group1 -1.270e-03? 2.077e-03?
>     ?-0.611
>     > 0.540933
>     >? ? ?Probability1:Block3-2:Session1:Group1? 1.678e-03? 2.131e-03? ?
>     0.788
>     > 0.430929
>     >? ? ?Probability1:Block4-3:Session1:Group1 -4.640e-03? 2.308e-03?
>     ?-2.010
>     > 0.044392 *
>     >? ? ?Probability1:Block5-4:Session1:Group1? 4.714e-03? 2.380e-03? ?
>     1.980
>     > 0.047649 *
>     >? ? ?---
>     >? ? ?Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>     >
>     >? ? ?Correlation matrix not shown by default, as p = 40 > 12.
>     >? ? ?Use print(x, correlation=TRUE)? or
>     >? ? ? ? ?vcov(x)? ? ? ? if you need it
>     >
>     > Plots:
>     >
>     >? ?[1]: https://i.stack.imgur.com/XPdtl.png
>     >? ?[2]: https://i.stack.imgur.com/zUNRX.png
>     >? ?[3]: https://i.stack.imgur.com/6slYG.png
>     >? ?[4]: https://i.stack.imgur.com/LlRwT.png
>     >? ?[5]: https://i.stack.imgur.com/TNYCP.png
>     >? ?[6]: https://i.stack.imgur.com/45l0P.png
>     >
>     >? ? ? ?[[alternative HTML version deleted]]
>     >
>     > _______________________________________________
>     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >
> 
> 
> 
> -- 
> C?tia Margarida Ferreira de?Oliveira
> Psychology PhD Student
> Department of Psychology, Room B214
> University of York, YO10 5DD
> pronouns: she, her


From mrm|500 @end|ng |rom york@@c@uk  Wed Jul 14 11:17:29 2021
From: mrm|500 @end|ng |rom york@@c@uk (Michael Lawson)
Date: Wed, 14 Jul 2021 10:17:29 +0100
Subject: [R-sig-ME] 
 Modelling with uncertain (but not missing) categorical
 random effect values
In-Reply-To: <CAJuCY5xD_4QNNhbKMOjsJ2uQETWyHzaBznkUxg65_+QV-5Vw9A@mail.gmail.com>
References: <CACtWw1HWv6ph0vwt4TLpUxiojZ_3993Kop0bvfXe=3yt2Lu9JA@mail.gmail.com>
 <CAJuCY5xD_4QNNhbKMOjsJ2uQETWyHzaBznkUxg65_+QV-5Vw9A@mail.gmail.com>
Message-ID: <CACtWw1EKYSEGhYDHqrr03ZQYcnA6pQzv53umKKJcf=2pKpY1TA@mail.gmail.com>

Dear Thierry,

Many thanks for your email - that looks like what I am after. I have
never used INLA before, so thus far I have just made a basic model
without specifying any further arguments to the call. Am I on the
right lines? How would I go about extracting the predicted probability
of conspecific mating for each group within mum_sp?

values <- as.factor(unique(c(levels(dat$dad_1), levels(dat$dad_2),
levels(dat$dad_3), levels(dat$dad_4))))

formula <- con ~ mum_sp + f(mum_id, model = "iid") + f(dad_1, w_1,
values = values, model = "iid") + f(dad_2, w_2, values = values, copy
= "dad_1") + f(dad_3, w_3, values = values, copy = "dad_1") + f(dad_4,
w_4, values = values, copy = "dad_1")

model <- inla(formula, family="binomial", data=dat,
control.family=list(link='logit'))
summary(model)

Call:
   "inla(formula = formula, family = \"binomial\", data = dat,
control.family = list(link = \"logit\"))"
Time used:
    Pre = 0.462, Running = 3.3, Post = 0.115, Total = 3.88
Fixed effects:
               mean     sd 0.025quant 0.5quant 0.975quant   mode   kld
(Intercept)  12.696 10.298      0.834   10.000     40.536  6.699 0.087
mum_spL      18.725 11.824      3.426   16.051     49.365 11.804 0.023
mum_spN     -11.697 10.257    -38.926   -9.318      1.392 -6.208 0.031

Random effects:
  Name   Model
    mum_id IID model
   dad_1 IID model
   dad_2 Copy
   dad_3 Copy
   dad_4 Copy

Model hyperparameters:
                         mean       sd 0.025quant 0.5quant 0.975quant     mode
Precision for mum_id 2.03e+04 1.97e+04    977.697 1.43e+04   7.21e+04 2331.739
Precision for dad_1  9.20e-02 5.10e-02      0.025 8.20e-02   2.17e-01    0.061

Expected number of effective parameters(stdev): 25.62(0.441)
Number of equivalent replicates : 7.46

Marginal log-Likelihood:  -81.32

Many thanks,
Mike


From th|erry@onke||nx @end|ng |rom |nbo@be  Wed Jul 14 14:10:27 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Wed, 14 Jul 2021 14:10:27 +0200
Subject: [R-sig-ME] 
 Modelling with uncertain (but not missing) categorical
 random effect values
In-Reply-To: <CACtWw1EKYSEGhYDHqrr03ZQYcnA6pQzv53umKKJcf=2pKpY1TA@mail.gmail.com>
References: <CACtWw1HWv6ph0vwt4TLpUxiojZ_3993Kop0bvfXe=3yt2Lu9JA@mail.gmail.com>
 <CAJuCY5xD_4QNNhbKMOjsJ2uQETWyHzaBznkUxg65_+QV-5Vw9A@mail.gmail.com>
 <CACtWw1EKYSEGhYDHqrr03ZQYcnA6pQzv53umKKJcf=2pKpY1TA@mail.gmail.com>
Message-ID: <CAJuCY5x=ZTLNtBTcNq=BvGVfH8aooOOe98z_oudeYML47_kEzQ@mail.gmail.com>

Dear Michael,

The model formulation seems reasonable to me. I assume you refer to the
fitted values? You get them when fitting the model after adding the
argument: control.predictor = list(compute = TRUE)
Another option is to specify linear combinations. See
https://www.r-inla.org/faq#h.dwc64vjwo03.
You might want to do some reading on fitting models with INLA. I recommend
http://www.highstat.com/index.php/beginner-s-guide-to-regression-models-with-spatial-and-temporal-correlation

Looking at the model output, I noticed a few things.
1) The effects for mum_sp are extreme. Do you have (quasi) complete
separation?
2) The precision for mum_id is large (small random effects). Does that make
sense?
3) The precision fordad_id is small (very large random effects). Does that
make sense?

You probably want to specify the priors of the random effects yourself
instead of using the default priors.

Note that INLA has its dedicated forum:
https://groups.google.com/g/r-inla-discussion-group?pli=1

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op wo 14 jul. 2021 om 11:17 schreef Michael Lawson <mrml500 at york.ac.uk>:

> Dear Thierry,
>
> Many thanks for your email - that looks like what I am after. I have
> never used INLA before, so thus far I have just made a basic model
> without specifying any further arguments to the call. Am I on the
> right lines? How would I go about extracting the predicted probability
> of conspecific mating for each group within mum_sp?
>
> values <- as.factor(unique(c(levels(dat$dad_1), levels(dat$dad_2),
> levels(dat$dad_3), levels(dat$dad_4))))
>
> formula <- con ~ mum_sp + f(mum_id, model = "iid") + f(dad_1, w_1,
> values = values, model = "iid") + f(dad_2, w_2, values = values, copy
> = "dad_1") + f(dad_3, w_3, values = values, copy = "dad_1") + f(dad_4,
> w_4, values = values, copy = "dad_1")
>
> model <- inla(formula, family="binomial", data=dat,
> control.family=list(link='logit'))
> summary(model)
>
> Call:
>    "inla(formula = formula, family = \"binomial\", data = dat,
> control.family = list(link = \"logit\"))"
> Time used:
>     Pre = 0.462, Running = 3.3, Post = 0.115, Total = 3.88
> Fixed effects:
>                mean     sd 0.025quant 0.5quant 0.975quant   mode   kld
> (Intercept)  12.696 10.298      0.834   10.000     40.536  6.699 0.087
> mum_spL      18.725 11.824      3.426   16.051     49.365 11.804 0.023
> mum_spN     -11.697 10.257    -38.926   -9.318      1.392 -6.208 0.031
>
> Random effects:
>   Name   Model
>     mum_id IID model
>    dad_1 IID model
>    dad_2 Copy
>    dad_3 Copy
>    dad_4 Copy
>
> Model hyperparameters:
>                          mean       sd 0.025quant 0.5quant 0.975quant
>  mode
> Precision for mum_id 2.03e+04 1.97e+04    977.697 1.43e+04   7.21e+04
> 2331.739
> Precision for dad_1  9.20e-02 5.10e-02      0.025 8.20e-02   2.17e-01
> 0.061
>
> Expected number of effective parameters(stdev): 25.62(0.441)
> Number of equivalent replicates : 7.46
>
> Marginal log-Likelihood:  -81.32
>
> Many thanks,
> Mike
>

	[[alternative HTML version deleted]]


From mrm|500 @end|ng |rom york@@c@uk  Wed Jul 14 16:09:57 2021
From: mrm|500 @end|ng |rom york@@c@uk (Michael Lawson)
Date: Wed, 14 Jul 2021 15:09:57 +0100
Subject: [R-sig-ME] 
 Modelling with uncertain (but not missing) categorical
 random effect values
In-Reply-To: <CAJuCY5x=ZTLNtBTcNq=BvGVfH8aooOOe98z_oudeYML47_kEzQ@mail.gmail.com>
References: <CACtWw1HWv6ph0vwt4TLpUxiojZ_3993Kop0bvfXe=3yt2Lu9JA@mail.gmail.com>
 <CAJuCY5xD_4QNNhbKMOjsJ2uQETWyHzaBznkUxg65_+QV-5Vw9A@mail.gmail.com>
 <CACtWw1EKYSEGhYDHqrr03ZQYcnA6pQzv53umKKJcf=2pKpY1TA@mail.gmail.com>
 <CAJuCY5x=ZTLNtBTcNq=BvGVfH8aooOOe98z_oudeYML47_kEzQ@mail.gmail.com>
Message-ID: <CACtWw1GnjVsRUK4vuhfdMZL1xy_zB2TZT-UQ7esqyjdjVyo-7g@mail.gmail.com>

Thanks Thierry,

Yes I refer to the fitted values and getting the marginal averages of these
fitted values for each group within mum_sp.

con = 1 for all offspring of 8 out of 9 (mum_id) individuals in one of the
groups within mum_sp, so this may be creating the complete separation.
Could I specify a prior on the mum_sp fixed effect in INLA to deal with the
quasi-complete separation?

Overall the responses don't vary much within mum_id levels. Males vary a
lot in number of offspring and proportion of their offspring with
particular females and species, so the high variance is expected. I had
previously collapsed all offspring per mum_id to individual rows and run as
a simple binomial GLM with a cbind(no._conspecific_offspring /
no._heterospecific offspring) response, but this didn't seem ideal as it
doesn't account for variation among parents. To get an idea of the data
structure (and whether what I'm trying to do here makes any sense)...
overall there are 27 individuals in mum_id, 18 individuals in dad_id and 3
groups for mum_sp. There are about 200 rows of offspring (averaging ~ 7-8
offspring / mum).

Thanks, I'll check out that forum.

All the best,
Mike

On Wed, 14 Jul 2021 at 13:10, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Michael,
>
> The model formulation seems reasonable to me. I assume you refer to the
> fitted values? You get them when fitting the model after adding the
> argument: control.predictor = list(compute = TRUE)
> Another option is to specify linear combinations. See
> https://www.r-inla.org/faq#h.dwc64vjwo03.
> You might want to do some reading on fitting models with INLA. I recommend
> http://www.highstat.com/index.php/beginner-s-guide-to-regression-models-with-spatial-and-temporal-correlation
>
> Looking at the model output, I noticed a few things.
> 1) The effects for mum_sp are extreme. Do you have (quasi) complete
> separation?
> 2) The precision for mum_id is large (small random effects). Does
> that make sense?
> 3) The precision fordad_id is small (very large random effects). Does that
> make sense?
>
> You probably want to specify the priors of the random effects yourself
> instead of using the default priors.
>
> Note that INLA has its dedicated forum:
> https://groups.google.com/g/r-inla-discussion-group?pli=1
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op wo 14 jul. 2021 om 11:17 schreef Michael Lawson <mrml500 at york.ac.uk>:
>
>> Dear Thierry,
>>
>> Many thanks for your email - that looks like what I am after. I have
>> never used INLA before, so thus far I have just made a basic model
>> without specifying any further arguments to the call. Am I on the
>> right lines? How would I go about extracting the predicted probability
>> of conspecific mating for each group within mum_sp?
>>
>> values <- as.factor(unique(c(levels(dat$dad_1), levels(dat$dad_2),
>> levels(dat$dad_3), levels(dat$dad_4))))
>>
>> formula <- con ~ mum_sp + f(mum_id, model = "iid") + f(dad_1, w_1,
>> values = values, model = "iid") + f(dad_2, w_2, values = values, copy
>> = "dad_1") + f(dad_3, w_3, values = values, copy = "dad_1") + f(dad_4,
>> w_4, values = values, copy = "dad_1")
>>
>> model <- inla(formula, family="binomial", data=dat,
>> control.family=list(link='logit'))
>> summary(model)
>>
>> Call:
>>    "inla(formula = formula, family = \"binomial\", data = dat,
>> control.family = list(link = \"logit\"))"
>> Time used:
>>     Pre = 0.462, Running = 3.3, Post = 0.115, Total = 3.88
>> Fixed effects:
>>                mean     sd 0.025quant 0.5quant 0.975quant   mode   kld
>> (Intercept)  12.696 10.298      0.834   10.000     40.536  6.699 0.087
>> mum_spL      18.725 11.824      3.426   16.051     49.365 11.804 0.023
>> mum_spN     -11.697 10.257    -38.926   -9.318      1.392 -6.208 0.031
>>
>> Random effects:
>>   Name   Model
>>     mum_id IID model
>>    dad_1 IID model
>>    dad_2 Copy
>>    dad_3 Copy
>>    dad_4 Copy
>>
>> Model hyperparameters:
>>                          mean       sd 0.025quant 0.5quant 0.975quant
>>  mode
>> Precision for mum_id 2.03e+04 1.97e+04    977.697 1.43e+04   7.21e+04
>> 2331.739
>> Precision for dad_1  9.20e-02 5.10e-02      0.025 8.20e-02   2.17e-01
>> 0.061
>>
>> Expected number of effective parameters(stdev): 25.62(0.441)
>> Number of equivalent replicates : 7.46
>>
>> Marginal log-Likelihood:  -81.32
>>
>> Many thanks,
>> Mike
>>
>

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Wed Jul 14 16:35:54 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Wed, 14 Jul 2021 16:35:54 +0200
Subject: [R-sig-ME] 
 Modelling with uncertain (but not missing) categorical
 random effect values
In-Reply-To: <CACtWw1GnjVsRUK4vuhfdMZL1xy_zB2TZT-UQ7esqyjdjVyo-7g@mail.gmail.com>
References: <CACtWw1HWv6ph0vwt4TLpUxiojZ_3993Kop0bvfXe=3yt2Lu9JA@mail.gmail.com>
 <CAJuCY5xD_4QNNhbKMOjsJ2uQETWyHzaBznkUxg65_+QV-5Vw9A@mail.gmail.com>
 <CACtWw1EKYSEGhYDHqrr03ZQYcnA6pQzv53umKKJcf=2pKpY1TA@mail.gmail.com>
 <CAJuCY5x=ZTLNtBTcNq=BvGVfH8aooOOe98z_oudeYML47_kEzQ@mail.gmail.com>
 <CACtWw1GnjVsRUK4vuhfdMZL1xy_zB2TZT-UQ7esqyjdjVyo-7g@mail.gmail.com>
Message-ID: <CAJuCY5z8YmxEOb6OFFFzTC+-Q8VQKRHSrKf942E+CCoMqeSsRQ@mail.gmail.com>

Dear Michael,

I'd set the reference of mum_sp to a species with plenty of data and a raw
proportion away from the extremes. And then set a more informative prior
for the mum_sp effects.

I tend to specify the random effect priors in INLA manually as penalised
complexity priors. I've noticed in the past that the default random effect
priors can underestimate the random effect variance.

Best regards,


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op wo 14 jul. 2021 om 16:10 schreef Michael Lawson <mrml500 at york.ac.uk>:

> Thanks Thierry,
>
> Yes I refer to the fitted values and getting the marginal averages of
> these fitted values for each group within mum_sp.
>
> con = 1 for all offspring of 8 out of 9 (mum_id) individuals in one of the
> groups within mum_sp, so this may be creating the complete separation.
> Could I specify a prior on the mum_sp fixed effect in INLA to deal with the
> quasi-complete separation?
>
> Overall the responses don't vary much within mum_id levels. Males vary a
> lot in number of offspring and proportion of their offspring with
> particular females and species, so the high variance is expected. I had
> previously collapsed all offspring per mum_id to individual rows and run as
> a simple binomial GLM with a cbind(no._conspecific_offspring /
> no._heterospecific offspring) response, but this didn't seem ideal as it
> doesn't account for variation among parents. To get an idea of the data
> structure (and whether what I'm trying to do here makes any sense)...
> overall there are 27 individuals in mum_id, 18 individuals in dad_id and 3
> groups for mum_sp. There are about 200 rows of offspring (averaging ~ 7-8
> offspring / mum).
>
> Thanks, I'll check out that forum.
>
> All the best,
> Mike
>
> On Wed, 14 Jul 2021 at 13:10, Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>
>> Dear Michael,
>>
>> The model formulation seems reasonable to me. I assume you refer to the
>> fitted values? You get them when fitting the model after adding the
>> argument: control.predictor = list(compute = TRUE)
>> Another option is to specify linear combinations. See
>> https://www.r-inla.org/faq#h.dwc64vjwo03.
>> You might want to do some reading on fitting models with INLA. I
>> recommend
>> http://www.highstat.com/index.php/beginner-s-guide-to-regression-models-with-spatial-and-temporal-correlation
>>
>> Looking at the model output, I noticed a few things.
>> 1) The effects for mum_sp are extreme. Do you have (quasi) complete
>> separation?
>> 2) The precision for mum_id is large (small random effects). Does
>> that make sense?
>> 3) The precision fordad_id is small (very large random effects). Does
>> that make sense?
>>
>> You probably want to specify the priors of the random effects yourself
>> instead of using the default priors.
>>
>> Note that INLA has its dedicated forum:
>> https://groups.google.com/g/r-inla-discussion-group?pli=1
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>> AND FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88 bus 73, 1000 Brussel
>> www.inbo.be
>>
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>
>> <https://www.inbo.be>
>>
>>
>> Op wo 14 jul. 2021 om 11:17 schreef Michael Lawson <mrml500 at york.ac.uk>:
>>
>>> Dear Thierry,
>>>
>>> Many thanks for your email - that looks like what I am after. I have
>>> never used INLA before, so thus far I have just made a basic model
>>> without specifying any further arguments to the call. Am I on the
>>> right lines? How would I go about extracting the predicted probability
>>> of conspecific mating for each group within mum_sp?
>>>
>>> values <- as.factor(unique(c(levels(dat$dad_1), levels(dat$dad_2),
>>> levels(dat$dad_3), levels(dat$dad_4))))
>>>
>>> formula <- con ~ mum_sp + f(mum_id, model = "iid") + f(dad_1, w_1,
>>> values = values, model = "iid") + f(dad_2, w_2, values = values, copy
>>> = "dad_1") + f(dad_3, w_3, values = values, copy = "dad_1") + f(dad_4,
>>> w_4, values = values, copy = "dad_1")
>>>
>>> model <- inla(formula, family="binomial", data=dat,
>>> control.family=list(link='logit'))
>>> summary(model)
>>>
>>> Call:
>>>    "inla(formula = formula, family = \"binomial\", data = dat,
>>> control.family = list(link = \"logit\"))"
>>> Time used:
>>>     Pre = 0.462, Running = 3.3, Post = 0.115, Total = 3.88
>>> Fixed effects:
>>>                mean     sd 0.025quant 0.5quant 0.975quant   mode   kld
>>> (Intercept)  12.696 10.298      0.834   10.000     40.536  6.699 0.087
>>> mum_spL      18.725 11.824      3.426   16.051     49.365 11.804 0.023
>>> mum_spN     -11.697 10.257    -38.926   -9.318      1.392 -6.208 0.031
>>>
>>> Random effects:
>>>   Name   Model
>>>     mum_id IID model
>>>    dad_1 IID model
>>>    dad_2 Copy
>>>    dad_3 Copy
>>>    dad_4 Copy
>>>
>>> Model hyperparameters:
>>>                          mean       sd 0.025quant 0.5quant 0.975quant
>>>  mode
>>> Precision for mum_id 2.03e+04 1.97e+04    977.697 1.43e+04   7.21e+04
>>> 2331.739
>>> Precision for dad_1  9.20e-02 5.10e-02      0.025 8.20e-02   2.17e-01
>>> 0.061
>>>
>>> Expected number of effective parameters(stdev): 25.62(0.441)
>>> Number of equivalent replicates : 7.46
>>>
>>> Marginal log-Likelihood:  -81.32
>>>
>>> Many thanks,
>>> Mike
>>>
>>

	[[alternative HTML version deleted]]


From @|ex@ndre@@nto@br @end|ng |rom y@hoo@com@br  Wed Jul 14 17:02:07 2021
From: @|ex@ndre@@nto@br @end|ng |rom y@hoo@com@br (Alexandre Santos)
Date: Wed, 14 Jul 2021 15:02:07 +0000 (UTC)
Subject: [R-sig-ME] Extract correct DF and random variance in GLMM
References: <359713612.4639208.1626274927797.ref@mail.yahoo.com>
Message-ID: <359713612.4639208.1626274927797@mail.yahoo.com>

Hi Everyone,

I'm my "scarab" data set, I have the response variable number of species ("Richness"), and my explanatory variables are lead concentration ("PbPPM") in 9 transects ("Plot") with 5 samples by transects. But the 5 samples by transects are pseudoreplication in each variable "Plot". Explained this, I don't have 43 degress of fredom (DF) (9*5= 45 = 1PbPPM - 1 = 43) and I used GLMM for considering this ((1|Plot)). Im my example:

library(lme4)?
scarab <- read.csv("https://raw.githubusercontent.com/Leprechault/PEN-533/master/scarab.csv")
str(scarab)
#'data.frame':? 45 obs. of? 4 variables:
# $ TrapID? : num? 1 2 3 4 5 6 7 8 9 10 ...
# $ Richness: num? 11 10 13 11 10 8 9 8 19 17 ...
# $ PbPPM? ?: num? 0.045 1.036 1.336 0.616 0.684 ...
# $ Plot? ? : Factor w/ 9 levels "1","2","3","4",..: 1 1 1 1 1 2 2 2 2 2 ...

# GLMM model
scara.glmer<-glmer(Richness~PbPPM + (1|Plot),data=scarab,family="poisson")
summary(scara.glmer)
#Generalized linear mixed model fit by maximum likelihood (Laplace
#? Approximation) [glmerMod]
# Family: poisson? ( log )
# Formula: Richness ~ PbPPM + (1 | Plot)
# ...
#Random effects:
# Groups Name? ? ? ? Variance Std.Dev.
# Plot? ?(Intercept) 0.2978? ?0.5457??
#Number of obs: 45, groups:? Plot, 9
#Fixed effects:
#? ? ? ? ? ? Estimate Std. Error z value Pr(>|z|)? ??
#(Intercept)? ?1.9982? ? ?0.2105? ?9.495? < 2e-16 ***
#PbPPM? ? ? ? -0.5625? ? ?0.1198? -4.695 2.66e-06 ***
#---
#Signif. codes:? 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

#Correlation of Fixed Effects:
? ? ? (Intr)
#PbPPM -0.368

Based on this analysis, I have two questions:

1) There is no way to find the number of degrees of freedom corrected in the output because, for me is not clear in "Number of obs: 45, groups:? Plot, 9".

2) I'd like to calculate the contribution in the variance of the variable "Plot" because, in lmer models, I have Variance of the Variable/Residual variance + Variance of the Variable. Still, in the glmer I don't have the residual variance.

Thanks in advance,

Alexandre


From ebhod@ghe|@|th @end|ng |rom gm@||@com  Wed Jul 14 17:38:59 2021
From: ebhod@ghe|@|th @end|ng |rom gm@||@com (Ebhodaghe Faith)
Date: Wed, 14 Jul 2021 18:38:59 +0300
Subject: [R-sig-ME] Problem installing glmmTMB
Message-ID: <CAEatWUoFU-aJTg-010CVgPWOnUfE5qNhG2cCu9oE4BH6s=C5Tg@mail.gmail.com>

Dear All,

I have made several attempts to install the glmmTMB package in R, but keep
getting the response 'glmmTMB is not available (for R version 3.3.2)'. I
tried using other versions of R (3.5.2, 3.5.3, & 4.1.0) but without
success. Could someone please kindly help diagnose the cause?

Regards,
Faith

	[[alternative HTML version deleted]]


From v|ctor@or|b@m|@e @end|ng |rom gm@||@com  Wed Jul 14 17:41:28 2021
From: v|ctor@or|b@m|@e @end|ng |rom gm@||@com (Victor Oribamise)
Date: Wed, 14 Jul 2021 11:41:28 -0400
Subject: [R-sig-ME] Problem installing glmmTMB
In-Reply-To: <CAEatWUoFU-aJTg-010CVgPWOnUfE5qNhG2cCu9oE4BH6s=C5Tg@mail.gmail.com>
References: <CAEatWUoFU-aJTg-010CVgPWOnUfE5qNhG2cCu9oE4BH6s=C5Tg@mail.gmail.com>
Message-ID: <CA+iPCzaM8g4x=0V-DuLi8HeZ08PzB-naFjxqOCvYBcMwvQhUNA@mail.gmail.com>

You can install using devtools

devtools::install_github(?glmmTMB/glmmTMB/glmmTMB?)

On Wed, Jul 14, 2021 at 11:39 AM Ebhodaghe Faith <ebhodaghefaith at gmail.com>
wrote:

> Dear All,
>
> I have made several attempts to install the glmmTMB package in R, but keep
> getting the response 'glmmTMB is not available (for R version 3.3.2)'. I
> tried using other versions of R (3.5.2, 3.5.3, & 4.1.0) but without
> success. Could someone please kindly help diagnose the cause?
>
> Regards,
> Faith
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Wed Jul 14 18:34:27 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 14 Jul 2021 12:34:27 -0400
Subject: [R-sig-ME] Problem installing glmmTMB
In-Reply-To: <CA+iPCzaM8g4x=0V-DuLi8HeZ08PzB-naFjxqOCvYBcMwvQhUNA@mail.gmail.com>
References: <CAEatWUoFU-aJTg-010CVgPWOnUfE5qNhG2cCu9oE4BH6s=C5Tg@mail.gmail.com>
 <CA+iPCzaM8g4x=0V-DuLi8HeZ08PzB-naFjxqOCvYBcMwvQhUNA@mail.gmail.com>
Message-ID: <2506d0cb-6e56-1af6-cb7b-55a5978c73d2@gmail.com>

   Yes.  A few comments:

1.

remotes::install_github("glmmTMB/glmmTMB/glmmTMB")

is a little bit better (the 'remotes' package has fewer dependencies, 
and this version uses plain quotes rather than "fancy" quotes (??) which 
are likely to confuse R.

2. glmmTMB has been *temporarily* removed from CRAN, which would explain 
why you can't install it even for the latest version of R - we've 
submitted a new version and hope it will be restored soon (fingers 
crossed), although it will take a few more days for the Windows & MacOS 
binaries to be restored even if it gets back today

3. In order to install from source you will need to have development 
tools (compilers etc.) installed. We might be able to provide binaries 
(see http://glmmtmb.github.io/glmmTMB/ ), but almost certainly not for 
older versions of R ...

   cheers
    Ben Bolker




On 7/14/21 11:41 AM, Victor Oribamise wrote:
> You can install using devtools
> 
> devtools::install_github(?glmmTMB/glmmTMB/glmmTMB?)
> 
> On Wed, Jul 14, 2021 at 11:39 AM Ebhodaghe Faith <ebhodaghefaith at gmail.com>
> wrote:
> 
>> Dear All,
>>
>> I have made several attempts to install the glmmTMB package in R, but keep
>> getting the response 'glmmTMB is not available (for R version 3.3.2)'. I
>> tried using other versions of R (3.5.2, 3.5.3, & 4.1.0) but without
>> success. Could someone please kindly help diagnose the cause?
>>
>> Regards,
>> Faith
>>
>>          [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics


From ebhod@ghe|@|th @end|ng |rom gm@||@com  Thu Jul 15 13:45:47 2021
From: ebhod@ghe|@|th @end|ng |rom gm@||@com (Ebhodaghe Faith)
Date: Thu, 15 Jul 2021 14:45:47 +0300
Subject: [R-sig-ME] Problem installing glmmTMB
In-Reply-To: <2506d0cb-6e56-1af6-cb7b-55a5978c73d2@gmail.com>
References: <CAEatWUoFU-aJTg-010CVgPWOnUfE5qNhG2cCu9oE4BH6s=C5Tg@mail.gmail.com>
 <CA+iPCzaM8g4x=0V-DuLi8HeZ08PzB-naFjxqOCvYBcMwvQhUNA@mail.gmail.com>
 <2506d0cb-6e56-1af6-cb7b-55a5978c73d2@gmail.com>
Message-ID: <CAEatWUrQvbefBZNP5EbzBQB7hC0_V3G4ma2zb8uETTWykBYpXA@mail.gmail.com>

Many thanks, Victor and Ben.

I have now successfully installed the package following your instructions.

Regards,
Faith

On Wed, 14 Jul 2021, 7:34 p.m. Ben Bolker, <bbolker at gmail.com> wrote:

>    Yes.  A few comments:
>
> 1.
>
> remotes::install_github("glmmTMB/glmmTMB/glmmTMB")
>
> is a little bit better (the 'remotes' package has fewer dependencies,
> and this version uses plain quotes rather than "fancy" quotes (??) which
> are likely to confuse R.
>
> 2. glmmTMB has been *temporarily* removed from CRAN, which would explain
> why you can't install it even for the latest version of R - we've
> submitted a new version and hope it will be restored soon (fingers
> crossed), although it will take a few more days for the Windows & MacOS
> binaries to be restored even if it gets back today
>
> 3. In order to install from source you will need to have development
> tools (compilers etc.) installed. We might be able to provide binaries
> (see http://glmmtmb.github.io/glmmTMB/ ), but almost certainly not for
> older versions of R ...
>
>    cheers
>     Ben Bolker
>
>
>
>
> On 7/14/21 11:41 AM, Victor Oribamise wrote:
> > You can install using devtools
> >
> > devtools::install_github(?glmmTMB/glmmTMB/glmmTMB?)
> >
> > On Wed, Jul 14, 2021 at 11:39 AM Ebhodaghe Faith <
> ebhodaghefaith at gmail.com>
> > wrote:
> >
> >> Dear All,
> >>
> >> I have made several attempts to install the glmmTMB package in R, but
> keep
> >> getting the response 'glmmTMB is not available (for R version 3.3.2)'. I
> >> tried using other versions of R (3.5.2, 3.5.3, & 4.1.0) but without
> >> success. Could someone please kindly help diagnose the cause?
> >>
> >> Regards,
> >> Faith
> >>
> >>          [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> --
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> Graduate chair, Mathematics & Statistics
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From d@|uedecke @end|ng |rom uke@de  Thu Jul 15 15:32:40 2021
From: d@|uedecke @end|ng |rom uke@de (=?iso-8859-1?Q?Daniel_L=FCdecke?=)
Date: Thu, 15 Jul 2021 15:32:40 +0200
Subject: [R-sig-ME] Problem installing glmmTMB
In-Reply-To: <CAEatWUoFU-aJTg-010CVgPWOnUfE5qNhG2cCu9oE4BH6s=C5Tg@mail.gmail.com>
References: <CAEatWUoFU-aJTg-010CVgPWOnUfE5qNhG2cCu9oE4BH6s=C5Tg@mail.gmail.com>
Message-ID: <003501d7797d$e303a9e0$a90afda0$@uke.de>

The package is archived:
https://cran.r-project.org/web/packages/glmmTMB/index.html

I guess it will be back on CRAN soon, meanwhile you can install it from
GitHub using the devtools or remotes packages:

devtools::install_github("glmmTMB/glmmTMB/glmmTMB")

or

remotes::install_github("glmmTMB/glmmTMB/glmmTMB")

Best
Daniel

-----Urspr?ngliche Nachricht-----
Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Im
Auftrag von Ebhodaghe Faith
Gesendet: Mittwoch, 14. Juli 2021 17:39
An: R-mixed models mailing list <r-sig-mixed-models at r-project.org>
Betreff: [R-sig-ME] Problem installing glmmTMB

Dear All,

I have made several attempts to install the glmmTMB package in R, but keep
getting the response 'glmmTMB is not available (for R version 3.3.2)'. I
tried using other versions of R (3.5.2, 3.5.3, & 4.1.0) but without
success. Could someone please kindly help diagnose the cause?

Regards,
Faith

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Joachim Pr?l?, Prof. Dr. Blanche Schwappach-Pignataro, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING


From kj@j@o|omon @end|ng |rom gm@||@com  Thu Jul 15 15:44:08 2021
From: kj@j@o|omon @end|ng |rom gm@||@com (Jack Solomon)
Date: Thu, 15 Jul 2021 08:44:08 -0500
Subject: [R-sig-ME] Is crossed random-effect the only choice?
In-Reply-To: <CA+sL+8WoDgEKfttJrOs-1hxO6hg34pGKtz+XJ2Fn2zp=ngf=8A@mail.gmail.com>
References: <CA+sL+8VM5R5pxhY12E8VerpmyoOquTxEAKQcg=YQqeiqu0meaQ@mail.gmail.com>
 <ccb81c51-ec18-21f3-a9b1-7d354e5e6187@gmail.com>
 <CA+sL+8WoDgEKfttJrOs-1hxO6hg34pGKtz+XJ2Fn2zp=ngf=8A@mail.gmail.com>
Message-ID: <CA+sL+8UcQJmOXv+uXiXSK2R3GWFrYX4-mzS-fiU8FWugvzifvQ@mail.gmail.com>

Dear Ben,

In the case of #3 in your response, if the researcher intends to generalize
beyond the 3 levels of the categorical factor/ predictor X, then can s/he
use: ~ (1|H) + (1|X)?

If yes, then H and X will be crossed?

Thanks,
Jack


On Sat, Jul 10, 2021, 10:36 PM Jack Solomon <kj.jsolomon at gmail.com> wrote:

> Dear Ben,
>
> Thank you for your informative response. I think # 4 is what matches my
> situation.
>
> Thanks again, Jack
>
> On Sat, Jul 10, 2021 at 8:30 PM Ben Bolker <bbolker at gmail.com> wrote:
>
>>    The "crossed vs random" terminology is only relevant in models with
>> more than one grouping variable.  I would call (1|X) " a random effect
>> of X" or more precisely "a random-intercept model with grouping variable
>> X"
>>
>>    However, your question is a little unclear to me.  Is X a grouping
>> variable or a predictor variable (numeric or categorical) that varies
>> across groups?
>>
>>    I can think of four possibilities.
>>
>>   1. X is the grouping variable (e.g. "hospital"). Then ~ (1|X) is a
>> model that describes variation in the model intercept / baseline value,
>> across hospitals.
>>
>>   2. X is a continuous covariate (e.g. annual hospital budget).  Then if
>> H is the factor designating hospitals, we want  ~ X + (1|H) (plus any
>> other fixed effects of interest. (It doesn't make sense / isn't
>> identifiable to fit a random-slopes model ~ (H | X) because budgets
>> don't vary within hospitals.
>>
>> 3. X is a categorical / factor predictor (e.g. hospital size class
>> {small, medium, large} with multiple hospitals measured in each size
>> class:  ~ X + (1|H) (the same as #2).
>>
>> 4. X is a categorical predictor with unique values for each hospital
>> (e.g. postal code).  Then X is redundant with H, you shouldn't try to
>> include them both in the same model.
>>
>> On 7/10/21 4:55 PM, Jack Solomon wrote:
>> > Hello Allo,
>> >
>> > In my two-level data structure, I have a cluster-level variable (called
>> > "X"; one that doesn't vary in any cluster). If I intend to generalize
>> > beyond X's current possible levels, then, I should take X as a random
>> > effect.
>> >
>> > However, because "X" doesn't vary in any cluster, therefore, such a
>> random
>> > effect necessarily must be a crossed random effect (e.g., "~ 1 | X"),
>> > correct?
>> >
>> > If yes, then what is "X" crossed with?
>> >
>> > Thank you,
>> > Jack
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>>
>> --
>> Dr. Benjamin Bolker
>> Professor, Mathematics & Statistics and Biology, McMaster University
>> Director, School of Computational Science and Engineering
>> Graduate chair, Mathematics & Statistics
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Thu Jul 15 15:46:21 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 15 Jul 2021 09:46:21 -0400
Subject: [R-sig-ME] Is crossed random-effect the only choice?
In-Reply-To: <CA+sL+8UcQJmOXv+uXiXSK2R3GWFrYX4-mzS-fiU8FWugvzifvQ@mail.gmail.com>
References: <CA+sL+8VM5R5pxhY12E8VerpmyoOquTxEAKQcg=YQqeiqu0meaQ@mail.gmail.com>
 <ccb81c51-ec18-21f3-a9b1-7d354e5e6187@gmail.com>
 <CA+sL+8WoDgEKfttJrOs-1hxO6hg34pGKtz+XJ2Fn2zp=ngf=8A@mail.gmail.com>
 <CA+sL+8UcQJmOXv+uXiXSK2R3GWFrYX4-mzS-fiU8FWugvzifvQ@mail.gmail.com>
Message-ID: <6b3b224f-71da-fb99-fe34-d3ff8f90facc@gmail.com>



On 7/15/21 9:44 AM, Jack Solomon wrote:
> Dear Ben,
> 
> In the case of #3 in your response, if the researcher intends to 
> generalize beyond the 3 levels of the categorical factor/ predictor X, 
> then can s/he use: ~ (1|H) + (1|X)?
> 
> If yes, then H and X will be crossed?
> 
> Thanks,
> Jack

   Yes, and yes.
> 
> 
> On Sat, Jul 10, 2021, 10:36 PM Jack Solomon <kj.jsolomon at gmail.com 
> <mailto:kj.jsolomon at gmail.com>> wrote:
> 
>     Dear?Ben,
> 
>     Thank you for your informative?response. I think # 4 is what matches
>     my situation.
> 
>     Thanks again, Jack
> 
>     On Sat, Jul 10, 2021 at 8:30 PM Ben Bolker <bbolker at gmail.com
>     <mailto:bbolker at gmail.com>> wrote:
> 
>          ? ?The "crossed vs random" terminology is only relevant in
>         models with
>         more than one grouping variable.? I would call (1|X) " a random
>         effect
>         of X" or more precisely "a random-intercept model with grouping
>         variable X"
> 
>          ? ?However, your question is a little unclear to me.? Is X a
>         grouping
>         variable or a predictor variable (numeric or categorical) that
>         varies
>         across groups?
> 
>          ? ?I can think of four possibilities.
> 
>          ? 1. X is the grouping variable (e.g. "hospital"). Then ~ (1|X)
>         is a
>         model that describes variation in the model intercept / baseline
>         value,
>         across hospitals.
> 
>          ? 2. X is a continuous covariate (e.g. annual hospital
>         budget).? Then if
>         H is the factor designating hospitals, we want? ~ X + (1|H)
>         (plus any
>         other fixed effects of interest. (It doesn't make sense / isn't
>         identifiable to fit a random-slopes model ~ (H | X) because budgets
>         don't vary within hospitals.
> 
>         3. X is a categorical / factor predictor (e.g. hospital size class
>         {small, medium, large} with multiple hospitals measured in each
>         size
>         class:? ~ X + (1|H) (the same as #2).
> 
>         4. X is a categorical predictor with unique values for each
>         hospital
>         (e.g. postal code).? Then X is redundant with H, you shouldn't
>         try to
>         include them both in the same model.
> 
>         On 7/10/21 4:55 PM, Jack Solomon wrote:
>          > Hello Allo,
>          >
>          > In my two-level data structure, I have a cluster-level
>         variable (called
>          > "X"; one that doesn't vary in any cluster). If I intend to
>         generalize
>          > beyond X's current possible levels, then, I should take X as
>         a random
>          > effect.
>          >
>          > However, because "X" doesn't vary in any cluster, therefore,
>         such a random
>          > effect necessarily must be a crossed random effect (e.g., "~
>         1 | X"),
>          > correct?
>          >
>          > If yes, then what is "X" crossed with?
>          >
>          > Thank you,
>          > Jack
>          >
>          >? ? ? ?[[alternative HTML version deleted]]
>          >
>          > _______________________________________________
>          > R-sig-mixed-models at r-project.org
>         <mailto:R-sig-mixed-models at r-project.org> mailing list
>          > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>         <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>          >
> 
>         -- 
>         Dr. Benjamin Bolker
>         Professor, Mathematics & Statistics and Biology, McMaster University
>         Director, School of Computational Science and Engineering
>         Graduate chair, Mathematics & Statistics
> 
>         _______________________________________________
>         R-sig-mixed-models at r-project.org
>         <mailto:R-sig-mixed-models at r-project.org> mailing list
>         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>         <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics


From m@rk@6 @end|ng |rom uw@edu  Thu Jul 15 20:22:52 2021
From: m@rk@6 @end|ng |rom uw@edu (Mark Sorel)
Date: Thu, 15 Jul 2021 11:22:52 -0700
Subject: [R-sig-ME] contrast sum with interaction
Message-ID: <CAG=EQjiNChtapMWBWBBW7m59EujvCqkud+f8iqbH3Jq+R9K3oQ@mail.gmail.com>

Not specifically a glmmTMB question, but maybe someone here can help.
I'd like to use a contrast sum constraint with an interaction between a
continuous and discrete variable, but I can't seem to get model.matrix to
do what I want.

The situation is that I want a categorical variable that is coded with a
sum constraint but only included in some rows of the model matrix (which is
why I am using the interaction with the continuous 0/1 valued variable).
Maybe there is a better way to code this.

Here is an example of what I mean:

dat<-data.frame(y=1,cont.var=rep(0:1,each=2),disc.var=rep(c("a","b"),2));
model.matrix(y~ cont.var  : disc.var  ,data=dat,contrasts.arg =
list(disc.var="contr.sum"))

What I'd like in this example is a model matrix with two columns, where the
second column has 0 when cont.var =0, 1 when cont.var=1 & disc.var = a, and
-1 when cont.var=1 and disc.var=b.



Thanks so much for your help! -Mark

-- 
Mark Sorel
Doctoral Student
Washington Cooperative Fish and Wildlife Research Unit
School of Aquatic and Fishery Sciences
University of Washington
Cell: 607-351-7352
He/ him/ his


*The University of Washington acknowledges the Coast Salish peoples of this
land, the land which touches the shared waters of all tribes and bands
within the Suquamish, Tulalip and Muckleshoot nations*.

	[[alternative HTML version deleted]]


From kj@j@o|omon @end|ng |rom gm@||@com  Fri Jul 16 01:08:37 2021
From: kj@j@o|omon @end|ng |rom gm@||@com (Jack Solomon)
Date: Thu, 15 Jul 2021 18:08:37 -0500
Subject: [R-sig-ME] Is crossed random-effect the only choice?
In-Reply-To: <6b3b224f-71da-fb99-fe34-d3ff8f90facc@gmail.com>
References: <CA+sL+8VM5R5pxhY12E8VerpmyoOquTxEAKQcg=YQqeiqu0meaQ@mail.gmail.com>
 <ccb81c51-ec18-21f3-a9b1-7d354e5e6187@gmail.com>
 <CA+sL+8WoDgEKfttJrOs-1hxO6hg34pGKtz+XJ2Fn2zp=ngf=8A@mail.gmail.com>
 <CA+sL+8UcQJmOXv+uXiXSK2R3GWFrYX4-mzS-fiU8FWugvzifvQ@mail.gmail.com>
 <6b3b224f-71da-fb99-fe34-d3ff8f90facc@gmail.com>
Message-ID: <CA+sL+8U7hs3BoFt9m=0ymqfTzqxCK5bWCgCTB6oB80JjP=xBNQ@mail.gmail.com>

Dear Ben,

Just to make sure, the structure of my data is below. With this data
structure, I wonder why ~ (1|H) + (1|X) would indicate that H and X are
crossed random-effects?

Because theoretically every value of X is capable of meeting every value of
H (Or because each value of X means the same thing across any given value
of H)?

Does this also mean each unique cluster (separately for H & X) is
considered correlated with another cluster?

Thank you, Jack

H  X
1   2
1   2
2   1
2   1
2   1
3   2
4   1

On Thu, Jul 15, 2021 at 8:46 AM Ben Bolker <bbolker at gmail.com> wrote:

>
>
> On 7/15/21 9:44 AM, Jack Solomon wrote:
> > Dear Ben,
> >
> > In the case of #3 in your response, if the researcher intends to
> > generalize beyond the 3 levels of the categorical factor/ predictor X,
> > then can s/he use: ~ (1|H) + (1|X)?
> >
> > If yes, then H and X will be crossed?
> >
> > Thanks,
> > Jack
>
>    Yes, and yes.
> >
> >
> > On Sat, Jul 10, 2021, 10:36 PM Jack Solomon <kj.jsolomon at gmail.com
> > <mailto:kj.jsolomon at gmail.com>> wrote:
> >
> >     Dear Ben,
> >
> >     Thank you for your informative response. I think # 4 is what matches
> >     my situation.
> >
> >     Thanks again, Jack
> >
> >     On Sat, Jul 10, 2021 at 8:30 PM Ben Bolker <bbolker at gmail.com
> >     <mailto:bbolker at gmail.com>> wrote:
> >
> >             The "crossed vs random" terminology is only relevant in
> >         models with
> >         more than one grouping variable.  I would call (1|X) " a random
> >         effect
> >         of X" or more precisely "a random-intercept model with grouping
> >         variable X"
> >
> >             However, your question is a little unclear to me.  Is X a
> >         grouping
> >         variable or a predictor variable (numeric or categorical) that
> >         varies
> >         across groups?
> >
> >             I can think of four possibilities.
> >
> >            1. X is the grouping variable (e.g. "hospital"). Then ~ (1|X)
> >         is a
> >         model that describes variation in the model intercept / baseline
> >         value,
> >         across hospitals.
> >
> >            2. X is a continuous covariate (e.g. annual hospital
> >         budget).  Then if
> >         H is the factor designating hospitals, we want  ~ X + (1|H)
> >         (plus any
> >         other fixed effects of interest. (It doesn't make sense / isn't
> >         identifiable to fit a random-slopes model ~ (H | X) because
> budgets
> >         don't vary within hospitals.
> >
> >         3. X is a categorical / factor predictor (e.g. hospital size
> class
> >         {small, medium, large} with multiple hospitals measured in each
> >         size
> >         class:  ~ X + (1|H) (the same as #2).
> >
> >         4. X is a categorical predictor with unique values for each
> >         hospital
> >         (e.g. postal code).  Then X is redundant with H, you shouldn't
> >         try to
> >         include them both in the same model.
> >
> >         On 7/10/21 4:55 PM, Jack Solomon wrote:
> >          > Hello Allo,
> >          >
> >          > In my two-level data structure, I have a cluster-level
> >         variable (called
> >          > "X"; one that doesn't vary in any cluster). If I intend to
> >         generalize
> >          > beyond X's current possible levels, then, I should take X as
> >         a random
> >          > effect.
> >          >
> >          > However, because "X" doesn't vary in any cluster, therefore,
> >         such a random
> >          > effect necessarily must be a crossed random effect (e.g., "~
> >         1 | X"),
> >          > correct?
> >          >
> >          > If yes, then what is "X" crossed with?
> >          >
> >          > Thank you,
> >          > Jack
> >          >
> >          >       [[alternative HTML version deleted]]
> >          >
> >          > _______________________________________________
> >          > R-sig-mixed-models at r-project.org
> >         <mailto:R-sig-mixed-models at r-project.org> mailing list
> >          > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >         <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >          >
> >
> >         --
> >         Dr. Benjamin Bolker
> >         Professor, Mathematics & Statistics and Biology, McMaster
> University
> >         Director, School of Computational Science and Engineering
> >         Graduate chair, Mathematics & Statistics
> >
> >         _______________________________________________
> >         R-sig-mixed-models at r-project.org
> >         <mailto:R-sig-mixed-models at r-project.org> mailing list
> >         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >         <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >
>
> --
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> Graduate chair, Mathematics & Statistics
>

	[[alternative HTML version deleted]]


From Amirhossei@@Amirhossei@T@iebi m@iii@g oii r@dboudumc@@i  Sat Jul 17 08:22:00 2021
From: Amirhossei@@Amirhossei@T@iebi m@iii@g oii r@dboudumc@@i (Amirhossei@@Amirhossei@T@iebi m@iii@g oii r@dboudumc@@i)
Date: Sat, 17 Jul 2021 06:22:00 +0000
Subject: [R-sig-ME] Theta Value in glmer
Message-ID: <1626502920034.31487@radboudumc.nl>

Dear all,

I am trying to fit a negative binomial regression using lme4 package. After several attempts using glmer.nb and having error of convergence, I have switched to glmer function to could set the argument nAGQ=0 and used negative binomial function as the family argument.
The question here is, as the theta value in negative binomial function I tried to use the theta value that glm.nb of package MASS gave me (157); but based on the vignette of glmer I can use theta=1.75. Could you please clarify that how can I choose the best theta value here and until what extend that can change my results? Or based on what parameter in model output I can understand that I used the best theta value?

Kind regards,
Amir

De informatie in dit bericht is uitsluitend bestemd voor de geadresseerde. Aan dit bericht en de bijlagen kunnen geen rechten worden ontleend. Heeft u deze e-mail onbedoeld ontvangen? Dan verzoeken wij u het te vernietigen en de afzender te informeren. Openbaar maken, kopi?ren en verspreiden van deze e-mail of informatie uit deze e-mail is alleen toegestaan met voorafgaande schriftelijke toestemming van de afzender. Het Radboudumc staat geregistreerd bij de Kamer van Koophandel in het handelsregister onder nummer 80262783.

The content of this message is intended solely for the addressee. No rights can be derived from this message or its attachments. If you are not the intended recipient, we kindly request you to delete the message and inform the sender. It is strictly prohibited to disclose, copy or distribute this email or the information inside it, without a written consent from the sender. Radboud university medical center is registered with the Dutch Chamber of Commerce trade register with number 80262783.

	[[alternative HTML version deleted]]


From b|mono@om @end|ng |rom gm@||@com  Sun Jul 18 17:09:37 2021
From: b|mono@om @end|ng |rom gm@||@com (=?UTF-8?B?UmVuw6k=?=)
Date: Sun, 18 Jul 2021 17:09:37 +0200
Subject: [R-sig-ME] contrast sum with interaction
In-Reply-To: <CAG=EQjiNChtapMWBWBBW7m59EujvCqkud+f8iqbH3Jq+R9K3oQ@mail.gmail.com>
References: <CAG=EQjiNChtapMWBWBBW7m59EujvCqkud+f8iqbH3Jq+R9K3oQ@mail.gmail.com>
Message-ID: <CADcpBHPc_+z8RyT8guRZ6DAGReBbL3Sm_QumgZ85vZtwx6_DFA@mail.gmail.com>

Hi Mark,

"The situation is that I want a categorical variable that is coded with a
sum constraint but only included in some rows "

Almost sounds like you could also simply delete all cont=0 rows... But I
assume you want something like this?

dat<-data.frame(y=1,cont.var=rep(0:1,each=2),
                disc.var=rep(c("a","b"),2));
dat$disc.var<-factor(dat$disc.var,levels=c("a","b"))
dat$cont.var<-as.factor(dat$cont.var)

model.matrix(y~ cont.var+cont.var:disc.var  ,data=dat,contrasts.arg =
               list(disc.var="contr.sum",cont.var="contr.treatment"))

If you dont want to have the "cont.var0:disc.var1" column in this matrix,
then all you need is a numeric (nonfactor) "dummy variable" in the data
frame:

dat$dummy<-0
dat$dummy[dat$cont.var==1]<-1

which you then can multiply with the interaction in the actual model
formula: e.g.
glmr(y~ cont.var+cont.var:disc.var*dummy ...)
As dummy is continuous it will always set the interaction term to 0 if
cont=0; this means if cont=0 there will only be an intercept estimate which
then is the effective mean of both a & b together (if cont=0). Not sure you
want this...

Hope this helps.

Best, Ren?

Am Do., 15. Juli 2021 um 20:44 Uhr schrieb Mark Sorel <marks6 at uw.edu>:

> Not specifically a glmmTMB question, but maybe someone here can help.
> I'd like to use a contrast sum constraint with an interaction between a
> continuous and discrete variable, but I can't seem to get model.matrix to
> do what I want.
>
> The situation is that I want a categorical variable that is coded with a
> sum constraint but only included in some rows of the model matrix (which is
> why I am using the interaction with the continuous 0/1 valued variable).
> Maybe there is a better way to code this.
>
> Here is an example of what I mean:
>
> dat<-data.frame(y=1,cont.var=rep(0:1,each=2),disc.var=rep(c("a","b"),2));
> model.matrix(y~ cont.var  : disc.var  ,data=dat,contrasts.arg =
> list(disc.var="contr.sum"))
>
> What I'd like in this example is a model matrix with two columns, where the
> second column has 0 when cont.var =0, 1 when cont.var=1 & disc.var = a, and
> -1 when cont.var=1 and disc.var=b.
>
>
>
> Thanks so much for your help! -Mark
>
> --
> Mark Sorel
> Doctoral Student
> Washington Cooperative Fish and Wildlife Research Unit
> School of Aquatic and Fishery Sciences
> University of Washington
> Cell: 607-351-7352
> He/ him/ his
>
>
> *The University of Washington acknowledges the Coast Salish peoples of this
> land, the land which touches the shared waters of all tribes and bands
> within the Suquamish, Tulalip and Muckleshoot nations*.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Mon Jul 19 08:58:24 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Mon, 19 Jul 2021 08:58:24 +0200
Subject: [R-sig-ME] Is crossed random-effect the only choice?
In-Reply-To: <CA+sL+8U7hs3BoFt9m=0ymqfTzqxCK5bWCgCTB6oB80JjP=xBNQ@mail.gmail.com>
References: <CA+sL+8VM5R5pxhY12E8VerpmyoOquTxEAKQcg=YQqeiqu0meaQ@mail.gmail.com>
 <ccb81c51-ec18-21f3-a9b1-7d354e5e6187@gmail.com>
 <CA+sL+8WoDgEKfttJrOs-1hxO6hg34pGKtz+XJ2Fn2zp=ngf=8A@mail.gmail.com>
 <CA+sL+8UcQJmOXv+uXiXSK2R3GWFrYX4-mzS-fiU8FWugvzifvQ@mail.gmail.com>
 <6b3b224f-71da-fb99-fe34-d3ff8f90facc@gmail.com>
 <CA+sL+8U7hs3BoFt9m=0ymqfTzqxCK5bWCgCTB6oB80JjP=xBNQ@mail.gmail.com>
Message-ID: <CAJuCY5yC-HPkHTqJPEC8a-UB2N=nvLKLvJa1mmU6w113z3rLVA@mail.gmail.com>

Dear Jack,

In your example H is implicitly nested in X. See
https://www.muscardinus.be/2017/07/lme4-random-effects/ for
more information on nested vs crossed effects.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op vr 16 jul. 2021 om 01:09 schreef Jack Solomon <kj.jsolomon at gmail.com>:

> Dear Ben,
>
> Just to make sure, the structure of my data is below. With this data
> structure, I wonder why ~ (1|H) + (1|X) would indicate that H and X are
> crossed random-effects?
>
> Because theoretically every value of X is capable of meeting every value of
> H (Or because each value of X means the same thing across any given value
> of H)?
>
> Does this also mean each unique cluster (separately for H & X) is
> considered correlated with another cluster?
>
> Thank you, Jack
>
> H  X
> 1   2
> 1   2
> 2   1
> 2   1
> 2   1
> 3   2
> 4   1
>
> On Thu, Jul 15, 2021 at 8:46 AM Ben Bolker <bbolker at gmail.com> wrote:
>
> >
> >
> > On 7/15/21 9:44 AM, Jack Solomon wrote:
> > > Dear Ben,
> > >
> > > In the case of #3 in your response, if the researcher intends to
> > > generalize beyond the 3 levels of the categorical factor/ predictor X,
> > > then can s/he use: ~ (1|H) + (1|X)?
> > >
> > > If yes, then H and X will be crossed?
> > >
> > > Thanks,
> > > Jack
> >
> >    Yes, and yes.
> > >
> > >
> > > On Sat, Jul 10, 2021, 10:36 PM Jack Solomon <kj.jsolomon at gmail.com
> > > <mailto:kj.jsolomon at gmail.com>> wrote:
> > >
> > >     Dear Ben,
> > >
> > >     Thank you for your informative response. I think # 4 is what
> matches
> > >     my situation.
> > >
> > >     Thanks again, Jack
> > >
> > >     On Sat, Jul 10, 2021 at 8:30 PM Ben Bolker <bbolker at gmail.com
> > >     <mailto:bbolker at gmail.com>> wrote:
> > >
> > >             The "crossed vs random" terminology is only relevant in
> > >         models with
> > >         more than one grouping variable.  I would call (1|X) " a random
> > >         effect
> > >         of X" or more precisely "a random-intercept model with grouping
> > >         variable X"
> > >
> > >             However, your question is a little unclear to me.  Is X a
> > >         grouping
> > >         variable or a predictor variable (numeric or categorical) that
> > >         varies
> > >         across groups?
> > >
> > >             I can think of four possibilities.
> > >
> > >            1. X is the grouping variable (e.g. "hospital"). Then ~
> (1|X)
> > >         is a
> > >         model that describes variation in the model intercept /
> baseline
> > >         value,
> > >         across hospitals.
> > >
> > >            2. X is a continuous covariate (e.g. annual hospital
> > >         budget).  Then if
> > >         H is the factor designating hospitals, we want  ~ X + (1|H)
> > >         (plus any
> > >         other fixed effects of interest. (It doesn't make sense / isn't
> > >         identifiable to fit a random-slopes model ~ (H | X) because
> > budgets
> > >         don't vary within hospitals.
> > >
> > >         3. X is a categorical / factor predictor (e.g. hospital size
> > class
> > >         {small, medium, large} with multiple hospitals measured in each
> > >         size
> > >         class:  ~ X + (1|H) (the same as #2).
> > >
> > >         4. X is a categorical predictor with unique values for each
> > >         hospital
> > >         (e.g. postal code).  Then X is redundant with H, you shouldn't
> > >         try to
> > >         include them both in the same model.
> > >
> > >         On 7/10/21 4:55 PM, Jack Solomon wrote:
> > >          > Hello Allo,
> > >          >
> > >          > In my two-level data structure, I have a cluster-level
> > >         variable (called
> > >          > "X"; one that doesn't vary in any cluster). If I intend to
> > >         generalize
> > >          > beyond X's current possible levels, then, I should take X as
> > >         a random
> > >          > effect.
> > >          >
> > >          > However, because "X" doesn't vary in any cluster, therefore,
> > >         such a random
> > >          > effect necessarily must be a crossed random effect (e.g., "~
> > >         1 | X"),
> > >          > correct?
> > >          >
> > >          > If yes, then what is "X" crossed with?
> > >          >
> > >          > Thank you,
> > >          > Jack
> > >          >
> > >          >       [[alternative HTML version deleted]]
> > >          >
> > >          > _______________________________________________
> > >          > R-sig-mixed-models at r-project.org
> > >         <mailto:R-sig-mixed-models at r-project.org> mailing list
> > >          > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >         <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> > >          >
> > >
> > >         --
> > >         Dr. Benjamin Bolker
> > >         Professor, Mathematics & Statistics and Biology, McMaster
> > University
> > >         Director, School of Computational Science and Engineering
> > >         Graduate chair, Mathematics & Statistics
> > >
> > >         _______________________________________________
> > >         R-sig-mixed-models at r-project.org
> > >         <mailto:R-sig-mixed-models at r-project.org> mailing list
> > >         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >         <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> > >
> >
> > --
> > Dr. Benjamin Bolker
> > Professor, Mathematics & Statistics and Biology, McMaster University
> > Director, School of Computational Science and Engineering
> > Graduate chair, Mathematics & Statistics
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From kj@j@o|omon @end|ng |rom gm@||@com  Mon Jul 19 16:31:59 2021
From: kj@j@o|omon @end|ng |rom gm@||@com (Jack Solomon)
Date: Mon, 19 Jul 2021 09:31:59 -0500
Subject: [R-sig-ME] Is crossed random-effect the only choice?
In-Reply-To: <CAJuCY5yC-HPkHTqJPEC8a-UB2N=nvLKLvJa1mmU6w113z3rLVA@mail.gmail.com>
References: <CA+sL+8VM5R5pxhY12E8VerpmyoOquTxEAKQcg=YQqeiqu0meaQ@mail.gmail.com>
 <ccb81c51-ec18-21f3-a9b1-7d354e5e6187@gmail.com>
 <CA+sL+8WoDgEKfttJrOs-1hxO6hg34pGKtz+XJ2Fn2zp=ngf=8A@mail.gmail.com>
 <CA+sL+8UcQJmOXv+uXiXSK2R3GWFrYX4-mzS-fiU8FWugvzifvQ@mail.gmail.com>
 <6b3b224f-71da-fb99-fe34-d3ff8f90facc@gmail.com>
 <CA+sL+8U7hs3BoFt9m=0ymqfTzqxCK5bWCgCTB6oB80JjP=xBNQ@mail.gmail.com>
 <CAJuCY5yC-HPkHTqJPEC8a-UB2N=nvLKLvJa1mmU6w113z3rLVA@mail.gmail.com>
Message-ID: <CA+sL+8WU9YrZOfPhH50DR=_Zaj0-TfOoFp4j1Ai_4b6huesAmQ@mail.gmail.com>

Dear Thierry,

Thank you for your interesting comment (H being nested in X). I read your
informative webpage as well which was in large part in line with this
comment: (https://stats.stackexchange.com/a/228814/140365).

I think a little context can help. Think of H as a group of studies (each
with one or more rows). And think of X as scientific formulas each of which
a study has used (for all its rows) to measure the same construct.

Given this context and the data below, do you think there is a "nesting" or
a "crossing" (full or partial) relationship between studies (H) and the
formulas (X) they used, why?

Thanks, Jack
H  X
1   2
1   2
2   1
2   1
2   1
3   2
4   1

On Mon, Jul 19, 2021 at 1:58 AM Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Jack,
>
> In your example H is implicitly nested in X. See
> https://www.muscardinus.be/2017/07/lme4-random-effects/ for
> more information on nested vs crossed effects.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op vr 16 jul. 2021 om 01:09 schreef Jack Solomon <kj.jsolomon at gmail.com>:
>
>> Dear Ben,
>>
>> Just to make sure, the structure of my data is below. With this data
>> structure, I wonder why ~ (1|H) + (1|X) would indicate that H and X are
>> crossed random-effects?
>>
>> Because theoretically every value of X is capable of meeting every value
>> of
>> H (Or because each value of X means the same thing across any given value
>> of H)?
>>
>> Does this also mean each unique cluster (separately for H & X) is
>> considered correlated with another cluster?
>>
>> Thank you, Jack
>>
>> H  X
>> 1   2
>> 1   2
>> 2   1
>> 2   1
>> 2   1
>> 3   2
>> 4   1
>>
>> On Thu, Jul 15, 2021 at 8:46 AM Ben Bolker <bbolker at gmail.com> wrote:
>>
>> >
>> >
>> > On 7/15/21 9:44 AM, Jack Solomon wrote:
>> > > Dear Ben,
>> > >
>> > > In the case of #3 in your response, if the researcher intends to
>> > > generalize beyond the 3 levels of the categorical factor/ predictor X,
>> > > then can s/he use: ~ (1|H) + (1|X)?
>> > >
>> > > If yes, then H and X will be crossed?
>> > >
>> > > Thanks,
>> > > Jack
>> >
>> >    Yes, and yes.
>> > >
>> > >
>> > > On Sat, Jul 10, 2021, 10:36 PM Jack Solomon <kj.jsolomon at gmail.com
>> > > <mailto:kj.jsolomon at gmail.com>> wrote:
>> > >
>> > >     Dear Ben,
>> > >
>> > >     Thank you for your informative response. I think # 4 is what
>> matches
>> > >     my situation.
>> > >
>> > >     Thanks again, Jack
>> > >
>> > >     On Sat, Jul 10, 2021 at 8:30 PM Ben Bolker <bbolker at gmail.com
>> > >     <mailto:bbolker at gmail.com>> wrote:
>> > >
>> > >             The "crossed vs random" terminology is only relevant in
>> > >         models with
>> > >         more than one grouping variable.  I would call (1|X) " a
>> random
>> > >         effect
>> > >         of X" or more precisely "a random-intercept model with
>> grouping
>> > >         variable X"
>> > >
>> > >             However, your question is a little unclear to me.  Is X a
>> > >         grouping
>> > >         variable or a predictor variable (numeric or categorical) that
>> > >         varies
>> > >         across groups?
>> > >
>> > >             I can think of four possibilities.
>> > >
>> > >            1. X is the grouping variable (e.g. "hospital"). Then ~
>> (1|X)
>> > >         is a
>> > >         model that describes variation in the model intercept /
>> baseline
>> > >         value,
>> > >         across hospitals.
>> > >
>> > >            2. X is a continuous covariate (e.g. annual hospital
>> > >         budget).  Then if
>> > >         H is the factor designating hospitals, we want  ~ X + (1|H)
>> > >         (plus any
>> > >         other fixed effects of interest. (It doesn't make sense /
>> isn't
>> > >         identifiable to fit a random-slopes model ~ (H | X) because
>> > budgets
>> > >         don't vary within hospitals.
>> > >
>> > >         3. X is a categorical / factor predictor (e.g. hospital size
>> > class
>> > >         {small, medium, large} with multiple hospitals measured in
>> each
>> > >         size
>> > >         class:  ~ X + (1|H) (the same as #2).
>> > >
>> > >         4. X is a categorical predictor with unique values for each
>> > >         hospital
>> > >         (e.g. postal code).  Then X is redundant with H, you shouldn't
>> > >         try to
>> > >         include them both in the same model.
>> > >
>> > >         On 7/10/21 4:55 PM, Jack Solomon wrote:
>> > >          > Hello Allo,
>> > >          >
>> > >          > In my two-level data structure, I have a cluster-level
>> > >         variable (called
>> > >          > "X"; one that doesn't vary in any cluster). If I intend to
>> > >         generalize
>> > >          > beyond X's current possible levels, then, I should take X
>> as
>> > >         a random
>> > >          > effect.
>> > >          >
>> > >          > However, because "X" doesn't vary in any cluster,
>> therefore,
>> > >         such a random
>> > >          > effect necessarily must be a crossed random effect (e.g.,
>> "~
>> > >         1 | X"),
>> > >          > correct?
>> > >          >
>> > >          > If yes, then what is "X" crossed with?
>> > >          >
>> > >          > Thank you,
>> > >          > Jack
>> > >          >
>> > >          >       [[alternative HTML version deleted]]
>> > >          >
>> > >          > _______________________________________________
>> > >          > R-sig-mixed-models at r-project.org
>> > >         <mailto:R-sig-mixed-models at r-project.org> mailing list
>> > >          > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> > >         <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>> > >          >
>> > >
>> > >         --
>> > >         Dr. Benjamin Bolker
>> > >         Professor, Mathematics & Statistics and Biology, McMaster
>> > University
>> > >         Director, School of Computational Science and Engineering
>> > >         Graduate chair, Mathematics & Statistics
>> > >
>> > >         _______________________________________________
>> > >         R-sig-mixed-models at r-project.org
>> > >         <mailto:R-sig-mixed-models at r-project.org> mailing list
>> > >         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> > >         <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>> > >
>> >
>> > --
>> > Dr. Benjamin Bolker
>> > Professor, Mathematics & Statistics and Biology, McMaster University
>> > Director, School of Computational Science and Engineering
>> > Graduate chair, Mathematics & Statistics
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

	[[alternative HTML version deleted]]


From bhud@on@g@u @end|ng |rom gm@||@com  Mon Jul 19 17:42:39 2021
From: bhud@on@g@u @end|ng |rom gm@||@com (Brian Hudson)
Date: Mon, 19 Jul 2021 11:42:39 -0400
Subject: [R-sig-ME] Multilevel equation
Message-ID: <CANodPHN1CH1CQAQ0qJ1HmWVoPBN+37arA2wdYNTgxFW9TUogOQ@mail.gmail.com>

Hello,

I am fitting a multilevel model in `lme4` and am having trouble writing the
equation for it. I very much appreciate any help. The formula and code is
below, but I am not sure if the equation represents the error correctly -
do I need to include error terms or is that captured by the distributions?
I am also not sure if I am representing the logit function correctly with
the indexing or functional form.

The data are comprised of US-state months nested within US-state-years and
US-states. I include predictors at each level and a varying intercept for
both state-years and states.

The formula looks like this in R:

```
as.formula(outcome ~ state_mnthyr_pred + state_year_pred + state_pred +
                         (1 | state) + (1 | state_year))
```
Where the outcome is dichotomous. The state months (e.g. jan-2010, feb-2010
... jan-2013) are nested with state years and within states.

The formula I am using can be seen here:

https://quicklatex.com/cache3/e9/ql_038eeb4e4e1b0af94d3ef69fe4ff7be9_l3.png
And the LaTeX code:

$$
\begin{aligned}
    \mu &=\alpha_{j[i],k[i]} +
\beta_{0}(\operatorname{state\_mnthyr\_pred})\ \\
    \alpha_{j}  &\sim N \left(\gamma_{0}^{\alpha} +
\gamma_{1}^{\alpha}(\operatorname{\textrm{state\_year\_pred}}),
\sigma^2_{\alpha_{j}} \right)
    \text{, for \textrm{State-Year} j = 1,} \dots \text{, J} \\
    \alpha_{k}  &\sim N \left(\gamma_{0}^{\alpha} +
\gamma_{1}^{\alpha}(\operatorname{\textrm{state\_pred}}),
\sigma^2_{\alpha_{k}} \right)
    \text{, for State k = 1,} \dots \text{, K}\\
\pi_{i} &=\frac{e_{i}^{\mu}}{1+e_{i}^{\mu}}\\
y_{i j k} \sim & \operatorname{Binom}\left(1, \pi_{i}\right)\\
\end{aligned}
$$

I really appreciate any help. Thank you.

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Mon Jul 19 19:19:18 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Mon, 19 Jul 2021 19:19:18 +0200
Subject: [R-sig-ME] Is crossed random-effect the only choice?
In-Reply-To: <CA+sL+8WU9YrZOfPhH50DR=_Zaj0-TfOoFp4j1Ai_4b6huesAmQ@mail.gmail.com>
References: <CA+sL+8VM5R5pxhY12E8VerpmyoOquTxEAKQcg=YQqeiqu0meaQ@mail.gmail.com>
 <ccb81c51-ec18-21f3-a9b1-7d354e5e6187@gmail.com>
 <CA+sL+8WoDgEKfttJrOs-1hxO6hg34pGKtz+XJ2Fn2zp=ngf=8A@mail.gmail.com>
 <CA+sL+8UcQJmOXv+uXiXSK2R3GWFrYX4-mzS-fiU8FWugvzifvQ@mail.gmail.com>
 <6b3b224f-71da-fb99-fe34-d3ff8f90facc@gmail.com>
 <CA+sL+8U7hs3BoFt9m=0ymqfTzqxCK5bWCgCTB6oB80JjP=xBNQ@mail.gmail.com>
 <CAJuCY5yC-HPkHTqJPEC8a-UB2N=nvLKLvJa1mmU6w113z3rLVA@mail.gmail.com>
 <CA+sL+8WU9YrZOfPhH50DR=_Zaj0-TfOoFp4j1Ai_4b6huesAmQ@mail.gmail.com>
Message-ID: <CAJuCY5xt6R68ZTpDbTq5T+CkTTRXn0uSQitKfp0+gw4kH5h5gQ@mail.gmail.com>

Dear Jack,

IMHO the discussion whether it is nested, partially nested, or crossed is
pointless. Use explicit nesting by creating random effects with unique
levels across the data. That is each level defines a unique state for that
variable, regardless any other variables. So if you consider the formula of
one study is the same as the formula of another study, then they get the
same level, otherwise they get a different level.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 19 jul. 2021 om 16:32 schreef Jack Solomon <kj.jsolomon at gmail.com>:

> Dear Thierry,
>
> Thank you for your interesting comment (H being nested in X). I read your
> informative webpage as well which was in large part in line with this
> comment: (https://stats.stackexchange.com/a/228814/140365).
>
> I think a little context can help. Think of H as a group of studies (each
> with one or more rows). And think of X as scientific formulas each of which
> a study has used (for all its rows) to measure the same construct.
>
> Given this context and the data below, do you think there is a "nesting"
> or a "crossing" (full or partial) relationship between studies (H) and the
> formulas (X) they used, why?
>
> Thanks, Jack
> H  X
> 1   2
> 1   2
> 2   1
> 2   1
> 2   1
> 3   2
> 4   1
>
> On Mon, Jul 19, 2021 at 1:58 AM Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>
>> Dear Jack,
>>
>> In your example H is implicitly nested in X. See
>> https://www.muscardinus.be/2017/07/lme4-random-effects/ for
>> more information on nested vs crossed effects.
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>> AND FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88 bus 73, 1000 Brussel
>> www.inbo.be
>>
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>
>> <https://www.inbo.be>
>>
>>
>> Op vr 16 jul. 2021 om 01:09 schreef Jack Solomon <kj.jsolomon at gmail.com>:
>>
>>> Dear Ben,
>>>
>>> Just to make sure, the structure of my data is below. With this data
>>> structure, I wonder why ~ (1|H) + (1|X) would indicate that H and X are
>>> crossed random-effects?
>>>
>>> Because theoretically every value of X is capable of meeting every value
>>> of
>>> H (Or because each value of X means the same thing across any given value
>>> of H)?
>>>
>>> Does this also mean each unique cluster (separately for H & X) is
>>> considered correlated with another cluster?
>>>
>>> Thank you, Jack
>>>
>>> H  X
>>> 1   2
>>> 1   2
>>> 2   1
>>> 2   1
>>> 2   1
>>> 3   2
>>> 4   1
>>>
>>> On Thu, Jul 15, 2021 at 8:46 AM Ben Bolker <bbolker at gmail.com> wrote:
>>>
>>> >
>>> >
>>> > On 7/15/21 9:44 AM, Jack Solomon wrote:
>>> > > Dear Ben,
>>> > >
>>> > > In the case of #3 in your response, if the researcher intends to
>>> > > generalize beyond the 3 levels of the categorical factor/ predictor
>>> X,
>>> > > then can s/he use: ~ (1|H) + (1|X)?
>>> > >
>>> > > If yes, then H and X will be crossed?
>>> > >
>>> > > Thanks,
>>> > > Jack
>>> >
>>> >    Yes, and yes.
>>> > >
>>> > >
>>> > > On Sat, Jul 10, 2021, 10:36 PM Jack Solomon <kj.jsolomon at gmail.com
>>> > > <mailto:kj.jsolomon at gmail.com>> wrote:
>>> > >
>>> > >     Dear Ben,
>>> > >
>>> > >     Thank you for your informative response. I think # 4 is what
>>> matches
>>> > >     my situation.
>>> > >
>>> > >     Thanks again, Jack
>>> > >
>>> > >     On Sat, Jul 10, 2021 at 8:30 PM Ben Bolker <bbolker at gmail.com
>>> > >     <mailto:bbolker at gmail.com>> wrote:
>>> > >
>>> > >             The "crossed vs random" terminology is only relevant in
>>> > >         models with
>>> > >         more than one grouping variable.  I would call (1|X) " a
>>> random
>>> > >         effect
>>> > >         of X" or more precisely "a random-intercept model with
>>> grouping
>>> > >         variable X"
>>> > >
>>> > >             However, your question is a little unclear to me.  Is X a
>>> > >         grouping
>>> > >         variable or a predictor variable (numeric or categorical)
>>> that
>>> > >         varies
>>> > >         across groups?
>>> > >
>>> > >             I can think of four possibilities.
>>> > >
>>> > >            1. X is the grouping variable (e.g. "hospital"). Then ~
>>> (1|X)
>>> > >         is a
>>> > >         model that describes variation in the model intercept /
>>> baseline
>>> > >         value,
>>> > >         across hospitals.
>>> > >
>>> > >            2. X is a continuous covariate (e.g. annual hospital
>>> > >         budget).  Then if
>>> > >         H is the factor designating hospitals, we want  ~ X + (1|H)
>>> > >         (plus any
>>> > >         other fixed effects of interest. (It doesn't make sense /
>>> isn't
>>> > >         identifiable to fit a random-slopes model ~ (H | X) because
>>> > budgets
>>> > >         don't vary within hospitals.
>>> > >
>>> > >         3. X is a categorical / factor predictor (e.g. hospital size
>>> > class
>>> > >         {small, medium, large} with multiple hospitals measured in
>>> each
>>> > >         size
>>> > >         class:  ~ X + (1|H) (the same as #2).
>>> > >
>>> > >         4. X is a categorical predictor with unique values for each
>>> > >         hospital
>>> > >         (e.g. postal code).  Then X is redundant with H, you
>>> shouldn't
>>> > >         try to
>>> > >         include them both in the same model.
>>> > >
>>> > >         On 7/10/21 4:55 PM, Jack Solomon wrote:
>>> > >          > Hello Allo,
>>> > >          >
>>> > >          > In my two-level data structure, I have a cluster-level
>>> > >         variable (called
>>> > >          > "X"; one that doesn't vary in any cluster). If I intend to
>>> > >         generalize
>>> > >          > beyond X's current possible levels, then, I should take X
>>> as
>>> > >         a random
>>> > >          > effect.
>>> > >          >
>>> > >          > However, because "X" doesn't vary in any cluster,
>>> therefore,
>>> > >         such a random
>>> > >          > effect necessarily must be a crossed random effect (e.g.,
>>> "~
>>> > >         1 | X"),
>>> > >          > correct?
>>> > >          >
>>> > >          > If yes, then what is "X" crossed with?
>>> > >          >
>>> > >          > Thank you,
>>> > >          > Jack
>>> > >          >
>>> > >          >       [[alternative HTML version deleted]]
>>> > >          >
>>> > >          > _______________________________________________
>>> > >          > R-sig-mixed-models at r-project.org
>>> > >         <mailto:R-sig-mixed-models at r-project.org> mailing list
>>> > >          > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> > >         <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>> > >          >
>>> > >
>>> > >         --
>>> > >         Dr. Benjamin Bolker
>>> > >         Professor, Mathematics & Statistics and Biology, McMaster
>>> > University
>>> > >         Director, School of Computational Science and Engineering
>>> > >         Graduate chair, Mathematics & Statistics
>>> > >
>>> > >         _______________________________________________
>>> > >         R-sig-mixed-models at r-project.org
>>> > >         <mailto:R-sig-mixed-models at r-project.org> mailing list
>>> > >         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> > >         <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>> > >
>>> >
>>> > --
>>> > Dr. Benjamin Bolker
>>> > Professor, Mathematics & Statistics and Biology, McMaster University
>>> > Director, School of Computational Science and Engineering
>>> > Graduate chair, Mathematics & Statistics
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>

	[[alternative HTML version deleted]]


From kj@j@o|omon @end|ng |rom gm@||@com  Mon Jul 19 19:29:04 2021
From: kj@j@o|omon @end|ng |rom gm@||@com (Jack Solomon)
Date: Mon, 19 Jul 2021 12:29:04 -0500
Subject: [R-sig-ME] Is crossed random-effect the only choice?
In-Reply-To: <CAJuCY5xt6R68ZTpDbTq5T+CkTTRXn0uSQitKfp0+gw4kH5h5gQ@mail.gmail.com>
References: <CA+sL+8VM5R5pxhY12E8VerpmyoOquTxEAKQcg=YQqeiqu0meaQ@mail.gmail.com>
 <ccb81c51-ec18-21f3-a9b1-7d354e5e6187@gmail.com>
 <CA+sL+8WoDgEKfttJrOs-1hxO6hg34pGKtz+XJ2Fn2zp=ngf=8A@mail.gmail.com>
 <CA+sL+8UcQJmOXv+uXiXSK2R3GWFrYX4-mzS-fiU8FWugvzifvQ@mail.gmail.com>
 <6b3b224f-71da-fb99-fe34-d3ff8f90facc@gmail.com>
 <CA+sL+8U7hs3BoFt9m=0ymqfTzqxCK5bWCgCTB6oB80JjP=xBNQ@mail.gmail.com>
 <CAJuCY5yC-HPkHTqJPEC8a-UB2N=nvLKLvJa1mmU6w113z3rLVA@mail.gmail.com>
 <CA+sL+8WU9YrZOfPhH50DR=_Zaj0-TfOoFp4j1Ai_4b6huesAmQ@mail.gmail.com>
 <CAJuCY5xt6R68ZTpDbTq5T+CkTTRXn0uSQitKfp0+gw4kH5h5gQ@mail.gmail.com>
Message-ID: <CA+sL+8WqFEdb80Davr5K+Msja-D5_zW9ixLT1+-p=HdA0W98kQ@mail.gmail.com>

Dear Thierry,

Thanks. Given the data structure, your previous comment (i.e., H being
implicitly nested in X) as well as your webpage, you mean (1|X/H)?

H  X
1   2
1   2
2   1
2   1
2   1
3   2
4   1

On Mon, Jul 19, 2021 at 12:19 PM Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Jack,
>
> IMHO the discussion whether it is nested, partially nested, or crossed is
> pointless. Use explicit nesting by creating random effects with unique
> levels across the data. That is each level defines a unique state for that
> variable, regardless any other variables. So if you consider the formula of
> one study is the same as the formula of another study, then they get the
> same level, otherwise they get a different level.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op ma 19 jul. 2021 om 16:32 schreef Jack Solomon <kj.jsolomon at gmail.com>:
>
>> Dear Thierry,
>>
>> Thank you for your interesting comment (H being nested in X). I read your
>> informative webpage as well which was in large part in line with this
>> comment: (https://stats.stackexchange.com/a/228814/140365).
>>
>> I think a little context can help. Think of H as a group of studies (each
>> with one or more rows). And think of X as scientific formulas each of which
>> a study has used (for all its rows) to measure the same construct.
>>
>> Given this context and the data below, do you think there is a "nesting"
>> or a "crossing" (full or partial) relationship between studies (H) and the
>> formulas (X) they used, why?
>>
>> Thanks, Jack
>> H  X
>> 1   2
>> 1   2
>> 2   1
>> 2   1
>> 2   1
>> 3   2
>> 4   1
>>
>> On Mon, Jul 19, 2021 at 1:58 AM Thierry Onkelinx <
>> thierry.onkelinx at inbo.be> wrote:
>>
>>> Dear Jack,
>>>
>>> In your example H is implicitly nested in X. See
>>> https://www.muscardinus.be/2017/07/lme4-random-effects/ for
>>> more information on nested vs crossed effects.
>>>
>>> Best regards,
>>>
>>> ir. Thierry Onkelinx
>>> Statisticus / Statistician
>>>
>>> Vlaamse Overheid / Government of Flanders
>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>>> AND FOREST
>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>> thierry.onkelinx at inbo.be
>>> Havenlaan 88 bus 73, 1000 Brussel
>>> www.inbo.be
>>>
>>>
>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of data.
>>> ~ John Tukey
>>>
>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>
>>> <https://www.inbo.be>
>>>
>>>
>>> Op vr 16 jul. 2021 om 01:09 schreef Jack Solomon <kj.jsolomon at gmail.com
>>> >:
>>>
>>>> Dear Ben,
>>>>
>>>> Just to make sure, the structure of my data is below. With this data
>>>> structure, I wonder why ~ (1|H) + (1|X) would indicate that H and X are
>>>> crossed random-effects?
>>>>
>>>> Because theoretically every value of X is capable of meeting every
>>>> value of
>>>> H (Or because each value of X means the same thing across any given
>>>> value
>>>> of H)?
>>>>
>>>> Does this also mean each unique cluster (separately for H & X) is
>>>> considered correlated with another cluster?
>>>>
>>>> Thank you, Jack
>>>>
>>>> H  X
>>>> 1   2
>>>> 1   2
>>>> 2   1
>>>> 2   1
>>>> 2   1
>>>> 3   2
>>>> 4   1
>>>>
>>>> On Thu, Jul 15, 2021 at 8:46 AM Ben Bolker <bbolker at gmail.com> wrote:
>>>>
>>>> >
>>>> >
>>>> > On 7/15/21 9:44 AM, Jack Solomon wrote:
>>>> > > Dear Ben,
>>>> > >
>>>> > > In the case of #3 in your response, if the researcher intends to
>>>> > > generalize beyond the 3 levels of the categorical factor/ predictor
>>>> X,
>>>> > > then can s/he use: ~ (1|H) + (1|X)?
>>>> > >
>>>> > > If yes, then H and X will be crossed?
>>>> > >
>>>> > > Thanks,
>>>> > > Jack
>>>> >
>>>> >    Yes, and yes.
>>>> > >
>>>> > >
>>>> > > On Sat, Jul 10, 2021, 10:36 PM Jack Solomon <kj.jsolomon at gmail.com
>>>> > > <mailto:kj.jsolomon at gmail.com>> wrote:
>>>> > >
>>>> > >     Dear Ben,
>>>> > >
>>>> > >     Thank you for your informative response. I think # 4 is what
>>>> matches
>>>> > >     my situation.
>>>> > >
>>>> > >     Thanks again, Jack
>>>> > >
>>>> > >     On Sat, Jul 10, 2021 at 8:30 PM Ben Bolker <bbolker at gmail.com
>>>> > >     <mailto:bbolker at gmail.com>> wrote:
>>>> > >
>>>> > >             The "crossed vs random" terminology is only relevant in
>>>> > >         models with
>>>> > >         more than one grouping variable.  I would call (1|X) " a
>>>> random
>>>> > >         effect
>>>> > >         of X" or more precisely "a random-intercept model with
>>>> grouping
>>>> > >         variable X"
>>>> > >
>>>> > >             However, your question is a little unclear to me.  Is X
>>>> a
>>>> > >         grouping
>>>> > >         variable or a predictor variable (numeric or categorical)
>>>> that
>>>> > >         varies
>>>> > >         across groups?
>>>> > >
>>>> > >             I can think of four possibilities.
>>>> > >
>>>> > >            1. X is the grouping variable (e.g. "hospital"). Then ~
>>>> (1|X)
>>>> > >         is a
>>>> > >         model that describes variation in the model intercept /
>>>> baseline
>>>> > >         value,
>>>> > >         across hospitals.
>>>> > >
>>>> > >            2. X is a continuous covariate (e.g. annual hospital
>>>> > >         budget).  Then if
>>>> > >         H is the factor designating hospitals, we want  ~ X + (1|H)
>>>> > >         (plus any
>>>> > >         other fixed effects of interest. (It doesn't make sense /
>>>> isn't
>>>> > >         identifiable to fit a random-slopes model ~ (H | X) because
>>>> > budgets
>>>> > >         don't vary within hospitals.
>>>> > >
>>>> > >         3. X is a categorical / factor predictor (e.g. hospital size
>>>> > class
>>>> > >         {small, medium, large} with multiple hospitals measured in
>>>> each
>>>> > >         size
>>>> > >         class:  ~ X + (1|H) (the same as #2).
>>>> > >
>>>> > >         4. X is a categorical predictor with unique values for each
>>>> > >         hospital
>>>> > >         (e.g. postal code).  Then X is redundant with H, you
>>>> shouldn't
>>>> > >         try to
>>>> > >         include them both in the same model.
>>>> > >
>>>> > >         On 7/10/21 4:55 PM, Jack Solomon wrote:
>>>> > >          > Hello Allo,
>>>> > >          >
>>>> > >          > In my two-level data structure, I have a cluster-level
>>>> > >         variable (called
>>>> > >          > "X"; one that doesn't vary in any cluster). If I intend
>>>> to
>>>> > >         generalize
>>>> > >          > beyond X's current possible levels, then, I should take
>>>> X as
>>>> > >         a random
>>>> > >          > effect.
>>>> > >          >
>>>> > >          > However, because "X" doesn't vary in any cluster,
>>>> therefore,
>>>> > >         such a random
>>>> > >          > effect necessarily must be a crossed random effect
>>>> (e.g., "~
>>>> > >         1 | X"),
>>>> > >          > correct?
>>>> > >          >
>>>> > >          > If yes, then what is "X" crossed with?
>>>> > >          >
>>>> > >          > Thank you,
>>>> > >          > Jack
>>>> > >          >
>>>> > >          >       [[alternative HTML version deleted]]
>>>> > >          >
>>>> > >          > _______________________________________________
>>>> > >          > R-sig-mixed-models at r-project.org
>>>> > >         <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>> > >          > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> > >         <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>> > >          >
>>>> > >
>>>> > >         --
>>>> > >         Dr. Benjamin Bolker
>>>> > >         Professor, Mathematics & Statistics and Biology, McMaster
>>>> > University
>>>> > >         Director, School of Computational Science and Engineering
>>>> > >         Graduate chair, Mathematics & Statistics
>>>> > >
>>>> > >         _______________________________________________
>>>> > >         R-sig-mixed-models at r-project.org
>>>> > >         <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>> > >         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> > >         <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>> > >
>>>> >
>>>> > --
>>>> > Dr. Benjamin Bolker
>>>> > Professor, Mathematics & Statistics and Biology, McMaster University
>>>> > Director, School of Computational Science and Engineering
>>>> > Graduate chair, Mathematics & Statistics
>>>> >
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Mon Jul 19 19:34:03 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Mon, 19 Jul 2021 19:34:03 +0200
Subject: [R-sig-ME] Multilevel equation
In-Reply-To: <CANodPHN1CH1CQAQ0qJ1HmWVoPBN+37arA2wdYNTgxFW9TUogOQ@mail.gmail.com>
References: <CANodPHN1CH1CQAQ0qJ1HmWVoPBN+37arA2wdYNTgxFW9TUogOQ@mail.gmail.com>
Message-ID: <CAJuCY5xykircuekjAHQvyuAJBKWrNmGPTv5tH5R=qh8uP+y7JQ@mail.gmail.com>

Dear Brian,

I'd write it as follows. In the case of a Gaussian model, you only have to
write $Y_{ijk} \sim \mathcal{N}(\eta_{ijk}, \sigma^2)$ and drop the link
function. (And you could replace \eta with \mu). Basically, Y depends on a
distribution defined by some parameters. And these parameters might need
some further definition.

$i$: state index
$j$: year index
$k$: observation index
$X_m$: state_mnthyr_pred
$X_y$: state_year_pred
$X_s$: state_pred
$$Y_{ijk} \sim Binom(\pi_{ijk})$$
$$\eta_{ijk} = \frac{\pi_{ijk}}{1- \pi_{ijk}}$$
$$\eta_{ijk} = \beta_0 + \beta_1X_m + \beta_2 X_y + \beta_3 X_s + b_i +
b_{ij}$$
$$b_i\sim \mathcal{N}(0, \sigma_s^2)$$
$$b_{ij}\sim \mathcal{N}(0, \sigma_{y}^2)$$

Best regards,


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 19 jul. 2021 om 17:44 schreef Brian Hudson <bhudson.gsu at gmail.com>:

> Hello,
>
> I am fitting a multilevel model in `lme4` and am having trouble writing the
> equation for it. I very much appreciate any help. The formula and code is
> below, but I am not sure if the equation represents the error correctly -
> do I need to include error terms or is that captured by the distributions?
> I am also not sure if I am representing the logit function correctly with
> the indexing or functional form.
>
> The data are comprised of US-state months nested within US-state-years and
> US-states. I include predictors at each level and a varying intercept for
> both state-years and states.
>
> The formula looks like this in R:
>
> ```
> as.formula(outcome ~ state_mnthyr_pred + state_year_pred + state_pred +
>                          (1 | state) + (1 | state_year))
> ```
> Where the outcome is dichotomous. The state months (e.g. jan-2010, feb-2010
> ... jan-2013) are nested with state years and within states.
>
> The formula I am using can be seen here:
>
> https://quicklatex.com/cache3/e9/ql_038eeb4e4e1b0af94d3ef69fe4ff7be9_l3.png
> And the LaTeX code:
>
> $$
> \begin{aligned}
>     \mu &=\alpha_{j[i],k[i]} +
> \beta_{0}(\operatorname{state\_mnthyr\_pred})\ \\
>     \alpha_{j}  &\sim N \left(\gamma_{0}^{\alpha} +
> \gamma_{1}^{\alpha}(\operatorname{\textrm{state\_year\_pred}}),
> \sigma^2_{\alpha_{j}} \right)
>     \text{, for \textrm{State-Year} j = 1,} \dots \text{, J} \\
>     \alpha_{k}  &\sim N \left(\gamma_{0}^{\alpha} +
> \gamma_{1}^{\alpha}(\operatorname{\textrm{state\_pred}}),
> \sigma^2_{\alpha_{k}} \right)
>     \text{, for State k = 1,} \dots \text{, K}\\
> \pi_{i} &=\frac{e_{i}^{\mu}}{1+e_{i}^{\mu}}\\
> y_{i j k} \sim & \operatorname{Binom}\left(1, \pi_{i}\right)\\
> \end{aligned}
> $$
>
> I really appreciate any help. Thank you.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From @|et@360 @end|ng |rom gm@||@com  Fri Jul 23 01:45:28 2021
From: @|et@360 @end|ng |rom gm@||@com (=?UTF-8?Q?Estefania_Isabel_Mu=C3=B1oz_Salas?=)
Date: Thu, 22 Jul 2021 16:45:28 -0700
Subject: [R-sig-ME] Statistical consultation GLMM
Message-ID: <CA+XLY+dicSUoObeMhtEdfHjUZxvfDr0Q=EydeXQ0vQg+tfXxzw@mail.gmail.com>

Hi,

 My name is Estefan?a; I am doing a master's degree in Marine Ecology. As
part of the project, we are dealing with shorebird count data, which have
been taken along the coast of California and northwestern Mexico. The
surveys are conducted under a standardized monitoring protocol. Sampling
units have been established at each of the sites, polygons with different
sizes, which vary from site to site. The birds present in each unit have
been counted year after year from 2011 to 2019 one time in winter. In
addition to the above, the count data in this case, given the nature of the
birds to congregate, make that many units have zeros, and some units have
abundances of 1000 birds or more, making the data do not approximate to a
normal distribution. Therefore, to treat these data, we use Generalized
Linear Mixed Models (GLMM) to contemplate the variability in bird abundance
from site to site and from the sampling unit to the sampling unit.
The objective of my work is to know the population trend of three species
of shorebirds (analyzed separately), and if there is a relationship with
environmental variables such as average temperature, minimum, and maximum
temperature, and precipitation; and if there is a difference between
regions, in this case, were grouped sites in California, those of the Baja
California peninsula and another region of northwestern Mexico, that we
called Continental.
Initially, I tested which distribution family fit the data by testing a
Poisson, Poisson zero-inflated, and negative binomial and negative binomial
zero-inflated distribution, which are the most common for count data. The
distribution that obtained the lowest AIC was the negative binomial
zero-inflated.
Knowing that there could be a correlation between the predictor variables,
I calculated their correlations and for the time we defined that since the
correlation between the years and the environmental variables was low <.30,
a single model would be made, in which the year, we also decided that the
size of each of the sampling units (logarithm of the hectares) would be
included since it is different in each unit, and we want to take that into
account. The region would also be considered as a factor with 3 levels.
Still, the temperature variables did present high correlations, but are the
variables we are interested in so, this is where I have several doubts
because my formation is not statistical
1.-Should I not include environmental variables in a single model because
they are correlated,  although they are of interest?
2.-If what I am doing is right or not?
3.-How do I know if I have made a good fit of the data to the model? How do
I test it?
4.-How do I select the best model?
5.-What assumptions should I test?
7.- Am I missing something obvious?

All the above I have done with the glmmTMB package in Rstudio.
Thank you very much and sorry in advance if these are very basic questions.

The fit I try so far is this:
m2znb.all<-glmmTMB(total~ logha + YearCollected + Geopolitical + tmp + tmn
+ tmx + pre + (1|Site/Plot), ziformula = ~1, data = mc2, family="nbinom2")
where:
total is the abundance of a species of shorebird
logha the size of the unit (logarithmic of the hectare)
YearCollected
Geopolitical is the region
tmp is the mean temperature
tmn is the minimum temperature
tmx is the maximum temperature
pre is the precipitation

It would be possible to share the data

Regards, Estefan?a.

	[[alternative HTML version deleted]]


From bhud@on@g@u @end|ng |rom gm@||@com  Tue Jul 27 04:05:19 2021
From: bhud@on@g@u @end|ng |rom gm@||@com (Brian Hudson)
Date: Mon, 26 Jul 2021 22:05:19 -0400
Subject: [R-sig-ME] Multilevel equation
In-Reply-To: <CAJuCY5xykircuekjAHQvyuAJBKWrNmGPTv5tH5R=qh8uP+y7JQ@mail.gmail.com>
References: <CANodPHN1CH1CQAQ0qJ1HmWVoPBN+37arA2wdYNTgxFW9TUogOQ@mail.gmail.com>
 <CAJuCY5xykircuekjAHQvyuAJBKWrNmGPTv5tH5R=qh8uP+y7JQ@mail.gmail.com>
Message-ID: <CANodPHM1Rg4c-B7x_whDewOcy6mm_z09T83zTmxom=yRSZozSA@mail.gmail.com>

Thierry,

Thank you! I appreciate your help and explanation - that makes sense and I
can see where my other attempts were incorrect.

A couple questions-

1) The two lines that defined eta confused me - are they supposed to be
equal to each other? I edited the equation below such that pi has the link
function and eta has the linear equation - does that work?
2) I added epsilon for the individual error
3) There was no k index (individual level) in the equations, just i and j,
so i added some indexing in the predictors.

Does this equation make sense? Any issues with what I did? Thanks again for
your (and the community's) help.

https://quicklatex.com/cache3/9f/ql_4a4eb44285f65ea0dcaf93d551c44c9f_l3.png

$$b_i\sim \mathcal{N}(0, \sigma_s^2)$$
$$b_{ij}\sim \mathcal{N}(0, \sigma_{y}^2)$$
$$\eta_{ijk} = \beta_0 + \beta_1 \textrm{X}\textsubscript{m[i]} + \beta_2
\textrm{X}\textsubscript{y[i,j]} + \beta_3
\textrm{X}\textsubscript{s[i,j,k]} + b_i + b_{ij} + \epsilon_{ijk}$$
$$\pi_{ijk} =\frac{e_{ijk}^{\eta}}{1+e_{ijk}^{\eta}}$$
$$Y_{ijk} \sim Binom(1, \pi_{ijk})$$


On Mon, Jul 19, 2021 at 1:34 PM Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Brian,
>
> I'd write it as follows. In the case of a Gaussian model, you only have to
> write $Y_{ijk} \sim \mathcal{N}(\eta_{ijk}, \sigma^2)$ and drop the link
> function. (And you could replace \eta with \mu). Basically, Y depends on a
> distribution defined by some parameters. And these parameters might need
> some further definition.
>
> $i$: state index
> $j$: year index
> $k$: observation index
> $X_m$: state_mnthyr_pred
> $X_y$: state_year_pred
> $X_s$: state_pred
> $$Y_{ijk} \sim Binom(\pi_{ijk})$$
> $$\eta_{ijk} = \frac{\pi_{ijk}}{1- \pi_{ijk}}$$
> $$\eta_{ijk} = \beta_0 + \beta_1X_m + \beta_2 X_y + \beta_3 X_s + b_i +
> b_{ij}$$
> $$b_i\sim \mathcal{N}(0, \sigma_s^2)$$
> $$b_{ij}\sim \mathcal{N}(0, \sigma_{y}^2)$$
>
> Best regards,
>
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op ma 19 jul. 2021 om 17:44 schreef Brian Hudson <bhudson.gsu at gmail.com>:
>
>> Hello,
>>
>> I am fitting a multilevel model in `lme4` and am having trouble writing
>> the
>> equation for it. I very much appreciate any help. The formula and code is
>> below, but I am not sure if the equation represents the error correctly -
>> do I need to include error terms or is that captured by the distributions?
>> I am also not sure if I am representing the logit function correctly with
>> the indexing or functional form.
>>
>> The data are comprised of US-state months nested within US-state-years and
>> US-states. I include predictors at each level and a varying intercept for
>> both state-years and states.
>>
>> The formula looks like this in R:
>>
>> ```
>> as.formula(outcome ~ state_mnthyr_pred + state_year_pred + state_pred +
>>                          (1 | state) + (1 | state_year))
>> ```
>> Where the outcome is dichotomous. The state months (e.g. jan-2010,
>> feb-2010
>> ... jan-2013) are nested with state years and within states.
>>
>> The formula I am using can be seen here:
>>
>>
>> https://quicklatex.com/cache3/e9/ql_038eeb4e4e1b0af94d3ef69fe4ff7be9_l3.png
>> And the LaTeX code:
>>
>> $$
>> \begin{aligned}
>>     \mu &=\alpha_{j[i],k[i]} +
>> \beta_{0}(\operatorname{state\_mnthyr\_pred})\ \\
>>     \alpha_{j}  &\sim N \left(\gamma_{0}^{\alpha} +
>> \gamma_{1}^{\alpha}(\operatorname{\textrm{state\_year\_pred}}),
>> \sigma^2_{\alpha_{j}} \right)
>>     \text{, for \textrm{State-Year} j = 1,} \dots \text{, J} \\
>>     \alpha_{k}  &\sim N \left(\gamma_{0}^{\alpha} +
>> \gamma_{1}^{\alpha}(\operatorname{\textrm{state\_pred}}),
>> \sigma^2_{\alpha_{k}} \right)
>>     \text{, for State k = 1,} \dots \text{, K}\\
>> \pi_{i} &=\frac{e_{i}^{\mu}}{1+e_{i}^{\mu}}\\
>> y_{i j k} \sim & \operatorname{Binom}\left(1, \pi_{i}\right)\\
>> \end{aligned}
>> $$
>>
>> I really appreciate any help. Thank you.
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

	[[alternative HTML version deleted]]


From cr|@tob@|moy@ @end|ng |rom gm@||@com  Tue Jul 27 19:06:30 2021
From: cr|@tob@|moy@ @end|ng |rom gm@||@com (Cristobal Moya)
Date: Tue, 27 Jul 2021 19:06:30 +0200
Subject: [R-sig-ME] How to obtain monotonic effect of ordered factor
 predictor in lme4 package
Message-ID: <CAAnFKoQWegVmy2TicfDmdqyoj=cx9sDZruiv9EiLt4aUQWxp9Q@mail.gmail.com>

Dear list members,

I have a question regarding monotonic effects with lme4. I also posted this
in StackOverflow (https://stackoverflow.com/q/68546489/6832021), which is
what I reproduce below.

I want to obtain a monotonic effect for an ordinal predictor with the
function `lmer()` from the package lme4. My reference is the estimate that
can be obtained with `mo()` in the brms package.

Below a reprex with the desired estimate (leaving aside the different
statistical approach behind both packages) in `m1`, and what happens by
default (`m2`) when an ordered factor is used in `lmer()`

library(brms)
library(lme4)
sleepstudy$Days <- factor(sleepstudy$Days, ordered = T)
m1 <- brm(Reaction ~ mo(Days) + (1 | Subject), data = sleepstudy, chains =
2)
#> Compiling Stan program...
...
summary(m1)
#>  Family: gaussian
#>   Links: mu = identity; sigma = identity
#> Formula: Reaction ~ mo(Days) + (1 | Subject)
#>    Data: sleepstudy (Number of observations: 180)
#> Samples: 2 chains, each with iter = 2000; warmup = 1000; thin = 1;
#>          total post-warmup samples = 2000
#>
#> Group-Level Effects:
#> ~Subject (Number of levels: 18)
#>               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
#> sd(Intercept)    39.73      7.85    27.73    58.76 1.01      538      751
#>
#> Population-Level Effects:
#>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
#> Intercept   257.11     10.87   235.14   277.72 1.00      468      774
#> moDays       10.12      1.01     8.16    12.09 1.00     1603     1315
#>
#> Simplex Parameters:
#>            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
#> moDays1[1]     0.07      0.06     0.00     0.20 1.00     1343      747
#> moDays1[2]     0.07      0.05     0.00     0.20 1.00     1275      524
#> moDays1[3]     0.13      0.07     0.01     0.29 1.00     1337      591
#> moDays1[4]     0.10      0.07     0.00     0.28 1.00     1600      850
#> moDays1[5]     0.16      0.09     0.01     0.34 1.00     1285      658
#> moDays1[6]     0.09      0.06     0.00     0.24 1.00     1543      840
#> moDays1[7]     0.09      0.07     0.00     0.25 1.00     1534      992
#> moDays1[8]     0.16      0.08     0.02     0.32 1.00     1897      906
#> moDays1[9]     0.13      0.08     0.01     0.31 1.00     1839      936
#>
#> Family Specific Parameters:
#>       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
#> sigma    31.25      1.81    27.93    35.19 1.00     1726     1341
#>
#> Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
#> and Tail_ESS are effective sample size measures, and Rhat is the
potential
#> scale reduction factor on split chains (at convergence, Rhat = 1).

m2 <- lmer(Reaction ~ Days + (1 | Subject), data = sleepstudy)
summary(m2)
#> Linear mixed model fit by REML ['lmerMod']
#> Formula: Reaction ~ Days + (1 | Subject)
#>    Data: sleepstudy
#>
#> REML criterion at convergence: 1731.8
#>
#> Scaled residuals:
#>     Min      1Q  Median      3Q     Max
#> -3.3473 -0.5293  0.0317  0.5328  4.2570
#>
#> Random effects:
#>  Groups   Name        Variance Std.Dev.
#>  Subject  (Intercept) 1375.5   37.09
#>  Residual              987.6   31.43
#> Number of obs: 180, groups:  Subject, 18
#>
#> Fixed effects:
#>             Estimate Std. Error t value
#> (Intercept)  298.508      9.050  32.985
#> Days.L        95.074      7.407  12.835
#> Days.Q         7.744      7.407   1.045
#> Days.C        -0.705      7.407  -0.095
#> Days^4         5.889      7.407   0.795
#> Days^5         1.754      7.407   0.237
#> Days^6        -6.036      7.407  -0.815
#> Days^7        -1.695      7.407  -0.229
#> Days^8        -4.161      7.407  -0.562
#> Days^9         6.435      7.407   0.869
...

How could an equivalent monotonic effect of `moDays` in `m1` can be
obtained with lme4?

I'm grateful for anyone who can provide some orientation. Kind regards,
--

Crist?bal Moya

Research Fellow

Chair for Social Structure Analysis of Social Inequalities

Faculty of Sociology

Bielefeld University

	[[alternative HTML version deleted]]


From |nk@@w|||m@ @end|ng |rom hotm@||@de  Tue Jul 27 19:54:30 2021
From: |nk@@w|||m@ @end|ng |rom hotm@||@de (Inka Willms)
Date: Tue, 27 Jul 2021 17:54:30 +0000
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 175, Issue 23
In-Reply-To: <mailman.19318.9.1627380001.48353.r-sig-mixed-models@r-project.org>
References: <mailman.19318.9.1627380001.48353.r-sig-mixed-models@r-project.org>
Message-ID: <AM8P190MB080372127D58162746F338C58CE99@AM8P190MB0803.EURP190.PROD.OUTLOOK.COM>

Hello,
I have a question which will probably sound very basic to most of you. However, I am insecure about my results and rather ask before presenting and publishing something I am not 100% certain about. Therefore, I would really appreciate your help!

I am working on an ecotoxicological field study where a fungicide was applied onto 4 fields (with 7 subplots) whereas nothing was applied onto 4 control fields. The experiment takes place over 43 days. I checked for spatial and temporal autocorrelation.  My dependent variable is for this example the number of insects. I am unfortunately not allowed to provide data, but I believe that my questions can be answered nevertheless.
DAT is a continuous variable (days of the experiment)
Treatment is either TRUE or FALSE
I use a linear model, because the number of insects is over 2000

I constructed this model: MyModel <-  glmmTMB(NumberInsects ~ Treatment poly(DAT,2) + (1|Plot/Subplot), data=dat, REML=T, family=gaussian?(link="identity"))

I checked for the model fit via Dharma residual diagnostics, including temporal and spatial correlations.

I answered the question for the significance of difference of number of insects in respect to treatment and control on specific days via:
A <- emmeans(MyModel, ~Treatment|DAT, at =list(DAT=c(0,8,14,28,35,43)))
pairs(A)

However, I have issues answering the following question:

  *   Does treatment have an effect on the number of insects, considering the complete time course of the experiment?

Is it correct to use the emtrends approach here? I understand that the slope of the specified time frame are compared, which would also decouple the results from the initial numer of insects, as the slope is independent from the intercept.
This is the code that I am using to answer this question:
B <- emtrends(MyModel, "Treatment", var="DAT")
pairs(B)

It would be wrong to answer this question with the p-value of Treatment of the summary(myModel) function, right? However, I am wondering whether the 2nd polynomial of DAT is regarded in the emtrends approach.


I really hope that you can help me!

Kind regards,

InkaMarei

________________________________
Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> im Auftrag von r-sig-mixed-models-request at r-project.org <r-sig-mixed-models-request at r-project.org>
Gesendet: Dienstag, 27. Juli 2021 12:00
An: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Betreff: R-sig-mixed-models Digest, Vol 175, Issue 22

Send R-sig-mixed-models mailing list submissions to
        r-sig-mixed-models at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
        https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
or, via email, send a message with subject or body 'help' to
        r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
        r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

   1. Re: Multilevel equation (Brian Hudson)

----------------------------------------------------------------------

Message: 1
Date: Mon, 26 Jul 2021 22:05:19 -0400
From: Brian Hudson <bhudson.gsu at gmail.com>
To: Thierry Onkelinx <thierry.onkelinx at inbo.be>
Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Multilevel equation
Message-ID:
        <CANodPHM1Rg4c-B7x_whDewOcy6mm_z09T83zTmxom=yRSZozSA at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Thierry,

Thank you! I appreciate your help and explanation - that makes sense and I
can see where my other attempts were incorrect.

A couple questions-

1) The two lines that defined eta confused me - are they supposed to be
equal to each other? I edited the equation below such that pi has the link
function and eta has the linear equation - does that work?
2) I added epsilon for the individual error
3) There was no k index (individual level) in the equations, just i and j,
so i added some indexing in the predictors.

Does this equation make sense? Any issues with what I did? Thanks again for
your (and the community's) help.

https://quicklatex.com/cache3/9f/ql_4a4eb44285f65ea0dcaf93d551c44c9f_l3.png

$$b_i\sim \mathcal{N}(0, \sigma_s^2)$$
$$b_{ij}\sim \mathcal{N}(0, \sigma_{y}^2)$$
$$\eta_{ijk} = \beta_0 + \beta_1 \textrm{X}\textsubscript{m[i]} + \beta_2
\textrm{X}\textsubscript{y[i,j]} + \beta_3
\textrm{X}\textsubscript{s[i,j,k]} + b_i + b_{ij} + \epsilon_{ijk}$$
$$\pi_{ijk} =\frac{e_{ijk}^{\eta}}{1+e_{ijk}^{\eta}}$$
$$Y_{ijk} \sim Binom(1, \pi_{ijk})$$


On Mon, Jul 19, 2021 at 1:34 PM Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Brian,
>
> I'd write it as follows. In the case of a Gaussian model, you only have to
> write $Y_{ijk} \sim \mathcal{N}(\eta_{ijk}, \sigma^2)$ and drop the link
> function. (And you could replace \eta with \mu). Basically, Y depends on a
> distribution defined by some parameters. And these parameters might need
> some further definition.
>
> $i$: state index
> $j$: year index
> $k$: observation index
> $X_m$: state_mnthyr_pred
> $X_y$: state_year_pred
> $X_s$: state_pred
> $$Y_{ijk} \sim Binom(\pi_{ijk})$$
> $$\eta_{ijk} = \frac{\pi_{ijk}}{1- \pi_{ijk}}$$
> $$\eta_{ijk} = \beta_0 + \beta_1X_m + \beta_2 X_y + \beta_3 X_s + b_i +
> b_{ij}$$
> $$b_i\sim \mathcal{N}(0, \sigma_s^2)$$
> $$b_{ij}\sim \mathcal{N}(0, \sigma_{y}^2)$$
>
> Best regards,
>
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be<http://www.inbo.be>
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op ma 19 jul. 2021 om 17:44 schreef Brian Hudson <bhudson.gsu at gmail.com>:
>
>> Hello,
>>
>> I am fitting a multilevel model in `lme4` and am having trouble writing
>> the
>> equation for it. I very much appreciate any help. The formula and code is
>> below, but I am not sure if the equation represents the error correctly -
>> do I need to include error terms or is that captured by the distributions?
>> I am also not sure if I am representing the logit function correctly with
>> the indexing or functional form.
>>
>> The data are comprised of US-state months nested within US-state-years and
>> US-states. I include predictors at each level and a varying intercept for
>> both state-years and states.
>>
>> The formula looks like this in R:
>>
>> ```
>> as.formula(outcome ~ state_mnthyr_pred + state_year_pred + state_pred +
>>                          (1 | state) + (1 | state_year))
>> ```
>> Where the outcome is dichotomous. The state months (e.g. jan-2010,
>> feb-2010
>> ... jan-2013) are nested with state years and within states.
>>
>> The formula I am using can be seen here:
>>
>>
>> https://quicklatex.com/cache3/e9/ql_038eeb4e4e1b0af94d3ef69fe4ff7be9_l3.png
>> And the LaTeX code:
>>
>> $$
>> \begin{aligned}
>>     \mu &=\alpha_{j[i],k[i]} +
>> \beta_{0}(\operatorname{state\_mnthyr\_pred})\ \\
>>     \alpha_{j}  &\sim N \left(\gamma_{0}^{\alpha} +
>> \gamma_{1}^{\alpha}(\operatorname{\textrm{state\_year\_pred}}),
>> \sigma^2_{\alpha_{j}} \right)
>>     \text{, for \textrm{State-Year} j = 1,} \dots \text{, J} \\
>>     \alpha_{k}  &\sim N \left(\gamma_{0}^{\alpha} +
>> \gamma_{1}^{\alpha}(\operatorname{\textrm{state\_pred}}),
>> \sigma^2_{\alpha_{k}} \right)
>>     \text{, for State k = 1,} \dots \text{, K}\\
>> \pi_{i} &=\frac{e_{i}^{\mu}}{1+e_{i}^{\mu}}\\
>> y_{i j k} \sim & \operatorname{Binom}\left(1, \pi_{i}\right)\\
>> \end{aligned}
>> $$
>>
>> I really appreciate any help. Thank you.
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

        [[alternative HTML version deleted]]




------------------------------

Subject: Digest Footer

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


------------------------------

End of R-sig-mixed-models Digest, Vol 175, Issue 22
***************************************************

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Wed Jul 28 01:39:26 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 27 Jul 2021 19:39:26 -0400
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 175, Issue 23
In-Reply-To: <AM8P190MB080372127D58162746F338C58CE99@AM8P190MB0803.EURP190.PROD.OUTLOOK.COM>
References: <mailman.19318.9.1627380001.48353.r-sig-mixed-models@r-project.org>
 <AM8P190MB080372127D58162746F338C58CE99@AM8P190MB0803.EURP190.PROD.OUTLOOK.COM>
Message-ID: <c7c85289-2247-a141-2ad9-caa8f582f680@gmail.com>

   Not a complete answer, but some thoughts that other people might 
comment on.

   If you're primarily interested in treatment effects, because your 
treatments are applied at the level of fields, it might make your life a 
lot easier to compute average values by field & day (see Murtaugh 2007). 
Your data are (1) Gaussian (or being treated that way) (2) balanced.

   I can't see from your post whether the fixed effect model is additive 
(Treatment + poly(DAT, 2)) or interactive (Treatment*poly(DAT,2)).  You 
don't really need emmeans/emtrends to test the overall effect of 
treatment: you could use anova() to compare the models

NumberInsects ~ Treatment * poly(DAT, 2) + ...

with

NumberInsects ~ poly(DAT,2) + ...

   It's not so important if your primary interest is in Treatment, but 
you have at least the potential to consider variation in the temporal 
patterns across plots and subplots (random effect  (poly(DAT, 2) | 
Plot/subplot) ), if you have sufficient data ...


Murtaugh, Paul A. ?Simplicity and Complexity in Ecological Data 
Analysis.? Ecology 88, no. 1 (2007): 56?62.


On 7/27/21 1:54 PM, Inka Willms wrote:
> Hello,
> I have a question which will probably sound very basic to most of you. However, I am insecure about my results and rather ask before presenting and publishing something I am not 100% certain about. Therefore, I would really appreciate your help!
> 
> I am working on an ecotoxicological field study where a fungicide was applied onto 4 fields (with 7 subplots) whereas nothing was applied onto 4 control fields. The experiment takes place over 43 days. I checked for spatial and temporal autocorrelation.  My dependent variable is for this example the number of insects. I am unfortunately not allowed to provide data, but I believe that my questions can be answered nevertheless.
> DAT is a continuous variable (days of the experiment)
> Treatment is either TRUE or FALSE
> I use a linear model, because the number of insects is over 2000
> 
> I constructed this model: MyModel <-  glmmTMB(NumberInsects ~ Treatment poly(DAT,2) + (1|Plot/Subplot), data=dat, REML=T, family=gaussian?(link="identity"))
> 
> I checked for the model fit via Dharma residual diagnostics, including temporal and spatial correlations.
> 
> I answered the question for the significance of difference of number of insects in respect to treatment and control on specific days via:
> A <- emmeans(MyModel, ~Treatment|DAT, at =list(DAT=c(0,8,14,28,35,43)))
> pairs(A)
> 
> However, I have issues answering the following question:
> 
>    *   Does treatment have an effect on the number of insects, considering the complete time course of the experiment?
> 
> Is it correct to use the emtrends approach here? I understand that the slope of the specified time frame are compared, which would also decouple the results from the initial numer of insects, as the slope is independent from the intercept.
> This is the code that I am using to answer this question:
> B <- emtrends(MyModel, "Treatment", var="DAT")
> pairs(B)
> 
> It would be wrong to answer this question with the p-value of Treatment of the summary(myModel) function, right? However, I am wondering whether the 2nd polynomial of DAT is regarded in the emtrends approach.
> 
> 
> I really hope that you can help me!
> 
> Kind regards,
> 
> InkaMarei
> 
> ________________________________
> Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> im Auftrag von r-sig-mixed-models-request at r-project.org <r-sig-mixed-models-request at r-project.org>
> Gesendet: Dienstag, 27. Juli 2021 12:00
> An: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
> Betreff: R-sig-mixed-models Digest, Vol 175, Issue 22
> 
> Send R-sig-mixed-models mailing list submissions to
>          r-sig-mixed-models at r-project.org
> 
> To subscribe or unsubscribe via the World Wide Web, visit
>          https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help' to
>          r-sig-mixed-models-request at r-project.org
> 
> You can reach the person managing the list at
>          r-sig-mixed-models-owner at r-project.org
> 
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-sig-mixed-models digest..."
> 
> 
> Today's Topics:
> 
>     1. Re: Multilevel equation (Brian Hudson)
> 
> ----------------------------------------------------------------------
> 
> Message: 1
> Date: Mon, 26 Jul 2021 22:05:19 -0400
> From: Brian Hudson <bhudson.gsu at gmail.com>
> To: Thierry Onkelinx <thierry.onkelinx at inbo.be>
> Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] Multilevel equation
> Message-ID:
>          <CANodPHM1Rg4c-B7x_whDewOcy6mm_z09T83zTmxom=yRSZozSA at mail.gmail.com>
> Content-Type: text/plain; charset="utf-8"
> 
> Thierry,
> 
> Thank you! I appreciate your help and explanation - that makes sense and I
> can see where my other attempts were incorrect.
> 
> A couple questions-
> 
> 1) The two lines that defined eta confused me - are they supposed to be
> equal to each other? I edited the equation below such that pi has the link
> function and eta has the linear equation - does that work?
> 2) I added epsilon for the individual error
> 3) There was no k index (individual level) in the equations, just i and j,
> so i added some indexing in the predictors.
> 
> Does this equation make sense? Any issues with what I did? Thanks again for
> your (and the community's) help.
> 
> https://quicklatex.com/cache3/9f/ql_4a4eb44285f65ea0dcaf93d551c44c9f_l3.png
> 
> $$b_i\sim \mathcal{N}(0, \sigma_s^2)$$
> $$b_{ij}\sim \mathcal{N}(0, \sigma_{y}^2)$$
> $$\eta_{ijk} = \beta_0 + \beta_1 \textrm{X}\textsubscript{m[i]} + \beta_2
> \textrm{X}\textsubscript{y[i,j]} + \beta_3
> \textrm{X}\textsubscript{s[i,j,k]} + b_i + b_{ij} + \epsilon_{ijk}$$
> $$\pi_{ijk} =\frac{e_{ijk}^{\eta}}{1+e_{ijk}^{\eta}}$$
> $$Y_{ijk} \sim Binom(1, \pi_{ijk})$$
> 
> 
> On Mon, Jul 19, 2021 at 1:34 PM Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
> 
>> Dear Brian,
>>
>> I'd write it as follows. In the case of a Gaussian model, you only have to
>> write $Y_{ijk} \sim \mathcal{N}(\eta_{ijk}, \sigma^2)$ and drop the link
>> function. (And you could replace \eta with \mu). Basically, Y depends on a
>> distribution defined by some parameters. And these parameters might need
>> some further definition.
>>
>> $i$: state index
>> $j$: year index
>> $k$: observation index
>> $X_m$: state_mnthyr_pred
>> $X_y$: state_year_pred
>> $X_s$: state_pred
>> $$Y_{ijk} \sim Binom(\pi_{ijk})$$
>> $$\eta_{ijk} = \frac{\pi_{ijk}}{1- \pi_{ijk}}$$
>> $$\eta_{ijk} = \beta_0 + \beta_1X_m + \beta_2 X_y + \beta_3 X_s + b_i +
>> b_{ij}$$
>> $$b_i\sim \mathcal{N}(0, \sigma_s^2)$$
>> $$b_{ij}\sim \mathcal{N}(0, \sigma_{y}^2)$$
>>
>> Best regards,
>>
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
>> FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88 bus 73, 1000 Brussel
>> www.inbo.be<http://www.inbo.be>
>>
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>
>> <https://www.inbo.be>
>>
>>
>> Op ma 19 jul. 2021 om 17:44 schreef Brian Hudson <bhudson.gsu at gmail.com>:
>>
>>> Hello,
>>>
>>> I am fitting a multilevel model in `lme4` and am having trouble writing
>>> the
>>> equation for it. I very much appreciate any help. The formula and code is
>>> below, but I am not sure if the equation represents the error correctly -
>>> do I need to include error terms or is that captured by the distributions?
>>> I am also not sure if I am representing the logit function correctly with
>>> the indexing or functional form.
>>>
>>> The data are comprised of US-state months nested within US-state-years and
>>> US-states. I include predictors at each level and a varying intercept for
>>> both state-years and states.
>>>
>>> The formula looks like this in R:
>>>
>>> ```
>>> as.formula(outcome ~ state_mnthyr_pred + state_year_pred + state_pred +
>>>                           (1 | state) + (1 | state_year))
>>> ```
>>> Where the outcome is dichotomous. The state months (e.g. jan-2010,
>>> feb-2010
>>> ... jan-2013) are nested with state years and within states.
>>>
>>> The formula I am using can be seen here:
>>>
>>>
>>> https://quicklatex.com/cache3/e9/ql_038eeb4e4e1b0af94d3ef69fe4ff7be9_l3.png
>>> And the LaTeX code:
>>>
>>> $$
>>> \begin{aligned}
>>>      \mu &=\alpha_{j[i],k[i]} +
>>> \beta_{0}(\operatorname{state\_mnthyr\_pred})\ \\
>>>      \alpha_{j}  &\sim N \left(\gamma_{0}^{\alpha} +
>>> \gamma_{1}^{\alpha}(\operatorname{\textrm{state\_year\_pred}}),
>>> \sigma^2_{\alpha_{j}} \right)
>>>      \text{, for \textrm{State-Year} j = 1,} \dots \text{, J} \\
>>>      \alpha_{k}  &\sim N \left(\gamma_{0}^{\alpha} +
>>> \gamma_{1}^{\alpha}(\operatorname{\textrm{state\_pred}}),
>>> \sigma^2_{\alpha_{k}} \right)
>>>      \text{, for State k = 1,} \dots \text{, K}\\
>>> \pi_{i} &=\frac{e_{i}^{\mu}}{1+e_{i}^{\mu}}\\
>>> y_{i j k} \sim & \operatorname{Binom}\left(1, \pi_{i}\right)\\
>>> \end{aligned}
>>> $$
>>>
>>> I really appreciate any help. Thank you.
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
> 
>          [[alternative HTML version deleted]]
> 
> 
> 
> 
> ------------------------------
> 
> Subject: Digest Footer
> 
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> ------------------------------
> 
> End of R-sig-mixed-models Digest, Vol 175, Issue 22
> ***************************************************
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics


From @|ngm@nn @end|ng |rom gm@||@com  Fri Jul 30 14:14:01 2021
From: @|ngm@nn @end|ng |rom gm@||@com (Henrik Singmann)
Date: Fri, 30 Jul 2021 14:14:01 +0200
Subject: [R-sig-ME] How to obtain monotonic effect of ordered factor
 predictor in lme4 package
In-Reply-To: <CAAnFKoQWegVmy2TicfDmdqyoj=cx9sDZruiv9EiLt4aUQWxp9Q@mail.gmail.com>
References: <CAAnFKoQWegVmy2TicfDmdqyoj=cx9sDZruiv9EiLt4aUQWxp9Q@mail.gmail.com>
Message-ID: <CA+rDMKJfn0i231ateMkcU1-Y2m=AT14qShD3ScpKCARR9jMRrw@mail.gmail.com>

Hi Crist?bal,

As far as I know, there is no correspondence in lme4 to the monotonic
effects as there is no way to enforce certain fixed effect estimate are
strictly positive or negative.

However, if the data is strictly ordered, you can get something similar by
using appropriate coding. So instead of using an ordered factor you use a
regular factor and code_diff_forward() from package codingMatrices.

library("lme4")
library("codingMatrices")
sleepstudy$Days <- factor(sleepstudy$Days)
m2 <- lmer(Reaction ~ Days + (1 | Subject), data = sleepstudy,
           contrasts = list(Days = "code_diff_forward"))
summary(m2)
#> Linear mixed model fit by REML ['lmerMod']
#> Formula: Reaction ~ Days + (1 | Subject)
#>    Data: sleepstudy
#>
#> REML criterion at convergence: 1729.5
#>
#> Scaled residuals:
#>     Min      1Q  Median      3Q     Max
#> -3.3473 -0.5293  0.0317  0.5328  4.2570
#>
#> Random effects:
#>  Groups   Name        Variance Std.Dev.
#>  Subject  (Intercept) 1375.5   37.09
#>  Residual              987.6   31.43
#> Number of obs: 180, groups:  Subject, 18
#>
#> Fixed effects:
#>             Estimate Std. Error t value
#> (Intercept) 298.5079     9.0499  32.985
#> Days0-1      -7.8439    10.4753  -0.749
#> Days1-2      -0.8661    10.4753  -0.083
#> Days2-3     -17.6301    10.4753  -1.683
#> Days3-4      -5.6574    10.4753  -0.540
#> Days4-5     -19.8690    10.4753  -1.897
#> Days5-6      -3.6598    10.4753  -0.349
#> Days6-7      -6.5723    10.4753  -0.627
#> Days7-8     -17.8789    10.4753  -1.707
#> Days8-9     -14.2217    10.4753  -1.358
#> [...]

This give you the differences between each two days as shown next:
library("tidyverse")
sleepstudy %>%
  group_by(Days) %>%
  summarise(mean = mean(Reaction)) %>%
  mutate(meanlag = lag(mean)) %>%
  mutate(diff = meanlag-mean)
#> # A tibble: 10 x 4
#>    Days   mean meanlag    diff
#>    <fct> <dbl>   <dbl>   <dbl>
#>  1 0      257.     NA   NA
#>  2 1      264.    257.  -7.84
#>  3 2      265.    264.  -0.866
#>  4 3      283.    265. -17.6
#>  5 4      289.    283.  -5.66
#>  6 5      309.    289. -19.9
#>  7 6      312.    309.  -3.66
#>  8 7      319.    312.  -6.57
#>  9 8      337.    319. -17.9
#> 10 9      351.    337. -14.2

There is also the possibility to get exactly the same results by just using
emmeans on the model fitted with default contrasts:
library("lme4")
sleepstudy$Days <- factor(sleepstudy$Days)

m2 <- lmer(Reaction ~ Days + (1 | Subject), data = sleepstudy)
library("emmeans")
emmeans(m2, "Days", contr = "consec")
#> $emmeans
#>  Days emmean   SE df lower.CL upper.CL
#>  0       257 11.5 42      234      280
#>  1       264 11.5 42      241      288
#>  2       265 11.5 42      242      288
#>  3       283 11.5 42      260      306
#>  4       289 11.5 42      266      312
#>  5       309 11.5 42      285      332
#>  6       312 11.5 42      289      335
#>  7       319 11.5 42      296      342
#>  8       337 11.5 42      314      360
#>  9       351 11.5 42      328      374
#>
#> Degrees-of-freedom method: kenward-roger
#> Confidence level used: 0.95
#>
#> $contrasts
#>  contrast estimate   SE  df t.ratio p.value
#>  1 - 0       7.844 10.5 153   0.749  0.9887
#>  2 - 1       0.866 10.5 153   0.083  1.0000
#>  3 - 2      17.630 10.5 153   1.683  0.5279
#>  4 - 3       5.657 10.5 153   0.540  0.9988
#>  5 - 4      19.869 10.5 153   1.897  0.3775
#>  6 - 5       3.660 10.5 153   0.349  1.0000
#>  7 - 6       6.572 10.5 153   0.627  0.9965
#>  8 - 7      17.879 10.5 153   1.707  0.5098
#>  9 - 8      14.222 10.5 153   1.358  0.7629
#>
#> Degrees-of-freedom method: kenward-roger
#> P value adjustment: mvt method for 9 tests

 Of course, all of this only works if the means are ordered in this way
(otherwise you will have effects that differ in sign).

Hope that helps,
Henrik



Am Di., 27. Juli 2021 um 19:06 Uhr schrieb Cristobal Moya <
cristobalmoya at gmail.com>:

> Dear list members,
>
> I have a question regarding monotonic effects with lme4. I also posted this
> in StackOverflow (https://stackoverflow.com/q/68546489/6832021), which is
> what I reproduce below.
>
> I want to obtain a monotonic effect for an ordinal predictor with the
> function `lmer()` from the package lme4. My reference is the estimate that
> can be obtained with `mo()` in the brms package.
>
> Below a reprex with the desired estimate (leaving aside the different
> statistical approach behind both packages) in `m1`, and what happens by
> default (`m2`) when an ordered factor is used in `lmer()`
>
> library(brms)
> library(lme4)
> sleepstudy$Days <- factor(sleepstudy$Days, ordered = T)
> m1 <- brm(Reaction ~ mo(Days) + (1 | Subject), data = sleepstudy, chains =
> 2)
> #> Compiling Stan program...
> ...
> summary(m1)
> #>  Family: gaussian
> #>   Links: mu = identity; sigma = identity
> #> Formula: Reaction ~ mo(Days) + (1 | Subject)
> #>    Data: sleepstudy (Number of observations: 180)
> #> Samples: 2 chains, each with iter = 2000; warmup = 1000; thin = 1;
> #>          total post-warmup samples = 2000
> #>
> #> Group-Level Effects:
> #> ~Subject (Number of levels: 18)
> #>               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
> Tail_ESS
> #> sd(Intercept)    39.73      7.85    27.73    58.76 1.01      538
> 751
> #>
> #> Population-Level Effects:
> #>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
> #> Intercept   257.11     10.87   235.14   277.72 1.00      468      774
> #> moDays       10.12      1.01     8.16    12.09 1.00     1603     1315
> #>
> #> Simplex Parameters:
> #>            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
> #> moDays1[1]     0.07      0.06     0.00     0.20 1.00     1343      747
> #> moDays1[2]     0.07      0.05     0.00     0.20 1.00     1275      524
> #> moDays1[3]     0.13      0.07     0.01     0.29 1.00     1337      591
> #> moDays1[4]     0.10      0.07     0.00     0.28 1.00     1600      850
> #> moDays1[5]     0.16      0.09     0.01     0.34 1.00     1285      658
> #> moDays1[6]     0.09      0.06     0.00     0.24 1.00     1543      840
> #> moDays1[7]     0.09      0.07     0.00     0.25 1.00     1534      992
> #> moDays1[8]     0.16      0.08     0.02     0.32 1.00     1897      906
> #> moDays1[9]     0.13      0.08     0.01     0.31 1.00     1839      936
> #>
> #> Family Specific Parameters:
> #>       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
> #> sigma    31.25      1.81    27.93    35.19 1.00     1726     1341
> #>
> #> Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
> #> and Tail_ESS are effective sample size measures, and Rhat is the
> potential
> #> scale reduction factor on split chains (at convergence, Rhat = 1).
>
> m2 <- lmer(Reaction ~ Days + (1 | Subject), data = sleepstudy)
> summary(m2)
> #> Linear mixed model fit by REML ['lmerMod']
> #> Formula: Reaction ~ Days + (1 | Subject)
> #>    Data: sleepstudy
> #>
> #> REML criterion at convergence: 1731.8
> #>
> #> Scaled residuals:
> #>     Min      1Q  Median      3Q     Max
> #> -3.3473 -0.5293  0.0317  0.5328  4.2570
> #>
> #> Random effects:
> #>  Groups   Name        Variance Std.Dev.
> #>  Subject  (Intercept) 1375.5   37.09
> #>  Residual              987.6   31.43
> #> Number of obs: 180, groups:  Subject, 18
> #>
> #> Fixed effects:
> #>             Estimate Std. Error t value
> #> (Intercept)  298.508      9.050  32.985
> #> Days.L        95.074      7.407  12.835
> #> Days.Q         7.744      7.407   1.045
> #> Days.C        -0.705      7.407  -0.095
> #> Days^4         5.889      7.407   0.795
> #> Days^5         1.754      7.407   0.237
> #> Days^6        -6.036      7.407  -0.815
> #> Days^7        -1.695      7.407  -0.229
> #> Days^8        -4.161      7.407  -0.562
> #> Days^9         6.435      7.407   0.869
> ...
>
> How could an equivalent monotonic effect of `moDays` in `m1` can be
> obtained with lme4?
>
> I'm grateful for anyone who can provide some orientation. Kind regards,
> --
>
> Crist?bal Moya
>
> Research Fellow
>
> Chair for Social Structure Analysis of Social Inequalities
>
> Faculty of Sociology
>
> Bielefeld University
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
Dr. Henrik Singmann
Lecturer, Experimental Psychology
University College London (UCL), UK
http://singmann.org

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Fri Jul 30 22:14:43 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 30 Jul 2021 16:14:43 -0400
Subject: [R-sig-ME] How to obtain monotonic effect of ordered factor
 predictor in lme4 package
In-Reply-To: <CA+rDMKJfn0i231ateMkcU1-Y2m=AT14qShD3ScpKCARR9jMRrw@mail.gmail.com>
References: <CAAnFKoQWegVmy2TicfDmdqyoj=cx9sDZruiv9EiLt4aUQWxp9Q@mail.gmail.com>
 <CA+rDMKJfn0i231ateMkcU1-Y2m=AT14qShD3ScpKCARR9jMRrw@mail.gmail.com>
Message-ID: <d5ee9e0f-f4ea-c568-feab-7964a4165518@gmail.com>

  A few more thoughts

codingMatrices::code_diff() and MASS::contr.sdif() are basically 
identical (in case you don't feel like installing another package -- 
MASS is automatically installed with base R)

Not quite sure why you're using code_diff_forward rather than code_diff? 
The latter would naively make more sense to me.

   You can't constrain fixed-effect parameters in lme4::lmer (they are 
profiled out of the likelihood function, so they're not accessible to be 
constrained), but in glmmTMB you could do this:

data("sleepstudy", package= "lme4")
ss <- within(sleepstudy, {
     Days <- factor(Days)
     contrasts(Days) <- MASS::contr.sdif
})
library(glmmTMB)
m1 <- glmmTMB(Reaction ~ Days + (1 | Subject), data = ss)
m2 <- update(m1,
              control = glmmTMBControl(
            optArgs = list(lower=c(-Inf, rep(0,9), rep(-Inf, 2)))))


   Notes: (1) the constraints aren't binding in this example because all 
the parameters are estimated as being positive anyway (I was too lazy to 
find another example/perturb this example); (2) you do need to know the 
parameter ordering for this to work: in this case we have the intercept 
(unconstrained) followed by 9 successive difference values, followed by 
parameters for the RE variance and the dispersion (estimated on the log 
scale, unconstrained).  The combination of fixef(m2) and m2$obj$par can 
help you figure this out.


On 7/30/21 8:14 AM, Henrik Singmann wrote:
> Hi Crist?bal,
> 
> As far as I know, there is no correspondence in lme4 to the monotonic
> effects as there is no way to enforce certain fixed effect estimate are
> strictly positive or negative.
> 
> However, if the data is strictly ordered, you can get something similar by
> using appropriate coding. So instead of using an ordered factor you use a
> regular factor and code_diff_forward() from package codingMatrices.
> 
> library("lme4")
> library("codingMatrices")
> sleepstudy$Days <- factor(sleepstudy$Days)
> m2 <- lmer(Reaction ~ Days + (1 | Subject), data = sleepstudy,
>             contrasts = list(Days = "code_diff_forward"))
> summary(m2)
> #> Linear mixed model fit by REML ['lmerMod']
> #> Formula: Reaction ~ Days + (1 | Subject)
> #>    Data: sleepstudy
> #>
> #> REML criterion at convergence: 1729.5
> #>
> #> Scaled residuals:
> #>     Min      1Q  Median      3Q     Max
> #> -3.3473 -0.5293  0.0317  0.5328  4.2570
> #>
> #> Random effects:
> #>  Groups   Name        Variance Std.Dev.
> #>  Subject  (Intercept) 1375.5   37.09
> #>  Residual              987.6   31.43
> #> Number of obs: 180, groups:  Subject, 18
> #>
> #> Fixed effects:
> #>             Estimate Std. Error t value
> #> (Intercept) 298.5079     9.0499  32.985
> #> Days0-1      -7.8439    10.4753  -0.749
> #> Days1-2      -0.8661    10.4753  -0.083
> #> Days2-3     -17.6301    10.4753  -1.683
> #> Days3-4      -5.6574    10.4753  -0.540
> #> Days4-5     -19.8690    10.4753  -1.897
> #> Days5-6      -3.6598    10.4753  -0.349
> #> Days6-7      -6.5723    10.4753  -0.627
> #> Days7-8     -17.8789    10.4753  -1.707
> #> Days8-9     -14.2217    10.4753  -1.358
> #> [...]
> 
> This give you the differences between each two days as shown next:
> library("tidyverse")
> sleepstudy %>%
>    group_by(Days) %>%
>    summarise(mean = mean(Reaction)) %>%
>    mutate(meanlag = lag(mean)) %>%
>    mutate(diff = meanlag-mean)
> #> # A tibble: 10 x 4
> #>    Days   mean meanlag    diff
> #>    <fct> <dbl>   <dbl>   <dbl>
> #>  1 0      257.     NA   NA
> #>  2 1      264.    257.  -7.84
> #>  3 2      265.    264.  -0.866
> #>  4 3      283.    265. -17.6
> #>  5 4      289.    283.  -5.66
> #>  6 5      309.    289. -19.9
> #>  7 6      312.    309.  -3.66
> #>  8 7      319.    312.  -6.57
> #>  9 8      337.    319. -17.9
> #> 10 9      351.    337. -14.2
> 
> There is also the possibility to get exactly the same results by just using
> emmeans on the model fitted with default contrasts:
> library("lme4")
> sleepstudy$Days <- factor(sleepstudy$Days)
> 
> m2 <- lmer(Reaction ~ Days + (1 | Subject), data = sleepstudy)
> library("emmeans")
> emmeans(m2, "Days", contr = "consec")
> #> $emmeans
> #>  Days emmean   SE df lower.CL upper.CL
> #>  0       257 11.5 42      234      280
> #>  1       264 11.5 42      241      288
> #>  2       265 11.5 42      242      288
> #>  3       283 11.5 42      260      306
> #>  4       289 11.5 42      266      312
> #>  5       309 11.5 42      285      332
> #>  6       312 11.5 42      289      335
> #>  7       319 11.5 42      296      342
> #>  8       337 11.5 42      314      360
> #>  9       351 11.5 42      328      374
> #>
> #> Degrees-of-freedom method: kenward-roger
> #> Confidence level used: 0.95
> #>
> #> $contrasts
> #>  contrast estimate   SE  df t.ratio p.value
> #>  1 - 0       7.844 10.5 153   0.749  0.9887
> #>  2 - 1       0.866 10.5 153   0.083  1.0000
> #>  3 - 2      17.630 10.5 153   1.683  0.5279
> #>  4 - 3       5.657 10.5 153   0.540  0.9988
> #>  5 - 4      19.869 10.5 153   1.897  0.3775
> #>  6 - 5       3.660 10.5 153   0.349  1.0000
> #>  7 - 6       6.572 10.5 153   0.627  0.9965
> #>  8 - 7      17.879 10.5 153   1.707  0.5098
> #>  9 - 8      14.222 10.5 153   1.358  0.7629
> #>
> #> Degrees-of-freedom method: kenward-roger
> #> P value adjustment: mvt method for 9 tests
> 
>   Of course, all of this only works if the means are ordered in this way
> (otherwise you will have effects that differ in sign).
> 
> Hope that helps,
> Henrik
> 
> 
> 
> Am Di., 27. Juli 2021 um 19:06 Uhr schrieb Cristobal Moya <
> cristobalmoya at gmail.com>:
> 
>> Dear list members,
>>
>> I have a question regarding monotonic effects with lme4. I also posted this
>> in StackOverflow (https://stackoverflow.com/q/68546489/6832021), which is
>> what I reproduce below.
>>
>> I want to obtain a monotonic effect for an ordinal predictor with the
>> function `lmer()` from the package lme4. My reference is the estimate that
>> can be obtained with `mo()` in the brms package.
>>
>> Below a reprex with the desired estimate (leaving aside the different
>> statistical approach behind both packages) in `m1`, and what happens by
>> default (`m2`) when an ordered factor is used in `lmer()`
>>
>> library(brms)
>> library(lme4)
>> sleepstudy$Days <- factor(sleepstudy$Days, ordered = T)
>> m1 <- brm(Reaction ~ mo(Days) + (1 | Subject), data = sleepstudy, chains =
>> 2)
>> #> Compiling Stan program...
>> ...
>> summary(m1)
>> #>  Family: gaussian
>> #>   Links: mu = identity; sigma = identity
>> #> Formula: Reaction ~ mo(Days) + (1 | Subject)
>> #>    Data: sleepstudy (Number of observations: 180)
>> #> Samples: 2 chains, each with iter = 2000; warmup = 1000; thin = 1;
>> #>          total post-warmup samples = 2000
>> #>
>> #> Group-Level Effects:
>> #> ~Subject (Number of levels: 18)
>> #>               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
>> Tail_ESS
>> #> sd(Intercept)    39.73      7.85    27.73    58.76 1.01      538
>> 751
>> #>
>> #> Population-Level Effects:
>> #>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
>> #> Intercept   257.11     10.87   235.14   277.72 1.00      468      774
>> #> moDays       10.12      1.01     8.16    12.09 1.00     1603     1315
>> #>
>> #> Simplex Parameters:
>> #>            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
>> #> moDays1[1]     0.07      0.06     0.00     0.20 1.00     1343      747
>> #> moDays1[2]     0.07      0.05     0.00     0.20 1.00     1275      524
>> #> moDays1[3]     0.13      0.07     0.01     0.29 1.00     1337      591
>> #> moDays1[4]     0.10      0.07     0.00     0.28 1.00     1600      850
>> #> moDays1[5]     0.16      0.09     0.01     0.34 1.00     1285      658
>> #> moDays1[6]     0.09      0.06     0.00     0.24 1.00     1543      840
>> #> moDays1[7]     0.09      0.07     0.00     0.25 1.00     1534      992
>> #> moDays1[8]     0.16      0.08     0.02     0.32 1.00     1897      906
>> #> moDays1[9]     0.13      0.08     0.01     0.31 1.00     1839      936
>> #>
>> #> Family Specific Parameters:
>> #>       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
>> #> sigma    31.25      1.81    27.93    35.19 1.00     1726     1341
>> #>
>> #> Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
>> #> and Tail_ESS are effective sample size measures, and Rhat is the
>> potential
>> #> scale reduction factor on split chains (at convergence, Rhat = 1).
>>
>> m2 <- lmer(Reaction ~ Days + (1 | Subject), data = sleepstudy)
>> summary(m2)
>> #> Linear mixed model fit by REML ['lmerMod']
>> #> Formula: Reaction ~ Days + (1 | Subject)
>> #>    Data: sleepstudy
>> #>
>> #> REML criterion at convergence: 1731.8
>> #>
>> #> Scaled residuals:
>> #>     Min      1Q  Median      3Q     Max
>> #> -3.3473 -0.5293  0.0317  0.5328  4.2570
>> #>
>> #> Random effects:
>> #>  Groups   Name        Variance Std.Dev.
>> #>  Subject  (Intercept) 1375.5   37.09
>> #>  Residual              987.6   31.43
>> #> Number of obs: 180, groups:  Subject, 18
>> #>
>> #> Fixed effects:
>> #>             Estimate Std. Error t value
>> #> (Intercept)  298.508      9.050  32.985
>> #> Days.L        95.074      7.407  12.835
>> #> Days.Q         7.744      7.407   1.045
>> #> Days.C        -0.705      7.407  -0.095
>> #> Days^4         5.889      7.407   0.795
>> #> Days^5         1.754      7.407   0.237
>> #> Days^6        -6.036      7.407  -0.815
>> #> Days^7        -1.695      7.407  -0.229
>> #> Days^8        -4.161      7.407  -0.562
>> #> Days^9         6.435      7.407   0.869
>> ...
>>
>> How could an equivalent monotonic effect of `moDays` in `m1` can be
>> obtained with lme4?
>>
>> I'm grateful for anyone who can provide some orientation. Kind regards,
>> --
>>
>> Crist?bal Moya
>>
>> Research Fellow
>>
>> Chair for Social Structure Analysis of Social Inequalities
>>
>> Faculty of Sociology
>>
>> Bielefeld University
>>
>>          [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics


From bbo|ker @end|ng |rom gm@||@com  Sun Aug  1 23:23:43 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sun, 1 Aug 2021 17:23:43 -0400
Subject: [R-sig-ME] lmer function
In-Reply-To: <CAJt0zy-2N4mgVvM3+eOToPUbktvMgsT9UgMTbWi7zXKGt3+-Rg@mail.gmail.com>
References: <CAJt0zy-YNO3mBVZOVgd-oKHonqs15GtU1B=-iPWphW-KgRQ4VQ@mail.gmail.com>
 <a0d0cac5-46b8-9198-9d90-1fbeb50ef790@gmail.com>
 <CAJt0zy-2N4mgVvM3+eOToPUbktvMgsT9UgMTbWi7zXKGt3+-Rg@mail.gmail.com>
Message-ID: <7f51de6c-44a6-02ab-331f-7584f2aaacab@gmail.com>

  Please reply to the list!

  I think the warnings are an edge-case/false positive.
  When reading a character vector R doesn't convert "NA" to a 
not-available (NA) value (because people might have character vectors 
denoting, say, North America (NA) or Nabisco (NA)).  These provoke a 
warning when converting.  Try this function instead to convert:


as_num <- function(x) {
     x <- as.character(x)
     x[!is.na(x) & (x=="NA")] <- NA_character_
     as.numeric(x)
}

On 8/1/21 5:00 PM, mina jahan wrote:
> Dear Ben,
> Thank you for your reply.
> age and bmi are quantitative variables.
> How can I define them as numeric variables?
> I used as.numeric, but I got warning message:NAs introduced by coercion
> 
> cheers
> Mina
> 
> On Mon, 2 Aug 2021 at 01:23, Ben Bolker <bbolker at gmail.com 
> <mailto:bbolker at gmail.com>> wrote:
> 
>      ? ? Since you made your data available to me via google drive, I was
>     able to figure out the problem; I wouldn't have been able to if you
>     hadn't shared the data, although if you had presented the results of
>     summary(B) or str(B) I (or someone) would probably have been able to
>     diagnose the issue.
> 
>      ? ?The problem is that your 'bmi' variable is of type *character*;
>     that
>     means that when building the model matrix for the fixed-effect part of
>     the model, we end up treating it as a categorical variable and
>     trying to
>     build a model matrix that is of size
> 
>     8.0*nr*((n_bmi-1)+(n_age-1) + 1 + 2)/2^30
> 
>     in GB (n_age, n_bmi are the number of unique values of bmi and age);
>     this comes out to about 30.5 Gb.? On my machine it fails immediately by
>     running out of memory; the proximal problem you are probably having is
>     when the program tries to compute the rank of the matrix to check for
>     muticollinearity.? In any case, though, you probably *don't* want to
>     fit
>     a model with 42,000 fixed parameters ...
> 
>      ? ?If we address this problem by converting age and bmi to numeric, or
>     by using readr::read_csv() to read in the file in the first place,
>     everything works. (Note usual cautions about applying as.numeric()
>     directly to a *factor*; in this case (with R>4.0) we are starting with
>     type character, so it's OK.
> 
> 
>      ? (to my surprise fread::data.table() also mis-categorizes these
>     columns.? I haven't been able to figure out why read.csv() and
>     (especially) fread() get fooled ...? the usual reasons (non-numeric
>     entries, large numbers of NAs at the start of the column, etc.) don't
>     seem to be present.
> 
>      ? ?cheers
>      ? ? ?Ben Bolker
> 
> 
>     On 7/31/21 6:09 PM, mina jahan wrote:
>      >
>      >? ?I have a data set containing 20 imputed data. I want to use the
>     lmer
>      > function for computing regression coefficients for each
>     imputation. But
>      > I was exposed with under error:
>      > Error in qr.default(X, tol = tol, LAPACK = FALSE) :
>      >? ? too large a matrix for LINPACK
>      > I can not understand this error.? I think that this issue is
>     related to
>      > the optimization algorithms used for inference.
>      > R code is as follows:
>      > library(lme4)
>      >
>     B<-read.csv("C:/Users/USER/Desktop/micemd2.csv",header=TRUE,na.string="")
>      > names(B)
>      > names(B)[names(B) == ".imp"] <- "imp"
>      > B<-B[ , -2]
>      > names(B)
>      > B<-B[which(B$imp!=0),]
>      > head(B)
>      > tail(B)
>      >
>      > ###################split dataset by imp
>      > list_df <- split(B, B$imp)
>      >
>      > ###################Coeficient for each imputation of lmer
>      > result1_df <- as.data.frame(matrix(ncol=5,nrow=length(list_df)))
>     # make
>      > an empty dataframe
>      > colnames(result1_df)<-c("intercept","age","sex","bmi","time")
>     #give the
>      > dataframe column names
>      > for (i in 1:length(list_df)){ #run a loop over the dataframes in
>     the list
>      >? ? mod<-lmer(dbp~age +factor( sex) + bmi +
>      > time+(1|id),data=list_df[[i]]) #mixed model
>      >? ? result1_df[i,]<-fixef(mod) #extract coefficients to dataframe
>      > rownames(result1_df)[i]<-names(list_df)[i] #assign rowname to
>     results
>      > from data used
>      > }
>      > result1_df
>      > mean(result1_df$intercept)
>      > mean(result1_df$age)
>      > mean(result1_df$sex)
>      > mean(result1_df$bmi)
>      > mean(result1_df$time)
>      >
>      >
> 
>     -- 
>     Dr. Benjamin Bolker
>     Professor, Mathematics & Statistics and Biology, McMaster University
>     Director, School of Computational Science and Engineering
>     Graduate chair, Mathematics & Statistics
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics


From biii m@iii@g oii de@@ey@ws  Mon Aug  2 03:43:19 2021
From: biii m@iii@g oii de@@ey@ws (biii m@iii@g oii de@@ey@ws)
Date: Sun, 1 Aug 2021 21:43:19 -0400
Subject: [R-sig-ME] Data Handling within nlme library
Message-ID: <05b901d7873f$c5ac93f0$5105bbd0$@denney.ws>

Hello,

 

I'm having an issue with data handling within the nlme library.
Specifically, when I fit a gnls model within one function, I cannot update
that model within another function with new data.  Are there any ways to
give data within a function and have the model work outside?  An example of
what I'm trying to do is below in the first example:

 

``` r

library(nlme)

 

make_model <- function() {

  my_soybean <- Soybean

  gnls(weight ~ SSlogis(Time, Asym, xmid, scal), data=my_soybean, weights =
varPower())

}

 

my_model <- make_model()

#> Error in stats::nls(formula = weight ~ SSlogis(Time, Asym, xmid, scal), :
object 'my_soybean' not found

# Issue: my_soybean is in the function environment but not found during
estimation

 

make_model <- function() {

  time <- Soybean$Time

  weight <- Soybean$weight

  gnls(

    weight ~ Asym/(1+exp((xmid-time)/scal)),

    start=c(Asym=30, xmid=40, scal=10),

    weights = varPower()

  )

}

 

my_model <- make_model()

#> Error in terms.formula(formula, data = data): '.' in formula and no
'data' argument

# Issue: No idea where the error is coming from (making a guess that it is
the weights argument)

 

make_model <- function() {

  time <- Soybean$Time

  weight <- Soybean$weight

  gnls(

    weight ~ Asym/(1+exp((xmid-time)/scal)),

    start=c(Asym=30, xmid=40, scal=10),

  )

}

 

my_model <- make_model()

# Issue: when data are given in the local environment but not with a `data`

# argument, it works.

```

 

<sup>Created on 2021-08-01 by the [reprex
package](https://reprex.tidyverse.org) (v2.0.0)</sup>

 

Thanks,

 

Bill

 

P.S.  I'm pretty sure that this is also related to an issue found in the
nlraa library described at https://github.com/femiguez/nlraa/issues/4


	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Mon Aug  2 16:03:19 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 2 Aug 2021 10:03:19 -0400
Subject: [R-sig-ME] Statistical consultation GLMM
In-Reply-To: <CA+XLY+dicSUoObeMhtEdfHjUZxvfDr0Q=EydeXQ0vQg+tfXxzw@mail.gmail.com>
References: <CA+XLY+dicSUoObeMhtEdfHjUZxvfDr0Q=EydeXQ0vQg+tfXxzw@mail.gmail.com>
Message-ID: <54995b40-7229-653c-6c43-1f6cf08cb3be@gmail.com>



On 7/22/21 7:45 PM, Estefania Isabel Mu?oz Salas wrote:
> Hi,
> 
>   My name is Estefan?a; I am doing a master's degree in Marine Ecology. As
> part of the project, we are dealing with shorebird count data, which have
> been taken along the coast of California and northwestern Mexico. The
> surveys are conducted under a standardized monitoring protocol. Sampling
> units have been established at each of the sites, polygons with different
> sizes, which vary from site to site. The birds present in each unit have
> been counted year after year from 2011 to 2019 one time in winter. In
> addition to the above, the count data in this case, given the nature of the
> birds to congregate, make that many units have zeros, and some units have
> abundances of 1000 birds or more, making the data do not approximate to a
> normal distribution. Therefore, to treat these data, we use Generalized
> Linear Mixed Models (GLMM) to contemplate the variability in bird abundance
> from site to site and from the sampling unit to the sampling unit.
> The objective of my work is to know the population trend of three species
> of shorebirds (analyzed separately), and if there is a relationship with
> environmental variables such as average temperature, minimum, and maximum
> temperature, and precipitation; and if there is a difference between
> regions, in this case, were grouped sites in California, those of the Baja
> California peninsula and another region of northwestern Mexico, that we
> called Continental.
> Initially, I tested which distribution family fit the data by testing a
> Poisson, Poisson zero-inflated, and negative binomial and negative binomial
> zero-inflated distribution, which are the most common for count data. The
> distribution that obtained the lowest AIC was the negative binomial
> zero-inflated.
> Knowing that there could be a correlation between the predictor variables,
> I calculated their correlations and for the time we defined that since the
> correlation between the years and the environmental variables was low <.30,
> a single model would be made, in which the year, we also decided that the
> size of each of the sampling units (logarithm of the hectares) would be
> included since it is different in each unit, and we want to take that into
> account. The region would also be considered as a factor with 3 levels.
> Still, the temperature variables did present high correlations, but are the
> variables we are interested in so, this is where I have several doubts
> because my formation is not statistical
> 1.-Should I not include environmental variables in a single model because
> they are correlated,  although they are of interest?
> 2.-If what I am doing is right or not?
> 3.-How do I know if I have made a good fit of the data to the model? How do
> I test it?
> 4.-How do I select the best model?
> 5.-What assumptions should I test?
> 7.- Am I missing something obvious?


   These aren't really GLMM-specific questions.

   Opinions differ about correlations; my personal opinion is that it is 
rarely a good idea to exclude highly correlated predictors from a 
regression (see refs below).

    I would recommend the DHARMa package (and its extensive, 
high-quality vignettes) for assessing issues with the fits.

   I would not recommend selecting a best model with a reduced set of 
predictors - I would use the full model - but AIC is fine.

Dormann, Carsten F., Jane Elith, Sven Bacher, Carsten Buchmann, Gudrun 
Carl, Gabriel Carr?, Jaime R. Garc?a Marqu?z, et al. ?Collinearity: A 
Review of Methods to Deal with It and a Simulation Study Evaluating 
Their Performance.? Ecography, 2012, no-no. 
https://doi.org/10.1111/j.1600-0587.2012.07348.x.

Graham, Michael H. ?Confronting Multicollinearity in Ecological Multiple 
Regression.? Ecology 84, no. 11 (2003): 2809?15. 
https://doi.org/10.1890/02-3114.

Morrissey, Michael B.?; Ruxton, and Graeme D. Ruxton. ?Multiple 
Regression Is Not Multiple Regressions: The Meaning of Multiple 
Regression and the Non-Problem of Collinearity.? Philosophy, Theory, and 
Practice in Biology 10 (2018). 
http://dx.doi.org/10.3998/ptpbio.16039257.0010.003.

Vanhove, Jan. ?Collinearity Isn?t a Disease That Needs Curing.? 
PsyArXiv, May 12, 2020. https://doi.org/10.31234/osf.io/mv2wx.

> 
> All the above I have done with the glmmTMB package in Rstudio.
> Thank you very much and sorry in advance if these are very basic questions.
> 
> The fit I try so far is this:
> m2znb.all<-glmmTMB(total~ logha + YearCollected + Geopolitical + tmp + tmn
> + tmx + pre + (1|Site/Plot), ziformula = ~1, data = mc2, family="nbinom2")
> where:
> total is the abundance of a species of shorebird
> logha the size of the unit (logarithmic of the hectare)
> YearCollected
> Geopolitical is the region
> tmp is the mean temperature
> tmn is the minimum temperature
> tmx is the maximum temperature
> pre is the precipitation
> 
> It would be possible to share the data
> 
> Regards, Estefan?a.
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics


From me @end|ng |rom ph||||p@|d@y@com  Tue Aug  3 00:56:41 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Mon, 2 Aug 2021 17:56:41 -0500
Subject: [R-sig-ME] Data Handling within nlme library
In-Reply-To: <05b901d7873f$c5ac93f0$5105bbd0$@denney.ws>
References: <05b901d7873f$c5ac93f0$5105bbd0$@denney.ws>
Message-ID: <8925eef6-0fba-c593-371e-529e8f785f1e@phillipalday.com>

This is a bug in the way gnls is using environments to call nls() to get
starting values for glns(). You can circumvent this by doing the call to
nls() for starting values directly:

make_model <- function() {
?
? my_soybean <- Soybean
?
? form <- weight ~ SSlogis(Time, Asym, xmid, scal)
?
? gnls(form, data=my_soybean, weights=varPower(),
?????? start=coef(nls(form, my_soybean)))
?
}

Phillip

On 01/08/2021 20:43, bill at denney.ws wrote:
> Hello,
>
>  
>
> I'm having an issue with data handling within the nlme library.
> Specifically, when I fit a gnls model within one function, I cannot update
> that model within another function with new data.  Are there any ways to
> give data within a function and have the model work outside?  An example of
> what I'm trying to do is below in the first example:
>
>  
>
> ``` r
>
> library(nlme)
>
>  
>
> make_model <- function() {
>
>   my_soybean <- Soybean
>
>   gnls(weight ~ SSlogis(Time, Asym, xmid, scal), data=my_soybean, weights =
> varPower())
>
> }
>
>  
>
> my_model <- make_model()
>
> #> Error in stats::nls(formula = weight ~ SSlogis(Time, Asym, xmid, scal), :
> object 'my_soybean' not found
>
> # Issue: my_soybean is in the function environment but not found during
> estimation
>
>  
>
> make_model <- function() {
>
>   time <- Soybean$Time
>
>   weight <- Soybean$weight
>
>   gnls(
>
>     weight ~ Asym/(1+exp((xmid-time)/scal)),
>
>     start=c(Asym=30, xmid=40, scal=10),
>
>     weights = varPower()
>
>   )
>
> }
>
>  
>
> my_model <- make_model()
>
> #> Error in terms.formula(formula, data = data): '.' in formula and no
> 'data' argument
>
> # Issue: No idea where the error is coming from (making a guess that it is
> the weights argument)
>
>  
>
> make_model <- function() {
>
>   time <- Soybean$Time
>
>   weight <- Soybean$weight
>
>   gnls(
>
>     weight ~ Asym/(1+exp((xmid-time)/scal)),
>
>     start=c(Asym=30, xmid=40, scal=10),
>
>   )
>
> }
>
>  
>
> my_model <- make_model()
>
> # Issue: when data are given in the local environment but not with a `data`
>
> # argument, it works.
>
> ```
>
>  
>
> <sup>Created on 2021-08-01 by the [reprex
> package](https://reprex.tidyverse.org) (v2.0.0)</sup>
>
>  
>
> Thanks,
>
>  
>
> Bill
>
>  
>
> P.S.  I'm pretty sure that this is also related to an issue found in the
> nlraa library described at https://github.com/femiguez/nlraa/issues/4
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From me @end|ng |rom ph||||p@|d@y@com  Tue Aug  3 22:34:40 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Tue, 3 Aug 2021 15:34:40 -0500
Subject: [R-sig-ME] Extract correct DF and random variance in GLMM
In-Reply-To: <359713612.4639208.1626274927797@mail.yahoo.com>
References: <359713612.4639208.1626274927797.ref@mail.yahoo.com>
 <359713612.4639208.1626274927797@mail.yahoo.com>
Message-ID: <5341ecaf-7366-9e6e-7a29-e9e6ea04616f@phillipalday.com>

What do you want to use the degrees of freedom for? DF are a bit of a
tricky question in mixed models. In your example, the by-plot random
intercepts actually only introduces *one* parameter into the model (for
the variance of the intercepts between plots) but in some vague sense it
feels like it should count for more than one degree of freedom since
we're able to *predict* (instead of estimate) 9 different intercepts
from this single parameter. So depending on what you're looking at,
somewhere between 1 and 9 seems like the right number, but it's quite
subtle. The GLMM FAQ discusses this a bit at different points, but
perhaps most relevant is the discussion on computing DF for AICc:

https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#can-i-use-aic-for-mixed-models-how-do-i-count-the-number-of-degrees-of-freedom-for-a-random-effect

Note also that the usual "-1" degree of freedom is for the parameter
covering the residual variance, but the Poisson distribution doesn't
have a separate parameter for the variance / dispersion: the variance
is, by definition, equal to the mean. That's why there's "residual
variance" in the model summary.

That said, it sounds like you're looking for a measure like the
intra-class correlation coefficient (ICC). Timothy Lau posted some
functions to handle this a few years ago:

https://stat.ethz.ch/pipermail/r-sig-mixed-models/2016q1/024361.html

It also looks like the `performance` package has an implementation:

https://easystats.github.io/performance/reference/icc.html

Phillip

On 14/07/2021 10:02, Alexandre Santos via R-sig-mixed-models wrote:
> Hi Everyone,
>
> I'm my "scarab" data set, I have the response variable number of species ("Richness"), and my explanatory variables are lead concentration ("PbPPM") in 9 transects ("Plot") with 5 samples by transects. But the 5 samples by transects are pseudoreplication in each variable "Plot". Explained this, I don't have 43 degress of fredom (DF) (9*5= 45 = 1PbPPM - 1 = 43) and I used GLMM for considering this ((1|Plot)). Im my example:
>
> library(lme4)?
> scarab <- read.csv("https://raw.githubusercontent.com/Leprechault/PEN-533/master/scarab.csv")
> str(scarab)
> #'data.frame':? 45 obs. of? 4 variables:
> # $ TrapID? : num? 1 2 3 4 5 6 7 8 9 10 ...
> # $ Richness: num? 11 10 13 11 10 8 9 8 19 17 ...
> # $ PbPPM? ?: num? 0.045 1.036 1.336 0.616 0.684 ...
> # $ Plot? ? : Factor w/ 9 levels "1","2","3","4",..: 1 1 1 1 1 2 2 2 2 2 ...
>
> # GLMM model
> scara.glmer<-glmer(Richness~PbPPM + (1|Plot),data=scarab,family="poisson")
> summary(scara.glmer)
> #Generalized linear mixed model fit by maximum likelihood (Laplace
> #? Approximation) [glmerMod]
> # Family: poisson? ( log )
> # Formula: Richness ~ PbPPM + (1 | Plot)
> # ...
> #Random effects:
> # Groups Name? ? ? ? Variance Std.Dev.
> # Plot? ?(Intercept) 0.2978? ?0.5457??
> #Number of obs: 45, groups:? Plot, 9
> #Fixed effects:
> #? ? ? ? ? ? Estimate Std. Error z value Pr(>|z|)? ??
> #(Intercept)? ?1.9982? ? ?0.2105? ?9.495? < 2e-16 ***
> #PbPPM? ? ? ? -0.5625? ? ?0.1198? -4.695 2.66e-06 ***
> #---
> #Signif. codes:? 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
> #Correlation of Fixed Effects:
> ? ? ? (Intr)
> #PbPPM -0.368
>
> Based on this analysis, I have two questions:
>
> 1) There is no way to find the number of degrees of freedom corrected in the output because, for me is not clear in "Number of obs: 45, groups:? Plot, 9".
>
> 2) I'd like to calculate the contribution in the variance of the variable "Plot" because, in lmer models, I have Variance of the Variable/Residual variance + Variance of the Variable. Still, in the glmer I don't have the residual variance.
>
> Thanks in advance,
>
> Alexandre
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From me @end|ng |rom ph||||p@|d@y@com  Tue Aug  3 22:39:27 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Tue, 3 Aug 2021 15:39:27 -0500
Subject: [R-sig-ME] Theta Value in glmer
In-Reply-To: <1626502920034.31487@radboudumc.nl>
References: <1626502920034.31487@radboudumc.nl>
Message-ID: <574bc5c6-349a-da1d-fcff-cc956a7c84bb@phillipalday.com>

Hi Amir,

can you share an anonymized version of your data? Or give a bit more of
a minimal working example (MWE)? Then we can probably provide more and
better help. :)

Best,
Phillip

On 17/07/2021 01:22, Amirhossein.AmirhosseinTalebi at radboudumc.nl wrote:
> Dear all,
>
> I am trying to fit a negative binomial regression using lme4 package. After several attempts using glmer.nb and having error of convergence, I have switched to glmer function to could set the argument nAGQ=0 and used negative binomial function as the family argument.
> The question here is, as the theta value in negative binomial function I tried to use the theta value that glm.nb of package MASS gave me (157); but based on the vignette of glmer I can use theta=1.75. Could you please clarify that how can I choose the best theta value here and until what extend that can change my results? Or based on what parameter in model output I can understand that I used the best theta value?
>
> Kind regards,
> Amir
>
> De informatie in dit bericht is uitsluitend bestemd voor de geadresseerde. Aan dit bericht en de bijlagen kunnen geen rechten worden ontleend. Heeft u deze e-mail onbedoeld ontvangen? Dan verzoeken wij u het te vernietigen en de afzender te informeren. Openbaar maken, kopi?ren en verspreiden van deze e-mail of informatie uit deze e-mail is alleen toegestaan met voorafgaande schriftelijke toestemming van de afzender. Het Radboudumc staat geregistreerd bij de Kamer van Koophandel in het handelsregister onder nummer 80262783.
>
> The content of this message is intended solely for the addressee. No rights can be derived from this message or its attachments. If you are not the intended recipient, we kindly request you to delete the message and inform the sender. It is strictly prohibited to disclose, copy or distribute this email or the information inside it, without a written consent from the sender. Radboud university medical center is registered with the Dutch Chamber of Commerce trade register with number 80262783.
>
> 	[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From me @end|ng |rom ph||||p@|d@y@com  Tue Aug  3 23:19:07 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Tue, 3 Aug 2021 16:19:07 -0500
Subject: [R-sig-ME] 
 Modelling with uncertain (but not missing) categorical
 random effect values
In-Reply-To: <CAJuCY5xD_4QNNhbKMOjsJ2uQETWyHzaBznkUxg65_+QV-5Vw9A@mail.gmail.com>
References: <CACtWw1HWv6ph0vwt4TLpUxiojZ_3993Kop0bvfXe=3yt2Lu9JA@mail.gmail.com>
 <CAJuCY5xD_4QNNhbKMOjsJ2uQETWyHzaBznkUxg65_+QV-5Vw9A@mail.gmail.com>
Message-ID: <47d07adf-6db0-e441-6e86-29d896c12ad1@phillipalday.com>

If I'm not mistaken, Thierry's suggestion is a particular case of
multi-membership models, which you can also do in brms. See e.g.:


https://rdrr.io/cran/brms/man/mm.html

https://github.com/paul-buerkner/brms/issues/130

https://discourse.mc-stan.org/t/cross-classified-multiple-membership-models-with-brms/8691


On 13/07/2021 06:09, Thierry Onkelinx via R-sig-mixed-models wrote:
> Dear Michael,
>
> Maybe something like (0 + w_1 | dad_1) + (0 + w_2 | dad_2) + (0 + w_3 |
> dad_3). Where w_1 is the probability of dad_1.
>
> Make sure that dad_1, dad_2 and dad_3 are factors with the same levels.
> Then INLA allows you to add this as f(dad_1, w_1, model = "iid") + f(dad_2,
> w_2, copy = "dad_"1) + f(dad_3, w_3, copy = "dad_1"). So you end up with a
> single random intercept for every dad (dad_2 and dad_3 share their
> estimates with dad_1).
>
> mum_id  mum_sp  dad_sp dad_id                    con    dad_1   w_1 dad_2
> w_ 2 dad_3 w_3
>
> Af1          A              A           Am1 / Am2             1      Am1
> 0.6   Am2 0.4  NA 0
> Af1          A              A           Am2                       1
> Am2    1     NA     0     NA 0
> Bf1          B             A           Am1 / Am2 / Am4   0      Am1    0.4
>  Am2 0.3   Am4 0.3
> Bf2          B              B          Bm1 / Bm3              1      Bm1
> 0.5   Bm2  0.5  NA 0
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op di 13 jul. 2021 om 12:30 schreef Michael Lawson via R-sig-mixed-models <
> r-sig-mixed-models at r-project.org>:
>
>> I have a dataset where I have offspring paternity of females with
>> males of different species. However, many of the offspring have
>> ambiguous paternity - where I know the offspring must be from
>> particular fathers, but not from others. The data currently looks a
>> bit like this (but with many more rows per mum_id):
>>
>> mum_id  mum_sp  dad_sp dad_id                    con
>>
>> Af1          A              A           Am1 / Am2             1
>> Af1          A              A           Am2                       1
>> Bf1          B             A           Am1 / Am2 / Am4   0
>> Bf2          B              B          Bm1 / Bm3              1
>>
>> Which I have so far run as a binomial GLMM with con (conspecific mating) as
>> a binary response, mum_sp and dad_sp (species) as fixed factors and
>> mum_id as a random factor - and have just not included dad_id as
>> a random factor. The ambiguously assigned fathers in dad_id is also
>> non-random, i.e.
>> certain individuals are more likely to be ambiguously assigned than
>> others, so just leaving these cases as NA is problematic.
>>
>> For some of the ambiguous assignments, I can also extract
>> probabilities that a possible male is the father of the offspring,
>> e.g. for the first row, father Am1 is 60% likely to be the father and
>> Am2 40% likely.
>>
>> Are there any approaches where I can include the ambiguous dad_id in
>> a GLMM framework? - where the uncertainty of the assignment contributes to
>> the
>> overall uncertainty in the tested relationship.
>>
>> Thank you for any suggestions,
>> Mike
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbo|ker @end|ng |rom gm@||@com  Wed Aug  4 00:15:43 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 3 Aug 2021 18:15:43 -0400
Subject: [R-sig-ME] 
 Modelling with uncertain (but not missing) categorical
 random effect values
In-Reply-To: <47d07adf-6db0-e441-6e86-29d896c12ad1@phillipalday.com>
References: <CACtWw1HWv6ph0vwt4TLpUxiojZ_3993Kop0bvfXe=3yt2Lu9JA@mail.gmail.com>
 <CAJuCY5xD_4QNNhbKMOjsJ2uQETWyHzaBznkUxg65_+QV-5Vw9A@mail.gmail.com>
 <47d07adf-6db0-e441-6e86-29d896c12ad1@phillipalday.com>
Message-ID: <b15a5261-9d37-9283-0f61-3c776cb1f929@gmail.com>

   Also see 
https://bbolker.github.io/mixedmodels-misc/notes/multimember.html (i.e. 
you can do it in lme4, but it takes a bit of hacking)

On 8/3/21 5:19 PM, Phillip Alday wrote:
> If I'm not mistaken, Thierry's suggestion is a particular case of
> multi-membership models, which you can also do in brms. See e.g.:
> 
> 
> https://rdrr.io/cran/brms/man/mm.html
> 
> https://github.com/paul-buerkner/brms/issues/130
> 
> https://discourse.mc-stan.org/t/cross-classified-multiple-membership-models-with-brms/8691
> 
> 
> On 13/07/2021 06:09, Thierry Onkelinx via R-sig-mixed-models wrote:
>> Dear Michael,
>>
>> Maybe something like (0 + w_1 | dad_1) + (0 + w_2 | dad_2) + (0 + w_3 |
>> dad_3). Where w_1 is the probability of dad_1.
>>
>> Make sure that dad_1, dad_2 and dad_3 are factors with the same levels.
>> Then INLA allows you to add this as f(dad_1, w_1, model = "iid") + f(dad_2,
>> w_2, copy = "dad_"1) + f(dad_3, w_3, copy = "dad_1"). So you end up with a
>> single random intercept for every dad (dad_2 and dad_3 share their
>> estimates with dad_1).
>>
>> mum_id  mum_sp  dad_sp dad_id                    con    dad_1   w_1 dad_2
>> w_ 2 dad_3 w_3
>>
>> Af1          A              A           Am1 / Am2             1      Am1
>> 0.6   Am2 0.4  NA 0
>> Af1          A              A           Am2                       1
>> Am2    1     NA     0     NA 0
>> Bf1          B             A           Am1 / Am2 / Am4   0      Am1    0.4
>>   Am2 0.3   Am4 0.3
>> Bf2          B              B          Bm1 / Bm3              1      Bm1
>> 0.5   Bm2  0.5  NA 0
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
>> FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88 bus 73, 1000 Brussel
>> www.inbo.be
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>
>> <https://www.inbo.be>
>>
>>
>> Op di 13 jul. 2021 om 12:30 schreef Michael Lawson via R-sig-mixed-models <
>> r-sig-mixed-models at r-project.org>:
>>
>>> I have a dataset where I have offspring paternity of females with
>>> males of different species. However, many of the offspring have
>>> ambiguous paternity - where I know the offspring must be from
>>> particular fathers, but not from others. The data currently looks a
>>> bit like this (but with many more rows per mum_id):
>>>
>>> mum_id  mum_sp  dad_sp dad_id                    con
>>>
>>> Af1          A              A           Am1 / Am2             1
>>> Af1          A              A           Am2                       1
>>> Bf1          B             A           Am1 / Am2 / Am4   0
>>> Bf2          B              B          Bm1 / Bm3              1
>>>
>>> Which I have so far run as a binomial GLMM with con (conspecific mating) as
>>> a binary response, mum_sp and dad_sp (species) as fixed factors and
>>> mum_id as a random factor - and have just not included dad_id as
>>> a random factor. The ambiguously assigned fathers in dad_id is also
>>> non-random, i.e.
>>> certain individuals are more likely to be ambiguously assigned than
>>> others, so just leaving these cases as NA is problematic.
>>>
>>> For some of the ambiguous assignments, I can also extract
>>> probabilities that a possible male is the father of the offspring,
>>> e.g. for the first row, father Am1 is 60% likely to be the father and
>>> Am2 40% likely.
>>>
>>> Are there any approaches where I can include the ambiguous dad_id in
>>> a GLMM framework? - where the uncertainty of the assignment contributes to
>>> the
>>> overall uncertainty in the tested relationship.
>>>
>>> Thank you for any suggestions,
>>> Mike
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics


From bbo|ker @end|ng |rom gm@||@com  Wed Aug  4 00:23:20 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 3 Aug 2021 18:23:20 -0400
Subject: [R-sig-ME] Theta Value in glmer
In-Reply-To: <574bc5c6-349a-da1d-fcff-cc956a7c84bb@phillipalday.com>
References: <1626502920034.31487@radboudumc.nl>
 <574bc5c6-349a-da1d-fcff-cc956a7c84bb@phillipalday.com>
Message-ID: <cc456f6e-32b1-6a0a-dc98-91e9423fd11a@gmail.com>

    I also don't really know what's going on here.

Some thoughts:

    * for NB fits, glmmTMB, which is a bit faster & more stable than 
glmer for this special case (and is pretty nearly a drop-in replacement 
for glmer.nb)
    * A common case of convergence problems for NB models is when you 
try to fit data that are equi-dispersed or underdispersed (conditional 
variance <= mean rather than >mean), in which case the theta coefficient 
gets very large (and the likelihood surface gets very flat).  In this 
case you're better of with a Poisson model anyway ...
    * Not sure what you mean by "the vignette of glmer" - there isn't 
any vignette describing glmer in the lme4 package AFAIK ...

On 8/3/21 4:39 PM, Phillip Alday wrote:
> Hi Amir,
> 
> can you share an anonymized version of your data? Or give a bit more of
> a minimal working example (MWE)? Then we can probably provide more and
> better help. :)
> 
> Best,
> Phillip
> 
> On 17/07/2021 01:22, Amirhossein.AmirhosseinTalebi at radboudumc.nl wrote:
>> Dear all,
>>
>> I am trying to fit a negative binomial regression using lme4 package. After several attempts using glmer.nb and having error of convergence, I have switched to glmer function to could set the argument nAGQ=0 and used negative binomial function as the family argument.
>> The question here is, as the theta value in negative binomial function I tried to use the theta value that glm.nb of package MASS gave me (157); but based on the vignette of glmer I can use theta=1.75. Could you please clarify that how can I choose the best theta value here and until what extend that can change my results? Or based on what parameter in model output I can understand that I used the best theta value?
>>
>> Kind regards,
>> Amir
>>
>> De informatie in dit bericht is uitsluitend bestemd voor de geadresseerde. Aan dit bericht en de bijlagen kunnen geen rechten worden ontleend. Heeft u deze e-mail onbedoeld ontvangen? Dan verzoeken wij u het te vernietigen en de afzender te informeren. Openbaar maken, kopi?ren en verspreiden van deze e-mail of informatie uit deze e-mail is alleen toegestaan met voorafgaande schriftelijke toestemming van de afzender. Het Radboudumc staat geregistreerd bij de Kamer van Koophandel in het handelsregister onder nummer 80262783.
>>
>> The content of this message is intended solely for the addressee. No rights can be derived from this message or its attachments. If you are not the intended recipient, we kindly request you to delete the message and inform the sender. It is strictly prohibited to disclose, copy or distribute this email or the information inside it, without a written consent from the sender. Radboud university medical center is registered with the Dutch Chamber of Commerce trade register with number 80262783.
>>
>> 	[[alternative HTML version deleted]]
>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics


From d@n|e|_rub| @end|ng |rom ym@||@com  Fri Aug  6 01:31:09 2021
From: d@n|e|_rub| @end|ng |rom ym@||@com (Daniel Rubi)
Date: Thu, 5 Aug 2021 23:31:09 +0000 (UTC)
Subject: [R-sig-ME] A model for paired data (treatment vs. control on the
 same subject) nested within time points
References: <1285410600.1843115.1628206269675.ref@mail.yahoo.com>
Message-ID: <1285410600.1843115.1628206269675@mail.yahoo.com>


0
I have an experimental design where I took the left and right brain hemispheres from mice across several time points (hence its cross-sectional) following treatment at time 0 to the left brain hemisphere only. Therefore the right hemisphere serves as a paired control for the left hemisphere at each of the time points. Here's the samples?data.frame:
library(dplyr)
df <- data.frame(animal_id = c("id1","id1","id2","id2","id3","id3","id4","id4","id5","id5","id6","id6","id7","id7","id8","id8","id9","id9","id10","id10","id11","id11","id12","id12","id13","id13","id14","id14","id15","id15","id16","id16","id17","id17","id18","id18","id19","id19","id20","id20","id21","id21","id22","id22","id23","id23","id24","id24","id25","id25","id26","id26","id27","id27","id28","id28","id29","id29","id30","id30"),
                  time_point = c(0,0,0,0,2,2,2,2,2,2,3,3,3,3,3,3,6,6,6,6,6,6,9,9,9,9,14,14,14,14,14,14,14,14,26,26,26,26,26,26,26,26,50,50,50,50,50,50,50,50,74,74,170,170,170,170,170,170,170,170),
                  hemisphere = c("L","R","L","R","L","R","L","R","L","R","L","R","L","R","L","R","L","R","L","R","L","R","L","R","L","R","L","R","L","R","L","R","L","R","L","R","L","R","L","R","L","R","L","R","L","R","L","R","L","R","L","R","L","R","L","R","L","R","L","R"),
                  cov1 = c(99,99,98,98,42.2,42.2,47.6,47.6,38.7,38.7,73.5,73.5,40.6,40.6,37.4,37.4,29.9,29.9,35.1,35.1,38.9,38.9,33.5,33.5,37.9,37.9,38,38,37.3,37.3,45.2,45.2,40.4,40.4,40.3,40.3,39.6,39.6,38.3,38.3,38.9,38.9,37.7,37.7,41.1,41.1,42.8,42.8,37.5,37.5,41.1,41.1,40.8,40.8,42.8,42.8,39,39,40.9,40.9),
                  cov2 = c(28,28,27.3,27.3,28.2,28.2,28.1,28.1,25.6,25.6,30,30,30.1,30.1,30.3,30.3,30.2,30.2,28.3,28.3,31.6,31.6,28.9,28.9,31.5,31.5,26.4,26.4,26.1,26.1,27.5,27.5,26.4,26.4,23.6,23.6,26.5,26.5,25,25,22.1,22.1,27.8,27.8,23.2,23.2,23.2,23.2,21.1,21.1,25.9,25.9,25.7,25.7,25.4,25.4,26.7,26.7,19,19),
                  stringsAsFactors = F) %>%
  dplyr::mutate(sample_id = paste0(animal_id,"_",hemisphere,"_",time_point))

As you can see I have 30 animals where for each I have both hemispheres at each time point, however the number of animals at each time point varies between 1 to 4.

The values that I measured are gene expression levels (which are positive integers).

For example, this simulated matrix has such counts for 10000 genes for each of the 60 samples.

What I'm interested in is how the difference in gene expression levels between the left and right hemispheres changes at each time point relative to the first time point, while controlling for the covariates (cov1?and?cov2). For this reason I convert?time_point?to a?factor, as well as?animal_id?and?hemisphere?(setting hemisphere?R?as baseline):
df$time_point <- factor(df$time_point)
df$animal_id <- factor(df$animal_id)
df$hemisphere <- factor(df$hemisphere, levels = c("R","L"))

What would be the right?lm?or?glm?model for my question and data?

Seems like?animal_id?is nested within?time_point?so perhaps:

gene_expression ~ cov1 + cov2 + hemisphere + (time_point/animal_id)??








	[[alternative HTML version deleted]]


From mudryjm @end|ng |rom b|uew|n@ch  Sun Aug  8 11:17:58 2021
From: mudryjm @end|ng |rom b|uew|n@ch (mudryjm)
Date: Sun, 8 Aug 2021 11:17:58 +0200
Subject: [R-sig-ME] FW: Variogram / confint prediction in LMM / time
 prediction some questions from Switerland area
In-Reply-To: <CAO7JsnSYFTA9hTcN7B-6bY82T1+nRcdg9YYHykH0Lgq9MicRig@mail.gmail.com>
References: <30015_1627827956_0QX6009OT034UF10_03aa01d786e1$16bb82b0$44328810$@bluewin.ch>
 <CAO7JsnSYFTA9hTcN7B-6bY82T1+nRcdg9YYHykH0Lgq9MicRig@mail.gmail.com>
Message-ID: <020301d78c36$482f9700$d88ec500$@bluewin.ch>

 


Sent: Sunday, August 1, 2021 5:32 PM
To: mudryjm <mudryjm at bluewin.ch>
Subject: Re: Variogram / confint prediction in LMM / time prediction some questions from Switerland area

 

I regret that I am not able to answer your questions at this time.  It has been a couple of decades since I worked on the nlme package and I have not kept up with the literature.

 

I suggest that you send your questions to the R-SIG-Mixed-Models at R-project.org <mailto:R-SIG-Mixed-Models at R-project.org>  mailing list.  Some information about the list is available at https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

 

On Sun, Aug 1, 2021 at 9:25 AM mudryjm <mudryjm at bluewin.ch <mailto:mudryjm at bluewin.ch> > wrote:

Dear Mr Bates and Pinhero

Tks for your incredible packages in R I did my master in statistics (attached). I?m a big fan!

However I?m puzzled with several theoretical questions on some topic where I?m struggling; instead of luring for stat input I asks directly WIZARDS!:


Variograms (Cressie):P 52 PDF

I have done several variograms on my model residuals expecting flat line along (sill flat).However some patient are at sill some on the correlation path-slope.

Q:How to interpret? (Two class of patient with biophysical discerpancies?

Q:The smoother fitted in graph is the theoretical one (Theoretical variogram based on exp?spherical?)?? Or is it a simple smoother.

Q: Is it possible with variogram (within (patient and sampling error) cor + between from LMM variance) to forecast the best time for re-measure?
I.e in cholesterol study some authors demonstrated when intra- variability exceed between variability? So measuring on too short intervals has no value.But I don?t know how to proceed

Or do you had a good reference.?

 

Fiiting confindance bands on XB+ZU:

 

Q.I try to get con band for predictings patients trajectories. As they is no close form (at least very complex) is the better way to bootstrap some model and fit a bootstrap confint on the 1000 Fitted values? Or do you have a smplier function?

 

Q:If I should predict when time  will be  reached for a patient his Upper reference limit how do I have to proceed? (back reversing formula?)
Page 54 :patients prediction

Tks for your help in an old retrained statistician

 

NB Your contribution to staworld is fabulous and inspired me in my daily work since  a year!

:)

 

Veuillez recevoir mes sinc?res salutations , 

Sincerely,

 

Mudry Jean-Marie

8 ch du Ch?no

1802 CORSEAUX 

Switzerland

 

+41.79.708.87.15

+41.21.921.10.18.

 

 <https://www.linkedin.com/profile/view?id=AAIAAAQNN6kBw4M_5pbYY8UTDonpSQEhwi-7DHs&trk=nav_responsive_tab_profile_pic> LinkedIn  <https://twitter.com/mudryjm> Twitter  <https://twitter.com/mudryjm/status/750591764080291840> Last Publication

 


	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Sun Aug  8 21:11:30 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sun, 8 Aug 2021 15:11:30 -0400
Subject: [R-sig-ME] FW: Variogram / confint prediction in LMM / time
 prediction some questions from Switerland area
In-Reply-To: <020301d78c36$482f9700$d88ec500$@bluewin.ch>
References: <30015_1627827956_0QX6009OT034UF10_03aa01d786e1$16bb82b0$44328810$@bluewin.ch>
 <CAO7JsnSYFTA9hTcN7B-6bY82T1+nRcdg9YYHykH0Lgq9MicRig@mail.gmail.com>
 <020301d78c36$482f9700$d88ec500$@bluewin.ch>
Message-ID: <de1b984a-5068-5665-2e48-9c331524698d@gmail.com>



On 8/8/21 5:17 AM, mudryjm wrote:
>   
> 
> 
> Sent: Sunday, August 1, 2021 5:32 PM
> To: mudryjm <mudryjm at bluewin.ch>
> Subject: Re: Variogram / confint prediction in LMM / time prediction some questions from Switerland area
> 
>   
> 
> I regret that I am not able to answer your questions at this time.  It has been a couple of decades since I worked on the nlme package and I have not kept up with the literature.
> 
>   
> 
> I suggest that you send your questions to the R-SIG-Mixed-Models at R-project.org <mailto:R-SIG-Mixed-Models at R-project.org>  mailing list.  Some information about the list is available at https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
>   
> 
> On Sun, Aug 1, 2021 at 9:25 AM mudryjm <mudryjm at bluewin.ch <mailto:mudryjm at bluewin.ch> > wrote:
> 
> Dear Mr Bates and Pinhero
> 
> Tks for your incredible packages in R I did my master in statistics (attached). I?m a big fan!
> 
> However I?m puzzled with several theoretical questions on some topic where I?m struggling; instead of luring for stat input I asks directly WIZARDS!:
> 
> 
> Variograms (Cressie):P 52 PDF
> 
> I have done several variograms on my model residuals expecting flat line along (sill flat).However some patient are at sill some on the correlation path-slope.

   I'm not really sure what this means.  One very common issue is that 
if you simply specify residuals(fitted_model), you get "raw" 
(observed-fitted) residuals; if you want residuals that take the 
autocorrelation structure of the model into account, you need to specify 
type="normalized" (see ?nlme::residuals.lme)
> 
> Q:How to interpret? (Two class of patient with biophysical discerpancies?

   Hard to say without more detail.

> 
> Q:The smoother fitted in graph is the theoretical one (Theoretical variogram based on exp?spherical?)?? Or is it a simple smoother.

   Not sure what you're referring to.  Perhaps some attached images got 
lost (the mailing list strips some attachment types).

> 
> Q: Is it possible with variogram (within (patient and sampling error) cor + between from LMM variance) to forecast the best time for re-measure? > I.e in cholesterol study some authors demonstrated when intra- 
variability exceed between variability? So measuring on too short 
intervals has no value.But I don?t know how to proceed

   This doesn't seem to have an obvious answer, but measurements taken 
with a time interval large enough that the estimated autocorrelation 
would be small would provide more information (e.g. if the 
autocorrelation model gives you a scale parameter, autocorrelation 
levels would typically drop to 'small' levels at a time difference of 
2*scale or 3*scale - but exactly how far it would drop depends on the 
particular autocorrelation model used, and the 'best' time for 
remeasurement would depend on a whole lot of details of the particular 
study system; how expensive or inconvenient is it to take additional 
samples? An autocorrelated sample doesn't provide *no* information, it 
just provides less information than one taken at a (typically) longer 
time interval.

> 
> Or do you had a good reference.?
> 
>   
> 
> Fiiting confindance bands on XB+ZU:
> 
>   
> 
> Q.I try to get con band for predictings patients trajectories. As they is no close form (at least very complex) is the better way to bootstrap some model and fit a bootstrap confint on the 1000 Fitted values? Or do you have a smplier function?
> 

    Bootstrapping seems like a good approach.
    Since your data are autocorrelated, you might need block 
bootstrapping (or, if you trust the model reasonably well, parametric 
bootstrapping)

> 
> Q:If I should predict when time  will be  reached for a patient his Upper reference limit how do I have to proceed? (back reversing formula?)
> Page 54 :patients prediction
> 
> Tks for your help in an old retrained statistician


  Yes, you probably need to invert the formula.  You might end up 
needing to solve numerically (?uniroot)

>   
> 
> NB Your contribution to staworld is fabulous and inspired me in my daily work since  a year!
> 
> :)
> 
>   
> 
> Veuillez recevoir mes sinc?res salutations ,
> 
> Sincerely,
> 
>   
> 
> Mudry Jean-Marie
> 
> 8 ch du Ch?no
> 
> 1802 CORSEAUX
> 
> Switzerland
> 
>   
> 
> +41.79.708.87.15
> 
> +41.21.921.10.18.
> 
>   
> 
>   <https://www.linkedin.com/profile/view?id=AAIAAAQNN6kBw4M_5pbYY8UTDonpSQEhwi-7DHs&trk=nav_responsive_tab_profile_pic> LinkedIn  <https://twitter.com/mudryjm> Twitter  <https://twitter.com/mudryjm/status/750591764080291840> Last Publication
> 
>   
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics


From @|ngm@nn @end|ng |rom gm@||@com  Tue Aug 10 07:26:35 2021
From: @|ngm@nn @end|ng |rom gm@||@com (Henrik Singmann)
Date: Tue, 10 Aug 2021 07:26:35 +0200
Subject: [R-sig-ME] Fwd: How to obtain monotonic effect of ordered factor
 predictor in lme4 package
In-Reply-To: <d5ee9e0f-f4ea-c568-feab-7964a4165518@gmail.com>
References: <CAAnFKoQWegVmy2TicfDmdqyoj=cx9sDZruiv9EiLt4aUQWxp9Q@mail.gmail.com>
 <CA+rDMKJfn0i231ateMkcU1-Y2m=AT14qShD3ScpKCARR9jMRrw@mail.gmail.com>
 <d5ee9e0f-f4ea-c568-feab-7964a4165518@gmail.com>
Message-ID: <CA+rDMKK1=xDcVJJZyVz3kVyaucgaGHWgFR+E9CKuo_18vRzyCw@mail.gmail.com>

Hi Crist?bal,

It looks like you did not get Ben's email (which only went to the list)
which I attach again below. It clarifies that monotonic effects in the way
implemented in brms are not possible in lme4 but in glmmTMB.

Cheers,
Henrik

---------- Forwarded message ---------
Von: Ben Bolker <bbolker at gmail.com>
Date: Fr., 30. Juli 2021 um 22:15 Uhr
Subject: Re: [R-sig-ME] How to obtain monotonic effect of ordered factor
predictor in lme4 package
To: <r-sig-mixed-models at r-project.org>


  A few more thoughts

codingMatrices::code_diff() and MASS::contr.sdif() are basically
identical (in case you don't feel like installing another package --
MASS is automatically installed with base R)

Not quite sure why you're using code_diff_forward rather than code_diff?
The latter would naively make more sense to me.

   You can't constrain fixed-effect parameters in lme4::lmer (they are
profiled out of the likelihood function, so they're not accessible to be
constrained), but in glmmTMB you could do this:

data("sleepstudy", package= "lme4")
ss <- within(sleepstudy, {
     Days <- factor(Days)
     contrasts(Days) <- MASS::contr.sdif
})
library(glmmTMB)
m1 <- glmmTMB(Reaction ~ Days + (1 | Subject), data = ss)
m2 <- update(m1,
              control = glmmTMBControl(
            optArgs = list(lower=c(-Inf, rep(0,9), rep(-Inf, 2)))))


   Notes: (1) the constraints aren't binding in this example because all
the parameters are estimated as being positive anyway (I was too lazy to
find another example/perturb this example); (2) you do need to know the
parameter ordering for this to work: in this case we have the intercept
(unconstrained) followed by 9 successive difference values, followed by
parameters for the RE variance and the dispersion (estimated on the log
scale, unconstrained).  The combination of fixef(m2) and m2$obj$par can
help you figure this out.


On 7/30/21 8:14 AM, Henrik Singmann wrote:
> Hi Crist?bal,
>
> As far as I know, there is no correspondence in lme4 to the monotonic
> effects as there is no way to enforce certain fixed effect estimate are
> strictly positive or negative.
>
> However, if the data is strictly ordered, you can get something similar by
> using appropriate coding. So instead of using an ordered factor you use a
> regular factor and code_diff_forward() from package codingMatrices.
>
> library("lme4")
> library("codingMatrices")
> sleepstudy$Days <- factor(sleepstudy$Days)
> m2 <- lmer(Reaction ~ Days + (1 | Subject), data = sleepstudy,
>             contrasts = list(Days = "code_diff_forward"))
> summary(m2)
> #> Linear mixed model fit by REML ['lmerMod']
> #> Formula: Reaction ~ Days + (1 | Subject)
> #>    Data: sleepstudy
> #>
> #> REML criterion at convergence: 1729.5
> #>
> #> Scaled residuals:
> #>     Min      1Q  Median      3Q     Max
> #> -3.3473 -0.5293  0.0317  0.5328  4.2570
> #>
> #> Random effects:
> #>  Groups   Name        Variance Std.Dev.
> #>  Subject  (Intercept) 1375.5   37.09
> #>  Residual              987.6   31.43
> #> Number of obs: 180, groups:  Subject, 18
> #>
> #> Fixed effects:
> #>             Estimate Std. Error t value
> #> (Intercept) 298.5079     9.0499  32.985
> #> Days0-1      -7.8439    10.4753  -0.749
> #> Days1-2      -0.8661    10.4753  -0.083
> #> Days2-3     -17.6301    10.4753  -1.683
> #> Days3-4      -5.6574    10.4753  -0.540
> #> Days4-5     -19.8690    10.4753  -1.897
> #> Days5-6      -3.6598    10.4753  -0.349
> #> Days6-7      -6.5723    10.4753  -0.627
> #> Days7-8     -17.8789    10.4753  -1.707
> #> Days8-9     -14.2217    10.4753  -1.358
> #> [...]
>
> This give you the differences between each two days as shown next:
> library("tidyverse")
> sleepstudy %>%
>    group_by(Days) %>%
>    summarise(mean = mean(Reaction)) %>%
>    mutate(meanlag = lag(mean)) %>%
>    mutate(diff = meanlag-mean)
> #> # A tibble: 10 x 4
> #>    Days   mean meanlag    diff
> #>    <fct> <dbl>   <dbl>   <dbl>
> #>  1 0      257.     NA   NA
> #>  2 1      264.    257.  -7.84
> #>  3 2      265.    264.  -0.866
> #>  4 3      283.    265. -17.6
> #>  5 4      289.    283.  -5.66
> #>  6 5      309.    289. -19.9
> #>  7 6      312.    309.  -3.66
> #>  8 7      319.    312.  -6.57
> #>  9 8      337.    319. -17.9
> #> 10 9      351.    337. -14.2
>
> There is also the possibility to get exactly the same results by just
using
> emmeans on the model fitted with default contrasts:
> library("lme4")
> sleepstudy$Days <- factor(sleepstudy$Days)
>
> m2 <- lmer(Reaction ~ Days + (1 | Subject), data = sleepstudy)
> library("emmeans")
> emmeans(m2, "Days", contr = "consec")
> #> $emmeans
> #>  Days emmean   SE df lower.CL upper.CL
> #>  0       257 11.5 42      234      280
> #>  1       264 11.5 42      241      288
> #>  2       265 11.5 42      242      288
> #>  3       283 11.5 42      260      306
> #>  4       289 11.5 42      266      312
> #>  5       309 11.5 42      285      332
> #>  6       312 11.5 42      289      335
> #>  7       319 11.5 42      296      342
> #>  8       337 11.5 42      314      360
> #>  9       351 11.5 42      328      374
> #>
> #> Degrees-of-freedom method: kenward-roger
> #> Confidence level used: 0.95
> #>
> #> $contrasts
> #>  contrast estimate   SE  df t.ratio p.value
> #>  1 - 0       7.844 10.5 153   0.749  0.9887
> #>  2 - 1       0.866 10.5 153   0.083  1.0000
> #>  3 - 2      17.630 10.5 153   1.683  0.5279
> #>  4 - 3       5.657 10.5 153   0.540  0.9988
> #>  5 - 4      19.869 10.5 153   1.897  0.3775
> #>  6 - 5       3.660 10.5 153   0.349  1.0000
> #>  7 - 6       6.572 10.5 153   0.627  0.9965
> #>  8 - 7      17.879 10.5 153   1.707  0.5098
> #>  9 - 8      14.222 10.5 153   1.358  0.7629
> #>
> #> Degrees-of-freedom method: kenward-roger
> #> P value adjustment: mvt method for 9 tests
>
>   Of course, all of this only works if the means are ordered in this way
> (otherwise you will have effects that differ in sign).
>
> Hope that helps,
> Henrik
>
>
>
> Am Di., 27. Juli 2021 um 19:06 Uhr schrieb Cristobal Moya <
> cristobalmoya at gmail.com>:
>
>> Dear list members,
>>
>> I have a question regarding monotonic effects with lme4. I also posted
this
>> in StackOverflow (https://stackoverflow.com/q/68546489/6832021), which is
>> what I reproduce below.
>>
>> I want to obtain a monotonic effect for an ordinal predictor with the
>> function `lmer()` from the package lme4. My reference is the estimate
that
>> can be obtained with `mo()` in the brms package.
>>
>> Below a reprex with the desired estimate (leaving aside the different
>> statistical approach behind both packages) in `m1`, and what happens by
>> default (`m2`) when an ordered factor is used in `lmer()`
>>
>> library(brms)
>> library(lme4)
>> sleepstudy$Days <- factor(sleepstudy$Days, ordered = T)
>> m1 <- brm(Reaction ~ mo(Days) + (1 | Subject), data = sleepstudy, chains
=
>> 2)
>> #> Compiling Stan program...
>> ...
>> summary(m1)
>> #>  Family: gaussian
>> #>   Links: mu = identity; sigma = identity
>> #> Formula: Reaction ~ mo(Days) + (1 | Subject)
>> #>    Data: sleepstudy (Number of observations: 180)
>> #> Samples: 2 chains, each with iter = 2000; warmup = 1000; thin = 1;
>> #>          total post-warmup samples = 2000
>> #>
>> #> Group-Level Effects:
>> #> ~Subject (Number of levels: 18)
>> #>               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
>> Tail_ESS
>> #> sd(Intercept)    39.73      7.85    27.73    58.76 1.01      538
>> 751
>> #>
>> #> Population-Level Effects:
>> #>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
>> #> Intercept   257.11     10.87   235.14   277.72 1.00      468      774
>> #> moDays       10.12      1.01     8.16    12.09 1.00     1603     1315
>> #>
>> #> Simplex Parameters:
>> #>            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
>> #> moDays1[1]     0.07      0.06     0.00     0.20 1.00     1343      747
>> #> moDays1[2]     0.07      0.05     0.00     0.20 1.00     1275      524
>> #> moDays1[3]     0.13      0.07     0.01     0.29 1.00     1337      591
>> #> moDays1[4]     0.10      0.07     0.00     0.28 1.00     1600      850
>> #> moDays1[5]     0.16      0.09     0.01     0.34 1.00     1285      658
>> #> moDays1[6]     0.09      0.06     0.00     0.24 1.00     1543      840
>> #> moDays1[7]     0.09      0.07     0.00     0.25 1.00     1534      992
>> #> moDays1[8]     0.16      0.08     0.02     0.32 1.00     1897      906
>> #> moDays1[9]     0.13      0.08     0.01     0.31 1.00     1839      936
>> #>
>> #> Family Specific Parameters:
>> #>       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
>> #> sigma    31.25      1.81    27.93    35.19 1.00     1726     1341
>> #>
>> #> Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
>> #> and Tail_ESS are effective sample size measures, and Rhat is the
>> potential
>> #> scale reduction factor on split chains (at convergence, Rhat = 1).
>>
>> m2 <- lmer(Reaction ~ Days + (1 | Subject), data = sleepstudy)
>> summary(m2)
>> #> Linear mixed model fit by REML ['lmerMod']
>> #> Formula: Reaction ~ Days + (1 | Subject)
>> #>    Data: sleepstudy
>> #>
>> #> REML criterion at convergence: 1731.8
>> #>
>> #> Scaled residuals:
>> #>     Min      1Q  Median      3Q     Max
>> #> -3.3473 -0.5293  0.0317  0.5328  4.2570
>> #>
>> #> Random effects:
>> #>  Groups   Name        Variance Std.Dev.
>> #>  Subject  (Intercept) 1375.5   37.09
>> #>  Residual              987.6   31.43
>> #> Number of obs: 180, groups:  Subject, 18
>> #>
>> #> Fixed effects:
>> #>             Estimate Std. Error t value
>> #> (Intercept)  298.508      9.050  32.985
>> #> Days.L        95.074      7.407  12.835
>> #> Days.Q         7.744      7.407   1.045
>> #> Days.C        -0.705      7.407  -0.095
>> #> Days^4         5.889      7.407   0.795
>> #> Days^5         1.754      7.407   0.237
>> #> Days^6        -6.036      7.407  -0.815
>> #> Days^7        -1.695      7.407  -0.229
>> #> Days^8        -4.161      7.407  -0.562
>> #> Days^9         6.435      7.407   0.869
>> ...
>>
>> How could an equivalent monotonic effect of `moDays` in `m1` can be
>> obtained with lme4?
>>
>> I'm grateful for anyone who can provide some orientation. Kind regards,
>> --
>>
>> Crist?bal Moya
>>
>> Research Fellow
>>
>> Chair for Social Structure Analysis of Social Inequalities
>>
>> Faculty of Sociology
>>
>> Bielefeld University
>>
>>          [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Dr. Henrik Singmann
Lecturer, Experimental Psychology
University College London (UCL), UK
http://singmann.org

	[[alternative HTML version deleted]]


From cr|@tob@|moy@ @end|ng |rom gm@||@com  Tue Aug 10 10:49:21 2021
From: cr|@tob@|moy@ @end|ng |rom gm@||@com (Cristobal Moya)
Date: Tue, 10 Aug 2021 10:49:21 +0200
Subject: [R-sig-ME] How to obtain monotonic effect of ordered factor
 predictor in lme4 package
In-Reply-To: <CA+rDMKK1=xDcVJJZyVz3kVyaucgaGHWgFR+E9CKuo_18vRzyCw@mail.gmail.com>
References: <CAAnFKoQWegVmy2TicfDmdqyoj=cx9sDZruiv9EiLt4aUQWxp9Q@mail.gmail.com>
 <CA+rDMKJfn0i231ateMkcU1-Y2m=AT14qShD3ScpKCARR9jMRrw@mail.gmail.com>
 <d5ee9e0f-f4ea-c568-feab-7964a4165518@gmail.com>
 <CA+rDMKK1=xDcVJJZyVz3kVyaucgaGHWgFR+E9CKuo_18vRzyCw@mail.gmail.com>
Message-ID: <CAAnFKoQ44Ac68ykAOR0zTw4SW5hQnStMoNJKLF+wkBgP8+NGmg@mail.gmail.com>

Dear Henrik and Ben,

Indeed, I hadn't seen Ben's email. Thank you very much for showing this
option with glmmTMB, it provides much similar estimates compared to the
brms mo() parameterization.

Kind regards,
Crist?bal

On Tue, Aug 10, 2021 at 7:26 AM Henrik Singmann <singmann at gmail.com> wrote:

> Hi Crist?bal,
>
> It looks like you did not get Ben's email (which only went to the list)
> which I attach again below. It clarifies that monotonic effects in the way
> implemented in brms are not possible in lme4 but in glmmTMB.
>
> Cheers,
> Henrik
>
> ---------- Forwarded message ---------
> Von: Ben Bolker <bbolker at gmail.com>
> Date: Fr., 30. Juli 2021 um 22:15 Uhr
> Subject: Re: [R-sig-ME] How to obtain monotonic effect of ordered factor
> predictor in lme4 package
> To: <r-sig-mixed-models at r-project.org>
>
>
>   A few more thoughts
>
> codingMatrices::code_diff() and MASS::contr.sdif() are basically
> identical (in case you don't feel like installing another package --
> MASS is automatically installed with base R)
>
> Not quite sure why you're using code_diff_forward rather than code_diff?
> The latter would naively make more sense to me.
>
>    You can't constrain fixed-effect parameters in lme4::lmer (they are
> profiled out of the likelihood function, so they're not accessible to be
> constrained), but in glmmTMB you could do this:
>
> data("sleepstudy", package= "lme4")
> ss <- within(sleepstudy, {
>      Days <- factor(Days)
>      contrasts(Days) <- MASS::contr.sdif
> })
> library(glmmTMB)
> m1 <- glmmTMB(Reaction ~ Days + (1 | Subject), data = ss)
> m2 <- update(m1,
>               control = glmmTMBControl(
>             optArgs = list(lower=c(-Inf, rep(0,9), rep(-Inf, 2)))))
>
>
>    Notes: (1) the constraints aren't binding in this example because all
> the parameters are estimated as being positive anyway (I was too lazy to
> find another example/perturb this example); (2) you do need to know the
> parameter ordering for this to work: in this case we have the intercept
> (unconstrained) followed by 9 successive difference values, followed by
> parameters for the RE variance and the dispersion (estimated on the log
> scale, unconstrained).  The combination of fixef(m2) and m2$obj$par can
> help you figure this out.
>
>
> On 7/30/21 8:14 AM, Henrik Singmann wrote:
> > Hi Crist?bal,
> >
> > As far as I know, there is no correspondence in lme4 to the monotonic
> > effects as there is no way to enforce certain fixed effect estimate are
> > strictly positive or negative.
> >
> > However, if the data is strictly ordered, you can get something similar
> by
> > using appropriate coding. So instead of using an ordered factor you use a
> > regular factor and code_diff_forward() from package codingMatrices.
> >
> > library("lme4")
> > library("codingMatrices")
> > sleepstudy$Days <- factor(sleepstudy$Days)
> > m2 <- lmer(Reaction ~ Days + (1 | Subject), data = sleepstudy,
> >             contrasts = list(Days = "code_diff_forward"))
> > summary(m2)
> > #> Linear mixed model fit by REML ['lmerMod']
> > #> Formula: Reaction ~ Days + (1 | Subject)
> > #>    Data: sleepstudy
> > #>
> > #> REML criterion at convergence: 1729.5
> > #>
> > #> Scaled residuals:
> > #>     Min      1Q  Median      3Q     Max
> > #> -3.3473 -0.5293  0.0317  0.5328  4.2570
> > #>
> > #> Random effects:
> > #>  Groups   Name        Variance Std.Dev.
> > #>  Subject  (Intercept) 1375.5   37.09
> > #>  Residual              987.6   31.43
> > #> Number of obs: 180, groups:  Subject, 18
> > #>
> > #> Fixed effects:
> > #>             Estimate Std. Error t value
> > #> (Intercept) 298.5079     9.0499  32.985
> > #> Days0-1      -7.8439    10.4753  -0.749
> > #> Days1-2      -0.8661    10.4753  -0.083
> > #> Days2-3     -17.6301    10.4753  -1.683
> > #> Days3-4      -5.6574    10.4753  -0.540
> > #> Days4-5     -19.8690    10.4753  -1.897
> > #> Days5-6      -3.6598    10.4753  -0.349
> > #> Days6-7      -6.5723    10.4753  -0.627
> > #> Days7-8     -17.8789    10.4753  -1.707
> > #> Days8-9     -14.2217    10.4753  -1.358
> > #> [...]
> >
> > This give you the differences between each two days as shown next:
> > library("tidyverse")
> > sleepstudy %>%
> >    group_by(Days) %>%
> >    summarise(mean = mean(Reaction)) %>%
> >    mutate(meanlag = lag(mean)) %>%
> >    mutate(diff = meanlag-mean)
> > #> # A tibble: 10 x 4
> > #>    Days   mean meanlag    diff
> > #>    <fct> <dbl>   <dbl>   <dbl>
> > #>  1 0      257.     NA   NA
> > #>  2 1      264.    257.  -7.84
> > #>  3 2      265.    264.  -0.866
> > #>  4 3      283.    265. -17.6
> > #>  5 4      289.    283.  -5.66
> > #>  6 5      309.    289. -19.9
> > #>  7 6      312.    309.  -3.66
> > #>  8 7      319.    312.  -6.57
> > #>  9 8      337.    319. -17.9
> > #> 10 9      351.    337. -14.2
> >
> > There is also the possibility to get exactly the same results by just
> using
> > emmeans on the model fitted with default contrasts:
> > library("lme4")
> > sleepstudy$Days <- factor(sleepstudy$Days)
> >
> > m2 <- lmer(Reaction ~ Days + (1 | Subject), data = sleepstudy)
> > library("emmeans")
> > emmeans(m2, "Days", contr = "consec")
> > #> $emmeans
> > #>  Days emmean   SE df lower.CL upper.CL
> > #>  0       257 11.5 42      234      280
> > #>  1       264 11.5 42      241      288
> > #>  2       265 11.5 42      242      288
> > #>  3       283 11.5 42      260      306
> > #>  4       289 11.5 42      266      312
> > #>  5       309 11.5 42      285      332
> > #>  6       312 11.5 42      289      335
> > #>  7       319 11.5 42      296      342
> > #>  8       337 11.5 42      314      360
> > #>  9       351 11.5 42      328      374
> > #>
> > #> Degrees-of-freedom method: kenward-roger
> > #> Confidence level used: 0.95
> > #>
> > #> $contrasts
> > #>  contrast estimate   SE  df t.ratio p.value
> > #>  1 - 0       7.844 10.5 153   0.749  0.9887
> > #>  2 - 1       0.866 10.5 153   0.083  1.0000
> > #>  3 - 2      17.630 10.5 153   1.683  0.5279
> > #>  4 - 3       5.657 10.5 153   0.540  0.9988
> > #>  5 - 4      19.869 10.5 153   1.897  0.3775
> > #>  6 - 5       3.660 10.5 153   0.349  1.0000
> > #>  7 - 6       6.572 10.5 153   0.627  0.9965
> > #>  8 - 7      17.879 10.5 153   1.707  0.5098
> > #>  9 - 8      14.222 10.5 153   1.358  0.7629
> > #>
> > #> Degrees-of-freedom method: kenward-roger
> > #> P value adjustment: mvt method for 9 tests
> >
> >   Of course, all of this only works if the means are ordered in this way
> > (otherwise you will have effects that differ in sign).
> >
> > Hope that helps,
> > Henrik
> >
> >
> >
> > Am Di., 27. Juli 2021 um 19:06 Uhr schrieb Cristobal Moya <
> > cristobalmoya at gmail.com>:
> >
> >> Dear list members,
> >>
> >> I have a question regarding monotonic effects with lme4. I also posted
> this
> >> in StackOverflow (https://stackoverflow.com/q/68546489/6832021), which
> is
> >> what I reproduce below.
> >>
> >> I want to obtain a monotonic effect for an ordinal predictor with the
> >> function `lmer()` from the package lme4. My reference is the estimate
> that
> >> can be obtained with `mo()` in the brms package.
> >>
> >> Below a reprex with the desired estimate (leaving aside the different
> >> statistical approach behind both packages) in `m1`, and what happens by
> >> default (`m2`) when an ordered factor is used in `lmer()`
> >>
> >> library(brms)
> >> library(lme4)
> >> sleepstudy$Days <- factor(sleepstudy$Days, ordered = T)
> >> m1 <- brm(Reaction ~ mo(Days) + (1 | Subject), data = sleepstudy,
> chains =
> >> 2)
> >> #> Compiling Stan program...
> >> ...
> >> summary(m1)
> >> #>  Family: gaussian
> >> #>   Links: mu = identity; sigma = identity
> >> #> Formula: Reaction ~ mo(Days) + (1 | Subject)
> >> #>    Data: sleepstudy (Number of observations: 180)
> >> #> Samples: 2 chains, each with iter = 2000; warmup = 1000; thin = 1;
> >> #>          total post-warmup samples = 2000
> >> #>
> >> #> Group-Level Effects:
> >> #> ~Subject (Number of levels: 18)
> >> #>               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
> >> Tail_ESS
> >> #> sd(Intercept)    39.73      7.85    27.73    58.76 1.01      538
> >> 751
> >> #>
> >> #> Population-Level Effects:
> >> #>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
> >> #> Intercept   257.11     10.87   235.14   277.72 1.00      468      774
> >> #> moDays       10.12      1.01     8.16    12.09 1.00     1603     1315
> >> #>
> >> #> Simplex Parameters:
> >> #>            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
> Tail_ESS
> >> #> moDays1[1]     0.07      0.06     0.00     0.20 1.00     1343
> 747
> >> #> moDays1[2]     0.07      0.05     0.00     0.20 1.00     1275
> 524
> >> #> moDays1[3]     0.13      0.07     0.01     0.29 1.00     1337
> 591
> >> #> moDays1[4]     0.10      0.07     0.00     0.28 1.00     1600
> 850
> >> #> moDays1[5]     0.16      0.09     0.01     0.34 1.00     1285
> 658
> >> #> moDays1[6]     0.09      0.06     0.00     0.24 1.00     1543
> 840
> >> #> moDays1[7]     0.09      0.07     0.00     0.25 1.00     1534
> 992
> >> #> moDays1[8]     0.16      0.08     0.02     0.32 1.00     1897
> 906
> >> #> moDays1[9]     0.13      0.08     0.01     0.31 1.00     1839
> 936
> >> #>
> >> #> Family Specific Parameters:
> >> #>       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
> >> #> sigma    31.25      1.81    27.93    35.19 1.00     1726     1341
> >> #>
> >> #> Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
> >> #> and Tail_ESS are effective sample size measures, and Rhat is the
> >> potential
> >> #> scale reduction factor on split chains (at convergence, Rhat = 1).
> >>
> >> m2 <- lmer(Reaction ~ Days + (1 | Subject), data = sleepstudy)
> >> summary(m2)
> >> #> Linear mixed model fit by REML ['lmerMod']
> >> #> Formula: Reaction ~ Days + (1 | Subject)
> >> #>    Data: sleepstudy
> >> #>
> >> #> REML criterion at convergence: 1731.8
> >> #>
> >> #> Scaled residuals:
> >> #>     Min      1Q  Median      3Q     Max
> >> #> -3.3473 -0.5293  0.0317  0.5328  4.2570
> >> #>
> >> #> Random effects:
> >> #>  Groups   Name        Variance Std.Dev.
> >> #>  Subject  (Intercept) 1375.5   37.09
> >> #>  Residual              987.6   31.43
> >> #> Number of obs: 180, groups:  Subject, 18
> >> #>
> >> #> Fixed effects:
> >> #>             Estimate Std. Error t value
> >> #> (Intercept)  298.508      9.050  32.985
> >> #> Days.L        95.074      7.407  12.835
> >> #> Days.Q         7.744      7.407   1.045
> >> #> Days.C        -0.705      7.407  -0.095
> >> #> Days^4         5.889      7.407   0.795
> >> #> Days^5         1.754      7.407   0.237
> >> #> Days^6        -6.036      7.407  -0.815
> >> #> Days^7        -1.695      7.407  -0.229
> >> #> Days^8        -4.161      7.407  -0.562
> >> #> Days^9         6.435      7.407   0.869
> >> ...
> >>
> >> How could an equivalent monotonic effect of `moDays` in `m1` can be
> >> obtained with lme4?
> >>
> >> I'm grateful for anyone who can provide some orientation. Kind regards,
> >> --
> >>
> >> Crist?bal Moya
> >>
> >> Research Fellow
> >>
> >> Chair for Social Structure Analysis of Social Inequalities
> >>
> >> Faculty of Sociology
> >>
> >> Bielefeld University
> >>
> >>          [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> >
>
> --
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> Graduate chair, Mathematics & Statistics
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> --
> Dr. Henrik Singmann
> Lecturer, Experimental Psychology
> University College London (UCL), UK
> http://singmann.org
>

	[[alternative HTML version deleted]]


From j@red@@nder@on@ext @end|ng |rom b@yer@com  Thu Aug 12 01:19:29 2021
From: j@red@@nder@on@ext @end|ng |rom b@yer@com (Jared Anderson)
Date: Wed, 11 Aug 2021 23:19:29 +0000
Subject: [R-sig-ME] Question about flexible LME4 Variance-Covariance
 Structure
Message-ID: <789FFEFE-3CD6-4DC1-AABD-9FBDD09DF751@contoso.com>

Hello All,

I am a Data Scientist with Bayer Crop Science and I deal often with generalized linear mixed models in my role. I am new to this subscription group and wanted to reach out because I am trying to fit two different kinds of models on the same data and use their residual variances as a statistic for assessing data quality.
For our variance-ratio statistic, two slightly different linear models are used. Both models are simple single treatment factor randomized complete block design models. The difference is in the assumed covariance structure of the residuals.
The first model makes the standard assumption that the residuals all have the same variance, while the second model assumes that the residuals variances differ from rep to rep.
Model 1: y = m + T + R + e, where m = overall mean, T = treatment effect, R = blocking effect and e = random error which is assumed to be homoschedastic: cov(e) = common variance*I = Diag(common variance).
Model 2: y = m + T + R + e, where m = overall mean, T = treatment effect, R = blocking effect and e = random error which is assumed to be heteroschedastic: cov(e) = D(var[i]) i=1, ?, number of reps. The variance of the residuals is different for each rep.
VR[i] = var[i]/common variance, one VR value for each rep.

I have been able to build the desired Model1 in LME4
Formula_LME4 <- as.formula(paste0(zParams$value,? ~ 1 + (1|?,zParams$factorLevelId,?) + (1|?BlockingName,?)?))
HomoS_LME4 <- lmer(Formula_LME4,data=zdf) #covariance structure is the same for all reps
(Treating the fixed effects (factorLevelId) as random is a way to trick the routines into calculating the needed variances.)


Where I am running into a problem and was hoping to get your advice: I cannot seem to implement Model 2 successfully
I think the LME4 Heteroscedastic formula is supposed to be this, if I understand it correctly:
lmer(NUM_VALUE ~ 1 + (1 | TREATMENT) + (1 | BlockingName) + (0 | BlockingName),data=zdf)
But it is throwing an error:
Linear mixed model fit by REML ['lmerMod']
Formula: NUM_VALUE ~ 1 + (1 | TREATMENT) + (1 | BlockingName) + (0 | BlockingName)
   Data: zdf
REML criterion at convergence: 1384.89
Error in thl[[i]] : subscript out of bounds
And I was wondering if you?ve ever come across the error above?


If it helps, back when we leveraged Asreml licenses for our work, I was able to generate Model 2 this way:

fixedFormula_ASREML <- as.formula(paste0(zParams$value," ~ 1"))
randomFormula_ASREML <- as.formula(paste0(" ~ ",zParams$factorLevelId," + ", BlockingName))
covFormula_ASREML    <- as.formula(paste0(" ~ at(", BlockingName, "):units"))

HeteroS_ASREML <- asreml(fixed  = fixedFormula_ASREML,
                  random = randomFormula_ASREML,
                  rcov   = covFormula_ASREML,
                  data   = zdf)


Best,
Jared A.


	[[alternative HTML version deleted]]


From me @end|ng |rom ph||||p@|d@y@com  Thu Aug 12 02:26:31 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Wed, 11 Aug 2021 19:26:31 -0500
Subject: [R-sig-ME] Question about flexible LME4 Variance-Covariance
 Structure
In-Reply-To: <789FFEFE-3CD6-4DC1-AABD-9FBDD09DF751@contoso.com>
References: <789FFEFE-3CD6-4DC1-AABD-9FBDD09DF751@contoso.com>
Message-ID: <9ca1b1d4-f29d-4f96-e5bd-8b7150c9eaaf@phillipalday.com>

The problem is

(0 | BlockingName)

The left-hand side of | doesn't have any coefficients (because 0 is
suppressing the intercept) and that's what's causing the error in lme4.

I don't have time to think about the statistical problem at the moment,
but maybe knowing the software issue already helps a bit.

Phillip

On 11/8/21 6:19 pm, Jared Anderson wrote:
> Hello All,
> 
> I am a Data Scientist with Bayer Crop Science and I deal often with generalized linear mixed models in my role. I am new to this subscription group and wanted to reach out because I am trying to fit two different kinds of models on the same data and use their residual variances as a statistic for assessing data quality.
> For our variance-ratio statistic, two slightly different linear models are used. Both models are simple single treatment factor randomized complete block design models. The difference is in the assumed covariance structure of the residuals.
> The first model makes the standard assumption that the residuals all have the same variance, while the second model assumes that the residuals variances differ from rep to rep.
> Model 1: y = m + T + R + e, where m = overall mean, T = treatment effect, R = blocking effect and e = random error which is assumed to be homoschedastic: cov(e) = common variance*I = Diag(common variance).
> Model 2: y = m + T + R + e, where m = overall mean, T = treatment effect, R = blocking effect and e = random error which is assumed to be heteroschedastic: cov(e) = D(var[i]) i=1, ?, number of reps. The variance of the residuals is different for each rep.
> VR[i] = var[i]/common variance, one VR value for each rep.
> 
> I have been able to build the desired Model1 in LME4
> Formula_LME4 <- as.formula(paste0(zParams$value,? ~ 1 + (1|?,zParams$factorLevelId,?) + (1|?BlockingName,?)?))
> HomoS_LME4 <- lmer(Formula_LME4,data=zdf) #covariance structure is the same for all reps
> (Treating the fixed effects (factorLevelId) as random is a way to trick the routines into calculating the needed variances.)
> 
> 
> Where I am running into a problem and was hoping to get your advice: I cannot seem to implement Model 2 successfully
> I think the LME4 Heteroscedastic formula is supposed to be this, if I understand it correctly:
> lmer(NUM_VALUE ~ 1 + (1 | TREATMENT) + (1 | BlockingName) + (0 | BlockingName),data=zdf)
> But it is throwing an error:
> Linear mixed model fit by REML ['lmerMod']
> Formula: NUM_VALUE ~ 1 + (1 | TREATMENT) + (1 | BlockingName) + (0 | BlockingName)
>    Data: zdf
> REML criterion at convergence: 1384.89
> Error in thl[[i]] : subscript out of bounds
> And I was wondering if you?ve ever come across the error above?
> 
> 
> If it helps, back when we leveraged Asreml licenses for our work, I was able to generate Model 2 this way:
> 
> fixedFormula_ASREML <- as.formula(paste0(zParams$value," ~ 1"))
> randomFormula_ASREML <- as.formula(paste0(" ~ ",zParams$factorLevelId," + ", BlockingName))
> covFormula_ASREML    <- as.formula(paste0(" ~ at(", BlockingName, "):units"))
> 
> HeteroS_ASREML <- asreml(fixed  = fixedFormula_ASREML,
>                   random = randomFormula_ASREML,
>                   rcov   = covFormula_ASREML,
>                   data   = zdf)
> 
> 
> Best,
> Jared A.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From @|m@h@rme| @end|ng |rom gm@||@com  Thu Aug 12 23:52:27 2021
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Thu, 12 Aug 2021 16:52:27 -0500
Subject: [R-sig-ME] A conceptual question regarding fixed effects
Message-ID: <CACgv6yU8wpbrceBnV=D37-kS9NDcrq8RJL+Vhtbcb+b0NncQ4g@mail.gmail.com>

Dear Colleagues,

Can we say in mixed-effects models, a fixed-effect coef. is some kind of
(weighted) average of its individual regression counterparts fit to each
level of a grouping variable and that is why fixed-effect coefs in
mixed-effects models can prevent things like a Simpson's Paradox case (
https://stats.stackexchange.com/a/478580/140365) from happening?

If yes, then, would this also mean that if we fit models with the exact
same fixed-effects specification but differing random-effect
specifications, then the fixed coefs can be expected to be different in
value but also meaning (i.e., what kind of [weighted] average they
represent)?

For example, would the meaning of a fixed-effect coef. for variable X
change if it has a corresponding random-effect in the model vs. when it
doesn't, or if we allow X to vary across levels of 1 grouping variable (X |
ID1) vs. those of 2 nested grouping variables (X | ID1/ID2)?

Many thanks for helping me understand this better,
Simon

	[[alternative HTML version deleted]]


From me @end|ng |rom ph||||p@|d@y@com  Fri Aug 13 00:46:32 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Thu, 12 Aug 2021 17:46:32 -0500
Subject: [R-sig-ME] A conceptual question regarding fixed effects
In-Reply-To: <CACgv6yU8wpbrceBnV=D37-kS9NDcrq8RJL+Vhtbcb+b0NncQ4g@mail.gmail.com>
References: <CACgv6yU8wpbrceBnV=D37-kS9NDcrq8RJL+Vhtbcb+b0NncQ4g@mail.gmail.com>
Message-ID: <7cb1c58c-5611-7623-b266-c8c5492940c0@phillipalday.com>

This differs somewhat depending on whether you're assuming an identity
link (as in linear mixed models) or a non-identity link (as in
generalized linear mixed models), see e.g. Dimitris Rizopoulos'
explanation of conditional vs. marginal effects on pdf-page 346 / slide
321 of his course notes http://drizopoulos.com/courses/EMC/CE08.pdf.

For LMM, once you've added a by-group intercept term, the biggest change
you'll generally see with adding addition by-group slopes is in the
standard errors of the fixed effects. The by-group intercept term
matters a lot because it begins to separate within vs. between/across
group effects and thus 'overcomes' Simpson's paradox. More directly,
introducing a by-group intercept allows the groups to have individual
lines instead of sharing one line, and thus you have a separation of
within vs between group effects. (Actually, this matters for any first
term, whether the intercept or not, but the first RE term is usually the
intercept.)

In Statistical Rethinking, Richard McElreath introduces random effects
as being a type of interaction, which is actually a fair intuition
(although there are substantial differences in estimation and formal
details). If you add in higher order effects, you also change the
precise interpretation of the lower-level effects, potentially along
with their estimates and standard errors. The same holds approximately
for adding in random effects.

Note that for the linked example, both the LM and LMM offer coefficients
with potentially meaningfully interpretations. Generally for a bigger
stimulus, you would expect a bigger response, which is a good prediction
if you don't know which subject a given observation came from. And thus
the LM tells you just that because it doesn't know which subject each
observation came from. But if you want to how a given subject will
respond to a larger stimulus, then the effect is paradoxically reversed.
And that's what the mixed model captures.

Or in yet other words, the LM assumes that there are no differences
between subjects and thus any differences are due to stimulus alone.
This isn't true, so it doesn't give a good estimate for different
subjects. Your choice of random effects is a statement about where you
assume differences to exist (and be measurable / distinguishable from
observation-level variance).

Note that there is one confound in the simulated data there: each
subject only saw stimuli within a relatively small range. If each
subject had seen stimuli across a wider range, then I suspect that each
subject's 2 very low response values would have had sufficient leverage
to flatten out the LM's slope estimate. (Such confounds of course exist
in reality in many practical contexts, but for a repeated-measures
design in biology/psychology/neuroscience, it would be great to have a
bit more control....)

Phillip

On 12/8/21 4:52 pm, Simon Harmel wrote:
> Dear Colleagues,
> 
> Can we say in mixed-effects models, a fixed-effect coef. is some kind of
> (weighted) average of its individual regression counterparts fit to each
> level of a grouping variable and that is why fixed-effect coefs in
> mixed-effects models can prevent things like a Simpson's Paradox case (
> https://stats.stackexchange.com/a/478580/140365) from happening?
> 
> If yes, then, would this also mean that if we fit models with the exact
> same fixed-effects specification but differing random-effect
> specifications, then the fixed coefs can be expected to be different in
> value but also meaning (i.e., what kind of [weighted] average they
> represent)?
> 
> For example, would the meaning of a fixed-effect coef. for variable X
> change if it has a corresponding random-effect in the model vs. when it
> doesn't, or if we allow X to vary across levels of 1 grouping variable (X |
> ID1) vs. those of 2 nested grouping variables (X | ID1/ID2)?
> 
> Many thanks for helping me understand this better,
> Simon
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From @|m@h@rme| @end|ng |rom gm@||@com  Fri Aug 13 01:17:18 2021
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Thu, 12 Aug 2021 18:17:18 -0500
Subject: [R-sig-ME] A conceptual question regarding fixed effects
In-Reply-To: <7cb1c58c-5611-7623-b266-c8c5492940c0@phillipalday.com>
References: <CACgv6yU8wpbrceBnV=D37-kS9NDcrq8RJL+Vhtbcb+b0NncQ4g@mail.gmail.com>
 <7cb1c58c-5611-7623-b266-c8c5492940c0@phillipalday.com>
Message-ID: <CACgv6yXbSEd+bQyVks_69P0BZF2AeXDGzemE3hGgfTkPTL9rcA@mail.gmail.com>

Dear Phillip,

Thank you very much. Unfortunately, I couldn't open the link you shared (I
get: This site can?t be reached). So, I mainly want to focus on the second
paragraph of your answer. My focus is only on LMMs.

To be clear, I gather that you believe it is correct to think that a
fixed-effect coef. is some kind of (weighted) average of its individual
regression counterparts fit to each level of a grouping variable and that
this issue is helpful in preventing Simpson's paradox-type conclusions?

Now, suppose X is a continuous predictor. It can vary across levels of ID1
and ID2; where ID2 is nested in ID1.

I fit three models with X:

1) y ~ X + (X | ID1)
2) y ~ X + (X | ID1 / ID2)
3) y ~ X

Can I interpret X in (1) as: Change in y for 1 unit of change in X averaged
across levels of ID1 disregarding combination of ID1-ID2 levels?
Can I interpret X in (2) as: Change in y for 1 unit of change in X averaged
across levels of ID1 and combination of ID1-ID2 levels?
Can I interpret X in (3) as: Change in y for 1 unit of change in X
disregarding levels of ID1 and combination of ID1-ID2 levels?

Thanks,
Simon

On Thu, Aug 12, 2021 at 5:46 PM Phillip Alday <me at phillipalday.com> wrote:

> This differs somewhat depending on whether you're assuming an identity
> link (as in linear mixed models) or a non-identity link (as in
> generalized linear mixed models), see e.g. Dimitris Rizopoulos'
> explanation of conditional vs. marginal effects on pdf-page 346 / slide
> 321 of his course notes http://drizopoulos.com/courses/EMC/CE08.pdf.
>
> For LMM, once you've added a by-group intercept term, the biggest change
> you'll generally see with adding addition by-group slopes is in the
> standard errors of the fixed effects. The by-group intercept term
> matters a lot because it begins to separate within vs. between/across
> group effects and thus 'overcomes' Simpson's paradox. More directly,
> introducing a by-group intercept allows the groups to have individual
> lines instead of sharing one line, and thus you have a separation of
> within vs between group effects. (Actually, this matters for any first
> term, whether the intercept or not, but the first RE term is usually the
> intercept.)
>
> In Statistical Rethinking, Richard McElreath introduces random effects
> as being a type of interaction, which is actually a fair intuition
> (although there are substantial differences in estimation and formal
> details). If you add in higher order effects, you also change the
> precise interpretation of the lower-level effects, potentially along
> with their estimates and standard errors. The same holds approximately
> for adding in random effects.
>
> Note that for the linked example, both the LM and LMM offer coefficients
> with potentially meaningfully interpretations. Generally for a bigger
> stimulus, you would expect a bigger response, which is a good prediction
> if you don't know which subject a given observation came from. And thus
> the LM tells you just that because it doesn't know which subject each
> observation came from. But if you want to how a given subject will
> respond to a larger stimulus, then the effect is paradoxically reversed.
> And that's what the mixed model captures.
>
> Or in yet other words, the LM assumes that there are no differences
> between subjects and thus any differences are due to stimulus alone.
> This isn't true, so it doesn't give a good estimate for different
> subjects. Your choice of random effects is a statement about where you
> assume differences to exist (and be measurable / distinguishable from
> observation-level variance).
>
> Note that there is one confound in the simulated data there: each
> subject only saw stimuli within a relatively small range. If each
> subject had seen stimuli across a wider range, then I suspect that each
> subject's 2 very low response values would have had sufficient leverage
> to flatten out the LM's slope estimate. (Such confounds of course exist
> in reality in many practical contexts, but for a repeated-measures
> design in biology/psychology/neuroscience, it would be great to have a
> bit more control....)
>
> Phillip
>
> On 12/8/21 4:52 pm, Simon Harmel wrote:
> > Dear Colleagues,
> >
> > Can we say in mixed-effects models, a fixed-effect coef. is some kind of
> > (weighted) average of its individual regression counterparts fit to each
> > level of a grouping variable and that is why fixed-effect coefs in
> > mixed-effects models can prevent things like a Simpson's Paradox case (
> > https://stats.stackexchange.com/a/478580/140365) from happening?
> >
> > If yes, then, would this also mean that if we fit models with the exact
> > same fixed-effects specification but differing random-effect
> > specifications, then the fixed coefs can be expected to be different in
> > value but also meaning (i.e., what kind of [weighted] average they
> > represent)?
> >
> > For example, would the meaning of a fixed-effect coef. for variable X
> > change if it has a corresponding random-effect in the model vs. when it
> > doesn't, or if we allow X to vary across levels of 1 grouping variable
> (X |
> > ID1) vs. those of 2 nested grouping variables (X | ID1/ID2)?
> >
> > Many thanks for helping me understand this better,
> > Simon
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>

	[[alternative HTML version deleted]]


From biii m@iii@g oii de@@ey@ws  Fri Aug 13 01:59:44 2021
From: biii m@iii@g oii de@@ey@ws (biii m@iii@g oii de@@ey@ws)
Date: Thu, 12 Aug 2021 19:59:44 -0400
Subject: [R-sig-ME] Error with nlme and fixed effects defined with a minus 1
Message-ID: <01f601d78fd6$1fcab2b0$5f601810$@denney.ws>

Hello,

 

I think that I have found a bug in nlme.  When I generate a model with fixed
effects defined with a factor - 1 (see model_minus1 below) and I simulate
with level=0 in a data.frame that does not have all the levels (see predict
into simdata2 with model_minus1 below), there is an error.  But, if the
model is defined without the minus 1 or all factor levels are represented
within the simulation data, there is no error.

 

Did I find a bug in nlme?

 

Thanks,

 

Bill

 

``` r

library(nlme)

simdata <-

  merge(

    merge(

      data.frame(treatment=factor(c("A", "B"))),

      data.frame(ID=factor(1:10))

    ),

    data.frame(time=1:10)

  )

set.seed(5)

simdata$obs <- rnorm(nrow(simdata))

model_minus1 <- nlme(obs~e0, data=simdata, fixed=e0~treatment - 1,
random=e0~1|ID, start=c(e0=c(0, 0)))

model <- nlme(obs~e0, data=simdata, fixed=e0~treatment, random=e0~1|ID,
start=c(e0=c(0, 0)))

 

# Generate new data with the correct treatment factor levels, but only one
of

# the levels represented within the data.

simdata2 <-

  merge(

    data.frame(treatment=factor("A", levels=c("A", "B"))),

    data.frame(time=1:10)

  )

# Generate new data with all factor levels represented

simdata3 <-

  merge(

    data.frame(treatment=factor(c("A", "B"))),

    data.frame(time=1:10)

  )

predict(model, newdata=simdata2, level=0)

#>  [1] 0.02690558 0.02690558 0.02690558 0.02690558 0.02690558 0.02690558

#>  [7] 0.02690558 0.02690558 0.02690558 0.02690558

#> attr(,"label")

#> [1] "Predicted values"

# Without all levels in newdata$treatment, it fails

predict(model_minus1, newdata=simdata2, level=0)

#> Error in pars[, nm] <- f %*% beta[fmap[[nm]]]: number of items to replace
is not a multiple of replacement length

# With all levels in newdata$treatment, it works

predict(model_minus1, newdata=simdata3, level=0)

#>  [1] 0.02690558 0.02123989 0.02690558 0.02123989 0.02690558 0.02123989

#>  [7] 0.02690558 0.02123989 0.02690558 0.02123989 0.02690558 0.02123989

#> [13] 0.02690558 0.02123989 0.02690558 0.02123989 0.02690558 0.02123989

#> [19] 0.02690558 0.02123989

#> attr(,"label")

#> [1] "Predicted values"

```

 

<sup>Created on 2021-08-12 by the [reprex
package](https://reprex.tidyverse.org) (v2.0.0)</sup>


	[[alternative HTML version deleted]]


From me @end|ng |rom ph||||p@|d@y@com  Fri Aug 13 03:19:10 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Thu, 12 Aug 2021 20:19:10 -0500
Subject: [R-sig-ME] A conceptual question regarding fixed effects
In-Reply-To: <CACgv6yXbSEd+bQyVks_69P0BZF2AeXDGzemE3hGgfTkPTL9rcA@mail.gmail.com>
References: <CACgv6yU8wpbrceBnV=D37-kS9NDcrq8RJL+Vhtbcb+b0NncQ4g@mail.gmail.com>
 <7cb1c58c-5611-7623-b266-c8c5492940c0@phillipalday.com>
 <CACgv6yXbSEd+bQyVks_69P0BZF2AeXDGzemE3hGgfTkPTL9rcA@mail.gmail.com>
Message-ID: <9f62ebe7-ab6f-8f71-c295-910145fb3186@phillipalday.com>

Here's a  second try with the link:

http://www.drizopoulos.com/courses/EMC/CE08.pdf

On 12/8/21 6:17 pm, Simon Harmel wrote:
> Dear Phillip,
> 
> Thank you very much. Unfortunately, I couldn't open the link you shared
> (I get: This site can?t be reached). So, I mainly want to focus on the
> second paragraph of your answer. My focus is only on LMMs.?
> 
> To be clear, I gather that you believe it is correct to think that a
> fixed-effect coef. is some kind of (weighted) average of its individual
> regression counterparts fit to each level of a grouping variable and
> that this issue is helpful?in preventing Simpson's paradox-type conclusions?
> 
> Now, suppose X is a continuous?predictor. It can vary across levels of
> ID1 and ID2; where ID2 is nested in ID1.
> 
> I fit three models with X:
> 
> 1) y ~ X?+?(X | ID1)??
> 2) y ~ X?+ (X | ID1 / ID2)
> 3) y ~ X
> 
> Can I interpret X in (1) as: Change in y for 1 unit of change in X
> averaged across levels of ID1 disregarding combination of ID1-ID2 levels?
> Can I interpret X in (2) as: Change in y for 1 unit of change in X
> averaged across levels of ID1 and combination of ID1-ID2 levels?
> Can I interpret X in (3) as: Change in y for 1 unit of change in X
> disregarding levels of ID1 and combination of ID1-ID2 levels?
> 
> Thanks,
> Simon
> 
> On Thu, Aug 12, 2021 at 5:46 PM Phillip Alday <me at phillipalday.com
> <mailto:me at phillipalday.com>> wrote:
> 
>     This differs somewhat depending on whether you're assuming an identity
>     link (as in linear mixed models) or a non-identity link (as in
>     generalized linear mixed models), see e.g. Dimitris Rizopoulos'
>     explanation of conditional vs. marginal effects on pdf-page 346 / slide
>     321 of his course notes http://drizopoulos.com/courses/EMC/CE08.pdf.
> 
>     For LMM, once you've added a by-group intercept term, the biggest change
>     you'll generally see with adding addition by-group slopes is in the
>     standard errors of the fixed effects. The by-group intercept term
>     matters a lot because it begins to separate within vs. between/across
>     group effects and thus 'overcomes' Simpson's paradox. More directly,
>     introducing a by-group intercept allows the groups to have individual
>     lines instead of sharing one line, and thus you have a separation of
>     within vs between group effects. (Actually, this matters for any first
>     term, whether the intercept or not, but the first RE term is usually the
>     intercept.)
> 
>     In Statistical Rethinking, Richard McElreath introduces random effects
>     as being a type of interaction, which is actually a fair intuition
>     (although there are substantial differences in estimation and formal
>     details). If you add in higher order effects, you also change the
>     precise interpretation of the lower-level effects, potentially along
>     with their estimates and standard errors. The same holds approximately
>     for adding in random effects.
> 
>     Note that for the linked example, both the LM and LMM offer coefficients
>     with potentially meaningfully interpretations. Generally for a bigger
>     stimulus, you would expect a bigger response, which is a good prediction
>     if you don't know which subject a given observation came from. And thus
>     the LM tells you just that because it doesn't know which subject each
>     observation came from. But if you want to how a given subject will
>     respond to a larger stimulus, then the effect is paradoxically reversed.
>     And that's what the mixed model captures.
> 
>     Or in yet other words, the LM assumes that there are no differences
>     between subjects and thus any differences are due to stimulus alone.
>     This isn't true, so it doesn't give a good estimate for different
>     subjects. Your choice of random effects is a statement about where you
>     assume differences to exist (and be measurable / distinguishable from
>     observation-level variance).
> 
>     Note that there is one confound in the simulated data there: each
>     subject only saw stimuli within a relatively small range. If each
>     subject had seen stimuli across a wider range, then I suspect that each
>     subject's 2 very low response values would have had sufficient leverage
>     to flatten out the LM's slope estimate. (Such confounds of course exist
>     in reality in many practical contexts, but for a repeated-measures
>     design in biology/psychology/neuroscience, it would be great to have a
>     bit more control....)
> 
>     Phillip
> 
>     On 12/8/21 4:52 pm, Simon Harmel wrote:
>     > Dear Colleagues,
>     >
>     > Can we say in mixed-effects models, a fixed-effect coef. is some
>     kind of
>     > (weighted) average of its individual regression counterparts fit
>     to each
>     > level of a grouping variable and that is why fixed-effect coefs in
>     > mixed-effects models can prevent things like a Simpson's Paradox
>     case (
>     > https://stats.stackexchange.com/a/478580/140365) from happening?
>     >
>     > If yes, then, would this also mean that if we fit models with the
>     exact
>     > same fixed-effects specification but differing random-effect
>     > specifications, then the fixed coefs can be expected to be
>     different in
>     > value but also meaning (i.e., what kind of [weighted] average they
>     > represent)?
>     >
>     > For example, would the meaning of a fixed-effect coef. for variable X
>     > change if it has a corresponding random-effect in the model vs.
>     when it
>     > doesn't, or if we allow X to vary across levels of 1 grouping
>     variable (X |
>     > ID1) vs. those of 2 nested grouping variables (X | ID1/ID2)?
>     >
>     > Many thanks for helping me understand this better,
>     > Simon
>     >
>     >? ? ? ?[[alternative HTML version deleted]]
>     >
>     > _______________________________________________
>     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >
>


From me @end|ng |rom ph||||p@|d@y@com  Fri Aug 13 04:08:24 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Thu, 12 Aug 2021 21:08:24 -0500
Subject: [R-sig-ME] 
 Error with nlme and fixed effects defined with a minus 1
In-Reply-To: <01f601d78fd6$1fcab2b0$5f601810$@denney.ws>
References: <01f601d78fd6$1fcab2b0$5f601810$@denney.ws>
Message-ID: <fdbf8a77-6b63-73d7-19ae-32922e907014@phillipalday.com>

This has more to do with how R expands formulae and contrast coding than
anything specific to nlme, I think. I suspect that if you did this with
just a normal (non mixed) linear model, the same problem would arise.
When you have -1, the intercept is suppressed, which in the presence of
a categorical variable means that all k levels of that variable are
represented as coefficients instead of k-1 (with the final contrast
thrown in with the intercept). This is of course not ideal behavior and
could probably be addressed or worked around in nlme, but it seems like
a bit of an edge case. Maybe setting the contrasts manually will help?

contrasts(simdata2$treatment) <- contrasts(simdata$treatment)

(Good call on setting the factor levels in simdata2!)

On 12/8/21 6:59 pm, bill at denney.ws wrote:
> Hello,
> 
>  
> 
> I think that I have found a bug in nlme.  When I generate a model with fixed
> effects defined with a factor - 1 (see model_minus1 below) and I simulate
> with level=0 in a data.frame that does not have all the levels (see predict
> into simdata2 with model_minus1 below), there is an error.  But, if the
> model is defined without the minus 1 or all factor levels are represented
> within the simulation data, there is no error.
> 
>  
> 
> Did I find a bug in nlme?
> 
>  
> 
> Thanks,
> 
>  
> 
> Bill
> 
>  
> 
> ``` r
> 
> library(nlme)
> 
> simdata <-
> 
>   merge(
> 
>     merge(
> 
>       data.frame(treatment=factor(c("A", "B"))),
> 
>       data.frame(ID=factor(1:10))
> 
>     ),
> 
>     data.frame(time=1:10)
> 
>   )
> 
> set.seed(5)
> 
> simdata$obs <- rnorm(nrow(simdata))
> 
> model_minus1 <- nlme(obs~e0, data=simdata, fixed=e0~treatment - 1,
> random=e0~1|ID, start=c(e0=c(0, 0)))
> 
> model <- nlme(obs~e0, data=simdata, fixed=e0~treatment, random=e0~1|ID,
> start=c(e0=c(0, 0)))
> 
>  
> 
> # Generate new data with the correct treatment factor levels, but only one
> of
> 
> # the levels represented within the data.
> 
> simdata2 <-
> 
>   merge(
> 
>     data.frame(treatment=factor("A", levels=c("A", "B"))),
> 
>     data.frame(time=1:10)
> 
>   )
> 
> # Generate new data with all factor levels represented
> 
> simdata3 <-
> 
>   merge(
> 
>     data.frame(treatment=factor(c("A", "B"))),
> 
>     data.frame(time=1:10)
> 
>   )
> 
> predict(model, newdata=simdata2, level=0)
> 
> #>  [1] 0.02690558 0.02690558 0.02690558 0.02690558 0.02690558 0.02690558
> 
> #>  [7] 0.02690558 0.02690558 0.02690558 0.02690558
> 
> #> attr(,"label")
> 
> #> [1] "Predicted values"
> 
> # Without all levels in newdata$treatment, it fails
> 
> predict(model_minus1, newdata=simdata2, level=0)
> 
> #> Error in pars[, nm] <- f %*% beta[fmap[[nm]]]: number of items to replace
> is not a multiple of replacement length
> 
> # With all levels in newdata$treatment, it works
> 
> predict(model_minus1, newdata=simdata3, level=0)
> 
> #>  [1] 0.02690558 0.02123989 0.02690558 0.02123989 0.02690558 0.02123989
> 
> #>  [7] 0.02690558 0.02123989 0.02690558 0.02123989 0.02690558 0.02123989
> 
> #> [13] 0.02690558 0.02123989 0.02690558 0.02123989 0.02690558 0.02123989
> 
> #> [19] 0.02690558 0.02123989
> 
> #> attr(,"label")
> 
> #> [1] "Predicted values"
> 
> ```
> 
>  
> 
> <sup>Created on 2021-08-12 by the [reprex
> package](https://reprex.tidyverse.org) (v2.0.0)</sup>
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From biii m@iii@g oii de@@ey@ws  Fri Aug 13 05:06:39 2021
From: biii m@iii@g oii de@@ey@ws (biii m@iii@g oii de@@ey@ws)
Date: Thu, 12 Aug 2021 23:06:39 -0400
Subject: [R-sig-ME] 
 Error with nlme and fixed effects defined with a minus 1
In-Reply-To: <fdbf8a77-6b63-73d7-19ae-32922e907014@phillipalday.com>
References: <01f601d78fd6$1fcab2b0$5f601810$@denney.ws>
 <fdbf8a77-6b63-73d7-19ae-32922e907014@phillipalday.com>
Message-ID: <021801d78ff0$3c703ab0$b550b010$@denney.ws>

Thanks for the quick reply.

lm() doesn't have the same issue (at least using what I think is the equivalent construction).  See the first test below for that.  And, when I try to manually add the contrasts, nlme drops the contrasts due to missing levels; see the second example with simdata4.

Other than regenerating the model or using a contrast setup that I don't want (due to the ease of interpreting the contrasts with -1), I don't see a way around it other than augmenting the data with some data that I don't want to use.

Also, I am apparently a consistent person because I had the same issue about 4 years ago (https://bugs.r-project.org/show_bug.cgi?id=17226), and in that bug, I found that someone on stackoverflow had the same issue (https://stats.stackexchange.com/questions/29513/error-in-getting-predictions-from-a-lme-object).  In the stackoverflow answer, there is a patch that may help.  (I hesitate to make that fix into a real fix myself because I don't fully understand the internals of nlme.)

``` r
simdata <-
  merge(
    merge(
      data.frame(treatment=factor(c("A", "B"))),
      data.frame(ID=factor(1:10))
    ),
    data.frame(time=1:10)
  )
set.seed(5)
simdata$obs <- rnorm(nrow(simdata))
model_minus1 <- lm(obs~treatment-1, data=simdata)
model <- lm(obs~treatment, data=simdata)

# Generate new data with the correct treatment factor levels, but only one of
# the levels represented within the data.
simdata2 <-
  merge(
    data.frame(treatment=factor("A", levels=c("A", "B"))),
    data.frame(time=1:10)
  )
# Generate new data with all factor levels represented
simdata3 <-
  merge(
    data.frame(treatment=factor(c("A", "B"))),
    data.frame(time=1:10)
  )
predict(model, newdata=simdata2)
#>          1          2          3          4          5          6          7 
#> 0.02690558 0.02690558 0.02690558 0.02690558 0.02690558 0.02690558 0.02690558 
#>          8          9         10 
#> 0.02690558 0.02690558 0.02690558
predict(model_minus1, newdata=simdata2)
#>          1          2          3          4          5          6          7 
#> 0.02690558 0.02690558 0.02690558 0.02690558 0.02690558 0.02690558 0.02690558 
#>          8          9         10 
#> 0.02690558 0.02690558 0.02690558
predict(model_minus1, newdata=simdata3)
#>          1          2          3          4          5          6          7 
#> 0.02690558 0.02123989 0.02690558 0.02123989 0.02690558 0.02123989 0.02690558 
#>          8          9         10         11         12         13         14 
#> 0.02123989 0.02690558 0.02123989 0.02690558 0.02123989 0.02690558 0.02123989 
#>         15         16         17         18         19         20 
#> 0.02690558 0.02123989 0.02690558 0.02123989 0.02690558 0.02123989
```

``` r
library(nlme)
simdata <-
  merge(
    merge(
      data.frame(treatment=factor(c("A", "B"))),
      data.frame(ID=factor(1:10))
    ),
    data.frame(time=1:10)
  )
set.seed(5)
simdata$obs <- rnorm(nrow(simdata))
model_minus1 <- nlme(obs~e0, data=simdata, fixed=e0~treatment - 1, random=e0~1|ID, start=c(e0=c(0, 0)))
model <- nlme(obs~e0, data=simdata, fixed=e0~treatment, random=e0~1|ID, start=c(e0=c(0, 0)))

# Generate new data with the correct treatment factor levels, but only one of
# the levels represented within the data.
simdata2 <-
  merge(
    data.frame(treatment=factor("A", levels=c("A", "B"))),
    data.frame(time=1:10)
  )
# Generate new data with all factor levels represented
simdata3 <-
  merge(
    data.frame(treatment=factor(c("A", "B"))),
    data.frame(time=1:10)
  )
simdata4 <- simdata2
contrasts(simdata4$treatment) <- contrasts(simdata$treatment)
predict(model, newdata=simdata2, level=0)
#>  [1] 0.02690558 0.02690558 0.02690558 0.02690558 0.02690558 0.02690558
#>  [7] 0.02690558 0.02690558 0.02690558 0.02690558
#> attr(,"label")
#> [1] "Predicted values"
# Without all levels in newdata$treatment, it fails
predict(model_minus1, newdata=simdata2, level=0)
#> Error in pars[, nm] <- f %*% beta[fmap[[nm]]]: number of items to replace is not a multiple of replacement length
# With all levels in newdata$treatment, it works
predict(model_minus1, newdata=simdata3, level=0)
#>  [1] 0.02690558 0.02123989 0.02690558 0.02123989 0.02690558 0.02123989
#>  [7] 0.02690558 0.02123989 0.02690558 0.02123989 0.02690558 0.02123989
#> [13] 0.02690558 0.02123989 0.02690558 0.02123989 0.02690558 0.02123989
#> [19] 0.02690558 0.02123989
#> attr(,"label")
#> [1] "Predicted values"
# Same error as simdata2, but now a warning that factor levels are dropped (when
# I don't think they should be)
predict(model_minus1, newdata=simdata4, level=0)
#> Warning: contrasts dropped from factor treatment due to missing levels
#> Error in pars[, nm] <- f %*% beta[fmap[[nm]]]: number of items to replace is not a multiple of replacement length
```

<sup>Created on 2021-08-12 by the [reprex package](https://reprex.tidyverse.org) (v2.0.0)</sup>

-----Original Message-----
From: Phillip Alday <me at phillipalday.com> 
Sent: Thursday, August 12, 2021 10:08 PM
To: bill at denney.ws; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Error with nlme and fixed effects defined with a minus 1

This has more to do with how R expands formulae and contrast coding than anything specific to nlme, I think. I suspect that if you did this with just a normal (non mixed) linear model, the same problem would arise.
When you have -1, the intercept is suppressed, which in the presence of a categorical variable means that all k levels of that variable are represented as coefficients instead of k-1 (with the final contrast thrown in with the intercept). This is of course not ideal behavior and could probably be addressed or worked around in nlme, but it seems like a bit of an edge case. Maybe setting the contrasts manually will help?

contrasts(simdata2$treatment) <- contrasts(simdata$treatment)

(Good call on setting the factor levels in simdata2!)

On 12/8/21 6:59 pm, bill at denney.ws wrote:
> Hello,
> 
>  
> 
> I think that I have found a bug in nlme.  When I generate a model with 
> fixed effects defined with a factor - 1 (see model_minus1 below) and I 
> simulate with level=0 in a data.frame that does not have all the 
> levels (see predict into simdata2 with model_minus1 below), there is 
> an error.  But, if the model is defined without the minus 1 or all 
> factor levels are represented within the simulation data, there is no error.
> 
>  
> 
> Did I find a bug in nlme?
> 
>  
> 
> Thanks,
> 
>  
> 
> Bill
> 
>  
> 
> ``` r
> 
> library(nlme)
> 
> simdata <-
> 
>   merge(
> 
>     merge(
> 
>       data.frame(treatment=factor(c("A", "B"))),
> 
>       data.frame(ID=factor(1:10))
> 
>     ),
> 
>     data.frame(time=1:10)
> 
>   )
> 
> set.seed(5)
> 
> simdata$obs <- rnorm(nrow(simdata))
> 
> model_minus1 <- nlme(obs~e0, data=simdata, fixed=e0~treatment - 1, 
> random=e0~1|ID, start=c(e0=c(0, 0)))
> 
> model <- nlme(obs~e0, data=simdata, fixed=e0~treatment, 
> random=e0~1|ID, start=c(e0=c(0, 0)))
> 
>  
> 
> # Generate new data with the correct treatment factor levels, but only 
> one of
> 
> # the levels represented within the data.
> 
> simdata2 <-
> 
>   merge(
> 
>     data.frame(treatment=factor("A", levels=c("A", "B"))),
> 
>     data.frame(time=1:10)
> 
>   )
> 
> # Generate new data with all factor levels represented
> 
> simdata3 <-
> 
>   merge(
> 
>     data.frame(treatment=factor(c("A", "B"))),
> 
>     data.frame(time=1:10)
> 
>   )
> 
> predict(model, newdata=simdata2, level=0)
> 
> #>  [1] 0.02690558 0.02690558 0.02690558 0.02690558 0.02690558 
> 0.02690558
> 
> #>  [7] 0.02690558 0.02690558 0.02690558 0.02690558
> 
> #> attr(,"label")
> 
> #> [1] "Predicted values"
> 
> # Without all levels in newdata$treatment, it fails
> 
> predict(model_minus1, newdata=simdata2, level=0)
> 
> #> Error in pars[, nm] <- f %*% beta[fmap[[nm]]]: number of items to 
> replace is not a multiple of replacement length
> 
> # With all levels in newdata$treatment, it works
> 
> predict(model_minus1, newdata=simdata3, level=0)
> 
> #>  [1] 0.02690558 0.02123989 0.02690558 0.02123989 0.02690558 
> 0.02123989
> 
> #>  [7] 0.02690558 0.02123989 0.02690558 0.02123989 0.02690558 
> 0.02123989
> 
> #> [13] 0.02690558 0.02123989 0.02690558 0.02123989 0.02690558 
> 0.02123989
> 
> #> [19] 0.02690558 0.02123989
> 
> #> attr(,"label")
> 
> #> [1] "Predicted values"
> 
> ```
> 
>  
> 
> <sup>Created on 2021-08-12 by the [reprex
> package](https://reprex.tidyverse.org) (v2.0.0)</sup>
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 


From @reedt@8 @end|ng |rom gm@||@com  Fri Aug 13 05:55:20 2021
From: @reedt@8 @end|ng |rom gm@||@com (sree datta)
Date: Thu, 12 Aug 2021 23:55:20 -0400
Subject: [R-sig-ME] A conceptual question regarding fixed effects
In-Reply-To: <9f62ebe7-ab6f-8f71-c295-910145fb3186@phillipalday.com>
References: <CACgv6yU8wpbrceBnV=D37-kS9NDcrq8RJL+Vhtbcb+b0NncQ4g@mail.gmail.com>
 <7cb1c58c-5611-7623-b266-c8c5492940c0@phillipalday.com>
 <CACgv6yXbSEd+bQyVks_69P0BZF2AeXDGzemE3hGgfTkPTL9rcA@mail.gmail.com>
 <9f62ebe7-ab6f-8f71-c295-910145fb3186@phillipalday.com>
Message-ID: <CAHftDbgmN-shZABsUuwr4xEze9O0eUP-wNYsWQo9je5N04U_uQ@mail.gmail.com>

Thanks for sharing this Phillip, a fabulous and a very helpful document!

Sree

On Thu, Aug 12, 2021 at 9:19 PM Phillip Alday <me at phillipalday.com> wrote:

> Here's a  second try with the link:
>
> http://www.drizopoulos.com/courses/EMC/CE08.pdf
>
> On 12/8/21 6:17 pm, Simon Harmel wrote:
> > Dear Phillip,
> >
> > Thank you very much. Unfortunately, I couldn't open the link you shared
> > (I get: This site can?t be reached). So, I mainly want to focus on the
> > second paragraph of your answer. My focus is only on LMMs.
> >
> > To be clear, I gather that you believe it is correct to think that a
> > fixed-effect coef. is some kind of (weighted) average of its individual
> > regression counterparts fit to each level of a grouping variable and
> > that this issue is helpful in preventing Simpson's paradox-type
> conclusions?
> >
> > Now, suppose X is a continuous predictor. It can vary across levels of
> > ID1 and ID2; where ID2 is nested in ID1.
> >
> > I fit three models with X:
> >
> > 1) y ~ X + (X | ID1)
> > 2) y ~ X + (X | ID1 / ID2)
> > 3) y ~ X
> >
> > Can I interpret X in (1) as: Change in y for 1 unit of change in X
> > averaged across levels of ID1 disregarding combination of ID1-ID2 levels?
> > Can I interpret X in (2) as: Change in y for 1 unit of change in X
> > averaged across levels of ID1 and combination of ID1-ID2 levels?
> > Can I interpret X in (3) as: Change in y for 1 unit of change in X
> > disregarding levels of ID1 and combination of ID1-ID2 levels?
> >
> > Thanks,
> > Simon
> >
> > On Thu, Aug 12, 2021 at 5:46 PM Phillip Alday <me at phillipalday.com
> > <mailto:me at phillipalday.com>> wrote:
> >
> >     This differs somewhat depending on whether you're assuming an
> identity
> >     link (as in linear mixed models) or a non-identity link (as in
> >     generalized linear mixed models), see e.g. Dimitris Rizopoulos'
> >     explanation of conditional vs. marginal effects on pdf-page 346 /
> slide
> >     321 of his course notes http://drizopoulos.com/courses/EMC/CE08.pdf.
> >
> >     For LMM, once you've added a by-group intercept term, the biggest
> change
> >     you'll generally see with adding addition by-group slopes is in the
> >     standard errors of the fixed effects. The by-group intercept term
> >     matters a lot because it begins to separate within vs. between/across
> >     group effects and thus 'overcomes' Simpson's paradox. More directly,
> >     introducing a by-group intercept allows the groups to have individual
> >     lines instead of sharing one line, and thus you have a separation of
> >     within vs between group effects. (Actually, this matters for any
> first
> >     term, whether the intercept or not, but the first RE term is usually
> the
> >     intercept.)
> >
> >     In Statistical Rethinking, Richard McElreath introduces random
> effects
> >     as being a type of interaction, which is actually a fair intuition
> >     (although there are substantial differences in estimation and formal
> >     details). If you add in higher order effects, you also change the
> >     precise interpretation of the lower-level effects, potentially along
> >     with their estimates and standard errors. The same holds
> approximately
> >     for adding in random effects.
> >
> >     Note that for the linked example, both the LM and LMM offer
> coefficients
> >     with potentially meaningfully interpretations. Generally for a bigger
> >     stimulus, you would expect a bigger response, which is a good
> prediction
> >     if you don't know which subject a given observation came from. And
> thus
> >     the LM tells you just that because it doesn't know which subject each
> >     observation came from. But if you want to how a given subject will
> >     respond to a larger stimulus, then the effect is paradoxically
> reversed.
> >     And that's what the mixed model captures.
> >
> >     Or in yet other words, the LM assumes that there are no differences
> >     between subjects and thus any differences are due to stimulus alone.
> >     This isn't true, so it doesn't give a good estimate for different
> >     subjects. Your choice of random effects is a statement about where
> you
> >     assume differences to exist (and be measurable / distinguishable from
> >     observation-level variance).
> >
> >     Note that there is one confound in the simulated data there: each
> >     subject only saw stimuli within a relatively small range. If each
> >     subject had seen stimuli across a wider range, then I suspect that
> each
> >     subject's 2 very low response values would have had sufficient
> leverage
> >     to flatten out the LM's slope estimate. (Such confounds of course
> exist
> >     in reality in many practical contexts, but for a repeated-measures
> >     design in biology/psychology/neuroscience, it would be great to have
> a
> >     bit more control....)
> >
> >     Phillip
> >
> >     On 12/8/21 4:52 pm, Simon Harmel wrote:
> >     > Dear Colleagues,
> >     >
> >     > Can we say in mixed-effects models, a fixed-effect coef. is some
> >     kind of
> >     > (weighted) average of its individual regression counterparts fit
> >     to each
> >     > level of a grouping variable and that is why fixed-effect coefs in
> >     > mixed-effects models can prevent things like a Simpson's Paradox
> >     case (
> >     > https://stats.stackexchange.com/a/478580/140365) from happening?
> >     >
> >     > If yes, then, would this also mean that if we fit models with the
> >     exact
> >     > same fixed-effects specification but differing random-effect
> >     > specifications, then the fixed coefs can be expected to be
> >     different in
> >     > value but also meaning (i.e., what kind of [weighted] average they
> >     > represent)?
> >     >
> >     > For example, would the meaning of a fixed-effect coef. for
> variable X
> >     > change if it has a corresponding random-effect in the model vs.
> >     when it
> >     > doesn't, or if we allow X to vary across levels of 1 grouping
> >     variable (X |
> >     > ID1) vs. those of 2 nested grouping variables (X | ID1/ID2)?
> >     >
> >     > Many thanks for helping me understand this better,
> >     > Simon
> >     >
> >     >       [[alternative HTML version deleted]]
> >     >
> >     > _______________________________________________
> >     > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     >
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From biii m@iii@g oii de@@ey@ws  Sat Aug 14 13:56:47 2021
From: biii m@iii@g oii de@@ey@ws (biii m@iii@g oii de@@ey@ws)
Date: Sat, 14 Aug 2021 07:56:47 -0400
Subject: [R-sig-ME] General Mispredictions of New Levels in nlme Package
 Models
Message-ID: <030901d79103$763e1af0$62ba50d0$@denney.ws>

Hello,

 

TLDR:  When given the same number of levels of a factor, it appears that all
nlme contrast handling doesn't check the levels themselves-just the number
of levels.  So, if levels c("A", "B") are fit, and a prediction occurs on
levels c("C", "D"), the prediction will assign predictions for "C" to "A"
and "D" to "B".  I believe that nlme should be checking the levels of
contrasts and not just the number of contrasts.

 

More info:

In a way that is somewhat related to my question from last week about
handling levels in nlme
(https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029663.html), I
have a bigger concern that came back to mind while working through those
issues.  I reported the below issue with contrast handling to Bugzilla a few
years ago (https://bugs.r-project.org/show_bug.cgi?id=17228), but I now
realize that it is more generalized within nlme.

 

I have illustrated this within gnls() and lme() below.  From the r-sig-mixed
thread linked above, it also applies to nlme().  So, I assume that it
applies to all contrast handling within nlme.

 

I assume that the fix relates to checking the names and order of contrasts,
but as I tried to follow the code within the package for it, I got a bit
lost along the way.  What is the best way to cause this to issue an error or
to have it do more detailed contrast level checking?

 

Thanks,

 

Bill

 

``` r

library(nlme)

d.mod <- mtcars

d.mod$gear <- factor(d.mod$gear)

 

mymod <-

  gnls(mpg~e.gear*disp,

       data=d.mod,

       params=e.gear~gear,

       start=rep(0.1, nlevels(d.mod$gear)))

summary(mymod)

#> Generalized nonlinear least squares fit

#>   Model: mpg ~ e.gear * disp 

#>   Data: d.mod 

#>        AIC      BIC    logLik

#>   248.5394 254.4023 -120.2697

#> 

#> Coefficients:

#>                         Value   Std.Error  t-value p-value

#> e.gear.(Intercept) 0.04386917 0.008303409 5.283272  0.0000

#> e.gear.gear4       0.12854341 0.025849086 4.972842  0.0000

#> e.gear.gear5       0.02942924 0.022995432 1.279787  0.2108

#> 

#>  Correlation: 

#>              e..(I) e.gr.4

#> e.gear.gear4 -0.321       

#> e.gear.gear5 -0.361  0.116

#> 

#> Standardized residuals:

#>        Min         Q1        Med         Q3        Max 

#> -1.0180679 -0.4677616  0.1612978  0.8554800  2.1495935 

#> 

#> Residual standard error: 10.89942 

#> Degrees of freedom: 32 total; 29 residual

 

# Fails "contrasts can be applied only to factors with 2 or more levels"

predict(mymod, newdata=data.frame(disp=100, gear=factor("3")))

#> Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]):
contrasts can be applied only to factors with 2 or more levels

# Fails "Error in p %*% beta[pmap[[nm]]] : non-conformable arguments"

predict(mymod, newdata=data.frame(disp=100, gear=factor(c("3", "4"))))

#> Error in p %*% beta[pmap[[nm]]]: non-conformable arguments

# Succeeds

predict(mymod, newdata=data.frame(disp=100, gear=factor(c("3", "4", "5"))))

#>         1         2         3 

#>  4.386917 17.241258  7.329842 

#> attr(,"label")

#> [1] "Predicted values"

# Should fail but does not!

predict(mymod, newdata=data.frame(disp=100, gear=factor(c("6", "7", "8"))))

#>         1         2         3 

#>  4.386917 17.241258  7.329842 

#> attr(,"label")

#> [1] "Predicted values"

 

# Unique levels are "Male" and "Female" for 'Sex'

unique(Orthodont$Sex)

#> [1] Male   Female

#> Levels: Male Female

fm2 <- lme(distance ~ age + Sex, data = Orthodont, random = ~ 1)

summary(fm2)

#> Linear mixed-effects model fit by REML

#>   Data: Orthodont 

#>        AIC      BIC    logLik

#>   447.5125 460.7823 -218.7563

#> 

#> Random effects:

#>  Formula: ~1 | Subject

#>         (Intercept) Residual

#> StdDev:    1.807425 1.431592

#> 

#> Fixed effects:  distance ~ age + Sex 

#>                 Value Std.Error DF   t-value p-value

#> (Intercept) 17.706713 0.8339225 80 21.233044  0.0000

#> age          0.660185 0.0616059 80 10.716263  0.0000

#> SexFemale   -2.321023 0.7614168 25 -3.048294  0.0054

#>  Correlation: 

#>           (Intr) age   

#> age       -0.813       

#> SexFemale -0.372  0.000

#> 

#> Standardized Within-Group Residuals:

#>         Min          Q1         Med          Q3         Max 

#> -3.74889609 -0.55034466 -0.02516628  0.45341781  3.65746539 

#> 

#> Number of Observations: 108

#> Number of Groups: 27

predict(fm2, newdata=data.frame(age=1:10, Sex="non-binary"), level=0)

#> Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]):
contrasts can be applied only to factors with 2 or more levels

# Should fail because the levels of Sex are not the same as the original 

predict(fm2, newdata=data.frame(age=1:10, Sex=c("trans", "non-binary")),
level=0)

#>  [1] 16.04588 19.02708 17.36625 20.34745 18.68662 21.66782 20.00699
22.98819

#>  [9] 21.32736 24.30856

#> attr(,"label")

#> [1] "Predicted values"

```

 

<sup>Created on 2021-08-14 by the [reprex
package](https://reprex.tidyverse.org) (v2.0.0)</sup>


	[[alternative HTML version deleted]]


From |@|ozo||ve|r@ @end|ng |rom gm@||@com  Mon Aug 16 22:17:30 2021
From: |@|ozo||ve|r@ @end|ng |rom gm@||@com (Laio Zimermann Oliveira)
Date: Mon, 16 Aug 2021 17:17:30 -0300
Subject: [R-sig-ME] Modest questions about mixed-effect model and
 correlation structure
Message-ID: <CAM=xsWw4nZ=OvTxF_7nkAineiqJ8FPQKhZJh1+uu28d4u02OhA@mail.gmail.com>

Dear Dr. Ben Bolker,

I have a dataset of stem volume of individual trees gathered on 154 sample
plots in the subtropical Brazilian Atlantic Forest, where 1 to 20 trees had
their volume determined per plot; the total sample size is n = 1,192. I
need to fit a model to predict the stem volume (V) of ~30,000 trees
measured on 192 plots each with an area of 0.4 ha using diameter at breast
height (D) and stem height (H) as predictor variables. I fitted a
fixed-effect only power model with the following command:

M1 <- nlme(V ~ b0*(D^b1)*(H^b2), start=start, fixed=b0+b1+b2~1, groups=~g,
weights=varPower(form=~D), data=data)

My questions are:

1) I believe I should incorporate correlation among trees from the same
plot into the model. I don't mean spatial correlation. How could I do this?
The problem is that I have just a few trees on certain plots.

2) Suppose I fit M1 with random intercepts for each plot to relax the
assumption of residual independency (correct me if I shouldn't do it). Is
there a problem using just the fixed-effects part of the model to
predict stem volume of the trees on the 192 sample plots? I ask this
because data to fit the model were gathered on 154 among 192 plots, and I
need to consider all plots to generate population estimates of mean growing
stock volume per hectare.

Probably my questions are elementary, I'm sorry for that.

I appreciate your attention very much. Best regards.

	[[alternative HTML version deleted]]


From d@kot@judo @end|ng |rom m@c@com  Mon Aug 16 23:12:00 2021
From: d@kot@judo @end|ng |rom m@c@com (Peter Claussen)
Date: Mon, 16 Aug 2021 16:12:00 -0500
Subject: [R-sig-ME] Question about flexible LME4 Variance-Covariance
 Structure
In-Reply-To: <789FFEFE-3CD6-4DC1-AABD-9FBDD09DF751@contoso.com>
References: <789FFEFE-3CD6-4DC1-AABD-9FBDD09DF751@contoso.com>
Message-ID: <B3C115B7-81CE-4286-899E-A44FEF61226C@mac.com>

Jared,

I?ll preface this by saying I?m the biometrician for GDM Solutions, and we provide software for managing agronomic trials. Our software is used by a wide range of scientists, many who collaborate with companies like BCS (and, IIRC, BCS holds a large number of licenses for our software). I think I?m familiar with the type of problem you?re trying to solve. We provide an interface for diagnostic screening of individual trials, including RCB designs, and we use R as the computational engine; we also write R scripts programmatically for independent analysis.

That said, I wouldn?t use lmer for this. I think lme might give you what you?re looking for. Try


lme(NUM_VALUE ~ TREATMENT, random =  ~ 1 | BlockingName, data = zdf, weights=varIdent(form= ~ 1| BlockingName)


I would avoid specifying TREATMENT as a random effect to ?trick? lmer into calculating variances. You might get numbers, but they don?t correspond to the correct model, so you really can?t be certain the variances are correct. The code I?ve given above should allow you to keep TREATMENT as fixed but will give ratios of residual variance within replicates. From an example trial, I get,


Linear mixed-effects model fit by REML
  Data: ARMdata 
  Log-restricted-likelihood: 5.914592
  Fixed: assessment18 ~ treatment 
(Intercept)  treatment2  treatment3  treatment4  treatment5  treatment6  treatment7  treatment8  treatment9 treatment10 
  0.9841966  -0.8691926  -0.8234544  -0.9225589  -0.9772064  -0.8645547  -0.9772064  -0.9772064  -0.9772064  -0.7643471 
treatment11 treatment12 
 -0.9657557  -0.9772064 

Random effects:
 Formula: ~1 | replicate
        (Intercept) Residual
StdDev:  0.02308651 0.134405

Variance function:
 Structure: Different standard deviations per stratum
 Formula: ~1 | replicate 
 Parameter estimates:
        1         2         3         4         5         6 
1.0000000 1.5128266 2.3479912 0.6976083 2.3369190 0.8236288 
Number of Observations: 72
Number of Groups: 6 


I?m making some assumptions about what you intend to do with the variances, but those would be beyond the scope of this group, I think. You can direct questions relating to those assumptions to me at Pete at gdmdata.com <mailto:Pete at gdmdata.com>

Cheers,


> On Aug 11, 2021, at 6:19 PM, Jared Anderson <jared.anderson.ext at bayer.com> wrote:
> 
> Hello All,
> 
> I am a Data Scientist with Bayer Crop Science and I deal often with generalized linear mixed models in my role. I am new to this subscription group and wanted to reach out because I am trying to fit two different kinds of models on the same data and use their residual variances as a statistic for assessing data quality.
> For our variance-ratio statistic, two slightly different linear models are used. Both models are simple single treatment factor randomized complete block design models. The difference is in the assumed covariance structure of the residuals.
> The first model makes the standard assumption that the residuals all have the same variance, while the second model assumes that the residuals variances differ from rep to rep.
> Model 1: y = m + T + R + e, where m = overall mean, T = treatment effect, R = blocking effect and e = random error which is assumed to be homoschedastic: cov(e) = common variance*I = Diag(common variance).
> Model 2: y = m + T + R + e, where m = overall mean, T = treatment effect, R = blocking effect and e = random error which is assumed to be heteroschedastic: cov(e) = D(var[i]) i=1, ?, number of reps. The variance of the residuals is different for each rep.
> VR[i] = var[i]/common variance, one VR value for each rep.
> 
> I have been able to build the desired Model1 in LME4
> Formula_LME4 <- as.formula(paste0(zParams$value,? ~ 1 + (1|?,zParams$factorLevelId,?) + (1|?BlockingName,?)?))
> HomoS_LME4 <- lmer(Formula_LME4,data=zdf) #covariance structure is the same for all reps
> (Treating the fixed effects (factorLevelId) as random is a way to trick the routines into calculating the needed variances.)
> 
> 
> Where I am running into a problem and was hoping to get your advice: I cannot seem to implement Model 2 successfully
> I think the LME4 Heteroscedastic formula is supposed to be this, if I understand it correctly:
> lmer(NUM_VALUE ~ 1 + (1 | TREATMENT) + (1 | BlockingName) + (0 | BlockingName),data=zdf)
> But it is throwing an error:
> Linear mixed model fit by REML ['lmerMod']
> Formula: NUM_VALUE ~ 1 + (1 | TREATMENT) + (1 | BlockingName) + (0 | BlockingName)
>   Data: zdf
> REML criterion at convergence: 1384.89
> Error in thl[[i]] : subscript out of bounds
> And I was wondering if you?ve ever come across the error above?
> 
> 
> If it helps, back when we leveraged Asreml licenses for our work, I was able to generate Model 2 this way:
> 
> fixedFormula_ASREML <- as.formula(paste0(zParams$value," ~ 1"))
> randomFormula_ASREML <- as.formula(paste0(" ~ ",zParams$factorLevelId," + ", BlockingName))
> covFormula_ASREML    <- as.formula(paste0(" ~ at(", BlockingName, "):units"))
> 
> HeteroS_ASREML <- asreml(fixed  = fixedFormula_ASREML,
>                  random = randomFormula_ASREML,
>                  rcov   = covFormula_ASREML,
>                  data   = zdf)
> 
> 
> Best,
> Jared A.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Mon Aug 16 23:18:43 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 16 Aug 2021 17:18:43 -0400
Subject: [R-sig-ME] Question about flexible LME4 Variance-Covariance
 Structure
In-Reply-To: <B3C115B7-81CE-4286-899E-A44FEF61226C@mac.com>
References: <789FFEFE-3CD6-4DC1-AABD-9FBDD09DF751@contoso.com>
 <B3C115B7-81CE-4286-899E-A44FEF61226C@mac.com>
Message-ID: <ffc9fbe0-ecc3-a31f-e78b-7394528db7dc@gmail.com>

   I agree that the 'hack' is suboptimal.  It can be done if you set up 
a bunch of dummy variables **and** use the lowest-variance group as the 
reference, e.g.

   NUM_VALUE ~ TREATMENT + (1|block) + (0+block2dummy|obs) + (0 + 
block3dummy|obs) + ...

   This is ugly (but can be automated); I think it *is* the correct 
model, but reconstructing the residual variances for each block is a 
nuisance.

   glmmTMB can also  do dispersion models, via

glmmTMB(NUM_VALUE ~ TREATMENT + (1|block), dispformula  = ~ block, ...)


   cheers
    Ben Bolker


On 8/16/21 5:12 PM, Peter Claussen via R-sig-mixed-models wrote:
> Jared,
> 
> I?ll preface this by saying I?m the biometrician for GDM Solutions, and we provide software for managing agronomic trials. Our software is used by a wide range of scientists, many who collaborate with companies like BCS (and, IIRC, BCS holds a large number of licenses for our software). I think I?m familiar with the type of problem you?re trying to solve. We provide an interface for diagnostic screening of individual trials, including RCB designs, and we use R as the computational engine; we also write R scripts programmatically for independent analysis.
> 
> That said, I wouldn?t use lmer for this. I think lme might give you what you?re looking for. Try
> 
> 
> lme(NUM_VALUE ~ TREATMENT, random =  ~ 1 | BlockingName, data = zdf, weights=varIdent(form= ~ 1| BlockingName)
> 
> 
> I would avoid specifying TREATMENT as a random effect to ?trick? lmer into calculating variances. You might get numbers, but they don?t correspond to the correct model, so you really can?t be certain the variances are correct. The code I?ve given above should allow you to keep TREATMENT as fixed but will give ratios of residual variance within replicates. From an example trial, I get,
> 
> 
> Linear mixed-effects model fit by REML
>    Data: ARMdata
>    Log-restricted-likelihood: 5.914592
>    Fixed: assessment18 ~ treatment
> (Intercept)  treatment2  treatment3  treatment4  treatment5  treatment6  treatment7  treatment8  treatment9 treatment10
>    0.9841966  -0.8691926  -0.8234544  -0.9225589  -0.9772064  -0.8645547  -0.9772064  -0.9772064  -0.9772064  -0.7643471
> treatment11 treatment12
>   -0.9657557  -0.9772064
> 
> Random effects:
>   Formula: ~1 | replicate
>          (Intercept) Residual
> StdDev:  0.02308651 0.134405
> 
> Variance function:
>   Structure: Different standard deviations per stratum
>   Formula: ~1 | replicate
>   Parameter estimates:
>          1         2         3         4         5         6
> 1.0000000 1.5128266 2.3479912 0.6976083 2.3369190 0.8236288
> Number of Observations: 72
> Number of Groups: 6
> 
> 
> I?m making some assumptions about what you intend to do with the variances, but those would be beyond the scope of this group, I think. You can direct questions relating to those assumptions to me at Pete at gdmdata.com <mailto:Pete at gdmdata.com>
> 
> Cheers,
> 
> 
>> On Aug 11, 2021, at 6:19 PM, Jared Anderson <jared.anderson.ext at bayer.com> wrote:
>>
>> Hello All,
>>
>> I am a Data Scientist with Bayer Crop Science and I deal often with generalized linear mixed models in my role. I am new to this subscription group and wanted to reach out because I am trying to fit two different kinds of models on the same data and use their residual variances as a statistic for assessing data quality.
>> For our variance-ratio statistic, two slightly different linear models are used. Both models are simple single treatment factor randomized complete block design models. The difference is in the assumed covariance structure of the residuals.
>> The first model makes the standard assumption that the residuals all have the same variance, while the second model assumes that the residuals variances differ from rep to rep.
>> Model 1: y = m + T + R + e, where m = overall mean, T = treatment effect, R = blocking effect and e = random error which is assumed to be homoschedastic: cov(e) = common variance*I = Diag(common variance).
>> Model 2: y = m + T + R + e, where m = overall mean, T = treatment effect, R = blocking effect and e = random error which is assumed to be heteroschedastic: cov(e) = D(var[i]) i=1, ?, number of reps. The variance of the residuals is different for each rep.
>> VR[i] = var[i]/common variance, one VR value for each rep.
>>
>> I have been able to build the desired Model1 in LME4
>> Formula_LME4 <- as.formula(paste0(zParams$value,? ~ 1 + (1|?,zParams$factorLevelId,?) + (1|?BlockingName,?)?))
>> HomoS_LME4 <- lmer(Formula_LME4,data=zdf) #covariance structure is the same for all reps
>> (Treating the fixed effects (factorLevelId) as random is a way to trick the routines into calculating the needed variances.)
>>
>>
>> Where I am running into a problem and was hoping to get your advice: I cannot seem to implement Model 2 successfully
>> I think the LME4 Heteroscedastic formula is supposed to be this, if I understand it correctly:
>> lmer(NUM_VALUE ~ 1 + (1 | TREATMENT) + (1 | BlockingName) + (0 | BlockingName),data=zdf)
>> But it is throwing an error:
>> Linear mixed model fit by REML ['lmerMod']
>> Formula: NUM_VALUE ~ 1 + (1 | TREATMENT) + (1 | BlockingName) + (0 | BlockingName)
>>    Data: zdf
>> REML criterion at convergence: 1384.89
>> Error in thl[[i]] : subscript out of bounds
>> And I was wondering if you?ve ever come across the error above?
>>
>>
>> If it helps, back when we leveraged Asreml licenses for our work, I was able to generate Model 2 this way:
>>
>> fixedFormula_ASREML <- as.formula(paste0(zParams$value," ~ 1"))
>> randomFormula_ASREML <- as.formula(paste0(" ~ ",zParams$factorLevelId," + ", BlockingName))
>> covFormula_ASREML    <- as.formula(paste0(" ~ at(", BlockingName, "):units"))
>>
>> HeteroS_ASREML <- asreml(fixed  = fixedFormula_ASREML,
>>                   random = randomFormula_ASREML,
>>                   rcov   = covFormula_ASREML,
>>                   data   = zdf)
>>
>>
>> Best,
>> Jared A.
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics


From r_1470 @end|ng |rom y@hoo@co@uk  Wed Aug 18 12:51:42 2021
From: r_1470 @end|ng |rom y@hoo@co@uk (r_1470)
Date: Wed, 18 Aug 2021 10:51:42 +0000 (UTC)
Subject: [R-sig-ME] Proportion response data in MCMCglmm (or INLA)
 phylogenetic mixed model
References: <1079965613.1043846.1629283902861.ref@mail.yahoo.com>
Message-ID: <1079965613.1043846.1629283902861@mail.yahoo.com>

Hi all,
I'm attempting to run a phylogenetic comparative analysis for which the response variable is a proportion, and I want to estimate the effect of one or more predictors while controlling for phylogenetic non-independence. I would like to use MCMCglmm, and the basic model would be (ignoring the 'family' argument for now):
MCMCglmm(phenotype ~ x, random=~taxon + id + species, ginverse=list(taxon=Ainv),data=data, prior=prior)

'x' is an experimental treatment, but a more complex fixed-effects model with factors and continuous covariates is likely to be used. There's both a pre- and a post-treatment measure for most individuals ('id' refers to individual), and multiple individuals per species in many cases ('species' is intended to estimate non-phylogenetic among-species variation).
However, MCMCglmm doesn't include beta family models. My question is: can I usefully run this analysis in MCMCglmm and interpret the coefficients, either by assuming gaussian family, or by logit-transforming the proportions, or by using another family? Most of the proportions are intermediate, which might be helpful, although there are a fair number between 0.1 - 0.01.
I tried to replicate the model formula in other packages that allow beta-distributed variables (although I simulated data with gaussian errors for now, for direct comparison with MCMCglmm), but so far have been unable to either get reliable convergence (brms) or produce even qualitatively similar estimates on simulated datasets (INLA and phyr with bayes=T, although I only compared many datasets with INLA). For INLA, among other attempts I copied one of the model formulae used by animalINLA (the one using model="generic2"), but given the vastly different results from MCMCglmm for both the phylogenetic effect and the fixed effect, I'm left with the impression that INLA is doing something conceptually different to MCMCglmm.
For INLA, I used the inverse matrix produced by MCMCglmm::inverseA, but only including tips and with rownames 1:N to match a numeric 'taxonN' variable in the data table.
Back to my basic question: can I usefully analyse my proportion data with MCMCglmm?
Best wishes,
Richard.
	[[alternative HTML version deleted]]


From Am|r@N@j@||M@rghm@|ek| @end|ng |rom @tudent@ut@@edu@@u  Fri Aug 20 01:27:19 2021
From: Am|r@N@j@||M@rghm@|ek| @end|ng |rom @tudent@ut@@edu@@u (Amir Najafi Marghmaleki)
Date: Thu, 19 Aug 2021 23:27:19 +0000
Subject: [R-sig-ME] Heteroskedasticity & Serial Correlation in Linear Mixed
 Models (lmer)
Message-ID: <SYBPR01MB70980A227DBC2B26D062F99BEBC09@SYBPR01MB7098.ausprd01.prod.outlook.com>

Hi,
The errors terms of this LMM example is heteroskedastic and almost certainly serially correlated:
    if (!require("pacman")) install.packages("pacman")

    pacman::p_load(lme4)

    library(gapminder)

    fit.lmm <- lmer( log(lifeExp) ~ log(pop) + log(gdpPercap) +
                   (1|year) + (1|country), data = gapminder)

    plot(fit.lmm)

Is there a way to deal with heteroskedasticity, serial correlation & cross-sectional dependence in linear mixed models?

Regards,


Amir Najafi | PhD Candidate (Political Economy)
University of Technology Sydney
amir.najafi at student.uts.edu.au<mailto:amir.najafi at student.uts.edu.au>



	[[alternative HTML version deleted]]


From p|erre@dev|||emereu|| @end|ng |rom ephe@p@|@eu  Fri Aug 20 13:57:05 2021
From: p|erre@dev|||emereu|| @end|ng |rom ephe@p@|@eu (Pierre de Villemereuil)
Date: Fri, 20 Aug 2021 13:57:05 +0200
Subject: [R-sig-ME] Proportion response data in MCMCglmm (or INLA)
 phylogenetic mixed model
In-Reply-To: <1079965613.1043846.1629283902861@mail.yahoo.com>
References: <1079965613.1043846.1629283902861.ref@mail.yahoo.com>
 <1079965613.1043846.1629283902861@mail.yahoo.com>
Message-ID: <2050528.UNZtxbQeiK@flyosyoga>

Hi,

If you want to fit a phylogenetic mixed model with a beta distribution, you can use brms, which allows for both features:
https://cran.r-project.org/web/packages/brms/vignettes/brms_customfamilies.html
https://cran.r-project.org/web/packages/brms/vignettes/brms_phylogenetics.html

Cheers,
Pierre

Le mercredi 18 ao?t 2021, 12:51:42 CEST r_1470 via R-sig-mixed-models a ?crit :
> Hi all,
> I'm attempting to run a phylogenetic comparative analysis for which the response variable is a proportion, and I want to estimate the effect of one or more predictors while controlling for phylogenetic non-independence. I would like to use MCMCglmm, and the basic model would be (ignoring the 'family' argument for now):
> MCMCglmm(phenotype ~ x, random=~taxon + id + species, ginverse=list(taxon=Ainv),data=data, prior=prior)
> 
> 'x' is an experimental treatment, but a more complex fixed-effects model with factors and continuous covariates is likely to be used. There's both a pre- and a post-treatment measure for most individuals ('id' refers to individual), and multiple individuals per species in many cases ('species' is intended to estimate non-phylogenetic among-species variation).
> However, MCMCglmm doesn't include beta family models. My question is: can I usefully run this analysis in MCMCglmm and interpret the coefficients, either by assuming gaussian family, or by logit-transforming the proportions, or by using another family? Most of the proportions are intermediate, which might be helpful, although there are a fair number between 0.1 - 0.01.
> I tried to replicate the model formula in other packages that allow beta-distributed variables (although I simulated data with gaussian errors for now, for direct comparison with MCMCglmm), but so far have been unable to either get reliable convergence (brms) or produce even qualitatively similar estimates on simulated datasets (INLA and phyr with bayes=T, although I only compared many datasets with INLA). For INLA, among other attempts I copied one of the model formulae used by animalINLA (the one using model="generic2"), but given the vastly different results from MCMCglmm for both the phylogenetic effect and the fixed effect, I'm left with the impression that INLA is doing something conceptually different to MCMCglmm.
> For INLA, I used the inverse matrix produced by MCMCglmm::inverseA, but only including tips and with rownames 1:N to match a numeric 'taxonN' variable in the data table.
> Back to my basic question: can I usefully analyse my proportion data with MCMCglmm?
> Best wishes,
> Richard.
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 


From Amirhossei@@Amirhossei@T@iebi m@iii@g oii r@dboudumc@@i  Fri Aug 20 17:14:03 2021
From: Amirhossei@@Amirhossei@T@iebi m@iii@g oii r@dboudumc@@i (Amirhossei@@Amirhossei@T@iebi m@iii@g oii r@dboudumc@@i)
Date: Fri, 20 Aug 2021 15:14:03 +0000
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 176, Issue 4
In-Reply-To: <mailman.19332.3.1628071201.45489.r-sig-mixed-models@r-project.org>
References: <mailman.19332.3.1628071201.45489.r-sig-mixed-models@r-project.org>
Message-ID: <1629472443431.89261@radboudumc.nl>

Dear Philip , Thierry, Ben and other list followers,

Thanks for your response.
Maybe the following codes can help you get a feel of the data that I am using, due to working in a cloud server I cannot share the real data I use. I also shared the latest models formula I tried to run but every time I have convergence problems :-(

set.seed(1)
df<-data.frame(id=rep(1:3,each=4),treatment=sample(c(0,1),12,replace = T),
               event=sample(c(0,1),12,replace = T),
               person.time=sample(c(15,31,30),12,replace = T),
               age=rep(c(65,58,74),each=4),gender=rep(c("m","f","m"),each=4))
df$person.time<-ave(df$person.time,df$id,FUN = cumsum)
df$logtime<-log(df$person.time)
# codes for model:
library(lme4)
nbm<-glmer.nb(event~treatment+age+gender+offset(logtime)+(1|id),df,glmerControl(optCtrl = list(maxfun=50)),verbose = T)
#END.


Please note that in data an individual can have multiple events over time and the treatment is a time variant variable; in real data I do not have complete separation problem.

Bests, Amir

________________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of r-sig-mixed-models-request at r-project.org <r-sig-mixed-models-request at r-project.org>
Sent: Wednesday, August 4, 2021 12:00 PM
To: r-sig-mixed-models at r-project.org
Subject: R-sig-mixed-models Digest, Vol 176, Issue 4

Send R-sig-mixed-models mailing list submissions to
        r-sig-mixed-models at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
        https://eur02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Camirhossein.amirhosseintalebi%40radboudumc.nl%7C06b1d8846f0d454b11f908d9572ecf29%7Cb208fe69471e48c48d87025e9b9a157f%7C1%7C0%7C637636680823457341%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=xIoOcJB0H2C4oijXwXBbg9Wajk%2FdOFT7zB48skRVRL0%3D&amp;reserved=0
or, via email, send a message with subject or body 'help' to
        r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
        r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

   1. Re: Theta Value in glmer (Ben Bolker)

----------------------------------------------------------------------

Message: 1
Date: Tue, 3 Aug 2021 18:23:20 -0400
From: Ben Bolker <bbolker at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Theta Value in glmer
Message-ID: <cc456f6e-32b1-6a0a-dc98-91e9423fd11a at gmail.com>
Content-Type: text/plain; charset="utf-8"; Format="flowed"

    I also don't really know what's going on here.

Some thoughts:

    * for NB fits, glmmTMB, which is a bit faster & more stable than
glmer for this special case (and is pretty nearly a drop-in replacement
for glmer.nb)
    * A common case of convergence problems for NB models is when you
try to fit data that are equi-dispersed or underdispersed (conditional
variance <= mean rather than >mean), in which case the theta coefficient
gets very large (and the likelihood surface gets very flat).  In this
case you're better of with a Poisson model anyway ...
    * Not sure what you mean by "the vignette of glmer" - there isn't
any vignette describing glmer in the lme4 package AFAIK ...

On 8/3/21 4:39 PM, Phillip Alday wrote:
> Hi Amir,
>
> can you share an anonymized version of your data? Or give a bit more of
> a minimal working example (MWE)? Then we can probably provide more and
> better help. :)
>
> Best,
> Phillip
>
> On 17/07/2021 01:22, Amirhossein.AmirhosseinTalebi at radboudumc.nl wrote:
>> Dear all,
>>
>> I am trying to fit a negative binomial regression using lme4 package. After several attempts using glmer.nb and having error of convergence, I have switched to glmer function to could set the argument nAGQ=0 and used negative binomial function as the family argument.
>> The question here is, as the theta value in negative binomial function I tried to use the theta value that glm.nb of package MASS gave me (157); but based on the vignette of glmer I can use theta=1.75. Could you please clarify that how can I choose the best theta value here and until what extend that can change my results? Or based on what parameter in model output I can understand that I used the best theta value?
>>
>> Kind regards,
>> Amir
>>
>> De informatie in dit bericht is uitsluitend bestemd voor de geadresseerde. Aan dit bericht en de bijlagen kunnen geen rechten worden ontleend. Heeft u deze e-mail onbedoeld ontvangen? Dan verzoeken wij u het te vernietigen en de afzender te informeren. Openbaar maken, kopi?ren en verspreiden van deze e-mail of informatie uit deze e-mail is alleen toegestaan met voorafgaande schriftelijke toestemming van de afzender. Het Radboudumc staat geregistreerd bij de Kamer van Koophandel in het handelsregister onder nummer 80262783.
>>
>> The content of this message is intended solely for the addressee. No rights can be derived from this message or its attachments. If you are not the intended recipient, we kindly request you to delete the message and inform the sender. It is strictly prohibited to disclose, copy or distribute this email or the information inside it, without a written consent from the sender. Radboud university medical center is registered with the Dutch Chamber of Commerce trade register with number 80262783.
>>
>>      [[alternative HTML version deleted]]
>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://eur02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Camirhossein.amirhosseintalebi%40radboudumc.nl%7C06b1d8846f0d454b11f908d9572ecf29%7Cb208fe69471e48c48d87025e9b9a157f%7C1%7C0%7C637636680823457341%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=xIoOcJB0H2C4oijXwXBbg9Wajk%2FdOFT7zB48skRVRL0%3D&amp;reserved=0
>
>       [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://eur02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Camirhossein.amirhosseintalebi%40radboudumc.nl%7C06b1d8846f0d454b11f908d9572ecf29%7Cb208fe69471e48c48d87025e9b9a157f%7C1%7C0%7C637636680823457341%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=xIoOcJB0H2C4oijXwXBbg9Wajk%2FdOFT7zB48skRVRL0%3D&amp;reserved=0
>

--
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics




------------------------------

Subject: Digest Footer

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://eur02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Camirhossein.amirhosseintalebi%40radboudumc.nl%7C06b1d8846f0d454b11f908d9572ecf29%7Cb208fe69471e48c48d87025e9b9a157f%7C1%7C0%7C637636680823457341%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=xIoOcJB0H2C4oijXwXBbg9Wajk%2FdOFT7zB48skRVRL0%3D&amp;reserved=0


------------------------------

End of R-sig-mixed-models Digest, Vol 176, Issue 4
**************************************************
De informatie in dit bericht is uitsluitend bestemd voor de geadresseerde. Aan dit bericht en de bijlagen kunnen geen rechten worden ontleend. Heeft u deze e-mail onbedoeld ontvangen? Dan verzoeken wij u het te vernietigen en de afzender te informeren. Openbaar maken, kopi?ren en verspreiden van deze e-mail of informatie uit deze e-mail is alleen toegestaan met voorafgaande schriftelijke toestemming van de afzender. Het Radboudumc staat geregistreerd bij de Kamer van Koophandel in het handelsregister onder nummer 80262783.

The content of this message is intended solely for the addressee. No rights can be derived from this message or its attachments. If you are not the intended recipient, we kindly request you to delete the message and inform the sender. It is strictly prohibited to disclose, copy or distribute this email or the information inside it, without a written consent from the sender. Radboud university medical center is registered with the Dutch Chamber of Commerce trade register with number 80262783.

From j@de@ @end|ng |rom he@|th@uc@d@edu  Fri Aug 20 20:46:01 2021
From: j@de@ @end|ng |rom he@|th@uc@d@edu (Ades, James)
Date: Fri, 20 Aug 2021 18:46:01 +0000
Subject: [R-sig-ME] MGCV Bam error
Message-ID: <DM6PR19MB3868501447C0A7537BFABBF0EAC19@DM6PR19MB3868.namprd19.prod.outlook.com>

Hi all,

In running bam(conn ~ region * timepoint + s(subjectID, bs = "re", by = timepoint) + s(subjectID, region, bs = "re", by = timepoint), data = tot.add.fil, method = "fREML", discrete=TRUE). I receive the following error.

Error in seq.default(xl[1], xl[2], length = m) :   'from' must be a finite numberIn addition: Warning message:In seq.default(xl[1], xl[2], length = m) : NAs introduced by coercion

Much thanks!

James

Googling this error will lead to warnings regarding the timepoint dummy coding (not explitly linked with multilevel modeling of mgcv). I double-checked timepoint in the dataset (using the same provided sample), and it seems that everything is defined correctly.

	[[alternative HTML version deleted]]


From mudryjm @end|ng |rom b|uew|n@ch  Wed Aug 25 17:03:18 2021
From: mudryjm @end|ng |rom b|uew|n@ch (mudryjm)
Date: Wed, 25 Aug 2021 17:03:18 +0200
Subject: [R-sig-ME] FW: Variogram / confint prediction in LMM / time
 prediction some questions from Switerland area
In-Reply-To: <CAO7JsnSYFTA9hTcN7B-6bY82T1+nRcdg9YYHykH0Lgq9MicRig@mail.gmail.com>
References: <30015_1627827956_0QX6009OT034UF10_03aa01d786e1$16bb82b0$44328810$@bluewin.ch>
 <CAO7JsnSYFTA9hTcN7B-6bY82T1+nRcdg9YYHykH0Lgq9MicRig@mail.gmail.com>
Message-ID: <0b4a01d799c2$56bb7570$04326050$@bluewin.ch>

 


Sent: Sunday, August 1, 2021 5:32 PM
To: mudryjm <mudryjm at bluewin.ch>
Subject: Re: Variogram / confint prediction in LMM / time prediction some questions from Switerland area

 

I regret that I am not able to answer your questions at this time.  It has been a couple of decades since I worked on the nlme package and I have not kept up with the literature.

 

I suggest that you send your questions to the R-SIG-Mixed-Models at R-project.org <mailto:R-SIG-Mixed-Models at R-project.org>  mailing list.  Some information about the list is available at https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

 

On Sun, Aug 1, 2021 at 9:25 AM mudryjm <mudryjm at bluewin.ch <mailto:mudryjm at bluewin.ch> > wrote:

Dear Mr Bates and Pinhero

Tks for your incredible packages in R I did my master in statistics (attached). I?m a big fan!

However I?m puzzled with several theoretical questions on some topic where I?m struggling; instead of luring for stat input I asks directly WIZARDS!:


Variograms (Cressie):P 52 PDF

I have done several variograms on my model residuals expecting flat line along (sill flat).However some patient are at sill some on the correlation path-slope.

Q:How to interpret? (Two class of patient with biophysical discerpancies?

Q:The smoother fitted in graph is the theoretical one (Theoretical variogram based on exp?spherical?)?? Or is it a simple smoother.

Q: Is it possible with variogram (within (patient and sampling error) cor + between from LMM variance) to forecast the best time for re-measure?
I.e in cholesterol study some authors demonstrated when intra- variability exceed between variability? So measuring on too short intervals has no value.But I don?t know how to proceed

Or do you had a good reference.?

 

Fiiting confindance bands on XB+ZU:

 

Q.I try to get con band for predictings patients trajectories. As they is no close form (at least very complex) is the better way to bootstrap some model and fit a bootstrap confint on the 1000 Fitted values? Or do you have a smplier function?

 

Q:If I should predict when time  will be  reached for a patient his Upper reference limit how do I have to proceed? (back reversing formula?)
Page 54 :patients prediction

Tks for your help in an old retrained statistician

 

NB Your contribution to staworld is fabulous and inspired me in my daily work since  a year!

:)

 

Veuillez recevoir mes sinc?res salutations , 

Sincerely,

 

Mudry Jean-Marie

8 ch du Ch?no

1802 CORSEAUX 

Switzerland

 

+41.79.708.87.15

+41.21.921.10.18.

 

 <https://www.linkedin.com/profile/view?id=AAIAAAQNN6kBw4M_5pbYY8UTDonpSQEhwi-7DHs&trk=nav_responsive_tab_profile_pic> LinkedIn  <https://twitter.com/mudryjm> Twitter  <https://twitter.com/mudryjm/status/750591764080291840> Last Publication

 


	[[alternative HTML version deleted]]


From |@08007 @end|ng |rom gm@||@com  Thu Aug 26 03:10:35 2021
From: |@08007 @end|ng |rom gm@||@com (=?UTF-8?B?5biC5bedIOa3sw==?=)
Date: Thu, 26 Aug 2021 10:10:35 +0900
Subject: [R-sig-ME] Advice for the R-package of lme4
Message-ID: <CAJQcLGO2yUz8B3LMic9xWBx06Y1t-iaZvhWKC6-nyG2nUGfUGA@mail.gmail.com>

Sorry for the sudden email.
I would like you to give me your advice.
This is my first post.

I have often used the package of lme4 and lmerTest to conduct a linear
mixed model analysis.
Meanwhile, I have been in trouble of which the values in the output are
slightly different between late April 2021 and August 2021.
The source code, R environment, and csv files are the same (R-3.6.1 in
Windows 10).

I surveyed and found out the following.
Around June 2020, (maybe) I installed lme4 1.1-23 and lmerTest 3.0-1.
I used these packages for a while; however I (maybe) updated lme4 1.1-26
and lmerTest 3.1-3 a few days ago (in August 2021).

I have checked the values of estimate, SE, p-value and so on in the output,
and have noticed that these were different between the packages mentioned
above.

Please advise me on the problem.
I uploaded samples of the source code and csv file.
https://drive.google.com/drive/folders/1gbP-Ib-nW7-zrmUyrpuLmbODCuw3Zuot?usp=sharing

I look forward to hearing from you.
Very sorry to bother you while you are busy, but I appreciate your
cooperation.

Best regards
Anonymity X

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Thu Aug 26 04:02:25 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 25 Aug 2021 22:02:25 -0400
Subject: [R-sig-ME] Advice for the R-package of lme4
In-Reply-To: <CAJQcLGO2yUz8B3LMic9xWBx06Y1t-iaZvhWKC6-nyG2nUGfUGA@mail.gmail.com>
References: <CAJQcLGO2yUz8B3LMic9xWBx06Y1t-iaZvhWKC6-nyG2nUGfUGA@mail.gmail.com>
Message-ID: <a01bd37f-be73-103e-4704-b609829ed691@gmail.com>

   If you want to check for yourself, you can retrieve older versions of 
the tarballs (.tar.gz files) from 
https://cran.r-project.org/src/contrib/Archive/lme4/

  Alternatively, if you install the 'remotes' package, you can use

remotes::install_version("lme4", "1.1-23")

- this basically automates the process of downloading the tarball and 
installing it.

  You *will* need development tools (compilers etc.) installed to do 
this (an alternative is to use the 'checkpoint' package to retrieve old 
package versions from MRAN (a versioned mirror of CRAN maintained by 
Microsoft).



On 8/25/21 9:10 PM, ?? ? wrote:
> Sorry for the sudden email.
> I would like you to give me your advice.
> This is my first post.
> 
> I have often used the package of lme4 and lmerTest to conduct a linear 
> mixed model analysis.
> Meanwhile, I have been in trouble of whichthe values in the output are 
> slightly different between late April 2021 and August 2021.
> The source code, R environment, and csv files are the same (R-3.6.1 in 
> Windows 10).
> 
> I surveyed and found out the following.
> Around June 2020, (maybe) I installed lme4 1.1-23 and lmerTest 3.0-1.
> I used these packages for a while; however I (maybe) updated lme4 1.1-26 
> and lmerTest 3.1-3 a few days ago (in August 2021).
> 
> I have checked the values of estimate, SE, p-value and so on in the 
> output, and have noticed that these were different between the packages 
> mentioned above.
> 
> Please advise me on the problem.
> I uploaded samples of the source code and csv file.
> https://drive.google.com/drive/folders/1gbP-Ib-nW7-zrmUyrpuLmbODCuw3Zuot?usp=sharing 
> <https://drive.google.com/drive/folders/1gbP-Ib-nW7-zrmUyrpuLmbODCuw3Zuot?usp=sharing>
> 
> I look forward to hearing from you.
> Very sorry to bother you while you are busy, but I appreciate your 
> cooperation.
> 
> Best regards
> Anonymity X

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics


From bbo|ker @end|ng |rom gm@||@com  Thu Aug 26 23:58:33 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 26 Aug 2021 17:58:33 -0400
Subject: [R-sig-ME] Advice for the R-package of lme4
In-Reply-To: <CAJQcLGOFQTyEvv30EnD_fkTxA_wfWMhLj=OTQKr-O1FdG+jjiQ@mail.gmail.com>
References: <CAJQcLGO2yUz8B3LMic9xWBx06Y1t-iaZvhWKC6-nyG2nUGfUGA@mail.gmail.com>
 <a01bd37f-be73-103e-4704-b609829ed691@gmail.com>
 <CAJQcLGOFQTyEvv30EnD_fkTxA_wfWMhLj=OTQKr-O1FdG+jjiQ@mail.gmail.com>
Message-ID: <f3514ebb-102c-f0d6-4f57-c29435c1730c@gmail.com>

   [Please keep r-sig-mixed-models at r-project.org in the Cc: list!]

   The warning message is *probably* irrelevant; to make it go away you 
would need to install the Matrix package from source on your machine 
(the binary packages on CRAN are built with the latest R version of a 
particular release series).

   A preliminary investigation on my side had the same general 
conclusions (fitting with 1.1-23 and 1.1-26 gave identical answers). I'm 
afraid that if you have tried with both versions of the package and 
can't replicate your former results exactly then, logically, *the 
lme4/lmerTest package versions cannot be the source of the problem*; 
some other aspect of your setup must have changed. Numerical 
computations are, unfortunately, subject to a great deal of 
(small-scale) instability due to changes in underlying linear algebra 
packages, compilers, etc..

  I'm not sure what else we can do to help.

   sincerely
    Ben Bolker

On 8/25/21 11:17 PM, ?? ? wrote:
> Thank you for your kind advice.
> 
> I installed the package of remotes and?compilers.
> I tried to analyze using the combination of? lme4 1.1-20, 1.1-21, 
> 1.1-23, or 1.1-25 and? lmerTest 3.0-1 or lmerTest 3.1-3;
> however,?I can't get the same results as before.
> 
> Incidentally, the following message is always displayed.
> 
> ====
> Warning message:
> Package 'Matrix' was built under R in version 3.6.3.
> //Actually, the message is in Japanese.
> =====
> 
> Very sorry to bother you while you are busy, but I appreciate your 
> cooperation.
> 
> Best regards
> Jun Ichikawa
> 
> 
> 2021?8?26?(?) 11:02 Ben Bolker <bbolker at gmail.com 
> <mailto:bbolker at gmail.com>>:
> 
>      ? ?If you want to check for yourself, you can retrieve older
>     versions of
>     the tarballs (.tar.gz files) from
>     https://cran.r-project.org/src/contrib/Archive/lme4/
>     <https://cran.r-project.org/src/contrib/Archive/lme4/>
> 
>      ? Alternatively, if you install the 'remotes' package, you can use
> 
>     remotes::install_version("lme4", "1.1-23")
> 
>     - this basically automates the process of downloading the tarball and
>     installing it.
> 
>      ? You *will* need development tools (compilers etc.) installed to do
>     this (an alternative is to use the 'checkpoint' package to retrieve old
>     package versions from MRAN (a versioned mirror of CRAN maintained by
>     Microsoft).
> 
> 
> 
>     On 8/25/21 9:10 PM, ?? ? wrote:
>      > Sorry for the sudden email.
>      > I would like you to give me your advice.
>      > This is my first post.
>      >
>      > I have often used the package of lme4 and lmerTest to conduct a
>     linear
>      > mixed model analysis.
>      > Meanwhile, I have been in trouble of whichthe values in the
>     output are
>      > slightly different between late April 2021 and August 2021.
>      > The source code, R environment, and csv files are the same
>     (R-3.6.1 in
>      > Windows 10).
>      >
>      > I surveyed and found out the following.
>      > Around June 2020, (maybe) I installed lme4 1.1-23 and lmerTest 3.0-1.
>      > I used these packages for a while; however I (maybe) updated lme4
>     1.1-26
>      > and lmerTest 3.1-3 a few days ago (in August 2021).
>      >
>      > I have checked the values of estimate, SE, p-value and so on in the
>      > output, and have noticed that these were different between the
>     packages
>      > mentioned above.
>      >
>      > Please advise me on the problem.
>      > I uploaded samples of the source code and csv file.
>      >
>     https://drive.google.com/drive/folders/1gbP-Ib-nW7-zrmUyrpuLmbODCuw3Zuot?usp=sharing
>     <https://drive.google.com/drive/folders/1gbP-Ib-nW7-zrmUyrpuLmbODCuw3Zuot?usp=sharing>
> 
>      >
>     <https://drive.google.com/drive/folders/1gbP-Ib-nW7-zrmUyrpuLmbODCuw3Zuot?usp=sharing
>     <https://drive.google.com/drive/folders/1gbP-Ib-nW7-zrmUyrpuLmbODCuw3Zuot?usp=sharing>>
>      >
>      > I look forward to hearing from you.
>      > Very sorry to bother you while you are busy, but I appreciate your
>      > cooperation.
>      >
>      > Best regards
>      > Anonymity X
> 
>     -- 
>     Dr. Benjamin Bolker
>     Professor, Mathematics & Statistics and Biology, McMaster University
>     Director, School of Computational Science and Engineering
>     Graduate chair, Mathematics & Statistics
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics


From |@08007 @end|ng |rom gm@||@com  Fri Aug 27 02:35:02 2021
From: |@08007 @end|ng |rom gm@||@com (ia08007)
Date: Fri, 27 Aug 2021 09:35:02 +0900
Subject: [R-sig-ME] Advice for the R-package of lme4
In-Reply-To: <f3514ebb-102c-f0d6-4f57-c29435c1730c@gmail.com>
References: <CAJQcLGO2yUz8B3LMic9xWBx06Y1t-iaZvhWKC6-nyG2nUGfUGA@mail.gmail.com>
 <a01bd37f-be73-103e-4704-b609829ed691@gmail.com>
 <CAJQcLGOFQTyEvv30EnD_fkTxA_wfWMhLj=OTQKr-O1FdG+jjiQ@mail.gmail.com>
 <f3514ebb-102c-f0d6-4f57-c29435c1730c@gmail.com>
Message-ID: <CAJQcLGMySWAa=ov+7MPUz9fD+XZ1Ki30H6aZrbQFwJv2DQd9ig@mail.gmail.com>

Dear Dr. Bolker

I appreciate your kind help.
I can identify the version of packages at that time.
lme4 was 1.1-23 and lmerTest was 3.1-2.

For reference, are there any other packages that might affect the results?
I have tried, but it seems that other packages would affect them.

Very sorry to bother you while you are busy, but I appreciate your
cooperation.

2021?8?27?(?) 6:58 Ben Bolker <bbolker at gmail.com>:

>    [Please keep r-sig-mixed-models at r-project.org in the Cc: list!]
>
>    The warning message is *probably* irrelevant; to make it go away you
> would need to install the Matrix package from source on your machine
> (the binary packages on CRAN are built with the latest R version of a
> particular release series).
>
>    A preliminary investigation on my side had the same general
> conclusions (fitting with 1.1-23 and 1.1-26 gave identical answers). I'm
> afraid that if you have tried with both versions of the package and
> can't replicate your former results exactly then, logically, *the
> lme4/lmerTest package versions cannot be the source of the problem*;
> some other aspect of your setup must have changed. Numerical
> computations are, unfortunately, subject to a great deal of
> (small-scale) instability due to changes in underlying linear algebra
> packages, compilers, etc..
>
>   I'm not sure what else we can do to help.
>
>    sincerely
>     Ben Bolker
>
>
>

	[[alternative HTML version deleted]]


From j-|ch|k@w@ @end|ng |rom k@n@g@w@-u@@c@jp  Fri Aug 27 02:52:17 2021
From: j-|ch|k@w@ @end|ng |rom k@n@g@w@-u@@c@jp (Jun ICHIKAWA)
Date: Fri, 27 Aug 2021 09:52:17 +0900
Subject: [R-sig-ME] Advice for the R-package of lme4
In-Reply-To: <CAJQcLGMySWAa=ov+7MPUz9fD+XZ1Ki30H6aZrbQFwJv2DQd9ig@mail.gmail.com>
References: <CAJQcLGO2yUz8B3LMic9xWBx06Y1t-iaZvhWKC6-nyG2nUGfUGA@mail.gmail.com>
 <a01bd37f-be73-103e-4704-b609829ed691@gmail.com>
 <CAJQcLGOFQTyEvv30EnD_fkTxA_wfWMhLj=OTQKr-O1FdG+jjiQ@mail.gmail.com>
 <f3514ebb-102c-f0d6-4f57-c29435c1730c@gmail.com>
 <CAJQcLGMySWAa=ov+7MPUz9fD+XZ1Ki30H6aZrbQFwJv2DQd9ig@mail.gmail.com>
Message-ID: <CAJQcLGNvFPkNHmuKf3o29bmjeX_aiiakEKKGFQjvfKbS43Ya5A@mail.gmail.com>

Sorry, in addition, I have something to know.

The following messages are presently displayed when both libraries of
lmerTest and lme4 were loaded in one program.

The following objects are masked from ?package: lme4?: lmer
The following objects are masked from ?package: stats?: step

It seems that I should specify which package (lme4 or lmerTest) to use the
function of lmer.
However, before this problem, such messages might not be displayed.
Is this related to the problem ?

Very sorry to bother you while you are busy, but I appreciate your
cooperation.

2021?8?27?(?) 9:35 ia08007 <ia08007 at gmail.com>:

> Dear Dr. Bolker
>
> I appreciate your kind help.
> I can identify the version of packages at that time.
> lme4 was 1.1-23 and lmerTest was 3.1-2.
>
> For reference, are there any other packages that might affect the results?
> I have tried, but it seems that other packages would affect them.
>
> Very sorry to bother you while you are busy, but I appreciate your
> cooperation.
>
> 2021?8?27?(?) 6:58 Ben Bolker <bbolker at gmail.com>:
>
>>    [Please keep r-sig-mixed-models at r-project.org in the Cc: list!]
>>
>>    The warning message is *probably* irrelevant; to make it go away you
>> would need to install the Matrix package from source on your machine
>> (the binary packages on CRAN are built with the latest R version of a
>> particular release series).
>>
>>    A preliminary investigation on my side had the same general
>> conclusions (fitting with 1.1-23 and 1.1-26 gave identical answers). I'm
>> afraid that if you have tried with both versions of the package and
>> can't replicate your former results exactly then, logically, *the
>> lme4/lmerTest package versions cannot be the source of the problem*;
>> some other aspect of your setup must have changed. Numerical
>> computations are, unfortunately, subject to a great deal of
>> (small-scale) instability due to changes in underlying linear algebra
>> packages, compilers, etc..
>>
>>   I'm not sure what else we can do to help.
>>
>>    sincerely
>>     Ben Bolker
>>
>>
>>

-- 
Jun ICHIKAWA, Ph.D (Information Science)
Assistant Professor
Department of Information Systems Creation
Faculty of Engineering, Kanagawa University
3-27-1, Rokkakubashi, Kanagawa-ku, Yokohama,
Kanagawa, 221-8686, JAPAN
E-mail?j-ichikawa at kanagawa-u.ac.jp
Researchmap?http://researchmap.jp/ichi-j0624

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Fri Aug 27 03:46:04 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 26 Aug 2021 21:46:04 -0400
Subject: [R-sig-ME] Advice for the R-package of lme4
In-Reply-To: <CAJQcLGMySWAa=ov+7MPUz9fD+XZ1Ki30H6aZrbQFwJv2DQd9ig@mail.gmail.com>
References: <CAJQcLGO2yUz8B3LMic9xWBx06Y1t-iaZvhWKC6-nyG2nUGfUGA@mail.gmail.com>
 <a01bd37f-be73-103e-4704-b609829ed691@gmail.com>
 <CAJQcLGOFQTyEvv30EnD_fkTxA_wfWMhLj=OTQKr-O1FdG+jjiQ@mail.gmail.com>
 <f3514ebb-102c-f0d6-4f57-c29435c1730c@gmail.com>
 <CAJQcLGMySWAa=ov+7MPUz9fD+XZ1Ki30H6aZrbQFwJv2DQd9ig@mail.gmail.com>
Message-ID: <d951b7f4-b635-1f66-2072-2e22d28834c6@gmail.com>

   Honestly, I don't really know what other change in your configuration 
could have led to the difference.  It would be more likely to be 
something else about your system - e.g. OS update with accompanying 
changes to the linear algebra libraries, etc..  It's almost impossible 
to diagnose these problems if they're not reproducible.

   sincerely
    Ben Bolker

On 8/26/21 8:35 PM, ia08007 wrote:
> Dear Dr. Bolker
> 
> I appreciate your kind help.
> I can identify the version of packages at that time.
> lme4 was 1.1-23 and lmerTest was 3.1-2.
> 
> For reference, are there any other packages that might affect the results?
> I have tried, but it seems that other packages would affect them.
> 
> Very sorry to bother you while you are busy, but I appreciate your 
> cooperation.
> 
> 2021?8?27?(?) 6:58 Ben Bolker <bbolker at gmail.com 
> <mailto:bbolker at gmail.com>>:
> 
>      ? ?[Please keep r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org> in the Cc: list!]
> 
>      ? ?The warning message is *probably* irrelevant; to make it go away
>     you
>     would need to install the Matrix package from source on your machine
>     (the binary packages on CRAN are built with the latest R version of a
>     particular release series).
> 
>      ? ?A preliminary investigation on my side had the same general
>     conclusions (fitting with 1.1-23 and 1.1-26 gave identical answers).
>     I'm
>     afraid that if you have tried with both versions of the package and
>     can't replicate your former results exactly then, logically, *the
>     lme4/lmerTest package versions cannot be the source of the problem*;
>     some other aspect of your setup must have changed. Numerical
>     computations are, unfortunately, subject to a great deal of
>     (small-scale) instability due to changes in underlying linear algebra
>     packages, compilers, etc..
> 
>      ? I'm not sure what else we can do to help.
> 
>      ? ?sincerely
>      ? ? Ben Bolker
> 
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics


From |@08007 @end|ng |rom gm@||@com  Fri Aug 27 09:09:10 2021
From: |@08007 @end|ng |rom gm@||@com (ia08007)
Date: Fri, 27 Aug 2021 16:09:10 +0900
Subject: [R-sig-ME] Advice for the R-package of lme4
In-Reply-To: <50c26250-b96a-0cac-2ecc-aa2035572d63@gmail.com>
References: <CAJQcLGO2yUz8B3LMic9xWBx06Y1t-iaZvhWKC6-nyG2nUGfUGA@mail.gmail.com>
 <a01bd37f-be73-103e-4704-b609829ed691@gmail.com>
 <CAJQcLGOFQTyEvv30EnD_fkTxA_wfWMhLj=OTQKr-O1FdG+jjiQ@mail.gmail.com>
 <f3514ebb-102c-f0d6-4f57-c29435c1730c@gmail.com>
 <CAJQcLGMySWAa=ov+7MPUz9fD+XZ1Ki30H6aZrbQFwJv2DQd9ig@mail.gmail.com>
 <CAJQcLGNvFPkNHmuKf3o29bmjeX_aiiakEKKGFQjvfKbS43Ya5A@mail.gmail.com>
 <50c26250-b96a-0cac-2ecc-aa2035572d63@gmail.com>
Message-ID: <CAJQcLGNLw5nSPDvCN+uRurb62q+GxAStOOMKX7VkkJVvYSQCyg@mail.gmail.com>

Thank you for your advice.
I appreciate your kindness.
Very sorry to bother you while you are busy.

I remembered making a backup of all R-packages before late April 2021.
Therefore, I loaded (downgraded) all packages and ran the program.
=====
Meanwhile, I have been in trouble of which the values in the output are
slightly different between late April 2021 and August 2021. The source
code, R environment, and csv files are the same (R-3.6.1 in Windows 10).
=====

For a different dataset made up before late April 2021, I could reproduce
the results.
So, the reason that I could not reproduce the results using the dataset,
which I posted you, seems that some problems have occurred in the period,
which I did not make a back up, such as OS update or consistency with other
packages.

I don't want to cause you any more trouble, so I'll do some more research
on my own for solving. Thank you very much.

Best regards

2021?8?27?(?) 10:48 Ben Bolker <bbolker at gmail.com>:

>    These are basically harmless.
>
>   lmerTest substitutes its own version of `lmer`. This is often
> confusing, but when it works it provides a seamless user experience
> (i.e., people load lmerTest and everything works the same but they also
> get denominator degrees of freedom and p-values in their summary tables).
>
>    It also defines its own version of 'step'.  You can see the help for
> `lmerTest::lmer` or `lmerTest::step` for an explanation of why these
> functions are masked.
>
>
> --
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> Graduate chair, Mathematics & Statistics
>

	[[alternative HTML version deleted]]


From jhw||@on@nb @end|ng |rom gm@||@com  Sat Aug 28 03:39:30 2021
From: jhw||@on@nb @end|ng |rom gm@||@com (John Wilson)
Date: Fri, 27 Aug 2021 22:39:30 -0300
Subject: [R-sig-ME] glmmTMB with spatial autocorrelation on a large dataset
Message-ID: <CABdA5Q3zG7BD_mFvOgS0Xe6Y5ghzjVQPfO4+oEd8CE2R7NoV-g@mail.gmail.com>

Hi all,

I'm running a glmmTMB on a large (~62,000 cases) dataset of animal counts
along transects. Transects are resampled on multiple sampling days across
several years. Some transects change between years. There's a total of
~1,100 unique coordinates in the data. I'm using a glmmTMB model, with a
SampleDate random effect and a set of fixed effects. Moran's I is
significant for 25% of the residuals of a model without spatial
autocorrelation.

When I add spatial autocorrelation following the glmmTMB covariance
structure tutorial, I get an error "Memory allocation fail in function
'MakeADGradObject'". I assume it's due to the large number of unique
coordinates? I checked the memory allocation and it's 48 gb, which is all
the ram I have. What are my options?

A reproducible toy example that is somewhat close to my data is below. The
model doesn't run on the full dataset (same error as I get for my real
data), but runs (without convergence) if I subset the data to only 1,000
rows.

Any help would be appreciated!
John

library(glmmTMB)
library(dplyr)

set.seed(0)
# create a large dataset with transects that are sampled repeatedly within
each year, where x and y are UTM coordinates.
df <- expand.grid(x = seq(392000, 460000, 5000), y = seq(5100000, 5200000,
1000), Year =
        2000:2004, DayYear = seq(30, 120, 10)) %>%
         # create a Date factor variable
         mutate(Date = paste(Year, DayYear, sep = "."),
                    Date = as.factor(Date),
                    # calculate distance to a single point - this will be
the fixed effect
                    Dist = sqrt((x - 400000)^ 2 + (y - 5150000)^2),
                    # simulate a linear response
                    Pred = x * 0.01 + 0.1,
                    Pred = rpois(n(), Pred))
# the model doesn't run on the full dataset (same error as I get for my
actual data). It runs (but does not converge) if I subset the data using
this:
#df <- df[sample(1:nrow(df), 1000, replace = FALSE),]

# create a position variable for the autocorrelation structure
df$pos <- numFactor(round(df$x), round(df$y)) # x and y are UTM coordinates
# run the model
m <- glmmTMB(Pred ~ Dist + exp(pos + 0|Date), family = poisson, data = df)

	[[alternative HTML version deleted]]


From ii@@bu m@iii@g oii c@u@edu@c@  Thu Sep  2 05:06:07 2021
From: ii@@bu m@iii@g oii c@u@edu@c@ (ii@@bu m@iii@g oii c@u@edu@c@)
Date: Thu, 2 Sep 2021 11:06:07 +0800
Subject: [R-sig-ME] A queation about random effect of lme4 package
Message-ID: <2021090211060782875320@cau.edu.cn>

Dear Sir/Madam,

Hope this email finds you well.
I am writing to inquiry about the progects published on github: https://github.com/lme4/lme4. 
I have multiple random variables, and I want to obtain a p-value of all the random variables, so how do I do that?  I don't know if this model (ranova(fm1<-lmer(V2 ~ V3 + V4 + (1|V5:V6:V7:V8:V9:V10:V11:V12:V13:V14) , data))) is correct. Is the design of random effect correct?
Another question: If I want to compute every estimate of random effects, how can I design the model? Is this the model [lmer(V2~V3+V4+(1|V5)+(1|V6)+(1|V7)+(1|V8)+...+(1|V14, data))] correct? 
I would appreciate your help.

Yours sincerely,
Lina

	[[alternative HTML version deleted]]


From p@u|@john@on @end|ng |rom g|@@gow@@c@uk  Thu Sep  2 14:10:46 2021
From: p@u|@john@on @end|ng |rom g|@@gow@@c@uk (Paul Johnson)
Date: Thu, 2 Sep 2021 12:10:46 +0000
Subject: [R-sig-ME] A queation about random effect of lme4 package
In-Reply-To: <2021090211060782875320@cau.edu.cn>
References: <2021090211060782875320@cau.edu.cn>
Message-ID: <98AA56F3-2B06-442D-A33F-DC6F8E242A11@glasgow.ac.uk>

Hi Lina,

If you have a number of grouping factors, the lme4 model-fitting functions will allow variation in the intercept using the syntax (e.g. for nested random effects):

... + (1 | village) + (1 | district) + (1 | region)

(here villages sampled within districts within regions). It's important to make sure all the nested villages and districts have unique names, e.g. if every district has villages A, B, C, ... this won't work. There is a nesting syntax, but it?s easier to use unique names. I think "(1|V5:V6:V7:V8.." does some kind of partial nesting but I never use this syntax and don't know exactly how it works.

The same syntax works for other sampling designs, e.g. crossed random effects (e.g. a sample of exam questions taken by a sample of students, or a panel of clinicians rating a sample of patients for disease severity).

It's very unusual to have large numbers of random effects (such as 10 in your code) in a model and usually lme4 will struggle to estimate them all. I can't comment on the appropriateness of your model for your data as I don't know anything about the specifics.

Best wishes,
Paul


?On 02/09/2021, 12:48, "R-sig-mixed-models on behalf of linabu at cau.edu.cn" <r-sig-mixed-models-bounces at r-project.org on behalf of linabu at cau.edu.cn> wrote:

    Dear Sir/Madam,

    Hope this email finds you well.
    I am writing to inquiry about the progects published on github: https://github.com/lme4/lme4. 
    I have multiple random variables, and I want to obtain a p-value of all the random variables, so how do I do that?  I don't know if this model (ranova(fm1<-lmer(V2 ~ V3 + V4 + (1|V5:V6:V7:V8:V9:V10:V11:V12:V13:V14) , data))) is correct. Is the design of random effect correct?
    Another question: If I want to compute every estimate of random effects, how can I design the model? Is this the model [lmer(V2~V3+V4+(1|V5)+(1|V6)+(1|V7)+(1|V8)+...+(1|V14, data))] correct? 
    I would appreciate your help.

    Yours sincerely,
    Lina

    	[[alternative HTML version deleted]]

    _______________________________________________
    R-sig-mixed-models at r-project.org mailing list
    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From @|ex@w@|dm@n @end|ng |rom @jc@ox@@c@uk  Thu Sep  2 16:58:16 2021
From: @|ex@w@|dm@n @end|ng |rom @jc@ox@@c@uk (Alex Waldman)
Date: Thu, 2 Sep 2021 14:58:16 +0000
Subject: [R-sig-ME] Convergence Issue
Message-ID: <18193AEB-C9E9-48F0-955A-82058CB76DC4@OX.AC.UK>

Dear All,

I have a dataset with 119 individuals with information on the presence of lesions of various types (1,2,3) at various levels (1,2,3) and want to understand the effect of type and location on lesion presence. Therefore, I ran the following:

glmer.model<-glmer(LesionPresence ~ Location*Type + (1 | ID), data=lesion_proportion_staged_level, family="binomial")

Unfortunately, I ran into the following warning:

In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv, :
Model failed to converge with max|grad| = 0.048092 (tol = 0.002, component 1)

I'm quite new to running mixed models and even with some googling am still unsure why I am running into this issue? Any insight would be much appreciated. I am attaching the model output below and the input data in case that is helpful and do let me know if you need any additional information:
Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) [
glmerMod]
Family: binomial  ( logit )
Formula: LesionPresence ~ Level * LesionType + (1 | ID)
   Data: lesion_proportion_staged_level

     AIC      BIC   logLik deviance df.resid
  1080.4   1129.2   -530.2   1060.4      962

Scaled residuals:
    Min      1Q  Median      3Q     Max
-1.6875 -0.5649 -0.3291  0.7170  4.2816

Random effects:
Groups Name        Variance Std.Dev.
ID     (Intercept) 1.519    1.232
Number of obs: 972, groups:  ID, 119

Fixed effects:
                   Estimate Std. Error z value Pr(>|z|)
(Intercept)         -1.6081     0.2966  -5.423 5.87e-08 ***
Level1              -0.6006     0.3900  -1.540 0.123600
Level2              -0.7270     0.4094  -1.776 0.075782 .
LesionType1          1.6362     0.3538   4.624 3.76e-06 ***
LesionType2          1.1659     0.3524   3.309 0.000938 ***
Level1:LesionType1  -0.3568     0.5022  -0.711 0.477379
Level2:LesionType1  -0.2015     0.5211  -0.387 0.698986
Level1:LesionType2   0.4030     0.5004   0.805 0.420607
Level2:LesionType2   0.1608     0.5229   0.308 0.758387
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
            (Intr) Level1 Level2 LsnTy1 LsnTy2 L1:LT1 L2:LT1 L1:LT2
Level1      -0.603
Level2      -0.574  0.447
LesionType1 -0.703  0.498  0.475
LesionType2 -0.694  0.503  0.479  0.582
Lvl1:LsnTy1  0.480 -0.766 -0.339 -0.691 -0.400
Lvl2:LsnTy1  0.461 -0.344 -0.775 -0.665 -0.385  0.466
Lvl1:LsnTy2  0.468 -0.772 -0.344 -0.392 -0.692  0.598  0.268
Lvl2:LsnTy2  0.453 -0.344 -0.773 -0.379 -0.665  0.267  0.607  0.468
optimizer (Nelder_Mead) convergence code: 0 (OK)
Model failed to converge with max|grad| = 0.048092 (tol = 0.002, component 1)

From me @end|ng |rom ph||||p@|d@y@com  Thu Sep  2 17:04:01 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Thu, 2 Sep 2021 10:04:01 -0500
Subject: [R-sig-ME] Convergence Issue
In-Reply-To: <18193AEB-C9E9-48F0-955A-82058CB76DC4@OX.AC.UK>
References: <18193AEB-C9E9-48F0-955A-82058CB76DC4@OX.AC.UK>
Message-ID: <2435404c-8154-3c1a-e596-4f76b7e99e3e@phillipalday.com>

I don't have time to give more thorough help at the moment, but look at
the help page on converge, accessible via ?convergence in R or mirrored
online, e.g. https://rdrr.io/cran/lme4/man/convergence.html

Hope that helps

Phillip

On 02/09/2021 09:58, Alex Waldman wrote:
> Dear All,
>
> I have a dataset with 119 individuals with information on the presence of lesions of various types (1,2,3) at various levels (1,2,3) and want to understand the effect of type and location on lesion presence. Therefore, I ran the following:
>
> glmer.model<-glmer(LesionPresence ~ Location*Type + (1 | ID), data=lesion_proportion_staged_level, family="binomial")
>
> Unfortunately, I ran into the following warning:
>
> In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv, :
> Model failed to converge with max|grad| = 0.048092 (tol = 0.002, component 1)
>
> I'm quite new to running mixed models and even with some googling am still unsure why I am running into this issue? Any insight would be much appreciated. I am attaching the model output below and the input data in case that is helpful and do let me know if you need any additional information:
> Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) [
> glmerMod]
> Family: binomial  ( logit )
> Formula: LesionPresence ~ Level * LesionType + (1 | ID)
>    Data: lesion_proportion_staged_level
>
>      AIC      BIC   logLik deviance df.resid
>   1080.4   1129.2   -530.2   1060.4      962
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -1.6875 -0.5649 -0.3291  0.7170  4.2816
>
> Random effects:
> Groups Name        Variance Std.Dev.
> ID     (Intercept) 1.519    1.232
> Number of obs: 972, groups:  ID, 119
>
> Fixed effects:
>                    Estimate Std. Error z value Pr(>|z|)
> (Intercept)         -1.6081     0.2966  -5.423 5.87e-08 ***
> Level1              -0.6006     0.3900  -1.540 0.123600
> Level2              -0.7270     0.4094  -1.776 0.075782 .
> LesionType1          1.6362     0.3538   4.624 3.76e-06 ***
> LesionType2          1.1659     0.3524   3.309 0.000938 ***
> Level1:LesionType1  -0.3568     0.5022  -0.711 0.477379
> Level2:LesionType1  -0.2015     0.5211  -0.387 0.698986
> Level1:LesionType2   0.4030     0.5004   0.805 0.420607
> Level2:LesionType2   0.1608     0.5229   0.308 0.758387
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>             (Intr) Level1 Level2 LsnTy1 LsnTy2 L1:LT1 L2:LT1 L1:LT2
> Level1      -0.603
> Level2      -0.574  0.447
> LesionType1 -0.703  0.498  0.475
> LesionType2 -0.694  0.503  0.479  0.582
> Lvl1:LsnTy1  0.480 -0.766 -0.339 -0.691 -0.400
> Lvl2:LsnTy1  0.461 -0.344 -0.775 -0.665 -0.385  0.466
> Lvl1:LsnTy2  0.468 -0.772 -0.344 -0.392 -0.692  0.598  0.268
> Lvl2:LsnTy2  0.453 -0.344 -0.773 -0.379 -0.665  0.267  0.607  0.468
> optimizer (Nelder_Mead) convergence code: 0 (OK)
> Model failed to converge with max|grad| = 0.048092 (tol = 0.002, component 1)
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From @|ex@w@|dm@n @end|ng |rom @jc@ox@@c@uk  Thu Sep  2 17:32:05 2021
From: @|ex@w@|dm@n @end|ng |rom @jc@ox@@c@uk (Alex Waldman)
Date: Thu, 2 Sep 2021 15:32:05 +0000
Subject: [R-sig-ME] Convergence Issue
In-Reply-To: <2435404c-8154-3c1a-e596-4f76b7e99e3e@phillipalday.com>
References: <18193AEB-C9E9-48F0-955A-82058CB76DC4@OX.AC.UK>
 <2435404c-8154-3c1a-e596-4f76b7e99e3e@phillipalday.com>
Message-ID: <9ECF0813-50CD-4879-9EEC-4DEB7A83B325@OX.AC.UK>

Thank you! This was helpful. 

When I tried double-checking the Hessian calculation, I got the following error:

Error in chol.default(hess) : the leading minor of order 6 is not positive definite 

Could this provide any indication as to why the model isn't converging?

I also tested all the optimizers and got the following result but was unsure how to interpret:

$which.OK
                       bobyqa                   Nelder_Mead 
                         TRUE                          TRUE 
                   nlminbwrap                         nmkbw 
                         TRUE                          TRUE 
              optimx.L-BFGS-B nloptwrap.NLOPT_LN_NELDERMEAD 
                         TRUE                          TRUE 
    nloptwrap.NLOPT_LN_BOBYQA 
                         TRUE 

$msgs
$msgs$bobyqa
NULL

$msgs$Nelder_Mead
[1] "Model failed to converge with max|grad| = 0.0555727 (tol = 0.002, component 1)"

$msgs$nlminbwrap
NULL

$msgs$nmkbw
[1] "Model failed to converge with max|grad| = 0.0083782 (tol = 0.002, component 1)"

$msgs$`optimx.L-BFGS-B`
NULL

$msgs$nloptwrap.NLOPT_LN_NELDERMEAD
NULL

$msgs$nloptwrap.NLOPT_LN_BOBYQA
[1] "Model failed to converge with max|grad| = 0.0122376 (tol = 0.002, component 1)"


$fixef
                              (Intercept)     Level1     Level2 LesionType1 LesionType2
bobyqa                          -1.607709 -0.5906779 -0.7133361    1.633654    1.169556
Nelder_Mead                     -1.609343 -0.5990970 -0.7248756    1.637308    1.166614
nlminbwrap                      -1.607742 -0.5906431 -0.7133012    1.633691    1.169589
nmkbw                           -1.612150 -0.5911478 -0.7154765    1.638517    1.173022
optimx.L-BFGS-B                 -1.612203 -0.5921513 -0.7152118    1.638355    1.173146
nloptwrap.NLOPT_LN_NELDERMEAD   -1.612326 -0.5921231 -0.7148693    1.638615    1.173143
nloptwrap.NLOPT_LN_BOBYQA       -1.608554 -0.5974722 -0.7194175    1.634395    1.169306
                              Level1:LesionType1 Level2:LesionType1 Level1:LesionType2
bobyqa                                -0.3646982         -0.2118206          0.3897427
Nelder_Mead                           -0.3570757         -0.2053771          0.4027594
nlminbwrap                            -0.3647408         -0.2118542          0.3897106
nmkbw                                 -0.3675755         -0.2125293          0.3896785
optimx.L-BFGS-B                       -0.3660791         -0.2125631          0.3904246
nloptwrap.NLOPT_LN_NELDERMEAD         -0.3663036         -0.2131734          0.3905315
nloptwrap.NLOPT_LN_BOBYQA             -0.3597335         -0.2075374          0.3969647
                              Level2:LesionType2
bobyqa                                 0.1426930
Nelder_Mead                            0.1586086
nlminbwrap                             0.1426555
nmkbw                                  0.1436730
optimx.L-BFGS-B                        0.1426133
nloptwrap.NLOPT_LN_NELDERMEAD          0.1423522
nloptwrap.NLOPT_LN_BOBYQA              0.1474815

$llik
                       bobyqa                   Nelder_Mead 
                    -530.1908                     -530.1818 
                   nlminbwrap                         nmkbw 
                    -530.1908                     -530.1810 
              optimx.L-BFGS-B nloptwrap.NLOPT_LN_NELDERMEAD 
                    -530.1810                     -530.1810 
    nloptwrap.NLOPT_LN_BOBYQA 
                    -530.1812 

$sdcor
                              ID.(Intercept)
bobyqa                              1.227682
Nelder_Mead                         1.232220
nlminbwrap                          1.227685
nmkbw                               1.231678
optimx.L-BFGS-B                     1.231639
nloptwrap.NLOPT_LN_NELDERMEAD       1.231837
nloptwrap.NLOPT_LN_BOBYQA           1.231765

$theta
                              ID.(Intercept)
bobyqa                              1.227682
Nelder_Mead                         1.232220
nlminbwrap                          1.227685
nmkbw                               1.231678
optimx.L-BFGS-B                     1.231639
nloptwrap.NLOPT_LN_NELDERMEAD       1.231837
nloptwrap.NLOPT_LN_BOBYQA           1.231765

$times
                              user.self sys.self elapsed user.child sys.child
bobyqa                            0.633    0.003   0.638          0         0
Nelder_Mead                       2.401    0.003   2.405          0         0
nlminbwrap                        0.581    0.001   0.585          0         0
nmkbw                             0.885    0.004   0.894          0         0
optimx.L-BFGS-B                   1.390    0.005   1.407          0         0
nloptwrap.NLOPT_LN_NELDERMEAD     0.976    0.003   0.984          0         0
nloptwrap.NLOPT_LN_BOBYQA         0.996    0.002   1.004          0         0

$feval
                       bobyqa                   Nelder_Mead 
                          572                          2605 
                   nlminbwrap                         nmkbw 
                           NA                           728 
              optimx.L-BFGS-B nloptwrap.NLOPT_LN_NELDERMEAD 
                           44                           904 
    nloptwrap.NLOPT_LN_BOBYQA 
                          972

Warm Regards,
Alex

?On 9/2/21, 4:04 PM, "Phillip Alday" <me at phillipalday.com> wrote:

    I don't have time to give more thorough help at the moment, but look at
    the help page on converge, accessible via ?convergence in R or mirrored
    online, e.g. https://rdrr.io/cran/lme4/man/convergence.html

    Hope that helps

    Phillip

    On 02/09/2021 09:58, Alex Waldman wrote:
    > Dear All,
    >
    > I have a dataset with 119 individuals with information on the presence of lesions of various types (1,2,3) at various levels (1,2,3) and want to understand the effect of type and location on lesion presence. Therefore, I ran the following:
    >
    > glmer.model<-glmer(LesionPresence ~ Location*Type + (1 | ID), data=lesion_proportion_staged_level, family="binomial")
    >
    > Unfortunately, I ran into the following warning:
    >
    > In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv, :
    > Model failed to converge with max|grad| = 0.048092 (tol = 0.002, component 1)
    >
    > I'm quite new to running mixed models and even with some googling am still unsure why I am running into this issue? Any insight would be much appreciated. I am attaching the model output below and the input data in case that is helpful and do let me know if you need any additional information:
    > Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) [
    > glmerMod]
    > Family: binomial  ( logit )
    > Formula: LesionPresence ~ Level * LesionType + (1 | ID)
    >    Data: lesion_proportion_staged_level
    >
    >      AIC      BIC   logLik deviance df.resid
    >   1080.4   1129.2   -530.2   1060.4      962
    >
    > Scaled residuals:
    >     Min      1Q  Median      3Q     Max
    > -1.6875 -0.5649 -0.3291  0.7170  4.2816
    >
    > Random effects:
    > Groups Name        Variance Std.Dev.
    > ID     (Intercept) 1.519    1.232
    > Number of obs: 972, groups:  ID, 119
    >
    > Fixed effects:
    >                    Estimate Std. Error z value Pr(>|z|)
    > (Intercept)         -1.6081     0.2966  -5.423 5.87e-08 ***
    > Level1              -0.6006     0.3900  -1.540 0.123600
    > Level2              -0.7270     0.4094  -1.776 0.075782 .
    > LesionType1          1.6362     0.3538   4.624 3.76e-06 ***
    > LesionType2          1.1659     0.3524   3.309 0.000938 ***
    > Level1:LesionType1  -0.3568     0.5022  -0.711 0.477379
    > Level2:LesionType1  -0.2015     0.5211  -0.387 0.698986
    > Level1:LesionType2   0.4030     0.5004   0.805 0.420607
    > Level2:LesionType2   0.1608     0.5229   0.308 0.758387
    > ---
    > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
    >
    > Correlation of Fixed Effects:
    >             (Intr) Level1 Level2 LsnTy1 LsnTy2 L1:LT1 L2:LT1 L1:LT2
    > Level1      -0.603
    > Level2      -0.574  0.447
    > LesionType1 -0.703  0.498  0.475
    > LesionType2 -0.694  0.503  0.479  0.582
    > Lvl1:LsnTy1  0.480 -0.766 -0.339 -0.691 -0.400
    > Lvl2:LsnTy1  0.461 -0.344 -0.775 -0.665 -0.385  0.466
    > Lvl1:LsnTy2  0.468 -0.772 -0.344 -0.392 -0.692  0.598  0.268
    > Lvl2:LsnTy2  0.453 -0.344 -0.773 -0.379 -0.665  0.267  0.607  0.468
    > optimizer (Nelder_Mead) convergence code: 0 (OK)
    > Model failed to converge with max|grad| = 0.048092 (tol = 0.002, component 1)
    > _______________________________________________
    > R-sig-mixed-models at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbo|ker @end|ng |rom gm@||@com  Thu Sep  2 18:03:41 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 2 Sep 2021 12:03:41 -0400
Subject: [R-sig-ME] Convergence Issue
In-Reply-To: <9ECF0813-50CD-4879-9EEC-4DEB7A83B325@OX.AC.UK>
References: <18193AEB-C9E9-48F0-955A-82058CB76DC4@OX.AC.UK>
 <2435404c-8154-3c1a-e596-4f76b7e99e3e@phillipalday.com>
 <9ECF0813-50CD-4879-9EEC-4DEB7A83B325@OX.AC.UK>
Message-ID: <14595f87-7e4c-1dfb-7c28-94990b0d2dcd@gmail.com>

   Without digging in deeply: the results across optimizers all look 
very similar to each other, so unless you need extremely precise answers 
I would say everything's OK.

   You could dig in further to look at the fixed-effect estimates (if 
that's what you're interested in) in conjunction with the approximate 
(Wald) confidence intervals, e.g.:

library(lme4)
library(broom.mixed)
library(purrr)
library(ggplot2)

gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
                    data = cbpp, family = binomial)
aa <- allFit(gm1)

tt <- purrr::map_dfr(aa, tidy, effect = "fixed", .id="optimizer")
ggplot(tt, aes(x=term, y=estimate, ymin=estimate-2*std.error,
         ymax =    estimate+2*std.error, colour=optimizer)) +
          geom_pointrange(position=position_dodge(width=0.25))

   (with apologies to people who are allergic to the tidyverse)


On 9/2/21 11:32 AM, Alex Waldman wrote:
> Thank you! This was helpful.
> 
> When I tried double-checking the Hessian calculation, I got the following error:
> 
> Error in chol.default(hess) : the leading minor of order 6 is not positive definite
> 
> Could this provide any indication as to why the model isn't converging?
> 
> I also tested all the optimizers and got the following result but was unsure how to interpret:
> 
> $which.OK
>                         bobyqa                   Nelder_Mead
>                           TRUE                          TRUE
>                     nlminbwrap                         nmkbw
>                           TRUE                          TRUE
>                optimx.L-BFGS-B nloptwrap.NLOPT_LN_NELDERMEAD
>                           TRUE                          TRUE
>      nloptwrap.NLOPT_LN_BOBYQA
>                           TRUE
> 
> $msgs
> $msgs$bobyqa
> NULL
> 
> $msgs$Nelder_Mead
> [1] "Model failed to converge with max|grad| = 0.0555727 (tol = 0.002, component 1)"
> 
> $msgs$nlminbwrap
> NULL
> 
> $msgs$nmkbw
> [1] "Model failed to converge with max|grad| = 0.0083782 (tol = 0.002, component 1)"
> 
> $msgs$`optimx.L-BFGS-B`
> NULL
> 
> $msgs$nloptwrap.NLOPT_LN_NELDERMEAD
> NULL
> 
> $msgs$nloptwrap.NLOPT_LN_BOBYQA
> [1] "Model failed to converge with max|grad| = 0.0122376 (tol = 0.002, component 1)"
> 
> 
> $fixef
>                                (Intercept)     Level1     Level2 LesionType1 LesionType2
> bobyqa                          -1.607709 -0.5906779 -0.7133361    1.633654    1.169556
> Nelder_Mead                     -1.609343 -0.5990970 -0.7248756    1.637308    1.166614
> nlminbwrap                      -1.607742 -0.5906431 -0.7133012    1.633691    1.169589
> nmkbw                           -1.612150 -0.5911478 -0.7154765    1.638517    1.173022
> optimx.L-BFGS-B                 -1.612203 -0.5921513 -0.7152118    1.638355    1.173146
> nloptwrap.NLOPT_LN_NELDERMEAD   -1.612326 -0.5921231 -0.7148693    1.638615    1.173143
> nloptwrap.NLOPT_LN_BOBYQA       -1.608554 -0.5974722 -0.7194175    1.634395    1.169306
>                                Level1:LesionType1 Level2:LesionType1 Level1:LesionType2
> bobyqa                                -0.3646982         -0.2118206          0.3897427
> Nelder_Mead                           -0.3570757         -0.2053771          0.4027594
> nlminbwrap                            -0.3647408         -0.2118542          0.3897106
> nmkbw                                 -0.3675755         -0.2125293          0.3896785
> optimx.L-BFGS-B                       -0.3660791         -0.2125631          0.3904246
> nloptwrap.NLOPT_LN_NELDERMEAD         -0.3663036         -0.2131734          0.3905315
> nloptwrap.NLOPT_LN_BOBYQA             -0.3597335         -0.2075374          0.3969647
>                                Level2:LesionType2
> bobyqa                                 0.1426930
> Nelder_Mead                            0.1586086
> nlminbwrap                             0.1426555
> nmkbw                                  0.1436730
> optimx.L-BFGS-B                        0.1426133
> nloptwrap.NLOPT_LN_NELDERMEAD          0.1423522
> nloptwrap.NLOPT_LN_BOBYQA              0.1474815
> 
> $llik
>                         bobyqa                   Nelder_Mead
>                      -530.1908                     -530.1818
>                     nlminbwrap                         nmkbw
>                      -530.1908                     -530.1810
>                optimx.L-BFGS-B nloptwrap.NLOPT_LN_NELDERMEAD
>                      -530.1810                     -530.1810
>      nloptwrap.NLOPT_LN_BOBYQA
>                      -530.1812
> 
> $sdcor
>                                ID.(Intercept)
> bobyqa                              1.227682
> Nelder_Mead                         1.232220
> nlminbwrap                          1.227685
> nmkbw                               1.231678
> optimx.L-BFGS-B                     1.231639
> nloptwrap.NLOPT_LN_NELDERMEAD       1.231837
> nloptwrap.NLOPT_LN_BOBYQA           1.231765
> 
> $theta
>                                ID.(Intercept)
> bobyqa                              1.227682
> Nelder_Mead                         1.232220
> nlminbwrap                          1.227685
> nmkbw                               1.231678
> optimx.L-BFGS-B                     1.231639
> nloptwrap.NLOPT_LN_NELDERMEAD       1.231837
> nloptwrap.NLOPT_LN_BOBYQA           1.231765
> 
> $times
>                                user.self sys.self elapsed user.child sys.child
> bobyqa                            0.633    0.003   0.638          0         0
> Nelder_Mead                       2.401    0.003   2.405          0         0
> nlminbwrap                        0.581    0.001   0.585          0         0
> nmkbw                             0.885    0.004   0.894          0         0
> optimx.L-BFGS-B                   1.390    0.005   1.407          0         0
> nloptwrap.NLOPT_LN_NELDERMEAD     0.976    0.003   0.984          0         0
> nloptwrap.NLOPT_LN_BOBYQA         0.996    0.002   1.004          0         0
> 
> $feval
>                         bobyqa                   Nelder_Mead
>                            572                          2605
>                     nlminbwrap                         nmkbw
>                             NA                           728
>                optimx.L-BFGS-B nloptwrap.NLOPT_LN_NELDERMEAD
>                             44                           904
>      nloptwrap.NLOPT_LN_BOBYQA
>                            972
> 
> Warm Regards,
> Alex
> 
> ?On 9/2/21, 4:04 PM, "Phillip Alday" <me at phillipalday.com> wrote:
> 
>      I don't have time to give more thorough help at the moment, but look at
>      the help page on converge, accessible via ?convergence in R or mirrored
>      online, e.g. https://rdrr.io/cran/lme4/man/convergence.html
> 
>      Hope that helps
> 
>      Phillip
> 
>      On 02/09/2021 09:58, Alex Waldman wrote:
>      > Dear All,
>      >
>      > I have a dataset with 119 individuals with information on the presence of lesions of various types (1,2,3) at various levels (1,2,3) and want to understand the effect of type and location on lesion presence. Therefore, I ran the following:
>      >
>      > glmer.model<-glmer(LesionPresence ~ Location*Type + (1 | ID), data=lesion_proportion_staged_level, family="binomial")
>      >
>      > Unfortunately, I ran into the following warning:
>      >
>      > In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv, :
>      > Model failed to converge with max|grad| = 0.048092 (tol = 0.002, component 1)
>      >
>      > I'm quite new to running mixed models and even with some googling am still unsure why I am running into this issue? Any insight would be much appreciated. I am attaching the model output below and the input data in case that is helpful and do let me know if you need any additional information:
>      > Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) [
>      > glmerMod]
>      > Family: binomial  ( logit )
>      > Formula: LesionPresence ~ Level * LesionType + (1 | ID)
>      >    Data: lesion_proportion_staged_level
>      >
>      >      AIC      BIC   logLik deviance df.resid
>      >   1080.4   1129.2   -530.2   1060.4      962
>      >
>      > Scaled residuals:
>      >     Min      1Q  Median      3Q     Max
>      > -1.6875 -0.5649 -0.3291  0.7170  4.2816
>      >
>      > Random effects:
>      > Groups Name        Variance Std.Dev.
>      > ID     (Intercept) 1.519    1.232
>      > Number of obs: 972, groups:  ID, 119
>      >
>      > Fixed effects:
>      >                    Estimate Std. Error z value Pr(>|z|)
>      > (Intercept)         -1.6081     0.2966  -5.423 5.87e-08 ***
>      > Level1              -0.6006     0.3900  -1.540 0.123600
>      > Level2              -0.7270     0.4094  -1.776 0.075782 .
>      > LesionType1          1.6362     0.3538   4.624 3.76e-06 ***
>      > LesionType2          1.1659     0.3524   3.309 0.000938 ***
>      > Level1:LesionType1  -0.3568     0.5022  -0.711 0.477379
>      > Level2:LesionType1  -0.2015     0.5211  -0.387 0.698986
>      > Level1:LesionType2   0.4030     0.5004   0.805 0.420607
>      > Level2:LesionType2   0.1608     0.5229   0.308 0.758387
>      > ---
>      > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>      >
>      > Correlation of Fixed Effects:
>      >             (Intr) Level1 Level2 LsnTy1 LsnTy2 L1:LT1 L2:LT1 L1:LT2
>      > Level1      -0.603
>      > Level2      -0.574  0.447
>      > LesionType1 -0.703  0.498  0.475
>      > LesionType2 -0.694  0.503  0.479  0.582
>      > Lvl1:LsnTy1  0.480 -0.766 -0.339 -0.691 -0.400
>      > Lvl2:LsnTy1  0.461 -0.344 -0.775 -0.665 -0.385  0.466
>      > Lvl1:LsnTy2  0.468 -0.772 -0.344 -0.392 -0.692  0.598  0.268
>      > Lvl2:LsnTy2  0.453 -0.344 -0.773 -0.379 -0.665  0.267  0.607  0.468
>      > optimizer (Nelder_Mead) convergence code: 0 (OK)
>      > Model failed to converge with max|grad| = 0.048092 (tol = 0.002, component 1)
>      > _______________________________________________
>      > R-sig-mixed-models at r-project.org mailing list
>      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics


From edw|n@john@ton @end|ng |rom m@|ne@edu  Thu Sep  2 18:27:03 2021
From: edw|n@john@ton @end|ng |rom m@|ne@edu (Elliot Johnston)
Date: Thu, 2 Sep 2021 12:27:03 -0400
Subject: [R-sig-ME] Shifting Count Data with Partial Residuals in glmmTMB
Message-ID: <CAMAqrC59dVtYsGVQ628iHKq4OqBCHVdXqO8F2WnXfTMatBdFRw@mail.gmail.com>

#Hi everyone. I'm a University of Maine PhD student and first-time poster
on this mailing list.

#I am looking for help on adjusting the values of my raw data (dependent
variable = Count) based on the
#effects of two continuous covariates to go along with model-predicted data
in a plot
#derived from a glmmTMB model.

#this website illustrates nicely what I want to do, but with an OLS linear
regression (scroll down
#to Partial Residual Plots section):
#https://cran.r-project.org/web/packages/jtools/vignettes/effect_plot.html

#some example code to visualize where I am stuck:

#code from above website showing how to shift values of raw data to
incorporate
#effects of multiple covariates
library(ggplot2)
library(jtools)
data(mpg)
fit_poly <- lm(cty ~ poly(displ, 2) + year + cyl + class + fl, data = mpg)

#raw data doesn't account for effect of covariates (year, cyl, class, fl)
effect_plot(fit_poly, pred = displ, interval = TRUE, plot.points = TRUE)

#raw data does account for effect of covariates (year, cyl, class, fl)
effect_plot(fit_poly, pred = displ, interval = TRUE, partial.residuals =
TRUE)

#I am working with a glmmTMB model. I will use an example dataset below:

#load salamander data set and create glmmTMB model
library(glmmTMB)
data(Salamanders)

##zero-inflated mixed model with a conditional model component and a
binomial model component
#categorical fixed effects: spp, mined
#continuous covariate: cover
#random effect: site
zinbm2 = glmmTMB(count~spp + mined + cover + (1|site), zi=~spp + mined +
cover, data = Salamanders, family=nbinom2)

#plot model-predicted estimates alongside raw data
#use model to make predictions on new data
spp.nd <- data.frame(rep(c("GP", "PR", "DM", "EC-A", "EC-L", "DES-L",
"DF"), each = 2))
mined.nd <- data.frame(rep(c("yes", "no"), times = 7))
cover = rep(0, times = 14)
site = rep(NA, times = 14)
nd.salamanders = cbind(spp.nd, mined.nd, cover, site)
colnames(nd.salamanders)<- c("spp", "mined", "cover", "site")
rm(spp.nd, mined.nd, cover, site)

#covariate set to mean (0 for scaled variables) and random site effect set
to 0 for all groups
predict.salamanders <- predict(zinbm2, type = "response",
                               newdata = nd.salamanders, se.fit = TRUE,
re.form = ~0)

predict.salamanders = as.data.frame(predict.salamanders)

#append values
predict.salamanders = cbind(predict.salamanders, nd.salamanders)

#create SE bounds
predict.salamanders$lower = predict.salamanders$fit -
predict.salamanders$se.fit
predict.salamanders$upper = predict.salamanders$fit +
predict.salamanders$se.fit

#set order of appearance on x-axis
predict.salamanders$mined <- factor(predict.salamanders$mined, levels =
c("yes", "no"))

#plot predicted points (with error bars) and raw data
plot.salamanders.pred =
  ggplot() +
  geom_point(data=predict.salamanders, aes(x=spp, y=fit, colour=mined),
position = position_dodge(0.9),
             size=3, shape=15) + #predicted points
  geom_errorbar(data=predict.salamanders, aes(x=spp, ymax=upper,
ymin=lower, colour=mined), position = position_dodge(0.9),
                width=0.5, size=1) + #error bars for predicted points
  geom_count(data=Salamanders, aes(x=spp, y=count, colour=mined), position
= position_dodge(0.9),
             alpha=0.5) + #raw data points
  xlab("Species") +
  ylab("Count")


print(plot.salamanders.pred)

#I now want to be able to shift the raw Count values to account for the
effect of the covariate 'cover'
#given that the predicted point estimates are incorporating this effect

#I can create partial residual plots with code taken from Ben Bolker's
response to a
#similar question on this mailing list in 2018:
#https://stat.ethz.ch/pipermail/r-sig-mixed-models/2018q1/026288.html

X <- getME(zinbm2,"X")
beta <- fixef(zinbm2)$cond
beta_X <- sweep(X,MARGIN=2,STATS=beta,FUN="*")
p_resid <- sweep(beta_X,MARGIN=1,STATS=residuals(zinbm2),FUN="+")
par(mfrow=c(2,4))
for (i in 2:9) {
  plot(X[,i],p_resid[,i],xlab=colnames(X)[i],ylab="partial residuals")
}

#I'm stuck at this point and not sure how to advance. Rather than just
creating partial residual
#plots, I need to use a numeric vector to modify the Count values and then
re-plot.
#I have scaled partial residual values of the covariate 'cover' in the
p_resid dataframe --
#do I simply add/subtract these to the raw Count values?

#The model I'm working with has two continuous covariates with effects that
I would like to incorporate.
#In this case, would I sequentially add/subtract both sets of values from
Count?

#As part of my homework before posting, I have looked at the Fox and
Weisberg (2018) paper on predictor
#effect plots and partial residuals but I can't quite figure out how to
make the leap to my desired outcome.

#thank you for the help!


-- 
Elliot Johnston
PhD Student
Ecology and Environmental Sciences
University of Maine
edwin.johnston at maine.edu

	[[alternative HTML version deleted]]


From @|ex@w@|dm@n @end|ng |rom @jc@ox@@c@uk  Thu Sep  2 18:54:53 2021
From: @|ex@w@|dm@n @end|ng |rom @jc@ox@@c@uk (Alex Waldman)
Date: Thu, 2 Sep 2021 16:54:53 +0000
Subject: [R-sig-ME] Convergence Issue
In-Reply-To: <14595f87-7e4c-1dfb-7c28-94990b0d2dcd@gmail.com>
References: <18193AEB-C9E9-48F0-955A-82058CB76DC4@OX.AC.UK>
 <2435404c-8154-3c1a-e596-4f76b7e99e3e@phillipalday.com>
 <9ECF0813-50CD-4879-9EEC-4DEB7A83B325@OX.AC.UK>
 <14595f87-7e4c-1dfb-7c28-94990b0d2dcd@gmail.com>
Message-ID: <14D19070-B92D-42FE-AA9C-A4DE48550E5F@OX.AC.UK>

Thanks! I plotted the fixed-effect estimates and CIs and they all look quite similar (attached). Since I'm interested in extracting the marginal means with emmeans and performing contrasts, I guess I shouldn't worry?

Warm Regards,
Alex

?On 9/2/21, 5:04 PM, "R-sig-mixed-models on behalf of Ben Bolker" <r-sig-mixed-models-bounces at r-project.org on behalf of bbolker at gmail.com> wrote:

       Without digging in deeply: the results across optimizers all look 
    very similar to each other, so unless you need extremely precise answers 
    I would say everything's OK.

       You could dig in further to look at the fixed-effect estimates (if 
    that's what you're interested in) in conjunction with the approximate 
    (Wald) confidence intervals, e.g.:

    library(lme4)
    library(broom.mixed)
    library(purrr)
    library(ggplot2)

    gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
                        data = cbpp, family = binomial)
    aa <- allFit(gm1)

    tt <- purrr::map_dfr(aa, tidy, effect = "fixed", .id="optimizer")
    ggplot(tt, aes(x=term, y=estimate, ymin=estimate-2*std.error,
             ymax =    estimate+2*std.error, colour=optimizer)) +
              geom_pointrange(position=position_dodge(width=0.25))

       (with apologies to people who are allergic to the tidyverse)


    On 9/2/21 11:32 AM, Alex Waldman wrote:
    > Thank you! This was helpful.
    > 
    > When I tried double-checking the Hessian calculation, I got the following error:
    > 
    > Error in chol.default(hess) : the leading minor of order 6 is not positive definite
    > 
    > Could this provide any indication as to why the model isn't converging?
    > 
    > I also tested all the optimizers and got the following result but was unsure how to interpret:
    > 
    > $which.OK
    >                         bobyqa                   Nelder_Mead
    >                           TRUE                          TRUE
    >                     nlminbwrap                         nmkbw
    >                           TRUE                          TRUE
    >                optimx.L-BFGS-B nloptwrap.NLOPT_LN_NELDERMEAD
    >                           TRUE                          TRUE
    >      nloptwrap.NLOPT_LN_BOBYQA
    >                           TRUE
    > 
    > $msgs
    > $msgs$bobyqa
    > NULL
    > 
    > $msgs$Nelder_Mead
    > [1] "Model failed to converge with max|grad| = 0.0555727 (tol = 0.002, component 1)"
    > 
    > $msgs$nlminbwrap
    > NULL
    > 
    > $msgs$nmkbw
    > [1] "Model failed to converge with max|grad| = 0.0083782 (tol = 0.002, component 1)"
    > 
    > $msgs$`optimx.L-BFGS-B`
    > NULL
    > 
    > $msgs$nloptwrap.NLOPT_LN_NELDERMEAD
    > NULL
    > 
    > $msgs$nloptwrap.NLOPT_LN_BOBYQA
    > [1] "Model failed to converge with max|grad| = 0.0122376 (tol = 0.002, component 1)"
    > 
    > 
    > $fixef
    >                                (Intercept)     Level1     Level2 LesionType1 LesionType2
    > bobyqa                          -1.607709 -0.5906779 -0.7133361    1.633654    1.169556
    > Nelder_Mead                     -1.609343 -0.5990970 -0.7248756    1.637308    1.166614
    > nlminbwrap                      -1.607742 -0.5906431 -0.7133012    1.633691    1.169589
    > nmkbw                           -1.612150 -0.5911478 -0.7154765    1.638517    1.173022
    > optimx.L-BFGS-B                 -1.612203 -0.5921513 -0.7152118    1.638355    1.173146
    > nloptwrap.NLOPT_LN_NELDERMEAD   -1.612326 -0.5921231 -0.7148693    1.638615    1.173143
    > nloptwrap.NLOPT_LN_BOBYQA       -1.608554 -0.5974722 -0.7194175    1.634395    1.169306
    >                                Level1:LesionType1 Level2:LesionType1 Level1:LesionType2
    > bobyqa                                -0.3646982         -0.2118206          0.3897427
    > Nelder_Mead                           -0.3570757         -0.2053771          0.4027594
    > nlminbwrap                            -0.3647408         -0.2118542          0.3897106
    > nmkbw                                 -0.3675755         -0.2125293          0.3896785
    > optimx.L-BFGS-B                       -0.3660791         -0.2125631          0.3904246
    > nloptwrap.NLOPT_LN_NELDERMEAD         -0.3663036         -0.2131734          0.3905315
    > nloptwrap.NLOPT_LN_BOBYQA             -0.3597335         -0.2075374          0.3969647
    >                                Level2:LesionType2
    > bobyqa                                 0.1426930
    > Nelder_Mead                            0.1586086
    > nlminbwrap                             0.1426555
    > nmkbw                                  0.1436730
    > optimx.L-BFGS-B                        0.1426133
    > nloptwrap.NLOPT_LN_NELDERMEAD          0.1423522
    > nloptwrap.NLOPT_LN_BOBYQA              0.1474815
    > 
    > $llik
    >                         bobyqa                   Nelder_Mead
    >                      -530.1908                     -530.1818
    >                     nlminbwrap                         nmkbw
    >                      -530.1908                     -530.1810
    >                optimx.L-BFGS-B nloptwrap.NLOPT_LN_NELDERMEAD
    >                      -530.1810                     -530.1810
    >      nloptwrap.NLOPT_LN_BOBYQA
    >                      -530.1812
    > 
    > $sdcor
    >                                ID.(Intercept)
    > bobyqa                              1.227682
    > Nelder_Mead                         1.232220
    > nlminbwrap                          1.227685
    > nmkbw                               1.231678
    > optimx.L-BFGS-B                     1.231639
    > nloptwrap.NLOPT_LN_NELDERMEAD       1.231837
    > nloptwrap.NLOPT_LN_BOBYQA           1.231765
    > 
    > $theta
    >                                ID.(Intercept)
    > bobyqa                              1.227682
    > Nelder_Mead                         1.232220
    > nlminbwrap                          1.227685
    > nmkbw                               1.231678
    > optimx.L-BFGS-B                     1.231639
    > nloptwrap.NLOPT_LN_NELDERMEAD       1.231837
    > nloptwrap.NLOPT_LN_BOBYQA           1.231765
    > 
    > $times
    >                                user.self sys.self elapsed user.child sys.child
    > bobyqa                            0.633    0.003   0.638          0         0
    > Nelder_Mead                       2.401    0.003   2.405          0         0
    > nlminbwrap                        0.581    0.001   0.585          0         0
    > nmkbw                             0.885    0.004   0.894          0         0
    > optimx.L-BFGS-B                   1.390    0.005   1.407          0         0
    > nloptwrap.NLOPT_LN_NELDERMEAD     0.976    0.003   0.984          0         0
    > nloptwrap.NLOPT_LN_BOBYQA         0.996    0.002   1.004          0         0
    > 
    > $feval
    >                         bobyqa                   Nelder_Mead
    >                            572                          2605
    >                     nlminbwrap                         nmkbw
    >                             NA                           728
    >                optimx.L-BFGS-B nloptwrap.NLOPT_LN_NELDERMEAD
    >                             44                           904
    >      nloptwrap.NLOPT_LN_BOBYQA
    >                            972
    > 
    > Warm Regards,
    > Alex
    > 
    > On 9/2/21, 4:04 PM, "Phillip Alday" <me at phillipalday.com> wrote:
    > 
    >      I don't have time to give more thorough help at the moment, but look at
    >      the help page on converge, accessible via ?convergence in R or mirrored
    >      online, e.g. https://rdrr.io/cran/lme4/man/convergence.html
    > 
    >      Hope that helps
    > 
    >      Phillip
    > 
    >      On 02/09/2021 09:58, Alex Waldman wrote:
    >      > Dear All,
    >      >
    >      > I have a dataset with 119 individuals with information on the presence of lesions of various types (1,2,3) at various levels (1,2,3) and want to understand the effect of type and location on lesion presence. Therefore, I ran the following:
    >      >
    >      > glmer.model<-glmer(LesionPresence ~ Location*Type + (1 | ID), data=lesion_proportion_staged_level, family="binomial")
    >      >
    >      > Unfortunately, I ran into the following warning:
    >      >
    >      > In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv, :
    >      > Model failed to converge with max|grad| = 0.048092 (tol = 0.002, component 1)
    >      >
    >      > I'm quite new to running mixed models and even with some googling am still unsure why I am running into this issue? Any insight would be much appreciated. I am attaching the model output below and the input data in case that is helpful and do let me know if you need any additional information:
    >      > Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) [
    >      > glmerMod]
    >      > Family: binomial  ( logit )
    >      > Formula: LesionPresence ~ Level * LesionType + (1 | ID)
    >      >    Data: lesion_proportion_staged_level
    >      >
    >      >      AIC      BIC   logLik deviance df.resid
    >      >   1080.4   1129.2   -530.2   1060.4      962
    >      >
    >      > Scaled residuals:
    >      >     Min      1Q  Median      3Q     Max
    >      > -1.6875 -0.5649 -0.3291  0.7170  4.2816
    >      >
    >      > Random effects:
    >      > Groups Name        Variance Std.Dev.
    >      > ID     (Intercept) 1.519    1.232
    >      > Number of obs: 972, groups:  ID, 119
    >      >
    >      > Fixed effects:
    >      >                    Estimate Std. Error z value Pr(>|z|)
    >      > (Intercept)         -1.6081     0.2966  -5.423 5.87e-08 ***
    >      > Level1              -0.6006     0.3900  -1.540 0.123600
    >      > Level2              -0.7270     0.4094  -1.776 0.075782 .
    >      > LesionType1          1.6362     0.3538   4.624 3.76e-06 ***
    >      > LesionType2          1.1659     0.3524   3.309 0.000938 ***
    >      > Level1:LesionType1  -0.3568     0.5022  -0.711 0.477379
    >      > Level2:LesionType1  -0.2015     0.5211  -0.387 0.698986
    >      > Level1:LesionType2   0.4030     0.5004   0.805 0.420607
    >      > Level2:LesionType2   0.1608     0.5229   0.308 0.758387
    >      > ---
    >      > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
    >      >
    >      > Correlation of Fixed Effects:
    >      >             (Intr) Level1 Level2 LsnTy1 LsnTy2 L1:LT1 L2:LT1 L1:LT2
    >      > Level1      -0.603
    >      > Level2      -0.574  0.447
    >      > LesionType1 -0.703  0.498  0.475
    >      > LesionType2 -0.694  0.503  0.479  0.582
    >      > Lvl1:LsnTy1  0.480 -0.766 -0.339 -0.691 -0.400
    >      > Lvl2:LsnTy1  0.461 -0.344 -0.775 -0.665 -0.385  0.466
    >      > Lvl1:LsnTy2  0.468 -0.772 -0.344 -0.392 -0.692  0.598  0.268
    >      > Lvl2:LsnTy2  0.453 -0.344 -0.773 -0.379 -0.665  0.267  0.607  0.468
    >      > optimizer (Nelder_Mead) convergence code: 0 (OK)
    >      > Model failed to converge with max|grad| = 0.048092 (tol = 0.002, component 1)
    >      > _______________________________________________
    >      > R-sig-mixed-models at r-project.org mailing list
    >      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    > 
    > _______________________________________________
    > R-sig-mixed-models at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    > 

    -- 
    Dr. Benjamin Bolker
    Professor, Mathematics & Statistics and Biology, McMaster University
    Director, School of Computational Science and Engineering
    Graduate chair, Mathematics & Statistics

    _______________________________________________
    R-sig-mixed-models at r-project.org mailing list
    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From me @end|ng |rom ph||||p@|d@y@com  Thu Sep  2 22:06:38 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Thu, 2 Sep 2021 15:06:38 -0500
Subject: [R-sig-ME] Convergence Issue
In-Reply-To: <14D19070-B92D-42FE-AA9C-A4DE48550E5F@OX.AC.UK>
References: <18193AEB-C9E9-48F0-955A-82058CB76DC4@OX.AC.UK>
 <2435404c-8154-3c1a-e596-4f76b7e99e3e@phillipalday.com>
 <9ECF0813-50CD-4879-9EEC-4DEB7A83B325@OX.AC.UK>
 <14595f87-7e4c-1dfb-7c28-94990b0d2dcd@gmail.com>
 <14D19070-B92D-42FE-AA9C-A4DE48550E5F@OX.AC.UK>
Message-ID: <8245566a-6d78-fcb2-97d6-03cbf963c3d8@phillipalday.com>

Why not just use a contrast coding scheme that represents your
hypotheses directly in the model rather than computing them post-hoc
with emmeans? That's both a general commentary on scientific practice
and relevant advice for this situation because emmeans may struggle with
a model that's having some convergence issues. (I agree with Ben though
-- all the optimizers gave the same answer, so you're probably fine with
the result.)


On 02/09/2021 11:54, Alex Waldman wrote:
> Thanks! I plotted the fixed-effect estimates and CIs and they all look quite similar (attached). Since I'm interested in extracting the marginal means with emmeans and performing contrasts, I guess I shouldn't worry?
>
> Warm Regards,
> Alex
>
> ?On 9/2/21, 5:04 PM, "R-sig-mixed-models on behalf of Ben Bolker" <r-sig-mixed-models-bounces at r-project.org on behalf of bbolker at gmail.com> wrote:
>
>        Without digging in deeply: the results across optimizers all look 
>     very similar to each other, so unless you need extremely precise answers 
>     I would say everything's OK.
>
>        You could dig in further to look at the fixed-effect estimates (if 
>     that's what you're interested in) in conjunction with the approximate 
>     (Wald) confidence intervals, e.g.:
>
>     library(lme4)
>     library(broom.mixed)
>     library(purrr)
>     library(ggplot2)
>
>     gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
>                         data = cbpp, family = binomial)
>     aa <- allFit(gm1)
>
>     tt <- purrr::map_dfr(aa, tidy, effect = "fixed", .id="optimizer")
>     ggplot(tt, aes(x=term, y=estimate, ymin=estimate-2*std.error,
>              ymax =    estimate+2*std.error, colour=optimizer)) +
>               geom_pointrange(position=position_dodge(width=0.25))
>
>        (with apologies to people who are allergic to the tidyverse)
>
>
>     On 9/2/21 11:32 AM, Alex Waldman wrote:
>     > Thank you! This was helpful.
>     > 
>     > When I tried double-checking the Hessian calculation, I got the following error:
>     > 
>     > Error in chol.default(hess) : the leading minor of order 6 is not positive definite
>     > 
>     > Could this provide any indication as to why the model isn't converging?
>     > 
>     > I also tested all the optimizers and got the following result but was unsure how to interpret:
>     > 
>     > $which.OK
>     >                         bobyqa                   Nelder_Mead
>     >                           TRUE                          TRUE
>     >                     nlminbwrap                         nmkbw
>     >                           TRUE                          TRUE
>     >                optimx.L-BFGS-B nloptwrap.NLOPT_LN_NELDERMEAD
>     >                           TRUE                          TRUE
>     >      nloptwrap.NLOPT_LN_BOBYQA
>     >                           TRUE
>     > 
>     > $msgs
>     > $msgs$bobyqa
>     > NULL
>     > 
>     > $msgs$Nelder_Mead
>     > [1] "Model failed to converge with max|grad| = 0.0555727 (tol = 0.002, component 1)"
>     > 
>     > $msgs$nlminbwrap
>     > NULL
>     > 
>     > $msgs$nmkbw
>     > [1] "Model failed to converge with max|grad| = 0.0083782 (tol = 0.002, component 1)"
>     > 
>     > $msgs$`optimx.L-BFGS-B`
>     > NULL
>     > 
>     > $msgs$nloptwrap.NLOPT_LN_NELDERMEAD
>     > NULL
>     > 
>     > $msgs$nloptwrap.NLOPT_LN_BOBYQA
>     > [1] "Model failed to converge with max|grad| = 0.0122376 (tol = 0.002, component 1)"
>     > 
>     > 
>     > $fixef
>     >                                (Intercept)     Level1     Level2 LesionType1 LesionType2
>     > bobyqa                          -1.607709 -0.5906779 -0.7133361    1.633654    1.169556
>     > Nelder_Mead                     -1.609343 -0.5990970 -0.7248756    1.637308    1.166614
>     > nlminbwrap                      -1.607742 -0.5906431 -0.7133012    1.633691    1.169589
>     > nmkbw                           -1.612150 -0.5911478 -0.7154765    1.638517    1.173022
>     > optimx.L-BFGS-B                 -1.612203 -0.5921513 -0.7152118    1.638355    1.173146
>     > nloptwrap.NLOPT_LN_NELDERMEAD   -1.612326 -0.5921231 -0.7148693    1.638615    1.173143
>     > nloptwrap.NLOPT_LN_BOBYQA       -1.608554 -0.5974722 -0.7194175    1.634395    1.169306
>     >                                Level1:LesionType1 Level2:LesionType1 Level1:LesionType2
>     > bobyqa                                -0.3646982         -0.2118206          0.3897427
>     > Nelder_Mead                           -0.3570757         -0.2053771          0.4027594
>     > nlminbwrap                            -0.3647408         -0.2118542          0.3897106
>     > nmkbw                                 -0.3675755         -0.2125293          0.3896785
>     > optimx.L-BFGS-B                       -0.3660791         -0.2125631          0.3904246
>     > nloptwrap.NLOPT_LN_NELDERMEAD         -0.3663036         -0.2131734          0.3905315
>     > nloptwrap.NLOPT_LN_BOBYQA             -0.3597335         -0.2075374          0.3969647
>     >                                Level2:LesionType2
>     > bobyqa                                 0.1426930
>     > Nelder_Mead                            0.1586086
>     > nlminbwrap                             0.1426555
>     > nmkbw                                  0.1436730
>     > optimx.L-BFGS-B                        0.1426133
>     > nloptwrap.NLOPT_LN_NELDERMEAD          0.1423522
>     > nloptwrap.NLOPT_LN_BOBYQA              0.1474815
>     > 
>     > $llik
>     >                         bobyqa                   Nelder_Mead
>     >                      -530.1908                     -530.1818
>     >                     nlminbwrap                         nmkbw
>     >                      -530.1908                     -530.1810
>     >                optimx.L-BFGS-B nloptwrap.NLOPT_LN_NELDERMEAD
>     >                      -530.1810                     -530.1810
>     >      nloptwrap.NLOPT_LN_BOBYQA
>     >                      -530.1812
>     > 
>     > $sdcor
>     >                                ID.(Intercept)
>     > bobyqa                              1.227682
>     > Nelder_Mead                         1.232220
>     > nlminbwrap                          1.227685
>     > nmkbw                               1.231678
>     > optimx.L-BFGS-B                     1.231639
>     > nloptwrap.NLOPT_LN_NELDERMEAD       1.231837
>     > nloptwrap.NLOPT_LN_BOBYQA           1.231765
>     > 
>     > $theta
>     >                                ID.(Intercept)
>     > bobyqa                              1.227682
>     > Nelder_Mead                         1.232220
>     > nlminbwrap                          1.227685
>     > nmkbw                               1.231678
>     > optimx.L-BFGS-B                     1.231639
>     > nloptwrap.NLOPT_LN_NELDERMEAD       1.231837
>     > nloptwrap.NLOPT_LN_BOBYQA           1.231765
>     > 
>     > $times
>     >                                user.self sys.self elapsed user.child sys.child
>     > bobyqa                            0.633    0.003   0.638          0         0
>     > Nelder_Mead                       2.401    0.003   2.405          0         0
>     > nlminbwrap                        0.581    0.001   0.585          0         0
>     > nmkbw                             0.885    0.004   0.894          0         0
>     > optimx.L-BFGS-B                   1.390    0.005   1.407          0         0
>     > nloptwrap.NLOPT_LN_NELDERMEAD     0.976    0.003   0.984          0         0
>     > nloptwrap.NLOPT_LN_BOBYQA         0.996    0.002   1.004          0         0
>     > 
>     > $feval
>     >                         bobyqa                   Nelder_Mead
>     >                            572                          2605
>     >                     nlminbwrap                         nmkbw
>     >                             NA                           728
>     >                optimx.L-BFGS-B nloptwrap.NLOPT_LN_NELDERMEAD
>     >                             44                           904
>     >      nloptwrap.NLOPT_LN_BOBYQA
>     >                            972
>     > 
>     > Warm Regards,
>     > Alex
>     > 
>     > On 9/2/21, 4:04 PM, "Phillip Alday" <me at phillipalday.com> wrote:
>     > 
>     >      I don't have time to give more thorough help at the moment, but look at
>     >      the help page on converge, accessible via ?convergence in R or mirrored
>     >      online, e.g. https://rdrr.io/cran/lme4/man/convergence.html
>     > 
>     >      Hope that helps
>     > 
>     >      Phillip
>     > 
>     >      On 02/09/2021 09:58, Alex Waldman wrote:
>     >      > Dear All,
>     >      >
>     >      > I have a dataset with 119 individuals with information on the presence of lesions of various types (1,2,3) at various levels (1,2,3) and want to understand the effect of type and location on lesion presence. Therefore, I ran the following:
>     >      >
>     >      > glmer.model<-glmer(LesionPresence ~ Location*Type + (1 | ID), data=lesion_proportion_staged_level, family="binomial")
>     >      >
>     >      > Unfortunately, I ran into the following warning:
>     >      >
>     >      > In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv, :
>     >      > Model failed to converge with max|grad| = 0.048092 (tol = 0.002, component 1)
>     >      >
>     >      > I'm quite new to running mixed models and even with some googling am still unsure why I am running into this issue? Any insight would be much appreciated. I am attaching the model output below and the input data in case that is helpful and do let me know if you need any additional information:
>     >      > Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) [
>     >      > glmerMod]
>     >      > Family: binomial  ( logit )
>     >      > Formula: LesionPresence ~ Level * LesionType + (1 | ID)
>     >      >    Data: lesion_proportion_staged_level
>     >      >
>     >      >      AIC      BIC   logLik deviance df.resid
>     >      >   1080.4   1129.2   -530.2   1060.4      962
>     >      >
>     >      > Scaled residuals:
>     >      >     Min      1Q  Median      3Q     Max
>     >      > -1.6875 -0.5649 -0.3291  0.7170  4.2816
>     >      >
>     >      > Random effects:
>     >      > Groups Name        Variance Std.Dev.
>     >      > ID     (Intercept) 1.519    1.232
>     >      > Number of obs: 972, groups:  ID, 119
>     >      >
>     >      > Fixed effects:
>     >      >                    Estimate Std. Error z value Pr(>|z|)
>     >      > (Intercept)         -1.6081     0.2966  -5.423 5.87e-08 ***
>     >      > Level1              -0.6006     0.3900  -1.540 0.123600
>     >      > Level2              -0.7270     0.4094  -1.776 0.075782 .
>     >      > LesionType1          1.6362     0.3538   4.624 3.76e-06 ***
>     >      > LesionType2          1.1659     0.3524   3.309 0.000938 ***
>     >      > Level1:LesionType1  -0.3568     0.5022  -0.711 0.477379
>     >      > Level2:LesionType1  -0.2015     0.5211  -0.387 0.698986
>     >      > Level1:LesionType2   0.4030     0.5004   0.805 0.420607
>     >      > Level2:LesionType2   0.1608     0.5229   0.308 0.758387
>     >      > ---
>     >      > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>     >      >
>     >      > Correlation of Fixed Effects:
>     >      >             (Intr) Level1 Level2 LsnTy1 LsnTy2 L1:LT1 L2:LT1 L1:LT2
>     >      > Level1      -0.603
>     >      > Level2      -0.574  0.447
>     >      > LesionType1 -0.703  0.498  0.475
>     >      > LesionType2 -0.694  0.503  0.479  0.582
>     >      > Lvl1:LsnTy1  0.480 -0.766 -0.339 -0.691 -0.400
>     >      > Lvl2:LsnTy1  0.461 -0.344 -0.775 -0.665 -0.385  0.466
>     >      > Lvl1:LsnTy2  0.468 -0.772 -0.344 -0.392 -0.692  0.598  0.268
>     >      > Lvl2:LsnTy2  0.453 -0.344 -0.773 -0.379 -0.665  0.267  0.607  0.468
>     >      > optimizer (Nelder_Mead) convergence code: 0 (OK)
>     >      > Model failed to converge with max|grad| = 0.048092 (tol = 0.002, component 1)
>     >      > _______________________________________________
>     >      > R-sig-mixed-models at r-project.org mailing list
>     >      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     > 
>     > _______________________________________________
>     > R-sig-mixed-models at r-project.org mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     > 
>
>     -- 
>     Dr. Benjamin Bolker
>     Professor, Mathematics & Statistics and Biology, McMaster University
>     Director, School of Computational Science and Engineering
>     Graduate chair, Mathematics & Statistics
>
>     _______________________________________________
>     R-sig-mixed-models at r-project.org mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From @|ex@w@|dm@n @end|ng |rom @jc@ox@@c@uk  Fri Sep  3 14:43:48 2021
From: @|ex@w@|dm@n @end|ng |rom @jc@ox@@c@uk (Alex Waldman)
Date: Fri, 3 Sep 2021 12:43:48 +0000
Subject: [R-sig-ME] Beta-Binomial Model Question
Message-ID: <1D9A6B04-FA9C-4591-B190-F800450D521F@OX.AC.UK>

Dear All,

My apologies for the additional question. I am working with data in which I have information on the proportional area taken by a lesion in different locations (region 1, 2, and 3) stratified by different lesion types (lesion type 1, 2, and 3). The denominator to derive the proportion will be different for each of the different locations. The data includes 0 and 1. Therefore, I was thinking of using a beta-binomial model. However, in my formula I included the proportion information as the response:

glmmTMB::glmmTMB(LesionAreaRatio ~ Location*LesionType + (1 | ID), family=betabinomial, data=total_data_staged, REML=TRUE, control=glmmTMBControl(optimizer=optim, optArgs=list(method="BFGS")))

I then got the following warnings:


  1.  In eval(family$initialize) : non-integer #successes in a binomial glm!
  2.  In fitTMB(TMBStruc) : Model convergence problem; extreme or very small eigenvalues detected. See vignette('troubleshooting')

I looked in the vignette and this made we wonder if this would be the right model type to use since the proportions are not success/failure data per se but rather represent a normalized area?

In addition, my data seems to be skewed toward 0s and I thought zero-inflation may be appropriate. When trying varying zero-inflation formulas I consistently received the following error (the eigenvalue error went away):

In fitTMB(TMBStruc) :
Model convergence problem; non-positive-definite Hessian matrix. See vignette('troubleshooting')

I looked in the vignette and noticed that the zero-inflation parameter was very negative no matter what I included in the zero-inflation model formula. I don?t get the Hessian matrix error if the zero-inflation is removed. Therefore, would that indicate that it is appropriate to leave out the zero-inflation?

Thanks again for all your help as this is all new to me and I want to make sure I?m going down the right path and not unnecessarily overcomplicating things.

Warm Regards,
Alex

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Sat Sep  4 03:33:11 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 3 Sep 2021 21:33:11 -0400
Subject: [R-sig-ME] Beta-Binomial Model Question
In-Reply-To: <1D9A6B04-FA9C-4591-B190-F800450D521F@OX.AC.UK>
References: <1D9A6B04-FA9C-4591-B190-F800450D521F@OX.AC.UK>
Message-ID: <cfdb7dc8-6304-640a-301e-07e63d5986e3@gmail.com>

   This is an interesting case.

   Beta-binomial models are *not* really appropriate for non-integer 
data; you'd be better off with a straight Beta model (see e.g. Smithson 
and Verkuilen "A better lemon squeezer" 2006).

   However, the Beta distribution has some disadvantages:

  * you have to think about how to incorporate the effects of the 
denominator in the model.  Does having a larger denominator affect the 
precision of the answer in an obvious way?  I can't immediately think of 
a sensible way to use an offset as one would in e.g. a Poisson model 
(where you would include the total counts rather than counts/area, then 
include log(area) in the model as an offset).

  * The Beta doesn't incorporate zero and one counts naturally. glmmTMB 
allows zero-inflation, but not zero-one inflation (brms will do this for 
mixed models; zoib will for non-mixed models).  Do you have a large 
proportion of zeros and ones? (If not, you can 'squeeze' them in a bit 
as in Smithson & Verkuilen) Do 0/1 values represent censoring (below a 
threshold for distinguishing from 0/1, i.e. measurement resolution) or a 
distinct category?

The fact that you got very negative zero-inflation values suggests that 
the model doesn't need them, but that will change when you go from 
Beta-binomial to Beta (at which point *all* zeroes will be 'structural' 
zeroes; if you use an intercept-only Z-I model (~1), this will basically 
just be an estimate of the fraction of zeros in the data).

  There is an experimental diagnose() function that's supposed to help 
you interpret problems with the model fit ...



On 9/3/21 8:43 AM, Alex Waldman wrote:
> Dear All,
> 
> My apologies for the additional question. I am working with data in which I have information on the proportional area taken by a lesion in different locations (region 1, 2, and 3) stratified by different lesion types (lesion type 1, 2, and 3). The denominator to derive the proportion will be different for each of the different locations. The data includes 0 and 1. Therefore, I was thinking of using a beta-binomial model. However, in my formula I included the proportion information as the response:
> 
> glmmTMB::glmmTMB(LesionAreaRatio ~ Location*LesionType + (1 | ID), family=betabinomial, data=total_data_staged, REML=TRUE, control=glmmTMBControl(optimizer=optim, optArgs=list(method="BFGS")))
> 
> I then got the following warnings:
> 
> 
>    1.  In eval(family$initialize) : non-integer #successes in a binomial glm!
>    2.  In fitTMB(TMBStruc) : Model convergence problem; extreme or very small eigenvalues detected. See vignette('troubleshooting')
> 
> I looked in the vignette and this made we wonder if this would be the right model type to use since the proportions are not success/failure data per se but rather represent a normalized area?
> 
> In addition, my data seems to be skewed toward 0s and I thought zero-inflation may be appropriate. When trying varying zero-inflation formulas I consistently received the following error (the eigenvalue error went away):
> 
> In fitTMB(TMBStruc) :
> Model convergence problem; non-positive-definite Hessian matrix. See vignette('troubleshooting')
> 
> I looked in the vignette and noticed that the zero-inflation parameter was very negative no matter what I included in the zero-inflation model formula. I don?t get the Hessian matrix error if the zero-inflation is removed. Therefore, would that indicate that it is appropriate to leave out the zero-inflation?
> 
> Thanks again for all your help as this is all new to me and I want to make sure I?m going down the right path and not unnecessarily overcomplicating things.
> 
> Warm Regards,
> Alex
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics


From @|ex@w@|dm@n @end|ng |rom @jc@ox@@c@uk  Sat Sep  4 22:28:26 2021
From: @|ex@w@|dm@n @end|ng |rom @jc@ox@@c@uk (Alex Waldman)
Date: Sat, 4 Sep 2021 20:28:26 +0000
Subject: [R-sig-ME] Beta-Binomial Model Question
In-Reply-To: <cfdb7dc8-6304-640a-301e-07e63d5986e3@gmail.com>
References: <1D9A6B04-FA9C-4591-B190-F800450D521F@OX.AC.UK>
 <cfdb7dc8-6304-640a-301e-07e63d5986e3@gmail.com>
Message-ID: <DFC036E2-D4E1-4C72-BA2C-53A9AB4AB855@OX.AC.UK>

Thanks this is helpful! 

1. The larger denominator is just inherent to the different regions (the cervical, thoracic, and lumbar spinal cord are different sizes) and won't affect the precision of the answer. It is just used to normalize the lesional area so that I can garner an understanding of the differences between regions.

2. I do have a large proportion of 0s but not 1s (I don?t even think 1s appear in the data). 0s represent a distinct category (ie cases that had no lesions at that particular region or of a particular lesion type).

Given those clarifications:

1. Would it be appropriate to directly use the tabulated proportions (ie lesional area/total area) in a beta model? 
2. Would transforming the data and using the beta model without zero inflation or using the zero-inflated beta be preferred? Is there a way to test this by detecting how much zero-inflation is actually present?
3. If I do move forward with the zero-inflated beta model, is it possible to test what terms should be included in the zero-inflated part of the model?

Thanks again for your help!

Warm Regards,
Alex 

?On 9/4/21, 2:33 AM, "R-sig-mixed-models on behalf of Ben Bolker" <r-sig-mixed-models-bounces at r-project.org on behalf of bbolker at gmail.com> wrote:

       This is an interesting case.

       Beta-binomial models are *not* really appropriate for non-integer 
    data; you'd be better off with a straight Beta model (see e.g. Smithson 
    and Verkuilen "A better lemon squeezer" 2006).

       However, the Beta distribution has some disadvantages:

      * you have to think about how to incorporate the effects of the 
    denominator in the model.  Does having a larger denominator affect the 
    precision of the answer in an obvious way?  I can't immediately think of 
    a sensible way to use an offset as one would in e.g. a Poisson model 
    (where you would include the total counts rather than counts/area, then 
    include log(area) in the model as an offset).

      * The Beta doesn't incorporate zero and one counts naturally. glmmTMB 
    allows zero-inflation, but not zero-one inflation (brms will do this for 
    mixed models; zoib will for non-mixed models).  Do you have a large 
    proportion of zeros and ones? (If not, you can 'squeeze' them in a bit 
    as in Smithson & Verkuilen) Do 0/1 values represent censoring (below a 
    threshold for distinguishing from 0/1, i.e. measurement resolution) or a 
    distinct category?

    The fact that you got very negative zero-inflation values suggests that 
    the model doesn't need them, but that will change when you go from 
    Beta-binomial to Beta (at which point *all* zeroes will be 'structural' 
    zeroes; if you use an intercept-only Z-I model (~1), this will basically 
    just be an estimate of the fraction of zeros in the data).

      There is an experimental diagnose() function that's supposed to help 
    you interpret problems with the model fit ...



    On 9/3/21 8:43 AM, Alex Waldman wrote:
    > Dear All,
    > 
    > My apologies for the additional question. I am working with data in which I have information on the proportional area taken by a lesion in different locations (region 1, 2, and 3) stratified by different lesion types (lesion type 1, 2, and 3). The denominator to derive the proportion will be different for each of the different locations. The data includes 0 and 1. Therefore, I was thinking of using a beta-binomial model. However, in my formula I included the proportion information as the response:
    > 
    > glmmTMB::glmmTMB(LesionAreaRatio ~ Location*LesionType + (1 | ID), family=betabinomial, data=total_data_staged, REML=TRUE, control=glmmTMBControl(optimizer=optim, optArgs=list(method="BFGS")))
    > 
    > I then got the following warnings:
    > 
    > 
    >    1.  In eval(family$initialize) : non-integer #successes in a binomial glm!
    >    2.  In fitTMB(TMBStruc) : Model convergence problem; extreme or very small eigenvalues detected. See vignette('troubleshooting')
    > 
    > I looked in the vignette and this made we wonder if this would be the right model type to use since the proportions are not success/failure data per se but rather represent a normalized area?
    > 
    > In addition, my data seems to be skewed toward 0s and I thought zero-inflation may be appropriate. When trying varying zero-inflation formulas I consistently received the following error (the eigenvalue error went away):
    > 
    > In fitTMB(TMBStruc) :
    > Model convergence problem; non-positive-definite Hessian matrix. See vignette('troubleshooting')
    > 
    > I looked in the vignette and noticed that the zero-inflation parameter was very negative no matter what I included in the zero-inflation model formula. I don?t get the Hessian matrix error if the zero-inflation is removed. Therefore, would that indicate that it is appropriate to leave out the zero-inflation?
    > 
    > Thanks again for all your help as this is all new to me and I want to make sure I?m going down the right path and not unnecessarily overcomplicating things.
    > 
    > Warm Regards,
    > Alex
    > 
    > 	[[alternative HTML version deleted]]
    > 
    > _______________________________________________
    > R-sig-mixed-models at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    > 

    -- 
    Dr. Benjamin Bolker
    Professor, Mathematics & Statistics and Biology, McMaster University
    Director, School of Computational Science and Engineering
    Graduate chair, Mathematics & Statistics

    _______________________________________________
    R-sig-mixed-models at r-project.org mailing list
    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbo|ker @end|ng |rom gm@||@com  Sat Sep  4 22:46:45 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sat, 4 Sep 2021 16:46:45 -0400
Subject: [R-sig-ME] Beta-Binomial Model Question
In-Reply-To: <DFC036E2-D4E1-4C72-BA2C-53A9AB4AB855@OX.AC.UK>
References: <1D9A6B04-FA9C-4591-B190-F800450D521F@OX.AC.UK>
 <cfdb7dc8-6304-640a-301e-07e63d5986e3@gmail.com>
 <DFC036E2-D4E1-4C72-BA2C-53A9AB4AB855@OX.AC.UK>
Message-ID: <b30127d0-6845-663b-3e45-a49e006184ca@gmail.com>



On 9/4/21 4:28 PM, Alex Waldman wrote:
> Thanks this is helpful!
> 
> 1. The larger denominator is just inherent to the different regions (the cervical, thoracic, and lumbar spinal cord are different sizes) and won't affect the precision of the answer. It is just used to normalize the lesional area so that I can garner an understanding of the differences between regions.

  OK.
> 
> 2. I do have a large proportion of 0s but not 1s (I don?t even think 1s appear in the data). 0s represent a distinct category (ie cases that had no lesions at that particular region or of a particular lesion type).
> 
> Given those clarifications:
> 
> 1. Would it be appropriate to directly use the tabulated proportions (ie lesional area/total area) in a beta model?

   Yes.

> 2. Would transforming the data and using the beta model without zero inflation or using the zero-inflated beta be preferred? Is there a way to test this by detecting how much zero-inflation is actually present?

   By "transforming" do you mean computing the proportions?

   If you have zeros in your data and want to fit a model, you *have* to 
use zero-inflation; the likelihood of a zero response under a Beta model 
is either zero (-infinity for log-likelihood) or infinite, except in the 
special case where shape1 = 1 ...

   A zero-inflated Beta model is essentially two separate models fitted 
together for convenience (a hurdle model); that is, prob(zero or 
not-zero) is fitted with a binomial/logistic model, and the conditional 
distribution (i.e., fitting the model to the non-zero values only) is 
fitted with a Beta model.  In other words, since there are no zeros in a 
Beta distribution, a zero in the data is by definition "inflated" (a 
structural zero, sometimes called a "true zero" although I hate that 
terminology).

    "How much zero-inflation is actually present" is just the proportion 
of zeros in the data ... as long as you have any zeros in your data, it 
doesn't really make sense to test "whether" the model is zero-inflated.

> 3. If I do move forward with the zero-inflated beta model, is it possible to test what terms should be included in the zero-inflated part of the model?

   Absolutely.  Your model would be

   glmmTMB(response ~ <stuff>, ziformula = ~ <other stuff>, ...)

  And you can test the effects of different predictors on the 
probability of a zero response in any of the usual ways (Wald p-values 
in summary(), comparing nested models via LRT/anova(), profile 
confidence intervals ...)
> 
> Thanks again for your help!
> 
> Warm Regards,
> Alex
> 
> ?On 9/4/21, 2:33 AM, "R-sig-mixed-models on behalf of Ben Bolker" <r-sig-mixed-models-bounces at r-project.org on behalf of bbolker at gmail.com> wrote:
> 
>         This is an interesting case.
> 
>         Beta-binomial models are *not* really appropriate for non-integer
>      data; you'd be better off with a straight Beta model (see e.g. Smithson
>      and Verkuilen "A better lemon squeezer" 2006).
> 
>         However, the Beta distribution has some disadvantages:
> 
>        * you have to think about how to incorporate the effects of the
>      denominator in the model.  Does having a larger denominator affect the
>      precision of the answer in an obvious way?  I can't immediately think of
>      a sensible way to use an offset as one would in e.g. a Poisson model
>      (where you would include the total counts rather than counts/area, then
>      include log(area) in the model as an offset).
> 
>        * The Beta doesn't incorporate zero and one counts naturally. glmmTMB
>      allows zero-inflation, but not zero-one inflation (brms will do this for
>      mixed models; zoib will for non-mixed models).  Do you have a large
>      proportion of zeros and ones? (If not, you can 'squeeze' them in a bit
>      as in Smithson & Verkuilen) Do 0/1 values represent censoring (below a
>      threshold for distinguishing from 0/1, i.e. measurement resolution) or a
>      distinct category?
> 
>      The fact that you got very negative zero-inflation values suggests that
>      the model doesn't need them, but that will change when you go from
>      Beta-binomial to Beta (at which point *all* zeroes will be 'structural'
>      zeroes; if you use an intercept-only Z-I model (~1), this will basically
>      just be an estimate of the fraction of zeros in the data).
> 
>        There is an experimental diagnose() function that's supposed to help
>      you interpret problems with the model fit ...
> 
> 
> 
>      On 9/3/21 8:43 AM, Alex Waldman wrote:
>      > Dear All,
>      >
>      > My apologies for the additional question. I am working with data in which I have information on the proportional area taken by a lesion in different locations (region 1, 2, and 3) stratified by different lesion types (lesion type 1, 2, and 3). The denominator to derive the proportion will be different for each of the different locations. The data includes 0 and 1. Therefore, I was thinking of using a beta-binomial model. However, in my formula I included the proportion information as the response:
>      >
>      > glmmTMB::glmmTMB(LesionAreaRatio ~ Location*LesionType + (1 | ID), family=betabinomial, data=total_data_staged, REML=TRUE, control=glmmTMBControl(optimizer=optim, optArgs=list(method="BFGS")))
>      >
>      > I then got the following warnings:
>      >
>      >
>      >    1.  In eval(family$initialize) : non-integer #successes in a binomial glm!
>      >    2.  In fitTMB(TMBStruc) : Model convergence problem; extreme or very small eigenvalues detected. See vignette('troubleshooting')
>      >
>      > I looked in the vignette and this made we wonder if this would be the right model type to use since the proportions are not success/failure data per se but rather represent a normalized area?
>      >
>      > In addition, my data seems to be skewed toward 0s and I thought zero-inflation may be appropriate. When trying varying zero-inflation formulas I consistently received the following error (the eigenvalue error went away):
>      >
>      > In fitTMB(TMBStruc) :
>      > Model convergence problem; non-positive-definite Hessian matrix. See vignette('troubleshooting')
>      >
>      > I looked in the vignette and noticed that the zero-inflation parameter was very negative no matter what I included in the zero-inflation model formula. I don?t get the Hessian matrix error if the zero-inflation is removed. Therefore, would that indicate that it is appropriate to leave out the zero-inflation?
>      >
>      > Thanks again for all your help as this is all new to me and I want to make sure I?m going down the right path and not unnecessarily overcomplicating things.
>      >
>      > Warm Regards,
>      > Alex
>      >
>      > 	[[alternative HTML version deleted]]
>      >
>      > _______________________________________________
>      > R-sig-mixed-models at r-project.org mailing list
>      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>      >
> 
>      --
>      Dr. Benjamin Bolker
>      Professor, Mathematics & Statistics and Biology, McMaster University
>      Director, School of Computational Science and Engineering
>      Graduate chair, Mathematics & Statistics
> 
>      _______________________________________________
>      R-sig-mixed-models at r-project.org mailing list
>      https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics


From @|ex@w@|dm@n @end|ng |rom @jc@ox@@c@uk  Mon Sep  6 01:46:25 2021
From: @|ex@w@|dm@n @end|ng |rom @jc@ox@@c@uk (Alex Waldman)
Date: Sun, 5 Sep 2021 23:46:25 +0000
Subject: [R-sig-ME] Beta-Binomial Model Question
In-Reply-To: <b30127d0-6845-663b-3e45-a49e006184ca@gmail.com>
References: <1D9A6B04-FA9C-4591-B190-F800450D521F@OX.AC.UK>
 <cfdb7dc8-6304-640a-301e-07e63d5986e3@gmail.com>
 <DFC036E2-D4E1-4C72-BA2C-53A9AB4AB855@OX.AC.UK>
 <b30127d0-6845-663b-3e45-a49e006184ca@gmail.com>
Message-ID: <C366F745-7201-42EA-AB96-61047A4FA910@OX.AC.UK>

Thanks! By transforming I was thinking of adding 0.001 to the 0s and subtracting 0.001 to the 1s. Is that a viable alternative to using a zero-inflated model?

Warm Regards,
Alex

?On 9/4/21, 9:47 PM, "Ben Bolker" <bbolker at gmail.com> wrote:



    On 9/4/21 4:28 PM, Alex Waldman wrote:
    > Thanks this is helpful!
    > 
    > 1. The larger denominator is just inherent to the different regions (the cervical, thoracic, and lumbar spinal cord are different sizes) and won't affect the precision of the answer. It is just used to normalize the lesional area so that I can garner an understanding of the differences between regions.

      OK.
    > 
    > 2. I do have a large proportion of 0s but not 1s (I don?t even think 1s appear in the data). 0s represent a distinct category (ie cases that had no lesions at that particular region or of a particular lesion type).
    > 
    > Given those clarifications:
    > 
    > 1. Would it be appropriate to directly use the tabulated proportions (ie lesional area/total area) in a beta model?

       Yes.

    > 2. Would transforming the data and using the beta model without zero inflation or using the zero-inflated beta be preferred? Is there a way to test this by detecting how much zero-inflation is actually present?

       By "transforming" do you mean computing the proportions?

       If you have zeros in your data and want to fit a model, you *have* to 
    use zero-inflation; the likelihood of a zero response under a Beta model 
    is either zero (-infinity for log-likelihood) or infinite, except in the 
    special case where shape1 = 1 ...

       A zero-inflated Beta model is essentially two separate models fitted 
    together for convenience (a hurdle model); that is, prob(zero or 
    not-zero) is fitted with a binomial/logistic model, and the conditional 
    distribution (i.e., fitting the model to the non-zero values only) is 
    fitted with a Beta model.  In other words, since there are no zeros in a 
    Beta distribution, a zero in the data is by definition "inflated" (a 
    structural zero, sometimes called a "true zero" although I hate that 
    terminology).

        "How much zero-inflation is actually present" is just the proportion 
    of zeros in the data ... as long as you have any zeros in your data, it 
    doesn't really make sense to test "whether" the model is zero-inflated.

    > 3. If I do move forward with the zero-inflated beta model, is it possible to test what terms should be included in the zero-inflated part of the model?

       Absolutely.  Your model would be

       glmmTMB(response ~ <stuff>, ziformula = ~ <other stuff>, ...)

      And you can test the effects of different predictors on the 
    probability of a zero response in any of the usual ways (Wald p-values 
    in summary(), comparing nested models via LRT/anova(), profile 
    confidence intervals ...)
    > 
    > Thanks again for your help!
    > 
    > Warm Regards,
    > Alex
    > 
    > On 9/4/21, 2:33 AM, "R-sig-mixed-models on behalf of Ben Bolker" <r-sig-mixed-models-bounces at r-project.org on behalf of bbolker at gmail.com> wrote:
    > 
    >         This is an interesting case.
    > 
    >         Beta-binomial models are *not* really appropriate for non-integer
    >      data; you'd be better off with a straight Beta model (see e.g. Smithson
    >      and Verkuilen "A better lemon squeezer" 2006).
    > 
    >         However, the Beta distribution has some disadvantages:
    > 
    >        * you have to think about how to incorporate the effects of the
    >      denominator in the model.  Does having a larger denominator affect the
    >      precision of the answer in an obvious way?  I can't immediately think of
    >      a sensible way to use an offset as one would in e.g. a Poisson model
    >      (where you would include the total counts rather than counts/area, then
    >      include log(area) in the model as an offset).
    > 
    >        * The Beta doesn't incorporate zero and one counts naturally. glmmTMB
    >      allows zero-inflation, but not zero-one inflation (brms will do this for
    >      mixed models; zoib will for non-mixed models).  Do you have a large
    >      proportion of zeros and ones? (If not, you can 'squeeze' them in a bit
    >      as in Smithson & Verkuilen) Do 0/1 values represent censoring (below a
    >      threshold for distinguishing from 0/1, i.e. measurement resolution) or a
    >      distinct category?
    > 
    >      The fact that you got very negative zero-inflation values suggests that
    >      the model doesn't need them, but that will change when you go from
    >      Beta-binomial to Beta (at which point *all* zeroes will be 'structural'
    >      zeroes; if you use an intercept-only Z-I model (~1), this will basically
    >      just be an estimate of the fraction of zeros in the data).
    > 
    >        There is an experimental diagnose() function that's supposed to help
    >      you interpret problems with the model fit ...
    > 
    > 
    > 
    >      On 9/3/21 8:43 AM, Alex Waldman wrote:
    >      > Dear All,
    >      >
    >      > My apologies for the additional question. I am working with data in which I have information on the proportional area taken by a lesion in different locations (region 1, 2, and 3) stratified by different lesion types (lesion type 1, 2, and 3). The denominator to derive the proportion will be different for each of the different locations. The data includes 0 and 1. Therefore, I was thinking of using a beta-binomial model. However, in my formula I included the proportion information as the response:
    >      >
    >      > glmmTMB::glmmTMB(LesionAreaRatio ~ Location*LesionType + (1 | ID), family=betabinomial, data=total_data_staged, REML=TRUE, control=glmmTMBControl(optimizer=optim, optArgs=list(method="BFGS")))
    >      >
    >      > I then got the following warnings:
    >      >
    >      >
    >      >    1.  In eval(family$initialize) : non-integer #successes in a binomial glm!
    >      >    2.  In fitTMB(TMBStruc) : Model convergence problem; extreme or very small eigenvalues detected. See vignette('troubleshooting')
    >      >
    >      > I looked in the vignette and this made we wonder if this would be the right model type to use since the proportions are not success/failure data per se but rather represent a normalized area?
    >      >
    >      > In addition, my data seems to be skewed toward 0s and I thought zero-inflation may be appropriate. When trying varying zero-inflation formulas I consistently received the following error (the eigenvalue error went away):
    >      >
    >      > In fitTMB(TMBStruc) :
    >      > Model convergence problem; non-positive-definite Hessian matrix. See vignette('troubleshooting')
    >      >
    >      > I looked in the vignette and noticed that the zero-inflation parameter was very negative no matter what I included in the zero-inflation model formula. I don?t get the Hessian matrix error if the zero-inflation is removed. Therefore, would that indicate that it is appropriate to leave out the zero-inflation?
    >      >
    >      > Thanks again for all your help as this is all new to me and I want to make sure I?m going down the right path and not unnecessarily overcomplicating things.
    >      >
    >      > Warm Regards,
    >      > Alex
    >      >
    >      > 	[[alternative HTML version deleted]]
    >      >
    >      > _______________________________________________
    >      > R-sig-mixed-models at r-project.org mailing list
    >      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    >      >
    > 
    >      --
    >      Dr. Benjamin Bolker
    >      Professor, Mathematics & Statistics and Biology, McMaster University
    >      Director, School of Computational Science and Engineering
    >      Graduate chair, Mathematics & Statistics
    > 
    >      _______________________________________________
    >      R-sig-mixed-models at r-project.org mailing list
    >      https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    > 

    -- 
    Dr. Benjamin Bolker
    Professor, Mathematics & Statistics and Biology, McMaster University
    Director, School of Computational Science and Engineering
    Graduate chair, Mathematics & Statistics


From |@w|@wt @end|ng |rom gm@||@com  Mon Sep  6 20:31:12 2021
From: |@w|@wt @end|ng |rom gm@||@com (Timothy MacKenzie)
Date: Mon, 6 Sep 2021 13:31:12 -0500
Subject: [R-sig-ME] contextual effects in 3-level models
Message-ID: <CADreqizwv=qd8UzCkYVXtEJoXe6GZeMGjSXCerZ24AstV+3_Fg@mail.gmail.com>

Dear All,

Suppose X is a continuous predictor that can vary within and between
two nested grouping variables in a 3-level linear mixed model:

effect.size ~ X + (1 | studies/outcomes)

How can I obtain the within effect of X, contextual effect of X at
level 2, and contextual effect of X at level 3?

I can think of two options but wonder which one makes more sense
(below)?   For both options, I will fit:

effect.size ~ X + X_ave_study + X_ave_outcome + (1 | studies/outcomes)

Thank you,
Tim

library(dplyr)

#-- Option 1:
    data %>%
    group_by(study) %>%
    mutate(X_ave_study = mean(X)) %>%
    group_by(outcome) %>%                         ## Here mean of
outcome *ignoring* studies is computed
    mutate(X_ave_outcome = mean(X))

#-- Option 2:
  data %>%
  group_by(study) %>%
  mutate(X_ave_study = mean(X)) %>%
  group_by(outcome, .add = TRUE) %>%     ## Here mean of outcome
*within* each study is computed
  mutate(X_ave_outcome = mean(X))


From o||verhooker @end|ng |rom pr@t@t|@t|c@@com  Wed Sep  8 17:44:23 2021
From: o||verhooker @end|ng |rom pr@t@t|@t|c@@com (Oliver Hooker)
Date: Wed, 8 Sep 2021 16:44:23 +0100
Subject: [R-sig-ME] Introduction to mixed models using R and Rstudio (IMMR05)
Message-ID: <CAEsSYzzy+j_12qUmATfTACUbCS5JKGeos7XW52sgbjLK5LQgQQ@mail.gmail.com>

Introduction to mixed models using R and Rstudio (IMMR05)



10 November 2021 - 11 November 2021



https://www.prstatistics.com/course/introduction-to-mixed-models-using-r-and-rstudio-immr05/



Course Overview:

In this two day course, we provide a comprehensive practical and
theoretical introduction to multilevel models, also known as hierarchical
or mixed effects models. We will focus primarily on multilevel linear
models, but also cover multilevel generalized linear models. Likewise, we
will also describe Bayesian approaches to multilevel modelling. On Day 1,
we will begin by focusing on *random effects* multilevel models. These
models make it clear how multilevel models are in fact models of models. In
addition, random effects models serve as a solid basis for understanding
mixed effects, i.e. fixed and random effects, models. In this coverage of
random effects, we will also cover the important concepts of statistical
shrinkage in the estimation of effects, as well as intraclass correlation.
We then proceed to cover linear mixed effects models, particularly focusing
on varying intercept and/or varying slopes regresssion models. On Day 2, we
cover further aspects of linear mixed effects models, including multilevel
models for nested and crossed data data, and group level predictor
variables. On Day 2, we also cover Bayesian approaches to multilevel levels
using the brms R package.



THIS IS ONE COURSE IN OUR R SERIES ? LOOK OUT FOR COURSES WITH THE SAME
COURSE IMAGE TO FIND MORE IN THIS SERIES



Email oliverhooker at prstatistiucs.com with any questions



Other upcoming courses



Species Distribution Modeling using R (SDMR04)
www.prstatistics.com/course/species-distribution-modeling-using-r-sdmr04/
21 September 2021 - 30 September 2021



Introduction to eco-phylogenetics and comparative analyses using R (ECPH01)
This course will be delivered live
https://www.prstatistics.com/course/introduction-to-eco-phylogenetics-and-comparative-analyses-using-r-ecph01/
22 September 2021 - 28 September 2021



Multivariate analysis of ecological communities in R with the VEGAN package
(VGNR03)
www.prstatistics.com/course/multivariate-analysis-of-ecological-communities-in-r-with-the-vegan-package-vgnr03/
4 October 2021 - 8 October



Introduction to Data Wrangling and Data Visualization using R (DWDV01)
www.prstatistics.com/course/introduction-to-data-wrangling-and-data-visualization-using-r-dwdv01/
4 October 2021 - 8 October 2021



Introduction to Bayesian modelling with INLA (BMIN02)
https://www.prstatistics.com/course/introduction-to-bayesian-modelling-with-inla-bmin02/
4 October 2021 - 8 October 2021



Landscape genetic data analysis using R (LNDG05)
https://www.prstatistics.com/course/landscape-genetic-data-analysis-using-r-lndg05/
18 October 2021 - 27 October 2021



FREE 1 DAY INTRO TO R AND R STUDIO (FIRR01)

https://www.prstatistics.com/course/free-1-day-intro-to-r-and-r-studio-firr01/

20 October 2021



Introduction to generalised linear models using R and Rstudio (IGLM04)
https://www.prstatistics.com/course/introduction-to-generalised-linear-models-using-r-and-rstudio-iglm04/
3 November 2021 - 4 November 2021



Introduction to mixed models using R and Rstudio (IMMR05)
https://www.prstatistics.com/course/introduction-to-mixed-models-using-r-and-rstudio-immr05/
10 November 2021 - 11 November 2021



Introduction to Machine Learning and Deep Learning using R (IMDL02)
https://www.prstatistics.com/course/introduction-to-machine-learning-and-deep-learning-using-r-imdl02/
17 November 2021 - 18 November 2021



Model selection and model simplification (MSMS02)
https://www.prstatistics.com/course/model-selection-and-model-simplification-msms02/
24 November 2021 - 25 November 2021



Species distribution modelling with Bayesian statistics in R (SDMB03)
www.prstatistics.com/course/species-distribution-modelling-with-bayesian-statistics-in-r-sdmb03/
6 December 2021 - 10 December 2021



Introduction to Hidden Markov and State Space models (HMSS01)
https://www.prstatistics.com/course/introduction-to-hidden-markov-and-state-space-models-hmss01/
8 December 2021 - 9 December 2021



Time Series Data Analysis (TSDA01)
https://www.prstatistics.com/course/time-series-data-analysis-tsda01/
14 December 2021 - 17 December 2021



Bayesian Data Analysis (BADA01)
https://www.prstatistics.com/course/bayesian-data-analysis-bada01/
10th January 2022 - 14th January 2022



Introduction to Stan for Bayesian Data Analysis (ISBD01)
https://www.prstatistics.com/course/introduction-to-stan-for-bayesian-data-analysis-isbd01/
18th January 2022 - 20th January 2022



Stable Isotope Mixing Models using SIBER, SIAR, MixSIAR (SIMM08)
https://www.prstatistics.com/course/stable-isotope-mixing-models-using-r-simm08/
1st February 2022 - 4th February 2022

-- 
Oliver Hooker PhD.
PR statistics

Missing Data Analytics (MDAR01)
www.prstatistics.com/course/online-course-missing-data-analytics-mdar01
8 September 2021 - 10 September 2021

Functional ecology from organism to ecosystem: theory and computation
(FEER02)
www.prstatistics.com/course/functional-ecology-from-organism-to-ecosystem-theory-and-computation-feer02/
13 September 2021 - 17 September 2021

Meta-analysis in ecology, evolution and environmental sciences (METR02)
www.prstatistics.com/course/meta-analysis-in-ecology-evolution-and-environmental-sciences-metr02/
13 September 2021 - 17 September 2021

Species Distribution Modeling using R (SDMR04)
www.prstatistics.com/course/species-distribution-modeling-using-r-sdmr04/
21 September 2021 - 30 September 2021

Phylogenetic comparative methods (PGCM01)
https://www.prstatistics.com/course/phylogenetic-comparative-methods-pgcm01/
22 September 2021 - 28 September 2021

Multivariate analysis of ecological communities in R with the VEGAN package
(VGNR03)
www.prstatistics.com/course/multivariate-analysis-of-ecological-communities-in-r-with-the-vegan-package-vgnr03/
4 October 2021 - 8 October

Introduction to Data Wrangling and Data Visualization using R (DWDV01)
www.prstatistics.com/course/introduction-to-data-wrangling-and-data-visualization-using-r-dwdv01/
4 October 2021 - 8 October 2021

Introduction to Bayesian modelling with INLA (BMIN02)
https://www.prstatistics.com/course/introduction-to-bayesian-modelling-with-inla-bmin02/
4 October 2021 - 8 October 2021

Landscape genetic data analysis using R (LNDG05)
https://www.prstatistics.com/course/landscape-genetic-data-analysis-using-r-lndg05/
18 October 2021 - 27 October 2021

Species distribution modelling with Bayesian statistics in R (SDMB03)
www.prstatistics.com/course/species-distribution-modelling-with-bayesian-statistics-in-r-sdmb03/
6 December 2021 - 10 December 2021

Time Series Data Analysis (TSDA01)
https://www.prstatistics.com/course/time-series-data-analysis-tsda01/
14 December 2021 - 17 December 2021

Bayesian Data Analysis (BADA01)
https://www.prstatistics.com/course/bayesian-data-analysis-bada01/
10th January 2022 - 14th January 2022

Stable Isotope Mixing Models using SIBER, SIAR, MixSIAR (SIMM08)
https://www.prstatistics.com/course/stable-isotope-mixing-models-using-r-simm08/
1st February 2022 - 4th February 2022

www.PRstatistics.com

53 Morrison Street
Glasgow
G5 8LB
+44 (0) 7966500340

	[[alternative HTML version deleted]]


From hedyeh@h @end|ng |rom u@c@edu  Wed Sep  8 18:24:31 2021
From: hedyeh@h @end|ng |rom u@c@edu (Hedyeh Ahmadi)
Date: Wed, 8 Sep 2021 16:24:31 +0000
Subject: [R-sig-ME] A nAGQ=0 question for glmer()
Message-ID: <BYAPR07MB5094D2957657788DBC154CFCD1D49@BYAPR07MB5094.namprd07.prod.outlook.com>

Hello all,
I have the following two questions:

  1.  If one is using a glmer() model with the nAGQ=0 option, I was wondering if there is a way to see if the model has actually converged?
  2.  If the mentioned model runs with no error/warning , does that mean the model has converged?

Any help would be appreciated.

Best,

Hedyeh Ahmadi, Ph.D.
Statistician
Keck School of Medicine
Department of Preventive Medicine
University of Southern California

LinkedIn
www.linkedin.com/in/hedyeh-ahmadi<http://www.linkedin.com/in/hedyeh-ahmadi>
<http://www.linkedin.com/in/hedyeh-ahmadi><http://www.linkedin.com/in/hedyeh-ahmadi>





	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Wed Sep  8 19:13:15 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 8 Sep 2021 13:13:15 -0400
Subject: [R-sig-ME] A nAGQ=0 question for glmer()
In-Reply-To: <BYAPR07MB5094D2957657788DBC154CFCD1D49@BYAPR07MB5094.namprd07.prod.outlook.com>
References: <BYAPR07MB5094D2957657788DBC154CFCD1D49@BYAPR07MB5094.namprd07.prod.outlook.com>
Message-ID: <956ca2ac-fe1d-f097-8fd3-73e75412089c@gmail.com>



On 9/8/21 12:24 PM, Hedyeh Ahmadi wrote:
> Hello all,
> I have the following two questions:
> 
>    1.  If one is using a glmer() model with the nAGQ=0 option, I was wondering if there is a way to see if the model has actually converged?
>    2.  If the mentioned model runs with no error/warning , does that mean the model has converged?
> 

   The convergence diagnostics and messages don't differ between nAGQ=0 
and nAGQ>0 (so, the answer to #2 is 'yes').

   For a fitted model gm1, any problems with convergence will be 
recorded in gm1 at modelinfo; specifically, see the $conv, $warnings, and 
$message components ($conv has two elements, $opt (optimizer convergence 
code) and $lme4 (warnings/non-convergence warnings from lme4). 
$conv$opt should be 0, $conv$lme4 and $warnings should be length-zero.

   For what it's worth, the best description of the 
assumption/approximation that nAGQ=0 makes is in the TMB (!) 
documentation: https://kaskr.github.io/adcomp/_book/Appendix.html, 
section 16.2


> Any help would be appreciated.
> 
> Best,
> 
> Hedyeh Ahmadi, Ph.D.
> Statistician
> Keck School of Medicine
> Department of Preventive Medicine
> University of Southern California
> 
> LinkedIn
> www.linkedin.com/in/hedyeh-ahmadi<http://www.linkedin.com/in/hedyeh-ahmadi>
> <http://www.linkedin.com/in/hedyeh-ahmadi><http://www.linkedin.com/in/hedyeh-ahmadi>
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics


From |e@||e@ch|mer|c @end|ng |rom gm@||@com  Mon Sep  6 16:33:49 2021
From: |e@||e@ch|mer|c @end|ng |rom gm@||@com (=?UTF-8?B?TMOpYSBGaWVzY2hpLU3DqXJpYw==?=)
Date: Mon, 6 Sep 2021 15:33:49 +0100
Subject: [R-sig-ME] Looking for help to test the effect of a grouping factor
 in repeated measures
Message-ID: <CAG_W+XFcprL6RT2OyTsQ4mfNYe2UE2D_NTWwi5yt+HKGpTsDfA@mail.gmail.com>

Hello,

I have a dataset to analyse and I am struggling to build my model set and
was wondering if you could advise me please.

The experimental plan is as follows: several species of animals were
observed for a year, but not regularly (some months have many observations,
others have less). *All individuals belonging to the same species were
housed together in the same terrarium* (unequal number of individuals per
species). The response variable is the number of awake individuals per
terrarium (i.e. per species). The year was divided in 3, unequal, periods
as follows: treatment / control / treatment.

I need to determine the effect of the *Period *(treatment / control), of
the *Species* (12 in total), and of their *Interaction *on the *proportion
of awake animals*. I wanted to use a GLMM with a binomial error
distribution. The problem is that I have repeated measures per species, so
I would like to account for that by using Species as a random effect to
avoid pseudoreplication, but I think I need Species to be a fixed effect
because I want to directly test its effect on my response. Therefore, I
wonder if adding the *Date* (as an integer: number of days since the
beginning of the experiment) to the model does control for these repeated
measures (but I can't use it as a random effect because it is continuous,
and it makes my model too complex to converge when integrated as a fixed
effect), or if I should sum the response per month to use *Month* as a
random effect ordered factor. Or if I could just use a linear model without
bothering, like this: y ~ Treatment * Species !
I am stuck here and would like to avoid taking a mathematically
erroneous approach. Could you advise me please?

I was also wondering what I need to do in order to, in a second phase, be
able to conclude exactly which species were sensitive to the treatment and
which were not?

I am looking forward to hearing back from you, and thank you in advance for
your help!

L?a

-- 
*L?a FIESCHI-MERIC*, PhD student

Laboratoire d'Ecologie et de Conservation des Amphibiens (LECA)
Freshwater and OCeanic science Unit of reSearch (FOCUS)
Universit? de Li?ge (Belgique)
&
Genetics and Ecology of Amphibians Research Group
Center for Evolutionary Ecology and Ethical Conservation
Laurentian University (Canada)

Tel: (+33) (0)6.59.32.29.15 <+32%204%20366%2050%2077>
E-mail: leafieschimeric at gmail.com

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Thu Sep  9 16:19:38 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Thu, 9 Sep 2021 16:19:38 +0200
Subject: [R-sig-ME] 
 Looking for help to test the effect of a grouping factor
 in repeated measures
In-Reply-To: <CAG_W+XFcprL6RT2OyTsQ4mfNYe2UE2D_NTWwi5yt+HKGpTsDfA@mail.gmail.com>
References: <CAG_W+XFcprL6RT2OyTsQ4mfNYe2UE2D_NTWwi5yt+HKGpTsDfA@mail.gmail.com>
Message-ID: <CAJuCY5xFhMPr-xHQrXrsy3eqA-8jw_BMwUsCH1ZeF9SE7q1fow@mail.gmail.com>

Dear Lea,

Please note that you want the binomial distribution. Not the binomial
_error_ distribution.

A model like y ~ treatment * species + (1|date) could make sense if you can
assume that the date could have a common effect on the results. E.g. the
observer being more awake on some days ;-) Use the actual date as a factor
instead of the number of days since the start of the experiment. That is
safer than using the number of days since the start.
If you assume no date effect, then there could be only temporal
autocorrelation within the species. As the strength of the autocorrelation
could be different among species, you could consider fitting a separate
model for every species.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op do 9 sep. 2021 om 15:43 schreef L?a Fieschi-M?ric <
leafieschimeric at gmail.com>:

> Hello,
>
> I have a dataset to analyse and I am struggling to build my model set and
> was wondering if you could advise me please.
>
> The experimental plan is as follows: several species of animals were
> observed for a year, but not regularly (some months have many observations,
> others have less). *All individuals belonging to the same species were
> housed together in the same terrarium* (unequal number of individuals per
> species). The response variable is the number of awake individuals per
> terrarium (i.e. per species). The year was divided in 3, unequal, periods
> as follows: treatment / control / treatment.
>
> I need to determine the effect of the *Period *(treatment / control), of
> the *Species* (12 in total), and of their *Interaction *on the *proportion
> of awake animals*. I wanted to use a GLMM with a binomial error
> distribution. The problem is that I have repeated measures per species, so
> I would like to account for that by using Species as a random effect to
> avoid pseudoreplication, but I think I need Species to be a fixed effect
> because I want to directly test its effect on my response. Therefore, I
> wonder if adding the *Date* (as an integer: number of days since the
> beginning of the experiment) to the model does control for these repeated
> measures (but I can't use it as a random effect because it is continuous,
> and it makes my model too complex to converge when integrated as a fixed
> effect), or if I should sum the response per month to use *Month* as a
> random effect ordered factor. Or if I could just use a linear model without
> bothering, like this: y ~ Treatment * Species !
> I am stuck here and would like to avoid taking a mathematically
> erroneous approach. Could you advise me please?
>
> I was also wondering what I need to do in order to, in a second phase, be
> able to conclude exactly which species were sensitive to the treatment and
> which were not?
>
> I am looking forward to hearing back from you, and thank you in advance for
> your help!
>
> L?a
>
> --
> *L?a FIESCHI-MERIC*, PhD student
>
> Laboratoire d'Ecologie et de Conservation des Amphibiens (LECA)
> Freshwater and OCeanic science Unit of reSearch (FOCUS)
> Universit? de Li?ge (Belgique)
> &
> Genetics and Ecology of Amphibians Research Group
> Center for Evolutionary Ecology and Ethical Conservation
> Laurentian University (Canada)
>
> Tel: (+33) (0)6.59.32.29.15 <+32%204%20366%2050%2077>
> E-mail: leafieschimeric at gmail.com
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From |@w|@wt @end|ng |rom gm@||@com  Thu Sep  9 17:37:43 2021
From: |@w|@wt @end|ng |rom gm@||@com (Timothy MacKenzie)
Date: Thu, 9 Sep 2021 10:37:43 -0500
Subject: [R-sig-ME] contextual effects in 3-level models
In-Reply-To: <CADreqizwv=qd8UzCkYVXtEJoXe6GZeMGjSXCerZ24AstV+3_Fg@mail.gmail.com>
References: <CADreqizwv=qd8UzCkYVXtEJoXe6GZeMGjSXCerZ24AstV+3_Fg@mail.gmail.com>
Message-ID: <CADreqiy509mfWJ9S7GcwrvkLKw40C4=zfEE6TQZ_jtEb18UZEw@mail.gmail.com>

Dear Colleagues,

I'm revising my question for better clarity. Suppose we have two
nested grouping variables (ID1 and ID2). The data structure looks like
below.

To obtain the contextual effects for ID1 and ID2, I wonder which
option is appropriate?

#-- Option 1: Create mean of X across ID1 (X_ave_ID1) and mean of X
across ID2 *ignoring* ID1 (X_ave_ID2)
#-- Option 2: Create mean of X across ID1 (X_ave_ID1) and mean of X
across ID2    *within*  ID1 (X_ave_ID2)

For both options, then, I will fit (in lme4::lmer()):

y ~ X + X_ave_ID1 + X_ave_ID2 + (1 | ID1 / ID2)

Thank you,
Tim

#------ DATA  STRUCTURE AND R CODE:

ID1    ID2                   X                      y
1       1                       0.474111397    1.9534671
1       1                      -0.712228120   0.9355230
1       2                      -0.009957293   1.1088756
1       2                      -1.237918646   0.8675550
2       1                      -0.554944765   2.7831133
2       1                      -0.320668268   0.1479290
2       2                       1.066993108   0.1688187
2       2                     -1.084870417    1.0536264

library(dplyr)

#-- Option 1:
    data %>%
    group_by(ID1) %>%
    mutate(X_ave_ID1 = mean(X)) %>%
    group_by(ID2) %>%
    mutate(X_ave_ID2 = mean(X))

#-- Option 2:
  data %>%
  group_by(ID1) %>%
  mutate(X_ave_ID1 = mean(X)) %>%
  group_by(ID2, .add = TRUE) %>%
  mutate(X_ave_ID2 = mean(X))

On Mon, Sep 6, 2021 at 1:31 PM Timothy MacKenzie <fswfswt at gmail.com> wrote:
>
> Dear All,
>
> Suppose X is a continuous predictor that can vary within and between
> two nested grouping variables in a 3-level linear mixed model:
>
> effect.size ~ X + (1 | studies/outcomes)
>
> How can I obtain the within effect of X, contextual effect of X at
> level 2, and contextual effect of X at level 3?
>
> I can think of two options but wonder which one makes more sense
> (below)?   For both options, I will fit:
>
> effect.size ~ X + X_ave_study + X_ave_outcome + (1 | studies/outcomes)
>
> Thank you,
> Tim
>
> library(dplyr)
>
> #-- Option 1:
>     data %>%
>     group_by(study) %>%
>     mutate(X_ave_study = mean(X)) %>%
>     group_by(outcome) %>%                         ## Here mean of
> outcome *ignoring* studies is computed
>     mutate(X_ave_outcome = mean(X))
>
> #-- Option 2:
>   data %>%
>   group_by(study) %>%
>   mutate(X_ave_study = mean(X)) %>%
>   group_by(outcome, .add = TRUE) %>%     ## Here mean of outcome
> *within* each study is computed
>   mutate(X_ave_outcome = mean(X))


From th|erry@onke||nx @end|ng |rom |nbo@be  Thu Sep  9 17:53:34 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Thu, 9 Sep 2021 17:53:34 +0200
Subject: [R-sig-ME] contextual effects in 3-level models
In-Reply-To: <CADreqiy509mfWJ9S7GcwrvkLKw40C4=zfEE6TQZ_jtEb18UZEw@mail.gmail.com>
References: <CADreqizwv=qd8UzCkYVXtEJoXe6GZeMGjSXCerZ24AstV+3_Fg@mail.gmail.com>
 <CADreqiy509mfWJ9S7GcwrvkLKw40C4=zfEE6TQZ_jtEb18UZEw@mail.gmail.com>
Message-ID: <CAJuCY5zhnzdvn_k14uZAZ5QC-wBc+06q+aMt65KhKakiJe5v9Q@mail.gmail.com>

Dear Timothy,

This won't work as your averaged X's will be highly correlated with each
other and with the original X.

I often find it easier to reason on a mathematical model. How would you
translate your 'contextual' effects into an equation? Or at least
clarify what a 'contextual' effect is.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op do 9 sep. 2021 om 17:38 schreef Timothy MacKenzie <fswfswt at gmail.com>:

> Dear Colleagues,
>
> I'm revising my question for better clarity. Suppose we have two
> nested grouping variables (ID1 and ID2). The data structure looks like
> below.
>
> To obtain the contextual effects for ID1 and ID2, I wonder which
> option is appropriate?
>
> #-- Option 1: Create mean of X across ID1 (X_ave_ID1) and mean of X
> across ID2 *ignoring* ID1 (X_ave_ID2)
> #-- Option 2: Create mean of X across ID1 (X_ave_ID1) and mean of X
> across ID2    *within*  ID1 (X_ave_ID2)
>
> For both options, then, I will fit (in lme4::lmer()):
>
> y ~ X + X_ave_ID1 + X_ave_ID2 + (1 | ID1 / ID2)
>
> Thank you,
> Tim
>
> #------ DATA  STRUCTURE AND R CODE:
>
> ID1    ID2                   X                      y
> 1       1                       0.474111397    1.9534671
> 1       1                      -0.712228120   0.9355230
> 1       2                      -0.009957293   1.1088756
> 1       2                      -1.237918646   0.8675550
> 2       1                      -0.554944765   2.7831133
> 2       1                      -0.320668268   0.1479290
> 2       2                       1.066993108   0.1688187
> 2       2                     -1.084870417    1.0536264
>
> library(dplyr)
>
> #-- Option 1:
>     data %>%
>     group_by(ID1) %>%
>     mutate(X_ave_ID1 = mean(X)) %>%
>     group_by(ID2) %>%
>     mutate(X_ave_ID2 = mean(X))
>
> #-- Option 2:
>   data %>%
>   group_by(ID1) %>%
>   mutate(X_ave_ID1 = mean(X)) %>%
>   group_by(ID2, .add = TRUE) %>%
>   mutate(X_ave_ID2 = mean(X))
>
> On Mon, Sep 6, 2021 at 1:31 PM Timothy MacKenzie <fswfswt at gmail.com>
> wrote:
> >
> > Dear All,
> >
> > Suppose X is a continuous predictor that can vary within and between
> > two nested grouping variables in a 3-level linear mixed model:
> >
> > effect.size ~ X + (1 | studies/outcomes)
> >
> > How can I obtain the within effect of X, contextual effect of X at
> > level 2, and contextual effect of X at level 3?
> >
> > I can think of two options but wonder which one makes more sense
> > (below)?   For both options, I will fit:
> >
> > effect.size ~ X + X_ave_study + X_ave_outcome + (1 | studies/outcomes)
> >
> > Thank you,
> > Tim
> >
> > library(dplyr)
> >
> > #-- Option 1:
> >     data %>%
> >     group_by(study) %>%
> >     mutate(X_ave_study = mean(X)) %>%
> >     group_by(outcome) %>%                         ## Here mean of
> > outcome *ignoring* studies is computed
> >     mutate(X_ave_outcome = mean(X))
> >
> > #-- Option 2:
> >   data %>%
> >   group_by(study) %>%
> >   mutate(X_ave_study = mean(X)) %>%
> >   group_by(outcome, .add = TRUE) %>%     ## Here mean of outcome
> > *within* each study is computed
> >   mutate(X_ave_outcome = mean(X))
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Thu Sep  9 17:56:08 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 9 Sep 2021 11:56:08 -0400
Subject: [R-sig-ME] contextual effects in 3-level models
In-Reply-To: <CAJuCY5zhnzdvn_k14uZAZ5QC-wBc+06q+aMt65KhKakiJe5v9Q@mail.gmail.com>
References: <CADreqizwv=qd8UzCkYVXtEJoXe6GZeMGjSXCerZ24AstV+3_Fg@mail.gmail.com>
 <CADreqiy509mfWJ9S7GcwrvkLKw40C4=zfEE6TQZ_jtEb18UZEw@mail.gmail.com>
 <CAJuCY5zhnzdvn_k14uZAZ5QC-wBc+06q+aMt65KhKakiJe5v9Q@mail.gmail.com>
Message-ID: <3ca96ac9-2452-b738-5b70-6a303e37bac0@gmail.com>


   I haven't looked at this carefully but I wonder if this is relevant:

van de Pol, M., and J. Wright. ?A Simple Method for Distinguishing 
Within-versus between-Subject Effects Using Mixed Models.? Animal 
Behaviour 77, no. 3 (2009): 753?58.


On 9/9/21 11:53 AM, Thierry Onkelinx via R-sig-mixed-models wrote:
> Dear Timothy,
> 
> This won't work as your averaged X's will be highly correlated with each
> other and with the original X.
> 
> I often find it easier to reason on a mathematical model. How would you
> translate your 'contextual' effects into an equation? Or at least
> clarify what a 'contextual' effect is.
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Statisticus / Statistician
> 
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
> 
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
> 
> <https://www.inbo.be>
> 
> 
> Op do 9 sep. 2021 om 17:38 schreef Timothy MacKenzie <fswfswt at gmail.com>:
> 
>> Dear Colleagues,
>>
>> I'm revising my question for better clarity. Suppose we have two
>> nested grouping variables (ID1 and ID2). The data structure looks like
>> below.
>>
>> To obtain the contextual effects for ID1 and ID2, I wonder which
>> option is appropriate?
>>
>> #-- Option 1: Create mean of X across ID1 (X_ave_ID1) and mean of X
>> across ID2 *ignoring* ID1 (X_ave_ID2)
>> #-- Option 2: Create mean of X across ID1 (X_ave_ID1) and mean of X
>> across ID2    *within*  ID1 (X_ave_ID2)
>>
>> For both options, then, I will fit (in lme4::lmer()):
>>
>> y ~ X + X_ave_ID1 + X_ave_ID2 + (1 | ID1 / ID2)
>>
>> Thank you,
>> Tim
>>
>> #------ DATA  STRUCTURE AND R CODE:
>>
>> ID1    ID2                   X                      y
>> 1       1                       0.474111397    1.9534671
>> 1       1                      -0.712228120   0.9355230
>> 1       2                      -0.009957293   1.1088756
>> 1       2                      -1.237918646   0.8675550
>> 2       1                      -0.554944765   2.7831133
>> 2       1                      -0.320668268   0.1479290
>> 2       2                       1.066993108   0.1688187
>> 2       2                     -1.084870417    1.0536264
>>
>> library(dplyr)
>>
>> #-- Option 1:
>>      data %>%
>>      group_by(ID1) %>%
>>      mutate(X_ave_ID1 = mean(X)) %>%
>>      group_by(ID2) %>%
>>      mutate(X_ave_ID2 = mean(X))
>>
>> #-- Option 2:
>>    data %>%
>>    group_by(ID1) %>%
>>    mutate(X_ave_ID1 = mean(X)) %>%
>>    group_by(ID2, .add = TRUE) %>%
>>    mutate(X_ave_ID2 = mean(X))
>>
>> On Mon, Sep 6, 2021 at 1:31 PM Timothy MacKenzie <fswfswt at gmail.com>
>> wrote:
>>>
>>> Dear All,
>>>
>>> Suppose X is a continuous predictor that can vary within and between
>>> two nested grouping variables in a 3-level linear mixed model:
>>>
>>> effect.size ~ X + (1 | studies/outcomes)
>>>
>>> How can I obtain the within effect of X, contextual effect of X at
>>> level 2, and contextual effect of X at level 3?
>>>
>>> I can think of two options but wonder which one makes more sense
>>> (below)?   For both options, I will fit:
>>>
>>> effect.size ~ X + X_ave_study + X_ave_outcome + (1 | studies/outcomes)
>>>
>>> Thank you,
>>> Tim
>>>
>>> library(dplyr)
>>>
>>> #-- Option 1:
>>>      data %>%
>>>      group_by(study) %>%
>>>      mutate(X_ave_study = mean(X)) %>%
>>>      group_by(outcome) %>%                         ## Here mean of
>>> outcome *ignoring* studies is computed
>>>      mutate(X_ave_outcome = mean(X))
>>>
>>> #-- Option 2:
>>>    data %>%
>>>    group_by(study) %>%
>>>    mutate(X_ave_study = mean(X)) %>%
>>>    group_by(outcome, .add = TRUE) %>%     ## Here mean of outcome
>>> *within* each study is computed
>>>    mutate(X_ave_outcome = mean(X))
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics


From mm@|ten @end|ng |rom gm@||@com  Thu Sep  9 18:08:44 2021
From: mm@|ten @end|ng |rom gm@||@com (Mitchell Maltenfort)
Date: Thu, 9 Sep 2021 12:08:44 -0400
Subject: [R-sig-ME] 
 Looking for help to test the effect of a grouping factor
 in repeated measures
In-Reply-To: <CAJuCY5xFhMPr-xHQrXrsy3eqA-8jw_BMwUsCH1ZeF9SE7q1fow@mail.gmail.com>
References: <CAG_W+XFcprL6RT2OyTsQ4mfNYe2UE2D_NTWwi5yt+HKGpTsDfA@mail.gmail.com>
 <CAJuCY5xFhMPr-xHQrXrsy3eqA-8jw_BMwUsCH1ZeF9SE7q1fow@mail.gmail.com>
Message-ID: <CANOgrHZ2v5PvykzFkZnpx=qMxzz1NjkLhYFEKA7mabgQva0w8Q@mail.gmail.com>

https://stats.stackexchange.com/questions/79360/mixed-effects-model-with-nesting
might be helpful

On Thu, Sep 9, 2021 at 10:20 AM Thierry Onkelinx via R-sig-mixed-models <
r-sig-mixed-models at r-project.org> wrote:

> Dear Lea,
>
> Please note that you want the binomial distribution. Not the binomial
> _error_ distribution.
>
> A model like y ~ treatment * species + (1|date) could make sense if you can
> assume that the date could have a common effect on the results. E.g. the
> observer being more awake on some days ;-) Use the actual date as a factor
> instead of the number of days since the start of the experiment. That is
> safer than using the number of days since the start.
> If you assume no date effect, then there could be only temporal
> autocorrelation within the species. As the strength of the autocorrelation
> could be different among species, you could consider fitting a separate
> model for every species.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88
> <https://www.google.com/maps/search/Havenlaan+88?entry=gmail&source=g>
> bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op do 9 sep. 2021 om 15:43 schreef L?a Fieschi-M?ric <
> leafieschimeric at gmail.com>:
>
> > Hello,
> >
> > I have a dataset to analyse and I am struggling to build my model set and
> > was wondering if you could advise me please.
> >
> > The experimental plan is as follows: several species of animals were
> > observed for a year, but not regularly (some months have many
> observations,
> > others have less). *All individuals belonging to the same species were
> > housed together in the same terrarium* (unequal number of individuals per
> > species). The response variable is the number of awake individuals per
> > terrarium (i.e. per species). The year was divided in 3, unequal, periods
> > as follows: treatment / control / treatment.
> >
> > I need to determine the effect of the *Period *(treatment / control), of
> > the *Species* (12 in total), and of their *Interaction *on the
> *proportion
> > of awake animals*. I wanted to use a GLMM with a binomial error
> > distribution. The problem is that I have repeated measures per species,
> so
> > I would like to account for that by using Species as a random effect to
> > avoid pseudoreplication, but I think I need Species to be a fixed effect
> > because I want to directly test its effect on my response. Therefore, I
> > wonder if adding the *Date* (as an integer: number of days since the
> > beginning of the experiment) to the model does control for these repeated
> > measures (but I can't use it as a random effect because it is continuous,
> > and it makes my model too complex to converge when integrated as a fixed
> > effect), or if I should sum the response per month to use *Month* as a
> > random effect ordered factor. Or if I could just use a linear model
> without
> > bothering, like this: y ~ Treatment * Species !
> > I am stuck here and would like to avoid taking a mathematically
> > erroneous approach. Could you advise me please?
> >
> > I was also wondering what I need to do in order to, in a second phase, be
> > able to conclude exactly which species were sensitive to the treatment
> and
> > which were not?
> >
> > I am looking forward to hearing back from you, and thank you in advance
> for
> > your help!
> >
> > L?a
> >
> > --
> > *L?a FIESCHI-MERIC*, PhD student
> >
> > Laboratoire d'Ecologie et de Conservation des Amphibiens (LECA)
> > Freshwater and OCeanic science Unit of reSearch (FOCUS)
> > Universit? de Li?ge (Belgique)
> > &
> > Genetics and Ecology of Amphibians Research Group
> > Center for Evolutionary Ecology and Ethical Conservation
> > Laurentian University (Canada)
> >
> > Tel: (+33) (0)6.59.32.29.15 <+32%204%20366%2050%2077>
> > E-mail: leafieschimeric at gmail.com
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
-- 
Sent from Gmail Mobile

	[[alternative HTML version deleted]]


From |@w|@wt @end|ng |rom gm@||@com  Thu Sep  9 18:17:45 2021
From: |@w|@wt @end|ng |rom gm@||@com (Timothy MacKenzie)
Date: Thu, 9 Sep 2021 11:17:45 -0500
Subject: [R-sig-ME] contextual effects in 3-level models
In-Reply-To: <CAJuCY5zhnzdvn_k14uZAZ5QC-wBc+06q+aMt65KhKakiJe5v9Q@mail.gmail.com>
References: <CADreqizwv=qd8UzCkYVXtEJoXe6GZeMGjSXCerZ24AstV+3_Fg@mail.gmail.com>
 <CADreqiy509mfWJ9S7GcwrvkLKw40C4=zfEE6TQZ_jtEb18UZEw@mail.gmail.com>
 <CAJuCY5zhnzdvn_k14uZAZ5QC-wBc+06q+aMt65KhKakiJe5v9Q@mail.gmail.com>
Message-ID: <CADreqiz_8oiJHB_hJy6hfV61Q8=7ieNP4_A6pKunM6d6b5DBCQ@mail.gmail.com>

Dear Thierry,

By contextual effects, I'm referring to the Raudenbush & Bryk (2002) book
pp. 139 - 146. In this section of the book, it is recommended that
researchers dealing with covariates that vary within and between a grouping
variable's levels, separate the within and contextual effects of such
covariates.

The authors only discuss this issue in the context of 2-level models (e.g.
y ~ X + (1 | ID1) ). For example, if X is a variable that varies within and
between each level of ID1, then to get the within and contextual effect of
X, the fixed-effect part of the model will be:

y ~ X + mean_of_X_in_each_ID1_level

In the above parametrization, "mean_of_X_in_each_ID1_level" coefficient
provides the contextual effect of X with the interpretation:

Average difference in y between two observations with the same value of X
that belong to ID1 levels whose mean X values differ by 1 unit.

The question I have posed is an extension of the above for when we have two
nested grouping variables; thus a 3-level model (e.g., y ~ X + (1 | ID1 /
ID2) ).

In this 3-level case, to obtain the contextual effects for ID1 and ID2, I
wonder which option is appropriate?

#-- Option 1: Create mean of X across ID1 levels (X_ave_ID1) and mean of X
across ID2 levels *ignoring* ID1 (X_ave_ID2)

#-- Option 2: Create mean of X across ID1 levels (X_ave_ID1) and mean of X
across ID2 levels   *within*   ID1 (X_ave_ID2)

For both options, then, I will fit (in lme4::lmer()):

y ~ X + X_ave_ID1 + X_ave_ID2 + (1 | ID1 / ID2)

#------ DATA  STRUCTURE AND R CODE:

ID1    ID2                   X                      y
1       1                       0.474111397    1.9534671
1       1                      -0.712228120   0.9355230
1       2                      -0.009957293   1.1088756
1       2                      -1.237918646   0.8675550
2       1                      -0.554944765   2.7831133
2       1                      -0.320668268   0.1479290
2       2                       1.066993108   0.1688187
2       2                     -1.084870417    1.0536264

library(dplyr)

#-- Option 1:
    data %>%
    group_by(ID1) %>%
    mutate(X_ave_ID1 = mean(X)) %>%
    group_by(ID2) %>%
    mutate(X_ave_ID2 = mean(X))

#-- Option 2:
  data %>%
  group_by(ID1) %>%
  mutate(X_ave_ID1 = mean(X)) %>%
  group_by(ID2, .add = TRUE) %>%
  mutate(X_ave_ID2 = mean(X))

On Thu, Sep 9, 2021 at 10:53 AM Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Timothy,
>
> This won't work as your averaged X's will be highly correlated with each
> other and with the original X.
>
> I often find it easier to reason on a mathematical model. How would you
> translate your 'contextual' effects into an equation? Or at least
> clarify what a 'contextual' effect is.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op do 9 sep. 2021 om 17:38 schreef Timothy MacKenzie <fswfswt at gmail.com>:
>
>> Dear Colleagues,
>>
>> I'm revising my question for better clarity. Suppose we have two
>> nested grouping variables (ID1 and ID2). The data structure looks like
>> below.
>>
>> To obtain the contextual effects for ID1 and ID2, I wonder which
>> option is appropriate?
>>
>> #-- Option 1: Create mean of X across ID1 (X_ave_ID1) and mean of X
>> across ID2 *ignoring* ID1 (X_ave_ID2)
>> #-- Option 2: Create mean of X across ID1 (X_ave_ID1) and mean of X
>> across ID2    *within*  ID1 (X_ave_ID2)
>>
>> For both options, then, I will fit (in lme4::lmer()):
>>
>> y ~ X + X_ave_ID1 + X_ave_ID2 + (1 | ID1 / ID2)
>>
>> Thank you,
>> Tim
>>
>> #------ DATA  STRUCTURE AND R CODE:
>>
>> ID1    ID2                   X                      y
>> 1       1                       0.474111397    1.9534671
>> 1       1                      -0.712228120   0.9355230
>> 1       2                      -0.009957293   1.1088756
>> 1       2                      -1.237918646   0.8675550
>> 2       1                      -0.554944765   2.7831133
>> 2       1                      -0.320668268   0.1479290
>> 2       2                       1.066993108   0.1688187
>> 2       2                     -1.084870417    1.0536264
>>
>> library(dplyr)
>>
>> #-- Option 1:
>>     data %>%
>>     group_by(ID1) %>%
>>     mutate(X_ave_ID1 = mean(X)) %>%
>>     group_by(ID2) %>%
>>     mutate(X_ave_ID2 = mean(X))
>>
>> #-- Option 2:
>>   data %>%
>>   group_by(ID1) %>%
>>   mutate(X_ave_ID1 = mean(X)) %>%
>>   group_by(ID2, .add = TRUE) %>%
>>   mutate(X_ave_ID2 = mean(X))
>>
>> On Mon, Sep 6, 2021 at 1:31 PM Timothy MacKenzie <fswfswt at gmail.com>
>> wrote:
>> >
>> > Dear All,
>> >
>> > Suppose X is a continuous predictor that can vary within and between
>> > two nested grouping variables in a 3-level linear mixed model:
>> >
>> > effect.size ~ X + (1 | studies/outcomes)
>> >
>> > How can I obtain the within effect of X, contextual effect of X at
>> > level 2, and contextual effect of X at level 3?
>> >
>> > I can think of two options but wonder which one makes more sense
>> > (below)?   For both options, I will fit:
>> >
>> > effect.size ~ X + X_ave_study + X_ave_outcome + (1 | studies/outcomes)
>> >
>> > Thank you,
>> > Tim
>> >
>> > library(dplyr)
>> >
>> > #-- Option 1:
>> >     data %>%
>> >     group_by(study) %>%
>> >     mutate(X_ave_study = mean(X)) %>%
>> >     group_by(outcome) %>%                         ## Here mean of
>> > outcome *ignoring* studies is computed
>> >     mutate(X_ave_outcome = mean(X))
>> >
>> > #-- Option 2:
>> >   data %>%
>> >   group_by(study) %>%
>> >   mutate(X_ave_study = mean(X)) %>%
>> >   group_by(outcome, .add = TRUE) %>%     ## Here mean of outcome
>> > *within* each study is computed
>> >   mutate(X_ave_outcome = mean(X))
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

	[[alternative HTML version deleted]]


From hedyeh@h @end|ng |rom u@c@edu  Thu Sep  9 20:55:33 2021
From: hedyeh@h @end|ng |rom u@c@edu (Hedyeh Ahmadi)
Date: Thu, 9 Sep 2021 18:55:33 +0000
Subject: [R-sig-ME] A nAGQ=0 question for glmer()
In-Reply-To: <956ca2ac-fe1d-f097-8fd3-73e75412089c@gmail.com>
References: <BYAPR07MB5094D2957657788DBC154CFCD1D49@BYAPR07MB5094.namprd07.prod.outlook.com>
 <956ca2ac-fe1d-f097-8fd3-73e75412089c@gmail.com>
Message-ID: <BYAPR07MB50949CA2B4C18FF78C5E126CD1D59@BYAPR07MB5094.namprd07.prod.outlook.com>

Thank you for the very helpful and informative reply.


Best,

Hedyeh Ahmadi, Ph.D.
Statistician
Keck School of Medicine
Department of Preventive Medicine
University of Southern California

LinkedIn
www.linkedin.com/in/hedyeh-ahmadi<http://www.linkedin.com/in/hedyeh-ahmadi>
<http://www.linkedin.com/in/hedyeh-ahmadi><http://www.linkedin.com/in/hedyeh-ahmadi>




________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Ben Bolker <bbolker at gmail.com>
Sent: Wednesday, September 8, 2021 10:13 AM
To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] A nAGQ=0 question for glmer()



On 9/8/21 12:24 PM, Hedyeh Ahmadi wrote:
> Hello all,
> I have the following two questions:
>
>    1.  If one is using a glmer() model with the nAGQ=0 option, I was wondering if there is a way to see if the model has actually converged?
>    2.  If the mentioned model runs with no error/warning , does that mean the model has converged?
>

   The convergence diagnostics and messages don't differ between nAGQ=0
and nAGQ>0 (so, the answer to #2 is 'yes').

   For a fitted model gm1, any problems with convergence will be
recorded in gm1 at modelinfo; specifically, see the $conv, $warnings, and
$message components ($conv has two elements, $opt (optimizer convergence
code) and $lme4 (warnings/non-convergence warnings from lme4).
$conv$opt should be 0, $conv$lme4 and $warnings should be length-zero.

   For what it's worth, the best description of the
assumption/approximation that nAGQ=0 makes is in the TMB (!)
documentation: https://urldefense.com/v3/__https://kaskr.github.io/adcomp/_book/Appendix.html__;!!LIr3w8kk_Xxm!44evfEd0xtcywxRiBNnQdcP2AYFaDSBH7Ma3kTRxWglURfVN-HkONx701kwN8GQ$ ,
section 16.2


> Any help would be appreciated.
>
> Best,
>
> Hedyeh Ahmadi, Ph.D.
> Statistician
> Keck School of Medicine
> Department of Preventive Medicine
> University of Southern California
>
> LinkedIn
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!44evfEd0xtcywxRiBNnQdcP2AYFaDSBH7Ma3kTRxWglURfVN-HkONx70TMoCxp8$ <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!44evfEd0xtcywxRiBNnQdcP2AYFaDSBH7Ma3kTRxWglURfVN-HkONx70TMoCxp8$ >
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!44evfEd0xtcywxRiBNnQdcP2AYFaDSBH7Ma3kTRxWglURfVN-HkONx70TMoCxp8$ ><https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!44evfEd0xtcywxRiBNnQdcP2AYFaDSBH7Ma3kTRxWglURfVN-HkONx70TMoCxp8$ >
>
>
>
>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!44evfEd0xtcywxRiBNnQdcP2AYFaDSBH7Ma3kTRxWglURfVN-HkONx70NW8rGaA$
>

--
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!44evfEd0xtcywxRiBNnQdcP2AYFaDSBH7Ma3kTRxWglURfVN-HkONx70NW8rGaA$

	[[alternative HTML version deleted]]


From hedyeh@h @end|ng |rom u@c@edu  Tue Sep 14 00:24:53 2021
From: hedyeh@h @end|ng |rom u@c@edu (Hedyeh Ahmadi)
Date: Mon, 13 Sep 2021 22:24:53 +0000
Subject: [R-sig-ME] Random Effect Tobit
Message-ID: <BYAPR07MB5094959120CD047F4BA59731D1D99@BYAPR07MB5094.namprd07.prod.outlook.com>

Hello all,
I was wonder if anyone is aware of an R package with random effect Tobit. Any help would be greatly appreciated.

Best,

Hedyeh Ahmadi, Ph.D.
Statistician
Keck School of Medicine
Department of Preventive Medicine
University of Southern California

Postdoctoral Scholar
Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
University of California, Irvine

LinkedIn
www.linkedin.com/in/hedyeh-ahmadi<http://www.linkedin.com/in/hedyeh-ahmadi>


	[[alternative HTML version deleted]]


From d@r|zopou|o@ @end|ng |rom er@@mu@mc@n|  Tue Sep 14 09:32:14 2021
From: d@r|zopou|o@ @end|ng |rom er@@mu@mc@n| (Dimitris Rizopoulos)
Date: Tue, 14 Sep 2021 07:32:14 +0000
Subject: [R-sig-ME] Random Effect Tobit
In-Reply-To: <BYAPR07MB5094959120CD047F4BA59731D1D99@BYAPR07MB5094.namprd07.prod.outlook.com>
References: <BYAPR07MB5094959120CD047F4BA59731D1D99@BYAPR07MB5094.namprd07.prod.outlook.com>
Message-ID: <AM8PR04MB7843E31AABDCC45EDC9A8AD1E8DA9@AM8PR04MB7843.eurprd04.prod.outlook.com>

You can use the GLMMadaptive package (https://drizopoulos.github.io/GLMMadaptive/) and the censored.normal() family object. An example is given here: https://drizopoulos.github.io/JMbayes2/articles/Non_Gaussian_Mixed_Models.html#censored-linear-mixed-models-1 


Best,
Dimitris

-----Original Message-----
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Hedyeh Ahmadi
Sent: Tuesday, September 14, 2021 12:25 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Random Effect Tobit

Hello all,
I was wonder if anyone is aware of an R package with random effect Tobit. Any help would be greatly appreciated.

Best,

Hedyeh Ahmadi, Ph.D.
Statistician
Keck School of Medicine
Department of Preventive Medicine
University of Southern California

Postdoctoral Scholar
Institute for Interdisciplinary Salivary Bioscience Research (IISBR) University of California, Irvine

LinkedIn
https://eur01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.linkedin.com%2Fin%2Fhedyeh-ahmadi&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C7364e0f85ee144bb719708d97705625c%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637671687284917965%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&amp;sdata=vLU5PQqaPxCr3p6PdnRWyYdyCJhys%2BA4r9RMaS%2FnPLU%3D&amp;reserved=0<https://eur01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.linkedin.com%2Fin%2Fhedyeh-ahmadi&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C7364e0f85ee144bb719708d97705625c%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637671687284917965%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&amp;sdata=vLU5PQqaPxCr3p6PdnRWyYdyCJhys%2BA4r9RMaS%2FnPLU%3D&amp;reserved=0>


	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C7364e0f85ee144bb719708d97705625c%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637671687284917965%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&amp;sdata=xeoG32%2FqVvSSAfwGEZvNK9dHVdkdOKhfUK6ZnOH6wqo%3D&amp;reserved=0


From bbo|ker @end|ng |rom gm@||@com  Wed Sep 15 02:08:13 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 14 Sep 2021 20:08:13 -0400
Subject: [R-sig-ME] Random Effect Tobit
In-Reply-To: <AM8PR04MB7843E31AABDCC45EDC9A8AD1E8DA9@AM8PR04MB7843.eurprd04.prod.outlook.com>
References: <BYAPR07MB5094959120CD047F4BA59731D1D99@BYAPR07MB5094.namprd07.prod.outlook.com>
 <AM8PR04MB7843E31AABDCC45EDC9A8AD1E8DA9@AM8PR04MB7843.eurprd04.prod.outlook.com>
Message-ID: <6d7a70e6-c3f1-60c5-7365-8a892f27ee75@gmail.com>

This CrossValidated answer: 
https://stats.stackexchange.com/questions/544511/zero-inflated-gaussian-for-weights-below-zero-recorded-as-0?noredirect=1#comment999636_544511

  says that the censReg package can handle random effects Tobit models 
via Gauss-Hermite Quadrature (GLMMadaptive is great, but it's nice to 
have options)

On 9/14/21 3:32 AM, Dimitris Rizopoulos wrote:
> You can use the GLMMadaptive package (https://drizopoulos.github.io/GLMMadaptive/) and the censored.normal() family object. An example is given here: https://drizopoulos.github.io/JMbayes2/articles/Non_Gaussian_Mixed_Models.html#censored-linear-mixed-models-1
> 
> 
> Best,
> Dimitris
> 
> -----Original Message-----
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Hedyeh Ahmadi
> Sent: Tuesday, September 14, 2021 12:25 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Random Effect Tobit
> 
> Hello all,
> I was wonder if anyone is aware of an R package with random effect Tobit. Any help would be greatly appreciated.
> 
> Best,
> 
> Hedyeh Ahmadi, Ph.D.
> Statistician
> Keck School of Medicine
> Department of Preventive Medicine
> University of Southern California
> 
> Postdoctoral Scholar
> Institute for Interdisciplinary Salivary Bioscience Research (IISBR) University of California, Irvine
> 
> LinkedIn
> https://eur01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.linkedin.com%2Fin%2Fhedyeh-ahmadi&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C7364e0f85ee144bb719708d97705625c%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637671687284917965%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&amp;sdata=vLU5PQqaPxCr3p6PdnRWyYdyCJhys%2BA4r9RMaS%2FnPLU%3D&amp;reserved=0<https://eur01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.linkedin.com%2Fin%2Fhedyeh-ahmadi&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C7364e0f85ee144bb719708d97705625c%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637671687284917965%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&amp;sdata=vLU5PQqaPxCr3p6PdnRWyYdyCJhys%2BA4r9RMaS%2FnPLU%3D&amp;reserved=0>
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C7364e0f85ee144bb719708d97705625c%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637671687284917965%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&amp;sdata=xeoG32%2FqVvSSAfwGEZvNK9dHVdkdOKhfUK6ZnOH6wqo%3D&amp;reserved=0
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics


From d@r|zopou|o@ @end|ng |rom er@@mu@mc@n|  Wed Sep 15 03:26:07 2021
From: d@r|zopou|o@ @end|ng |rom er@@mu@mc@n| (Dimitris Rizopoulos)
Date: Wed, 15 Sep 2021 01:26:07 +0000
Subject: [R-sig-ME] Random Effect Tobit
In-Reply-To: <6d7a70e6-c3f1-60c5-7365-8a892f27ee75@gmail.com>
References: <BYAPR07MB5094959120CD047F4BA59731D1D99@BYAPR07MB5094.namprd07.prod.outlook.com>
 <AM8PR04MB7843E31AABDCC45EDC9A8AD1E8DA9@AM8PR04MB7843.eurprd04.prod.outlook.com>
 <6d7a70e6-c3f1-60c5-7365-8a892f27ee75@gmail.com>
Message-ID: <AM8PR04MB78439A5B50D555ED02437D36E8DB9@AM8PR04MB7843.eurprd04.prod.outlook.com>

Indeed, but the censReg does not seem to update the abscissas and weights during the optimization procedure.

Best,
Dimitris

??
Dimitris Rizopoulos
Professor of Biostatistics
Erasmus University Medical Center
The Netherlands
________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Ben Bolker <bbolker at gmail.com>
Sent: Wednesday, September 15, 2021 2:08:13 AM
To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Random Effect Tobit

This CrossValidated answer:
https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstats.stackexchange.com%2Fquestions%2F544511%2Fzero-inflated-gaussian-for-weights-below-zero-recorded-as-0%3Fnoredirect%3D1%23comment999636_544511&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C40b92da1072c42854dfd08d977dcf8ed%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672613225156938%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=YnBAIBxTozwjcNne6Mwu%2Fks6bMGD8h65RPGNk1pkiyg%3D&amp;reserved=0

  says that the censReg package can handle random effects Tobit models
via Gauss-Hermite Quadrature (GLMMadaptive is great, but it's nice to
have options)

On 9/14/21 3:32 AM, Dimitris Rizopoulos wrote:
> You can use the GLMMadaptive package (https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fdrizopoulos.github.io%2FGLMMadaptive%2F&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C40b92da1072c42854dfd08d977dcf8ed%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672613225156938%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=fPFues1lFb26w8DBx2Pg2RvbCRZT3Uq7Pd3QQUbfeic%3D&amp;reserved=0) and the censored.normal() family object. An example is given here: https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fdrizopoulos.github.io%2FJMbayes2%2Farticles%2FNon_Gaussian_Mixed_Models.html%23censored-linear-mixed-models-1&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C40b92da1072c42854dfd08d977dcf8ed%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672613225156938%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=tKMo%2BIYYy3M8mdUf5KdLjvk%2BCSC0QxGvfLRk6Vln3rU%3D&amp;reserved=0
>
>
> Best,
> Dimitris
>
> -----Original Message-----
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Hedyeh Ahmadi
> Sent: Tuesday, September 14, 2021 12:25 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Random Effect Tobit
>
> Hello all,
> I was wonder if anyone is aware of an R package with random effect Tobit. Any help would be greatly appreciated.
>
> Best,
>
> Hedyeh Ahmadi, Ph.D.
> Statistician
> Keck School of Medicine
> Department of Preventive Medicine
> University of Southern California
>
> Postdoctoral Scholar
> Institute for Interdisciplinary Salivary Bioscience Research (IISBR) University of California, Irvine
>
> LinkedIn
> https://eur01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.linkedin.com%2Fin%2Fhedyeh-ahmadi&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C40b92da1072c42854dfd08d977dcf8ed%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672613225156938%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=GUUoQKAivyRPkhnPXgn1m4eV2Oxjh7LLMhtjn9rW4eM%3D&amp;reserved=0<https://eur01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.linkedin.com%2Fin%2Fhedyeh-ahmadi&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C40b92da1072c42854dfd08d977dcf8ed%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672613225156938%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=GUUoQKAivyRPkhnPXgn1m4eV2Oxjh7LLMhtjn9rW4eM%3D&amp;reserved=0>
>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C40b92da1072c42854dfd08d977dcf8ed%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672613225156938%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=koYI8ZbBkZ024kmS1Q5LtOlXC7HAAb2EPTgHdM0kLV8%3D&amp;reserved=0
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C40b92da1072c42854dfd08d977dcf8ed%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672613225156938%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=koYI8ZbBkZ024kmS1Q5LtOlXC7HAAb2EPTgHdM0kLV8%3D&amp;reserved=0
>

--
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C40b92da1072c42854dfd08d977dcf8ed%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672613225166895%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=N7h54dblmroqr5%2FkKXyFfzO73GDNXpFCHIR61frsGaA%3D&amp;reserved=0

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Wed Sep 15 03:28:43 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 14 Sep 2021 21:28:43 -0400
Subject: [R-sig-ME] Random Effect Tobit
In-Reply-To: <AM8PR04MB78439A5B50D555ED02437D36E8DB9@AM8PR04MB7843.eurprd04.prod.outlook.com>
References: <BYAPR07MB5094959120CD047F4BA59731D1D99@BYAPR07MB5094.namprd07.prod.outlook.com>
 <AM8PR04MB7843E31AABDCC45EDC9A8AD1E8DA9@AM8PR04MB7843.eurprd04.prod.outlook.com>
 <6d7a70e6-c3f1-60c5-7365-8a892f27ee75@gmail.com>
 <AM8PR04MB78439A5B50D555ED02437D36E8DB9@AM8PR04MB7843.eurprd04.prod.outlook.com>
Message-ID: <fb8f7a59-a782-1ec3-7c5f-e6f9dc644792@gmail.com>

    Can you explain a bit more? Is this the distinction that is 
sometimes made between Gauss-Hermite quadrature and *adaptive* GHQ, i.e. 
whether the expansion is centered at the population-level value or at 
zero?  (If so, I would *definitely* recommend GLMMadaptive, non-adaptive 
GHQ can be terrible in some cases ...)

   cheers
    Ben Bolker

On 9/14/21 9:26 PM, Dimitris Rizopoulos wrote:
> Indeed, but the censReg does not seem to update the abscissas and 
> weights during the optimization procedure.
> 
> Best,
> Dimitris
> 
> ??
> Dimitris Rizopoulos
> Professor of Biostatistics
> Erasmus University Medical Center
> The Netherlands
> ------------------------------------------------------------------------
> *From:* R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on 
> behalf of Ben Bolker <bbolker at gmail.com>
> *Sent:* Wednesday, September 15, 2021 2:08:13 AM
> *To:* r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
> *Subject:* Re: [R-sig-ME] Random Effect Tobit
> This CrossValidated answer:
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstats.stackexchange.com%2Fquestions%2F544511%2Fzero-inflated-gaussian-for-weights-below-zero-recorded-as-0%3Fnoredirect%3D1%23comment999636_544511&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C40b92da1072c42854dfd08d977dcf8ed%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672613225156938%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=YnBAIBxTozwjcNne6Mwu%2Fks6bMGD8h65RPGNk1pkiyg%3D&amp;reserved=0 
> <https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstats.stackexchange.com%2Fquestions%2F544511%2Fzero-inflated-gaussian-for-weights-below-zero-recorded-as-0%3Fnoredirect%3D1%23comment999636_544511&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C40b92da1072c42854dfd08d977dcf8ed%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672613225156938%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=YnBAIBxTozwjcNne6Mwu%2Fks6bMGD8h65RPGNk1pkiyg%3D&amp;reserved=0>
> 
>  ? says that the censReg package can handle random effects Tobit models
> via Gauss-Hermite Quadrature (GLMMadaptive is great, but it's nice to
> have options)
> 
> On 9/14/21 3:32 AM, Dimitris Rizopoulos wrote:
>> You can use the GLMMadaptive package (https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fdrizopoulos.github.io%2FGLMMadaptive%2F&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C40b92da1072c42854dfd08d977dcf8ed%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672613225156938%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=fPFues1lFb26w8DBx2Pg2RvbCRZT3Uq7Pd3QQUbfeic%3D&amp;reserved=0 
> <https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fdrizopoulos.github.io%2FGLMMadaptive%2F&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C40b92da1072c42854dfd08d977dcf8ed%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672613225156938%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=fPFues1lFb26w8DBx2Pg2RvbCRZT3Uq7Pd3QQUbfeic%3D&amp;reserved=0>) 
> and the censored.normal() family object. An example is given here: 
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fdrizopoulos.github.io%2FJMbayes2%2Farticles%2FNon_Gaussian_Mixed_Models.html%23censored-linear-mixed-models-1&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C40b92da1072c42854dfd08d977dcf8ed%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672613225156938%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=tKMo%2BIYYy3M8mdUf5KdLjvk%2BCSC0QxGvfLRk6Vln3rU%3D&amp;reserved=0 
> <https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fdrizopoulos.github.io%2FJMbayes2%2Farticles%2FNon_Gaussian_Mixed_Models.html%23censored-linear-mixed-models-1&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C40b92da1072c42854dfd08d977dcf8ed%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672613225156938%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=tKMo%2BIYYy3M8mdUf5KdLjvk%2BCSC0QxGvfLRk6Vln3rU%3D&amp;reserved=0>
>> 
>> 
>> Best,
>> Dimitris
>> 
>> -----Original Message-----
>> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Hedyeh Ahmadi
>> Sent: Tuesday, September 14, 2021 12:25 AM
>> To: r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] Random Effect Tobit
>> 
>> Hello all,
>> I was wonder if anyone is aware of an R package with random effect Tobit. Any help would be greatly appreciated.
>> 
>> Best,
>> 
>> Hedyeh Ahmadi, Ph.D.
>> Statistician
>> Keck School of Medicine
>> Department of Preventive Medicine
>> University of Southern California
>> 
>> Postdoctoral Scholar
>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR) University of California, Irvine
>> 
>> LinkedIn
>> https://eur01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.linkedin.com%2Fin%2Fhedyeh-ahmadi&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C40b92da1072c42854dfd08d977dcf8ed%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672613225156938%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=GUUoQKAivyRPkhnPXgn1m4eV2Oxjh7LLMhtjn9rW4eM%3D&amp;reserved=0<https://eur01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.linkedin.com%2Fin%2Fhedyeh-ahmadi&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C40b92da1072c42854dfd08d977dcf8ed%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672613225156938%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=GUUoQKAivyRPkhnPXgn1m4eV2Oxjh7LLMhtjn9rW4eM%3D&amp;reserved=0 
> <https://eur01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.linkedin.com%2Fin%2Fhedyeh-ahmadi&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C40b92da1072c42854dfd08d977dcf8ed%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672613225156938%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=GUUoQKAivyRPkhnPXgn1m4eV2Oxjh7LLMhtjn9rW4eM%3D&amp;reserved=0<https://eur01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.linkedin.com%2Fin%2Fhedyeh-ahmadi&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C40b92da1072c42854dfd08d977dcf8ed%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672613225156938%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=GUUoQKAivyRPkhnPXgn1m4eV2Oxjh7LLMhtjn9rW4eM%3D&amp;reserved=0>>
>> 
>> 
>>??????? [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C40b92da1072c42854dfd08d977dcf8ed%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672613225156938%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=koYI8ZbBkZ024kmS1Q5LtOlXC7HAAb2EPTgHdM0kLV8%3D&amp;reserved=0 
> <https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C40b92da1072c42854dfd08d977dcf8ed%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672613225156938%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=koYI8ZbBkZ024kmS1Q5LtOlXC7HAAb2EPTgHdM0kLV8%3D&amp;reserved=0>
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C40b92da1072c42854dfd08d977dcf8ed%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672613225156938%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=koYI8ZbBkZ024kmS1Q5LtOlXC7HAAb2EPTgHdM0kLV8%3D&amp;reserved=0 
> <https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C40b92da1072c42854dfd08d977dcf8ed%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672613225156938%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=koYI8ZbBkZ024kmS1Q5LtOlXC7HAAb2EPTgHdM0kLV8%3D&amp;reserved=0>
>> 
> 
> -- 
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> Graduate chair, Mathematics & Statistics
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C40b92da1072c42854dfd08d977dcf8ed%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672613225166895%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=N7h54dblmroqr5%2FkKXyFfzO73GDNXpFCHIR61frsGaA%3D&amp;reserved=0 
> <https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C40b92da1072c42854dfd08d977dcf8ed%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672613225166895%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=N7h54dblmroqr5%2FkKXyFfzO73GDNXpFCHIR61frsGaA%3D&amp;reserved=0>

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics


From d@r|zopou|o@ @end|ng |rom er@@mu@mc@n|  Wed Sep 15 03:36:04 2021
From: d@r|zopou|o@ @end|ng |rom er@@mu@mc@n| (Dimitris Rizopoulos)
Date: Wed, 15 Sep 2021 01:36:04 +0000
Subject: [R-sig-ME] Random Effect Tobit
In-Reply-To: <fb8f7a59-a782-1ec3-7c5f-e6f9dc644792@gmail.com>
References: <BYAPR07MB5094959120CD047F4BA59731D1D99@BYAPR07MB5094.namprd07.prod.outlook.com>
 <AM8PR04MB7843E31AABDCC45EDC9A8AD1E8DA9@AM8PR04MB7843.eurprd04.prod.outlook.com>
 <6d7a70e6-c3f1-60c5-7365-8a892f27ee75@gmail.com>
 <AM8PR04MB78439A5B50D555ED02437D36E8DB9@AM8PR04MB7843.eurprd04.prod.outlook.com>
 <fb8f7a59-a782-1ec3-7c5f-e6f9dc644792@gmail.com>
Message-ID: <AM8PR04MB7843DA8E5A3B4284133B0D31E8DB9@AM8PR04MB7843.eurprd04.prod.outlook.com>

Yes, it seems to me that the non-adaptive GH is used according to procedure described in Section 3.4 here: https://cran.r-project.org/web/packages/censReg/vignettes/censReg.pdf

The adaptive GH updates the position of the abscissas and the weights during the optimization to achieve a better approximation of the log-likelihood.



??
Dimitris Rizopoulos
Professor of Biostatistics
Erasmus University Medical Center
The Netherlands
________________________________
From: Ben Bolker <bbolker at gmail.com>
Sent: Wednesday, September 15, 2021 3:28:43 AM
To: Dimitris Rizopoulos <d.rizopoulos at erasmusmc.nl>; r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Random Effect Tobit

    Can you explain a bit more? Is this the distinction that is
sometimes made between Gauss-Hermite quadrature and *adaptive* GHQ, i.e.
whether the expansion is centered at the population-level value or at
zero?  (If so, I would *definitely* recommend GLMMadaptive, non-adaptive
GHQ can be terrible in some cases ...)

   cheers
    Ben Bolker

On 9/14/21 9:26 PM, Dimitris Rizopoulos wrote:
> Indeed, but the censReg does not seem to update the abscissas and
> weights during the optimization procedure.
>
> Best,
> Dimitris
>
> ??
> Dimitris Rizopoulos
> Professor of Biostatistics
> Erasmus University Medical Center
> The Netherlands
> ------------------------------------------------------------------------
> *From:* R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on
> behalf of Ben Bolker <bbolker at gmail.com>
> *Sent:* Wednesday, September 15, 2021 2:08:13 AM
> *To:* r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
> *Subject:* Re: [R-sig-ME] Random Effect Tobit
> This CrossValidated answer:
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstats.stackexchange.com%2Fquestions%2F544511%2Fzero-inflated-gaussian-for-weights-below-zero-recorded-as-0%3Fnoredirect%3D1%23comment999636_544511&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C596d927815de4130a05708d977e8293c%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672661273318983%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=c4FixGlxg5IY%2BOsgfi2CfQsBANPImB5n6k8eT7Ordag%3D&amp;reserved=0
> <https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstats.stackexchange.com%2Fquestions%2F544511%2Fzero-inflated-gaussian-for-weights-below-zero-recorded-as-0%3Fnoredirect%3D1%23comment999636_544511&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C596d927815de4130a05708d977e8293c%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672661273318983%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=c4FixGlxg5IY%2BOsgfi2CfQsBANPImB5n6k8eT7Ordag%3D&amp;reserved=0>
>
>    says that the censReg package can handle random effects Tobit models
> via Gauss-Hermite Quadrature (GLMMadaptive is great, but it's nice to
> have options)
>
> On 9/14/21 3:32 AM, Dimitris Rizopoulos wrote:
>> You can use the GLMMadaptive package (https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fdrizopoulos.github.io%2FGLMMadaptive%2F&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C596d927815de4130a05708d977e8293c%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672661273318983%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=vPMiaxS3qhMVxCTCCk%2F25Rofp80fuyVxvc4BQTuPaQ0%3D&amp;reserved=0
> <https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fdrizopoulos.github.io%2FGLMMadaptive%2F&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C596d927815de4130a05708d977e8293c%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672661273318983%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=vPMiaxS3qhMVxCTCCk%2F25Rofp80fuyVxvc4BQTuPaQ0%3D&amp;reserved=0>)
> and the censored.normal() family object. An example is given here:
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fdrizopoulos.github.io%2FJMbayes2%2Farticles%2FNon_Gaussian_Mixed_Models.html%23censored-linear-mixed-models-1&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C596d927815de4130a05708d977e8293c%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672661273318983%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=EHNedoTKhPZCOb20NCgnUMwovT%2FNQlqJsfWL3nK%2BzV0%3D&amp;reserved=0
> <https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fdrizopoulos.github.io%2FJMbayes2%2Farticles%2FNon_Gaussian_Mixed_Models.html%23censored-linear-mixed-models-1&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C596d927815de4130a05708d977e8293c%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672661273318983%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=EHNedoTKhPZCOb20NCgnUMwovT%2FNQlqJsfWL3nK%2BzV0%3D&amp;reserved=0>
>>
>>
>> Best,
>> Dimitris
>>
>> -----Original Message-----
>> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Hedyeh Ahmadi
>> Sent: Tuesday, September 14, 2021 12:25 AM
>> To: r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] Random Effect Tobit
>>
>> Hello all,
>> I was wonder if anyone is aware of an R package with random effect Tobit. Any help would be greatly appreciated.
>>
>> Best,
>>
>> Hedyeh Ahmadi, Ph.D.
>> Statistician
>> Keck School of Medicine
>> Department of Preventive Medicine
>> University of Southern California
>>
>> Postdoctoral Scholar
>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR) University of California, Irvine
>>
>> LinkedIn
>> https://eur01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.linkedin.com%2Fin%2Fhedyeh-ahmadi&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C596d927815de4130a05708d977e8293c%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672661273318983%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=sgV%2BBBAHfwTRqn9fTiOYsGsIgkvsOnNLaAJ9hAziMv8%3D&amp;reserved=0<https://eur01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.linkedin.com%2Fin%2Fhedyeh-ahmadi&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C596d927815de4130a05708d977e8293c%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672661273318983%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=sgV%2BBBAHfwTRqn9fTiOYsGsIgkvsOnNLaAJ9hAziMv8%3D&amp;reserved=0
> <https://eur01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.linkedin.com%2Fin%2Fhedyeh-ahmadi&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C596d927815de4130a05708d977e8293c%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672661273318983%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=sgV%2BBBAHfwTRqn9fTiOYsGsIgkvsOnNLaAJ9hAziMv8%3D&amp;reserved=0<https://eur01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.linkedin.com%2Fin%2Fhedyeh-ahmadi&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C596d927815de4130a05708d977e8293c%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672661273318983%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=sgV%2BBBAHfwTRqn9fTiOYsGsIgkvsOnNLaAJ9hAziMv8%3D&amp;reserved=0>>
>>
>>
>>        [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C596d927815de4130a05708d977e8293c%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672661273318983%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=JeXCvNShZ9xfCFlX7qBV%2BlR7RguHfsgEAoSPHBJzI%2FY%3D&amp;reserved=0
> <https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C596d927815de4130a05708d977e8293c%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672661273318983%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=JeXCvNShZ9xfCFlX7qBV%2BlR7RguHfsgEAoSPHBJzI%2FY%3D&amp;reserved=0>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C596d927815de4130a05708d977e8293c%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672661273318983%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=JeXCvNShZ9xfCFlX7qBV%2BlR7RguHfsgEAoSPHBJzI%2FY%3D&amp;reserved=0
> <https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C596d927815de4130a05708d977e8293c%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672661273328938%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=Bla%2FRWD6uYWMRaG6dLGKyoOVzMuWrXH%2B4HzftJmbLk4%3D&amp;reserved=0>
>>
>
> --
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> Graduate chair, Mathematics & Statistics
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C596d927815de4130a05708d977e8293c%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672661273328938%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=Bla%2FRWD6uYWMRaG6dLGKyoOVzMuWrXH%2B4HzftJmbLk4%3D&amp;reserved=0
> <https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C596d927815de4130a05708d977e8293c%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637672661273328938%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=Bla%2FRWD6uYWMRaG6dLGKyoOVzMuWrXH%2B4HzftJmbLk4%3D&amp;reserved=0>

--
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Fri Sep 17 22:10:37 2021
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 17 Sep 2021 15:10:37 -0500
Subject: [R-sig-ME] calculate power-linear mixed effect model
Message-ID: <CAF9-5jPFf2KqSKd4dV+4EXNDuyx_4UdbGH_8m2_fnYZF38kVZA@mail.gmail.com>

Hi All,

I plan to identify metabolite levels that differ between individuals
with various retinopathy outcomes (DR or noDR). I plan to model
metabolite levels using linear mixed models ref as implemented in
lmm2met software. The model covariates will include: age, sex, SV1,
SV, and disease_condition.

The random effect is subject variation (ID)

Disease condition is the fixed effect because I am interested in
metabolite differences between those disease conditions.

This command  will build a model for each metabolite:
fitMet = fitLmm(fix=c('Sex','Age','SV1,'SV2','disease_condition'),
random='(1|ID)', data=df, start=10)

SV1 and SV2 are surrogate variables (numerical values)

Next I need to calculate the power of my study. Let's say that I have
1,172 individuals total in the study, from which 431 are DR. Let's say
that I would like to determine the power of this study given the
effect size of 0.337.

I know about SIMR software in R but I am not sure how to apply it to
my study design.

I looked at this paper:
https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.12504

But I am not sure how to adapt the code given in the tutorial so that
it is matching to mine design.

Can you please help,

Thanks
Ana


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Fri Sep 17 22:55:32 2021
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 17 Sep 2021 15:55:32 -0500
Subject: [R-sig-ME] calculate power-linear mixed effect model
In-Reply-To: <CAF9-5jPFf2KqSKd4dV+4EXNDuyx_4UdbGH_8m2_fnYZF38kVZA@mail.gmail.com>
References: <CAF9-5jPFf2KqSKd4dV+4EXNDuyx_4UdbGH_8m2_fnYZF38kVZA@mail.gmail.com>
Message-ID: <CAF9-5jOXeG-te1ucNw+F_ptwqJd=LQmb=V8EwYqxL7Q8xpLSGw@mail.gmail.com>

I tried doing this but I am unsure if I am on the right track:

library(simr)

## trying to simulate some data and run a power calculation
x1 <- rnorm(1172) ## creating a continuous variable
x2 <- sample(1:2,1172,replace=T) # creating some sort of grouping
variable with 2 groups
y <- rbinom(n = 1172, size = 1, prob= 0.3) # creating a binary (0,1)
response variable (with probability of success = 0.3)
a=age(1172, x = 18:89, prob = NULL, name = "Age")   #simulating age
with ?wakefield? package
s=sex(1172)   #simulating sex with ?wakefield? package
df <- data.frame(y = y, x1 = x1, x2 = x2, a=a, s=s) #merging into one data set

> head(df)
  y          x1 x2  a      s
1 0 -0.28876179  1 53   Male
2 0 -0.05696877  2 23 Female

m1 <- lmer(y ~ x1+a+s + (1|x2), data = df)

fixef(m1)["x1"] <-0.337

powerSim(m1)

I am getting a bunch of these messages when I run this:

?boundary (singular) fit: see ?isSingular?

On Fri, Sep 17, 2021 at 3:10 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hi All,
>
> I plan to identify metabolite levels that differ between individuals
> with various retinopathy outcomes (DR or noDR). I plan to model
> metabolite levels using linear mixed models ref as implemented in
> lmm2met software. The model covariates will include: age, sex, SV1,
> SV, and disease_condition.
>
> The random effect is subject variation (ID)
>
> Disease condition is the fixed effect because I am interested in
> metabolite differences between those disease conditions.
>
> This command  will build a model for each metabolite:
> fitMet = fitLmm(fix=c('Sex','Age','SV1,'SV2','disease_condition'),
> random='(1|ID)', data=df, start=10)
>
> SV1 and SV2 are surrogate variables (numerical values)
>
> Next I need to calculate the power of my study. Let's say that I have
> 1,172 individuals total in the study, from which 431 are DR. Let's say
> that I would like to determine the power of this study given the
> effect size of 0.337.
>
> I know about SIMR software in R but I am not sure how to apply it to
> my study design.
>
> I looked at this paper:
> https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.12504
>
> But I am not sure how to adapt the code given in the tutorial so that
> it is matching to mine design.
>
> Can you please help,
>
> Thanks
> Ana


From biii m@iii@g oii de@@ey@ws  Sat Sep 18 21:09:44 2021
From: biii m@iii@g oii de@@ey@ws (biii m@iii@g oii de@@ey@ws)
Date: Sat, 18 Sep 2021 15:09:44 -0400
Subject: [R-sig-ME] nlme::gnls Warning Message Suggests Potential Bug
Message-ID: <001901d7acc0$bdef3db0$39cdb910$@denney.ws>

Hello,

 

While working on an nlme::gnls model just now, I made an error in the model
specification where I included a params argument without specifying all of
the params.  When I did that, I got a warning that suggested that the error
in the params argument should have been caught earlier.

 

Is this something that should be fixed?  (Not exactly a bug but some level
of issue seems to be afoot.)

 

Thanks,


Bill

 

``` r

library(nlme)

#> Warning: package 'nlme' was built under R version 4.1.1

set.seed(5)

d <-

  expand.grid(

    STUDYID=c("A", "B"),

    ANIMAL=factor(1:10)

  )

d$indep <- 1:nrow(d)

d$value <- exp(rnorm(nrow(d)))

 

model <- gnls(value~e0+slope*indep, data=d, start=c(e0=0, slope=0))

model <-

  gnls(

    value~e0+slope*indep,

    data=d,

    # Whoops, I forgot to include 'slope' in the 'params'

    params=e0~STUDYID,

    start=c(e0=c(0, 0), slope=0),

    weights=varExp(form=~fitted(.))

  )

#> Warning in terms.formula(formula, data = data): 'varlist' has changed
(from

#> nvar=4) to new 5 after EncodeVars() -- should no longer happen!

#> Error in eval(predvars, data, env): object 'slope' not found

# But, the warning suggests that something should have been caught sooner.

 

# When I include 'slope' in the 'params' argument, everything is fine.

model <-

  gnls(

    value~e0+slope*indep,

    data=d,

    params=

      list(

        e0~STUDYID,

        slope~1

      ),

    start=c(e0=c(0, 0), slope=0),

    weights=varExp(form=~fitted(.))

  )

```

 

<sup>Created on 2021-09-18 by the [reprex
package](https://reprex.tidyverse.org) (v2.0.1)</sup>


	[[alternative HTML version deleted]]


From @|m@h@rme| @end|ng |rom gm@||@com  Sat Sep 25 23:26:39 2021
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Sat, 25 Sep 2021 16:26:39 -0500
Subject: [R-sig-ME] Help with interpreting one fixed-effect coefficient
Message-ID: <CACgv6yUv3D=+6ftFQSoaGiXWWPq4SQkMO+wU-XKCBa9azzehmA@mail.gmail.com>

Dear Colleagues,

Apologies for crossposting (https://stats.stackexchange.com/q/545975/284623).

I've two categorical moderators i.e., students' ***sex*** (`boys`,
`girls`) and the ***school-gender system*** (`boy-only`, `girl-only`,
`mixed`) in a model like: `y ~ sex + schoolgend`.

My coefs are below. I can interpret three of the coefs but wonder how
to interpret the third one from the top (.175)?

Assume "intrcpt" represents the boys' mean in mixed schools.

                         Estimate
(Intercept)             -0.189
schgendboy-only   0.180
schgendgirl-only    0.175
sexgirls                  0.168

My interpretations of the coefficients are as follows:

            "(Intercept)": mean of y for boys in mixed schools = -.189
 "schgendboy-only": diff. bet. boys in boy-only vs. mixed schools = +.180
  "schgendgirl-only": diff. bet. ???????????????????????????? = +.175
                "sexgirls": diff. bet. girls vs. boys in mixed schools = +.168

If my interpretation logic for all other coefs is correct, then, this
third coef. must mean:

diff. bet. boys in girl-only vs. mixed schools = +.175! (which makes no sense!)

ps. I know I will end-up interpreting +1.75 as: diff. bet. girls in
girl-only vs. mixed schools BUT this doesn't follow the interpretation
logic for other coefs PLUS there are no labels in the output to show
what's what!

Many thanks,
Simon


From juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com  Sun Sep 26 06:59:55 2021
From: juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com (Juho Kristian Ruohonen)
Date: Sun, 26 Sep 2021 07:59:55 +0300
Subject: [R-sig-ME] Help with interpreting one fixed-effect coefficient
In-Reply-To: <CACgv6yUv3D=+6ftFQSoaGiXWWPq4SQkMO+wU-XKCBa9azzehmA@mail.gmail.com>
References: <CACgv6yUv3D=+6ftFQSoaGiXWWPq4SQkMO+wU-XKCBa9azzehmA@mail.gmail.com>
Message-ID: <CAG_dBVfoKiUgTo08s7bUaR2z48qL+U+0ux-nVKayx_gKTwEY2g@mail.gmail.com>

Fellow student commenting here...

As you suggest, schgendgirl-only can only ever apply to female students.
Strictly speaking, it's the estimated mean difference between a student of
any sex in a girls-only school and a similar student in a mixed school. But
since such comparisons are only observed between girls, the estimate is
necessarily informed by girl data only. So your intended interpretation of
the coefficient is correct.


su 26. syysk. 2021 klo 0.27 Simon Harmel (sim.harmel at gmail.com) kirjoitti:

> Dear Colleagues,
>
> Apologies for crossposting (
> https://stats.stackexchange.com/q/545975/284623).
>
> I've two categorical moderators i.e., students' ***sex*** (`boys`,
> `girls`) and the ***school-gender system*** (`boy-only`, `girl-only`,
> `mixed`) in a model like: `y ~ sex + schoolgend`.
>
> My coefs are below. I can interpret three of the coefs but wonder how
> to interpret the third one from the top (.175)?
>
> Assume "intrcpt" represents the boys' mean in mixed schools.
>
>                          Estimate
> (Intercept)             -0.189
> schgendboy-only   0.180
> schgendgirl-only    0.175
> sexgirls                  0.168
>
> My interpretations of the coefficients are as follows:
>
>             "(Intercept)": mean of y for boys in mixed schools = -.189
>  "schgendboy-only": diff. bet. boys in boy-only vs. mixed schools = +.180
>   "schgendgirl-only": diff. bet. ???????????????????????????? = +.175
>                 "sexgirls": diff. bet. girls vs. boys in mixed schools =
> +.168
>
> If my interpretation logic for all other coefs is correct, then, this
> third coef. must mean:
>
> diff. bet. boys in girl-only vs. mixed schools = +.175! (which makes no
> sense!)
>
> ps. I know I will end-up interpreting +1.75 as: diff. bet. girls in
> girl-only vs. mixed schools BUT this doesn't follow the interpretation
> logic for other coefs PLUS there are no labels in the output to show
> what's what!
>
> Many thanks,
> Simon
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From @|m@h@rme| @end|ng |rom gm@||@com  Sun Sep 26 08:03:41 2021
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Sun, 26 Sep 2021 01:03:41 -0500
Subject: [R-sig-ME] Help with interpreting one fixed-effect coefficient
In-Reply-To: <CAG_dBVfoKiUgTo08s7bUaR2z48qL+U+0ux-nVKayx_gKTwEY2g@mail.gmail.com>
References: <CACgv6yUv3D=+6ftFQSoaGiXWWPq4SQkMO+wU-XKCBa9azzehmA@mail.gmail.com>
 <CAG_dBVfoKiUgTo08s7bUaR2z48qL+U+0ux-nVKayx_gKTwEY2g@mail.gmail.com>
Message-ID: <CACgv6yWuVxxvZZuFhpwKAC4hGtEBFFxuX0j0WWqHtRvjD3REtQ@mail.gmail.com>

Dear Juho and other List Members,

My problem is the logic of interpretation. Assuming no interaction, a
categorical-predictors-only model, and aside from the intercept which
captures the mean for reference categories (in this case, boys in the
mixed schools), I have learned to interpret any main effect coef for a
categorical predictor by thinking of that coef. as something that can
differ from its reference category to affect "y" ***holding any other
categorical predictor in the model at its reference category***.

By this logic, "schgendboy-only" main effect coef should mean diff.
bet. boys (held constant at the reference category) in boy-only vs.
mixed schools (which shows "schgendboy-only" can differ from its
reference category i.e, mixed schools).

By this logic, "sexgirls" main effect coef should mean diff. bet.
girls vs. boys (which shows "sexgirls" can differ from its reference
category i.e, boys) in mixed schools (held constant at the reference
category).

Therefore, by this logic, "schgendgirl-only" main effect coef should
mean diff. bet. boys (held constant at the reference category) in
girl-only vs. mixed schools (which shows "schgendgirl-only" can differ
from its reference category i.e, mixed schools).

My question is that is my logic of interpretation incorrect? Or are
there exceptions to my logic of interpretation of which interpreting
"schgendgirl-only" coef is one?

Thank you very much,
Simon

On Sun, Sep 26, 2021 at 12:00 AM Juho Kristian Ruohonen
<juho.kristian.ruohonen at gmail.com> wrote:
>
> Fellow student commenting here...
>
> As you suggest, schgendgirl-only can only ever apply to female students. Strictly speaking, it's the estimated mean difference between a student of any sex in a girls-only school and a similar student in a mixed school. But since such comparisons are only observed between girls, the estimate is necessarily informed by girl data only. So your intended interpretation of the coefficient is correct.
>
>
> su 26. syysk. 2021 klo 0.27 Simon Harmel (sim.harmel at gmail.com) kirjoitti:
>>
>> Dear Colleagues,
>>
>> Apologies for crossposting (https://stats.stackexchange.com/q/545975/284623).
>>
>> I've two categorical moderators i.e., students' ***sex*** (`boys`,
>> `girls`) and the ***school-gender system*** (`boy-only`, `girl-only`,
>> `mixed`) in a model like: `y ~ sex + schoolgend`.
>>
>> My coefs are below. I can interpret three of the coefs but wonder how
>> to interpret the third one from the top (.175)?
>>
>> Assume "intrcpt" represents the boys' mean in mixed schools.
>>
>>                          Estimate
>> (Intercept)             -0.189
>> schgendboy-only   0.180
>> schgendgirl-only    0.175
>> sexgirls                  0.168
>>
>> My interpretations of the coefficients are as follows:
>>
>>             "(Intercept)": mean of y for boys in mixed schools = -.189
>>  "schgendboy-only": diff. bet. boys in boy-only vs. mixed schools = +.180
>>   "schgendgirl-only": diff. bet. ???????????????????????????? = +.175
>>                 "sexgirls": diff. bet. girls vs. boys in mixed schools = +.168
>>
>> If my interpretation logic for all other coefs is correct, then, this
>> third coef. must mean:
>>
>> diff. bet. boys in girl-only vs. mixed schools = +.175! (which makes no sense!)
>>
>> ps. I know I will end-up interpreting +1.75 as: diff. bet. girls in
>> girl-only vs. mixed schools BUT this doesn't follow the interpretation
>> logic for other coefs PLUS there are no labels in the output to show
>> what's what!
>>
>> Many thanks,
>> Simon
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com  Sun Sep 26 08:39:25 2021
From: juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com (Juho Kristian Ruohonen)
Date: Sun, 26 Sep 2021 09:39:25 +0300
Subject: [R-sig-ME] Help with interpreting one fixed-effect coefficient
In-Reply-To: <CACgv6yWuVxxvZZuFhpwKAC4hGtEBFFxuX0j0WWqHtRvjD3REtQ@mail.gmail.com>
References: <CACgv6yUv3D=+6ftFQSoaGiXWWPq4SQkMO+wU-XKCBa9azzehmA@mail.gmail.com>
 <CAG_dBVfoKiUgTo08s7bUaR2z48qL+U+0ux-nVKayx_gKTwEY2g@mail.gmail.com>
 <CACgv6yWuVxxvZZuFhpwKAC4hGtEBFFxuX0j0WWqHtRvjD3REtQ@mail.gmail.com>
Message-ID: <CAG_dBVep4WSVRaOwRkZLKF8zrVBZMZ-_4X=_X63sJw9C1ZEKfw@mail.gmail.com>

In my view, your logic is slightly oversimplified (i.e. incorrect).
Regression models do not estimate coefficients by holding predictors
constant exclusively at the reference category. They do something more
general, namely estimate coefficients by holding predictors constant at any
value at which variation is observed in the values of the other predictors.

su 26. syysk. 2021 klo 9.03 Simon Harmel (sim.harmel at gmail.com) kirjoitti:

> Dear Juho and other List Members,
>
> My problem is the logic of interpretation. Assuming no interaction, a
> categorical-predictors-only model, and aside from the intercept which
> captures the mean for reference categories (in this case, boys in the
> mixed schools), I have learned to interpret any main effect coef for a
> categorical predictor by thinking of that coef. as something that can
> differ from its reference category to affect "y" ***holding any other
> categorical predictor in the model at its reference category***.
>
> By this logic, "schgendboy-only" main effect coef should mean diff.
> bet. boys (held constant at the reference category) in boy-only vs.
> mixed schools (which shows "schgendboy-only" can differ from its
> reference category i.e, mixed schools).
>
> By this logic, "sexgirls" main effect coef should mean diff. bet.
> girls vs. boys (which shows "sexgirls" can differ from its reference
> category i.e, boys) in mixed schools (held constant at the reference
> category).
>
> Therefore, by this logic, "schgendgirl-only" main effect coef should
> mean diff. bet. boys (held constant at the reference category) in
> girl-only vs. mixed schools (which shows "schgendgirl-only" can differ
> from its reference category i.e, mixed schools).
>
> My question is that is my logic of interpretation incorrect? Or are
> there exceptions to my logic of interpretation of which interpreting
> "schgendgirl-only" coef is one?
>
> Thank you very much,
> Simon
>
> On Sun, Sep 26, 2021 at 12:00 AM Juho Kristian Ruohonen
> <juho.kristian.ruohonen at gmail.com> wrote:
> >
> > Fellow student commenting here...
> >
> > As you suggest, schgendgirl-only can only ever apply to female students.
> Strictly speaking, it's the estimated mean difference between a student of
> any sex in a girls-only school and a similar student in a mixed school. But
> since such comparisons are only observed between girls, the estimate is
> necessarily informed by girl data only. So your intended interpretation of
> the coefficient is correct.
> >
> >
> > su 26. syysk. 2021 klo 0.27 Simon Harmel (sim.harmel at gmail.com)
> kirjoitti:
> >>
> >> Dear Colleagues,
> >>
> >> Apologies for crossposting (
> https://stats.stackexchange.com/q/545975/284623).
> >>
> >> I've two categorical moderators i.e., students' ***sex*** (`boys`,
> >> `girls`) and the ***school-gender system*** (`boy-only`, `girl-only`,
> >> `mixed`) in a model like: `y ~ sex + schoolgend`.
> >>
> >> My coefs are below. I can interpret three of the coefs but wonder how
> >> to interpret the third one from the top (.175)?
> >>
> >> Assume "intrcpt" represents the boys' mean in mixed schools.
> >>
> >>                          Estimate
> >> (Intercept)             -0.189
> >> schgendboy-only   0.180
> >> schgendgirl-only    0.175
> >> sexgirls                  0.168
> >>
> >> My interpretations of the coefficients are as follows:
> >>
> >>             "(Intercept)": mean of y for boys in mixed schools = -.189
> >>  "schgendboy-only": diff. bet. boys in boy-only vs. mixed schools =
> +.180
> >>   "schgendgirl-only": diff. bet. ???????????????????????????? = +.175
> >>                 "sexgirls": diff. bet. girls vs. boys in mixed schools
> = +.168
> >>
> >> If my interpretation logic for all other coefs is correct, then, this
> >> third coef. must mean:
> >>
> >> diff. bet. boys in girl-only vs. mixed schools = +.175! (which makes no
> sense!)
> >>
> >> ps. I know I will end-up interpreting +1.75 as: diff. bet. girls in
> >> girl-only vs. mixed schools BUT this doesn't follow the interpretation
> >> logic for other coefs PLUS there are no labels in the output to show
> >> what's what!
> >>
> >> Many thanks,
> >> Simon
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From @|m@h@rme| @end|ng |rom gm@||@com  Sun Sep 26 08:56:59 2021
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Sun, 26 Sep 2021 01:56:59 -0500
Subject: [R-sig-ME] Help with interpreting one fixed-effect coefficient
In-Reply-To: <CAG_dBVep4WSVRaOwRkZLKF8zrVBZMZ-_4X=_X63sJw9C1ZEKfw@mail.gmail.com>
References: <CACgv6yUv3D=+6ftFQSoaGiXWWPq4SQkMO+wU-XKCBa9azzehmA@mail.gmail.com>
 <CAG_dBVfoKiUgTo08s7bUaR2z48qL+U+0ux-nVKayx_gKTwEY2g@mail.gmail.com>
 <CACgv6yWuVxxvZZuFhpwKAC4hGtEBFFxuX0j0WWqHtRvjD3REtQ@mail.gmail.com>
 <CAG_dBVep4WSVRaOwRkZLKF8zrVBZMZ-_4X=_X63sJw9C1ZEKfw@mail.gmail.com>
Message-ID: <CACgv6yW-1Ls9shO2NiJtEXGAA3EMQz_50taJ2stQSKG6f-Z6qg@mail.gmail.com>

Could you please apply your logic step by step to the three coefficients?



On Sun, Sep 26, 2021 at 1:39 AM Juho Kristian Ruohonen
<juho.kristian.ruohonen at gmail.com> wrote:
>
> In my view, your logic is slightly oversimplified (i.e. incorrect). Regression models do not estimate coefficients by holding predictors constant exclusively at the reference category. They do something more general, namely estimate coefficients by holding predictors constant at any value at which variation is observed in the values of the other predictors.
>
> su 26. syysk. 2021 klo 9.03 Simon Harmel (sim.harmel at gmail.com) kirjoitti:
>>
>> Dear Juho and other List Members,
>>
>> My problem is the logic of interpretation. Assuming no interaction, a
>> categorical-predictors-only model, and aside from the intercept which
>> captures the mean for reference categories (in this case, boys in the
>> mixed schools), I have learned to interpret any main effect coef for a
>> categorical predictor by thinking of that coef. as something that can
>> differ from its reference category to affect "y" ***holding any other
>> categorical predictor in the model at its reference category***.
>>
>> By this logic, "schgendboy-only" main effect coef should mean diff.
>> bet. boys (held constant at the reference category) in boy-only vs.
>> mixed schools (which shows "schgendboy-only" can differ from its
>> reference category i.e, mixed schools).
>>
>> By this logic, "sexgirls" main effect coef should mean diff. bet.
>> girls vs. boys (which shows "sexgirls" can differ from its reference
>> category i.e, boys) in mixed schools (held constant at the reference
>> category).
>>
>> Therefore, by this logic, "schgendgirl-only" main effect coef should
>> mean diff. bet. boys (held constant at the reference category) in
>> girl-only vs. mixed schools (which shows "schgendgirl-only" can differ
>> from its reference category i.e, mixed schools).
>>
>> My question is that is my logic of interpretation incorrect? Or are
>> there exceptions to my logic of interpretation of which interpreting
>> "schgendgirl-only" coef is one?
>>
>> Thank you very much,
>> Simon
>>
>> On Sun, Sep 26, 2021 at 12:00 AM Juho Kristian Ruohonen
>> <juho.kristian.ruohonen at gmail.com> wrote:
>> >
>> > Fellow student commenting here...
>> >
>> > As you suggest, schgendgirl-only can only ever apply to female students. Strictly speaking, it's the estimated mean difference between a student of any sex in a girls-only school and a similar student in a mixed school. But since such comparisons are only observed between girls, the estimate is necessarily informed by girl data only. So your intended interpretation of the coefficient is correct.
>> >
>> >
>> > su 26. syysk. 2021 klo 0.27 Simon Harmel (sim.harmel at gmail.com) kirjoitti:
>> >>
>> >> Dear Colleagues,
>> >>
>> >> Apologies for crossposting (https://stats.stackexchange.com/q/545975/284623).
>> >>
>> >> I've two categorical moderators i.e., students' ***sex*** (`boys`,
>> >> `girls`) and the ***school-gender system*** (`boy-only`, `girl-only`,
>> >> `mixed`) in a model like: `y ~ sex + schoolgend`.
>> >>
>> >> My coefs are below. I can interpret three of the coefs but wonder how
>> >> to interpret the third one from the top (.175)?
>> >>
>> >> Assume "intrcpt" represents the boys' mean in mixed schools.
>> >>
>> >>                          Estimate
>> >> (Intercept)             -0.189
>> >> schgendboy-only   0.180
>> >> schgendgirl-only    0.175
>> >> sexgirls                  0.168
>> >>
>> >> My interpretations of the coefficients are as follows:
>> >>
>> >>             "(Intercept)": mean of y for boys in mixed schools = -.189
>> >>  "schgendboy-only": diff. bet. boys in boy-only vs. mixed schools = +.180
>> >>   "schgendgirl-only": diff. bet. ???????????????????????????? = +.175
>> >>                 "sexgirls": diff. bet. girls vs. boys in mixed schools = +.168
>> >>
>> >> If my interpretation logic for all other coefs is correct, then, this
>> >> third coef. must mean:
>> >>
>> >> diff. bet. boys in girl-only vs. mixed schools = +.175! (which makes no sense!)
>> >>
>> >> ps. I know I will end-up interpreting +1.75 as: diff. bet. girls in
>> >> girl-only vs. mixed schools BUT this doesn't follow the interpretation
>> >> logic for other coefs PLUS there are no labels in the output to show
>> >> what's what!
>> >>
>> >> Many thanks,
>> >> Simon
>> >>
>> >> _______________________________________________
>> >> R-sig-mixed-models at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com  Sun Sep 26 09:43:25 2021
From: juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com (Juho Kristian Ruohonen)
Date: Sun, 26 Sep 2021 10:43:25 +0300
Subject: [R-sig-ME] Help with interpreting one fixed-effect coefficient
In-Reply-To: <CACgv6yW-1Ls9shO2NiJtEXGAA3EMQz_50taJ2stQSKG6f-Z6qg@mail.gmail.com>
References: <CACgv6yUv3D=+6ftFQSoaGiXWWPq4SQkMO+wU-XKCBa9azzehmA@mail.gmail.com>
 <CAG_dBVfoKiUgTo08s7bUaR2z48qL+U+0ux-nVKayx_gKTwEY2g@mail.gmail.com>
 <CACgv6yWuVxxvZZuFhpwKAC4hGtEBFFxuX0j0WWqHtRvjD3REtQ@mail.gmail.com>
 <CAG_dBVep4WSVRaOwRkZLKF8zrVBZMZ-_4X=_X63sJw9C1ZEKfw@mail.gmail.com>
 <CACgv6yW-1Ls9shO2NiJtEXGAA3EMQz_50taJ2stQSKG6f-Z6qg@mail.gmail.com>
Message-ID: <CAG_dBVfvCSwcnwvpO9CwbBdPh31YfQtzkf0RpOJJesnLD3HE2w@mail.gmail.com>

 (Intercept): with all predictors at zero, an average student is estimated
to have a response value of -0.18.
schgendboy-only: on average, students in boys-only schools are estimated to
have response values 0.180 units higher than otherwise comparable students
in a mixed-sex schools.
schgendgirl-only: on average, students in girls-only schools are estimated
to have response values  0.175 units higher than otherwise comparable
students in a mixed-sex schools.
sexgirl: on average, female students are estimated to have response values
0.168 units higher than otherwise comparable male students.

su 26. syysk. 2021 klo 9.57 Simon Harmel (sim.harmel at gmail.com) kirjoitti:

> Could you please apply your logic step by step to the three coefficients?
>
>
>
> On Sun, Sep 26, 2021 at 1:39 AM Juho Kristian Ruohonen
> <juho.kristian.ruohonen at gmail.com> wrote:
> >
> > In my view, your logic is slightly oversimplified (i.e. incorrect).
> Regression models do not estimate coefficients by holding predictors
> constant exclusively at the reference category. They do something more
> general, namely estimate coefficients by holding predictors constant at any
> value at which variation is observed in the values of the other predictors.
> >
> > su 26. syysk. 2021 klo 9.03 Simon Harmel (sim.harmel at gmail.com)
> kirjoitti:
> >>
> >> Dear Juho and other List Members,
> >>
> >> My problem is the logic of interpretation. Assuming no interaction, a
> >> categorical-predictors-only model, and aside from the intercept which
> >> captures the mean for reference categories (in this case, boys in the
> >> mixed schools), I have learned to interpret any main effect coef for a
> >> categorical predictor by thinking of that coef. as something that can
> >> differ from its reference category to affect "y" ***holding any other
> >> categorical predictor in the model at its reference category***.
> >>
> >> By this logic, "schgendboy-only" main effect coef should mean diff.
> >> bet. boys (held constant at the reference category) in boy-only vs.
> >> mixed schools (which shows "schgendboy-only" can differ from its
> >> reference category i.e, mixed schools).
> >>
> >> By this logic, "sexgirls" main effect coef should mean diff. bet.
> >> girls vs. boys (which shows "sexgirls" can differ from its reference
> >> category i.e, boys) in mixed schools (held constant at the reference
> >> category).
> >>
> >> Therefore, by this logic, "schgendgirl-only" main effect coef should
> >> mean diff. bet. boys (held constant at the reference category) in
> >> girl-only vs. mixed schools (which shows "schgendgirl-only" can differ
> >> from its reference category i.e, mixed schools).
> >>
> >> My question is that is my logic of interpretation incorrect? Or are
> >> there exceptions to my logic of interpretation of which interpreting
> >> "schgendgirl-only" coef is one?
> >>
> >> Thank you very much,
> >> Simon
> >>
> >> On Sun, Sep 26, 2021 at 12:00 AM Juho Kristian Ruohonen
> >> <juho.kristian.ruohonen at gmail.com> wrote:
> >> >
> >> > Fellow student commenting here...
> >> >
> >> > As you suggest, schgendgirl-only can only ever apply to female
> students. Strictly speaking, it's the estimated mean difference between a
> student of any sex in a girls-only school and a similar student in a mixed
> school. But since such comparisons are only observed between girls, the
> estimate is necessarily informed by girl data only. So your intended
> interpretation of the coefficient is correct.
> >> >
> >> >
> >> > su 26. syysk. 2021 klo 0.27 Simon Harmel (sim.harmel at gmail.com)
> kirjoitti:
> >> >>
> >> >> Dear Colleagues,
> >> >>
> >> >> Apologies for crossposting (
> https://stats.stackexchange.com/q/545975/284623).
> >> >>
> >> >> I've two categorical moderators i.e., students' ***sex*** (`boys`,
> >> >> `girls`) and the ***school-gender system*** (`boy-only`, `girl-only`,
> >> >> `mixed`) in a model like: `y ~ sex + schoolgend`.
> >> >>
> >> >> My coefs are below. I can interpret three of the coefs but wonder how
> >> >> to interpret the third one from the top (.175)?
> >> >>
> >> >> Assume "intrcpt" represents the boys' mean in mixed schools.
> >> >>
> >> >>                          Estimate
> >> >> (Intercept)             -0.189
> >> >> schgendboy-only   0.180
> >> >> schgendgirl-only    0.175
> >> >> sexgirls                  0.168
> >> >>
> >> >> My interpretations of the coefficients are as follows:
> >> >>
> >> >>             "(Intercept)": mean of y for boys in mixed schools =
> -.189
> >> >>  "schgendboy-only": diff. bet. boys in boy-only vs. mixed schools =
> +.180
> >> >>   "schgendgirl-only": diff. bet. ???????????????????????????? = +.175
> >> >>                 "sexgirls": diff. bet. girls vs. boys in mixed
> schools = +.168
> >> >>
> >> >> If my interpretation logic for all other coefs is correct, then, this
> >> >> third coef. must mean:
> >> >>
> >> >> diff. bet. boys in girl-only vs. mixed schools = +.175! (which makes
> no sense!)
> >> >>
> >> >> ps. I know I will end-up interpreting +1.75 as: diff. bet. girls in
> >> >> girl-only vs. mixed schools BUT this doesn't follow the
> interpretation
> >> >> logic for other coefs PLUS there are no labels in the output to show
> >> >> what's what!
> >> >>
> >> >> Many thanks,
> >> >> Simon
> >> >>
> >> >> _______________________________________________
> >> >> R-sig-mixed-models at r-project.org mailing list
> >> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From |upp @end|ng |rom uch|c@go@edu  Sun Sep 26 15:28:46 2021
From: |upp @end|ng |rom uch|c@go@edu (Stuart Luppescu)
Date: Sun, 26 Sep 2021 22:28:46 +0900
Subject: [R-sig-ME] Help with interpreting one fixed-effect coefficient
In-Reply-To: <CACgv6yUv3D=+6ftFQSoaGiXWWPq4SQkMO+wU-XKCBa9azzehmA@mail.gmail.com>
References: <CACgv6yUv3D=+6ftFQSoaGiXWWPq4SQkMO+wU-XKCBa9azzehmA@mail.gmail.com>
Message-ID: <704bf59d-0f59-8755-9f8e-8a4b543567bc@uchicago.edu>

On 9/26/21 06:26, Simon Harmel wrote:
> I've two categorical moderators i.e., students' ***sex*** (`boys`,
> `girls`) and the ***school-gender system*** (`boy-only`, `girl-only`,
> `mixed`) in a model like: `y ~ sex + schoolgend`.

I don't get this. Why is this posted to a mixed-effects model list when 
there is no random effect? That said, this really is a hierarchical 
model, since the sex predictor is an individual-level predictor, and 
school-gender-system is a school-level predictor. In a case like this, 
you're getting messed up trying to conceptualize the cross-level 
interaction. My head is all messed up just trying to figure it out.

-- 
Stuart Luppescu
Chief Psychometrician (ret.)
UChicago Consortium on School Research


From |@brun@ @end|ng |rom udc@e@  Sun Sep 26 15:52:05 2021
From: |@brun@ @end|ng |rom udc@e@ (Fernando Pedro Bruna Quintas)
Date: Sun, 26 Sep 2021 13:52:05 +0000
Subject: [R-sig-ME] Help with interpreting one fixed-effect coefficient
In-Reply-To: <704bf59d-0f59-8755-9f8e-8a4b543567bc@uchicago.edu>
References: <CACgv6yUv3D=+6ftFQSoaGiXWWPq4SQkMO+wU-XKCBa9azzehmA@mail.gmail.com>
 <704bf59d-0f59-8755-9f8e-8a4b543567bc@uchicago.edu>
Message-ID: <PAXPR02MB779834E6CF128A2E70D7989192A69@PAXPR02MB7798.eurprd02.prod.outlook.com>


It is a good question for a list on mixed models, though the interpretation would be common to traditional linear models. There is no mess in the questions. There are not interactions. The question is about the interpretation of the parameters in the following equation:

Yij = Cij + B1 x Xij + B2 x Zj

The special characteristics of the question is about the gender composition of the variables Xij and Zj.

Best,

Fernando

________________________________
De: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> en nombre de Stuart Luppescu <lupp at uchicago.edu>
Enviado: domingo, 26 de septiembre de 2021 15:28
Para: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Asunto: Re: [R-sig-ME] Help with interpreting one fixed-effect coefficient

On 9/26/21 06:26, Simon Harmel wrote:
> I've two categorical moderators i.e., students' ***sex*** (`boys`,
> `girls`) and the ***school-gender system*** (`boy-only`, `girl-only`,
> `mixed`) in a model like: `y ~ sex + schoolgend`.

I don't get this. Why is this posted to a mixed-effects model list when
there is no random effect? That said, this really is a hierarchical
model, since the sex predictor is an individual-level predictor, and
school-gender-system is a school-level predictor. In a case like this,
you're getting messed up trying to conceptualize the cross-level
interaction. My head is all messed up just trying to figure it out.

--
Stuart Luppescu
Chief Psychometrician (ret.)
UChicago Consortium on School Research

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From @|m@h@rme| @end|ng |rom gm@||@com  Sun Sep 26 17:20:09 2021
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Sun, 26 Sep 2021 10:20:09 -0500
Subject: [R-sig-ME] Help with interpreting one fixed-effect coefficient
In-Reply-To: <CAG_dBVfvCSwcnwvpO9CwbBdPh31YfQtzkf0RpOJJesnLD3HE2w@mail.gmail.com>
References: <CACgv6yUv3D=+6ftFQSoaGiXWWPq4SQkMO+wU-XKCBa9azzehmA@mail.gmail.com>
 <CAG_dBVfoKiUgTo08s7bUaR2z48qL+U+0ux-nVKayx_gKTwEY2g@mail.gmail.com>
 <CACgv6yWuVxxvZZuFhpwKAC4hGtEBFFxuX0j0WWqHtRvjD3REtQ@mail.gmail.com>
 <CAG_dBVep4WSVRaOwRkZLKF8zrVBZMZ-_4X=_X63sJw9C1ZEKfw@mail.gmail.com>
 <CACgv6yW-1Ls9shO2NiJtEXGAA3EMQz_50taJ2stQSKG6f-Z6qg@mail.gmail.com>
 <CAG_dBVfvCSwcnwvpO9CwbBdPh31YfQtzkf0RpOJJesnLD3HE2w@mail.gmail.com>
Message-ID: <CACgv6yU5PD32hhbyoYyxiWCvaupN_aoZNaW_jRbV0gXXu4-j3w@mail.gmail.com>

Dear Juho,

Sure. However, all major resources disagree with your interpretation
(e.g., https://onlinelibrary.wiley.com/doi/book/10.1002/9781118625590).
This is because the goal of fixed-effect coefs is to predict/estimate
the mean of "y"'s population distribution conditional on specific
values/levels of a combination of predictors in the model. This means
that the coefs. themselves must represent specific values/levels of a
combination of predictors in the model to make such conditional
predictions possible.

Applying this logic to your interpretations, your interpretations
simply ignore specifying which specific values/levels of a combination
of predictors in the model each coef. represents. Therefore, it
logically doesn't agree with the goal of fixed-effects coefficients.

Thanks,
Simon

On Sun, Sep 26, 2021 at 2:43 AM Juho Kristian Ruohonen
<juho.kristian.ruohonen at gmail.com> wrote:
>
> (Intercept): with all predictors at zero, an average student is estimated to have a response value of -0.18.
> schgendboy-only: on average, students in boys-only schools are estimated to have response values 0.180 units higher than otherwise comparable students in a mixed-sex schools.
> schgendgirl-only: on average, students in girls-only schools are estimated to have response values  0.175 units higher than otherwise comparable students in a mixed-sex schools.
> sexgirl: on average, female students are estimated to have response values 0.168 units higher than otherwise comparable male students.
>
> su 26. syysk. 2021 klo 9.57 Simon Harmel (sim.harmel at gmail.com) kirjoitti:
>>
>> Could you please apply your logic step by step to the three coefficients?
>>
>>
>>
>> On Sun, Sep 26, 2021 at 1:39 AM Juho Kristian Ruohonen
>> <juho.kristian.ruohonen at gmail.com> wrote:
>> >
>> > In my view, your logic is slightly oversimplified (i.e. incorrect). Regression models do not estimate coefficients by holding predictors constant exclusively at the reference category. They do something more general, namely estimate coefficients by holding predictors constant at any value at which variation is observed in the values of the other predictors.
>> >
>> > su 26. syysk. 2021 klo 9.03 Simon Harmel (sim.harmel at gmail.com) kirjoitti:
>> >>
>> >> Dear Juho and other List Members,
>> >>
>> >> My problem is the logic of interpretation. Assuming no interaction, a
>> >> categorical-predictors-only model, and aside from the intercept which
>> >> captures the mean for reference categories (in this case, boys in the
>> >> mixed schools), I have learned to interpret any main effect coef for a
>> >> categorical predictor by thinking of that coef. as something that can
>> >> differ from its reference category to affect "y" ***holding any other
>> >> categorical predictor in the model at its reference category***.
>> >>
>> >> By this logic, "schgendboy-only" main effect coef should mean diff.
>> >> bet. boys (held constant at the reference category) in boy-only vs.
>> >> mixed schools (which shows "schgendboy-only" can differ from its
>> >> reference category i.e, mixed schools).
>> >>
>> >> By this logic, "sexgirls" main effect coef should mean diff. bet.
>> >> girls vs. boys (which shows "sexgirls" can differ from its reference
>> >> category i.e, boys) in mixed schools (held constant at the reference
>> >> category).
>> >>
>> >> Therefore, by this logic, "schgendgirl-only" main effect coef should
>> >> mean diff. bet. boys (held constant at the reference category) in
>> >> girl-only vs. mixed schools (which shows "schgendgirl-only" can differ
>> >> from its reference category i.e, mixed schools).
>> >>
>> >> My question is that is my logic of interpretation incorrect? Or are
>> >> there exceptions to my logic of interpretation of which interpreting
>> >> "schgendgirl-only" coef is one?
>> >>
>> >> Thank you very much,
>> >> Simon
>> >>
>> >> On Sun, Sep 26, 2021 at 12:00 AM Juho Kristian Ruohonen
>> >> <juho.kristian.ruohonen at gmail.com> wrote:
>> >> >
>> >> > Fellow student commenting here...
>> >> >
>> >> > As you suggest, schgendgirl-only can only ever apply to female students. Strictly speaking, it's the estimated mean difference between a student of any sex in a girls-only school and a similar student in a mixed school. But since such comparisons are only observed between girls, the estimate is necessarily informed by girl data only. So your intended interpretation of the coefficient is correct.
>> >> >
>> >> >
>> >> > su 26. syysk. 2021 klo 0.27 Simon Harmel (sim.harmel at gmail.com) kirjoitti:
>> >> >>
>> >> >> Dear Colleagues,
>> >> >>
>> >> >> Apologies for crossposting (https://stats.stackexchange.com/q/545975/284623).
>> >> >>
>> >> >> I've two categorical moderators i.e., students' ***sex*** (`boys`,
>> >> >> `girls`) and the ***school-gender system*** (`boy-only`, `girl-only`,
>> >> >> `mixed`) in a model like: `y ~ sex + schoolgend`.
>> >> >>
>> >> >> My coefs are below. I can interpret three of the coefs but wonder how
>> >> >> to interpret the third one from the top (.175)?
>> >> >>
>> >> >> Assume "intrcpt" represents the boys' mean in mixed schools.
>> >> >>
>> >> >>                          Estimate
>> >> >> (Intercept)             -0.189
>> >> >> schgendboy-only   0.180
>> >> >> schgendgirl-only    0.175
>> >> >> sexgirls                  0.168
>> >> >>
>> >> >> My interpretations of the coefficients are as follows:
>> >> >>
>> >> >>             "(Intercept)": mean of y for boys in mixed schools = -.189
>> >> >>  "schgendboy-only": diff. bet. boys in boy-only vs. mixed schools = +.180
>> >> >>   "schgendgirl-only": diff. bet. ???????????????????????????? = +.175
>> >> >>                 "sexgirls": diff. bet. girls vs. boys in mixed schools = +.168
>> >> >>
>> >> >> If my interpretation logic for all other coefs is correct, then, this
>> >> >> third coef. must mean:
>> >> >>
>> >> >> diff. bet. boys in girl-only vs. mixed schools = +.175! (which makes no sense!)
>> >> >>
>> >> >> ps. I know I will end-up interpreting +1.75 as: diff. bet. girls in
>> >> >> girl-only vs. mixed schools BUT this doesn't follow the interpretation
>> >> >> logic for other coefs PLUS there are no labels in the output to show
>> >> >> what's what!
>> >> >>
>> >> >> Many thanks,
>> >> >> Simon
>> >> >>
>> >> >> _______________________________________________
>> >> >> R-sig-mixed-models at r-project.org mailing list
>> >> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From ru@@e||-|enth @end|ng |rom u|ow@@edu  Sun Sep 26 19:39:42 2021
From: ru@@e||-|enth @end|ng |rom u|ow@@edu (Lenth, Russell V)
Date: Sun, 26 Sep 2021 17:39:42 +0000
Subject: [R-sig-ME] Help with interpreting one fixed-effect coefficient
Message-ID: <DM6PR04MB4474B04E915E92DBB28EDB83F1A69@DM6PR04MB4474.namprd04.prod.outlook.com>

It kind of bugs me to see people get unduly fixated on interpreting regression coefficients. To me, it is like driving a car down the highway while intently focused on the instrument panel instead of where we are going. Let's see -- the tachometer looks OK and we're just slightly above the speed limit -- but did you notice that you are passing a truck and you're entering a construction zone?

Speaking of construction... for starters, the model is problematic. I can't imagine that those two factors don't interact; yet the model doesn't include interaction. Is that because the coefficients would be even harder to interpret? Because they will be.

I suggest looking instead at what the (improved) model predicts. That may be done via an expression like 

    new <- expand.grid(sex = c('boys', 'girls', schgender = c('boy-only', 'girl-only', 'mixed')

which constructs a data frame with all combinations of the factors. Then use 'predict(model, newdata = new)` and you will see what the model predicts for all those combinations. It does not require much expertise or experience to interpret those. Moreover, they can be plotted so you can visualize the factor effects and their joint effects.

Or (forgive me for self-promotion) you could use a package like `emmeans', or 'effects' or 'ggeffects' to facilitate this kind of exploration.

Just my 2 cents worth.

Russ Lenth

-----Original Message-----

Date: Sun, 26 Sep 2021 09:39:25 +0300
From: Juho Kristian Ruohonen <juho.kristian.ruohonen at gmail.com>
To: Simon Harmel <sim.harmel at gmail.com>
Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Help with interpreting one fixed-effect
	coefficient
Message-ID:
	<CAG_dBVep4WSVRaOwRkZLKF8zrVBZMZ-_4X=_X63sJw9C1ZEKfw at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

In my view, your logic is slightly oversimplified (i.e. incorrect).
Regression models do not estimate coefficients by holding predictors
constant exclusively at the reference category. They do something more
general, namely estimate coefficients by holding predictors constant at any
value at which variation is observed in the values of the other predictors.

su 26. syysk. 2021 klo 9.03 Simon Harmel (sim.harmel at gmail.com) kirjoitti:

> Dear Juho and other List Members,
>
> My problem is the logic of interpretation. Assuming no interaction, a
> categorical-predictors-only model, and aside from the intercept which
> captures the mean for reference categories (in this case, boys in the
> mixed schools), I have learned to interpret any main effect coef for a
> categorical predictor by thinking of that coef. as something that can
> differ from its reference category to affect "y" ***holding any other
> categorical predictor in the model at its reference category***.
>
> By this logic, "schgendboy-only" main effect coef should mean diff.
> bet. boys (held constant at the reference category) in boy-only vs.
> mixed schools (which shows "schgendboy-only" can differ from its
> reference category i.e, mixed schools).
>
> By this logic, "sexgirls" main effect coef should mean diff. bet.
> girls vs. boys (which shows "sexgirls" can differ from its reference
> category i.e, boys) in mixed schools (held constant at the reference
> category).
>
> Therefore, by this logic, "schgendgirl-only" main effect coef should
> mean diff. bet. boys (held constant at the reference category) in
> girl-only vs. mixed schools (which shows "schgendgirl-only" can differ
> from its reference category i.e, mixed schools).
>
> My question is that is my logic of interpretation incorrect? Or are
> there exceptions to my logic of interpretation of which interpreting
> "schgendgirl-only" coef is one?
>
> Thank you very much,
> Simon
>
> On Sun, Sep 26, 2021 at 12:00 AM Juho Kristian Ruohonen
> <juho.kristian.ruohonen at gmail.com> wrote:
> >
> > Fellow student commenting here...
> >
> > As you suggest, schgendgirl-only can only ever apply to female students.
> Strictly speaking, it's the estimated mean difference between a student of
> any sex in a girls-only school and a similar student in a mixed school. But
> since such comparisons are only observed between girls, the estimate is
> necessarily informed by girl data only. So your intended interpretation of
> the coefficient is correct.
> >
> >
> > su 26. syysk. 2021 klo 0.27 Simon Harmel (sim.harmel at gmail.com)
> kirjoitti:
> >>
> >> Dear Colleagues,
> >>
> >> Apologies for crossposting (
> https://stats.stackexchange.com/q/545975/284623).
> >>
> >> I've two categorical moderators i.e., students' ***sex*** (`boys`,
> >> `girls`) and the ***school-gender system*** (`boy-only`, `girl-only`,
> >> `mixed`) in a model like: `y ~ sex + schoolgend`.
> >>
> >> My coefs are below. I can interpret three of the coefs but wonder how
> >> to interpret the third one from the top (.175)?
> >>
> >> Assume "intrcpt" represents the boys' mean in mixed schools.
> >>
> >>                          Estimate
> >> (Intercept)             -0.189
> >> schgendboy-only   0.180
> >> schgendgirl-only    0.175
> >> sexgirls                  0.168
> >>
> >> My interpretations of the coefficients are as follows:
> >>
> >>             "(Intercept)": mean of y for boys in mixed schools = -.189
> >>  "schgendboy-only": diff. bet. boys in boy-only vs. mixed schools =
> +.180
> >>   "schgendgirl-only": diff. bet. ???????????????????????????? = +.175
> >>                 "sexgirls": diff. bet. girls vs. boys in mixed schools
> = +.168
> >>
> >> If my interpretation logic for all other coefs is correct, then, this
> >> third coef. must mean:
> >>
> >> diff. bet. boys in girl-only vs. mixed schools = +.175! (which makes no
> sense!)
> >>
> >> ps. I know I will end-up interpreting +1.75 as: diff. bet. girls in
> >> girl-only vs. mixed schools BUT this doesn't follow the interpretation
> >> logic for other coefs PLUS there are no labels in the output to show
> >> what's what!
> >>
> >> Many thanks,
> >> Simon


From @|m@h@rme| @end|ng |rom gm@||@com  Sun Sep 26 20:03:23 2021
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Sun, 26 Sep 2021 13:03:23 -0500
Subject: [R-sig-ME] Help with interpreting one fixed-effect coefficient
In-Reply-To: <DM6PR04MB4474B04E915E92DBB28EDB83F1A69@DM6PR04MB4474.namprd04.prod.outlook.com>
References: <DM6PR04MB4474B04E915E92DBB28EDB83F1A69@DM6PR04MB4474.namprd04.prod.outlook.com>
Message-ID: <CACgv6yUZH9a_N63S28vAjq+bwvu5ECv-GnBKuXei-xcuXv9+1w@mail.gmail.com>

Dear Russell,

Thanks for sharing your perspective. First, I'm seeking an answer to
the following question:
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html .

Second, the model is from p.80 (section 6.1) of the following manual:
http://www.bristol.ac.uk/cmm/media/software/mlwin/downloads/manuals/3-05/manual-web.pdf

Third, you can replicate (or apply 'emmeans' to) the model using the following:

library(R2MLwiN) # just for the dataset
library(lmer)
data("tutorial")

Form <- normexam ~ 1 + standlrt + schgend + sex + (standlrt | school)
model <- lmer(Form, data = tutorial, REML = FALSE)  # ML to match the
manual's results
round(coef(summary(model )),3)

On Sun, Sep 26, 2021 at 12:40 PM Lenth, Russell V
<russell-lenth at uiowa.edu> wrote:
>
> It kind of bugs me to see people get unduly fixated on interpreting regression coefficients. To me, it is like driving a car down the highway while intently focused on the instrument panel instead of where we are going. Let's see -- the tachometer looks OK and we're just slightly above the speed limit -- but did you notice that you are passing a truck and you're entering a construction zone?
>
> Speaking of construction... for starters, the model is problematic. I can't imagine that those two factors don't interact; yet the model doesn't include interaction. Is that because the coefficients would be even harder to interpret? Because they will be.
>
> I suggest looking instead at what the (improved) model predicts. That may be done via an expression like
>
>     new <- expand.grid(sex = c('boys', 'girls', schgender = c('boy-only', 'girl-only', 'mixed')
>
> which constructs a data frame with all combinations of the factors. Then use 'predict(model, newdata = new)` and you will see what the model predicts for all those combinations. It does not require much expertise or experience to interpret those. Moreover, they can be plotted so you can visualize the factor effects and their joint effects.
>
> Or (forgive me for self-promotion) you could use a package like `emmeans', or 'effects' or 'ggeffects' to facilitate this kind of exploration.
>
> Just my 2 cents worth.
>
> Russ Lenth
>
> -----Original Message-----
>
> Date: Sun, 26 Sep 2021 09:39:25 +0300
> From: Juho Kristian Ruohonen <juho.kristian.ruohonen at gmail.com>
> To: Simon Harmel <sim.harmel at gmail.com>
> Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] Help with interpreting one fixed-effect
>         coefficient
> Message-ID:
>         <CAG_dBVep4WSVRaOwRkZLKF8zrVBZMZ-_4X=_X63sJw9C1ZEKfw at mail.gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
> In my view, your logic is slightly oversimplified (i.e. incorrect).
> Regression models do not estimate coefficients by holding predictors
> constant exclusively at the reference category. They do something more
> general, namely estimate coefficients by holding predictors constant at any
> value at which variation is observed in the values of the other predictors.
>
> su 26. syysk. 2021 klo 9.03 Simon Harmel (sim.harmel at gmail.com) kirjoitti:
>
> > Dear Juho and other List Members,
> >
> > My problem is the logic of interpretation. Assuming no interaction, a
> > categorical-predictors-only model, and aside from the intercept which
> > captures the mean for reference categories (in this case, boys in the
> > mixed schools), I have learned to interpret any main effect coef for a
> > categorical predictor by thinking of that coef. as something that can
> > differ from its reference category to affect "y" ***holding any other
> > categorical predictor in the model at its reference category***.
> >
> > By this logic, "schgendboy-only" main effect coef should mean diff.
> > bet. boys (held constant at the reference category) in boy-only vs.
> > mixed schools (which shows "schgendboy-only" can differ from its
> > reference category i.e, mixed schools).
> >
> > By this logic, "sexgirls" main effect coef should mean diff. bet.
> > girls vs. boys (which shows "sexgirls" can differ from its reference
> > category i.e, boys) in mixed schools (held constant at the reference
> > category).
> >
> > Therefore, by this logic, "schgendgirl-only" main effect coef should
> > mean diff. bet. boys (held constant at the reference category) in
> > girl-only vs. mixed schools (which shows "schgendgirl-only" can differ
> > from its reference category i.e, mixed schools).
> >
> > My question is that is my logic of interpretation incorrect? Or are
> > there exceptions to my logic of interpretation of which interpreting
> > "schgendgirl-only" coef is one?
> >
> > Thank you very much,
> > Simon
> >
> > On Sun, Sep 26, 2021 at 12:00 AM Juho Kristian Ruohonen
> > <juho.kristian.ruohonen at gmail.com> wrote:
> > >
> > > Fellow student commenting here...
> > >
> > > As you suggest, schgendgirl-only can only ever apply to female students.
> > Strictly speaking, it's the estimated mean difference between a student of
> > any sex in a girls-only school and a similar student in a mixed school. But
> > since such comparisons are only observed between girls, the estimate is
> > necessarily informed by girl data only. So your intended interpretation of
> > the coefficient is correct.
> > >
> > >
> > > su 26. syysk. 2021 klo 0.27 Simon Harmel (sim.harmel at gmail.com)
> > kirjoitti:
> > >>
> > >> Dear Colleagues,
> > >>
> > >> Apologies for crossposting (
> > https://stats.stackexchange.com/q/545975/284623).
> > >>
> > >> I've two categorical moderators i.e., students' ***sex*** (`boys`,
> > >> `girls`) and the ***school-gender system*** (`boy-only`, `girl-only`,
> > >> `mixed`) in a model like: `y ~ sex + schoolgend`.
> > >>
> > >> My coefs are below. I can interpret three of the coefs but wonder how
> > >> to interpret the third one from the top (.175)?
> > >>
> > >> Assume "intrcpt" represents the boys' mean in mixed schools.
> > >>
> > >>                          Estimate
> > >> (Intercept)             -0.189
> > >> schgendboy-only   0.180
> > >> schgendgirl-only    0.175
> > >> sexgirls                  0.168
> > >>
> > >> My interpretations of the coefficients are as follows:
> > >>
> > >>             "(Intercept)": mean of y for boys in mixed schools = -.189
> > >>  "schgendboy-only": diff. bet. boys in boy-only vs. mixed schools =
> > +.180
> > >>   "schgendgirl-only": diff. bet. ???????????????????????????? = +.175
> > >>                 "sexgirls": diff. bet. girls vs. boys in mixed schools
> > = +.168
> > >>
> > >> If my interpretation logic for all other coefs is correct, then, this
> > >> third coef. must mean:
> > >>
> > >> diff. bet. boys in girl-only vs. mixed schools = +.175! (which makes no
> > sense!)
> > >>
> > >> ps. I know I will end-up interpreting +1.75 as: diff. bet. girls in
> > >> girl-only vs. mixed schools BUT this doesn't follow the interpretation
> > >> logic for other coefs PLUS there are no labels in the output to show
> > >> what's what!
> > >>
> > >> Many thanks,
> > >> Simon
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From j|ox @end|ng |rom mcm@@ter@c@  Sun Sep 26 22:04:48 2021
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Sun, 26 Sep 2021 16:04:48 -0400
Subject: [R-sig-ME] Help with interpreting one fixed-effect coefficient
In-Reply-To: <531_1632679437_18QI3un4014412_CACgv6yUZH9a_N63S28vAjq+bwvu5ECv-GnBKuXei-xcuXv9+1w@mail.gmail.com>
References: <DM6PR04MB4474B04E915E92DBB28EDB83F1A69@DM6PR04MB4474.namprd04.prod.outlook.com>
 <531_1632679437_18QI3un4014412_CACgv6yUZH9a_N63S28vAjq+bwvu5ECv-GnBKuXei-xcuXv9+1w@mail.gmail.com>
Message-ID: <97ba750e-665a-a697-d569-21e60299510f@mcmaster.ca>

Dear Simon,

On 2021-09-26 2:03 p.m., Simon Harmel wrote:
> Dear Russell,
> 
> Thanks for sharing your perspective. First, I'm seeking an answer to
> the following question:
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html .
> 
> Second, the model is from p.80 (section 6.1) of the following manual:
> http://www.bristol.ac.uk/cmm/media/software/mlwin/downloads/manuals/3-05/manual-web.pdf
> 
> Third, you can replicate (or apply 'emmeans' to) the model using the following:
> 
> library(R2MLwiN) # just for the dataset
> library(lmer)
> data("tutorial")
> 
> Form <- normexam ~ 1 + standlrt + schgend + sex + (standlrt | school)
> model <- lmer(Form, data = tutorial, REML = FALSE)  # ML to match the
> manual's results
> round(coef(summary(model )),3)

For example, try the following (using effects, but you could get 
something similar from emmeans):

library("lme4") # NB: lme4, not lmer
data("tutorial", package="R2MLwiN")

Form <- normexam ~ 1 + standlrt + schgend + sex + (standlrt | school)
model <- lmer(Form, data = tutorial, REML = FALSE)

library("effects")
plot(predictorEffects(model))

(Russell: The same-sex schools have students of only one one gender, so 
what's meant by an interaction between sex and schgend would have to be 
thought out a bit more -- maybe just ravel to four categories or 
redefine school gender as coed or same.)

I hope this helps,
  John

-- 
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/

> 
> On Sun, Sep 26, 2021 at 12:40 PM Lenth, Russell V
> <russell-lenth at uiowa.edu> wrote:
>>
>> It kind of bugs me to see people get unduly fixated on interpreting regression coefficients. To me, it is like driving a car down the highway while intently focused on the instrument panel instead of where we are going. Let's see -- the tachometer looks OK and we're just slightly above the speed limit -- but did you notice that you are passing a truck and you're entering a construction zone?
>>
>> Speaking of construction... for starters, the model is problematic. I can't imagine that those two factors don't interact; yet the model doesn't include interaction. Is that because the coefficients would be even harder to interpret? Because they will be.
>>
>> I suggest looking instead at what the (improved) model predicts. That may be done via an expression like
>>
>>      new <- expand.grid(sex = c('boys', 'girls', schgender = c('boy-only', 'girl-only', 'mixed')
>>
>> which constructs a data frame with all combinations of the factors. Then use 'predict(model, newdata = new)` and you will see what the model predicts for all those combinations. It does not require much expertise or experience to interpret those. Moreover, they can be plotted so you can visualize the factor effects and their joint effects.
>>
>> Or (forgive me for self-promotion) you could use a package like `emmeans', or 'effects' or 'ggeffects' to facilitate this kind of exploration.
>>
>> Just my 2 cents worth.
>>
>> Russ Lenth
>>
>> -----Original Message-----
>>
>> Date: Sun, 26 Sep 2021 09:39:25 +0300
>> From: Juho Kristian Ruohonen <juho.kristian.ruohonen at gmail.com>
>> To: Simon Harmel <sim.harmel at gmail.com>
>> Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
>> Subject: Re: [R-sig-ME] Help with interpreting one fixed-effect
>>          coefficient
>> Message-ID:
>>          <CAG_dBVep4WSVRaOwRkZLKF8zrVBZMZ-_4X=_X63sJw9C1ZEKfw at mail.gmail.com>
>> Content-Type: text/plain; charset="utf-8"
>>
>> In my view, your logic is slightly oversimplified (i.e. incorrect).
>> Regression models do not estimate coefficients by holding predictors
>> constant exclusively at the reference category. They do something more
>> general, namely estimate coefficients by holding predictors constant at any
>> value at which variation is observed in the values of the other predictors.
>>
>> su 26. syysk. 2021 klo 9.03 Simon Harmel (sim.harmel at gmail.com) kirjoitti:
>>
>>> Dear Juho and other List Members,
>>>
>>> My problem is the logic of interpretation. Assuming no interaction, a
>>> categorical-predictors-only model, and aside from the intercept which
>>> captures the mean for reference categories (in this case, boys in the
>>> mixed schools), I have learned to interpret any main effect coef for a
>>> categorical predictor by thinking of that coef. as something that can
>>> differ from its reference category to affect "y" ***holding any other
>>> categorical predictor in the model at its reference category***.
>>>
>>> By this logic, "schgendboy-only" main effect coef should mean diff.
>>> bet. boys (held constant at the reference category) in boy-only vs.
>>> mixed schools (which shows "schgendboy-only" can differ from its
>>> reference category i.e, mixed schools).
>>>
>>> By this logic, "sexgirls" main effect coef should mean diff. bet.
>>> girls vs. boys (which shows "sexgirls" can differ from its reference
>>> category i.e, boys) in mixed schools (held constant at the reference
>>> category).
>>>
>>> Therefore, by this logic, "schgendgirl-only" main effect coef should
>>> mean diff. bet. boys (held constant at the reference category) in
>>> girl-only vs. mixed schools (which shows "schgendgirl-only" can differ
>>> from its reference category i.e, mixed schools).
>>>
>>> My question is that is my logic of interpretation incorrect? Or are
>>> there exceptions to my logic of interpretation of which interpreting
>>> "schgendgirl-only" coef is one?
>>>
>>> Thank you very much,
>>> Simon
>>>
>>> On Sun, Sep 26, 2021 at 12:00 AM Juho Kristian Ruohonen
>>> <juho.kristian.ruohonen at gmail.com> wrote:
>>>>
>>>> Fellow student commenting here...
>>>>
>>>> As you suggest, schgendgirl-only can only ever apply to female students.
>>> Strictly speaking, it's the estimated mean difference between a student of
>>> any sex in a girls-only school and a similar student in a mixed school. But
>>> since such comparisons are only observed between girls, the estimate is
>>> necessarily informed by girl data only. So your intended interpretation of
>>> the coefficient is correct.
>>>>
>>>>
>>>> su 26. syysk. 2021 klo 0.27 Simon Harmel (sim.harmel at gmail.com)
>>> kirjoitti:
>>>>>
>>>>> Dear Colleagues,
>>>>>
>>>>> Apologies for crossposting (
>>> https://stats.stackexchange.com/q/545975/284623).
>>>>>
>>>>> I've two categorical moderators i.e., students' ***sex*** (`boys`,
>>>>> `girls`) and the ***school-gender system*** (`boy-only`, `girl-only`,
>>>>> `mixed`) in a model like: `y ~ sex + schoolgend`.
>>>>>
>>>>> My coefs are below. I can interpret three of the coefs but wonder how
>>>>> to interpret the third one from the top (.175)?
>>>>>
>>>>> Assume "intrcpt" represents the boys' mean in mixed schools.
>>>>>
>>>>>                           Estimate
>>>>> (Intercept)             -0.189
>>>>> schgendboy-only   0.180
>>>>> schgendgirl-only    0.175
>>>>> sexgirls                  0.168
>>>>>
>>>>> My interpretations of the coefficients are as follows:
>>>>>
>>>>>              "(Intercept)": mean of y for boys in mixed schools = -.189
>>>>>   "schgendboy-only": diff. bet. boys in boy-only vs. mixed schools =
>>> +.180
>>>>>    "schgendgirl-only": diff. bet. ???????????????????????????? = +.175
>>>>>                  "sexgirls": diff. bet. girls vs. boys in mixed schools
>>> = +.168
>>>>>
>>>>> If my interpretation logic for all other coefs is correct, then, this
>>>>> third coef. must mean:
>>>>>
>>>>> diff. bet. boys in girl-only vs. mixed schools = +.175! (which makes no
>>> sense!)
>>>>>
>>>>> ps. I know I will end-up interpreting +1.75 as: diff. bet. girls in
>>>>> girl-only vs. mixed schools BUT this doesn't follow the interpretation
>>>>> logic for other coefs PLUS there are no labels in the output to show
>>>>> what's what!
>>>>>
>>>>> Many thanks,
>>>>> Simon
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From @|m@h@rme| @end|ng |rom gm@||@com  Sun Sep 26 22:08:21 2021
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Sun, 26 Sep 2021 15:08:21 -0500
Subject: [R-sig-ME] Help with interpreting one fixed-effect coefficient
In-Reply-To: <CACgv6yUZH9a_N63S28vAjq+bwvu5ECv-GnBKuXei-xcuXv9+1w@mail.gmail.com>
References: <DM6PR04MB4474B04E915E92DBB28EDB83F1A69@DM6PR04MB4474.namprd04.prod.outlook.com>
 <CACgv6yUZH9a_N63S28vAjq+bwvu5ECv-GnBKuXei-xcuXv9+1w@mail.gmail.com>
Message-ID: <CACgv6yXtSHhLGVGiqr7wPWTX0wAh4U8P6KRbv_6fTMF6QnnrPQ@mail.gmail.com>

Dear Russ and the List Members,

If we use Russ' great package (emmeans), we see that although meaningless,
but "schgendgirl-only" can be interpreted using the logic I mentioned here:
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html .

That is, "schgendgirl-only" can meaninglessly mean: ***diff. bet. boys in
girl-only vs. mixed schools*** just like it can meaningfully mean:
***diff. bet. girls in girl-only vs. mixed schools***

Russ, have I used emmeans correctly?

Simon

Here is a reproducible code:

library(R2MLwiN) # For the dataset
library(lme4)
library(emmeans)

data("tutorial")

Form <- normexam ~ 1 + standlrt + schgend + sex + (standlrt | school)
model <- lmer(Form, data = tutorial, REML = FALSE)

emmeans(model, pairwise~schgend+sex)$contrast

contrast                     estimate     SE  df z.ratio p.value
mixedsch boy - boysch boy    -0.17986 0.0991 Inf -1.814  0.4565
mixedsch boy - girlsch boy   -0.17482 0.0788 Inf -2.219  0.2287   <--This
coef. equals
mixedsch boy - mixedsch girl -0.16826 0.0338 Inf -4.975  <.0001
mixedsch boy - boysch girl   -0.34813 0.1096 Inf -3.178  0.0186
mixedsch boy - girlsch girl  -0.34308 0.0780 Inf -4.396  0.0002
boysch boy - girlsch boy      0.00505 0.1110 Inf  0.045  1.0000
boysch boy - mixedsch girl    0.01160 0.0997 Inf  0.116  1.0000
boysch boy - boysch girl     -0.16826 0.0338 Inf -4.975  <.0001
boysch boy - girlsch girl    -0.16322 0.1058 Inf -1.543  0.6361
girlsch boy - mixedsch girl   0.00656 0.0928 Inf  0.071  1.0000
girlsch boy - boysch girl    -0.17331 0.1255 Inf -1.381  0.7388
girlsch boy - girlsch girl   -0.16826 0.0338 Inf -4.975  <.0001
mixedsch girl - boysch girl  -0.17986 0.0991 Inf -1.814  0.4565
mixedsch girl - girlsch girl -0.17482 0.0788 Inf -2.219  0.2287   <--This
coef.
boysch girl - girlsch girl    0.00505 0.1110 Inf  0.045  1.0000

On Sun, Sep 26, 2021 at 1:03 PM Simon Harmel <sim.harmel at gmail.com> wrote:
>
> Dear Russell,
>
> Thanks for sharing your perspective. First, I'm seeking an answer to
> the following question:
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html .
>
> Second, the model is from p.80 (section 6.1) of the following manual:
>
http://www.bristol.ac.uk/cmm/media/software/mlwin/downloads/manuals/3-05/manual-web.pdf
>
> Third, you can replicate (or apply 'emmeans' to) the model using the
following:
>
> library(R2MLwiN) # just for the dataset
> library(lmer)
> data("tutorial")
>
> Form <- normexam ~ 1 + standlrt + schgend + sex + (standlrt | school)
> model <- lmer(Form, data = tutorial, REML = FALSE)  # ML to match the
> manual's results
> round(coef(summary(model )),3)
>
> On Sun, Sep 26, 2021 at 12:40 PM Lenth, Russell V
> <russell-lenth at uiowa.edu> wrote:
> >
> > It kind of bugs me to see people get unduly fixated on interpreting
regression coefficients. To me, it is like driving a car down the highway
while intently focused on the instrument panel instead of where we are
going. Let's see -- the tachometer looks OK and we're just slightly above
the speed limit -- but did you notice that you are passing a truck and
you're entering a construction zone?
> >
> > Speaking of construction... for starters, the model is problematic. I
can't imagine that those two factors don't interact; yet the model doesn't
include interaction. Is that because the coefficients would be even harder
to interpret? Because they will be.
> >
> > I suggest looking instead at what the (improved) model predicts. That
may be done via an expression like
> >
> >     new <- expand.grid(sex = c('boys', 'girls', schgender =
c('boy-only', 'girl-only', 'mixed')
> >
> > which constructs a data frame with all combinations of the factors.
Then use 'predict(model, newdata = new)` and you will see what the model
predicts for all those combinations. It does not require much expertise or
experience to interpret those. Moreover, they can be plotted so you can
visualize the factor effects and their joint effects.
> >
> > Or (forgive me for self-promotion) you could use a package like
`emmeans', or 'effects' or 'ggeffects' to facilitate this kind of
exploration.
> >
> > Just my 2 cents worth.
> >
> > Russ Lenth
> >
> > -----Original Message-----
> >
> > Date: Sun, 26 Sep 2021 09:39:25 +0300
> > From: Juho Kristian Ruohonen <juho.kristian.ruohonen at gmail.com>
> > To: Simon Harmel <sim.harmel at gmail.com>
> > Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
> > Subject: Re: [R-sig-ME] Help with interpreting one fixed-effect
> >         coefficient
> > Message-ID:
> >         <CAG_dBVep4WSVRaOwRkZLKF8zrVBZMZ-_4X=_
X63sJw9C1ZEKfw at mail.gmail.com>
> > Content-Type: text/plain; charset="utf-8"
> >
> > In my view, your logic is slightly oversimplified (i.e. incorrect).
> > Regression models do not estimate coefficients by holding predictors
> > constant exclusively at the reference category. They do something more
> > general, namely estimate coefficients by holding predictors constant at
any
> > value at which variation is observed in the values of the other
predictors.
> >
> > su 26. syysk. 2021 klo 9.03 Simon Harmel (sim.harmel at gmail.com)
kirjoitti:
> >
> > > Dear Juho and other List Members,
> > >
> > > My problem is the logic of interpretation. Assuming no interaction, a
> > > categorical-predictors-only model, and aside from the intercept which
> > > captures the mean for reference categories (in this case, boys in the
> > > mixed schools), I have learned to interpret any main effect coef for a
> > > categorical predictor by thinking of that coef. as something that can
> > > differ from its reference category to affect "y" ***holding any other
> > > categorical predictor in the model at its reference category***.
> > >
> > > By this logic, "schgendboy-only" main effect coef should mean diff.
> > > bet. boys (held constant at the reference category) in boy-only vs.
> > > mixed schools (which shows "schgendboy-only" can differ from its
> > > reference category i.e, mixed schools).
> > >
> > > By this logic, "sexgirls" main effect coef should mean diff. bet.
> > > girls vs. boys (which shows "sexgirls" can differ from its reference
> > > category i.e, boys) in mixed schools (held constant at the reference
> > > category).
> > >
> > > Therefore, by this logic, "schgendgirl-only" main effect coef should
> > > mean diff. bet. boys (held constant at the reference category) in
> > > girl-only vs. mixed schools (which shows "schgendgirl-only" can differ
> > > from its reference category i.e, mixed schools).
> > >
> > > My question is that is my logic of interpretation incorrect? Or are
> > > there exceptions to my logic of interpretation of which interpreting
> > > "schgendgirl-only" coef is one?
> > >
> > > Thank you very much,
> > > Simon
> > >
> > > On Sun, Sep 26, 2021 at 12:00 AM Juho Kristian Ruohonen
> > > <juho.kristian.ruohonen at gmail.com> wrote:
> > > >
> > > > Fellow student commenting here...
> > > >
> > > > As you suggest, schgendgirl-only can only ever apply to female
students.
> > > Strictly speaking, it's the estimated mean difference between a
student of
> > > any sex in a girls-only school and a similar student in a mixed
school. But
> > > since such comparisons are only observed between girls, the estimate
is
> > > necessarily informed by girl data only. So your intended
interpretation of
> > > the coefficient is correct.
> > > >
> > > >
> > > > su 26. syysk. 2021 klo 0.27 Simon Harmel (sim.harmel at gmail.com)
> > > kirjoitti:
> > > >>
> > > >> Dear Colleagues,
> > > >>
> > > >> Apologies for crossposting (
> > > https://stats.stackexchange.com/q/545975/284623).
> > > >>
> > > >> I've two categorical moderators i.e., students' ***sex*** (`boys`,
> > > >> `girls`) and the ***school-gender system*** (`boy-only`,
`girl-only`,
> > > >> `mixed`) in a model like: `y ~ sex + schoolgend`.
> > > >>
> > > >> My coefs are below. I can interpret three of the coefs but wonder
how
> > > >> to interpret the third one from the top (.175)?
> > > >>
> > > >> Assume "intrcpt" represents the boys' mean in mixed schools.
> > > >>
> > > >>                          Estimate
> > > >> (Intercept)             -0.189
> > > >> schgendboy-only   0.180
> > > >> schgendgirl-only    0.175
> > > >> sexgirls                  0.168
> > > >>
> > > >> My interpretations of the coefficients are as follows:
> > > >>
> > > >>             "(Intercept)": mean of y for boys in mixed schools =
-.189
> > > >>  "schgendboy-only": diff. bet. boys in boy-only vs. mixed schools =
> > > +.180
> > > >>   "schgendgirl-only": diff. bet. ???????????????????????????? =
+.175
> > > >>                 "sexgirls": diff. bet. girls vs. boys in mixed
schools
> > > = +.168
> > > >>
> > > >> If my interpretation logic for all other coefs is correct, then,
this
> > > >> third coef. must mean:
> > > >>
> > > >> diff. bet. boys in girl-only vs. mixed schools = +.175! (which
makes no
> > > sense!)
> > > >>
> > > >> ps. I know I will end-up interpreting +1.75 as: diff. bet. girls in
> > > >> girl-only vs. mixed schools BUT this doesn't follow the
interpretation
> > > >> logic for other coefs PLUS there are no labels in the output to
show
> > > >> what's what!
> > > >>
> > > >> Many thanks,
> > > >> Simon
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Mon Sep 27 02:19:07 2021
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Sun, 26 Sep 2021 20:19:07 -0400
Subject: [R-sig-ME] Help with interpreting one fixed-effect coefficient
In-Reply-To: <CACgv6yUjfyZ-GJWqsDVZpikemCUGWKNVNTGh_Jp1Jswrm58AvA@mail.gmail.com>
References: <DM6PR04MB4474B04E915E92DBB28EDB83F1A69@DM6PR04MB4474.namprd04.prod.outlook.com>
 <531_1632679437_18QI3un4014412_CACgv6yUZH9a_N63S28vAjq+bwvu5ECv-GnBKuXei-xcuXv9+1w@mail.gmail.com>
 <97ba750e-665a-a697-d569-21e60299510f@mcmaster.ca>
 <CACgv6yUjfyZ-GJWqsDVZpikemCUGWKNVNTGh_Jp1Jswrm58AvA@mail.gmail.com>
Message-ID: <e47551d0-d39e-705b-6456-52e2367e7193@mcmaster.ca>

Dear Simon,

First, thank you for the kind remark.

vignette("methods-supported-by-effects", package="effects") explains how 
to make the functions in the effects package work with model objects of 
different classes, assuming that the objects contain the necessary 
information. I took a quick look at metafor::rma.mv() and don't think 
that the object that it turns includes a model formula, which is 
necessary for constructing effect plots.

I'm cc'ing this response to the R-sig-ME list. Keeping the discussion on 
the list makes it available to people who may be potentially interested 
in it, either now or in the future.

Best,
  John

On 2021-09-26 4:27 p.m., Simon Harmel wrote:
> Dear John,
> 
> Thanks! I have used your great package for years, it's just wonderful! 
> (I wish it worked with metafor::rma.mv <http://rma.mv/>(), though!)
> 
> Simon
> 
> On Sun, Sep 26, 2021 at 3:04 PM John Fox <jfox at mcmaster.ca 
> <mailto:jfox at mcmaster.ca>> wrote:
> 
>     Dear Simon,
> 
>     On 2021-09-26 2:03 p.m., Simon Harmel wrote:
>      > Dear Russell,
>      >
>      > Thanks for sharing your perspective. First, I'm seeking an answer to
>      > the following question:
>      >
>     https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html
>     <https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html> .
>      >
>      > Second, the model is from p.80 (section 6.1) of the following manual:
>      >
>     http://www.bristol.ac.uk/cmm/media/software/mlwin/downloads/manuals/3-05/manual-web.pdf
>     <http://www.bristol.ac.uk/cmm/media/software/mlwin/downloads/manuals/3-05/manual-web.pdf>
>      >
>      > Third, you can replicate (or apply 'emmeans' to) the model using
>     the following:
>      >
>      > library(R2MLwiN) # just for the dataset
>      > library(lmer)
>      > data("tutorial")
>      >
>      > Form <- normexam ~ 1 + standlrt + schgend + sex + (standlrt | school)
>      > model <- lmer(Form, data = tutorial, REML = FALSE)? # ML to match the
>      > manual's results
>      > round(coef(summary(model )),3)
> 
>     For example, try the following (using effects, but you could get
>     something similar from emmeans):
> 
>     library("lme4") # NB: lme4, not lmer
>     data("tutorial", package="R2MLwiN")
> 
>     Form <- normexam ~ 1 + standlrt + schgend + sex + (standlrt | school)
>     model <- lmer(Form, data = tutorial, REML = FALSE)
> 
>     library("effects")
>     plot(predictorEffects(model))
> 
>     (Russell: The same-sex schools have students of only one one gender, so
>     what's meant by an interaction between sex and schgend would have to be
>     thought out a bit more -- maybe just ravel to four categories or
>     redefine school gender as coed or same.)
> 
>     I hope this helps,
>      ? John
> 
>     -- 
>     John Fox, Professor Emeritus
>     McMaster University
>     Hamilton, Ontario, Canada
>     web: https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>
> 
>      >
>      > On Sun, Sep 26, 2021 at 12:40 PM Lenth, Russell V
>      > <russell-lenth at uiowa.edu <mailto:russell-lenth at uiowa.edu>> wrote:
>      >>
>      >> It kind of bugs me to see people get unduly fixated on
>     interpreting regression coefficients. To me, it is like driving a
>     car down the highway while intently focused on the instrument panel
>     instead of where we are going. Let's see -- the tachometer looks OK
>     and we're just slightly above the speed limit -- but did you notice
>     that you are passing a truck and you're entering a construction zone?
>      >>
>      >> Speaking of construction... for starters, the model is
>     problematic. I can't imagine that those two factors don't interact;
>     yet the model doesn't include interaction. Is that because the
>     coefficients would be even harder to interpret? Because they will be.
>      >>
>      >> I suggest looking instead at what the (improved) model predicts.
>     That may be done via an expression like
>      >>
>      >>? ? ? new <- expand.grid(sex = c('boys', 'girls', schgender =
>     c('boy-only', 'girl-only', 'mixed')
>      >>
>      >> which constructs a data frame with all combinations of the
>     factors. Then use 'predict(model, newdata = new)` and you will see
>     what the model predicts for all those combinations. It does not
>     require much expertise or experience to interpret those. Moreover,
>     they can be plotted so you can visualize the factor effects and
>     their joint effects.
>      >>
>      >> Or (forgive me for self-promotion) you could use a package like
>     `emmeans', or 'effects' or 'ggeffects' to facilitate this kind of
>     exploration.
>      >>
>      >> Just my 2 cents worth.
>      >>
>      >> Russ Lenth
>      >>
>      >> -----Original Message-----
>      >>
>      >> Date: Sun, 26 Sep 2021 09:39:25 +0300
>      >> From: Juho Kristian Ruohonen <juho.kristian.ruohonen at gmail.com
>     <mailto:juho.kristian.ruohonen at gmail.com>>
>      >> To: Simon Harmel <sim.harmel at gmail.com
>     <mailto:sim.harmel at gmail.com>>
>      >> Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>>
>      >> Subject: Re: [R-sig-ME] Help with interpreting one fixed-effect
>      >>? ? ? ? ? coefficient
>      >> Message-ID:
>      >>         
>     <CAG_dBVep4WSVRaOwRkZLKF8zrVBZMZ-_4X=_X63sJw9C1ZEKfw at mail.gmail.com
>     <mailto:X63sJw9C1ZEKfw at mail.gmail.com>>
>      >> Content-Type: text/plain; charset="utf-8"
>      >>
>      >> In my view, your logic is slightly oversimplified (i.e. incorrect).
>      >> Regression models do not estimate coefficients by holding predictors
>      >> constant exclusively at the reference category. They do
>     something more
>      >> general, namely estimate coefficients by holding predictors
>     constant at any
>      >> value at which variation is observed in the values of the other
>     predictors.
>      >>
>      >> su 26. syysk. 2021 klo 9.03 Simon Harmel (sim.harmel at gmail.com
>     <mailto:sim.harmel at gmail.com>) kirjoitti:
>      >>
>      >>> Dear Juho and other List Members,
>      >>>
>      >>> My problem is the logic of interpretation. Assuming no
>     interaction, a
>      >>> categorical-predictors-only model, and aside from the intercept
>     which
>      >>> captures the mean for reference categories (in this case, boys
>     in the
>      >>> mixed schools), I have learned to interpret any main effect
>     coef for a
>      >>> categorical predictor by thinking of that coef. as something
>     that can
>      >>> differ from its reference category to affect "y" ***holding any
>     other
>      >>> categorical predictor in the model at its reference category***.
>      >>>
>      >>> By this logic, "schgendboy-only" main effect coef should mean diff.
>      >>> bet. boys (held constant at the reference category) in boy-only vs.
>      >>> mixed schools (which shows "schgendboy-only" can differ from its
>      >>> reference category i.e, mixed schools).
>      >>>
>      >>> By this logic, "sexgirls" main effect coef should mean diff. bet.
>      >>> girls vs. boys (which shows "sexgirls" can differ from its
>     reference
>      >>> category i.e, boys) in mixed schools (held constant at the
>     reference
>      >>> category).
>      >>>
>      >>> Therefore, by this logic, "schgendgirl-only" main effect coef
>     should
>      >>> mean diff. bet. boys (held constant at the reference category) in
>      >>> girl-only vs. mixed schools (which shows "schgendgirl-only" can
>     differ
>      >>> from its reference category i.e, mixed schools).
>      >>>
>      >>> My question is that is my logic of interpretation incorrect? Or are
>      >>> there exceptions to my logic of interpretation of which
>     interpreting
>      >>> "schgendgirl-only" coef is one?
>      >>>
>      >>> Thank you very much,
>      >>> Simon
>      >>>
>      >>> On Sun, Sep 26, 2021 at 12:00 AM Juho Kristian Ruohonen
>      >>> <juho.kristian.ruohonen at gmail.com
>     <mailto:juho.kristian.ruohonen at gmail.com>> wrote:
>      >>>>
>      >>>> Fellow student commenting here...
>      >>>>
>      >>>> As you suggest, schgendgirl-only can only ever apply to female
>     students.
>      >>> Strictly speaking, it's the estimated mean difference between a
>     student of
>      >>> any sex in a girls-only school and a similar student in a mixed
>     school. But
>      >>> since such comparisons are only observed between girls, the
>     estimate is
>      >>> necessarily informed by girl data only. So your intended
>     interpretation of
>      >>> the coefficient is correct.
>      >>>>
>      >>>>
>      >>>> su 26. syysk. 2021 klo 0.27 Simon Harmel (sim.harmel at gmail.com
>     <mailto:sim.harmel at gmail.com>)
>      >>> kirjoitti:
>      >>>>>
>      >>>>> Dear Colleagues,
>      >>>>>
>      >>>>> Apologies for crossposting (
>      >>> https://stats.stackexchange.com/q/545975/284623
>     <https://stats.stackexchange.com/q/545975/284623>).
>      >>>>>
>      >>>>> I've two categorical moderators i.e., students' ***sex***
>     (`boys`,
>      >>>>> `girls`) and the ***school-gender system*** (`boy-only`,
>     `girl-only`,
>      >>>>> `mixed`) in a model like: `y ~ sex + schoolgend`.
>      >>>>>
>      >>>>> My coefs are below. I can interpret three of the coefs but
>     wonder how
>      >>>>> to interpret the third one from the top (.175)?
>      >>>>>
>      >>>>> Assume "intrcpt" represents the boys' mean in mixed schools.
>      >>>>>
>      >>>>>? ? ? ? ? ? ? ? ? ? ? ? ? ?Estimate
>      >>>>> (Intercept)? ? ? ? ? ? ?-0.189
>      >>>>> schgendboy-only? ?0.180
>      >>>>> schgendgirl-only? ? 0.175
>      >>>>> sexgirls? ? ? ? ? ? ? ? ? 0.168
>      >>>>>
>      >>>>> My interpretations of the coefficients are as follows:
>      >>>>>
>      >>>>>? ? ? ? ? ? ? "(Intercept)": mean of y for boys in mixed
>     schools = -.189
>      >>>>>? ?"schgendboy-only": diff. bet. boys in boy-only vs. mixed
>     schools =
>      >>> +.180
>      >>>>>? ? "schgendgirl-only": diff. bet.
>     ???????????????????????????? = +.175
>      >>>>>? ? ? ? ? ? ? ? ? "sexgirls": diff. bet. girls vs. boys in
>     mixed schools
>      >>> = +.168
>      >>>>>
>      >>>>> If my interpretation logic for all other coefs is correct,
>     then, this
>      >>>>> third coef. must mean:
>      >>>>>
>      >>>>> diff. bet. boys in girl-only vs. mixed schools = +.175!
>     (which makes no
>      >>> sense!)
>      >>>>>
>      >>>>> ps. I know I will end-up interpreting +1.75 as: diff. bet.
>     girls in
>      >>>>> girl-only vs. mixed schools BUT this doesn't follow the
>     interpretation
>      >>>>> logic for other coefs PLUS there are no labels in the output
>     to show
>      >>>>> what's what!
>      >>>>>
>      >>>>> Many thanks,
>      >>>>> Simon
>      >>
>      >> _______________________________________________
>      >> R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>      >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >
>      > _______________________________________________
>      > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >
> 
-- 
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/


From ru@@e||-|enth @end|ng |rom u|ow@@edu  Mon Sep 27 02:42:31 2021
From: ru@@e||-|enth @end|ng |rom u|ow@@edu (Lenth, Russell V)
Date: Mon, 27 Sep 2021 00:42:31 +0000
Subject: [R-sig-ME] 
 [External] Re: Help with interpreting one fixed-effect coefficient
In-Reply-To: <CACgv6yXtSHhLGVGiqr7wPWTX0wAh4U8P6KRbv_6fTMF6QnnrPQ@mail.gmail.com>
References: <DM6PR04MB4474B04E915E92DBB28EDB83F1A69@DM6PR04MB4474.namprd04.prod.outlook.com>
 <CACgv6yUZH9a_N63S28vAjq+bwvu5ECv-GnBKuXei-xcuXv9+1w@mail.gmail.com>
 <CACgv6yXtSHhLGVGiqr7wPWTX0wAh4U8P6KRbv_6fTMF6QnnrPQ@mail.gmail.com>
Message-ID: <DM6PR04MB447412A47A489873E5942DFFF1A79@DM6PR04MB4474.namprd04.prod.outlook.com>

I guess correctness is in the eyes of the beholder. But I think this illustrates the folly of the additive model. Having additive effects suggests a belief that you can vary one factor more or less independently of the other. In his comments, John Fox makes a good point that escaped my earlier cursory view of the original question, that you don't have data on girls attending all-boys' schools, nor boys attending all-girls' schools; yet the model that was fitted estimates a mean response for both those situations. That's a pretty clear testament to the failure of that model ? and also why the coefficients don't make sense. And finally why we have estimates of 15 comparisons (some of which are aliased with one another), when only 6 of them make sense.

If instead, a model with interaction were fitted, it would be a rank-deficient model because two cells are empty. Perhaps there is some sort of nesting structure that could be used to work around that. However, it doesn't matter much because emmeans assesses estimability, and the two combinations I mentioned above would be flagged as non-estimable. One could then more judiciously use the contrast function to test meaningful contrasts across this irregular array of cell means. Or even injudiciously asking for all pairwise comparisons, you will see 6 estimable ones and 9 non-estimable ones. See output below.

Russ

----- Interactive model -----

> Form <- normexam ~ 1 + standlrt + schgend * sex + (standlrt | school)
> model <- lmer(Form, data = tutorial, REML = FALSE)
fixed-effect model matrix is rank deficient so dropping 2 columns / coefficients
> 
> emmeans(model, pairwise~schgend+sex)

... messages deleted ...

$emmeans
 schgend  sex    emmean     SE  df asymp.LCL asymp.UCL
 mixedsch boy  -0.18781 0.0514 Inf   -0.2885   -0.0871
 boysch   boy  -0.00795 0.0880 Inf   -0.1805    0.1646
 girlsch  boy    nonEst     NA  NA        NA        NA
 mixedsch girl -0.01955 0.0521 Inf   -0.1216    0.0825
 boysch   girl   nonEst     NA  NA        NA        NA
 girlsch  girl  0.15527 0.0632 Inf    0.0313    0.2792

Degrees-of-freedom method: asymptotic 
Confidence level used: 0.95 

$contrasts
 contrast                     estimate     SE  df z.ratio p.value
 mixedsch boy - boysch boy     -0.1799 0.0991 Inf  -1.814  0.4565
 mixedsch boy - girlsch boy     nonEst     NA  NA      NA      NA
 mixedsch boy - mixedsch girl  -0.1683 0.0338 Inf  -4.975  <.0001
 mixedsch boy - boysch girl     nonEst     NA  NA      NA      NA
 mixedsch boy - girlsch girl   -0.3431 0.0780 Inf  -4.396  0.0002
 boysch boy - girlsch boy       nonEst     NA  NA      NA      NA
 boysch boy - mixedsch girl     0.0116 0.0997 Inf   0.116  1.0000
 boysch boy - boysch girl       nonEst     NA  NA      NA      NA
 boysch boy - girlsch girl     -0.1632 0.1058 Inf  -1.543  0.6361
 girlsch boy - mixedsch girl    nonEst     NA  NA      NA      NA
 girlsch boy - boysch girl      nonEst     NA  NA      NA      NA
 girlsch boy - girlsch girl     nonEst     NA  NA      NA      NA
 mixedsch girl - boysch girl    nonEst     NA  NA      NA      NA
 mixedsch girl - girlsch girl  -0.1748 0.0788 Inf  -2.219  0.2287
 boysch girl - girlsch girl     nonEst     NA  NA      NA      NA

Degrees-of-freedom method: asymptotic 
P value adjustment: tukey method for comparing a family of 6 estimates


---------------------------------------------------------
From: Simon Harmel <sim.harmel at gmail.com> 
Sent: Sunday, September 26, 2021 3:08 PM
To: Lenth, Russell V <russell-lenth at uiowa.edu>
Cc: r-sig-mixed-models at r-project.org
Subject: [External] Re: [R-sig-ME] Help with interpreting one fixed-effect coefficient

Dear Russ and the List Members,

If we use Russ' great package (emmeans), we see that although meaningless, but "schgendgirl-only" can be interpreted using the logic I mentioned here: https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html .

That is, "schgendgirl-only" can meaninglessly mean: ***diff. bet. boys in girl-only vs. mixed schools*** just like it can meaningfully mean:? ***diff. bet. girls in girl-only vs. mixed schools***

Russ, have I used emmeans correctly?

Simon

Here is a reproducible code:

library(R2MLwiN) # For the dataset
library(lme4)
library(emmeans)

data("tutorial")

Form <- normexam ~ 1 + standlrt + schgend + sex + (standlrt | school)
model <- lmer(Form, data = tutorial, REML = FALSE)

emmeans(model, pairwise~schgend+sex)$contrast

contrast ? ? ? ? ? ? ? ? ? ? estimate ? ? SE ?df z.ratio p.value
mixedsch boy - boysch boy ? ?-0.17986 0.0991 Inf -1.814 ?0.4565
mixedsch boy - girlsch boy ? -0.17482 0.0788 Inf -2.219 ?0.2287 ? <--This coef. equals
mixedsch boy - mixedsch girl -0.16826 0.0338 Inf -4.975 ?<.0001
mixedsch boy - boysch girl ? -0.34813 0.1096 Inf -3.178 ?0.0186
mixedsch boy - girlsch girl ?-0.34308 0.0780 Inf -4.396 ?0.0002
boysch boy - girlsch boy ? ? ?0.00505 0.1110 Inf ?0.045 ?1.0000
boysch boy - mixedsch girl ? ?0.01160 0.0997 Inf ?0.116 ?1.0000
boysch boy - boysch girl ? ? -0.16826 0.0338 Inf -4.975 ?<.0001
boysch boy - girlsch girl ? ?-0.16322 0.1058 Inf -1.543 ?0.6361
girlsch boy - mixedsch girl ? 0.00656 0.0928 Inf ?0.071 ?1.0000
girlsch boy - boysch girl ? ?-0.17331 0.1255 Inf -1.381 ?0.7388
girlsch boy - girlsch girl ? -0.16826 0.0338 Inf -4.975 ?<.0001
mixedsch girl - boysch girl ?-0.17986 0.0991 Inf -1.814 ?0.4565
mixedsch girl - girlsch girl -0.17482 0.0788 Inf -2.219 ?0.2287 ? <--This coef.
boysch girl - girlsch girl ? ?0.00505 0.1110 Inf ?0.045 ?1.0000



From ru@@e||-|enth @end|ng |rom u|ow@@edu  Mon Sep 27 03:22:23 2021
From: ru@@e||-|enth @end|ng |rom u|ow@@edu (Lenth, Russell V)
Date: Mon, 27 Sep 2021 01:22:23 +0000
Subject: [R-sig-ME] 
 [External] Re: Help with interpreting one fixed-effect coefficient
In-Reply-To: <DM6PR04MB447412A47A489873E5942DFFF1A79@DM6PR04MB4474.namprd04.prod.outlook.com>
References: <DM6PR04MB4474B04E915E92DBB28EDB83F1A69@DM6PR04MB4474.namprd04.prod.outlook.com>
 <CACgv6yUZH9a_N63S28vAjq+bwvu5ECv-GnBKuXei-xcuXv9+1w@mail.gmail.com>
 <CACgv6yXtSHhLGVGiqr7wPWTX0wAh4U8P6KRbv_6fTMF6QnnrPQ@mail.gmail.com>
 <DM6PR04MB447412A47A489873E5942DFFF1A79@DM6PR04MB4474.namprd04.prod.outlook.com>
Message-ID: <DM6PR04MB4474236A39405921364CF2B5F1A79@DM6PR04MB4474.namprd04.prod.outlook.com>

By the way, returning to the topic of interpreting coefficients, you ought to have fun with the ones from the model I just fitted:

Fixed effects:
               Estimate Std. Error t value
(Intercept)    -0.18882    0.05135  -3.677
standlrt        0.55442    0.01994  27.807
schgendboysch   0.17986    0.09915   1.814
schgendgirlsch  0.17482    0.07877   2.219
sexgirl         0.16826    0.03382   4.975

One curious thing you'll notice is that there are no coefficients for the interaction terms. Why? Because those terms were "thrown out" of the model, and so they are not shown. I think it is unwise to not show what was thrown out (e.g., lm would have shown them as NAs), because in fact what we see is but one of infinitely many possible solutions to the regression equations. This is the solution where the last two coefficients are constrained to zero. There is another equally reasonable one where the coefficients for schgendboysch and schgendgirlsch  are constrained to zero, and the two interaction effects would then be non-zero. And infinitely more where all 7 coefficients are non-zero, and there are two linear constraints among them.

Of course, since the particular estimate shown consists of all the main effects and interactions are constrained to zero, it does demonstrate that the additive model *could* have been used to obtain the same estimates and standard errors, and you can see that by comparing the results (and ignoring the invalid ones from the additive model). But it is just a lucky coincidence that it worked out this way, and the additive model did lead us down a primrose path containing silly results among the correct ones.

Russ

-----Original Message-----
From: Lenth, Russell V 
Sent: Sunday, September 26, 2021 7:43 PM
To: Simon Harmel <sim.harmel at gmail.com>
Cc: r-sig-mixed-models at r-project.org
Subject: RE: [External] Re: [R-sig-ME] Help with interpreting one fixed-effect coefficient

I guess correctness is in the eyes of the beholder. But I think this illustrates the folly of the additive model. Having additive effects suggests a belief that you can vary one factor more or less independently of the other. In his comments, John Fox makes a good point that escaped my earlier cursory view of the original question, that you don't have data on girls attending all-boys' schools, nor boys attending all-girls' schools; yet the model that was fitted estimates a mean response for both those situations. That's a pretty clear testament to the failure of that model ? and also why the coefficients don't make sense. And finally why we have estimates of 15 comparisons (some of which are aliased with one another), when only 6 of them make sense.

If instead, a model with interaction were fitted, it would be a rank-deficient model because two cells are empty. Perhaps there is some sort of nesting structure that could be used to work around that. However, it doesn't matter much because emmeans assesses estimability, and the two combinations I mentioned above would be flagged as non-estimable. One could then more judiciously use the contrast function to test meaningful contrasts across this irregular array of cell means. Or even injudiciously asking for all pairwise comparisons, you will see 6 estimable ones and 9 non-estimable ones. See output below.

Russ

----- Interactive model -----

> Form <- normexam ~ 1 + standlrt + schgend * sex + (standlrt | school)
> model <- lmer(Form, data = tutorial, REML = FALSE)
fixed-effect model matrix is rank deficient so dropping 2 columns / coefficients
> 
> emmeans(model, pairwise~schgend+sex)

... messages deleted ...

$emmeans
 schgend  sex    emmean     SE  df asymp.LCL asymp.UCL
 mixedsch boy  -0.18781 0.0514 Inf   -0.2885   -0.0871
 boysch   boy  -0.00795 0.0880 Inf   -0.1805    0.1646
 girlsch  boy    nonEst     NA  NA        NA        NA
 mixedsch girl -0.01955 0.0521 Inf   -0.1216    0.0825
 boysch   girl   nonEst     NA  NA        NA        NA
 girlsch  girl  0.15527 0.0632 Inf    0.0313    0.2792

Degrees-of-freedom method: asymptotic 
Confidence level used: 0.95 

$contrasts
 contrast                     estimate     SE  df z.ratio p.value
 mixedsch boy - boysch boy     -0.1799 0.0991 Inf  -1.814  0.4565
 mixedsch boy - girlsch boy     nonEst     NA  NA      NA      NA
 mixedsch boy - mixedsch girl  -0.1683 0.0338 Inf  -4.975  <.0001
 mixedsch boy - boysch girl     nonEst     NA  NA      NA      NA
 mixedsch boy - girlsch girl   -0.3431 0.0780 Inf  -4.396  0.0002
 boysch boy - girlsch boy       nonEst     NA  NA      NA      NA
 boysch boy - mixedsch girl     0.0116 0.0997 Inf   0.116  1.0000
 boysch boy - boysch girl       nonEst     NA  NA      NA      NA
 boysch boy - girlsch girl     -0.1632 0.1058 Inf  -1.543  0.6361
 girlsch boy - mixedsch girl    nonEst     NA  NA      NA      NA
 girlsch boy - boysch girl      nonEst     NA  NA      NA      NA
 girlsch boy - girlsch girl     nonEst     NA  NA      NA      NA
 mixedsch girl - boysch girl    nonEst     NA  NA      NA      NA
 mixedsch girl - girlsch girl  -0.1748 0.0788 Inf  -2.219  0.2287
 boysch girl - girlsch girl     nonEst     NA  NA      NA      NA

Degrees-of-freedom method: asymptotic 
P value adjustment: tukey method for comparing a family of 6 estimates


---------------------------------------------------------
From: Simon Harmel <sim.harmel at gmail.com> 
Sent: Sunday, September 26, 2021 3:08 PM
To: Lenth, Russell V <russell-lenth at uiowa.edu>
Cc: r-sig-mixed-models at r-project.org
Subject: [External] Re: [R-sig-ME] Help with interpreting one fixed-effect coefficient

Dear Russ and the List Members,

If we use Russ' great package (emmeans), we see that although meaningless, but "schgendgirl-only" can be interpreted using the logic I mentioned here: https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html .

That is, "schgendgirl-only" can meaninglessly mean: ***diff. bet. boys in girl-only vs. mixed schools*** just like it can meaningfully mean:? ***diff. bet. girls in girl-only vs. mixed schools***

Russ, have I used emmeans correctly?

Simon

Here is a reproducible code:

library(R2MLwiN) # For the dataset
library(lme4)
library(emmeans)

data("tutorial")

Form <- normexam ~ 1 + standlrt + schgend + sex + (standlrt | school)
model <- lmer(Form, data = tutorial, REML = FALSE)

emmeans(model, pairwise~schgend+sex)$contrast

contrast ? ? ? ? ? ? ? ? ? ? estimate ? ? SE ?df z.ratio p.value
mixedsch boy - boysch boy ? ?-0.17986 0.0991 Inf -1.814 ?0.4565
mixedsch boy - girlsch boy ? -0.17482 0.0788 Inf -2.219 ?0.2287 ? <--This coef. equals
mixedsch boy - mixedsch girl -0.16826 0.0338 Inf -4.975 ?<.0001
mixedsch boy - boysch girl ? -0.34813 0.1096 Inf -3.178 ?0.0186
mixedsch boy - girlsch girl ?-0.34308 0.0780 Inf -4.396 ?0.0002
boysch boy - girlsch boy ? ? ?0.00505 0.1110 Inf ?0.045 ?1.0000
boysch boy - mixedsch girl ? ?0.01160 0.0997 Inf ?0.116 ?1.0000
boysch boy - boysch girl ? ? -0.16826 0.0338 Inf -4.975 ?<.0001
boysch boy - girlsch girl ? ?-0.16322 0.1058 Inf -1.543 ?0.6361
girlsch boy - mixedsch girl ? 0.00656 0.0928 Inf ?0.071 ?1.0000
girlsch boy - boysch girl ? ?-0.17331 0.1255 Inf -1.381 ?0.7388
girlsch boy - girlsch girl ? -0.16826 0.0338 Inf -4.975 ?<.0001
mixedsch girl - boysch girl ?-0.17986 0.0991 Inf -1.814 ?0.4565
mixedsch girl - girlsch girl -0.17482 0.0788 Inf -2.219 ?0.2287 ? <--This coef.
boysch girl - girlsch girl ? ?0.00505 0.1110 Inf ?0.045 ?1.0000



From @|m@h@rme| @end|ng |rom gm@||@com  Mon Sep 27 18:09:54 2021
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Mon, 27 Sep 2021 11:09:54 -0500
Subject: [R-sig-ME] 
 [External] Re: Help with interpreting one fixed-effect coefficient
In-Reply-To: <DM6PR04MB4474236A39405921364CF2B5F1A79@DM6PR04MB4474.namprd04.prod.outlook.com>
References: <DM6PR04MB4474B04E915E92DBB28EDB83F1A69@DM6PR04MB4474.namprd04.prod.outlook.com>
 <CACgv6yUZH9a_N63S28vAjq+bwvu5ECv-GnBKuXei-xcuXv9+1w@mail.gmail.com>
 <CACgv6yXtSHhLGVGiqr7wPWTX0wAh4U8P6KRbv_6fTMF6QnnrPQ@mail.gmail.com>
 <DM6PR04MB447412A47A489873E5942DFFF1A79@DM6PR04MB4474.namprd04.prod.outlook.com>
 <DM6PR04MB4474236A39405921364CF2B5F1A79@DM6PR04MB4474.namprd04.prod.outlook.com>
Message-ID: <CACgv6yVEGaJaQ1Y0=xCbPD2aAVoc6_0LypvwgdHKxfKO9Tfuvg@mail.gmail.com>

Thanks, Russ! There is one thing that I still don't understand. We
have two completely empty cells (boys in girl-only & girls in boy-only
schools). Then, how are the means of those empty cells computed (what
data is used in their place in the additive model)?

Let's' simplify the model for clarity:

library(R2MLwiN)
library(emmeans)

Form3 <- normexam ~ schgend + sex ## + standlrt + (standlrt | school)
model3 <- lm(Form3, data = tutorial)

emmeans(model3, pairwise~sex+schgend)$emmeans

 sex  schgend   emmean     SE   df lower.CL upper.CL
 boy  mixedsch -0.2160 0.0297 4055  -0.2742 -0.15780
 girl mixedsch  0.0248 0.0304 4055  -0.0348  0.08437
 boy  boysch    0.0234 0.0437 4055  -0.0623  0.10897
 girl boysch    0.2641 0.0609 4055   0.1447  0.38360<-how computed?
 boy  girlsch  -0.0948 0.0502 4055  -0.1931  0.00358<-how computed?
 girl girlsch   0.1460 0.0267 4055   0.0938  0.19829





On Sun, Sep 26, 2021 at 8:22 PM Lenth, Russell V
<russell-lenth at uiowa.edu> wrote:
>
> By the way, returning to the topic of interpreting coefficients, you ought to have fun with the ones from the model I just fitted:
>
> Fixed effects:
>                Estimate Std. Error t value
> (Intercept)    -0.18882    0.05135  -3.677
> standlrt        0.55442    0.01994  27.807
> schgendboysch   0.17986    0.09915   1.814
> schgendgirlsch  0.17482    0.07877   2.219
> sexgirl         0.16826    0.03382   4.975
>
> One curious thing you'll notice is that there are no coefficients for the interaction terms. Why? Because those terms were "thrown out" of the model, and so they are not shown. I think it is unwise to not show what was thrown out (e.g., lm would have shown them as NAs), because in fact what we see is but one of infinitely many possible solutions to the regression equations. This is the solution where the last two coefficients are constrained to zero. There is another equally reasonable one where the coefficients for schgendboysch and schgendgirlsch  are constrained to zero, and the two interaction effects would then be non-zero. And infinitely more where all 7 coefficients are non-zero, and there are two linear constraints among them.
>
> Of course, since the particular estimate shown consists of all the main effects and interactions are constrained to zero, it does demonstrate that the additive model *could* have been used to obtain the same estimates and standard errors, and you can see that by comparing the results (and ignoring the invalid ones from the additive model). But it is just a lucky coincidence that it worked out this way, and the additive model did lead us down a primrose path containing silly results among the correct ones.
>
> Russ
>
> -----Original Message-----
> From: Lenth, Russell V
> Sent: Sunday, September 26, 2021 7:43 PM
> To: Simon Harmel <sim.harmel at gmail.com>
> Cc: r-sig-mixed-models at r-project.org
> Subject: RE: [External] Re: [R-sig-ME] Help with interpreting one fixed-effect coefficient
>
> I guess correctness is in the eyes of the beholder. But I think this illustrates the folly of the additive model. Having additive effects suggests a belief that you can vary one factor more or less independently of the other. In his comments, John Fox makes a good point that escaped my earlier cursory view of the original question, that you don't have data on girls attending all-boys' schools, nor boys attending all-girls' schools; yet the model that was fitted estimates a mean response for both those situations. That's a pretty clear testament to the failure of that model ? and also why the coefficients don't make sense. And finally why we have estimates of 15 comparisons (some of which are aliased with one another), when only 6 of them make sense.
>
> If instead, a model with interaction were fitted, it would be a rank-deficient model because two cells are empty. Perhaps there is some sort of nesting structure that could be used to work around that. However, it doesn't matter much because emmeans assesses estimability, and the two combinations I mentioned above would be flagged as non-estimable. One could then more judiciously use the contrast function to test meaningful contrasts across this irregular array of cell means. Or even injudiciously asking for all pairwise comparisons, you will see 6 estimable ones and 9 non-estimable ones. See output below.
>
> Russ
>
> ----- Interactive model -----
>
> > Form <- normexam ~ 1 + standlrt + schgend * sex + (standlrt | school)
> > model <- lmer(Form, data = tutorial, REML = FALSE)
> fixed-effect model matrix is rank deficient so dropping 2 columns / coefficients
> >
> > emmeans(model, pairwise~schgend+sex)
>
> ... messages deleted ...
>
> $emmeans
>  schgend  sex    emmean     SE  df asymp.LCL asymp.UCL
>  mixedsch boy  -0.18781 0.0514 Inf   -0.2885   -0.0871
>  boysch   boy  -0.00795 0.0880 Inf   -0.1805    0.1646
>  girlsch  boy    nonEst     NA  NA        NA        NA
>  mixedsch girl -0.01955 0.0521 Inf   -0.1216    0.0825
>  boysch   girl   nonEst     NA  NA        NA        NA
>  girlsch  girl  0.15527 0.0632 Inf    0.0313    0.2792
>
> Degrees-of-freedom method: asymptotic
> Confidence level used: 0.95
>
> $contrasts
>  contrast                     estimate     SE  df z.ratio p.value
>  mixedsch boy - boysch boy     -0.1799 0.0991 Inf  -1.814  0.4565
>  mixedsch boy - girlsch boy     nonEst     NA  NA      NA      NA
>  mixedsch boy - mixedsch girl  -0.1683 0.0338 Inf  -4.975  <.0001
>  mixedsch boy - boysch girl     nonEst     NA  NA      NA      NA
>  mixedsch boy - girlsch girl   -0.3431 0.0780 Inf  -4.396  0.0002
>  boysch boy - girlsch boy       nonEst     NA  NA      NA      NA
>  boysch boy - mixedsch girl     0.0116 0.0997 Inf   0.116  1.0000
>  boysch boy - boysch girl       nonEst     NA  NA      NA      NA
>  boysch boy - girlsch girl     -0.1632 0.1058 Inf  -1.543  0.6361
>  girlsch boy - mixedsch girl    nonEst     NA  NA      NA      NA
>  girlsch boy - boysch girl      nonEst     NA  NA      NA      NA
>  girlsch boy - girlsch girl     nonEst     NA  NA      NA      NA
>  mixedsch girl - boysch girl    nonEst     NA  NA      NA      NA
>  mixedsch girl - girlsch girl  -0.1748 0.0788 Inf  -2.219  0.2287
>  boysch girl - girlsch girl     nonEst     NA  NA      NA      NA
>
> Degrees-of-freedom method: asymptotic
> P value adjustment: tukey method for comparing a family of 6 estimates
>
>
> ---------------------------------------------------------
> From: Simon Harmel <sim.harmel at gmail.com>
> Sent: Sunday, September 26, 2021 3:08 PM
> To: Lenth, Russell V <russell-lenth at uiowa.edu>
> Cc: r-sig-mixed-models at r-project.org
> Subject: [External] Re: [R-sig-ME] Help with interpreting one fixed-effect coefficient
>
> Dear Russ and the List Members,
>
> If we use Russ' great package (emmeans), we see that although meaningless, but "schgendgirl-only" can be interpreted using the logic I mentioned here: https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html .
>
> That is, "schgendgirl-only" can meaninglessly mean: ***diff. bet. boys in girl-only vs. mixed schools*** just like it can meaningfully mean:  ***diff. bet. girls in girl-only vs. mixed schools***
>
> Russ, have I used emmeans correctly?
>
> Simon
>
> Here is a reproducible code:
>
> library(R2MLwiN) # For the dataset
> library(lme4)
> library(emmeans)
>
> data("tutorial")
>
> Form <- normexam ~ 1 + standlrt + schgend + sex + (standlrt | school)
> model <- lmer(Form, data = tutorial, REML = FALSE)
>
> emmeans(model, pairwise~schgend+sex)$contrast
>
> contrast                     estimate     SE  df z.ratio p.value
> mixedsch boy - boysch boy    -0.17986 0.0991 Inf -1.814  0.4565
> mixedsch boy - girlsch boy   -0.17482 0.0788 Inf -2.219  0.2287   <--This coef. equals
> mixedsch boy - mixedsch girl -0.16826 0.0338 Inf -4.975  <.0001
> mixedsch boy - boysch girl   -0.34813 0.1096 Inf -3.178  0.0186
> mixedsch boy - girlsch girl  -0.34308 0.0780 Inf -4.396  0.0002
> boysch boy - girlsch boy      0.00505 0.1110 Inf  0.045  1.0000
> boysch boy - mixedsch girl    0.01160 0.0997 Inf  0.116  1.0000
> boysch boy - boysch girl     -0.16826 0.0338 Inf -4.975  <.0001
> boysch boy - girlsch girl    -0.16322 0.1058 Inf -1.543  0.6361
> girlsch boy - mixedsch girl   0.00656 0.0928 Inf  0.071  1.0000
> girlsch boy - boysch girl    -0.17331 0.1255 Inf -1.381  0.7388
> girlsch boy - girlsch girl   -0.16826 0.0338 Inf -4.975  <.0001
> mixedsch girl - boysch girl  -0.17986 0.0991 Inf -1.814  0.4565
> mixedsch girl - girlsch girl -0.17482 0.0788 Inf -2.219  0.2287   <--This coef.
> boysch girl - girlsch girl    0.00505 0.1110 Inf  0.045  1.0000
>
>


From ru@@e||-|enth @end|ng |rom u|ow@@edu  Mon Sep 27 18:13:59 2021
From: ru@@e||-|enth @end|ng |rom u|ow@@edu (Lenth, Russell V)
Date: Mon, 27 Sep 2021 16:13:59 +0000
Subject: [R-sig-ME] Help with interpreting one fixed-effect coefficient
Message-ID: <DM6PR04MB4474DE9CADDA68F6F0ED8B0BF1A79@DM6PR04MB4474.namprd04.prod.outlook.com>

Look at the model I fitted, which INCLUDES the interaction, and notice that those combinations are NOT estimated.

Russ

-----Original Message-----
From: Simon Harmel <sim.harmel at gmail.com> 
Sent: Monday, September 27, 2021 11:10 AM
To: Lenth, Russell V <russell-lenth at uiowa.edu>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [External] Re: [R-sig-ME] Help with interpreting one fixed-effect coefficient

Thanks, Russ! There is one thing that I still don't understand. We
have two completely empty cells (boys in girl-only & girls in boy-only
schools). Then, how are the means of those empty cells computed (what
data is used in their place in the additive model)?

Let's' simplify the model for clarity:

library(R2MLwiN)
library(emmeans)

Form3 <- normexam ~ schgend + sex ## + standlrt + (standlrt | school)
model3 <- lm(Form3, data = tutorial)

emmeans(model3, pairwise~sex+schgend)$emmeans

 sex  schgend   emmean     SE   df lower.CL upper.CL
 boy  mixedsch -0.2160 0.0297 4055  -0.2742 -0.15780
 girl mixedsch  0.0248 0.0304 4055  -0.0348  0.08437
 boy  boysch    0.0234 0.0437 4055  -0.0623  0.10897
 girl boysch    0.2641 0.0609 4055   0.1447  0.38360<-how computed?
 boy  girlsch  -0.0948 0.0502 4055  -0.1931  0.00358<-how computed?
 girl girlsch   0.1460 0.0267 4055   0.0938  0.19829





On Sun, Sep 26, 2021 at 8:22 PM Lenth, Russell V
<russell-lenth at uiowa.edu> wrote:
>
> By the way, returning to the topic of interpreting coefficients, you ought to have fun with the ones from the model I just fitted:
>
> Fixed effects:
>                Estimate Std. Error t value
> (Intercept)    -0.18882    0.05135  -3.677
> standlrt        0.55442    0.01994  27.807
> schgendboysch   0.17986    0.09915   1.814
> schgendgirlsch  0.17482    0.07877   2.219
> sexgirl         0.16826    0.03382   4.975
>
> One curious thing you'll notice is that there are no coefficients for the interaction terms. Why? Because those terms were "thrown out" of the model, and so they are not shown. I think it is unwise to not show what was thrown out (e.g., lm would have shown them as NAs), because in fact what we see is but one of infinitely many possible solutions to the regression equations. This is the solution where the last two coefficients are constrained to zero. There is another equally reasonable one where the coefficients for schgendboysch and schgendgirlsch  are constrained to zero, and the two interaction effects would then be non-zero. And infinitely more where all 7 coefficients are non-zero, and there are two linear constraints among them.
>
> Of course, since the particular estimate shown consists of all the main effects and interactions are constrained to zero, it does demonstrate that the additive model *could* have been used to obtain the same estimates and standard errors, and you can see that by comparing the results (and ignoring the invalid ones from the additive model). But it is just a lucky coincidence that it worked out this way, and the additive model did lead us down a primrose path containing silly results among the correct ones.
>
> Russ
>
> -----Original Message-----
> From: Lenth, Russell V
> Sent: Sunday, September 26, 2021 7:43 PM
> To: Simon Harmel <sim.harmel at gmail.com>
> Cc: r-sig-mixed-models at r-project.org
> Subject: RE: [External] Re: [R-sig-ME] Help with interpreting one fixed-effect coefficient
>
> I guess correctness is in the eyes of the beholder. But I think this illustrates the folly of the additive model. Having additive effects suggests a belief that you can vary one factor more or less independently of the other. In his comments, John Fox makes a good point that escaped my earlier cursory view of the original question, that you don't have data on girls attending all-boys' schools, nor boys attending all-girls' schools; yet the model that was fitted estimates a mean response for both those situations. That's a pretty clear testament to the failure of that model ? and also why the coefficients don't make sense. And finally why we have estimates of 15 comparisons (some of which are aliased with one another), when only 6 of them make sense.
>
> If instead, a model with interaction were fitted, it would be a rank-deficient model because two cells are empty. Perhaps there is some sort of nesting structure that could be used to work around that. However, it doesn't matter much because emmeans assesses estimability, and the two combinations I mentioned above would be flagged as non-estimable. One could then more judiciously use the contrast function to test meaningful contrasts across this irregular array of cell means. Or even injudiciously asking for all pairwise comparisons, you will see 6 estimable ones and 9 non-estimable ones. See output below.
>
> Russ
>
> ----- Interactive model -----
>
> > Form <- normexam ~ 1 + standlrt + schgend * sex + (standlrt | school)
> > model <- lmer(Form, data = tutorial, REML = FALSE)
> fixed-effect model matrix is rank deficient so dropping 2 columns / coefficients
> >
> > emmeans(model, pairwise~schgend+sex)
>
> ... messages deleted ...
>
> $emmeans
>  schgend  sex    emmean     SE  df asymp.LCL asymp.UCL
>  mixedsch boy  -0.18781 0.0514 Inf   -0.2885   -0.0871
>  boysch   boy  -0.00795 0.0880 Inf   -0.1805    0.1646
>  girlsch  boy    nonEst     NA  NA        NA        NA
>  mixedsch girl -0.01955 0.0521 Inf   -0.1216    0.0825
>  boysch   girl   nonEst     NA  NA        NA        NA
>  girlsch  girl  0.15527 0.0632 Inf    0.0313    0.2792
>
> Degrees-of-freedom method: asymptotic
> Confidence level used: 0.95
>
> $contrasts
>  contrast                     estimate     SE  df z.ratio p.value
>  mixedsch boy - boysch boy     -0.1799 0.0991 Inf  -1.814  0.4565
>  mixedsch boy - girlsch boy     nonEst     NA  NA      NA      NA
>  mixedsch boy - mixedsch girl  -0.1683 0.0338 Inf  -4.975  <.0001
>  mixedsch boy - boysch girl     nonEst     NA  NA      NA      NA
>  mixedsch boy - girlsch girl   -0.3431 0.0780 Inf  -4.396  0.0002
>  boysch boy - girlsch boy       nonEst     NA  NA      NA      NA
>  boysch boy - mixedsch girl     0.0116 0.0997 Inf   0.116  1.0000
>  boysch boy - boysch girl       nonEst     NA  NA      NA      NA
>  boysch boy - girlsch girl     -0.1632 0.1058 Inf  -1.543  0.6361
>  girlsch boy - mixedsch girl    nonEst     NA  NA      NA      NA
>  girlsch boy - boysch girl      nonEst     NA  NA      NA      NA
>  girlsch boy - girlsch girl     nonEst     NA  NA      NA      NA
>  mixedsch girl - boysch girl    nonEst     NA  NA      NA      NA
>  mixedsch girl - girlsch girl  -0.1748 0.0788 Inf  -2.219  0.2287
>  boysch girl - girlsch girl     nonEst     NA  NA      NA      NA
>
> Degrees-of-freedom method: asymptotic
> P value adjustment: tukey method for comparing a family of 6 estimates
>
>
> ---------------------------------------------------------
> From: Simon Harmel <sim.harmel at gmail.com>
> Sent: Sunday, September 26, 2021 3:08 PM
> To: Lenth, Russell V <russell-lenth at uiowa.edu>
> Cc: r-sig-mixed-models at r-project.org
> Subject: [External] Re: [R-sig-ME] Help with interpreting one fixed-effect coefficient
>
> Dear Russ and the List Members,
>
> If we use Russ' great package (emmeans), we see that although meaningless, but "schgendgirl-only" can be interpreted using the logic I mentioned here: https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html .
>
> That is, "schgendgirl-only" can meaninglessly mean: ***diff. bet. boys in girl-only vs. mixed schools*** just like it can meaningfully mean:  ***diff. bet. girls in girl-only vs. mixed schools***
>
> Russ, have I used emmeans correctly?
>
> Simon
>
> Here is a reproducible code:
>
> library(R2MLwiN) # For the dataset
> library(lme4)
> library(emmeans)
>
> data("tutorial")
>
> Form <- normexam ~ 1 + standlrt + schgend + sex + (standlrt | school)
> model <- lmer(Form, data = tutorial, REML = FALSE)
>
> emmeans(model, pairwise~schgend+sex)$contrast
>
> contrast                     estimate     SE  df z.ratio p.value
> mixedsch boy - boysch boy    -0.17986 0.0991 Inf -1.814  0.4565
> mixedsch boy - girlsch boy   -0.17482 0.0788 Inf -2.219  0.2287   <--This coef. equals
> mixedsch boy - mixedsch girl -0.16826 0.0338 Inf -4.975  <.0001
> mixedsch boy - boysch girl   -0.34813 0.1096 Inf -3.178  0.0186
> mixedsch boy - girlsch girl  -0.34308 0.0780 Inf -4.396  0.0002
> boysch boy - girlsch boy      0.00505 0.1110 Inf  0.045  1.0000
> boysch boy - mixedsch girl    0.01160 0.0997 Inf  0.116  1.0000
> boysch boy - boysch girl     -0.16826 0.0338 Inf -4.975  <.0001
> boysch boy - girlsch girl    -0.16322 0.1058 Inf -1.543  0.6361
> girlsch boy - mixedsch girl   0.00656 0.0928 Inf  0.071  1.0000
> girlsch boy - boysch girl    -0.17331 0.1255 Inf -1.381  0.7388
> girlsch boy - girlsch girl   -0.16826 0.0338 Inf -4.975  <.0001
> mixedsch girl - boysch girl  -0.17986 0.0991 Inf -1.814  0.4565
> mixedsch girl - girlsch girl -0.17482 0.0788 Inf -2.219  0.2287   <--This coef.
> boysch girl - girlsch girl    0.00505 0.1110 Inf  0.045  1.0000
>
>

From @|m@h@rme| @end|ng |rom gm@||@com  Mon Sep 27 18:25:28 2021
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Mon, 27 Sep 2021 11:25:28 -0500
Subject: [R-sig-ME] Help with interpreting one fixed-effect coefficient
In-Reply-To: <DM6PR04MB4474DE9CADDA68F6F0ED8B0BF1A79@DM6PR04MB4474.namprd04.prod.outlook.com>
References: <DM6PR04MB4474DE9CADDA68F6F0ED8B0BF1A79@DM6PR04MB4474.namprd04.prod.outlook.com>
Message-ID: <CACgv6yXdi9cS59ZY6yXKfmim-kMtkRydnXOjuEv+-NqZkBhQMg@mail.gmail.com>

I fully understand that. My question is something else, though. Given the
empty cells, how these "erroneous" cell means for the empty cells are
obtained by the additive model? (can we hand-calculate these "erroneous"
cell means for the empty cells)

library(R2MLwiN)
library(emmeans)

Form3 <- normexam ~ schgend + sex
model3 <- lm(Form3, data = tutorial)

emmeans(model3, pairwise~sex+schgend)$emmeans

 sex  schgend   emmean     SE   df lower.CL upper.CL
 boy  mixedsch -0.2160 0.0297 4055  -0.2742 -0.15780
 girl mixedsch  0.0248 0.0304 4055  -0.0348  0.08437
 boy  boysch    0.0234 0.0437 4055  -0.0623  0.10897
 girl boysch    0.2641 0.0609 4055   0.1447  0.38360<-how computed?
 boy  girlsch  -0.0948 0.0502 4055  -0.1931  0.00358<-how computed?
 girl girlsch   0.1460 0.0267 4055   0.0938  0.19829

On Mon, Sep 27, 2021 at 11:14 AM Lenth, Russell V <russell-lenth at uiowa.edu>
wrote:

> Look at the model I fitted, which INCLUDES the interaction, and notice
> that those combinations are NOT estimated.
>
> Russ
>
> -----Original Message-----
> From: Simon Harmel <sim.harmel at gmail.com>
> Sent: Monday, September 27, 2021 11:10 AM
> To: Lenth, Russell V <russell-lenth at uiowa.edu>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [External] Re: [R-sig-ME] Help with interpreting one
> fixed-effect coefficient
>
> Thanks, Russ! There is one thing that I still don't understand. We
> have two completely empty cells (boys in girl-only & girls in boy-only
> schools). Then, how are the means of those empty cells computed (what
> data is used in their place in the additive model)?
>
> Let's' simplify the model for clarity:
>
> library(R2MLwiN)
> library(emmeans)
>
> Form3 <- normexam ~ schgend + sex ## + standlrt + (standlrt | school)
> model3 <- lm(Form3, data = tutorial)
>
> emmeans(model3, pairwise~sex+schgend)$emmeans
>
>  sex  schgend   emmean     SE   df lower.CL upper.CL
>  boy  mixedsch -0.2160 0.0297 4055  -0.2742 -0.15780
>  girl mixedsch  0.0248 0.0304 4055  -0.0348  0.08437
>  boy  boysch    0.0234 0.0437 4055  -0.0623  0.10897
>  girl boysch    0.2641 0.0609 4055   0.1447  0.38360<-how computed?
>  boy  girlsch  -0.0948 0.0502 4055  -0.1931  0.00358<-how computed?
>  girl girlsch   0.1460 0.0267 4055   0.0938  0.19829
>
>
>
>
>
> On Sun, Sep 26, 2021 at 8:22 PM Lenth, Russell V
> <russell-lenth at uiowa.edu> wrote:
> >
> > By the way, returning to the topic of interpreting coefficients, you
> ought to have fun with the ones from the model I just fitted:
> >
> > Fixed effects:
> >                Estimate Std. Error t value
> > (Intercept)    -0.18882    0.05135  -3.677
> > standlrt        0.55442    0.01994  27.807
> > schgendboysch   0.17986    0.09915   1.814
> > schgendgirlsch  0.17482    0.07877   2.219
> > sexgirl         0.16826    0.03382   4.975
> >
> > One curious thing you'll notice is that there are no coefficients for
> the interaction terms. Why? Because those terms were "thrown out" of the
> model, and so they are not shown. I think it is unwise to not show what was
> thrown out (e.g., lm would have shown them as NAs), because in fact what we
> see is but one of infinitely many possible solutions to the regression
> equations. This is the solution where the last two coefficients are
> constrained to zero. There is another equally reasonable one where the
> coefficients for schgendboysch and schgendgirlsch  are constrained to zero,
> and the two interaction effects would then be non-zero. And infinitely more
> where all 7 coefficients are non-zero, and there are two linear constraints
> among them.
> >
> > Of course, since the particular estimate shown consists of all the main
> effects and interactions are constrained to zero, it does demonstrate that
> the additive model *could* have been used to obtain the same estimates and
> standard errors, and you can see that by comparing the results (and
> ignoring the invalid ones from the additive model). But it is just a lucky
> coincidence that it worked out this way, and the additive model did lead us
> down a primrose path containing silly results among the correct ones.
> >
> > Russ
> >
> > -----Original Message-----
> > From: Lenth, Russell V
> > Sent: Sunday, September 26, 2021 7:43 PM
> > To: Simon Harmel <sim.harmel at gmail.com>
> > Cc: r-sig-mixed-models at r-project.org
> > Subject: RE: [External] Re: [R-sig-ME] Help with interpreting one
> fixed-effect coefficient
> >
> > I guess correctness is in the eyes of the beholder. But I think this
> illustrates the folly of the additive model. Having additive effects
> suggests a belief that you can vary one factor more or less independently
> of the other. In his comments, John Fox makes a good point that escaped my
> earlier cursory view of the original question, that you don't have data on
> girls attending all-boys' schools, nor boys attending all-girls' schools;
> yet the model that was fitted estimates a mean response for both those
> situations. That's a pretty clear testament to the failure of that model ?
> and also why the coefficients don't make sense. And finally why we have
> estimates of 15 comparisons (some of which are aliased with one another),
> when only 6 of them make sense.
> >
> > If instead, a model with interaction were fitted, it would be a
> rank-deficient model because two cells are empty. Perhaps there is some
> sort of nesting structure that could be used to work around that. However,
> it doesn't matter much because emmeans assesses estimability, and the two
> combinations I mentioned above would be flagged as non-estimable. One could
> then more judiciously use the contrast function to test meaningful
> contrasts across this irregular array of cell means. Or even injudiciously
> asking for all pairwise comparisons, you will see 6 estimable ones and 9
> non-estimable ones. See output below.
> >
> > Russ
> >
> > ----- Interactive model -----
> >
> > > Form <- normexam ~ 1 + standlrt + schgend * sex + (standlrt | school)
> > > model <- lmer(Form, data = tutorial, REML = FALSE)
> > fixed-effect model matrix is rank deficient so dropping 2 columns /
> coefficients
> > >
> > > emmeans(model, pairwise~schgend+sex)
> >
> > ... messages deleted ...
> >
> > $emmeans
> >  schgend  sex    emmean     SE  df asymp.LCL asymp.UCL
> >  mixedsch boy  -0.18781 0.0514 Inf   -0.2885   -0.0871
> >  boysch   boy  -0.00795 0.0880 Inf   -0.1805    0.1646
> >  girlsch  boy    nonEst     NA  NA        NA        NA
> >  mixedsch girl -0.01955 0.0521 Inf   -0.1216    0.0825
> >  boysch   girl   nonEst     NA  NA        NA        NA
> >  girlsch  girl  0.15527 0.0632 Inf    0.0313    0.2792
> >
> > Degrees-of-freedom method: asymptotic
> > Confidence level used: 0.95
> >
> > $contrasts
> >  contrast                     estimate     SE  df z.ratio p.value
> >  mixedsch boy - boysch boy     -0.1799 0.0991 Inf  -1.814  0.4565
> >  mixedsch boy - girlsch boy     nonEst     NA  NA      NA      NA
> >  mixedsch boy - mixedsch girl  -0.1683 0.0338 Inf  -4.975  <.0001
> >  mixedsch boy - boysch girl     nonEst     NA  NA      NA      NA
> >  mixedsch boy - girlsch girl   -0.3431 0.0780 Inf  -4.396  0.0002
> >  boysch boy - girlsch boy       nonEst     NA  NA      NA      NA
> >  boysch boy - mixedsch girl     0.0116 0.0997 Inf   0.116  1.0000
> >  boysch boy - boysch girl       nonEst     NA  NA      NA      NA
> >  boysch boy - girlsch girl     -0.1632 0.1058 Inf  -1.543  0.6361
> >  girlsch boy - mixedsch girl    nonEst     NA  NA      NA      NA
> >  girlsch boy - boysch girl      nonEst     NA  NA      NA      NA
> >  girlsch boy - girlsch girl     nonEst     NA  NA      NA      NA
> >  mixedsch girl - boysch girl    nonEst     NA  NA      NA      NA
> >  mixedsch girl - girlsch girl  -0.1748 0.0788 Inf  -2.219  0.2287
> >  boysch girl - girlsch girl     nonEst     NA  NA      NA      NA
> >
> > Degrees-of-freedom method: asymptotic
> > P value adjustment: tukey method for comparing a family of 6 estimates
> >
> >
> > ---------------------------------------------------------
> > From: Simon Harmel <sim.harmel at gmail.com>
> > Sent: Sunday, September 26, 2021 3:08 PM
> > To: Lenth, Russell V <russell-lenth at uiowa.edu>
> > Cc: r-sig-mixed-models at r-project.org
> > Subject: [External] Re: [R-sig-ME] Help with interpreting one
> fixed-effect coefficient
> >
> > Dear Russ and the List Members,
> >
> > If we use Russ' great package (emmeans), we see that although
> meaningless, but "schgendgirl-only" can be interpreted using the logic I
> mentioned here:
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html .
> >
> > That is, "schgendgirl-only" can meaninglessly mean: ***diff. bet. boys
> in girl-only vs. mixed schools*** just like it can meaningfully mean:
> ***diff. bet. girls in girl-only vs. mixed schools***
> >
> > Russ, have I used emmeans correctly?
> >
> > Simon
> >
> > Here is a reproducible code:
> >
> > library(R2MLwiN) # For the dataset
> > library(lme4)
> > library(emmeans)
> >
> > data("tutorial")
> >
> > Form <- normexam ~ 1 + standlrt + schgend + sex + (standlrt | school)
> > model <- lmer(Form, data = tutorial, REML = FALSE)
> >
> > emmeans(model, pairwise~schgend+sex)$contrast
> >
> > contrast                     estimate     SE  df z.ratio p.value
> > mixedsch boy - boysch boy    -0.17986 0.0991 Inf -1.814  0.4565
> > mixedsch boy - girlsch boy   -0.17482 0.0788 Inf -2.219  0.2287
>  <--This coef. equals
> > mixedsch boy - mixedsch girl -0.16826 0.0338 Inf -4.975  <.0001
> > mixedsch boy - boysch girl   -0.34813 0.1096 Inf -3.178  0.0186
> > mixedsch boy - girlsch girl  -0.34308 0.0780 Inf -4.396  0.0002
> > boysch boy - girlsch boy      0.00505 0.1110 Inf  0.045  1.0000
> > boysch boy - mixedsch girl    0.01160 0.0997 Inf  0.116  1.0000
> > boysch boy - boysch girl     -0.16826 0.0338 Inf -4.975  <.0001
> > boysch boy - girlsch girl    -0.16322 0.1058 Inf -1.543  0.6361
> > girlsch boy - mixedsch girl   0.00656 0.0928 Inf  0.071  1.0000
> > girlsch boy - boysch girl    -0.17331 0.1255 Inf -1.381  0.7388
> > girlsch boy - girlsch girl   -0.16826 0.0338 Inf -4.975  <.0001
> > mixedsch girl - boysch girl  -0.17986 0.0991 Inf -1.814  0.4565
> > mixedsch girl - girlsch girl -0.17482 0.0788 Inf -2.219  0.2287
>  <--This coef.
> > boysch girl - girlsch girl    0.00505 0.1110 Inf  0.045  1.0000
> >
> >
>

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Mon Sep 27 18:26:03 2021
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Mon, 27 Sep 2021 12:26:03 -0400
Subject: [R-sig-ME] 
 [External] Re: Help with interpreting one fixed-effect coefficient
In-Reply-To: <24474_1632759044_18RGAgpJ015661_CACgv6yVEGaJaQ1Y0=xCbPD2aAVoc6_0LypvwgdHKxfKO9Tfuvg@mail.gmail.com>
References: <DM6PR04MB4474B04E915E92DBB28EDB83F1A69@DM6PR04MB4474.namprd04.prod.outlook.com>
 <CACgv6yUZH9a_N63S28vAjq+bwvu5ECv-GnBKuXei-xcuXv9+1w@mail.gmail.com>
 <CACgv6yXtSHhLGVGiqr7wPWTX0wAh4U8P6KRbv_6fTMF6QnnrPQ@mail.gmail.com>
 <DM6PR04MB447412A47A489873E5942DFFF1A79@DM6PR04MB4474.namprd04.prod.outlook.com>
 <DM6PR04MB4474236A39405921364CF2B5F1A79@DM6PR04MB4474.namprd04.prod.outlook.com>
 <24474_1632759044_18RGAgpJ015661_CACgv6yVEGaJaQ1Y0=xCbPD2aAVoc6_0LypvwgdHKxfKO9Tfuvg@mail.gmail.com>
Message-ID: <2ee2479e-acab-c730-b57a-0be95089f11c@mcmaster.ca>

Dear Simon,

I believe that Russ's point is that the fact that the additive model 
allows you to estimate nonsensical quantities like a mean for girls in 
all-boys' schools implies a problem with the model. Why not do as I 
suggested and define two dichotomous factors: sex of student 
(male/female) and type of school (coed, same-sex)? The four combinations 
of levels then make sense.

Best,
  John

On 2021-09-27 12:09 p.m., Simon Harmel wrote:
> Thanks, Russ! There is one thing that I still don't understand. We
> have two completely empty cells (boys in girl-only & girls in boy-only
> schools). Then, how are the means of those empty cells computed (what
> data is used in their place in the additive model)?
> 
> Let's' simplify the model for clarity:
> 
> library(R2MLwiN)
> library(emmeans)
> 
> Form3 <- normexam ~ schgend + sex ## + standlrt + (standlrt | school)
> model3 <- lm(Form3, data = tutorial)
> 
> emmeans(model3, pairwise~sex+schgend)$emmeans
> 
>   sex  schgend   emmean     SE   df lower.CL upper.CL
>   boy  mixedsch -0.2160 0.0297 4055  -0.2742 -0.15780
>   girl mixedsch  0.0248 0.0304 4055  -0.0348  0.08437
>   boy  boysch    0.0234 0.0437 4055  -0.0623  0.10897
>   girl boysch    0.2641 0.0609 4055   0.1447  0.38360<-how computed?
>   boy  girlsch  -0.0948 0.0502 4055  -0.1931  0.00358<-how computed?
>   girl girlsch   0.1460 0.0267 4055   0.0938  0.19829
> 
> 
> 
> 
> 
> On Sun, Sep 26, 2021 at 8:22 PM Lenth, Russell V
> <russell-lenth at uiowa.edu> wrote:
>>
>> By the way, returning to the topic of interpreting coefficients, you ought to have fun with the ones from the model I just fitted:
>>
>> Fixed effects:
>>                 Estimate Std. Error t value
>> (Intercept)    -0.18882    0.05135  -3.677
>> standlrt        0.55442    0.01994  27.807
>> schgendboysch   0.17986    0.09915   1.814
>> schgendgirlsch  0.17482    0.07877   2.219
>> sexgirl         0.16826    0.03382   4.975
>>
>> One curious thing you'll notice is that there are no coefficients for the interaction terms. Why? Because those terms were "thrown out" of the model, and so they are not shown. I think it is unwise to not show what was thrown out (e.g., lm would have shown them as NAs), because in fact what we see is but one of infinitely many possible solutions to the regression equations. This is the solution where the last two coefficients are constrained to zero. There is another equally reasonable one where the coefficients for schgendboysch and schgendgirlsch  are constrained to zero, and the two interaction effects would then be non-zero. And infinitely more where all 7 coefficients are non-zero, and there are two linear constraints among them.
>>
>> Of course, since the particular estimate shown consists of all the main effects and interactions are constrained to zero, it does demonstrate that the additive model *could* have been used to obtain the same estimates and standard errors, and you can see that by comparing the results (and ignoring the invalid ones from the additive model). But it is just a lucky coincidence that it worked out this way, and the additive model did lead us down a primrose path containing silly results among the correct ones.
>>
>> Russ
>>
>> -----Original Message-----
>> From: Lenth, Russell V
>> Sent: Sunday, September 26, 2021 7:43 PM
>> To: Simon Harmel <sim.harmel at gmail.com>
>> Cc: r-sig-mixed-models at r-project.org
>> Subject: RE: [External] Re: [R-sig-ME] Help with interpreting one fixed-effect coefficient
>>
>> I guess correctness is in the eyes of the beholder. But I think this illustrates the folly of the additive model. Having additive effects suggests a belief that you can vary one factor more or less independently of the other. In his comments, John Fox makes a good point that escaped my earlier cursory view of the original question, that you don't have data on girls attending all-boys' schools, nor boys attending all-girls' schools; yet the model that was fitted estimates a mean response for both those situations. That's a pretty clear testament to the failure of that model ? and also why the coefficients don't make sense. And finally why we have estimates of 15 comparisons (some of which are aliased with one another), when only 6 of them make sense.
>>
>> If instead, a model with interaction were fitted, it would be a rank-deficient model because two cells are empty. Perhaps there is some sort of nesting structure that could be used to work around that. However, it doesn't matter much because emmeans assesses estimability, and the two combinations I mentioned above would be flagged as non-estimable. One could then more judiciously use the contrast function to test meaningful contrasts across this irregular array of cell means. Or even injudiciously asking for all pairwise comparisons, you will see 6 estimable ones and 9 non-estimable ones. See output below.
>>
>> Russ
>>
>> ----- Interactive model -----
>>
>>> Form <- normexam ~ 1 + standlrt + schgend * sex + (standlrt | school)
>>> model <- lmer(Form, data = tutorial, REML = FALSE)
>> fixed-effect model matrix is rank deficient so dropping 2 columns / coefficients
>>>
>>> emmeans(model, pairwise~schgend+sex)
>>
>> ... messages deleted ...
>>
>> $emmeans
>>   schgend  sex    emmean     SE  df asymp.LCL asymp.UCL
>>   mixedsch boy  -0.18781 0.0514 Inf   -0.2885   -0.0871
>>   boysch   boy  -0.00795 0.0880 Inf   -0.1805    0.1646
>>   girlsch  boy    nonEst     NA  NA        NA        NA
>>   mixedsch girl -0.01955 0.0521 Inf   -0.1216    0.0825
>>   boysch   girl   nonEst     NA  NA        NA        NA
>>   girlsch  girl  0.15527 0.0632 Inf    0.0313    0.2792
>>
>> Degrees-of-freedom method: asymptotic
>> Confidence level used: 0.95
>>
>> $contrasts
>>   contrast                     estimate     SE  df z.ratio p.value
>>   mixedsch boy - boysch boy     -0.1799 0.0991 Inf  -1.814  0.4565
>>   mixedsch boy - girlsch boy     nonEst     NA  NA      NA      NA
>>   mixedsch boy - mixedsch girl  -0.1683 0.0338 Inf  -4.975  <.0001
>>   mixedsch boy - boysch girl     nonEst     NA  NA      NA      NA
>>   mixedsch boy - girlsch girl   -0.3431 0.0780 Inf  -4.396  0.0002
>>   boysch boy - girlsch boy       nonEst     NA  NA      NA      NA
>>   boysch boy - mixedsch girl     0.0116 0.0997 Inf   0.116  1.0000
>>   boysch boy - boysch girl       nonEst     NA  NA      NA      NA
>>   boysch boy - girlsch girl     -0.1632 0.1058 Inf  -1.543  0.6361
>>   girlsch boy - mixedsch girl    nonEst     NA  NA      NA      NA
>>   girlsch boy - boysch girl      nonEst     NA  NA      NA      NA
>>   girlsch boy - girlsch girl     nonEst     NA  NA      NA      NA
>>   mixedsch girl - boysch girl    nonEst     NA  NA      NA      NA
>>   mixedsch girl - girlsch girl  -0.1748 0.0788 Inf  -2.219  0.2287
>>   boysch girl - girlsch girl     nonEst     NA  NA      NA      NA
>>
>> Degrees-of-freedom method: asymptotic
>> P value adjustment: tukey method for comparing a family of 6 estimates
>>
>>
>> ---------------------------------------------------------
>> From: Simon Harmel <sim.harmel at gmail.com>
>> Sent: Sunday, September 26, 2021 3:08 PM
>> To: Lenth, Russell V <russell-lenth at uiowa.edu>
>> Cc: r-sig-mixed-models at r-project.org
>> Subject: [External] Re: [R-sig-ME] Help with interpreting one fixed-effect coefficient
>>
>> Dear Russ and the List Members,
>>
>> If we use Russ' great package (emmeans), we see that although meaningless, but "schgendgirl-only" can be interpreted using the logic I mentioned here: https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html .
>>
>> That is, "schgendgirl-only" can meaninglessly mean: ***diff. bet. boys in girl-only vs. mixed schools*** just like it can meaningfully mean:  ***diff. bet. girls in girl-only vs. mixed schools***
>>
>> Russ, have I used emmeans correctly?
>>
>> Simon
>>
>> Here is a reproducible code:
>>
>> library(R2MLwiN) # For the dataset
>> library(lme4)
>> library(emmeans)
>>
>> data("tutorial")
>>
>> Form <- normexam ~ 1 + standlrt + schgend + sex + (standlrt | school)
>> model <- lmer(Form, data = tutorial, REML = FALSE)
>>
>> emmeans(model, pairwise~schgend+sex)$contrast
>>
>> contrast                     estimate     SE  df z.ratio p.value
>> mixedsch boy - boysch boy    -0.17986 0.0991 Inf -1.814  0.4565
>> mixedsch boy - girlsch boy   -0.17482 0.0788 Inf -2.219  0.2287   <--This coef. equals
>> mixedsch boy - mixedsch girl -0.16826 0.0338 Inf -4.975  <.0001
>> mixedsch boy - boysch girl   -0.34813 0.1096 Inf -3.178  0.0186
>> mixedsch boy - girlsch girl  -0.34308 0.0780 Inf -4.396  0.0002
>> boysch boy - girlsch boy      0.00505 0.1110 Inf  0.045  1.0000
>> boysch boy - mixedsch girl    0.01160 0.0997 Inf  0.116  1.0000
>> boysch boy - boysch girl     -0.16826 0.0338 Inf -4.975  <.0001
>> boysch boy - girlsch girl    -0.16322 0.1058 Inf -1.543  0.6361
>> girlsch boy - mixedsch girl   0.00656 0.0928 Inf  0.071  1.0000
>> girlsch boy - boysch girl    -0.17331 0.1255 Inf -1.381  0.7388
>> girlsch boy - girlsch girl   -0.16826 0.0338 Inf -4.975  <.0001
>> mixedsch girl - boysch girl  -0.17986 0.0991 Inf -1.814  0.4565
>> mixedsch girl - girlsch girl -0.17482 0.0788 Inf -2.219  0.2287   <--This coef.
>> boysch girl - girlsch girl    0.00505 0.1110 Inf  0.045  1.0000
>>
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
-- 
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/


From @|m@h@rme| @end|ng |rom gm@||@com  Mon Sep 27 18:31:17 2021
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Mon, 27 Sep 2021 11:31:17 -0500
Subject: [R-sig-ME] 
 [External] Re: Help with interpreting one fixed-effect coefficient
In-Reply-To: <2ee2479e-acab-c730-b57a-0be95089f11c@mcmaster.ca>
References: <DM6PR04MB4474B04E915E92DBB28EDB83F1A69@DM6PR04MB4474.namprd04.prod.outlook.com>
 <CACgv6yUZH9a_N63S28vAjq+bwvu5ECv-GnBKuXei-xcuXv9+1w@mail.gmail.com>
 <CACgv6yXtSHhLGVGiqr7wPWTX0wAh4U8P6KRbv_6fTMF6QnnrPQ@mail.gmail.com>
 <DM6PR04MB447412A47A489873E5942DFFF1A79@DM6PR04MB4474.namprd04.prod.outlook.com>
 <DM6PR04MB4474236A39405921364CF2B5F1A79@DM6PR04MB4474.namprd04.prod.outlook.com>
 <24474_1632759044_18RGAgpJ015661_CACgv6yVEGaJaQ1Y0=xCbPD2aAVoc6_0LypvwgdHKxfKO9Tfuvg@mail.gmail.com>
 <2ee2479e-acab-c730-b57a-0be95089f11c@mcmaster.ca>
Message-ID: <CACgv6yWPLFXWMaaTCZTvaRp7bA=udRxEdoR8Fyi2hTdekZammw@mail.gmail.com>

Dear John,

Sure, but I want to understand the folly of the additive model itself.
Specifically, how are the erroneous means of those empty cells computed
(what data is used to compute them in the additive model)?

library(R2MLwiN)
library(emmeans)

Form3 <- normexam ~ schgend + sex
model3 <- lm(Form3, data = tutorial)

emmeans(model3, pairwise~sex+schgend)$emmeans

 sex  schgend   emmean     SE   df lower.CL upper.CL
 boy  mixedsch -0.2160 0.0297 4055  -0.2742 -0.15780
 girl mixedsch  0.0248 0.0304 4055  -0.0348  0.08437
 boy  boysch    0.0234 0.0437 4055  -0.0623  0.10897
 girl boysch    0.2641 0.0609 4055   0.1447  0.38360<-how computed?
 boy  girlsch  -0.0948 0.0502 4055  -0.1931  0.00358<-how computed?
 girl girlsch   0.1460 0.0267 4055   0.0938  0.19829

On Mon, Sep 27, 2021 at 11:26 AM John Fox <jfox at mcmaster.ca> wrote:

> Dear Simon,
>
> I believe that Russ's point is that the fact that the additive model
> allows you to estimate nonsensical quantities like a mean for girls in
> all-boys' schools implies a problem with the model. Why not do as I
> suggested and define two dichotomous factors: sex of student
> (male/female) and type of school (coed, same-sex)? The four combinations
> of levels then make sense.
>
> Best,
>   John
>
> On 2021-09-27 12:09 p.m., Simon Harmel wrote:
> > Thanks, Russ! There is one thing that I still don't understand. We
> > have two completely empty cells (boys in girl-only & girls in boy-only
> > schools). Then, how are the means of those empty cells computed (what
> > data is used in their place in the additive model)?
> >
> > Let's' simplify the model for clarity:
> >
> > library(R2MLwiN)
> > library(emmeans)
> >
> > Form3 <- normexam ~ schgend + sex ## + standlrt + (standlrt | school)
> > model3 <- lm(Form3, data = tutorial)
> >
> > emmeans(model3, pairwise~sex+schgend)$emmeans
> >
> >   sex  schgend   emmean     SE   df lower.CL upper.CL
> >   boy  mixedsch -0.2160 0.0297 4055  -0.2742 -0.15780
> >   girl mixedsch  0.0248 0.0304 4055  -0.0348  0.08437
> >   boy  boysch    0.0234 0.0437 4055  -0.0623  0.10897
> >   girl boysch    0.2641 0.0609 4055   0.1447  0.38360<-how computed?
> >   boy  girlsch  -0.0948 0.0502 4055  -0.1931  0.00358<-how computed?
> >   girl girlsch   0.1460 0.0267 4055   0.0938  0.19829
> >
> >
> >
> >
> >
> > On Sun, Sep 26, 2021 at 8:22 PM Lenth, Russell V
> > <russell-lenth at uiowa.edu> wrote:
> >>
> >> By the way, returning to the topic of interpreting coefficients, you
> ought to have fun with the ones from the model I just fitted:
> >>
> >> Fixed effects:
> >>                 Estimate Std. Error t value
> >> (Intercept)    -0.18882    0.05135  -3.677
> >> standlrt        0.55442    0.01994  27.807
> >> schgendboysch   0.17986    0.09915   1.814
> >> schgendgirlsch  0.17482    0.07877   2.219
> >> sexgirl         0.16826    0.03382   4.975
> >>
> >> One curious thing you'll notice is that there are no coefficients for
> the interaction terms. Why? Because those terms were "thrown out" of the
> model, and so they are not shown. I think it is unwise to not show what was
> thrown out (e.g., lm would have shown them as NAs), because in fact what we
> see is but one of infinitely many possible solutions to the regression
> equations. This is the solution where the last two coefficients are
> constrained to zero. There is another equally reasonable one where the
> coefficients for schgendboysch and schgendgirlsch  are constrained to zero,
> and the two interaction effects would then be non-zero. And infinitely more
> where all 7 coefficients are non-zero, and there are two linear constraints
> among them.
> >>
> >> Of course, since the particular estimate shown consists of all the main
> effects and interactions are constrained to zero, it does demonstrate that
> the additive model *could* have been used to obtain the same estimates and
> standard errors, and you can see that by comparing the results (and
> ignoring the invalid ones from the additive model). But it is just a lucky
> coincidence that it worked out this way, and the additive model did lead us
> down a primrose path containing silly results among the correct ones.
> >>
> >> Russ
> >>
> >> -----Original Message-----
> >> From: Lenth, Russell V
> >> Sent: Sunday, September 26, 2021 7:43 PM
> >> To: Simon Harmel <sim.harmel at gmail.com>
> >> Cc: r-sig-mixed-models at r-project.org
> >> Subject: RE: [External] Re: [R-sig-ME] Help with interpreting one
> fixed-effect coefficient
> >>
> >> I guess correctness is in the eyes of the beholder. But I think this
> illustrates the folly of the additive model. Having additive effects
> suggests a belief that you can vary one factor more or less independently
> of the other. In his comments, John Fox makes a good point that escaped my
> earlier cursory view of the original question, that you don't have data on
> girls attending all-boys' schools, nor boys attending all-girls' schools;
> yet the model that was fitted estimates a mean response for both those
> situations. That's a pretty clear testament to the failure of that model ?
> and also why the coefficients don't make sense. And finally why we have
> estimates of 15 comparisons (some of which are aliased with one another),
> when only 6 of them make sense.
> >>
> >> If instead, a model with interaction were fitted, it would be a
> rank-deficient model because two cells are empty. Perhaps there is some
> sort of nesting structure that could be used to work around that. However,
> it doesn't matter much because emmeans assesses estimability, and the two
> combinations I mentioned above would be flagged as non-estimable. One could
> then more judiciously use the contrast function to test meaningful
> contrasts across this irregular array of cell means. Or even injudiciously
> asking for all pairwise comparisons, you will see 6 estimable ones and 9
> non-estimable ones. See output below.
> >>
> >> Russ
> >>
> >> ----- Interactive model -----
> >>
> >>> Form <- normexam ~ 1 + standlrt + schgend * sex + (standlrt | school)
> >>> model <- lmer(Form, data = tutorial, REML = FALSE)
> >> fixed-effect model matrix is rank deficient so dropping 2 columns /
> coefficients
> >>>
> >>> emmeans(model, pairwise~schgend+sex)
> >>
> >> ... messages deleted ...
> >>
> >> $emmeans
> >>   schgend  sex    emmean     SE  df asymp.LCL asymp.UCL
> >>   mixedsch boy  -0.18781 0.0514 Inf   -0.2885   -0.0871
> >>   boysch   boy  -0.00795 0.0880 Inf   -0.1805    0.1646
> >>   girlsch  boy    nonEst     NA  NA        NA        NA
> >>   mixedsch girl -0.01955 0.0521 Inf   -0.1216    0.0825
> >>   boysch   girl   nonEst     NA  NA        NA        NA
> >>   girlsch  girl  0.15527 0.0632 Inf    0.0313    0.2792
> >>
> >> Degrees-of-freedom method: asymptotic
> >> Confidence level used: 0.95
> >>
> >> $contrasts
> >>   contrast                     estimate     SE  df z.ratio p.value
> >>   mixedsch boy - boysch boy     -0.1799 0.0991 Inf  -1.814  0.4565
> >>   mixedsch boy - girlsch boy     nonEst     NA  NA      NA      NA
> >>   mixedsch boy - mixedsch girl  -0.1683 0.0338 Inf  -4.975  <.0001
> >>   mixedsch boy - boysch girl     nonEst     NA  NA      NA      NA
> >>   mixedsch boy - girlsch girl   -0.3431 0.0780 Inf  -4.396  0.0002
> >>   boysch boy - girlsch boy       nonEst     NA  NA      NA      NA
> >>   boysch boy - mixedsch girl     0.0116 0.0997 Inf   0.116  1.0000
> >>   boysch boy - boysch girl       nonEst     NA  NA      NA      NA
> >>   boysch boy - girlsch girl     -0.1632 0.1058 Inf  -1.543  0.6361
> >>   girlsch boy - mixedsch girl    nonEst     NA  NA      NA      NA
> >>   girlsch boy - boysch girl      nonEst     NA  NA      NA      NA
> >>   girlsch boy - girlsch girl     nonEst     NA  NA      NA      NA
> >>   mixedsch girl - boysch girl    nonEst     NA  NA      NA      NA
> >>   mixedsch girl - girlsch girl  -0.1748 0.0788 Inf  -2.219  0.2287
> >>   boysch girl - girlsch girl     nonEst     NA  NA      NA      NA
> >>
> >> Degrees-of-freedom method: asymptotic
> >> P value adjustment: tukey method for comparing a family of 6 estimates
> >>
> >>
> >> ---------------------------------------------------------
> >> From: Simon Harmel <sim.harmel at gmail.com>
> >> Sent: Sunday, September 26, 2021 3:08 PM
> >> To: Lenth, Russell V <russell-lenth at uiowa.edu>
> >> Cc: r-sig-mixed-models at r-project.org
> >> Subject: [External] Re: [R-sig-ME] Help with interpreting one
> fixed-effect coefficient
> >>
> >> Dear Russ and the List Members,
> >>
> >> If we use Russ' great package (emmeans), we see that although
> meaningless, but "schgendgirl-only" can be interpreted using the logic I
> mentioned here:
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html .
> >>
> >> That is, "schgendgirl-only" can meaninglessly mean: ***diff. bet. boys
> in girl-only vs. mixed schools*** just like it can meaningfully mean:
> ***diff. bet. girls in girl-only vs. mixed schools***
> >>
> >> Russ, have I used emmeans correctly?
> >>
> >> Simon
> >>
> >> Here is a reproducible code:
> >>
> >> library(R2MLwiN) # For the dataset
> >> library(lme4)
> >> library(emmeans)
> >>
> >> data("tutorial")
> >>
> >> Form <- normexam ~ 1 + standlrt + schgend + sex + (standlrt | school)
> >> model <- lmer(Form, data = tutorial, REML = FALSE)
> >>
> >> emmeans(model, pairwise~schgend+sex)$contrast
> >>
> >> contrast                     estimate     SE  df z.ratio p.value
> >> mixedsch boy - boysch boy    -0.17986 0.0991 Inf -1.814  0.4565
> >> mixedsch boy - girlsch boy   -0.17482 0.0788 Inf -2.219  0.2287
>  <--This coef. equals
> >> mixedsch boy - mixedsch girl -0.16826 0.0338 Inf -4.975  <.0001
> >> mixedsch boy - boysch girl   -0.34813 0.1096 Inf -3.178  0.0186
> >> mixedsch boy - girlsch girl  -0.34308 0.0780 Inf -4.396  0.0002
> >> boysch boy - girlsch boy      0.00505 0.1110 Inf  0.045  1.0000
> >> boysch boy - mixedsch girl    0.01160 0.0997 Inf  0.116  1.0000
> >> boysch boy - boysch girl     -0.16826 0.0338 Inf -4.975  <.0001
> >> boysch boy - girlsch girl    -0.16322 0.1058 Inf -1.543  0.6361
> >> girlsch boy - mixedsch girl   0.00656 0.0928 Inf  0.071  1.0000
> >> girlsch boy - boysch girl    -0.17331 0.1255 Inf -1.381  0.7388
> >> girlsch boy - girlsch girl   -0.16826 0.0338 Inf -4.975  <.0001
> >> mixedsch girl - boysch girl  -0.17986 0.0991 Inf -1.814  0.4565
> >> mixedsch girl - girlsch girl -0.17482 0.0788 Inf -2.219  0.2287
>  <--This coef.
> >> boysch girl - girlsch girl    0.00505 0.1110 Inf  0.045  1.0000
> >>
> >>
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> --
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> web: https://socialsciences.mcmaster.ca/jfox/
>
>

	[[alternative HTML version deleted]]


From ru@@e||-|enth @end|ng |rom u|ow@@edu  Mon Sep 27 18:32:04 2021
From: ru@@e||-|enth @end|ng |rom u|ow@@edu (Lenth, Russell V)
Date: Mon, 27 Sep 2021 16:32:04 +0000
Subject: [R-sig-ME] Help with interpreting one fixed-effect coefficient
Message-ID: <DM6PR04MB447487C289234EDC174260CFF1A79@DM6PR04MB4474.namprd04.prod.outlook.com>

I guess I misinterpreted Simon's last question... Those coefficients in the additive model are just estimated using data from other cells. Under a model that the effects are additive, there are fewer parameters and that makes it possible -- just like having an empty cell or two in a block experiment, it is still possible to impute the missing data based on an additive model for a block design. Or yet simpler, a straight-line model for y vs. x allows us to estimate E(y|x) for infinitely many x's not included in the dataset. A simple enough model can estimate anything.

Russ

-----Original Message-----
From: Simon Harmel <sim.harmel at gmail.com> 
Sent: Monday, September 27, 2021 11:10 AM
To: Lenth, Russell V <russell-lenth at uiowa.edu>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [External] Re: [R-sig-ME] Help with interpreting one fixed-effect coefficient

Thanks, Russ! There is one thing that I still don't understand. We
have two completely empty cells (boys in girl-only & girls in boy-only
schools). Then, how are the means of those empty cells computed (what
data is used in their place in the additive model)?

Let's' simplify the model for clarity:

library(R2MLwiN)
library(emmeans)

Form3 <- normexam ~ schgend + sex ## + standlrt + (standlrt | school)
model3 <- lm(Form3, data = tutorial)

emmeans(model3, pairwise~sex+schgend)$emmeans

 sex  schgend   emmean     SE   df lower.CL upper.CL
 boy  mixedsch -0.2160 0.0297 4055  -0.2742 -0.15780
 girl mixedsch  0.0248 0.0304 4055  -0.0348  0.08437
 boy  boysch    0.0234 0.0437 4055  -0.0623  0.10897
 girl boysch    0.2641 0.0609 4055   0.1447  0.38360<-how computed?
 boy  girlsch  -0.0948 0.0502 4055  -0.1931  0.00358<-how computed?
 girl girlsch   0.1460 0.0267 4055   0.0938  0.19829





On Sun, Sep 26, 2021 at 8:22 PM Lenth, Russell V
<russell-lenth at uiowa.edu> wrote:
>
> By the way, returning to the topic of interpreting coefficients, you ought to have fun with the ones from the model I just fitted:
>
> Fixed effects:
>                Estimate Std. Error t value
> (Intercept)    -0.18882    0.05135  -3.677
> standlrt        0.55442    0.01994  27.807
> schgendboysch   0.17986    0.09915   1.814
> schgendgirlsch  0.17482    0.07877   2.219
> sexgirl         0.16826    0.03382   4.975
>
> One curious thing you'll notice is that there are no coefficients for the interaction terms. Why? Because those terms were "thrown out" of the model, and so they are not shown. I think it is unwise to not show what was thrown out (e.g., lm would have shown them as NAs), because in fact what we see is but one of infinitely many possible solutions to the regression equations. This is the solution where the last two coefficients are constrained to zero. There is another equally reasonable one where the coefficients for schgendboysch and schgendgirlsch  are constrained to zero, and the two interaction effects would then be non-zero. And infinitely more where all 7 coefficients are non-zero, and there are two linear constraints among them.
>
> Of course, since the particular estimate shown consists of all the main effects and interactions are constrained to zero, it does demonstrate that the additive model *could* have been used to obtain the same estimates and standard errors, and you can see that by comparing the results (and ignoring the invalid ones from the additive model). But it is just a lucky coincidence that it worked out this way, and the additive model did lead us down a primrose path containing silly results among the correct ones.
>
> Russ
>
> -----Original Message-----
> From: Lenth, Russell V
> Sent: Sunday, September 26, 2021 7:43 PM
> To: Simon Harmel <sim.harmel at gmail.com>
> Cc: r-sig-mixed-models at r-project.org
> Subject: RE: [External] Re: [R-sig-ME] Help with interpreting one fixed-effect coefficient
>
> I guess correctness is in the eyes of the beholder. But I think this illustrates the folly of the additive model. Having additive effects suggests a belief that you can vary one factor more or less independently of the other. In his comments, John Fox makes a good point that escaped my earlier cursory view of the original question, that you don't have data on girls attending all-boys' schools, nor boys attending all-girls' schools; yet the model that was fitted estimates a mean response for both those situations. That's a pretty clear testament to the failure of that model ? and also why the coefficients don't make sense. And finally why we have estimates of 15 comparisons (some of which are aliased with one another), when only 6 of them make sense.
>
> If instead, a model with interaction were fitted, it would be a rank-deficient model because two cells are empty. Perhaps there is some sort of nesting structure that could be used to work around that. However, it doesn't matter much because emmeans assesses estimability, and the two combinations I mentioned above would be flagged as non-estimable. One could then more judiciously use the contrast function to test meaningful contrasts across this irregular array of cell means. Or even injudiciously asking for all pairwise comparisons, you will see 6 estimable ones and 9 non-estimable ones. See output below.
>
> Russ
>
> ----- Interactive model -----
>
> > Form <- normexam ~ 1 + standlrt + schgend * sex + (standlrt | school)
> > model <- lmer(Form, data = tutorial, REML = FALSE)
> fixed-effect model matrix is rank deficient so dropping 2 columns / coefficients
> >
> > emmeans(model, pairwise~schgend+sex)
>
> ... messages deleted ...
>
> $emmeans
>  schgend  sex    emmean     SE  df asymp.LCL asymp.UCL
>  mixedsch boy  -0.18781 0.0514 Inf   -0.2885   -0.0871
>  boysch   boy  -0.00795 0.0880 Inf   -0.1805    0.1646
>  girlsch  boy    nonEst     NA  NA        NA        NA
>  mixedsch girl -0.01955 0.0521 Inf   -0.1216    0.0825
>  boysch   girl   nonEst     NA  NA        NA        NA
>  girlsch  girl  0.15527 0.0632 Inf    0.0313    0.2792
>
> Degrees-of-freedom method: asymptotic
> Confidence level used: 0.95
>
> $contrasts
>  contrast                     estimate     SE  df z.ratio p.value
>  mixedsch boy - boysch boy     -0.1799 0.0991 Inf  -1.814  0.4565
>  mixedsch boy - girlsch boy     nonEst     NA  NA      NA      NA
>  mixedsch boy - mixedsch girl  -0.1683 0.0338 Inf  -4.975  <.0001
>  mixedsch boy - boysch girl     nonEst     NA  NA      NA      NA
>  mixedsch boy - girlsch girl   -0.3431 0.0780 Inf  -4.396  0.0002
>  boysch boy - girlsch boy       nonEst     NA  NA      NA      NA
>  boysch boy - mixedsch girl     0.0116 0.0997 Inf   0.116  1.0000
>  boysch boy - boysch girl       nonEst     NA  NA      NA      NA
>  boysch boy - girlsch girl     -0.1632 0.1058 Inf  -1.543  0.6361
>  girlsch boy - mixedsch girl    nonEst     NA  NA      NA      NA
>  girlsch boy - boysch girl      nonEst     NA  NA      NA      NA
>  girlsch boy - girlsch girl     nonEst     NA  NA      NA      NA
>  mixedsch girl - boysch girl    nonEst     NA  NA      NA      NA
>  mixedsch girl - girlsch girl  -0.1748 0.0788 Inf  -2.219  0.2287
>  boysch girl - girlsch girl     nonEst     NA  NA      NA      NA
>
> Degrees-of-freedom method: asymptotic
> P value adjustment: tukey method for comparing a family of 6 estimates
>
>
> ---------------------------------------------------------
> From: Simon Harmel <sim.harmel at gmail.com>
> Sent: Sunday, September 26, 2021 3:08 PM
> To: Lenth, Russell V <russell-lenth at uiowa.edu>
> Cc: r-sig-mixed-models at r-project.org
> Subject: [External] Re: [R-sig-ME] Help with interpreting one fixed-effect coefficient
>
> Dear Russ and the List Members,
>
> If we use Russ' great package (emmeans), we see that although meaningless, but "schgendgirl-only" can be interpreted using the logic I mentioned here: https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html .
>
> That is, "schgendgirl-only" can meaninglessly mean: ***diff. bet. boys in girl-only vs. mixed schools*** just like it can meaningfully mean:  ***diff. bet. girls in girl-only vs. mixed schools***
>
> Russ, have I used emmeans correctly?
>
> Simon
>
> Here is a reproducible code:
>
> library(R2MLwiN) # For the dataset
> library(lme4)
> library(emmeans)
>
> data("tutorial")
>
> Form <- normexam ~ 1 + standlrt + schgend + sex + (standlrt | school)
> model <- lmer(Form, data = tutorial, REML = FALSE)
>
> emmeans(model, pairwise~schgend+sex)$contrast
>
> contrast                     estimate     SE  df z.ratio p.value
> mixedsch boy - boysch boy    -0.17986 0.0991 Inf -1.814  0.4565
> mixedsch boy - girlsch boy   -0.17482 0.0788 Inf -2.219  0.2287   <--This coef. equals
> mixedsch boy - mixedsch girl -0.16826 0.0338 Inf -4.975  <.0001
> mixedsch boy - boysch girl   -0.34813 0.1096 Inf -3.178  0.0186
> mixedsch boy - girlsch girl  -0.34308 0.0780 Inf -4.396  0.0002
> boysch boy - girlsch boy      0.00505 0.1110 Inf  0.045  1.0000
> boysch boy - mixedsch girl    0.01160 0.0997 Inf  0.116  1.0000
> boysch boy - boysch girl     -0.16826 0.0338 Inf -4.975  <.0001
> boysch boy - girlsch girl    -0.16322 0.1058 Inf -1.543  0.6361
> girlsch boy - mixedsch girl   0.00656 0.0928 Inf  0.071  1.0000
> girlsch boy - boysch girl    -0.17331 0.1255 Inf -1.381  0.7388
> girlsch boy - girlsch girl   -0.16826 0.0338 Inf -4.975  <.0001
> mixedsch girl - boysch girl  -0.17986 0.0991 Inf -1.814  0.4565
> mixedsch girl - girlsch girl -0.17482 0.0788 Inf -2.219  0.2287   <--This coef.
> boysch girl - girlsch girl    0.00505 0.1110 Inf  0.045  1.0000
>
>

From @|m@h@rme| @end|ng |rom gm@||@com  Mon Sep 27 19:45:25 2021
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Mon, 27 Sep 2021 12:45:25 -0500
Subject: [R-sig-ME] Help with interpreting one fixed-effect coefficient
In-Reply-To: <DM6PR04MB447487C289234EDC174260CFF1A79@DM6PR04MB4474.namprd04.prod.outlook.com>
References: <DM6PR04MB447487C289234EDC174260CFF1A79@DM6PR04MB4474.namprd04.prod.outlook.com>
Message-ID: <CACgv6yUGErkdkgp=EJoNCSuePgGDVAozseWA2m8jXiNRmeqMDw@mail.gmail.com>

Sure, many thanks.

Simon

On Mon, Sep 27, 2021 at 11:32 AM Lenth, Russell V <russell-lenth at uiowa.edu>
wrote:

> I guess I misinterpreted Simon's last question... Those coefficients in
> the additive model are just estimated using data from other cells. Under a
> model that the effects are additive, there are fewer parameters and that
> makes it possible -- just like having an empty cell or two in a block
> experiment, it is still possible to impute the missing data based on an
> additive model for a block design. Or yet simpler, a straight-line model
> for y vs. x allows us to estimate E(y|x) for infinitely many x's not
> included in the dataset. A simple enough model can estimate anything.
>
> Russ
>
> -----Original Message-----
> From: Simon Harmel <sim.harmel at gmail.com>
> Sent: Monday, September 27, 2021 11:10 AM
> To: Lenth, Russell V <russell-lenth at uiowa.edu>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [External] Re: [R-sig-ME] Help with interpreting one
> fixed-effect coefficient
>
> Thanks, Russ! There is one thing that I still don't understand. We
> have two completely empty cells (boys in girl-only & girls in boy-only
> schools). Then, how are the means of those empty cells computed (what
> data is used in their place in the additive model)?
>
> Let's' simplify the model for clarity:
>
> library(R2MLwiN)
> library(emmeans)
>
> Form3 <- normexam ~ schgend + sex ## + standlrt + (standlrt | school)
> model3 <- lm(Form3, data = tutorial)
>
> emmeans(model3, pairwise~sex+schgend)$emmeans
>
>  sex  schgend   emmean     SE   df lower.CL upper.CL
>  boy  mixedsch -0.2160 0.0297 4055  -0.2742 -0.15780
>  girl mixedsch  0.0248 0.0304 4055  -0.0348  0.08437
>  boy  boysch    0.0234 0.0437 4055  -0.0623  0.10897
>  girl boysch    0.2641 0.0609 4055   0.1447  0.38360<-how computed?
>  boy  girlsch  -0.0948 0.0502 4055  -0.1931  0.00358<-how computed?
>  girl girlsch   0.1460 0.0267 4055   0.0938  0.19829
>
>
>
>
>
> On Sun, Sep 26, 2021 at 8:22 PM Lenth, Russell V
> <russell-lenth at uiowa.edu> wrote:
> >
> > By the way, returning to the topic of interpreting coefficients, you
> ought to have fun with the ones from the model I just fitted:
> >
> > Fixed effects:
> >                Estimate Std. Error t value
> > (Intercept)    -0.18882    0.05135  -3.677
> > standlrt        0.55442    0.01994  27.807
> > schgendboysch   0.17986    0.09915   1.814
> > schgendgirlsch  0.17482    0.07877   2.219
> > sexgirl         0.16826    0.03382   4.975
> >
> > One curious thing you'll notice is that there are no coefficients for
> the interaction terms. Why? Because those terms were "thrown out" of the
> model, and so they are not shown. I think it is unwise to not show what was
> thrown out (e.g., lm would have shown them as NAs), because in fact what we
> see is but one of infinitely many possible solutions to the regression
> equations. This is the solution where the last two coefficients are
> constrained to zero. There is another equally reasonable one where the
> coefficients for schgendboysch and schgendgirlsch  are constrained to zero,
> and the two interaction effects would then be non-zero. And infinitely more
> where all 7 coefficients are non-zero, and there are two linear constraints
> among them.
> >
> > Of course, since the particular estimate shown consists of all the main
> effects and interactions are constrained to zero, it does demonstrate that
> the additive model *could* have been used to obtain the same estimates and
> standard errors, and you can see that by comparing the results (and
> ignoring the invalid ones from the additive model). But it is just a lucky
> coincidence that it worked out this way, and the additive model did lead us
> down a primrose path containing silly results among the correct ones.
> >
> > Russ
> >
> > -----Original Message-----
> > From: Lenth, Russell V
> > Sent: Sunday, September 26, 2021 7:43 PM
> > To: Simon Harmel <sim.harmel at gmail.com>
> > Cc: r-sig-mixed-models at r-project.org
> > Subject: RE: [External] Re: [R-sig-ME] Help with interpreting one
> fixed-effect coefficient
> >
> > I guess correctness is in the eyes of the beholder. But I think this
> illustrates the folly of the additive model. Having additive effects
> suggests a belief that you can vary one factor more or less independently
> of the other. In his comments, John Fox makes a good point that escaped my
> earlier cursory view of the original question, that you don't have data on
> girls attending all-boys' schools, nor boys attending all-girls' schools;
> yet the model that was fitted estimates a mean response for both those
> situations. That's a pretty clear testament to the failure of that model ?
> and also why the coefficients don't make sense. And finally why we have
> estimates of 15 comparisons (some of which are aliased with one another),
> when only 6 of them make sense.
> >
> > If instead, a model with interaction were fitted, it would be a
> rank-deficient model because two cells are empty. Perhaps there is some
> sort of nesting structure that could be used to work around that. However,
> it doesn't matter much because emmeans assesses estimability, and the two
> combinations I mentioned above would be flagged as non-estimable. One could
> then more judiciously use the contrast function to test meaningful
> contrasts across this irregular array of cell means. Or even injudiciously
> asking for all pairwise comparisons, you will see 6 estimable ones and 9
> non-estimable ones. See output below.
> >
> > Russ
> >
> > ----- Interactive model -----
> >
> > > Form <- normexam ~ 1 + standlrt + schgend * sex + (standlrt | school)
> > > model <- lmer(Form, data = tutorial, REML = FALSE)
> > fixed-effect model matrix is rank deficient so dropping 2 columns /
> coefficients
> > >
> > > emmeans(model, pairwise~schgend+sex)
> >
> > ... messages deleted ...
> >
> > $emmeans
> >  schgend  sex    emmean     SE  df asymp.LCL asymp.UCL
> >  mixedsch boy  -0.18781 0.0514 Inf   -0.2885   -0.0871
> >  boysch   boy  -0.00795 0.0880 Inf   -0.1805    0.1646
> >  girlsch  boy    nonEst     NA  NA        NA        NA
> >  mixedsch girl -0.01955 0.0521 Inf   -0.1216    0.0825
> >  boysch   girl   nonEst     NA  NA        NA        NA
> >  girlsch  girl  0.15527 0.0632 Inf    0.0313    0.2792
> >
> > Degrees-of-freedom method: asymptotic
> > Confidence level used: 0.95
> >
> > $contrasts
> >  contrast                     estimate     SE  df z.ratio p.value
> >  mixedsch boy - boysch boy     -0.1799 0.0991 Inf  -1.814  0.4565
> >  mixedsch boy - girlsch boy     nonEst     NA  NA      NA      NA
> >  mixedsch boy - mixedsch girl  -0.1683 0.0338 Inf  -4.975  <.0001
> >  mixedsch boy - boysch girl     nonEst     NA  NA      NA      NA
> >  mixedsch boy - girlsch girl   -0.3431 0.0780 Inf  -4.396  0.0002
> >  boysch boy - girlsch boy       nonEst     NA  NA      NA      NA
> >  boysch boy - mixedsch girl     0.0116 0.0997 Inf   0.116  1.0000
> >  boysch boy - boysch girl       nonEst     NA  NA      NA      NA
> >  boysch boy - girlsch girl     -0.1632 0.1058 Inf  -1.543  0.6361
> >  girlsch boy - mixedsch girl    nonEst     NA  NA      NA      NA
> >  girlsch boy - boysch girl      nonEst     NA  NA      NA      NA
> >  girlsch boy - girlsch girl     nonEst     NA  NA      NA      NA
> >  mixedsch girl - boysch girl    nonEst     NA  NA      NA      NA
> >  mixedsch girl - girlsch girl  -0.1748 0.0788 Inf  -2.219  0.2287
> >  boysch girl - girlsch girl     nonEst     NA  NA      NA      NA
> >
> > Degrees-of-freedom method: asymptotic
> > P value adjustment: tukey method for comparing a family of 6 estimates
> >
> >
> > ---------------------------------------------------------
> > From: Simon Harmel <sim.harmel at gmail.com>
> > Sent: Sunday, September 26, 2021 3:08 PM
> > To: Lenth, Russell V <russell-lenth at uiowa.edu>
> > Cc: r-sig-mixed-models at r-project.org
> > Subject: [External] Re: [R-sig-ME] Help with interpreting one
> fixed-effect coefficient
> >
> > Dear Russ and the List Members,
> >
> > If we use Russ' great package (emmeans), we see that although
> meaningless, but "schgendgirl-only" can be interpreted using the logic I
> mentioned here:
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q3/029723.html .
> >
> > That is, "schgendgirl-only" can meaninglessly mean: ***diff. bet. boys
> in girl-only vs. mixed schools*** just like it can meaningfully mean:
> ***diff. bet. girls in girl-only vs. mixed schools***
> >
> > Russ, have I used emmeans correctly?
> >
> > Simon
> >
> > Here is a reproducible code:
> >
> > library(R2MLwiN) # For the dataset
> > library(lme4)
> > library(emmeans)
> >
> > data("tutorial")
> >
> > Form <- normexam ~ 1 + standlrt + schgend + sex + (standlrt | school)
> > model <- lmer(Form, data = tutorial, REML = FALSE)
> >
> > emmeans(model, pairwise~schgend+sex)$contrast
> >
> > contrast                     estimate     SE  df z.ratio p.value
> > mixedsch boy - boysch boy    -0.17986 0.0991 Inf -1.814  0.4565
> > mixedsch boy - girlsch boy   -0.17482 0.0788 Inf -2.219  0.2287
>  <--This coef. equals
> > mixedsch boy - mixedsch girl -0.16826 0.0338 Inf -4.975  <.0001
> > mixedsch boy - boysch girl   -0.34813 0.1096 Inf -3.178  0.0186
> > mixedsch boy - girlsch girl  -0.34308 0.0780 Inf -4.396  0.0002
> > boysch boy - girlsch boy      0.00505 0.1110 Inf  0.045  1.0000
> > boysch boy - mixedsch girl    0.01160 0.0997 Inf  0.116  1.0000
> > boysch boy - boysch girl     -0.16826 0.0338 Inf -4.975  <.0001
> > boysch boy - girlsch girl    -0.16322 0.1058 Inf -1.543  0.6361
> > girlsch boy - mixedsch girl   0.00656 0.0928 Inf  0.071  1.0000
> > girlsch boy - boysch girl    -0.17331 0.1255 Inf -1.381  0.7388
> > girlsch boy - girlsch girl   -0.16826 0.0338 Inf -4.975  <.0001
> > mixedsch girl - boysch girl  -0.17986 0.0991 Inf -1.814  0.4565
> > mixedsch girl - girlsch girl -0.17482 0.0788 Inf -2.219  0.2287
>  <--This coef.
> > boysch girl - girlsch girl    0.00505 0.1110 Inf  0.045  1.0000
> >
> >
>

	[[alternative HTML version deleted]]


From gu|||@ume@|mon@@2 @end|ng |rom gm@||@com  Wed Sep 29 14:04:03 2021
From: gu|||@ume@|mon@@2 @end|ng |rom gm@||@com (Guillaume Adeux)
Date: Wed, 29 Sep 2021 14:04:03 +0200
Subject: [R-sig-ME] contrasts vs. directly modelling differences: big diff?
Message-ID: <CAENiVe-9kCktF40a-kDTNoJNbLRcMhTS6OWUJy4k=7qSvaDavg@mail.gmail.com>

Good afternoon everyone,

I have this recurring question of whether it is best to directly model the
response as % differences (e.g. Yield_loss=(Yield_without_weeds -
Yield_with_weeds)/(Yield_without_weeds)) or whether it is best to directly
model the response (e.g. Yield) and compute yield loss through post hoc
contrasts on the log scale.

I hope this following example can illustrate better:
Let's take two different weed communities: WC1 and WC2.
Each community is present on 6 fields, with multiple samples per field.
Next to each weedy sample of WC1 and WC2 within each of the 6 fields, there
is a hand weed control, inducing a hierarchical structure (paired data
within each field for each of the two weed communities).
The objective is to compute yield loss induced by the two communities and
to compare them.
One option could be to directly compute yield loss (e.g.
Yield_loss=(Yield_without_weeds - Yield_with_weeds)/(Yield_without_weeds))
for each weedy/weeded couple within each field and model
* mod0=glmer(Yield_loss~WC+(1|field)+(1|field:WC),family="binomial"),data=yl)*
(I
suppose beta or beta_binomial would also be a reasonable choice but it's
not the matter of today). Comparisons could then be made with
*cld(emmeans(mod0,~WC))*

Another option could be to directly model the response (e.g. Yield),
introduce a "Handweeding" (yes/no) variable and compute Yield loss through
the following code:
*mod1=lmer(log(Yield)~Handweeding*WC+(1|field)+(1|field:Handweeding)+(1|field:WC)+(1|field:Handweeding:WC),data=yl)*

*x=pairs(emmeans(mod1,~Handweeding|WC),reverse=TRUE)
y=regrid(x,transform="response")
*# differences on the log scale are exponentiated
*summary(y,infer=c(TRUE,TRUE),null=1) *# is yield loss significantly
different from 0 for each of the 2 community?
*cld(emmeans(y,~WC),adjust="mvt") *# is yield loss induced by WC1 different
from yield loss induced by WC2?

Are both these "procedures" correct? Which is preferable? Why?

Do not hesitate to request further information if I wasn't clear enough.
Thanks a lot.
Guillaume ADEUX

	[[alternative HTML version deleted]]


From kev|n@thorpe @end|ng |rom utoronto@c@  Wed Sep 29 14:25:54 2021
From: kev|n@thorpe @end|ng |rom utoronto@c@ (Kevin Thorpe)
Date: Wed, 29 Sep 2021 12:25:54 +0000
Subject: [R-sig-ME] 
 contrasts vs. directly modelling differences: big diff?
In-Reply-To: <CAENiVe-9kCktF40a-kDTNoJNbLRcMhTS6OWUJy4k=7qSvaDavg@mail.gmail.com>
References: <CAENiVe-9kCktF40a-kDTNoJNbLRcMhTS6OWUJy4k=7qSvaDavg@mail.gmail.com>
Message-ID: <EA7E0F5A-4735-42FA-91EC-1C07D0578314@utoronto.ca>

I will not speak to the mixed-effect case but here are some thoughts.

Andrew Vickers published a paper (in BMC Medical Research Methodology (2001) 1:6) that demonstrates a loss of efficiency analyzing percent change as opposed to an ANCOVA on the raw data.

Second, as I recall, when you analyze on a log scale and exponentiate to obtain percent change, this gives a symmetric percent change estimate, while the usual calculation of percent difference is not.

I see no obvious reason why these ideas would not carry over to mixed-effect models.


> On Sep 29, 2021, at 8:04 AM, Guillaume Adeux <guillaumesimon.a2 at gmail.com> wrote:
> 
> Good afternoon everyone,
> 
> I have this recurring question of whether it is best to directly model the
> response as % differences (e.g. Yield_loss=(Yield_without_weeds -
> Yield_with_weeds)/(Yield_without_weeds)) or whether it is best to directly
> model the response (e.g. Yield) and compute yield loss through post hoc
> contrasts on the log scale.
> 
> I hope this following example can illustrate better:
> Let's take two different weed communities: WC1 and WC2.
> Each community is present on 6 fields, with multiple samples per field.
> Next to each weedy sample of WC1 and WC2 within each of the 6 fields, there
> is a hand weed control, inducing a hierarchical structure (paired data
> within each field for each of the two weed communities).
> The objective is to compute yield loss induced by the two communities and
> to compare them.
> One option could be to directly compute yield loss (e.g.
> Yield_loss=(Yield_without_weeds - Yield_with_weeds)/(Yield_without_weeds))
> for each weedy/weeded couple within each field and model
> * mod0=glmer(Yield_loss~WC+(1|field)+(1|field:WC),family="binomial"),data=yl)*
> (I
> suppose beta or beta_binomial would also be a reasonable choice but it's
> not the matter of today). Comparisons could then be made with
> *cld(emmeans(mod0,~WC))*
> 
> Another option could be to directly model the response (e.g. Yield),
> introduce a "Handweeding" (yes/no) variable and compute Yield loss through
> the following code:
> *mod1=lmer(log(Yield)~Handweeding*WC+(1|field)+(1|field:Handweeding)+(1|field:WC)+(1|field:Handweeding:WC),data=yl)*
> 
> *x=pairs(emmeans(mod1,~Handweeding|WC),reverse=TRUE)
> y=regrid(x,transform="response")
> *# differences on the log scale are exponentiated
> *summary(y,infer=c(TRUE,TRUE),null=1) *# is yield loss significantly
> different from 0 for each of the 2 community?
> *cld(emmeans(y,~WC),adjust="mvt") *# is yield loss induced by WC1 different
> from yield loss induced by WC2?
> 
> Are both these "procedures" correct? Which is preferable? Why?
> 
> Do not hesitate to request further information if I wasn't clear enough.
> Thanks a lot.
> Guillaume ADEUX
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016


From th|erry@onke||nx @end|ng |rom |nbo@be  Wed Sep 29 14:27:40 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Wed, 29 Sep 2021 14:27:40 +0200
Subject: [R-sig-ME] 
 contrasts vs. directly modelling differences: big diff?
In-Reply-To: <CAENiVe-9kCktF40a-kDTNoJNbLRcMhTS6OWUJy4k=7qSvaDavg@mail.gmail.com>
References: <CAENiVe-9kCktF40a-kDTNoJNbLRcMhTS6OWUJy4k=7qSvaDavg@mail.gmail.com>
Message-ID: <CAJuCY5zPg+z7uD6Xa8Q_o3DsVE2w6yRfH1ors0Tw=FGZUi1hjw@mail.gmail.com>

Dear Guillaume,

I prefer to model the yield as that is the response of your experiment. It
is easier to find a suitable distribution for the yield.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op wo 29 sep. 2021 om 14:04 schreef Guillaume Adeux <
guillaumesimon.a2 at gmail.com>:

> Good afternoon everyone,
>
> I have this recurring question of whether it is best to directly model the
> response as % differences (e.g. Yield_loss=(Yield_without_weeds -
> Yield_with_weeds)/(Yield_without_weeds)) or whether it is best to directly
> model the response (e.g. Yield) and compute yield loss through post hoc
> contrasts on the log scale.
>
> I hope this following example can illustrate better:
> Let's take two different weed communities: WC1 and WC2.
> Each community is present on 6 fields, with multiple samples per field.
> Next to each weedy sample of WC1 and WC2 within each of the 6 fields, there
> is a hand weed control, inducing a hierarchical structure (paired data
> within each field for each of the two weed communities).
> The objective is to compute yield loss induced by the two communities and
> to compare them.
> One option could be to directly compute yield loss (e.g.
> Yield_loss=(Yield_without_weeds - Yield_with_weeds)/(Yield_without_weeds))
> for each weedy/weeded couple within each field and model
> *
> mod0=glmer(Yield_loss~WC+(1|field)+(1|field:WC),family="binomial"),data=yl)*
> (I
> suppose beta or beta_binomial would also be a reasonable choice but it's
> not the matter of today). Comparisons could then be made with
> *cld(emmeans(mod0,~WC))*
>
> Another option could be to directly model the response (e.g. Yield),
> introduce a "Handweeding" (yes/no) variable and compute Yield loss through
> the following code:
>
> *mod1=lmer(log(Yield)~Handweeding*WC+(1|field)+(1|field:Handweeding)+(1|field:WC)+(1|field:Handweeding:WC),data=yl)*
>
> *x=pairs(emmeans(mod1,~Handweeding|WC),reverse=TRUE)
> y=regrid(x,transform="response")
> *# differences on the log scale are exponentiated
> *summary(y,infer=c(TRUE,TRUE),null=1) *# is yield loss significantly
> different from 0 for each of the 2 community?
> *cld(emmeans(y,~WC),adjust="mvt") *# is yield loss induced by WC1 different
> from yield loss induced by WC2?
>
> Are both these "procedures" correct? Which is preferable? Why?
>
> Do not hesitate to request further information if I wasn't clear enough.
> Thanks a lot.
> Guillaume ADEUX
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From t|m@co|e @end|ng |rom uc|@@c@uk  Wed Sep 29 16:06:23 2021
From: t|m@co|e @end|ng |rom uc|@@c@uk (Cole, Tim)
Date: Wed, 29 Sep 2021 14:06:23 +0000
Subject: [R-sig-ME] 
 contrasts vs. directly modelling differences: big diff?
Message-ID: <29CEE161-47D7-40D7-A487-C0554E5CB8DF@ucl.ac.uk>

Dear Guillaume,

 As Thierry says, yield is the response of your experiment, yet you choose to define yield loss as delta(yield)/yield rather than the more obvious delta(yield).

Clearly if delta(yield) were your measure of yield loss, then yield would be the appropriate outcome to work with.

But if you prefer delta(yield)/yield as your measure of loss, then this is different and the appropriate outcome is log(yield). This follows directly because delta(log(yield)) is delta(yield)/yield. 

Better still, work with 100 log(yield) as the outcome, then differences in outcome can be viewed as being in % units. Read more here: https://doi.org/10.1136/BMJ.J3683 

Best wishes,
Tim Cole

Population Policy and Practice
UCL Great Ormond Street Institute of Child Health
30 Guilford Street, London WC1N 1EH
    ------------------------------
    Date: Wed, 29 Sep 2021 14:27:40 +0200
    From: Thierry Onkelinx <thierry.onkelinx at inbo.be>
    To: Guillaume Adeux <guillaumesimon.a2 at gmail.com>
    Cc: R-mixed models mailing list <r-sig-mixed-models at r-project.org>
    Subject: Re: [R-sig-ME]  contrasts vs. directly modelling differences:
    	big diff?
    Message-ID:
    	<CAJuCY5zPg+z7uD6Xa8Q_o3DsVE2w6yRfH1ors0Tw=FGZUi1hjw at mail.gmail.com>
    Content-Type: text/plain; charset="utf-8"

    Dear Guillaume,

    I prefer to model the yield as that is the response of your experiment. It
    is easier to find a suitable distribution for the yield.

    Best regards,

    ir. Thierry Onkelinx
    Statisticus / Statistician

    Vlaamse Overheid / Government of Flanders
    INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
    FOREST
    Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
    thierry.onkelinx at inbo.be
    Havenlaan 88 bus 73, 1000 Brussel
    https://eur01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.inbo.be%2F&amp;data=04%7C01%7Ctim.cole%40ucl.ac.uk%7Cd7980087949e4ef4d2fb08d98345c822%7C1faf88fea9984c5b93c9210a11d9a5c2%7C0%7C0%7C637685158208166257%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=5eQEnxVLmZDHOnwEoVjOvRZYEDYwmQEBlUekB9tN0ng%3D&amp;reserved=0

    ///////////////////////////////////////////////////////////////////////////////////////////
    To call in the statistician after the experiment is done may be no more
    than asking him to perform a post-mortem examination: he may be able to say
    what the experiment died of. ~ Sir Ronald Aylmer Fisher
    The plural of anecdote is not data. ~ Roger Brinner
    The combination of some data and an aching desire for an answer does not
    ensure that a reasonable answer can be extracted from a given body of data.
    ~ John Tukey
    ///////////////////////////////////////////////////////////////////////////////////////////

    <https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.inbo.be%2F&amp;data=04%7C01%7Ctim.cole%40ucl.ac.uk%7Cd7980087949e4ef4d2fb08d98345c822%7C1faf88fea9984c5b93c9210a11d9a5c2%7C0%7C0%7C637685158208166257%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=SDvKjBFdx0bQwMqQSj2O7ed%2BeaxVDGnphhrx2ZEzFUc%3D&amp;reserved=0>


    Op wo 29 sep. 2021 om 14:04 schreef Guillaume Adeux <
    guillaumesimon.a2 at gmail.com>:

    > Good afternoon everyone,
    >
    > I have this recurring question of whether it is best to directly model the
    > response as % differences (e.g. Yield_loss=(Yield_without_weeds -
    > Yield_with_weeds)/(Yield_without_weeds)) or whether it is best to directly
    > model the response (e.g. Yield) and compute yield loss through post hoc
    > contrasts on the log scale.
    >
    > I hope this following example can illustrate better:
    > Let's take two different weed communities: WC1 and WC2.
    > Each community is present on 6 fields, with multiple samples per field.
    > Next to each weedy sample of WC1 and WC2 within each of the 6 fields, there
    > is a hand weed control, inducing a hierarchical structure (paired data
    > within each field for each of the two weed communities).
    > The objective is to compute yield loss induced by the two communities and
    > to compare them.
    > One option could be to directly compute yield loss (e.g.
    > Yield_loss=(Yield_without_weeds - Yield_with_weeds)/(Yield_without_weeds))
    > for each weedy/weeded couple within each field and model
    > *
    > mod0=glmer(Yield_loss~WC+(1|field)+(1|field:WC),family="binomial"),data=yl)*
    > (I
    > suppose beta or beta_binomial would also be a reasonable choice but it's
    > not the matter of today). Comparisons could then be made with
    > *cld(emmeans(mod0,~WC))*
    >
    > Another option could be to directly model the response (e.g. Yield),
    > introduce a "Handweeding" (yes/no) variable and compute Yield loss through
    > the following code:
    >
    > *mod1=lmer(log(Yield)~Handweeding*WC+(1|field)+(1|field:Handweeding)+(1|field:WC)+(1|field:Handweeding:WC),data=yl)*
    >
    > *x=pairs(emmeans(mod1,~Handweeding|WC),reverse=TRUE)
    > y=regrid(x,transform="response")
    > *# differences on the log scale are exponentiated
    > *summary(y,infer=c(TRUE,TRUE),null=1) *# is yield loss significantly
    > different from 0 for each of the 2 community?
    > *cld(emmeans(y,~WC),adjust="mvt") *# is yield loss induced by WC1 different
    > from yield loss induced by WC2?
    >
    > Are both these "procedures" correct? Which is preferable? Why?
    >
    > Do not hesitate to request further information if I wasn't clear enough.
    > Thanks a lot.
    > Guillaume ADEUX



From o||verhooker @end|ng |rom pr@t@t|@t|c@@com  Thu Sep 30 15:45:52 2021
From: o||verhooker @end|ng |rom pr@t@t|@t|c@@com (Oliver Hooker)
Date: Thu, 30 Sep 2021 14:45:52 +0100
Subject: [R-sig-ME] Introduction to mixed models using R and Rstudio (IMMR05)
Message-ID: <CAEsSYzxWYv0-s0fxmOanpD0HOm5-e4XtCTFxf+5Q=0tC7r55dw@mail.gmail.com>

ONLINE COURSE ? Introduction to mixed models using R and Rstudio (IMMR05)

https://www.prstatistics.com/course/introduction-to-mixed-models-using-r-and-rstudio-immr05/

This course will be delivered live but will also have all sessions recorded
allowing you to take the course in your own time should you choose.

Course Overview:
In this two day course, we provide a comprehensive practical and
theoretical introduction to multilevel models, also known as hierarchical
or mixed effects models. We will focus primarily on multilevel linear
models, but also cover multilevel generalized linear models. Likewise, we
will also describe Bayesian approaches to multilevel modelling. On Day 1,
we will begin by focusing on random effects multilevel models. These models
make it clear how multilevel models are in fact models of models. In
addition, random effects models serve as a solid basis for understanding
mixed effects, i.e. fixed and random effects, models. In this coverage of
random effects, we will also cover the important concepts of statistical
shrinkage in the estimation of effects, as well as intraclass correlation.
We then proceed to cover linear mixed effects models, particularly focusing
on varying intercept and/or varying slopes regresssion models. On Day 2, we
cover further aspects of linear mixed effects models, including multilevel
models for nested and crossed data data, and group level predictor
variables. On Day 2, we also cover Bayesian approaches to multilevel levels
using the brms R package.

THIS IS ONE COURSE IN OUR R SERIES ? LOOK OUT FOR COURSES WITH THE SAME
COURSE IMAGE TO FIND MORE IN THIS SERIES

Email oliverhooker at prstatistics.com with any questions

-- 
Oliver Hooker PhD.
PR statistics

Species Distribution Modeling using R

21 September 2021 - 30 September


Introduction to eco-phylogenetics and comparative analyses using R 22
September 2021 - 28 September 2021



Multivariate analysis of ecological communities in R with the VEGAN package

4 October 2021 - 8 October



Introduction to Data Wrangling and Data Visualization using R

4 October 2021 - 8 October 2021

Introduction to Bayesian modelling with INLA

4 October 2021 - 8 October 2021

 Landscape genetic data analysis using R

18 October 2021 - 27 October 2021

FREE 1 DAY INTRO TO R AND R STUDIO

20 October 2021


 Introduction to generalised linear models using R and Rstudio

3 November 2021 - 4 November 2021

 Introduction to mixed models using R and Rstudio

10 November 2021 - 11 November 2021

 Introduction to Machine Learning and Deep Learning using R

17 November 2021 - 18 November 2021

Model selection and model simplification

24 November 2021 - 25 November 2021


 Species distribution modelling with Bayesian statistics in R

6 December 2021 - 10 December 2021

	[[alternative HTML version deleted]]


